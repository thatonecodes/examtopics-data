{"pageProps":{"questions":[{"id":"r2sOTFjOJDZEZCSja3GU","answer":"D","unix_timestamp":1605727740,"question_text":"An online registration system is currently hosted on one large Oracle Cloud Infrastructure (OCI) Bare metal compute instance with attached block volumes to store all of the users' data. The registration system accepts the information from the user, including documents and photos and then performs automated verification and processing to check is the user is eligible for registration.\nThe registration system becomes unavailable at times, when there is a surge of users using the system. The existing architecture needs improvement as it takes a long time for the system to complete the processing and the attached block volumes are not large enough to store the ever growing data being uploaded by the users.\nWhich is the most effective option to achieve a highly scalable solution? (Choose the best answer.)","discussion":[{"comment_id":"222204","content":"I'm agree with D as answer.","poster":"fhoyos","timestamp":"1605727740.0","upvote_count":"5"},{"poster":"jcarlos","timestamp":"1606925160.0","upvote_count":"5","content":"Block volumes have to be attached to machines. if information on block volumes needs to be shared among all nodes, each of them executing part of the whole process for each registration, them it would be needed to use a cluster file system to correctly manage those block volumes attached among all server in shared mode and adapt the application to work with the cluster file system. I find option B much easier.","comment_id":"233156"},{"comments":[{"comment_id":"527827","upvote_count":"1","content":"B is clearly wrong. How is rewriting your application ever cost effective? Multiple VM instances might end up being cheaper than a single BM instance. If not, at least you can easily scale the VMs. The Streaming Service is completely irrelevant to the solution. You can use Events/Notifications to trigger actions, but not Streaming.","poster":"IT_Thinker","timestamp":"1642617660.0"}],"comment_id":"513886","timestamp":"1640927160.0","content":"B is a better option and cost effective","upvote_count":"3","poster":"Tanat"},{"comment_id":"503239","timestamp":"1639695720.0","upvote_count":"1","content":"Selected Answer: D\nAgree, D is the most effective one","poster":"SilNilanjan"},{"timestamp":"1637962860.0","poster":"Desong","comment_id":"487657","upvote_count":"2","content":"D is the right answer"},{"poster":"nenoAZ","comment_id":"302824","timestamp":"1614798480.0","content":"D is the most effective answer.","upvote_count":"1"},{"comment_id":"257038","timestamp":"1609529340.0","upvote_count":"2","poster":"WanderingBrain","content":"B requires an application level change. D doesnâ€™t. So, for me, D it is."},{"comments":[{"upvote_count":"4","comment_id":"475826","poster":"mifune","content":"The main feature of Store Data is to manage unstructured data such as video and photos, indeed. So, it's B the right answer. By the way, try to choose only one option ankit89 :)","timestamp":"1636581600.0"}],"content":"D is correct: B is not right because users are uploading vidoe and photo, not a hight volume data.","poster":"ankit89","comment_id":"240956","upvote_count":"2","timestamp":"1607693340.0"},{"upvote_count":"3","comment_id":"233764","poster":"ankit89","timestamp":"1606981260.0","content":"B: https://blogs.oracle.com/developers/publishing-to-object-storage-from-oracle-streaming-service"},{"upvote_count":"2","poster":"ankit89","comment_id":"233762","timestamp":"1606981200.0","content":"B is a better architecture option"}],"timestamp":"2020-11-18 20:29:00","answer_images":[],"answers_community":["D (100%)"],"answer_description":"","exam_id":412,"answer_ET":"D","isMC":true,"question_id":26,"choices":{"A":"Upgrade your architecture to use a pool of Bare metal servers and configure them to use their local SSDs for faster data access. Set up Oracle Streaming Service (OSS) to distribute the tasks to the pool of Bare metal instances with Auto Scaling to dynamically increase or decrease the pool of compute instances depending on the length of the Streaming queue.","B":"Change your architecture to use an OCI Object Storage standard tier bucket; replace the single bare metal instance with an Oracle Streaming Service (OSS) to ingest the incoming requests and distribute the tasks to a group of compute instances with Auto Scaling.","C":"Attach more Block volumes as the data volume increases, use Oracle Notification Service (ONS) to distribute tasks to a pool of compute instances working in parallel, and Auto Scaling to dynamically size the pool of instances depending on the number of notifications received from the Notification Service. Use Resource Manager stacks to replicate your architecture to another region.","D":"Upgrade your architecture to use more Block volumes as the data volume increases. Replace the single bare metal instance with a group of compute instances with Auto Scaling to dynamically increase or decrease the compute instance pools depending on the traffic."},"question_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/oracle/view/37242-exam-1z0-997-20-topic-1-question-32-discussion/"},{"id":"0z74KjY2eQ2yHpXLc0wf","url":"https://www.examtopics.com/discussions/oracle/view/37252-exam-1z0-997-20-topic-1-question-33-discussion/","unix_timestamp":1605734100,"isMC":true,"answer":"C","answers_community":[],"topic":"1","question_text":"Your customer recently provisioned a 1-Gbps FastConnect connection in ap-tokyo-1 region of Oracle Cloud Infrastructure (OCI). They will use this to connect to one Virtual Cloud Network (VCN) in their production OCI tenancy compartment and another VCN in their development OCI tenancy.\nHow should you configure the connectivity between on-premises and the two VCNs in OCI using the single FastConnect connection? (Choose the best answer.)","answer_images":[],"question_images":[],"question_id":27,"choices":{"B":"Create two private virtual circuits on the FastConnect link. Create two Dynamic Routing Gateways, one for each VCNs. Attach the virtual circuits to the dynamic routing gateways.","A":"Provision a Dynamic Routing Gateway (DRG) and create a private virtual circuit for the FastConnect connection. Create one additional route table in your production VCN that includes two routes rules. One with a destination of the on-premises network using the DRG, and a second with a destination of the development VCN, also using the DRG.","C":"Create a hub-VCN that uses DRG to communicate with the on-premises network over FastConnect. Connect the hub-VCN to the production VCN spoke and with development VCN spoke, each peered via their respective Local Peering Gateway (LPG).","D":"Create a single private virtual circuit over FastConnect and attach Fastconnect to either of the VCN's DRG. Use Remote Peering to peer production and development VCNs."},"discussion":[{"poster":"fhoyos","upvote_count":"5","comment_id":"222257","timestamp":"1605734100.0","content":"Answer is C: There's an advanced routing scenario called transit routing that enables communication between an onpremises network and multiple VCNs over a single Oracle Cloud Infrastructure FastConnect or IPSec VPN.\nThe VCNs must be in the same region and locally peered in a hub-and-spoke layout. As part of the scenario, the VCN that is acting as the hub has a route table associated with each LPG (typically route tables are associated with a VCN's subnets)."},{"content":"C is correct Hub -VCN","comment_id":"337913","timestamp":"1618713000.0","upvote_count":"3","poster":"URB"},{"upvote_count":"2","timestamp":"1610697960.0","poster":"MASD","comment_id":"267727","content":"Answer is C"},{"content":"C is right","timestamp":"1607693460.0","poster":"ankit89","comment_id":"240957","upvote_count":"2"}],"timestamp":"2020-11-18 22:15:00","answer_description":"Reference:\nhttps://docs.cloud.oracle.com/en-us/iaas/Content/Network/Tasks/transitrouting.htm","exam_id":412,"answer_ET":"C"},{"id":"zvs52AbA0dilFzX0SLlp","question_id":28,"unix_timestamp":1606181280,"discussion":[{"content":"Answer A: From the documentation and link provided. \nWe recommend using the maximum availability mode in SYNC mode between two availability domains (same region), and using the maximum availability mode in ASYNC mode between two regions. This architecture provides you the best RTO and RPO without causing any data loss.","timestamp":"1606181280.0","poster":"fhoyos","comment_id":"226266","upvote_count":"5"},{"upvote_count":"4","comment_id":"267724","timestamp":"1610697900.0","content":"Correct : A","poster":"MASD"}],"question_text":"All three Data Guard configurations are fully supported on Oracle Cloud Infrastructure (OCI). You want to deploy a maximum availability architecture (MAA) for database workload.\nWhich option should you consider while designing your Data Guard configuration to ensure best RTO and RPO without causing any data loss? (Choose the best answer.)","topic":"1","question_images":[],"isMC":true,"answer":"A","choices":{"C":"Configure \"Maximum Scalability\" mode which provides the highest level of scalability without compromising the availability of the primary database.","D":"Configure \"Maximum Performance\" mode in SYNC mode between two availability domains (same region) which provides the highest level of data protection that is possible without affecting the performance of the primary database.","A":"Configure \"Maximum Availability\" mode in SYNC mode between two availability domains (same region), and use the Maximum Availability mode in ASYNC mode between two regions.","B":"Configure \"Maximum Protection\" mode which provides zero data loss if the primary database fails."},"exam_id":412,"answer_description":"Reference:\nhttps://docs.oracle.com/en/solutions/design-dr/plan-dr-databases1.html#GUID-52D010DF-FB8D-4098-B6D3-C7C4CAFB0FE4","timestamp":"2020-11-24 02:28:00","answers_community":[],"answer_images":[],"answer_ET":"A","url":"https://www.examtopics.com/discussions/oracle/view/37654-exam-1z0-997-20-topic-1-question-34-discussion/"},{"id":"7Z5yduyQIRcWcn2QgUD2","answers_community":["CE (100%)"],"choices":{"B":"Contiguous numbers need to be assigned for each part so that Object Storage constructs the object by ordering part numbers in ascending order.","D":"It is possible to split this file into multiple parts using the APIs provided by Object Storage.","A":"It is possible to split this file into multiple parts using rclone tool provided by Object Storage.","C":"After initiating a multipart upload by making a CreateMultiPartUpload REST API Call, the upload remains active until you explicitly commit it or about it.","E":"Active multipart upload can be checked by listing all parts that have been uploaded, however it is not possible to list information for an individual object part in an active multipart upload."},"question_id":29,"question_images":[],"question_text":"As a part of a migration exercise for an existing on-premises application to Oracle Cloud Infrastructure (OCI), you are required to transfer a 7 TB file to OCI Object\nStorage. You have decided to upload it using the multipart upload functionality of Object Storage.\nWhich two statements are true? (Choose two.)","answer":"CE","url":"https://www.examtopics.com/discussions/oracle/view/36533-exam-1z0-997-20-topic-1-question-35-discussion/","answer_description":"Reference:\nhttps://docs.cloud.oracle.com/en-us/iaas/Content/Object/Tasks/usingmultipartuploads.htm","topic":"1","exam_id":412,"timestamp":"2020-11-09 09:05:00","answer_ET":"BC","unix_timestamp":1604909100,"answer_images":[],"isMC":true,"discussion":[{"content":"should be CE","upvote_count":"10","timestamp":"1604909100.0","poster":"nwongsf","comment_id":"215748"},{"timestamp":"1646878740.0","poster":"LeeToowey","upvote_count":"2","comment_id":"564462","content":"B can not be righthttps://docs.oracle.com/en-us/iaas/Content/Object/Tasks/usingmultipartuploads.htm#:~:text=Multipart%20uploads%20accommodate%20objects%20that,no%20larger%20than%2050%20GiB.\nIt specifically says you DO NOT need to assign contiguous numbers"},{"content":"C and E\nhttps://docs.oracle.com/en-us/iaas/Content/Object/Tasks/usingmultipartuploads.htm\nThe answers are literally taken from the text of the website. Search for 'check' and 'active' and you will quickly see that C and E are the correct answers.","timestamp":"1642618620.0","upvote_count":"3","poster":"IT_Thinker","comment_id":"527833"},{"poster":"VishnuChirra","content":"Selected Answer: CE\nC and E","comment_id":"512641","timestamp":"1640806500.0","upvote_count":"2"},{"comment_id":"249587","timestamp":"1608576540.0","content":"Its corrects C y E","upvote_count":"3","poster":"Dollmaster"},{"poster":"ankit89","upvote_count":"2","comment_id":"240958","content":"CE is the right answer!","timestamp":"1607693640.0"},{"comments":[{"poster":"adesmaster","upvote_count":"2","content":"You don't need to assign contiguous numbers... so B is incorrect.","comment_id":"234190","timestamp":"1607015880.0"}],"timestamp":"1606985340.0","comment_id":"233804","upvote_count":"1","content":"BC is right: Creating Object Parts\nWith multipart upload, you split the object you want to upload into individual parts. Individual parts can be as large as 50 GiB. Decide what part number you want to use for each part. Part numbers can range from 1 to 10,000. You do not need to assign contiguous numbers, but Object Storage constructs the object by ordering part numbers in ascending order.\n\nInitiating an Upload\nAfter you finish creating object parts, initiate a multipart upload by making a CreateMultipartUpload REST API call. Provide the object name and any object metadata. Object Storage responds with a unique upload ID that you must include in any requests related to this multipart upload. Object Storage also marks the upload as active. The upload remains active until you explicitly commit it or abort it.\n\nhttps://docs.cloud.oracle.com/en-us/iaas/Content/Object/Tasks/usingmultipartuploads.htm","poster":"ankit89"},{"content":"CE are the right ones","timestamp":"1606181760.0","poster":"fhoyos","upvote_count":"4","comment_id":"226271"}]},{"id":"gtJqZ7blPdCWQMnWdqJw","isMC":true,"exam_id":412,"answer_description":"","url":"https://www.examtopics.com/discussions/oracle/view/37255-exam-1z0-997-20-topic-1-question-36-discussion/","question_id":30,"discussion":[{"timestamp":"1605874020.0","comment_id":"223559","poster":"rc_1030","upvote_count":"11","comments":[{"poster":"Ganmook","upvote_count":"2","timestamp":"1635185100.0","comment_id":"467625","content":"So, what you think about A than C? in the question, there is emphasized 'Most time-efficient'."}],"content":"Yes, C is the answer.\nCan a customer use an Oracle Autonomous Database backup to restore a database to another/new Oracle Autonomous Database instance?\nNo, ADB backups can only be used to restore and recover to the same database. However, customers have the ability to clone a database and can choose to clone either the full database or only the database metadata.\n(https://www.oracle.com/database/technologies/datawarehouse-bigdata/adb-faqs.html)"},{"content":"Selected Answer: C\nC is the answer. It is even possible to create refreshable clone (read only) and share it for reporting purposes","poster":"Tanat","comment_id":"513895","timestamp":"1640928540.0","upvote_count":"3"},{"content":"C is correct","poster":"MASD","upvote_count":"2","comment_id":"267729","timestamp":"1610698080.0"},{"comment_id":"233809","poster":"ankit89","content":"Answer is C only","upvote_count":"1","timestamp":"1606985700.0"},{"upvote_count":"3","comment_id":"222267","poster":"fhoyos","content":"I think the C option is the fastest way to get a non production copy of the database. A is valid option too. D is the option if we are creating the non production database in different tenant. What others think about it?","timestamp":"1605734820.0"}],"answer_ET":"C","answer":"C","choices":{"D":"Take a Data Pump export of the production Autonomous database and import into the non-production database.","B":"Create a metadata clone of the production Autonomous Database and create the non-production database from it.","A":"Take a full database backup of the production Autonomous database and create the non-production database from it.","C":"Create a full clone of the production Autonomous Database and create the non-production database from it."},"timestamp":"2020-11-18 22:27:00","answer_images":[],"unix_timestamp":1605734820,"answers_community":["C (100%)"],"question_text":"You are advising the database administrator responsible for managing non-production environment for Oracle Autonomous Database running on Oracle Cloud\nInfrastructure. You need to help the database administrator ensure that the non-production environments have a copy of the current data from the production environment in a manner that is most time-efficient.\nWhich method should you recommend? (Choose the best answer.)","topic":"1","question_images":[]}],"exam":{"isBeta":false,"isImplemented":true,"id":412,"lastUpdated":"12 Apr 2025","numberOfQuestions":50,"isMCOnly":true,"name":"1z0-997-20","provider":"Oracle"},"currentPage":6},"__N_SSP":true}