{"pageProps":{"questions":[{"id":"yeTIY7RHNB9RYTF8or7l","isMC":true,"timestamp":"2021-01-02 17:51:00","url":"https://www.examtopics.com/discussions/oracle/view/41246-exam-1z0-1072-20-topic-1-question-14-discussion/","unix_timestamp":1609606260,"question_text":"You are designing a lab exercise with an application that includes a large number of graphics with large file sizes. The application becomes unresponsive if the graphics are embedded in the application. You have uploaded the graphics to Oracle Cloud Infrastructure Object Storage bucket and added the URL paths for the individual objects in the application. You need to ensure these graphics are accessible without requiring any authentication for an extended period of time.\nHow can you achieve these requirements?","exam_id":384,"answers_community":["C (100%)"],"answer":"C","answer_description":"","choices":{"C":"Make the Object Storage bucket public and use the URL path for the individual objects.","B":"Make the Object Storage bucket private, make all objects public, and use the URL found in the object \"Details\".","D":"Create pre-authenticated requests (PAR) and specify 00:00:0000 as the expiration time.","A":"Create pre-authenticated requests (PAR) and do not specify any expiration time."},"topic":"1","question_images":[],"question_id":6,"answer_ET":"C","discussion":[{"upvote_count":"13","timestamp":"1609606260.0","content":"That is correct.\nC is the answer.","comment_id":"257677","poster":"Davar39"},{"timestamp":"1622106060.0","comment_id":"367736","upvote_count":"5","comments":[{"upvote_count":"1","comment_id":"500381","content":"C is correct. This question is part of the preparation course on the OCI 2021 Architect workshop.","poster":"sam_11","timestamp":"1639370460.0"},{"comment_id":"417677","upvote_count":"5","content":"That input is invalid. So C is right.","timestamp":"1627698600.0","poster":"medusarose"},{"timestamp":"1671780240.0","comment_id":"753963","upvote_count":"1","content":"00:00:0000 is not a valid expiration time. That is why this is wrong option.\nCorrect is \"C\"","poster":"abhijitviktor"}],"poster":"anuj0710","content":"The correct answer is D. \nExpiration date is required, but has no limits. You can set them as far out in the future as you want.\n\nhttps://docs.oracle.com/en-us/iaas/Content/Object/Tasks/usingpreauthenticatedrequests.htm"},{"timestamp":"1644691740.0","poster":"moustaoui","upvote_count":"1","content":"The correct answer is C","comment_id":"546043"},{"timestamp":"1639658460.0","comment_id":"502921","poster":"drunkenBear","content":"Selected Answer: C\nC is the answer.","upvote_count":"1"}],"answer_images":[]},{"id":"Hg9Wcp9ax6xqQprRxB5B","answer_description":"","answer_ET":"C","url":"https://www.examtopics.com/discussions/oracle/view/39240-exam-1z0-1072-20-topic-1-question-15-discussion/","choices":{"B":"Update the security list TWO to restrict CLIENT-Y access to read-only.","D":"Update the security list ONE to restrict CLIENT-Y access to read only.","A":"Update the OS firewall in CLIENT-X to allow READ/WRITE access.","C":"Update the mount target export options to restrict CLIENT-Y access to read-only."},"answers_community":["C (100%)"],"question_text":"You have setup your environment as shown below with the Mount Target \"MT\" successfully mounted on both compute instances CLIENT-X and CLIENT-Y.\nFor security reasons you want to control the access to the File System A in such a way that CLIENT-X has READ/WRITE and CLIENT-Y has READ only permission.\n//IMG//\n\nWhat you should do?","isMC":true,"unix_timestamp":1607440920,"question_images":["https://www.examtopics.com/assets/media/exam-media/03496/0000900001.jpg"],"exam_id":384,"discussion":[{"timestamp":"1607440920.0","comments":[{"poster":"mifune","timestamp":"1634292060.0","upvote_count":"2","comment_id":"462523","content":"Agree, the security list does not have the control over this kind of granular permissions like read/write, just enable or disable routes"}],"content":"C should be the answer as the security list is common for both the instance. hence the export option is the only available to restrict the access","comment_id":"238434","upvote_count":"22","poster":"pattabi"},{"content":"C is the correct Answer \n\nUsing NFS export option access controls, you can limit clients' ability to connect to the file system and view or write data. For example, if you want to allow clients to consume but not update resources in your file system, you can set access to Read Only. You can also reduce client root access to your file systems and map specified User IDs (UIDs) and Group IDs (GIDs) to an anonymous UID/GID of your choice. For more information about how NFS export options work with other security layers, see About Security.\nREF: https://docs.oracle.com/search/?q=mount+target+export+options+&lang=en&product=en%2Fcloud%2Foracle-cloud-infrastructure","comment_id":"317306","timestamp":"1616428440.0","poster":"Mohamed79","upvote_count":"8"},{"poster":"mkr_toronto","upvote_count":"1","timestamp":"1691582400.0","comment_id":"976614","content":"Answer is \"C\" \nhttps://docs.oracle.com/en-us/iaas/Content/File/Tasks/exportoptions2.htm#Export"},{"content":"Selected Answer: C\nI think is C","poster":"ViniciusGeral123","upvote_count":"1","timestamp":"1643440980.0","comment_id":"535277"},{"upvote_count":"1","timestamp":"1642417440.0","poster":"Rishadpp","content":"Selected Answer: C\nMount Export Option allows controlling","comment_id":"525705"},{"comment_id":"491013","content":"Selected Answer: C\nC is the correct Answer","poster":"Sherifci","upvote_count":"2","timestamp":"1638308760.0"},{"upvote_count":"1","comment_id":"483057","poster":"ethylyn","content":"C is corect \nhttps://docs.oracle.com/search/?q=mount+target+export+options+&lang=en&product=en%2Fcloud%2Foracle-cloud-infrastructure","timestamp":"1637476680.0"},{"timestamp":"1635823080.0","upvote_count":"2","poster":"adouban","content":"C for sure","comment_id":"471486"},{"timestamp":"1628130960.0","upvote_count":"2","poster":"ThaiAnh","content":"Its C because security list is grant for general access, not specific for object level","comment_id":"420020"},{"content":"The correct answere is C","poster":"anuj0710","timestamp":"1622106180.0","upvote_count":"3","comment_id":"367737"},{"comment_id":"313697","content":"C is the answer , security list cannot be used to provide read/write operations on objects","timestamp":"1616029200.0","poster":"satyalanka","upvote_count":"3"},{"upvote_count":"4","comment_id":"268799","timestamp":"1610798160.0","poster":"dreadsi3","content":"C is correct, security list just lets you define type of network traffic not to specify read/write options"},{"comment_id":"264761","upvote_count":"2","content":"From documentation - \"Access (Read_Only, Read_Write): This setting specifies the source NFS client access. If unspecified, defaults to Read_Write.\" So you have to change CLIENT-Y access to read-only.","poster":"SlawekSz","timestamp":"1610372040.0"},{"content":"C is correct","timestamp":"1610250240.0","poster":"Lif","comment_id":"263633","upvote_count":"2"},{"timestamp":"1608187920.0","content":"export options make the mount target in R only, or R/W. Security lists grant the access!!","poster":"Carminetor","comment_id":"246258","upvote_count":"1"}],"topic":"1","question_id":7,"answer_images":[],"answer":"C","timestamp":"2020-12-08 16:22:00"},{"id":"CMga160OraitApA1awla","discussion":[{"comment_id":"336187","timestamp":"1618485180.0","poster":"KAYSERSOZE","content":"IT is A and C.\n\nREF: \nhttps://www.oracle.com/database/technologies/datawarehouse-bigdata/adb-faqs.html#MIGRATION-BOOKMARK \n\nIt is clearly written that RMAN is NOT supported and \"Data Pump\" is the official way to go.","upvote_count":"14"},{"content":"AC are correct.\nhttps://docs.oracle.com/en/cloud/paas/autonomous-data-warehouse-cloud/user/load-data-sqldeveloper-web.html#GUID-C06A4E05-CCD1-4241-A8FB-76A19F5F727F","timestamp":"1608102600.0","upvote_count":"10","poster":"Carminetor","comment_id":"245268"},{"poster":"abhijitviktor","timestamp":"1671781140.0","comment_id":"753979","upvote_count":"1","content":"B, C\nRMAN Duplicate is mentioned on ORacle Documentation\nhttps://docs.oracle.com/en-us/iaas/Content/Database/Tasks/migrating.htm"},{"content":"i think answers C & D","comments":[{"upvote_count":"1","poster":"Yeanka","timestamp":"1645594380.0","comment_id":"554185","content":"It should be CD"}],"poster":"_Ahmed_Hassan_","upvote_count":"2","comment_id":"542761","timestamp":"1644276900.0"},{"poster":"Sherifci","comment_id":"491012","content":"Selected Answer: AC\nThe main migration tool for migrating to ADB is Data Pump. You can export your schemas and import them into ADB using Data Pump. To sync up the additional/incremental changes on the source database during the export/import process you can use GoldenGate or GoldenGate Cloud Service to replicate those changes to ADB.\n\nIn the current release you cannot use physical migration methods like backup/restore, Data Guard, database clones, and transportable tablespaces to move your existing database to ADB.","upvote_count":"3","timestamp":"1638308760.0"},{"content":"A,C correct\nHow can I migrate my existing Oracle Database to Oracle Autonomous Database?\n: Since an ADB database has some restrictions on the object types and Oracle Database Options you need to use a logical migration method rather than a physical one.","upvote_count":"1","comment_id":"490403","timestamp":"1638245580.0","poster":"Dylan3160"},{"poster":"ethylyn","timestamp":"1637476800.0","comment_id":"483058","content":"B AND C. Already pass the ADB exam just like this is the question","upvote_count":"1"},{"comment_id":"334219","content":"B and C maybe\nhttps://docs.oracle.com/en-us/iaas/Content/Database/Tasks/mig-rman-duplicate-active-database.htm\nThis topic explains how to migrate an entire, active container database (CDB) or non-CDB database to Oracle Cloud Infrastructure by using RMAN Active Duplication. The database to be migrated can reside on-premises or in Oracle Cloud Infrastructure Classic.","poster":"JavierV","upvote_count":"1","timestamp":"1618255800.0"},{"comment_id":"317423","poster":"briansbums","comments":[{"comment_id":"377856","upvote_count":"1","timestamp":"1623195780.0","comments":[{"content":"Because of the \"selected objects\" clause. You want to migrate the entire DB","upvote_count":"1","comment_id":"611974","timestamp":"1654450140.0","poster":"Joe_Qu"}],"poster":"vlad_74","content":"why this option can not be used?\nSQL Developer and INSERT Statements to Migrate Selected Objects"},{"timestamp":"1671781080.0","poster":"abhijitviktor","content":"Thanks for this. As per Oracle official document RMAN/Data Pump are valid options.\n\nB,C are correct","upvote_count":"1","comment_id":"753976"}],"timestamp":"1616437320.0","content":"B and C\nhttps://docs.oracle.com/en-us/iaas/Content/Database/Tasks/migrating.htm\nMigration Methods\nMany methods exist to migrate Oracle databases to the Oracle Cloud Infrastructure Database service. Which of these methods apply to a given migration scenario depends on several factors, including the version, character set, and platform endian format of the source and target databases.\n\nData Pump Conventional Export/Import\nData Pump Full Transportable\nData Pump Transportable Tablespace\nRemote Cloning a PDB\nRemote Cloning Non-CDB\nRMAN Cross-Platform Transportable PDB\nRMAN Cross-Platform Transportable Tablespace Backup Sets\nRMAN Transportable Tablespace with Data Pump\nRMAN DUPLICATE from an Active Database\nRMAN CONVERT Transportable Tablespace with Data Pump\nSQL Developer and INSERT Statements to Migrate Selected Objects\nSQL Developer and SQL*Loader to Migrate Selected Objects\nUnplugging/Plugging a PDB\nUnplugging/Plugging Non-CDB\nZero Downtime Migration Service","upvote_count":"3"},{"content":"A nd C is the answer \nRMAN wont work and what we will do by copying data files to OCOI when RMAN is not supported","upvote_count":"1","timestamp":"1616029260.0","comment_id":"313698","poster":"satyalanka"},{"comment_id":"286890","upvote_count":"2","timestamp":"1612881240.0","poster":"d5a865u","content":"A and C are the correct answers"},{"timestamp":"1611055380.0","comment_id":"271169","content":"i think A & C are the most proper ways. RMAN is not supported for migration and any backup/ or physical DB files should have the same file / DB structure in order to migrate directly","poster":"AmrWaly","upvote_count":"3"},{"timestamp":"1610798880.0","poster":"dreadsi3","upvote_count":"1","comment_id":"268810","content":"A and C"},{"content":"I think it's AC. RMAN, or physical migration methods like backup/restore are not supported (https://www.oracle.com/database/technologies/datawarehouse-bigdata/adb-faqs.html)","poster":"riso51","upvote_count":"3","timestamp":"1607861520.0","comment_id":"242537"},{"poster":"pattabi","content":"RMAN and Data pump makes more sense in migration, since there is no data volume in question","upvote_count":"1","timestamp":"1607442360.0","comment_id":"238458"}],"answer_ET":"AC","timestamp":"2020-12-08 16:46:00","answer_images":[],"question_images":[],"unix_timestamp":1607442360,"isMC":true,"question_id":8,"answer":"AC","answers_community":["AC (100%)"],"question_text":"Which two methods are supported for migrating your on-premises Oracle database to an Oracle Autonomous Transaction Processing (ATP) database in Oracle\nCloud Infrastructure? (Choose two.)","choices":{"B":"Use RMAN duplicate.","D":"Transfer the physical database files and re-create the database.","C":"Use Oracle Data Pump.","E":"Use database backup and restore.","A":"Load text files into ATP using SQL Developer."},"answer_description":"","exam_id":384,"url":"https://www.examtopics.com/discussions/oracle/view/39244-exam-1z0-1072-20-topic-1-question-16-discussion/","topic":"1"},{"id":"X2MmCv1v5LK7VNEywRp3","answer_description":"Reference:\nhttps://docs.cloud.oracle.com/en-us/iaas/Content/Object/Tasks/usingversioning.htm","answer_ET":"B","url":"https://www.examtopics.com/discussions/oracle/view/39369-exam-1z0-1072-20-topic-1-question-17-discussion/","choices":{"B":"Immutable option for data stored in the Object Storage can be set via retention rules.","A":"Object storage resources can be shared across tenancies.","D":"Object lifecycle rules can be used to either archive or delete objects.","C":"Object versioning is enabled at namespace level."},"answers_community":["C (100%)"],"question_text":"Which statement is NOT true about the Oracle Cloud Infrastructure Object Storage service?","isMC":true,"unix_timestamp":1607510640,"discussion":[{"poster":"riso51","content":"It's C:\nhttps://docs.cloud.oracle.com/en-us/iaas/Content/Object/Tasks/usingversioning.htm\nEverything else is true.","upvote_count":"18","comment_id":"242544","timestamp":"1607861940.0"},{"poster":"satyalanka","content":"C is correct , because object versioning is not enabled at bucket level not at namespace","upvote_count":"7","timestamp":"1616029740.0","comment_id":"313700"},{"upvote_count":"1","poster":"topi","content":"Selected Answer: C\nAbout Object Versioning\nObject versioning is enabled at the bucket level. Versioning directs Object Storage to automatically create an object version each time a new object is uploaded, an existing object is overwritten, or when an object is deleted. You can enable object versioning at bucket creation time or later.\nFrom: https://docs.oracle.com/en-us/iaas/Content/Object/Tasks/usingversioning.htm","timestamp":"1645041540.0","comment_id":"548889"},{"poster":"sam_11","comment_id":"500383","upvote_count":"4","content":"Why are all the answers wrong on purpose?","timestamp":"1639370760.0"},{"comment_id":"491515","upvote_count":"1","timestamp":"1638353220.0","content":"yes C is the right answer","poster":"oberte007"},{"comment_id":"491015","timestamp":"1638308880.0","upvote_count":"1","poster":"Sherifci","content":"Selected Answer: C\nC is correct"},{"timestamp":"1637476860.0","content":"C. its bucket level","upvote_count":"1","comment_id":"483059","poster":"ethylyn"},{"timestamp":"1615419960.0","upvote_count":"3","poster":"treborbg","comment_id":"307499","content":"It's C, Object versioning it's enabled at bucket level. \"About Object Versioning\" https://docs.oracle.com/en-us/iaas/Content/Object/Tasks/usingversioning.htm"},{"upvote_count":"3","timestamp":"1615347900.0","poster":"bhushandba","comment_id":"306841","content":"Object versioning is enabled at the bucket level. C is correct"},{"timestamp":"1611061500.0","upvote_count":"2","content":"C is correct. for A you can copy or access the using HTTP to copy data across tenancies. For B you can set retention rule to unmodify objects in bucket. For D this the basic rule of object life cycle","comment_id":"271233","poster":"AmrWaly"},{"poster":"Lif","comment_id":"263636","content":"C is correct","upvote_count":"2","timestamp":"1610250360.0"},{"comment_id":"257695","poster":"Davar39","timestamp":"1609607100.0","upvote_count":"4","content":"Dear mods, if you approve this comment, please make sure to change the answer to \"C\", the link you provide is pointing to the correct article stating that object versioning is enabled at the bucket level, thanks."},{"timestamp":"1609606920.0","upvote_count":"2","poster":"Davar39","content":"Agree with riso51, correct answer is C.","comment_id":"257692"},{"timestamp":"1607510640.0","upvote_count":"1","poster":"alfonso_223","comment_id":"239110","comments":[{"poster":"alfonso_223","timestamp":"1607535360.0","content":"seems I missed the \"NOT\" true in the question.","upvote_count":"1","comment_id":"239414"},{"upvote_count":"1","timestamp":"1607594940.0","content":"So both B and C are \"NOT\" true :\nObject versioning is enabled at the bucket level.\nhttps://docs.cloud.oracle.com/en-us/iaas/Content/Object/Tasks/usingversioning.htm","comment_id":"239970","poster":"alfonso_223"}],"content":"It's D.\nObject Lifecycle Management works by taking automated action based on rules you define that instruct Object Storage to archive or delete the supported resources on your behalf within a given bucket. A bucket's lifecycle rules are collectively known as an object lifecycle policy. \nhttps://docs.cloud.oracle.com/en-us/iaas/Content/Object/Tasks/usinglifecyclepolicies.htm\nAs for B the retention option is not immutable (since it's duration can be raised)"}],"question_images":[],"exam_id":384,"topic":"1","question_id":9,"answer":"C","answer_images":[],"timestamp":"2020-12-09 11:44:00"},{"id":"uTGrO3I7h33t2FDx8gI6","answer_images":[],"discussion":[{"timestamp":"1609607220.0","poster":"Davar39","upvote_count":"9","comment_id":"257698","content":"Given answers are correct, the following was taken from oracle docs.\n \"Oracle recommends that you perform a multipart upload to upload objects larger than 100 MiB. The maximum size for an uploaded object is 10 TiB. Object parts must be no larger than 50 GiB.\""},{"content":"A , C . Are correct.","poster":"CarlosGomes","upvote_count":"5","timestamp":"1617184500.0","comment_id":"324949"},{"content":"Selected Answer: AC\nsee the discussion","comment_id":"557358","upvote_count":"1","poster":"bekey59","timestamp":"1645970760.0"},{"timestamp":"1639103340.0","content":"With multipart upload, you split the object you want to upload into individual parts. Individual parts can be as large as 50 GiB. Decide what part number you want to use for each part. Part numbers can range from 1 to 10,000.\nWhile a multipart upload is still active, you can keep adding parts as long as the total number is less than 10,000.","poster":"11exam_mania11","comment_id":"498232","upvote_count":"1"},{"poster":"mcl007","timestamp":"1636493700.0","content":"A and C\nfrom oracle docs. D is not correct « While a multipart upload is still active, you can keep adding parts as long as the total number is less than 10,000.«","upvote_count":"1","comment_id":"475080"},{"content":"A and C","poster":"bjmC","comment_id":"472132","upvote_count":"1","timestamp":"1635953040.0"},{"content":"A, C are correct.","timestamp":"1633975740.0","upvote_count":"1","comment_id":"460750","poster":"Soojit"}],"answer":"AC","question_text":"You are about to upload a large log file (5 TIB size) to Oracle Cloud Infrastructure object storage and have decided to use multipart upload capability for a more efficient and resilient upload.\nWhich two statements are true about multipart upload? (Choose two.)","topic":"1","answer_description":"Reference:\nhttps://docs.cloud.oracle.com/en-us/iaas/Content/Object/Tasks/usingmultipartuploads.htm","choices":{"B":"You do not have to commit the upload after you have uploaded all the object parts.","A":"The maximum size for an uploaded object is 10 TiB.","D":"While a multipart upload is still active, you cannot add parts even if the total number of parts is less than 10,000.","C":"Individual object parts can be as small as 10 MiB or as large as 50 GiB."},"isMC":true,"exam_id":384,"answer_ET":"AC","url":"https://www.examtopics.com/discussions/oracle/view/41248-exam-1z0-1072-20-topic-1-question-18-discussion/","answers_community":["AC (100%)"],"unix_timestamp":1609607220,"timestamp":"2021-01-02 18:07:00","question_images":[],"question_id":10}],"exam":{"isBeta":false,"id":384,"name":"1z0-1072-20","isImplemented":true,"provider":"Oracle","isMCOnly":true,"numberOfQuestions":60,"lastUpdated":"12 Apr 2025"},"currentPage":2},"__N_SSP":true}