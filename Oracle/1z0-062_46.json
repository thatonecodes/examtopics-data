{"pageProps":{"questions":[{"id":"ruqQoz9GIdMKqxffsksg","isMC":true,"answer_description":"With adaptive SQL plan management, DBAs no longer have to manually run the verification or evolve process for non-accepted plans. When automatic SQL tuning is in COMPREHENSIVE mode, it runs a verification or evolve process for all SQL statements that have non-accepted plans during the nightly maintenance window. If the non-accepted plan performs better than the existing accepted plan (or plans) in the SQL plan baseline, then the plan is automatically accepted and becomes usable by the optimizer. After the verification is complete, a persistent report is generated detailing how the non-accepted plan performs compared to the accepted plan performance. Because the evolve process is now an AUTOTASK, DBAs can also schedule their own evolve job at end time.\nNote:\n* The optimizer is able to adapt plans on the fly by predetermining multiple subplans for portions of the plan.\n* Adaptive plans, introduced in Oracle Database 12c, enable the optimizer to defer the final plan decision for a statement until execution time. The optimizer instruments its chosen plan (the default plan) with statistics collectors so that it can detect at runtime, if its cardinality estimates differ greatly from the actual number of rows seen by the operations in the plan. If there is a significant difference, then the plan or a portion of it will be automatically adapted to avoid suboptimal performance on the first execution of a SQL statement.\nReferences:","url":"https://www.examtopics.com/discussions/oracle/view/26292-exam-1z0-062-topic-1-question-60-discussion/","question_images":[],"answer":"ADE","unix_timestamp":1595299200,"answers_community":[],"topic":"1","exam_id":373,"choices":{"B":"The optimizer always uses the fixed plan, if the fixed plan exists in the plan baseline.","E":"The non-accepted plans in a SQL plan baseline are automatically evolved, in COMPREHENSIVE mode, during the nightly maintenance window and a","A":"It automatically performs verification or evolves non-accepted plans, in COMPREHENSIVE mode when they perform better than existing accepted plans.","D":"The non-accepted plans are automatically accepted and become usable by the optimizer if they perform better than the existing accepted plans.","C":"It adds new, bettor plans automatically as fixed plans to the baseline."},"discussion":[{"poster":"sela","timestamp":"1663915320.0","comment_id":"676838","content":"a,d,e\n2.2.4.2 Adaptive SQL Plan Management\n\nWith adaptive SQL plan management, DBAs no longer have to manually run the verification or evolve process for non-accepted plans. When automatic SQL tuning is in COMPREHENSIVE mode, it runs a verification or evolve process for all SQL statements that have non-accepted plans during the nightly maintenance window. If the non-accepted plan performs better than the existing accepted plan (or plans) in the SQL plan baseline, then the plan is automatically accepted and becomes usable by the optimizer. After the verification is complete, a persistent report is generated detailing how the non-accepted plan performs compared to the accepted plan performance. Because the evolve process is now an AUTOTASK, DBAs can also schedule their own evolve job at end time.\n\nUnaccepted plans in a SQL plan baseline are automatically evolved during the nightly maintenance window and a persistent verification report is generated which means a DBA no longer has to manual evolve plans and they can go back days or weeks later and review what plans were evolved during each of the nightly maintenance windows.\n\nhttps://docs.oracle.com/database/121/NEWFT/chapter12101.htm#NEWFT205","upvote_count":"1"},{"comment_id":"139981","upvote_count":"4","timestamp":"1595299200.0","content":"Check the documentation: https://docs.oracle.com/database/121/NEWFT/chapter12101.htm#NEWFT205 Section: 2.2.4.2 Adaptive SQL Plan Management The key of this is: COMPREHENSIVE mode","poster":"TuxBingo"}],"question_text":"Which three statements are true about adaptive SQL plan management? (Choose three.)","question_id":226,"answer_ET":"ADE","answer_images":[],"timestamp":"2020-07-21 04:40:00"},{"id":"su08Bzp9KRJ0FtJRtP1d","choices":{"B":"Rebalance operations are completed faster than with a fixed extent size","C":"An ASM Instance automatically allocates an appropriate extent size.","D":"Resync operations are completed faster when a disk comes online after being taken offline.","E":"Performance improves in a stretch cluster configuration by reading from a local copy of an extent.","A":"The metadata used to track extents in SGA is reduced."},"url":"https://www.examtopics.com/discussions/oracle/view/26293-exam-1z0-062-topic-1-question-62-discussion/","answer":"AC","answer_images":[],"answer_description":"A: Variable size extents enable support for larger ASM datafiles, reduce SGA memory requirements for very large databases (A), and improve performance for file create and open operations.\nC: You don't have to worry about the sizes; the ASM instance automatically allocates the appropriate extent size.\nNote:\n* The contents of ASM files are stored in a disk group as a set, or collection, of data extents that are stored on individual disks within disk groups. Each extent resides on an individual disk. Extents consist of one or more allocation units (AU). To accommodate increasingly larger files, ASM uses variable size extents.\n* The size of the extent map that defines a file can be smaller by a factor of 8 and 64 depending on the file size. The initial extent size is equal to the allocation unit size and it increases by a factor of 8 and 64 at predefined thresholds. This feature is automatic for newly created and resized datafiles when the disk group compatibility attributes are set to Oracle Release 11 or higher.","timestamp":"2020-07-21 04:57:00","topic":"1","answer_ET":"AC","discussion":[{"upvote_count":"2","poster":"TuxBingo","timestamp":"1595300220.0","comment_id":"139988","content":"I agree with the answer, please refere to the link: https://docs.oracle.com/cd/B28359_01/server.111/b31107/asmcon.htm#OSTMG94058"}],"question_images":[],"question_id":227,"exam_id":373,"answers_community":[],"isMC":true,"unix_timestamp":1595300220,"question_text":"Which two statements are true about variable extent size support for large ASM files? (Choose two.)"},{"id":"dAKdCkRgBPnJch75SqMM","answer_ET":"C","answer_images":[],"unix_timestamp":1585245240,"discussion":[{"content":"Agree with the answer C \nLik Oracle documentation:https://docs.oracle.com/cd/E11882_01/backup.112/e10642/rcmtspit.htm#BRADV89790","poster":"TuxBingo","upvote_count":"2","timestamp":"1595300760.0","comment_id":"140000"},{"content":"Why is not E?","comments":[{"poster":"TuxBingo","timestamp":"1595300520.0","comment_id":"139993","content":"Hi Phoenix22\nWhen you perform a drop user or drop user cascade, the recycle bin is purge by default. Reference: https://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_9008.htm \"When you drop a user, Oracle Database also purges all of that user's schema objects from the recycle bin.\"\n\nRegards.","upvote_count":"5"},{"timestamp":"1648570680.0","content":"This is a version 11g database if it was version 12 then E is the correct answer.","upvote_count":"1","comment_id":"577719","poster":"Blade69"}],"timestamp":"1585245240.0","upvote_count":"1","comment_id":"68408","poster":"Phoenix22"}],"exam_id":373,"question_images":[],"isMC":true,"answer":"C","question_id":228,"url":"https://www.examtopics.com/discussions/oracle/view/17528-exam-1z0-062-topic-1-question-63-discussion/","topic":"1","choices":{"C":"Recover the table using Automated Tablespace Point In Time Recovery.","A":"Execute FLASHBACK TABLE OCA.EXAM_RESULTS TO BEFORE DROP RENAME TO OCP.EXAM_RESULTS; connected as SYSTEM.","D":"Recovery the table using Database Point In Time Recovery.","B":"Recover the table using traditional Tablespace Point In Time Recovery.","E":"Execute FLASHBACK TABLE OCA.EXAM_RESULTS TO BEFORE DROP RENAME TO EXAM_RESULTS; connected as the OCP user."},"question_text":"You executed a DROP USER CASCADE on an Oracle 11g release 1 database and immediately realized that you forgot to copy the OCA.EXAM_RESULTS table to the OCP schema.\nThe RECYCLE_BIN enabled before the DROP USER was executed and the OCP user has been granted the FLASHBACK ANY TABLE system privilege.\nWhat is the quickest way to recover the contents of the OCA.EXAM_RESULTS table to the OCP schema?","answers_community":[],"answer_description":"RMAN tablespace point-in-time recovery (TSPITR).\nRecovery Manager (RMAN) TSPITR enables quick recovery of one or more tablespaces in a database to an earlier time without affecting the rest of the tablespaces and objects in the database.\nFully Automated (the default)\nIn this mode, RMAN manages the entire TSPITR process including the auxiliary instance. You specify the tablespaces of the recovery set, an auxiliary destination, the target time, and you allow RMAN to manage all other aspects of TSPITR.\nThe default mode is recommended unless you specifically need more control over the location of recovery set files after TSPITR, auxiliary set files during TSPITR, channel settings and parameters or some other aspect of your auxiliary instance.","timestamp":"2020-03-26 18:54:00"},{"id":"6h70yBQHOPxhSEuu2j6U","answer_description":"* The CREATE DATABASE ... ENABLE PLUGGABLE DATABASE SQL statement creates a new CDB. If you do not specify the ENABLE PLUGGABLE\nDATABASE clause, then the newly created database is a non-CDB and can never contain PDBs.\nAlong with the root (CDB$ROOT), Oracle Database automatically creates a seed PDB (PDB$SEED). The following graphic shows a newly created CDB:\n\n* Creating a PDB\nRather than constructing the data dictionary tables that define an empty PDB from scratch, and then populating its Obj$ and Dependency$ tables, the empty PDB is created when the CDB is created. (Here, we use empty to mean containing no customer-created artifacts.) It is referred to as the seed PDB and has the name\nPDB$Seed. Every CDB non-negotiably contains a seed PDB; it is non-negotiably always open in read-only mode. This has no conceptual significance; rather, it is just an optimization device. The create PDB operation is implemented as a special case of the clone PDB operation.","choices":{"E":"It will create a CDB with root opened and seed mounted.","D":"It will create a CDB that must be plugged into an existing CDB.","C":"It will create a CDB with root and seed opened and one PDB mounted.","B":"It will create a CDB with root opened and seed read only.","A":"It will create a multitenant container database (CDB) with only the root opened."},"url":"https://www.examtopics.com/discussions/oracle/view/71364-exam-1z0-062-topic-1-question-66-discussion/","isMC":true,"topic":"1","question_id":229,"answers_community":[],"answer":"B","answer_ET":"B","exam_id":373,"timestamp":"2022-02-13 10:40:00","question_text":"What is the effect of specifying the \"ENABLE PLUGGABLE DATABASE\" clause in a \"CREATE DATABASE\" statement?","question_images":[],"unix_timestamp":1644745200,"discussion":[{"timestamp":"1644745200.0","upvote_count":"2","comment_id":"546360","content":"That means create a CDB will not include a PDB by default?","poster":"jackymak"}],"answer_images":["https://www.examtopics.com/assets/media/exam-media/02261/0005300001.jpg"]},{"id":"60FE7c0PUsvURzRENdZD","timestamp":"2020-04-28 17:38:00","question_images":[],"question_text":"Examine the following parameters for a database instance:\n\nMEMORY_MAX_TARGET=0 -\n\nMEMORY_TARGET=0 -\n\nSGA_TARGET=0 -\n\nPGA_AGGREGATE_TARGET=500m -\nWhich three initialization parameters are not controlled by Automatic Shared Memory Management (ASMM)? (Choose three.)","url":"https://www.examtopics.com/discussions/oracle/view/19268-exam-1z0-062-topic-1-question-68-discussion/","answers_community":[],"unix_timestamp":1588088280,"choices":{"D":"STREAMS_POOL_SIZE","E":"DB_16K_CACHE_SZIE","B":"SORT_AREA_SIZE","F":"DB_KEEP_CACHE_SIZE","A":"LOG_BUFFER","C":"JAVA_POOL_SIZE"},"isMC":true,"answer_images":["https://www.examtopics.com/assets/media/exam-media/02261/0005500001.png"],"topic":"1","discussion":[{"comment_id":"546379","upvote_count":"1","poster":"jackymak","content":"A,B,F is what I think.","timestamp":"1644746880.0"},{"comment_id":"337581","timestamp":"1618663380.0","upvote_count":"2","poster":"IamGo0ke","content":"A,E,F is correct. Under automatic memory control the following memory components will be managed automatically, you can override the ASMM by specifying the size of the component in the init.ora file or setting its value (spfile), remember that the values will be deducted from the SGA_TARGET value. The values also state the minimum value that will be allocated.\n\nBuffer cache (DB_CACHE_SIZE)\nshared pool (SHARED_POOL_SIZE)\nlarge pool (LARGE_POOL_SIZE)\njava pool (JAVA_POOL_SIZE)\nstreams pool (STREAMS_POOL_SIZE)\nWhen using ASMM you still need to manually configure\n\nlog buffer (LOG_BUFFER)\ndb buffer cache keep pool (DB_KEEP_CACHE_SIZE)\ndb buffer recycle pool (DB_RECYCLE_CACHE_SIZE)\ndb buffer nK block size pools (DB_nK_CACHE_SIZE) https://sites.google.com/site/oracledb009/database-concepts/asmm"},{"upvote_count":"2","comment_id":"286014","content":"It should be - A, B, F ??","timestamp":"1612767660.0","poster":"fridaytar"}],"question_id":230,"exam_id":373,"answer_ET":"AEF","answer":"AEF","answer_description":"Manually Sized SGA Components that Use SGA_TARGET Space\nSGA Component, Initialization Parameter\n/ The log buffer\n\nLOG_BUFFER -\n/ The keep and recycle buffer caches\n\nDB_KEEP_CACHE_SIZE -\n\nDB_RECYCLE_CACHE_SIZE -\n/ Nonstandard block size buffer caches\n\nDB_nK_CACHE_SIZE -\nNote:\n* In addition to setting SGA_TARGET to a nonzero value, you must set to zero all initialization parameters listed in the table below to enable full automatic tuning of the automatically sized SGA components.\n* Table, Automatically Sized SGA Components and Corresponding Parameters"}],"exam":{"id":373,"isImplemented":true,"isBeta":false,"lastUpdated":"12 Apr 2025","isMCOnly":true,"numberOfQuestions":282,"provider":"Oracle","name":"1z0-062"},"currentPage":46},"__N_SSP":true}