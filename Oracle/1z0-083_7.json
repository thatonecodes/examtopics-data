{"pageProps":{"questions":[{"id":"inQ0GhhaKzvsp3oGDzUF","answer_description":"","question_images":[],"answer_images":[],"answers_community":["CD (100%)"],"url":"https://www.examtopics.com/discussions/oracle/view/52256-exam-1z0-083-topic-1-question-126-discussion/","discussion":[{"upvote_count":"12","comment_id":"353467","content":"I thinks CD correct","poster":"RinD","timestamp":"1652161860.0"},{"timestamp":"1653059280.0","poster":"dunhill","upvote_count":"5","comment_id":"362298","content":"I think CD"},{"poster":"piontk","comment_id":"1017173","upvote_count":"1","content":"Selected Answer: CD\nCD. REF: https://www.oracle.com/a/tech/docs/twp-upgrade-oracle-database-19c.pdf","timestamp":"1727293380.0"},{"poster":"_gio_","timestamp":"1720158240.0","upvote_count":"1","content":"Selected Answer: CD\nSure of CD: https://www.oracle.com/a/tech/docs/twp-upgrade-oracle-database-19c.pdf","comment_id":"943338"},{"content":"Selected Answer: CD\nCD should be correct","poster":"vkra","comment_id":"825884","upvote_count":"1","comments":[{"upvote_count":"1","content":"https://docs.oracle.com/en/database/oracle/oracle-database/19/upgrd/upgrading-oracle-database-upgrade-assistant-dbua.html#GUID-A10C2BBB-F884-4BD3-A8EA-3A8E48029E2E","comment_id":"825886","timestamp":"1709299800.0","poster":"vkra"}],"timestamp":"1709299680.0"}],"isMC":true,"topic":"1","question_text":"In which two situations can you use Database Upgrade Assistant? (Choose two.)","question_id":31,"answer_ET":"CD","answer":"CD","exam_id":381,"unix_timestamp":1620625860,"timestamp":"2021-05-10 07:51:00","choices":{"D":"when the target and source database are on the same platform","B":"when a character set conversion is required during the upgrade","A":"when the operating system (OS) needs to be changed as part of the upgrade","E":"when the hardware platform needs to be changed as part of the upgrade","C":"when multiple pluggable databases in a container database have to be upgraded in a specific sequence"}},{"id":"nB3B2OgvXU6xBs75ztt6","answers_community":["DE (100%)"],"answer_images":[],"exam_id":381,"answer_description":"","isMC":true,"url":"https://www.examtopics.com/discussions/oracle/view/52172-exam-1z0-083-topic-1-question-127-discussion/","choices":{"B":"PGA_AGGREGATE_LIMIT is a hard limit on the PGA size for any one session.","A":"The private SQL area (UGA) is located in the System Global Area (SGA) when using dedicated servers.","D":"Sorts and Hash Joins use PGA memory.","C":"The entire PGA is located in the System Global Area (SGA) when using shared servers.","E":"The private SQL area (UGA) is located in the System Global Area (SGA) when using shared servers."},"discussion":[{"comment_id":"353473","upvote_count":"9","poster":"RinD","timestamp":"1636531560.0","content":"DE correct","comments":[{"timestamp":"1720102080.0","poster":"Kuraudio","comment_id":"1113849","upvote_count":"1","content":"E explanation:\n\"The UGA must be available to a database session for the life of the session. For this reason, the UGA cannot be stored in the PGA when using a shared server connection because the PGA is specific to a single process. Therefore, the UGA is stored in the SGA when using shared server connections, enabling any shared server process access to it. When using a dedicated server connection, the UGA is stored in the PGA. \""}]},{"timestamp":"1704441480.0","content":"Selected Answer: DE\nDE excluding wrong answers, but only a specific part of Private SQL Area is located in SGA when shared server is enables","comment_id":"943343","upvote_count":"1","poster":"_gio_"},{"timestamp":"1698620880.0","comment_id":"884718","poster":"ScottL","content":"DE correct.\n\nhttps://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/memory-architecture.html#GUID-0788EAEE-0E93-497B-9ACA-401EC0F7BCA1","upvote_count":"1"},{"content":"Selected Answer: DE\nDE\nhttps://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/memory-architecture.html#GUID-0788EAEE-0E93-497B-9ACA-401EC0F7BCA1","poster":"vkra","comment_id":"825900","timestamp":"1693568640.0","upvote_count":"1"},{"comment_id":"765375","content":"D E sure","timestamp":"1688451600.0","poster":"hilaire","upvote_count":"1"},{"poster":"nobody347","upvote_count":"3","content":"D and E 100%","comment_id":"446161","timestamp":"1647465660.0"},{"upvote_count":"3","timestamp":"1638135480.0","poster":"ABAJ","comment_id":"368993","content":"DE are correct answer."},{"comment_id":"366996","timestamp":"1637925780.0","upvote_count":"1","content":"I agree with DE. (https://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/memory-architecture.html#GUID-913335DF-050A-479A-A653-68A064DCCA41)","poster":"Rogazan"},{"comment_id":"363142","timestamp":"1637516700.0","poster":"ObserverPL","content":"Agree, D and E","upvote_count":"4"},{"content":"I think DE","poster":"dunhill","timestamp":"1636446660.0","comment_id":"352836","upvote_count":"2"}],"answer_ET":"AB","question_id":32,"question_images":[],"answer":"DE","timestamp":"2021-05-09 08:31:00","unix_timestamp":1620541860,"topic":"1","question_text":"Which two are true about the Program Global Area (PGA) and its management in an Oracle database instance? (Choose two.)"},{"id":"BQb5Lv2lcY2rDFIaUHmZ","question_text":"Which two are true about creating RMAN backups for an Oracle container database? (Choose two.)","answer_ET":"BC","url":"https://www.examtopics.com/discussions/oracle/view/52176-exam-1z0-083-topic-1-question-128-discussion/","isMC":true,"answer_images":[],"topic":"1","choices":{"B":"Control file backups can be created while connected to the root container.","D":"Archived Redo Log backups can be created while connected to an application root CDB.","C":"The BACKUP TABLESPACE command can back up a PDB tablespace even if RMAN is connected to CDB$ROOT.","E":"Control file backups can be created while connected to a nonroot container.","A":"Online Redo Log backups can be created while connected to the root container."},"answer":"BC","answers_community":["BC (55%)","BE (45%)"],"discussion":[{"content":"A - FALSE. The ARCH process backs up online redo logs (by creating Arch redo logs), never the DBA. DBAs backup Archive Redo Logs, not online redo logs. \nB - TRUE. Control files are DB wide - backing them up, from the Container Root, is exactly where you do this.\nC - TRUE. Part of the point of Multitenant is that you have control of all PDBs from the CDB level. \nD - FALSE. An application root container is still below the main Container, so you cannot administer control files from here.\nE - FALSE. For the same reason as above, you can only create control file backups from the Root Container.\n\nSo, BC is correct.","timestamp":"1643381700.0","poster":"xRodge","upvote_count":"9","comment_id":"416200"},{"comment_id":"363146","timestamp":"1637516760.0","content":"B and C no doubt","poster":"ObserverPL","upvote_count":"7"},{"content":"Selected Answer: BC\nE is wrong. tested in lab. connecting to pdb directly and running a backup doesnt take archivelog backup or controlfile auto backup. so D is wrong also.\nC is correct and tested in lab and in documentation and student guide.","comment_id":"1325657","timestamp":"1734013080.0","upvote_count":"1","poster":"wagihov"},{"comment_id":"1204530","timestamp":"1730294100.0","content":"Selected Answer: BC\nE: controlfile can be created in PDB, but can it be created in PDB$SEED?","poster":"7206e44","upvote_count":"1"},{"content":"E- FALSE, TESTED\n\nRMAN> BACKUP CONTROLFILECOPY all;\n\nStarting backup at 30-MAR-24\nusing target database control file instead of recovery catalog\nallocated channel: ORA_DISK_1\nchannel ORA_DISK_1: SID=505 device type=DISK\nRMAN-00571: ===========================================================\nRMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============\nRMAN-00571: ===========================================================\nRMAN-03002: failure of backup command at 03/30/2024 16:43:06\nRMAN-20220: control file copy not found in the repository","comment_id":"1186165","timestamp":"1727703780.0","poster":"antonica","upvote_count":"1"},{"poster":"antonica","comment_id":"1184793","timestamp":"1727523720.0","upvote_count":"1","content":"BC i agree"},{"content":"Selected Answer: BC\nthree answers are correct BCE.\nI tested E in lab and it works, I agree with xRodge for A","timestamp":"1704443640.0","upvote_count":"2","poster":"_gio_","comment_id":"943378"},{"poster":"ScottL","content":"BE and C are correct\nA. Online Redo Log backups can be created while connected to the root container.\nFALSE - we don't backup online redo logs, we backup archived logs. ARCH backs up online redo\nB. Control file backups can be created while connected to the root container.\nTRUE - backup current controlfile;\nC. The BACKUP TABLESPACE command can back up a PDB tablespace even if RMAN is connected to CDB$ROOT.\nTRUE - backup tablepace pdb1:t1;\nD. Archived Redo Log backups can be created while connected to an application root CDB.\nFALSE - \"skipping archived logs when connected to a PDB\"\nE. Control file backups can be created while connected to a nonroot container.\nTRUE - During tests, I am able to backup a controlfile while connected to a nonroot container","upvote_count":"1","comment_id":"884722","timestamp":"1698621720.0"},{"poster":"vkra","upvote_count":"2","content":"Selected Answer: BC\nB and C is correct","comment_id":"825969","timestamp":"1693571760.0"},{"poster":"flaviogcmelo","comment_id":"593435","timestamp":"1666914360.0","content":"Selected Answer: BE\nI believe there are three correct answers to this question;\nb) obvious answer\nc) Tested in version 19.3: tablespace backup pdb1:tbs_name;\ne) Tested on version 19.3 connected to pdb1: backup current controlfile;","upvote_count":"5"},{"upvote_count":"1","timestamp":"1663959180.0","content":"Connected to:\nOracle Database 19c Standard Edition 2 Release 19.0.0.0.0 - Production\nVersion 19.12.0.0.0\n\nSQL> SHOW PDBS\n\n CON_ID CON_NAME OPEN MODE RESTRICTED\n---------- ------------------------------ ---------- ----------\n 2 PDB$SEED READ ONLY NO\n 3 PDB1 READ WRITE NO\nSQL> alter session set container=PDB1;\n\nSession altered.\n\nSQL> ALTER DATABASE BACKUP CONTROLFILE TO '/tmp/control1.bak';\nALTER DATABASE BACKUP CONTROLFILE TO '/tmp/control1.bak'\n*\nERROR at line 1:\nORA-65040: operation not allowed from within a pluggable database\n\n\nSQL>","poster":"mtnetmaker","comments":[{"upvote_count":"2","content":"the question need creating RMAN backups, nor by SQL*Plus.","comment_id":"604401","poster":"Eric_F","timestamp":"1668954120.0"},{"content":"B and C","poster":"mtnetmaker","comment_id":"573896","timestamp":"1663959180.0","comments":[{"poster":"freemun05","content":"1) \nRMAN> connect target \"backup@pdb1 AS SYSBACKUP\"\n\ntarget database Password: \nconnected to target database: ORADB:PDB1 (DBID=1492547052)\n\nRMAN> backup current controlfile;\n\nStarting backup at 31-MAR-2022 07:51:08\nusing target database control file instead of recovery catalog\nallocated channel: ORA_DISK_1\nchannel ORA_DISK_1: SID=279 device type=DISK\nchannel ORA_DISK_1: starting full datafile backup set\nchannel ORA_DISK_1: specifying datafile(s) in backup set\nincluding current control file in backup set\nchannel ORA_DISK_1: starting piece 1 at 31-MAR-2022 07:51:10\nchannel ORA_DISK_1: finished piece 1 at 31-MAR-2022 07:51:11\npiece handle=+DATADISK/ORADB/A98B865CBFAF359CE0537F01A8C08251/BACKUPSET/2022_03_31/ncnnf0_tag20220331t075109_0.292.1100764271 tag=TAG20220331T075109 comment=NONE\nchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:01\nFinished backup at 31-MAR-2022 07:51:11\n\n2) C - wrong, read docs.","comment_id":"578626","timestamp":"1664503020.0","comments":[{"comment_id":"789357","timestamp":"1690431420.0","poster":"jackymak","content":"C is true.\nAlternatively, you can remove the ambiguity by qualifying the PDB name with the tablespace name when connected to the root container.\n\n$ rman target=sys@cdb1\nRMAN> BACKUP TABLESPACE pdb1:system, pdb1:sysaux, pdb1:users, pdb2:system;\n\nhttps://oracle-base.com/articles/12c/multitenant-rman-backup-recovery-cdb-and-pdb-12cr1#tablespace-and-datafile-backups","upvote_count":"3"}],"upvote_count":"2"}],"upvote_count":"3"}],"comment_id":"573895"},{"poster":"Aldrid","timestamp":"1637246520.0","upvote_count":"1","content":"D incorrect: U must be connected to CDB root, not application root.","comment_id":"360498"},{"upvote_count":"3","timestamp":"1637048700.0","poster":"mporislav","comment_id":"358339","content":"B, C\n\nnot D :\nwhen connected to application root PDB:\nRMAN> backup archivelog all;\nskipping archived logs when connected to a PDB\n\nE , also correct, you can create cf backup:\nbackup current controlfile;"},{"upvote_count":"3","content":"BC correct","poster":"RinD","timestamp":"1636532760.0","comment_id":"353483"},{"comment_id":"352855","timestamp":"1636448940.0","upvote_count":"1","comments":[{"timestamp":"1637428800.0","comments":[{"upvote_count":"3","comment_id":"393780","poster":"navingupta52","timestamp":"1640788500.0","content":"BC are perfectly correct but I think even E is correct. I connected to a PDB on my system and backed up controlfile.\n\ntarget database Password:\nconnected to target database: CRYPTODB:PDB2 (DBID=1223325248)\n\nRMAN> backup current controlfile;\n\nStarting backup at 29-JUN-21\nusing target database control file instead of recovery catalog\nallocated channel: ORA_DISK_1\nchannel ORA_DISK_1: SID=402 device type=DISK\nchannel ORA_DISK_1: starting full datafile backup set\nchannel ORA_DISK_1: specifying datafile(s) in backup set\nincluding current control file in backup set\nchannel ORA_DISK_1: starting piece 1 at 29-JUN-21\nchannel ORA_DISK_1: finished piece 1 at 29-JUN-21\npiece handle=H:\\ORACLE\\ORACLE19C\\FRA2\\CRYPTODB\\195AE5877EB842D6AD88571743F1FBA0\\BACKUPSET\\2021_06_29\\O1_MF_NCNNF_TAG20210629T200025_JFPCN4YJ_.BKP tag=TAG20210629T200025 comment=NONE\nchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:02\nFinished backup at 29-JUN-21"}],"comment_id":"362308","upvote_count":"1","poster":"dunhill","content":"RinD, mporislav, Aldrid are right. It's BC.\nI miss the key word \"application\" root."}],"poster":"dunhill","content":"I think BD"}],"answer_description":"","question_images":[],"unix_timestamp":1620544140,"timestamp":"2021-05-09 09:09:00","question_id":33,"exam_id":381},{"id":"gTzsnaTDGhxfcAAPp7Iw","answers_community":["ABE (100%)"],"choices":{"C":"They are always created automatically.","E":"They can be retained forever.","B":"They are generated if STATISTICS_LEVEL is set to ALL.","D":"They are always created manually.","A":"They are generated if STATISTICS_LEVEL is set to TYPICAL.","F":"They are generated if STATISTICS_LEVEL is set to BASIC."},"exam_id":381,"question_images":[],"url":"https://www.examtopics.com/discussions/oracle/view/52174-exam-1z0-083-topic-1-question-129-discussion/","answer_images":[],"answer":"ABE","answer_ET":"ABE","answer_description":"","isMC":true,"question_text":"Which three are true about Automatic Workload Repository (AWR) snapshots? (Choose three.)","discussion":[{"upvote_count":"9","comment_id":"416205","poster":"xRodge","timestamp":"1659013380.0","content":"A - TRUE. Only STATISTICS_LEVEL=BASIC stops them being generated\nB - TRUE. Only STATISTICS_LEVEL=BASIC stops them being generated\nC - FALSE. You can create them manually.\nD - FALSE. The DB will, by default, create them automatically every hour\nE - TRUE. You can setup AWR Warehouse, allowing these reports to be kept, and queried, forever. \nF - FALSE. STATISTICS_LEVEL=BASIC stops them being generated\n\nSo, ABE is correct.\n\nRef: https://docs.oracle.com/en/database/oracle/oracle-database/19/refrn/STATISTICS_LEVEL.html"},{"timestamp":"1720161420.0","poster":"_gio_","upvote_count":"1","content":"Selected Answer: ABE\nI agree with xRodge","comment_id":"943381"},{"timestamp":"1714425780.0","upvote_count":"1","poster":"ScottL","comment_id":"884723","content":"Selected Answer: ABE\nABE - see xrodge"},{"timestamp":"1696565940.0","upvote_count":"1","comment_id":"687434","poster":"G_C","content":"Selected Answer: ABE\nNo doubts no comments. See xRodge's explanation."},{"upvote_count":"3","poster":"smartvan","content":"ABE is correct","timestamp":"1666904880.0","comment_id":"468867"},{"content":"It's ABE.","upvote_count":"3","comment_id":"424175","timestamp":"1660382160.0","poster":"Neil107"},{"upvote_count":"1","timestamp":"1656506640.0","comment_id":"393783","content":"ABE are correction options.\n\nSnapshots can be retained forever in warehouse environment so E is correct.","poster":"navingupta52"},{"poster":"Aldrid","content":"A, B, E\nE: https://docs.oracle.com/database/121/TDPPT/tdppt_auto.htm#TDPPT025\nC,D - not always.. based on statistic_level\nF- only manual possible","upvote_count":"4","timestamp":"1652878800.0","comment_id":"360523"},{"poster":"mporislav","content":"A, B, E\nNot always manual , not always automatic.\nto retain forever (E):\nexec DBMS_WORKLOAD_REPOSITORY.MODIFY_SNAPSHOT_SETTINGS( retention=>0);","timestamp":"1652759520.0","comment_id":"359225","upvote_count":"4"},{"timestamp":"1652719260.0","comment_id":"358929","upvote_count":"1","poster":"Rogazan","content":"ABD (DBMS_WORKLOAD_REPOSITORY.create_snapshot)","comments":[{"upvote_count":"1","content":"sorry I was wrong. The correct answer is ABE","comment_id":"364185","poster":"Rogazan","timestamp":"1653286980.0"}]},{"upvote_count":"1","poster":"RinD","content":"ABE correct","comment_id":"353495","timestamp":"1652164980.0"},{"poster":"dunhill","content":"I think ABC","comments":[{"timestamp":"1653060300.0","poster":"dunhill","content":"I correct myself. It's ABE.","upvote_count":"1","comment_id":"362310"}],"comment_id":"352853","timestamp":"1652079720.0","upvote_count":"1"}],"topic":"1","unix_timestamp":1620543720,"timestamp":"2021-05-09 09:02:00","question_id":34},{"id":"yjf6EhrlmTMlO3xuwvnR","unix_timestamp":1590555960,"url":"https://www.examtopics.com/discussions/oracle/view/21432-exam-1z0-083-topic-1-question-13-discussion/","choices":{"A":"1, 2, 4, 5, 7, 8","E":"2, 4, 5, 6, 7","B":"1, 2, 4, 6, 7, 8","D":"1, 2, 3, 4, 5, 6, 7, 8","C":"1, 2, 3, 4, 5, 7, 8"},"question_images":[],"topic":"1","exam_id":381,"answer_description":"","discussion":[{"poster":"asefa","content":"easy way \nwe must convert either on destination or source so A is incorrect (no option 3 and 6)\nwe must copy data pump set from source to destination so B is incorrect (no step 5)\nno need to convert on destination if we aleady did conversion on source so D is incorrect (both step 3 and 6) are included\nwe must make tablespace read only son E is incorrect\nso answer must be C","upvote_count":"15","timestamp":"1618593540.0","comments":[{"poster":"egore0496","content":"Why not B\nAccording https://docs.oracle.com/en/database/oracle/oracle-database/19/admin/transporting-data.html#GUID-E4C56852-73A5-44A2-BB10-938831DA6E4C\nC \nbut\nwhat about network mode of data pump\nor nfs/cifs export?","comment_id":"530728","timestamp":"1658591940.0","comments":[{"comment_id":"530729","content":"15.2.4 Transporting a Database Over the Network \nhttps://docs.oracle.com/en/database/oracle/oracle-database/19/admin/transporting-data.html#GUID-032C9715-B2F8-4ACD-8A1C-C1A899DEA3C1","upvote_count":"2","timestamp":"1658592480.0","comments":[{"poster":"asduta","content":"thats not in the choices isnt it?","timestamp":"1669473000.0","comment_id":"607638","upvote_count":"1"}],"poster":"egore0496"}],"upvote_count":"2"}],"comment_id":"201160"},{"timestamp":"1612887060.0","poster":"janw","content":"agree with c\nmust contain 1, 5, 8\nmust contain 3 and 6 (not both)","comments":[{"poster":"Alejandrrro","content":"Agree with C too\nMOS Doc ID 371556.1 describes the action plan almost the same as in C. Files are converted on the source system","upvote_count":"2","timestamp":"1626144420.0","comment_id":"266027"}],"upvote_count":"9","comment_id":"153725"},{"content":"Selected Answer: C\nThe correct order is 3, 1, 2, 5, 4, 6, 7, 8.\nReference: https://mylearn.oracle.com/ou/ekit/86212/38560/dc9de5cb-8c91-4bd5-bc30-18406127a61b/course\nPage: 296","timestamp":"1735594140.0","comment_id":"1334417","poster":"alrech","upvote_count":"1"},{"comment_id":"1093954","upvote_count":"1","poster":"jaimegarcia","content":"Selected Answer: B\nyes , transportable tablespace","comments":[{"content":"Answer is C at first i also thought it was B but step 5 is important otherwise you have not moved the exported dump in step 2. then you can choose an option with either of 6 or 3.","comment_id":"1164480","poster":"mamadu","upvote_count":"1","timestamp":"1725327300.0"}],"timestamp":"1718144820.0"},{"upvote_count":"1","poster":"LEOC71","content":"Selected Answer: C\nStep 2 is part of all alternatives, then the data pump set created must be transferred to the destination system (step 5). => C: TRUE\nB:FALSE => to be true step 2 shouldn't be mentioned as part of the procedure, only step 7 (using impdp network mode).","comment_id":"1062643","timestamp":"1714878960.0"},{"comment_id":"1003989","poster":"flaviogcmelo","timestamp":"1710081120.0","content":"Selected Answer: C\nIn my opinion, choosing alternative C instead of B is the detail of making the dump file available to the destination database.\nhttps://docs.oracle.com/en/database/oracle/oracle-database/19/spmds/migrating-oracle-database.html#GUID-F224185E-6AEC-45FC-B4F3-7F8B6469606D","upvote_count":"1"},{"comment_id":"963698","content":"Selected Answer: C\nI think C","upvote_count":"1","timestamp":"1706279040.0","poster":"_gio_"},{"content":"Selected Answer: C\nFor me, the right answer should B, but here, we have a lot of person saying the correct one is C, so go with the others.","poster":"Guhborges","comment_id":"946657","timestamp":"1704743700.0","upvote_count":"1"},{"poster":"Marcello86CT","content":"I would say that correct Answer is : E\n\nWith Data Pump Conventional Export and Import we no need to make any convesrion because it support different endian format. In conventional mode is not requeired neither to set db in read only.","upvote_count":"1","comment_id":"684235","timestamp":"1680355920.0","comments":[{"upvote_count":"1","timestamp":"1683109980.0","content":"Hi,\n\nthe conversion is a must between different endianess \nsee https://docs.oracle.com/en/database/oracle/oracle-database/19/spmdu/task-4-transport-the-tablespace-set.html#GUID-41D10DCA-7733-4E4C-A41A-B94F63A82F7C","poster":"abdelouahab","comment_id":"710480"}]},{"content":"Selected Answer: C\nMust C","timestamp":"1673179140.0","upvote_count":"3","comment_id":"628715","poster":"Patrick9230"},{"upvote_count":"2","comments":[{"comment_id":"530732","upvote_count":"1","timestamp":"1658592660.0","content":"15.2.4 Transporting a Database Over the Network \nhttps://docs.oracle.com/en/database/oracle/oracle-database/19/admin/transporting-data.html#GUID-032C9715-B2F8-4ACD-8A1C-C1A899DEA3C1","poster":"egore0496"},{"content":"5 is a must since above choices doesn't list other type of moving the dump file, including one you mentioned.","poster":"asduta","timestamp":"1669473060.0","comment_id":"607641","upvote_count":"1"}],"timestamp":"1658591100.0","content":"B\n5 is not must\nhttps://docs.oracle.com/en/database/oracle/oracle-database/19/sutil/oracle-data-pump-export-utility.html#GUID-72973E3D-FC0A-47E8-A62A-6DF8AD83138D\n\nNetwork Considerations for Oracle Data Pump Export","poster":"egore0496","comment_id":"530717"},{"upvote_count":"1","content":"It's C.\nIt is always preferred/recommended to convert at the source, as far as possible, rather than convert it at the destination. Saves a lot of headache!","poster":"Neil107","comment_id":"422113","timestamp":"1644416040.0"},{"poster":"Dhanushbh","comment_id":"394850","content":"C is correct [Doc ID 2013271.1]","timestamp":"1640883060.0","upvote_count":"1"},{"upvote_count":"4","comment_id":"374182","content":"B is correct\n\nE is wrong: 1 is a must\nD is wrong: 3 & 6 need either one\nA & C are wrong: 5 is not a must if using network mode of data pump","timestamp":"1638612300.0","poster":"fukaka"},{"poster":"Jatindra","timestamp":"1632282780.0","upvote_count":"1","comment_id":"316863","content":"Correct Answer is E"},{"comment_id":"313795","timestamp":"1631930340.0","content":"I also think that it should be B.","poster":"Bda","upvote_count":"1"},{"upvote_count":"1","content":"B is a correct answer","poster":"Abdou1968","comment_id":"185972","timestamp":"1616579340.0"},{"timestamp":"1616173380.0","content":"You only need to convert the data once. On the source side, you convert the Tablespaces, but on the target side, you convert the datafiles. So answer C is correct.\nReference: https://docs.oracle.com/en/database/oracle/oracle-database/18/spmdu/converting-data-using-rman.html#GUID-DDFA71A3-396A-440A-B9AB-E0970F843904","upvote_count":"1","poster":"Roberto2","comment_id":"182357"},{"upvote_count":"2","content":"option C is correct, but, the question says: \"Which is the MINIMUM number of actions required\", so we can transport a tbs in open-write mode, with extra steps to perform at the end, however, the questions says \"minimum\" the correct answer is \"E\"->steps 2,4,5,6,7","poster":"erial","timestamp":"1615045680.0","comment_id":"174598","comments":[{"comment_id":"607643","timestamp":"1669473180.0","poster":"asduta","upvote_count":"1","content":"thats the thing. its \"minimum required\". so since the 'extra step' wasn't a choice, C is the answer."}]},{"poster":"cerebro2000x","timestamp":"1612751220.0","upvote_count":"1","content":"C the conversion can be either done in the source or the destination server","comment_id":"152782"},{"upvote_count":"3","timestamp":"1612015080.0","poster":"julica","content":"it must contain points 4 & 5 and 3 or 6 (but not both).\nSo, C looks correct.","comment_id":"147387"},{"poster":"IOracle","comment_id":"129528","upvote_count":"4","content":"A - is not correct because the endinaess are different so either 3 or 6 is needed\nB - is not correct because step 5 is missing but the trasport of the dump on the target is mandatory accoridng to : \nhttps://docs.oracle.com/en/database/oracle/oracle-database/12.2/admin/transporting-data.html#GUID-CEDFBF9B-3A3B-43D4-9FF2-84EA2537BA8C\nC - is the correct answer\n\nD- not correct because it containes both 3 and 6 \n\nE - is not correct beacuse they missed step 1 of setting the tbs read-only","timestamp":"1610097300.0"},{"comment_id":"121052","poster":"Sha7","timestamp":"1609059060.0","content":"C is the correct answer","upvote_count":"2"},{"timestamp":"1607516460.0","upvote_count":"1","poster":"asefa","comment_id":"105861","content":"https://www.oracle.com/assets/full-transportable-wp-12c-1973971.pdf\ny not C based on this white paper."},{"poster":"Jatindra","content":"Correct answer is B","comment_id":"103669","timestamp":"1607251380.0","upvote_count":"6"},{"upvote_count":"6","comment_id":"101126","poster":"tamagogo","timestamp":"1606943460.0","content":"correct answer is B \n\nconversion is done only once at source or at destination\nData Pump dump set is metadata only, can be imported remotely"},{"content":"Correct answer is D","poster":"git17","upvote_count":"1","comment_id":"96585","timestamp":"1606460760.0"}],"answer_images":[],"question_text":"You must transport the UNIVERSITY tablespace from one database to another.\nThe UNIVERSITY tablespace is currently open read/write.\nThe source and destination platforms have different endian formats.\nExamine this list of actions:\n1. Make the UNIVERSITY tablespace read-only on the source system.\n2. Export the UNIVERSITY tablespace metadata using EXPDP.\n3. Convert the UNIVERSITY tablespace data files to the destination platform format using RMAN on the source system.\n4. Copy the UNIVERSITY tablespace data files to the destination system.\n5. Copy the Data Pump dump set to the destination system.\n6. Convert the UNIVERSITY tablespace data files to the destination platform format using RMAN on the destination system.\n7. Import the UNIVERSITY tablespace metadata using IMPDP.\n8. Make the UNIVERSITY tablespace read/write on the destination system.\nWhich is the minimum number of actions required, in the correct order, to transport the UNIVERSITY tablespace?","question_id":35,"isMC":true,"answer_ET":"C","answers_community":["C (89%)","11%"],"timestamp":"2020-05-27 07:06:00","answer":"C"}],"exam":{"numberOfQuestions":181,"isMCOnly":true,"isImplemented":true,"name":"1z0-083","provider":"Oracle","lastUpdated":"12 Apr 2025","isBeta":false,"id":381},"currentPage":7},"__N_SSP":true}