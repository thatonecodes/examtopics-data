{"pageProps":{"questions":[{"id":"5oXj9mEVXo6C0HmuBbFG","exam_id":214,"timestamp":"2023-06-29 15:23:00","unix_timestamp":1688044980,"discussion":[{"content":"Selected Answer: ABE\nABE - all definitions of when to use Salesforce Connect","comment_id":"1199393","poster":"lizbette","upvote_count":"1","timestamp":"1729469580.0"},{"timestamp":"1719711420.0","poster":"ETH777","content":"Selected Answer: ABE\nNot C - Salesforce Connect supports connections via VPN, but it's not a primary factor.\nNot D - Salesforce Connect is for virtualization.\n\nB - Salesforce Connect enables filtering and querying external data on the fly.","upvote_count":"2","comment_id":"1109373"},{"timestamp":"1710554880.0","content":"Selected Answer: ABE\nhttps://trailhead.salesforce.com/content/learn/modules/big-data-strategy/compare-data-storage-options","comment_id":"1008765","upvote_count":"3","poster":"ksho"},{"content":"Selected Answer: ABE\nA, B, E looks correct. VPN has nothing to do with External Objects. And all the data is kept in the external system, just Meta and Layout data is stored in Salesforce.","poster":"thneeb","upvote_count":"3","comment_id":"938163","timestamp":"1703863380.0"}],"question_id":36,"answer_ET":"ABE","answers_community":["ABE (100%)"],"topic":"1","url":"https://www.examtopics.com/discussions/salesforce/view/113668-exam-certified-data-architect-topic-1-question-35-discussion/","choices":{"D":"You have a large amount of data and would like to copy subsets of it into Salesforce.","C":"You need to expose data via a virtual private connection.","E":"You have a large amount of data that you don't want to copy into your Salesforce org.","B":"You need small amounts of external data at any one time.","A":"You want real-time access to the latest data from other systems."},"answer_description":"","question_images":[],"question_text":"Universal Containers (UC) stores 10 million rows of inventory data in a cloud database. As part of creating a connected experience in Salesforce, UC would like to expose this inventory data to Sales Cloud without a direct import. UC has asked its data architect to determine if Salesforce Connect is needed.\nWhich three considerations should the data architect make when evaluating the need for Salesforce Connect? (Choose three.)","isMC":true,"answer_images":[],"answer":"ABE"},{"id":"VZpUQG2JxSN87v7pUiF4","unix_timestamp":1686169860,"answer_description":"","isMC":true,"answer_images":[],"question_images":[],"discussion":[{"timestamp":"1701988260.0","comment_id":"917595","poster":"mspriya455","content":"Correct Answer is B","upvote_count":"7"},{"upvote_count":"1","comment_id":"1199394","content":"Selected Answer: B\nB is correct.","timestamp":"1729469700.0","poster":"lizbette"},{"content":"Selected Answer: B\nNot A - This would remove all data.\nNot C - This would unnecessarily move recent data off-platform.\nNot D - Backups are primarily for disaster recovery, not long-term archiving.\n\nB - Selective archiving of older than two years record and data is still available for historical reporting.","timestamp":"1719711660.0","upvote_count":"2","poster":"ETH777","comment_id":"1109376"},{"poster":"tobicky","comment_id":"1068565","timestamp":"1715515380.0","content":"B. Build a batch job to move two-year-old records off platform, and delete old records from Salesforce.\n\nThis approach aligns with UCâ€™s requirement to maintain two years of data in Salesforce and archive older data out of Salesforce. The batch job can be scheduled to run periodically to move records that are more than two years old off the platform, and then delete those records from Salesforce to free up storage.","upvote_count":"2"},{"comments":[{"comment_id":"1127885","timestamp":"1721566140.0","upvote_count":"1","content":"you can archive and also backup the data via AppExhange apps but it's going not to release 2 years old data from your org. That's why not D","poster":"[Removed]"}],"upvote_count":"3","poster":"ksho","content":"Selected Answer: B\nB. This is backing up 2yr old data and then deleting it, which is what was asked.\n\nNot A. This is literally destroying all of the data. Good way to get sued.\nNot C. We do not need to move active data over. This could cause duplicates in the backup system without a sophisticated matching system. Best to let the data age out if we're using a batch job.\nNot D. This only solves for backing up the data, but it doesn't archive it off the system.\n\nFor clarity \"archive\" = backup in an external system and delete from salesforce.","comment_id":"1008768","timestamp":"1710555180.0"},{"content":"Selected Answer: B\nB the old records are archived out and deleted from Salesforce","timestamp":"1706907840.0","upvote_count":"3","comment_id":"970482","poster":"supersam1982"},{"comments":[{"poster":"supersam1982","timestamp":"1706907780.0","comment_id":"970480","upvote_count":"1","content":"no way, is it required to archive out, this means you have to delete them from Salesforce because they are running out of space"}],"poster":"rahulnwo","comment_id":"962208","timestamp":"1706153460.0","content":"As A Band C have delete keyword they cannot be ans as questiin tell to archive. So D is correct","upvote_count":"1"},{"comments":[{"timestamp":"1704994500.0","content":"Why should we move all data off platform? Just moving the old data off platform makes more sense, or?","upvote_count":"2","comment_id":"949095","poster":"thneeb"}],"comment_id":"941761","content":"why not C?","upvote_count":"1","poster":"RishikeshRanjan0501","timestamp":"1704287280.0"},{"comment_id":"938167","timestamp":"1703863500.0","content":"Selected Answer: B\nTHe backup solution (D) is fine, but does not delete the old data. So B is the correct answer.","upvote_count":"4","poster":"thneeb"}],"exam_id":214,"answer":"B","question_text":"Universal Containers (UC) has implemented Salesforce. UC is running out of storage and needs to have an archiving solution. UC would like to maintain two years of data in Salesforce and archive older data out of Salesforce.\nWhich solution should a data architect recommend as an archiving solution?","topic":"1","answers_community":["B (100%)"],"question_id":37,"answer_ET":"B","timestamp":"2023-06-07 22:31:00","url":"https://www.examtopics.com/discussions/salesforce/view/111446-exam-certified-data-architect-topic-1-question-36-discussion/","choices":{"D":"Use a third-party backup solution to back up all data off platform.","A":"Build a batch job to move all records off platform, and delete all records from Salesforce.","C":"Build a batch job to move all records off platform, and delete old records from Salesforce.","B":"Build a batch job to move two-year-old records off platform, and delete old records from Salesforce."}},{"id":"QDTH8ZQCKCof9oBpcYMT","timestamp":"2023-07-11 17:38:00","isMC":true,"url":"https://www.examtopics.com/discussions/salesforce/view/114899-exam-certified-data-architect-topic-1-question-37-discussion/","unix_timestamp":1689089880,"answer":"A","answers_community":["A (77%)","D (23%)"],"question_images":[],"question_id":38,"topic":"1","choices":{"A":"Ensure validation rules, triggers, and other automation tools are disabled","C":"Bulkify the triggers to handle import loads","D":"Import the data is smaller batches over a 24-hour period","B":"Ensure duplication and matching rules are defined"},"answer_description":"","answer_ET":"A","discussion":[{"timestamp":"1729470000.0","comment_id":"1199395","content":"Selected Answer: A\nA is correct and is general best practice.","poster":"lizbette","upvote_count":"1"},{"comment_id":"1109388","timestamp":"1719712800.0","upvote_count":"3","poster":"ETH777","content":"Selected Answer: A\nNot D - it help manage governor limits, but doesn't prevent issues caused by automation tools running during each batch. It also extend the duration of the overall import time.\n\nA - Automation tools are not designed for large-scale data loads. Disabling avoids trigger recursion and speeds up the import process."},{"comment_id":"1074121","timestamp":"1716039480.0","poster":"tobicky","upvote_count":"2","content":"Selected Answer: A\nThe most accurate answer is A. Ensure validation rules, triggers, and other automation tools are disabled. During a large data import, these features can cause delays and conflicts. Disabling them can help prevent errors and improve the performance of the data import.\n\nD. Import the data in smaller batches over a 24-hour period: This could help avoid overloading the system, but it might not be enough to prevent all unwanted results, especially if the issues are caused by validation rules, triggers, or other automation tools"},{"upvote_count":"2","comment_id":"1021260","timestamp":"1711782180.0","content":"Selected Answer: A\nBecause we want to save all data and prevent any problems so VR should be disabled and also salesforce recommend to by VR and triggers during import and instead preprocess the data","poster":"Amine98ma"},{"poster":"ksho","content":"Selected Answer: D\nA is only plausible if there is a trigger framework in place that allows code to be disabled via custom settings. Otherwise, the unit tests would fail while trying to disable them and you'd end up working more on commenting code out/deployment and dealing with that fall out rather than your import. But even disabling validation rules and flows can cause well written unit tests to fail if there are dependencies. \n\nFor this reason, I think it's the answer is D. It's slower, but you'll get the data in without tampering with code. The data can be preprocessed so that validation rules aren't triggered.\n\nRealistically, the answer is a combination of A & D - disable what you can and lower the batch size to accomodate for what you cannot.","timestamp":"1710555660.0","comment_id":"1008769","upvote_count":"2"},{"poster":"Oleg_M","upvote_count":"2","comment_id":"985056","content":"Selected Answer: A\nThe answer is A. Even though you can mitigate any lack of bulkyfication by importing records in small batches, that won't bypass validation rules, So in the end you'll still have a lot of data not imported because of validation rules.\nSo I'd say A since it'll allow you to import all set of data.","timestamp":"1708337400.0"},{"poster":"thneeb","upvote_count":"1","comment_id":"949098","timestamp":"1704994680.0","content":"Selected Answer: D\nI would tend more to D. Sure in a well designed Salesforce org, it would not have a big impact, if the triggers are disabled during the load the the processing of the triggers can be executed afterwards.\nBut here I would say, import the 100K records in smaller batches. (D)"}],"question_text":"Universal Containers (UC) has a very large and complex Salesforce org with hundreds of validation rules and triggers. The triggers are responsible for system updates and data manipulation as records are created or updated by users. A majority of the automation tools within UC's org were not designed to run during a data load. UC is importing 100,000 records into Salesforce across several objects over the weekend.\nWhat should a data architect do to mitigate any unwanted results during the import?","answer_images":[],"exam_id":214},{"id":"KvKNcDglPTXy4haOgI52","discussion":[{"comment_id":"1199396","content":"Selected Answer: D\nD is correct","poster":"lizbette","timestamp":"1729470180.0","upvote_count":"1"},{"poster":"ksho","comment_id":"1009424","content":"Selected Answer: D\nD. Salesforce Connect allows data from an external system to be virtualized in salesforce.\n\nNot A. Canvas apps are a kind of connect app. This is generally used to expose a third-party app interface within salesforce. Since the sales reps do not have access to the ERP, this still does not give them access to the data.\nhttps://salesforce.stackexchange.com/questions/15494/whats-the-practical-difference-between-canvas-connected-apps#:~:text=Canvas%20don't%20work%20in,organization%20on%20behalf%20of%20it.\n\nNot B. We should avoid replication where possible as it doubles storage needs. \n\nNot C. We should avoid replication where possible as double storage needs.","timestamp":"1710641160.0","upvote_count":"2"}],"url":"https://www.examtopics.com/discussions/salesforce/view/120839-exam-certified-data-architect-topic-1-question-38-discussion/","question_id":39,"question_images":[],"timestamp":"2023-09-17 02:06:00","question_text":"Universal Containers is using Salesforce for Opportunity management and enterprise resource planning (ERP) for order management. Sales reps do not have access to the ERP and have no visibility into order status.\nWhat solution should a data architect recommend to give the sales team visibility into order status?","answers_community":["D (100%)"],"answer_images":[],"answer_ET":"D","choices":{"B":"Build real-time integration to pull order line items into Salesforce when viewing orders.","A":"Leverage Canvas to bring the order management UI in to the Salesforce tab.","C":"Build batch jobs to push order line items to Salesforce.","D":"Leverage Salesforce Connect to bring the order line item from the legacy system to Salesforce."},"isMC":true,"exam_id":214,"topic":"1","answer":"D","answer_description":"","unix_timestamp":1694909160},{"id":"32D00amMz8fruiVdslXk","answer_images":[],"question_images":[],"url":"https://www.examtopics.com/discussions/salesforce/view/120840-exam-certified-data-architect-topic-1-question-39-discussion/","answer":"C","choices":{"C":"Configure Price Books for each region and share with distributors.","B":"Manually update Opportunities with Prices applicable to distributors","A":"Create lookup to Custom Price object and share with distributors.","D":"Add custom fields in Opportunity and use triggers to update prices."},"answers_community":["C (100%)"],"unix_timestamp":1694909340,"timestamp":"2023-09-17 02:09:00","topic":"1","question_id":40,"isMC":true,"question_text":"A large multinational B2C Salesforce customer is looking to implement their distributor management application in Salesforce. The application has the following capabilities:\n1. Distributors create Sales Orders in Salesforce.\n2. Sales Orders are based on Product prices applicable to their region.\n3. Sales Orders are closed once they are fulfilled.\n4. It is decided to maintain Sales Orders in Opportunities object.\nHow should the data architect model this requirement?","exam_id":214,"answer_ET":"C","answer_description":"","discussion":[{"comment_id":"1398895","timestamp":"1742050260.0","upvote_count":"1","poster":"tbt7979","content":"Selected Answer: C\nC. Configure Price Books for each region and share with distributors."},{"content":"Selected Answer: C\nagreed, C","timestamp":"1729470360.0","comment_id":"1199397","poster":"lizbette","upvote_count":"1"},{"poster":"ksho","comment_id":"1009427","content":"Selected Answer: C\nC. Configure Price Books for each region and share with distributors.\n\nhttps://help.salesforce.com/s/articleView?id=sf.pricebooks_landing_page.htm&type=5","timestamp":"1710641340.0","upvote_count":"2"}]}],"exam":{"provider":"Salesforce","isImplemented":true,"id":214,"name":"Certified Data Architect","isBeta":false,"lastUpdated":"12 Apr 2025","numberOfQuestions":83,"isMCOnly":true},"currentPage":8},"__N_SSP":true}