{"pageProps":{"questions":[{"id":"VkcWHWXHrX0oD2hJlnKu","answer":"BDE","question_text":"Northern Trail Outfitters (NTO) has outgrown its current Salesforce org and will be migrating to a new org shortly. As part of this process, NTO will be migrating all of its metadata and data. NTO's data model in the source org has a complex relationship hierarchy with several master-detail and lookup relationships across objects, which should be maintained in the target org.\nWhich three things should a data architect do to maintain the relationship hierarchy during migration? (Choose three.)","exam_id":214,"question_id":71,"question_images":[],"answer_ET":"BDE","unix_timestamp":1694283180,"url":"https://www.examtopics.com/discussions/salesforce/view/120368-exam-certified-data-architect-topic-1-question-74-discussion/","choices":{"D":"Replace source record IDs with new record IDs from the target org in the import file.","C":"Keep the relationship fields populated with the source record IDs in the import file.","B":"Use Data Loader to export the data from the source org and then import/upsert into the target org in sequential order.","E":"Create an external ID field for each object in the target org and map source record IDs to this field.","A":"Redefine the master-detail relationship fields to lookup relationship fields in the target org."},"isMC":true,"answer_images":[],"answers_community":[],"topic":"1","discussion":[{"upvote_count":"2","comment_id":"1151708","poster":"bayayan","timestamp":"1723769820.0","content":"i think BCE is correct"},{"timestamp":"1722166860.0","comment_id":"1134110","upvote_count":"1","content":"BDE is correct:\nhttps://help.salesforce.com/s/articleView?id=000384648&type=1\nhttps://help.salesforce.com/s/articleView?id=000383207&type=1\n\ni.e. you'll replace any occurrences of legacy Account Ids in your import files with NEW Account Ids from the target org. \ni.e., consider creating a custom External Id field and map or insert your previous record Ids or other unique identifiers from your source organization into the field. This will allow you to Import related records using an External ID.\ni.e, Recommended sample order for importing core objects (gotta be sequential):","poster":"[Removed]"},{"timestamp":"1710015180.0","content":"ACE may be correct","poster":"vkm","upvote_count":"1","comment_id":"1003408"}],"answer_description":"","timestamp":"2023-09-09 20:13:00"},{"id":"1cpXrbrh0bVxBGa9XovT","answer_images":[],"answer_description":"","answer":"B","exam_id":214,"url":"https://www.examtopics.com/discussions/salesforce/view/118025-exam-certified-data-architect-topic-1-question-75-discussion/","isMC":true,"question_id":72,"question_text":"Universal Containers (UC) has millions of case records with case history and service level agreement data. UC's compliance team would like historical cases to be accessible for 10 years for audit purposes.\nWhat solution should a data architect recommend?","answer_ET":"B","topic":"1","choices":{"A":"Purchase more data storage to support the case object.","C":"Archive case data using a Salesforce Archival solution.","B":"Use a custom big object to store archived case data.","D":"Use a custom object to store archived case data."},"answers_community":["B (88%)","13%"],"question_images":[],"unix_timestamp":1691916960,"discussion":[{"comment_id":"1283952","poster":"92b6348","content":"Why not archival solution","timestamp":"1726384860.0","upvote_count":"1"},{"timestamp":"1713671280.0","content":"Selected Answer: B\nb is correct","poster":"lizbette","comment_id":"1199453","upvote_count":"3"},{"comment_id":"1074717","upvote_count":"4","timestamp":"1700410140.0","poster":"tobicky","content":"Selected Answer: B\nThe most accurate answer would be Option B: Use a custom big object to store archived case data.\n\nBig Objects in Salesforce are designed to provide consistent performance, whether you’re dealing with millions or billions of records. They are ideal for storing large amounts of data that you don’t need to access frequently, such as historical data. This makes them a good fit for UC’s requirement of keeping historical cases accessible for 10 years for audit purposes."},{"content":"Selected Answer: C\nThis is a scalable solution and would allow to store the records accordingly as option D will also bring a lot of storage burden on the org","timestamp":"1691916960.0","comment_id":"979869","poster":"vip_10","comments":[{"content":"Not Option C: Archive case data using a Salesforce Archival solution. Salesforce does not provide an out-of-the-box archival solution. While there are third-party archival solutions available, they might not be as seamless or efficient as using a feature that is native to Salesforce, like Big Objects.","upvote_count":"4","timestamp":"1700410200.0","comment_id":"1074718","poster":"tobicky"}],"upvote_count":"1"}],"timestamp":"2023-08-13 10:56:00"},{"id":"fO6Vad32FQUalYDqXJMU","answer_images":[],"discussion":[{"poster":"Aisha_Khalid","comment_id":"1401705","timestamp":"1742593380.0","upvote_count":"1","content":"Selected Answer: BD\nNot C. A solution to this wouldn't be to create MORE uses and use up additional licenses for this purpose"},{"comment_id":"1268281","timestamp":"1724027460.0","content":"Selected Answer: BD\nB and D is correct","poster":"SS1121","upvote_count":"3"},{"poster":"Shivender","upvote_count":"3","content":"Selected Answer: CD\nC. Create a pool of generic users and distribute the assignment of owners to the pool of users.\nBy distributing the ownership of orders among a pool of generic users, the load on any single user is reduced, improving overall system performance.\n\nD. Create a role at the top of the role hierarchy and assign the role to the generic user.\nThis approach can streamline access controls and potentially improve performance by reducing the number of sharing rules that need to be evaluated. However, it's important to carefully consider the security implications of this approach.\n\nWhile option A might seem appealing, Salesforce's automatic assignment of orders can still lead to performance issues if not managed properly. Option B, clearing the role field, might not have a significant impact on performance and could potentially lead to security risks.","comment_id":"1256945","timestamp":"1722187980.0"}],"unix_timestamp":1722187980,"answer_ET":"BD","answer_description":"","answer":"BD","timestamp":"2024-07-28 19:33:00","isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/salesforce/view/144639-exam-certified-data-architect-topic-1-question-76-discussion/","question_images":[],"choices":{"D":"Create a role at the top of the role hierarchy and assign the role to the generic user.","B":"Clear the role field in the generic user record.","C":"Create a pool of generic users and distribute the assignment of owners to the pool of users.","A":"Salesforce handles the assignment of orders automatically and there is no performance impact."},"exam_id":214,"question_text":"Universal Containers has a large number of orders coming in from its online portal. Historically all orders are assigned to a generic user.\nWhich two measures should a data architect recommend to avoid any performance issues while working with a large number of order records? (Choose two.)","question_id":73,"answers_community":["BD (57%)","CD (43%)"]},{"id":"yIdgx5GRtcY1jrlMQqEi","answer_description":"","url":"https://www.examtopics.com/discussions/salesforce/view/108107-exam-certified-data-architect-topic-1-question-8-discussion/","answer":"C","topic":"1","answer_images":[],"question_images":[],"isMC":true,"answers_community":["C (100%)"],"exam_id":214,"unix_timestamp":1682939160,"answer_ET":"C","question_text":"Universal Containers (UC) is in the process of migrating legacy inventory data from an enterprise resource planning (ERP) system into Sales Cloud with the following requirements:\n1. Legacy inventory data will be stored in a custom child object called Inventory__c.\n2. Inventory data should be related to the standard Account object.\n3. The Inventory__c object should inherit the same sharing rules as the Account object.\n4. Anytime an Account record is deleted in Salesforce. the related Inventory__c record(s) should be deleted as well.\nWhat type of relationship field should a data architect recommend in this scenario?","choices":{"C":"Master-detail relationship field on Inventory__c, related to Account","B":"Indirect lookup relationship field on Account, related to Inventory__c","D":"Master-detail relationship field on Account, related to Inventory__c","A":"Lookup relationship field on Inventory__c, related to Account"},"timestamp":"2023-05-01 13:06:00","discussion":[{"poster":"bssrilakshmi","content":"Correct answer: C","timestamp":"1698843960.0","upvote_count":"10","comment_id":"886132"},{"timestamp":"1703332020.0","upvote_count":"7","comment_id":"931433","poster":"BorisBoris","content":"C is correct. On the Inventory__c Object, we create a field called Account and for field type, we designate M/D. Then we are prompted to select an Object to which we want this to look-up to and we choose Account. In doing so, we cxreate an M/D relationship i.e Many-to-one"},{"comment_id":"1207731","poster":"Nilesh_Nanda","timestamp":"1730964480.0","content":"C is correct answer","upvote_count":"2"},{"poster":"lizbette","content":"Selected Answer: C\nC. Remember the syntax on Master-Detail relationships. They are created on the child object, and used to add a relationship that links the child object to the parent. In this case, the child object is the Custom Inventory Object, and the parent is the Account object. Therefore, the syntax is that we create the Master-Detail relationship ON the inventory object, to link it to the Account parent.","comment_id":"1199237","upvote_count":"2","timestamp":"1729440060.0"},{"comment_id":"1077347","content":"Selected Answer: C\nDefinitely C, s account cannot be a child in a master detail","timestamp":"1716372180.0","poster":"DavidHolland","upvote_count":"2"},{"timestamp":"1710381240.0","upvote_count":"3","comment_id":"1007035","content":"Selected Answer: C\nC - master detail fields are created on the child object and related to the parent object","poster":"ksho"},{"timestamp":"1703771220.0","content":"Selected Answer: C\nDefinitly C","comment_id":"936599","poster":"thneeb","upvote_count":"5"},{"upvote_count":"5","timestamp":"1701190800.0","poster":"Alokv","content":"Correct answer is C. Account can't be a child object in master detail realtionship.","comment_id":"908703"}],"question_id":74},{"id":"UGigo9zv0qY46EDDNzBI","answer":"AD","question_text":"Universal Containers (UC) requires 2 years of customer related cases to be available on Salesforce for operational reporting. Any cases older than 2 years and up to 7 years need to be available on demand to service agents. UC creates 5 million cases per year.\nWhich two data archiving strategies should a data architect recommend? (Choose two.)","exam_id":214,"question_id":75,"question_images":[],"unix_timestamp":1691917320,"answer_ET":"AD","url":"https://www.examtopics.com/discussions/salesforce/view/118026-exam-certified-data-architect-topic-1-question-80-discussion/","choices":{"A":"Sync cases older than 2 years to an external database and provide service agents access to the database.","D":"Use Big objects for cases older than 2 years and use a nightly batch to move them.","C":"Use Heroku and external objects to display cases older than 2 years and the Bulk API to hard delete them from Salesforce.","B":"Use Custom objects for cases older than 2 years and use a nightly batch to move them."},"answer_images":[],"isMC":true,"answers_community":["AD (67%)","CD (33%)"],"topic":"1","answer_description":"","discussion":[{"content":"if the requirement is to archive cases older then 2, but not older then 7 years, then you certainly need archiving strategy but also a deleting strategy as well.\n\nAbout B) option: with such big number of records to store, you can not use Custom Object is out of question -> NOT B)\n\nAbout A) option: well Heroku is also an external db, and it used extra stgorage and archiving place (Heroku Connect App i.e.), so Heroku is a natural choice over A)\n\nOn the end you are left with C) and D) options.","poster":"bb0607978","timestamp":"1731843960.0","upvote_count":"2","comment_id":"1212825"},{"comment_id":"1199455","content":"Selected Answer: AD\nA is definitely right because it's a recommended solution\nB cannot be right because over time, you'll hit a data limit\nC cannot be right because Heroku has 20million record limitation, and 5 years x 5 mill cases is 25million which is over the limit\nD - big objects have enough capacity to handle the data volume\n\nA&D","poster":"lizbette","timestamp":"1729482840.0","upvote_count":"2"},{"comment_id":"1074841","content":"Selected Answer: AD\nOption A is recommended because syncing older cases to an external database and providing service agents access to this database can help reduce the load on the Salesforce org while still making the data accessible.\n\nOption D is suggested because Big Objects provide a way to handle and store massive amounts of data within Salesforce’s multi-tenant environment. They are designed to provide consistent performance, whether you have 1 million records, 100 million, or even 1 billion.","poster":"tobicky","timestamp":"1716136080.0","upvote_count":"3"},{"poster":"noox","comments":[{"content":"The question doesn’t specify that records need to be deleted. The use of the Bulk API to hard delete them from Salesforce in option C might not be necessary if the requirement is to only make the cases available on demand. The main focus should be on strategies that allow for older cases to be easily accessed without affecting the performance of the Salesforce org.","comment_id":"1074844","comments":[{"upvote_count":"2","comment_id":"1127822","timestamp":"1721560560.0","content":"1) UC creates 5 million cases per year. 2) There are records up to 7 years old. \n1+2 means that a large amount of data is generated in UC and should not be saved in Salesforce but somewhere else. so deleting data from Salesforce is necessary.","poster":"DonDemik"}],"poster":"tobicky","upvote_count":"1","timestamp":"1716136140.0"}],"upvote_count":"3","comment_id":"1025057","timestamp":"1712253540.0","content":"Selected Answer: CD\nC and D are correct.\n\nA - You can't expect a service agent to know how to use a database.\nB - Custom Object are not designed for LVD (Large Data Volume)"},{"upvote_count":"3","timestamp":"1710015720.0","poster":"vkm","comments":[],"comment_id":"1003411","content":"why can't CD"},{"poster":"vip_10","comment_id":"979871","timestamp":"1707822120.0","content":"Selected Answer: AD\nWith option B if the data is stored in custom object still it will count against the org's data storage limit.","upvote_count":"1"}],"timestamp":"2023-08-13 11:02:00"}],"exam":{"isBeta":false,"isMCOnly":true,"id":214,"name":"Certified Data Architect","isImplemented":true,"lastUpdated":"12 Apr 2025","numberOfQuestions":83,"provider":"Salesforce"},"currentPage":15},"__N_SSP":true}