{"pageProps":{"questions":[{"id":"CMgGRs9FKJe8YlPZc7qL","answers_community":["CE (71%)","CD (29%)"],"unix_timestamp":1689496080,"question_text":"What are benefits of using Snowpark with Snowflake? (Choose two.)","choices":{"A":"Snowpark uses a Spark engine to generate optimized SQL query plans.","B":"Snowpark automatically sets up Spark within Snowflake virtual warehouses.","D":"Snowpark allows users to run existing Spark code on virtual warehouses without the need to reconfigure the code.","C":"Snowpark does not require that a separate cluster be running outside of Snowflake.","E":"Snowpark executes as much work as possible in the source databases for all operations including User-Defined Functions (UDFs)."},"discussion":[{"comment_id":"1357587","content":"Selected Answer: CE\nhttps://docs.snowflake.com/en/developer-guide/snowpark/index\nSupport for pushdown for all operations, including Snowflake UDFs. This means Snowpark pushes down all data transformation and heavy lifting to the Snowflake data cloud, enabling you to efficiently work with data of any size.\n\nNo requirement for a separate cluster outside of Snowflake for computations. All of the computations are done within Snowflake. Scale and compute management are handled by Snowflake.","upvote_count":"1","timestamp":"1739770140.0","poster":"JRayan"},{"poster":"0e504b5","timestamp":"1723574460.0","content":"Selected Answer: CE\nhttps://www.snowflake.com/en/data-cloud/snowpark/spark-to-snowpark/\nhttps://www.snowflake.com/en/data-cloud/snowpark/\nhttps://docs.snowflake.com/en/developer-guide/snowpark/index\nhttps://medium.com/snowflake/pyspark-versus-snowpark-for-ml-in-terms-of-mindset-and-approach-8be4bdafa547#:~:text=Snowpark%20pushes%20all%20of%20its,leverage%20the%20power%20of%20Snowflake.\nhttps://www.snowflake.com/blog/snowpark-designing-performant-processing-python-java-scala/\nhttps://docs.snowflake.com/en/user-guide/warehouses-snowpark-optimized","upvote_count":"3","comment_id":"1149564"},{"comment_id":"1120448","poster":"Rana1986","content":"CE as per documentation. Pushdown means pushing as much as code to Source DB.","upvote_count":"2","timestamp":"1720754160.0"},{"poster":"[Removed]","content":"Selected Answer: CE\nThere is no mention of D anywhere.. you need to migrate the job code","timestamp":"1714705080.0","comment_id":"1061084","upvote_count":"3"},{"timestamp":"1713765600.0","comment_id":"1050242","upvote_count":"2","content":"Selected Answer: CE\nD is not an answer, document does not say this and snowpark has its own API which you need to use and cannot run spark code directly.. need to be customised","poster":"[Removed]"},{"timestamp":"1709599860.0","content":"Selected Answer: CD\nOption E :In general, Snow park will try to execute as much work as possible in the source databases, but there are some cases where it will need to transfer data to the server. The specific cases will depend on the operations that you are performing and the data that you are accessing.\n\nLet's say you want to join two tables in Snowflake. If the two tables are in the same database, then Snow park can execute the join operation in the source database. However, if the two tables are in different databases, then Snow park will need to transfer the data from one database to the other before it can execute the join operation.","poster":"JG1984","comment_id":"998882","upvote_count":"3"},{"timestamp":"1705678740.0","upvote_count":"3","comment_id":"956685","poster":"ukpino","content":"Selected Answer: CE\nhttps://docs.snowflake.com/en/developer-guide/snowpark/index\n\nBenefits When Compared with the Spark Connector\n\nIn comparison to using the Snowflake Connector for Spark, developing with Snowpark includes the following benefits:\n\n Support for interacting with data within Snowflake using libraries and patterns purpose built for different languages without compromising on performance or functionality.\n\n Support for authoring Snowpark code using local tools such as Jupyter, VS Code, or IntelliJ.\n\n Support for pushdown for all operations, including Snowflake UDFs. This means Snowpark pushes down all data transformation and heavy lifting to the Snowflake data cloud, enabling you to efficiently work with data of any size.\n\n No requirement for a separate cluster outside of Snowflake for computations. All of the computations are done within Snowflake. Scale and compute management are handled by Snowflake."},{"comment_id":"953169","upvote_count":"2","timestamp":"1705400880.0","comments":[{"timestamp":"1735408500.0","poster":"MultiCloudIronMan","comment_id":"1333091","content":"CE not CD","upvote_count":"1"}],"content":"Selected Answer: CD\nCorrect","poster":"MultiCloudIronMan"}],"timestamp":"2023-07-16 10:28:00","question_images":[],"isMC":true,"answer_images":[],"topic":"1","question_id":966,"answer":"CE","answer_ET":"CE","exam_id":167,"answer_description":"","url":"https://www.examtopics.com/discussions/snowflake/view/115453-exam-snowpro-core-topic-1-question-734-discussion/"},{"id":"FsgljXYdy3s2CbIwes0a","answer_description":"","topic":"1","timestamp":"2023-07-16 10:29:00","isMC":true,"exam_id":167,"answer_ET":"AE","url":"https://www.examtopics.com/discussions/snowflake/view/115454-exam-snowpro-core-topic-1-question-735-discussion/","answer":"AE","answers_community":["AE (67%)","E (33%)"],"answer_images":[],"question_text":"What are Snowflake best practices when assigning the ACCOUNTADMIN role to users? (Choose two.)","choices":{"E":"All users assigned the ACCOUNTADMIN role should use Multi-Factor Authentication (MFA).","D":"The ACCOUNTADMIN role should be given to any user who needs a high level of authority.","C":"The ACCOUNTADMIN role should be used for running automated scripts.","A":"The ACCOUNTADMIN role should be assigned to at least two users.","B":"The ACCOUNTADMIN role should be used to create Snowflake objects."},"unix_timestamp":1689496140,"discussion":[{"timestamp":"1730749020.0","comment_id":"1206595","upvote_count":"1","content":"Selected Answer: AE\nA and E","poster":"mickies9"},{"upvote_count":"1","comment_id":"1088374","poster":"umidjon03","content":"Selected Answer: AE\nA and E are correct","timestamp":"1717575360.0"},{"poster":"junaid2107","timestamp":"1717374840.0","content":"Selected Answer: E\nSysadmin should be given to 2 users. Account Admin should have highest authority an MFA as per best practices","upvote_count":"2","comment_id":"1086540"},{"comment_id":"953170","content":"Selected Answer: AE\nCorrect","upvote_count":"2","timestamp":"1705400940.0","poster":"MultiCloudIronMan"}],"question_id":967,"question_images":[]},{"id":"3xs5Dfk8qCPWwqCUasLt","question_text":"What is a recommended approach for optimizing query performance in Snowflake?","exam_id":167,"answer_images":[],"timestamp":"2023-07-22 15:39:00","isMC":true,"unix_timestamp":1690033140,"answer_ET":"D","question_id":968,"answer":"D","answers_community":["D (67%)","A (33%)"],"url":"https://www.examtopics.com/discussions/snowflake/view/116081-exam-snowpro-core-topic-1-question-736-discussion/","discussion":[{"content":"Selected Answer: D\nD this time","timestamp":"1724591160.0","upvote_count":"2","comment_id":"1158884","poster":"guau"},{"upvote_count":"4","comment_id":"985836","timestamp":"1708445040.0","content":"D is the correct answer. Snowflake makes use of clustering on tables. Users can utilize cluster key to enhance query performance (partition pruning) on large tables. Lesser the number of joins between several tables = better performance in general.","poster":"singhks"},{"poster":"arnabbis4u","comments":[{"poster":"alfredofmt","upvote_count":"2","comment_id":"991481","content":"Love the copy-paste from ChatGPT","timestamp":"1709048520.0"}],"upvote_count":"4","comment_id":"964006","timestamp":"1706295720.0","content":"The correct answer is D. Use a smaller number of larger tables rather than a larger number of smaller tables.\n\nHere are some of the reasons why using a smaller number of larger tables can improve query performance in Snowflake:\n\nReduced data movement: When you join multiple tables, Snowflake needs to move data between the tables. This can be a bottleneck, especially if the tables are large. Using a smaller number of larger tables can reduce the amount of data that needs to be moved, which can improve performance.\nImproved caching: Snowflake caches data in memory. When you use a smaller number of larger tables, the data is more likely to be cached in memory, which can also improve performance.\nSimplified query planning: Snowflake's query planner is more efficient when it has to plan queries for a smaller number of tables. This can also improve performance."},{"timestamp":"1705937940.0","content":"Selected Answer: A\nThis because subqueries will cache their result and it can be reused","comment_id":"959568","upvote_count":"1","poster":"MultiCloudIronMan"}],"answer_description":"","topic":"1","choices":{"C":"Select all columns from tables, even if they are not needed in the query.","B":"Use a large number of joins to combine data from multiple tables.","A":"Use subqueries whenever possible.","D":"Use a smaller number of larger tables rather than a larger number of smaller tables."},"question_images":[]},{"id":"Bse03Y9cW7G0q1jUZhlK","exam_id":167,"answer_ET":"CD","answer_images":[],"isMC":true,"question_images":[],"discussion":[{"poster":"Rajivnb","content":"Selected Answer: CD\nhttps://docs.snowflake.com/en/user-guide/snowsql-use#exporting-data.\nQuiet is also correct, but this is optional. Not a REQUIRED parameter.","comment_id":"1044496","upvote_count":"1","timestamp":"1729032300.0"},{"content":"Selected Answer: CD\nLooks like a good choice","poster":"MultiCloudIronMan","comment_id":"959571","timestamp":"1721655660.0","upvote_count":"1"}],"answer":"CD","answers_community":["CD (100%)"],"unix_timestamp":1690033260,"question_text":"When using SnowSQL, which configuration options are required when unloading data from a SQL query run on a local machine? (Choose two.)","choices":{"A":"echo","E":"force_put_overwrite","C":"output_file","B":"quiet","D":"output_format"},"question_id":969,"answer_description":"","topic":"1","url":"https://www.examtopics.com/discussions/snowflake/view/116082-exam-snowpro-core-topic-1-question-737-discussion/","timestamp":"2023-07-22 15:41:00"},{"id":"BPBLSNx9IyLejPi88NQ7","answer_images":[],"topic":"1","answers_community":["A (100%)"],"unix_timestamp":1690033320,"choices":{"B":"COPY_HISTORY","D":"ROW_ACCESS_POLICIES","A":"ACCESS_HISTORY","C":"QUERY_HISTORY"},"answer_description":"","discussion":[{"content":"Selected Answer: A\nThe \"ACCESS_HISTORY\" view in Snowflake is primarily used to support compliance auditing. This view contains information about historical access and usage patterns related to tables and views within your Snowflake account. It provides details on who accessed the data, when, and from which IP addresses, among other audit-related information.","upvote_count":"1","timestamp":"1725312480.0","poster":"JG1984","comment_id":"997140"},{"upvote_count":"1","content":"Selected Answer: A\nhttps://www.bing.com/search?q=Which+Snowflake+view+is+used+to+support+compliance+auditing%3F&aqs=edge..69i57j69i11004&FORM=ANCMS9&PC=U531","comments":[{"content":"According to the above search results, it should be C: QUERY_HISTORY","upvote_count":"1","timestamp":"1725624780.0","poster":"sarthakgirdhar","comments":[{"content":"https://docs.snowflake.com/en/user-guide/access-history","upvote_count":"1","comment_id":"1044490","timestamp":"1729031820.0","poster":"Rajivnb"}],"comment_id":"1000578"}],"poster":"MultiCloudIronMan","timestamp":"1721655720.0","comment_id":"959574"}],"timestamp":"2023-07-22 15:42:00","exam_id":167,"url":"https://www.examtopics.com/discussions/snowflake/view/116083-exam-snowpro-core-topic-1-question-738-discussion/","question_text":"Which Snowflake view is used to support compliance auditing?","isMC":true,"question_id":970,"answer":"A","answer_ET":"A","question_images":[]}],"exam":{"lastUpdated":"12 Apr 2025","numberOfQuestions":1259,"isMCOnly":true,"isBeta":false,"id":167,"isImplemented":true,"name":"SnowPro Core","provider":"Snowflake"},"currentPage":194},"__N_SSP":true}