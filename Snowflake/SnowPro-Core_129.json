{"pageProps":{"questions":[{"id":"zhNhgT7IGrqE3PWATjj7","answer_images":[],"unix_timestamp":1675105260,"answer_description":"","question_id":641,"question_images":[],"timestamp":"2023-01-30 20:01:00","url":"https://www.examtopics.com/discussions/snowflake/view/97263-exam-snowpro-core-topic-1-question-441-discussion/","answer_ET":"C","choices":{"B":"Parquet","C":"CSV (Gzipped)","D":"ORC","A":"CSV (Unzipped)"},"discussion":[{"timestamp":"1722358860.0","content":"Selected Answer: C\nLoading from Gzipped CSV is several times faster than loading from ORC and Parquet at an impressive 15 TB/Hour. While 5-6 TB/hour is decent if your data is originally in ORC or Parquet, don’t go out of your way to CREATE ORC or Parquet files from CSV in the hope that it will load Snowflake faster.\nLoading data into fully structured (columnarized) schema is ~10-20% faster than landing it into a VARIANT.\n\nhttps://community.snowflake.com/s/article/How-to-Load-Terabytes-Into-Snowflake-Speeds-Feeds-and-Techniques","upvote_count":"7","poster":"leozhang","comment_id":"793208"},{"comment_id":"873884","poster":"MultiCloudIronMan","comments":[{"timestamp":"1735295880.0","content":"should be B While CSV (Gzipped) (option C) is a commonly used format and can be efficient in terms of storage space due to compression, it is not as performant as Parquet (option B) for loading data in Snowflake.","comment_id":"1332357","poster":"MultiCloudIronMan","upvote_count":"1"}],"content":"Selected Answer: C\nVerified","timestamp":"1729269780.0","upvote_count":"1"}],"isMC":true,"exam_id":167,"answers_community":["C (100%)"],"answer":"C","question_text":"What is the MOST performant file format for loading data in Snowflake?","topic":"1"},{"id":"E92Qbrba2w8l7PyuPDnu","timestamp":"2022-12-23 00:46:00","isMC":true,"question_images":[],"discussion":[{"upvote_count":"7","comment_id":"761573","content":"Selected Answer: D\nSnowsight supports the following types of charts:\n\nBar charts\nLine charts\nScatterplots\nHeat grids\nScorecards\n\nhttps://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations.html","poster":"SV1122","timestamp":"1672359600.0"},{"timestamp":"1719230100.0","upvote_count":"1","content":"Selected Answer: D\nSnowsight supports the following types of charts:\n\nBar charts\nLine charts\nScatterplots\nHeat grids\nScorecards","comment_id":"1236308","poster":"Rameez1"},{"timestamp":"1681836240.0","comment_id":"873885","upvote_count":"1","content":"Selected Answer: D\nCorrect","poster":"MultiCloudIronMan"},{"poster":"SnowProCertDec22","upvote_count":"3","timestamp":"1671752760.0","content":"Selected Answer: D\nhttps://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations.html#:~:text=Snowsight%20supports%20the%20following%20types,Scatterplots","comment_id":"753753"}],"choices":{"A":"Box plot","C":"Pie chart","D":"Scatterplot","B":"Bubble chart"},"answer_images":[],"unix_timestamp":1671752760,"exam_id":167,"answer":"D","topic":"1","answers_community":["D (100%)"],"question_id":642,"question_text":"Which chart type does Snowsight support to visualize worksheet data?","url":"https://www.examtopics.com/discussions/snowflake/view/92513-exam-snowpro-core-topic-1-question-442-discussion/","answer_description":"","answer_ET":"D"},{"id":"tZMDDgUyWVhEJKWOjdkX","timestamp":"2022-12-19 22:56:00","answer_description":"","question_text":"Which result shows efficient pruning?","answer":"B","discussion":[{"timestamp":"1688542440.0","poster":"AlexbDku","upvote_count":"9","content":"Selected Answer: B\nB \nhttps://docs.snowflake.com/en/user-guide/ui-query-profile.html#inefficient-pruning","comment_id":"766455"},{"comment_id":"1106533","poster":"gizzamo","content":"Selected Answer: B\nhttps://docs.snowflake.com/en/user-guide/ui-query-profile#inefficient-pruning\n\n...\nThe efficiency of pruning can be observed by comparing Partitions scanned and Partitions total statistics in the TableScan operators. If the former is a small fraction of the latter, pruning is efficient. If not, the pruning did not have an effect.\n...","timestamp":"1719451980.0","upvote_count":"2"},{"upvote_count":"2","comment_id":"958920","content":"Selected Answer: B\ncorrect","timestamp":"1705876860.0","poster":"MultiCloudIronMan"},{"comment_id":"905063","upvote_count":"2","poster":"KnightVictor","timestamp":"1700762280.0","content":"Selected Answer: B\nfor sure B. thats the primary purpose of pruning... to scan less partitions"},{"poster":"MultiCloudIronMan","timestamp":"1697647500.0","upvote_count":"2","content":"Selected Answer: B\nB is correct","comment_id":"873886"},{"upvote_count":"2","content":"Selected Answer: B\nB - correct","poster":"EmiB","timestamp":"1694361180.0","comment_id":"835283"},{"upvote_count":"4","content":"Answer Should be B (scanned partitions should be less than total partitions)","timestamp":"1687755120.0","comment_id":"757143","poster":"AravindhTN"},{"poster":"sachchhab","upvote_count":"4","content":"B-https://docs.snowflake.com/en/user-guide/ui-query-profile.html#inefficient-pruning","timestamp":"1687204560.0","comment_id":"750272"}],"url":"https://www.examtopics.com/discussions/snowflake/view/92133-exam-snowpro-core-topic-1-question-443-discussion/","answers_community":["B (100%)"],"question_id":643,"answer_images":[],"answer_ET":"B","question_images":[],"topic":"1","unix_timestamp":1671486960,"exam_id":167,"choices":{"A":"Partitions scanned is greater than partitions total.","D":"Partitions scanned is greater than or equal to the partitions total.","B":"Partitions scanned is less than partitions total.","C":"Partitions scanned is equal to the partitions total."},"isMC":true},{"id":"qdj3QS2tbnuLIaBvqSUl","url":"https://www.examtopics.com/discussions/snowflake/view/92192-exam-snowpro-core-topic-1-question-444-discussion/","answer":"B","isMC":true,"answer_images":[],"timestamp":"2022-12-20 15:29:00","unix_timestamp":1671546540,"question_text":"Which clustering indicator will show if a large table in Snowflake will benefit from explicitly defining a clustering key?","answer_description":"","exam_id":167,"question_images":[],"question_id":644,"topic":"1","discussion":[{"poster":"nexerSnow","comment_id":"1213209","timestamp":"1731924780.0","content":"Selected Answer: B\nClustering Depth\nThe clustering depth for a populated table measures the average depth (1 or greater) of the overlapping micro-partitions for specified columns in a table. The smaller the average depth, the better clustered the table is with regards to the specified columns.\n\nClustering depth can be used for a variety of purposes, including:\n\nMonitoring the clustering “health” of a large table, particularly over time as DML is performed on the table.\n\nDetermining whether a large table would benefit from explicitly defining a clustering key.","upvote_count":"3"},{"upvote_count":"1","comment_id":"1165666","poster":"_yyukta","content":"Selected Answer: B\nB. Depth","timestamp":"1725452640.0"},{"comment_id":"873887","poster":"MultiCloudIronMan","content":"Selected Answer: B\nCorrect","upvote_count":"1","timestamp":"1697647500.0"},{"upvote_count":"1","timestamp":"1696655280.0","content":"Selected Answer: B\nVerified","poster":"Kvk117","comment_id":"863496"},{"upvote_count":"3","timestamp":"1687264140.0","poster":"Rob__C","content":"https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html#label-clustering-depth","comment_id":"751008"}],"answer_ET":"B","answers_community":["B (100%)"],"choices":{"A":"Percentage","B":"Depth","D":"Total partition count","C":"Ratio"}},{"id":"ZsRqbZLrh9Eey64kXnZg","question_images":[],"answer_description":"","question_id":645,"url":"https://www.examtopics.com/discussions/snowflake/view/93015-exam-snowpro-core-topic-1-question-445-discussion/","choices":{"B":"CSV","A":"Parquet","C":"ORC","D":"Avro"},"isMC":true,"answers_community":["B (100%)"],"unix_timestamp":1672175100,"answer":"B","exam_id":167,"answer_images":[],"timestamp":"2022-12-27 22:05:00","topic":"1","question_text":"Which file format is MOST performant in Snowflake for data loading?","discussion":[{"content":"Selected Answer: B\nB. CSV","upvote_count":"1","comment_id":"1165668","poster":"_yyukta","timestamp":"1725452700.0"},{"comment_id":"873889","poster":"MultiCloudIronMan","upvote_count":"1","comments":[{"poster":"MultiCloudIronMan","content":"Changed my mind, Answer is 'A' The most performant file format for loading data in Snowflake is Parquet. According to Snowflake's official documentation, Parquet is a columnar storage file format that provides efficient data compression and encoding schemes, which improves performance for both storage and query execution","timestamp":"1735296120.0","comment_id":"1332361","upvote_count":"1"}],"content":"Selected Answer: B\nCorrect","timestamp":"1697647560.0"},{"timestamp":"1687892700.0","upvote_count":"3","comment_id":"759066","content":"Selected Answer: B\nLoading from Gzipped CSV is several times faster than loading from ORC and Parquet at an impressive 15 TB/Hour. While 5-6 TB/hour is decent if your data is originally in ORC or Parquet, don’t go out of your way to CREATE ORC or Parquet files from CSV in the hope that it will load Snowflake faster.\n\nhttps://community.snowflake.com/s/article/How-to-Load-Terabytes-Into-Snowflake-Speeds-Feeds-and-Techniques#:~:text=Loading%20data%20into%20Snowflake%20is,into%20fully%20structured%20Snowflake%20tables.","poster":"SV1122"}],"answer_ET":"B"}],"exam":{"numberOfQuestions":1259,"provider":"Snowflake","isImplemented":true,"isMCOnly":true,"name":"SnowPro Core","isBeta":false,"id":167,"lastUpdated":"12 Apr 2025"},"currentPage":129},"__N_SSP":true}