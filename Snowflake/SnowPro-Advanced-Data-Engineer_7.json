{"pageProps":{"questions":[{"id":"TEaXbZAQOqOYcqK8SW5U","topic":"1","timestamp":"2023-11-12 23:08:00","choices":{"D":"FIELD_OPTIONALLY_ENCLOSED_BY = '\"'","A":"ESCAPE_UNENCLOSED FIELD = '\\\\'","C":"FIELD_DELIMITER = ','","B":"ERROR_ON_COLUMN_COUNT_MISMATCH = FALSE"},"answer_ET":"D","unix_timestamp":1699826880,"question_id":31,"discussion":[{"upvote_count":"1","comment_id":"1123821","content":"https://docs.snowflake.com/en/user-guide/data-unload-considerations\nFIELD_OPTIONALLY_ENCLOSED_BY = 'character' | NONE\nUse this option to enclose strings in the specified character: single quote ('), double quote (\"), or NONE.","poster":"ecvdata","timestamp":"1721090820.0"},{"timestamp":"1715544480.0","upvote_count":"1","comment_id":"1068891","poster":"stopthisnow","content":"Selected Answer: D\nD makes sense. Due to commas in the column value, the column needs to be enclosed by \" to be treated as a single column."}],"question_images":["https://img.examtopics.com/snowpro-advanced-data-engineer/image23.png","https://img.examtopics.com/snowpro-advanced-data-engineer/image24.png","https://img.examtopics.com/snowpro-advanced-data-engineer/image25.png"],"answers_community":["D (100%)"],"isMC":true,"question_text":"A Data Engineer is trying to load the following rows from a CSV file into a table in Snowflake with the following structure:\n//IMG//\n\n//IMG//\n\nThe engineer is using the following COPY INTO statement:\n//IMG//\n\nHowever, the following error is received:\nNumber of columns in file (6) does not match that of the corresponding table (3), use file format option error_on_column_count_mismatch=false to ignore this error File 'address.csv.gz', line 3, character 1 Row 1 starts at line 2, column \"STGCUSTOMER\"[6] If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option.\nWhich file format option should be used to resolve the error and successfully load all the data into the table?","url":"https://www.examtopics.com/discussions/snowflake/view/125893-exam-snowpro-advanced-data-engineer-topic-1-question-37/","answer_description":"","answer_images":[],"answer":"D","exam_id":166},{"id":"IjzNiSlsAupUcezi4WaH","choices":{"D":"Decrease the buffer size to trigger delivery of files sized between 100 to 250 MB in Kinesis Firehose.","C":"Change the file compression size and increase the frequency of the Snowpipe loads.","B":"Split the files before loading them and set the SIZE_LIMIT option to 250 MB.","A":"Increase the size of the virtual warehouse used by Snowpipe."},"answer":"D","topic":"1","question_text":"A Data Engineer is working on a continuous data pipeline which receives data from Amazon Kinesis Firehose and loads the data into a staging table which will later be used in the data transformation process. The average file size is 300-500 MB.\nThe Engineer needs to ensure that Snowpipe is performant while minimizing costs.\nHow can this be achieved?","answer_description":"","timestamp":"2023-11-12 23:18:00","question_images":[],"unix_timestamp":1699827480,"question_id":32,"answer_images":[],"isMC":true,"url":"https://www.examtopics.com/discussions/snowflake/view/125895-exam-snowpro-advanced-data-engineer-topic-1-question-38/","discussion":[{"poster":"DIPARJ","content":"Selected Answer: B\nIt should be option B","timestamp":"1743330360.0","comment_id":"1411989","upvote_count":"1"},{"comment_id":"1074059","upvote_count":"1","timestamp":"1731940080.0","poster":"Snow_P","content":"Selected Answer: D\nhttps://docs.snowflake.com/en/user-guide/data-load-considerations-prepare"},{"comment_id":"1068894","upvote_count":"1","content":"Selected Answer: D\nVarious tools can aggregate and batch data files. One convenient option is Amazon Kinesis Firehose. Firehose allows defining both the desired file size, called the buffer size, and the wait interval after which a new file is sent (to cloud storage in this case), called the buffer interval. For more information, see the Kinesis Firehose documentation. If your source application typically accumulates enough data within a minute to populate files larger than the recommended maximum for optimal parallel processing, you could decrease the buffer size to trigger delivery of smaller files. Keeping the buffer interval setting at 60 seconds (the minimum value) helps avoid creating too many files or increasing latency.","poster":"stopthisnow","timestamp":"1731449880.0"}],"answer_ET":"D","answers_community":["D (67%)","B (33%)"],"exam_id":166},{"id":"WaEmveCj4Gp3vQLrS1hg","unix_timestamp":1699827840,"timestamp":"2023-11-12 23:24:00","url":"https://www.examtopics.com/discussions/snowflake/view/125897-exam-snowpro-advanced-data-engineer-topic-1-question-39/","answer_images":[],"question_id":33,"answers_community":["D (75%)","C (25%)"],"question_images":[],"discussion":[{"content":"Selected Answer: C\nFeels C is more aligned to the question","comment_id":"1411974","poster":"DIPARJ","upvote_count":"1","timestamp":"1743324480.0"},{"comment_id":"1074062","poster":"Snow_P","content":"Selected Answer: D\nMore info here https://docs.snowflake.com/en/user-guide/security-column-intro","upvote_count":"1","timestamp":"1731940320.0"},{"poster":"stopthisnow","upvote_count":"2","content":"Selected Answer: D\nhttps://docs.snowflake.com/en/sql-reference/functions/is_granted_to_invoker_role","comment_id":"1068902","timestamp":"1731450240.0"}],"answer_ET":"D","isMC":true,"answer":"D","answer_description":"","exam_id":166,"topic":"1","question_text":"Within a Snowflake account. permissions have been defined with custom roles and role hierarchies.\nTo set up column-level masking using a role in the hierarchy of the current user, what command would be used?","choices":{"B":"INVOKER_ROLE","C":"IS_ROLE_IN_SESSION","D":"IS_GRANTED_TO_INVOKER_ROLE","A":"CURRENT_ROLE"}},{"id":"ZxDkO0tkYokFu00uqPLW","answer":"BDE","answer_description":"","exam_id":166,"url":"https://www.examtopics.com/discussions/snowflake/view/124927-exam-snowpro-advanced-data-engineer-topic-1-question-4/","discussion":[{"comment_id":"1182272","content":"Selected Answer: BDE\nA - incorrect as size too large; C - incorrect as not good practice for any data platform; \nF - Quote from Snowflake:\nCreating smaller data files and staging them in cloud storage more often than once per minute has the following disadvantages:\n- A reduction in latency between staging and loading the data cannot be guaranteed.\n- An overhead to manage files in the internal load queue is included in the utilization costs charged for Snowpipe. This overhead increases in relation to the number of files queued for loading.","timestamp":"1727240940.0","poster":"rbeam","upvote_count":"1"},{"timestamp":"1716032340.0","poster":"Snow_P","comment_id":"1074017","content":"Selected Answer: BDE\nhttps://docs.snowflake.com/en/user-guide/data-load-considerations-prepare","upvote_count":"3"},{"poster":"stopthisnow","comment_id":"1057548","upvote_count":"2","content":"Selected Answer: BDE\nLoading data files roughly 100-250 MB in size or larger reduces the overhead charge relative to the amount of total data loaded to the point where the overhead cost is immaterial.\nhttps://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#label-snowpipe-file-size","timestamp":"1714465980.0"}],"question_text":"A Data Engineer needs to load JSON output from some software into Snowflake using Snowpipe.\nWhich recommendations apply to this scenario? (Choose three.)","choices":{"F":"Create data files that are less than 100 MB and stage them in cloud storage at a sequence greater than once each minute.","B":"Ensure that data files are 100-250 MB (or larger) in size, compressed.","D":"Verify each value of each unique element stores a single native data type (string or number).","A":"Load large files (1 GB or larger).","E":"Extract semi-structured data elements containing null values into relational columns before loading.","C":"Load a single huge array containing multiple records into a single table row."},"question_id":34,"topic":"1","question_images":[],"unix_timestamp":1698661980,"timestamp":"2023-10-30 11:33:00","answer_ET":"BDE","isMC":true,"answers_community":["BDE (100%)"],"answer_images":[]},{"id":"qVoujBa42C2uDJDYk7Ux","answer":"AC","exam_id":166,"answer_description":"","url":"https://www.examtopics.com/discussions/snowflake/view/125899-exam-snowpro-advanced-data-engineer-topic-1-question-40/","discussion":[{"timestamp":"1731450780.0","poster":"stopthisnow","comment_id":"1068909","comments":[{"poster":"19Arpit98","upvote_count":"1","timestamp":"1736525700.0","comment_id":"1338862","comments":[{"content":"The database is MYDATbase AND snowflake.information_schema.fucntions view will only have the functions that are available in the database\"Snowflake\".","timestamp":"1738288440.0","upvote_count":"1","comment_id":"1349351","poster":"akellaanurag"}],"content":"Why B is incorrect?"}],"content":"Selected Answer: AC\nSHOW USER FUNCTIONS LIKE 'DAY_NAME_ON' IN SCHEMA DEMO_SCHEMA;\n SELECT IS_SECURE FROM INFORMATION_SCHEMA.FUNCTIONS WHERE FUNCTION_SCHEMA = 'DEMO_SCHEMA' AND FUNCTION_NAME = 'DAY_NAME_ON';","upvote_count":"1"}],"question_text":"Assuming a Data Engineer has all appropriate privileges and context, which statements would be used to assess whether the User-Defined Function (UDF), MYDATABASE.SALES.REVENUE_BY_REGION, exists and is secure? (Choose two.)","choices":{"A":"SHOW USER FUNCTIONS LIKE 'REVENUE_BY_REGION' IN SCHEMA SALES;","C":"SELECT IS_SECURE FROM INFORMATION_SCHEMA.FUNCTIONS WHERE FUNCTION_SCHEMA = 'SALES' AND FUNCTION_NAME = 'REVENUE_BY_REGION';","B":"SELECT IS_SECURE FROM SNOWFLAKE.INFORMATION_SCHEMA.FUNCTIONS WHERE FUNCTION_SCHEMA = 'SALES' AND FUNCTION_NAME = 'REVENUE_BY_REGION';","E":"SHOW SECURE FUNCTIONS LIKE 'REVENUE_BY_REGION' IN SCHEMA SALES;","D":"SHOW EXTERNAL FUNCTIONS LIKE 'REVENUE_BY_REGION' IN SCHEMA SALES;"},"question_id":35,"topic":"1","question_images":[],"unix_timestamp":1699828380,"timestamp":"2023-11-12 23:33:00","answer_ET":"AC","isMC":true,"answers_community":["AC (100%)"],"answer_images":[]}],"exam":{"isBeta":false,"provider":"Snowflake","isMCOnly":true,"id":166,"lastUpdated":"12 Apr 2025","name":"SnowPro Advanced Data Engineer","isImplemented":true,"numberOfQuestions":65},"currentPage":7},"__N_SSP":true}