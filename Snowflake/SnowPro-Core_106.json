{"pageProps":{"questions":[{"id":"1lnLuv3G5RunRTwHx42z","unix_timestamp":1670609760,"isMC":true,"answer_description":"","question_images":[],"timestamp":"2022-12-09 19:16:00","url":"https://www.examtopics.com/discussions/snowflake/view/90833-exam-snowpro-core-topic-1-question-338-discussion/","discussion":[{"poster":"harshagc180","timestamp":"1702145760.0","content":"Answer : OBJECT and ARRAY","upvote_count":"12","comment_id":"740340"},{"comment_id":"760019","poster":"SV1122","timestamp":"1703776740.0","upvote_count":"6","content":"A VARIANT can store a value of any other type, including OBJECT and ARRAY. The maximum length of a VARIANT is 16 MB."},{"content":"C and D is correct","comment_id":"1060226","timestamp":"1730519580.0","upvote_count":"1","poster":"Afzy"},{"upvote_count":"1","poster":"Heetec","comment_id":"1022548","content":"Selected Answer: BD\nB and D","timestamp":"1727803800.0"},{"timestamp":"1726743480.0","comment_id":"1011206","poster":"Amitsnowflake","content":"VARIANT can store a value of any other type, including OBJECT and ARRAY.","upvote_count":"1"},{"comment_id":"949161","content":"Selected Answer: BD\nCorrect","timestamp":"1720716660.0","poster":"MultiCloudIronMan","upvote_count":"1"},{"timestamp":"1712882400.0","content":"BD is correct.\n\nhttps://docs.snowflake.com/en/sql-reference/data-types-semistructured","upvote_count":"2","poster":"learner2023","comment_id":"867770"},{"timestamp":"1709859060.0","poster":"EmiB","upvote_count":"3","content":"Selected Answer: BD\nOBJECT and ARRAY","comment_id":"832398"},{"poster":"SnowProCertDec22","content":"OBJECT and ARRAY","upvote_count":"4","timestamp":"1702572420.0","comment_id":"745291"}],"answer":"BD","exam_id":167,"answer_images":[],"answer_ET":"BD","topic":"1","answers_community":["BD (100%)"],"question_text":"What are value types that a VARIANT column can store? (Choose two.)","question_id":526,"choices":{"D":"ARRAY","A":"STRUCT","C":"BINARY","E":"CLOB","B":"OBJECT"}},{"id":"Gjrt8QbsGouCW2IAMjwD","answers_community":["C (100%)"],"answer":"C","exam_id":167,"choices":{"A":"Use auto-ingest Snowpipes to load large files in a serverless model.","C":"Produce a larger number of smaller files and process the ingestion with size Small virtual warehouses.","B":"Produce the largest files possible, reducing the overall number of files to process.","D":"Use an external tool to issue batched row-by-row inserts within BEGIN TRANSACTION and COMMIT commands."},"question_text":"A company needs to read multiple terabytes of data for an initial load as part of a Snowflake migration. The company can control the number and size of CSV extract files.\n\nHow does Snowflake recommend maximizing the load performance?","question_id":527,"answer_images":[],"url":"https://www.examtopics.com/discussions/snowflake/view/91981-exam-snowpro-core-topic-1-question-339-discussion/","topic":"1","question_images":[],"answer_ET":"C","discussion":[{"comment_id":"748681","content":"Selected Answer: C\nc i think \nhttps://www.analytics.today/blog/top-3-snowflake-performance-tuning-tactics#:~:text=Avoid%20Scanning%20Files&text=Before%20copying%20data%2C%20Snowflake%20checks,that%20have%20already%20been%20loaded.","timestamp":"1671350520.0","upvote_count":"7","poster":"halol"},{"content":"Selected Answer: C\nSplit larger files into a greater number of smaller files to distribute the load among the compute resources in an active warehouse. The number of data files that are processed in parallel is determined by the amount of compute resources in a warehouse. We recommend splitting large files by line to avoid records that span chunks.\n\nhttps://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#:~:text=Split%20larger%20files,that%20span%20chunks.","poster":"aemilka","comment_id":"1285811","timestamp":"1726670340.0","upvote_count":"1"},{"content":"Selected Answer: C\ncorrect","comment_id":"957774","upvote_count":"1","timestamp":"1689867900.0","poster":"MultiCloudIronMan"},{"comment_id":"827779","content":"Selected Answer: C\nI'd go for C. A severless approach (A) is usually not recommended for large files due to the higher costs.","timestamp":"1677832380.0","upvote_count":"3","poster":"OTE"},{"comment_id":"755850","upvote_count":"2","comments":[{"content":"Snowpipe is designed for continuous ingestion and is built on COPY.\nThe COPY command enables loading batches of data available in external cloud storage or an internal stage.\n\nSo for the initial stage i think that i s a better solution COPY\nSo the answer is C","timestamp":"1674212220.0","comment_id":"782144","poster":"BigDataBB","upvote_count":"2"}],"timestamp":"1671988080.0","poster":"AS314","content":"https://www.snowflake.com/blog/best-practices-for-data-ingestion/\nI think A is correct"}],"unix_timestamp":1671350520,"isMC":true,"timestamp":"2022-12-18 09:02:00","answer_description":""},{"id":"bmmP9QkF3KWzZeqfPfRK","timestamp":"2022-01-03 12:38:00","unix_timestamp":1641209880,"answer_images":[],"isMC":true,"discussion":[{"content":"Answer is B False:\n\nE.g. JDBC:\n\nhttps://docs.snowflake.com/en/user-guide/jdbc.html\n\nSnowflake provides a JDBC type 4 driver that supports core JDBC functionality. The JDBC driver must be installed in a 64-bit environment and requires Java 1.8 (or higher). The driver can be used with most client tools/applications that support JDBC for connecting to a database server.","timestamp":"1641209880.0","comment_id":"515652","poster":"redsky0","upvote_count":"28"},{"upvote_count":"14","comment_id":"921137","poster":"shubtred","content":"False.\n\nA third-party tool that supports standard JDBC or ODBC can connect to Snowflake even without a Snowflake-specific driver. Snowflake provides JDBC and ODBC connectors that adhere to the standard JDBC and ODBC interfaces, allowing third-party tools to establish a connection to Snowflake using these standard protocols.\n\nThe Snowflake JDBC and ODBC connectors act as bridges between the third-party tools and the Snowflake service, enabling communication and data exchange. As long as the third-party tool supports JDBC or ODBC, it can utilize the Snowflake connectors to connect to Snowflake and interact with the data warehouse.\n\nThis approach ensures compatibility and interoperability with a wide range of tools and applications that support JDBC or ODBC, making it easier to integrate Snowflake into existing ecosystems or use preferred third-party tools for data analysis, reporting, or other purposes.","timestamp":"1686546480.0"},{"content":"Selected Answer: B\nA third-party tool that supports standard JDBC or ODBC can connect to Snowflake even if it does not have a Snowflake-specific driver. Snowflake provides its own JDBC and ODBC drivers that can be used by any tool that supports these standard interfaces. Therefore, as long as the tool can use a JDBC or ODBC driver, it can connect to Snowflake using Snowflake's provided drivers.","upvote_count":"1","poster":"Sudhansu21","timestamp":"1739855580.0","comment_id":"1358132"},{"content":"Selected Answer: B\nJDBC Driver is provided by snowflake","comment_id":"1331797","poster":"rocky_vits1","upvote_count":"2","timestamp":"1735190760.0"},{"timestamp":"1734566280.0","upvote_count":"2","comment_id":"1328775","poster":"legohax","content":"Selected Answer: B\nFalse, Snowflake has generic ODBC/JDBC driver support"},{"poster":"Yugendharsai","content":"Selected Answer: A\nSnowflake supports JDBC OR ODBC Does not care about driver it having its supported driver version to connect","upvote_count":"1","timestamp":"1734327480.0","comment_id":"1327169"},{"timestamp":"1732042980.0","upvote_count":"1","content":"Answer is B : False","poster":"Djama","comment_id":"1314860"},{"content":"Selected Answer: B\nThe correct answer is B. False\n\nA third-party tool that supports standard JDBC or ODBC can connect to Snowflake even without a Snowflake-specific driver. This is because Snowflake supports standard JDBC and ODBC protocols, allowing tools that use these standard database connectivity interfaces to establish connections to Snowflake.\n\nThe statement is false because:\n1. Standard JDBC/ODBC support is sufficient for basic connectivity\n2. Snowflake is designed to work with standard database connectivity protocols\n3. While Snowflake-specific drivers might offer optimized performance or additional features, they are not strictly required for basic connectivity","timestamp":"1731695040.0","comment_id":"1312766","poster":"kentucky13caa","upvote_count":"1"},{"content":"False.\n\nA third-party tool that supports standard JDBC or ODBC can connect to Snowflake even without a Snowflake-specific driver.","poster":"Shipra123","timestamp":"1731669060.0","comment_id":"1312594","upvote_count":"1"},{"content":"Selected Answer: B\nAnswer is B","poster":"HICH9173","upvote_count":"1","timestamp":"1730454660.0","comment_id":"1305723"},{"upvote_count":"1","timestamp":"1730327220.0","comment_id":"1305215","poster":"pjfunner","content":"Selected Answer: B\nIt's B. As long as ODBC and JDBC are supported you can connect to Snowflake."},{"upvote_count":"1","timestamp":"1730134020.0","content":"Selected Answer: B\nas long as JDBC or ODBC is supported it can connect","comment_id":"1304055","poster":"Daniel1412"},{"poster":"d22770a","upvote_count":"2","timestamp":"1728321900.0","content":"It is B","comment_id":"1294409"},{"upvote_count":"1","content":"Selected Answer: B\nB. False","timestamp":"1728028620.0","comment_id":"1293073","poster":"theriderzone"},{"comment_id":"1291487","timestamp":"1727685720.0","upvote_count":"1","poster":"jiriz","content":"Selected Answer: A\nI believe, that the answer is True, so A"},{"comment_id":"1257650","timestamp":"1722278700.0","content":"Answer is B","poster":"Tushar0807","upvote_count":"1"},{"comment_id":"1251830","content":"Correct Answer: B","upvote_count":"1","poster":"Anithec0der","timestamp":"1721490960.0"},{"timestamp":"1721311560.0","poster":"Mallikharjuna452","comment_id":"1250440","upvote_count":"1","content":"B.False"},{"content":"Selected Answer: A\nTrue is the answer","poster":"bot314","timestamp":"1718363040.0","upvote_count":"1","comment_id":"1230452"},{"poster":"p22_nilesh","upvote_count":"1","timestamp":"1717432320.0","content":"Selected Answer: A\nYes, it can connect.","comment_id":"1223695"},{"poster":"nexerSnow","timestamp":"1715602080.0","upvote_count":"1","comment_id":"1210845","content":"Selected Answer: B\nb is cott"},{"comment_id":"1208635","timestamp":"1715219160.0","content":"Selected Answer: B\nFalse. Snowflake provides JDBC and ODBC drivers that allow third-party tools supporting these standards to connect to Snowflake. While having Snowflake-specific drivers might offer optimized performance and additional features, standard JDBC or ODBC drivers can still establish a connection to Snowflake.","poster":"JasMozai","upvote_count":"1"},{"upvote_count":"1","timestamp":"1715014860.0","comment_id":"1207460","content":"Selected Answer: B\nB correct","poster":"TheHuman_"},{"comment_id":"1196408","upvote_count":"1","content":"The entire purpose of JDBC or ODBC is to remove the dependency on any specific provider dirvers. And:B","timestamp":"1713249780.0","poster":"havik"},{"upvote_count":"1","comment_id":"1157648","timestamp":"1708753140.0","poster":"DineshDalvi","content":"Selected Answer: A\nStraight Forward question is, third party tools support JDBC/ODBC that has snowflake driver which can connect to snowflake. - \nIt has same meant; third party tool supports JDBC/ODBC that has no snowflake driver that will be unable to connect to snowflake.\nTherefore, answer is True.\nAnswer is A.True"},{"poster":"_yyukta","timestamp":"1708698720.0","content":"Selected Answer: B\nb . false","upvote_count":"1","comment_id":"1157190"},{"upvote_count":"1","comment_id":"1147102","timestamp":"1707643320.0","poster":"Karimo","content":"Selected Answer: B\nB of course"},{"upvote_count":"1","poster":"whiteomax","timestamp":"1706917740.0","content":"This is how I understand the question, if the tool does not come with a snowflake drive, can it be connected to Snowflake? \nI think the answer is YES, \nBecause Snowflake provides the driver, as long as the tool supports JBDC, the snowflake provided driver can connect the tool to Snowflake.\nTo me, it does not make sense if the question is asking: this tool does support JDBC but does not support Snowflake driver, can it still connected to Snowflake?","comment_id":"1138915"},{"poster":"snowman1911","upvote_count":"1","content":"Selected Answer: B\nB is the correct answer as stated by others","timestamp":"1706645400.0","comment_id":"1136126"},{"poster":"Nospamd","content":"Entire purpose of JDBC or ODBC connector is to make it generic. B is correct.","upvote_count":"1","timestamp":"1705602240.0","comment_id":"1126106"},{"poster":"0e504b5","comment_id":"1123799","timestamp":"1705367160.0","content":"Selected Answer: B\nI vote False. As long as you support JDBC or ODBC, you should be able to connect to Snowflake https://docs.snowflake.com/en/developer-guide/drivers","upvote_count":"3"},{"timestamp":"1705289400.0","poster":"sandy91","comment_id":"1123033","content":"Selected Answer: A\nTRUE\nA snowflake driver is required","upvote_count":"1"},{"timestamp":"1696983480.0","poster":"BobFar","upvote_count":"1","content":"Answer is A: true\nNeed snowflake driver to connect \nhttps://www.phdata.io/blog/connecting-to-snowflake-jdbc-odbc-drivers/","comment_id":"1039992"},{"comment_id":"1020348","content":"Selected Answer: A\nLooks like the Snowflake-provided driver is necessary...\n\nhttps://www.snowflake.com/blog/ability-to-connect-to-snowflake-with-jdbc/","poster":"oscarglob","timestamp":"1695952320.0","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: A\nJDBC or ODBC needs snowflake driver to connect snowflake","timestamp":"1692528720.0","comment_id":"985722","poster":"Karthikparasuraman"},{"comment_id":"909083","timestamp":"1685340480.0","upvote_count":"1","content":"Selected Answer: A\ntrue drivers must be snowflake provided","poster":"surya610"},{"upvote_count":"1","timestamp":"1683862500.0","comment_id":"895620","content":"its possible to connect to snowflake in Python using JDBC .Snowflake also provides a native python-snowflake connector.","poster":"Pythonscript"},{"content":"Selected Answer: A\nA is correct","timestamp":"1683789780.0","poster":"Mayuri917233","comment_id":"894705","upvote_count":"1"},{"upvote_count":"1","poster":"shyemko","content":"Selected Answer: A\nA third-party tool that supports standard JDBC or ODBC is not enough, they should have a JDBC driver for Snowflake and ODBC driver for Snowflake","comment_id":"853018","timestamp":"1679993100.0"},{"content":"Selected Answer: A\nTrue is True :)","comment_id":"826912","upvote_count":"4","poster":"ShagunMittal","timestamp":"1677761880.0"},{"poster":"Anu825","timestamp":"1677732480.0","content":"Answer is A True","comment_id":"826502","upvote_count":"2"},{"upvote_count":"3","poster":"c0d3g","timestamp":"1677682920.0","content":"Selected Answer: A\nThe question says - \" but has no Snowflake-specific driver\" that means it cannot connect. It has to be Snowflake-specific JDBC/ODBC. So, answer is A. True","comment_id":"825996"},{"comment_id":"801943","content":"The question is not clear","upvote_count":"4","poster":"KarBiswa","timestamp":"1675856400.0"},{"poster":"joe12","content":"the answer is true because they saying will be unable to connect","upvote_count":"3","timestamp":"1674585420.0","comment_id":"786804"},{"poster":"ajay_1233456","comment_id":"784248","timestamp":"1674388260.0","content":"Answer is B False:","upvote_count":"1"},{"comment_id":"780463","poster":"systematics78","content":"A is the correct Answer - to connect to snowflake you have to use snowflake native drivers","upvote_count":"1","timestamp":"1674078780.0"},{"comment_id":"767234","content":"Selected Answer: A\nTrue, verified","timestamp":"1672975200.0","upvote_count":"2","poster":"Andywu213"},{"content":"False. A third-party tool that supports standard JDBC (Java Database Connectivity) or ODBC (Open Database Connectivity) can be used to connect to Snowflake, as long as the tool is properly configured to connect to Snowflake's database. Snowflake provides JDBC and ODBC drivers that can be used to connect to Snowflake from third-party tools, but it is not necessary to use these drivers in order to connect to Snowflake. Any tool that supports standard JDBC or ODBC and is properly configured to connect to Snowflake's database will be able to connect to Snowflake.","upvote_count":"4","poster":"ExamGuruBhai","timestamp":"1671927840.0","comment_id":"755335"},{"content":"A - You can't connect to Snowflake with standard ODBC/JDBC connectors. Snowflake has it's own ODBC/JDBC drivers (https://docs.snowflake.com/en/user-guide/conns-drivers.html). Of course, you can connect with (for example) Python without any ODBC/JDBC driver, but this is not the question.","timestamp":"1670163480.0","upvote_count":"2","comment_id":"735135","poster":"tinkofee"},{"timestamp":"1660471980.0","comment_id":"646691","poster":"Percy2112","upvote_count":"1","content":"Selected Answer: B\nSnowflake provides JDBC , ODBC etc drivers to connect."},{"timestamp":"1659312720.0","comment_id":"640286","content":"Selected Answer: B\nSnowflake provides JDBC driver","poster":"BobCui","upvote_count":"1"},{"content":"Selected Answer: A\nYou need the drivers, therefore the answer is A - TRUE.","timestamp":"1655907180.0","upvote_count":"2","poster":"BungyTex","comment_id":"620457"},{"timestamp":"1652175240.0","poster":"DK69","comment_id":"599494","upvote_count":"3","content":"So it requires the Snowflake JDBC type 4 driver. So answer is A"},{"timestamp":"1652108820.0","upvote_count":"1","comment_id":"599096","poster":"Graghu","content":"B is the answer"},{"timestamp":"1652088060.0","content":"So answer it TRUE (A). Just ODBC or JDBC is not enough. Need to have the Snowflake driver","comment_id":"598957","poster":"DK69","upvote_count":"3","comments":[{"content":"The tool must be support the ODBC/JDBC connection don't must use his \"internal\" connector. If it support JDBC/ODBC connection, then can use the SF JDBC/ODBC connector to connect to SF.","timestamp":"1673361000.0","comment_id":"771512","upvote_count":"1","poster":"BigDataBB"}]},{"upvote_count":"1","poster":"Anirudh2020","comment_id":"551927","timestamp":"1645370100.0","content":"B is right"},{"upvote_count":"1","poster":"Sid460545","timestamp":"1643570340.0","comment_id":"536425","content":"B, False"},{"poster":"Julien25","timestamp":"1642958280.0","upvote_count":"1","content":"Selected Answer: B\nJDBC and ODBC could be used","comment_id":"530709"},{"timestamp":"1641993000.0","upvote_count":"2","poster":"Fab33","comment_id":"522173","content":"Selected Answer: B\nB should be correct."},{"comment_id":"520945","content":"B should be correct.","upvote_count":"2","timestamp":"1641827640.0","poster":"Zafar202"}],"answer_ET":"B","choices":{"A":"True","B":"False"},"question_text":"True or False: A third-party tool that supports standard JDBC or ODBC but has no Snowflake-specific driver will be unable to connect to Snowflake.","answers_community":["B (51%)","A (49%)"],"exam_id":167,"topic":"1","url":"https://www.examtopics.com/discussions/snowflake/view/69364-exam-snowpro-core-topic-1-question-34-discussion/","answer":"B","answer_description":"","question_images":[],"question_id":528},{"id":"IV9sqO0RArMbSDnQ7SHO","question_images":[],"answer_images":[],"answers_community":["B (100%)"],"exam_id":167,"answer_ET":"B","timestamp":"2022-12-13 15:07:00","discussion":[{"upvote_count":"1","comment_id":"957775","content":"Selected Answer: B\ncorrect","timestamp":"1721490360.0","poster":"MultiCloudIronMan"},{"content":"Selected Answer: B\nhttps://docs.snowflake.com/en/user-guide/views-secure#determining-if-a-view-is-secure","upvote_count":"2","timestamp":"1710188580.0","comment_id":"836478","poster":"examed11"},{"upvote_count":"4","poster":"halol","timestamp":"1702476420.0","comment_id":"744108","content":"Answer is correct"}],"topic":"1","answer":"B","isMC":true,"question_text":"For non-materialized views, what column in Information Schema and Account Usage identifies whether a view is secure or not?","choices":{"B":"IS_SECURE","D":"TABLE_NAME","A":"CHECK_OPTION","C":"IS_UPDATEABLE"},"unix_timestamp":1670940420,"answer_description":"","question_id":529,"url":"https://www.examtopics.com/discussions/snowflake/view/91437-exam-snowpro-core-topic-1-question-340-discussion/"},{"id":"SnjSRQXyx62OhvhV5me9","answer_ET":"C","timestamp":"2022-12-09 19:25:00","answer_description":"","question_id":530,"topic":"1","answer_images":[],"choices":{"B":"In the metadata of the pipe for 14 days","C":"In the metadata of the target table for 64 days","A":"In the metadata of the target table for 14 days","D":"In the metadata of the pipe for 64 days"},"question_images":[],"discussion":[{"timestamp":"1702146300.0","content":"Correct Answer : C\nhttps://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro.html#load-history","upvote_count":"22","poster":"harshagc180","comment_id":"740344"},{"poster":"fahfouhi94","content":"Selected Answer: C\ndata bulk load history ===> in the metadata of the target table for 64 days\nsnowpipe ====> in the metadata of the pipe for 14 days","timestamp":"1707207300.0","upvote_count":"10","comment_id":"799522"},{"timestamp":"1743332160.0","poster":"PrasantSadangi","content":"Selected Answer: C\nLoad history\n\nBulk data load\nStored in the metadata of the target table for 64 days. Available upon completion of the COPY statement as the statement output.\n\nSnowpipe\nStored in the metadata of the pipe for 14 days. Must be requested from Snowflake via a REST endpoint, SQL table function, or ACCOUNT_USAGE view.","upvote_count":"1","comment_id":"1412000"},{"timestamp":"1726746120.0","upvote_count":"1","comment_id":"1011241","content":"1. The load history for Snowpipe operations is stored in the metadata of the pipe object , it remains for 14 days. When a pipe is recreatedthe load history is dropped","poster":"Amitsnowflake"},{"content":"Selected Answer: C\nLoad history is stored in the metadata of the target table for 64 days","comment_id":"985380","timestamp":"1724093280.0","upvote_count":"1","poster":"singhks"},{"content":"For Snowpipe use copy_history. and for table LOAD_History, both have 14day hisotry\nhttps://docs.snowflake.com/en/sql-reference/functions/copy_history.html\nhttps://docs.snowflake.com/en/sql-reference/info-schema/load_history.html","timestamp":"1707753780.0","comment_id":"806520","poster":"SA_206","upvote_count":"4"},{"poster":"BigDataBB","upvote_count":"1","comment_id":"780124","content":"Selected Answer: C\nhttps://docs.snowflake.com/en/user-guide/data-load-considerations-load.html#load-metadata\n\nSnowflake maintains detailed metadata for each table into which data is loaded \n....\nThis load metadata expires after 64 days. If the LAST_MODIFIED date for a staged data file is less than or equal to 64 days, the COPY command can determine its load status for a given table and prevent reloading (and data duplication).","timestamp":"1705590660.0"},{"content":"Selected Answer: C\nIt is C","upvote_count":"2","poster":"sakis213","comment_id":"762343","timestamp":"1703975760.0"},{"comment_id":"760757","comments":[{"comment_id":"760759","timestamp":"1703836980.0","upvote_count":"3","content":"Sorry the answer is C.","poster":"SV1122"}],"timestamp":"1703836980.0","upvote_count":"2","content":"Selected Answer: D\nBulk data load\nStored in the metadata of the target table for 64 days. Available upon completion of the COPY statement as the statement output.\n\nhttps://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro.html#load-history","poster":"SV1122"},{"poster":"Naveen90","comment_id":"760659","timestamp":"1703831340.0","content":"I think, since it is Bulk loading. Answer is A","upvote_count":"2"},{"upvote_count":"4","content":"Selected Answer: A\nA CORRET : https://docs.snowflake.com/en/sql-reference/info-schema/load_history.html","comments":[{"comment_id":"924265","poster":"Def21","timestamp":"1718460660.0","content":"This refers to Information schema view. A talks about \"metadata of the target table\" so this is not correct. \n\nThe information in target table metadata is retained for 64 days\nhttps://docs.snowflake.com/en/user-guide/data-load-considerations-load#load-metadata\n\nSo, C is correct","upvote_count":"1"}],"comment_id":"748775","timestamp":"1702897980.0","poster":"halol"}],"isMC":true,"exam_id":167,"question_text":"The bulk data load history that is available upon completion of the COPY statement is stored where and for how long?","answers_community":["C (71%)","A (19%)","10%"],"answer":"C","unix_timestamp":1670610300,"url":"https://www.examtopics.com/discussions/snowflake/view/90834-exam-snowpro-core-topic-1-question-341-discussion/"}],"exam":{"lastUpdated":"12 Apr 2025","isMCOnly":true,"id":167,"name":"SnowPro Core","numberOfQuestions":1259,"provider":"Snowflake","isImplemented":true,"isBeta":false},"currentPage":106},"__N_SSP":true}