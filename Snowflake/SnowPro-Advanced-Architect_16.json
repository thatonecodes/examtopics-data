{"pageProps":{"questions":[{"id":"hJWwXDThu2PlCEASqw7F","answer_ET":"D","topic":"1","question_id":76,"unix_timestamp":1709833080,"discussion":[{"poster":"Soumak","comment_id":"1343336","content":"Selected Answer: D\nvalidated","timestamp":"1737349080.0","upvote_count":"2"},{"upvote_count":"3","content":"D is right\nhttps://docs.snowflake.com/en/user-guide/override_share_restrictions","poster":"swe12","timestamp":"1725723480.0","comment_id":"1168232"}],"url":"https://www.examtopics.com/discussions/snowflake/view/135441-exam-snowpro-advanced-architect-topic-1-question-69/","isMC":true,"answer":"D","question_text":"Is it possible for a data provider account with a Snowflake Business Critical edition to share data with an Enterprise edition data consumer account?","question_images":[],"exam_id":165,"timestamp":"2024-03-07 18:38:00","choices":{"B":"If a user in the provider account with role authority to CREATE or ALTER SHARE adds an Enterprise account as a consumer, it can import the share.","A":"A Business Critical account cannot be a data sharing provider to an Enterprise consumer. Any consumer accounts must also be Business Critical.","D":"If a user in the provider account with a share owning role which also has OVERRIDE SHARE RESTRICTIONS privilege SHARE_RESTRICTIONS set to False when adding an Enterprise consumer account, it can import the share.","C":"If a user in the provider account with a share owning role sets SHARE_RESTRICTIONS to False when adding an Enterprise consumer account, it can import the share."},"answers_community":["D (100%)"],"answer_images":[],"answer_description":""},{"id":"mnVT5NZ3Xgy4SMO7eLKq","question_id":77,"question_images":[],"answers_community":["B (67%)","D (33%)"],"question_text":"How can an Architect enable optimal clustering to enhance performance for different access paths on a given table?","answer_images":[],"unix_timestamp":1685373420,"answer_ET":"B","topic":"1","exam_id":165,"discussion":[{"timestamp":"1738540320.0","content":"Selected Answer: B\nCreating multiple materialized views with different cluster keys allows you to optimize for various access paths by distributing the data in ways that best suit each specific query pattern. This approach can significantly improve query performance as each materialized view can be tailored to different use cases, providing efficient access and faster retrieval times for specific queries.","comment_id":"1350703","upvote_count":"2","poster":"Yogendra_examtopic"},{"comment_id":"1342196","poster":"Balakt","timestamp":"1737125220.0","upvote_count":"1","content":"Selected Answer: D\nD is correct"},{"upvote_count":"1","content":"B\n\nTHE PROBLEM: MULTIPLE ACCESS PATHS\nTHE SOLUTION: CLUSTERED MATERIALIZED VIEW","poster":"Makabaka","timestamp":"1730993460.0","comment_id":"1064943"},{"timestamp":"1720177620.0","comment_id":"943620","upvote_count":"2","poster":"hillcat111","content":"Answer is B and is validated"},{"timestamp":"1717936200.0","comment_id":"919304","content":"i think its D","upvote_count":"1","poster":"hillcat111"},{"poster":"Indraneil2","comment_id":"909506","upvote_count":"4","content":"Creating the materialized view with Snowflake allows you to specify the new clustering key, which enables Snowflake to reorganize the data during the initial creation of the materialized view.","timestamp":"1716995820.0"}],"isMC":true,"url":"https://www.examtopics.com/discussions/snowflake/view/110493-exam-snowpro-advanced-architect-topic-1-question-7/","answer":"B","answer_description":"","timestamp":"2023-05-29 17:17:00","choices":{"D":"Create a clustering key that contains all columns used in the access paths.","C":"Create super projections that will automatically create clustering.","A":"Create multiple clustering keys for a table.","B":"Create multiple materialized views with different cluster keys."}},{"id":"4dpfgHG3TXbZ5MVFfq15","isMC":true,"question_id":78,"answer_images":[],"exam_id":165,"timestamp":"2024-05-09 21:53:00","url":"https://www.examtopics.com/discussions/snowflake/view/140240-exam-snowpro-advanced-architect-topic-1-question-70/","answers_community":["C (100%)"],"topic":"1","answer":"C","unix_timestamp":1715284380,"choices":{"B":"Snowflake streams","D":"Spark","C":"Snowpipe","A":"Snowflake Connector for Kafka"},"answer_description":"","question_images":[],"discussion":[{"comment_id":"1343338","content":"Selected Answer: C\nsnowpipe looks to be the correct answer as it can easily integrate with SQS for streaming data ingestion.","poster":"Soumak","timestamp":"1737349200.0","upvote_count":"2"},{"upvote_count":"2","timestamp":"1735402020.0","poster":"ukpino","comment_id":"1333040","content":"Selected Answer: C\nI would go C.\nAutomating Snowpipe using cloud messaging\n\nAutomated data loads leverage event notifications for cloud storage to inform Snowpipe of the arrival of new data files to load. Snowpipe polls the event notifications from a queue.\nhttps://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro"},{"content":"A, Kafka is the messaging service so I would use the Snowflake Connector for Kafka","comment_id":"1254346","timestamp":"1721819580.0","upvote_count":"1","poster":"isadd_"},{"upvote_count":"1","timestamp":"1715284380.0","poster":"DBSS","comment_id":"1209067","content":"C \nAutomating Snowpipe using Amazon SQS notifications works well\nhttps://docs.snowflake.com/en/user-guide/data-load-snowpipe-auto-s3"}],"answer_ET":"C","question_text":"Which of the following ingestion methods can be used to load near real-time data by using the messaging services provided by a cloud provider?"},{"id":"MtJGjoxKb76gGp4vOsrU","timestamp":"2024-07-24 13:17:00","url":"https://www.examtopics.com/discussions/snowflake/view/144481-exam-snowpro-advanced-architect-topic-1-question-71/","answers_community":["B (100%)"],"isMC":true,"question_id":79,"topic":"1","discussion":[{"upvote_count":"1","comment_id":"1386935","content":"Selected Answer: B\nSnowSQL is Snowflake's command-line client. The GET command is specifically designed to download files from Snowflake internal stages to a local file system.","timestamp":"1741637640.0","poster":"ywan1600"},{"content":"B, Snowsight would require to manually download the file each time and the other two options would increase the operational overhead","timestamp":"1721819820.0","comment_id":"1254351","poster":"isadd_","upvote_count":"1"}],"answer_ET":"B","answer_description":"","question_images":[],"exam_id":165,"unix_timestamp":1721819820,"choices":{"A":"Use the Snowflake Connector for Python, connect to remote storage and download the file.","B":"Use the GET command in SnowSQL to retrieve the file.","D":"Use the Snowflake API endpoint and download the file.","C":"Use the GET command in Snowsight to retrieve the file."},"answer":"B","answer_images":[],"question_text":"An Architect is designing a file ingestion recovery solution. The project will use an internal named stage for file storage. Currently, in the case of an ingestion failure, the Operations team must manually download the failed file and check for errors.\n\nWhich downloading method should the Architect recommend that requires the LEAST amount of operational overhead?"},{"id":"cL9dPJhCndevhvCQV7JK","choices":{"A":"IOT_timestamp","B":"City and DeviceManufacturer","D":"UniqueId","C":"DeviceId and CustomerId"},"url":"https://www.examtopics.com/discussions/snowflake/view/140654-exam-snowpro-advanced-architect-topic-1-question-72/","answers_community":["C (100%)"],"answer_images":[],"exam_id":165,"topic":"1","timestamp":"2024-05-14 17:59:00","answer_description":"","answer":"C","discussion":[{"poster":"Soumak","upvote_count":"2","timestamp":"1737349860.0","comment_id":"1343341","content":"Selected Answer: C\nmedium cardinal columns, timestamp will have very high cardinality"},{"content":"Should be C:\nhttps://docs.snowflake.com/en/user-guide/tables-clustering-keys","comment_id":"1211545","upvote_count":"2","poster":"cui_li","timestamp":"1731607140.0"}],"isMC":true,"answer_ET":"C","question_id":80,"unix_timestamp":1715702340,"question_text":"A table for IOT devices that measures water usage is created. The table quickly becomes large and contains more than 2 billion rows.\n\n//IMG//\n\n\nThe general query patterns for the table are:\n\n1. DeviceId, IOT_timestamp and CustomerId are frequently used in the filter predicate for the select statement\n2. The columns City and DeviceManufacturer are often retrieved\n3. There is often a count on UniqueId\n\nWhich field(s) should be used for the clustering key?","question_images":["https://img.examtopics.com/snowpro-advanced-architect/image6.png"]}],"exam":{"provider":"Snowflake","lastUpdated":"12 Apr 2025","isMCOnly":true,"numberOfQuestions":109,"isBeta":false,"isImplemented":true,"id":165,"name":"SnowPro Advanced Architect"},"currentPage":16},"__N_SSP":true}