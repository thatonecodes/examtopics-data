{"pageProps":{"questions":[{"id":"rNSCkWKb2NvTHYejbPri","isMC":true,"question_id":26,"url":"https://www.examtopics.com/discussions/snowflake/view/106552-exam-snowpro-advanced-architect-topic-1-question-23/","answer_description":"","question_images":[],"choices":{"D":"1. In the Production account, create an external function that connects into the QA account and returns all the data for one specific table\n2. Run the external function as part of a stored procedure that loops through each table in the Production account and populates each table in the QA account","B":"1. Create a stage in the Production account\n2. Create a stage in the QA account that points to the same external object-storage location\n3. Create a task that runs nightly to unload each table in the Production account into the stage\n4. Use Snowpipe to populate the QA account","C":"1. Enable replication for each database in the Production account\n2. Create replica databases in the QA account\n3. Create clones of the replica databases on a nightly basis\n4. Run tests directly on those cloned databases","A":"1. Create a share in the Production account for each database\n2. Share access to the QA account as a Consumer\n3. The QA account creates a database directly from each share\n4. Create clones of those databases on a nightly basis\n5. Run tests directly on those cloned databases"},"topic":"1","answer":"C","exam_id":165,"question_text":"An Architect has chosen to separate their Snowflake Production and QA environments using two separate Snowflake accounts.\nThe QA account is intended to run and test changes on data and database objects before pushing those changes to the Production account. It is a requirement that all database objects and data in the QA account need to be an exact copy of the database objects, including privileges and data in the Production account on at least a nightly basis.\nWhich is the LEAST complex approach to use to populate the QA account with the Production account’s data and database objects on a nightly basis?","answers_community":["C (100%)"],"timestamp":"2023-04-18 09:55:00","discussion":[{"timestamp":"1738891740.0","content":"Selected Answer: C\nIt's simple \nQuestion needs same privileges as of production\nShare dosnt provide it but replication provide it \nSo easiest way is replicate not share","comment_id":"1352738","upvote_count":"1","poster":"Yogendra_examtopic"},{"timestamp":"1737815340.0","content":"Selected Answer: C\nLots of issues and gaps in question & options provided. There is no mention of region for prod and dev account, which dictates the choice between Share & replication.","upvote_count":"1","comment_id":"1346494","poster":"nareeshk"},{"upvote_count":"1","content":"Selected Answer: C\nBut it is not \"shared\", is \"replicated\". And we can create a clone from a replicated database. It's C","timestamp":"1720703700.0","comment_id":"1246136","poster":"NachoPrendes"},{"upvote_count":"1","content":"The least complex approach among the options provided is likely option B.\nThis approach involves setting up a shared stage between the Production and QA accounts and utilizing Snowpipe for data ingestion. Snowpipe can automatically load data from the stage into the QA environment, simplifying the process and reducing the need for manual intervention. Additionally, unloading data from the Production account into a stage is a straightforward task, and Snowpipe's automated data loading capabilities streamline the process further.","poster":"rkarthik0789","timestamp":"1716776100.0","comment_id":"1219272"},{"timestamp":"1699515780.0","content":"Share database cannot be cloned. therefore A is wrong, C is correct","upvote_count":"2","poster":"anikl","comment_id":"1066221"},{"poster":"hillcat111","upvote_count":"1","timestamp":"1688555940.0","content":"Answer is C and is validated","comment_id":"943647"},{"timestamp":"1685306820.0","poster":"victorleonis","upvote_count":"2","comment_id":"908865","content":"Selected Answer: C\nAns C is incorrect. We can clone a shared object."},{"upvote_count":"2","poster":"Dhamod","timestamp":"1684844340.0","comment_id":"904882","content":"https://community.snowflake.com/s/article/Snowflake-DTAP-Environment-Setup\nAns: C"},{"upvote_count":"4","comment_id":"873398","poster":"callipso21","content":"Selected Answer: C\nhttps://community.snowflake.com/s/article/How-to-Copy-a-Database-from-One-account-to-Another","timestamp":"1681804500.0"}],"unix_timestamp":1681804500,"answer_images":[],"answer_ET":"C"},{"id":"YX219kiJzYmgmXqMW3Kv","answer_images":[],"question_images":[],"question_id":27,"answer_description":"","isMC":true,"exam_id":165,"answer_ET":"C","timestamp":"2023-04-15 22:25:00","unix_timestamp":1681590300,"answers_community":["C (100%)"],"answer":"C","discussion":[{"comment_id":"1208403","content":"Selected Answer: C\nC for sure","timestamp":"1731080640.0","poster":"DBSS","upvote_count":"1"},{"comment_id":"943648","timestamp":"1704460740.0","poster":"hillcat111","upvote_count":"2","content":"Answer is C and is validated"},{"comment_id":"877560","upvote_count":"2","content":"Selected Answer: C\nshould be C","poster":"Jay_98_11","timestamp":"1698001020.0"},{"upvote_count":"3","comment_id":"873401","poster":"callipso21","content":"Selected Answer: C\nObject Parameters¶\nObject parameters can be set at the following levels:\n\nAccount\nAccount administrators can use the ALTER ACCOUNT command to set object parameters for the account. The values set for the account default to the objects created in the account.\n\nObject\nUsers with the appropriate privileges can use the corresponding CREATE <object> or ALTER <object> commands to override object parameters for an individual object.","timestamp":"1697616360.0"},{"content":"Selected Answer: C\nhttps://docs.snowflake.com/en/sql-reference/parameters#object-parameters","timestamp":"1697401500.0","comment_id":"871268","upvote_count":"4","poster":"serg_khar"}],"topic":"1","question_text":"A user can change object parameters using which of the following roles?","url":"https://www.examtopics.com/discussions/snowflake/view/106304-exam-snowpro-advanced-architect-topic-1-question-24/","choices":{"B":"SYSADMIN, SECURITYADMIN","D":"SECURITYADMIN, USER with PRIVILEGE","C":"ACCOUNTADMIN, USER with PRIVILEGE","A":"ACCOUNTADMIN, SECURITYADMIN"}},{"id":"AxQFnKm5ZdBFE2ozvZrY","answer_description":"","question_text":"A media company needs a data pipeline that will ingest customer review data into a Snowflake table, and apply some transformations. The company also needs to use Amazon Comprehend to do sentiment analysis and make the de-identified final data set available publicly for advertising companies who use different cloud providers in different regions.\nThe data pipeline needs to run continuously ang efficiently as new records arrive in the object storage leveraging event notifications. Also, the operational complexity, maintenance of the infrastructure, including platform upgrades and security, and the development effort should be minimal.\nWhich design will meet these requirements?","question_images":[],"answer_ET":"B","question_id":28,"isMC":true,"url":"https://www.examtopics.com/discussions/snowflake/view/109860-exam-snowpro-advanced-architect-topic-1-question-25/","unix_timestamp":1684699200,"timestamp":"2023-05-21 22:00:00","answer":"B","answer_images":[],"topic":"1","answers_community":["B (100%)"],"choices":{"D":"Ingest the data using Snowpipe and use streams and tasks to orchestrate transformations. Export the data into Amazon S3 to do model inference with Amazon Comprehend and ingest the data back into a Snowflake table. Then create a listing in the Snowflake Marketplace to make the data available to other companies.","A":"Ingest the data using COPY INTO and use streams and tasks to orchestrate transformations. Export the data into Amazon S3 to do model inference with Amazon Comprehend and ingest the data back into a Snowflake table. Then create a listing in the Snowflake Marketplace to make the data available to other companies.","C":"Ingest the data into Snowflake using Amazon EMR and PySpark using the Snowflake Spark connector. Apply transformations using another Spark job. Develop a python program to do model inference by leveraging the Amazon Comprehend text analysis API. Then write the results to a Snowflake table and create a listing in the Snowflake Marketplace to make the data available to other companies.","B":"Ingest the data using Snowpipe and use streams and tasks to orchestrate transformations. Create an external function to do model inference with Amazon Comprehend and write the final records to a Snowflake table. Then create a listing in the Snowflake Marketplace to make the data available to other companies."},"exam_id":165,"discussion":[{"upvote_count":"2","content":"Answer is B and is validated","timestamp":"1720178640.0","poster":"hillcat111","comment_id":"943652"},{"timestamp":"1716321600.0","poster":"HighBMI","upvote_count":"1","comment_id":"903522","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/apn/using-amazon-comprehend-medical-with-the-snowflake-data-cloud/"}]},{"id":"FT5cJdTjsFFfptWakFok","answer_images":[],"choices":{"C":"Create an object for each tenant strategy if row level security is not viable for isolating tenants.","B":"Create an object for each tenant strategy if row level security is viable for isolating tenants.","A":"Create accounts for each tenant in the Snowflake organization.","D":"Create a multi-tenant table strategy if row level security is not viable for isolating tenants."},"question_id":29,"question_images":[],"isMC":true,"discussion":[{"timestamp":"1730306940.0","comments":[{"poster":"IndunaZulu","timestamp":"1739306400.0","upvote_count":"1","content":"The question states RBAC is viable, Roles are under the account","comment_id":"1355164"}],"upvote_count":"1","content":"Answer \"A\", according to these two points from this link. \n• Isolates tenants, thereby reducing the risk of mismanaging security.\n• Allows for strict security measures (encryption keys, IP allow lists, better-than-RBAC controls) by isolating tenants by account.","poster":"MSIDDIQUI18","comment_id":"1305076"},{"timestamp":"1713445080.0","content":"Why not A?\n\nThis approach utilizes separate Snowflake accounts for each tenant, ensuring the highest level of isolation as required by strong legal rules, while still allowing multi-tenancy within the broader organizational context. Each tenant's data and processes remain fully isolated in their dedicated account, aligned with stringent compliance needs.","poster":"SilversRayleigh","comment_id":"1197940","upvote_count":"2"},{"comment_id":"985261","poster":"mrango","content":"Selected Answer: C\nAnswer c","upvote_count":"2","timestamp":"1692455340.0"},{"comment_id":"943653","timestamp":"1688556240.0","poster":"hillcat111","comments":[{"comment_id":"1346804","poster":"Soumak","comments":[{"comment_id":"1373407","upvote_count":"1","content":"You can use a single object for multiple tenants if row-level security is viable.","timestamp":"1741551660.0","poster":"ywan1600"}],"timestamp":"1737869520.0","content":"but why not B, as the question says that isolating the tenants is a viable option.","upvote_count":"1"}],"content":"Answer is C and is validated","upvote_count":"2"},{"content":"C https://resources.snowflake.com/white-paper/design-patterns-for-building-multi-tenant-applications-on-snowflake","upvote_count":"1","poster":"Alachramkowa","timestamp":"1682782080.0","comment_id":"884441"}],"unix_timestamp":1682782080,"answers_community":["C (100%)"],"topic":"1","question_text":"A Snowflake Architect is designing an application and tenancy strategy for an organization where strong legal isolation rules as well as multi-tenancy are requirements.\nWhich approach will meet these requirements if Role-Based Access Policies (RBAC) is a viable option for isolating tenants?","answer":"C","exam_id":165,"answer_description":"","url":"https://www.examtopics.com/discussions/snowflake/view/107886-exam-snowpro-advanced-architect-topic-1-question-26/","timestamp":"2023-04-29 17:28:00","answer_ET":"B"},{"id":"dFzQ1gbrGMpBCXH2aroA","answer":"BD","answer_ET":"BD","url":"https://www.examtopics.com/discussions/snowflake/view/105539-exam-snowpro-advanced-architect-topic-1-question-27/","answer_description":"","unix_timestamp":1680894840,"answers_community":["BD (100%)"],"question_text":"Which statements describe characteristics of the use of materialized views in Snowflake? (Choose two.)","topic":"1","question_images":[],"isMC":true,"choices":{"B":"They cannot include nested subqueries.","C":"They can include context functions, such as CURRENT_TIME().","E":"They can support inner joins, but not outer joins.","D":"They can support MIN and MAX aggregates.","A":"They can include ORDER BY clauses."},"discussion":[{"content":"Answer is B,D and is validated","upvote_count":"1","timestamp":"1720178640.0","comment_id":"943654","poster":"hillcat111"},{"poster":"ManojRaghuwanshi","content":"Selected Answer: BD\nTime functions are non deterministic","comment_id":"912911","upvote_count":"1","timestamp":"1717341900.0"},{"poster":"victorleonis","timestamp":"1716930360.0","content":"Selected Answer: BD\nhttps://docs.snowflake.com/en/user-guide/views-materialized","comment_id":"908874","upvote_count":"2"},{"content":"Selected Answer: BD\nhttps://docs.snowflake.com/en/user-guide/views-materialized#limitations-on-creating-materialized-views\n* The aggregate functions that are supported in materialized views are: MIN/MAX\n* Functions used in a materialized view must be deterministic. For example, using CURRENT_TIME or CURRENT_TIMESTAMP is not permitted.","timestamp":"1712517240.0","comment_id":"864189","poster":"serg_khar","upvote_count":"1"}],"answer_images":[],"exam_id":165,"question_id":30,"timestamp":"2023-04-07 21:14:00"}],"exam":{"numberOfQuestions":109,"isBeta":false,"id":165,"lastUpdated":"12 Apr 2025","provider":"Snowflake","name":"SnowPro Advanced Architect","isMCOnly":true,"isImplemented":true},"currentPage":6},"__N_SSP":true}