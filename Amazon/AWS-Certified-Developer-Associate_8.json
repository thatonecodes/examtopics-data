{"pageProps":{"questions":[{"id":"smg8PxunCSt2sxiSFFDt","exam_id":25,"url":"https://www.examtopics.com/discussions/amazon/view/82927-exam-aws-certified-developer-associate-topic-1-question-130/","choices":{"B":"The resource-based policy for the Lambda function does not have the required permissions to be invoked by Amazon S3.","A":"The S3 event notification does not activate for files that are larger than 1,000 MB.","D":"The S3 bucket needs to be made public.","C":"Lambda functions cannot be invoked directly from an S3 event."},"question_text":"A developer has created an AWS Lambda function to provide notification through Amazon Simple Notification Service (Amazon SNS) whenever a file is uploaded to Amazon S3 that is larger than 50 MB. The developer has deployed and tested the Lambda function by using the CLI. However, when the event notification is added to the S3 bucket and a 3,000 MB file is uploaded, the Lambda function does not launch.\nWhich of the following is a possible reason for the Lambda function's inability to launch?","isMC":true,"answer_images":[],"question_images":[],"topic":"1","unix_timestamp":1663677060,"answer":"B","question_id":36,"timestamp":"2022-09-20 14:31:00","answer_ET":"B","answers_community":["B (100%)"],"discussion":[{"comment_id":"674146","content":"Selected Answer: B\nAnswer is B\nA. No such limits \nB. Yes, resource based policies allows principals to assume it. \nC. S3 has direct integration with lambda\nD. definitely not a secure choice","timestamp":"1663677060.0","poster":"colintkn","upvote_count":"10"},{"poster":"Reyyy1234","content":"Lambda function does not have resource based policy so why B is correct here ?","timestamp":"1686567060.0","upvote_count":"2","comment_id":"921351"},{"content":"B it is","upvote_count":"1","comment_id":"774852","timestamp":"1673643900.0","poster":"sichilam"},{"timestamp":"1669989240.0","comments":[{"content":"maybe the developer tested the lambda only, using \"aws lambda invoke\" with custom event payload. but the s3-lambda integration was not tested.","poster":"qiaoli","timestamp":"1680088800.0","comment_id":"854322","upvote_count":"2"}],"poster":"gpit","upvote_count":"2","content":"If B, why it's good in CLI test, as it implies?","comment_id":"733784"},{"poster":"dark_cherrymon","upvote_count":"2","comment_id":"721540","content":"Selected Answer: B\nB, the other ones didn't make any sense","timestamp":"1668801120.0"},{"comment_id":"695229","poster":"cloud_collector","timestamp":"1665815580.0","upvote_count":"2","content":"Selected Answer: B\nRule out A & D at first.\nC: Amazon S3 can send an event to a Lambda function when an object is created or deleted.\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-s3.html"}],"answer_description":""},{"id":"oTEXELpggXWqmU1tsCfl","timestamp":"2022-09-01 00:14:00","exam_id":25,"answers_community":["B (92%)","8%"],"topic":"1","isMC":true,"discussion":[{"poster":"Chhotu_DBA","comment_id":"655542","upvote_count":"10","timestamp":"1661984040.0","comments":[{"poster":"Spamuel","content":"Agreed - AWS KMS provides auditability, where as s3 does not.","comment_id":"675130","upvote_count":"1","timestamp":"1663763880.0"}],"content":"Selected Answer: B\nit should be B"},{"upvote_count":"8","content":"Selected Answer: B\nServer-Side Encryption with AWS KMS keys (SSE-KMS) is similar to SSE-S3, but with some additional benefits and charges for using this service. There are separate permissions for the use of a KMS key that provides added protection against unauthorized access of your objects in Amazon S3. SSE-KMS also provides you with an audit trail that shows when your KMS key was used and by whom. Additionally, you can create and manage customer managed keys or use AWS managed keys that are unique to you, your service, and your Region. \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/serv-side-encryption.html","comment_id":"693023","timestamp":"1665575460.0","poster":"gary_gary"},{"poster":"SD_CS","content":"Selected Answer: B\nIt clearly states that the Customer does not want to manage the key outside of AWS. Hence going for B, C cannot be correct","timestamp":"1707197940.0","upvote_count":"1","comment_id":"1141795"},{"poster":"AswinDe","comment_id":"959658","timestamp":"1690039740.0","upvote_count":"2","content":"How can it be C? Customer does not want to manager key in out of AWS."},{"poster":"pancman","timestamp":"1677007500.0","upvote_count":"2","comment_id":"817056","content":"Selected Answer: B\nB is the answer due to the rotation and audit requirements. SSE-KMS shows you when your KMS key was used and by whom. This type of records are not kept with S3 managed keys."},{"content":"Selected Answer: B\nSSS-S3 key rotation is not per year, it's random.","poster":"Phinx","timestamp":"1674177840.0","comment_id":"781755","upvote_count":"1","comments":[{"timestamp":"1693226400.0","poster":"ninomfr64","comment_id":"992169","content":"Docs mention this \"Server-side encryption protects data at rest. Amazon S3 encrypts each object with a unique key. As an additional safeguard, it encrypts the key itself with a key that it rotates regularly\". It seems the key is not rotate, instead key used to encrypt it is rotate. Rotation frequency is not mentioned.\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html","upvote_count":"1"}]},{"comment_id":"775521","poster":"sichilam","timestamp":"1673707140.0","upvote_count":"1","content":"I vote for B"},{"content":"Selected Answer: A\nAmazon S3 managed encryption keys can do all requirements.\nThe main advantage of SSE-KMS over SSE-S3 is the additional level of security provided by permissions on the KMS key itself an audit trail that shows when your KMS key was used and by whom. !!\nThere is nothing specified in the description about securing the KMS key or auditing the usage\n\nSure B is better than A but that requires an additional cost. I think the objectif is to choose the better solution with a minimal cost ?\nAnd now","comment_id":"769773","comments":[],"upvote_count":"2","poster":"ayoubmk","timestamp":"1673207280.0"},{"timestamp":"1669946820.0","upvote_count":"1","poster":"hamimelon","comment_id":"733336","content":"B. AWS KMS provides key rotation."},{"content":"Selected Answer: B\ni was thinking A or B, looking at the comments it's B","poster":"dark_cherrymon","timestamp":"1668801240.0","comment_id":"721541","upvote_count":"2"},{"comment_id":"667052","upvote_count":"2","timestamp":"1662990960.0","poster":"szhang2004","content":"B is the answer"}],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/78806-exam-aws-certified-developer-associate-topic-1-question-131/","question_images":[],"answer":"B","answer_description":"","question_id":37,"choices":{"B":"Use server-side encryption with AWS KMS managed encryption keys (SSE-KMS).","C":"Use server-side encryption with customer-provided encryption keys (SSE-C).","A":"Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3).","D":"Use client-side encryption before sending the data to Amazon S3."},"question_text":"A company stores documents in Amazon S3 with default settings. A new regulation requires the company to encrypt the documents at rest, rotate the encryption keys annually, and keep a record of when the encryption keys were rotated. The company does not want to manage the encryption keys outside of AWS.\nWhich solution will meet these requirements?","unix_timestamp":1661984040,"answer_ET":"B"},{"id":"pJeOxAJRQlPEu2NkyYC6","choices":{"C":"Call the ReceiveMessage API to set MaxNumberOfMessages to a value greater than the default of 1.","D":"Call the SetQueueAttributes API for the queue and set MaxNumberOfMessages to a value greater than the default of 1.","B":"Call the AddPermission API to set MaxNumberOfMessages for the ReceiveMessage action to a value greater than the default of 1.","A":"Call the ChangeMessageVisibility API for the queue and set MaxNumberOfMessages to a value greater than the default of 1."},"answer_description":"","isMC":true,"answer_ET":"C","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/28438-exam-aws-certified-developer-associate-topic-1-question-132/","timestamp":"2020-08-13 10:32:00","question_images":[],"question_id":38,"exam_id":25,"question_text":"A developer has discovered that an application responsible for processing messages in an Amazon SQS queue is routinely falling behind. The application is capable of processing multiple messages in one invocation, but is only receiving one message at a time.\nWhat should the developer do to increase the number of messages the application receives?","answer":"C","unix_timestamp":1597307520,"answer_images":[],"answers_community":["C (100%)"],"discussion":[{"content":"C is the answer\n\nOne can change the number of messages received in a queue from 1 to 10 messages ate a time, by calling the ReceiveMessage API","comment_id":"244638","timestamp":"1634808540.0","poster":"RicardoD","upvote_count":"20"},{"poster":"SD_CS","content":"Selected Answer: C\nC is correct","timestamp":"1707198000.0","comment_id":"1141797","upvote_count":"1"},{"poster":"rcaliandro","upvote_count":"1","content":"Selected Answer: C\nC is the correct one. We need to set the parameter \"MaxNumberOfMessages\" to a value greater then 1 and we can do that by using the ReceiveMessage API","timestamp":"1687971180.0","comment_id":"936924"},{"poster":"sichilam","upvote_count":"1","timestamp":"1673707800.0","comment_id":"775537","content":"https://sqs.us-east-2.amazonaws.com/123456789012/MyQueue/\n?Action=ReceiveMessage\n&MaxNumberOfMessages=5\n&VisibilityTimeout=15\n&AttributeName=All\n&Expires=2020-04-18T22%3A52%3A43PST\n&Version=2012-11-05\n&AUTHPARAMS"},{"upvote_count":"1","content":"Selected Answer: C\nANS: C","comment_id":"538311","timestamp":"1643767200.0","poster":"JP_PA"},{"poster":"Chinta","comment_id":"194807","content":"C is correct","timestamp":"1634550000.0","upvote_count":"1"},{"comment_id":"160055","content":"answer: C","upvote_count":"1","poster":"requiem","timestamp":"1634064720.0"},{"content":"C is correct\nUse ReceiveMessage API to retrieve up to 10 messages at a time, from the specified queue.","timestamp":"1633773660.0","poster":"saeidp","upvote_count":"4","comment_id":"157778"},{"upvote_count":"4","content":"C. Call the ReceiveMessage API to set MaxNumberOfMessages to a value greater than the default of 1.\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_ReceiveMessage.html","comment_id":"157131","poster":"WilsonNF","timestamp":"1633504620.0"}]},{"id":"bOyNV5isepEY8UJJ2GGD","choices":{"A":"Create a Kinesis Data Firehose data transformation by using an Amazon EC2 instance.","C":"Configure the Kinesis Data Firehose delivery stream to store data in the DynamoDB table. Export the table to Amazon S3.","B":"Configure the Kinesis Data Firehose delivery stream to send data to a Kinesis data stream. Enrich the data by using an AWS Lambda function.","D":"Create a Kinesis Data Firehose data transformation by using an AWS Lambda function."},"answer_description":"","isMC":true,"answer_ET":"D","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/78807-exam-aws-certified-developer-associate-topic-1-question-133/","timestamp":"2022-09-01 00:16:00","question_images":[],"question_id":39,"exam_id":25,"question_text":"A developer is using an Amazon Kinesis Data Firehose delivery stream to store data in Amazon S3. Before storing the data in Amazon S3, the developer wants to enrich the data by combining the data with data from an Amazon DynamoDB table.\nHow can the developer implement the data enrichment?","answer":"D","unix_timestamp":1661984160,"answer_images":[],"answers_community":["D (88%)","8%"],"discussion":[{"upvote_count":"11","poster":"Danbraga","content":"Selected Answer: D\nI Vote D, diregard first message LOL\nhttps://docs.aws.amazon.com/firehose/latest/dev/data-transformation.html","timestamp":"1662208200.0","comment_id":"658450"},{"poster":"sidvic","comment_id":"659849","content":"Selected Answer: D\ni think D. Is the second scenario from this document\nhttps://aws.amazon.com/it/blogs/big-data/joining-and-enriching-streaming-data-on-amazon-kinesis/","timestamp":"1662362400.0","upvote_count":"5"},{"comment_id":"1141801","content":"Selected Answer: D\nWe can transform messages flowing through firehose using lambda.","upvote_count":"1","poster":"SD_CS","timestamp":"1707198300.0"},{"upvote_count":"1","timestamp":"1693366200.0","poster":"MaxelRozario","comment_id":"993675","content":"We cannot connect the dynamo db directly to the Kinesis fire hose, so we need the Kinesis streams and lambda function to enrich the data."},{"poster":"rcaliandro","content":"Selected Answer: D\nI vote for D, by using Amazon Kinesis Data Firehose to process data before store to DynamoDB","upvote_count":"1","comment_id":"936930","timestamp":"1687971360.0"},{"comment_id":"911338","upvote_count":"2","content":"I would choose B because of this link: \nhttps://aws.amazon.com/es/blogs/big-data/joining-and-enriching-streaming-data-on-amazon-kinesis/","poster":"mgonblan","timestamp":"1685540820.0"},{"upvote_count":"3","poster":"pancman","comments":[{"timestamp":"1678561740.0","comment_id":"836427","content":"Did you do the new exam DVA-C02","poster":"Dun6","upvote_count":"2"}],"content":"This question was on the exam today (Feb 2023)","comment_id":"823169","timestamp":"1677471180.0"},{"poster":"pancman","comment_id":"817096","upvote_count":"1","content":"Selected Answer: D\nD makes sense","timestamp":"1677009420.0"},{"timestamp":"1676721360.0","upvote_count":"2","content":"Selected Answer: D\nIts D.\nFirehose works with lambda for data transformation","poster":"aarti_k","comment_id":"812913"},{"upvote_count":"2","comments":[{"timestamp":"1713452640.0","poster":"Cr4zyd34thg0d","upvote_count":"1","content":"This, The fact it asks for enrichment is why it is B. Either way it requires a Lambda function vote for B.","comment_id":"1197989"}],"poster":"sichilam","timestamp":"1673708160.0","comment_id":"775546","content":"Difference here: \nEnrich: more data \nTransform: same data but different form\nVoted for B"},{"timestamp":"1673560920.0","poster":"whenthan","content":"D \nKinesis Data Firehose can invoke your Lambda function to transform incoming source data and deliver the transformed data to destinations. You can enable Kinesis Data Firehose data transformation when you create your delivery stream.","comment_id":"773923","upvote_count":"1"},{"comment_id":"693310","timestamp":"1665598500.0","content":"Selected Answer: B\nThe wording may be wrong as it sounds like the lambda is not invoked between the two streams, but having two streams is mandatory. D is written like it is a single stream which will not work.","upvote_count":"1","poster":"tbhtp","comments":[{"poster":"tbhtp","upvote_count":"3","timestamp":"1665598620.0","comment_id":"693312","content":"I am wrong. Did not read the question right. D is correct"}]},{"poster":"szhang2004","content":"D is correct.","timestamp":"1662991200.0","comment_id":"667062","upvote_count":"1"},{"content":"Selected Answer: C\nI vote C\nhttps://docs.aws.amazon.com/firehose/latest/dev/data-transformation.html","comment_id":"658448","timestamp":"1662208140.0","upvote_count":"1","poster":"Danbraga"},{"upvote_count":"3","timestamp":"1662199200.0","poster":"JOL86","content":"Answer is D I think. Kinesis firehose has the ability to add a lambda transformation. Kinesis Data Streams doesn't have this","comment_id":"658308"},{"upvote_count":"1","timestamp":"1661984160.0","content":"Selected Answer: B\nB is correct","comment_id":"655543","poster":"Chhotu_DBA"}]},{"id":"WDBvi4Cy3WgQqlu1mn6R","answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/78839-exam-aws-certified-developer-associate-topic-1-question-134/","isMC":true,"topic":"1","question_id":40,"timestamp":"2022-09-01 02:15:00","answer_ET":"B","choices":{"B":"Create a new SQS queue. Set the new queue as a dead-letter queue for the application queue. Configure the Maximum Receives setting.","D":"Configure an Amazon CloudWatch alarm for Lambda function errors. Publish messages to an Amazon Simple Notification Service (Amazon SNS) topic to notify administrator users.","A":"Configure Amazon CloudWatch Logs to save the error messages to a separate log stream.","C":"Change the SQS queue to a FIFO queue. Configure the message retention period to 0 seconds."},"discussion":[{"content":"Selected Answer: B\nI think its B","timestamp":"1661991300.0","upvote_count":"6","poster":"Chhotu_DBA","comment_id":"655615"},{"timestamp":"1707198360.0","content":"Selected Answer: B\nB is the most logical option","poster":"SD_CS","comment_id":"1141802","upvote_count":"1"},{"content":"How can it be C? Is answer correct? I am not sure, please correct it for confusion","upvote_count":"1","comment_id":"959665","comments":[{"comment_id":"976195","poster":"RaidenKurosaki","content":"Yeah, its definitely B.","timestamp":"1691550420.0","upvote_count":"1"}],"poster":"AswinDe","timestamp":"1690040280.0"},{"upvote_count":"1","poster":"rcaliandro","comment_id":"936933","timestamp":"1687971540.0","content":"Selected Answer: B\nIt is possible to create another SQS Queue to send failed and error messages. This Queue is called DLQ (Dead-Letter-Queue). We can also set the maximum number of messages that can be read from the queue given the issues. For me is B"},{"timestamp":"1682469360.0","poster":"MrTee","content":"B. Create a new SQS queue. Set the new queue as a dead-letter queue for the application queue. Configure the Maximum Receives setting is the MOST operationally efficient solution that meets these requirements.\nBy creating a new SQS queue and setting it as a dead-letter queue for the application queue, messages that cannot be processed successfully by the application will be automatically sent to the dead-letter queue. This allows the application to continue processing other messages in the main queue without being blocked.","comment_id":"880994","upvote_count":"1"},{"poster":"pancman","content":"Selected Answer: B\nB dead-letter queue","timestamp":"1677009480.0","upvote_count":"1","comment_id":"817099"},{"timestamp":"1676584560.0","upvote_count":"2","content":"How can C be a correct answer!!! Are these dumps years old and answers are not updated!!","poster":"Sidhusaab","comment_id":"811136"},{"comment_id":"775558","poster":"sichilam","upvote_count":"1","content":"Dead letter queue for later analysis\nB","timestamp":"1673708700.0"},{"timestamp":"1670555160.0","content":"Selected Answer: B\nThe main keywords here are \"save these messages for further analysis\" so DLQ is always a good option in this kind of question","comment_id":"739697","poster":"aws_leo","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\nIt's B.","timestamp":"1669867800.0","comment_id":"732231","poster":"G4Exams"},{"content":"Selected Answer: B\nDead-letter queues are useful for debugging your application or messaging system because they let you isolate unconsumed messages to determine why their processing doesn't succeed.","timestamp":"1665903840.0","comment_id":"696048","poster":"cloud_collector","upvote_count":"2"},{"poster":"szhang2004","comment_id":"667065","upvote_count":"1","content":"B is the answer","timestamp":"1662991320.0"},{"timestamp":"1662017280.0","content":"B.........","upvote_count":"3","comment_id":"655931","poster":"LEHUY"}],"unix_timestamp":1661991300,"exam_id":25,"question_text":"A company created an application to consume and process data. The application uses Amazon Simple Queue Service (Amazon SQS) and AWS Lambda functions. The application is currently working as expected, but it occasionally receives several messages that it cannot process properly. The company needs to clear these messages to prevent the queue from becoming blocked.\nA developer must implement a solution that makes queue processing always operational. The solution must give the company the ability to defer the messages with errors and save these messages for further analysis.\nWhat is the MOST operationally efficient solution that meets these requirements?","answer_description":"","answers_community":["B (100%)"],"question_images":[],"answer_images":[]}],"exam":{"name":"AWS Certified Developer Associate","numberOfQuestions":443,"isMCOnly":true,"isImplemented":true,"id":25,"provider":"Amazon","isBeta":false,"lastUpdated":"11 Apr 2025"},"currentPage":8},"__N_SSP":true}