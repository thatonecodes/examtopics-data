{"pageProps":{"questions":[{"id":"27O7rpaAjrw89UUQO9i9","timestamp":"2023-08-01 12:45:00","isMC":true,"question_text":"A company wants to direct its users to a backup static error page if the company's primary website is unavailable. The primary website's DNS records are hosted in Amazon Route 53. The domain is pointing to an Application Load Balancer (ALB). The company needs a solution that minimizes changes and infrastructure overhead.\n\nWhich solution will meet these requirements?","question_images":[],"answer_description":"","answer":"B","answer_images":[],"topic":"1","discussion":[{"content":"Selected Answer: B\nSet up a Route 53 active-passive failover configuration. Direct traffic to a static error page that is hosted in an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.","timestamp":"1700206320.0","poster":"TariqKipkemei","upvote_count":"6","comment_id":"1073083"},{"comment_id":"997006","timestamp":"1693673100.0","poster":"ssa03","upvote_count":"5","content":"Selected Answer: B\nB is correct"},{"poster":"Danilus","timestamp":"1731270180.0","upvote_count":"1","comment_id":"1309610","content":"key -minimizes changes and infrastructure overhead\nkey- backup static error page \nOption B is the appropriate solution because it sets up automatic failover to an alternative endpoint (the static error page in S3) when the ALB becomes unavailable. Option D is not viable as it does not implement a true failover mechanism and may continue to direct traffic to an unhealthy ALB."},{"timestamp":"1692641880.0","comments":[{"upvote_count":"6","poster":"Guru4Cloud","content":"Sorry. I mean B","comment_id":"986826","timestamp":"1692641880.0"}],"poster":"Guru4Cloud","comment_id":"986825","content":"Selected Answer: D\nSetting up a Route 53 active-passive failover configuration with the ALB as the primary endpoint and an Amazon S3 static website as the passive endpoint meets the requirements with minimal overhead.\n\nRoute 53 health checks can monitor the ALB health. If the ALB becomes unhealthy, traffic will automatically failover to the S3 static website. This provides automatic failover with minimal configuration changes","upvote_count":"3"},{"content":"B is correct","comment_id":"975126","upvote_count":"3","timestamp":"1691463000.0","poster":"Nirav1112"},{"comment_id":"971128","timestamp":"1691068140.0","upvote_count":"4","poster":"mrsoa","content":"Selected Answer: B\nB seems correct"},{"content":"B is correct..\n\nhttps://repost.aws/knowledge-center/fail-over-s3-r53","upvote_count":"4","comment_id":"968960","timestamp":"1690886700.0","comments":[{"timestamp":"1704927300.0","upvote_count":"2","comment_id":"1119121","content":"Nice link find!","poster":"awsgeek75"}],"poster":"Bmaster"}],"url":"https://www.examtopics.com/discussions/amazon/view/116974-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["B (83%)","D (17%)"],"unix_timestamp":1690886700,"answer_ET":"B","choices":{"A":"Update the Route 53 records to use a latency routing policy. Add a static error page that is hosted in an Amazon S3 bucket to the records so that the traffic is sent to the most responsive endpoints.","C":"Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance that hosts a static error page as endpoints. Configure Route 53 to send requests to the instance only if the health checks fail for the ALB.","D":"Update the Route 53 records to use a multivalue answer routing policy. Create a health check. Direct traffic to the website if the health check passes. Direct traffic to a static error page that is hosted in Amazon S3 if the health check does not pass.","B":"Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page that is hosted in an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy."},"question_id":516,"exam_id":31},{"id":"b4ZtSIPaTceSUInqHsSj","timestamp":"2023-08-01 12:57:00","question_id":517,"unix_timestamp":1690887420,"answers_community":["D (100%)"],"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/116975-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"D","choices":{"D":"Set up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface.","C":"Set up an Amazon EFS file system that connects with the backup applications using the iSCSI interface.","B":"Set up an Amazon EFS file system that connects with the backup applications using the NFS interface.","A":"Set up AWS Storage Gateway to connect with the backup applications using the NFS interface."},"isMC":true,"topic":"1","question_text":"A recent analysis of a company's IT expenses highlights the need to reduce backup costs. The company's chief information officer wants to simplify the on-premises backup infrastructure and reduce costs by eliminating the use of physical backup tapes. The company must preserve the existing investment in the on-premises backup applications and workflows.\n\nWhat should a solutions architect recommend?","answer_images":[],"answer_description":"","question_images":[],"exam_id":31,"discussion":[{"timestamp":"1720645080.0","poster":"awsgeek75","content":"Selected Answer: D\nTape... lol\n\nThe company must preserve it's existing investment so they want to keep using existing applications. This means EFS won't work. and NFS may not be compatible. VTL is the only thing that may be compatible with an application workflow that backups to tapes.\n\nWho the hell comes up with these questions!","upvote_count":"6","comment_id":"1119125"},{"upvote_count":"5","content":"Selected Answer: D\nUse Tape Gateway to replace physical tapes on premises with virtual tapes on AWSâ€”reducing your data storage costs without changing your tape-based backup workflows. Tape Gateway supports all leading backup applications and caches virtual tapes on premises for low-latency data access. It compresses your tape data, encrypts it, and stores it in a virtual tape library in Amazon Simple Storage Service (Amazon S3). From there, you can transfer it to either Amazon S3 Glacier Flexible Retrieval or Amazon S3 Glacier Deep Archive to help minimize your long-term storage costs.\n\nhttps://aws.amazon.com/storagegateway/vtl/#:~:text=Use-,Tape%20Gateway,-to%20replace%20physical","poster":"TariqKipkemei","timestamp":"1715925180.0","comment_id":"1073090"},{"comment_id":"1047711","poster":"Nisarg2121","upvote_count":"4","content":"Selected Answer: D\nTape Gateway is use for attache with app.","timestamp":"1713515700.0"},{"upvote_count":"4","poster":"gouranga45","timestamp":"1712876460.0","content":"Selected Answer: D\nOption says it all","comment_id":"1041212"},{"content":"Selected Answer: D\nTape Gateway enables you to replace using physical tapes on premises with virtual tapes in AWS without changing existing backup workflows. Tape Gateway supports all leading backup applications and caches virtual tapes on premises for low-latency data access. Tape Gateway encrypts data between the gateway and AWS for secure data transfer, and compresses data and transitions virtual tapes between Amazon S3 and Amazon S3 Glacier Flexible Retrieval, or Amazon S3 Glacier Deep Archive, to minimize storage costs.","comment_id":"1040840","upvote_count":"3","timestamp":"1712850720.0","poster":"Po_chih"},{"poster":"ssa03","content":"Selected Answer: D\nhttps://aws.amazon.com/storagegateway/vtl/?nc1=h_ls","comment_id":"997005","timestamp":"1709405100.0","upvote_count":"2"},{"poster":"Guru4Cloud","upvote_count":"2","timestamp":"1708546320.0","content":"Selected Answer: D\nSet up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface.","comment_id":"986819"},{"timestamp":"1706792220.0","upvote_count":"2","comment_id":"968972","poster":"Bmaster","content":"D is correct\n\nhttps://aws.amazon.com/storagegateway/vtl/?nc1=h_ls"}]},{"id":"xfTB7ZhAMwUeD5pk0sH9","topic":"1","choices":{"B":"Use AWS Glue to deliver streaming data to Amazon S3.","C":"Use AWS Lambda to deliver streaming data and store the data to Amazon S3.","D":"Use AWS Database Migration Service (AWS DMS) to deliver streaming data to Amazon S3.","A":"Use Amazon Kinesis Data Firehose to deliver streaming data to Amazon S3."},"question_id":518,"answer":"A","question_text":"A company has data collection sensors at different locations. The data collection sensors stream a high volume of data to the company. The company wants to design a platform on AWS to ingest and process high-volume streaming data. The solution must be scalable and support data collection in near real time. The company must store the data in Amazon S3 for future reporting.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","exam_id":31,"isMC":true,"answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/116976-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"poster":"emakid","timestamp":"1719695160.0","upvote_count":"3","content":"Selected Answer: A\nAmazon Kinesis Data Firehose is a fully managed service for delivering real-time streaming data to destinations such as Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, and Splunk. It requires minimal setup and maintenance, automatically scales to match the throughput of your data, and offers near real-time data delivery with minimal operational overhead.","comment_id":"1239423"},{"comment_id":"1119128","upvote_count":"3","timestamp":"1704927660.0","poster":"awsgeek75","content":"Selected Answer: A\nHigh volume streaming data = Kinesis\nB: Glue is for ETL (to S3 is ok) but not for streaming\nC: Lambda more overhead\nD: Streaming != Data migration"},{"timestamp":"1704123420.0","comment_id":"1111318","upvote_count":"4","content":"Selected Answer: A\nsensor data = Kinesis","poster":"pentium75"},{"content":"Selected Answer: A\nAmazon Kinesis Data Firehose: Capture, transform, and load data streams into AWS data stores (S3) in near real-time.\n\nhttps://aws.amazon.com/pm/kinesis/?gclid=CjwKCAiAu9yqBhBmEiwAHTx5px9z182o0HBEX0BGXU7VeOCOdNpkJMxgbSfvcHlNKN4NHVnbEa0Y1xoCuU0QAvD_BwE&trk=239a97c0-9c5d-42a5-ac65-7381b62f3756&sc_channel=ps&ef_id=CjwKCAiAu9yqBhBmEiwAHTx5px9z182o0HBEX0BGXU7VeOCOdNpkJMxgbSfvcHlNKN4NHVnbEa0Y1xoCuU0QAvD_BwE:G:s&s_kwcid=AL!4422!3!651612444428!e!!g!!kinesis%20firehose!19836376048!149982297311#:~:text=Kinesis%20Data%20Firehose-,Capture%2C,-transform%2C%20and%20load","comment_id":"1073093","poster":"TariqKipkemei","upvote_count":"3","timestamp":"1700208240.0"},{"content":"Selected Answer: A\nA for sure","upvote_count":"3","comment_id":"1063970","timestamp":"1699283640.0","poster":"potomac"},{"comment_id":"997007","poster":"ssa03","timestamp":"1693673160.0","content":"Selected Answer: A\nCorrect Answer: A","upvote_count":"3"},{"content":"A is the answer, near real-time = Kinesis Data Firehose.","timestamp":"1693502640.0","upvote_count":"4","comment_id":"995351","poster":"manOfThePeople"},{"timestamp":"1692641460.0","poster":"Guru4Cloud","comments":[],"content":"Selected Answer: D\nUse Amazon Kinesis Data Firehose to deliver streaming data to Amazon S3","upvote_count":"3","comment_id":"986818"},{"comments":[],"timestamp":"1692131220.0","poster":"bjexamprep","upvote_count":"3","comment_id":"981973","content":"Selected Answer: D\nKinesis Data Firehose is only real-time answer"},{"poster":"mrsoa","content":"Selected Answer: A\nA is the correct answer","upvote_count":"3","timestamp":"1691069100.0","comment_id":"971136"},{"comment_id":"970926","timestamp":"1691053560.0","upvote_count":"4","poster":"Deepakin96","content":"Selected Answer: A\nKinesis = Near Real Time"},{"timestamp":"1690973640.0","upvote_count":"4","poster":"Kaiden123","comment_id":"970065","content":"Selected Answer: A\nData collection in near real time = Amazon Kinesis Data Firehose"},{"comment_id":"968979","poster":"Bmaster","content":"A is correct..","timestamp":"1690887780.0","upvote_count":"2"}],"answers_community":["A (83%)","D (17%)"],"timestamp":"2023-08-01 13:03:00","unix_timestamp":1690887780,"question_images":[],"answer_ET":"A"},{"id":"KdupvyzbE8vmTUXQf09z","question_text":"A company has separate AWS accounts for its finance, data analytics, and development departments. Because of costs and security concerns, the company wants to control which services each AWS account can use.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","answer_images":[],"answer_description":"","question_images":[],"exam_id":31,"discussion":[{"timestamp":"1738900860.0","content":"Selected Answer: D\nSCP set a guardrail (what you can not do, permission on IAM user and role), ASC provides templates services that you can only use.","comment_id":"1352800","upvote_count":"1","poster":"zdi561"},{"comment_id":"1119130","upvote_count":"2","content":"Selected Answer: B\nDepartments = Organizational Units","poster":"awsgeek75","timestamp":"1720645380.0"},{"upvote_count":"2","timestamp":"1715926200.0","poster":"TariqKipkemei","comment_id":"1073095","content":"Selected Answer: B\nCreate organization units (OUs) for each department in AWS Organizations. Attach service control policies (SCPs) to the OUs"},{"upvote_count":"2","timestamp":"1709405220.0","comment_id":"997008","content":"Selected Answer: B\nCorrect Answer: B","poster":"ssa03"},{"content":"Selected Answer: B\nSCPs to centralize permissioning","poster":"lemur88","comment_id":"990834","timestamp":"1708963080.0","upvote_count":"2"},{"content":"Selected Answer: B\nCreate organization units (OUs) for each department in AWS Organizations. Attach service control policies (SCPs) to the OUs.","poster":"Guru4Cloud","comment_id":"986816","timestamp":"1708546140.0","upvote_count":"2"},{"poster":"xyb","comment_id":"976976","timestamp":"1707514380.0","content":"Selected Answer: B\ncontrol services --> SCP","upvote_count":"2"},{"poster":"Ale1973","content":"Selected Answer: D\nMy rational: Scenary is \"A company has separate AWS accounts\", it is not mentioning anything about use of Organizations or needs related to centralized managment of these accounts. \nThen, set up a list of products in AWS Service Catalog in the AWS accounts (on each AWS account) is the best way to manage and control the usage of specific AWS services.","comment_id":"976695","upvote_count":"1","timestamp":"1707492840.0","comments":[{"timestamp":"1719841260.0","comment_id":"1111323","content":"\"Separate AWS accounts\" just says that it's multiple accounts, it does not indicate that they are NOT connected into a organization.\n\nService Catalog alone does not restrict anything. You'd need to create a service in Service Catalog for everything you're allowing to use, then grant permissions on those services, and you'd need to remove other permissions from everyone. All of which is not mentioned in D. Just \"setting up a list of products in AWS Service Catalog in the AWS accounts\" will not restrict anyone from doing what he could do before.","poster":"pentium75","upvote_count":"3"}]},{"poster":"mrsoa","content":"Selected Answer: B\nBBBBBBBBB","upvote_count":"2","comment_id":"972115","timestamp":"1707054720.0"},{"timestamp":"1706958300.0","content":"Selected Answer: B\nTo control different AWS account you required AWS Organisation","upvote_count":"2","comment_id":"970924","poster":"Deepakin96"},{"poster":"Bmaster","comment_id":"968980","timestamp":"1706792640.0","upvote_count":"2","content":"B is correct!!!!"}],"timestamp":"2023-08-01 13:04:00","question_id":519,"unix_timestamp":1690887840,"answers_community":["B (89%)","11%"],"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/116977-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"B","choices":{"B":"Create organization units (OUs) for each department in AWS Organizations. Attach service control policies (SCPs) to the OUs.","D":"Set up a list of products in AWS Service Catalog in the AWS accounts to manage and control the usage of specific AWS services.","C":"Use AWS CloudFormation to automatically provision only the AWS services that each department can use.","A":"Use AWS Systems Manager templates to control which AWS services each department can use."},"isMC":true,"topic":"1"},{"id":"Gk9lN8sywAL5bgLqk1sz","answer_images":[],"question_text":"A company has created a multi-tier application for its ecommerce website. The website uses an Application Load Balancer that resides in the public subnets, a web tier in the public subnets, and a MySQL cluster hosted on Amazon EC2 instances in the private subnets. The MySQL database needs to retrieve product catalog and pricing information that is hosted on the internet by a third-party provider. A solutions architect must devise a strategy that maximizes security without increasing operational overhead.\n\nWhat should the solutions architect do to meet these requirements?","answer_description":"","question_images":[],"exam_id":31,"discussion":[{"poster":"awsgeek75","comment_id":"1119137","content":"Selected Answer: B\nA: Probably an old question so this option is here but NAT instance is overhead\nC: Not secure as IG opens up a lot of things\nD: VPG connects to a service\nB: NG is managed solution. Secure by config","timestamp":"1720645620.0","upvote_count":"3"},{"upvote_count":"4","comment_id":"1073096","timestamp":"1715926260.0","poster":"TariqKipkemei","content":"Selected Answer: B\nDeploy a NAT gateway in the public subnets. Modify the private subnet route table to direct all internet-bound traffic to the NAT gateway"},{"timestamp":"1709405280.0","upvote_count":"4","content":"Selected Answer: B\nCorrect Answer: B","poster":"ssa03","comment_id":"997010"},{"poster":"Guru4Cloud","content":"Selected Answer: B\nDeploy a NAT gateway in the public subnets. Modify the private subnet route table to direct all internet-bound traffic to the NAT gateway.","upvote_count":"3","timestamp":"1708546080.0","comment_id":"986815"},{"poster":"Deepakin96","content":"Selected Answer: B\nNAT Gateway is safe","upvote_count":"3","comment_id":"970918","timestamp":"1706957940.0"},{"timestamp":"1706793000.0","upvote_count":"2","comment_id":"968988","content":"B is correct","poster":"Bmaster"}],"timestamp":"2023-08-01 13:10:00","question_id":520,"unix_timestamp":1690888200,"answers_community":["B (100%)"],"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/116978-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"B","choices":{"C":"Configure an internet gateway and attach it to the VPModify the private subnet route table to direct internet-bound traffic to the internet gateway.","B":"Deploy a NAT gateway in the public subnets. Modify the private subnet route table to direct all internet-bound traffic to the NAT gateway.","A":"Deploy a NAT instance in the VPC. Route all the internet-based traffic through the NAT instance.","D":"Configure a virtual private gateway and attach it to the VPC. Modify the private subnet route table to direct internet-bound traffic to the virtual private gateway."},"isMC":true,"topic":"1"}],"exam":{"isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"id":31,"provider":"Amazon","isBeta":false},"currentPage":104},"__N_SSP":true}