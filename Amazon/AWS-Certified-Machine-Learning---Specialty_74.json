{"pageProps":{"questions":[{"id":"i7TOXBhepUGf0NITYqR1","unix_timestamp":1612391700,"topic":"1","answer":"A","question_text":"A Machine Learning Specialist is attempting to build a linear regression model.\n//IMG//\n\nGiven the displayed residual plot only, what is the MOST likely problem with the model?","question_images":["https://www.examtopics.com/assets/media/exam-media/04145/0005700001.jpg"],"discussion":[{"comment_id":"283183","content":"I would choose A. See: https://www.itl.nist.gov/div898/handbook/pmd/section4/pmd442.htm and \nhttps://blog.minitab.com/blog/the-statistics-game/checking-the-assumption-of-constant-variance-in-regression-analyses","timestamp":"1664529780.0","upvote_count":"25","poster":"[Removed]"},{"content":"Ans. is A.\nHigh-degree polynomial transformation.","comment_id":"283007","poster":"takahirokoyama","timestamp":"1664139000.0","upvote_count":"12","comments":[{"upvote_count":"2","comment_id":"283493","poster":"TrekkingMachine","content":"I think so too.","timestamp":"1665573840.0"}]},{"timestamp":"1731538080.0","content":"Answer A.\nOne of the key assumptions of linear regression is that the residuals have constant variance at every level of the predictor variable(s). If this assumption is not met, the residuals are said to suffer from heteroscedasticity. When this occurs, the estimates for the model coefficients become unreliable\nhttps://www.statology.org/constant-variance-assumption/","comment_id":"1069825","upvote_count":"1","poster":"geoan13"},{"comment_id":"992214","upvote_count":"1","content":"Selected Answer: A\nAgree with A","timestamp":"1724851020.0","poster":"Mickey321"},{"timestamp":"1709982300.0","content":"Selected Answer: A\nhttps://blog.minitab.com/en/the-statistics-game/checking-the-assumption-of-constant-variance-in-regression-analyses","upvote_count":"1","poster":"Nadia0012","comment_id":"833881"},{"poster":"Tomatoteacher","upvote_count":"1","comment_id":"778223","timestamp":"1705437240.0","content":"Selected Answer: A\nKind of like heteroskedasticity, anyways it is A."},{"comment_id":"707053","timestamp":"1698573600.0","content":"Selected Answer: A\nAnswer is A. It does not has constant variance !","poster":"jrff","upvote_count":"3"},{"upvote_count":"1","poster":"Shailendraa","content":"A is correct answer","timestamp":"1693736400.0","comment_id":"658328"},{"comment_id":"622806","upvote_count":"2","poster":"ovokpus","content":"These images are broken. I cannot review the question properly!","timestamp":"1687811160.0"},{"timestamp":"1676911680.0","poster":"John_Pongthorn","comment_id":"552023","content":"Selected Answer: D\nD is best answer\nall x values are scattering as a whole , no matter what x is\nhttps://www.statisticshowto.com/residual-plot/\n\nif you take all x values to plot histogram , it will be bel-curv.","upvote_count":"2"},{"timestamp":"1676146140.0","comments":[{"upvote_count":"2","poster":"eeah","content":"yes, it does. One of the main assumptions is homoscedasticity.","timestamp":"1680521820.0","comment_id":"580245"}],"upvote_count":"1","poster":"AddiWei","content":"And it does NOT mean linear regression is not appropriate. It means your linear regression model is biased due to several reasons.","comment_id":"545468"},{"poster":"AddiWei","content":"100% A","comment_id":"545467","timestamp":"1676146080.0","upvote_count":"1"},{"timestamp":"1674914220.0","content":"I will choose A , because the data is heteroscedastic. It violates a key assumption of linear regeression","comment_id":"534745","poster":"u404","upvote_count":"2"},{"poster":"Huy","content":"A. https://www.originlab.com/doc/origin-help/residual-plot-analysis","upvote_count":"2","comment_id":"401328","timestamp":"1667043180.0"},{"poster":"yummytaco","comment_id":"361387","upvote_count":"2","content":"Do not have content variance\nhttps://stats.stackexchange.com/questions/52089/what-does-having-constant-variance-in-a-linear-regression-model-mean","timestamp":"1666977540.0"},{"content":"Answer is A. As x raises, the residuals become higher and higher...","timestamp":"1666600860.0","upvote_count":"1","comment_id":"324964","poster":"Vita_Rasta84444"},{"timestamp":"1666298160.0","upvote_count":"7","comments":[{"content":"Thank you for sharing.","upvote_count":"1","poster":"Sadgamaya","timestamp":"1680651540.0","comment_id":"580951"}],"content":"Some Good Reading https://www.andrew.cmu.edu/user/achoulde/94842/homework/regression_diagnostics.html\n\nAns is A","comment_id":"284235","poster":"cnethers"}],"answer_images":[],"exam_id":26,"answer_description":"","choices":{"B":"Linear regression is inappropriate. The underlying data has outliers.","C":"Linear regression is appropriate. The residuals have a zero mean.","D":"Linear regression is appropriate. The residuals have constant variance.","A":"Linear regression is inappropriate. The residuals do not have constant variance."},"answer_ET":"A","isMC":true,"question_id":366,"url":"https://www.examtopics.com/discussions/amazon/view/43948-exam-aws-certified-machine-learning-specialty-topic-1/","answers_community":["A (75%)","D (25%)"],"timestamp":"2021-02-03 23:35:00"},{"id":"GGzQfAzeHJhiRhsylVZ4","answer_ET":"CDF","answers_community":["CDF (47%)","CEF (33%)","CDE (15%)","3%"],"isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/43962-exam-aws-certified-machine-learning-specialty-topic-1/","answer_images":[],"choices":{"D":"Amazon Polly","F":"Amazon Transcribe","B":"Amazon Connect","E":"Amazon Comprehend","C":"Amazon Lex","A":"Alexa for Business"},"question_id":367,"unix_timestamp":1612416780,"exam_id":26,"answer_description":"","question_text":"A large company has developed a BI application that generates reports and dashboards using data collected from various operational metrics. The company wants to provide executives with an enhanced experience so they can use natural language to get data from the reports. The company wants the executives to be able ask questions using written and spoken interfaces.\nWhich combination of services can be used to build this conversational interface? (Choose three.)","answer":"CDF","timestamp":"2021-02-04 06:33:00","discussion":[{"comment_id":"291726","timestamp":"1633158660.0","upvote_count":"35","poster":"astonm13","comments":[{"comment_id":"397399","poster":"hero67","upvote_count":"4","timestamp":"1634868840.0","content":"Why would I need to transcribe while I have Lex that do the NLU part? It would be more reasonable to select Either Connect (B) or Polly (D) if the specs to generate output speech."},{"content":"E - is more to express the \"feeling\" or \"mood\". We would rather need something, that can speak to the customer. So my suggestion is c,d,f","timestamp":"1635888540.0","upvote_count":"5","poster":"Hariru","comments":[{"comment_id":"1199850","upvote_count":"1","timestamp":"1713739560.0","content":"The question states that the company wants to \"provide executives with an enhanced experience so they can use natural language to get data from the reports.\" The key phrase here is \"use natural language,\" which implies that the executives will be interacting with the system using human-like language, either written or spoken. To understand and interpret natural language inputs from users, whether written or spoken, the system needs to have natural language understanding (NLU) or natural language processing (NLP) capabilities. Without NLU/NLP capabilities, the system would not be able to make sense of the executives' natural language queries and extract the relevant information to retrieve data from the reports and dashboards. Services like Amazon Lex and Amazon Comprehend are specifically designed to provide NLU and NLP functionalities, respectively. Amazon Lex uses NLU models to understand the intent and extract relevant information from user inputs, while Amazon Comprehend provides NLP capabilities to analyze and extract insights from text data.","poster":"F1Fan"}],"comment_id":"442319"}],"content":"C - voice and text interface\nE - understanding\nF - Speech to text"},{"timestamp":"1633715880.0","comment_id":"343876","comments":[{"comment_id":"343878","comments":[{"content":"I second that, the keyword here is \"conversational interface\". so, no conversation without Amazon Lex","timestamp":"1634808960.0","poster":"weelz","comment_id":"388578","upvote_count":"1"}],"content":"*C - Lex\n\nSo C,D,F","timestamp":"1634199300.0","poster":"eganilovic","upvote_count":"17"}],"upvote_count":"23","poster":"eganilovic","content":"If we need to build written and spoken interfaces we need :\nF - Transcribe (speech to text)\nD- Polly (text ot speech)\nAnd for chatbot:\nE - Lex"},{"timestamp":"1720348500.0","poster":"sheetalconect","upvote_count":"1","content":"Selected Answer: ACD\nAlexa for Business: Handles the voice interaction, converting spoken queries into text and providing the voice interface that executives use to interact with the BI application.\nAmazon Lex: Processes the text input (converted by Alexa) and understands the intent behind the queries, enabling the conversational interface.\nAmazon Polly: Optional but useful if you want to convert the textual responses from the BI application back into spoken responses, providing a complete voice-based interaction.","comment_id":"1243787"},{"upvote_count":"2","timestamp":"1709407380.0","content":"Selected Answer: CDF\nLex for bot service, Polly for text-to-speech (answer) and Transcribe for speech-to-text (question).","poster":"ArchMelody","comment_id":"1164344"},{"timestamp":"1708990560.0","comment_id":"1160145","poster":"vkbajoria","upvote_count":"1","content":"I believe Answer should be CDF\nC: Lex \nD: Polly\nF: Transcribe"},{"upvote_count":"2","poster":"kyuhuck","content":"Selected Answer: CDF\nFor a BI application where executives can ask questions using written and spoken interfaces, the following combination of services would be suitable:\n\nAmazon Lex (Option C): To build the core conversational interface that understands and processes natural language queries.\nAmazon Polly (Option D): To provide spoken responses to written queries, giving a more interactive experience for users who are not using the voice interface.\nAmazon Transcribe (Option F): To convert spoken queries into text that can be understood by Amazon Lex.\nThese three services would work together to provide a comprehensive conversational interface that allows for both text and voice interactions, meeting the requirements of the scenario provided.","comment_id":"1143571","timestamp":"1707326460.0"},{"upvote_count":"1","poster":"Alice1234","comment_id":"1142466","content":"C. Amazon Lex: It provides advanced deep learning functionalities of automatic speech recognition (ASR) for converting speech to text, and natural language understanding (NLU) to recognize the intent of the text, enabling you to build applications with highly engaging user experiences and lifelike conversational interactions.\n\nD. Amazon Polly: This service turns text into lifelike speech using deep learning. It would enable the BI application to deliver the answers to the executives' questions in a spoken format.\n\nF. Amazon Transcribe: This is an automatic speech recognition (ASR) service that makes it easy for developers to add speech-to-text capability to their applications. This would be necessary for the BI application to interpret spoken questions from the executives.","timestamp":"1707244080.0"},{"content":"Selected Answer: CDF\nCDF -> CEF. you dont need comprehend in this scenario.","timestamp":"1705940760.0","comment_id":"1128868","poster":"CloudHandsOn","upvote_count":"3"},{"content":"Selected Answer: CDF\nAmazon Lex (C): This service is crucial for building conversational interfaces. It provides the capabilities to understand and interpret user input in natural language, which is essential for understanding the questions asked by executives.\n\n Amazon Transcribe (F): For a spoken interface, you need a service that can convert speech into text. Amazon Transcribe does exactly this, allowing the system to process spoken questions by converting them into text that can then be interpreted by Amazon Lex.\n\n Amazon Polly (D): To enhance the user experience by responding to inquiries not only in text but also in spoken form, Amazon Polly is ideal. It converts text responses into lifelike speech, allowing the system to verbally communicate with the executives.\n\nTogether, these three services (Amazon Lex, Amazon Transcribe, and Amazon Polly) will enable a comprehensive conversational interface for the BI application, catering to both written and spoken queries and responses","comment_id":"1116619","upvote_count":"2","poster":"CloudHandsOn","timestamp":"1704718920.0"},{"content":"Selected Answer: CDF\nwhy does aws use muliplt service for tts and stt?","timestamp":"1701122400.0","comment_id":"1081972","poster":"endeesa","upvote_count":"3"},{"comment_id":"1076866","poster":"sukye","upvote_count":"2","timestamp":"1700620260.0","content":"Selected Answer: CDF\nNo, don't need E Comprehend because the report has already been generated."},{"content":"Answer is CEF --> Input can be speech but the output to the user will be text (as nothing specific is mentioned) using Lex for conversational interface, Transcribe to convert speech to text (if input is speech) and Comprehend for insights from text","poster":"akgarg00","comment_id":"1074354","upvote_count":"1","timestamp":"1700350020.0"},{"upvote_count":"1","poster":"elvin_ml_qayiran25091992razor","comment_id":"1067100","timestamp":"1699607220.0","content":"Selected Answer: CEF\nCEF is correct"},{"upvote_count":"1","timestamp":"1698651720.0","poster":"DimLam","comment_id":"1057437","content":"Selected Answer: CDE\nI will go with:\n lex for the chat interface\n comprehend for getting insights from reports\n Polly for text-to-speech transformation\n\nhttps://aws.amazon.com/blogs/machine-learning/deriving-conversational-insights-from-invoices-with-amazon-textract-amazon-comprehend-and-amazon-lex/"},{"comment_id":"1008620","timestamp":"1694798940.0","content":"Amazon Polly is essential for providing spoken responses in a conversational interface, it doesn't directly handle the natural language understanding and processing aspect, which is why it wasn't included as one of the top three services for building the conversational interface in this scenario.\n\nCorrect is C, E, F","poster":"jopaca1216","upvote_count":"1"},{"comment_id":"1008427","poster":"loict","upvote_count":"4","timestamp":"1694778900.0","content":"Selected Answer: CDF\nA. NO - Alexa for Business\nB. NO - Amazon Connect for call centers\nC. YES - Amazon Lex for chatbots\nD. YES - Lex Text-to-Speech\nE. NO - Amazon Comprehend is for topic extraction and sentiment analysis, Transcribe already does it\nF. YES - Transcribe Speech-to-Text","comments":[{"content":"Transcribe does not do sentiment analysis and topic extraction it just generates transcript from speech so we need Amazon Comprehend","timestamp":"1697446800.0","upvote_count":"1","poster":"AmeeraM","comment_id":"1044796"}]},{"comment_id":"992226","poster":"Mickey321","upvote_count":"2","timestamp":"1693228980.0","content":"Selected Answer: CDF\nAgree with CDF"},{"timestamp":"1693088100.0","poster":"teka112233","content":"Selected Answer: CEF\nAmazon Lex - A service for building conversational interfaces into any application using voice and text\nAmazon Comprehend is a natural language processing (NLP) service that uses machine learning to extract insights from text. It can recognize entities, key phrases, language, sentiments, and more. You can also customize it for your specific needs\nAmazon Transcribe - A service for transcribing speech to text\nI don't think polly which is used to text to speech is required over here since the app will accept either written wrods or voice and will produce reports","upvote_count":"3","comment_id":"991071"},{"content":"Selected Answer: CEF\nLetter B is discarded, as it is for Call Center scenarios. Letter F is correct for transcribing executives' speeches. Letter D is correct to convert the texts found into the robot's speech and thus have a conversational interface. However, Lex is recommended in these conversational interface cases, negating the need for AWS Polly. Lyrics behind the understanding part. So the correct one is C-E-F (I completely understand who is from C-D-F).","timestamp":"1691004480.0","comment_id":"970501","upvote_count":"1","poster":"kaike_reis"},{"timestamp":"1690111440.0","content":"Selected Answer: CDF\nLex to understand what answer to provide acording to the topic detected. Polly for text to speech and transcribe gor speech to text","poster":"Ramozz","comment_id":"960378","upvote_count":"1"},{"upvote_count":"1","content":"C: so they can Write to ask\nE: so ML will know what report to show\nF: so they can Speak to ask","poster":"ADVIT","comment_id":"939404","timestamp":"1688161080.0"},{"upvote_count":"2","content":"Selected Answer: CDF\nOption C,D,F (old answer)\nOption C (nowadays)\n\nI do not think this question is still relevant for the exam.\n\nAmazon Lex V2 has ASR(Automatic Speech to Text ~ Transcribe inside) & NTTS (Natural Text to Speech ~ Polly inside). \n\nAWS Comprehend is needed to extract key phrases, or do sentiment analysis but in our case we asked to get insights from data and this is converted to implementing SQL providing text (What ChatGPT successfully do). So, Comprehend is redundant for the current task.\n\nhttps://aws.amazon.com/blogs/machine-learning/best-practices-for-creating-amazon-lex-interaction-models/\n\nhttps://docs.aws.amazon.com/lexv2/latest/dg/what-is.html\n\nhttps://aws.amazon.com/about-aws/whats-new/2021/11/amazon-lex-amazon-polly-neural-text-to-speech-ntts-voices/","timestamp":"1682492160.0","comment_id":"881211","poster":"injoho"},{"content":"Selected Answer: CDF\nhttps://aws.amazon.com/about-aws/whats-new/2021/11/amazon-lex-amazon-polly-neural-text-to-speech-ntts-voices/","comment_id":"881208","upvote_count":"1","poster":"injoho","timestamp":"1682492100.0"},{"upvote_count":"1","poster":"SANDEEP_AWS","comment_id":"838636","timestamp":"1678781580.0","content":"Selected Answer: CDE\nThe question asks: The company wants the executives to be able ask questions using written and spoken interfaces. So D might be important."},{"poster":"AjoseO","timestamp":"1676068380.0","upvote_count":"6","comment_id":"804830","content":"Selected Answer: CEF\nC - Amazon Lex for voice and text interface - note that Polly is inbuilt into Lex \nE - Amazon Comprehend - understanding\nF - Amazon Transcribe - Speech to text"},{"timestamp":"1676025480.0","comment_id":"804221","content":"Selected Answer: CDF\nC. Amazon Lex Most Voted\nD. Amazon Polly\nF. Amazon Transcribe\nE: Comprehend is not require in this case","upvote_count":"1","poster":"sqavi"},{"timestamp":"1674893220.0","comment_id":"790392","content":"Correct Answer is CEF","upvote_count":"1","poster":"CertArvind"},{"timestamp":"1673901660.0","poster":"Tomatoteacher","upvote_count":"1","comment_id":"778235","content":"Selected Answer: CDF\nThis is a very strange question, I feel as if there would need to be one more sentence of explanation, anyways I go with C,D,F as dont need comprehend to find sentiment, classify documents, or whatnot, need conversational interface."},{"upvote_count":"1","content":"DEF if output needs via text ---the question confuses they are asking data but didn't exclusively say it is in which form ---conversational I see manager can ask questions via spoke --- but not sure conversational output they are asking ...,if it is conversational output I go with CEF","poster":"expertguru","timestamp":"1673125920.0","comment_id":"768927"},{"poster":"hamimelon","content":"I think it should be CDF","timestamp":"1671417120.0","upvote_count":"1","comment_id":"749385"},{"content":"Selected Answer: CDE\nFor speech inputs, Amazon Lex uses Amazon Transcribe behind the scenes to convert speech to text and then processes the text to understand the user's intent. Lex uses the knowledge learned from sample utterances provided during the training phase to detect the user intent and generate a response.","upvote_count":"2","timestamp":"1669500660.0","poster":"ystotest","comment_id":"727828"},{"upvote_count":"3","poster":"aScientist","comment_id":"710751","content":"Selected Answer: CEF\nPolly is incorrect because executives dont want answers read to them\nAmazon connect is a contact center service\nAlexa for business is an irrelevant option","timestamp":"1667503800.0"},{"poster":"Ob1KN0B","content":"Selected Answer: CEF\nThis is fairly an easy question but surprised to see the confusion.\n\n\"Allowing to get data from reports in natural language\" - means speech to text - F. Transcribe, for conversion from speech to text AND E. Comprehend, for NLP text extraction.\n\n\"Be able to communicate using written or spoken\" - means text or IVR which is C. Lex, only service which provides BOTH capabilities.","comment_id":"649466","timestamp":"1661006280.0","upvote_count":"4"},{"comment_id":"633957","upvote_count":"2","timestamp":"1658308860.0","poster":"KlaudYu","content":"Selected Answer: CDF\nTranscribe -> Lex -> Polly"},{"comment_id":"621302","content":"Selected Answer: CEF\nLex is suitable for office chat channels like slack to enhance written and spoken interfaces(chatbots)\n\nAmazon Comprehend is suitable for text and Natural Language data.\n\nAmazon Transcribe is suitable for speech to text.\n\nPolly(text to speech) is not high priority in this use case","upvote_count":"2","poster":"ovokpus","timestamp":"1656017700.0"},{"poster":"ovokpus","comment_id":"621295","upvote_count":"1","timestamp":"1656017280.0","content":"Any answer without Lex is wrong"},{"comments":[{"poster":"cpal012","comment_id":"833429","content":"None of those options allow you to \"get data from the reports\". Presumably this is where Comprehend comes in?","upvote_count":"1","timestamp":"1678316220.0"}],"timestamp":"1655471520.0","content":"I would go with ABC because they don't ask which combination of services and there is as well no right combination (e.g. Lex doesn't need Transcribe and Polly).\nA: Alex offers a voice interface\nB: Connect offers chat and voice interfaces\nC: Lex as well (voice and text)","comment_id":"617729","upvote_count":"1","poster":"f4bi4n"},{"upvote_count":"2","comment_id":"607690","poster":"irimala","timestamp":"1653573180.0","content":"Selected Answer: CDE\nObviously CDE"},{"comment_id":"596082","content":"CDE, Lex can handle functions performed by Transcribe.","upvote_count":"5","timestamp":"1651501620.0","poster":"rohit07cf"},{"poster":"spaceexplorer","upvote_count":"6","content":"I lean towards CDE but the question is confusing","comment_id":"594661","timestamp":"1651259880.0"},{"comment_id":"552977","upvote_count":"3","content":"Selected Answer: CDE\nI choose C, D, E. ------ F is incorrect. The question does not mention a desire to do Voice to Text only to incorporate Machine Learning comprehension of documents.","poster":"TerrancePythonJava","timestamp":"1645458900.0"},{"content":"Selected Answer: DEF\nI believe the answer is DEF","poster":"KM226","upvote_count":"2","comments":[{"upvote_count":"3","poster":"KM226","comment_id":"518548","content":"I believe the right answer is CDF\nC: Amazon Lex can create a human-like interface to your applications AND\nF: Amazon Transcribe can automatically convert spoken language to text\nD: Amazon Polly can convert written text to spoken language","timestamp":"1641499500.0"}],"timestamp":"1641128280.0","comment_id":"514978"},{"comment_id":"401355","upvote_count":"4","timestamp":"1635466980.0","poster":"Huy","content":"Lex, Comprehend and Transcribe. Lex already have voice output function built-in so no need to use Polly (although behind the scene it uses Polly). We need to find the topics of reports on dashboard. Comprehend may help."},{"upvote_count":"1","timestamp":"1634899800.0","comment_id":"397404","content":"C : Lex ( For natural language understanding and speech to text work)\nE: Comprehend (because there is a need to extract data from the graph )\nBut I am not sure about the third option: \nD: Polly (text to speech) to complete the conversational requirement \nor \nB: Connect ( Amazon Connect offers high-quality audio capabilities, natural interactive voice response (IVR), and interactive chatbots)","poster":"hero67"},{"content":"People seem to think the interface needs to speak back, but I do not think this is the case. Person talk --> graph returned\nI'd go for lex, comprehend, and speech to text","comment_id":"384662","poster":"jerto97","timestamp":"1634357820.0","upvote_count":"3"},{"poster":"gcpwhiz","upvote_count":"1","timestamp":"1633513020.0","comment_id":"341519","content":"Why do you need C and F? Lex already does speech to text, you don't need transcribe."},{"content":"CEF !!!","timestamp":"1633383900.0","comment_id":"324965","upvote_count":"3","poster":"Vita_Rasta84444"},{"timestamp":"1633266600.0","content":"C, E and F","upvote_count":"2","poster":"SophieSu","comment_id":"299198"},{"timestamp":"1633228200.0","comment_id":"293857","poster":"scuzzy2010","upvote_count":"8","content":"C (building conversational interfaces into any application using voice and text.)\nD (text to speech - app can answer verbally)\nE (natural language processing (NLP) service that uses machine learning to find insights and relationships in text - can be used with Lex)"},{"timestamp":"1632547560.0","poster":"jdstone","comment_id":"289891","upvote_count":"4","content":"C (written quesions)\nE (sentiment and understanding)\nF (speech to text)"},{"upvote_count":"4","comment_id":"284583","poster":"cnethers","content":"D. Amazon Polly Text to Speach \nE. Amazon Comprehend Derive sentiment and understanding \nF. Amazon Transcribe Speach to text","timestamp":"1632387600.0"},{"content":"I would answer A (spoken questions), C(written questions), and E (NLP to parse reports).","comment_id":"283190","poster":"[Removed]","timestamp":"1632236100.0","upvote_count":"2"}],"question_images":[]},{"id":"GUeXJtXLTQezraa6Feqn","choices":{"B":"Add more data to the training set and retrain the model using transfer learning to reduce the bias.","C":"Use a neural network model with more layers that are pretrained on ImageNet and apply transfer learning to increase the variance.","A":"Upload the model to an Amazon SageMaker notebook instance and use the Amazon SageMaker HPO feature to optimize the model's hyperparameters.","D":"Train a new model using the current neural network architecture."},"isMC":true,"discussion":[{"upvote_count":"11","poster":"dolorez","comment_id":"605229","content":"Selected Answer: B\nthe answer is B - the model is underfitting = high bias, so we want to reduce it\nC is wrong because the intention is not to increase variance which equals overfitting (using a more complex model would be good, but to reduce bias not increase variance)","timestamp":"1684740480.0"},{"comment_id":"1339659","content":"Selected Answer: B\nThe 68% accuracy on the training set and 67% accuracy on the validation set suggest that the model is biased - underfitting and does not have enough capacity or relevant information to learn the underlying patterns in the data.","poster":"CloudGyan","upvote_count":"1","timestamp":"1736712420.0"},{"poster":"endeesa","timestamp":"1732744980.0","comment_id":"1081976","upvote_count":"1","content":"Selected Answer: B\nI would think ImageNet network is good enough already, so more data"},{"content":"Selected Answer: B\nA. NO - HPO has already been done though grid search\nB. YES - 150 images is very small; need x10 that\nC. NO - need bigger training set\nD. NO - what would the new model be ?","poster":"loict","timestamp":"1726401600.0","comment_id":"1008433","upvote_count":"2"},{"comment_id":"992227","poster":"Mickey321","upvote_count":"1","timestamp":"1724851440.0","content":"Selected Answer: B\nMore data to training set"},{"poster":"kaike_reis","content":"Selected Answer: B\nLetter B is the correct one. We can add more data with data augmentation. Letter A would be a repetition of what has already been done. Letter C is impractical. Letter D is starting from scratch without need.","upvote_count":"1","timestamp":"1722627060.0","comment_id":"970503"},{"content":"Selected Answer: D\nI think it should be D: \"Train a new model using the current neural network architecture\".\nBecause apples data is very specific and ImageNet weights will be to generic there. We still can leave ImageNet weights for an initial configuration but the model should be retrained from scratch.","comment_id":"925264","poster":"mirik","upvote_count":"1","timestamp":"1718547720.0"},{"timestamp":"1714296480.0","comment_id":"883373","poster":"cox1960","content":"Selected Answer: A\n450 images should be fine. HPO for me.","upvote_count":"1"},{"poster":"expertguru","comment_id":"768938","content":"bOTH VALIdation set and train set performing equally but performance not good. So the basic problem here is high bias (train error) and high variance (test error). Ideally we want both low, but there is trade-off need to be cautious to avoid overfitting. So this problem needs solution for Low bias first (so training performance improves with decent) for later to figure out whether that leads to overfit or not when you test it,! Answer choice B","timestamp":"1704663720.0","upvote_count":"1"},{"poster":"deng113jie","comment_id":"646162","timestamp":"1691908020.0","content":"why not A?\nhttps://aws.amazon.com/about-aws/whats-new/2022/07/amazon-sagemaker-automatic-model-tuning-supports-increased-limits-improve-accuracy-models/","upvote_count":"2"},{"content":"not B, c is corect","timestamp":"1686939780.0","comment_id":"617357","upvote_count":"1","poster":"[Removed]"},{"upvote_count":"1","comment_id":"602492","poster":"edvardo","timestamp":"1684225080.0","content":"Given that the model can't even fit the training set properly, it would be convenient to amplify the layers that are trained. If I understood the phrasing correctly, I would go with C."},{"comments":[{"comment_id":"595084","content":"B is more accurate, while adding more complexity for model is viable but you don't want to increase variance","poster":"spaceexplorer","upvote_count":"12","timestamp":"1682865720.0"},{"comment_id":"612479","upvote_count":"4","timestamp":"1686078660.0","content":"It only has 150 photos for training, more complex neural network won't help","poster":"NeverMinda"}],"comment_id":"589057","content":"Selected Answer: C\nC, accuracy on training set is low, model not complex enough","upvote_count":"1","timestamp":"1682046540.0","poster":"Istdanagan"}],"question_text":"A machine learning specialist works for a fruit processing company and needs to build a system that categorizes apples into three types. The specialist has collected a dataset that contains 150 images for each type of apple and applied transfer learning on a neural network that was pretrained on ImageNet with this dataset.\nThe company requires at least 85% accuracy to make use of the model.\nAfter an exhaustive grid search, the optimal hyperparameters produced the following:\n✑ 68% accuracy on the training set\n✑ 67% accuracy on the validation set\nWhat can the machine learning specialist do to improve the system's accuracy?","timestamp":"2022-04-21 05:09:00","url":"https://www.examtopics.com/discussions/amazon/view/73977-exam-aws-certified-machine-learning-specialty-topic-1/","answer_ET":"B","answer_images":[],"answer":"B","topic":"1","unix_timestamp":1650510540,"answers_community":["B (85%)","Other"],"answer_description":"","exam_id":26,"question_id":368,"question_images":[]},{"id":"VdAI6yTgpSG2aOP5kSa5","answer_description":"","choices":{"B":"Reduce the number of distinct items from 10 to 2, build the model, and iterate","C":"Attach different colored labels to each item, take the images again, and build the model","D":"Augment training data for each item using image variants like inversions and translations, build the model, and iterate.","A":"Convert the images to grayscale and retrain the model"},"discussion":[{"content":"Selected Answer: D\nData Augumentation is the way to go here. \n\nHow does converting to grayscale help? What if the colors of the items are relevant in object identification???","comment_id":"621204","timestamp":"1687544340.0","upvote_count":"11","poster":"ovokpus"},{"poster":"AmeeraM","upvote_count":"1","content":"Selected Answer: D\ndata augemntation","comment_id":"1044815","timestamp":"1729070700.0"},{"comment_id":"1008629","upvote_count":"1","timestamp":"1726423140.0","content":"D is correct\n\nHow can I make the decision to use gray images if the question doesn't even indicate whether the images are colored or not? and even so, colored images are important to ensure more accuracy in training than compared to gray imagens.\n\nDue that the model is underfitting, more data like indicated the option D is the correct action.","poster":"jopaca1216"},{"content":"C: \"Attach different colored labels to each item, take the images again, and build the model\"\nIt is also kind of augmentation. It is even better than just inverting and translating existing samples.","comments":[{"poster":"kaike_reis","timestamp":"1722627240.0","upvote_count":"1","content":"But it's done in real life and your manual work would be lost.","comment_id":"970505"}],"upvote_count":"1","poster":"mirik","timestamp":"1718548500.0","comment_id":"925276"},{"content":"shouldnt it be reduced to 2 variables , taking image of empty shelf and non empty and that should do it ?","upvote_count":"1","poster":"Debayandt91","timestamp":"1715494320.0","comment_id":"895685"},{"comment_id":"812049","content":"D is of course the right answer, grayscale only won't help anything","timestamp":"1708182900.0","upvote_count":"3","poster":"Sylzys"},{"content":"D is the CORRECT ANSWER\n\nhttps://research.aimultiple.com/data-augmentation/","poster":"PHTR","timestamp":"1704719100.0","upvote_count":"1","comment_id":"769427"},{"content":"Selected Answer: D\nData augmentation is correct. we need more samples","comment_id":"710755","timestamp":"1699039920.0","upvote_count":"1","poster":"aScientist"},{"comment_id":"610057","content":"D is correct","poster":"tgaos","upvote_count":"3","timestamp":"1685605860.0"},{"upvote_count":"4","comment_id":"590311","timestamp":"1682209440.0","content":"Selected Answer: D\nD is my answer for this. A can help but it'll need more than that.","poster":"cron0001"},{"content":"Selected Answer: D\nD, i guess","upvote_count":"4","timestamp":"1682046600.0","comment_id":"589058","poster":"Istdanagan"}],"answer_images":[],"topic":"1","exam_id":26,"answers_community":["D (100%)"],"question_images":[],"isMC":true,"answer_ET":"D","question_id":369,"question_text":"A company uses camera images of the tops of items displayed on store shelves to determine which items were removed and which ones still remain. After several hours of data labeling, the company has a total of 1,000 hand-labeled images covering 10 distinct items. The training results were poor.\nWhich machine learning approach fulfills the company's long-term needs?","timestamp":"2022-04-21 05:10:00","url":"https://www.examtopics.com/discussions/amazon/view/73978-exam-aws-certified-machine-learning-specialty-topic-1/","answer":"D","unix_timestamp":1650510600}],"exam":{"lastUpdated":"11 Apr 2025","isBeta":false,"name":"AWS Certified Machine Learning - Specialty","id":26,"isMCOnly":false,"numberOfQuestions":369,"isImplemented":true,"provider":"Amazon"},"currentPage":74},"__N_SSP":true}