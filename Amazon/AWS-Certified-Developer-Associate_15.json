{"pageProps":{"questions":[{"id":"VICgR8EcdXyFTDjiSquM","answer":"AB","answers_community":["AB (56%)","AE (31%)","13%"],"unix_timestamp":1669043400,"timestamp":"2022-11-21 16:10:00","discussion":[{"timestamp":"1676981820.0","content":"Selected Answer: AE\nAE - You must have complete lifecycle, encryption at rest and encryption in transit.\n\nA. Create a Lambda@Edge function to encrypt data when CloudFront processes a client request. Configure the distribution to invoke the Lambda@Edge function when the origin request event occurs. \nThis will ensure that data is encrypted at rest, in transit, and during processing. The Lambda@Edge function should use a customer managed AWS KMS key to encrypt the sensitive data.\n\nE. Store the data in the S3 bucket by using server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Transfer the encrypted data from the S3 bucket to the DynamoDB table. \nThis will ensure that data is encrypted at rest in the S3 bucket, and during transfer to the DynamoDB table. Using SSE-S3 simplifies key management since AWS manages the encryption keys for the S3 bucket.","comments":[{"comment_id":"838031","upvote_count":"3","poster":"fomenkogregory","content":"I thinks, if you encrypt the data with Lambda@Edge it will be remain encrypted all the way to storage as shown on \"Figure 2: Field-level encryption process\"\nhttps://aws.amazon.com/blogs/security/how-to-protect-sensitive-data-for-its-entire-lifecycle-in-aws/","timestamp":"1678721340.0"}],"poster":"mistral","comment_id":"816539","upvote_count":"5"},{"comment_id":"937088","timestamp":"1687981500.0","poster":"rcaliandro","upvote_count":"1","content":"Selected Answer: AB\nFor me is both A and B. Firstly, we need to generate an AWS Key using KMS in order to allow Lambda@Edge to use it. Then, allow encryption when CloudFront process client request and origin request"},{"timestamp":"1682474820.0","upvote_count":"1","content":"A. Create a Lambda@Edge function to encrypt data when CloudFront processes a client request. Configure the distribution to invoke the Lambda@Edge function when the origin request event occurs. This step ensures that the sensitive data is encrypted during transmission.\nB. Generate an AWS Key Management Service (AWS KMS) customer managed key that Lambda@Edge can use. This step ensures that the sensitive data is encrypted with a customer-managed key, giving the company greater control over the key.","comment_id":"881034","poster":"MrTee"},{"poster":"PRINCE072002","content":"Selected Answer: BE\nSEE it on CHatgpt","comment_id":"846122","upvote_count":"2","timestamp":"1679413680.0","comments":[{"timestamp":"1680491040.0","upvote_count":"1","content":"I saw A and E on chatGPT","poster":"shahs10","comment_id":"859511"}]},{"upvote_count":"3","content":"Selected Answer: AB\nMaybe I'm wrong but the key here is ...to protect sensitive data... from this requirement I understand field level encryption and that only can be done here using lambda@edge using AWS KMS.","poster":"rlnd2000","timestamp":"1679169240.0","comment_id":"843120"},{"comment_id":"813817","poster":"zek","content":"E has to be one of the answers!","timestamp":"1676791500.0","upvote_count":"1","comments":[{"content":"why? if lambda@edge is encrypting the data, then it will remain encrypted in S3 even if you have no encryption at rest (and now is impossible because by default is encrypted at rest)","timestamp":"1679414220.0","poster":"captainpike","comment_id":"846132","comments":[{"comment_id":"846133","timestamp":"1679414280.0","poster":"captainpike","upvote_count":"1","content":"S3 will only have the web site files, so no sensitive data"}],"upvote_count":"1"}]},{"timestamp":"1675494180.0","poster":"appuNBablu","upvote_count":"1","content":"Totally confusing question. AWS Cloudfront is configured with S3 as source. We then have API Gateway in front of lambda which stores data in Dynamo. How the answer is AB?","comment_id":"797683"},{"timestamp":"1673955540.0","content":"A and B make more sense","upvote_count":"2","poster":"sichilam","comment_id":"778850"},{"timestamp":"1673445300.0","poster":"ayoubmk","comment_id":"772600","upvote_count":"3","content":"Selected Answer: AB\nA and B \nhttps://aws.amazon.com/blogs/security/how-to-protect-sensitive-data-for-its-entire-lifecycle-in-aws/"},{"comment_id":"766787","upvote_count":"1","timestamp":"1672933260.0","content":"Okie since already encrypted by Lambda@Edge no nned to encrypt again..","poster":"renmathw"},{"upvote_count":"1","comment_id":"766785","comments":[{"content":"S3 store the website not the data the client enters into the site","poster":"Dirisme","comment_id":"774577","upvote_count":"2","timestamp":"1673619960.0"}],"poster":"renmathw","timestamp":"1672933200.0","content":"Why can't it be A & E ? since its sensitive data encryption might be required at S3 also, I' m I correct..."},{"content":"Selected Answer: AB\nA and B","timestamp":"1669699440.0","upvote_count":"1","comment_id":"729943","poster":"michaldavid"},{"content":"Selected Answer: AB\nhttps://aws.amazon.com/blogs/security/how-to-protect-sensitive-data-for-its-entire-lifecycle-in-aws/","timestamp":"1669355700.0","poster":"k1kavi1","upvote_count":"1","comment_id":"726421"},{"content":"I will go with A,B according to the doc. use Lambda @Edge, along with KMS that Lambda Edge can use\nreference: https://aws.amazon.com/blogs/security/how-to-protect-sensitive-data-for-its-entire-lifecycle-in-aws/","comment_id":"725771","timestamp":"1669289340.0","upvote_count":"3","poster":"CloudHandsOn"},{"timestamp":"1669043520.0","upvote_count":"3","content":"https://aws.amazon.com/blogs/security/how-to-protect-sensitive-data-for-its-entire-lifecycle-in-aws/","comment_id":"723682","poster":"sionita"},{"content":"A and B","upvote_count":"3","timestamp":"1669043400.0","comment_id":"723680","poster":"sionita"}],"question_text":"A company has deployed a single-page application on AWS. The application stores assets in an Amazon S3 bucket. The application has an Amazon CloudFront distribution that is configured with the S3 bucket as the origin. Amazon API Gateway APIs access AWS Lambda functions that store information in an Amazon DynamoDB table. The application ingests a payload that includes 20 fields of sensitive data.\n\nWhich combination of steps should a developer take to protect the sensitive data through its entire lifecycle in AWS? (Choose two.)","question_images":[],"choices":{"E":"Store the data in the S3 bucket by using server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Transfer the encrypted data from the S3 bucket to the DynamoDB table.","B":"Generate an AWS Key Management Service (AWS KMS) customer managed key that Lambda@Edge can use.","D":"Set up a Network Load Balancer for API Gateway private integrations.","A":"Create a Lambda@Edge function to encrypt data when CloudFront processes a client request. Configure the distribution to invoke the Lambda@Edge function when the origin request event occurs.","C":"Create an SSL/TLS certificate in AWS Certificate Manager (ACM). Associate the certificate with the Network Load Balancer."},"answer_ET":"AB","exam_id":25,"isMC":true,"answer_description":"","topic":"1","answer_images":[],"question_id":71,"url":"https://www.examtopics.com/discussions/amazon/view/88236-exam-aws-certified-developer-associate-topic-1-question-162/"},{"id":"pcHSL023MOgrOmC9tVEx","exam_id":25,"topic":"1","question_id":72,"discussion":[{"timestamp":"1687981680.0","comment_id":"937091","upvote_count":"1","poster":"rcaliandro","content":"Selected Answer: A\nA of course if we want to avoid to overwrite data we have to use attribute_not_exists from streamID and seqID"},{"content":"Selected Answer: A\nAaaaaaaAAA","timestamp":"1674206820.0","comment_id":"782051","upvote_count":"1","poster":"Phinx"},{"upvote_count":"1","poster":"sichilam","content":"A it is","timestamp":"1673957880.0","comment_id":"778894"},{"comment_id":"745221","upvote_count":"4","timestamp":"1671032100.0","content":"Selected Answer: A\naws dynamodb put-item \\\n --table-name ProductCatalog \\\n --item file://item.json \\\n --condition-expression \"attribute_not_exists(Id)\"","poster":"freerider76"},{"upvote_count":"1","timestamp":"1670881440.0","content":"Selected Answer: A\nThe corretc is A","poster":"fabriciollf","comment_id":"743353"},{"upvote_count":"2","poster":"michaldavid","timestamp":"1669699500.0","content":"aaaaaaaaaa","comment_id":"729944"},{"upvote_count":"1","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html","comment_id":"726423","poster":"k1kavi1","timestamp":"1669355940.0"},{"content":"Answer is A.\nC does not make sense, as that condition will attempt to PutItem if the StreamID and SeqID is is found.","comment_id":"725777","timestamp":"1669289640.0","poster":"CloudHandsOn","upvote_count":"3"},{"poster":"AKRAMPO","upvote_count":"2","content":"Selected Answer: A\nA .....To prevent a new item from replacing an existing item, use a conditional expression that contains the attribute_not_exists function with the name of the attribute being used as the partition key for the table. Since every record must contain that attribute, the attribute_not_exists function will only succeed if no matching item exists.","comment_id":"725663","timestamp":"1669278720.0"},{"upvote_count":"3","poster":"kapil206001","timestamp":"1669219440.0","comment_id":"725248","content":"A\nhttps://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_PutItem.html"}],"answer_description":"","answer_images":[],"timestamp":"2022-11-21 15:36:00","choices":{"C":"","B":"","A":"","D":""},"question_images":[],"answer":"A","question_text":"A developer is writing an application that stores data in an Amazon DynamoDB table by using the Putltem API operation. The table has a partition key of streamID and has a sort key of seqID. The developer needs to make sure that the Putltem invocation does not overwrite the existing partition key and sort key.\n\nWhich condition expression will maintain the uniqueness of the partition key and the sort key?","answers_community":["A (100%)"],"unix_timestamp":1669041360,"isMC":true,"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/88219-exam-aws-certified-developer-associate-topic-1-question-163/"},{"id":"Y47Qqbl4ST3ICL6PWF4f","exam_id":25,"unix_timestamp":1669043700,"discussion":[{"upvote_count":"1","timestamp":"1703078100.0","comment_id":"1101538","content":"DynamoDB resource based policy. that is why not C","comments":[{"comment_id":"1277680","timestamp":"1725375780.0","poster":"preachr","upvote_count":"1","content":"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_lambda-access-dynamodb.html"}],"poster":"SideGly"},{"content":"Option C is the answer. The remaining all options are irrelevant","comment_id":"976175","poster":"jayvarma","upvote_count":"1","timestamp":"1691547780.0"},{"upvote_count":"1","poster":"rcaliandro","content":"Selected Answer: C\nOnce S3 invoke correctly the lambda, the function needs the right permission to write to DynamoDB. So, the correct answer is C","comment_id":"937094","timestamp":"1687981800.0"},{"comment_id":"780507","timestamp":"1674082740.0","upvote_count":"2","content":"C it is","poster":"sichilam"},{"comment_id":"729946","timestamp":"1669699560.0","content":"Selected Answer: C\ncccccccc","poster":"michaldavid","upvote_count":"1"},{"upvote_count":"1","comment_id":"726425","timestamp":"1669356180.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_lambda-access-dynamodb.html","poster":"k1kavi1"},{"content":"C -The Lambda function does not have IAM permissions to write to DynamoDB.","timestamp":"1669043700.0","poster":"sionita","comment_id":"723684","upvote_count":"1"}],"answer":"C","answer_description":"","isMC":true,"choices":{"D":"The DynamoDB table is not running in the same Availability Zone as the Lambda function.","C":"The Lambda function does not have IAM permissions to write to DynamoDB.","B":"The DynamoDB table requires a global secondary index (GSI) to support writes.","A":"The Lambda function's concurrency limit has been exceeded."},"question_text":"A developer has created an AWS Lambda function that is written in Python. The Lambda function reads data from objects in Amazon S3 and writes data to an Amazon DynamoDB table.\n\nThe function is successfully invoked from an S3 event notification when an object is created. However, the function fails when it attempts to write to the DynamoDB table.\n\nWhat is the MOST likely cause of this issue?","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/88237-exam-aws-certified-developer-associate-topic-1-question-164/","answers_community":["C (100%)"],"question_id":73,"timestamp":"2022-11-21 16:15:00","topic":"1","answer_ET":"C","answer_images":[]},{"id":"5Hqc61ghUOwnvqhotIZ2","choices":{"A":"AWS CodeDeploy","C":"AWS CodeCommit","D":"Amazon CodeGuru","B":"AWS CodeArtifact"},"answer_ET":"C","question_text":"A development team wants to build a continuous integration/continuous delivery (CI/CD) pipeline. The team is using AWS CodePipeline to automate the code build and deployment. The team wants to store the program code to prepare for the CI/CD pipeline.\n\nWhich AWS service should the team use to store the program code?","answer_images":[],"timestamp":"2022-11-23 12:54:00","url":"https://www.examtopics.com/discussions/amazon/view/88429-exam-aws-certified-developer-associate-topic-1-question-165/","question_id":74,"topic":"1","answers_community":["C (100%)"],"answer":"C","answer_description":"","exam_id":25,"question_images":[],"isMC":true,"unix_timestamp":1669204440,"discussion":[{"timestamp":"1669204440.0","comment_id":"725092","upvote_count":"6","content":"This is confusing for me. I will lean towards code commit which is like a git-hub preparatory for cicd jobs. This phrase \"The team wants to store the program code to prepare for the CI/CD pipeline\" is my cue to that . AWS code-artifacts works like nexus to store packages that have undergone build and maybe test process","poster":"saysamsuf"},{"poster":"rcaliandro","timestamp":"1687982100.0","comment_id":"937096","upvote_count":"2","content":"Selected Answer: C\nThe pipeline is almost complete: we have CodeBuild to build or eventually run also tests, we have CodeDeploy to deploy the application. What is missing is a version control repository to achieve the following requirement \"The team wants to store the program code\". CodeCommit is the right answer"},{"upvote_count":"1","comment_id":"823176","content":"A very similar question was on the exam today, asking for the CodeCommit (Feb 2023)","timestamp":"1677471600.0","poster":"pancman"},{"comment_id":"819294","timestamp":"1677162900.0","content":"Selected Answer: C\nCodeArtifact is not the best choice for storing program code that needs to be version controlled and managed as source code. CodeArtifact is designed to store artifacts and dependencies that are typically produced during the build process, rather than the source code itself. While it is possible to store source code in CodeArtifact, it is not a recommended practice for managing source code repositories.\n\nTherefore, if the development team wants to store the program code to prepare for the CI/CD pipeline, AWS CodeCommit is the most suitable AWS service to use for managing and version-controlling the source code repository.","poster":"MMaquis","upvote_count":"2"},{"content":"Selected Answer: C\nC - CodeCommit. It is like the GitHub of AWS, so you store the code there.","upvote_count":"1","comment_id":"815605","poster":"pancman","timestamp":"1676914440.0"},{"comment_id":"780513","content":"CodeArtifact allows you to store artifacts using popular package managers and build tools like Maven, Gradle, npm, Yarn, Twine, pip, and NuGet. CodeArtifact can automatically fetch software packages on demand from public package repositories so you can access the latest versions of application dependencies.","timestamp":"1674083100.0","poster":"sichilam","upvote_count":"3"},{"comment_id":"763328","upvote_count":"2","timestamp":"1672602600.0","poster":"nharaz","content":"Selected Answer: C\nAWS CodeCommit â€“ A fully-managed source control service that hosts secure Git-based repositories. CodeCommit makes it easy for teams to collaborate on code in a secure and highly scalable ecosystem. This solution uses CodeCommit to create a repository to store the application and deployment codes."},{"comment_id":"729947","poster":"michaldavid","content":"Selected Answer: C\ncccccccc","upvote_count":"1","timestamp":"1669699620.0"},{"poster":"k1kavi1","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/devops/complete-ci-cd-with-aws-codecommit-aws-codebuild-aws-codedeploy-and-aws-codepipeline/","comment_id":"726426","timestamp":"1669356480.0","upvote_count":"1"},{"content":"I believe its C, AWS CodeCommit.\nNot sure if the code-artifact option fits this use case.","poster":"CloudHandsOn","upvote_count":"1","comment_id":"725784","timestamp":"1669290000.0"}]},{"id":"olqiq12wKIEguvAO7eiI","answer_description":"","timestamp":"2022-11-21 15:41:00","answer_images":[],"choices":{"B":"Create two AWS Lambda functions: one to delete the items and one to process the items. Create a DynamoDB stream. Use the DeleteItem API operation to delete the items based on the expirationDate attribute. Use the GetRecords API operation to get the items from the DynamoDB stream and process them.","C":"Create two AWS Lambda functions: one to delete the items and one to process the items. Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled rule to invoke the Lambda functions. Use the DeleteItem API operation to delete the items based on the expirationDate attribute. Use the GetRecords API operation to get the items from the DynamoDB table and process them.","A":"Enable TTL on the expirationDate attribute in the table. Create a DynamoDB stream. Create an AWS Lambda function to process the deleted items. Create a DynamoDB trigger for the Lambda function.","D":"Enable TTL on the expirationDate attribute in the table. Specify an Amazon Simple Queue Service (Amazon SQS) dead-letter queue as the target to delete the items. Create an AWS Lambda function to process the items."},"answer":"A","question_images":[],"question_text":"A developer supports an application that accesses data in an Amazon DynamoDB table. One of the item attributes is expiration Date in the timestamp format. The application uses this attribute to find items, archive them, and remove them from the table based on the timestamp value.\n\nThe application will be decommissioned soon, and the developer must find another way to implement this functionality. The developer needs a solution that will require the least amount of code to write.\n\nWhich solution will meet these requirements?","answers_community":["A (92%)","8%"],"unix_timestamp":1669041660,"isMC":true,"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/88220-exam-aws-certified-developer-associate-topic-1-question-166/","exam_id":25,"topic":"1","question_id":75,"discussion":[{"upvote_count":"6","timestamp":"1669356840.0","comment_id":"726429","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/database/automatically-archive-items-to-s3-using-dynamodb-time-to-live-with-aws-lambda-and-amazon-kinesis-firehose/","poster":"k1kavi1"},{"content":"I won't vote even if from the comments seems to be A. What I didn't understand why we don't just enable TTL on the expirationDate attribute? Why we enable a DynamoDB stream and trigger a lambda function as soon as an item has been deleted?","comment_id":"937104","timestamp":"1687982820.0","poster":"rcaliandro","upvote_count":"1","comments":[{"poster":"kaes","upvote_count":"2","comment_id":"1018663","timestamp":"1695807360.0","content":"\"application uses this attribute to find items, ARCHIVE them, and remove them from the table\"\nOne thing is to remove entry from the table, but we need to archive it somewhere as well"}]},{"comment_id":"815607","poster":"pancman","content":"Selected Answer: A\nEasy A","timestamp":"1676914620.0","upvote_count":"1"},{"content":"A it is","poster":"sichilam","upvote_count":"1","timestamp":"1674083820.0","comment_id":"780519"},{"upvote_count":"2","comment_id":"760664","timestamp":"1672295400.0","content":"least amount of code to write - dynamoDB ez","poster":"thensanity"},{"comment_id":"729952","content":"Selected Answer: A\naaaaaaaaa","poster":"michaldavid","timestamp":"1669699740.0","upvote_count":"4"},{"poster":"CloudHandsOn","upvote_count":"2","comment_id":"725794","content":"I believe the answer is A.\nWe can set TTL in dynamoDB to remove items","timestamp":"1669290480.0"},{"comment_id":"725256","timestamp":"1669220400.0","poster":"kapil206001","content":"A\nhttps://aws.amazon.com/blogs/database/automatically-archive-items-to-s3-using-dynamodb-time-to-live-with-aws-lambda-and-amazon-kinesis-firehose/","upvote_count":"3"},{"timestamp":"1669044060.0","poster":"sionita","content":"A- TTL and a DynamoDB stream","upvote_count":"3","comment_id":"723694"},{"content":"Selected Answer: C\nccccccccc","poster":"dark_cherrymon","upvote_count":"1","comment_id":"723626","timestamp":"1669041660.0"}]}],"exam":{"name":"AWS Certified Developer Associate","lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":true,"id":25,"isImplemented":true,"isBeta":false,"numberOfQuestions":443},"currentPage":15},"__N_SSP":true}