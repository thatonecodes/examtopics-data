{"pageProps":{"questions":[{"id":"nnYHcWZXmC0c6EwFKhbW","topic":"1","isMC":true,"question_images":[],"discussion":[{"content":"Correct answer is B as Kinesis Producer Library (KPL) is a wrapper over Kinesis Agent provides the ability to buffer, batch and retry functionality and helps achieve high write throughput. \n\nThe Amazon Kinesis Producer Library (KPL) simplifies the producer application development by enabling developers to achieve high write throughput to one or more Kinesis data streams. The KPL is an easy to use, highly configurable library that you install on your hosts. It acts as an intermediary between your producer application code and the Kinesis Streams API actions. \n\nThe KPL can help build high-performance producers. Consider a situation where your Amazon EC2 instances serve as a proxy for collecting 100-byte events from hundreds or thousands of low power devices and writing records into a Kinesis data stream. These EC2 instances must each write thousands of events per second to your data stream. To achieve the throughput needed, producers must implement complicated logic, such as batching or multithreading, in addition to retry logic and record de-aggregation at the consumer side. The KPL performs all of these tasks for you.","comment_id":"705772","upvote_count":"10","comments":[{"poster":"cloudlearnerhere","upvote_count":"3","comments":[{"poster":"cloudlearnerhere","upvote_count":"3","timestamp":"1666891980.0","comment_id":"705774","content":"The KPL provides the following features out of the box:\n\n Batching of puts using PutRecords (the Collector in the architecture diagram)\n Tracking of record age and enforcement of maximum buffering times (all components)\n Per-shard record aggregation (the Aggregator)\n Retries in case of errors, with ability to distinguish between retryable and non-retryable errors (the Retrier)\n Per-shard rate limiting to prevent excessive and pointless spamming (the Limiter)\n Useful metrics and a highly efficient CloudWatch client"}],"content":"Because the KPL may buffer records before sending them to Kinesis Data Streams, it does not force the caller application to block and wait for a confirmation that the record has arrived at the server before continuing execution. A call to put a record into the KPL always returns immediately and does not wait for the record to be sent or a response to be received from the server. Instead, a Future object is created that receives the result of sending the record to Kinesis Data Streams at a later time. This is the same behavior as asynchronous clients in the AWS SDK.","comment_id":"705773","timestamp":"1666891980.0"}],"poster":"cloudlearnerhere","timestamp":"1666891920.0"},{"comment_id":"886523","upvote_count":"2","timestamp":"1682959800.0","content":"B: I passed the test","poster":"pk349"},{"content":"Selected Answer: B\nAnswer is B","comment_id":"643509","timestamp":"1659816900.0","poster":"rocky48","upvote_count":"2"},{"content":"B.\nhttps://docs.aws.amazon.com/ja_jp/streams/latest/dev/developing-producers-with-kpl.html","poster":"wata9821","timestamp":"1651269420.0","comment_id":"594710","upvote_count":"4"}],"answer_ET":"B","choices":{"C":"Kinesis Data Firehose","A":"Kinesis Agent","B":"Kinesis Producer Library (KPL)","D":"Kinesis SDK"},"question_id":6,"url":"https://www.examtopics.com/discussions/amazon/view/74931-exam-aws-certified-data-analytics-specialty-topic-1-question/","answer_images":[],"question_text":"A transport company wants to track vehicular movements by capturing geolocation records. The records are 10 B in size and up to 10,000 records are captured each second. Data transmission delays of a few minutes are acceptable, considering unreliable network conditions. The transport company decided to use\nAmazon Kinesis Data Streams to ingest the data. The company is looking for a reliable mechanism to send data to Kinesis Data Streams while maximizing the throughput efficiency of the Kinesis shards.\nWhich solution will meet the company's requirements?","answers_community":["B (100%)"],"answer_description":"Reference:\nhttps://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-sdk.htmls","timestamp":"2022-04-29 23:57:00","unix_timestamp":1651269420,"exam_id":20,"answer":"B"},{"id":"2J8k1RMARCSl8pbw2wyT","answer_images":[],"isMC":true,"answer_description":"","topic":"1","exam_id":20,"unix_timestamp":1630137360,"question_id":7,"answer_ET":"C","answers_community":["C (58%)","A (27%)","B (15%)"],"choices":{"A":"Geospatial chart","D":"Tree map","C":"Heat map","B":"Line chart"},"question_images":[],"discussion":[{"timestamp":"1632252540.0","comment_id":"433664","upvote_count":"25","content":"Answer is C\nhttps://docs.aws.amazon.com/quicksight/latest/user/heat-map.html\nUse a heat map if you want to identify trends and outliers, because the use of color makes these easier to spot.","poster":"SamChan"},{"timestamp":"1666892340.0","content":"Selected Answer: C\nCorrect answer is C as Heat Map can help measure the intersection between two dimensions i.e cities and stores, with color-coding to easily differentiate the patterns.\n\nUse heat maps to show a measure for the intersection of two dimensions, with color-coding to easily differentiate where values fall in the range. Heat maps can also be used to show the count of values for the intersection of the two dimensions.\n\nEach rectangle on a heat map represents the value for the specified measure for the intersection of the selected dimensions. Rectangle color represents where the value falls in the range for the measure, with darker colors indicating higher values and lighter colors indicating lower ones.\n\nHeat maps and pivot tables display data in a similar tabular fashion. Use a heat map if you want to identify trends and outliers, because the use of color makes these easier to spot. Use a pivot table if you want to further analyze data on the visual, for example by changing column sort order or applying aggregate functions across rows or columns.","poster":"cloudlearnerhere","comment_id":"705779","upvote_count":"6"},{"content":"C: I passed the test","comment_id":"886584","upvote_count":"1","timestamp":"1682965500.0","poster":"pk349"},{"content":"Correct ans is C","poster":"[Removed]","timestamp":"1681877760.0","upvote_count":"1","comment_id":"874267"},{"poster":"milofficial","upvote_count":"4","content":"Selected Answer: C\nC is the right answer.\nWe have the requirements \"easily identify revenue trends across cities and stores\" and \"identify outliers\"\nA: first requirement not fulfilled, there are more stores than cities so it is possible that two stores have the sam postal code, which means they are not distinguishable with geospatial charts\nB - first requirement not fulfilled, a line chart with 15 lines is impossible to understand \"easily\"\nC - both requirements fulfilled, it's easy to tell apart stores / cities and outliers are easily visible, also you can view trends over time\nD - first requirement not fulfilled, it's not possible to see trends over time","timestamp":"1675524960.0","comment_id":"798111"},{"content":"Answer is B \nThe best type of visualization for the sales team's requirements is a line chart. A line chart provides an easy way to identify revenue trends across cities and stores, as well as outliers that need to be examined with further analysis. It is also suited to compare multiple sets of data easily. With a line chart, users can simply follow the line to identify where the revenue for each city and store is trending up or down.","comment_id":"794387","upvote_count":"1","poster":"DB_Ram","timestamp":"1675181640.0"},{"content":"Selected Answer: C\nUse heat maps to show a measure for the intersection of two dimensions, with color-coding to easily differentiate where values fall in the range. Heat maps can also be used to show the count of values for the intersection of the two dimensions.","upvote_count":"1","poster":"Ody__","comment_id":"770225","timestamp":"1673258520.0"},{"poster":"rocky48","content":"Selected Answer: C\nOption \"C\". \nQuote below from AWS :-\n\"Heat maps and pivot tables display data in a similar tabular fashion. Use a heat map if you want to identify trends and outliers, because the use of color makes these easier to spot. Use a pivot table if you want to further analyze data on the visual, for example by changing column sort order or applying aggregate functions across rows or columns.\"","timestamp":"1670735640.0","upvote_count":"1","comment_id":"741427"},{"content":"Selected Answer: A\nIf the option is base on product or store (only) then I select heat map, but in here we have location information","comment_id":"738776","timestamp":"1670488860.0","upvote_count":"1","poster":"siju13"},{"timestamp":"1668452520.0","upvote_count":"2","poster":"alinato","content":"Selected Answer: B\nB: All other options fail to show a trend over time. Outliers are also clearly visible in line chart.","comment_id":"718197"},{"poster":"b33f","upvote_count":"1","comment_id":"712845","timestamp":"1667802420.0","content":"Selected Answer: C\nI vote for C.\n\"Use a heat map if you want to identify trends and outliers, because the use of color makes these easier to spot.\"\nhttps://docs.aws.amazon.com/quicksight/latest/user/heat-map.html\n\nI don't think A is the answer because a geospatial chart would display the total revenue in each city and would not be able to identify outliers at the store level."},{"content":"Selected Answer: C\nHeat map - \nthe rectangle gives - value (revenue range per city can be identified) , trend/outlier (darkness of the colour)","comment_id":"673534","timestamp":"1663610100.0","poster":"hary104","upvote_count":"1"},{"comment_id":"668537","upvote_count":"2","timestamp":"1663119840.0","poster":"he11ow0rId","content":"Selected Answer: B\nmy vote for B"},{"content":"Selected Answer: A\nAnswer is A","poster":"rocky48","comments":[{"upvote_count":"1","comment_id":"741424","timestamp":"1670735580.0","poster":"rocky48","content":"Updated answer => Option \"C\". \nQuote below from AWS :-\n\"Heat maps and pivot tables display data in a similar tabular fashion. Use a heat map if you want to identify trends and outliers, because the use of color makes these easier to spot. Use a pivot table if you want to further analyze data on the visual, for example by changing column sort order or applying aggregate functions across rows or columns.\""}],"upvote_count":"2","timestamp":"1658380620.0","comment_id":"634370"},{"comment_id":"627599","timestamp":"1657051500.0","content":"Selected Answer: A\nI suppose ans should be A.\nYou can create two types of maps in Amazon QuickSight: point maps and filled maps. Point maps show the difference between data values for each location by size. Filled maps show the difference between data values for each location by varying shades of color.\n\nhttps://docs.aws.amazon.com/quicksight/latest/user/geospatial-charts.html","poster":"Wesley27","upvote_count":"3"},{"comment_id":"616617","comments":[{"upvote_count":"2","comment_id":"623745","poster":"Ramshizzle","timestamp":"1656393420.0","content":"To add to my earlier suggestion. I've also done AWS-licensed practice exams and similar questions also stated to use geospatial charts. If you see: \"across locations on a map\" then think \"geospatial chart\""}],"upvote_count":"1","poster":"Ramshizzle","content":"Selected Answer: A\nI think it should be A. The questions states that it wants to quickly identify patterns across locations, this is what a geospatial chart is for. I would use colors and circle size to quickly show the patterns.","timestamp":"1655280780.0"},{"content":"It's B. I.e. line chart. You can display revenue patterns with each line representing each location. A is ruled out as you can't show any pattern using Geospacial. Also, there are multiple locations within each city so this type of chart won't make sense. C and D are ruled out as they can't show any pattern.","timestamp":"1653644400.0","comment_id":"608015","upvote_count":"1","poster":"certificationJunkie"},{"poster":"f4bi4n","comment_id":"604742","timestamp":"1653116580.0","content":"Selected Answer: C\nB is not working as you cant have more than 1 line in a chart. You would need 16 charts to compare them. So C makes the most sense here.","upvote_count":"1"},{"content":"Answer : C","comment_id":"595256","upvote_count":"2","poster":"jrheen","timestamp":"1651349640.0"},{"comment_id":"559013","upvote_count":"2","content":"to identify outliers heatmap is the best reporting format.","timestamp":"1646167740.0","poster":"Agn3001"},{"content":"Answer is A, not C\nThe key is the requirement that \"across cities and locations\".","comments":[{"comment_id":"673112","upvote_count":"1","poster":"allanm","timestamp":"1663578720.0","content":"Just because you have cities and locations doesn't mean it's automatically a geospatial map. The easiest way to identify trend analysis across a dataset is to provide a heat map across your dimensions.\n\nAnswer is C"}],"upvote_count":"2","comment_id":"552832","timestamp":"1645445580.0","poster":"Japanese1"},{"comment_id":"533212","upvote_count":"2","timestamp":"1643227080.0","content":"A is the right answe","poster":"jamesbond1983"},{"timestamp":"1642979580.0","content":"Answer is C","poster":"vkbajoria","comment_id":"530890","upvote_count":"1"},{"comment_id":"520704","content":"Why not A? With geospatial the size of the circle will help in identifying the outliers and also provide numbers next to it.","upvote_count":"3","poster":"Shivanikats","timestamp":"1641799500.0"},{"poster":"awsmani","upvote_count":"4","timestamp":"1638282900.0","comment_id":"490764","content":"it is \"C\". Quote below from AWS\n\"Heat maps and pivot tables display data in a similar tabular fashion. Use a heat map if you want to identify trends and outliers, because the use of color makes these easier to spot. Use a pivot table if you want to further analyze data on the visual, for example by changing column sort order or applying aggregate functions across rows or columns."},{"poster":"arun004","content":"actually C will be useful if only need to visualize outliers but A can visualize total revenue for each city across other locations and also they can easily identifies outliers among them using the size of circle mark","timestamp":"1637540700.0","upvote_count":"4","comment_id":"483752"},{"upvote_count":"3","comment_id":"478440","comments":[{"comments":[{"upvote_count":"1","poster":"f4bi4n","comment_id":"604741","timestamp":"1653116520.0","content":"I would agree if you could create more than 1 line in a chart. Then B would make sense, but with only one location per chart, you would need 16 charts. So C makes the most sense here."}],"content":"My exact thoughts too with \"Patterns & Outliers\". B is answer for me","comment_id":"499482","upvote_count":"1","poster":"tobsam","timestamp":"1639236660.0"}],"timestamp":"1636946340.0","content":"I am little confused. Following are the important factors\n* 16 location across cities\n* Revenue patterns\n* Anomaly detection \nOption D is out \nOption A and C support geo location but not revenue patterns and outliers.\nSo I would argue line chart for each location and cities which show the revenue pattern and outliers","poster":"attaraya"},{"comment_id":"475250","poster":"Chints01","content":"Answer should be A as the question asks for easy identification of revenue across cities... C also makes sense but then the geographical information will be lost","upvote_count":"4","timestamp":"1636526460.0"},{"content":"its C\nhttps://docs.aws.amazon.com/quicksight/latest/user/heat-map.html","comment_id":"439351","timestamp":"1635352440.0","upvote_count":"1","poster":"ITalica"},{"comment_id":"439293","upvote_count":"1","timestamp":"1633661220.0","poster":"ITalica","content":"Answer is A"}],"answer":"C","timestamp":"2021-08-28 09:56:00","question_text":"A retail company has 15 stores across 6 cities in the United States. Once a month, the sales team requests a visualization in Amazon QuickSight that provides the ability to easily identify revenue trends across cities and stores. The visualization also helps identify outliers that need to be examined with further analysis.\nWhich visual type in QuickSight meets the sales team's requirements?","url":"https://www.examtopics.com/discussions/amazon/view/60900-exam-aws-certified-data-analytics-specialty-topic-1-question/"},{"id":"W5Ke51EluUqzJVwhf0GC","isMC":true,"question_id":8,"url":"https://www.examtopics.com/discussions/amazon/view/60189-exam-aws-certified-data-analytics-specialty-topic-1-question/","question_images":[],"choices":{"C":"Use Amazon Redshift federated queries to join the data sources. Use Amazon QuickSight to generate the mobile dashboards.","B":"Use AWS Lake Formation to migrate the data sources into Amazon S3. Use Amazon QuickSight to generate the mobile dashboards.","D":"Use Amazon QuickSight to connect to the data sources and generate the mobile dashboards.","A":"Use Amazon Athena federated queries to join the data sources. Use Amazon QuickSight to generate the mobile dashboards."},"answer_ET":"D","answer_images":[],"unix_timestamp":1629583440,"topic":"1","exam_id":20,"answer_description":"","answers_community":["D (100%)"],"question_text":"A marketing company has data in Salesforce, MySQL, and Amazon S3. The company wants to use data from these three locations and create mobile dashboards for its users. The company is unsure how it should create the dashboards and needs a solution with the least possible customization and coding.\nWhich solution meets these requirements?","discussion":[{"upvote_count":"14","timestamp":"1633536420.0","poster":"SamChan","content":"I vote for D\nIt haven't mention the requirement of data joining, and it support salesforce as data source\nhttps://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-salesforce.html","comment_id":"431385"},{"timestamp":"1666892460.0","comment_id":"705781","content":"Correct answer is D as QuickSight supports all the above data sources and can help create the dashboards and needs a solution with the least possible customization and coding. \n\nhttps://docs.aws.amazon.com/quicksight/latest/user/supported-data-sources.html\n\n\nOptions A, B & C are wrong as they would not support all data sources.","upvote_count":"7","poster":"cloudlearnerhere"},{"content":"Selected Answer: D\nAmazon QuickSight announced the launch of Cross Data Source Join, which allows you to connect to multiple data sources and join data across these sources in Amazon QuickSight directly to create data sets used to build dashboards.","upvote_count":"1","poster":"whenthan","comment_id":"971576","timestamp":"1691110200.0"},{"timestamp":"1682965560.0","content":"D: I passed the test","upvote_count":"2","comment_id":"886585","poster":"pk349"},{"timestamp":"1675525080.0","content":"Selected Answer: D\nD is right. Least operational overhead","comment_id":"798114","upvote_count":"2","poster":"milofficial"},{"comment_id":"781582","poster":"Erso","content":"D is the answer https://docs.aws.amazon.com/quicksight/latest/user/supported-data-sources.html","upvote_count":"1","timestamp":"1674160680.0"},{"poster":"APIsche","comment_id":"647981","content":"Definitely D","upvote_count":"2","timestamp":"1660723380.0"},{"timestamp":"1656713880.0","poster":"Sen5476","content":"Ans is A: Athena federated query can connect to JDBC compliant data sources along with S3. It can join or union the data to provide single dataset for Quicksight,\nB and C: Requires more effort and coding.\nD: I'm not sure if Quicksight can join or consolidate the results from multiple sources into single dataset","comment_id":"625875","upvote_count":"1"},{"content":"Selected Answer: D\nD: Quicksight connects to all of the mentioned data sources","timestamp":"1653924840.0","upvote_count":"3","poster":"Ob1KN0B","comment_id":"609281"},{"upvote_count":"1","timestamp":"1653645120.0","content":"D. Quicksight has capability to connect to multiple sources at the same time and generation visualization.","comment_id":"608018","poster":"certificationJunkie"},{"upvote_count":"1","content":"Answer: D","comment_id":"595260","timestamp":"1651349820.0","poster":"jrheen"},{"upvote_count":"2","poster":"dhuna","comment_id":"491844","content":"Vote for D. https://aws.amazon.com/blogs/big-data/joining-across-data-sources-on-amazon-quicksight/","timestamp":"1638379860.0"},{"poster":"Thiya","timestamp":"1638036960.0","upvote_count":"1","content":"Answer is D, QuickSight support cross-data source joins across all three data sources mentioned in the question.","comment_id":"488381"},{"upvote_count":"2","poster":"aws2019","timestamp":"1637356860.0","content":"Ans is \"D\" Quick sight has integration capabilities with all 3","comment_id":"482104"},{"comment_id":"475927","upvote_count":"1","timestamp":"1636596900.0","poster":"Chints01","content":"the answer should be A leveraging Athena's federated query feature. Scroll down (almost) to the the end of this blog to see the screenshot showing which data sources can be connected via Athena"},{"timestamp":"1636109160.0","comment_id":"440277","content":"\"the least possible customization and coding\" - for me this points to option D","poster":"virendrapsingh","upvote_count":"3"},{"comment_id":"431234","poster":"sk71","timestamp":"1633138080.0","upvote_count":"3","content":"Why not D?\nhttps://aws.amazon.com/blogs/big-data/joining-across-data-sources-on-amazon-quicksight/"},{"comments":[{"poster":"AnkAro","upvote_count":"5","timestamp":"1635178080.0","comment_id":"436417","content":"Your link doesn't explicitly indicate join capability with Salesforce. whereas this other link does: https://aws.amazon.com/blogs/big-data/joining-across-data-sources-on-amazon-quicksight/\nit appears that D is the correct option."}],"content":"I think the answer is A\nI quessed it from this source : https://aws.amazon.com/ko/blogs/big-data/accessing-and-visualizing-data-from-multiple-data-sources-with-amazon-athena-and-amazon-quicksight/","comment_id":"428952","timestamp":"1632142380.0","upvote_count":"4","poster":"Zzang"}],"timestamp":"2021-08-22 00:04:00","answer":"D"},{"id":"PHCFtzQOnNJCrMp3EzfP","topic":"1","answer_ET":"D","timestamp":"2021-08-22 10:45:00","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/60219-exam-aws-certified-data-analytics-specialty-topic-1-question/","exam_id":20,"answer_description":"","discussion":[{"upvote_count":"11","poster":"SamChan","timestamp":"1633419540.0","content":"Answer is B\nhttps://docs.aws.amazon.com/redshift/latest/dg/concurrency-scaling.html\nYou manage which queries are sent to the concurrency-scaling cluster by configuring WLM queues. When you turn on concurrency scaling, eligible queries are sent to the concurrency-scaling cluster instead of waiting in a queue.","comment_id":"433672"},{"comment_id":"434279","content":"correct answer is B. (https://docs.aws.amazon.com/redshift/latest/dg/concurrency-scaling.html)\nD is wrong because it works only for manual WLM config. (https://docs.aws.amazon.com/redshift/latest/dg/wlm-queue-hopping.html)","timestamp":"1636263180.0","upvote_count":"9","poster":"imgeek"},{"timestamp":"1682965620.0","comment_id":"886587","content":"B: I passed the test","poster":"pk349","upvote_count":"1"},{"timestamp":"1666892580.0","content":"Correct answer is B as concurrency scaling can help scale the avoiding query queuing without impacting latency and the query times of other teams.\n\nWith the Concurrency Scaling feature, you can support virtually unlimited concurrent users and concurrent queries, with consistently fast query performance.When you turn on concurrency scaling, Amazon Redshift automatically adds additional cluster capacity to process an increase in both read and write queries. Users see the most current data, whether the queries run on the main cluster or a concurrency-scaling cluster. You're charged for concurrency-scaling clusters only for the time they're actively running queries.\n\nOption D is wrong as workload management query queue hopping works only with manual WLM config.\n\nOption A is wrong as it does not help avoid query queuing.\n\nOption C is wrong as concurrency scaling does the same automatically.","comment_id":"705784","upvote_count":"3","poster":"cloudlearnerhere"},{"content":"Selected Answer: B\nAnswer is B","timestamp":"1659817380.0","comment_id":"643514","upvote_count":"1","poster":"rocky48"},{"content":"Selected Answer: B\nAnswer is B","comment_id":"571552","poster":"moon2351","upvote_count":"1","timestamp":"1647774300.0"},{"comment_id":"429132","poster":"taizo777","upvote_count":"1","timestamp":"1632634680.0","content":"I think B is right answer"}],"answer":"B","question_text":"A company uses Amazon Redshift for its data warehousing needs. ETL jobs run every night to load data, apply business rules, and create aggregate tables for reporting. The company's data analysis, data science, and business intelligence teams use the data warehouse during regular business hours. The workload management is set to auto, and separate queues exist for each team with the priority set to NORMAL.\nRecently, a sudden spike of read queries from the data analysis team has occurred at least twice daily, and queries wait in line for cluster resources. The company needs a solution that enables the data analysis team to avoid query queuing without impacting latency and the query times of other teams.\nWhich solution meets these requirements?","question_images":[],"choices":{"A":"Increase the query priority to HIGHEST for the data analysis queue.","B":"Configure the data analysis queue to enable concurrency scaling.","D":"Use workload management query queue hopping to route the query to the next matching queue.","C":"Create a query monitoring rule to add more cluster capacity for the data analysis queue when queries are waiting for resources."},"isMC":true,"answer_images":[],"question_id":9,"unix_timestamp":1629621900},{"id":"omZnmqnFV8IdhdrIg4RN","choices":{"C":"Connect Amazon Kinesis Data Firehose to analyze the stream data by using an AWS Lambda function. Save the output to DynamoDB by using the default output from Kinesis Data Firehose.","B":"Connect Amazon Kinesis Data Analytics to analyze the stream data. Save the output to DynamoDB by using an AWS Lambda function.","D":"Connect Amazon Kinesis Data Firehose to analyze the stream data by using an AWS Lambda function. Save the data to Amazon S3. Then run an AWS Glue job on schedule to ingest the data into DynamoDB.","A":"Connect Amazon Kinesis Data Analytics to analyze the stream data. Save the output to DynamoDB by using the default output from Kinesis Data Analytics."},"discussion":[{"content":"It is B. https://aws.amazon.com/about-aws/whats-new/2017/12/amazon-kinesis-data-analytics-can-now-output-real-time-sql-results-to-aws-lambda/","timestamp":"1638197460.0","upvote_count":"15","poster":"awsmani","comment_id":"489982"},{"comment_id":"705786","content":"Correct answer is B as Kinesis Data Analytics would help generate near-real time and using Lambda function the output can be saved to DynamoDB. Using AWS Lambda as a destination allows you to more easily perform post-processing of your SQL results before sending them to a final destination.Lambda functions can deliver analytic information to a variety of AWS services and other destinations,\n\nOption A is wrong as Kinesis Data Analytics does not support DynamoDB as its default output destination.\n\nOptions C & D are wrong as Kinesis Data Firehose does not support DynamoDB as its default output destination.","timestamp":"1666892760.0","upvote_count":"9","poster":"cloudlearnerhere"},{"comment_id":"886588","poster":"pk349","timestamp":"1682965620.0","content":"B: I passed the test","upvote_count":"1"},{"upvote_count":"1","comment_id":"789006","content":"Kinesis data analytic can send output to lambda and lambda send it DynamoDB\n\nhttps://aws.amazon.com/about-aws/whats-new/2017/12/amazon-kinesis-data-analytics-can-now-output-real-time-sql-results-to-aws-lambda/","poster":"Chelseajcole","timestamp":"1674758340.0"},{"upvote_count":"1","timestamp":"1671576900.0","comment_id":"751604","content":"Answer: B","poster":"[Removed]"},{"comments":[{"content":"If you want to query/analyse streaming data in near real time you need to use KDA rather than lambda.","comment_id":"721481","timestamp":"1668795240.0","upvote_count":"2","poster":"allanm"}],"poster":"virginia167","content":"It’s C https://www.teamdatascience.com/post/how-to-write-kinesis-data-stream-to-dynamodb","timestamp":"1667767800.0","upvote_count":"1","comment_id":"712642"},{"comment_id":"643515","timestamp":"1659817440.0","upvote_count":"1","content":"Selected Answer: B\nAnswer: B","poster":"rocky48"},{"poster":"Bik000","upvote_count":"1","timestamp":"1653133080.0","content":"Selected Answer: B\nI think the Answer should be B","comment_id":"604868"},{"comments":[{"poster":"WLELEL2","timestamp":"1645697280.0","content":"Glue is not near-real time","upvote_count":"2","comment_id":"555176"},{"timestamp":"1652168520.0","comment_id":"599453","upvote_count":"1","poster":"MWL","content":"KDF can do some data transformation, but if you want to do analysis, DF is not suitable."}],"content":"Why not D ?? \"The insights must be extracted in near-real time\" and KDF is the right candidate for this.","poster":"sanpak","comment_id":"511673","timestamp":"1640738340.0","upvote_count":"2"},{"comment_id":"442027","poster":"ovilla","upvote_count":"1","content":"I agree with B","timestamp":"1635816840.0"},{"timestamp":"1635194160.0","poster":"VAG1595","upvote_count":"2","content":"Answer: B","comment_id":"436873"},{"comment_id":"436477","timestamp":"1634450940.0","comments":[{"content":"*answer is B sorry for confusion","timestamp":"1635053760.0","upvote_count":"1","comment_id":"436479","poster":"itsharpreet"}],"poster":"itsharpreet","upvote_count":"2","content":"I think answer is C. Kinesis analytics can help in performing near real time analysis. Then to storing it to DDB. Kinesis analytics can send data to lambda and lambda can help write to DDB table."},{"comment_id":"436406","content":"why not b ?","upvote_count":"1","timestamp":"1633248120.0","poster":"Gekko"},{"comments":[{"upvote_count":"3","timestamp":"1640568540.0","comment_id":"509939","poster":"justsaysid","content":"C is ruled out because KDF default output does not support direct write to DynamoDB."}],"comment_id":"429141","content":"I agree C is answer","poster":"taizo777","upvote_count":"3","timestamp":"1632555300.0"}],"answers_community":["B (100%)"],"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/60222-exam-aws-certified-data-analytics-specialty-topic-1-question/","answer_description":"","question_images":[],"answer_images":[],"unix_timestamp":1629622140,"topic":"1","exam_id":20,"answer_ET":"C","question_text":"A company owns facilities with IoT devices installed across the world. The company is using Amazon Kinesis Data Streams to stream data from the devices to\nAmazon S3. The company's operations team wants to get insights from the IoT data to monitor data quality at ingestion. The insights need to be derived in near- real time, and the output must be logged to Amazon DynamoDB for further analysis.\nWhich solution meets these requirements?","question_id":10,"isMC":true,"timestamp":"2021-08-22 10:49:00"}],"exam":{"isMCOnly":true,"isBeta":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Data Analytics - Specialty","numberOfQuestions":164,"id":20,"isImplemented":true,"provider":"Amazon"},"currentPage":2},"__N_SSP":true}