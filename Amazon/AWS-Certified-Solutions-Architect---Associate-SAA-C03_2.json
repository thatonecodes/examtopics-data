{"pageProps":{"questions":[{"id":"C48Gt8cpHH1FPWT0MXOQ","exam_id":31,"answer_ET":"D","choices":{"D":"Use DynamoDB global tables for automatic multi-Region replication. Deploy tables in multiple AWS Regions. Use provisioned capacity mode. Enable auto scaling.","C":"Create DynamoDB tables in multiple AWS Regions. Use on-demand capacity mode. Use DynamoDB Streams for Cross-Region Replication between Regions.","A":"Create DynamoDB tables in a single AWS Region. Use on-demand capacity mode. Use global tables to replicate data across multiple Regions.","B":"Use DynamoDB Accelerator (DAX) to cache frequently accessed data. Deploy tables in a single AWS Region and enable auto scaling. Configure Cross-Region Replication manually to additional Regions."},"discussion":[{"timestamp":"1733549700.0","upvote_count":"2","poster":"trinh_le","comment_id":"1323020","content":"Selected Answer: D\nFollowing keywords\nrobust: provisioned capacity reduces cost\ncontinuously available: global tables\nresilient: multiple regions enhances available"},{"timestamp":"1732696020.0","poster":"Cpso","upvote_count":"2","content":"Selected Answer: D\nc &d can do 2 ways rep. But C need user logic to handle conflict ,so it not robust","comment_id":"1318505"},{"upvote_count":"2","timestamp":"1732612860.0","comment_id":"1317992","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/capacity.html","poster":"78b9037"},{"content":"Selected Answer: C\nDynamoDB Streams for replication are less expensive than Global tables. \nOn-demand capacity mode can be less expensive than provisionned mode. \nMulti region deployment ensure high availability.","timestamp":"1731061800.0","upvote_count":"1","comment_id":"1308704","poster":"striker89"},{"poster":"Bwhizzy","content":"Selected Answer: D\nD. Use DynamoDB global tables for automatic multi-Region replication. Deploy tables in multiple AWS Regions. Use provisioned capacity mode. Enable auto scaling.\n\nExplanation:\nDynamoDB global tables automatically replicate data across multiple Regions, ensuring that the data is available and consistent across all Regions. This provides resilience and high availability by allowing users in different geographical locations to access data from the closest Region.\n\nProvisioned capacity mode allows you to pre-allocate read and write capacity units, which can result in cost savings over on-demand capacity mode if the traffic is predictable. Additionally, auto scaling can be enabled to dynamically adjust the capacity based on the actual traffic, ensuring that you only pay for the capacity that you need.\n\nMulti-Region deployment improves the resilience of the system. If a failure occurs in one Region, another Region can seamlessly take over, ensuring an uninterrupted gaming experience.","comments":[{"comment_id":"1341740","content":"\"if the traffic is predictable\". Good point, but how do you know this from the question?","upvote_count":"1","timestamp":"1737040740.0","poster":"GOTJ"}],"upvote_count":"4","timestamp":"1729362780.0","comment_id":"1300124"}],"question_text":"An online gaming company is transitioning user data storage to Amazon DynamoDB to support the company's growing user base. The current architecture includes DynamoDB tables that contain user profiles, achievements, and in-game transactions.\n\nThe company needs to design a robust, continuously available, and resilient DynamoDB architecture to maintain a seamless gaming experience for users.\n\nWhich solution will meet these requirements MOST cost-effectively?","timestamp":"2024-10-07 13:03:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/148808-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":6,"unix_timestamp":1728298980,"answers_community":["D (91%)","9%"],"answer_images":[],"answer_description":"","answer":"D","isMC":true,"question_images":[]},{"id":"UsVhjbJszZNS7ByxWpaj","timestamp":"2024-10-07 13:10:00","answer_ET":"B","answers_community":["B (100%)"],"answer_description":"","choices":{"C":"Copy the data from Amazon S3 to Amazon FSx for Windows File Server. Configure an Amazon FSx File Gateway to provide storage for the on-premises application.","B":"Configure an Amazon S3 File Gateway to provide storage for the on-premises application.","A":"Use Mountpoint for Amazon S3 to access the data in Amazon S3 for the on-premises application.","D":"Configure an on-premises file server. Use the Amazon S3 API to connect to S3 storage. Configure the application to access the storage from the on-premises file server."},"question_text":"A company runs its media rendering application on premises. The company wants to reduce storage costs and has moved all data to Amazon S3. The on-premises rendering application needs low-latency access to storage.\n\nThe company needs to design a storage solution for the application. The storage solution must maintain the desired application performance.\n\nWhich storage solution will meet these requirements in the MOST cost-effective way?","unix_timestamp":1728299400,"url":"https://www.examtopics.com/discussions/amazon/view/148809-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"answer":"B","topic":"1","exam_id":31,"answer_images":[],"question_id":7,"discussion":[{"comment_id":"1338220","upvote_count":"4","timestamp":"1736406660.0","poster":"LeonSauveterre","content":"Selected Answer: B\nA - Mountpoint is not designed for on-premises environments or low-latency access; it works well for cloud-based applications.\nB - Amazon S3 File Gateway provides low-latency, on-premises access to data stored in Amazon S3 through a file-based interface. It caches frequently accessed data locally to reduce latency.\nC - Copying data to FSx increases costs, as FSx storage is more expensive than S3. Let alone unnecessary complexity.\nD - Direct interaction with S3 introduces higher latency for on-premises applications and lacks local caching."},{"comment_id":"1316365","poster":"Americanman","content":"Amazon S3 File Gateway enables your existing file-based applications, devices, and workflows to use Amazon S3, without modification. Amazon S3 File Gateway securely and durably stores both file contents and metadata as objects, while providing your on-premises applications low-latency access to cached data.","timestamp":"1732287540.0","upvote_count":"2"},{"poster":"Bwhizzy","comment_id":"1300126","content":"Selected Answer: B\nB. Configure an Amazon S3 File Gateway to provide storage for the on-premises application.\n\nExplanation:\nAmazon S3 File Gateway provides a way for on-premises applications to access objects stored in Amazon S3 as files. It caches frequently accessed data locally, which ensures low-latency access to the data. This is crucial for maintaining the performance of the rendering application.\n\nBy keeping the data in Amazon S3, the company benefits from lower storage costs compared to using other storage services like Amazon FSx, while still providing the necessary performance for the on-premises application through the local caching capabilities of the File Gateway.\n\nThe File Gateway seamlessly integrates with Amazon S3, allowing the application to access data using standard file protocols like NFS or SMB, which simplifies the setup.","upvote_count":"3","timestamp":"1729363080.0"}],"question_images":[]},{"id":"QvD5PcmUDlQL5TDkZBd9","question_images":[],"answer_ET":"C","question_text":"A company hosts its enterprise resource planning (ERP) system in the us-east-1 Region. The system runs on Amazon EC2 instances. Customers use a public API that is hosted on the EC2 instances to exchange information with the ERP system. International customers report slow API response times from their data centers.\n\nWhich solution will improve response times for the international customers MOST cost-effectively?","answer_description":"","timestamp":"2024-10-07 13:14:00","choices":{"A":"Create an AWS Direct Connect connection that has a public virtual interface (VIF) to provide connectivity from each customer's data center to us-east-1. Route customer API requests by using a Direct Connect gateway to the ERP system API.","B":"Set up an Amazon CloudFront distribution in front of the API. Configure the CachingOptimized managed cache policy to provide improved cache efficiency.","D":"Use AWS Site-to-Site VPN to establish dedicated VPN tunnels between Regions and customer networks. Route traffic to the API over the VPN connections.","C":"Set up AWS Global Accelerator. Configure listeners for the necessary ports. Configure endpoint groups for the appropriate Regions to distribute traffic. Create an endpoint in the group for the API."},"answer":"C","answers_community":["C (59%)","B (41%)"],"discussion":[{"timestamp":"1728935340.0","comments":[{"timestamp":"1731710520.0","content":"While dynamic content typically has low caching potential, CloudFront reduces latency by routing requests to the nearest edge location. There is also TCP Connection Reuse, which is also beneficial for low latency.","comment_id":"1312834","upvote_count":"2","poster":"Sergantus"}],"upvote_count":"11","content":"Selected Answer: C\nCloudFront can reduce response times by caching API responses, but if the API is dynamic and not cacheable, it may not be as effective. Global Accelerator is better for improving latency when caching is not an option.","comment_id":"1297805","poster":"TewatiaAmit"},{"comment_id":"1298949","upvote_count":"10","content":"Selected Answer: B\nCloudFront for Dynamic content (such as API acceleration and dynamic site delivery)","poster":"8621a7c","timestamp":"1729111620.0"},{"timestamp":"1741732320.0","comments":[{"content":"MOST cost-effectively.. this is another reason to use CloudFont...","upvote_count":"1","timestamp":"1741732680.0","poster":"tch","comment_id":"1387667"}],"upvote_count":"1","content":"Selected Answer: B\nHow is AWS Global Accelerator different from Amazon CloudFront?\nAWS Global Accelerator and Amazon CloudFront are separate services that use the AWS global network and its edge locations around the world. CloudFront improves performance for both cacheable content (such as images and videos) and dynamic content (such as API acceleration and dynamic site delivery). Global Accelerator improves performance for a wide range of applications over TCP or UDP by proxying packets at the edge to applications running in one or more AWS Regions. Global Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP, as well as for HTTP use cases that specifically require static IP addresses or deterministic, fast regional failover. Both services integrate with AWS Shield for DDoS protection","poster":"tch","comment_id":"1387666"},{"poster":"FlyingHawk","timestamp":"1737259260.0","content":"Selected Answer: B\nGiven that the ERP system is hosted in us-east-1 and the API is likely HTTP/HTTPS-based, Option B (Amazon CloudFront) is the best solution. CloudFront’s global edge network and caching capabilities will significantly improve response times for international customers while reducing the load on the backend EC2 instances.","comment_id":"1342854","upvote_count":"1"},{"upvote_count":"1","poster":"joanna91","content":"Selected Answer: C\nC. AWS global accelerator is more suitable for cost-effective solutions to improve API respons time for int'l users by using AWS global network to optimize traffic routing. Whereas, D. AWS Cloudfront is less effective for dynamic, real-time API interactions like this ERP system.","timestamp":"1736824560.0","comment_id":"1340143"},{"upvote_count":"2","timestamp":"1736407140.0","content":"Selected Answer: C\nA - Direct Connect requires dedicated connections for each customer, making it expensive and impractical for a public API.\nB - CloudFront improves performance but caching efficiency depends on the API use case. Dynamic & personalized API responses may not benefit significantly from caching. CloudFront is best suited for static content or APIs with predictable responses.\nC - Global Accelerator provides a global static IP address and uses the AWS global network to route traffic optimally, reducing latency for geographically distant users. Unlike CloudFront, it works well in this case because it doesn't rely on caching contents.\nD - VPNs are not ideal for public APIs because they require specific setup for each customer, so high operational overhead.","poster":"LeonSauveterre","comment_id":"1338223"},{"timestamp":"1736106180.0","content":"Selected Answer: C\nI think that the following quote \"to exchange information with the ERP system\" suggest that the clients use the api not only to get, but to add and/or update ERP data. If this is the case, using a Cloudfront distribution for caching should be useless as the add/update operations must be performed by the ERP system itself.\n\nOption \"C\" approach is different: it's \"forcing\" users to access API ERP via AWS routing optimised networks by configuring the current API as an endpoint for the globally distributed endpoints groups (no need to duplicate current infrastructure or setup replication)","poster":"GOTJ","comment_id":"1336856","upvote_count":"2"},{"poster":"Anyio","timestamp":"1735353960.0","content":"Selected Answer: C\nThe correct answer is C.\n\nExplanation:\n\nOption C: Correct. AWS Global Accelerator provides access via the AWS global network, reducing latency and improving performance for globally distributed users. By using Global Accelerator, you can direct global traffic to optimal AWS endpoints, offering lower latency and better connectivity compared to standard internet routing. It achieves this without modifying the API infrastructure, making it a highly cost-effective solution for improving API response times for international users.","upvote_count":"1","comment_id":"1332722"},{"comment_id":"1330388","content":"Selected Answer: B\nMOST cost-effectively - \n(ERP) system in the us-east-1 Region (one region only)\nwill be B\n\nAWS Global Accelerator use case for one or multiple AWS regions!","poster":"tch","upvote_count":"1","timestamp":"1734872100.0"},{"poster":"dragossky","upvote_count":"3","timestamp":"1734291660.0","content":"Selected Answer: C\nC. Set up AWS Global Accelerator. Configure listeners for the necessary ports. Configure endpoint groups for the appropriate Regions to distribute traffic. Create an endpoint in the group for the API.","comment_id":"1327031"},{"upvote_count":"1","comment_id":"1324870","content":"Selected Answer: B\nCloudfront used for API acceleration and Dynamic content delivery","timestamp":"1733895840.0","poster":"DhirajBansal"}],"exam_id":31,"question_id":8,"url":"https://www.examtopics.com/discussions/amazon/view/148810-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1728299640,"answer_images":[],"topic":"1","isMC":true},{"id":"Acx5lfQcNsMCxNsmSY4m","choices":{"C":"Write the survey results data to an Amazon S3 bucket. Use S3 Event Notifications to invoke an AWS Lambda function to read the data and call Amazon Rekognition for sentiment analysis. Store the sentiment analysis results in a second S3 bucket. Use S3 lifecycle policies on each bucket to expire objects after 365 days.","D":"Send the survey results data to an Amazon API Gateway endpoint that is connected to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the SQS queue to invoke an AWS Lambda function that calls Amazon Lex for sentiment analysis and saves the results to an Amazon DynamoDB table. Set the TTL for all records to 365 days in the future.","B":"Send the survey results data to an API that is running on an Amazon EC2 instance. Configure the API to store the survey results as a new record in an Amazon DynamoDB table, call Amazon Comprehend for sentiment analysis, and save the results in a second DynamoDB table. Set the TTL for all records to 365 days in the future.","A":"Send the survey results data to an Amazon API Gateway endpoint that is connected to an Amazon Simple Queue Service (Amazon SQS) queue. Create an AWS Lambda function to poll the SQS queue, call Amazon Comprehend for sentiment analysis, and save the results to an Amazon DynamoDB table. Set the TTL for all records to 365 days in the future."},"answer_description":"","timestamp":"2024-10-07 13:23:00","discussion":[{"poster":"EllenLiu","comment_id":"1331852","upvote_count":"1","timestamp":"1735204320.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/comprehend/latest/dg/what-is.html"},{"content":"Selected Answer: A\nFollowing keywords\nreach thousands of customers every hour: use SQS\nAutomate handle survey: aws comprehen","timestamp":"1733551860.0","upvote_count":"1","comment_id":"1323023","poster":"trinh_le"},{"poster":"siheom","upvote_count":"2","content":"Selected Answer: A\nVOTE A","timestamp":"1732895580.0","comment_id":"1319791"},{"upvote_count":"2","poster":"Changwha","comment_id":"1315201","content":"A. This solution is the most scalable, cost-effective, and tailored to the requirements. It uses Amazon Comprehend for sentiment analysis, leverages serverless architecture, and retains data for 12 months using DynamoDB's TTL feature.","timestamp":"1732100280.0"}],"isMC":true,"exam_id":31,"answer_ET":"A","topic":"1","answer":"A","question_text":"A company tracks customer satisfaction by using surveys that the company hosts on its website. The surveys sometimes reach thousands of customers every hour. Survey results are currently sent in email messages to the company so company employees can manually review results and assess customer sentiment.\n\nThe company wants to automate the customer survey process. Survey results must be available for the previous 12 months.\n\nWhich solution will meet these requirements in the MOST scalable way?","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/148811-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1728300180,"question_images":[],"question_id":9,"answer_images":[]},{"id":"jKbnHQSglm2XXvraJqnt","answers_community":["CD (90%)","10%"],"unix_timestamp":1728300360,"answer":"CD","isMC":true,"question_id":10,"answer_images":[],"answer_description":"","answer_ET":"CD","topic":"1","discussion":[{"timestamp":"1741032600.0","upvote_count":"1","content":"Selected Answer: AC\nThe document deregisters instances from target group. Since they are using IP address type, it won't prevent traffic from reaching the server. Need to work choice A into the answer.","poster":"JoeAWS","comment_id":"1364565"},{"poster":"LeonSauveterre","timestamp":"1736415960.0","content":"Selected Answer: CD\nYOU SHOULD KNOW: The errors occur because the company is trying to patch instances that are still actively serving traffic.\n\nA - Unnecessary when existing tools can handle the issue.\nB - The existing document is not optimized for instances in an IP address type target group, so errors would persist.\nC - This document automates the process of deregistering instances from the ALB during patching and re-registering them afterward, ensuring no traffic is routed to the instances while they are being patched. It directly addresses the issue and adheres to best practices.\nD - Maintenance Windows allow you to define a schedule for patching and ensure instances are temporarily removed from service during the process.\nE - This alone can't de-register and re-register instances.","comment_id":"1338272","upvote_count":"2"},{"poster":"EllenLiu","content":"Selected Answer: CD\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/state-manager-vs-maintenance-windows.html","timestamp":"1735206120.0","upvote_count":"1","comment_id":"1331856"},{"content":"Selected Answer: CD\nhttps://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awsec2-patch-load-balancer-instance.html","comment_id":"1313077","timestamp":"1731767220.0","upvote_count":"3","poster":"bujuman"},{"comment_id":"1312964","upvote_count":"3","content":"Selected Answer: CD\nAnswe is CD","poster":"aragon_saa","timestamp":"1731736980.0"}],"timestamp":"2024-10-07 13:26:00","choices":{"C":"Implement the AWSEC2-PatchLoadBalanacerInstance Systems Manager Automation document to manage the patching process.","D":"Use Systems Manager Maintenance Windows to automatically remove the instances from service to patch the instances.","E":"Configure Systems Manager State Manager to remove the instances from service and manage the patching schedule. Use ALB health checks to re-route traffic.","B":"Continue to use the existing Systems Manager document without changes because it is already optimized to handle instances that are in an IP address type target group behind an ALB.","A":"Change the target type of the target group from IP address type to instance type."},"question_images":[],"question_text":"A company uses AWS Systems Manager for routine management and patching of Amazon EC2 instances. The EC2 instances are in an IP address type target group behind an Application Load Balancer (ALB).\n\nNew security protocols require the company to remove EC2 instances from service during a patch. When the company attempts to follow the security protocol during the next patch, the company receives errors during the patching window.\n\nWhich combination of solutions will resolve the errors? (Choose two.)","exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/148812-exam-aws-certified-solutions-architect-associate-saa-c03/"}],"exam":{"provider":"Amazon","lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Associate SAA-C03","isMCOnly":true,"numberOfQuestions":1019,"id":31,"isImplemented":true,"isBeta":false},"currentPage":2},"__N_SSP":true}