{"pageProps":{"questions":[{"id":"tzqoRrBbGGGcdVinH1Cn","answer_images":[],"answers_community":["B (92%)","8%"],"question_images":[],"answer":"B","exam_id":31,"answer_ET":"B","question_text":"A company has an application that uses Docker containers in its local data center. The application runs on a container host that stores persistent data in a volume on the host. The container instances use the stored persistent data.\n\nThe company wants to move the application to a fully managed service because the company does not want to manage any servers or storage infrastructure.\n\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/132862-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":686,"discussion":[{"timestamp":"1707834900.0","content":"Selected Answer: B\nMounting S3 in Fargate is not supported commonly. You'd have to make it manually. EFS is very well supported with Fargate.\nhttps://stackoverflow.com/questions/66391791/how-to-mount-s3-bucket-to-ecs-fargate-container\n\nhttps://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/storage.html","upvote_count":"8","poster":"Marunio","comment_id":"1149223"},{"timestamp":"1707148140.0","comment_id":"1141242","content":"B looks correct","poster":"Andy_09","upvote_count":"6"},{"comment_id":"1195078","poster":"waldirlsantos","content":"Selected Answer: B\nEFS is listed like a best practice for this cases\n\"ou can use Amazon ECS to run stateful containerized applications at scale by using AWS storage services, such as Amazon EFS, Amazon EBS, or FSx for Windows File Server, that provide data persistence to inherently ephemeral containers. The term data persistence means that the data itself outlasts the process that created it. \"","upvote_count":"2","timestamp":"1713031080.0"},{"content":"Selected Answer: B\nB is correct","comment_id":"1176385","poster":"MattBJ","upvote_count":"2","timestamp":"1710758820.0"},{"comment_id":"1155346","upvote_count":"1","comments":[{"poster":"MatAlves","content":"Both B and C work with AWS launch type. So you have to decide between EFS vs S3.\n\nHow are you going to MOUNT s3 buckets in the containers?!","timestamp":"1726607820.0","comment_id":"1285461","upvote_count":"2","comments":[{"timestamp":"1726608000.0","poster":"MatAlves","comment_id":"1285464","upvote_count":"2","content":"It's simply not good practice, unless you're confusing S3 with S3 storage gateway."}]}],"timestamp":"1708501680.0","content":"Selected Answer: C\nThe company does not want to manage any servers or storage infrastructure.\nI would go with C","poster":"ogerber"}],"timestamp":"2024-02-05 16:49:00","answer_description":"","unix_timestamp":1707148140,"topic":"1","isMC":true,"choices":{"A":"Use Amazon Elastic Kubernetes Service (Amazon EKS) with self-managed nodes. Create an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance. Use the EBS volume as a persistent volume mounted in the containers.","B":"Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers.","D":"Use Amazon Elastic Container Service (Amazon ECS) with an Amazon EC2 launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers.","C":"Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon S3 bucket. Map the S3 bucket as a persistent storage volume mounted in the containers."}},{"id":"mvhYiipg3NHS4fIAUByK","choices":{"B":"Deploy the ingestion application on Amazon EC2 instances in an Auto Scaling group to scale the number of EC2 instances based on CPU metrics.","D":"Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with multiple Amazon Simple Queue Service (Amazon SOS) subscriptions. Configure the consumer applications to process the messages from the queues.","A":"Persist the messages to Amazon Kinesis Data Analytics. Configure the consumer applications to read and process the messages.","C":"Write the messages to Amazon Kinesis Data Streams with a single shard. Use an AWS Lambda function to preprocess messages and store them in Amazon DynamoDB. Configure the consumer applications to read from DynamoDB to process the messages."},"unix_timestamp":1665233040,"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/84721-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","question_images":[],"timestamp":"2022-10-08 14:44:00","exam_id":31,"question_text":"A company has an application that ingests incoming messages. Dozens of other applications and microservices then quickly consume these messages. The number of messages varies drastically and sometimes increases suddenly to 100,000 each second. The company wants to decouple the solution and increase scalability.\nWhich solution meets these requirements?","discussion":[{"comments":[{"timestamp":"1673018460.0","poster":"SilentMilli","content":"By default, an SQS queue can handle a maximum of 3,000 messages per second. However, you can request higher throughput by contacting AWS Support. AWS can increase the message throughput for your queue beyond the default limits in increments of 300 messages per second, up to a maximum of 10,000 messages per second.\n\nIt's important to note that the maximum number of messages per second that a queue can handle is not the same as the maximum number of requests per second that the SQS API can handle. The SQS API is designed to handle a high volume of requests per second, so it can be used to send messages to your queue at a rate that exceeds the maximum message throughput of the queue.","upvote_count":"18","comment_id":"767830"},{"comment_id":"732687","upvote_count":"3","timestamp":"1669903500.0","content":"of course, the answer is D","poster":"9014"},{"content":"D. Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with multiple Amazon Simple Queue Service (Amazon SQS) subscriptions. Configure the consumer applications to process the messages from the queues.\n\nThis solution uses Amazon SNS and SQS to publish and subscribe to messages respectively, which decouples the system and enables scalability by allowing multiple consumer applications to process the messages in parallel. Additionally, using Amazon SQS with multiple subscriptions can provide increased resiliency by allowing multiple copies of the same message to be processed in parallel.","timestamp":"1675215960.0","comment_id":"794802","poster":"daizy","upvote_count":"16"}],"comment_id":"689305","content":"Selected Answer: D\nD makes more sense to me.","poster":"rein_chau","timestamp":"1665233040.0","upvote_count":"55"},{"timestamp":"1726903920.0","comments":[{"upvote_count":"2","timestamp":"1681001100.0","poster":"shinejh0528","comment_id":"865212","content":"oh... I confused between Kinesis Data Analytics and Kinesis Data Stream as you mentioned... I solved several this type of questions, but SNS is always about 'notification', so i choose A. but i think Kinesis Data Analytics is just wrong, so D is most correct answer."}],"upvote_count":"20","comment_id":"860732","poster":"PhucVuu","content":"Selected Answer: D\nKeywords:\n- The number of messages varies drastically \n- Sometimes increases suddenly to 100,000 each second\n\nA: Incorrect - Don't confuse between Kinesis Data Analytics and Kinesis Data Stream =)) Kinesis Data Analytics will get the data from Kinesis Data Stream or Kinesis Data FireHose or MSK (Managed Stream for apache Kafka) for analytic purpose. It can not consume message and send to applications.\nB: Incorrect - Base on the keywords -> Auto Scaling group not scale well because it need time to check the CPU metric and need time to start up the EC2 and the messages varies drastically. Example: we have to scale from 10 to 100 EC2. Our servers may be down a while when it was scaling.\nC: Incorrect - Kinesis Data Streams can handle this case but we should increase the more shards but not single shard.\nD: Correct: We can handle high workload well with fan-out pattern SNS + multiple SQS -> This is good for use case:\n- The number of messages varies drastically \n- Sometimes increases suddenly to 100,000 each second"},{"poster":"Aychi","upvote_count":"1","content":"Selected Answer: D\nD is correct answer","comment_id":"1402096","timestamp":"1742693340.0"},{"poster":"melvis8","content":"Selected Answer: D\nusing an SQS queues to decouple this soluton will be the best approach since an SQS queue is very scalable and the number of messages to scale can be incremented by the user manually or by the use of security groups","comment_id":"1400756","upvote_count":"1","timestamp":"1742420760.0"},{"timestamp":"1740486000.0","upvote_count":"1","content":"Selected Answer: D\nI choose D because the question say \"decouple/scalable\" and the best services for that are SNS/SQS.","comment_id":"1361426","poster":"chente_diaz"},{"comment_id":"1345903","upvote_count":"1","timestamp":"1737697500.0","poster":"Mrigraj12","content":"Selected Answer: D\nD should be the answer as it is achieving a good decoupling: \n1. Use SNS to create topics so messages for different applications will go on different topics \n2. Create multiple SQS queues and subscribe to different SNS topics and let the different applications poll from their related SQS qeueus."},{"content":"Selected Answer: D\nAmazon SNS + SQS provides a scalable and decoupled architecture:\nSNS is a publish-subscribe messaging service that allows the ingestion application to broadcast messages to multiple subscribers.\nSQS acts as the subscriber to the SNS topic, creating separate message queues for each consumer application. This ensures:\nScalability: Messages are distributed across queues, decoupling the producer and consumers.\nReliability: SQS queues store messages until consumer applications can process them, accommodating sudden spikes in message volume.","poster":"MGKYAING","upvote_count":"1","timestamp":"1735139880.0","comment_id":"1331614"},{"upvote_count":"1","content":"Selected Answer: D\nD is correct, and the easiest way to choose this answer choice is by the keyword \"decouple.\" In order to decouple services, you can choose to use SQS/SNS (I believe there is a typo that says SOS)","poster":"hopefully2022","comment_id":"1320406","timestamp":"1733014620.0"},{"content":"The Correct Answer is D because it is required loosely couple and distributed queing system apporach.","upvote_count":"1","comment_id":"1309866","timestamp":"1731307800.0","poster":"MGKYAING"},{"timestamp":"1726903860.0","poster":"Buruguduystunstugudunstuy","content":"***CORRECT ANSWER***\nThe correct solution that meets these requirements is Option D: Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with multiple Amazon Simple Queue Service (Amazon SQS) subscriptions. Configure the consumer applications to process the messages from the queues.\n\nOption D involves using Amazon Simple Notification Service (SNS) and Amazon Simple Queue Service (SQS) to decouple the solution and increase scalability. SNS is a fully managed, publish-subscribe messaging service that allows you to send messages to multiple recipients simultaneously. SQS is a fully managed, distributed message queue service that enables you to store, process, and transmit messages between microservices, distributed systems, and serverless applications.","comment_id":"751139","upvote_count":"4","comments":[{"timestamp":"1671550920.0","comments":[{"poster":"Buruguduystunstugudunstuy","comments":[{"timestamp":"1671550980.0","poster":"Buruguduystunstugudunstuy","content":"Option C involves writing the messages to Amazon Kinesis Data Streams with a single shard and using an AWS Lambda function to preprocess the messages and store them in DynamoDB. This option would not be the most efficient solution, as it would require the consumer applications to continuously poll DynamoDB for new messages, which could impact their performance.\n\nOverall, Option D is the most effective solution for decoupling the solution and increasing scalability.","upvote_count":"5","comment_id":"751143"}],"comment_id":"751142","timestamp":"1671550980.0","content":"***WRONG AS EXPLAINED***\nOption A involves persisting the messages to Amazon Kinesis Data Analytics and configuring the consumer applications to read and process the messages. This option would not be the most efficient solution, as it would require the consumer applications to continuously poll Kinesis Data Analytics for new messages, which could impact their performance.\n\nOption B involves deploying the ingestion application on Amazon EC2 instances in an Auto Scaling group to scale the number of EC2 instances based on CPU metrics. This option would not decouple the solution and increase scalability, as the consumer applications would still be directly connected to the ingestion application.","upvote_count":"2"}],"poster":"Buruguduystunstugudunstuy","comment_id":"751140","upvote_count":"4","content":"To implement this solution, you would first publish the incoming messages to an SNS topic. You could then create multiple SQS subscriptions to the SNS topic, and configure the consumer applications to process the messages from the queues. This approach allows you to decouple the ingestion application from the consumer applications, and it allows you to scale the number of consumer applications independently of the ingestion application."}]},{"poster":"karloscetina007","comment_id":"925297","content":"Selected Answer: A\nSNS and SQS still have an standard limit of tails under 3000 messages per sec, because SNS and SQS still have an standard limit of tails under 3000 messages per sec. It does not accomplishes with the requirement.\n\nPerharps it's a possible solution: Amazon Kinesis Data Analytics. Configure the consumer applications to read and process the messages, but it requires that change the arch of this app, but this point is no matter on ther requirement.","comments":[{"content":"thats for FIFO queue.","comment_id":"979829","comments":[{"upvote_count":"2","timestamp":"1691910600.0","content":"for standard queue there is nearly no limit to messages","poster":"Fresbie99","comment_id":"979833"}],"timestamp":"1691910420.0","upvote_count":"1","poster":"Fresbie99"}],"upvote_count":"1","timestamp":"1726903800.0"},{"poster":"cookieMr","content":"Selected Answer: D\nOption A: It is more suitable for real-time analytics and processing of streaming data rather than decoupling and scaling message ingestion and consumption.\n\nOption B: It may help with scalability to some extent, but it doesn't provide decoupling.\n\nOption C: It is a valid option, but it lacks the decoupling aspect. In this approach, the consumer applications would still need to read directly from DynamoDB, creating tight coupling between the ingestion and consumption processes.\n\nOption D: It is the recommended solution for decoupling and scalability. The ingestion application can publish messages to an SNS topic, and multiple consumer apps can subscribe to the relevant SQS queues. SNS ensures that each message is delivered to all subscribed queues, allowing the consuming apps to independently process the messages at their own pace and scale horizontally as needed. This provides loose coupling, scalability, and fault tolerance, as the queues can handle message spikes and manage the consumption rate based on the consumer's processing capabilities.","timestamp":"1726903800.0","comment_id":"926513","upvote_count":"4"},{"content":"Selected Answer: D\nThe answer is D. Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with multiple Amazon Simple Queue Service (Amazon SQS) subscriptions. Configure the consumer applications to process the messages from the queues.\nThis solution is the most scalable and decoupled solution for the given scenario. Amazon SNS is a pub/sub messaging service that can be used to decouple applications. Amazon SQS is a fully managed message queuing service that can be used to store and process messages.\nThe solution would work as follows:\n The ingestion application would publish the messages to an Amazon SNS topic.\n The Amazon SNS topic would have multiple Amazon SQS subscriptions.\n The consumer applications would subscribe to the Amazon SQS queues.\n The consumer applications would process the messages from the Amazon SQS queues.","timestamp":"1726903800.0","poster":"Guru4Cloud","comment_id":"954329","upvote_count":"2"},{"upvote_count":"3","timestamp":"1726903800.0","comment_id":"969529","content":"D. is the answer.\n The question states that there are dozens of other applications and microservices that consume these messages and that the volume of messages can vary drastically and increase suddenly. Therefore, you need a solution that can handle a high volume of messages, distribute them to multiple consumers, and scale quickly. SNS with SQS provides these capabilities.\n\nPublishing messages to an SNS topic with multiple SQS subscriptions is a common AWS pattern for achieving both decoupling and scalability in message-driven systems. SNS allows messages to be fanned out to multiple subscribers, which in this case would be SQS queues. Each consumer application could then process messages from its SQS queue at its own pace, providing scalability and ensuring that all messages are processed by all consumer applications.\n\nA. Amazon Kinesis Data Analytics is primarily used for real-time analysis of streaming data. It's not designed to distribute messages to multiple consumers.","poster":"Stevey"},{"content":"Option D\n\nAmazon SNS allows you to publish messages to a topic, which can then fan out those messages to multiple subscribers.\nBy using Amazon SQS as a subscriber to the SNS topic, you can handle the message load in a decoupled and scalable way. SQS can store messages until the consuming application is ready to process them, helping to smooth out the variance in message load.\nThis approach allows the company to effectively decouple the message producing applications from the consuming applications, and it can easily scale to handle the high load of messages.\nThe number of messages (100,000 each second) might require careful configuration and sharding of SQS queues or use of FIFO queues to ensure that they can handle the load.\nOptions A, B, and C have their own limitations:","upvote_count":"3","poster":"hrushikeshrelekar","timestamp":"1726903800.0","comment_id":"1021205"},{"timestamp":"1726903800.0","content":"Selected Answer: D\nD. Here’s why option D is the correct choice:\n\nAmazon SNS: Amazon SNS is a fully managed pub/sub messaging service that enables message publishing and subscription to topics. It provides fast and flexible communication between publishers and subscribers.\nAmazon SQS: Amazon SQS is a fully managed message queuing service that decouples the components of a distributed application. It offers reliable and scalable queues for storing messages and enables applications to process them asynchronously.\nBy publishing the messages to an Amazon SNS topic and using Amazon SQS subscriptions, the solution achieves decoupling and scalability. Multiple applications and microservices can subscribe to the topic and receive messages through their individual SQS queues. This allows for parallel processing and enables the system to handle varying message volumes, including spikes of up to 100,000 messages per second.","upvote_count":"3","comment_id":"1039772","poster":"IdanAWS"},{"poster":"Ruffyit","content":"D. Here’s why option D is the correct choice:\n\nAmazon SNS: Amazon SNS is a fully managed pub/sub messaging service that enables message publishing and subscription to topics. It provides fast and flexible communication between publishers and subscribers.\nAmazon SQS: Amazon SQS is a fully managed message queuing service that decouples the components of a distributed application. It offers reliable and scalable queues for storing messages and enables applications to process them asynchronously.\nBy publishing the messages to an Amazon SNS topic and using Amazon SQS subscriptions, the solution achieves decoupling and scalability. Multiple applications and microservices can subscribe to the topic and receive messages through their individual SQS queues. This allows for parallel processing and enables the system to handle varying message volumes, including spikes of up to 100,000 messages per second.","upvote_count":"3","comment_id":"1053746","timestamp":"1726903800.0"}],"answers_community":["D (84%)","Other"],"topic":"1","answer_images":[],"answer":"D","question_id":687,"isMC":true},{"id":"chf0gT5TiZ0pC8iTdXOy","isMC":true,"timestamp":"2022-10-17 16:56:00","exam_id":31,"answer_description":"","answer_images":[],"answer":"C","question_images":[],"choices":{"B":"Add a cron job to the EC2 instances to check the local application's logs once each minute. If HTTP errors are detected. the application will restart.","D":"Create an Amazon Cloud Watch alarm that monitors the UnhealthyHostCount metric for the NLB. Configure an Auto Scaling action to replace unhealthy instances when the alarm is in the ALARM state.","C":"Replace the NLB with an Application Load Balancer. Enable HTTP health checks by supplying the URL of the company's application. Configure an Auto Scaling action to replace unhealthy instances.","A":"Enable HTTP health checks on the NLB, supplying the URL of the company's application."},"unix_timestamp":1666018560,"question_text":"A company's HTTP application is behind a Network Load Balancer (NLB). The NLB's target group is configured to use an Amazon EC2 Auto Scaling group with multiple EC2 instances that run the web service.\nThe company notices that the NLB is not detecting HTTP errors for the application. These errors require a manual restart of the EC2 instances that run the web service. The company needs to improve the application's availability without writing custom scripts or code.\nWhat should a solutions architect do to meet these requirements?","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/85734-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":688,"answer_ET":"C","discussion":[{"comment_id":"697490","upvote_count":"32","timestamp":"1666018560.0","comments":[{"content":"I think even http health check is feasible, option A does not provide any suggestion when health check fails","timestamp":"1742547060.0","comment_id":"1401482","upvote_count":"1","poster":"jerryl"},{"comment_id":"719626","content":"can you elaborate more pls","comments":[{"upvote_count":"11","comments":[{"timestamp":"1682453880.0","comments":[{"content":"A URL includes the hostname. The health check path is only the path portion. For example,\nURL = https://i-0123456789abcdef.us-west-2.compute.internal/index.html\nhealth check path= /index.html","upvote_count":"15","comment_id":"918394","timestamp":"1686237240.0","poster":"majubmo"}],"poster":"km142646","comment_id":"880829","content":"What's the difference between endpoint URL and health check path?","upvote_count":"2"}],"content":"NLBs support HTTP, HTTPS and TCP health checks:\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-health-checks.html (check HealthCheckProtocol)\n\nBut NLBs only accept either selecting EC2 instances or IP addresses directly as targets. You can't provide a URL to your endpoints, only a health check path (if you're using HTTP or HTTPS health checks).","timestamp":"1674128640.0","comment_id":"781067","poster":"BlueVolcano1"}],"poster":"Ack3rman","timestamp":"1668602520.0","upvote_count":"3"}],"poster":"123jhl0","content":"Selected Answer: C\nI would choose A, as NLB supports HTTP and HTTPS Health Checks, BUT you can't put any URL (as proposed), only the node IP addresses. \nSo, the solution is C."},{"content":"Selected Answer: C\nOption C. NLB works at Layer 4 so it does not support HTTP/HTTPS. The replacement for the ALB is the best choice.","comments":[{"upvote_count":"7","poster":"BlueVolcano1","content":"That's incorrect. NLB does support HTTP and HTTPS (and TCP) health checks.\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-health-checks.html\n\nThere just isn't an answer option that reflects that. My guess is that the question and/or answer options are outdated.","comment_id":"781069","timestamp":"1674128700.0"}],"comment_id":"698197","upvote_count":"19","poster":"ArielSchivo","timestamp":"1666094160.0"},{"poster":"AwsAbhiKumar","content":"Selected Answer: C\nNLB only supports TCP-level health checks, it cannot detect HTTP errors","upvote_count":"1","comment_id":"1349220","timestamp":"1738268700.0"},{"timestamp":"1735844640.0","upvote_count":"2","content":"Selected Answer: C\nALB is more suitable for HTTP requests.","comment_id":"1335723","poster":"satyaammm"},{"comment_id":"1282144","content":"Selected Answer: C\nAns C - Yup, somethings happening at the Application level so replace NLB with ALB","timestamp":"1726061400.0","upvote_count":"4","poster":"PaulGa"},{"poster":"awsgeek75","comment_id":"1122715","timestamp":"1705253340.0","content":"Selected Answer: C\nNLB is for network errors and low level traffic stuff\nALB is for application so C is the only realistic option here","upvote_count":"8"},{"timestamp":"1703811360.0","content":"Selected Answer: A\nNLB does support HTTP/HTTPS Health Checks.\n\nI saw other people comments, it seems like the question were rephrased. The comments were highlighting \"application URL\", but I don't see words on the question.","upvote_count":"3","poster":"kel2023","comment_id":"1108222"},{"poster":"ignajtpolandstrong","content":"Selected Answer: C\nYou can use HTTP/HTTPS ONLY when Target is ALB.\nBy default it is TCP.\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-health-checks.html#health-check-settings\nHealthCheckProtocol\nThe protocol the load balancer uses when performing health checks on targets. The possible protocols are HTTP, HTTPS, and TCP. The default is the TCP protocol. If the target type is ALB, the supported health check protocols are HTTP and HTTPS.","timestamp":"1703767080.0","comment_id":"1107762","upvote_count":"3"},{"upvote_count":"4","content":"Selected Answer: C\nALB allows you to specify the path which helps to check the error. NLB cannot do that.","timestamp":"1696862460.0","poster":"tom_cruise","comment_id":"1038758"},{"comment_id":"977968","upvote_count":"4","poster":"Guru4Cloud","content":"Selected Answer: C\nThe key points are:\n\nUse an Application Load Balancer (ALB) instead of a Network Load Balancer (NLB) since ALBs support HTTP health checks.\nConfigure HTTP health checks on the ALB to monitor the application health.\nUse an Auto Scaling action triggered by the ALB health checks to automatically replace unhealthy instances.","timestamp":"1691689620.0"},{"timestamp":"1689786960.0","comment_id":"956854","content":"Option C is the right answer.","upvote_count":"1","poster":"miki111"},{"comments":[{"poster":"Gizmo2022","comment_id":"1316465","timestamp":"1732303620.0","upvote_count":"1","content":"Thank you for explaining this, I'm currently studying for the exam and your explanation was helpful."}],"comment_id":"929603","content":"Selected Answer: C\nA. NLB, but NLB's health checks are designed for TCP/UDP protocols and lack the advanced features specific to HTTP applications provided by ALB.\n\nB. This approach involves custom scripting and manual intervention, which contradicts the requirement of not writing custom scripts or code.\n\nD. Since the NLB does not detect HTTP errors, relying solely on the UnhealthyHostCount metric may not accurately capture the health of the application instances.\n\nTherefore, C is the recommended choice for improving the application's availability without custom scripting or code. By replacing the NLB with an ALB, enabling HTTP health checks, and configuring Auto Scaling to replace unhealthy instances, the company can ensure that only healthy instances are serving traffic, enhancing the application's availability automatically.","upvote_count":"10","timestamp":"1687356660.0","poster":"cookieMr"},{"comment_id":"901614","timestamp":"1684465920.0","upvote_count":"1","content":"Replace the NLB (layer 4 udp and tcp) with an Application Load Balancer - ALB (layer 7) supports http and https requests.","poster":"Abrar2022"},{"timestamp":"1679299440.0","upvote_count":"1","comment_id":"844637","comments":[{"upvote_count":"1","timestamp":"1679299620.0","comment_id":"844638","content":"Also A doesn't offer what bellow in C offers...\n\nConfigure an Auto Scaling action to replace unhealthy instances","poster":"datz"}],"content":"Selected Answer: C\nmust be C\n\nApplication availability: NLB cannot assure the availability of the application. This is because it bases its decisions solely on network and TCP-layer variables and has no awareness of the application at all. Generally, NLB determines availability based on the ability of a server to respond to ICMP ping or to correctly complete the three-way TCP handshake. ALB goes much deeper and is capable of determining availability based on not only a successful HTTP GET of a particular page but also the verification that the content is as was expected based on the input parameters.","poster":"datz"},{"upvote_count":"1","poster":"Tony1980","timestamp":"1675337820.0","comment_id":"795996","content":"Answer is C\n\nA solution architect can use Amazon EC2 Auto Scaling health checks to automatically detect and replace unhealthy instances in the EC2 Auto Scaling group. The health checks can be configured to check the HTTP errors returned by the application and terminate the unhealthy instances. This will ensure that the application's availability is improved, without requiring custom scripts or code."},{"comment_id":"792971","comments":[{"comment_id":"1105195","upvote_count":"2","timestamp":"1703502060.0","content":"But you'd need to check the health of the individual nodes, NOT \"the URL of the company's application\" which points to the Load Balancer.","poster":"pentium75"}],"content":"I will go with A as Network load balancer supports HTTP and HTTPS health checks, maybe the answer is outdated.","upvote_count":"2","timestamp":"1675092120.0","poster":"aakashkumar1999"},{"comments":[{"timestamp":"1674128760.0","poster":"BlueVolcano1","comment_id":"781070","content":"That's incorrect. NLB does support HTTP and HTTPS (and TCP) health checks.\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-health-checks.html\n\nJust a general tip: Medium is not a reliable resource. Anyone can create content there. Rely only on official AWS documentation.","comments":[],"upvote_count":"4"}],"content":"Selected Answer: C\nhttps://medium.com/awesome-cloud/aws-difference-between-application-load-balancer-and-network-load-balancer-cb8b6cd296a4\nAs NLB does not support HTTP health checks, you can only use ALB to do so.","poster":"John_Zhuang","comment_id":"763681","upvote_count":"1","timestamp":"1672659420.0"},{"upvote_count":"3","content":"Answer is C, and A is wrong because\nIn NLB, for HTTP or HTTPS health check requests, the host header contains the IP address of the load balancer node and the listener port, not the IP address of the target and the health check port.\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-health-checks.html","timestamp":"1672249500.0","poster":"benjl","comment_id":"760169"},{"upvote_count":"1","comment_id":"755651","poster":"Silvestr","content":"Selected Answer: C\nCorrect answer - C\nNetwork load balancers (Layer 4) allow to:\n• Forward TCP & UDP traffic to your instances\n• Handle millions of request per seconds\n• Less latency ~100 ms (vs 400 ms for ALB)\nBest choice for HTTP traffic - replace to Application load balancer","timestamp":"1671973440.0"},{"content":"Selected Answer: A\nThe best option to meet the requirements is to enable HTTP health checks on the NLB by supplying the URL of the company's application. This will allow the NLB to automatically detect HTTP errors and take action, such as marking the target instance as unhealthy and routing traffic away from it.\n\nOption A - Enable HTTP health checks on the NLB, supplying the URL of the company's application.\nThis is the correct solution as it allows the NLB to automatically detect HTTP errors and take action.","poster":"Buruguduystunstugudunstuy","timestamp":"1671577200.0","comments":[{"poster":"Schladde","upvote_count":"1","content":"This won't increase availability when instances become unavailable.","comment_id":"858228","timestamp":"1680376800.0"},{"timestamp":"1686990720.0","content":"Option C right. A is is not necessarily wrong, but it may not be the most effective solution to meet the requirements in this scenario. Here's why:\n\nOption A suggests enabling HTTP health checks on the Network Load Balancer (NLB) by supplying the URL of the company's application. While this can help the NLB detect if the application is accessible or not, it does not directly address the specific requirement of automatically restarting the EC2 instances when HTTP errors occur.","upvote_count":"1","comment_id":"925869","poster":"vipyodha"},{"timestamp":"1671577320.0","poster":"Buruguduystunstugudunstuy","comments":[{"upvote_count":"1","timestamp":"1671577380.0","poster":"Buruguduystunstugudunstuy","content":"Option D - Create an Amazon CloudWatch alarm that monitors the UnhealthyHostCount metric for the NLB. Configure an Auto Scaling action to replace unhealthy instances when the alarm is in the ALARM state.\nThis option involves monitoring the UnhealthyHostCount metric, which only reflects the number of unhealthy targets that the NLB is currently routing traffic away from. It does not directly monitor the health of the application or detects HTTP errors. Additionally, this solution may not be sufficient to detect and respond to HTTP errors in a timely manner.","comment_id":"751614"}],"content":"Option B - Add a cron job to the EC2 instances to check the local application's logs once each minute. If HTTP errors are detected, the application will restart.\nThis option involves writing custom scripts or code, which is not allowed by the requirements. Additionally, this solution may not be reliable or efficient, as it relies on checking the logs locally on each instance and may not catch all errors.\n\nOption C - Replace the NLB with an Application Load Balancer. Enable HTTP health checks by supplying the URL of the company's application. Configure an Auto Scaling action to replace unhealthy instances.\nWhile this option may improve the availability of the application, it is not necessary to replace the NLB with an Application Load Balancer in order to enable HTTP health checks. The NLB can support HTTP health checks as well, and replacing it may involve additional effort and cost.","comment_id":"751613","upvote_count":"3"},{"content":"But A suggests to monitor health of \"the URL of the company's application\", which would point to the Load Balancer and return the health of a random node, not the one that is checked.\n\nSo you're checking Node 3 using the application URL, the Load Balancer directs your request to Node 2 which is unhealthy, thus the health check for Node 3 fails and Node 3 gets evicted.","upvote_count":"1","comment_id":"1105199","timestamp":"1703502180.0","poster":"pentium75"}],"upvote_count":"5","comment_id":"751610"},{"upvote_count":"1","timestamp":"1671406560.0","comment_id":"749298","poster":"career360guru","content":"Selected Answer: A\nOption A is very much a valid option as Autoscaling group can be configured to remove EC2 instances that fails http health check of NLB. AWS NLB supports http based health check.","comments":[]},{"upvote_count":"1","timestamp":"1669379880.0","comment_id":"726753","poster":"LeGloupier","content":"Selected Answer: A\nA is the best option.\nNLB support http healthcheck, so why do we need to move to ALB ?\nmoreover the sentence \"Configure an Auto Scaling action to replace unhealthy instances\" in C seems to be wrong, as auto scaling remove any unhealthy instance by default, you do not need to configure it.","comments":[{"upvote_count":"2","comment_id":"736876","content":"I would say A will not give you what you want. \"If you add a TLS listener to your Network Load Balancer, we perform a listener connectivity test.\" (https://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-health-checks.html) So a check will be made to see that something is listening on port 443. What it will not check is the status of the application e.g. HTTP 200 OK. Now the Application Load Balancer HTTP health check using the URL of the company's application, will do this, so C is the correct answer.","timestamp":"1670335020.0","poster":"JayBee65"}]},{"comment_id":"723619","timestamp":"1669041240.0","content":"C is correct","upvote_count":"1","poster":"Wpcorgan"},{"comment_id":"713057","upvote_count":"4","timestamp":"1667826720.0","poster":"mabotega","content":"Selected Answer: C\nC is the correct!\nNLB does not handle HTTP (layer 7) listerns errors only TCP (layer 4) listeners.\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environments-cfg-nlb.html"},{"timestamp":"1667542140.0","upvote_count":"1","poster":"Solarch","comment_id":"710929","content":"Answer is A\nNLB is ideal for TPC and UDP Traffic and checks operating in layer 4. \nALB- Supports HTTP and HTTPs traffics. Hence the ELB needs to be changed from NLB to ALB."},{"poster":"Aman54","content":"Selected Answer: A\nNLB supports HTTP health checks, they are part of the target group and the setting is the same for ALB and NLB HTTP/HTTPS health checks.","upvote_count":"1","comments":[{"comments":[{"upvote_count":"2","comment_id":"709910","content":"NLB is already configured with a target group supported by EC2 ASG \"NLB's target group is configured to use an Amazon EC2 Auto Scaling group\". NLB need to be configured to use http health check. Hence A","timestamp":"1667404380.0","poster":"Maharaja","comments":[{"comment_id":"741212","upvote_count":"1","timestamp":"1670701980.0","poster":"wh1t4k3r","content":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environments-cfg-nlb.html\n\nNote\nUnlike a Classic Load Balancer or an Application Load Balancer, a Network Load Balancer can't have application layer (layer 7) HTTP or HTTPS listeners. It only supports transport layer (layer 4) TCP listeners. HTTP and HTTPS traffic can be routed to your environment over TCP."}]}],"timestamp":"1666797660.0","comment_id":"704805","poster":"oxfordcommaa","content":"\"The company needs to improve the application's availability\"\nAnswer A does not address this. The auto scaling group in answer C does.","upvote_count":"1"},{"poster":"Vesperia","timestamp":"1669391460.0","comment_id":"726910","content":"A is incorrect. NLB cannot detect http errors. Adding health check only detects the healthiness of the instances, not http errors.","upvote_count":"2"}],"comment_id":"700070","timestamp":"1666278960.0"}],"answers_community":["C (90%)","10%"]},{"id":"JBf4gnwSgnADvhvJsoGC","question_id":689,"unix_timestamp":1707148320,"exam_id":31,"answers_community":["AC (94%)","6%"],"url":"https://www.examtopics.com/discussions/amazon/view/132863-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A gaming company wants to launch a new internet-facing application in multiple AWS Regions. The application will use the TCP and UDP protocols for communication. The company needs to provide high availability and minimum latency for global users.\n\nWhich combination of actions should a solutions architect take to meet these requirements? (Choose two.)","isMC":true,"answer_description":"","answer":"AC","timestamp":"2024-02-05 16:52:00","question_images":[],"discussion":[{"content":"Correct answer should be AC","timestamp":"1722865920.0","comments":[{"poster":"mestule","content":"Agreed. \n\nWhen you add an internal Load Balancer or an Amazon EC2 instance endpoint in AWS Global Accelerator, you enable internet traffic to flow directly to and from the endpoint in Virtual Private Clouds (VPCs) by targeting it in a private subnet. The VPC that contains the load balancer or EC2 instance must have an internet gateway attached to it, to indicate that the VPC accepts internet traffic. However, you don't need public IP addresses on the load balancer or EC2 instance. You also don't need an associated internet gateway route for the subnet.","comment_id":"1142808","upvote_count":"8","timestamp":"1722976800.0"}],"comment_id":"1141248","upvote_count":"10","poster":"Andy_09"},{"upvote_count":"5","timestamp":"1723733760.0","comment_id":"1151131","poster":"ogerber","content":"Selected Answer: AC\nGaming + TCP / UDP => always think NLB and global accelerator"},{"upvote_count":"1","poster":"yangbo","content":"Selected Answer: CD\nA is wrong . AWS Global Accelerator cannot directly connect to Internal Network Load Balancers (NLBs). It can only connect to Internet-facing NLBs or Application Load Balancers (ALBs), and cannot connect to Internal NLBs because Internal NLBs are designed to serve traffic within the VPC and are not exposed to the internet.","timestamp":"1741255800.0","comments":[{"upvote_count":"1","poster":"yangbo","comment_id":"1365839","content":"client - dns - AWS Global Accelerator - NLB -EC2","timestamp":"1741256100.0"}],"comment_id":"1365835"},{"timestamp":"1729862520.0","poster":"sandordini","comment_id":"1202012","upvote_count":"2","content":"Selected Answer: AC\nGaming, TCP&UDP, HA, Low latency >> NLB + AWS Global Accelerator"},{"timestamp":"1728841560.0","comment_id":"1195072","poster":"waldirlsantos","upvote_count":"2","content":"Selected Answer: AC\nGlobal Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP. NLB + GA for UDP, TCP"},{"comment_id":"1177198","timestamp":"1726732620.0","upvote_count":"4","poster":"Kezuko","content":"Selected Answer: AC\nUDP -> NLB and Global Accelerator"},{"comment_id":"1147817","poster":"1Alpha1","content":"Selected Answer: AC\n*AC* - the app is using TCP & UDP","timestamp":"1723429320.0","upvote_count":"3"},{"timestamp":"1723304520.0","content":"For global user where TCP and UDP protocols are used and HA with minimum latency is needed.... Global Accelerator with NLB is the solution combination .","comment_id":"1146549","upvote_count":"3","poster":"jaswantn"}],"answer_ET":"AC","topic":"1","choices":{"E":"Configure Amazon CloudFront to handle the traffic and route requests to the application in each Region","A":"Create internal Network Load Balancers in front of the application in each Region.","B":"Create external Application Load Balancers in front of the application in each Region.","C":"Create an AWS Global Accelerator accelerator to route traffic to the load balancers in each Region.","D":"Configure Amazon Route 53 to use a geolocation routing policy to distribute the traffic."},"answer_images":[]},{"id":"RZFrcO7GdwN7Fi2iRgfm","url":"https://www.examtopics.com/discussions/amazon/view/132865-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":690,"topic":"1","exam_id":31,"unix_timestamp":1707148860,"answer":"C","choices":{"A":"Enable an AWS WAF web ACL on the ALB, and configure rules to block traffic from unknown sources.","C":"Subscribe to AWS Shield Advanced. Engage the AWS DDoS Response Team (DRT) to integrate mitigating controls into the service.","D":"Create an Amazon CloudFront distribution for the application, and set the ALB as the origin. Enable an AWS WAF web ACL on the distribution, and configure rules to block traffic from unknown sources","B":"Subscribe to Amazon Inspector. Engage the AWS DDoS Response Team (DRT) to integrate mitigating controls into the service."},"question_text":"A city has deployed a web application running on Amazon EC2 instances behind an Application Load Balancer (ALB). The application's users have reported sporadic performance, which appears to be related to DDoS attacks originating from random IP addresses. The city needs a solution that requires minimal configuration changes and provides an audit trail for the DDoS sources.\n\nWhich solution meets these requirements?","isMC":true,"timestamp":"2024-02-05 17:01:00","answer_ET":"C","answers_community":["C (100%)"],"answer_images":[],"answer_description":"","question_images":[],"discussion":[{"comment_id":"1141254","content":"C is the correct answer","timestamp":"1707148860.0","upvote_count":"7","poster":"Andy_09"},{"poster":"Scheldon","content":"Selected Answer: C\nAnswerC","timestamp":"1719825780.0","comment_id":"1240073","upvote_count":"1"},{"poster":"NSA_Poker","upvote_count":"1","timestamp":"1718137920.0","content":"Selected Answer: C\n(A & D) are incorrect.\nAWS WAF Web ACL - contain WAF rules that define how to inspect web requests and what to do when a web request matches the inspection criteria.\nWe don't have the inspection criteria necessary to use WAF Web ACL effectively bc DDoS attacks are originating from random IP addresses. \nThe AWS DDoS Response Team can respond to the randomness. \n\n(B) is incorrect. \nAmazon Inspector - a service that analyzes your EC2 instances to identify potential security and configuration issues. \nInspector is not good at dealing with an actual DDOS attack like AWS Shield Advanced.","comment_id":"1228648"},{"content":"Selected Answer: C\nDDoS = AWS Shield","upvote_count":"2","timestamp":"1714053840.0","poster":"sandordini","comment_id":"1202042"},{"poster":"Mikado211","content":"Selected Answer: C\nC is the correct answer, AWS Shield Advanced.","upvote_count":"1","comment_id":"1187408","timestamp":"1711974120.0"},{"timestamp":"1709505120.0","comment_id":"1165138","poster":"asdfcdsxdfc","content":"Selected Answer: C\nC looks correct","upvote_count":"1"},{"upvote_count":"2","timestamp":"1708527900.0","content":"C is the correct answer.\nAmazon Inspector is an automated vulnerability management service whereas AWS Shield Advanced is a managed service that helps you protect your application against external threats, like DDoS attacks, volumetric bots, and vulnerability exploitation attempts. For higher levels of protection against attacks.","poster":"Naveena_Devanga","comment_id":"1155620"},{"content":"Selected Answer: C\nC is the correct answer","poster":"Darshan07","comment_id":"1148052","timestamp":"1707738300.0","upvote_count":"1"}]}],"exam":{"provider":"Amazon","isBeta":false,"isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","numberOfQuestions":1019,"id":31,"isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":138},"__N_SSP":true}