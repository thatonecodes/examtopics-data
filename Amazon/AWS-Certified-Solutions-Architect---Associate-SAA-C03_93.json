{"pageProps":{"questions":[{"id":"HHjeFH5m8ms3tEgGhHYp","answers_community":["BD (100%)"],"question_text":"A company uses on-premises servers to host its applications. The company is running out of storage capacity. The applications use both block storage and NFS storage. The company needs a high-performing solution that supports local caching without re-architecting its existing applications.\n\nWhich combination of actions should a solutions architect take to meet these requirements? (Choose two.)","isMC":true,"topic":"1","question_images":[],"choices":{"E":"Deploy Amazon Elastic File System (Amazon EFS) volumes and mount them to on-premises servers.","C":"Deploy AWS Snowball Edge to provision NFS mounts to on-premises servers.","A":"Mount Amazon S3 as a file system to the on-premises servers.","B":"Deploy an AWS Storage Gateway file gateway to replace NFS storage.","D":"Deploy an AWS Storage Gateway volume gateway to replace the block storage."},"timestamp":"2023-05-17 15:56:00","answer":"BD","question_id":461,"url":"https://www.examtopics.com/discussions/amazon/view/109552-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1684331760,"answer_images":[],"answer_ET":"BD","discussion":[{"upvote_count":"7","poster":"cloudenthusiast","timestamp":"1700340840.0","comment_id":"901461","content":"Selected Answer: BD\nBy combining the deployment of an AWS Storage Gateway file gateway and an AWS Storage Gateway volume gateway, the company can address both its block storage and NFS storage needs, while leveraging local caching capabilities for improved performance."},{"timestamp":"1720468680.0","comment_id":"1117046","poster":"awsgeek75","upvote_count":"4","content":"Selected Answer: BD\nA: Not possible\nC: Snowball edge is snowball with computing. It's not a NAS!\nE: Technically yes but requires VPN or Direct Connect so re-architecture\nB & D both use Storage Gateway which can be used as NFS and Block storage\nhttps://aws.amazon.com/storagegateway/"},{"poster":"ftaws","content":"Use the Storage Gateway -> It means that use S3 for storage ?","upvote_count":"3","timestamp":"1718871900.0","comment_id":"1101438"},{"content":"DE\nB is not correct be cause NFS is a file system while storage gw is a storage. To replace a file system, need another file system which is EFS.","comments":[{"timestamp":"1716285000.0","content":"That's what i thought. but I think B is work too.","upvote_count":"2","comment_id":"1076248","poster":"Tekk97"},{"upvote_count":"1","timestamp":"1729861080.0","comment_id":"1201993","content":"if you focus on the wording of option B its \"Storage gateway File gateway\" not volume gateway hence it is perfect replacement for NFS files.","poster":"wizcloudifa"}],"upvote_count":"3","comment_id":"1049381","timestamp":"1713691440.0","poster":"thanhnv142"},{"poster":"TariqKipkemei","upvote_count":"3","timestamp":"1705128420.0","content":"Selected Answer: BD\nDeploy an AWS Storage Gateway file gateway to replace NFS storage\nDeploy an AWS Storage Gateway volume gateway to replace the block storage","comment_id":"950331"},{"poster":"elmogy","content":"Selected Answer: BD\nlocal caching is a key feature of AWS Storage Gateway solution\nhttps://aws.amazon.com/storagegateway/features/\nhttps://aws.amazon.com/blogs/storage/aws-storage-gateway-increases-cache-4x-and-enhances-bandwidth-throttling/#:~:text=AWS%20Storage%20Gateway%20increases%20cache%204x%20and%20enhances,for%20Volume%20Gateway%20customers%20...%205%20Conclusion%20","upvote_count":"4","comment_id":"908749","timestamp":"1701197520.0"},{"poster":"Piccalo","upvote_count":"2","content":"Selected Answer: BD\nB and D is the correct answer","comment_id":"900223","timestamp":"1700236560.0"}],"exam_id":31,"answer_description":""},{"id":"CmVIOxSKz4iq9zWJPmGX","timestamp":"2023-05-18 20:55:00","isMC":true,"answers_community":["C (100%)"],"unix_timestamp":1684436100,"question_text":"A company has a service that reads and writes large amounts of data from an Amazon S3 bucket in the same AWS Region. The service is deployed on Amazon EC2 instances within the private subnet of a VPC. The service communicates with Amazon S3 over a NAT gateway in the public subnet. However, the company wants a solution that will reduce the data output costs.\n\nWhich solution will meet these requirements MOST cost-effectively?","exam_id":31,"question_images":[],"choices":{"D":"Provision a second NAT gateway. Configure the route table for the private subnet to use this NAT gateway as the destination for all S3 traffic.","B":"Provision a dedicated EC2 NAT instance in the private subnet. Configure the route table for the public subnet to use the elastic network interface of this instance as the destination for all S3 traffic.","A":"Provision a dedicated EC2 NAT instance in the public subnet. Configure the route table for the private subnet to use the elastic network interface of this instance as the destination for all S3 traffic.","C":"Provision a VPC gateway endpoint. Configure the route table for the private subnet to use the gateway endpoint as the route for all S3 traffic."},"url":"https://www.examtopics.com/discussions/amazon/view/109667-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"C","answer_description":"","topic":"1","discussion":[{"comment_id":"901462","timestamp":"1700340900.0","poster":"cloudenthusiast","content":"Selected Answer: C\nA VPC gateway endpoint allows you to privately access Amazon S3 from within your VPC without using a NAT gateway or NAT instance. By provisioning a VPC gateway endpoint for S3, the service in the private subnet can directly communicate with S3 without incurring data transfer costs for traffic going through a NAT gateway.","upvote_count":"10"},{"content":"Selected Answer: C\nAs a rule of thumb, EC2<->S3 in your workload should always try to use a VPC gateway unless there is an explicit restriction (account etc.) which disallows it.","timestamp":"1720469520.0","comment_id":"1117057","upvote_count":"4","poster":"awsgeek75"},{"content":"Selected Answer: C\nUsing a VPC endpoint for S3 allows the EC2 instances to access S3 directly over the Amazon network without traversing the internet. This significantly reduces data output charges.","comment_id":"988346","timestamp":"1708700820.0","upvote_count":"3","poster":"Guru4Cloud"},{"timestamp":"1705128600.0","poster":"TariqKipkemei","content":"Selected Answer: C\nuse VPC gateway endpoint to route traffic internally and save on costs.","comment_id":"950333","upvote_count":"2"},{"upvote_count":"3","comment_id":"908750","timestamp":"1701197640.0","poster":"elmogy","content":"Selected Answer: C\nprivate subnet needs to communicate with S3 --> VPC endpoint right away"}],"answer":"C","answer_images":[],"question_id":462},{"id":"hByhM5rjyN8VUw8qncZN","answer_images":[],"topic":"1","answer_ET":"A","discussion":[{"content":"Selected Answer: A\nS3 Lifecycle policies allow you to define rules that automatically transition or expire objects based on their age or other criteria. By configuring an S3 Lifecycle policy to delete expired object versions and retain only the two most recent versions, you can effectively manage the storage costs while maintaining the desired retention policy. This solution is highly automated and requires minimal operational overhead as the lifecycle management is handled by S3 itself.","poster":"cloudenthusiast","upvote_count":"6","timestamp":"1700341020.0","comment_id":"901463"},{"comment_id":"945236","upvote_count":"5","content":"Selected Answer: A\nA --> \"you can also provide a maximum number of noncurrent versions to retain.\"\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/intro-lifecycle-rules.html","timestamp":"1704606180.0","poster":"VellaDevil"},{"comment_id":"1117061","content":"Selected Answer: A\nB: Too much work with Lambda\nC: Possible but requires lot of work\nD: Oxymoron statement... i.e. how do you remove version and retain version at same time without additional overhead? Custom solution may be more work.\nA: S3 Lifecycle is designed to retain object and version with set criteria","poster":"awsgeek75","upvote_count":"4","timestamp":"1720469820.0"},{"timestamp":"1708700640.0","comment_id":"988345","upvote_count":"3","poster":"Guru4Cloud","content":"Selected Answer: A\nUse S3 Lifecycle to delete expired object versions and retain the two most recent versions."},{"upvote_count":"3","content":"Selected Answer: A\nS3 Lifecycle to the rescue...whoooosh","comment_id":"950334","poster":"TariqKipkemei","timestamp":"1705128720.0"},{"comment_id":"915372","content":"Selected Answer: A\nA is correct.","poster":"antropaws","upvote_count":"3","timestamp":"1701781440.0"},{"upvote_count":"4","comment_id":"904610","content":"Selected Answer: A\nAgree with LONGMEN","poster":"Konb","timestamp":"1700726460.0"}],"answer":"A","question_id":463,"choices":{"D":"Deactivate versioning on the S3 bucket and retain the two most recent versions.","B":"Use an AWS Lambda function to check for older versions and delete all but the two most recent versions.","A":"Use S3 Lifecycle to delete expired object versions and retain the two most recent versions.","C":"Use S3 Batch Operations to delete noncurrent object versions and retain only the two most recent versions."},"question_images":[],"isMC":true,"answer_description":"","timestamp":"2023-05-18 20:57:00","exam_id":31,"question_text":"A company uses Amazon S3 to store high-resolution pictures in an S3 bucket. To minimize application changes, the company stores the pictures as the latest version of an S3 object. The company needs to retain only the two most recent versions of the pictures.\n\nThe company wants to reduce costs. The company has identified the S3 bucket as a large expense.\n\nWhich solution will reduce the S3 costs with the LEAST operational overhead?","unix_timestamp":1684436220,"answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/109668-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"iXNP6pNK4AarKmILrSy0","question_images":[],"answer_ET":"D","isMC":true,"discussion":[{"poster":"Abrar2022","comment_id":"915059","timestamp":"1701757620.0","upvote_count":"11","content":"Selected Answer: D\nHosted Connection 50 Mbps, 100 Mbps, 200 Mbps,\nDedicated Connection 1 Gbps, 10 Gbps, and 100 Gbps"},{"comment_id":"901369","content":"Selected Answer: D\nD \n\nFor Dedicated Connections, 1 Gbps, 10 Gbps, and 100 Gbps ports are available. For Hosted Connections, connection speeds of 50 Mbps, 100 Mbps, 200 Mbps, 300 Mbps, 400 Mbps, 500 Mbps, 1 Gbps, 2 Gbps, 5 Gbps and 10 Gbps may be ordered from approved AWS Direct Connect Partners. See AWS Direct Connect Partners for more information.","timestamp":"1700331720.0","poster":"norris81","upvote_count":"5"},{"comment_id":"1160034","poster":"Ravan","timestamp":"1724694720.0","upvote_count":"4","content":"Selected Answer: D\nNo, you cannot directly adjust the speed of an existing Direct Connect connection through the AWS Management Console.\n\nTo adjust the speed of an existing Direct Connect connection, you typically need to contact your Direct Connect service provider. They can assist you in modifying the speed of your connection based on your requirements. Depending on the provider, this process may involve submitting a request or contacting their support team to initiate the necessary changes. Keep in mind that adjusting the speed of your Direct Connect connection may also involve contractual and billing considerations."},{"upvote_count":"4","comment_id":"1117067","poster":"awsgeek75","content":"Selected Answer: D\nA: Not secure as sharing with another account\nB: I don't think this possible as you need ISP to setup Direct Connect\nC: Less secure due to sharing\nD: Direct connect partners can provide hosted solutions for existing accounts so correct answer","timestamp":"1720470060.0","comments":[{"upvote_count":"2","comment_id":"1117070","poster":"awsgeek75","content":"For B I'm wrong above, it's because you cannot order 200MB connection through management console.","timestamp":"1720470180.0"}]},{"comment_id":"1111028","upvote_count":"3","poster":"pentium75","content":"Selected Answer: D\n< 1 Gbps = Hosted (through partner)","timestamp":"1719814620.0"},{"timestamp":"1708700400.0","poster":"Guru4Cloud","comments":[{"comment_id":"988344","upvote_count":"6","content":"I meant D.. DDDDDDDDDD","poster":"Guru4Cloud","timestamp":"1708700400.0"}],"content":"Selected Answer: B\nIf you already have an existing AWS Direct Connect connection configured at 1 Gbps, and you wish to reduce the connection bandwidth to 200 Mbps to minimize costs, you should indeed contact your AWS Direct Connect Partner and request to lower the connection speed to 200 Mbps.","upvote_count":"4","comment_id":"988343"},{"content":"BBBBBBBBBBBBBB","timestamp":"1701318120.0","comment_id":"910737","poster":"omoakin","upvote_count":"2"},{"poster":"elmogy","comment_id":"908755","upvote_count":"5","content":"Selected Answer: D\ncompany need to setup a cheaper connection (200 M) but B is incorrect because you can only order port speeds of 1, 10, or 100 Gbps\nfor more flexibility you can go with hosted connection, You can order port speeds between 50 Mbps and 10 Gbps. \n\nhttps://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-direct-connect.html","timestamp":"1701198180.0"},{"timestamp":"1700341320.0","comment_id":"901467","comments":[],"content":"Selected Answer: B\nBy opting for a lower capacity 200 Mbps connection instead of the 1 Gbps connection, the company can significantly reduce costs. This solution ensures a dedicated and secure connection while aligning with the company's low utilization, resulting in cost savings.","poster":"cloudenthusiast","upvote_count":"4"},{"content":"Selected Answer: D\nA hosted connection is a lower-cost option that is offered by AWS Direct Connect Partners","poster":"nosense","upvote_count":"5","comment_id":"899997","timestamp":"1700224200.0","comments":[{"poster":"Efren","content":"Also, there are not 200 MBps direct connection speed.","comment_id":"900952","timestamp":"1700304720.0","comments":[{"timestamp":"1700389560.0","comment_id":"901762","content":"Hosted Connection 50 Mbps, 100 Mbps, 200 Mbps, \nDedicated Connection 1 Gbps, 10 Gbps, and 100 Gbps\nB would require the company to purchase additional hardware or software","upvote_count":"3","poster":"nosense"}],"upvote_count":"1"}]}],"choices":{"B":"Set up a new 200 Mbps Direct Connect connection in the AWS Management Console.","D":"Contact an AWS Direct Connect Partner to order a 200 Mbps hosted connection for an existing AWS account.","A":"Set up a new 1 Gbps Direct Connect connection. Share the connection with another AWS account.","C":"Contact an AWS Direct Connect Partner to order a 1 Gbps connection. Share the connection with another AWS account."},"timestamp":"2023-05-17 12:30:00","url":"https://www.examtopics.com/discussions/amazon/view/109515-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"answer_images":[],"unix_timestamp":1684319400,"answer":"D","question_text":"A company needs to minimize the cost of its 1 Gbps AWS Direct Connect connection. The company's average connection utilization is less than 10%. A solutions architect must recommend a solution that will reduce the cost without compromising security.\n\nWhich solution will meet these requirements?","answers_community":["D (82%)","B (18%)"],"question_id":464,"answer_description":"","topic":"1"},{"id":"CtYlkqb8m8d8CTE1JVHY","timestamp":"2022-10-10 11:39:00","choices":{"B":"Configure the Application Load Balancer to direct a user to the server with the documents","A":"Copy the data so both EBS volumes contain all the documents","D":"Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server","C":"Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS"},"question_text":"A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that, each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.\nWhat should a solutions architect propose to ensure users see all of their documents at once?","answer":"C","question_id":465,"topic":"1","answers_community":["C (98%)","2%"],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/84981-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1665394740,"exam_id":31,"question_images":[],"answer_images":[],"isMC":true,"discussion":[{"timestamp":"1665394740.0","content":"Selected Answer: C\nConcurrent or at the same time key word for EFS","poster":"D2w","upvote_count":"54","comment_id":"690945"},{"timestamp":"1668551160.0","comment_id":"719165","upvote_count":"40","content":"Ebs doesnt support cross az only reside in one Az but Efs does, that why it's c","poster":"mikey2000","comments":[{"timestamp":"1683399000.0","content":"And just for clarification to others, you can have COPIES of the same EBS volume in one AZ and in another via EBS Snapshots, but don't confuse that with the idea of having some sort of global capability that has concurrent copying mechanisms.","poster":"pbpally","comment_id":"890948","upvote_count":"10"}]},{"content":"Selected Answer: C\nThe correct anszwer to this question is C question EBS volumes are AZ locked so when transferring the architecture to a different AZ the data can no longer be received by users whereas with EFS volume we can EC2 instances across AZs","comment_id":"1400754","upvote_count":"1","poster":"melvis8","timestamp":"1742420040.0"},{"upvote_count":"1","timestamp":"1742216040.0","poster":"kimardamina","comment_id":"1399646","content":"Selected Answer: C\nMy immediate understanding was the fact that EFS is multi az and will make it less complex as a solution for this."},{"content":"Selected Answer: C\nNot A: because it requires sync between the EBS volumes which is complex and not scalable.\nNot B: It's not scalable if the LB only directs user to one instance\nNot D: Impractical. The application will need to have a mechanism to merge the responses coming from 2 instance","comment_id":"1366130","timestamp":"1741318560.0","poster":"francisizme","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nUse common storage like EFS so that the instances can access the document without any hassle and without being uploaded into them separately","comment_id":"1345884","poster":"Mrigraj12","timestamp":"1737696660.0"},{"poster":"ANDREWKIM1","timestamp":"1735695360.0","comment_id":"1335098","upvote_count":"1","content":"Selected Answer: C\nAmazon S3 is the optimal solution for this scenario. It provides centralized, scalable, and highly available storage, ensuring that all users can see all their documents regardless of which instance they are routed to."},{"comment_id":"954305","upvote_count":"5","content":"Selected Answer: C\nThe answer is C. Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS.\n\nThe current architecture is using two separate EBS volumes, one for each EC2 instance. This means that each instance only has a subset of the documents. When a user refreshes the website, the Application Load Balancer will randomly direct them to one of the two instances. If the user's documents are not on the instance that they are directed to, they will not be able to see them.","timestamp":"1727009760.0","poster":"Guru4Cloud"},{"content":"Selected Answer: C\nTo ensure that users see all of their documents at once, the solutions architect should propose Option C: Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS.\n\nOption C involves copying the data from both EBS volumes to Amazon Elastic File System (EFS), and modifying the application to save new documents to EFS. Amazon EFS is a fully managed, scalable file storage service that allows you to store and access files from multiple EC2 instances concurrently. By moving the data to EFS and modifying the application to save new documents to EFS, the application will be able to access all of the documents from a single, centralized location, ensuring that users see all of their documents at once.\n\nOverall, Option C is the most effective solution for ensuring that users see all of their documents at once.","poster":"Buruguduystunstugudunstuy","comment_id":"750528","upvote_count":"6","comments":[{"comment_id":"750531","poster":"Buruguduystunstugudunstuy","content":"***WRONG***\nOption A involves copying the data so both EBS volumes contain all the documents. This option would not solve the issue, as the data is still stored on two separate EBS volumes, and the application would still need to read from both volumes to retrieve all of the documents.\n\nOption B involves configuring the Application Load Balancer to direct a user to the server with the documents. This option would not solve the issue, as the user may not always be directed to the server that has the documents they are looking for.\n\nOption D involves configuring the Application Load Balancer to send the request to both servers and return each document from the correct server. This option would not be an efficient solution, as it would require the application to send requests to both servers and receive and process the responses from both servers, which could increase the load on the application.","timestamp":"1671513840.0","upvote_count":"4"}],"timestamp":"1726903260.0"},{"content":"Selected Answer: C\nKeyword: \nsecond EC2 instance and EBS volume. They could see one subset of their documents or the other, but never all of the documents at the same time.\n\nEBS: attached to one instance (special EBS io1, io2 can attached to multiple instances but not much)\nEFS: can attached to multiple instances\n\nA: Incorrect - EBS volumes don't have function to copy data from running EBS volume to running EBS volume. \nB: Incorrect - We can use sticky session to forward same user to the same server but when user lose the session the user might be forward to another server.\nC: Correct - Because 2 instance now point to one EFS data storage, user will see both data.\nD: Incorrect - We only use Traffic Mirroring to sent request to both servers. Application Load Balancer don't support send request to both servers because it's design it balance workload between server. And also ALB cannot combine document from both servers and return.","comment_id":"860521","poster":"PhucVuu","timestamp":"1726903260.0","upvote_count":"10"},{"upvote_count":"3","poster":"IMTechguy","content":"Option A is not a good solution because copying data to both volumes would not ensure consistency of the data.\n\nOption B would require the Load Balancer to have knowledge of which documents are stored on which server, which would be difficult to maintain.\n\nOption C is a viable solution, but may require modifying the application to use Amazon EFS instead of EBS.\n\nOption D is a good solution because it would distribute the requests to both servers and return the correct document from the correct server. This can be achieved by configuring session stickiness on the Load Balancer so that each user's requests are directed to the same server for consistency.\n\nTherefore, the correct answer is D.","comments":[{"content":"Sending requests to both servers can increase the response time since it would require checking two servers instead of one.\nSession stickiness only works if the user has data in only one of the servers; otherwise, it would continue missing data.\nOption C is not the best option, but is the one that fits better.","comment_id":"1298321","poster":"Anthony_Rodrigues","timestamp":"1729005120.0","upvote_count":"1"}],"timestamp":"1726903260.0","comment_id":"877593"},{"upvote_count":"1","timestamp":"1723278660.0","comment_id":"1263388","content":"Ans C. Altho' A could do it, it would require a manual operation; the clue is \"better scalability and availability\" - EFS does that automatically","poster":"PaulGa"},{"poster":"aquarian_ngc","comment_id":"1246411","timestamp":"1720747320.0","content":"Correct Answer is C","upvote_count":"2"},{"timestamp":"1719254880.0","content":"Selected Answer: C\nC is correct answer.","comment_id":"1236552","poster":"williamsmith95","upvote_count":"3"},{"poster":"ChymKuBoy","timestamp":"1717564440.0","upvote_count":"2","comment_id":"1224524","content":"Selected Answer: C\nC for sure"},{"poster":"Ishu_","comment_id":"1220953","timestamp":"1716987840.0","upvote_count":"3","content":"Selected Answer: C\nusing Amazon EFS to provide a shared storage solution ensures that both EC2 instances can access the same documents, which resolves the issue of users seeing different subsets of documents depending on which instance they are connected to."},{"comment_id":"1197138","content":"C is Correct whereas the purpose of Amazon EFS is to provide a scalable, shared, and fully managed file storage solution that seamlessly integrates with AWS services and meets the performance, availability, and durability requirements of modern applications.","upvote_count":"1","timestamp":"1713347340.0","poster":"Muavia"},{"comment_id":"1172554","upvote_count":"1","poster":"TilTil","timestamp":"1710334200.0","content":"Selected Answer: C\nThe alternative is to use Aurora or DynamoDB with master-slave replication, otherwise EFS is the most logical."},{"comment_id":"1150337","timestamp":"1707927960.0","upvote_count":"3","poster":"TheFivePips","content":"Selected Answer: C\nEBS volumes must be in the same AZ as the instances they are attached to. So you cannot share an EBS across AZs. Unless you plan to have two separate volumes in each AZ, the simpliest solution is to use EFS as a shared file system that can be used across both AZs","comments":[{"comment_id":"1152446","poster":"sidharthwader","upvote_count":"1","content":"Correct EBS can be used for one Az if you need the a solution which could be accessed across a AZ then go for File storage which is a regional service","timestamp":"1708158600.0"}]},{"comment_id":"1149549","timestamp":"1707855480.0","poster":"ldruizsan","upvote_count":"1","content":"Selected Answer: C\nIf the idea is to keep documents in different places, then the only solution here is a file sharing system, EFS in this case"},{"poster":"awsgeek75","content":"Selected Answer: C\nABD are not even possible without further deails\nC is EFS which is shared volume.","upvote_count":"1","comment_id":"1121952","timestamp":"1705170420.0"},{"comment_id":"1121603","poster":"A_jaa","timestamp":"1705148460.0","content":"Selected Answer: C\nAnswer-c","upvote_count":"1"},{"poster":"adamslee","content":"EBS can exist only one AZ. so C","upvote_count":"2","comment_id":"1104413","timestamp":"1703382060.0"},{"comment_id":"1104139","upvote_count":"3","content":"Selected Answer: C\nCopy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS: Amazon Elastic File System (EFS) provides a simple, scalable, elastic file storage for use with AWS Cloud services and on-premises resources. It is designed to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as files are added and removed. By moving the documents to EFS, both EC2 instances can access all the documents at the same time, resolving the issue.","poster":"wyejay","timestamp":"1703351280.0"},{"timestamp":"1699275480.0","comment_id":"1063850","upvote_count":"1","poster":"Hayden001","content":"Proposed = new service = EFS"},{"timestamp":"1698238260.0","comment_id":"1053735","upvote_count":"1","content":"Keyword \"stores user-uploaded documents\". Two EC2 instances behind Application Load Balancer. In the diagram, Per Amazon EC2 in a different Availability zone, and Amazon Elastic File System support this case.","poster":"Ruffyit"},{"upvote_count":"1","content":"C is correct","poster":"bnagaraja9099","timestamp":"1697374080.0","comment_id":"1044138"},{"comment_id":"1027859","upvote_count":"2","timestamp":"1696758840.0","content":"Selected Answer: D\nOption C (copying data to Amazon EFS and modifying the application) is a valid alternative, but it may require more changes to the application code and data migration to EFS. This option is suitable when you want to centralize shared data storage.\n\nIn summary, option D is the most straightforward and scalable solution to ensure that users can access all of their documents when using multiple EC2 instances behind an Application Load Balancer.","comments":[{"timestamp":"1701099960.0","comment_id":"1081719","content":"No. The point of an LB to achieve scalability is to send DIFFERENT requests to different instances of the service NOT the SAME request to different services. That doesn't scale well.","upvote_count":"1","poster":"0xE8D4A51000"}],"poster":"mattuyghur"},{"content":"Selected Answer: C\nEFS is to muliple AZ","comment_id":"998622","poster":"RNess","upvote_count":"1","timestamp":"1693839120.0"},{"timestamp":"1690432620.0","content":"Selected Answer: C\nShared file storage = EFS","comment_id":"964331","poster":"TariqKipkemei","upvote_count":"1"},{"content":"Selected Answer: C\nKeyword \"stores user-uploaded documents\". Two EC2 instances behind Application Load Balancer. \n\nIn the diagram, Per Amazon EC2 in a different Availability zone, and Amazon Elastic File System support this case.","timestamp":"1689400620.0","upvote_count":"1","poster":"james2033","comment_id":"952039"},{"content":"Option C MET THE REQUIREMENT","poster":"miki111","upvote_count":"1","timestamp":"1689176520.0","comment_id":"949954"},{"comment_id":"944649","content":"They could use Sicky sessions with EBS, if they don't want to use EFS","upvote_count":"1","poster":"FroZor","comments":[{"timestamp":"1694151060.0","comment_id":"1002145","content":"no, they want to see both documents so must be EFS, not sticky sessions.","poster":"datmd77","upvote_count":"1"}],"timestamp":"1688647260.0"},{"content":"EFS Reduces latency and all user can see all files at once","poster":"capino","upvote_count":"1","comment_id":"942053","timestamp":"1688402400.0"},{"upvote_count":"4","timestamp":"1687019280.0","poster":"cookieMr","content":"Selected Answer: C\nTo ensure users can see all their documents at once in the duplicated architecture with multiple EC2 instances and EBS volumes behind an Application Load Balancer, the most appropriate solution is Option C: Copy the data from both EBS volumes to Amazon EFS (Elastic File System) and modify the application to save new documents to Amazon EFS.\n\nIn summary, Option C, which involves copying the data to Amazon EFS and modifying the application to use Amazon EFS for document storage, is the most appropriate solution to ensure users can see all their documents at once in the duplicated architecture. Amazon EFS provides scalability, availability, and shared access, allowing both EC2 instances to access and synchronize the documents seamlessly.","comment_id":"926119"},{"timestamp":"1685624160.0","upvote_count":"1","content":"Selected Answer: C\nC is right answer.","comment_id":"912120","poster":"Bmarodi"},{"timestamp":"1684872420.0","poster":"Praveen_Ch","comment_id":"905202","upvote_count":"1","content":"Selected Answer: C\nC because the other options don't put all the data in one place."},{"upvote_count":"1","poster":"smash_aws","content":"Option C is the best answer, option D is pretty vague. All other options are obviously wrong.","timestamp":"1684627920.0","comment_id":"902822"},{"content":"The answer is B as it is aligned to min. b/w usage and also the time taken is 6-7 days which is about the same as transferring over the internet of 1G as per option C.","timestamp":"1684546080.0","comment_id":"902313","upvote_count":"2","poster":"abhishek2021"},{"poster":"cheese929","upvote_count":"1","comment_id":"897313","content":"Selected Answer: C\nC is correct","timestamp":"1684045800.0"},{"poster":"linux_admin","content":"Selected Answer: C\nOption C proposes copying the data from both EBS volumes to Amazon EFS and modifying the application to save new documents to EFS. This would ensure that all documents are accessible from both servers as EFS is a shared file storage service that can be mounted on multiple instances simultaneously. Additionally, modifying the application to save new documents to EFS would ensure that any new documents are available on both servers.","comment_id":"855977","upvote_count":"1","timestamp":"1680195180.0"},{"content":"Selected Answer: C","comment_id":"852674","poster":"alexiscloud","timestamp":"1679970240.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"847895","content":"Selected Answer: C\nEBS AZ locked bạn ơi :)","poster":"tienhoboss","timestamp":"1679554740.0"},{"upvote_count":"1","poster":"iamRohanKaushik","content":"Selected Answer: C\nAnswer is C.","comment_id":"845533","timestamp":"1679374140.0"},{"poster":"bilel500","comment_id":"819193","content":"Selected Answer: C\nEFS automatically scales as users upload and delete files. EBS volumes can scale vertically by reconfiguring volume types and horizontally by managing additional EC2 volumes.","upvote_count":"1","timestamp":"1677156240.0"},{"comment_id":"807020","poster":"buiducvu","content":"Selected Answer: C\nCorrect answer: C","timestamp":"1676258880.0","upvote_count":"1"},{"comment_id":"803947","upvote_count":"1","poster":"dvoaviarison","content":"Selected Answer: C\nEFS allows to share storage","timestamp":"1676000940.0"},{"poster":"SaiPavan10","timestamp":"1675478280.0","comment_id":"797549","upvote_count":"1","content":"option C makes sense."},{"upvote_count":"4","comment_id":"767815","content":"Selected Answer: C\nAmazon Elastic File System (EFS) is a fully managed file storage service that enables users to store and access data in the Amazon cloud. EFS is accessible over the network and can be mounted on multiple Amazon EC2 instances. By copying the data from both EBS volumes to EFS and modifying the application to save new documents to EFS, users will be able to access all of their documents at the same time.","timestamp":"1673016960.0","poster":"SilentMilli"},{"upvote_count":"1","poster":"pazabal","comment_id":"749809","content":"Selected Answer: C\nEFS is useful to store files from multiple AZs to a single storage. On the other hand, for EBS files must be within the same AZ as the EBS volume","timestamp":"1671452820.0"},{"poster":"psr83","content":"Selected Answer: C\nAmazon EFS provides shared file storage for use with compute instances in the AWS Cloud and on-premises servers. Applications that require shared file access can use Amazon EFS for reliable file storage delivering high aggregate throughput to thousands of clients simultaneously.","timestamp":"1671431820.0","upvote_count":"1","comment_id":"749542"},{"comment_id":"747430","upvote_count":"1","poster":"NikaCZ","content":"Selected Answer: C\nEFS can be mounted to multiple EC2 instances across AZs. The Performance is higher latency & throughput.","timestamp":"1671209520.0"},{"poster":"Myxa","content":"Selected Answer: C\nCorrect answer: C","timestamp":"1671192180.0","upvote_count":"1","comment_id":"747140"},{"comment_id":"734970","timestamp":"1670146380.0","upvote_count":"1","poster":"javitech83","content":"Selected Answer: C\nc is correct"},{"content":"Selected Answer: C\nC is the only solution that make sense.","comment_id":"724365","poster":"cheese929","upvote_count":"1","timestamp":"1669125960.0"},{"comment_id":"723462","upvote_count":"1","content":"C is correct","timestamp":"1669033320.0","poster":"Wpcorgan"},{"content":"Amazon Elastic File System is a cloud storage service provided by Amazon Web Services designed to provide scalable, elastic and concurrency. Answer is C","poster":"Azeeza","comment_id":"714178","upvote_count":"4","timestamp":"1667955480.0"},{"timestamp":"1667673060.0","upvote_count":"2","content":"It's C, EFS can be mounted to multiple EC2 instances across AZs. The Performance is higher latency & throughput.","poster":"pm2229","comment_id":"711949"},{"poster":"17Master","timestamp":"1666994580.0","upvote_count":"1","content":"Selected Answer: C\nAns is C","comment_id":"706779"},{"timestamp":"1666132740.0","content":"Selected Answer: C\nAnswer is C.\nAdaptive throughput – EFS’s performance can scale in-line with its storage, operating at a higher throughput for sudden, high-volume file dumps, reaching up to 500,000 IOPS or 10 GB per second\nTotally elastic – once you’ve spun up an EFS instance, you can add add files without worrying about provisioning or disturbing your application’s performance\nAdditional accessibility – EFS can be mounted from different EC2 instances, but it can also cross the AWS region boundary via the use of VPC peering","upvote_count":"4","comment_id":"698540","poster":"bilel500"},{"content":"CCCCCCCCCCCC","timestamp":"1665946320.0","comment_id":"696443","poster":"queen101","upvote_count":"1"},{"comment_id":"692574","content":"Selected Answer: C\nI'm not sure if ALB could configure like session ID thing, so I choose C","upvote_count":"1","poster":"BoboChow","timestamp":"1665542220.0"}],"answer_ET":"C"}],"exam":{"lastUpdated":"11 Apr 2025","isImplemented":true,"id":31,"provider":"Amazon","numberOfQuestions":1019,"isBeta":false,"isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":93},"__N_SSP":true}