{"pageProps":{"questions":[{"id":"yem6Qb0wAa8ijRSy0Pm3","choices":{"C":"Amazon Aurora with auto scaling enabled","D":"Amazon Aurora in a serverless mode","B":"Amazon DynamoDB with on-demand capacity mode","A":"Amazon DynamoDB with provisioned capacity mode and auto scaling"},"answer_images":[],"exam_id":22,"answer_ET":"D","question_text":"A database specialist is designing an application to answer one-time queries. The application will query complex customer data and provide reports to end users.\nThese reports can include many fields. The database specialist wants to give users the ability to query the database by using any of the provided fields.\nThe database's traffic volume will be high but variable during peak times. However, the database will not have much traffic at other times during the day.\nWhich solution will meet these requirements MOST cost-effectively?","answer_description":"","question_id":96,"answers_community":["D (100%)"],"unix_timestamp":1636969500,"question_images":[],"discussion":[{"poster":"Justu","timestamp":"1638345120.0","content":"Hard question. As \"database specialist want to enable users to query the database using any of the fields offered\" I think DynamoDB is out of the question. \nSo it leave C and D. As max load is not known in the peak hours, (variables), then then D is the only option. In C, with autoscaling, you would need to define min and max ACUs for the autoscaling.","comments":[{"poster":"lollyj","comment_id":"756097","content":"DynamoDB out of question? I thought it would qualigy because GSIs are predetermined and flexible. I'm confused....","upvote_count":"1","timestamp":"1672013520.0"}],"upvote_count":"11","comment_id":"491388"},{"poster":"RotterDam","content":"Guys - I see this constant confusion about when to use On Demand vs Provisioned w/ Autoscaling. There's a HUGE HUGE difference in cost when it comes to On Demand especially for large applications (typically AWS asks about large applications). It can be SEVEN times higher. Autoscaling can adjust to almost negligible capacity during off peak hours to large capacity during peak . Usually the winner here is autoscaling with Provisioned!!\n\nWhile on-demand delivers the best fit for scalability, the cost is approximately seven times higher than provisioned capacity. In addition, provisioned capacity offers the option to purchase reserved capacity, which can save between 40% and 80% compared to non-reserved provisioned capacity. This means on-demand could cost between 15 times and 20 times more than reserved provisioned capacity for some configurations. For small applications, the flexibility of on-demand may be worth the extra cost, but for large applications, it can mean spending hundreds or thousands of dollars more per month","timestamp":"1646505240.0","upvote_count":"5","comment_id":"561574"},{"upvote_count":"1","content":"Selected Answer: D\nD. Amazon Aurora in a serverless mode","comment_id":"994751","timestamp":"1693457220.0","poster":"Pranava_GCP"},{"poster":"Dantas","upvote_count":"1","comment_id":"609431","content":"Selected Answer: D\nLarge amounts of client data would require large amounts of RCUs.\nQuery the database using any of the fields offered ins't a good match for key/value storage.","timestamp":"1653938460.0"},{"comment_id":"595032","poster":"novice_expert","content":"Selected Answer: D\nRDS for query on any field\nC. auto scaling can be option if we know more about load\nD. Aurora Serverless for current info","upvote_count":"2","timestamp":"1651324920.0"},{"content":"Selected Answer: D\nOption D","poster":"GMartinelli","timestamp":"1638447360.0","upvote_count":"4","comment_id":"492441"},{"content":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html#limits-items","timestamp":"1638342120.0","comment_id":"491361","upvote_count":"1","poster":"cynthiacy"},{"content":"I voted for D as well.","timestamp":"1638341940.0","upvote_count":"2","comment_id":"491355","poster":"cynthiacy"},{"comment_id":"478583","content":"Option D.","upvote_count":"2","timestamp":"1636969500.0","poster":"leunamE"}],"topic":"1","timestamp":"2021-11-15 10:45:00","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/66062-exam-aws-certified-database-specialty-topic-1-question-185/","answer":"D"},{"id":"wY9em90bQaF50IZMkdKF","url":"https://www.examtopics.com/discussions/amazon/view/79511-exam-aws-certified-database-specialty-topic-1-question-186/","answer":"C","discussion":[{"comment_id":"903965","upvote_count":"4","poster":"aviathor","timestamp":"1684753440.0","content":"Selected Answer: C\nWhat bothers me with A, B and D is that they refer to \"replica instance endpoint\" either as the application DB endpoint, or as a report query endpoint, instead of a \"reader endpoint\". \n\nUsing a \"replica instance endpoint\" defeats the failover mechanism, so that will never make sense."},{"content":"Selected Answer: C\nC is correct. Aurora is 20% more expensive than RDS per instance. However, if you want RDS to have high availability and even read replicas, you need 3 instances and Aurora only needs 2.","poster":"fufufu","timestamp":"1684055340.0","upvote_count":"2","comment_id":"897426"},{"timestamp":"1682300520.0","comment_id":"878939","upvote_count":"1","poster":"SeemaDataReader","content":"Selected Answer: B\nI would go for B as the MOST cost effective is the keyword. It also satisfies the condition of Highly Available"},{"timestamp":"1680956820.0","upvote_count":"1","poster":"mbadioum","comment_id":"864678","content":"I think B for cost-effective solution"},{"poster":"lollyj","timestamp":"1672014600.0","upvote_count":"1","comment_id":"756105","content":"Selected Answer: B\nAurora is 20% more expensive."},{"content":"Selected Answer: C\nKeyword: significant amount of downtime, \n\nFailover\n\nIn RDS, Failover to read replica is done manually, which could lead to data loss. You can use Multi-AZ (Standby instance) feature for automatic failover, and to prevent downtime and data loss.\n\nIn Aurora, Failover to read replica is done automatically to prevent data loss. Failover time is faster on Aurora.","upvote_count":"1","timestamp":"1671513120.0","comment_id":"750515","poster":"SouvikC94"},{"poster":"khun","timestamp":"1671342180.0","comment_id":"748623","upvote_count":"2","content":"Selected Answer: B\nIt's B. looking for cost-effective approach.\nAurora instances will cost you ~20% more than RDS MySQL. If you create Aurora read replicas then the cost of your Aurora cluster will double. Aurora is only available on certain RDS instance sizes."},{"poster":"vkruger","comment_id":"735457","upvote_count":"1","content":"Selected Answer: B\nThe company requires a solution that is highly available and the most cost-effective.\nKeyword is \"highly available\"\nMy answer is B","timestamp":"1670188320.0"},{"timestamp":"1662386760.0","poster":"Adi_M","comment_id":"660249","content":"Selected Answer: C\nreader endpoint - is the keyword","upvote_count":"2"},{"comment_id":"658325","upvote_count":"1","comments":[{"timestamp":"1663139460.0","content":"Changing to C as B will need 3 instances whereas is aurora can do the same with 2 instances.","poster":"SonamDhingra","upvote_count":"1","comment_id":"668698"}],"content":"B is correct","timestamp":"1662200340.0","poster":"SonamDhingra"},{"poster":"mbar94","timestamp":"1662139740.0","comment_id":"657658","upvote_count":"1","content":"Selected Answer: C\nSeems that it's C. https://aws.amazon.com/about-aws/whats-new/2016/09/reader-end-point-for-amazon-aurora/"}],"timestamp":"2022-09-02 19:29:00","unix_timestamp":1662139740,"answer_ET":"C","choices":{"D":"Create an Amazon Aurora DB cluster and configure an Aurora Replica in a different Availability Zone. Configure the application to reference the primary DB instance endpoint and report queries to reference the replica instance endpoint.","C":"Create an Amazon Aurora DB cluster and configure an Aurora Replica in a different Availability Zone. Configure the application to reference the cluster endpoint and report queries to reference the reader endpoint.","B":"Create an Amazon RDS for MySQL Multi-AZ DB instance and configure a read replica in a different Availability Zone. Configure the application to reference the primary DB instance endpoint and report queries to reference the replica instance endpoint.","A":"Create an Amazon RDS for MySQL Multi-AZ DB instance and configure a read replica in a different Availability Zone. Configure the application to reference the replica instance endpoint and report queries to reference the primary DB instance endpoint."},"topic":"1","answer_images":[],"question_images":[],"exam_id":22,"answers_community":["C (67%)","B (33%)"],"answer_description":"","isMC":true,"question_id":97,"question_text":"A financial services company runs an on-premises MySQL database for a critical application. The company is dissatisfied with its current database disaster recovery (DR) solution. The application experiences a significant amount of downtime whenever the database fails over to its DR facility. The application also experiences slower response times when reports are processed on the same database. To minimize the downtime in DR situations, the company has decided to migrate the database to AWS. The company requires a solution that is highly available and the most cost-effective.\nWhich solution meets these requirements?"},{"id":"qQX3OqToozZbT0sDxNVn","question_id":98,"question_text":"A company with 500,000 employees needs to supply its employee list to an application used by human resources. Every 30 minutes, the data is exported using the LDAP service to load into a new Amazon DynamoDB table. The data model has a base table with Employee ID for the partition key and a global secondary index with Organization ID as the partition key.\nWhile importing the data, a database specialist receives ProvisionedThroughputExceededException errors. After increasing the provisioned write capacity units\n(WCUs) to 50,000, the specialist receives the same errors. Amazon CloudWatch metrics show a consumption of 1,500 WCUs.\nWhat should the database specialist do to address the issue?","answer_description":"","answer_images":[],"isMC":true,"unix_timestamp":1662139980,"topic":"1","discussion":[{"content":"Selected Answer: A\nAnswer A - hot partition. https://aws.amazon.com/premiumsupport/knowledge-center/dynamodb-table-throttled/","poster":"mbar94","upvote_count":"6","timestamp":"1662139980.0","comment_id":"657659"},{"comment_id":"903992","poster":"aviathor","upvote_count":"1","content":"Selected Answer: B\nGiven the CloudWatch metric, the error cannot be due to write capacity, so any answer consisting in adjusting write capacity has to be discarded.","timestamp":"1684755240.0"},{"comment_id":"780396","poster":"parle101","upvote_count":"1","timestamp":"1674073380.0","content":"Selected Answer: D\nhttps://stackoverflow.com/questions/31468379/how-to-solve-throughput-error-for-dynamodb\nhttps://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/dynamodbv2/model/ProvisionedThroughputExceededException.html"},{"content":"Selected Answer: A\nA is correct","poster":"cloudsunriser","timestamp":"1664125860.0","comment_id":"679024","upvote_count":"1"},{"upvote_count":"1","poster":"SonamDhingra","content":"Selected Answer: A\nA is correct","comment_id":"668699","timestamp":"1663139520.0"}],"answer_ET":"A","timestamp":"2022-09-02 19:33:00","url":"https://www.examtopics.com/discussions/amazon/view/79512-exam-aws-certified-database-specialty-topic-1-question-187/","choices":{"D":"Increase the number of retries on the bulk loading application.","B":"Enable auto scaling for the table to automatically increase write capacity during bulk imports.","A":"Change the data model to avoid hot partitions in the global secondary index.","C":"Modify the table to use on-demand capacity instead of provisioned capacity."},"exam_id":22,"answers_community":["A (80%)","10%","10%"],"answer":"A","question_images":[]},{"id":"GdKvqk2iBsjadaMMLP2X","url":"https://www.examtopics.com/discussions/amazon/view/79663-exam-aws-certified-database-specialty-topic-1-question-188/","question_text":"A company has an application that uses an Amazon DynamoDB table as its data store. During normal business days, the throughput requirements from the application are uniform and consist of 5 standard write calls per second to the DynamoDB table. Each write call has 2 KB of data.\nFor 1 hour each day, the company runs an additional automated job on the DynamoDB table that makes 20 write requests per second. No other application writes to the DynamoDB table. The DynamoDB table does not have to meet any additional capacity requirements.\nHow should a database specialist configure the DynamoDB table's capacity to meet these requirements MOST cost-effectively?","discussion":[{"poster":"mbar94","comment_id":"658016","upvote_count":"6","timestamp":"1662174480.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html\n\nIt's C. 5x2KB = 10 WCU + auto scaling needed as well for peak time."},{"content":"Selected Answer: C\nC is the answer based on this doc.\n\nIf the batch occurs at scheduled times, you can schedule an increase to your auto- scaling capacity before it runs\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CostOptimization_TableCapacityMode.html","poster":"parle101","comment_id":"758368","upvote_count":"1","timestamp":"1672136760.0"},{"comment_id":"658329","timestamp":"1662200460.0","poster":"SonamDhingra","upvote_count":"1","content":"Selected Answer: C\nC is correct"}],"answer_ET":"C","choices":{"C":"Use DynamoDB provisioned capacity with 10 WCUs and auto scaling.","A":"Use DynamoDB provisioned capacity with 5 WCUs and auto scaling.","B":"Use DynamoDB provisioned capacity with 5 WCUs and a write-through cache that DynamoDB Accelerator (DAX) provides.","D":"Use DynamoDB provisioned capacity with 10 WCUs and no auto scaling."},"unix_timestamp":1662174480,"isMC":true,"exam_id":22,"answer_description":"","topic":"1","answer":"C","timestamp":"2022-09-03 05:08:00","answer_images":[],"question_id":99,"question_images":[],"answers_community":["C (100%)"]},{"id":"HJqdFX8i8ae7sl0XSxB0","question_id":100,"question_text":"A company wants to build a new invoicing service for its cloud-native application on AWS. The company has a small development team and wants to focus on service feature development and minimize operations and maintenance as much as possible. The company expects the service to handle billions of requests and millions of new records every day. The service feature requirements, including data access patterns are well-defined. The service has an availability target of\n99.99% with a milliseconds latency requirement. The database for the service will be the system of record for invoicing data.\nWhich database solution meets these requirements at the LOWEST cost?","answer_description":"","answer_images":[],"isMC":true,"unix_timestamp":1662176220,"topic":"1","discussion":[{"comments":[{"poster":"Pranava_GCP","content":"switching to D. Amazon DynamoDB. \n\nfrom below user case DynamoDB as a data store for an online shop which includes invoicing data.\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/data-modeling-online-shop.html","comment_id":"1027639","timestamp":"1696718460.0","upvote_count":"1"}],"content":"Selected Answer: B\nB. Amazon Aurora PostgreSQL Serverless\n\n-- SLA 99.99% for Aurora, https://aws.amazon.com/rds/aurora/sla/ \n while RDS with only 99.95%, https://aws.amazon.com/rds/sla/\n\n-- invoicing data, this has to be relational database with SQL query capability. DynamoDB being key-value NoSQL service does not fit for this.\n\n-- minimize operations and maintenance as much as possible, Serverless could be a good fit.\n\n-- cost, RDS is cheaper than Aurora, however RDS with SLA 99.95% without meeting the availability requirement.\n\nTherefore B. Amazon Aurora PostgreSQL Serverless","timestamp":"1693119480.0","comment_id":"991266","poster":"Pranava_GCP","upvote_count":"1"},{"comments":[{"upvote_count":"1","content":"The SLA of Aurora is 99.99%\nhttps://aws.amazon.com/rds/aurora/sla/","poster":"JasonZhu","timestamp":"1696171560.0","comment_id":"1022368"}],"content":"Selected Answer: D\nBecause the SLA is 99.99","timestamp":"1691218860.0","comment_id":"972763","upvote_count":"2","poster":"hogs"},{"timestamp":"1682293320.0","upvote_count":"3","content":"Selected Answer: B\nAs Invoicing will mostly use relational data and not NOSQL, so I wont go with Dynamodb. \nAurora serverless is less costly and provides millisecond latency, availability of 99.99%. Capacity to process billions of records.","comment_id":"878866","poster":"SeemaDataReader"},{"upvote_count":"2","timestamp":"1679791920.0","comment_id":"850591","content":"Selected Answer: D\nClearly DynamoDB because of millisecond latency and 99.99 availability SLA. RDS maximum SLA is between 99 to 99.5 only whereas DynamoDB could go between 99.99 to 99.999\nhttps://aws.amazon.com/about-aws/whats-new/2018/06/amazon-dynamodb-announces-a-monthly-service-level-agreement/\n\nhttps://aws.amazon.com/rds/sla/","poster":"backbencher2022"},{"poster":"teo2157","upvote_count":"1","content":"Selected Answer: C\nIt's asking for lower cost, billions of requests and millions of new records every day has a huge cost in DynamoDB. I'll go for C, PostgreSQL on RDS","timestamp":"1676296380.0","comment_id":"807457"},{"upvote_count":"1","content":"Selected Answer: D\nKnown patterns, minimum maintenance, miliseconds latency","comment_id":"679026","timestamp":"1664125980.0","poster":"cloudsunriser"},{"comment_id":"665922","content":"invoice system requires ACID ?","poster":"VMHarry","timestamp":"1662882240.0","upvote_count":"3"},{"upvote_count":"2","content":"Selected Answer: D\nD is correct","comment_id":"658333","timestamp":"1662200580.0","poster":"SonamDhingra"},{"poster":"mbar94","timestamp":"1662176220.0","upvote_count":"4","comment_id":"658031","content":"Selected Answer: D\nKnown patterns, minimum maintenance, miliseconds latency - vote for DynamoDB."}],"timestamp":"2022-09-03 05:37:00","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/79668-exam-aws-certified-database-specialty-topic-1-question-189/","choices":{"A":"Amazon Neptune","D":"Amazon DynamoDB","B":"Amazon Aurora PostgreSQL Serverless","C":"Amazon RDS for PostgreSQL"},"exam_id":22,"answers_community":["D (69%)","B (25%)","6%"],"answer":"D","question_images":[]}],"exam":{"isMCOnly":false,"lastUpdated":"11 Apr 2025","isBeta":false,"numberOfQuestions":359,"name":"AWS Certified Database - Specialty","id":22,"isImplemented":true,"provider":"Amazon"},"currentPage":20},"__N_SSP":true}