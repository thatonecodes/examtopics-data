{"pageProps":{"questions":[{"id":"jcHBVmk55gzgazN3nfG7","answer_ET":"B","question_text":"A company has an application that runs across multiple AWS Regions. The application is experiencing performance issues at irregular intervals. A developer must use AWS X-Ray to implement distributed tracing for the application to troubleshoot the root cause of the performance issues.\n\nWhat should the developer do to meet this requirement?","discussion":[{"content":"Selected Answer: B\nB is the correct answer.","timestamp":"1732458480.0","poster":"65703c1","comment_id":"1217439","upvote_count":"1"},{"timestamp":"1725716820.0","poster":"Abdullah22","upvote_count":"3","comment_id":"1168142","content":"Selected Answer: B\nUser-defined services:\nDeveloped by users: These services are applications, microservices, or any software components specifically built and deployed by the user or organization using AWS. They can be written in any programming language and deployed on various platforms, including EC2 instances, Lambda functions, or containers on platforms like Amazon ECS or EKS."},{"comment_id":"1164830","poster":"KarBiswa","upvote_count":"2","timestamp":"1725365400.0","content":"Selected Answer: B\nhttps://aws.amazon.com/xray/faqs/#:~:text=Region%20annotation%20for%20AWS%20services%20will%20be%20added%20automatically%2C%20however%2C%20customers%20will%20need%20to%20instrument%20custom%20services%20to%20add%20the%20regional%20annotation%20to%20make%20use%20of%20the%20cross%2Dregion%20support."},{"content":"Selected Answer: B\nUser defined has to be in sdk.","comment_id":"1155289","upvote_count":"4","poster":"CrescentShared","timestamp":"1724213040.0"}],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/134288-exam-aws-certified-developer-associate-dva-c02-topic-1/","exam_id":24,"topic":"1","answers_community":["B (100%)"],"answer":"B","isMC":true,"choices":{"D":"Use Region annotation that X-Ray adds automatically for user-defined services. Configure X-Ray to add Region annotation for AWS services.","A":"Use the X-Ray console to add annotations for AWS services and user-defined services.","C":"Use the X-Ray daemon to add annotations for AWS services and user-defined services.","B":"Use Region annotation that X-Ray adds automatically for AWS services. Add Region annotation for user-defined services."},"answer_images":[],"timestamp":"2024-02-21 07:04:00","question_id":211,"question_images":[],"unix_timestamp":1708495440},{"id":"rrEVmHMslQUB7KTO0XDq","discussion":[{"poster":"eboehm2","content":"Selected Answer: AC\n100% AC as per AWS : ProvisionedThroughputExceededException\nThe request rate for the stream is too high, or the requested data is too large for the available throughput. Reduce the frequency or size of your requests. For more information, see Streams Limits in the Amazon Kinesis Data Streams Developer Guide, and Error Retries and Exponential Backoff in AWS in the AWS General Reference.\n\nhttps://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecords.html","timestamp":"1686702960.0","comment_id":"922634","upvote_count":"8"},{"upvote_count":"2","poster":"sumanshu","comment_id":"1330353","content":"Selected Answer: AC\nA) Correct - Retries with exponential backoff help manage temporary spikes by delaying subsequent retry attempts progressively\n\nB) Eliminated - Switching to PutRecord would increase API calls, worsening the throughput issue\n\nC) Correct - Reducing request size or frequency directly addresses the throughput limits by spreading out the data more evenly.\n\nD) Eliminated - Amazon SNS is a messaging service, not designed for streaming data with high throughput like Kinesis.","timestamp":"1734865320.0","comments":[{"poster":"sumanshu","comment_id":"1330354","timestamp":"1734865380.0","upvote_count":"2","content":"E) Eliminated - KCL consumers consume data from Kinesis streams; reducing their number will not address the write throughput limits causing the ProvisionedThroughputExceededException"}]},{"content":"Selected Answer: AC\n==> Discard B: PutRecord doesn't reduce throughput issues as it sends one record at a time, increasing API calls.\n==> Discard D: SNS isn't designed for streaming data; it handles pub/sub messaging.\n==> Discard E: Reducing KCL consumers affects reading, not writing throughput.\n\n- A: Exponential backoff reduces retries during peak usage, easing shard throughput pressure. \n- C: Lowering request frequency or size directly mitigates throughput exceedance on shards.","upvote_count":"1","timestamp":"1734144720.0","poster":"trieudo","comment_id":"1326329"},{"comment_id":"1307172","timestamp":"1730772540.0","upvote_count":"2","content":"Answer is A and C\nBatch Efficiency: The `PutRecords` API allows you to send multiple records in a single request, which is generally more efficient than sending individual records with `PutRecord`. Using `PutRecords` can help optimize throughput by reducing the number of API calls and better utilizing the available capacity.","poster":"Venky786"},{"content":"Selected Answer: AC\nAC is the correct answer.","timestamp":"1716303600.0","poster":"65703c1","comment_id":"1215046","upvote_count":"1"},{"poster":"Baba_Eni","comment_id":"914255","content":"Selected Answer: AC\nAC is the best answer. When there is throttling, it is best practise to implement retries with exponential backoff.","timestamp":"1685867880.0","upvote_count":"1"},{"poster":"ezredame","upvote_count":"3","comments":[{"comment_id":"922633","content":"I thought this at first too, but I was doing some additional reading and using the PutRecord API over PutRecords is wrong as it could actually make the problem worse as producers may make too many rapid requests to write to the stream\nhttps://repost.aws/knowledge-center/kinesis-data-stream-throttling","upvote_count":"4","poster":"eboehm2","timestamp":"1686702720.0"},{"upvote_count":"1","content":"Can you please add a link where I can find this information. From what I can read on AWS is that you can implement exponential backoff but it is not by default.","timestamp":"1685517540.0","poster":"Majong","comment_id":"910959"}],"comment_id":"910157","timestamp":"1685443020.0","content":"Selected Answer: BC\nI think this is really tricky question. To get this exception, the request rate for the stream is too high, or the requested data is too large for the available throughput. Reduce the frequency or size of your requests. So we can \"Reduce the frequency and/or size of the requests\" also decrease the size with \"Use a PutRecord API instead of PutRecords\"\n\nThe API already implements retries with exponential backoff. So there is no need for A."},{"timestamp":"1679573880.0","upvote_count":"4","poster":"Untamables","comment_id":"848174","content":"Selected Answer: AC\nA and C\nhttps://aws.amazon.com/premiumsupport/knowledge-center/kinesis-data-stream-throttling-errors/"},{"comment_id":"841809","comments":[{"upvote_count":"1","timestamp":"1685766480.0","comment_id":"913258","poster":"yashika2005","content":"thanks a lotttt!"}],"upvote_count":"4","poster":"aragon_saa","content":"AC\nhttps://www.examtopics.com/discussions/amazon/view/69142-exam-aws-certified-developer-associate-topic-1-question-370/","timestamp":"1679043000.0"}],"unix_timestamp":1679043000,"answer_ET":"AC","answer_description":"","isMC":true,"topic":"1","question_text":"An application is processing clickstream data using Amazon Kinesis. The clickstream data feed into Kinesis experiences periodic spikes. The PutRecords API call occasionally fails and the logs show that the failed call returns the response shown below:\n//IMG//\n\nWhich techniques will help mitigate this exception? (Choose two.)","exam_id":24,"url":"https://www.examtopics.com/discussions/amazon/view/102903-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_id":212,"timestamp":"2023-03-17 09:50:00","answers_community":["AC (85%)","BC (15%)"],"question_images":["https://img.examtopics.com/aws-certified-developer-associate-dva-c02/image1.png"],"choices":{"C":"Reduce the frequency and/or size of the requests.","E":"Reduce the number of KCL consumers.","D":"Use Amazon SNS instead of Kinesis.","A":"Implement retries with exponential backoff.","B":"Use a PutRecord API instead of PutRecords."},"answer_images":[],"answer":"AC"},{"id":"6wAZiJFXtCnluq1SxmOb","timestamp":"2024-02-21 07:07:00","answers_community":["C (100%)"],"choices":{"C":"Set the event source mapping maximum concurrency to 10 for the high priority queue and to 90 for the low priority queue.","D":"Set the event source mapping batch window to 10 for the high priority queue and to 90 for the low priority queue.","B":"Set the delivery delay to 0 seconds for the high priority queue and to 10 seconds for the low priority queue.","A":"Set the event source mapping batch size to 10 for the high priority queue and to 90 for the low priority queue."},"isMC":true,"answer_description":"","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/134289-exam-aws-certified-developer-associate-dva-c02-topic-1/","exam_id":24,"discussion":[{"comment_id":"1313347","content":"Selected Answer: C\nResources:\n HighPriorityEventSourceMapping:\n Type: AWS::Lambda::EventSourceMapping\n Properties:\n BatchSize: 10\n MaximumConcurrency: 10\n EventSourceArn: arn:aws:sqs:region:account-id:high-priority-queue\n FunctionName: myLambdaFunction\n\n LowPriorityEventSourceMapping:\n Type: AWS::Lambda::EventSourceMapping\n Properties:\n BatchSize: 10\n MaximumConcurrency: 90\n EventSourceArn: arn:aws:sqs:region:account-id:low-priority-queue\n FunctionName: myLambdaFunction","upvote_count":"1","timestamp":"1731809760.0","poster":"albert_kuo"},{"upvote_count":"2","content":"Selected Answer: C\nYou can use the maximum concurrency setting to control scaling behavior for your SQS event sources. The maximum concurrency setting limits the number of concurrent instances of the function that an Amazon SQS event source can invoke. Maximum concurrency is an event source-level setting. If you have multiple Amazon SQS event sources mapped to one function, each event source can have a separate maximum concurrency setting. You can use maximum concurrency to prevent one queue from using all of the function's reserved concurrency or the rest of the account's concurrency quota. There is no charge for configuring maximum concurrency on an Amazon SQS event source.","poster":"preachr","timestamp":"1727367480.0","comment_id":"1289594"},{"timestamp":"1716553800.0","content":"Selected Answer: C\nC is the correct answer.","comment_id":"1217440","poster":"65703c1","upvote_count":"1"},{"comment_id":"1164839","poster":"KarBiswa","upvote_count":"2","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-max-concurrency","timestamp":"1709475720.0"},{"content":"Selected Answer: C\nShould be C","poster":"monishvster","comment_id":"1162059","timestamp":"1709164560.0","upvote_count":"2"},{"comment_id":"1155291","content":"Selected Answer: C\nNone of them seems to be guarantee the requirement. \nSet the reserved concurrency on the Lambda function to 100 to limit the total invocations across all triggers.\nConfigure the event source mapping for the high priority queue to use a maximum concurrency that ensures its messages are processed first. This could be most of the reserved concurrency (but not all, to allow for some processing of the low priority queue).\nConfigure the event source mapping for the low priority queue with a smaller maximum concurrency to ensure it doesn't starve the high priority queue of Lambda resources.","timestamp":"1708495620.0","poster":"CrescentShared","upvote_count":"2"}],"question_id":213,"unix_timestamp":1708495620,"question_images":[],"answer_ET":"C","answer":"C","question_text":"A company runs an application on AWS. The application uses an AWS Lambda function that is configured with an Amazon Simple Queue Service (Amazon SQS) queue called high priority queue as the event source. A developer is updating the Lambda function with another SQS queue called low priority queue as the event source. The Lambda function must always read up to 10 simultaneous messages from the high priority queue before processing messages from low priority queue. The Lambda function must be limited to 100 simultaneous invocations.\n\nWhich solution will meet these requirements?","answer_images":[]},{"id":"Sl3DDugFNYtWodrXpwOG","exam_id":24,"unix_timestamp":1708495740,"answer_ET":"D","answer":"D","question_id":214,"answer_description":"","question_images":[],"answers_community":["D (100%)"],"discussion":[{"poster":"65703c1","comment_id":"1217445","content":"Selected Answer: D\nD is the correct answer.","timestamp":"1732459140.0","upvote_count":"2"},{"comment_id":"1202533","content":"A comprehensive guide to help you navigate the landscape and find the perfect <a href=\"https://keensolution.in/data-visualization-services/\">data visualization agencies in India</a> for your business","timestamp":"1729938120.0","upvote_count":"1","poster":"keensolution"},{"upvote_count":"3","timestamp":"1725717180.0","comment_id":"1168150","content":"Selected Answer: D\nD. Configure AWS Secrets Manager to create a new secret for each environment type. Store the environment-specific credentials in the secret.\n\nAWS Secrets Manager supports the encryption of secrets (including sensitive credentials) and allows for automatic rotation of these secrets. By creating a new secret for each environment (development, staging, pre-production, and production), you can manage and access the environment-specific credentials securely. This approach facilitates operational efficiency by leveraging AWS Secrets Manager's built-in capabilities for encryption and rotation, without the need for manual intervention or complex configurations. Secrets Manager also provides a straightforward way to retrieve the correct version of the credentials for each specific environment, simplifying the management of sensitive data across different stages of application deployment.","poster":"SerialiDr"},{"upvote_count":"1","comment_id":"1164843","poster":"KarBiswa","content":"Selected Answer: D\nDifferent credentials","timestamp":"1725366420.0"},{"poster":"monishvster","upvote_count":"1","comment_id":"1162062","content":"Selected Answer: D\nShould be D","timestamp":"1724882400.0"},{"comment_id":"1155292","poster":"CrescentShared","content":"Selected Answer: D\nC does not make sense.","upvote_count":"2","timestamp":"1724213340.0"}],"question_text":"A data visualization company wants to strengthen the security of its core applications. The applications are deployed on AWS across its development, staging, pre-production, and production environments. The company needs to encrypt all of its stored sensitive credentials. The sensitive credentials need to be automatically rotated. A version of the sensitive credentials need to be stored for each environment.\n\nWhich solution will meet these requirements in the MOST operationally efficient way?","choices":{"C":"Configure the environment variables in the application code. Use different names for each environment type.","D":"Configure AWS Secrets Manager to create a new secret for each environment type. Store the environment-specific credentials in the secret.","A":"Configure AWS Secrets Manager versions to store different copies of the same credentials across multiple environments.","B":"Create a new parameter version in AWS Systems Manager Parameter Store for each environment. Store the environment-specific credentials in the parameter version."},"isMC":true,"timestamp":"2024-02-21 07:09:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/134290-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer_images":[]},{"id":"3MzZrXyffyiWxIFx5z0b","answers_community":["AD (100%)"],"question_text":"A developer is investigating an issue in part of a company's application. In the application, messages are sent to an Amazon Simple Queue Service (Amazon SQS) queue. The AWS Lambda function polls messages from the SQS queue and sends email messages by using Amazon Simple Email Service (Amazon SES). Users have been receiving duplicate email messages during periods of high traffic.\n\nWhich reasons could explain the duplicate email messages? (Choose two.)","url":"https://www.examtopics.com/discussions/amazon/view/134291-exam-aws-certified-developer-associate-dva-c02-topic-1/","topic":"1","answer_images":[],"discussion":[{"poster":"CrescentShared","upvote_count":"6","timestamp":"1708495800.0","content":"Selected Answer: AD\nAD is correct.","comment_id":"1155293"},{"timestamp":"1719399000.0","poster":"Alabi","upvote_count":"1","content":"Selected Answer: AD\nAD for sure","comment_id":"1237402"},{"timestamp":"1716554580.0","content":"Selected Answer: AD\nAD is the correct answer.","upvote_count":"1","comment_id":"1217450","poster":"65703c1"},{"upvote_count":"3","poster":"KarBiswa","content":"Selected Answer: AD\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html","timestamp":"1709476560.0","comment_id":"1164849"}],"choices":{"A":"Standard SQS queues support at-least-once message delivery.","B":"Standard SQS queues support exactly-once processing, so the duplicate email messages are because of user error.","C":"Amazon SES has the DomainKeys Identified Mail (DKIM) authentication incorrectly configured.","D":"The SQS queue's visibility timeout is lower than or the same as the Lambda function's timeout.","E":"The Amazon SES bounce rate metric is too high."},"answer_description":"","question_images":[],"question_id":215,"timestamp":"2024-02-21 07:10:00","isMC":true,"exam_id":24,"answer":"AD","unix_timestamp":1708495800,"answer_ET":"AD"}],"exam":{"isBeta":false,"id":24,"numberOfQuestions":551,"provider":"Amazon","name":"AWS Certified Developer - Associate DVA-C02","isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":true},"currentPage":43},"__N_SSP":true}