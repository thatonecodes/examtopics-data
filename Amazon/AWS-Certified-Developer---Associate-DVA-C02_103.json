{"pageProps":{"questions":[{"id":"DJ2HLLE3Dxcug3Css27n","timestamp":"2023-03-27 02:20:00","answer_ET":"C","topic":"1","unix_timestamp":1679876400,"answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/104016-exam-aws-certified-developer-associate-dva-c02-topic-1/","answers_community":["C (95%)","5%"],"question_id":511,"choices":{"D":"Change the deployment policy to rolling. Specify a batch size of 2.","A":"Change the Auto Scaling group to six desired instances.","B":"Change the deployment policy to traffic splitting. Specify an evaluation time of 1 hour.","C":"Change the deployment policy to rolling with additional batch. Specify a batch size of 1."},"question_text":"A company has deployed an application on AWS Elastic Beanstalk. The company has configured the Auto Scaling group that is associated with the Elastic Beanstalk environment to have five Amazon EC2 instances. If the capacity is fewer than four EC2 instances during the deployment, application performance degrades. The company is using the all-at-once deployment policy.\nWhat is the MOST cost-effective way to solve the deployment issue?","answer":"C","isMC":true,"question_images":[],"exam_id":24,"discussion":[{"poster":"gpt_test","content":"Selected Answer: C\nExplanation: The rolling with additional batch deployment policy allows Elastic Beanstalk to launch additional instances in a new batch before terminating the old instances. In this case, specifying a batch size of 1 means that Elastic Beanstalk will deploy the application updates to 1 new instance at a time, ensuring that there are always at least 4 instances available during the deployment process. This method maintains application performance while minimizing the additional cost.","timestamp":"1696376580.0","upvote_count":"19","comment_id":"860462"},{"timestamp":"1702984260.0","comment_id":"927329","content":"Selected Answer: C\n1. Rolling with additional batch deployment: This type of deployment maintains full capacity while new application versions are deployed. It launches a new batch of instances with the new application version, and if the new batch is healthy, it terminates a batch of instances running the old application version.\n\n2. Batch size of 1: This will ensure that one new instance is launched with the new version of the application. Once it is deemed healthy, one of the old instances will be terminated. This will continue until all instances are running the new version, ensuring the capacity is never less than four instances. This approach will add only a minimal additional cost for the temporary overlapping instances during deployment.","poster":"gagol14","upvote_count":"13"},{"timestamp":"1735035000.0","poster":"sumanshu","upvote_count":"2","comments":[{"timestamp":"1735035120.0","content":"C) Batch Size of 1: Specifies that only one instance will be updated at a time, minimizing downtime and maintaining the required instance capacity for performance.\n\nRolling with additional Batch - This deployment strategy adds an extra batch of EC2 instances during deployment. After updating one batch, the additional instances are terminated, ensuring cost efficiency.","poster":"sumanshu","upvote_count":"1","comment_id":"1331078"}],"comment_id":"1331077","content":"Selected Answer: C\nA) Eliminated - Permanently increasing the desired capacity to six EC2 instances incurs unnecessary ongoing costs.\n\nB) Eliminated - Traffic splitting is primarily used for canary testing or gradual traffic shifting. It does not guarantee maintaining the desired instance capacity during deployment.\n\nD) Eliminated - A rolling deployment with a batch size of 2 means two instances are replaced at a time. With a fixed capacity of 5 instances, this would temporarily reduce the number of running instances to 3, causing performance degradation."},{"upvote_count":"1","content":"Selected Answer: C\nC is the correct answer.","comment_id":"1215316","timestamp":"1732244400.0","poster":"65703c1"},{"comment_id":"1104688","poster":"Alearn","timestamp":"1719235620.0","content":"Selected Answer: D\nOption D is the best solution because it allows the company to update the application without losing service or reducing availability significantly, and without increasing the cost or complexity of the solution.","upvote_count":"2","comments":[{"comments":[{"comment_id":"1350595","poster":"sumanshu","upvote_count":"1","comments":[{"comment_id":"1366341","content":"Even if it mentions rolling with additional batches, D would still not be the correct answer. The question asks what is the MOST COST EFFECTIVE way, rolling with additional batch of 2 means the instance count goes to 6 at some moments as opose to the 5 in option C, which makes it still more cost effective","upvote_count":"1","poster":"Shamalka","timestamp":"1741368900.0"}],"content":"@Alern - option D mentioned: Option D only mentions \"Rolling\" and not \"Rolling with Additional Batch...\n\nIf it;s mentioned Rolling with Additional Batch - Then \"D\" is the answer and fastest...","timestamp":"1738519560.0"}],"timestamp":"1729148700.0","upvote_count":"1","poster":"poklakni","content":"the requirement is not to go below 4 instances. Option D specifies a batch size of 2 which would lead to 3 running instances. The correct option is C","comment_id":"1197052"}]},{"timestamp":"1718622600.0","poster":"KarBiswa","comment_id":"1098929","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","upvote_count":"2"},{"content":"Selected Answer: C\nThe correct answer is: C","upvote_count":"1","timestamp":"1706519220.0","comment_id":"966192","poster":"quangphungdev218"},{"content":"The correct answer is: D. Change the deployment policy to rolling. Specify a batch size of 2.\n\nA rolling deployment policy will deploy the new application version to one batch of instances at a time, while the other batches continue to serve traffic. This ensures that the application always has at least four instances available during the deployment.\n\nSpecifying a batch size of 2 means that two instances will be deployed at a time. This is the most cost-effective option because it minimizes the number of instances that are needed to maintain application performance during the deployment.\n\nThe other options are not as cost-effective because they require more instances to be running during the deployment. Option A requires six instances, option B requires at least five instances, and option C requires at least four instances.","poster":"Prem28","comment_id":"917501","timestamp":"1701979980.0","comments":[{"comment_id":"1023091","timestamp":"1712061540.0","upvote_count":"2","content":"If batch size of 1:\nDuring the time the new instances are being deployed and are not yet in service, there are only 5 - 2 = 3 old instances available to serve the traffic, which violates the requirement to maintain at least 4 instances to avoid performance degradation.\nso, i go with A answer.","poster":"nmc12"},{"poster":"jipark","content":"C: cost 1 additional EC2\nD : degrade performance\nit looks exam gave key \"2 batch\" meaning - do not choose this answer.","timestamp":"1706708700.0","comment_id":"968036","upvote_count":"1"}],"upvote_count":"2"},{"timestamp":"1695774000.0","upvote_count":"4","comment_id":"851586","poster":"Untamables","content":"Selected Answer: C\nC\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html"}]},{"id":"lNPONBg1qTtspIbutCZw","answers_community":["A (81%)","Other"],"question_text":"A developer is incorporating AWS X-Ray into an application that handles personal identifiable information (PII). The application is hosted on Amazon EC2 instances. The application trace messages include encrypted PII and go to Amazon CloudWatch. The developer needs to ensure that no PII goes outside of the EC2 instances.\nWhich solution will meet these requirements?","answer_ET":"A","answer_images":[],"exam_id":24,"url":"https://www.examtopics.com/discussions/amazon/view/103955-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_description":"","choices":{"A":"Manually instrument the X-Ray SDK in the application code.","B":"Use the X-Ray auto-instrumentation agent.","D":"Use AWS Distro for Open Telemetry.","C":"Use Amazon Macie to detect and hide PII. Call the X-Ray API from AWS Lambda."},"unix_timestamp":1679833500,"question_id":512,"isMC":true,"timestamp":"2023-03-26 14:25:00","answer":"A","discussion":[{"timestamp":"1696376460.0","upvote_count":"25","poster":"gpt_test","comment_id":"860460","content":"Selected Answer: A\nExplanation: By manually instrumenting the X-Ray SDK in the application code, the developer can have full control over which data is included in the trace messages. This way, the developer can ensure that no PII is sent to X-Ray by carefully handling the PII within the application and not including it in the trace messages."},{"comment_id":"851623","content":"Selected Answer: A\nA\nNot to send any PII to AWS X-Ray service, add instrumentation code in your application at each location to send trace information that PII is eliminated.\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-instrumenting-your-app.html","timestamp":"1695780000.0","poster":"Untamables","upvote_count":"7"},{"content":"Selected Answer: D\nCurrently, with the all-at-once deployment policy, Elastic Beanstalk updates all EC2 instances simultaneously. This can cause issues with application performance, as the entire fleet of instances is replaced at once, leading to potential downtime or degraded performance if the number of available instances falls below the necessary threshold (fewer than four EC2 instances in your case).\n\nSwitching to a rolling deployment with a batch size of 2 will allow Elastic Beanstalk to update the instances in smaller batches. During each batch update, only two instances will be updated at a time, which means that there will always be a sufficient number of EC2 instances running (at least three instances at all times). This avoids the performance degradation caused by having fewer than four EC2 instances available.","poster":"Niluka","comment_id":"1334474","upvote_count":"1","timestamp":"1735600800.0"},{"comment_id":"1331080","upvote_count":"1","timestamp":"1735035300.0","poster":"sumanshu","content":"Selected Answer: A\nC) Eliminated - Amazon Macie is designed for identifying and securing sensitive data stored in AWS services like S3\n\nA) A (manual instrumentation) is the best solution because it gives the developer full control over what data is sent to X-Ray, ensuring that no PII leaves the EC2 instances.\n\nB) Eliminated - Auto-instrumentation automatically captures data without offering granular control over what is sent to X-Ray. This approach could inadvertently send sensitive PII data to X-Ray, violating the requirements."},{"poster":"65703c1","upvote_count":"1","comment_id":"1215326","timestamp":"1732245960.0","content":"Selected Answer: A\nA is the correct answer."},{"timestamp":"1725467760.0","upvote_count":"2","comment_id":"1165891","content":"Selected Answer: A\nX-Ray auto-instrumentation agent itself does not inherently remove or redact Personally Identifiable Information (PII). The primary purpose of the auto-instrumentation agent is to automate the process of instrumenting supported frameworks and libraries for tracing with AWS X-Ray.\n\nWhen dealing with PII or any sensitive information, the responsibility for ensuring that such data is not exposed in traces lies with the application code and configuration, rather than the X-Ray auto-instrumentation agent.\n\nWhile the X-Ray auto-instrumentation agent simplifies the instrumentation process, the need for precise control over PII and the ability to implement custom security measures make manual instrumentation more suitable in this scenario.","poster":"TheFivePips"},{"comment_id":"1159453","upvote_count":"1","content":"Selected Answer: A\nA.To ensure that no personally identifiable information (PII) goes outside of the EC2 instances while incorporating AWS X-Ray into an application that handles PII, the developer should manually instrument the X-Ray SDK in the application code. This approach allows for precise control over what data is captured and sent to X-Ray, enabling the developer to exclude or anonymize PII before it leaves the application environment, thereby meeting the requirement to ensure that no PII goes outside of the EC2 instances.","timestamp":"1724648820.0","poster":"SerialiDr"},{"comment_id":"1118984","content":"Selected Answer: A\nThis approach allows for granular control over what data is captured and sent to AWS X-Ray. The developer can instrument the code to ensure that PII is either not included in the trace data or is properly encrypted before being sent. This method provides the necessary control to meet the requirement.","poster":"SerialiDr","timestamp":"1720632780.0","upvote_count":"1"},{"content":"Selected Answer: B\nThe X-Ray auto-instrumentation agent can help ensure that sensitive information like PII is not transmitted outside of the EC2 instances. It automatically instruments the application without requiring manual intervention, making it easier to maintain traceability without risking the exposure of sensitive data.\n\nOptions A and D involve manual or custom instrumentations, which might inadvertently expose PII if not implemented correctly. Option C, using Amazon Macie to detect and hide PII and calling the X-Ray API from Lambda, might add complexity to the architecture and doesn't directly address the prevention of PII leaving the EC2 instances.","poster":"a_win","timestamp":"1719283800.0","comment_id":"1105017","upvote_count":"2"},{"upvote_count":"5","content":"Selected Answer: B\nOption B, using the X-Ray auto-instrumentation agent, is the most appropriate solution for ensuring that no PII goes outside of the EC2 instances.","comments":[{"timestamp":"1717928280.0","comment_id":"1091791","content":"A. Manually instrumenting the X-Ray SDK in the application code might lead to the possibility of inadvertently including PII in trace messages, and it may not be as foolproof as the auto-instrumentation agent.\n\nB. The X-Ray auto-instrumentation agent automatically instruments the supported runtime environments, making it less error-prone and ensuring that sensitive information like PII is not leaked.","upvote_count":"1","comments":[{"content":"C. Amazon Macie is a service designed for discovering, classifying, and protecting sensitive data, but using it to detect and hide PII in combination with X-Ray is not a standard approach. It's more focused on data discovery and classification.\n\nD. AWS Distro for OpenTelemetry is an observability project but may not provide the same level of automation for ensuring that no PII goes outside of the EC2 instances as the X-Ray auto-instrumentation agent.","timestamp":"1717928280.0","poster":"chewasa","upvote_count":"1","comment_id":"1091792"}],"poster":"chewasa"}],"comment_id":"1091790","poster":"chewasa","timestamp":"1717928220.0"},{"upvote_count":"2","poster":"love777","content":"Selected Answer: B\nThe X-Ray auto-instrumentation agent is designed to automatically trace and collect data from AWS resources and services without requiring manual instrumentation in your application code.\nIt helps ensure that sensitive information, such as PII, remains within the EC2 instances by not transmitting the data outside explicitly. The agent focuses on tracing the application behavior and performance without directly sending PII to external services.\nThis solution is suitable for ensuring compliance and data security while still benefiting from X-Ray's tracing and insights.","timestamp":"1709130780.0","comment_id":"992163"},{"poster":"r3mo","timestamp":"1706587380.0","comment_id":"966787","upvote_count":"2","content":"Option \"B\" : Because. Avoids human error."},{"content":"Using the X-Ray auto-instrumentation agent (Option B) is the best choice in this scenario because it will automatically instrument the application without requiring any manual code changes. Additionally, when using X-Ray with auto-instrumentation, you can control the sampling rate to ensure that only a subset of trace data (and encrypted PII) is sent to X-Ray and CloudWatch, reducing the risk of sensitive data being exposed outside of the instances.","upvote_count":"2","timestamp":"1706405580.0","poster":"Umman","comment_id":"965159"},{"upvote_count":"2","timestamp":"1706187720.0","comment_id":"962607","poster":"jasper_pigeon","content":"For non-Java applications running on EC2 instances, you will need to use the appropriate X-Ray SDKs to manually instrument the application code. You can't use auto-agent"},{"upvote_count":"1","poster":"kris_jec","content":"Its very clear from Macie definition that it also provides automated protection as well apart from findings the PII data","comment_id":"960074","timestamp":"1705992900.0"},{"upvote_count":"1","comment_id":"952604","content":"Selected Answer: A\nI think B is incorrect as the auto instrument cannot hide it, right?","poster":"tttamtttam","timestamp":"1705351260.0"},{"timestamp":"1698325800.0","upvote_count":"3","poster":"dan80","content":"Selected Answer: A\nC is wrong, Amazon Macie discover PII but dont hide it","comment_id":"881642"},{"upvote_count":"1","poster":"macross","comment_id":"851528","content":"c https://docs.aws.amazon.com/macie/latest/user/data-classification.html","timestamp":"1695765540.0"},{"timestamp":"1695731100.0","comments":[{"upvote_count":"2","comment_id":"968097","comments":[{"upvote_count":"3","content":"It is my understanding that Macie only supports S3","poster":"ninomfr64","comment_id":"985176","timestamp":"1708352100.0"}],"timestamp":"1706711160.0","content":"exactly sayed there.","poster":"jipark"}],"comment_id":"850987","content":"C : Amazon Macie is a data security service that discovers sensitive data using machine learning and pattern matching, provides visibility into data security risks, and enables you to automate protection against those risks.\nhttps://aws.amazon.com/macie/features/?nc1=h_ls","poster":"StarLoard","upvote_count":"3"}],"topic":"1"},{"id":"XXNkIxswzRuMxLoZerW8","answer_images":[],"answers_community":["D (92%)","8%"],"answer":"D","unix_timestamp":1679593080,"question_id":513,"choices":{"D":"Configure the VPC, subnets, and a security group for the Lambda functions.","C":"Configure a NAT gateway and a security group for the Lambda functions.","A":"Configure the DB cluster's public access setting to Yes.","B":"Configure an Amazon RDS database proxy for he Lambda functions."},"url":"https://www.examtopics.com/discussions/amazon/view/103687-exam-aws-certified-developer-associate-dva-c02-topic-1/","discussion":[{"comment_id":"978153","content":"Option D is the right answer. When we want the lambda to privately access the DB cluster instead of moving the traffic over the public internet, we need to have the lambda and db cluster to be in the same VPC.\n\nWhen we configure the VPC, subnets, and a security group for the lambda function, the lambda function will be able to communicate with the db cluster using the private IPs that are associated to the VPC.\n\nNAT gateway comes into use when you have the lambda deployed in a private subnet and you would want to provide internet access to it.","timestamp":"1691713440.0","upvote_count":"17","poster":"jayvarma"},{"poster":"gpt_test","upvote_count":"8","comment_id":"860457","timestamp":"1680565140.0","content":"Selected Answer: D\nExplanation: To securely access the Amazon Aurora DB cluster without crossing the public internet, the Lambda functions need to be configured to run within the same VPC as the DB cluster. This involves configuring the VPC, subnets, and a security group for the Lambda functions. This setup ensures that the Lambda functions can communicate with the DB cluster using private IP addresses within the VPC."},{"content":"Selected Answer: D\nLambda functions can be configured to run within a VPC. By assigning the Lambda functions to the same VPC and private subnets as the Aurora DB cluster, the communication remains internal to the VPC and does not cross the public internet. Configuring the security group ensures that the Lambda functions can securely connect to the Aurora DB cluster by allowing appropriate inbound/outbound rules.","upvote_count":"1","poster":"sumanshu","comment_id":"1331122","timestamp":"1735045980.0"},{"poster":"AmitRanchi","timestamp":"1728378420.0","comment_id":"1294656","content":"Selected Answer: D\nAns is D.","upvote_count":"1"},{"content":"Selected Answer: D\nD is the correct answer.","timestamp":"1716341280.0","comment_id":"1215327","poster":"65703c1","upvote_count":"1"},{"content":"B\nhttps://repost.aws/questions/QULXSqEPGbQx6qiyBa1D1Udg/lambda-to-db-connectivity-best-practices","poster":"Wendy1113","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"1184288","timestamp":"1711564080.0","poster":"maurice2005","content":"Actually Proxy should be on the same VPC as the database and since lambda is in another vpc it doesnt have access unless a connection happens between these two vpc or just option D"}],"timestamp":"1700112960.0","comment_id":"1072163"},{"content":"Selected Answer: B\nhttps://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/36527788#overview\n\nhttps://aws.amazon.com/ru/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/","comment_id":"1023694","upvote_count":"1","poster":"alex_heavy","timestamp":"1696316040.0"},{"comment_id":"942407","poster":"eberhe900","comments":[{"comment_id":"1255334","upvote_count":"1","content":"After reading doc in the link that you mention, my conclusion is D\nNAT GW is required if Lamba in the user VPC need to access internet","poster":"ejlp","timestamp":"1721959800.0"}],"timestamp":"1688448180.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html","upvote_count":"2"},{"poster":"Untamables","comment_id":"851630","upvote_count":"5","timestamp":"1679883540.0","content":"Selected Answer: D\nD\nhttps://docs.aws.amazon.com/lambda/latest/dg/foundation-networking.html"},{"upvote_count":"6","poster":"Dun6","content":"Selected Answer: D\nD is correct, NATGateway is for when we want Lambda to access the public when it is in a private VPC","timestamp":"1679593080.0","comment_id":"848515"}],"question_images":[],"answer_description":"","exam_id":24,"question_text":"A developer is migrating some features from a legacy monolithic application to use AWS Lambda functions instead. The application currently stores data in an Amazon Aurora DB cluster that runs in private subnets in a VPC. The AWS account has one VPC deployed. The Lambda functions and the DB cluster are deployed in the same AWS Region in the same AWS account.\nThe developer needs to ensure that the Lambda functions can securely access the DB cluster without crossing the public internet.\nWhich solution will meet these requirements?","isMC":true,"timestamp":"2023-03-23 18:38:00","topic":"1","answer_ET":"D"},{"id":"NW7d8cI9RJKkIqy8ysjK","answer_ET":"A","answer_description":"","isMC":true,"timestamp":"2023-03-23 18:36:00","answers_community":["A (100%)"],"unix_timestamp":1679592960,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/103686-exam-aws-certified-developer-associate-dva-c02-topic-1/","exam_id":24,"question_text":"A developer is building a new application on AWS. The application uses an AWS Lambda function that retrieves information from an Amazon DynamoDB table. The developer hard coded the DynamoDB table name into the Lambda function code. The table name might change over time. The developer does not want to modify the Lambda code if the table name changes.\nWhich solution will meet these requirements MOST efficiently?","answer":"A","question_id":514,"discussion":[{"comment_id":"848509","upvote_count":"9","poster":"Dun6","timestamp":"1695483360.0","content":"Selected Answer: A\nYou need to use environment variables"},{"timestamp":"1695781380.0","upvote_count":"7","poster":"Untamables","content":"Selected Answer: A\nA\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html","comment_id":"851632"},{"upvote_count":"1","timestamp":"1735046520.0","comment_id":"1331124","content":"Selected Answer: A\nEnvironment variables are a built-in feature of AWS Lambda","poster":"sumanshu"},{"comment_id":"1215328","content":"Selected Answer: A\nA is the correct answer.","timestamp":"1732246140.0","upvote_count":"1","poster":"65703c1"},{"content":"Selected Answer: A\nWhy are some answers wrong on here?","upvote_count":"1","poster":"mma34","timestamp":"1716305460.0","comment_id":"1076495"},{"upvote_count":"2","poster":"eberhe900","comment_id":"942409","timestamp":"1704353220.0","content":"Selected Answer: A\nYou can use environment variables to adjust your function's behavior without updating code. An environment variable is a pair of strings that is stored in a function's version-specific configuration. The Lambda runtime makes environment variables available to your code and sets additional environment variables that contain information about the function and invocation request."},{"poster":"gpt_test","content":"Selected Answer: A\nExplanation: Using Lambda environment variables allows you to store configuration information separate from your code, which makes it easy to update the table name without changing the Lambda function code. AWS Lambda provides built-in support for environment variables, making it the most efficient solution.","comment_id":"860455","timestamp":"1696376280.0","upvote_count":"5"}],"choices":{"A":"Create a Lambda environment variable to store the table name. Use the standard method for the programming language to retrieve the variable.","C":"Create a file to store the table name. Zip the file and upload the file to the Lambda layer. Use the SDK for the programming language to retrieve the table name.","D":"Create a global variable that is outside the handler in the Lambda function to store the table name.","B":"Store the table name in a file. Store the file in the /tmp folder. Use the SDK for the programming language to retrieve the table name."},"answer_images":[],"topic":"1"},{"id":"VfH1Eiwb1Z5ZJ5HZ4Bdj","answer":"B","choices":{"B":"Use Amazon RDS Proxy to create a proxy that connects to the DB instance. Update the Lambda function to connect to the proxy.","A":"Decrease the number of vCPUs for the DB instance. Increase the max_connections setting.","D":"Add an Amazon EventBridge rule that increases the max_connections setting of the DB instance when CPU utilization is above 75%.","C":"Add a CloudWatch alarm that changes the DB instance class when the number of connections increases to more than 1,000."},"exam_id":24,"question_images":[],"question_id":515,"url":"https://www.examtopics.com/discussions/amazon/view/107437-exam-aws-certified-developer-associate-dva-c02-topic-1/","topic":"1","timestamp":"2023-04-25 14:35:00","answer_ET":"B","answer_description":"","answers_community":["B (93%)","7%"],"isMC":true,"question_text":"A company has a critical application on AWS. The application exposes an HTTP API by using Amazon API Gateway. The API is integrated with an AWS Lambda function. The application stores data in an Amazon RDS for MySQL DB instance with 2 virtual CPUs (vCPUs) and 64 GB of RAM.\n\nCustomers have reported that some of the API calls return HTTP 500 Internal Server Error responses. Amazon CloudWatch Logs shows errors for “too many connections.” The errors occur during peak usage times that are unpredictable.\n\nThe company needs to make the application resilient. The database cannot be down outside of scheduled maintenance hours.\n\nWhich solution will meet these requirements?","discussion":[{"content":"Selected Answer: B\nThe best solution to meet these requirements would be to use Amazon RDS Proxy to create a proxy that connects to the DB instance and update the Lambda function to connect to the proxy.","timestamp":"1698237300.0","comment_id":"880370","poster":"MrTee","upvote_count":"11"},{"upvote_count":"3","comment_id":"1331128","poster":"sumanshu","timestamp":"1735046940.0","content":"Selected Answer: B\nA) Eliminated - Decreasing the number of vCPUs will worsen performance.\n\nB) When your Lambda function wants to query the database, instead of opening a new connection every time (which is what causes \"too many connections\"), it talks to the RDS Proxy. For example, if 100 Lambda functions try to connect at the same time, instead of opening 100 database connections, the RDS Proxy might only open 10 and reuse them.\n\nC) Eliminated - It incurs unnecessary costs for increased capacity, even if the issue is caused by connection management."},{"timestamp":"1732246320.0","poster":"65703c1","content":"Selected Answer: B\nB is the correct answer.","comment_id":"1215329","upvote_count":"1"},{"upvote_count":"3","comment_id":"1119452","timestamp":"1720675260.0","poster":"SerialiDr","content":"Selected Answer: B\nAmazon RDS Proxy is designed to handle a large number of simultaneous connections efficiently. It sits between your application and your RDS database to pool and share database connections, improving database efficiency and application scalability. This approach can reduce the number of connections to the database and handle unpredictable peak loads more effectively."},{"timestamp":"1710161580.0","content":"Selected Answer: B\nB: RDS Proxy establishes and manages the necessary connection pools to your database so that your Lambda function creates fewer database connections¹. RDS Proxy also handles failovers and retries automatically, which improves the availability of your application.\n\nA will reduce the performance and capacity of the database.\nC may incur additional charges for scaling up the DB instance. It may also cause downtime during the scaling process, which violates the requirement that the database cannot be down outside of scheduled maintenance hours.\nD may not react fast enough to handle unpredictable peak usage times. It may also cause memory issues if the max_connections setting is too high.","comment_id":"1004650","poster":"hsinchang","upvote_count":"1"},{"content":"Selected Answer: B\nAdding an Amazon EventBridge rule to increase the max_connections setting based on CPU utilization is not directly addressing the issue of too many connections. Additionally, focusing solely on CPU utilization might not be the best metric for handling connection-related issues.","poster":"love777","upvote_count":"2","comment_id":"994189","timestamp":"1709222760.0"},{"comment_id":"952609","timestamp":"1705352100.0","upvote_count":"1","poster":"tttamtttam","content":"Selected Answer: B\nI think D is incorrect because it increases the number of connections based on the CPU consumption not the number of connections."},{"content":"Selected Answer: D\nhttps://repost.aws/knowledge-center/rds-mysql-max-connections","timestamp":"1704880500.0","poster":"Naj_64","comment_id":"947878","upvote_count":"1"},{"timestamp":"1701807240.0","upvote_count":"3","poster":"csG13","comment_id":"915668","content":"Selected Answer: B\nIt’s B. RDS proxy can handle many open connections to the database."},{"poster":"awsdummie","content":"Selected Answer: D\nThere should not be any downtime. Create an Event bridge rule to update the max_connections parameter in Parameter group of DB instance.","upvote_count":"1","comment_id":"909722","timestamp":"1701299160.0"}],"unix_timestamp":1682426100,"answer_images":[]}],"exam":{"numberOfQuestions":551,"isBeta":false,"isMCOnly":true,"id":24,"provider":"Amazon","lastUpdated":"11 Apr 2025","name":"AWS Certified Developer - Associate DVA-C02","isImplemented":true},"currentPage":103},"__N_SSP":true}