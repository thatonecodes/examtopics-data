{"pageProps":{"questions":[{"id":"sEk8FUZcfv3pd7y3D9Jw","url":"https://www.examtopics.com/discussions/amazon/view/152299-exam-aws-certified-machine-learning-engineer-associate-mla/","answer":"A","question_id":91,"answers_community":["A (100%)"],"answer_description":"","answer_images":[],"choices":{"D":"Specificity","B":"Precision","A":"Accuracy","C":"Recall"},"exam_id":27,"answer_ET":"A","timestamp":"2024-11-28 17:42:00","topic":"1","unix_timestamp":1732812120,"question_text":"A company has a binary classification model in production. An ML engineer needs to develop a new version of the model.\nThe new model version must maximize correct predictions of positive labels and negative labels. The ML engineer must use a metric to recalibrate the model to meet these requirements.\nWhich metric should the ML engineer use for the model recalibration?","discussion":[{"upvote_count":"1","poster":"aws_Tamilan","comment_id":"1413916","timestamp":"1743390300.0","content":"Selected Answer: A\nüîë Keyword: Maximize correct predictions of both positive and negative labels\n‚úÖ Correct Answer: A. Accuracy\n\nWhy?\n\nAccuracy measures the proportion of correctly classified instances (both positive and negative).\n\nIt is the most appropriate metric when both false positives and false negatives need to be minimized.\n\nWhy Others Are Wrong?\n‚ùå B. Precision focuses only on correctly predicted positives, not overall correctness.\n‚ùå C. Recall focuses only on capturing all true positives, ignoring true negatives.\n‚ùå D. Specificity only measures the ability to identify true negatives."},{"poster":"kyo","comment_id":"1342880","upvote_count":"1","content":"Selected Answer: A\nFor imbalanced data, F1 score is preferred over confusion matrix-derived metrics. Ideally, option A would be \"F1 Score\". Given the choices, A (Accuracy) is the most reasonable, though not ideal.","timestamp":"1737266400.0"},{"upvote_count":"3","poster":"Saransundar","content":"Selected Answer: A\nA. Accuracy: Correct choice; maximizes both true positives and true negatives. Formula: (TP + TN) / Total Predictions\nB. Precision: Focuses only on true positives, not negatives. Formula: TP / (TP + FP)\nC. Recall: Focuses on capturing all true positives, ignoring negatives. Formula: TP / (TP + FN)\nD. Specificity: Focuses only on true negatives, ignoring positives. Formula: TN / (TN + FP)","comment_id":"1322273","timestamp":"1733386020.0"},{"comment_id":"1319358","poster":"GiorgioGss","upvote_count":"1","timestamp":"1732812180.0","content":"Selected Answer: A\nAccuracy formula:\n(True Positives + True Negatives) / Total Predictions"},{"timestamp":"1732812120.0","upvote_count":"1","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/clarify-accuracy-evaluation.html","comment_id":"1319357","poster":"GiorgioGss"}],"question_images":[],"isMC":true},{"id":"oQ1XcRLEZrFuowIzV80d","question_images":[],"discussion":[{"timestamp":"1732676940.0","upvote_count":"7","poster":"a4002bd","comment_id":"1318401","content":"Selected Answer: D\nSageMaker Pipelines provides a robust way to manage and visualize ML workflows as directed acyclic graphs (DAGs), while SageMaker Experiments helps track and manage the history of model experiments and supports model governance"},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/define-pipeline.html\nI don't see how you can manage the \"entire ML flow\" (as question asks) with something else other than Studio.","poster":"GiorgioGss","comment_id":"1319367","upvote_count":"5","timestamp":"1732812600.0"},{"comment_id":"1413917","timestamp":"1743390300.0","content":"Selected Answer: C\nüîë Keyword: Fine-grained control, DAG visualization, model governance, auditing\n‚úÖ Correct Answer: C. Use SageMaker Pipelines and its integration with SageMaker Studio to manage the entire ML workflows. Use SageMaker ML Lineage Tracking for the running history of experiments and for auditing and compliance verifications.\n\nWhy?\n\nSageMaker Pipelines provides workflow orchestration with DAG visualization.\n\nSageMaker ML Lineage Tracking enables experiment history and model governance for auditing.\n\nWhy Others Are Wrong?\n‚ùå A & B. AWS CodePipeline is more suited for software CI/CD than for ML workflows.\n‚ùå D. SageMaker Experiments focuses on tracking experiments but lacks full model lineage tracking.","poster":"aws_Tamilan","upvote_count":"1"},{"timestamp":"1741675500.0","poster":"chris_spencer","content":"Selected Answer: C\nContrary to its name, Amazon SageMaker ML Lineage Tracking does:\n\n1. Keep a running history of model discovery experiments.\n2. Establish model governance by tracking model lineage artifacts for auditing and compliance verification.\n\nReference: https://docs.aws.amazon.com/sagemaker/latest/dg/lineage-tracking.html","comment_id":"1387310","upvote_count":"1"},{"poster":"abrarjahin","timestamp":"1738011840.0","upvote_count":"1","comment_id":"1347573","content":"Selected Answer: D\nSageMaker Pipelines handles the orchestration of workflows with fine-grained control.\nSageMaker Experiments provides the necessary tracking, organization, and governance features for experiments and compliance."},{"content":"Selected Answer: C\nML Lineage for Audit/Compliance, Studio for DAG, SM Pipeline for entire workflow","timestamp":"1737604200.0","poster":"fnuuu","comment_id":"1345078","upvote_count":"3"},{"timestamp":"1735888260.0","content":"Selected Answer: C\nThe correct answer is C.\n\nOptions B and D suggest using SageMaker Experiments, which is good for tracking experiments but doesn't provide the comprehensive lineage tracking and governance features that ML Lineage Tracking offers.\n\nRunning history of experiments: SageMaker ML Lineage Tracking provides a comprehensive way to track the lineage of ML workflows, including datasets, algorithms, hyperparameters, and models. This fulfills the requirement for keeping a running history of model discovery experiments.\n\nModel governance for auditing and compliance: ML Lineage Tracking also supports model governance by providing detailed information about each step in the ML process, which is crucial for auditing and compliance verifications.","poster":"khchan123","upvote_count":"4","comment_id":"1335926"},{"timestamp":"1734827220.0","content":"Selected Answer: D\nSageMaker Experiments https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html","comment_id":"1330212","poster":"jackzhang846","upvote_count":"2"},{"content":"Selected Answer: C\nSageMaker ML Lineage Tracking Êèê‰æõÊ®°ÂûãÂíåÊï∞ÊçÆÁöÑË°ÄÁºòËøΩË∏™ÂäüËÉΩÔºåÊîØÊåÅÂÆ°ËÆ°ÂíåÂêàËßÑÊÄß„ÄÇ","poster":"jackzhang846","timestamp":"1734767340.0","upvote_count":"2","comment_id":"1329874"},{"poster":"Saransundar","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/lineage-tracking.html\nWith SageMaker AI Lineage Tracking data scientists and model builders to Keep a running history of model discovery experiments. Establish model governance by tracking model lineage artifacts for auditing and compliance verification.","comment_id":"1321773","timestamp":"1733301240.0","upvote_count":"4"}],"answer_ET":"C","question_id":92,"answers_community":["C (67%)","D (33%)"],"unix_timestamp":1732676940,"timestamp":"2024-11-27 04:09:00","exam_id":27,"isMC":true,"question_text":"A company is using Amazon SageMaker to create ML models. The company's data scientists need fine-grained control of the ML workflows that they orchestrate. The data scientists also need the ability to visualize SageMaker jobs and workflows as a directed acyclic graph (DAG). The data scientists must keep a running history of model discovery experiments and must establish model governance for auditing and compliance verifications.\nWhich solution will meet these requirements?","choices":{"A":"Use AWS CodePipeline and its integration with SageMaker Studio to manage the entire ML workflows. Use SageMaker ML Lineage Tracking for the running history of experiments and for auditing and compliance verifications.","B":"Use AWS CodePipeline and its integration with SageMaker Experiments to manage the entire ML workflows. Use SageMaker Experiments for the running history of experiments and for auditing and compliance verifications.","D":"Use SageMaker Pipelines and its integration with SageMaker Experiments to manage the entire ML workflows. Use SageMaker Experiments for the running history of experiments and for auditing and compliance verifications.","C":"Use SageMaker Pipelines and its integration with SageMaker Studio to manage the entire ML workflows. Use SageMaker ML Lineage Tracking for the running history of experiments and for auditing and compliance verifications."},"answer":"C","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/152095-exam-aws-certified-machine-learning-engineer-associate-mla/","answer_description":"","answer_images":[]},{"id":"ydggQdSU4GBqNJAhqhkI","exam_id":27,"timestamp":"2024-11-28 17:52:00","question_text":"A company wants to reduce the cost of its containerized ML applications. The applications use ML models that run on Amazon EC2 instances, AWS Lambda functions, and an Amazon Elastic Container Service (Amazon ECS) cluster. The EC2 workloads and ECS workloads use Amazon Elastic Block Store (Amazon EBS) volumes to save predictions and artifacts.\nAn ML engineer must identify resources that are being used inefficiently. The ML engineer also must generate recommendations to reduce the cost of these resources.\nWhich solution will meet these requirements with the LEAST development effort?","answer_ET":"D","answers_community":["D (100%)"],"answer_images":[],"answer":"D","topic":"1","discussion":[{"content":"Selected Answer: D\nüîë Keyword: Identify inefficient ML resources, generate cost recommendations with minimal effort\n‚úÖ Correct Answer: D. Run AWS Compute Optimizer.\n\nWhy?\n\nAWS Compute Optimizer provides automated recommendations for optimizing EC2 instances, EBS volumes, and Lambda.\n\nIt minimizes development effort by analyzing workloads automatically.\n\nWhy Others Are Wrong?\n‚ùå A. Writing custom code for resource evaluation is manual and inefficient.\n‚ùå B. Cost allocation tags help track expenses but do not provide recommendations.\n‚ùå C. CloudTrail shows historical logs but does not analyze cost inefficiencies.","timestamp":"1743390540.0","comment_id":"1413919","upvote_count":"1","poster":"aws_Tamilan"},{"timestamp":"1733302380.0","comment_id":"1321779","content":"Selected Answer: D\nAWS Compute Optimizer finds wasted resources in EC2, EBS and suggests easy ways to save money and boost performance.","upvote_count":"2","poster":"Saransundar"},{"timestamp":"1732812720.0","content":"Selected Answer: D\nAll is compute related so, D.","comment_id":"1319369","poster":"GiorgioGss","upvote_count":"1"}],"unix_timestamp":1732812720,"choices":{"D":"Run AWS Compute Optimizer.","C":"Check AWS CloudTrail event history for the creation of the resources.","B":"Add cost allocation tags to the resources. Activate the tags in AWS Billing and Cost Management.","A":"Create code to evaluate each instance's memory and compute usage."},"question_id":93,"answer_description":"","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/152305-exam-aws-certified-machine-learning-engineer-associate-mla/","question_images":[]},{"id":"YzPGnwp9r8pvvUkLDuE5","question_images":[],"topic":"1","exam_id":27,"answer_images":[],"choices":{"D":"Use an AWS Glue Data Catalog to store the models. Run an AWS Glue crawler to migrate the models from the ECR repositories to the Data Catalog. Configure cross-account access to the Data Catalog.","C":"Use the Amazon SageMaker Model Registry to create a model group for models hosted in Amazon ECR. Create a new AWS account. In the new account, use the SageMaker Model Registry as the central catalog. Attach a cross-account resource policy to each model group in the initial AWS accounts.","B":"Create a new AWS account with a new ECR repository as the central catalog. Configure ECR cross-account replication between the initial ECR repositories and the central catalog.","A":"Configure ECR cross-account replication for each existing ECR repository. Ensure that each model is visible in each AWS account."},"answer_ET":"C","isMC":true,"unix_timestamp":1732677060,"discussion":[{"comment_id":"1319374","upvote_count":"6","timestamp":"1732813200.0","comments":[{"upvote_count":"1","content":"Is it possible to use SageMaker Model Registry to create a model group for models from ECR repos?","poster":"Saransundar","comments":[{"content":"yes. https://aws.amazon.com/about-aws/whats-new/2023/10/amazon-sagemaker-model-registry-private-model-repositories/","comment_id":"1334710","timestamp":"1735635660.0","upvote_count":"1","poster":"Ell89"}],"comment_id":"1321807","timestamp":"1733307840.0"}],"content":"Selected Answer: C\nThe question asks for a \"central catalog\" so I believe metadata, lineage tracking are also \"included\". ECR could not be the solution.","poster":"GiorgioGss"},{"upvote_count":"1","poster":"aws_Tamilan","comment_id":"1413925","timestamp":"1743391200.0","content":"Selected Answer: C\nüîë Keyword: Central catalog for ML models across AWS accounts, models stored in ECR\n‚úÖ Correct Answer: C. Use the Amazon SageMaker Model Registry to create a model group for models hosted in Amazon ECR. Create a new AWS account. In the new account, use the SageMaker Model Registry as the central catalog. Attach a cross-account resource policy to each model group in the initial AWS accounts.\n\nWhy?\n\nSageMaker Model Registry provides a central catalog for ML models, supporting cross-account access.\n\nCross-account resource policies enable access to models across AWS accounts.\n\nWhy Others Are Wrong?\n‚ùå A. ECR cross-account replication does not create a centralized catalog.\n‚ùå B. A new ECR repository with replication does not offer model versioning or governance.\n‚ùå D. AWS Glue Data Catalog is for metadata storage, not for ML model management."},{"timestamp":"1732677060.0","content":"Selected Answer: B\nThis approach allows you to centralize all models in a single ECR repository, making it easier to manage and access them across different AWS accounts. Cross-account replication ensures that the models are synchronized between the initial repositories and the central catalog, maintaining consistency and availability.","comment_id":"1318403","poster":"a4002bd","upvote_count":"1"}],"answer":"C","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/152097-exam-aws-certified-machine-learning-engineer-associate-mla/","timestamp":"2024-11-27 04:11:00","question_id":94,"question_text":"A company needs to create a central catalog for all the company's ML models. The models are in AWS accounts where the company developed the models initially. The models are hosted in Amazon Elastic Container Registry (Amazon ECR) repositories.\nWhich solution will meet these requirements?","answers_community":["C (88%)","13%"]},{"id":"oPp5KId7gjzxKCFt2wIY","exam_id":27,"answer_description":"","answer_images":[],"unix_timestamp":1732813560,"url":"https://www.examtopics.com/discussions/amazon/view/152310-exam-aws-certified-machine-learning-engineer-associate-mla/","answer":"A","discussion":[{"content":"Selected Answer: A\nüîë Keyword: Validate new model on 10% of traffic with minimal overhead\n‚úÖ Correct Answer: A. Use production variants to add the new model to the existing SageMaker endpoint. Set the variant weight to 0.1 for the new model. Monitor the number of invocations by using Amazon CloudWatch.\n\nWhy?\n\nSageMaker production variants allow traffic splitting across multiple models on a single endpoint.\n\nSetting variant weight to 0.1 ensures only 10% of traffic is sent to the new model.\n\nCloudWatch can monitor invocations for validation.\n\nWhy Others Are Wrong?\n‚ùå B. Setting the variant weight to 1 will send all traffic to the new model, defeating the purpose.\n‚ùå C. Creating a new endpoint increases operational overhead unnecessarily.\n‚ùå D. ALB-based routing is more complex than using SageMaker variants for traffic splitting.","upvote_count":"1","poster":"aws_Tamilan","timestamp":"1743391260.0","comment_id":"1413926"},{"upvote_count":"1","comment_id":"1321804","timestamp":"1733307360.0","poster":"Saransundar","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html"},{"content":"Selected Answer: A\n{\n 'ProductionVariants': [\n {\n 'VariantName': 'existing-model',\n 'ModelName': 'existing-model',\n 'InitialVariantWeight': 0.9\n },\n {\n 'VariantName': 'new-model',\n 'ModelName': 'new-model',\n 'InitialVariantWeight': 0.1\n }\n ]\n}","upvote_count":"2","timestamp":"1732813560.0","poster":"GiorgioGss","comment_id":"1319381"}],"isMC":true,"timestamp":"2024-11-28 18:06:00","topic":"1","question_images":[],"question_text":"A company has developed a new ML model. The company requires online model validation on 10% of the traffic before the company fully releases the model in production. The company uses an Amazon SageMaker endpoint behind an Application Load Balancer (ALB) to serve the model.\nWhich solution will set up the required online validation with the LEAST operational overhead?","answers_community":["A (100%)"],"choices":{"B":"Use production variants to add the new model to the existing SageMaker endpoint. Set the variant weight to 1 for the new model. Monitor the number of invocations by using Amazon CloudWatch.","C":"Create a new SageMaker endpoint. Use production variants to add the new model to the new endpoint. Monitor the number of invocations by using Amazon CloudWatch.","A":"Use production variants to add the new model to the existing SageMaker endpoint. Set the variant weight to 0.1 for the new model. Monitor the number of invocations by using Amazon CloudWatch.","D":"Configure the ALB to route 10% of the traffic to the new model at the existing SageMaker endpoint. Monitor the number of invocations by using AWS CloudTrail."},"question_id":95,"answer_ET":"A"}],"exam":{"isMCOnly":false,"isBeta":false,"numberOfQuestions":106,"id":27,"isImplemented":true,"lastUpdated":"11 Apr 2025","name":"AWS Certified Machine Learning Engineer - Associate MLA-C01","provider":"Amazon"},"currentPage":19},"__N_SSP":true}