{"pageProps":{"questions":[{"id":"Pf9DnlD4FBvAx6OxR7fT","answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/47021-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":["https://www.examtopics.com/assets/media/exam-media/04241/0029700001.png"],"unix_timestamp":1615708860,"question_text":"A company with several AWS accounts is using AWS Organizations and service control policies (SCPs). An Administrator created the following SCP and has attached it to an organizational unit (OU) that contains AWS account 1111-1111-1111:\n//IMG//\n\nDevelopers working in account 1111-1111-1111 complain that they cannot create Amazon S3 buckets. How should the Administrator address this problem?","timestamp":"2021-03-14 09:01:00","discussion":[{"upvote_count":"11","poster":"walkwolf3","content":"C\n\nA. It will give other people access of creating S3 bucket.\nB. It doesn't comply with organization's rule by removing accournt from OU. And it won't work either.\nC. Add required access to Developers only, not affecting others, right option.\nD. Provide people to change cloudtrail, which should be prohibited.","comment_id":"424557","comments":[{"poster":"joe16","comment_id":"451967","timestamp":"1635783060.0","content":"C is right.\nHowever A's explanation is incorrect - https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\n\"SCPs are similar to AWS Identity and Access Management (IAM) permission policies and use almost the same syntax. However, an SCP never grants permissions.\"","upvote_count":"5"}],"timestamp":"1633183680.0"},{"timestamp":"1632665820.0","comment_id":"344278","poster":"Waiweng","upvote_count":"5","content":"go with C"},{"content":"C the answer","comment_id":"1062187","upvote_count":"1","timestamp":"1699110000.0","poster":"Kondon200"},{"timestamp":"1672157520.0","comment_id":"758764","content":"Selected Answer: C\nC looks better\nSCP doesn't grant permissions","poster":"evargasbrz","upvote_count":"1"},{"poster":"mrgreatness","content":"100pc it is C. If you don't understand why I suggest studying IAM and Orgs more.","comment_id":"704149","timestamp":"1666728780.0","upvote_count":"1"},{"poster":"dmscountera","content":"Selected Answer: C\nBased on all comments","comment_id":"685667","upvote_count":"1","timestamp":"1664814180.0"},{"poster":"jj22222","content":"Selected Answer: C\nC looks ok","comment_id":"577907","upvote_count":"1","timestamp":"1648593840.0"},{"content":"Answer - C - The below passage clarifies why its C.\nSCPs alone are not sufficient to granting permissions to the accounts in your organization. No permissions are granted by an SCP. An SCP defines a guardrail, or sets limits, on the actions that the account's administrator can delegate to the IAM users and roles in the affected accounts. The administrator must still attach identity-based or resource-based policies to IAM users or roles, or to the resources in your accounts to actually grant permissions. The effective permissions are the logical intersection between what is allowed by the SCP and what is allowed by the IAM and resource-based policies.","timestamp":"1640170920.0","comment_id":"507001","poster":"tkanmani76","upvote_count":"5"},{"timestamp":"1638639900.0","comment_id":"493869","upvote_count":"1","content":"C seems perfect","poster":"AzureDP900"},{"upvote_count":"1","comments":[{"poster":"mnsait","comment_id":"1323236","timestamp":"1733597100.0","content":"Nicely put. The statement is C is oxy-moron - one cannot add a permission to oneself if one does not have the permission.","upvote_count":"1"}],"timestamp":"1638187740.0","content":"why C ? I cannot add a permission to my user explicitly. if i do not have it then i need to ask someone to add it for like an admin. so C is ruled out here as well","poster":"ryu10_09","comment_id":"489854"},{"timestamp":"1634813040.0","poster":"andylogan","content":"It's C","comment_id":"450766","upvote_count":"1"},{"timestamp":"1634210100.0","comment_id":"445418","content":"B seems the best \n\nThe SCP will continue to allow until it reaches and explicit Deny.","comments":[{"timestamp":"1634611080.0","comment_id":"445422","poster":"AWSum1","upvote_count":"2","content":"Changing to C, \n\nTaking this link into consideration , C is correct \n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html"}],"upvote_count":"1","poster":"AWSum1"},{"upvote_count":"3","poster":"tekkart","comment_id":"423617","timestamp":"1633097700.0","comments":[{"comment_id":"430269","poster":"AWS_Noob","timestamp":"1633280580.0","content":"I tend to agree \n\nThe deny on the ou is blocking","upvote_count":"1"}],"content":"I would say answer B.\nSee this page : https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_inheritance_auth.html\n-> Permissions work as the intersection from SCP of decreasing levels : root OU, child OU, account\n-> Explicit Deny > Explicit Allow > Implicit Deny > Implicit Allow\nwhere > means \"takes precedence over\".\nIf in this (OU-level SCP) where Explicit Allow on All Resources, S3 actions cannot be performed, it means that there must be an Explicit Deny on the (Root-OU Level).\nThen to troubleshoot, the 2 options would be : \n- to remove this Explicit Deny from the Root-OU SCP we assume there is (not proposed in the answers)\n- or remove the OU dependency of the 1111-1111-1111 account for the Root-OU SCP not to apply anymore. This will have the impact that this Child-OU SCP will not apply anymore either, the only left will be Account-Level-IAM-Policy , assuming that she allows S3 actions\n\nAnswer B"},{"content":"I'll go with C","upvote_count":"2","poster":"WhyIronMan","timestamp":"1632995760.0","comment_id":"409574"},{"poster":"CarisB","content":"C is the only one which makes sense","comment_id":"337511","timestamp":"1632407160.0","upvote_count":"1"},{"comment_id":"329054","timestamp":"1632236640.0","poster":"certainly","content":"C is correct","upvote_count":"1"},{"timestamp":"1632101520.0","poster":"gsw","upvote_count":"1","comment_id":"328792","content":"\"SCPs don't affect resource-based policies directly.\" https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html"},{"poster":"Nguyenhau","upvote_count":"3","timestamp":"1632094980.0","comment_id":"310378","content":"I go with C"}],"question_id":411,"isMC":true,"answer_description":"","topic":"1","answer_images":[],"answer_ET":"C","choices":{"B":"Remove the account from the OU, and attach the SCP directly to account 1111-1111-1111.","C":"Instruct the Developers to add Amazon S3 permissions to their IAM entities.","A":"Add s3:CreateBucket with ג€Allowג€ effect to the SCP.","D":"Remove the SCP from account 1111-1111-1111."},"answers_community":["C (100%)"],"exam_id":32},{"id":"KEZEKkVsoHbDOATABHJ1","url":"https://www.examtopics.com/discussions/amazon/view/5118-exam-aws-certified-solutions-architect-professional-topic-1/","answer_description":"","question_id":412,"exam_id":32,"discussion":[{"timestamp":"1632448620.0","upvote_count":"48","content":"B\nhttps://docs.aws.amazon.com/firehose/latest/dev/writing-with-agents.html\nA: Not real time.\nC: Not sure if in-memory caching will help in terms of logs and not DB? Anyway installing ES cluster on the same EC2 instance means the ES is not managed and will increase overhead.\nD: ES already has direct integration with Firehose, there is no need to transfer to S3 first unless it needs to retain the data for long period of time for analysis\nhttps://aws.amazon.com/elasticsearch-service/?nc=sn&loc=1","comment_id":"13215","poster":"donathon","comments":[{"poster":"StelSen","timestamp":"1636241160.0","upvote_count":"1","content":"Just adding one more link to support Option B. https://aws.amazon.com/blogs/big-data/ingest-streaming-data-into-amazon-elasticsearch-service-within-the-privacy-of-your-vpc-with-amazon-kinesis-data-firehose/","comment_id":"455850"}]},{"timestamp":"1632160320.0","content":"Should be B?","upvote_count":"10","poster":"Xiaoyao2000","comment_id":"11162"},{"comment_id":"943082","content":"Selected Answer: B\nB\nhttps://docs.aws.amazon.com/firehose/latest/dev/writing-with-agents.html\nA: Not real time.\nC: Not sure if in-memory caching will help in terms of logs and not DB? Anyway installing ES cluster on the same EC2 instance means the ES is not managed and will increase overhead.\nD: ES already has direct integration with Firehose, there is no need to transfer to S3 first unless it needs to retain the data for long period of time for analysis\nhttps://aws.amazon.com/elasticsearch-service/?nc=sn&loc=1","upvote_count":"1","timestamp":"1688496180.0","poster":"SkyZeroZx"},{"content":"Selected Answer: B\nI'd say B too.","upvote_count":"1","timestamp":"1668288180.0","poster":"DarthYoda","comment_id":"716936"},{"content":"Selected Answer: B\nBased on all comments","comment_id":"685669","timestamp":"1664814360.0","poster":"dmscountera","upvote_count":"1"},{"content":"B. Use an Amazon Kinesis agent running on an EC2 instance in an Auto Scaling group to collect and send the data to an Amazon Kinesis Data Firehose delivery stream. The Kinesis Data Firehose delivery stream will deliver the data directly to Amazon ES. Use Kibana to visualize the data.","timestamp":"1639059180.0","comment_id":"497783","upvote_count":"2","poster":"cldy"},{"poster":"AzureDP900","comment_id":"493874","timestamp":"1638640200.0","content":"There is no need of Lambda function that is the reason B is right!","upvote_count":"1"},{"comment_id":"457110","upvote_count":"2","timestamp":"1636266660.0","content":"Would use OpenSearch these days instead of ElasticSearch, otherwise still B is the correct answer.\n\nhttps://docs.aws.amazon.com/opensearch-service/latest/developerguide/integrations.html","poster":"kirrim"},{"upvote_count":"1","content":"it's B","comment_id":"450786","poster":"andylogan","timestamp":"1636235280.0"},{"content":"B Kinesis to fire hose to s3","comment_id":"450692","timestamp":"1636223220.0","poster":"awsbob2021","upvote_count":"1"},{"comment_id":"409580","upvote_count":"2","poster":"WhyIronMan","content":"I'll go with B","timestamp":"1635839580.0"},{"timestamp":"1635654660.0","poster":"nodogoshi","upvote_count":"1","content":"D. Firehose dont supplementary efs.","comment_id":"408780"},{"comment_id":"406675","upvote_count":"1","poster":"Akhil254","content":"B Correct","timestamp":"1635523020.0"},{"comment_id":"349095","content":"The answer is B because Kinesis Firehose is for near real time streaming of data from cloudwatch, IOT, EC2 etc and it outputs data to splunk/http endpoints, redshift, S3 and elastic seacrch","timestamp":"1635457380.0","poster":"macshild","upvote_count":"2"},{"comment_id":"344359","content":"B is correct","poster":"Waiweng","upvote_count":"2","timestamp":"1635413940.0"},{"poster":"AJBA","timestamp":"1635405420.0","upvote_count":"1","content":"B \nhttps://docs.aws.amazon.com/firehose/latest/dev/create-destination.html","comment_id":"292586"},{"poster":"Kian1","comment_id":"289583","timestamp":"1635330060.0","upvote_count":"2","content":"going with B"},{"poster":"Ebi","content":"I go with B, there is no need to have a Lambda function","comment_id":"283172","timestamp":"1635195180.0","upvote_count":"3"},{"content":"B for sure kinesis for ingestion and Firehose for almost real-time","upvote_count":"2","poster":"kopper2019","timestamp":"1635124560.0","comment_id":"271759"},{"content":"100% B.","timestamp":"1634906700.0","poster":"sanjaym","comment_id":"267424","upvote_count":"1"},{"comment_id":"242445","poster":"T14102020","upvote_count":"1","content":"Correct answer is B. Kinesis Data Firehose can directly write to ES.","timestamp":"1634857500.0"},{"timestamp":"1634755980.0","poster":"jackdryan","upvote_count":"2","content":"I'll go with B","comment_id":"229448"},{"poster":"Bulti","timestamp":"1634599740.0","content":"Answer is B. Kinesis Data Firehose can directly write to ES. Others options are either not cost effective or scalable.","upvote_count":"2","comment_id":"228804"},{"comment_id":"194874","content":"B for sure. This is a very common topic for the Data Analytics Speciality exam which I passed recently.","upvote_count":"1","timestamp":"1634516280.0","poster":"Paitan"},{"content":"D: Seem like from this site. https://medium.com/@sagargulabani/centralized-logging-on-aws-using-cloudwatch-elasticsearch-and-firehose-3cb213d4cc24","poster":"AlwaysLearning2020","upvote_count":"2","timestamp":"1634507700.0","comment_id":"191496"},{"comment_id":"182650","content":"I go for B...\nhttps://aws.amazon.com/kinesis/data-firehose/?nc1=h_ls&kinesis-blogs.sort-by=item.additionalFields.createdDate&kinesis-blogs.sort-order=desc\n\nNo need to process tthe stream with an aditional lambda as D","poster":"ipindado2020","upvote_count":"1","timestamp":"1633927740.0"},{"poster":"fullaws","content":"B is correct","comment_id":"149478","upvote_count":"2","timestamp":"1633842060.0"},{"upvote_count":"2","poster":"noisonnoiton","timestamp":"1633373700.0","content":"B acceptable\nFirehose direct to ES","comment_id":"137713"},{"poster":"NikkyDicky","timestamp":"1633349520.0","comment_id":"134257","upvote_count":"2","content":"B for sure"},{"upvote_count":"1","timestamp":"1633082400.0","content":"B.\nD is not scaleable/highly available with only one EC2","comment_id":"100442","poster":"JAWS1600"},{"comment_id":"77508","content":"B. \nAs Elasticsearch is a database by itself, and is designed to store, retrieve and manage document oriented or semi-structured data. No need for S3 for storing the data.","poster":"fw","upvote_count":"3","timestamp":"1632941220.0"},{"comment_id":"49579","timestamp":"1632837360.0","poster":"amog","content":"Should be B","upvote_count":"3"},{"upvote_count":"7","content":"Correct answer is \"B\".\nKinesis Firehose integrate with ES, as in the below video.\nhttps://youtu.be/bC0un7kzCnU","poster":"Moon","comment_id":"14010","timestamp":"1632467280.0","comments":[{"comment_id":"76440","upvote_count":"2","content":"Longer version: https://youtu.be/NfkGpjrdy_Y?t=470","poster":"Smart","timestamp":"1632842220.0"}]},{"upvote_count":"2","timestamp":"1632154140.0","comments":[{"poster":"MGM","content":"D not scalable","timestamp":"1632316140.0","upvote_count":"1","comments":[{"poster":"9Ow30","content":"Which component is not scalable?\nB does not satisfies storage requirements. \nI will go for D","comment_id":"29049","upvote_count":"3","comments":[{"upvote_count":"1","timestamp":"1633188420.0","poster":"meenu2225","content":"Option D is no scalable with only 1 ec2.","comments":[{"poster":"oatif","timestamp":"1633283700.0","comments":[{"comment_id":"426401","timestamp":"1636032540.0","content":"B is scalable but does not seem to have a log storage element. D has a log storage element but is not scalable (single EC2). ??","upvote_count":"1","poster":"somebodyelse"}],"upvote_count":"1","content":"what about the storage requirement?","comment_id":"103588"}],"comment_id":"102162"}],"timestamp":"1632645600.0"}],"comment_id":"12793"},{"content":"requirement is least administrative overhead, lambda introduces overhead of maintaining scripts","timestamp":"1634299620.0","poster":"sam422","comment_id":"186782","upvote_count":"2"}],"content":"Why not D","comment_id":"10810","poster":"awsec2"}],"choices":{"C":"Use an in-memory caching application running on an Amazon EBS-optimized EC2 instance to capture the log data in near real-time. Install an Amazon ES cluster on the same EC2 instance to store the log files as they are delivered to Amazon EC2 in near real-time. Install a Kibana plugin to create the visualizations.","A":"Develop a Python script to capture the data from Amazon EC2 in real time and store the data in Amazon S3. Use a copy command to copy data from Amazon S3 to Amazon Redshift. Connect a business intelligence tool running on Amazon EC2 to Amazon Redshift and create the visualizations.","B":"Use an Amazon Kinesis agent running on an EC2 instance in an Auto Scaling group to collect and send the data to an Amazon Kinesis Data Firehose delivery stream. The Kinesis Data Firehose delivery stream will deliver the data directly to Amazon ES. Use Kibana to visualize the data.","D":"Use an Amazon Kinesis agent running on an EC2 instance to collect and send the data to an Amazon Kinesis Data Firehose delivery stream. The Kinesis Data Firehose delivery stream will deliver the data to Amazon S3. Use an AWS Lambda function to deliver the data from Amazon S3 to Amazon ES. Use Kibana to visualize the data."},"question_images":[],"answer":"B","answers_community":["B (100%)"],"unix_timestamp":1568293740,"answer_images":[],"isMC":true,"question_text":"A company that provides wireless services needs a solution to store and analyze log files about user activities. Currently, log files are delivered daily to Amazon\nLinux on an Amazon EC2 instance. A batch script is run once a day to aggregate data used for analysis by a third-party tool. The data pushed to the third-party tool is used to generate a visualization for end users. The batch script is cumbersome to maintain, and it takes several hours to deliver the ever-increasing data volumes to the third-party tool. The company wants to lower costs, and is open to considering a new tool that minimizes development effort and lowers administrative overhead. The company wants to build a more agile solution that can store and perform the analysis in near-real time, with minimal overhead. The solution needs to be cost effective and scalable to meet the company's end-user base growth.\nWhich solution meets the company's requirements?","answer_ET":"B","topic":"1","timestamp":"2019-09-12 15:09:00"},{"id":"Ksqf9LQrOeDPFtey2omD","answer_images":[],"topic":"1","question_text":"A company wants to move a web application to AWS. The application stores session information locally on each web server, which will make auto scaling difficult.\nAs part of the migration, the application will be rewritten to decouple the session data from the web servers. The company requires low latency, scalability, and availability.\nWhich service will meet the requirements for storing the session information in the MOST cost-effective way?","unix_timestamp":1569971040,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/5949-exam-aws-certified-solutions-architect-professional-topic-1/","answer":"D","choices":{"C":"Amazon RDS MySQL","D":"Amazon ElastiCache with the Redis engine","A":"Amazon ElastiCache with the Memcached engine","B":"Amazon S3"},"exam_id":32,"answer_ET":"D","discussion":[{"timestamp":"1632368640.0","poster":"donathon","content":"D\nWhile Key/Value data stores are known to be extremely fast and provide sub-millisecond latency, the added network latency and added cost are the drawbacks. An added benefit of leveraging Key/Value stores is that they can also be utilized to cache any data, not just HTTP sessions, which can help boost the overall performance of your applications.\nA vs D: ElastiCache offerings for In-Memory key/value stores include ElastiCache for Redis, which can support replication, and ElastiCache for Memcached which does not support replication.\nhttps://aws.amazon.com/caching/session-management/","upvote_count":"28","comment_id":"13785"},{"upvote_count":"11","poster":"Pupu86","comment_id":"310061","comments":[{"comment_id":"455855","timestamp":"1635942900.0","poster":"StelSen","upvote_count":"1","comments":[{"timestamp":"1665194760.0","comment_id":"688980","poster":"Jonfernz","upvote_count":"2","content":"plus Memcached isn't easy to scale. every time you want to upgrade, you cant do it directly. you'd need to create a new cluster."}],"content":"Agree. And possible to loose all user sessions from that node in this case. So Redis is better."}],"content":"I think they key aspect to choosing whether it is Memcached (A) or Redis (D) is to understand the key difference between both. \n\nMemcache & Redis offers low latency & scalability however if you talk about availability (1 of the pillar of good framework architecture), you must know that Redis is the only one that offers read replicas in the event of a node failure while Memcached doesn't have the ability to replicate a failed node (which means downtime)","timestamp":"1633862880.0"},{"upvote_count":"1","comment_id":"943085","poster":"SkyZeroZx","timestamp":"1688496240.0","content":"Selected Answer: D\nD is a classic usage for cache for session ( i have various aplications with Redis )"},{"upvote_count":"1","poster":"BlueSpark","timestamp":"1672619820.0","content":"D. Amazon ElastiCache with the Redis engine","comment_id":"763411"},{"poster":"DarthYoda","upvote_count":"1","comment_id":"716940","timestamp":"1668288420.0","content":"Selected Answer: D\nI'd say D. S3 doesn't really qualify for \"scalability\""},{"comment_id":"716938","upvote_count":"2","content":"Selected Answer: D\nI'd say D. S3 doesn't really qualify for \"scalability\"","poster":"DarthYoda","timestamp":"1668288360.0"},{"upvote_count":"1","comment_id":"704152","content":"D for sure","timestamp":"1666729320.0","poster":"mrgreatness"},{"content":"Selected Answer: D\nBased on all comments","comment_id":"685672","poster":"dmscountera","upvote_count":"1","timestamp":"1664814480.0"},{"upvote_count":"1","content":"Why not B? S3 is more cost-effective, is it not useful when it comes to storing sessions information with high-performance needs?","poster":"Mechanic","comments":[{"timestamp":"1665966840.0","poster":"ashii007","content":"S3 cannot support millisecond latency that is required for session management. In-memory caching solution is the way to go","upvote_count":"1","comment_id":"696686"}],"timestamp":"1648376340.0","comment_id":"576110"},{"timestamp":"1638863040.0","comment_id":"495747","content":"D. Amazon ElastiCache with the Redis engine","upvote_count":"2","poster":"cldy"},{"timestamp":"1635840180.0","upvote_count":"1","content":"It's D","comment_id":"450790","poster":"andylogan"},{"content":"A in real life, probably D for the exam.","upvote_count":"1","timestamp":"1635831240.0","comment_id":"445659","poster":"DonSp"},{"comment_id":"441133","timestamp":"1635165240.0","content":"Answer is D\n\nRedis: \nBuilding real-time apps across versatile use cases like gaming, geospatial service, caching, session stores, or queuing, with advanced data structures, replication, and point-in-time snapshot support. \n\nMemcached: \nBuilding a simple, scalable caching layer for your data-intensive apps. \n\nhttps://aws.amazon.com/elasticache/","upvote_count":"1","poster":"student22"},{"upvote_count":"2","timestamp":"1634827680.0","poster":"tgv","content":"DDD\n---","comment_id":"437819"},{"poster":"WhyIronMan","content":"I'll go with D","timestamp":"1634789940.0","upvote_count":"1","comment_id":"409583"},{"timestamp":"1634515140.0","upvote_count":"2","poster":"nodogoshi","comment_id":"408782","content":"A COST BEST. redis PERFORMANCE UNDERGONE"},{"comment_id":"344361","poster":"Waiweng","upvote_count":"2","timestamp":"1634103660.0","content":"D is correct"},{"content":"sure for D","comment_id":"322363","timestamp":"1633993320.0","upvote_count":"1","poster":"alisyech"},{"timestamp":"1633709760.0","comment_id":"282605","content":"I go with D","upvote_count":"5","poster":"Ebi"},{"content":"this for who support A - > https://aws.amazon.com/elasticache/redis-vs-memcached/\nD is the right one","comment_id":"278560","upvote_count":"2","timestamp":"1633680120.0","comments":[{"timestamp":"1633777860.0","content":"going with D","upvote_count":"2","comment_id":"290290","poster":"Kian1"}],"poster":"Kian1"},{"upvote_count":"1","poster":"sanjaym","timestamp":"1633501860.0","comment_id":"267425","content":"D for sure."},{"timestamp":"1633427760.0","upvote_count":"2","content":"A (memcached) as the question asked for “MOST cost effective way”","comment_id":"253259","poster":"RLai"},{"timestamp":"1633369320.0","content":"A.\nTo me, Redis for session caching is an overkill, memcached is good for session caching for it's simplicity, as well as reasonable scalability and availability by clustering with multiple nodes.","comments":[{"comment_id":"443414","poster":"Viper57","content":"Memcached is not suitable for session storage as it is not highly available. Memcached is suitable for caching because the information it stores is not critical.","upvote_count":"4","timestamp":"1635364740.0"}],"comment_id":"248833","upvote_count":"6","poster":"MichaelHuang"},{"poster":"T14102020","comment_id":"242448","upvote_count":"1","timestamp":"1633252380.0","content":"Correct answer is D. Redis ElastiCache"},{"poster":"jackdryan","timestamp":"1633052520.0","upvote_count":"2","content":"I'll go with D","comment_id":"229994"},{"timestamp":"1632923880.0","content":"Answer is D since Redis support replication in a multi-AZ environment.","comment_id":"228809","poster":"Bulti","upvote_count":"2"},{"comments":[{"comment_id":"277884","upvote_count":"2","poster":"lalitsrana","content":"Although both Memcached and Redis appear similar on the surface, in that they are\nboth in-memory key stores, they are quite different in practice. Because of the\nreplication and persistence features of Redis, ElastiCache manages Redis more as a relational database. Redis ElastiCache clusters are managed as stateful entities that\ninclude failover, similar to how Amazon RDS manages database failover.\n\nConversely, because Memcached is designed as a pure caching solution with no\npersistence, ElastiCache manages Memcached nodes as a pool that can grow and\nshrink, similar to an Amazon EC2 Auto Scaling group. Individual nodes are expendable,\nand ElastiCache provides additional capabilities here such as automatic node\nreplacement and Auto Discovery.\n\nBecause of availablity it's REDIS, I suppose.","timestamp":"1633653180.0"}],"poster":"petebear55","upvote_count":"3","comment_id":"227497","timestamp":"1632816000.0","content":"Why not A here .. as it says Scalable and MOST COST effective ? .. Redis can only scale Horizontally whilst memchche is cheap and highly scalable and perfect for the simple task of storing 'SESSION DATA' so im inclined for a"},{"comment_id":"226681","upvote_count":"3","poster":"lostri","content":"why not A? https://aws.amazon.com/elasticache/memcached/","timestamp":"1632769860.0"},{"comment_id":"198412","upvote_count":"1","content":"Option D","poster":"Paitan","timestamp":"1632756900.0"},{"poster":"noisonnoiton","upvote_count":"2","timestamp":"1632409500.0","content":"D acceptable","comment_id":"137715"},{"poster":"cmm103","upvote_count":"6","comment_id":"13497","comments":[{"timestamp":"1632684300.0","content":"Yes, Redis covers the requirement for high availability","comment_id":"143828","upvote_count":"3","poster":"MultiAZ"}],"content":"D\nhttps://aws.amazon.com/caching/session-management/\nhttps://aws.amazon.com/elasticache/redis-vs-memcached/","timestamp":"1632113280.0"}],"isMC":true,"timestamp":"2019-10-02 01:04:00","answers_community":["D (100%)"],"question_id":413,"answer_description":""},{"id":"7AFEX8YXvP2RNcXhiUI3","exam_id":32,"unix_timestamp":1568530920,"answer_ET":"C","choices":{"B":"Change the Classic Load Balancer to an Application Load Balancer","D":"Replace the application tier with 4 m4.2xlarge instances","A":"Migrate the existing EC2 instances to a serverless deployment using AWS Lambda functions","C":"Replace the application tier with m4.large instances in an Auto Scaling group"},"topic":"1","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/5196-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"isMC":true,"question_id":414,"question_text":"A company has an Amazon EC2 deployment that has the following architecture:\n✑ An application tier that contains 8 m4.xlarge instances\n✑ A Classic Load Balancer\n✑ Amazon S3 as a persistent data store\nAfter one of the EC2 instances fails, users report very slow processing of their requests. A Solutions Architect must recommend design changes to maximize system reliability. The solution must minimize costs.\nWhat should the Solutions Architect recommend?","timestamp":"2019-09-15 09:02:00","question_images":[],"answer_description":"","discussion":[{"upvote_count":"31","content":"C looks to be the best answer IMO. This is a capacity issue. Losing one EC2 instance resulted in reduced performance. What's needed is the benefits of an Auto Scaling group. You can scale out when needed and scale in as well (during off-peak hours, for example). Also, changing the size of the server can help with costs. You can scale out and in with smaller increments of capacity at a time. So I don't see an issue with the instance size change.\n\nNothing in this question points to an issue with CLB. Yes, AWS is encouraging people to move to ALB, but CLB is not the cause of the issue here. Having an ALB would not have avoided the issue being experienced.","timestamp":"1632941220.0","poster":"sb333","comment_id":"46406","comments":[{"poster":"Smart","upvote_count":"3","comment_id":"76459","content":"Agreed. The main problem is capacity that is fixed with ASG. It also helps reduce instance cost. \nA (Invalid): CLB cannot trigger Lambda functions - ALB can. Otherwise, good choice. \nB & D(Invalid): Doesn't resolve capacity issue or auto-healing (achieved by ASG)","timestamp":"1633443240.0"}]},{"upvote_count":"21","poster":"donathon","comments":[{"poster":"awsgcpazure","timestamp":"1632440160.0","comment_id":"13148","content":"Wow, amazing! \nYour comments are very helpful.","upvote_count":"2"},{"upvote_count":"1","content":"So, Ans is B?","timestamp":"1632482580.0","poster":"awspro","comment_id":"13550"},{"poster":"awspro","timestamp":"1632516900.0","upvote_count":"2","content":"Ah~ got it.\nELB + auto scaling \nyeah. thank you","comment_id":"13553"},{"poster":"donathon","comment_id":"13786","upvote_count":"8","content":"Yes answer is B.\nA: There is no sufficient information to say if the app can be replaced using Lambda.\nC\\D: There is no indication to say this is a load issue.","timestamp":"1632531540.0","comments":[{"upvote_count":"4","comment_id":"279840","poster":"shammous","content":"This is a reliability issue: \"After one of the EC2 instances fails --> slowness\". This means that the current setting is not elastic to replace the failed instances and scale according to the load. ASG is the solution for that. C is the best option here. B is really irrelevant.","timestamp":"1634851980.0"}]},{"content":"There is no mention anywhere that the application uses http/https. If it is a TCP app, then Application load balancer will not work.","comment_id":"393237","poster":"DashL","upvote_count":"2","timestamp":"1635450240.0"},{"comment_id":"443418","content":"Moving to an ALB does not improve the system reliability which is clearly stated in in the question. Using an ASG helps improve the reliability and allows instances to scale in the event of high demand. So Donathon's reasoning is incorrect in this instance.","timestamp":"1635882060.0","upvote_count":"1","poster":"Viper57"},{"comment_id":"49764","timestamp":"1632999780.0","poster":"AWSPro24","upvote_count":"45","comments":[{"upvote_count":"33","content":"I have read all donathon answers in Topic 2 and most are correct with great analysis. It's unfair to accuse people like that as we are all still learning and preparing for the exam. Instead, you might just criticize wrong answers and provide your preferred one based on your own analysis and references.","comments":[{"comment_id":"552340","timestamp":"1645396980.0","content":"When an instance breaks, it is dead. All connections to that instance break. What is the use of draining? How can \"the load balancer will allow existing, in-flight requests made to an instance to complete\"?","poster":"johnnsmith","upvote_count":"1"}],"comment_id":"279842","poster":"shammous","timestamp":"1634970360.0"}],"content":"I think donathon is feeding people bad answers. Either he's not knowledgeable or works for AWS and is trying to spread disinformation. How is connection draining related to the fact that a single failed instances causes degraded performance? You say there is no indication it is a load issue but how can it not be a load issue when only a single failure causes performance degradation. That sounds like the definition of a load issue to me and so Autoscaling is what is needed to adjust to both instance failures and fluctuating demand. Autoscaling also automatically replaces failed instances.. which would solve your single failure issue as well. https://aws.amazon.com/ec2/autoscaling/faqs/#Replacing_Impaired_Instances\n\nC should be the answer."}],"comment_id":"12707","timestamp":"1632433800.0","content":"By default, connection draining is enabled for Application Load Balancers but must be enabled for Classic Load Balancers. When Connection Draining is enabled and configured, the process of deregistering an instance from an Elastic Load Balancer gains an additional step. For the duration of the configured timeout, the load balancer will allow existing, in-flight requests made to an instance to complete, but it will not send any new requests to the instance. During this time, the API will report the status of the instance as InService, along with a message stating that “Instance deregistration currently in progress.” Once the timeout is reached, any remaining connections will be forcibly closed.\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/attach-load-balancer-asg.html\nhttps://aws.amazon.com/blogs/aws/elb-connection-draining-remove-instances-from-service-with-care/"},{"comment_id":"758779","timestamp":"1672158360.0","upvote_count":"2","poster":"evargasbrz","content":"Selected Answer: C\nC looks ok.\nI got it, It's a performance issue, so only ALB will solve this!"},{"comment_id":"716945","timestamp":"1668288600.0","poster":"DarthYoda","content":"Selected Answer: C\nC looks good. Q says \"maximize system reliability.\", the issue is with one of the instances failing, and we know autoscaling will immediately remediate this when one instance is lost","upvote_count":"1"},{"timestamp":"1664814840.0","content":"Selected Answer: C\nBased on all comments","poster":"dmscountera","comment_id":"685675","upvote_count":"1"},{"content":"Selected Answer: C\n@sb333's explanation clearly shows that the answer should be C.","comment_id":"679284","upvote_count":"1","timestamp":"1664149800.0","poster":"tomosabc1"},{"content":"B SURE","poster":"Sizuma","upvote_count":"1","comment_id":"655208","timestamp":"1661957700.0"},{"comments":[{"upvote_count":"1","comment_id":"715244","content":"I guess the keyword is AutoScaling.. even when the instance type is lower in spec but it can scale up automatically","timestamp":"1668085560.0","poster":"Aum"}],"upvote_count":"1","timestamp":"1661841960.0","comment_id":"653872","content":"what i do not get for C is how come a m4.large is more capable than m4.xlarge? I meant, I have chosen B. Then again, B isn't the best, either. This entire question has a lot of assumptions in it. If there is a capacity issue by loosing a m4.xlarge, by replacing the entire fleet of m4.xlarge with something less capable, wouldn't cause similar problem, too?","poster":"Guoxian"},{"poster":"astalavista1","timestamp":"1661697240.0","comment_id":"652983","upvote_count":"1","content":"Selected Answer: C\nThe scaling issue has nothing to do with intermittent session issues or users being logged off after an instance fails.\nThe answer has to be C, not B."},{"poster":"AzureDP900","timestamp":"1638640980.0","upvote_count":"5","comment_id":"493879","content":"requests processing slow don't have any relation with ALB vs Classic LB, it is capacity issue so C is right answer"},{"timestamp":"1636154640.0","content":"It's C","comment_id":"451147","poster":"andylogan","upvote_count":"1"},{"comment_id":"445423","content":"C \n\nThink of it this way. \n\nIf 2 instances fail, processing is gonna get slower. The CLB will still direct traffic to the instances. If it was latency or SNI needed than, an ALB would satisfy the answer","timestamp":"1636141680.0","upvote_count":"1","poster":"AWSum1"},{"timestamp":"1635847620.0","upvote_count":"2","content":"CCC\n---","comment_id":"437821","poster":"tgv"},{"timestamp":"1635641820.0","content":"I'll go with C","upvote_count":"4","poster":"WhyIronMan","comment_id":"409599"},{"content":"I think the answer is C.\nBecause the use of Classic Load Balancer is a pre-requisite, which means the application is using EC2-Classic Network instead of VPC, hence this rule out the use of ALB.","timestamp":"1635530640.0","upvote_count":"1","poster":"kuroro","comment_id":"406918"},{"comment_id":"406678","poster":"Akhil254","timestamp":"1635492840.0","content":"B,C correct","upvote_count":"1"},{"timestamp":"1635379140.0","upvote_count":"2","content":"key word reduce cost and improve reability, both direct me to go for C.","poster":"Kopa","comment_id":"392679"},{"comment_id":"363548","upvote_count":"2","timestamp":"1635272880.0","content":"C is the anwer. A classic Load Balancer has the connection draining feature. So they point here is Auto Scaling.","poster":"ibrahimsow"},{"content":"answer is C","timestamp":"1635204060.0","poster":"Waiweng","upvote_count":"3","comment_id":"344386"},{"poster":"Waiweng","content":"go for C","upvote_count":"2","timestamp":"1635200640.0","comment_id":"344366"},{"poster":"kiev","comments":[{"comment_id":"310233","timestamp":"1635142140.0","content":"C straight forward. What's your logic for B?","upvote_count":"1","poster":"ItsmeP"}],"timestamp":"1635135480.0","upvote_count":"1","comment_id":"298909","content":"This is my Fifth Cert and I have had this question on Sys Ops and Devops exams as well and I have always gone with B."},{"timestamp":"1635125940.0","comment_id":"290294","poster":"Kian1","upvote_count":"2","content":"will go with C"},{"content":"I also don't think issue is related to connection draining, to me it seems like a load and capacity issue which an auto scaling group will resolve it, also with proper usage of metrics and min/max setting of ASG you can save costs, so I go with C","comment_id":"282623","poster":"Ebi","upvote_count":"7","timestamp":"1635016920.0"},{"comments":[{"upvote_count":"2","comment_id":"425404","content":"One of the requirements is \"The solution must minimize costs\". So reducing the instance size by half and using ASG to scale the servers will solve the slowness issue and also save running infrastructure cost.","timestamp":"1635805320.0","poster":"jing8"}],"poster":"Trap_D0_r","comment_id":"280917","upvote_count":"3","timestamp":"1634977200.0","content":"I would agree with C if the answer didn't require instance resizing. There's literally no information about the application or its resource consumption, so there's no information to suggest that C (Converting the instances to half the size in an ASG) would be a viable option--why would you be able to cut the instances in half and presumably use twice as many of them? Have the instances been over-sized the entire time? The problem stemmed from when an instance went down behind a Classic (dumb) Load Balancer and most likely that load balancer was still trying to process jobs on the dead ec2 (CLBs are dumb, they don't know to stop serving requests to dead instances), causing a cascade of time-outs, resends, and extremely slow application performance. The easiest solution in an 8-instance application stack is to replace the single CLB with an ALB and enable health checks, so that the ALB will stop trying to serve up requests to an instance if it dies. This is the most practical solution with the provided information for this question."},{"content":"It's C at 100%. In the question I don't see any ASG mentioned. There is only the CLB and not the ASG.","comment_id":"271845","timestamp":"1634730420.0","poster":"Superomam","upvote_count":"3"},{"comment_id":"267432","content":"80% C , 20% still thinking about B.","poster":"sanjaym","upvote_count":"1","timestamp":"1634710320.0"},{"poster":"newme","content":"To pick an answer, I'll go with C.\nB is really tempting, the question is like an advertisement for ALB.\nI just can't find any evidence the problem is caused by Classic Load Balancer.","comment_id":"245200","upvote_count":"1","timestamp":"1634632140.0"},{"content":"Correct answer is C. Auto Scaling group","poster":"T14102020","upvote_count":"1","timestamp":"1634442420.0","comment_id":"242454"},{"comment_id":"229999","content":"I'll go with C","poster":"jackdryan","upvote_count":"3","timestamp":"1634393400.0"},{"upvote_count":"1","content":"answer is C as auto-scaling group should fix the problem.","comment_id":"228818","poster":"Bulti","timestamp":"1634370120.0"},{"comment_id":"226685","timestamp":"1634354280.0","poster":"lostri","content":"i vote for C","upvote_count":"1"},{"content":"If EC2 fails , LB notices that through healtchecks and removes that instance from Target Group pool. So we end up in same load spread across reduced number of EC \"backend\" servers. In order to fill that gap (reduced \"backend\" capacity) we need mechanism like auto-scaling , that will be able to start another EC2 to fill the gap.","poster":"jar0d","comment_id":"202537","upvote_count":"1","timestamp":"1634280720.0"},{"content":"This is typical use case of Auto scaling. So will go with option C.","comment_id":"194881","upvote_count":"1","timestamp":"1634214660.0","poster":"Paitan"},{"upvote_count":"2","content":"Answer is C moving to m4.large from m4.xlarge with ASG does reduce cost and improves reliability","timestamp":"1634203140.0","poster":"sam422","comment_id":"186737"},{"poster":"sam422","upvote_count":"3","timestamp":"1634196840.0","comment_id":"186736","content":"Answer is B moving to m4.large from m4.xlarge with ASG does reduce cost and improves reliability"},{"poster":"sam422","comment_id":"186735","timestamp":"1634166480.0","content":"Answer is B moving to m4.large from m4.xlarge with ASG does reduce cost and improves reliability","upvote_count":"2"},{"upvote_count":"1","comment_id":"149534","timestamp":"1634093100.0","poster":"fullaws","content":"C is correct, add autoscaling will help to handle increase of traffic request"},{"comment_id":"144487","poster":"shputhan","timestamp":"1633988100.0","content":"Ans is C. The requirement states cost must be reduced. \nA - while lambda may reduce cost in run, no details on effort required in changing application & feasibility.\nB- The question mention slowness in processing jobs which indicates load. Again no mention of application using L4/L7.\nC. Auto scaling can reduce cost and improve reliability.\nD. Increasing size means more congestion when a EC2 fails.","upvote_count":"1"},{"upvote_count":"1","content":"Its for sure C as the issue is with EC2 instance failure. For making all instances scale up or down can be done by Autoscaling. Changing the load balancer is also an option but the scenario here is different and limited to opt only one choice.","timestamp":"1633967820.0","poster":"Anila_Dhharisi","comment_id":"141725"},{"upvote_count":"1","content":"C acceptable","timestamp":"1633919820.0","poster":"noisonnoiton","comment_id":"137717"},{"comment_id":"134382","poster":"NikkyDicky","timestamp":"1633852560.0","upvote_count":"1","content":"C most likely"},{"comment_id":"132185","timestamp":"1633812840.0","content":"Answer: C\nA - incorrect - question states \"slow\" processing, which could indicate lengthy processing times (e.g. > 15min is possible, which Lambda can't handle). Maybe the average run time for a request is 1 hour - not enough info. Would also need code changes - costly. No suggestion that the EC2 application can run on Lambda. \nB - incorrect - doesn't state the \"application\" tier uses HTTP/HTTPS. Might be a layer 4 app (TCP-based) given its an application tier. Not enough info.\nC - correct - for instance 16 x m4.large instances - better reliability, cheaper when scaling, distribute load better - less users affected by a single instance outage. Change autoscaling config to scale up/down as needed to reduce costs. No additional code changes required thus saving costs\nD - incorrect - worst option, more eggs(users) in one basket, if the basket falls - unhappy users. Plus its a fixed number of hosts, no cost savings","upvote_count":"3","poster":"inf"},{"comment_id":"118730","timestamp":"1633776960.0","poster":"chicagomassageseeker","content":"Answer B: The key is \"report very slow processing of their requests\".\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/classic/config-conn-drain.html","upvote_count":"1"},{"comments":[{"upvote_count":"1","comment_id":"94146","timestamp":"1633588560.0","content":"I changed my answer, It is C","poster":"Ibranthovic"}],"upvote_count":"1","comment_id":"93273","timestamp":"1633548420.0","poster":"Ibranthovic","content":"For me, the problem is related to the classic Load Balancer, and should be replaced by ALB\nI will go with B"},{"timestamp":"1633531620.0","upvote_count":"2","comment_id":"91641","poster":"JAWS1600","content":"It is simpler than what we all have been talking about. Let us look at the requirements 1. reliability and 2. Cost. Look at each of the options. After comparing all - C has these qualities. By using smaller instance we are optimizing the cost by running the compute and by attaching it to ASG ( There is no additional charge for AWS Auto Scaling. ) we will increase reliability and also scale down the env by running what is minimally required. So the net result is reduced cost and increased reliability."},{"poster":"virtual","comment_id":"60804","timestamp":"1633266120.0","upvote_count":"2","content":"I think it's C (Auto-Scaling). Regarding cnx draining, it would be a too tricky question then ..."},{"timestamp":"1633260840.0","poster":"Averageguy","content":"Think simple: \n\n1 . Maximize reliability => increase High availability => Auto Scaling \n2. Minimize cost => Need Elasticity => Auto Scaling\n\nC is my final answer.","upvote_count":"8","comment_id":"54006"},{"comment_id":"49765","timestamp":"1633031400.0","comments":[{"content":"Also, users report slow processing not failed. If an instance failed and the CLB routed to that instance (which it wouldn't bc of the health check) it would result in a failed request not a slow one. \"slow\" indicates load usually.","upvote_count":"1","poster":"AWSPro24","timestamp":"1633174140.0","comment_id":"49766"}],"poster":"AWSPro24","upvote_count":"8","content":"I think donathon is feeding people bad answers. Either he's not knowledgeable or works for AWS and is trying to spread disinformation. How is connection draining related to the fact that a single failed instances causes degraded performance? You say there is no indication it is a load issue but how can it not be a load issue when only a single failure causes performance degradation. That sounds like the definition of a load issue to me and so Autoscaling is what is needed to adjust to both instance failures and fluctuating demand. Autoscaling also automatically replaces failed instances.. which would solve your single failure issue as well. https://aws.amazon.com/ec2/autoscaling/faqs/#Replacing_Impaired_Instances\n\nC should be the answer."},{"upvote_count":"1","comment_id":"17635","poster":"TechGuru","content":"I Support A, because the requirement here to have design change with lost cost, so just changing ELB to ALB may not fit for the requirement.","comments":[{"content":"The cost of ALB is lower than ELB.\nMost importantly though, COST.\nApplication Load Balancers cost $0.0252 per hour.\nClassic Load Balancers cost $0.028 per hour\nbut it gets higher than this ..\nAWS have changed the way they bill on the ALB and have added a new unit, LCU (Load Balancer Capacity Units) which uses the highest values of the following metrics:\n1. New connections (per second)\n2. Active connections (per minute)\n3. Bandwidth (Mbps)\nSo, the calculation becomes a little bit more complex… I’ll show you how we worked it through at CognitoIQ.\nApplication Load Balancer = $0.0252/h * 24 hours * 5 ALBs = $3.02 per day\nClassic Load Balancer = $0.028 p/h * 24 hours * 50 ELBs = $33.60 per day\nI do agree on B.","upvote_count":"3","timestamp":"1632928680.0","poster":"G3","comments":[{"upvote_count":"1","comment_id":"76456","content":"I don't think AWS expects such cost analysis. I am not sure about the calculation. Check out calculator.aws instead.","timestamp":"1633294680.0","poster":"Smart"}],"comment_id":"19946"}],"timestamp":"1632674220.0"},{"comment_id":"15697","content":"The fact that \"By default, connection draining is enabled for Application Load Balancers but must be enabled for Classic Load Balancers\" means that you don't need to redesign the solution. You just need\nto enable connection draining on the CLB. \n\nDisabled connection draining will result on failed request as described in the article:\n\"Imagine each broken connection as a half-drawn web page, an aborted file download, or a failed web service call, each of which results in an unhappy user or customer.\"\n\nThe questions states that \" users report very slow processing of their requests\". I don't think that a disabled connection draining will result in slow processing requests. The\nrequests won't be processed at all or will be partially processed. This has to do with performance and serverless was developed for better performance. I would choose A.","poster":"Marcos","timestamp":"1632619740.0","upvote_count":"4"},{"upvote_count":"4","timestamp":"1632571860.0","comment_id":"14009","comments":[{"timestamp":"1635649380.0","upvote_count":"1","poster":"DerekKey","comment_id":"413075","content":"Moon - how a change of load balancer type can impact processing after one instance fails? Both will do equal routing especially when we have the same instance types.\nThe simplest answer is C. It also minimizes cost.\nregarding A - The question asks for recommended design changes for an existing environment to maximize reliability. Nothing more."}],"content":"Support answer \"B\".\nA: there is no enough information that this solution can be used.\nC/D: there is no evidence that the issue is from EC2 sizing.","poster":"Moon"},{"upvote_count":"3","timestamp":"1632273900.0","content":"It looks like a bad test question.\nThe link content has the benefit of alb migration\nbut the evidence is poor. \n\"Amazon S3 as a persistent data store\". It seems easy to implement auto scaling.\n\nC if reliability is important, B if costs are more important. OTL\n\n#Benefits of Migrating from a Classic Load Balancer\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html\n#Details for Elastic Load Balancing Products\nhttps://aws.amazon.com/elasticloadbalancing/features/","poster":"awsgcpazure","comment_id":"11515","comments":[{"timestamp":"1633980240.0","upvote_count":"1","content":"C can also help with costs, if the resources are under-utilized at specific times, ASG will consume less than the current $$$","comment_id":"143827","poster":"MultiAZ"}]},{"poster":"Xiaoyao2000","upvote_count":"2","comments":[{"comments":[{"timestamp":"1632358320.0","content":"nvm, autoscaling","poster":"dpvnme","comment_id":"11692","upvote_count":"1"}],"comment_id":"11691","upvote_count":"1","poster":"dpvnme","timestamp":"1632317220.0","content":"C doesn't say how many instances so B would still be best"}],"timestamp":"1632237360.0","content":"Shouldn't be C?","comment_id":"11164"}],"answer":"C"},{"id":"WNTyzYOe9zRYHQWPITvx","isMC":true,"unix_timestamp":1568473200,"answer_description":"","exam_id":32,"answer_images":[],"timestamp":"2019-09-14 17:00:00","discussion":[{"timestamp":"1632247620.0","content":"LEAST impcat on the Operations staff after the migration.\n\nA. Need to be managed by Operations staff\nB. ES data can not be used as source for DMS. It can be used as target.\nC. Need to be managed by Operations staff\nD. Company has 10GB DX, so migration can be done done within 48 hours. \n\nAnswer is D","poster":"arunkumar","comment_id":"34842","comments":[{"timestamp":"1632513720.0","comment_id":"76469","poster":"Smart","content":"Perfect!","upvote_count":"2"},{"comments":[{"content":"Elastic Beanstalk is a managed service by AWS, it's meant for developers so that they can easily deploy their app to AWS without having near to zero knowledge of AWS on how to manage stuffs, because AWS will do the management of beanstalk","poster":"DeathFrmAbv","upvote_count":"2","timestamp":"1635921660.0","comment_id":"403591"}],"timestamp":"1635865080.0","upvote_count":"1","content":"Who will manage the Elastic Beanstalk environment?\nSince operations staff manages VMs, they can manage EC2. But learning about Elastic Beanstalk??","poster":"DashL","comment_id":"393240"}],"upvote_count":"50"},{"upvote_count":"25","content":"Can't be B as AWS DMS supports Elasticsearch as a target, not a source","poster":"johannes756","comment_id":"26953","timestamp":"1632212580.0"},{"poster":"SkyZeroZx","timestamp":"1687379580.0","content":"Selected Answer: D\nLEAST impcat on the Operations staff after the migration.\n\nA. Need to be managed by Operations staff\nB. ES data can not be used as source for DMS. It can be used as target.\nC. Need to be managed by Operations staff\nD. Company has 10GB DX, so migration can be done done within 48 hours.","comment_id":"929899","upvote_count":"1"},{"content":"Selected Answer: B\nB is correct\nYou can use DMS to replicate ES \nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Elasticsearch.html","timestamp":"1681233060.0","poster":"dev112233xx","upvote_count":"1","comment_id":"867511"},{"poster":"unknownUser22952","content":"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Elasticsearch.html\n\nB is the right answer. ElasticSearch is now renamed to OpenSearch","comment_id":"798314","timestamp":"1675540200.0","upvote_count":"2"},{"content":"Selected Answer: D\nBased on all comments","comment_id":"685676","poster":"dmscountera","upvote_count":"1","timestamp":"1664815080.0"},{"content":"Selected Answer: D\nES not supported as source in DMS","timestamp":"1663315080.0","comment_id":"670594","poster":"Dionenonly","upvote_count":"1"},{"timestamp":"1661957760.0","comment_id":"655210","poster":"Sizuma","content":"B FOR SURE","upvote_count":"1"},{"content":"D - It doesn't talk about ES current 1TB data migration to AWS just an Index...???","timestamp":"1638920340.0","poster":"vbal","upvote_count":"2","comments":[{"comment_id":"679302","upvote_count":"1","timestamp":"1664151480.0","poster":"tomosabc1","content":"A valid point. I am confused with the same question."}],"comment_id":"496397"},{"timestamp":"1636285920.0","content":"It's D","poster":"andylogan","comment_id":"451148","upvote_count":"1"},{"timestamp":"1636228800.0","content":"I'll go with D","poster":"WhyIronMan","upvote_count":"2","comment_id":"409603"},{"comment_id":"406680","content":"D Correct","poster":"Akhil254","timestamp":"1635947400.0","upvote_count":"2"},{"upvote_count":"1","poster":"blackgamer","content":"I will go with D.","comment_id":"344992","timestamp":"1635817560.0"},{"poster":"Waiweng","upvote_count":"3","timestamp":"1635698040.0","comment_id":"344396","content":"It's D"},{"upvote_count":"3","content":"Which strategy will have the LEAST impact on the Operations staff after the migration?\n\nA- Will require management of EC2 nodes for ES post migration\nB- ES cant be source for DMS as it can be only a target\nC- ec2 VMs will be required to manage post migration\nD- Correct Answer","poster":"Amitv2706","comment_id":"333686","timestamp":"1635469140.0"},{"timestamp":"1635464400.0","poster":"ajeeshb","comment_id":"308818","upvote_count":"2","content":"Answer: D.\nIndex snapshots are a popular way to migrate from a self-managed Elasticsearch cluster to Amazon Elasticsearch Service.\nRefer: https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/migration.html"},{"poster":"rosebank","upvote_count":"1","timestamp":"1635311220.0","content":"so, which is the correct answer in the exam, B or D?","comment_id":"297070"},{"timestamp":"1635284940.0","poster":"Kian1","comment_id":"290297","upvote_count":"3","content":"will go with D"},{"timestamp":"1635060240.0","content":"No to A & C: No ES cluster. No DMS source for ES. That leaves D. The time window of 48 hours aligns with 1TB size and 10 GB band width. I ll go with D","poster":"bnagaraja9099","comment_id":"285100","upvote_count":"2"},{"comment_id":"282629","content":"This is easy, minimum overhead for staff means AWS ES, so answer is either B or D\nDMS does not support ES as source, so B ruled out \nAnswer is D","upvote_count":"7","timestamp":"1634955360.0","poster":"Ebi"},{"timestamp":"1634457600.0","comments":[{"timestamp":"1663489080.0","poster":"Azerty1313","comment_id":"672119","upvote_count":"1","content":"I agree. The others are probably new technologies for the Ops team."}],"comment_id":"269743","content":"The question is \"LEAST impact on the Operations staff after the migration\" - this is Lift&Shift.\nOption C","upvote_count":"3","poster":"rasti"},{"comments":[{"content":"True. Answer is D","upvote_count":"1","poster":"ajeeshb","timestamp":"1635380220.0","comment_id":"308817"}],"content":"I read through all comments and agrees that B sounds compelling but the truth is to migrate on prem ES to AWS ES the index snapshot is the only way quoting to this link: https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/migration.html\n\nSo B is out and D sounds to be the most accurate answer.","timestamp":"1634436960.0","comment_id":"261996","upvote_count":"3","poster":"elf78"},{"upvote_count":"2","comment_id":"242466","poster":"T14102020","timestamp":"1634362140.0","content":"Correct is D. AWS Elastic Beanstalk least operational stuff"},{"comment_id":"240878","content":"I still prefer C .. but will go with D as the majority seem to be doing .... although it could be B ... This is just one of those questions well never be sure of the correct answer and should just move on ...","timestamp":"1634295780.0","comments":[{"content":"Red herring?","poster":"shammous","comment_id":"279848","upvote_count":"1","timestamp":"1634948400.0"}],"upvote_count":"1","poster":"petebear55"},{"comment_id":"230018","poster":"jackdryan","timestamp":"1634248200.0","upvote_count":"3","content":"I'll go with D"},{"comments":[{"upvote_count":"1","poster":"shammous","comment_id":"279846","timestamp":"1634522520.0","content":"You don't need to pause before replication with SMS as it will automatically replicate volumes of live servers. This make Option C more legitimate."}],"content":"Answer is D. There is a 48 hour change window and therefore it makes sense to pause the data sources from populating the ES VM before any migration/replication activity can begin. Only Option D does that. Option C is the next closet in terms of least operational impact but it doesn't pause before replication using SMS. Option B won't work as ES is not an eligible source for DMS. Option A has the most operational impact as it is a customer managed option. So given the above rationale, the correct answer is D. It has the least impact post migration since its a managed infrastructure for ES and web app.","timestamp":"1634245680.0","upvote_count":"3","comment_id":"229172","poster":"Bulti"},{"timestamp":"1634243520.0","comment_id":"228629","upvote_count":"1","content":"To the people who would go for B: \"Use AWS DMS to replicate Elasticsearch data.\" Can you tell me how? lol\nAnswer is D for sure.","poster":"ting_66"},{"comment_id":"226708","upvote_count":"1","timestamp":"1634235300.0","poster":"lostri","content":"I vote for D"},{"comments":[{"content":"Sorry D has same statement, so ...","timestamp":"1634200560.0","comment_id":"208322","poster":"saddly","upvote_count":"1"}],"content":"data source feeds from local systems that will not be migrated\nSo B is not valid by moving the feed to new end point.","comment_id":"208321","timestamp":"1633957980.0","upvote_count":"1","poster":"saddly"},{"poster":"sam422","comment_id":"187326","timestamp":"1633850700.0","upvote_count":"3","content":"I go with B, this has least operational overhead \nAWS ES cluster to migrate Elastic search\nAWS Beanstalk for web application\nUse DMS to replicate elastic search data\n\nOPTION C: Doesn't mention how Elastic search is migrated. SMS migrates VM but not elastic search data.\nOPTION D: This is operation overhead, export and import of ES index data\nOPTION A: not a friendly setup"},{"content":"I go with B, this has least operational overhead \nAWS ES cluster to migrate Elastic search\nAWS Beanstalk for web application\nUse DMS to replicate elastic search data\n\nOPTION C: Doesn't mention how Elastic search is migrated. SMS migrates VM but not elastic search data.\nOPTION D: This is operation overhead, export and import of ES index data\nOPTION A: not a friendly setup","timestamp":"1633836480.0","poster":"sam422","upvote_count":"3","comment_id":"187324"},{"poster":"exergeng","comment_id":"184895","content":"The web servers and ES server are in virtual machines in on premise environment, but which type of virtual technology is not mentioned.\nhttps://docs.aws.amazon.com/server-migration-service/latest/userguide/SMS_setup.html\nFor now ,only Vmware,Hyper-V are supported. \nThus , no support for KVM/XEN/VIRTUALBOX and so on.\nChoose D.","upvote_count":"1","timestamp":"1633789680.0"},{"poster":"Ganfeng","upvote_count":"3","content":"D is my pick. \nFor C, when import via SMS, virtually we are created the self managed ES which I don't like, similarly to the Web app","timestamp":"1633662540.0","comment_id":"174900"},{"comment_id":"174833","content":"It D. between C & D, always going for managed service would be the rule of thumb in aws exams","timestamp":"1633542900.0","upvote_count":"5","poster":"hailiang"},{"content":"C is correct because of LEAST impact on Operation Staff after migration. DMS cannot support source from elasticsearch(nosql). If it is LEAST operation workload after migration, will go for D.","upvote_count":"1","poster":"fullaws","comment_id":"149547","timestamp":"1633345800.0","comments":[{"poster":"ipindado2020","timestamp":"1633745760.0","upvote_count":"3","comment_id":"182653","content":"\"LEAST impact on Operation Staff after migration\" means managed...so better managed services as AWS ES and AWS Beanstalk instead of managin AWS EC2 instances....\n\nThat leaves D..."}]},{"poster":"NikkyDicky","timestamp":"1632873420.0","upvote_count":"2","content":"D - min ops for managed service. B is wrong as DMS doesn't support ES source","comment_id":"132254"},{"poster":"chicagomassageseeker","timestamp":"1632731220.0","content":"Dont get caught up in Ealstic Search world. Onpremise is just an elastic search VIRTUAL MACHINE. This needs \"rehosting\" along with the other 3 VMS. Just use AWS Server Migration Service which is specially designed for Rehosting and does VM migrations.","upvote_count":"1","comment_id":"118800"},{"poster":"chicagomassageseeker","upvote_count":"1","content":"For sure not B. DMS cannot replicate ES data. I go with C. \nWe have 4 virtual machines. Elasticsearch virtual machine+3Apache Tomcat . Use SMS to migrate these Virtual Machines.\nEntire OS is kept in tact in these VMS and you can turn and use them after mingration. This is an example of rehosting.","comment_id":"118792","timestamp":"1632728460.0"},{"timestamp":"1632693780.0","poster":"Abramelin","comment_id":"116605","comments":[{"poster":"sami777","upvote_count":"1","comment_id":"133993","comments":[{"poster":"Phat","comment_id":"173107","upvote_count":"2","timestamp":"1633536180.0","content":"the link said ES is a target, not source.","comments":[{"timestamp":"1633895040.0","poster":"cpd","content":"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.html","comment_id":"205167","upvote_count":"2"}]}],"timestamp":"1633013220.0","content":"https://aws.amazon.com/blogs/database/introducing-amazon-elasticsearch-service-as-a-target-in-aws-database-migration-service/"}],"upvote_count":"6","content":"Guys Ive searched and searched and I can’t find anything that says DMS can use ES as a source!"},{"comment_id":"116240","timestamp":"1632646680.0","upvote_count":"1","poster":"sara_an","content":"ANS B: https://aws.amazon.com/blogs/database/introducing-amazon-elasticsearch-service-as-a-target-in-aws-database-migration-service/#:~:text=Using%20AWS%20DMS%20to%20migrate,or%20an%20Amazon%20S3%20bucket.\n\nWe’re excited to announce the addition of a new target in AWS Database Migration Service (AWS DMS)—Amazon Elasticsearch Service. You can now migrate data to Amazon Elasticsearch Service from all AWS DMS–supported sources. With support for this new target, you can use DMS in your data integration pipelines to replicate data in near-real time into Amazon Elasticsearch Service."},{"upvote_count":"2","content":"a - need maintenance of ec2 instances\nb - DMS doesn't support ES as source\nc - before replicating the data source feeds needs to be paused and also needs management of instances in future\nd - correct","timestamp":"1632548040.0","poster":"JohnyGaddar","comment_id":"97881"},{"poster":"JAWS1600","comment_id":"95636","upvote_count":"1","content":"B . DMS is the right way to migrate Elasticsearch\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Elasticsearch.html","timestamp":"1632533400.0"},{"poster":"Joeylee","comment_id":"76194","upvote_count":"3","content":"I would go with C re-host. Others require Ops to learn a lot of staff. Then impact them. Service interrupt is not a issue in the question","timestamp":"1632458460.0"},{"poster":"sb333","timestamp":"1632331620.0","comments":[{"comments":[{"content":"But the question is about \"after the migration\". Once the migration is initially done and they have used Elastic Beanstalk, future deployments will be less work for operations. These deployments are at LEAST 4 times per year if you include could be patches. That means either B or D. Since Elasticsearch cannot be a SOURCE for DMS, that leaves D as the correct answer.","poster":"LunchTime","timestamp":"1632868320.0","comment_id":"119675","upvote_count":"3"}],"upvote_count":"5","timestamp":"1632332700.0","comment_id":"46732","content":"i.e. Lift-and-Shift - valid solution for AWS and one that you need to know for the exam.","poster":"sb333"}],"content":"C\nLeast impact to Operations staff translates into having the most like-for-like that they are used to. Changing to use AWS ES and Beanstalk is an impact to Operations. It changes the way they support the solution. There is nothing wrong with migrating as-is if it meets the overall goal. In this case, it's causing the LEAST impact (i.e. keeping things as they are with current Processes and Procedures, etc).","upvote_count":"8","comment_id":"46728"},{"timestamp":"1632329700.0","comments":[{"comment_id":"57743","timestamp":"1632402000.0","upvote_count":"4","content":"says \"to elastic search\" not from","poster":"mandrakenet"},{"comment_id":"157945","poster":"Stec1980","content":"ES is a supported target, not source...","timestamp":"1633465380.0","upvote_count":"4"}],"poster":"olg","content":"DMS actually supports elasticsearch as a source\nhttps://aws.amazon.com/about-aws/whats-new/2018/08/aws-dms-supports-elasticsearch-kinesis-datastreams/","comment_id":"45832","upvote_count":"1"},{"timestamp":"1632256200.0","comments":[{"poster":"newme","content":"As a target not source","upvote_count":"1","timestamp":"1634390820.0","comment_id":"245302"}],"poster":"sa2020","content":"Using AWS DMS to migrate your data to ES\nAWS DMS can do a one-time data migration, or it can do a continuous replication of the data from any of our supported sources to an Amazon ES target. These sources include relational databases (such as Oracle and Amazon Aurora), a NoSQL database (MongoDB), or an Amazon S3 bucket\n\nhttps://aws.amazon.com/blogs/database/introducing-amazon-elasticsearch-service-as-a-target-in-aws-database-migration-service/","comment_id":"43347","upvote_count":"1"},{"upvote_count":"7","comment_id":"29102","timestamp":"1632229860.0","poster":"9Ow30","content":"Question asked for LEAST impact on the Operations staff after the migration\n\nI think this is saying less learning curve for ops staff after the migration. Elasticbeanstalk will be a new thing for ops. So , I am more inclined towards SMS migration option"},{"comments":[{"comment_id":"26954","upvote_count":"2","poster":"johannes756","timestamp":"1632221340.0","content":"D\nPause, replicate, resume makes sure you get changes since replication started."}],"timestamp":"1632210780.0","content":"I support answer \"B\". The key point of the question is that, \"LEAST operation staff after migration\". This means, use as much as AWS automated services as possible.\nBest, in this question is to use: ES & EB - Elastic Search and Elastic Beanstalk.\n\nA: uses EC2s, and that requires maintenance after the migration. contradicting with least operation after migration.\nC: Good, but again uses self Elastic Search and EC2s, which requires operation maintenance staff after migration.\nD: the sequence of moving the index to ES is wrong. They should have replicate then pause! However, answer \"B\" uses DMS as a replication tool.\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Elasticsearch.html\nhttps://aws.amazon.com/blogs/database/introducing-amazon-elasticsearch-service-as-a-target-in-aws-database-migration-service/","poster":"Moon","comment_id":"14002","upvote_count":"7"},{"comment_id":"12709","upvote_count":"9","poster":"donathon","content":"B\nhttps://aws.amazon.com/blogs/database/introducing-amazon-elasticsearch-service-as-a-target-in-aws-database-migration-service/\nA\\C\\D: Require at least 30 minutes downtime.","comments":[{"content":"DMS cannot have the on-prem ES as a source. EX is only target for DMS. \nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.html\nSo B will not work. D is the answer","timestamp":"1633093440.0","upvote_count":"8","poster":"MultiAZ","comment_id":"143823"},{"content":"Why is this being upvoted? Where in the question does it say anything about only having 30 minutes of downtime. In fact it says we have 48 hours.","comment_id":"49740","timestamp":"1632356640.0","poster":"AWSPro24","upvote_count":"16"},{"poster":"consultsk","upvote_count":"1","timestamp":"1634416800.0","content":"AWSPro24 thoughts seem correct. Do you want to re-evaluate your thoughts? - D is more appropriate and correct.","comment_id":"252630"}],"timestamp":"1632165840.0"},{"comment_id":"12665","upvote_count":"2","poster":"awsec2","timestamp":"1632144120.0","content":"sorry b"},{"poster":"awsec2","upvote_count":"3","timestamp":"1632136020.0","content":"i prefer c","comment_id":"11077"}],"answer_ET":"D","answer":"D","topic":"1","question_id":415,"url":"https://www.examtopics.com/discussions/amazon/view/5166-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"A":"Create an Elasticsearch server on Amazon EC2 right-sized with 2 TB of Amazon EBS and a public AWS Elastic Beanstalk environment for the web application. Pause the data sources, export the Elasticsearch index from on premises, and import into the EC2 Elasticsearch server. Move data source feeds to the new Elasticsearch server and move users to the web application.","B":"Create an Amazon ES cluster for Elasticsearch and a public AWS Elastic Beanstalk environment for the web application. Use AWS DMS to replicate Elasticsearch data. When replication has finished, move data source feeds to the new Amazon ES cluster endpoint and move users to the new web application.","D":"Create an Amazon ES cluster for Elasticsearch and a public AWS Elastic Beanstalk environment for the web application. Pause the data source feeds, export the Elasticsearch index from on premises, and import into the Amazon ES cluster. Move the data source feeds to the new Amazon ES cluster endpoint and move users to the new web application.","C":"Use the AWS SMS to replicate the virtual machines into AWS. When the migration is complete, pause the data source feeds and start the migrated Elasticsearch and web application instances. Place the web application instances behind a public Elastic Load Balancer. Move the data source feeds to the new Elasticsearch server and move users to the new web Application Load Balancer."},"question_images":[],"question_text":"An on-premises application will be migrated to the cloud. The application consists of a single Elasticsearch virtual machine with data source feeds from local systems that will not be migrated, and a Java web application on Apache Tomcat running on three virtual machines. The Elasticsearch server currently uses 1 TB of storage out of 16 TB available storage, and the web application is updated every 4 months. Multiple users access the web application from the Internet. There is a 10Gbit AWS Direct Connect connection established, and the application can be migrated over a scheduled 48-hour change window.\nWhich strategy will have the LEAST impact on the Operations staff after the migration?","answers_community":["D (75%)","B (25%)"]}],"exam":{"isBeta":false,"name":"AWS Certified Solutions Architect - Professional","isImplemented":true,"id":32,"lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":false,"numberOfQuestions":1019},"currentPage":83},"__N_SSP":true}