{"pageProps":{"questions":[{"id":"jmek32aXfMpsAOMtcxPh","topic":"1","answer_images":[],"question_text":"A company has an AWS CodePipeline pipeline that is configured with an Amazon S3 bucket in the eu-west-1 Region. The pipeline deploys an AWS Lambda application to the same Region. The pipeline consists of an AWS CodeBuild project build action and an AWS CloudFormation deploy action.\nThe CodeBuild project uses the aws cloudformation package AWS CLI command to build an artifact that contains the Lambda function code’s .zip file and the CloudFormation template. The CloudFormation deploy action references the CloudFormation template from the output artifact of the CodeBuild project’s build action.\nThe company wants to also deploy the Lambda application to the us-east-1 Region by using the pipeline in eu-west-1. A DevOps engineer has already updated the CodeBuild project to use the aws cloudformation package command to produce an additional output artifact for us-east-1.\nWhich combination of additional steps should the DevOps engineer take to meet these requirements? (Choose two.)","url":"https://www.examtopics.com/discussions/amazon/view/105247-exam-aws-certified-devops-engineer-professional-dop-c02/","unix_timestamp":1680665100,"isMC":true,"question_images":[],"timestamp":"2023-04-05 05:25:00","discussion":[{"poster":"madperro","timestamp":"1686381600.0","comment_id":"919863","content":"Selected Answer: CE\nAs below. You need S# bucket in the new region so C. You need to output artifacts to this new bucket so E.\nhttps://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html","upvote_count":"19"},{"upvote_count":"2","poster":"Priyank1912","timestamp":"1742764260.0","content":"Selected Answer: BC\nB and C are the right option","comment_id":"1406304"},{"comment_id":"1317206","content":"Selected Answer: CE\nArtifact bucket is needed in the deployment region","poster":"steli0","upvote_count":"1","timestamp":"1732479600.0"},{"upvote_count":"1","poster":"Ravi_Bulusu","timestamp":"1731859140.0","content":"The Answer is : AB\nTo deploy to a different region, the CloudFormation template should be flexible enough to accept a parameter for the Lambda function’s zip file location. This allows the template to be reused in both regions. The new CloudFormation action in us-east-1 should reference this parameter and pass in the appropriate location of the artifact for that region\nAfter the CodeBuild project outputs artifacts for both eu-west-1 and us-east-1, you need a separate CloudFormation deploy action in the pipeline that targets the us-east-1 region. This action should reference the CloudFormation template from the us-east-1 output artifact produced by the CodeBuild step.","comment_id":"1313644"},{"timestamp":"1721892720.0","poster":"jamesf","content":"Selected Answer: CE\nCE\nNot D because \"A DevOps engineer has already updated the CodeBuild project to use the aws cloudformation package command to produce an additional output artifact for us-east-1\"\n\nhttps://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html","comment_id":"1254808","upvote_count":"1"},{"poster":"shammous","upvote_count":"1","comments":[{"upvote_count":"1","content":"A: It suggests pointing directly to the Lambda function but we also need the Cloudformation template. So we can rule option A out.\nB: Here, we are missing the new region (us-east-1) artifact store where the new Cloudformation deploys action would store the artifacts upon completion.\nE: Includes the missing part in option B and is the right answer.\nD: \"A DevOps engineer has already updated the CodeBuild project to use the AWS CloudFormation package command to produce an additional output artifact for us-east-1.\" So as we are directly producing the artifact in the S3 bucket in us-east-1, I don't see the point of having a cross-replication.\nC: This option is mandatory as we should provide permissions to services (CodePipeline) to access resources (S3 bucket).","poster":"shammous","timestamp":"1721890260.0","comment_id":"1254781"}],"comment_id":"1254779","content":"C and E are the right answers.","timestamp":"1721890200.0"},{"timestamp":"1716830100.0","upvote_count":"1","poster":"ihustle","comments":[{"upvote_count":"1","comment_id":"1219715","content":"Apologies, I meant C and E.","timestamp":"1716830160.0","poster":"ihustle"}],"content":"B and C are the answers. \nThe two important things to note here are the use of AWS CLI and artifacts from two different regions.","comment_id":"1219712"},{"upvote_count":"1","poster":"kyuhuck","comment_id":"1154405","timestamp":"1708392600.0","content":"Selected Answer: AB\na/b correct\na: the cloudformation template should be modified to incllude a parameter that indicates the location of the.zip file containing the lambda function's cod, this allows the cloudformation deploy action to use the correct artifact depending on the region, this is critical because lambda functions needto reference their code artifacts form the same region they are being deployed in, b. you tould also need to create a new cloudformation deploy action fro the us-east-1 region within the pipelinem this action should be confiured to use the cloudformation template from the artiface that was sepcifically created for us-eat-1"},{"timestamp":"1706512380.0","comment_id":"1134704","poster":"thanhnv142","upvote_count":"4","content":"C and E are correct: To achieve the goal. we need an empty S3 in the us-east-1 and create additional stage in the pipline\nA: No mention of S3 - incorrect\nB: no mention of S3 - incoorect\nD: we need an empty S3 to store artifact, Cross-Region Replicate incurs more unnecessary cost. Additionally, this way force the S3 in us-east-1 to be exactly like that of us-west-1, which is incorrect. Each S3 has a different set of artifacts (though they might be very similar)"},{"content":"Why C and not D?","comments":[{"upvote_count":"2","content":"\"A DevOps engineer has already updated the CodeBuild project to use the aws cloudformation package command to produce an additional output artifact for us-east-1\"","comment_id":"1248557","poster":"tgv","timestamp":"1721074200.0"}],"timestamp":"1704580680.0","upvote_count":"1","comment_id":"1115481","poster":"Bans"},{"upvote_count":"1","content":"https://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html#actions-create-cross-region-cfn\nCE is my answers","timestamp":"1702565940.0","poster":"DucSiu","comment_id":"1096577"},{"comment_id":"1073743","timestamp":"1700269200.0","upvote_count":"1","poster":"learnwithaniket","content":"For CloudFormation you need to add the Region parameter: https://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html#actions-create-cross-region-cfn"},{"poster":"robertohyena","timestamp":"1699875960.0","content":"Selected Answer: CE\nAnswers: C E\nScenario:\n- We have Pipeline in RegionA (eu-west-1 Region)\n- We have Deploy action in RegionA (eu-west-1 Region)\nRequirements:\n- Need to have Deploy to RegionB (us-east-1 Region)\n- And still use RegionA pipeline above (eu-west-1 Region)","upvote_count":"3","comments":[{"poster":"robertohyena","content":"Which combination of additional steps to meet requirements:\n- Create bucket in RegionB (us-east-1 Region) [artifact store] This will be the OutputArtifact bucket for Deploy action in RegionB (us-east-1 Region)\n- Add a cross-Region action to a pipeline (CLI)\n-- Described in step #3 \"Modify the pipeline to include the S3 bucket for us-east-1 as an artifact store.\" \n-- Described in step #2 \"Create a new CloudFormation deploy action for us-east-1 in the pipeline.\" and \"Configure the new deploy action to use the CloudFormation template from the us-east-1 output artifact.\"\n\nREF: https://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html#actions-cross-region-cli\n\nINCORRECT\n- A B cannot be a \"combination of steps\". They both have \"Create a new CloudFormation deploy action for us-east-1 in the pipeline.\"\n- D - we do not need S3 Cross-Region Replication (CRR) in the solution.","timestamp":"1699876020.0","upvote_count":"2","comment_id":"1069255"}],"comment_id":"1069254"},{"timestamp":"1699073160.0","comments":[{"upvote_count":"3","timestamp":"1703051280.0","comment_id":"1101275","content":"we are not using codedeploy","poster":"z_inderjot"}],"comment_id":"1061900","content":"A and B is the answer. Anything related to create S3 is wrong since Code Deploy have ability to automatically share artifacts to other regions","poster":"2pk","upvote_count":"1"},{"comment_id":"1060870","poster":"zain1258","timestamp":"1698956880.0","upvote_count":"3","content":"Selected Answer: CE\nC & E are correct options"},{"timestamp":"1698922140.0","content":"Would go for CE","comment_id":"1060482","upvote_count":"1","poster":"denccc"},{"poster":"DZ_Ben","timestamp":"1698747180.0","comment_id":"1058673","upvote_count":"1","content":"It should be BC! In order to do cross-region deployment, we should create two s3 for each region for ArtifactStore. Then CodeBuild should bundle the sam template and upload to each bucket. Finally CodePipeline should have two separate action for Cloudformation deployment, and each deployment has a region attribute to be defined and needs to pull the template from the ArtifactStore respectively."},{"comments":[{"timestamp":"1716231540.0","upvote_count":"1","content":"That link also says if you are using Cloudformation or CLI then you have to provide the buckets. So C and E","poster":"Cappy46789","comment_id":"1214565"}],"poster":"kacsabacsi78","content":"Selected Answer: AB\nC, D and E answers are wrong. CodePipeline automatically creates an S3 bucket in the cross-region for the artifacts. CodePipeline handles the copying of artifacts from one AWS Region to the other Regions when performing cross-region actions.\nhttps://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html","timestamp":"1697639700.0","comment_id":"1047000","upvote_count":"2"},{"comment_id":"1027735","timestamp":"1696742580.0","poster":"Mohammed_Elsabaa","upvote_count":"1","content":"CE\nyou need to create s3 bucket to set it as output artifact for code build \ncode build can have one source and 5 output artifacts"},{"timestamp":"1693080060.0","comment_id":"991020","content":"Selected Answer: CE\nCE seems correct","upvote_count":"2","poster":"Skshitiz"},{"timestamp":"1690871460.0","upvote_count":"2","comment_id":"968783","content":"Selected Answer: CE\nCE \nWorks well","poster":"vherman"},{"upvote_count":"1","comment_id":"933431","timestamp":"1687686240.0","poster":"FunkyFresco","content":"Selected Answer: AB\nThe correct answer is A and B."},{"timestamp":"1687589220.0","poster":"Jeb","comment_id":"932273","upvote_count":"1","content":"The correct answer is CE"},{"timestamp":"1687206240.0","poster":"tartarus23","comment_id":"927892","content":"Selected Answer: AB\nExplanation:\n\nA. The CloudFormation template should be modified to include a parameter that indicates the location of the .zip file containing the Lambda function's code. This allows the CloudFormation deploy action to use the correct artifact depending on the region. This is critical because Lambda functions need to reference their code artifacts from the same region they are being deployed in.\n\nB. You would also need to create a new CloudFormation deploy action for the us-east-1 Region within the pipeline. This action should be configured to use the CloudFormation template from the artifact that was specifically created for us-east-1.","upvote_count":"1"},{"comment_id":"911188","poster":"rdoty","upvote_count":"1","timestamp":"1685533860.0","content":"It is CE","comments":[{"comment_id":"911189","content":"https://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html#:~:text=You%20must%20have%20created%20the%20following%3A","upvote_count":"1","timestamp":"1685533860.0","poster":"rdoty"}]},{"comment_id":"907045","poster":"qan1257","content":"Selected Answer: AB\nhttps://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html\nC D E are not needed when you use the CodePipeline console","timestamp":"1685076240.0","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"990902","content":"This article specifically says \"When you create or edit a pipeline, you must have an artifact bucket in the pipeline Region and then you must have one artifact bucket per Region where you plan to execute an action. \" Which makes the Artifact S3 bucket in all deploying regions a must.","timestamp":"1693062780.0","poster":"Radeeka"}]},{"content":"C E are correct options as per this AWS link- https://aws.amazon.com/blogs/devops/using-aws-codepipeline-to-perform-multi-region-deployments/\nIt shows that we need one S3 bucket in each region as an Artifact Store.\nThe pipeline should have one deploy action for every region and that will refer the bucket as artifact store for deployment.","upvote_count":"2","poster":"ipsingh","timestamp":"1683992820.0","comment_id":"896855"},{"poster":"ParagSanyashiv","upvote_count":"1","timestamp":"1683540840.0","comment_id":"892002","content":"Selected Answer: AC\nAC makes more sense in this scenario."},{"upvote_count":"1","timestamp":"1681578960.0","poster":"alce2020","content":"To deploy the Lambda application to the us-east-1 Region by using the pipeline in eu-west-1, the DevOps engineer should take the following steps:\n\nCreate a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the us-east-1 output artifact. (Option B)\nModify the CloudFormation template to include a parameter for the Lambda function code’s zip file location. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to pass in the us-east-1 artifact location as a parameter override. (Option A)\nThese two steps will allow the company to deploy the Lambda application to the us-east-1 Region using the pipeline in eu-west-1","comment_id":"871149"},{"content":"Selected Answer: AB\nTo deploy the Lambda application to the us-east-1 region using the existing pipeline in eu-west-1, the DevOps engineer needs to create a new CloudFormation deploy action for us-east-1 and configure it to use the CloudFormation template from the us-east-1 output artifact. Additionally, they need to modify the CloudFormation template to include a parameter for the Lambda function code’s zip file location, and configure the new deploy action to pass in the us-east-1 artifact location as a parameter override.\n\nTherefore, options A and B are both correct. Option C is not necessary because the S3 bucket already exists in the eu-west-1 region. Option D is not necessary since the pipeline only needs to deploy to us-east-1 and not replicate the S3 bucket. Option E is not necessary since the pipeline is already configured to use the S3 bucket in eu-west-1 as an artifact store.","comment_id":"870369","upvote_count":"3","timestamp":"1681493880.0","poster":"jqso234"},{"upvote_count":"3","comment_id":"865706","content":"Selected Answer: AC\nWill have to go with A C\nA- Need to update the CF code to point to the bucket dynamically something like this:\nResources:\n MyLambdaFunction:\n Type: AWS::Lambda::Function\n Properties:\n Code:\n S3Bucket: !GetAtt CodeZipFile.BucketName\n S3Key: !GetAtt CodeZipFile.ObjectKey\nC - Need to add access to codepipeline to retrieve artifacts from codebuild build action.\nD - for sure is wrong no need CRR here each execution has its own artifcats.\nB - Missing cloudformation template changes (CF will still point to eu-west-1)\nE - Will always point to us-east-1 it will replace eu-west-1 with us-east-1 (always).","poster":"asfsdfsdf","timestamp":"1681060920.0"},{"content":"Selected Answer: AD\nLambda requires the bucket to reside in the same AWS Region as the function, but creating a single template that references a single bucket confines your template to a single Region. Replication will provide the .zip in the us-east-1 region. CFN template will be one, and it must be region-agnostic.","comment_id":"864467","poster":"ele","timestamp":"1680935340.0","upvote_count":"3","comments":[{"upvote_count":"1","timestamp":"1685075040.0","comment_id":"907035","content":"D is incorrect.\nCodePipeline handles the copying of artifacts from one AWS Region to the other Regions when performing cross-region actions. So CRR is not need.\nhttps://docs.aws.amazon.com/codepipeline/latest/userguide/actions-create-cross-region.html","poster":"qan1257"}]},{"comment_id":"863139","timestamp":"1680798000.0","upvote_count":"3","poster":"Dimidrol","content":"Selected Answer: CE\nC E for me"},{"poster":"lqpO_Oqpl","comment_id":"861727","upvote_count":"3","timestamp":"1680665100.0","content":"I think A, E"}],"answer_ET":"CE","answer_description":"","answer":"CE","choices":{"C":"Create an S3 bucket in us-east-1. Configure the S3 bucket policy to allow CodePipeline to have read and write access.","A":"Modify the CloudFormation template to include a parameter for the Lambda function code’s zip file location. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to pass in the us-east-1 artifact location as a parameter override.","B":"Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the us-east-1 output artifact.","D":"Create an S3 bucket in us-east-1. Configure S3 Cross-Region Replication (CRR) from the S3 bucket in eu-west-1 to the S3 bucket in us-east-1.","E":"Modify the pipeline to include the S3 bucket for us-east-1 as an artifact store. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the us-east-1 output artifact."},"question_id":146,"answers_community":["CE (65%)","AB (17%)","Other"],"exam_id":23},{"id":"pkLYdnMsCd2buTq8Vvf8","answers_community":["CEF (93%)","7%"],"question_id":147,"discussion":[{"timestamp":"1719511200.0","upvote_count":"5","poster":"KaranNishad","content":"Selected Answer: CEF\nCorrect answer.","comment_id":"1238339"},{"comment_id":"1368543","poster":"asimohat","timestamp":"1741509720.0","upvote_count":"1","content":"Selected Answer: DEF\nI think “C” is better than “D”.\nThe filter pattern can identify the root user's login event and include the content of that event in the SNS.\nWith “C” notification, we only know that the root user logged in."},{"poster":"jamesf","content":"Selected Answer: CEF\nOption E: Use CloudTrail to capture and forward root user activities.\nOption C: Set up metric filters and alarms to alert on root user login events.\nOption F: Create a CloudWatch dashboard for visualizing root user activities.\n\nAdditional Note:\nCloudWatch Logs Subscription Filter:\n- Real-time processing of log events, but typically used for streaming log data to other services like AWS Lambda or Elasticsearch.\n- Not necessary for the specific task of alerting on root user login events.\n\nAWS Config is not directly relevant to capturing and forwarding root user login events to CloudWatch Logs.","timestamp":"1722390900.0","comment_id":"1258500","upvote_count":"3"},{"upvote_count":"2","poster":"tgv","timestamp":"1721035200.0","content":"---> CEF","comment_id":"1248217"},{"poster":"TEC1","upvote_count":"3","timestamp":"1720936080.0","content":"Selected Answer: CEF\nE- AWS CloudTrail will log all activities, including root user logins, across all accounts in the organisation. Sending these logs to CloudWatch Logs enables further processing and analysis.\n\nC- Creating a metric filter to detect root user login events will allow you to trigger a CloudWatch alarm. The alarm can then send notifications via SNS to the company's monitoring system, ensuring real-time alerts for root user logins.\n\nF- Using CloudWatch Logs Insights, you can create queries to extract and visualise log data related to root user activity. This data can be displayed on a CloudWatch dashboard, providing a centralised view of root user actions.","comment_id":"1247630"},{"upvote_count":"3","content":"Selected Answer: CEF\nE first, then C, and the last is F\n\nE ensures that all events, including root user login events, are captured across all accounts in the organization. By sending these events to CloudWatch Logs, you centralize the logging data, making it accessible for further processing.\nC creating a metric filter in CloudWatch Logs to detect specific patterns in the log data, such as root user login events. \nF creating a CloudWatch dashboard that utilizes CloudWatch Logs Insights to query and visualize the log data. This dashboard can be used to display detailed information about root user login activity and other relevant log events.","comment_id":"1247506","timestamp":"1720907760.0","poster":"trungtd"}],"answer_ET":"CEF","exam_id":23,"choices":{"C":"Create an Amazon CloudWatch Logs metric filter to match root user login events. Configure a CloudWatch alarm and an Amazon Simple Notification Service (Amazon SNS) topic to send alerts to the company's monitoring system.","B":"Create an Amazon QuickSight dashboard that uses an Amazon CloudWatch Logs query.","A":"Enable AWS Config with a multi-account aggregator. Configure log forwarding to Amazon CloudWatch Logs.","E":"Create an AWS CloudTrail organization trail. Configure the organization trail to send events to Amazon CloudWatch Logs.","F":"Create an Amazon CloudWatch dashboard that uses a CloudWatch Logs Insights query.","D":"Create an Amazon CloudWatch Logs subscription filter to match root user login events. Configure the filter to forward events to an Amazon Simple Notification Service (Amazon SNS) topic. Configure the SNS topic to send alerts to the company's monitoring system."},"url":"https://www.examtopics.com/discussions/amazon/view/142993-exam-aws-certified-devops-engineer-professional-dop-c02/","isMC":true,"answer_description":"","topic":"1","unix_timestamp":1719511200,"question_text":"A company uses AWS Organizations to manage its AWS accounts. The company wants its monitoring system to receive an alert when a root user logs in. The company also needs a dashboard to display any log activity that the root user generates.\n\nWhich combination of steps will meet these requirements? (Choose three.)","question_images":[],"timestamp":"2024-06-27 20:00:00","answer_images":[],"answer":"CEF"},{"id":"aECAso4fJxlgXU24itsR","question_images":[],"choices":{"E":"Create an SCP in Organizations to deny password creation for IAM users.","C":"Create a permissions boundary in AWS IAM Identity Center to deny password logins for IAM users.","B":"Use AWS IAM Identity Center to configure identity federation with SAML 2.0.","A":"Use Amazon GuardDuty with a delegated administrator account Use GuardDuty to enforce denial of IAM user logins.","D":"Create IAM groups in the Organizations management account to apply consistent permissions for all IAM users."},"question_text":"A company uses AWS Organizations to manage its AWS accounts. A DevOps engineer must ensure that all users who access the AWS Management Console are authenticated through the company’s corporate identity provider (IdP).\n\nWhich combination of steps will meet these requirements? (Choose two.)","answers_community":["BE (82%)","BC (18%)"],"answer":"BE","answer_description":"","unix_timestamp":1719511920,"topic":"1","timestamp":"2024-06-27 20:12:00","answer_images":[],"answer_ET":"BE","discussion":[{"comment_id":"1272357","timestamp":"1724635380.0","upvote_count":"2","content":"Selected Answer: BC\nUse AWS IAM Identity Center to configure identity federation with SAML 2.0:\nConfigure SAML-based federation between your corporate IdP and AWS IAM.\nThis allows users to authenticate via your corporate identity provider when accessing the AWS Management Console.\n\nCreate a permissions boundary in AWS IAM Identity Center:\nSet up a permissions boundary to deny password logins for IAM users.\nThis ensures that users must authenticate through the corporate IdP rather than using IAM user credentials.","poster":"limelight04"},{"comment_id":"1258502","upvote_count":"2","poster":"jamesf","timestamp":"1722391260.0","content":"Selected Answer: BE\nOption B: Configure identity federation with SAML 2.0 using AWS IAM Identity Center.\nOption E: Implement an SCP to deny password creation for IAM users, enforcing IdP authentication.\n\nIncorrect for C - Permissions Boundaries \n- Permissions boundaries in AWS IAM Identity Center define the maximum permissions an IAM entity can have but are not used to control login methods or deny password logins.\n- Permissions boundaries do not restrict authentication methods or enforce federation.\n- Permissions boundaries are not applicable for denying IAM user logins."},{"poster":"tgv","timestamp":"1721035260.0","comment_id":"1248218","content":"---> BE","upvote_count":"2"},{"poster":"trungtd","comment_id":"1247509","upvote_count":"3","content":"Selected Answer: BE\nof course B.\nE enforce that users cannot log in directly with IAM credentials. Instead, they must use the SSO setup provided by AWS IAM Identity Center, ensuring compliance with the requirement to authenticate through the corporate IdP.","timestamp":"1720908060.0"},{"poster":"KaranNishad","upvote_count":"4","timestamp":"1719511920.0","content":"Selected Answer: BE\nBE is answer\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n {\n \"Effect\": \"Deny\",\n \"Action\": [\n \"iam:CreateLoginProfile\",\n \"iam:UpdateLoginProfile\"\n ],\n \"Resource\": \"*\"\n }\n ]\n}","comment_id":"1238342"}],"question_id":148,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/142994-exam-aws-certified-devops-engineer-professional-dop-c02/","exam_id":23},{"id":"shombHi1w57Inh4OMeDi","question_text":"A company has deployed a new platform that runs on Amazon Elastic Kubernetes Service (Amazon EKS). The new platform hosts web applications that users frequently update. The application developers build the Docker images for the applications and deploy the Docker images manually to the platform.\n\nThe platform usage has increased to more than 500 users every day. Frequent updates, building the updated Docker images for the applications, and deploying the Docker images on the platform manually have all become difficult to manage.\n\nThe company needs to receive an Amazon Simple Notification Service (Amazon SNS) notification if Docker image scanning returns any HIGH or CRITICAL findings for operating system or programming language package vulnerabilities.\n\nWhich combination of steps will meet these requirements? (Choose two.)","answer_images":[],"unix_timestamp":1720191180,"answer":"BD","answer_description":"","timestamp":"2024-07-05 16:53:00","answers_community":["BD (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/143368-exam-aws-certified-devops-engineer-professional-dop-c02/","question_images":[],"exam_id":23,"choices":{"A":"Create an AWS CodeCommit repository to store the Dockerfile and Kubernetes deployment files. Create a pipeline in AWS CodePipeline. Use an Amazon S3 event to invoke the pipeline when a newer version of the Dockerfile is committed. Add a step to the pipeline to initiate the AWS CodeBuild project.","C":"Create an AWS CodeBuild project that builds the Docker images and stores the Docker images in an Amazon Elastic Container Registry (Amazon ECR) repository. Turn on basic scanning for the ECR repository. Create an Amazon EventBridge rule that monitors Amazon GuardDuty events. Configure the EventBridge rule to send an event to an SNS topic when the finding-severity-counts parameter is more than 0 at a CRITICAL or HIGH level.","E":"Create an AWS CodeBuild project that scans the Dockerfile. Configure the project to build the Docker images and store the Docker images in an Amazon Elastic Container Registry (Amazon ECR) repository if the scan is successful. Configure an SNS topic to provide notification if the scan returns any vulnerabilities.","D":"Create an AWS CodeBuild project that builds the Docker images and stores the Docker images in an Amazon Elastic Container Registry (Amazon ECR) repository. Turn on enhanced scanning for the ECR repository. Create an Amazon EventBridge rule that monitors ECR image scan events. Configure the EventBridge rule to send an event to an SNS topic when the finding-severity-counts parameter is more than 0 at a CRITICAL or HIGH level.","B":"Create an AWS CodeCommit repository to store the Dockerfile and Kubernetes deployment files. Create a pipeline in AWS CodePipeline. Use an Amazon EventBridge event to invoke the pipeline when a newer version of the Dockerfile is committed. Add a step to the pipeline to initiate the AWS CodeBuild project."},"topic":"1","question_id":149,"discussion":[{"poster":"limelight04","timestamp":"1724635740.0","comment_id":"1272361","content":"Selected Answer: BD\nThe answer is BD","upvote_count":"2"},{"content":"Selected Answer: BD\nOption B: \n- AWS CodeCommit repository to store the Dockerfile and Kubernetes deployment files. \n- Amazon EventBridge event to invoke the pipeline when a newer version of the Dockerfile is committed. \n\nOption D: \n- AWS CodeBuild project that builds the Docker images and stores the Docker images in an Amazon Elastic Container Registry (Amazon ECR) repository.\n- enhanced scanning for the ECR repository.","poster":"jamesf","comment_id":"1258508","timestamp":"1722391680.0","upvote_count":"3"},{"upvote_count":"2","poster":"tgv","comment_id":"1248219","timestamp":"1721035380.0","content":"---> BD"},{"comment_id":"1247516","poster":"trungtd","upvote_count":"4","timestamp":"1720908900.0","content":"Selected Answer: BD\nB sets up a CI/CD pipeline with AWS CodePipeline triggered by changes in the AWS CodeCommit repository. Using Amazon EventBridge ensures that the pipeline is invoked whenever there is a new commit, automating the build and deployment process.\n\nD ensures that Docker images are built and pushed to ECR, where enhanced scanning is enabled. Enhanced scanning provides detailed vulnerability information. An EventBridge rule is configured to monitor scan events and trigger notifications via SNS when HIGH or CRITICAL vulnerabilities are found."},{"content":"Selected Answer: BD\nAgree with B,D","timestamp":"1720454760.0","comment_id":"1244457","poster":"inturist","upvote_count":"3"},{"poster":"tgv","comment_id":"1243954","timestamp":"1720375800.0","upvote_count":"2","content":"--> B D"}],"isMC":true,"answer_ET":"BD"},{"id":"AxmTF6ryQKd0nIja8oVb","answer":"AE","answer_ET":"AE","topic":"1","question_id":150,"unix_timestamp":1720189380,"answers_community":["AE (95%)","5%"],"answer_description":"","exam_id":23,"question_images":["https://img.examtopics.com/aws-certified-devops-engineer-professional-dop-c02/image21.png"],"url":"https://www.examtopics.com/discussions/amazon/view/143365-exam-aws-certified-devops-engineer-professional-dop-c02/","timestamp":"2024-07-05 16:23:00","choices":{"C":"Create a request parameter-based AWS Lambda authorizer that passes the caller's identity in a combination of headers, query string parameters, stage variables, and $cortext variables.","B":"Create a token-based AWS Lambda authorizer that passes the caller's identity in a bearer token.","D":"Use Amazon Cognito user pools as the authorizer to control access to the API.","E":"Verify the identity of the requester by using Signature Version 4 to sign client requests by using AWS credentials.","A":"Enable IAM authentication on all API methods by setting AWS JAM as the authorization method."},"answer_images":[],"isMC":true,"question_text":"A company groups its AWS accounts in OUs in an organization in AWS Organizations. The company has deployed a set of Amazon API Gateway APIs in one of the Organizations accounts. The APIs are bound to the account's VPC and have no existing authentication mechanism. Only principals in a specific OU can have permissions to invoke the APIs.\n\nThe company applies the following policy to the API Gateway interface VPC endpoint:\n\n//IMG//\n\n\nThe company also updates the API Gateway resource policies to deny invocations that do not come through the interface VPC endpoint. After the updates, the following error message appears during attempts to use the interface VPC endpoint URL to invoke an API: \"User: anonymous is not authorized.\"\n\nWhich combination of steps will solve this problem? (Choose two.)","discussion":[{"timestamp":"1722392040.0","content":"Selected Answer: AE\nHope is Typo for the Option A, AWS JAM = AWS IAM\n\nOption A. Enable IAM authentication on all API methods by setting AWS IAM as the authorization method.\n- This ensures that all requests to the API must be authenticated using IAM credentials, directly addressing the anonymous access issue.\n\nOption E. Verify the identity of the requester by using Signature Version 4 to sign client requests by using AWS credentials.\n- By using AWS Signature Version 4, requests are authenticated, ensuring they are authorized according to IAM policies linked to the specific Organizational Unit.","upvote_count":"5","poster":"jamesf","comment_id":"1258509"},{"upvote_count":"3","timestamp":"1735230780.0","comment_id":"1331999","content":"Selected Answer: AE\nThis is for requests from Interface VPC endpoints, which means all principals are internal and have aws identities. \nBCD are all for external request control in general.","poster":"youonebe"},{"poster":"limelight04","comment_id":"1272369","timestamp":"1724636700.0","upvote_count":"1","content":"Selected Answer: AB\nOption A\nEnable IAM authentication on all API methods:\nSet AWS IAM as the authorization method for all API methods.\nThis ensures that authentication is required for invoking the APIs1.\n\nOption B\nCreate a token-based AWS Lambda authorizer:\nImplement a custom Lambda authorizer that validates bearer tokens.\nPass the caller’s identity in the token to authorize API requests"},{"comment_id":"1270820","content":"Selected Answer: AE\nvote for AE","timestamp":"1724341980.0","poster":"[Removed]","upvote_count":"3"},{"comment_id":"1268681","timestamp":"1724072280.0","content":"Selected Answer: AE\nYou can enable IAM authorization for HTTP API routes. When IAM authorization is enabled, clients must use Signature Version 4 (SigV4) to sign their requests with AWS credentials. API Gateway invokes your API route only if the client has execute-api permission for the route.","poster":"GripZA","upvote_count":"4"},{"timestamp":"1721647200.0","comment_id":"1253035","content":"Selected Answer: AE\nJAM= IAM","upvote_count":"4","poster":"d9iceguy"},{"timestamp":"1721036280.0","comment_id":"1248224","content":"---> A E (assuming there's a typo in AWS JAM)\nIf there's no typo in AWS JAM, I'd go for B & E","poster":"tgv","upvote_count":"2"},{"content":"Anser:B,E","upvote_count":"1","comment_id":"1247043","poster":"komorebi","timestamp":"1720826040.0"}]}],"exam":{"provider":"Amazon","isBeta":false,"numberOfQuestions":355,"isMCOnly":true,"id":23,"lastUpdated":"11 Apr 2025","name":"AWS Certified DevOps Engineer - Professional DOP-C02","isImplemented":true},"currentPage":30},"__N_SSP":true}