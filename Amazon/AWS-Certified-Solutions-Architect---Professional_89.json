{"pageProps":{"questions":[{"id":"KAJrNBBGOb7aYzAbGCxN","answer_images":[],"answers_community":["D (100%)"],"exam_id":32,"choices":{"A":"Update the runbook to describe how to create the VPC, the EC2 instances, and the RDS instance for the application by using the AWS Console. Make sure that the rest of the steps in the runbook are updated to reflect any changes that may come from the AWS migration.","C":"Write an AWS CloudFormation template that creates the VPC, the EC2 instances, and the RDS instance for the application. Ensure that the rest of the steps in the runbook are updated to reflect any changes that may come from the AWS migration.","D":"Write an AWS CloudFormation template that creates the VPC, the EC2 instances, and the RDS instance for the application. Include EC2 user data in the AWS CloudFormation template to install and configure the software.","B":"Write a Python script that uses the AWS API to create the VPC, the EC2 instances, and the RDS instance for the application. Write shell scripts that implement the rest of the steps in the runbook. Have the Python script copy and run the shell scripts on the newly created instances to complete the installation."},"question_id":441,"unix_timestamp":1568483400,"isMC":true,"answer_description":"","timestamp":"2019-09-14 19:50:00","question_text":"A company is migrating its marketing website and content management system from an on-premises data center to AWS. The company wants the AWS application to be deployed in a VPC with Amazon EC2 instances used for the web servers and an Amazon RDS instance for the database.\nThe company has a runbook document that describes the installation process of the on-premises system. The company would like to base the AWS system on the processes referenced in the runbook document. The runbook document describes the installation and configuration of the operating systems, network settings, the website, and content management system software on the servers. After the migration is complete, the company wants to be able to make changes quickly to take advantage of other AWS features.\nHow can the application and environment be deployed and automated in AWS, while allowing for future changes?","topic":"1","answer_ET":"D","question_images":[],"discussion":[{"timestamp":"1632468360.0","upvote_count":"26","comment_id":"12696","poster":"donathon","content":"D\nA: This is not automated.\nB: This cannot be easily re-used for future.\nC: The runbook is still considered manual configuration. Only D is fully automated."},{"comment_id":"13831","content":"I do support answer \"D\".\nThe runbook is having the \"Website, and content management software on the servers\". That means, the installation and configuration is required in the CloudFormation.\nC: The runbook does not need to have migration configuration, but the current configuration.","timestamp":"1632753780.0","upvote_count":"15","poster":"Moon"},{"poster":"SkyZeroZx","upvote_count":"1","comment_id":"926325","content":"Selected Answer: D\nOnly D is fully automated.","timestamp":"1687044180.0"},{"comment_id":"709073","timestamp":"1667302740.0","poster":"Blair77","content":"Selected Answer: D\nDDD for me","upvote_count":"1"},{"comment_id":"533255","content":"D for me. full automation achieved here","upvote_count":"1","poster":"Ni_yot","timestamp":"1643228280.0"},{"comment_id":"499004","upvote_count":"2","poster":"challenger1","content":"My answer: D\nD is the only fully automated option","timestamp":"1639179300.0"},{"timestamp":"1638651240.0","comment_id":"493958","content":"agree with D as others commented","upvote_count":"1","poster":"AzureDP900"},{"timestamp":"1636268040.0","upvote_count":"2","content":"I'll go with D","comment_id":"409804","poster":"WhyIronMan"},{"poster":"Kian1","content":"Going with D","timestamp":"1636170480.0","comment_id":"290938","upvote_count":"2"},{"upvote_count":"4","comment_id":"282403","content":"D is the answer","timestamp":"1636159080.0","poster":"Ebi"},{"comment_id":"268244","content":"D without doubt.","poster":"sanjaym","timestamp":"1635933840.0","upvote_count":"1"},{"timestamp":"1635918540.0","comment_id":"251473","upvote_count":"1","poster":"01037","content":"D.\nRunbook doesn't help with automation."},{"upvote_count":"1","comment_id":"242810","content":"D is correct answer. CloudFormation and include EC2 user data","poster":"T14102020","timestamp":"1635895560.0"},{"upvote_count":"3","content":"D is the right answer. Always use userdata to configure the instances as per the steps defined in the runbook.","poster":"Bulti","comment_id":"230169","timestamp":"1635603660.0"},{"upvote_count":"4","poster":"jackdryan","timestamp":"1634931480.0","comment_id":"230069","content":"I'll go with D"},{"poster":"gd1","timestamp":"1634510340.0","content":"Dedicated circuit takes 3 months to 5 months. D can not be the answer. - C looks logical.","upvote_count":"1","comment_id":"152090"},{"upvote_count":"1","comment_id":"149780","content":"D is corrcet","timestamp":"1634483400.0","poster":"fullaws"},{"upvote_count":"1","comment_id":"134462","poster":"NikkyDicky","content":"D makes sense","timestamp":"1634366400.0"},{"content":"ans : D","poster":"mat2020","comment_id":"110333","upvote_count":"1","timestamp":"1634269980.0"},{"timestamp":"1634120940.0","poster":"Gorha","content":"D makes more sense: the user data will take care of the the installation and configuration of the operating systems, etc. as mentioned in the questions","upvote_count":"2","comment_id":"53095"},{"timestamp":"1634077080.0","comment_id":"51072","upvote_count":"2","poster":"amog","content":"Confuse between C and D\nI will choose D as recommend"},{"upvote_count":"1","timestamp":"1633982760.0","content":"187 answer is ABF","poster":"michaelaws","comment_id":"32691"},{"comment_id":"23595","comments":[{"timestamp":"1633988280.0","comments":[{"timestamp":"1634242080.0","content":"Agree with B, C, F.\nhttps://aws.amazon.com/blogs/mobile/amazon-cognito-user-pools-supports-federation-with-saml/\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-integrate-with-cognito.html","poster":"fw","comments":[{"upvote_count":"1","comment_id":"223465","content":"BCF\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cognito-okta-saml-identity-provider/","poster":"kj07","timestamp":"1634618700.0"}],"comment_id":"85446","upvote_count":"1"}],"upvote_count":"4","content":"Bcf you cant have both lambda authorizer and cognito","poster":"wolke89","comment_id":"48373"}],"poster":"One_picese","content":"QUESTION 187\nA Security Engineer is working with a Product team building a web application on AWS. The application\nuses Amazon S3 to host the static content, Amazon API Gateway to provide RESTful services; and\nAmazon DynamoDB as the backend data store. The users already exist in a directory that is exposed\nthrough a SAML identity provider. Which combination of the following actions should the Engineer take to\nenable users to be authenticated into the web application and call APIs? (Choose three.)\nA. Create a custom authorization service using AWS Lambda.\nB. Configure a SAML identity provider in Amazon Cognito to map attributes to the Amazon Cognito user\npool attributes.\nC. Configure the SAML identity provider to add the Amazon Cognito user pool as a relying party.\nD. Configure an Amazon Cognito identity pool to integrate with social login providers.\nE. Update DynamoDB to store the user email addresses and passwords.\nF. Update API Gateway to use a COGNITO_USER_POOLS authorizer.\nCorrect Answer: ABE","upvote_count":"1","timestamp":"1633119840.0"},{"timestamp":"1632265560.0","comment_id":"11741","upvote_count":"5","poster":"dpvnme","content":"I would go with D"},{"comment_id":"11105","timestamp":"1632088320.0","content":"c might be","poster":"awsec2","upvote_count":"5"}],"url":"https://www.examtopics.com/discussions/amazon/view/5179-exam-aws-certified-solutions-architect-professional-topic-1/","answer":"D"},{"id":"0G2bBmaNrRjmAml9FsJY","question_text":"A company is adding a new approved external vendor that only supports IPv6 connectivity. The company's backend systems sit in the private subnet of an\nAmazon VPC. The company uses a NAT gateway to allow these systems to communicate with external vendors over IPv4. Company policy requires systems that communicate with external vendors to use a security group that limits access to only approved external vendors. The virtual private cloud (VPC) uses the default network ACL.\nThe Systems Operator successfully assigns IPv6 addresses to each of the backend systems. The Systems Operator also updates the outbound security group to include the IPv6 CIDR of the external vendor (destination). The systems within the VPC are able to ping one another successfully over IPv6. However, these systems are unable to communicate with the external vendor.\nWhat changes are required to enable communication with the external vendor?","isMC":true,"answer_images":[],"unix_timestamp":1568484300,"discussion":[{"content":"D\nNAT gateways are not supported for IPv6 traffic—use an egress-only internet gateway instead.\nhttps://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html","poster":"donathon","comment_id":"12697","upvote_count":"30","timestamp":"1632505440.0"},{"upvote_count":"14","timestamp":"1632334260.0","comment_id":"11742","poster":"dpvnme","content":"D. ipv6 address are public, no need for NAT"},{"timestamp":"1687044360.0","comment_id":"926326","upvote_count":"1","content":"Selected Answer: D\nipv6 == Egress Only \nipv4 = NAT Gatway","poster":"SkyZeroZx"},{"poster":"hilft","upvote_count":"1","content":"D. ipv6 are public no need for NAT. EGRESS ONLY.","comment_id":"637693","timestamp":"1658880480.0"},{"content":"Selected Answer: D\nD, easy one. Long question but look at the answer will immediately take the answer","comment_id":"613069","timestamp":"1654663800.0","poster":"Anhdd","upvote_count":"1"},{"upvote_count":"1","comment_id":"499293","content":"D. Create an egress-only internet gateway. Add a route for destination ::/0 pointing to the gateway.","timestamp":"1639216500.0","poster":"cldy"},{"poster":"AzureDP900","comment_id":"493961","upvote_count":"1","content":"D is right","timestamp":"1638651420.0"},{"upvote_count":"3","timestamp":"1638240780.0","poster":"acloudguru","comment_id":"490364","content":"hope i can have such simple question in my exam"},{"comment_id":"409811","timestamp":"1635999180.0","upvote_count":"2","poster":"WhyIronMan","content":"I'll go with D"},{"comment_id":"314781","poster":"Pupu86","timestamp":"1635977640.0","content":"Pertaining to outbound traffic for IPv6, it is always related to a egress-only internet gateway","upvote_count":"1"},{"timestamp":"1634911440.0","upvote_count":"2","content":"D is the answer","comment_id":"290946","poster":"Kian1"},{"timestamp":"1634617620.0","content":"D is the answer","upvote_count":"2","poster":"Ebi","comment_id":"282404"},{"comment_id":"268245","timestamp":"1634514480.0","content":"D. No second thought.","upvote_count":"1","poster":"sanjaym"},{"upvote_count":"1","content":"D is correct. egress-only internet gateway","timestamp":"1634100120.0","poster":"T14102020","comment_id":"242811"},{"poster":"Bulti","upvote_count":"2","timestamp":"1633380000.0","content":"D is the answer","comment_id":"230172"},{"content":"I'll go with D","comment_id":"230072","upvote_count":"4","timestamp":"1633239600.0","poster":"jackdryan"},{"poster":"ipindado2020","upvote_count":"2","content":"D for sure","comment_id":"182725","timestamp":"1633051980.0"},{"upvote_count":"2","comment_id":"149754","content":"D is correct","poster":"fullaws","timestamp":"1633040040.0"},{"upvote_count":"2","poster":"NikkyDicky","content":"D - 100%","comment_id":"132375","timestamp":"1632993840.0"},{"content":"Ans: D egress-only internet gateway","comment_id":"110334","poster":"mat2020","upvote_count":"3","timestamp":"1632962880.0"},{"upvote_count":"4","poster":"amog","comment_id":"51073","content":"D is correct","timestamp":"1632865920.0"},{"upvote_count":"5","content":"D is correct","poster":"certguy","timestamp":"1632766920.0","comment_id":"19179"},{"upvote_count":"9","comment_id":"11434","poster":"huhupai","content":"I would go for D, because both NAT instance and NAT gateway don't support IPv6.","timestamp":"1632332520.0"},{"poster":"awsec2","content":"b \nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html#route-tables-internet-gateway","upvote_count":"1","comment_id":"11107","timestamp":"1632111060.0"}],"topic":"1","answer_ET":"D","choices":{"C":"Enable IPv6 on the internet gateway. Add a route for destination 0.0.0.0/0 pointing to the IGW.","D":"Create an egress-only internet gateway. Add a route for destination ::/0 pointing to the gateway.","A":"Create an IPv6 NAT instance. Add a route for destination 0.0.0.0/0 pointing to the NAT instance.","B":"Enable IPv6 on the NAT gateway. Add a route for destination ::/0 pointing to the NAT gateway."},"url":"https://www.examtopics.com/discussions/amazon/view/5181-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"timestamp":"2019-09-14 20:05:00","exam_id":32,"answer_description":"Reference:\nhttps://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html","answer":"D","answers_community":["D (100%)"],"question_id":442},{"id":"k2Q0x8JnVVjyPkgoYnRI","timestamp":"2021-03-31 11:13:00","choices":{"E":"Launch configurations","A":"Route 53 Record Sets","D":"EC2 Key Pairs","C":"Elastic IP Addresses (EIP)","B":"IAM Roles","F":"Security Groups"},"answers_community":["AB (100%)"],"exam_id":32,"url":"https://www.examtopics.com/discussions/amazon/view/48577-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1617181980,"discussion":[{"upvote_count":"14","content":"A. B.\nIAM & R53 are global services.","comments":[{"upvote_count":"1","poster":"01037","timestamp":"1633147500.0","content":"Agreed","comment_id":"346714"}],"comment_id":"324912","timestamp":"1632200940.0","poster":"cldy"},{"content":"A. Route 53 Record Sets\nB. IAM Roles","timestamp":"1723735140.0","comment_id":"1266518","poster":"amministrazione","upvote_count":"1"},{"upvote_count":"1","timestamp":"1710766080.0","poster":"Kubernetes","comment_id":"1176488","content":"A and b"},{"poster":"Cal88","comment_id":"706744","upvote_count":"1","timestamp":"1666987980.0","content":"A and B\nEven though technically you can use use the same c2 key pair across region but its not best practice for security reasons so I would go with A and B"},{"upvote_count":"2","content":"Yeb A and B being global service dont need replicating","timestamp":"1660840560.0","comment_id":"648522","poster":"Ni_yot"},{"upvote_count":"1","poster":"jj22222","content":"Selected Answer: AB\nAB look right","timestamp":"1648572120.0","comment_id":"577732"}],"isMC":true,"topic":"1","answer":"AB","answer_images":[],"question_id":443,"question_images":[],"answer_ET":"AB","answer_description":"As per the document defined, new IPs should be reserved not the same ones\nElastic IP Addresses are static IP addresses designed for dynamic cloud computing. Unlike traditional static IP addresses, however, Elastic IP addresses enable you to mask instance or Availability Zone failures by programmatically remapping your public IP addresses to instances in your account in a particular region. For\nDR, you can also pre-allocate some IP addresses for the most critical systems so that their IP addresses are already known before disaster strikes. This can simplify the execution of the DR plan.\nReference:\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/resources.html","question_text":"You would like to create a mirror image of your production environment in another region for disaster recovery purposes.\nWhich of the following AWS resources do not need to be recreated in the second region? (Choose two.)"},{"id":"Pu2SgNMlSQjM78L80fVS","answer_images":[],"exam_id":32,"question_text":"A finance company is running its business-critical application on current-generation Linux EC2 instances. The application includes a self-managed MySQL database performing heavy I/O operations. The application is working fine to handle a moderate amount of traffic during the month. However, it slows down during the final three days of each month due to month-end reporting, even though the company is using Elastic Load Balancers and Auto Scaling within its infrastructure to meet the increased demand.\nWhich of the following actions would allow the database to handle the month-end load with the LEAST impact on performance?","url":"https://www.examtopics.com/discussions/amazon/view/5180-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"answer_description":"","isMC":true,"choices":{"B":"Performing a one-time migration of the database cluster to Amazon RDS, and creating several additional read replicas to handle the load during end of month.","A":"Pre-warming Elastic Load Balancers, using a bigger instance type, changing all Amazon EBS volumes to GP2 volumes.","C":"Using Amazon CloudWatch with AWS Lambda to change the type, size, or IOPS of Amazon EBS volumes in the cluster based on a specific CloudWatch metric.","D":"Replacing all existing Amazon EBS volumes with new PIOPS volumes that have the maximum available storage size and I/O per second by taking snapshots before the end of the month and reverting back afterwards."},"unix_timestamp":1568483460,"discussion":[{"comment_id":"12702","comments":[{"timestamp":"1639866480.0","poster":"challenger1","upvote_count":"1","comment_id":"504491","content":"\"The bottleneck is on the DB\" - well said."}],"content":"B\nA\\C\\D: Would not solve the problem as the bottleneck is on the DB. Amazon ELB is able to handle the vast majority of use cases for our customers without requiring \"pre-warming\" (configuring the load balancer to have the appropriate level of capacity based on expected traffic). In certain scenarios, such as when flash traffic is expected, or in the case where a load test cannot be configured to gradually increase traffic, we recommend that you contact us to have your load balancer \"pre-warmed\". We will then configure the load balancer to have the appropriate level of capacity based on the traffic that you expect. We will need to know the start and end dates of your tests or expected flash traffic, the expected request rate per second and the total size of the typical request/response that you will be testing.","timestamp":"1632170100.0","poster":"donathon","upvote_count":"36"},{"timestamp":"1632172260.0","comment_id":"13811","poster":"Moon","upvote_count":"19","content":"I support \"B\" answer.\nA: is not appropriate as the pre-warming ELB requires to contact AWS, and that is recommended if the traffic is expecting to have sudden increase in 5 minutes duration.\nC: not practical.\nD: does not add much enhancement. Plus the question never talked about snapshots!"},{"poster":"nimbus_00","upvote_count":"1","comment_id":"1295113","content":"Selected Answer: B\nAmazon RDS + Read Replicas","timestamp":"1728471480.0"},{"upvote_count":"1","content":"Selected Answer: B\nkeyword = read replicas \nB","poster":"SkyZeroZx","timestamp":"1687044420.0","comment_id":"926328"},{"upvote_count":"1","poster":"hilft","content":"I'm also going for B.\n\nwith the LEAST amount of performance degradation.","comment_id":"635781","timestamp":"1658616540.0"},{"content":"Selected Answer: B\nD is based on metric, still could have performance degradation. \"LEAST amount of performance degradation\"","comment_id":"626398","upvote_count":"1","timestamp":"1656820140.0","poster":"aandc"},{"poster":"HellGate","timestamp":"1643718540.0","content":"C\nB and D need too much manual works and there is still possibility of failure by unexpected events.","upvote_count":"1","comment_id":"537839"},{"comment_id":"534540","timestamp":"1643358960.0","upvote_count":"1","content":"B; month-end reporting == READ REPLICAS","poster":"zoliv"},{"comment_id":"521959","timestamp":"1641972420.0","upvote_count":"1","content":"Selected Answer: B\nWhich of the following actions would enable the database to manage the month-end load with the LEAST amount of performance degradation? For me this is key moving all the reads to a read replica will be highly efficient .","poster":"pititcu667"},{"content":"B is an overkill, solution needs to solve the issue for the last 3 days that's why C seems more relevant, you can test it in stage to know how much time it takes to switch EBS so then you can schedule it ahead of time. Plus read replica comes with a cost and the rest of the time it won't do anything.","upvote_count":"1","timestamp":"1640915820.0","poster":"peddyua","comment_id":"513819"},{"comment_id":"513785","content":"Option C is right - Refer https://aws.amazon.com/blogs/storage/automating-amazon-ebs-volume-resizing-with-aws-step-functions-and-aws-systems-manager/","upvote_count":"2","poster":"tkanmani76","timestamp":"1640909280.0"},{"poster":"AzureDP900","timestamp":"1638651660.0","content":"last three days of each month owing to month-end reporting is key here in this question, I will go with B. C doesn't make any sense to me","comment_id":"493964","upvote_count":"2"},{"comment_id":"456293","upvote_count":"1","poster":"StelSen","content":"Both B & C technically will work and satisfies the requirement. But I will choose C. Because we already know high volumes are just last 3 days. So, I will execute the lambda on 26th 11pm to change it to IOPS and run the lambda again on 1st 6am of the month to revert to original. Just bare in mind, adding read replicas comes with heavy cost and no use to do this just for 3 days high usage.","timestamp":"1636293840.0"},{"comment_id":"435672","upvote_count":"6","timestamp":"1636002540.0","content":"CCC:\n---\n\"You can now increase volume size, adjust performance, or change the volume type while the volume is in use. You can continue to use your application while the change takes effect.\n\nSpiking Demand – You are running a relational database on a Provisioned IOPS volume that is set to handle a moderate amount of traffic during the month, with a 10x spike in traffic during the final three days of each month due to month-end processing. You can use Elastic Volumes to dial up the provisioning in order to handle the spike, and then dial it down afterward.\" --> https://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/\n----\nOption C refers to the attached EBS volumes (not EC2 instances)\nWhile option B might work as well, I don't see the need of creating several additional read replicas to be used just in the final three days of the month. AUrora MySQL with Auto-Scaling Read Replicas would have been nice","poster":"tgv"},{"upvote_count":"1","comments":[{"upvote_count":"1","poster":"student22","content":"Changing to B","timestamp":"1636157220.0","comment_id":"455683"}],"content":"C\nThis will handle the spike.","timestamp":"1635814080.0","comment_id":"434448","poster":"student22"},{"poster":"Kopa","comment_id":"429939","content":"after reading all comments i choose C as from the link\nhttps://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/","upvote_count":"1","timestamp":"1635757800.0"},{"comment_id":"413770","timestamp":"1635490140.0","comments":[{"comments":[{"upvote_count":"2","poster":"StelSen","content":"It can be proactive. We already know last 3 days are high vol. So, I will execute the lambda on 26th 11pm to change it to IOPS and run the lambda again on 1st of the month to decrease. Just bare in mind, adding read replicas comes with heavy cost and no use to do this just for 3 days high usage.","timestamp":"1636242780.0","comment_id":"456291"}],"comment_id":"414257","content":"But that seems like a reactive approach and would have atleast some impact on the performance. We want LEAST impact on the performance and hence read replicas should be the solution","timestamp":"1635505560.0","poster":"TiredDad","upvote_count":"1"}],"poster":"DerekKey","upvote_count":"3","content":"C correct - Amazon EBS Elastic Volumes - By using Amazon CloudWatch with AWS Lambda you can automate volume changes to meet the changing needs of your applications."},{"content":"I'll go with B","upvote_count":"3","timestamp":"1635480900.0","poster":"WhyIronMan","comment_id":"409814"},{"poster":"blackgamer","comment_id":"345764","timestamp":"1635353760.0","content":"No option is a good solution here. B is more relevant compared to others and I will go with B.","upvote_count":"1"},{"timestamp":"1635295140.0","poster":"Waiweng","upvote_count":"3","comment_id":"345333","content":"it's C"},{"poster":"ExtHo","content":"Supporting B\nIn this scenario, the Amazon EC2 instances are in an Auto Scaling group already which means that the database read operations is the possible bottleneck especially during the month-end wherein the reports are generated. This can be solved by creating RDS read replicas.","timestamp":"1635063000.0","comment_id":"323888","upvote_count":"2"},{"comment_id":"291542","content":"C is correct. Note below information:\"Spiking Demand – You are running a relational database on a Provisioned IOPS volume that is set to handle a moderate amount of traffic during the month, with a 10x spike in traffic during the final three days of each month due to month-end processing. You can use Elastic Volumes to dial up the provisioning in order to handle the spike, and then dial it down afterward.\"","timestamp":"1634725140.0","poster":"wind","upvote_count":"1"},{"poster":"Kian1","upvote_count":"2","content":"will go with B over C, AWS RDS, Read replicas","timestamp":"1634724420.0","comment_id":"290953"},{"timestamp":"1634656860.0","upvote_count":"2","content":"Just because of month end activity for few days, is it needed to maintain the READ REPLICAS all the time ?\nFeels like D is most appropriate.","comments":[{"timestamp":"1634861280.0","upvote_count":"3","poster":"selva","content":"Taking snapshots manually does not sound effective. Should be C, to just adjust the IOPS automatically.","comment_id":"292268"}],"comment_id":"290951","poster":"Satya1405"},{"content":"Anyone who thinks \"B\" has the LEAST IMPACT on performance has clearly never migrated a database between platforms before, although I agree it will provide the greatest long-term performance and is in alignment with AWS recognized success patterns. Database migration for PRODUCTION databases that are needed every day for reporting isn't a small job--for a large company with many departments this effort could take several months and completely bog down the Database staff. \"C\" is an option with virtually zero impact on day-to-day performance and can be entirely managed by the Cloud Architect. Read carefully.\nThe answer is C.","poster":"Trap_D0_r","comment_id":"282690","upvote_count":"3","timestamp":"1634652300.0","comments":[{"content":"Also with option B i think we need to update endpoints with read replica to distribute load.","upvote_count":"1","poster":"kalyan_krishna742020","timestamp":"1635043020.0","comment_id":"306704"},{"upvote_count":"1","poster":"TiredDad","comment_id":"414260","content":"in exam setting, when I read LEAST impact on performance, it seems they are referring to application performance. Problem with C is it may still have some impact as it is suggesting to change based on cloudwatch metric","timestamp":"1635581580.0"},{"content":"You did not read it clearly. \"B\" says a \"one time migration\". This only happens once. Afterwards this would be sufficient to handle load and would not cause disruptions.","comment_id":"443878","poster":"Viper57","upvote_count":"1","timestamp":"1636078140.0"}]},{"content":"I go with C","comment_id":"282410","upvote_count":"3","timestamp":"1634482080.0","poster":"Ebi"},{"comment_id":"278719","content":"If Answer B looks more suitable.. Be aware of the wording \"one time migrate\". Migration is not copying/sync ... 2 different things and that might affect the performance and would need application adjustments etc...","timestamp":"1634449020.0","upvote_count":"1","poster":"aimar047"},{"content":"Other answer can also be correct but B is most appropriate.","upvote_count":"1","comment_id":"268251","timestamp":"1634345460.0","poster":"sanjaym"},{"poster":"01037","content":"C.\nOriginally, I chose B. Reporting is so much like a read-heavy task where a read replica is a suitable solution.\n\nBut after checking\nhttps://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/\nI have to go with C.\nIt's like the question is created from the post.","comment_id":"251487","timestamp":"1634294340.0","upvote_count":"12","comments":[{"poster":"elf78","timestamp":"1634420820.0","comment_id":"278270","upvote_count":"3","content":"+1 on the blog article"},{"comment_id":"429273","poster":"Geetar","timestamp":"1635619200.0","upvote_count":"1","content":"Cheers for the link, this is from the blog: \"Spiking Demand – You are running a relational database on a Provisioned IOPS volume that is set to handle a moderate amount of traffic during the month, with a 10x spike in traffic during the final three days of each month due to month-end processing. You can use Elastic Volumes to dial up the provisioning in order to handle the spike, and then dial it down afterward.\""}]},{"poster":"petebear55","timestamp":"1634182740.0","comment_id":"245501","content":"b: having read this although C would be the answer if the question mentioned the Application was where the bottleneck was ... Another shitty red herring question from AWS which sends one round the block https://aws.amazon.com/blogs/database/best-storage-practices-for-running-production-workloads-on-hosted-databases-with-amazon-rds-or-amazon-ec2/","upvote_count":"1","comments":[{"poster":"rcher","content":"I think some AWS questions need to be QC properly","timestamp":"1634359260.0","upvote_count":"1","comment_id":"276705"}]},{"poster":"T14102020","comment_id":"242817","content":"Correct answer is B. Amazon RDS","upvote_count":"1","timestamp":"1634136960.0"},{"timestamp":"1634099640.0","upvote_count":"4","content":"Correct answer is B. All other options are distractions","comment_id":"230504","poster":"Bulti"},{"content":"simply B proactive versus C Reactive and could affect the performance during the modification.","poster":"YouYouYou","upvote_count":"2","timestamp":"1633910820.0","comment_id":"230442"},{"upvote_count":"4","timestamp":"1633909140.0","content":"I'll go with B","poster":"jackdryan","comment_id":"230073"},{"content":"No need to overcomplicate things. This is one of the easier question. B is the right choice.","poster":"Paitan","timestamp":"1633895100.0","comment_id":"196436","upvote_count":"2"},{"comment_id":"149794","upvote_count":"1","timestamp":"1633857900.0","content":"B is correct compare to C as C trigger scaling based on metric, if scaling by scheduling will be the best choice.","poster":"fullaws"},{"upvote_count":"1","timestamp":"1633688220.0","content":"B is correct, is using C, need to consider the right EC2 instance in order for the IOPS to be fully utilized.","comment_id":"149791","poster":"fullaws"},{"content":"Its B. The issue is with database performing slow during last 3 days. so performing migration and creating read replicas will solve the problem in here.","upvote_count":"1","timestamp":"1633600800.0","poster":"Anila_Dhharisi","comment_id":"143015"},{"upvote_count":"1","timestamp":"1633585440.0","comment_id":"134463","content":"B for sure","poster":"NikkyDicky"},{"timestamp":"1633570980.0","content":"Answer: B\nNote: issue when reporting requirements increase - database problem\nA - incorrect - GP2 is less suited to database work than is PIOPS volumes. Systems may already be using PIOPS volumes so why downgrade.\nB - correct - absolutely the best option enabling reads to be offloaded to DB replicas. Migrate during a \nC - incorrect - if metrics are being used, they result from an anomoly such as bad performance - using elastic volumes, it takes time to migrate to the desired performance levels \"Performance (IOPS) changes can take from a few minutes to a few hours to complete and are dependent on the configuration change being made.\". What happens if a metric triggers another IOPS increase during those 3 days - potentially no performance increase for hours. When is enough IOPS enough?\nD - incorrect - huh? snapshots then reverting, possible if we don't need the data anymore","upvote_count":"4","poster":"inf","comment_id":"134377"},{"upvote_count":"1","poster":"chicagomassageseeker","content":"Answer B. This is a simple question. Reporting is done on read replicas to reduce the load on main db. its a basic thing, This is associate question. Sometimes you should not overthink.","timestamp":"1633424280.0","comment_id":"119120"},{"comment_id":"110336","timestamp":"1633290240.0","upvote_count":"1","content":"i support ans \"B\"","poster":"mat2020"},{"upvote_count":"2","comments":[{"content":"in the question, it does not mention anything about a cluster.","upvote_count":"1","poster":"oatif","comment_id":"132618","timestamp":"1633570980.0"}],"comment_id":"109002","poster":"pmjcr","content":"No doubt is C. I this article (https://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything) there is even the same example as the one described in the problem.","timestamp":"1633180140.0"},{"content":"C Does make sense with the EBS Elastic Volume the only problem I Have with it is that it says \"Cluster\" Whereas the problem is te DB being overloaded during reporting \"reads\" The SQL: ius a stand alone by the sounds of it and not a cluster.","comment_id":"99415","poster":"Merlin1","upvote_count":"1","timestamp":"1633172400.0"},{"upvote_count":"1","poster":"nawfal6809","timestamp":"1633166040.0","comment_id":"99270","content":"Answer is C. You are running a relational database on a Provisioned IOPS volume that is set to handle a moderate amount of traffic during the month, with a in traffic during the final three days of each month due to month-end processing. You can use Elastic Volumes to dial up the provisioning in order to handle the spike, and then dial it down afterward. https://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/"},{"content":"Documentation to support C.\nhttps://stackoverflow.com/questions/45261988/is-there-a-way-to-modify-an-ebs-volume-through-aws-lambda-boto3","poster":"JAWS1600","comment_id":"98272","timestamp":"1633131960.0","upvote_count":"1"},{"poster":"3parusr","comment_id":"94328","timestamp":"1632984300.0","comments":[{"poster":"JAWS1600","content":"Migration to RDS cannot be done without impacting the performance. But once migrated to RDS, I agree this is the right choice. I have scanned all the aws documentation and cannot find any clue of impact on the performance of changing the IO type.","timestamp":"1633040520.0","comment_id":"98266","upvote_count":"1"}],"upvote_count":"1","content":"Question states \"Which of the following actions would allow the database to handle the month-end load with the LEAST impact on performance\" Not least changes to environment. 10% the Least impact from reporting load is Read Replicas as the month end reporting does not hot the primary instance at all to cause contention."},{"timestamp":"1632937620.0","content":"\"even though the company is using Elastic Load Balancers and Auto Scaling within its infrastructure to meet the increased demand.\"\nwhich means the problem is not related to the EC2 instances, The problem is related to the DB.\nB","poster":"Ibranthovic","comment_id":"94226","upvote_count":"3"},{"upvote_count":"1","content":"C is the best choice. Volumes can be changed on the fly using lambdas as well.\nhttps://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/.\nThanks all who shared this link","timestamp":"1632849900.0","poster":"JAWS1600","comment_id":"93041"},{"timestamp":"1632824100.0","content":"Sorry, not D but C. Since D says replace existing EBS with new PIOPS that does not support the benefit of elastic volume which is changing on the EBS type on the fly. Still referring to same link provided by Chinmoy, you will observe that automatic elastic volume operation uses Cloudwatch and Lambda. \"Right-Sizing – Use a CloudWatch alarm to watch for a volume that is running at or near its IOPS limit. Initiate a workflow and approval process that could provision additional IOPS or change the type of the volume\"\n\nI believe the answer is \"C\"","comment_id":"63450","upvote_count":"5","poster":"Zek"},{"comment_id":"63441","content":"I agree with Chinmoy, D is the answer. Also note that the question says application runs on \"current-generation Linux EC2 instances. From the link provided by Chinmoy, you will also notice the statement \"Today we are launching a new EBS feature we call Elastic Volumes and making it available for all current-generation EBS volumes attached to current-generation EC2 instances.\"","upvote_count":"1","timestamp":"1632816900.0","poster":"Zek"},{"content":"D .. Spiking Demand – You are running a relational database on a Provisioned IOPS volume that is set to handle a moderate amount of traffic during the month, with a 10x spike in traffic during the final three days of each month due to month-end processing. You can use Elastic Volumes to dial up the provisioning in order to handle the spike, and then dial it down afterward.\nhttps://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/","upvote_count":"2","comments":[{"comment_id":"76589","timestamp":"1632828720.0","content":"^You mean Option C. \nWith keywords such as heavy I/O operations and month-end reporting, this is all about heavy write activities. Read replicas won't help here. I was skeptical about option C because you cannot reduce EBS volume size. However, this seems to be correct answer.","poster":"Smart","upvote_count":"2"}],"poster":"Chinmoy","timestamp":"1632798900.0","comment_id":"62540"},{"comment_id":"61645","upvote_count":"1","poster":"virtual","content":"\"it slows down during the final three days of each month due to month-end reporting\". This comforts me to choose B as it has read-replicas, so I go with RDS migration, thus B.","timestamp":"1632615300.0"},{"content":"The link provided by @dchaing appears to explain this scenario. I would go with C as the answer. https://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/","upvote_count":"3","poster":"Zek","timestamp":"1632600960.0","comment_id":"58040"},{"comment_id":"55967","content":"A won't really help - if they are using current generation instances, they already have GP2 volumes, pre-warming is not for this usecase. C won't help - you would need to resize the volumes inside the instances as well and you cannot reduce EBS volumes. Not sure about B or D - there is nothing about data migration requirements and whether its mostly read or write I/O during critical phase. Right now I'd opt for D, B is too disruptive during migration.","timestamp":"1632597120.0","poster":"MrP","upvote_count":"1"},{"upvote_count":"4","timestamp":"1632426840.0","poster":"Averageguy","comment_id":"51083","content":"Month-end reporting -> Need read replica."},{"comments":[{"poster":"Oleksandr","content":"I re-read question, and I agree that the key is \"reporting\". This is where read-replicas suits the best.","upvote_count":"1","comment_id":"103562","timestamp":"1633179360.0"}],"poster":"amog","timestamp":"1632328080.0","upvote_count":"9","content":"Read replica is good for reporting.\nThink about B too","comment_id":"51077"},{"poster":"dchaing","content":"I would choose answer \"C\"\n\"You can now increase volume size, adjust performance, or change the volume type while the volume is in use. You can continue to use your application while the change takes effect.\n\nThis new feature will greatly simplify (or even eliminate) many of your planning, tuning, and space management chores. Instead of a traditional provisioning cycle that can take weeks or months, you can make changes to your storage infrastructure instantaneously, with a simple API call.\"\n\"Spiking Demand – You are running a relational database on a Provisioned IOPS volume that is set to handle a moderate amount of traffic during the month, with a 10x spike in traffic during the final three days of each month due to month-end processing. You can use Elastic Volumes to dial up the provisioning in order to handle the spike, and then dial it down afterward.\"\nhttps://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/","comment_id":"48247","upvote_count":"10","comments":[{"timestamp":"1633678380.0","poster":"MultiAZ","comment_id":"143590","content":"So some words of the real-world. You can change the IOPS of a volume on the fly, but from my experience, for big database volumes this takes hours, even days. AWS takes care you can use your provisioned IOPS and does the sync to faster storage at the background with what extra IOPS they have left. Also there is absolutely no SLA for this process - it will eventually happen. \nSo if you count on CloudWath metrics for this change (as stated in C), you will still get angry customers. If you would do it planned and 2 days before, this might work.\nSo I go for read replica, because question is about *reporting* at month end. This can be scheduled during low-load time the night before the first high-load day.","upvote_count":"4"},{"timestamp":"1633564680.0","poster":"koniec","comment_id":"130930","content":"I go for C as well as creating Read Replica can cause some performance issues:\n\"When you create a read replica, Amazon RDS takes a DB snapshot of your source DB instance and begins replication. As a result, you experience a brief I/O suspension on your source DB instance while the DB snapshot occurs. The I/O suspension typically lasts about one minute. You can avoid the I/O suspension if the source DB instance is a Multi-AZ deployment, because in that case the snapshot is taken from the secondary DB instance.\"\nIt's nothing about multi-az in this question so it can take some risk.","upvote_count":"1"}],"timestamp":"1632264720.0"},{"comment_id":"11106","timestamp":"1632166980.0","upvote_count":"4","poster":"awsec2","content":"why not b"}],"answer_ET":"B","timestamp":"2019-09-14 19:51:00","answer":"B","question_id":444,"topic":"1","answers_community":["B (100%)"]},{"id":"5cMVDx2PZ3RRn3w3O1BT","exam_id":32,"unix_timestamp":1568722560,"question_id":445,"topic":"1","choices":{"A":"Store the data files in Amazon S3 and use Range GET for each file's metadata, then index the relevant data.","C":"Store the data files on Amazon EBS volumes and allow the EC2 fleet and EMR to mount and unmount the volumes where they are needed.","D":"Store the content of the data files in Amazon DynamoDB tables with the metadata, index, and data as their own keys.","B":"Store the data files in Amazon EFS mounted by the EC2 fleet and EMR nodes."},"answer_description":"","question_images":[],"answer_images":[],"answer":"A","isMC":true,"discussion":[{"upvote_count":"35","content":"A\nEffectively performs a 'ranged' GET request for the part specified. Useful for downloading just a part of an object.\nhttps://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectGET.html\nB: The maximum throughput you can drive for each NFS client is 250 MB/s. S3 does not have this limit.\nC: Can only be mounted on a single instance and not scalable.\nD: The file is too large for Dynamo DB.","poster":"donathon","comment_id":"12706","timestamp":"1632604800.0"},{"timestamp":"1632487200.0","comment_id":"11743","content":"A is the way","upvote_count":"6","poster":"dpvnme"},{"comment_id":"926330","content":"Selected Answer: A\nA: S3 + EMR.","upvote_count":"1","poster":"SkyZeroZx","timestamp":"1687044840.0"},{"comment_id":"758941","content":"Selected Answer: A\nA looks good!","timestamp":"1672167240.0","upvote_count":"1","poster":"evargasbrz"},{"content":"I ll go for A","comment_id":"686246","poster":"Ni_yot","timestamp":"1664893620.0","upvote_count":"1"},{"timestamp":"1641025380.0","poster":"cldy","comment_id":"514429","upvote_count":"1","content":"A: S3 + EMR."},{"comment_id":"499003","timestamp":"1639179000.0","upvote_count":"1","content":"My Answer: A","poster":"challenger1"},{"comment_id":"410198","timestamp":"1635427980.0","content":"I'll go with A","upvote_count":"1","poster":"WhyIronMan"},{"poster":"Waiweng","upvote_count":"2","timestamp":"1635365160.0","content":"It's A","comment_id":"345784"},{"upvote_count":"3","comment_id":"314799","poster":"Pupu86","content":"understanding Range GET from Cloudfront to S3 perspective:\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RangeGETs.html","timestamp":"1635267480.0"},{"content":"ans: A","poster":"k","timestamp":"1635117840.0","comment_id":"296374","upvote_count":"1"},{"timestamp":"1634960100.0","comment_id":"290956","poster":"Kian1","content":"will go with A ofc","upvote_count":"2"},{"comment_id":"282412","content":"I go with A","upvote_count":"2","poster":"Ebi","timestamp":"1634954880.0"},{"upvote_count":"1","content":"A for sure.","timestamp":"1634926920.0","comment_id":"268253","poster":"sanjaym"},{"upvote_count":"1","comment_id":"242822","timestamp":"1634764860.0","content":"Correct answer is A. S3 and use Range GET","poster":"T14102020"},{"content":"A is the answer for storage and indexing of large number of data files to be later processed by EMRFS, S3 is the best choice","poster":"Bulti","comment_id":"230508","timestamp":"1634577180.0","upvote_count":"3"},{"timestamp":"1634159460.0","content":"I'll go with A","upvote_count":"4","poster":"jackdryan","comment_id":"230075"},{"upvote_count":"1","comments":[{"content":"correction, EMR does not work with EFS, has to be S3","poster":"lostri","comment_id":"227064","upvote_count":"1","timestamp":"1634114880.0"}],"content":"why not B?","timestamp":"1634086560.0","comment_id":"227062","poster":"lostri"},{"content":"A is the right choice.","comment_id":"196437","timestamp":"1634058720.0","poster":"Paitan","upvote_count":"1"},{"upvote_count":"2","comment_id":"149753","poster":"fullaws","timestamp":"1633944180.0","content":"A is correct"},{"upvote_count":"2","timestamp":"1633811100.0","comment_id":"138208","poster":"noisonnoiton","content":"A acceptable\nEMR with S3"},{"comment_id":"134465","poster":"NikkyDicky","upvote_count":"2","content":"A for sure","timestamp":"1633809420.0"},{"poster":"mat2020","timestamp":"1633242480.0","comment_id":"110337","upvote_count":"2","content":"ans : A"},{"poster":"pgarg","content":"A is correct. Beginning of the file means he head of the file storing metadata and with the help of s3 get range , we can fetch the head of the file.","comment_id":"105307","timestamp":"1633187880.0","upvote_count":"1"},{"content":"I thinks S3 indexing requires Dynamo DB, as per documentation of AWS. This means S3 option would not work. \nMy next hop will be NFS -optionB","comment_id":"98941","upvote_count":"1","timestamp":"1633121580.0","poster":"JAWS1600"},{"content":"DynamoDB is not a good option as The files are large.\nBetween EBS, EFS and S3, It should be S3. A","poster":"Ibranthovic","upvote_count":"1","comment_id":"94228","timestamp":"1633017180.0"},{"timestamp":"1633010940.0","upvote_count":"3","content":"S3 is HA and cost effective\nAnswer is A","comment_id":"51079","poster":"amog"},{"timestamp":"1632531180.0","comment_id":"12241","content":"a is my view","poster":"awsec2","upvote_count":"4"},{"comments":[{"content":"I think EBS is not cost-effective.","comment_id":"37297","poster":"sparkf1","upvote_count":"2","timestamp":"1632807300.0"}],"content":"Why C?","timestamp":"1632250980.0","upvote_count":"1","poster":"huhupai","comment_id":"11432"}],"timestamp":"2019-09-17 14:16:00","question_text":"A Solutions Architect is designing the storage layer for a data warehousing application. The data files are large, but they have statically placed metadata at the beginning of each file that describes the size and placement of the file's index. The data files are read in by a fleet of Amazon EC2 instances that store the index size, index location, and other category information about the data file in a database. That database is used by Amazon EMR to group files together for deeper analysis.\nWhat would be the MOST cost-effective, high availability storage solution for this workflow?","answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/5309-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["A (100%)"]}],"exam":{"isMCOnly":false,"provider":"Amazon","isImplemented":true,"isBeta":false,"id":32,"name":"AWS Certified Solutions Architect - Professional","lastUpdated":"11 Apr 2025","numberOfQuestions":1019},"currentPage":89},"__N_SSP":true}