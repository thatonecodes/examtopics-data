{"pageProps":{"questions":[{"id":"B0JN2YHejuipX2farihp","answers_community":["BC (100%)"],"choices":{"C":"Configure the ALB to forward only requests that contain the custom HTTP header.","B":"Configure CloudFront to add a custom: HTTP header to requests that CloudFront sends to the ALB.","D":"Configure the ALB and CloudFront to use the X-Forwarded-For header to check client IP addresses.","E":"Configure the ALB and CloudFront to use the same X.509 certificate that is generated by AWS Certificate Manager (ACM).","A":"Configure CloudFront to add a cache key policy to allow a custom HTTP header that CloudFront sends to the ALB."},"unix_timestamp":1669222440,"question_id":376,"url":"https://www.examtopics.com/discussions/amazon/view/88447-exam-aws-certified-security-specialty-topic-1-question-437/","answer_ET":"BC","exam_id":29,"topic":"1","isMC":true,"answer":"BC","question_text":"A company’s public Application Load Balancer (ALB) recently experienced a DDoS attack. To mitigate this issue. the company deployed Amazon CloudFront in front of the ALB so that users would not directly access the Amazon EC2 instances behind the ALB.\n\nThe company discovers that some traffic is still coming directly into the ALB and is still being handled by the EC2 instances.\n\nWhich combination of steps should the company take to ensure that the EC2 instances will receive traffic only from CloudFront? (Choose two.)","answer_description":"","discussion":[{"comment_id":"725276","timestamp":"1669222440.0","poster":"AdamWest","content":"Selected Answer: BC\nBC-\nTo prevent users from directly accessing an Application Load Balancer and allow access only through CloudFront, complete these high-level steps:\nConfigure CloudFront to add a custom HTTP header to requests that it sends to the Application Load Balancer.\nConfigure the Application Load Balancer to only forward requests that contain the custom HTTP header.\n(Optional) Require HTTPS to improve the security of this solution.\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/restrict-access-to-load-balancer.html","upvote_count":"12"},{"comment_id":"842393","upvote_count":"1","content":"Selected Answer: BC\nB: Configure CloudFront to add a custom HTTP header to requests that CloudFront sends to the ALB. This header can be used as a way to identify requests that are coming from CloudFront.\n\nC: Configure the ALB to forward only requests that contain the custom HTTP header. This will ensure that the EC2 instances will only receive traffic that has been forwarded by CloudFront.","timestamp":"1679100960.0","poster":"c73bf38"},{"content":"B and C it is","timestamp":"1669421400.0","upvote_count":"2","comment_id":"727164","poster":"D2"}],"timestamp":"2022-11-23 17:54:00","question_images":[],"answer_images":[]},{"id":"NtC8Znd2BlsccsoKONJf","answers_community":["CD (100%)"],"topic":"1","timestamp":"2022-11-24 09:15:00","question_text":"A company has two web applications that run on Amazon EC2 and Amazon S3. The applications failed an HTTP security audit, and users are reporting latency issues.\n\nThe applications need to deliver web content at low latencies while improving security and privacy for users and content providers. The company must implement a solution that does not require changes to the application code.\n\nWhich combination of actions should the company take to meet these requirements? (Choose two.)","answer_ET":"CD","discussion":[{"comment_id":"735690","timestamp":"1670219940.0","comments":[{"comment_id":"742042","upvote_count":"1","timestamp":"1670787840.0","content":"CD makes sense","poster":"Balki"}],"poster":"tainh","upvote_count":"5","content":"Selected Answer: CD\nI think C, D \nuse CloudFront & Lambda@Edge to improve latency & security\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/adding-http-security-headers-using-lambdaedge-and-amazon-cloudfront/"},{"comments":[{"comment_id":"897421","content":"I don`t know. \nThat`s why take into with 'function', email protected.","poster":"Blue15","upvote_count":"1","timestamp":"1684055040.0"},{"timestamp":"1684735260.0","content":"How to create a Cloudfront distribution with EC2 origin? We must use the S3, ALB, API Gateway","comment_id":"903754","upvote_count":"1","poster":"572f16d"}],"upvote_count":"5","content":"Selected Answer: CD\nAnswer CD\n\nCloudFront will reduce latency\nLambda@edge security headers would improve security\nOnly these two are making sense","timestamp":"1669876800.0","comment_id":"732337","poster":"D2"},{"comment_id":"725655","upvote_count":"1","poster":"tryks","content":"D / E are correct","timestamp":"1669277700.0","comments":[{"poster":"cherry23","upvote_count":"1","timestamp":"1688463600.0","content":"Language of E is totally not worth selection","comment_id":"942580"},{"comment_id":"733401","content":"It is not E. Implement an Application Load Balancer (ALB)\nbecause the question says \"EC2 and S3\", and the ALB will only secure EC2, not S3. So Lambda@Edge will help protect both","upvote_count":"4","poster":"landsamboni","timestamp":"1669951440.0"}]}],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/88499-exam-aws-certified-security-specialty-topic-1-question-438/","question_id":377,"question_images":[],"choices":{"B":"Configure Amazon API Gateway with a request parameter-based AWS Lambda authorizer to add HTTP security headers on origin responses.","C":"Write a Lambda@Edge function to add HTTP security headers on origin responses.","D":"Configure Amazon CloudFront. Create a distribution for the EC2 and S3 origins.","A":"Deploy Amazon API Gateway. Cache the endpoint’s responses.","E":"Implement an Application Load Balancer (ALB) to honor the connection header from the incoming client request after forwarding the response back to the client."},"unix_timestamp":1669277700,"exam_id":29,"answer_images":[],"isMC":true,"answer":"CD"},{"id":"QQUjmrybGpO7YLjU5I15","exam_id":29,"url":"https://www.examtopics.com/discussions/amazon/view/88451-exam-aws-certified-security-specialty-topic-1-question-439/","answer_ET":"C","timestamp":"2022-11-23 18:39:00","discussion":[{"timestamp":"1669225140.0","comment_id":"725302","upvote_count":"9","content":"C:\nAs part of copying the objects, specify that S3 should encrypt the object with SSE-S3 or SSE-KMS encryption. This job copies the objects, so all your objects show an updated creation date upon completion, regardless of when you originally added them to S3. You also must specify the other properties for your set of objects as part of the S3 Batch Operations job, including object tags and storage class.\nhttps://aws.amazon.com/blogs/storage/encrypting-objects-with-amazon-s3-batch-operations/","comments":[{"comment_id":"927357","content":"but question also sayin \"encryption at rest for all objects in S3 buckets, and key rotation once every year.\" B, saying ok ı will do this. C doing this?","upvote_count":"1","timestamp":"1687169580.0","poster":"komik_101"}],"poster":"AdamWest"},{"comment_id":"927344","content":"I asked to BARD. he gave this awser. and I will say B. \n\nME:are you sure this? some people saying answer is C.\n\nSure, let's take a look at option C as well:\n\nC. Create a new AWS Key Management Service (AWS KMS) customer managed key. Configure annual automatic key rotation. Enable server-side encryption with AWS KMS keys (SSE-KMS) for the S3 bucket. Use an S3 Batch Operations job with the COPY command to change all the objects in the S3 bucket to use the customer managed key. Configure the EC2 instance profile with permissions to use the customer managed key.\n\nOption C is also a valid approach, but it does not meet the requirement for key rotation once every year. The S3 Batch Operations job will only encrypt the objects in the S3 bucket once, and the customer managed key will not be rotated until the next year.\n\nOption B, on the other hand, meets all of the requirements. The customer managed key will be rotated annually, which will help to mitigate the risk of unauthorized access to the data.","comments":[{"content":"Option B does not take into account existing objects in S3. Enabling default encryption does not change the encryption of existing objects in the same bucket - which means they will remain unencrypted whilst new uploads are encrypted. \n\nhttps://aws.amazon.com/blogs/storage/encrypting-existing-amazon-s3-objects-with-the-aws-cli/","timestamp":"1687671780.0","poster":"francinetanzx","upvote_count":"3","comment_id":"933260"}],"upvote_count":"1","timestamp":"1687168080.0","poster":"komik_101"},{"upvote_count":"3","poster":"6_8ftwin","content":"C\nAnswer B does not encrypt currently unencrypted objects. Also, once server side encryption is enabled, there isn't a need for a bucket policy to enforce encryption on new objects.","comment_id":"914784","timestamp":"1685893200.0"},{"timestamp":"1683709800.0","comment_id":"893774","upvote_count":"1","poster":"OCHT","content":"Selected Answer: B\nB. Create a new AWS Key Management Service (AWS KMS) customer managed key. Configure annual automatic key rotation. Enable server-side encryption with AWS KMS keys (SSE-KMS) for the S3 bucket. Add a bucket policy to the S3 bucket to enforce SSE-KMS encryption. Configure the EC2 instance profile with permissions to use the customer managed key.\n\nThis option meets all the requirements stated in the question. By creating a new AWS KMS customer managed key and configuring annual key rotation, you address the encryption at rest and key rotation requirements. Enabling server-side encryption with SSE-KMS for the S3 bucket ensures that new objects are encrypted at rest. Adding a bucket policy to enforce SSE-KMS encryption will ensure all new objects uploaded to the bucket are encrypted. Finally, configuring the EC2 instance profile with permissions to use the customer managed key allows the application to read and write encrypted objects in the S3 bucket."},{"comment_id":"764594","timestamp":"1672746720.0","content":"Selected c","upvote_count":"1","poster":"jishrajesh"},{"upvote_count":"3","poster":"tainh","comment_id":"735691","timestamp":"1670220240.0","content":"Selected Answer: C\nC is correct"}],"question_text":"A company’s application runs on an Amazon EC2 instance and stores objects in an Amazon S3 bucket. The EC2 instance is using an instance profile that provides access to read and write objects in the S3 bucket. The S3 bucket contains objects and has not been configured for any encryption at rest. The company is adopting a new security policy that mandates encryption at rest for all S3 buckets, encryption at rest for all objects in S3 buckets, and key rotation once every year.\n\nWhat should a security engineer do to meet these requirements?","question_id":378,"answer_description":"","question_images":[],"unix_timestamp":1669225140,"answer":"C","isMC":true,"answer_images":[],"answers_community":["C (75%)","B (25%)"],"choices":{"D":"Enable server-side encryption with Amazon S3 managed encryption keys (SSE-S3) for the S3 bucket. Configure annual automatic key rotation. Configure the EC2 instance profile with permissions to use the SSE-S3 key. Use the AWS CLI to copy the S3 objects in place by specifying the SSE-S3 key as the encryption key. Configure S3 data events to encrypt an object during a write operation.","B":"Create a new AWS Key Management Service (AWS KMS) customer managed key. Configure annual automatic key rotation. Enable server-side encryption with AWS KMS keys (SSE-KMS) for the S3 bucket. Add a bucket policy to the S3 bucket to enforce SSE-KMS encryption. Configure the EC2 instance profile with permissions to use the customer managed key.","A":"Enable server-side encryption with Amazon S3 managed encryption keys (SSE-S3) for the S3 bucket. Configure annual automatic key rotation. Use an S3 Batch Operations job with the COPY command to change all the objects in the S3 bucket to use the SSE-S3 key. Configure the EC2 instance profile with permissions to use the SSE-S3 key. Configure S3 data events to encrypt an object during a write operation.","C":"Create a new AWS Key Management Service (AWS KMS) customer managed key. Configure annual automatic key rotation. Enable server-side encryption with AWS KMS keys (SSE-KMS) for the S3 bucket. Use an S3 Batch Operations job with the COPY command to change all the objects in the S3 bucket to use the customer managed key. Configure the EC2 instance profile with permissions to use the customer managed key."},"topic":"1"},{"id":"c2kfaN0xGTGoRTV9VqnZ","question_text":"An organization has tens of applications deployed on thousands of Amazon EC2 instances. During testing, the Application team needs information to let them know whether the network access control lists (network ACLs) and security groups are working as expected.\nHow can the Application team's requirements be met?","isMC":true,"exam_id":29,"unix_timestamp":1640782440,"choices":{"C":"Create an AWS Config rule for each network ACL and security group configuration, send the logs to Amazon S3, and use Amazon Athena to query the logs.","A":"Turn on VPC Flow Logs, send the logs to Amazon S3, and use Amazon Athena to query the logs.","D":"Turn on AWS CloudTrail, send the trails to Amazon S3, and use AWS Lambda to query the trails.","B":"Install an Amazon Inspector agent on each EC2 instance, send the logs to Amazon S3, and use Amazon EMR to query the logs."},"answer_images":[],"question_images":[],"answer":"A","answers_community":["A (88%)","13%"],"discussion":[{"comment_id":"519760","content":"Ans is A;\nAWS Config rule for each network ACL and security group is not a good option. If we have 100 ACL and SG means we need 100 rules. VPC Flow log is an easy option and no need to manual work.","poster":"BKhan","upvote_count":"10","timestamp":"1641673260.0"},{"comment_id":"948765","content":"Selected Answer: C\nCloud Network Engineer here:\n\nImagine a scenario: You write a Network ACL\nrandom network for eg 99.0.0.0/24 is DENIED\nand everything else 0.0.0.0/0 is ALLOWED\n\nYou start testing and see Flow Logs.\nYou see that everything is ALLOWED for 5 hours straight you are happy and go to bed\n\nBut what happens if everything is allowed cause data was NOT generated from 99.0.0.0/24 during the test?\n\nIn order for Answer A to be correct is to test EVERY SINGLE THING thats on the ACL (and that could be 70-80-90 rules not just the 2 I wrote)\n\nI would go with Option C","poster":"Sickcnt","comments":[{"upvote_count":"1","timestamp":"1730268780.0","poster":"shammous","content":"AWS Config is great for tracking configuration compliance and auditing changes to ACLs and security groups.\nVPC Flow Logs are the better choice for analyzing network traffic and verifying that ACLs and security groups are performing as expected.\nOption A is the correct answer in this case.","comment_id":"1304878"},{"content":"For option C with AWS Config we have a couple of rules that I found that could monitor the Security Group:\n\nvpc-sg-open-only-to-authorized-ports:\n\"Checks if security groups allowing unrestricted incoming traffic ('0.0.0.0/0' or '::/0') only allow inbound TCP or UDP connections on authorized ports. The rule is NON_COMPLIANT if such security groups do not have ports specified in the rule parameters.\"","timestamp":"1689059100.0","comment_id":"948769","poster":"Sickcnt","upvote_count":"1"},{"content":"The more I think about it Option A could be an option if they are specifically testing for their applications I guess.. :\\","timestamp":"1689059220.0","comment_id":"948772","poster":"Sickcnt","upvote_count":"1"}],"upvote_count":"1","timestamp":"1689058860.0"},{"comments":[{"timestamp":"1708277160.0","content":"Yes I think the goal is to check whether there are not REJECT records. \nSo A is correct.","poster":"virtual","comment_id":"1153452","upvote_count":"1"}],"comment_id":"902747","upvote_count":"2","timestamp":"1684612560.0","content":"A is the best answer because it gets the job done and is more efficient than C.","poster":"ITGURU51"},{"content":"Selected Answer: A\nA is the answer. I present the evidence below.\nhttps://docs.aws.amazon.com/en_us/vpc/latest/userguide/flow-logs.html","timestamp":"1684217100.0","poster":"Blue15","upvote_count":"3","comment_id":"898908"},{"timestamp":"1670521800.0","comment_id":"739319","upvote_count":"1","content":"Answer is A to me. C is an overkill","poster":"MikeDuB"},{"timestamp":"1669185120.0","poster":"boooliyooo","comment_id":"724940","content":"I don't see this question as Compliance but rather; as an operation flow instead. Making sure things are working.","upvote_count":"1"},{"poster":"arae","comment_id":"704101","content":"I dont understand how A is right?\nIf we use config then we are 99% sure that the acl and sg are working as expected all the time, if we use the vpc flow logs with athena then we need to query the s3 every single time we want to check right?\nI went with C but please tell me how am i wrong.","upvote_count":"2","timestamp":"1666722960.0"},{"comment_id":"691404","content":"isnt the answer C? i mean this is a compliance use case","poster":"arae","timestamp":"1665425400.0","upvote_count":"3"},{"poster":"sapien45","comment_id":"658667","upvote_count":"2","timestamp":"1662224280.0","content":"Selected Answer: A\nAmazon Athena is an interactive query service that enables you to analyze data in Amazon S3, such as your flow logs, using standard SQL. You can use Athena with VPC Flow Logs to quickly get actionable insights about the traffic flowing through your VPC. For example, you can identify which resources in your virtual private clouds (VPCs) are the top talkers or identify the IP addresses with the most rejected TCP connections.\nhttps://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-athena.html"},{"upvote_count":"2","comment_id":"612830","timestamp":"1654619580.0","poster":"lotfi50","content":"Selected Answer: A\nA is a good answer"},{"timestamp":"1641414780.0","comment_id":"517790","poster":"roger8978","upvote_count":"2","content":"C..... AWS Config rule > Manage Remediation > S3 > Athena"},{"upvote_count":"2","comment_id":"517057","content":"A,\n\"https://aws.amazon.com/blogs/aws/vpc-flow-logs-log-and-view-network-traffic-flows/\"","poster":"argol","timestamp":"1641339660.0"},{"content":"Compliance so it should be C","timestamp":"1640782440.0","upvote_count":"4","poster":"roger8978","comment_id":"512170"}],"question_id":379,"topic":"1","timestamp":"2021-12-29 13:54:00","answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/68918-exam-aws-certified-security-specialty-topic-1-question-44/","answer_description":""},{"id":"bE9lx70oZ19tzVPVJtgz","unix_timestamp":1668979260,"answers_community":["D (94%)","6%"],"choices":{"A":"Create a security group that denies access on HTTP to 169.254.169.254. Attach this security group to all EC2 instances.","B":"Deactivate all access to IMDSv1 through the instance metadata options when using the AWS CLI, AWS API, or AWS Management Console to launch an EC2 instance.","D":"Attach the following SCP to the root OU in AWS Organizations:","C":"Attach the following SCP to the root OU in AWS Organizations:"},"discussion":[{"comment_id":"742035","poster":"Balki","upvote_count":"6","timestamp":"1670787300.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ExamplePolicies_EC2.html#iam-example-instance-metadata-require-roles-to-use-IMDSv2-credentials Role Credentials is the key word"},{"timestamp":"1669952460.0","comment_id":"733422","upvote_count":"6","poster":"landsamboni","content":"Selected Answer: D\nC option won't affect existing EC2 instances, so the correct answer is D."},{"upvote_count":"1","poster":"kejam","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_ec2.html#example-ec2-2","timestamp":"1700025600.0","comment_id":"1071109"},{"comments":[{"comment_id":"889838","poster":"Mehdi_ahmednacer","upvote_count":"1","timestamp":"1683268620.0","content":"After reading different comment. i'm sure is D.\nC and D address the same issue. However, D addresses the issue in case EC2 instance is already running (the case of this question). While, C prevents provisioning new instances with IMDSv1"}],"comment_id":"889807","upvote_count":"1","content":"C\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-metadata-transition-to-version-2.html","poster":"Mehdi_ahmednacer","timestamp":"1683264180.0"},{"poster":"examtopics_dummy","timestamp":"1675406040.0","comment_id":"796803","content":"Selected Answer: D\nBased on https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ExamplePolicies_EC2.html\nC is Require the use of IMDSv2\nD is Require role credentials to be retrieved from IMDSv2\n\nC stops us from starting a new instance but the question asks for \"must never use IAM credentials from Instance Metadata Service Version 1 (IMDSv1)\"\n\nThus D must be correct as it \"specifies that if this policy is applied to a role, and the role is assumed by the EC2 service and the resulting credentials are used to sign a request, then the request must be signed by EC2 role credentials retrieved from IMDSv2. Otherwise, all of its API calls will get an UnauthorizedOperation error. This statement/policy can be applied generally because, if the request is not signed by EC2 role credentials, it has no effect.\"","upvote_count":"4"},{"comments":[],"content":"C and D address the issue. However, D addresses the issue in case EC2 instance is already running. C prevents provisioning new instances with IMDSv1\n\nhttps://summitroute.com/blog/2020/03/25/aws_scp_best_practices/#require-the-use-of-imdsv2","poster":"D2","upvote_count":"4","timestamp":"1669422540.0","comment_id":"727175"},{"content":"Selected Answer: C\nC is the answer","timestamp":"1668979260.0","comment_id":"723019","comments":[{"content":"Provide the reason","upvote_count":"2","comment_id":"761056","timestamp":"1672320540.0","poster":"Teknoklutz"}],"poster":"Fyssy","upvote_count":"1"}],"isMC":true,"timestamp":"2022-11-20 22:21:00","answer_ET":"D","exam_id":29,"url":"https://www.examtopics.com/discussions/amazon/view/88133-exam-aws-certified-security-specialty-topic-1-question-440/","answer":"D","answer_description":"","answer_images":[],"question_id":380,"question_text":"A company uses AWS Organizations. According to compliance requirements, the company’s applications that are hosted on Amazon EC2 instances must never use IAM credentials from Instance Metadata Service Version 1 (IMDSv1).\n\nWhat should a security engineer do to meet this requirement?","topic":"1","question_images":[]}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Security - Specialty","id":29,"numberOfQuestions":509,"provider":"Amazon","isMCOnly":false,"isImplemented":true},"currentPage":76},"__N_SSP":true}