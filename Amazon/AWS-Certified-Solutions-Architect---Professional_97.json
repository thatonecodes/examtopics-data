{"pageProps":{"questions":[{"id":"PEonRFgGXG3YgbvkWWoU","url":"https://www.examtopics.com/discussions/amazon/view/5161-exam-aws-certified-solutions-architect-professional-topic-1/","answer_description":"","answers_community":["B (100%)"],"topic":"1","answer_ET":"B","question_images":[],"answer_images":[],"unix_timestamp":1568466540,"question_text":"A company is planning to migrate an application from on-premises to AWS. The application currently uses an Oracle database and the company can tolerate a brief downtime of 1 hour when performing the switch to the new infrastructure. As part of the migration, the database engine will be changed to MySQL. A\nSolutions Architect needs to determine which AWS services can be used to perform the migration while minimizing the amount of work and time required.\nWhich of the following will meet the requirements?","discussion":[{"poster":"donathon","comment_id":"13643","timestamp":"1633040520.0","content":"B\nA: Need to minimize work and time required. MySQL has already been chosen why do we need to provide recommendation?\nC\\D: SCT needs to be used.","comments":[{"upvote_count":"1","poster":"sam422","content":"To move an instance to a placement group using the AWS CLI\n\nStop the instance using the stop-instances command.\n\nUse the modify-instance-placement command and specify the name of the placement group to which to move the instance.\n\naws ec2 modify-instance-placement --instance-id i-0123a456700123456 --group-name MySpreadGroup\nStart the instance using the start-instances command.","timestamp":"1633645920.0","comment_id":"185986"}],"upvote_count":"22"},{"comments":[{"content":"Bbbbbbb","upvote_count":"5","comment_id":"11878","poster":"dpvnme","timestamp":"1632319680.0"}],"poster":"huhupai","upvote_count":"12","comment_id":"11069","timestamp":"1632309000.0","content":"AWS Application Discovery Service can't identify what embedded SQL code in the application, SCT can scan application source code for embedded SQL statements and convert them as part of a database schema conversion project. So I think the correct answer is B."},{"poster":"SkyZeroZx","comment_id":"930755","timestamp":"1687449060.0","content":"Selected Answer: B\nB\nA: Need to minimize work and time required. MySQL has already been chosen why do we need to provide recommendation?\nC\\D: SCT needs to be used.","upvote_count":"1"},{"timestamp":"1676975640.0","comment_id":"816450","upvote_count":"1","poster":"andras","content":"https://docs.amazonaws.cn/en_us/dms/latest/userguide/CHAP_SchemaConversion.html\nIt seems Schema conversion could be solved with DMS. Why do we need separate SCT???"},{"comment_id":"497386","poster":"cldy","upvote_count":"1","content":"B. Use AWS SCT to generate the schema scripts and apply them on the target prior to migration. Use AWS DMS to begin moving data from the on-premises database to AWS. After the initial copy, continue to use AWS DMS to keep the databases in sync until cutting over to the new database. Use AWS SCT to identify what embedded SQL code in the application can be converted and what has to be done manually.","timestamp":"1639031160.0"},{"timestamp":"1638734280.0","upvote_count":"2","poster":"AzureDP900","content":"I agree with B","comment_id":"494614"},{"poster":"WhyIronMan","upvote_count":"2","timestamp":"1636260480.0","comment_id":"411115","content":"I'll go with B"},{"timestamp":"1636108800.0","comment_id":"346917","content":"It's B","upvote_count":"2","poster":"Waiweng"},{"timestamp":"1635972300.0","upvote_count":"1","content":"BBBBBBBBBB","comment_id":"336694","poster":"Kelvin"},{"timestamp":"1635615720.0","poster":"Kian1","comment_id":"291679","content":"going with B","upvote_count":"2"},{"upvote_count":"4","comment_id":"279862","timestamp":"1634916840.0","content":"Answer is B","poster":"Ebi"},{"poster":"rkbala","comment_id":"267024","timestamp":"1634868840.0","content":"B is the correct answer","upvote_count":"2"},{"timestamp":"1634617740.0","upvote_count":"1","content":"Answer is B not A as it doesn't seem to meet the 1 hour downtime req","comment_id":"251869","poster":"Bulti"},{"comment_id":"247496","poster":"petebear55","content":"This is a typical example of how aws tries to trip u up in the exam .. using terms like SCT instead of the full The AWS Schema Conversion Tool (AWS SCT) which helps convert your existing database schema from one database engine to another. You can convert from a relational OLTP schema or any supported data warehouse OLAP schema to Amazon RDS (for example, Amazon Aurora MySQL or Amazon Aurora PostgreSQL, among others).","timestamp":"1634482980.0","upvote_count":"1"},{"upvote_count":"1","content":"Correct is B. SCT + without DMS to analyze","timestamp":"1634368020.0","comment_id":"243457","poster":"T14102020"},{"timestamp":"1634362020.0","comment_id":"238648","content":"BBBBBBBBBB","poster":"MeepMeep","upvote_count":"1"},{"content":"I'll go with B","timestamp":"1634088600.0","poster":"jackdryan","comment_id":"230823","upvote_count":"3"},{"timestamp":"1633909920.0","comment_id":"230084","poster":"gookseang","content":"seems B","upvote_count":"1"},{"comment_id":"198499","timestamp":"1633907400.0","content":"Option B","poster":"Paitan","upvote_count":"1"},{"upvote_count":"1","content":"B is correct","comment_id":"151783","poster":"fullaws","timestamp":"1633612980.0"},{"poster":"NikkyDicky","content":"B fore sure","upvote_count":"1","comment_id":"133126","timestamp":"1633500240.0"},{"content":"B is correct","poster":"FreeSwan","timestamp":"1633305540.0","comment_id":"94709","upvote_count":"1"},{"upvote_count":"1","poster":"amog","comment_id":"51666","timestamp":"1633282920.0","content":"Should be B"},{"content":"IT'S B\nSCT to modify the schema and DMS to move the data","poster":"Ibranthovic","comment_id":"14560","upvote_count":"4","timestamp":"1633081620.0"},{"timestamp":"1632968880.0","content":"I support answer \"B\" too.","poster":"Moon","comment_id":"13433","upvote_count":"8"}],"question_id":481,"exam_id":32,"timestamp":"2019-09-14 15:09:00","choices":{"C":"Use AWS DMS to help identify the best target deployment between installing the database engine on Amazon EC2 directly or moving to Amazon RDS. Then, use AWS DMS to migrate to the platform. Use AWS Application Discovery Service to identify what embedded SQL code in the application can be converted and what has to be done manually.","B":"Use AWS SCT to generate the schema scripts and apply them on the target prior to migration. Use AWS DMS to begin moving data from the on-premises database to AWS. After the initial copy, continue to use AWS DMS to keep the databases in sync until cutting over to the new database. Use AWS SCT to identify what embedded SQL code in the application can be converted and what has to be done manually.","A":"Use AWS SCT to generate the schema scripts and apply them on the target prior to migration. Use AWS DMS to analyze the current schema and provide a recommendation for the optimal database engine. Then, use AWS DMS to migrate to the recommended engine. Use AWS SCT to identify what embedded SQL code in the application can be converted and what has to be done manually.","D":"Use AWS DMS to begin moving data from the on-premises database to AWS. After the initial copy, continue to use AWS DMS to keep the databases in sync until cutting over to the new database. Use AWS Application Discovery Service to identify what embedded SQL code in the application can be converted and what has to be done manually."},"answer":"B","isMC":true},{"id":"EZb19zuT78NjLiwYJ4MF","answer_ET":"C","question_id":482,"timestamp":"2019-09-02 07:30:00","answer":"C","isMC":true,"question_text":"A company is using AWS to run an internet-facing production application written in Node.js. The Development team is responsible for pushing new versions of their software directly to production. The application software is updated multiple times a day. The team needs guidance from a Solutions Architect to help them deploy the software to the production fleet quickly and with the least amount of disruption to the service.\nWhich option meets these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/4516-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"upvote_count":"24","content":"\"C\",\nou can avoid this downtime by performing a blue/green deployment, where you deploy the new version to a separate environment, and then swap CNAMEs of the two environments to redirect traffic to the new version instantly.","comment_id":"13431","poster":"Moon","timestamp":"1632319440.0"},{"upvote_count":"20","poster":"donathon","comment_id":"13642","timestamp":"1632498780.0","content":"C\nA\\D: Not feasible\nB: CodeDeploy does not push AMI."},{"content":"Selected Answer: C\n\"C\",\nou can avoid this downtime by performing a blue/green deployment, where you deploy the new version to a separate environment, and then swap CNAMEs of the two environments to redirect traffic to the new version instantly.","poster":"SkyZeroZx","comment_id":"941158","upvote_count":"1","timestamp":"1688322600.0"},{"timestamp":"1663390800.0","upvote_count":"1","content":"Selected Answer: C\nC has the least amount of efforts","comment_id":"671264","poster":"Dionenonly"},{"poster":"Ni_yot","timestamp":"1660663500.0","upvote_count":"1","content":"yep C for me","comment_id":"647728"},{"comment_id":"561155","upvote_count":"1","timestamp":"1646450940.0","poster":"pal40sg","content":"Selected Answer: C\npush this to the production fleet using a blue/green deployment method"},{"poster":"pititcu667","comment_id":"552958","timestamp":"1645457460.0","content":"Selected Answer: C\nc seems to make sense","upvote_count":"1"},{"poster":"AzureDP900","content":"I will go with C","timestamp":"1638734460.0","comment_id":"494618","upvote_count":"1"},{"poster":"WhyIronMan","content":"I'll go with C","upvote_count":"1","comment_id":"411118","timestamp":"1636236900.0"},{"content":"it's C","upvote_count":"2","poster":"Waiweng","timestamp":"1636037580.0","comment_id":"346919"},{"poster":"blackgamer","upvote_count":"1","comment_id":"346677","content":"C is the correct answer","timestamp":"1636035960.0"},{"timestamp":"1636022340.0","content":"going with C","upvote_count":"2","poster":"Kian1","comment_id":"291682"},{"upvote_count":"4","comment_id":"279876","poster":"Ebi","timestamp":"1635755520.0","content":"I go with C"},{"poster":"Firststack","comment_id":"279686","timestamp":"1635428580.0","upvote_count":"2","content":"Answer is C"},{"upvote_count":"1","poster":"Bulti","timestamp":"1634337900.0","content":"Answer is C","comment_id":"251870"},{"timestamp":"1634316180.0","content":"Correct is C. Elastic Beanstalk","upvote_count":"1","poster":"T14102020","comment_id":"243460"},{"timestamp":"1634079420.0","comment_id":"230826","content":"I'll go with C","poster":"jackdryan","upvote_count":"4"},{"content":"seems c","poster":"gookseang","timestamp":"1633975200.0","comment_id":"230090","upvote_count":"1"},{"comment_id":"151785","timestamp":"1633734120.0","upvote_count":"1","poster":"fullaws","content":"C is correct"},{"poster":"NikkyDicky","comment_id":"133136","upvote_count":"1","timestamp":"1633279560.0","content":"C most likely, although A could work with rolling update policy"},{"content":"C is correct","comment_id":"94711","upvote_count":"1","poster":"FreeSwan","timestamp":"1633036440.0"},{"comment_id":"92911","timestamp":"1632994200.0","content":"C, App stream is specifically for desktop applications.\nAmazon AppStream 2.0 allows organizations to stream desktop applications from AWS to any device running a web browser, without the need to rewrite them. With AppStream 2.0, you’ll have instant-on access to the application of your choice, all with a responsive user experience that works with different devices.\n\nAmazon AppStream 2.0 offers you the ability to import your existing desktop applications to AWS so that you can still maintain a single version of each of your apps, but also have them accessible across computers, tablets, and other mobile devices.\nSee the link below for details:\nhttps://cloudhesive.com/blog-posts/appstream-2-0-vs-workspaces-basics/","poster":"JAWS1600","upvote_count":"1"},{"timestamp":"1632906780.0","poster":"SamuelK","upvote_count":"1","comment_id":"53609","content":"A & b : updating AMI will disrupt the service: question said, least amount of disruption\nD. this is not quick and it's too much\nB: Developers can just deploy to Beanstalk"},{"timestamp":"1632696180.0","upvote_count":"4","comment_id":"51667","poster":"amog","content":"Agree C"},{"poster":"jxhyxxclyp","content":"why not c??","comments":[{"timestamp":"1632307080.0","content":"Yeah, I think C would be better","comment_id":"10465","poster":"dpvnme","upvote_count":"6"}],"upvote_count":"5","timestamp":"1632254760.0","comment_id":"9244"}],"exam_id":32,"choices":{"B":"Use AWS CodeDeploy to push the prepackaged AMI to production. For software changes, reconfigure CodeDeploy with new AMI identification to push the new AMI to the production fleet.","A":"Prepackage the software into an AMI and then use Auto Scaling to deploy the production fleet. For software changes, update the AMI and allow Auto Scaling to automatically push the new AMI to production.","C":"Use AWS Elastic Beanstalk to host the production application. For software changes, upload the new application version to Elastic Beanstalk to push this to the production fleet using a blue/green deployment method.","D":"Deploy the base AMI through Auto Scaling and bootstrap the software using user data. For software changes, SSH to each of the instances and replace the software with the new version."},"answer_description":"","answers_community":["C (100%)"],"question_images":[],"unix_timestamp":1567402200,"answer_images":[],"topic":"1"},{"id":"VdSFHSPz8qi93WQcw4VQ","answer":"C","discussion":[{"poster":"donathon","content":"C\nA: Issue seems to be latency and load related. EFS does not solve the issue since the issue lies with EC2.\nB: Risky as an EC2 instance failure could corrupt the data.\nD: Origin cannot point to ALB (either S3, EC2 or HTTP based)?","upvote_count":"20","comments":[{"comment_id":"43317","timestamp":"1633049520.0","poster":"PacoDerek","upvote_count":"2","content":"orgin can be ELB, the point of D is the data to be served resided on EFS, point to ELB is useless"},{"content":"Origins:\nUsing an Amazon S3 bucket\nUsing a MediaStore container or a MediaPackage channel\nUsing an Application Load Balancer\nUsing a Lambda function URL\nUsing Amazon EC2 (or another custom origin)\nUsing CloudFront origin groups\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/restrict-access-to-load-balancer.html","timestamp":"1651771320.0","comment_id":"597403","upvote_count":"1","poster":"bobsmith2000"},{"poster":"leeo","content":"C looks more relevant ,but we can add ALB as CF origin.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-connection-fails/","comments":[{"upvote_count":"4","poster":"Ibranthovic","content":"We can add ALB as Cloudfront origin, then why not D ?\nWhy to use S3 when the data are already in EFS. and go to migration between S3 and EFS.\nI think the right answer is D","timestamp":"1632520140.0","comment_id":"14563","comments":[{"timestamp":"1634778240.0","upvote_count":"1","poster":"shammous","content":"Because S3 is more cost-effective.","comment_id":"279177"},{"poster":"ahmedghanem","content":"the deployment should be cost-effective and scalable \nas u know EFS 10 time more expensive than S3","comment_id":"16529","timestamp":"1632869040.0","upvote_count":"12"}]}],"comment_id":"14237","timestamp":"1632499140.0","upvote_count":"6"}],"comment_id":"13646","timestamp":"1632346200.0"},{"content":"C.\nS3 Cheaper compare to EFS\nCF woks better with S3\nUsing ALB which makes easy to point to Video file when needed","comment_id":"45608","timestamp":"1633064940.0","poster":"ashp","upvote_count":"9"},{"content":"Selected Answer: C\nC\nA: Issue seems to be latency and load related. EFS does not solve the issue since the issue lies with EC2.\nB: Risky as an EC2 instance failure could corrupt the data.\nD: Origin cannot point to ALB (either S3, EC2 or HTTP based)?","poster":"SkyZeroZx","comment_id":"930809","timestamp":"1687453080.0","upvote_count":"1"},{"timestamp":"1676016240.0","comment_id":"804107","poster":"Heer","upvote_count":"1","content":"ChatGPT output :\nIn general, if the primary concern is improving the video playback experience for users, then CloudFront with S3 may be the better option. On the other hand, if the primary concern is simplifying the deployment and improving the overall performance of the site, then CloudFront with ALB may be the better option.\n\nSeems for this question option D is more relevant"},{"poster":"cldy","timestamp":"1638767880.0","content":"C. Configure an Amazon CloudFront distribution. Point the distribution to an S3 bucket, and migrate the videos from EFS to Amazon S3.","upvote_count":"2","comment_id":"494915"},{"comment_id":"494621","timestamp":"1638734640.0","poster":"AzureDP900","upvote_count":"2","content":"C is right"},{"content":"I'll go with C","timestamp":"1636062960.0","comment_id":"411119","upvote_count":"1","poster":"WhyIronMan"},{"poster":"pradhyumna","content":"I would go with D. Option C may only solve the buffering issue with videos and there would be additional changes required for the app to provide links to s3. The question also points at users having issues in reaching the site which can't be solved with option C, so an overall caching solution like option D would really help.","timestamp":"1635958500.0","comment_id":"377097","upvote_count":"1"},{"poster":"Waiweng","timestamp":"1635951300.0","upvote_count":"1","content":"it's C","comment_id":"346923"},{"comment_id":"291686","timestamp":"1635670560.0","poster":"Kian1","content":"defo going with C","upvote_count":"2"},{"comments":[{"content":"C does not say the EFS is going to be removed, just say to move videos from EFS to S3. \n\nI'll go with C","timestamp":"1635048840.0","upvote_count":"4","poster":"lechuk","comment_id":"288186"}],"comment_id":"279893","poster":"Ebi","upvote_count":"2","timestamp":"1634976000.0","content":"C doesn't seem to be correct, moving videos to S3 does not mean that architecture won't have EFS anymore, all other contents are still in EFS,\nI go with D, ALB of course can be the origin for CFN\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesDomainName"},{"poster":"Firststack","content":"I'll go with C","comment_id":"279688","upvote_count":"1","timestamp":"1634968200.0"},{"content":"C is the right answer","comment_id":"251871","upvote_count":"1","timestamp":"1634741640.0","poster":"Bulti"},{"poster":"petebear55","content":"D IS TOO COMPLEX AND DOES NOT MEET THE PARAMETERS OF THE QUESTION ... ANSWER IS C WHICH IS BEST PRACTICE","timestamp":"1634699640.0","comment_id":"247512","upvote_count":"1"},{"comment_id":"243463","content":"Correct is C. S3 + CloudFront","upvote_count":"2","poster":"T14102020","timestamp":"1634580120.0"},{"content":"I'll go with C","upvote_count":"4","poster":"jackdryan","timestamp":"1634518020.0","comment_id":"230828"},{"comment_id":"230091","poster":"gookseang","timestamp":"1634472240.0","upvote_count":"2","content":"CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC"},{"comment_id":"199549","timestamp":"1634274120.0","poster":"SMS","upvote_count":"1","content":"A. Reconfigure Amazon EFS to enable maximum I/O is the right answer.https://docs.aws.amazon.com/efs/latest/ug/performance.html"},{"content":"Option C","upvote_count":"2","comment_id":"198504","poster":"Paitan","timestamp":"1634150160.0"},{"poster":"fullaws","timestamp":"1633791300.0","comment_id":"151788","upvote_count":"2","content":"C, because cost efficient, and scalable with s3 can store more video than EFS. If the question say serve global billion user, D will be more scalable"},{"poster":"inf","timestamp":"1633389540.0","comment_id":"136408","upvote_count":"2","content":"Answer: D\nNote: C seems too simple - almost swayed\nA - incorrect - this is not how higher EFS I/O is achieved - works on file system size, greater size equals greater performance \nB - incorrect - not scalable, may or may not improve performance.\nC - incorrect - question states users have issues accessing the website, even before reaching the blog site. Moving videos to S3 won't fix the website response issues \nD - correct - use ALB as the origin for all content - website + files - which may help eliminate buffering of the website and video\nNote: 10x the number of people accessing the website - we can't assume the website is under performing because people are uploading/downloading video files. Some may just be browsing knowing there may be new files to watch. Offloading the files to S3 and caching in CloudFront may improve video file access, but the website itself may still be a bottleneck with the additional user. Maybe only one video is uploaded per day, but the user count increases because of expectation. Increasing EC2 compute may also have helped","comments":[{"comments":[{"upvote_count":"2","comment_id":"137685","content":"Also dont forget the question is looking for MOST cost efficient. S3 is a winner here.","timestamp":"1633680060.0","poster":"xhova"}],"timestamp":"1633563420.0","comment_id":"137680","poster":"xhova","upvote_count":"1","content":"Cloudfront in front on EFS is not a good solution. The key is to first move the videos to S3."},{"comment_id":"181658","timestamp":"1634053140.0","poster":"proxyolism","upvote_count":"1","content":"cloudfront cannot support EFS as a origin.\nhttps://forums.aws.amazon.com/message.jspa?messageID=699673\nSo D is wrong. C is the answer."}]},{"poster":"NikkyDicky","upvote_count":"3","content":"C most likely","timestamp":"1633220160.0","comment_id":"133142"}],"url":"https://www.examtopics.com/discussions/amazon/view/6008-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"answer_images":[],"choices":{"B":"Update the blog site to use instance store volumes for storage. Copy the site contents to the volumes at launch and to Amazon S3 at shutdown.","C":"Configure an Amazon CloudFront distribution. Point the distribution to an S3 bucket, and migrate the videos from EFS to Amazon S3.","A":"Reconfigure Amazon EFS to enable maximum I/O.","D":"Set up an Amazon CloudFront distribution for all site contents, and point the distribution at the ALB."},"answers_community":["C (100%)"],"answer_ET":"C","answer_description":"Reference:\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-connection-fails/","unix_timestamp":1570061160,"timestamp":"2019-10-03 02:06:00","topic":"1","question_text":"A company used Amazon EC2 instances to deploy a web fleet to host a blog site. The EC2 instances are behind an Application Load Balancer (ALB) and are configured in an Auto Scaling group. The web application stores all blog content on an Amazon EFS volume.\nThe company recently added a feature for bloggers to add video to their posts, attracting 10 times the previous user traffic. At peak times of day, users report buffering and timeout issues while attempting to reach the site or watch videos.\nWhich is the MOST cost-efficient and scalable deployment that will resolve the issues for users?","exam_id":32,"question_images":[],"question_id":483},{"id":"cXRbtG0zV3fqpdFQ0ddj","choices":{"A":"Schedule the jobs on an Amazon ECS cluster using the Amazon EC2 launch type. Use Service Auto Scaling to increase or decrease the number of running tasks to suit the number of running jobs.","C":"Schedule the jobs on an Amazon ECS cluster using the Fargate launch type. Use Service Auto Scaling to increase or decrease the number of running tasks to suit the number of running jobs.","D":"Schedule the jobs on an Amazon ECS cluster using the Fargate launch type. Use Spot Instances in an Auto Scaling group to scale the platform based on demand. Use Service Auto Scaling to increase or decrease the number of running tasks to suit the number of running jobs.","B":"Schedule the jobs directly on EC2 instances. Use Reserved Instances for the baseline minimum load, and use On-Demand Instances in an Auto Scaling group to scale up the platform based on demand."},"discussion":[{"content":"C\nA: EC2 Launch type you have to determine the EC2 instance beforehand and scaling up down is not that fast as Fargate.\nB: This is not feasible as it may not be fast enough and it’s not managed.\nD: You cannot use Spot instance because it is not guaranteed.","poster":"donathon","comment_id":"13647","upvote_count":"22","timestamp":"1633228440.0"},{"poster":"dpvnme","timestamp":"1632207120.0","comment_id":"10466","upvote_count":"12","content":"I would go with C in this situation"},{"timestamp":"1687453200.0","content":"Selected Answer: C\nC\nA: EC2 Launch type you have to determine the EC2 instance beforehand and scaling up down is not that fast as Fargate , Addicionally EC2 more overhead administrationt for user\nB: This is not feasible as it may not be fast enough and it’s not managed , same the A more overhead\nD: You cannot use Spot instance because it is not guaranteed , no recommed for production envoritment or in specify case of use","comment_id":"930811","poster":"SkyZeroZx","upvote_count":"1"},{"timestamp":"1638879180.0","comment_id":"495948","upvote_count":"1","poster":"cldy","content":"C. Schedule the jobs on an Amazon ECS cluster using the Fargate launch type. Use Service Auto Scaling to increase or decrease the number of running tasks to suit the number of running jobs."},{"comment_id":"494622","poster":"AzureDP900","timestamp":"1638734700.0","content":"I go with C","upvote_count":"1"},{"comment_id":"411120","content":"I'll go with C","timestamp":"1635782100.0","upvote_count":"1","poster":"WhyIronMan"},{"upvote_count":"2","poster":"Waiweng","content":"it's C","timestamp":"1635743700.0","comment_id":"346933"},{"poster":"kiev","timestamp":"1635130080.0","comment_id":"294348","content":"Fargate. C","upvote_count":"1"},{"poster":"Kian1","upvote_count":"2","timestamp":"1634602020.0","comment_id":"291689","content":"ofc going with C"},{"timestamp":"1634453340.0","upvote_count":"3","comment_id":"279898","poster":"Ebi","content":"I go with C"},{"comment_id":"263777","poster":"cox1960","content":"very strange answers since a \"service\" in ECS is not used for batches.","upvote_count":"1","timestamp":"1634427600.0"},{"poster":"Bulti","content":"Answer is C.","upvote_count":"1","timestamp":"1634413200.0","comment_id":"251872"},{"content":"C THIS TOPIC IS COVERED QUITE WELL IN THE LATEST ADDED QUESTIONS ON WIZZ LABS ... REMEMBER ITS FARGATE ONLY IF YOU WANT AWS TO MANAGE IT .. SO BE CAREFUL HERE IN THE EXAM ,,,,, ANSWER C","comment_id":"247520","poster":"petebear55","timestamp":"1634157840.0","upvote_count":"3"},{"poster":"T14102020","comment_id":"243466","content":"Correct is C. Fargate + without Spot","timestamp":"1634112540.0","upvote_count":"1"},{"poster":"jackdryan","content":"I'll go with C","upvote_count":"3","timestamp":"1634082300.0","comment_id":"230829"},{"comment_id":"230094","timestamp":"1633990800.0","content":"CCCCCCCCCCCCCCCCCCCC","upvote_count":"3","poster":"gookseang"},{"upvote_count":"2","timestamp":"1633949640.0","comment_id":"151793","content":"C is correct","poster":"fullaws"},{"comment_id":"133147","content":"C most likley","upvote_count":"2","timestamp":"1633758720.0","poster":"NikkyDicky"},{"upvote_count":"3","poster":"mat2020","content":"Answer C","comment_id":"132532","timestamp":"1633741380.0"},{"poster":"pmjcr","upvote_count":"2","timestamp":"1633583940.0","comment_id":"118172","content":"I would also go for C due to unpredicted load and number of tasks. Also there is no requirement that requires an EC2 instead of Fargate"},{"content":"C Fargate vs. ECS. Fargate is faster due to the ec2 fleet on the ready.\nhttps://medium.com/faun/ecs-vs-eks-vs-fargate-the-good-the-bad-the-ugly-9f68bfc3bb73","poster":"Merlin1","timestamp":"1633487640.0","upvote_count":"2","comment_id":"93491"},{"content":"Checking on C","timestamp":"1633300140.0","upvote_count":"6","comment_id":"51668","poster":"amog"},{"content":"I would go with \"C\".\nBetter than spot instances for immediate response, and easier for automation and scaling than fixed EC2 Launch type.","timestamp":"1633221960.0","upvote_count":"10","poster":"Moon","comment_id":"13298"},{"upvote_count":"9","comment_id":"12283","content":"c is my view","poster":"awsec2","timestamp":"1632660060.0"}],"exam_id":32,"answer_ET":"C","answer_images":[],"question_id":484,"url":"https://www.examtopics.com/discussions/amazon/view/5009-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"2019-09-10 17:50:00","question_text":"A company runs its containerized batch jobs on Amazon ECS. The jobs are scheduled by submitting a container image, a task definition, and the relevant data to an Amazon S3 bucket. Container images may be unique per job. Running the jobs as quickly as possible is of utmost importance, so submitting job artifacts to the\nS3 bucket triggers the job to run immediately. Sometimes there may be no jobs running at all. However, jobs of any size can be submitted with no prior warning to the IT Operations team. Job definitions include CPU and memory resource requirements.\nWhat solution will allow the batch jobs to complete as quickly as possible after being scheduled?","answers_community":["C (100%)"],"question_images":[],"topic":"1","isMC":true,"answer":"C","answer_description":"","unix_timestamp":1568130600},{"id":"L6EKlbAYjuJUWM7312Ci","answers_community":["D (100%)"],"question_images":[],"isMC":true,"discussion":[{"comment_id":"10565","upvote_count":"28","comments":[{"comments":[{"comment_id":"43328","comments":[{"upvote_count":"2","comments":[{"poster":"LunchTime","upvote_count":"1","content":"D is the correct answer.\nIf S3 event notifications are configured property, this will not be an issue, as explained in the following link:\nhttps://aws.amazon.com/premiumsupport/knowledge-center/lambda-configure-s3-event-notification/","comment_id":"123665","timestamp":"1633915980.0"}],"poster":"PacoDerek","content":"https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html","comment_id":"43330","timestamp":"1632933240.0"},{"comment_id":"659286","poster":"pixepe","content":"C (hourly schedule) is INCORRECT as requirement is \"The data consumers ask for the data be available as soon as possible.\"\n\nD is correct","timestamp":"1662295860.0","upvote_count":"1"}],"poster":"PacoDerek","content":"C\nas s3 event may lost. cloudwatch event is more reliable. using rate expression to trigger Lambda is ok","timestamp":"1632813300.0","upvote_count":"1"}],"content":"https://docs.aws.amazon.com/lambda/latest/dg/with-s3.html","timestamp":"1632799800.0","comment_id":"13648","poster":"donathon","upvote_count":"2"},{"poster":"shammous","timestamp":"1635520620.0","comment_id":"279193","content":"D is the answer, but I disagree with you regarding CW Event being \"still based on schedule\". It can do the same job as S3 events by instantaneously triggering a lambda function based on a write event on S3, but the fact that it should be \"as soon as possible\" make S3 events service a better choice as it will perform quicker than CW Event.","upvote_count":"3"}],"poster":"donathon","content":"D\nA: Will not help.\nB: Not feasible since it is based on a schedule not event.\nC: This is still based on schedule.","timestamp":"1632093720.0"},{"content":"prefer D, too.\nC is still hour-based, which is not \"as soon as possible\".","upvote_count":"9","comment_id":"11948","timestamp":"1632368940.0","poster":"uopspop"},{"upvote_count":"1","comment_id":"930818","timestamp":"1687453440.0","content":"Selected Answer: D\nD\nhttps://aws.amazon.com/blogs/aws/s3-event-notification/","poster":"SkyZeroZx"},{"upvote_count":"1","poster":"Racinely","content":"Explanation\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-s3.html","timestamp":"1653567540.0","comment_id":"607633"},{"comment_id":"494625","poster":"AzureDP900","content":"D is fine with me. Amazon S3 using S3 event notifications","upvote_count":"1","timestamp":"1638734880.0"},{"timestamp":"1638698760.0","upvote_count":"1","poster":"cldy","comment_id":"494209","content":"D. Create an AWS Lambda function that runs when a file is delivered to Amazon S3 using S3 event notifications."},{"content":"D is correct","timestamp":"1635997500.0","upvote_count":"1","comment_id":"448104","poster":"moon2351"},{"content":"I'll go with D","upvote_count":"1","timestamp":"1635994080.0","comment_id":"411123","poster":"WhyIronMan"},{"upvote_count":"2","timestamp":"1635913380.0","content":"it's D","comment_id":"348215","poster":"Waiweng"},{"timestamp":"1635848340.0","upvote_count":"2","content":"going with D","comment_id":"291691","poster":"Kian1"},{"timestamp":"1635715680.0","content":"Answer is D","poster":"Ebi","comment_id":"280231","upvote_count":"4"},{"comment_id":"251873","upvote_count":"2","poster":"Bulti","timestamp":"1635283440.0","content":"D is correct"},{"comment_id":"243469","timestamp":"1634638920.0","poster":"T14102020","upvote_count":"2","content":"Correct is D. Lambda runs when a file is delivered"},{"upvote_count":"3","comment_id":"230830","poster":"jackdryan","timestamp":"1634601540.0","content":"I'll go with D"},{"poster":"gookseang","upvote_count":"2","content":"DDDDDDDDDDDDDD","comment_id":"230098","timestamp":"1634449560.0"},{"comment_id":"197438","poster":"Paitan","upvote_count":"1","content":"Definitely D. Since we are calling Lambda based on S3 notifications, 15 minutes limit of Lambda is not an issue here.","timestamp":"1634394060.0"},{"content":"D is correct","upvote_count":"1","comment_id":"151800","poster":"fullaws","timestamp":"1634361480.0"},{"timestamp":"1634110500.0","poster":"3parusr","upvote_count":"3","content":"Has to be A - trick question since lambda Max run time is 15 minutes? https://aws.amazon.com/about-aws/whats-new/2018/10/aws-lambda-supports-functions-that-can-run-up-to-15-minutes/","comment_id":"147776","comments":[{"upvote_count":"7","poster":"khksoma","timestamp":"1634189640.0","comment_id":"148155","content":"The cron job takes 15 to 30 minutes to process 24 hours of data. We are not doing this once a day..we are doing it based on the s3 notification."}]},{"upvote_count":"1","poster":"NikkyDicky","comment_id":"133151","timestamp":"1634026860.0","content":"D for sure"},{"comment_id":"111187","content":"@JAWS1600 you are comments are always confusing and misleading. Can you please research it and post it.","upvote_count":"3","poster":"mat2020","timestamp":"1633786680.0"},{"upvote_count":"2","timestamp":"1633657320.0","content":"D\nhttps://aws.amazon.com/blogs/aws/s3-event-notification/","poster":"JAWS1600","comment_id":"107945"},{"upvote_count":"2","poster":"meenu2225","timestamp":"1633530540.0","content":"D is correct.","comment_id":"106350"},{"upvote_count":"1","poster":"NKnab","comment_id":"100493","content":"as soon as possible makes it D. C is every one hour","timestamp":"1633363440.0"},{"upvote_count":"1","timestamp":"1633200000.0","content":"D is not correct . Pay attention to \"S3 events\" in option D. It should be claoudwatch events not S3 events. C is the right option - run every hour using cloud watch events.","comment_id":"95114","poster":"JAWS1600"},{"comment_id":"51669","timestamp":"1633076760.0","content":"Agree D","poster":"amog","upvote_count":"3"},{"timestamp":"1633003020.0","comment_id":"44444","content":"D is correct","upvote_count":"4","poster":"dumma"},{"poster":"Moon","comment_id":"13297","timestamp":"1632428400.0","content":"I would go with \"D\".","upvote_count":"8"},{"poster":"huhupai","timestamp":"1632195120.0","comment_id":"11144","upvote_count":"6","content":"I prefer D."}],"answer":"D","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/5037-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"timestamp":"2019-09-11 08:41:00","question_id":485,"topic":"1","answer_description":"Reference:\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-s3.html","exam_id":32,"unix_timestamp":1568184060,"question_text":"A company receives clickstream data files to Amazon S3 every five minutes. A Python script runs as a cron job once a day on an Amazon EC2 instance to process each file and load it into a database hosted on Amazon RDS. The cron job takes 15 to 30 minutes to process 24 hours of data. The data consumers ask for the data be available as soon as possible.\nWhich solution would accomplish the desired outcome?","choices":{"B":"Convert the cron job to an AWS Lambda function and trigger this new function using a cron job on an EC2 instance.","D":"Create an AWS Lambda function that runs when a file is delivered to Amazon S3 using S3 event notifications.","A":"Increase the size of the instance to speed up processing and update the schedule to run once an hour.","C":"Convert the cron job to an AWS Lambda function and schedule it to run once an hour using Amazon CloudWatch Events."}}],"exam":{"numberOfQuestions":1019,"id":32,"lastUpdated":"11 Apr 2025","isMCOnly":false,"provider":"Amazon","isImplemented":true,"isBeta":false,"name":"AWS Certified Solutions Architect - Professional"},"currentPage":97},"__N_SSP":true}