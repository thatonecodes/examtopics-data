{"pageProps":{"questions":[{"id":"FrYN3PqCHR4dXLX5LARA","exam_id":21,"question_images":[],"answer":"C","choices":{"D":"Amazon SageMaker Data Wrangler","B":"Amazon S3 Storage Lens","A":"Amazon Textract","C":"Amazon Macie"},"answers_community":["C (100%)"],"discussion":[{"upvote_count":"1","comment_id":"1341212","timestamp":"1736967120.0","content":"Selected Answer: C\nDetection only (no redaction) = Macie","poster":"MerryLew"},{"timestamp":"1734945720.0","content":"Selected Answer: C\nPII in AWS --> Macie","upvote_count":"1","comment_id":"1330746","poster":"HagarTheHorrible"}],"timestamp":"2024-12-18 11:56:00","answer_ET":"C","answer_images":[],"question_text":"An online retailer uses multiple delivery partners to deliver products to customers. The delivery partners send order summaries to the retailer. The retailer stores the order summaries in Amazon S3.\n\nSome of the order summaries contain personally identifiable information (PII) about customers. A data engineer needs to detect PII in the order summaries so the company can redact the PII.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","answer_description":"","isMC":true,"unix_timestamp":1734519360,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/153157-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","question_id":111},{"id":"gGTCp95FPEoQvnluWJfq","answer_ET":"B","question_id":112,"choices":{"B":"Register the S3 bucket as a data lake location in AWS Lake Formation. Use the Lake Formation row-level security features to enforce the company's access policies.","C":"Move the data to AWS Regions that are close to the countries where the customers are. Provide access to each analyst based on the country that the analyst serves.","A":"Create a separate table for each country's customer data. Provide access to each analyst based on the country that the analyst serves.","D":"Load the data into Amazon Redshift. Create a view for each country. Create separate IAM roles for each country to provide access to data from each country. Assign the appropriate roles to the analysts."},"discussion":[{"timestamp":"1715225220.0","poster":"k350Secops","content":"Selected Answer: B\nAWS Lake Formation: It's specifically designed for managing data lakes on AWS, providing capabilities for securing and controlling access to data.\nRow-Level Security: With Lake Formation, you can define fine-grained access control policies, including row-level security. This means you can enforce policies to restrict access to data based on specific conditions, such as the country associated with each customer.\nLeast Operational Effort: Once the policies are defined within Lake Formation, they can be centrally managed and applied to the data in the S3 bucket without the need for creating separate tables or views for each country, as in options A, C, and D. This reduces operational overhead and complexity.","upvote_count":"12","comment_id":"1208677"},{"poster":"dried0extents","upvote_count":"1","timestamp":"1741645560.0","content":"Selected Answer: A\nI agree that it is A","comment_id":"1387212"},{"timestamp":"1724380560.0","comment_id":"1271022","poster":"gray2205","content":"if the situation is not about least operational effort, D makes sense","upvote_count":"1"},{"content":"Selected Answer: B\nSelect B. It means \"with the LEAST operational effort\".","upvote_count":"1","timestamp":"1721268780.0","comment_id":"1250061","poster":"lunachi4"},{"timestamp":"1717367880.0","poster":"nanaw770","content":"Selected Answer: B\nB is correct answer.","upvote_count":"2","comment_id":"1223302"},{"content":"Selected Answer: B\nAWS really likes Lakeformation, plus creating separate tables might require some refactoring, and the requirements is about the LEAST operational effor","upvote_count":"1","comment_id":"1187919","poster":"mattia_besharp","timestamp":"1712044560.0"},{"timestamp":"1711560540.0","poster":"rishadhb","upvote_count":"1","comment_id":"1184254","content":"Selected Answer: A\nAgreed with Bartosz. I think setup DataLake, then integrate it with LakeFormation take a lot of effort than just separate the table"},{"comment_id":"1167768","content":"Selected Answer: B\nKeyword \"LEAST operational effort\" - I will go with B","timestamp":"1709798400.0","poster":"GiorgioGss","upvote_count":"1"},{"content":"Creating DataLake takes at least few days to set up and the solution should be LEAST operational. I think B is not correct.","timestamp":"1707381060.0","poster":"BartoszGolebiowski24","upvote_count":"2","comment_id":"1144280"},{"comment_id":"1127586","upvote_count":"3","poster":"[Removed]","timestamp":"1705803360.0","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/lake-formation/latest/dg/register-data-lake.html\nhttps://docs.aws.amazon.com/lake-formation/latest/dg/registration-role.html"}],"question_images":[],"answers_community":["B (91%)","9%"],"url":"https://www.examtopics.com/discussions/amazon/view/131714-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","answer_description":"","timestamp":"2024-01-21 03:16:00","isMC":true,"unix_timestamp":1705803360,"answer_images":[],"exam_id":21,"answer":"B","question_text":"A retail company has a customer data hub in an Amazon S3 bucket. Employees from many countries use the data hub to support company-wide analytics. A governance team must ensure that the company's data analysts can access data only for customers who are within the same country as the analysts.\nWhich solution will meet these requirements with the LEAST operational effort?","topic":"1"},{"id":"2V920AXUufLcGYllQpMI","answers_community":["B (82%)","A (18%)"],"question_id":113,"answer_images":[],"isMC":true,"topic":"1","question_images":[],"unix_timestamp":1705749600,"exam_id":21,"url":"https://www.examtopics.com/discussions/amazon/view/131684-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","answer_ET":"B","answer_description":"","answer":"B","question_text":"A company is migrating on-premises workloads to AWS. The company wants to reduce overall operational overhead. The company also wants to explore serverless options.\nThe company's current workloads use Apache Pig, Apache Oozie, Apache Spark, Apache Hbase, and Apache Flink. The on-premises workloads process petabytes of data in seconds. The company must maintain similar or better performance after the migration to AWS.\nWhich extract, transform, and load (ETL) service will meet these requirements?","discussion":[{"content":"Selected Answer: B\nGlue is like the more good-looking one, but weaker brother of EMR. So when it's about petabyte scales, let EMR do the work and have Glue stay away from the action.","timestamp":"1705749600.0","poster":"milofficial","upvote_count":"18","comment_id":"1127234"},{"poster":"Ell89","content":"Selected Answer: B\nGlue doesnt natively support Pig, HBase and Flink.","upvote_count":"1","timestamp":"1740433080.0","comment_id":"1361188"},{"content":"Selected Answer: B\nApache = EMR","comment_id":"1339176","timestamp":"1736604720.0","upvote_count":"1","poster":"Udyan"},{"upvote_count":"2","timestamp":"1730878680.0","content":"Selected Answer: B\nAmazon EMR Serverless is a deployment option for Amazon EMR that provides a serverless runtime environment. This simplifies the operation of analytics applications that use the latest open-source frameworks, such as Apache Spark and Apache Hive. With EMR Serverless, you don’t have to configure, optimize, secure, or operate clusters to run applications with these frameworks.\n\nhttps://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/emr-serverless.html","poster":"heavenlypearl","comment_id":"1307701"},{"upvote_count":"2","content":"Discarded, not 'discarted'. 'Discarted' isn't a word.","timestamp":"1729980300.0","comment_id":"1303439","poster":"87ebc7d"},{"poster":"leotoras","upvote_count":"1","comment_id":"1281169","timestamp":"1725904920.0","content":"B.\nAmazon EMR Serverless is a deployment option for Amazon EMR that provides a serverless runtime environment. This simplifies the operation of analytics applications that use the latest open-source frameworks, such as Apache Spark and Apache Hive. With EMR Serverless, you don’t have to configure, optimize, secure, or operate clusters to run applications with these frameworks."},{"poster":"Eleftheriia","upvote_count":"2","timestamp":"1724828400.0","comment_id":"1273884","content":"Selected Answer: A\nI think it is A, Glue\n• Amazon EMR is used for petabyte-scale data collection and data processing.\n• AWS Glue is used as a serverless and managed ETL service, and also used for managing data quality with AWS Glue Data Quality."},{"upvote_count":"1","comment_id":"1272408","poster":"San_Juan","content":"Selected Answer: A\nGlue.\nIt talks about \"serverless\" so EMR is discarted. The mention of Spark, Hbase, etc is for confusing you, because it doesn't say that they wanted to keep using them. Glue can run Spark using \"glueContext\" (similar a SparkContext) for reading tables, files and create frames.","timestamp":"1724647320.0"},{"content":"The company also wants to explore serverless options. ? Glue (A). or EMR Serverless","comment_id":"1264239","timestamp":"1723395480.0","upvote_count":"1","poster":"sachin"},{"upvote_count":"1","content":"Selected Answer: A\nServerless: AWS Glue is a fully managed, serverless ETL service that automates the process of data discovery, preparation, and transformation, helping minimize operational overhead.Integration with Big Data Tools: It integrates well with various AWS services and supports Spark jobs for ETL purposes, which aligns well with Apache Spark workloads.Performance: AWS Glue can handle large-scale ETL workloads, and it is designed to manage petabytes of data efficiently, comparable to the performance of on-premises solutions.While B. Amazon EMR could also be considered for its flexibility in handling big data workloads using tools like Apache Spark, it requires more management and doesn't fit the serverless requirement as closely as AWS Glue. Therefore, AWS Glue is the most suitable choice given the constraints and requirements.","comment_id":"1260935","poster":"V0811","timestamp":"1722835020.0"},{"content":"Selected Answer: B\nEMR provides a managed Hadoop framework that natively supports Apache Pig,\nOozie, Spark, and Flink. This allows the company to migrate their existing workloads with minimal code changes, reducing development effort","comment_id":"1227001","upvote_count":"3","poster":"pypelyncar","timestamp":"1717895160.0"},{"upvote_count":"2","poster":"tgv","comment_id":"1223026","timestamp":"1717306020.0","content":"Selected Answer: B\nThat's exactly the purpose of EMR. \n\n\"Amazon EMR is the industry-leading cloud big data solution for petabyte-scale data processing, interactive analytics, and machine learning using open-source frameworks such as Apache Spark, Apache Hive, and Presto.\"\n\nhttps://aws.amazon.com/emr/"},{"comment_id":"1207947","content":"Selected Answer: A\nGlue is Serverless :)","upvote_count":"3","timestamp":"1715099280.0","poster":"Just_Ninja"},{"timestamp":"1712616900.0","comment_id":"1191856","upvote_count":"2","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/ja_jp/emr/latest/ManagementGuide/emr-what-is-emr.html","poster":"wa212"},{"content":"- While AWS Glue is a fully managed ETL service and offers serverless capabilities, it might not provide the same level of performance and flexibility as Amazon EMR for handling petabyte-scale workloads with complex processing requirements.\n - AWS Glue is optimized for data integration, cataloging, and ETL jobs but may not be as well-suited for heavy-duty processing tasks that require frameworks like Apache Spark, Apache Flink, etc., which are commonly used for large-scale data processing.\n - Documentation on AWS Glue can be found in the AWS Glue Developer Guide https://docs.aws.amazon.com/glue/index.html.","poster":"certplan","timestamp":"1710955260.0","upvote_count":"2","comment_id":"1178547"},{"comment_id":"1178545","upvote_count":"2","timestamp":"1710955200.0","content":"A. AWS Glue:\nAWS Glue is a fully managed extract, transform, and load (ETL) service provided by Amazon Web Services (AWS). It allows users to prepare and load data for analytics purposes\n\nB. Amazon EMR:\nAmazon Elastic MapReduce (EMR) is a cloud-based big data platform provided by AWS. It allows users to process and analyze large amounts of data using popular frameworks such as Apache Hadoop, Apache Spark, Apache Hive, Apache HBase, and more. \n\nhttps://docs.aws.amazon.com/emr/index.html\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-best-practices.html\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-manage.html\nhttps://docs.aws.amazon.com/emr/latest/DeveloperGuide/emr-developer-guide.html\n\nAs per the AWS/Amazon docs, option B specifically calls out it out with the specific features/options that the question asked directly about.","poster":"certplan"},{"comment_id":"1167991","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html","poster":"GiorgioGss","upvote_count":"1","timestamp":"1709815680.0"},{"poster":"TonyStark0122","content":"A. AWS Glue","upvote_count":"1","comment_id":"1137945","timestamp":"1706823000.0"},{"upvote_count":"1","poster":"[Removed]","timestamp":"1705801020.0","comment_id":"1127570","content":"Selected Answer: B\nhttps://aws.amazon.com/emr/features/"}],"timestamp":"2024-01-20 12:20:00","choices":{"B":"Amazon EMR","C":"AWS Lambda","D":"Amazon Redshift","A":"AWS Glue"}},{"id":"hCILu73hTymVEyFTxAnm","answer_ET":"A","answer_images":[],"discussion":[{"comment_id":"1330747","upvote_count":"1","timestamp":"1734945900.0","poster":"HagarTheHorrible","content":"Selected Answer: A\nthe only possible answers are A and B but B wouldn't be enough."},{"upvote_count":"2","comment_id":"1328410","content":"Selected Answer: A\nRow level or column level is not enough in this case","timestamp":"1734519420.0","poster":"7a1d491"}],"question_images":[],"timestamp":"2024-12-18 11:57:00","choices":{"A":"Use the role-based access control (RBAC) feature of Amazon Redshift.","C":"Use the column-level security (CLS) feature of Amazon Redshift.","B":"Use the row-level security (RLS) feature of Amazon Redshift.","D":"Use dynamic data masking policies in Amazon Redshift."},"topic":"1","exam_id":21,"answer":"A","answer_description":"","question_text":"A company has an Amazon Redshift data warehouse that users access by using a variety of IAM roles. More than 100 users access the data warehouse every day.\n\nThe company wants to control user access to the objects based on each user's job role, permissions, and how sensitive the data is.\n\nWhich solution will meet these requirements?","isMC":true,"question_id":114,"url":"https://www.examtopics.com/discussions/amazon/view/153158-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","unix_timestamp":1734519420,"answers_community":["A (100%)"]},{"id":"rrab1DCpzsdjD8jv4jv3","topic":"1","answer_images":[],"choices":{"D":"Configure AWS Glue ETL jobs to use an Evaluate Data Quality transform. Define a data quality ruleset inside the jobs. Configure the Amazon DataZone project to have an Amazon Redshift data source. Enable the data quality configuration for the data source.","C":"Create a data quality ruleset with Data Quality Definition language (DQDL) rules that apply to a specific AWS Glue table. Schedule the ruleset to run daily. Configure the Amazon DataZone project to have an AWS Glue data source. Enable the data quality configuration for the data source.","B":"Configure AWS Glue ETL jobs to use an Evaluate Data Quality transform. Define a data quality ruleset inside the jobs. Configure the Amazon DataZone project to have an AWS Glue data source. Enable the data quality configuration for the data source.","A":"Create a data quality ruleset with Data Quality Definition language (DQDL) rules that apply to a specific AWS Glue table. Schedule the ruleset to run daily. Configure the Amazon DataZone project to have an Amazon Redshift data source. Enable the data quality configuration for the data source."},"question_images":[],"question_id":115,"answers_community":["C (100%)"],"discussion":[{"content":"Selected Answer: C\ndata zone should be configured to work with glue as data source","timestamp":"1734942840.0","poster":"HagarTheHorrible","comment_id":"1330729","upvote_count":"1"},{"timestamp":"1734519000.0","upvote_count":"1","poster":"7a1d491","content":"Selected Answer: C\nGlue has to be the data source","comment_id":"1328396"}],"exam_id":21,"isMC":true,"question_text":"A company uses Amazon DataZone as a data governance and business catalog solution. The company stores data in an Amazon S3 data lake. The company uses AWS Glue with an AWS Glue Data Catalog.\n\nA data engineer needs to publish AWS Glue Data Quality scores to the Amazon DataZone portal.\n\nWhich solution will meet this requirement?","timestamp":"2024-12-18 11:50:00","answer":"C","unix_timestamp":1734519000,"answer_description":"","answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/153156-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/"}],"exam":{"lastUpdated":"11 Apr 2025","provider":"Amazon","isBeta":false,"isMCOnly":true,"numberOfQuestions":207,"id":21,"name":"AWS Certified Data Engineer - Associate DEA-C01","isImplemented":true},"currentPage":23},"__N_SSP":true}