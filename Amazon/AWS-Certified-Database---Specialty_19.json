{"pageProps":{"questions":[{"id":"O751FB1cNePkfLbCZ4Lq","discussion":[{"upvote_count":"10","comments":[{"upvote_count":"1","poster":"novice_expert","content":"Binary Logging is now gracefully handled","comment_id":"595297","timestamp":"1651353180.0","comments":[{"timestamp":"1696095360.0","poster":"Germaneli","content":"Even if it's gracefully handled now - option D has the LEAST impact on ZDP.\nIt's not even mentioned in the list of exclusions / constraints above.","upvote_count":"1","comment_id":"1021767"}]}],"timestamp":"1646587320.0","comment_id":"562160","poster":"RotterDam","content":"Selected Answer: D\nZeroDowntime patching wont work if any of the following is true:\n- Binary Logging is Enabled\n- Long Running queries/transactions are in progress\n- Temporary Tables are in use\n- Table Locks are in use\n- SSL connections are Open\n\nBy Elimination The answer is (D) - which actually makes sense since it makes no difference to patching."},{"upvote_count":"8","timestamp":"1638819780.0","comments":[{"timestamp":"1652953020.0","upvote_count":"4","content":"The question is asking MINIMUM influence. So it's not A. The answer is D.","comment_id":"603755","poster":"khchan123"},{"poster":"Mintwater","content":"A\nZDP might not complete successfully under the following conditions:\n\nLong-running queries or transactions are in progress. If Aurora can perform ZDP in this case, any open transactions are canceled.\n\nOpen Secure Socket Layer (SSL) connections exist.\n\nTemporary tables or table locks are in use, for example while data definition language (DDL) statements run. If Aurora can perform ZDP in this case, any open transactions are canceled.\n\nPending parameter changes exist.","comment_id":"866721","timestamp":"1681173240.0","upvote_count":"1"}],"content":"I think its A\n\nIn Aurora MySQL 2.10 and higher, Aurora can perform a zero-downtime patch when binary log replication is enabled. Aurora MySQL automatically drops the connection to the binlog target during a ZDP operation. Aurora MySQL automatically reconnects to the binlog target and resumes replication after the restart finishes.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.Patching.html","poster":"grekh001","comment_id":"495376"},{"upvote_count":"1","poster":"Pranava_GCP","comment_id":"1018482","timestamp":"1695792840.0","content":"Selected Answer: A\nA. Binary logging is enabled, or binary log replication is in progress. \n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.Patching.html\n\n\"In Aurora MySQL version 2.10 and higher and version 3, Aurora can perform a zero-downtime patch whether or not binary log replication is enabled. If binary log replication is enabled, Aurora MySQL automatically drops the connection to the binlog target during a ZDP operation. Aurora MySQL automatically reconnects to the binlog target and resumes replication after the restart finishes.\""},{"timestamp":"1673124420.0","content":"Answer is A. ZDP might not complete successfully under the following conditions:\n\n\nLong-running queries or transactions are in progress. If Aurora can perform ZDP in this case, any open transactions are canceled.\nOpen Secure Socket Layer (SSL) connections exist.\nTemporary tables or table locks are in use, for example while data definition language (DDL) statements run. If Aurora can perform ZDP in this case, any open transactions are canceled.\nPending parameter changes exist.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.Patching.html","comments":[{"upvote_count":"1","timestamp":"1673124480.0","content":"lower_case_table_names parameter change need reboot","comment_id":"768911","poster":"Sathish_dbs"}],"comment_id":"768910","poster":"Sathish_dbs","upvote_count":"2"},{"upvote_count":"1","content":"Selected Answer: D\nif question likes :\nWhich element will have tnothing on ZDP's success. so we can easliy asnswer .","poster":"awsguys","timestamp":"1653223020.0","comment_id":"605489"},{"upvote_count":"1","comment_id":"605482","timestamp":"1653222780.0","poster":"awsguys","content":"MINIMUM influence os key to answer question"},{"comment_id":"595296","poster":"novice_expert","content":"Selected Answer: D\nA. Binary logging is enabled, or binary log replication is in progress. (used to block before MySQL 2.10, no longer affects ZDP )\nx B. Current SSL connections are open to the database. (affects ZDP)\nC. Temporary tables or table locks are in use.(affects ZDP)\nD. The value of the lower_case_table_names server parameter was set to 0 when the tables were created. (unrelated to ZDP)","timestamp":"1651353120.0","upvote_count":"3"},{"content":"I think D has no influence on ZDP's success and B and C has major influence, so, A should have the minimum influence.. Thoughts?","comment_id":"508295","poster":"jove","upvote_count":"2","timestamp":"1640317860.0","comments":[{"timestamp":"1644769680.0","comment_id":"546572","upvote_count":"5","comments":[{"content":"Good point. But - if it was set to 0 after tables were created, the database would've been rebooted for it to come into effect. Otherwise, nothing would change during the ZDP patch window.","timestamp":"1696095660.0","upvote_count":"1","poster":"Germaneli","comment_id":"1021773"}],"poster":"oopsy","content":"lower_case_table_names need to reboot instance"}]}],"question_text":"A media company wants to use zero-downtime patching (ZDP) for its Amazon Aurora MySQL database. Multiple processing applications are using SSL certificates to connect to database endpoints and the read replicas.\nWhich factor will have the LEAST impact on the success of ZDP?","topic":"1","unix_timestamp":1638819780,"exam_id":22,"question_images":[],"isMC":true,"question_id":91,"answer_description":"","answer":"D","timestamp":"2021-12-06 20:43:00","answers_community":["D (93%)","7%"],"url":"https://www.examtopics.com/discussions/amazon/view/67242-exam-aws-certified-database-specialty-topic-1-question-180/","answer_ET":"D","choices":{"B":"Current SSL connections are open to the database.","D":"The value of the lower_case_table_names server parameter was set to 0 when the tables were created.","A":"Binary logging is enabled, or binary log replication is in progress.","C":"Temporary tables or table locks are in use."},"answer_images":[]},{"id":"kwB3AAWtyf0jLubFyyS5","answer_images":[],"timestamp":"2021-11-14 18:51:00","answer":"C","choices":{"C":"Enable Aurora Database Activity Streams on the database in asynchronous mode. Connect the Amazon Kinesis data stream to Kinesis Data Firehose. Set the Firehose destination to an Amazon S3 bucket.","B":"Create an AWS CloudTrail trail in the Region where the database runs. Associate the database activity logs with the trail.","A":"Enable Aurora Database Activity Streams on the database in synchronous mode. Connect the Amazon Kinesis data stream to Kinesis Data Firehose. Set the Kinesis Data Firehose destination to an Amazon S3 bucket.","D":"Allow connections to the DB cluster through a bastion host only. Restrict database access to the bastion host and application servers. Push the bastion host logs to Amazon CloudWatch Logs using the CloudWatch Logs agent."},"topic":"1","answer_ET":"C","unix_timestamp":1636912260,"answers_community":["C (100%)"],"question_id":92,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/66035-exam-aws-certified-database-specialty-topic-1-question-181/","exam_id":22,"answer_description":"","question_text":"A financial services company has an application deployed on AWS that uses an Amazon Aurora PostgreSQL DB cluster. A recent audit showed that no log files contained database administrator activity. A database specialist needs to recommend a solution to provide database access and activity logs. The solution should use the least amount of effort and have a minimal impact on performance.\nWhich solution should the database specialist recommend?","discussion":[{"content":"Selected Answer: C\nC. Enable Aurora Database Activity Streams on the database in asynchronous mode.\n\nAsynchronous mode favors database performance so to alleviate performance impact.","upvote_count":"1","poster":"Pranava_GCP","comment_id":"1017188","timestamp":"1695673260.0"},{"poster":"justfmm","upvote_count":"1","comment_id":"612594","content":"If the question states that we are able to have negligible effect on performance, should we use sync mode instead as it prioritize accuracy over performance ? \n\nAsynchronous mode favors database performance over the accuracy of the activity stream.\n\nThe synchronous mode favors the accuracy of the activity stream over database performance.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/DBActivityStreams.Overview.html#DBActivityStreams.Overview.sync-mode\n\nI believe the answer should be sync mode.","timestamp":"1654580340.0"},{"upvote_count":"2","poster":"novice_expert","comment_id":"594731","timestamp":"1651275600.0","content":"Selected Answer: C\n- asynchronous mode because our solution should have negligible effect on performance"},{"comment_id":"555604","poster":"tugboat","content":"Selected Answer: C\nAsync for performance","upvote_count":"2","timestamp":"1645741020.0"},{"content":"Answer : C .. Here are the details : https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/DBActivityStreams.Overview.html","timestamp":"1638042900.0","poster":"jove","upvote_count":"4","comment_id":"488474"},{"poster":"leunamE","comment_id":"478258","upvote_count":"2","content":"Option C asynchronous mode because our solution should have negligible effect on performance","timestamp":"1636912260.0"}],"question_images":[]},{"id":"dOTvVyHQZAzO5f0JClXz","answer_images":[],"unix_timestamp":1637378220,"exam_id":22,"discussion":[{"comment_id":"755974","poster":"lollyj","timestamp":"1671998220.0","upvote_count":"2","content":"Selected Answer: B\nMulti-AZ doesn't stop the outage. B is better however the solution doesn't explain all of the necessary steps e.g. create read replica and making it primary by failing over."},{"comment_id":"711151","content":"Selected Answer: D\nOnly one answer provides high availability here.","poster":"hogtrough","timestamp":"1667566500.0","upvote_count":"2"},{"poster":"awsjjj","content":"Selected Answer: D\nKey word in the question is \"to make the DB instance highly available until the sales event ends.\" hence answer is D","timestamp":"1665839940.0","upvote_count":"3","comment_id":"695412","comments":[{"poster":"Mintwater","comment_id":"867145","upvote_count":"1","timestamp":"1681206840.0","content":"Agree with D.\nMulti-AZ can serve failover while the primary is doing the patch, the standby will be promoted as the new primary."}]},{"content":"Selected Answer: D\nD is correct because that is the only option that makes the DB highly available. \n\nThe requirement is \"The company wants to minimize downtime for the DB instance and asks a database specialist to make the DB instance highly available until the sales event ends\" \n\nThe read replica needs manual effort to be promoted to primary. Hence B is wrong.","comment_id":"668693","upvote_count":"2","timestamp":"1663139040.0","poster":"SonamDhingra"},{"comment_id":"628578","content":"B is the correct answer \n\nHow to minimize downtime using read replicas\nTypically in a self-managed or on-premises environment, a DBA minimizes downtime on an upgrade by using a rolling upgrade using read replicas. Amazon RDS doesn’t fully automate one-click rolling upgrades. However, you can still perform a rolling upgrade by creating a read replica, upgrading the replica, promoting the replica, and then routing traffic to the promoted replica.\n\nOne other caveat about upgrade downtime is how Multi-AZ fits into the picture. One common fallacy is that Multi-AZ configurations prevents downtime during an upgrade. We do recommend that you use Multi-AZ for high availability, because it can prevent extended downtime due to hardware failure or a network outage. However, in the case of a MySQL or MariaDB engine upgrade, Multi-AZ doesn’t eliminate downtime. The slow shutdown and the physical changes made on the active server by the mysql_upgrade program require this downtime.","poster":"sachin","comments":[{"poster":"db2luwdba","comments":[{"poster":"db2luwdba","content":"B is correct \nhttps://aws.amazon.com/blogs/database/best-practices-for-upgrading-amazon-rds-for-mysql-and-amazon-rds-for-mariadb/","timestamp":"1657988700.0","comment_id":"632264","upvote_count":"2"}],"timestamp":"1657988640.0","comment_id":"632263","upvote_count":"1","content":"https://aws.amazon.com/blogs/database/best-practices-for-upgrading-amazon-rds-for-mysql-and-amazon-rds-for-mariadb/"}],"upvote_count":"4","timestamp":"1657245840.0"},{"upvote_count":"2","content":"Selected Answer: D\nReading through all of the comments and the link for /rds-required-maintenance page, it's obvious that multi az is the solution to \"MINIMIZE\" the down time.","poster":"elf78","comment_id":"622682","timestamp":"1656261900.0"},{"poster":"praffuln","upvote_count":"1","timestamp":"1652702940.0","comment_id":"602568","content":"Selected Answer: A\nA should be answer. As multi-az mode will update to both db engines."},{"content":"Selected Answer: D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-required-maintenance/\n\nmulti AZ outage will be the time for failover (60 sec)","comment_id":"594734","poster":"novice_expert","upvote_count":"2","timestamp":"1651276260.0"},{"upvote_count":"1","comment_id":"584149","poster":"Sashe","content":"I'll go with B\nUsing a read replica to reduce downtime when upgrading a MySQL database\nsection - Using a read replica to reduce downtime when upgrading a MySQL database","timestamp":"1649673300.0"},{"upvote_count":"2","poster":"RotterDam","timestamp":"1646460780.0","comment_id":"561255","content":"Selected Answer: D\nIt has to be D since this wording in the question is key \"the maintenance update has been designated as necessary. \""},{"upvote_count":"1","comment_id":"557433","timestamp":"1645978680.0","poster":"user0001","content":"question is missing more info\nA is good as you keep an environment that you know is working \nwith D , you can't guaranty problem with the patch and need time to test it"},{"poster":"user0001","upvote_count":"1","comments":[{"timestamp":"1646460840.0","poster":"RotterDam","content":"the update IS mandatory. Its right there in the question: \"the maintenance update has been designated as necessary.\" - That necessitates converting the DB to Multi-AZ and since deferment is not possible due to the maint updates mandatory nature","comment_id":"561256","upvote_count":"1"}],"comment_id":"548907","timestamp":"1645042860.0","content":"i go with A,\nthe update not not urgent so they can wait"},{"content":"D. \n\nWith B, the database endpoint needs to be updated in the applications. That requires testing to ensure that the connectivity works.","poster":"awsmonster","timestamp":"1643363580.0","comment_id":"534582","upvote_count":"1"},{"content":"I prefer B\n1. This is \"database\" required maintenance.\n2. Major DB engine you need both primary and read replica downtime\n3. Miner DB engine upgrade you can upgrade read replica first.\nhttps://aws.amazon.com/blogs/database/best-practices-for-upgrading-amazon-rds-for-mysql-and-amazon-rds-for-mariadb/","comment_id":"510231","timestamp":"1640602320.0","poster":"Shunpin","upvote_count":"1"},{"upvote_count":"2","timestamp":"1639715520.0","content":"Ans is D","poster":"mnzsql365","comment_id":"503357"},{"poster":"jove","content":"Selected Answer: D\nThis explains : https://aws.amazon.com/premiumsupport/knowledge-center/rds-required-maintenance/","comment_id":"488479","upvote_count":"3","timestamp":"1638043440.0"},{"poster":"Sp230","upvote_count":"4","comment_id":"487479","timestamp":"1637940480.0","content":"I think A.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-mysql-downtime-impact/\n \"the DB engine version upgrade happens to both the primary and standby hosts at the same time. Therefore, a DB engine version upgrade doesn't benefit from a Multi-AZ deployment\""},{"upvote_count":"1","poster":"GaryY","timestamp":"1637378220.0","comment_id":"482240","content":"Answer is D"}],"question_id":93,"choices":{"A":"Defer the maintenance update until the sales event is over.","D":"Convert the DB instance into a Multi-AZ deployment. Apply the maintenance update.","B":"Create a read replica with the latest update. Initiate a failover before the sales event.","C":"Create a read replica with the latest update. Transfer all read-only traffic to the read replica during the sales event."},"question_images":[],"isMC":true,"question_text":"A company uses a single-node Amazon RDS for MySQL DB instance for its production database. The DB instance runs in an AWS Region in the United States.\nA week before a big sales event, a new maintenance update is available for the DB instance. The maintenance update is marked as required. The company wants to minimize downtime for the DB instance and asks a database specialist to make the DB instance highly available until the sales event ends.\nWhich solution will meet these requirements?","topic":"1","answers_community":["D (84%)","Other"],"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/66371-exam-aws-certified-database-specialty-topic-1-question-182/","answer_ET":"D","answer_description":"","timestamp":"2021-11-20 04:17:00"},{"id":"3EOpZNZGCeIub2QKrvdU","answer_ET":"D","timestamp":"2021-11-11 14:42:00","exam_id":22,"unix_timestamp":1636638120,"answer_images":[],"question_text":"A company is migrating a database in an Amazon RDS for SQL Server DB instance from one AWS Region to another. The company wants to minimize database downtime during the migration.\nWhich strategy should the company choose for this cross-Region migration?","choices":{"A":"Back up the source database using native backup to an Amazon S3 bucket in the same Region. Then restore the backup in the target Region.","B":"Back up the source database using native backup to an Amazon S3 bucket in the same Region. Use Amazon S3 Cross-Region Replication to copy the backup to an S3 bucket in the target Region. Then restore the backup in the target Region.","D":"Add an RDS for SQL Server cross-Region read replica in the target Region. Once the replication is in sync, promote the read replica to master.","C":"Configure AWS Database Migration Service (AWS DMS) to replicate data between the source and the target databases. Once the replication is in sync, terminate the DMS task."},"answer":"D","topic":"1","answer_description":"","discussion":[{"comment_id":"477831","upvote_count":"13","content":"Minimum downtime > AWS DMS : Option C","timestamp":"1636842420.0","poster":"jove"},{"comment_id":"733875","timestamp":"1669994940.0","upvote_count":"10","content":"Selected Answer: D\nAmazon RDS for SQL Server now support Cross Region Read Replica that can be promoted to standalone instance.\nSo Answer D is the best fit .","poster":"Sab"},{"upvote_count":"1","comment_id":"1002979","poster":"chen0305_099","timestamp":"1694240760.0","content":"Selected Answer: C\nCCCCCCC"},{"upvote_count":"1","content":"Selected Answer: C\nC is supported now","comment_id":"932829","poster":"navkumin","timestamp":"1687629360.0"},{"poster":"tucobbad","timestamp":"1672157940.0","comment_id":"758772","upvote_count":"2","content":"Now Read Replica for RDS SQL Server is supported. Now what? Go with C or D? BTW, does AWS update their exams with new features?"},{"upvote_count":"1","comment_id":"723889","timestamp":"1669062900.0","content":"Amazon RDS for SQL Server now support Cross Region Read Replica that can be promoted to standalone instance. \nSo Answer D is the best fit .","poster":"Sab"},{"comment_id":"660225","timestamp":"1662385740.0","comments":[{"upvote_count":"3","comment_id":"677398","timestamp":"1663960680.0","content":"From link, \"SQL Server MS Replication is one such feature that, as of this writing, isn’t yet available in Amazon RDS for SQL Server. However, you can to use AWS Database Migration Service (AWS DMS) to do continuous replication\"","comments":[{"content":"Agree with you - C\nAfter reviewing the link.","comment_id":"846304","timestamp":"1679429520.0","upvote_count":"1","poster":"Mintwater"}],"poster":"JeanGat"}],"content":"Cross-Region disaster recovery of Amazon RDS for SQL Server - is possible https://aws.amazon.com/blogs/database/cross-region-disaster-recovery-of-amazon-rds-for-sql-server/. Why not D?","poster":"Adi_M","upvote_count":"1"},{"poster":"sachin","upvote_count":"1","timestamp":"1655859900.0","content":"C will provide minimum down time","comment_id":"620078"},{"comments":[{"comment_id":"903944","timestamp":"1684752180.0","content":"As of Nov 16, 2022 cross-Region read replica IS supported :)\n\nHopefully the exams have been updated to reflect this.","upvote_count":"2","poster":"aviathor"}],"poster":"novice_expert","comment_id":"594633","upvote_count":"2","timestamp":"1651255380.0","content":"Selected Answer: C\nA. slow\nB. slow \nC. source-> AWS DMS -> target region database -> sync -> terminate DMS\nD. cross-Region read replica not supported"},{"comments":[{"content":"- Creating a read replica in a different AWS Region (a cross-Region read replica) \nis supported. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html","poster":"Sathish_dbs","upvote_count":"1","comment_id":"768929","timestamp":"1673126400.0"}],"poster":"Dantas","upvote_count":"3","timestamp":"1647158520.0","content":"Selected Answer: C\nOption C.\n\nThe following aren't supported on Amazon RDS for SQL Server:\n- Creating a read replica in a different AWS Region (a cross-Region read replica)\n- Backup retention of read replicas\n- Point-in-time recovery from read replicas\n- Manual snapshots of read replicas\n- Multi-AZ read replicas\n- Creating read replicas of read replicas\n- Synchronization of user logins to read replicas\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html","comment_id":"566613"},{"upvote_count":"1","timestamp":"1645736760.0","comment_id":"555559","content":"Selected Answer: C\nA and B will be slow\nD is not possible yet","poster":"tugboat"},{"content":"C\nMinimum downtime > AWS DMS","comment_id":"548455","upvote_count":"1","poster":"yahooos","timestamp":"1645004340.0"},{"timestamp":"1639288740.0","content":"A - for me, the question is about transferring database from one region to another. Native backup restore is supported for RDS SQL Server using S3.","comments":[{"upvote_count":"2","comment_id":"561168","timestamp":"1646453700.0","content":"you missed the \"minimum downtime\"","poster":"RotterDam"}],"upvote_count":"1","comment_id":"499815","poster":"mnzsql365"},{"upvote_count":"4","content":"C for me \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.XRgn.html\nWith Amazon RDS, you can create a MariaDB, MySQL, Oracle, or PostgreSQL read replica in a different AWS Region from the source DB instance. Creating a cross-Region read replica isn't supported for SQL Server on Amazon RDS.","poster":"nood","timestamp":"1639063500.0","comment_id":"497836"},{"timestamp":"1638613560.0","comment_id":"493644","content":"Option B seems correct from https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.Procedural.Importing.html, yet there is a requirement that throughout the transfer that the downtime needs to be minimal, therefore, AWS DMS would be the choice to fulfill the requirement. For detail, one can refer to this blog post, https://aws.amazon.com/blogs/database/replicate-and-transform-data-in-amazon-aurora-postgresql-across-multiple-regions-using-aws-dms/, and notice that AWS DMS supports abundant sources and targets.","comments":[{"timestamp":"1658456400.0","content":"maybe you mean C","comment_id":"634949","poster":"eji","upvote_count":"1"}],"poster":"scottkerker","upvote_count":"2"},{"poster":"Tonytt","comment_id":"476304","upvote_count":"4","timestamp":"1636642140.0","content":"should be C"},{"poster":"[Removed]","content":"A,B - No minimal downtime\nD- Cross Region replica not supported for RDS SQL Server\nAns : C","upvote_count":"6","timestamp":"1636638120.0","comment_id":"476238"}],"answers_community":["D (56%)","C (44%)"],"question_id":94,"url":"https://www.examtopics.com/discussions/amazon/view/65834-exam-aws-certified-database-specialty-topic-1-question-183/","question_images":[],"isMC":true},{"id":"xh1cAI8yKCtuxcaMAvWS","answer_images":[],"answer":"B","unix_timestamp":1636719660,"choices":{"B":"Use the point-in-time restore capability to restore the DB instance to the specified time. Change the application connection string to the new, restored DB instance.","A":"Use the point-in-time restore capability to restore the DB instance to the specified time. No changes to the application connection string are required.","D":"Restore using the appropriate automated backup. No changes to the application connection string are required.","C":"Restore using the latest automated backup. Change the application connection string to the new, restored DB instance."},"answer_description":"","question_id":95,"answer_ET":"B","timestamp":"2021-11-12 13:21:00","exam_id":22,"discussion":[{"timestamp":"1636912800.0","upvote_count":"17","comment_id":"478260","content":"It has to be B \"Please note: When you perform a restore operation to a point in time or from a DB Snapshot, a new DB Instance is created with a new endpoint (the old DB Instance can be deleted if so desired). This is done to enable you to create multiple DB Instances from a specific DB Snapshot or point in time.\"","poster":"johnconnor"},{"upvote_count":"1","content":"Selected Answer: B\nB. Use the point-in-time restore capability to restore the DB instance to the specified time. Change the application connection string to the new, restored DB instance.","poster":"Pranava_GCP","timestamp":"1693456380.0","comment_id":"994743"},{"comment_id":"864658","poster":"mbadioum","upvote_count":"1","content":"B is right\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIT.html","timestamp":"1680954420.0"},{"upvote_count":"1","content":"Selected Answer: B\nB - New Instance Creates, need to change connection string from application.\nA - Not correct. Not inplace PITR, this feature support in Aurora Mysql","timestamp":"1673178360.0","comment_id":"769341","poster":"praffuln"},{"comment_id":"594749","content":"Selected Answer: B\nrestore operation to a point in time or from a DB Snapshot, a new DB Instance is created","timestamp":"1651278960.0","upvote_count":"4","poster":"novice_expert"},{"poster":"RotterDam","comment_id":"562566","timestamp":"1646652300.0","upvote_count":"1","content":"Got this question in my exam. (i cleared it). B is correct"},{"poster":"tugboat","timestamp":"1645742160.0","comment_id":"555619","upvote_count":"2","content":"Selected Answer: B\nPoint app to restored instance"},{"comment_id":"522824","poster":"szl0144","content":"I vote C","upvote_count":"1","timestamp":"1642077060.0"},{"upvote_count":"4","poster":"jove","content":"Selected Answer: B\nPIT restore requires a new instance to be created. Hence, the answer is B","comment_id":"509324","timestamp":"1640472840.0"},{"timestamp":"1638280860.0","content":"B is the correct one","comment_id":"490737","upvote_count":"1","poster":"Justu"},{"comment_id":"476918","content":"Option B.","timestamp":"1636719660.0","poster":"leunamE","upvote_count":"2"}],"question_images":[],"question_text":"A financial company is hosting its web application on AWS. The application's database is hosted on Amazon RDS for MySQL with automated backups enabled.\nThe application has caused a logical corruption of the database, which is causing the application to become unresponsive. The specific time of the corruption has been identified, and it was within the backup retention period.\nHow should a database specialist recover the database to the most recent point before corruption?","url":"https://www.examtopics.com/discussions/amazon/view/65888-exam-aws-certified-database-specialty-topic-1-question-184/","isMC":true,"answers_community":["B (100%)"],"topic":"1"}],"exam":{"isMCOnly":false,"isImplemented":true,"provider":"Amazon","name":"AWS Certified Database - Specialty","numberOfQuestions":359,"id":22,"isBeta":false,"lastUpdated":"11 Apr 2025"},"currentPage":19},"__N_SSP":true}