{"pageProps":{"questions":[{"id":"k0O3FqIzz6eVnAiLJv3j","answers_community":["D (63%)","C (38%)"],"answer_images":[],"exam_id":26,"discussion":[{"poster":"endeesa","content":"Selected Answer: D\nD makes more sence to me. Collaborative filtering takes into account other users preferences which is what we want to avoid because we do not want irrelevant promotions","upvote_count":"7","timestamp":"1701207660.0","comment_id":"1082969"},{"comment_id":"1298415","timestamp":"1729019820.0","upvote_count":"1","content":"Selected Answer: C\nAnswer 'C' is better for efficiency","poster":"MultiCloudIronMan"},{"timestamp":"1728397620.0","upvote_count":"1","comment_id":"1294745","content":"As per the documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html\n\nFactorization machines are a good choice for tasks dealing with high dimensional sparse datasets, such as click prediction and item recommendation.\n\nAnd factorization machines is better with sparse data.","poster":"amlgeek"},{"poster":"JonSno","comment_id":"1206746","timestamp":"1714873800.0","upvote_count":"1","content":"C. Use the Neural Collaborative Filtering algorithm with a SageMaker batch inference job\n\nThis solution uses the Neural Collaborative Filtering algorithm to leverage the latest techniques in recommendation systems, while SageMaker's batch inference jobs provide efficient and cost-effective processing of recommendations in bulk. This aligns well with the company's weekly email campaigns and minimizes operational overhead."},{"poster":"DimLam","upvote_count":"1","comment_id":"1053452","content":"Selected Answer: D\nI will go with D, as it is more operationally eficient","timestamp":"1698209520.0"},{"comment_id":"1005776","content":"Selected Answer: C\nA. NO - Factorization Machines is classification\nB. NO - an endpoint needed be invoked \nC. YES - Collaborative Filtering is good for recommendations based on past activities, and a batch job will generate the fiel we want \nD. NO - Factorization Machines is classification","timestamp":"1694524200.0","poster":"loict","upvote_count":"3"},{"poster":"chet100","upvote_count":"1","comment_id":"997065","content":"My choice D","timestamp":"1693679640.0"},{"upvote_count":"1","comment_id":"992731","content":"factorization machine algorithm is used for regression or classification. Generating recommendation is neither. Use neural collaborative filtering and do batch inference to identify email addresses.","timestamp":"1693275960.0","poster":"ashii007"},{"comment_id":"981311","content":"From Chat GPT\nThe solution that will meet the requirements with the MOST operational efficiency is option C: Use the Neural Collaborative Filtering algorithm to build a model that can generate personalized offer recommendations for customers. Deploy a SageMaker batch inference job to generate offer recommendations. Feed the offer recommendations into the bulk email marketing system.\n\nBy using the Neural Collaborative Filtering algorithm, the ML team can build a model that can provide personalized offer recommendations based on customer profiles and past accepted offers. Deploying a SageMaker batch inference job allows for efficient processing of a large batch of customer data to generate offer recommendations. These recommendations can then be fed directly into the bulk email marketing system, streamlining the process and improving operational efficiency.","poster":"strike3test","timestamp":"1692076620.0","upvote_count":"3"},{"content":"Selected Answer: D\n: Use the Factorization Machines algorithm to build a model that can generate personalized offer recommendations for customers. Deploy a SageMaker batch inference job to generate offer recommendations. Feed the offer recommendations into the bulk email marketing system","timestamp":"1691077860.0","poster":"Mickey321","comment_id":"971273","comments":[{"timestamp":"1691078040.0","upvote_count":"3","content":", option D is more operationally efficient.","comment_id":"971274","poster":"Mickey321"}],"upvote_count":"2"},{"upvote_count":"2","timestamp":"1690303620.0","poster":"awsarchitect5","comment_id":"962904","content":"Selected Answer: C\nC batch predictions and collaborative"},{"content":"C is a better option for efficiency.","timestamp":"1688787300.0","comment_id":"946129","poster":"ADVIT","upvote_count":"2"}],"question_id":176,"choices":{"C":"Use the Neural Collaborative Filtering algorithm to build a model that can generate personalized offer recommendations for customers. Deploy a SageMaker batch inference job to generate offer recommendations. Feed the offer recommendations into the bulk email marketing system.","B":"Use the Neural Collaborative Filtering algorithm to build a model that can generate personalized offer recommendations for customers. Deploy a SageMaker endpoint to generate offer recommendations. Feed the offer recommendations into the bulk email marketing system.","A":"Use the Factorization Machines algorithm to build a model that can generate personalized offer recommendations for customers. Deploy a SageMaker endpoint to generate offer recommendations. Feed the offer recommendations into the bulk email marketing system.","D":"Use the Factorization Machines algorithm to build a model that can generate personalized offer recommendations for customers. Deploy a SageMaker batch inference job to generate offer recommendations. Feed the offer recommendations into the bulk email marketing system."},"answer_description":"","question_images":[],"isMC":true,"unix_timestamp":1688787300,"topic":"1","answer_ET":"D","answer":"D","question_text":"A financial company sends special offers to customers through weekly email campaigns. A bulk email marketing system takes the list of email addresses as an input and sends the marketing campaign messages in batches. Few customers use the offers from the campaign messages. The company does not want to send irrelevant offers to customers.\n\nA machine learning (ML) team at the company is using Amazon SageMaker to build a model to recommend specific offers to each customer based on the customer's profile and the offers that the customer has accepted in the past.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","timestamp":"2023-07-08 05:35:00","url":"https://www.examtopics.com/discussions/amazon/view/114475-exam-aws-certified-machine-learning-specialty-topic-1/"},{"id":"b1WxgzBI71TxExzrkc4r","answers_community":["D (100%)"],"exam_id":26,"timestamp":"2023-06-23 16:14:00","answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/113104-exam-aws-certified-machine-learning-specialty-topic-1/","answer_description":"","answer_images":[],"question_id":177,"answer_ET":"D","question_text":"A social media company wants to develop a machine learning (ML) model to detect inappropriate or offensive content in images. The company has collected a large dataset of labeled images and plans to use the built-in Amazon SageMaker image classification algorithm to train the model. The company also intends to use SageMaker pipe mode to speed up the training.\n\nThe company splits the dataset into training, validation, and testing datasets. The company stores the training and validation images in folders that are named Training and Validation, respectively. The folders contain subfolders that correspond to the names of the dataset classes. The company resizes the images to the same size and generates two input manifest files named training.lst and validation.lst, for the training dataset and the validation dataset, respectively. Finally, the company creates two separate Amazon S3 buckets for uploads of the training dataset and the validation dataset.\n\nWhich additional data preparation steps should the company take before uploading the files to Amazon S3?","choices":{"C":"Compress the training and validation directories by using the gzip compression library. Upload the manifest and compressed files to the training S3 bucket.","A":"Generate two Apache Parquet files, training.parquet and validation.parquet, by reading the images into a Pandas data frame and storing the data frame as a Parquet file. Upload the Parquet files to the training S3 bucket.","B":"Compress the training and validation directories by using the Snappy compression library. Upload the manifest and compressed files to the training S3 bucket.","D":"Generate two RecordIO files, training.rec and validation.rec, from the manifest files by using the im2rec Apache MXNet utility tool. Upload the RecordIO files to the training S3 bucket."},"topic":"1","question_images":[],"unix_timestamp":1687529640,"discussion":[{"upvote_count":"4","timestamp":"1725503700.0","comment_id":"1166221","content":"Selected Answer: D\nAmazon SageMaker's built-in image classification algorithm supports input data in RecordIO format for training. RecordIO is a binary file format that efficiently stores images and labels in a compact format, making it suitable for training deep learning models with large datasets. The im2rec utility tool provided by Apache MXNet can be used to generate RecordIO files from the manifest files (training.lst and validation.lst) containing image paths and labels. Using RecordIO files allows for efficient streaming of data during training, especially when combined with SageMaker's pipe mode, which can speed up the training process by reducing disk I/O.","poster":"AIWave"},{"comment_id":"1005783","content":"Selected Answer: D\nA. NO - SageMaker requires RecordIO input\nB. NO - SageMaker requires RecordIO input\nC. NO - SageMaker requires RecordIO input\nD. YES - SageMaker requires RecordIO input","poster":"loict","upvote_count":"2","timestamp":"1710256560.0"},{"upvote_count":"1","content":"Selected Answer: D\nIf they want to use the RecordIO content type for training in pipe mode, they should generate two RecordIO files, training.rec and validation.rec, from the manifest files by using the im2rec Apache MXNet utility tool1. They should upload the RecordIO files to the training S3 bucket. This corresponds to option D in the question.","comment_id":"971281","poster":"Mickey321","timestamp":"1706983200.0"},{"comment_id":"962908","content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/machine-learning/classify-your-own-images-using-amazon-sagemaker/","timestamp":"1706208840.0","upvote_count":"1","poster":"awsarchitect5"},{"comment_id":"946134","timestamp":"1704692640.0","content":"Selected Answer: D\nIt's D.\nhttps://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-fulltraining.html","poster":"ADVIT","upvote_count":"1"},{"upvote_count":"4","timestamp":"1703348040.0","content":"should be D.he company wants to use the Amazon SageMaker image classification algorithm to train the model. SageMaker's image classification algorithm requires the data to be in the RecordIO format. Therefore, the company should use the im2rec utility tool, which is part of the Apache MXNet framework, to generate RecordIO files from the manifest files.\n\nThe company should generate two RecordIO files, one for the training dataset (training.rec) and one for the validation dataset (validation.rec). These RecordIO files will contain the image data along with their corresponding labels.","poster":"xinyingw","comment_id":"931690"}],"isMC":true},{"id":"w8K7vbq9fSGPE6yFeqjo","exam_id":26,"topic":"1","answer_description":"","unix_timestamp":1688788080,"answer_images":[],"timestamp":"2023-07-08 05:48:00","answer_ET":"C","question_text":"A media company wants to create a solution that identifies celebrities in pictures that users upload. The company also wants to identify the IP address and the timestamp details from the users so the company can prevent users from uploading pictures from unauthorized locations.\n\nWhich solution will meet these requirements with LEAST development effort?","question_images":[],"choices":{"B":"Use AWS Panorama to identify celebrities in the pictures. Make calls to the AWS Panorama Device SDK to capture IP address and timestamp details.","C":"Use Amazon Rekognition to identify celebrities in the pictures. Use AWS CloudTrail to capture IP address and timestamp details.","A":"Use AWS Panorama to identify celebrities in the pictures. Use AWS CloudTrail to capture IP address and timestamp details.","D":"Use Amazon Rekognition to identify celebrities in the pictures. Use the text detection feature to capture IP address and timestamp details."},"discussion":[{"poster":"ec8or","comment_id":"1189689","upvote_count":"3","content":"Its B. CloudTrail records API calls for AWS USERS in AWS accounts. It has nothing to do with some random users who submit pictures via an app. CloudTrail is NOT the answer.","timestamp":"1728111060.0"},{"poster":"vkbajoria","timestamp":"1727651760.0","comment_id":"1186473","content":"Selected Answer: C\nRekognition and cloud trail","upvote_count":"1"},{"timestamp":"1710256740.0","comment_id":"1005790","content":"Selected Answer: C\nA. NO - AWS Panorama is for edge computing\nB. NO - AWS Panorama is for edge computing\nC. YES - best practice\nD. NO - IP address cannot be captured from the image, but from internet traffic","upvote_count":"2","poster":"loict"},{"content":"Selected Answer: C\nAgree with C","timestamp":"1708687440.0","upvote_count":"3","poster":"Mickey321","comment_id":"988143"},{"content":"Selected Answer: C\nC. Rekognition text detection is for text inside image and not for source ip.","upvote_count":"2","timestamp":"1706210400.0","comment_id":"962938","poster":"awsarchitect5"},{"content":"C or D but CloudTrail detect IP only of API calls and not record API call for Invoke_Model.","comment_id":"946139","poster":"ADVIT","upvote_count":"1","timestamp":"1704692880.0"}],"question_id":178,"answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/114477-exam-aws-certified-machine-learning-specialty-topic-1/","answers_community":["C (100%)"],"isMC":true},{"id":"5mjAUEj7g8ZzKO6SXKuw","isMC":true,"question_id":179,"answer":"AC","answer_description":"","question_images":[],"discussion":[{"timestamp":"1729778220.0","content":"Selected Answer: AC\nA. LDA is designed to discover abstract topics in a collection of documents. It is commonly used for topic modeling and is one of the most popular techniques for extracting topics from text data.\n\nC. NTM is also used in topic modeling. It uses deep learning to discover topics in a collection of documents, and it can produce similar results to LDA but potentially with better accuracy due to its neural network foundation.\n\nIncorrect choices:\n\nB. Random forest classifier is a classification algorithm. It is better suited for classification tasks based on labeled data.\n\nD. SVM is also a classification algorithm. It works well for binary classification problems.\n\nE. Linear regression is a regression algorithm used to predict continuous values. It's not suitable for topic modeling.","comment_id":"1052902","poster":"seifskl","upvote_count":"5"},{"comment_id":"1082970","content":"Selected Answer: AC\nLDA and NTM are the only applicable options for topic modelling here","timestamp":"1732830600.0","upvote_count":"1","poster":"endeesa"},{"content":"Selected Answer: AC\nA. YES\nB. NO - for classification \nC. YES\nD. NO - for classification \nE. NO - for classification","upvote_count":"2","poster":"loict","timestamp":"1726149300.0","comment_id":"1005819"},{"upvote_count":"1","timestamp":"1724400360.0","comment_id":"988084","poster":"Mickey321","content":"Selected Answer: AC\nboth unsupervised learning algorithms that can discover abstract topics in a collection of text documents . These algorithms can help the data scientist to analyze the audit documents and provide a list of the top words for each category to help the auditors assess the relevance of the topic. LDA and NTM are different from other algorithms that are not suitable for this scenario, such as:"},{"comment_id":"962940","poster":"awsarchitect5","timestamp":"1721928120.0","upvote_count":"1","content":"Selected Answer: AC\nAC for topics"},{"comment_id":"942200","timestamp":"1720038060.0","poster":"worldboss","upvote_count":"4","content":"Although you can use both the Amazon SageMaker NTM and LDA algorithms for topic modeling, they are distinct algorithms and can be expected to produce different results on the same input data.\n\nA and C\n\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/ntm.html\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/lda.html"}],"question_text":"A pharmaceutical company performs periodic audits of clinical trial sites to quickly resolve critical findings. The company stores audit documents in text format. Auditors have requested help from a data science team to quickly analyze the documents. The auditors need to discover the 10 main topics within the documents to prioritize and distribute the review work among the auditing team members. Documents that describe adverse events must receive the highest priority.\n\nA data scientist will use statistical modeling to discover abstract topics and to provide a list of the top words for each category to help the auditors assess the relevance of the topic.\n\nWhich algorithms are best suited to this scenario? (Choose two.)","unix_timestamp":1688415660,"answer_images":[],"answers_community":["AC (100%)"],"choices":{"A":"Latent Dirichlet allocation (LDA)","D":"Linear support vector machine","E":"Linear regression","C":"Neural topic modeling (NTM)","B":"Random forest classifier"},"timestamp":"2023-07-03 22:21:00","answer_ET":"AC","url":"https://www.examtopics.com/discussions/amazon/view/114030-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","exam_id":26},{"id":"2EuSDtuw18opdj7EekJG","answers_community":["A (100%)"],"discussion":[{"poster":"seifskl","comment_id":"1052909","timestamp":"1729778580.0","content":"Selected Answer: A\nA. Amazon Kendra is designed to search through various types of documents and provide relevant answers.\n\nB. Training a BiDAF network requires expertise in deep learning and natural language processing. It would require substantial effort in data preparation, model training, and integration.\n\nC. Amazon SageMaker Blazing Text is primarily used for text classification and word embeddings, not for extracting answers from company documents based on user queries.\n\nD. Amazon OpenSearch Service is a search and analytics engine, but it's not tailored for extracting precise answers from documents. The k-NN Query API is used for similarity searches and isn't inherently designed to answer questions based on document content.","upvote_count":"6"},{"content":"Selected Answer: A\nAmazon Kendra is a managed search service that helps you find answers to your questions from your content. It uses natural language processing and machine learning to understand the meaning of your questions and match them to the most relevant content.","upvote_count":"2","comment_id":"988065","timestamp":"1724398860.0","poster":"Mickey321"},{"comment_id":"984518","poster":"kaike_reis","content":"Selected Answer: A\nA is the correct. All the others are really hard.","timestamp":"1723987260.0","upvote_count":"1"},{"timestamp":"1720410840.0","upvote_count":"1","poster":"ADVIT","comment_id":"946146","content":"Selected Answer: A\nFor sure A."},{"poster":"kukreti18","comment_id":"945586","content":"A is correct\nAmazon Kendra is an intelligent search service powered by machine learning. It can be used to index and search through company documents, making it a suitable solution for the chatbot to base its answers on.\nOption A suggests indexing company documents using Amazon Kendra, which simplifies the process of searching and retrieving relevant information from the documentation.\nIntegrating the chatbot with Amazon Kendra using the Kendra Query API operation allows the chatbot to send customer questions to Kendra and receive relevant answers based on the indexed documents.\nThis solution requires minimal development effort as it leverages the built-in capabilities of Amazon Kendra and its integration with the chatbot.\nOption B, training a Bidirectional Attention Flow (BiDAF) network, and option C, training a SageMaker Blazing Text model, both involve training custom models, which would require significant development effort, including data preparation, model training, and deployment.","upvote_count":"2","timestamp":"1720350900.0"}],"topic":"1","exam_id":26,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/114427-exam-aws-certified-machine-learning-specialty-topic-1/","question_text":"A company needs to deploy a chatbot to answer common questions from customers. The chatbot must base its answers on company documentation.\n\nWhich solution will meet these requirements with the LEAST development effort?","question_id":180,"answer":"A","timestamp":"2023-07-07 13:15:00","answer_ET":"A","question_images":[],"answer_description":"","unix_timestamp":1688728500,"answer_images":[],"choices":{"D":"Index company documents by using Amazon OpenSearch Service. Integrate the chatbot with OpenSearch Service by using the OpenSearch Service k-nearest neighbors (k-NN) Query API operation to answer customer questions.","C":"Train an Amazon SageMaker Blazing Text model based on past customer questions and company documents. Deploy the model as a real-time SageMaker endpoint. Integrate the model with the chatbot by using the SageMaker Runtime InvokeEndpoint API operation to answer customer questions.","A":"Index company documents by using Amazon Kendra. Integrate the chatbot with Amazon Kendra by using the Amazon Kendra Query API operation to answer customer questions.","B":"Train a Bidirectional Attention Flow (BiDAF) network based on past customer questions and company documents. Deploy the model as a real-time Amazon SageMaker endpoint. Integrate the model with the chatbot by using the SageMaker Runtime InvokeEndpoint API operation to answer customer questions."}}],"exam":{"isMCOnly":false,"id":26,"isBeta":false,"numberOfQuestions":369,"lastUpdated":"11 Apr 2025","name":"AWS Certified Machine Learning - Specialty","isImplemented":true,"provider":"Amazon"},"currentPage":36},"__N_SSP":true}