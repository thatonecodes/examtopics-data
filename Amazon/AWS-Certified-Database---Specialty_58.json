{"pageProps":{"questions":[{"id":"V1nXRyRNvWxJLR52bvCN","timestamp":"2024-03-03 10:41:00","unix_timestamp":1709458860,"question_text":"A company has more than 100 AWS accounts that need Amazon RDS instances. The company wants to build an automated solution to deploy the RDS instances with specific compliance parameters. The data does not need to be replicated. The company needs to create the databases within 1 day.\n\nWhich solution will meet these requirements in the MOST operationally efficient way?","question_images":[],"question_id":286,"answer_ET":"A","answer":"A","answers_community":["A (100%)"],"exam_id":22,"choices":{"C":"Use AWS CloudFormation to create RDS instances in each account. Run AWS Database Migration Service (AWS DMS) replication to each of the created instances.","D":"Create a script by using the AWS CLI to copy the RDS instance into the other accounts from a template account.","A":"Create RDS resources by using AWS CloudFormation. Share the CloudFormation template with each account.","B":"Create an RDS snapshot. Share the snapshot with each account. Deploy the snapshot into each account."},"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/135107-exam-aws-certified-database-specialty-topic-1-question-356/","discussion":[{"poster":"tsangckl","comment_id":"1193517","content":"Selected Answer: A\nAWS CloudFormation provides a common language for you to describe and provision all the infrastructure resources in your cloud environment. It allows you to use a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all regions and accounts. This file serves as the single source of truth for your cloud environment.","upvote_count":"1","timestamp":"1712819640.0"},{"upvote_count":"3","comment_id":"1164664","poster":"fceb2c1","content":"Selected Answer: A\nA\n\nOption C - Wrong: (Use AWS CloudFormation to create RDS instances and run AWS DMS replication) introduces unnecessary complexity by involving AWS DMS replication, which is not needed according to the requirements. It may also prolong the deployment process.","timestamp":"1709458860.0"}],"answer_images":[],"isMC":true,"topic":"1"},{"id":"UKKbNzHreqEMgZm4x5Vx","isMC":true,"question_images":[],"answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/135108-exam-aws-certified-database-specialty-topic-1-question-357/","question_id":287,"exam_id":22,"answer":"D","unix_timestamp":1709459160,"answer_images":[],"answer_description":"","topic":"1","discussion":[{"comment_id":"1193519","content":"Selected Answer: D\nAmazon Aurora PostgreSQL with Babelfish provides a new way to run SQL Server applications on PostgreSQL. Babelfish understands the SQL Server wire protocol (TDS) and T-SQL, the SQL Server query language. By using Babelfish, you can switch from SQL Server to Aurora PostgreSQL with minimal effort and reduce the cost because Aurora PostgreSQL is less expensive than SQL Server.","upvote_count":"1","timestamp":"1712819700.0","poster":"tsangckl"},{"upvote_count":"1","poster":"kenlevi","comment_id":"1180476","content":"https://aws.amazon.com/cn/blogs/database/migrate-from-sql-server-to-amazon-aurora-using-babelfish/","timestamp":"1711161540.0"},{"content":"Selected Answer: D\nD. Use AWS Database Migration Service (DMS) to migrate the database to Amazon Aurora PostgreSQL. Turn on Babelfish for Aurora PostgreSQL. Update the application to use the Babelfish TDS port.","timestamp":"1709459160.0","comment_id":"1164670","upvote_count":"2","poster":"fceb2c1"}],"answer_ET":"D","timestamp":"2024-03-03 10:46:00","question_text":"A database specialist needs to reduce the cost of an application's database. The database is running on a Multi-AZ deployment of an Amazon RDS for Microsoft SQL Server DB instance. The application requires the database to support stored procedures, SQL Server Wire Protocol (TDS), and T-SQL. The database must also be highly available. The database specialist is using AWS Database Migration Service (AWS DMS) to migrate the database to a new data store.\n\nWhich solution will reduce the cost of the database with the LEAST effort?","choices":{"B":"Use AWS Database Migration Service (DMS) to migrate to an RDS for PostgreSQL Multi-AZ database. Turn on the SQL_COMPAT optional extension within the database to allow the required features. Update the application to use the PostgreSQL port.","D":"Use AWS Database Migration Service (DMS) to migrate the database to Amazon Aurora PostgreSQL. Turn on Babelfish for Aurora PostgreSQL. Update the application to use the Babelfish TDS port.","C":"Use AWS Database Migration Service (DMS) to migrate to an RDS for SQL Server Single-AZ database. Update the application to use the new database endpoint.","A":"Use AWS Database Migration Service (DMS) to migrate to an RDS for MySQL Multi-AZ database. Update the application code to use the features of MySQL that correspond to SQL Server. Update the application to use the MySQL port."}},{"id":"cnYthcPGJPh30GpOws1G","url":"https://www.examtopics.com/discussions/amazon/view/135109-exam-aws-certified-database-specialty-topic-1-question-358/","timestamp":"2024-03-03 10:49:00","discussion":[{"timestamp":"1709691300.0","poster":"must_be_rohit","content":"Selected Answer: C\nC is the right answer","upvote_count":"1","comment_id":"1166878"},{"timestamp":"1709459340.0","poster":"fceb2c1","comment_id":"1164673","content":"Selected Answer: C\nC. Deploy an Amazon DynamoDB database with global tables.","upvote_count":"2"}],"unix_timestamp":1709459340,"answer_images":[],"exam_id":22,"question_text":"A company's application team needs to select an AWS managed database service to store application and user data. The application team is familiar with MySQL but is open to new solutions. The application and user data is stored in 10 tables and is de-normalized. The application will access this data through an API layer using a unique ID in each table. The company expects the traffic to be light at first, but the traffic will increase to thousands of transactions each second within the first year. The database service must support active reads and writes in multiple AWS Regions at the same time. Query response times need to be less than 100 ms.\n\nWhich AWS database solution will meet these requirements?","isMC":true,"answer":"C","question_images":[],"answer_ET":"C","topic":"1","question_id":288,"choices":{"C":"Deploy an Amazon DynamoDB database with global tables.","B":"Deploy an Amazon Aurora MySQL global database with write forwarding turned on.","D":"Deploy an Amazon DocumentDB global cluster across multiple Regions.","A":"Deploy an Amazon RDS for MySQL environment in each Region and leverage AWS Database Migration Service (AWS DMS) to set up a multi-Region bidirectional replication."},"answer_description":"","answers_community":["C (100%)"]},{"id":"rt6fVGPFc7y7CD9Ilz21","isMC":true,"timestamp":"2024-03-03 10:53:00","answer_description":"","topic":"1","answer_images":[],"answer_ET":"D","answers_community":["B (100%)"],"question_id":289,"answer":"B","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/135110-exam-aws-certified-database-specialty-topic-1-question-359/","question_text":"A manufacturing company stores its inventory details in an Amazon DynamoDB table in the us-east-2 Region. According to new compliance and regulatory policies, the company is required to back up all of its tables nightly and store these backups in the us-west-2 Region for disaster recovery for 1 year.","unix_timestamp":1709459580,"exam_id":22,"discussion":[{"comment_id":"1171454","upvote_count":"1","content":"answer :B","poster":"rajujala479","timestamp":"1710220560.0"},{"comment_id":"1164678","poster":"fceb2c1","timestamp":"1709459580.0","upvote_count":"2","content":"Selected Answer: B\nOption B suggests using AWS Backup to create a backup plan, which allows for centralized management of backups across multiple AWS services, including DynamoDB. By configuring cross-Region replication in the backup plan, the backups of the DynamoDB table will be automatically replicated to the us-west-2 Region as required by the compliance and regulatory policies."}],"choices":{"C":"Create an on-demand backup of the DynamoDB table and restore this backup in the us-west-2 Region.","B":"Use AWS Backup to create a backup plan. Configure cross-Region replication in the plan and assign the DynamoDB table to this plan.","A":"Convert the existing DynamoDB table into a global table and create a global table replica in the us-west-2 Region.","D":"Enable Amazon S3 Cross-Region Replication (CRR) on the S3 bucket where DynamoDB on-demand backups are stored."}},{"id":"ZUcwnPx9fkvNwijBo3ZD","question_images":[],"answer_images":[],"exam_id":22,"timestamp":"2020-07-14 15:31:00","answer_ET":"D","question_text":"A company is using Amazon with Aurora Replicas for read-only workload scaling. A Database Specialist needs to split up two read-only applications so each application always connects to a dedicated replica. The Database Specialist wants to implement load balancing and high availability for the read-only applications.\nWhich solution meets these requirements?","answers_community":["D (100%)"],"answer_description":"","choices":{"B":"Use reader endpoints for both the read-only workload applications.","C":"Use a reader endpoint for one read-only application and use an instance endpoint for the other read-only application.","D":"Use custom endpoints for the two read-only applications.","A":"Use a specific instance endpoint for each replica and add the instance endpoint to each read-only application connection string."},"topic":"1","answer":"D","unix_timestamp":1594733460,"question_id":290,"discussion":[{"content":"Selected Answer: D\nD is answer","comment_id":"772723","timestamp":"1673455260.0","poster":"SachinGoel","upvote_count":"1"},{"upvote_count":"2","content":"Custome end points are usually used when custom load balancing is needed ,i.e. when specific read application should connect to comstom read replicat directed by custom rules in load balancing. When all RR are of same size, so need for custom end point reader end point will do .","timestamp":"1658150280.0","comments":[{"content":"So B is correct","poster":"sachin","comment_id":"633038","upvote_count":"2","timestamp":"1658150280.0"}],"comment_id":"633037","poster":"sachin"},{"comment_id":"621665","timestamp":"1656076020.0","poster":"ryuhei","content":"Selected Answer: D\nAnswer:D","upvote_count":"1"},{"timestamp":"1651362180.0","upvote_count":"2","poster":"novice_expert","comment_id":"595352","content":"Selected Answer: D\nA custom endpoint for an Aurora cluster represents a set of DB instances (here replicas) that you choose. When you connect to the endpoint, Aurora performs load balancing and chooses one of the instances in the group to handle the connection.\n\nwe can create like two custom endpoints: \n1. With two specific read replicas for application A, \nanother three read replicas for application B.\nHA and meet the requirements that A and B will connect to different replicas"},{"content":"Selected Answer: D\nDefinitely (D)","timestamp":"1646586720.0","poster":"RotterDam","upvote_count":"2","comment_id":"562156"},{"content":"Answer is: D","upvote_count":"1","poster":"guru_ji","timestamp":"1636091820.0","comment_id":"438311"},{"content":"A is incorrect because it is not HA: \"Use a specific instance endpoint for each replica\"\n=> if the specific instance is down, connection is lost\nB is incorrect because the demand requires 02 applications connect to different RO replicas. In case B, the traffic will be distributed among read replicas.\nC is same with A, using one endpoint or instance does not meet the HA requirement. \nD. Use custom endpoints for the two read-only applications.\nD is correct because we can create like two customer endpoints: 1. With two specific read replicas for application A, another three read replicas for application B.\nHA and meet the requirements that A and B will connect to different replicas","upvote_count":"2","poster":"ChauPhan","comment_id":"426166","timestamp":"1636051080.0"},{"poster":"Dip11","timestamp":"1635672060.0","upvote_count":"3","content":"Ans is D. In order for application to connect to specific instance, and also provide HA by flipping DNS in case of one read replica goes down.","comment_id":"364718"},{"poster":"LMax","upvote_count":"4","timestamp":"1635628560.0","content":"No doubts that D is the answer.","comment_id":"314842"},{"upvote_count":"2","poster":"myutran","comment_id":"297992","timestamp":"1635552120.0","content":"Ans: D"},{"content":"A. For example, your client application might require more fine-grained load balancing based on workload type. In this case, you can configure multiple clients to connect to different Aurora Replicas in a DB cluster to distribute read workloads.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Endpoints.Viewing","upvote_count":"1","poster":"Exia","timestamp":"1634036640.0","comment_id":"293081","comments":[{"comment_id":"293082","timestamp":"1634878080.0","upvote_count":"1","poster":"Exia","content":"The reader endpoint load-balances connections to available Aurora Replicas in an Aurora DB cluster. It doesn't load-balance individual queries. If you want to load-balance each query to distribute the read workload for a DB cluster, open a new connection to the reader endpoint for each query."}]},{"content":"D - Custom endpoints allows distributing workload in a customized way by grouping read-replicas of various size, configuration and location","comment_id":"253178","upvote_count":"1","timestamp":"1633880280.0","poster":"JobinAkaJoe"},{"timestamp":"1633722660.0","poster":"Billhardy","upvote_count":"2","content":"D, custom endpoints","comment_id":"226112"},{"content":"D. Custom endpoint for custom requirements","poster":"Ashoks","timestamp":"1633301040.0","comment_id":"212067","upvote_count":"2"},{"content":"the answer is D , dedicated endpoint for each application by custom endpoint \n or each application has to use reader endoint not cluster reader and this option does not exists in the answers.","upvote_count":"1","comment_id":"196815","poster":"halol","timestamp":"1633223820.0"},{"timestamp":"1632848400.0","comment_id":"158602","poster":"awscamus","upvote_count":"2","content":"D is the answer. Dedicated replica is the key"},{"upvote_count":"1","comment_id":"154365","poster":"Ebi","content":"Answer is D.\nB is not correct, reader endpoint of the cluster performs load balancing across all reader instances, questions say reader instances must be split up between to applications.","timestamp":"1632713820.0"},{"timestamp":"1632489300.0","poster":"firbhat","comment_id":"153917","content":"Answer D:\nUse case – custom load balancing with HA\nhttps://aws.amazon.com/about-aws/whats-new/2018/11/amazon-aurora-simplifies-workload-management-with-custom-endpoints/","upvote_count":"3"},{"timestamp":"1632225300.0","poster":"BillyMadison","upvote_count":"2","content":"Think B is correct.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html\n\"A reader endpoint for an Aurora DB cluster provides load-balancing support for read-only connections to the DB cluster. Use the reader endpoint for read operations, such as queries. By processing those statements on the read-only Aurora Replicas, this endpoint reduces the overhead on the primary instance. It also helps the cluster to scale the capacity to handle simultaneous SELECT queries, proportional to the number of Aurora Replicas in the cluster. Each Aurora DB cluster has one reader endpoint.\"","comment_id":"140528","comments":[{"upvote_count":"3","poster":"BillyMadison","timestamp":"1632854700.0","comment_id":"161510","content":"Switching answer to D\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Endpoints.Reader\n“Instead of using one DB instance for each specialized purpose and connecting to its instance endpoint, you can have multiple groups of specialized DB instances. In this case, each group has its own custom endpoint. This way, Aurora can perform load balancing among all the instances dedicated to tasks such as reporting or handling production or internal queries. The custom endpoints provide load balancing and high availability for each group of DB instances within your cluster.”"}]},{"upvote_count":"1","poster":"Mickysingh","comment_id":"134877","timestamp":"1632132000.0","content":"Ans B Load baclacing can only be done as if we point instance endpoint high availability will be lost."}],"url":"https://www.examtopics.com/discussions/amazon/view/25722-exam-aws-certified-database-specialty-topic-1-question-36/","isMC":true}],"exam":{"name":"AWS Certified Database - Specialty","id":22,"lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":false,"isBeta":false,"isImplemented":true,"numberOfQuestions":359},"currentPage":58},"__N_SSP":true}