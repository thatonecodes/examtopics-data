{"pageProps":{"questions":[{"id":"vJ6YBC6ljg4nE4f2kMNx","answer":"C","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/5631-exam-aws-sysops-topic-1-question-594-discussion/","unix_timestamp":1569282480,"answers_community":["C (100%)"],"question_text":"Based on the AWS Shared Responsibility Model, which of the following actions are the responsibility of the customer for an Aurora database?","answer_description":"Reference:\nhttps://www.skyhighnetworks.com/cloud-security-blog/aws-shared-responsibility-model-for-security-and-compliance/","discussion":[{"poster":"mukeshs","timestamp":"1664216280.0","comment_id":"12364","upvote_count":"21","content":"I think the answer should be C. Since Aurora is AWS managed, the execution of all maintenance related tasks is owned by AWS."},{"poster":"albert_kuo","content":"Selected Answer: C\nAccording to the AWS Shared Responsibility Model, the responsibility for scheduling maintenance, patches, and other updates for an Aurora database lies with the customer. This includes managing the maintenance windows, scheduling updates, and applying patches to the Aurora database.","timestamp":"1719888420.0","comment_id":"940473","upvote_count":"1"},{"poster":"221898","timestamp":"1686822660.0","content":"Selected Answer: C\nC is the answer","upvote_count":"1","comment_id":"616656"},{"comment_id":"576758","timestamp":"1679999520.0","poster":"VTHOR","content":"C in the answer!","upvote_count":"1"},{"timestamp":"1667833560.0","comment_id":"324876","content":"C is the answer\n\nevery other option is taken care by aws","poster":"RicardoD","upvote_count":"4"},{"poster":"nemisis95","timestamp":"1667123580.0","upvote_count":"3","comment_id":"285966","content":"C. Scheduling"},{"comment_id":"285674","poster":"HVarada","upvote_count":"3","content":"Answer is \"C\".","timestamp":"1666861440.0"},{"poster":"abhishek_m_86","content":"C. Scheduling maintenance, patches, and other updates","upvote_count":"3","comment_id":"273330","timestamp":"1666438980.0"},{"content":"C is the correct Answer.","comment_id":"266693","upvote_count":"2","poster":"Radhaghosh","timestamp":"1666343940.0"},{"poster":"jackdryan","upvote_count":"3","comment_id":"226366","timestamp":"1666215360.0","content":"I'll go with C"},{"upvote_count":"3","content":"C. Scheduling maintenance, patches, and other updates","timestamp":"1665975840.0","comment_id":"208085","poster":"MFDOOM"},{"timestamp":"1665856680.0","upvote_count":"3","poster":"professor","comment_id":"111645","content":"C is right answer"},{"timestamp":"1665600900.0","comment_id":"100990","upvote_count":"3","content":"C is the correct Answer.","poster":"MrKhan"},{"upvote_count":"4","content":"I agree the answer is C as per the Document here:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.Maintenance.html\n\nIf an update is available, you can take one of the actions:\n\nIf the maintenance value is next window, defer the maintenance items by choosing Defer upgrade from Actions. You can't defer a maintenance action if it has already started.\n\nApply the maintenance items immediately.\n\nSchedule the maintenance items to start during your next maintenance window.\n\nTake no action.","timestamp":"1665261120.0","comment_id":"100719","poster":"mano29"},{"upvote_count":"2","poster":"TheKsi","timestamp":"1665252900.0","comment_id":"92176","content":"Answer should be C has Aurora is fully managed\naccording to this link, AWS is in charge of the maintenance\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.Maintenance.html"},{"poster":"sen12","upvote_count":"2","content":"Ans is C:\n\nIf an update is available, you can take one of the actions:\n\nIf the maintenance value is next window, defer the maintenance items by choosing Defer upgrade from Actions. You can't defer a maintenance action if it has already started.\n\nApply the maintenance items immediately.\n\nSchedule the maintenance items to start during your next maintenance window.\n\nTake no action.","comment_id":"66850","timestamp":"1665176280.0"},{"comment_id":"38727","poster":"leowenlu","timestamp":"1665080460.0","content":"storage provisioning here means physical harddisk, so Provisioning of storage for database\n is the not right answer\nC is correct I believe.","upvote_count":"1"},{"comments":[{"comment_id":"285968","upvote_count":"2","content":"Fully Managed\nAmazon Aurora is fully managed by Amazon Relational Database Service (RDS). You no longer need to worry about database management tasks such as hardware provisioning, software patching, setup, configuration, or backups. Aurora automatically and continuously monitors and backs up your database to Amazon S3, enabling granular point-in-time recovery.","timestamp":"1667496060.0","poster":"nemisis95"},{"timestamp":"1665120300.0","poster":"MS_PFE","content":"Aurora Auto Grows the disk for you. so you don't need to manage it.","upvote_count":"6","comment_id":"53281"}],"poster":"cloud","upvote_count":"1","content":"why not Provisioning of storage for database","timestamp":"1664638440.0","comment_id":"37244"},{"upvote_count":"2","content":"Ans is C. Scheduling is User Task.","poster":"karmaah","comment_id":"25539","timestamp":"1664308260.0"},{"upvote_count":"4","timestamp":"1664282100.0","poster":"saumenP","content":"C is correct","comment_id":"17893"}],"timestamp":"2019-09-24 01:48:00","choices":{"A":"Performing underlying OS updates","B":"Provisioning of storage for database","C":"Scheduling maintenance, patches, and other updates","D":"Executing maintenance, patches, and other updates"},"isMC":true,"answer_images":[],"answer_ET":"D","question_id":546,"exam_id":36,"question_images":[]},{"id":"NKQpoYFq0yVRNAYLWw6k","answer":"B","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/7513-exam-aws-sysops-topic-1-question-595-discussion/","unix_timestamp":1572510480,"answers_community":["B (100%)"],"question_text":"A web-commerce application stores its data in an Amazon Aurora DB cluster with an Aurora replica. The application displays shopping cart information by reading data from the reader endpoint. When monitoring the Aurora database, the SysOps Administrator sees that the AuroraReplicaLagMaximum metric for a single replica is high.\nWhat behavior is the application MOST likely exhibiting to users?","answer_description":"","discussion":[{"comment_id":"18490","upvote_count":"14","poster":"saumenP","content":"B is correct","timestamp":"1664057580.0"},{"poster":"sen12","timestamp":"1665184620.0","comment_id":"66904","upvote_count":"12","content":"You can reduce the lag between updates to a source DB instance and the subsequent updates to the Read Replica by doing the following:\n\nSet the DB instance class of the Read Replica to have a storage size comparable to that of the source DB instance.\n\nMake sure that parameter settings in the DB parameter groups used by the source DB instance and the Read Replica are compatible. For more information and an example, see the discussion of the max_allowed_packet parameter in the next section.\n\nDisable the query cache. For tables that are modified often, using the query cache can increase replica lag because the cache is locked and refreshed often. If this is the case, you might see less replica lag if you disable the query cache. You can disable the query cache by setting the query_cache_type parameter to 0 in the DB parameter group for the DB instance."},{"poster":"albert_kuo","content":"Selected Answer: B\nWhen the AuroraReplicaLagMaximum metric for a replica is high, it indicates that there is a delay between the primary instance and the replica in the Aurora DB cluster. This means that changes made to the primary instance may not be immediately replicated to the replica. As a result, users may experience inconsistencies in the shopping cart information displayed by the application.\n\nIt's important to note that Aurora replicas are designed to provide high availability and scalability, but there can be some replication lag due to network latency or other factors. Applications should be designed to handle such replication lag and ensure data consistency across replicas.","upvote_count":"1","timestamp":"1719888540.0","comment_id":"940475"},{"poster":"RicardoD","upvote_count":"2","timestamp":"1667790900.0","content":"B is the answer","comment_id":"324878"},{"upvote_count":"1","content":"Answer is \"B\".\nAs user might be connecting to the ReadReplica which is having high utilization.\nSo, its kind of a blip and if user tries again; he would be connected to a healthy node which will resolve the problem.","timestamp":"1667215620.0","comment_id":"285679","poster":"HVarada"},{"content":"B. Users intermittently notice that the cart is not updated correctly.","comment_id":"273333","poster":"abhishek_m_86","upvote_count":"2","timestamp":"1667206380.0"},{"upvote_count":"1","content":"Agree. B is correct answer.","timestamp":"1666778040.0","poster":"Radhaghosh","comment_id":"266694"},{"comment_id":"226367","poster":"jackdryan","content":"I'll go with B","timestamp":"1666164180.0","upvote_count":"2"},{"comment_id":"208086","timestamp":"1665754980.0","upvote_count":"1","content":"B. Users intermittently notice that the cart is not updated correctly.","poster":"MFDOOM"},{"content":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_Troubleshooting.html#CHAP_Troubleshooting.MySQL.ReplicaLag","upvote_count":"5","timestamp":"1665593520.0","comment_id":"66905","poster":"sen12"},{"timestamp":"1664755560.0","content":"Any one can provide comment, How to fix this kind of issues in realtime ?","comment_id":"33047","upvote_count":"3","poster":"karmaah"}],"timestamp":"2019-10-31 09:28:00","choices":{"A":"Users cannot add any items to the shopping cart.","C":"Users cannot remove any items from the shopping cart.","B":"Users intermittently notice that the cart is not updated correctly.","D":"Users cannot use the application because it is falling back to an error page."},"isMC":true,"answer_images":[],"answer_ET":"B","question_id":547,"exam_id":36,"question_images":[]},{"id":"EW9UlwlpDEJMVHrCIlIz","discussion":[{"comment_id":"17894","content":"C is correct\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html","poster":"saumenP","upvote_count":"18","timestamp":"1663731960.0","comments":[{"comment_id":"25542","poster":"karmaah","timestamp":"1664580480.0","content":"Good Link Saumen.\n\nChange sets allow you to preview how proposed changes to a stack might impact your running resources, for example, whether your changes will delete or replace any critical resources, AWS CloudFormation makes the changes to your stack only when you decide to execute the change set, allowing you to decide whether to proceed with your proposed changes or explore other changes by creating another change set.","upvote_count":"2"}]},{"upvote_count":"1","poster":"albert_kuo","timestamp":"1719888840.0","content":"Selected Answer: C\nIn AWS CloudFormation, a change set is a summary of changes that will be applied to a stack. It provides a detailed preview of how the update will modify the resources in the stack without actually making any changes. By creating a change set, the Administrator can review the proposed changes and understand the impact they will have on the infrastructure.\n\nCreating a change set allows the Administrator to validate the proposed changes, verify that they align with the intended modifications, and assess any potential risks or issues before executing the update. It provides an opportunity to review and discuss the changes with stakeholders, ensuring that they are aware of the modifications and their potential implications.","comment_id":"940478"},{"content":"C is the answer","comment_id":"324880","poster":"RicardoD","upvote_count":"2","timestamp":"1667223000.0"},{"comment_id":"285680","content":"Answer is \"C\".","upvote_count":"1","timestamp":"1666301220.0","poster":"HVarada"},{"comment_id":"273335","content":"C. Create a change set for the running stack.","timestamp":"1666143060.0","upvote_count":"1","poster":"abhishek_m_86"},{"timestamp":"1665692280.0","content":"C. Create a change set for the running stack.","upvote_count":"1","comment_id":"266695","poster":"Radhaghosh"},{"timestamp":"1665525420.0","upvote_count":"2","poster":"jackdryan","content":"I'll go with C","comment_id":"226368"},{"poster":"MFDOOM","comment_id":"208088","content":"C. Create a change set for the running stack.","timestamp":"1664582460.0","upvote_count":"3"}],"answer":"C","unix_timestamp":1572238500,"timestamp":"2019-10-28 05:55:00","answer_ET":"C","choices":{"A":"Implement a blue/green strategy using AWS Elastic Beanstalk.","D":"Submit the update using the UpdateStack API call.","C":"Create a change set for the running stack.","B":"Perform a canary deployment using Application Load Balancers and target groups."},"question_id":548,"isMC":true,"exam_id":36,"answer_description":"Reference:\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/best-practices.html","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/7358-exam-aws-sysops-topic-1-question-596-discussion/","topic":"1","answer_images":[],"question_text":"A company would like to review each change in the infrastructure before deploying updates in its AWS CloudFormation stacks.\nWhich action will allow an Administrator to understand the impact of these changes before implementation?","question_images":[]},{"id":"dN0hLcvOWXO6CcpIOiMs","url":"https://www.examtopics.com/discussions/amazon/view/7966-exam-aws-sysops-topic-1-question-597-discussion/","discussion":[{"comment_id":"31779","poster":"karmaah","content":"Ans D:\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharingamis-explicit.html","upvote_count":"13","timestamp":"1664382240.0"},{"upvote_count":"8","timestamp":"1664311620.0","poster":"Moon","comment_id":"20544","content":"It could be option D.\nB: is opening the AMI widely!"},{"upvote_count":"1","content":"Selected Answer: D\nTo share an AMI using the console, the Administrator can navigate to the EC2 Dashboard, select the desired AMI, and choose the \"Actions\" dropdown menu. From there, they can select the \"Modify Image Permissions\" option and specify the AWS account IDs with which the AMI should be shared.\n\nAlternatively, the Administrator can use the AWS CLI to share the AMI by using the modify-image-attribute command and specifying the appropriate --launch-permission parameter with the AWS account IDs.\n\nBy sharing the AMIs with each AWS account, the Administrator ensures that the approved AMIs are accessible and can be used for launching instances in the respective accounts while maintaining control over who has access to the AMIs.","poster":"albert_kuo","timestamp":"1719888960.0","comment_id":"940479"},{"upvote_count":"1","timestamp":"1667730420.0","content":"D is the answer","poster":"RicardoD","comment_id":"324883"},{"comment_id":"285683","upvote_count":"2","content":"Answer is \"D\".\nWe can share a custom AMI (Golden AMI) with other accounts/regions using console/CLI.","timestamp":"1667099880.0","poster":"HVarada"},{"comment_id":"273340","content":"D. Share the AMIs with each AWS account using the console or CLI.","poster":"abhishek_m_86","timestamp":"1666734780.0","upvote_count":"2"},{"content":"I'll go with D","timestamp":"1665983220.0","comment_id":"226369","upvote_count":"3","poster":"jackdryan"},{"comment_id":"208089","poster":"MFDOOM","upvote_count":"3","content":"D. Share the AMIs with each AWS account using the console or CLI.","timestamp":"1664800260.0"},{"poster":"NitiATOS","timestamp":"1664738340.0","content":"Take a Note: Modify the permissions on the AMIs so that they are publicly accessible.\nEven this is One way. But that will make the AMI publicly available to everyone. It will be added to Community AMI. and We do not want that.","upvote_count":"1","comment_id":"111270"},{"timestamp":"1664681460.0","poster":"shammous","comment_id":"103473","upvote_count":"1","content":"Answer D is correct"},{"poster":"sen12","timestamp":"1664589300.0","upvote_count":"3","content":"you can share AMI using Console or CLI. \nAnswer is D","comment_id":"66908"}],"question_text":"A Systems Administrator is responsible for maintaining custom, approved AMIs for a company. These AMIs must be shared with each of the company's AWS accounts.\nHow can the Administrator address this issue?","unix_timestamp":1573482720,"isMC":true,"answer_images":[],"timestamp":"2019-11-11 15:32:00","choices":{"A":"Contact AWS Support for sharing AMIs with other AWS accounts.","C":"Modify the permissions on the IAM role that are associated with the AMI.","B":"Modify the permissions on the AMIs so that they are publicly accessible.","D":"Share the AMIs with each AWS account using the console or CLI."},"exam_id":36,"answers_community":["D (100%)"],"topic":"1","answer":"D","answer_ET":"D","answer_description":"Reference:\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharingamis-explicit.html","question_id":549,"question_images":[]},{"id":"5rcyVBZm6YoWNeohzewP","discussion":[{"poster":"white_shadow","upvote_count":"11","content":"I would go with C too. S3 lifecycle can't be implemented on EBS volumes. EBS volumes has its own lifecycle manager and it is accessed through EC2 console, not S3.","comments":[{"upvote_count":"5","comment_id":"33053","timestamp":"1664695860.0","comments":[{"comment_id":"67378","poster":"nicat","comments":[{"timestamp":"1665594900.0","upvote_count":"3","poster":"nicat","content":"http://asvignesh.in/aws-lambda-delete-old-ebs-snapshots-using-boto3/","comment_id":"67379"}],"timestamp":"1665482340.0","content":"https://blog.skeddly.com/2017/03/ebs-snapshots-explained.html\nEBS snapshots are stored in Amazon S3. However, you are not going to find your snapshots in any of your S3 buckets.\nAWS uses the S3 infrastructure to store your EBS snapshots, but you cannot access them while they reside in S3.\n\nSo A is wrong. Because you cannot see this bucket.\n\nAnswer is C.","upvote_count":"7"}],"content":"Ans C says to delete old snapshots and does not mention the retention period as per the requirement.Also EBS maintains the snapshot in S3, Lifecycle policy is applicable as per the nature of s3 for that snapshot maintained in s3. Snapshot is not an EBS Volume exactly.","poster":"karmaah"}],"timestamp":"1664564160.0","comment_id":"29176"},{"comment_id":"19602","timestamp":"1663702140.0","content":"i would choose C.","poster":"chris82","upvote_count":"9"},{"timestamp":"1719889140.0","poster":"albert_kuo","upvote_count":"1","content":"Selected Answer: C\nBy scheduling an AWS Lambda function using Amazon CloudWatch Events, you can define a recurring schedule to trigger the Lambda function at specific intervals. Within the Lambda function, you can write a script to identify and delete EBS snapshots that are older than two years.\n\nThe script can use the AWS SDK or command-line tools to interact with the Amazon EBS service and identify snapshots based on their creation date or any other relevant criteria. Once identified, the script can issue the necessary API calls to delete the snapshots.","comment_id":"940481"},{"upvote_count":"1","poster":"RicardoD","content":"C is the Answer","comment_id":"324886","timestamp":"1667814420.0"},{"timestamp":"1667702400.0","content":"Answerer is C \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html\n\nYou can use Amazon Data Lifecycle Manager to automate the creation, retention, and deletion of EBS snapshots and EBS-backed AMIs.","comment_id":"286253","upvote_count":"1","poster":"Chirantan"},{"timestamp":"1667505000.0","poster":"HVarada","comment_id":"285688","upvote_count":"2","content":"Answer is \"A\".\nEBS snapshots are stored in S#. So, we can setup S3 lifecycle policies for the objects stored in S3.\nData Lifecycle Manager (dlm) is a best choice as well but we don't have it in the options."},{"timestamp":"1667499240.0","poster":"abhishek_m_86","comment_id":"273341","upvote_count":"2","content":"C. Schedule an AWS Lambda function using Amazon CloudWatch Events to periodically run a script to delete old snapshots."},{"upvote_count":"4","content":"C is the correct answer\nS3 lifecycle policies cannot work on EBS snapshots; even if they are stored on S3, this part of S3 is not reachable from our account","poster":"Radhaghosh","timestamp":"1667359380.0","comment_id":"266699"},{"poster":"tahaRyski","upvote_count":"1","timestamp":"1667222880.0","content":"The answer is definitely C\nhttps://cloud.netapp.com/blog/automate-ebs-volumes-cost-efficiency","comment_id":"252041"},{"timestamp":"1667221980.0","comment_id":"242101","content":"S3 lifecycle policy can be configured to automate transition of Data in S3. A is the Answer","upvote_count":"2","poster":"dozymars","comments":[{"poster":"Radhaghosh","timestamp":"1667330940.0","upvote_count":"1","comment_id":"265265","comments":[{"comment_id":"265266","upvote_count":"1","content":"The answer is definitely C","poster":"Radhaghosh","timestamp":"1667332920.0"}],"content":"S3 saves EBS snapshot but you can't see it. So you can not use the S3 Lifecycle Policy to delete them"}]},{"upvote_count":"2","content":"I'll go with C","timestamp":"1667208300.0","comment_id":"226370","poster":"jackdryan"},{"upvote_count":"2","poster":"SONLE","timestamp":"1666971300.0","content":"S3 saves EBS snapshot but you can't see it. So you can not use the S3 Lifecycle Policy to delete them","comment_id":"187511"},{"poster":"AWS1212","content":"The answer is not A. It's C.\n\n\"First, we use Amazon CloudWatch Events to invoke an AWS Lambda function periodically. This Lambda function parses AWS CloudTrail for EBS events and creates operational work items (OpsItems) for EBS volumes that are in the available state and have not been attached to an EC2 instance for a user-definable time period.\"\n\nhttps://aws.amazon.com/blogs/mt/controlling-your-aws-costs-by-deleting-unused-amazon-ebs-volumes/","upvote_count":"1","timestamp":"1666827180.0","comment_id":"186588"},{"poster":"firstabed","timestamp":"1666667820.0","comment_id":"186021","upvote_count":"1","content":"C. Schedule an AWS Lambda function using Amazon CloudWatch Events to periodically run a script to delete old snapshots."},{"comment_id":"171641","upvote_count":"2","poster":"asim1982","content":"EBS snapshot are stored in S3 however those S3 bucket belong to AWS and you cannot define S3 policy on bucket which you dont own. Hence C is the correct answer where it gives you visibility to schedule.","timestamp":"1666520460.0"},{"comment_id":"154023","poster":"teosinh","upvote_count":"1","content":"I choose C for the correct answer. Follow this one: https://blog.skeddly.com/2017/03/ebs-snapshots-explained.html at key point \"When you delete an old EBS snapshot, behind the scenes, AWS will consolidate the snapshot data. It will move valid data forward to the next EBS snapshot and it will discard invalid data\".","timestamp":"1666497360.0"},{"comment_id":"103474","upvote_count":"6","content":"\"EBS snapshots are stored in Amazon S3. However, you are not going to find your snapshots in any of your S3 buckets. AWS uses the S3 infrastructure to store your EBS snapshots, but you cannot access them while they reside in S3.\"\n\nBased on this, Answer A can't be implemented. The correct alternative would be Answer C.","comments":[{"poster":"kopper2019","upvote_count":"1","content":"yes as it is stated there snapshots are safe in S3 when comming from EBS but is not like you have a bucket named EBS_snapshots so you apply a S3 lfecycle policy, so Answer is C","timestamp":"1666317660.0","comment_id":"131801"}],"poster":"shammous","timestamp":"1666107840.0"},{"comment_id":"93545","content":"Technically, if you keep your snapshots in S3 bucket, you may schedule life cycle policy to delete them. Then answer A. If it's not S3, that answer C","timestamp":"1665941940.0","poster":"Bad_Mat","upvote_count":"2"},{"content":"S3 lifecycle policies cannot work on EBS snapshots; even if they are stored on S3, this part of S3 is not reachable from our account. Data lifecycle manager is the product to use and is not S3 Lifecycle management.\nThe only other valid answer is C \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","comment_id":"92186","poster":"TheKsi","upvote_count":"5","timestamp":"1665752100.0"},{"poster":"ThoseWereTheDays","timestamp":"1665741900.0","comment_id":"77854","content":"C is the correct one.\n\nYou can use Amazon Data Lifecycle Manager to automate the creation, retention, and deletion of snapshots taken to back up your Amazon EBS volumes. Automating snapshot management helps you to:\n\nReduce storage costs by deleting outdated backups.\n\nYou can use the following features to monitor the lifecycle of your snapshots.\n\nCloudWatch Events:\n Amazon EBS and Amazon Data Lifecycle Manager emit events related to lifecycle policy actions. You can use AWS Lambda and Amazon CloudWatch Events to handle event notifications programmatically > So this can be handle as the C answer provided.\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html#monitor-cloudwatch-events\n\nhttps://aws.amazon.com/blogs/mt/controlling-your-aws-costs-by-deleting-unused-amazon-ebs-volumes/","upvote_count":"3"},{"poster":"ezat","upvote_count":"3","content":"I'll choose A","timestamp":"1665712680.0","comment_id":"75867"},{"timestamp":"1664924400.0","poster":"sen12","comment_id":"66910","content":"Its straightforward case of S3 lifecycle policy. Cheaper and easier setup\nI will go with Option A","upvote_count":"4"},{"content":"Ans: A\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","poster":"Ka","timestamp":"1664580420.0","comment_id":"29657","upvote_count":"3"},{"poster":"karmaah","upvote_count":"1","content":"Ans is A.","comment_id":"25544","timestamp":"1664447820.0"},{"content":"Creating and Using a Lifecycle Policy\nData Lifecycle Manager uses lifecycle policies to figure out when to run, which volumes to snapshot, and how long to keep the snapshots around. \n\nRef:\nhttps://aws.amazon.com/blogs/aws/new-lifecycle-management-for-amazon-ebs-snapshots/\n\nNone of the 4 answers mention Data Lifecycle Manager. As ELB snapshots are stored in S3, Option A is right answer for given 4 options","timestamp":"1664381700.0","poster":"aksliveswithaws","comment_id":"25318","upvote_count":"4"},{"poster":"RGT","timestamp":"1664089440.0","comment_id":"22637","upvote_count":"1","content":"Ans should be A\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html"}],"question_text":"A company's data retention policy dictates that backups be stored for exactly two years. After that time, the data must be deleted.\nHow can Amazon EBS snapshots be managed to conform to this data retention policy?","unix_timestamp":1573070820,"isMC":true,"answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/7765-exam-aws-sysops-topic-1-question-598-discussion/","answer_ET":"A","question_images":[],"question_id":550,"answer_images":[],"exam_id":36,"choices":{"D":"Configure an Amazon CloudWatch alarm to trigger the launch of an AWS CloudFormation template that will clean the older snapshots.","A":"Use an Amazon S3 lifecycle policy to delete snapshots older than two years.","B":"Configure Amazon Inspector to find and delete old EBS snapshots.","C":"Schedule an AWS Lambda function using Amazon CloudWatch Events to periodically run a script to delete old snapshots."},"timestamp":"2019-11-06 21:07:00","topic":"1","answer":"C","answer_description":""}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":false,"isImplemented":true,"id":36,"name":"AWS-SysOps","numberOfQuestions":928},"currentPage":110},"__N_SSP":true}