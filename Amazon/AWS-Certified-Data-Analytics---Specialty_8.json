{"pageProps":{"questions":[{"id":"UKL8eenMYkJbqqyi1SA2","question_images":[],"answer":"A","exam_id":20,"discussion":[{"comment_id":"479249","timestamp":"1637051940.0","content":"You can now use AWS Glue to find matching records across a dataset (including ones without identifiers) by using the new FindMatches ML Transform, a custom machine learning transformation that helps you identify matching records. By adding the FindMatches transformation to your Glue ETL jobs, you can find related products, places, suppliers, customers, and more.\n\nYou can also use the FindMatches transformation for deduplication, such as to identify customers who have signed up more than once, products that have accidentally been added to your product catalog more than once, and so forth. You can teach the FindMatches ML Transform your definition of a “duplicate” through examples, and it will use machine learning to identify other potential duplicates in your dataset.","upvote_count":"11","poster":"polooor"},{"timestamp":"1705388940.0","poster":"JiyuKim","content":"I also agree with A. But I have a doubt about whether it can \"generate\" a unique identifier.","upvote_count":"2","comment_id":"1123931"},{"timestamp":"1682966880.0","content":"A: I passed the test","comment_id":"886625","poster":"pk349","upvote_count":"3"},{"comment_id":"706371","poster":"cloudlearnerhere","timestamp":"1666954620.0","upvote_count":"2","content":"Correct answer is A as Glue can be used to perform matching across data stores using the FinMatches API. \nhttps://docs.aws.amazon.com/glue/latest/dg/machine-learning.html\nOption B is wrong as Amazon Kendra is an intelligent search service powered by machine learning (ML). Kendra reimagines enterprise search for your websites and applications so your employees and customers can easily find the content they’re looking for, even when it’s scattered across multiple locations and content repositories within your organization.\n\nOption C is wrong as Amazon SageMaker Ground Truth is a data labeling service that makes it easy to label data and gives you the option to use human annotators through Amazon Mechanical Turk.\n\nOption D is wrong as ResolveChoice helps resolve a choice type within a DynamicFrame. It is ideal for format changes."},{"upvote_count":"2","content":"Selected Answer: A\nA is the answer","timestamp":"1659584520.0","comment_id":"642161","poster":"maitis"},{"timestamp":"1658807760.0","poster":"rocky48","content":"Selected Answer: A\nA is the answer","upvote_count":"1","comment_id":"637134"},{"content":"A is the answer","upvote_count":"2","comment_id":"490386","poster":"Thiya","timestamp":"1638242880.0"},{"comment_id":"479198","timestamp":"1637041920.0","upvote_count":"3","poster":"Chints01","content":"Answer should be A as FindMatches completely addresses the use case in question"},{"poster":"goutes","content":"OPTION A: FindMatches ML: identify duplicate or matching records in your dataset,\neven when the records do not have a common unique identifier and no fields\nmatch exactly.","comment_id":"478987","timestamp":"1637008800.0","upvote_count":"1"},{"timestamp":"1636468140.0","poster":"Fazil_Cp","content":"Option A - https://aws.amazon.com/about-aws/whats-new/2019/08/aws-glue-provides-findmatches-ml-transform-to-deduplicate/","comment_id":"474851","upvote_count":"4"},{"content":"Answer: B\nhttps://aws.amazon.com/kendra/","comment_id":"467503","timestamp":"1632794880.0","upvote_count":"2","poster":"srinivasa"}],"unix_timestamp":1635172620,"url":"https://www.examtopics.com/discussions/amazon/view/64707-exam-aws-certified-data-analytics-specialty-topic-1-question/","answer_description":"","topic":"1","answer_images":[],"choices":{"D":"An AWS Glue ETL job with the ResolveChoice transform","B":"Amazon Kendra","C":"Amazon SageMaker Ground Truth","A":"An AWS Glue ETL job with the FindMatches transform"},"answers_community":["A (100%)"],"isMC":true,"question_id":36,"question_text":"A hospital is building a research data lake to ingest data from electronic health records (EHR) systems from multiple hospitals and clinics. The EHR systems are independent of each other and do not have a common patient identifier. The data engineering team is not experienced in machine learning (ML) and has been asked to generate a unique patient identifier for the ingested records.\nWhich solution will accomplish this task?","timestamp":"2021-10-25 16:37:00","answer_ET":"A"},{"id":"glJmdZWcgc4eAiazf2XJ","answer_description":"","answer":"AC","unix_timestamp":1650665460,"question_text":"A company is Running Apache Spark on an Amazon EMR cluster. The Spark job writes to an Amazon S3 bucket. The job fails and returns an HTTP 503 `Slow\nDown` AmazonS3Exception error.\nWhich actions will resolve this error? (Choose two.)","answer_ET":"AC","topic":"1","question_id":37,"answers_community":["AC (100%)"],"timestamp":"2022-04-23 00:11:00","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/74178-exam-aws-certified-data-analytics-specialty-topic-1-question/","discussion":[{"timestamp":"1658985060.0","content":"Selected Answer: AC\nThere are three ways to resolve this problem:\n\nAdd more prefixes to the S3 bucket.\nReduce the number of Amazon S3 requests.\nIncrease the EMR File System (EMRFS) retry limit.","upvote_count":"8","poster":"rocky48","comment_id":"638470"},{"comment_id":"641544","poster":"alfredofmt","content":"Selected Answer: AC\nA - CORRECT, limit of S3 are defined on a per-prefix basis. ( https://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html , \"3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per partitioned prefix\" ). If you \"add\" more prefixes, meaning you change the logic to make tasks write to \"less shared\" prefixes, then the limit is less likely to be hit.\nB - WRONG, limit of S3 are defined on a per-prefix basis. If you reduce the prefixes, then the limit is more likely to be hit.\nC - CORRECT, EMRFS uses an exponential backoff strategy to retry requests to Amazon S3 with default value 15. To increase the retry limit, change the value of fs.s3.maxRetries parameter. ( https://aws.amazon.com/premiumsupport/knowledge-center/emr-s3-503-slow-down/ )\nD - WRONG, dynamic partition pruning decreases the number of requests to S3, because it helps select which prefixes to read\nE - WRONG, increasing the partitions increases the number of Spark tasks, hence the number of write requests to S3","timestamp":"1659497220.0","upvote_count":"8"},{"timestamp":"1682967000.0","content":"AC: I passed the test","comment_id":"886627","poster":"pk349","upvote_count":"2"},{"comment_id":"850856","upvote_count":"1","timestamp":"1679822640.0","poster":"CleverMonkey092","content":"AC for me"},{"content":"A C\nhttps://aws.amazon.com/premiumsupport/knowledge-center/emr-s3-503-slow-down/\n\n\nThis error occurs when you exceed the Amazon Simple Storage Service (Amazon S3) request rate. The request rate is 3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket.\n\nThere are three ways to resolve this problem:\n\n Add more prefixes to the S3 bucket.\n Reduce the number of Amazon S3 requests.\n Increase the EMR File System (EMRFS) retry limit.","poster":"fl0resi3nsis","comment_id":"590262","comments":[{"content":"Agree AC","timestamp":"1652348280.0","comment_id":"600546","upvote_count":"1","poster":"Seb23495786234"}],"timestamp":"1650665460.0","upvote_count":"2"}],"choices":{"B":"Reduce the number of prefixes in the S3 bucket","D":"Disable dynamic partition pruning in the Spark configuration for the cluster","A":"Add additional prefixes to the S3 bucket","E":"Add more partitions in the Spark configuration for the cluster","C":"Increase the EMR File System (EMRFS) retry limit"},"isMC":true,"exam_id":20},{"id":"veR4YEVP2W0l5FMH4mwT","discussion":[{"content":"Why is B and C the exact same answer?","poster":"chp2022","timestamp":"1653481560.0","upvote_count":"8","comment_id":"607217"},{"content":"Selected Answer: D\nOption A doesn't have Trust Policy , so its D","comment_id":"603972","poster":"Shammy45","upvote_count":"6","timestamp":"1652970120.0"},{"content":"correct answer is D , Here is the Link\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters.html","comment_id":"980761","upvote_count":"3","poster":"njraman","timestamp":"1692015060.0"},{"upvote_count":"2","content":"D: I passed the test","timestamp":"1682967060.0","comment_id":"886628","poster":"pk349"},{"upvote_count":"1","timestamp":"1679822940.0","comment_id":"850859","content":"selected D","poster":"CleverMonkey092"},{"content":"Selected Answer: D\nSelected Answer: D","comment_id":"638473","timestamp":"1658985360.0","poster":"rocky48","upvote_count":"4"},{"comments":[{"upvote_count":"1","content":"Answer = D","timestamp":"1650693900.0","poster":"CHRIS12722222","comment_id":"590428"}],"comment_id":"590427","content":"Options B & C do not mention the use of subscription filters so they are eliminated.\nOption A does not mention Trust policy which is a required step in the link below.\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CreateDestination.html","upvote_count":"4","timestamp":"1650693900.0","poster":"CHRIS12722222"}],"choices":{"D":"Create a destination data stream in Kinesis Data Streams in the test account with an IAM role and a trust policy that allow CloudWatch Logs in the production account to write to the test account. Create a subscription filter in the production account's CloudWatch Logs to target the Kinesis data stream in the test account as its destination.","B":"In the test account, create an IAM role that grants access to the Kinesis data stream and the CloudWatch Logs resources in the production account. Create a destination data stream in Kinesis Data Streams in the test account with an IAM role and a trust policy that allow CloudWatch Logs in the production account to write to the test account.","C":"In the test account, create an IAM role that grants access to the Kinesis data stream and the CloudWatch Logs resources in the production account. Create a destination data stream in Kinesis Data Streams in the test account with an IAM role and a trust policy that allow CloudWatch Logs in the production account to write to the test account.","A":"Create a subscription filter in the production account's CloudWatch Logs to target the Kinesis data stream in the test account as its destination. In the test account, create an IAM role that grants access to the Kinesis data stream and the CloudWatch Logs resources in the production account."},"answer":"D","exam_id":20,"timestamp":"2022-04-23 08:05:00","question_images":[],"answer_description":"","isMC":true,"answers_community":["D (100%)"],"answer_ET":"D","question_id":38,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/74200-exam-aws-certified-data-analytics-specialty-topic-1-question/","answer_images":[],"question_text":"A company recently created a test AWS account to use for a development environment. The company also created a production AWS account in another AWS\nRegion. As part of its security testing, the company wants to send log data from Amazon CloudWatch Logs in its production account to an Amazon Kinesis data stream in its test account.\nWhich solution will allow the company to accomplish this goal?","unix_timestamp":1650693900},{"id":"0uLaRCSZWKaV4mDN3Rxd","answer":"A","discussion":[{"content":"A - CORRECT, Lambda function is used as on-the-fly masking due to the requirement \"All PII on the AWS Cloud must be hidden\"\nB - WRONG, the requirement \"All PII on the AWS Cloud must be hidden\" imposes that masking must be performed on-the-fly, while Macie can be applied to data already in S3. https://aws.amazon.com/blogs/big-data/automate-the-archival-and-deletion-of-sensitive-data-using-amazon-macie/\nC - WRONG, encryption != masking\nD - WRONG, Amazon Comprehend PII API has no integration with KDF","comment_id":"642947","poster":"alfredofmt","comments":[{"poster":"ccpmad","content":"\"that is stored in the AWS Cloud to be masked\" is not on the fly\nI am still between A and B.","upvote_count":"2","comment_id":"948788","timestamp":"1689061020.0"}],"timestamp":"1659698880.0","upvote_count":"11"},{"upvote_count":"1","poster":"njraman","content":"D : Correct answer and we do have intergration \nhttps://aws.amazon.com/blogs/machine-learning/redact-sensitive-data-from-streaming-data-in-near-real-time-using-amazon-comprehend-and-amazon-kinesis-data-firehose/","timestamp":"1692016740.0","comment_id":"980779"},{"timestamp":"1682967060.0","poster":"pk349","content":"A: I passed the test","comment_id":"886629","upvote_count":"2"},{"timestamp":"1678326300.0","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/machine-learning/redact-sensitive-data-from-streaming-data-in-near-real-time-using-amazon-comprehend-and-amazon-kinesis-data-firehose/\n\nFrom the link above, A makes more sense.","poster":"Jerry84","comment_id":"833520","upvote_count":"1"},{"comment_id":"769309","comments":[{"comment_id":"948793","upvote_count":"2","poster":"ccpmad","content":"Yes it should be A. But they should also write the question better. As \"that is stored in the AWS Cloud to be masked\" is not clear. Be masked before or could be after stored.","timestamp":"1689061140.0"}],"upvote_count":"2","poster":"Ody__","timestamp":"1673175780.0","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/machine-learning/protect-pii-using-amazon-s3-object-lambda-to-process-and-modify-data-during-retrieval/"},{"poster":"[Removed]","upvote_count":"1","timestamp":"1671481320.0","content":"A https://aws.amazon.com/blogs/machine-learning/protect-pii-using-amazon-s3-object-lambda-to-process-and-modify-data-during-retrieval/","comment_id":"750226"},{"content":"Selected Answer: A\nA might be the answer. Amazon Comprehend is used for unstructured data.","comment_id":"749437","timestamp":"1671422940.0","poster":"rocky48","upvote_count":"2"},{"poster":"rav009","timestamp":"1666696980.0","upvote_count":"1","content":"Selected Answer: A\nthe source is a relational database, so you can get to know which column has PII and need masked. So A. And aws comprehend is for text","comment_id":"703799"},{"content":"Selected Answer: A\nBetween A and D, don't think Comprehend is invokable by KDF, and shouldn't be used for structured data (at least not efficient), hence A","comment_id":"669212","timestamp":"1663175940.0","poster":"he11ow0rId","upvote_count":"3"},{"timestamp":"1662472920.0","comment_id":"661298","upvote_count":"3","content":"A Correct. Amazon Comprehend is used for unstructured data. Apparently, not the case here","poster":"ystotest"},{"upvote_count":"1","comments":[{"comment_id":"749436","timestamp":"1671422880.0","upvote_count":"1","content":"Given the use-case, i guess A could be a better option.","poster":"rocky48"}],"comment_id":"643496","timestamp":"1659815580.0","content":"Selected Answer: D\nSelected Answer: D","poster":"rocky48"},{"poster":"vpatel3701","timestamp":"1658663520.0","content":"D \nhttps://aws.amazon.com/about-aws/whats-new/2020/09/amazon-comprehend-helps-mask-personally-identifiable-information-from-text-documents/","upvote_count":"1","comment_id":"636025"},{"poster":"Ramshizzle","content":"Selected Answer: B\nI feel like there is a mistake in this question. Without looking at the answers I would choose to use Amazon Macie. Maybe Answer B was supposed to say Amazon Macie instead of Amazon Made?? Amazon Made is not a real service. \n\nIf Macie is not an option I would choose A. Because just using encryption is not hiding PII and I don't think it is possible invoke Amazon Comprehend from FireHose.","upvote_count":"4","timestamp":"1656067020.0","comment_id":"621581","comments":[{"upvote_count":"1","content":"That's what I was thinking, it should be Amazon MACIE","comment_id":"903292","timestamp":"1684676700.0","poster":"gndu"}]},{"comment_id":"600642","timestamp":"1652361780.0","content":"A - Kinesis Firehorse invoke lambda","upvote_count":"1","poster":"siju13"},{"content":"B - I think we can use aws Maice","comment_id":"591495","timestamp":"1650877980.0","poster":"mouli15","upvote_count":"2"},{"upvote_count":"2","comment_id":"590772","content":"Selected Answer: D\nD - Would go for this as Amazon Comprehend can mask PII - https://docs.aws.amazon.com/comprehend/latest/dg/pii.html","poster":"astalavista1","timestamp":"1650740700.0"},{"content":"I think answer = A\nData encryption and masking are not the same thing","timestamp":"1650696420.0","comments":[{"timestamp":"1651173600.0","comment_id":"594003","content":"Changed to D\n\nhttps://medium.com/fernando-pereiro/analyzing-twitter-on-real-time-with-aws-big-data-and-machine-learning-services-1fa888f962cf","comments":[{"comment_id":"650120","upvote_count":"1","timestamp":"1661148300.0","poster":"Dun6","content":"but the comprehend is not in the KDF as D states"}],"upvote_count":"1","poster":"CHRIS12722222"}],"upvote_count":"1","comment_id":"590442","poster":"CHRIS12722222"},{"poster":"rb39","upvote_count":"4","comment_id":"589402","content":"Selected Answer: A\nLambda as intermediate step of Kinesis Firehose","timestamp":"1650546300.0"}],"unix_timestamp":1650546300,"question_images":[],"answers_community":["A (65%)","B (20%)","D (15%)"],"question_id":39,"question_text":"A data architect is building an Amazon S3 data lake for a bank. The goal is to provide a single data repository for customer data needs, such as personalized recommendations. The bank uses Amazon Kinesis Data Firehose to ingest customers' personal information bank accounts, and transactions in near-real time from a transactional relational database. The bank requires all personally identifiable information (PII) that is stored in the AWS Cloud to be masked.\nWhich solution will meet these requirements?","timestamp":"2022-04-21 15:05:00","url":"https://www.examtopics.com/discussions/amazon/view/74024-exam-aws-certified-data-analytics-specialty-topic-1-question/","exam_id":20,"choices":{"D":"Invoke Amazon Comprehend from Kinesis Data Firehose to detect and mask PII before delivering the data into Amazon S3.","A":"Invoke an AWS Lambda function from Kinesis Data Firehose to mask PII before delivering the data into Amazon S3.","B":"Use Amazon Made, and configure it to discover and mask PII.","C":"Enable server-side encryption (SSE) in Amazon S3."},"answer_images":[],"topic":"1","answer_description":"","isMC":true,"answer_ET":"A"},{"id":"3r7bdzA2WFaBhf4SqCWa","answer_description":"","question_text":"An analytics software as a service (SaaS) provider wants to offer its customers business intelligence (BI) reporting capabilities that are self-service. The provider is using Amazon QuickSight to build these reports. The data for the reports resides in a multi-tenant database, but each customer should only be able to access their own data.\nThe provider wants to give customers two user role options:\n✑ Read-only users for individuals who only need to view dashboards.\n✑ Power users for individuals who are allowed to create and share new dashboards with other users.\nWhich QuickSught feature allows the provider to meet these requirements?","timestamp":"2022-04-21 13:14:00","isMC":true,"answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/74012-exam-aws-certified-data-analytics-specialty-topic-1-question/","exam_id":20,"answer_ET":"C","topic":"1","choices":{"B":"Table calculations","A":"Embedded dashboards","D":"SPICE","C":"Isolated namespaces"},"question_id":40,"question_images":[],"discussion":[{"comment_id":"973956","upvote_count":"1","timestamp":"1691334720.0","poster":"MLCL","content":"Selected Answer: C\nC, Namespaces are logical containers to achieve multi-tenancy."},{"comment_id":"886630","upvote_count":"3","content":"C: I passed the test","timestamp":"1682967120.0","poster":"pk349"},{"poster":"AwsNewPeople","timestamp":"1679379180.0","content":"Selected Answer: C\nThe QuickSight feature that allows the provider to meet these requirements is C. Isolated namespaces. Isolated namespaces provide a way to isolate the data sources and user permissions for different customers or tenants in a multi-tenant environment. With isolated namespaces, the provider can ensure that each customer only has access to their own data, while still allowing them to create and share dashboards if they are power users. Isolated namespaces also allow for fine-grained control over user permissions, so the provider can grant read-only access to some users and power user access to others.","comment_id":"845569","upvote_count":"4"},{"timestamp":"1671423120.0","comment_id":"749442","upvote_count":"1","content":"Selected Answer: C\nAmazon QuickSight Enterprise edition supports multitenancy through namespaces.","poster":"rocky48"},{"comment_id":"742759","timestamp":"1670847000.0","poster":"Saneeda","upvote_count":"2","content":"C: Amazon QuickSight Enterprise edition supports multitenancy through namespaces. A QuickSight namespace is a logical container that you can use to organize clients, subsidiaries, \nteams, and so on. Namespaces can help you achieve the following goals:\nYou can allow the users of your QuickSight subscription to discover shared content and share with other users. At the same time, you can be sure that users in one namespace \ncan't see or interact with users in another namespace.\nYou can securely isolate data and also support diverse workloads without adding additional AWS accounts.","comments":[{"poster":"nadavw","timestamp":"1670940480.0","comment_id":"744111","content":"C https://docs.aws.amazon.com/quicksight/latest/user/namespaces.html","upvote_count":"1"}]},{"comment_id":"637112","comments":[{"comment_id":"749441","timestamp":"1671423060.0","poster":"rocky48","upvote_count":"2","content":"Amazon QuickSight Enterprise edition supports multi-tenancy through namespaces."}],"timestamp":"1658806620.0","upvote_count":"2","poster":"rocky48","content":"Selected Answer: C\nAnswer is C"},{"comment_id":"604827","upvote_count":"3","timestamp":"1653130560.0","poster":"Bik000","content":"Selected Answer: A\nAnswer is A"},{"poster":"CHRIS12722222","comments":[{"content":"chnged to C - namespaces","timestamp":"1651163580.0","upvote_count":"1","comment_id":"593942","poster":"CHRIS12722222"}],"content":"Answer = A\n\nhttps://docs.aws.amazon.com/quicksight/latest/user/embedded-analytics-dashboards-for-everyone.html","upvote_count":"1","comment_id":"590470","timestamp":"1650701400.0"},{"comment_id":"590355","poster":"rb39","upvote_count":"4","content":"Selected Answer: C\nC - https://docs.aws.amazon.com/quicksight/latest/user/namespaces.html","timestamp":"1650681120.0"},{"comments":[{"upvote_count":"3","poster":"astalavista1","timestamp":"1650741060.0","content":"How is the answer A if you're referring to the Isolated namespace?","comments":[{"upvote_count":"1","timestamp":"1669026000.0","poster":"rav009","content":"the web must have changed the order of options before. So some people choosed A which was namespace at that time.","comment_id":"723383"}],"comment_id":"590773"},{"poster":"[Removed]","content":"You mean C - isolated namespace ?","comment_id":"590826","upvote_count":"2","timestamp":"1650754860.0"}],"poster":"naidooo","timestamp":"1650539640.0","content":"It's A.\nhttps://docs.aws.amazon.com/quicksight/latest/user/namespaces.html","upvote_count":"1","comment_id":"589284"}],"unix_timestamp":1650539640,"answer_images":[],"answers_community":["C (80%)","A (20%)"]}],"exam":{"lastUpdated":"11 Apr 2025","provider":"Amazon","isImplemented":true,"numberOfQuestions":164,"isBeta":false,"id":20,"isMCOnly":true,"name":"AWS Certified Data Analytics - Specialty"},"currentPage":8},"__N_SSP":true}