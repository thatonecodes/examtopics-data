{"pageProps":{"questions":[{"id":"0B91wRhgmAYCbh6pS90L","question_images":[],"choices":{"D":"Associate the private hosted zone to the shared services VPC. Create a Route 53 inbound resolver in the shared services VPC. Attach the shared services VPC to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.","C":"Associate the private hosted zone to the shared services VPCreate a Route 53 outbound resolver in the shared services VPAttach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the outbound resolver.","A":"Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.","B":"Associate the private hosted zone to all the VPCs. Deploy an Amazon EC2 conditional forwarder in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the conditional forwarder."},"question_id":1,"answer_description":"","timestamp":"2022-12-09 19:52:00","answer_images":[],"answer_ET":"A","discussion":[{"comment_id":"741364","comments":[{"content":"A is valid answer Ref : https://lc.cx/kXboHy","timestamp":"1744263360.0","poster":"alihassan4286654","comment_id":"1559476","upvote_count":"1"},{"comment_id":"1295453","upvote_count":"2","poster":"danielcharles554234","timestamp":"1728544140.0","content":"A is correct answer"},{"timestamp":"1708812720.0","content":"In your link, you missed this sentence:\n\"The most reliable, performant and low-cost approach is to share and associate private hosted zones directly to all VPCs that need them.\" You share the PHZ via the Shared Services VPC. You use the .2 DNS Resolver Address in each VPC to connect to the PHZ in the shared services VPC for domain resolution.","comment_id":"1158183","upvote_count":"1","poster":"awsylum","comments":[{"poster":"alexkro","comment_id":"1184023","content":"You forgot an additional condition mentioned in the question: \"All VPCs should be able to resolve cloud.example.com.\" Nobody said there are only shared VPCs there.","upvote_count":"1","timestamp":"1711538640.0"}]}],"content":"A. Correct answer. Source: https://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/\n\nNOT B. EC2 conditional forwarder will not meet Highest performance requirement.\n\nNOT C. Missing: Need to associate private hosted zone to all VPC.\n\"All VPC’s will need to associate their private hosted zones to all other VPC’s if required to.\"\nSource: https://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/\n\nNOT D. Missing: Need to associate private hosted zone to all VPC.\n\"All VPC’s will need to associate their private hosted zones to all other VPC’s if required to.\"\nSource: https://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","upvote_count":"56","timestamp":"1727060880.0","poster":"robertohyena"},{"comment_id":"740358","poster":"zhangyu20000","timestamp":"1670611920.0","content":"A because it requires all VPC can resolve the example.com. All VPCs must be associated with private hosted zone","upvote_count":"10"},{"upvote_count":"1","content":"Selected Answer: A\n529問を全て行った結果合格できました！体感80%ほど似た問題があったので頑張ってください！","timestamp":"1742470740.0","comment_id":"1401011","poster":"pekomari"},{"content":"Selected Answer: A\nI have just taken the exam and 75 percent of the questions were from here. Prepare well for these Questions. Good Luck!","timestamp":"1741615500.0","upvote_count":"1","poster":"mssc","comment_id":"1382143"},{"upvote_count":"1","timestamp":"1738635840.0","comment_id":"1351171","content":"Selected Answer: A\nOn-premises systems should be able to resolve and connect to cloud.example.com, it is inbound resolver, C is incorrect. \n\nAll VPCS will need to associate their private zones to the Transit Gateway, associated only the shared VPC with TGW forces all the DNS query from other VPCS forward to shared VPC, add the latency. d is incorrect","poster":"FlyingHawk"},{"poster":"pk0619","upvote_count":"1","comment_id":"1327061","timestamp":"1734297300.0","content":"Selected Answer: A\nWhen a Route 53 private hosted zone needs to be resolved in multiple VPCs and AWS accounts as described earlier, the most reliable pattern is to share the private hosted zone between accounts and associate it to each VPC that needs it."},{"timestamp":"1730920920.0","upvote_count":"1","content":"A. Correct answer. Source: https://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","comment_id":"1308096","poster":"jrheen"},{"content":"Selected Answer: A\nAssociate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.","poster":"TariqKipkemei","timestamp":"1730178480.0","upvote_count":"1","comment_id":"1304294"},{"upvote_count":"1","comments":[{"upvote_count":"1","content":"Route 53 Resolver : inbound","comment_id":"1298539","poster":"to_to","timestamp":"1729052880.0","comments":[{"content":"When I organized it slowly, I decided that it was \"A\" because it was attributed to an account, not a VPC.","timestamp":"1729054680.0","comment_id":"1298553","upvote_count":"1","poster":"to_to"}]}],"comment_id":"1298538","poster":"to_to","content":"Selected Answer: D\n1-1. Private hosted zone One Account -> 2 Account PHZ is not Equals.\n1-2. VPCs in Private hosted zone\n2. On-Premise -> AWS Domain Name Query [ Route 53 Resolver ]\n3. Private hosted zone - Route 53 Resolver","timestamp":"1729052520.0"},{"upvote_count":"1","poster":"veds85","timestamp":"1727873640.0","content":"Selected Answer: A\n\"All VPCs and only need inbound Resolver\"","comment_id":"1292413"},{"content":"Answer is A: Please see link below for the solution:\nhttps://docs.aws.amazon.com/whitepapers/latest/hybrid-cloud-dns-options-for-vpc/route-53-resolver-endpoints-and-forwarding-rules.html","poster":"310e976","comment_id":"1289635","timestamp":"1727371980.0","upvote_count":"1"},{"poster":"masetromain","comment_id":"774663","timestamp":"1727061000.0","upvote_count":"1","content":"Selected Answer: A\nThe correct option would be option A:\n\nAssociate the private hosted zone to all the VPCs.\nCreate a Route 53 inbound resolver in the shared services VPC.\nAttach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.\nThis option will allow the on-premises systems to resolve and connect to cloud.example.com by forwarding the DNS queries to the inbound resolver in the shared services VPC, which will then forward the queries to the private hosted zone. All VPCs will be able to resolve cloud.example.com by resolving the queries through the private hosted zone associated to all VPCs. Additionally, this option takes advantage of the already existing AWS Direct Connect connection between the on-premises corporate network and AWS Transit Gateway, which will provide the highest performance."},{"content":"Selected Answer: A\nThe best architecture to meet the given requirements with the HIGHEST performance would be Option A:\n\nA. Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.\n\nThis architecture ensures that all VPCs can resolve the cloud.example.com domain using the private hosted zone. Additionally, it creates a Route 53 inbound resolver in the shared services VPC that can handle DNS resolution requests from on-premises systems through the transit gateway. This setup allows for fast and efficient DNS resolution with minimal latency.","poster":"c73bf38","comment_id":"809114","upvote_count":"1","timestamp":"1727061000.0"},{"content":"Selected Answer: A\nAll options mention a Shared Services VPC that is not in the question. This is used for Route 53 for cloud.example.com.\n\nOption A - Associating all VPCs with the private hosted zone allows resolution of cloud.example.com; an inbound resolves allows on-premise resource to resolve to cloud.example.com; the final bit of connectivity allows on-premise to connect and resolve to cloud.example.com\n\nOption B - An Amazon EC2 Conditional Forwarder does not apply in this situation because an Active Directory is not in play in this situation\n\nOption C - Would not work because it is relying on an Outbound resolver (from cloud to on-premise) \n\nOption D - Would not work because the other VPCs are not connected to the private zone. Moreover, connectivity is not complete because only the Shared Services VPC is connected to the Transit Gateway","upvote_count":"3","poster":"atirado","comment_id":"1099953","timestamp":"1727060940.0"},{"comment_id":"1211991","timestamp":"1727060940.0","upvote_count":"2","content":"Selected Answer: A\nTo achieve the highest performance hybrid DNS solution, the company should associate a Route 53 private hosted zone with \"cloud.example.com\" to all VPCs, then create a Route 53 inbound resolver in a shared services VPC. This inbound resolver is connected to the on-premises network via AWS Direct Connect and Transit Gateway, allowing on-premises systems to resolve the private hosted zone. Forwarding rules on the on-premises DNS server direct queries for \"cloud.example.com\" to the inbound resolver, ensuring seamless resolution for both on-premises and cloud resources.","poster":"higashikumi"},{"content":"A. Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.","upvote_count":"1","poster":"amministrazione","timestamp":"1727060880.0","comment_id":"1275425"},{"poster":"fabriciollf","timestamp":"1727060880.0","comment_id":"1282358","content":"Selected Answer: D\n\"Inbound DNS resolution – Create Route 53 Resolver inbound endpoints in a centralized VPC and associate all the private hosted zones in your Landing Zone with this centralized VPC.\" Source: https://docs.aws.amazon.com/whitepapers/latest/building-scalable-secure-multi-vpc-network-infrastructure/dns.html","upvote_count":"2"},{"comment_id":"1267966","timestamp":"1723967040.0","content":"Inbound resolver + private zone","poster":"onlyvimal2103","upvote_count":"1"},{"poster":"buiquangbk90","content":"Correct the answer: A","upvote_count":"1","comment_id":"1254653","timestamp":"1721874780.0"},{"comment_id":"1231364","timestamp":"1718541000.0","upvote_count":"2","poster":"Helpnosense","content":"Selected Answer: A\nThe 2nd requirement in the question is \"All VPCs should be able to resolve cloud.example.com.\" So the answer is A, not D which is only one VPC not all VPCs."},{"comment_id":"1211441","timestamp":"1715692800.0","poster":"AloraCloud","content":"Selected Answer: A\nYou need to associate the private hosted zone to all the VPCs for them to be able to use it for DNS resolution.","upvote_count":"1"},{"poster":"ichi2kazu","comment_id":"1190862","timestamp":"1712479620.0","content":"i think A.","upvote_count":"1"},{"comment_id":"1189568","content":"Selected Answer: A\nAll VPC’s will need to associate their private hosted zones to all other VPC’s if required to","poster":"jj888","timestamp":"1712272800.0","upvote_count":"1"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/whitepapers/latest/hybrid-cloud-dns-options-for-vpc/route-53-resolver-endpoints-and-forwarding-rules.html","poster":"frmynd","upvote_count":"3","comment_id":"1187399","timestamp":"1711972740.0"},{"poster":"gofavad926","comment_id":"1175036","timestamp":"1710600480.0","content":"Selected Answer: A\nBy associating the Route 53 private hosted zone with all VPCs, resources within any of those VPCs can resolve domain names within the cloud.example.com domain.","upvote_count":"1"},{"poster":"MoT0ne","comment_id":"1171655","timestamp":"1710245760.0","content":"Selected Answer: D\nUsing \"share service\" is the magic word here","upvote_count":"1"},{"content":"Selected Answer: A\nD is definitly wrong","upvote_count":"2","timestamp":"1709650440.0","comment_id":"1166549","poster":"leoncao"},{"upvote_count":"1","content":"A and B are out since they talk about attaching the private domain to all accounts. This is wrong; you attach it to the shared VPC in the networking account which then is used for any local VPCs. This reduces the question to whether we need an inbound or outbound resolver for the onprem infra; the answer is that for onprem to be able to resolve the domain, we need an inbound resolver. And therefore the only possible correct answer is D. \n\nI see that most people voted A, but I'm afraid that's wrong.","timestamp":"1709291880.0","comments":[{"poster":"Shenannigan","timestamp":"1716670020.0","content":"D is incorrect because - This would not provide the necessary DNS resolution for all VPCs, as only the shared services VPC would have the private hosted zone associated, limiting the resolution scope.","comment_id":"1218564","upvote_count":"1"}],"comment_id":"1163452","poster":"Dgix"},{"timestamp":"1709159940.0","upvote_count":"1","poster":"24Gel","content":"B C are definitely not answers","comment_id":"1162030"},{"content":"Selected Answer: D\nMost efficient way to get all the VPC's to be able to resolve the private domain is using a shared services VPC.","upvote_count":"3","comment_id":"1158295","poster":"luis_guevara","timestamp":"1708828080.0"},{"upvote_count":"2","comment_id":"1158182","content":"The answer is D. Why? Because you associate a single Private Hosted Zone with DNS Resolvers in multiple VPCs (.2 address). You don't associate a PHZ in each VPC. That's the point of each VPC having a DNS Resolver address. So, you use the Shared Services VPC to host the PHZ with the Route53 inbound endpoint. Each VPC uses the DNS Resolver address to connect to the Shared Services VPC. And on the flip side, the Transit Gateway allows the on-prem traffic to connect to all VPCs using the Route53 inbound endpoint. Scroll down to the On premises section of this page: https://aws.amazon.com/blogs/networking-and-content-delivery/integrating-aws-transit-gateway-with-aws-privatelink-and-amazon-route-53-resolver/","comments":[{"comment_id":"1158189","upvote_count":"1","poster":"awsylum","timestamp":"1708813740.0","content":"Just to clarify, the Transit Gateway is to provide Layer 3 networking between the on-prem and AWS environments, while the Inbound Route53 Endpoint is used to join the DNS of on-prem and AWS environments. I kind of mixed the two up in my explanation above."}],"timestamp":"1708812480.0","poster":"awsylum"},{"timestamp":"1706355420.0","poster":"awsgeek75","content":"Selected Answer: A\nBC don't have a resolver setup for on-prem traffic as outbound resolver is on AWS side. Even if D works, the traffic will have taken a longer route.\nD It is not connecting all the VPCs","upvote_count":"3","comment_id":"1133291"},{"content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","timestamp":"1704577320.0","poster":"GibaSP45","comment_id":"1115454","upvote_count":"3"},{"poster":"cgsoft","comment_id":"1094131","upvote_count":"1","content":"Selected Answer: A\nAll VPCs should be able to resolve cloud.example.com. This is possible if all VPCs are associated with the private hosted zone.","timestamp":"1702357740.0"},{"content":"Selected Answer: A\nNot B. \"EC2 conditional forwarder in the shared services VPC\" as conditional forward is not needed in this scenario and also I am not aware of EC2 conditional forward (but I am not an expert)\nNot C. \"private hosted zone to the shared services VPC\" we need to have it attached to all VPCs and \"Route 53 outbound resolver\" is not needed as we do not need to resolve on-preme from VPCs in this scenario\nNot D. \"private hosted zone to the shared services VPC\" we need to have it attached to all VPCs, ref to https://docs.aws.amazon.com/whitepapers/latest/hybrid-cloud-dns-options-for-vpc/route-53-resolver-endpoints-and-forwarding-rules.html#:~:text=AWS%20Glossary-,Route%C2%A053%20Resolver%20endpoints%20and%20forwarding%20rules,-PDF (this is not super clear as diagrams do not include VPCs and steps do not refer to VPCs consistently)\n\nThus A. is correct as we have all the key pieces needed listed there","poster":"ninomfr64","timestamp":"1702112340.0","comment_id":"1091648","upvote_count":"1"},{"timestamp":"1701019620.0","upvote_count":"2","content":"A is correct","poster":"abeb","comment_id":"1080897"},{"comment_id":"1079659","content":"Selected Answer: A\nall vpc can access cloud.example.com domain name.","upvote_count":"1","timestamp":"1700874000.0","poster":"KevinYao"},{"comment_id":"1077005","content":"D seems to be the right answer.","upvote_count":"1","poster":"jainparag1","timestamp":"1700634900.0"},{"content":"Selected Answer: A\nDNS server aka 'Route 53 resolver' will only know how to resolve the hostname if you provide DNS table aka 'Route 53 PHZ' to it. Separate DNS server is available in all VPCs, hence you need to provide PHZ to all VPCs aka 'associate'.","poster":"severlight","comment_id":"1067707","upvote_count":"1","timestamp":"1699690680.0"},{"poster":"rlf","timestamp":"1696653360.0","comment_id":"1027091","content":"A. And this blog is also helpful to understand https://aws.amazon.com/blogs/architecture/using-route-53-private-hosted-zones-for-cross-account-multi-region-architectures/","upvote_count":"1"},{"timestamp":"1696057260.0","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","comment_id":"1021302","upvote_count":"1","poster":"puffetor"},{"upvote_count":"2","timestamp":"1695810960.0","content":"Selected Answer: A\nA. Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.","poster":"ansgohar","comment_id":"1018714"},{"timestamp":"1694485140.0","upvote_count":"3","content":"Selected Answer: D\nD provides the best balance between performance, simplicity, and security, making it the most suitable choice for the given requirements.\nBy using a Route 53 inbound resolver within the shared services VPC, you reduce the latency and complexity associated with forwarding DNS queries to other VPCs or EC2 instances.","poster":"task_7","comment_id":"1005313"},{"timestamp":"1693948020.0","upvote_count":"1","comment_id":"999916","poster":"Soweetadad","content":"Selected Answer: A\nAnswer is A. In the link that someone posted, it says \"When a Route 53 private hosted zone needs to be resolved in multiple VPCs and AWS accounts as described earlier, the most reliable pattern is to share the private hosted zone between accounts and associate it to each VPC that needs it.\" https://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/"},{"upvote_count":"1","poster":"career360guru","comment_id":"997745","timestamp":"1693755660.0","content":"Correct Answer is A. D does not meet the requirement of all VPC able to resolve example.com."},{"upvote_count":"2","timestamp":"1692907080.0","content":"Selected Answer: D\nD is more suitable","comment_id":"989463","comments":[{"content":"https://aws.amazon.com/vi/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/#:~:text=Although%20it%20is%20possible%20to%20use%20forwarding%20rules%20to%20resolve%20private%20hosted%20zones%20in%20other%20VPCs%2C%20we%20do%20not%20recommend%20that.%20The%20most%20reliable%2C%20performant%20and%20low%2Dcost%20approach%20is%20to%20share%20and%20associate%20private%20hosted%20zones%20directly%20to%20all%20VPCs%20that%20need%20them\nAnswer is A not D","upvote_count":"1","poster":"vn_thanhtung","comment_id":"994633","timestamp":"1693444740.0"}],"poster":"dimitry_khan_arc"},{"comment_id":"985919","poster":"weequan","upvote_count":"1","content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/security/simplify-dns-management-in-a-multiaccount-environment-with-route-53-resolver/","timestamp":"1692547440.0"},{"comment_id":"970865","upvote_count":"1","poster":"autobahn","timestamp":"1691048700.0","content":"So which the correct answer? A or D? When most people have voted for A, should I take that as the correct answer?"},{"content":"Selected Answer: A\nRequirement 2: All VPCs should be able to resolve cloud.example.com.","timestamp":"1690437540.0","comment_id":"964409","upvote_count":"1","poster":"chico2023"},{"upvote_count":"2","comment_id":"946550","timestamp":"1688825880.0","content":"Selected Answer: A\nOption D is incorrect because it associates the private hosted zone only with the shared services VPC, rather than all the VPCs. This does not meet the requirement of ensuring that all VPCs can resolve cloud.example.com","poster":"Magoose"},{"comment_id":"934665","timestamp":"1687799580.0","poster":"NikkyDicky","upvote_count":"1","content":"Selected Answer: A\nit's a"},{"poster":"Jonalb","comment_id":"927292","timestamp":"1687162140.0","upvote_count":"3","content":"Selected Answer: A\nIts A\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver-overview-DSN-queries-to-vpc.html\n\nhttps://aws.amazon.com/pt/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/"},{"content":"Selected Answer: A\n\"The most reliable, performant and low-cost approach is to share and associate private hosted zones directly to all VPCs that need them.\" Reference: https://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","comment_id":"924453","upvote_count":"2","timestamp":"1686851280.0","poster":"antonvigs"},{"upvote_count":"1","comment_id":"924446","content":"\"The most reliable, performant and low-cost approach is to share and associate private hosted zones directly to all VPCs that need them.\" Ref:https://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","poster":"antonvigs","timestamp":"1686850980.0"},{"content":"all the vpc needs to reach the inbound resolver in the shared services vpc and so tgw attachments are needed. so IMO answer is A","comment_id":"918379","upvote_count":"1","timestamp":"1686236400.0","poster":"tromyunpak"},{"comments":[{"timestamp":"1685625420.0","poster":"Roontha","upvote_count":"1","content":"I go with D. AWS has given the info on this exact use case with Architecture diagram.\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","comment_id":"912135"}],"upvote_count":"1","timestamp":"1685493060.0","poster":"Roontha","content":"Answer : A\nhttps://medium.com/tuimm/resolve-aws-private-hosted-zones-from-on-premise-with-route-53-inbound-resolver-ba683b371522","comment_id":"910670"},{"timestamp":"1684840800.0","poster":"rtguru","comment_id":"904842","upvote_count":"1","content":"I go with D"},{"poster":"dev112233xx","comment_id":"903042","upvote_count":"1","content":"Selected Answer: D\nA doesn't make sense! why attaching all the VPC to the TGW? was there a requirement in the question to share all VPC network? the requirement was to share only the PHZ with all VPCs and create inbound resolver for the On-premise, so i think D makes more sense.","timestamp":"1684658940.0"},{"content":"exactly correct answer A.","timestamp":"1684456380.0","poster":"dewlim","comments":[{"upvote_count":"1","content":"@dewlim\n\nIt seems to be answer D. Given AWS blog post explains with arch diagram\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","timestamp":"1685497260.0","poster":"Roontha","comment_id":"910711"}],"upvote_count":"1","comment_id":"901578"},{"upvote_count":"1","poster":"hellothereby","timestamp":"1684022340.0","content":"A is correct.","comment_id":"897137"},{"poster":"RunkieMax","comment_id":"896070","timestamp":"1683909600.0","content":"Selected Answer: A\nA fit the best the question","upvote_count":"1"},{"upvote_count":"1","comment_id":"895018","content":"Selected Answer: A\nshould be for all VPC","timestamp":"1683805800.0","poster":"Limlimwdwd"},{"upvote_count":"1","poster":"AWS_Sam","comment_id":"890392","content":"The correct answer is A. Another reason A is correct and D is wrong, because all VPCs need to be connected to the Transit Gateway for them to be able to communicate.","timestamp":"1683334440.0"},{"poster":"F_Eldin","comment_id":"887853","content":"Selected Answer: A\nOption B is not optimal because the use of an EC2 conditional forwarder can introduce additional latency and potential points of failure.\n\nOption C is not optimal because it requires all VPCs to use the outbound resolver in the shared services VPC to resolve cloud.example.com, which may introduce additional latency.\n\nOption D is not optimal because it only allows the shared services VPC to resolve cloud.example.com, and all other VPCs and on-premises systems would have to forward DNS queries to the shared services VPC, which can introduce additional latency and potential points of failure.","upvote_count":"1","timestamp":"1683057600.0"},{"poster":"God_Is_Love","upvote_count":"4","comment_id":"874285","timestamp":"1681880400.0","content":"Selected Answer: D\nD is correct , not A\nhttps://d2908q01vomqb2.cloudfront.net/5b384ce32d8cdef02bc3a139d4cac0a22bb029e8\nRoute 53 private hosted zone ( example sqs.us-east-1.amazonaws.com) associated to the shared services VPC and (NOT all VPCs as in option A)"},{"content":"A is the most correct Answer","poster":"moses101","comment_id":"864942","upvote_count":"1","timestamp":"1680978960.0"},{"poster":"rubio83","upvote_count":"1","timestamp":"1680728160.0","comment_id":"862465","content":"Only with this dump its enough for the exam?"},{"content":"Selected Answer: A\nAssociate the private hosted zone to all the VPCs.","upvote_count":"1","timestamp":"1679976660.0","comment_id":"852751","poster":"mfsec"},{"poster":"IndreshKumar","content":"Selected Answer: A\nA. Correct answer","comment_id":"835464","timestamp":"1678484520.0","upvote_count":"1"},{"poster":"mKrishna","timestamp":"1678199100.0","upvote_count":"1","content":"Correct answer is A\n\nWhy D is not correct - The transit gateway may need to forward requests to the inbound resolver in order to introduce additional latency.","comment_id":"831995"},{"poster":"kiran15789","timestamp":"1678180080.0","comment_id":"831689","comments":[{"upvote_count":"1","timestamp":"1687161960.0","content":"On premises my friend.","comment_id":"927289","poster":"Jonalb"}],"upvote_count":"2","content":"Selected Answer: A\nttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/"},{"comments":[{"content":"I have the same question","comment_id":"890393","poster":"AWS_Sam","timestamp":"1683334500.0","upvote_count":"1"}],"upvote_count":"4","comment_id":"827664","timestamp":"1677818640.0","poster":"krushna5966","content":"Every one has selected option A so why system is showing Option D can anyone explain"},{"poster":"gameoflove","upvote_count":"1","comment_id":"826508","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","timestamp":"1677733320.0"},{"content":"can I check with those who has written the exam, \n1. was this question even there? \n2. Was the answer A right?","upvote_count":"2","comment_id":"818661","timestamp":"1677117600.0","poster":"Gabehcoud"},{"poster":"ospherenet","comment_id":"816007","upvote_count":"2","content":"It appears that Option A is the correct answer. The company can associate the private hosted zone to all the VPCs and create a Route 53 inbound resolver in the shared services VPC. They can then attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver. This will allow on-premises systems to resolve and connect to cloud.example.com and all VPCs to resolve cloud.example.com with the highest performance. Option B is incorrect because an EC2 conditional forwarder will not meet the highest performance requirement. Option C and D are incorrect because they both miss the requirement of associating the private hosted zone to all the VPCs.","timestamp":"1676935440.0"},{"upvote_count":"1","comment_id":"804661","timestamp":"1676056200.0","content":"Selected Answer: A\nA is correct.","poster":"Sarutobi"},{"timestamp":"1674031320.0","upvote_count":"1","comment_id":"779764","content":"A answer","poster":"Jacktheriser2019"},{"content":"Selected Answer: A\nDefinitely A","timestamp":"1673786160.0","poster":"Nicocacik","comment_id":"776540","upvote_count":"1"},{"comment_id":"771071","timestamp":"1673327640.0","poster":"AjayD123","content":"Selected Answer: A\nA is correct answer as all VPCs need to be accessed","upvote_count":"1"},{"comment_id":"752894","poster":"WuKongCoder","content":"A correct answer","upvote_count":"2","timestamp":"1671668160.0"},{"timestamp":"1671592980.0","upvote_count":"4","poster":"arron86","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/","comment_id":"751834"}],"topic":"1","question_text":"A company needs to architect a hybrid DNS solution. This solution will use an Amazon Route 53 private hosted zone for the domain cloud.example.com for the resources stored within VPCs.\nThe company has the following DNS resolution requirements:\nOn-premises systems should be able to resolve and connect to cloud.example.com.\nAll VPCs should be able to resolve cloud.example.com.\nThere is already an AWS Direct Connect connection between the on-premises corporate network and AWS Transit Gateway.\nWhich architecture should the company use to meet these requirements with the HIGHEST performance?","answers_community":["A (77%)","D (23%)"],"isMC":true,"answer":"A","unix_timestamp":1670611920,"exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/90837-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"FIRZzEtZZRyl5zMYXVaY","answer_images":[],"answers_community":["AE (90%)","6%"],"answer_description":"","choices":{"E":"Add a custom error response by configuring a CloudFront custom error page. Modify DNS records to point to a publicly accessible web page.","B":"Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Target.FailedHealthChecks is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicly accessible web server.","C":"Modify the existing Amazon Route 53 records by adding health checks. Configure a fallback target if the health check fails. Modify DNS records to point to a publicly accessible webpage.","D":"Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Elb.InternalError is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a public accessible web server.","A":"Create an Amazon S3 bucket. Configure the S3 bucket to host a static webpage. Upload the custom error pages to Amazon S3."},"question_id":2,"url":"https://www.examtopics.com/discussions/amazon/view/90945-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"AE","exam_id":33,"isMC":true,"discussion":[{"content":"A & E\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/GeneratingCustomErrorResponses.html#custom-error-pages-procedure","poster":"Raj40","comment_id":"742509","timestamp":"1670830200.0","upvote_count":"34"},{"timestamp":"1727061720.0","poster":"atirado","upvote_count":"9","content":"Selected Answer: AE\nOption A - This option helps: Allows exposing custom error pages from a highly-available location\n\nOption B - This option requires a lot of set up\n\nOption C - This option might not work because modifying DNS will redirect all traffic publicly accessible webpage\n\nOption D - This option requires a lot of set up\n\nOption E - This option helps: Shows a custom error page when the error occurs","comment_id":"1100200"},{"timestamp":"1740110160.0","poster":"teeee123","comment_id":"1359616","content":"Selected Answer: AE\nMaybe A and E","upvote_count":"1"},{"timestamp":"1728370980.0","upvote_count":"1","poster":"hoef03","content":"Selected Answer: AC\nAC, beacuse for E to work, another s3 origin needs to be created, ( OAI when not static website ) , and a behaviour for the path routing to the error html.. Also unclear what the \"DNS record motification\" is made for.","comment_id":"1294611"},{"content":"Selected Answer: AE\nCustom error pages need to setup in different location then source (where web pages is hosted), configure CloudFront to use those custom error pages","timestamp":"1727061720.0","poster":"Parimal1983","upvote_count":"2","comment_id":"932690"},{"comment_id":"871018","poster":"Sarutobi","timestamp":"1727061720.0","content":"Selected Answer: AE\nWe need a combination, so A provides the error page; should we go with DNS health-check (C+A) or CloudFront (E+A)? In my case, I try to stick to a single service to do failover, and DNS is a great option, but it looks like, in this question, CloudFront is already present with the least-operational overhead.","upvote_count":"5"},{"comment_id":"819931","poster":"dev112233xx","content":"Selected Answer: AE\nA&E are the correct answers imo","upvote_count":"1","timestamp":"1727061720.0"},{"upvote_count":"1","comment_id":"1275437","content":"A. Create an Amazon S3 bucket. Configure the S3 bucket to host a static webpage. Upload the custom error pages to Amazon S3.\n E. Add a custom error response by configuring a CloudFront custom error page. Modify DNS records to point to a publicly accessible web page.","poster":"amministrazione","timestamp":"1725090600.0"},{"comment_id":"1241251","content":"Selected Answer: AC\nOption A - Allow us to expose a error page with low effort.\nOption B - Requires a lot of set up\nOption C - Allow us to redirect all the traffic to our error page exposed by S3 in case of errors.\nOption D - requires a lot of set up\nOption E - Custom Error Pages in CloudFront refers to the same Origin (in our case the Load Balancer) so it does not work with all the other answers.\n\nSo correct answer are A and C","timestamp":"1719992640.0","upvote_count":"2","poster":"agatim"},{"comment_id":"1230062","poster":"roger8t8","timestamp":"1718305800.0","upvote_count":"1","content":"A & E \nhttps://aws.amazon.com/blogs/aws/custom-error-pages-and-responses-for-amazon-cloudfront/"},{"content":"I think it is wordplay. Option A says to upload \"error pages\", which will be an overhead for creating a page for each error and unnecessary. that's where C & E are correct","comments":[{"content":"my exact thoughts. Why not use already available pages","timestamp":"1736375760.0","poster":"shmoeee","upvote_count":"1","comment_id":"1338111"}],"timestamp":"1717544280.0","comment_id":"1224416","poster":"azhar3128","upvote_count":"4"},{"comment_id":"1218789","content":"Selected Answer: AE\nA and E according to AWS documentation: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/GeneratingCustomErrorResponses.html#custom-error-pages-procedur","upvote_count":"1","poster":"iulian0585","timestamp":"1716708240.0"},{"upvote_count":"6","content":"Selected Answer: AE\nThe only problem with E is that it say \"Modify DNS records to point to a publicly accessible web page\" at the end. It doesn't make sense to begin with. And configuring custom error responses in CF has nothing to do with DNS anyway.","poster":"kz407","timestamp":"1710506700.0","comment_id":"1174266"},{"timestamp":"1710251160.0","content":"I think why is not A is because of this sentence - \"The webpage returns successfully when a solutions architect reloads the webpage immediately after the error occurs.\" - so let's not think it as requiring a maintenance page","upvote_count":"1","poster":"MoT0ne","comment_id":"1171737"},{"comment_id":"1080910","timestamp":"1701020220.0","upvote_count":"2","content":"should be AE","poster":"abeb"},{"timestamp":"1699701660.0","upvote_count":"3","comment_id":"1067794","poster":"severlight","content":"Selected Answer: AE\nI haven't found out why should we use C."},{"upvote_count":"3","content":"Selected Answer: AE\nAgree with Raj40","timestamp":"1693362600.0","comment_id":"993658","poster":"bur4an"},{"timestamp":"1693134300.0","comment_id":"991403","upvote_count":"2","comments":[{"upvote_count":"1","poster":"jainparag1","timestamp":"1700731740.0","content":"Do you have any further reference to your explanation of custom code requirement to fetch the error page from S3?","comment_id":"1078289"},{"content":"not really , you just need to static url provided by aws when you use the bucket for static webpage and embed it anywhere to reach to the static website","comment_id":"1141756","timestamp":"1707193920.0","upvote_count":"1","poster":"_Jassybanga_"}],"poster":"dimitry_khan_arc","content":"Selected Answer: CE\nC & E.\nB & D are incorrect. Managing lambda is overhead.\nA is incorrect. Static page from S3 need to retrieve with custom code."},{"timestamp":"1689761820.0","upvote_count":"4","content":"Selected Answer: AE\nAE because it accomplishes the task and is the least complex.","poster":"cattle_rei","comment_id":"956508"},{"poster":"NikkyDicky","comment_id":"934835","content":"Selected Answer: AE\nAE is right","timestamp":"1687818300.0","upvote_count":"2"},{"upvote_count":"2","timestamp":"1684846020.0","poster":"rtguru","comment_id":"904908","content":"Correct answer is A&E"},{"comment_id":"852782","timestamp":"1679978940.0","upvote_count":"1","poster":"mfsec","content":"Selected Answer: AE\nAE - easy"},{"timestamp":"1678182960.0","comment_id":"831723","upvote_count":"1","content":"Selected Answer: AE\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html","poster":"kiran15789"},{"poster":"higashikumi","content":"Explanation:\nOption A allows the creation of a custom error page that can be hosted on an S3 bucket. Option E provides a way to configure a custom error response for CloudFront, which can point to the S3 bucket hosting the error page. This allows visitors to see a custom error page without modifying any of the application infrastructure.","comment_id":"828287","timestamp":"1677871140.0","upvote_count":"3"},{"comment_id":"813074","upvote_count":"1","timestamp":"1676729760.0","poster":"Pratap","content":"A and E as per https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/GeneratingCustomErrorResponses.html#custom-error-pages-procedure"},{"comment_id":"807109","timestamp":"1676269320.0","content":"A is incorrect because, Cloud front already handles OAI and its easy to build up error page with it. DNS records apply is pretty quick, So C,E are correct.","poster":"God_Is_Love","upvote_count":"3"},{"comment_id":"788913","poster":"vsk12","comments":[{"poster":"MRL110","timestamp":"1690332900.0","content":"Option E says: \"Modify DNS records to point to a publicly accessible web page\" which should mean Route53 here I guess.","comment_id":"963217","upvote_count":"1"}],"content":"A & C as S3 can be used to host the static website and Route 53 can be configured for health checks and fail-over routing.\nRefer AWS documentation -\nRoute 53 Fail Over S3\n(https://aws.amazon.com/premiumsupport/knowledge-center/fail-over-s3-r53/)\n\nOption E is wrong as CloudFront would return the error response for failure and does not provide a page that Route 53 can point to.","timestamp":"1674750300.0","upvote_count":"2"},{"timestamp":"1672339020.0","upvote_count":"2","poster":"excoRt","content":"Selected Answer: AE\nA & E - Classic Cloudfront error page mechanism","comment_id":"761369"},{"poster":"Untamables","content":"Selected Answer: AE\nOption A and E are the most simple way to meet the requirement.","upvote_count":"3","comment_id":"759334","timestamp":"1672199460.0"},{"comment_id":"753911","timestamp":"1671776400.0","content":"I go with AE\nsince R53 \"Evaluate Target Health\" works with Alias Records that support health checks, so CLDFR distribution cannot be selected","poster":"ptpho","upvote_count":"2"},{"upvote_count":"3","comment_id":"753804","timestamp":"1671762420.0","content":"Selected Answer: AE\nAE\nSAP-C01 #831","poster":"JimmyWong0911"},{"content":"AE\nSAP-C01 #831","poster":"spencer_sharp","upvote_count":"2","comment_id":"752117","timestamp":"1671616980.0"},{"upvote_count":"4","timestamp":"1670757720.0","content":"Answer: A & C\n\nC & E never state where is the publicly accessible webpage.","poster":"robertohyena","comment_id":"741628"},{"timestamp":"1670695620.0","poster":"masetromain","comment_id":"741162","upvote_count":"3","content":"I want to answer AC.\nAnswer A to have a static web page.\nThe C response to have an ALB status check."}],"question_text":"A retail company is operating its ecommerce application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The company uses an Amazon RDS DB instance as the database backend. Amazon CloudFront is configured with one origin that points to the ALB. Static content is cached. Amazon Route 53 is used to host all public zones.\nAfter an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway) error. The root cause is malformed HTTP headers that are returned to the ALB. The webpage returns successfully when a solutions architect reloads the webpage immediately after the error occurs.\nWhile the company is working on the problem, the solutions architect needs to provide a custom error page instead of the standard ALB error page to visitors.\nWhich combination of steps will meet this requirement with the LEAST amount of operational overhead? (Choose two.)","question_images":[],"unix_timestamp":1670695620,"timestamp":"2022-12-10 19:07:00","topic":"1","answer_ET":"AE"},{"id":"fdMPhCM1G2vefSz6L0T6","timestamp":"2023-01-15 10:31:00","exam_id":33,"answer_description":"","answer_images":[],"unix_timestamp":1673775060,"choices":{"B":"Use an AWS Step Functions state machine to pass events to the Lambda function.","A":"Use an Amazon Simple Queue Service (Amazon SQS) queue to store events and invoke the Lambda function.","D":"Use an Amazon Simple Notification Service (Amazon SNS) topic to store events and Invoke the Lambda function.","C":"Use an Amazon EventBridge rule to pass events to the Lambda function."},"topic":"1","answer":"A","discussion":[{"upvote_count":"5","content":"Selected Answer: A\nThe correct answer is A. Using an Amazon Simple Queue Service (SQS) queue to store events and invoke the Lambda function is a good solution to decouple the third-party service calls and ensure that all the calls are eventually completed. SQS is a fully managed, reliable, and highly scalable message queuing service that allows applications to send, store, and receive messages between distributed components. By sending the third-party service calls to an SQS queue, it allows the application to continue processing without waiting for the third-party services to respond, which can result in faster response times and lower error rates.","timestamp":"1673775060.0","poster":"masetromain","comment_id":"776356","comments":[{"comment_id":"776357","content":"Other options like AWS Step Functions state machine, Amazon EventBridge, and Amazon Simple Notification Service (SNS) topic are not appropriate for this use case. AWS Step Functions is a service that makes it easy to coordinate the components of distributed applications and microservices using visual workflows. Amazon EventBridge is a serverless event bus that makes it easy to connect applications together using data from your own applications, integrated SaaS applications, and AWS services. Amazon SNS is a fully managed messaging service for both application-to-application and application-to-person (A2P) communication. These services are not focused on providing message queues and would not be the best fit for this use case.","poster":"masetromain","upvote_count":"1","timestamp":"1673775060.0"}]},{"content":"Selected Answer: A\nwhile polling a, c is another solution accomodating the requirement. In the real case, i would pick c for a large scale eda app scenario","timestamp":"1736726760.0","comment_id":"1339737","upvote_count":"1","poster":"GabrielShiao"},{"comment_id":"1302422","content":"Selected Answer: A\nDecoupling = SQS","poster":"AWSum1","timestamp":"1729769580.0","upvote_count":"1"},{"poster":"nimbus_00","upvote_count":"1","comment_id":"1295080","content":"Selected Answer: A\nSQS Queue = Decoupling the service calls + Eventual completion + Error handling and retries (DLQ)","timestamp":"1728468600.0"},{"comment_id":"1276376","upvote_count":"1","content":"A. Use an Amazon Simple Queue Service (Amazon SQS) queue to store events and invoke the Lambda function.","poster":"amministrazione","timestamp":"1725251760.0"},{"comment_id":"1175582","upvote_count":"1","poster":"career360guru","timestamp":"1710650100.0","content":"Selected Answer: A\nOption A"},{"comment_id":"1103717","upvote_count":"2","poster":"career360guru","content":"Selected Answer: A\nOption A","timestamp":"1703278320.0"},{"upvote_count":"1","timestamp":"1700828940.0","content":"Selected Answer: A\nSQS support dead letter queue and retry if the event processed fails","poster":"HC888","comment_id":"1079250"},{"timestamp":"1688333880.0","content":"Selected Answer: A\nA no brainer","upvote_count":"1","poster":"NikkyDicky","comment_id":"941256"},{"content":"Selected Answer: A\nstep functions would not help on the decoupling if you are not using an asynchronous element in this architecture which is SQS. the application need to have the ability to move out from synchronous calls to the third party services. correct answer is A.","upvote_count":"2","timestamp":"1683690120.0","poster":"rbm2023","comment_id":"893579"},{"timestamp":"1680265920.0","upvote_count":"1","content":"Selected Answer: A\nA : SQS QUEUE","comment_id":"857066","poster":"hpipit"},{"content":"Selected Answer: A\nSQS for decoupling","timestamp":"1679848020.0","upvote_count":"2","poster":"mfsec","comment_id":"851257"},{"poster":"c73bf38","content":"Selected Answer: A\nSQS ---> Lambda is the correct option","timestamp":"1677111360.0","comment_id":"818564","upvote_count":"2"},{"timestamp":"1675118460.0","upvote_count":"1","comment_id":"793421","poster":"zozza2023","content":"Selected Answer: A\ndecouple ==> SQS"},{"timestamp":"1674923760.0","content":"Selected Answer: A\nThe application needs to pass the initiative to the next step. That means the application does not wait the response from the Lambda function, it should have the responsibility only to call the Lambda function. To do so, the application only throw the job information to Amazon SQS queue and finish. After that, AWS Lambda function can pull the job information from SQS queue and start processing actively.\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html","comment_id":"790808","poster":"Untamables","upvote_count":"2"},{"comment_id":"788868","content":"I vote for C - use Step Functions with its callback feature to throttle the third party api call.","poster":"Qing","upvote_count":"1","timestamp":"1674747600.0"}],"question_images":[],"answers_community":["A (100%)"],"isMC":true,"question_id":3,"url":"https://www.examtopics.com/discussions/amazon/view/95399-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"A","question_text":"A company is running an application in the AWS Cloud. Recent application metrics show inconsistent response times and a significant increase in error rates. Calls to third-party services are causing the delays. Currently, the application calls third-party services synchronously by directly invoking an AWS Lambda function.\n\nA solutions architect needs to decouple the third-party service calls and ensure that all the calls are eventually completed.\n\nWhich solution will meet these requirements?"},{"id":"CB0Hd9VxJwOOb8Yh1yrn","answer_description":"","timestamp":"2023-01-15 14:20:00","topic":"1","exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/95416-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"D","question_images":[],"discussion":[{"timestamp":"1673975100.0","upvote_count":"27","comment_id":"779100","content":"Selected Answer: D\nThe correct answer is D. Create an IAM role in the sales account and grant access to the S3 bucket. From the marketing account, assume the IAM role in the sales account to access the S3 bucket. Update the QuickSight role to create a trust relationship with the new IAM role in the sales account.\n\nThis solution meets the requirements by allowing the marketing team to access the data in the S3 bucket in the sales account through assuming an IAM role, which eliminates the need to copy the data or share the KMS key, and also eliminates the need to modify the S3 bucket policy or create a KMS grant. This solution allows to use the same access to the bucket without duplicating data and re-encrypting it.","poster":"masetromain","comments":[{"comment_id":"779101","comments":[{"content":"C. Update the S3 bucket policy in the marketing account to grant access to the QuickSight role. Create a KMS grant for the encryption key that is used in the S3 bucket. Grant decrypt access to the QuickSight role. Update the QuickSight permissions in the marketing account to grant access to the S3 bucket is not correct because the Sales team's S3 bucket is in a different account, so the Marketing team cannot update the policy on the Sales team's S3 bucket.","comment_id":"779102","upvote_count":"2","timestamp":"1673975160.0","poster":"masetromain"}],"poster":"masetromain","content":"A. Create a new S3 bucket in the marketing account. Create an S3 replication rule in the sales account to copy the objects to the new S3 bucket in the marketing account. Update the QuickSight permissions in the marketing account to grant access to the new S3 bucket is not correct because it would create unnecessary data duplication and increased storage costs.\n\nB. Create an SCP to grant access to the S3 bucket to the marketing account. Use AWS Resource Access Manager (AWS RAM) to share the KMS key from the sales account with the marketing account. Update the QuickSight permissions in the marketing account to grant access to the S3 bucket is not correct because it does not provide a secure way to share the KMS key between accounts and also it would create unnecessary data duplication and increased storage costs.","upvote_count":"4","timestamp":"1673975100.0"}]},{"comment_id":"929757","poster":"Maria2023","content":"Selected Answer: D\nThe catch is in the answers - \"Update the S3 bucket policy in the marketing account\". We don't need to access a bucket in the marketing but the sales account.","upvote_count":"9","timestamp":"1687367340.0"},{"upvote_count":"1","timestamp":"1737898380.0","content":"Selected Answer: D\nThe correct answer is D.\n\nRationale:\n- Lowest operational overhead using native IAM mechanisms\n- Enables secure cross-account access through role assumption\n- Maintains centralized access control\n- No data duplication or additional storage costs\n- Works seamlessly with existing KMS encryption\n\nOther options' drawbacks:\nA: Duplicates data and costs\nB: SCPs aren't for granular access control\nC: Incorrect bucket policy location (bucket is in sales account, not marketing)","comment_id":"1346931","poster":"kylix75"},{"timestamp":"1735003920.0","comment_id":"1330991","poster":"bhanus","content":"Selected Answer: C\nOption C provides the most straightforward and efficient solution with the least operational overhead. It directly addresses the cross-account access need while maintaining security through appropriate S3 bucket and KMS key policies.","upvote_count":"3"},{"upvote_count":"1","content":"Selected Answer: C\nCreating an IAM role in the sales account that grants access to the S3 bucket and allowing the marketing account (QuickSight) to assume that role.","poster":"nimbus_00","comment_id":"1295093","timestamp":"1728469500.0"},{"comment_id":"1276386","upvote_count":"1","content":"C. Update the S3 bucket policy in the marketing account to grant access to the QuickSight role. Create a KMS grant for the encryption key that is used in the S3 bucket. Grant decrypt access to the QuickSight role. Update the QuickSight permissions in the marketing account to grant access to the S3 bucket.","timestamp":"1725253080.0","poster":"amministrazione"},{"poster":"Jason666888","comments":[{"upvote_count":"1","timestamp":"1724909760.0","poster":"helloworldabc","content":"just D","comment_id":"1274360"},{"timestamp":"1722907920.0","comment_id":"1261330","poster":"Jason666888","upvote_count":"3","content":"In C, \"Update the S3 bucket policy in the marketing account\" should be changed to \"Update the S3 bucket policy in the sales account\""}],"comment_id":"1261329","content":"Selected Answer: C\nThere must be a typo in C.\n\nIn the context of option D, if Amazon QuickSight needs to access data in an S3 bucket in a different AWS account, and the setup involves assuming multiple roles, this approach could be problematic. QuickSight would not be able to assume the role in the sales account while simultaneously using its own role in the marketing account.","timestamp":"1722907860.0","upvote_count":"4"},{"timestamp":"1722525300.0","comments":[{"comment_id":"1261325","timestamp":"1722907620.0","content":"Dude, do you have any idea of what Petabytes amount of data mean? No one would do that in real life if there's other options","poster":"Jason666888","upvote_count":"1"}],"poster":"8693a49","upvote_count":"1","content":"Selected Answer: A\nWhat is QuickSight rote? It can't be D. I'm assuming there is no typo, so C is wrong too. B is wrong because you can't grant that permission with SCPs.\n\nA would work provided that the replication permissions are set up correctly. It's not great because I don't think it's necessary to duplicate the data, but it's the only viable option we are given.","comment_id":"1259458"},{"content":"Selected Answer: C\nC should be correct if change typo from market account to sales account for S3 bucket policy statement.","poster":"vip2","comment_id":"1238055","timestamp":"1719483540.0","upvote_count":"3"},{"poster":"quizzical_kiwi","timestamp":"1717952100.0","content":"Selected Answer: C\nAgree with other answers on C. This question is clearly a typo, and \"marketing\" should be changed to \"sales\" in C. The resolution for this scenario is even stated in the AWS Knowledge base, and the solution is identical when replacing \"marketing\" with \"sales\": https://repost.aws/knowledge-center/quicksight-cross-account-s3","comment_id":"1227432","upvote_count":"3"},{"timestamp":"1713875880.0","upvote_count":"2","poster":"teo2157","comment_id":"1200730","content":"Selected Answer: C\nIt should be C and there should be a misspelling in \"Update the S3 bucket policy in the marketing account\" when it's referring to sales account"},{"comments":[{"content":"https://repost.aws/knowledge-center/quicksight-cross-account-s3","timestamp":"1709651460.0","comment_id":"1166564","upvote_count":"1","poster":"djeong95"}],"content":"I think this is a great question with poorly phrased answers. If I have to choose between C and D, it would be neither since they both do not provide complete answers. Let me explain:\n\nFor C, you are updating the S3 bucket policy for the marketing account, when you should be doing that for the sales account. So, C is wrong. However, if that were fixed to the sales account, everything would make sense, since the sales account would be providing the right policy, granting the correct KMS key permission, and the marketing account would be tweaking its permission in QuickSight. \n\nFor D, it is wrong simply because it says nothing about providing KMS key grant. Not only do you have to establish trust policy in the QuickSight role to access S3 bucket, you have to allow Decrypt to happen. You have to explicitly spell this out (read the permission part in the link below).\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingKMSEncryption.html","upvote_count":"2","timestamp":"1709651160.0","poster":"djeong95","comment_id":"1166556"},{"poster":"VerRi","timestamp":"1708860540.0","content":"Selected Answer: D\nOption C: Update the S3 bucket policy in the \"marketing account\" ....lol","upvote_count":"2","comment_id":"1158662"},{"timestamp":"1707953700.0","comment_id":"1150614","upvote_count":"2","content":"Selected Answer: C\nThe answer is C. Update the S3 bucket policy in the sales account to grant access to the QuickSight role in the marketing account. Create a KMS grant for the encryption key that is used in the S3 bucket. Grant decrypt access to the QuickSight role. Update the QuickSight permissions in the marketing account to grant access to the S3 bucket.\n\nOption C correctly identifies the need to update the S3 bucket policy to grant access specifically to the QuickSight IAM role in the marketing account, which directly addresses the requirement for cross-account access to S3 data. Additionally, creating a KMS grant for the encryption key to allow decrypt access by the QuickSight role aligns with best practices for secure, cross-account access to encrypted S3 data. This approach minimizes operational overhead by using existing roles and permissions without the need for replication or additional resource sharing mechanisms.","poster":"8608f25"},{"timestamp":"1706990280.0","poster":"AimarLeo","content":"the question is badly formulated.. with all given options missing each a spec .. none of the answers are fully convincing","upvote_count":"2","comment_id":"1139558"},{"timestamp":"1705049400.0","comment_id":"1120584","content":"Selected Answer: C\nAll answers are wrong:\n\nA. No KMS, not necessary replication \nB. No IAM\nD. No KMS\n\n\nBut the most likely answer is C.\n\n\"Update the S3 bucket policy in the marketing account\"\nThe question was never asked marketing s3 team bucket and all the data store in sales team S3 bucket.\nI think it's a typing error (marketing-> sales).","upvote_count":"4","poster":"tmlong18"},{"content":"Selected Answer: D\nOption D","timestamp":"1703281080.0","poster":"career360guru","comment_id":"1103731","upvote_count":"2"},{"upvote_count":"2","timestamp":"1703154780.0","poster":"ayadmawla","comment_id":"1102359","content":"Selected Answer: D\nAnswer is D - see: https://medium.com/codebyte/cross-account-s3-object-copying-with-kms-encrypted-buckets-5ebabef8aa03"},{"poster":"bjexamprep","content":"none of the answers is correct.\nA: no mention of role granted to quicksight and no permission to KMS is granted. \nB: SCP is not designed for this.\nC: no mentioning of creating S3 bucket in marketing account. QuickSight role is created in Marketing account, while the dycryption access is required in sales account.\nD: Lack of dycryption access to KMS is grated to the new created IAM role in sales account.","comment_id":"1088170","upvote_count":"1","timestamp":"1701747480.0"},{"timestamp":"1699954860.0","content":"Selected Answer: A\nlooks like the answer is D, but take a look on Hyperdanny's answer","comment_id":"1070190","poster":"severlight","upvote_count":"1"},{"comment_id":"1003612","content":"Selected Answer: A\nD is not correct. Trust relationship must be established in the role in Sales account to grant access to Marketing account..","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1699698120.0","comment_id":"1067757","content":"Trust relationship must be established on both sides. From Marketing account, the role must have allow to assume the IAM role in Sales account. In Sales account IAM role must have Principle == to Marketing account.\nD is correct.","poster":"ele"}],"timestamp":"1694311560.0","poster":"rsn"},{"poster":"uC6rW1aB","comment_id":"1001170","timestamp":"1694062260.0","upvote_count":"2","content":"Selected Answer: B\nThe problems with option D are mainly that it adds more operational burden and complexity relative to the other options, and does not explicitly address how KMS keys are shared.\nOption B use AWS Resource Access Manager (AWS RAM) to share the KMS key and access to S3 bucket looks more reasonable"},{"comment_id":"983528","poster":"softarts","content":"Selected Answer: D\nD for sure","upvote_count":"3","timestamp":"1692269700.0"},{"timestamp":"1689512280.0","poster":"Hyperdanny","comment_id":"953323","upvote_count":"4","content":"Selected Answer: A\nAll answers seem to be a little bit off. \n\nWhat confuses me about answer D is \"Update the QuickSight rote, to create a trust relationship with the new IAM role in the sales account.\" Why would you update the Quicksight role?\n\nLooking at all the answers, I think only A is actually feasible, although it is not a good solution to replicate everything....","comments":[{"poster":"rsn","content":"I agree","upvote_count":"1","comment_id":"1003611","timestamp":"1694311440.0"},{"comment_id":"996219","content":"i am also inclined towards A but D is also correct here but i believe it;s poorly worded\ncuz Sales account needs to be the one who maintains \"trust relationship\" with Marketing account; Marketing accounts needs to edit its policy to \"assume Sales role\"","timestamp":"1693584060.0","upvote_count":"4","poster":"chikorita"}]},{"content":"Selected Answer: C\nIt's C, although the wording about s3 bucket being in the marketing dept is probably off.\nOther options make even less sense","poster":"NikkyDicky","upvote_count":"3","timestamp":"1688334720.0","comment_id":"941263"},{"upvote_count":"3","poster":"Jesuisleon","comment_id":"902178","content":"Selected Answer: D\nD Is right and C is wrong. \nI have read the link https://repost.aws/knowledge-center/quicksight-cross-account-s3 \nI found C is really badly worded \"Update the S3 bucket policy in the marketing account to grant access to the QuickSight role\", you should update the S3 bucket policy in the sale account NOT marketing account because S3 is inside sale account not market account.\nCorrect this sentence and based on the link above, I think C is right answer.","timestamp":"1684521480.0"},{"content":"C. Company needs to implement solution, not marketing team.","comment_id":"891776","timestamp":"1683516660.0","upvote_count":"2","poster":"RaghavendraPrakash"},{"comment_id":"865279","timestamp":"1681015560.0","upvote_count":"2","content":"Least operational overhead - C -","poster":"passthatexam1"},{"content":"D\nhttps://repost.aws/knowledge-center/quicksight-cross-account-s3","upvote_count":"3","poster":"yama234","comment_id":"863471","timestamp":"1680841380.0"},{"poster":"mfsec","comment_id":"851282","timestamp":"1679849640.0","upvote_count":"2","content":"Selected Answer: D\nSince the S3 bucket belongs to the sales account, the marketing team cannot directly update the policy on the sales team's S3 bucket. In that case, option D would be the better option."},{"comment_id":"843318","content":"Selected Answer: C\nLEAST operational overhead, you could do D and it would work, but honestly it is three steps w/ C.","timestamp":"1679187420.0","poster":"zejou1","upvote_count":"3"},{"content":"I just found the official documentation about cross-account s3 access by Quicksight : https://aws.amazon.com/premiumsupport/knowledge-center/quicksight-cross-account-s3/\nHence, the answer is C. No IAM role required because Quicksight uses a service role instead of a service-linked role.","poster":"sambb","timestamp":"1678091460.0","upvote_count":"3","comment_id":"830635"},{"timestamp":"1678074120.0","content":"Selected Answer: D\nSame as source bucket to destination bucket copy question in different form. first source should share its data. have a role created for destination bucket and that role will be assumed by dest bucket to get access to data. D is answer. C sounds wrong \"Create KMS grant for encryption key\" sounds wierd.","comment_id":"830525","upvote_count":"2","poster":"God_Is_Love"},{"timestamp":"1676381820.0","upvote_count":"4","poster":"spd","comment_id":"808420","comments":[{"poster":"Sarutobi","content":"That is also my point; the other one, which is C, then is missing the S3 bucket permission in the sales account to provide access from the marketing account.","timestamp":"1677719820.0","upvote_count":"1","comment_id":"826352"},{"upvote_count":"1","poster":"frfavoreto","content":"Exactly. 'D' is correct but incomplete. You can't access KMS-key encrypted S3 objects without access to the key in order to decrypt them.","comment_id":"995119","timestamp":"1693486140.0"}],"content":"Selected Answer: D\nD is the answer but it does have enough information about KMS"},{"content":"Selected Answer: D\nThe rest of options have errors.","upvote_count":"2","poster":"Musk","timestamp":"1675288860.0","comment_id":"795549"},{"upvote_count":"3","content":"Selected Answer: D\nInitially i thought C and D are correct answers BUT seems C is uncorrrect as The marketing team doesn't have access to data that the sales team stores in the S3 bucket","timestamp":"1675118820.0","comment_id":"793424","comments":[],"poster":"zozza2023"},{"poster":"zhangyu20000","upvote_count":"4","content":"D is correct.\nC is not correct because The marketing team needs access to data that the sates team stores in the S3 bucket","timestamp":"1673824680.0","comment_id":"777165"},{"comment_id":"776576","upvote_count":"1","content":"Selected Answer: C\nThe correct answer is option C for ME. (D is also correct but the choice is difficult)\n\nIn this option, the solution architect updates the S3 bucket policy in the marketing account to grant access to the QuickSight role. This allows the QuickSight service to read the data stored in the S3 bucket. Additionally, the solution architect creates a KMS grant for the encryption key that is used in the S3 bucket, granting the QuickSight role the ability to decrypt the data. This will allow the marketing team to access and visualize the data stored in the S3 bucket, while keeping it secure with the use of encryption.\n\nOption A would require the creation of a new S3 bucket in the marketing account and a replication rule to copy the data. This would increase the operational overhead and could also cause data consistency issues.","timestamp":"1673788800.0","comments":[{"upvote_count":"2","content":"C is only allow marketing bucket. But data is stored on sales bucket","poster":"zhangyu20000","comment_id":"777954","timestamp":"1673887980.0"},{"comment_id":"776577","upvote_count":"1","comments":[{"timestamp":"1673788860.0","upvote_count":"2","content":"Option C:\n\n- Update the S3 bucket policy in the sales account to grant access to the QuickSight role in the marketing account.\n\n- Create a KMS grant for the encryption key that is used in the S3 bucket. Grant decrypt access to the QuickSight role in the marketing account.\n\n- Update the QuickSight permissions in the marketing account to grant access to the S3 bucket.\n\nThis option allows the marketing team to access the data in the S3 bucket in the sales account, while ensuring that the data remains encrypted at rest and during transfer. The KMS grant allows the marketing team to access the decryption key without having to have access to the key itself.","poster":"masetromain","comments":[{"content":"Option D:\n\n- Create an IAM role in the sales account and grant access to the S3 bucket.\n- From the marketing account, assume the IAM role in the sales account to access the S3 bucket.\n- Update the QuickSight role, to create a trust relationship with the new IAM role in the sales account.\n\nThis option is similar to option C but instead of using KMS grant, it uses IAM role to access the S3 bucket in the sales account. This option also allows the marketing team to access the data in the S3 bucket in the sales account, while ensuring that the data remains encrypted at rest and during transfer.","poster":"masetromain","upvote_count":"1","comment_id":"776581","timestamp":"1673788860.0"}],"comment_id":"776580"}],"timestamp":"1673788800.0","poster":"masetromain","content":"Option B would require the creation of a service control policy (SCP) in the marketing account, and the use of AWS RAM to share the KMS key, but this option would not grant the QuickSight role the ability to decrypt the data.\n\nOption D would require creating an IAM role in the sales account and granting access to the S3 bucket. From the marketing account, assuming the IAM role in the sales account to access the S3 bucket. This would also increase operational overhead and complexity."},{"upvote_count":"1","timestamp":"1679201940.0","poster":"ignorica","comment_id":"843448","content":"same as zhangyu wrote, C is not correct..wrong account specified..bucket is in the Sales one"}],"poster":"masetromain"}],"question_id":4,"answer":"D","answers_community":["D (61%)","C (29%)","8%"],"isMC":true,"question_text":"A company is running applications on AWS in a multi-account environment. The company's sales team and marketing team use separate AWS accounts in AWS Organizations.\n\nThe sales team stores petabytes of data in an Amazon S3 bucket. The marketing team uses Amazon QuickSight for data visualizations. The marketing team needs access to data that the sates team stores in the S3 bucket. The company has encrypted the S3 bucket with an AWS Key Management Service (AWS KMS) key. The marketing team has already created the IAM service role for QuickSight to provide QuickSight access in the marketing AWS account. The company needs a solution that will provide secure access to the data in the S3 bucket across AWS accounts.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","unix_timestamp":1673788800,"choices":{"C":"Update the S3 bucket policy in the marketing account to grant access to the QuickSight role. Create a KMS grant for the encryption key that is used in the S3 bucket. Grant decrypt access to the QuickSight role. Update the QuickSight permissions in the marketing account to grant access to the S3 bucket.","B":"Create an SCP to grant access to the S3 bucket to the marketing account. Use AWS Resource Access Manager (AWS RAM) to share the KMS key from the sates account with the marketing account. Update the QuickSight permissions in the marketing account to grant access to the S3 bucket.","D":"Create an IAM role in the sales account and grant access to the S3 bucket. From the marketing account, assume the IAM role in the sales account to access the S3 bucket. Update the QuickSight rote, to create a trust relationship with the new IAM role in the sales account.","A":"Create a new S3 bucket in the marketing account. Create an S3 replication rule in the sales account to copy the objects to the new S3 bucket in the marketing account. Update the QuickSight permissions in the marketing account to grant access to the new S3 bucket."},"answer_images":[]},{"id":"Zwvg3EpBoRcH1FS5vwmB","answers_community":["C (100%)"],"answer_ET":"C","choices":{"A":"Migrate the SQL Server databases to Amazon RDS for MySQL by using backup and restore utilities.","D":"Use AWS DataSync to migrate data over the network between on-premises storage and Amazon S3. Set up Amazon RDS for MySQL. Use S3 integration with SQL Server features, such as BULK INSERT.","B":"Use an AWS Snowball Edge Storage Optimized device to transfer data to Amazon S3. Set up Amazon RDS for MySQL. Use S3 integration with SQL Server features, such as BULK INSERT.","C":"Use the AWS Schema Conversion Tool to translate the database schema to Amazon RDS for MySQL. Then use AWS Database Migration Service (AWS DMS) to migrate the data from on-premises databases to Amazon RDS."},"answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/95417-exam-aws-certified-solutions-architect-professional-sap-c02/","question_text":"A company is planning to migrate its business-critical applications from an on-premises data center to AWS. The company has an on-premises installation of a Microsoft SQL Server Always On cluster. The company wants to migrate to an AWS managed database service. A solutions architect must design a heterogeneous database migration on AWS.\n\nWhich solution will meet these requirements?","isMC":true,"topic":"1","discussion":[{"timestamp":"1691695920.0","content":"Selected Answer: C\nThis question quietly smell weird to me but no problem answer is C \nExp : AWS Schema Conversion Tool (SCT) can automatically convert the database schema from Microsoft SQL Server to Amazon RDS for MySQL. This allows for a smooth transition of the database schema without any manual intervention. AWS DMS can then be used to migrate the data from the on-premises databases to the newly created Amazon RDS for MySQL instance. This service can perform a one-time migration of the data or can set up ongoing replication of data changes to keep the on-premises and AWS databases in sync.","comment_id":"978027","upvote_count":"8","poster":"xplusfb"},{"timestamp":"1728470100.0","upvote_count":"1","comment_id":"1295104","poster":"nimbus_00","content":"Selected Answer: C\nSchema conversion required!"},{"upvote_count":"1","comment_id":"1276417","poster":"amministrazione","timestamp":"1725255360.0","content":"C. Use the AWS Schema Conversion Tool to translate the database schema to Amazon RDS for MySQL. Then use AWS Database Migration Service (AWS DMS) to migrate the data from on-premises databases to Amazon RDS."},{"poster":"TonytheTiger","timestamp":"1709926440.0","upvote_count":"3","content":"Selected Answer: C\nThis process becomes easier with services like AWS DMS and AWS Schema Conversion Tool (AWS SCT), which help you migrate your commercial database to an open-source database on AWS with minimal downtime.\n\nIn heterogeneous database migrations, the source and target databases engines are different, as in Oracle to Amazon Aurora, or Oracle to PostgreSQL, MySQL, or MariaDB migrations. The schema structure, data types, and database code in the source and target databases can be quite different, so the schema and code must be transformed before the data migration starts. For this reason, heterogeneous migration is a two-step process:\n\nStep 1. Convert the source schema and code to match that of the target database. You can use AWS SCT for this conversion.\n\nStep 2. Migrate data from the source database to the target database. You can use AWS DMS for this process. \nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/migration-oracle-database/heterogeneous-migration.html","comment_id":"1169055"},{"poster":"career360guru","content":"Selected Answer: C\nOption C","timestamp":"1703286060.0","upvote_count":"1","comment_id":"1103766"},{"timestamp":"1692381420.0","comment_id":"984712","content":"Selected Answer: C\nMy 2 cents, Heterogeneous database migration and SCT go with each other","upvote_count":"3","poster":"SK_Tyagi"},{"timestamp":"1688346900.0","poster":"NikkyDicky","comment_id":"941342","upvote_count":"1","content":"Selected Answer: C\nC of course"},{"upvote_count":"1","comment_id":"926965","timestamp":"1687133160.0","poster":"SkyZeroZx","content":"Selected Answer: C\nkeyword = AWS Schema Conversion Tool"},{"timestamp":"1683692280.0","poster":"rbm2023","comment_id":"893592","content":"Selected Answer: C\nThe question is about heterogenous database migration so in this case we need to convert the DB to a new schema. \nTherefore, answer is C","upvote_count":"2"},{"comment_id":"851285","upvote_count":"1","poster":"mfsec","timestamp":"1679849760.0","content":"Selected Answer: C\nUse the AWS Schema Conversion Tool"},{"upvote_count":"1","timestamp":"1678075140.0","poster":"God_Is_Love","comment_id":"830535","content":"Selected Answer: C\nFor heterogenous DBs, SCT is apt."},{"timestamp":"1675692840.0","comment_id":"799832","poster":"Appon","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/database/migrating-a-sql-server-database-to-a-mysql-compatible-database-engine/","upvote_count":"2"},{"content":"Selected Answer: C\nheterogenous -> frmo onee DB engine to another","timestamp":"1675497900.0","upvote_count":"2","comment_id":"797724","poster":"Musk"},{"comment_id":"796187","upvote_count":"2","content":"Straightforward - C","poster":"MasterP007","timestamp":"1675353180.0"},{"comment_id":"793426","poster":"zozza2023","upvote_count":"3","content":"Selected Answer: C\nC is the answer","timestamp":"1675118880.0"},{"upvote_count":"4","comments":[{"comment_id":"776586","timestamp":"1673789100.0","poster":"masetromain","content":"Option A is not correct because while Amazon RDS for MySQL supports SQL Server databases, it is not a good fit for migrating business-critical applications. The data model and architecture are different and would require significant re-engineering.\n\nOption B is not correct because AWS Snowball Edge Storage Optimized devices are used for transferring large amounts of data to and from AWS, but they do not support SQL Server.\n\nOption D is not correct because AWS DataSync can only transfer files and folders, it does not support SQL Server databases.","upvote_count":"2"}],"content":"Selected Answer: C\nThe correct answer is C. Use the AWS Schema Conversion Tool to translate the database schema to Amazon RDS for MySQL. Then use AWS Database Migration Service (AWS DMS) to migrate the data from on-premises databases to Amazon RDS.\n\nAWS Schema Conversion Tool (SCT) can automatically convert the database schema from Microsoft SQL Server to Amazon RDS for MySQL. This allows for a smooth transition of the database schema without any manual intervention.\n\nAWS DMS can then be used to migrate the data from the on-premises databases to the newly created Amazon RDS for MySQL instance. This service can perform a one-time migration of the data or can set up ongoing replication of data changes to keep the on-premises and AWS databases in sync.","timestamp":"1673789040.0","comment_id":"776585","poster":"masetromain"}],"unix_timestamp":1673789040,"question_images":[],"question_id":5,"exam_id":33,"timestamp":"2023-01-15 14:24:00","answer_images":[],"answer_description":""}],"exam":{"isBeta":false,"name":"AWS Certified Solutions Architect - Professional SAP-C02","numberOfQuestions":529,"isImplemented":true,"isMCOnly":true,"lastUpdated":"11 Apr 2025","provider":"Amazon","id":33},"currentPage":1},"__N_SSP":true}