{"pageProps":{"questions":[{"id":"k0dh5M5Xw0CpfLPfOp4E","question_id":6,"discussion":[{"upvote_count":"7","poster":"2pk","timestamp":"1699980600.0","comment_id":"897620","content":"Selected Answer: B\nThe logs from the firewall appliance are already being sent to Amazon CloudWatch Logs. So , The best approach to meet the given requirements is to create an Amazon CloudWatch metric filter by using a search for CRITICAL events"},{"comment_id":"947215","timestamp":"1704810420.0","poster":"habros","upvote_count":"5","content":"B. As the appliance pipes to CW Logs for consolidation. Define an alarm listening to the metric and should be okay.\n\nD is ONLY CORRECT IF YOU ARE USING AWS FIREWALL MANAGER."},{"upvote_count":"1","poster":"seetpt","comment_id":"1205452","content":"Selected Answer: B\nI think B","timestamp":"1730551320.0"},{"poster":"dkp","comment_id":"1195278","upvote_count":"2","timestamp":"1728882300.0","content":"Selected Answer: B\nanswer B"},{"content":"B is correct: <firewall appliance sends logs to Amazon CloudWatch Logs> means we already have the log in CW logs, only need to create alarm on these log files and send to sends\nA: No need to monitor the state of the firewall\nC and D: no mention of CloudWatch Logs","timestamp":"1722736920.0","poster":"thanhnv142","upvote_count":"4","comment_id":"1139760"},{"upvote_count":"1","comment_id":"899239","poster":"OrganizedChaos25","content":"B is the correct answer","timestamp":"1700148960.0"},{"upvote_count":"1","comment_id":"897448","poster":"devnv","timestamp":"1699962720.0","content":"B is correct"}],"isMC":true,"answer":"B","exam_id":23,"answer_images":[],"unix_timestamp":1684057920,"answer_ET":"B","question_text":"A company’s DevOps engineer is working in a multi-account environment. The company uses AWS Transit Gateway to route all outbound traffic through a network operations account. In the network operations account, all account traffic passes through a firewall appliance for inspection before the traffic goes to an internet gateway.\n\nThe firewall appliance sends logs to Amazon CloudWatch Logs and includes event severities of CRITICAL, HIGH, MEDIUM, LOW, and INFO. The security team wants to receive an alert if any CRITICAL events occur.\n\nWhat should the DevOps engineer do to meet these requirements?","question_images":[],"answers_community":["B (100%)"],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/109224-exam-aws-certified-devops-engineer-professional-dop-c02/","topic":"1","choices":{"D":"Use AWS Firewall Manager to apply consistent policies across all accounts. Create an Amazon EventBridge event rule that is invoked by Firewall Manager events that are CRITICAL. Define an Amazon Simple Notification Service (Amazon SNS) topic as a target. Subscribe the security team’s email address to the topic.","A":"Create an Amazon CloudWatch Synthetics canary to monitor the firewall state. If the firewall reaches a CRITICAL state or logs a CRITICAL event, use a CloudWatch alarm to publish a notification to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team’s email address to the topic.","C":"Enable Amazon GuardDuty in the network operations account. Configure GuardDuty to monitor flow logs. Create an Amazon EventBridge event rule that is invoked by GuardDuty events that are CRITICAL. Define an Amazon Simple Notification Service (Amazon SNS) topic as a target. Subscribe the security team’s email address to the topic.","B":"Create an Amazon CloudWatch metric filter by using a search for CRITICAL events. Publish a custom metric for the finding. Use a CloudWatch alarm based on the custom metric to publish a notification to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team’s email address to the topic."},"timestamp":"2023-05-14 11:52:00"},{"id":"f5HzwCrOlsSeG6qYeTnO","answer_ET":"D","timestamp":"2023-05-14 17:03:00","unix_timestamp":1684076580,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/109237-exam-aws-certified-devops-engineer-professional-dop-c02/","choices":{"D":"Create an SCP that allows access to only approved AWS services. Attach the SCP to the root OU of the organization. Remove the FullAWSAccess SCP from the root OU of the organization.","B":"Use AWS Control Tower to provision the accounts into OUs within the organization. Configure AWS Control Tower to enable AWS IAM Identity Center (AWS Single Sign-On). Configure IAM Identity Center to provide administrative access. Include deny policies on user roles for restricted AWS services.","C":"Place all the accounts under a new top-level OU within the organization. Create an SCP that denies access to restricted AWS services. Attach the SCP to the OU.","A":"Use AWS CloudFormation StackSets to provision IAM policies in each account to deny access to restricted AWS services. In each account, configure AWS Config rules that ensure that the policies are attached to IAM principals in the account."},"question_text":"A company is divided into teams. Each team has an AWS account, and all the accounts are in an organization in AWS Organizations. Each team must retain full administrative rights to its AWS account. Each team also must be allowed to access only AWS services that the company approves for use. AWS services must gain approval through a request and approval process.\n\nHow should a DevOps engineer configure the accounts to meet these requirements?","question_images":[],"question_id":7,"answer":"D","exam_id":23,"topic":"1","discussion":[{"poster":"lunt","upvote_count":"21","comment_id":"907493","content":"Selected Answer: D\nA=local account admin can change this.\nB=local admin has admin permissions. Complicated.\nC=implicit permit on everything else = breaks requirements.\nD= As they want to approve each service, its got to be white-list based SCP setup.\nAnswer is D.","timestamp":"1685117940.0"},{"timestamp":"1713072360.0","poster":"dkp","upvote_count":"5","comment_id":"1195286","content":"Selected Answer: D\nAns D:\nIt is easier to allow approved services than deny all the other services, considering the vast amount of AWS services. it's easier to whitelist than blacklisting all the remaining services."},{"upvote_count":"2","poster":"79f3aa3","comment_id":"1361009","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\n\n\"AWS strongly recommends that you don't attach SCPs to the root of your organization without thoroughly testing the impact that the policy has on accounts. Instead, create an OU that you can move your accounts into one at a time, or at least in small numbers, to ensure that you don't inadvertently lock users out of key services.\"","timestamp":"1740401280.0"},{"content":"Selected Answer: C\nNot Option D, Using allow-list SCP, since:\n - Too restrictive\n - More difficult to maintain\n - Might block essential services\n - Could break account functionality\n - Requires constant updates","upvote_count":"2","poster":"ce0df07","comment_id":"1352120","timestamp":"1738797960.0"},{"content":"Selected Answer: C\nGoing for C as removing the FullAWSAccess SCP from the root OU requires impacts directly in the Administrative Access and restrict necessary administrative actions required for account management and operations.","upvote_count":"3","timestamp":"1737619140.0","poster":"teo2157","comment_id":"1345184"},{"poster":"auxwww","timestamp":"1728828300.0","upvote_count":"2","content":"Selected Answer: D\nD is more straight forward","comment_id":"1296942"},{"timestamp":"1724596680.0","upvote_count":"2","content":"Selected Answer: D\nThe answer is (D). The following SCP example from the AWS DOCUMENT allows accounts to create resource shares that share prefix lists\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_ram.html","poster":"hzaki","comment_id":"1272180"},{"timestamp":"1724146560.0","comment_id":"1269303","poster":"[Removed]","upvote_count":"2","content":"Selected Answer: D\nAgree with D\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html"},{"poster":"jamesf","comment_id":"1259688","upvote_count":"2","content":"Selected Answer: C\nI prefer C than D.\nAs SCP more in Deny but not Allow\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html","timestamp":"1722576480.0"},{"upvote_count":"3","timestamp":"1721866560.0","poster":"auxwww","comment_id":"1254632","content":"Selected Answer: C\nSCP - only deny not allow - So answer is C"},{"poster":"zsoni","timestamp":"1718843760.0","content":"The question is looking to use the Allow List Strategy using SCP. So the answer that best fits is D.","upvote_count":"1","comment_id":"1233386"},{"timestamp":"1718046780.0","upvote_count":"4","poster":"zijo","comment_id":"1228066","content":"Selected Answer: C\nSCPs primary function is not grant permissions by themselves but restrict the permissions that IAM policies and other access control mechanisms can grant."},{"poster":"seetpt","content":"Selected Answer: D\nD seems better.","timestamp":"1714646940.0","upvote_count":"2","comment_id":"1205457"},{"content":"Selected Answer: C\nOption C:\nPlace all the accounts under a new top-level OU within the organization: This allows for centralized management of the accounts.\nCreate an SCP that denies access to restricted AWS services: This ensures that only approved services are accessible. SCPs (Service Control Policies) are the best way to control permissions at the organizational level.\nAttach the SCP to the OU: By attaching the SCP to the OU, all accounts within the OU will inherit the restrictions set by the SCP.\nD is wrong: This option allows access only to approved AWS services by creating an SCP that allows access to only approved services and attaching it to the root OU of the organization. However, this would restrict all accounts, including those of other departments or teams within the organization. It doesn't meet the requirement of allowing each team to retain full administrative rights to its AWS account.","poster":"fdoxxx","comments":[{"timestamp":"1713968520.0","upvote_count":"2","content":"I think Option C is wrong because the question says 'Each team also must be allowed to access only AWS services that the company approves for use'\nWhen you deny specific services they can still access services that have not been approved.","poster":"MalonJay","comment_id":"1201445"}],"upvote_count":"2","timestamp":"1711287300.0","comment_id":"1181613"},{"content":"Selected Answer: C\nConclusion: Option C is the best solution to meet the requirements with operational efficiency and scalability. It allows teams to retain administrative rights while enforcing company-wide controls on service access through SCPs. This approach is straightforward to manage at scale, as adding or removing services from the SCP can adjust access permissions across all accounts within the OU. It directly aligns with the goal of allowing access only to approved AWS services and supports a governance model that can evolve with the organization's needs.","timestamp":"1708154280.0","upvote_count":"3","poster":"kyuhuck","comment_id":"1152410"},{"upvote_count":"2","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html","comment_id":"1143560","poster":"vortegon","timestamp":"1707325860.0"},{"comment_id":"1140144","comments":[{"poster":"thanhnv142","upvote_count":"2","comment_id":"1142348","timestamp":"1707235440.0","content":"correction: D: SCP has allow statement. D perfectly fits this question"}],"poster":"thanhnv142","upvote_count":"4","timestamp":"1707053160.0","content":"Selected Answer: C\nC is correct: <all the accounts are in an organization in AWS Organizations> means we need scps\nA and B: no mention of scps\nD: SCP only denies access, not allow. Additionally, should not attack SCP to the root OU because this may inadvertently denies users' access to AWS services"},{"upvote_count":"2","content":"Selected Answer: C\nC is correct; apart from SCP's only denying ... why would u want to add SCPs to the root org.","comment_id":"1131278","poster":"sksegha","timestamp":"1706151360.0"},{"timestamp":"1704886380.0","content":"D is wrong SCP can only deny, not approve. my answer is C","comment_id":"1118514","upvote_count":"2","poster":"yuliaqwerty"},{"content":"Option C is Correct \nOption D is wrong because AWS strongly recommends that you don't attach SCPs to the root of your organization without thoroughly testing the impact that the policy has on accounts. Instead, create an OU that you can move your accounts into one at a time, or at least in small numbers, to ensure that you don't inadvertently lock users out of key services.\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html","upvote_count":"2","poster":"vikasnm123","comment_id":"1098042","timestamp":"1702720380.0"},{"comment_id":"1088556","poster":"svjl","timestamp":"1701785700.0","content":"Sill C must correct answer. \nThe use case is just to restrict access to not allowed services. Everything else should stay as the current configuration.\n\" Each team must RETAIN full administrative rights to its AWS account. Each team also must be allowed to ACCESS ONLY AWS services that the company approves for use","upvote_count":"2"},{"comment_id":"1066448","poster":"hzhang","timestamp":"1699537980.0","content":"Selected Answer: C\nSCPs alone are not sufficient in granting permissions to the accounts in your organization. No permissions are granted by an SCP. An SCP defines a guardrail, or sets limits, on the actions that the account's administrator can delegate to the IAM users and roles in the affected accounts. \nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html","upvote_count":"2"},{"content":"Selected Answer: C\nD wrong because: Attach the SCP to the root OU of the organization. Remove the FullAWSAccess SCP from the root OU of the organization. This makes locking your own root account with inability with full root access. You need keep root OU full access for better management for other accounts. Better move all to separate OU with the restricted access.","timestamp":"1699188240.0","poster":"2pk","upvote_count":"2","comments":[{"comment_id":"1232228","timestamp":"1718682540.0","poster":"Gomer","content":"Not true. Ok to remove if you replace it with something. References:\n\"SCPs don't affect users or roles in the management account. They affect only the member accounts in your organization.\"\n\"You should not remove the FullAWSAccess policy unless you modify or replace it with a separate policy with allowed actions, otherwise all AWS actions from member accounts will fail.\"\nThe second URL below gives and example of a custom \"Deny\" SCP to replace default FullAWSAccess policy.\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html#strategy_using_scps","upvote_count":"1"}],"comment_id":"1062891"},{"content":"Selected Answer: D\nThis ensures only the approved services can be used in all accounts. \nC can work , however everytime AWS introduces a new service that will be accessible and need to be included in SCP deny to disable it","comment_id":"1013414","upvote_count":"3","poster":"RVivek","timestamp":"1695333900.0"},{"upvote_count":"1","comment_id":"990496","poster":"beanxyz","content":"Selected Answer: C\nI prefer C to D. Say users have full admin access with permission set in their own account and what we need is to use SCP to deny certain services and actions. What is the point of granting explicit access to them again from scp when they have already?","timestamp":"1693022340.0"},{"poster":"totopopo","comment_id":"953492","content":"Selected Answer: D\nIt’s D, because it’s the only one to propose a white list and not a black list.\nWhite list is important because AWS regularly opens new services as GA.","upvote_count":"3","timestamp":"1689526440.0"},{"content":"C seems better if you can create top level OU. Retain the FullAccess to prevent unforeseen issues and restrict access only to selected resources.","comment_id":"953220","upvote_count":"2","poster":"ogwu2000","timestamp":"1689501240.0"},{"content":"I’ll insist on D. FullAWSAccess is the whitelist for ALL services. To deny every service, you will have a very good time writing deny policies as long as FullAWSAccess is around. Hence, remove it to have service whitelisting via SCP.","upvote_count":"1","timestamp":"1688906160.0","comment_id":"947222","poster":"habros"},{"poster":"Wardove","comments":[{"upvote_count":"2","poster":"pepecastr0","timestamp":"1688365080.0","comment_id":"941510","content":"D states that \"Create an SCP that allows access to only approved AWS services\""}],"content":"Selected Answer: C\nBy default, an OU in AWS Organizations comes with a FullAWSAccess service control policy (SCP) attached, which allows all services and actions in the AWS accounts under the OU.\n\nIf you remove the FullAWSAccess SCP without having another SCP in place that allows necessary permissions, you could inadvertently lock out users, including administrators, from the resources and services in the AWS accounts. \nSo answer has to be C","upvote_count":"1","timestamp":"1687547220.0","comment_id":"931888"},{"timestamp":"1686922020.0","comment_id":"925209","poster":"rhinozD","upvote_count":"4","content":"Selected Answer: D\nI see no reason to create a new OU for this case.\nAnd by using the explicit deny strategy, D is more secure."},{"timestamp":"1686296400.0","content":"Selected Answer: B\nB also seems as a possible solution. any objection?","comment_id":"919054","poster":"BasselBuzz","upvote_count":"2"},{"upvote_count":"2","timestamp":"1684076580.0","comment_id":"897630","comments":[{"content":"having full admin rights = does not mean having full execution rights. They can still be admins with IAM admin permissions > SCP permissions will still stop them from using a service without approval. Answer is D.","timestamp":"1685118120.0","comment_id":"907496","upvote_count":"7","poster":"lunt"}],"poster":"2pk","content":"Selected Answer: C\nC is correct answer, D is wrong because it does not meet the specific requirement of allowing each team to retain full administrative rights to its own AWS account."}],"answers_community":["D (53%)","C (45%)","2%"],"answer_images":[],"isMC":true},{"id":"3x1oDFZP9VYXrqJgrZfd","question_images":[],"topic":"1","choices":{"C":"Ensure the Lambda function IAM role has cloudformation:UpdateStack permissions for the stack ARN.","B":"Ensure the Lambda function code returns a response to the pre-signed URL.","A":"Ensure the Lambda function code has exited successfully.","D":"Ensure the Lambda function IAM role has ds:ConnectDirectory permissions for the AWS account."},"answers_community":["B (100%)"],"unix_timestamp":1684059180,"discussion":[{"timestamp":"1703870700.0","content":"Selected Answer: B\nB. Ensure the Lambda function code returns a response to the pre-signed URL.\nExplanation:\nWhen using a custom resource in CloudFormation, the AWS Lambda function responsible for handling the resource creation should send a response to the pre-signed URL provided by CloudFormation. This response signals the completion status of the custom resource creation process to CloudFormation.\n\nIn this case, since the Lambda function successfully created the AD Connector, the engineer should ensure that the Lambda function code includes the logic to send a response to the pre-signed URL. This response should indicate the success status and any relevant data, such as the ARN or other details of the created AD Connector.","poster":"haazybanj","comment_id":"938307","upvote_count":"14"},{"comment_id":"1195289","timestamp":"1728883980.0","upvote_count":"1","content":"Selected Answer: B\nits B","poster":"dkp"},{"timestamp":"1722771240.0","content":"B is correct: <but CloudFormation is not transitioning from CREATE_IN_PROGRESS to CREATE_COMPLETE> means ACF hasnot received a response code from Lambda\nA, C and D: no mention of response code","poster":"thanhnv142","comment_id":"1140148","upvote_count":"2"},{"comment_id":"1055427","content":"Selected Answer: B\nLambda should send a cfnresponsse to presign url","timestamp":"1714212780.0","upvote_count":"1","poster":"YR4591"},{"timestamp":"1712909700.0","content":"B is correct \nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html","upvote_count":"3","comment_id":"1041541","poster":"BaburTurk"},{"upvote_count":"2","poster":"MarDog","content":"Selected Answer: B\nIt's B.","timestamp":"1703115300.0","comment_id":"928822"},{"timestamp":"1700228580.0","content":"B is correct","comment_id":"900071","upvote_count":"2","poster":"OrganizedChaos25"},{"upvote_count":"2","content":"B is the right answer","poster":"devnv","timestamp":"1699963980.0","comment_id":"897463"}],"timestamp":"2023-05-14 12:13:00","isMC":true,"exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/109225-exam-aws-certified-devops-engineer-professional-dop-c02/","question_text":"A DevOps engineer used an AWS CloudFormation custom resource to set up AD Connector. The AWS Lambda function ran and created AD Connector, but CloudFormation is not transitioning from CREATE_IN_PROGRESS to CREATE_COMPLETE.\n\nWhich action should the engineer take to resolve this issue?","question_id":8,"answer_description":"","answer_images":[],"answer":"B","answer_ET":"B"},{"id":"2wNDPktCdlTNzGciovRB","timestamp":"2023-05-14 12:16:00","isMC":true,"choices":{"D":"Create an additional policy to include an Allow rule for the GitPush and PutFile actions. Include a restriction for the specific repositories in the policy statement with a condition that references the feature branches.","C":"Modify the IAM policy. Include a Deny rule for the GitPush and PutFile actions for the specific repositories in the policy statement with a condition that references the main branch.","A":"Create an additional policy to include a Deny rule for the GitPush and PutFile actions. Include a restriction for the specific repositories in the policy statement with a condition that references the main branch.","B":"Remove the IAM policy, and add an AWSCodeCommitReadOnly managed policy. Add an Allow rule for the GitPush and PutFile actions for the specific repositories in the policy statement with a condition that references the main branch."},"topic":"1","question_images":[],"unix_timestamp":1684059360,"answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/109226-exam-aws-certified-devops-engineer-professional-dop-c02/","discussion":[{"timestamp":"1689183600.0","comment_id":"950053","poster":"Just_Ninja","content":"Selected Answer: A\nA is possible!\nIf you think C is correct, then you should know that a policy managed by AWS cannot be modified.","upvote_count":"15"},{"timestamp":"1722868260.0","poster":"jamesf","comment_id":"1261089","content":"Selected Answer: A\nNot C as AWS managed policy cannot be modified","upvote_count":"1"},{"content":"Selected Answer: A\nAWS Managed Policies are read-only, meaning you cannot modify their contents. If you need a similar policy with slight modifications, you can copy the managed policy and create a customer-managed policy.","comment_id":"1228624","timestamp":"1718132160.0","poster":"zijo","upvote_count":"2"},{"content":"Selected Answer: A\nit s A.","poster":"dkp","comment_id":"1195291","timestamp":"1713073020.0","upvote_count":"1"},{"comment_id":"1140159","timestamp":"1707054180.0","upvote_count":"3","poster":"thanhnv142","content":"Selected Answer: A\nA is correct: <The developers should not be able to push changes directly to the main branch> means we should deny these permissions in IAM policy. <managed polic> means we should add another policy, not modify this one. \nB: <Remove the IAM policy>: this is an managed policy, cannot remove it\nC: Cannot modify a managed policy. We can only create another policy\nD: This option would deny commiting code to every sub-branches, which is not correct"},{"timestamp":"1703594880.0","upvote_count":"3","poster":"giovanna_mag","comment_id":"1106015","content":"Selected Answer: A\nA, AWS managed policy cannot be modified, additional policy must be attached with a DENY"},{"timestamp":"1688555220.0","poster":"Blueee","content":"Selected Answer: A\nA is correct","comment_id":"943616","upvote_count":"1"},{"content":"Selected Answer: A\nAWSCodeCommitPowerUser is an AWS-managed policy.\nSo you need to add an additional policy to deny push to the main branch directly.","upvote_count":"3","timestamp":"1686922920.0","comment_id":"925221","poster":"rhinozD"},{"upvote_count":"1","timestamp":"1684875420.0","comment_id":"905228","content":"A is correct","poster":"Kodoma"},{"comment_id":"903755","timestamp":"1684735320.0","upvote_count":"2","poster":"Ryan1002","content":"Selected Answer: A\nIt`s A"},{"comment_id":"902379","poster":"PhuocT","upvote_count":"2","timestamp":"1684562700.0","content":"Selected Answer: C\nC, why we need to create an additional policy?","comments":[{"upvote_count":"5","timestamp":"1684918260.0","content":"You can never modify a managed policy","poster":"EricZhang","comment_id":"905664"}]},{"upvote_count":"3","comment_id":"897464","timestamp":"1684059360.0","poster":"devnv","content":"A is correct"}],"answers_community":["A (94%)","6%"],"answer_ET":"A","question_id":9,"exam_id":23,"question_text":"A company uses AWS CodeCommit for source code control. Developers apply their changes to various feature branches and create pull requests to move those changes to the main branch when the changes are ready for production.\n\nThe developers should not be able to push changes directly to the main branch. The company applied the AWSCodeCommitPowerUser managed policy to the developers’ IAM role, and now these developers can push changes to the main branch directly on every repository in the AWS account.\n\nWhat should the company do to restrict the developers’ ability to push changes to the main branch directly?","answer":"A"},{"id":"kDIVer4sAP2M3Z5s1TLe","exam_id":23,"question_id":10,"isMC":true,"answer_description":"","answers_community":["D (90%)","10%"],"choices":{"D":"Launch a replica environment of everything except Amazon RDS in a different AWS Region. Create an RDS read replica in the new Region, and configure the new environment to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a failover routing policy. In the event of an outage, promote the read replica to primary.","B":"Launch a replica environment of everything except Amazon RDS in a different AWS Region. Create an RDS read replica in the new Region, and configure the new stack to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a latency routing policy.","C":"Launch a replica environment of everything except Amazon RDS in a different AWS Region. In the event of an outage, copy and restore the latest RDS snapshot from the primary Region to the DR Region. Adjust the Route 53 record set to point to the ALB in the DR Region.","A":"Launch a replica environment of everything except Amazon RDS in a different Availability Zone. Create an RDS read replica in the new Availability Zone, and configure the new stack to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a failover routing policy."},"question_text":"A company manages a web application that runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances run in an Auto Scaling group across multiple Availability Zones. The application uses an Amazon RDS for MySQL DB instance to store the data. The company has configured Amazon Route 53 with an alias record that points to the ALB.\n\nA new company guideline requires a geographically isolated disaster recovery (DR) site with an RTO of 4 hours and an RPO of 15 minutes.\n\nWhich DR strategy will meet these requirements with the LEAST change to the application stack?","answer_ET":"D","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/109227-exam-aws-certified-devops-engineer-professional-dop-c02/","unix_timestamp":1684059600,"discussion":[{"upvote_count":"5","content":"Selected Answer: D\nD is correct. Failover policy will route traffic to the ALB in the backup region.","comment_id":"1055436","poster":"YR4591","timestamp":"1714213080.0"},{"timestamp":"1734790380.0","poster":"youonebe","comment_id":"1330060","content":"Selected Answer: D\nD is correct. My answer was C, but GPT told me this:\nThis process does not guarantee a quick recovery within the 4-hour RTO. Restoring from a snapshot would take significant time, and it doesn't provide continuous replication of data to minimize RPO. This option does not meet the RTO requirement because the recovery process (snapshot restore) will take too long. It also doesn’t address continuous data replication, leading to a higher potential RPO.","upvote_count":"1"},{"timestamp":"1728884940.0","poster":"dkp","upvote_count":"2","comment_id":"1195297","content":"Selected Answer: D\ngeographically isolated location applies to option D"},{"upvote_count":"3","poster":"WhyIronMan","timestamp":"1727685960.0","comment_id":"1186686","content":"Selected Answer: D\nAnswer is D.\n\nA. It did not cover the whole scenario. there is a need to promote the read replica otherwise the application in the region will not be able to write in that rds. Also, another Region means geographically isolated, while other Az will not solve the problem.\n\nDetails are everything during an investigation..."},{"timestamp":"1727685900.0","comment_id":"1186685","upvote_count":"1","content":"Answer is D.\n\nA. It did not cover the whole scenario. there is a need to promote the read replica otherwise the application in the region will not be able to write in that rds. Also, another Region means geographically isolated, while other Az will not solve the problem.\n\nDetails are everything during an investigation...","poster":"WhyIronMan"},{"comment_id":"1153859","poster":"jojom19980","comments":[{"poster":"WhyIronMan","upvote_count":"1","content":"A did not cover the whole scenario. there is a need to promote the read replica otherwise the application in the region will not be able to write in that rds. Also, another Region means geographically isolated.\nDetails are everything during an investigation...","timestamp":"1727685840.0","comment_id":"1186684"}],"content":"Selected Answer: A\nthey mentioned geographically not regional , the cost will be more if we make it regional so we can go with the AZ DR","timestamp":"1724058480.0","upvote_count":"2"},{"upvote_count":"3","timestamp":"1722772260.0","content":"Selected Answer: D\nD is correct: < configured Amazon Route 53> and <requires a geographically isolated disaster recovery (DR) site> means fail-over routing and the DR site should be in another region\nA: <Amazon RDS in a different Availability Zone>: We need to setup the DB in a different region, not in a different AZ, which is still in the same region\nB and C: no mention of fail-over","poster":"thanhnv142","comment_id":"1140174"},{"poster":"sarlos","timestamp":"1719959280.0","comment_id":"1112380","content":"D is the answer","upvote_count":"2"},{"timestamp":"1716988620.0","poster":"HugoFM","comment_id":"1083603","content":"What about C? I have an RTO of 4 hours I mean we got time we dont need a read replica we could take time to restore from a snapshot","upvote_count":"3","comments":[{"poster":"davdan99","comment_id":"1117345","content":"Restore Time vs. RTO: While 4 hours might seem like a sufficient window for restoring a snapshot, the actual restore time can vary depending on several factors:\nSnapshot size: Larger snapshots take longer to restore.\nRDS instance type: High-performance instance types can handle restorations faster.\nNetwork bandwidth: Sufficient bandwidth is crucial for speedy data transfer during restoration.\nRDS engine version: Newer versions might have optimized restore processes.\nIn practice, restoring a large RDS snapshot, especially across Regions, could easily take more than 15 minutes, potentially exceeding the RPO and resulting in data loss.","timestamp":"1720510500.0","upvote_count":"2"}]},{"timestamp":"1703872140.0","comment_id":"938332","upvote_count":"4","content":"Selected Answer: D\nD is right","poster":"haazybanj"},{"timestamp":"1700780220.0","upvote_count":"2","content":"D is true","poster":"Kodoma","comment_id":"905229"},{"poster":"devnv","timestamp":"1699964400.0","comment_id":"897466","content":"D is correct","upvote_count":"1"}],"question_images":[],"answer":"D","timestamp":"2023-05-14 12:20:00","topic":"1"}],"exam":{"id":23,"isMCOnly":true,"lastUpdated":"11 Apr 2025","isBeta":false,"provider":"Amazon","isImplemented":true,"name":"AWS Certified DevOps Engineer - Professional DOP-C02","numberOfQuestions":355},"currentPage":2},"__N_SSP":true}