{"pageProps":{"questions":[{"id":"cagRlCNirrGIXjvsSE8R","topic":"1","question_images":[],"discussion":[{"timestamp":"1632847260.0","comments":[{"content":"Agree...","upvote_count":"1","poster":"Moon","timestamp":"1633017240.0","comment_id":"14613"},{"upvote_count":"1","poster":"SachinJha","comments":[{"content":"40 KB for HTTP POST requests. PutMetricData can handle 150 transactions per second (TPS), which is the maximum number of operation requests you can make per second without being throttled.\nYou can request a quota increase.","poster":"DerekKey","comment_id":"408895","upvote_count":"3","timestamp":"1636077300.0"}],"comment_id":"258724","timestamp":"1635217380.0","content":"I agree with C but keep a watch on CloudWatch PutEvent limit which could cause throttling and hence loss of logs. See https://aws.amazon.com/about-aws/whats-new/2017/07/cloudwatch-events-increases-rules-and-api-requests-limits/"}],"comment_id":"13510","content":"C\nAdjusting the batch count to 1 means transferring the log to CloudWatch logs after every event instead of 100 event for example to make it closer to real time.\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html","poster":"donathon","upvote_count":"51"},{"timestamp":"1632716400.0","comment_id":"11024","content":"C makes more sense","poster":"dpvnme","upvote_count":"15"},{"upvote_count":"1","poster":"SkyZeroZx","timestamp":"1687371900.0","content":"Selected Answer: C\nC\nAdjusting the batch count to 1 means transferring the log to CloudWatch logs after every event instead of 100 event for example to make it closer to real time.\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html","comment_id":"929815"},{"content":"I'll go with C. There is similar question in Neal Davis practice tests with 30 minutes :)","poster":"AzureDP900","timestamp":"1640125200.0","comment_id":"506484","upvote_count":"1"},{"content":"C. Use the Amazon CloudWatch Logs agent to stream log messages directly to CloudWatch Logs. Configure the agent with a batch count of 1 to reduce the possibility of log messages being lost in an outage.","timestamp":"1638965460.0","upvote_count":"1","comment_id":"496797","poster":"cldy"},{"comment_id":"493429","timestamp":"1638577140.0","upvote_count":"1","poster":"AzureDP900","content":"I will go with C"},{"poster":"acloudguru","content":"hope i can have such simple question in my exam.","timestamp":"1637572800.0","upvote_count":"1","comment_id":"484031"},{"upvote_count":"2","comment_id":"450009","content":"It's C","poster":"andylogan","timestamp":"1636300560.0"},{"content":"I go for C","timestamp":"1636158780.0","upvote_count":"1","poster":"mimadour21698","comment_id":"424370"},{"upvote_count":"1","comment_id":"362516","poster":"Radhaghosh","timestamp":"1635971160.0","content":"Option C is correct."},{"poster":"WhyIronMan","upvote_count":"1","timestamp":"1635862920.0","content":"I'll go with C","comment_id":"336888"},{"comment_id":"290943","timestamp":"1635822960.0","upvote_count":"2","poster":"wind","content":"B is correct. \"You can now create CloudWatch Events rules that use EC2 Run Command to perform actions on EC2 instances or on-premises servers. This opens the door to all sorts of interesting ideas; here are a few that I came up with:\n\nFinal Log Collection – Collect application or system logs from instances that are being shut down (either manually or as a result of a scale-in operation initiated by Auto Scaling).\""},{"poster":"Kian1","content":"going with C","comment_id":"289470","timestamp":"1635762120.0","upvote_count":"2"},{"content":"its sure is B. Focus on this line \" Occasionally, scaling events or unplanned outages have caused the instances to stop before the latest logs were collected, and the log files were lost.\" Now read this link\nhttps://aws.amazon.com/blogs/aws/ec2-run-command-is-now-a-cloudwatch-events-target/","poster":"AJBA","upvote_count":"2","comment_id":"288505","timestamp":"1635508140.0"},{"poster":"Ebi","timestamp":"1635474540.0","comment_id":"283997","upvote_count":"2","content":"C is my choice"},{"poster":"certainly","comment_id":"281542","timestamp":"1635353700.0","content":"B says Amazon Kinesis Data \"Firehouse\" instead of \"Firehose\". I would go for A.","upvote_count":"1"},{"comment_id":"262961","upvote_count":"2","poster":"sanjaym","timestamp":"1635341160.0","content":"I'll with C."},{"upvote_count":"2","content":"C is correct answer. Batch count is 1 means send every event.","comment_id":"241960","poster":"T14102020","timestamp":"1635186060.0"},{"poster":"jackdryan","comment_id":"228780","comments":[{"upvote_count":"1","poster":"ali98","content":"the problem with C is batch count of 1 . it will send only one event at a time. I have tested it myself, the events get queued up and more the event more long is Queue as batch count if 1.","comment_id":"234563","timestamp":"1634929080.0"}],"timestamp":"1634873640.0","upvote_count":"3","content":"I'll go with C"},{"comment_id":"227798","content":"Answer is C as this is the most reliable solution to centralize logs and is also an AWS best practise","timestamp":"1634832660.0","upvote_count":"1","poster":"Bulti"},{"poster":"Calig","upvote_count":"1","content":"i would go with C because the few minutes of grace period in B only apply in normal shutdown event but for unplanned outage it will not work, whereas C can minimise log loss since it is almost realtime streaming.","timestamp":"1634679660.0","comment_id":"194802"},{"poster":"TK2019","comment_id":"157148","content":"Though it mentions that You can also specify Run Command as a target action when a CloudWatch event occurs. For example, say a CloudWatch event is triggered that an instance in an Auto Scaling group is about to terminate. You can configure CloudWatch so the target of that event is a Run Command script that captures the log files from the instance before it is terminated. But changing the batch size to 1 will have a real time log generation . Also the logs needs to be consolidated which is collected by cron job currently. Cloudwatch agent will provide the cron job that ensures a daemon is always running .\nSo C is better.","upvote_count":"2","timestamp":"1634565000.0"},{"content":"The answer is C: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html","upvote_count":"1","comment_id":"150112","timestamp":"1634428980.0","poster":"7thGuest"},{"timestamp":"1634419200.0","poster":"fullaws","content":"B is correct","upvote_count":"1","comment_id":"148591"},{"upvote_count":"3","poster":"NikkyDicky","timestamp":"1634291940.0","comment_id":"134153","content":"C for sure"},{"upvote_count":"2","poster":"noisonnoiton","content":"go with C\nYou can centralize logs in your applications and AWS services. So hand these\nEasily check to search for specific error codes or patterns, or filter by specific fields\nI can safely keep it for future analysis.","comment_id":"133634","timestamp":"1633957440.0"},{"timestamp":"1633908720.0","poster":"NKnab","content":"b is correct -https://docs.aws.amazon.com/systems-manager/latest/userguide/rc-cwe.html","comment_id":"99798","upvote_count":"2"},{"timestamp":"1633904700.0","poster":"JAWS1600","comment_id":"98324","content":"After doing more research . I am thinking B will work. Here is the explanations. If we set a count of 1 , the batch will be full and published. That means we we have batches of 1 event. It is not a great idea, but only way to avoid loosing information in logs\n\nA batch becomes full and is published when any of the following conditions are met:\n\nThe buffer_duration amount of time has passed since the first log event was added.\n\nLess than batch_size of log events have been accumulated but adding the new log event exceeds the batch_size.\n\nThe number of log events has reached batch_count.\n\nLog events from the batch don't span more than 24 hours, but adding the new log event exceeds the 24 hours constraint.","upvote_count":"1"},{"timestamp":"1633661940.0","content":"cloud watch logs agent doesn't capture all events before the instance is being stopped. Once the instance is stopped, you are not able to collect any logs from the instance. In order for us to capture the events from the scaling or any instances, use a cloud watch event instead and we have few minutes left to call \"AWS Systems Run Command\" to collect all logs before the instance is being stopped. The best choice is B.","comment_id":"97172","upvote_count":"2","poster":"Jeb"},{"timestamp":"1633640700.0","poster":"JAWS1600","comment_id":"90201","upvote_count":"1","content":"B. Another document to show, how it is done.\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/rc-cwe.html"},{"timestamp":"1633639680.0","content":"B. Is the answer\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/monitoring-cloudwatch-metrics.html","comment_id":"90190","upvote_count":"1","poster":"JAWS1600"},{"poster":"ghostrider8001","upvote_count":"1","comment_id":"64148","content":"@wuehie https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html","timestamp":"1633626000.0"},{"comment_id":"55542","comments":[{"timestamp":"1635122280.0","comment_id":"239829","poster":"newme","content":"Can't find any references about it.","upvote_count":"1"}],"content":"About C: There is a quota of 5 requests per second per log stream. Additional requests are throttled. This quota can't be changed.","poster":"wuehie","upvote_count":"1","timestamp":"1633273920.0"},{"comment_id":"44838","poster":"amog","upvote_count":"4","timestamp":"1633223280.0","content":"C make sense"},{"upvote_count":"2","timestamp":"1633125240.0","comment_id":"41195","poster":"markpark","content":"C is the answer"},{"content":"C makes sense","comment_id":"30454","timestamp":"1633071840.0","poster":"dojo","upvote_count":"2"},{"upvote_count":"1","content":"Why ans is B?","timestamp":"1632434340.0","comment_id":"10314","poster":"DalianYifang"}],"unix_timestamp":1568047980,"question_id":376,"timestamp":"2019-09-09 18:53:00","answers_community":["C (100%)"],"answer_images":[],"exam_id":32,"answer_ET":"C","answer":"C","answer_description":"Reference:\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html","choices":{"A":"Update the cron jobs to run every 5 minutes instead of every hour to reduce the possibility of log messages being lost in an outage.","D":"Use Amazon CloudWatch Events to trigger AWS Lambda to SSH into each running instance and invoke the log collection scripts more frequently to reduce the possibility of log messages being lost in an outage.","C":"Use the Amazon CloudWatch Logs agent to stream log messages directly to CloudWatch Logs. Configure the agent with a batch count of 1 to reduce the possibility of log messages being lost in an outage.","B":"Use Amazon CloudWatch Events to trigger Amazon Systems Manager Run Command to invoke the log collection scripts more frequently to reduce the possibility of log messages being lost in an outage."},"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/4958-exam-aws-certified-solutions-architect-professional-topic-1/","question_text":"A three-tier web application runs on Amazon EC2 instances. Cron daemons are used to trigger scripts that collect the web server, application, and database logs and send them to a centralized location every hour. Occasionally, scaling events or unplanned outages have caused the instances to stop before the latest logs were collected, and the log files were lost.\nWhich of the following options is the MOST reliable way of collecting and preserving the log files?"},{"id":"KfzN3rdqQcNRAR04JQAc","answer_description":"","question_images":[],"question_text":"You require the ability to analyze a large amount of data, which is stored on Amazon S3 using Amazon Elastic Map Reduce. You are using the cc2 8xlarge instance type, whose CPUs are mostly idle during processing. Which of the below would be the most cost efficient way to reduce the runtime of the job?","unix_timestamp":1581533760,"discussion":[{"upvote_count":"6","timestamp":"1632491520.0","poster":"BillyC","comment_id":"49667","content":"Yes, C is Correct!"},{"upvote_count":"1","content":"C is correct","comment_id":"1285534","timestamp":"1726622940.0","poster":"thanhpolimi"},{"comment_id":"1266507","content":"C. Use smaller instances that have higher aggregate I/O performance.","timestamp":"1723733820.0","poster":"amministrazione","upvote_count":"1"},{"content":"Selected Answer: A\nFiles are on S3 so it is network not I/O so C is out.\nTo reduce duration of a job, reduce the file size, it will make individual jobs/batch faster. It will use more cpu but we have lots of it so that is fine.\n\nIncreasing file size would reduce overall (daily) cpu usage but each job runtime will take longer as it will have more data to process","upvote_count":"1","comment_id":"1215202","timestamp":"1716320280.0","poster":"a6a3d55"},{"timestamp":"1687185720.0","comment_id":"927609","poster":"SkyZeroZx","content":"Selected Answer: C\nC is more logic","upvote_count":"1"},{"poster":"rtguru","content":"C is best fit","timestamp":"1684444200.0","comment_id":"901500","upvote_count":"1"},{"comment_id":"635817","poster":"hilft","upvote_count":"1","timestamp":"1658622660.0","content":"C.\nD is wrong larger files slow down the performance\nA is wrong smaller files but more files slow down the performance"},{"content":"Create fewer, larger files on Amazon S3 is to get the better CPU performance, here in question we already have CPU idle so can't be the answer.","poster":"vbal","comment_id":"499755","upvote_count":"2","timestamp":"1639274760.0"},{"content":"C Correct","upvote_count":"1","poster":"Akhil254","timestamp":"1635867780.0","comment_id":"406203"},{"upvote_count":"1","content":"C.\nSince I/O is the bottleneck","comment_id":"345004","poster":"01037","timestamp":"1635700740.0"},{"upvote_count":"1","comment_id":"276320","poster":"Ajeeshpv","content":"C is the correct one","timestamp":"1635345180.0"},{"timestamp":"1634603520.0","comment_id":"230373","upvote_count":"1","content":"It talks about cost efficient way to reduce processing time. Having a server that is mostly idle means several smaller instances could help speed it up ?","poster":"BillyT"},{"comments":[{"poster":"newme","comment_id":"210313","timestamp":"1634420160.0","upvote_count":"1","content":"Only A isn't enough though.\nAlso needs more instances to do the processing.\nSo instances don't need to wait long to start processing."}],"content":"It feels like A.\n\"instances that have higher aggregate I/O performance\" is all about EBS, isn't it?\nReading from S3 only uses network, so why does high IO performance instances have anything to do with S3?","upvote_count":"2","comment_id":"210307","poster":"newme","timestamp":"1633826700.0"},{"comment_id":"190279","content":"C is correct","upvote_count":"1","timestamp":"1633755240.0","poster":"srknbngl"},{"content":"I would definitely go with D.","poster":"DS2021","timestamp":"1633557540.0","comment_id":"188804","upvote_count":"2"},{"comment_id":"188584","timestamp":"1633123680.0","poster":"smartassX","upvote_count":"2","content":"\" the most cost efficient way to reduce the runtime of the job\" --> D. Create fewer, larger files on Amazon S3."},{"timestamp":"1632961620.0","poster":"fullaws","content":"C is correct","comment_id":"143848","upvote_count":"1"},{"upvote_count":"1","timestamp":"1632910740.0","comment_id":"131040","poster":"noisonnoiton","content":"go with C"},{"timestamp":"1632610860.0","comment_id":"75182","poster":"Joeylee","content":"C is correct","upvote_count":"1"}],"answer_images":[],"answers_community":["C (50%)","A (50%)"],"choices":{"C":"Use smaller instances that have higher aggregate I/O performance.","A":"Create more, smaller flies on Amazon S3.","B":"Add additional cc2 8xlarge instances by introducing a task group.","D":"Create fewer, larger files on Amazon S3."},"answer":"C","question_id":377,"isMC":true,"exam_id":32,"timestamp":"2020-02-12 19:56:00","url":"https://www.examtopics.com/discussions/amazon/view/13938-exam-aws-certified-solutions-architect-professional-topic-1/","topic":"1","answer_ET":"C"},{"id":"Erg7iH61YsCWjN50Qbdm","timestamp":"2020-11-13 19:59:00","answer_images":[],"answer_ET":"C","exam_id":32,"url":"https://www.examtopics.com/discussions/amazon/view/36943-exam-aws-certified-solutions-architect-professional-topic-1/","topic":"1","choices":{"D":"Use event patterns in Amazon CloudWatch Events to capture DynamoDB API call events with an AWS Lambda function as a target to analyze behavior. Send SNS notifications when anomalous behaviors are detected.","A":"Copy the DynamoDB tables into Apache Hive tables on Amazon EMR every hour and analyze them for anomalous behaviors. Send Amazon SNS notifications when anomalous behaviors are detected.","C":"Use Amazon DynamoDB Streams to capture and send updates to AWS Lambda. Create a Lambda function to output records to Amazon Kinesis Data Streams. Analyze any anomalies with Amazon Kinesis Data Analytics. Send SNS notifications when anomalous behaviors are detected.","B":"Use AWS CloudTrail to capture all the APIs that change the DynamoDB tables. Send SNS notifications when anomalous behaviors are detected using CloudTrail event filtering."},"question_images":[],"answers_community":["C (100%)"],"isMC":true,"discussion":[{"content":"Correct answer is C. DynamoDB Streams is key","timestamp":"1633534800.0","poster":"T14102020","upvote_count":"15","comment_id":"241966"},{"content":"C is correct. \nhttps://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/#:~:text=DynamoDB%20Streams%20is%20a%20powerful,for%20up%20to%2024%20hours.","timestamp":"1634567640.0","comment_id":"344338","poster":"blackgamer","upvote_count":"8"},{"comment_id":"927925","content":"Selected Answer: C\nYou can use Amazon Kinesis Data Streams to capture changes to Amazon DynamoDB.\n\nKinesis Data Streams captures item-level modifications in any DynamoDB table and replicates them to a Kinesis data stream. Your applications can access this stream and view item-level changes in near-real time.","poster":"MHD84","upvote_count":"1","timestamp":"1687207860.0"},{"upvote_count":"1","comment_id":"925696","timestamp":"1686966780.0","poster":"SkyZeroZx","content":"Selected Answer: C\nkeyword -> DynamoDB Streams"},{"upvote_count":"1","content":"from when lambda can write directly to KDA? C? Sure? too confusing","poster":"Arunava1","comment_id":"778839","timestamp":"1673954700.0"},{"comment_id":"772137","poster":"Prasadvd","timestamp":"1673419320.0","upvote_count":"1","content":"Selected Answer: C\nDoes anyone review/moderate?? Almost 100% votes are for C. C is the correct answer as dynamoDB streams will provide original and modified values which the lambda can forward to kinesis for event processing. Cloudwatch events is not going to do what is expected"},{"content":"C\nD - I'm unable to find out DynamoDB table as an event type: https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/EventTypes.html","comment_id":"758481","upvote_count":"1","poster":"evargasbrz","timestamp":"1672144560.0"},{"content":"I'd go with C too","upvote_count":"1","poster":"DarthYoda","comment_id":"716759","timestamp":"1668264480.0"},{"comment_id":"671478","poster":"jujumomma","upvote_count":"2","timestamp":"1663415220.0","content":"C\nhttps://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/Streams.html"},{"poster":"TechX","upvote_count":"2","timestamp":"1656321480.0","content":"C is OK, but I wonder that is it too fast with the questione only require within 30 minutes, while with DynamoDB Streams we have anh real-time...","comment_id":"623165","comments":[{"content":"Miss spelling:\nC is OK, but I wonder that is it too fast with the questione only require within 30 minutes, while with DynamoDB Streams we have a real-time...","timestamp":"1656321480.0","upvote_count":"1","poster":"TechX","comment_id":"623166"}]},{"upvote_count":"1","timestamp":"1641015840.0","comment_id":"514390","content":"C correct.","poster":"cldy"},{"upvote_count":"1","comment_id":"493431","timestamp":"1638577200.0","content":"C is right Dynamo DB streams is key","poster":"AzureDP900"},{"content":"Selected Answer: C\nC,Amazon DynamoDB Streams is designed for this ,this is a simple question, hope i can have it in my exam","timestamp":"1638322200.0","comment_id":"491121","upvote_count":"1","poster":"acloudguru"},{"comment_id":"464456","content":"C is correct","timestamp":"1636219860.0","upvote_count":"1","poster":"nsei"},{"content":"It's C","comment_id":"450015","poster":"andylogan","timestamp":"1635988860.0","upvote_count":"1"},{"comment_id":"447068","content":"Answer is C","timestamp":"1635420480.0","poster":"moon2351","upvote_count":"1"},{"comment_id":"440693","poster":"student22","timestamp":"1635115260.0","content":"Answer is C\nD would not work without Cloudtrail. If that was the case, it would have been the better solution.","upvote_count":"1"},{"comment_id":"396371","content":"Option: C, DynamoDB Streams + KDS + Lambda function + KDA","upvote_count":"1","timestamp":"1635030840.0","poster":"KittuCheeku"},{"content":"Correct Answer is C, keyword - Amazon DynamoDB Streams to keep the records of changes.","timestamp":"1634883960.0","poster":"Kukkuji","comment_id":"369450","upvote_count":"1"},{"comment_id":"362519","upvote_count":"2","content":"Only correct option is C.\nDynamoDb Stream to capture DynamoDB update. And Kinesis Data Analytics for anomaly detection (it uses AWS proprietary Random Cut Forest Algorithm)","poster":"Radhaghosh","timestamp":"1634613420.0"},{"timestamp":"1634503260.0","poster":"WhyIronMan","comment_id":"336889","upvote_count":"5","content":"I'll go with C"},{"poster":"ppshein","comment_id":"335248","content":"C is correct one as to detect.\nD is kinda tricky as not to detect.","timestamp":"1634293920.0","upvote_count":"3"},{"content":"C is correct. Note \"all changes to the items\" this is the key point.","comment_id":"290957","timestamp":"1634281920.0","upvote_count":"3","poster":"wind"},{"comment_id":"289472","upvote_count":"3","content":"going with C","timestamp":"1633979100.0","poster":"Kian1"},{"timestamp":"1633944540.0","comment_id":"283347","content":"Correct answer is C","upvote_count":"3","poster":"Ebi"},{"timestamp":"1633744980.0","poster":"certainly","upvote_count":"3","content":"C is correct","comment_id":"281547"},{"timestamp":"1633662480.0","comment_id":"262962","content":"C for sure.","upvote_count":"2","poster":"sanjaym"},{"timestamp":"1633638540.0","upvote_count":"2","poster":"cox1960","content":"C but no need for Lambda anymore in between with \"Kinesis Data Streams for DynamoDB\"","comment_id":"260228"},{"upvote_count":"5","comment_id":"256444","comments":[{"content":"DynamoDB works in Cloudwatch events but yes you will also need to enable CloudTrail. With the emphasis on logged within 30 minutes rather than near real-time, the correct answer is D..","comment_id":"264233","poster":"nqobza","timestamp":"1633663800.0","upvote_count":"3"}],"timestamp":"1633619640.0","content":"D is not right as DynamoDB is not supported by CloudWatch Events -> https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html. Instead you need CloudTrail for Dynamo: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/logging-using-cloudtrail.html.\n\nC is the correct one.\n\nB is not correct as we want to track item changes, not table changes.","poster":"sarofi"},{"poster":"jackdryan","timestamp":"1633172400.0","upvote_count":"5","comment_id":"228783","content":"I'll go with C"},{"content":"Answer is C.","timestamp":"1632958920.0","comment_id":"227812","poster":"Bulti","upvote_count":"1"},{"upvote_count":"1","timestamp":"1632822060.0","content":"why not B?\nhttps://aws.amazon.com/blogs/mt/streamline-aws-cloudtrail-logs-using-event-filters/","poster":"lostri","comments":[{"content":"CloudTrail Insights are used for anomaly detection.\nFiltering does not analyze logs","upvote_count":"2","comment_id":"237897","poster":"Cantaloupe","timestamp":"1633529760.0"}],"comment_id":"226216"},{"timestamp":"1632708060.0","comment_id":"223776","upvote_count":"2","content":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html#HowItWorks.CoreComponents.Streams\n\nhttps://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.Lambda.Tutorial.html\n\ncombining these three links i think answer is C","poster":"YouYouYou"},{"comments":[{"content":"Sorry I meant C","timestamp":"1632676800.0","upvote_count":"1","poster":"kj07","comment_id":"221674"}],"timestamp":"1632568740.0","poster":"kj07","content":"Answer: D","comment_id":"221673","upvote_count":"1"},{"content":"C or D?","timestamp":"1632331200.0","comments":[{"poster":"smartassX","content":"C mentions detecting anomalous behavior.\nD doesn't mention how lambda is detecting the anomaly in the captured event.","timestamp":"1632345660.0","upvote_count":"1","comment_id":"218683"}],"comment_id":"218680","poster":"smartassX","upvote_count":"1"}],"unix_timestamp":1605293940,"question_id":378,"question_text":"A company stores sales transaction data in Amazon DynamoDB tables. To detect anomalous behaviors and respond quickly, all changes to the items stored in the DynamoDB tables must be logged within 30 minutes.\nWhich solution meets the requirements?","answer_description":"","answer":"C"},{"id":"0AS0XScjOmQTV4DmRO3Z","answer_description":"Reference:\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_iam-tags.html","timestamp":"2019-09-13 20:46:00","discussion":[{"upvote_count":"35","comment_id":"13217","content":"C\nPrincipal – Control what the person making the request (the principal) is allowed to do based on the tags that are attached to that person's IAM user or role. To do this, use the aws:PrincipalTag/key-name condition key to specify what tags must be attached to the IAM user or role before the request is allowed. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_iam-tags.html\nA: This would be too disruptive and Organizations should be used instead.\nB: Question did not say if prod\\dev\\test are in separate VPC or not. It could be separated using business units instead. Hence this is not feasible.\nD: This is too much effort and disruption.","comments":[{"upvote_count":"11","content":"C is correct. Good resource here: https://aws.amazon.com/blogs/security/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles/","comment_id":"51029","poster":"AWSPro24","timestamp":"1632770640.0"}],"poster":"donathon","timestamp":"1632359940.0"},{"poster":"sb333","comment_id":"64496","content":"D is the correct answer. There is no disruption to users by setting up roles and policies. Using least privileges is obviously something that was not setup and really needs to be.\nC is not correct as it does not cover the scenario. The issue was that people were terminating AND modifying resources of other people. Answer C only addresses terminating. It doesn't completely address the problem, so it's not correct.","upvote_count":"13","timestamp":"1633091100.0","comments":[{"timestamp":"1634568420.0","upvote_count":"5","comment_id":"236413","poster":"nqobza","content":"It's not the resources of other people we are protecting, it's resources of other business units. C is correct. D will actually get out of hand almost immediately because of the roles and permissions we will have to define."},{"timestamp":"1633288740.0","poster":"Smart","content":"Agreed. The first essential step is to apply 'Least Privilege Principal' then optimize further with Tagging-based Policy. Option C is the least disruptive as the users don't have do anything on their end; however, restrictions are not appropriately set. Option D is minimally disruptive as users would have to be notified of the roles they can assume. If not setup properly, there will be additional disruption. However, it does fulfill the requirement.","comment_id":"69871","upvote_count":"4"}]},{"content":"Selected Answer: C\nCD C. Implement a tagging policy based on business units. Create an IAM policy so that each user can terminate instances belonging to their own business units only.","timestamp":"1686968220.0","upvote_count":"1","comment_id":"925703","poster":"SkyZeroZx"},{"poster":"mrgreatness","upvote_count":"1","timestamp":"1666379820.0","content":"100% C - least disruption so no new accounts, and tagging policy works, can use resource tag","comment_id":"701120"},{"poster":"Network_1","upvote_count":"1","content":"I will go with C. \"another business unit\" is the key phrase in the statement, 'Production applications suffered multiple outages when users accidentally terminated and modified resources that belonged to another business unit.'","timestamp":"1662482460.0","comment_id":"661461"},{"comment_id":"543009","poster":"Ishu_awsguy","content":"C is the correct answer\nYou can then create an IAM policy that allows or denies access to a resource based on that resource's tag. In that policy, you can use tag condition keys to control access to any of the following:\n\nResource – Control access to AWS service resources based on the tags on those resources. To do this, use the ResourceTag/key-name condition key to determine whether to allow access to the resource based on the tags that are attached to the resource.","upvote_count":"1","timestamp":"1644319740.0"},{"poster":"cldy","timestamp":"1639114200.0","content":"C. Implement a tagging policy based on business units. Create an IAM policy so that each user can terminate instances belonging to their own business units only.","upvote_count":"1","comment_id":"498321"},{"content":"C is right.","comment_id":"493432","timestamp":"1638577320.0","poster":"AzureDP900","upvote_count":"1"},{"content":"hope i can have this easy one in my exam","poster":"acloudguru","upvote_count":"1","comment_id":"488631","timestamp":"1638061740.0"},{"timestamp":"1636301760.0","upvote_count":"1","content":"It's C","comment_id":"450307","poster":"andylogan"},{"upvote_count":"2","content":"C - ABAC","comment_id":"439470","poster":"AWS_Noob","timestamp":"1636283340.0"},{"upvote_count":"1","content":"CCC\n---","comment_id":"437804","poster":"tgv","timestamp":"1636270140.0"},{"timestamp":"1636098540.0","poster":"WhyIronMan","upvote_count":"1","comment_id":"349315","content":"I'll go with C"},{"upvote_count":"1","timestamp":"1636086660.0","content":"C it is","comment_id":"343720","poster":"Waiweng"},{"comments":[{"upvote_count":"1","content":"D could not be correct.","poster":"gpark","timestamp":"1635961740.0","comment_id":"294672"}],"content":"C.\nIt could be a quite burden to control individual developers based on \"limited permissions based on individual roles\". Supposed that the company has 1000s of employees.","poster":"gpark","comment_id":"294671","upvote_count":"1","timestamp":"1635952020.0"},{"poster":"Kian1","upvote_count":"1","content":"C is the right ans","comment_id":"289474","timestamp":"1635885480.0"},{"content":"I go with C\nhttps://aws.amazon.com/blogs/security/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles/","poster":"AJBA","timestamp":"1635858060.0","upvote_count":"1","comment_id":"288696"},{"upvote_count":"1","comment_id":"283352","timestamp":"1635788460.0","content":"I go with C","poster":"Ebi"},{"poster":"Sourabh1703","comment_id":"270184","timestamp":"1635376440.0","upvote_count":"2","content":"Each application managed by multiple business units, hence tagging will not help, i would go with D"},{"poster":"halfdeaf","content":"The main issue here is service disruption and how it can be mitigated so the right answer would be D. Restricting the developers access using least privilege model.","upvote_count":"2","comment_id":"263911","timestamp":"1635368520.0"},{"comment_id":"262963","poster":"sanjaym","content":"tempting for A but C is more relevant.","upvote_count":"1","timestamp":"1635296880.0"},{"comment_id":"241969","poster":"T14102020","upvote_count":"1","content":"C is correct. Key is tagging","timestamp":"1635241740.0"},{"content":"C.\nD also can do the work, but one user with specific role for each developer is not a desirable way to it.\nAnd you can only have 5000 users in one account.","poster":"newme","comment_id":"240876","timestamp":"1634955000.0","upvote_count":"1"},{"content":"C is Sure","timestamp":"1634540880.0","poster":"lydia_young","upvote_count":"1","comment_id":"233151"},{"content":"I'll go with C","comment_id":"229375","upvote_count":"2","poster":"jackdryan","timestamp":"1634536020.0"},{"timestamp":"1634481720.0","upvote_count":"2","content":"D is more disruptive and requires a lot more maintenance of role based access policies. Moreover if users are not organized into job functions in the first place then it would be tough to asking the appropriate role to them, let alone defining the right identity policy for each role which will work for all users. Therefore c is the right answer.","comment_id":"227823","poster":"Bulti"},{"comment_id":"223599","poster":"Edgecrusher77","content":"I go for C for sure","upvote_count":"1","timestamp":"1634455500.0"},{"timestamp":"1634394840.0","content":"should be c, tag based policy","upvote_count":"2","poster":"micahdevops","comment_id":"206689"},{"comment_id":"148879","content":"C is correct, here said access to the resource they needed mean, developer can perform ec2 action, but does not allow action perform on production ec2. Tag is better to satisfied, instead of least priviledge method (mostly for restricting which services can be used)","poster":"fullaws","upvote_count":"2","timestamp":"1634360820.0"},{"content":"C most likely","timestamp":"1634142840.0","upvote_count":"2","poster":"NikkyDicky","comment_id":"134156"},{"poster":"noisonnoiton","content":"go with C\ntagging and IAM Policy","upvote_count":"2","comment_id":"133650","timestamp":"1634049600.0"},{"poster":"mat2020","timestamp":"1633928820.0","content":"answer :C","comment_id":"133237","upvote_count":"2"},{"comment_id":"117929","poster":"chicagomassageseeker","content":"C is the answer: https://aws.amazon.com/blogs/security/resource-level-permissions-for-ec2-controlling-management-access-on-specific-instances/","timestamp":"1633881660.0","upvote_count":"3"},{"upvote_count":"2","timestamp":"1633869600.0","comment_id":"106343","poster":"easytoo","content":"Leveraging tagging is the way to go here. C for me."},{"content":"tagging policy means you can indicate the environment which allows you to terminate or start. For example, The current environment tag of the instance is Development which will be assigned to the Developer group only. When you tried to terminate the Production instance which is tagged as the Production environment, the Developer team will get access denied to terminate. The best choice is C.","timestamp":"1633797420.0","comment_id":"97184","upvote_count":"3","poster":"Jeb"},{"comment_id":"95024","poster":"arunkumar","timestamp":"1633776360.0","upvote_count":"3","content":"In option D, how would you restrict Developer from accessing resource like production EC2 instances alone? Option states giving access to the service level(EC2, S3, RDS). \nWe need to use control access based on the tag.\nOption C is right."},{"poster":"JAWS1600","comment_id":"90224","upvote_count":"2","content":"D is the answer. C is very catchy -- It talks about segregating the roles by \"business unit\"\n\"Create an IAM policy so that each user can terminate instances belonging to their own business units only\"\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_iam-tags.html \nRead the question \"access to the resources they need\" - D is clearly the choice, as need is not to segregate by business units. need is to give them access that they \"NEED\" Least privilege principle will kick in here. \nC and D, both would work in the practical world. For question requirements, D is the right pick.","timestamp":"1633615920.0"},{"upvote_count":"4","timestamp":"1632800820.0","content":"D makes more sense! The ask is \"Developers access to the resources\" not terminating instances.","poster":"Gorha","comment_id":"52687","comments":[{"upvote_count":"2","poster":"SamuelK","content":"D is the right answer. C is wrong because it allows the developers to terminate instances","timestamp":"1633014000.0","comment_id":"52819"}]},{"content":"Answer is C","comment_id":"45256","poster":"amog","upvote_count":"2","timestamp":"1632689940.0"},{"timestamp":"1632595920.0","poster":"markpark","content":"C is right","comment_id":"41200","upvote_count":"2"},{"comments":[{"poster":"Moon","upvote_count":"3","timestamp":"1632533520.0","comment_id":"14464","content":"tagging is a great tool to separate the access for different teams, if used correctly."}],"upvote_count":"3","content":"\"C\", is the answer here.","comment_id":"14462","poster":"Moon","timestamp":"1632400200.0"},{"upvote_count":"5","timestamp":"1632200040.0","content":"c is right","poster":"awsec2","comment_id":"11050"},{"comment_id":"11028","timestamp":"1632194700.0","upvote_count":"6","content":"Least disruption would be C","poster":"dpvnme"}],"question_id":379,"answer_ET":"C","answer_images":[],"answers_community":["C (100%)"],"topic":"1","choices":{"A":"Create an AWS account for each business unit. Move each business unit's instances to its own account and set up a federation to allow users to access their business unit's account.","D":"Set up role-based access for each user and provide limited permissions based on individual roles and the services for which each user is responsible.","C":"Implement a tagging policy based on business units. Create an IAM policy so that each user can terminate instances belonging to their own business units only.","B":"Set up a federation to allow users to use their corporate credentials, and lock the users down to their own VPC. Use a network ACL to block each VPC from accessing other VPCs."},"url":"https://www.examtopics.com/discussions/amazon/view/5149-exam-aws-certified-solutions-architect-professional-topic-1/","answer":"C","unix_timestamp":1568400360,"question_text":"A company is running multiple applications on Amazon EC2. Each application is deployed and managed by multiple business units. All applications are deployed on a single AWS account but on different virtual private clouds (VPCs). The company uses a separate VPC in the same account for test and development purposes.\nProduction applications suffered multiple outages when users accidentally terminated and modified resources that belonged to another business unit. A Solutions\nArchitect has been asked to improve the availability of the company applications while allowing the Developers access to the resources they need.\nWhich option meets the requirements with the LEAST disruption?","exam_id":32,"isMC":true,"question_images":[]},{"id":"lz71psq6evnu7IjoZ6Du","timestamp":"2019-09-12 08:18:00","answer_description":"","answers_community":["C (80%)","A (20%)"],"answer_images":[],"topic":"1","exam_id":32,"discussion":[{"timestamp":"1632717900.0","comments":[{"poster":"AWSPro24","content":"Hey i found a cool discussion of exactly this use case on Reddit after I wrote my previous comment. https://www.reddit.com/r/aws/comments/5j9r31/one_or_multiple_apps_per_ecs_cluster/","upvote_count":"2","comment_id":"51021","timestamp":"1632977340.0"},{"content":"I agree with this. If they are all tiny aps and serve nearly no traffic you can host them all on a very small ECS cluster. All 103 of them. A is out because how would you route to 103 separate apps with no LB. B is out because you'll need 103 EC2 instances which will have a significant cost. D is out because if it's a single-instance environment you're still going to have 103 EB environments which means 103 EC2 instances behind them. ECS is the only option that allows you to have 103 apps and all their runtime environements smushed together in the smallest set of infrastructure just to \"keep the lights on\".","timestamp":"1632940440.0","comment_id":"51020","poster":"AWSPro24","upvote_count":"18"}],"poster":"examacc","upvote_count":"37","comment_id":"24046","content":"C is right. it has lowest infra costs. Rest all options will need VMs for each service."},{"poster":"chaudh","timestamp":"1632463860.0","comment_id":"16153","upvote_count":"21","comments":[{"timestamp":"1635871080.0","poster":"gpark","comment_id":"298753","upvote_count":"1","content":"This is a fair point.\nI have left the comment to make people check upvoted count."},{"comment_id":"670102","content":"No need 103 Instances, We can use the dynamic port and 1 instance we can run multiple containers(tasks) it's depending on your instance type...","upvote_count":"1","timestamp":"1663258560.0","poster":"Sathish1412"}],"content":"C will give lowest infrastructure cost. All other solutions will need 103 instances"},{"timestamp":"1702045320.0","comment_id":"1091140","poster":"Chris22usa","content":"Maybe A? Beantalk can be deployed by Docker","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nC is right. it has lowest infra costs. Rest all options will need VMs for each service.","comment_id":"925705","timestamp":"1686968520.0","poster":"SkyZeroZx"},{"timestamp":"1667850480.0","content":"C, Though in reality ALB supports only 100 target groups, so it will have to be 2 ALB's. Still probably best option","upvote_count":"1","comment_id":"713287","poster":"Yvarr"},{"timestamp":"1667259960.0","poster":"AjayPrajapati","upvote_count":"1","comment_id":"708771","content":"Selected Answer: C\nSingle instance is too risky. C is good with small container to serve small traffic"},{"upvote_count":"1","comment_id":"701143","content":"C it seems as basic applications only need a run time environment in a container and not a full VM.. as 103 applications what instance type would we choose here?","poster":"mrgreatness","timestamp":"1666383360.0"},{"timestamp":"1658501940.0","content":"C is the most correct one.\nA is the least expensive but will not work since there can be multiple application listening to port 443 or 80 and it will break the deployment.\nB and D will create 103 EC2 instances its not cost effective","comment_id":"635253","poster":"asfsdfsdf","upvote_count":"1"},{"comment_id":"614349","upvote_count":"1","content":"A is correct as the apps are not developed and you can upgrade the environment from a single instance one to a fully load-balanced production environment.","poster":"Alvindo","timestamp":"1654840500.0"},{"timestamp":"1654263240.0","poster":"bobsmith2000","content":"Selected Answer: C\nThe cheapest one. Fixed small number of instances and numerous hardly used applications","comment_id":"611103","upvote_count":"2"},{"poster":"RVivek","content":"Selected Answer: A\nA is LEAST expensive infrastrucre as requested in the quetion","upvote_count":"1","timestamp":"1644764100.0","comment_id":"546511"},{"poster":"AzureDP900","content":"A. Deploy the applications to single-instance AWS Elastic Beanstalk environments without a load balancer. Please check Neal Davis questions for explanation.","upvote_count":"3","timestamp":"1640128320.0","comments":[{"comment_id":"686727","timestamp":"1664960580.0","poster":"JohnPi","content":"Neal Davis's question is related to \"LOWEST operational overhead\".","upvote_count":"1"}],"comment_id":"506501"},{"timestamp":"1640125860.0","poster":"CloudChef","content":"A is right.","comment_id":"506491","upvote_count":"1"},{"comment_id":"496809","upvote_count":"1","timestamp":"1638966360.0","poster":"cldy","content":"A. Deploy the applications to single-instance AWS Elastic Beanstalk environments without a load balancer."},{"upvote_count":"1","comment_id":"484035","poster":"acloudguru","timestamp":"1637573100.0","content":"hope i can have such simple questions in my exam"},{"timestamp":"1636169820.0","upvote_count":"1","poster":"andylogan","comment_id":"450308","content":"It's C"},{"content":"CCC\n---","comment_id":"437805","timestamp":"1636119540.0","poster":"tgv","upvote_count":"1"},{"content":"C should be the answer - especially with binpack placement strategy\nA = B = D\nSingle-instance AWS Elastic Beanstalk environments = multiple single EC2 instances\nElastic Beanstalk is nothing more but EC2 managed by AWS","comment_id":"409096","timestamp":"1636078740.0","poster":"DerekKey","upvote_count":"1"},{"poster":"dilprt123","content":"A is right, is cheaper than C where it runs a cluster and ALB. The key is lowest infra cost & serves little (means no) traffic. So no need of ALB\nD is not possible as different VMs cannot be run on the same instance\nB is very expensive for apps that serves no traffic","upvote_count":"2","timestamp":"1635984060.0","comment_id":"400692"},{"timestamp":"1635984000.0","upvote_count":"1","content":"D is correct. please see Multicontainer Docker\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker_ecs.html#create_deploy_docker_ecs_dockerrun","poster":"N_null","comment_id":"397221"},{"poster":"Waiweng","content":"go with C","timestamp":"1635897660.0","comment_id":"343721","upvote_count":"3"},{"upvote_count":"1","poster":"ppshein","comment_id":"335251","content":"C is the best.\nA. impossible to host 103 applications in single instance\nB. Huge cost\nD. impossible as same as A.","timestamp":"1635894540.0"},{"timestamp":"1635827100.0","comment_id":"289482","poster":"Kian1","content":"going with C","upvote_count":"2"},{"poster":"Ebi","comment_id":"283357","content":"I go with C","upvote_count":"4","timestamp":"1635819180.0"},{"poster":"rkbala","upvote_count":"1","timestamp":"1635711000.0","comments":[{"comment_id":"273901","comments":[{"timestamp":"1635794040.0","comment_id":"276569","upvote_count":"2","content":"C is for sure not a good design, but the options presented are like choosing the lesser evil lol. \n\nProbably the ALB will be loaded with 103 SNIS, and 103 dynamic ports ranging from 49153–65535 and 32768–61000, doable, but its a weird design. \n\nIf you wanna dig deeper, you can run EKS with an ingress controller, and front with ALB with wildcard domain for the 103 services :)","poster":"rcher"}],"timestamp":"1635749940.0","content":"So you're going to load balance using a single ALB to 103 completely different applications? What could possibly go wrong! Seriously, how are you going to ensure requests for one of the 103 applications hits the correct target?","poster":"ncloud1","upvote_count":"1"}],"comment_id":"267175","content":"C is right. Lowest cost infra option"},{"upvote_count":"3","content":"I'll go with C","timestamp":"1635581400.0","comment_id":"262973","poster":"sanjaym"},{"upvote_count":"1","poster":"matt21","content":"B. AWS SMS is the later product over vm import export. (It doesn't say there is a 1:1 mapping for app to vm, just 103 apps on vm's)..\n\nThere are no developers, that kills C for me. And you can't deploy the application without migration of vm, so not A.\n\nI'd note that the beanstalk examples still target single EC2 instances (note the s) i.e. one per migrated vm, you can't merge these apps together, they are all web app's so all on port 80/443. \n\nSo cost wise B is the same as the beanstalk of D .\n\nThen it incomes down to the migration tool, hence AWS SMS. Only question does beanstalk give another cost advantage (code isn't changing).","timestamp":"1635453240.0","comments":[{"poster":"DashL","comment_id":"392008","content":"The key word is \"virtual machines\". So SMS will migrate each VM to an EC2 instance - that means unknown number of instances which can be up to 103. The cost will be exponential.\nC seems most logical.","upvote_count":"1","timestamp":"1635976260.0"}],"comment_id":"260939"},{"timestamp":"1635357600.0","upvote_count":"1","comment_id":"260239","content":"B for two reasons. \"no longer developed\" means lift and shift. \"many of\" means not all of the apps are simple.","poster":"cox1960"},{"timestamp":"1635326280.0","content":"C. Dockers works well with ECS that can run mutiple images in one or a cluster of ECS. The remaining options will need many EC2 instances and more x.","poster":"happpieee","comment_id":"247027","upvote_count":"1"},{"poster":"T14102020","comment_id":"241972","timestamp":"1635206760.0","content":"Correct answer is C. Key is ECS and Load Balancer","upvote_count":"1"},{"content":"Personally, I like option C.\nBut what the definition of \"infrastructure costs\", I think it includes not only AWS, but also people who are working on it. So\nA: it need too much work to make it happen, and hard to maintain which means maybe AWS costs little, but human cost will be high.\nB: too expensive.\nD: I don't see any difference with A, and I don't get why we need those AMIs, because finally a custom image is used.","comment_id":"240885","poster":"newme","timestamp":"1635193860.0","upvote_count":"1"},{"comment_id":"237911","timestamp":"1635190200.0","content":"A is off without LB\nB is too expensive with 103 instances\nC is not feasible as development is over and there's nobody to do conversion\nD might be the answer but not finding reference to similar solution","poster":"Cantaloupe","upvote_count":"1"},{"poster":"lydia_young","timestamp":"1635145020.0","upvote_count":"1","comment_id":"233160","content":"I agree with C"},{"content":"I'll go with C","comment_id":"228786","upvote_count":"2","poster":"jackdryan","timestamp":"1635134700.0"},{"poster":"Bulti","comment_id":"227840","content":"B and C are the only practical options that will actually work. However B is more expensive than C because we will end up creating 103 EC2 instances. On the other hand C is most cost effective as you can create a single ECS task and deploy containers for each application and size it as per the traffic needs. Auto scaling is also an option depending upon where or not the app arch of these simple app would support it. So correct answer is C","upvote_count":"2","timestamp":"1634906820.0"},{"content":"A: Impossible that's useless without a LB to tell your traffic to which application port it will be routed \nhttps://medium.com/finnovate-io/deployment-multiple-services-on-a-single-instance-of-aws-elastic-beanstalk-f9bc00908c64\n\nB: no use we will create a similar number of EC2's\n\nD: why run import export to create AMIs and then run them on a single instance EBT with a custom image doesn't make sense to do both steps could have been ok if he didn't mention the import export step and we really don't have to use custom images now we are now capable of using multi container docker BT instance.\n\nso answer for sure is C: through elimination","timestamp":"1634868420.0","upvote_count":"1","comment_id":"223814","poster":"YouYouYou"},{"comment_id":"217677","upvote_count":"2","timestamp":"1634867880.0","poster":"cpd","content":"Fact that there is very little traffic and no more development, makes me think this is NOT a docker solution. We can deploy all of these application in one Elastic Beanstalk backed by EC2 but, will need load balancer to route request to different backend ports; here is documentation on how to do this https://medium.com/finnovate-io/deployment-multiple-services-on-a-single-instance-of-aws-elastic-beanstalk-f9bc00908c64"},{"comment_id":"215735","timestamp":"1634864760.0","content":"C is correct. 100%.\nAll other are costly as you end up creating one server per application.","upvote_count":"1","poster":"vjt"},{"timestamp":"1634805660.0","content":"b is the correct one. C is the first one to discard as it needs develop and it clearly says \"are no longer actively developed).","poster":"lsa2002","upvote_count":"1","comment_id":"203791"},{"comments":[{"comment_id":"236418","upvote_count":"2","content":"I don't think anyone is an architecture bro.","timestamp":"1635161760.0","poster":"nqobza"}],"timestamp":"1634785080.0","content":"Anybody choose A, are you really an architecture? \nC is correct, ECS is not cost much and elastic/scalable/high available/easy to maintain.","comment_id":"187713","upvote_count":"2","poster":"kiki3890528"},{"comment_id":"181590","poster":"sam422","timestamp":"1634628000.0","upvote_count":"2","content":"Answer is A, 103 line -of business apps on VM is a distractor. For deploying PHP, Java, Ruby AWS recommends elastic beanstalk with lowest cost. \nB: ask is not for migration of servers, so no SMS is required\nC: ECS cluster with ALB is not lowest cost\nD. No VM Import /export for elastic beanstalk"},{"timestamp":"1634496060.0","poster":"Gallux","upvote_count":"1","content":"I think C but \"Rules per load balancer (not counting default rules): limits 100\" So i'm confused","comment_id":"177636"},{"poster":"Phat","comment_id":"177171","content":"I think A is correct. normally it should have ALB/ELB, but question mentions lowest cost.","timestamp":"1634449560.0","upvote_count":"3"},{"comments":[{"timestamp":"1634597040.0","comment_id":"181584","poster":"sam422","upvote_count":"2","content":"Irrespective of infrastructure, PHP, Java , Ruby application is just easy to deploy on elastic beanstalk with no big effort"}],"comment_id":"177148","timestamp":"1634239320.0","poster":"Neive","content":"C is correct Answer.\nA - INCORRECT. at on-premise 103 application running on multiple VMs (may be 103 VMs, not clear). Running all 103 applications on single vm with multiple technology stack not recommended. I have Never seen it in production.\nb - with one to one mapping - 103 EC2 instances - not cost effective.\nc - CORRECT. You can created a small ECS cluster (10-15 EC2; don't know, but definitely less than 103). Deploy all 103 docker container. It will be cost effective.\nD - Same as A. all 103 instances on single EC2 not recommended.","upvote_count":"1"},{"content":"A key point to note is This is for an Enterprise and AWS does NOT recommend enterprise Apps on Elastic Bean Stalk , This leaves EC2 options and believe C is best","poster":"kaush","timestamp":"1634161380.0","comment_id":"174868","comments":[{"upvote_count":"1","comment_id":"174870","content":"Edit should be B ,SMS is enhancement over VM import / Export and there B is more cost effective than C , there is no need for a cluster nor a load balancer in the given context","poster":"kaush","timestamp":"1634201040.0"}],"upvote_count":"1"},{"timestamp":"1633995660.0","content":"I would go to C. \n\nFor A, Single EB env, -- when you create the EB env, you need to choose the platform, so to me, it can not host all this PHP/JAVA/Ruby together. IMO","upvote_count":"1","comment_id":"174811","poster":"Ganfeng"},{"upvote_count":"1","timestamp":"1633969680.0","comment_id":"171388","poster":"Neive","content":"Correct answer is C"},{"comment_id":"166706","upvote_count":"2","poster":"MrP","content":"The key phrase here is \"many of the applications...\" - nowhere does it say all of them are simply web applications, so we have to consider legacy applications which will not work with an ALB or with Beanstalk. The incentive to choose C is clear, but from a business perspective it is wrong and B should be the correct answer.","timestamp":"1633855800.0"},{"timestamp":"1633817640.0","content":"C is correct, A is hard because they have multiple Java/PHP, the environment setting will be hugely different from each application. B and D required more infrastructure cost (each instance per AMIs) compare to C","comment_id":"148883","upvote_count":"1","poster":"fullaws"},{"comment_id":"134159","content":"C more likely","upvote_count":"1","timestamp":"1633800780.0","poster":"NikkyDicky"},{"timestamp":"1633714680.0","comment_id":"133656","upvote_count":"1","poster":"noisonnoiton","content":"go with C\nlowest infrastructure cost"},{"timestamp":"1633686660.0","poster":"inf","upvote_count":"3","content":"Answer: B\nA - incorrect - deploying apps (i.e. replatforming) incurs costs and with no developers, not ideal. Importantly, a service limit increase from 5 to 103 Elastic IPs is needed. We can't launch more than 5 Single Instance EB environments in the account as each needs an EIP.\nB - correct - although SMS involves a pfaffing about, and results in a 1-1 mapping of source VM to EC2 instance (pricey), it is feasible, and the VMs can have a low compute footprint, no EIP required, no ALB limits to contend with. Lift & Shift appropriate here.\nC - incorrect - technically impossible. Running multiple containers on an instance has low costs, HOWEVER, a SINGLE ALB has a limit of 100 rules, and there are 103 apps/containers - we can't route all requests to the appropriate container. Multiple ALBs would have helped\nD - incorrect - same issue as A whereby we hit the EIP limit per account of 5.","comment_id":"131056"},{"content":"Answer is A :applications are PHP, Java, Ruby, Launch this Applications\nwith AWS Elastic Beanstalk without export the VM or convert to docker , just upload the code. \nhttps://aws.amazon.com/getting-started/hands-on/launch-an-app/","comment_id":"114624","poster":"ramikhreim","upvote_count":"2","timestamp":"1633679460.0"},{"poster":"VrushaliD","comment_id":"105858","content":"I think D is correct - note the line \"..by configuring a custom image.\"","upvote_count":"1","timestamp":"1633597440.0"},{"content":"Correct Answer is : C\nOption A: No Load balancer and all the apps on single EB instance is not a good design\nOptionB: So running 103 instances?? Not a good option\nOptionC: Containerising the apps and running them on ECS cluster with Load balancer is a good option out of the lot.\nOptionD: Again have 103 instances to run the apps? Not a good option","upvote_count":"1","poster":"meenu2225","comment_id":"105461","timestamp":"1633574580.0"},{"poster":"Jeb","content":"When you need to deploy different services such as Java, PHP, Ruby, .NET, the easiest way and cheapest option is to use AWS ECS which is just one instance but you have a lot of different services deployed right now. This is what we call Containerized Apps. No need to purchase your enterprise OS license again per EC2 instance. Containerization is cheaper than any infra instance. That's why the world technology is changing. The best choice is C.","upvote_count":"3","timestamp":"1633526520.0","comment_id":"97189"},{"upvote_count":"1","timestamp":"1633425180.0","comment_id":"90235","content":"B is the right choice. EB does not give the option of integrating multiple applications ( PHP Java Ruby) into a single instance. EB Options are out. EB is not going to do extra cost-saving, as it uses Ec2 under the covers. The intent of EB is self manged (PAAS), Deploying it on ECS, applications need to migrate to microservices. Cost to run ECS cluster will incur- not a good option to select. Remaining Option is B - It has to be migrated using SMS to individual Ec2s.","poster":"JAWS1600"},{"upvote_count":"5","content":"Logic is really simple .In question it's mentioned a variety of applications (php,java) which is difficult to install in a single instance because of the base packages mismatch .This is where dockers are used to overcome this .Option C suits this requirement.","comment_id":"80634","poster":"likku","timestamp":"1633228740.0"},{"comment_id":"75518","content":"C is correct","poster":"Joeylee","timestamp":"1633101240.0","upvote_count":"1"},{"poster":"Smart","timestamp":"1633100100.0","content":"C is valid. These are line-of-business apps hence high-availability/scalability should be considered. Not running load balancer and autoscaling eliminates most of them (although none talks about autoscaling). Running containers on EC2 instances will efficiently utilized EC2s of the cluster. Images can be converted to Docker image through various solutions; we are not redeveloping the application itself.","upvote_count":"3","comment_id":"75342"},{"upvote_count":"2","timestamp":"1632985020.0","poster":"nil12","content":"C. The load balancer is there because these are web application apps","comment_id":"51605"},{"content":"Maybe the answer is suffle. \nAnswer is C\nhttp://jayendrapatil.com/aws-cloud-migration-services/","comment_id":"45259","timestamp":"1632919200.0","poster":"amog","upvote_count":"6"},{"comment_id":"42702","content":"Correct answer is C as using ECS with Application Load Balancer would allow the multiple applications to hosted within the same container, thereby reducing the number of instances required for deployments. https://docs.aws.amazon.com/AmazonECS/latest/userguide/service-load-balancing.html","upvote_count":"9","timestamp":"1632889200.0","poster":"dumma"},{"content":"Answer: A\nB - Pay for AMI Storage as well as the running instance\nC - Why do you need a LB\nD - Same as B, Import/Export will store data in S3, easiest option is to simply use Single Instance EB","poster":"CSharpPro","timestamp":"1632837120.0","comment_id":"36300","upvote_count":"2"},{"comment_id":"30459","upvote_count":"1","content":"B is correct answer","poster":"dojo","timestamp":"1632799740.0"},{"upvote_count":"2","content":"I think the answer is A. according to https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html\nB: am not sure\nC : wrong because its using ALB, that is an extra cost.\nD: Wrong, even though VM import/export has no charge, it uses S3 , which is a cost.","poster":"JayK","comment_id":"30030","timestamp":"1632722700.0"},{"timestamp":"1632718080.0","comments":[{"timestamp":"1632872820.0","poster":"sparkf1","content":"It's a line of business application, so I think LB is needed.","comment_id":"36950","upvote_count":"1"}],"comment_id":"26211","poster":"Ye198711","content":"No need for load balance. To Be LEAST cost, single EC2 should be enough.\nSo B","upvote_count":"1"},{"timestamp":"1632654120.0","comment_id":"17516","poster":"TechGuru","comments":[{"timestamp":"1632679260.0","upvote_count":"1","content":"The question says cost effective. A is not cost effective. I feel B is cost effective.","poster":"G3","comment_id":"18581"},{"comment_id":"94300","timestamp":"1633483440.0","poster":"VrushaliD","content":"its mentioned .. 103 line-of-business applications on virtual machines","upvote_count":"1"}],"content":"I guess A is right. No where it has mentioned that current architecture is using VM so B is worn","upvote_count":"2"},{"poster":"pudak","comment_id":"17311","upvote_count":"3","timestamp":"1632536040.0","content":"A is right. \nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html"},{"poster":"Ibranthovic","timestamp":"1632325380.0","upvote_count":"1","content":"I'm not sure about B,\nI think A is the best Answer","comment_id":"14122"},{"content":"B\nhttp://jayendrapatil.com/aws-cloud-migration-services/\nA\\D: While this will work, it will be more costly then B.\nC: The applications are no longer actively being developed, this would require some form of development for sure since they could be very using the same instance but different ports for example.","timestamp":"1632224760.0","comment_id":"13219","upvote_count":"5","poster":"donathon"},{"poster":"awspro","timestamp":"1632209640.0","upvote_count":"1","comment_id":"12981","content":"So, B? or D? what's the real?"},{"upvote_count":"1","content":"b\nhttp://jayendrapatil.com/aws-cloud-migration-services/","comment_id":"10720","comments":[{"timestamp":"1633610460.0","comment_id":"107287","upvote_count":"1","poster":"JAWS1600","content":"That Link says right option is C. Not sure if JP has updated ."},{"timestamp":"1634540160.0","upvote_count":"1","comment_id":"181580","comments":[{"comment_id":"187431","content":"I'll go with A","poster":"sam422","upvote_count":"1","timestamp":"1634678040.0"}],"poster":"sam422","content":"ECS cluster with ALB is not lowest cost"},{"poster":"dpvnme","timestamp":"1632095880.0","upvote_count":"3","comment_id":"11452","comments":[{"poster":"awsec2","timestamp":"1632175020.0","comment_id":"12322","content":"B is wrong ?","upvote_count":"1"}],"content":"beanstalk can work well with PHP, Java, or Ruby. plus it's free to use"}],"timestamp":"1632069300.0","poster":"awsec2"}],"question_id":380,"question_text":"An enterprise runs 103 line-of-business applications on virtual machines in an on-premises data center. Many of the applications are simple PHP, Java, or Ruby web applications, are no longer actively developed, and serve little traffic.\nWhich approach should be used to migrate these applications to AWS with the LOWEST infrastructure costs?","unix_timestamp":1568269080,"url":"https://www.examtopics.com/discussions/amazon/view/5089-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"C":"Convert each application to a Docker image and deploy to a small Amazon ECS cluster behind an Application Load Balancer.","A":"Deploy the applications to single-instance AWS Elastic Beanstalk environments without a load balancer.","B":"Use AWS SMS to create AMIs for each virtual machine and run them in Amazon EC2.","D":"Use VM Import/Export to create AMIs for each virtual machine and run them in single-instance AWS Elastic Beanstalk environments by configuring a custom image."},"answer":"C","question_images":[],"isMC":true,"answer_ET":"C"}],"exam":{"numberOfQuestions":1019,"id":32,"isBeta":false,"isMCOnly":false,"name":"AWS Certified Solutions Architect - Professional","isImplemented":true,"lastUpdated":"11 Apr 2025","provider":"Amazon"},"currentPage":76},"__N_SSP":true}