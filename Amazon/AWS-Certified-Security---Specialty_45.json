{"pageProps":{"questions":[{"id":"UNnhGWxNpDjc23MafZAE","question_images":["https://www.examtopics.com/assets/media/exam-media/04239/0019700001.jpg"],"answer_images":[],"question_id":221,"discussion":[{"comment_id":"731088","content":"Selected Answer: B\nAnswer B\n\nFirst block of policy grants 'admin' permissions to users. IAM root indicates all users in the account. Refer below:\nA key policy document with a statement that allows access to the AWS account (root user) enables IAM policies in the account to allow access to the KMS key. This means that IAM users and roles in the account might have access to the KMS key even if they are not explicitly listed as principals in the key policy document. \n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/determining-access-key-policy.html","poster":"D2","timestamp":"1669782600.0","upvote_count":"9"},{"upvote_count":"1","comment_id":"1155879","timestamp":"1708551600.0","content":"Selected Answer: B\nBest of these options is B.\n\nAlthough logically the security engineer should sanitize the other IAM roles to stop them from using the key, instead of removing the default policy part.","poster":"Raphaello"},{"upvote_count":"1","comment_id":"946044","content":"C is the answer\n\nSID: is a security identifier that is optional , it doesn't have any key role play.","poster":"Noexperience","timestamp":"1688772000.0"},{"comment_id":"639438","upvote_count":"3","poster":"ude","content":"Selected Answer: B\nB is the answer","timestamp":"1659145200.0"},{"comment_id":"549440","timestamp":"1645107540.0","upvote_count":"1","content":"B. Key policy is the best place to control who can use the key, no IAM policy.","poster":"Skr81"},{"upvote_count":"1","content":"Did find the article but still no sure if we need to pick B as answer\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html","comment_id":"535129","timestamp":"1643426880.0","poster":"AliS2020"},{"comments":[{"comment_id":"644269","timestamp":"1659992760.0","upvote_count":"1","content":"I agree, it will lock users from access the key, but it seems to be the only possible answer.","poster":"dcasabona"}],"comment_id":"530694","poster":"sam_live","content":"B can't be the answer. If the default key policy is removed then no other IAM principal will be able to access the key. KMS policy is different than other AWS resources. \nNone of the options seem correct to me. possible that some parts of the question are missing.","timestamp":"1642957320.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1641589200.0","comment_id":"519200","poster":"roger8978","content":"Only B makes sense. StringEquals and us-west-2 is okay to use in viaService."},{"comment_id":"519196","content":"key management policy\n\"B\" is the answer","timestamp":"1641587940.0","upvote_count":"1","poster":"argol"}],"topic":"1","timestamp":"2022-01-07 21:39:00","answer_description":"","isMC":true,"answer_ET":"B","answer":"B","choices":{"B":"In the policy document, remove the statement block that contains the Sid ג€Enable IAM User Permissionsג€. Add key management policies to the KMS policy.","C":"In the statement block that contains the Sid ג€Allow use of the keyג€, under the ג€Conditionג€ block, change the kms:ViaService value to ec2.us-east- 1.amazonaws.com.","A":"In the statement block that contains the Sid ג€Allow use of the keyג€, under the ג€Conditionג€ block, change StringEquals to StringLike.","D":"In the policy document, add a new statement block that grants the kms:Disable* permission to the security engineer's IAM role."},"answers_community":["B (100%)"],"exam_id":29,"question_text":"A company wants to establish separate AWS Key Management Service (AWS KMS) keys to use for different AWS services. The company's security engineer created the following key policy to allow the infrastructure deployment team to create encrypted Amazon Elastic Block Store (Amazon EBS) volumes by assuming the InfrastructueDeployment IAM role:\n//IMG//\n\nThe security engineer recently discovered that IAM roles other than the InfrastructureDeployment role used this key for other services.\nWhich change to the policy should the security engineer make to resolve these issues?","url":"https://www.examtopics.com/discussions/amazon/view/69644-exam-aws-certified-security-specialty-topic-1-question-298/","unix_timestamp":1641587940},{"id":"oiEzKgMVoWiO45Chswdf","answer_images":[],"question_id":222,"discussion":[{"comment_id":"534232","timestamp":"1643331060.0","poster":"Radhaghosh","comments":[{"upvote_count":"2","content":"I mean to say either \"Option A*\" should be --> NAT is Public Subnet\nor \"Option F*\"should be --> ALB is Public Subnet.\n\nBased on that either A*CE or CEF*","poster":"Radhaghosh","comment_id":"534233","timestamp":"1643331120.0"}],"content":"This Question Options are not correct \n\nEither, Option A --> NAT is Public Subnet or Option F --> ALB is Public Subnet.\nBelow are valid \nC. Place the DB instance in a private subnet.\nE. Configure the Auto Scaling group to place the EC2 instances in a private subnet.\n\nSo either ACE or CEF","upvote_count":"5"},{"timestamp":"1710977580.0","comment_id":"1178847","poster":"hro","upvote_count":"1","content":"Public subnets have a direct route to an internet gateway, while private subnets do not. Resources in a private subnet require a NAT device to access the public internet.\nA C E"},{"upvote_count":"1","timestamp":"1708559940.0","comment_id":"1155948","content":"Selected Answer: ACE\nKeyword: \" preconfigured allow list of IP addresses\" >>> private NAT GW.\n\nA C E would make sense.\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/nat-gateway-scenarios.html#private-nat-allowed-range","poster":"Raphaello"},{"comment_id":"1067084","upvote_count":"1","poster":"ahrentom","timestamp":"1699606140.0","content":"Selected Answer: CEF\nAnwsers CEF"},{"comment_id":"1039488","upvote_count":"2","content":"ACE, according to ChatGPT. \n\n A) Deploy a NAT Gateway in each private subnet for every Availability Zone that is in use:\n - This is required to allow EC2 instances in private subnets to initiate outbound connections to the internet. This is necessary for software updates, package installations, and other tasks that require internet access, such as communicating with the external payment provider.\n\nC) Place the DB instance in a private subnet:\n- Placing the RDS DB instance in a private subnet provides an additional layer of security by not exposing the database directly to the internet. It ensures that database traffic is routed through the VPC and not accessible from the public internet.\n\nE) Configure the Auto Scaling group to place the EC2 instances in a private subnet:\n- Similar to the database instance, EC2 instances should also be placed in private subnets for security reasons. This ensures that incoming traffic to your application passes through the ALB (which can be in a public subnet) but doesn't expose the instances directly to the internet.","timestamp":"1696940940.0","poster":"AWSvad"},{"comment_id":"1020372","timestamp":"1695956640.0","poster":"Braindumpjr","upvote_count":"1","content":"Selected Answer: CEF\nTo meet the requirements of only allowing internet access to the application via HTTP/HTTPS, ensure connectivity to the external payment provider as the environment scales, and isolate the database, the security engineer should recommend:\n\nC) Place the DB instance in a private subnet\nE) Configure the Auto Scaling group to place the EC2 instances in a private subnet \nF) Deploy the ALB in a public subnet\n\nC and E place the application components in private subnets, limiting internet access.\n\nF puts the ALB in a public subnet to allow ingress of HTTP/HTTPS traffic. \n\nTogether this provides isolation and limits external connectivity while allowing internet traffic to the application via the load balancer.\n\nA and D are incorrect because public subnets provide direct internet access which violates the requirements.\n\nB is incorrect because the database should not be in a public subnet."},{"comment_id":"913507","timestamp":"1685793120.0","content":"Selected Answer: AB\nA - sounds weird since NAT Gateway can't be deployed in Private subnet (Probably copy/past issue). but i can't find any other solution for this situation. \nSo i'm choosing anyway A+B+E which is in simple words:\nMoving the DB and the APP layer to private subnet and deploy NAT gateway which will be associated with an ENI+Static IP","poster":"Toptip","upvote_count":"2","comments":[{"upvote_count":"1","content":"Sorry i meant: A+C+E","comment_id":"913510","timestamp":"1685793240.0","poster":"Toptip"},{"timestamp":"1690376340.0","upvote_count":"1","comment_id":"963741","content":"Yes. it can. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","poster":"captainpike"}]},{"comment_id":"883480","timestamp":"1682684040.0","content":"These actions will ensure that only HTTP and HTTPS traffic from the internet can reach the application, while allowing communication with the external payment provider through the NAT gateway. Placing the DB instance and EC2 instances in private subnets will provide an additional layer of security. ACE are the best choices here.","poster":"ITGURU51","upvote_count":"1"},{"comment_id":"830006","upvote_count":"1","poster":"Ell89","timestamp":"1678029000.0","content":"i dont think the answers are correct to chose 3 from. whoever is choosing A needs their head examining."},{"upvote_count":"3","content":"Selected Answer: CEF\nThe security engineer should recommend the following actions:\nC. Place the DB instance in a private subnet.\nE. Configure the Auto Scaling group to place the EC2 instances in a private subnet.\nF. Deploy the ALB in a private subnet.\nThis will ensure that the communication with the external payment provider is not interrupted as the environment scales and only HTTP and HTTPS traffic is allowed from the internet.","poster":"Jimmy123","timestamp":"1674917220.0","comment_id":"790675"},{"content":"ACE is correct","upvote_count":"3","comment_id":"764514","poster":"jishrajesh","timestamp":"1672744500.0"},{"upvote_count":"3","timestamp":"1669782960.0","poster":"D2","comment_id":"731093","content":"C and E are correct. However, something wrong in wordings of A or D options. NAT must be in public subnet, so is ALB"},{"content":"Selected Answer: AEF\nThe question says that BD will be running on AWS RDS, so we don't need to worry about it. It also asks to to break the app as the system grows, so implement ASG and ALB in private subnets and use NAT gateway to be able to communicate to external world.","comments":[{"comment_id":"661416","upvote_count":"1","timestamp":"1662479760.0","content":"The only require connectivity from the internet is for HTTP and HTTPS traffic to the application. \n\nYou cant put your ALB in private subnet and get internet traffic.","poster":"Root_Access"}],"timestamp":"1659215340.0","upvote_count":"1","poster":"dcasabona","comment_id":"639815"},{"upvote_count":"2","timestamp":"1658484540.0","content":"Thanks for the answers. ACE is correct","poster":"subhoaws","comment_id":"635124"},{"upvote_count":"2","comment_id":"633623","timestamp":"1658240460.0","content":"Selected Answer: ACE\nStandard Load Balancers Best PRactices","poster":"sapien45"},{"content":"There are only two right answers C and E.","poster":"TigerInTheCloud","comment_id":"586095","timestamp":"1649984700.0","upvote_count":"2"},{"comment_id":"556225","content":"Selected Answer: ACE\ni think A C E","poster":"lotfi50","timestamp":"1645820700.0","upvote_count":"4"},{"content":"It Should be ACD . Amazon Relational Database Service (RDS) is a managed SQL database service provided by Amazon Web Services (AWS). So we dont need to move the instances .","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"545621","content":"i think ACE makes more sense","poster":"AliS2020","timestamp":"1644634740.0"}],"comment_id":"535137","poster":"AliS2020","timestamp":"1643427480.0"},{"content":"This is ACE.\nASG must be in private subnet for better security while LB is in public subnet.","poster":"NSF2","timestamp":"1642536420.0","upvote_count":"2","comment_id":"526985"},{"timestamp":"1642334640.0","content":"Something wrong in this question as A and F are not correct, and B-C and D-E mutually exclusive.","poster":"CarisB","comment_id":"524919","upvote_count":"2"},{"timestamp":"1642084020.0","content":"ACD - DB instance should be in private subnets, which requires private NAT Gateway to communicate with VM instances in public subnets, which is required since instances receive HTTP(S) traffic from a secured list of IPs","upvote_count":"2","poster":"studlystudybuddy","comment_id":"522890"},{"content":"C, E is definitely correct. out of other 3, A is the only legitimate option but it should be in the Public subnet not private. If the NAT GW is in private subnet, application servers will not be able to connect to internet and payment gateway.","comments":[{"comment_id":"534142","upvote_count":"1","timestamp":"1643319180.0","content":"It must be a typo in the option A","poster":"RamKun"}],"comment_id":"521155","timestamp":"1641851400.0","poster":"jayaj","upvote_count":"4"},{"upvote_count":"2","timestamp":"1641657780.0","content":"NAT Gateway should be placed in a public subnet, Isn't option A itself wrong?","poster":"cloudchica","comment_id":"519639"},{"poster":"ddm123","timestamp":"1641582540.0","comment_id":"519170","upvote_count":"4","content":"A - C. - E"},{"comments":[{"content":"A is incorrect. NAT Gateway must be placed in a public subnet to provide access to the resources running in private subnet","comments":[{"timestamp":"1641314640.0","content":"Public Subnet is the default\nThe NAT gateway replaces the source IP address of the instances with the IP address of the NAT gateway. For a public NAT gateway, this is the elastic IP address of the NAT gateway. For a private NAT gateway, this is the private IP address of the NAT gateway. When sending response traffic to the instances, the NAT device translates the addresses back to the original source IP address.","poster":"argol","upvote_count":"1","comment_id":"516829"}],"upvote_count":"2","poster":"roger8978","comment_id":"514673","timestamp":"1641070800.0"},{"poster":"network_zeal","upvote_count":"1","timestamp":"1641543720.0","comment_id":"518839","content":"D is incorrect. Put EC2 in private sub in ASG is option E"}],"timestamp":"1640890680.0","content":"Ans is ACD\nDB instance must be in private subnet and ALB should be in Public subnet and Auto Scaling group to place the EC2 instances should be in private subnet behind ALB","poster":"BKhan","comment_id":"513644","upvote_count":"1"}],"topic":"1","answers_community":["ACE (47%)","CEF (33%)","13%","7%"],"timestamp":"2021-12-30 19:58:00","question_images":[],"unix_timestamp":1640890680,"question_text":"A security engineer is working with a company to design an ecommerce application. The application will run on Amazon EC2 instances that run in an Auto Scaling group behind an Application Load Balancer (ALB). The application will use an Amazon RDS DB instance for its database.\nThe only require connectivity from the internet is for HTTP and HTTPS traffic to the application. The application must communicate with an external payment provider that allows traffic only from a preconfigured allow list of IP addresses. The company must ensure that communicators with the external payment provider are not interrupted as the environment scales.\nWhich combination of actions should the security engineer recommend to meet these requirements? (Choose three.)","answer":"ACE","isMC":true,"choices":{"C":"Place the DB instance in a private subnet.","F":"Deploy the ALB in a private subnet.","E":"Configure the Auto Scaling group to place the EC2 instances in a private subnet.","A":"Deploy a NAT gateway in each private subnet for every Availability Zone that is in use.","B":"Place the DB instance in a public subnet.","D":"Configure the Auto Scaling group to place the EC2 instances in a public subnet."},"url":"https://www.examtopics.com/discussions/amazon/view/69095-exam-aws-certified-security-specialty-topic-1-question-299/","answer_description":"","exam_id":29,"answer_ET":"ACE"},{"id":"OcGM5MjWMDXt40MZvVEc","answer_description":"","choices":{"B":"AWS IAM users","D":"AWS IAM access keys","A":"AWS IAM groups","C":"AWS IAM roles"},"question_id":223,"url":"https://www.examtopics.com/discussions/amazon/view/4029-exam-aws-certified-security-specialty-topic-1-question-3/","isMC":true,"question_text":"A company wants to control access to its AWS resources by using identities and groups that are defined in its existing Microsoft Active Directory.\nWhat must the company create in its AWS account to map permissions for AWS services to Active Directory user attributes?","question_images":[],"topic":"1","unix_timestamp":1566745920,"exam_id":29,"answer":"C","answers_community":["C (100%)"],"answer_ET":"C","timestamp":"2019-08-25 17:12:00","discussion":[{"content":"Correct is C\nPrerequisites to establish Federation Services in AWS\n- You have a working AD directory and AD FS server.\n- You have created an identity provider (IdP) in your AWS account using your XML file from your AD FS server. Remember the name of your IdP because you will use it later in this solution.\n -You have created the appropriate IAM roles in your AWS account, which will be used for federated access.\nhttps://aws.amazon.com/blogs/security/how-to-establish-federated-access-to-your-aws-resources-by-using-active-directory-user-attributes/","poster":"josellama2000","timestamp":"1632280380.0","comment_id":"8360","upvote_count":"35"},{"timestamp":"1725257280.0","poster":"[Removed]","content":"C is correct answer.","comment_id":"1276449","upvote_count":"9"},{"content":"Correct answer is C","comment_id":"1005371","upvote_count":"1","timestamp":"1694493840.0","poster":"Benah"},{"timestamp":"1694493780.0","comment_id":"1005370","upvote_count":"1","content":"AWS IAM roles","poster":"Benah"},{"content":"Selected Answer: C\nCorrect is C","poster":"Robert0","comment_id":"914215","timestamp":"1685861100.0","upvote_count":"1"},{"poster":"ITGURU51","timestamp":"1684352760.0","content":"The recommended best practice is to map federated users to roles within AWS. C","comment_id":"900476","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: C\nIt is Option :C \nAs in case of other IAM identities like User , Groups - Permanent identities. In this case the identity store is AD. So for temporary identities we will be need IAM roles","poster":"KVK16","timestamp":"1673703720.0","comment_id":"775449"},{"content":"C for sure! Users in AD match roles in AWS","upvote_count":"1","comment_id":"764333","poster":"luis12345","timestamp":"1672735500.0"},{"content":"Selected Answer: C\nC - IAM Roles are preferred for this scenario.","comment_id":"715964","timestamp":"1668163440.0","poster":"gg12345","upvote_count":"1"},{"poster":"sanjaym","timestamp":"1636152840.0","comment_id":"353733","content":"Ans: C 100%","upvote_count":"3"},{"timestamp":"1635629940.0","content":"CCCCCCCCCCCC","comment_id":"340040","upvote_count":"3","poster":"ashok1234567890"},{"comment_id":"289132","upvote_count":"2","poster":"Haxor","content":"C!!! https://docs.aws.amazon.com/directoryservice/latest/admin-guide/assign_role.html","timestamp":"1635530460.0"},{"content":"Ans > C","timestamp":"1634966340.0","upvote_count":"1","comment_id":"221706","poster":"devjava"},{"timestamp":"1634813040.0","poster":"mahtab","comment_id":"212001","upvote_count":"1","content":"Definitely C"},{"comment_id":"207351","upvote_count":"1","poster":"AfricanCloudGuru","content":"Ans (C)\nAWS IAM","timestamp":"1634628840.0"},{"content":"ANSWER C","poster":"IfyEze","comment_id":"107209","upvote_count":"2","timestamp":"1634600940.0"},{"comment_id":"93518","content":"C is correct answer.","timestamp":"1634505300.0","poster":"Cyb3rgh057","upvote_count":"2"},{"timestamp":"1634155740.0","content":"C is correct","comment_id":"67202","upvote_count":"2","poster":"RaySmith"},{"comment_id":"51018","upvote_count":"3","content":"Active Directory GROUPs should be mapped to AWS IAM ROLES to establish federation services.","timestamp":"1634140620.0","poster":"aws_learner"},{"upvote_count":"4","content":"Iam roles, are used to delegate the Temparory access. So answer is c.","poster":"RakeshTaninki","timestamp":"1633763820.0","comment_id":"44421"},{"upvote_count":"3","poster":"bp339","content":"Answer is C\n Appropriate IAM roles are necessary in your AWS account, which will be used for federated access.","comment_id":"43209","timestamp":"1633527120.0"},{"timestamp":"1633526400.0","content":"YES C IS CORRECT","poster":"jaysource","comment_id":"27033","upvote_count":"2"},{"timestamp":"1633306500.0","upvote_count":"2","content":"C is correct. AWS IAM roles","poster":"rctaptap","comment_id":"19238"},{"content":"C is correct , you can only map IAM roles to MS AD group attributes when you create federations services.","poster":"INASR","comment_id":"10770","timestamp":"1632587280.0","upvote_count":"2"},{"content":"Yes.. C is Correct","poster":"BillyC","timestamp":"1632200280.0","comment_id":"8197","upvote_count":"8"}],"answer_images":[]},{"id":"d2ITdNke4iIFjtUaMqhe","topic":"1","answer_description":"","answer":"C","choices":{"A":"Implement a ג€write-onlyג€ CloudTrail event filter to detect any modifications to the AWS account resources.","D":"Enable Amazon S3 event notifications to trigger an AWS Lambda function that sends an email alarm when there are new CloudTrail API entries.","B":"Configure Amazon Macie to classify and discover sensitive data in the Amazon S3 bucket that contains the CloudTrail audit logs.","C":"Configure Amazon Athena to read from the CloudTrail S3 bucket and query the logs to examine account activities."},"question_text":"A Security Administrator is performing a log analysis as a result of a suspected AWS account compromise. The Administrator wants to analyze suspicious AWS\nCloudTrail log files but is overwhelmed by the volume of audit logs being generated.\nWhat approach enables the Administrator to search through the logs MOST efficiently?","unix_timestamp":1566747000,"timestamp":"2019-08-25 17:30:00","discussion":[{"upvote_count":"33","comment_id":"10811","timestamp":"1632455100.0","content":"C is the correct answer since it asks how to search the logs most efficiently and the only way to search and analyze huge logs is using Athena queries on S3. A is wrong because you can create a trail with write-only managment and data events upon creation of the trail and this has nothing to do with searching exisitng huge number of logs in an efficient way.","poster":"INASR"},{"content":"I had this question on my exam today. Correct answer is C","poster":"hozefa","upvote_count":"13","comments":[{"comments":[{"timestamp":"1636167720.0","comment_id":"392201","content":"He has the exact same answer format for every question. I'd be wary of his answers","poster":"skipbaylessfor3","upvote_count":"10"}],"comment_id":"262466","timestamp":"1635809280.0","content":"Did you see the result for this particular question or did you score 100%. How do you know you selected the correct answer :)","upvote_count":"12","poster":"GeeBeeEl"}],"timestamp":"1634065800.0","comment_id":"97064"},{"poster":"Majoko","comment_id":"1183455","upvote_count":"2","timestamp":"1711471320.0","content":"Saw a similar question in TJ that makes this one look like an incomplete copy;\nEssentially the same situation except they specify KMS is used and that the sec engineer needs to track certain events (Disable, Delete, ScheduleKey) and is overwhelmed when 99% of the events are Encrypt, Decrypt, and GenerateDataKey API calls, essentially calling for a solution to search through audit logs for the events they need to see.\n\nDisable / Delete / ScheduleKey actions are write events while Encrypt / Decrypt / GenerateDataKey are read events.\n\nLong story short, this feels like an incomplete question"},{"timestamp":"1708826400.0","poster":"Raphaello","comment_id":"1158279","content":"Selected Answer: A\nA is the best answer.\nAfter a compromise incident, it is more efficient to filter out \"write-only\" event in CloudTrail event history.\n\nOption C does not give any edge in relation to this context.","upvote_count":"1"},{"comment_id":"901522","timestamp":"1684448040.0","content":"The most efficient way to analyze AWS CloudTrail logs is to **configure Amazon Athena** to read from the CloudTrail S3 bucket and query the logs to examine account activities¹. Using Athena, you can easily write SQL queries to filter and analyze CloudTrail log events. C","upvote_count":"1","poster":"ITGURU51"},{"timestamp":"1683044580.0","comment_id":"887667","content":"Selected Answer: C\nNote \"search through the logs\" - search = Athena","poster":"SaucyVip3r","upvote_count":"1"},{"content":"Selected Answer: A\nA is the correct one. MOST efficiently! \nhttps://aws.amazon.com/blogs/mt/streamline-aws-cloudtrail-logs-using-event-filters/","timestamp":"1682838840.0","comment_id":"884947","poster":"matrpro","upvote_count":"1"},{"timestamp":"1672751520.0","comment_id":"764668","upvote_count":"1","content":"I have done this practically with the Logs generated by a Firewall Manager. They were analyzed with Athena and worked perfectly!","poster":"luis12345"},{"comment_id":"716397","upvote_count":"2","timestamp":"1668213000.0","poster":"janvandermerwer","content":"Selected Answer: C\nI'm going to go with C - Key concept \"search data/logs\"\n- Athena is useful for scanning VPC flow logs and similar, so would be a similar scenario for Cloudtrail.\n\nThis also improves management, rather than needing to create new (or modify) existing cloudtrails.\nExample:\nhttps://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html\nhttps://aws.amazon.com/premiumsupport/knowledge-center/athena-tables-search-cloudtrail-logs/"},{"upvote_count":"1","timestamp":"1665418680.0","poster":"arae","content":"C because we can use Athena to query the s3 which will filter out lots of things.","comment_id":"691344"},{"comment_id":"655250","poster":"123Raj333","upvote_count":"3","timestamp":"1661962320.0","content":"Selected Answer: A\nbut is overwhelmed by the volume of audit logs being generated\" is the keyword here. So, option A is the correct solution"},{"comment_id":"641440","poster":"dcasabona","content":"Selected Answer: C\nI also agree on C.","timestamp":"1659470700.0","upvote_count":"2"},{"poster":"teo2157","comment_id":"589700","upvote_count":"2","content":"Selected Answer: C\nC, Athena https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html","timestamp":"1650596640.0"},{"comment_id":"531571","timestamp":"1643057520.0","upvote_count":"2","content":"The reason why A is not correct because THERE IS NO WRITE-ONLY option in the drop down list, hence I will go with C","poster":"NSF2"},{"comment_id":"520195","content":"Answer is A according to Tutorial Dojo","upvote_count":"4","timestamp":"1641733260.0","poster":"uninit","comments":[{"content":"Don't lie","comment_id":"595492","timestamp":"1651391220.0","poster":"HananS","upvote_count":"1"}]},{"comment_id":"481113","content":"answer is C","poster":"IMAHM","timestamp":"1637272500.0","upvote_count":"1"},{"comment_id":"405648","comments":[{"timestamp":"1682046900.0","poster":"vavofa5697","upvote_count":"1","comment_id":"876160","content":"thanks!"}],"timestamp":"1636301700.0","content":"For those saying that CloudTrail doesn't have a write-only events filter, I invite you to check out the CloudTrail console, go to Event History, choose the \"Read-only\" lookup attribute, and the to right of it, select \"false\". Voila, you will then see write only events show up... Thus, implementing this is possible. What makes A probably incorrect for me is that it says use this to \"detect any modifications to the AWS account resources\" which sounds more like Config. That's the reason A's wrong in my opinion, not the reason that everyone seems to think it is","upvote_count":"7","poster":"skipbaylessfor3"},{"poster":"ShakthiVinu","content":"my answer is C","upvote_count":"1","comment_id":"397275","timestamp":"1636222800.0"},{"poster":"rhinozD","timestamp":"1635945120.0","content":"I think C is the answer.\nYou dont want to do it when you setup cloudtrail. How about read? How about other purposes on Cloudtrail logs? \n\"log analysis as a result of a suspected AWS account compromise. \" \nI think this mention that the account is already compromised -> everything is already logged","comment_id":"388709","upvote_count":"1"},{"upvote_count":"2","timestamp":"1635928740.0","poster":"sanjaym","content":"Ans: A","comment_id":"353796"},{"upvote_count":"2","content":"\"........ but is overwhelmed by the volume of audit logs being generated\" is the keyword here. So, option A is the correct solution.","poster":"akbntc","comment_id":"274898","timestamp":"1635922440.0"},{"timestamp":"1635883500.0","poster":"GeeBeeEl","comments":[{"upvote_count":"5","content":"Amazon Macie will search S3 buckets for stuff like drivers license numbers, social security numbers, etc. but it cannot filter through logs from CloudTrail, you have to use Athena for that so you can run SQL queries","timestamp":"1635922020.0","comment_id":"270916","poster":"eviecat"}],"comment_id":"269013","upvote_count":"1","content":"I select B, Amazon Macie, see https://docs.aws.amazon.com/macie/latest/userguide/macie-classify-data.html Question objective, how do you search through logs most efficiently. Answer from link \"Macie Classic can help you classify your sensitive and business-critical data stored in the AWS cloud.\" \"enable Macie Classic to continuously monitor and discover new data as it enters your AWS infrastructure\""},{"poster":"MJ06","timestamp":"1635827520.0","upvote_count":"2","content":"AWS CloudTrail is a service that records AWS API calls and events for AWS accounts.\n\nCloudTrail logs include details about any API calls made to your AWS services, including the console. CloudTrail generates encrypted log files and stores them in Amazon S3. For more information, see the AWS CloudTrail User Guide.\n\nUsing Athena with CloudTrail logs is a powerful way to enhance your analysis of AWS service activity. For example, you can use queries to identify trends and further isolate activity by attributes, such as source IP address or user.\nhttps://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html","comment_id":"262902"},{"content":"For me it is C.\nI don't know why no one mentions a point here: it asks for \"performing a log analysis\", which means it wants to process the already existing logs. Many people mentioned Event filters, but it only applies when creating a new Trail, so it only affects new logs. Thus, A cannot be true.","poster":"examtaker12","timestamp":"1635750360.0","comment_id":"247297","upvote_count":"2"},{"content":"How is A correct? Enabling “write-only” is going to change Cloudtrail to send those events from that time onwards. The question is talking about analyzing existing logs, so they need to be analyzed/queried/filtered and that’s possible via Athena .","poster":"awscerts2020","upvote_count":"2","comment_id":"232454","comments":[{"comment_id":"232458","content":"Unless this is being done on AWS Console which keeps the data only for 90 days. Considering no timeline is mentioned, I don’t think its A","poster":"awscerts2020","timestamp":"1635647100.0","upvote_count":"1"}],"timestamp":"1635630900.0"},{"upvote_count":"1","content":"A is correct. Ben Piper on Pluralsight talked about this scenario","timestamp":"1635534480.0","comment_id":"229716","poster":"shooricg"},{"comment_id":"227876","upvote_count":"2","content":"CloudTrail Event filter definitions:\n Read-only\n Includes API operations that read your resources, but don’t make changes. For example, read-only events include the Amazon EC2 DescribeSecurityGroups and DescribeSubnets API operations as well as all other List and Describe type calls. These operations return only information about your Amazon EC2 resources and don’t change your configurations or resources.\n Write-only\n Includes API operations that modify (or might modify) your resources. For example, the Amazon EC2 RunInstances and TerminateInstances API operations modify your instances. Console sign-in events are also considered write-only.\n All\n Includes both read-only and write-only API operations\nanswer....A","poster":"argol","timestamp":"1635405480.0"},{"upvote_count":"2","timestamp":"1635286440.0","poster":"devjava","comment_id":"221864","content":"Ans > C"},{"content":"Ans(C)","upvote_count":"1","timestamp":"1635231300.0","poster":"AfricanCloudGuru","comment_id":"207428"},{"poster":"AfricanCloudGuru","upvote_count":"1","timestamp":"1635195720.0","comment_id":"207427","content":"Ans (c)"},{"timestamp":"1634977980.0","content":"well, for me, the answer is A.\nThe question is asking about the most efficiency way in order to analyze the log while the analysis is overwhelming of auditing log being generated.\nHence, if you are using the Athena, it is not MOST efficiency cause you still have to execute the query and filtering the most related event (write-only or modification events) from the huge size of data.\nHence, just filtering the modification and focusing on it will be the most efficiency way for me.","poster":"MichaelHoang","comment_id":"171794","upvote_count":"3"},{"comment_id":"155124","timestamp":"1634933040.0","content":"C is correct","upvote_count":"2","poster":"enthuguys"},{"timestamp":"1634755500.0","comment_id":"132883","content":"The correct is A as we can search the modification in CloudTrail immediately by using the CloudTrail event filter. You don't need Athena.","comments":[{"timestamp":"1634895240.0","poster":"echo_cert","upvote_count":"2","content":"C for me. Athena is relevant to query the logs \n\nSo you think A is correct? Does it mean you think an AWS account cannot be compromised by a read event?","comment_id":"154778"}],"upvote_count":"1","poster":"Jeb"},{"content":"Answer is C for sure.","comment_id":"116997","timestamp":"1634395980.0","poster":"AWSandeep","upvote_count":"1"},{"content":"Administrator wants to analyze suspicious AWS CloudTrail log files --this make me think if this A or C","comment_id":"114021","upvote_count":"1","timestamp":"1634372940.0","poster":"Kalimalar"},{"upvote_count":"1","poster":"RB80","content":"With option A, it will impact whole account which is not desirable, So should be option C","timestamp":"1634245140.0","comment_id":"109739"},{"content":"C!! ATHENA QUERY on S3 !!! Guys can you suggest why default answer selection after revel is always the wrong one !!! is this intentional !!!!! If reader follows the default answers and attend the exam he is DOOOOOMED !!!!","poster":"AnilL","upvote_count":"2","comment_id":"87125","timestamp":"1633876440.0"},{"upvote_count":"1","comment_id":"75243","poster":"RaySmith","content":"C is correct","timestamp":"1633843980.0"},{"timestamp":"1633359840.0","poster":"ssubbu","upvote_count":"1","comment_id":"72127","content":"My Answer is C"},{"comment_id":"70748","timestamp":"1633247760.0","upvote_count":"1","content":"my answer is C","poster":"tomtom2020"},{"comments":[{"comment_id":"67815","upvote_count":"3","comments":[{"timestamp":"1633246020.0","poster":"luis12345","upvote_count":"2","comment_id":"68381","content":"There is no such \"write-only\" filter on CloudTrail, only \"read only\". Answer is therefore C."}],"content":"This is totally wrong as Macie is not used to analyze CloudTrail logs at all... Right answer I would say its C","timestamp":"1633064160.0","poster":"luis12345"},{"timestamp":"1635186000.0","comment_id":"173184","upvote_count":"2","poster":"freddyman","content":"Macie is for discovering sensitive data in S3 buckets, and in future in other sources. It has nothing to do with log file analysis. Athena is the answer."}],"upvote_count":"1","comment_id":"65855","content":"Im going to say Amazon Macie, since it says easiest way for Admin to ANALYZE the data in S3. Macie Identifies and Detects security focused data, and ML/AI recognizes unusual user behavior and activity","poster":"simplimarvelous","timestamp":"1633029960.0"},{"comments":[{"content":"correct, if you follow option A, Cloud Trail will have only 3 months of logs. the question never specified a point of time. So the engineer should search from the whole logs and it can be done by option C. If they have specified that this is before 3 months then option A is the MOST efficient way.","upvote_count":"2","poster":"boya","comments":[{"timestamp":"1634016660.0","poster":"boya","content":"So that makes it Option C the only answer.","comment_id":"89265","upvote_count":"2"}],"comment_id":"89264","timestamp":"1633951440.0"}],"comment_id":"59848","upvote_count":"1","content":"A is the right answer because the question is about MOST efficiently.\n\nit means minimum wasted effort or expense.\n\nwhen you select C it is more effort and more expense.","poster":"ankurpatel18","timestamp":"1633019580.0"},{"comments":[{"timestamp":"1632969300.0","content":"we can separate write-only event filter.\nhttps://aws.amazon.com/blogs/mt/streamline-aws-cloudtrail-logs-using-event-filters/","upvote_count":"2","comment_id":"55527","comments":[{"content":"no, but it is when you CREATE a new Trail, not when you want to review old CloudTrail logs","timestamp":"1635690720.0","comment_id":"247293","upvote_count":"2","poster":"examtaker12"}],"poster":"bp339"}],"content":"C is the answer, we dont have option to choose write only filter.","upvote_count":"2","comment_id":"45658","timestamp":"1632898920.0","poster":"RakeshTaninki"},{"poster":"donathon","upvote_count":"2","comment_id":"39987","timestamp":"1632796920.0","content":"A\nIncludes API operations that modify (or might modify) your resources. For example, the Amazon EC2 RunInstances and TerminateInstances API operations modify your instances. Console sign-in events are also considered write-only.\nhttps://aws.amazon.com/blogs/mt/streamline-aws-cloudtrail-logs-using-event-filters/\nB: Amazon Macie is a security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS. Amazon Macie recognizes sensitive data such as personally identifiable information (PII) or intellectual property, and provides you with dashboards and alerts that give visibility into how this data is being accessed or moved. The fully managed service continuously monitors data access activity for anomalies, and generates detailed alerts when it detects risk of unauthorized access or inadvertent data leaks. Today, Amazon Macie is available to protect data stored in Amazon S3, with support for additional AWS data stores coming later this year.\nC\\D: Not the most efficient."},{"content":"Cccccc","upvote_count":"1","timestamp":"1632571440.0","poster":"henry76","comment_id":"37593"},{"timestamp":"1632456240.0","content":"If the data has been generated then how will it possible to apply a write-only filter on event cloudtrail logs?\nI think the answer should be C as Athena can parse and query the files available on S3.","upvote_count":"5","poster":"aws_ninja","comment_id":"17066"},{"timestamp":"1632406080.0","upvote_count":"1","poster":"ugreenhost","content":"A is doable but not comprehensive, option C is a better choice","comment_id":"10191"},{"poster":"PR","comment_id":"10093","content":"A=> Write-only\nIncludes API operations that modify (or might modify) your resources. For example, the Amazon EC2 RunInstances and TerminateInstances API operations modify your instances. Console sign-in events are also considered write-only.","upvote_count":"3","timestamp":"1632405600.0"},{"poster":"duduga40","timestamp":"1632280200.0","content":"A or C.. anybody?","comment_id":"9935","upvote_count":"1"},{"timestamp":"1632139860.0","poster":"BillyC","content":"C is Correct!","comment_id":"9639","upvote_count":"4"},{"content":"To search through voluminous log files effectively, the answer is C. Amazon Athena is built specifically for this purpose, hence it could be used for Data Lake.","timestamp":"1632131640.0","upvote_count":"5","comment_id":"9381","poster":"Osemk"},{"comment_id":"9342","upvote_count":"5","poster":"polo","timestamp":"1632090960.0","comments":[{"poster":"cloudprincipal","upvote_count":"3","content":"Agreed, C makes sense","timestamp":"1632677700.0","comment_id":"38227"}],"content":"C for me....A is telling you resources changes/modifications (thats aws config)"},{"comment_id":"8215","poster":"BillyC","content":"A or C, :(","upvote_count":"1","timestamp":"1632068700.0"}],"isMC":true,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/4047-exam-aws-certified-security-specialty-topic-1-question-30/","question_id":224,"answer_images":[],"answers_community":["C (58%)","A (42%)"],"exam_id":29,"answer_ET":"C"},{"id":"R9OQKSr4AgbL6T9fJMfu","topic":"1","choices":{"B":"Host the database on Amazon RDS. Use Amazon Elastic Block Store (Amazon EBS) for encryption. Use an AWS managed CMK in AWS Key Management Service (AWS KMS) for key management.","A":"Host the database on Amazon RDS. Use Amazon Elastic Block Store (Amazon EBS) for encryption. Use an AWS Key Management Service (AWS KMS) custom key store that is backed by AWS CloudHSM for key management.","D":"Host the database on an Amazon EC2 instance. Use Transparent Data Encryption (TDE) for encryption and key management.","C":"Host the database on an Amazon EC2 instance. Use Amazon Elastic Block Store (Amazon EBS) for encryption. Use a customer managed CMK in AWS Key Management Service (AWS KMS) for key management."},"isMC":true,"answer":"A","discussion":[{"upvote_count":"12","poster":"Radhaghosh","content":"CloudHSM --> FIPS 140-2 Level 3 \nKMS --> FIPS 140-2 Level 2 \nA is the only Valid Option.","timestamp":"1643241060.0","comment_id":"533350"},{"comment_id":"1274425","upvote_count":"1","timestamp":"1724921220.0","content":"Selected Answer: B\nFor now, the answer is B\nCurrently KMS support FIPS 140-2 Level 3\nKeywords: minimizes operational overhead\nso B better","poster":"jamesf"},{"content":"Selected Answer: A\nThat's an old question. Now KMS uses HSM's that are FIPS 140-2 Level 3 compliant, same as CloudHSM. \nTherefore both A & B are correct now.","comment_id":"1155949","upvote_count":"2","poster":"Raphaello","timestamp":"1708560120.0"},{"timestamp":"1704719400.0","comments":[{"timestamp":"1722176520.0","upvote_count":"1","comment_id":"1256840","content":"https://aws.amazon.com/blogs/security/aws-kms-now-fips-140-2-level-3-what-does-this-mean-for-you/","poster":"61cfe5f"}],"content":"Selected Answer: B\nas of Now","upvote_count":"3","comment_id":"1116626","poster":"yorkicurke"},{"upvote_count":"3","poster":"lmimi","timestamp":"1700265540.0","comment_id":"1073724","content":"Now AWS KMS supports FIPS 140-2 Level 3 as well. So B should be the right answer due to minimizes operational overhead."},{"upvote_count":"1","timestamp":"1685793360.0","comment_id":"913512","content":"Selected Answer: A\nA easy one... FIPS 140-2 Level 3 = CloudHSM","poster":"Toptip","comments":[{"comments":[{"upvote_count":"2","content":"Yeah now B should be the right option","timestamp":"1700135880.0","comment_id":"1072377","poster":"Maffo102"}],"content":"Now KMS is FIPS 140-2 Level 3 does that change the ans to B? https://aws.amazon.com/kms/faqs/","timestamp":"1699064700.0","poster":"M2ao","comment_id":"1061869","upvote_count":"3"}]},{"timestamp":"1682685900.0","comment_id":"883494","upvote_count":"1","poster":"ITGURU51","content":"A is the best answer because CloudHSM minimizes operational overhead and satisfies the security requirement. (FIPS 140-2 Level 3 encryption)"},{"content":"Never heard Amazon Elastic Block Store (Amazon EBS) is used for encryption !","timestamp":"1673094840.0","poster":"abeb","comment_id":"768548","upvote_count":"1"},{"content":"Selected Answer: A\nFIPS + RDS minimizes operational overhead","comment_id":"757378","timestamp":"1672055580.0","upvote_count":"1","poster":"bazoch78"},{"upvote_count":"1","comment_id":"731103","timestamp":"1669783560.0","content":"Selected Answer: A\nAnswer A","poster":"D2"},{"content":"Selected Answer: A\nA is the valid answer due to FIPS = CloudHSM.\nAlso, host database other than in RDS (in an AWS exam context) seems odd.","poster":"Sarksa","comment_id":"640593","upvote_count":"1","timestamp":"1659353160.0"},{"comment_id":"639314","content":"Selected Answer: A\nOption A.","upvote_count":"1","timestamp":"1659111540.0","poster":"dcasabona"},{"content":"Selected Answer: A\nI am a simple man, I see FIPS 140-2 Level 3, I thing CloudHSM","comment_id":"633076","poster":"sapien45","upvote_count":"4","timestamp":"1658158440.0"},{"content":"Selected Answer: A\nFIPS 140-2 Level 3 filtered out all other choices","comment_id":"585762","poster":"TigerInTheCloud","upvote_count":"2","timestamp":"1649940720.0"},{"content":"Selected Answer: A\nA - Needs to be CloudHSM which is the only compliant with FIPS 140-2 Level 3","poster":"ceros399","upvote_count":"3","timestamp":"1647862680.0","comment_id":"572137"},{"content":"CloudHSM only option that meets the FIPS req. - therefore gotta be \"A\".","comment_id":"521023","poster":"LearnMeSomeAWS","timestamp":"1641838440.0","upvote_count":"3"},{"timestamp":"1640970540.0","content":"A. \nYou can store your KMS customer master keys (CMKs) in a custom key store instead of the standard KMS key store. Custom key stores are created using an AWS CloudHSM cluster that you own and manage. This provides direct control of the hardware security modules (HSMs) that generate the key material for your CMKs and perform cryptographic operations with them.","poster":"roger8978","comment_id":"514169","upvote_count":"3"},{"comment_id":"513813","timestamp":"1640915220.0","upvote_count":"4","poster":"khamrumunnu","content":"Answer: A\n\nFIPS 140-2 Level 3 is CloudHSM"}],"url":"https://www.examtopics.com/discussions/amazon/view/69113-exam-aws-certified-security-specialty-topic-1-question-300/","question_images":[],"question_id":225,"exam_id":29,"unix_timestamp":1640915220,"answer_description":"","answer_images":[],"timestamp":"2021-12-31 02:47:00","answers_community":["A (80%)","B (20%)"],"answer_ET":"A","question_text":"A company's application team needs to host a MySQL database on AWS. According to the company's security policy, all data that is stored on AWS must be encrypted at rest. In addition, all cryptographic material must be compliant with FIPS 140-2 Level 3 validation.\nThe application team needs a solution that satisfies the company's security requirements and minimizes operational overhead.\nWhich solution will meet these requirements?"}],"exam":{"lastUpdated":"11 Apr 2025","isMCOnly":false,"provider":"Amazon","id":29,"numberOfQuestions":509,"name":"AWS Certified Security - Specialty","isImplemented":true,"isBeta":false},"currentPage":45},"__N_SSP":true}