{"pageProps":{"questions":[{"id":"qnv0mNDmvieUVrLaLiCr","answer_images":[],"question_id":591,"question_images":[],"question_text":"An enterprise company wants to allow its developers to purchase third-party software through AWS Marketplace. The company uses an AWS Organizations account structure with full features enabled, and has a shared services account in each organizational unit (OU) that will be used by procurement managers. The procurement team's policy indicates that developers should be able to obtain third-party software from an approved list only and use Private Marketplace in AWS\nMarketplace to achieve this requirement. The procurement team wants administration of Private Marketplace to be restricted to a role named procurement- manager-role, which could be assumed by procurement managers. Other IAM users, groups, roles, and account administrators in the company should be denied\nPrivate Marketplace administrative access.\nWhat is the MOST efficient way to design an architecture to meet these requirements?","discussion":[{"poster":"Nemer","timestamp":"1632091020.0","content":"C. SCP to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role.\n\nhttps://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/","comment_id":"157018","upvote_count":"21","comments":[{"comment_id":"400249","content":"I will go with C as Procurement manager need access from shared account. We don't want any other account have the proc-mag-role as goes with least permission principle.","timestamp":"1635754260.0","poster":"Gladabhi","upvote_count":"3"},{"upvote_count":"9","content":"Changed to D. In C, there is the issue of ROOT-level SCP to deny permissions to create an IAM role named procurement-manager-role to EVERYONE in the organization..","comments":[{"upvote_count":"3","content":"D is wrong. Developers should not have the procurement-manager-role.\n\"...restricted to a role named procurement- manager-role, which could be assumed by procurement managers\"","poster":"joe16","comment_id":"456235","timestamp":"1636295520.0"},{"timestamp":"1635119940.0","poster":"Kelvin","upvote_count":"1","comment_id":"338885","content":"Yes, D looks correct."},{"upvote_count":"1","comments":[{"content":"@shammous I am 1/1/2 year late but you should read-up on IAM Privilege Escalation on why that statement is not useless.","timestamp":"1680836700.0","comment_id":"863452","poster":"OnePunchExam","upvote_count":"1"},{"timestamp":"1634701620.0","comments":[{"timestamp":"1636297980.0","content":"Good explanation. \nC makes sense.","comment_id":"458431","upvote_count":"1","poster":"student22"}],"upvote_count":"6","poster":"RedKane","content":"Without second SCP users/roles in other accounts that have full IAM access could create role with this name \"procurement-manager-role\" and assign any permission they want - since first SCP explicitly excludes \"procurement-manager-role\" from the DENY that would allow bypassing intended design of security rules.","comment_id":"330177"}],"content":"The issue is not with the word \"EVERYONE\", but with the entire useless statement: \"Create another organization root-level SCP to deny permissions to create an IAM role named procurement-manager-role to everyone in the organization.\": First, this could be done in the first SCP, second, denying permissions to create an IAM role named procurement-manager-role doesn't change anything.","timestamp":"1634470860.0","poster":"shammous","comment_id":"277769"}],"poster":"Nemer","timestamp":"1632779100.0","comment_id":"163625"}]},{"content":"I'll go with C","upvote_count":"6","poster":"WhyIronMan","comment_id":"413258","timestamp":"1635819180.0"},{"comment_id":"786513","content":"Selected Answer: C\nprocurement-manager-role is needed in shared accounts only. Org level SCP needs to deny permissions to administer Private Marketplace to everyone (including admins) but the role. Another SCP is needed so that role name is not created in any other account. It is C","timestamp":"1674563520.0","upvote_count":"1","poster":"pitakk"},{"poster":"SureNot","timestamp":"1670194440.0","comment_id":"735505","content":"Selected Answer: C\nD is wrong. You can apply SCP to OUs, not accounts","upvote_count":"2","comments":[{"timestamp":"1678083180.0","upvote_count":"1","poster":"[Removed]","comment_id":"830582","content":"wrong, scps can be applied to OU and Member Accounts. Correct answer is still C but thought i would clear that up for you."}]},{"upvote_count":"2","poster":"dcdcdc3","timestamp":"1663858500.0","comment_id":"676272","content":"Selected Answer: D\nper the link provided below\nhttps://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/\n\nand per this paragraph within that link\n\"As an additional control, I applied an SCP to all the organizational units in this example organization to restrict Private Marketplace administration access to an IAM role called procurement-manager. This guardrail prevents other IAM roles, users, or groups from accessing the Private Marketplace administration page, even administrators in any of these organizational units’ accounts.\"\n\nI would choose D","comments":[{"content":"But here the question also says \"Other IAM users, groups, roles, and account administrators in the company should be denied Private Marketplace administrative access\". That means Answer C only matches your point.","comment_id":"695062","upvote_count":"2","timestamp":"1665792240.0","poster":"Rahu"}]},{"comment_id":"637723","poster":"hilft","upvote_count":"2","timestamp":"1658885220.0","content":"D. not C\nnever root level SCP"},{"comment_id":"542755","poster":"jj22222","upvote_count":"1","content":"C looks right","timestamp":"1644275820.0"},{"comment_id":"530852","timestamp":"1642975260.0","upvote_count":"1","poster":"AMKazi","content":"Answer should be B. - meets both requirements of procurement mgmt and dev access\nC- only solving requirement of procurement manager. What about developer access to use the marketplace?\nD- giving procurement manager role to Developers"},{"content":"C is correct.","comment_id":"513381","poster":"cldy","timestamp":"1640869860.0","upvote_count":"1"},{"comment_id":"506909","timestamp":"1640166360.0","poster":"Ni_yot","content":"C for me. The link attached in the write up is worth a read. https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/","upvote_count":"1"},{"timestamp":"1639219800.0","comment_id":"499344","content":"C. Create an IAM role named procurement-manager-role in all the shared services accounts in the organization. Add the AWSPrivateMarketplaceAdminFullAccess managed policy to the role. Create an organization root-level SCP to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role. Create another organization root-level SCP to deny permissions to create an IAM role named procurement-manager-role to everyone in the organization.","poster":"cldy","upvote_count":"1"},{"content":"Selected Answer: C\nC is right!\nhttps://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/","upvote_count":"3","timestamp":"1638322680.0","comment_id":"491128","poster":"AzureDP900"},{"timestamp":"1638255540.0","poster":"acloudguru","content":"Selected Answer: C\nC. SCP to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role.\n\nhttps://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/","comment_id":"490479","upvote_count":"1"},{"timestamp":"1636206360.0","upvote_count":"1","content":"It's C","comment_id":"443232","poster":"andylogan"},{"poster":"tgv","content":"CCC\n---","upvote_count":"1","comment_id":"436163","timestamp":"1636160340.0"},{"poster":"blackgamer","upvote_count":"3","timestamp":"1635590160.0","comments":[{"timestamp":"1635598740.0","comment_id":"358761","upvote_count":"1","content":"Please refer following links for more details why C is correct. \nhttps://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/","poster":"blackgamer"}],"content":"C is the answer. D is wrong as the SCP applying to shared service account which is not being used by developer.","comment_id":"358739"},{"content":"C is the Answer! D is giving procurement-manager-role to DEVELOPERS!!\nAlthough its not the best practice to apply SCP at root level, but C is the most viable answer for me here.","upvote_count":"3","timestamp":"1635339240.0","comment_id":"350537","poster":"beebatov"},{"comment_id":"344020","timestamp":"1635144060.0","content":"worth checking the Jon Bonso exams as this question is in one of the exam sets and he gives answer A. PowerUserAccess is a IAM default user role for developers https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_job-functions.html","poster":"gsw","upvote_count":"4"},{"poster":"KnightVictor","content":"going with D","timestamp":"1634831580.0","upvote_count":"1","comment_id":"334086"},{"upvote_count":"2","poster":"ExtHo","timestamp":"1634688780.0","content":"Correct Answer is D \nC is out due to \"Create another organization rootlevel\nSCP to deny permissions to create an IAM role named procurement-manager-role to\neveryone in the organization\"\n AWS strongly recommends that you don't attach SCPs to the root of your organization as this may impact the policies on child accounts and possibly lockout key features. You should apply SCPs on the OU level instead to allow finer-grained control of permissions.","comment_id":"327111"},{"timestamp":"1634418120.0","upvote_count":"4","comment_id":"268592","poster":"Ebi","content":"C and D both seems correct, as questions is asking MOST efficient, I will go with C as you don't need to apply SCPs to each account.","comments":[{"timestamp":"1634785080.0","poster":"RedKane","comment_id":"330179","upvote_count":"4","content":"In 'D' SCP with DENY is only applied to SharedServices accounts thus other roles not named \"procurement-manager-role\" in other accounts will be able to administer the marketplace assuming they have attached permissions as DENY rule in SCP does not apply"}]},{"poster":"rkbala","content":"D is correct.","upvote_count":"1","comment_id":"266179","timestamp":"1634268660.0"},{"comment_id":"256053","poster":"vipgcp","content":"C - on \"everyone\" in the organisation means everyone within OU, so that developer will not create role by this name to get privilege access","timestamp":"1634186040.0","upvote_count":"2"},{"timestamp":"1634052660.0","comment_id":"244784","poster":"T14102020","upvote_count":"1","content":"Correct is C. SCP + without giving procurement-manager-role to developers as D."},{"poster":"jackdryan","upvote_count":"3","comment_id":"232496","content":"I'll go with C*","timestamp":"1633936500.0"},{"content":"C is the correct answer.\nin d the SCP is being applied to the shared services account instead of at the OU root.","poster":"cloudgc","comment_id":"231200","timestamp":"1633824240.0","upvote_count":"3"},{"timestamp":"1633809300.0","upvote_count":"2","poster":"CYL","comment_id":"208586","content":"C. SCP is the way to go."},{"upvote_count":"3","poster":"Bulti","content":"C is the answer. The link to the blog provided in this discussion is a good source to confirm that C is the right answer.","comment_id":"205179","timestamp":"1633608600.0"},{"poster":"sam422","upvote_count":"2","comment_id":"185771","timestamp":"1633430640.0","content":"It is D , https://aws.amazon.com/blogs/awsmarketplace/controlling-access-to-a-well-architected-private-marketplace-using-iam-and-aws-organizations/"},{"comment_id":"167188","timestamp":"1632857580.0","upvote_count":"1","content":"i think D","poster":"[Removed]","comments":[{"timestamp":"1633209300.0","comments":[{"poster":"DerekKey","timestamp":"1636058460.0","upvote_count":"1","comment_id":"429161","content":"That's true. \"procurement-manager-role\"+\"will be used by developers\"\nThis is what we want to prevent."}],"content":"D is giving procurement-manager-role to developers . That is an admin role for procurement. Why would a developer need that role just to order something in the private marketplace?","poster":"sk2022","comment_id":"185647","upvote_count":"5"}]},{"comment_id":"158438","timestamp":"1632653520.0","content":"i guess its D","poster":"shakthi000005","upvote_count":"2"},{"poster":"shakthi000005","upvote_count":"1","timestamp":"1632642960.0","content":"C or D","comment_id":"158437"},{"comment_id":"157914","upvote_count":"1","timestamp":"1632498780.0","content":"sorry its D typo.","poster":"Anila_Dhharisi"},{"comment_id":"157910","timestamp":"1632332940.0","poster":"Anila_Dhharisi","upvote_count":"3","content":"yes its C to use SCP to deny permissions"}],"url":"https://www.examtopics.com/discussions/amazon/view/28410-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"2020-08-13 08:11:00","answers_community":["C (78%)","D (22%)"],"answer":"C","answer_ET":"C","choices":{"C":"Create an IAM role named procurement-manager-role in all the shared services accounts in the organization. Add the AWSPrivateMarketplaceAdminFullAccess managed policy to the role. Create an organization root-level SCP to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role. Create another organization root-level SCP to deny permissions to create an IAM role named procurement-manager-role to everyone in the organization.","D":"Create an IAM role named procurement-manager-role in all AWS accounts that will be used by developers. Add the AWSPrivateMarketplaceAdminFullAccess managed policy to the role. Create an SCP in Organizations to deny permissions to administer Private Marketplace to everyone except the role named procurement-manager-role. Apply the SCP to all the shared services accounts in the organization.","A":"Create an IAM role named procurement-manager-role in all AWS accounts in the organization. Add the PowerUserAccess managed policy to the role. Apply an inline policy to all IAM users and roles in every AWS account to deny permissions on the AWSPrivateMarketplaceAdminFullAccess managed policy.","B":"Create an IAM role named procurement-manager-role in all AWS accounts in the organization. Add the AdministratorAccess managed policy to the role. Define a permissions boundary with the AWSPrivateMarketplaceAdminFullAccess managed policy and attach it to all the developer roles."},"unix_timestamp":1597299060,"isMC":true,"topic":"1","answer_description":"","exam_id":32},{"id":"Ccb8R34qEbQmhB1GgIeu","answer_description":"","discussion":[{"upvote_count":"32","poster":"Nemer","comments":[{"comment_id":"366344","upvote_count":"2","poster":"oscargee","content":"DynamoDB is a Key/Value storage. And it fits big data read/write. So it cannot be used in this situation.","timestamp":"1635237780.0","comments":[{"upvote_count":"4","content":"Hmmm.... \"The program is meant to continuously consume millions of tiny records per minute from devices located around the globe.\" If that doesn't say big data read/write than I don't know what is. Also, DynamoDB is perfect for this especially seeing that the 4k value is the limit size.","timestamp":"1636825920.0","poster":"sashenka","comment_id":"477667"}]}],"comment_id":"157061","timestamp":"1632194640.0","content":"B. DynamoDB with TTL, cheaper for sustained throughput of small items + suited for fast retrievals. S3 cheaper for storage only, much higher costs with writes. RDS not designed for this use case."},{"upvote_count":"1","timestamp":"1644036480.0","comment_id":"540780","content":"Selected Answer: B\nOnly B can do it","poster":"kyo"},{"poster":"cannottellname","timestamp":"1643086260.0","content":"BBBBBBBBBBB","comment_id":"531839","upvote_count":"1"},{"upvote_count":"1","comment_id":"514393","poster":"cldy","timestamp":"1641017640.0","content":"B correct."},{"poster":"vbal","upvote_count":"2","comments":[{"comment_id":"509738","content":"I wld say building index have a cost attached which could be offset by adding more items in a batch ...","upvote_count":"1","poster":"vbal","timestamp":"1640542140.0"}],"comment_id":"509732","content":"Answer: D; Anyone who thinks S3 Object Metadata Search is not possible: https://aws.amazon.com/blogs/architecture/swiftly-search-metadata-with-an-amazon-s3-serverless-architecture/","timestamp":"1640541300.0"},{"timestamp":"1638329220.0","content":"B is correct!","comment_id":"491211","poster":"AzureDP900","upvote_count":"1"},{"timestamp":"1638322620.0","comment_id":"491127","upvote_count":"3","content":"Selected Answer: B\nB. DynamoDB with TTL, cheaper for sustained throughput of small items + suited for fast retrievals. S3 cheaper for storage only, much higher costs with writes. RDS not designed for this use case.","poster":"acloudguru"},{"comment_id":"443231","timestamp":"1636126020.0","upvote_count":"1","poster":"andylogan","content":"It's B"},{"poster":"tgv","upvote_count":"1","comment_id":"436165","content":"BBB\n---","timestamp":"1636093020.0"},{"upvote_count":"1","poster":"DerekKey","comment_id":"429170","content":"A & C - wrong\nB - should be correct\nD - I am not aware of the API that you can use to search S3 object using used-defined matadata btw. 1.000 put requests cost 0,005 and PUT request header has limitation for user-defined metadata to 2 KB","comments":[{"comment_id":"462199","poster":"kirrim","upvote_count":"1","timestamp":"1636165020.0","content":"Kendra and ElasticSearch will let you search S3 object metadata, but D sounds to me like they're saying it's a native function of S3 itself, which neither of those are. So I'm not saying D is right, just that other services can do it.\n\nRe: PUT header request with limitation for user-defined metadata to 2KB, that should be OK, you're not storing 4KB data in metadata, you'd be combining multiple 4KB data pieces into a very large flat file. The metadata would only tell you which data pieces are in that very large flat file."}],"timestamp":"1635884520.0"},{"comment_id":"413259","poster":"WhyIronMan","content":"I'll go with B","upvote_count":"2","timestamp":"1635811740.0"},{"content":"B is cost effective compared to C. Also low latency.","timestamp":"1635126180.0","upvote_count":"1","poster":"blackgamer","comment_id":"358767"},{"poster":"Waiweng","upvote_count":"2","content":"it's B","comment_id":"353691","timestamp":"1635082920.0"},{"timestamp":"1634562900.0","poster":"Ajeeshpv","upvote_count":"1","content":"B, millions of input with size less than 4 kb and low latency","comment_id":"310441"},{"content":"going with B","poster":"Kian1","upvote_count":"1","timestamp":"1634270040.0","comment_id":"292959","comments":[{"upvote_count":"1","comment_id":"304694","timestamp":"1634509920.0","content":"I'll go with B, since it's an exam.\nBut I think S3 is pretty cost-effective in this case, though I don't know what \"indexed retrieval\" is.\nAs long as we give enough prefix, I think it may meet the requirement, since S3 has at least\"3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket\".","comments":[{"comments":[{"comment_id":"687510","poster":"tomosabc1","timestamp":"1665034980.0","upvote_count":"1","content":"Thanks for pointing this out."}],"upvote_count":"4","content":"S3 is $5 per million requests, if you have 1 million per minute it's $216,000 per month. Roughly 6x cost of DynamoDB","comment_id":"330206","poster":"RedKane","timestamp":"1635047460.0"}],"poster":"01037"}]},{"timestamp":"1634155560.0","content":"Answer is B\nCost effective, low latency, TTL supports retention","comment_id":"267612","poster":"Ebi","upvote_count":"4"},{"poster":"petebear55","upvote_count":"2","content":"This is in the exam guys !!! answer is B Dynamo db is most suitable in these cases. 'ingest millions of small records per minute from devices all around the world.' D IS RED HERRING","comment_id":"254901","timestamp":"1633906380.0"},{"comments":[{"content":"Good analysis but still RDS is not the way to go for low latency.","comment_id":"258842","timestamp":"1634129100.0","comments":[{"timestamp":"1634165460.0","upvote_count":"2","poster":"kopper2019","content":"so is B the answer Bulti? Thanks","comment_id":"278797"}],"poster":"Bulti","upvote_count":"1"},{"comment_id":"330199","timestamp":"1634887560.0","content":"S3 Calculator (https://calculator.s3.amazonaws.com/index.html) shows $34,228 a month for 4KB items 16667 per second. How did you calculate 6,232.45 USD ??","poster":"RedKane","upvote_count":"1"},{"content":"What does \"A - no value to have small csv in S3 since size limit\" mean?","comment_id":"304693","timestamp":"1634413680.0","poster":"01037","upvote_count":"1"}],"upvote_count":"2","comment_id":"254581","timestamp":"1633845540.0","poster":"Cantaloupe","content":"MOST cost-effective is the key\nA - no value to have small csv in S3 since size limit\nB - might make sense with reserved capacity. but it needs 1 write units for 1kb. Becomes extremely expensive with high throughput. \nhttps://segment.com/blog/the-million-dollar-eng-problem/\nIf not provisioned enough capacity (that is charged even if not used) it's even more expensive\n15,360 GB x 0.25 USD = 3,840.00 USD (Data storage cost) monthly\nMillion of writes per minute =16667 per second = 66,668.00 WCUs = 6,232.45 USD monthly cost of reserved capacity (still not sure this is correct as it seems cheap)\nC - RDS starts to make sense \nit can go up to 80000 IOPS\n15,360 GB x 0.125 USD x 1 instances = 1,920.00 USD (EBS Storage Cost)\n16,667 Provisioned IOPS x 0.10 USD x 1 instances = 1,666.70 USD (EBS IOPS Cost)\n1,920.00 USD + 1,666.70 USD = 3,586.70 USD\nStorage pricing (monthly): 3,586.70 USD\nD - S3 metadata search feature does not exist"},{"timestamp":"1633799460.0","poster":"Britts","upvote_count":"1","comment_id":"250655","content":"Agree with DynamoDB for the following reasons - The application is designed to ingest millions of small records per minute from devices all around the world. Each record is less than 4 KB in size and needs to be stored in a durable location where it can be retrieved with low latency\nS3 will never be able to support it, even though dynamo DB is expensive"},{"timestamp":"1633655400.0","content":"Correct is D. Batching records for minimum cost.","comment_id":"244792","poster":"T14102020","upvote_count":"3"},{"upvote_count":"3","timestamp":"1633496520.0","poster":"jackdryan","content":"I'll go with B","comment_id":"232506"},{"poster":"CYL","upvote_count":"2","timestamp":"1633419720.0","content":"D. Batching records is a way to optimize on cost.","comment_id":"208497"},{"comment_id":"205164","poster":"Bulti","content":"B is the right answer as the record size is small and therefore will be cost effective and provide the much needed performance as stated in the question","timestamp":"1633340520.0","upvote_count":"2"},{"content":"B is right:\nDynamoDB Write request units $1.25 per million write request units (Not so expensive 4KB it will use 4 Writeunits still very cheap)","upvote_count":"1","poster":"sam700","comment_id":"191865","timestamp":"1633313280.0","comments":[{"upvote_count":"1","content":"There is something wrong with B. We are talking of a million records per minute, and you say it is 4 WU. So you pay 1.25$x4WU=5$xminute since you have a million req x minute. So in a day it is 86400 minutes so more than 400K$ per day. It seems a lot, better S3.","timestamp":"1633537200.0","comments":[{"poster":"PAUGURU","upvote_count":"1","comment_id":"237951","timestamp":"1633624980.0","content":"sorry 1440 minutes x day but it's still a lot."},{"content":"Wind OnDemand it's $1.25 per million WCUs a MONTH not a minute.","comment_id":"330193","timestamp":"1634775360.0","comments":[{"content":"Typo - meant to write \"With\" not \"Wind\" ...","timestamp":"1634835240.0","comment_id":"330195","upvote_count":"1","poster":"RedKane"}],"poster":"RedKane","upvote_count":"1"}],"comment_id":"237906","poster":"PAUGURU"}]},{"poster":"Joanale","comment_id":"190958","timestamp":"1633037340.0","content":"Batch is always recommended for this tipe of small records, answer D.","upvote_count":"1"},{"timestamp":"1632849840.0","content":"B, look at the scale to handle the records and TTL","upvote_count":"1","comment_id":"190410","poster":"KhatriRocks"},{"timestamp":"1632789120.0","comment_id":"169700","poster":"Mugger888","upvote_count":"1","content":"The answer would be B, given that DynamoDb is low latency."},{"poster":"b3llman","comment_id":"167330","comments":[{"comment_id":"167337","timestamp":"1632675720.0","content":"The 3.5k adds/s limit applies per S3 prefix. In addition to that, S3 is not designed for low latency retrieval.","poster":"b3llman","upvote_count":"1"}],"upvote_count":"3","timestamp":"1632578400.0","content":"Ans: C (the most cost-effective)\n\nA: an S3 bucket is limited to 3.5k adds per sec\nB. thousands of WCU per sec. This option is extremely expensive\nC. might not look like the best solution but it should work and cheap\nD. same as A and metadata search is not an existing feature"},{"poster":"[Removed]","content":"answer is B","upvote_count":"3","comment_id":"167191","timestamp":"1632350280.0"},{"comment_id":"163759","content":"answer is d","poster":"briantod1970","timestamp":"1632247260.0","upvote_count":"3"}],"answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/28419-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"2020-08-13 09:11:00","question_text":"A solutions architect is designing the data storage and retrieval architecture for a new application that a company will be launching soon. The application is designed to ingest millions of small records per minute from devices all around the world. Each record is less than 4 KB in size and needs to be stored in a durable location where it can be retrieved with low latency. The data is ephemeral and the company is required to store the data for 120 days only, after which the data can be deleted.\nThe solutions architect calculates that, during the course of a year, the storage requirements would be about 10-15 TB.\nWhich storage strategy is the MOST cost-effective and meets the design requirements?","unix_timestamp":1597302660,"answer_images":[],"topic":"1","question_id":592,"choices":{"A":"Design the application to store each incoming record as a single .csv file in an Amazon S3 bucket to allow for indexed retrieval. Configure a lifecycle policy to delete data older than 120 days.","D":"Design the application to batch incoming records before writing them to an Amazon S3 bucket. Update the metadata for the object to contain the list of records in the batch and use the Amazon S3 metadata search feature to retrieve the data. Configure a lifecycle policy to delete the data after 120 days.","C":"Design the application to store each incoming record in a single table in an Amazon RDS MySQL database. Run a nightly cron job that executes a query to delete any records older than 120 days.","B":"Design the application to store each incoming record in an Amazon DynamoDB table properly configured for the scale. Configure the DynamoDB Time to Live (TTL) feature to delete records older than 120 days."},"isMC":true,"exam_id":32,"question_images":[],"answers_community":["B (100%)"],"answer":"B"},{"id":"P0lF4Gu6x3HyQEh7Kkkl","answer_description":"","question_text":"A company provides auction services for artwork and has users across North America and Europe. The company hosts its application in Amazon EC2 instances in the us-east-1 Region. Artists upload photos of their work as large-size, high-resolution image files from their mobile phones to a centralized Amazon S3 bucket created in the us-east-1 Region. The users in Europe are reporting slow performance for their image uploads.\nHow can a solutions architect improve the performance of the image upload process?","question_id":593,"answer":"C","answer_images":[],"timestamp":"2020-08-09 18:59:00","url":"https://www.examtopics.com/discussions/amazon/view/27793-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1596992340,"topic":"1","isMC":true,"answer_ET":"C","choices":{"B":"Create an Amazon CloudFront distribution and point to the application as a custom origin.","D":"Create an Auto Scaling group for the EC2 instances and create a scaling policy.","C":"Configure the buckets to use S3 Transfer Acceleration.","A":"Redeploy the application to use S3 multipart uploads."},"answers_community":["C (100%)"],"exam_id":32,"discussion":[{"poster":"Nemer","upvote_count":"22","comment_id":"157075","timestamp":"1632130020.0","content":"C. Typical S3 Transfer Acceleration use case. Uses CloudFront’s globally distributed edge locations. \nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html\nExclude option A, as only EU customers have latency issues."},{"upvote_count":"6","poster":"Ebi","comment_id":"267615","content":"Definitely C","timestamp":"1634432520.0"},{"comment_id":"497564","upvote_count":"1","timestamp":"1639043820.0","content":"C. Configure the buckets to use S3 Transfer Acceleration.","poster":"cldy"},{"upvote_count":"1","comment_id":"491213","timestamp":"1638329340.0","content":"Transfer acceleration is correct. C is right answer","poster":"AzureDP900"},{"poster":"acloudguru","upvote_count":"1","comment_id":"484750","timestamp":"1637643120.0","content":"Selected Answer: C\nA does not make sense, should be C , to use Transfer acceleration for S3 in different region. hope I can have such easy question in my exam."},{"poster":"andylogan","upvote_count":"1","timestamp":"1636255860.0","content":"It's C","comment_id":"443230"},{"timestamp":"1636087440.0","comment_id":"436166","poster":"tgv","upvote_count":"1","content":"CCC\n---"},{"content":"I'll go with C","timestamp":"1636060860.0","upvote_count":"1","poster":"WhyIronMan","comment_id":"413261"},{"timestamp":"1635730920.0","content":"C is the answer.","comment_id":"358765","upvote_count":"1","poster":"blackgamer"},{"comment_id":"353695","timestamp":"1635672720.0","poster":"Waiweng","content":"it's C","upvote_count":"3"},{"upvote_count":"1","timestamp":"1635578340.0","comment_id":"321747","content":"i go with C","poster":"alisyech"},{"timestamp":"1635566640.0","poster":"Kian1","upvote_count":"3","comment_id":"292971","content":"going with C"},{"comment_id":"254908","upvote_count":"2","content":"This question is very similar to one in teh exam .. where u will be asked to choose two answers ... the other answer is 'upload LARGER images' rather than the (which one would first go for ) smaller images","poster":"petebear55","timestamp":"1633879140.0"},{"poster":"Bulti","timestamp":"1633871520.0","upvote_count":"1","content":"Answer is C.","comment_id":"254289"},{"content":"Correct is C. S3 Transfer Acceleration","poster":"T14102020","timestamp":"1633415040.0","upvote_count":"1","comment_id":"244796"},{"upvote_count":"3","comment_id":"232509","timestamp":"1633239060.0","poster":"jackdryan","content":"I'll go with C"},{"poster":"cloudgc","comment_id":"231223","upvote_count":"1","timestamp":"1633086240.0","content":"C as the performance issue is only in uploading images from Europe."},{"timestamp":"1633030440.0","poster":"oopsy","comment_id":"229577","comments":[{"poster":"Kopa","timestamp":"1636033260.0","comment_id":"406184","content":"origin is application, doesnt make sense.","upvote_count":"1"},{"poster":"HALFHUMAN","comments":[{"content":"\"Up until today, you could use CloudFront to efficiently distribute content from the “center” (the static or dynamic origin) out to the edges, where the customers are located. With today’s release you can also use CloudFront to accelerate the transfer of information from the end-user back to the origin. This has been the top feature request for CloudFront.\", according to https://aws.amazon.com/blogs/aws/amazon-cloudfront-content-uploads-post-put-other-methods/","poster":"wannaaws","timestamp":"1642905600.0","upvote_count":"1","comment_id":"530219"}],"upvote_count":"1","comment_id":"258488","timestamp":"1634147340.0","content":"cloudfront is for improve reading speed not upload"}],"upvote_count":"1","content":"why not cloudfront?"},{"content":"C. Users in US are not meeting the problem. Hence the problem should be related to geographical distances. Hence using S3 Transfer acceleration will be the correct choice.","upvote_count":"3","poster":"CYL","timestamp":"1632918960.0","comment_id":"208501"},{"comment_id":"157918","content":"C is correct.","timestamp":"1632739320.0","upvote_count":"2","poster":"Anila_Dhharisi"}],"question_images":[]},{"id":"5w2N2rzXuGWH0pt4Frwn","topic":"1","exam_id":32,"unix_timestamp":1596990960,"answer":"C","timestamp":"2020-08-09 18:36:00","url":"https://www.examtopics.com/discussions/amazon/view/27790-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"comment_id":"157094","content":"C. CloudFront for the website + game download URL.\n\nAs this a public download that allows anonymous access, option D is excluded.","poster":"Nemer","upvote_count":"16","timestamp":"1632182160.0"},{"timestamp":"1634459820.0","comment_id":"267616","poster":"Ebi","content":"C is the answer","upvote_count":"5"},{"upvote_count":"1","poster":"loopback0","content":"It's C","timestamp":"1665684720.0","comment_id":"694192"},{"upvote_count":"1","timestamp":"1638881220.0","poster":"cldy","comment_id":"495996","content":"C. Configure Amazon Route 53 and an Amazon S3 bucket for website hosting. Upload the game files to the S3 bucket. Use Amazon CloudFront for the website. Publish the game download URL for users to download the package."},{"timestamp":"1638329580.0","content":"C is right","upvote_count":"1","comment_id":"491216","poster":"AzureDP900"},{"timestamp":"1635812100.0","upvote_count":"1","content":"It's C","comment_id":"443229","poster":"andylogan"},{"comment_id":"436172","content":"CCC\n---","upvote_count":"1","timestamp":"1635525780.0","poster":"tgv"},{"timestamp":"1635392880.0","poster":"mericov","upvote_count":"1","comment_id":"415207","content":"C ->\nhttps://aws.amazon.com/blogs/aws/amazon-cloudfront-support-for-20-gb-objects/"},{"upvote_count":"1","poster":"WhyIronMan","comment_id":"413263","content":"I'll go with C","timestamp":"1635230460.0"},{"content":"C, cloudfront more cost effective","poster":"Kopa","comment_id":"406191","upvote_count":"1","timestamp":"1635042000.0"},{"content":"it's C","upvote_count":"3","timestamp":"1634658720.0","poster":"Waiweng","comment_id":"353697"},{"poster":"Kian1","timestamp":"1634532240.0","upvote_count":"2","content":"going with C","comment_id":"292972"},{"content":"answer is C.","comment_id":"254295","timestamp":"1634010600.0","poster":"Bulti","upvote_count":"1"},{"content":"D reduces the transfer costs","comment_id":"246160","poster":"srinivasa","timestamp":"1633793880.0","upvote_count":"1","comments":[{"timestamp":"1633954320.0","comments":[{"upvote_count":"1","content":"but c where your coming from","poster":"petebear55","timestamp":"1634293980.0","comment_id":"254917"}],"upvote_count":"2","poster":"darthvoodoo","comment_id":"251702","content":"D is not feasible because users are expected to have AWS accounts to absorb the download cost."}]},{"poster":"T14102020","timestamp":"1632785880.0","upvote_count":"1","comment_id":"244799","content":"Correct is C. CloudFront"},{"upvote_count":"3","content":"I'll go with C","poster":"jackdryan","timestamp":"1632776580.0","comment_id":"232512"},{"upvote_count":"1","comment_id":"208505","timestamp":"1632684780.0","poster":"CYL","content":"C. Since users are from worldwide, using cloudfront as a CDN will help to improve speed of download. Moreover, the game file is likely the same content for each user who does the download."},{"content":"yes its C.","upvote_count":"3","comment_id":"157920","timestamp":"1632411780.0","poster":"Anila_Dhharisi"}],"choices":{"D":"Configure Amazon Route 53 and an Amazon S3 bucket for website hosting. Upload the game files to the S3 bucket. Set Requester Pays for the S3 bucket. Publish the game download URL for users to download the package.","C":"Configure Amazon Route 53 and an Amazon S3 bucket for website hosting. Upload the game files to the S3 bucket. Use Amazon CloudFront for the website. Publish the game download URL for users to download the package.","A":"Store the game files on Amazon EBS volumes mounted on Amazon EC2 instances within an Auto Scaling group. Configure an FTP service on the EC2 instances. Use an Application Load Balancer in front of the Auto Scaling group. Publish the game download URL for users to download the package.","B":"Store the game files on Amazon EFS volumes that are attached to Amazon EC2 instances within an Auto Scaling group. Configure an FTP service on each of the EC2 instances. Use an Application Load Balancer in front of the Auto Scaling group. Publish the game download URL for users to download the package."},"answers_community":[],"question_images":[],"answer_ET":"C","question_id":594,"answer_images":[],"answer_description":"","isMC":true,"question_text":"A company has developed a new release of a popular video game and wants to make it available for public download. The new release package is approximately\n5 GB in size. The company provides downloads for existing releases from a Linux-based, publicly facing FTP site hosted in an on-premises data center. The company expects the new release will be downloaded by users worldwide. The company wants a solution that provides improved download performance and low transfer costs, regardless of a user's location.\nWhich solutions will meet these requirements?"},{"id":"ExNHDhzUlykAQQmuTelT","url":"https://www.examtopics.com/discussions/amazon/view/46421-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"A":"A blue/green deployment","C":"A canary deployment","B":"A linear deployment","D":"An all-at-once deployment"},"answer_images":[],"isMC":true,"answer":"C","question_text":"A new startup is running a serverless application using AWS Lambda as the primary source of compute. New versions of the application must be made available to a subset of users before deploying changes to all users. Developers should also have the ability to abort the deployment and have access to an easy rollback\n\nmechanism. A solutions architect decides to use AWS CodeDeploy to deploy changes when a new version is available.\nWhich CodeDeploy configuration should the solutions architect use?","topic":"1","timestamp":"2021-03-11 16:38:00","unix_timestamp":1615477080,"answer_description":"","question_id":595,"exam_id":32,"answer_ET":"C","answers_community":["C (100%)"],"question_images":[],"discussion":[{"timestamp":"1678633020.0","content":"Selected Answer: C\nsubset of users -> canary\n\nALWAYS\n\nCCCCC","poster":"milofficial","upvote_count":"1","comment_id":"837132"},{"timestamp":"1672259280.0","comment_id":"760300","upvote_count":"1","poster":"evargasbrz","content":"Selected Answer: C\nLambda deployment modes only: canary, linear, all, so C is the right answer."},{"upvote_count":"1","comments":[{"content":"Only these predefined deployment configurations are available for AWS Lambda compute platform:\nCanary: Traffic is shifted in two increments. You can choose from predefined canary options. The options specify the percentage of traffic that's shifted to your updated Lambda function version in the first increment, and the interval, in minutes, before the remaining traffic is shifted in the second increment.\n\nLinear: Traffic is shifted in equal increments with an equal number of minutes between each increment. You can choose from predefined linear options that specify the percentage of traffic that's shifted in each increment and the number of minutes between each increment.\n\nAllAtOnce: All traffic is shifted from the original Lambda function to the updated Lambda function version at once.\n\nTherefore, Blue/Green is not a valid answer here.\n\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html#deployment-configuration-lambda","comment_id":"717677","upvote_count":"1","poster":"et22s","timestamp":"1668397500.0"}],"timestamp":"1667989200.0","poster":"Heer","comment_id":"714466","content":"Why are we not considering the following points:\n1)Its a new version of 'COMPLETE APPLICATION' .\n2)We have to release it to subset of users (i.2 using Route53 we can have this distribution )\n3)Rollback is available in Blue/green also \n\nThe right answers is A ,Blue/Green Deployment \n\njust read this for more clarification:\nCanary deployment works similarly to blue-green deployment, but uses a slightly different method. Instead of another full environment waiting to be switched over once deployment is finished, canary deployments cut over just a small subset of servers or nodes first, before finishing the others."},{"comment_id":"694926","timestamp":"1665767460.0","poster":"Blair77","upvote_count":"2","content":"Selected Answer: C\nC for Canary !!! Let's go!"},{"comment_id":"637340","poster":"CloudHandsOn","timestamp":"1658832540.0","content":"C.\n\"..subset of users.\" <- Canary is the job for this","upvote_count":"3"},{"timestamp":"1646658480.0","content":"Selected Answer: C\nC: https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html","poster":"gorodetsky","comments":[{"upvote_count":"1","content":"This is the key \"program must be made accessible to a subset of users\"","timestamp":"1654414320.0","poster":"Chuky64","comment_id":"611713"}],"upvote_count":"2","comment_id":"562635"},{"poster":"GeniusMikeLiu","content":"why not A? blue/green also support rollback /","timestamp":"1642677780.0","comments":[{"comment_id":"656534","poster":"kadev","upvote_count":"2","content":"because it's a concept defined by AWS. lambda deployment modes only: canary, linear, all","timestamp":"1662056220.0"}],"upvote_count":"1","comment_id":"528365"},{"comment_id":"497704","poster":"cldy","content":"C. A canary deployment","timestamp":"1639052280.0","upvote_count":"1"},{"comment_id":"491218","poster":"AzureDP900","timestamp":"1638329700.0","upvote_count":"1","content":"C is correct answer"},{"upvote_count":"1","poster":"pcops","content":"C: new versions of the program must be made accessible to a subset of users. Definition of canary deployment - A canary deployment, or canary release, is a deployment pattern that allows you to roll out new code/features to a subset of users as an initial test","timestamp":"1637805720.0","comment_id":"486371"},{"content":"It's C","timestamp":"1636205820.0","comment_id":"443228","poster":"andylogan","upvote_count":"1"},{"poster":"tgv","timestamp":"1634830860.0","upvote_count":"1","comment_id":"436173","content":"CCC\n---"},{"content":"I'll go with C","poster":"WhyIronMan","comment_id":"413267","upvote_count":"1","timestamp":"1634565780.0"},{"comment_id":"406198","timestamp":"1634124360.0","content":"Its C since at serverless application ECS we can use canary.","upvote_count":"1","poster":"Kopa"},{"poster":"blackgamer","content":"It is C, Canary deployment.","comment_id":"358773","timestamp":"1633645620.0","upvote_count":"2"},{"comment_id":"353705","upvote_count":"4","timestamp":"1633464660.0","content":"it's A, sorry Codedeploy on use blue/green deployment for lambda","comments":[{"content":"C is the Answer: https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html.\nQuestion is about Deployment configuration.","upvote_count":"3","poster":"surekye","comment_id":"369609","timestamp":"1634096880.0"}],"poster":"Waiweng"},{"content":"it's C","comment_id":"353700","poster":"Waiweng","timestamp":"1633347780.0","upvote_count":"4"},{"content":"would go with C","upvote_count":"1","timestamp":"1633166040.0","poster":"KnightVictor","comment_id":"334090"},{"poster":"nitinz","timestamp":"1632652320.0","comment_id":"322225","content":"C is correct answer.","upvote_count":"1"},{"upvote_count":"3","timestamp":"1632623580.0","poster":"Ajeeshpv","comment_id":"310456","content":"C , subset of users"},{"comment_id":"309868","timestamp":"1632335220.0","content":"C\nCanary deployment will give access to subset of users","upvote_count":"1","poster":"sek12324"},{"upvote_count":"3","content":"A\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/deployments.html","poster":"kalyan_krishna742020","comment_id":"308001","comments":[{"comment_id":"369608","timestamp":"1633972860.0","poster":"surekye","upvote_count":"2","content":"C is the Answer: https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html. \nQuestion is about Deployment configuration."}],"timestamp":"1632200400.0"}]}],"exam":{"isMCOnly":false,"lastUpdated":"11 Apr 2025","isBeta":false,"name":"AWS Certified Solutions Architect - Professional","numberOfQuestions":1019,"isImplemented":true,"provider":"Amazon","id":32},"currentPage":119},"__N_SSP":true}