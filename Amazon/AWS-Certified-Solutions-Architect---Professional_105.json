{"pageProps":{"questions":[{"id":"LrT1r3MOE68rAj1qUc07","choices":{"D":"Use an IAM user with access credentials assigned a role providing access to the Score Data DynamoDB table and the Game State S3 bucket for distribution with the mobile app.","C":"Use Login with Amazon allowing users to sign in with an Amazon account providing the mobile app with access to the Score Data DynamoDB table and the Game State S3 bucket.","B":"Use temporary security credentials that assume a role providing access to the Score Data DynamoDB table and the Game State S3 bucket using web identity federation.","A":"Use an EC2 Instance that is launched with an EC2 role providing access to the Score Data DynamoDB table and the GameState S3 bucket that communicates with the mobile app via web services."},"answer_description":"Web Identity Federation -\nImagine that you are creating a mobile app that accesses AWS resources, such as a game that runs on a mobile device and stores player and score information using Amazon S3 and DynamoDB.\nWhen you write such an app, you'll make requests to AWS services that must be signed with an AWS access key. However, we strongly recommend that you do not embed or distribute long-term AWS credentials with apps that a user downloads to a device, even in an encrypted store. Instead, build your app so that it requests temporary AWS security credentials dynamically when needed using web identity federation. The supplied temporary credentials map to an AWS role that has only the permissions needed to perform the tasks required by the mobile app.\nWith web identity federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well- known identity provider (IdP) ג€\"such as Login with Amazon, Facebook, Google, or any other\nOpenID Connect (OIDC)\n-compatible IdP, receive an authentication\ntoken, and then exchange that token for temporary security credentials in AWS that map to an IAM role with permissions to use the resources in your AWS account. Using an IdP helps you keep your AWS account secure, because you don't have to embed and distribute long-term security credentials with your application.\nFor most scenarios, we recommend that you use\n\nAmazon Cognito -\nbecause it acts as an identity broker and does much of the federation work for you. For details, see the following section,\nUsing Amazon Cognito for Mobile Apps\n.\nIf you don't use Amazon Cognito, then you must write code that interacts with a web IdP (Login with Amazon, Facebook, Google, or any other OIDC-compatible\nIdP) and then calls the AssumeRoleWithWebIdentity API to trade the authentication token you get from those IdPs for AWS temporary security credentials. If you have already used this approach for existing apps, you can continue to use it.\nUsing Amazon Cognito for Mobile Apps\nThe preferred way to use web identity federation is to use\n\nAmazon Cognito -\n. For example, Adele the developer is building a game for a mobile device where user data such as scores and profiles is stored in Amazon S3 and Amazon DynamoDB. Adele could also store this data locally on the device and use Amazon Cognito to keep it synchronized across devices. She knows that for security and maintenance reasons, long-term AWS security credentials should not be distributed with the game. She also knows that the game might have a large number of users. For all of these reasons, she does not want to create new user identities in IAM for each player. Instead, she builds the game so that users can sign in using an identity that they've already established with a well-known identity provider, such as\nLogin with Amazon, Facebook, Google, or any OpenID Connect (OIDC)-compatible identity provider. Her game can take advantage of the authentication mechanism from one of these providers to validate the user's identity.\nTo enable the mobile app to access her AWS resources, Adele first registers for a developer ID with her chosen IdPs. She also configures the application with each of these providers. In her AWS account that contains the Amazon S3 bucket and DynamoDB table for the game, Adele uses Amazon Cognito to create IAM roles that precisely define permissions that the game needs. If she is using an OIDC IdP, she also creates an IAM OIDC identity provider entity to establish trust between her AWS account and the IdP.\nIn the app's code, Adele calls the sign-in interface for the IdP that she configured previously. The IdP handles all the details of letting the user sign in, and the app gets an OAuth access token or OIDC ID token from the provider. Adele's app can trade this authentication information for a set of temporary security credentials that consist of an AWS access key ID, a secret access key, and a session token. The app can then use these credentials to access web services offered by AWS.\nThe app is limited to the permissions that are defined in the role that it assumes.\nThe following figure shows a simplified flow for how this might work, using Login with Amazon as the IdP. For Step 2, the app can also use Facebook, Google, or any OIDC-compatible identity provider, but that's not shown here.\nSample workflow using Amazon Cognito to federate users for a mobile application\n\nA customer starts your app on a mobile device. The app asks the user to sign in.\nThe app uses Login with Amazon resources to accept the user's credentials.\nThe app uses Cognito APIs to exchange the Login with Amazon ID token for a Cognito token.\nThe app requests temporary security credentials from AWS STS, passing the Cognito token.\nThe temporary security credentials can be used by the app to access any AWS resources required by the app to operate. The role associated with the temporary security credentials and its assigned policies determines what can be accessed.\nUse the following process to configure your app to use Amazon Cognito to authenticate users and give your app access to AWS resources. For specific steps to accomplish this scenario, consult the documentation for Amazon Cognito.\n(Optional) Sign up as a developer with Login with Amazon, Facebook, Google, or any other OpenID Connect (OIDC)ג€\"compatible identity provider and configure one or more apps with the provider. This step is optional because Amazon Cognito also supports unauthenticated (guest) access for your users.\n\nGo to -\nAmazon Cognito in the AWS Management Console\n. Use the Amazon Cognito wizard to create an identity pool, which is a container that Amazon Cognito uses to keep end user identities organized for your apps. You can share identity pools between apps. When you set up an identity pool, Amazon Cognito creates one or two IAM roles (one for authenticated identities, and one for unauthenticated \"guest\" identities) that define permissions for Amazon Cognito users.\n\nDownload and integrate the -\n\nAWS SDK for iOS -\nor the\n\nAWS SDK for Android -\nwith your app, and import the files required to use Amazon Cognito.\nCreate an instance of the Amazon Cognito credentials provider, passing the identity pool ID, your AWS account number, and the Amazon Resource Name (ARN) of the roles that you associated with the identity pool. The Amazon Cognito wizard in the AWS Management Console provides sample code to help you get started.\nWhen your app accesses an AWS resource, pass the credentials provider instance to the client object, which passes temporary security credentials to the client.\nThe permissions for the credentials are based on the role or roles that you defined earlier.","exam_id":32,"question_images":[],"timestamp":"2021-04-01 06:56:00","answer":"B","answer_ET":"B","topic":"1","unix_timestamp":1617252960,"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/48614-exam-aws-certified-solutions-architect-professional-topic-1/","question_id":521,"discussion":[{"poster":"cldy","content":"B.\nWeb Identity Federation is the right way to store data in DynamoDB & S3 using existing social identities.","comment_id":"325512","upvote_count":"6","timestamp":"1632952800.0"},{"upvote_count":"1","poster":"amministrazione","comment_id":"1266649","timestamp":"1723751460.0","content":"B. Use temporary security credentials that assume a role providing access to the Score Data DynamoDB table and the Game State S3 bucket using web identity federation."},{"upvote_count":"1","comment_id":"927759","content":"Selected Answer: B\nkeyword = web identity federation.","timestamp":"1687195680.0","poster":"SkyZeroZx"},{"poster":"rtguru","upvote_count":"1","comment_id":"902001","content":"Selected Answer: B\nSince users will log into game using their social media a/cs, B is the right answer. It allows Identity federation","timestamp":"1684505520.0"},{"comment_id":"349107","poster":"01037","timestamp":"1635822720.0","content":"B for sure","upvote_count":"1"},{"upvote_count":"1","poster":"Malcnorth59","timestamp":"1634077920.0","content":"B. Is the answer","comment_id":"340758"},{"poster":"M_Asep","upvote_count":"1","timestamp":"1633338780.0","comment_id":"328852","content":"B definately"}],"question_text":"Company B is launching a new game app for mobile devices. Users will log into the game using their existing social media account to streamline data capture.\nCompany B would like to directly save player data and scoring information from the mobile app to a DynamoDS table named Score Data When a user saves their game the progress data will be stored to the Game state S3 bucket.\nWhat is the best approach for storing data to DynamoDB and S3?","answer_images":["https://www.examtopics.com/assets/media/exam-media/04241/0005500001.jpg"],"isMC":true},{"id":"FR3qHk0f0v08KXX9AEGI","isMC":true,"exam_id":32,"discussion":[{"upvote_count":"19","timestamp":"1635733080.0","poster":"wasabidev","comment_id":"320087","content":"A, now Amazon Route 53 supports DNSSEC for domain registration as well as DNSSEC signing"},{"content":"Answer: D","upvote_count":"8","timestamp":"1633829280.0","comment_id":"87819","comments":[{"poster":"hilft","upvote_count":"1","timestamp":"1658972520.0","comment_id":"638382","content":"A better"}],"poster":"Mkumar"},{"timestamp":"1654795200.0","poster":"ravisar","upvote_count":"2","content":"The answer is A - https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-configure-dnssec.html \"You can protect your domain from this type of attack, known as DNS spoofing or a man-in-the-middle attack, by configuring Domain Name System Security Extensions (DNSSEC), a protocol for securing DNS traffic\"","comment_id":"614122"},{"content":"Selected Answer: A\nSeems to be A.\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-configuring-dnssec.html","upvote_count":"2","timestamp":"1653641820.0","comment_id":"608002","poster":"bobsmith2000"},{"upvote_count":"2","content":"Selected Answer: A\nAnswer is A. Bind is not good. CLB is wrong. ACM's SSL certificate cannot use in EC2 instance.","timestamp":"1644033120.0","poster":"kyo","comment_id":"540760"},{"content":"Agree its A. See link https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-configure-dnssec.html","upvote_count":"1","timestamp":"1641934140.0","poster":"Ni_yot","comment_id":"521763"},{"upvote_count":"1","content":"A correct.","timestamp":"1641015660.0","comment_id":"514388","poster":"cldy"},{"comment_id":"497780","content":"A. Use Amazon Route 53 for domain registration and DNS services. Enable DNSSEC for all Route 53 requests. Use AWS Certificate Manager (ACM) to register TLS/SSL certificates for the shopping website, and use Application Load Balancers configured with those TLS/SSL certificates for the site. Use the Server Name Identification extension in all client requests to the site.","upvote_count":"1","timestamp":"1639058820.0","poster":"cldy"},{"comment_id":"433226","poster":"denccc","timestamp":"1636202640.0","content":"It's A","upvote_count":"1"},{"upvote_count":"3","comment_id":"411634","content":"I'll go with D","timestamp":"1636184220.0","poster":"WhyIronMan"},{"comment_id":"349134","content":"it's A","timestamp":"1636169220.0","poster":"Waiweng","upvote_count":"4"},{"comment_id":"347416","poster":"blackgamer","upvote_count":"1","timestamp":"1636149540.0","content":"A for me"},{"timestamp":"1635968160.0","upvote_count":"3","poster":"BloodCube","comment_id":"339303","content":"After June 2021, the answer is A\nBefore that, D is correct."},{"timestamp":"1635792000.0","comment_id":"337493","content":"A, as now AWS supports DNSSEC on its own.","upvote_count":"3","poster":"Amitv2706"},{"content":"Answer is D since R53 started supporting DNSSEC since last December 2020 which is not over 6 months yet.","timestamp":"1635771600.0","poster":"kalyan_krishna742020","comment_id":"325481","upvote_count":"3"},{"timestamp":"1635408900.0","content":"With very recent announcement from AWS answer should be A:\nhttps://aws.amazon.com/about-aws/whats-new/2020/12/announcing-amazon-route-53-support-dnssec/","comment_id":"277696","upvote_count":"7","poster":"Ebi"},{"upvote_count":"3","poster":"01037","timestamp":"1635213840.0","comment_id":"261420","content":"A.\nOld question?\nAccording to\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-configure-dnssec.html\nAmazon Route 53 supports DNSSEC for domain registration as well as DNSSEC signing"},{"content":"would go for A with this new functionality(Dec 2020) where Route 53 provides DNSSEC","upvote_count":"5","timestamp":"1635207900.0","poster":"njthomas","comment_id":"256076"},{"comment_id":"256075","content":"https://aws.amazon.com/about-aws/whats-new/2020/12/announcing-amazon-route-53-support-dnssec/","timestamp":"1635004080.0","upvote_count":"1","poster":"njthomas"},{"upvote_count":"1","timestamp":"1634979660.0","content":"Both C and D are partially incorrect, however will choose C over D as you can't use ACM to generate the certificate as it doesn't support 2048 bit encryption needed for DNSSEC support.","comment_id":"250922","poster":"Britts"},{"comment_id":"243933","poster":"T14102020","content":"Correct is D. EC2 instances running Bind.","timestamp":"1634940600.0","upvote_count":"1"},{"content":"I'll go with D","comment_id":"231569","upvote_count":"3","timestamp":"1634721660.0","poster":"jackdryan"},{"upvote_count":"2","comment_id":"133444","content":"D, Dup of Q151","poster":"NikkyDicky","timestamp":"1634597640.0"},{"upvote_count":"2","comment_id":"106001","content":"Correct answer is D\n\nAmazon Route 53 supports DNSSEC for domain registration. However, Route 53 does not support DNSSEC for DNS service, regardless of whether the domain is registered with Route 53. If you want to configure DNSSEC for a domain that is registered with Route 53, you must either use another DNS service provider or set up your own DNS server.\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-configure-dnssec.html","poster":"nxt_RTX5","timestamp":"1634546700.0"},{"content":"Option D makes more sense.","poster":"meenu2225","timestamp":"1634304600.0","upvote_count":"2","comment_id":"104838"},{"timestamp":"1634267760.0","poster":"FreeSwan","content":"D is correct.","upvote_count":"2","comment_id":"94320"},{"upvote_count":"5","poster":"nil12","content":"Answer D. Classic LB doesn't support SNI certs.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/acm-add-domain-certificates-elb/","timestamp":"1634249280.0","comment_id":"89416"},{"comment_id":"84843","timestamp":"1633801560.0","upvote_count":"4","content":"D， CLB is not supported for https SNI.","poster":"zgydmy"},{"content":"I meant B","poster":"AmazonAu","comment_id":"82566","upvote_count":"1","timestamp":"1633725420.0"},{"upvote_count":"2","comment_id":"82565","timestamp":"1633551600.0","content":"C\nImportant\n\nAmazon Route 53 supports DNSSEC for domain registration. However, Route 53 does not support DNSSEC for DNS service, regardless of whether the domain is registered with Route 53. If you want to configure DNSSEC for a domain that is registered with Route 53, you must either use another DNS service provider or set up your own DNS server.","poster":"AmazonAu"},{"upvote_count":"1","comment_id":"68979","content":"This is a replication of Question #151Topic 2","poster":"LunchTime","timestamp":"1632908340.0"},{"comment_id":"68837","poster":"zgydmy","timestamp":"1632557760.0","upvote_count":"2","content":"C，ACM only be used to API Gateway, ELB and Cloudfront."},{"comment_id":"67861","content":"B\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-configure-dnssec.html","upvote_count":"1","poster":"Asds","timestamp":"1632362100.0"}],"question_id":522,"topic":"1","timestamp":"2020-03-24 20:35:00","url":"https://www.examtopics.com/discussions/amazon/view/17372-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"C":"Use Route 53 for domain registration. Register 2048-bit encryption keys from a third-party certificate service. Use a third-party DNS service that supports DNSSEC for DNS requests that use the customer managed keys. Import the customer managed keys to ACM to deploy the certificates to Classic Load Balancers configured with those TLS/SSL certificates for the site. Use the Server Name Identification extension in all clients requests to the site.","A":"Use Amazon Route 53 for domain registration and DNS services. Enable DNSSEC for all Route 53 requests. Use AWS Certificate Manager (ACM) to register TLS/SSL certificates for the shopping website, and use Application Load Balancers configured with those TLS/SSL certificates for the site. Use the Server Name Identification extension in all client requests to the site.","B":"Register 2048-bit encryption keys from a third-party certificate service. Use a third-party DNS provider that uses the customer managed keys for DNSSec. Upload the keys to ACM, and use ACM to automatically deploy the certificates for secure web services to an EC2 front-end web server fleet by using NGINX. Use the Server Name Identification extension in all client requests to the site.","D":"Use Route 53 for domain registration, and host the company DNS root servers on Amazon EC2 instances running Bind. Enable DNSSEC for DNS requests. Use ACM to register TLS/SSL certificates for the shopping website, and use Application Load Balancers configured with those TLS/SSL certificates for the site. Use the Server Name Identification extension in all client requests to the site."},"answer_description":"","answer_ET":"A","answer":"A","answers_community":["A (100%)"],"answer_images":[],"question_images":[],"question_text":"A company wants to launch an online shopping website in multiple countries and must ensure that customers are protected against potential `man-in-the-middle` attacks.\nWhich architecture will provide the MOST secure site access?","unix_timestamp":1585078500},{"id":"HdjOABbcl6GHolLCKEfS","timestamp":"2020-03-28 21:25:00","question_text":"A company is creating an account strategy so that they can begin using AWS. The Security team will provide each team with the permissions they need to follow the principle or least privileged access. Teams would like to keep their resources isolated from other groups, and the Finance team would like each team's resource usage separated for billing purposes.\nWhich account creation process meets these requirements and allows for changes?","discussion":[{"poster":"Ebi","upvote_count":"12","comment_id":"277695","timestamp":"1634689500.0","content":"D is the answer"},{"upvote_count":"5","timestamp":"1634391180.0","content":"Answer is D. AWS organization, separation of accounts by function is a standard AWS best practice when it comes to account creation.","comment_id":"253005","poster":"Bulti"},{"content":"Selected Answer: D\nA) Sounds Good until say use Active Directory is more overhead\nB) Create individuals accounts without AWS Organizations is incorrect\nC) use third-party billing solution when exist currently AWS Organization with billing consolitation is incorrect\nD) Is correct use AWS Organization SCP and Cross Account roles","comment_id":"941064","timestamp":"1688315220.0","poster":"SkyZeroZx","upvote_count":"2"},{"comment_id":"676522","poster":"Naj_64","timestamp":"1663875360.0","comments":[{"timestamp":"1665817140.0","poster":"Vinafec","upvote_count":"3","comment_id":"695238","content":"You don't have to enable consolidated billing"}],"upvote_count":"4","content":"How does D satisfies \"Finance team would like each team's resource usage separated for billing purposes.\"?"},{"timestamp":"1644358500.0","poster":"jj22222","upvote_count":"1","comment_id":"543372","content":"D. Create a master account for billing using Organizations, and create each teamג€™s account from that master account. Create a security account for logs and cross-account access. Apply service control policies on each account, and grant the Security team cross-account access to all accounts. Security will create IAM policies for each account to maintain least privilege access."},{"upvote_count":"1","content":"Selected Answer: D\nD: AWS Organizations is the best solution","comment_id":"539654","poster":"kyo","timestamp":"1643888700.0"},{"poster":"cannottellname","comment_id":"526917","upvote_count":"1","content":"Selected Answer: D\nD is correct","timestamp":"1642530480.0"},{"upvote_count":"1","poster":"Ni_yot","timestamp":"1641223680.0","comment_id":"515871","content":"D for me."},{"upvote_count":"1","comment_id":"514343","timestamp":"1641009540.0","content":"D correct.","poster":"cldy"},{"content":"D is the best answer","upvote_count":"1","poster":"AzureDP900","timestamp":"1638741720.0","comment_id":"494711"},{"timestamp":"1636981980.0","comment_id":"478678","upvote_count":"1","content":"D is the answer","poster":"ryu10_09"},{"poster":"CloudChef","comment_id":"413928","content":"A) Reason/ Require each team to tag their resources, and separate bills based on tags.","upvote_count":"4","timestamp":"1636151760.0"},{"poster":"WhyIronMan","upvote_count":"2","comment_id":"411636","timestamp":"1635828780.0","content":"I'll go with D"},{"comment_id":"349298","content":"it is D","timestamp":"1635712320.0","poster":"Waiweng","upvote_count":"2"},{"timestamp":"1635505140.0","upvote_count":"1","content":"D is the answer.","poster":"blackgamer","comment_id":"347466"},{"poster":"T14102020","upvote_count":"1","comment_id":"243942","content":"Correct is D. master account","timestamp":"1634376240.0"},{"content":"I'll go with D","timestamp":"1634219400.0","poster":"jackdryan","upvote_count":"3","comment_id":"231571"},{"comment_id":"209612","poster":"CYL","upvote_count":"1","timestamp":"1634052780.0","content":"D. Use SCP to control organizational level policies."},{"comment_id":"203531","poster":"angarc","timestamp":"1633522140.0","upvote_count":"1","content":"For me Answer is D too."},{"timestamp":"1633506960.0","upvote_count":"2","poster":"NikkyDicky","comment_id":"133446","content":"D. Dup of Q152"},{"comment_id":"104840","timestamp":"1632491040.0","poster":"meenu2225","upvote_count":"3","content":"D is the answer"},{"comment_id":"94327","content":"D is correct","upvote_count":"3","poster":"FreeSwan","timestamp":"1632472980.0"},{"content":"Answer: D","timestamp":"1632068760.0","poster":"Mkumar","upvote_count":"4","comment_id":"87820"},{"upvote_count":"2","content":"This is a replication of Question #152Topic 2","comment_id":"68980","poster":"LunchTime","timestamp":"1632068280.0"}],"isMC":true,"answer_images":[],"question_id":523,"answer_ET":"D","choices":{"A":"Create a new AWS Organizations account. Create groups in Active Directory and assign them to roles in AWS to grant federated access. Require each team to tag their resources, and separate bills based on tags. Control access to resources through IAM granting the minimally required privilege.","B":"Create individual accounts for each team. Assign the security account as the master account, and enable consolidated billing for all other accounts. Create a cross-account role for security to manage accounts, and send logs to a bucket in the security account.","C":"Create a new AWS account, and use AWS Service Catalog to provide teams with the required resources. Implement a third-party billing solution to provide the Finance team with the resource use for each team based on tagging. Isolate resources using IAM to avoid account sprawl. Security will control and monitor logs and permissions.","D":"Create a master account for billing using Organizations, and create each team's account from that master account. Create a security account for logs and cross-account access. Apply service control policies on each account, and grant the Security team cross-account access to all accounts. Security will create IAM policies for each account to maintain least privilege access."},"question_images":[],"unix_timestamp":1585427100,"answer_description":"","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/17612-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"answer":"D","answers_community":["D (100%)"]},{"id":"yAFAMveExQI1cn75a7nu","answer":"C","topic":"1","discussion":[{"comment_id":"277704","timestamp":"1634946180.0","poster":"Ebi","upvote_count":"12","content":"C is the answer, \nwith 50Mbps connection only around 11TB can be transferred in 3 weeks, so 24TB of data must be transferred differently which is Snowball in this case"},{"timestamp":"1632141660.0","poster":"jay1ram2","comment_id":"65328","upvote_count":"7","content":"The Correct Answer is C"},{"timestamp":"1688315340.0","poster":"SkyZeroZx","content":"Selected Answer: C\nCorrect is C. snowball + without of premise offline","upvote_count":"1","comment_id":"941068"},{"comment_id":"622147","timestamp":"1656164760.0","upvote_count":"1","poster":"skyblue07","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MySQL.Procedural.Importing.NonRDSRepl.html"},{"comment_id":"498440","poster":"cldy","content":"C. 1. Create a database export locally using database-native tools. 2. Import that into AWS using AWS Snowball. 3. Launch an Amazon RDS Aurora DB instance. 4. Load the data in the RDS Aurora DB instance from the export. 5. Set up database replication from the on-premises database to the RDS Aurora DB instance over the VPN. 6. Change the DNS entry to point to the RDS Aurora DB instance. 7. Stop the replication.","upvote_count":"1","timestamp":"1639126680.0"},{"content":"C is right answer!","timestamp":"1638742980.0","comment_id":"494716","upvote_count":"1","poster":"AzureDP900"},{"poster":"Goram113","content":"Now DMS can use snowball for entry synchronization and it would be best answer, but in available options C is best.","upvote_count":"2","comment_id":"441796","timestamp":"1636168560.0"},{"upvote_count":"1","comment_id":"411639","timestamp":"1635844740.0","poster":"WhyIronMan","content":"I'll go with C"},{"upvote_count":"3","comment_id":"349303","timestamp":"1635679080.0","content":"it's C","poster":"Waiweng"},{"timestamp":"1635053760.0","content":"C is correct and D required at least 1 week downtime.","upvote_count":"2","poster":"ExtHo","comment_id":"325438"},{"comment_id":"321762","content":"C is correct","upvote_count":"1","poster":"alisyech","timestamp":"1635005520.0"},{"content":"Correct is C. snowball + without of premise offline","comment_id":"243945","timestamp":"1634719500.0","poster":"T14102020","upvote_count":"3"},{"poster":"jackdryan","content":"I'll go with C","comment_id":"231575","timestamp":"1634448120.0","upvote_count":"1"},{"content":"C is the answer as soon as you see 25TB over a 25mb links no way.... based on torrent leeching experience :)","comment_id":"215662","upvote_count":"1","timestamp":"1634394360.0","poster":"kopper2019"},{"content":"C. D requires downtime.","upvote_count":"1","timestamp":"1634348640.0","comment_id":"209613","poster":"CYL"},{"comment_id":"133448","content":"C. Dup of Q153","poster":"NikkyDicky","timestamp":"1633894080.0","comments":[{"comment_id":"261534","upvote_count":"1","poster":"01037","content":"149 now","timestamp":"1634732760.0"}],"upvote_count":"2"},{"content":"I think it's C\nDMS: 50Mbps = 6.25 MB/sec = ... = 0.5Tb/day. 24 Tb = 48 days, which is way above 3 weeks.","timestamp":"1633773840.0","poster":"Oleksandr","upvote_count":"5","comment_id":"104994"},{"comment_id":"104843","content":"C is the one.","timestamp":"1633559940.0","upvote_count":"2","poster":"meenu2225"},{"content":"RDS supports native restores of databases up to 16 TB. If your on-premises database can't be offline, we recommend that you use the AWS Database Migration Service to migrate your database to Amazon RDS. a terabyte of data in approximately 12 to 13 hours using dms = 12 days. Correct answer is B - use dms","upvote_count":"4","comments":[{"upvote_count":"6","poster":"Oleksandr","timestamp":"1633638420.0","content":"50Mbps = 6.25 MB/sec = ... = 0.5Tb/day. 24 Tb = 48 days, which is way above 3 weeks.","comment_id":"104993"}],"timestamp":"1633520940.0","comment_id":"95906","poster":"NKnab"},{"timestamp":"1633409580.0","comment_id":"94331","content":"C is correct.","poster":"FreeSwan","upvote_count":"2"},{"poster":"Mkumar","timestamp":"1633024920.0","upvote_count":"2","content":"Answer is C","comment_id":"87821"},{"content":"This is a replication of Question #153Topic 2","upvote_count":"1","poster":"LunchTime","timestamp":"1632823320.0","comment_id":"68981"},{"comment_id":"66016","comments":[{"timestamp":"1632536760.0","poster":"Asds","upvote_count":"1","comment_id":"67862","content":"Agree on D"},{"comment_id":"73127","timestamp":"1632969300.0","poster":"Smart","content":"What about associated downtime? C is correct.","upvote_count":"2"},{"poster":"Amitv2706","content":"How will you satisfy requirement of LEAST downtime with D?","timestamp":"1635381180.0","comment_id":"337502","upvote_count":"1"}],"poster":"virtual","upvote_count":"2","content":"I prefer D because replicate 24TB over VPN ... Better to use local export and local import, and also stop and restart applis.","timestamp":"1632300120.0"}],"question_text":"A company has a 24 TB MySQL database in its on-premises data center that grows at the rate of 10 GB per day. The data center is connected to the company's\nAWS infrastructure with a 50 Mbps VPN connection.\nThe company is migrating the application and workload to AWS. The application code is already installed and tested on Amazon EC2. The company now needs to migrate the database and wants to go live on AWS within 3 weeks.\nWhich of the following approaches meets the schedule with LEAST downtime?","answer_images":[],"answer_description":"","answer_ET":"C","exam_id":32,"answers_community":["C (100%)"],"unix_timestamp":1584478800,"question_id":524,"url":"https://www.examtopics.com/discussions/amazon/view/16886-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"choices":{"B":"1. Launch an AWS DMS instance. 2. Launch an Amazon RDS Aurora MySQL DB instance. 3. Configure the AWS DMS instance with on-premises and Amazon RDS database information. 4. Start the replication task within AWS DMS over the VPN. 5. Change the DNS entry to point to the Amazon RDS MySQL database. 6. Stop the replication.","C":"1. Create a database export locally using database-native tools. 2. Import that into AWS using AWS Snowball. 3. Launch an Amazon RDS Aurora DB instance. 4. Load the data in the RDS Aurora DB instance from the export. 5. Set up database replication from the on-premises database to the RDS Aurora DB instance over the VPN. 6. Change the DNS entry to point to the RDS Aurora DB instance. 7. Stop the replication.","D":"1. Take the on-premises application offline. 2. Create a database export locally using database-native tools. 3. Import that into AWS using AWS Snowball. 4. Launch an Amazon RDS Aurora DB instance. 5. Load the data in the RDS Aurora DB instance from the export. 6. Change the DNS entry to point to the Amazon RDS Aurora DB instance. 7. Put the Amazon EC2 hosted application online.","A":"1. Use the VM Import/Export service to import a snapshot of the on-premises database into AWS. 2. Launch a new EC2 instance from the snapshot. 3. Set up ongoing database replication from on premises to the EC2 database over the VPN. 4. Change the DNS entry to point to the EC2 database. 5. Stop the replication."},"isMC":true,"timestamp":"2020-03-17 22:00:00"},{"id":"FddVbjl4e9lXQfxzRaf0","url":"https://www.examtopics.com/discussions/amazon/view/16829-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"answer":"B","question_images":[],"discussion":[{"upvote_count":"27","content":"The answer is B. This is the only option that satisfies all requirements\n\nEncryption Rest/Transit - S3/Athena\nManage users and groups - IAM\nDeny Access - Ensures the strictest access. \nAudit Queries - CloudTrail logs\n\nA - RDS MySQL only pushes slow query log to CLoudwatch\nC - DynamoDB streams push only data changes not SQL\nD - This option up Athena but recommends using S3 select","timestamp":"1632156300.0","comment_id":"65045","poster":"jay1ram2"},{"comments":[{"upvote_count":"1","poster":"AWSum1","comment_id":"450801","timestamp":"1635867960.0","content":"Correct. And the question states 100s of files"}],"upvote_count":"5","poster":"Amitv2706","content":"B is correct. Athena can run queries on multiple files at same time. However S3 Select is applicable for only one object at a time","timestamp":"1635026940.0","comment_id":"337512"},{"poster":"3a632a3","upvote_count":"1","content":"Selected Answer: B\nThe answer is B because Athena can query hundreds of files and S3 select only works on a single file at a time. In regards to the SCP, D is valid if setup correctly. You should use both Allow and Deny in your SCPs appropriately. Think of no Allow as a soft deny for your general case and Deny as your hard deny for rigid compliance.\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html","comment_id":"1126940","timestamp":"1705693320.0"},{"content":"Selected Answer: B\nEncryption Rest/Transit - S3/Athena\nManage users and groups - IAM\nDeny Access - Ensures the strictest access.\nAudit Queries - CloudTrail logs\n\nA - RDS MySQL only pushes slow query log to CLoudwatch\nC - DynamoDB streams push only data changes not SQL\nD - This option up Athena but recommends using S3 select\n\nThis is a easy one for solution type of questions, hope I can have it in my exam","upvote_count":"1","comment_id":"941073","timestamp":"1688315580.0","poster":"SkyZeroZx"},{"content":"\"no team members should have access to services or resources not required for the SQL queries\" with this statement indicate that all other services access should be denied and only answer B fits the bill.","comment_id":"780681","upvote_count":"1","timestamp":"1674098880.0","poster":"davidy2020"},{"poster":"dcdcdc3","content":"this is what S3 Select is:\nhttps://aws.amazon.com/about-aws/whats-new/2018/09/amazon-s3-announces-new-features-for-s3-select/","upvote_count":"1","timestamp":"1663445880.0","comment_id":"671792"},{"comment_id":"498585","poster":"cldy","timestamp":"1639137600.0","content":"B. Apply a service control policy (SCP) that denies access to all services except IAM, Amazon Athena, Amazon S3, and AWS CloudTrail. Store customer record files in Amazon S3 and train users to execute queries using the CLI via Athena. Analyze CloudTrail events to audit and alarm on queries against personal data.","upvote_count":"1"},{"poster":"AzureDP900","upvote_count":"1","timestamp":"1638747900.0","content":"I'll go with B","comment_id":"494738"},{"upvote_count":"1","timestamp":"1638082680.0","content":"Selected Answer: B\nEncryption Rest/Transit - S3/Athena\nManage users and groups - IAM\nDeny Access - Ensures the strictest access.\nAudit Queries - CloudTrail logs\n\nA - RDS MySQL only pushes slow query log to CLoudwatch\nC - DynamoDB streams push only data changes not SQL\nD - This option up Athena but recommends using S3 select\n\nThis is a easy one for solution type of questions, hope I can have it in my exam","comment_id":"488908","poster":"acloudguru"},{"poster":"Smartphone","timestamp":"1636203660.0","upvote_count":"1","content":"Answer is B. \nEach of the following policies is an example of a deny list policy strategy. Deny list policies must be attached along with other policies that allow the approved actions in the affected accounts.\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples.html","comment_id":"455903"},{"timestamp":"1635441900.0","upvote_count":"1","comment_id":"411643","poster":"WhyIronMan","content":"I'll go with B"},{"poster":"Waiweng","timestamp":"1635102240.0","content":"it's B","comment_id":"349325","upvote_count":"2"},{"comment_id":"347489","upvote_count":"1","poster":"blackgamer","timestamp":"1635077760.0","content":"Answer is B. Athena can query but what it S3 select."},{"comment_id":"346313","comments":[{"content":"It is not possible to grant permissions using SCP, only deny them. This means you can ignore all questions that state \"Use an SCP that allows access\".","poster":"Viper57","timestamp":"1635740760.0","upvote_count":"1","comment_id":"446078"}],"upvote_count":"2","timestamp":"1635059160.0","poster":"gsw","content":"there is nothing to suggest in the question that it is required to pull out hundreds of queries at a time in which case why B? Surely D is ok?"},{"comment_id":"277708","poster":"Ebi","content":"I will go with B","timestamp":"1634968440.0","upvote_count":"3"},{"upvote_count":"3","timestamp":"1634952540.0","poster":"T14102020","content":"Correct is B. Athena + SCP denies","comment_id":"243947"},{"content":"I'll go with B","poster":"jackdryan","timestamp":"1634799060.0","comment_id":"231578","upvote_count":"3"},{"timestamp":"1634702100.0","comment_id":"209617","upvote_count":"1","content":"B. Use Deny policies in order to restrict usage of services outside the allowable ones.","poster":"CYL"},{"comment_id":"133453","content":"B, Dup of Q154","comments":[{"comment_id":"402531","content":"why you guys write always dup of questions on 1-450 questions, i dont understand. Should we look into 1-450 questions too?","poster":"Kopa","timestamp":"1635345000.0","upvote_count":"1"},{"comment_id":"261541","timestamp":"1634959980.0","upvote_count":"1","content":"150 now","poster":"01037"}],"upvote_count":"2","poster":"NikkyDicky","timestamp":"1634671860.0"},{"timestamp":"1634029560.0","content":"B is the answer","poster":"roger8978","comment_id":"114452","upvote_count":"1"},{"poster":"FreeSwan","upvote_count":"1","comments":[{"upvote_count":"2","poster":"VrushaliD","timestamp":"1632757560.0","comment_id":"109655","content":"SCP is for deny and cannot allow.","comments":[{"comments":[{"timestamp":"1634662440.0","upvote_count":"2","content":"Answer D\nkey thing to notice is \"Enable S3 object-level logging\"","poster":"jamjam2020","comment_id":"130488"}],"upvote_count":"1","poster":"jamjam2020","timestamp":"1634180880.0","comment_id":"130485","content":"you are wrong. The value can be either Allow or Deny. \nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_reference_scp-syntax.html#scp-syntax-effect"}]}],"comment_id":"94180","content":"B,C are in implicit deny mode.","timestamp":"1632681840.0"},{"content":"D is correct","timestamp":"1632658320.0","poster":"FreeSwan","comment_id":"94163","upvote_count":"1"},{"content":"Only Athena and RDS supports SQL. SCP are not able to \"allow\" access, SCP manages denying rules. \"B\" is the right answer.","timestamp":"1632550620.0","upvote_count":"1","comment_id":"90976","poster":"30th"},{"content":"answer is B","timestamp":"1632496140.0","poster":"Mkumar","comment_id":"87823","upvote_count":"2"},{"timestamp":"1632459360.0","upvote_count":"2","content":"This is a replication of Question #154Topic 2","comments":[{"poster":"Kopa","timestamp":"1635424020.0","content":"whats the meaning where isn't Topic2 450-750? Please explain","comment_id":"402532","upvote_count":"1"}],"comment_id":"68983","poster":"LunchTime"}],"question_id":525,"unix_timestamp":1584426600,"answer_description":"","timestamp":"2020-03-17 07:30:00","exam_id":32,"answer_ET":"B","choices":{"B":"Apply a service control policy (SCP) that denies access to all services except IAM, Amazon Athena, Amazon S3, and AWS CloudTrail. Store customer record files in Amazon S3 and train users to execute queries using the CLI via Athena. Analyze CloudTrail events to audit and alarm on queries against personal data.","A":"Apply a service control policy (SCP) that allows access to IAM, Amazon RDS, and AWS CloudTrail. Load customer records in Amazon RDS MySQL and train users to execute queries using the AWS CLI. Stream the query logs to Amazon CloudWatch Logs from the RDS database instance. Use a subscription filter with AWS Lambda functions to audit and alarm on queries against personal data.","C":"Apply a service control policy (SCP) that denies access to all services except IAM, Amazon DynamoDB, and AWS CloudTrail. Store customer records in DynamoDB and train users to execute queries using the AWS CLI. Enable DynamoDB streams to track the queries that are issued and use an AWS Lambda function for real-time monitoring and alerting.","D":"Apply a service control policy (SCP) that allows access to IAM, Amazon Athena, Amazon S3, and AWS CloudTrail. Store customer records as files in Amazon S3 and train users to leverage the Amazon S3 Select feature and execute queries using the AWS CLI. Enable S3 object-level logging and analyze CloudTrail events to audit and alarm on queries against personal data."},"topic":"1","answers_community":["B (100%)"],"question_text":"A company wants to allow its Marketing team to perform SQL queries on customer records to identify market segments. The data is spread across hundreds of files. The records must be encrypted in transit and at rest. The Team Manager must have the ability to manage users and groups, but no team members should have access to services or resources not required for the SQL queries. Additionally, Administrators need to audit the queries made and receive notifications when a query violates rules defined by the Security team.\nAWS Organizations has been used to create a new account and an AWS IAM user with administrator permissions for the Team Manager.\nWhich design meets these requirements?","isMC":true}],"exam":{"isBeta":false,"provider":"Amazon","id":32,"isMCOnly":false,"name":"AWS Certified Solutions Architect - Professional","lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"isImplemented":true},"currentPage":105},"__N_SSP":true}