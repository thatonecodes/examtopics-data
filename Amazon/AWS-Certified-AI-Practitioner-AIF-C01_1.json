{"pageProps":{"questions":[{"id":"i3AjmhrkXmbLTqZYPip1","url":"https://www.examtopics.com/discussions/amazon/view/150663-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","exam_id":14,"discussion":[{"upvote_count":"9","poster":"jove","content":"Selected Answer: B\nB. Partial Dependence Plots (PDPs)\n\nExplanation:\nPartial Dependence Plots (PDPs) are useful tools for understanding the relationship between specific features and the model's predictions, making it easier to see how changes in input variables affect the forecast. PDPs are particularly helpful for stakeholders because they visually show the impact of individual features on predictions without requiring a deep understanding of the model's inner workings.","timestamp":"1730693100.0","comment_id":"1306763"},{"timestamp":"1744197240.0","comment_id":"1559215","content":"Selected Answer: B\nB is the answer Thanks to P A S S 4 S U R E H U B","poster":"rason5","upvote_count":"1"},{"timestamp":"1743943800.0","comment_id":"1558243","content":"Selected Answer: B\nExplicação:Gráficos de dependência parcial (Partial Dependence Plots - PDPs) são usados para mostrar como uma variável de entrada afeta a previsão do modelo, mantendo as outras variáveis constantes.São ferramentas poderosas de explicabilidade e transparência, especialmente para partes interessadas não técnicas. Eles ajudam a visualizar a relação entre características importantes e as previsões do modelo, respondendo perguntas como:\n\"Se aumentarmos o orçamento em marketing, o que acontece com a demanda prevista?\"","poster":"Rcosmos","upvote_count":"1"},{"upvote_count":"4","content":"Selected Answer: B\nanyone able to provide all questions. i can see only first 32 questions","timestamp":"1739432460.0","comment_id":"1356005","poster":"swat2024"},{"upvote_count":"1","poster":"Jessiii","content":"Selected Answer: B\nPDPs help in explaining the relationship between the features and the model’s predictions, offering transparency into how the model makes decisions, which is critical for explainability to stakeholders. PDPs show how changes in a feature impact the model's output, thus helping to provide an understanding of the model's behavior.","timestamp":"1739324580.0","comment_id":"1355319"},{"timestamp":"1738933800.0","poster":"preetgoswami","comment_id":"1352990","content":"Selected Answer: B\nB. Partial dependence plots (PDPs)","upvote_count":"1"},{"timestamp":"1736885640.0","upvote_count":"2","poster":"kopper2019","content":"Selected Answer: B\nAWS certification exams are introducing new question types, including ordering, matching, and case study questions, alongside traditional multiple choice and multiple response formats. The ordering type requires arranging selected responses in the correct sequence, while matching questions involve linking statements to prompts. Case studies recycle a scenario across multiple questions, allowing candidates to save time by understanding the context once. Each question is evaluated independently, meaning it's crucial to answer all parts correctly to receive credit.","comment_id":"1340526"},{"comment_id":"1339022","upvote_count":"1","timestamp":"1736557740.0","content":"Selected Answer: B\nAnswer:B. Partial dependence plots (PDPs)","poster":"Owolabi19"},{"poster":"sacha12","upvote_count":"1","timestamp":"1730676180.0","content":"I think B is correct","comment_id":"1306683"}],"answer":"B","answer_description":"","unix_timestamp":1730620320,"question_images":[],"answers_community":["B (100%)"],"answer_images":[],"topic":"1","question_text":"A company makes forecasts each quarter to decide how to optimize operations to meet expected demand. The company uses ML models to make these forecasts.\nAn AI practitioner is writing a report about the trained ML models to provide transparency and explainability to company stakeholders.\nWhat should the AI practitioner include in the report to meet the transparency and explainability requirements?","choices":{"B":"Partial dependence plots (PDPs)","A":"Code for model training","C":"Sample data for training","D":"Model convergence tables"},"isMC":true,"timestamp":"2024-11-03 08:52:00","answer_ET":"B","question_id":1},{"id":"9ZWvRqve4XLsFQsqi4S3","answers_community":["A (92%)","8%"],"question_images":[],"unix_timestamp":1730485140,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/150627-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","topic":"1","answer":"A","timestamp":"2024-11-01 19:19:00","question_text":"A company wants to use language models to create an application for inference on edge devices. The inference must have the lowest latency possible.\nWhich solution will meet these requirements?","question_id":2,"answer_images":[],"choices":{"D":"Incorporate a centralized large language model (LLM) API for asynchronous communication with edge devices.","A":"Deploy optimized small language models (SLMs) on edge devices.","B":"Deploy optimized large language models (LLMs) on edge devices.","C":"Incorporate a centralized small language model (SLM) API for asynchronous communication with edge devices."},"isMC":true,"discussion":[{"timestamp":"1743947640.0","poster":"Rcosmos","upvote_count":"1","content":"Selected Answer: U\nQuando o objetivo é inferência com a menor latência possível, a melhor abordagem é executar o modelo diretamente no dispositivo de borda (edge).\nSLMs (Small Language Models) são projetados para serem leves, rápidos e eficientes, o que os torna ideais para: Dispositivos com recursos limitados\nTempo de resposta imediato . Execução offline ou com pouca conectividade","comment_id":"1558257"},{"comment_id":"1355330","timestamp":"1739325120.0","upvote_count":"1","content":"Selected Answer: A\nOptimized small language models (SLMs) are specifically designed to run efficiently on edge devices with limited resources (such as memory and processing power). Deploying smaller, optimized models directly on the edge devices allows for near-instantaneous inference with minimal latency, as the data doesn't need to travel to a central server for processing.","poster":"Jessiii"},{"timestamp":"1735608780.0","poster":"Moon","content":"Selected Answer: A\nA: Deploy optimized small language models (SLMs) on edge devices.\n\nExplanation:\nDeploying optimized small language models (SLMs) on edge devices ensures low latency because the inference happens directly on the device without relying on cloud communication. Small language models are lightweight and designed to run efficiently on devices with limited resources, making them ideal for edge computing.","upvote_count":"4","comment_id":"1334547"},{"timestamp":"1735112220.0","comment_id":"1331424","upvote_count":"1","poster":"Aryan_10","content":"Selected Answer: A\nLowest latency possible - SLM"},{"poster":"Nicocacik","content":"Selected Answer: A\nLow latency with edge devices -> SLM","timestamp":"1733313120.0","comment_id":"1321837","upvote_count":"1"},{"poster":"Blair77","timestamp":"1731345300.0","comment_id":"1310215","upvote_count":"1","content":"A is good - Minimal latency: SLMs are designed to run efficiently on resource-constrained devices, offering fast inference directly on the device."},{"timestamp":"1730828280.0","comment_id":"1307485","poster":"jove","content":"Selected Answer: A\nSLM on edge devices","upvote_count":"2"},{"comment_id":"1306669","poster":"tccusa","content":"Selected Answer: A\nSLM on edge devices is the correct solution.","timestamp":"1730672820.0","upvote_count":"2"},{"comment_id":"1305950","timestamp":"1730485140.0","poster":"galliaj","content":"Using Optimized Small Language Models (SLMs) on edge devices is the best choice because they are designed to run efficiently within the resource constraints of edge hardware. This minimizes latency and helps deliver fast inference times while using less computational power and memory. The problem with trying to use centralized APIs is the associated latentcy.","upvote_count":"4"}],"exam_id":14,"answer_ET":"A"},{"id":"kmsflCBeUuojiRu0QgFi","question_id":3,"url":"https://www.examtopics.com/discussions/amazon/view/153548-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answer_description":"","discussion":[{"timestamp":"1739321640.0","comment_id":"1355261","poster":"Jessiii","upvote_count":"2","content":"Selected Answer: A\nIn this scenario, the company is demonstrating the principle of Fairness by ensuring their training data includes a diverse range of demographics, preventing potential biases based on gender, ethnicity, or geographic location, which aligns with the core idea of responsible AI."},{"poster":"may2021_r","content":"Selected Answer: A\nThe correct answer is A. Fairness. Using diverse datasets ensures equal representation and performance across different demographic groups.","comment_id":"1333226","upvote_count":"1","timestamp":"1735431060.0"},{"poster":"aws_Tamilan","timestamp":"1735359180.0","content":"Selected Answer: A\nBy using a diverse dataset that includes different genders, ethnicities, and geographic locations, the company is addressing fairness by making sure the model does not discriminate against any particular group.","upvote_count":"1","comment_id":"1332761"}],"answer":"A","answer_ET":"A","question_images":[],"isMC":true,"exam_id":14,"timestamp":"2024-12-28 05:13:00","question_text":"A company is developing a mobile ML app that uses a phone's camera to diagnose and treat insect bites. The company wants to train an image classification model by using a diverse dataset of insect bite photos from different genders, ethnicities, and geographic locations around the world.\n\nWhich principle of responsible AI does the company demonstrate in this scenario?","unix_timestamp":1735359180,"answers_community":["A (100%)"],"topic":"1","answer_images":[],"choices":{"B":"Explainability","D":"Transparency","C":"Governance","A":"Fairness"}},{"id":"hJtgegQvQIm82uILCKp6","exam_id":14,"url":"https://www.examtopics.com/discussions/amazon/view/153549-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answer_images":[],"choices":{"B":"Amazon SageMaker Data Wrangler","C":"Amazon SageMaker Model Cards","A":"Amazon SageMaker Clarify","D":"AWS AI Service Cards"},"answers_community":["A (100%)"],"timestamp":"2024-12-28 05:17:00","unix_timestamp":1735359420,"answer_description":"","answer_ET":"A","question_images":[],"discussion":[{"content":"Selected Answer: A\nThe solution that meets the requirements of detecting bias and explaining model predictions in a loan approval scenario is A. Amazon SageMaker Clarify","poster":"Jessiii","upvote_count":"1","timestamp":"1739321700.0","comment_id":"1355262"},{"upvote_count":"2","content":"Selected Answer: A\nThe correct answer is A. SageMaker Clarify provides both bias detection and model explainability features.","timestamp":"1735431120.0","poster":"may2021_r","comment_id":"1333227"},{"upvote_count":"3","poster":"aws_Tamilan","comment_id":"1332763","content":"Selected Answer: A\nAmazon SageMaker Clarify provides both bias detection and model explainability features, making it the most suitable choice for detecting bias in a loan approval model and explaining its predictions.","timestamp":"1735359420.0"}],"question_text":"A company is developing an ML model to make loan approvals. The company must implement a solution to detect bias in the model. The company must also be able to explain the model's predictions.\n\nWhich solution will meet these requirements?","topic":"1","answer":"A","isMC":true,"question_id":4},{"id":"cxDZyMhbBo9fqvk8hlGW","question_id":5,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/153532-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","timestamp":"2024-12-28 02:24:00","topic":"1","exam_id":14,"answer":"C","unix_timestamp":1735349040,"isMC":true,"answer_description":"","question_images":[],"choices":{"C":"BERTScore","D":"Real world knowledge (RWK) score","B":"F1 score","A":"Area Under the ROC Curve (AUC) score"},"answers_community":["C (100%)"],"discussion":[{"content":"Selected Answer: C\nBERTScore: This metric leverages the capabilities of a pre-trained BERT model to assess the semantic similarity between the generated summaries and the reference text, providing a more accurate evaluation of the model's ability to capture the key points of the original text, which is crucial for text summarization.","comment_id":"1355264","timestamp":"1739321760.0","upvote_count":"1","poster":"Jessiii"},{"timestamp":"1735431240.0","content":"Selected Answer: C\nThe correct answer is C. BERTScore is specifically designed for evaluating text generation quality.","poster":"may2021_r","upvote_count":"1","comment_id":"1333228"},{"content":"Selected Answer: C\nBERTScore is the most appropriate metric for evaluating the accuracy of a generative text summarization model because it compares semantic similarity in a manner that aligns well with the goal of text summarization.","upvote_count":"1","timestamp":"1735359600.0","poster":"aws_Tamilan","comment_id":"1332764"},{"content":"Selected Answer: C\nBERTScore is a metric specifically designed to evaluate text generation tasks, such as summarization. It measures the semantic similarity between the generated text and the reference text by leveraging contextual embeddings from pre-trained models like BERT.\n\nBERTScore captures deeper semantic relationships, making it ideal for evaluating the accuracy and meaningfulness of summaries.","upvote_count":"1","comment_id":"1332711","timestamp":"1735349040.0","poster":"ap6491"}],"answer_images":[],"question_text":"A company has developed a generative text summarization model by using Amazon Bedrock. The company will use Amazon Bedrock automatic model evaluation capabilities.\n\nWhich metric should the company use to evaluate the accuracy of the model?"}],"exam":{"numberOfQuestions":154,"id":14,"name":"AWS Certified AI Practitioner AIF-C01","isImplemented":true,"lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":false,"isBeta":false},"currentPage":1},"__N_SSP":true}