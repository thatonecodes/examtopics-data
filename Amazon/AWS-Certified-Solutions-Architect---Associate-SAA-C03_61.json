{"pageProps":{"questions":[{"id":"AsHEldDKN0xgDqV5Zb4J","question_text":"A company is moving its data management application to AWS. The company wants to transition to an event-driven architecture. The architecture needs to be more distributed and to use serverless concepts while performing the different aspects of the workflow. The company also wants to minimize operational overhead.\n\nWhich solution will meet these requirements?","question_id":301,"topic":"1","exam_id":31,"discussion":[{"comment_id":"820947","content":"Selected Answer: D\nThis is why I’m voting D…..QUESTION ASKED FOR IT TO: use serverless concepts while performing the different aspects of the workflow. Is option D utilizing Serverless concepts?","poster":"Lonojack","upvote_count":"12","timestamp":"1692904380.0"},{"upvote_count":"8","comment_id":"820144","timestamp":"1692848700.0","poster":"geekgirl22","content":"It is D. Cannot be C because C is \"scheduled\""},{"timestamp":"1726900560.0","comment_id":"1179064","poster":"bujuman","upvote_count":"3","content":"Selected Answer: D\nWhile considering this requirement: The architecture needs to be more distributed and to use serverless concepts while performing the different aspects of the workflow\nAnd checking the following link : https://aws.amazon.com/step-functions/?nc1=h_ls, Answer D is the best for this use case"},{"upvote_count":"2","content":"Selected Answer: D\nOne of the use cases for step functions is to Automate extract, transform, and load (ETL) processes.\nhttps://aws.amazon.com/step-functions/#:~:text=for%20modern%20applications.-,Use%20cases,-Automate%20extract%2C%20transform","poster":"TariqKipkemei","timestamp":"1713239100.0","comment_id":"1044631"},{"poster":"Guru4Cloud","content":"Selected Answer: D\nAWS Step functions is serverless Visual workflows for distributed applications\nhttps://aws.amazon.com/step-functions/","comment_id":"998564","upvote_count":"2","timestamp":"1709564520.0"},{"timestamp":"1699683420.0","content":"Selected Answer: D\nStep Functions is based on state machines and tasks. A state machine is a workflow. A task is a state in a workflow that represents a single unit of work that another AWS service performs. Each step in a workflow is a state.\nDepending on your use case, you can have Step Functions call AWS services, such as Lambda, to perform tasks.\nhttps://docs.aws.amazon.com/step-functions/latest/dg/welcome.html","poster":"TariqKipkemei","upvote_count":"3","comment_id":"894558"},{"timestamp":"1699683360.0","content":"Answer is D.\nStep Functions is based on state machines and tasks. A state machine is a workflow. A task is a state in a workflow that represents a single unit of work that another AWS service performs. Each step in a workflow is a state. \nDepending on your use case, you can have Step Functions call AWS services, such as Lambda, to perform tasks. \nhttps://docs.aws.amazon.com/step-functions/latest/dg/welcome.html","poster":"TariqKipkemei","upvote_count":"3","comment_id":"894557"},{"content":"Selected Answer: C\nThere are two main types of routers used in event-driven architectures: event buses and event topics. At AWS, we offer Amazon EventBridge to build event buses and Amazon Simple Notification Service (SNS) to build event topics. https://aws.amazon.com/event-driven-architecture/","comments":[{"poster":"pentium75","content":"How do you 'build out a workflow' in EventBridge?","timestamp":"1719737700.0","upvote_count":"4","comment_id":"1109624"}],"timestamp":"1693832520.0","upvote_count":"1","poster":"Karlos99","comment_id":"829055"},{"content":"Selected Answer: D\nStep 3: Create a State Machine\nUse the Step Functions console to create a state machine that invokes the Lambda function that you created earlier in Step 1.\nhttps://docs.aws.amazon.com/step-functions/latest/dg/tutorial-creating-lambda-state-machine.html\nIn Step Functions, a workflow is called a state machine, which is a series of event-driven steps. Each step in a workflow is called a state.","poster":"TungPham","upvote_count":"3","timestamp":"1693008840.0","comment_id":"822002"},{"upvote_count":"2","comment_id":"820699","poster":"Bilalazure","content":"Selected Answer: D\nDistrubuted****","timestamp":"1692886200.0"},{"comment_id":"819671","upvote_count":"2","comments":[{"upvote_count":"2","content":"It is true that an Event-driven is made with EventBridge but with a Lambda on schedule??? It is a mismatch, isn´t it?","poster":"MssP","timestamp":"1695889920.0","comment_id":"853009","comments":[{"upvote_count":"3","content":"Tricky question huh!","poster":"kraken21","comment_id":"858424","timestamp":"1696210200.0"}]}],"content":"Selected Answer: C\nVou de C, orientada a eventos","timestamp":"1692813360.0","poster":"Americo32"},{"comment_id":"819480","upvote_count":"2","timestamp":"1692804240.0","content":"Selected Answer: D\nAWS Step functions is serverless Visual workflows for distributed applications\nhttps://aws.amazon.com/step-functions/","comments":[{"comment_id":"825046","content":"Besides, \"Visualize and develop resilient workflows for EVENT-DRIVEN architectures.\"","upvote_count":"2","timestamp":"1693234140.0","poster":"leoattf"}],"poster":"bdp123"},{"upvote_count":"3","timestamp":"1692745260.0","poster":"tellmenowwwww","comment_id":"818610","content":"Could it be a C because it's event-driven architecture?"},{"poster":"SMAZ","upvote_count":"3","timestamp":"1692702360.0","comment_id":"817842","content":"Option D..\nAWS Step functions are used for distributed applications"}],"unix_timestamp":1677071160,"question_images":[],"answer":"D","choices":{"D":"Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps.","C":"Build out the workflow in Amazon EventBridge. Use EventBridge to invoke AWS Lambda functions on a schedule to process the workflow steps.","A":"Build out the workflow in AWS Glue. Use AWS Glue to invoke AWS Lambda functions to process the workflow steps.","B":"Build out the workflow in AWS Step Functions. Deploy the application on Amazon EC2 instances. Use Step Functions to invoke the workflow steps on the EC2 instances."},"answer_description":"","timestamp":"2023-02-22 14:06:00","answer_ET":"D","answers_community":["D (91%)","9%"],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/100371-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[]},{"id":"KCcpTYQCvYV0NRw9bg2s","url":"https://www.examtopics.com/discussions/amazon/view/100197-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"question_text":"A company is designing the network for an online multi-player game. The game uses the UDP networking protocol and will be deployed in eight AWS Regions. The network architecture needs to minimize latency and packet loss to give end users a high-quality gaming experience.\n\nWhich solution will meet these requirements?","exam_id":31,"timestamp":"2023-02-21 10:24:00","discussion":[{"content":"Selected Answer: B\nAWS Global Accelerator = TCP/UDP minimize latency","upvote_count":"12","comment_id":"904630","timestamp":"1684823520.0","poster":"lucdt4"},{"timestamp":"1683053460.0","poster":"OAdekunle","upvote_count":"5","content":"General\nQ: What is AWS Global Accelerator?\n\nA: AWS Global Accelerator is a networking service that helps you improve the availability and performance of the applications that you offer to your global users. AWS Global Accelerator is easy to set up, configure, and manage. It provides static IP addresses that provide a fixed entry point to your applications and eliminate the complexity of managing specific IP addresses for different AWS Regions and Availability Zones. AWS Global Accelerator always routes user traffic to the optimal endpoint based on performance, reacting instantly to changes in application health, your user’s location, and policies that you configure. You can test the performance benefits from your location with a speed comparison tool. Like other AWS services, AWS Global Accelerator is a self-service, pay-per-use offering, requiring no long term commitments or minimum fees.\n\nhttps://aws.amazon.com/global-accelerator/faqs/","comment_id":"887806"},{"upvote_count":"2","content":"Selected Answer: B\nkey-UDP networking protocol \nkey-minimize latency and packet loss \nTransit gateway is to conect multiple vpc \nThe solution is B because its accept udp protocol and its s global .\nThe solution is not C because cloudfront just accept http and https protocols","poster":"Danilus","comment_id":"1308921","timestamp":"1731098040.0"},{"poster":"mwwt2022","timestamp":"1704255900.0","upvote_count":"4","content":"online game -> Global Accelerator\ncloudfront is for static/dynamic content caching","comment_id":"1112490"},{"timestamp":"1693831920.0","poster":"Guru4Cloud","content":"Selected Answer: B\nSet up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.","comment_id":"998552","upvote_count":"3"},{"timestamp":"1683779100.0","poster":"TariqKipkemei","comments":[{"upvote_count":"2","comment_id":"1044635","content":"UDP = Global Accelerator","poster":"TariqKipkemei","timestamp":"1697428200.0"}],"upvote_count":"2","comment_id":"894562","content":"Selected Answer: B\nConnect to up to 10 regions within the AWS global network using the AWS Global Accelerator."},{"poster":"elearningtakai","comment_id":"855851","upvote_count":"5","timestamp":"1680185040.0","content":"Selected Answer: B\nGlobal Accelerator supports the User Datagram Protocol (UDP) and Transmission Control Protocol (TCP), making it an excellent choice for an online multi-player game using UDP networking protocol. By setting up Global Accelerator with UDP listeners and endpoint groups in each Region, the network architecture can minimize latency and packet loss, giving end users a high-quality gaming experience."},{"timestamp":"1677812160.0","content":"Selected Answer: B\nAWS Global Accelerator is a service that improves the availability and performance of applications with local or global users. Global Accelerator improves performance for a wide range of applications over TCP or UDP by proxying packets at the edge to applications running in one or more AWS Regions. Global Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP, as well as for HTTP use cases that specifically require static IP addresses or deterministic, fast regional failover. Both services integrate with AWS Shield for DDoS protection.","poster":"Bofi","comment_id":"827614","upvote_count":"2"},{"poster":"K0nAn","content":"Selected Answer: B\nGlobal Accelerator for UDP and TCP traffic","timestamp":"1677347280.0","comment_id":"821710","upvote_count":"2"},{"content":"Selected Answer: B\nGlobal Accelerator","upvote_count":"2","timestamp":"1677100560.0","poster":"bdp123","comment_id":"818429"},{"comment_id":"816390","upvote_count":"2","timestamp":"1676971440.0","poster":"Neha999","content":"B\nGlobal Accelerator for UDP traffic"}],"answer_ET":"B","topic":"1","answer_description":"","unix_timestamp":1676971440,"answer":"B","answers_community":["B (100%)"],"isMC":true,"question_id":302,"answer_images":[],"choices":{"A":"Setup a transit gateway in each Region. Create inter-Region peering attachments between each transit gateway.","C":"Set up Amazon CloudFront with UDP turned on. Configure an origin in each Region.","D":"Set up a VPC peering mesh between each Region. Turn on UDP for each VPC.","B":"Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region."}},{"id":"JC6fgcyON8I8zAtvsq3t","question_id":303,"unix_timestamp":1676983320,"isMC":true,"question_text":"A company hosts a three-tier web application on Amazon EC2 instances in a single Availability Zone. The web application uses a self-managed MySQL database that is hosted on an EC2 instance to store data in an Amazon Elastic Block Store (Amazon EBS) volume. The MySQL database currently uses a 1 TB Provisioned IOPS SSD (io2) EBS volume. The company expects traffic of 1,000 IOPS for both reads and writes at peak traffic.\n\nThe company wants to minimize any disruptions, stabilize performance, and reduce costs while retaining the capacity for double the IOPS. The company wants to move the database tier to a fully managed solution that is highly available and fault tolerant.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer":"B","answer_description":"","timestamp":"2023-02-21 13:42:00","answers_community":["B (92%)","8%"],"discussion":[{"timestamp":"1677065760.0","content":"Selected Answer: B\nRDS does not support IO2 or IO2express . GP2 can do the required IOPS \n\n\nRDS supported Storage > \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html\nGP2 max IOPS > \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/general-purpose.html#gp2-performance","poster":"AlmeroSenior","comment_id":"817772","upvote_count":"16"},{"comment_id":"1183101","content":"Selected Answer: B\nRDS now supports io2 but it might still be an overkill given Gp2 is enough and we are looking for the most cost effective solution.","upvote_count":"8","poster":"sophieb","timestamp":"1711438440.0"},{"upvote_count":"2","timestamp":"1734517380.0","poster":"EllenLiu","content":"Selected Answer: B\ngp2: 1,000 GiB => 3000 Baseline performance (IOPS) match the requirement which is 2000 only\nBaseline IOPS performance : 100 ~16,000 at a rate of 3 IOPS per GiB of volume size.","comment_id":"1328387"},{"comment_id":"998511","timestamp":"1693828800.0","poster":"Guru4Cloud","content":"Selected Answer: B\nRDS does not support IO2 or IO2express . GP2 can do the required IOPS","upvote_count":"4"},{"poster":"Gooniegoogoo","content":"The Options is A only because it is sufficient.. Provisioned IOPS are available but overkill.. just want to make sure we understand why its A for the right reason","comments":[{"content":"Provisioned IOPS are available, but not io2, just io1.","timestamp":"1709467800.0","poster":"dkw2342","upvote_count":"1","comment_id":"1164752"}],"comment_id":"938223","timestamp":"1688047620.0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1686466260.0","content":"Simplified by Almero - thanks.\n\nRDS does not support IO2 or IO2express . GP2 can do the required IOPS","comment_id":"920472","poster":"Abrar2022"},{"comments":[{"timestamp":"1685531460.0","poster":"ruqui","upvote_count":"2","comment_id":"911130","content":"it doesn't matter whether or no io* is supported, using io2 is overkill, you only need 1K IOPS, B is the correct answer"}],"comment_id":"894568","upvote_count":"4","timestamp":"1683779880.0","poster":"TariqKipkemei","content":"Selected Answer: B\nI tried on the portal and only gp3 and i01 are supported. \nThis is 11 May 2023."},{"upvote_count":"2","content":"A\n Amazon RDS supports the use of Amazon EBS Provisioned IOPS (io2) volumes. When creating a new DB instance or modifying an existing one, you can select the io2 volume type and specify the amount of IOPS and storage capacity required. RDS also supports the newer io2 Block Express volumes, which can deliver even higher performance for mission-critical database workloads.","poster":"SimiTik","comments":[{"poster":"TariqKipkemei","comment_id":"894566","content":"Impossible. I just tried on the portal and only io1 and gp3 are supported.","timestamp":"1683779820.0","upvote_count":"2"}],"comment_id":"877460","timestamp":"1682181660.0"},{"poster":"klayytech","upvote_count":"2","timestamp":"1679865660.0","content":"Selected Answer: B\nhe most cost-effective solution that meets the requirements is to use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume. This solution will provide high availability and fault tolerance while minimizing disruptions and stabilizing performance. The gp2 EBS volume can handle up to 16,000 IOPS. You can also scale up to 64 TiB of storage.\n\nAmazon RDS for MySQL provides automated backups, software patching, and automatic host replacement. It also provides Multi-AZ deployments that automatically replicate data to a standby instance in another Availability Zone. This ensures that data is always available even in the event of a failure.","comment_id":"851509"},{"poster":"test_devops_aws","comment_id":"843659","upvote_count":"1","timestamp":"1679223660.0","content":"Selected Answer: B\nRDS does not support io2 !!!"},{"content":"B:gp3 would be the better option, but considering we have only gp2 option and such storage volume - gp2 will be the right choice","timestamp":"1678891200.0","upvote_count":"4","comment_id":"839980","poster":"Maximus007"},{"upvote_count":"1","timestamp":"1678765140.0","comment_id":"838528","poster":"Nel8","content":"Selected Answer: B\nI thought the answer here is A. But when I found the link from Amazon website; as per AWS:\n\nAmazon RDS provides three storage types: General Purpose SSD (also known as gp2 and gp3), Provisioned IOPS SSD (also known as io1), and magnetic (also known as standard). They differ in performance characteristics and price, which means that you can tailor your storage performance and cost to the needs of your database workload. You can create MySQL, MariaDB, Oracle, and PostgreSQL RDS DB instances with up to 64 tebibytes (TiB) of storage. You can create SQL Server RDS DB instances with up to 16 TiB of storage. For this amount of storage, use the Provisioned IOPS SSD and General Purpose SSD storage types.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","comments":[{"comment_id":"1315354","timestamp":"1732117860.0","content":"[updated - 21 Nove 2024]\n\nAmazon RDS provides three storage types: Provisioned IOPS SSD (also known as io1 and io2 Block Express), General Purpose SSD (also known as gp2 and gp3), and magnetic (also known as standard). They differ in performance characteristics and price, which means that you can tailor your storage performance and cost to the needs of your database workload. You can create Db2, MySQL, MariaDB, Oracle, SQL Server, and PostgreSQL RDS DB instances with up to 64 tebibytes (TiB) of storage. RDS for Db2 doesn't support the gp2 and magnetic storage types.","poster":"JA2018","upvote_count":"1"}]},{"comment_id":"828482","content":"Selected Answer: B\nfor DB instances between 1 TiB and 4 TiB, storage is striped across four Amazon EBS volumes providing burst performance of up to 12,000 IOPS.\n\nfrom \"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html\"","poster":"Steve_4542636","timestamp":"1677888600.0","upvote_count":"2"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html\nAmazon RDS provides three storage types: General Purpose SSD (also known as gp2 and gp3), Provisioned IOPS SSD (also known as io1), and magnetic (also known as standard)\nB - MOST cost-effectively","comment_id":"822048","timestamp":"1677381360.0","upvote_count":"4","poster":"TungPham"},{"upvote_count":"1","poster":"KZM","comment_id":"821403","comments":[{"poster":"KZM","upvote_count":"2","content":"If a 1 TB gp3 EBS volume is used, the maximum available IOPS according to calculations is 3000. This means that the storage can support a requirement of 1000 IOPS, and even 2000 IOPS if the requirement is doubled.\nI am confusing between choosing A or B.","comment_id":"824240","timestamp":"1677542340.0"}],"content":"The baseline IOPS performance of gp2 volumes is 3 IOPS per GB, which means that a 1 TB gp2 volume will have a baseline performance of 3,000 IOPS. However, the volume can also burst up to 16,000 IOPS for short periods, but this burst performance is limited and may not be sustained for long durations.\nSo, I am more prefer option A.","timestamp":"1677323220.0"},{"upvote_count":"1","poster":"mark16dc","timestamp":"1677207480.0","content":"Selected Answer: A\nOption A is the correct answer. A Multi-AZ deployment provides high availability and fault tolerance by automatically replicating data to a standby instance in a different Availability Zone. This allows for seamless failover in the event of a primary instance failure. Using an io2 Block Express EBS volume provides the needed IOPS performance and capacity for the database. It is also designed for low latency and high durability, which makes it a good choice for a database tier.","comments":[{"upvote_count":"1","poster":"CapJackSparrow","comment_id":"841239","content":"How will you select io2 when RDS only offers io1....magic?","timestamp":"1678988460.0"}],"comment_id":"820057"},{"content":"Selected Answer: B\nCorrection - hit wrong answer button - meant 'B'\nAmazon RDS provides three storage types: General Purpose SSD (also known as gp2 and gp3), Provisioned IOPS SSD (also known as io1)\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","poster":"bdp123","comment_id":"818438","timestamp":"1677100800.0","upvote_count":"2"},{"timestamp":"1677100740.0","upvote_count":"1","comment_id":"818435","content":"Selected Answer: A\nAmazon RDS provides three storage types: General Purpose SSD (also known as gp2 and gp3), Provisioned IOPS SSD (also known as io1)\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","poster":"bdp123"},{"content":"Selected Answer: A\nhttps://aws.amazon.com/about-aws/whats-new/2021/07/aws-announces-general-availability-amazon-ebs-block-express-volumes/","comment_id":"816571","timestamp":"1676983320.0","upvote_count":"2","poster":"everfly"}],"topic":"1","exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/100225-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"choices":{"D":"Use two large EC2 instances to host the database in active-passive mode.","B":"Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.","A":"Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with an io2 Block Express EBS volume.","C":"Use Amazon S3 Intelligent-Tiering access tiers."},"answer_ET":"B","answer_images":[]},{"id":"oBai6zbDzbTErYI5aPtG","question_text":"A company hosts a serverless application on AWS. The application uses Amazon API Gateway, AWS Lambda, and an Amazon RDS for PostgreSQL database. The company notices an increase in application errors that result from database connection timeouts during times of peak traffic or unpredictable traffic. The company needs a solution that reduces the application failures with the least amount of change to the code.\n\nWhat should a solutions architect do to meet these requirements?","timestamp":"2023-02-21 10:25:00","exam_id":31,"question_images":[],"discussion":[{"timestamp":"1683780180.0","comment_id":"894571","upvote_count":"10","content":"Selected Answer: B\nMany applications, including those built on modern serverless architectures, can have a large number of open connections to the database server and may open and close database connections at a high rate, exhausting database memory and compute resources. Amazon RDS Proxy allows applications to pool and share connections established with the database, improving database efficiency and application scalability. With RDS Proxy, failover times for Aurora and RDS databases are reduced by up to 66%.\n\nhttps://aws.amazon.com/rds/proxy/","poster":"TariqKipkemei"},{"upvote_count":"5","timestamp":"1701875400.0","comment_id":"1089477","content":"Selected Answer: B\nA. Reduce the Lambda concurrency rate? Has nothing to do with decreasing connections timeout.\nB. Enable RDS Proxy on the RDS DB instance. Correct answer\nC. Resize the RDS DB instance class to accept more connections? More connections means worse performance. Therefore, not correct.\nD. Migrate the database to Amazon DynamoDB with on-demand scaling? DynamoDB is a noSQL database. Not correct.","poster":"Murtadhaceit"},{"comment_id":"1315356","upvote_count":"1","poster":"JA2018","timestamp":"1732117980.0","content":"Selected Answer: B\nKeys found in STEM:\n\n1. The company notices an increase in application errors that result from database connection timeouts during times of peak traffic or unpredictable traffic. \n\n2. The company needs a solution that reduces the application failures with the least amount of change to the code."},{"timestamp":"1693828080.0","comment_id":"998503","content":"Selected Answer: B\nRDS Proxy is a fully managed, highly available, and scalable proxy for Amazon Relational Database Service (RDS) that makes it easy to connect to your RDS instances from applications running on AWS Lambda. RDS Proxy offloads the management of connections to the database, which can help to improve performance and reliability.","upvote_count":"4","poster":"Guru4Cloud"},{"content":"Selected Answer: B\nTo reduce application failures resulting from database connection timeouts, the best solution is to enable RDS Proxy on the RDS DB instance","upvote_count":"2","poster":"elearningtakai","comment_id":"855853","timestamp":"1680185160.0"},{"comment_id":"843389","content":"Selected Answer: B\nRDS Proxy","upvote_count":"4","timestamp":"1679195220.0","poster":"WherecanIstart"},{"upvote_count":"2","timestamp":"1677178980.0","poster":"nder","content":"Selected Answer: B\nRDS Proxy will pool connections, no code changes need to be made","comment_id":"819600"},{"content":"Selected Answer: B\nRDS proxy","upvote_count":"2","timestamp":"1677101160.0","poster":"bdp123","comment_id":"818443"},{"comment_id":"816391","content":"B RDS Proxy\nhttps://aws.amazon.com/rds/proxy/","upvote_count":"3","timestamp":"1676971500.0","poster":"Neha999"}],"answer":"B","topic":"1","answers_community":["B (100%)"],"unix_timestamp":1676971500,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/100198-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":304,"answer_ET":"B","answer_images":[],"choices":{"A":"Reduce the Lambda concurrency rate.","C":"Resize the RDS DB instance class to accept more connections.","D":"Migrate the database to Amazon DynamoDB with on-demand scaling.","B":"Enable RDS Proxy on the RDS DB instance."},"isMC":true},{"id":"5PrOiA2OmVjonpGgqhfn","unix_timestamp":1676983920,"discussion":[{"timestamp":"1676983920.0","content":"The amount of CPU and memory resources required by the batch job exceeds the capabilities of AWS Lambda and Amazon Lightsail with AWS Auto Scaling, which offer limited compute resources. AWS Fargate offers containerized application orchestration and scalable infrastructure, but may require additional operational overhead to configure and manage the environment. AWS Batch is a fully managed service that automatically provisions the required infrastructure for batch jobs, with options to use different instance types and launch modes.\n\nTherefore, the solution that will run the batch job within 15 minutes with the LEAST operational overhead is D. Use AWS Batch on Amazon EC2. AWS Batch can handle all the operational aspects of job scheduling, instance management, and scaling while using Amazon EC2 injavascript:void(0)stances with the right amount of CPU and memory resources to meet the job's requirements.","poster":"NolaHOla","upvote_count":"20","comment_id":"816579"},{"content":"Selected Answer: D\nAWS Batch is a fully-managed service that can launch and manage the compute resources needed to execute batch jobs. It can scale the compute environment based on the size and timing of the batch jobs.","comment_id":"816644","timestamp":"1676988420.0","poster":"everfly","upvote_count":"12"},{"upvote_count":"1","poster":"FlyingHawk","content":"Selected Answer: D\nLambda has a hard limit of 10 GB of memory and 6 vCPUs per function execution, Amazon Light sail has the limit of 8vCPUs and 32GB memory, so A and C out, B and D can meet vCPU and memory requirements, but B is more expensive than D, so correct answer is D.","comment_id":"1344503","timestamp":"1737505680.0"},{"content":"Selected Answer: D\nkey-The batch job takes 15 minutes on average \nkey-LEAST operational overhead\nkey-the batch job \nis not A because lambda execution takes 15 max and lambda dont support 512 GIB of memory\nthe answer is D batch it is designed to run large-scale batch jobs an automatically manages the scaling of resources also batch allow jobs to be distributed accross multiple instances because supports parallel execution","comment_id":"1308928","poster":"Danilus","timestamp":"1731100680.0","upvote_count":"3"},{"poster":"Ramdi1","upvote_count":"4","comment_id":"1024146","timestamp":"1696358340.0","content":"Selected Answer: D\nThe question needs to be phrased differently. I assume at first it was Lambda, because it says 15 minutes in the question which can be done. Yes it also does say CPU intensive however they go on with a full stop and then give you the server specs. It does not say it uses that much of the specs so they need to really rephrase the questions."},{"content":"Selected Answer: D\nThe main reasons are:\n\nAWS Batch can easily schedule and run batch jobs on EC2 instances. It can scale up to the required vCPUs and memory to match the on-premises server.\nUsing EC2 provides full control over the instance type to meet the resource needs.\nNo servers or clusters to manage like with ECS/Fargate or Lightsail. AWS Batch handles this automatically.\nMore cost effective and operationally simple compared to Lambda which is not ideal for long running batch jobs.","upvote_count":"7","timestamp":"1693827540.0","comment_id":"998494","poster":"Guru4Cloud"},{"timestamp":"1693787100.0","poster":"BrijMohan08","upvote_count":"1","comment_id":"998048","content":"Selected Answer: A\nOn-Prem was avg 15 min, but target state architecture is expected to finish within 15 min","comments":[{"upvote_count":"5","poster":"pentium75","timestamp":"1703934300.0","comment_id":"1109627","content":"How? The on-prem server has 64 CPUs and 512 GB RAM, Lambda offers much less. And even on-prem it takes 15 minutes ON AVERAGE, sometimes more."}]},{"upvote_count":"3","content":"Selected Answer: D\nNot Lambda, \"average 15 minutes\" means there are jobs with running more and less than 15 minutes. Lambda max is 15 minutes.","comment_id":"967573","poster":"jayce5","timestamp":"1690757820.0"},{"poster":"Gooniegoogoo","upvote_count":"5","timestamp":"1688048700.0","comment_id":"938250","content":"This is for certain a tough one. I do see that they have thrown a curve ball in making it Lambda Functional scaling, however what we dont know is if this application has many request or one large one.. looks like Lambda can scale and use the same lambda env.. seems intensive tho so will go with D"},{"content":"Selected Answer: D\nAWS Batch","timestamp":"1683780600.0","poster":"TariqKipkemei","upvote_count":"3","comment_id":"894577"},{"upvote_count":"7","timestamp":"1678174680.0","poster":"JLII","content":"Selected Answer: D\nNot A because: \"AWS Lambda now supports up to 10 GB of memory and 6 vCPU cores for Lambda Functions.\" https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/ vs. \"The server has 64 virtual CPU (vCPU) and 512 GiB of memory\" in the question.","comment_id":"831632"},{"comments":[{"poster":"nder","content":"Wrong, the job takes \"On average 15 minutes\" and requires more cpu and ram than lambda can deal with. AWS Batch is correct in this scenario","comments":[{"content":"read the rest of the question which gives the answer:\n\"Which solution will run the batch job within 15 minutes with the LEAST operational overhead?\" \nKeyword \"Within 15 minutes\"","upvote_count":"3","comments":[{"comment_id":"820693","comments":[{"comment_id":"1017794","timestamp":"1695734340.0","upvote_count":"2","poster":"Terion","content":"I think what he means is that it takes on average 15 min on prem only"}],"upvote_count":"8","timestamp":"1677254580.0","content":"What happens if it EXCEEDS the 15 min AVERAGE? \nAverage = possibly can be more than 15min.\nThe safer bet would be option D: AWS Batch on EC2","poster":"Lonojack"}],"poster":"geekgirl22","comment_id":"820151","timestamp":"1677218640.0"}],"comment_id":"819598","timestamp":"1677178920.0","upvote_count":"4"},{"timestamp":"1705597620.0","comment_id":"1126070","poster":"awsgeek75","content":"How are you going to get 64 vCPUS to a Lambda function?","upvote_count":"2"}],"comment_id":"818666","upvote_count":"2","poster":"geekgirl22","content":"A is the answer. Lambda is known that has a limit of 15 minutes. So for as long as it says \"within 15 minutes\" that should be a clear indication it is Lambda","timestamp":"1677117900.0"},{"content":"Selected Answer: D\nAWS batch on EC2","comment_id":"818447","poster":"bdp123","upvote_count":"2","timestamp":"1677101220.0"}],"answers_community":["D (98%)","2%"],"timestamp":"2023-02-21 13:52:00","answer_images":[],"question_images":[],"isMC":true,"answer_ET":"D","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/100227-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company is migrating an old application to AWS. The application runs a batch job every hour and is CPU intensive. The batch job takes 15 minutes on average with an on-premises server. The server has 64 virtual CPU (vCPU) and 512 GiB of memory.\n\nWhich solution will run the batch job within 15 minutes with the LEAST operational overhead?","answer_description":"","exam_id":31,"answer":"D","choices":{"C":"Use Amazon Lightsail with AWS Auto Scaling.","B":"Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate.","D":"Use AWS Batch on Amazon EC2.","A":"Use AWS Lambda with functional scaling."},"question_id":305}],"exam":{"id":31,"provider":"Amazon","lastUpdated":"11 Apr 2025","isMCOnly":true,"isBeta":false,"isImplemented":true,"numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":61},"__N_SSP":true}