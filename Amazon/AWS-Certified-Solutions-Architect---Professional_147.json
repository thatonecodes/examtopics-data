{"pageProps":{"questions":[{"id":"DFFsCIk7CTytSTqkEZhp","exam_id":32,"answer":"A","topic":"1","timestamp":"2021-04-30 14:53:00","answer_images":[],"isMC":true,"question_text":"A company that develops consumer electronics with offices in Europe and Asia has 60 TB of software images stored on premises in Europe. The company wants to transfer the images to an Amazon S3 bucket in the ap-northeast-1 Region. New software images are created daily and must be encrypted in transit. The company needs a solution that does not require custom development to automatically transfer all existing and new software images to Amazon S3.\nWhat is the next step in the transfer process?","question_images":[],"answers_community":["A (100%)"],"question_id":731,"answer_ET":"A","discussion":[{"upvote_count":"5","timestamp":"1634773620.0","comments":[{"timestamp":"1635940920.0","upvote_count":"2","comment_id":"460362","poster":"StelSen","content":"I would say combination of C&A."}],"content":"I'll go with A\nUnfortunately in real world it will be a combination of D and A due the first high volume","comment_id":"414192","poster":"WhyIronMan"},{"timestamp":"1655011500.0","upvote_count":"3","poster":"Chuky64","content":"Selected Answer: A\nAWS DataSync for current and new objects.","comment_id":"615162"},{"upvote_count":"3","comment_id":"603187","timestamp":"1652857140.0","content":"Selected Answer: A\n\"current and new objects\" = DataSync","poster":"bobsmith2000"},{"upvote_count":"1","content":"A. Deploy an AWS DataSync agent and configure a task to transfer the images to the S3 bucket","timestamp":"1639031280.0","poster":"cldy","comment_id":"497388"},{"comment_id":"497172","timestamp":"1638995880.0","upvote_count":"1","content":"A is right \nhttps://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html","poster":"AzureDP900"},{"timestamp":"1635678180.0","content":"It's A","upvote_count":"1","comment_id":"448563","poster":"andylogan"},{"upvote_count":"1","comment_id":"434821","timestamp":"1635669120.0","poster":"tgv","content":"AAA\n---"},{"timestamp":"1634984520.0","content":"its A,\n\n. DataSync provides built-in security capabilities such as encryption of data in-transit, and data integrity verification in-transit and at-rest. It optimizes use of network bandwidth, and automatically recovers from network connectivity failures. In addition, DataSync provides control and monitoring capabilities such as data transfer scheduling and granular visibility into the transfer process through Amazon CloudWatch metrics, logs, and events.","comment_id":"416061","upvote_count":"4","poster":"Kopa"},{"poster":"vimgoru24","content":"No custom development + no time constraints = A","upvote_count":"3","comment_id":"400037","timestamp":"1634193240.0"},{"content":"A is my answer!!","comment_id":"385775","upvote_count":"1","timestamp":"1634082480.0","poster":"hk436"},{"poster":"Rich_Rich","timestamp":"1634078340.0","comment_id":"382648","content":"(A) https://aws.amazon.com/blogs/storage/migrating-hundreds-of-tb-of-data-to-amazon-s3-with-aws-datasync/","upvote_count":"1"},{"poster":"Waiweng","upvote_count":"2","timestamp":"1633974960.0","comment_id":"360279","content":"it's A"},{"upvote_count":"4","content":"Agree on A","poster":"CarisB","comment_id":"352589","timestamp":"1633959420.0"},{"comment_id":"352273","timestamp":"1633719360.0","poster":"beebatov","upvote_count":"4","content":"Answer: A\n\nDataSync can automate the transfer + Snowball can't be shipped cross-region!\n\nhttps://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html\nhttps://docs.aws.amazon.com/snowball/latest/ug/shipping.html"},{"upvote_count":"2","timestamp":"1632197460.0","content":"datasync agent uses TLS so it could well be A","comment_id":"346191","comments":[{"content":"How long will it take to transfer 60TB from one region to another?","comments":[{"poster":"sergioandreslq","comment_id":"433995","timestamp":"1635628560.0","upvote_count":"1","content":"There is no time constraint in the requirements, so, DataSync is the best option to comply with requirements of: \"automatically transfer all existing and new software images to Amazon S3 encrypted in transit\"\nC: Incorrect: Won't fit the requirement to \"automatically transfer all existing and NEW SOFTWARE IMAGES\" \nD: Incorrect: it works however, it is easier use DataSync as this process is automatic, upload files using Site To Site VPN will require a manual intervention to review status of upload."}],"comment_id":"348770","timestamp":"1632639540.0","upvote_count":"1","poster":"Chibuzo1"}],"poster":"gsw"}],"choices":{"D":"Transfer the images over a Site-to-Site VPN connection using the S3 API with multipart upload","C":"Use an AWS Snowball device to transfer the images with the S3 bucket as the target","B":"Configure Amazon Kinesis Data Firehose to transfer the images using S3 Transfer Acceleration","A":"Deploy an AWS DataSync agent and configure a task to transfer the images to the S3 bucket"},"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/51252-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1619787180},{"id":"qlC7RLMASMj89wwfPMYv","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/48927-exam-aws-certified-solutions-architect-professional-topic-1/","answer":"C","answer_images":[],"question_id":732,"question_text":"You are migrating a legacy client-server application to AWS. The application responds to a specific DNS domain (e.g. www.example.com) and has a 2-tier architecture, with multiple application servers and a database server. Remote clients use TCP to connect to the application servers. The application servers need to know the IP address of the clients in order to function properly and are currently taking that information from the TCP socket. A Multi-AZ RDS MySQL instance will be used for the database.\nDuring the migration you can change the application code, but you have to file a change request.\nHow would you implement the architecture on AWS in order to maximize scalability and high availability?","answers_community":["C (67%)","D (33%)"],"answer_description":"Reference:\nhttps://aws.amazon.com/blogs/aws/elastic-load-balancing-adds-support-for-proxy-protocol/","timestamp":"2021-04-03 14:14:00","answer_ET":"D","unix_timestamp":1617452040,"isMC":true,"choices":{"D":"File a change request to implement Proxy Protocol support in the application. Use an ELB with a TCP Listener and Proxy Protocol enabled to distribute load on two application servers in different Azs.","C":"File a change request to implement Cross-Zone support in the application. Use an ELB with a TCP Listener and Cross-Zone Load Balancing enabled, two application servers in different AZs.","A":"File a change request to implement Alias Resource support in the application. Use Route 53 Alias Resource Record to distribute load on two application servers in different Azs.","B":"File a change request to implement Latency Based Routing support in the application. Use Route 53 with Latency Based Routing enabled to distribute load on two application servers in different Azs."},"exam_id":32,"question_images":[],"discussion":[{"comment_id":"535198","timestamp":"1643433120.0","content":"D is incorrect - it passes the Client IP part of header, when proxy protocol is enabled. How will this improve availability.\nC will help ensure the load is distributed across instance in different AZs.","upvote_count":"8","poster":"tkanmani76"},{"content":"D. File a change request to implement Proxy Protocol support in the application. Use an ELB with a TCP Listener and Proxy Protocol enabled to distribute load on two application servers in different Azs.","poster":"amministrazione","upvote_count":"1","comment_id":"1266693","timestamp":"1723755540.0"},{"poster":"Udyan","upvote_count":"1","timestamp":"1695996060.0","content":"options C and D are the most suitable for your requirements, but the final choice between them depends on your specific needs and whether preserving the client's original IP address is essential for your application. If preserving the client's IP address is a priority, then option D is a good choice. Otherwise, option C with Cross-Zone Load Balancing is a simpler and effective approach for load balancing and high availability.","comment_id":"1020848"},{"timestamp":"1672094040.0","poster":"hobokabobo","content":"Selected Answer: D\nI would go for D as this is what was designed with protocol: add a header with the client information. Now with that information preserved the ELB can distribute and forward traffic anywhere. Having at least two machines in two AZ: if one fails you still have the second plus different availability zone even if the whole availability zone fails, the service will be up. Also future scalability is addressed: as long as we can preserve the header we can think of any load balancer or proxy ... to spread load.\n\nOne thing: I do not understand the change request in C. Why would they need cross zone support in the application? From the question I only find that application needs the client IP and need to reach the database which is multi AZ. So why can't application can be deployed in multiple az without modification? I see no reason for such support.","upvote_count":"1","comment_id":"757895"},{"timestamp":"1671812340.0","content":"Selected Answer: C\n\"are currently taking that information from the TCP socket\" and \"During the migration you can change the application code\"\nBefore NLB is available, the choice is D.\nNow the better answer is C, no change of code, with client IP preserved (for target group type instance, or target group type IP with UDP_TCP listener)","upvote_count":"1","poster":"TigerInTheCloud","comment_id":"754352"},{"content":"Selected Answer: C\ncccccc","poster":"welcomeYM","upvote_count":"1","comment_id":"658511","timestamp":"1662211200.0"},{"poster":"cldy","upvote_count":"1","timestamp":"1639059360.0","comment_id":"497784","content":"D. File a change request to implement Proxy Protocol support in the application. Use an ELB with a TCP Listener and Proxy Protocol enabled to distribute load on two application servers in different Azs."},{"poster":"cldy","timestamp":"1633475820.0","comments":[{"poster":"01037","timestamp":"1635346740.0","content":"Yes, D","upvote_count":"1","comment_id":"361686"}],"upvote_count":"4","content":"D.\nProxy Protocol to obtain the clients IP address if the ELB is configured for TCP load balancing.\nX-Forwarded-For headers to obtain the clients IP address if the ELB is configured for HTTP(s) load balancing.","comment_id":"327332"}]},{"id":"8lBf5GYaVBmJ5KpUhaSa","answer_description":"","question_id":733,"timestamp":"2021-04-30 15:00:00","answer_ET":"D","question_images":[],"discussion":[{"upvote_count":"16","comment_id":"556134","timestamp":"1645809540.0","content":"D, EFS cross-Region Replication is now possible with RTO of 15mins\nhttps://aws.amazon.com/blogs/aws/new-replication-for-amazon-elastic-file-system-efs/","poster":"seyik"},{"timestamp":"1635131220.0","upvote_count":"11","content":"I'll go with A\n\nBy elimination: \n\n- B and C because of S3 Glacier will not attend the 1 hour RTO\n\n- D: there is no such thing \"EFS Cross-Region Replication\".... if you google it, everything points to AWS DataSync instead","comment_id":"414202","poster":"WhyIronMan","comments":[{"upvote_count":"1","poster":"JohnPi","comment_id":"690872","timestamp":"1665390240.0","content":"https://aws.amazon.com/blogs/aws/new-replication-for-amazon-elastic-file-system-efs/"}]},{"upvote_count":"1","timestamp":"1683346860.0","content":"Selected Answer: D\nCorrect Answer is D\nD. Turn on EFS Cross-Region Replication and set the secondary Region as the target. Create a lifecycle policy to move files to the EFS Infrequent Access storage class in the secondary Region.\n\nRefer AWS updates:\nhttps://www.stratusgrid.com/open-space/an-intro-to-amazon-efs-replication?locale=en\nhttps://aws.amazon.com/about-aws/whats-new/2022/01/amazon-elastic-file-system-replication/","comment_id":"890466","poster":"Amitst"},{"poster":"Amitst","content":"Correct Answer is D\nD. Turn on EFS Cross-Region Replication and set the secondary Region as the target. Create a lifecycle policy to move files to the EFS Infrequent Access storage class in the secondary Region.\n\nRefer AWS updates:\nhttps://www.stratusgrid.com/open-space/an-intro-to-amazon-efs-replication?locale=en\nhttps://aws.amazon.com/about-aws/whats-new/2022/01/amazon-elastic-file-system-replication/","timestamp":"1683346800.0","comment_id":"890465","upvote_count":"1"},{"content":"For those who have selected option B\n\nYes, S3 Glacier with expedited retrieval can meet the RTO of 1 hour. With expedited retrieval, data retrieval can be completed within a few minutes. However, it should be noted that expedited retrieval is more expensive than standard retrieval, so there may be additional costs associated with using this option.\n\n\nSo the right preferable answer seems to be Option D","upvote_count":"2","comment_id":"793517","poster":"Heer","timestamp":"1675127340.0"},{"poster":"janvandermerwer","upvote_count":"1","timestamp":"1668061680.0","comment_id":"714969","content":"Selected Answer: D\nD - I agree with other comments.\n\nB - May be an option depending on what tier of glacier is being used - i.e instance retrieval, flexible retrieval: https://aws.amazon.com/s3/storage-classes/glacier/\nC - Doesn't meet RTO of 1 hour (Glacier Deep Archive)"},{"timestamp":"1659375840.0","comment_id":"640793","poster":"Ni_yot","upvote_count":"1","content":"Change my ans to D. EFS cross region replication does exist. It depends on really when answered the question. As of Jan 2022 EFS CRR is a thing. \nhttps://aws.amazon.com/blogs/aws/new-replication-for-amazon-elastic-file-system-efs/"},{"content":"D should be the answer - RTO of 15\nhttps://aws.amazon.com/blogs/aws/new-replication-for-amazon-elastic-file-system-efs/\nbefore jan 2022 answer its A - Since C is for deep archive more than 1 hour, B you cant copy backup data to s3 only vaults, D wasn't exists before 2022 jan","upvote_count":"1","comment_id":"630180","poster":"asfsdfsdf","timestamp":"1657566300.0"},{"content":"Selected Answer: D\nanyone who choose A can tell me why One Zone - IA could be anh failover? I support for D","comment_id":"613665","timestamp":"1654757520.0","poster":"Anhdd","comments":[{"upvote_count":"1","content":"anyone who choose A can tell me why One Zone - IA could be a failover? I support for D\n- my typo sorry","timestamp":"1654757580.0","poster":"Anhdd","comment_id":"613666"}],"upvote_count":"1"},{"content":"I go D","timestamp":"1654658940.0","upvote_count":"1","poster":"hilft","comment_id":"613051"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/efs/latest/ug/efs-replication.html","poster":"bobsmith2000","comment_id":"607675","timestamp":"1653571920.0","upvote_count":"1"},{"poster":"Mimek","comment_id":"577286","timestamp":"1648535100.0","content":"Selected Answer: D\nD as of Jan 2022","upvote_count":"8"},{"content":"B. Glacier supports expedited archive. AWS Backup is the recommended backup solution for EFS. Not sure about cost here but the question does not mention anything about cost-efficiency.","upvote_count":"1","timestamp":"1644724800.0","poster":"futen0326","comment_id":"546218"},{"poster":"AMKazi","timestamp":"1643327700.0","content":"Ans is C: \"use as a fallback in the event of a main Region performance issue.\" meets this requirements as data needs to be continuously replicated. \nRemember its being copied to S3 so it can meet RTO requirement. Glacier will come into picture as a lifecycle policy , not in effect immediately.","upvote_count":"1","comment_id":"534194"},{"comment_id":"527808","upvote_count":"1","content":"Its C in my opinion\nhttps://aws.amazon.com/about-aws/whats-new/2019/05/aws-datasync-now-supports-efs-to-efs-transfer/ - copying data between EFS file systems\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/downloading-an-archive-two-steps.html - Expedited recovery from Glacier is between 1-5 minutes.","timestamp":"1642616280.0","poster":"lulz111","comments":[{"poster":"lulz111","timestamp":"1642616400.0","upvote_count":"2","content":"B sorry, i missed the Deep archive bit of C. \nhttps://aws.amazon.com/about-aws/whats-new/2020/01/aws-backup-supports-cross-region-backup/","comment_id":"527810"}]},{"content":"I will go with A\nhttps://aws.amazon.com/about-aws/whats-new/2019/05/aws-datasync-now-supports-efs-to-efs-transfer/","poster":"AzureDP900","timestamp":"1639000380.0","comment_id":"497198","upvote_count":"1"},{"upvote_count":"1","timestamp":"1638996060.0","comment_id":"497174","poster":"AzureDP900","content":"A is right"},{"poster":"tkanmani76","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"514756","timestamp":"1641083280.0","poster":"tkanmani76","content":"Pricing wise S3 Glacier is cheaper than EFS - $0.0133 for EFS Vs .0036$ for Glacier. Using Glacier we can retrieve in minutes using expedited option. DeepArchive though cheaper retrieval can take more than 12 hours. I retract from C and B is the right option."}],"comment_id":"496505","timestamp":"1638933960.0","content":"Option C\nA- Is a legacy solution for EFS backup - Refer https://docs.aws.amazon.com/efs/latest/ug/alternative-efs-backup.html#backup-considerations - hence not preferred\n2. Batch - Preferred approach - But not cost effective\n3. Data Sync - Supports data movement across regions and can be used to hook EFS with S3. Also Glacier Deep archive cheaper than Glacier storage and hence the best choice, considering that the expenses should be minimum."},{"comment_id":"491765","timestamp":"1638372240.0","content":"Should be B.\n\nAWS Documentation clearly mentions AWS Backup as a recommended service for EFS backup solution.\n\"Recommended Amazon EFS backup solutions\nThere are two recommended solutions available for backing up your Amazon EFS file systems.\n\nAWS Backup service\n\nThe EFS-to-EFS backup solution\n\n\"\nhttps://docs.aws.amazon.com/efs/latest/ug/alternative-efs-backup.html#recommended-backup-solutions","upvote_count":"3","comments":[{"timestamp":"1638372360.0","content":"And Glacier expedited retrieval supports 1-5 minutes retrieval time.","poster":"Gaurav_GGG","comment_id":"491767","upvote_count":"2"}],"poster":"Gaurav_GGG"},{"timestamp":"1636667220.0","poster":"sashenka","comment_id":"476525","content":"Technically speaking both B and C would meet the requirements of the 1 hour RTO! Creating a lifecycle policy to move backups to the S3 Glacier or S# Glacier Deep Archive storage class happens asynchronously and the actual transition typically takes over 24 hrs. Both B and C do not state the number of days to transition to Glacier from S3 and even if 0 is selected one would have at least 24 hrs and certainly more than the required 1 hour of RTO to have direct access to the backup data. Again, the point I am making is that the data is not being moved DIRECTLY into S3 Glacier or S3 Glacier Archive and as such the lifecycle policy transition is not immediate and will allow for a 1 hour RTO.","upvote_count":"1"},{"poster":"student22","upvote_count":"5","timestamp":"1636301400.0","content":"B\n---\nGlacier expedited retrieval supports 1-5 minutes retrieval time.\nA is more expensive with EFS and less reliable with One-Zone IA.","comment_id":"451352"},{"comment_id":"448584","upvote_count":"1","poster":"andylogan","timestamp":"1636184580.0","content":"It's A"},{"comment_id":"444691","poster":"anandkl80","timestamp":"1635885780.0","content":"AWS DataSync makes it easy for customers to replicate data from one Amazon EFS file system to another without traversing a public network. - https://aws.amazon.com/blogs/storage/transferring-file-data-across-aws-regions-and-accounts-using-aws-datasync/","comments":[{"content":"but A is using Data pipline ,not data sync. So my question is : can data pipeline support cross region EFS?","comment_id":"490528","timestamp":"1638262140.0","poster":"acloudguru","upvote_count":"1"}],"upvote_count":"1"},{"timestamp":"1635802920.0","upvote_count":"1","content":"A correct - while minimizing extra cost","comment_id":"440713","poster":"DerekKey"},{"poster":"student22","content":"A is the best out of the given solution.","comment_id":"440132","upvote_count":"1","timestamp":"1635765900.0"},{"comment_id":"434822","upvote_count":"3","poster":"tgv","content":"AAA\n---\nB and C are ruled out because of Glacier (RTO is 1 hour)\nD is ruled out because EFS does not have a Cross-Region Replication feature","timestamp":"1635578940.0"},{"poster":"TomPaschenda","timestamp":"1635294060.0","comments":[{"content":"A: Correct\nB: Incorrect will fulfill RTO if expedited Retrieval is selected, However, this is not specified in the answer, A is more exact to the requirement than B. If B has the Expedited retrieval this would be the answer, but it is not there. so, the retrieval will take more than 1H and won't comply with requirement RTO 1H.\nC: Data stored in the S3 Glacier Deep Archive storage class has a minimum storage duration period of 180 days and a default RETRIEVAL TIME OF 12 HOURS!!!!!!.\nD: EFS does not have a Cross-Region Replication feature","timestamp":"1635574920.0","comment_id":"433998","poster":"sergioandreslq","upvote_count":"2"}],"upvote_count":"6","comment_id":"417814","content":"Will go with B here as Glacier supports expedited retrievals (1-5 minutes retrieval time)\n\nA - not good for backup because of One-Zone IA (one zone = less reliability)\nB - WILL FULFILL RTO with Expedited Retrievals (see https://docs.aws.amazon.com/amazonglacier/latest/dev/downloading-an-archive-two-steps.html#api-downloading-an-archive-two-steps-retrieval-options)\nC - Fails RTO because of Deep Archive\nD - EFS does not have a Cross-Region Replication feature"},{"upvote_count":"2","poster":"vimgoru24","timestamp":"1634479740.0","content":"Guys, how can you choose A when it’s purpose to store backup. S3 One-Zone IA is not a backup storage.","comment_id":"400038"},{"poster":"zapper1234","comment_id":"399209","comments":[{"content":"There is nothing called cross-region replication with EFS.\nA - Correct\nB - Cannot be restored with an RTO of 1 hour\nC - Cannot be restored with an RTO of 1 hour\nD - Cross-Region replication is an S3 concept. Not valid for EFS.","timestamp":"1634868840.0","upvote_count":"1","poster":"DashL","comment_id":"400276"}],"content":"D is the most complete solution. C is not correct because Glacier, under most circumstances, cannot meet a 1 hour RTO.","upvote_count":"1","timestamp":"1634351400.0"},{"poster":"ogryzek","comment_id":"396923","content":"Using the AWS Data Pipeline to back up your EFS file systems is a legacy solution.\nLooks like an old question","upvote_count":"1","timestamp":"1634284380.0","comments":[{"upvote_count":"1","content":"It's not so old, Datasync is a very new service...","timestamp":"1635108180.0","comment_id":"414196","poster":"WhyIronMan"}]},{"poster":"TonyGe","upvote_count":"3","timestamp":"1634259000.0","comment_id":"391590","content":"A is correct.\nhttps://docs.aws.amazon.com/efs/latest/ug/alternative-efs-backup.html\nUsing AWS Data Pipeline to back up EFS file systems is a legacy backup solution. In this backup solution, you create a data pipeline by using the AWS Data Pipeline service. This pipeline copies data from your Amazon EFS file system (called the production file system) to another Amazon EFS file system (called the backup file system)"},{"poster":"hk436","upvote_count":"1","timestamp":"1634211660.0","comment_id":"385777","content":"A is my answer!!"},{"timestamp":"1633712160.0","comment_id":"365528","poster":"Waiweng","content":"it's A because of RTO is 1 hour","upvote_count":"7"},{"upvote_count":"3","comment_id":"364833","poster":"vkbajoria","content":"None of the options are good. But have to choose A as the best available option.\nB and C do not meet RTO. D is not an option available in EFS","timestamp":"1633603620.0"},{"content":"ld be A . Becasue RTO is 1 hour . S3 glacier Deep Archive take 12 to 48 hours to retrive/restore data https://aws.amazon.com/blogs/storage/storing-data-with-partner-backup-solutions-and-amazon-s3-glacier-deep-archive/","upvote_count":"3","comment_id":"356156","poster":"tvs","timestamp":"1633454700.0"},{"poster":"KnightVictor","comment_id":"354284","upvote_count":"1","content":"Will go for D\nhttps://aws.amazon.com/about-aws/whats-new/2020/01/aws-backup-supports-cross-region-backup/","timestamp":"1633255440.0"},{"upvote_count":"1","comment_id":"352590","timestamp":"1633021080.0","content":"I go with A","poster":"CarisB"},{"timestamp":"1632609300.0","comment_id":"352277","poster":"beebatov","content":"Answer: A\n\nBoth B & C are misleading, EFS has its own storage class, no need for S3.\n\nhttps://docs.aws.amazon.com/efs/latest/ug/alternative-efs-backup.html\nhttps://dzone.com/articles/cross-region-aws-efs-data-transfer-using-aws-datas","upvote_count":"1"},{"poster":"ExtHo","comment_id":"352029","upvote_count":"2","timestamp":"1632505980.0","content":"A pipeline in AWS Data Pipeline to back up your EFS file systems is a legacy solution.\nC AWS DataSync + S3 Glacier Deep Archive storage class will meet RTO of 1 hour?\nB https://docs.aws.amazon.com/efs/latest/ug/alternative-efs-backup.html\nRecommended Amazon EFS backup solutions\nThere are two recommended solutions available for backing up your Amazon EFS file systems.\nAWS Backup service\nThe EFS-to-EFS backup solution\nAny thoughts?","comments":[{"poster":"kpcert","timestamp":"1633243140.0","upvote_count":"1","comment_id":"352636","comments":[{"comment_id":"360669","upvote_count":"2","poster":"Scarback","content":"There is no such thing as \"Turn on EFS Cross-Region Replication and set the secondary Region as the target\". Alternative D is saying that this option is available directly from EFS configurations. It does not mention \"DataSync\".","timestamp":"1633576320.0"}],"content":"You are correct, RTO should be 1 hour, with Options B and C , we cannot achieve the RTO within 1 hr. So it should be A or D.\nD - makes sense we can use Data sync from EFS to secondary region EFS with the lifecycle policy set to move the files to EFS Infrequent Access.\nhttps://aws.amazon.com/about-aws/whats-new/2019/05/aws-datasync-now-supports-efs-to-efs-transfer/"}]},{"content":"Voting for C.","comments":[{"content":"Actually no, voting for A.","comment_id":"347703","poster":"Jaypdv","upvote_count":"2","timestamp":"1632291540.0"}],"poster":"Jaypdv","comment_id":"346197","upvote_count":"2","timestamp":"1632237420.0"},{"comments":[{"content":"trouble with data pipeline is that it is a legacy solution - so C could be more relevant https://docs.aws.amazon.com/efs/latest/ug/alternative-efs-backup.html","poster":"gsw","comment_id":"348705","upvote_count":"2","timestamp":"1632375300.0"}],"timestamp":"1632141840.0","poster":"gsw","comment_id":"346194","upvote_count":"1","content":"A makes sense \"You can now use AWS DataSync to automatically, efficiently, and securely copy files between two Amazon Elastic File System (Amazon EFS) resources, including file systems in different AWS Regions and ones owned by different AWS accounts.\""}],"isMC":true,"topic":"1","unix_timestamp":1619787600,"answer":"D","choices":{"B":"Set up automatic backups by using AWS Backup. Create a copy rule to copy backups to an Amazon S3 bucket in the secondary Region. Create a lifecycle policy to move backups to the S3 Glacier storage class.","A":"Create a pipeline in AWS Data Pipeline. Copy the data to an EFS file system in the secondary Region. Create a lifecycle policy to move files to the EFS One Zone-Infrequent Access storage class.","D":"Turn on EFS Cross-Region Replication and set the secondary Region as the target. Create a lifecycle policy to move files to the EFS Infrequent Access storage class in the secondary Region.","C":"Set up AWS DataSync and continuously copy the files to an Amazon S3 bucket in the secondary Region. Create a lifecycle policy to move files to the S3 Glacier Deep Archive storage class."},"answer_images":[],"question_text":"A company is running a distributed application on a set of Amazon EC2 instances in an Auto Scaling group. The application stores large amounts of data on an\nAmazon Elastic File System (Amazon EFS) file system, and new data is generated monthly. The company needs to back up the data in a secondary AWS Region to restore from in case of a performance problem in its primary Region. The company has an RTO of 1 hour. A solutions architect needs to create a backup strategy while minimizing the extra cost.\nWhich backup strategy should the solutions architect recommend to meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/51253-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["D (100%)"],"exam_id":32},{"id":"vk6Sn2YD5tbZ1s210qF4","url":"https://www.examtopics.com/discussions/amazon/view/51254-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["A (100%)"],"answer_images":[],"choices":{"D":"Configure the Lambda function to store and retrieve the database credentials as encrypted AWS Systems Manager Parameter Store parameters. Create another Lambda function to automatically rotate the credentials. Create an encrypted read replica of the DB instance. Promote the encrypted read replica to be the new primary node.","B":"Enable IAM DB authentication on the DB instance. Grant the Lambda execution role access to the DB instance. Modify the DB instance and enable encryption.","C":"Enable IAM DB authentication on the DB instance. Grant the Lambda execution role access to the DB instance. Create an encrypted read replica of the DB instance. Promote the encrypted read replica to be the new primary node.","A":"Configure the Lambda function to store and retrieve the database credentials in AWS Secrets Manager and enable rotation of the credentials. Take a snapshot of the DB instance and encrypt a copy of that snapshot. Replace the DB instance with a new DB instance that is based on the encrypted snapshot."},"exam_id":32,"unix_timestamp":1619787720,"timestamp":"2021-04-30 15:02:00","answer":"A","answer_ET":"A","question_images":[],"discussion":[{"content":"Answer: A\n\nParameter store can store DB credentials as secure string but CANNOT rotate secrets, hence, go with A + Cannot enable encryption on existing MySQL RDS instance, must create a new encrypted one from unencrypted snapshot.","poster":"beebatov","comments":[{"upvote_count":"1","poster":"AnonymousJhb","comment_id":"543946","timestamp":"1644426720.0","content":"https://aws.amazon.com/blogs/security/rotate-amazon-rds-database-credentials-automatically-with-aws-secrets-manager/#:~:text=Secrets%20Manager%20offers%20built%2Din%20integrations%20for%20rotating%20credentials%20for,rotate%20other%20types%20of%20secrets."}],"comment_id":"352302","upvote_count":"21","timestamp":"1632260940.0"},{"comment_id":"347328","upvote_count":"11","poster":"ExtHo","timestamp":"1632232500.0","content":"A \nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html"},{"comment_id":"655826","timestamp":"1662009300.0","upvote_count":"1","content":"A for sure.","poster":"AYANtheGLADIATOR"},{"content":"My first answer was A","comment_id":"631696","upvote_count":"1","timestamp":"1657881660.0","poster":"CloudHandsOn"},{"upvote_count":"2","timestamp":"1651070580.0","comment_id":"593244","poster":"bobsmith2000","content":"Selected Answer: A\nB and C are wrong because of RDS encryption limitation\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.Limitations\n\nD is incorrect due to parameter store usage. There's no rotation provided by the service"},{"poster":"RVD","timestamp":"1647412080.0","upvote_count":"1","comment_id":"568807","content":"Selected Answer: A\nAns: A"},{"timestamp":"1646292480.0","upvote_count":"1","comment_id":"559883","content":"A is correct","poster":"KennethTam"},{"poster":"ashehzad","content":"Selected Answer: A\nA is the right answer","upvote_count":"1","timestamp":"1643614080.0","comment_id":"536723"},{"content":"Here is why D cannot be correct: https://aws.amazon.com/premiumsupport/knowledge-center/rds-encrypt-instance-mysql-mariadb/\nIn the short description of this link - it specifically states that you cannot create an encrypted read-replica from an unencrypted DB. The only way to set encryption on an RDS instance is during deployment of the initial instance or creating a new instance from a snapshot and selecting the Encryption and Key in the parameters page. So that eliminates B,C,D. D is also incorrect since you would not need to create another Lambda function to rotate the keys - this is a feature included in Secrets Manager OOTB.","upvote_count":"2","timestamp":"1642532460.0","poster":"mattfaz","comment_id":"526938"},{"poster":"RVivek","timestamp":"1640601300.0","content":"Answer: A\nEncrypting a unencrypted instance of DB or creating a encrypted replica of an un encrypted DB instance are not possible Hence A is the only solution possible. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.Limitations","comment_id":"510224","upvote_count":"1"},{"poster":"AzureDP900","timestamp":"1639000680.0","content":"A is correct","upvote_count":"1","comment_id":"497200"},{"upvote_count":"1","timestamp":"1638931620.0","poster":"rogan1821","comment_id":"496487","content":"Selected Answer: A\n지금 사용중"},{"comment_id":"494296","content":"A. Configure the Lambda function to store and retrieve the database credentials in AWS Secrets Manager and enable rotation of the credentials. Take a snapshot of the DB instance and encrypt a copy of that snapshot. Replace the DB instance with a new DB instance that is based on the encrypted snapshot.","timestamp":"1638705600.0","poster":"cldy","upvote_count":"2"},{"upvote_count":"1","poster":"RVD","timestamp":"1637832240.0","comment_id":"486546","content":"Selected Answer: A\nRDS has integration with Secret Manger with Key rotation fuction."},{"comment_id":"485219","poster":"Gaurav_GGG","content":"Answer is A. Secret manager will store and rotate secrets. And need encrypted snapshot to create encryption at rest DB.","timestamp":"1637687520.0","upvote_count":"1"},{"poster":"backfringe","timestamp":"1637389080.0","upvote_count":"1","comment_id":"482287","content":"AAAAAAAAAAAAAAAAA"},{"comment_id":"475233","content":"Option A is correct. Because you can't create an encrypted read replica from an unencrypted instance. https://aws.amazon.com/premiumsupport/knowledge-center/rds-encrypt-instance-mysql-mariadb","poster":"ByomkeshDas","upvote_count":"1","timestamp":"1636522440.0"},{"upvote_count":"1","comment_id":"448586","content":"It's A","poster":"andylogan","timestamp":"1636301100.0"},{"comment_id":"446538","poster":"abdurixit","content":"A is right answer","timestamp":"1635875580.0","upvote_count":"1"},{"poster":"tgv","upvote_count":"1","comment_id":"434824","content":"AAA\n---","timestamp":"1635463200.0"},{"upvote_count":"1","poster":"blackgamer","content":"A is the answer","comment_id":"434455","timestamp":"1635351540.0"},{"content":"AAAAAAAA","upvote_count":"2","poster":"Suresh108","comment_id":"432746","timestamp":"1635101940.0"},{"upvote_count":"4","comment_id":"416085","timestamp":"1634998740.0","content":"Im going for A,\n\nIn other answers to create read replica in encrypted mode seems not correct. The correct way is described at where you should perform an enrcypted snapshot first and then restore.","poster":"Kopa"},{"content":"I'll go with A","poster":"WhyIronMan","upvote_count":"2","timestamp":"1634874900.0","comment_id":"414205"},{"comment_id":"408111","upvote_count":"1","timestamp":"1634276940.0","content":"Answer is A:\nC seems better because there is no password rotation required but the second part of the answer is NOT correct. You cannot create an encrypted read replica from a non-encrypted RDS instance.\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-encrypt-instance-mysql-mariadb/","poster":"student2020"},{"content":"The answer is A, even C is the right way to access the DB this link explains how to move from a No Encrypt DB to an Encrypt DB:\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/encrypt-an-existing-amazon-rds-for-postgresql-db-instance.html","timestamp":"1633956780.0","poster":"zolthar_z","upvote_count":"1","comment_id":"403265"},{"timestamp":"1633741020.0","poster":"vimgoru24","upvote_count":"1","content":"C is better than A since there is nothing to rotate.","comment_id":"399969"},{"content":"It's B. Enable IAM DB auth, attach a role to Lambda and just enable the encryption","comments":[{"timestamp":"1633718580.0","upvote_count":"1","comment_id":"388104","poster":"ivanova","content":"encryption can be done only for new instances (or via snapshot for already running), then A"}],"upvote_count":"1","poster":"ivanova","timestamp":"1633338960.0","comment_id":"388097"},{"poster":"hk436","comment_id":"385778","upvote_count":"1","content":"A is my answer!!","timestamp":"1633257840.0"},{"comments":[{"poster":"johnnyboiii","content":"Can't be C because of the encryption problem:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html\n- You can't have an encrypted read replica of an unencrypted DB instance or an unencrypted read replica of an encrypted DB instance.","timestamp":"1634916000.0","comment_id":"416041","upvote_count":"1"}],"upvote_count":"2","comment_id":"384597","content":"It's C, for database use IAM DB authentication\nhttps://aws.amazon.com/premiumsupport/knowledge-center/users-connect-rds-iam/","poster":"Waiweng","timestamp":"1633182720.0"},{"timestamp":"1632267300.0","poster":"robertomartinez","comment_id":"358544","content":"C : https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html : no pass, no need for rotation","comments":[{"timestamp":"1633106520.0","comment_id":"358551","poster":"robertomartinez","upvote_count":"1","content":"But A, because of , \"Replace the DB instance with a new DB instance that is based on the encrypted snapshot. \" As always, crap confusing wording, even when you know the solution as a non native speaker I can't make sense of the sentences"}],"upvote_count":"1"},{"upvote_count":"3","comment_id":"346199","poster":"Jaypdv","timestamp":"1632142380.0","content":"Going for A."},{"upvote_count":"3","poster":"gsw","content":"should be A","timestamp":"1632126600.0","comment_id":"346196"}],"isMC":true,"topic":"1","question_text":"A company runs an application on AWS. An AWS Lambda function uses credentials to authenticate to an Amazon RDS for MySQL DB instance. A security risk assessment identified that these credentials are not frequently rotated. Also, encryption at rest is not enabled for the DB instance. The security team requires that both of these issues be resolved.\nWhich strategy should a solutions architect recommend to remediate these security risks?","answer_description":"","question_id":734},{"id":"eNoSBhYpGH5LmFZyVMWQ","question_id":735,"url":"https://www.examtopics.com/discussions/amazon/view/51255-exam-aws-certified-solutions-architect-professional-topic-1/","topic":"1","answers_community":["A (100%)"],"answer_images":[],"question_images":[],"isMC":true,"answer_description":"","question_text":"A company recently deployed a new application that runs on a group of Amazon EC2 Linux instances in a VPC. In a peered VPC, the company launched an EC2\nLinux instance that serves as a bastion host. The security group of the application instances allows access only on TCP port 22 from the private IP of the bastion host. The security group of the bastion host allows access to TCP port 22 from 0.0.0.0/0 so that system administrators can use SSH to remotely log in to the application instances from several branch offices.\nWhile looking through operating system logs on the bastion host, a cloud engineer notices thousands of failed SSH logins to the bastion host from locations around the world. The cloud engineer wants to change how remote access is granted to the application instances and wants to meet the following requirements:\n✑ Eliminate brute-force SSH login attempts.\n✑ Retain a log of commands run during an SSH session.\n✑ Retain the ability to forward ports.\nWhich solution meets these requirements for remote access to the application instances?","exam_id":32,"timestamp":"2021-04-30 15:10:00","answer_ET":"C","answer":"A","unix_timestamp":1619788200,"discussion":[{"comment_id":"346206","poster":"Jaypdv","upvote_count":"20","content":"A.\n\"Session Manager removes the need to open inbound ports, manage SSH keys, or use bastion hosts\"\nRef: https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html","timestamp":"1632646200.0"},{"upvote_count":"6","timestamp":"1634048460.0","comment_id":"398729","content":"B\nquestion says \" Retain the ability to forward ports\" - NAT gateway can not do this. Only NAT instance or bastian host is capable to do this.","poster":"SJain50"},{"comment_id":"906234","upvote_count":"1","poster":"Jesuisleon","content":"Why D is not right ?","comments":[{"poster":"vn_thanhtung","content":"Because use \"Systems Manager Run Command\"","comment_id":"997209","timestamp":"1693700820.0","upvote_count":"1"}],"timestamp":"1684978020.0"},{"timestamp":"1655007660.0","comment_id":"615143","upvote_count":"1","content":"A is correct:\nAs its now also support port forwarding\nRef: https://aws.amazon.com/about-aws/whats-new/2022/05/aws-systems-manager-support-port-forwarding-remote-hosts-using-session-manager/","poster":"Shankar124"},{"upvote_count":"2","timestamp":"1653654360.0","comment_id":"608069","poster":"user89","content":"A.\nSession Manager logs the commands you enter and their output during a session depending on your session preferences. so it covers all requirement.\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-logging.html"},{"poster":"tartarus23","timestamp":"1652025720.0","content":"Selected Answer: A\nA. Session manager enables secure SSH Access, port forwarding, and logging of sesssions","comment_id":"598608","upvote_count":"1"},{"poster":"chatvinoth","timestamp":"1641801300.0","content":"I go for A, as session manager also allows port forwarding - Refer below blog\nhttps://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/","upvote_count":"1","comment_id":"520721"},{"timestamp":"1639000920.0","comment_id":"497201","content":"A right answer","poster":"AzureDP900","upvote_count":"1"},{"poster":"andylogan","comment_id":"448589","content":"It's A","upvote_count":"1","timestamp":"1636030140.0"},{"upvote_count":"1","poster":"tgv","comment_id":"434825","content":"AAA\n---\nGood job @ExtHo on sharing:\nRetain a log of commands run during an SSH session. https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-logging.html\nRetain the ability to forward ports. https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/","timestamp":"1635076320.0"},{"content":"A is the answer.","upvote_count":"1","timestamp":"1635043620.0","comment_id":"434457","poster":"blackgamer"},{"poster":"sergioandreslq","comment_id":"434015","upvote_count":"1","content":"A: Incorrect: It is the most secure, However, it does not comply with requirement to: \"Retain the ability to forward ports.\"\nB: Correct: It is the easy way just allowing SSH from offices, the SysAdmins will continue connecting in the same way they are doing today and Retain the ability to forward ports.\nC: Incorrect, It will work but the issue is the amount of work of the deployment for VPN.","comments":[{"content":"changed From B to A. At the end, session manager is the most secure. I like the B because it is faster and easier, but exist the risk of brute force even from the on-premise network. So, the most secure is option A.","comment_id":"436769","poster":"sergioandreslq","timestamp":"1635113700.0","upvote_count":"2"}],"timestamp":"1634782320.0"},{"comment_id":"432751","timestamp":"1634670900.0","content":"AAAAAAA","poster":"Suresh108","upvote_count":"1"},{"upvote_count":"2","poster":"Kopa","timestamp":"1634597400.0","comment_id":"416087","content":"Its A, \n\nSession Manager provides secure and auditable instance management without the need to open inbound ports, maintain bastion hosts, or manage SSH keys. Session Manager also allows you to comply with corporate policies that require controlled access to instances, strict security practices, and fully auditable logs with instance access details, while still providing end users with simple one-click cross-platform access to your managed instances."},{"timestamp":"1634180280.0","upvote_count":"2","comment_id":"414206","content":"I'll go with A","poster":"WhyIronMan"},{"comment_id":"403581","poster":"qurren","content":"https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-logging.html\n\nIt says: \"Logging isn't available for Session Manager sessions that connect through port forwarding or SSH. This is because SSH encrypts all session data, and Session Manager only serves as a tunnel for SSH connections.\" So A is not correct...\n\nI will choose B.","timestamp":"1634069880.0","upvote_count":"2"},{"poster":"hk436","timestamp":"1633966020.0","comment_id":"385779","content":"A is my answer!!\nSession Manager logs the commands you enter and their output during a session depending on your session preferences. To prevent sensitive data, such as passwords, from being viewed in your session logs we recommend using the following commands when entering sensitive data during a session.\n\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-logging.html","upvote_count":"2"},{"upvote_count":"1","poster":"Karthic","timestamp":"1633959300.0","content":"It should be A\nref: https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html","comment_id":"371071"},{"comment_id":"364842","timestamp":"1633341060.0","comments":[{"comment_id":"364848","timestamp":"1633905060.0","poster":"vkbajoria","content":"After reading the link provided by Jaypdv, I am convinced it is \"A\". Plus \"Eliminate brute-force SSH login attempts.\" As long as port 22 is open it will be there eventhough they will all be denied.","upvote_count":"1"}],"upvote_count":"1","content":"I like A alot because this is the new way AWS recommend. B seems like the answer to me based on what the question is asking for. Any thoughts","poster":"vkbajoria"},{"content":"it's A","comment_id":"360353","poster":"Waiweng","upvote_count":"1","timestamp":"1633220220.0"},{"timestamp":"1632913560.0","content":"\"Logging is not available for Session Manager sessions that connect through port forwarding or SSH. This is because SSH encrypts all session data, and Session Manager only serves as a tunnel for SSH connections\"\nAnswer is still D.","comment_id":"353641","upvote_count":"2","poster":"Chibuzo1"},{"poster":"beebatov","upvote_count":"1","comment_id":"352307","content":"Answer: A\n\nSession Manager can do activity logging during session + offers the ability to forward ports.","timestamp":"1632877680.0"},{"timestamp":"1632833880.0","comment_id":"348044","content":"Should be D, they also need to log the commands and run command will do that","poster":"oxfordsolutions","upvote_count":"2"},{"poster":"ExtHo","timestamp":"1632748620.0","content":"A\nRetain a log of commands run during an SSH session.\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-logging.html\n\nRetain the ability to forward ports.\nhttps://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/","comment_id":"347325","upvote_count":"3"},{"poster":"gsw","timestamp":"1632496620.0","content":"It should be A or B, limiting to an IP range is the fastest way to protect against these sort of attacks.","comment_id":"346205","upvote_count":"1"}],"choices":{"B":"Update the security group of the bastion host to allow traffic from only the public IP addresses of the branch offices.","D":"Configure the application instances to communicate with AWS Systems Manager. Grant access to the system administrators to issue commands to the application instances by using Systems Manager Run Command. Terminate the bastion host.","A":"Configure the application instances to communicate with AWS Systems Manager. Grant access to the system administrators to use Session Manager to establish a session with the application instances. Terminate the bastion host.","C":"Configure an AWS Client VPN endpoint and provision each system administrator with a certificate to establish a VPN connection to the application VPC. Update the security group of the application instances to allow traffic from only the Client VPN IPv4 CIDR. Terminate the bastion host."}}],"exam":{"numberOfQuestions":1019,"provider":"Amazon","lastUpdated":"11 Apr 2025","isImplemented":true,"name":"AWS Certified Solutions Architect - Professional","isBeta":false,"id":32,"isMCOnly":false},"currentPage":147},"__N_SSP":true}