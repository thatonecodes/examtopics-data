{"pageProps":{"questions":[{"id":"WfSDIgN4FHiAFNRyrnT3","topic":"1","question_images":[],"answer":"B","question_id":96,"answers_community":["B (100%)"],"unix_timestamp":1669223940,"exam_id":25,"answer_images":[],"question_text":"A developer has built an application running on AWS Lambda using AWS Serverless Application Model (AWS SAM).\n\nWhat is the correct sequence of steps to successfully deploy the application?","choices":{"D":"1. Build the SAM template locally.\n2. Package the SAM template from AWS CodeCommit.\n3. Deploy the SAM template to CodeCommit.","C":"1. Build the SAM template locally.\n2. Deploy the SAM template from Amazon S3.\n3. Package the SAM template for use.","A":"1. Build the SAM template in Amazon EC2.\n2. Package the SAM template to Amazon EBS storage.\n3. Deploy the SAM template from Amazon EBS.","B":"1. Build the SAM template locally.\n2. Package the SAM template onto Amazon S3.\n3. Deploy the SAM template from Amazon S3."},"answer_description":"","isMC":true,"timestamp":"2022-11-23 18:19:00","answer_ET":"B","discussion":[{"content":"sam build => build the code locally\nsam package => creates a .zip file and upload it on S3 and returns a CloudFormation template sam deploy => run the CloudFormation stack and instantiate the resources\n\n(now the command sam deploy also execute sam package first). So, B is the correct answer","poster":"rcaliandro","comment_id":"938181","timestamp":"1688046000.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"891868","content":"Option A is incorrect because Amazon EBS (Elastic Block Store) is not used to store SAM templates. It is a service that provides block-level storage volumes for use with EC2 instances.\n\nOption B is correct because the developer needs to first build the SAM template locally, then package the SAM template and upload it to an S3 bucket. Finally, the developer can deploy the SAM template from S3 using the AWS CLI or AWS Management Console.\n\nOption C is incorrect because it suggests deploying the SAM template directly from S3 without first packaging it, which is not a valid option. Packaging the SAM template is required to create a deployment package that includes the application code and other dependencies.\n\nOption D is incorrect because AWS CodeCommit is a managed source control service that is used to store and manage source code, and not SAM templates. SAM templates can be stored in CodeCommit, but it is not required for deploying the application","timestamp":"1683529380.0","poster":"BATSIE"},{"comments":[{"timestamp":"1703033160.0","upvote_count":"1","poster":"Dipak25","content":"Hope you passed the exam by now. Not all the people knows the explanation. ExamTopics also didn't provide any SME as it is free platform. Now there are explanation given you can see.","comment_id":"1101094"}],"timestamp":"1678732980.0","upvote_count":"4","poster":"fomenkogregory","comment_id":"838172","content":"guys when you choose some variant at least provide a source, or explain your thoughts. Your generic \"I choose B\" doesn't help much as a comment."},{"upvote_count":"1","poster":"ShriniW","content":"Selected Answer: B\nB Is the answer","comment_id":"810993","timestamp":"1676571120.0"},{"upvote_count":"1","content":"B it is","timestamp":"1674170220.0","comment_id":"781686","poster":"sichilam"},{"upvote_count":"1","timestamp":"1669701300.0","comment_id":"729993","content":"Selected Answer: B\nbbbbbbbbb","poster":"michaldavid"},{"timestamp":"1669362840.0","content":"Selected Answer: B\nChoosing B","poster":"k1kavi1","upvote_count":"1","comment_id":"726480"},{"upvote_count":"1","comment_id":"725289","content":"Selected Answer: B\nI agree","timestamp":"1669223940.0","poster":"saysamsuf"}],"url":"https://www.examtopics.com/discussions/amazon/view/88450-exam-aws-certified-developer-associate-topic-1-question-185/"},{"id":"k4EQbvyXoaj12Iz4mRQs","choices":{"D":"Add a new stage to the pipeline. Use Jenkins as the provider. Configure CodePipeline to use Jenkins to run the unit tests. Write a Jenkinsfile that fails the stage if any test does not pass. Use the test report plugin for Jenkins to integrate the report with the Jenkins dashboard. View the test results in Jenkins. Resolve any issues.","C":"Add a new stage to the pipeline. Use AWS CodeBuild as the provider. Add the new stage before the stage that deploys code revisions to the test environment. Write a buildspec that fails the CodeBuild stage if any test does not pass. Use the test reports feature of CodeBuild to integrate the report with the CodeBuild console. View the test results in CodeBuild. Resolve any issues.","A":"Write a Git pre-commit hook that runs the tests before every commit. Ensure that each developer who is working on the project has the pre-commit hook installed locally. Review the test report and resolve any issues before pushing changes to AWS CodeCommit.","B":"Add a new stage to the pipeline. Use AWS CodeBuild as the provider. Add the new stage after the stage that deploys code revisions to the test environment. Write a buildspec that fails the CodeBuild stage if any test does not pass. Use the test reports feature of CodeBuild to integrate the report with the CodeBuild console. View the test results in CodeBuild. Resolve any issues."},"topic":"1","isMC":true,"question_text":"A team of developers is using an AWS CodePipeline pipeline as a continuous integration and continuous delivery (CI/CD) mechanism for a web application. A developer has written unit tests to programmatically test the functionality of the application code. The unit tests produce a test report that shows the results of each individual check. The developer now wants to run these tests automatically during the CI/CD process.\n\nWhich solution will meet this requirement with the LEAST operational effort?","unix_timestamp":1669363080,"exam_id":25,"question_id":97,"timestamp":"2022-11-25 08:58:00","answer_description":"","discussion":[{"poster":"k1kavi1","comment_id":"726484","timestamp":"1669363080.0","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/devops/test-reports-with-aws-codebuild/","upvote_count":"8"},{"upvote_count":"2","comment_id":"938193","poster":"rcaliandro","content":"Selected Answer: C\nWhy some of you guys vote for B? We need to perform tests first and deploy if the tests are ok. \nSo, to integrate tests to the pipeline we can use CodeBuild before the deploy fase (even if the the deploy is in test environment). We have to configure the buildspec saying that if there is at least one failed test, then we have a CodeBuild failure and we stop the deployment.\nSince we also want a report, we can use the test reports feature of CodeBuild to integrate the report with the CodeBuild console and view the test results in CodeBuild. \nSo, The C is correct!","timestamp":"1688046360.0"},{"comment_id":"870584","poster":"Syre","content":"Selected Answer: B\nAnswer is B.\n\nOption C is similar to option B, but it adds the new stage before the stage that deploys code revisions to the test environment. This approach might be useful if the developer wants to ensure that only code revisions that pass the unit tests are deployed to the test environment. However, this approach requires more configuration than option B.","upvote_count":"1","timestamp":"1681527120.0"},{"content":"Selected Answer: C\nC has less operational effort than B because unit tests are run before deployment.","poster":"capesignalfreer","upvote_count":"1","timestamp":"1680063600.0","comment_id":"853998"},{"upvote_count":"2","comment_id":"820382","poster":"MMaquis","content":"Selected Answer: C\nIt is generally recommended to run unit tests before deploying code revisions to the test environment. This allows you to catch and fix any issues in the code before they are deployed to the test environment and potentially cause problems for other team members or stakeholders who are relying on that environment.\n\nTherefore, option C is the correct answer to the question \"Which solution will meet this requirement with the LEAST operational effort?\" as it adds a new stage to the pipeline using AWS CodeBuild as the provider and runs the unit tests before deploying the code revisions to the test environment. This approach allows you to catch and fix any issues with the code before they are deployed to the test environment and helps to ensure that your test environment remains stable and reliable for other team members or stakeholders to use.","timestamp":"1677236400.0"},{"content":"Selected Answer: C\ncccccc","comment_id":"818695","timestamp":"1677120120.0","upvote_count":"1","poster":"jra777"},{"comments":[],"poster":"m4r0ck","content":"Selected Answer: B\nB: you cant' do a unit test for a code that isn't deployed yet","timestamp":"1676991000.0","comment_id":"816691","upvote_count":"2"},{"comments":[{"poster":"isshin","comment_id":"818776","content":"No they are not read carefully. 'b' is after the deployment and 'c' is before.","upvote_count":"1","timestamp":"1677125100.0"}],"upvote_count":"1","content":"Selected Answer: C\nThough its C the option B and C are repeated.","timestamp":"1676571480.0","comment_id":"810997","poster":"ShriniW"},{"comment_id":"804735","timestamp":"1676060520.0","upvote_count":"1","content":"Selected Answer: C\nShould be C","poster":"Krt5894"},{"upvote_count":"1","poster":"sichilam","content":"C it is","timestamp":"1674212640.0","comment_id":"782152"},{"content":"Selected Answer: C\nCCCCCCCCCCCC","poster":"Duded12121","comment_id":"775064","upvote_count":"1","timestamp":"1673667480.0"},{"timestamp":"1671188100.0","poster":"fabriciollf","content":"Selected Answer: C\nC is the correct answer here, we dont need to deploy the application to the test enviroment in order to execute unit tests.","upvote_count":"3","comment_id":"747076"},{"content":"Selected Answer: C\nVote for C","poster":"fswklotto1","upvote_count":"2","timestamp":"1670946360.0","comment_id":"744227"},{"comment_id":"735502","upvote_count":"1","content":"Pretty sure it's C","poster":"hamimelon","timestamp":"1670194200.0"},{"upvote_count":"3","poster":"SoMaL69","timestamp":"1669817940.0","comments":[{"comment_id":"738565","poster":"bindukas","content":"But it's unit tests, not e2e tests. Why do we need env for unit tests?","timestamp":"1670468100.0","upvote_count":"3"}],"content":"Selected Answer: B\nI believe it should be B.\nAs we need deploy app to test env first and then run unit tests","comment_id":"731589"}],"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/88632-exam-aws-certified-developer-associate-topic-1-question-186/","answers_community":["C (79%)","B (21%)"],"question_images":[],"answer_images":[],"answer":"C"},{"id":"Qh17GGG1IPQdpgOtopKL","isMC":true,"unix_timestamp":1669363260,"exam_id":25,"choices":{"C":"Stage data in SQS queues to inject metadata before accessing DynamoDB.","B":"Restrict access to specific items based on certain primary key values.","A":"Encrypt the game data with individual user keys.","D":"Read records from DynamoDB and discard irrelevant data client-side."},"answers_community":["B (100%)"],"answer":"B","timestamp":"2022-11-25 09:01:00","question_text":"A game stores user game data in an Amazon DynamoDB table. Individual users should not have access to other users' game data.\n\nHow can this be accomplished?","answer_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/88633-exam-aws-certified-developer-associate-topic-1-question-187/","answer_ET":"B","question_images":[],"answer_description":"","discussion":[{"poster":"rcaliandro","comment_id":"938197","timestamp":"1688046600.0","upvote_count":"1","content":"Selected Answer: B\nI agree B is the right way. \"Restrict access to specific items based on certain primary key values.\""},{"poster":"Krt5894","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_dynamodb_items.html","timestamp":"1676060520.0","upvote_count":"1","comment_id":"804737"},{"content":"Selected Answer: B\nbbbbbbbbbbbbbbb","upvote_count":"1","poster":"Duded12121","timestamp":"1673668020.0","comment_id":"775067"},{"poster":"michaldavid","upvote_count":"3","content":"Selected Answer: B\nbbbbbbb","comment_id":"729995","timestamp":"1669701480.0"},{"upvote_count":"2","poster":"k1kavi1","comment_id":"726485","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_dynamodb_items.html","timestamp":"1669363260.0"}],"question_id":98},{"id":"pKQRNHf0F1RXbxfkR9ha","isMC":true,"discussion":[{"comment_id":"976281","upvote_count":"1","poster":"jayvarma","content":"As it is not a good practice to create a new IAM user for each user that signs up for the application, Option C is ruled out. Amazon Cognito user pools primary purpose is to authenticate and authorize web and mobile applications. \n\nAs the solution requires the application to store images that are between 300KB and 5MB in size, The idea of storing the images in the DynamoDB is ruled out because the object size in a dynamoDb table cannot exceed 400kb. The ideal solution for this problem would be to store the photos in S3 and store the object's key in the DynamoDB table. \n\nSo, Option B is the right answer","timestamp":"1691559540.0"},{"poster":"rcaliandro","upvote_count":"2","comment_id":"938221","comments":[{"timestamp":"1688047560.0","upvote_count":"2","content":"Part 2) Since we have constraing regarding the pictures (size between 300KB and 5MB), we can't memorize those information on DynamoDB, because the limit for each row in DynamoDB is 400KB even if we don't have this constraint, it is better to memorize the uploaded pictures on a permanent storage rather than the DB. That's why it's better to use S3.\nFinally in order to retrieve the right object, we have to memorize a key (like the name of the bucket, path and object name) on DynamoDB plus other information, like the username, date and so on. Between A and B I would say that B is the correct one!","comment_id":"938222","poster":"rcaliandro"}],"content":"Selected Answer: B\nPart 1) The authentication process is managed by Amazon Cognito users pools. For this reason we can exclude C and D (it's ridicolous to create a IAM user for each user) and can create an user table and manage the authentication but this doesn't meet the requirements because we want the least possible overhead. Since congnito user pools gives us only authorization mechanism, we have to create a cognito authorizer in API Gateway and use this authorizer when we release the methods in order to deny the requests for unauthorized access. So far A and B are both valid.","timestamp":"1688047560.0"},{"upvote_count":"1","content":"Selected Answer: B\ntest BBB","poster":"rcaliandro","timestamp":"1688047500.0","comment_id":"938218"},{"timestamp":"1677746460.0","upvote_count":"1","content":"B is the answer which matches the requirement of the scenario.","comment_id":"826669","poster":"GARGMOH"},{"comment_id":"782168","upvote_count":"2","poster":"sichilam","content":"B it is","timestamp":"1674213960.0"},{"upvote_count":"1","comment_id":"745490","comments":[{"poster":"Duded12121","comments":[{"content":"You actually can store images in DynamoDB if the images are small in size. It is a NoSQL database, that's why it's possible. But the filesizes given in the question are too big to store in DynamoDB. Hence, the answer is B.","comment_id":"815508","poster":"pancman","timestamp":"1676909580.0","comments":[],"upvote_count":"1"}],"timestamp":"1673668260.0","content":"BBB because pictures are not stored in DynamoDB","upvote_count":"2","comment_id":"775068"},{"timestamp":"1680437940.0","upvote_count":"1","comment_id":"858826","poster":"Krok","content":"It's B. Because the max size of DynamoDB item is 400KB."}],"poster":"BelloMio","content":"Why not A?","timestamp":"1671055680.0"},{"content":"Selected Answer: B\nbbbbbb","comment_id":"730010","poster":"michaldavid","upvote_count":"1","timestamp":"1669702980.0"},{"content":"Selected Answer: B\nI agree","upvote_count":"1","poster":"k1kavi1","comment_id":"726523","timestamp":"1669365360.0","comments":[{"poster":"k1kavi1","upvote_count":"5","comment_id":"726527","content":"DynamoDB Item limits :The maximum item size in DynamoDB is 400 KB, which includes both attribute name binary length (UTF-8 length) and attribute value lengths (again binary length). The attribute name counts towards the size limit.\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ServiceQuotas.html\nBest practices for storing large items and attributes - https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-use-s3-too.html","timestamp":"1669365840.0"}]}],"question_id":99,"topic":"1","unix_timestamp":1669365360,"answer_images":[],"answer":"B","answer_ET":"B","choices":{"D":"Create a user’s table in DynamoDB. Use the table to manage user accounts. Create a Lambda authorizer that validates user credentials against the users table. Integrate the Lambda authorizer with API Gateway to control access to the API. Use the Lambda function to store the photos in Amazon S3. Store the object's S3 key as part of the photo details in the DynamoDB table. Retrieve previously uploaded photos by querying DynamoDB for the S3 key.","B":"Use Amazon Cognito user pools to manage user accounts. Create an Amazon Cognito user pool authorizer in API Gateway to control access to the API. Use the Lambda function to store the photos in Amazon S3. Store the object's S3 key as part of the photo details in the DynamoDB table. Retrieve previously uploaded photos by querying DynamoDB for the S3 key.","C":"Create an IAM user for each user of the application during the sign-up process. Use IAM authentication to access the API Gateway API. Use the Lambda function to store the photos in Amazon S3. Store the object's S3 key as part of the photo details in the DynamoDB table. Retrieve previously uploaded photos by querying DynamoDB for the S3 key.","A":"Use Amazon Cognito user pools to manage user accounts. Create an Amazon Cognito user pool authorizer in API Gateway to control access to the API. Use the Lambda function to store the photos and details in the DynamoDB table. Retrieve previously uploaded photos directly from the DynamoDB table."},"question_text":"A developer is creating an application that will give users the ability to store photos from their cellphones in the cloud. The application needs to support tens of thousands of users. The application uses an Amazon API Gateway REST API that is integrated with AWS Lambda functions to process the photos. The application stores details about the photos in Amazon DynamoDB.\n\nUsers need to create an account to access the application. In the application, users must be able to upload photos and retrieve previously uploaded photos. The photos will range in size from 300 KB to 5 MB.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","timestamp":"2022-11-25 09:36:00","question_images":[],"exam_id":25,"answer_description":"","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/88645-exam-aws-certified-developer-associate-topic-1-question-188/"},{"id":"ChiUhlNKp0VhItSN6ncd","url":"https://www.examtopics.com/discussions/amazon/view/88646-exam-aws-certified-developer-associate-topic-1-question-189/","answers_community":["C (100%)"],"answer":"C","answer_ET":"C","question_id":100,"unix_timestamp":1669366080,"isMC":true,"discussion":[{"poster":"rushi0611","upvote_count":"1","comment_id":"957502","content":"Selected Answer: C\nLowest LATENCY = Memcache","timestamp":"1689853560.0"},{"poster":"rcaliandro","upvote_count":"1","content":"Selected Answer: C\nLow latency, we have to chooes Elastic Cache memcache Cluster. I'll go for C","comments":[{"comments":[{"upvote_count":"1","content":"Cluster is property for Amazon ElastiCache Memcached. Check following link https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/WhatIs.html","timestamp":"1703085840.0","poster":"Dipak25","comment_id":"1101680"}],"poster":"rcaliandro","upvote_count":"2","comment_id":"938235","content":"Why it is specified \"cluster\". This should be an Elastic Cache Redis property, shouldn't be?","timestamp":"1688048100.0"}],"timestamp":"1688047920.0","comment_id":"938233"},{"upvote_count":"1","timestamp":"1683532620.0","comment_id":"891901","poster":"BATSIE","content":"Amazon ElastiCache is a managed in-memory data store that is optimized for low-latency operations. Using a Memcached cluster to store session data can provide fast access to the data, and is designed for high-throughput scenarios. D can work but will require addional additional setup and configuration compared to ElastiCache Memcached."},{"timestamp":"1677018840.0","poster":"GD_ZH","comment_id":"817238","comments":[{"comment_id":"1101677","timestamp":"1703085780.0","content":"Where did you get Amazon ElastiCache Memcached does not support cluster? Check following link https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/WhatIs.html","upvote_count":"1","poster":"Dipak25"}],"content":"It should be D. Amazon ElastiCache Memcached does not support cluster, only Redis supports cluster.","upvote_count":"2"},{"content":"Selected Answer: C\nWhich is faster DynamoDB or ElastiCache?\nCompared to traditional databases, which are usually double-digit milliseconds, ElastiCache is much faster and serves the purpose of an in-memory data store.","comment_id":"797268","timestamp":"1675449900.0","poster":"gaddour_med","upvote_count":"1"},{"content":"C it is","comment_id":"782170","upvote_count":"1","poster":"sichilam","timestamp":"1674214320.0"},{"poster":"hamimelon","upvote_count":"2","comments":[{"poster":"Mark1000","content":"\"keeping latency at the LOWEST\" --> elasticache","timestamp":"1672326600.0","upvote_count":"1","comment_id":"761175"}],"content":"What's wrong with D?","comment_id":"735504","timestamp":"1670194380.0"},{"comments":[{"content":"https://www.examtopics.com/discussions/amazon/view/7029-exam-aws-certified-developer-associate-topic-1-question-193/","poster":"k1kavi1","timestamp":"1669820100.0","upvote_count":"2","comment_id":"731629"}],"comment_id":"726530","content":"Selected Answer: C\nhttps://www.amazonaws.cn/en/elasticache/memcached/","timestamp":"1669366080.0","poster":"k1kavi1","upvote_count":"2"}],"answer_images":[],"topic":"1","answer_description":"","timestamp":"2022-11-25 09:48:00","choices":{"B":"Implement a shared file system solution across the underlying Amazon EC2 instances, then implement session handling at the application level to leverage the shared file system for session data storage.","C":"Create an Amazon ElastiCache Memcached cluster, then implement session handling at the application level to leverage the cluster for session data storage.","D":"Create an Amazon DynamoDB table, then implement session handling at the application level to leverage the table for session data storage.","A":"Create an Amazon RDS instance, then implement session handling at the application level to leverage a database inside the RDS database instance for session data storage."},"question_images":[],"exam_id":25,"question_text":"A developer is building a three-tier web application that should be able to handle a minimum of 5000 requests per minute. Requirements state that the web tier should be completely stateless while the application maintains session state for the users.\n\nHow can session data be externalized, keeping latency at the LOWEST possible value?"}],"exam":{"name":"AWS Certified Developer Associate","provider":"Amazon","id":25,"numberOfQuestions":443,"lastUpdated":"11 Apr 2025","isBeta":false,"isMCOnly":true,"isImplemented":true},"currentPage":20},"__N_SSP":true}