{"pageProps":{"questions":[{"id":"CqogeUnjdrkoy44EcC5s","isMC":true,"unix_timestamp":1685101740,"exam_id":33,"question_images":[],"question_text":"An online retail company is migrating its legacy on-premises .NET application to AWS. The application runs on load-balanced frontend web servers, load-balanced application servers, and a Microsoft SQL Server database.\n\nThe company wants to use AWS managed services where possible and does not want to rewrite the application. A solutions architect needs to implement a solution to resolve scaling issues and minimize licensing costs as the application scales.\n\nWhich solution will meet these requirements MOST cost-effectively?","answers_community":["A (85%)","C (15%)"],"timestamp":"2023-05-26 13:49:00","url":"https://www.examtopics.com/discussions/amazon/view/110298-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"D":"Separate the application functions into AWS Lambda functions. Use Amazon API Gateway for the web frontend tier and the application tier. Migrate the data to Amazon S3. Use Amazon Athena to query the data.","C":"Containerize the web frontend tier and the application tier. Provision an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. Create an Auto Scaling group behind a Network Load Balancer for the web tier and for the application tier. Use Amazon RDS for SQL Server to host the database.","B":"Create images of all the servers by using AWS Database Migration Service (AWS DMS). Deploy Amazon EC2 instances that are based on the on-premises imports. Deploy the instances in an Auto Scaling group behind a Network Load Balancer for the web tier and for the application tier. Use Amazon DynamoDB as the database tier.","A":"Deploy Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer for the web tier and for the application tier. Use Amazon Aurora PostgreSQL with Babelfish turned on to replatform the SQL Server database."},"question_id":121,"answer_images":[],"topic":"1","answer_description":"","answer_ET":"A","discussion":[{"content":"Selected Answer: A\n\"does not want to rewrite the application. \" leaves the possible answer between A and C, cause B and D will force the application team to rewrite the data access part of the application.\nC is using EKS, which makes AutoScalingGroup is not required. ASG scales instances. ASG doesn't scale PODs in EKS. \nBabelfish is the key point in this question. \"Babelfish for Aurora PostgreSQL is a new capability for Amazon Aurora PostgreSQL-Compatible Edition that enables Aurora to understand commands from applications written for Microsoft SQL Server.\"","poster":"bjexamprep","upvote_count":"12","comment_id":"1101283","timestamp":"1703051700.0"},{"comment_id":"911319","upvote_count":"6","content":"Selected Answer: A\nThere is no good solution here. A is just forcing that company to use AWS services as \"MOST cost-effectively\" alternative. Practically Bablefish has bad reviews, companies prefer to migrate SQL-Server as-is.","poster":"F_Eldin","timestamp":"1685539260.0"},{"content":"Selected Answer: A\nThe key is 'minimise licensing cost' so, option A is the best because it can radically cut down the SQL Server licensing cost by putting it to Aurora PostgreSQL. Option C has equivalent licensing cost since it is SQL RDS.","upvote_count":"1","comment_id":"1330196","timestamp":"1734817980.0","poster":"SIJUTHOMASP"},{"upvote_count":"1","content":"Selected Answer: C\nOption C is the most cost-effective solution as it leverages containerization with Amazon EKS, Auto Scaling groups with Network Load Balancers, and Amazon RDS for SQL Server. This approach allows for efficient scaling, resource utilization, and minimizes licensing costs without requiring significant application changes.\n\nContainerizing the web and application tiers enables portability and scalability. Amazon EKS provides a fully managed Kubernetes service, reducing operational overhead. Auto Scaling groups and Network Load Balancers enable automatic scaling based on demand. Amazon RDS for SQL Server offers a fully managed database service with various licensing models, including BYOL, to optimize costs as the application scales.\n\nThe other options have drawbacks, such as requiring replatforming the database (Option A), significant application changes (Option B), or a complete rewrite (Option D), which goes against the requirements.","comment_id":"1308953","timestamp":"1731113700.0","poster":"0b43291"},{"content":"Selected Answer: C\nAll answers are wrong. A is not using managed services where possible (EKS would be better than EC2 and can run windows) and on C you can't have Auto Scaling group for EKS. Realistically C is the better option if scaled with Karpenter, etc.","upvote_count":"1","timestamp":"1722455580.0","poster":"8693a49","comment_id":"1259075","comments":[{"upvote_count":"1","poster":"helloworldabc","timestamp":"1724293380.0","comment_id":"1270461","content":"just A"}]},{"comment_id":"1205887","poster":"BrijMohan08","content":"Selected Answer: C\nKey here is AWS Managed = EKS\nA. Says both Web tier and Application tier is behind ALB, which is not secure. \nA good design should have web tier behind ALB, and application tier behind NLB","timestamp":"1714696920.0","upvote_count":"1"},{"comment_id":"1174270","upvote_count":"1","timestamp":"1710507360.0","poster":"TonytheTiger","content":"Selected Answer: A\nOption A: Babelfish for Aurora PostgreSQL is a capability for Amazon Aurora PostgreSQL-Compatible Edition developed using the PostgreSQL extension framework that enables Aurora to understand commands from applications written for Microsoft SQL Server. Babelfish for Aurora PostgreSQL understands T-SQL, Microsoft SQL Server’s SQL dialect, and supports\n\n https://aws.amazon.com/blogs/database/run-sql-server-reporting-services-reports-against-babelfish-for-aurora-postgresql/"},{"comment_id":"1078150","content":"Selected Answer: A\nOption A","timestamp":"1700722080.0","upvote_count":"1","poster":"career360guru"},{"content":"Selected Answer: C\nAs much as I would like to choose A but the question request for lift and shift approach rather than a replatform","timestamp":"1700577240.0","upvote_count":"2","poster":"Pupu86","comment_id":"1076374"},{"timestamp":"1700237400.0","content":"Selected Answer: C\nI vote C. Babelfish - another layer to keep an eye on. Is it really going to translate all SQL app calls perfectly, or will they need tuning?","comment_id":"1073466","upvote_count":"1","poster":"enk"},{"timestamp":"1693721340.0","content":"why not C","comments":[{"content":"C would be probably the most realistic way a team work to engage such case regarding to the choices we have. However Babelfish is a tool made to execute Microsoft SQL on a postgreSQL server. In practice Babelfish is a toy and should not be used for a real strong usage since the database engine is the last thing you want to play with. Still, people who answered A have followed the theory, and it's probably the expected answer here.","comment_id":"1065188","poster":"Mikado211","timestamp":"1699394580.0","upvote_count":"3"}],"comment_id":"997365","upvote_count":"1","poster":"kjcncjek"},{"comment_id":"989243","content":"A : the best of the worst","timestamp":"1692885780.0","poster":"chikorita","upvote_count":"3"},{"poster":"ggrodskiy","upvote_count":"1","timestamp":"1690148460.0","comment_id":"960851","content":"Correct A."},{"comments":[{"poster":"rxhan","comment_id":"971186","upvote_count":"1","timestamp":"1691072580.0","content":"golden."}],"comment_id":"944232","poster":"YodaMaster","timestamp":"1688608560.0","content":"Selected Answer: A\nA. The other options sound fishy.","upvote_count":"5"},{"comment_id":"944164","upvote_count":"2","content":"Selected Answer: A\nA by elimination","poster":"NikkyDicky","timestamp":"1688598360.0"},{"upvote_count":"1","comment_id":"929870","poster":"easytoo","timestamp":"1687377180.0","content":"a-a-a-a-a-a-a\n\nafter much consideration it's the babelfish to the rescue - \nzaphod beeblebrox ftw"},{"comment_id":"910603","poster":"rbm2023","timestamp":"1685482440.0","content":"Selected Answer: A\nAgree with A the NLB with EKS might be a interesting choice if chose too fast. \nThe correct option should be A, using an ALB and rehost to from M SQL Server to Aurora using Belfish.\nhttps://aws.amazon.com/rds/aurora/babelfish/\n\"With Babelfish, Aurora PostgreSQL now understands T-SQL, Microsoft SQL Server's proprietary SQL dialect, and supports the same communications protocol, so your apps that were originally written for SQL Server can now work with Aurora with fewer code changes\"","upvote_count":"3"},{"content":"Selected Answer: A\nAnswer is A. B and C are wrong as putting web apps behind NLB is not the correct approach. Also D is wrong as having SQL DB on S3 is impossible to do it straight forward, will require to refactor everything in the backend side and data layer side.","poster":"andreitugui","upvote_count":"2","comment_id":"910043","timestamp":"1685433360.0"},{"content":"Answer : A\nIt includes a network end-point added to PostgreSQL to enable your PostgreSQL database to understand the SQL Server wire protocol and commonly used SQL Server commands. With Babelfish, applications that were originally built for SQL Server can work directly with PostgreSQL, with little to no code changes, and without changing database drivers.","comments":[{"comment_id":"908897","poster":"ShinLi","upvote_count":"1","content":"agree A https://aws.amazon.com/rds/aurora/babelfish/","timestamp":"1685313900.0"}],"poster":"Roontha","timestamp":"1685101740.0","comment_id":"907322","upvote_count":"4"}],"answer":"A"},{"id":"fDPL2X3YwRkJgZPxevhx","exam_id":33,"topic":"1","discussion":[{"timestamp":"1685433600.0","comments":[{"upvote_count":"1","timestamp":"1724852340.0","poster":"sam2ng","content":"as the ALB and EKS are running in one region only which is us-east-1, how does the global accelerator help when traffic comes from other region e.g. EU ?\nAlso you don't configure origin in global accelerator, you configure endpoint group.","comment_id":"1274084"},{"upvote_count":"2","content":"Yes you can, see - https://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-how-it-works.html\n\n--> For standard accelerators, the endpoints are Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses.","comment_id":"914568","timestamp":"1685881320.0","poster":"nexus2020"}],"poster":"andreitugui","upvote_count":"10","content":"Selected Answer: C\nAWS Global Accelerator is a service that improves the availability and performance of applications for global users. By adding an accelerator in AWS Global Accelerator and configuring the ALB as the origin, the traffic from users outside the United States will be routed through the Global Accelerator network, which uses the AWS global network infrastructure to optimize the delivery of the application traffic.","comment_id":"910044"},{"timestamp":"1702549680.0","upvote_count":"5","poster":"ayadmawla","content":"Selected Answer: C\nimho answer is C. Here is my thinking: There are two issues that we need to consider:\n1- Non US Users are reporting long and inconsistent response times for these APIs\n2- The APIs are running in EKS and are exposed by the ALB (i.e., not the other way round)\n\nSo the issue is about latency not API design.","comment_id":"1096345"},{"content":"Selected Answer: C\nC","comment_id":"1292960","timestamp":"1727996280.0","poster":"fabriciollf","upvote_count":"1"},{"upvote_count":"2","comment_id":"1234451","content":"Selected Answer: C\nNot B. Because Gateway Edge-Optimized API Endpoint improve the performance by caching API responses. But (un)link the call is not supported by API Gateway so the rest will be passed to ALB anyway. So unlikely API gateway will cache and no benefit for performance improvement.","timestamp":"1718979000.0","poster":"Helpnosense"},{"content":"Selected Answer: C\nAnswer: C\n\nAWS Global Accelerator is a service in which you create accelerators to improve the performance of your applications for local and global users.\nhttps://docs.aws.amazon.com/global-accelerator/latest/dg/what-is-global-accelerator.html\n\nWhen you create an ALB or NLB, you can optionally add an accelerator at the same time. Elastic Load Balancing and Global Accelerator work together to transparently add the accelerator for you. The accelerator is created in your account, with the load balancer as an endpoint. Using an accelerator provides static IP addresses and improves the availability and performance of your applications.\nhttps://docs.aws.amazon.com/global-accelerator/latest/dg/about-accelerators.alb-accelerator.html","poster":"titi_r","timestamp":"1715118240.0","comment_id":"1208047","upvote_count":"1","comments":[{"comment_id":"1208054","poster":"titi_r","timestamp":"1715118780.0","upvote_count":"4","content":"Ans “B” is wrong, because API Gateway does NOT support non-standard REST methods. The supported methods are DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT, and ANY (which can substitute any of the other 7).\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-method-settings-method-request.html#setup-method-add-http-method ."}]},{"comment_id":"1149674","upvote_count":"2","poster":"dankositzke","timestamp":"1707869280.0","content":"Selected Answer: D\nA: No\nB: No, API Gateway doesn’t support LINK, UNLINK, LOCK, UNLOCK.\nC: No, GA doesn’t have the concept of “origin” - this is a CloudFront concept.\nD: Yes, because this addresses the main concern which is latency."},{"poster":"duriselvan","content":"b IS ANS\nMinimal operational overhead: API Gateway edge-optimized endpoints offer several advantages:\n\nReduced latency: They leverage AWS's global network of edge locations, significantly reducing latency for users outside the United States.\nScalability: They automatically scale to handle traffic spikes, eliminating the need for manual intervention.\nSecurity: They offer built-in security features, including access control and throttling, minimizing the need for additional configuration.\nNon-standard methods compatibility: API Gateway supports a wide range of HTTP methods, including custom methods like LINK, UNLINK, LOCK, and UNLOCK, ensuring compatibility with the existing APIs.\n\nEase of configuration: Configuring API Gateway with ALB as the target is straightforward and requires minimal changes to the existing infrastructure.","comment_id":"1092621","timestamp":"1702224180.0","upvote_count":"1"},{"content":"Selected Answer: B\nAmazon CloudFront primarily supports standard HTTP/HTTPS request methods like GET, POST, PUT, DELETE, HEAD, OPTIONS, and PATCH. It does not natively support non-standard methods such as LINK and UNLINK, LOCK...etc\nHOWEVER>>>>>\nIf you need to use these non-standard methods, you have a couple of options:\nCustom Handling with Lambda@Edge\nAPI Gateway Integration: If you require more complex routing and method handling, integrating AWS API Gateway with CloudFront might be a more suitable solution. API Gateway provides robust support for various HTTP methods and can be set up to handle non-standard methods.\n\nClearly its B","upvote_count":"3","comment_id":"1088595","poster":"awsamar","timestamp":"1701790020.0"},{"content":"Selected Answer: C\nOption C, GA is safest option.","poster":"career360guru","timestamp":"1700722560.0","comment_id":"1078153","upvote_count":"1"},{"poster":"severlight","upvote_count":"2","content":"Selected Answer: C\nthere is no proper use case for API gateway here","comment_id":"1073856","timestamp":"1700295360.0"},{"poster":"joleneinthebackyard","content":"Selected Answer: C\nA is invalid because cloudFront only support standard Rest Methods\nB C D all technically feasible but let's consider \"minimized operational overhead\" requirement, it's must be C.","timestamp":"1698792780.0","upvote_count":"2","comment_id":"1059239"},{"poster":"chico2023","comment_id":"985388","content":"Selected Answer: B\nAnswer: B\nI don't understand why people are choosing GA. I would rather go with option D.\n\nFrom AWS documentation: \n\nEdge-optimized API endpoint\nThe default hostname of an API Gateway API that is deployed to the specified Region while using a CloudFront distribution to facilitate client access typically from across AWS Regions. API requests are routed to the nearest CloudFront Point of Presence (POP), which typically improves connection time for geographically diverse clients.\n\nI couldn't find any document mentioning that Edge-optimized API endpoints won't support non-standard REST methods.","timestamp":"1692472140.0","comments":[{"comment_id":"985393","comments":[{"content":"Now, why would I use GA? \n\nI don't know you, but I would use in a situation where I have an application that connects to a database and I need to reduce the latency of my application for users by launching EC2 instances around the world. Note that I can't do that (not that easy, at least) with my RDS DB, so what I do? I use Global Accelerator to speed up communication between my instances in different countries to the database server in a single location, for example.","upvote_count":"1","poster":"chico2023","timestamp":"1692472740.0","comment_id":"985395"}],"poster":"chico2023","timestamp":"1692472440.0","upvote_count":"1","content":"I know we can't trust AI assistants, but take a look at my little chat with:\n\n=== Labiba\nYes, Amazon API Gateway Edge-optimized APIs can handle non-standard REST methods. Edge-optimized APIs are designed to provide low-latency access to your API by using the AWS CloudFront global network. You can set up API methods to handle any HTTP method, including non-standard ones, and configure them to work with your specific requirements and use cases.\n\n=== Bard\nYes, Amazon API Gateway edge-optimized APIs can handle non-standard REST methods. However, there are some limitations.\n\nThe non-standard REST method must be supported by the integration that you use for the API method. For example, if you are using a Lambda integration, the Lambda function must be able to handle the non-standard REST method."},{"timestamp":"1692874320.0","content":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html#api-gateway-api-endpoint-types-edge-optimized:~:text=traffic%20originates%20from.-,Edge%2Doptimized%20API%20endpoints,-An%20edge%2Doptimized\nI think can help you, C is answer","poster":"vn_thanhtung","upvote_count":"1","comment_id":"989103"}],"upvote_count":"2"},{"upvote_count":"4","poster":"Arnaud92","content":"Selected Answer: C\nCloudfront cannot handle non standard REST methods. There are Clod front involved behind API Gateway edge-optimized. So only C make sense here","comment_id":"970089","timestamp":"1690975080.0"},{"upvote_count":"3","comment_id":"957341","content":"Selected Answer: B\nIt only can B... \nHere is a AWS entry. https://repost.aws/knowledge-center/api-gateway-cloudfront-distribution","poster":"Just_Ninja","timestamp":"1689844080.0"},{"content":"Selected Answer: C\nB would be nice if edge-optimized was supported for HTTP APIs","comment_id":"944173","upvote_count":"3","timestamp":"1688599500.0","poster":"NikkyDicky"},{"poster":"SandyIndia","content":"Selected Answer: C\nBy adding an accelerator in AWS Global Accelerator and configuring the ALB as the origin, the traffic to the ALB will be routed through the global network, reducing latency and improving response times for users outside the United States.\nThis solution minimizes operational overhead as AWS Global Accelerator handles the routing and optimization automatically, without requiring additional infrastructure deployment or configuration changes.","comment_id":"933436","timestamp":"1687686600.0","upvote_count":"3"},{"upvote_count":"4","content":"Selected Answer: C\nI was also supporting answer B, however just tested API Gateway and it seems that it only supports GET, POST, PUT, PATCH, DELETE, HEAD, and OPTIONS methods. I personally couldn't find a way to create a custom method which is part of the requirement. Please share if you find a way","poster":"Maria2023","comment_id":"932554","timestamp":"1687612080.0"},{"comment_id":"931005","upvote_count":"3","poster":"SmileyCloud","timestamp":"1687465320.0","comments":[{"timestamp":"1687686960.0","poster":"SandyIndia","content":"Option B suggests adding an Amazon API Gateway edge-optimized API endpoint with the ALB as the target. While API Gateway can provide API management capabilities, it may not directly address the latency issue for non-standard REST methods.","comment_id":"933442","upvote_count":"3"}],"content":"Selected Answer: B\nIt's B. That's the point of an edge-optimized API endpoint."},{"upvote_count":"1","timestamp":"1687377300.0","poster":"easytoo","comment_id":"929874","content":"c-c-cc-cc-c-cc--c-c-c-c-c"},{"comment_id":"925493","upvote_count":"2","timestamp":"1686942480.0","poster":"gd1","content":"The solution that meets these requirements most effectively would be:\n\nA. Add an Amazon CloudFront distribution. Configure the ALB as the origin.\n\nCloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency and high transfer speeds. By configuring CloudFront with your Application Load Balancer (ALB) as the origin, users can access your API through the CloudFront edge location that's closest to them, reducing latency.\n\nOption B, Amazon API Gateway, does not support non-standard REST methods. Option C, AWS Global Accelerator, is a networking service that improves your applications' availability and performance, but its benefits are more noticeable for TCP/UDP-based workloads rather than HTTP(S)-based APIs. Option D, deploying the APIs in multiple regions and using Amazon Route 53 latency-based routing, would require much more operational overhead compared to the recommended solution."},{"timestamp":"1685816760.0","comments":[{"upvote_count":"1","timestamp":"1685817000.0","content":"Why I think C is WRONG ? GA is usually for TCP/UDP level, in this question it explictly points to rest api which is at OSI 7 layer(https://stackoverflow.com/questions/29264855/in-which-osi-layer-is-the-rest-api-paradigm), so GA is not suitable here.","poster":"Jesuisleon","comment_id":"913867"}],"poster":"Jesuisleon","comment_id":"913864","upvote_count":"3","content":"Selected Answer: B\nI prefer B as in the question it emphasize API, edge-optimized API is perfact for the global users.\n\"An edge-optimized API endpoint is best for geographically distributed clients. API requests are routed to the nearest CloudFront Point of Presence (POP). This is the default endpoint type for API Gateway REST APIs.\" from \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html"},{"comments":[{"poster":"rbm2023","content":"in addition the cloud front solution may not support the methods informed in the question - Option A. \nD requires too much overhead.","comment_id":"910597","upvote_count":"2","timestamp":"1685480940.0"}],"comment_id":"910593","poster":"rbm2023","content":"Selected Answer: C\nIn my view you can use Global Accelerator with a load balancer. \nI vote for C.\nhttps://cloudonaut.io/review-aws-global-accelerator-latency-multi-region-disaster-recovery/","upvote_count":"1","timestamp":"1685480760.0"},{"content":"Selected Answer: A\nA should be the answer as @deegadaze1 explanation","comment_id":"908850","upvote_count":"1","timestamp":"1685304600.0","poster":"AMEJack"},{"poster":"deegadaze1","upvote_count":"1","content":"Answer is : A\nNo, you cannot directly configure an Application Load Balancer (ALB) as the origin for an accelerator in AWS Global Accelerator.\n\nAWS Global Accelerator is designed to improve the availability and performance of applications running over TCP or UDP protocols. It directs client traffic to the nearest AWS edge location and then routes it to your application's endpoints, such as Elastic IP addresses, Network Load Balancers (NLBs), or EC2 instances.\nOn the other hand, AWS Global Accelerator primarily focuses on improving the availability and reliability of TCP and UDP-based applications by directing traffic through the AWS global network backbone. While Global Accelerator can improve performance for certain use cases, such as minimising connection setup times, it may not provide the same level of optimisation for API response times compared to CloudFront.","timestamp":"1685245800.0","comment_id":"908313","comments":[{"timestamp":"1685881620.0","content":"https://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-components.html\n\nEndpoint\nAn endpoint is the resource that Global Accelerator directs traffic to.\n\nEndpoints for standard accelerators can be Network Load Balancers, Application Load Balancers, EC2 instances, or Elastic IP addresses. An Application Load Balancer endpoint can be an internet-facing or internal. Traffic for standard accelerators is routed to endpoints based on the health of the endpoint along with configuration options that you choose, such as endpoint weights. For each endpoint, you can configure weights, which are numbers that you can use to specify the proportion of traffic to route to each one. This can be useful, for example, to do performance testing within a Region.","comment_id":"914573","poster":"nexus2020","upvote_count":"1","comments":[{"content":"Well, not sure what were supported in the past, however as of today in the link above, ALB is supported as orgin/endpoint behind the Global Accelerator","comment_id":"914575","timestamp":"1685881680.0","upvote_count":"2","poster":"nexus2020"}]},{"poster":"chathur","upvote_count":"3","content":"Global accelerator can expose an ALB\nhttps://aws.amazon.com/global-accelerator/faqs/#:~:text=If%20you%20have%20workloads%20hosted%20in%20a%20single%20AWS%20Region%20and%20used%20by%20clients%20in%20and%20around%20the%20same%20Region%2C%20you%20can%20use%20an%20Application%20Load%20Balancer%20or%20Network%20Load%20Balancer%20to%20manage%20your%20resources.","timestamp":"1685814540.0","comment_id":"913852"}]},{"comment_id":"907733","upvote_count":"4","poster":"Masonyeoh","timestamp":"1685159580.0","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/accessing-an-aws-api-gateway-via-static-ip-addresses-provided-by-aws-global-accelerator/"},{"upvote_count":"2","timestamp":"1685101440.0","content":"Answer : A\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCustomOrigins.html","comment_id":"907317","comments":[{"upvote_count":"3","timestamp":"1685189700.0","poster":"Roontha","comment_id":"907969","content":"My bad...Answer : C","comments":[{"upvote_count":"1","timestamp":"1705186440.0","content":"I am following you Roontha. Big thank you.","comment_id":"1122105","poster":"JMAN1"}]}],"poster":"Roontha"}],"isMC":true,"timestamp":"2023-05-26 13:44:00","question_id":122,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/110297-exam-aws-certified-solutions-architect-professional-sap-c02/","question_images":[],"unix_timestamp":1685101440,"choices":{"B":"Add an Amazon API Gateway edge-optimized API endpoint to expose the APIs. Configure the ALB as the target.","C":"Add an accelerator in AWS Global Accelerator. Configure the ALB as the origin.","A":"Add an Amazon CloudFront distribution. Configure the ALB as the origin.","D":"Deploy the APIs to two additional AWS Regions: eu-west-1 and ap-southeast-2. Add latency-based routing records in Amazon Route 53."},"answer":"C","answer_images":[],"question_text":"A software-as-a-service (SaaS) provider exposes APIs through an Application Load Balancer (ALB). The ALB connects to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster that is deployed in the us-east-1 Region. The exposed APIs contain usage of a few non-standard REST methods: LINK, UNLINK, LOCK, and UNLOCK.\n\nUsers outside the United States are reporting long and inconsistent response times for these APIs. A solutions architect needs to resolve this problem with a solution that minimizes operational overhead.\n\nWhich solution meets these requirements?","answer_description":"","answers_community":["C (72%)","B (23%)","3%"]},{"id":"fgPu16BV9DzpW9wDZ2yr","url":"https://www.examtopics.com/discussions/amazon/view/112693-exam-aws-certified-solutions-architect-professional-sap-c02/","discussion":[{"timestamp":"1687377420.0","comment_id":"929877","upvote_count":"5","content":"b-b-b-b-bb-\n\nGreengrass is typically used for edge computing scenarios and may not be the most suitable solution for addressing MQTT broker reliability and scalability.","poster":"easytoo"},{"upvote_count":"1","timestamp":"1711929480.0","poster":"junja","comment_id":"1187095","content":"Selected Answer: B\noption B"},{"comment_id":"1078155","poster":"career360guru","upvote_count":"1","content":"Selected Answer: B\nOption B","timestamp":"1700722920.0"},{"comment_id":"1008693","upvote_count":"1","content":"I think this is repeat question.","timestamp":"1694811120.0","poster":"bur4an"},{"timestamp":"1692564420.0","poster":"SK_Tyagi","content":"Selected Answer: B\nAWS service is the answer.","upvote_count":"3","comment_id":"986070"},{"content":"Selected Answer: B\nIOT core for anything IOT","poster":"lferrari","timestamp":"1692315420.0","comment_id":"984055","upvote_count":"2"},{"poster":"NikkyDicky","comment_id":"944174","upvote_count":"4","timestamp":"1688599560.0","content":"Selected Answer: B\nIOT core for anything IOT"},{"timestamp":"1687878660.0","content":"Selected Answer: B\nOption C doesn't mention required auto-scaling group, hence eliminated.","comment_id":"935527","poster":"pupsik","upvote_count":"1"},{"upvote_count":"3","timestamp":"1687706340.0","comment_id":"933719","content":"Selected Answer: B\nvoting for B. IoT Core","poster":"SkyZeroZx"},{"upvote_count":"2","timestamp":"1687613100.0","comment_id":"932572","poster":"Maria2023","comments":[{"upvote_count":"1","content":"IoT core support availability whereas option c did not mention about auto scaling. With just one instance it might still fail to process when there's a surge in incoming data.","poster":"Daniel76","comment_id":"1306459","timestamp":"1730623500.0"}],"content":"Selected Answer: B\nBoth C and B should work. I suggest AWS wants us to use as many native services as we can, therefore B should be the preferred answer."},{"timestamp":"1687331640.0","content":"Selected Answer: B\nvoting for B. IoT Core","poster":"chiaseed","comment_id":"929148","upvote_count":"2"},{"comment_id":"928598","upvote_count":"1","content":"Selected Answer: B\nIoT core, B","timestamp":"1687278900.0","poster":"nexus2020"}],"answer":"B","answer_description":"","answer_images":[],"answer_ET":"B","unix_timestamp":1687278900,"answers_community":["B (100%)"],"question_images":[],"timestamp":"2023-06-20 18:35:00","exam_id":33,"choices":{"A":"Create an Application Load Balancer (ALB) and an Auto Scaling group for the MQTT broker. Use the Auto Scaling group as the target for the ALB. Update the DNS record in Route 53 to an alias record. Point the alias record to the ALB. Use the MQTT broker to store the data.","D":"Set up AWS IoT Greengrass to receive the sensor data. Update the DNS record in Route 53 to point to the AWS IoT Greengrass endpoint. Configure an AWS IoT rule to invoke an AWS Lambda function to store the data.","B":"Set up AWS IoT Core to receive the sensor data. Create and configure a custom domain to connect to AWS IoT Core. Update the DNS record in Route 53 to point to the AWS IoT Core Data-ATS endpoint. Configure an AWS IoT rule to store the data.","C":"Create a Network Load Balancer (NLB). Set the MQTT broker as the target. Create an AWS Global Accelerator accelerator. Set the NLB as the endpoint for the accelerator. Update the DNS record in Route 53 to a multivalue answer record. Set the Global Accelerator IP addresses as values. Use the MQTT broker to store the data."},"topic":"1","question_id":123,"isMC":true,"question_text":"A company runs an IoT application in the AWS Cloud. The company has millions of sensors that collect data from houses in the United States. The sensors use the MQTT protocol to connect and send data to a custom MQTT broker. The MQTT broker stores the data on a single Amazon EC2 instance. The sensors connect to the broker through the domain named iot.example.com. The company uses Amazon Route 53 as its DNS service. The company stores the data in Amazon DynamoDB.\n\nOn several occasions, the amount of data has overloaded the MQTT broker and has resulted in lost sensor data. The company must improve the reliability of the solution.\n\nWhich solution will meet these requirements?"},{"id":"TtNbtkcKNsyHw6c2pnEY","answer_description":"","question_text":"A company is using an on-premises Active Directory service for user authentication. The company wants to use the same authentication service to sign in to the company’s AWS accounts, which are using AWS Organizations. AWS Site-to-Site VPN connectivity already exists between the on-premises environment and all the company’s AWS accounts.\nThe company’s security policy requires conditional access to the accounts based on user groups and roles. User identities must be managed in a single location.\nWhich solution will meet these requirements?","timestamp":"2022-12-12 18:17:00","url":"https://www.examtopics.com/discussions/amazon/view/91245-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"D":"In one of the company’s AWS accounts, configure AWS Identity and Access Management (IAM) to use an OpenID Connect (OIDC) identity provider. Provision IAM roles that grant access to the AWS account for the federated users that correspond to appropriate groups in Active Directory. Grant access to the required AWS accounts by using cross-account IAM roles.","A":"Configure AWS IAM Identity Center (AWS Single Sign-On) to connect to Active Directory by using SAML 2.0. Enable automatic provisioning by using the System for Cross-domain Identity Management (SCIM) v2.0 protocol. Grant access to the AWS accounts by using attribute-based access controls (ABACs).","B":"Configure AWS IAM Identity Center (AWS Single Sign-On) by using IAM Identity Center as an identity source. Enable automatic provisioning by using the System for Cross-domain Identity Management (SCIM) v2.0 protocol. Grant access to the AWS accounts by using IAM Identity Center permission sets.","C":"In one of the company’s AWS accounts, configure AWS Identity and Access Management (IAM) to use a SAML 2.0 identity provider. Provision IAM users that are mapped to the federated users. Grant access that corresponds to appropriate groups in Active Directory. Grant access to the required AWS accounts by using cross-account IAM users."},"discussion":[{"timestamp":"1673632320.0","comment_id":"774750","poster":"masetromain","comments":[{"upvote_count":"2","comment_id":"774751","timestamp":"1673632320.0","content":"In option C, the company will use IAM to use a SAML 2.0 identity provider, and it will use the appropriate groups in Active Directory to grant access to the required AWS accounts by using cross-account IAM users. In this way, it can implement its security policy of conditional access to the accounts based on user groups and roles.\n\nIn summary, both option A and C are valid solutions, both of them allow you to use your on-premises Active Directory service for user authentication, and both of them allow you to manage user identities in a single location and grant access to the AWS accounts based on user groups and roles.","poster":"masetromain"}],"upvote_count":"30","content":"Selected Answer: A\nhttps://www.examtopics.com/discussions/amazon/view/74174-exam-aws-certified-solutions-architect-professional-topic-1/\n\nBoth option C and option A are valid solutions that meet the requirements for the scenario.\n\nABAC, or attribute-based access control, is a method of granting access to resources based on the attributes of the user, the resource, and the action. This allows for fine-grained access control, which can be useful for implementing a security policy that requires conditional access to the accounts based on user groups and roles.\n\nAWS IAM Identity Center (AWS SSO) allows you to connect to your on-premises Active Directory service using SAML 2.0. With this, you can enable automatic provisioning by using the System for Cross-domain Identity Management (SCIM) v2.0 protocol, which allows for the management of user identities in a single location."},{"content":"Selected Answer: A\nA is has options for SAML and SCIM configuration with AD\nC is all about users and no roles are mentioned. AD User attributes cannot be mapped to IAM users direct\nD is openID based, MS AD would not support this\n\nso I go with A","poster":"bititan","timestamp":"1674058320.0","comment_id":"780191","upvote_count":"14","comments":[{"content":"native AD doesn't support SAML 2.0 without an ADFS server. SCIM is also not supported at all. SCIM provisioning is supported by other IDPs like Azure AD","timestamp":"1699810140.0","poster":"trap","comment_id":"1068715","comments":[{"upvote_count":"1","poster":"gonzjo52","comment_id":"1191116","content":"Si, si son compatibles. https://aws.amazon.com/es/directoryservice/faqs/","timestamp":"1712512800.0"},{"content":"https://docs.aws.amazon.com/singlesignon/latest/userguide/supported-idps.html","poster":"trap","upvote_count":"2","comment_id":"1068718","timestamp":"1699810260.0"}],"upvote_count":"3"}]},{"upvote_count":"1","poster":"Heman31in","timestamp":"1733641080.0","comment_id":"1323418","content":"Selected Answer: A\nSCIM v2.0 in the Context of AWS SSO and Active Directory\nWhen using AWS IAM Identity Center (AWS SSO) with Active Directory, SCIM v2.0 is utilized to automatically provision and de-provision users and groups. This eliminates the need for manual user or group management and ensures that changes in your on-premises AD are reflected in AWS SSO."},{"comment_id":"1308236","upvote_count":"2","content":"Selected Answer: A\nkeywords:\n'Use active directory to sign in Aws accounts' = AWS IAM Identity Center (AWS Single Sign-On) , SAML 2.0\n 'conditional access to the accounts based on user groups and roles' = AWS IAM (ABAC)","poster":"TariqKipkemei","timestamp":"1730955720.0"},{"timestamp":"1723713060.0","upvote_count":"1","content":"AWS IAM Identity Center + SAML","poster":"Ashu_0007","comment_id":"1266323"},{"timestamp":"1706295960.0","content":"A is correct\n\nReasons -\n\nOption A mentions about Active Directory as identity Source configuration which solves the purpose of establishing trust and sync from on prem AD using Directory Service. Solves the purpose of using on-prem AD as Single Sign On asked in the question. \n\nIt is also mentioned that AWS org is in place, which works well with AWS Identity Centre. Gives another validation. It gives us hint of efficiently managing AWS Org accounts / OUs with Identity Centre (Permission Set behind the scene ) to manage RBAC within accounts.\n\nFinally this line - \"The company's security policy requires conditional access to the accounts based on user groups and roles.\" is talking about conditional access which can only be solved by ABAC(Attribute Based Access Control). For example user with green attribute should only get access to resources with green attribute. This can be solved by Tag functionality within AWS Identity Centre.","upvote_count":"2","poster":"Vaibs099","comment_id":"1132797"},{"content":"Selected Answer: D\nOption A - This option works however it moves authentication and managing user identities from Active Directory to Identity Center but the question states the company wants to use the same authentication service to sign into AWS in reference to Active Directory\n\nOption B - This option works but it moves user identity management and authentication tie Identity Center which is not what the question states the company wants to do\n\nOption C - This option does not work because in AWS you provision cross-account IAM roles rather than users.\n\nOption D - This option might work but it is missing AD FS, a component that enables OIDC flows in AD. Otherwise it maintains user identity management in one place and allows the company to keep using Active Directory for authentication as the question states","timestamp":"1703035920.0","poster":"atirado","upvote_count":"2","comment_id":"1101112"},{"comments":[{"comment_id":"1135629","content":"After reviewing it, the correct answer is A. \"User identities must be managed in a single location\" -> \"Configure AWS IAM Identity Center (AWS Single Sign-On) to connect to Active Directory by using SAML 2.0\" while B states \"Configure AWS IAM Identity Center (AWS Single Sign-On) by using IAM Identity Center as an identity source\". Using AWs IdC as identity source will not meet requirement to manage all users in a single place","upvote_count":"1","poster":"ninomfr64","timestamp":"1706605260.0"}],"content":"Selected Answer: B\nDidn't spent time checking if C and D works, because when you have an AWS Organitazion and need to use AD to sign-in to the company’s AWS accounts AWS IdC is the way to go. \n\nNow, with AWS IdC we need ADFS and while ADFS does not support SCIM, it is possible to still have your users and groups automatically synchronize with the IAM IDC by using the SCIM API and PowerShell as per https://aws.amazon.com/blogs/modernizing-with-aws/synchronize-active-directory-users-to-aws-iam-identity-center-using-scim-and-powershell/#:~:text=While%20ADFS%20does%20not%20support,the%20SCIM%20API%20and%20PowerShell.\n\nFinally, ABAC is an authorization strategy and it is not alternative to IdC Permission Sets. Also the scenario requires conditional access to the accounts based on user groups and roles, this point me to RBAC strategy. I would pick ABAC if the request mentioned user attributes like Department, Cost Center or Project thus.","timestamp":"1702742880.0","comment_id":"1098296","poster":"ninomfr64","upvote_count":"2"},{"content":"Answer A for AWS SSO would the right answer at first glance since IAM roles can be mapped to AD groups but it would require additional AD functions like ADFS for SCIM so the next best option is D.","timestamp":"1702428840.0","upvote_count":"3","poster":"924641e","comment_id":"1095054"},{"content":"A is a correct one, because need to use the SAML for single sign on from the on-premise directory and also C is not correct because the federated should not come in to the picture federated is for only facebook, twitter, gmail account sign on - but we should use the companies active directory, so A is a correct one.","poster":"subbupro","timestamp":"1701771600.0","comment_id":"1088377","upvote_count":"1"},{"timestamp":"1701124140.0","upvote_count":"1","comments":[{"content":"P: ¿Puedo usar la autenticación basada en lenguaje de marcado de aserción de seguridad (SAML) 2.0 con aplicaciones de la nube que usen AWS Managed Microsoft AD?\n\nSí. Puede usar los servicios federados de Microsoft Active Directory (AD FS) para Windows 2016 con su dominio administrado de AWS Managed Microsoft AD para autenticar usuarios en aplicaciones en la nube compatibles con SAML. https://aws.amazon.com/es/directoryservice/faqs/","poster":"gonzjo52","timestamp":"1712512920.0","upvote_count":"1","comment_id":"1191118"}],"poster":"siasiasia","comment_id":"1081990","content":"Selected Answer: C\nAD and SCIM don't go together so forget A and B. I've never seen a document talking about integrating OpenID with AWS account login so D is also out. C is doable so I go with C."},{"comment_id":"1081948","poster":"sizzla83","timestamp":"1701117900.0","comments":[{"comment_id":"1098287","content":"Agree with you on B, but:\n\n- You can use IAM Identity Center to manage access to your AWS resources across multiple AWS accounts using user attributes that come from any IAM Identity Center identity source - https://docs.aws.amazon.com/singlesignon/latest/userguide/abac.html\n\n- ABAC is an authorization strategy that defines permissions based on attributes and it is implemented using IdC Permission Sets.","upvote_count":"1","poster":"ninomfr64","timestamp":"1702741920.0"}],"content":"I am with B on this one. A is incorrect because you can only use ABAC (Attribute-Based Access Control) with IAM Identity Center Identity Store NOT with Active Directory","upvote_count":"1"},{"comment_id":"1080141","content":"Selected Answer: A\nAs mentioned, SAML 2.0 doesn't directly integrate with AD and requires ADFS proxy as a go between, so the lack of ADFS being mentioned in A or B is throwing people off. However, AD on-premise with direct/VPN connectivity...IAM identify center is the way to go for SSO. I believe ADFS is implied when the question casually mentions \"IAM Identify Center connect to AD using SAML 2.0\".","upvote_count":"1","poster":"enk","timestamp":"1700927940.0"},{"content":"Selected Answer: A\nfederated IdP is required and access to multiple accounts","comment_id":"1068327","upvote_count":"1","poster":"severlight","timestamp":"1699768440.0"},{"poster":"trap","comment_id":"1066463","content":"Answer A and B are wrong!!! \nActive Directory doesn't support SAML without the use of Active Directory Federation Server!! SCIM is also not supported. The articles that all are pasting here mention the need of an AD connect or the trust between the local AD and an AWS managed Microsoft AD which is not the case here.\nC is also wrong. Cross account IAM users option doesn't exist.\nThe correct is D!! You can use an OpenID Connect (OIDC) identity provider (e.g OKTA or Azure AD) and sync AD groups in it. You can then use cross account roles to grant access to the federated users\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc.html\nhttps://help.okta.com/en-us/content/topics/directory/ad-agent-manage-users-groups.htm\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_aws-accounts.html","upvote_count":"3","timestamp":"1699539420.0"},{"comment_id":"1023815","timestamp":"1696327560.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/onelogin-idp.html#onelogin-passing-abac","poster":"M4D3V1L","upvote_count":"1"},{"comment_id":"1020398","timestamp":"1695958800.0","content":"Selected Answer: A\nA: combination SSO + SAML2.0 + AD sounds correct. Automatic provisioning with SCIM means creating users and groups that synced with AD. ABAC seems not too fit for this as the requirements is \"requires conditional access to the accounts based on user groups and roles\" but that already satisfied with SCIM. \n\nB: \"use Identity Center as an identity source\" -> not using on premise AD -> wrong\n\nD: use OIDC -> wrong as on premise AD does not support OIDC. Cannot find an exact source for this but ChatGpt says so..\n\nC: creating users mapped to federated users sounds red flags. Could have been correct if it was \"creating roles\", the same way with the classic \"creating roles for EC2 to access S3 instead of user...\"\n\nConclusion: A","poster":"imvb88","upvote_count":"3"},{"comment_id":"995298","poster":"whenthan","content":"Selected Answer: C\nMore compreshensive approach \nhow to map users, grant access based on groups, and utilize cross-account IAM users.","upvote_count":"2","timestamp":"1693500600.0"},{"comment_id":"995296","content":"C provides more comprehensve approach","timestamp":"1693500480.0","poster":"whenthan","upvote_count":"1"},{"timestamp":"1693382940.0","content":"Selected Answer: A\nA. Configure AWS IAM Identity Center (AWS Single Sign-On) to connect to Active Directory by using SAML 2.0. Enable automatic provisioning by using the System for Cross-domain Identity Management (SCIM) v2.0 protocol. Grant access to the AWS accounts by using attribute-based access controls (ABACs).\n\nOption B does not mention the use of SAML integration with Active Directory, which is needed for the company's requirement of using the existing Active Directory for user authentication.\n\nOption C involves managing cross-account IAM users, which can be more complex and less centralized compared to using a dedicated identity service like AWS SSO.\n\nOption D involves OpenID Connect (OIDC), which is not mentioned as a requirement, and using cross-account IAM roles. While IAM roles are a valid way to grant access, the solution provided in option A offers a more centralized and streamlined approach through AWS SSO.","upvote_count":"1","poster":"bur4an","comment_id":"993832"},{"timestamp":"1692370500.0","comment_id":"984596","content":"Option C is NOT correct because of the following reasons\n While IAM can use a SAML 2.0 identity provider for federation, managing cross-account IAM users introduces complexity and can be challenging.\n Provisioning IAM users mapped to federated users is a manual, cumbersome process.\n Managing user identities across multiple AWS accounts rather than a single location doesn't align well with the company's requirement.\n It may not easily provide the granular, conditional access based on user groups and roles in the Active Directory, especially across multiple accounts.\n\nSo, Answer A is correct \nAWS Single Sign-On (SSO) is designed to integrate with identity sources, including on-premises Active Directory, via SAML 2.0.\nAWS SSO supports automatic provisioning with SCIM.\nWith AWS SSO, you can grant access to AWS accounts using attribute-based access controls (ABACs), which provides the conditional access based on user groups and roles.\nIt meets the requirement of managing user identities in a single location.","poster":"venvig","upvote_count":"1"},{"timestamp":"1691154180.0","comment_id":"972170","upvote_count":"1","poster":"chico2023","content":"Selected Answer: A\nAnswer: A\n\n\"The company’s security policy requires conditional access to the accounts based on **user groups and roles**\"\n\nC would require an IdP to work."},{"upvote_count":"1","timestamp":"1688561220.0","comment_id":"943752","poster":"awsrd2023","content":"Selected Answer: A\nPerfectly matches the requirement"},{"timestamp":"1687957680.0","poster":"NikkyDicky","content":"Selected Answer: A\nit's A","comment_id":"936686","upvote_count":"1"},{"content":"Selected Answer: B\nB is perfectly possible, we use it in my organization. AD could be possible but A is easier to implemente and fully ocvers the requirement. It uses same authentication service, users are only managed in the active directory, and permissions are assigned based on the Active Directory groups that the user belongs to, adn that are synchronized with AWS SSO using SSO and permission sets.","upvote_count":"1","comment_id":"933396","poster":"javitech83","timestamp":"1687682460.0"},{"upvote_count":"1","content":"Selected Answer: A\nHere's how this solution satisfies the requirements:\n\nConnect to Active Directory: AWS IAM Identity Center (AWS Single Sign-On) can be configured to integrate with Active Directory using SAML 2.0. This allows for the synchronization of user identities and authentication with the on-premises Active Directory service.\n\nAutomatic provisioning: By enabling automatic provisioning using the SCIM v2.0 protocol, user identities can be automatically provisioned and deprovisioned based on changes in the Active Directory. This ensures that user management remains centralized in a single location.\n\nAttribute-based access controls (ABACs): AWS IAM Identity Center supports ABACs, which allow for conditional access to AWS accounts based on user groups and roles. This enables fine-grained control over access to the AWS resources based on attributes associated with the user identities in the Active Directory.","poster":"Jonalb","comment_id":"930951","timestamp":"1687461240.0"},{"upvote_count":"1","timestamp":"1687193220.0","content":"Selected Answer: A\nInitially I went for B, because I use permissionsets to assign policies in AD-to-AWS integrations. But that part - \"Configure AWS IAM Identity Center (AWS Single Sign-On) by using IAM Identity Center as an identity source\" means to abandon SAML and SCIM. Think the question is trick by nature and neither answer is completely right. You don't definitely need to use attributes - standard scenario is to provision users and groups and assign groups to accounts and permissionsets.","comment_id":"927703","poster":"Maria2023"},{"content":"B\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/permissionsetsconcept.html","poster":"geo1551","upvote_count":"2","comment_id":"922352","timestamp":"1686670860.0"},{"upvote_count":"1","timestamp":"1686492420.0","comment_id":"920742","content":"Selected Answer: D\nI think A is wrong because ABAC refers to utilizing tags for access control, in this case we are required to use access control based on roles and groups, which is RBAC.","poster":"johnballs221"},{"content":"Selected Answer: A\nThe fill guide is here.\n\nhttps://aws.amazon.com/blogs/security/configure-aws-sso-abac-for-ec2-instances-and-systems-manager-session-manager/","timestamp":"1685372940.0","upvote_count":"1","comment_id":"909502","poster":"chathur"},{"timestamp":"1685105460.0","comments":[{"timestamp":"1701115860.0","content":"I am with B on this one. A is incorrect because you can only use ABAC (Attribute-Based Access Control) with IAM Identity Center Identity Store NOT with Active Directory.","poster":"sizzla83","upvote_count":"1","comment_id":"1081933"}],"poster":"emiliocb4","upvote_count":"4","content":"Selected Answer: B\nB because AWS IAM Identity Center (AWS Single Sign-On) and to manage in a single point the user permission with the permission set.\nI'm using the same in my organization.","comment_id":"907365"},{"timestamp":"1684936260.0","poster":"rtguru","upvote_count":"1","content":"I go with C","comment_id":"905946"},{"content":"Selected Answer: A\nI will go with A.\nWhen I look to this \"conditional access to the accounts based on user groups and roles\", this a conditional access based on groups and roles, this is clear ABAC, access base on some conditions/attributes from the user. For example: if the user has a role as Manager (attribute) and a group as Finance (attribute), then the user access an AWS Resource.\n\nLooking to \"A company is using an on-premises Active Directory service for user authentication\" this is SAML.\n\nTo simplify all this integration AWS IAM Identity Center (AWS Single Sign-On)","comment_id":"905022","upvote_count":"1","timestamp":"1684854660.0","poster":"aca1"},{"upvote_count":"1","comment_id":"892122","poster":"gameoflove","content":"Selected Answer: D\nin Option A, ABAC required tags and Federated user used to filter users based on it however Option D is the right option as per my knowledge","timestamp":"1683547320.0"},{"comment_id":"865551","upvote_count":"3","timestamp":"1681048500.0","poster":"huanaws088","content":"Selected Answer: A\nit is A , I only vote A to increment Rate for A\nhttps://aws.amazon.com/vi/blogs/aws/new-attributes-based-access-control-with-aws-single-sign-on/"},{"upvote_count":"1","timestamp":"1680872460.0","poster":"jj22222","content":"Selected Answer: D\nI think its D","comment_id":"863890"},{"upvote_count":"2","timestamp":"1679980320.0","content":"Selected Answer: A\nA is the best choice.","poster":"mfsec","comment_id":"852801"},{"content":"Selected Answer: C\nA and B are wrong. https://docs.aws.amazon.com/singlesignon/latest/userguide/supported-idps.html","comment_id":"846436","poster":"Dimidrol","timestamp":"1679440500.0","upvote_count":"1","comments":[{"content":"That page of documentation appears to be for IdPs *excluding* AD - which gets its own page further up in the docs: https://docs.aws.amazon.com/singlesignon/latest/userguide/manage-your-identity-source-ad.html\n\n\"If you're using a self-managed directory in Active Directory or an AWS Managed Microsoft AD, see Connect to a Microsoft AD directory. For other external identity providers (IdPs), you can use AWS IAM Identity Center (successor to AWS Single Sign-On) to authenticate identities from the IdPs through the Security Assertion Markup Language (SAML) 2.0 standard. \"","timestamp":"1686659880.0","poster":"Scoobyben","upvote_count":"1","comment_id":"922222"},{"poster":"Dimidrol","upvote_count":"2","content":"Changed to D. https://aws.amazon.com/ru/blogs/security/aws-federated-authentication-with-active-directory-federation-services-ad-fs/","timestamp":"1679440860.0","comment_id":"846443"}]},{"comments":[{"comment_id":"860719","upvote_count":"1","poster":"hobokabobo","content":"\"Connect (OIDC) identity provider, which does not integrate with Active Directory.\": You seriously think AD does not support OIDC? Defacto standard besides SAML in most big companies which need a unified solution almost every software supports.","timestamp":"1680590220.0"}],"content":"ANS is B\n\nOption A is incorrect because it suggests using SAML 2.0 for authentication but does not address the requirements for managing user identities in a single location or providing conditional access based on user groups and roles.\n\nOption C is incorrect because it suggests creating cross-account IAM users, which would require duplicating user identities across AWS accounts, defeating the purpose of using a single location for managing user identities.\n\nOption D is incorrect because it suggests using an OpenID Connect (OIDC) identity provider, which does not integrate with Active Directory.","comment_id":"832528","timestamp":"1678250040.0","upvote_count":"3","poster":"mKrishna"},{"poster":"cudbyanc","timestamp":"1677351900.0","upvote_count":"2","content":"Selected Answer: A\nAWS Single Sign-On (SSO) is designed to manage access to multiple AWS accounts and business applications, and it allows users to sign in once using their existing credentials, including those from Active Directory. By configuring AWS SSO to connect to Active Directory by using SAML 2.0, the user identities can be managed in a single location. Additionally, automatic provisioning can be enabled using the System for Cross-domain Identity Management (SCIM) v2.0 protocol. This will ensure that users are created and updated in AWS SSO based on changes in Active Directory.","comment_id":"821759"},{"upvote_count":"2","timestamp":"1677224040.0","comment_id":"820210","poster":"hobokabobo","content":"Selected Answer: D\nA: imo not possible with on premises AD (SCIM not supported)\nB: imo not possible with on premises AD (SCIM not supported)\nC: \"Provision users in IAM\" violates the requirement of central user Management.\nD: OIDC may be an ugly pig but works. Usage of roles removes the necessity of maintaining users in AWS.\n(admitted: A would be much nicer if it was possible. )"},{"upvote_count":"1","content":"Logical answer : SAML, Existing Active Directory services authentication mechanism and ABAC are key terms for the requirement. A fits well. D is wrong because, OIDC does not need to be implemented as the auth mechanism is already in place with AD. OIDC does not jell with Active Directory. AD and SAML is a workable solution though.","poster":"God_Is_Love","comment_id":"818405","timestamp":"1677099660.0"},{"timestamp":"1671559320.0","upvote_count":"4","poster":"tman22","comment_id":"751311","content":"C.\nOn-premises Active Directory does not support SCIM or OIDC. Azure AD is not mentioned."},{"upvote_count":"2","poster":"aragon_saa","comment_id":"750626","content":"I choose A","timestamp":"1671522900.0"},{"upvote_count":"5","content":"Selected Answer: A\nI prefer to go to answer A for ABAC\n\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/scim-profile-saml.html\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/abac.html","poster":"masetromain","comment_id":"743079","timestamp":"1670865420.0","comments":[{"upvote_count":"2","poster":"masetromain","content":"https://www.examtopics.com/discussions/amazon/view/74174-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"1670865720.0","comment_id":"743088"}]}],"unix_timestamp":1670865420,"exam_id":33,"answers_community":["A (80%)","8%","8%"],"answer_ET":"A","question_id":124,"topic":"1","question_images":[],"answer":"A","answer_images":[],"isMC":true},{"id":"Yooo2dGwcmWixlRF3gPV","discussion":[{"upvote_count":"1","poster":"pk0619","content":"Selected Answer: D\nSSM RunCommand is the only solution that can actually replace the keys on EC2 instances.","timestamp":"1734830100.0","comment_id":"1330224"},{"upvote_count":"3","comment_id":"1149682","timestamp":"1723587420.0","content":"Selected Answer: A\nNot sure why you would need to “invoke an AWS Lambda function to generate new key pairs” when Secrets Manager natively supports automatic key rotation? Anyways, A seems to be the least worst answer.","poster":"dankositzke","comments":[{"comment_id":"1158156","poster":"sat2008","upvote_count":"4","timestamp":"1724525700.0","content":"Lambda is part of the key creation and rotation see the link\nhttps://aws.amazon.com/blogs/security/how-to-use-aws-secrets-manager-securely-store-rotate-ssh-key-pairs/"}]},{"poster":"Maygam","comments":[{"timestamp":"1734830040.0","upvote_count":"1","content":"this is a 5 years old solution, currently the answer should be either B or best D, also Lambda cannot replace the public keys on EC2 instances, you need SSM RunCommand for that.","poster":"pk0619","comment_id":"1330223"}],"timestamp":"1719723300.0","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/security/how-to-use-aws-secrets-manager-securely-store-rotate-ssh-key-pairs/","comment_id":"1109487","upvote_count":"3"},{"comment_id":"1106941","timestamp":"1719494280.0","poster":"CProgrammer","content":"@duriselvan ==> How did you arrive at \"Automatic key rotation\" from \"key rotation policy that will, upon request\nB. Parameter Store: While Parameter Store can store keys, it's not designed for automated key rotation. It would require manual configuration and orchestration.\nC. AWS KMS: KMS is designed for managing encryption keys, not SSH key pairs.\n It doesn't support the rotation of SSH key pairs on EC2 instances.\nD. Fleet Manager: Fleet Manager, while facilitating management tasks on EC2 instances,\n doesn't intrinsically handle key rotation.\n It would require integration with other services and custom scripts.","upvote_count":"1"},{"comment_id":"1091653","content":"C ans\nAutomatic key rotation: AWS KMS automatically rotates keys according to the configured schedule, eliminating the need for manual intervention and ensuring timely key updates.\n\nLess than 1 minute downtime: AWS KMS allows for seamless key rotation with minimal downtime. The old key remains active until the new key is generated and propagated, ensuring uninterrupted access to instances.\n\nSecure storage: AWS KMS provides a highly secure and encrypted environment for storing cryptographic keys, exceeding the security offered by Parameter Store.\n\nLambda function integration: The EventBridge rule can trigger a Lambda function to perform additional tasks during key rotation, such as updating user access controls or notifying administrators.","timestamp":"1717916880.0","upvote_count":"3","poster":"duriselvan"},{"comment_id":"1078383","content":"Torn between A and D. I don't like the do-it-yourself nature (Lambda) of A, but I understand what everyone is saying about the unique key requirement, which would seem to imply that D is wrong. Don't know tbh.","upvote_count":"1","poster":"Jay_2pt0_1","timestamp":"1716457500.0"},{"comment_id":"1078162","upvote_count":"1","timestamp":"1716441000.0","content":"Selected Answer: A\nOption A","poster":"career360guru"},{"content":"Selected Answer: A\nA will work, don't overthink, you can request secret rotation in the Secrets manager, and secrets will be stored in a safe place","poster":"severlight","comment_id":"1073862","upvote_count":"2","timestamp":"1716014520.0"},{"comment_id":"1058984","timestamp":"1714483980.0","upvote_count":"1","poster":"Sab","content":"Selected Answer: A\nD is best option if we need to rotate for all Ec2 with same key pair. Since each EC2 to have a different Key pair, will be better to store in Secrets Manager and have that rotated using lambda."},{"upvote_count":"3","poster":"wahaha2023","content":"Selected Answer: A\nI think the Systems Manager maintenance window is to perform some potentially disruptive actions, which means the duration of the window is equal to system downtime. and I check the white paper, I seems the duration of system maintenance window should be longer than 1 hour.","comment_id":"987818","timestamp":"1708650420.0"},{"comments":[{"comment_id":"989111","content":"With D how to \"keep the keys in a securely encrypted place\" ? Should be A","poster":"vn_thanhtung","timestamp":"1708779720.0","upvote_count":"1"},{"comments":[{"upvote_count":"2","content":"I am curious about how we can define a 1-minute Systems Manager maintenance window.","comment_id":"987812","poster":"wahaha2023","timestamp":"1708650000.0"}],"timestamp":"1708340640.0","content":"Same option A, says the following: \"Define a Secrets Manager rotation schedule to invoke an AWS Lambda function to generate new key pairs. Replace public keys on EC2 instances.\"\n\nNow, this is A lot, but how are we going to replace the public keys on EC2 instances? Answer doesn't say.\n\nFinally, for those who are supporting their answer on an AWS blog showing how to use SM to rotate SSH key to manage servers, pay attention to this part: \"A secret is created in AWS Secrets Manager. The secret holds the SSH keypair that the master node will use to connect to the other nodes in the cluster.\"\n\nTheir design is \"one to many\", that is not part of what question says, and I would like to remind you \"Each machine requires a unique EC2 key pair.\"","comment_id":"985077","upvote_count":"1","poster":"chico2023"}],"comment_id":"985076","content":"Selected Answer: D\nSeriously, all. While it can be done in A, it's better to do that with D. Here is why:\n\nQuestion says:\n\"A company has Linux-based Amazon EC2 instances.\" and \"Each machine requires a unique EC2 key pair.\"\n\nWe might be talking about thousands of EC2 instances. But let's continue. Option A says:\n\"Store all the keys in AWS Secrets Manager.\" which is OK, you can store up to 500,000 apparently but, seriously, think about. Instances are generated and deleted all the time. This would be cumbersome, even if you do that programmatically. Not convinced? Let me continue.","timestamp":"1708340640.0","poster":"chico2023","upvote_count":"1"},{"comment_id":"968420","poster":"easytoo","upvote_count":"1","timestamp":"1706734080.0","content":"a-a-a-a-a-a-a-a"},{"comment_id":"958041","timestamp":"1705817640.0","upvote_count":"1","poster":"Just_Ninja","content":"Selected Answer: A\nA: Based on the Well Architecting Framework for best Practices and that tutorial :) https://aws.amazon.com/de/blogs/security/how-to-use-aws-secrets-manager-securely-store-rotate-ssh-key-pairs/"},{"poster":"nicecurls","timestamp":"1704711900.0","content":"Selected Answer: D\nWhy A? Select D","upvote_count":"2","comment_id":"946342","comments":[{"timestamp":"1705817700.0","comment_id":"958043","content":"D is wrong, Parameter Store is a good practice to store Parameters but not the Secrets. I know you can use KMS to encrypt the Parameters, but you need a secure store für Secrets and here we have for exmaple the secret manager with FIPS 140-2 Standard.","poster":"Just_Ninja","upvote_count":"2"}]},{"upvote_count":"1","poster":"YodaMaster","timestamp":"1704514860.0","comment_id":"944243","content":"Selected Answer: A\ngoing with A"},{"content":"Selected Answer: A\nas someone pointed out D breaks the requirement for unique keys","upvote_count":"1","comment_id":"944175","timestamp":"1704504840.0","poster":"NikkyDicky"},{"comment_id":"938239","timestamp":"1703866680.0","poster":"javitech83","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/security/how-to-use-aws-secrets-manager-securely-store-rotate-ssh-key-pairs/","upvote_count":"1"},{"upvote_count":"4","content":"Selected Answer: A\nAccording to the link below A is a better answer since the process does not require manual generation of the keys\nhttps://aws.amazon.com/blogs/security/how-to-use-aws-secrets-manager-securely-store-rotate-ssh-key-pairs/","timestamp":"1703432220.0","comment_id":"932590","poster":"Maria2023"},{"comment_id":"931099","content":"Selected Answer: D\nD. Fleet Manager does this. https://tutorialsdojo.com/automatic-ssh-key-pair-rotation-via-aws-systems-manager-fleet-manager/","timestamp":"1703292300.0","comments":[],"poster":"SmileyCloud","upvote_count":"2"},{"content":"Selected Answer: A\nBy storing the keys in AWS Secrets Manager, you can securely encrypt them. Defining a rotation schedule in Secrets Manager allows you to automatically generate new key pairs using an AWS Lambda function. This ensures that each machine has a unique key pair. During the rotation process, the public keys on the EC2 instances can be replaced, and the private keys can be updated in Secrets Manager. This solution minimizes downtime and provides a secure way to manage and rotate the EC2 key pairs","poster":"easytoo","timestamp":"1703207520.0","upvote_count":"2","comment_id":"929987"}],"answers_community":["A (79%)","D (21%)"],"url":"https://www.examtopics.com/discussions/amazon/view/112870-exam-aws-certified-solutions-architect-professional-sap-c02/","question_id":125,"choices":{"A":"Store all the keys in AWS Secrets Manager. Define a Secrets Manager rotation schedule to invoke an AWS Lambda function to generate new key pairs. Replace public keys on EC2 instances. Update the private keys in Secrets Manager.","B":"Store all the keys in Parameter Store, a capability of AWS Systems Manager, as a string. Define a Systems Manager maintenance window to invoke an AWS Lambda function to generate new key pairs. Replace public keys on EC2 instances. Update the private keys in Parameter Store.","D":"Add all the EC2 instances to Fleet Manager, a capability of AWS Systems Manager. Define a Systems Manager maintenance window to issue a Systems Manager Run Command document to generate new key pairs and to rotate public keys to all the instances in Fleet Manager.","C":"Import the EC2 key pairs into AWS Key Management Service (AWS KMS). Configure automatic key rotation for these key pairs. Create an Amazon EventBridge scheduled rule to invoke an AWS Lambda function to initiate the key rotation in AWS KMS."},"question_text":"A company has Linux-based Amazon EC2 instances. Users must access the instances by using SSH with EC2 SSH key pairs. Each machine requires a unique EC2 key pair.\n\nThe company wants to implement a key rotation policy that will, upon request, automatically rotate all the EC2 key pairs and keep the keys in a securely encrypted place. The company will accept less than 1 minute of downtime during key rotation.\n\nWhich solution will meet these requirements?","timestamp":"2023-06-22 01:12:00","answer_ET":"A","answer_description":"","question_images":[],"isMC":true,"answer":"A","answer_images":[],"topic":"1","unix_timestamp":1687389120,"exam_id":33}],"exam":{"id":33,"numberOfQuestions":529,"isImplemented":true,"lastUpdated":"11 Apr 2025","provider":"Amazon","name":"AWS Certified Solutions Architect - Professional SAP-C02","isMCOnly":true,"isBeta":false},"currentPage":25},"__N_SSP":true}