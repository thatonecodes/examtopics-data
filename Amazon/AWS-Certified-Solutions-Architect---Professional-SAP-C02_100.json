{"pageProps":{"questions":[{"id":"JvoQNlu2mruukZK8EXDb","answers_community":["C (100%)"],"unix_timestamp":1673712120,"timestamp":"2023-01-14 17:02:00","discussion":[{"content":"Selected Answer: C\nThe correct answer is C. Choice C meets the requirements for the application to be highly available and to dynamically scale to meet user traffic, as well as implementing a disaster recovery environment in the us-west-1 Region through active-passive failover.\n\nIn choice C, the company creates a VPC in us-east-1 and a VPC in us-west-1, and sets up an Application Load Balancer (ALB) and Auto Scaling group in both VPCs. The ALB extends across multiple Availability Zones in each VPC, and the Auto Scaling group deploys the EC2 instances across these Availability Zones. The Auto Scaling group is placed behind the ALB, which allows for automatic scaling of the instances to meet user traffic.\n\nAn Amazon Route 53 hosted zone is also created, with separate records for each ALB. Health checks are enabled for each record, and a failover routing policy is configured. This allows for active-passive failover between the two regions, ensuring high availability for the application.","timestamp":"1673712120.0","comment_id":"775667","upvote_count":"19","poster":"masetromain","comments":[{"upvote_count":"6","timestamp":"1673712120.0","comments":[{"comment_id":"775671","timestamp":"1673712180.0","content":"Choice D is similar to choice A, the VPCs in us-east-1 and us-west-1 are peered and the Auto Scaling group and Application Load Balancer (ALB) are extended across multiple availability zones in both regions. However, there is no explicit failover routing policy configured, so it is not clear how the application would failover to the us-west-1 region in the event of an outage.\n\nChoice C is the correct answer as it includes all the necessary components for a disaster recovery environment in the us-west-1 region. It creates separate VPCs, Application Load Balancer, and Auto Scaling Group in both regions, and it enables health checks and configure a failover routing policy for each record. This ensures that in the event of an outage, the application can automatically failover to the us-west-1 region with minimal downtime.","poster":"masetromain","upvote_count":"6"}],"comment_id":"775668","poster":"masetromain","content":"Choice A, B, and D do not fully meet the requirements of the disaster recovery environment in the us-west-1 Region and the failover routing policy because they do not include the necessary configurations for active-passive failover.\n\nIn choice A, the VPCs in us-east-1 and us-west-1 are peered and the Auto Scaling group and Application Load Balancer (ALB) are extended across multiple availability zones in both regions. However, there is no explicit failover routing policy configured, so it is not clear how the application would failover to the us-west-1 region in the event of an outage.\n\nChoice B, the VPCs in us-east-1 and us-west-1 are separate, and the configuration is replicated in both regions but there is no explicit failover routing policy configured, so it is not clear how the application would failover to the us-west-1 region in the event of an outage."}]},{"poster":"zozza2023","upvote_count":"7","timestamp":"1675110780.0","content":"Selected Answer: C\nactive-passive failover==>a failover routing policy within route 53","comment_id":"793300"},{"comment_id":"1275525","timestamp":"1725095520.0","content":"C. Create a VPC in us-east-1 and a VPC in us-west-1. In the us-east-1 VPC, create an Application Load Balancer (ALB) that extends across multiple Availability Zones in that VPCreate an Auto Scaling group that deploys the EC2 instances across the multiple Availability Zones in the us-east-1 VPPlace the Auto Scaling group behind the ALB. Set up the same configuration in the us-west-1 VPCreate an Amazon Route 53 hosted zone. Create separate records for each ALB. Enable health checks and configure a failover routing policy for each record.","poster":"amministrazione","upvote_count":"1"},{"timestamp":"1688320740.0","comment_id":"941138","poster":"NikkyDicky","upvote_count":"1","content":"Selected Answer: C\nIt's C"},{"content":"Selected Answer: C\nC for DR","poster":"mfsec","upvote_count":"2","comment_id":"850967","timestamp":"1679832000.0"},{"poster":"God_Is_Love","content":"Selected Answer: C\nActive-Passive failover with primary and secondary records in Route53\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html\nhttps://d1tcczg8b21j1t.cloudfront.net/strapi-assets/32_Route_53_health_checks_4_64165fc533.png","comments":[{"comment_id":"827525","content":"VPC Peering is good for fully accessing all resources in a shared env but thats not asked here, so A and D gets eliminated. B does not mention the weighted routing config enable ment although setup is good. So answer is C","upvote_count":"3","timestamp":"1677798180.0","poster":"God_Is_Love"}],"timestamp":"1677797940.0","upvote_count":"5","comment_id":"827524"},{"content":"C is correct","upvote_count":"3","comment_id":"776964","timestamp":"1673809620.0","poster":"zhangyu20000"}],"answer_description":"","isMC":true,"exam_id":33,"answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/95288-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_images":[],"question_id":496,"choices":{"B":"Create a VPC in us-east-1 and a VPC in us-west-1. In the us-east-1 VPC, create an Application Load Balancer (ALB) that extends across multiple Availability Zones in that VPC. Create an Auto Scaling group that deploys the EC2 instances across the multiple Availability Zones in the us-east-1 VPC. Place the Auto Scaling group behind the ALSet up the same configuration in the us-west-1 VPC. Create an Amazon Route 53 hosted zone. Create separate records for each ALEnable health checks to ensure high availability between Regions.","D":"Create a VPC in us-east-1 and a VPC in us-west-1. Configure VPC peering. In the us-east-1 VPC, create an Application Load Balancer (ALB) that extends across multiple Availability Zones in both VPCs. Create an Auto Scaling group that deploys the EC2 instances across the multiple Availability Zones in both VPCs. Place the Auto Scaling group behind the ALB. Create an Amazon Route 53 hosted zone. Create a record for the ALB.","A":"Create a VPC in us-east-1 and a VPC in us-west-1. Configure VPC peering. In the us-east-1 VPC, create an Application Load Balancer (ALB) that extends across multiple Availability Zones in both VPCs. Create an Auto Scaling group that deploys the EC2 instances across the multiple Availability Zones in both VPCs. Place the Auto Scaling group behind the ALB.","C":"Create a VPC in us-east-1 and a VPC in us-west-1. In the us-east-1 VPC, create an Application Load Balancer (ALB) that extends across multiple Availability Zones in that VPCreate an Auto Scaling group that deploys the EC2 instances across the multiple Availability Zones in the us-east-1 VPPlace the Auto Scaling group behind the ALB. Set up the same configuration in the us-west-1 VPCreate an Amazon Route 53 hosted zone. Create separate records for each ALB. Enable health checks and configure a failover routing policy for each record."},"answer_ET":"C","question_text":"A financial services company in North America plans to release a new online web application to its customers on AWS. The company will launch the application in the us-east-1 Region on Amazon EC2 instances. The application must be highly available and must dynamically scale to meet user traffic. The company also wants to implement a disaster recovery environment for the application in the us-west-1 Region by using active-passive failover.\n\nWhich solution will meet these requirements?","question_images":[],"topic":"1"},{"id":"UxD6tzwsA14SCTnxu4vl","question_text":"A company is running a traditional web application on Amazon EC2 instances. The company needs to refactor the application as microservices that run on containers. Separate versions of the application exist in two distinct environments: production and testing. Load for the application is variable, but the minimum load and the maximum load are known. A solutions architect needs to design the updated application with a serverless architecture that minimizes operational complexity.\nWhich solution will meet these requirements MOST cost-effectively?","choices":{"D":"Upload the container images to AWS Elastic Beanstalk. In Elastic Beanstalk, create separate environments and deployments for production and testing. Configure two separate Application Load Balancers to direct traffic to the Elastic Beanstalk deployments.","B":"Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters.","C":"Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the EKS clusters.","A":"Upload the container images to AWS Lambda as functions. Configure a concurrency limit for the associated Lambda functions to handle the expected peak load. Configure two separate Lambda integrations within Amazon API Gateway: one for production and one for testing."},"unix_timestamp":1670693580,"timestamp":"2022-12-10 18:33:00","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/90941-exam-aws-certified-solutions-architect-professional-sap-c02/","exam_id":33,"discussion":[{"poster":"masetromain","content":"Selected Answer: B\nB. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters.\nThis option meets the requirement of using a serverless architecture by utilizing the Fargate launch type for the ECS clusters, which allows for automatic scaling of the containers based on the expected load. It also allows for separate deployments for production and testing by configuring separate ECS clusters and Application Load Balancers for each environment. This option also minimizes operational complexity by utilizing ECS and Fargate for the container orchestration and scaling.","comment_id":"774685","upvote_count":"22","timestamp":"1727061480.0"},{"content":"Answer is A. ABC all works but A is most COST EFFECTIVE","timestamp":"1670807580.0","poster":"zhangyu20000","comments":[{"upvote_count":"3","comment_id":"742773","poster":"masetromain","content":"Is true but \" you can now package and deploy Lambda functions as container images of up to 10 GB in size.\" the size is not specified, personally I find it too small","timestamp":"1670848140.0","comments":[{"content":"10 GB is ENORMOUS for a container image. Even most Windows Server OS container images (which won't work in Lambda anyway) are smaller than that, and it's very very rare to see a Linux container image over ~1 GB (typically they are a few hundred MB)","comment_id":"1339636","timestamp":"1736707380.0","upvote_count":"1","poster":"Kirkster"},{"poster":"anita_student","content":"10GB image is too small for what? I'm curious how do you containerise those images?\nI'd say the average image size is ~300-400MB","comment_id":"812482","timestamp":"1676675880.0","upvote_count":"5"}]},{"poster":"zhangyu20000","upvote_count":"3","content":"https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/","timestamp":"1670807700.0","comment_id":"742276"},{"content":"Yes, would be cheap, but can't run a web app from Lambda","upvote_count":"5","comment_id":"812486","timestamp":"1676676000.0","comments":[{"timestamp":"1736707500.0","comment_id":"1339638","poster":"Kirkster","upvote_count":"1","content":"Of course you can run web applications from Lambda, with API Gateway (or Lambda HTTP URL) in front of it. You have to refactor a little, unless you're using ASP.NET Core, which can run nearly unmodified in Lambda using the Amazon.Lambda.AspNetCoreServer package."}],"poster":"anita_student"},{"comment_id":"763230","upvote_count":"4","poster":"yuyuyuyuyu","content":"I do not think A is the right answer. \nBecause image must be upload to the ECR.","timestamp":"1672585200.0"},{"content":"A) is not correct. AWS documentation says you can package and deploy Lambda functions AS container images. A) says Deploy Container images as lambda functions, the opposite.","upvote_count":"5","poster":"MansaMunsa","timestamp":"1679145180.0","comment_id":"842792"},{"upvote_count":"1","content":"Not trivial to move containers to lambda functions. Not impossible though. They have containers. A serverless way of directly hosting those containers is ECS fargate.","comment_id":"926484","poster":"bcx","timestamp":"1687070820.0"},{"poster":"chikorita","content":"you surely dont have any industry experience or else you wouldn't recommend to run Microservice architecture on LAMBDA functions","timestamp":"1685156520.0","comment_id":"907707","upvote_count":"10"},{"content":"You cannot run container microservices always up on Lambda. Lambda containers needs to be ad-hoc prepared to just run a predefined command that dies in max 15 minutes, so it does not make any sense.","comment_id":"1021360","poster":"puffetor","timestamp":"1696064160.0","upvote_count":"5"}],"upvote_count":"15","comment_id":"742275"},{"comment_id":"1351276","poster":"zhen234","upvote_count":"1","timestamp":"1738661400.0","content":"Selected Answer: A\nmost cost-effective and lest operational overhead"},{"poster":"Kirkster","timestamp":"1736707860.0","upvote_count":"1","comment_id":"1339639","content":"Selected Answer: B\nI was initially torn between A and B, but answer A says to upload the container image to Lambda, which isn't possible - to use a container with Lambda, you still upload the image to ECR. Answer D (Beanstalk) isn't the most cost-effective for running containers. \n\nSo between B and C (ECS vs EKS), ECS has less operational overhead, and also doesn't require the master node to be running, which means ECS will likely be very slightly cheaper, and have less operational work."},{"poster":"fbukevin","upvote_count":"1","comment_id":"1334492","content":"Selected Answer: B\nAt the time I consider B & C without doubt. But finally consider to migration efforts, I choose B. I don't really consider the cost between B & C.","timestamp":"1735603920.0"},{"timestamp":"1733162160.0","poster":"attila9778","content":"Selected Answer: B\nAWS Fargate launch type for Amazon ECS is indeed a pay-per-use model. With Fargate, you pay for the amount of vCPU and memory resources that your containerized application requests. The billing is based on the resources used from the time your container images are pulled until the Amazon ECS task terminates, rounded up to the nearest second, with a minimum charge of one minute12.\n\nThis model allows you to focus on building and managing your applications without worrying about managing the underlying infrastructure, making it a convenient and scalable option for many use cases.\nSee: https://aws.amazon.com/ecs/pricing/","upvote_count":"1","comment_id":"1321052"},{"poster":"TariqKipkemei","upvote_count":"1","comment_id":"1304863","timestamp":"1730265420.0","content":"Selected Answer: B\n\"microservices that run on containers, with a serverless architecture that minimizes operational complexity and costs\" = Amazon Elastic Container Service (Amazon ECS)"},{"upvote_count":"1","poster":"85b5b55","content":"Serverless and Most Cost-Effective Solutions - B","comment_id":"1302959","timestamp":"1729877700.0"},{"poster":"AWSum1","timestamp":"1729528620.0","comments":[{"content":"Adding to this, the questions states minimal operation complexity. ECR + ECS + ELB seems like quite a lot to manage","comment_id":"1301163","timestamp":"1729528740.0","poster":"AWSum1","upvote_count":"1"}],"upvote_count":"1","content":"Selected Answer: A\nChoosing A, Fargate had a minimum charge per minute. Lambda is per invocation. So lambda Is probably cheaper in THIS case","comment_id":"1301161"},{"poster":"c73bf38","timestamp":"1727061540.0","comment_id":"816194","comments":[{"content":"Changing to A, B is not serverless and cost-effective.","timestamp":"1677086880.0","upvote_count":"1","comments":[{"poster":"bcx","content":"Fargate is serverless by definition.","timestamp":"1687070940.0","comment_id":"926487","upvote_count":"2"}],"comment_id":"818105","poster":"c73bf38"}],"upvote_count":"4","content":"Selected Answer: B\nOption B is the most cost-effective solution for the following reasons:\n\nThe use of Fargate, a serverless compute engine for containers, eliminates the need for managing and scaling the underlying infrastructure. This minimizes operational complexity and reduces costs as the resources are used only when required.\nAuto scaling ensures that the application scales up and down based on the load, providing the required performance and availability without incurring additional costs.\nAmazon ECS is a simpler and more cost-effective solution than Amazon EKS, which requires more management and additional resources to operate the Kubernetes control plane.\nUsing Application Load Balancers to direct traffic to the ECS clusters ensures high availability and fault tolerance."},{"poster":"Jonalb","comment_id":"927304","timestamp":"1727061540.0","content":"Selected Answer: B\nExplanation:\n\nAmazon ECS with Fargate: By uploading the container images to Amazon ECR and using Amazon ECS with the Fargate launch type, you can run the microservices in containers without having to manage the underlying infrastructure. Fargate automatically scales the containers based on the load.\nSeparate Production and Testing Environments: With two separate auto-scaled Amazon ECS clusters, you can have dedicated environments for production and testing, ensuring isolation and allowing for separate deployments and configurations.\nApplication Load Balancers (ALB): Configuring two separate ALBs allows you to direct traffic to the appropriate ECS clusters. This ensures proper routing of requests between the production and testing environments.\nOption B provides a cost-effective solution by utilizing the serverless nature of Fargate, which eliminates the need to provision and manage EC2 instances explicitly. It also allows for separate environments, easy scalability, and traffic routing using ALBs, providing flexibility and minimizing operational complexity.","upvote_count":"2"},{"content":"Selected Answer: B\nOption A - This option might not work. AWS Lambda provides a cheap option to run containers however nothing is said about execution times could be a concern, i.e. AWS Lambda only provides 15 minutes of execution time \n\nOption B - This option will work. ALB, ECR, ECS and Fargate in combination will deliver a running solution.\n\nOption C - This option will work. ALB, ECR, EKS and Fargate will deliver a running solution.\n\nOption D - This option will work: Beanstalk will rely on ECS to run the containers. See https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker_ecs.html\n\nCheapest option is B.","comment_id":"1100130","timestamp":"1727061540.0","poster":"atirado","upvote_count":"5"},{"timestamp":"1725090360.0","comment_id":"1275434","poster":"amministrazione","upvote_count":"1","content":"B. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters."},{"poster":"MAZIADI","timestamp":"1723283880.0","upvote_count":"1","content":"Selected Answer: A\nA because ALB & Beanstalk are not serverless & Lambda added support to use docker images directly. you can upload container images to AWS Lambda and use them as functions. AWS Lambda introduced support for deploying functions as container images, allowing you to package and deploy Lambda functions with custom runtimes, libraries, and dependencies that might exceed the limitations of traditional Lambda deployment packages (zip files).","comment_id":"1263417"},{"upvote_count":"1","comment_id":"1240136","content":"Selected Answer: A\nNOT B and C, because ALB is not serverless architecture\nNOT D, because Beantalk is not serverless architecture\n\nA is also most effective","poster":"ukivanlamlpi","timestamp":"1719836160.0"},{"comment_id":"1235286","upvote_count":"2","timestamp":"1719047580.0","content":"Selected Answer: A\nA - COST EFFECTIVE (lambda is only solution where users pay by invocation)","poster":"4bc91ae"},{"comment_id":"1209578","poster":"[Removed]","upvote_count":"1","content":"Selected Answer: B\nOnce choose eks,do not config load balance manually","timestamp":"1715391720.0"},{"comment_id":"1185442","timestamp":"1711719060.0","upvote_count":"2","content":"Selected Answer: B\nOption B and NOT Option C: I wasn't able to find a good comparison btw AWS ECS vs AWS EKS pricing in AWS documentation however I found a few articles saying that AWS EKS has additional cost for using EKS control plane. I will leave it up to you to decide. \n\nhttps://www.densify.com/eks-best-practices/aws-ecs-vs-eks/","poster":"TonytheTiger"},{"comment_id":"1171712","content":"AWS Elastic Beanstalk is not considered a serverless architecture. While it abstracts away some of the underlying infrastructure management, it still involves running and managing EC2 instances, which are virtual servers.","upvote_count":"1","poster":"MoT0ne","timestamp":"1710249180.0"},{"comment_id":"1141751","content":"D - because BCD are right solution , D because - beanstalk runs ECS in backend + Reduce operation complexity which is asked in the question","upvote_count":"1","poster":"_Jassybanga_","timestamp":"1707193620.0"},{"timestamp":"1704054120.0","comment_id":"1110804","upvote_count":"1","poster":"liux99","content":"The confusion here is choice between B and C. Both ECS and EKS are container orchestration service which supports fargate. But ECS is aws fully managed, better suited for simple application and also more cost effective."},{"upvote_count":"2","comment_id":"1091797","poster":"ninomfr64","content":"Selected Answer: B\nNot A. as Lambda is not good for running a \"traditional web application\", also you can use container with Lambda but ECS is \"ideal for organizations that want a simple and cost-effective way to deploy and manage containerized applications\"\nNot C. as there is o pointer to EKS (e.g. open-source, industry standard, etc.) and also ECS is \"ideal for organizations that want a simple and cost-effective way to deploy and manage containerized applications\"\nNot D. as Beanstalk is not serverless\n\nHence B.","timestamp":"1702125180.0"},{"content":"Selected Answer: B\nB. Not D as Beanstalk isn't serverless. Not C because there are no pointers to use EKS. Not A, because microservices are requested.","timestamp":"1699699140.0","comment_id":"1067770","upvote_count":"1","poster":"severlight"},{"upvote_count":"2","poster":"ansgohar","timestamp":"1695893340.0","comment_id":"1019662","content":"Selected Answer: B\nB. Image on ECR and ECS cost effective over EKS."},{"upvote_count":"2","comment_id":"1006169","content":"Selected Answer: D\nI would go with d\na serverless architecture that minimizes operational complexity.","poster":"task_7","timestamp":"1694577480.0"},{"upvote_count":"1","timestamp":"1694346240.0","comment_id":"1003953","poster":"cheese929","content":"Selected Answer: B\nB is correct."},{"comment_id":"997810","upvote_count":"1","content":"B is right option.\nA is possible but Lambda container images has 10GB size limitation and requires you to keep updating these container images as customer re-factors the code. I feel A will have higher operational overhead. B is best option that will be most cost effective and operationally efficient.","poster":"career360guru","timestamp":"1693759380.0"},{"poster":"dimitry_khan_arc","content":"Selected Answer: B\nB. Image on ECR and ECS cost effective over EKS.","comment_id":"991201","timestamp":"1693109880.0","upvote_count":"1"},{"comments":[{"timestamp":"1693378500.0","comment_id":"993782","poster":"aviathor","content":"You can indeed use FarGate with EKS...\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/fargate.html","upvote_count":"1"}],"timestamp":"1690656360.0","content":"B seems right. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/launch_types.html\nC seems distractor as there is no option as Amazon EKS with Fargate Launch type.","upvote_count":"2","comment_id":"966590","poster":"Shijokingo"},{"timestamp":"1690571940.0","content":"Seems option A provides the most cost-effective solution with minimal operational complexity by leveraging AWS Lambda and API Gateway for the serverless architecture of the microservices.","comment_id":"965776","upvote_count":"1","poster":"stevegod0"},{"timestamp":"1690171980.0","poster":"hirenshah005","upvote_count":"2","comment_id":"961112","content":"Selected Answer: B\nThe key points from Q. you can get is solution have to be minimum operation overhead and most cost effective.\nThe amount of steps needed to work with Lambda are high as beyond what they mentioned in A we have to have API Gateway as well to make it work properly. Also Lambda with high concurrency is expensive compared to Fargate.\nOn the other hand B makes it super simple ECS and fargate makes it cheaper."},{"timestamp":"1687817280.0","content":"Selected Answer: B\nit's B","upvote_count":"1","poster":"NikkyDicky","comment_id":"934820"},{"poster":"SkyZeroZx","content":"Selected Answer: B\nEKS is more costly than only use fargate \nthen B","timestamp":"1687054260.0","comment_id":"926376","upvote_count":"3"},{"timestamp":"1685961420.0","upvote_count":"1","comment_id":"915343","poster":"Jonalb","content":"Selected Answer: B\nI would vote for B! \nBut the segmentation with namespace in k8s cluster is a reality for economy reasons. Although it is not a good practice."},{"poster":"rtguru","content":"B seems to be the most cost effective compared to A&C","comment_id":"904880","upvote_count":"1","timestamp":"1684844340.0"},{"timestamp":"1682196960.0","upvote_count":"1","poster":"EthicalBond","comment_id":"877644","content":"Selected Answer: B\nA is great but takes time and too many integrations\nB is serverless and easy to achieve.\nC is not serverless\nD not applicable"},{"poster":"2aldous","upvote_count":"1","comments":[{"upvote_count":"2","timestamp":"1684067940.0","comment_id":"897522","poster":"2aldous","content":"Change to \"B\", because A says \"upload image to AWS Lambda\" that's actually not possible, you should upload the image to ECR also for Lambda container."}],"content":"A.\nBefore the discussion, check this: https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-images.html\nAlso, manage two load balancers are not cost effective.","timestamp":"1681839720.0","comment_id":"873935"},{"timestamp":"1680873360.0","upvote_count":"3","content":"B makes more sense... A says \"upload image to AWS Lambda\" that's actually not possible, you should upload the image to ECR also for Lambda container.","comment_id":"863908","poster":"dev112233xx"},{"upvote_count":"1","timestamp":"1680132840.0","poster":"cuonglc","comment_id":"855077","content":"Selected Answer: B\nb for sure"},{"timestamp":"1679978400.0","poster":"mfsec","comment_id":"852775","content":"Selected Answer: B\nECS + Fargate","upvote_count":"2"},{"comments":[{"content":"Not correct. The question already states that the application has to be migrated to a container. 'A' mentions something not feasible (uploading container images to Lambda) and also doesn't meet the requirement to migrate to a containerised architecture. \n\nOption 'B' meets all the requirements by offering a serverless way to launch containers in AWS (Fargate instances).","upvote_count":"1","comment_id":"857975","poster":"frfavoreto","timestamp":"1680357120.0"}],"poster":"kiran15789","comment_id":"835329","content":"Selected Answer: A\nConfused between A and B but after a long think decided to go with A\n\nOption A suggests uploading the container images to AWS Lambda as functions and configuring a concurrency limit to handle the expected peak load. This approach allows the company to take advantage of the benefits of serverless computing, such as auto-scaling, without having to manage any infrastructure. In addition, using Lambda integrations within Amazon API Gateway allows the company to direct traffic to the appropriate environment for testing or production.","timestamp":"1678474680.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"827940","poster":"higashikumi","content":"Option B is the most cost-effective solution that meets all the requirements.\n\nThis solution uploads the container images to Amazon Elastic Container Registry (Amazon ECR) and deploys them using Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Two separate Application Load Balancers are configured to direct traffic to the ECS clusters for production and testing.\n\nThis solution is cost-effective as it leverages the benefits of serverless architecture with Fargate launch type that removes the need for server management and the cost of running idle servers. Additionally, with auto-scaling, the resources can be dynamically adjusted to handle varying traffic. Furthermore, the use of Application Load Balancers reduces operational complexity and allows for efficient traffic routing.","timestamp":"1677845280.0"},{"comment_id":"819275","content":"Selected Answer: B\nI think the answer is B","timestamp":"1677161580.0","poster":"macc183","upvote_count":"1"},{"upvote_count":"1","poster":"c73bf38","comment_id":"818100","timestamp":"1677086700.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/definitions.html\n\nThe question states the Solutions Architect needs to update the application with a serverless architecture."},{"content":"Selected Answer: A\nAlthough I would not use this way in production, A is the cheapest.\nAll ECS/EKS needs some LB in front, plus the hourly fee of the cluster.","poster":"Sarutobi","upvote_count":"1","comment_id":"807552","timestamp":"1676303340.0"},{"comment_id":"806099","upvote_count":"1","content":"Selected Answer: B\nB is cheaper than C, otherwise both would work","timestamp":"1676190000.0","poster":"Musk"},{"comment_id":"802408","poster":"moota","upvote_count":"1","timestamp":"1675881540.0","content":"Selected Answer: B\nA can be cheaper but it's not performant for a web application. I assume that A does not use provisioned concurrency, so I have to deal with cold starts. If I use provisioned concurrency, I can make B cheaper."},{"poster":"sergza","comment_id":"794492","timestamp":"1675188720.0","upvote_count":"2","content":"Selected Answer: A\nA is most Cost effective Does not need ALB and smallest operational overhead"},{"timestamp":"1672879440.0","comment_id":"766170","upvote_count":"2","poster":"NYB","content":"it should be ECR + ECS + Fargate, ans: B"},{"timestamp":"1672812420.0","poster":"jeussin","comment_id":"765305","upvote_count":"1","content":"Enable EKS+Fargate ??"},{"comment_id":"760217","content":"Selected Answer: B\nC & D is both valid but when it comes to cost-effective solution, I would go for ECS which does have additional cluster cost for its control plane.\nhttps://www.clickittech.com/aws/amazon-ecs-vs-eks/","poster":"skashanali","upvote_count":"2","timestamp":"1672253520.0"},{"poster":"Untamables","comment_id":"758539","upvote_count":"6","content":"Selected Answer: B\nI Vote B.\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-java-microservices-on-amazon-ecs-using-amazon-ecr-and-aws-fargate.html\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-java-microservices-on-amazon-ecs-using-amazon-ecr-and-load-balancing.html\n\nOption C and D also work, but B is the most cost-effective.\n\nOption A is wrong. It can launch only APIs and does not mention Web UI.\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-lambda-functions-with-container-images.html\n\nOption C is wrong. Amazon EKS costs more than Amazon ECS a bit.\nhttps://aws.amazon.com/ecs/pricing/\nhttps://aws.amazon.com/eks/pricing/\n\nOption D is wrong. The Docker environment of AWS Elastic Beanstalk is based on Amazon EC2. That costs more than AWS Fargate.\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html","timestamp":"1672147260.0","comments":[{"poster":"moota","timestamp":"1675880520.0","content":"It's still technically possible to return html/css with AWS Lambda like what this guy did https://stackoverflow.com/a/59385039/422842","upvote_count":"1","comment_id":"802383"}]},{"timestamp":"1671774360.0","comment_id":"753882","poster":"ptpho","upvote_count":"5","content":"I go with B.\nwhy EKS while there is no K8s.\nJust ECS is OK (cost saving and container support)"},{"poster":"yuyuyuyuyu","content":"I think the correct answer is B.\nC has no notion of tasks.","comment_id":"753290","upvote_count":"1","timestamp":"1671713220.0"},{"upvote_count":"3","comments":[{"comment_id":"774686","content":"Option C, using Amazon EKS with Fargate launch type, would be a valid solution for deploying containerized microservices, but it may not be the most cost-effective option. Amazon EKS is a managed Kubernetes service that is more complex to set up and operate than other container orchestration options like Amazon ECS or Elastic Beanstalk. It also generally incurs additional costs for the management of Kubernetes control plane and worker nodes. For a simple use case with a known load and minimal operational complexity, it may not be necessary to use a fully-managed Kubernetes service like EKS and a simpler solution like ECS or Elastic Beanstalk may be more cost-effective.","timestamp":"1673628900.0","poster":"masetromain","upvote_count":"2"}],"content":"Selected Answer: C\nAnswer C makes the most sense\nhttps://aws.amazon.com/eks/\nhttps://aws.amazon.com/ecr/","comment_id":"741142","poster":"masetromain","timestamp":"1670693580.0"}],"topic":"1","answers_community":["B (81%)","Other"],"question_images":[],"answer_ET":"B","answer_images":[],"question_id":497,"answer":"B","isMC":true},{"id":"yWODGI399jelgtKYr7XC","answers_community":["D (77%)","B (20%)","3%"],"topic":"1","answer_description":"","exam_id":33,"choices":{"D":"Create an organization in AWS Organizations. Turn on all features for the organization. Create and configure an AD Connector to connect to the company’s on-premises Active Directory. Configure IAM Identity Center and set the AD Connector as the identity source. Create permission sets and map them to the existing groups within the company’s Active Directory.","B":"Create an organization in AWS Organizations. Turn on the IAM Identity Center feature in Organizations. Create and configure an AD Connector to connect to the company’s on-premises Active Directory. Configure IAM Identity Center and select the AD Connector as the identity source. Create permission sets and map them to the existing groups within the company’s Active Directory.","A":"Create an organization in AWS Organizations. Turn on the IAM Identity Center feature in Organizations. Create and configure a directory in AWS Directory Service for Microsoft Active Directory (AWS Managed Microsoft AD) with a two-way trust to the company’s on-premises Active Directory. Configure IAM Identity Center and set the AWS Managed Microsoft AD directory as the identity source. Create permission sets and map them to the existing groups within the AWS Managed Microsoft AD directory.","C":"Create an organization in AWS Organizations. Turn on all features for the organization. Create and configure a directory in AWS Directory Service for Microsoft Active Directory (AWS Managed Microsoft AD) with a two-way trust to the company’s on-premises Active Directory. Configure IAM Identity Center and select the AWS Managed Microsoft AD directory as the identity source. Create permission sets and map them to the existing groups within the AWS Managed Microsoft AD directory."},"url":"https://www.examtopics.com/discussions/amazon/view/95289-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"D","discussion":[{"comment_id":"778224","timestamp":"1673901300.0","content":"Selected Answer: D\nhttps://www.examtopics.com/discussions/amazon/view/69172-exam-aws-certified-solutions-architect-professional-topic-1/\n\nYou are correct, I apologize for the oversight. To meet the requirements of the IT support workers, option D would be the correct solution:\n\nThis option will first enable all features in AWS Organizations, then create and configure an AD Connector to connect to the company's on-premises Active Directory. Then, it will configure IAM Identity Center (AWS SSO) and set the AD Connector as the identity source, allowing the IT support workers to access the console using their existing Active Directory credentials. Finally, it will create permission sets and map them to the existing groups within the company's Active Directory. This solution will also be cost-effective as it does not involve creating a new directory in AWS Directory Service.","poster":"masetromain","upvote_count":"22"},{"content":"Selected Answer: D\nD is the correct answer.. B is wrong answer \n\nFrom aws documentation:\nQ: Which AWS accounts can I connect to IAM Identity Center?\n\nYou can add any AWS account managed using AWS Organizations to IAM Identity Center. You need to enable all features in your organizations to manage your accounts single sign-on.","upvote_count":"17","poster":"dev112233xx","comment_id":"843198","timestamp":"1679177100.0","comments":[{"timestamp":"1703698980.0","poster":"carpa_jo","comment_id":"1107039","upvote_count":"1","content":"Source: https://aws.amazon.com/iam/identity-center/faqs/#product-faqs#iam-identity-center-faqs#identity-sources-and-applications-support"}]},{"upvote_count":"1","poster":"scaag92","content":"Selected Answer: B\nOpción B dice: \"...Enciende la funcionalidad de IAM Identity Center en Organizations...\" (Activa solo lo necesario para SSO).\n\nOpción D dice: \"...Enciende todas las funcionalidades para la organización...\" (Activa todo lo que Organizations puede hacer). \nAmbas B y D eligen la forma económica de conectar con AD (usando AD Connector). Pero la Opción B es más precisa y sigue mejor las buenas prácticas al activar solo la funcionalidad específica de IAM Identity Center que se necesita, en lugar de activar \"todas\" las funcionalidades de Organizations (como dice la D) que no son requeridas para esta tarea en particular. Por eso, B es la respuesta ligeramente mejor y más correcta.","comment_id":"1558732","timestamp":"1744061820.0"},{"timestamp":"1743558960.0","content":"Selected Answer: D\nAnswer is D:\nI quote:\nAWS Organizations is recommended, but not required, for use with IAM Identity Center. If you haven't set up an organization, you don't have to. If you've already set up AWS Organizations and are going to add IAM Identity Center to your organization, make sure that all AWS Organizations features are enabled\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/identity-center-prerequisites.html","poster":"BelloMio","upvote_count":"1","comment_id":"1419712"},{"poster":"hhiguita","comment_id":"1405095","content":"Selected Answer: B\nAll features is not required.","comments":[],"upvote_count":"1","timestamp":"1742758800.0"},{"upvote_count":"1","poster":"29fb203","comment_id":"1380676","timestamp":"1741608300.0","content":"Selected Answer: B\nAll features is not required."},{"content":"Selected Answer: B\nLower cost compared to AWS Managed Microsoft AD, since AD Connector does not require an additional managed directory service. Also, is answer D AWS Organizations does not require \"all features\" for IAM Identity Center to work with AD Connector. \"All features\" is needed for SCPs and governance, not for SSO setup.","upvote_count":"1","comment_id":"1370829","poster":"LeoSantos121212121212121","timestamp":"1741524420.0"},{"poster":"shmoeee","upvote_count":"1","comment_id":"1346244","content":"Selected Answer: D\n\"Need to turn on all features\" didn't sound cost effective...but apparently it's a requirement to provide SSO","timestamp":"1737754080.0"},{"comment_id":"1327640","content":"Selected Answer: B\nQuestion asks \"MOST cost-effectively\". Turning on all features is free of charge but used resources will make up a cost.\n\nD is wrong because: enabling All Features in AWS Organizations introduces governance tools that the company does not require, making it less cost-effective than B.","poster":"JOJO9","upvote_count":"3","timestamp":"1734383580.0"},{"poster":"amministrazione","content":"D. Create an organization in AWS Organizations. Turn on all features for the organization. Create and configure an AD Connector to connect to the company’s on-premises Active Directory. Configure IAM Identity Center and set the AD Connector as the identity source. Create permission sets and map them to the existing groups within the company’s Active Directory.","comments":[{"upvote_count":"1","poster":"pk0619","comment_id":"1328718","timestamp":"1734556800.0","content":"You need to enable all features for the organization to set up single sign-on for accounts."}],"timestamp":"1725095580.0","comment_id":"1275526","upvote_count":"1"},{"content":"Selected Answer: B\nB, Turn on the IAM Identity Center feature in Organizations... similar to D, but without enabling directy the SSO, you can't configure it...","poster":"gofavad926","timestamp":"1710664320.0","upvote_count":"2","comment_id":"1175677","comments":[{"content":"just D","timestamp":"1725435660.0","poster":"helloworldabc","comment_id":"1278087","upvote_count":"1"}]},{"content":"Selected Answer: D\nOption D is the best because AWS FAQs asked the following question and answered: \"Which AWS accounts can I connect to IAM Identity Center?\nYou can add any AWS account managed using AWS Organizations to IAM Identity Center. You need to enable all features in your organizations to manage your accounts single sign-on.\" Link: https://aws.amazon.com/iam/identity-center/faqs/#product-faqs#iam-identity-center-faqs#identity-sources-and-applications-support.\nWith the clarification that enabling all features in AWS Organizations is necessary for integrating with IAM Identity Center, Option D becomes the most accurate and compliant solution. It correctly combines the need to enable all features in AWS Organizations with the use of an AD Connector for a direct connection to the company’s on-premises Active Directory, which remains the most cost-effective way to leverage existing Active Directory credentials for AWS console access.","poster":"8608f25","timestamp":"1707585480.0","upvote_count":"1","comment_id":"1146447"},{"poster":"LazyAutonomy","comment_id":"1137800","content":"Selected Answer: D\nMost cost effective is D.\n\nBut C is also technically a valid solution that meets all the other requirements. A two way trust means AD users in the on-premise AD can be added to AD groups in the AWS-managed AD.","timestamp":"1706809380.0","upvote_count":"1"},{"poster":"ninomfr64","timestamp":"1705226400.0","upvote_count":"5","comment_id":"1122440","content":"Selected Answer: D\nA = you do not turn on AWS IdC feature only in AWS Orgs. It is either Consolidation billing or All features\nB = same as above\nC = requirements is to login users based on-premise AD, for this there is no need to AWS Managed AD with a local domain/directory and 2-way trust. AD Connector is enough and cheaper\nD = correct"},{"upvote_count":"1","timestamp":"1704479040.0","poster":"marszalekm","comment_id":"1114721","content":"I love such questions, while both B and D seems reasonable, I thinking more about B because of this https://docs.aws.amazon.com/singlesignon/latest/userguide/get-set-up-for-idc.html"},{"upvote_count":"3","comment_id":"1099111","timestamp":"1702834800.0","content":"Selected Answer: B\nyou can absolutely use an AD Connector as the identity source for AWS IAM Identity Center without turning on all features in your AWS organization. In fact, it's the most cost-effective and recommended approach if you only need single sign-on functionality with your existing on-premises Active Directory","poster":"Russs99"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/prereq-orgs.html\n\n```If you've already set up AWS Organizations and are going to add IAM Identity Center to your organization, make sure that all AWS Organizations features are enabled. When you create an organization, enabling all features is the default.```","poster":"holymancolin","comment_id":"1078422","upvote_count":"4","timestamp":"1700742480.0"},{"content":"Selected Answer: D\nsee dev112233xx's answer","poster":"severlight","comment_id":"1070048","timestamp":"1699942080.0","upvote_count":"1"},{"timestamp":"1695814380.0","upvote_count":"2","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/get-started-prereqs-considerations.html#:~:text=if%20you've%20already%20set%20up%20aws%20organizations%2C%20make%20sure%20that%20all%20features%20are%20enabled.","poster":"Tofu13","comment_id":"1018755"},{"upvote_count":"1","comments":[{"content":"Actually not. AWS Org has 2 feature modes: All features enabled (default) and Consolidated billing. AWS Orgs is free of charge regardless feature mode select see Billing section in the https://aws.amazon.com/organizations/faqs/","timestamp":"1705227600.0","poster":"ninomfr64","comment_id":"1122452","upvote_count":"2"}],"poster":"[Removed]","content":"Selected Answer: B\ni think it's b because having all the features enabled is not a requirement, otherwise it could incour in more charges. the features are not enabled by default , you have to go one by one or select all to enable them","timestamp":"1689814320.0","comment_id":"957029"},{"upvote_count":"1","comment_id":"941144","content":"Selected Answer: D\nIt's D.\nB would work if was supported","timestamp":"1688321040.0","poster":"NikkyDicky"},{"timestamp":"1683995820.0","comment_id":"896891","upvote_count":"3","poster":"karma4moksha","content":"Selected Answer: D\nAfter reading all comments i concur with D. Reason being , requirement is no duplication fs users so it all stay at one place, thats what they want. So rule out all the 2-way trust options. Why not B? because there is no way in AWS organisations, you can only enable IAM identity center. The available feature sets are only two : All features, or only consolidated billing. Check here https://docs.aws.amazon.com/organizations/latest/userguide/orgs_getting-started_concepts.html#feature-set-cb-only"},{"comment_id":"891613","upvote_count":"4","content":"Selected Answer: D\nThe options where they turn on only the AWS SSO feature in Organizations must be excluded (A and B). Because it is a requirement to have all features enabled in the organizations.\nReference from https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_org_support-all-features.html\nPrerequisites for using AWS IAM Identity Center or former AWS SSO:\n“Your AWS account must be managed by AWS Organizations. If you have not set up an organization, you don’t have to. When you enable IAM IC, you will choose whether to have AWS create an organization for you.\nIf you already set up AWS Organizations, make sure that all features are enabled.”\nBetween C and D, you do not need to create and configure a new AWS Managed Microsoft AD since you already have an AD present in the on premises, so there is no reason to expend more on this solution. Hence the response is D.","poster":"rbm2023","timestamp":"1683482880.0"},{"poster":"Cccb35","upvote_count":"3","comment_id":"891553","timestamp":"1683477120.0","content":"Selected Answer: B\nI think, the correct is \"B\". Because, when you create an organization, enabling all features is the default, according this link: https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_org_support-all-features.html\n\n\"When you create an organization, enabling all features is the default. With all features enabled, you can use the advanced account management features available in AWS Organizations such as integration with supported AWS services and organization management policies.\"\n\nThis would rule out the option \"D\""},{"content":"Selected Answer: D\nD as Vherman said below","timestamp":"1680038340.0","comment_id":"853716","upvote_count":"2","poster":"Amac1979"},{"timestamp":"1679832360.0","comment_id":"850969","poster":"mfsec","upvote_count":"2","content":"Selected Answer: D\nOption D is the most cost-effective"},{"timestamp":"1678705920.0","poster":"vherman","comment_id":"837878","upvote_count":"4","content":"Selected Answer: D\nD is correct\nThere is no IAM Identity Center feature in Organizations. hence, B is out","comments":[{"upvote_count":"2","timestamp":"1679415420.0","poster":"senhorjorge","comment_id":"846152","content":"Yes there is and it should be all you need to enable, therefore B is correct."}]},{"comment_id":"829394","content":"Selected Answer: D\nSee pre-requisites for AWS SSO: https://docs.aws.amazon.com/singlesignon/latest/userguide/get-started-prereqs-considerations.html","poster":"anita_student","upvote_count":"3","timestamp":"1677962340.0"},{"upvote_count":"1","comment_id":"827608","comments":[{"content":"https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_ad_connector.html\n\nI assume single account is Management account and it does not need org features enabled.See above link and follow all steps listed there. no necessity to enable organizations features. I stick with B only.","timestamp":"1677813420.0","upvote_count":"2","comment_id":"827630","poster":"God_Is_Love"},{"poster":"God_Is_Love","timestamp":"1677811500.0","content":"This link someone posted https://docs.aws.amazon.com/singlesignon/latest/userguide/get-started-prereqs-considerations.html\nis in favor of D. but I think, here in question , its a single account only. I am resistant to choose D, I could be wrong though.","comment_id":"827612","upvote_count":"1"}],"content":"Selected Answer: B\nQuestion : Does aws AD connector configuration needs aws organization features turned on ?\n\nChatGPT : Answer No, AWS Microsoft AD Connector does not require AWS Organization features to be turned on.\n\nThe AWS Microsoft AD Connector is a standalone service that enables you to connect your AWS resources to an existing Microsoft Active Directory (AD) domain or forest. It does not depend on or require any specific AWS organization features or settings.\n\nHowever, if you are using AWS Directory Service to create a new AD directory in AWS, you can choose to enable AWS Organizations integration to simplify the management of multiple AWS accounts. This integration allows you to manage AWS Directory Service directories across multiple AWS accounts and regions from a single master account.\n\nBut again, this is an optional feature and does not affect the functionality of the AWS Microsoft AD Connector itself. You can use the AWS Microsoft AD Connector without enabling AWS Organizations integration if you prefer.","timestamp":"1677811200.0","poster":"God_Is_Love"},{"content":"Selected Answer: D\nCorrecting the Answer - Its D","comment_id":"814656","timestamp":"1676848800.0","poster":"spd","upvote_count":"2"},{"upvote_count":"1","timestamp":"1676590200.0","comment_id":"811198","comments":[{"content":"It's D. You need it s explained in https://docs.aws.amazon.com/singlesignon/latest/userguide/get-started-prereqs-considerations.html","timestamp":"1676726460.0","upvote_count":"5","comment_id":"812999","poster":"Musk","comments":[{"content":"Thanks, so its not B.","poster":"spd","timestamp":"1676848740.0","upvote_count":"1","comment_id":"814655","comments":[{"upvote_count":"1","timestamp":"1676911560.0","poster":"Musk","content":"Exactly, it's not B. Additionally, B refers to enabling IAM Identity Center in Organizations, and you would enable that in the IAM Identity Center console. What's confusing about D is that it does not refer to enabling it.","comment_id":"815554"}]}]}],"content":"Selected Answer: B\nB - Why need all feature","poster":"spd"},{"poster":"DWsk","upvote_count":"5","content":"Selected Answer: D\nThis one is tricky because in order to enable SSO in Organizations you need to enable all features. Thanks @moota for the explanation","comment_id":"811093","timestamp":"1676581080.0"},{"comment_id":"809669","upvote_count":"1","timestamp":"1676473140.0","content":"Selected Answer: B\njust need a feature with AD connector","poster":"klog"},{"upvote_count":"3","comments":[{"content":"The keyword is \"Accounts\" vs \"single account\", why is All Features required for a single account?","upvote_count":"1","timestamp":"1676526060.0","comment_id":"810287","poster":"c73bf38","comments":[{"timestamp":"1677625080.0","poster":"Sarutobi","comment_id":"825368","upvote_count":"1","content":"Take a look at this link: https://docs.aws.amazon.com/singlesignon/latest/userguide/get-started-prereqs-considerations.html scroll down to \"If you've already set up AWS Organizations, make sure that all features are enabled. \""},{"content":"Because the ONLY OTHER option is to enable Consolidated Billing, which is of no use here, hence All Features must be enabled","poster":"scuzzy2010","upvote_count":"1","comment_id":"819972","timestamp":"1677201360.0"}]}],"timestamp":"1676088060.0","content":"Selected Answer: D\nThere are only two feature sets to turn on.\nAll features – The default feature set that is available to AWS Organizations. It includes all the functionality of consolidated billing, plus advanced features that give you more control over accounts in your organization.\n\nConsolidated billing – This feature set provides shared billing functionality, but doesn't include the more advanced features of AWS Organizations. For example, you can't enable other AWS services to integrate with your organization to work across all of its accounts, or use policies to restrict what users and roles in different accounts can do. To use the advanced AWS Organizations features, you must enable all features in your organization.","comment_id":"804976","poster":"moota"},{"timestamp":"1675284600.0","upvote_count":"1","poster":"jojom19980","comment_id":"795518","content":"AWS SSO is configured to use AD Connector as an identity source\nhttps://controltower.aws-management.tools/aa/sso/ad_connector/"},{"upvote_count":"3","comment_id":"790732","poster":"Untamables","timestamp":"1674920100.0","comments":[{"poster":"Kazr","timestamp":"1674941160.0","upvote_count":"1","content":"https://docs.aws.amazon.com/singlesignon/latest/userguide/connectonpremad.html\n\nAWS IAM Identity Center (successor to AWS Single Sign-On) \"requires a two-way trust\" so that it has permissions to read user and group information from your domain to synchronize user and group metadata. IAM Identity Center uses this metadata when assigning access to \"permission sets\" or applications.","comment_id":"791109"}],"content":"Selected Answer: A\nA\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/connectonpremad.html\nhttps://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_ad_connector.html\nOption B is wrong. AD Connector is a directory gateway that can redirect directory requests to your self-managed AD. Hence you cannot create permission sets and map them with the AD.\nOption C and D are wrong. There is no need to enable all features in AWS Organizations.\nhttps://docs.aws.amazon.com/organizations/latest/userguide/services-that-can-integrate-sso.html"},{"upvote_count":"3","timestamp":"1673809740.0","comment_id":"776968","poster":"zhangyu20000","content":"D is correct"},{"comments":[{"timestamp":"1673712720.0","upvote_count":"2","comment_id":"775685","content":"Choice A is not the best solution because it creates and configures a directory in AWS Directory Service for Microsoft Active Directory (AWS Managed Microsoft AD) with a two-way trust to the company’s on-premises Active Directory, which may lead to additional costs and complexity.\nChoice C and D are not the best solutions as they turn on all features for the organization, which is not necessary to achieve the desired functionality and may lead to additional costs and complexity.","poster":"masetromain"},{"poster":"Amac1979","timestamp":"1676028600.0","content":"B is correct.. question explicitly says \"one account\". No need to enable all features in this case.","upvote_count":"2","comment_id":"804244"}],"content":"Selected Answer: B\nThe correct answer is B.\n\nIn this solution, the company creates an organization in AWS Organizations, turns on the IAM Identity Center feature in Organizations, creates and configures an AD Connector to connect to the company’s on-premises Active Directory, configures IAM Identity Center and selects the AD Connector as the identity source, and creates permission sets and maps them to the existing groups within the company’s Active Directory.\n\nThis solution meets the requirements of the company's IT support workers, as it allows them to use their existing Active Directory credentials to access the AWS Management Console. Additionally, the solution is most cost-effective as it only uses the necessary features of AWS Organizations and IAM Identity Center to achieve the desired functionality without unnecessary costs.","timestamp":"1673712720.0","comment_id":"775684","poster":"masetromain","upvote_count":"3"}],"answer_ET":"D","question_text":"A company has an environment that has a single AWS account. A solutions architect is reviewing the environment to recommend what the company could improve specifically in terms of access to the AWS Management Console. The company’s IT support workers currently access the console for administrative tasks, authenticating with named IAM users that have been mapped to their job role.\n\nThe IT support workers no longer want to maintain both their Active Directory and IAM user accounts. They want to be able to access the console by using their existing Active Directory credentials. The solutions architect is using AWS IAM Identity Center (AWS Single Sign-On) to implement this functionality.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_images":[],"question_id":498,"timestamp":"2023-01-14 17:12:00","question_images":[],"unix_timestamp":1673712720,"isMC":true},{"id":"qbxXqwbisjMXGBAtnhXn","unix_timestamp":1673712840,"discussion":[{"comment_id":"793312","upvote_count":"12","poster":"zozza2023","timestamp":"1675111380.0","content":"Selected Answer: AD\nTransfer Accelerator + Multi-part uploads for files more 500MB"},{"poster":"OCHT","comment_id":"862126","upvote_count":"7","content":"Selected Answer: AD\nExplanation for this .\n\nB: Configuring an S3 bucket in each Region to receive the uploads and using S3 Cross-Region Replication to copy the files to the distribution S3 bucket may improve data durability and availability, but it does not address the issue of slow uploads from Australia.\n\nC: Amazon Route 53 with latency-based routing can route the uploads to the nearest S3 bucket Region based on network latency, but it cannot guarantee faster upload speeds or better reliability.\n\nE: Adding random prefixes to the files before uploading will not improve upload performance or reliability.\n\nThence, I select A and D.","timestamp":"1680700320.0"},{"content":"A. Enable S3 Transfer Acceleration on the S3 bucket. Configure the app to use the Transfer Acceleration endpoint for uploads.\nD. Configure the app to break the video files into chunks. Use a multipart upload to transfer files to Amazon S3.","comment_id":"1275527","poster":"amministrazione","timestamp":"1725095580.0","upvote_count":"1"},{"timestamp":"1705229340.0","content":"Selected Answer: AD\nA = correct (improve upload performance)\nB = this could work along with C to improve performance, but this will not fix upload failure for files >5GB as you need multi-part upload\nC = se answer B\nD = correct (required to fix upload failures for >5GB files)\nE = this could help with throttling which is not clearly stated as an issue","upvote_count":"1","comment_id":"1122465","poster":"ninomfr64"},{"timestamp":"1692772440.0","content":"Selected Answer: DE\nAnswer: A, D? Maybe. But I prefer D and E. Let me explain why:\n\nRequirement is: \"A solutions architect must improve the app’s performance for these uploads.\"\n\nShould we change S3 or the app? (or both?) \n\nDepending on how you interpret this question, you might think on the app, then it should be D and E, seriously. And it DOES make sense. Bear with me here. If you break the files into chunks, you will still have to upload them, let's say 10GB. And here comes the option E, which helps improving uploads with PARALELLISM, and you didn't touch S3 to fix that, just the app :)\n\nB and C would also work and would address the issue with users in Australia but it would change their design. I am not sure this is required, but in the real world, it's good to have options ;)\n\nAll in all, I personally would go with D, E, but AD and BC would also work.","poster":"chico2023","upvote_count":"1","comment_id":"988000"},{"content":"Selected Answer: AD\nits AD","timestamp":"1688321220.0","upvote_count":"2","poster":"NikkyDicky","comment_id":"941145"},{"upvote_count":"1","timestamp":"1687284540.0","poster":"Maria2023","comment_id":"928675","content":"Selected Answer: AD\nA and D satisfy the requirement"},{"content":"Selected Answer: AD\nTransfer Accelerator + Multi-part uploads for files more 500MB\nQuestion similar to AWS Certified Solutions Architect Associate","timestamp":"1684693980.0","comment_id":"903466","poster":"SkyZeroZx","upvote_count":"1"},{"comment_id":"850970","content":"Selected Answer: AD\nAD all day","poster":"mfsec","upvote_count":"2","timestamp":"1679832480.0"},{"poster":"aqiao","content":"Selected Answer: AD\nB is not suitable here, since it wants to improve upload experience, not download","timestamp":"1678875780.0","comment_id":"839772","upvote_count":"2"},{"content":"I like AD but I am unsure. If the users in US don't complain about issues, it must be because multi-part upload is already enabled, otherwise it would fail 50% of the times. If only Australia users complain, it must be something else... Maybe A+B is a better option, although B is not the most cost efficient certainly.","poster":"Musk","timestamp":"1675098780.0","upvote_count":"2","comment_id":"793084"},{"content":"AD is correct","timestamp":"1673809860.0","upvote_count":"1","comment_id":"776971","poster":"zhangyu20000"},{"content":"Selected Answer: AD\nhttps://www.examtopics.com/discussions/amazon/view/74177-exam-aws-certified-solutions-architect-professional-topic-1/\n\nThe correct answers would be A and D.\n\nA. Enabling S3 Transfer Acceleration on the S3 bucket and configuring the app to use the Transfer Acceleration endpoint for uploads will improve the app's performance for users in Australia by providing a fast and secure way to transfer large files over the Internet.\n\nD. Configuring the app to break the video files into chunks and using a multipart upload to transfer files to Amazon S3, will improve the app's performance for users in Australia by allowing them to upload large files in parallel, which can increase upload speed and reduce the risk of upload failures.","timestamp":"1673712840.0","comment_id":"775689","upvote_count":"4","poster":"masetromain","comments":[{"poster":"masetromain","content":"B. Configuring an S3 bucket in each Region to receive the uploads and using S3 Cross-Region Replication to copy the files to the distribution S3 bucket is not the most cost-effective solution for this specific use case.\n\nC. Setting up Amazon Route 53 with latency-based routing to route the uploads to the nearest S3 bucket Region is not a solution that would improve the performance of the uploads specifically for users in Australia.\n\nE. Modifying the app to add random prefixes to the files before uploading will not improve the app's performance for users in Australia.","timestamp":"1673712840.0","comments":[{"comment_id":"831582","upvote_count":"2","timestamp":"1678166760.0","content":"yes, it will. Other options are more important, but sure random (rsp. any hash that distributes well) prefixes improve performance a lot.","poster":"hobokabobo"}],"comment_id":"775690","upvote_count":"1"}]}],"exam_id":33,"question_images":[],"answer_ET":"AD","answers_community":["AD (97%)","3%"],"question_id":499,"question_text":"A video streaming company recently launched a mobile app for video sharing. The app uploads various files to an Amazon S3 bucket in the us-east-1 Region. The files range in size from 1 GB to 10 GB.\n\nUsers who access the app from Australia have experienced uploads that take long periods of time. Sometimes the files fail to completely upload for these users. A solutions architect must improve the app’s performance for these uploads.\n\nWhich solutions will meet these requirements? (Choose two.)","answer":"AD","choices":{"B":"Configure an S3 bucket in each Region to receive the uploads. Use S3 Cross-Region Replication to copy the files to the distribution S3 bucket.","D":"Configure the app to break the video files into chunks. Use a multipart upload to transfer files to Amazon S3.","A":"Enable S3 Transfer Acceleration on the S3 bucket. Configure the app to use the Transfer Acceleration endpoint for uploads.","E":"Modify the app to add random prefixes to the files before uploading.","C":"Set up Amazon Route 53 with latency-based routing to route the uploads to the nearest S3 bucket Region."},"timestamp":"2023-01-14 17:14:00","answer_description":"","isMC":true,"topic":"1","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/95290-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"nLbDTnvg82iwx4yr90H2","topic":"1","answers_community":["B (100%)"],"unix_timestamp":1673712960,"answer_images":[],"question_text":"An application is using an Amazon RDS for MySQL Multi-AZ DB instance in the us-east-1 Region. After a failover test, the application lost the connections to the database and could not re-establish the connections. After a restart of the application, the application re-established the connections.\n\nA solutions architect must implement a solution so that the application can re-establish connections to the database without requiring a restart.\n\nWhich solution will meet these requirements?","question_images":[],"isMC":true,"choices":{"A":"Create an Amazon Aurora MySQL Serverless v1 DB instance. Migrate the RDS DB instance to the Aurora Serverless v1 DB instance. Update the connection settings in the application to point to the Aurora reader endpoint.","D":"Create an Amazon S3 bucket. Export the database to Amazon S3 by using AWS Database Migration Service (AWS DMS). Configure Amazon Athena to use the S3 bucket as a data store. Install the latest Open Database Connectivity (ODBC) driver for the application. Update the connection settings in the application to point to the Athena endpoint","C":"Create a two-node Amazon Aurora MySQL DB cluster. Migrate the RDS DB instance to the Aurora DB cluster. Create an RDS proxy. Configure the existing RDS endpoint as a target. Update the connection settings in the application to point to the RDS proxy endpoint.","B":"Create an RDS proxy. Configure the existing RDS endpoint as a target. Update the connection settings in the application to point to the RDS proxy endpoint."},"answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/95291-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_description":"","discussion":[{"poster":"God_Is_Love","content":"Selected Answer: B\nAmazon RDS Proxy is a fully managed database proxy service for Amazon Relational Database Service (RDS) that makes applications more scalable, resilient, and secure. It allows applications to pool and share connections to an RDS database, which can help reduce database connection overhead, improve scalability, and provide automatic failover and high availability.","upvote_count":"10","timestamp":"1677816360.0","comment_id":"827647"},{"poster":"zhangyu20000","upvote_count":"7","comment_id":"777081","timestamp":"1673818140.0","content":"B is correct.\nC: Aurora is useless, Proxy is pointing to existing RDS"},{"content":"B. Create an RDS proxy. Configure the existing RDS endpoint as a target. Update the connection settings in the application to point to the RDS proxy endpoint.","timestamp":"1725095640.0","upvote_count":"1","comment_id":"1275528","poster":"amministrazione"},{"poster":"pangchn","content":"Selected Answer: B\nC is wrong since RDS proxy for Aurora cluster only support reader endpoint, where in question it doesn't mention the read-only as requirement","comment_id":"1188492","upvote_count":"1","timestamp":"1712123760.0"},{"poster":"ninomfr64","content":"Selected Answer: B\nA = using Aurora MySQL Serverless will not fix the issue, also serverless V1 is not great with HA. If you are running a single instance (no read replicas) it will attempt to create a new DB Instance in the same AZ\nB = correct (RDS Proxy in addition to pooling connections, makes applications more resilient to database failures by automatically connecting to a standby DB instance while preserving application connections and detects failover and routes requests to standby instance up to 66% faster failover time)\nC = Creating and migrating to Aurora cluster is not needed, RDS Proxy is enough\nD = this requires a lot of work","timestamp":"1705230000.0","comment_id":"1122475","upvote_count":"5"},{"content":"Selected Answer: B\nit's a B","comment_id":"941189","poster":"NikkyDicky","upvote_count":"1","timestamp":"1688326440.0"},{"comment_id":"926781","poster":"SkyZeroZx","upvote_count":"1","content":"Selected Answer: B\nkeyword = RDS proxy","timestamp":"1687103100.0"},{"poster":"mfsec","timestamp":"1679832540.0","comment_id":"850971","upvote_count":"1","content":"Selected Answer: B\nCreate an RDS proxy."},{"content":"Selected Answer: B\nproxy will be a buffer","upvote_count":"1","timestamp":"1676473380.0","comment_id":"809673","poster":"klog"},{"content":"Selected Answer: B\nThe correct solution is B. Create an RDS proxy. Configure the existing RDS endpoint as a target. Update the connection settings in the application to point to the RDS proxy endpoint.\n\nAn RDS proxy is a service that allows you to pool and share connections to an RDS database. By using an RDS proxy, your application can automatically reconnect to the database after a failover event, without the need to restart the application.\n\nSolution A, migrating to Aurora Serverless, may not solve the problem because Aurora Serverless does not support Multi-AZ.\nSolution C and D are not the correct solutions because it does not solve the problem of reconnecting to the database after a failover event.","comment_id":"775693","comments":[{"comments":[{"timestamp":"1685619960.0","upvote_count":"1","poster":"chikorita","content":"was about to point this","comment_id":"912033"},{"timestamp":"1685697060.0","comment_id":"912671","upvote_count":"7","comments":[{"upvote_count":"1","content":"masetromain ~> X \nGPTromain ~> O lol","poster":"k8s_Seoul","timestamp":"1693979640.0","comment_id":"1000205"}],"content":"they are copying the answers from chatgpt","poster":"BabaP"}],"poster":"God_Is_Love","comment_id":"827645","timestamp":"1677815940.0","content":"What?? Aurora does not support Multi AZ ? its a blunder !","upvote_count":"5"},{"content":"Even if the person is copying from chatgpt, they are saving your time and giving some pointers.","timestamp":"1703742360.0","poster":"SeemaDataReader","comment_id":"1107458","upvote_count":"1"}],"poster":"masetromain","timestamp":"1673712960.0","upvote_count":"4"}],"exam_id":33,"timestamp":"2023-01-14 17:16:00","answer":"B","question_id":500}],"exam":{"provider":"Amazon","name":"AWS Certified Solutions Architect - Professional SAP-C02","lastUpdated":"11 Apr 2025","isImplemented":true,"isMCOnly":true,"isBeta":false,"id":33,"numberOfQuestions":529},"currentPage":100},"__N_SSP":true}