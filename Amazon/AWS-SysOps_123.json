{"pageProps":{"questions":[{"id":"RZpftFu2HoLxgeI6X0Rd","answers_community":["D (100%)"],"answer_images":[],"answer_description":"","question_images":[],"unix_timestamp":1568005200,"exam_id":36,"isMC":true,"discussion":[{"comment_id":"52644","comments":[{"comment_id":"162778","upvote_count":"1","poster":"KhatriRocks","timestamp":"1664702820.0","content":"Kind of agree but you see the Application performs read-heavy operations, so was tempted for A but does not make sense compared to D.\nB and C are not relevant"},{"timestamp":"1664698200.0","upvote_count":"2","comment_id":"137366","content":"True: Ans D, in addition to your sentence, the other metrics do not help with monitoring the cpu utilization.","poster":"angelsrp"}],"content":"D is correct. if there is more insert query going to aurora database it will spike the cpu utilization.","timestamp":"1664614320.0","poster":"amo82","upvote_count":"11"},{"poster":"saumenP","upvote_count":"8","timestamp":"1664117160.0","comments":[{"timestamp":"1667709000.0","comment_id":"340896","upvote_count":"1","poster":"CanBe","content":"There is a difference between read-heavy and read-only."}],"comment_id":"19111","content":"it say An Application performs read-heavy operations ....then How insertLatency matrix will help to find CPU usage"},{"content":"Selected Answer: D\nmonitoring the DatabaseConnections and InsertLatency metrics (Option D) in addition to the CPUUtilization metric is recommended. These metrics can provide valuable insights into the number of connections and latency for insert queries, which can help diagnose the cause of the CPU surge.","comment_id":"946415","upvote_count":"1","timestamp":"1720436280.0","poster":"albert_kuo"},{"poster":"Akinwaleo","comment_id":"896388","timestamp":"1715572380.0","upvote_count":"1","content":"According to chat GPT the Answer is A.\n\nTo understand the CPU surge on an Amazon Aurora DB instance, in addition to monitoring the CPUUtilization CloudWatch metric, the SysOps Administrator should monitor the following:\n\n1. Database Connections: \n2. Disk Queue Depth: High Disk Queue Depth \n3. SQL Statements: \n4. Memory Usage: SysOps Administrator can monitor the \"FreeableMemory\""},{"upvote_count":"1","poster":"RicardoD","timestamp":"1667774640.0","comment_id":"350822","content":"D is the answer\n\nOne should also look for DatabaseConnections and InsertLatency for the number of connections to the DB instance and latency to insert queries."},{"upvote_count":"1","comment_id":"339032","poster":"Kimle","timestamp":"1667560740.0","content":"I believe having high CPU utilization will result in insert latency and that can arise from having high DB connections .. Memory seem irrelevant .. i would choose D over A"},{"upvote_count":"4","comment_id":"293266","poster":"Kelvin","timestamp":"1667307120.0","content":"It's C.\n\nIf an Aurora Replica runs out of CPU credits before the primary instance, the lag behind the primary instance results in the Aurora Replica frequently restarting. This result is common when an application has a heavy load of read operations distributed among Aurora Replicas in an Aurora MySQL DB cluster, at the same time that the primary instance has a minimal load of write operations.\nRef: https://docs.amazonaws.cn/en_us/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.BestPractices.html"},{"content":"D. DatabaseConnections and InsertLatency for the number of connections to the DB instance and latency for insert queries.","upvote_count":"2","timestamp":"1666854720.0","poster":"abhishek_m_86","comment_id":"273950"},{"poster":"jackdryan","content":"I'll go with D","upvote_count":"1","comment_id":"242748","timestamp":"1666176840.0"},{"comment_id":"240713","poster":"apwangzh","upvote_count":"1","content":"I think it is saying the cpu of primary instance is high, not the replica. So replicalatecy is not the main point. However, insert is made on the primary instance. So I prefer D.","timestamp":"1665930480.0"},{"poster":"Mahmoud_Borham","timestamp":"1665673500.0","upvote_count":"1","content":"D should be right as your concern is to understand why the CPU has increased, so you may need to understand how many DML queries are ongoing and from each of the connections in addition to their latency IOP .. this is closer to just monitor the CPU and memory","comment_id":"219255"},{"poster":"Newguru2020","comment_id":"210174","comments":[{"upvote_count":"1","comment_id":"267464","content":"Freeable memory doesn't seem to be a valid use case for CPU surge. Replica lag seems more plausible. Freeable memory according to AWS is \"The amount of available random access memory.\"","comments":[{"timestamp":"1666765980.0","comment_id":"267465","content":"To be clear, I think C is the correct answer - based on the link you posted.","upvote_count":"1","poster":"Manny20"}],"poster":"Manny20","timestamp":"1666316280.0"}],"upvote_count":"3","content":"Ans: A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/MonitoringOverview.html\nInvestigate consistent or trending variances from your baseline. The following metrics are often the source of performance issues:\n1) High CPU or RAM consumption\n2) Disk space consumption\n3) Network traffic \n4) Database connections\n5) IOPS metrics","timestamp":"1665389880.0"},{"comment_id":"205468","timestamp":"1665351420.0","comments":[{"comment_id":"256224","poster":"Jordanro","upvote_count":"3","content":"Don't trust these resources - they automatically get default answers from www.examtopics.com )) These answers are often wrong.","timestamp":"1666213080.0"}],"content":"I will go with D due to this links\nhttps://pegacert.com/vendor/aws/soa-c01/application-performs-readheavy-operations-amazon-aurora-23806\nhttps://www.freecram.com/question/Amazon.AWS-SysOps.v2019-09-03.q368/an-application-performs-read-heavy-operations-on-an-amazon-aurora-db-instance-the-sysops-administrator","upvote_count":"2","poster":"r_man"},{"poster":"waterzhong","upvote_count":"1","comment_id":"185087","timestamp":"1665285120.0","content":"performs read-heavy operations and not insert anything so D incorrect. The Answer is A"},{"poster":"DannyExamination","upvote_count":"2","timestamp":"1665008040.0","content":"It's C. Because it is a Read heavy application. You can assume it has a Read Only setup. So you want know about the database connection and the replication lag.","comment_id":"185023","comments":[{"upvote_count":"1","comment_id":"185025","content":"So D, is wrong DatabaseConnections and InsertLatency for the number of connections to the DB instance and latency for insert queries is all about inserting and thus writing.","poster":"DannyExamination","timestamp":"1665240720.0"}]},{"comment_id":"182023","content":"performs read-heavy operations and not insert anything so D incorrect. The Answer is A","timestamp":"1664971380.0","poster":"SONLE","upvote_count":"1"},{"poster":"MrDEVOPS","timestamp":"1664866140.0","comment_id":"167198","upvote_count":"2","content":"why not A?\nBecause RAM has a direct influence on CPU utilization.i.e in many scenarios we upgrade to bigger instance when CPU utilisation is high, upgrading means higher RAM too ri8.???"},{"content":"I will go with answer , because in a question they have mentioned the heavy read operation, so this occurs if less memory available due to the huge number of connections which utilize the virtual memory of Aurora DB and affect CPU usage.","timestamp":"1664463780.0","comment_id":"48576","upvote_count":"2","comments":[{"timestamp":"1664537460.0","upvote_count":"7","poster":"JGD","comments":[{"content":"I second this","timestamp":"1664950560.0","upvote_count":"1","poster":"shammous","comment_id":"169103"}],"comment_id":"48577","content":"I will go with answer A, because in a question they have mentioned the heavy read operation, so this occurs if less memory available due to the huge number of connections which utilize the virtual memory of Aurora DB and affect CPU usage."}],"poster":"JGD"},{"comment_id":"25788","upvote_count":"3","content":"Looks C is more appropriate even replica is not mentioned. But alternative they have mentioned read heavy.","timestamp":"1664286240.0","comments":[{"timestamp":"1664419020.0","comment_id":"31977","upvote_count":"7","content":"I revert back . Replica lag is not the reason of high CPU Utilization. Replica lag depends on network and How much DML activity going on source DB. During insert or any DML , DB Internally will put Row level or table level Lock until the transactions completed which will make other connections to wait. Repeated sessions will span the high CPU utilization for DBA Point of View. Hence D is more suited comparing other options.","poster":"karmaah"}],"poster":"karmaah"},{"upvote_count":"3","poster":"chris82","comment_id":"19663","timestamp":"1664250660.0","content":"From my understanding insertLatency generates high CPU Usage, AuroraReplicaLag is the effect of the high CPU usage, not the cause. I would choose D"},{"timestamp":"1664040480.0","poster":"kkwang","content":"D is correct. AuroraReplicaLag- there is not mentioned any replicate in question.","upvote_count":"2","comment_id":"13794"},{"comment_id":"11793","poster":"coolboylqy","content":"should be C","upvote_count":"1","timestamp":"1663941660.0"},{"content":"why not C?\nhttps://www.datadoghq.com/blog/monitoring-amazon-aurora-performance-metrics/#resource-utilization","poster":"saumenP","comment_id":"10238","upvote_count":"3","timestamp":"1663771860.0"}],"question_id":611,"question_text":"An Application performs read-heavy operations on an Amazon Aurora DB instance. A SysOps Administrator monitors the CPUUtilization CloudWatch metric and has recently seen it increase to 90%. The Administrator would like to understand what is driving the CPU surge.\nWhich of the following should the Administrator additionally monitor to understand the CPU surge?","answer":"D","choices":{"C":"DatabaseConnections and AuroraReplicaLag for the number of connections to the DB instance and the amount of lag when replicating updates from the primary instance.","A":"FreeableMemory and DatabaseConnections to understand the amount of available RAM and number of connections to DB instance.","B":"FreeableMemory and EngineUptime to understand the amount of available RAM and the amount of time the instance has been up and running.","D":"DatabaseConnections and InsertLatency for the number of connections to the DB instance and latency for insert queries."},"timestamp":"2019-09-09 07:00:00","answer_ET":"D","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/4929-exam-aws-sysops-topic-1-question-652-discussion/"},{"id":"QgtRqAP6KTiDk2jmsPJ2","question_id":612,"answer_ET":"D","answer_description":"","unix_timestamp":1573110900,"timestamp":"2019-11-07 08:15:00","choices":{"A":"Assign the same IAM role to the Administrator that is assigned to the bastion host.","D":"Create a new administrative account on the bastion host, and provide those credentials to the Administrator using AWS Secrets Manager.","B":"Provide the Administrator with the SSH key that was used for the bastion host when it was originally launched.","C":"Create a new IAM role with the same permissions as the Security team, and assign it to the Administrator."},"answer_images":[],"exam_id":36,"answer":"D","answers_community":["D (100%)"],"isMC":true,"topic":"1","discussion":[{"poster":"smplysam","comment_id":"40637","content":"D is the MOST secure way of providing access. Providing the SSH key that was used while launching the instance, means providing root access. Its definitely not advisable to share the original keypair, and you also wouldn't be sure if the SysOps Admin would keep it safe. By creating an Administrative account, you can still restrict the access that is required by the admin (ALMOST full access but not root access), and storing the credentials in AWS Secrets Manger would ensure that they are safe and secure.","upvote_count":"17","timestamp":"1665820320.0"},{"poster":"albert_kuo","comment_id":"946416","content":"Selected Answer: D\nBy creating a new administrative account on the bastion host, separate from the existing accounts managed by the Security team, and securely storing the credentials in AWS Secrets Manager, the Security team can provide controlled access to the SysOps Administrator. AWS Secrets Manager enables secure storage and retrieval of secrets, such as passwords and access keys, and provides integration with IAM for access management.\n\nThis approach allows for fine-grained control over the access to the bastion host by managing the credentials separately. It also offers auditability and the ability to rotate the secrets periodically to enhance security.","upvote_count":"1","timestamp":"1720436460.0"},{"poster":"asfsdfsdf","comment_id":"551233","timestamp":"1676831340.0","upvote_count":"2","content":"Selected Answer: D\nI would go with D and not the default answer.\nWhy not B? the orignal SSH key that the bastion was created is a PRIVATE key!\nYou should never share your private key or else someone can use your identity.\n(this is why its called a PRIVATE key)"},{"comment_id":"343090","upvote_count":"1","timestamp":"1667394960.0","poster":"RicardoD","content":"D is the answer"},{"content":"D. Create a new administrative account on the bastion host, and provide those credentials to the Administrator using AWS Secrets Manager.","comment_id":"273954","poster":"abhishek_m_86","timestamp":"1667219880.0","upvote_count":"1"},{"poster":"jackdryan","timestamp":"1667170080.0","upvote_count":"2","content":"I'll go with D","comment_id":"242863"},{"comment_id":"194689","comments":[{"content":"user/pwd is not the only way to connect to a server: keys are also a way or rdp string encrypted are also a way. Then AWS SM can help us. And as other explain, sharing SSH key are not secure because you only know that someone? connect with this key ... and for ec2-user (who can sudo su to become root) it's not the right user to manage landscape via bastion: https://aws.amazon.com/blogs/security/how-to-use-aws-secrets-manager-securely-store-rotate-ssh-key-pairs/","poster":"MegatonN","comment_id":"201999","upvote_count":"1","timestamp":"1667114820.0"}],"content":"How can AWS Secrets Manager understand User/Password on Bastion Host. I go with B","timestamp":"1667114100.0","upvote_count":"1","poster":"SONLE"},{"upvote_count":"1","content":"Answer D:","timestamp":"1667006820.0","comment_id":"185090","poster":"waterzhong"},{"upvote_count":"1","content":"D, is the MOST secure way.","poster":"Pirulou","timestamp":"1666989000.0","comment_id":"178100"},{"poster":"shammous","timestamp":"1666987020.0","content":"B would be correct if a new key pair was provided. As the answer is mentioning the original key pair, I would avoid that answer and choose the more appropriate one which is D. A and C suggest providing similar credentials or role as the security team which doesnâ€™t make sense.","comment_id":"169116","upvote_count":"1"},{"poster":"KhatriRocks","content":"B is not secure to share SSH keys!\nD is a better and more secure option","comment_id":"162782","timestamp":"1666772040.0","upvote_count":"2"},{"poster":"JGD","upvote_count":"1","timestamp":"1666742220.0","content":"Answer D:\n\nB should be right if they not mentioned about \"bastion host when it was originally launched\". So, this not a correct answer. IF we are looking at a secure way of storing the keys, then Secret Manager is only an answer. Where, we can give access to the Security Team and their keys will be rotated based on the period we configure. \n\nhttps://aws.amazon.com/blogs/security/how-to-use-aws-secrets-manager-securely-store-rotate-ssh-key-pairs/","comment_id":"156133"},{"poster":"teosinh","upvote_count":"2","timestamp":"1666582080.0","comment_id":"154054","content":"I think B is correct. Because AWS Secrets Manager is seen at not relate to remote Bastion Host. Normally, it will use for authentication for some another services (rds, user/pass parameter need encrypt + rorate)."},{"content":"B\nhttp://justsomestuff.co.uk/theblog/2017/01/15/using-a-bastion-host-to-access-your-aws-ec2-instances/","comment_id":"103657","upvote_count":"1","timestamp":"1666409220.0","poster":"gretch"},{"timestamp":"1665178440.0","comment_id":"37573","upvote_count":"1","content":"D. Create a new administrative account on the bastion host, and provide those credentials to the Administrator using AWS Secrets Manager.","poster":"cloud"},{"poster":"awsnoob","timestamp":"1664456040.0","content":"What if the bastion host is Winidows RDP?\nI inclined to choose D","comment_id":"26255","upvote_count":"3"},{"comment_id":"25798","timestamp":"1664297400.0","poster":"karmaah","content":"Both B & D are possible. But the question is Most Secure way which thinks to select D.","upvote_count":"1"},{"poster":"Moon","timestamp":"1664051100.0","comment_id":"20324","upvote_count":"2","content":"B\nUse SSH to login to the bastion host. Administrative access to the Bastion is much more than what is required. (least privileged is SSH).","comments":[{"comment_id":"25799","comments":[{"content":"If you've ever created an EC2 instance before, then you know that one of the last steps requires that you assign a key and tick the checkbox to accept the certificate key....this is what they mean....that is the time when you \"originally launch/provision\" your EC2. Once you choose a key, that is a key you have to use for that EC2.\n\nAlso, you're not riht when you say..\"Usually SSH 22 wil be allowed in SG to access Bastion\"...this depends on you as an engineer, your network architeture, etc.","upvote_count":"1","timestamp":"1667665920.0","comment_id":"433217","poster":"Cyril_the_Squirl"}],"timestamp":"1664363580.0","upvote_count":"1","content":"Usually SSH 22 wil be allowed in SG to access Bastion. But here we need to think about why the answer displays like \n\" bastion host when it was originally launched.\"","poster":"karmaah"}]},{"timestamp":"1663951320.0","comment_id":"19666","poster":"chris82","upvote_count":"2","content":"I would choose D"}],"question_text":"A SysOps Administrator must use a bastion host to administer a fleet of Amazon EC2 instances. All access to the bastion host is managed by the Security team.\nWhat is the MOST secure way for the Security team to provide the SysOps Administrator access to the bastion host?","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/7771-exam-aws-sysops-topic-1-question-653-discussion/"},{"id":"YL8bRtfGYe1OP7X4hAdh","timestamp":"2019-09-19 14:52:00","answer_images":[],"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/5449-exam-aws-sysops-topic-1-question-654-discussion/","question_images":[],"discussion":[{"poster":"coolboylqy","content":"should be D.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.Enabling","timestamp":"1695531720.0","comment_id":"11794","upvote_count":"19"},{"upvote_count":"9","timestamp":"1695614940.0","poster":"mukeshs","comment_id":"13066","content":"It should be D. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.Enabling\n\nYou can only enable encryption for an Amazon RDS DB instance when you create it, not after the DB instance is created.\n\nHowever, because you can encrypt a copy of an unencrypted DB snapshot, you can effectively add encryption to an unencrypted DB instance. That is, you can create a snapshot of your DB instance, and then create an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot, and thus you have an encrypted copy of your original DB instance."},{"content":"Should be D","comment_id":"710945","upvote_count":"1","timestamp":"1730703300.0","poster":"Shruti09753"},{"content":"Selected Answer: D\nI choose D, this is common question in SAA","timestamp":"1710349740.0","upvote_count":"1","comment_id":"567082","poster":"aidenpearce01"},{"timestamp":"1708367640.0","comment_id":"551235","content":"Selected Answer: D\nD is the correct answer - Enc can be enabled only when a DB is created.\nAlso you cant encrypt a read-replica of an undecrypted RDS primary source","poster":"asfsdfsdf","upvote_count":"2"},{"timestamp":"1698983880.0","poster":"Cyril_the_Squirl","upvote_count":"1","comment_id":"433494","content":"D is correct.\nThere is no option in the console to encrypt a db instance. But you can create replica and encrypt it"},{"content":"D is the answer","poster":"RicardoD","comment_id":"343092","upvote_count":"2","timestamp":"1698104460.0"},{"timestamp":"1697883600.0","upvote_count":"3","comment_id":"273956","content":"D. Take a snapshot of the RDS instance, copy and encrypt the snapshot, and then restore to the new RDS instance.","poster":"abhishek_m_86"},{"comment_id":"242873","content":"I'll go with D","timestamp":"1697820060.0","poster":"jackdryan","upvote_count":"3"},{"comment_id":"242629","content":"You can only enable encryption for an Amazon RDS DB instance when you create it, not after the DB instance is created.\n\nHowever, because you can encrypt a copy of an unencrypted snapshot, you can effectively add encryption to an unencrypted DB instance. That is, you can create a snapshot of your DB instance, and then create an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot, and thus you have an encrypted copy of your original DB instance.","upvote_count":"2","timestamp":"1697787540.0","poster":"allanon"},{"timestamp":"1697628600.0","poster":"MFDOOM","comment_id":"210088","content":"D. Take a snapshot of the RDS instance, copy and encrypt the snapshot, and then restore to the new RDS instance.","upvote_count":"4"},{"upvote_count":"3","poster":"waterzhong","timestamp":"1697515740.0","content":"It should be D.","comment_id":"185092"},{"upvote_count":"2","poster":"KhatriRocks","timestamp":"1697294460.0","comment_id":"162783","content":"D is correct"},{"comment_id":"101012","poster":"MrKhan","content":"You cannot encrypt RDS once it is created, so D is the correct Answer.","timestamp":"1697054160.0","upvote_count":"3"},{"upvote_count":"2","timestamp":"1697038380.0","comment_id":"82773","poster":"AWS_Noob","content":"D - encrypting an existing RDS follows the same rule as if you wish to encrypt an existing EBS volume"},{"upvote_count":"2","comment_id":"25800","content":"Encryption should be always in place while creating db itself.\nso D.","timestamp":"1696319340.0","poster":"karmaah"},{"comment_id":"17370","content":"D is correct","poster":"saumenP","upvote_count":"8","timestamp":"1696123260.0"}],"exam_id":36,"answer_ET":"D","choices":{"C":"Encrypt the standby replica in the secondary Availability Zone and promote it to the primary instance.","D":"Take a snapshot of the RDS instance, copy and encrypt the snapshot, and then restore to the new RDS instance.","A":"Log in to the RDS console and select the encryption box to encrypt the database.","B":"Create a new encrypted Amazon EBS volume and attach it to the instance."},"isMC":true,"question_text":"A database is running on an Amazon RDS Multi-AZ DB instance. A recent security audit found the database to be out of compliance because it was not encrypted.\nWhich approach will resolve the encryption requirement?","answers_community":["D (100%)"],"answer_description":"","question_id":613,"topic":"1","unix_timestamp":1568897520},{"id":"tBLXnJFWfu2L8ux8dbYl","question_images":[],"question_id":614,"choices":{"D":"Add a rule to the security group for the instance to explicitly permit TCP port 25 outbound to any address.","C":"Install an email client on the instance to ensure that it communicates correctly on TCP port 25 to the SMTP server.","B":"Disable the iptables service on the SMTP server so that the instance can properly communicate over the network.","A":"Add the instance to the security group for the SMTP server and ensure that is permitted to communicate over TCP port 25."},"answer_images":[],"answers_community":["A (100%)"],"question_text":"An Amazon EC2 instance is unable to connect an SMTP server in a different subnet. Other instances are successfully communicating with the SMTP server, however VPC Flow Logs have been enabled on the SMTP server's network interface and show the following information:\n2 223342798652 eni-abe77dab 10.1.1.200 10.100.1.10 1123 25 17 70 48252 1515534437 1515535037 REJECT OK\nWhat can be done to correct this problem?","url":"https://www.examtopics.com/discussions/amazon/view/7772-exam-aws-sysops-topic-1-question-655-discussion/","timestamp":"2019-11-07 08:21:00","discussion":[{"poster":"chris82","comment_id":"19667","content":"The FlowLogs has been activated on SMTP vpc, not on ec2-instance one.\nThat`s why the REJECT is happening on SMTP side.\nI would choose A","comments":[{"upvote_count":"3","comment_id":"259586","timestamp":"1667201760.0","poster":"PlayerDN","content":"According to https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html\nREJECT means - \"The recorded traffic was not permitted by the security groups or network ACLs.\"\nSo the answer is A."}],"upvote_count":"24","timestamp":"1663948920.0"},{"upvote_count":"11","content":"A\nyou can use security groups to allow certain traffic between instances of the same SG\nNow D is incorrect because outbound traffic is already authorized because other instances can connect and SG statefull","comment_id":"98544","timestamp":"1665891420.0","poster":"elies_jebri"},{"poster":"albert_kuo","upvote_count":"1","content":"Selected Answer: A\nBased on the provided VPC Flow Logs information, the connection between the EC2 instance (source IP 10.1.1.200) and the SMTP server (destination IP 10.100.1.10) is being rejected. This rejection indicates that the security group associated with the EC2 instance is blocking outbound communication on TCP port 25.\n\nTo resolve the issue, you should update the security group associated with the EC2 instance to allow outbound communication on TCP port 25. This can be done by adding a rule to the security group that permits outbound traffic on port 25 to the IP range or specific IP address of the SMTP server.","timestamp":"1720437180.0","comment_id":"946424"},{"upvote_count":"1","poster":"gulu73","timestamp":"1707126240.0","comment_id":"798717","content":"Selected Answer: A\nId choose A"},{"content":"I would go with A since the log is for the SMTP server and other instances can communicate correctly.\nhowever the protocol is wrong its not TCP its UDP (17)","poster":"asfsdfsdf","timestamp":"1676832360.0","upvote_count":"1","comment_id":"551239"},{"comment_id":"433499","upvote_count":"1","timestamp":"1667797500.0","content":"A is correct.\nThe logs on smtp server side show rejected traffic from instance, therefore traffic does reach smtp server subnet but gets rejected, answer is A.","poster":"Cyril_the_Squirl"},{"content":"A is the answer\n\nTraffic is being rejected so SG inbound should allow traffic to pass through","upvote_count":"1","poster":"RicardoD","timestamp":"1667764260.0","comment_id":"350838"},{"upvote_count":"2","comment_id":"339102","poster":"Kimle","timestamp":"1667745840.0","content":"The fact that traffic is detected \"but refused\" in VPC flow logs mean that ec2 instance have SMTP client installed and that client SG allow outbound traffic over port 25. so C,D excluded ..\n- adding ec2 \"smtp client\" to same SG as server doesn't enable it to communicate with the server , a rule must be defined in SG to accept traffic from same SG over port 25 .. \n choice A taxonomy is very weird as it say \" and ensure that is permitted to communicate over TCP port 25.\" does this mean adding inbound rule or outbound rule or what !!"},{"timestamp":"1667731680.0","comment_id":"273959","content":"A. Add the instance to the security group for the SMTP server and ensure that is permitted to communicate over TCP port 25.","poster":"abhishek_m_86","upvote_count":"1"},{"content":"AWS blocks outbound traffic on port 25 (SMTP) of all EC2 instances and Lambda functions by default. If you want to send outbound traffic on port 25, you can request for this restriction to be removed. Ans is D as the EC2 instance SG should explicitly have outbound rules to connect to port 25 (SMTP)\nhttps://aws.amazon.com/premiumsupport/knowledge-center/ec2-port-25-throttle/","upvote_count":"1","timestamp":"1667689920.0","comment_id":"267501","poster":"Manny20"},{"poster":"jackdryan","content":"I'll go with A","upvote_count":"2","timestamp":"1667131140.0","comment_id":"242883"},{"upvote_count":"4","content":"C - the flow shown is using UDP, not TCP\nThe flow shows it is using protocol #17, which is UDP (https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml). SMTP traditionally uses TCP (protocol #6)","comment_id":"230440","poster":"tegucgringo","timestamp":"1667060160.0"},{"upvote_count":"3","timestamp":"1666612680.0","content":"A. Add the instance to the security group for the SMTP server and ensure that is permitted to communicate over TCP port 25.","poster":"MFDOOM","comment_id":"210089"},{"upvote_count":"1","timestamp":"1666325760.0","comment_id":"185094","content":"IT IS A","poster":"waterzhong"},{"upvote_count":"2","content":"SG is stateful and allows outbound traffic of allowed inbound ports. This eliminates answer D and The only provable answer is A then.","comments":[{"content":"@shammous, your explanation regarding SG statefull is \"wrong\" .Statefull means that if you allow a packet to reach your server/service you can reply (no need to create a rule for) But if you want to initiation a new \"communication\" from the server (port 25) then you will need a rule allowing port 25 (your server is in fact playing the role of a client)","upvote_count":"1","comment_id":"202005","timestamp":"1666571700.0","poster":"MegatonN"}],"poster":"shammous","timestamp":"1666250640.0","comment_id":"169119"},{"comment_id":"159402","timestamp":"1665966120.0","content":"The fact we see captured packet on SMTP_Server_ENI means that on the instance site port 25 (outbound direction) is permitted and packet has been successfully sent from the source but rejected (drop) from SMTP-Server.\nFor me its ans A.","poster":"not_so_free","upvote_count":"2"},{"upvote_count":"8","timestamp":"1665817860.0","comment_id":"86491","content":"Answer: A\n(given the other options are wrong, not saying A is a perfect answer. think its worded badly)\nB: huh?\nC: huh?\nD: wrong - the EC2 instance has outbound TCP/25 already given the traffic reaches the network interface of the SMTP server, which then rejects it.","poster":"inf"},{"comments":[{"poster":"karmaah","comments":[{"poster":"praveenshen","comments":[{"timestamp":"1665081420.0","content":"D. Check the Last line.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/ec2-port-25-throttle/","poster":"karmaah","comments":[{"timestamp":"1665541680.0","poster":"kanzagh","comment_id":"79225","upvote_count":"1","content":"when there was one inductance with capability of using SMTP port , it shows the action that mentioned in your link have been done before that is not necessary to request for asking eliminate restriction that mentions in your link . only you should apply instance to the group policy Moon told ."},{"comments":[{"content":"In order to maintain the quality of Amazon EC2 addresses for sending email, we enforce default limits on the amount of email that can be sent from EC2 accounts. If you wish to send larger amounts of email from EC2, you can apply to have these limits removed from your account by filling out this form.(these limits removed from your account but in your account Other instances are successfully communicating with the SMTP server. you should provide same condition as another instance that you have ...how ? dd the instance to the security group for the SMTP server and ensure that is permitted to communicate over TCP port 25.","upvote_count":"1","timestamp":"1665657120.0","comment_id":"81055","poster":"kanzagh"},{"poster":"kanzagh","timestamp":"1665645780.0","content":"Other instances are successfully communicating with the SMTP server. there for we dont have default restriction . (read carefully )","comment_id":"81050","upvote_count":"2"}],"timestamp":"1665549060.0","comment_id":"79438","upvote_count":"1","content":"D is correct.\n\nSimilar issue :\nhttps://forums.aws.amazon.com/thread.jspa?threadID=238277","poster":"ThoseWereTheDays"},{"poster":"praveenshen","upvote_count":"3","content":"Thanks Karmaah","comments":[{"upvote_count":"1","comment_id":"43765","content":"Because the packet itself originates from EC2 and is rejected by the SMTP server's ENI (SG), it is irrelevant to Port.25 restrictions.","poster":"suresehe","timestamp":"1665200160.0"}],"comment_id":"33340","timestamp":"1665106980.0"}],"upvote_count":"5","comment_id":"33126"}],"upvote_count":"1","timestamp":"1664732040.0","comment_id":"32697","content":"So what do you choose A or D ?"}],"comment_id":"25806","timestamp":"1664366640.0","content":"I just like to know, How do you add instance (EC2) in Security Group and Amazon EC2 throttles traffic on port 25 of all EC2 instances by default, but you can request for this throttle to be removed by allowing in outbound. It throttles few of the ports which includes 25 too.","upvote_count":"3"}],"comment_id":"20320","timestamp":"1664242260.0","poster":"Moon","upvote_count":"2","content":"I would go with A.\nAs said, the flow log is enabled on SMTP interface, and the flow log information is showing destination port (25), with rejected message. That means, the packet is generated by the EC2, and captured by the security group and rejected, because it is not added to the allowed list of the SMTP security Group.\nSolution is to add the EC2 \"IP\" to the security group of the SMTP server."}],"exam_id":36,"answer":"A","answer_description":"","topic":"1","answer_ET":"D","unix_timestamp":1573111260,"isMC":true},{"id":"cZrtfhD98j00M2gq2sTH","answers_community":[],"exam_id":36,"answer_images":[],"topic":"1","choices":{"D":"Monitor AWS costs with Amazon CloudWatch and create billing alerts and notifications.","B":"Use AWS CloudTrail Logs to access daily costs in JSON format.","C":"Set up a daily Cost and Usage Report and download the output from Amazon S3.","A":"Share the monthly AWS bill with management."},"isMC":true,"unix_timestamp":1578694200,"answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/11744-exam-aws-sysops-topic-1-question-656-discussion/","answer_description":"","question_id":615,"question_images":[],"question_text":"A company's use of AWS Cloud services is quickly growing, so a SysOps Administrator has been asked to generate details of daily spending to share with management.\nWhich method should the Administrator choose to produce this data?","answer_ET":"C","timestamp":"2020-01-10 23:10:00","discussion":[{"poster":"cloud","timestamp":"1711504140.0","content":"C. Set up daily Cost and Usage Report and download the output from Amazon S3.","upvote_count":"12","comment_id":"37577"},{"comment_id":"581476","timestamp":"1728166380.0","content":"It is (C). https://docs.aws.amazon.com/cur/latest/userguide/what-is-cur.html","upvote_count":"1","poster":"FHU"},{"content":"C is the answer.\n\nsetting up a daily cost and usage report and making it available on S3 for download","upvote_count":"1","timestamp":"1714760820.0","poster":"RicardoD","comment_id":"350840"},{"content":"C. Set up daily Cost and Usage Report and download the output from Amazon S3.","comment_id":"273962","timestamp":"1714155360.0","upvote_count":"2","poster":"abhishek_m_86"},{"upvote_count":"2","poster":"arpana_03","comment_id":"265901","timestamp":"1713139200.0","content":"C is correct answer"},{"timestamp":"1712729580.0","poster":"jackdryan","content":"I'll go with C","upvote_count":"2","comment_id":"242895"},{"poster":"MFDOOM","content":"C. Set up daily Cost and Usage Report and download the output from Amazon S3.","upvote_count":"3","timestamp":"1712258820.0","comment_id":"210092"}]}],"exam":{"numberOfQuestions":928,"id":36,"provider":"Amazon","isMCOnly":false,"lastUpdated":"11 Apr 2025","name":"AWS-SysOps","isImplemented":true,"isBeta":false},"currentPage":123},"__N_SSP":true}