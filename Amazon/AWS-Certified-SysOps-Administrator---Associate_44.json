{"pageProps":{"questions":[{"id":"oZIQj7sdyCMHcH0tDfO2","url":"https://www.examtopics.com/discussions/amazon/view/116241-exam-aws-certified-sysops-administrator-associate-topic-1/","answer_ET":"AC","question_id":216,"timestamp":"2023-07-24 02:17:00","discussion":[{"poster":"AWSdeveloper08","comment_id":"997551","timestamp":"1725361440.0","upvote_count":"3","content":"Selected Answer: AC\nTo encrypt the traffic in transit for a web application using Amazon CloudFront with an SSL certificate from AWS Certificate Manager (ACM), you should take the following steps:\n\nC. Enter the alternate domain name (CNAME) of www.example.com for the CloudFront distribution. Select the custom SSL certificate:\n\nThis step ensures that CloudFront is configured to use the custom SSL certificate from ACM for encrypting the traffic between the viewer (client) and CloudFront.\nA. For each cache behavior in the CloudFront distribution, modify the Viewer Protocol Policy setting to redirect HTTP to HTTPS:\n\nThis step enforces the use of HTTPS by redirecting any HTTP requests to HTTPS. This is an important security practice to ensure that all traffic is encrypted in transit."},{"comment_id":"960965","content":"AC is correct. On the settings when you create a new CF distribution the second parameter is Alternate domain name (CNAME) - optional here you can add the domain name you will use to access to the CF distribution. And in the bahavior config you need to check \"Redirect HTTP to HTTPS\" option in the viewer protocol policy.","timestamp":"1721780220.0","upvote_count":"3","poster":"Zotarix"}],"answer_description":"","answer":"AC","exam_id":34,"question_images":[],"choices":{"A":"For each cache behavior in the CloudFront distribution, modify the Viewer Protocol Policy setting to redirect HTTP to HTTPS.","C":"Enter the alternate domain name (CNAME) of www.example.com for the CloudFront distribution. Select the custom SSL certificate.","E":"Configure CloudFront Origin Shield for the CloudFront origin.","B":"For each cache behavior in the CloudFront distribution, modify the Viewer Protocol Policy setting to allow HTTP and HTTPS.","D":"Configure an AWS WAF web ACL for the CloudFront distribution."},"answer_images":[],"question_text":"A company is building a web application on AWS. The company is using Amazon CloudFront with a domain name of www.example.com. All traffic to CloudFront must be encrypted in transit. The company already has provisioned an SSL certificate for www.example.com in AWS Certificate Manager (ACM).\n\nWhich combination of steps should a SysOps administrator take to encrypt the traffic in transit? (Choose two.)","isMC":true,"answers_community":["AC (100%)"],"unix_timestamp":1690157820,"topic":"1"},{"id":"uWlAojO4bFPHK10KZiRG","answer":"A","question_text":"A company runs an application on hundreds of Amazon EC2 instances in three Availability Zones. The application calls a third-party API over the public internet. A SysOps administrator must provide the third party with a list of static IP addresses so that the third party can allow traffic from the application.\n\nWhich solution will meet these requirements?","answer_ET":"A","answer_images":[],"discussion":[{"poster":"Gomer","upvote_count":"19","comment_id":"888890","timestamp":"1699048860.0","content":"Selected Answer: A\nFrom my perspective, you can't assign an elastic IP to multiple instances in an AZ. Also, the API will never see a private IP on the AWS side. To me, the answer is to have a static public IP (EIP) assigned to the NAT gateway in each AZ, and have the EC2 instances on a private subnet. Everytime and instance hits the external API, the API is going to see one of three unchanging EIPs. Enough said."},{"comment_id":"1164669","upvote_count":"1","poster":"confusedyeti69","timestamp":"1725349500.0","content":"Selected Answer: C\nI literally can't see where in the question does it say the EC2 are in private subnets."},{"poster":"TareDHakim","content":"Selected Answer: A\nLoadbalancer was never meant to be used as a gateway for outbound traffic, that's what NAT Gateways are for!","upvote_count":"2","comment_id":"1115522","timestamp":"1720305480.0"},{"upvote_count":"2","content":"Selected Answer: A\nOption A: Add a NAT gateway in the public subnet of each Availability Zone. Make the NAT gateway the default route of all private subnets in those Availability Zones.\n\nBy deploying a NAT gateway in each public subnet and making it the default route for private subnets in the respective Availability Zones, the EC2 instances in the private subnets will use the NAT gateways to communicate with the third-party API over the internet. Each NAT gateway will have an Elastic IP address, providing a static IP address for the outbound traffic.","timestamp":"1719559980.0","comment_id":"1107637","poster":"r2c3po"},{"content":"Selected Answer: A\nAWS NAT Gateway is a highly available and horizontally scalable Network Address Translation (NAT) service. AWS NAT Gateway allows resources in a private subnet to connect to target resources outside the subnet using the NAT Gatewayâ€™s IP address. \nhttps://aws.amazon.com/blogs/networking-and-content-delivery/attach-multiple-ips-to-a-nat-gateway-to-scale-your-egress-traffic-pattern/\n\nNLB does not provide egress traffic. It is for ingress.","poster":"[Removed]","comment_id":"979825","timestamp":"1707815100.0","upvote_count":"3"},{"upvote_count":"1","comment_id":"973558","poster":"paultantony","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/network-load-balancers.html\nWhen you create an internet-facing load balancer, you can optionally specify one Elastic IP address per subnet. If you do not choose one of your own Elastic IP addresses, Elastic Load Balancing provides one Elastic IP address per subnet for you. These Elastic IP addresses provide your load balancer with static IP addresses that will not change during the life of the load balancer. You can't change these Elastic IP addresses after you create the load balancer.","timestamp":"1707206580.0"},{"poster":"RayHK","comment_id":"959391","upvote_count":"2","timestamp":"1705923660.0","content":"Answer A if under this situation\n\nhttps://stackoverflow.com/questions/54742522/assign-multiple-ec2-instances-to-one-elastic-ip"},{"poster":"RayHK","content":"how to communicate with outside world with the answer A? can we use the EIP instead with a NLB ? So answer B is not a good answer and cannot assign to hundreds of EC2 instance.\n\nwondering Ans C is correct but it didn't mention the EIP in NLB...\nhttps://repost.aws/knowledge-center/elb-attach-elastic-ip-to-public-nlb","comment_id":"959390","upvote_count":"1","timestamp":"1705923540.0"},{"upvote_count":"3","timestamp":"1704840960.0","comment_id":"947552","poster":"Atest00678","content":"Selected Answer: C\nWhen you create an internet-facing load balancer, you can optionally specify one Elastic IP address per subnet. If you do not choose one of your own Elastic IP addresses, Elastic Load Balancing provides one Elastic IP address per subnet for you. These Elastic IP addresses provide your load balancer with static IP addresses that will not change during the life of the load balancer"},{"timestamp":"1701066960.0","upvote_count":"2","poster":"thetnyeinmoe","content":"Selected Answer: B\nExplanation:\nIn this scenario, you need to provide a list of static IP addresses to a third party for allowing traffic from the application. The Elastic IP (EIP) address is a static, public IPv4 address that can be associated with an Amazon EC2 instance. By allocating one EIP in each Availability Zone and associating it with all the instances in that Availability Zone, you can provide the third party with a list of static IP addresses.","comment_id":"907752"},{"comment_id":"887881","timestamp":"1698963720.0","upvote_count":"1","poster":"Abdullxh","content":"Selected Answer: B\nBy allocating one Elastic IP address in each Availability Zone, the SysOps administrator can assign a unique static IP address to each instance running in that Availability Zone. Once the Elastic IP addresses are associated with the instances, the administrator can provide the list of Elastic IP addresses to the third-party API provider to allow traffic from the application.","comments":[{"poster":"Gomer","upvote_count":"1","timestamp":"1700782680.0","comments":[{"comments":[{"upvote_count":"1","timestamp":"1700883780.0","poster":"landsamboni","comment_id":"906237","content":"I'd go with B, but what you think about the arguments towards A?"}],"content":"ChatGPT answer: \"Option A is not the optimal solution for the given requirements. Adding a NAT gateway in the public subnet of each Availability Zone and making it the default route of all private subnets in those Availability Zones would enable instances in the private subnets to communicate with the internet using the NAT gateway's public IP address. However, this solution does not provide a list of static IP addresses that can be shared with the third party to allow traffic from the application. The NAT gateway's public IP address is shared among all the instances in the private subnets and is not a dedicated static IP address per instance or per Availability Zone. Therefore, option A does not fulfill the requirement of providing a list of static IP addresses to the third party.\"","comment_id":"906236","upvote_count":"1","poster":"landsamboni","timestamp":"1700883660.0"}],"content":"Since there are \"hundreds of Amazon EC2\" instances, three elastic IP's assigned to EC2 isn't going to work. However, assigning them to the 3 NAT gateway's would work if the EC2 instances are in private subnet and using the NAT Gateway to access public web API.","comment_id":"905253"}]},{"comment_id":"877264","poster":"AndyMartinez","timestamp":"1697978280.0","upvote_count":"4","content":"Selected Answer: A\nOption A makes more sense to me."}],"question_images":[],"choices":{"D":"Update the main route table to send the traffic to the internet through an Elastic IP address that is assigned to each instance.","B":"Allocate one Elastic IP address in each Availability Zone. Associate the Elastic IP address with all the instances in the Availability Zone.","C":"Place the instances behind a Network Load Balancer (NLB). Send the traffic to the internet through the private IP address of the NLB.","A":"Add a NAT gateway in the public subnet of each Availability Zone. Make the NAT gateway the default route of all private subnets in those Availability Zones."},"isMC":true,"exam_id":34,"answer_description":"","question_id":217,"unix_timestamp":1682167080,"answers_community":["A (79%)","13%","8%"],"timestamp":"2023-04-22 14:38:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/106978-exam-aws-certified-sysops-administrator-associate-topic-1/"},{"id":"5BhcoLtymwvKHpCgtcVH","discussion":[{"poster":"DocHolliday","comments":[{"content":"It is also the one option that mentions the SCP. Remember that the accounts are in AWS Organizations.","upvote_count":"1","timestamp":"1713293400.0","comment_id":"1196750","poster":"AgboolaKun"},{"poster":"Hatem08","upvote_count":"2","content":"Agreed I will go with B. It covers all the requirements needed.","comment_id":"1087137","timestamp":"1701640560.0"},{"comment_id":"1078774","upvote_count":"3","poster":"joaocarvalhojp","timestamp":"1700771880.0","content":"Exactly that, letter A does not resolve the stipulation of denying the deletion of snapshots, just resolve the problem of creating automated daily basis snapshots."}],"timestamp":"1693506060.0","upvote_count":"16","comment_id":"995394","content":"Selected Answer: B\nI'm gonna go against the grain here and go with answer B. While initially it looks like an elephant because of its complexity compared to the other options...it does satisfy every requirement and its the ONLY option that satisfies the stipulation that denys the deletion of a resource."},{"comment_id":"888916","comments":[{"upvote_count":"2","comment_id":"1164674","content":"Doesn't prevent users from using Amazon EC2 * permissions to delete snapshots still.","poster":"confusedyeti69","timestamp":"1709459340.0"}],"timestamp":"1683145260.0","poster":"Gomer","upvote_count":"11","content":"Selected Answer: C\nI think answer is \"C\" because using AWS backup is the established method/tool for this, and EC2 instance role/profile would not be allow to control or delete backups unless explicitly allowed. The word \"cron\" in en answer \"B\" is red flag that is is the wrong answer. I know all about cron, and it's invaluable and bullet proof on a system. However, it's anathema to AWS Cloud way of doing things. Wherever you see the word \"cron\" in AWS response, you know its the wrong answer (IMHO)."},{"timestamp":"1743010080.0","upvote_count":"1","poster":"chathur","content":"Selected Answer: C\nWhen the AWS backups create the backup points they can not be deleted by ec2:* permission. User need to have backup:DeleteRecoveryPoint","comment_id":"1410493"},{"content":"Selected Answer: B\nCome on people, B is literally the ONLY answer that addresses a way to prevent deletion. The answer in C does not state a way to prevent deletion, even IF AWS Backbackup can do it, it doesn't say it in that answer.","upvote_count":"1","comment_id":"1325039","timestamp":"1733924400.0","poster":"numark"},{"poster":"igor12ghsj577","content":"Selected Answer: C\nc is the answer","timestamp":"1732613580.0","comment_id":"1317996","upvote_count":"1"},{"poster":"igor12ghsj577","upvote_count":"1","content":"Selected Answer: C\nAWS BACKUP comes with features to manage access to the created AMIs and snapshots, and protect them from deletion with a vault lock.","comment_id":"1317979","timestamp":"1732610400.0"},{"upvote_count":"1","content":"Selected Answer: B\nB is the only option for handling the deletion of any of these production snapshots.","timestamp":"1721755620.0","comment_id":"1253829","poster":"VerRi"},{"upvote_count":"1","timestamp":"1721675280.0","poster":"Ramdi1","comment_id":"1253238","content":"Selected Answer: B\nEven though it is a complex solution, the two facts are that accounts are in organizations and the best way to control is using SCP's"},{"timestamp":"1718711520.0","comment_id":"1232405","upvote_count":"2","content":"Selected Answer: C\nAws backup fulfills all needs. So C","poster":"kaszczur"},{"content":"Selected Answer: C\nFor me the answer has to be C. Cron is usually a red herring that it's the wrong answer. Whilst B makes sense in the fact that it's using SCP controls alongside organizations, Cron just feels like bad practice in the context of AWS exams.\nConsider in backup controls that you are not able to delete unless specifically allowed and to really prevent deletion at an organizational level you can apply compliance mode which after a cooling off period, will not allow any users to delete the resource:\nhttps://docs.aws.amazon.com/aws-backup/latest/devguide/vault-lock.html#:~:text=AWS%20Backup%20ensures%20that%20your%20backups%20are%20available,locked%20vault%2C%20AWS%20Backup%20will%20deny%20the%20operation.","timestamp":"1715815440.0","upvote_count":"2","poster":"Tarsmandaturd","comment_id":"1212164"},{"upvote_count":"1","timestamp":"1713171660.0","poster":"Koshi202","comment_id":"1195919","content":"Selected Answer: C\nIncremental backup, TAG, Manage permissions for the backup. All fit"},{"poster":"icecool36","comment_id":"1145995","upvote_count":"1","timestamp":"1707555660.0","content":"Selected Answer: C\nAWS backup is the only one to fulfil the requirements"},{"content":"Selected Answer: C\nThe question mentioned the solution requirements are:\n1. Automated EBS backups\n2. Incremental EBS backups \n3. Lifecycle policy\n4. Prevent deletion by users (with Permission to delete snapshots)\nAWS Backup is smarter than DLM, they both automatically create AMIs and Incremental Snapshots. \nHowever, AWS BACKUP comes with features to manage access to the created AMIs and snapshots, and protect them from deletion with a vault lock.\nhttps://repost.aws/questions/QU8o5m88yhQk6UVAgQA3Mnng/aws-backup-vs-aws-data-lifecycle-management.","timestamp":"1704590460.0","upvote_count":"5","comments":[{"poster":"icecool36","timestamp":"1707555600.0","upvote_count":"1","content":"incremental was the trick word in this question indeed","comment_id":"1145994"}],"comment_id":"1115538","poster":"TareDHakim"},{"upvote_count":"2","timestamp":"1702812060.0","poster":"konieczny69","comment_id":"1098842","content":"Selected Answer: B\nAltough not elegant, its the only option that fulfils `prevent deletion` requirement"},{"content":"Selected Answer: B\nbbbbbbbbb","upvote_count":"2","comment_id":"1095521","poster":"mattyb123abc","timestamp":"1702476300.0"},{"poster":"Hatem08","upvote_count":"2","content":"Selected Answer: B\nbbbbbbbb","comment_id":"1092048","timestamp":"1702154160.0"},{"content":"Selected Answer: C\nThe correct answer is C.\nOption A is incorrect, because it is clearly said that you need to prevent users from using Amazon EC2 * permissions to delete any of these production snapshots.\n\nAWS Backup is another service where users will not be able to use EC2 * permissions.","timestamp":"1692787020.0","upvote_count":"2","comment_id":"988196","poster":"xSohox"},{"poster":"Christina666","comment_id":"965156","upvote_count":"7","comments":[{"poster":"Christina666","comments":[{"upvote_count":"1","timestamp":"1692433620.0","content":"helps a lot !!\n\"DLM managed policy prevents users from deleting the snapshots\"","comment_id":"985067","poster":"jipark"}],"upvote_count":"5","timestamp":"1690522740.0","content":"Option C (Creating a daily snapshot of all EBS volumes by using AWS Backup) is incorrect because AWS Backup is a different service for managing backup and recovery of various AWS resources, including EBS volumes. It does not use the \"Lifecycle\" tag for EBS snapshots, and it does not inherently prevent users from deleting the snapshots using EC2 permissions.","comment_id":"965157"}],"content":"Selected Answer: A\nExplanation:\n\nAmazon Data Lifecycle Manager (DLM) allows you to automate the creation, retention, and deletion of EBS snapshots based on specified schedules and tags.\n\nBy configuring DLM to create daily snapshots of all EBS volumes that are tagged with \"Lifecycle: Production,\" you can meet the requirement of creating daily incremental backups for the specified volumes.\n\nRegarding preventing users from using EC2 permissions to delete these production snapshots, DLM uses its own managed policy to ensure that the created snapshots are protected from direct deletion by EC2 permissions. The DLM managed policy prevents users from deleting the snapshots created by the DLM service, even if they have EC2 permissions.","timestamp":"1690500480.0"},{"timestamp":"1689902520.0","content":"Selected Answer: C\nPretty sure the answer is C as that is the only answer that would prevent users from deleting the snapshots. All of the other \"answers\" here are failing to fully read what the question is asking and I question their ability to clear the exam","poster":"eboehm","upvote_count":"2","comments":[{"content":"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-scheduled-snapshot.html","timestamp":"1689902700.0","upvote_count":"1","poster":"eboehm","comment_id":"957985"}],"comment_id":"957983"},{"content":"Selected Answer: A\nExplanation:\nAmazon Data Lifecycle Manager (DLM) is a service that allows you to automate the creation, retention, and deletion of EBS snapshots. By using DLM, you can create policies that define the schedule and criteria for creating snapshots of your EBS volumes. In this scenario, you can create a DLM policy that takes daily incremental backups of any EBS volume with the specified tag key \"Lifecycle\" and tag value \"Production.\"","upvote_count":"2","comment_id":"956693","poster":"SIREDWINGM","timestamp":"1689774240.0"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","poster":"rdiaz","upvote_count":"1","timestamp":"1687078980.0","comment_id":"926575"},{"poster":"thetnyeinmoe","comment_id":"907755","timestamp":"1685162400.0","comments":[{"content":"In retrospect, I agree, and I'd change my answer to \"A\" if I could. DLM is the tool to use for EBS snapshots. Backup is not designed to manage/schedule snapshots.\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","poster":"Gomer","upvote_count":"4","timestamp":"1686250740.0","comment_id":"918591"}],"upvote_count":"7","content":"Selected Answer: A\nExplanation:\nIn this scenario, the objective is to automate the creation of daily incremental backups for EBS volumes marked with a specific tag and prevent users from deleting these snapshots using EC2 permissions. Amazon Data Lifecycle Manager (DLM) is a service that can automate the creation, retention, and deletion of EBS snapshots based on policies. By creating a DLM policy with a daily schedule and configuring it to target EBS volumes with the \"Lifecycle: Production\" tag, you can achieve the automated backup requirement."}],"choices":{"D":"Create a daily Amazon Machine Image (AMI) of every production EC2 instance within the AWS account by using Amazon Data Lifecycle Manager.","B":"Associate a service control policy (SCP) with the account to deny users the ability to delete EBS snapshots. Create an Amazon EventBridge rule with a 24-hour cron schedule. Configure EBS Create Snapshot as the target. Target all EBS volumes with the specified tags.","C":"Create a daily snapshot of all EBS volumes by using AWS Backup. Specify Lifecycle as the tag key. Specify Production as the tag value.","A":"Create a daily snapshot of all EBS volumes by using Amazon Data Lifecycle Manager. Specify Lifecycle as the tag key. Specify Production as the tag value."},"answer":"C","answer_ET":"C","answers_community":["C (39%)","B (39%)","A (23%)"],"question_id":218,"isMC":true,"unix_timestamp":1683145260,"answer_images":[],"timestamp":"2023-05-03 22:21:00","exam_id":34,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/108447-exam-aws-certified-sysops-administrator-associate-topic-1/","topic":"1","answer_description":"","question_text":"A company manages its multi-account environment by using AWS Organizations. The company needs to automate the creation of daily incremental backups of any Amazon Elastic Block Store (Amazon EBS) volume that is marked with a Lifecycle: Production tag in one of its primary AWS accounts.\n\nThe company wants to prevent users from using Amazon EC2 * permissions to delete any of these production snapshots.\n\nWhat should a SysOps administrator do to meet these requirements?"},{"id":"jR4u1hGPkYskcxIjdCqL","choices":{"A":"Create an Amazon Elastic File System (Amazon EFS) Multi-AZ file system. Copy the files to the EFS file system. Connect the EFS file system to mount points on the application servers.","D":"Create two Amazon FSx for Windows File Server file systems. Configure Distributed File System (DFS) replication between the file systems. Copy the files to the Amazon FSx file systems. Adjust the connections from the application servers to use the shares that the Amazon FSx file systems expose.","C":"Create an Amazon Elastic Block Store (Amazon EBS) volume that has EBS Multi-Attach enabled. Create an Auto Scaling group for the Windows file server. Use a script in the file server's user data to attach the SharedFileAccess tag to the EBS volume during launch.","B":"Create an Amazon FSx for Windows File Server Multi-AZ file system. Copy the files to the Amazon FSx file system. Adjust the connections from the application servers to use the share that the Amazon FSx file system exposes."},"answer_description":"","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/109082-exam-aws-certified-sysops-administrator-associate-topic-1/","answer_images":[],"timestamp":"2023-05-12 17:25:00","answer_ET":"B","question_id":219,"question_images":[],"answers_community":["B (89%)","11%"],"question_text":"A company hosts a Windows-based file server on a fleet of Amazon EC2 instances across multiple Availability Zones. The current setup does not allow application servers to access files simultaneously from the EC2 fleet.\n\nWhich solution will allow this access in the MOST operationally efficient way?","unix_timestamp":1683905100,"discussion":[{"poster":"kondratyevmn","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html","upvote_count":"8","comments":[{"content":"https://docs.aws.amazon.com/fsx/latest/WindowsGuide/high-availability-multiAZ.html","comment_id":"896025","poster":"kondratyevmn","upvote_count":"4","timestamp":"1699809900.0"}],"comment_id":"896024","timestamp":"1699809900.0"},{"poster":"r2c3po","upvote_count":"1","comment_id":"1107639","content":"Selected Answer: D\nOptions A and B involve using Amazon EFS and Amazon FSx for Windows File Server, respectively, but the DFS replication for synchronization between file systems is a key feature for simultaneous access in multiple Availability Zones, making option D more suitable for the specified requirements.","timestamp":"1719560340.0"},{"poster":"Zotarix","content":"A is incorrect because talks about EFS in general.\nC is incorrect because EBS Multi-Attach only works for instances in the same AZ.\nD is incorrect because Distributed File System (DFS) replication applies only for regions. \nB is the correct answer.\n\nhttps://aws.amazon.com/blogs/storage/how-to-replicate-amazon-fsx-file-server-data-across-aws-regions/\nhttps://aws.amazon.com/blogs/storage/delivering-instant-data-sharing-with-multi-attach-enabled-amazon-ebs/","timestamp":"1706063700.0","comment_id":"960982","upvote_count":"3"}],"answer":"B","exam_id":34,"topic":"1"},{"id":"iBiXiqEcTMhnQfB1wde9","url":"https://www.examtopics.com/discussions/amazon/view/111473-exam-aws-certified-sysops-administrator-associate-topic-1/","answer_ET":"A","question_text":"A company has deployed an application on Amazon EC2 instances in a single VPC. The company has placed the EC2 instances in a private subnet in the VPC.\n\nThe EC2 instances need access to Amazon S3 buckets that are in the same AWS Region as the EC2 instances. A SysOps administrator must provide the EC2 instances with access to the S3 buckets without requiring any changes to the EC2 instances or the application. The EC2 instances must not have access to the internet.\n\nWhich solution will meet these requirements?","answer_description":"","timestamp":"2023-06-08 04:16:00","isMC":true,"question_images":[],"answer_images":[],"answer":"A","exam_id":34,"choices":{"A":"Create an S3 gateway endpoint that uses the default gateway endpoint policy. Associate the private subnet with the gateway endpoint.","B":"Create an S3 interface endpoint. Associate the EC2 instances with the interface endpoint.","D":"Configure a proxy EC2 instance. Update the private subnet route tables to route traffic through the proxy EC2 instance. Configure the proxy to route all S3 requests to the target S3 bucket.","C":"Configure a NAT gateway. Associate the private subnet with the NAT gateway."},"unix_timestamp":1686190560,"question_id":220,"discussion":[{"upvote_count":"9","content":"Selected Answer: A\nCreate an S3 gateway endpoint that uses the default gateway endpoint policy. Associate the private subnet with the gateway endpoint.\n\nNotes:\n\nAmazon S3 supports both gateway endpoints and interface endpoints. With a gateway endpoint, you can access Amazon S3 from your VPC, without requiring an internet gateway or NAT device for your VPC, and with no additional cost. However, gateway endpoints do not allow access from on-premises networks, from peered VPCs in other AWS Regions, or through a transit gateway. For those scenarios, you must use an interface endpoint, which is available for an additional cost.\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html\n\n\nInterface endpoints - These endpoints are directly accessible from applications that are on premises over VPN and AWS Direct Connect, or in a different AWS Region over VPC peering.\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html","timestamp":"1703480340.0","poster":"noahsark","comment_id":"933143"},{"content":"Selected Answer: A\nsame s3 region - use gateway endpoint\nanother s3 region - use interface endpoint\nhttps://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/","comment_id":"961248","upvote_count":"5","poster":"maddyr","timestamp":"1706086920.0"},{"content":"Selected Answer: A\ngateway is for inside the VPC and Interface is for Outside the VPC.","comment_id":"1325040","upvote_count":"1","poster":"numark","timestamp":"1733924580.0"},{"timestamp":"1727158020.0","content":"Selected Answer: A\nGateway Endpoint: Free to use\nInterface Endpoint: $0.01 per hour per Availability Zone (AZ) with additional charges of $0.01 per GB of data transferred (depending on region)\nConnectivity:\n\nGateway Endpoint: Limited to access within the same region and VPC. Does not allow access from on-premises networks, peered VPCs in other regions, or through a transit gateway.\nInterface Endpoint: More flexible, allowing access from your VPC, peered VPCs in other regions, on-premises networks, and through a transit gateway.\nUse Cases:\n\nGateway Endpoint: Ideal for simple setups within a single region where cost is a major concern.\nInterface Endpoint: Better suited for complex network architectures, cross-region access, or when you need to connect to other AWS services besides S3.","comment_id":"1181367","poster":"klayytech","upvote_count":"2"},{"comment_id":"1115550","timestamp":"1720309860.0","content":"Selected Answer: A\nGateway Endpoint is the right answer.\n\nInterface Endpoints offer more connectivity options at much higher cost!","poster":"TareDHakim","upvote_count":"2"},{"comment_id":"1107643","upvote_count":"3","timestamp":"1719560580.0","content":"Selected Answer: B\nS3 Interface Endpoint (Gateway VPC Endpoint): This allows communication between resources in your VPC and Amazon S3, without relying on internet access. Interface endpoints are powered by AWS PrivateLink and provide a secure connection over the AWS global network. It does not require a NAT gateway or a proxy EC2 instance.\n\n Private Subnet Association: By associating the EC2 instances with the interface endpoint, you enable them to communicate with S3 securely without internet access.","poster":"r2c3po"},{"upvote_count":"2","poster":"xile1021","content":"Selected Answer: A\nA\nThis option, utilizing an S3 gateway endpoint, is designed for secure and private communication between a VPC and S3 over Direct Connect or VPN connections without requiring changes to the instances or applications. It allows EC2 instances in the private subnet to access S3 securely without using the public internet and does not require modifications to the instances or applications.\n\nOption B (S3 interface endpoint) is also a valid choice, but it's typically used for private VPC-to-S3 communication within the AWS network. However, it still requires creating an interface endpoint and associating EC2 instances with it.","timestamp":"1712280300.0","comment_id":"1025240"},{"upvote_count":"2","content":"Selected Answer: A\nA makes more sense","timestamp":"1705278960.0","poster":"lluukkyy","comment_id":"951881"},{"timestamp":"1704099360.0","poster":"TQM__9MD","comment_id":"939676","upvote_count":"2","content":"Selected Answer: B\nThe solution that meets these requirements is option B.\n\nIn option B, you would create an S3 interface endpoint and associate the EC2 instance with that interface endpoint. The S3 interface endpoint provides a private connection for accessing the S3 bucket directly from within the VPC. This solution allows the EC2 instance to access the S3 bucket without requiring internet access.\n\nOption A suggests using an S3 gateway endpoint with a default gateway endpoint policy. While the gateway endpoint provides a private connection for S3 object operations, it does not provide direct file system-level access from the EC2 instance."},{"poster":"jas26says","content":"Answer is A.\nGateway endpoint purpose is to provide access to S3 without giving access to the internet.\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjlmd3xgNP_AhXSSDABHeCrDTwQFnoECBgQAQ&url=https%3A%2F%2Fdocs.aws.amazon.com%2Fvpc%2Flatest%2Fprivatelink%2Fvpc-endpoints-s3.html&usg=AOvVaw0FB63FuHzsLuHYlvNgB-rW&opi=89978449","timestamp":"1703115120.0","comment_id":"928821","upvote_count":"2"},{"content":"Selected Answer: B\nI think both A and B could provide EC2 access to S3. However, I found gateway endpoint is only associated with a VPC, not a subnet. The Interface Endpoint is associated with a subnet. Secondly, I don't think the default endpoint policy is sufficient.\n\"ensure that your endpoint policy allows the AWS service or resource to access these buckets using the s3:GetObject action\"\nTo me, the answer has to be \"B\". Its a tough question (at least for me)\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","comments":[{"poster":"eboehm","upvote_count":"2","content":"While I agree that you are right about the use of the default endpoint policy not being sufficient and kinda is throwing me off as well. \nI am still going to go with A because it states they want no change to the EC2 instances. A gateway endpoint is done with a route entry","comment_id":"957992","timestamp":"1705808220.0"}],"upvote_count":"3","timestamp":"1702158000.0","comment_id":"919604","poster":"Gomer"},{"upvote_count":"3","poster":"Nrn143","comment_id":"917730","timestamp":"1702008960.0","content":"A\nThe EC2 instances must not have access to the internet, so gateway and point"}],"topic":"1","answers_community":["A (74%)","B (26%)"]}],"exam":{"isMCOnly":false,"numberOfQuestions":477,"id":34,"provider":"Amazon","isBeta":false,"name":"AWS Certified SysOps Administrator - Associate","lastUpdated":"11 Apr 2025","isImplemented":true},"currentPage":44},"__N_SSP":true}