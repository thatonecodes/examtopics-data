{"pageProps":{"questions":[{"id":"EB1tZm7YvSaqQZAzNJOD","answer_ET":"B","timestamp":"2020-07-21 10:23:00","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/26311-exam-aws-certified-database-specialty-topic-1-question-78/","topic":"1","answer":"B","question_text":"A financial company has allocated an Amazon RDS MariaDB DB instance with large storage capacity to accommodate migration efforts. Post-migration, the company purged unwanted data from the instance. The company now want to downsize storage to save money. The solution must have the least impact on production and near-zero downtime.\nWhich solution would meet these requirements?","unix_timestamp":1595319780,"answers_community":["B (100%)"],"question_id":336,"answer_description":"","discussion":[{"timestamp":"1632699300.0","comment_id":"147512","upvote_count":"24","poster":"BillyMadison","content":"https://aws.amazon.com/premiumsupport/knowledge-center/rds-db-storage-size/\"After you create an Amazon RDS DB instance, you can't modify the allocated storage size of the DB instance to decrease the total storage space it uses. To decrease the storage size of your DB instance, create a new DB instance that has less provisioned storage size. Then, migrate your data into the new DB instance using one of the following methods:\nUse the database engine's native dump and restore method.\nNote: This method causes some downtime.\nUse AWS Database Migration Service (AWS DMS) for minimal downtime.\""},{"content":"Selected Answer: B\nA. Create a snapshot of the old databases and restore the snapshot with the required storage (Downtime )\nB. Create a new RDS DB instance with the required storage and move the databases from the old instances to the new instance using AWS DMS ( no downtime)\nC. Create a new database using native backup and restore (Downtime like A)\nD. Create a new read replica and make it the primary by terminating the existing primary (wont change the storage)","upvote_count":"5","comment_id":"561173","timestamp":"1646454240.0","poster":"RotterDam"},{"timestamp":"1655876340.0","poster":"sachin","comment_id":"620187","upvote_count":"4","content":"Its not D because For replication to operate effectively, each Read Replica should have the same amount of compute & storage resources as the source DB instance."},{"content":"Selected Answer: B\nB. When you create a read replica you cannot set the storage size... so D is incorrect.","timestamp":"1647172620.0","poster":"Dantas","comment_id":"566783","upvote_count":"2"},{"upvote_count":"1","comment_id":"548462","poster":"yahooos","timestamp":"1645004760.0","content":"B\nAlmost no downtime > AWS DMS"},{"poster":"aws_enthu","content":"Isn't A?","comments":[{"content":"no, this will not shrink the size","comment_id":"557367","timestamp":"1645971360.0","upvote_count":"2","poster":"user0001"},{"timestamp":"1678084140.0","upvote_count":"1","content":"key: 'near-zero downtime'.","poster":"Nice_Guy","comment_id":"830586"}],"comment_id":"511603","timestamp":"1640728500.0","upvote_count":"1"},{"comment_id":"491995","timestamp":"1638400260.0","upvote_count":"2","poster":"shuraosipov","content":"Selected Answer: B\nAnswer is B.\nYou cannot downsize the database storage size on RDS."},{"timestamp":"1636842540.0","comment_id":"477833","upvote_count":"2","content":"Almost no downtime > AWS DMS : Option B","poster":"jove"},{"upvote_count":"3","timestamp":"1635746040.0","content":"D is not correct because, You cannot set the size of the read replica, which is always same as the master.","poster":"aws4myself","comment_id":"433352"},{"upvote_count":"1","timestamp":"1635352680.0","content":"B is correct. D is close, however, you don't make the read replica the primary by terminating the existing primary.\n\"Create a new read replica and make it the primary by terminating the existing primary\"","poster":"stevewuoisiro","comments":[{"content":"Yes, you can make the read replica the primary just by terminating the current primary. Anyways option D is incorrect once the replica storage will be the same as the primary.","comment_id":"566831","upvote_count":"1","timestamp":"1647175260.0","poster":"Dantas"}],"comment_id":"370900"},{"content":"D can be an option too. Read replicas can have different storage size and Read replicas will have less impact on production as compared to DMS.","comment_id":"365484","poster":"Dip11","upvote_count":"1","timestamp":"1635137460.0"},{"content":"B looks correct according to BillyMadaison's link. Not my initial answer though","upvote_count":"1","poster":"Aesthet","comment_id":"358876","timestamp":"1634957820.0"},{"timestamp":"1634593620.0","content":"Ans: B","upvote_count":"1","comment_id":"299152","poster":"myutran"},{"poster":"JobinAkaJoe","upvote_count":"1","timestamp":"1634183400.0","content":"B looks to be the correct answer","comment_id":"253521"},{"poster":"Ashoks","comment_id":"212857","content":"Yes. B is the answer\nsnapshot will retain same size. DB needs to be recreated and DMS is for near zero","timestamp":"1633374300.0","upvote_count":"3"},{"upvote_count":"1","comment_id":"210010","timestamp":"1632913020.0","poster":"halol","content":"B is corect"},{"upvote_count":"1","poster":"Ebi","comment_id":"159746","timestamp":"1632761340.0","content":"B is correct"},{"upvote_count":"1","content":"Ans B is correct for me","poster":"BillyC","comment_id":"144981","timestamp":"1632631200.0"},{"content":"why not D ?\nOk read replicas should be scaled as the primary.","timestamp":"1632505380.0","comment_id":"141895","upvote_count":"1","poster":"SaulGoodman"},{"comment_id":"140139","upvote_count":"4","poster":"pan24","timestamp":"1632131520.0","content":"Ans:B\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-db-storage-size/\nUse AWS Database Migration Service (AWS DMS) for minimal downtime."}],"choices":{"A":"Create a snapshot of the old databases and restore the snapshot with the required storage","C":"Create a new database using native backup and restore","B":"Create a new RDS DB instance with the required storage and move the databases from the old instances to the new instance using AWS DMS","D":"Create a new read replica and make it the primary by terminating the existing primary"},"exam_id":22,"isMC":true},{"id":"mGJWP7dwbYtXkaeGqyOZ","answer_description":"","discussion":[{"content":"D is correct","upvote_count":"8","timestamp":"1632833640.0","poster":"k115","comment_id":"138022"},{"content":"Selected Answer: D\nIt's noted in the question that the connection needs to be encrypted.\nIt's also noted that the logon credentials are confirmed, they should be right.\nB is out of question, there is no such thing as a subnet group to control access.\nD is the only reasonable option.","poster":"Germaneli","comment_id":"1010784","upvote_count":"1","timestamp":"1695058440.0"},{"timestamp":"1693566420.0","content":"Selected Answer: D\nD. Ensure that the connection is using SSL and is addressing the port where the RDS DB instance is listening for encrypted connections","upvote_count":"2","comment_id":"995976","poster":"Pranava_GCP"},{"content":"Selected Answer: D\nA lot of time this issue has happened to me, a Developer call me because is unable to connect to Redshift or any other DB and the problem is that they forgot to check \"use SSL\" in DBeaver. :)\nI will go with D:","timestamp":"1656458700.0","poster":"rlnd2000","upvote_count":"4","comment_id":"624313"},{"comment_id":"620946","timestamp":"1655985120.0","poster":"ryuhei","upvote_count":"1","content":"Selected Answer: D\nOfcourse it's decided to be D"},{"poster":"awsguys","timestamp":"1653169560.0","upvote_count":"2","comment_id":"605037","content":"d. as all data in transit be encrypted"},{"upvote_count":"2","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.Concepts.General.SSL.Using.html\n\nD. addressing the port where the RDS DB instance is listening for encrypted connections (communications connection failure => port)","poster":"novice_expert","comment_id":"595208","timestamp":"1651343280.0"},{"timestamp":"1649850060.0","comment_id":"585168","poster":"kret","upvote_count":"2","content":"Selected Answer: D\n\"Other members of the Development team are able to connect\", so obviously not B"},{"timestamp":"1642848120.0","content":"Selected Answer: B\n\"firm mandates that all data in transit be encrypted\" but \"Other members of the Development team are able to connect\", then SSL connections are ok. B is the answer that has more sence for communication error.","poster":"soyyodario","upvote_count":"1","comment_id":"529762"},{"comment_id":"510825","timestamp":"1640670720.0","poster":"Shunpin","content":"Selected Answer: D\n\"a communications connection failure\". It's about communication failure during connection.","upvote_count":"1"},{"content":"Asnwer D: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.Concepts.General.SSL.Using.html","comment_id":"415885","upvote_count":"1","poster":"gelsm","timestamp":"1636022520.0"},{"timestamp":"1635854280.0","content":"D for sure.","poster":"Dip11","upvote_count":"1","comment_id":"365486"},{"poster":"shantest1","timestamp":"1635813540.0","comment_id":"326613","content":"D is correct","upvote_count":"1"},{"timestamp":"1635737160.0","content":"Ans: D","upvote_count":"2","comment_id":"299160","poster":"myutran"},{"timestamp":"1635619140.0","comment_id":"253524","poster":"JobinAkaJoe","upvote_count":"2","content":"D is my choice"},{"comment_id":"212864","timestamp":"1635173340.0","content":"D is the answer","poster":"Ashoks","upvote_count":"2"},{"timestamp":"1633795560.0","comment_id":"159748","content":"D is answer","poster":"Ebi","upvote_count":"1"},{"poster":"szmulder","content":"B is incorrect due to \"Other members of the Development team can connect\"","comment_id":"159540","upvote_count":"3","timestamp":"1632917280.0"},{"comment_id":"144983","poster":"BillyC","content":"Ans D here","timestamp":"1632885600.0","upvote_count":"3"}],"topic":"1","timestamp":"2020-07-18 07:29:00","choices":{"C":"Ensure that the RDS DB instance has not reached its maximum connections limit","A":"Ensure that the database option group for the RDS DB instance allows ingress from the Developer machine's IP address","D":"Ensure that the connection is using SSL and is addressing the port where the RDS DB instance is listening for encrypted connections","B":"Ensure that the RDS DB instance's subnet group includes a public subnet to allow the Developer to connect"},"unix_timestamp":1595050140,"question_text":"A large financial services company requires that all data be encrypted in transit. A Developer is attempting to connect to an Amazon RDS DB instance using the company VPC for the first time with credentials provided by a Database Specialist. Other members of the Development team can connect, but this user is consistently receiving an error indicating a communications link failure. The Developer asked the Database Specialist to reset the password a number of times, but the error persists.\nWhich step should be taken to troubleshoot this issue?","isMC":true,"answers_community":["D (93%)","7%"],"answer":"D","question_images":[],"exam_id":22,"answer_images":[],"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/26024-exam-aws-certified-database-specialty-topic-1-question-79/","question_id":337},{"id":"AN9OF4KmbJgwVawBj54L","answer_images":[],"answer":"ACF","topic":"1","choices":{"F":"Ensure the cluster is created with the auth-token parameter and that the parameter is used in all subsequent commands.","A":"Enable in-transit and at-rest encryption on the ElastiCache cluster.","C":"Ensure the security group for the ElastiCache cluster allows all inbound traffic from itself and inbound traffic on TCP port 6379 from trusted clients only.","E":"Ensure the security group for the ElastiCache clients authorize inbound TCP port 6379 and port 22 traffic from the trusted ElastiCache cluster's security group.","B":"Ensure that Amazon CloudWatch metrics are configured in the ElastiCache cluster.","D":"Create an IAM policy to allow the application service roles to access all ElastiCache API actions."},"isMC":true,"answer_ET":"ACF","answers_community":["ACF (100%)"],"answer_description":"","question_id":338,"url":"https://www.examtopics.com/discussions/amazon/view/67043-exam-aws-certified-database-specialty-topic-1-question-8/","question_text":"A financial services company is developing a shared data service that supports different applications from throughout the company. A Database Specialist designed a solution to leverage Amazon ElastiCache for Redis with cluster mode enabled to enhance performance and scalability. The cluster is configured to listen on port 6379.\nWhich combination of steps should the Database Specialist take to secure the cache data and protect it from unauthorized access? (Choose three.)","question_images":[],"exam_id":22,"unix_timestamp":1638374760,"timestamp":"2021-12-01 17:06:00","discussion":[{"timestamp":"1694694480.0","comment_id":"1007609","upvote_count":"2","poster":"Pranava_GCP","content":"Selected Answer: ACF\nACF are correct\n\nA refer to\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html\n\nF refers to \nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html"},{"timestamp":"1688456400.0","upvote_count":"1","comment_id":"942485","content":"Selected Answer: ACF\nACF is correct because those are preventive protection\nB - not preventive\nD - what about non-IAM-based connections? :)\nE - client-server architecture -> always the client initiates the connection! The cluster needs SG to prevent connections from unexpected sources and on unexpected ports, instead of clients...","poster":"mraronsimon"},{"upvote_count":"1","content":"ACF is the correct answer","comment_id":"852840","poster":"ken_test1234","timestamp":"1679983560.0"},{"poster":"SteveMartin9","timestamp":"1673959020.0","content":"Selected Answer: ACF\nAuthor from the Udemy.com practice test says ACF is the correct answer.","comment_id":"778905","upvote_count":"3"},{"timestamp":"1673695800.0","poster":"SachinGoel","upvote_count":"1","comment_id":"775286","content":"Selected Answer: ACF\nACF is right choice"},{"content":"Why A, if data is encrypted, it will remain confidentials but open for manipulation as you can delete it. Encryption can give confidentiality but can't gurantee integrity.","comment_id":"743759","poster":"sju","timestamp":"1670920740.0","upvote_count":"1"},{"poster":"Sab","comment_id":"729573","content":"Elasticache for Redis 7.0 now support IAM authentication through users and roles.","upvote_count":"1","timestamp":"1669665300.0"},{"upvote_count":"4","poster":"novice_expert","timestamp":"1651351800.0","comment_id":"595284","content":"Selected Answer: ACF\nA. Enable in-transit and at-rest encryption on the ElastiCache cluster.\nx B. why CloudWatch ?\nC. Ensure the security group for the ElastiCache cluster allows all inbound traffic from itself and inbound traffic on TCP port 6379 from trusted clients only.\nx why all API? D. Create an IAM policy to allow the application service roles to access all ElastiCache API actions.\nx why 22? E. Ensure the security group for the ElastiCache clients authorize inbound TCP port 6379 and port 22 traffic from the trusted ElastiCache cluster's security group.\nF. Ensure the cluster is created with the auth-token parameter and that the parameter is used in all subsequent commands."},{"comment_id":"531540","content":"Selected Answer: ACF\nACF are the correct\nE Why do you need port 22?","poster":"soyyodario","upvote_count":"2","timestamp":"1643053260.0"},{"content":"ADF are the correct options","upvote_count":"1","comment_id":"498689","poster":"2025flakyt","timestamp":"1639145940.0"},{"timestamp":"1639145520.0","poster":"2025flakyt","comments":[{"timestamp":"1640316180.0","poster":"jove","comment_id":"508289","upvote_count":"1","content":"These questions are not for up to date versions. When this question was added the \nmost likely the EC2-Classic was still very much available. \n\nMy choice is ACF"},{"content":"The following is needed to protect ElastiCache\nUse multi-factor authentication (MFA) with each account.\nUse SSL/TLS to communicate with AWS resources.\nSet up API and user activity logging with AWS CloudTrail.\nUse AWS encryption solutions, along with all default security controls within AWS services.\nUse advanced managed security services such as Amazon Macie, which assists in discovering and securing personal data that is stored in Amazon S3.","upvote_count":"2","timestamp":"1639145880.0","poster":"2025flakyt","comment_id":"498686"}],"upvote_count":"1","comment_id":"498678","content":"Ensure the security group for the ElastiCache cluster allows all inbound traffic from itself is only needed when you launched your ElastiCache instance in EC2 Classic. so C is not a valid option"},{"content":"ACF.\nF refers to https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html","comment_id":"491791","timestamp":"1638374760.0","poster":"cynthiacy","upvote_count":"2"}]},{"id":"LIL1mSDKkgPlPCU6cBfn","url":"https://www.examtopics.com/discussions/amazon/view/25210-exam-aws-certified-database-specialty-topic-1-question-80/","question_text":"A company is running Amazon RDS for MySQL for its workloads. There is downtime when AWS operating system patches are applied during the Amazon RDS- specified maintenance window.\nWhat is the MOST cost-effective action that should be taken to avoid downtime?","isMC":true,"unix_timestamp":1594278660,"answers_community":["D (100%)"],"question_id":339,"timestamp":"2020-07-09 09:11:00","topic":"1","answer_description":"","exam_id":22,"answer_images":[],"choices":{"D":"Enable an Amazon RDS for MySQL Multi-AZ configuration","A":"Migrate the workloads from Amazon RDS for MySQL to Amazon DynamoDB","C":"Enable a read replica and direct read traffic to it when Amazon RDS is down","B":"Enable cross-Region read replicas and direct read traffic to them when Amazon RDS is down"},"discussion":[{"comment_id":"147409","poster":"BillyMadison","timestamp":"1632877440.0","content":"Going with D for now\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-required-maintenance/\nTo minimize downtime, modify the Amazon RDS DB instance to a Multi-AZ deployment. For Multi-AZ deployments, OS maintenance is applied to the secondary instance first, then the instance fails over, and then the primary instance is updated. The downtime is during failover. For more information, see Maintenance for Multi-AZ Deployments.\nhttps://aws.amazon.com/rds/faqs/\nThe availability benefits of Multi-AZ also extend to planned maintenance. For example, with automated backups, I/O activity is no longer suspended on your primary during your preferred backup window, since backups are taken from the standby. In the case of patching or DB instance class scaling, these operations occur first on the standby, prior to automatic fail over. As a result, your availability impact is limited to the time required for automatic failover to complete.","upvote_count":"14"},{"timestamp":"1632503160.0","upvote_count":"5","comment_id":"130405","content":"Ans: D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-required-maintenance/","poster":"pan24"},{"timestamp":"1695058740.0","upvote_count":"1","content":"Selected Answer: D\nA is a diverter.\nB + C are only for reading, that doesn't help a Production database to avoid downtime.\nD is documented to help reduce downtime during OS patch cycles.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-required-maintenance/","comment_id":"1010787","poster":"Germaneli"},{"timestamp":"1693567080.0","upvote_count":"1","poster":"Pranava_GCP","content":"Selected Answer: D\nD. Enable an Amazon RDS for MySQL Multi-AZ configuration","comment_id":"995983"},{"upvote_count":"1","timestamp":"1691320440.0","comment_id":"973758","content":"Selected Answer: D\nFor OS maintenance (\"AWS operating system patches are applied \"), OS maintenance is applied to the secondary instance first, then the instance fails over, and then the primary instance is updated. \nhttps://repost.aws/knowledge-center/rds-required-maintenance","poster":"IhorK"},{"comment_id":"938751","timestamp":"1688093700.0","upvote_count":"1","content":"Selected Answer: D\nhttps://repost.aws/knowledge-center/rds-required-maintenance","poster":"adelcold"},{"content":"Selected Answer: D\nObviously D is correct.","timestamp":"1653225720.0","poster":"praffuln","comment_id":"605533","upvote_count":"2"},{"poster":"novice_expert","content":"Selected Answer: D\nC is the answer if the workload is read-only.\nD is the answer to do the maintenance for R+W workload with reduced outage","timestamp":"1651352340.0","comment_id":"595288","upvote_count":"1"},{"poster":"stevewuoisiro","timestamp":"1635955680.0","comment_id":"370913","upvote_count":"1","content":"D is correct: \"Single-AZ deployments are unavailable for a few minutes. Multi-AZ deployments are unavailable for the time it takes the instance to failover (usually about 60 seconds) if the Availability Zone is affected by the maintenance. If only the secondary Availability Zone is affected, then there is no failover or downtime. \"\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-required-maintenance/"},{"content":"D for sure.","timestamp":"1635842400.0","upvote_count":"1","poster":"Dip11","comment_id":"365489"},{"poster":"shantest1","comment_id":"326614","content":"Ans: D","upvote_count":"2","timestamp":"1635264120.0"},{"upvote_count":"2","poster":"myutran","content":"-Ans: D","comment_id":"299169","timestamp":"1635182760.0"},{"poster":"JobinAkaJoe","timestamp":"1635001260.0","comment_id":"253529","content":"A. Migrate the workloads from Amazon RDS for MySQL to Amazon DynamoDB\nDynamoDB is not appropriate to take over RDS workload.\nB. Enable cross-Region read replicas and direct read traffic to then when Amazon RDS is down\nWhat about writes ? why do you need cross-region when you can have read-replicas in same region\nC. Enable a read replicas and direct read traffic to it when Amazon RDS is down\nWhat about write workload ?\nD. Enable an Amazon RDS for MySQL Multi-AZ configuration\nHelps in reducing the outage required for the maintenance(just a failover)\n\nC is the answer if the workload is read-only.\nD is the answer to do the maintenance for R+W workload with reduced outage","upvote_count":"4"},{"comment_id":"212867","content":"Yes it is D","poster":"Ashoks","upvote_count":"2","timestamp":"1634903280.0"},{"comment_id":"178362","content":"Ans is D","timestamp":"1634432040.0","poster":"Billhardy","upvote_count":"1"},{"upvote_count":"1","poster":"Ebi","content":"Answer is D","comment_id":"159754","timestamp":"1634405400.0"},{"poster":"[Removed]","content":"D. 100%","comment_id":"158594","timestamp":"1633398720.0","upvote_count":"2"},{"timestamp":"1632808620.0","comment_id":"146513","content":"Yes D is correct","upvote_count":"2","poster":"BillyC"}],"question_images":[],"answer":"D","answer_ET":"D"},{"id":"Rzu6PehwUWub6IR1Xffi","exam_id":22,"discussion":[{"comment_id":"140141","timestamp":"1632762540.0","content":"ANS: A\nsnapshot is lazy loaded If the volume is accessed where the data is not loaded, the application accessing the volume encounters a higher latency than normal while the data gets loaded","poster":"pan24","upvote_count":"15","comments":[{"content":"https://aws.amazon.com/about-aws/whats-new/2019/11/amazon-ebs-fast-snapshot-restore-eliminates-need-for-prewarming-data-into-volumes-created-snapshots/","upvote_count":"1","poster":"gelsm","comment_id":"414327","timestamp":"1635789780.0","comments":[{"timestamp":"1657093380.0","content":"question is about RDS this link is irrevalent not need to confuse ebs and rds","poster":"hariti_crafting","comment_id":"627778","upvote_count":"4"}]}]},{"timestamp":"1646458860.0","comment_id":"561246","poster":"RotterDam","content":"Selected Answer: A\nUnlike Aurora - RDS does not have a warm pool of cache (unless its POSTGRES and you are using CCM there - but there is MYSQL). First touch penalty. Can be mitigated with doing a select * from all tables","upvote_count":"10"},{"comment_id":"912698","poster":"aviathor","upvote_count":"2","timestamp":"1685698740.0","content":"Selected Answer: B\nAn active, long-running transaction can slow the process of creating the read replica. We recommend that you wait for long-running transactions to complete before creating a read replica. If you create multiple read replicas in parallel from the same source DB instance, Amazon RDS takes only one snapshot at the start of the first create action.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.Create"},{"upvote_count":"2","comments":[{"poster":"ray6li","timestamp":"1658083560.0","content":"Correction: Ans: A. Lag != slow response time.","upvote_count":"3","comment_id":"632673"}],"poster":"Rayls2000","comment_id":"630151","content":"Ans: B\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-mysql-high-replica-lag/\nIf the replica SQL_THREAD is the source of replication delays, then those delays could be caused by the following:\n\nLong-running queries on the primary DB instance\nInsufficient DB instance class size or storage\nParallel queries run on the primary DB instance\nBinary logs synced to the disk on the replica DB instance\nBinlog_format on the replica is set to ROW\nReplica creation lag","timestamp":"1657561140.0"},{"poster":"novice_expert","upvote_count":"3","content":"Selected Answer: A\nhttps://aws.amazon.com/about-aws/whats-new/2019/11/amazon-ebs-fast-snapshot-restore-eliminates-need-for-prewarming-data-into-volumes-created-snapshots/","timestamp":"1651263720.0","comment_id":"594683","comments":[]},{"content":"Selected Answer: A\nOption A.","timestamp":"1637931000.0","poster":"GMartinelli","comment_id":"487359","upvote_count":"2"},{"upvote_count":"1","content":"Ans: A","comment_id":"326616","timestamp":"1635635520.0","poster":"shantest1"},{"content":"A is my choice","poster":"JobinAkaJoe","comment_id":"253530","upvote_count":"1","timestamp":"1634980920.0"},{"timestamp":"1634917320.0","comment_id":"212871","upvote_count":"2","content":"Yes, it is A","poster":"Ashoks"},{"timestamp":"1634488800.0","poster":"Ebi","comment_id":"159756","upvote_count":"2","content":"A is correct"},{"upvote_count":"2","content":"Ans A\nWhen you spin up a new replica, its EBS volume loads lazily in the background","poster":"firbhat","comment_id":"154315","timestamp":"1634409060.0"},{"upvote_count":"3","timestamp":"1632933720.0","comment_id":"148066","poster":"BillyC","content":"Yes A is Correct"}],"answer_images":[],"choices":{"D":"Overload of a single replication thread by excessive writes on the master","C":"Insufficient resources on the master","A":"New volumes created from snapshots load lazily in the background","B":"Long-running statements on the master"},"answer":"A","answers_community":["A (88%)","12%"],"question_id":340,"answer_ET":"A","answer_description":"","unix_timestamp":1595319960,"isMC":true,"question_images":[],"topic":"1","timestamp":"2020-07-21 10:26:00","url":"https://www.examtopics.com/discussions/amazon/view/26312-exam-aws-certified-database-specialty-topic-1-question-81/","question_text":"A Database Specialist must create a read replica to isolate read-only queries for an Amazon RDS for MySQL DB instance. Immediately after creating the read replica, users that query it report slow response times.\nWhat could be causing these slow response times?"}],"exam":{"isImplemented":true,"numberOfQuestions":359,"lastUpdated":"11 Apr 2025","name":"AWS Certified Database - Specialty","isMCOnly":false,"provider":"Amazon","id":22,"isBeta":false},"currentPage":68},"__N_SSP":true}