{"pageProps":{"questions":[{"id":"yMn5dI8dUWCDpXpyimav","discussion":[{"comments":[{"timestamp":"1667973180.0","content":"AC: https://aws.amazon.com/blogs/aws/aws-privatelink-for-amazon-s3-now-available/","comment_id":"714327","poster":"Byrney","upvote_count":"3"}],"poster":"Ni_yot","comment_id":"671562","content":"Ans is A C. S3 supports both gateway and interface endpoints. The main difference is that interface endpoint allows access from on-premises while gateway endpoint does not. \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","upvote_count":"15","timestamp":"1663421760.0"},{"content":"Selected Answer: AC\nAnswer: Private VIF + Interface endpoint \n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-bucket-access-direct-connect/\n\nUse a private IP address over Direct Connect (with an interface VPC endpoint)\nTo access Amazon S3 using a private IP address over Direct Connect, perform the following steps:\n...\n3. Create a private virtual interface for your connection.\n...\n5. Create an interface VPC endpoint for Amazon S3 in a VPC that is associated with the virtual private gateway. The VGW must connect to a Direct Connect private virtual interface. This interface VPC endpoint resolves to a private IP address even if you enable a VPC endpoint for S3.","poster":"redipa","timestamp":"1663702740.0","upvote_count":"8","comment_id":"674471","comments":[{"timestamp":"1665274980.0","comment_id":"689778","upvote_count":"1","content":"AC \n\nRule out B because it didn't mentioned creating an interface VPC endpoint for Amazon S3 which is needed for Using a private IP address over Direct Connect (with an interface VPC endpoint).. Thus A seems a logical choice instead of B.","poster":"skywalker"}]},{"comment_id":"1248411","poster":"WhyIronMan","timestamp":"1721054820.0","content":"Selected Answer: AC\nA,C, as interface endpoint allows access from on-premises while gateway endpoint does not","upvote_count":"1"},{"timestamp":"1689202080.0","content":"Correct AC.","comment_id":"950228","poster":"ggrodskiy","upvote_count":"1"},{"comment_id":"717534","timestamp":"1668375120.0","upvote_count":"1","content":"A and C. You can't route from on prem to the gateway VPC endpoint.","poster":"LrdKanien"},{"poster":"alnadan","content":"Selected Answer: AC\nAC\nHere is the link: https://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/","comment_id":"715962","upvote_count":"1","timestamp":"1668163380.0"},{"comment_id":"715961","timestamp":"1668163320.0","poster":"alnadan","upvote_count":"1","content":"A & C\nhttps://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/"},{"timestamp":"1666275000.0","poster":"Blair77","upvote_count":"2","content":"Selected Answer: AC\nA&C:\nhttps://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/","comment_id":"700005"},{"comment_id":"697399","content":"BD\nNeed public VIF + Gateway endpoint for S3","comments":[{"content":"changed to AC","upvote_count":"1","timestamp":"1667245620.0","comment_id":"708697","poster":"Rocketeer"}],"timestamp":"1666009980.0","poster":"Rocketeer","upvote_count":"3"},{"comments":[{"timestamp":"1665591600.0","upvote_count":"1","poster":"JohnPi","comment_id":"693248","content":"AC Private VIF + Interface endpoint"}],"poster":"JohnPi","comment_id":"685263","timestamp":"1664778360.0","content":"Selected Answer: BC\npublic VIF + interface endpoint","upvote_count":"2"},{"content":"In scenarios where you must access S3 buckets securely from on-premises or from across Regions, we recommend using an interface endpoint. If you chose a gateway endpoint, install a fleet of proxies in the VPC to address transitive routing.","comment_id":"671399","upvote_count":"2","poster":"Cloudxie","timestamp":"1663407480.0"},{"comment_id":"665258","poster":"Biden","upvote_count":"2","timestamp":"1662800640.0","content":"As an architect consider future needs too. GW EPs is supported for resources in a specific VPC to which the EP is associated, which complicates future design. Hence A,C !!"},{"upvote_count":"4","content":"My Answer is A,C\n\nWe all have consensus on A.\n\nBetween D & E,\nD (S3 Gateway Endpoint) is Regional, and doesn't support in cross-VPC. Here question doesn't state anything on region on cross-account. So have doubt on D that it will NOT work.\n\nAnd C(S3 Interfcae endpoint) can work on multi-region, cross-account etc.\n\nREf - https://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/","poster":"pixepe","comment_id":"663571","timestamp":"1662637740.0"},{"comment_id":"662757","upvote_count":"3","poster":"AwsBRFan","content":"Selected Answer: AD\nS3 - Gateway interface - https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html","timestamp":"1662572400.0"},{"comments":[{"poster":"cale","timestamp":"1662508620.0","content":"I think so too - it's A & C","comment_id":"661751","upvote_count":"1"}],"timestamp":"1662430980.0","upvote_count":"2","content":"A & C to me are preferable","poster":"SGES","comment_id":"660715"},{"comment_id":"655123","poster":"Cloudyheema","content":"D & E make sense","timestamp":"1661952900.0","upvote_count":"1"}],"answer_images":[],"answer_ET":"AC","timestamp":"2022-08-31 15:35:00","isMC":true,"topic":"1","answer":"AC","unix_timestamp":1661952900,"question_id":916,"exam_id":32,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/78707-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"E":"Establish a networking account in the AWS Cloud. Create a private VPC in the networking account. Peer VPCs from the accounts that host the S3 buckets with the VPC in the network account.","A":"Establish a networking account in the AWS Cloud. Create a private VPC in the networking account. Set up an AWS Direct Connect connection with a private VIF between the on-premises environment and the private VPC.","C":"Create an Amazon S3 interface endpoint in the networking account.","B":"Establish a networking account in the AWS Cloud. Create a private VPC in the networking account. Set up an AWS Direct Connect connection with a public VIF between the on-premises environment and the private VPC.","D":"Create an Amazon S3 gateway endpoint in the networking account."},"answers_community":["AC (71%)","AD (18%)","12%"],"question_text":"A company wants to send data from its on-premises systems to Amazon S3 buckets. The company created the S3 buckets in three different accounts. The company must send the data privately without the data traveling across the internet. The company has no existing dedicated connectivity to AWS.\nWhich combination of steps should a solutions architect take to meet these requirements? (Choose two.)","question_images":[]},{"id":"E5gNFtcqU8zjzZrxUa0G","question_images":[],"timestamp":"2022-09-02 08:23:00","answers_community":["A (100%)"],"question_text":"A company wants to use a hybrid cloud architecture between an on-premises data center and AWS. The company already has deployed a multi-account structure in AWS Organizations while following the AWS Well-Architected Framework.\nDue to strict security requirements, connectivity between the data center and AWS must be encrypted in transit. Only a single entry point into AWS is permitted from the data center. The data center must be able to access all the AWS accounts.\nWhich solution meets these requirements?","unix_timestamp":1662099780,"answer_description":"","topic":"1","discussion":[{"poster":"AwsBRFan","content":"Selected Answer: A\nA.\nhttps://docs.aws.amazon.com/directconnect/latest/UserGuide/encryption-in-transit.html","comment_id":"662761","timestamp":"1662572700.0","upvote_count":"6"},{"content":"Selected Answer: A\ntraffic goes from on prem -> direct connect -> transit gateway and then the transit gateway routing tables decide on account\nD is wrong. If its marked as the correct answer, good chance its wrong for exam topics.","timestamp":"1724164740.0","poster":"devilman222","comment_id":"1269546","upvote_count":"2"},{"timestamp":"1721054940.0","upvote_count":"1","comment_id":"1248412","content":"Selected Answer: A\nA) as need encryption and it is not mention in D) as direct connect uses no encryption by default","poster":"WhyIronMan"},{"comment_id":"706281","content":"Selected Answer: A\nBecause of transit encryption, site to site vpn (using IPSec) should be created instead of direct connect, mentioned in D","poster":"zdlt","timestamp":"1666946340.0","upvote_count":"1"},{"timestamp":"1666834020.0","upvote_count":"2","comment_id":"705111","poster":"ToanVN1988","content":"Selected Answer: A\nA or D but need to encrypt in transit . Directconnect not correct. Answer is A"},{"content":"A. \n\n1. For the transit to be encrypted, Site to Site VPN is required i.e. IPSec. \n2. For the single point of entry from DC, only Transit GW will work. Because VPC Peering does not allow traffic to transit i.e. https://docs.aws.amazon.com/vpc/latest/peering/invalid-peering-configurations.html","timestamp":"1662365880.0","comment_id":"659910","poster":"rajvee","upvote_count":"2"},{"poster":"pixepe","timestamp":"1662305520.0","comment_id":"659358","content":"Answer - A.\nRequirement - \"connectivity between the data center and AWS must be encrypted in transit\" means it's VPN.\n\nVPN: \"VPN connections use IPsec to establish encrypted network connectivity between your intranet and an Amazon VPC over the public internet.\"\n\nDirect connect: By DEFAULT traffic is unencrypted. Of course, we can encrypt by additional step, but it's NOT mentioned in answer-D. \nHence, correct answer is A.","upvote_count":"2"},{"timestamp":"1662231780.0","upvote_count":"1","poster":"Rocketeer","comment_id":"658762","content":"VPN goes through internet and hence need encryption. DX is direct connection from on-prem to AWS. Using https provided the needed encryption. My answer is D"},{"comment_id":"657055","content":"Selected Answer: A\nEncryption in transit is possible by ipsec not DX","timestamp":"1662099780.0","upvote_count":"4","poster":"RVD"}],"answer_images":[],"answer":"A","isMC":true,"answer_ET":"A","question_id":917,"exam_id":32,"choices":{"A":"Connect the AWS accounts with AWS Transit Gateway. Establish an AWS Site-to-Site VPN connection with the data center, and attach the connection to the transit gateway. Route traffic from the data center to all AWS accounts.","B":"Connect the AWS accounts with VPC peering. Establish an AWS Site-to-Site VPN connection with the data center. Route traffic from the data center to all AWS accounts.","C":"Connect the AWS accounts with VPC peering. Establish an AWS Direct Connect connection to the closest AWS Region. Route traffic from the data center to all AWS accounts.","D":"Connect the AWS accounts with AWS Transit Gateway. Establish an AWS Direct Connect connection to the closest AWS Region, and attach the connection to the transit gateway. Route traffic from the data center to all AWS accounts."},"url":"https://www.examtopics.com/discussions/amazon/view/79293-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"MNsypQTt3LjZUVIkF5E6","choices":{"A":"Configure a policy in Amazon Data Lifecycle Manager (Amazon DLM) to run once daily to copy the EBS snapshots to the additional Regions.","C":"Set up AWS Backup to create the EBS snapshots. Configure Amazon S3 cross-Region replication to copy the EBS snapshots to the additional Regions.","D":"Schedule Amazon EC2 Image Builder to run once daily to create an AMI and copy the AMI to the additional Regions.","B":"Use Amazon EventBridge (Amazon CloudWatch Events) to schedule an AWS Lambda function to copy the EBS snapshots to the additional Regions."},"exam_id":32,"answer_description":"","discussion":[{"upvote_count":"10","comment_id":"663542","timestamp":"1662636120.0","content":"Answer is A.\n\nAmazon DLM features:\nAutomated snapshot and AMI creation:\nCreate a policy that automates the creation, retention, and deletion of EBS snapshots and EBS-backed AMIs.\n\nFast snapshot restore integration:\nAutomate the creation of snapshots that are enabled for fast snapshot restore. Fast snapshot restore enables you to restore volumes that are fully initialized at creation and instantly deliver all of their provisioned performance.\n\nBuilt-in cross-Region copy:\nAutomatically copy snapshots that are created by a lifecycle policy to up to three AWS Regions.\n\nAutomated cross-account snapshot copy:\nUse cross-account sharing in conjunction with a cross-account copy event policy to automatically share and copy snapshots created by a policy across accounts.","poster":"pixepe"},{"timestamp":"1672620300.0","comment_id":"763416","poster":"BlueSpark","content":"I would choose A","upvote_count":"1"},{"poster":"sb333","upvote_count":"2","comments":[{"upvote_count":"4","content":"Just re-read answer C and although I think AWS Backup (can do EBS backups) itself has less operational overhead than DLM, you do not have access to the S3 buckets to be able to configure cross-region replication - you would configure that cross-region replication within AWS Backup itself. So answer C is not technically feasible. It has to be A.","comment_id":"695548","timestamp":"1665853740.0","poster":"sb333"}],"content":"I would choose C over A. AWS Backup has MUCH less overhead in both configuration and monitoring of backup jobs for EBS snapshots (and is the newer of the two services).","timestamp":"1664671920.0","comment_id":"684541"},{"comment_id":"673582","poster":"astalavista1","content":"Selected Answer: A\nA - DLM provides low overhead.","timestamp":"1663615260.0","upvote_count":"4"},{"comment_id":"671570","upvote_count":"3","timestamp":"1663422360.0","content":"Correct Ans A","poster":"Ni_yot"},{"timestamp":"1662572820.0","upvote_count":"3","poster":"AwsBRFan","content":"Selected Answer: A\nA - DLM for EBS backups","comment_id":"662762"}],"timestamp":"2022-09-07 19:47:00","question_id":918,"topic":"1","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/80988-exam-aws-certified-solutions-architect-professional-topic-1/","question_text":"A solutions architect works for a government agency that has strict disaster recovery requirements. All Amazon Elastic Block Store (Amazon EBS) snapshots are required to be saved in at least two additional AWS Regions. The agency also is required to maintain the lowest possible operational overhead.\nWhich solution meets these requirements?","question_images":[],"unix_timestamp":1662572820,"isMC":true,"answer":"A","answer_ET":"A","answer_images":[]},{"id":"s29KPeAQIDcSDaeQAmsi","discussion":[{"comment_id":"661772","content":"Selected Answer: B\nI think it is B because the cause of the issue is not known (i.e. it might not be slow queries) and RDS has SQL statistics in Performance Insight to investigate re: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/sql-statistics.html","comments":[{"comment_id":"661773","content":"Additional reference to support: (1) https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.Cloudwatch.html and (2) https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights_Counters.html.","poster":"cale","timestamp":"1662509880.0","upvote_count":"1"}],"poster":"cale","upvote_count":"16","timestamp":"1662509580.0"},{"timestamp":"1662573660.0","content":"Selected Answer: D\nYeap really in doubt about A and D.\n1- Yes, performance insight support RDS PostgresSQL:\nhttps://aws.amazon.com/rds/performance-insights/\n2- Performance insight will help on RCA","poster":"AwsBRFan","upvote_count":"5","comment_id":"662779"},{"poster":"WhyIronMan","comment_id":"1248415","timestamp":"1721055540.0","upvote_count":"1","content":"Selected Answer: B\nB)\n\nEnhanced Monitoring plus Performance Insights will provide that +\nwith the LEAST operational overhead\nand changing the parameter group can cause the RDS do enter in modifying state making it unavailable... and we are in production..."},{"poster":"evargasbrz","content":"Selected Answer: B\nI'll go with B","timestamp":"1672840980.0","upvote_count":"1","comment_id":"765721"},{"comment_id":"716076","upvote_count":"3","content":"B for me: https://aws.amazon.com/blogs/database/monitor-amazon-rds-for-postgresql-and-amazon-aurora-for-postgresql-database-log-errors-and-set-up-notifications-using-amazon-cloudwatch/","timestamp":"1668173280.0","poster":"mrgreatness"},{"poster":"28hangcan","content":"Selected Answer: A\nA is the correct Answer","timestamp":"1667569680.0","comment_id":"711188","upvote_count":"2"},{"upvote_count":"1","comment_id":"707713","content":"Why A is wrong?","poster":"aqiao","comments":[{"content":"Because its marketed as the correct answer which is usually wrong also wrong as OS information won't help with sql errors.","comment_id":"1269551","poster":"devilman222","upvote_count":"1","timestamp":"1724165160.0"},{"timestamp":"1667120760.0","comment_id":"707721","poster":"aqiao","content":"Got it, Enhanced log is for collecting and analyzing OS level metrics, such as CPU,memory, which can't get SQL running information","upvote_count":"1"}],"timestamp":"1667120100.0"},{"timestamp":"1666834620.0","comment_id":"705126","poster":"ToanVN1988","upvote_count":"1","content":"Selected Answer: D\nNeed to combine monitor and logging analytics. D is correct"},{"timestamp":"1666786920.0","comment_id":"704666","upvote_count":"2","content":"Selected Answer: B\n-\"The company also wants to collect enough information to determine the root cause of any future incident.\" Enhanced Monitoring plus Performance Insights will provide that... Go with BBB\nhttps://www.youtube.com/watch?v=iTDt4ZhD25U","poster":"Blair77"},{"content":"Selected Answer: B\nI think it's B because the way to determine the root problem is to enable multiple mechanisms. Enhanced Monitoring, Performance Insights and metrics in CloudWatch:\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-aurora-postgresql-performance-issues/?nc1=h_ls","comment_id":"696802","upvote_count":"1","timestamp":"1665980400.0","poster":"joancarles"},{"timestamp":"1665917160.0","comment_id":"696186","content":"i would go with D","upvote_count":"1","poster":"psou7"},{"upvote_count":"1","comment_id":"689781","timestamp":"1665275280.0","poster":"skywalker","content":"Selected Answer: B\nB is my choice."},{"comment_id":"684533","poster":"sb333","timestamp":"1664670840.0","upvote_count":"4","comments":[{"poster":"JohnPi","upvote_count":"1","timestamp":"1664779140.0","comment_id":"685271","content":"Performance Insights automatically publishes metrics to Amazon CloudWatch"}],"content":"The answer is B - to enable both Enhanced Monitoring and Performance Insights. Enhanced Monitoring produces CloudWatch metrics, which can be the basis for CloudWatch alarms. Performance Insights is a great tool for troubleshooting, but it is a dashboard that does not allow data to be exported (to CloudWatch or otherwise).\n\nThe answer cannot be D, because neither Performance Insights nor query logging (stored locally on DB server) can be enabled for CloudWatch alarms."},{"timestamp":"1663593660.0","comment_id":"673329","poster":"kapara","upvote_count":"4","content":"Selected Answer: D\nD. Performance Insights will publish fewer metrics and will be less complex to set alarm policy too. since this question seems to blame the DB performance as the source for the issue, the Performance Insights metrics should be the metrics we need."},{"comment_id":"666104","timestamp":"1662898020.0","upvote_count":"3","content":"Option D","poster":"Sathish1412"},{"upvote_count":"2","content":"I would vote for D since it could be both. D covers both Postgres DB performance and slow query.","poster":"Guoxian","comment_id":"665773","timestamp":"1662862740.0"},{"comments":[{"poster":"Biden","upvote_count":"1","timestamp":"1662801240.0","comment_id":"665261","content":"Perf Insights supported for Postgre; https://aws.amazon.com/rds/performance-insights/. Hence D"},{"timestamp":"1663164360.0","content":"my bad. Perf insight is supported for RDS Postgres","comment_id":"669092","poster":"ArreRaja","upvote_count":"1"}],"upvote_count":"2","comment_id":"662374","content":"cannot be D as Performance insight is not supported for RDS PostgresSQL. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.Enabling.html","poster":"ArreRaja","timestamp":"1662548460.0"}],"answer_images":[],"exam_id":32,"topic":"1","unix_timestamp":1662509580,"url":"https://www.examtopics.com/discussions/amazon/view/80768-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"isMC":true,"answers_community":["B (65%)","D (29%)","6%"],"answer_description":"","choices":{"C":"Turn on log exports to Amazon CloudWatch for the PostgreSQL logs on the DB instance. Analyze the logs by using Amazon Elasticsearch Service (Amazon ES) and Kibana. Create a dashboard in Kibana. Configure alerts that are based on the metrics that are collected.","B":"Turn on Enhanced Monitoring and Performance Insights for the DB instance. Create Amazon CloudWatch alarms. Set the alarms to appropriate thresholds that are based on performance metrics in CloudWatch.","D":"Turn on Performance Insights for the DB instance. Modify the corresponding parameter group to turn on query logging for all the slow queries. Create Amazon CloudWatch alarms. Set the alarms to appropriate thresholds that are based on performance metrics in CloudWatch.","A":"Turn on Enhanced Monitoring for the DB instance. Modify the corresponding parameter group to turn on query logging for all the slow queries. Create Amazon CloudWatch alarms. Set the alarms to appropriate thresholds that are based on performance metrics in CloudWatch."},"answer_ET":"B","question_text":"A retail company has a small ecommerce web application that uses an Amazon RDS for PostgreSQL DB instance. The DB instance is deployed with the Multi-AZ option turned on.\nApplication usage recently increased exponentially, and users experienced frequent HTTP 503 errors. Users reported the errors, and the company's reputation suffered. The company could not identify a definitive root cause.\nThe company wants to improve its operational readiness and receive alerts before users notice an incident. The company also wants to collect enough information to determine the root cause of any future incident.\nWhich solution will meet these requirements with the LEAST operational overhead?","question_id":919,"answer":"B","timestamp":"2022-09-07 02:13:00"},{"id":"a3Q43z0dzK24unpvSiH5","unix_timestamp":1662434040,"timestamp":"2022-09-06 05:14:00","answers_community":["C (100%)"],"answer_ET":"C","answer":"C","choices":{"D":"Deploy the application in Amazon Elastic Kubernetes Service (Amazon EKS) clusters. Set up an Application Load Balancer for the EKS pods. Set up an Amazon Cognito user pool and service pod for authentication.","C":"Deploy the application as AWS Lambda functions. Set up Amazon API Gateway REST API endpoints for the application. Set up an Amazon Cognito user pool, and configure an Amazon Cognito authorizer.","A":"Deploy the application as AWS Lambda functions. Set up Amazon API Gateway REST API endpoints for the application. Create a Lambda function, and configure a Lambda authorizer.","B":"Deploy the application in AWS AppSync, and configure AWS Lambda resolvers. Set up an Amazon Cognito user pool, and configure AWS AppSync to use the user pool for authorization."},"isMC":true,"exam_id":32,"discussion":[{"timestamp":"1662434040.0","upvote_count":"7","content":"C - agreed to be better option","comment_id":"660747","poster":"SGES"},{"upvote_count":"1","timestamp":"1721055780.0","content":"Selected Answer: C\nit is c","poster":"WhyIronMan","comment_id":"1248416"},{"upvote_count":"3","poster":"masetromain","comment_id":"772826","content":"Selected Answer: C\nanswer from chatgpt\n\nThe most operationally efficient solution that meets the requirements would be option C.\nThis solution involves deploying the application as AWS Lambda functions and setting up Amazon API Gateway REST API endpoints for the application. Additionally, setting up an Amazon Cognito user pool and configuring an Amazon Cognito authorizer to handle user authentication.\n\nThis approach provides the desired level of abstraction as the application team would not have to maintain any infrastructure or servers. Also, AWS Lambda functions are a highly scalable and cost-effective way to build serverless applications. And by using the Amazon Cognito, it will handle all the user authentication and access management which is highly secure and manageable.","timestamp":"1673464500.0"},{"content":"Selected Answer: C\nC is best choice","timestamp":"1666834920.0","poster":"ToanVN1988","upvote_count":"2","comment_id":"705131"},{"upvote_count":"1","timestamp":"1665917400.0","poster":"psou7","comment_id":"696189","content":"I would go with C"},{"content":"C - lamda and conigto for authentication","poster":"Ni_yot","upvote_count":"2","timestamp":"1662738300.0","comment_id":"664754"}],"question_text":"A company is planning to set up a REST API application on AWS. The application team wants to set up a new identity store on AWS. The IT team does not want to maintain any infrastructure or servers for this deployment.\nWhat is the MOST operationally efficient solution that meets these requirements?","topic":"1","answer_description":"","question_id":920,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/80490-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[]}],"exam":{"isBeta":false,"isMCOnly":false,"id":32,"isImplemented":true,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Professional","provider":"Amazon","numberOfQuestions":1019},"currentPage":184},"__N_SSP":true}