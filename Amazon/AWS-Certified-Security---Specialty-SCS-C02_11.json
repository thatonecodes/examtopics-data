{"pageProps":{"questions":[{"id":"ue3AovJfQ3JJmHG6c94K","choices":{"D":"Create a patch policy that patches all managed nodes and sends a patch operation log output to an Amazon S3 bucket. Use a custom scan schedule to set Patch Manager to check every hour for new patches. Assign the baseline to the patch policy.","E":"Use Systems Manager Application Manager to inspect the package versions that were installed on the EC2 instances. Additionally use Application Manager to validate that the patches were correctly installed.","A":"Create a new patching baseline in Patch Manager. Specify Amazon Linux 2 as the product. Specify Security as the classification. Set the automatic approval for patches to 0 days. Ensure that the new patching baseline is the designated default for Amazon Linux 2.","B":"Use the Patch Now option with the scan and install operation in the Patch Manager console to apply patches against the baseline to all nodes. Specify an Amazon S3 bucket as the patching log storage option.","C":"Use the Clone function of Patch Manager to create a copy of the AWS-AmazonLmux2DefaultPatchBaseline built-in baseline. Set the automatic approval for patches to 1 day."},"isMC":true,"answer":"AB","question_id":51,"answer_ET":"AB","answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/140875-exam-aws-certified-security-specialty-scs-c02-topic-1/","discussion":[{"timestamp":"1743953640.0","upvote_count":"1","poster":"phmeeeee","comment_id":"1558302","content":"Selected Answer: AB\nA - selected for security classification only.\nB - for immediately apply the patch which is no need to schedule."},{"content":"Selected Answer: BD\nB and D, for sure\nI guess D is an obvious answer, but the majority says it's A.\nWhy I think other choices are wrong?\nA: While creating a baseline with 0-day approval accelerates patch availability, it doesn’t address immediate deployment or evidence.\n\nC: Reducing approval to 1 day still introduces delay and doesn’t enable on-demand action.\n\nE: Application Manager validates installations but lacks automated logging and isn’t designed for urgent deployments.","comment_id":"1395444","poster":"molerowan","upvote_count":"1","timestamp":"1741906380.0"},{"timestamp":"1721967540.0","comment_id":"1255400","poster":"toshimizu","upvote_count":"2","content":"Selected Answer: AD\nA,D　correct"},{"poster":"cumzle_com","timestamp":"1719252480.0","comments":[{"timestamp":"1741906860.0","poster":"molerowan","comment_id":"1395447","upvote_count":"1","content":"The AWS-AmazonLinux2DefaultPatchBaseline already includes security patches in its auto-approval rules. Creating a new baseline (Answer A) is redundant unless the company needs stricter controls (e.g., approving patches faster than the default 7-day delay). However, the requirement focuses on immediate deployment during incidents, not baseline modification.\nThe default baseline’s auto-approval rules are sufficient for urgent patching. The critical need is to trigger on-demand patching, not adjust approval timelines."}],"comment_id":"1236536","content":"Selected Answer: AB\nA: Creating a new patching baseline with the specific settings ensures that security patches are automatically approved without delay (0 days). This immediate approval is crucial during a security incident when rapid patch deployment is necessary. Making this baseline the designated default for Amazon Linux 2 ensures that it is applied consistently across all instances.\n\nB: Using the Patch Now option with the scan and install operation ensures that patches are deployed immediately to all EC2 instances. By specifying an Amazon S3 bucket for log storage, the company can centrally store and review logs to provide evidence that the patches were applied successfully. This meets the requirement for centralized evidence of successful patch application.","upvote_count":"4"},{"content":"A,D correct","upvote_count":"1","poster":"sema2232","timestamp":"1718185620.0","comment_id":"1228930"},{"comment_id":"1228927","comments":[{"timestamp":"1743953460.0","comment_id":"1558298","upvote_count":"1","content":"Hourly scan doesn't meet the need for immediate patching on demand. D is talking with schedule to patch not immediately.","poster":"phmeeeee"},{"poster":"lovekiller","timestamp":"1728704700.0","comment_id":"1296327","content":"Application Manager is useful for inspecting and validating package versions, but it does not provide the mechanism for immediate patch deployment. It is more suited for post-deployment validation rather than immediate action.","comments":[{"upvote_count":"2","content":"FR? Boy is asking for why not D.","timestamp":"1741906680.0","comment_id":"1395446","poster":"molerowan"}],"upvote_count":"1"}],"poster":"sema2232","content":"why not D","upvote_count":"2","timestamp":"1718185260.0"},{"timestamp":"1716277440.0","content":"Selected Answer: AB\nA & B are corrects!","comment_id":"1214787","poster":"5409b91","upvote_count":"1"},{"comment_id":"1213941","upvote_count":"1","content":"Selected Answer: AB\nA & B are correct","poster":"Certified101","timestamp":"1716144660.0"}],"question_text":"An online media company has an application that customers use to watch events around the world. The application is hosted on a fleet of Amazon EC2 instances that run Amazon Linux 2. The company uses AWS Systems Manager to manage the EC2 instances. The company applies patches and application updates by using the AWS-AmazonLinux2DefaultPatchBaseline patching baseline in Systems Manager Patch Manager.\n\nThe company is concerned about potential attacks on the application during the week of an upcoming event. The company needs a solution that can immediately deploy patches to all the EC2 instances in response to a security incident or vulnerability. The solution also must provide centralized evidence that the patches were applied successfully.\n\nWhich combination of steps will meet these requirements? (Choose two.)","answers_community":["AB (70%)","AD (20%)","10%"],"timestamp":"2024-05-19 20:51:00","exam_id":30,"unix_timestamp":1716144660,"question_images":[],"topic":"1"},{"id":"b0IkoUQ5hO9qlXYqSjem","choices":{"B":"Add the EC2 IAM role as the authorized Principal to the S3 bucket policy","A":"Edit the ReadOnlyAccess policy to add kms:Decrypt actions","C":"Attach an inline policy with kms:Decrypt permissions to the IAM role","D":"Attach an inline policy with S3:* permissions to the IAM role"},"question_id":52,"unix_timestamp":1716114480,"question_images":[],"exam_id":30,"answer":"C","topic":"1","answers_community":["C (86%)","14%"],"url":"https://www.examtopics.com/discussions/amazon/view/140866-exam-aws-certified-security-specialty-scs-c02-topic-1/","answer_images":[],"timestamp":"2024-05-19 12:28:00","discussion":[{"upvote_count":"1","poster":"IPLogic","timestamp":"1733323380.0","content":"Selected Answer: C\nTo resolve the IAM access issue, the administrator should ensure that the IAM role has the necessary permissions to decrypt the encrypted files in the S3 bucket. Since the files are encrypted, the role needs kms:Decrypt permissions to access them.\n\nTherefore, the correct answer is C. Attaching an inline policy with kms:Decrypt permissions to the IAM role will allow the application running on the EC2 instance to read the encrypted files from the S3 bucket.\n\nOption A is not ideal because editing the AWS managed ReadOnlyAccess policy is not possible. Option B is unnecessary because the S3 bucket policy already allows access. Option D is too broad and grants more permissions than needed, which is not a best practice for security.","comment_id":"1321958"},{"content":"Selected Answer: C\nC is correct.","comment_id":"1220563","poster":"aescudero51","timestamp":"1716935520.0","upvote_count":"2"},{"upvote_count":"2","timestamp":"1716484560.0","content":"Selected Answer: C\nC is correct, ReadOnlyAccess is a administer policy by AWS, can't edit.","comment_id":"1216794","poster":"fibonacciname"},{"timestamp":"1716484440.0","comment_id":"1216788","content":"Selected Answer: B\nB es correct, ReadOnlyAccess is a administer policy by AWS, can't edit.","upvote_count":"1","poster":"fibonacciname","comments":[{"upvote_count":"1","comment_id":"1216792","content":"is wrong, the answer is C","timestamp":"1716484500.0","poster":"fibonacciname"}]},{"timestamp":"1716144720.0","poster":"Certified101","upvote_count":"1","content":"Selected Answer: C\nC is correct, cant edit an AWS managed policy. Need to create a new inline policy","comment_id":"1213942"},{"comment_id":"1213717","content":"C\nA. Edit ReadOnlyAccess Policy: Modifying the ReadOnlyAccess policy to include kms:Decrypt actions would grant these permissions to any role or user attached to that policy. This might be more permissive than necessary and could introduce security risks if the policy is used elsewhere.\nB. Add Role to S3 Bucket Policy: While adding the EC2 instance profile role to the S3 bucket policy would allow access, it bypasses IAM role-based access control and couples the policy directly to the instance role. This approach is less flexible and doesn't leverage the benefits of IAM roles for managing access.\nD. Attach Policy with S3: Permissions:* Granting S3:* permissions through an inline policy would provide excessive access to the application. It's essential to follow the principle of least privilege and only grant the necessary kms:Decrypt permissions for the specific KMS key used for encryption.","poster":"Nash101","timestamp":"1716114480.0","upvote_count":"1"}],"answer_ET":"C","isMC":true,"answer_description":"","question_text":"A developer operations team uses AWS Identity and Access Management (IAM) to manage user permissions. The team created an Amazon EC2 instance profile role that uses an AWS managed ReadOnlyAccess policy. When an application that is running on Amazon EC2 tries to read a file from an encrypted Amazon S3 bucket, the application receives an AccessDenied error.\n\nThe team administrator has verified that the S3 bucket policy allows everyone in the account to access the S3 bucket. There is no object ACL that is attached to the file.\n\nWhat should the administrator do to fix the IAM access issue?"},{"id":"mALks8tlgD4BiQkstLgu","answer_images":[],"timestamp":"2024-05-13 21:48:00","discussion":[{"timestamp":"1732049760.0","poster":"Certified101","upvote_count":"4","comment_id":"1213943","content":"Selected Answer: B\nThe correct answer is B. The security engineer should enable Kubernetes API server component logs for each cluster. This is because the API server component logs contain details about the Kubernetes events such as pod creation, which are not included in the AWS CloudTrail logs. Once these logs are enabled, they can be viewed from Amazon CloudWatch."},{"comment_id":"1211050","timestamp":"1731534480.0","content":"Will go with B\n\nhttps://www.examtopics.com/discussions/amazon/view/88358-exam-aws-certified-security-specialty-topic-1-question-405/","poster":"Zek","upvote_count":"4"}],"answers_community":["B (100%)"],"answer_ET":"B","answer":"B","unix_timestamp":1715629680,"isMC":true,"question_text":"A company uses AWS Organizations and has Amazon Elastic Kubernetes Service (Amazon EKS) clusters in many AWS accounts. A security engineer integrates Amazon EKS with AWS CloudTrail. The CloudTrail trails are stored in an Amazon S3 bucket in each account to monitor API calls. The security engineer observes that CloudTrail logs are not displaying Kubernetes pod creation events.\n\nWhat should the security engineer do to view the Kubernetes events from Amazon CloudWatch?","url":"https://www.examtopics.com/discussions/amazon/view/140591-exam-aws-certified-security-specialty-scs-c02-topic-1/","answer_description":"","choices":{"B":"Enable Kubernetes API server component logs for each cluster.","C":"Enable cross-origin resource sharing (CORS) in the S3 bucket that is used for logging.","D":"Configure CloudWatch. View the events in the CloudWatch console.","A":"Configure the EKS clusters to use private S3 VPC endpoints. Configure the S3 buckets for logging."},"topic":"1","question_images":[],"exam_id":30,"question_id":53},{"id":"5FBO4aLbjMLoQZeh0tC8","question_text":"A security engineer needs to build a solution to turn AWS CloudTrail back on in multiple AWS Regions in case it is ever turned off.\n\nWhat is the MOST efficient way to implement this solution?","unix_timestamp":1716145020,"exam_id":30,"question_images":[],"topic":"1","answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/140876-exam-aws-certified-security-specialty-scs-c02-topic-1/","isMC":true,"choices":{"D":"Monitor AWS Trusted Advisor to ensure CloudTrail logging is enabled.","A":"Use AWS Config with a managed rule to initiate the AWS-EnableCloudTrail remediation.","C":"Create an Amazon CloudWatch alarm with a cloudtrail.amazonaws.com event source and a StopLoggmg event name to invoke an AWS Lambda function to call the StartLogging API.","B":"Create an Amazon EventBridge event with a cloudtrail.amazonaws.com event source and a StartLogging event name to invoke an AWS Lambda function to call the StartLogging\nAPI."},"question_id":54,"discussion":[{"poster":"Certified101","timestamp":"1716150720.0","comment_id":"1213983","upvote_count":"6","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automatically-re-enable-aws-cloudtrail-by-using-a-custom-remediation-rule-in-aws-config.html"},{"comment_id":"1273049","poster":"PegasusForever","timestamp":"1724712900.0","content":"Selected Answer: C\nAWS-EnableCloudTrail -> Create an AWS CloudTrail trail and configure logging to an S3 bucket not re-enabled for that we require an AWS Config Custom Rule, not listed.\n\nMOST Efficient C. Create an Amazon CloudWatch alarm with a cloudtrail.amazonaws.com event source and a StopLoggmg event name to invoke an AWS Lambda function to call the StartLogging API.\n\nB is wrong.","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\nTo efficiently turn AWS CloudTrail back on in multiple AWS Regions if it is ever turned off, the best approach is to use AWS Config with a managed rule to automatically remediate the situation.","comment_id":"1259101","timestamp":"1722460020.0","poster":"xTrayusx"},{"upvote_count":"1","poster":"navid1365","comment_id":"1257765","timestamp":"1722301200.0","content":"Selected Answer: A\nThe \"most efficient\" solution is A."},{"poster":"Certified101","upvote_count":"2","content":"Selected Answer: A\nThe correct answer is A. The most efficient way to implement this solution is to use AWS Config with a managed rule to initiate the AWS-EnableCloudTrail remediation. This will automatically turn AWS CloudTrail back on if it is ever turned off.","comment_id":"1213944","timestamp":"1716145020.0"}],"answers_community":["A (100%)"],"answer_ET":"A","timestamp":"2024-05-19 20:57:00","answer":"A"},{"id":"VRi4c1PyUiJ4LWv9kvFQ","choices":{"B":"Create a public Application Load Balancer. Create two listeners one listener on port 80 and one listener on port 443. Create one target group. Create a rule to forward traffic from port 80 to the listener on port 443. Provision a public TLS certificate in AWS Certificate Manager (ACM). Attach the certificate to the listener on port 80.","A":"Create a public Application Load Balancer. Create two listeners: one listener on port 80 and one listener on port 443. Create one target group. Create a rule to forward traffic from port 80 to the listener on port 443. Provision a public TLS certificate in AWS Certificate Manager (ACM). Attach the certificate to the listener on port 443.","D":"Create a public Network Load Balancer. Create a listener on port 443. Create one target group. Create a rule to forward traffic from port 443 to the target group. Set the protocol for the listener on port 443 to TLS.","C":"Create a public Network Load Balancer. Create two listeners one listener on port 80 and one listener on port 443. Create one target group. Create a rule to forward traffic from port 80 to the listener on port 443. Set the protocol for the listener on port 443 to TLS."},"question_id":55,"unix_timestamp":1716145140,"question_images":[],"exam_id":30,"answer":"A","topic":"1","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/140877-exam-aws-certified-security-specialty-scs-c02-topic-1/","answer_images":[],"timestamp":"2024-05-19 20:59:00","discussion":[{"comment_id":"1213946","content":"Selected Answer: A\nThe correct answer is A. The security engineer should create a public Application Load Balancer, create two listeners (one on port 80 and one on port 443), create one target group, and create a rule to forward traffic from port 80 to the listener on port 443. Then, they should provision a public TLS certificate in AWS Certificate Manager (ACM) and attach the certificate to the listener on port 443. This setup will implement TLS for incoming traffic to the application, without requiring an end-to-end configuration.","poster":"Certified101","timestamp":"1732049940.0","upvote_count":"8"}],"answer_ET":"A","isMC":true,"answer_description":"","question_text":"An ecommerce company is developing new architecture for an application release. The company needs to implement TLS for incoming traffic to the application. Traffic for the application will originate from the internet. TLS does not have to be implemented in an end-to-end configuration because the company is concerned about impacts on performance The incoming traffic types will be HTTP and HTTPS The application uses ports 80 and 443.\n\nWhat should a security engineer do to meet these requirements?"}],"exam":{"isMCOnly":true,"numberOfQuestions":288,"provider":"Amazon","lastUpdated":"11 Apr 2025","id":30,"isBeta":false,"name":"AWS Certified Security - Specialty SCS-C02","isImplemented":true},"currentPage":11},"__N_SSP":true}