{"pageProps":{"questions":[{"id":"Rp26qaHMuzWWwKMv15KF","answer_description":"","exam_id":24,"answers_community":["C (86%)","14%"],"question_text":"A developer is building an event-driven application by using AWS Lambda and Amazon EventBridge. The Lambda function needs to push events to an EventBridge event bus. The developer uses an SDK to run the PutEvents EventBridge action and specifies no credentials in the code. After deploying the Lambda function, the developer notices that the function is failing and there are AccessDeniedException errors in the logs.\n\nHow should the developer resolve this issue?","url":"https://www.examtopics.com/discussions/amazon/view/136958-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_id":261,"answer_images":[],"isMC":true,"discussion":[{"content":"Selected Answer: C\nCorrect Answer:\nC. Modify the Lambda function execution role to include permissions for the PutEvents EventBridge action.\n\nThe developer should update the Lambda function's execution role to include the necessary permissions for the PutEvents action on the EventBridge event bus. This will resolve the AccessDeniedException errors and allow the Lambda function to push events to EventBridge.","poster":"examuserss","comment_id":"1331150","timestamp":"1735050720.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nC is the correct answer.","timestamp":"1716584040.0","comment_id":"1217818","poster":"65703c1"},{"comment_id":"1193820","timestamp":"1712840880.0","poster":"be1dca8","content":"C\nyou use IAM roles on the sender event bus to give the sender event bus permission to send events to the receiver event bus. You use Resource-based policies on the receiver event bus to give the receiver event bus permission to receive events from the sender event bus.\n\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-bus-to-bus.html","upvote_count":"3","comments":[{"timestamp":"1722055740.0","poster":"albert_kuo","comment_id":"1256016","upvote_count":"1","content":"{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n {\n \"Effect\": \"Allow\",\n \"Action\": \"events:PutEvents\",\n \"Resource\": \"*\"\n }\n ]\n}"}]},{"timestamp":"1711451100.0","upvote_count":"2","content":"Selected Answer: C\nAs lambda is initiating the action (push), permission must be attached the the execution role.","poster":"DeaconStJohn","comment_id":"1183237"},{"content":"Selected Answer: C\nLambda Execution Role (IAM Role)\nâ€¢ Grants the Lambda function permissions to AWS services / resources","poster":"outrageous7","comment_id":"1181783","timestamp":"1711294200.0","upvote_count":"2"},{"comment_id":"1180473","timestamp":"1711161240.0","upvote_count":"1","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-bus-perms.html","poster":"KarBiswa"}],"answer_ET":"C","unix_timestamp":1711161240,"choices":{"D":"Add a resource-based policy to the Lambda function to include permissions for the PutEvents EventBridge action.","A":"Configure a VPC peering connection between the Lambda function and EventBridge.","B":"Modify their AWS credentials to include permissions for the PutEvents EventBridge action.","C":"Modify the Lambda function execution role to include permissions for the PutEvents EventBridge action."},"question_images":[],"answer":"C","topic":"1","timestamp":"2024-03-23 03:34:00"},{"id":"pPLhbC3AignwIO5hLwK8","timestamp":"2024-03-19 15:05:00","unix_timestamp":1710857100,"question_id":262,"topic":"1","isMC":true,"answer":"C","question_text":"A company's application has an AWS Lambda function that processes messages from IoT devices. The company wants to monitor the Lambda function to ensure that the Lambda function is meeting its required service level agreement (SLA).\n\nA developer must implement a solution to determine the application's throughput in near real time. The throughput must be based on the number of messages that the Lambda function receives and processes in a given time period. The Lambda function performs initialization and post-processing steps that must not factor into the throughput measurement.\n\nWhat should the developer do to meet these requirements?","answer_images":[],"question_images":[],"discussion":[{"poster":"Alagong","timestamp":"1711348860.0","content":"Selected Answer: C\nUse the metrics to calculate the throughput. This is because custom metrics can provide a more accurate measure of throughput, as they can be configured to only increment when a message is received and processed by the Lambda function. This would exclude the time spent on initialization and post-processing, which are not part of the throughput measurement.","comment_id":"1182260","upvote_count":"5"},{"content":"Selected Answer: C\nCorrect Answer:\nC. Modify the application to publish custom Amazon CloudWatch metrics when the Lambda function receives and processes each message. Use the metrics to calculate the throughput.\n\nThis solution allows the developer to focus on the specific parts of the Lambda function that are responsible for processing messages, providing the most accurate and real-time measurement of throughput. By publishing custom metrics, the developer can ensure the throughput is tracked exactly as required, excluding any irrelevant steps.","poster":"examuserss","upvote_count":"1","timestamp":"1735050840.0","comment_id":"1331151"},{"poster":"albert_kuo","upvote_count":"1","content":"Selected Answer: C\nimport boto3\nimport time\n\ncloudwatch = boto3.client('cloudwatch')\n\ndef lambda_handler(event, context):\n # Process the IoT message\n process_message(event)\n \n # Publish custom CloudWatch metric for throughput\n cloudwatch.put_metric_data(\n Namespace='IoTMessageProcessing',\n MetricData=[\n {\n 'MetricName': 'MessagesProcessed',\n 'Timestamp': time.time(),\n 'Value': 1,\n 'Unit': 'Count'\n },\n ]\n )","comment_id":"1292634","timestamp":"1727930220.0"},{"comment_id":"1217820","content":"Selected Answer: C\nC is the correct answer.","timestamp":"1716584400.0","poster":"65703c1","upvote_count":"1"},{"poster":"trungtd","content":"Selected Answer: C\nBecause this requirement provides its own definition of how throughput is measured, you must use custom metrics.","upvote_count":"2","timestamp":"1712291040.0","comment_id":"1189648"},{"content":"Selected Answer: C\nI think C","upvote_count":"2","poster":"seetpt","comment_id":"1185651","timestamp":"1711742640.0"},{"poster":"KarBiswa","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/compute/understanding-aws-lambda-scaling-and-throughput/","timestamp":"1710857100.0","comment_id":"1177391","upvote_count":"2"}],"answers_community":["C (86%)","14%"],"url":"https://www.examtopics.com/discussions/amazon/view/136640-exam-aws-certified-developer-associate-dva-c02-topic-1/","exam_id":24,"choices":{"D":"Use the Lambda function's Invocations metric and Duration metric to calculate the throughput in Amazon CloudWatch.","A":"Use the Lambda function's ConcurrentExecutions metric in Amazon CloudWatch to measure the throughput.","B":"Modify the application to log the calculated throughput to Amazon CloudWatch Logs. Use Amazon EventBridge to invoke a separate Lambda function to process the logs on a schedule.","C":"Modify the application to publish custom Amazon CloudWatch metrics when the Lambda function receives and processes each message. Use the metrics to calculate the throughput."},"answer_ET":"C","answer_description":""},{"id":"uB7Pl3xy5iGHuunTiTv7","answer":"D","choices":{"A":"Create an Amazon S3 bucket to store the dependency .jar file. Publish the dependency .jar file to the S3 bucket. Use an Amazon Simple Notification Service (Amazon SNS) notification to start a CodePipeline pipeline build.","C":"Create an Amazon Elastic Container Registry (Amazon ECR) private repository. Publish the dependency .jar file to the repository. Use an Amazon Simple Notification Service (Amazon SNS) notification to start a CodePipeline pipeline build.","D":"Create an AWS CodeArtifact repository. Publish the dependency .jar file to the repository. Use an Amazon EventBridge rule to start a CodePipeline pipeline build.","B":"Create an Amazon Elastic Container Registry (Amazon ECR) private repository. Publish the dependency .jar file to the repository. Use an ECR source action to start a CodePipeline pipeline build."},"url":"https://www.examtopics.com/discussions/amazon/view/136644-exam-aws-certified-developer-associate-dva-c02-topic-1/","isMC":true,"answer_ET":"D","answer_description":"","answer_images":[],"answers_community":["D (100%)"],"topic":"1","question_id":263,"unix_timestamp":1710858060,"question_images":[],"exam_id":24,"discussion":[{"poster":"Anandesh","comment_id":"1252096","timestamp":"1721523240.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/codeartifact/latest/ug/configure-service-events-codepipeline.html","upvote_count":"1"},{"comment_id":"1232545","timestamp":"1718731140.0","upvote_count":"1","poster":"Alabi","content":"Selected Answer: D\nD is correct\nKeyword for using CodeArtifact is Dependency"},{"upvote_count":"1","timestamp":"1716584520.0","content":"Selected Answer: D\nD is the correct answer.","poster":"65703c1","comment_id":"1217822"},{"content":"Selected Answer: D\nAWS CodeArtifact is a managed artifact repository service that lets you securely store, publish, and share software packages.","upvote_count":"3","poster":"trungtd","comment_id":"1189651","timestamp":"1712291340.0"},{"timestamp":"1710858060.0","upvote_count":"3","comment_id":"1177406","poster":"KarBiswa","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/codeartifact/latest/ug/configure-service-events-codepipeline.html#configure-service-events-codepipeline-create-rule"}],"timestamp":"2024-03-19 15:21:00","question_text":"A developer is using an AWS CodePipeline pipeline to provide continuous integration and continuous delivery (CI/CD) support for a Java application. The developer needs to update the pipeline to support the introduction of a new application dependency .jar file. The pipeline must start a build when a new version of the .jar file becomes available.\n\nWhich solution will meet these requirements?"},{"id":"ca9Lk5jgCOw2F2ObJNtQ","question_images":[],"discussion":[{"poster":"examuserss","content":"Selected Answer: D\nCorrect Answer:\nD. Create an Amazon EventBridge scheduled rule that invokes the Lambda function once each day at the predefined time.\n\nThis solution allows you to trigger the Lambda function at the desired time each day without unnecessary compute usage and cost. EventBridge is ideal for time-based scheduling and provides a low-cost, highly efficient way to run tasks on a predefined schedule.","upvote_count":"1","timestamp":"1735051560.0","comment_id":"1331157"},{"upvote_count":"2","poster":"65703c1","comment_id":"1217823","timestamp":"1716584640.0","content":"Selected Answer: D\nD is the correct answer."},{"comment_id":"1189655","content":"Selected Answer: D\nBest practice for cronjob in Lamda","timestamp":"1712291940.0","upvote_count":"3","poster":"trungtd"},{"upvote_count":"2","timestamp":"1711831860.0","content":"Selected Answer: D\nD is right","comment_id":"1186372","poster":"seetpt"},{"content":"Selected Answer: D\nA - This does not meet the criteria. it will trigger with every report upload which is multiple invocations. the requirement is a single invocation that analyses all reports at a predefined time. these invocations will be firing off all over the place as every report comes in.\nB - Step functions is over the top for this use case.\nC - lambda to run continuously...\nD - This is a single invocation that triggers the lambda function at a predefined time using CRON. Eventbridge was developed for this use case.","poster":"DeaconStJohn","comment_id":"1183242","timestamp":"1711451820.0","upvote_count":"4"},{"content":"Selected Answer: A\nLeast cost involved and simple","upvote_count":"2","comments":[{"poster":"albert_kuo","timestamp":"1722056400.0","content":"analyzes the reports from all branch offices in a single pass","upvote_count":"1","comment_id":"1256032"}],"timestamp":"1711161600.0","poster":"KarBiswa","comment_id":"1180477"}],"answer":"D","choices":{"C":"Configure the Lambda function to run continuously and to begin analysis only at the predefined time each day.","B":"Create an AWS Step Functions state machine that invokes the Lambda function once each day at the predefined time.","D":"Create an Amazon EventBridge scheduled rule that invokes the Lambda function once each day at the predefined time.","A":"Configure an S3 event notification to invoke the Lambda function when a branch office uploads a sales report."},"url":"https://www.examtopics.com/discussions/amazon/view/136959-exam-aws-certified-developer-associate-dva-c02-topic-1/","exam_id":24,"answer_description":"","question_id":264,"question_text":"A company with multiple branch locations has an analytics and reporting application. Each branch office pushes a sales report to a shared Amazon S3 bucket at a predefined time each day. The company has developed an AWS Lambda function that analyzes the reports from all branch offices in a single pass. The Lambda function stores the results in a database.\n\nThe company needs to start the analysis once each day at a specific time.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_images":[],"timestamp":"2024-03-23 03:40:00","answers_community":["D (86%)","14%"],"answer_ET":"D","isMC":true,"topic":"1","unix_timestamp":1711161600},{"id":"9gInWGJyHNxt5N6tvltw","discussion":[{"upvote_count":"5","timestamp":"1727342460.0","poster":"DeaconStJohn","content":"Selected Answer: C\nAsync allows DLQ to be created from lambda function\nSync requires DLQ to be created by SQS.","comment_id":"1183246"},{"comment_id":"1217829","content":"Selected Answer: C\nC is the correct answer.","timestamp":"1732490400.0","poster":"65703c1","upvote_count":"1"},{"comment_id":"1186374","content":"Selected Answer: C\nC is correct","upvote_count":"2","timestamp":"1727722320.0","poster":"seetpt"},{"upvote_count":"2","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-dlq","comment_id":"1180484","poster":"KarBiswa","timestamp":"1727052420.0"}],"unix_timestamp":1711162020,"choices":{"A":"Set up Amazon CloudWatch Logs log groups to filter and store the messages in an Amazon S3 bucket. Import the messages in Lambda. Run the Lambda function again.","D":"Send Amazon EventBridge events to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda function to pull messages from the SQS queue. Run the Lambda function again.","C":"Implement a dead-letter queue for discarded messages. Set the dead-letter queue as an event source for the Lambda function.","B":"Configure Amazon EventBridge to send the messages to Amazon Simple Notification Service (Amazon SNS) to initiate the Lambda function again."},"topic":"1","question_images":[],"timestamp":"2024-03-23 03:47:00","question_id":265,"answer":"C","answer_images":[],"answer_description":"","question_text":"A developer has an application that asynchronously invokes an AWS Lambda function. The developer wants to store messages that resulted in failed invocations of the Lambda function so that the application can retry the call later.\n\nWhat should the developer do to accomplish this goal with the LEAST operational overhead?","url":"https://www.examtopics.com/discussions/amazon/view/136961-exam-aws-certified-developer-associate-dva-c02-topic-1/","answers_community":["C (100%)"],"exam_id":24,"isMC":true,"answer_ET":"C"}],"exam":{"isMCOnly":true,"lastUpdated":"11 Apr 2025","provider":"Amazon","isBeta":false,"numberOfQuestions":551,"name":"AWS Certified Developer - Associate DVA-C02","isImplemented":true,"id":24},"currentPage":53},"__N_SSP":true}