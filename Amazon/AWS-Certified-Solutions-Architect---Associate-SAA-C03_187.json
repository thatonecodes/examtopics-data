{"pageProps":{"questions":[{"id":"Dk3F5uvtPM7tu9GJlV50","answers_community":["A (88%)","13%"],"discussion":[{"poster":"FlyingHawk","comment_id":"1341286","timestamp":"1736986560.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/sql-server-ec2-best-practices/striping.html","comments":[{"comment_id":"1341287","poster":"FlyingHawk","timestamp":"1736986860.0","upvote_count":"1","content":"When the performance requirement cannot be met by a single EBS volume, consider striping using Logical Volume Management (LVM). For example, if a single volume has 250 MiB/s throughput capacity, having a stripe set across four volumes can deliver 1000 MiB/s throughput.\n\nVolumes should be of the same size and performance characteristics.\nhttps://docs.aws.amazon.com/wellarchitected/latest/sap-lens/best-practice-14-2.html"}],"upvote_count":"1"},{"comment_id":"1335968","poster":"LeonSauveterre","upvote_count":"2","timestamp":"1735896900.0","content":"Selected Answer: A\nA - For example, given two io1 volumes, each provisioned with 64,000 IOPS, would provide a combined 128,000 IOPS.\nB - The maximum IOPS for an io1 volume is capped at 64,000 IOPS when attached to an EC2 instance.\nC - While increasing the size of the volume increases baseline throughput (3 IOPS per GB), it wonâ€™t exceed the 64,000 IOPS limit.\nD - Storage optimized instances (like i3 or i4i) use instance store volumes, which are ephemeral (non-persistent) and cannot be used as a replacement for durable EBS volumes in this use case.\n\nWhat is the deal with LVM striping?\nLVM striping allows multiple volumes to be treated as a single logical volume. Reads and writes are distributed across the striped volumes, effectively increasing the available IOPS and throughput beyond the single-volume limits."},{"comment_id":"1330812","poster":"JA2018","content":"Selected Answer: B\nwhy I would choose Option B:\n\n- Issue:\nThe problem is that the current IOPS (Input/Output Operations Per Second) provisioned on the EBS volume are not sufficient to meet the database workload demands, leading to slower performance compared to the on-premises setup.\n\n- Solution:\nSince the bottleneck is clearly identified as inadequate IOPS, the most effective solution is to simply increase the provisioned IOPS on the existing EBS volume, allowing for faster data read/write operations.","timestamp":"1734958620.0","upvote_count":"1"},{"comment_id":"1300288","timestamp":"1729401300.0","poster":"jingen11","upvote_count":"2","content":"Selected Answer: A\nA"},{"content":"Selected Answer: A\nIncrease the Provisioned IOPS SSD (io1) EBS volume to more than 64,000 IOPS.","comment_id":"1279061","timestamp":"1725554160.0","upvote_count":"2","poster":"elmyth"},{"poster":"pujithacg8","upvote_count":"4","content":"A is correct, The maximum provisioned IOPS for io1 is 64000 and hence you can achieve higher aggregate performance by adding more io1 volumes","timestamp":"1723307280.0","comment_id":"1263578"}],"timestamp":"2024-08-10 18:28:00","isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/145414-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"B":"Increase the Provisioned IOPS SSD (io1) EBS volume to more than 64,000 IOPS.","A":"Add more Provisioned IOPS SSD (io1) EBS volumes. Use OS commands to create a Logical Volume Management (LVM) stripe.","C":"Increase the size of the Provisioned IOPS SSD (io1) EBS volume to 2 TB.","D":"Change the EC2 Linux instance to a storage optimized instance type. Do not change the Provisioned IOPS SSD (io1) EBS volume."},"question_text":"A company recently performed a lift and shift migration of its on-premises Oracle database workload to run on an Amazon EC2 memory optimized Linux instance. The EC2 Linux instance uses a 1 TB Provisioned IOPS SSD (io1) EBS volume with 64,000 IOPS.\n\nThe database storage performance after the migration is slower than the performance of the on-premises database.\n\nWhich solution will improve storage performance?","answer_images":[],"question_id":931,"exam_id":31,"answer_ET":"A","unix_timestamp":1723307280,"question_images":[],"answer_description":"","answer":"A"},{"id":"vq72UFyMHYMp7desNvSb","exam_id":31,"unix_timestamp":1666176720,"url":"https://www.examtopics.com/discussions/amazon/view/85903-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"timestamp":"1666176720.0","upvote_count":"5","content":"Selected Answer: AC\nOptions A and C.\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-private-connection-no-authentication/","comment_id":"698937","poster":"ArielSchivo"},{"poster":"awsgeek75","content":"Selected Answer: AC\nA: VPC S3 gateway for direct connection (no public internet) to access S3\nC: Bucket policy to secure access and only allow the VPC application tier to access it\n\nB: Opens up to public\nD: Not secure to copy credentials\nE: NAT instance (obsolete now) is not useful for limiting resource access, it's for subnet connections","upvote_count":"5","timestamp":"1705269060.0","comment_id":"1122891"},{"poster":"satyaammm","comment_id":"1336750","upvote_count":"1","timestamp":"1736080500.0","content":"Selected Answer: AC\nVPC Gateway endpoint provides secure access to S3 and DynamoDB while the bucket policy allows access only to the application tier making it a secure connection."},{"comment_id":"1284150","content":"Selected Answer: AD\nA,D - altho' I stand corrected: D means copying credentials which introduces a security risk... so that means A,C","timestamp":"1726406760.0","upvote_count":"1","poster":"PaulGa"},{"poster":"jaradat02","content":"Selected Answer: AC\nA removes the need for a NAT gateway and keeps the connection private, C restricts access to the bucket.","timestamp":"1721575440.0","upvote_count":"3","comment_id":"1252524"},{"content":"no one mentioned the translation issue, \"limit access to sth\" sounds like limit this but allow others, confusing for non-English speaker.","upvote_count":"3","comment_id":"1099471","timestamp":"1702883520.0","poster":"rityoui"},{"comment_id":"1056625","timestamp":"1698562200.0","poster":"Ruffyit","upvote_count":"2","content":") Configure a VPC gateway endpoint for Amazon S3 within the VPC.\n\nC) Create a bucket policy that limits access to only the application tier running in the VPC.\n\nThe key requirements are secure access to the S3 bucket from EC2 instances in the VPC.\n\nA VPC endpoint for S3 allows connectivity from the VPC to S3 without needing internet access. The bucket policy should limit access only to the VPC by whitelisting the VPC endpoint."},{"poster":"David_Ang","upvote_count":"4","timestamp":"1696609860.0","content":"Selected Answer: AC\nThese are correct because \"A\" and \"C\" ensure secure access and secure connectivity between the S3 and the EC2 instances","comment_id":"1026804"},{"poster":"Guru4Cloud","comment_id":"981012","timestamp":"1692035940.0","content":"Selected Answer: AC\nThe key requirements are to provide secure access to the S3 bucket only from the application tier EC2 instances inside the VPC.\n\nA VPC gateway endpoint allows private access to S3 from within the VPC without needing internet access. This keeps the traffic secure within the AWS network.\n\nThe bucket policy should limit access to only the application tier, not make the objects public. This restricts access to the sensitive data to only the authorized application tier.","upvote_count":"3"},{"timestamp":"1691764440.0","poster":"Guru4Cloud","comment_id":"978721","upvote_count":"3","content":"Selected Answer: AC\nThe correct options are:\n\nA) Configure a VPC gateway endpoint for Amazon S3 within the VPC.\n\nC) Create a bucket policy that limits access to only the application tier running in the VPC.\n\nThe key requirements are secure access to the S3 bucket from EC2 instances in the VPC.\n\nA VPC endpoint for S3 allows connectivity from the VPC to S3 without needing internet access. The bucket policy should limit access only to the VPC by whitelisting the VPC endpoint."},{"poster":"sohailn","content":"ac is the correct answer, as per my knowledge people are confused with IAM user we can use IAM role for secure access.","upvote_count":"2","comment_id":"978040","timestamp":"1691697120.0"},{"timestamp":"1688226660.0","comment_id":"940133","poster":"tamefi5512","upvote_count":"2","content":"Selected Answer: AC\nAC is the right answer"},{"comment_id":"930223","upvote_count":"3","poster":"cookieMr","content":"Selected Answer: AC\nA. This eliminates the need for the traffic to go over the internet, providing an added layer of security.\n\nB. It is important to restrict access to the bucket and its objects only to authorized entities.\n\nC. This helps maintain the confidentiality of the sensitive user information by limiting access to authorized resources.\n\nD. In this case, since the EC2 instances are accessing the S3 bucket from within the VPC, using IAM user credentials is unnecessary and can introduce additional security risks.\n\nE. a NAT instance to access the S3 bucket adds unnecessary complexity and overhead.\n\nIn summary, the recommended steps to provide secure access to the S3 from the application tier running on EC2 inside a VPC are to configure a VPC gateway endpoint for S3 within the VPC (option A) and create a bucket policy that limits access to only the application tier running in the VPC (option C).","timestamp":"1687416420.0"},{"comment_id":"903350","timestamp":"1684680900.0","poster":"Bmarodi","upvote_count":"2","content":"Selected Answer: AC\nA & C the correct solutions."},{"content":"Selected Answer: AC\nA and C","upvote_count":"1","timestamp":"1684058820.0","poster":"TillieEhaung","comment_id":"897458"},{"upvote_count":"1","poster":"annabellehiro","comment_id":"849967","content":"Selected Answer: AC\nA and C","timestamp":"1679737260.0"},{"content":"Selected Answer: AC\nThe key part that many miss out on is 'Combination' \nThe other answers are not wrong but \nA works with C and not with the rest as they need an internet connection.","comment_id":"814136","timestamp":"1676814660.0","poster":"Help2023","upvote_count":"3"},{"content":"Selected Answer: AC\nAC is correct","comment_id":"814119","timestamp":"1676813580.0","poster":"vherman","upvote_count":"1"},{"comment_id":"810000","poster":"bdp123","content":"Selected Answer: AC\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-private-connection-noauthentication/","timestamp":"1676496540.0","upvote_count":"2"},{"content":"Selected Answer: CD\nc & D for security. A addresses accessibility which is not a concern here imo","timestamp":"1673895480.0","comment_id":"778130","upvote_count":"2","comments":[{"content":"\"Copy the IAM credentials to the EC2 instance\" hell no","comment_id":"1105278","timestamp":"1703508420.0","poster":"pentium75","upvote_count":"2"}],"poster":"remand"},{"comment_id":"774636","timestamp":"1673625240.0","upvote_count":"3","poster":"goodmail","content":"Selected Answer: AC\nA & C. \nWhen the question is about security, do not select the answer that storing credential in EC2. This shall be done by using IAM policy + role or Secret Manager."},{"timestamp":"1672743000.0","poster":"mhmt4438","comments":[{"comment_id":"1105279","poster":"pentium75","timestamp":"1703508540.0","upvote_count":"2","content":"\"No traffic from the applications is allowed to travel across the internet\" which is exactly what an S3 Gateway Endpoint (A) does."}],"upvote_count":"1","content":"C and D \nTo provide secure access to the S3 bucket from the application tier running on EC2 instances inside a VPC, you should create a bucket policy that limits access to only the application tier running in the VPC. This will ensure that only the application tier has access to the bucket and its contents.\n\nAdditionally, you should create an IAM user with an S3 access policy and copy the IAM credentials to the EC2 instance. This will allow the EC2 instance to access the S3 bucket using the IAM user's permissions.\n\nOption A, configuring a VPC gateway endpoint for Amazon S3 within the VPC, would not provide any additional security for the S3 bucket.\n\nOption B, creating a bucket policy to make the objects in the S3 bucket public, would not provide sufficient security for sensitive user information.\n\nOption E, creating a NAT instance and having the EC2 instances use the NAT instance to access the S3 bucket, would not provide any additional security for the S3 bucket","comment_id":"764465"},{"content":"Selected Answer: AC\nA and C is right among the choice. \nBut instead of having bucket policy for VPC access better option would be to create a role with specific S3 bucket access and attach that role EC2 instances that needs access to S3 buckets.","timestamp":"1672086840.0","poster":"career360guru","upvote_count":"4","comment_id":"757828"},{"upvote_count":"1","content":"Selected Answer: AC\nA & C looks correct","poster":"k1kavi1","comment_id":"754892","timestamp":"1671888120.0"},{"upvote_count":"3","content":"Selected Answer: CD\n***CORRECT***\nThe solutions architect should take the following steps to accomplish secure access to the S3 bucket from the application tier running on Amazon EC2 instances inside a VPC:\n\nC. Create a bucket policy that limits access to only the application tier running in the VPC.\nD. Create an IAM user with an S3 access policy and copy the IAM credentials to the EC2 instance.","comment_id":"752657","timestamp":"1671649260.0","comments":[{"timestamp":"1672181880.0","upvote_count":"8","content":"After reviewing thoroughly the AWS documentation and the other answers in the discussion, I am taking back my previous answer. The correct answer for me is Option A and Option C.\n\nTo provide secure access to the S3 bucket from the application tier running on Amazon EC2 instances inside the VPC, the solutions architect should take the following combination of steps:\n\n Option A: Configure a VPC gateway endpoint for Amazon S3 within the VPC.\n\nAmazon S3 VPC Endpoints: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-s3.html\n\nOption C: Create a bucket policy that limits access to only the application tier running in the VPC.\n\nAmazon S3 Bucket Policies: https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html\n\nAWS Identity and Access Management (IAM) Policies: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html","poster":"Buruguduystunstugudunstuy","comment_id":"759137"},{"poster":"Buruguduystunstugudunstuy","content":"***INCORRECT***\nOption C ensures that the S3 bucket is only accessible to the application tier running in the VPC, while Option D allows the EC2 instances to access the S3 bucket using the IAM credentials of the IAM user. This ensures that access to the S3 bucket is secure and controlled through IAM.\n\nOption A is incorrect because configuring a VPC gateway endpoint for Amazon S3 does not directly control access to the S3 bucket.\n\nOption B is incorrect because making the objects in the S3 bucket public would not provide secure access to the bucket.\n\nOption E is incorrect because creating a NAT instance is not necessary to provide secure access to the S3 bucket from the application tier running on EC2 instances in the VPC.","timestamp":"1671649320.0","upvote_count":"1","comment_id":"752659"}],"poster":"Buruguduystunstugudunstuy"},{"timestamp":"1669485060.0","poster":"DivaLight","upvote_count":"1","content":"Selected Answer: AC\nOption AC","comment_id":"727727"},{"upvote_count":"1","content":"A and C","timestamp":"1669049280.0","poster":"Wpcorgan","comment_id":"723759"},{"upvote_count":"1","content":"Selected Answer: AC\nAC is the correct answer in the use case","timestamp":"1668370740.0","comment_id":"717503","poster":"Jtic"},{"comment_id":"715621","poster":"rjam","upvote_count":"1","comments":[{"poster":"rjam","comment_id":"715623","upvote_count":"1","timestamp":"1668124020.0","content":"Typo it should be A and C"}],"content":"Options A and E","timestamp":"1668123900.0"}],"answer_description":"","question_id":932,"answer":"AC","answer_ET":"AC","question_text":"A company is storing sensitive user information in an Amazon S3 bucket. The company wants to provide secure access to this bucket from the application tier running on Amazon EC2 instances inside a VPC.\nWhich combination of steps should a solutions architect take to accomplish this? (Choose two.)","answers_community":["AC (89%)","9%"],"timestamp":"2022-10-19 12:52:00","choices":{"C":"Create a bucket policy that limits access to only the application tier running in the VPC.","D":"Create an IAM user with an S3 access policy and copy the IAM credentials to the EC2 instance.","A":"Configure a VPC gateway endpoint for Amazon S3 within the VPC.","E":"Create a NAT instance and have the EC2 instances use the NAT instance to access the S3 bucket.","B":"Create a bucket policy to make the objects in the S3 bucket public."},"answer_images":[],"isMC":true,"topic":"1","question_images":[]},{"id":"wH11wyR09v0kY1gA9FoI","timestamp":"2024-08-10 18:32:00","answer_images":[],"topic":"1","choices":{"D":"Configure an Amazon API Gateway HTTP API to invoke an AWS Lambda function that publishes events to an Amazon Simple Notification Service (Amazon SNS) topic. Configure one or more subscribers to receive events from the topic.","C":"Configure an Amazon API Gateway WebSocket API to write to a data stream in Amazon Kinesis Data Streams with enhanced fan-out. Configure one or more subscribers to receive events from the data stream.","A":"Configure an Amazon API Gateway REST API to invoke an AWS Lambda function that publishes events to an Amazon Simple Queue Service (Amazon SQS) queue. Configure one or more subscribers to read events from the SQS queue.","B":"Configure an Amazon API Gateway REST API to invoke an AWS Lambda function that publishes events to an Amazon Simple Notification Service (Amazon SNS) topic. Configure one or more subscribers to receive events from the SNS topic."},"answer":"D","unix_timestamp":1723307520,"exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/145415-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","answer_ET":"D","question_text":"A company is migrating from a monolithic architecture for a web application that is hosted on Amazon EC2 to a serverless microservices architecture. The company wants to use AWS services that support an event-driven, loosely coupled architecture. The company wants to use the publish/subscribe (pub/sub) pattern.\n\nWhich solution will meet these requirements MOST cost-effectively?","question_images":[],"discussion":[{"upvote_count":"1","content":"REST APIs and HTTP APIs are both RESTful API products. REST APIs support more features than HTTP APIs, while HTTP APIs are designed with minimal features so that they can be offered at a lower price. Choose REST APIs if you need features such as API keys, per-client throttling, request validation, AWS WAF integration, or private API endpoints. Choose HTTP APIs if you don't need the features included with REST APIs.","comment_id":"1363898","poster":"tch","timestamp":"1740910800.0"},{"timestamp":"1737829920.0","comment_id":"1346594","poster":"tomasmolinari","upvote_count":"2","content":"Selected Answer: D\n\"HTTP APIs enable you to create RESTful APIs with lower latency and lower cost than REST APIs.\" \nHTTP APIs are more cost-effective than REST APIs"},{"content":"Selected Answer: B\nAmazon SNS is perfectly designed to support the pub/sub pattern efficiently. So B or D.\nAbout option D: Using an HTTP API instead of a REST API is less common when using SNS for event publishing. Typically, REST APIs in API Gateway are used for interacting with Lambda functions, making option B a more conventional choice.\n\nThat said, scenarios vary based on your actual, detailed needs, like predicted frequencies and costs. For the SAA exam, I'll definitely go with B.","comment_id":"1335972","upvote_count":"1","timestamp":"1735897320.0","poster":"LeonSauveterre"},{"comment_id":"1335942","poster":"jfedotov","timestamp":"1735892520.0","upvote_count":"1","content":"Selected Answer: D\nHttp api"},{"comment_id":"1334030","content":"Selected Answer: B\nWhile the Amazon API Gateway HTTP API (Option D) can be more cost-effective for simple APIs with low data transfer and minimal feature requirements, the Amazon API Gateway REST API (Option B) may still be more cost-effective in many real-world scenarios, especially for more complex web applications with additional requirements.\n\nThe choice between Options B and D should be based on a careful evaluation of your specific requirements, existing infrastructure, and potential cost savings or trade-offs involved.","poster":"Denise123","upvote_count":"1","timestamp":"1735553640.0"},{"comment_id":"1326777","poster":"78b9037","timestamp":"1734257220.0","upvote_count":"2","content":"Selected Answer: D\nHTTP API is cheaper. The difference in pricing is steep. REST APIs will run you USD $3.50 per one million requests plus charges for data transferred out. By contrast, HTTP APIs cost a mere $1.00 per request for the first million requests and then $0.90 per million requests after that."},{"upvote_count":"2","timestamp":"1729401660.0","poster":"jingen11","content":"Selected Answer: D\nQuestion ask for cheapest.\nHttp api offers everything the requirements asked for. i.e Lambda function for serverless, event driven.","comment_id":"1300290"},{"timestamp":"1726282260.0","comment_id":"1283455","poster":"fis_examtopic","upvote_count":"1","content":"HTTP APIs with Lambda. I'm go with D"},{"content":"Selected Answer: B\nrest is cheaper than http","poster":"progounick","comments":[{"upvote_count":"3","poster":"Noveo","comment_id":"1278831","comments":[{"upvote_count":"1","content":"The Amazon API Gateway HTTP API is a more recent addition to API Gateway and is designed to be a more cost-effective option for simple APIs. However, it has fewer features and capabilities compared to the REST API.\nHere's a comparison of the costs between the two API Gateway options:\n-REST API: $3.50 per million API calls received, plus data transfer costs.\n-HTTP API: $0.90 per million API calls received, plus data transfer costs.\nAs you can see, the HTTP API is cheaper in terms of the API call pricing. However, the REST API may still be more cost-effective in certain scenarios. I am not sure what is needed in this question though.","comment_id":"1334033","timestamp":"1735553820.0","poster":"Denise123"},{"content":"based on this answer should be D","comment_id":"1310474","upvote_count":"1","poster":"mk168898","timestamp":"1731397260.0"}],"timestamp":"1725530760.0","content":"Quite the opposite: \"REST APIs support more features than HTTP APIs, while HTTP APIs are designed with minimal features so that they can be offered at a lower price.\""}],"comment_id":"1273413","timestamp":"1724759700.0","upvote_count":"1"},{"comment_id":"1270442","poster":"dhewa","upvote_count":"2","timestamp":"1724288220.0","content":"Selected Answer: B\nAn HTTP API instead might not be necessary for this use case."},{"comment_id":"1264766","poster":"muhammadahmer36","upvote_count":"2","timestamp":"1723488000.0","content":"Selected Answer: D\nD is the right answer"},{"upvote_count":"2","content":"B or D, Will go with B","comment_id":"1263579","timestamp":"1723307520.0","poster":"pujithacg8","comments":[{"timestamp":"1723487760.0","content":"Why B, not D?","comment_id":"1264762","poster":"muhammadahmer36","upvote_count":"1"}]}],"isMC":true,"answers_community":["D (64%)","B (36%)"],"question_id":933},{"id":"aPBrQwefEZV0U50McY1L","question_text":"A company recently migrated a monolithic application to an Amazon EC2 instance and Amazon RDS. The application has tightly coupled modules. The existing design of the application gives the application the ability to run on only a single EC2 instance.\n\nThe company has noticed high CPU utilization on the EC2 instance during peak usage times. The high CPU utilization corresponds to degraded performance on Amazon RDS for read requests. The company wants to reduce the high CPU utilization and improve read request performance.\n\nWhich solution will meet these requirements?","choices":{"D":"Resize the EC2 instance to an EC2 instance type that has more CPU capacity. Configure an Auto Scaling group with a minimum and maximum size of 1. Resize the RDS DB instance to an instance type that has more CPU capacity.","A":"Resize the EC2 instance to an EC2 instance type that has more CPU capacity. Configure an Auto Scaling group with a minimum and maximum size of 1. Configure an RDS read replica for read requests.","C":"Configure an Auto Scaling group with a minimum size of 1 and maximum size of 2. Resize the RDS DB instance to an instance type that has more CPU capacity.","B":"Resize the EC2 instance to an EC2 instance type that has more CPU capacity. Configure an Auto Scaling group with a minimum and maximum size of 1. Add an RDS read replica and redirect all read/write traffic to the replica."},"answer_ET":"A","discussion":[{"content":"Selected Answer: A\nOption \"A\", but... How does an auto scaling group with min = max = 1 instances contribute to the solution?","timestamp":"1739117460.0","comment_id":"1353993","upvote_count":"2","poster":"GOTJ"},{"timestamp":"1724279880.0","poster":"dhewa","content":"Selected Answer: A\nThis approach addresses both the high CPU utilization on the EC2 instance and the degraded read performance on the RDS instance effectively.","upvote_count":"2","comment_id":"1270409"},{"timestamp":"1723896780.0","comment_id":"1267694","upvote_count":"2","poster":"[Removed]","content":"Selected Answer: A\nA sounds right"},{"comment_id":"1263156","upvote_count":"2","content":"Selected Answer: A\nA is correct","timestamp":"1723222560.0","poster":"Abbas_Abi_AWS"},{"timestamp":"1723212960.0","upvote_count":"4","poster":"ltetti","content":"Selected Answer: A\nOption B incorrectly suggests redirecting all read/write traffic to the replica. RDS read replicas are designed to handle read operations only, not write operations. Writes must still be handled by the primary DB instance","comment_id":"1263073"}],"answer":"A","unix_timestamp":1723212960,"url":"https://www.examtopics.com/discussions/amazon/view/145343-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","isMC":true,"question_images":[],"answer_description":"","timestamp":"2024-08-09 16:16:00","answer_images":[],"answers_community":["A (100%)"],"question_id":934,"exam_id":31},{"id":"AsYDepnWVnCRsIoY6Oem","answer_images":[],"question_images":[],"discussion":[{"comments":[{"poster":"hpirnaj","content":"it says \" team of developers \" . they are not in the company's AWS account. how do you want to apply IAM roles without defining users ? I think C is the answer","comments":[{"content":"also, roles can not assign to user/group . you need to make a policy from IAM roles first then assign policies to user/group","timestamp":"1736359980.0","upvote_count":"1","poster":"hpirnaj","comment_id":"1338044"}],"upvote_count":"1","timestamp":"1736248320.0","comment_id":"1337528"}],"upvote_count":"1","timestamp":"1735968120.0","content":"Selected Answer: B\nA - Sharing IAM user credentials is a security risk and violates AWS best practices.\nB - IAM roles allow for temporary credentials that can be automatically rotated, and that improves security.\nC - Would work but managing static keys for multiple developers introduces significant operational overhead.\nD - AWS Cognito is primarily designed for managing end-user authentication (for web or mobile apps or such), not for managing access to AWS resources for developers.","poster":"LeonSauveterre","comment_id":"1336268"},{"timestamp":"1735144740.0","poster":"KennethYY","comment_id":"1331639","upvote_count":"1","content":"Selected Answer: D\nA is wrong, common sense not security\nB is wrong, role cannot assign to user/group\nD is wrong, is designed for authentication and access control for web or mobile app users, not for internal developers accessing AWS resources.\nso remain C."},{"comment_id":"1331325","poster":"EllenLiu","upvote_count":"1","timestamp":"1735094880.0","content":"Selected Answer: B\nAWS Cognito is designed for authentication and access control for web or mobile app users, not for internal developers accessing AWS resources."},{"poster":"EllenLiu","timestamp":"1735095420.0","comment_id":"1331326","content":"Sorry, go with B.","upvote_count":"1"},{"timestamp":"1732776420.0","comment_id":"1319058","upvote_count":"2","content":"Selected Answer: B\ngood practice should B. but map role to Identity center federated to corporate IDP.","poster":"Cpso"},{"poster":"Bwhizzy","upvote_count":"2","comment_id":"1296570","content":"Selected Answer: B\nB is the right answer. IAM Role","timestamp":"1728745680.0"},{"poster":"[Removed]","content":"B sounds right","upvote_count":"3","comment_id":"1267698","timestamp":"1723896960.0"},{"content":"Selected Answer: B\nAnswer is B","timestamp":"1723587000.0","poster":"aragon_saa","upvote_count":"3","comment_id":"1265402"},{"upvote_count":"1","poster":"muhammadahmer36","timestamp":"1723570860.0","content":"Create an AWS Cognito user pool. Grant developers access to AWS resources by using the user pool.","comments":[{"content":"cognito for app user auth, qns asking for access to AWS resource. your answer is wrong","upvote_count":"2","poster":"mk168898","timestamp":"1731399660.0","comment_id":"1310489"}],"comment_id":"1265272"}],"isMC":true,"choices":{"B":"Define IAM roles that have fine-grained permissions based on the principle of least privilege. Assign an IAM role to each developer.","A":"Share the IAM user credentials for each development team member with the rest of the team to simplify access management and to streamline development workflows.","C":"Create IAM access keys to grant programmatic access to AWS resources. Allow only developers to interact with AWS resources through API calls by using the access keys.","D":"Create an AWS Cognito user pool. Grant developers access to AWS resources by using the user pool."},"unix_timestamp":1723570860,"answer_ET":"B","answers_community":["B (82%)","Other"],"url":"https://www.examtopics.com/discussions/amazon/view/145676-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"B","question_id":935,"question_text":"A company needs to grant a team of developers access to the company's AWS resources. The company must maintain a high level of security for the resources.\n\nThe company requires an access control solution that will prevent unauthorized access to the sensitive data.\n\nWhich solution will meet these requirements?","timestamp":"2024-08-13 19:41:00","topic":"1","exam_id":31,"answer_description":""}],"exam":{"id":31,"lastUpdated":"11 Apr 2025","isMCOnly":true,"provider":"Amazon","isImplemented":true,"isBeta":false,"numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":187},"__N_SSP":true}