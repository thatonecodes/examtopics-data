{"pageProps":{"questions":[{"id":"fXOgKD01fsj7GzFkXhOm","topic":"1","discussion":[{"content":"Selected Answer: D\nMy PoV is that D requires LEAST amount of effort from the internal team.\nThe blog post (https://aws.amazon.com/blogs/machine-learning/identify-rooftop-solar-panels-from-satellite-imagery-using-amazon-rekognition-custom-labels/) does not mention that the effort would be huge, to label 8k images even with Ground Truth active learning. Far more than the effort of using SageMaker Object Detection algorithm and SageMaker batch transform.\nConsidering the fact that the internal team has no ML expertise and no ML experience, they need to do some configuration, learn key concepts (e.g., preparing data in the correct format, specifying hyperparameters), and follow AWS documentation and industrial best practices for training and inference...","comments":[{"timestamp":"1735042800.0","content":"Now, everyone is learning on the job, no ML expertise and no ML experience only means they have a poor start point. Study Rekognition Custom Labels sounds a little bit easier than leaning SageMaker Object Detection algorithm and SageMaker batch transform. But because SageMaker and its features are AWS managed and out-of-box, the operational overhead is acceptable. And because Object Detection algorithm is a SageMaker built-in algorithm, the related effort is also not big.\nSo to sum up, comparing the effort to label 8k images even with Ground Truth active learning, the effort of using SageMaker Object Detection algorithm and SageMaker batch transform is expected to be less, IMHO.","comment_id":"1331107","upvote_count":"1","poster":"LeoD"}],"upvote_count":"1","comment_id":"1331106","timestamp":"1735042680.0","poster":"LeoD"},{"timestamp":"1719080160.0","upvote_count":"2","comment_id":"1235544","poster":"pandkast","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/machine-learning/identify-rooftop-solar-panels-from-satellite-imagery-using-amazon-rekognition-custom-labels/"},{"content":"Selected Answer: A\nLeast effort + no ML experience, so A","comment_id":"1082980","timestamp":"1701209340.0","poster":"endeesa","upvote_count":"1"},{"poster":"loict","content":"Selected Answer: A\nA. YES - Amazon Rekognition Custom Labels is better than other option like Face/Celebrity/etc.; Ground Truth Active Learning will require human labelling only when needed, works well with small internal team\nB. NO - missing Active Learning\nC. NO - SageMaker Object Detection is more complicated than labelling\nD. NO","upvote_count":"2","comment_id":"1005830","timestamp":"1694527380.0"},{"upvote_count":"1","content":"Selected Answer: A\nVote for A","comment_id":"993069","poster":"Mickey321","timestamp":"1693312380.0"},{"upvote_count":"1","timestamp":"1692791700.0","content":"Selected Answer: A\nSageMaker Ground Truth can use active learning to automate the labeling of the input data for certain built-in task types, such as object detection. Active learning is a machine learning technique that identifies data that should be labeled by human workers. This helps to reduce the cost and time that it takes to label the dataset compared to using only humans1. By setting up a private workforce, the internal team can use their own domain knowledge to label the data and ensure quality and consistency.","poster":"Mickey321","comment_id":"988264"},{"content":"Selected Answer: A\nAs we have an internal team working on this project, it is understood that they will do the labeling. Letter A is correct, as SageMaker Active Learning Feature allows you to streamline the team's efforts. Letters C - D are wrong as they use the wrong algorithm (object detection) and Letter B takes longer than Letter A.","upvote_count":"1","poster":"kaike_reis","timestamp":"1692365220.0","comment_id":"984522"},{"poster":"Mickey321","timestamp":"1691168700.0","content":"Selected Answer: D\nOption D uses a public workforce to label the data. This means that the company can leverage a large pool of workers from Amazon Mechanical Turk, who are experienced and qualified in labeling tasks. The public workforce can provide more diverse and accurate labels than the internal team, who may have limited or biased perspectives. The public workforce can also complete the labeling task faster and more efficiently than the internal team, who may have other priorities or responsibilities.","comment_id":"972334","upvote_count":"1","comments":[{"timestamp":"1692791760.0","upvote_count":"1","poster":"Mickey321","content":"changed to A. public workforce may need effort.","comment_id":"988266"}]},{"upvote_count":"1","comment_id":"967854","poster":"cfx210","timestamp":"1690787880.0","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/machine-learning/identify-rooftop-solar-panels-from-satellite-imagery-using-amazon-rekognition-custom-labels/"},{"comment_id":"946753","upvote_count":"1","content":"https://docs.aws.amazon.com/sagemaker/latest/dg/sms-automated-labeling.html","timestamp":"1688851980.0","poster":"Richaqua"},{"comment_id":"946150","upvote_count":"2","content":"It's A due to small team on the project and minimal effort from the team required.\nSageMaker Ground Truth active learning feature can speed up the labeling process for 8000 images.","timestamp":"1688788740.0","poster":"ADVIT"},{"upvote_count":"3","content":"Selected Answer: B\nB is correct","comment_id":"926043","poster":"SandeepGun","timestamp":"1687013220.0"},{"comment_id":"923594","poster":"RRST","upvote_count":"3","content":"B. Set up a private workforce that consists of the internal team. Use the private workforce to label the data. Use Amazon Rekognition Custom Labels for model training and hosting.\n\nBy setting up a private workforce consisting of the internal team and using Amazon Rekognition Custom Labels, the company can leverage the labeling capabilities of the internal team to label the data. Amazon Rekognition Custom Labels can then be used for model training and hosting.\n\nThis option eliminates the need for additional complex steps such as active learning or object detection algorithm training, which may require more ML expertise and effort from the internal team. Instead, it relies on the simplicity and convenience of using Amazon Rekognition Custom Labels for model training and hosting, making it the least effort-intensive option for the team with no ML expertise or experience.","timestamp":"1686782160.0"},{"content":"C is correct.","poster":"kukreti18","comment_id":"919925","timestamp":"1686387960.0","upvote_count":"1"}],"question_images":[],"answer_images":[],"question_id":181,"question_text":"A company wants to conduct targeted marketing to sell solar panels to homeowners. The company wants to use machine learning (ML) technologies to identify which houses already have solar panels. The company has collected 8,000 satellite images as training data and will use Amazon SageMaker Ground Truth to label the data.\n\nThe company has a small internal team that is working on the project. The internal team has no ML expertise and no ML experience.\n\nWhich solution will meet these requirements with the LEAST amount of effort from the internal team?","choices":{"B":"Set up a private workforce that consists of the internal team. Use the private workforce to label the data. Use Amazon Rekognition Custom Labels for model training and hosting.","A":"Set up a private workforce that consists of the internal team. Use the private workforce and the SageMaker Ground Truth active learning feature to label the data. Use Amazon Rekognition Custom Labels for model training and hosting.","C":"Set up a private workforce that consists of the internal team. Use the private workforce and the SageMaker Ground Truth active learning feature to label the data. Use the SageMaker Object Detection algorithm to train a model. Use SageMaker batch transform for inference.","D":"Set up a public workforce. Use the public workforce to label the data. Use the SageMaker Object Detection algorithm to train a model. Use SageMaker batch transform for inference."},"answer_description":"","exam_id":26,"answer_ET":"A","answers_community":["A (64%)","B (21%)","14%"],"unix_timestamp":1686387960,"isMC":true,"answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/111820-exam-aws-certified-machine-learning-specialty-topic-1/","timestamp":"2023-06-10 11:06:00"},{"id":"POd3O6gFqz91kQPWuFkC","topic":"1","discussion":[{"timestamp":"1723865700.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/databrew/latest/dg/personal-information-protection.html","comment_id":"1152382","upvote_count":"1","poster":"Untamables"},{"comment_id":"972335","poster":"Mickey321","content":"Selected Answer: C\noption C is better than the other options because it can meet the company’s requirements with the least development effort. Option C can leverage DataBrew’s native capabilities to identify and handle PII data in a visual and intuitive way.","timestamp":"1707073620.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nAnswer C\n\nhttps://aws.amazon.com/blogs/big-data/introducing-pii-data-identification-and-handling-using-aws-glue-databrew/","comment_id":"960983","poster":"D2","timestamp":"1706063700.0"},{"comment_id":"946152","upvote_count":"4","timestamp":"1704693840.0","poster":"ADVIT","content":"Selected Answer: C\nC cause A require customization."}],"answers_community":["C (100%)"],"question_images":[],"unix_timestamp":1688789040,"answer":"C","choices":{"B":"Create a custom AWS Lambda function to read the files, identify the PII. and redact the PII","D":"Use an AWS Glue development endpoint to implement the PII redaction from within a notebook","A":"Use Amazon SageMaker Data Wrangler with a custom transformation to identify and redact the PII.","C":"Use AWS Glue DataBrew to identity and redact the PII"},"question_text":"A company hosts a machine learning (ML) dataset repository on Amazon S3. A data scientist is preparing the repository to train a model. The data scientist needs to redact personally identifiable information (PH) from the dataset.\n\nWhich solution will meet these requirements with the LEAST development effort?","question_id":182,"url":"https://www.examtopics.com/discussions/amazon/view/114478-exam-aws-certified-machine-learning-specialty-topic-1/","answer_description":"","exam_id":26,"answer_images":[],"isMC":true,"timestamp":"2023-07-08 06:04:00","answer_ET":"C"},{"id":"uTIcBNJ1sOSipxn2k06R","unix_timestamp":1688789280,"answers_community":["C (47%)","D (43%)","10%"],"isMC":true,"question_images":[],"question_text":"A company is deploying a new machine learning (ML) model in a production environment. The company is concerned that the ML model will drift over time, so the company creates a script to aggregate all inputs and predictions into a single file at the end of each day. The company stores the file as an object in an Amazon S3 bucket. The total size of the daily file is 100 GB. The daily file size will increase over time.\n\nFour times a year, the company samples the data from the previous 90 days to check the ML model for drift. After the 90-day period, the company must keep the files for compliance reasons.\n\nThe company needs to use S3 storage classes to minimize costs. The company wants to maintain the same storage durability of the data.\n\nWhich solution will meet these requirements?","topic":"1","exam_id":26,"url":"https://www.examtopics.com/discussions/amazon/view/114479-exam-aws-certified-machine-learning-specialty-topic-1/","answer_images":[],"choices":{"B":"Store the daily objects in the S3 One Zone-Infrequent Access (S3 One Zone-IA) storage class. Configure an S3 Lifecycle rule to move the objects to S3 Glacier Flexible Retrieval after 90 days.","A":"Store the daily objects in the S3 Standard-InfrequentAccess (S3 Standard-IA) storage class. Configure an S3 Lifecycle rule to move the objects to S3 Glacier Flexible Retrieval after 90 days.","D":"Store the daily objects in the S3 One Zone-Infrequent Access (S3 One Zone-IA) storage class. Configure an S3 Lifecycle rule to move the objects to S3 Glacier Deep Archive after 90 days.","C":"Store the daily objects in the S3 Standard-InfrequentAccess (S3 Standard-IA) storage class. Configure an S3 Lifecycle rule to move the objects to S3 Glacier Deep Archive after 90 days."},"answer":"C","question_id":183,"discussion":[{"timestamp":"1742080020.0","upvote_count":"1","comment_id":"1399073","content":"Selected Answer: D\nAvailability is not mentioned in the question. So D","poster":"2eb8df0"},{"content":"Selected Answer: C\nThe lowest cost is Glacier Deep Archive (so A and B discarded).\nDespite the fact that D is slightly cheaper than C, we are talking about productive data. Losing access to them is never an option. One zone only are for data that can be easily replicated as image thumbnails.","poster":"santi1975","upvote_count":"1","comment_id":"1352570","timestamp":"1738866480.0"},{"timestamp":"1738230720.0","content":"Selected Answer: A\nDurability and access patterns","poster":"AbhayD","comment_id":"1348987","comments":[{"comment_id":"1348989","upvote_count":"1","content":"Four times a year, the company samples the data from the previous 90 days to check the ML model for drift.","timestamp":"1738230780.0","poster":"AbhayD"}],"upvote_count":"1"},{"comment_id":"1326907","poster":"2a18a01","content":"Selected Answer: C\nDurability is the key, retrieval time is not a factor. Answer is C.","timestamp":"1734273000.0","upvote_count":"1"},{"comment_id":"1306343","poster":"spinatram","upvote_count":"1","content":"D\n11 9s for all storage classes, durability is the key not availability","timestamp":"1730586480.0"},{"timestamp":"1714392600.0","comment_id":"1204002","upvote_count":"1","poster":"Denise123","content":"Selected Answer: C\nobvious. no need retrieval time to be short."},{"upvote_count":"1","content":"Selected Answer: C\nYou cannot achieved durability in standard IA","timestamp":"1712425080.0","comment_id":"1190539","poster":"Gmishra"},{"poster":"AIWave","content":"Selected Answer: C\nLowest cost - past 90 days in deep archive. \nAccess only 4 times an year - standard IA - we need to be able to recover data in case of a zone failure","timestamp":"1709656680.0","upvote_count":"1","comment_id":"1166618"},{"upvote_count":"4","timestamp":"1707370440.0","content":"Selected Answer: D\nthe question only mentions \"the same durability\" and \"minimize cost\".\nIt didn't mention \"availability\"\nSo D","comment_id":"1144110","poster":"rav009"},{"poster":"Kampton","content":"If the company is required to \"must\" keep the files after 90 days then what happens if One Zone is hit by a disaster?! Therefore option \"C\" is the best solution here.","timestamp":"1707362340.0","comment_id":"1144018","upvote_count":"2"},{"comment_id":"1125378","content":"Selected Answer: C\nIf the company can tolerate retrieval times of several hours and is looking for the lowest cost solution, Option C is the best choice over D, as S3 Glacier Deep Archive offers the lowest storage cost.","upvote_count":"2","poster":"CloudHandsOn","timestamp":"1705529160.0"},{"comments":[{"content":"D\n11 9s for all storage classes. Availability not mentioned. Durability is the key point","poster":"spinatram","upvote_count":"1","timestamp":"1730586420.0","comment_id":"1306342"}],"upvote_count":"2","poster":"Jahm","content":"Selected Answer: C\nS3 Standard-IA : Designed for 99.9% availability over a given year\nS3 One Zone-IA : Designed for 99.5% availability over a given year\nhttps://aws.amazon.com/s3/storage-classes/?nc1=h_ls","comment_id":"1073956","timestamp":"1700307120.0"},{"content":"Answer C\nNot A - S3 Glacier Flexible Retrieval is not needed. it cost more than Glacier Deep Archive. And the question doesnt mention to retrieve the file immediately when neede.\nNot B - Although One Zone-Infrequent Access is possible, the question doesnt mention thre is another copy of files somewhere else or there is no problem if some files are lost. Although the loss of data is very rare we use One Zone-Infrequent Access for data that can tolerate loss.","upvote_count":"2","poster":"geoan13","comment_id":"1072224","timestamp":"1700117280.0"},{"poster":"giustino98","comment_id":"1062899","timestamp":"1699189140.0","content":"Selected Answer: D\n\"Amazon S3 Standard, S3 Standard-IA, S3 One Zone-IA, and Amazon Glacier, are all designed for 99.999999999% durability.\" One Zone is as durable as Standard but cheaper than Standard IA. Glacier Deep Archive is cheaper than Flexible Retrieval. D is the cheapest (without compromising on durability).","upvote_count":"4"},{"upvote_count":"2","content":"Selected Answer: D\nD is the right option because S3 One Zone-Infrequent Access has the same durability (11 nines) as S3 Standard-IA with an added benefit of 20% less cost than S3 Standard-IA. Only downside is that One-Zone is less resilient than Standard-IA as data is not replicated to multiple AZs. This question is asking about durability not resiliency. Also, option D has the cheapest archival option (Glacier Deep Archive) which comes with 11 nines durability so, daily data files and archived files will have the same durability.","poster":"backbencher2022","comment_id":"1026916","timestamp":"1696618920.0"},{"content":"Selected Answer: C\nA. NO - can store in cheapest Glacier Deep Archive after 90 days\nB. NO - can store in cheapest Glacier Deep Archive after 90 days\nC. YES\nD. NO - need multiple zones for higher resiliency due to legal requirements","poster":"loict","timestamp":"1694528100.0","upvote_count":"1","comment_id":"1005839"},{"comment_id":"997355","timestamp":"1693720320.0","content":"Selected Answer: D\n\"Amazon S3 Standard, S3 Standard-IA, S3 One Zone-IA, and Amazon Glacier, are all designed for 99.999999999% durability.\" One Zone is as durable as Standard but cheaper than Standard IA. Glacier Deep Archive is cheaper than Flexible Retrieval. D is the cheapest (without compromising on durability).","upvote_count":"2","poster":"goku58"},{"poster":"chet100","timestamp":"1693681020.0","comment_id":"997074","content":"Go for A","upvote_count":"1"},{"poster":"kaike_reis","upvote_count":"2","comments":[{"upvote_count":"1","poster":"devakram","timestamp":"1706266560.0","comment_id":"1132454","content":"Where the hell did you source your info? 180 days to be accessed?!!:\n\n\n\n - S3 Glacier Instant Retrieval for archiving data that might be needed once per quarter and needs to be restored quickly (milliseconds)\n\n - S3 Glacier Flexible Retrieval for archiving data that might infrequently need to be restored, once or twice per year, within a few hours\n\n - S3 Glacier Deep Archive for archiving long-term backup cycle data that might infrequently need to be restored within 12 hours\n\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/backup-recovery/amazon-s3-glacier.html"}],"timestamp":"1692366060.0","content":"Selected Answer: A\nIf we want to maintain the same durability, we cannot use One Zone, given the importance of maintaining these data for the quality of the model (thus, we discard B - D). As we want to minimize the cost and we need to access the data every 90 days, the correct alternative is Letter A as the minimum recovery time is 90 days for S3 Glacier Flexible Retrieval (in contrast, Deep Archive needs 180 days to be accessed ).","comment_id":"984539"},{"comment_id":"972337","poster":"Mickey321","upvote_count":"1","content":"Selected Answer: C\nIndeed option C","timestamp":"1691169180.0"},{"upvote_count":"1","comment_id":"962234","timestamp":"1690251120.0","poster":"awsarchitect5","content":"Selected Answer: C\nC it is"},{"comment_id":"946153","timestamp":"1688789280.0","content":"Selected Answer: C\nFor same storage Durability we should NOT use S3 One Zone-IA.\nFor Glacier we will use Deep Archive for more cost saving.\nSo it's C","poster":"ADVIT","upvote_count":"2"}],"answer_ET":"C","timestamp":"2023-07-08 06:08:00","answer_description":""},{"id":"5umpKNGawgVClsLPlSFC","answer_ET":"D","unix_timestamp":1688789640,"answer_description":"","answers_community":["D (53%)","B (47%)"],"topic":"1","timestamp":"2023-07-08 06:14:00","answer":"D","question_text":"A company wants to enhance audits for its machine learning (ML) systems. The auditing system must be able to perform metadata analysis on the features that the ML models use. The audit solution must generate a report that analyzes the metadata. The solution also must be able to set the data sensitivity and authorship of features.\n\nWhich solution will meet these requirements with the LEAST development effort?","discussion":[{"comment_id":"1362436","content":"Selected Answer: D\nThe creation of DynamoDB is logical, so never\nNot suitable for \"LEAST development effort\".","timestamp":"1740637380.0","poster":"Carpediem78","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\nCopilot initially said option D, but when you challenge the machine saying that QuickSight is purely a data representation tool and does not analyse anything (as clearly requested in the question) changed its mind, and says B.\n\n\"Considering the need for both analyzing metadata and generating a report, Option B might be a better fit because SageMaker Studio has the comprehensive tools needed for both tasks: in-depth analysis and reporting.\"","poster":"santi1975","comment_id":"1355996","timestamp":"1739431200.0"},{"content":"Selected Answer: D\nOption B involves using Amazon SageMaker Feature Store to set feature groups and assign metadata, then using SageMaker Studio to analyze the metadata. While this approach is valid, it may not be the best choice. Studio is for development not for visualisation.","comment_id":"1301225","timestamp":"1729537260.0","poster":"MultiCloudIronMan","upvote_count":"1"},{"timestamp":"1716638280.0","upvote_count":"2","comment_id":"1218290","content":"Selected Answer: B\nyou can input metadata directly in sagemaker feature store, no need for dydb.\nhttps://docs.amazonaws.cn/en_us/sagemaker/latest/dg/feature-store-add-metadata.html","poster":"rav009"},{"poster":"Richa_sh","comment_id":"1175531","upvote_count":"1","content":"Selected Answer: B\nOption D is similar to option B but suggests using Amazon QuickSight for metadata analysis instead of SageMaker Studio. While QuickSight is a viable option for visualization, it may require additional configuration and setup compared to using SageMaker Studio, which is already integrated with SageMaker Feature Store.","timestamp":"1710640620.0"},{"comment_id":"1048831","poster":"backbencher2022","content":"Selected Answer: D\nOn second thoughts, D (QuickSight) is also a possible option because feature store parquet files could be queried by Athena and Athena could be used with Quicksight without any development efforts. Would go with option D","upvote_count":"1","timestamp":"1697809140.0"},{"poster":"backbencher2022","upvote_count":"1","content":"Selected Answer: B\nB is the correct option because in option D, Quicksight is used which doesn't support parquet files. Sagemaker feature groups created in offline feature store use parquet to store feature values on S3. This question is talking about auditing which makes offline feature store an obvious choice. In order to use Quicksight, there is an additional step to convert feature store parquet file to a supported format (like CSV, JSON, etc.) and hence, it has more efforts compared to creating a dataframe in Data Wrangler and using it for visualizations","timestamp":"1696611480.0","comment_id":"1026829"},{"content":"Selected Answer: D\nThe answer should be D,\nboth the sagemaker studio and the quicksight can analyze metadata \nbut Amazon SageMaker Studio is a web-based, integrated development environment (IDE) for machine learning that provides all the tools you need to take your models from data preparation to experimentation to production.\nand the question is asking about a solution with the least development so it should be Quicksight","poster":"teka112233","upvote_count":"1","timestamp":"1694965860.0","comment_id":"1009925"},{"content":"Selected Answer: D\nA. NO - Amazon SageMaker Feature Store cannot transform\nB. NO - SageMaker Studio require Python to analyze the metadata\nC. NO - custom algorithms are dev-intensive\nD. YES - use built-in functionnalities","timestamp":"1694528580.0","comment_id":"1005842","upvote_count":"1","poster":"loict"},{"upvote_count":"1","comment_id":"993071","poster":"Mickey321","content":"Selected Answer: D\nAgree D","timestamp":"1693312440.0"},{"comment_id":"984542","timestamp":"1692366300.0","poster":"kaike_reis","upvote_count":"1","content":"Selected Answer: D\nPor menor esforço de desenvolvimento descartamos Letra A (levantar um serviço gerenciado como DynamoDB normalmente não é a melhor solução), Letra B (não é performática), Letra C (mesmo motivo da A). Logo por eliminação, Letra D está correta."},{"poster":"Mickey321","content":"Selected Answer: D\nThis solution meets the requirements with the least development effort because it uses Amazon SageMaker Feature Store, which is a fully managed service that makes it easy to store and manage feature metadata. Amazon SageMaker Feature Store also provides built-in functionality for analyzing feature metadata, so there is no need to create custom algorithms or data flows.","upvote_count":"1","comment_id":"972389","timestamp":"1691173920.0"},{"upvote_count":"1","comment_id":"962242","timestamp":"1690251540.0","poster":"awsarchitect5","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/machine-learning/controlling-and-auditing-data-exploration-activities-with-amazon-sagemaker-studio-and-aws-lake-formation/\nStudio supports Audit"},{"content":"Selected Answer: B\nI think it's B","comment_id":"946155","timestamp":"1688789640.0","comments":[{"comment_id":"946156","timestamp":"1688789760.0","content":"Maybe It's D as QuickSight less development effort.","poster":"ADVIT","comments":[{"comment_id":"955353","upvote_count":"1","content":"Agreed, should be D","timestamp":"1689681420.0","poster":"kukreti18"}],"upvote_count":"2"}],"upvote_count":"1","poster":"ADVIT"}],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/114480-exam-aws-certified-machine-learning-specialty-topic-1/","isMC":true,"question_id":184,"exam_id":26,"answer_images":[],"choices":{"C":"Use Amazon SageMaker Features Store to apply custom algorithms to analyze the feature-level metadata that the company requires. Create an Amazon DynamoDB table to store feature-level metadata. Use Amazon QuickSight to analyze the metadata.","A":"Use Amazon SageMaker Feature Store to select the features. Create a data flow to perform feature-level metadata analysis. Create an Amazon DynamoDB table to store feature-level metadata. Use Amazon QuickSight to analyze the metadata.","B":"Use Amazon SageMaker Feature Store to set feature groups for the current features that the ML models use. Assign the required metadata for each feature. Use SageMaker Studio to analyze the metadata.","D":"Use Amazon SageMaker Feature Store to set feature groups for the current features that the ML models use. Assign the required metadata for each feature. Use Amazon QuickSight to analyze the metadata."}},{"id":"KTqe2da7UtAHfIH62tm3","question_images":[],"answer":"C","unix_timestamp":1688789760,"discussion":[{"upvote_count":"2","timestamp":"1709179320.0","content":"https://stackoverflow.com/questions/66692579/aws-sagemaker-permissionerror-access-denied-reading-data-from-s3-bucket\n\n'C' is the correct answer.","comment_id":"992724","poster":"ashii007"},{"poster":"kaike_reis","content":"Selected Answer: C\nNote that the question does not mention VPC, so we discard Letter B. Letter C appears to be correct, as they use IAM to grant permission (congruent with their role). SG is beyond the scope of KMS, so we discard Letter A. Letter D is incongruous.","comment_id":"984545","timestamp":"1708271460.0","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: C\nOption C allows the ML specialist to assign an IAM role that provides S3 read access for the dataset to the SageMaker notebook. IAM is a service that helps users manage access to AWS resources. An IAM role is an entity that defines a set of permissions for making AWS service requests. The ML specialist can create an IAM role that has a policy that allows the notebook to read the dataset from the S3 bucket. The ML specialist can then attach the IAM role to the notebook when creating or updating it.","timestamp":"1707079440.0","comment_id":"972396","poster":"Mickey321"},{"comment_id":"962249","content":"Selected Answer: C\nC it is","upvote_count":"2","poster":"awsarchitect5","timestamp":"1706156580.0"},{"content":"C is correct","comment_id":"955387","poster":"kukreti18","upvote_count":"3","timestamp":"1705587720.0"},{"upvote_count":"1","timestamp":"1704694560.0","comments":[{"poster":"kaike_reis","timestamp":"1708271520.0","upvote_count":"2","comment_id":"984547","content":"It's not"},{"content":"stop misleading people","poster":"fa0d8b7","upvote_count":"1","comment_id":"1098849","timestamp":"1718616840.0"}],"poster":"ADVIT","content":"100% it's D.","comment_id":"946157"}],"choices":{"A":"Define security groups to allow all HTTP inbound and outbound traffic. Assign the security groups to the SageMaker notebook instance.","D":"Assign the same KMS key that encrypts the data in Amazon S3 to the SageMaker notebook instance.","C":"Assign an IAM role that provides S3 read access for the dataset to the SageMaker notebook. Grant permission in the KMS key policy to the IAM role.","B":"Configure the SageMaker notebook instance to have access to the VPC. Grant permission in the AWS Key Management Service (AWS KMS) key policy to the notebook’s VPC."},"isMC":true,"exam_id":26,"question_id":185,"answers_community":["C (100%)"],"answer_images":[],"topic":"1","timestamp":"2023-07-08 06:16:00","url":"https://www.examtopics.com/discussions/amazon/view/114481-exam-aws-certified-machine-learning-specialty-topic-1/","answer_description":"","answer_ET":"C","question_text":"A machine learning (ML) specialist uploads a dataset to an Amazon S3 bucket that is protected by server-side encryption with AWS KMS keys (SSE-KMS). The ML specialist needs to ensure that an Amazon SageMaker notebook instance can read the dataset that is in Amazon S3.\n\nWhich solution will meet these requirements?"}],"exam":{"lastUpdated":"11 Apr 2025","name":"AWS Certified Machine Learning - Specialty","isImplemented":true,"isBeta":false,"provider":"Amazon","isMCOnly":false,"id":26,"numberOfQuestions":369},"currentPage":37},"__N_SSP":true}