{"pageProps":{"questions":[{"id":"7gklx8mUx82av0VVxPdx","answers_community":["D (100%)"],"answer_images":[],"unix_timestamp":1732779840,"timestamp":"2024-11-28 08:44:00","exam_id":27,"isMC":true,"topic":"1","answer_ET":"D","discussion":[{"comment_id":"1321813","content":"Selected Answer: D\nKey phrase extraction and custom entity recognition - Amazon Comprehend helps with least operational overhead.","upvote_count":"2","poster":"Saransundar","timestamp":"1733308560.0"},{"upvote_count":"1","timestamp":"1732779840.0","poster":"GiorgioGss","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/comprehend/latest/dg/what-is.html","comment_id":"1319077"}],"question_text":"An ML engineer needs to use AWS services to identify and extract meaningful unique keywords from documents.\nWhich solution will meet these requirements with the LEAST operational overhead?","question_images":[],"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/152229-exam-aws-certified-machine-learning-engineer-associate-mla/","question_id":76,"choices":{"B":"Use Amazon SageMaker and the BlazingText algorithm. Apply custom pre-processing steps for stemming and removal of stop words. Calculate term frequency-inverse document frequency (TF-IDF) scores to identify and extract relevant keywords.","A":"Use the Natural Language Toolkit (NLTK) library on Amazon EC2 instances for text pre-processing. Use the Latent Dirichlet Allocation (LDA) algorithm to identify and extract relevant keywords.","D":"Use Amazon Comprehend custom entity recognition and key phrase extraction to identify and extract relevant keywords.","C":"Store the documents in an Amazon S3 bucket. Create AWS Lambda functions to process the documents and to run Python scripts for stemming and removal of stop words. Use bigram and trigram techniques to identify and extract relevant keywords."},"answer_description":""},{"id":"X68HQeonNH9Kjeh7vz6r","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/152230-exam-aws-certified-machine-learning-engineer-associate-mla/","question_text":"A company needs to give its ML engineers appropriate access to training data. The ML engineers must access training data from only their own business group. The ML engineers must not be allowed to access training data from other business groups.\nThe company uses a single AWS account and stores all the training data in Amazon S3 buckets. All ML model training occurs in Amazon SageMaker.\nWhich solution will provide the ML engineers with the appropriate access?","answer_images":[],"choices":{"B":"Configure S3 Object Lock settings for each user.","D":"Create IAM policies. Attach the policies to IAM users or IAM roles.","C":"Add cross-origin resource sharing (CORS) policies to the S3 buckets.","A":"Enable S3 bucket versioning."},"answers_community":["D (100%)"],"answer":"D","exam_id":27,"unix_timestamp":1732779960,"answer_ET":"D","timestamp":"2024-11-28 08:46:00","discussion":[{"poster":"Saransundar","upvote_count":"1","timestamp":"1733308380.0","comment_id":"1321812","content":"Selected Answer: D\nIAM policies helps to define the access required and control. Can be applied to user or role."},{"comment_id":"1319079","upvote_count":"2","timestamp":"1732779960.0","poster":"GiorgioGss","content":"Selected Answer: D\nIAM to have 'granular' permissions"}],"question_id":77,"answer_description":"","topic":"1","isMC":true},{"id":"yACszbv3pKURtCwt1ges","isMC":false,"unix_timestamp":1736943420,"topic":"1","question_images":["https://img.examtopics.com/aws-certified-machine-learning-engineer-associate-mla-c01/image5.png"],"timestamp":"2025-01-15 13:17:00","answer_images":["https://img.examtopics.com/aws-certified-machine-learning-engineer-associate-mla-c01/image6.png"],"question_text":"HOTSPOT -\nA company wants to host an ML model on Amazon SageMaker. An ML engineer is configuring a continuous integration and continuous delivery (Cl/CD) pipeline in AWS CodePipeline to deploy the model. The pipeline must run automatically when new training data for the model is uploaded to an Amazon S3 bucket.\nSelect and order the pipeline's correct steps from the following list. Each step should be selected one time or not at all. (Select and order three.)\n• An S3 event notification invokes the pipeline when new data is uploaded.\n• S3 Lifecycle rule invokes the pipeline when new data is uploaded.\n• SageMaker retrains the model by using the data in the S3 bucket.\n• The pipeline deploys the model to a SageMaker endpoint.\n• The pipeline deploys the model to SageMaker Model Registry.\n//IMG//","exam_id":27,"answer_ET":"","answers_community":[],"url":"https://www.examtopics.com/discussions/amazon/view/154557-exam-aws-certified-machine-learning-engineer-associate-mla/","answer_description":"","discussion":[{"comment_id":"1351701","timestamp":"1738728960.0","upvote_count":"4","content":"1. An S3 event notification invokes the pipeline when new data is uploaded.\n 2. SageMaker retrains the model by using the data in the S3 bucket.\n 3. The pipeline deploys the model to a SageMaker endpoint.","poster":"djeong95"},{"upvote_count":"2","comments":[{"comment_id":"1381809","content":"I suppose you had a typo in \"So 2 is the correct third step.\".\n\nThe model should be deployed to an endpoint (not registry): \n• An S3 event notification invokes the pipeline when new data is uploaded.\n• SageMaker retrains the model by using the data in the S3 bucket.\n• The pipeline deploys the model to a SageMaker endpoint.","timestamp":"1741613820.0","upvote_count":"1","poster":"chris_spencer"}],"poster":"0c2d840","timestamp":"1736943420.0","content":"First two steps are obvious. For the last (third) step, there are two choices.\n1. The pipeline deploys the model to a SageMaker endpoint.\n2. The pipeline deploys the model to SageMaker Model Registry.\nSince the question says deploy the model, 1st option is correct. If we add the model to Model Registry, it will be just there in the catalog, but won't get deployed. It needs to be explicitly deployed to the endpoint. So 2 is the correct third step.","comment_id":"1340870"}],"answer":"","question_id":78},{"id":"i8Sjj3yHzhPa5ChMCbzr","question_images":[],"answers_community":["C (100%)"],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/152231-exam-aws-certified-machine-learning-engineer-associate-mla/","unix_timestamp":1732780080,"answer_description":"","discussion":[{"comment_id":"1321811","content":"Selected Answer: C\nLoad is predictable and sustainable with 2 hrs usage pattern; Needs quick response as well; Sagemaker - Provisioned concurrency + Serverless inference will be able to support it. https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html","poster":"Saransundar","timestamp":"1733308260.0","upvote_count":"2"},{"content":"Selected Answer: C\nFor only 2h each day it does not worth provisioning resources. Go serverless.","poster":"GiorgioGss","upvote_count":"2","comment_id":"1319080","timestamp":"1732780080.0"}],"isMC":true,"timestamp":"2024-11-28 08:48:00","choices":{"C":"Use Amazon SageMaker Serverless Inference with provisioned concurrency.","A":"Schedule an Amazon SageMaker batch transform job by using AWS Lambda.","D":"Run the model on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster on Amazon EC2 with pod auto scaling.","B":"Configure an Auto Scaling group of Amazon EC2 instances to use scheduled scaling."},"answer_ET":"C","exam_id":27,"question_text":"A company needs to host a custom ML model to perform forecast analysis. The forecast analysis will occur with predictable and sustained load during the same 2-hour period every day.\nMultiple invocations during the analysis period will require quick responses. The company needs AWS to manage the underlying infrastructure and any auto scaling activities.\nWhich solution will meet these requirements?","answer":"C","question_id":79,"topic":"1"},{"id":"DsSm1FdN2EMLcbcbC47E","answers_community":["B (100%)"],"answer_images":[],"isMC":true,"question_text":"A company's ML engineer has deployed an ML model for sentiment analysis to an Amazon SageMaker endpoint. The ML engineer needs to explain to company stakeholders how the model makes predictions.\nWhich solution will provide an explanation for the model's predictions?","answer":"B","timestamp":"2024-11-28 08:50:00","exam_id":27,"discussion":[{"poster":"Saransundar","timestamp":"1733382120.0","comment_id":"1322256","upvote_count":"1","content":"Selected Answer: B\nSentiment analysis model → SageMaker Clarify → Analyze feature impact → Explain predictions to stakeholders"}],"answer_ET":"B","answer_description":"","choices":{"C":"Show the distribution of inferences from A/В testing in Amazon CloudWatch.","B":"Use SageMaker Clarify on the deployed model.","D":"Add a shadow endpoint. Analyze prediction differences on samples.","A":"Use SageMaker Model Monitor on the deployed model."},"question_images":[],"topic":"1","unix_timestamp":1732780200,"question_id":80,"url":"https://www.examtopics.com/discussions/amazon/view/152232-exam-aws-certified-machine-learning-engineer-associate-mla/"}],"exam":{"id":27,"lastUpdated":"11 Apr 2025","isImplemented":true,"provider":"Amazon","isMCOnly":false,"name":"AWS Certified Machine Learning Engineer - Associate MLA-C01","isBeta":false,"numberOfQuestions":106},"currentPage":16},"__N_SSP":true}