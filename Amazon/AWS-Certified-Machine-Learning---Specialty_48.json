{"pageProps":{"questions":[{"id":"pUFqJwLWGUJa2ex2hByc","answer_ET":"A","discussion":[{"poster":"Peter_Hsieh","timestamp":"1730299200.0","comment_id":"1204569","upvote_count":"2","content":"Selected Answer: A\nhttps://aws.amazon.com/about-aws/whats-new/2022/04/amazon-sagemaker-data-wrangler-supports-random-sampling-stratified-sampling/"},{"upvote_count":"1","poster":"F1Fan","content":"A.\nBalanced Class Representation. Stratified sampling divides the original dataset into strata (groups) based on the class labels. It then selects instances from each stratum in a proportional manner, ensuring that the class distribution in the training and validation datasets reflects the original class distribution.\nImproved Generalization. By having a balanced representation of all classes in the training and validation datasets, the model is exposed to a diverse range of instances during training. This helps the model learn the distinguishing features of each class more effectively, leading to better generalization performance on the validation dataset.\nAddressing Imbalanced Data. Stratified sampling directly addresses the issue of imbalanced data, which was identified as the root cause of the model's poor generalization performance on the validation dataset.","comment_id":"1185482","timestamp":"1727613060.0"},{"poster":"vkbajoria","content":"Selected Answer: A\nStratified sampling","comment_id":"1180305","upvote_count":"1","timestamp":"1727030280.0"},{"comment_id":"1169821","poster":"AIWave","timestamp":"1725908220.0","upvote_count":"3","content":"Selected Answer: A\nA: Yes - Stratified sampling ensures that each class is proportionally represented and mitigates the impact of class imbalance on model performance\nB: No - additional data about the majority classes does not solve class imbalance issue\nC: No - Does not solve class imbalance issue and may worsen the situation\nD: No - selecting data points at regular intervals does not solve class imbalance issue"}],"answer_description":"","question_text":"A machine learning engineer is building a bird classification model. The engineer randomly separates a dataset into a training dataset and a validation dataset. During the training phase, the model achieves very high accuracy. However, the model did not generalize well during validation of the validation dataset. The engineer realizes that the original dataset was imbalanced.\n\nWhat should the engineer do to improve the validation accuracy of the model?","isMC":true,"timestamp":"2024-03-09 21:57:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/135608-exam-aws-certified-machine-learning-specialty-topic-1/","answer":"A","question_images":[],"answer_images":[],"unix_timestamp":1710017820,"choices":{"A":"Perform stratified sampling on the original dataset.","B":"Acquire additional data about the majority classes in the original dataset.","C":"Use a smaller, randomly sampled version of the training dataset.","D":"Perform systematic sampling on the original dataset."},"question_id":236,"answers_community":["A (100%)"],"exam_id":26},{"id":"QCz8TpVWhhcwHbVHclwY","question_id":237,"exam_id":26,"answers_community":["A (57%)","B (43%)"],"discussion":[{"poster":"ef12052","comment_id":"1533275","content":"Selected Answer: A\nhttps://aws.amazon.com/it/blogs/aws/new-amazon-athena-for-apache-spark/","timestamp":"1743854400.0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1735341600.0","comment_id":"1332679","poster":"587df71","content":"Selected Answer: A\nAmazon Athena makes it easy to interactively run data analytics and exploration using Apache Spark without the need to plan for, configure, or manage resources\n\nreference :-https://docs.aws.amazon.com/athena/latest/ug/notebooks-spark.html"},{"poster":"spinatram","comment_id":"1306323","upvote_count":"1","timestamp":"1730580600.0","content":"B - SageMaker\nAthena and redshift does not support Apache spark scripts\nEMR requires managing infra"},{"upvote_count":"2","comment_id":"1293745","content":"Selected Answer: B\nSageMaker provide serverless, spark cluster notebook, pay as you go if you remember to close it when you finished your work.","timestamp":"1728193980.0","poster":"MJSY"},{"poster":"Shivanshub","content":"Selected Answer: B\nAmazon Athena does not natively support running Python code directly. Amazon Athena is primarily a serverless, interactive query service that allows you to analyze data in Amazon S3 using standard SQL.\n\nUse Apache Spark from within Amazon SageMaker.\n\nAmazon SageMaker allows you to run Jupyter notebooks and provides managed Apache Spark integration, which means you don't need to manage the underlying compute resources yourself. You can also use SageMaker to perform the analysis and pay only for the resources you consume during the execution of your queries.","comment_id":"1274605","timestamp":"1724946840.0","upvote_count":"2"},{"comment_id":"1246415","upvote_count":"2","poster":"eicresv2","content":"Selected Answer: A\nA and not B also because of paying for queries that you run. Notebooks will continue to run and cost money","timestamp":"1720748040.0"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/athena/latest/ug/notebooks-spark-working-with-notebooks.html","comment_id":"1235778","poster":"pandkast","timestamp":"1719137940.0","upvote_count":"2"},{"upvote_count":"2","poster":"rav009","timestamp":"1716783000.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/athena/latest/ug/notebooks-spark-editor.html","comment_id":"1219303"},{"upvote_count":"2","poster":"ddaanndann","comment_id":"1186358","timestamp":"1711829220.0","content":"Correct Answer: A\n\nhttps://docs.aws.amazon.com/athena/latest/ug/notebooks-spark.html"},{"content":"It's A - Using Apache Spark on Amazon Athena \nhttps://aws-sdk-pandas.readthedocs.io/en/3.2.1/tutorials/041%20-%20Apache%20Spark%20on%20Amazon%20Athena.html","poster":"JonSno","upvote_count":"1","timestamp":"1711813740.0","comment_id":"1186166"},{"timestamp":"1711139760.0","comments":[{"timestamp":"1711755120.0","content":"I changed my mind, Athena supports spark. It's A","upvote_count":"1","comment_id":"1185747","poster":"vkbajoria"}],"comment_id":"1180303","upvote_count":"2","poster":"vkbajoria","content":"Selected Answer: B\nServerless, Python, and Notebook are key elements for making the decision. It's B"},{"upvote_count":"4","content":"Selected Answer: A\nhttps://docs.amazonaws.cn/en_us/athena/latest/ug/notebooks-spark-getting-started.html","poster":"rav009","timestamp":"1710740160.0","comment_id":"1176276"},{"content":"Just thinking out loud, how can it be not Redshift as well? The question also mentions pay for queries, and handle petabyte of data.\nSpark is an integration possible with Amazon Redshift, and Redshift has serverless version too. \nhttps://aws.amazon.com/blogs/aws/new-amazon-redshift-integration-with-apache-spark/","comment_id":"1175394","timestamp":"1710631020.0","poster":"shivamgulati13","upvote_count":"1"},{"poster":"AIWave","timestamp":"1710019140.0","upvote_count":"4","comment_id":"1169838","content":"Selected Answer: B\nA: No - Athena does not support python code\nB: Yes - Sagemaker is serverless and SageMaker Processing allows you to run Spark jobs from a Jupyter notebook using Python. You only pay for resources used during processing jobs.\nC: No - involves managing the EMR cluster. You pay for running EC2 instances whether in use or not.\nD: No - Redshift can't run spark jobs and no native support for python/Jupiter notebooks"}],"timestamp":"2024-03-09 22:19:00","topic":"1","answer_images":[],"answer_description":"","question_text":"A data engineer wants to perform exploratory data analysis (EDA) on a petabyte of data. The data engineer does not want to manage compute resources and wants to pay only for queries that are run. The data engineer must write the analysis by using Python from a Jupyter notebook.\n\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/135610-exam-aws-certified-machine-learning-specialty-topic-1/","choices":{"D":"Use Apache Spark through an integration with Amazon Redshift.","B":"Use Apache Spark from within Amazon SageMaker.","C":"Use Apache Spark from within an Amazon EMR cluster.","A":"Use Apache Spark from within Amazon Athena."},"unix_timestamp":1710019140,"answer_ET":"A","isMC":true,"answer":"A","question_images":[]},{"id":"NMtJpdH8PfUkwclmYtPH","exam_id":26,"discussion":[{"poster":"MultiCloudIronMan","timestamp":"1727094840.0","comment_id":"1288112","content":"Selected Answer: D\nData wrangler design for ML etl with inbuilt functions","upvote_count":"1"},{"upvote_count":"1","comment_id":"1180301","timestamp":"1711139580.0","content":"Selected Answer: D\nData Wrangler best tool for the job","poster":"vkbajoria"},{"timestamp":"1710740280.0","poster":"rav009","content":"Selected Answer: D\nData wrangler for all you need when prepare data for ML.","upvote_count":"1","comment_id":"1176277"},{"upvote_count":"2","content":"Selected Answer: D\nA: No - more manual/operational overhead\nB: No - more manual/operational overhead \nC: No - Data transformation to parquet requires more unnecessary operational overhead\nD: Yes - least operational effort - wrangler has built-in identification of data quality issues and outliers","poster":"AIWave","timestamp":"1710019560.0","comment_id":"1169843"}],"answer":"D","answers_community":["D (100%)"],"question_id":238,"unix_timestamp":1710019560,"isMC":true,"question_images":[],"answer_ET":"D","choices":{"A":"Create an AWS Glue job to transform the data from .csv format to Apache Parquet format. Use an AWS Glue crawler and Amazon Athena with appropriate SQL queries to retrieve the required information.","B":"Leave the dataset in .csv format. Use an AWS Glue crawler and Amazon Athena with appropriate SQL queries to retrieve the required information.","D":"Leave the dataset in .csv format. Import the data into Amazon SageMaker Data Wrangler. Use the Data Quality and Insights Report to retrieve the required information.","C":"Create an AWS Glue job to transform the data from .csv format to Apache Parquet format. Import the data into Amazon SageMaker Data Wrangler. Use the Data Quality and Insights Report to retrieve the required information."},"url":"https://www.examtopics.com/discussions/amazon/view/135611-exam-aws-certified-machine-learning-specialty-topic-1/","question_text":"A data scientist receives a new dataset in .csv format and stores the dataset in Amazon S3. The data scientist will use the dataset to train a machine learning (ML) model.\n\nThe data scientist first needs to identify any potential data quality issues in the dataset. The data scientist must identify values that are missing or values that are not valid. The data scientist must also identify the number of outliers in the dataset.\n\nWhich solution will meet these requirements with the LEAST operational effort?","answer_description":"","answer_images":[],"timestamp":"2024-03-09 22:26:00","topic":"1"},{"id":"Ka9jsNTOeJ64PTaAh08W","discussion":[{"timestamp":"1729955400.0","comment_id":"1202669","upvote_count":"2","content":"Correct B.\nIt seems there was a typographical error in the provided options. \"validation'll\" is not a valid metric name. It appears to be an error or a typo.\nB. Tune the csv_weight hyperparameter and the scale_pos_weight hyperparameter by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:f1\", \"Type\": \"Maximize\"}}.","poster":"ggrodskiy"},{"timestamp":"1726630980.0","comment_id":"1176280","upvote_count":"4","poster":"rav009","content":"Selected Answer: B\nthe ll in the option B is recall, there must be some bug make the system miss some charactor."},{"comment_id":"1175637","upvote_count":"1","timestamp":"1726549620.0","content":"Selected Answer: C\nGiven the imbalanced nature of the dataset where only 5% of customers return items, the focus should be on maximizing the model's ability to correctly identify the returned items, which corresponds to maximizing the recall or F1 score. Option C and D aim to optimize the F1 score, but option D specifies minimizing the F1 score, which is incorrect.\n\nC. Tune all possible hyperparameters by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:f1\", \"Type\": \"Maximize\"}}.","poster":"chewasa"},{"timestamp":"1725975000.0","upvote_count":"4","comment_id":"1170410","poster":"F1Fan","content":"B. Tune the csv_weight hyperparameter and the scale_pos_weight hyperparameter by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:recall\", \"Type\": \"Maximize\"}}.\n\nThe dataset is imbalanced, with only 5% of customers returning items (or the positive class). The goal is typically to capture as many instances of the minority class (returned items) as possible, even at the expense of some false positives.\n\nOption D might be incorrect, as the goal is to maximize the model's ability to capture instances of returned items, not minimize the F1 score."},{"content":"Selected Answer: D\nA: No - tuning all hyperparemeters requires compute - not very cost effective\nB: No - Log Loss has to be not applicable to imbalanced dataset\nC: No - tuning all hyperparemeters requires compute - not very cost effective\nD: Yes - F1 metric combines both precision and recall which is more suitable for unbalanced datasets","poster":"AIWave","comment_id":"1169855","upvote_count":"1","timestamp":"1725910800.0","comments":[]}],"exam_id":26,"answer":"B","answers_community":["B (67%)","D (17%)","C (17%)"],"question_id":239,"unix_timestamp":1710020400,"isMC":true,"answer_ET":"B","question_images":[],"choices":{"A":"Tune all possible hyperparameters by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:accuracy\", \"Type\": \"Maximize\"}}.","D":"Tune the csv_weight hyperparameter and the scale_pos_weight hyperparameter by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:f1\", \"Type\": \"Minimize\"}}.","C":"Tune all possible hyperparameters by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:f1\", \"Type\": \"Maximize\"}}.","B":"Tune the csv_weight hyperparameter and the scale_pos_weight hyperparameter by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation'll\", \"Type\": \"Maximize\"}}."},"url":"https://www.examtopics.com/discussions/amazon/view/135612-exam-aws-certified-machine-learning-specialty-topic-1/","question_text":"An ecommerce company has developed a XGBoost model in Amazon SageMaker to predict whether a customer will return a purchased item. The dataset is imbalanced. Only 5% of customers return items.\n\nA data scientist must find the hyperparameters to capture as many instances of returned items as possible. The company has a small budget for compute.\n\nHow should the data scientist meet these requirements MOST cost-effectively?","answer_description":"","answer_images":[],"timestamp":"2024-03-09 22:40:00","topic":"1"},{"id":"rDG6q5scrFAcAI9eZf6a","isMC":true,"choices":{"A":"Use the Hyperband tuning strategy.","E":"Set a lower value for the MaxParallelTrainingJobs parameter.","B":"Increase the number of hyperparameters.","C":"Set a lower value for the MaxNumberOfTrainingJobs parameter.","D":"Use the grid search tuning strategy."},"answer_images":[],"question_id":240,"url":"https://www.examtopics.com/discussions/amazon/view/135662-exam-aws-certified-machine-learning-specialty-topic-1/","question_images":[],"discussion":[{"comment_id":"1558812","content":"Selected Answer: AC\nReducing parallelism increases sequential execution time, making the job take longer overall.","upvote_count":"1","poster":"ef12052","timestamp":"1744092660.0"},{"comment_id":"1300413","upvote_count":"2","poster":"wiss_90","timestamp":"1729423860.0","content":"AE\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-considerations.html#automatic-model-tuning-num-hyperparameters"},{"timestamp":"1726216320.0","poster":"luccabastos","comment_id":"1283076","content":"Selected Answer: AC\n(ChatGPT)\nOption A (Hyperband):\n\nEfficiently utilizes computational resources.\nReduces computation time by early stopping unpromising training jobs.\nAllows for a broader search of hyperparameter space within a shorter time.\nOption C (Lower MaxNumberOfTrainingJobs):\n\nReduces the total number of training jobs.\nDirectly decreases computation time.\nHelps stay within the small compute budget.","upvote_count":"2","comments":[{"content":"stop give GPT answer, GPT may not correct","poster":"sfwewv","comment_id":"1364147","timestamp":"1740954360.0","upvote_count":"1"}]},{"content":"Selected Answer: AE\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-considerations.html#automatic-model-tuning-num-hyperparameters","comment_id":"1204544","poster":"Peter_Hsieh","upvote_count":"4","timestamp":"1714477560.0"},{"timestamp":"1714139280.0","poster":"ggrodskiy","comment_id":"1202637","upvote_count":"1","content":"Correct AE"},{"content":"Selected Answer: AC\nA for sure\nC will reduce the tuning time because we are limiting the no. of Max Training jobs.\n\nE would be find with object is not reducing time","poster":"vkbajoria","timestamp":"1710980040.0","upvote_count":"2","comment_id":"1178868"},{"content":"Selected Answer: AC\nA: Yes - hyperband tuning early stops bad performing tuning jobs and reallocates resources to better performing ones\nB: No - Increase in hyperparams will increase time taken\nC: Yes - Limiting number of tuning jobs causes system not to run through entire list of tuning jobs reducing time\nD: No - grid search is computationally expensive and will take longer\nE: No - will increase time taken","upvote_count":"3","comment_id":"1171794","timestamp":"1710257040.0","poster":"AIWave"},{"content":"A and D surely. Grid search to tune the hyperparameters.Grid search algorithm is more efficient than exhaustive search and will speed up tuning the hyperparameters.","upvote_count":"1","comment_id":"1170483","timestamp":"1710091140.0","poster":"gsw"},{"content":"Option A: Use the Hyperband tuning strategy.\nThe Hyperband tuning strategy is a resource-efficient and time-saving approach for hyperparameter tuning. It works by running a set of hyperparameter configurations for a small number of training iterations and eliminating the poorly performing configurations early on. This strategy can significantly reduce the overall computation time compared to traditional methods like grid search or random search, especially for large hyperparameter spaces or time-consuming models like neural networks.\n\nOption E: Set a lower value for the MaxParallelTrainingJobs parameter.\nThe MaxParallelTrainingJobs parameter in Amazon SageMaker specifies the maximum number of concurrent training jobs to be run in parallel during the hyperparameter tuning process. By setting a lower value for this parameter, the data scientist can limit the amount of computational resources used simultaneously, potentially reducing the overall computation time and cost.","comment_id":"1170413","comments":[{"upvote_count":"1","comment_id":"1180355","timestamp":"1711145100.0","content":"On second thought A,C makes more sense.\n\nC. Set a lower value for the MaxNumberOfTrainingJobs parameter.\n- The MaxNumberOfTrainingJobs parameter specifies the maximum number of training jobs that can be created during the tuning job.\n- Setting a lower value for this parameter will limit the number of training jobs and potentially reduce the computation time.\n- However, it may also limit the exploration of the hyperparameter space and potentially lead to suboptimal results.\n- This option should be considered with caution and in conjunction with other strategies to ensure adequate hyperparameter exploration.","poster":"F1Fan"}],"timestamp":"1710084840.0","poster":"F1Fan","upvote_count":"2"}],"answer_ET":"AC","topic":"1","unix_timestamp":1710084840,"answer":"AC","answers_community":["AC (67%)","AE (33%)"],"question_text":"A data scientist is trying to improve the accuracy of a neural network classification model. The data scientist wants to run a large hyperparameter tuning job in Amazon SageMaker. However, previous smaller tuning jobs on the same model often ran for several weeks. The ML specialist wants to reduce the computation time required to run the tuning job.\n\nWhich actions will MOST reduce the computation time for the hyperparameter tuning job? (Choose two.)","answer_description":"","exam_id":26,"timestamp":"2024-03-10 16:34:00"}],"exam":{"provider":"Amazon","id":26,"isBeta":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Machine Learning - Specialty","isMCOnly":false,"numberOfQuestions":369,"isImplemented":true},"currentPage":48},"__N_SSP":true}