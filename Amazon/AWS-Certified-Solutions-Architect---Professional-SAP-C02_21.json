{"pageProps":{"questions":[{"id":"Hf9vlKmEMDztbThqZZ8h","answer_images":[],"isMC":true,"timestamp":"2022-12-12 17:56:00","question_id":101,"answers_community":["B (100%)"],"question_images":[],"question_text":"A company has a serverless application comprised of Amazon CloudFront, Amazon API Gateway, and AWS Lambda functions. The current deployment process of the application code is to create a new version number of the Lambda function and run an AWS CLI script to update. If the new function version has errors, another CLI script reverts by deploying the previous working version of the function. The company would like to decrease the time to deploy new versions of the application logic provided by the Lambda functions, and also reduce the time to detect and revert when errors are identified.\nHow can this be accomplished?","answer_description":"","exam_id":33,"topic":"1","answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/91242-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"B":"Use AWS SAM and built-in AWS CodeDeploy to deploy the new Lambda version, gradually shift traffic to the new version, and use pre-traffic and post-traffic test functions to verify code. Rollback if Amazon CloudWatch alarms are triggered.","D":"Create and deploy an AWS CloudFormation stack that consists of a new API Gateway endpoint that references the new Lambda version. Change the CloudFront origin to the new API Gateway endpoint, monitor errors and if detected, change the AWS CloudFront origin to the previous API Gateway endpoint.","A":"Create and deploy nested AWS CloudFormation stacks with the parent stack consisting of the AWS CloudFront distribution and API Gateway, and the child stack containing the Lambda function. For changes to Lambda, create an AWS CloudFormation change set and deploy; if errors are triggered, revert the AWS CloudFormation change set to the previous version.","C":"Refactor the AWS CLI scripts into a single script that deploys the new Lambda version. When deployment is completed, the script tests execute. If errors are detected, revert to the previous Lambda version."},"unix_timestamp":1670864160,"discussion":[{"comment_id":"774735","poster":"masetromain","timestamp":"1673631540.0","upvote_count":"29","content":"Selected Answer: B\nAWS Serverless Application Model (SAM) is a framework that helps you build, test and deploy your serverless applications. It uses CloudFormation under the hood, so it is a way to simplify the process of creating, updating, and deploying CloudFormation templates. CodeDeploy is a service that automates code deployments to any instance, including on-premises instances and Lambda functions.\nWith AWS SAM you can use the built-in CodeDeploy to deploy new versions of the Lambda function, gradually shift traffic to the new version, and use pre-traffic and post-traffic test functions to verify code.\nYou can also define CloudWatch Alarms to trigger a rollback in case of any issues.\nThis allows for a faster and more efficient deployment process, as well as a more reliable rollback process when errors are identified. This way you can increase the speed of deployment and reduce the time to detect and revert when errors are identified."},{"comment_id":"1308233","poster":"TariqKipkemei","timestamp":"1730954460.0","upvote_count":"2","content":"Selected Answer: B\nkeywords:\n'Code deployment, reduce deployment time, rollback, serverless' = AWS Serverless Application Model, AWS CodeDeploy"},{"upvote_count":"3","comment_id":"844771","timestamp":"1727062260.0","poster":"5up3rm4n","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html\n\nAWS Serverless Application Model (AWS SAM) comes built-in with CodeDeploy to provide gradual AWS Lambda deployments. With just a few lines of configuration, AWS SAM does the following for you:\n\nDeploys new versions of your Lambda function, and automatically creates aliases that point to the new version.\n\nGradually shifts customer traffic to the new version until you're satisfied that it's working as expected. If an update doesn't work correctly, you can roll back the changes.\n\nDefines pre-traffic and post-traffic test functions to verify that the newly deployed code is configured correctly and that your application operates as expected.\n\nAutomatically rolls back the deployment if CloudWatch alarms are triggered."},{"upvote_count":"3","poster":"atirado","content":"Selected Answer: B\nOption A - This work will allow reverting to previous versions of the Lambda functions but reverting means all functions will be reverted. This does not minimize the the time needed to detect and revert errors.\n\nOption B - This option minimizes the time needed to deploy functions and detect and revert errors: As each function is deployed it can be tested and reverted individually. Moreover, the option provides a straightforward mechanism to detect and revert errors: Detect errors in CloudWatch, fix the functions' code in SAM, redeploy with AWS CodeDeploy.\n\nOption C - This option does not minimize the time needed to detect and revert errors. It only automates the current process.\n\nOption D - This option does not minimize the time needed to detect and revert errors: It takes time for CloudFormation to switch origins and nothing has been done to about the current process for deploying and testing functions.","comment_id":"1101011","timestamp":"1727062260.0"},{"timestamp":"1725905400.0","comment_id":"1281175","poster":"AWSum1","upvote_count":"1","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html\n\nPretty much what the question wants"},{"timestamp":"1725091560.0","comment_id":"1275451","poster":"amministrazione","upvote_count":"1","content":"B. Use AWS SAM and built-in AWS CodeDeploy to deploy the new Lambda version, gradually shift traffic to the new version, and use pre-traffic and post-traffic test functions to verify code. Rollback if Amazon CloudWatch alarms are triggered."},{"content":"why not a？","upvote_count":"2","comment_id":"1231193","poster":"AwsZora","timestamp":"1718509680.0"},{"upvote_count":"1","content":"Selected Answer: B\nB, use SAM to deploy serverless applications on aws","timestamp":"1710610020.0","comment_id":"1175155","poster":"gofavad926"},{"content":"Selected Answer: B\nAnswer B. Use SAM and Codedeploy. Revert if any errors to the previous version.","upvote_count":"1","comment_id":"1087656","timestamp":"1701695640.0","poster":"shaaam80"},{"upvote_count":"1","content":"Selected Answer: B\nobvious","comment_id":"1068314","poster":"severlight","timestamp":"1699766100.0"},{"content":"Selected Answer: B\nrequirmeents : \ndecrease the time to deploy new versions of the application logic provided by the Lambda functions,\nrevert when erros identified","upvote_count":"1","timestamp":"1692752280.0","poster":"whenthan","comment_id":"987851"},{"comment_id":"935959","upvote_count":"1","content":"Selected Answer: B\nB no do0ubt","poster":"NikkyDicky","timestamp":"1687915380.0"},{"comment_id":"934220","timestamp":"1687769700.0","upvote_count":"1","poster":"Jonalb","content":"Selected Answer: B\n100% B"},{"poster":"gameoflove","upvote_count":"1","timestamp":"1683546660.0","comment_id":"892104","content":"Selected Answer: B\nB solve the problem which is causing in the current scenario"},{"comment_id":"874699","timestamp":"1681910460.0","poster":"2aldous","content":"Selected Answer: B\nDefinitile B\nhttps://docs.aws.amazon.com/es_es/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html","upvote_count":"1"},{"comment_id":"852800","poster":"mfsec","upvote_count":"1","timestamp":"1679979960.0","content":"Selected Answer: B\nUse AWS SAM and built-in AWS CodeDeploy"},{"comment_id":"831775","upvote_count":"1","content":"Selected Answer: B\nAWS Serverless Application Model (SAM)","timestamp":"1678185960.0","poster":"kiran15789"},{"upvote_count":"3","content":"Selected Answer: B\nsam typical use case","timestamp":"1671721380.0","poster":"spencer_sharp","comment_id":"753409"},{"comments":[{"comment_id":"743090","timestamp":"1670865840.0","upvote_count":"1","content":"https://www.examtopics.com/discussions/amazon/view/5158-exam-aws-certified-solutions-architect-professional-topic-1/","poster":"masetromain"}],"poster":"masetromain","upvote_count":"2","comment_id":"743060","timestamp":"1670864160.0","content":"Selected Answer: B\nAWS CodeDeploy is intended for this kind of use\nhttps://aws.amazon.com/fr/codedeploy/"}],"answer_ET":"B"},{"id":"yevLNVy2X26SWYOa3b9S","answer_images":[],"isMC":true,"choices":{"C":"Create a CloudFront origin group that has two origins. Set the ALB endpoint as the primary origin. For the secondary origin, set an S3 bucket that is configured to host a static website Set up origin failover for the CloudFront distribution. Update the S3 static website to incorporate the custom error page.","A":"Set up a Route 53 failover routing policy. Configure a health check to determine the status of the ALB endpoint and to fail over to the failover S3 bucket endpoint.","B":"Create a second CloudFront distribution and an S3 static website to host the custom error page. Set up a Route 53 failover routing policy. Use an active-passive configuration between the two distributions.","D":"Create a CloudFront function that validates each HTTP response code that the ALB returns. Create an S3 static website in an S3 bucket. Upload the custom error page to the S3 bucket as a failover. Update the function to read the S3 bucket and to serve the error page to the end users."},"answer_description":"","question_id":102,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/110393-exam-aws-certified-solutions-architect-professional-sap-c02/","answers_community":["C (72%)","D (28%)"],"topic":"1","answer":"C","timestamp":"2023-05-27 20:40:00","exam_id":33,"question_text":"A company runs a web application on AWS. The web application delivers static content from an Amazon S3 bucket that is behind an Amazon CloudFront distribution. The application serves dynamic content by using an Application Load Balancer (ALB) that distributes requests to a fleet of Amazon EC2 instances in Auto Scaling groups. The application uses a domain name setup in Amazon Route 53.\n\nSome users reported occasional issues when the users attempted to access the website during peak hours. An operations team found that the ALB sometimes returned HTTP 503 Service Unavailable errors. The company wants to display a custom error message page when these errors occur. The page should be displayed immediately for this error code.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","discussion":[{"upvote_count":"6","comment_id":"935375","content":"Selected Answer: C\nOrigin Groups in CloudFront is what we need here.","timestamp":"1687870620.0","poster":"pupsik"},{"upvote_count":"5","timestamp":"1687354560.0","comment_id":"929567","content":"Selected Answer: C\nFrom olabiba.ai: \n\nBy using a CloudFront origin group with two origins, you can configure failover between the ALB endpoint and the S3 bucket hosting the static website. This ensures that if the ALB returns HTTP 503 Service Unavailable errors, CloudFront will automatically failover to the S3 bucket and serve the custom error page.\n\nSetting up origin failover for the CloudFront distribution allows for immediate failover to the secondary origin when the primary origin is unavailable. This minimizes the impact of the ALB errors and provides a seamless experience for users by displaying the custom error page.\n\nUpdating the S3 static website to incorporate the custom error page ensures that the error page is readily available and can be served to users without any additional processing or delays.","poster":"Jackhemo"},{"timestamp":"1728584700.0","comment_id":"1295715","content":"Selected Answer: C\nC because of custom error pages \n https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/creating-custom-error-pages.html","poster":"chris_spencer","upvote_count":"1"},{"upvote_count":"4","content":"Selected Answer: D\nA and B are plainly wrong and can be eliminated straight away. The choice therefore is between C and D. The question asks for an immediate display of a custom error page - NOT about permanent failover. Therefore, the correct answer is D.","comments":[{"timestamp":"1737509520.0","upvote_count":"1","comment_id":"1344534","poster":"altonh","content":"D is wrong because of this statement: \"Update the function to read the S3 bucket and serve the error page to the end users.\"\nCloudFront function cannot do any network access."},{"poster":"fartosh","comment_id":"1220505","upvote_count":"1","content":"According to https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/high_availability_origin_failover.html\nCloudFront always tries to serve the content from the primary origin first.\n> CloudFront routes all incoming requests to the primary origin, even when a previous request failed over to the secondary origin. CloudFront only sends requests to the secondary origin after a request to the primary origin fails.\n\nTherefore option C is still valid as it does not leave CloudFront in \"permanent failover\".","timestamp":"1716924360.0"}],"poster":"Dgix","comment_id":"1168160","timestamp":"1709828220.0"},{"timestamp":"1706861580.0","content":"Selected Answer: D\nI go for D: it contains all steps to setup the requested solution, and CloudFront function suits here\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cloudfront-functions.html\n\"URL redirects or rewrites – You can redirect viewers to other pages based on information in the request, or rewrite all requests from one path to another\".","upvote_count":"1","comment_id":"1138291","poster":"chelbsik"},{"content":"Selected Answer: D\n'The company wants to display a custom error message page when these errors occur. The page should be displayed immediately for this error code.' The purpose of the question obviously is to return that error page not really a FAILOVER mechanism --> Leaves D as an asnwer","timestamp":"1706824800.0","upvote_count":"3","comment_id":"1137957","poster":"AimarLeo"},{"timestamp":"1704116340.0","upvote_count":"3","content":"For people are asking why C is better than A:\nThe approach of A is more suited for scenarios where there is a complete failure of the primary endpoint rather than intermittent errors. The health checks may not register a failure if the 502 errors are sporadic and the system is generally operational, thus the failover might not be triggered.\nWith the approach of C CloudFront will always automatically switch to the secondary origin when the primary origin returns specific HTTP status code failure responses.","poster":"carpa_jo","comment_id":"1111205"},{"upvote_count":"2","poster":"Niko13","timestamp":"1703277420.0","content":"Selected Answer: C\nLeast Operational Overhead is C","comment_id":"1103704"},{"content":"Selected Answer: C\nLeast Operational Overhead is C","upvote_count":"2","comment_id":"1078967","poster":"career360guru","timestamp":"1700790000.0"},{"timestamp":"1697816280.0","comment_id":"1048927","upvote_count":"1","comments":[{"content":"Route 53 failover will not be as immediate as C. Cloudfront will immediately seerve up the error page if the request to the primary origin fails, so there is no delay between the primary origin health being degraded and the failover page being served.","timestamp":"1700227740.0","upvote_count":"2","poster":"SuperDuperPooperScooper","comment_id":"1073341"}],"poster":"KCjoe","content":"I know C is good, but why not A, seems to me A is much easier."},{"poster":"bur4an","upvote_count":"1","comment_id":"1007292","content":"Repeat question?","timestamp":"1694673120.0"},{"upvote_count":"3","comments":[{"poster":"hamimelon","comment_id":"1293984","timestamp":"1728267060.0","upvote_count":"1","content":"Route 53 fail over to S3? How can Route 53 display the image?"}],"comment_id":"996647","content":"why not A?","timestamp":"1693636440.0","poster":"kjcncjek"},{"upvote_count":"2","timestamp":"1688584560.0","comment_id":"944068","poster":"NikkyDicky","content":"Selected Answer: C\nit's a C"},{"comment_id":"910693","poster":"rbm2023","upvote_count":"2","content":"Almost went for D but this would take too much operational overhead.","timestamp":"1685495580.0","comments":[{"content":"Option C","poster":"rbm2023","comment_id":"910694","timestamp":"1685495640.0","upvote_count":"1"}]},{"poster":"andreitugui","upvote_count":"3","comment_id":"909342","content":"Selected Answer: C\nAnswer is C, you can use origin groups and configure error response pages in Cloud Front based on different request response codes (503, 404, 403 etc)","timestamp":"1685360040.0"},{"timestamp":"1685212800.0","content":"Answer : C\nhttps://repost.aws/knowledge-center/cloudfront-distribution-serve-content","poster":"Roontha","upvote_count":"3","comment_id":"908164"}],"unix_timestamp":1685212800,"question_images":[]},{"id":"f0C3IrZIqtHLfh693K1n","answers_community":["A (100%)"],"exam_id":33,"answer_description":"","answer_images":[],"timestamp":"2023-05-27 20:33:00","topic":"1","question_id":103,"choices":{"A":"Deploy the application containers by using Amazon Elastic Container Service (Amazon ECS) with the Fargate launch type. Use Amazon Elastic File System (Amazon EFS) for shared storage. Reference the EFS file system ID, container mount point, and EFS authorization IAM role in the ECS task definition.","C":"Deploy the application containers by using Amazon Elastic Container Service (Amazon ECS) with the Amazon EC2 launch type and auto scaling turned on. Use Amazon Elastic File System (Amazon EFS) for shared storage. Mount the EFS file system on the ECS container instances. Add the EFS authorization IAM role to the EC2 instance profile.","D":"Deploy the application containers by using Amazon Elastic Container Service (Amazon ECS) with the Amazon EC2 launch type and auto scaling turned on. Use Amazon Elastic Block Store (Amazon EBS) volumes with Multi-Attach enabled for shared storage. Attach the EBS volumes to ECS container instances. Add the EBS authorization IAM role to an EC2 instance profile.","B":"Deploy the application containers by using Amazon Elastic Container Service (Amazon ECS) with the Fargate launch type. Use Amazon FSx for Lustre for shared storage. Reference the FSx for Lustre file system ID, container mount point, and FSx for Lustre authorization IAM role in the ECS task definition."},"isMC":true,"unix_timestamp":1685212380,"url":"https://www.examtopics.com/discussions/amazon/view/110392-exam-aws-certified-solutions-architect-professional-sap-c02/","question_text":"A company is planning to migrate an application to AWS. The application runs as a Docker container and uses an NFS version 4 file share.\n\nA solutions architect must design a secure and scalable containerized solution that does not require provisioning or management of the underlying infrastructure.\n\nWhich solution will meet these requirements?","answer":"A","question_images":[],"answer_ET":"A","discussion":[{"content":"It's very easy... you read docker => ECS. NFS => EFS, no underlaying infrastructure => Fargate","poster":"chris_spencer","timestamp":"1728668940.0","comment_id":"1296198","upvote_count":"1"},{"comment_id":"1149695","poster":"saggy4","upvote_count":"3","content":"Selected Answer: A\nC and D: Both these options have hassles of EC2 management\nBetween A and B: Mounting FSx for Lustre on an AWS Fargate launch type isn't supported.\n\nHence the correct option is A","timestamp":"1707870600.0"},{"poster":"Niko13","timestamp":"1703277540.0","comment_id":"1103705","upvote_count":"1","content":"Selected Answer: A\nECS, EFS - answer A"},{"content":"Selected Answer: A\nOption A - \nEFS = NFS 4\nFargate = No mgmt or provisioning overheads for servers","poster":"career360guru","timestamp":"1700790540.0","upvote_count":"3","comment_id":"1078971"},{"timestamp":"1688766600.0","content":"Selected Answer: A\nAmazon EFS is a managed NAS filer for EC2 instances based on Network File System (NFS) version 4.","upvote_count":"4","comment_id":"946017","poster":"Christina666"},{"timestamp":"1688584680.0","content":"Selected Answer: A\nA for sure","comment_id":"944069","poster":"NikkyDicky","upvote_count":"1"},{"upvote_count":"2","comment_id":"941268","content":"Selected Answer: A\nA is correct\nB Fsx For Lustre is POSIX Compilance not is correct in this question\nC and D usage EC2 more overhead administrative is incorrect","timestamp":"1688335320.0","poster":"SkyZeroZx","comments":[{"content":"EFS is POSIX Compliant too. A is correct, because EFS file systems can be accessed by Amazon EC2 Linux instances, Amazon ECS, Amazon EKS, AWS Fargate, and AWS Lambda functions via a file system interface such as NFS protocol.","timestamp":"1689044640.0","poster":"Gishpi","upvote_count":"2","comment_id":"948629"}]},{"upvote_count":"2","comment_id":"932316","timestamp":"1687592460.0","content":"Selected Answer: A\nhttps://aws.amazon.com/fsx/when-to-choose-fsx/","poster":"Maria2023"},{"content":"Selected Answer: A\nMust be fargate due to the \"not require provisioning or management of the underlying infra\"\nA or B , tie breaker using EFS and not FSx\nHence option A.","upvote_count":"1","timestamp":"1685495400.0","comment_id":"910691","poster":"rbm2023"},{"comment_id":"909344","poster":"andreitugui","content":"Selected Answer: A\nThe correct answer is A, fargate(no infra management) & efs for NFSv4","upvote_count":"2","timestamp":"1685360220.0"},{"content":"A is correct due to -- NFS version 4.","timestamp":"1685212920.0","poster":"deegadaze1","comment_id":"908165","upvote_count":"3"},{"upvote_count":"1","content":"Answer : A\nhttps://aws.amazon.com/about-aws/whats-new/2017/03/amazon-elastic-file-system-amazon-efs-now-supports-nfsv4-lock-upgrading-and-downgrading/","timestamp":"1685212380.0","poster":"Roontha","comment_id":"908161"}]},{"id":"ZkxS3X8bZFbkTAV7DE0n","discussion":[{"poster":"career360guru","upvote_count":"4","timestamp":"1732413780.0","comment_id":"1078975","content":"Selected Answer: B\nB is better option considering the fact that a customer should get same business logic during testing window. This means we need session stickiness that only option B can provide."},{"upvote_count":"3","timestamp":"1732112100.0","content":"Selected Answer: B\nThis is canary deployment not blue/green","comment_id":"1075459","poster":"Pupu86"},{"timestamp":"1730451840.0","poster":"joleneinthebackyard","content":"Selected Answer: B\nI was struggled between A and B because I overlooked this line \"A customer must use the same version of the business logic during the testing window.\"\nSo we need session stickiness in place, then B is the obvious choice.","comment_id":"1059488","upvote_count":"1"},{"timestamp":"1723976160.0","upvote_count":"1","content":"The problem I have with B is that is does not mention stickiness. The problem I have with A is that the stickiness will work only as long as the DNS entry does not time out...","comments":[{"timestamp":"1723976520.0","content":"Oops. It does mention stickiness...","comment_id":"984373","poster":"aviathor","upvote_count":"1"}],"comment_id":"984365","poster":"aviathor"},{"timestamp":"1721849100.0","content":"Correct B.","upvote_count":"1","comment_id":"961973","poster":"ggrodskiy"},{"content":"Selected Answer: B\nB better","poster":"NikkyDicky","timestamp":"1720207200.0","comment_id":"944071","upvote_count":"1"},{"comment_id":"933679","timestamp":"1719325440.0","upvote_count":"2","poster":"SkyZeroZx","content":"Selected Answer: B\nB ) Classic usage of Blue/Green deployment \nA is good option but not have a stickness with Route 53 more apropiate is ALB with stickness"},{"comment_id":"932331","upvote_count":"1","poster":"Maria2023","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/load-balancer-stickiness/target-group-stickiness.html","timestamp":"1719216120.0"},{"upvote_count":"4","comments":[{"poster":"rbm2023","timestamp":"1717117500.0","upvote_count":"3","content":"https://aws.amazon.com/blogs/aws/new-application-load-balancer-simplifies-deployment-with-weighted-target-groups/","comment_id":"910690"}],"content":"Selected Answer: B\nAgree with B\nblue green deployment, using target group","comment_id":"910688","timestamp":"1717117440.0","poster":"rbm2023"},{"comment_id":"909689","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/aws/new-application-load-balancer-simplifies-deployment-with-weighted-target-groups/","upvote_count":"4","timestamp":"1717013100.0","poster":"F_Eldin"},{"upvote_count":"2","poster":"Roontha","timestamp":"1716833880.0","content":"Answer : B\nhttps://medium.com/capital-one-tech/deploying-with-confidence-strategies-for-canary-deployments-on-aws-7cab3798823e","comment_id":"908155"}],"question_text":"A company is running an application in the AWS Cloud. The core business logic is running on a set of Amazon EC2 instances in an Auto Scaling group. An Application Load Balancer (ALB) distributes traffic to the EC2 instances. Amazon Route 53 record api.example.com is pointing to the ALB.\n\nThe company's development team makes major updates to the business logic. The company has a rule that when changes are deployed, only 10% of customers can receive the new logic during a testing window. A customer must use the same version of the business logic during the testing window.\n\nHow should the company deploy the updates to meet these requirements?","answer":"B","answers_community":["B (100%)"],"choices":{"A":"Create a second ALB, and deploy the new logic to a set of EC2 instances in a new Auto Scaling group. Configure the ALB to distribute traffic to the EC2 instances. Update the Route 53 record to use weighted routing, and point the record to both of the ALBs.","C":"Create a new launch configuration for the Auto Scaling group. Specify the launch configuration to use the AutoScalingRollingUpdate policy, and set the MaxBatchSize option to 10. Replace the launch configuration on the Auto Scaling group. Deploy the changes.","D":"Create a second Auto Scaling group that is referenced by the ALB. Deploy the new logic on a set of EC2 instances in this new Auto Scaling group. Change the ALB routing algorithm to least outstanding requests (LOR). Configure ALB session stickiness.","B":"Create a second target group that is referenced by the ALDeploy the new logic to EC2 instances in this new target group. Update the ALB listener rule to use weighted target groups. Configure ALB target group stickiness."},"question_id":104,"isMC":true,"question_images":[],"timestamp":"2023-05-27 20:18:00","answer_images":[],"topic":"1","answer_ET":"B","answer_description":"","unix_timestamp":1685211480,"exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/110391-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"7ywcw5y5hCRVdf6o44AY","topic":"1","answer_images":[],"isMC":true,"answer":"B","answer_ET":"B","question_id":105,"exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/110340-exam-aws-certified-solutions-architect-professional-sap-c02/","unix_timestamp":1685149920,"question_images":[],"question_text":"A large education company recently introduced Amazon Workspaces to provide access to internal applications across multiple universities. The company is storing user profiles on an Amazon FSx for Windows File Server file system. The file system is configured with a DNS alias and is connected to a self-managed Active Directory. As more users begin to use the Workspaces, login time increases to unacceptable levels.\n\nAn investigation reveals a degradation in performance of the file system. The company created the file system on HDD storage with a throughput of 16 MBps. A solutions architect must improve the performance of the file system during a defined maintenance window.\n\nWhat should the solutions architect do to meet these requirements with the LEAST administrative effort?","answer_description":"","answers_community":["B (56%)","A (44%)"],"timestamp":"2023-05-27 03:12:00","discussion":[{"comments":[{"comment_id":"1025131","upvote_count":"8","poster":"Sab","timestamp":"1696450620.0","content":"Storage type can be modified \nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html"},{"comment_id":"1046679","comments":[{"poster":"AK2020","timestamp":"1697614020.0","content":"So B is correct. my apologies","comment_id":"1046683","upvote_count":"2"}],"timestamp":"1697613960.0","poster":"AK2020","upvote_count":"3","content":"You can change your file system storage type from HDD to SSD using the Amazon FSx console or Amazon FSx API. You can't change your file system storage type from SSD to HDD. So A is correct as we can do this during the downtime"}],"comment_id":"910195","content":"Selected Answer: A\nB is wrong : https://aws.amazon.com/fsx/windows/faqs/#:~:text=A%3A%20While%20you%20cannot%20change,with%20a%20different%20storage%20type.\nI can modify the capacity, but not the type.","timestamp":"1685447160.0","poster":"F_Eldin","upvote_count":"17"},{"poster":"Andres123456","comment_id":"1065818","content":"Selected Answer: B\nStorage type can be modified\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html","upvote_count":"9","timestamp":"1699466280.0"},{"comment_id":"1355751","upvote_count":"1","poster":"820b83f","content":"Selected Answer: A\nMy reasons for its A: \n 1. FSx does not support live storage type changes from HDD to SSD. You must create a new file system.","timestamp":"1739389440.0"},{"poster":"bhanus","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/updating-storage-type.html\n\nHDD can be changed to SSd","timestamp":"1735431540.0","upvote_count":"1","comment_id":"1333230"},{"timestamp":"1734799200.0","comment_id":"1330130","content":"Selected Answer: B\nComparing between A and B, the trade-off decision would be on the key requirement for 'least administrative efforts'. Which seems to be lesser in B, because it's single step but on the other hand on A, there are multiple steps of backup, creating new FSx etc should be of more admin efforts. Hence B.","upvote_count":"1","poster":"SIJUTHOMASP"},{"poster":"pk0619","content":"Selected Answer: B\nYou can update both throughput capacity as well as storage capacity of an existing filesystem","comment_id":"1329838","upvote_count":"1","timestamp":"1734760920.0"},{"content":"Selected Answer: B\nSSD to HDD is impossible, but HDD to SSD is okay => B is feasible. \nB is less effort since B just disconnects users from the file system for a while, and then updates the FSx. While A needs a new FSx, backup, restore, clean up then switch, more steps to do than A","poster":"LuongTo","upvote_count":"2","comment_id":"1320756","timestamp":"1733104920.0"},{"content":"Selected Answer: A\nLet consider that B is correct (updating storage type is possible).\nBetween A and B, A needs the LEAST administrative effort. \nA is seamless for users. However, B requires to disconnect users and thus service interruption and administrative effort to manage that!","upvote_count":"1","timestamp":"1731410280.0","poster":"FZA24","comment_id":"1310540"},{"timestamp":"1729382040.0","content":"Selected Answer: A\nI pity those who are selecting B. \n\nupdating the storage type (from HDD to SSD) is not supported for an existing FSx for Windows File Server file system. You would need to create a new file system to change the storage type. Therefore, this solution is not feasible.","poster":"Sin_Dan","comment_id":"1300217","comments":[{"comment_id":"1330679","content":"https://docs.aws.amazon.com/fsx/latest/WindowsGuide/updating-storage-type.html","timestamp":"1734931440.0","upvote_count":"1","poster":"Zinnia_Wang"}],"upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\n\"You CAN CHANGE your file system storage type from HDD to SSD using the AWS Management Console and AWS CLI.\"\n\"You CANNOT CHANGE your file system storage type from SSD to HDD.\"\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-configuration.html#managing-storage-type","poster":"JoeTromundo","comment_id":"1294414","timestamp":"1728322260.0"},{"comment_id":"1269585","content":"Selected Answer: A\nOption B would be incorrect because it mentions updating the throughput and storage type directly in the FSx console, which is not supported for an existing FSx for Windows File Server.","timestamp":"1724168160.0","poster":"Syre","upvote_count":"1","comments":[{"comment_id":"1274355","timestamp":"1724908920.0","upvote_count":"1","poster":"helloworldabc","content":"just B"}]},{"content":"Selected Answer: B\nB is right answer.","upvote_count":"3","comment_id":"1234455","timestamp":"1718979120.0","poster":"dragongoseki"},{"content":"Selected Answer: B\nSince hdd to ssd type is doable. B is better answer.","upvote_count":"1","poster":"Helpnosense","comment_id":"1234129","timestamp":"1718928720.0"},{"upvote_count":"2","timestamp":"1714850580.0","content":"Selected Answer: A\nAWS Backup to create a point-in-time backup of the existing file system, restoring the backup to a new FSx for Windows File Server file system with SSD storage and higher throughput capacity, adjusting the DNS alias, and deleting the original file system provides the most efficient and least administratively intensive solution to improve the performance of the file system during a defined maintenance window","poster":"Bobshaw","comment_id":"1206633"},{"poster":"seetpt","upvote_count":"1","timestamp":"1714666500.0","content":"Selected Answer: B\nB is correct","comment_id":"1205703"},{"upvote_count":"2","content":"Selected Answer: B\nIt's possible to change storage type from HDD to SSD:\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html\n\n\"B\" is correct because it needs less administrative effort.","timestamp":"1711998000.0","poster":"titi_r","comment_id":"1187624"},{"content":"Selected Answer: B\nchange your file system storage type from HDD to SSD using the Amazon FSx console or Amazon FSx API\n\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html","poster":"CMMC","upvote_count":"3","timestamp":"1710920640.0","comment_id":"1178001"},{"upvote_count":"3","comment_id":"1173510","comments":[{"content":"Plus these give you the \" LEAST administrative effort\" Not A , because the question doesn't ask or states a need to backup data","poster":"TonytheTiger","upvote_count":"1","timestamp":"1710429480.0","comment_id":"1173514"}],"content":"Selected Answer: B\nOption B. Two important points. 1. Changing the storage type. 2. Must improve the performance of the file system during a defined maintenance window. Solution: 1. You can change your file system storage type from HDD to SSD using the Amazon FSx console or Amazon FSx API. You can't change your file system storage type from SSD to HDD. 2. AWS recommend updating your storage type when there is minimal traffic on your file system.\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html","timestamp":"1710429120.0","poster":"TonytheTiger"},{"timestamp":"1709041740.0","comment_id":"1160647","upvote_count":"3","content":"Selected Answer: A\nhttps://aws.amazon.com/fsx/windows/faqs/ Can I change the storage type (SSD/HDD) of my file system?\nWhile you cannot change the storage type on your existing file system, you can take a backup and restore that backup to a new file system with a different storage type.","poster":"yog927","comments":[{"timestamp":"1710897780.0","content":"correct myself it is possible to upgrade from HDD to ssd https://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html","upvote_count":"2","comment_id":"1177865","poster":"yog927"}]},{"content":"Selected Answer: B\nB is possible.","poster":"VerRi","comment_id":"1160256","upvote_count":"4","timestamp":"1709009640.0"},{"upvote_count":"4","content":"I am confused:\nhttps://aws.amazon.com/fsx/windows/faqs/#:~:text=Q%3A%20Can%20I%20change%20the%20storage%20type%20(SSD/HDD)%20of%20my%20file%20system%3F \"While you cannot change the storage type on your existing file system, you can take a backup and restore that backup to a new file system with a different storage type.\"\n\nbut\n\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html\n\nYou can change your file system storage type from HDD to SSD using the Amazon FSx console or Amazon FSx API.","comment_id":"1156623","poster":"marszalekm","timestamp":"1708627980.0"},{"poster":"ninomfr64","content":"Selected Answer: A\nA is correct.\nYou cannot change storage type - https://aws.amazon.com/fsx/windows/faqs/#:~:text=Q%3A%20Can%20I%20change%20the%20storage%20type%20(SSD/HDD)%20of%20my%20file%20system%3F\nWhile you can increase/decrease troughput at any time - https://aws.amazon.com/fsx/windows/faqs/#:~:text=Q%3A%20Can%20I%20change%20my%20file%20system%E2%80%99s%20storage%20capacity%20and%20throughput%20capacity%3F","upvote_count":"3","timestamp":"1706458320.0","comment_id":"1134259"},{"upvote_count":"3","timestamp":"1704295560.0","content":"Selected Answer: A\nWhile you cannot change the storage type on your existing file system, you can take a backup and restore that backup to a new file system with a different storage type.","comment_id":"1112888","poster":"JWalid"},{"timestamp":"1703471340.0","poster":"CProgrammer","upvote_count":"1","content":"[ https://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html#updating-storage-type ] You can update a file system's storage type using the Amazon FSx console, the AWS CLI, or the Amazon FSx API. \n [ https://aws.amazon.com/fsx/windows/faqs/ ]\nQ: Can I change the storage type (SSD/HDD) of my file system?\nA: While you cannot change the storage type on your existing file system, you can take a backup and restore that backup to a new file system with a different storage type.\nRelated Entertainment [ https://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-capacity.html ] \nYou can't increase storage capacity for file systems created before June 23, 2019 or file systems restored from a backup belonging to a file system that was created before June 23, 2019.","comment_id":"1104973"},{"content":"Both A and B can do it but the question says \"Least Administrative effort\". So, it is B.","timestamp":"1703074680.0","poster":"GoKhe","comment_id":"1101511","upvote_count":"2"},{"content":"B is answer. Refer below docs on how to change storage type and update throughput capacity.\n1. https://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-throughput-capacity.html\n2. https://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html","poster":"blackgamer","timestamp":"1702388580.0","comment_id":"1094580","upvote_count":"3"},{"poster":"awsamar","comments":[{"comment_id":"1094327","upvote_count":"2","timestamp":"1702374300.0","content":"So you have answered your query. If you take backup and restore you will still need to disconnect users and connect them to new FS after backup and restore and backup and restore will also take time, so maintenance window will be longer. Since you have to disconnect users in both cases. Disconnect user login to console change settings and connect users back and no change in DNS needed. In first case take backup disconnect users change DNS and then connect users on new FSx","poster":"swadeey"}],"content":"Selected Answer: A\nBetween option A and B, option A would be easier to implement with minimal effort.\nOption A involves creating a point-in-time backup using AWS Backup and restoring it to a new FSx file system. This is an automated process that restores the backed up data to a new file system. Only adjusting the DNS alias is needed to transition users.\nOption B requires manually disconnecting users, making configuration changes in the FSx console to update throughput and storage, and then reconnecting users. This is more manual effort compared to the backup and restore process.","timestamp":"1701758340.0","upvote_count":"2","comment_id":"1088222"},{"comments":[{"timestamp":"1700879340.0","content":"I take that back, FSx does indeed support changing of HDD to SSD:\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html","upvote_count":"2","poster":"heatblur","comment_id":"1079683"}],"timestamp":"1700879100.0","comment_id":"1079681","upvote_count":"2","poster":"heatblur","content":"Selected Answer: A\nA is the answer.\n\nIt can't be B because Amazon FSx does not support in-place upgrades of storage type from HDD to SSD or direct changes to throughput capacity on the existing file system."},{"content":"Selected Answer: B\nleast Administrative effort is option B. Maintenance window is provided so it should be OK. \nOption A requires lot of operational effort and size of the file volume is not mentioned. So B is better option.","upvote_count":"4","poster":"career360guru","comment_id":"1078978","timestamp":"1700791980.0"},{"poster":"severlight","comment_id":"1076124","upvote_count":"3","content":"Selected Answer: B\nit is possible and it fits more with the 'defined maintenance window', because with option A we are going to lose data updated after backup is completed","timestamp":"1700555820.0"},{"upvote_count":"2","comment_id":"1044365","poster":"Certified101","timestamp":"1697393220.0","content":"Selected Answer: B\nB is correct with LEAST administrative effort. Throughput and Storage type can be modified.\n\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html"},{"upvote_count":"2","content":"Selected Answer: B\nAccording to task_7's reference B is correct","comment_id":"1021564","poster":"covabix879","timestamp":"1696083660.0"},{"poster":"task_7","upvote_count":"4","timestamp":"1695902640.0","comments":[{"timestamp":"1696100700.0","comment_id":"1021837","upvote_count":"2","poster":"GeoPat","content":"AWS just added the feature to update from HDD to SDD as of Sept 29, 2023 (check the RSS feed for that link). So go with A becuase they probably havne't updated the test..."}],"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-storage-type.html\nYou can change your file system storage type from HDD to SSD at any time in the Amazon FSx console or Amazon FSx API. You can't change your file system storage type from SSD to HDD. Keep in mind that you can't make further changes to your file system configuration until 6 hours after the last update was requested, or until the storage optimization process has completed, whichever time is longer. Storage optimization can take from a few hours up to a few days to complete. To minimize the time it takes for storage optimization to complete, we recommend updating your storage type when there is minimal traffic on your file system.","comment_id":"1019815"},{"timestamp":"1689703140.0","comment_id":"955726","poster":"Jonalb","content":"Selected Answer: A\nA or D\n\nIts corret more certain A","upvote_count":"2"},{"poster":"NikkyDicky","comment_id":"944072","content":"Selected Answer: A\ngo with A","timestamp":"1688584980.0","upvote_count":"2"},{"comment_id":"939647","timestamp":"1688192220.0","upvote_count":"2","poster":"javitech83","content":"Selected Answer: A\ncorrect is A. There is a maintenance windows so there can be service outage"},{"poster":"TECHNOWARRIOR","timestamp":"1687071360.0","content":"Selected answer A: Considering the time constraints of the maintenance window and the requirement for the least administrative effort, it might be more efficient to focus on optimizing the existing file system directly. This could involve adjusting the storage configuration, increasing throughput, or optimizing the file system settings to improve performance.\n\nBy concentrating on the file system itself, the administrative effort can be minimized, and the maintenance window can be utilized more effectively to address the degradation in performance. This approach allows for a targeted and streamlined solution without introducing the complexities of deploying and managing DataSync.","upvote_count":"1","comment_id":"926488"},{"comments":[{"comment_id":"1137973","timestamp":"1706827680.0","upvote_count":"2","poster":"AimarLeo","content":"Datasync does not an agent when moving data between different aws storage services. Agent is needed only for On-prem or other CSP"}],"timestamp":"1685802960.0","poster":"chathur","content":"Selected Answer: A\nC is wrong as datasync does need an agent to migrate data between two AWS Services.","upvote_count":"4","comment_id":"913686"},{"comment_id":"908630","timestamp":"1685276100.0","content":"A is correct.\nC \"Deploy an aws datasync agent onto a new amazon ec2 instance\" is not right, should be \n\"Deploy an aws datasync agent as an amazon ec2 instance\", see \nhttps://docs.aws.amazon.com/datasync/latest/userguide/deploy-agents.html#ec2-deploy-agent\n\"To learn how to transfer files from an existing in-cloud file system to your FSx for Windows File Server, see Deploy your agent as an Amazon EC2 instance in the AWS DataSync User Guide. \"\n\nBackup can also do the backups for FSx\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/using-backups.html#aws-backup-and-fsx","poster":"Jesuisleon","comments":[{"timestamp":"1685276400.0","comments":[{"comment_id":"908635","upvote_count":"3","poster":"Jesuisleon","content":"Q: Can I change the storage type (SSD/HDD) of my file system?\n\"A: While you cannot change the storage type on your existing file system, you can take a backup and restore that backup to a new file system with a different storage type.\"\nfrom https://aws.amazon.com/fsx/windows/faqs/\nhere \" take a backup and restore\" also proves aws backup is the right answer.","timestamp":"1685276460.0"}],"upvote_count":"1","comment_id":"908632","content":"\"We recommend using AWS DataSync to transfer data between FSx for Windows File Server file systems. DataSync is a data transfer service that simplifies, automates, and accelerates moving and replicating data between on-premises storage systems and other AWS storage services over the internet or AWS Direct Connect. \" https://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-files-to-fsx-datasync.html \nhere we can see datasync is used between on-premises and aws storage services. the scenario in the question is already in aws. so datasync is not right.","poster":"Jesuisleon"}],"upvote_count":"1"},{"upvote_count":"4","comment_id":"908457","timestamp":"1685265000.0","content":"Selected Answer: B\nI am thinking is B. Refer https://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-throughput-capacity.html","comments":[{"comment_id":"910152","content":"my bad, change answer to A, as it needs change disk type as well\nQ: Can I change the storage type (SSD/HDD) of my file system?\n\nA: While you cannot change the storage type on your existing file system, you can take a backup and restore that backup to a new file system with a different storage type.","poster":"ShinLi","timestamp":"1685442660.0","upvote_count":"1"}],"poster":"ShinLi"},{"poster":"Roontha","upvote_count":"2","comment_id":"907684","timestamp":"1685149920.0","content":"Answer : C\n\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-files-to-fsx-datasync.html","comments":[{"comment_id":"908146","poster":"Roontha","upvote_count":"1","comments":[{"comments":[{"poster":"geoakes","timestamp":"1685747100.0","comment_id":"913077","content":"Not C. Why I would go with A is that the question states \"during a defined maintenance window.\" - DataSync tends to be more than just a maintenance window that the service is operating. So 'A' makes the most sense. Maintenance window also implies any clients that need disconnecting / reconnecting as well plus your not adding to operational overhead of new services and instances","upvote_count":"1"}],"timestamp":"1685445720.0","content":"Still sticking with C as per https://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-files-to-fsx-datasync.html#migrating-between-two-systems","comment_id":"910184","upvote_count":"1","poster":"ahmedferdous"}],"content":"Agree with Answer : A\nhttps://www.youtube.com/watch?v=pGZhlg6-gqY\n(AWS re:Invent 2020: Deep dive on Amazon FSx for Windows File Server)\n\nC option is valid only when end user want to to perform individual files/folders (i.e self service).\n\nBut question is asking about entire system","timestamp":"1685210400.0"}]}],"choices":{"A":"Use AWS Backup to create a point-in-time backup of the file system. Restore the backup to a new FSx for Windows File Server file system. Select SSD as the storage type. Select 32 MBps as the throughput capacity. When the backup and restore process is completed, adjust the DNS alias accordingly. Delete the original file system.","B":"Disconnect users from the file system. In the Amazon FSx console, update the throughput capacity to 32 MBps. Update the storage type to SSD. Reconnect users to the file system.","D":"Enable shadow copies on the existing file system by using a Windows PowerShell command. Schedule the shadow copy job to create a point-in-time backup of the file system. Choose to restore previous versions. Create a new FSx for Windows File Server file system with SSD storage and 32 MBps of throughput. When the copy job is completed, adjust the DNS alias. Delete the original file system.","C":"Deploy an AWS DataSync agent onto a new Amazon EC2 instance. Create a task. Configure the existing file system as the source location. Configure a new FSx for Windows File Server file system with SSD storage and 32 MBps of throughput as the target location. Schedule the task. When the task is completed, adjust the DNS alias accordingly. Delete the original file system."}}],"exam":{"name":"AWS Certified Solutions Architect - Professional SAP-C02","isImplemented":true,"isBeta":false,"isMCOnly":true,"numberOfQuestions":529,"id":33,"lastUpdated":"11 Apr 2025","provider":"Amazon"},"currentPage":21},"__N_SSP":true}