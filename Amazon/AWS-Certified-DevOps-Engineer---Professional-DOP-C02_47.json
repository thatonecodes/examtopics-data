{"pageProps":{"questions":[{"id":"b2KwUNJTwvPAg7w56oQn","exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/152245-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_images":[],"answer":"ACF","choices":{"A":"Deploy the CloudWatch agent and Fluent Bit to the cluster. Ensure that the EKS cluster has appropriate permissions to send metrics and logs to CloudWatch.","B":"Deploy AWS Distro for OpenTelemetry to the cluster. Ensure that the EKS cluster has appropriate permissions to send metrics and logs to CloudWatch.","D":"Create a CloudWatch composite alarm to monitor a metric log filter of the CPU, memory, and node metrics of the cluster. Configure the alarm to send an SNS email notification to the DevOps team when anomalies are detected.","F":"Create a CloudWatch alarm to monitor a metric log filter of the Autoscaler deployments for errors. Configure the alarm to send an SNS email notification to the DevOps team if thresholds are exceeded.","E":"Create a CloudWatch alarm to monitor the logs of the Autoscaler deployments for errors. Configure the alarm to send an SNS email notification to the DevOps team if thresholds are exceeded.","C":"Create CloudWatch alarms to monitor the CPU, memory, and node failure metrics of the cluster. Configure the alarms to send an SNS email notification to the DevOps team if thresholds are exceeded."},"isMC":true,"topic":"1","unix_timestamp":1732784460,"question_text":"A company has deployed an Amazon Elastic Kubernetes Service (Amazon EKS) cluster with Amazon EC2 node groups. The company's DevOps team uses the Kubernetes Horizontal Pod Autoscaler and recently installed a supported EKS cluster Autoscaler.\n\nThe DevOps team needs to implement a solution to collect metrics and logs of the EKS cluster to establish a baseline for performance. The DevOps team will create an initial set of thresholds for specific metrics and will update the thresholds over time as the cluster is used. The DevOps team must receive an Amazon Simple Notification Service (Amazon SNS) email notification if the initial set of thresholds is exceeded or if the EKS cluster Autoscaler is not functioning properly.\n\nThe solution must collect cluster, node, and pod metrics. The solution also must capture logs in Amazon CloudWatch.\n\nWhich combination of steps should the DevOps team take to meet these requirements? (Choose three.)","answers_community":["ACF (80%)","10%","10%"],"timestamp":"2024-11-28 10:01:00","answer_description":"","question_images":[],"answer_ET":"ACF","question_id":231,"discussion":[{"timestamp":"1743547740.0","upvote_count":"1","content":"Selected Answer: ACF\nExplanation\nTo collect logs and metrics from the EKS cluster, nodes, and pods, and to ensure notifications are sent when thresholds are exceeded, we need:\n\nA mechanism to collect logs and metrics (Option A).\nAlarms for key cluster performance metrics (Option C).\nAlarms to detect Autoscaler failures (Option F).","poster":"Srikantha","comment_id":"1418775"},{"timestamp":"1735548000.0","upvote_count":"1","comment_id":"1333991","comments":[{"comment_id":"1333999","poster":"matt200","upvote_count":"2","content":"change my mind to ACF","timestamp":"1735548600.0"}],"poster":"matt200","content":"Selected Answer: BCE\nCorrect:\n\n B. Deploy AWS Distro for OpenTelemetry (ADOT):\nADOT is the recommended solution for collecting metrics and logs from EKS clusters\n\n\n E. Create CloudWatch alarm for Autoscaler logs:\n Monitors Autoscaler functionality through log analysis\n\nWrong:\nA. Deploy CloudWatch agent and Fluent Bit:\n While this would work, it's not the recommended approach for EKS\nF. Create CloudWatch alarm with metric log filter for Autoscaler:\n Direct log monitoring (Option E) is more appropriate"},{"upvote_count":"3","content":"Selected Answer: ACF\nA collects metrics and logs, C create the alarms and F monitors the auto scaler","comment_id":"1324597","timestamp":"1733837760.0","poster":"luisfsm_111"},{"comment_id":"1321788","timestamp":"1733303640.0","content":"Selected Answer: ACE\nThe question asks to \"collect metrics and logs\".\nYou need to install the CloudWatch Agent which is A.\nYou need to collect metrics which is C.\nYou need to collect logs which is E.","upvote_count":"1","poster":"tinyshare"},{"upvote_count":"4","content":"Selected Answer: ACF\nA- To collect the cloudwatch logs and send to cloudwatch service.\nC - To setup Alarms\nF - To monitor and alert","timestamp":"1732784460.0","poster":"ArunRav","comment_id":"1319126"}]},{"id":"ThJBqoB8w73fsI3k5y6e","exam_id":23,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/151709-exam-aws-certified-devops-engineer-professional-dop-c02/","topic":"1","isMC":true,"answer":"D","choices":{"B":"Use AWS Backup to create a backup vault and a custom backup plan that has a 10-minute frequency. Specify the DR Region as the target Region. Assign the EC2 instances in the production Region to the backup plan.","C":"Create an AWS Lambda function to create snapshots of the instance store volumes that are attached to the EC2 instances. Configure the Lambda function to copy the snapshots to the DR Region and to remove the previous copies. Create an Amazon EventBridge scheduled rule that invokes the Lambda function every 10 minutes.","D":"Create an FSx for ONTAP instance in the DR Region. Configure a 5-minute schedule for a volume-level NetApp SnapMirror to replicate the volume from the production Region to the DR Region.","A":"Create an Amazon S3 bucket in both Regions. Configure S3 Cross-Region Replication (CRR) for the S3 buckets. Create a scheduled AWS Lambda function to copy any new content from the FSx for ONTAP volume to the S3 bucket in the production Region."},"unix_timestamp":1732121640,"question_text":"A company discovers that its production environment and disaster recovery (DR) environment are deployed to the same AWS Region. All the production applications run on Amazon EC2 instances and are deployed by AWS CloudFormation. The applications use an Amazon FSx for NetApp ONTAP volume for application storage. No application data resides on the EC2 instances.\n\nA DevOps engineer copies the required AMIs to a new DR Region. The DevOps engineer also updates the CloudFormation code to accept a Region as a parameter. The storage needs to have an RPO of 10 minutes in the DR Region.\n\nWhich solution will meet these requirements?","answers_community":["D (100%)"],"timestamp":"2024-11-20 17:54:00","answer_description":"","question_images":[],"answer_ET":"D","question_id":232,"discussion":[{"comment_id":"1418788","upvote_count":"1","timestamp":"1743548640.0","content":"Selected Answer: D\nOption D: Use FSx for ONTAP SnapMirror with a 5-minute replication schedule.\nThis ensures continuous, low-latency replication and meets the 10-minute RPO requirement efficiently.","poster":"Srikantha"},{"poster":"matt200","comment_id":"1331368","upvote_count":"2","timestamp":"1735104720.0","content":"Selected Answer: D\nshould be D"},{"content":"Implementation Steps :\nCreate an FSx for ONTAP Instance in the DR Region:\n\nDeploy an FSx for NetApp ONTAP instance in the new DR Region.\nSet Up SnapMirror Replication:\n\nConfigure SnapMirror from the FSx volume in the production Region to the FSx instance in the DR Region.\nSet the replication schedule to 5 minutes to meet the 10-minute RPO requirement.\nTest the DR Setup:\n\nVerify that the replicated volume in the DR Region is consistent and accessible.\nEnsure that the DR environment can failover to the replicated FSx volume.\nUpdate CloudFormation:\n\nEnsure the updated CloudFormation templates can deploy EC2 instances in the DR Region and mount the replicated FSx volume.","upvote_count":"2","timestamp":"1732121640.0","poster":"f4b18ba","comment_id":"1315406"}]},{"id":"K0KBbhZDCrZ9dwSPBINz","question_text":"During a security audit, a company discovered that some security groups allow SSH traffic from 0.0.0.0/0. A security team must implement a solution to detect and remediate this issue as soon as possible. The company uses one organization in AWS Organizations to manage all the company's AWS accounts.\n\nWhich solution will meet these requirements?","answer":"C","answer_description":"","unix_timestamp":1732067220,"isMC":true,"timestamp":"2024-11-20 02:47:00","exam_id":23,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/151655-exam-aws-certified-devops-engineer-professional-dop-c02/","question_images":[],"answers_community":["C (100%)"],"answer_images":[],"answer_ET":"C","choices":{"B":"Create an AWS Lambda function in each AWS account to delete all the security group rules. Create an Amazon EventBridge rule to match security group update events or creation events. Set the Lambda function in each account as a target for the rule.","A":"Enable AWS Config for all AWS accounts. Use a periodic trigger to activate the vpe-sg-port-restriction-check AWS Config rule. Create an AWS Lambda function to remediate any noncompliant rules.","C":"Enable AWS Config for all AWS accounts. Create a custom AWS Config rule to run on the restricted-ssh configuration change trigger. Configure the rule to invoke an AWS Lambda function to remediate any noncompliant resources.","D":"Create an AWS Systems Manager Automation document in each account to inspect all security groups and to delete noncompliant rules. Use an Amazon EventBridge rule to run the Automation document every hour."},"discussion":[{"comment_id":"1418792","upvote_count":"1","timestamp":"1743549240.0","content":"Selected Answer: C\nOption C: AWS Config + real-time rule evaluation + Lambda remediation.\nThis provides real-time security enforcement across all accounts.","poster":"Srikantha"},{"poster":"Slays","upvote_count":"4","timestamp":"1734264960.0","content":"Selected Answer: C\nThis option involves enabling AWS Config across all accounts, deploying the restricted-ssh rule, and setting up automatic remediation to address non-compliant security groups, thereby meeting the requirements efficiently.","comment_id":"1326843"},{"upvote_count":"4","comment_id":"1315004","content":"C\nwhy not A:\n\nThe vpe-sg-port-restriction-check AWS Config rule is not specific to this use case.\nThe periodic trigger does not provide real-time detection, potentially delaying remediation.","poster":"phu0298","timestamp":"1732067220.0"}],"question_id":233},{"id":"OfKTpJlAXUj0zn5WRIU6","question_images":[],"answer":"B","topic":"1","unix_timestamp":1733061900,"discussion":[{"upvote_count":"1","poster":"Srikantha","comment_id":"1418795","content":"Selected Answer: B\nption B: Install the AWS Systems Manager Agent (SSM Agent) on all VMs. Use the SSM Agent to install the package. Use AWS Config to monitor for configuration drift. Use Amazon SNS to notify the system administrator if any drift is found.","timestamp":"1743549900.0"},{"timestamp":"1733061900.0","poster":"gunjan229","content":"Selected Answer: B\nCoorect Ans B","comment_id":"1320583","upvote_count":"3"}],"answer_ET":"B","answer_images":[],"timestamp":"2024-12-01 15:05:00","url":"https://www.examtopics.com/discussions/amazon/view/152430-exam-aws-certified-devops-engineer-professional-dop-c02/","answers_community":["B (100%)"],"answer_description":"","question_id":234,"choices":{"C":"Write a script that checks if the package is installed across the environment. Configure the script to create a list of all VMs that are noncompliant. Configure the script to send the list to the system administrator, who will install the package on the noncompliant VMs.","D":"Log in to each VM. Use a local package manager to install the package. Use AWS Config to monitor the AWS resources for configuration changes. Write a script to monitor the on-premises resources.","A":"Write a script that iterates through the list of VMs once a week. Configure the script to check for the package and install the package if the package is not found. Configure the script to send an email message notification to the system administrator if the package is not found.","B":"Install the AWS Systems Manager Agent (SSM Agent) on all VMs. Use the SSM Agent to install the package. Use AWS Config to monitor for configuration drift. Use Amazon Simple Notification Service (Amazon SNS) to notify the system administrator if any drift is found."},"question_text":"A company's DevOps engineer must install a software package on 30 on-premises VMs and 15 Amazon EC2 instances.\n\nThe DevOps engineer needs to ensure that all VMs receive the package in a process that is auditable and that any configuration drift on the VMs is automatically identified and alerted on. The company uses AWS Direct Connect to connect its on-premises data center to AWS.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","exam_id":23,"isMC":true},{"id":"jCDCJLDUNeGwOFWXhsWy","timestamp":"2023-04-05 22:25:00","question_text":"A company has migrated its container-based applications to Amazon EKS and want to establish automated email notifications. The notifications sent to each email address are for specific activities related to EKS components. The solution will include Amazon SNS topics and an AWS Lambda function to evaluate incoming log events and publish messages to the correct SNS topic.\nWhich logging solution will support these requirements?","question_id":235,"isMC":true,"answer_images":[],"question_images":[],"exam_id":23,"unix_timestamp":1680726300,"choices":{"C":"Enable Amazon S3 logging for the EKS components. Configure an Amazon CloudWatch subscription filter for each component with Lambda as the subscription feed destination.","A":"Enable Amazon CloudWatch Logs to log the EKS components. Create a CloudWatch subscription filter for each component with Lambda as the subscription feed destination.","B":"Enable Amazon CloudWatch Logs to log the EKS components. Create CloudWatch Logs Insights queries linked to Amazon EventBridge events that invoke Lambda.","D":"Enable Amazon S3 logging for the EKS components. Configure S3 PUT Object event notifications with AWS Lambda as the destination."},"answer_description":"","answer_ET":"A","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/105336-exam-aws-certified-devops-engineer-professional-dop-c02/","answer":"A","answers_community":["A (97%)","3%"],"discussion":[{"poster":"tartarus23","upvote_count":"15","content":"Selected Answer: A\nCorrect Answer is A. \nExplanation:\nAmazon EKS integrates with CloudWatch Logs to provide detailed logs of the state and execution of the services in the cluster. CloudWatch subscription filters can be used to route specific log events from a CloudWatch Logs group to a Lambda function. The Lambda function can then process the events and publish notifications to the appropriate Amazon SNS topic.","timestamp":"1703025780.0","comment_id":"927913"},{"comment_id":"1168810","poster":"4555894","upvote_count":"3","timestamp":"1725793980.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters.html#LambdaFunctionExample\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters.html"},{"poster":"zijo","comment_id":"1166684","timestamp":"1725554940.0","upvote_count":"1","content":"AWS EKS itself does not offer native S3 logging for container logs. CloudWatch Logs Insights queries cannot directly link to Amazon EventBridge events. So the answer here is A."},{"timestamp":"1724109180.0","content":"Selected Answer: A\nCloudWatch Logs subscription filtering is a feature that allows capture log data in real time and forward it to other AWS services such as Kinesis Data Firehose, Kinesis Streams, and Lambda.","comment_id":"1154396","upvote_count":"1","poster":"dzn"},{"timestamp":"1722264300.0","comment_id":"1135118","poster":"thanhnv142","upvote_count":"3","content":"A is correct: Use cloudwatch logs to collect logs from EKS. Use subcription filter to filter out logs and only send relevant logs to lambda to trigger it. \nB: CloudWatch Logs Insights is for data analysis. Additionally, using EventBridge events to trigger lambda incur costs\nC and D: Amazon S3 logging is used for monitoring actions on S3 itself, not EKS"},{"upvote_count":"4","poster":"z_inderjot","content":"Selected Answer: A\nA is right \nC, D are wrong , because there is not integration in EKS to send logs to s3. \nB is for log analysis , and aggreation","timestamp":"1718938740.0","comment_id":"1102190"},{"comments":[{"poster":"zolthar_z","comment_id":"1074827","upvote_count":"2","content":"No, sorry, this was for the previous questions","timestamp":"1716135600.0"}],"comment_id":"1074810","content":"Selected Answer: B\nI don't have a technical reason but others dumps shows B as the Answer","poster":"zolthar_z","timestamp":"1716134340.0","upvote_count":"1"},{"content":"Selected Answer: A\nA, metric filter can call Lambda.","timestamp":"1702649220.0","comment_id":"924159","poster":"madperro","upvote_count":"1"},{"comment_id":"911231","timestamp":"1701353880.0","poster":"rdoty","upvote_count":"1","content":"Selected Answer: A\ncertainly cloudwatch logs metric filter A"},{"timestamp":"1698895440.0","poster":"haazybanj","comment_id":"886945","upvote_count":"1","content":"Selected Answer: A\nA. Enable Amazon CloudWatch Logs to log the EKS components. Create a CloudWatch subscription filter for each component with Lambda as the subscription feed destination.\n\nThis solution involves enabling Amazon CloudWatch Logs to log the EKS components and creating a CloudWatch subscription filter for each component with AWS Lambda as the subscription feed destination. This approach will allow the Lambda function to evaluate incoming log events and publish messages to the correct Amazon SNS topic. Amazon SNS can then send email notifications to each email address based on the messages it receives from the corresponding SNS topic."},{"poster":"ele","upvote_count":"1","content":"Selected Answer: A\nA, clear","timestamp":"1697379300.0","comment_id":"870978"},{"poster":"alce2020","content":"A is the correct answer","comment_id":"870485","upvote_count":"1","timestamp":"1697319600.0"},{"content":"Selected Answer: A\nAmazon CloudWatch Logs can log the EKS components, and subscription filters can be created for each component with AWS Lambda as the subscription feed destination. The Lambda function can evaluate incoming log events and publish messages to the appropriate Amazon SNS topic, enabling automated email notifications to be sent. Therefore, option A is the correct solution. Option C is incorrect because Amazon S3 logging is not designed for logging EKS components.","comment_id":"870380","poster":"jqso234","timestamp":"1697305860.0","upvote_count":"1"},{"upvote_count":"3","poster":"Dimidrol","content":"Selected Answer: A\nA for sure","timestamp":"1696537500.0","comment_id":"862454"}]}],"exam":{"isMCOnly":true,"name":"AWS Certified DevOps Engineer - Professional DOP-C02","lastUpdated":"11 Apr 2025","isImplemented":true,"id":23,"numberOfQuestions":355,"isBeta":false,"provider":"Amazon"},"currentPage":47},"__N_SSP":true}