{"pageProps":{"questions":[{"id":"WGbIbtrR5zPG7lDRCy44","answer_description":"","timestamp":"2023-01-13 11:02:00","unix_timestamp":1673604120,"answers_community":["A (97%)","3%"],"topic":"1","discussion":[{"comment_id":"776549","upvote_count":"24","content":"Selected Answer: A\nA. Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic\n\nAWS Storage Gateway is a service that connects an on-premises software appliance with cloud-based storage to provide seamless and secure integration between an organization's on-premises IT environment and AWS's storage infrastructure. By deploying a file gateway as a virtual machine on each clinic's premises, the medical research lab can provide low-latency access to the data stored in the S3 bucket while maintaining read-only permissions for each clinic. This solution allows the clinics to access the data files directly from their on-premises file-based applications without the need for data transfer or migration.","poster":"mhmt4438","timestamp":"1689417900.0"},{"comment_id":"936678","upvote_count":"8","poster":"cookieMr","timestamp":"1703775600.0","content":"A. It allows the clinics to access the data files stored in the S3 bucket through a file interface. The file gateway caches frequently accessed data locally, reducing latency and providing fast access to the data.\n\nB. It involves transferring the data files from the Amazon S3 bucket to each clinic's on-premises applications using AWS DataSync. While this enables data migration, it may not provide real-time access and may introduce additional latency.\n\nC. It is suitable for block-level access to data rather than file-level access. It may not be the most efficient solution for file-based applications.\n\nD. It involves using Amazon EFS, which is a scalable file storage service, to provide file-level access to the data. However, it may introduce additional complexity and latency compared to using a file gateway solution."},{"timestamp":"1740063420.0","comment_id":"1359309","upvote_count":"1","content":"Selected Answer: A\nAWS Storage File Gateway is the most suitable here.","poster":"satyaammm"},{"timestamp":"1719549720.0","content":"Selected Answer: A\nA: does exactly that is required here\nB: \"Migrate\", as to MOVE the files out from S3, doesn't make sense\nC: Volume Gateway provides iSCSI volumes backed by an object in AWS-managed S3, it does not provide access to S3 objects\nD: You can do that but it would have high (not \"minimum\") latency, and the data is not in that EFS volume, it's in S3","comment_id":"1107513","poster":"pentium75","upvote_count":"5"},{"upvote_count":"2","poster":"Ruffyit","comment_id":"1089239","content":"AWS Storage Gateway is a service that connects an on-premises software appliance with cloud-based storage to provide seamless and secure integration between an organization's on-premises IT environment and AWS's storage infrastructure. By deploying a file gateway as a virtual machine on each clinic's premises, the medical research lab can provide low-latency access to the data stored in the S3 bucket while maintaining read-only permissions for each clinic. This solution allows the clinics to access the data files directly from their on-premises file-based applications without the need for data transfer or migration.","timestamp":"1717665240.0"},{"comment_id":"1017391","upvote_count":"4","timestamp":"1711437240.0","content":"Selected Answer: A\nThe Amazon S3 File Gateway enables you to store and retrieve objects in Amazon Simple Storage Service (S3) using file protocols such as Network File System (NFS) and Server Message Block (SMB). Objects written through S3 File Gateway can be directly accessed in S3.","poster":"TariqKipkemei"},{"comment_id":"1004824","timestamp":"1710169320.0","poster":"Guru4Cloud","content":"Selected Answer: A\nA. Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic","upvote_count":"3"},{"timestamp":"1701330960.0","content":"Selected Answer: A\nOption A meets the requirements.","poster":"Bmarodi","upvote_count":"2","comment_id":"910879"},{"content":"For File-based applications use File Gateway: (Option A)","upvote_count":"2","timestamp":"1697830800.0","comment_id":"875958","poster":"jaswantn"},{"upvote_count":"5","poster":"Grace83","content":"Definitely A. \nWhy are there so many wrong answers by Admins?","comment_id":"844550","timestamp":"1695178860.0","comments":[{"upvote_count":"3","poster":"maggie135","comment_id":"939762","content":"I guess to force us to read and think, so one can't just memorize the answer and go to exam ?)","timestamp":"1704106560.0"}]},{"poster":"AlessandraSAA","timestamp":"1693644720.0","content":"Selected Answer: A\nAmazon S3 File Gateway enables you to store file data as objects in Amazon S3 cloud storage for data lakes, backups, and Machine Learning workflows. With Amazon S3 File Gateway, each file is stored as an object in Amazon S3 with a one-to-one mapping between a file and an object.\n\nVolume Gateway provides block storage volumes over iSCSI, backed by Amazon S3, and provides point-in-time backups as Amazon EBS snapshots. Volume Gateway integrates with AWS Backup, an automated and centralized backup service, to protect Storage Gateway volumes.\n\nSo it's A","comment_id":"826754","upvote_count":"5"},{"poster":"Steve_4542636","comment_id":"826118","upvote_count":"2","content":"Selected Answer: A\nA for answer","timestamp":"1693581900.0"},{"comment_id":"796346","upvote_count":"2","poster":"bdp123","content":"Selected Answer: A\nhttps://cloud.in28minutes.com/aws-certification-aws-storage-gateway","timestamp":"1690995480.0"},{"comment_id":"785048","upvote_count":"2","content":"Selected Answer: A\nA. Deploy an AWS Storage Gateway file gateway...","timestamp":"1690087500.0","poster":"kbaruu"},{"comment_id":"780223","upvote_count":"2","timestamp":"1689691200.0","poster":"imisioluwa","content":"Selected Answer: A\nThe correct answer is A.\n https://www.knowledgehut.com/tutorials/aws/aws-storage-gateway#:~:text=AWS%20Storage%20Gateway%20helps%20in%20connecting,as%20well%20as%20providing%20data%20security.&text=AWS%20Storage%20Gateway%20helps,as%20providing%20data%20security.&text=Gateway%20helps%20in%20connecting,as%20well%20as%20providing \nhttps://docs.aws.amazon.com/storagegateway/latest/vgw/WhatIsStorageGateway.html"},{"comments":[{"content":"Volume gateway provides an iSCSI volume and stores that as a single object in an AWS-managed S3 bucket. It does not provide access to S3 objects.","timestamp":"1719549600.0","poster":"pentium75","comment_id":"1107511","upvote_count":"2"}],"upvote_count":"2","content":"Selected Answer: C\nI think C (Volume Gateway) is correct as it has an option to have Local Storage with Asynchronous sync with S3. This would give low latency access to all local files not just cached/recent files.","timestamp":"1689394140.0","comment_id":"776196","poster":"venice1234"},{"upvote_count":"2","timestamp":"1689382200.0","content":"Selected Answer: A\nhttps://aws.amazon.com/storagegateway/file/","comment_id":"776126","poster":"laicos"},{"upvote_count":"2","timestamp":"1689355980.0","comment_id":"775867","content":"Selected Answer: A\nA. Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic","poster":"Aninina"},{"content":"Selected Answer: A\nIt's A imo (file gatewat)","timestamp":"1689235320.0","upvote_count":"3","poster":"Morinator","comment_id":"774320"}],"isMC":true,"exam_id":31,"answer_images":[],"question_id":181,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/95002-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"A","answer_ET":"A","question_text":"A medical research lab produces data that is related to a new study. The lab wants to make the data available with minimum latency to clinics across the country for their on-premises, file-based applications. The data files are stored in an Amazon S3 bucket that has read-only permissions for each clinic.\n\nWhat should a solutions architect recommend to meet these requirements?","choices":{"A":"Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic","C":"Deploy an AWS Storage Gateway volume gateway as a virtual machine (VM) on premises at each clinic.","D":"Attach an Amazon Elastic File System (Amazon EFS) file system to each clinic’s on-premises servers.","B":"Migrate the files to each clinic’s on-premises applications by using AWS DataSync for processing."}},{"id":"e6iDe2UsJVAIepD9i0Vs","timestamp":"2023-01-14 21:46:00","question_images":[],"isMC":true,"answer_ET":"C","answers_community":["C (98%)","2%"],"exam_id":31,"answer":"C","topic":"1","answer_images":[],"question_text":"A company is using a content management system that runs on a single Amazon EC2 instance. The EC2 instance contains both the web server and the database software. The company must make its website platform highly available and must enable the website to scale to meet user demand.\n\nWhat should a solutions architect recommend to meet these requirements?","discussion":[{"comments":[{"timestamp":"1701332880.0","poster":"Bmarodi","comment_id":"910910","content":"Very good explanations!","upvote_count":"2"}],"upvote_count":"23","comment_id":"776553","timestamp":"1689418140.0","content":"Selected Answer: C\nC. Move the database to Amazon Aurora with a read replica in another Availability Zone. Create an Amazon Machine Image (AMI) from the EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones.\n\nThis approach will provide both high availability and scalability for the website platform. By moving the database to Amazon Aurora with a read replica in another availability zone, it will provide a failover option for the database. The use of an Application Load Balancer and an Auto Scaling group across two availability zones allows for automatic scaling of the website to meet increased user demand. Additionally, creating an AMI from the original EC2 instance allows for easy replication of the instance in case of failure.","poster":"mhmt4438"},{"comment_id":"936900","timestamp":"1703788200.0","content":"Selected Answer: C\nOption A does not provide a solution for high availability or scalability. Manually launching another EC2 instance in the same AZ may not ensure high availability, as a failure in that AZ would result in downtime.\n\nOption B improves database performance and provides a level of fault tolerance, it does not address the scalability aspect of the website platform.\n\nOption C provides both high availability and fault tolerance. Creating an AMI allows for easy replication of the EC2 instance across AZs. Configuring an ALB in two AZs and attaching an ASG ensures scalability and load distribution across multiple instances.\n\nOption D does not provide the high availability and scalability required by the company. Scheduled backups to S3 address data protection but do not contribute to website availability or scalability.","poster":"cookieMr","upvote_count":"6"},{"timestamp":"1740063540.0","comment_id":"1359311","upvote_count":"1","poster":"satyaammm","content":"Selected Answer: C\nAurora with read replica in different region is the most suitable here."},{"content":"Selected Answer: C\nC is the only option via deduction logic based on the assumption the CMS database is Aurora compatible. Other solutions don't promise scaling as much as Aurora solution in option C does.","comment_id":"1111355","timestamp":"1719845640.0","poster":"awsgeek75","comments":[{"upvote_count":"4","timestamp":"1721236920.0","poster":"awsgeek75","comment_id":"1125251","content":"Just to clarify, the question is vague as we don't know anything about the DB types on the CMS so making an assumption that Aurora will work with the CMS."}],"upvote_count":"2"},{"comment_id":"1107517","poster":"pentium75","timestamp":"1719550020.0","upvote_count":"5","content":"Selected Answer: C\nA and B involve manual steps and do not include scaling (it's just two fixed instances)\nD scales the application part but leaves the database on a single EC2 instance which would be neither \"highly available\" nor \"scaleable\""},{"upvote_count":"2","comment_id":"1089245","timestamp":"1717665540.0","content":"C. Move the database to Amazon Aurora with a read replica in another Availability Zone. Create an Amazon Machine Image (AMI) from the EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones.","poster":"Ruffyit"},{"timestamp":"1711437360.0","poster":"TariqKipkemei","comment_id":"1017393","content":"Selected Answer: C\nMove the database to Amazon Aurora with a read replica in another Availability Zone. Create an Amazon Machine Image (AMI) from the EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones.","upvote_count":"2"},{"timestamp":"1710168360.0","poster":"Guru4Cloud","upvote_count":"2","comment_id":"1004811","content":"Selected Answer: C\nC. Move the database to Amazon Aurora with a read replica in another Availability Zone. Create an Amazon Machine Image (AMI) from the EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones."},{"timestamp":"1706379300.0","poster":"MutiverseAgent","upvote_count":"1","comment_id":"964886","content":"Selected Answer: D\nThe question does not say if the current application is using a relational database, so how we can be sure that it can moved to RDS or aurora as answers A, B & C states? In my opinion the right answer is D.","comments":[{"poster":"pentium75","upvote_count":"2","content":"In D, you \"move the database to a separate EC2 instance\" BEFORE creating the AMI for the Auto Scaling group. So you'd still have a single EC2 instance running the database, which would meet neither the availability nor the scalability requirement.","comment_id":"1107515","timestamp":"1719549900.0"}]},{"timestamp":"1704283140.0","poster":"animefan1","comment_id":"941684","upvote_count":"2","content":"Selected Answer: C\nhas all options needed for HA"},{"upvote_count":"2","timestamp":"1701332580.0","comment_id":"910905","poster":"Bmarodi","content":"Selected Answer: C\nOption C meets the requirements."},{"timestamp":"1700797080.0","content":"Why not D?\n\nAre we just assuming that there will be no write to the db?","comment_id":"905412","upvote_count":"1","poster":"ssoffline"},{"upvote_count":"2","content":"Selected Answer: C\nAbsolutely C.","comment_id":"903811","poster":"antropaws","timestamp":"1700644980.0"},{"content":"Selected Answer: C\nC: This will allow the website platform to be highly available by using Aurora, which provides automatic failover and replication. Additionally, by creating an AMI from the original EC2 instance, the Auto Scaling group can automatically launch new instances in multiple availability zones and use the Application Load Balancer to distribute traffic across them. This way, the website will be able to handle the increased traffic, and will be less likely to go down due to a single point of failure.","upvote_count":"3","comment_id":"775915","poster":"Aninina","timestamp":"1689360360.0"}],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/95336-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"A":"Move the database to Amazon RDS, and enable automatic backups. Manually launch another EC2 instance in the same Availability Zone. Configure an Application Load Balancer in the Availability Zone, and set the two instances as targets.","D":"Move the database to a separate EC2 instance, and schedule backups to Amazon S3. Create an Amazon Machine Image (AMI) from the original EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones.","B":"Migrate the database to an Amazon Aurora instance with a read replica in the same Availability Zone as the existing EC2 instance. Manually launch another EC2 instance in the same Availability Zone. Configure an Application Load Balancer, and set the two EC2 instances as targets.","C":"Move the database to Amazon Aurora with a read replica in another Availability Zone. Create an Amazon Machine Image (AMI) from the EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones."},"unix_timestamp":1673729160,"question_id":182},{"id":"hvtJzpcf6zfIMlGJonDo","isMC":true,"discussion":[{"comment_id":"776557","timestamp":"1673787360.0","comments":[{"timestamp":"1674545040.0","upvote_count":"10","comment_id":"786252","poster":"JayBee65","comments":[{"upvote_count":"4","poster":"pentium75","timestamp":"1703749320.0","content":"But it will keep the number of instances at two, while the production environment has \"AT LEAST two\".","comment_id":"1107530"}],"content":"No, it will not reduce the number of instances being used, since a minimum of 2 will be used at all times."}],"upvote_count":"20","poster":"mhmt4438","content":"Selected Answer: D\nD. Reduce the maximum number of EC2 instances in the development environment’s Auto Scaling group\n\nThis option will configure the development environment in the most cost-effective way as it reduces the number of instances running in the development environment and therefore reduces the cost of running the application. The development environment typically requires less resources than the production environment, and it is unlikely that the development environment will have periods of high traffic that would require a large number of instances. By reducing the maximum number of instances in the development environment's Auto Scaling group, the company can save on costs while still maintaining a functional development environment."},{"comment_id":"1107537","timestamp":"1703749560.0","upvote_count":"10","poster":"pentium75","content":"Selected Answer: D\nA modifies only the ALB target group (= directs traffic only to one node), but does not affect the number of nodes (and the cost)\nB balances load between nodes but does not affect the cost\nC impacts the prod environment so that would be unable to handle its \"periods of high traffic\"\nD makes sure that the dev environment will not scale to more than 2 instances, as does the prod environment"},{"comment_id":"1410346","poster":"jerryl","content":"Selected Answer: D\nanalysis/explanation by copilot\n> A: you reduce the target group instance, doesnt mean the other one is shut down / terminated (sound tricky but could be true, it didnt mention the other machine is terminated)\n> D: that make sure only 1 machine is always up\nin that case then D would make more sense (disregard the high availability concern, A is still more costly then)","upvote_count":"1","timestamp":"1742992440.0"},{"upvote_count":"1","comment_id":"1402004","timestamp":"1742667840.0","content":"Selected Answer: A\nA. This is the most cost-effective approach for a development environment. Since development environments typically don't need the same level of high availability or performance as production, reducing the number of target EC2 instances to one minimizes costs.\nD. Reducing the maximum size of the Auto Scaling group can limit scaling, but it doesn't guarantee cost savings if those instances are running. Reconfiguring the target group to use only one instance is a more direct way to reduce costs in the development environment.","poster":"SirDNS"},{"comment_id":"1350539","poster":"zdi561","content":"Selected Answer: A\nD is not right, if you decrease max number it will not meet the high traffic requirement. Actually it does not matter because the ASG will automatically adjust the running target. A really means set the max, min and desired to one which can save a little bit money, The requirement for two really means the min is 2 in prod. max could be higher than 2.","timestamp":"1738512540.0","upvote_count":"1"},{"comment_id":"1284668","timestamp":"1726489140.0","comments":[{"upvote_count":"1","comment_id":"1316585","poster":"LeonSauveterre","content":"Weird... ChatGPT says to choose D when I asked about this question. It said option A compromises high availability because ALBs require at least two targets for redundancy and fault tolerance, so not a valid option due to the risk of downtime if the single instance becomes unavailable, while option D provides targeted cost optimization for the development environment without compromising availability or production performance.","timestamp":"1732342260.0"},{"content":"Answer is A, option A says reduce(rec9nfigure) the instance in target group to one, makes sense. If a group has only implemented instance, it's not autoscall8ng.","comment_id":"1305600","upvote_count":"1","timestamp":"1730414580.0","poster":"babayomi"}],"poster":"XXXXXlNN","upvote_count":"2","content":"chatGPT sucks too. it says A, but A abviously just says reduced the number of Target Group, reduce Target Group does not mean the reduce of EC2 instances themself, so there is no cost saved at all. Thus DDDDDDDDDD...."},{"upvote_count":"3","content":"Selected Answer: D\nSo, in short, the question asks for a way to reduce cost wasted with the dev env, since it's resources are being underused. \n\n(A)Target group vs (B) Auto Scaling Group.\n\nReducing the target group won't affect the number of \"nodes\" (instances), cost will stay the same. To eliminate the excess of ec2 instances in the dev env, you actually need to reduce the auto scaling group.","comment_id":"1279935","poster":"MatAlves","timestamp":"1725697320.0"},{"poster":"TheFivePips","comment_id":"1159922","timestamp":"1708964160.0","upvote_count":"4","content":"Selected Answer: D\nThe application uses an Application Load Balancer (ALB) to direct traffic to at least two Amazon EC2 instances in a single target group\n\nYou are required to keep at least two instances in each target group. A sets it to one, which would be more cost effective, but doesnt meet the requirement."},{"upvote_count":"5","poster":"Priyapani","content":"Selected Answer: D\nIn the question it is said minimum it should have 2 instances in Target group. So in development group we can reduce the the target group. \nIn option A. It is said it will have only one instance in development group that doesn't match to our question","timestamp":"1705061160.0","comment_id":"1120736"},{"content":"Selected Answer: D\nB and C don't actually save any cost without impacting performance during high traffic on production.\nA and D are basically same thing but A enforces a limit of one EC2 instance which is not acceptable as the question asks: \"Application Load Balancer (ALB) to direct traffic to at least two Amazon EC2 instances in a single target group. The instances are in an Auto Scaling group for each environment\" \nHence D is the only valid answer.","comment_id":"1111356","upvote_count":"6","timestamp":"1704128460.0","poster":"awsgeek75"},{"timestamp":"1703610840.0","poster":"ddaanndann","upvote_count":"1","comments":[{"comment_id":"1107532","timestamp":"1703749380.0","upvote_count":"4","content":"No, you're confusing \"target group\" (of the ALB) with \"Auto Scaling group\". Answer A will direct ALB traffic only to one node, but it does not affect the number of nodes in any way (it will still be \"at least two\").","poster":"pentium75"}],"content":"The most cost-effective solution is to reconfigure the target group in the development environment to have only one EC2 instance as a target. This will ensure that the development environment only uses the resources that it needs, which will save the company money.\n\nThe other solutions are not as cost-effective. Changing the ALB balancing algorithm to least outstanding requests will not reduce the number of EC2 instances that are used, and it may actually increase the amount of traffic that is directed to each instance. Reducing the size of the EC2 instances will also not reduce the number of instances that are used, and it may actually make the application slower. Reducing the maximum number of EC2 instances in the development environment's Auto Scaling group will only reduce the number of instances that are used when the traffic is high, and it will not reduce the number of instances that are used on average.\n\nTherefore, the most cost-effective solution is to reconfigure the target group in the development environment to have only one EC2 instance as a target.","comment_id":"1106246"},{"poster":"chasingsummer","content":"Selected Answer: A\nBy reconfiguring the target group in the development environment to have only one EC2 instance as a target, it reduces the number of instances handling the development environment's traffic. This ensures the minimum setup required for the development environment's functionality without incurring unnecessary costs associated with multiple instances.\n\nThis solution optimizes costs by scaling down the infrastructure specifically in the development environment where lower traffic or fewer resources might be acceptable for testing or development purposes, thus reducing unnecessary expenses related to running multiple instances.","upvote_count":"1","comments":[],"timestamp":"1703339100.0","comment_id":"1104042"},{"content":"Selected Answer: D\nthe correct answer is D. This is from Amazon Q : The most cost-effective way to configure the development environment would be to reduce the maximum number of EC2 instances in the development environment's Auto Scaling group (Option D). The most cost-effective way to configure the development environment would be to reduce the maximum number of EC2 instances in the development environment's Auto Scaling group (Option D).The most cost-effective way to configure the development environment would be to reduce the maximum number of EC2 instances in the development environment's Auto Scaling group (Option D).","comment_id":"1103851","upvote_count":"4","poster":"MiniYang","timestamp":"1703302860.0"},{"comments":[{"timestamp":"1709388120.0","content":"\"might not directly optimize.\" No, it does, you're paying less for fewer machines. This is the most direct cost optimisation practice there could ever be. The correct answer is D","comment_id":"1164142","poster":"saymolet","upvote_count":"1"}],"poster":"meowruki","timestamp":"1701309960.0","content":"Selected Answer: A\nOption D: Reducing the maximum number of EC2 instances in the development environment's Auto Scaling group could limit scalability but might not directly optimize costs. Min can still be the same number of EC2","upvote_count":"1","comment_id":"1083917"},{"content":"Answear is A but I'am not agree. We use only one instance with A and D.\nBut with D, by default, instance is terminated whereas with A, instance still exist.\nAnswear should be D","poster":"Chef_couincouin","upvote_count":"3","comment_id":"1081686","timestamp":"1701097860.0"},{"comment_id":"1058271","timestamp":"1698699060.0","poster":"ravinperera","content":"Selected Answer: D\nThis option is specific to the development environment and focuses on reducing the number of instances that can be spun up during scaling events. This means cost savings because fewer instances will be used even if the scaling policies are triggered.\nGiven the goal to configure the development environment in the most cost-effective way, without compromising the production environment, the best option is D","upvote_count":"3"},{"upvote_count":"1","comment_id":"1019566","content":"Selected Answer: A\nOption A","poster":"Mandar15","timestamp":"1695885900.0"},{"upvote_count":"1","comments":[{"upvote_count":"3","content":"Wrong, think more. A reduces to one instance whereas: \n\n\"The application uses an Application Load Balancer (ALB) to direct traffic to at least two Amazon EC2 instances in a single target group\"\n\nThe ALB NEEDS at least 2 instances so where is your second instance?","comment_id":"1125254","poster":"awsgeek75","timestamp":"1705519680.0"}],"content":"Selected Answer: A\nwont think much about this, option A is the most cost effective","comment_id":"1017396","poster":"TariqKipkemei","timestamp":"1695705780.0"},{"comment_id":"1015173","upvote_count":"2","comments":[{"upvote_count":"2","poster":"pentium75","timestamp":"1703749440.0","content":"No, you're confusing \"target group\" (of the ALB) with \"Auto Scaling group\". Answer A will direct ALB traffic only to one node, but it does not affect the number of nodes in any way (it will still be \"at least two\").","comment_id":"1107535"}],"poster":"Its_SaKar","timestamp":"1695492180.0","content":"Selected Answer: A\nOption A because it can't be option D as there should be at least two EC2 instances in Auto scaling group, and can't be reduced to one as said in option D.\n\nSo, simply reconfigure the target group in the development environment to have only one EC2 instance as a target as said in option A to reduce cost."},{"content":"Selected Answer: D\nOption A because it can't be option D as there should be at least two EC2 instances in Auto scaling group, and can't be reduced to one as said in option D.\n\nSo, simply reconfigure the target group in the development environment to have only one EC2 instance as a target as said in option A to reduce cost.","upvote_count":"2","poster":"Its_SaKar","comment_id":"1015170","comments":[{"timestamp":"1695492240.0","content":"plz remove this comment as i mistakely voted option D here. I have posted another comment above.","comment_id":"1015178","poster":"Its_SaKar","upvote_count":"1"}],"timestamp":"1695492120.0"},{"timestamp":"1694436120.0","content":"Selected Answer: A\nA. Reconfigure the target group in the development environment to have only one EC2 instance as a target","comment_id":"1004808","poster":"Guru4Cloud","upvote_count":"2"},{"comment_id":"997436","timestamp":"1693726800.0","upvote_count":"1","content":"Selected Answer: A\nI choose A but cannot understand this question, which environment handles the traffic? The question is not clearly for have correct answer.","poster":"kwang312"},{"upvote_count":"1","poster":"yhonatan2288","timestamp":"1691791500.0","content":"Selected Answer: A\nEl entorno de desarrollo generalmente no necesita manejar la misma cantidad de tráfico que el entorno de producción y, por lo tanto, puede tener una infraestructura más pequeña para ahorrar costos. Al configurar solo una instancia EC2 como objetivo en el grupo de Auto Scaling del entorno de desarrollo, estarás reduciendo los costos operativos al tener menos recursos activos y consumiendo menos instancias EC2.","comment_id":"979006"},{"poster":"cookieMr","timestamp":"1687970040.0","content":"Selected Answer: A\nBy configuring the target group in the development environment to have only one EC2 instance as a target, you are effectively reducing the resources allocated to that environment. This helps minimize costs by utilizing fewer EC2 instances and associated resources.\n\nOption B does not directly address the cost-effectiveness of the development environment. It focuses on load balancing strategies rather than cost optimization.\n\nOption C may not be the most cost-effective solution unless the current instance sizes are over-provisioned or unnecessary for the application's requirements.\n\nOption D can help reduce costs, but it may impact the environment's ability to handle traffic and scale efficiently, especially during periods of increased load.\n\nOverall, option A provides a cost-effective approach by minimizing the resources allocated to the development environment while still maintaining a functional setup.","comment_id":"936910","upvote_count":"5"},{"poster":"MrAWSAssociate","timestamp":"1686906840.0","comment_id":"925006","content":"I think option D is true, only in case we have multipe target groups, but remember in the question it has been mentioned that there is only single target group. If we do what option \"D\" indicated in a single target group, it will affect the production group too. Therefore, I think option A is more reasonable.","upvote_count":"1"},{"comment_id":"917420","poster":"ChrisAn","content":"Selected Answer: A\nA# By reducing the number of EC2 instances in the target group of the development environment to just one, you can lower the cost associated with running multiple instances. Since the development environment typically has lower traffic and does not require the same level of availability and scalability as the production environment, having a single instance is sufficient for testing and development purposes.","comments":[{"poster":"markw92","comment_id":"927634","upvote_count":"1","content":"I also thought D is the answer but after careful reading of the question, the current minimum number of ec2 are 2, so even though we reduce the auto scaling group to minimum, it still leaves 2 in dev env. I think A is the answer. Pretty tricky and we have to pay attention to small details.","timestamp":"1687188660.0"}],"upvote_count":"4","timestamp":"1686156480.0"},{"poster":"Bmarodi","content":"Selected Answer: A\nOption A is most-effective.","timestamp":"1685515020.0","upvote_count":"1","comment_id":"910916"},{"upvote_count":"2","poster":"michellemeloc","comment_id":"900129","content":"Selected Answer: A\nJust A reduce the cost effectively. D COULD reduce, but not reduce immediately.","timestamp":"1684326660.0"},{"timestamp":"1681451340.0","poster":"ErfanKh","upvote_count":"4","content":"Selected Answer: A\nI am voting A here, there is no need for Autoscaling since we can just set dev environment to 1 EC2 instance which would be the lowest cost.","comment_id":"869983"},{"content":"Honestly this question is useless, there's nothing wrong with the existing environment","poster":"Kenzo","timestamp":"1680784500.0","upvote_count":"2","comment_id":"862957"},{"timestamp":"1678448820.0","comment_id":"834914","content":"Selected Answer: D\nif specify only one instance in target group, \nwe dont have any merit for using auto scale group\ni think so i go with d","upvote_count":"3","poster":"[Removed]"},{"content":"Selected Answer: A\nit's A (D does not reduce €)","poster":"HaineHess","timestamp":"1678027500.0","upvote_count":"3","comment_id":"829980"},{"poster":"Steve_4542636","timestamp":"1677692400.0","content":"Selected Answer: A\nDev doesn't need autoscaling so setting it to one is the most COST effective solution, not the most operationally efficient","comment_id":"826130","upvote_count":"3"},{"poster":"K0nAn","timestamp":"1677594180.0","comment_id":"824899","upvote_count":"3","content":"Selected Answer: A\nSince option D says that decrease max number ,it will not affect minimum number which 2 ,it will be always same ,so option A makes sense for me"},{"comments":[{"upvote_count":"2","comment_id":"826131","poster":"Steve_4542636","content":"Group here refers to auto scaling group. Target refers to ec2 instances","timestamp":"1677692580.0","comments":[{"poster":"Steve_4542636","content":"Nm, delete this comment","upvote_count":"1","timestamp":"1677692820.0","comment_id":"826133"}]}],"content":"Selected Answer: D\nYou cant use a Target Group to change ASG behavior guys . \n\nALB's Target Group is pointing to an ASG . So no amount to TG tweaking is going to lead to a scale in opportunity on ASG side .","timestamp":"1677247500.0","upvote_count":"2","poster":"AlmeroSenior","comment_id":"820576"},{"content":"Selected Answer: D\nhttps://medium.com/dnx-labs/reducing-aws-costs-by-turning-off-development-environments-at-night-the-easy-way-without-lambda-c7b40abc7287","poster":"bdp123","comment_id":"808750","timestamp":"1676403300.0","upvote_count":"2"},{"poster":"G3","content":"B.\n\nhttps://aws.amazon.com/about-aws/whats-new/2019/11/application-load-balancer-now-supports-least-outstanding-requests-algorithm-for-load-balancing-requests/","comments":[{"upvote_count":"1","comment_id":"928969","poster":"joechen2023","content":"This link talk about how the healthy instance is selected/routed. It will not reduce cost if multiple EC2 are up","timestamp":"1687314120.0"}],"comment_id":"806457","timestamp":"1676213820.0","upvote_count":"3"},{"upvote_count":"1","timestamp":"1675453320.0","comment_id":"797309","poster":"joric","content":"Selected Answer: C\nI choose C: Reduce the size of the EC2 instances in both environments.\n they are gona use 2 at minimum anyway because they need the availability if you set the maximum to 100 instances its not gona cost more because it will only use 2 and then lets say 3 or 4 for for a period of high load and scale back to 2. if you reduce the size of the instances they will still be runing at 2 most of the time but will cost less."},{"poster":"aws4myself","content":"Selected Answer: D\nA is wrong - if it is an auto-scaling group, then if you remove it from the target group also it will not be deleted/ terminated. So there is no cost reduction.\n\nBut for D, if you reduce the max capacity, EC2 will be terminated.","upvote_count":"3","comment_id":"788523","timestamp":"1674721320.0"},{"timestamp":"1674623640.0","comment_id":"787288","poster":"kerl","content":"my opinion, A is wrong, if you remove the instance in the Target Group, ASG will reprovision to match the minimum/desire number of instance. I choose D because i can configure my ASG to assigned minimum / maximum to 1. ASG will automatically create the instanced and add into the Target Group. If u delete the instance, ASG will reprovison and readd into the Target Group. So A is wrong. Answer is D","comments":[{"poster":"Michal_L_95","content":"But the question states:\n\"The application uses an Application Load Balancer (ALB) to direct traffic to at least two Amazon EC2 instances in a single target group.\"\nWhich means that we can not reduce number of instances to 1 as each stage is different target group","upvote_count":"1","comments":[{"timestamp":"1677182460.0","poster":"Michal_L_95","upvote_count":"1","comment_id":"819678","content":"Sorry under wrong comment. D is ok."}],"comment_id":"819675","timestamp":"1677182340.0"}],"upvote_count":"4"},{"content":"A is correct. D will not save costs unless the development environment has a heavy load placed upon it, and it requires the current maximum number or instances, which is pretty unlikely in a development environment. For most (all?) of the time, it will continue to run 2 EC2 instances (the minimum number) when these are unlikely to be required. A will however reduce the number of EC2 instances being used in development from 2 to 1, so will actually save money.","upvote_count":"1","timestamp":"1674544980.0","poster":"JayBee65","comment_id":"786250","comments":[]},{"upvote_count":"3","comments":[{"content":"This is the correct answer. Why do we need to scale development environment if the load is constant?","timestamp":"1674507180.0","upvote_count":"2","poster":"Karlos99","comment_id":"785825"}],"comment_id":"781886","content":"Selected Answer: A\nA: Reconfigure the target group in the development environment to have only one EC2 instance as a target.\nD will defeat the purpose of having the EC2 in an auto scaling group because limiting it to only one instance means it can't auto-scale over that single instance.","poster":"LuckyAro","timestamp":"1674189600.0"},{"poster":"forzadejan","timestamp":"1673765280.0","content":"D. Reduce the maximum number of EC2 instances in the development environment’s Auto Scaling group.\nThis option will reduce the number of instances running in the development environment, which will decrease the cost of running the environment. The other options do not directly address the cost of running the development environment.","comment_id":"776215","upvote_count":"2"},{"comment_id":"775922","timestamp":"1673729940.0","poster":"Aninina","upvote_count":"3","content":"Selected Answer: D\nD. Reduce the maximum number of EC2 instances in the development environment’s Auto Scaling group\nThis will help to configure the development environment more cost-effectively as it reduces the maximum number of instances that can be launched at a time, which in turn reduces the costs associated with running the instances. Since the development environment is not expected to experience periods of high traffic, it will not require as many instances as the production environment, thus reducing costs.\nIt's worth noting that if the traffic is not high and the instances are not being utilized, the cost of running instances is the same as having them idle. So, the best cost-effective solution will be to have the minimum number of instances that can handle the traffic and scale it up as needed."}],"unix_timestamp":1673729940,"question_images":[],"answer":"D","question_id":183,"url":"https://www.examtopics.com/discussions/amazon/view/95337-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"answers_community":["D (63%)","A (36%)","1%"],"answer_description":"","question_text":"A company is launching an application on AWS. The application uses an Application Load Balancer (ALB) to direct traffic to at least two Amazon EC2 instances in a single target group. The instances are in an Auto Scaling group for each environment. The company requires a development environment and a production environment. The production environment will have periods of high traffic.\n\nWhich solution will configure the development environment MOST cost-effectively?","choices":{"D":"Reduce the maximum number of EC2 instances in the development environment’s Auto Scaling group.","B":"Change the ALB balancing algorithm to least outstanding requests.","C":"Reduce the size of the EC2 instances in both environments.","A":"Reconfigure the target group in the development environment to have only one EC2 instance as a target."},"answer_images":[],"topic":"1","answer_ET":"D","timestamp":"2023-01-14 21:59:00"},{"id":"yrbxjUiD54sAx7NgcSJV","url":"https://www.examtopics.com/discussions/amazon/view/95003-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"choices":{"C":"Update the route tables for the EC2 instances’ subnets to send 0.0.0.0/0 traffic through the internet gateway route. Add a rule to the EC2 instances’ security groups to allow outbound traffic to 0.0.0.0/0.","D":"Create public subnets in each Availability Zone. Associate the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets.","B":"Move the EC2 instances to public subnets. Add a rule to the EC2 instances’ security groups to allow outbound traffic to 0.0.0.0/0.","A":"Replace the ALB with a Network Load Balancer. Configure a NAT gateway in a public subnet to allow internet traffic."},"answer_description":"","topic":"1","discussion":[{"comments":[{"comment_id":"838778","upvote_count":"8","content":"Completely agreed, I was looking for an option to allow HTTPS traffic on port 443 from the ALB to the EC2 instance's security group.\n\nEither the question or the answers are wrong.","timestamp":"1694683500.0","poster":"UnluckyDucky"}],"poster":"ktulu2602","comment_id":"829785","timestamp":"1693898160.0","content":"I think either the question or the answers are not formulated correctly because of this document:\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/load-balancer-stickiness/subnets-routing.html\nA - Might be possible but it's quite impractical\nB - Not needed as the setup described should work as is provided the SGs of the EC2 instances accept traffic from the ALB\nC - Update the route tables for the EC2 instances’ subnets to send 0.0.0.0/0 traffic through the internet gateway route - not needed as the EC2 instances would receive the traffic from the ALB ENIs. Add a rule to the EC2 instances’ security groups to allow outbound traffic to 0.0.0.0/0 - the default behaviour of the SG is to allow outbound traffic only.\nD - Create public subnets in each Availability Zone. Associate the public subnets with the ALB - if it's a internet facing ALB these should already be in place. Update the route tables for the public subnets with a route to the private subnets - no need as the local prefix entry in the route tables would take care of this point\n\nI'm 110% sure the question or answers or both are wrong. Prove me wrong! :)","upvote_count":"21"},{"comment_id":"817979","upvote_count":"15","poster":"bdp123","content":"Selected Answer: D\nI change my answer to 'D' because of following link:\nhttps://aws.amazon.com/premiumsupport/knowledge-center/public-load-balancer-private-ec2/","timestamp":"1692710940.0"},{"upvote_count":"3","poster":"JackyCCK","content":"Can a EC2 in the private subnet sends traffic to the internet through ELB without using NAT gateway/instance?\nif it's only about responses to requests coming through the ELB then no, you don't need NAT. If on the other hand you expect that your instances will need to initiate connections as oppose to just sending responses to the requests then yes, you will have to use NAT. The key point is that response to a request is not a new connection and will be sent to where it came from, i.e. to the ELB.\n\nhttps://serverfault.com/questions/986447/can-a-ec2-in-the-private-subnet-sends-traffic-to-the-internet-through-elb-withou","comment_id":"1189499","timestamp":"1728067800.0"},{"timestamp":"1725954960.0","comment_id":"1170210","content":"D looks the best but still it must have a internet gateway and once it has internet gateway we must add the route table for private subnet to talk to the public subnet so by using the it should be able to access. I don't think lb can act like internet gateway","poster":"sidharthwader","upvote_count":"2"},{"upvote_count":"2","timestamp":"1724326140.0","comment_id":"1156379","content":"Selected Answer: D\nConsidering these statements:\n-The EC2 instances are in private subnets.\n- However, the internet traffic is not reaching the EC2 instances.\nA reliable solution is D according to following link:\nhttps://repost.aws/knowledge-center/public-load-balancer-private-ec2\nAnswer C could not satisfy the requirements because only outbound traffic rules are mentionned","poster":"bujuman"},{"comments":[{"content":"D is the \"least wrong\" answer here. I was also confused by the route table part and thought I was missing something critical in the question.","timestamp":"1721238180.0","comment_id":"1125263","upvote_count":"4","poster":"awsgeek75"}],"timestamp":"1719554040.0","content":"Selected Answer: D\nA - \"NAT gateway\" is \"to allow [outbound] internet traffic\", but this is about inbound traffic\nB - This is about outbound traffic while the problem is inbound\nC - This is about outbound traffic while the problem is inbound\nD - Sounds correct, though the \"update the route tables\" should not be required if both subnets are in same VPC","poster":"pentium75","upvote_count":"7","comment_id":"1107542"},{"poster":"David_Ang","comment_id":"1058825","timestamp":"1714476480.0","upvote_count":"3","content":"Selected Answer: A\nthis is a bad formulated question with gaps, but my reason tells me that if you want to connect something from a private subnet to internet you need a NAT (instance or gateway, bastion). \nCreating public subnets in each Availability Zone and associating them with the Application Load Balancer (ALB) won't resolve the problem of allowing internet traffic to reach the private EC2 instances. Public subnets are typically used when you want your EC2 instances to have direct internet access, not when you want to keep them in private subnets with indirect access through a load balancer."},{"comment_id":"1020766","timestamp":"1711722960.0","content":"Selected Answer: D\nption A (replace ALB with Network Load Balancer and add a NAT gateway) is not the most straightforward solution because it changes the load balancer type and introduces a NAT gateway, which might be unnecessary if the goal is to use an ALB for web traffic. ALBs are commonly used for internet-facing web applications.\n\nOption B (move EC2 instances to public subnets and modify security group rules) involves placing instances in public subnets, which is generally not recommended for security reasons. Additionally, it suggests modifying security group rules for outbound traffic, which might not be the best practice to resolve the issue.\n\nOption C (update route tables and security group rules) addresses the route table update, but it also suggests moving instances to public subnets, which is not ideal from a security perspective.","upvote_count":"2","poster":"vijaykamal"},{"comment_id":"1017399","content":"Selected Answer: D\nCreate public subnets in each Availability Zone. Associate the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets.","poster":"TariqKipkemei","timestamp":"1711438020.0","upvote_count":"3"},{"upvote_count":"3","content":"Selected Answer: D\nOption A is incorrect Internet traffic is http and https so it cant be configured to NLB\nOption B and option C is incorrect because senging 0.0.0.0/0 is not best practices\n\nOption D is correct because its the only option left. and updating the route tables for the public subnets with a route to the private subnets ensures internet access to EC2 instances in private subnet.","poster":"Its_SaKar","comment_id":"1015197","timestamp":"1711224900.0"},{"poster":"Guru4Cloud","comment_id":"1004804","upvote_count":"4","timestamp":"1710167940.0","content":"Selected Answer: D\nD. is the correct solution. By creating public subnets and associating them with the ALB, inbound internet traffic can reach the ALB. The route tables for the public subnets are updated to include a route to the private subnets, allowing traffic to reach the EC2 instances in the private subnets. This setup enables secure access to the application while allowing internet traffic to reach the EC2 instances through the ALB."},{"poster":"A1975","timestamp":"1706671200.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-example-private-subnets-nat.html","comment_id":"967639","upvote_count":"3"},{"poster":"cookieMr","timestamp":"1703788620.0","upvote_count":"6","comment_id":"936918","content":"Selected Answer: D\nA. suggests using a different type of load balancer and configuring a NAT gateway, but it does not address the issue of internet traffic reaching the EC2 instances.\n\nB. suggests exposing the EC2 instances to the public internet, which may pose security risks and does not address the issue of inbound internet traffic reaching the instances.\n\nC. suggests configuring the EC2 instances to have outbound internet access, but it does not solve the problem of inbound internet traffic reaching the instances.\n\nD. is the correct solution. By creating public subnets and associating them with the ALB, inbound internet traffic can reach the ALB. The route tables for the public subnets are updated to include a route to the private subnets, allowing traffic to reach the EC2 instances in the private subnets. This setup enables secure access to the application while allowing internet traffic to reach the EC2 instances through the ALB."},{"poster":"Vinhkewl","timestamp":"1703502660.0","comments":[{"content":"C allows the EC2 instances to be accessed directly from the Internet, which we don't want. It's the ALB (not the Internet) that can't access them. We must make sure that the ALB can be reached from the Internet and that the EC2 instances can be reached from the ALB.","poster":"pentium75","timestamp":"1719553860.0","upvote_count":"2","comment_id":"1107539"}],"upvote_count":"1","comment_id":"933409","content":"Should be C\nIt would normally make sense to segregate your ALBs into public or private zones by security group and target group, but this is configuration rather than architectural placement - there is nothing preventing you from adding a rule to route specific paths or ports to a public subnet from an ALB that has until then been serving private subnets only."},{"timestamp":"1702197240.0","content":"Selected Answer: D\nTo attach Amazon EC2 instances that are located in a private subnet, first create public subnets","upvote_count":"5","comment_id":"919852","poster":"Abrar2022"},{"timestamp":"1701334380.0","poster":"Bmarodi","comment_id":"910934","upvote_count":"2","content":"Selected Answer: D\nI vote with the option D."},{"upvote_count":"4","comment_id":"903836","content":"D is not quite accurate because subnets in a VPC have a local route by default, meaning that all subnets are able to communicate with each other: \"Every route table contains a local route for communication within the VPC. This route is added by default to all route tables\". This question is poorly formulated.","poster":"antropaws","timestamp":"1700647140.0"},{"content":"Selected Answer: D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/public-load-balancer-private-ec2/","comment_id":"857134","upvote_count":"3","poster":"kraken21","timestamp":"1696081560.0"},{"upvote_count":"1","comment_id":"829521","content":"Selected Answer: C\nI think C would be correct answer.","poster":"Theodorz","timestamp":"1693869600.0"},{"poster":"AYap","timestamp":"1692581640.0","upvote_count":"4","comment_id":"816163","content":"Answer: D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/public-load-balancer-private-ec2/"},{"content":"Selected Answer: C\nJust need to configure the outbound path from the servers back out to the Internet. Inbound path is already configured","comment_id":"808780","upvote_count":"1","poster":"bdp123","timestamp":"1692035400.0"},{"comments":[{"timestamp":"1703012520.0","upvote_count":"3","comment_id":"927724","content":"Private subnet can only access internet via NAT Gateway or instance. You can't attach internet gateway to private. Internet gateway allows public subnet reachable via internet. The whole idea of private is shielding from outside world. It doesn;t make sense to add internet gateway. May be it is a typo, the answer should have NAT not internet gateway?!!","poster":"markw92"},{"comment_id":"906425","content":"your answer is wrong!!! private subnets don't have access to the internet gateway, it's not possible to configure a private subnet to send traffic to an internet gateway","upvote_count":"2","timestamp":"1700899320.0","poster":"ruqui"},{"content":"Option B is not a complete solution, as it only allows outbound traffic, but the instances need to be able to receive inbound traffic from the internet. \n\nOption D is not necessary, as the internet-facing ALB is already specified and the EC2 instances are already part of the target group. \n\nOption A is not a solution to the problem, as it does not address the underlying issue of the EC2 instances not being able to receive internet traffic.","upvote_count":"1","comment_id":"803076","poster":"nickolaj","timestamp":"1691569320.0"}],"upvote_count":"1","content":"Selected Answer: C\nThe correct answer is C. To resolve the issue of internet traffic not reaching the EC2 instances, the solutions architect should update the route tables for the EC2 instances' subnets to send 0.0.0.0/0 traffic through the internet gateway route. The EC2 instances are in private subnets, so they need a route to the internet to be able to receive internet traffic. Additionally, the solutions architect should add a rule to the EC2 instances' security groups to allow outbound traffic to 0.0.0.0/0, to ensure that the instances are allowed to send traffic out to the internet.","timestamp":"1691569320.0","poster":"nickolaj","comment_id":"803075"},{"poster":"Bofi","content":"Selected Answer: B\ni choose B because it makes more sense to me. You want to place your web application in a public subnet not in private subnet for security reasons. You don't need to open your inbound traffic for all traffic, your already have a load balance. However, u need to be able to return the traffic , hence open up the outbound to 0.0.0.0/00.","upvote_count":"2","comment_id":"799893","timestamp":"1691328060.0"},{"comment_id":"790468","timestamp":"1690529880.0","poster":"dexpos","content":"Selected Answer: D\nD makes more sense to enable the internet traffic reach the EC2, the C is only considering outbound","upvote_count":"2"},{"poster":"aws4myself","timestamp":"1690352280.0","comment_id":"788521","upvote_count":"4","content":"Selected Answer: C\nSimply we can update the private subnet route table to get internet with IGW id. Aslo we are allowing security group outbound to 0.0.0.0/0. \n\nD is a bad answer. If you launch a public ALB, there should be min 2 AZs with internet access. There is nothing to update route tables for public and private subnets. By default, every route table has a default rule with VPC CIDR range."},{"upvote_count":"4","timestamp":"1690256880.0","poster":"Chan1509","comment_id":"787304","content":"Selected Answer: D\nhttps://www.examtopics.com/discussions/amazon/view/80859-exam-aws-certified-solutions-architect-associate-saa-c02/"},{"content":"Selected Answer: D\nD. Create public subnets in each Availability Zone. Associate the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets.\n\nThis solution will resolve the issue by allowing the internet traffic to reach the EC2 instances. By creating public subnets in each availability zone and associating them with the ALB, the internet traffic will be directed to the ALB. Updating the route tables for the public subnets with a route to the private subnets will allow the traffic to be routed to the private subnets where the EC2 instances reside. This ensures that the traffic reaches the correct target group, and the security group of the instances allows inbound traffic from the internet.","comment_id":"776562","upvote_count":"5","timestamp":"1689418860.0","poster":"mhmt4438"},{"poster":"Aninina","comment_id":"775882","content":"Selected Answer: D\nTo attach Amazon EC2 instances that are located in a private subnet, first create public subnets. These public subnets must be in the same Availability Zones as the private subnets that are used by the backend instances. Then, associate the public subnets with your load balancer.\n\nNote: Your load balancer establishes a connection with its target privately. To download software or security patches from the internet, use a NAT gateway rule on the target instance's route table to allow internet access.","upvote_count":"3","comments":[{"content":"But where is the net gateway mentioned in option D.","upvote_count":"1","timestamp":"1689997680.0","poster":"jainparag1","comment_id":"783942","comments":[{"timestamp":"1692811680.0","poster":"Deepak_k","comment_id":"819633","content":"NAT Gateway is used when the question asks you the private EC2 are not able to connect to internet to download window patches etc.. Here the question is Internet is not able to reach the EC2 Instances. The only way the internet traffic reaches to EC2 instances in private subnet is through ALB in public subnet and need to edit the route table to reach private subnets","upvote_count":"1"}]}],"timestamp":"1689357300.0"},{"timestamp":"1689241200.0","poster":"bamishr","upvote_count":"2","content":"Selected Answer: D\nhttps://www.examtopics.com/discussions/amazon/view/80859-exam-aws-certified-solutions-architect-associate-saa-c02/","comment_id":"774394"},{"upvote_count":"2","content":"Selected Answer: D\nhttps://www.examtopics.com/discussions/amazon/view/80859-exam-aws-certified-solutions-architect-associate-saa-c02/","comment_id":"774325","timestamp":"1689236100.0","poster":"Morinator"}],"answer":"D","answers_community":["D (86%)","8%"],"answer_ET":"D","answer_images":[],"isMC":true,"question_id":184,"unix_timestamp":1673604900,"exam_id":31,"timestamp":"2023-01-13 11:15:00","question_text":"A company runs a web application on Amazon EC2 instances in multiple Availability Zones. The EC2 instances are in private subnets. A solutions architect implements an internet-facing Application Load Balancer (ALB) and specifies the EC2 instances as the target group. However, the internet traffic is not reaching the EC2 instances.\n\nHow should the solutions architect reconfigure the architecture to resolve this issue?"},{"id":"eRA91PuXHs3GtjtlP0mm","answers_community":["CE (78%)","14%","7%"],"answer_description":"","isMC":true,"question_images":[],"answer_ET":"CE","url":"https://www.examtopics.com/discussions/amazon/view/95004-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"E":"Enable automatic backups on the source instance by setting the backup retention period to a value other than 0.","B":"Choose a failover priority for the source DB instance.","A":"Enable binlog replication on the RDS primary node.","C":"Allow long-running transactions to complete on the source DB instance.","D":"Create a global table and specify the AWS Regions where the table will be available."},"unix_timestamp":1673605020,"exam_id":31,"discussion":[{"poster":"fkie4","content":"Who would know this stuff man...","comment_id":"832137","upvote_count":"129","comments":[{"upvote_count":"2","poster":"presetacsing","comment_id":"904255","content":"exactly","timestamp":"1684776300.0"},{"comment_id":"948910","timestamp":"1689073320.0","content":"\"Allow long-running transactions to complete on the source DB instance.\" --. Makes sense / Also a backup before changing anything again made a sense.","upvote_count":"3","poster":"MNotABot"},{"comment_id":"1128262","content":"Just take an intelligent guess. Eliminate 2 wrong answers and you will have a 50percent success chance.","poster":"foha2012","timestamp":"1705883400.0","upvote_count":"3"}],"timestamp":"1678209000.0"},{"timestamp":"1673851080.0","content":"C,E\n\"An active, long-running transaction can slow the process of creating the read replica. We recommend that you wait for long-running transactions to complete before creating a read replica. If you create multiple read replicas in parallel from the same source DB instance, Amazon RDS takes only one snapshot at the start of the first create action.\n\nWhen creating a read replica, there are a few things to consider. First, you must enable automatic backups on the source DB instance by setting the backup retention period to a value other than 0. This requirement also applies to a read replica that is the source DB instance for another read replica\"\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html","poster":"KelvinEM","comment_id":"777368","upvote_count":"52"},{"comment_id":"1342291","content":"Selected Answer: UE\nOpção A: Habilite a replicação de log binário no nó primário do RDS\nA replicação de log binário é necessária para habilitar réplicas de leitura no RDS for MySQL. O banco de dados de origem precisa capturar e armazenar logs binários que serão usados para replicar alterações para as réplicas de leitura,\nE: Habilite backups automáticos na instância de origem definindo o período de retenção de backup como um valor diferente de 0 Backups automáticos devem estar habilitados na instância de origem para criar réplicas de leitura. Isso garante que a réplica possa ser criada a partir de um ponto consistente do banco de dados de origem","poster":"Rcosmos","timestamp":"1737139080.0","upvote_count":"1"},{"poster":"derekxxxxxxxx","content":"Selected Answer: CE\nAllow long-running transactions to complete on the source DB instance.","upvote_count":"1","comment_id":"1323134","timestamp":"1733582160.0"},{"content":"Selected Answer: CE\nBased on the official documentation, the correct steps to prepare for creating a read replica are:\n\nA. Enable binlog replication on the RDS primary node.\nC. Allow long-running transactions to complete on the source DB instance.\nE. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0.\nThese ensure smooth and efficient setup while adhering to AWS best practices.\n\nFor more detailed information, you can refer to the AWS documentation: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.Create.html\n\nA (Enable binlog replication) is not a required manual step in Amazon RDS.\nAmazon RDS automatically manages this requirement during the creation of the read replica for MySQL and MariaDB.","comment_id":"1318434","timestamp":"1732685220.0","poster":"FlyingHawk","upvote_count":"2"},{"timestamp":"1732343040.0","content":"Selected Answer: CE\nAnswer: CE.\nA: In Amazon RDS, binary logging is automatically enabled when creating a read replica. You don’t need to enable it manually.\nB: Read replicas are used for improving read performance, not for failover purposes.\nC: This ensures a clean state before replication begins.\nD: Global tables are part of Amazon DynamoDB, not Amazon RDS.\nE: RDS uses the automated backup feature to take a snapshot of the primary DB instance and initialize the replica.","comment_id":"1316588","poster":"LeonSauveterre","upvote_count":"2"},{"timestamp":"1727749260.0","content":"Selected Answer: CE\nA isn't correct because binary log is just for external DB instance.","poster":"tonybuivannghia","comment_id":"1291745","upvote_count":"3"},{"timestamp":"1723918020.0","poster":"ccceb01","content":"Answer is C and E\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html","comment_id":"1267807","upvote_count":"2"},{"timestamp":"1719582900.0","upvote_count":"3","comment_id":"1238756","content":"Selected Answer: AE\nA. Enable binlog replication on the RDS primary node:\n\nDirect Impact: Enabling binlog replication is crucial for setting up read replicas, which will directly help in distributing the read load and improving read performance.\nE. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0:\n\nDirect Impact: Automatic backups are necessary to ensure data integrity when creating read replicas. This setup is critical for maintaining consistent and reliable replicas.","poster":"1166ae3"},{"upvote_count":"4","poster":"awsgeek75","content":"Selected Answer: CE\nB and D don't have anything to do with the question.\nE is a must have before doing major architecture changes\nA is not something you need to do explicitly when creating read replicas as it is managed by RDS\nC makes sense \n\n* I think the options are really badly worded which makes it confusing. I doubt this is a real question.","comment_id":"1111359","timestamp":"1704129900.0","comments":[{"timestamp":"1704130260.0","content":"Also, to add, binlog replication is needed if you are replicating to a non RDS instance. This is why I think the question is badly phrased as it does not specify the location of read replica. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MySQL.Procedural.Importing.External.Repl.html","comment_id":"1111360","upvote_count":"1","poster":"awsgeek75"}]},{"content":"An active, long-running transaction can slow the process of creating the read replica. We recommend that you wait for long-running transactions to complete before creating a read replica. If you create multiple read replicas in parallel from the same source DB instance, Amazon RDS takes only one snapshot at the start of the first create action.\n\nWhen creating a read replica, there are a few things to consider. First, you must enable automatic backups on the source DB instance by setting the backup retention period to a value other than 0. This requirement also applies to a read replica that is the source DB instance for another read replica","comment_id":"1089292","timestamp":"1701864240.0","poster":"Ruffyit","upvote_count":"2"},{"content":"Selected Answer: AC\nTo improve the read performance of a database in Amazon RDS for MySQL by adding a read replica, you should take the following actions:\n\n Enable binlog replication on the RDS primary node: This allows the primary node to stream its binary logs to the read replica, enabling data replication.\n\n A. Enable binlog replication on the RDS primary node.\n\n Allow long-running transactions to complete on the source DB instance: Before creating a read replica, it's advisable to let any long-running transactions complete to ensure consistency between the source and the replica.\n\n C. Allow long-running transactions to complete on the source DB instance.\n\nThe other options are not directly related to setting up a read replica:","poster":"meowruki","timestamp":"1701310320.0","comment_id":"1083921","comments":[{"timestamp":"1701310380.0","comment_id":"1083923","content":"B. Choose a failover priority for the source DB instance: Failover priority is more relevant in a Multi-AZ setup where automatic failover might occur. It's not directly related to creating a read replica.\n\n D. Create a global table and specify the AWS Regions where the table will be available: Global tables are used for cross-region replication, but they are not directly related to setting up a read replica for improved read performance.\n\n E. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0: While it's a good practice to have backups enabled, it is not a prerequisite for creating a read replica.\n\nTherefore, the most appropriate actions are A and C.","poster":"meowruki","upvote_count":"1"}],"upvote_count":"1"},{"content":"Selected Answer: AE\nA - it's essential for continuous replication\nE - it's essential for setting up replication, initial data in replica is based on latest backup\n\nother options:\nB - we're not designing for HA, and it's related to mutli-AZ RDS deployments\nC - is this needed for adding read replica?\nD - it's not a dynamodb to create global table","poster":"xdkonorek2","comment_id":"1079171","upvote_count":"5","timestamp":"1700820480.0"},{"content":"Selected Answer: CE\nA. Enabling binlog replication is not something you need to do manually before creating a read replica. Amazon RDS for MySQL manages replication internally, and it's not necessary to enable binlog replication explicitly.\n\nB. Choosing a failover priority is related to Multi-AZ configurations and automatic failover, but it is not specifically required when adding a read replica.\n\nD. Creating a global table and specifying AWS Regions is related to Aurora Global Databases, which is not the same as creating a read replica for a standard RDS instance.","upvote_count":"2","poster":"vijaykamal","comment_id":"1020771","timestamp":"1695991200.0"},{"poster":"Guru4Cloud","timestamp":"1694435580.0","upvote_count":"2","comment_id":"1004791","content":"Selected Answer: CE\n**C. Long-running transactions can prevent the read replica from catching up with the source DB instance. Allowing these transactions to complete before creating the read replica can help ensure that the replica is able to stay synchronized with the source.\n\n**E. Automatic backups must be enabled on the source DB instance for read replicas to be created. This is done by setting the backup retention period to a value other than 0."},{"content":"Bin log (binary log) is a specific terminology to MySQL, it is a write-only file that logs all history and used for purposes such as point-in-time recovery and transaction replication.\n\nOption A is technically correct but on AWS RDS, this MySQL feature is turned on by setting backup retention period > 0, that is why we must enable backup before replication can work (for MySQL, at least) => Option E is the more general answer for AWS RDS.\n\nOption C is just a recommendation from AWS official documentation, it is there to prevent data mismatch on primary and secondaries when the long-running transactions have not been complete yet.","poster":"cd93","timestamp":"1692076800.0","comment_id":"981317","upvote_count":"1"},{"timestamp":"1690768260.0","upvote_count":"2","comment_id":"967657","content":"Selected Answer: CE\nBefore a MySQL DB instance can serve as a replication source, make sure to enable automatic backups on the source DB instance. To do this, set the backup retention period to a value other than 0. This requirement also applies to a read replica that is the source DB instance for another read replica. Automatic backups are supported for read replicas running any version of MySQL. You can configure replication based on binary log coordinates for a MySQL DB instance\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_MySQL.Replication.ReadReplicas.html","poster":"A1975"},{"comment_id":"967637","timestamp":"1690766220.0","content":"A E. Binlog is needed for on-going replication setup and DB backup is needed for setup the replication DB","poster":"StacyY","upvote_count":"1"},{"upvote_count":"1","content":"Correction: c and e","timestamp":"1688338500.0","comment_id":"941289","poster":"Mmmmmmkkkk"},{"timestamp":"1688338380.0","content":"A and e","comment_id":"941286","poster":"Mmmmmmkkkk","upvote_count":"1"},{"timestamp":"1687970580.0","comment_id":"936919","poster":"cookieMr","upvote_count":"3","content":"Selected Answer: CE\nA. enables the binary log replication feature on the RDS primary node, which is necessary for setting up a read replica.\n\nB. determines the order in which DB instances are promoted to the primary role during a failover scenario. It is not directly related to adding a read replica to address slow reads.\n\nC. ensures that any ongoing transactions on the source DB instance are allowed to finish before implementing the change. It helps maintain data integrity and consistency during the transition to the read replica.\n\nD. is a feature specific to DynamoDB. It allows for multi-region replication and high availability in DynamoDB, but it is not applicable in this scenario.\n\nE. ensures that regular backups are taken for the source DB instance. This is important for data protection and recovery purposes, as it allows for point-in-time restoration in case of any issues during or after the addition of the read replica."},{"comment_id":"919855","upvote_count":"2","timestamp":"1686380040.0","poster":"Abrar2022","content":"Selected Answer: CE\nBefore adding read replicas, one needs to allow long-running transactions to complete on the source DB instance otherwise you might end up interrupting transactions. The, you should enable automatic backups on the source instance and set the backup retention period to a value other than 0."},{"poster":"Bmarodi","timestamp":"1685518500.0","upvote_count":"2","content":"Selected Answer: CE\nThe combination of actions should a solutions architect take before implementing this chang are options C & E.","comment_id":"910970"},{"timestamp":"1685153580.0","content":"AAAAAAAAAAA EEEEEEEEEEEEEEEE","comment_id":"907696","poster":"omoakin","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: CE\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.Create","comment_id":"899711","timestamp":"1684292280.0","poster":"Yadav_Sanjay"},{"timestamp":"1676404500.0","comment_id":"808782","poster":"bdp123","content":"Selected Answer: CE\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.Create","upvote_count":"3"},{"comment_id":"796418","poster":"bdp123","content":"Selected Answer: CE\nWhen creating a Read Replica, there are a few things to consider. First, you must enable automatic backups on the source DB instance by setting the backup retention period to a value other than 0. This requirement also applies to a Read Replica that is the source DB instance for another Read Replica. \n\nAfter you enable automatic backups by modifying your read replica instance to have a backup retention period greater than 0 days, you’ll find that the log_bin and binlog_format will align itself with the configuration specified in your parameter group dynamically and will not require the RDS instance to be restarted. You will also be able to create a read replica from your read replica instance with no further modification requirements.\n\nhttps://blog.pythian.com/enabling-binary-logging-rds-read-replica/","upvote_count":"3","timestamp":"1675369920.0"},{"timestamp":"1674362940.0","comments":[{"poster":"JayBee65","upvote_count":"1","content":"Binlog replication is a popular feature serving multiple use cases, including offloading transactional work from a source database, replicating changes to a separate dedicated system to run analytics, and streaming data into other systems, but the benefits don’t come for free. I don't believe it is used for creating read replicas. It is not mentioned in the link below.\nOn the other hand this link https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.Create says...\n(C) We recommend that you wait for long-running transactions to complete before creating a read replica.\n(E) First, you must enable automatic backups on the source DB instance by setting the backup retention period to a value other than 0","timestamp":"1674547680.0","comment_id":"786295","comments":[{"poster":"alexleely","timestamp":"1674613740.0","upvote_count":"3","content":"You are right, Binlog is enabled by doing (E). If we think from Database-as-a-service, C and E would be the correct answer. My answer will only be correct if it is not using AWS. Apologizes.","comment_id":"787209"}]}],"comment_id":"783918","upvote_count":"3","content":"Selected Answer: AC\nA,C\n\nA: Before we can start read replica, it is important to enable binary logging on the RDS primary node, thus, ensuring read replica to have up-to-date data.\nC: To avoid inconsistencies between the primary and replica instances by allowing long-running transactions to complete on the source DB instance\n\nThough E is a good practise, it is not part of the steps you need to do before enabling read replica.","poster":"alexleely"},{"poster":"techhb","upvote_count":"2","content":"Selected Answer: CE\nC&E ARE right choices.","timestamp":"1673974860.0","comment_id":"779096"},{"upvote_count":"4","comment_id":"776570","poster":"mhmt4438","timestamp":"1673788140.0","content":"Selected Answer: CE\nhttps://www.examtopics.com/discussions/amazon/view/68927-exam-aws-certified-solutions-architect-associate-saa-c02/"},{"poster":"Aninina","upvote_count":"3","content":"Selected Answer: CE\nC and E","comment_id":"775883","timestamp":"1673726220.0"},{"comment_id":"774472","timestamp":"1673613840.0","content":"Selected Answer: CE\nC and E","poster":"bamishr","upvote_count":"2"},{"poster":"Morinator","content":"Selected Answer: CE\nhttps://www.examtopics.com/discussions/amazon/view/68927-exam-aws-certified-solutions-architect-associate-saa-c02/","timestamp":"1673605020.0","comment_id":"774327","upvote_count":"2"}],"timestamp":"2023-01-13 11:17:00","question_text":"A company has deployed a database in Amazon RDS for MySQL. Due to increased transactions, the database support team is reporting slow reads against the DB instance and recommends adding a read replica.\n\nWhich combination of actions should a solutions architect take before implementing this change? (Choose two.)","question_id":185,"answer_images":[],"answer":"CE","topic":"1"}],"exam":{"isBeta":false,"name":"AWS Certified Solutions Architect - Associate SAA-C03","numberOfQuestions":1019,"id":31,"lastUpdated":"11 Apr 2025","provider":"Amazon","isImplemented":true,"isMCOnly":true},"currentPage":37},"__N_SSP":true}