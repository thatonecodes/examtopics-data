{"pageProps":{"questions":[{"id":"g6PGtV7hsFuQUHkAvCvZ","answer_description":"","timestamp":"2022-09-04 04:25:00","exam_id":32,"answer":"C","discussion":[{"comment_id":"865898","poster":"hobokabobo","upvote_count":"2","timestamp":"1681085280.0","content":"Selected Answer: A\nUsing mysqldump. For me its tempting: have been using it for decades. But it does not reduce operational overhead. Where should it be executed btw. and how do you create a secure tunnel for the stream(doable with simple ssh but think about the \"operational overhead\" ...) or where do you store the dumps as streaming is pipe plumbing...\nData in relational Databases in general is more read more than written. This is also the case if the database is used by the backend which is not uncommon. That the data that was stored in the database is backend data does not imply that it is written more then read. \nHence read replica should be fine. A is perfect. \nJust imagine an architect suggest C on the job ... on time fail."},{"poster":"coolt2","comment_id":"806364","upvote_count":"3","timestamp":"1676208480.0","content":"Selected Answer: C\nAmazon Aurora is a fully managed, high-performance relational database with low latency and high availability. It supports MySQL and can be easily scaled. The global database feature allows you to create a single, low-latency database across multiple AWS Regions, making it a great fit for this use case. By using native MySQL tools to migrate existing databases, the company can minimize the amount of development effort required to make the application highly available."},{"content":"Selected Answer: C\nA - available across multiple aws regions and has read replicas for improved scaling. - Initially thoguht this was the right answer.\nC - This appears to be the most correct answer - \n\n\nB - Wrong database platform - Solution will require MySQL / Aurora\nD - Not scalable and requires operational overhead","upvote_count":"1","comment_id":"715086","poster":"janvandermerwer","timestamp":"1668072240.0"},{"upvote_count":"2","poster":"sjpd10","comments":[{"content":"Because the question states \"uses MySQL servers to store backend data\" which implies writes, and the A answer opts for \"cross-Region read replica\" which are useless in this scenario.","upvote_count":"2","comment_id":"707748","poster":"joancarles","comments":[{"content":"Got it. So, its a READ vs. WRITE and a read HA in option A is useless.\n'C' for sure then.","poster":"sjpd10","comment_id":"714652","upvote_count":"1","timestamp":"1668004140.0"},{"content":"Don't think so. RDS master can send all write updates to read replica asynchronously. \ncross-region read replica will cache that write updates.\nand c, \"Use native MySQL tools to migrate existing databases\" never met aws recommend non-aws tool in aws environment and don't think use global database as necessary.","comment_id":"910586","timestamp":"1685479500.0","upvote_count":"1","poster":"Jesuisleon"}],"timestamp":"1667123640.0"}],"timestamp":"1667020500.0","comment_id":"706982","content":"For choosing between 'A' & 'C', is the DMS service more effort that 'MySQL Tools ~ mysqlimport utility' ?\n\nThere is no mention of saving costs and 'Amazon RDS for MySQL' supports cross-region replica.\n\nSo why should we discount 'A' ?"},{"poster":"JayF88","timestamp":"1664949000.0","content":"Selected Answer: C\nI agree Aurora would be more beneficial (C), but I would be skeptical about an SA Pro exam answer with mysql > aurora shift without DMS","comment_id":"686619","upvote_count":"3"},{"content":"A or C but why Dynamo DB?\nThe solution must require the least possible development effort. Should the answer be A?","comment_id":"683876","upvote_count":"1","poster":"blitzzzz","comments":[{"poster":"blitzzzz","upvote_count":"1","content":"sorry I misread, it should be C","timestamp":"1664578080.0","comment_id":"683878"}],"timestamp":"1664578020.0"},{"content":"Selected Answer: C\nC no doubts","upvote_count":"2","timestamp":"1663000140.0","comment_id":"667220","poster":"AwsBRFan"},{"content":"Answer is C:\n\n\n\n\n\nAurora (C) is far better than MySQL RDS (A).\nIn Option C, DMS isn't mentioned. However, native MySQL tool (mysqldump utility) is fine for migration as per below FAQ from AWS.\n\nHow can I migrate from MySQL to Amazon Aurora and vice versa?\nIf you want to migrate from MySQL to Amazon Aurora (and vice versa), you have several options:\n\nYou can use the standard mysqldump utility to export data from MySQL and mysqlimport utility to import data to Amazon Aurora, and vice-versa.\nYou can also use Amazon RDSâ€™s DB Snapshot migration feature to migrate an Amazon RDS for MySQL DB Snapshot to Amazon Aurora using the AWS Management Console.\nMigration to Aurora completes for most customers in under an hour, though the duration depends on format and data set size. For more information see Best Practices for Migrating MySQL Databases to Amazon Aurora.","comment_id":"659331","upvote_count":"2","poster":"pixepe","timestamp":"1662300780.0"},{"poster":"SGES","timestamp":"1662258300.0","upvote_count":"1","content":"C\nAmazon Aurora offers higher availability zone, global replication and compatability to existing on-premise DB","comment_id":"658915"}],"question_images":[],"answers_community":["C (82%)","A (18%)"],"url":"https://www.examtopics.com/discussions/amazon/view/79933-exam-aws-certified-solutions-architect-professional-topic-1/","topic":"1","isMC":true,"unix_timestamp":1662258300,"answer_ET":"C","question_id":951,"choices":{"B":"Deploy Amazon DynamoDB with global tables. Use AWS Database Migration Service (AWS DMS) to migrate existing databases. Adapt the application to work with DynamoDB.","A":"Create an Amazon RDS for MySQL DB cluster that includes a cross-Region read replica. Use AWS Database Migration Service (AWS DMS) to migrate existing databases.","D":"Create MySQL servers on Amazon EC2 instances in two Regions. Set up asynchronous software replication across Regions.","C":"Create an Amazon Aurora global database. Use native MySQL tools to migrate existing databases."},"answer_images":[],"question_text":"A company wants to move an application from on premises to the AWS Cloud. The application uses MySQL servers to store backend data. However, the application does not scale properly. The databases have become unresponsive as the user base has increased.\nThe company needs a solution to make the application highly available with low latency across multiple AWS Regions. The solution must require the least possible operational overhead and development effort.\nWhich solution will meet these requirements?"},{"id":"x3tLkMxmP1HTl2w9IUwA","topic":"1","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/81635-exam-aws-certified-solutions-architect-professional-topic-1/","question_text":"A company is running a serverless application that consists of several AWS Lambda functions and Amazon DynamoDB tables. The company has created new functionality that requires the Lambda functions to access an Amazon Neptune DB cluster. The Neptune DB cluster is located in three subnets in a VPC.\nWhich of the possible solutions will allow the Lambda functions to access the Neptune DB cluster and DynamoDB tables? (Choose two.)","timestamp":"2022-09-11 11:12:00","question_images":[],"answer_ET":"BE","question_id":952,"answer_images":[],"choices":{"B":"Create three private subnets in the Neptune VPC, and route internet traffic through a NAT gateway. Host the Lambda functions in the three new private subnets.","E":"Create three private subnets in the Neptune VPC. Host the Lambda functions in the three new isolated subnets. Create a VPC endpoint for DynamoDB, and route DynamoDB traffic to the VPC endpoint.","D":"Host the Lambda functions outside the VPC. Create a VPC endpoint for the Neptune database, and have the Lambda functions access Neptune over the VPC endpoint.","A":"Create three public subnets in the Neptune VPC, and route traffic through an internet gateway. Host the Lambda functions in the three new public subnets.","C":"Host the Lambda functions outside the VPC. Update the Neptune security group to allow access from the IP ranges of the Lambda functions."},"isMC":true,"discussion":[{"content":"Selected Answer: BE\nC and D are out due to \"Lambda functions always run inside VPCs owned by the Lambda service.\" https://docs.aws.amazon.com/lambda/latest/operatorguide/networking-vpc.html\nyou can't run lambda outside an VPC","upvote_count":"2","timestamp":"1685023440.0","comment_id":"906710","poster":"Jesuisleon","comments":[{"content":"A is out because you can't connect Neptune via public internet, see https://docs.aws.amazon.com/neptune/latest/userguide/security-vpc.html","comment_id":"921687","timestamp":"1686598140.0","upvote_count":"1","poster":"Jesuisleon"}]},{"comment_id":"727107","content":"Selected Answer: BE\nYou can configure a Lambda function to connect to private subnets in a virtual private cloud (VPC) in your AWS account","timestamp":"1669414140.0","upvote_count":"2","poster":"SureNot"},{"upvote_count":"2","comment_id":"715068","poster":"janvandermerwer","content":"Selected Answer: BE\nAgree with comments.","timestamp":"1668070860.0"},{"content":"Selected Answer: BE\nB & E, private subnets for the DB. VPC end point works for dynamo not for neptune DB","comment_id":"713983","poster":"AjayPrajapati","timestamp":"1667925900.0","upvote_count":"3"},{"comment_id":"711772","upvote_count":"4","timestamp":"1667654820.0","content":"Selected Answer: BE\nB and E. Lambda functions can only be hosted in a private subnet","poster":"Ni_yot"},{"poster":"xxmike89","timestamp":"1666712880.0","content":"Selected Answer: BE\nNeptuneDB must in VPC ; wile DynamoDB must be outside VPC","comment_id":"703998","upvote_count":"2"},{"timestamp":"1665280500.0","poster":"skywalker","comment_id":"689850","upvote_count":"3","content":"Selected Answer: BE\nNeptuneDB must in VPC ; wile DynamoDB must be outside VPC\n\nThus B and E\nBoth allow connection to DynamoDB either via NAT or VPC endpoint... E will cost lesser since no outbound traffic ."},{"comment_id":"686613","content":"Selected Answer: BE\nBE is correct","poster":"JayF88","upvote_count":"2","timestamp":"1664948580.0"},{"content":"Selected Answer: BE\nBE is correct\nfor option D to work you need a Network Load Balancer","upvote_count":"2","timestamp":"1664794380.0","comment_id":"685448","poster":"JohnPi","comments":[{"upvote_count":"1","timestamp":"1665643380.0","poster":"JohnPi","content":"https://docs.aws.amazon.com/neptune/latest/userguide/security-vpc.html","comment_id":"693671"}]},{"upvote_count":"3","content":"Selected Answer: BE\nIn order to connect the lambda with de Netptune, it should reside inside the VPC. How no there are an option with and endpoint and loadbalancer, I choose the private subnets, so B.\nThe other response that cover the Dynamodb connection , remaining the lambdas in a private subnet, so my option is E\nIn resume, BE","timestamp":"1664695980.0","comment_id":"684664","poster":"joancarles"},{"comment_id":"680552","content":"D is wrong - if Lambda is hosted outside VPC then why VPC endpoint is needed ?\nVote for B&E !","timestamp":"1664269440.0","upvote_count":"3","poster":"Biden"},{"content":"Why not A?","poster":"Trump2022","upvote_count":"1","comment_id":"678586","timestamp":"1664094780.0"},{"poster":"Cloudxie","upvote_count":"4","comment_id":"668897","content":"Amazon Neptune only allows connections from clients located in the same VPC as the Neptune cluster. D is wrong","timestamp":"1663151940.0"},{"upvote_count":"1","comment_id":"665973","poster":"Biden","content":"Selected Answer: BD\nLambda needs access to the Neptune DB. Host Lambda within VPC in private subnet within Neptune VPC. OR Host Lambda outside VPC and access Neptune DB using VPC Endpoints","timestamp":"1662887520.0"}],"unix_timestamp":1662887520,"answers_community":["BE (96%)","4%"],"exam_id":32,"answer":"BE"},{"id":"5UmDQHAarAUccQnyyAfM","unix_timestamp":1662888120,"isMC":true,"answers_community":["A (80%)","C (20%)"],"exam_id":32,"choices":{"C":"Use AWS Certificate Manager (ACM) to issue trusted device certificates to the machines deployed in the branch office locations. Enable restricted access on the WorkSpaces directory.","A":"Create an IP access control group rule with the list of public addresses from the branch offices. Associate the IP access control group with the WorkSpaces directory.","D":"Create a custom WorkSpace image with Windows Firewall configured to restrict access to the public addresses of the branch offices. Use the image to deploy the WorkSpaces.","B":"Use AWS Firewall Manner to create a web ACL rule with an IPSet with the list of public addresses from the branch office locations. Associate the web ACL with the WorkSpaces directory."},"answer_ET":"A","question_images":[],"answer":"A","discussion":[{"comment_id":"675640","timestamp":"1663808820.0","poster":"gnandam","upvote_count":"6","content":"A - \nAmazon WorkSpaces allows you to control which IP addresses your WorkSpaces can be accessed from. By using IP address-based control groups, you can define and manage groups of trusted IP addresses, and only allow users to access their WorkSpaces when they're connected to a trusted network.\n\nAn IP access control group acts as a virtual firewall that controls the IP addresses from which users are allowed to access their WorkSpaces. To specify the CIDR address ranges, add rules to your IP access control group, and then associate the group with your directory. You can associate each IP access control group with one or more directories. You can create up to 100 IP access control groups per Region per AWS account. However, you can only associate up to 25 IP access control groups with a single directory.\nC - is not MOST operational efficiency"},{"comment_id":"689853","poster":"skywalker","upvote_count":"5","timestamp":"1665280680.0","content":"Selected Answer: A\nA - https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces-ip-access-control-groups.html"},{"comment_id":"709474","content":"trusted device cert model won't support Linux it works with only Windows and MAC. So lean towards A\nhttps://aws.amazon.com/blogs/security/how-to-secure-your-amazon-workspaces-for-external-users/","poster":"breathingcloud","upvote_count":"2","timestamp":"1667346300.0"},{"comment_id":"682482","timestamp":"1664440200.0","poster":"akash_it","upvote_count":"3","content":"Selected Answer: A\nA is correct"},{"content":"Selected Answer: C\nCant be A since desktops wudnt have public IPs. Trusted Certs can be used: https://docs.aws.amazon.com/workspaces/latest/adminguide/trusted-devices.html","comments":[{"content":"But the branch will have a Public IP, not the desktops. Public IP for the branch and private IP for workspace, no ?","upvote_count":"4","timestamp":"1663928040.0","comment_id":"676984","poster":"astalavista1"},{"upvote_count":"1","poster":"joancarles","comment_id":"684351","timestamp":"1664642460.0","content":"It is not possible to export public certificates whether they are ACM-issued or imported.\nhttps://docs.aws.amazon.com/acm/latest/userguide/sdk-export.html\nSo it's A"},{"poster":"rsn","upvote_count":"1","comment_id":"998532","timestamp":"1693830780.0","content":"I support C https://docs.aws.amazon.com/workspaces/latest/adminguide/certificate-based-authentication.html"}],"timestamp":"1662888120.0","comment_id":"665978","upvote_count":"2","poster":"Biden"}],"answer_images":[],"topic":"1","question_text":"A company wants to use Amazon WorkSpaces in combination with thin client devices to replace aging desktops. Employees use the desktops to access applications that work with clinical trial data. Corporate security policy states that access to the applications must be restricted to only company branch office locations. The company is considering adding an additional branch office in the next 6 months.\nWhich solution meets these requirements with the MOST operational efficiency?","answer_description":"","timestamp":"2022-09-11 11:22:00","url":"https://www.examtopics.com/discussions/amazon/view/81637-exam-aws-certified-solutions-architect-professional-topic-1/","question_id":953},{"id":"LMs6No4kvtNTZa85dHca","question_id":954,"discussion":[{"timestamp":"1723806300.0","content":"C. Use your on-premises SAML 2.0-compliant identity provider (IDP) to grant the NOC members federated access to the AWS Management Console via the AWS single sign-on (SSO) endpoint.","comment_id":"1266997","upvote_count":"1","poster":"amministrazione"},{"timestamp":"1687210920.0","content":"Selected Answer: C\nKEYWORD = Federated access via SSO endpoint.","comment_id":"927972","poster":"SkyZeroZx","upvote_count":"1"},{"comment_id":"561176","timestamp":"1646454540.0","content":"Selected Answer: C\nFederated access via SSO endpoint.\nhttp://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_enable-console-saml.html","upvote_count":"2","poster":"pal40sg"},{"poster":"nwk","upvote_count":"1","timestamp":"1635036540.0","content":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_enable-console-saml.html","comment_id":"430630"},{"content":"Yes C\n\nhttp://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_enable-console-saml.html\n\nThis specific use of SAML differs from the more general one illustrated at About SAML 2.0-based federation because this workflow opens the AWS Management Console on behalf of the user. This requires the use of the AWS SSO endpoint instead of directly calling the AssumeRoleWithSAML API. The endpoint calls the API for the user and returns a URL that automatically redirects the user's browser to the AWS Management Console.","comment_id":"370490","timestamp":"1634066100.0","upvote_count":"3","poster":"01037"},{"poster":"cldy","comment_id":"329243","timestamp":"1633843920.0","content":"C.\nFederated access via SSO endpoint.\nhttp://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_enable-console-saml.html","upvote_count":"2"}],"choices":{"C":"Use your on-premises SAML 2.0-compliant identity provider (IDP) to grant the NOC members federated access to the AWS Management Console via the AWS single sign-on (SSO) endpoint.","D":"Use your on-premises SAML2.0-compliam identity provider (IDP) to retrieve temporary security credentials to enable NOC members to sign in to the AWS Management Console.","A":"Use OAuth 2.0 to retrieve temporary AWS security credentials to enable your NOC members to sign in to the AWS Management Console.","B":"Use web Identity Federation to retrieve AWS temporary security credentials to enable your NOC members to sign in to the AWS Management Console."},"unix_timestamp":1617681060,"timestamp":"2021-04-06 05:51:00","answer_ET":"C","answer_images":[],"answer_description":"","topic":"1","answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/49320-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"answers_community":["C (100%)"],"question_text":"Your company has recently extended its datacenter into a VPC on AWS to add burst computing capacity as needed Members of your Network Operations Center need to be able to go to the AWS Management Console and administer Amazon EC2 instances as necessary. You don't want to create new IAM users for each\nNOC member and make those users sign in again to the AWS Management Console.\nWhich option below will meet the needs for your NOC members?","exam_id":32,"isMC":true},{"id":"BHOHJ6hXMBafmVx7zMG3","discussion":[{"comment_id":"1247944","upvote_count":"1","poster":"WhyIronMan","timestamp":"1720984740.0","content":"The answer is A"},{"upvote_count":"3","comment_id":"716107","timestamp":"1668175680.0","poster":"mrgreatness","content":"The answer is A -- I had to do this myself. see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/query-api-troubleshooting.html . I'm 100% sure. AWS will very rarely approve increases to this limit"},{"upvote_count":"1","timestamp":"1667656020.0","comment_id":"711784","content":"Selected Answer: A\nBoth A and C appear to be correct. As a solutions architect though i would apply the workaround to handle the error before thinking of requesting an increase. so for me A seems the best ans. - https://aws.amazon.com/premiumsupport/knowledge-center/ec2-launch-multiple-requestlimitexceeded/","poster":"Ni_yot"},{"comment_id":"707558","upvote_count":"2","poster":"hqmb","comments":[{"timestamp":"1667921340.0","upvote_count":"2","poster":"superuser784","content":"I was thinking the same, but, even though if you request an increase for the API, it does not guarantee that you will not have that error again as everything has a limit, you can not request for an infinite amount of API call, thats why we have to implement exponential backoff. for that reason I changed my answer from C to A","comment_id":"713924"}],"content":"Not A, exponential backoff strategy only slows down the retry API, but it will not solve the problem as the automation script has to launch many EC2 instances at the same time anyway\nhttps://docs.aws.amazon.com/AWSEC2/latest/APIReference/query-api-troubleshooting.html#api-request-rate\nIf an API request exceeds the API request rate for its category, the request returns the RequestLimitExceeded error code. To prevent this error, ensure that your application doesn't retry API requests at a high rate. You can do this by using care when polling and by using exponential backoff retries.\n\nAns C\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/APIReference/throttling.html\nIf you exceed an API throttling limit, you get the RequestLimitExceeded error code. \nAdjusting API throttling limits\nYou can request an increase for API throttling limits for your AWS account. To request a limit adjustment, contact the AWS Support Center.","timestamp":"1667088300.0"},{"upvote_count":"3","comment_id":"683884","timestamp":"1664580600.0","poster":"blitzzzz","content":"A - If an API request exceeds the API request rate for its category, the request returns the RequestLimitExceeded error code. To prevent this error, ensure that your application doesn't retry API requests at a high rate. You can do this by using care when polling and by using exponential backoff retries.\nhttps://docs.aws.amazon.com/AWSEC2/latest/APIReference/query-api-troubleshooting.html#api-request-rate"},{"content":"Selected Answer: A\nA- Exponential Backoff\nA RequestLimitExceeded error for Amazon EC2 APIs usually indicates request rate limiting or resource rate limiting API throttling. You can use a combination of retry logic and exponential backoff strategies to work around this issue.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/ec2-launch-multiple-requestlimitexceeded/","timestamp":"1663684620.0","upvote_count":"4","poster":"redipa","comment_id":"674270"},{"content":"RequestLimitExceeded error for Amazon EC2 APIs usually indicates request rate limiting or resource rate limiting API throttling. You can use a combination of retry logic and exponential backoff strategies to work around this issue.","comment_id":"668871","timestamp":"1663150140.0","upvote_count":"2","poster":"Cloudxie"},{"comment_id":"667562","upvote_count":"2","timestamp":"1663031280.0","content":"I will vote for C simply because it will resolve the EC2 API call. A will not solve the problem of excessive API call.","poster":"Guoxian"}],"question_id":955,"timestamp":"2022-09-13 03:08:00","exam_id":32,"question_text":"A company provides specialized analytics services to customers. The analytics run on Amazon EC2 instances that need to be launched and terminated in response to requests from customers. A solutions architect is creating automation to manage the EC2 instances that handle customer requests. However, when the automation scripts attempt to launch many EC2 instances at the same time, a RequestLimitExceeded error frequently occurs.\nWhat should the solutions architect do to handle this error?","isMC":true,"topic":"1","answer_images":[],"answers_community":["A (100%)"],"question_images":[],"choices":{"C":"Request an increase for API throttling quotas from the AWS Support Center.","D":"Request an EC2 API quota increase through the Service Quotas console.","B":"Modify the EC2 instance launch configuration to install diagnostic tools on each instance to troubleshoot the issue.","A":"Implement an exponential backoff strategy so that the API token bucket can refill."},"url":"https://www.examtopics.com/discussions/amazon/view/81905-exam-aws-certified-solutions-architect-professional-topic-1/","answer_description":"","answer_ET":"A","unix_timestamp":1663031280,"answer":"A"}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","isMCOnly":false,"numberOfQuestions":1019,"isImplemented":true,"provider":"Amazon","id":32,"name":"AWS Certified Solutions Architect - Professional"},"currentPage":191},"__N_SSP":true}