{"pageProps":{"questions":[{"id":"2t0NOEkYJE1ZcNvRiSXS","answers_community":["CE (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/169486-exam-aws-certified-machine-learning-engineer-associate-mla/","topic":"1","question_images":[],"exam_id":27,"answer_images":[],"answer":"CE","answer_description":"","choices":{"E":"Average weighted quantile loss (wQL)","C":"Root mean square error (RMSE)","D":"InferenceLatency","A":"Recall","B":"LogLoss"},"question_text":"An ML engineer needs to use metrics to assess the quality of a time-series forecasting model.\n\nWhich metrics apply to this model? (Choose two.)","discussion":[{"comment_id":"1421451","upvote_count":"1","content":"Selected Answer: CE\nC. Root mean square error (RMSE)\n‚úÖ E. Average weighted quantile loss (wQL)\nHere's why:\n\n RMSE is a standard regression metric that measures the average magnitude of the error between predicted and actual values. It penalizes larger errors more than smaller ones.\n\n Weighted Quantile Loss (wQL) is commonly used in probabilistic forecasting models (e.g., Amazon Forecast, DeepAR). It assesses the accuracy of quantile predictions.","poster":"eesa","timestamp":"1743578580.0"},{"upvote_count":"1","comment_id":"1413936","poster":"aws_Tamilan","timestamp":"1743392040.0","content":"Selected Answer: CE\nüîë Keyword: Time-series forecasting model evaluation metrics\n‚úÖ Correct Answers: C. Root mean square error (RMSE) & E. Average weighted quantile loss (wQL)\n\nWhy?\n\nRMSE (Root Mean Square Error): Measures error magnitude in time-series predictions.\n\nwQL (Weighted Quantile Loss): Used in Amazon Forecast to evaluate quantile forecasts.\n\nWhy Others Are Wrong?\n‚ùå A. Recall is a classification metric, not for forecasting.\n‚ùå B. LogLoss is used for classification models, not time-series.\n‚ùå D. Inference latency is about model performance, not accuracy."}],"isMC":true,"question_id":101,"unix_timestamp":1742480580,"timestamp":"2025-03-20 15:23:00","answer_ET":"CE"},{"id":"YOcLhFQ8brfrz9bs97Yc","question_text":"A company runs Amazon SageMaker ML models that use accelerated instances. The models require real-time responses. Each model has different scaling requirements. The company must not allow a cold start for the models.\n\nWhich solution will meet these requirements?","isMC":true,"answer_ET":"C","unix_timestamp":1742480760,"answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/169487-exam-aws-certified-machine-learning-engineer-associate-mla/","question_id":102,"answer_images":[],"discussion":[{"upvote_count":"2","comment_id":"1401606","timestamp":"1742569500.0","poster":"eesa","content":"Selected Answer: C\n‚úÖ Explanation:\nRequirements Recap:\n\n Real-time inference: Needs low-latency predictions.\n Accelerated instances: Likely GPU-backed, costly to scale inefficiently.\n No cold starts: Endpoints must always be warm and responsive.\n Each model has different scaling needs: Must support independent scaling of each model.\n\n‚úÖ Why Option C is correct:\n\n Inference components are a new SageMaker feature that allow:\n Hosting multiple models on a single endpoint.\n Independent scaling of each model (component).\n Avoiding cold starts via minimum number of copies.\n Setting min invocations or min replicas ‚â• 1 keeps the model always warm, eliminating cold starts.\n This solution meets all requirements efficiently."},{"timestamp":"1742480760.0","content":"Selected Answer: A\nthis is correct","comment_id":"1401093","upvote_count":"1","poster":"ygn4ei"}],"choices":{"A":"Create a SageMaker Serverless Inference endpoint for each model. Use provisioned concurrency for the endpoints.","B":"Create a SageMaker Asynchronous Inference endpoint for each model. Create an auto scaling policy for each endpoint.","D":"Create an Amazon S3 bucket. Store all the model artifacts in the S3 bucket. Create a SageMaker multi-model endpoint. Point the endpoint to the S3 bucket. Create an auto scaling policy for the endpoint. Set the parameter for the minimum number of copies to at least 1.","C":"Create a SageMaker endpoint. Create an inference component for each model. In the inference component settings, specify the newly created endpoint. Create an auto scaling policy for each inference component. Set the parameter for the minimum number of copies to at least 1."},"question_images":[],"answer_description":"","topic":"1","exam_id":27,"answers_community":["C (67%)","A (33%)"],"timestamp":"2025-03-20 15:26:00"},{"id":"PT5BQ725jTsDF8tqjr5Z","unix_timestamp":1741698000,"url":"https://www.examtopics.com/discussions/amazon/view/168854-exam-aws-certified-machine-learning-engineer-associate-mla/","topic":"1","answers_community":["D (100%)"],"question_images":[],"timestamp":"2025-03-11 14:00:00","exam_id":27,"answer_images":[],"answer_description":"","discussion":[{"comment_id":"1387419","content":"Selected Answer: D\nSageMaker Savings Plans offer a discount for long-term use of SageMaker instances.","timestamp":"1741698000.0","poster":"chris_spencer","upvote_count":"1"}],"answer":"D","question_text":"A company runs training jobs on Amazon SageMaker by using a compute optimized instance. Demand for training runs will remain constant for the next 55 weeks. The instance needs to run for 35 hours each week. The company needs to reduce its model training costs.\n\nWhich solution will meet these requirements?","question_id":103,"answer_ET":"D","isMC":true,"choices":{"B":"Use SageMaker Edge Manager for the training. Specify the instance requirement in the edge device configuration. Run the training.","A":"Use a serverless endpoint with a provisioned concurrency of 35 hours for each week. Run the training on the endpoint.","C":"Use the heterogeneous cluster feature of SageMaker Training. Configure the instance_type, instance_count, and instance_groups arguments to run training jobs.","D":"Opt in to a SageMaker Savings Plan with a 1-year term and an All Upfront payment. Run a SageMaker Training job on the instance."}},{"id":"ZM5TFnmq1asJkBTiqF7C","answer_description":"","discussion":[{"poster":"hdomingo","timestamp":"1741877760.0","upvote_count":"1","content":"Selected Answer: C\nOption C - SageMaker Clarify is built for bias detection and explainability.   \nIt can analyze training data and model predictions to identify potential biases.   \nIt provides insights into how different demographic groups are affected by the model.","comment_id":"1389445"}],"isMC":true,"question_text":"A company has an ML model that uses historical transaction data to predict customer behavior. An ML engineer is optimizing the model in Amazon SageMaker to enhance the model's predictive accuracy. The ML engineer must examine the input data and the resulting predictions to identify trends that could skew the model's performance across different demographics.\n\nWhich solution will provide this level of analysis?","question_id":104,"topic":"1","answers_community":["C (100%)"],"answer_ET":"C","answer":"C","timestamp":"2025-03-11 14:11:00","choices":{"A":"Use Amazon CloudWatch to monitor network metrics and CPU metrics for resource optimization during model training.","D":"Create AWS Lambda functions to automate data pre-processing and to ensure consistent quality of input data for the model.","C":"Use SageMaker Clarify to evaluate the model and training data for underlying patterns that might affect accuracy.","B":"Create AWS Glue DataBrew recipes to correct the data based on statistics from the model output."},"url":"https://www.examtopics.com/discussions/amazon/view/168856-exam-aws-certified-machine-learning-engineer-associate-mla/","exam_id":27,"question_images":[],"unix_timestamp":1741698660,"answer_images":[]},{"id":"m4JWxy4XJTgaWBODzmp6","question_images":[],"topic":"1","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/168857-exam-aws-certified-machine-learning-engineer-associate-mla/","timestamp":"2025-03-11 14:15:00","answer_images":[],"question_id":105,"unix_timestamp":1741698900,"answer_description":"","exam_id":27,"question_text":"A company uses 10 Reserved Instances of accelerated instance types to serve the current version of an ML model. An ML engineer needs to deploy a new version of the model to an Amazon SageMaker real-time inference endpoint.\n\nThe solution must use the original 10 instances to serve both versions of the model. The solution also must include one additional Reserved Instance that is available to use in the deployment process. The transition between versions must occur with no downtime or service interruptions.\n\nWhich solution will meet these requirements?","isMC":true,"choices":{"A":"Configure a blue/green deployment with all-at-once traffic shifting.","B":"Configure a blue/green deployment with canary traffic shifting and a size of 10%.","D":"Configure a rolling deployment with a rolling batch size of 1.","C":"Configure a shadow test with a traffic sampling percentage of 10%."},"answer":"B","discussion":[{"poster":"ygn4ei","upvote_count":"1","timestamp":"1742481480.0","content":"Selected Answer: B\nthis is it","comment_id":"1401104"},{"comment_id":"1387428","content":"Selected Answer: B\nshould be B.\n\nD doesn‚Äôt provide a clear strategy for managing traffic during the transition.","timestamp":"1741698900.0","poster":"chris_spencer","upvote_count":"2"}],"answers_community":["B (100%)"]}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","id":27,"numberOfQuestions":106,"isImplemented":true,"provider":"Amazon","isMCOnly":false,"name":"AWS Certified Machine Learning Engineer - Associate MLA-C01"},"currentPage":21},"__N_SSP":true}