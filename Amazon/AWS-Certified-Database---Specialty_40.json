{"pageProps":{"questions":[{"id":"AUObrPX0uMYJciD9RHpt","answer_description":"","question_images":[],"question_id":196,"discussion":[{"timestamp":"1669858140.0","comment_id":"732145","poster":"Sab","upvote_count":"5","content":"A\nFailover priority of writer and reader needs to be Tier-0\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.cluster-cache-mgmt.html"},{"upvote_count":"1","comment_id":"1122386","poster":"MultiAZ","content":"Selected Answer: A\nA\nTier-o is needed as per https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.cluster-cache-mgmt.html","timestamp":"1705221060.0"},{"comment_id":"754309","poster":"Don2021","upvote_count":"1","content":"A\nSet the value of the apg_ccm_enabled cluster parameter to 1 and both writer and reader tier 0 for failover priority.","timestamp":"1671807240.0"},{"upvote_count":"1","content":"I donâ€™t know guys & gals, distributing optimizer plans globally seem to me to be a better way to get consistent query performance from the failover. \n\nhttps://aws.amazon.com/about-aws/whats-new/2018/12/amazon-aurora-postgresql-compatibility-adds-query-plan-management/","poster":"Llytle","timestamp":"1671651000.0","comment_id":"752685"},{"comment_id":"744806","poster":"Mardoyyy","timestamp":"1671000840.0","content":"Selected Answer: A\nA\nFailover priority of writer and reader needs to be Tier-0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1670734740.0","content":"Selected Answer: A\nrefer the link given by Sab","comment_id":"741417","poster":"amulbaba"}],"exam_id":22,"answers_community":["A (100%)"],"answer_images":[],"answer_ET":"A","timestamp":"2022-12-01 02:29:00","isMC":true,"question_text":"A company is using an Amazon Aurora PostgreSQL DB cluster for the backend of its mobile application. The application is running continuously and a database specialist is satisfied with high availability and fast failover, but is concerned about performance degradation after failover.\n\nHow can the database specialist minimize the performance degradation after failover?","answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/89481-exam-aws-certified-database-specialty-topic-1-question-275/","choices":{"C":"Enable Query Plan Management for the Aurora DB cluster and perform a manual plan capture","B":"Enable cluster cache management tor the Aurora DB cluster and set the promotion priority for the writer DB instance and replica to tier-1","D":"Enable Query Plan Management for the Aurora DB cluster and force the query optimizer to use the desired plan","A":"Enable cluster cache management for the Aurora DB cluster and set the promotion priority for the writer DB instance and replica to tier-0"},"topic":"1","unix_timestamp":1669858140},{"id":"yC8NMUNeDdHCS67DPzG3","answer_ET":"B","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/90980-exam-aws-certified-database-specialty-topic-1-question-276/","topic":"1","answers_community":["B (100%)"],"question_images":[],"answer":"B","exam_id":22,"timestamp":"2022-12-11 06:01:00","choices":{"B":"Use AWS DMS to perform data migration and use the AWS Schema Conversion Tool (AWS SCT) to automatically generate the converted code","C":"Use the AWS Schema Conversion Tool (AWS SCT) to automatically convert all types of Oracle schemas to PostgreSQL and migrate the data to Aurora","A":"Use AWS DMS to perform data migration and to automatically create all schemas with Aurora PostgreSQL","D":"Use the dump and pg_dump utilities for both data migration and schema conversion"},"unix_timestamp":1670734860,"answer_description":"","isMC":true,"discussion":[{"poster":"Pranava_GCP","timestamp":"1694150640.0","content":"Selected Answer: B\nB. AWS DMS for data migration and AWS SCT for generating the converted code\n\n\"AWS SCT will automatically assess and convert the source database schema and a majority of the database code objects, including views, stored procedures, and functions, to a format compatible with the target database. Any objects that cannot be automatically converted are clearly marked as action items with prescriptive instructions on how to convert, so that they can be manually converted to complete the migration.\nAWS SCT can also scan your application source codes for embedded SQL statements and convert them as part of a database-schema-conversion project. During this process, AWS SCT performs cloud-native code optimization by converting legacy Oracle and SQL Server functions to their equivalent AWS service, helping to modernize the applications at the same time of database migration. Once schema conversion is complete, it can help migrate data from a range of data warehouses to Amazon Redshift using built-in data migration agents.\"\n\nhttps://aws.amazon.com/dms/schema-conversion-tool/","upvote_count":"3","comment_id":"1002141"},{"timestamp":"1680524640.0","comment_id":"859892","upvote_count":"1","content":"B\nUsing AWS DMS for data migration is a suitable approach as it can migrate data from Oracle to Aurora PostgreSQL with minimal downtime. However, it does not address the issue of converting the Oracle code to PostgreSQL.\n\nUsing AWS SCT can help with the conversion of stored procedures and functions, as well as application source code with embedded SQL statements. AWS SCT also allows for customization and manual intervention where needed. It can generate the converted code and provide recommendations for any manual changes required.","poster":"Mintwater"},{"comment_id":"836387","content":"B, but this is not SCS exam question","upvote_count":"1","timestamp":"1678558860.0","poster":"awsguru1998"},{"content":"Selected Answer: B\nB is the right answer SCT doesn't migrate data","comment_id":"805627","upvote_count":"3","poster":"guau","timestamp":"1676146620.0"},{"upvote_count":"2","comment_id":"741418","content":"Selected Answer: B\nB is correct . SCT can not be used for migration , It helps to generate code for conversion of non compatible components / items .","timestamp":"1670734860.0","poster":"amulbaba"}],"question_text":"A company wants to move its on-premises Oracle database to an Amazon Aurora PostgreSQL DB cluster. The source database includes 500 GB of data. 900 stored procedures and functions, and application source code with embedded SQL statements. The company understands there are some database code objects and custom features that may not be automatically converted and may need some manual intervention. Management would like to complete this migration as fast as possible with minimal downtime.\n\nWhich tools and approach should be used to meet these requirements?","question_id":197},{"id":"38DsHMqm9Gi5WSxnk4bI","answer_images":[],"answer_description":"","timestamp":"2022-12-01 02:35:00","choices":{"A":"Create a manual backup of the existing Redis replication group by using the create-snapshot command. Restore from the backup by using the create-replication-group command","E":"Use the --at-rest-encryption-enabled parameter on the new Redis replication group","B":"Use the --transit-encryption-enabled parameter on the new Redis replication group","F":"Create a manual backup of the existing Redis replication group by using the CreateBackupSelection command. Restore from the backup by using the StartRestoreJob command","D":"Use the --transit-encryption-enabled parameter on the existing Redis replication group","C":"Use the --at-rest-encryption-enabled parameter on the existing Redis replication group"},"url":"https://www.examtopics.com/discussions/amazon/view/89482-exam-aws-certified-database-specialty-topic-1-question-277/","question_id":198,"question_images":[],"answer":"ABE","isMC":true,"answers_community":["ABE (100%)"],"answer_ET":"ABE","discussion":[{"comment_id":"732154","upvote_count":"8","content":"ABE\nTLS and Encryption at rest cannot be configured on existing cluster.\nSnapshot CLI command - create-snapshot\nRestore snapshot to a new cluster :- create-cache-cluster or create-replication-group","timestamp":"1669858500.0","poster":"Sab"},{"upvote_count":"5","comment_id":"744815","content":"Selected Answer: ABE\nABE\nTLS and Encryption at rest cannot be configured on existing cluster.","poster":"Mardoyyy","timestamp":"1671001620.0"},{"timestamp":"1694699160.0","comment_id":"1007704","upvote_count":"1","content":"Selected Answer: ABE\nTLS and encryption at rest cannot be configured on existing cluster","poster":"DanShone"},{"comment_id":"830387","timestamp":"1678056060.0","poster":"sk1974","upvote_count":"1","content":"Could be DAB too . https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/in-transit-encryption.html"}],"question_text":"A company recently launched a mobile app that has grown in popularity during the last week. The company started development in the cloud and did not initially follow security best practices during development of the mobile app. The mobile app gives customers the ability to use the platform anonymously. Platform architects use Amazon ElastiCache for Redis in a VPC to manage session affinity (sticky sessions) and cookies for customers.\n\nThe company's security team now mandates encryption in transit and encryption at rest for all traffic. A database specialist is using the AWS CLI to comply with this mandate.\n\nWhich combination of steps should the database specialist take to meet these requirements? (Choose three.)","unix_timestamp":1669858500,"exam_id":22,"topic":"1"},{"id":"TE7xIoNt4RojVFWzqSFl","discussion":[{"poster":"Pranava_GCP","comment_id":"1001937","content":"Selected Answer: C\nC. MongoDB explain() method","upvote_count":"2","timestamp":"1694128740.0"},{"timestamp":"1684933680.0","content":"Selected Answer: C\nexplain() in order to retrieve the query plan, since that was the question...","poster":"aviathor","upvote_count":"3","comment_id":"905910"},{"poster":"Sab","upvote_count":"4","comment_id":"733088","timestamp":"1669927560.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/documentdb/latest/developerguide/user_diagnostics.html#user_diagnostics-query_plan"},{"content":"C\nIf a query runs slow, it could be because the query execution requires a full scan of the collection to choose the relevant documents. Sometimes creating appropriate indexes enables the query to run faster. To detect this scenario and decide the fields on which to create the indexes, use the explain command.\n\nhttps://docs.aws.amazon.com/documentdb/latest/developerguide/user_diagnostics.html#user_diagnostics-query_plan","upvote_count":"4","timestamp":"1669858740.0","comment_id":"732158","poster":"Sab"}],"answer_ET":"C","answers_community":["C (100%)"],"unix_timestamp":1669858740,"question_images":[],"topic":"1","timestamp":"2022-12-01 02:39:00","answer_description":"","answer_images":[],"question_id":199,"url":"https://www.examtopics.com/discussions/amazon/view/89484-exam-aws-certified-database-specialty-topic-1-question-278/","answer":"C","question_text":"A company is using Amazon DocumentDB (with MongoDB compatibility) to manage its complex documents. Users report that an Amazon DocumentDB cluster takes a long time to return query results. A database specialist must investigate and resolve this issue.\n\nWhich of the following can the database specialist use to investigate the query plan and analyze the query performance?","exam_id":22,"choices":{"C":"MongoDB explain() method","B":"Amazon CloudWatch Logs Insights","D":"AWS CloudTrail with a custom filter","A":"AWS X-Ray deep linking"},"isMC":true},{"id":"4jmopO7jPZuo3D2Ktr2I","timestamp":"2022-11-30 18:11:00","question_text":"A company's database specialist is migrating a production Amazon RDS for MySQL database to Amazon Aurora MySQL. The source database is configured for Multi-AZ. The company's production team wants to validate the target database before switching the associated application over to use the new database endpoint. The database specialist plans to use AWS Database Migration Service (AWS DMS) for the migration.\n\nWhich steps should the database specialist perform to meet the production team's requirement? (Choose three.)","discussion":[{"upvote_count":"6","content":"Selected Answer: ACE\nI think the answer is ACE. However, C should be binlog_format (not binlog format(. The information below is from https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.MySQL.html#CHAP_Source.MySQL.Homogeneous.\nWhen using an AWS-managed MySQL-compatible database as a source for AWS DMS, make sure that you have the following prerequisites for CDC:\n\nTo enable binary logs for RDS for MySQL and for RDS for MariaDB, enable automatic backups at the instance level.\nSet the binlog_format parameter to \"ROW\".","poster":"DBA_MJF","comment_id":"731783","timestamp":"1669828260.0"},{"timestamp":"1705221660.0","upvote_count":"1","poster":"MultiAZ","content":"ACE\nThe binlog_format has to be ROW as per https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.MySQL.html","comment_id":"1122392"},{"content":"why not D? MIXED is recommended unless you have a need for a specific binlog format.","timestamp":"1701676200.0","poster":"calduck","comment_id":"1087405","upvote_count":"1"},{"comment_id":"1007705","timestamp":"1694699280.0","content":"Selected Answer: ACE\nACE Is Correct","poster":"DanShone","upvote_count":"1"},{"comment_id":"733728","timestamp":"1669985880.0","upvote_count":"4","content":"ACE should be right.","poster":"satishstechie"}],"answer":"ACE","answer_ET":"ACE","exam_id":22,"answer_images":[],"choices":{"A":"Enable automatic backups on the source database","B":"Disable automatic backups on the source database","D":"Enable binary logging. Set the binlog_format parameter to MIXED on the source database","F":"Use the source secondary database as the source endpoint for the DMS task. Configure the task as full load plus change data capture (CDC) to complete the migration","E":"Use the source primary database as the source endpoint for the DMS task. Configure the task as full load plus change data capture(CDC) to complete the migration","C":"Enable binary logging. Set the binlog format parameter to ROW on the source database."},"topic":"1","question_id":200,"isMC":true,"answer_description":"","unix_timestamp":1669828260,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/89425-exam-aws-certified-database-specialty-topic-1-question-279/","answers_community":["ACE (100%)"]}],"exam":{"isImplemented":true,"isMCOnly":false,"isBeta":false,"id":22,"lastUpdated":"11 Apr 2025","numberOfQuestions":359,"provider":"Amazon","name":"AWS Certified Database - Specialty"},"currentPage":40},"__N_SSP":true}