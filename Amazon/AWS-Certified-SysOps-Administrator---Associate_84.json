{"pageProps":{"questions":[{"id":"E5iTUaL9isP8DNjw5NoG","answers_community":["B (75%)","D (25%)"],"answer_ET":"B","question_text":"A company is using an Amazon EC2 Auto Scaling group to support a workload. A SysOps administrator finds that the Auto Scaling group is configured with two similar scaling policies.\n\nOne scaling policy adds 5 instances when CPU utilization reaches 80%. The other scaling policy adds 10 instances when CPU utilization reaches 80%.\n\nWhat will happen when CPU utilization reaches the 80% threshold?","url":"https://www.examtopics.com/discussions/amazon/view/150469-exam-aws-certified-sysops-administrator-associate-topic-1/","discussion":[{"content":"Selected Answer: B\nWhen these situations occur, Amazon EC2 Auto Scaling chooses the policy that provides the largest capacity for both scale out and scale in.\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html?utm_source=chatgpt.com#multiple-scaling-policy-resolution","poster":"robotgeek","timestamp":"1738046160.0","comment_id":"1347759","upvote_count":"2"},{"upvote_count":"1","poster":"examaws","timestamp":"1735731180.0","content":"Selected Answer: D\nD. The Auto Scaling group will not scale because of conflicting policies.\nThis is correct because Auto Scaling does not execute either policy when they conflict. The presence of two policies that trigger at the same threshold with different scaling actions leads to a situation where no scaling occurs.","comment_id":"1335180"},{"poster":"numark","comment_id":"1314629","content":"I thought it was 10 as well, but chatGPT stated 15>>>> When the CPU utilization of the Auto Scaling group reaches the 80% threshold, both scaling policies will trigger concurrently because they are configured with the same condition (CPU utilization reaching 80%). As a result:\n\nThe first scaling policy will attempt to add 5 instances.\nThe second scaling policy will attempt to add 10 instances.\nThis will result in the Auto Scaling group trying to launch a total of 15 new instances simultaneously.","upvote_count":"1","comments":[{"poster":"numark","content":"In the scenario described, if an Amazon EC2 Auto Scaling group has two scaling policies that both trigger at the same CPU utilization level (80% in this case), and if both policies are active, then both will be executed when the threshold is reached. This means that if one policy adds 5 instances and the other adds 10 instances when the CPU utilization hits 80%, then a total of 15 instances will be added to the Auto Scaling group if the threshold is met and sustained for the duration specified by the policy's cool-down period.In a real-world scenario, the execution of scaling policies would also be influenced by the cooldown timers set within the Auto Scaling group configuration. If the cooldown period is still in effect from a previous scaling activity, it may temporarily prevent another scaling activity from being triggered by the second policy. But assuming that both policies are able to trigger without any cooldown conflicts, the described behavior (adding a total of 15 instances) would occur.","comment_id":"1323204","upvote_count":"1","timestamp":"1733589900.0"}],"timestamp":"1732020360.0"},{"timestamp":"1730222160.0","comment_id":"1304612","poster":"Aamee","upvote_count":"1","content":"Selected Answer: B\nLogically, 10 instances should scale up with 80% utilization as it may not add with the previous instances so going with B here..."}],"answer_description":"","isMC":true,"answer":"B","answer_images":[],"choices":{"D":"The Auto Scaling group will not scale because of conflicting policies.","C":"Amazon EC2 Auto Scaling will add 15 instances.","A":"Amazon EC2 Auto Scaling will add 5 instances.","B":"Amazon EC2 Auto Scaling will add 10 instances."},"exam_id":34,"timestamp":"2024-10-29 18:16:00","question_images":[],"topic":"1","question_id":416,"unix_timestamp":1730222160},{"id":"Tr982vpxkcTIzTckoA14","isMC":true,"exam_id":34,"timestamp":"2024-10-29 18:34:00","question_id":417,"answer":"D","answer_images":[],"choices":{"C":"Migrate to a new Aurora DB cluster that has multiple writer instances. Modify the application's database connection string.","B":"Modify the DB cluster by changing to serverless mode whenever the number of user connections exceeds 200.","A":"Modify the DB cluster by increasing the Aurora Replica instance size.","D":"Create an auto scaling policy that has a target value of 195 for the DatabaseConnections metric."},"discussion":[{"content":"D and chatGPT agrees>>>>To address the read performance degradation and ensure the application scales automatically based on user demand, the SysOps administrator should optimize the Amazon Aurora MySQL DB cluster for scaling. Here's the solution:Navigate to the Aurora DB cluster.\nUnder the \"Read Replicas\" section, enable Auto Scaling.\nDefine scaling policies (e.g., target CPU utilization or custom CloudWatch metrics such as DatabaseConnections).","comments":[{"upvote_count":"1","content":"Amazon Aurora supports auto scaling of read replicas based on the actual workload. By setting an auto scaling policy that targets a metric like the DatabaseConnections metric, you ensure that additional read replicas are added when the number of connections approaches the specified threshold (in this case, 195). When the number of user connections decreases, the auto scaling policy can also remove replicas to reduce costs. This approach allows the database to handle increases or decreases in demand automatically.","timestamp":"1733590020.0","poster":"numark","comment_id":"1323206"}],"timestamp":"1732020720.0","upvote_count":"1","poster":"numark","comment_id":"1314634"},{"content":"Selected Answer: D\nD makes most sense here..","timestamp":"1730223240.0","upvote_count":"1","comment_id":"1304619","poster":"Aamee"}],"answer_description":"","question_text":"An application uses an Amazon Aurora MySQL DB cluster that includes one Aurora Replica. The application's read performance degrades when there are more than 200 user connections. The number of user connections is approximately 180 on a consistent basis. Occasionally, the number of user connections increases rapidly to more than 200.\n\nA SysOps administrator must implement a solution that will scale the application automatically as user demand increases or decreases.\n\nWhich solution will meet these requirements?","answer_ET":"D","unix_timestamp":1730223240,"url":"https://www.examtopics.com/discussions/amazon/view/150470-exam-aws-certified-sysops-administrator-associate-topic-1/","topic":"1","answers_community":["D (100%)"],"question_images":[]},{"id":"aPhG6n7myamFRyWPGxXw","unix_timestamp":1732021140,"answer_ET":"A","answers_community":["A (100%)"],"topic":"1","exam_id":34,"answer_images":[],"question_id":418,"question_text":"A company runs a single-page web application on AWS. The application uses Amazon CloudFront to deliver static content from an Amazon S3 bucket origin. The application also uses an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to serve API calls.\n\nUsers sometimes report that the website is not operational, even when monitoring shows that the index page is reachable and that the EKS cluster is healthy. A SysOps administrator must implement additional monitoring that can detect when the website is not operational before users report the problem.\n\nWhich solution will meet these requirements?","isMC":true,"discussion":[{"timestamp":"1732262160.0","poster":"igor12ghsj577","comment_id":"1316198","upvote_count":"2","content":"Selected Answer: A\nI would say better is A. It checks end to end, not only API calls."},{"poster":"numark","comments":[{"poster":"numark","upvote_count":"1","comment_id":"1323209","timestamp":"1733590380.0","content":"it is A>>Amazon CloudWatch Synthetics allows you to create canaries to monitor your endpoints and APIs. A heartbeat monitor canary is like a scheduled task that automatically performs health checks at specified intervals. By creating a canary that points to the FQDN of the website, you can test the entire front-end application stack, including content delivery through Amazon CloudFront and the static content hosting on Amazon S3. While monitoring the API endpoints is important for ensuring that the application's backend is functioning correctly, it does not provide a complete picture of the user experience. Since the reported issue is that the website is not operational, it suggests that the problem may not be with the backend alone but could include the front end and the interaction between the front end and the backend."}],"upvote_count":"1","content":"Answer is B and chatGPT agrees: Answer is B and chatGPT agrees: to detect when the website is not operational before users report the problem, the SysOps administrator should implement synthetic monitoring. Create a CloudWatch Synthetics Canary: Amazon CloudWatch Synthetics allows you to create canaries, which are scripts that run on a scheduled basis to simulate user interactions with the web application. The canaries can check if both the index page (served from S3) and API endpoints (served from EKS) are reachable and functioning as expected.","timestamp":"1732021140.0","comment_id":"1314637"}],"answer_description":"","choices":{"B":"Create an Amazon CloudWatch Synthetics API canary that monitors the availability of API endpoints from the EKS cluster.","A":"Create an Amazon CloudWatch Synthetics heartbeat monitor canary that points to the fully qualified domain name (FQDN) of the website.","D":"Create an Amazon CloudWatch RUM app monitor that uses the API endpoints from the EKS cluster.","C":"Create an Amazon CloudWatch RUM app monitor that points to the fully qualified domain name (FQDN) of the website. Configure the app monitor to collect performance telemetry and JavaScript errors."},"url":"https://www.examtopics.com/discussions/amazon/view/151636-exam-aws-certified-sysops-administrator-associate-topic-1/","answer":"A","timestamp":"2024-11-19 13:59:00","question_images":[]},{"id":"kQk136p0t0TdWsMaGzTn","answer_description":"","timestamp":"2024-10-29 20:26:00","choices":{"A":"Ensure that the Delete on termination setting is turned off in the UserData section of the launch template.","B":"Update the Auto Scaling group by enabling instance scale-in protection for newly launched instances.","D":"Use Amazon GuardDuty to configure rules to protect the instances from termination.","C":"Use Amazon Inspector to configure a rules package to protect the instances from termination."},"answer":"B","answer_ET":"B","isMC":true,"question_text":"A company hosts an application on Amazon EC2 instances. The instances are in an Amazon EC2 Auto Scaling group that uses a launch template. The amount of application traffic changes throughout the day. Scaling events happen frequently.\n\nA SysOps administrator needs to help developers troubleshoot the application. When a scaling event removes an instance, EC2 Auto Scaling terminates the instance before the developers can log in to the instance to diagnose issues.\n\nWhich solution will prevent termination of the instance so that the developers can log in to the instance?","answer_images":[],"exam_id":34,"question_id":419,"answers_community":["B (75%)","A (25%)"],"topic":"1","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/150474-exam-aws-certified-sysops-administrator-associate-topic-1/","unix_timestamp":1730229960,"discussion":[{"poster":"numark","comment_id":"1323212","content":"Selected Answer: B\nInstance scale-in protection is a feature that can be used to prevent specific EC2 instances in an Auto Scaling group from being terminated during scale-in events. By enabling this for the instances, developers can have the time they need to log in and diagnose any issues. This protection can be enabled manually on individual instances, or it can be configured so that it is automatically applied to new instances when they are launched. The \"Delete on termination\" setting in the launch template primarily applies to the Amazon Elastic Block Store (EBS) volumes associated with the instance. Turning this setting off would only mean that the EBS volumes are not deleted when the instance is terminated.","upvote_count":"2","timestamp":"1733590560.0"},{"content":"of course B...","comment_id":"1316201","timestamp":"1732262340.0","upvote_count":"1","poster":"igor12ghsj577"},{"content":"Selected Answer: B\nEither A or B but B makes complete sense here..","upvote_count":"1","poster":"Aamee","timestamp":"1730229960.0","comment_id":"1304666"}]},{"id":"tiJwv2mWW89X9xoXntr4","url":"https://www.examtopics.com/discussions/amazon/view/150477-exam-aws-certified-sysops-administrator-associate-topic-1/","answer_images":[],"unix_timestamp":1730231160,"choices":{"B":"Configure an S3 bucket policy that requires all current and future S3 buckets to have logging enabled.","C":"Use the s3-bucket-logging-enabled AWS Config managed rule. Add a remediation action that uses an AWS Lambda function to enable logging.","A":"Use AWS Trusted Advisor to perform a check for S3 buckets that do not have logging enabled. Configure the check to enable logging for S3 buckets that do not have logging enabled.","D":"Use the s3-bucket-logging-enabled AWS Config managed rule. Add a remediation action that uses the AWS-ConfigureS3BucketLogging AWS Systems Manager Automation runbook to enable logging."},"question_images":[],"isMC":true,"timestamp":"2024-10-29 20:46:00","question_id":420,"answer_ET":"D","answer_description":"","question_text":"A SysOps administrator must ensure that all of a company's current and future Amazon S3 buckets have logging enabled. If an S3 bucket does not have logging enabled, an automated process must enable logging for the S3 bucket.\n\nWhich solution will meet these requirements?","exam_id":34,"discussion":[{"content":"Selected Answer: D\nprebuilt AWS Systems Manager Automation runbook (AWS-ConfigureS3BucketLogging)","poster":"igor12ghsj577","comment_id":"1316204","timestamp":"1732262580.0","upvote_count":"3"},{"comments":[{"comment_id":"1323214","upvote_count":"1","content":"D This solution meets the requirements by ensuring all current and future S3 buckets have logging enabled, and if any do not, it enables logging through an automated process without the need for writing custom scripts by using Lambda.","timestamp":"1733590800.0","poster":"numark"}],"poster":"numark","comment_id":"1314641","upvote_count":"1","timestamp":"1732021560.0","content":"S3 is not a system... Answer is C and ChatGPT agress>>>To ensure that all current and future Amazon S3 buckets have logging enabled, and to automatically enable logging for any S3 bucket that does not have it configured, the SysOps administrator can use AWS Config with AWS Lambda to automate this process."},{"timestamp":"1730231160.0","upvote_count":"2","comment_id":"1304679","poster":"Aamee","content":"Selected Answer: D\nSince it's been specifically asked about an automated method to enable for existing and future buckets so that's why Config Rule for automated detection and Systems Manager Automation Runbook for automated enabling makes a perfect combination via option D IMO."}],"topic":"1","answer":"D","answers_community":["D (100%)"]}],"exam":{"isMCOnly":false,"isImplemented":true,"lastUpdated":"11 Apr 2025","isBeta":false,"name":"AWS Certified SysOps Administrator - Associate","provider":"Amazon","id":34,"numberOfQuestions":477},"currentPage":84},"__N_SSP":true}