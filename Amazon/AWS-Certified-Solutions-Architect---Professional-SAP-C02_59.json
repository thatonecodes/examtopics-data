{"pageProps":{"questions":[{"id":"ew6GTKaHlFOWo6f3OLjc","answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/126826-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_description":"","discussion":[{"content":"Selected Answer: C\nOption C. Option A does not provide control over deployment of resources and configurations.","poster":"career360guru","upvote_count":"5","comment_id":"1117992","timestamp":"1704849000.0"},{"upvote_count":"1","comment_id":"1409618","content":"Selected Answer: C\nAWS Service Catalog permite definir plantillas preaprobadas para lanzar EMR clusters con configuraciones controladas (versiones, aplicaciones, seguridad).\n\nSe pueden definir permisos por rol (por persona o grupo de IAM) para controlar qué acciones puede realizar cada usuario.\n\nSe pueden forzar políticas de etiquetado obligatorio mediante plantillas y restricciones de uso.\n\nGarantiza el principio de menor privilegio, ya que los usuarios no tienen acceso completo a EMR sino sólo a lo autorizado por Service Catalog.\n\nIdeal para ambientes empresariales donde se necesita control centralizado, gobernanza y cumplimiento","poster":"eesa","timestamp":"1742809740.0"},{"poster":"AzureDP900","timestamp":"1731794400.0","upvote_count":"1","comment_id":"1313286","content":"Using AWS Service Catalog (Option C) to control the Amazon EMR versions available for deployment, the cluster configuration, and the permissions for each user persona meets all the requirements:\n\n\n\nIt provides a centralized management interface for IT services\n\nIt allows you to define and enforce policies for resource provisioning and access control\n\nIt enables you to manage multiple instances of an application (in this case, EMR clusters) from a single console"},{"poster":"AloraCloud","comment_id":"1297238","content":"Why not Option A is because it involves creating IAM roles and attaching identity-based policies, which is solid. But it relies on AWS Config rules to ensure compliance, which adds an extra layer of management and potential lag in remediation. \n\nAWS Service Catalog, on the other hand, simplifies control over EMR versions, configurations, and permissions, and it also enforces resource tagging directly during deployment, making it more efficient and streamlined for managing access and compliance.","timestamp":"1728887100.0","upvote_count":"1"},{"poster":"gfhbox0083","comment_id":"1247293","upvote_count":"1","timestamp":"1720873020.0","content":"Selected Answer: C\nC, for sure.\nAWS Service Catalog ensures that all resources created are compliant with the organization's policies, including mandatory tagging."},{"upvote_count":"3","comment_id":"1117849","timestamp":"1704834540.0","content":"Selected Answer: C\nC because tagging ensured by Service Catalogue.","poster":"JMAN1"},{"content":"Selected Answer: C\nOption A: While IAM roles and identity-based policies offer user-level control, they lack the functionality for managing EMR deployment options and configurations centrally.","poster":"vibzr2023","timestamp":"1704650640.0","comment_id":"1116055","upvote_count":"1"},{"upvote_count":"4","comment_id":"1096846","timestamp":"1702589520.0","poster":"awsamar","content":"Selected Answer: C\nkeyword here are: \"...only applications that are approved and authorized...\"\nOnly C provides this"},{"comments":[{"content":"it seems that I was wrong and C is the approach as per: https://aws.amazon.com/blogs/big-data/build-a-self-service-environment-for-each-line-of-business-using-amazon-emr-and-aws-service-catalog/","poster":"ayadmawla","upvote_count":"5","timestamp":"1703006340.0","comment_id":"1100848"}],"comment_id":"1091891","upvote_count":"4","content":"Selected Answer: A\nA - IAM Roles define actions Service Catalogue is about resources (EMR)","poster":"ayadmawla","timestamp":"1702137480.0"},{"poster":"shaaam80","upvote_count":"1","timestamp":"1701860040.0","content":"Please vote your answers rather than just commenting. It skews the vote % for someone who doesnt read all the comments.","comment_id":"1089215"},{"poster":"dutchy1988","content":"It seems that AWS is upselling AWS Service Catalog here with this question. Some key parts in this question:\n1. Least privilige access\n2. launch only approved and authorized applications\n3. ensure tagging.","upvote_count":"2","timestamp":"1701680880.0","comment_id":"1087456","comments":[{"comment_id":"1087457","timestamp":"1701680880.0","comments":[{"timestamp":"1701680880.0","comment_id":"1087458","poster":"dutchy1988","upvote_count":"4","content":"Leaves only C, \nquote from https://aws.amazon.com/servicecatalog/\nCreate, organize, and govern a curated catalog of AWS resources that can be shared at the permissions level so you can quickly provision approved cloud resources without needing direct access to the underlying AWS services. -> meets only allowed and authorized application launch. \nAutoTag fulfills the requirement to tag resources with creator -> aws:servicecatalog:provisioningPrincipalArn - The ARN of the provisioning principal (user) who created the provisioned product.\n\nthis can only be AWS Server Catalog.\n\nand please stop seeding GPT answers! do your own research."}],"content":"due to point 3, all options with AWS config rule are out since it only measures if you are compliant, so that means tagging is not ensured upfront. A and D are out!\nB doenst fullfill the requirement for tagging and even more, is kerberos really helpfull here?","poster":"dutchy1988","upvote_count":"2"}]},{"upvote_count":"3","poster":"PouyaK","comment_id":"1085553","content":"Answer A - \nThe answers from Chat GPT are inaccurate and untrustable.","timestamp":"1701472500.0"},{"poster":"shaaam80","content":"Selected Answer: C\nFrom GPT: AWS Service Catalog allows you to control and manage access to resources by defining portfolios and products with specific permissions. Allows you to create portfolios with approved and authorized applications, ensuring that only the specified applications are launched. AWS Service Catalog can enforce tagging on provisioned resources, ensuring that all resources created by the user personas are appropriately tagged.","upvote_count":"3","timestamp":"1701227700.0","comment_id":"1083081"},{"timestamp":"1700947200.0","content":"Selected Answer: C\nC is correct: AWS Service Catalog allows organizations to create and manage catalogs of IT services that are approved for use on AWS. This is ideal for controlling which Amazon EMR versions and cluster configurations are available to users. Specific cluster configurations and permissions can be set for each user persona, ensuring they have only the access they need. This meets the least privilege principle. The Service Catalog can be configured to allow users to launch only certain applications, ensuring adherence to company policies on approved and authorized software. It also supports resource tagging.","upvote_count":"3","comment_id":"1080344","poster":"heatblur"},{"content":"A is correct\n\nAws:\nTo ensure that all user personas have least privilege access to only the resources they need, can launch only approved and authorized applications, and ensure tagging for all resources that the user personas create, a solutions architect can consider the following steps:\n1. IAM roles for each user persona. Attach identity-based policies to define which actions the user who assumes the role can perform.\n2.Create an AWS Config rule to check for noncompliant resources. Configure the rule to notify the administrator to remediate the noncompliant resources.","upvote_count":"1","poster":"devalenzuela86","timestamp":"1700898540.0","comment_id":"1079813"},{"comment_id":"1077012","poster":"cypkir","timestamp":"1700635020.0","upvote_count":"1","content":"Selected Answer: C\nAnswer: C"}],"question_images":[],"question_text":"A financial services company has an asset management product that thousands of customers use around the world. The customers provide feedback about the product through surveys. The company is building a new analytical solution that runs on Amazon EMR to analyze the data from these surveys. The following user personas need to access the analytical solution to perform different actions:\n\n• Administrator: Provisions the EMR cluster for the analytics team based on the team’s requirements\n• Data engineer: Runs ETL scripts to process, transform, and enrich the datasets\n• Data analyst: Runs SQL and Hive queries on the data\n\nA solutions architect must ensure that all the user personas have least privilege access to only the resources that they need. The user personas must be able to launch only applications that are approved and authorized. The solution also must ensure tagging for all resources that the user personas create.\n\nWhich solution will meet these requirements?","answer_images":[],"timestamp":"2023-11-22 07:37:00","unix_timestamp":1700635020,"answers_community":["C (84%)","A (16%)"],"topic":"1","isMC":true,"answer":"C","choices":{"D":"Launch the EMR cluster by using AWS CloudFormation, Attach resource-based policies to the EMR cluster during cluster creation. Create an AWS. Config rule to check for noncompliant clusters and noncompliant Amazon S3 buckets. Configure the rule to notify the administrator to remediate the noncompliant resources.","C":"Use AWS Service Catalog to control the Amazon EMR versions available for deployment, the cluster configuration, and the permissions for each user persona.","A":"Create IAM roles for each user persona. Attach identity-based policies to define which actions the user who assumes the role can perform. Create an AWS Config rule to check for noncompliant resources. Configure the rule to notify the administrator to remediate the noncompliant resources.","B":"Setup Kerberos-based authentication for EMR clusters upon launch. Specify a Kerberos security configuration along with cluster-specific Kerberos options."},"question_id":291,"exam_id":33},{"id":"TgBOBgg1RZjpxcBPvbfN","answer":"B","answers_community":["B (50%)","A (50%)"],"unix_timestamp":1700635140,"answer_description":"","answer_images":[],"discussion":[{"upvote_count":"16","poster":"heatblur","content":"Selected Answer: B\nThe best option among these is B. While it introduces some complexity, it's the most viable solution that aligns with AWS capabilities and the company's requirements. Creating an NLB in us-east-1 and targeting the IP addresses of the existing instances in eu-west-2 is a feasible approach. This setup allows the company to use their existing infrastructure in eu-west-2 while providing access to the customer in us-east-1 through the PrivateLink endpoint service in us-east-1. This avoids the immediate need to deploy new EC2 resources in the us-east-1 region.\n\nIt can't be A because AWS PrivateLink endpoint services cannot span regions. They are region-specific, so an endpoint service in us-east-1 cannot directly use an NLB located in eu-west-2.","comment_id":"1084663","timestamp":"1701370140.0","comments":[{"content":"I was unable to find documentation saying that an AWS PrivateLink endpoint requires the NLB to be in the same region but if you go to the console for instance here:\n\nhttps://eu-west-1.console.aws.amazon.com/vpcconsole/home?region=eu-west-1#CreateVpcEndpointServiceConfiguration:\n\ntry to create an endpoint service and you don't have a NLB there the console explicitly states:\n\n\"No Network Load Balancers or Gateway Load Balancers available in this Region.\" so for me A in invalid","poster":"liquen14","upvote_count":"4","timestamp":"1709914980.0","comment_id":"1168942"},{"timestamp":"1712236920.0","comments":[{"content":"This is saying you can access privatelink in us-east-1 from ec2 instance in eu-west-1. It does not say that you can create a privatelink in us-east-1 for a resource like NLB in eu-west-1.","timestamp":"1735102020.0","poster":"pk0619","upvote_count":"1","comment_id":"1331344"}],"comment_id":"1189358","content":"Wrong on part where private link support for inter region vpc peering .\nhttps://aws.amazon.com/about-aws/whats-new/2018/10/aws-privatelink-now-supports-access-over-inter-region-vpc-peering/","upvote_count":"4","poster":"SKS"},{"comment_id":"1091894","timestamp":"1702137780.0","content":"But the company has establishing Inter-Region VPC Peering so the endpoint would work","upvote_count":"2","poster":"ayadmawla"}]},{"comments":[{"upvote_count":"2","content":"Answer is A because ... VPC peering between the VPCs in the two Regions already done & company does not want to immediately deploy new EC2 resources in us-east-1, later on company will change the architecture","comment_id":"1115747","timestamp":"1704625260.0","poster":"abhitricanada"},{"comment_id":"1085215","poster":"Pilot","upvote_count":"4","timestamp":"1701435600.0","content":"Network Load Balancers now support connections from clients to IP-based targets in peered VPCs across different AWS Regions. Previously, access to Network Load Balancers from an inter-region peered VPC was not possible. With this launch, you can now have clients access Network Load Balancers over an inter-region peered VPC. Network Load Balancers can also load balance to IP-based targets that are deployed in an inter-region peered VPC. This support on Network Load Balancers is available in all AWS Regions. \n\nhttps://aws.amazon.com/about-aws/whats-new/2018/10/network-load-balancer-now-supports-inter-region-vpc-peering/\n\nNLB support client from different region, I think A is correct."}],"poster":"devalenzuela86","comment_id":"1077454","content":"Selected Answer: A\nA\n\nExplanation:\n* Configuring a PrivateLink endpoint service in us-east-1 to use the existing NLB that is in eu-west-2 will allow the new customer to access the SaaS service without deploying new EC2 resources in us-east-1 1.\n* Granting specific AWS accounts access to connect to the SaaS service will ensure that only authorized users can access the service 1.","upvote_count":"15","timestamp":"1700664300.0"},{"poster":"kyo","comment_id":"1354923","content":"Selected Answer: B\nThis question was written before AWS PrivateLink supported cross-region connectivity. At that time, the only way to give a customer in us-east-1 access to a service in eu-west-2 without deploying resources in us-east-1 was the complex workaround described in Option B. This involved creating an NLB in us-east-1 and using an IP target group pointing back to the instances in eu-west-2. It was a complicated solution, but it was the only way to achieve the desired outcome given the limitations at the time. Therefore, B was the correct answer for the question as it was originally written.\n\nBut now the answer has changed to A.","timestamp":"1739265420.0","upvote_count":"2"},{"poster":"Spike2020","comment_id":"1323696","content":"Selected Answer: B\nAs of November 2024, AWS PrivateLink supports native cross-region connectivity. However, since this exam question appears to be set before this feature was available, we need to consider the solution using the previous architecture patterns.\nOption A: Not viable because PrivateLink endpoint services must be in the same region as the NLB","timestamp":"1733683800.0","upvote_count":"3"},{"poster":"TomTom","content":"Selected Answer: A\nAnswer A is correct (now) Recently AWS announce, Now PrivateLink endpoint supports native cross-region connectivity.\nhttps://aws.amazon.com/about-aws/whats-new/2024/11/aws-privatelink-across-region-connectivity/","timestamp":"1732847160.0","comments":[{"content":"A is still incorrect. Note that A requires creating an ENDPOINT SERVICE in us-east-1 that points to an NLB in us-west-2. This is not possible. What you can do is create an endpoint service in us-west-2 that points to the NLB in us-west-2 and then make the endpoint service cross-region. Then, in us-east-1, you can create an ENDPOINT that points to the ENDPOINT SERVICE in us-east-1.","comment_id":"1356002","upvote_count":"1","poster":"altonh","timestamp":"1739431980.0"},{"comment_id":"1321352","content":"The article refers to Interface VPC endpoints connectivity to VPC endpoint services, but this is not the use case here. The comment of liquen14 is still valid, I tested today 3rd of Dec 2024. When creating an endpoint service, you can only select load balancers in the same region. Hence for the current use case we must create an NLB in us-east-1, which will be able to connect to the EC2 instances over the peered VPC due to the link in Pilot's comment (however, his comment is not right, A does not work):\n\nhttps://aws.amazon.com/about-aws/whats-new/2018/10/network-load-balancer-now-supports-inter-region-vpc-peering/","comments":[{"content":"Bottom line, A does not work, B does","timestamp":"1733227200.0","comment_id":"1321353","poster":"alexbraila","upvote_count":"1"}],"upvote_count":"1","timestamp":"1733227140.0","poster":"alexbraila"}],"upvote_count":"1","comment_id":"1319516"},{"content":"Selected Answer: B\nCreating an NLB in us-east-1 with IP target group pointing to the existing eu-west-2 instances is the most efficient solution because:\nIP target groups can route traffic across VPC peering connections\nThis configuration allows the use of existing EC2 instances while providing local access in us-east-1\nPrivateLink endpoint service can be configured with the new NLB to provide secure access","upvote_count":"2","poster":"youonebe","timestamp":"1732771200.0","comment_id":"1319028"},{"poster":"0b43291","content":"Selected Answer: B\nThe correct solution is Option B: Create an NLB in us-east-1. Create an IP target group that uses the IP addresses of the company's instances in eu-west-2 that host the SaaS service. Configure a PrivateLink endpoint service that uses the NLB that is in us-east-1. Grant specific AWS accounts access to connect to the SaaS service.\n\nOption A is not possible because PrivateLink endpoint services cannot span across AWS Regions. The existing NLB in eu-west-2 cannot be directly used for a PrivateLink endpoint service in us-east-1.","timestamp":"1732230480.0","comment_id":"1316061","upvote_count":"1"},{"poster":"AzureDP900","content":"correct answer : A \nUsing an existing NLB in eu-west-2 as the basis for a PrivateLink endpoint service in us-east-1 allows the company to quickly provide access to its SaaS service without having to create new EC2 resources or configure complex networking setups.","timestamp":"1731794100.0","comment_id":"1313284","upvote_count":"1"},{"timestamp":"1730046480.0","poster":"Woody1848","comment_id":"1303658","content":"Selected Answer: A\n\"An interface endpoint is essentially a service-level ENI. The service is attached straight to\nthe VPC subnet through the ENI. This allows us to assign a private IP address from the\nsubnet pool directly to the service.\" (AWS Certified Advanced Networking - Specialty Exam Guide pg. 36)\n\nThere is no need to create EC2 resources in us-east-1 when creating a PrivateLink endpoint.","upvote_count":"1"},{"upvote_count":"1","poster":"fabriciollf","content":"Selected Answer: B\nInter-Region endpoint services\n\"Service providers can leverage a Network Load Balancer in a remote Region and create an IP target group that uses the IPs of their instance fleet in the remote Region hosting the service.\"\nhttps://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/use-case-examples.html#:~:text=Inter%2DRegion%20access%20to%20endpoint%20services,-As%20customers%20expand&text=Inter%2DRegion%20VPC%20peering%20traffic%20is%20transported%20over%20Amazon's%20network,costs%20between%20the%20two%20Regions.","timestamp":"1728599340.0","comment_id":"1295760"},{"content":"Selected Answer: B\nA is wrong, In this scenario, the existing NLB is located in the eu-west-2 Region, while the new customer is in the us-east-1 Region. PrivateLink does not support cross-Region connectivity directly. Therefore, you cannot create a PrivateLink endpoint service in us-east-1 and associate it with the NLB in eu-west-2.\n\nTo provide access to the SaaS service for the new customer in us-east-1, you need to create a load balancer (in this case, an NLB) in the us-east-1 Region and then configure a PrivateLink endpoint service in us-east-1 that uses that NLB. This NLB can then forward traffic to the instances in eu-west-2 over the inter-Region VPC peering connection, as described in the correct solution (option B).","comment_id":"1270336","timestamp":"1724264820.0","upvote_count":"2","poster":"asquared16"},{"comment_id":"1247666","poster":"mark_232323","content":"Selected Answer: B\nOption A is not possible because a PrivateLink endpoint service in us-east-1 cannot directly use an NLB in another Region (eu-west-2).","upvote_count":"2","timestamp":"1720942260.0"},{"content":"Selected Answer: A\na because of this https://aws.amazon.com/about-aws/whats-new/2018/10/aws-privatelink-now-supports-access-over-inter-region-vpc-peering/","comment_id":"1207911","comments":[{"content":"it is accessing private endpoint from remote region, it is not possible to configure private endpoint to a nlb in the remote region.","comments":[{"timestamp":"1723457940.0","content":"A is correct.\n\nIn this case, the remote EU region is accessing US region, becuase the EU region is the SaaS, the US region is \"customer\"","poster":"kgpoj","upvote_count":"1","comment_id":"1264594"}],"timestamp":"1722073080.0","poster":"ctrue","comment_id":"1256236","upvote_count":"1"}],"poster":"qaz12wsx","timestamp":"1715091720.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\nA for me","poster":"seetpt","timestamp":"1714729260.0","comment_id":"1206022"},{"comment_id":"1201960","upvote_count":"3","content":"Selected Answer: A\nOption A : you don't need to create a new NLB in the us-east-1. Read the link below for Inter-Region access to endpoint service .\n\nhttps://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/use-case-examples.html#inter-region-endpoint-services","comments":[{"comment_id":"1235892","content":"This article requires new NLB in new region which uses the instances in old region.","poster":"Josh1217","timestamp":"1719159000.0","upvote_count":"1"}],"poster":"TonytheTiger","timestamp":"1714046340.0"},{"upvote_count":"2","poster":"titi_r","comment_id":"1196783","timestamp":"1713296400.0","content":"Selected Answer: A\nA - correct."},{"content":"A. A looks to be right answer","poster":"tushar321","comment_id":"1195808","upvote_count":"1","timestamp":"1713156840.0"},{"comment_id":"1185914","poster":"VerRi","content":"Selected Answer: A\nAWS PrivateLink now supports access over Inter-Region VPC Peering since 2018.\nhttps://aws.amazon.com/about-aws/whats-new/2018/10/aws-privatelink-now-supports-access-over-inter-region-vpc-peering/","upvote_count":"2","timestamp":"1711780620.0"},{"poster":"mav3r1ck","upvote_count":"2","comment_id":"1185366","content":"Selected Answer: B\nThis is the use case: https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/use-case-examples.html#inter-region-endpoint-services","timestamp":"1711709880.0"},{"upvote_count":"3","content":"It is A.\nFor all those saying can not access PrivateLink endpoint service across region.\n \n\"This release makes it possible for customers to privately connect to a service even if the service endpoint resides in a different AWS Region.\"\n\nhttps://aws.amazon.com/about-aws/whats-new/2018/10/aws-privatelink-now-supports-access-over-inter-region-vpc-peering/","comment_id":"1175010","timestamp":"1710599100.0","poster":"yog927"},{"content":"Selected Answer: B\nWhen you create PrivateLink endpoint service in us-east-1 you also need a NLB to handle traffic flow between target NLB . So A doesn't seem to be a complete answer","comment_id":"1164332","timestamp":"1709406060.0","poster":"sat2008","upvote_count":"1"},{"comment_id":"1158283","poster":"bjexamprep","timestamp":"1708826640.0","content":"Selected Answer: B\nPrivate link endpoint service can only use the NLB in the same region. So A is wrong.","upvote_count":"2"},{"timestamp":"1708263840.0","comment_id":"1153295","upvote_count":"1","poster":"adelynllllllllll","content":"A:\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/privatelink-share-your-services.html"},{"timestamp":"1708187280.0","comment_id":"1152689","poster":"ele","upvote_count":"3","content":"Selected Answer: A\nA: AWS PrivateLink endpoints can now be accessed across both intra- and inter-region VPC peering connections.\nhttps://aws.amazon.com/about-aws/whats-new/2019/03/aws-privatelink-now-supports-access-over-vpc-peering/"},{"comment_id":"1150441","upvote_count":"2","timestamp":"1707938580.0","content":"Selected Answer: A\nhttps://repost.aws/questions/QU4qk3TdeBTyqZ-vcvODn84w/private-link-cross-region-cross-account-support","poster":"marszalekm"},{"content":"Selected Answer: A\nB will also work but unnecessaey complexities","timestamp":"1707843060.0","comment_id":"1149375","upvote_count":"3","poster":"pri32"},{"timestamp":"1707379500.0","comment_id":"1144240","content":"Selected Answer: A\nA- Private link supports access over inter region vpc peering","upvote_count":"3","poster":"saggy4"},{"content":"Selected Answer: B\nB\nhttps://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/use-case-examples.html#inter-region-endpoint-services","comment_id":"1137386","timestamp":"1706775120.0","upvote_count":"3","poster":"Arnaud92"},{"content":"Selected Answer: A\nA is the ans","timestamp":"1705759560.0","upvote_count":"3","poster":"igor12ghsj577","comment_id":"1127312"},{"poster":"career360guru","timestamp":"1704850020.0","comment_id":"1118003","upvote_count":"1","content":"Selected Answer: B\nOption B is best option."},{"poster":"vibzr2023","timestamp":"1704649680.0","upvote_count":"2","content":"Answer: B Somehow A also supports but there is limitations to only S3\n- Multi-Region Access Points are designed for Amazon S3, not directly for AWS PrivateLink.\n- Provide a single global endpoint for accessing S3 buckets across multiple regions.\n- Simplify data access and management for multi-region S3 deployments.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/MultiRegionAccessConfiguration.html","comment_id":"1116045"},{"comment_id":"1104548","content":"Selected Answer: A\nhttps://aws.amazon.com/pt/about-aws/whats-new/2018/10/aws-privatelink-now-supports-access-over-inter-region-vpc-peering/","upvote_count":"3","timestamp":"1703414160.0","poster":"GibaSP45"},{"upvote_count":"3","poster":"ayadmawla","content":"Selected Answer: A\nAnswer is A. Notice the reference to \"Inter-Region VPC Peering\" in the question. \n\nSee: https://aws.amazon.com/about-aws/whats-new/2018/10/aws-privatelink-now-supports-access-over-inter-region-vpc-peering/#:~:text=Applications%20in%20an%20AWS%20VPC,using%20Inter%2DRegion%20VPC%20Peering.","timestamp":"1702137720.0","comment_id":"1091893"},{"upvote_count":"2","timestamp":"1701688200.0","content":"Selected Answer: B\nAnswer: B","poster":"J0n102","comment_id":"1087593"},{"timestamp":"1701519240.0","poster":"kalitwol","upvote_count":"4","content":"Selected Answer: B\nPrivatelink service is a regional service and cannot be accessed across regions.","comment_id":"1086149"},{"content":"Option A is not feasible because AWS PrivateLink endpoint services are region-specific and cannot use an NLB from a different region.","comments":[{"poster":"ele","timestamp":"1708187400.0","content":"AWS PrivateLink endpoints can now be accessed across both intra- and inter-region VPC peering connections.\nhttps://aws.amazon.com/about-aws/whats-new/2019/03/aws-privatelink-now-supports-access-over-vpc-peering/","upvote_count":"1","comment_id":"1152693"}],"comment_id":"1083819","upvote_count":"1","timestamp":"1701294300.0","poster":"kujin"},{"poster":"shaaam80","upvote_count":"3","content":"Selected Answer: B\nAnswer B","comment_id":"1083086","timestamp":"1701228960.0"},{"content":"Selected Answer: A\nI guess A. Becuase this https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/use-case-examples.html documentation related only to PrivateLink connections WITHOUT VPC peering","comment_id":"1081653","comments":[{"timestamp":"1701096060.0","comment_id":"1081659","upvote_count":"2","poster":"HunkyBunky","content":"I guess that B is correct, because during creation of PrivateLink - you need to define NLB for it, so it should be created under same VPC\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/create-endpoint-service.html#create-endpoint-service-nlb"}],"upvote_count":"3","poster":"HunkyBunky","timestamp":"1701095580.0"},{"comment_id":"1079299","timestamp":"1700833680.0","poster":"George88","upvote_count":"3","comments":[{"timestamp":"1700897940.0","comments":[{"upvote_count":"2","content":"I think is A","poster":"devalenzuela86","comment_id":"1079806","timestamp":"1700898060.0"}],"upvote_count":"1","comment_id":"1079805","content":"https://aws.amazon.com/es/blogs/architecture/building-saas-services-for-aws-customers-with-privatelink/","poster":"devalenzuela86"}],"content":"B is correct.\nSee https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/use-case-examples.html"},{"comment_id":"1077014","upvote_count":"2","poster":"cypkir","content":"Selected Answer: B\nAnswer: B","timestamp":"1700635140.0"}],"topic":"1","question_text":"A software as a service (SaaS) company uses AWS to host a service that is powered by AWS PrivateLink. The service consists of proprietary software that runs on three Amazon EC2 instances behind a Network Load Balancer (NLB). The instances are in private subnets in multiple Availability Zones in the eu-west-2 Region. All the company's customers are in eu-west-2.\n\nHowever, the company now acquires a new customer in the us-east-1 Region. The company creates a new VPC and new subnets in us-east-1. The company establishes inter-Region VPC peering between the VPCs in the two Regions.\n\nThe company wants to give the new customer access to the SaaS service, but the company does not want to immediately deploy new EC2 resources in us-east-1.\n\nWhich solution will meet these requirements?","question_images":[],"answer_ET":"B","exam_id":33,"choices":{"D":"Use AWS Resource Access Manager (AWS RAM) to share the EC2 instances that are in eu-west-2. In us-east-1, create an NLB and an instance target group that includes the shared EC2 instances from eu-west-2. Configure a PrivateLink endpoint service that uses the NLB that is in us-east-1. Grant specific AWS accounts access to connect to the SaaS service.","A":"Configure a PrivateLink endpoint service in us-east-1 to use the existing NLB that is in eu-west-2. Grant specific AWS accounts access to connect to the SaaS service.","C":"Create an Application Load Balancer (ALB) in front of the EC2 instances in eu-west-2. Create an NLB in us-east-1. Associate the NLB that is in us-east-1 with an ALB target group that uses the ALB that is in eu-west-2. Configure a PrivateLink endpoint service that uses the NLB that is in us-east-1. Grant specific AWS accounts access to connect to the SaaS service.","B":"Create an NLB in us-east-1. Create an IP target group that uses the IP addresses of the company's instances in eu-west-2 that host the SaaS service. Configure a PrivateLink endpoint service that uses the NLB that is in us-east-1. Grant specific AWS accounts access to connect to the SaaS service."},"timestamp":"2023-11-22 07:39:00","url":"https://www.examtopics.com/discussions/amazon/view/126827-exam-aws-certified-solutions-architect-professional-sap-c02/","question_id":292,"isMC":true},{"id":"P1Qt9ZKCKmxvO8s6K3aH","question_text":"A company needs to monitor a growing number of Amazon S3 buckets across two AWS Regions. The company also needs to track the percentage of objects that are encrypted in Amazon S3. The company needs a dashboard to display this information for internal compliance teams.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","answers_community":["C (78%)","A (15%)","7%"],"timestamp":"2023-11-22 07:40:00","isMC":true,"answer":"C","answer_ET":"C","question_id":293,"exam_id":33,"answer_images":[],"question_images":[],"choices":{"A":"Create a new 3 Storage Lens dashboard in each Region to track bucket and encryption metrics. Aggregate data from both Region dashboards into a single dashboard in Amazon QuickSight for the compliance teams.","D":"Create an Amazon EventBridge rule to detect AWS CloudTrail events for S3 object creation. Configure the rule to invoke an AWS Lambda function to record encryption metrics in Amazon DynamoDB. Use Amazon QuickSight to display the metrics in a dashboard for the compliance teams.","C":"Use the S3 Storage Lens default dashboard to track bucket and encryption metrics. Give the compliance teams access to the dashboard directly in the S3 console.","B":"Deploy an AWS Lambda function in each Region to list the number of buckets and the encryption status of objects. Store this data in Amazon S3. Use Amazon Athena queries to display the data on a custom dashboard in Amazon QuickSight for the compliance teams."},"discussion":[{"poster":"cypkir","timestamp":"1700635200.0","upvote_count":"10","content":"Selected Answer: C\nAnswer: C","comment_id":"1077016"},{"poster":"AzureDP900","timestamp":"1731793920.0","content":"C is right \nThis solution requires the least operational overhead because it leverages the existing S3 Storage Lens feature, which provides a pre-built dashboard for monitoring bucket and encryption metrics.\n\nThe compliance teams can access this dashboard directly in the S3 console without requiring additional setup or configuration.\n\nThis solution also eliminates the need to set up and manage multiple AWS resources (e.g., Lambda functions, Athena queries) or aggregate data from separate dashboards.","upvote_count":"1","comment_id":"1313283"},{"comment_id":"1222395","poster":"trungtd","upvote_count":"3","timestamp":"1717201980.0","content":"Selected Answer: A\nThis use-case is really too rare to learn about on your own"},{"poster":"TonytheTiger","comment_id":"1182619","content":"Selected Answer: C\nOption C: Not A because the requirement is asking for \"Least Operation Overhead\" w/ S3 Storage Lens has a default dashboard. If you include QucikSight you are adding additional operational overhead, now you have to build your dashboard. \n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens_basics_metrics_recommendations.html#storage_lens_basics_default_dashboard","timestamp":"1711383360.0","upvote_count":"4"},{"content":"Selected Answer: C\nOption C","comment_id":"1118015","poster":"career360guru","upvote_count":"1","timestamp":"1704850740.0"},{"content":"Answer: C\nStorage Lens is a built-in S3 feature that automatically collects and aggregates storage metrics, eliminating the need for custom development or infrastructure management.\nOption A: While Storage Lens supports multiple dashboards, creating and aggregating regional dashboards in QuickSight adds complexity and maintenance overhead.\nOption B: Involves custom Lambda development, data storage in S3, Athena queries, and QuickSight integration, increasing operational complexity and costs.\nOption D: Requires EventBridge rule configuration, Lambda function development, DynamoDB table management, and QuickSight integration, adding significant overhead.","poster":"vibzr2023","comment_id":"1116035","timestamp":"1704647880.0","upvote_count":"2"},{"poster":"GoKhe","comment_id":"1103214","timestamp":"1703228760.0","content":"C\nI was leaning towards A but it says in each region so that is wrong since Storage Lens gives you a view of all the regions. Someone has chosen B which is wrong b/c it has operational overhead.","upvote_count":"4"},{"timestamp":"1702507500.0","content":"Selected Answer: C\nI doubt B as the question is asking for LEAST operational choice instead of Best choice. The lambda function needs developer to write code.","comment_id":"1095881","upvote_count":"1","poster":"GaryQian"},{"upvote_count":"1","timestamp":"1701860760.0","content":"Selected Answer: C\nAnswer C.\nStorage Lens metrics include % of encrypted objects","poster":"shaaam80","comment_id":"1089232"},{"timestamp":"1701687660.0","comment_id":"1087586","poster":"J0n102","content":"Selected Answer: C\nAnswer: C, S3 Storage Lens default=free metrics which offers encryption tracking. It's easy to set up and least overhead. https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens_metrics_glossary.html","upvote_count":"3"},{"timestamp":"1701370380.0","poster":"heatblur","comment_id":"1084672","content":"Selected Answer: C\nC is the best answer -- it's the most straightforward and involves the least operational overhead. It directly addresses the need to monitor S3 buckets and track encryption status without the need for additional setup or custom integrations. While it may not offer the same level of customization as some of the other options, it should suffice for most internal compliance requirements and is the most efficient choice in terms of minimizing operational complexity.","upvote_count":"1"},{"upvote_count":"1","comments":[{"timestamp":"1701282120.0","comment_id":"1083713","upvote_count":"1","poster":"pic1","content":"On second thought, I'm switching to option B. It appears to be the lightest between the candidates."}],"comment_id":"1082959","poster":"pic1","timestamp":"1701206220.0","content":"Selected Answer: A\nGiven the scenario specifics, it's the only option that answers the need to aggregate data from two regions in a dashboard for compliance teams."},{"poster":"devalenzuela86","content":"Selected Answer: B\nB is ok.\nTo monitor a growing number of Amazon S3 buckets across two AWS Regions and track the percentage of objects that are encrypted in Amazon S3 with the least operational overhead, a solutions architect can consider the following steps:\nDeploy an AWS Lambda function in each Region to list the number of buckets and the encryption status of objects. Store this data in Amazon S3.\nUse Amazon Athena queries to display the data on a custom dashboard in Amazon QuickSight for the compliance teams","comment_id":"1079799","timestamp":"1700896920.0","upvote_count":"2"}],"unix_timestamp":1700635200,"url":"https://www.examtopics.com/discussions/amazon/view/126828-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_description":"","topic":"1"},{"id":"AYmGeiU3gEcTYhJTQnJI","topic":"1","question_text":"A company’s CISO has asked a solutions architect to re-engineer the company's current CI/CD practices to make sure patch deployments to its application can happen as quickly as possible with minimal downtime if vulnerabilities are discovered. The company must also be able to quickly roll back a change in case of errors.\n\nThe web application is deployed in a fleet of Amazon EC2 instances behind an Application Load Balancer. The company is currently using GitHub to host the application source code, and has configured an AWS CodeBuild project to build the application. The company also intends to use AWS CodePipeline to trigger builds from GitHub commits using the existing CodeBuild project.\n\nWhat CI/CD configuration meets all of the requirements?","answer":"B","answer_description":"","exam_id":33,"choices":{"D":"Configure the CodePipeline with a deploy stage using AWS OpsWorks and in-place deployments. Monitor the newly deployed code, and, if there are any issues, push another code update.","A":"Configure CodePipeline with a deploy stage using AWS CodeDeploy configured for in-place deployment. Monitor the newly deployed code, and, if there are any issues, push another code update","B":"Configure CodePipeline with a deploy stage using AWS CodeDeploy configured for blue/green deployments. Monitor the newly deployed code, and, if there are any issues, trigger a manual rollback using CodeDeploy.","C":"Configure CodePipeline with a deploy stage using AWS CloudFormation to create a pipeline for test and production stacks. Monitor the newly deployed code, and, if there are any issues, push another code update."},"answers_community":["B (100%)"],"timestamp":"2023-11-22 07:41:00","unix_timestamp":1700635260,"isMC":true,"question_id":294,"url":"https://www.examtopics.com/discussions/amazon/view/126829-exam-aws-certified-solutions-architect-professional-sap-c02/","question_images":[],"answer_ET":"B","answer_images":[],"discussion":[{"content":"Selected Answer: B\nB is the best choice. Using a B/G approach aligns with the requirements for quick patch deployments and minimal downtime. In the event of an issue, the company can quickly revert to the previous version, meeting the need for a fast rollback process. This method offers a balance of speed, reliability, and safety for critical updates.","timestamp":"1701370680.0","poster":"heatblur","upvote_count":"8","comment_id":"1084675"},{"upvote_count":"1","poster":"AzureDP900","timestamp":"1731793800.0","comment_id":"1313282","content":"B is right \nBlue/green deployments allow for multiple instances of the application to be deployed simultaneously, one in production and one in a standby state (the \"blue\" instance). This approach provides several benefits, including:\n\n\n\nMinimal downtime: If an issue arises with the production instance, users can quickly switch to the standby instance without disrupting the application.\n\nEasy rollbacks: If issues cannot be resolved, blue/green deployments allow for a quick rollback to the previous version of the application."},{"timestamp":"1724419620.0","poster":"Daniel76","comment_id":"1271312","upvote_count":"1","content":"Manual code rollback in CodeDeploy: \nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/deployments-rollback-and-redeploy.html#:~:text=a%20deployment%20group.-,Manual%20rollbacks,gotten%20into%20an%20unknown%20state."},{"content":"Selected Answer: B\nOption B","timestamp":"1704851100.0","comment_id":"1118023","poster":"career360guru","upvote_count":"1"},{"content":"Selected Answer: B\nAWS like green/blue deployment for new code & roll back scenario","timestamp":"1702507620.0","upvote_count":"2","poster":"GaryQian","comment_id":"1095882"},{"comment_id":"1087578","timestamp":"1701686820.0","poster":"J0n102","upvote_count":"1","content":"Selected Answer: B\nAnswer: B"},{"timestamp":"1701472680.0","poster":"PouyaK","comment_id":"1085554","content":"Answer B","upvote_count":"2"},{"comment_id":"1083091","timestamp":"1701229740.0","upvote_count":"2","content":"Selected Answer: B\nAnswer B","poster":"shaaam80"},{"timestamp":"1700664840.0","comment_id":"1077461","upvote_count":"3","poster":"devalenzuela86","content":"Selected Answer: B\nB for sure"},{"timestamp":"1700635260.0","upvote_count":"2","content":"Selected Answer: B\nAnswer: B","comment_id":"1077018","poster":"cypkir"}]},{"id":"wWjdzkTfqyW8D4nFmAri","exam_id":33,"isMC":true,"answers_community":["C (74%)","B (19%)","6%"],"unix_timestamp":1700635260,"timestamp":"2023-11-22 07:41:00","answer_description":"","question_images":[],"answer":"C","answer_ET":"C","question_id":295,"choices":{"C":"Create an SCP and attach the SCP to the root of the organization. Include the following statement in the SCP:","A":"Enable tag policies in the organization. Create a tag policy for the BusinessUnit tag. Ensure that compliance with tag key capitalization is turned off. Implement the tag policy for the ec2:instance resource type. Attach the tag policy to the root of the organization.","D":"Create an SCP and attach the SCP to the organization’s management account. Include the following statement in the SCP:","B":"Enable tag policies in the organization. Create a tag policy for the BusinessUnit tag. Ensure that compliance with tag key capitalization is turned on. Implement the tag policy for the ec2:instance resource type. Attach the tag policy to the organization's management account."},"question_text":"A company is managing many AWS accounts by using an organization in AWS Organizations. Different business units in the company run applications on Amazon EC2 instances. All the EC2 instances must have a BusinessUnit tag so that the company can track the cost for each business unit.\n\nA recent audit revealed that some instances were missing this tag. The company manually added the missing tag to the instances.\n\nWhat should a solutions architect do to enforce the tagging requirement in the future?","answer_images":[],"discussion":[{"comment_id":"1092536","comments":[{"content":"You apply SCP in root account and tag policy in management account, but I think crucial issue here is to \"enforce the tagging requirement in the future\", only SCP can do that.\n\nhttps://aws.amazon.com/blogs/mt/implement-aws-resource-tagging-strategy-using-aws-tag-policies-and-service-control-policies-scps/ \n\"SCPs can be used along-side tag policies to ensure that the tags are applied at the resource creation time and remain attached to the resource.\"\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_tag-policies.html \n\"When you sign in to the organization's management account, you use Organizations to enable the tag policies feature. [...] in the organization's management account. Then you can create tag policies and attach them to the organization entities to put those tagging rules in effect. \"","poster":"marszalekm","timestamp":"1708364220.0","comment_id":"1154155","upvote_count":"3"}],"upvote_count":"15","poster":"ayadmawla","timestamp":"1702218360.0","content":"Selected Answer: C\nAnswer is C. To those that are getting confused between a Management Account vs Root of the Organisation here is my two pennies: \n\nManagement Account is where you create accounts, management payments, create organisation, etc. \n\nRoot of Organisation is where you apply the policies\n\nSee: https://docs.aws.amazon.com/organizations/latest/userguide/orgs_getting-started_concepts.html"},{"comment_id":"1113778","timestamp":"1704379920.0","upvote_count":"7","poster":"MegalodonBolado","content":"Selected Answer: C\nFrom repost:\n * Use tag policies to prevent tagging on existing resources\n * Use SCPs to prevent tagging for creating new resources\nhttps://repost.aws/knowledge-center/organizations-scp-tag-policies\n\nWhat should a solutions architect do to enforce the tagging requirement in the future?\nYou can use SCPs to prevent the creation of new AWS resources that aren't tagged for your Organization’s tagging restriction guidelines. To make sure that the AWS resources are created only if a certain tag is present, use the example SCP policy to require a tag on specified created resources: https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_tagging.html#example-require-tag-on-create","comments":[{"upvote_count":"1","content":"Looks like I can't post json code here, so follow the last link to find the policy","poster":"MegalodonBolado","timestamp":"1704379980.0","comment_id":"1113780"}]},{"content":"C is correct","poster":"AzureDP900","upvote_count":"1","comment_id":"1313281","timestamp":"1731793560.0"},{"content":"Selected Answer: C\nOption A and B is incorrect:\n\nTag policies with capitalization control provide the following regulation:\nFor example, if the \"BusinessUnit\" tag requires case sensitivity, creating resources with tags like \"BusineSSUnit\" or \"businessunit\" will fail, while creating resources with the \"Business\" tag will be allowed.\nCase sensitivity enforces rules within the same string, but does not fulfill the requirements of this question.","upvote_count":"1","timestamp":"1720351740.0","comment_id":"1243829","poster":"053081f"},{"timestamp":"1720350120.0","upvote_count":"1","content":"Selected Answer: A\nCorrect answer is A, rather than B.\n\nC: While this SCP would prevent instances from being created without the tag, it's a more restrictive approach than using tag policies. SCPs are better suited for broad permission management rather than enforcing tagging.","poster":"053081f","comment_id":"1243806"},{"timestamp":"1715503080.0","comment_id":"1210185","poster":"red_panda","content":"Selected Answer: C\nFor me it's C.\nHere we have to note that when the AWS Organization Units are mentioned, for the most we need to use SCP or RAM at the exams. Just little tips.\nA part of this, C seems most correct answer in my point of view :)","upvote_count":"2"},{"comment_id":"1195820","content":"C. “true”: This means that the condition will evaluate to true (and thus the policy statement will be in effect) if the Project tag is not present in the request.\n\ncondition states that the policy statement is in effect when the Project tag is not included in the request. If the Project tag is present, the condition will evaluate to false","timestamp":"1713158520.0","upvote_count":"2","poster":"tushar321"},{"comment_id":"1185917","content":"Selected Answer: C\nTag policies take control of auto-tagging but do not \"enforce\" the tagging requirement.","upvote_count":"1","poster":"VerRi","timestamp":"1711781040.0"},{"poster":"TonytheTiger","content":"Selected Answer: C\nOption C - SCP for tagging resources \n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_tagging.html#example-require-tag-on-create","upvote_count":"1","timestamp":"1711388940.0","comment_id":"1182691"},{"upvote_count":"1","content":"Selected Answer: C\nC\nDid a recent project which is similar to this question.\nB D out since they apply to management account which is wrong.\nFor C, SCP will deny the resource creation, if it is missing the tag\nFor A, tagging policy will deny tag creation if the tag key is not matching the name\nFor this question asked, it is C\nIf question is asking that resource must be have tag key ABC=***, and can't not have tag key CBA=*** then A would be the answer.\nFor a real world restriction, you may have both A and C setup","poster":"pangchn","timestamp":"1710447960.0","comment_id":"1173688"},{"comment_id":"1118027","content":"Selected Answer: C\nOption C","upvote_count":"1","poster":"career360guru","timestamp":"1704851640.0"},{"poster":"Laercio96","timestamp":"1704303420.0","comment_id":"1112980","content":"Selected Answer: C\nAfter you create a tagging policy, you can put your tagging rules into effect. To do this, attach the policy to the organization root, organizational units (OUs), AWS Accounts within the organization, or a combination of organization entities.\n\nhttps://docs.aws.amazon.com/pt_br/organizations/latest/userguide/orgs_manage_policies_tag-policies-create.html\n\nOption B asks to attach the management account, but the question informs you that you have several accounts.\n\nThat's why I'll go with \"C\"","upvote_count":"1"},{"poster":"NOZOMI","upvote_count":"1","content":"The answer is c. Tag policies control the key and value when a tag is applied, but they cannot prevent the application of tags themselves.","timestamp":"1703995680.0","comment_id":"1110249"},{"upvote_count":"1","comment_id":"1109809","poster":"duriselvan","timestamp":"1703949960.0","content":"https://aws.amazon.com/blogs/mt/implement-aws-resource-tagging-strategy-using-aws-tag-policies-and-service-control-policies-scps/"},{"content":"ANs :c \nhttps://aws.amazon.com/blogs/mt/implement-aws-resource-tagging-strategy-using-aws-tag-policies-and-service-control-policies-scps/","poster":"duriselvan","timestamp":"1703937420.0","upvote_count":"1","comment_id":"1109707"},{"comment_id":"1108565","upvote_count":"1","poster":"water314","timestamp":"1703844720.0","content":"Selected Answer: A\nImplement a tag policy that specifically requires the BusinessUnit tag on EC2 instances. This policy can be enforced across the organization, ensuring that all EC2 instances carry the mandatory tag. Compliance with tag key capitalization can be turned off to allow flexibility in how the tag key is formatted. Once the policy is created, it should be attached to the root of the organization, which ensures that it is applied across all accounts within the organization."},{"poster":"wmp7039","comments":[{"upvote_count":"1","comment_id":"1127410","poster":"igor12ghsj577","timestamp":"1705770720.0","content":"Tag Policy only enforces the accepted value of a tag, and not its presence. Therefore, users (with appropriate IAM permissions) would still be able to create untagged resources. To restrict the creation of an AWS resource without the appropriate tags, we will utilize SCPs to set guardrails around resource creation requests."}],"content":"Selected Answer: B\nUse AWS Organizations to manage tag policies. When you sign in to the organization's management account, you use Organizations to enable the tag policies feature. \nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_tag-policies.html\nhttps://aws.amazon.com/blogs/mt/implement-aws-resource-tagging-strategy-using-aws-tag-policies-and-service-control-policies-scps/","comment_id":"1108369","timestamp":"1703828820.0","upvote_count":"1"},{"timestamp":"1702540860.0","poster":"blackgamer","upvote_count":"1","content":"Selected Answer: A\nThe correct answer is A.","comment_id":"1096188"},{"timestamp":"1702217940.0","upvote_count":"2","poster":"ayadmawla","content":"Selected Answer: C\nAnswer is C - See: https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_tagging.html#example-require-tag-on-create","comment_id":"1092529"},{"upvote_count":"1","poster":"Russs99","comment_id":"1091854","content":"Selected Answer: C\nCentralized enforcement: Attaching the policy at the root ensures it applies to all member accounts within the organization, regardless of their individual configuration. This provides consistent and centralized enforcement of the BusinessUnit tagging requirement","timestamp":"1702132980.0"},{"poster":"heatblur","comments":[{"upvote_count":"1","comment_id":"1085290","content":"Yes, very tricky question.\nThe question is about how to enforce the tagging environment, rather than how to manage permission to run the instance.\nSo B is the correct answer.","poster":"Pilot","timestamp":"1701442260.0"}],"content":"Selected Answer: B\nTough question -- usually the answer is SCPs but here, it's better to leverage the tag policy and attached it to the management account of the org.\n\nNote the question: \"A company is managing many AWS accounts by using an organization in AWS Organizations.\" So the policy must go to the management account, which isn't the same at the root account.\n\nThis exam is 50% technical and 50% reading comprehension apparently....","comment_id":"1084689","timestamp":"1701371100.0","upvote_count":"4"},{"timestamp":"1701151260.0","upvote_count":"2","poster":"ProMax","content":"Selected Answer: C\nOption C is the correct with minimum operational overhead.","comment_id":"1082201"},{"upvote_count":"2","comment_id":"1077493","poster":"devalenzuela86","content":"Selected Answer: B\nB si ok for me.\nTo enforce the tagging requirement in the future, a solutions architect should enable tag policies in the organization. The tag policy should be created for the BusinessUnit tag and implemented for the ec2:instance resource type. The tag policy should be attached to the organization’s management account.","timestamp":"1700667120.0"},{"poster":"cypkir","comment_id":"1077019","timestamp":"1700635260.0","upvote_count":"2","content":"Selected Answer: B\nAnswer: B"}],"url":"https://www.examtopics.com/discussions/amazon/view/126830-exam-aws-certified-solutions-architect-professional-sap-c02/","topic":"1"}],"exam":{"isMCOnly":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":529,"name":"AWS Certified Solutions Architect - Professional SAP-C02","provider":"Amazon","isImplemented":true,"id":33,"isBeta":false},"currentPage":59},"__N_SSP":true}