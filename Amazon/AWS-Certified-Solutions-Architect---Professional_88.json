{"pageProps":{"questions":[{"id":"yx9BzOtRjvJwTxKt0eQr","discussion":[{"upvote_count":"52","poster":"Moon","comment_id":"13869","comments":[{"comment_id":"14084","comments":[{"poster":"donathon","content":"Moon is correct.\nD\nA: You can use VPC peering, there is no need to use VPN.\nB: This will create unnecessary load on the Direct Connect and your on premise internet connection.\nC: You cannot route traffic to a NAT gateway through a VPC peering connection, a Site-to-Site VPN connection, or AWS Direct Connect. A NAT gateway cannot be used by resources on the other side of these connections. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html\nD: https://aws.amazon.com/blogs/networking-and-content-delivery/how-to-use-aws-privatelink-to-secure-and-scale-web-filtering-using-explicit-proxy/","timestamp":"1632785400.0","upvote_count":"10","comment_id":"14188","comments":[{"poster":"chaudh","content":"Thank you, D is an answer.","upvote_count":"4","comment_id":"16197","timestamp":"1633300200.0","comments":[{"content":"No one explained why A is incorrect properly. So let me do that. The method in A is valid, however it is far more expensive than D. Cause VPN traffic between VPCs traverses internet which is AWS to Internet traffic. And that is more expensive then D.","timestamp":"1644741480.0","comment_id":"546322","poster":"wahlbergusa","upvote_count":"2"}]}]}],"timestamp":"1632637080.0","poster":"manhmaluc","upvote_count":"2","content":"best answer"}],"content":"Answer is: \"D\"\nuser proxy fleet over PrivateLink. As explained in this AWS website:\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/how-to-use-aws-privatelink-to-secure-and-scale-web-filtering-using-explicit-proxy/\nA: does not provide a full solution, only showing transit VPC, and VPN but without the exiting solution to internet. Also, it is a costly solution.\nB: This would work, but it will send traffic to on-premise, and the question does not show that the company is having on-premise network!\nC: can not work, because VPC-Peering can not be used for transit traffic over Net Gateway.","timestamp":"1632546720.0"},{"poster":"SkyZeroZx","timestamp":"1687040580.0","content":"Selected Answer: D\nD. Creating a proxy fleet in a central VPC account allows for centralized management and monitoring of outbound internet traffic. Using an AWS PrivateLink endpoint service in the central VPC enables secure and cost-effective access to the internet via the proxy fleet. This solution can scale as new accounts are provisioned by simply connecting them to the central VPC.\n\nTherefore, option D is the recommended solution as it meets the current needs, reduces costs, provides visibility into outbound traffic, and allows for future growth.","comment_id":"926311","upvote_count":"1"},{"content":"Selected Answer: D\nD is correct","comment_id":"799403","upvote_count":"1","timestamp":"1675658100.0","poster":"anhyou"},{"comment_id":"758913","timestamp":"1672165500.0","upvote_count":"1","content":"Selected Answer: A\nB-> No need to send internet traffic to on-premise route\nC-> NAT gateway cannot be shared using VPC-peering\nD-> You need to create an AWS PrivateLink endpoint service in each VPC to use proxy fleet, so A is the only answer.","poster":"evargasbrz"},{"timestamp":"1644466920.0","comments":[{"poster":"RVivek","upvote_count":"1","comment_id":"544310","content":"my comment about PrivateLink end point on each VPC is wrong . so the answer is D.\nThough A can work , D is easier to setup, sacle\n and add new VPCs","timestamp":"1644469680.0"}],"content":"Answer is A. Transit VPC with VPN connection to each VPC and roting table entry complete solution\nB: No need to send internet traffic to on-premise route\nC: NAT gateway cannot be shared using VPC-peering\nD: PrivateLink end point should be used on each VPC that tries to access the central VPC. If Central VPC has a PrivateLinK that is not enough","upvote_count":"2","comment_id":"544296","poster":"RVivek"},{"content":"Answer - D - \nWhy not C ? Currently there are 100 accounts which could grow in future. However there is a 125 max VPC peering limit which will become a bottleneck. And obviously it will be too messy.","poster":"tkanmani76","comment_id":"513791","upvote_count":"1","timestamp":"1640911860.0"},{"comment_id":"499120","content":"D. Create a proxy fleet in a central VPC account. Create an AWS PrivateLink endpoint service in the central VPC. Use PrivateLink interface for internet connectivity through the proxy fleet.","timestamp":"1639195440.0","poster":"cldy","upvote_count":"2"},{"timestamp":"1638649680.0","upvote_count":"2","comment_id":"493946","content":"D is right","poster":"AzureDP900"},{"poster":"tgv","timestamp":"1636155480.0","upvote_count":"1","content":"DDD\n---","comment_id":"437860"},{"timestamp":"1636038900.0","content":"I'll go with D","upvote_count":"2","comment_id":"409783","poster":"WhyIronMan"},{"content":"It's D","upvote_count":"3","poster":"Waiweng","timestamp":"1635950220.0","comment_id":"345080"},{"upvote_count":"1","timestamp":"1635920820.0","content":"D.\nI think A also works, but it needs more work","poster":"01037","comment_id":"342417"},{"poster":"Amitv2706","upvote_count":"3","content":"Answer is D.\n\nWhy not C?\nYou cannot route traffic to a NAT gateway through a VPC peering connection, a Site-to-Site VPN connection, or AWS Direct Connect. A NAT gateway cannot be used by resources on the other side of these connections.\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","comment_id":"333993","timestamp":"1635838680.0"},{"upvote_count":"1","poster":"ajeeshb","timestamp":"1635624600.0","comment_id":"307130","content":"Yes, the answer should be D"},{"poster":"Kian1","upvote_count":"2","comment_id":"290737","content":"D a proxy fleet","timestamp":"1635593760.0"},{"content":"I go with D","timestamp":"1635463860.0","poster":"Ebi","comment_id":"281633","upvote_count":"3"},{"comment_id":"242571","content":"Correct answer is D.\nNAT-Gateway can not be used through VPC peering","poster":"T14102020","upvote_count":"2","timestamp":"1635252480.0"},{"timestamp":"1634863920.0","poster":"jackdryan","comment_id":"230059","content":"I'll go with D","upvote_count":"2"},{"poster":"Bulti","upvote_count":"1","timestamp":"1634861220.0","content":"D is correct. C is incorrect due to the limitations of using NAT Gateway via VPC-to-VPC peering.","comment_id":"229892"},{"upvote_count":"2","comment_id":"149683","poster":"fullaws","content":"D is correct","timestamp":"1634619120.0"},{"comment_id":"138182","poster":"noisonnoiton","upvote_count":"2","timestamp":"1634385240.0","content":"D acceptable\nNAT-Gateway can not be used through VPC peering"},{"upvote_count":"2","timestamp":"1634129580.0","comment_id":"134453","content":"D for sure","poster":"NikkyDicky"},{"timestamp":"1633961580.0","content":"answer D","upvote_count":"2","comment_id":"110323","poster":"mat2020"},{"content":"D is cocrrect -https://aws.amazon.com/blogs/networking-and-content-delivery/how-to-use-aws-privatelink-to-secure-and-scale-web-filtering-using-explicit-proxy/","comment_id":"100617","timestamp":"1633939440.0","upvote_count":"2","poster":"NKnab"},{"poster":"VrushaliD","content":"ans is D","comment_id":"93776","upvote_count":"2","timestamp":"1633889040.0"},{"upvote_count":"2","comment_id":"76223","poster":"Joeylee","content":"A doesn’t grow\nB too expensive\nC don’t work\nSo D","timestamp":"1633774620.0"},{"timestamp":"1633728600.0","upvote_count":"2","comment_id":"51066","content":"VPC peering does not work with NAT\nAnswer is D","poster":"amog"},{"content":"C VPC peering using the central VPC which contains the VGWs","timestamp":"1633660140.0","poster":"aperally","comments":[{"comment_id":"257553","timestamp":"1635424560.0","content":"nat gateway not active with VPC peering","upvote_count":"1","poster":"binhdx"}],"upvote_count":"1","comment_id":"29823"},{"poster":"chaudh","timestamp":"1633156260.0","comment_id":"16195","content":"PrivateLink privately connect to AWS-hosted service, notuse public internet protocols (IP) addresses nor traverse the internet. \nA Transit VPC connects multiple Amazon Virtual Private Clouds that might be geographically disparate or running in separate AWS accounts, to a common Amazon VPC that serves as a global network transit center.\nhttps://d1.awsstatic.com/whitepapers/aws-privatelink.pdf","upvote_count":"3"},{"poster":"donathon","content":"C\nA: You can use VPC peering, there is no need to use VPN.\nB: This will create unnecessary load on the Direct Connect and your on premise internet connection.\nD: Private link are used for connecting to public AWS services like S3 and cannot connect to internet. Connect your VPCs to services in AWS in a secure and scalable manner with AWS PrivateLink. AWS PrivateLink traffic doesn't traverse the Internet, reducing the exposure to threat vectors such as brute force and distributed denial-of-service attacks. Use private IP connectivity and security groups so that your services function as though they were hosted directly on your private network.","timestamp":"1632358740.0","comment_id":"12557","upvote_count":"2","comments":[{"content":"C is not correct, because NAT-Gateway can not be used through VPC peering. VPC-Peering does not meant for transiting.\nhttps://serverfault.com/questions/789844/using-aws-nat-gateway-from-diferrent-vpc-across-vpc-peering","poster":"Moon","timestamp":"1632362100.0","comment_id":"13867","upvote_count":"6","comments":[{"upvote_count":"3","poster":"Moon","content":"https://docs.aws.amazon.com/vpc/latest/peering/invalid-peering-configurations.html#transitive-peering","timestamp":"1632513000.0","comments":[{"timestamp":"1634067480.0","upvote_count":"2","content":"what about A, the question is regarding transitive routing...which vpc peering is not. transit vpc is however, like a hub and spoke","poster":"sdee1013","comment_id":"111995"}],"comment_id":"13868"}]}]},{"content":"why not c ?","upvote_count":"1","timestamp":"1632279600.0","poster":"awsec2","comment_id":"12232"}],"answer":"D","answer_ET":"D","question_id":436,"url":"https://www.examtopics.com/discussions/amazon/view/5590-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"C":"Create a central VPC for outbound internet traffic. Use VPC peering to default route to a set of redundant NAT gateway in the central VPC.","D":"Create a proxy fleet in a central VPC account. Create an AWS PrivateLink endpoint service in the central VPC. Use PrivateLink interface for internet connectivity through the proxy fleet.","B":"Create multiple hosted-private AWS Direct Connect VIFs, one per account, each with a Direct Connect gateway. Default route internet traffic back to an on- premises router to route to the internet.","A":"Create a transit VPC across two AZs using a third-party routing appliance. Create a VPN connection to each VPC. Default route internet traffic to the transit VPC."},"answer_images":[],"timestamp":"2019-09-23 07:35:00","exam_id":32,"isMC":true,"answer_description":"Reference:\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/how-to-use-aws-privatelink-to-secure-and-scale-web-filtering-using-explicit-proxy/","question_text":"A company has more than 100 AWS accounts, with one VPC per account, that need outbound HTTPS connectivity to the internet. The current design contains one NAT gateway per Availability Zone (AZ) in each VPC. To reduce costs and obtain information about outbound traffic, management has asked for a new architecture for internet access.\nWhich solution will meet the current needs, and continue to grow as new accounts are provisioned, while reducing costs?","answers_community":["D (67%)","A (33%)"],"unix_timestamp":1569216900,"topic":"1","question_images":[]},{"id":"OJolr7CNkz2L8qlaB1LN","discussion":[{"upvote_count":"21","comment_id":"12558","comments":[{"comment_id":"61903","timestamp":"1632877140.0","content":"Agree on B\nAdditionally and to be more precise : CF gives protection over DDOS through Shield, D only lacks Multi-AZ hence","upvote_count":"4","poster":"Asds"}],"poster":"donathon","timestamp":"1632730800.0","content":"B\nA: Does not need third party load balancer.\nC: SSH should be disabled and commands run from System Manager. SQL needs to be more highly available and not on a single EC2 instance.\nD: DB should be multi-AZ. DDOS protection needs Shield."},{"upvote_count":"1","content":"WAF and SHIELD.","comment_id":"636285","timestamp":"1658703840.0","poster":"hilft"},{"poster":"aandc","timestamp":"1656825780.0","comment_id":"626421","content":"Selected Answer: B\nAWS Systems Manager -> can disable SSH\nD does not mention DDOS","upvote_count":"1"},{"upvote_count":"1","comment_id":"580490","poster":"bfal","content":"still on why B is wrong\nLeverage an Elastic Load Balancer to spread the load ? load of what ? Amazon RDS multi-AZ, would you put LB in front of these, if this doable? or just use DNS to lb?","timestamp":"1649030040.0"},{"timestamp":"1649028720.0","comments":[{"content":"I take it back, you can access through AWS session manager, but I still think connecting through the bastion host has mitigated the risk, so C is still correct in my view","comment_id":"580486","poster":"bfal","upvote_count":"1","timestamp":"1649029320.0"}],"poster":"bfal","comment_id":"580482","upvote_count":"1","content":"How else would you connect to the instance if you disable SSH access ? how would you disable SSH access? Correct answer is C.\nB is wrong, so AWS WAF will be used to \"manage\" rules on the distribution??? which rules?"},{"timestamp":"1649028240.0","content":"C is correct. Why would you want to disabled ssh access? Best practice is to connect through a bastion host, so do that, and whitelist.","comment_id":"580481","poster":"bfal","upvote_count":"1"},{"comment_id":"558326","upvote_count":"1","content":"B for me. Shield advance for DDOS protection and disabling ssh give more protection.","timestamp":"1646080200.0","poster":"Ni_yot"},{"upvote_count":"1","comments":[{"comment_id":"505132","timestamp":"1639953660.0","poster":"AkaAka4","content":"With System Manager? I think it's mentioned in the question, it's one of the actions that they have already taken.","upvote_count":"1"}],"poster":"KiraguJohn","timestamp":"1639469460.0","comment_id":"501201","content":"I will go with B but how will they maintain the patches if they cannot use SSH to login to the instances?"},{"poster":"AzureDP900","comment_id":"493947","upvote_count":"1","content":"B is right answer","timestamp":"1638649800.0"},{"content":"This one was way too predictable, only B has both HIGH AVAILABILITY AND ADDITIONAL SECURITY","upvote_count":"2","timestamp":"1635926700.0","poster":"DeathFrmAbv","comment_id":"413055"},{"comment_id":"409786","upvote_count":"2","timestamp":"1635895320.0","content":"I'll go with B","poster":"WhyIronMan"},{"comment_id":"365993","upvote_count":"1","timestamp":"1635042960.0","content":"You cannot simply disable SSH.","poster":"ss160700","comments":[{"content":"Yeah you can? Just close port 22 and then use session manager to connect instead of SSH","timestamp":"1635488220.0","poster":"memester","comment_id":"405703","upvote_count":"4"}]},{"poster":"Waiweng","timestamp":"1634956140.0","content":"It's B","upvote_count":"3","comment_id":"345083"},{"comment_id":"341074","content":"B is the correct answer","poster":"01037","timestamp":"1634636160.0","upvote_count":"1"},{"content":"going with B","upvote_count":"2","poster":"Kian1","timestamp":"1634113620.0","comment_id":"290742"},{"poster":"Ebi","comment_id":"281636","timestamp":"1633942320.0","upvote_count":"4","content":"B\nD could be an answer as well, only issue is Single AZ"},{"timestamp":"1633864500.0","poster":"binhdx","comment_id":"247671","upvote_count":"1","content":"B forsure"},{"timestamp":"1633783680.0","comment_id":"242577","upvote_count":"1","poster":"T14102020","content":"Correct answer is B. AWS Shield Advanced"},{"comment_id":"230062","timestamp":"1633764000.0","upvote_count":"3","content":"I'll go with B","poster":"jackdryan"},{"comment_id":"229946","content":"Answer is B. A and C are out as they continue with SSH in spite of enabling system manager to manage patches. D is out because it doesn't enable DDoS","upvote_count":"1","timestamp":"1633605180.0","poster":"Bulti"},{"poster":"kj07","content":"Answer: B\nYou can eliminate easily option AC, you don't want SSH enabled.\nAnd then you can eliminate D because you don't want a single AZ DB.","comment_id":"223380","timestamp":"1633507260.0","upvote_count":"1"},{"upvote_count":"1","poster":"fullaws","comment_id":"149699","content":"B is correct","timestamp":"1633499820.0"},{"content":"B acceptable\nSSH should be disabled","upvote_count":"1","timestamp":"1633435980.0","comment_id":"138185","poster":"noisonnoiton"},{"poster":"NikkyDicky","comment_id":"134454","content":"B for sure","upvote_count":"1","timestamp":"1633209240.0"},{"content":"Answer is B","poster":"mat2020","timestamp":"1633135200.0","upvote_count":"1","comment_id":"110324"},{"upvote_count":"1","poster":"NKnab","comment_id":"102273","content":"B is correct. multi az rds","timestamp":"1633131720.0"},{"poster":"DeepakNChandwani","upvote_count":"1","comment_id":"39543","timestamp":"1632773160.0","content":"Agree as Shield Advanced provides Level 4/Level 7 protection,"}],"url":"https://www.examtopics.com/discussions/amazon/view/5591-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"B","timestamp":"2019-09-23 07:44:00","answer_description":"","question_id":437,"choices":{"C":"Enable SSH access to the Amazon EC2 instances through a bastion host secured by limiting access to specific IP addresses. Migrate on-premises MySQL to a self-managed EC2 instance. Leverage an AWS Elastic Load Balancer to spread the load and enable AWS Shield Standard for DDoS protection. Add an Amazon CloudFront distribution in front of the website.","A":"Enable SSH access to the Amazon EC2 instances using a security group that limits access to specific IPs. Migrate on-premises MySQL to Amazon RDS Multi- AZ. Install the third-party load balancer from the AWS Marketplace and migrate the existing rules to the load balancer's AWS instances. Enable AWS Shield Standard for DDoS protection.","B":"Disable SSH access to the Amazon EC2 instances. Migrate on-premises MySQL to Amazon RDS Multi-AZ. Leverage an Elastic Load Balancer to spread the load and enable AWS Shield Advanced for protection. Add an Amazon CloudFront distribution in front of the website. Enable AWS WAF on the distribution to manage the rules.","D":"Disable SSH access to the EC2 instances. Migrate on-premises MySQL to Amazon RDS Single-AZ. Leverage an AWS Elastic Load Balancer to spread the load. Add an Amazon CloudFront distribution in front of the website. Enable AWS WAF on the distribution to manage the rules."},"unix_timestamp":1569217440,"answers_community":["B (100%)"],"question_text":"A company runs an e-commerce platform with front-end and e-commerce tiers. Both tiers run on LAMP stacks with the front-end instances running behind a load balancing appliance that has a virtual offering on AWS. Currently, the Operations team uses SSH to log in to the instances to maintain patches and address other concerns. The platform has recently been the target of multiple attacks, including:\n✑ A DDoS attack.\n✑ An SQL injection attack.\n✑ Several successful dictionary attacks on SSH accounts on the web servers.\nThe company wants to improve the security of the e-commerce platform by migrating to AWS. The company's Solutions Architects have decided to use the following approach:\n✑ Code review the existing application and fix any SQL injection issues.\n✑ Migrate the web application to AWS and leverage the latest AWS Linux AMI to address initial security patching.\n✑ Install AWS Systems Manager to manage patching and allow the system administrators to run commands on all instances, as needed. all\nWhat additional steps will address\nof the identified attack types while providing high availability and minimizing risk?","isMC":true,"question_images":[],"exam_id":32,"answer_images":[],"topic":"1","answer":"B"},{"id":"lgLDAbSK9g0aSWCNJSJS","answer":"C","timestamp":"2021-12-31 01:33:00","unix_timestamp":1640910780,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/69111-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"question_text":"A company has a High Performance Computing (HPC) cluster in its on-premises data center, which runs thousands of jobs in parallel for one week every month, processing petabytes of images. The images are stored on a network file server, which is replicated to a disaster recovery site. The on-premises data center has reached capacity and has started to spread the jobs out over the course of the month in order to better utilize the cluster, causing a delay in the job completion.\nThe company has asked its Solutions Architect to design a cost-effective solution on AWS to scale beyond the current capacity of 5,000 cores and 10 petabytes of data. The solution must require the least amount of management overhead and maintain the current level of durability.\nWhich solution will meet the company's requirements?","discussion":[{"timestamp":"1704390780.0","content":"Selected Answer: B\nB: is the most cost effective using EMR as it uses S3 as the file system (EMRFS). 10PB of data is about 200k and it is using spot instances for the task nodes.\nC: may or may not be doable as it doesn't specify how much data is required by each job and EBS is limited to 64TB per volume given that the OS supports that much. Considering 10PB EBS for storage alone is $1.287M + IOPS cost for io2 it seems like a more costly solution. \nD: is technically more feasible than C but more costly at $3M for 10PB in EFS alone.","comment_id":"1113944","poster":"3a632a3","upvote_count":"1"},{"comment_id":"743426","content":"Selected Answer: C\nA: stopped reading after the word container.\nB: I like the idea of utilizing spark and it indeed can pull from S3 but whats the EMR for if data is in S3 and procssed clientside on an ec2. Either the data goes HFS in the EMR or the spark need to run serverside in the EMR (which only makes sense if the data is in the EMR) - and not in S3 or the EMR. Clumsy at best.\nC: yes, we have batch processing and this is a perfect setup for batch processing that works and it says that they move the data to s3. \nD: EFS? For petabyte of Data? Clumsy at best.","timestamp":"1670888940.0","poster":"hobokabobo","upvote_count":"1"},{"upvote_count":"1","timestamp":"1667427900.0","poster":"superuser784","content":"Selected Answer: C\nAWS Batch is more suitable for this case, AWS EMR if mainly for BigData and ML processing.","comment_id":"710110"},{"timestamp":"1665017820.0","comment_id":"687358","upvote_count":"3","content":"Selected Answer: C\nFor cost effective, C is best choice","poster":"ToanVN1988"},{"upvote_count":"3","content":"Selected Answer: C\nemr is not for HPC scenario","comment_id":"652508","timestamp":"1661587320.0","poster":"aqiao"},{"poster":"TechX","content":"Selected Answer: B\nIt's B. The question said that \"The solution must be as low-maintenance as possible while maintaining the existing degree of durability\"\nWith B, we can maintain durability and also can safe cost with combination of on-demand and reverse instance. Other choices are using Spot Instance which is not satisfy the requirement.","timestamp":"1656645420.0","upvote_count":"2","comment_id":"625550"},{"timestamp":"1648594320.0","poster":"jj22222","comment_id":"577915","upvote_count":"4","content":"Selected Answer: C\nmore cost effective than B"},{"timestamp":"1648113180.0","poster":"gorodetsky","upvote_count":"4","comment_id":"574207","comments":[{"upvote_count":"3","poster":"wassb","content":"B is not cost effective because you use Reserved Instance one week every month ...","comment_id":"689572","timestamp":"1665251820.0"}],"content":"Selected Answer: B\nAnswer is B, \nA,C,D are using Spot instances, there is guarantee for a cluster with more then 5000 cores with Spot instances"},{"comments":[{"comment_id":"689704","upvote_count":"2","content":"that's how hpc/batch processing works. you'd have a fleet of ec2 instances processing data stored in a single file storage.","poster":"Jonfernz","timestamp":"1665267900.0"}],"comment_id":"536191","timestamp":"1643550360.0","content":"My answer is B.\nEBS seems not proper storage choice in C.","poster":"HellGate","upvote_count":"4"},{"comment_id":"521587","content":"Selected Answer: C\nI would go for c","upvote_count":"3","timestamp":"1641912360.0","poster":"pititcu667"},{"content":"I would go for c","comment_id":"521586","poster":"pititcu667","timestamp":"1641912300.0","upvote_count":"2"},{"upvote_count":"3","poster":"peddyua","timestamp":"1640912880.0","content":"C\nhttps://aws.amazon.com/blogs/industries/building-a-scalable-image-processing-pipeline-for-image-based-transcriptomics/\nhttps://docs.aws.amazon.com/wellarchitected/latest/high-performance-computing-lens/batch-based-architecture.html","comment_id":"513796"},{"timestamp":"1640910780.0","comment_id":"513790","comments":[{"content":"They are not asking for cost efficient, it's looking for durability and less maintenance","comments":[{"timestamp":"1644686760.0","poster":"wahlbergusa","content":"\"...with developing a cost-effective solution on AWS...\"","comment_id":"546019","upvote_count":"6"}],"upvote_count":"2","poster":"lavy","comment_id":"543159","timestamp":"1644334380.0"}],"content":"C looks more cost effective over B.","upvote_count":"3","poster":"tkanmani76"}],"topic":"1","answers_community":["C (68%)","B (32%)"],"question_id":438,"exam_id":32,"question_images":[],"answer_images":[],"answer_description":"","choices":{"A":"Create a container in the Amazon Elastic Container Registry with the executable file for the job. Use Amazon ECS with Spot Fleet in Auto Scaling groups. Store the raw data in Amazon EBS SC1 volumes and write the output to Amazon S3.","B":"Create an Amazon EMR cluster with a combination of On Demand and Reserved Instance Task Nodes that will use Spark to pull data from Amazon S3. Use Amazon DynamoDB to maintain a list of jobs that need to be processed by the Amazon EMR cluster.","C":"Store the raw data in Amazon S3, and use AWS Batch with Managed Compute Environments to create Spot Fleets. Submit jobs to AWS Batch Job Queues to pull down objects from Amazon S3 onto Amazon EBS volumes for temporary storage to be processed, and then write the results back to Amazon S3.","D":"Submit the list of jobs to be processed to an Amazon SQS to queue the jobs that need to be processed. Create a diversified cluster of Amazon EC2 worker instances using Spot Fleet that will automatically scale based on the queue depth. Use Amazon EFS to store all the data sharing it across all instances in the cluster."}},{"id":"KPbtFLvhYSqqndM4V7sY","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/5592-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"answer":"D","isMC":true,"question_text":"A large company has many business units. Each business unit has multiple AWS accounts for different purposes. The CIO of the company sees that each business unit has data that would be useful to share with other parts of the company. In total, there are about 10 PB of data that needs to be shared with users in\n1,000 AWS accounts. The data is proprietary, so some of it should only be available to users with specific job types. Some of the data is used for throughput of intensive workloads, such as simulations. The number of accounts changes frequently because of new initiatives, acquisitions, and divestitures.\nA Solutions Architect has been asked to design a system that will allow for sharing data for use in AWS with all of the employees in the company.\nWhich approach will allow for secure data sharing in scalable way?","answer_images":[],"unix_timestamp":1569218220,"discussion":[{"timestamp":"1632825900.0","upvote_count":"24","comment_id":"76579","comments":[{"comment_id":"330656","poster":"SD13","content":"Token vending machine can be single point of failure.. Going with C","timestamp":"1635365580.0","upvote_count":"2","comments":[{"comment_id":"709598","content":"TVM can be implemented with LAMBDA - https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/implement-saas-tenant-isolation-for-amazon-s3-by-using-an-aws-lambda-token-vending-machine.html\n\nSo Option D is not single point of failure","poster":"pixepe","timestamp":"1667358900.0","upvote_count":"1"}]}],"poster":"Smart","content":"I am gonna go with D. \nI just don't feel comfortable with putting all kinds of data in a single bucket. With options A & B, there is going to be lot of editing of IAM Roles & Bucket policy as add or remove more accounts. Option C is good but what about auditability at CloudTrail if application API is used for data access. At this business level, AD or AWS SSO is must."},{"timestamp":"1632244320.0","poster":"donathon","upvote_count":"14","content":"B\nA: Not scalable. Remember this company has 1000 accounts.\nC: How would users be easily access the files using the application’s API?\nD: STS are used for web based identity like Google or Facebook and not used for IDP. https://aws.amazon.com/blogs/mobile/simplifying-token-vending-machine-deployment-with-aws-cloudformation/","comments":[{"comment_id":"80633","timestamp":"1633170540.0","content":"With SAML, STS can work with IdP. \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_saml.html","upvote_count":"8","poster":"Konnon"},{"comments":[{"content":"A bucket can contain unlimited amounts of data","timestamp":"1635761640.0","comment_id":"412371","upvote_count":"4","poster":"Japs"},{"comment_id":"177646","content":"The total volume of data and number of objects you can store are unlimited. Individual Amazon S3 objects can range in size from a minimum of 0 bytes to a maximum of 5 terabytes.","poster":"SadioMane","timestamp":"1634197500.0","upvote_count":"3"}],"content":"I will go with D. A,B store the data in a single S3 bucket. Note that the questions says petabytes of data. A single S3 bucket can only store 5 terabytes of data, so a series of buckets will be needed.","timestamp":"1634021040.0","upvote_count":"2","comment_id":"151925","poster":"directconnect"},{"upvote_count":"1","timestamp":"1636118700.0","poster":"tiffanny","content":"Max IAM user to attch is 20","comment_id":"414021"},{"comment_id":"414203","upvote_count":"2","poster":"TiredDad","timestamp":"1636250160.0","content":"Bucket policies are limited to 20 KB in size.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies.html"},{"content":"\"Store the data in a single Amazon S3 bucket\", Nope, exclude Answer with single bucket","comment_id":"651143","upvote_count":"1","timestamp":"1661326620.0","poster":"kadev"}],"comment_id":"12694"},{"timestamp":"1708020300.0","upvote_count":"1","comment_id":"1151217","poster":"marszalekm","content":"https://aws.amazon.com/blogs/apn/isolating-saas-tenants-with-dynamically-generated-iam-policies/"},{"content":"Selected Answer: D\nThe answer is D.\nThanks for bobsmith2000's explanation.","timestamp":"1664350440.0","poster":"tomosabc1","comment_id":"681478","upvote_count":"3"},{"upvote_count":"1","content":"Max S3 bucket size is 5TB. A and B cannot be correct because they want to store 10PB in a SINGLE bucket.","comment_id":"608173","timestamp":"1653677220.0","poster":"redipa","comments":[{"upvote_count":"1","timestamp":"1667142900.0","comment_id":"707883","content":"A bucket has unlimited storage , the 5 TB max is for each object","poster":"Cal88"}]},{"timestamp":"1652377920.0","comment_id":"600759","poster":"bobsmith2000","upvote_count":"3","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/implement-saas-tenant-isolation-for-amazon-s3-by-using-an-aws-lambda-token-vending-machine.html"},{"upvote_count":"1","poster":"user0001","content":"A , because The roles should have trust policies that allow the business unit's AWS accounts to assume their roles\nyou can not share s3 without trust relation","comment_id":"598772","timestamp":"1652054820.0"},{"comment_id":"567731","poster":"syscao","timestamp":"1647271080.0","content":"B is perfect. key word is prefix\nD too many policies to manage","upvote_count":"1"},{"comment_id":"549061","poster":"jyrajan69","timestamp":"1645060920.0","upvote_count":"1","content":"Based on number of accounts and the size of Data and the following link (https://aws.amazon.com/blogs/apn/isolating-saas-tenants-with-dynamically-generated-iam-policies/), my answer for this will be D"},{"upvote_count":"1","timestamp":"1637572500.0","content":"If you see the question is about role so the proper answer seems D, also B is lot more complex and not so scalable.","poster":"Kopa","comment_id":"484025"},{"comment_id":"446710","poster":"AWSum1","timestamp":"1636282500.0","content":"D \n\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/implement-saas-tenant-isolation-for-amazon-s3-by-using-an-aws-lambda-token-vending-machine.html","upvote_count":"4"},{"comment_id":"413758","poster":"DerekKey","content":"10 PB of data - users in 1,000 AWS accounts\nA wrong - \"an IAM role for every combination of job type and business unit\"\nB wrong - \"write a bucket policy that uses conditions to grant read and write access where appropriate, based on each user's business unit and job type\" & \"with a prefix in the IAM user's name\"\nC wrong - a single point of failure and bottleneck\nD correct - I don't see any other way to manage such a huge environment BTW. https://aws.amazon.com/blogs/apn/isolating-saas-tenants-with-dynamically-generated-iam-policies/","timestamp":"1636108860.0","upvote_count":"2"},{"comment_id":"413068","content":"Going with D as this is the most scalable solution","timestamp":"1636106760.0","poster":"DeathFrmAbv","upvote_count":"2"},{"content":"I'll go with D","comment_id":"409796","timestamp":"1635568260.0","poster":"WhyIronMan","upvote_count":"1"},{"comment_id":"406849","content":"B Correct","timestamp":"1635377040.0","upvote_count":"1","poster":"Akhil254"},{"poster":"Pupu86","comment_id":"314749","timestamp":"1635317820.0","upvote_count":"1","content":"The question has clearly indicated the permutations of BU and AWS accounts and the key objectives is scalability & clarity of purpose for various amount of data shared (10PB). Having a different S3 buckets resolve the clarify of purpose for various data type shared. Crafting a STS solutions mitigates the permutations of user accounts * IAM roles = scalability"},{"content":"going with D, STS API","poster":"Kian1","comment_id":"290900","upvote_count":"2","timestamp":"1635313140.0"},{"comment_id":"287490","poster":"Ebi","upvote_count":"2","timestamp":"1635284220.0","content":"I go with B"},{"poster":"lostre","content":"Why not A? Effort is minimal\n1 IAM Role for every combination of Job Type and BU, NOT PER user\ne.g. Admin_BI, Power_user_BI etc. This will be a fixed number and small (e.g, 50)\nAnd the same number of bucket prefixes\nAnd the code will be the same for all (\"assumeRole on your role\")","upvote_count":"2","timestamp":"1635115560.0","comment_id":"278780"},{"poster":"gookseang","content":"seems D","upvote_count":"1","timestamp":"1635025440.0","comment_id":"275158","comments":[{"content":"B is ok","poster":"gookseang","timestamp":"1635029760.0","comment_id":"275161","upvote_count":"1"}]},{"upvote_count":"1","content":"I'll go with B","poster":"sanjaym","timestamp":"1635021960.0","comment_id":"268239"},{"content":"B.\nIsn't Token Vending Machine a solution for mobile, and I think it is already replaced by Cognito.","comment_id":"251442","upvote_count":"2","comments":[{"content":"https://aws.amazon.com/articles/authenticating-users-of-aws-mobile-applications-with-a-token-vending-machine/","poster":"01037","comment_id":"251443","upvote_count":"1","timestamp":"1634895120.0"}],"timestamp":"1634798640.0","poster":"01037"},{"content":"Correct answer is D. STS and using without special API client","timestamp":"1634742720.0","comment_id":"242728","poster":"T14102020","upvote_count":"2"},{"poster":"jackdryan","comment_id":"230457","upvote_count":"3","timestamp":"1634645340.0","content":"I'll go with D"},{"timestamp":"1634588100.0","content":"Correct answer is D. The choice is between C and D because A and B are not scalable security designs. I would go from D over C because with C there is a lot of custom development not using many of the IAM and STS service features that D uses go provide the same outcome. Moreover I think D is scalable because there are no bucket level resource policies to maintain ad new accounts are added of existing ones deleted due to merger and acquisitions etc.","comment_id":"230102","poster":"Bulti","upvote_count":"4"},{"content":"The question states '' The data is proprietary, so some of it should only be available to users with specific job types. Some of the data is used for throughput of intensive workloads, such as simulations''. Better to put the data in series of S3 buckets. Option D makes sense.","timestamp":"1634428320.0","poster":"liono","upvote_count":"3","comment_id":"203795"},{"comments":[{"content":"B seems work. Any idea else?","timestamp":"1634372460.0","poster":"Phat","comment_id":"178091","upvote_count":"1"}],"poster":"AWSKrish","comment_id":"152155","timestamp":"1634072220.0","content":"Firstly all answers storing in S3 bucket are not appropriate as company is huge bib organization and 10 Pico DB, the maximum 5 terabytes. What you say?","upvote_count":"1"},{"upvote_count":"1","comment_id":"149748","content":"D, IAM user number restriction, Bucket policy size restriction, ec2 potential security holes as it required to access to all s3 bucket.","poster":"fullaws","timestamp":"1633936860.0"},{"upvote_count":"10","comments":[{"poster":"cox1960","timestamp":"1634909640.0","upvote_count":"1","content":"C says EC2, not single EC2 instance.","comment_id":"263070"}],"timestamp":"1633932360.0","comment_id":"134323","poster":"inf","content":"Answer: D (most appropriate)\nKey points - performance, scalability, security - a single bucket with all data (without using s3 prefixes) will be a bottleneck if mixing high throughput workloads with basic data retrieval. Don't assume all employees have AWS user accounts - use IDP. Adding/dropping accounts must be manageable - avoid IAM changes in each new account\nA - incorrect - single S3 bucket - performance; every combination of role/job-type would be 1000s of roles - unmanageable (may hit bucket policy size limit of 20kb); business unit account managers would determine what data a user can access - should be authorised centrally; \nB - incorrect - single S3 bucket - performance issue?; would have to rename every user in every account to insert job-type prefix - unmanageable\nC - incorrect - not scalable given its a single EC2 instance - potential bottleneck if data moved through EC2 application; multiple buckets are good.\nD - correct - multiple S3 buckets - better performance; TVM+IDP for ALL employees, and manage security centrally; no changes to AWS account roles/users when accounts added/removed - manageable"},{"upvote_count":"2","timestamp":"1633720860.0","poster":"mat2020","content":"answer: D","comment_id":"132770"},{"poster":"NikkyDicky","comment_id":"132365","content":"B. 20K limit is not an issue if policy uses conditions with multi-values","upvote_count":"1","timestamp":"1633642440.0"},{"poster":"LunchTime","comment_id":"121400","upvote_count":"1","timestamp":"1633446960.0","content":"Based on all of the comments I believe D is the correct answer.\nA. Too much work + complexity. There are already 1,000 accounts and this will grow. Requirements is \"in a scalable way\".\nB. The 20K size limit will be a problem as with 1,000 account there will likely need to be a least 1,000 subfolders in the bucket and likely many times more, given there is 10 PB of data to share. That leaves less then 20 bytes per sub-bucket in the policy.\nC. This makes sense but the issue it that it does not leverage IAM. That creates a potential security hole and violates the “least privileges principle. (i.e., the applications API would need access to all of the buckets and their information).\nD. The token vending machine doesn't address the complexity of this problem. There are a HUGE number of combinations of sub-bucket access, job types and departments. That logic has to be managed somewhere and a TVM does not readily do that. Still it can be added and its possible for create it here.\n\nThe ideal answer, I believe, would be a combination of C and D – create a custom application that leverages the security token vending machine. Given that IS not an option, I would go with D."},{"upvote_count":"1","timestamp":"1633373460.0","poster":"meenu2225","comment_id":"105663","content":"D makes sense."},{"comment_id":"89489","poster":"leahlee14083","timestamp":"1633361880.0","content":"Is it A? \"Which approach will allow for secure data sharing in scalable way?\" not on how we will apply it. B ' job type with a prefix in the IAM user's name' is impossible, and it cannot fit up to 20 KB policy size for 1000 accounts and we dont have access to usernames in other accounts? C and D is a bit tedious","upvote_count":"1"},{"content":"D \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_use-resources.html","upvote_count":"4","timestamp":"1633281600.0","comment_id":"80799","poster":"AmazonAu"},{"content":"I will go with D.","comment_id":"76230","timestamp":"1632734580.0","upvote_count":"2","poster":"Joeylee"},{"comment_id":"55955","content":"I'd go with TVM variant 1 (answer C): TVM assentially replaces IAM policy functionality so D doesn't really make sense either: https://aws.amazon.com/articles/authenticating-users-of-aws-mobile-applications-with-a-token-vending-machine/ \" For example, temporary credentials could be configured to allow access only to the Amazon Simple Storage Service (S3) or only to a particular storage bucket within the S3 service. Unlike account credentials, temporary credentials are time limited.\" So access to S3 can be granted this way and the customers application takes care of the rest through its API. C doesn't say anything about only running one EC2 instance - and also its common that all users will eventually end in a business Identity provider, be it AD or LDAP or, so that's the best solution from a business perspective. How users get their files through that API isn't relevant .","upvote_count":"1","timestamp":"1632729000.0","poster":"MrP"},{"comment_id":"55867","poster":"MrP","upvote_count":"1","timestamp":"1632601500.0","content":"B won't work: https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html \"Bucket policies are limited to 20 KB in size.\". As A won't work either (not scalable), that only leaves C and D."},{"poster":"Gorha","timestamp":"1632601140.0","comment_id":"53085","upvote_count":"1","content":"B is scalable!"},{"content":"B - Bucket policy is best\n\nA is having issue since company also acquires new accounts, hence A needs to create again roles which is not good way.","poster":"cinopi","comment_id":"32530","timestamp":"1632391200.0","upvote_count":"2"},{"comment_id":"24098","poster":"uopspop","upvote_count":"2","comments":[{"upvote_count":"1","content":"I guess it is being added as a prefix for username. that can be read.","comment_id":"31700","timestamp":"1632335160.0","poster":"9Ow30"}],"timestamp":"1632292440.0","content":"A\nB: you cannot see the IAM users information of one AWS account in another AWS account."},{"poster":"Moon","comment_id":"13842","content":"\"B\" make sense!\nA: is very work intensive, and requires editing for every user. While answer \"B\" apply the policy on the S3 token directly, using account-prefixes of users business unit.\nD: even STS & Idp work together but all the users are already having AWS Accounts. Plus Token Vending Machine (TVM) is complicated and does not have enough documentation in AWS.","timestamp":"1632257940.0","upvote_count":"10"},{"upvote_count":"1","poster":"awsec2","timestamp":"1632174300.0","comment_id":"12238","content":"why not a ?"}],"answer_ET":"D","answers_community":["D (100%)"],"question_id":439,"choices":{"B":"Store the data in a single Amazon S3 bucket. Write a bucket policy that uses conditions to grant read and write access where appropriate, based on each user's business unit and job type. Determine the business unit with the AWS account accessing the bucket and the job type with a prefix in the IAM user's name. Users can access data by using IAM credentials from their business unit's AWS account with an S3 client.","C":"Store the data in a series of Amazon S3 buckets. Create an application running in Amazon EC2 that is integrated with the company's identity provider (IdP) that authenticates users and allows them to download or upload data through the application. The application uses the business unit and job type information in the IdP to control what users can upload and download through the application. The users can access the data through the application's API.","D":"Store the data in a series of Amazon S3 buckets. Create an AWS STS token vending machine that is integrated with the company's identity provider (IdP). When a user logs in, have the token vending machine attach an IAM policy that assumes the role that limits the user's access and/or upload only the data the user is authorized to access. Users can get credentials by authenticating to the token vending machine's website or API and then use those credentials with an S3 client.","A":"Store the data in a single Amazon S3 bucket. Create an IAM role for every combination of job type and business unit that allows for appropriate read/write access based on object prefixes in the S3 bucket. The roles should have trust policies that allow the business unit's AWS accounts to assume their roles. Use IAM in each business unit's AWS account to prevent them from assuming roles for a different job type. Users get credentials to access the data by using AssumeRole from their business unit's AWS account. Users can then use those credentials with an S3 client."},"timestamp":"2019-09-23 07:57:00","answer_description":"","question_images":[]},{"id":"vQeH4WicSkqPffdpe6co","choices":{"E":"Apply security groups to the tasks, and use IAM roles for tasks to access other resources.","D":"Apply security groups to the tasks, and pass IAM credentials into the container at launch time to access other resources.","B":"Create tasks using the awsvpc network mode.","C":"Apply security groups to Amazon EC2 instances, and use IAM roles for EC2 instances to access other resources.","A":"Create tasks using the bridge network mode."},"question_id":440,"discussion":[{"comment_id":"11570","timestamp":"1632082380.0","upvote_count":"23","content":"I would go for B, E. \nhttps://amazonaws-china.com/blogs/compute/introducing-cloud-native-networking-for-ecs-containers/\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html","poster":"huhupai"},{"comment_id":"12695","content":"Agree BE","upvote_count":"14","timestamp":"1632186720.0","poster":"donathon","comments":[{"timestamp":"1632844620.0","upvote_count":"12","content":": With the default bridge network mode, containers on an instance are connected to each other using the docker0 bridge. This means you cannot address these containers with the IP address allocated by Docker (it’s allocated from a pool of locally scoped addresses), nor can you enforce finely grained network ACLs and firewall rules. Instead, containers are addressable in your VPC by the combination of the IP address of the primary elastic network interface of the instance, and the host port to which they are mapped (either via static or dynamic port mapping). Also, because a single elastic network interface is shared by multiple containers, it can be difficult to create easily understandable network policies for each container. The awsvpc networking mode addresses these issues by provisioning elastic network interfaces on a per-task basis. Hence, containers no longer share or contend use these resources.","comment_id":"13784","poster":"donathon"}]},{"timestamp":"1687044120.0","poster":"SkyZeroZx","comment_id":"926324","content":"Selected Answer: BE\nBE AND E ... GOOD GUESS BY ME ;)","upvote_count":"2"},{"poster":"Ni_yot","content":"B and E looks good","timestamp":"1645461180.0","comment_id":"553016","upvote_count":"1"},{"poster":"AzureDP900","comment_id":"493955","content":"I agree with B,E","upvote_count":"2","timestamp":"1638651000.0"},{"poster":"moon2351","timestamp":"1635610140.0","comment_id":"447894","content":"Answer is B&E","upvote_count":"1"},{"content":"I'll go with B,E","timestamp":"1635473580.0","poster":"WhyIronMan","upvote_count":"3","comment_id":"409798"},{"content":"only BE...","poster":"Kian1","comment_id":"290932","upvote_count":"2","timestamp":"1635437580.0"},{"upvote_count":"1","content":"BE are correct answer","poster":"Ebi","timestamp":"1635017100.0","comment_id":"282402"},{"content":"BE AND E ... GOOD GUESS BY ME ;)","timestamp":"1634727540.0","upvote_count":"3","comment_id":"244102","poster":"petebear55"},{"timestamp":"1634649540.0","content":"Correct answer BE. Bridge and role","upvote_count":"1","poster":"T14102020","comment_id":"242712"},{"comment_id":"230162","content":"B & E is the right answer","upvote_count":"3","poster":"Bulti","timestamp":"1634633340.0"},{"content":"I'll go with B,E","timestamp":"1634534880.0","poster":"jackdryan","comment_id":"230068","upvote_count":"4"},{"timestamp":"1634413140.0","poster":"fullaws","upvote_count":"1","comment_id":"149742","content":"B and E, awsvpc & task role (not task execution role)"},{"content":"B,E acceptable\nAmazon EC2 Container Service Task Role","timestamp":"1634333640.0","upvote_count":"1","poster":"noisonnoiton","comment_id":"138194"},{"content":"BE for sure","timestamp":"1633997520.0","upvote_count":"1","poster":"NikkyDicky","comment_id":"134460"},{"upvote_count":"1","timestamp":"1633778100.0","content":"Agree B & E","comment_id":"110332","poster":"mat2020"},{"content":"Should be B,E as the link below","comment_id":"51070","timestamp":"1633199700.0","poster":"amog","upvote_count":"4"},{"upvote_count":"3","comment_id":"13890","timestamp":"1633151340.0","content":"the E is a right answer,would you please follow this link:https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html","poster":"One_picese"},{"upvote_count":"4","timestamp":"1632587700.0","poster":"AdityaM","content":"B and E\nhttps://aws.amazon.com/about-aws/whats-new/2017/11/amazon-ecs-introduces-awsvpc-networking-mode-for-containers-to-support-full-networking-capabilities/","comment_id":"12953"},{"comments":[{"upvote_count":"2","content":"Using option B...Network Interface is provisioned at Task level.","timestamp":"1633564020.0","comment_id":"70283","poster":"Smart"}],"content":"How can we assign the security group to tasks? .. i feel B & C is the correct answer","timestamp":"1632578040.0","poster":"SivaG","upvote_count":"1","comment_id":"12872"}],"isMC":true,"answers_community":["BE (100%)"],"question_text":"A company wants to migrate its website from an on-premises data center onto AWS. At the same time, it wants to migrate the website to a containerized microservice-based architecture to improve the availability and cost efficiency. The company's security policy states that privileges and network permissions must be configured according to best practice, using least privilege.\nA Solutions Architect must create a containerized architecture that meets the security requirements and has deployed the application to an Amazon ECS cluster.\nWhat steps are required after the deployment to meet the requirements? (Choose two.)","topic":"1","answer_description":"Reference:\nhttps://aws.amazon.com/about-aws/whats-new/2017/11/amazon-ecs-introduces-awsvpc-networking-mode-for-containers-to-support-full-networking-capabilities/ https://amazonaws-china.com/blogs/compute/introducing-cloud-native-networking-for-ecs-containers/ https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html","url":"https://www.examtopics.com/discussions/amazon/view/5362-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"answer_ET":"BE","timestamp":"2019-09-18 08:51:00","question_images":[],"exam_id":32,"answer":"BE","unix_timestamp":1568789460}],"exam":{"id":32,"isBeta":false,"isImplemented":true,"isMCOnly":false,"provider":"Amazon","lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Professional"},"currentPage":88},"__N_SSP":true}