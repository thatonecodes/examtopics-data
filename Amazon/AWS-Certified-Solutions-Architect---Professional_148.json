{"pageProps":{"questions":[{"id":"uVDKyz9PHDZHsNO5mmdk","answer_images":[],"question_images":[],"unix_timestamp":1619788260,"timestamp":"2021-04-30 15:11:00","exam_id":32,"answer":"C","answer_ET":"C","answer_description":"","topic":"1","question_id":736,"isMC":true,"question_text":"A company that provisions job boards for a seasonal workforce is seeing an increase in traffic and usage. The backend services run on a pair of Amazon EC2 instances behind an Application Load Balancer with Amazon DynamoDB as the datastore. Application read and write traffic is slow during peak seasons.\nWhich option provides a scalable application architecture to handle peak seasons with the LEAST development effort?","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/51256-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"timestamp":"1633044000.0","upvote_count":"9","content":"Agree , C [ Key : LEAST development work]","comment_id":"352484","poster":"kpcert"},{"upvote_count":"1","timestamp":"1688157180.0","poster":"SkyZeroZx","comment_id":"939374","content":"Selected Answer: C\nAgree , C [ Key : LEAST development work]"},{"content":"C works perfectly fine. There is no need of SQS as mentioned in option D","upvote_count":"1","poster":"AzureDP900","timestamp":"1639001160.0","comment_id":"497202"},{"poster":"acloudguru","content":"simple one, hope i can have it in my exam C","upvote_count":"1","timestamp":"1638336600.0","comment_id":"491294"},{"upvote_count":"1","timestamp":"1635955260.0","poster":"andylogan","content":"It's C","comment_id":"448590"},{"content":"CCC\n---\nLEAST development work","poster":"tgv","upvote_count":"3","comment_id":"434826","timestamp":"1635729660.0"},{"content":"I'll go with C","comment_id":"414207","timestamp":"1634991120.0","poster":"WhyIronMan","upvote_count":"4"},{"content":"C is my answer!!","upvote_count":"1","timestamp":"1634905620.0","poster":"hk436","comment_id":"385780"},{"timestamp":"1633780320.0","comment_id":"368501","content":"C for sure","poster":"mustpassla","upvote_count":"1"},{"poster":"vkbajoria","content":"least amount of work. Answer is C","comment_id":"364852","timestamp":"1633129860.0","upvote_count":"2"},{"upvote_count":"4","comment_id":"360367","poster":"Waiweng","timestamp":"1633110060.0","content":"it's C"},{"poster":"gsw","timestamp":"1632681660.0","content":"i agree C","comment_id":"346208","upvote_count":"2"},{"timestamp":"1632567660.0","content":"C. works","poster":"Jaypdv","upvote_count":"3","comment_id":"346207"}],"choices":{"A":"Migrate the backend services to AWS Lambda. Increase the read and write capacity of DynamoDB","C":"Use Auto Scaling groups for the backend services. Use DynamoDB auto scaling","B":"Migrate the backend services to AWS Lambda. Configure DynamoDB to use global tables","D":"Use Auto Scaling groups for the backend services. Use Amazon Simple Queue Service (Amazon SQS) and an AWS Lambda function to write to DynamoDB"}},{"id":"zONfwIBWkU7VAYWstOzT","question_images":[],"answer_images":[],"unix_timestamp":1619788620,"timestamp":"2021-04-30 15:17:00","exam_id":32,"answer_ET":"A","answer":"C","answer_description":"","topic":"1","question_id":737,"isMC":true,"question_text":"A company has an application that sells tickets online and experiences bursts of demand every 7 days. The application has a stateless presentation layer running on Amazon EC2, an Oracle database to store unstructured data catalog information, and a backend API layer. The front-end layer uses an Elastic Load Balancer to distribute the load across nine On-Demand instances over three Availability Zones (AZs). The Oracle database is running on a single EC2 instance. The company is experiencing performance issues when running more than two concurrent campaigns. A solutions architect must design a solution that meets the following requirements:\n✑ Address scalability issues.\n✑ Increase the level of concurrency.\n✑ Eliminate licensing costs.\n✑ Improve reliability.\nWhich set of steps should the solutions architect take?","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/51258-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"comment_id":"347318","upvote_count":"23","timestamp":"1633243800.0","poster":"ExtHo","content":"C\nCombination of On-Demand and Spot Instances + DynamoDB.\nD Should be eliminated due to only use of Spot Instance as any time can be taken back by AWS","comments":[{"poster":"hilft","content":"CCC. GJ","timestamp":"1658700840.0","upvote_count":"1","comment_id":"636259"}]},{"comment_id":"352304","timestamp":"1634264640.0","poster":"beebatov","upvote_count":"5","content":"Answer: C\n\nHints: Unstructured data store + Eliminate licenses cost"},{"poster":"SkyZeroZx","upvote_count":"1","content":"Selected Answer: C\nc because eliminate licensing costs and scalability.","comment_id":"939314","timestamp":"1688149080.0"},{"upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1734288180.0","content":"DynamoDB is NoSQL. Can be used for both structured and unstructured data. Better suited for unstructured use cases that require an extremely fast database that can scale very well.","comment_id":"1327015","poster":"mnsait"}],"content":"Isn't DynamoDB used for \"structured\" data?","poster":"syaldram","comment_id":"771749","timestamp":"1673380620.0"},{"upvote_count":"2","timestamp":"1643724120.0","poster":"HellGate","content":"Answer is C!!!","comment_id":"537901"},{"timestamp":"1641978300.0","comment_id":"522012","poster":"pititcu667","content":"Selected Answer: C\nc because eliminate licensing costs and scalability.","upvote_count":"1"},{"content":"C is right answer for scalability and reduce license cost","upvote_count":"1","timestamp":"1639001280.0","poster":"AzureDP900","comment_id":"497203"},{"timestamp":"1635452700.0","poster":"andylogan","comment_id":"448591","upvote_count":"2","content":"It's C"},{"upvote_count":"3","timestamp":"1635205860.0","comment_id":"434828","content":"CCC\n---\nA: single RDS doesn't improve reliability\nB: two additional copies of the Oracle database doesn't eliminate licensing costs \nD: doesn't address the scalability issues","poster":"tgv"},{"poster":"blackgamer","content":"C is the answer.","comment_id":"434466","upvote_count":"1","timestamp":"1634925180.0"},{"content":"Im going for C","comment_id":"416131","upvote_count":"1","timestamp":"1634837220.0","poster":"Kopa"},{"comment_id":"414210","upvote_count":"4","poster":"WhyIronMan","timestamp":"1634799600.0","content":"I'll go with C"},{"comment_id":"368507","poster":"mustpassla","content":"C for sure","upvote_count":"1","timestamp":"1634699940.0"},{"comment_id":"364853","content":"my vote goes to C","upvote_count":"1","poster":"vkbajoria","timestamp":"1634637720.0"},{"upvote_count":"2","content":"it's C","poster":"Waiweng","comment_id":"360371","timestamp":"1634614800.0"},{"comments":[{"timestamp":"1633332000.0","upvote_count":"3","poster":"Jaypdv","content":"Typo. I mean C.","comment_id":"347716"}],"comment_id":"346531","upvote_count":"2","content":"Voting for D. Option A. does not eliminate licensing cost. At best it's included in the RDS instance price. And the question mentions \"unstructured data\" which fits DynamoDB well.","poster":"Jaypdv","timestamp":"1632897060.0"},{"poster":"gsw","comment_id":"346214","timestamp":"1632161280.0","content":"doesn't make sense - structured data would normally be Dynamo DB","comments":[{"comments":[{"content":"Spot instances (option D) is not valid response, because dont meet de requirements of \"Address scalability issues\". Correct option is C","poster":"hdomingo","comment_id":"378330","upvote_count":"1","timestamp":"1634700540.0"},{"timestamp":"1632548400.0","poster":"gsw","upvote_count":"2","comment_id":"346217","content":"i think C"}],"content":"has to be C or D","comment_id":"346215","poster":"gsw","upvote_count":"1","timestamp":"1632443940.0"},{"timestamp":"1633632060.0","poster":"jduo","upvote_count":"1","content":"Oracle database to store unstructured data catalog information","comment_id":"351842"},{"content":"It is required to address \"Scalability issue\", which can be addressed only by AutoScaling. That means the options are A, B or C. No \"Licensing cost - That is addressed by only option C.\nThe other two requirements are: \"Increase the level of concurrency \"and \"Improve reliability\" - Options C meets those.","poster":"DashL","timestamp":"1634721420.0","upvote_count":"2","comment_id":"400309"}],"upvote_count":"1"}],"choices":{"D":"Convert the On-Demand Instances into Spot instances to reduce costs for the front end. Convert the tables in the Oracle database into Amazon DynamoDB tables.","A":"Create an Auto Scaling group for the front end with a combination of On-Demand and Spot Instances to reduce costs. Convert the Oracle database into a single Amazon RDS reserved DB instance.","C":"Create an Auto Scaling group for the front end with a combination of On-Demand and Spot Instances to reduce costs. Convert the tables in the Oracle database into Amazon DynamoDB tables.","B":"Create an Auto Scaling group for the front end with a combination of On-Demand and Spot Instances to reduce costs. Create two additional copies of the database instance, then distribute the databases in separate AZs."}},{"id":"LRt2Z0aFyqcsi3fixOIU","question_text":"A company wants to refactor its retail ordering web application that currently has a load-balanced Amazon EC2 instance fleet for web hosting, database API services, and business logic. The company needs to create a decoupled, scalable architecture with a mechanism for retaining failed orders while also minimizing operational costs.\nWhich solution will meet these requirements?","question_images":[],"topic":"1","answer":"C","discussion":[{"timestamp":"1632791280.0","poster":"testtaker3434","comment_id":"347688","upvote_count":"16","content":"It should be C. You dont use long pooling \" for retaining failed orders while also minimizing operational costs.\". You use DLQ."},{"poster":"beebatov","upvote_count":"10","content":"Answer C:\n\nHints: Refactoring app to use GraphQL APIs (AppSync) + Serverless + DLQ for failed orders","timestamp":"1633546980.0","comment_id":"352316"},{"upvote_count":"1","comment_id":"950762","poster":"SkyZeroZx","timestamp":"1689259500.0","content":"Selected Answer: C\nAnswer C:\n\nHints: Refactoring app to use GraphQL APIs (AppSync) + Serverless + DLQ for failed orders"},{"poster":"AMKazi","comment_id":"544859","upvote_count":"1","timestamp":"1644525300.0","content":"C: solves all problems"},{"comment_id":"514430","upvote_count":"1","content":"C: DLQ","timestamp":"1641025560.0","poster":"cldy"},{"timestamp":"1639192620.0","content":"My Answer: C\nUse a Dead Letter Queue, not long polling","poster":"challenger1","upvote_count":"1","comment_id":"499065"},{"upvote_count":"2","timestamp":"1639006980.0","poster":"tkanmani76","comment_id":"497241","comments":[{"timestamp":"1644525480.0","upvote_count":"3","content":"You are only hosting website on S3, for all server side processing you have lambda","poster":"AMKazi","comment_id":"544862"}],"content":"Everyone is in favour of C - however the application mentioned is not a static one - retail ordering online application - so how can S3 host it ? So it cannot be Option C. The next decoupled scalable architecture is with Step Functions - Option B is correct in that case."},{"upvote_count":"1","comment_id":"497207","timestamp":"1639001520.0","content":"It is C, SQS is required.","poster":"AzureDP900"},{"timestamp":"1636239600.0","upvote_count":"1","content":"It's C","poster":"andylogan","comment_id":"448593"},{"timestamp":"1635567720.0","content":"CCC\n---\nA: you don't retain failed orders with SQS long polling\nB: Amazon S3 Glacier Deep Archive for retaining failed orders doesn't sound good\nC: You cannot use Amazon Simple Email Service (Amazon SES) for order queuing","comments":[{"upvote_count":"1","poster":"tgv","comment_id":"436996","content":"D: You cannot use Amazon Simple Email Service (Amazon SES) for order queuing*","timestamp":"1635843180.0"}],"poster":"tgv","comment_id":"434831","upvote_count":"4"},{"comment_id":"432767","poster":"Suresh108","upvote_count":"2","timestamp":"1635356820.0","content":"CCCCC\n\nMethod of Elimination -- look for failed order options in all the answers"},{"timestamp":"1635323160.0","upvote_count":"6","comment_id":"414213","poster":"WhyIronMan","content":"I'll go with C\n\nUnfortunately is a Trick question...While AppSync is no better than API GW in this context, DLQ is better choice than SQS long polling for retaining failed orders\n\nDamn aws..."},{"upvote_count":"1","content":"I think its C itself","comment_id":"410051","timestamp":"1635152520.0","poster":"santhoshmp"},{"content":"can S3 be used to host a retail web application. ? answer should be B or D ?","timestamp":"1634814300.0","poster":"santhoshmp","upvote_count":"2","comment_id":"410050"},{"comment_id":"399991","content":"C\n\nWhile AppSync is no better than API GW in this context, the latter part of the answer does mention DLQ which is a “must have”","timestamp":"1634678580.0","upvote_count":"2","poster":"vimgoru24"},{"poster":"hk436","upvote_count":"1","comment_id":"385781","content":"C is my answer!!","timestamp":"1633800120.0"},{"upvote_count":"1","timestamp":"1633763640.0","poster":"vkbajoria","content":"It is C","comment_id":"364856"},{"poster":"Waiweng","timestamp":"1633557660.0","content":"it's C","comment_id":"360375","upvote_count":"3"},{"upvote_count":"5","poster":"gsw","timestamp":"1632324180.0","content":"i think A as C doesn't mention Graph QL which would be relevant for using AppSync","comment_id":"346221"}],"question_id":738,"timestamp":"2021-04-30 15:23:00","answer_ET":"C","unix_timestamp":1619788980,"url":"https://www.examtopics.com/discussions/amazon/view/51260-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"isMC":true,"answer_images":[],"choices":{"B":"Use AWS Elastic Beanstalk for web hosting with Amazon API Gateway for database API services. Use Amazon MQ for order queuing. Use AWS Step Functions for business logic with Amazon S3 Glacier Deep Archive for retaining failed orders.","D":"Use Amazon Lightsail for web hosting with AWS AppSync for database API services. Use Amazon Simple Email Service (Amazon SES) for order queuing. Use Amazon Elastic Kubernetes Service (Amazon EKS) for business logic with Amazon Elasticsearch Service (Amazon ES) for retaining failed orders.","A":"Use Amazon S3 for web hosting with Amazon API Gateway for database API services. Use Amazon Simple Queue Service (Amazon SQS) for order queuing. Use Amazon Elastic Container Service (Amazon ECS) for business logic with Amazon SQS long polling for retaining failed orders.","C":"Use Amazon S3 for web hosting with AWS AppSync for database API services. Use Amazon Simple Queue Service (Amazon SQS) for order queuing. Use AWS Lambda for business logic with an Amazon SQS dead-letter queue for retaining failed orders."},"answer_description":"","answers_community":["C (100%)"]},{"id":"4Lr1RKlexhDyIKn9rRRt","answer":"C","question_id":739,"discussion":[{"comment_id":"346534","content":"C. \nObject lock and compliance mode: https://aws.amazon.com/about-aws/whats-new/2018/11/s3-object-lock/. The rest makes the most sense","timestamp":"1633950240.0","poster":"Jaypdv","upvote_count":"18"},{"timestamp":"1688089020.0","content":"Selected Answer: D\nS3 Storage Class: Storing the statements in S3 One Zone-IA is cost-effective compared to S3 Standard or S3 Intelligent-Tiering. S3 One Zone-IA offers a lower storage cost but doesn't provide the same level of data durability as S3 Standard or S3 Intelligent-Tiering. However, the company can tolerate the reduced durability because the statements are also stored in Glacier for long-term retention.\n\nLifecycle Policy: By defining an S3 Lifecycle policy to move the data to S3 Glacier Deep Archive after 2 years, the company can take advantage of the significantly lower storage cost of Glacier Deep Archive. This reduces the overall storage costs for the older statements that are rarely accessed.\n\nGlacier Vault Lock: Attaching an S3 Glacier Vault Lock policy with deny delete permissions for archives less than 7 years old ensures compliance with the company's security and compliance policy. It prevents the deletion of any statement archives before the 7-year retention period expires.","upvote_count":"1","comment_id":"938705","poster":"ajchi1980"},{"content":"Selected Answer: C\nC is correct","timestamp":"1647506640.0","poster":"KennethTam","upvote_count":"2","comment_id":"569570"},{"upvote_count":"2","comment_id":"497209","poster":"AzureDP900","content":"C is right answer","timestamp":"1639001700.0"},{"comment_id":"496608","content":"C. Create an S3 bucket with Object Lock enabled. Store statements in S3 Intelligent-Tiering. Enable compliance mode with a default retention period of 2 years. Define an S3 Lifecycle policy to move the data to S3 Glacier after 2 years. Attach an S3 Glacier Vault Lock policy with deny delete permissions for archives less than 7 years old.","upvote_count":"1","poster":"cldy","timestamp":"1638948840.0"},{"content":"Selected Answer: C\nC https://aws.amazon.com/about-aws/whats-new/2018/11/s3-object-lock/. The rest makes the most sense","poster":"acloudguru","timestamp":"1637548860.0","upvote_count":"3","comment_id":"483828"},{"upvote_count":"1","poster":"andylogan","timestamp":"1636111080.0","comment_id":"448659","content":"It's C"},{"poster":"Liongeek","timestamp":"1636108380.0","content":"CCC because of Object lock","upvote_count":"2","comment_id":"435975"},{"poster":"tgv","comment_id":"434832","content":"CCC\n---","timestamp":"1635946260.0","upvote_count":"1"},{"timestamp":"1635696540.0","upvote_count":"1","content":"It is C","poster":"blackgamer","comment_id":"434505"},{"poster":"Suresh108","comment_id":"432768","upvote_count":"1","timestamp":"1635674160.0","content":"CCCCC -- 'object lock enabled'"},{"comment_id":"414216","poster":"WhyIronMan","timestamp":"1635343800.0","upvote_count":"2","content":"I'll go with C, you convinced me"},{"content":"C is far superior than any other answer","comment_id":"399992","upvote_count":"1","timestamp":"1635106440.0","poster":"vimgoru24"},{"comment_id":"385785","poster":"hk436","timestamp":"1634689560.0","content":"C is my answer!!","upvote_count":"1"},{"content":"C.\nif you don't know Object lock and compliance mode, you will surely get it wrong like I did.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html","upvote_count":"3","timestamp":"1634498820.0","poster":"vkbajoria","comment_id":"364871"},{"upvote_count":"3","content":"it's C","timestamp":"1634342040.0","poster":"Waiweng","comment_id":"360381"},{"timestamp":"1634186280.0","poster":"beebatov","upvote_count":"2","comment_id":"352318","content":"Answer: C\n\nS3 Object Lock protection is maintained regardless of which storage class the object resides in and throughout S3 Lifecycle transitions between storage classes."},{"comment_id":"346225","content":"has to be C the others are silly","upvote_count":"3","timestamp":"1633683660.0","poster":"gsw"}],"question_text":"A financial company is building a system to generate monthly, immutable bank account statements for its users. Statements are stored in Amazon S3. Users should have immediate access to their monthly statements for up to 2 years. Some users access their statements frequently, whereas others rarely access their statements. The company's security and compliance policy requires that the statements be retained for at least 7 years.\nWhat is the MOST cost-effective solution to meet the company's needs?","timestamp":"2021-04-30 15:26:00","topic":"1","answers_community":["C (83%)","D (17%)"],"isMC":true,"answer_images":[],"unix_timestamp":1619789160,"answer_description":"","answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/51263-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"choices":{"B":"Create an S3 bucket with versioning enabled. Store statements in S3 Intelligent-Tiering. Use same-Region replication to replicate objects to a backup S3 bucket. Define an S3 Lifecycle policy for the backup S3 bucket to move the data to S3 Glacier. Attach an S3 Glacier Vault Lock policy with deny delete permissions for archives less than 7 years old.","D":"Create an S3 bucket with versioning disabled. Store statements in S3 One Zone-Infrequent Access (S3 One Zone-IA). Define an S3 Lifecycle policy to move the data to S3 Glacier Deep Archive after 2 years. Attach an S3 Glacier Vault Lock policy with deny delete permissions for archives less than 7 years old.","A":"Create an S3 bucket with Object Lock disabled. Store statements in S3 Standard. Define an S3 Lifecycle policy to transition the data to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days. Define another S3 Lifecycle policy to move the data to S3 Glacier Deep Archive after 2 years. Attach an S3 Glacier Vault Lock policy with deny delete permissions for archives less than 7 years old.","C":"Create an S3 bucket with Object Lock enabled. Store statements in S3 Intelligent-Tiering. Enable compliance mode with a default retention period of 2 years. Define an S3 Lifecycle policy to move the data to S3 Glacier after 2 years. Attach an S3 Glacier Vault Lock policy with deny delete permissions for archives less than 7 years old."},"question_images":[]},{"id":"JtEZuUJRWjcxcGF3BwHk","question_text":"A company hosts a large on-premises MySQL database at its main office that supports an issue tracking system used by employees around the world. The company already uses AWS for some workloads and has created an Amazon Route 53 entry for the database endpoint that points to the on-premises database.\nManagement is concerned about the database being a single point of failure and wants a solutions architect to migrate the database to AWS without any data loss or downtime.\nWhich set of actions should the solutions architect implement?","answers_community":["C (100%)"],"isMC":true,"answer_ET":"C","topic":"1","answer_images":[],"exam_id":32,"question_id":740,"answer":"C","answer_description":"","choices":{"D":"Create a backup of the database and restore it to an Amazon Aurora multi-master cluster. This Aurora cluster will be in a master-master replication configuration with the on-premises database. Update the Route 53 entry for the database to point to the Aurora cluster endpoint, and shut down the on- premises database.","B":"During nonbusiness hours, shut down the on-premises database and create a backup. Restore this backup to an Amazon Aurora DB cluster. When the restoration is complete, update the Route 53 entry for the database to point to the Aurora cluster endpoint, and shut down the on-premises database.","A":"Create an Amazon Aurora DB cluster. Use AWS Database Migration Service (AWS DMS) to do a full load from the on-premises database to Aurora. Update the Route 53 entry for the database to point to the Aurora cluster endpoint, and shut down the on-premises database.","C":"Create an Amazon Aurora DB cluster. Use AWS Database Migration Service (AWS DMS) to do a full load with continuous replication from the on-premises database to Aurora. When the migration is complete, update the Route 53 entry for the database to point to the Aurora cluster endpoint, and shut down the on- premises database."},"question_images":[],"discussion":[{"timestamp":"1632102240.0","comment_id":"346535","content":"C.\nGot the feeling some of those questions come from the DB Specialist cert.","poster":"Jaypdv","upvote_count":"14"},{"poster":"hilft","content":"A or C?\nSeems it's C","timestamp":"1658794740.0","upvote_count":"1","comment_id":"637012"},{"content":"Selected Answer: C\nC. does not have a downtime or data loss since live replication happens so on-premise DB is still operational until the new AWS Aurora DB is completely migrated.","comment_id":"596170","timestamp":"1651514820.0","upvote_count":"2","poster":"tartarus23"},{"upvote_count":"1","content":"Selected Answer: C\ncontinuous replication from on-premises to Aurora is a feasible solution.","poster":"tartarus23","timestamp":"1649338380.0","comment_id":"582469"},{"content":"Yah its C. Continuous replication is the key here. No downtime or data loss. Just do a cutover to finalize the migration when complete.","comment_id":"561458","poster":"Ni_yot","upvote_count":"1","timestamp":"1646488800.0"},{"poster":"AzureDP900","upvote_count":"1","timestamp":"1639002000.0","content":"I will go with C, there is no dataloss with this option","comment_id":"497210"},{"poster":"andylogan","timestamp":"1635929460.0","content":"It's C","upvote_count":"1","comment_id":"448663"},{"timestamp":"1635634800.0","comment_id":"434834","poster":"tgv","content":"CCC\n---","upvote_count":"1"},{"content":"I'll go with C","poster":"WhyIronMan","comment_id":"414217","upvote_count":"4","timestamp":"1635507720.0"},{"poster":"vimgoru24","comment_id":"399997","content":"C\n\n“Around the world” eliminates possibility for the maintenance window at night. The other difference is ability to leverage continuous replication in MySQL to Aurora case.","upvote_count":"3","timestamp":"1635272640.0"},{"poster":"hk436","timestamp":"1635060780.0","content":"C is my answer!!","comment_id":"385786","upvote_count":"1"},{"timestamp":"1634040360.0","upvote_count":"2","content":"Always choose full load with continuous replication. \nC","comment_id":"364873","poster":"vkbajoria"},{"timestamp":"1633138380.0","comment_id":"360387","content":"it's C","upvote_count":"2","poster":"Waiweng"},{"content":"go with C","upvote_count":"1","poster":"LCC92","timestamp":"1632588720.0","comment_id":"353589"},{"upvote_count":"2","timestamp":"1632490080.0","content":"Answer: C\n\nAWS DMS + CDC to capture daily changes","comment_id":"352308","poster":"beebatov"},{"upvote_count":"3","timestamp":"1632378480.0","poster":"gsw","content":"i agree with C","comment_id":"348765"}],"unix_timestamp":1619835840,"timestamp":"2021-05-01 04:24:00","url":"https://www.examtopics.com/discussions/amazon/view/51340-exam-aws-certified-solutions-architect-professional-topic-1/"}],"exam":{"isMCOnly":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Professional","numberOfQuestions":1019,"isImplemented":true,"provider":"Amazon","isBeta":false,"id":32},"currentPage":148},"__N_SSP":true}