{"pageProps":{"questions":[{"id":"ADTkBpRSY4SQRqEquz7C","answer_ET":"A","discussion":[{"content":"A. It is a push message that is received by your application on a user's device that will not be seen by the user.","poster":"amministrazione","upvote_count":"1","timestamp":"1723816020.0","comment_id":"1267187"},{"poster":"SkyZeroZx","timestamp":"1686693480.0","comment_id":"922576","content":"this questions outdate","upvote_count":"1"},{"content":"Selected Answer: A\nSure A.\nhttps://docs.aws.amazon.com/cognito/latest/developerguide/push-sync.html","poster":"foxrj21","timestamp":"1647339960.0","comment_id":"568287","upvote_count":"1"},{"poster":"cldy","upvote_count":"1","timestamp":"1638684480.0","content":"A. It is a push message that is received by your application on a user's device that will not be seen by the user.","comment_id":"494101"},{"poster":"01037","comment_id":"379643","timestamp":"1635983400.0","upvote_count":"3","content":"Sure A"}],"question_images":[],"exam_id":32,"answers_community":["A (100%)"],"answer_images":[],"question_id":176,"isMC":true,"answer":"A","answer_description":"Amazon Cognito uses the Amazon Simple Notification Service (SNS) to send silent push notifications to devices. A silent push notification is a push message that is received by your application on a user's device that will not be seen by the user.\nReference:\nhttp://aws.amazon.com/cognito/faqs/","unix_timestamp":1623404340,"question_text":"In Amazon Cognito what is a silent push notification?","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/55094-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"B":"It is a push message that is received by your application on a user's device that will return the user's geolocation.","A":"It is a push message that is received by your application on a user's device that will not be seen by the user.","C":"It is a push message that is received by your application on a user's device that will not be heard by the user.","D":"It is a push message that is received by your application on a user's device that will return the user's authentication credentials."},"timestamp":"2021-06-11 11:39:00"},{"id":"Vb2Zs5T6k6kZTnpUvu5x","unix_timestamp":1616101800,"isMC":true,"answer_images":[],"answer":"A","question_images":[],"choices":{"A":"Use Amazon Simple Storage Service (S3) with server-side encryption, and run simulations on subsets in ephemeral drives on Amazon EC2.","B":"Use Amazon S3 with server-side encryption, and run simulations on subsets in-memory on Amazon EC2.","E":"Store the full data set in encrypted Amazon Elastic Block Store (EBS) volumes, and regularly capture snapshots that can be cloned to EC2 workstations.","C":"Use HDFS on Amazon EMR, and run simulations on subsets in ephemeral drives on Amazon EC2.","D":"Use HDFS on Amazon Elastic MapReduce (EMR), and run simulations on subsets in-memory on Amazon Elastic Compute Cloud (EC2)."},"answer_description":"","question_id":177,"timestamp":"2021-03-18 22:10:00","url":"https://www.examtopics.com/discussions/amazon/view/47684-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"discussion":[{"timestamp":"1723724040.0","content":"A. Use Amazon Simple Storage Service (S3) with server-side encryption, and run simulations on subsets in ephemeral drives on Amazon EC2.","poster":"amministrazione","comment_id":"1266420","upvote_count":"1"},{"poster":"KevinYao","upvote_count":"1","timestamp":"1700748480.0","comment_id":"1078471","content":"Selected Answer: A\nS3 is best option for long term storage."},{"timestamp":"1677058140.0","upvote_count":"2","content":"Selected Answer: A\nmany explanations below, long term storage + 5TB capacity needed makes A the best option","poster":"sr987654","comment_id":"817672"},{"content":"Selected Answer: A\nA is the best one among the answers\nS3 (storage) + Anthan or Redshift Spectrum could be a better solution.\nHDFS is expensive non-long-term storage.\n5TB in-memory (RAM) is expensive.\nEBS expensive than S3","timestamp":"1670621820.0","upvote_count":"2","poster":"TigerInTheCloud","comment_id":"740464"},{"timestamp":"1668558180.0","poster":"hobokabobo","content":"Selected Answer: A\nThat said HDFS cached on local EBS is the most reasonable approach of the given approaches: A. HDFS vrs S3: small files and store only nectling EMR features. Store on disk because 5TB in ram would be huge.\nA","comments":[{"timestamp":"1672727700.0","upvote_count":"1","content":"It should read s3 cached on EBS. Hence the selection of A.","comment_id":"764266","poster":"hobokabobo"}],"upvote_count":"1","comment_id":"719202"},{"comment_id":"668534","timestamp":"1663118580.0","content":"why not B, the u-24tb1.metal can provide 24TB memory, and data handled in memory will be more secure than in EBS","poster":"LeoExam","upvote_count":"3"},{"timestamp":"1661967960.0","poster":"davideccc","comment_id":"655340","upvote_count":"1","content":"Selected Answer: A\nthe only reasonable options are A and C (5TB in memory? no way). However C does not mention any long-term storage service, leaving A as the only reasonable answer (not the best approach though - which would be have the processing in EMR and the storage in S3. The EMR cluster can get subset data directly from S3 using EMRFS)"},{"content":"Selected Answer: A\nBecause of \"long term storage\" specified. EMR is not a service designed for that. So S3 seems to be accurate.","comment_id":"590695","upvote_count":"3","poster":"virtual","timestamp":"1650728280.0"},{"poster":"jj22222","comment_id":"577849","timestamp":"1648584540.0","content":"Selected Answer: A\nA. Use Amazon Simple Storage Service (S3) with server-side encryption, and run simulations on subsets in ephemeral drives on Amazon EC2.","upvote_count":"1"},{"poster":"Alvindo","comment_id":"561288","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-file-systems.html\nthis link tells us hdfs isn't long-term which by itself cancels out c and d, leaving a as only practical answer","upvote_count":"1","timestamp":"1646465940.0"},{"content":"Selected Answer: D\nbecause of emr","comment_id":"525724","poster":"pititcu667","timestamp":"1642419420.0","upvote_count":"1"},{"timestamp":"1640798160.0","poster":"Vendu","comment_id":"512479","upvote_count":"1","content":"Selected Answer: A\nS3 would be cist effective compare to EMR"},{"timestamp":"1640735280.0","upvote_count":"1","comment_id":"511651","content":"Asks for a cost effective solution. S3 is better than EMR.","poster":"wahlbergusa"},{"poster":"dv1","upvote_count":"3","timestamp":"1639483620.0","comment_id":"501333","content":"EMR can do encryption at rest and in transit: https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-data-encryption.html \n\nAlso, you can combine EMR with EC2 for running simulations:\nhttps://aws.amazon.com/getting-started/hands-on/optimize-amazon-emr-clusters-with-ec2-spot/"},{"timestamp":"1636173900.0","comment_id":"442802","poster":"Bhagirathi","upvote_count":"1","content":"can someone pls help explain - why / how it should be A?"},{"timestamp":"1635273660.0","poster":"Akhil254","comments":[{"poster":"ciberado","content":"The question does not explictly says the ephemeral storage is going to be encrypted in any way, so I would discard this option.","timestamp":"1636097760.0","comment_id":"422023","upvote_count":"1"}],"upvote_count":"1","comment_id":"405802","content":"A Correct"},{"comment_id":"397970","content":"I go with A as it says cost-effective","timestamp":"1635235440.0","poster":"backfringe","upvote_count":"3"},{"timestamp":"1635229740.0","poster":"nodogoshi","content":"Concurrency Analysis require EMR. not S3. C and D are candidate.","upvote_count":"2","comment_id":"374978"},{"comment_id":"333311","poster":"01037","content":"What's wrong with B?","timestamp":"1634676000.0","upvote_count":"1","comments":[{"timestamp":"1636055580.0","upvote_count":"3","comment_id":"409277","content":"Data size is 5TB","poster":"dli"}]},{"upvote_count":"1","poster":"anandbabu","comment_id":"327971","timestamp":"1632685680.0","content":"i will go with A"},{"poster":"cldy","upvote_count":"3","comment_id":"323221","content":"A.\nencryption at rest - with S3 server side encryption.\nencryption in transit - between S3 & EC2 encrypted with HTTPS; betweeb EC2 and instance store also encrypted.","timestamp":"1632516540.0"},{"comment_id":"314407","content":"A, data at rest encrypted. for data in transit, when using boto or aws cli, s3 endpoint is always https so data in transit is also encrypted. and its scalable and cheap.","timestamp":"1632515400.0","upvote_count":"3","poster":"nitinz"}],"question_text":"Your company is storing millions of sensitive transactions across thousands of 100-GB files that must be encrypted in transit and at rest. Analysts concurrently depend on subsets of files, which can consume up to 5 TB of space, to generate simulations that can be used to steer business decisions.\nYou are required to design an AWS solution that can cost effectively accommodate the long-term storage and in-flight subsets of data.\nWhich approach can satisfy these objectives?","answers_community":["A (93%)","7%"],"answer_ET":"A","topic":"1"},{"id":"wLJ6CnpvZPjSeJ4fVmTp","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/17891-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"poster":"sam_1975","timestamp":"1635949440.0","comment_id":"162019","content":"A. http://awsdocs.s3.amazonaws.com/SQS/2011-10-01/sqs-dg-2011-10-01.pdf","upvote_count":"5"},{"comment_id":"1267189","content":"A. numlteq","poster":"amministrazione","timestamp":"1723816020.0","upvote_count":"1"},{"upvote_count":"1","poster":"Sizuma","comment_id":"655180","timestamp":"1661955960.0","content":"Correct Answer: A\nWhen using Numeric Conditions within IAM, short versions of the available comparators can be used instead of the more verbose versions. For instance, numIteq is the short version of NumericLessThanEquals.\nhttp://awsdocs.s3.amazonaws.com/SQS/2011-10-01/sqs-dg-2011-10-01.pdf"},{"content":"why such question????","timestamp":"1638271020.0","upvote_count":"4","poster":"acloudguru","comment_id":"490627"},{"upvote_count":"2","poster":"01037","content":"I Guess A\nThought I can find any references","timestamp":"1636184100.0","comment_id":"379645"},{"poster":"Exam_boy","upvote_count":"2","comment_id":"71352","content":"not relevant any more. can't find any reference of short version of operators in IAM docs","timestamp":"1633722240.0"}],"isMC":true,"unix_timestamp":1586076060,"answer":"A","topic":"1","choices":{"B":"numlteql","C":"numltequals","A":"numlteq","D":"numeql"},"timestamp":"2020-04-05 10:41:00","answers_community":[],"answer_description":"When using Numeric Conditions within IAM, short versions of the available comparators can be used instead of the more verbose versions. For instance, numIteq is the short version of NumericLessThanEquals.\nReference:\nhttp://awsdocs.s3.amazonaws.com/SQS/2011-10-01/sqs-dg-2011-10-01.pdf","answer_ET":"A","answer_images":[],"exam_id":32,"question_id":178,"question_text":"When using Numeric Conditions within IAM, short versions of the available comparators can be used instead of the more verbose versions.\nWhich of the following is the short version of the Numeric Condition \"NumericLessThanEquals\"?"},{"id":"te9tn2MgcB5vAkxLeuJ7","answer_description":"A Virtual Private Cloud (VPC) is a virtual network dedicated to the user's AWS account. The user can create subnets as per the requirement within a VPC. The\nAWS account provides two platforms:\nEC2-CLASSIC and EC2-VPC, depending on when the user has created his AWS account and which regions he is using. If the user has created the AWS account after 2013-12-04, it supports only EC2-VPC. In this scenario, since the account is before the required date the supported platform will be EC2-CLASSIC. It is required that the organization creates a VPC as the T2 instances can be launched only as a part of VPC.\nReference:\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-migrate.html","url":"https://www.examtopics.com/discussions/amazon/view/29104-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"C","topic":"1","timestamp":"2020-08-20 08:50:00","choices":{"A":"The organization must migrate to the EC2-VPC platform first before launching a T2 instance.","C":"Create a VPC and launch a T2 instance as part of one of the subnets of that VPC.","B":"While launching a T2 instance the organization must create a new AWS account as this account does not have the EC2-VPC platform.","D":"While launching a T2 instance the organization must select EC2-VPC as the platform."},"answers_community":["C (100%)"],"exam_id":32,"discussion":[{"timestamp":"1723816080.0","upvote_count":"1","poster":"amministrazione","content":"C. Create a VPC and launch a T2 instance as part of one of the subnets of that VPC.","comment_id":"1267191"},{"poster":"MWinter","timestamp":"1648967820.0","comment_id":"580132","upvote_count":"4","content":"it is basically saying the they are using EC2-classic platform, therefore, we will need to create VPC based on EC2-VPC platform initiate the T2 type instance.\nSo, C is the correct answer."},{"timestamp":"1646469420.0","comment_id":"561307","poster":"Mechanic","content":"Selected Answer: C\nC.\nEven though I thought the question is about scheduling Autoscaling or some instance specs, it was so weird in the choices, but chose the answer because it makes sense.","upvote_count":"1"},{"upvote_count":"2","timestamp":"1639103220.0","comment_id":"498230","poster":"GeniusMikeLiu","content":"this question is really wired from now"},{"content":"C. Create a VPC and launch a T2 instance as part of one of the subnets of that VPC.","upvote_count":"1","timestamp":"1638712260.0","poster":"cldy","comment_id":"494386"},{"comment_id":"379836","poster":"01037","upvote_count":"1","content":"C is the only valid option","timestamp":"1635793440.0"},{"upvote_count":"1","poster":"aimar047","timestamp":"1633447020.0","content":"What is the difference between A and C? In both cases will be requiring to create a new EC2-VPC ..","comment_id":"277728"},{"timestamp":"1633043760.0","content":"What does \"since Jan 2012\" imply?\nThere were VPC then","comment_id":"230892","upvote_count":"1","poster":"newme"},{"poster":"sam_1975","comment_id":"162021","timestamp":"1632093900.0","content":"I go with C as VPC is the pre-requisite for creating EC2, assuming user doesn;t want to use the default VPC","upvote_count":"1"}],"isMC":true,"question_id":179,"question_images":[],"question_text":"AWS has launched T2 instances which come with CPU usage credit. An organization has a requirement which keeps an instance running for 24 hours. However, the organization has high usage only during 11 AM to 12 PM. The organization is planning to use a T2 small instance for this purpose.\nIf the organization already has multiple instances running since Jan 2012, which of the below mentioned options should the organization implement while launching a T2 instance?","answer":"C","answer_images":[],"unix_timestamp":1597906200},{"id":"RPCdx4YpQTQly4R9LWoI","answers_community":["A (100%)"],"unix_timestamp":1610526240,"discussion":[{"poster":"Mansur","timestamp":"1633360320.0","comment_id":"288673","upvote_count":"5","comments":[{"content":"Thank you","upvote_count":"1","comment_id":"379837","poster":"01037","timestamp":"1635415200.0"}],"content":"Answer A\nQ: Can I execute activities on on-premise resources or AWS resources that I manage?\n\nYes. To enable running activities using on-premise resources, AWS Data Pipeline supplies a Task Runner package that can be installed on your on-premise hosts. This package continuously polls the AWS Data Pipeline service for work to perform. When it’s time to run a particular activity on your on-premise resources, for example, executing a DB stored procedure or a database dump, AWS Data Pipeline will issue the appropriate command to the Task Runner. To ensure that your pipeline activities are highly available, you can optionally assign multiple Task Runners to poll for a given job. This way, if one Task Runner becomes unavailable, the others will pick up its work.\n\nREF: https://aws.amazon.com/datapipeline/faqs/"},{"comment_id":"1267192","upvote_count":"1","content":"A. By supplying a Task Runner package that can be installed on your on-premise hosts","timestamp":"1723816140.0","poster":"amministrazione"},{"poster":"SkyZeroZx","timestamp":"1687312200.0","comment_id":"928948","content":"Selected Answer: A\nAnswer A\nQ: Can I execute activities on on-premise resources or AWS resources that I manage?\n\nYes. To enable running activities using on-premise resources, AWS Data Pipeline supplies a Task Runner package that can be installed on your on-premise hosts. This package continuously polls the AWS Data Pipeline service for work to perform. When it’s time to run a particular activity on your on-premise resources, for example, executing a DB stored procedure or a database dump, AWS Data Pipeline will issue the appropriate command to the Task Runner. To ensure that your pipeline activities are highly available, you can optionally assign multiple Task Runners to poll for a given job. This way, if one Task Runner becomes unavailable, the others will pick up its work.\n\nREF: https://aws.amazon.com/datapipeline/faqs/","upvote_count":"1"},{"comment_id":"655184","upvote_count":"1","content":"A CORRECT","timestamp":"1661956080.0","poster":"Sizuma"},{"upvote_count":"4","timestamp":"1632476880.0","content":"Bad question: \"or AWS resources that you manage\". Does AWS resources need Task Runner package?","poster":"Justu","comment_id":"266113","comments":[{"upvote_count":"1","content":"agree with","timestamp":"1633274040.0","poster":"aimar047","comment_id":"277729"}]}],"answer_ET":"A","isMC":true,"exam_id":32,"timestamp":"2021-01-13 09:24:00","question_id":180,"question_images":[],"answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/42237-exam-aws-certified-solutions-architect-professional-topic-1/","answer_description":"To enable running activities using on-premise resources, AWS Data Pipeline does the following: It supply a Task Runner package that can be installed on your on- premise hosts. This package continuously polls the AWS Data Pipeline service for work to perform. When it's time to run a particular activity on your on-premise resources, it will issue the appropriate command to the Task Runner.\nReference:\nhttps://aws.amazon.com/datapipeline/faqs/","answer_images":[],"topic":"1","question_text":"How does AWS Data Pipeline execute activities on on-premise resources or AWS resources that you manage?","choices":{"D":"By supplying a Task Runner json script that can be installed on your on-premise hosts","C":"By supplying a Task Runner file that the resources can access for execution","A":"By supplying a Task Runner package that can be installed on your on-premise hosts","B":"None of these"}}],"exam":{"provider":"Amazon","isBeta":false,"isImplemented":true,"isMCOnly":false,"numberOfQuestions":1019,"id":32,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Professional"},"currentPage":36},"__N_SSP":true}