{"pageProps":{"questions":[{"id":"NHIVLKyihSV0tIyXHG2J","url":"https://www.examtopics.com/discussions/amazon/view/88722-exam-aws-certified-developer-associate-topic-1-question-248/","choices":{"B":"A directory named \"deploy\" under the root source directory","A":"A directory named \"aws\" under the route source directory","D":"The root of the source directory","C":"A directory named \"scripts\" under the root source directory"},"exam_id":25,"answer_description":"","answer_ET":"D","answer_images":[],"discussion":[{"upvote_count":"1","comment_id":"938441","timestamp":"1688062560.0","poster":"rcaliandro","content":"Selected Answer: D\nEasy: the root of source directory. D is the correct answer"},{"content":"Selected Answer: D\nD. The root of the source directory\n\nPlacing the configuration files in the root directory allows AWS CodeBuild and AWS CodeDeploy to automatically detect and use them. The default locations for the configuration files are:\n\nbuildspec.yml for CodeBuild: Placing this file in the root directory allows CodeBuild to automatically detect and use it as the build specification file for the project.\n\nappspec.yml for CodeDeploy: Placing this file in the root directory allows CodeDeploy to automatically detect and use it as the application specification file for the deployment.\n\nBy following the service defaults and placing the configuration files in the root directory, the team can ensure that CodeBuild and CodeDeploy recognize and utilize them correctly during the build and deployment processes.","timestamp":"1684311600.0","upvote_count":"2","comment_id":"899856","poster":"pranay_2406"},{"upvote_count":"2","comments":[{"timestamp":"1674743040.0","poster":"JuanFe","upvote_count":"1","content":"\"If you include a buildspec as part of the source code, by default, the buildspec file must be named buildspec.yml and placed in the root of your source directory.\" https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html","comment_id":"788800"}],"content":"I think D is correct because buildspec.yml for example has to be at the root of the source directory. So if We mention CodeBuild, we are talking about buildspec too indirectly","comment_id":"788797","timestamp":"1674742920.0","poster":"JuanFe"},{"timestamp":"1669443960.0","poster":"michaldavid","content":"appspec.yml and it must be placed in the root of the directory structure of an application's source code","upvote_count":"1","comment_id":"727319"},{"comment_id":"727315","poster":"michaldavid","timestamp":"1669443840.0","content":"Selected Answer: D\nGoing with D","upvote_count":"2"},{"comment_id":"726915","poster":"k1kavi1","content":"Selected Answer: D\nShould be root of the source directory","timestamp":"1669391700.0","upvote_count":"1"}],"timestamp":"2022-11-25 16:55:00","question_id":166,"question_images":[],"answer":"D","isMC":true,"question_text":"A development team sets up a project's file directory structure in AWS CodeCommit. The team plans to use AWS CodeBuild and AWS CodeDeploy. The team creates the necessary configuration files for CodeBuild and CodeDeploy. The team wants to name and place these files according to service defaults.\n\nWhere should the team place the CodeBuild and CodeDeploy files?","answers_community":["D (100%)"],"unix_timestamp":1669391700,"topic":"1"},{"id":"3FQCUOVadvMid8CBDH63","url":"https://www.examtopics.com/discussions/amazon/view/88677-exam-aws-certified-developer-associate-topic-1-question-249/","question_images":[],"topic":"1","isMC":true,"question_id":167,"answer_images":[],"question_text":"A software company must ensure that documents that are uploaded by users are securely stored in Amazon S3. The documents must be encrypted at rest in Amazon S3. The company wants to avoid client-side encryption and does not want to manage the security infrastructure. In addition, the company wants control over the keys that are used for encryption at rest.\n\nWhich solution for encryption keys should a developer use to meet these requirements?","answer_description":"","answer_ET":"C","unix_timestamp":1669373820,"choices":{"A":"Amazon S3 managed keys","B":"Application-level encryption with customer-provided encryption keys that are stored in an on-premises hardware security module (HSM)","D":"IAM access keys","C":"AWS Key Management Service (AWS KMS) customer managed keys"},"exam_id":25,"discussion":[{"timestamp":"1688062860.0","poster":"rcaliandro","upvote_count":"1","content":"Selected Answer: C\nSorry I have one question. Among the options is of course C because we can create, delete and manage the keys rather then use the default server-side encryption at rest. \nBut, given the requirements shouldn't be SSE-C encryption? In this way the user can manage the keys in local","comment_id":"938447"},{"content":"Selected Answer: C\ncccccccccccccc","poster":"anitauk","timestamp":"1676573760.0","comment_id":"811021","upvote_count":"2"},{"content":"Selected Answer: C\nEasy C","poster":"michaldavid","comment_id":"727320","upvote_count":"2","timestamp":"1669444020.0"},{"content":"Selected Answer: C\nC. AWS Key Management Service (AWS KMS) customer managed keys","upvote_count":"4","timestamp":"1669391820.0","comment_id":"726918","poster":"k1kavi1"},{"content":"C \nAWS KMS with CMK","timestamp":"1669373820.0","upvote_count":"1","comment_id":"726679","poster":"kapil206001"}],"answer":"C","timestamp":"2022-11-25 11:57:00","answers_community":["C (100%)"]},{"id":"76IsoxK3RNx8zjVu431H","answer_ET":"D","answer_images":[],"topic":"1","question_text":"A company is adding items to an Amazon DynamoDB table from an AWS Lambda function that is written in Python. A developer needs to implement a solution that inserts records in the DynamoDB table and performs automatic retry when the insert fails.\nWhich solution meets these requirements with MINIMUM code changes?","timestamp":"2022-09-03 05:57:00","discussion":[{"content":"Selected Answer: D\nThe answer is D\nThe AWS SDKs for DynamoDB automatically retry requests that receive this exception. Your request is eventually successful, unless your retry queue is too large to finish. Reduce the frequency of requests using Error retries and exponential backoff.\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html","comment_id":"665825","poster":"LaXuanLinh","upvote_count":"6","timestamp":"1662873240.0"},{"comment_id":"1328936","content":"Selected Answer: C\nChuthyas it is C it requires no code changes","poster":"Chutyapathy","timestamp":"1734603720.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"1327248","content":"Selected Answer: D\nD) Correct Boto3 automatically handles retries for transient failures (e.g., throttling, network errors) by leveraging AWS's built-in retry logic.","poster":"sumanshu","timestamp":"1734341220.0"},{"poster":"rcaliandro","upvote_count":"1","comment_id":"935656","content":"Selected Answer: D\nD for sure, we need SDK for python to call put_item API in order to insert or update an item in the DynamoDB table.\nPlease correct me if I'm wrong but the exponential backoff is implemented in the lambda function itself and not in the AWS SDK. I mean, even if we don't use the SDK, if the lambda throttles an error, it will try other 2 times to execute.","timestamp":"1687887720.0"},{"comment_id":"904569","timestamp":"1684818600.0","content":"Selected Answer: D\nboto3 is a SDK used for Python to interact with AWS","poster":"peterpain","upvote_count":"1"},{"timestamp":"1676061120.0","upvote_count":"1","comment_id":"804770","poster":"Krt5894","content":"Selected Answer: D\nD it is"},{"timestamp":"1666370340.0","content":"It is D","comment_id":"701062","poster":"cwit63","upvote_count":"1"},{"timestamp":"1665647640.0","comment_id":"693719","upvote_count":"3","content":"Selected Answer: D\nD since AWS SDKs implements exponential backoff which will retry the requests until they are successful","poster":"denbond"},{"poster":"tam2801","content":"Voted D","upvote_count":"1","comment_id":"671902","timestamp":"1663463160.0"},{"timestamp":"1662177420.0","upvote_count":"3","comment_id":"658046","content":"Selected Answer: D\nhttps://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html\n\nanswer should be D","poster":"sindra"}],"choices":{"C":"Queue the items in AWS Glue, which will put them into the DynamoDB table","B":"Call the PutItem operation from Python by using the DynamoDB HTTP API","A":"Configure the Python code to run the AWS CLI through shell to call the PutItem operation","D":"Use the AWS software development kit (SDK) for Python (boto3) to call the PutItem operation"},"exam_id":25,"isMC":true,"question_images":[],"unix_timestamp":1662177420,"answer":"D","question_id":168,"answers_community":["D (94%)","6%"],"url":"https://www.examtopics.com/discussions/amazon/view/79670-exam-aws-certified-developer-associate-topic-1-question-25/","answer_description":""},{"id":"olnIYdktlnHcTnhf6BHl","question_text":"In a move toward using microservices, a company's management team has asked all development teams to build their services so that API requests depend only on that service's data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB.\n\nWhat approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?","choices":{"B":"Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.","C":"Use Amazon Kinesis Data Firehose to deliver all changes from the Accounts database to the Payments database.","A":"Use Amazon Glue to perform frequent ETL updates from the Accounts database to the Payments database.","D":"Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database."},"question_images":[],"isMC":true,"unix_timestamp":1669373880,"answer_ET":"D","answer":"D","discussion":[{"comments":[{"content":"DB not table*","comment_id":"938450","poster":"rcaliandro","timestamp":"1688063040.0","upvote_count":"1"}],"timestamp":"1688063040.0","content":"Selected Answer: D\nI agree with using Amazon Dynamo DB Streams to catch changes from one table to the other table","poster":"rcaliandro","comment_id":"938449","upvote_count":"1"},{"timestamp":"1676593140.0","upvote_count":"1","comment_id":"811239","poster":"pancman","content":"Selected Answer: D\nEasy D"},{"upvote_count":"1","timestamp":"1669444140.0","comment_id":"727321","content":"Selected Answer: D\nAgree with D","poster":"michaldavid"},{"comment_id":"726920","upvote_count":"1","content":"D. Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.","poster":"k1kavi1","timestamp":"1669392000.0"},{"upvote_count":"1","comment_id":"726680","content":"D\nhttps://www.examtopics.com/discussions/amazon/view/10855-exam-aws-certified-developer-associate-topic-1-question-131/","poster":"kapil206001","timestamp":"1669373880.0"}],"timestamp":"2022-11-25 11:58:00","answers_community":["D (100%)"],"question_id":169,"exam_id":25,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/88678-exam-aws-certified-developer-associate-topic-1-question-250/","answer_images":[],"answer_description":""},{"id":"uamDc3MAQO2famaZvl5g","unix_timestamp":1669378080,"answer_images":[],"topic":"1","isMC":true,"discussion":[{"content":"Selected Answer: D\nD, by increasing the memory to a lambda function, also the CPU will be increased. Memory + CPU = improvement of the performances","timestamp":"1688063160.0","comment_id":"938451","upvote_count":"2","poster":"rcaliandro"},{"content":"Selected Answer: D\nMemory and computing power:\nMemory is the principal lever available to Lambda developers for controlling the performance of a function.\n\nThe amount of memory also determines the amount of virtual CPU available to a function. Adding more memory proportionally increases the amount of CPU, increasing the overall computational power available. If a function is CPU-, network- or memory-bound, then changing the memory setting can dramatically improve its performance.\n\nhttps://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html","poster":"DrCloud","timestamp":"1670104080.0","comment_id":"734710","upvote_count":"2"},{"comment_id":"727331","poster":"michaldavid","content":"Selected Answer: D\nMore CPU comes with increasing memory within Lambda function so D","timestamp":"1669444800.0","upvote_count":"2"},{"content":"Selected Answer: D\nD. Increase the available memory to the function.","upvote_count":"2","poster":"k1kavi1","comment_id":"726924","timestamp":"1669392060.0"},{"timestamp":"1669378080.0","content":"D\nhttps://www.examtopics.com/discussions/amazon/view/28322-exam-aws-certified-developer-associate-topic-1-question-231/","poster":"kapil206001","upvote_count":"1","comment_id":"726712"}],"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/88681-exam-aws-certified-developer-associate-topic-1-question-251/","answers_community":["D (100%)"],"question_id":170,"question_text":"A software engineer developed an AWS Lambda function in Node.js to do some CPU-intensive data processing. With the default settings, the Lambda function takes about 5 minutes to complete.\n\nWhich approach should a developer take to increase the speed of completion?","choices":{"D":"Increase the available memory to the function.","C":"Allocate the maximum available CPU units to the function.","A":"Instead of using Node.js. rewrite the Lambda function using Python.","B":"Instead of packaging the libraries in the ZIP file with the function, move them to a Lambda layer and use the layer with the function."},"question_images":[],"answer":"D","answer_description":"","exam_id":25,"timestamp":"2022-11-25 13:08:00"}],"exam":{"id":25,"isMCOnly":true,"numberOfQuestions":443,"isBeta":false,"lastUpdated":"11 Apr 2025","isImplemented":true,"name":"AWS Certified Developer Associate","provider":"Amazon"},"currentPage":34},"__N_SSP":true}