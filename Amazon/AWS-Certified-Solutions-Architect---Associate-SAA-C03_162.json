{"pageProps":{"questions":[{"id":"ngs6BLVqN8JyGeR2SzQT","exam_id":31,"answer_ET":"B","answer_images":[],"timestamp":"2024-03-05 22:48:00","choices":{"D":"Use the Amazon Elastic File System (Amazon EFS) One Zone-Infrequent Access (One Zone-IA) storage class. Activate the infrequent access lifecycle policy.","B":"Set up an AWS Storage Gateway Amazon S3 File Gateway. Use an Amazon S3 Lifecycle policy to transition the data to the appropriate storage class.","A":"Set up an AWS Storage Gateway Volume Gateway. Use an Amazon S3 Lifecycle policy to transition the data to the appropriate storage class.","C":"Use the Amazon Elastic File System (Amazon EFS) Standard-Infrequent Access (Standard-IA) storage class. Activate the infrequent access lifecycle policy."},"url":"https://www.examtopics.com/discussions/amazon/view/135263-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A social media company has workloads that collect and process data. The workloads store the data in on-premises NFS storage. The data store cannot scale fast enough to meet the company’s expanding business needs. The company wants to migrate the current data store to AWS.\n\nWhich solution will meet these requirements MOST cost-effectively?","answers_community":["B (95%)","5%"],"topic":"1","unix_timestamp":1709675280,"answer_description":"","question_id":806,"discussion":[{"upvote_count":"9","comment_id":"1180410","poster":"alawada","content":"Selected Answer: B\nThis solution meets the requirements most cost-effectively because it enables the company to migrate its on-premises NFS data store to AWS without changing the existing applications or workflows. AWS Storage Gateway is a hybrid cloud storage service that provides seamless and secure integration between on-premises and AWS storage. Amazon S3 File Gateway is a type of AWS Storage Gateway that provides a file interface to Amazon S3, with local caching for low-latency access. By setting up an Amazon S3 File Gateway, the company can store and retrieve files as objects in Amazon S3 using standard file protocols such as NFS.","timestamp":"1711150260.0"},{"timestamp":"1738423500.0","content":"Selected Answer: B\nas their is nfs = file gateway","upvote_count":"1","comment_id":"1349951","poster":"Gorkha"},{"poster":"LeonSauveterre","content":"Selected Answer: B\nI'm a little confused by option C & D. How does infrequent access have anything to do with this?","comment_id":"1332158","timestamp":"1735260000.0","upvote_count":"1"},{"timestamp":"1729345800.0","upvote_count":"2","content":"Selected Answer: B\nS3 File Gateway => Best for NFS-like file storage workloads","comment_id":"1300030","poster":"mk168898"},{"timestamp":"1728446400.0","poster":"hharbiordun85","upvote_count":"1","comment_id":"1294958","content":"Answer: C"},{"comment_id":"1229413","upvote_count":"1","timestamp":"1718217300.0","comments":[{"comment_id":"1239000","upvote_count":"2","content":"It say migrating data into cloud, EFS does not satisfy that. You're right, It needs more information to make your choice to be a better answer.","timestamp":"1719631800.0","poster":"EdricHoang"}],"content":"Selected Answer: D\nAnswerD\n\nTaking into consideration that we are talking about social media company probably storing a lot of quite small files i would say it cannot be Option A or B. \nFor example\nAmazon S3 File Gateway pricing\nStorage Pricing \nStorage Pricing Stored and billed as Amazon S3 objects.\nRequest Pricing \nData written to AWS storage by your gateway $0.01 per GB†\nFile storage in S3 Billed as Amazon S3 requests.\nIt can be quite expensive, especially when we will be working on small files.\nI would go with EFS with OneZone-IA (option D) which should be less expensive taking into consideration that we are paying only for Storage and Data Transfer (per GB).\nBut to be honest we need more information to device which solution will be better.","poster":"Scheldon"},{"comment_id":"1180404","content":"Selected Answer: B\nyeah B","upvote_count":"2","timestamp":"1711149900.0","poster":"alawada"},{"comment_id":"1168677","timestamp":"1709889060.0","upvote_count":"3","content":"Selected Answer: B\nI think B too","poster":"seetpt"},{"poster":"asdfcdsxdfc","content":"Selected Answer: B\nB looks correct","upvote_count":"2","comment_id":"1166781","timestamp":"1709675280.0"}],"question_images":[],"isMC":true,"answer":"B"},{"id":"JnVDZo8guTk8NinWVakg","discussion":[{"timestamp":"1718706180.0","comment_id":"1232365","content":"Selected Answer: B\neserved concurrency — It guarantees the maximum number of concurrent instances for the function which can be invoked. When a function has being with a reserved concurrency configuration then no other lambda function within the same AWS account and region can use that concurrency. There is no charge for configuring reserved concurrency for a function.\nProvisioned concurrency — This concurrency initializes a requested number of execution environments so that they are prepared to respond immediately to your function’s invocations. Note that configuring provisioned concurrency incurs charges to your AWS account.","upvote_count":"8","poster":"JonJon03"},{"content":"Selected Answer: B\n• Reserved concurrency – This represents the maximum number of concurrent instances allocated to your function. When a function has reserved concurrency, no other function can use that concurrency. Reserved concurrency is useful for ensuring that your most critical functions always have enough concurrency to handle incoming requests. Configuring reserved concurrency for a function incurs no additional charges.","timestamp":"1741615980.0","comment_id":"1382233","upvote_count":"1","poster":"tch"},{"comment_id":"1349948","timestamp":"1738423320.0","upvote_count":"1","content":"Selected Answer: D\nfor reserved we don't know the incoming traffic as traffic is increasing so we choose provisioned and as it realted to cpu so compute optimizer.","poster":"Gorkha"},{"content":"Selected Answer: D\nI vote D instead of B because of constantly increasing number of messages and to maintain service latency for its customer although provisioned concurrency incurs the charges to your AWS account. If the reduce of comput costs is more important than service latency , B is correct.","poster":"FlyingHawk","timestamp":"1737678780.0","upvote_count":"1","comment_id":"1345731"},{"comment_id":"1335937","timestamp":"1735891680.0","poster":"Salilgen","content":"Selected Answer: D\nIMO answer is D.\nThe number of messages in message queue is constantly increasing: then, to maintain service latency you need to configure provisioned concurrency.\nFor cpu-intensive job you can optimize the duration increasing memory","upvote_count":"2"},{"comment_id":"1332159","content":"Selected Answer: B\nLet's think - Should we increase or decrease memory? Know that CPU resources scale proportionally with memory allocation in AWS Lambda, so increasing memory will help reduce the execution time for CPU-intensive tasks. Shorter execution times lower the overall compute cost. Then, A & C are out.\n\nAbout option D, it ensures performance and prevents cold starts, yes, but it also incurs additional costs to keep Lambda execution environments pre-warmed, even when not in use. Reserved concurrency is more cost-effective for sustained workloads.","upvote_count":"3","timestamp":"1735261500.0","poster":"LeonSauveterre"},{"comments":[{"content":"then should use reserved concurrency... as no additional charges....","poster":"tch","upvote_count":"1","timestamp":"1741752180.0","comment_id":"1387724"}],"upvote_count":"2","comment_id":"1328670","content":"Selected Answer: D\nReserved concurrency – This represents the maximum number of concurrent instances allocated to your function. When a function has reserved concurrency, no other function can use that concurrency. Reserved concurrency is useful for ensuring that your most critical functions always have enough concurrency to handle incoming requests. Configuring reserved concurrency for a function incurs no additional charges.\n\nProvisioned concurrency – This is the number of pre-initialized execution environments allocated to your function. These execution environments are ready to respond immediately to incoming function requests. Provisioned concurrency is useful for reducing cold start latencies for functions. Configuring provisioned concurrency incurs additional charges to your AWS account.","poster":"dragossky","timestamp":"1734549720.0"},{"content":"Selected Answer: D\nProvisioned concurrency:\nFor scenarios with predictable high traffic like marketing events, using provisioned concurrency ensures Lambda functions are always ready to process requests, maintaining low latency.\n\nIncrease memory based on Compute Optimizer recommendations:\nSince the Lambda functions are CPU intensive, increasing allocated memory based on AWS Compute Optimizer suggestions can often improve performance and reduce costs by allowing the functions to process more data without hitting CPU throttling.","poster":"JA2018","comment_id":"1320078","upvote_count":"1","timestamp":"1732946280.0"},{"content":"Selected Answer: B\nProvioned concurrency will increase cost and we need to maintain latency not to decrease latency. Also, provisioned concurrency cost is very related to memory, so if you use provisioned and increase memory this will affect the cost dramatically.","poster":"AMEJack","comment_id":"1316804","timestamp":"1732396740.0","upvote_count":"2"},{"upvote_count":"3","poster":"bujuman","timestamp":"1715866500.0","content":"Selected Answer: D\nAlso Lambda provisioned concurrency incure additionnal Account charges (https://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html), it's the best option because it is stated:\n- The company wants to reduce the compute costs and to maintain service latency for its customers.\nSo maintaining service latency while reducing compute cost is requested.\nThat being said, Lambda optimization is not a trivial task, that's why one should rely on AWS Compute Optimizer recommendations to analyze usage and find the best fit.\nPlease read following for more insights:\nhttps://aws.amazon.com/blogs/compute/optimizing-aws-lambda-cost-and-performance-using-aws-compute-optimizer/","comment_id":"1212430"},{"poster":"JackyCCK","timestamp":"1712157840.0","comment_id":"1188736","upvote_count":"2","content":"Increase the memory according to AWS Compute Optimizer recommendations --> so we can lower the duration of lambda function to reduce the cost.\nThe ans must be between B & D"},{"content":"Selected Answer: D\nProvisioned Concurrency keeps the Lambda functions initialized and ready to process incoming events, reducing the cold start latency associated with spinning up new execution environments.","upvote_count":"4","poster":"alawada","timestamp":"1711150620.0","comment_id":"1180415"},{"content":"Selected Answer: D\nD is correct","comment_id":"1170916","upvote_count":"3","timestamp":"1710149340.0","poster":"asdfcdsxdfc"},{"timestamp":"1710101460.0","poster":"osmk","upvote_count":"2","content":"Selected Answer: A\nWhen a large number of messages are in the SQS queue, Lambda scales out, adding additional functions to process the messages. The scale out can consume the concurrency quota in the account. To prevent this from happening, you can set reserved concurrency for individual Lambda functions. This ensures that the specified Lambda function can always scale to that much concurrency, but it also cannot exceed this number. https://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html","comment_id":"1170601"},{"timestamp":"1710101160.0","comment_id":"1170598","content":"When a large number of messages are in the SQS queue, Lambda scales out, adding additional functions to process the messages. The scale out can consume the concurrency quota in the account. To prevent this from happening, you can set reserved concurrency for individual Lambda functions. This ensures that the specified Lambda function can always scale to that much concurrency, but it also cannot exceed this number. https://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html","poster":"osmk","upvote_count":"1"},{"upvote_count":"3","poster":"Sivaeas","timestamp":"1710076500.0","comment_id":"1170336","content":"Selected Answer: D\nTo reduce compute costs and maintain service latency for customers while using AWS Lambda functions for processing CPU-intensive tasks, you can consider the following strategies:\n\nOptimize Lambda Function Configuration:\nAdjust the memory allocation for Lambda functions to better match the CPU requirements of your workload. Higher memory configurations provide more CPU power.\nTune the timeout settings to match the expected processing time of your workload. This prevents unnecessary over-provisioning and reduces costs.\nFine-tune the concurrency settings to control the number of concurrent executions based on your workload's characteristics.\nUse Provisioned Concurrency:\nAWS Lambda's provisioned concurrency feature allows you to preallocate a number of execution environments to handle incoming requests instantly. This can help reduce cold starts and maintain consistent performance, especially during peak events."},{"content":"Reserved concurrency its no charges reduce the computation cost, \"latency for its customer\" then I'll go for A","upvote_count":"1","comment_id":"1169238","comments":[{"comment_id":"1170469","content":"Reserved concurrency guarantees a minimum number of concurrent executions but doesn't inherently improve cold start times like provisioned concurrency.","upvote_count":"2","timestamp":"1710089280.0","poster":"lenotc"}],"timestamp":"1709954040.0","poster":"1dd"}],"answer_images":[],"topic":"1","isMC":true,"exam_id":31,"answer_ET":"D","answers_community":["D (56%)","B (39%)","6%"],"answer":"D","unix_timestamp":1709954040,"choices":{"C":"Configure provisioned concurrency for the Lambda functions. Decrease the memory allocated to the Lambda functions.","A":"Configure reserved concurrency for the Lambda functions. Decrease the memory allocated to the Lambda functions.","B":"Configure reserved concurrency for the Lambda functions. Increase the memory according to AWS Compute Optimizer recommendations.","D":"Configure provisioned concurrency for the Lambda functions. Increase the memory according to AWS Compute Optimizer recommendations."},"answer_description":"","question_images":[],"question_id":807,"question_text":"A company uses high concurrency AWS Lambda functions to process a constantly increasing number of messages in a message queue during marketing events. The Lambda functions use CPU intensive code to process the messages. The company wants to reduce the compute costs and to maintain service latency for its customers.\n\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/135552-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2024-03-09 04:14:00"},{"id":"41dPZt9ZTmK5DMAXL331","answer_ET":"A","timestamp":"2024-03-08 03:39:00","question_images":[],"question_id":808,"unix_timestamp":1709865540,"discussion":[{"comment_id":"1169239","timestamp":"1725844980.0","upvote_count":"9","content":"Selected Answer: A\nneed less workload changes and CVEs\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html","poster":"1dd"},{"timestamp":"1725755940.0","upvote_count":"6","comment_id":"1168515","poster":"xBUGx","content":"Selected Answer: A\nFEWEST changes to the workloads and scan CVE is enough. A looks OK."},{"poster":"zdi561","comment_id":"1355748","upvote_count":"1","content":"Selected Answer: D\nA is not right because ECR basic scan only scan OS. in B enhanced scan does scan app packages but it is required to run EKS. D is simpler.","timestamp":"1739389140.0"},{"comment_id":"1332166","timestamp":"1735263000.0","content":"Selected Answer: A\nAmazon ECR: Designed for storing container images, integrates seamlessly with Amazon ECS.\nScan on Push: Automatically scans images for vulnerabilities (CVEs) when they are uploaded. This is built-in functionality and requires minimal changes to existing workflows.\nFewest Changes: Existing ECS workloads can directly pull images from ECR without modification to the workloads themselves.\n\nB - Amazon Macie focuses on data discovery and classification (such as identifying sensitive data in S3 buckets), not container image vulnerabilities.\nC - Result-wise OK, but switching from ECS to EKS is unnecessary and involves a steep learning curve and operational overhead.\nD - Result-wise OK. Amazon Inspector can scan for vulnerabilities, but this is too complex and requires a custom setup, including using S3 and Lambda to trigger scans.","poster":"LeonSauveterre","upvote_count":"1"},{"upvote_count":"5","poster":"sandordini","content":"Selected Answer: A\nBasic scan looks for Common Vulnerabilities and Exposures (CVEs)","comment_id":"1203091","timestamp":"1730036100.0"}],"exam_id":31,"choices":{"A":"Use Amazon Elastic Container Registry (Amazon ECR) as a private image repository to store the container images. Specify scan on push filters for the ECR basic scan.","B":"Store the container images in an Amazon S3 bucket. Use Amazon Macie to scan the images. Use an S3 Event Notification to initiate a Macie scan for every event with an s3:ObjectCreated:Put event type.","C":"Deploy the workloads to Amazon Elastic Kubernetes Service (Amazon EKS). Use Amazon Elastic Container Registry (Amazon ECR) as a private image repository. Specify scan on push filters for the ECR enhanced scan.","D":"Store the container images in an Amazon S3 bucket that has versioning enabled. Configure an S3 Event Notification for s3:ObjectCreated:* events to invoke an AWS Lambda function. Configure the Lambda function to initiate an Amazon Inspector scan."},"answer_description":"","topic":"1","question_text":"A company runs its workloads on Amazon Elastic Container Service (Amazon ECS). The container images that the ECS task definition uses need to be scanned for Common Vulnerabilities and Exposures (CVEs). New container images that are created also need to be scanned.\n\nWhich solution will meet these requirements with the FEWEST changes to the workloads?","isMC":true,"answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/135473-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"answers_community":["A (95%)","5%"]},{"id":"pDNZrZAUB9YOO9eNWeIX","answer_ET":"A","answer_images":[],"answers_community":["A (64%)","B (27%)","9%"],"choices":{"C":"Configure an AWS Batch job to publish job SUCCEEDED events to an Amazon API Gateway REST API. Configure an HTTP proxy integration on the API Gateway REST API to invoke the third-party API by using a username and password.","D":"Configure an AWS Batch job to publish job SUCCEEDED events to an Amazon API Gateway REST API. Configure a proxy integration on the API Gateway REST API to an AWS Lambda function. Configure the Lambda function to invoke the third-party API by using a username and password.","B":"Configure Amazon EventBridge Scheduler to match incoming AWS Batch job SUCCEEDED events. Configure an AWS Lambda function to invoke the third-party API by using a username and password. Set the Lambda function as the EventBridge rule target.","A":"Configure an Amazon EventBridge rule to match incoming AWS Batch job SUCCEEDED events. Configure the third-party API as an EventBridge API destination with a username and password. Set the API destination as the EventBridge rule target."},"answer":"A","answer_description":"","question_images":[],"exam_id":31,"timestamp":"2024-03-10 21:41:00","discussion":[{"content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/compute/using-api-destinations-with-amazon-eventbridge/\nAmazon EventBridge enables developers to route events between AWS services, integrated software as a service (SaaS) applications, and your own applications. It can help decouple applications and produce more extensible, maintainable architectures. With the new API destinations feature, EventBridge can now integrate with services outside of AWS using REST API calls.","poster":"venutadi","comment_id":"1201587","comments":[{"comment_id":"1202385","content":"I agree.","upvote_count":"1","timestamp":"1714107060.0","poster":"shintaro0914"}],"upvote_count":"13","timestamp":"1713985260.0"},{"comment_id":"1203093","content":"I'm confused. Both A and B seem to be viable. There is no requirement of cost, complexity, or overhead. :S","upvote_count":"5","timestamp":"1714218240.0","poster":"sandordini"},{"timestamp":"1735264020.0","poster":"LeonSauveterre","comment_id":"1332167","content":"Selected Answer: A\nA - EventBridge API Destination is specifically designed to send events to HTTP APIs. It supports basic authentication (username and password), which fits the requirement for 3rd-party API authentication.\nB - OK, but EventBridge Scheduler is unnecessary because EventBridge rules can already match Batch job events. Introducing Lambda functions adds complexity and costs.\nC - An HTTP proxy integration on API Gateway cannot handle authentication directly. We still need to manage username and password authentication separately.\nD - OK, but even more complex than option B.","upvote_count":"2"},{"content":"Selected Answer: A\nAnswerA\n\nEventBridge Schedule will not work as it will allow us to \"do something\" per schedule. \nEventBridge rule will allow us to \"do something\" when event will occur.\nI think there is no possibility to publish/send job \"SUCCEEDED\" to AMAZON API Gateway REST API or that we can do anykind of integration with AMAZON API Gateway, hence I would choose A","comment_id":"1229463","poster":"Scheldon","upvote_count":"1","timestamp":"1718222340.0"},{"upvote_count":"1","comment_id":"1212707","content":"Selected Answer: A\nEven though option A and B could do the trick and also no statement related to least effort is rquested, EventBridge is dedicated for similar use case.\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-api-destinations.html\nPlus, it can also handle basic authentication\nhttps://aws.amazon.com/blogs/compute/using-api-destinations-with-amazon-eventbridge/","timestamp":"1715923380.0","poster":"bujuman"},{"timestamp":"1714713900.0","comment_id":"1205937","poster":"Sergiuss95","upvote_count":"3","comments":[{"timestamp":"1720259940.0","upvote_count":"1","comment_id":"1243305","content":"EventBridge also store credentials in Secret manager: https://aws.amazon.com/blogs/compute/using-api-destinations-with-amazon-eventbridge/","poster":"EdricHoang"}],"content":"Selected Answer: B\nI think is better to programming a lambda and obtain user and password from Secret Manager... So I think the better solution is B"},{"content":"Selected Answer: B\nAnswer should be B.","upvote_count":"1","comment_id":"1198850","timestamp":"1713564540.0","poster":"Oluwatosin09"},{"content":"Selected Answer: B\nConfigure Amazon EventBridge Scheduler to match incoming AWS Batch job SUCCEEDED events.\nConfigure an AWS Lambda function to invoke the third-party API using a username and password.\nSet the Lambda function as the EventBridge rule target.","timestamp":"1713054840.0","upvote_count":"2","comment_id":"1195171","poster":"boluwatito"},{"comment_id":"1188699","content":"Selected Answer: A\nA. Configure an Amazon EventBridge rule to match incoming AWS Batch job SUCCEEDED events. Configure the third-party API as an EventBridge API destination with a username and password. Set the API destination as the EventBridge rule target.\n\nThis option is the most direct and serverless approach to meeting the requirements. Amazon EventBridge can detect the successful completion of the AWS Batch job and trigger actions based on this event. By configuring the third-party API as an API destination with authentication credentials, EventBridge can directly invoke the third-party reporting application without the need for additional services. This approach minimizes complexity and operational overhead.","timestamp":"1712152380.0","upvote_count":"4","poster":"AlvinC2024"},{"comment_id":"1180446","poster":"alawada","timestamp":"1711154160.0","upvote_count":"3","content":"Selected Answer: D\nCreate an AWS Lambda function responsible for invoking the third-party reporting application's HTTP API endpoint. The Lambda function will be triggered by the successful completion of the AWS Batch job."},{"upvote_count":"3","timestamp":"1710823680.0","poster":"k_k_kkk","comment_id":"1176989","content":"Selected Answer: B\nAWS Batch sends job status change to EventBridge.\n\nhttps://docs.aws.amazon.com/batch/latest/userguide/batch_cwe_events.html"},{"timestamp":"1710103260.0","upvote_count":"1","comment_id":"1170608","content":"look like B","poster":"osmk"}],"question_text":"A company uses an AWS Batch job to run its end-of-day sales process. The company needs a serverless solution that will invoke a third-party reporting application when the AWS Batch job is successful. The reporting application has an HTTP API interface that uses username and password authentication.\n\nWhich solution will meet these requirements?","unix_timestamp":1710103260,"url":"https://www.examtopics.com/discussions/amazon/view/135695-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":809,"isMC":true,"topic":"1"},{"id":"DdLUzcDMxwMMneTmgb4w","answer_ET":"C","topic":"1","answer_description":"","question_images":[],"isMC":true,"timestamp":"2022-10-29 02:49:00","question_text":"A solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored.\nWhich design should the solutions architect use?","unix_timestamp":1667004540,"answer":"C","exam_id":31,"answers_community":["C (100%)"],"choices":{"A":"Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage.","D":"Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic.","B":"Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage.","C":"Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue."},"discussion":[{"comment_id":"743450","timestamp":"1670891760.0","content":"Selected Answer: C\ndecoupled = SQS\nLaunch template = AMI\nLaunch configuration = EC2","upvote_count":"54","poster":"Marge_Simpson"},{"comment_id":"929746","upvote_count":"9","timestamp":"1687366440.0","content":"Selected Answer: C\nThis design follows the best practices for loosely coupled and scalable architecture. By using SQS, the jobs are durably stored in the queue, ensuring they are not lost. The processor application is stateless, which aligns with the design requirement. The AMI allows for consistent deployment of the application. The launch template and ASG facilitate the dynamic scaling of the application based on the number of items in the SQS, ensuring parallel processing of jobs.\n\nOptions A and D suggest using SNS, which is a publish/subscribe messaging service and may not provide the durability required for job storage.\n\nOption B suggests using network usage as a scaling metric, which may not be directly related to the number of jobs to be processed. The number of items in the SQS provides a more accurate metric for scaling based on the workload.","poster":"cookieMr"},{"comment_id":"1284088","poster":"PaulGa","upvote_count":"2","content":"Selected Answer: C\nAns C - decoupled and durable (SQS), auto-scaling based on number of messages.","timestamp":"1726401660.0"},{"timestamp":"1717846380.0","content":"Selected Answer: C\nC for sure","upvote_count":"1","comment_id":"1226712","poster":"setout4saa"},{"comment_id":"1110022","content":"Selected Answer: C\nSNS is not reliable in case of processing failure which is why none of the SNS options are useful. SQS (not in FIFO mode) allows parallel message processing but reliability/durability of messages is guaranteed. AMI/EC2 scaling is good choice and scaling parameter should be number of messages. Hence \"C\" is the correct answer","poster":"awsgeek75","upvote_count":"3","timestamp":"1703971440.0"},{"poster":"pentium75","comment_id":"1105247","content":"Selected Answer: C\n\"Based on the number of jobs to be processed\" -> that alone rules out ABD because only C is based on queue length. (D is based on \"number of messages published to the queue\", not number of messages currently in queue.)\n\n\"Job items are durably stored\" also speaks for SQS over SNS.","timestamp":"1703505720.0","upvote_count":"3"},{"content":"so many words...","timestamp":"1703401380.0","upvote_count":"2","comment_id":"1104482","poster":"clumsyninja4life","comments":[{"poster":"awsgeek75","timestamp":"1705259160.0","upvote_count":"3","comment_id":"1122770","content":"... yet only one answer is correct"}]},{"poster":"slimen","upvote_count":"4","content":"Selected Answer: C\nfrom my perspective, I didn't go for D even though it provides decoupled architecture is because in the question they said \"parallel processing\"\nSNS sends the same message to all the subscribers, but in this case we don't want all the nodes to process the same message instead we want them to process as much jobs as possible in a parallel fashion.\nSQS in this case is more suitable because each job will get a message and process it and the next message will be taken by another job and so on..","timestamp":"1698817440.0","comment_id":"1059376"},{"content":"https://aws.amazon.com/about-aws/whats-new/2021/03/aws-certificate-manager-provides-certificate-expiry-monitoring-through-amazon-cloudwatch/","upvote_count":"3","comment_id":"997175","poster":"darekw","timestamp":"1693694760.0"},{"timestamp":"1692161100.0","poster":"TariqKipkemei","content":"Selected Answer: C\nLoosely coupled = Amazon SQS queue\nNew application being deployed = deploy on Amazon Machine Image\nAdding and removing application nodes as needed based on the number of jobs to be processed = Auto Scaling group with launch template","comment_id":"982186","upvote_count":"3"},{"comment_id":"978031","upvote_count":"3","timestamp":"1691696280.0","content":"Selected Answer: C\nThe recommended design is to use an SQS queue to store jobs (option C):\n\nSQS provides a durable and decoupled queue to store job items\nAn Auto Scaling group with scaling policies based on SQS queue length will add/remove nodes as needed\nLaunch templates provide flexibility to update AMIs\nThe key points:\n\nSQS enables loose coupling and stores jobs durably\nAuto Scaling provides parallel processing\nScaling based on queue length manages nodes effectively","poster":"Guru4Cloud"},{"comment_id":"902908","timestamp":"1684647540.0","poster":"Bmarodi","upvote_count":"1","content":"Selected Answer: C\nC for sure"},{"timestamp":"1671592680.0","upvote_count":"6","content":"Selected Answer: C\n***CORRECT***\nThe correct design is Option C. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.\n\nThis design satisfies the requirements of the application by using Amazon Simple Queue Service (SQS) as durable storage for the job items and Amazon Elastic Compute Cloud (EC2) Auto Scaling to add and remove nodes based on the number of items in the queue. The processor application can be run in parallel on multiple nodes, and the use of launch templates allows for flexibility in the configuration of the EC2 instances.","comment_id":"751830","comments":[{"poster":"Buruguduystunstugudunstuy","upvote_count":"7","comments":[{"timestamp":"1691217960.0","upvote_count":"1","comment_id":"972751","comments":[{"timestamp":"1699296600.0","upvote_count":"1","comment_id":"1064168","poster":"cyber_bedouin","content":"SQS satisfies the decoupling requirement"},{"comment_id":"1122772","content":"SNS is not a durable storage. SQS stores the messages until they are process. SNS just notifies the subscribers and doesn't care if the notification is processed or not. It's kind of \"fire and forget\"","poster":"awsgeek75","upvote_count":"1","timestamp":"1705259280.0"}],"content":"SNS provides durable storage of all messages that it receives.\nRef: https://aws.amazon.com/sns/faqs/#:~:text=SNS%20provides%20durable%20storage%20of%20all%20messages%20that%20it%20receives.\n\nWhy use SQS instead of SNS? In the question it says parallel execution of processes. SNS has that ability.","poster":"graveend"}],"timestamp":"1671592680.0","comment_id":"751831","content":"***WRONG***\nOption A is incorrect because it uses Amazon Simple Notification Service (SNS) instead of SQS, which is not a durable storage solution. \n\nOption B is incorrect because it uses CPU usage as the scaling trigger instead of the number of items in the queue. \n\nOption D is incorrect for the same reasons as option A."}],"poster":"Buruguduystunstugudunstuy"},{"comment_id":"747612","upvote_count":"1","timestamp":"1671227340.0","poster":"career360guru","content":"Selected Answer: C\nSQS with EC2 autoscaling policy based number of messages in the queue."},{"timestamp":"1670351640.0","content":"Selected Answer: C\nC is correct","poster":"Uhrien","upvote_count":"2","comment_id":"737125"},{"poster":"kelljons","upvote_count":"1","timestamp":"1670087520.0","content":"what about the word \"coupled\"","comment_id":"734583"},{"upvote_count":"3","poster":"kewl","content":"Selected Answer: C\nAWS strongly recommends that you do not use launch configurations hence answer is C\nhttps://docs.amazonaws.cn/en_us/autoscaling/ec2/userguide/launch-configurations.html","comment_id":"734470","timestamp":"1670073960.0"},{"comment_id":"730216","poster":"HussamShokr","upvote_count":"5","content":"Selected Answer: C\nanswer is C a there is nothing called \" Launch Configuration\" it's called \"Launch Template\" which is used by the autoscalling group to creat the new instances.","comments":[{"content":"There's launch configuration. Search","timestamp":"1673348400.0","poster":"lulzsec2019","comment_id":"771313","upvote_count":"3"}],"timestamp":"1669716600.0"},{"poster":"Liliwood","content":"I was not sure between Launch template and Launch configuration.","comment_id":"726278","upvote_count":"2","timestamp":"1669333560.0"},{"content":"C is correct","comment_id":"723733","poster":"Wpcorgan","timestamp":"1669047600.0","upvote_count":"1"},{"poster":"devopspro","content":"Selected Answer: C\nanswer is c","comment_id":"713863","upvote_count":"1","timestamp":"1667914260.0"},{"comment_id":"712149","upvote_count":"3","content":"https://www.examtopics.com/discussions/amazon/view/22139-exam-aws-certified-solutions-architect-associate-saa-c02/","poster":"Wilson_S","timestamp":"1667709900.0"},{"comment_id":"707001","content":"It looks like C","poster":"wookchan","upvote_count":"1","timestamp":"1667023440.0"},{"timestamp":"1667004540.0","upvote_count":"1","poster":"dokaedu","content":"Correct Answer: C","comment_id":"706848"}],"question_id":810,"url":"https://www.examtopics.com/discussions/amazon/view/86621-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[]}],"exam":{"name":"AWS Certified Solutions Architect - Associate SAA-C03","lastUpdated":"11 Apr 2025","id":31,"isImplemented":true,"provider":"Amazon","numberOfQuestions":1019,"isBeta":false,"isMCOnly":true},"currentPage":162},"__N_SSP":true}