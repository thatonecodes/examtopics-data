{"pageProps":{"questions":[{"id":"TB7STDKKOrqWQWacKu5Q","answer_images":[],"answer_description":"","timestamp":"2023-03-10 15:01:00","url":"https://www.examtopics.com/discussions/amazon/view/102144-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"question_id":331,"answer_ET":"B","unix_timestamp":1678456860,"isMC":true,"topic":"1","exam_id":31,"answers_community":["B (100%)"],"choices":{"C":"Cache the results of the queries in Amazon S3 for faster retrieval of similar datasets.","B":"Configure provisioned concurrency for the Lambda function that handles the requests.","A":"Establish a connection between the frontend application and the database to make queries faster by bypassing the API.","D":"Increase the size of the database to increase the number of connections Lambda can establish at one time."},"question_text":"A company hosts a frontend application that uses an Amazon API Gateway API backend that is integrated with AWS Lambda. When the API receives requests, the Lambda function loads many libraries. Then the Lambda function connects to an Amazon RDS database, processes the data, and returns the data to the frontend application. The company wants to ensure that response latency is as low as possible for all its users with the fewest number of changes to the company's operations.\n\nWhich solution will meet these requirements?","answer":"B","discussion":[{"timestamp":"1710252600.0","poster":"UnluckyDucky","content":"Selected Answer: B\nKey: the Lambda function loads many libraries\n\nConfiguring provisioned concurrency would get rid of the \"cold start\" of the function therefore speeding up the proccess.","comment_id":"837095","upvote_count":"17"},{"poster":"kampatra","timestamp":"1710513600.0","comment_id":"839983","content":"Selected Answer: B\nProvisioned concurrency â€“ Provisioned concurrency initializes a requested number of execution environments so that they are prepared to respond immediately to your function's invocations. Note that configuring provisioned concurrency incurs charges to your AWS account.","upvote_count":"11"},{"content":"Selected Answer: B\nProvisioned concurrency pre-initializes execution environments which are prepared to respond immediately to incoming function requests.","poster":"TariqKipkemei","timestamp":"1729225380.0","upvote_count":"7","comment_id":"1046541"},{"upvote_count":"4","comment_id":"996156","content":"Selected Answer: B\nProvisioned concurrency ensures a configured number of execution environments are ready to serve requests to the Lambda function. This avoids cold starts where the function would otherwise need to load all the libraries on each invocation.","poster":"Guru4Cloud","timestamp":"1725203400.0"},{"poster":"Guru4Cloud","content":"Selected Answer: B\nProvisioned concurrency ensures a configured number of execution environments are ready to serve requests to the Lambda function. This avoids cold starts where the function would otherwise need to load all the libraries on each invocation.","timestamp":"1725203220.0","comment_id":"996150","upvote_count":"2"},{"timestamp":"1711791060.0","content":"Selected Answer: B\nAnswer B is correct\nhttps://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html\nAnswer C: need to modify the application","comments":[{"timestamp":"1711791120.0","content":"This is relevant to \"cold start\" with keywords: \"Lambda function loads many libraries\"","comment_id":"855373","upvote_count":"2","poster":"elearningtakai"}],"comment_id":"855370","upvote_count":"5","poster":"elearningtakai"},{"comment_id":"836978","upvote_count":"4","timestamp":"1710245040.0","poster":"Karlos99","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html"}]},{"id":"5eOCPqJwYwo64VwvVJca","topic":"1","discussion":[{"upvote_count":"39","comment_id":"926675","content":"Selected Answer: C\nOption A (replicating the S3 bucket to all AWS Regions) can be costly and complex, requiring replication of data across multiple Regions and managing synchronization. It may not provide a significant latency improvement compared to the CloudFront solution.\n\nOption B (provisioning accelerators in AWS Global Accelerator) can be more expensive as it adds an extra layer of infrastructure (accelerators) and requires associating IP addresses with the S3 bucket. CloudFront already includes global edge locations and provides similar acceleration capabilities.\n\nOption D (enabling S3 Transfer Acceleration) can help improve upload speed to the S3 bucket but may not have a significant impact on reducing latency for website visitors.\n\nTherefore, option C is the most cost-effective solution as it leverages CloudFront's caching and global distribution capabilities to decrease latency and improve website performance.","poster":"cookieMr","timestamp":"1687090980.0"},{"timestamp":"1691120880.0","poster":"TariqKipkemei","comment_id":"971655","content":"Keywords:\nGlobal, Reduce latency, S3, Static Website, Cost effective = Amazon CloudFront","upvote_count":"5"},{"comment_id":"1339835","upvote_count":"2","timestamp":"1736757960.0","content":"Selected Answer: C\nCost effective solution + Static Website = Cloud Front + S3","poster":"AshishDhole"},{"poster":"satyaammm","timestamp":"1735638840.0","content":"Selected Answer: C\nCloudFront helps reduce latency most cost-effectively.","comment_id":"1334728","upvote_count":"1"},{"poster":"MGKYAING","comment_id":"1332292","content":"Selected Answer: C\nGlobal Content Delivery:\n\nCloudFront is a content delivery network (CDN) that caches content at edge locations around the world, reducing latency by serving content from the nearest edge location to the user.\nSeamless Integration:\n\nCloudFront integrates easily with S3 buckets. It fetches and caches the static content while reducing the load on the origin S3 bucket.\nCost-Effectiveness:\n\nCloudFront charges based on data transfer and requests, which is often more economical than replicating S3 buckets across Regions or using other solutions that require additional infrastructure.\nPerformance and Scalability:\n\nCloudFront handles spikes in traffic without additional configuration or cost overhead for provisioning and managing infrastructure.","timestamp":"1735285380.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"1280537","poster":"zied007","timestamp":"1725820560.0","content":"Selected Answer: C\nAnswer is C"},{"comment_id":"1216079","upvote_count":"2","timestamp":"1716421080.0","content":"Some of these questions seem too easy for SAA. These seem like Cloud Practitioner questions...","poster":"hb0011"},{"content":"Cloudfront is a lovely and affordable CDN for static content.","comment_id":"1176330","timestamp":"1710747180.0","poster":"TilTil","upvote_count":"2"},{"comment_id":"1122114","poster":"awsgeek75","upvote_count":"2","content":"Selected Answer: C\nS3 static website so CloudFront is the best CDN solution for low cost and low latency\n\nA: Very expensive way of doing this\nB: Makes no sense\nD: Transfer Acc is for upload boosting\nC: CloudFront literally solves this problem","timestamp":"1705187280.0"},{"timestamp":"1705149840.0","content":"Selected Answer: C\nAnswer-C","upvote_count":"1","comment_id":"1121655","poster":"A_jaa"},{"upvote_count":"2","comment_id":"1054728","content":"Option A (replicating the S3 bucket to all AWS Regions) can be costly and complex, requiring replication of data across multiple Regions and managing synchronization. It may not provide a significant latency improvement compared to the CloudFront solution.\n\nOption B (provisioning accelerators in AWS Global Accelerator) can be more expensive as it adds an extra layer of infrastructure (accelerators) and requires associating IP addresses with the S3 bucket. CloudFront already includes global edge locations and provides similar acceleration capabilities.\n\nOption D (enabling S3 Transfer Acceleration) can help improve upload speed to the S3 bucket but may not have a significant impact on reducing latency for website visitors.\n\nTherefore, option C is the most cost-effective solution as it leverages CloudFront's caching and global distribution capabilities to decrease latency and improve website performance.","poster":"Ruffyit","timestamp":"1698335700.0"},{"poster":"Guru4Cloud","upvote_count":"5","comment_id":"976020","timestamp":"1691525580.0","content":"Selected Answer: C\nAmazon CloudFront is a content delivery network (CDN) service that distributes content globally to reduce latency. By setting up a CloudFront distribution in front of the S3 bucket hosting the static website, you can take advantage of its edge locations around the world to deliver content from the nearest location to the users, reducing the latency they experience.\n\nCloudFront automatically caches and replicates content to its edge locations, resulting in faster delivery and lower latency for users worldwide. This solution is highly effective in optimizing performance while keeping costs under control because CloudFront charges are based on actual data transfer and requests, and the pay-as-you-go pricing model ensures that you only pay for what you use."},{"timestamp":"1689751260.0","comment_id":"956373","poster":"james2033","upvote_count":"1","content":"Selected Answer: C\nKeyword \"Amazon CloudFront\" (C)."},{"upvote_count":"1","comment_id":"953634","content":"Option C is the right answer for this.","timestamp":"1689539880.0","poster":"miki111"},{"poster":"TienHuynh","content":"Selected Answer: C\nkey words:\n-around the world\n-decrease latency\n-most cost-effective\n\nanswer is C","upvote_count":"2","timestamp":"1687537980.0","comment_id":"931778"},{"comment_id":"863645","timestamp":"1680854700.0","content":"Selected Answer: C\nC is the most cost effective.","poster":"cheese929","upvote_count":"1"},{"comment_id":"857108","timestamp":"1680268740.0","poster":"linux_admin","content":"Selected Answer: C\nAmazon CloudFront is a content delivery network (CDN) that caches content at edge locations around the world, providing low latency and high transfer speeds to users accessing the content. Adding a CloudFront distribution in front of the S3 bucket will cache the static website's content at edge locations around the world, decreasing latency for users accessing the website.\n\nThis solution is also cost-effective as it only charges for the data transfer and requests made by users accessing the content from the CloudFront edge locations. Additionally, this solution provides scalability and reliability benefits as CloudFront can automatically scale to handle increased demand and provide high availability for the website.","upvote_count":"2"},{"comment_id":"841587","content":"Selected Answer: C\nCloud front","poster":"test_devops_aws","upvote_count":"1","timestamp":"1679028600.0"},{"timestamp":"1678198680.0","content":"Selected Answer: C\nAmazon CloudFront is a content delivery network (CDN) that speeds up the delivery of static and dynamic web content, such as HTML, CSS, JavaScript, and images. It does this by placing cache servers in locations around the world, which store copies of the content and serve it to users from the location that is nearest to them.","upvote_count":"2","poster":"bilel500","comment_id":"831986"},{"timestamp":"1677087300.0","content":"My vote is: option B. Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3.\nThis question has 2 requirements:\n1. The company needs a scalable, near-real-time solution to share the details of millions of financial transactions with several other internal applications. \n2. Transactions also need to be processed to remove sensitive data before being stored in a document database for low-latency retrieval.","poster":"Bhawesh","comment_id":"818115","upvote_count":"1"},{"poster":"Ello2023","timestamp":"1675686960.0","content":"Selected Answer: C\nC. S3 accelerator is best for uploads to S3, whereas Cloudfront is for content delivery. S3 static website can be the origin which is distributed to Cloudfront and routed by Route 53.","upvote_count":"3","comment_id":"799717"},{"comment_id":"797316","poster":"AndyMartinez","timestamp":"1675453860.0","content":"Selected Answer: C\nOption C.","upvote_count":"1"},{"comment_id":"768130","poster":"SilentMilli","upvote_count":"3","timestamp":"1673045580.0","content":"Selected Answer: C\nOption C. Adding an Amazon CloudFront distribution in front of the S3 bucket and editing the Route 53 entries to point to the CloudFront distribution would meet the requirements most cost-effectively. CloudFront is a content delivery network (CDN) that speeds up the delivery of static and dynamic web content by distributing it across a global network of edge locations. When a user accesses the website, CloudFront will automatically route the request to the edge location that provides the lowest latency, reducing the time it takes for the content to be delivered to the user. This solution also allows for easy integration with S3 and Route 53, and provides additional benefits such as DDoS protection and support for custom SSL certificates."},{"comment_id":"751316","upvote_count":"2","poster":"pazabal","timestamp":"1671559500.0","content":"Selected Answer: C\ndecrease latency and most cost-effective = cloudfront in front of S3 bucket (content can be served closer to the user, reducing latency). Replicating S3 bucket and Global accelerator would also decrease latency but would be less cost-effective. Transfer accelerator wouldn't decrease latency since it's not for delivering content, but for transfering it"},{"poster":"Buruguduystunstugudunstuy","upvote_count":"3","content":"Selected Answer: C\nThe correct answer is C: Add an Amazon CloudFront distribution in front of the S3 bucket. Edit the Route 53 entries to point to the CloudFront distribution.\n\nAmazon CloudFront is a content delivery network (CDN) that speeds up the delivery of static and dynamic web content, such as HTML, CSS, JavaScript, and images. It does this by placing cache servers in locations around the world, which store copies of the content and serve it to users from the location that is nearest to them.\n\nTo decrease latency for users who access the static website hosted on Amazon S3, you can add an Amazon CloudFront distribution in front of the S3 bucket and edit the Route 53 entries to point to the CloudFront distribution. This will allow CloudFront to cache the content of the website at locations around the world, which will reduce the time it takes for users to access the website by serving it from the location that is nearest to them.","comments":[{"upvote_count":"5","comment_id":"750445","content":"Answer A, (WRONG) - Replicating the S3 bucket that contains the website to all AWS Regions and adding Route 53 geolocation routing entries would be more expensive than using CloudFront, as it would require you to pay for the additional storage and data transfer costs associated with replicating the bucket to multiple Regions.\n\nAnswer B, (WRONG) - Provisioning accelerators in AWS Global Accelerator and associating the supplied IP addresses with the S3 bucket would also be more expensive than using CloudFront, as it would require you to pay for the additional cost of the accelerators.\n\nAnswer D, (WRONG) - Enabling S3 Transfer Acceleration on the bucket and editing the Route 53 entries to point to the new endpoint would not reduce latency for users who access the website from around the world, as it only speeds up the transfer of large files over the public internet and does not have cache servers in multiple locations around the world.","poster":"Buruguduystunstugudunstuy","timestamp":"1671506940.0"}],"comment_id":"750444","timestamp":"1671506880.0"},{"content":"Selected Answer: C\nOption C - Cloudfront is the right answer.","timestamp":"1671433260.0","upvote_count":"1","poster":"career360guru","comment_id":"749567"},{"poster":"k1kavi1","upvote_count":"1","timestamp":"1671010320.0","content":"Selected Answer: C\nCloudFront","comment_id":"744933"},{"timestamp":"1669858200.0","content":"Isn't Transfer Acceleration the same thing? I mean, what's the difference between C and D?","upvote_count":"1","poster":"DasCert","comment_id":"732146","comments":[{"poster":"DasCert","upvote_count":"8","content":"ok, I got the answer to this:\nIn short, Transfer Acceleration is for Writes and CloudFront is for Reads.","timestamp":"1669858260.0","comment_id":"732148"}]},{"poster":"Wpcorgan","timestamp":"1669036080.0","upvote_count":"1","comment_id":"723522","content":"C is correct"},{"timestamp":"1668610500.0","comment_id":"719761","content":"Selected Answer: C\nok CloudFront","upvote_count":"1","poster":"17Master"},{"comment_id":"719127","poster":"xeun88","upvote_count":"1","timestamp":"1668546180.0","content":"C is right"},{"upvote_count":"1","timestamp":"1667819280.0","content":"Selected Answer: C\nANSWER C","comment_id":"712993","poster":"Mordans"},{"poster":"ninjawrz","content":"Selected Answer: C\nC: Cloudfront","upvote_count":"2","timestamp":"1665801000.0","comment_id":"695136"},{"content":"Selected Answer: C\nof course cloudfront it's the answer","timestamp":"1665559140.0","poster":"masetromain","upvote_count":"3","comment_id":"692801"}],"timestamp":"2022-10-12 09:19:00","unix_timestamp":1665559140,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/85238-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":332,"answer":"C","answer_ET":"C","exam_id":31,"question_text":"A company is hosting a static website on Amazon S3 and is using Amazon Route 53 for DNS. The website is experiencing increased demand from around the world. The company must decrease latency for users who access the website.\nWhich solution meets these requirements MOST cost-effectively?","choices":{"B":"Provision accelerators in AWS Global Accelerator. Associate the supplied IP addresses with the S3 bucket. Edit the Route 53 entries to point to the IP addresses of the accelerators.","A":"Replicate the S3 bucket that contains the website to all AWS Regions. Add Route 53 geolocation routing entries.","C":"Add an Amazon CloudFront distribution in front of the S3 bucket. Edit the Route 53 entries to point to the CloudFront distribution.","D":"Enable S3 Transfer Acceleration on the bucket. Edit the Route 53 entries to point to the new endpoint."},"question_images":[],"isMC":true,"answers_community":["C (100%)"],"answer_images":[]},{"id":"NbPdKMVLmCOcYXpBeau5","answer_description":"","answer_images":[],"timestamp":"2023-03-10 15:03:00","url":"https://www.examtopics.com/discussions/amazon/view/102145-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"question_id":333,"unix_timestamp":1678456980,"answer_ET":"D","topic":"1","isMC":true,"exam_id":31,"answers_community":["D (100%)"],"choices":{"A":"Scale the EC2 instances by using elastic resize. Scale the DB instances to zero outside of business hours.","B":"Explore AWS Marketplace for partner solutions that will automatically start and stop the EC2 instances and DB instances on a schedule.","C":"Launch another EC2 instance. Configure a crontab schedule to run shell scripts that will start and stop the existing EC2 instances and DB instances on a schedule.","D":"Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule."},"question_text":"A company is migrating its on-premises workload to the AWS Cloud. The company already uses several Amazon EC2 instances and Amazon RDS DB instances. The company wants a solution that automatically starts and stops the EC2 instances and DB instances outside of business hours. The solution must minimize cost and infrastructure maintenance.\n\nWhich solution will meet these requirements?","answer":"D","discussion":[{"content":"Selected Answer: D\nThe most efficient solution for automatically starting and stopping EC2 instances and DB instances on a schedule while minimizing cost and infrastructure maintenance is to create an AWS Lambda function and configure Amazon EventBridge to invoke the function on a schedule.\n\nOption A, scaling EC2 instances by using elastic resize and scaling DB instances to zero outside of business hours, is not feasible as DB instances cannot be scaled to zero.\n\nOption B, exploring AWS Marketplace for partner solutions, may be an option, but it may not be the most efficient solution and could potentially add additional costs.\n\nOption C, launching another EC2 instance and configuring a crontab schedule to run shell scripts that will start and stop the existing EC2 instances and DB instances on a schedule, adds unnecessary infrastructure and maintenance.","upvote_count":"17","timestamp":"1678526880.0","poster":"ktulu2602","comment_id":"835793"},{"poster":"Guru4Cloud","comment_id":"996145","upvote_count":"6","timestamp":"1693580040.0","content":"Selected Answer: D\nThis option leverages AWS Lambda and EventBridge to automatically schedule the starting and stopping of resources.\n\nLambda provides the script/code to stop/start instances without managing servers.\nEventBridge triggers the Lambda on a schedule without cronjobs.\nNo additional code or third party tools needed.\nServerless, maintenance-free solution"},{"content":"Selected Answer: D\nits d but nowadays u use system manager me thinks","upvote_count":"3","comment_id":"1260717","timestamp":"1722786360.0","poster":"1e22522"},{"content":"Selected Answer: D\nCreate an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule.","timestamp":"1697603100.0","upvote_count":"4","comment_id":"1046545","poster":"TariqKipkemei"},{"poster":"WherecanIstart","upvote_count":"3","comment_id":"844482","timestamp":"1679282880.0","content":"Selected Answer: D\nMinimize cost and maintenance..."},{"upvote_count":"1","timestamp":"1678992540.0","poster":"[Removed]","content":"Selected Answer: D\nDDDDDDDDDDD","comment_id":"841273"}]},{"id":"t9rWQ3h4TiRXXI4uRku1","question_text":"A company hosts a three-tier web application that includes a PostgreSQL database. The database stores the metadata from documents. The company searches the metadata for key terms to retrieve documents that the company reviews in a report each month. The documents are stored in Amazon S3. The documents are usually written only once, but they are updated frequently.\n\nThe reporting process takes a few hours with the use of relational queries. The reporting process must not prevent any document modifications or the addition of new documents. A solutions architect needs to implement a solution to speed up the reporting process.\n\nWhich solution will meet these requirements with the LEAST amount of change to the application code?","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/102147-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","exam_id":31,"unix_timestamp":1678457340,"answers_community":["B (96%)","2%"],"isMC":true,"discussion":[{"upvote_count":"12","comment_id":"1011483","poster":"Guru4Cloud","timestamp":"1695137640.0","content":"Selected Answer: B\nThe key reasons are:\n\nAurora PostgreSQL provides native PostgreSQL compatibility, so minimal code changes would be required.\nUsing an Aurora Replica separates the reporting workload from the main workload, preventing any slowdown of document updates/inserts.\nAurora can auto-scale read replicas to handle the reporting load.\nThis allows leveraging the existing PostgreSQL database without major changes. DynamoDB would require more significant rewrite of data access code.\nRDS Multi-AZ alone would not fully separate the workloads, as the secondary is for HA/failover more than scaling read workloads."},{"comments":[{"timestamp":"1707318660.0","upvote_count":"4","poster":"BillaRanga","comment_id":"1143448","content":"No Modifications allowerd = Read Replica"}],"timestamp":"1684471380.0","upvote_count":"8","comment_id":"901642","poster":"TariqKipkemei","content":"Selected Answer: B\nLoad balancing = Read replica \nHigh availability = Multi AZ"},{"poster":"terminator69","content":"How in the bloody hell it's D?????","timestamp":"1723890600.0","upvote_count":"1","comment_id":"1267622"},{"timestamp":"1711420140.0","content":"B is correct","upvote_count":"2","comment_id":"1182933","poster":"TruthWS"},{"upvote_count":"5","timestamp":"1711376400.0","poster":"ExamGuru727","comment_id":"1182558","content":"Selected Answer: B\nWe also have a requirement for the Least amount of change to the code.\nSince our DB is PostgreSQL, A & D are immediately out.\nMulti-AZ won't help with offloading read requests, hence the answer is B ;)"},{"content":"It is B","comment_id":"1155350","poster":"Buck12345","upvote_count":"2","timestamp":"1708502100.0"},{"upvote_count":"1","poster":"Cyberkayu","timestamp":"1702858740.0","comments":[{"poster":"pentium75","comment_id":"1110287","content":"How would 'issuing queries to the read replica' prevent modifications or updates?","timestamp":"1704001980.0","upvote_count":"2"}],"comment_id":"1099343","content":"Selected Answer: C\nD. Reporting process Must not prevent = allow modification and addition of new document. \n\nall read replica were wrong."},{"comment_id":"906412","timestamp":"1684993500.0","content":"Selected Answer: A\nWhy not A? :(","poster":"KMohsoe","upvote_count":"1","comments":[{"upvote_count":"4","poster":"wRhlH","timestamp":"1687413720.0","comment_id":"930191","comments":[{"content":"DocumentDB (For MongoDB) is no SQL. DynamoDB is also No SQL. Therefore, options A and D are out.","timestamp":"1701947880.0","upvote_count":"5","poster":"Murtadhaceit","comment_id":"1090205"}],"content":"\"The reporting process takes a few hours with the use of RELATIONAL queries.\""}]},{"upvote_count":"4","content":"Selected Answer: B\nB is the right one. why admin does not correct these wrong answers?","timestamp":"1682257440.0","poster":"lexotan","comment_id":"878415"},{"upvote_count":"5","timestamp":"1681727340.0","content":"Selected Answer: B\nThe reporting process queries the metadata (not the documents) and use relational queries-> A, D out \nC: wrong since secondary RDS node in MultiAZ setup is in standby mode, not available for querying \nB: reporting using a Replica is a design pattern. Using Aurora is an exam pattern.","comment_id":"872600","poster":"imvb88"},{"poster":"WherecanIstart","content":"Selected Answer: B\nB is right..","upvote_count":"2","comment_id":"844491","timestamp":"1679283120.0"},{"poster":"Maximus007","content":"Selected Answer: B\nWhile both B&D seems to be a relevant, ChatGPT suggest B as a correct one","comment_id":"840758","timestamp":"1678959060.0","upvote_count":"2"},{"timestamp":"1678722900.0","poster":"cegama543","upvote_count":"3","content":"Selected Answer: B\nOption B (Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports) is the best option for speeding up the reporting process for a three-tier web application that includes a PostgreSQL database storing metadata from documents, while not impacting document modifications or additions, with the least amount of change to the application code.","comment_id":"838041"},{"poster":"UnluckyDucky","content":"Selected Answer: B\n\"LEAST amount of change to the application code\"\n\nAurora is a relational database, it supports PostgreSQL and with the help of read replicas we can issue the reporting proccess that take several hours to the replica, therefore not affecting the primary node which can handle new writes or document modifications.","timestamp":"1678630680.0","upvote_count":"2","comment_id":"837102"},{"comments":[{"poster":"Murtadhaceit","upvote_count":"2","timestamp":"1701947940.0","comment_id":"1090207","content":"DynamoDB is no SQL. A and D are out!"}],"timestamp":"1678586700.0","upvote_count":"2","comment_id":"836671","poster":"Ashukaushal619","content":"its D only ,recorrected"},{"poster":"Ashukaushal619","comment_id":"836670","upvote_count":"2","content":"Selected Answer: B\nbbbbbbbb","timestamp":"1678586040.0"}],"timestamp":"2023-03-10 15:09:00","answer_images":[],"answer_ET":"B","question_id":334,"choices":{"D":"Set up a new Amazon DynamoDB table to store the documents. Use a fixed write capacity to support new document entries. Automatically scale the read capacity to support the reports.","C":"Set up a new Amazon RDS for PostgreSQL Multi-AZ DB instance. Configure the reporting module to query the secondary RDS node so that the reporting module does not affect the primary node.","B":"Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports.","A":"Set up a new Amazon DocumentDB (with MongoDB compatibility) cluster that includes a read replica. Scale the read replica to generate the reports."},"answer":"B","question_images":[]},{"id":"x5AtXg0SY0n9ue8AgaU5","question_text":"A company has a three-tier application on AWS that ingests sensor data from its usersâ€™ devices. The traffic flows through a Network Load Balancer (NLB), then to Amazon EC2 instances for the web tier, and finally to EC2 instances for the application tier. The application tier makes calls to a database.\n\nWhat should a solutions architect do to improve the security of the data in transit?","topic":"1","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/102149-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"unix_timestamp":1678457520,"answers_community":["A (100%)"],"isMC":true,"discussion":[{"content":"Selected Answer: A\nNetwork Load Balancers now support TLS protocol. With this launch, you can now offload resource intensive decryption/encryption from your application servers to a high throughput, and low latency Network Load Balancer. Network Load Balancer is now able to terminate TLS traffic and set up connections with your targets either over TCP or TLS protocol.\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/create-tls-listener.html\n\nhttps://exampleloadbalancer.com/nlbtls_demo.html","timestamp":"1710211920.0","poster":"fruto123","comment_id":"836682","upvote_count":"22"},{"poster":"imvb88","content":"Selected Answer: A\nsecurity of data in transit -> think of SSL/TLS. Check: NLB supports TLS\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/create-tls-listener.html\n\nB (DDoS), C (SQL Injection), D (EBS) is for data at rest.","upvote_count":"17","comment_id":"872603","timestamp":"1713350160.0"},{"content":"Selected Answer: A\nsecure data in transit = TLS","comment_id":"1047485","upvote_count":"2","timestamp":"1729308720.0","poster":"TariqKipkemei"},{"poster":"Guru4Cloud","upvote_count":"6","comment_id":"996142","content":"Selected Answer: A\nTLS provides encryption for data in motion over the network, protecting against eavesdropping and tampering. A valid server certificate signed by a trusted CA will provide further security.","timestamp":"1725201900.0"},{"poster":"klayytech","comment_id":"858247","content":"Selected Answer: A\nTo improve the security of data in transit, you can configure a TLS listener on the Network Load Balancer (NLB) and deploy the server certificate on it. This will encrypt traffic between clients and the NLB. You can also use AWS Certificate Manager (ACM) to provision, manage, and deploy SSL/TLS certificates for use with AWS services and your internal connected resources1.\n\nYou can also change the load balancer to an Application Load Balancer (ALB) and enable AWS WAF on it. AWS WAF is a web application firewall that helps protect your web applications from common web exploits that could affect application availability, compromise security, or consume excessive resources3.\n\nthe A and C correct without transit but the need to improve the security of the data in transit? so he need SSL/TLS certificates","upvote_count":"3","timestamp":"1712001180.0"},{"poster":"Maximus007","comment_id":"840759","timestamp":"1710581700.0","upvote_count":"4","content":"Selected Answer: A\nagree with fruto123"}],"timestamp":"2023-03-10 15:12:00","answer_images":[],"answer_ET":"A","question_id":335,"choices":{"C":"Change the load balancer to an Application Load Balancer (ALB). Enable AWS WAF on the ALB.","A":"Configure a TLS listener. Deploy the server certificate on the NLB.","B":"Configure AWS Shield Advanced. Enable AWS WAF on the NLB.","D":"Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances by using AWS Key Management Service (AWS KMS)."},"answer":"A","question_images":[]}],"exam":{"lastUpdated":"11 Apr 2025","id":31,"isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","provider":"Amazon","isBeta":false,"numberOfQuestions":1019,"isImplemented":true},"currentPage":67},"__N_SSP":true}