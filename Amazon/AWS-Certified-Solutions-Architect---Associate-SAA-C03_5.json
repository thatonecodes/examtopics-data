{"pageProps":{"questions":[{"id":"HhZEqheTmdYqelJWixo3","exam_id":31,"question_images":[],"answer":"B","unix_timestamp":1728313740,"answer_ET":"B","isMC":true,"choices":{"C":"Configure an S3 bucket policy to allow traffic from the Elastic IP address that is assigned to the NAT gateway.","D":"Create a second NAT gateway in the same subnet where the legacy application is deployed. Update the VPC route table to use the second NAT gateway.","B":"Configure an S3 gateway endpoint. Update the VPC route table to use the endpoint.","A":"Configure an S3 interface endpoint. Create a security group that allows outbound traffic to Amazon S3."},"timestamp":"2024-10-07 17:09:00","question_id":21,"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/148824-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"comment_id":"1301072","content":"Selected Answer: B\nS3 gateway endpoint\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html","timestamp":"1729523640.0","poster":"sOI852POL","upvote_count":"5"},{"timestamp":"1735408860.0","upvote_count":"2","comment_id":"1333098","poster":"GOTJ","content":"Selected Answer: B\nHere's another document that support option \"B\" as the most cost-effectively:\n\nhttps://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/"},{"content":"Selected Answer: B\nKeyword: ec2 connect s3 -> vpc endpoint or s3 endpoint","comment_id":"1320567","upvote_count":"3","poster":"trinh_le","timestamp":"1733060040.0"},{"timestamp":"1729290900.0","upvote_count":"2","poster":"aragon_saa","comment_id":"1299818","content":"Selected Answer: B\nAnswer is B"}],"question_text":"A company runs an application in a private subnet behind an Application Load Balancer (ALB) in a VPC. The VPC has a NAT gateway and an internet gateway. The application calls the Amazon S3 API to store objects.\n\nAccording to the company's security policy, traffic from the application must not travel across the internet.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_images":[],"topic":"1","answer_description":""},{"id":"K8qsBcXmiHBAfPDxTu90","question_text":"A company has an application that runs on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster on Amazon EC2 instances. The application has a UI that uses Amazon DynamoDB and data services that use Amazon S3 as part of the application deployment.\n\nThe company must ensure that the EKS Pods for the UI can access only Amazon DynamoDB and that the EKS Pods for the data services can access only Amazon S3. The company uses AWS Identity and Access Management (IAM).\n\nWhich solution meals these requirements?","question_images":[],"exam_id":31,"timestamp":"2024-10-07 17:12:00","topic":"1","answer_images":[],"discussion":[{"timestamp":"1729249980.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/eks/latest/userguide/service-accounts.html#service-accounts-iam","upvote_count":"8","poster":"jingen11","comment_id":"1299633"},{"content":"Selected Answer: C\nIRSA allows Kubernetes service accounts to assume IAM roles, enabling fine-grained access control for EKS Pods. This ensures that each Pod can access only the AWS resources it needs. \nAttach the AmazonDynamoDBFullAccess policy to the service account for the UI Pods, allowing them to access only DynamoDB.\nAttach the AmazonS3FullAccess policy to the service account for the data services Pods, allowing them to access only S3.","comment_id":"1342915","upvote_count":"2","poster":"FlyingHawk","timestamp":"1737273060.0"},{"content":"Selected Answer: C\nA - This is a major security flaw. All Pods running on the EC2 instances would inherit both the S3 and DynamoDB permissions.\nB - Directly attaching IAM policies to Pods is not a valid AWS mechanism. You should use roles.\nC - Not recommended unless we throw least privilege principles to the wind. BUT this is the only feasible option here, so.\nD - This option mixes up the permissions. It gives UI Pods access to S3 and data service Pods access to DynamoDB, which is the OPPOSITE of the requirement.","timestamp":"1736578260.0","upvote_count":"4","comment_id":"1339077","poster":"LeonSauveterre"},{"poster":"BugsyWarribwoy","timestamp":"1736385960.0","comment_id":"1338155","upvote_count":"4","content":"Selected Answer: C\nD is sneakily WRONG because it swaps the services incorrectly. Pay attention. UWC."},{"upvote_count":"3","comment_id":"1333067","poster":"GOTJ","content":"Selected Answer: C\nEven though there are a couple of comments rightfully discarding \"D\" because the UI --> S3/DataServices --> DynamoDB swap, I found an AWS document claiming that Kubernetes Service accounts and IAM Role for Service Accounts combination should be the right answer:\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\n\nHaving this in mind, I'm also discarding \"D\" (right reasoning, wrong scenario), as well \"A\" and \"B\". I didn't like the \"full access\" policy, but is technically correct, so my vote goes to \"C\"","timestamp":"1735407060.0"},{"upvote_count":"3","comment_id":"1320585","poster":"trinh_le","content":"Selected Answer: C\n* A. Attach both IAM policies to the EC2 instance profile. Does not separate each EKS Pod\n* B. Aws does not support Attach the Amazon S3 IAM policy directly to the EKS Pods\n* \n* D. provide access â€œUI to Amazon S3â€ and â€œdata services to DynamoDBâ€ => it does not meet requirements","timestamp":"1733061960.0"},{"poster":"rosanna","content":"Selected Answer: C\nThe answer is C as they're switching data pods with DynamoDB service and vice versa (configure the wrong resources)","comment_id":"1320340","upvote_count":"2","timestamp":"1732991280.0"},{"content":"answer is D","upvote_count":"1","comment_id":"1302005","timestamp":"1729681260.0","poster":"tm1000000"}],"answer_ET":"C","answer":"C","answer_description":"","isMC":true,"answers_community":["C (69%)","D (31%)"],"choices":{"B":"Create separate IAM policies for Amazon S3 and DynamoDB access with the required permissions. Attach the Amazon S3 IAM policy directly to the EKS Pods for the data services and the DynamoDB policy to the EKS Pods for the UI.","C":"Create separate Kubernetes service accounts for the UI and data services to assume an IAM role. Attach the AmazonS3FullAccess policy to the data services account and the AmazonDynamoDBFullAccess policy to the UI service account.","A":"Create separate IAM policies for Amazon S3 and DynamoDB access with the required permissions. Attach both IAM policies to the EC2 instance profile. Use role-based access control (RBAC) to control access to Amazon S3 or DynamoDB for the respective EKS Pods.","D":"Create separate Kubernetes service accounts for the UI and data services to assume an IAM role. Use IAM Role for Service Accounts (IRSA) to provide access to the EKS Pods for the UI to Amazon S3 and the EKS Pods for the data services to DynamoDB."},"url":"https://www.examtopics.com/discussions/amazon/view/148825-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1728313920,"question_id":22},{"id":"Ck7UggF9i9Vtn176IRwQ","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/148826-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["C (79%)","A (21%)"],"unix_timestamp":1728314400,"answer_description":"","exam_id":31,"topic":"1","choices":{"B":"Create an IAM user for each developer. Manually manage permissions for each IAM user based on each user's involvement with each project. Enforce multi-factor authentication (MFA) as an additional layer of security.","A":"Set up AWS Directory Service to create an AWS managed Microsoft Active Directory on AWS. Establish a trust relationship with the on-premises Active Directory. Use IAM rotes that are assigned to Active Directory groups to access AWS resources within the company's AWS accounts.","C":"Use AD Connector in AWS Directory Service to connect to the on-premises Active Directory. Integrate AD Connector with AWS IAM Identity Center. Configure permissions sets to give each AD group access to specific AWS accounts and resources.","D":"Use Amazon Cognito to deploy an identity federation solution. Integrate the identity federation solution with the on-premises Active Directory. Use Amazon Cognito to provide access tokens for developers to access AWS accounts and resources."},"answer_images":[],"answer_ET":"C","timestamp":"2024-10-07 17:20:00","question_id":23,"question_text":"A company needs to give a globally distributed development team secure access to the company's AWS resources in a way that complies with security policies.\n\nThe company currently uses an on-premises Active Directory for internal authentication. The company uses AWS Organizations to manage multiple AWS accounts that support multiple projects.\n\nThe company needs a solution to integrate with the existing infrastructure to provide centralized identity management and access control.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","answer":"C","discussion":[{"comment_id":"1339078","content":"Selected Answer: C\nA - On-premises Active Directory already exists.\nB - \"Manually\" ? Oh hell no. But MFA is something I guess.\nC - AD Connector seamlessly connects AWS to the on-premises Active Directory without the need to synchronize or replicate the directory. Identity Center (formerly AWS SSO) allows centralized access management across AWS accounts in an AWS Organizations setup. Permissions sets can be configured to map Active Directory groups to specific AWS accounts and resources, making access control easy and secure.\nD - Amazon Cognito is better suited for application-level identity management (like customer-facing apps), not for internal teams working across multiple AWS accounts.","timestamp":"1736578740.0","upvote_count":"3","poster":"LeonSauveterre"},{"content":"Selected Answer: A\nWhy not \"A\"? Check out the note of this link: https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_ad_connector.html\n\nAD Connector cannot be shared with other AWS accounts. If this is a requirement, consider using AWS Managed Microsoft AD to Share your AWS Managed Microsoft AD. AD Connector is also not multi-VPC aware, which means that AWS applications like WorkSpaces are required to be provisioned into the same VPC as your AD Connector.\n\nAnd I think managing multiple aws accounts is, indeed, a requirement","poster":"GOTJ","comments":[{"comments":[{"upvote_count":"1","poster":"GOTJ","timestamp":"1738569480.0","content":"I guess so, but... is the alternative configure one AD connector per account more operational friendly?","comment_id":"1350786"}],"upvote_count":"1","poster":"FlyingHawk","timestamp":"1737274440.0","content":"While this option provides centralized identity management, it requires setting up a separate AWS managed Microsoft AD, which increases operational overhead. A trust relationship is also more complex to configure than AD Connector.","comment_id":"1342921"}],"timestamp":"1735225860.0","upvote_count":"3","comment_id":"1331965"},{"content":"Selected Answer: C\nC: AD Connector allows AWS to use the on-premises Active Directory for authentication without replicating directory data to AWS.\n â€¢ Maintains centralized identity management in the on-premises directory, adhering to the companyâ€™s security policies.\nA: Higher Overhead: Requires creating and maintaining a separate managed Active Directory instance in AWS.\nB: Scalability Issues: Manually creating and managing IAM users for a globally distributed team is cumbersome.\nD: Unnecessary Federation Layer: Cognito is more suited for customer identity use cases rather than managing internal developer access to AWS resources.","comment_id":"1320590","upvote_count":"2","timestamp":"1733062860.0","poster":"trinh_le"},{"content":"Selected Answer: C\nOnce set up, it requires minimal ongoing management. User provisioning and deprovisioning are handled through the existing Active Directory.processes.","upvote_count":"2","poster":"78b9037","timestamp":"1732609080.0","comment_id":"1317972"},{"content":"Selected Answer: C\nanswer C","upvote_count":"2","comment_id":"1298598","poster":"xekiva3329","timestamp":"1729064040.0"},{"content":"Selected Answer: C\nAnswer is C","comment_id":"1294966","poster":"aragon_saa","timestamp":"1728450900.0","upvote_count":"2"}],"isMC":true},{"id":"bNoHaejWJCmlGSCbsm5O","url":"https://www.examtopics.com/discussions/amazon/view/148827-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"B","choices":{"D":"Modify the security group that is attached to API Gateway to allow inbound traffic from only the trusted IP addresses.","C":"Directly deploy the API in a private subnet. Create a network ACL. Set up rules to allow the traffic from specific IP addresses.","A":"Set up an API Gateway private integration to restrict access to a predefined set of IP addresses.","B":"Create a resource policy for the API that denies access to any IP address that is not specifically allowed."},"question_text":"A company is developing an application in the AWS Cloud. The application's HTTP API contains critical information that is published in Amazon API Gateway. The critical information must be accessible from only a limited set of trusted IP addresses that belong to the company's internal network.\n\nWhich solution will meet these requirements?","answer_images":[],"answer_description":"","discussion":[{"upvote_count":"23","comment_id":"1294586","poster":"Jassn3","timestamp":"1728366960.0","content":"OMG finally I have reached here"},{"poster":"Bwhizzy","upvote_count":"13","timestamp":"1729366440.0","comment_id":"1300142","content":"Finally made it. Congratulations to everyone who got here. I know the journey has been hard and long. best of luck"},{"upvote_count":"5","comment_id":"1351482","content":"ðŸŽ‰ I cleared the AWS Solutions Architect â€“ Associate exam!\n\nFor those on the same journey, many exam questions are from or related to these 1019 questions. Go through them twice for a solid prep.\nAlso, check out Shaping Pixel's YouTube channelâ€”focus only on the latest videos as most questions overlap.\n\nYou've got thisâ€”good luck! ðŸš€","timestamp":"1738685340.0","poster":"whoeevd2eww3322d"},{"timestamp":"1737393780.0","upvote_count":"1","comment_id":"1343759","content":"Selected Answer: B\nGot to the end, worth it and great contributions","poster":"techghost"},{"content":"Selected Answer: B\nA - A private integration is for connecting API Gateway to private resources within VPCs, such as EC2 instances or Lambda functions. It doesn't restrict access based on IP addresses. It controls how the API interacts with private resources.\nB - This is the most direct way to restrict access at the API Gateway level.\nC - Deploying the API in a private subnet would require users to connect to your VPC (e.g., via VPN or Direct Connect). This is not what the question implies (the API should be publicly accessible, but restricted by IP).\nD - API Gateway doesn't even use security groups because it's a regional managed service, not directly tied to VPCs like EC2 instances.","comment_id":"1339080","poster":"LeonSauveterre","comments":[{"poster":"LeonSauveterre","comment_id":"1339082","content":"Now people let's go back to square one and nail this frickin' exam!","timestamp":"1736579280.0","upvote_count":"4"}],"timestamp":"1736579220.0","upvote_count":"3"},{"comment_id":"1336381","poster":"jfedotov","timestamp":"1735994400.0","content":"Selected Answer: B\nThe correct answer should be B, but the question is misleading. This is because HTTP APIs do not support resource policies; only REST APIs do.","upvote_count":"1"},{"comment_id":"1334464","upvote_count":"1","timestamp":"1735598700.0","poster":"Denise123","content":"Selected Answer: B\nI can't believe that I made it! Congrats everyone! Time to restart from the Q1 to polish, and good luck for the exam!"},{"comment_id":"1331913","poster":"EllenLiu","upvote_count":"2","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-resource-policies-examples.html#apigateway-resource-policies-source-ip-address-example","timestamp":"1735217040.0"},{"timestamp":"1733155980.0","comment_id":"1321026","content":"Selected Answer: D\nyes, finally, the finishing point.....\n\n---\nWhy not D?\n\nBy modifying the security group attached to API Gateway, you can explicitly define which IP addresses are allowed to access the API, effectively restricting access to only the trusted internal network IPs","upvote_count":"2","poster":"JA2018"},{"timestamp":"1733064120.0","poster":"trinh_le","comment_id":"1320593","content":"Selected Answer: B\nB: api gateway allows configure resource policy to restricted IP\nA: private integration-> private api\nC: private subnet -> private api\nD: security group does not support api gateway","upvote_count":"4"},{"timestamp":"1731714360.0","content":"Congrats to everyone who made it here. On to the next step, gents.","poster":"Sergantus","comment_id":"1312855","upvote_count":"6"},{"comment_id":"1306623","upvote_count":"5","timestamp":"1730663340.0","poster":"Ben_88","content":"And now it's time to start all over again to see if you can do better this time . good luck lads !"},{"upvote_count":"5","poster":"xekiva3329","comment_id":"1298596","content":"Selected Answer: B\nanswer B","timestamp":"1729063740.0"}],"isMC":true,"topic":"1","answer_ET":"B","unix_timestamp":1728314580,"question_images":[],"timestamp":"2024-10-07 17:23:00","exam_id":31,"question_id":24,"answers_community":["B (89%)","11%"]},{"id":"UMpiPjDari1Bq12EP2Av","discussion":[{"poster":"Buruguduystunstugudunstuy","comments":[{"timestamp":"1671654720.0","poster":"Buruguduystunstugudunstuy","content":"Next, you should use AWS DataSync to create a suitable location configuration for the on-premises SFTP server. A location represents a data source or a data destination in an AWS DataSync task. You can create a location for the on-premises SFTP server by specifying the IP address, the path to the data, and the necessary credentials to access the data.\n\nOnce you have created the location configuration for the on-premises SFTP server, you can use AWS DataSync to transfer the data to the EC2 instance with the EFS file system. AWS DataSync handles the data transfer process automatically and efficiently, transferring the data at high speeds and minimizing downtime.","comment_id":"752733","upvote_count":"21","comments":[{"content":"Explanation of other options\n\nA. Launch the EC2 instance into the same Availability Zone as the EFS file system.\n\nThis option is not wrong, but it is not directly related to automating the process of transferring the data from the on-premises SFTP server to the EC2 instance with the EFS file system. Launching the EC2 instance into the same Availability Zone as the EFS file system can improve the performance and reliability of the file system, as it reduces the latency between the EC2 instance and the file system. However, it is not necessary for automating the data transfer process.","upvote_count":"15","poster":"Buruguduystunstugudunstuy","timestamp":"1671654840.0","comment_id":"752735","comments":[{"comments":[{"upvote_count":"6","timestamp":"1671654840.0","comment_id":"752737","content":"D. Manually use an operating system copy command to push the data to the EC2 instance.\n\nThis option is not wrong, but it is not the most efficient or automated way to transfer the data from the on-premises SFTP server to the EC2 instance with the EFS file system. Manually transferring the data using an operating system copy command would require manual intervention and would not scale well for large amounts of data. It would also not provide the same level of performance and reliability as a fully managed service like AWS DataSync.","poster":"Buruguduystunstugudunstuy"}],"timestamp":"1671654840.0","poster":"Buruguduystunstugudunstuy","content":"C. Create a secondary Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instance for the data.\n\nThis option is incorrect because Amazon EBS is a block-level storage service that is designed for use with Amazon EC2 instances. It is not suitable for storing large amounts of data that need to be accessed by multiple EC2 instances, like in the case of the NFS-based file system on the on-premises SFTP server. Instead, you should use Amazon EFS, which is a fully managed, scalable, and distributed file system that can be accessed by multiple EC2 instances concurrently.","comment_id":"752736","upvote_count":"7"}]}]}],"upvote_count":"69","comment_id":"752732","timestamp":"1671654720.0","content":"Selected Answer: BE\nAnswer and HOW-TO\n\nB. Install an AWS DataSync agent in the on-premises data center.\nE. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.\n\nTo automate the process of transferring the data from the on-premises SFTP server to an EC2 instance with an EFS file system, you can use AWS DataSync. AWS DataSync is a fully managed data transfer service that simplifies, automates, and accelerates transferring data between on-premises storage systems and Amazon S3, Amazon EFS, or Amazon FSx for Windows File Server.\n\nTo use AWS DataSync for this task, you should first install an AWS DataSync agent in the on-premises data center. This agent is a lightweight software application that you install on your on-premises data source. The agent communicates with the AWS DataSync service to transfer data between the data source and target locations."},{"poster":"123jhl0","timestamp":"1666103760.0","content":"Selected Answer: AB\n**A**. Launch the EC2 instance into the same Availability Zone as the EFS file system.\nMakes sense to have the instance in the same AZ the EFS storage is.\n**B**. Install an AWS DataSync agent in the on-premises data center.\nThe DataSync with move the data to the EFS, which already uses the EC2 instance (see the info provided). No more things are required...\nC. Create a secondary Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instance for the data.\nThis secondary EBS volume isn't required... the data should be move on to EFS...\nD. Manually use an operating system copy command to push the data to the EC2 instance.\nPotentially possible (instead of A), BUT the \"automate this task\" premise goes against any \"manually\" action. So, we should keep A.\nE. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.\nI don't get the relationship between DataSync and the configuration for SFTP \"on-prem\"! Nonsense.\nSo, anwers are A&B","upvote_count":"60","comments":[{"comment_id":"812386","poster":"Lalo","upvote_count":"16","content":"CORRECT ANSWER: B&E\nSteps 4 &5\nhttps://aws.amazon.com/datasync/getting-started/?nc1=h_ls","timestamp":"1676668440.0"},{"content":"Just go to AWS Console, to DataSync and choose \"Create Location Configuration\". Locations configurations are endpoints used in DataSync task. A location can be the source endpoint of the task, e.g. a NFS on-premise filesystem. So E is helping in the automation process. A is not even part of this automation process, it is a solution already agreed to have EC2 with EFS, how you connect EC2 to EFS is not part of the solution!","comment_id":"1013358","upvote_count":"6","timestamp":"1695322980.0","poster":"Iconique"},{"upvote_count":"3","content":"will A,B work without E?","poster":"RBSK","comment_id":"743871","timestamp":"1670926320.0"},{"poster":"Cizzla7049","comment_id":"720169","content":"E is correct\nhttps://aws.amazon.com/blogs/storage/migrating-storage-with-aws-datasync/","timestamp":"1668655680.0","comments":[{"comment_id":"1161002","content":"Use AWS Transfer Family instead of DataSync for SFTP. So E seems incorrect.\n\nWhen do I use AWS DataSync and when do I use AWS Transfer Family?\n\nA: If you currently use SFTP to exchange data with third parties, AWS Transfer Family provides a fully managed SFTP, FTPS, FTP, and AS2 transfer directly into and out of Amazon S3, while reducing your operational burden.\n\nIf you want an accelerated and automated data transfer between NFS servers, SMB file shares, Hadoop clusters, self-managed or cloud object storage, AWS Snowcone, Amazon S3, Amazon EFS, and Amazon FSx, you can use AWS DataSync. DataSync is ideal for customers who need online migrations for active data sets, timely transfers for continuously generated data, or replication for business continuity.","poster":"happpieee","upvote_count":"1","timestamp":"1709069100.0"}],"upvote_count":"4"},{"upvote_count":"7","comments":[{"upvote_count":"2","comment_id":"846800","content":"However, launching the EC2 instance in the same AZ as the EFS file system can provide some performance benefits, such as reduced network latency and improved throughput. Therefore, it may be a best practice to launch the EC2 instance in the same AZ as the EFS file system if performance is a concern.","timestamp":"1679473440.0","poster":"lovelazur"},{"poster":"BlueVolcano1","timestamp":"1674216900.0","comment_id":"782203","upvote_count":"4","content":"Yes exactly, that's why A doesn't make sense. I voted for B and E."}],"comment_id":"724149","content":"Can someone explain why A is correct?\nEFS is spread across Availability Zones in a region, as per https://aws.amazon.com/blogs/gametech/gearbox-entertainment-goes-remote-with-aws-and-perforce/\nMy question then is whether it makes sense to launch EC2 instances in the *same Availability Zone as the EFS file system* ?","poster":"attila9778","timestamp":"1669102140.0"}],"comment_id":"698297"},{"poster":"Vandaman","comment_id":"1358649","timestamp":"1739957760.0","content":"Selected Answer: BE\nI was initially going with AB, but I questioned why would you need to launch an EC2 Instance for?","upvote_count":"1"},{"upvote_count":"1","timestamp":"1736241420.0","comment_id":"1337502","content":"Selected Answer: BE\nSince DataSync needs to me installed locally on on-premises and also we need DataSync to use SFTP.","poster":"satyaammm"},{"comment_id":"1327619","poster":"Gizmo2022","timestamp":"1734380580.0","upvote_count":"1","content":"I'm going to go with AB because AWS DataSync does not support SFTP location configuration."},{"upvote_count":"1","timestamp":"1732636920.0","content":"Selected Answer: BE\nA is wrong because EFS is across AZ.","poster":"tom_cruise","comment_id":"1318157"},{"upvote_count":"2","poster":"0de7d1b","content":"Selected Answer: AB\nA. Launch the EC2 instance into the same Availability Zone as the EFS file system:\nAmazon EFS file systems are tied to specific Availability Zones (AZs) within a region, and for optimal performance and availability, the EC2 instance should be launched in the same AZ as the EFS file system. This ensures low-latency access to the EFS data.\n\nB. Install an AWS DataSync agent in the on-premises data center:\nAWS DataSync is a service that automates data transfer between on-premises storage and AWS. To transfer the data from the on-premises server to EFS, you would need to install the DataSync agent on your on-premises system. The agent securely handles data transfer, ensuring the process is efficient and reliable.","timestamp":"1732212060.0","comment_id":"1315940"},{"content":"Selected Answer: AB\nA, B for sure","timestamp":"1729210800.0","upvote_count":"1","comment_id":"1299493","poster":"ChymKuBoy"},{"poster":"PaulGa","timestamp":"1726485480.0","comment_id":"1284625","content":"Selected Answer: AB\nAns A,B - hint: \"The server must be hosted on an Amazon EC2 instance that uses an Amazon Elastic File System (Amazon EFS) file system\" then use DataSync on-prem","upvote_count":"2"},{"poster":"XXXXXlNN","comment_id":"1281329","timestamp":"1725934440.0","content":"option E is not valid because AWS DataSync does not support SFTP as a location configuration. Instead, you would need to use AWS Transfer Family for SFTP transfers.","upvote_count":"3"},{"content":"Selected Answer: BE\nBE is correct","comment_id":"1274311","timestamp":"1724900880.0","poster":"SaurabhTiwari1","upvote_count":"1"},{"poster":"KTEgghead","timestamp":"1722221820.0","upvote_count":"1","content":"Selected Answer: BE\nlet DataSync work it all out - AWS DataSync can create a suitable location configuration for an on-premises SFTP server.","comment_id":"1257215"},{"comment_id":"1252965","poster":"jaradat02","timestamp":"1721639340.0","upvote_count":"1","content":"Selected Answer: BE\nB and E is the most logical solution, launching the instance in the same AZ as the EFS is not cruicial, C and D negate the automation part and the part where it says that we need to use EFS."},{"poster":"freedafeng","content":"I don't think E is correct. You create an EC2, and DataSync to migrate the NFS to EFS. That's it. You don't need to migrate anything on the on-presmise sftp server","comment_id":"1246083","timestamp":"1720697040.0","upvote_count":"1"},{"timestamp":"1720056300.0","comment_id":"1241735","content":"Selected Answer: BE\nA could be the right choice but here have to choose 2 options so alone with AB and with E it won't work so correct combination is BE","upvote_count":"1","poster":"jatric"},{"content":"Selected Answer: BE\nBE for sure","poster":"ChymKuBoy","upvote_count":"1","timestamp":"1718667300.0","comment_id":"1232159"},{"timestamp":"1716815880.0","comment_id":"1219572","content":"did think AB and now im thinking B and E. the questions and answers seem a bit vague like something is missing but have a look at the info on the AWS page. Use Datasync for migrations between NFS servers. \n\n\nQ: When do I use AWS DataSync and when do I use AWS Transfer Family?\n\nA: If you currently use SFTP to exchange data with third parties, AWS Transfer Family provides a fully managed SFTP, FTPS, FTP, and AS2 transfer directly into and out of Amazon S3, while reducing your operational burden.\n\nIf you want an accelerated and automated data transfer between NFS servers, SMB file shares, Hadoop clusters, self-managed or cloud object storage, AWS Snowcone, Amazon S3, Amazon EFS, and Amazon FSx, you can use AWS DataSync. DataSync is ideal for customers who need online migrations for active data sets, timely transfers for continuously generated data, or replication for business continuity.","poster":"lofzee","upvote_count":"1"},{"comment_id":"1191151","poster":"soufiyane","upvote_count":"2","timestamp":"1712516700.0","content":"Selected Answer: AB\nthe questions says combinations of two steps, so AB makes more sense"},{"upvote_count":"2","content":"Selected Answer: AB\nAWS DataSync does not support SFTP","comment_id":"1159629","timestamp":"1708946340.0","poster":"Risin42"},{"timestamp":"1708863600.0","content":"Selected Answer: AE\nThe most appropriate combination of steps to automate the task of migrating the on-premises SFTP server to an Amazon EC2 instance using Amazon EFS is:\n\nA. Launch the EC2 instance into the same Availability Zone as the EFS file system.\nE. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.\n\nExplanation:\n\nA. Launching the EC2 instance into the same Availability Zone as the EFS file system ensures optimal performance and low-latency access to the file system.\n\nE. AWS DataSync can be used to automate and accelerate the transfer of data between on-premises systems and AWS. Creating a suitable location configuration for the on-premises SFTP server with AWS DataSync facilitates the migration process.\n\nTherefore, options A and E together provide an efficient and automated approach to migrate the data.","comment_id":"1158691","upvote_count":"1","poster":"Ikki77"},{"timestamp":"1708740420.0","comment_id":"1157596","poster":"nntuan","content":"My choice is B and E.\nData Sync is used to transfer data between on-premises and AWS. It is required to deploy AWS Data Sync Agent in on-premises and configure the location FROM/TO in AWS Data Sync.","upvote_count":"1"},{"upvote_count":"2","poster":"app12","timestamp":"1705408680.0","comment_id":"1124195","content":"Apparently it's not B, as it says: \n\"Install\" an AWS DataSync agent in the on-premises data center.\nYou actually don't install it.\nYou deploy it as a vm or EC2.\nSo I guess it's the terminology that hints at \"E\""},{"comment_id":"1123656","poster":"awsgeek75","timestamp":"1705350900.0","content":"***The question is confusing and misleading!!!***\nThis part of question remains unanswered: \"The server must be hosted on an Amazon EC2 instance that uses an Amazon Elastic File System (Amazon EFS) file system\" and A doesn't actually make sense. BE doesn't fulfil this requirement. AB doesn't work without a location. \nI think something is missing in the dump","upvote_count":"1"},{"content":"Selected Answer: BE\nIt's already given EC2 with EFS opted for the solution.\nWhich combination of steps should a solutions architect take to automate this task?\nBE","poster":"data_cloud_aws","upvote_count":"1","comment_id":"1117186","comments":[{"timestamp":"1705351020.0","poster":"awsgeek75","content":"Are you saying the question is about automating the transfer and not migrating the SFTP server?","comment_id":"1123657","upvote_count":"1"}],"timestamp":"1704770940.0"},{"upvote_count":"1","poster":"Priyapani","content":"Correct answer BE\nA is not correct. EFS is region specific not AZ","timestamp":"1704730020.0","comment_id":"1116745"},{"poster":"SaurabhTiwari1","upvote_count":"1","content":"Selected Answer: BE\nBE is correct","comment_id":"1100270","timestamp":"1702960020.0"},{"upvote_count":"1","timestamp":"1702946280.0","poster":"djgodzilla","comment_id":"1100138","content":"Selected Answer: AB\nData Sync is agent based solution that allows to transfer between on-premises NFS/SMB shares and AWS, between AWS storage services and between different Clouds. it supports EFS,S3, and Fsx.. it requires an agent installation on-prem"},{"upvote_count":"1","content":"A because the statement in the question \"The server must be hosted on an Amazon EC2 instance that uses an Amazon Elastic File System (Amazon EFS) file system.\"\n\nB answer is explained in every comment","timestamp":"1701862260.0","comment_id":"1089260","poster":"Cyberkayu"},{"comment_id":"1076933","timestamp":"1700631300.0","upvote_count":"3","content":"Selected Answer: AE\nInstalling the AWS DataSync agent on the local data center, although it can be an efficient way, may be regarded as wasteful in this case, because the SFTP server already has a secure transport method, and DataSync is mainly used to simplify Data transfer in cross-domain transfer environment (local data center to AWS)Installing the AWS DataSync agent on the local data center, although it can be an efficient way, may be regarded as wasteful in this case, because the SFTP server already has a secure transport method, and DataSync is mainly used to simplify Data transfer in cross-domain transfer environment (local data center to AWS) and A. This ensures that EC2 instances and EFS file systems run in the same Availability Zone to maximize performance and reduce latency.","poster":"MiniYang"},{"content":"A and B\n\nanswer on the FAQ, SFTP has nothing to do with DataSync\nQ: When do I use AWS DataSync and when do I use AWS Transfer Family?\n\nA: If you currently use SFTP to exchange data with third parties, AWS Transfer Family provides a fully managed SFTP, FTPS, FTP, and AS2 transfer directly into and out of Amazon S3, while reducing your operational burden.\n\nhttps://aws.amazon.com/datasync/faqs/","poster":"t0nx","comment_id":"1076543","upvote_count":"2","timestamp":"1700591700.0"},{"comment_id":"1061969","timestamp":"1699087920.0","poster":"xdkonorek2","content":"Selected Answer: BE\nBE combination allow migration using datasync, architecture already is defined in the question. \nA is wrong because it's not said EFS uses single AZ mode, by default it works in multi-AZ mode","upvote_count":"1"},{"content":"Selected Answer: BD\nBE is the correct answer","timestamp":"1694588280.0","upvote_count":"1","comment_id":"1006297","poster":"axelrodb"},{"content":"https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/view/11/#","poster":"SuperDuperPooperScooper","comment_id":"985867","timestamp":"1692542280.0","upvote_count":"1"},{"content":"Selected Answer: AE\nA. Launch the EC2 instance into the same Availability Zone as the EFS file system and E. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.\nThese two steps in combination should be taken to automate this task. Launching the EC2 instance into the same Availability Zone as the EFS file system ensures that the instance has low latency access to the file system. AWS DataSync can then be used to automate the transfer of data from the on-premises SFTP server to the EFS file system on the EC2 instance. DataSync is an easy-to-use data transfer service that simplifies, automates, and accelerates moving large amounts of data into and out of AWS services such as Amazon S3, Amazon Elastic File System (Amazon EFS), and Amazon FSx for Windows File Server. The other options are not relevant or do not provide an automated solution for migrating the data center to AWS.\n\nThis is AI response, Is this correct?","timestamp":"1692345180.0","poster":"Raggz","comment_id":"984267","upvote_count":"1"},{"poster":"Abdou1604","comment_id":"979568","upvote_count":"1","content":"C is good , Amazon CloudFront is a content delivery network (CDN) service that helps distribute content globally with low latency and high data transfer speeds. By configuring your website to use CloudFront, your website's traffic can be distributed across multiple edge locations around the world. This not only improves user experience by reducing latency but also provides protection against DDoS attacks. CloudFront is designed to absorb and mitigate DDoS attacks by distributing traffic across its network of edge locations.","timestamp":"1691871540.0"},{"upvote_count":"1","timestamp":"1689839700.0","content":"Selected Answer: BE\nKeyword \"AWS DataSync\" . Choose B and E, where has this keyword. NFS stands for \"Network File System\". SFTP stands for \"Secure Fiel Transfer Protocol\". AWS DataSync https://aws.amazon.com/datasync/ , it is suitable for migration data from on-premises to AWS cloud.","comment_id":"957284","poster":"james2033"},{"poster":"cookieMr","comment_id":"930331","content":"Selected Answer: BE\nB. By installing an AWS DataSync agent in the on-premises data center, the architect can establish a secure connection between the on-premises environment and AWS.\n\nE. Once the DataSync agent is installed, the solutions architect should configure it to create a suitable location configuration that specifies the source location as the on-premises SFTP server and the target location as the EFS. AWS DataSync will handle the secure and efficient transfer of the data from the on-premises server to the EC2 using EFS.\n\nA. Launching EC2 into the same AZ as the EFS is not directly related to automating the migration task.\n\nC. Creating a secondary EBS on the EC2 for the data is not necessary when using EFS. EFS provides a scalable, fully managed NFS-based file system that can be mounted directly on the EC2, eliminating the need for separate EBS.\n\nD. It would require manual intervention and could be error-prone, especially for large amounts of data.","upvote_count":"2","timestamp":"1687425600.0"},{"comment_id":"926643","poster":"Anmol_1010","timestamp":"1687087920.0","upvote_count":"1","content":"Efs is launched in same region so.answer is option AB"},{"upvote_count":"1","poster":"fishy_resolver","comment_id":"917774","timestamp":"1686196200.0","content":"Selected Answer: BE\nB: DataSync to copy the data automatically\nE: DataSync discovery job to identify how / where to store your data automatically\nhttps://docs.aws.amazon.com/datasync/latest/userguide/getting-started-discovery-job.html"},{"upvote_count":"1","comment_id":"911246","timestamp":"1685536560.0","content":"Selected Answer: BE\nA is irrelevant given the scenario.","poster":"antropaws"},{"comment_id":"890100","timestamp":"1683297840.0","poster":"Pradeepdekhane","content":"Selected Answer: BE\nDatasync configuration are required","upvote_count":"1"},{"comment_id":"887059","content":"Selected Answer: BE\nA : same AZ? why?","timestamp":"1683007260.0","poster":"shinejh0528","upvote_count":"1"},{"comment_id":"879613","poster":"kruasan","upvote_count":"1","content":"Selected Answer: BE\nB* To access your self-managed on-premises or cloud storage, you need an AWS DataSync agent that's associated with your AWS account.\nhttps://docs.aws.amazon.com/datasync/latest/userguide/configure-agent.html\n\nE* A location is a storage system or service that AWS DataSync reads from or writes to. Each DataSync transfer has a source and destination location.\nhttps://docs.aws.amazon.com/datasync/latest/userguide/configure-agent.html","timestamp":"1682359860.0"},{"timestamp":"1681847940.0","content":"Selected Answer: BE\nneeds to install and provide a location so BE","poster":"kamx44","comment_id":"874067","upvote_count":"1"},{"upvote_count":"1","poster":"darn","comment_id":"872996","timestamp":"1681757100.0","content":"Selected Answer: AB\nA needs instance\nB needs Datasync"},{"content":"Selected Answer: AB\nI chose AB and Chat GPT said AB","poster":"ErfanKh","timestamp":"1681099860.0","upvote_count":"2","comment_id":"865973"},{"timestamp":"1681034940.0","comment_id":"865407","poster":"channn","upvote_count":"2","content":"Selected Answer: BE\nvote for BE"},{"poster":"sam20231","comment_id":"865335","timestamp":"1681024740.0","content":"AE is correct\nA. It is recommended to launch the EC2 in the same AZ as EFS file system to avoid any data transfer charges between different AZs\nE. Using DataSync the data from on-prem can be directly transferred to the EFS file system in an automated manner without datasync agent","upvote_count":"1"},{"timestamp":"1680705540.0","comment_id":"862200","content":"Selected Answer: AB\nA must be choosen, cos' it said that the server must be on EC2. Being in the same AZ help performance (no trans between AZ's)\nB will sync the onprem volume with the EBS in aws.\nAfter some days you can switch it off.\n\nD) manual opt ? ==> nooooo\nE) \"create location configuration\" ???, that does not exists !","upvote_count":"2","poster":"jdr75"},{"timestamp":"1680617460.0","upvote_count":"1","poster":"kraken21","comment_id":"861147","content":"Selected Answer: BE\nI changed my response to B,E. https://docs.aws.amazon.com/datasync/latest/userguide/working-with-locations.html"},{"upvote_count":"1","poster":"linux_admin","timestamp":"1680385800.0","content":"Selected Answer: AB\nA. Launching the EC2 instance into the same Availability Zone as the EFS file system ensures that the instance can access the EFS file system. This reduces latency and helps improve application performance.\n\nB. Installing an AWS DataSync agent in the on-premises data center helps automate the migration process by enabling the agent to transfer the data directly to the Amazon EFS file system. DataSync can perform incremental transfers of data and ensure data integrity.","comment_id":"858310"},{"content":"AB: is the best choice","timestamp":"1680135960.0","comment_id":"855111","upvote_count":"1","poster":"alexiscloud"},{"timestamp":"1680093300.0","upvote_count":"2","poster":"kraken21","content":"Selected Answer: AB\nI think E is a distractor. We need an instance(check the question) and datasync agent on prem. Hence A,B.","comment_id":"854404","comments":[{"timestamp":"1680617400.0","upvote_count":"1","comment_id":"861146","content":"I changed my response to B,E. https://docs.aws.amazon.com/datasync/latest/userguide/working-with-locations.html","poster":"kraken21"}]},{"timestamp":"1680086220.0","content":"chat gpt : B,E","poster":"jooddonging","comment_id":"854270","upvote_count":"1"},{"comment_id":"838057","upvote_count":"2","poster":"CapJackSparrow","timestamp":"1678723740.0","content":"Selected Answer: BE\n\"location\" keyword. No EC2 needed."},{"timestamp":"1678723620.0","comment_id":"838056","poster":"CapJackSparrow","upvote_count":"2","content":"Every DataSync \"job\" has TWO \"locations\" FROM and WHERE TO. EC2 is not needed for the Datasync \"job\" just an agent on prem and a \"location\" to where the data is going. So I'm inclined to go with B and E."},{"content":"Selected Answer: AB\nUse AWS Transfer family for SFTP\nhttps://aws.amazon.com/datasync/faqs/","upvote_count":"2","timestamp":"1677015300.0","poster":"bdp123","comment_id":"817195","comments":[{"content":"SFTP server it confuse us to link this to AWS transfer family... then we will not choose E","upvote_count":"1","timestamp":"1741846560.0","poster":"tch","comment_id":"1388204"}]},{"timestamp":"1676817660.0","poster":"vherman","upvote_count":"3","content":"Selected Answer: BE\nBE is correct. \nI did not select A because EC2 instance is not necessary to have in order to automate data transfer","comment_id":"814179"},{"timestamp":"1676674080.0","upvote_count":"2","poster":"K0nAn","content":"Selected Answer: BE\nSince EFS will be used in all AZ zones ,so A does not make sense ,BE makes sense for me","comment_id":"812465"},{"comment_id":"801355","poster":"bdp123","timestamp":"1675799340.0","upvote_count":"2","content":"Selected Answer: AB\nA and B is all that is needed"},{"upvote_count":"1","poster":"CaoMengde09","content":"I need to pay attention more to the ambiguous wording in those kind of questions.\n\nYou cannot transfer data from OnPrem to AWS without installing the AWS DataSync Agent inside the OnPrem server. The AWS DataSync Agent acts like a VM that cache and send data to AWS (in this case the EFS store). Without the AWS DataSync Agent just forget of any data transfer. So E. Answer for me is just a distractor. B. is the right one. And since C&D are ruled out A answer is the optimal architecture for data Availability.\n\nA&B Are the correct answers","comment_id":"798783","timestamp":"1675597080.0"},{"comment_id":"791676","poster":"Vickysss","timestamp":"1674999840.0","upvote_count":"2","content":"Selected Answer: AB\nThis can be a bit confusing but i believe the ab choice is correct. The company need to migrate a workload on AWS. The workload consists in having computation and storage power in the cloud (which lead you to choice A). Also, the company needs to migrate the existing data part into EFS (using DataSync). Which such a combination (without off course considering the technicality in details) the company will be able to run the workload on AWS."},{"comment_id":"791333","timestamp":"1674960180.0","upvote_count":"2","poster":"ChiggaBoy","content":"Selected Answer: BE\nB and E, A might not work with E"},{"poster":"kdinesh95","comment_id":"788422","upvote_count":"3","content":"Selected Answer: AB\nAB dudes","timestamp":"1674712080.0"},{"comments":[{"poster":"AjithKumar3","content":"DataSync allows you to configure a source storage location (NFS or SMB share) on-premises, and a destination in AWS storage services (Amazon S3 or Amazon EFS). It uses a purpose-built network protocol and scale-out architecture to accelerate the transfer of data to AWS","comment_id":"796593","timestamp":"1675387200.0","upvote_count":"1"}],"comment_id":"783817","poster":"bullrem","content":"Option E, using AWS DataSync to create a suitable location configuration for the on-premises SFTP server, is not a correct solution because DataSync is used to transfer data between on-premises locations and other cloud storage, it's not designed to work with SFTP servers.","timestamp":"1674343680.0","upvote_count":"3"},{"comments":[{"timestamp":"1675597200.0","content":"How you insure the transfer without installing the AWS DataSync. All those configurations are bound to fail without the AGENT.","upvote_count":"1","poster":"CaoMengde09","comment_id":"798784"}],"poster":"BlueVolcano1","timestamp":"1674217680.0","comment_id":"782210","upvote_count":"2","content":"Selected Answer: BE\nIt's B and E. Set up DataSync and the configure it to use the on-premise SMB server as a location: \nhttps://docs.aws.amazon.com/datasync/latest/userguide/create-smb-location.html\n\nA doesn't make sense as EFS is Multi-AZ.\nFrom the docs: \"Amazon EC2 and other AWS compute instances running in multiple Availability Zones within the same AWS Region can access the file system, so that many users can access and share a common data source.\"\nhttps://docs.aws.amazon.com/efs/latest/ug/how-it-works.html"},{"poster":"remand","content":"Selected Answer: AB\nAB are the answers.","upvote_count":"1","timestamp":"1673910600.0","comment_id":"778363"},{"upvote_count":"2","content":"Selected Answer: AB\nA and B","timestamp":"1673814420.0","poster":"Ello2023","comment_id":"777039"},{"content":"Selected Answer: BE\nIf B is right, how DataSync agent works without the step mentioned in E?","comment_id":"775106","timestamp":"1673674140.0","upvote_count":"1","poster":"goodmail"},{"content":"Selected Answer: BE\nB. Install an AWS DataSync agent in the on-premises data center.\nE. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.\n\nA is not necessary for automating the data transfer process.\nB & E are related to the automation.","comment_id":"774550","upvote_count":"3","poster":"Myxa","timestamp":"1673618280.0"},{"comment_id":"762542","timestamp":"1672473720.0","poster":"Zerotn3","content":"Selected Answer: BE\nB. Install an AWS DataSync agent in the on-premises data center.\nE. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.","upvote_count":"1"},{"comment_id":"755408","timestamp":"1671944700.0","upvote_count":"4","content":"Selected Answer: BE\nhttps://aws.amazon.com/blogs/storage/migrating-storage-with-aws-datasync/","poster":"k1kavi1"},{"timestamp":"1671873060.0","comment_id":"754781","upvote_count":"1","poster":"Silvestr","content":"My answer is related to AWS DataSync"},{"comment_id":"754780","poster":"Silvestr","content":"Selected Answer: BE\nCorrect answer - B,E\nMove large amount of data to and from\nâ€¢ On-premises / other cloud to AWS (NFS, SMB, HDFS, S3 APIâ€¦) â€“ needs agent\nâ€¢ AWS to AWS (different storage services) â€“ no agent needed\nâ€¢ Can synchronize to:\nâ€¢ Amazon S3 (any storage classes â€“ including Glacier)\nâ€¢ Amazon EFS\nâ€¢ Amazon FSx (Windows, Lustre, NetApp, OpenZFS...)\nâ€¢ Replication tasks can be scheduled hourly, daily, weekly","timestamp":"1671873000.0","upvote_count":"1"},{"timestamp":"1671853740.0","upvote_count":"4","comment_id":"754685","content":"Selected Answer: BE\nIt is B and E but option E is badly worded or has typo error. It should say create a approriate location on EC2 EFS filesystem to transfer the data","poster":"career360guru"},{"content":"Selected Answer: BE\nThe correct answer is B and E.\nOption A is not necessary because the EC2 instance and the EFS file system can be in different Availability Zones.","upvote_count":"1","poster":"DavidNamy","timestamp":"1671615900.0","comment_id":"752094"},{"upvote_count":"1","content":"The correct answer is B and E.\nOption A is not necessary because the EC2 instance and the EFS file system can be in different Availability Zones.","poster":"DavidNamy","comment_id":"752088","timestamp":"1671615780.0"},{"timestamp":"1671601860.0","comment_id":"751915","content":"Creating AWS DataSync locations with the AWS CLI\nPDF\nRSS\nEach AWS DataSync task is made up of a pair of locations in a transfer. The source location defines the storage system or service that you want to read data from. The destination location defines the storage system or service that you want to write data to.\n\nWith the AWS Command Line Interface (AWS CLI), you can create locations for the following storage systems and services:\n\nNetwork File System (NFS)\n\nServer Message Block (SMB)\n\nHadoop Distributed File System (HDFS)\n\nSelf-managed object storage source locations\n\nAmazon Elastic File System (Amazon EFS)\n\nAmazon FSx for Windows File Server\n\nAmazon FSx for Lustre\n\nAmazon FSx for OpenZFS\n\nAmazon FSx for NetApp ONTAP\n\nAmazon Simple Storage Service (Amazon S3)","upvote_count":"1","poster":"duriselvan"},{"comment_id":"750992","upvote_count":"1","poster":"duriselvan","timestamp":"1671546060.0","content":"AWS DataSync\nNFS / SMB to AWS (S3, EFS, FSxâ€¦)\n\n1)instal the Agent On-Premises-AWS DataSync\nAgent \n2) AWS DataSync will be storage S3 and EFS and Amazon FSx"},{"upvote_count":"1","content":"A doesn't make a whole lot of sense since Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. You create a mount point in each AZ you wish to connect to the EFS FS, but the EFS FS is regional, so is not within any particular AZ, so I see A must be wrong","timestamp":"1671464280.0","comment_id":"749993","poster":"JayBee65"},{"upvote_count":"1","timestamp":"1671001860.0","comment_id":"744819","poster":"vtbk","content":"B and E"},{"timestamp":"1670878260.0","upvote_count":"1","content":"Selected Answer: BE\nEFS is available within all AZ.","comment_id":"743324","poster":"[Removed]"},{"comment_id":"736572","timestamp":"1670308440.0","upvote_count":"2","poster":"PDR","content":"badly worded question as we actually need :\n- and ec2 instance , which means A\n- the datasync agent installed on premises, which means B\n- to configure the location configuration for datasync to specify the source location to create the transfer task , so E\n\nanswer is then A B and E , to only provide 2 means we have to make assumptions but there is a variety of possible assumptions we can make !"},{"upvote_count":"3","content":"Selected Answer: BE\nhttps://aws.amazon.com/datasync/","poster":"Cizzla7049","timestamp":"1669612260.0","comment_id":"728796"},{"poster":"DivaLight","upvote_count":"1","timestamp":"1669491780.0","comment_id":"727784","content":"Selected Answer: BE\nOption BE"},{"timestamp":"1669369200.0","upvote_count":"3","comment_id":"726578","content":"Selected Answer: BE\nB and E make more sens","poster":"LeGloupier"},{"content":"Selected Answer: AE\nI chose A and E, because firstly we need to install DataSync agent to copy from SFTP and then create respective location.","comment_id":"725257","upvote_count":"1","timestamp":"1669220580.0","poster":"nVizzz"},{"comment_id":"723809","timestamp":"1669053720.0","upvote_count":"1","content":"A and E","poster":"Wpcorgan"},{"timestamp":"1668747360.0","comment_id":"721068","upvote_count":"1","poster":"kmliuy73","content":"BE are correct"},{"upvote_count":"2","poster":"Cizzla7049","content":"Selected Answer: AE\nAE are correct\nhttps://aws.amazon.com/blogs/storage/migrating-storage-with-aws-datasync/","comment_id":"720170","timestamp":"1668655740.0"}],"answer_description":"","question_text":"A company wants to migrate an on-premises data center to AWS. The data center hosts an SFTP server that stores its data on an NFS-based file system. The server holds 200 GB of data that needs to be transferred. The server must be hosted on an Amazon EC2 instance that uses an Amazon Elastic File System (Amazon EFS) file system.\nWhich combination of steps should a solutions architect take to automate this task? (Choose two.)","answer_ET":"BE","timestamp":"2022-10-18 16:36:00","choices":{"E":"Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.","A":"Launch the EC2 instance into the same Availability Zone as the EFS file system.","C":"Create a secondary Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instance for the data.","B":"Install an AWS DataSync agent in the on-premises data center.","D":"Manually use an operating system copy command to push the data to the EC2 instance."},"exam_id":31,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/85814-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","isMC":true,"question_id":25,"answer":"BE","answer_images":[],"answers_community":["BE (56%)","AB (40%)","4%"],"unix_timestamp":1666103760}],"exam":{"numberOfQuestions":1019,"isMCOnly":true,"isBeta":false,"lastUpdated":"11 Apr 2025","provider":"Amazon","isImplemented":true,"id":31,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":5},"__N_SSP":true}