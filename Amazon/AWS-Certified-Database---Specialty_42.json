{"pageProps":{"questions":[{"id":"ID9J2rYMYiSTNgsG6Oug","answer_description":"","question_text":"A company is working on migrating a large Oracle database schema with 3,500 stored procedures to Amazon Aurora PostgreSQL. An application developer is using the AWS Schema Conversion Tool (AWS SCT) to convert code from Oracle to Aurora PostgreSQL. However, the code conversion is taking a longer time with performance issues. The application team has reached out to a database specialist to improve the performance of the AWS SCT conversion.\n\nWhat should the database specialist do to resolve the performance issues?","question_images":[],"topic":"1","answer_images":[],"answers_community":["C (83%)","B (17%)"],"question_id":206,"answer":"C","exam_id":22,"isMC":true,"timestamp":"2023-03-25 01:39:00","url":"https://www.examtopics.com/discussions/amazon/view/103811-exam-aws-certified-database-specialty-topic-1-question-284/","choices":{"C":"In AWS SCT, turn on the fast conversion with large memory consumption performance option and set the JavaOptions section to the maximum memory available.","D":"Provision a client Amazon EC2 machine with more CPU and memory resources in the same AWS Region as the Aurora PostgreSQL database.","A":"In AWS SCT, turn on the balance speed with memory consumption performance option with the optimal memory settings on local desktop.","B":"Provision the target Aurora PostgreSQL database with a higher instance class. In AWS SCT. turn on the balance speed with memory consumption performance option."},"discussion":[{"upvote_count":"1","timestamp":"1684996980.0","comment_id":"906451","poster":"aviathor","content":"Selected Answer: C\nA. Probably won't help\nB. Increasing the size of the Aurora instance will not improve the performance of AWS SCT.\nC. \"Use one of these methods to control the memory usage and performance of the AWS SCT tool.\"\nD. \"It's a best practice to install the AWS SCT on a separate machine that's in the same network as your source. This allows for better performance in the code conversion and data migration phases\""},{"comment_id":"884053","upvote_count":"2","timestamp":"1682746320.0","poster":"clarksu","content":"Selected Answer: C\nKey factor would be the performance of the SCT running env.\n\nhttps://repost.aws/knowledge-center/dms-optimize-aws-sct-performance\n\nFast conversion, but large memory consumption - This optimizes the speed of the conversion. But, it might need more memory for the object reference cache.\n\n+ Java \nIn the JavaOptions section, set the minimum and maximum memory available to the AWS SCT. This example sets a minimum of 4GB and a maximum of 40GB:"},{"poster":"backbencher2022","timestamp":"1680211380.0","content":"Selected Answer: C\nDefinitely option C. check this link to validate - https://repost.aws/knowledge-center/dms-optimize-aws-sct-performance.\nThe goal is to improve performance and not memory consumption so, option A must be ruled out as balanced setting will compromise performance and option A doesn't even mention Java memory setting which is another key mechanism to improve SCT performance. Remaining options are distractors so, option C is the best.","upvote_count":"1","comment_id":"856287"},{"timestamp":"1679943300.0","comment_id":"852391","upvote_count":"1","poster":"hughnguyen","content":"Selected Answer: C\nThe answer is C\nRefer to the link below, the compute power of the target database does not matter. \n\"The performance of the AWS SCT depends on the memory that's available on the local machine that it's installed on. If you increase the memory that's available to the AWS SCT, then you also speed up the performance of your conversion. But this means that the AWS SCT also consumes more memory resources on your local machine.\"\n\nFurthermore fast conversion tells SCT to use optimise speed at the expense of memory"},{"poster":"dougporto1988","upvote_count":"1","content":"Selected Answer: B\nTo resolve the performance issues of the AWS SCT conversion, the database specialist should provision the target Aurora PostgreSQL database with a higher instance class and turn on the balance speed with memory consumption performance option in AWS SCT.\n\nOption B is the correct answer because increasing the instance class of the target Aurora PostgreSQL database will improve its processing power and memory, which will allow it to handle the AWS SCT conversion more efficiently. Additionally, turning on the balance speed with memory consumption performance option in AWS SCT will optimize the conversion process for performance and memory usage.","timestamp":"1679704740.0","comment_id":"849715"}],"unix_timestamp":1679704740,"answer_ET":"C"},{"id":"c2dg5QSIOcqvaztifibp","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/103962-exam-aws-certified-database-specialty-topic-1-question-285/","choices":{"C":"Use the cluster reader endpoint. Configure the failover priority of the three Aurora Replicas.","B":"Configure an Aurora custom endpoint for the three Aurora Replicas.","A":"Use CNAMEs to set up DNS aliases for the three Aurora Replicas.","D":"Use the specific instance endpoints for each of the three Aurora Replicas."},"isMC":true,"timestamp":"2023-03-26 15:35:00","question_images":[],"exam_id":22,"topic":"1","question_id":207,"answer":"B","unix_timestamp":1679837700,"question_text":"A company has a 12-node Amazon Aurora MySQL DB cluster. The company wants to use three specific Aurora Replicas to handle the workload from one of its read-only applications.\n\nWhich solution will meet this requirement with the LEAST operational overhead?","answers_community":["B (100%)"],"answer_images":[],"discussion":[{"content":"Selected Answer: B\nCustom endpoint\nA custom endpoint for an Aurora cluster represents a set of DB instances that you choose. When you connect to the endpoint, Aurora performs load balancing and chooses one of the instances in the group to handle the connection.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Endpoints.Custom","poster":"dbkorn","comment_id":"1085636","upvote_count":"1","timestamp":"1701483660.0"},{"content":"Selected Answer: B\nB (custom endpoint) is the correct option. Refer to this url for more details - https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Endpoints.Custom","timestamp":"1680211500.0","upvote_count":"1","poster":"backbencher2022","comment_id":"856289"},{"poster":"rdiaz","comment_id":"851085","content":"Selected Answer: B\nB custom endpoint https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Endpoints.Custom","upvote_count":"4","timestamp":"1679837700.0"}],"answer_description":""},{"id":"5L4OQzTeHIkY7qI9QLf2","answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/103963-exam-aws-certified-database-specialty-topic-1-question-286/","answer_images":[],"answer_ET":"D","discussion":[{"upvote_count":"2","content":"Selected Answer: D\nAnswer D","comment_id":"1027840","poster":"roymunson","timestamp":"1696756380.0"},{"content":"Selected Answer: D\nD. Turn on the require_secure_transport parameter in the DB cluster parameter group","timestamp":"1693953480.0","poster":"Pranava_GCP","upvote_count":"2","comment_id":"999974"},{"upvote_count":"1","timestamp":"1693809480.0","content":"Selected Answer: D\nDDDDDDD","comment_id":"998258","poster":"chen0305_099"},{"poster":"rdiaz","upvote_count":"2","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Security.html","comment_id":"851098","timestamp":"1679838120.0"}],"timestamp":"2023-03-26 15:42:00","exam_id":22,"unix_timestamp":1679838120,"choices":{"C":"Turn on data encryption by using AWS Key Management Service (AWS KMS). Use the AWS KMS key to encrypt the connections between a MySQL client and the Aurora DB cluster.","D":"Turn on the require_secure_transport parameter in the DB cluster parameter group. Download the root certificate for the DB instance. Reference that file from the --ssl-ca option when connecting with a MySQL client.","B":"Download the key pair for the DB instance. Reference that file from the --key-name option when connecting with a MySQL client.","A":"Turn on data encryption when modifying the DB cluster by using the AWS Management Console or by using the AWS CLI to call the modify-db-cluster command."},"question_id":208,"answer":"D","question_images":[],"topic":"1","question_text":"A company uses an Amazon Aurora MySQL DB cluster with the most recent version of the MySQL database engine. The company wants all data that is transferred between clients and the DB cluster to be encrypted.\n\nWhat should a database specialist do to meet this requirement?","isMC":true,"answer_description":""},{"id":"6KAJk26D8DTw5GzBIjYF","timestamp":"2023-03-26 15:46:00","answers_community":["B (100%)"],"choices":{"D":"Use AWS DataSync to back up the DB instance in the source AWS account. Use AWS Resource Access Manager (AWS RAM) to restore the backup in the destination AWS account.","A":"Use AWS Database Migration Service (AWS DMS) to migrate the DB instance from the source AWS account to the destination AWS account.","C":"Create a Multi-AZ deployment for the DB instance. Create a read replica for the DB instance in the source AWS account. Use the read replica to replicate the data into the DB instance in the destination AWS account.","B":"Create a DB snapshot of the DB instance. Share the snapshot with the destination AWS account. Create a new DB instance by restoring the snapshot in the destination AWS account."},"answer_ET":"B","answer_images":[],"question_images":[],"topic":"1","answer":"B","unix_timestamp":1679838360,"isMC":true,"question_text":"A database specialist needs to move an Amazon RDS DB instance from one AWS account to another AWS account.\n\nWhich solution will meet this requirement with the LEAST operational effort?","url":"https://www.examtopics.com/discussions/amazon/view/103964-exam-aws-certified-database-specialty-topic-1-question-287/","discussion":[{"poster":"chen0305_099","comment_id":"998256","content":"Selected Answer: B\nBBBBBBB","timestamp":"1693809480.0","upvote_count":"1"},{"upvote_count":"1","content":"B is right. No migration (source to destination) involved, just move and best way is using snapshot sharing.","comment_id":"894986","timestamp":"1683804000.0","poster":"tsk9921"},{"timestamp":"1679838360.0","upvote_count":"4","comment_id":"851101","comments":[{"comments":[{"timestamp":"1684474260.0","content":"From the same reference link, A is right as well. \nA --> DMS: less downtime\nB-> manual steps, more downtime","comment_id":"901662","comments":[{"upvote_count":"1","timestamp":"1690229400.0","comment_id":"962008","content":"C even less downtime\nbut it the downtime requirements are not clear","poster":"Zdujgfr567783ff"}],"upvote_count":"1","poster":"AWS_SJ"}],"content":"Vote for B","poster":"Mintwater","timestamp":"1681866960.0","comment_id":"874213","upvote_count":"1"}],"poster":"rdiaz","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/migrate-an-amazon-rds-db-instance-to-another-vpc-or-account.html"}],"question_id":209,"answer_description":"","exam_id":22},{"id":"8O6WojBLxgyTPQTVErCh","answer_description":"","question_id":210,"question_text":"A company uses Amazon DynamoDB as a data store for multi-tenant data. Approximately 70% of the reads by the company's application are strongly consistent. The current key schema for the DynamoDB table is as follows:\n\nPartition key: OrgID -\n\nSort key: TenantID#Version -\n\nDue to a change in design and access patterns, the company needs to support strongly consistent lookups based on the new schema below:\n\nPartition key: OrgID#TenantID -\n\nSort key: Version -\n\nHow can the database specialist implement this change?","answers_community":["C (100%)"],"answer":"C","topic":"1","timestamp":"2023-03-29 18:17:00","url":"https://www.examtopics.com/discussions/amazon/view/104401-exam-aws-certified-database-specialty-topic-1-question-288/","unix_timestamp":1680106620,"exam_id":22,"discussion":[{"comment_id":"906456","upvote_count":"6","poster":"aviathor","content":"Selected Answer: C\nxA. Create a global secondary index (GSI) on the existing table with the specified partition and sort key. - GSI does not support strongly consistent searches\nxB. Create a local secondary index (LSI) on the existing table with the specified partition and sort key. - the secondary index only contains the sort key, it does not help for the partition key, and it cannot be added after the table has been created.\nC. Create a new table with the specified partition and sort key. Create an AWS Glue ETL job to perform the transformation and write the transformed data to the new table. - by elimination, this has to be the correct answer\nxD. Create a new table with the specified partition and sort key. Use AWS Database Migration Service (AWS DMS) to migrate the data to the new table. - DMS only supports DynamoDB as a target","timestamp":"1684997940.0"},{"poster":"rn30","comment_id":"948176","timestamp":"1688997120.0","content":"C\nyou can not update the sort key after the table is provisioned. However, you can create a new table and put the existing data in the newly created table, and delete the old table.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1681908420.0","poster":"mawsman","content":"Selected Answer: C\nGSI uses the same data and is eventually consistent - we need to combine two columns to create new primary key, plus it needs to be strongly consistent. Hence new table and glue, but a bit of a trick question none the less, since it asks for LEAST effort.","comment_id":"874660"},{"poster":"Mintwater","comments":[{"upvote_count":"1","poster":"Mintwater","comment_id":"860484","content":"A maybe not the right answer --\n\"Data synchronization between tables and Global Secondary Indexes\nDynamoDB automatically synchronizes each global secondary index with its base table. When an application writes or deletes items in a table, any global secondary indexes on that table are updated asynchronously, using an eventually consistent model. Applications never write directly to an index.","timestamp":"1680566580.0"}],"comment_id":"860474","content":"A. Create a global secondary index (GSI) on the existing table with the specified partition and sort key.\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html#GSI.scenario\n\"By creating a GSI with the new partition and sort key, the existing table can continue to be used, and there is no need to create a new table or migrate the data. This approach can support strongly consistent lookups for the new access pattern while maintaining the existing access pattern. A GSI is ideal for handling queries with different access patterns without changing the primary key of the table.\"","upvote_count":"1","timestamp":"1680566100.0"},{"content":"Selected Answer: C\nA. KO - GSI is not strongly consistent.\nB. KO - LSI cannot be created once the table exists.\nC. OK - New table + glue\nD. KO - Dynamo is not a compatible source for DMS: https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.html","timestamp":"1680106620.0","poster":"rdiaz","comments":[{"comments":[{"comment_id":"874218","content":"You are right. Dynamo is not the source for DMS.","upvote_count":"1","poster":"Mintwater","timestamp":"1681867800.0"}],"timestamp":"1680573960.0","poster":"Mintwater","upvote_count":"1","content":"GLUE is complex. I prefer D","comment_id":"860542"}],"comment_id":"854667","upvote_count":"3"}],"choices":{"B":"Create a local secondary index (LSI) on the existing table with the specified partition and sort key.","A":"Create a global secondary index (GSI) on the existing table with the specified partition and sort key.","C":"Create a new table with the specified partition and sort key. Create an AWS Glue ETL job to perform the transformation and write the transformed data to the new table.","D":"Create a new table with the specified partition and sort key. Use AWS Database Migration Service (AWS DMS) to migrate the data to the new table."},"answer_ET":"C","question_images":[],"isMC":true,"answer_images":[]}],"exam":{"isMCOnly":false,"isImplemented":true,"lastUpdated":"11 Apr 2025","id":22,"isBeta":false,"numberOfQuestions":359,"provider":"Amazon","name":"AWS Certified Database - Specialty"},"currentPage":42},"__N_SSP":true}