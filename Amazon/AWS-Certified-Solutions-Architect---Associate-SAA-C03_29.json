{"pageProps":{"questions":[{"id":"6aXBXijOtpdW8beWUzK6","question_images":[],"topic":"1","question_text":"A company owns an asynchronous API that is used to ingest user requests and, based on the request type, dispatch requests to the appropriate microservice for processing. The company is using Amazon API Gateway to deploy the API front end, and an AWS Lambda function that invokes Amazon DynamoDB to store user requests before dispatching them to the processing microservices.\n\nThe company provisioned as much DynamoDB throughput as its budget allows, but the company is still experiencing availability issues and is losing user requests.\n\nWhat should a solutions architect do to address this issue without impacting existing users?","timestamp":"2022-11-28 15:36:00","answer_description":"","exam_id":31,"isMC":true,"discussion":[{"comment_id":"1106670","timestamp":"1719470340.0","upvote_count":"14","poster":"pentium75","content":"Selected Answer: D\nA does not meet the \"without impacting existing users\" requirement\nB does not help with writing (DAX caches reads)\nC does not help with writing (index could increase read performance only)\nD decouples writing from front-end, which is acceptable because it is \"an asynchronous API\" anyway"},{"comment_id":"822227","upvote_count":"12","timestamp":"1693037820.0","content":"Selected Answer: D\nThe key here is \"Losing user requests\" sqs messages will stay in the queue until it has been processed","poster":"nder"},{"poster":"lofzee","timestamp":"1732805220.0","comment_id":"1220246","content":"Selected Answer: D\nD bro. Believe","upvote_count":"3"},{"timestamp":"1710188160.0","content":"Selected Answer: D\nThis solution can handle bursts of incoming requests more effectively and reduce the chances of losing requests due to DynamoDB capacity limitations. The Lambda can be configured to retrieve messages from the SQS and write them to DynamoDB at a controlled rate, allowing DynamoDB to handle the requests within its provisioned capacity. This approach provides resilience to spikes in traffic and ensures that requests are not lost during periods of high demand.","upvote_count":"5","poster":"Guru4Cloud","comment_id":"1005086"},{"timestamp":"1703669460.0","content":"Selected Answer: D\nThis solution can handle bursts of incoming requests more effectively and reduce the chances of losing requests due to DynamoDB capacity limitations. The Lambda can be configured to retrieve messages from the SQS and write them to DynamoDB at a controlled rate, allowing DynamoDB to handle the requests within its provisioned capacity. This approach provides resilience to spikes in traffic and ensures that requests are not lost during periods of high demand.\n\nA. It limits can help control the request rate, but it may lead to an increase in errors and affect the user experience. Throttling alone may not be sufficient to address the availability issues and prevent the loss of requests.\n\nB. It can improve read performance but does not directly address the availability issues and loss of requests. It focuses on optimizing read operations rather than buffering writes.\n\nC. It may help with querying the user requests efficiently, but it does not directly solve the availability issues or prevent the loss of requests. It is more focused on data retrieval rather than buffering writes.","upvote_count":"4","poster":"cookieMr","comment_id":"935107"},{"poster":"studynoplay","comment_id":"898464","content":"Selected Answer: D\nDAX is for reads","timestamp":"1700070360.0","comments":[{"upvote_count":"3","content":"DAX is not ideal for the following types of applications:\n\n Applications that require strongly consistent reads (or that cannot tolerate eventually consistent reads).\n\n Applications that do not require microsecond response times for reads, or that do not need to offload repeated read activity from underlying tables.\n\n Applications that are write-intensive, or that do not perform much read activity.\n\n Applications that are already using a different caching solution with DynamoDB, and are using their own client-side logic for working with that caching solution.","comment_id":"916773","timestamp":"1701920400.0","poster":"smartegnine"}],"upvote_count":"4"},{"timestamp":"1690509600.0","comment_id":"790257","upvote_count":"4","content":"Selected Answer: D\nD because SQS is the cheapest way. First 1,000,000 requests are free each month.\n\nQuestion states: \"The company provisioned as much DynamoDB throughput as its budget allows\"","poster":"dark_firzen"},{"poster":"Wajif","upvote_count":"2","content":"Selected Answer: D\nD is more likely to fix this problem as SQS queue has the ability to wait (buffer) for consumer to notify that the request or message has been processed.","comment_id":"755373","timestamp":"1687650720.0"},{"upvote_count":"7","content":"Selected Answer: D\nTo address the issue of lost user requests and improve the availability of the API, the solutions architect should use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB. Option D (correct answer)\n\nBy using an SQS queue and Lambda, the solutions architect can decouple the API front end from the processing microservices and improve the overall scalability and availability of the system. The SQS queue acts as a buffer, allowing the API front end to continue accepting user requests even if the processing microservices are experiencing high workloads or are temporarily unavailable. The Lambda function can then retrieve requests from the SQS queue and write them to DynamoDB, ensuring that all user requests are stored and processed. This approach allows the company to scale the processing microservices independently from the API front end, ensuring that the API remains available to users even during periods of high demand.","timestamp":"1687537920.0","comment_id":"754421","poster":"Buruguduystunstugudunstuy"},{"poster":"alect096","comment_id":"752520","content":"Selected Answer: B\nI would go to B : https://aws.amazon.com/es/blogs/database/amazon-dynamodb-accelerator-dax-a-read-throughwrite-through-cache-for-dynamodb/","comments":[{"content":"That's wrong. The document you mentioned explained it very clearly: \n\"Whereas both read-through and write-through caches address read-heavy workloads, a write-back (or write-behind) cache is designed to address write-heavy workloads. Note that DAX is not a write-back cache currently\"","upvote_count":"3","timestamp":"1704704460.0","comment_id":"946258","poster":"ruqui"}],"timestamp":"1687355100.0","upvote_count":"1"},{"comment_id":"750466","poster":"BENICE","content":"D is correct answer","timestamp":"1687226100.0","upvote_count":"2"},{"comment_id":"748267","poster":"NikaCZ","content":"Selected Answer: D\nD. Use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB.","timestamp":"1687018200.0","upvote_count":"2"},{"upvote_count":"2","comment_id":"747834","content":"Selected Answer: D\nOption D is right answer","poster":"career360guru","timestamp":"1686978360.0"},{"content":"Why not B? DAX.\n\n\"When you’re developing against DAX, instead of pointing your application at the DynamoDB endpoint, you point it at the DAX endpoint, and DAX handles the rest. As a read-through/write-through cache, DAX seamlessly intercepts the API calls that an application normally makes to DynamoDB so that both read and write activity are reflected in the DAX cache.\"\n\nhttps://aws.amazon.com/es/blogs/database/amazon-dynamodb-accelerator-dax-a-read-throughwrite-through-cache-for-dynamodb/","comment_id":"745889","upvote_count":"1","poster":"alexfk","comments":[{"comment_id":"869684","poster":"AgboolaKun","content":"It is not DAX because of the company's budget restriction associated with the DynamoDB. This is a requirement in the question. DynamoDB charges for DAX capacity by the hour and your DAX instances run with no long-term commitments. Please refer to: https://aws.amazon.com/dynamodb/pricing/provisioned/#.E2.80.A2_DynamoDB_Accelerator_.28DAX.29","upvote_count":"3","timestamp":"1697223540.0"},{"poster":"ruqui","comment_id":"946261","upvote_count":"2","timestamp":"1704704580.0","content":"B is wrong because of this: \n\n\"Whereas both read-through and write-through caches address read-heavy workloads, a write-back (or write-behind) cache is designed to address write-heavy workloads. Note that DAX is not a write-back cache currently\""}],"timestamp":"1686814380.0"},{"content":"yeah I though the answer is also DAX.","comment_id":"735746","upvote_count":"1","timestamp":"1685944500.0","poster":"akosigengen"},{"comment_id":"729755","comments":[{"upvote_count":"1","content":"Why not DAX? Could somebody explain?","timestamp":"1685872980.0","comments":[{"timestamp":"1687538040.0","poster":"Buruguduystunstugudunstuy","upvote_count":"2","content":"Using DynamoDB Accelerator (DAX) and Lambda to buffer writes to DynamoDB, may improve the write performance of the system, but it does not provide the same level of scalability and availability as using an SQS queue and Lambda. \n\nHence, Option B is incorrect.","comment_id":"754422"},{"timestamp":"1686178140.0","upvote_count":"6","comment_id":"738488","content":"key noted issue is \"losing user requests\" which is resolved with SQS","poster":"bmofo"},{"timestamp":"1685902860.0","content":"DAX helps in reducing the read loads from DynamoDB, here we need a solution to handle write requests, which is well handled by SQS and Lamda to buffer writes on DynamoDB.","comment_id":"735430","upvote_count":"5","poster":"Rameez1"}],"comment_id":"735058","poster":"nVizzz"}],"content":"Selected Answer: D\nUsing SQS should be the answer.","poster":"leonnnn","upvote_count":"4","timestamp":"1685313960.0"},{"timestamp":"1685310180.0","comment_id":"729722","upvote_count":"3","poster":"jambajuice","content":"Selected Answer: D\nAnswer d"},{"upvote_count":"2","timestamp":"1685277360.0","poster":"Nigma","content":"Answer : D","comment_id":"729233"}],"choices":{"C":"Create a secondary index in DynamoDB for the table with the user requests.","A":"Add throttling on the API Gateway with server-side throttling limits.","B":"Use DynamoDB Accelerator (DAX) and Lambda to buffer writes to DynamoDB.","D":"Use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB."},"answer":"D","answers_community":["D (99%)","1%"],"url":"https://www.examtopics.com/discussions/amazon/view/89087-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"D","answer_images":[],"unix_timestamp":1669646160,"question_id":141},{"id":"72ZuDxdaNSc7VIDWrusI","question_text":"A company needs to move data from an Amazon EC2 instance to an Amazon S3 bucket. The company must ensure that no API calls and no data are routed through public internet routes. Only the EC2 instance can have access to upload data to the S3 bucket.\n\nWhich solution will meet these requirements?","answer_ET":"A","choices":{"A":"Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.","B":"Create a gateway VPC endpoint for Amazon S3 in the Availability Zone where the EC2 instance is located. Attach appropriate security groups to the endpoint. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.","C":"Run the nslookup tool from inside the EC2 instance to obtain the private IP address of the S3 bucket’s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.","D":"Use the AWS provided, publicly available ip-ranges.json file to obtain the private IP address of the S3 bucket’s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access."},"question_images":[],"answer_description":"","discussion":[{"comments":[{"content":"It's possible:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/connect-s3-vpc-endpoint/","timestamp":"1671408000.0","upvote_count":"5","poster":"A_New_Guy","comment_id":"749308","comments":[{"timestamp":"1682707200.0","comments":[{"upvote_count":"2","content":"Create a security group that allows the resources in your VPC to communicate with the endpoint network interfaces for the VPC endpoint. To ensure that tools such as the AWS CLI can make requests over HTTPS from resources in the VPC to the AWS service, the security group must allow inbound HTTPS traffic.\n\n\nFor Security groups, select the security groups to associate with the endpoint network interfaces for the VPC endpoint. By default, we associate the default security group for the VPC.","poster":"smartegnine","comment_id":"916777","comments":[{"upvote_count":"4","poster":"slackbot","timestamp":"1692880860.0","comment_id":"989202","content":"this is valid for interface endpoint, not for gateway endpoint, which option B mentioned"}],"timestamp":"1686102780.0"},{"comment_id":"926305","upvote_count":"9","poster":"markw92","timestamp":"1687039320.0","content":"Gateway endpoint must be used as a target in a route table does not use security groups."},{"poster":"Guru4Cloud","timestamp":"1695201060.0","upvote_count":"2","comment_id":"1012137","content":"it is possible - you should do more reading"}],"comment_id":"883825","poster":"kruasan","upvote_count":"3","content":"No, it’s not"},{"upvote_count":"2","content":"Go to console and test it yourself! With Interface Endpoint you can add security groups.","poster":"Iconique","comment_id":"1017920","timestamp":"1695741960.0","comments":[{"upvote_count":"2","comment_id":"1305109","poster":"elmyth","timestamp":"1730311980.0","content":"interface VPC endpoint is A))))"}]}]}],"timestamp":"1669694940.0","comment_id":"729892","poster":"SSASSWS","content":"Selected Answer: A\nI think answer should be A and not B.\nas we cannot \"Attach a security groups to a gateway endpoint.\"","upvote_count":"41"},{"poster":"Buruguduystunstugudunstuy","comments":[{"timestamp":"1731936540.0","poster":"JA2018","content":"check this out: https://www.examtopics.com/discussions/amazon/view/83857-exam-aws-certified-solutions-architect-associate-saa-c02/\n\nSelected answer: B\n\nSo which is the correct answer?!!!!","comment_id":"1314010","upvote_count":"1"},{"comments":[{"timestamp":"1676615580.0","content":"There are two types VPC Endpoint:\n\nGateway endpoint\nInterface endpoint\n\nA Gateway endpoint:\n\n1) Helps you to securely connect to Amazon S3 and DynamoDB\n2) Endpoint serves as a target in your route table for traffic\n3) Provide access to endpoint (endpoint, identity and resource policies)\n\nAn Interface endpoint:\n\n1) Help you to securely connect to AWS services EXCEPT FOR Amazon S3 and DynamoDB\n2) Powered by PrivateLink (keeps network traffic within AWS network)\n3) Needs a elastic network interface (ENI) (entry point for traffic)","comments":[{"comment_id":"989203","upvote_count":"10","timestamp":"1692880980.0","poster":"slackbot","content":"interface endpoint exists for S3 as well"}],"comment_id":"811558","upvote_count":"35","poster":"ChrisG1454"},{"content":"An interface VPC endpoint does provide a direct connection between the EC2 instance and the S3 bucket. It enables private communication between instances in your VPC and resources in other services without requiring an internet gateway, a NAT device, or a VPN connection.\n\nOption A , which recommends creating an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located and attaching a resource policy to the S3 bucket to only allow the EC2 instance's IAM role for access, is the correct solution for the given scenario. It meets the requirement to ensure that no API calls and no data are routed through public internet routes and that only the EC2 instance can have access to upload data to the S3 bucket.","timestamp":"1672751820.0","comment_id":"764669","comments":[{"content":"In support, see https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","comment_id":"797652","timestamp":"1675492140.0","poster":"Omok","upvote_count":"8"}],"poster":"mhmt4438","upvote_count":"7"}],"timestamp":"1671819780.0","comment_id":"754416","content":"Option A is incorrect because an interface VPC endpoint for Amazon S3 would not provide a direct connection between the EC2 instance and the S3 bucket. \n\nOption C is incorrect because using the nslookup tool to obtain the private IP address of the S3 bucket's service API endpoint would not provide a secure connection between the EC2 instance and the S3 bucket. \n\nOption D is incorrect because using the ip-ranges.json file to obtain the private IP address of the S3 bucket's service API endpoint is not a secure method to connect the EC2 instance to the S3 bucket.","poster":"Buruguduystunstugudunstuy","upvote_count":"4"}],"comment_id":"754415","upvote_count":"36","content":"Selected Answer: B\nThe correct solution to meet the requirements is Option B. A gateway VPC endpoint for Amazon S3 should be created in the Availability Zone where the EC2 instance is located. This will allow the EC2 instance to access the S3 bucket directly, without routing through the public internet. The endpoint should also be configured with appropriate security groups to allow access to the S3 bucket. Additionally, a resource policy should be attached to the S3 bucket to only allow the EC2 instance's IAM role for access.","timestamp":"1671819780.0"},{"upvote_count":"1","comment_id":"1559534","poster":"7dcef09","content":"Selected Answer: B\nInterface Endpoint = AWS PrivateLink\nGateway Endpoint = Supports S3 and DynamoDB","timestamp":"1744279080.0"},{"upvote_count":"1","poster":"nadeerm","timestamp":"1741837680.0","comment_id":"1388170","content":"Reasons for B: \nSimplicity: Gateway VPC endpoints are easier to configure and manage compared to interface VPC endpoints.\nCost: Gateway VPC endpoints are free to use, whereas interface VPC endpoints incur costs for each hour and per GB of data processed.\nPerformance: Gateway VPC endpoints are highly scalable and optimized for S3 and DynamoDB traffic."},{"upvote_count":"1","poster":"chir827389_3","timestamp":"1739217180.0","comment_id":"1354629","content":"Selected Answer: A\ngateway endpoint does not have any SG."},{"poster":"certifiedlegend","comment_id":"1354184","timestamp":"1739152740.0","upvote_count":"1","content":"Selected Answer: B\nA VPC gateway endpoint is primarily used for accessing specific AWS services like Amazon S3 and DynamoDB privately within your VPC by specifying a route in your route table, while a VPC interface endpoint offers more flexible connectivity to a wider range of AWS services through AWS PrivateLink, allowing access from both within your VPC and from other VPCs using peering or Transit Gateways, typically with a dedicated private IP address within your VPC network; essentially, gateway endpoints are simpler and often free, while interface endpoints provide greater control and may incur additional costs depending on usage. \nGateway endpoints are ideal for simple private access to S3 and DynamoDB, while interface endpoints are better suited for more complex scenarios where you need to access various AWS services from different VPCs or on-premises networks."},{"upvote_count":"1","poster":"DeliKadir","timestamp":"1738543320.0","comment_id":"1350710","content":"Selected Answer: A\nEven though Amazon S3 typically uses a Gateway VPC Endpoint, AWS now provides Interface VPC Endpoints for Amazon S3 as well via AWS PrivateLink....and \"Attach a security groups to a gateway endpoint.\" makes the option B - false"},{"content":"Selected Answer: A\nB will be correct if removing the \"Attach appropriate security group to the endpoint\" and gateway point is free of charge.","poster":"FlyingHawk","timestamp":"1737423960.0","comment_id":"1343959","upvote_count":"1"},{"upvote_count":"1","comment_id":"1332259","content":"Selected Answer: B\nOption A uses an interface VPC endpoint, which is typically used for services that require a private IP address within your VPC. For S3, a gateway VPC endpoint is more appropriate and cost-effective1","poster":"MaxMingxing","timestamp":"1735280700.0"},{"upvote_count":"1","timestamp":"1735197240.0","poster":"hilker1983","comment_id":"1331822","content":"Selected Answer: B\nInterface VPC Endpoint: Interface endpoints are generally used for other AWS services and do not provide the same direct access optimization for S3 that gateway endpoints do."},{"upvote_count":"1","comment_id":"1331207","timestamp":"1735064700.0","poster":"LizavetaD","content":"Selected Answer: B\nIn this context, a Gateway VPC Endpoint is the correct choice for S3, as it provides direct, private access to S3 and routes traffic internally within the AWS networ"},{"comment_id":"1327841","timestamp":"1734429000.0","upvote_count":"1","content":"Selected Answer: B\nWhy Option B is Correct:\n\n Gateway VPC Endpoint for Amazon S3:\n S3 does not require an interface endpoint; it uses a gateway VPC endpoint.\n Gateway endpoints ensure that requests stay within the AWS network, meeting the requirement of no public internet routes.\n Resource Policy:\n Attaching a bucket policy ensures that only the EC2 instance's IAM role has access to the bucket.\n Appropriate Security Controls:\n The gateway endpoint can be secured further using policies and security group configurations.","poster":"dipenich"},{"content":"Selected Answer: A\nIt is A. Gateway endpoint route table. Interface endpoint uses security groups and private link. See aws video https://youtu.be/TqApkvJx5hw?si=9Gpk3V7OcPU6MVJI","upvote_count":"1","timestamp":"1734047880.0","poster":"ARV14","comment_id":"1325905"},{"poster":"SteveNguyen","content":"Selected Answer: B\ngateway VPC endpoint is used for connect from VPC to S3 and DynamoDB","upvote_count":"1","timestamp":"1733822520.0","comment_id":"1324465"},{"content":"Selected Answer: A\nYou might initially lean toward Option B since a gateway endpoint is generally the preferred solution for EC2 instances in the same region. It’s cost-effective (free), performance-optimized, and simpler to configure. However, for the exam, technical precision in details is crucial.\n\nOption B is incorrect because:\n\nGateway VPC endpoints are created at the VPC level, not at the Availability Zone level.\nSecurity groups must be attached to the EC2 instance (the source service) to allow outbound traffic using the prefix list associated with the gateway endpoint.\nDue to these reasons, Option A is the correct answer. While not ideal in real-world scenarios for EC2 instances in the same region, it is technically accurate and satisfies the exam's requirements.","comment_id":"1317887","upvote_count":"4","timestamp":"1732594380.0","poster":"FlyingHawk"},{"content":"Selected Answer: B\ncorrect ans is B","comment_id":"1315733","upvote_count":"1","timestamp":"1732181160.0","poster":"Garryg"},{"comments":[],"comment_id":"1311156","content":"you cannot attach a security group to a gateway VPC endpoint. Security groups can only be attached to interface VPC endpoints-- so option B is wrong \nOption A won’t work because an interface VPC endpoint for Amazon S3 is not supported. Amazon S3 only supports gateway VPC endpoints. Interface VPC endpoints are used for services that are powered by AWS PrivateLink, which is not applicable to S3.\nThere is something wrong with options provided","timestamp":"1731483720.0","poster":"jayessh","upvote_count":"2"},{"upvote_count":"2","content":"B have \"Attach appropriate security groups to the endpoint\"\nGateway Endpoints: Provisions a gateway and must be used as a target in a route table (does not use security groups)\nso B is incorrect and A is correct$","timestamp":"1730899380.0","poster":"MALEK00","comment_id":"1307875"},{"upvote_count":"1","timestamp":"1730805000.0","poster":"Mish","content":"Selected Answer: B\nB. Create a gateway VPC endpoint for Amazon S3 in the Availability Zone where the EC2 instance is located. Attach appropriate security groups to the endpoint. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.","comment_id":"1307325"},{"poster":"Cmtan","upvote_count":"1","timestamp":"1727271120.0","comment_id":"1289020","content":"Selected Answer: A\nGateway endpoint for S3 Use Amazon S3 public IP addresses, while interface endpoint use private IP addresses from your VPC to access Amazon S3. As mentioned, no traffic is allowed through the public route, so ANS is A"},{"poster":"bignatov","comment_id":"1285654","content":"Selected Answer: A\nI vote for A, because there is no option to attach security group for gateway vpc endpoint. Apart from that in most cases gateway endpoint is preferable for S3, but this little detail about the security group changes my answer for A. Gateway endpoints uses routing tables instead security groups.","upvote_count":"2","timestamp":"1726650180.0"},{"upvote_count":"2","content":"Selected Answer: B\nInterface VPC endpoints are more suited for services that require private connectivity via a network interface. For S3, a Gateway VPC Endpoint is more appropriate and cost-effective since it integrates at the route table level without requiring additional cost per endpoint.","timestamp":"1724903580.0","poster":"OlehKom","comment_id":"1274331"},{"timestamp":"1724442300.0","content":"Selected Answer: A\nits A, private equals interfsce. https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","poster":"SamDevNation","upvote_count":"1","comment_id":"1271432"},{"comment_id":"1260348","upvote_count":"2","content":"Answer Should be B. You can attached security group with VPC endpoint. This is not the point. For S3 you need to create gateway VPC endpoint not interface VPC endpoint.","poster":"AWS_Debu","timestamp":"1722695940.0"},{"content":"Gateway endpoints do not enable AWS PrivateLink. So the answer is A.","poster":"tom_cruise","timestamp":"1722446700.0","upvote_count":"1","comment_id":"1259014"},{"comment_id":"1257786","upvote_count":"1","poster":"sonlduet","timestamp":"1722306960.0","content":"It's definitely A, B is wrong because we configure route table for Gateway VPC Endpoint, not security group or subnet"},{"poster":"jatric","content":"Selected Answer: B\nGateway endpoint would be sufficient here which is specifically for S3 and dynamo DB and don't incurr any charges. Interface VPC endpoint might be usefull if a scneario with cross region or on-premises connectivity within private VPC\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html","comment_id":"1244620","upvote_count":"2","timestamp":"1720484520.0"},{"upvote_count":"2","content":"Selected Answer: A\nThe wording in B says create a gateway VPC endpoint in the AZ, surely it should say in the VPC......\nL","timestamp":"1720455240.0","comment_id":"1244460","poster":"Hightower_IT"},{"timestamp":"1719449460.0","upvote_count":"1","comment_id":"1237813","content":"Selected Answer: A\nA for sure","poster":"ChymKuBoy"},{"upvote_count":"3","content":"Selected Answer: B\nDynamoDB & S3 uses Gateway VPC endpoint (not interface)","timestamp":"1719054000.0","comment_id":"1235342","poster":"a7md0"},{"content":"Selected Answer: A\nYou associate a gateway endpoint with a VPC and its subnets (so the prefix list can be added to the appropriate routing tables). You cannot specify an AZ or associate an SG when creating a gateway endpoint.","timestamp":"1718570820.0","upvote_count":"4","comment_id":"1231540","poster":"Duckydoo"},{"upvote_count":"2","timestamp":"1718123040.0","content":"Selected Answer: A\nIt must be Interface VPC endpoint. As the Gateway VPC endpoint requires a S3 pubilc IP address to work:\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html\n\nIf the bucket has a public IP address, it means the bucket is publicy accessible, which is not the case here.","comment_id":"1228527","poster":"Rhydian25"},{"comment_id":"1226538","upvote_count":"2","poster":"rohitph","timestamp":"1717823280.0","content":"Selected Answer: A\nwe cannot \"Attach a security groups to a gateway endpoint.\""},{"timestamp":"1716901440.0","upvote_count":"2","comment_id":"1220270","poster":"lofzee","content":"im almost certain that the answers in this question are written slightly wrong.\nthere is no reason (based on the question), for you to select A.\nOnly EC2 needs access to S3, 99% of the time you'd use a gateway endpoint.\n\nReasons you might use an interface endpoint are:\n- requirement of on-premise access to S3\n- requirement of access from another VPC in another region using peering or transit gateway\n- requirement of using specific endpoint S3 DNS names\n- use of private IPs from your VPC to access S3\n\nbased on the above, i believe the answer to be B, its just written incorrectly with the addition of the security groups part."},{"upvote_count":"1","content":"Selected Answer: A\nOption A as security group is not applicable for Gateway end point.","comment_id":"1206922","timestamp":"1714918500.0","poster":"ManikRoy"},{"poster":"Solomon2001","content":"Selected Answer: A\nExplanation:\n\nOption A:\nInterface VPC endpoint for Amazon S3 ensures that the data transfer between the EC2 instance and the S3 bucket stays within the AWS network, avoiding the public internet.\nBy attaching a resource policy to the S3 bucket to only allow access from the EC2 instance's IAM role, you ensure that only the EC2 instance can upload data to the S3 bucket.\nOption B:\n\nGateway VPC endpoint for Amazon S3 doesn't ensure that the data transfer stays within the AWS network; it can still use the public internet.\nAlthough you can attach security groups to the endpoint, it doesn't guarantee that the data transfer won't use public internet routes.","timestamp":"1714885320.0","upvote_count":"1","comment_id":"1206776"},{"comment_id":"1204109","timestamp":"1714406700.0","poster":"7ce90e0","upvote_count":"2","content":"Selected Answer: B\nB. Interface endpoints are for private link and require ip address. gateway endpoints are for internal services and don't need ip address. https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/what-are-vpc-endpoints.html"},{"timestamp":"1713088020.0","comment_id":"1195424","content":"Selected Answer: A\nOption B is confusing but not after you see the fine-print. \n - User cannot create Gateway endpoint in any specific Availability Zone, User only specify under which VPC it needs to be created. \n - User do not select/attach security group to Gateway Endpoint, as this gateway only works be adding destination prefix list(S3) to gateway endpoint route.\n\nCorrect Answer: A","upvote_count":"4","poster":"MehulKapadia"},{"timestamp":"1712054760.0","upvote_count":"1","comment_id":"1187974","content":"Answer B\nWhat is VPC gateway endpoint\nConsider a scenario where you have to access S3 from your EC2 instance in a public subnet. As the subnet has an internet gateway attached, the traffic to S3 will go through the public internet. However, the problem arises if your instance is in a private subnet and does not have any NAT gateway/instance attached or you cannot afford charges of NAT gateway. Currently, AWS S3 and DynamoDB are the only services supported by gateway endpoints. Using Gateway endpoints does not incur any data processing or hourly charges.","poster":"NishantM"},{"poster":"scar0909","upvote_count":"1","content":"Selected Answer: B\nvpc gateway endpoint","timestamp":"1710039060.0","comment_id":"1170016"},{"upvote_count":"1","timestamp":"1708951980.0","comment_id":"1159733","content":"Selected Answer: A\nI used to think that gatway endpoints were only for s3 and dynamodb, but I guess thats not the whole story. S3 can use interface endpoints, and they are privately routed.\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","poster":"TheFivePips"},{"timestamp":"1706747640.0","upvote_count":"3","comment_id":"1137168","content":"Selected Answer: A\nOption B is wrong:\n- you cannot attach security groups to gateway VPC endpoint\n- you cannot create gateway VPC endpoint in the Availability Zone","poster":"frmrkc"},{"content":"Selected Answer: B\nThe main difference between an interface VPC endpoint and a gateway VPC endpoint is how traffic is routed to AWS services outside the VPC:\n\nInterface VPC Endpoint:\n\nUses an Elastic Network Interface (ENI) within your VPC subnets to allow communication between your VPC and AWS services.\n\nWhen you create an interface endpoint, a private IP address is assigned to the ENI that acts as the entry point for traffic destined to the AWS service.\n\nDNS queries for the service are routed to the private IP address of the ENI, avoiding the public internet.","poster":"thewalker","timestamp":"1706685600.0","upvote_count":"1","comments":[{"content":"Gateway VPC Endpoint:\n\nAdds an entry in your VPC route table that defines the service as a valid destination and routes traffic to it.\n\nTraffic destined for the service leaves your VPC and travels across the AWS global network to the service.\n\nGateway endpoints currently only support S3 and DynamoDB. Interface endpoints support many more AWS services.\n\nSome key points to consider when choosing an endpoint type include availability of the service, need for cross-region access, and whether traffic needs to flow from on-premises.","timestamp":"1706685600.0","upvote_count":"2","comment_id":"1136489","poster":"thewalker"}],"comment_id":"1136488"},{"comment_id":"1134670","content":"Selected Answer: A\nInterface Endpoints are used for accessing AWS services within the same region over the AWS PrivateLink network, while Gateway Endpoints are used for providing private connectivity to specific AWS services outside your VPC. Each serves a distinct purpose based on the type of service and the desired network architecture.","poster":"Charumathi","upvote_count":"1","timestamp":"1706506680.0"},{"content":"Answer should be B\nhttps://k21academy.com/amazon-web-services/aws-solutions-architect/aws-gateway-endpoints/","upvote_count":"1","comment_id":"1133025","timestamp":"1706325780.0","poster":"prudhvi08"},{"content":"Selected Answer: A\nI choose A because this phrase \"no API calls and no data are routed through PUBLIC INTERNET routes\"\nYou can use two types of VPC endpoints to access Amazon S3: gateway endpoints and interface endpoints (by using AWS PrivateLink). A gateway endpoint is a gateway that you specify in your route table to access Amazon S3 from your VPC over the AWS network. Interface endpoints extend the functionality of gateway endpoints by using PRIVATE IP addresses to route requests to Amazon S3 from within your VPC, on premises, or from a VPC in another AWS Region by using VPC peering or AWS Transit Gateway.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html","comment_id":"1114214","upvote_count":"1","timestamp":"1704423060.0","poster":"ThongHM"},{"upvote_count":"1","content":"Selected Answer: A\nBoth A and B are close. I prefer A but B also seems to work as both have configurable security and limit traffic to within AWS network. I don't have a test account now but for Gateway end-point, I suspect that the security group will force you to allow traffic on public IP.\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html#gateway-endpoint-security\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html#gateway-endpoint-security","timestamp":"1704118260.0","poster":"awsgeek75","comment_id":"1111243"},{"upvote_count":"3","timestamp":"1703666760.0","content":"Selected Answer: A\nB is wrong because question does NOT ask that no data is \"transferred over public Internet\", it asks that no data is \"routed through public internet routes (!)\". Gateway VPC Endpoint uses public IP, thus from VPC perspective the traffic would hit a \"public internet route\", even if AWS would route the traffic internally.\n\nBesides, you don't create a Gateway VPC endpoint 'in an Availability Zone'.","comment_id":"1106672","poster":"pentium75"},{"timestamp":"1703485800.0","comment_id":"1105058","upvote_count":"1","poster":"jAtlas7","content":"Selected Answer: B\nVoting B (use gateway endpoint) on the basis that, to enable private connection between VPC and S3, one may either:\noption 1: interface VPC endpoint -> AWS PrivateLink -> S3\noption 2: gateway VPC endpoint -> S3\ni.e. Answer A (interface endpoint) would have been ok if it mentions the use of PrivateLink - unfortunately answer A doesn't mention PrivateLink.\nAnswer B (interface endpoint) is basically option 1 - and therefore Answer B appears to be best answer.\nRef: https://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/"},{"comment_id":"1097447","timestamp":"1702654020.0","upvote_count":"1","content":"Selected Answer: A\nAnswer is A, Option B is wrong as with Gateway Endpoint you need to set up also the Route Table to use to reach the endpoint resource (S3 or DynamoDB) and not the security groups.","poster":"ale_brd_111"},{"comment_id":"1096671","timestamp":"1702573200.0","poster":"osmk","upvote_count":"1","content":"https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html#gateway-endpoint-considerations-s3\n\nThe rules for the security groups for your instances that access Amazon S3 through a gateway endpoint must allow traffic to and from Amazon S3. You can reference the ID of the prefix list for Amazon S3 in security group rules."},{"poster":"v_rainbow","timestamp":"1702231920.0","upvote_count":"3","content":"Selected Answer: A\nWhile gateway endpoints also provide private connectivity, they are designed to be used by multiple resources within the VPC. This adds complexity and is not necessary for this scenario where only one EC2 instance needs access.","comment_id":"1092723"},{"poster":"ansagr","content":"Selected Answer: A\nYou cannot attach security groups to VPC gateway endpoints. For VPC gateway endpoints (like S3 or DynamoDB), you typically rely on route tables and IAM policies for access control.","timestamp":"1702216260.0","upvote_count":"1","comment_id":"1092523"},{"poster":"MiniYang","timestamp":"1701320160.0","comment_id":"1084001","upvote_count":"1","content":"Selected Answer: A\nWhen you need to ensure that only specific Amazon EC2 instances can access your Amazon S3 bucket, but do not allow data to be routed over the public internet, you can consider the following two key concepts:\nVPC Endpoint:VPC endpoints are a way for EC2 instances to privately communicate with AWS services within your virtual private cloud (VPC). For Amazon S3, you can create an interface VPC endpoint, which allows EC2 instances to access S3 directly through a network connection within the VPC instead of going through the public Internet.\nIAM roles and S3 access control:You can use AWS Identity and Access Management (IAM) to control EC2 instance access to S3 buckets. You can grant EC2 instances access to S3 by assigning them specific IAM roles. At the same time, you can set a resource policy (Resource Policy) on the S3 bucket to only allow specific IAM roles or specific EC2 instances to access."},{"poster":"MiniYang","timestamp":"1701319620.0","upvote_count":"1","content":"Selected Answer: A\nThis method creates a VPC endpoint in a specific subnet, ensuring that only EC2 instances in that subnet can access S3 through the VPC endpoint. This approach ensures more precise control that only EC2 instances in a specific subnet can upload data to S3, while also complying with the requirement that it not be routed through the public Internet.","comment_id":"1083994"},{"poster":"lucasbg","timestamp":"1701196800.0","content":"Definitly A since you cant attach a security group to a gateway endpoint, only to an ENI.","upvote_count":"1","comment_id":"1082850"},{"poster":"Marco_St","timestamp":"1701061140.0","content":"Selected Answer: A\nI voted A since the question did not mention LEAST cost operation. interface VPC endpoint can be used for most services while it is not free. Gateway VPC endpoint is free and only for S3 and AWS DynamoDB. But Gateway Endpoint is not using security group to control the access, it is using route table. Security group is required for interface VPC endpoint which provides an ENI and needs security group. So A","comment_id":"1081210","upvote_count":"2"},{"upvote_count":"1","timestamp":"1697819880.0","comment_id":"1048950","poster":"ivan_riqueros12","content":"Selected Answer: B\nB. The endpoint should also be configured with appropriate security groups to allow access to the S3 bucket"},{"upvote_count":"1","content":"Option B\nB. Create a gateway VPC endpoint for Amazon S3 in the Availability Zone where the EC2 instance is located. Attach appropriate security groups to the endpoint. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.\n\nThis solution ensures that the traffic between the EC2 instance and S3 bucket does not leave the Amazon network, meeting the company's requirement for no data to be routed through the public internet. The use of security groups and resource policies ensures that only the specified EC2 instance has access to the S3 bucket.","poster":"Phoese","timestamp":"1697718600.0","comment_id":"1047892"},{"poster":"Wayne23Fang","content":"Selected Answer: B\nBut first phrase in (A) is wrong: Interface Endpoint doesn't work for the case.","upvote_count":"1","comment_id":"1041727","timestamp":"1697114400.0"},{"poster":"Ramdi1","content":"Selected Answer: B\nGateway VPC endpoints provide reliable connectivity to Amazon S3 and DynamoDB without requiring an internet gateway or a NAT device for your VPC","upvote_count":"1","comment_id":"1023879","timestamp":"1696332540.0"},{"comment_id":"1019433","upvote_count":"1","poster":"vijaykamal","content":"Selected Answer: A\nOption B mentions creating a gateway VPC endpoint for Amazon S3, but gateway endpoints are primarily used for routing traffic to Amazon S3 over Direct Connect or VPN connections, and they don't support attaching security groups. It's also essential to restrict access with a resource policy on the S3 bucket, which is not mentioned in option B.\n\nOptions C and D suggest alternative approaches using DNS resolution and VPC route tables, but these options may not provide the same level of security and isolation as the interface VPC endpoint in option A. Additionally, these options are more complex to set up and maintain.","timestamp":"1695877320.0"},{"poster":"Mandar15","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","upvote_count":"1","timestamp":"1695742860.0","comment_id":"1017938"},{"poster":"Mandar15","upvote_count":"1","timestamp":"1695742740.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","comment_id":"1017934"},{"poster":"JKevin778","content":"Selected Answer: B\nGateway Endpoint for S3 and DynamoDB, So B","timestamp":"1695586500.0","comment_id":"1016153","upvote_count":"2"},{"content":"Selected Answer: B\nB is the correct answer.\n\nTo meet the requirements of no public internet access and only allowing the EC2 instance access, the solution is to:\n\nCreate a gateway VPC endpoint for S3 in the subnet where the EC2 instance is located. This keeps S3 access within the VPC and does not route via the internet.\nAttach appropriate security groups to the endpoint to control access.\nUse a S3 bucket resource policy to only allow access from the EC2 instance IAM role.","upvote_count":"2","timestamp":"1695201000.0","poster":"Guru4Cloud","comment_id":"1012131"},{"upvote_count":"1","timestamp":"1695097440.0","content":"Selected Answer: A\nYou can provision interface endpoints for s3.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#:~:text=With-,AWS%20PrivateLink,-for%20Amazon%20S3","poster":"TariqKipkemei","comment_id":"1011048"},{"content":"B is correct,The outbound rules for the security group for instances that access Amazon S3 through the gateway endpoint must allow traffic to Amazon S3. You can use the prefix list ID for Amazon S3 as the destination in the outbound rule.","poster":"5ab5e39","comment_id":"1001614","upvote_count":"1","timestamp":"1694094060.0"},{"upvote_count":"2","poster":"ukivanlamlpi","comments":[{"content":"Interface endpoint exists\nhttps://youtu.be/TqApkvJx5hw","poster":"skh015","upvote_count":"1","comment_id":"994553","timestamp":"1693438020.0"}],"comment_id":"985040","content":"Selected Answer: B\nnothing call interface VPC endpoint for s3, only gateway interface VPC for s3","timestamp":"1692429960.0"},{"comment_id":"965223","content":"Both the Interface Endpoint and Gateway Endpoint are forms of VPC Endpoint. The earlier is located inside a subnet and connected to a security group; the subsequent is located inside a VPC and connected to a routing table.","timestamp":"1690511100.0","upvote_count":"2","poster":"A1975"},{"poster":"aadityaravi8","timestamp":"1688956980.0","comment_id":"947683","content":"you cannot directly attach security groups to VPC endpoints in AWS.\nHence Option A is the right choice.","upvote_count":"2"},{"poster":"minkian_","comment_id":"945567","content":"Selected Answer: A\n정답은 A 입니다 게이트웨이 엔드포인트는 Private Link 를 지원하지 않습니다 \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","timestamp":"1688726640.0","upvote_count":"1"},{"timestamp":"1687998480.0","upvote_count":"4","poster":"darren_song","content":"Selected Answer: B\nPlease refer to the following documents :\n\nhttps://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/what-are-vpc-endpoints.html\n\nhttps://repost.aws/knowledge-center/connect-s3-vpc-endpoint\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html\n\nhttps://digitalcloud.training/vpc-interface-endpoint-vs-gateway-endpoint-in-aws/","comment_id":"937279"},{"content":"Selected Answer: B\nThere is no additional charge for using gateway endpoints.\n\nAmazon S3 supports both gateway endpoints and interface endpoints. With a gateway endpoint, you can access Amazon S3 from your VPC, without requiring an internet gateway or NAT device for your VPC, and with no additional cost. However, gateway endpoints do not allow access from on-premises networks, from peered VPCs in other AWS Regions, or through a transit gateway. For those scenarios, you must use an interface endpoint, which is available for an additional cost.\n\nThe topic mentioned no API or other public network service should access to S3.\nSo Gateway endpoint should be better.","poster":"Mia2009687","upvote_count":"3","comment_id":"937215","timestamp":"1687993260.0"},{"content":"Selected Answer: A\nBy creating an interface VPC endpoint for Amazon S3 in the same subnet as the EC2 instance, the data transfer between the EC2 instance and S3 can occur privately within the Amazon network, without traversing the public internet. This ensures secure and direct communication between the EC2 instance and S3. Attaching a resource policy to the S3 bucket that allows access only from the IAM role associated with the EC2 instance further restricts access to only the authorized instance.\n\nB. Creating a gateway VPC endpoint for Amazon S3 would still involve routing through the public internet, which is not desired in this case.\n\nC. Running nslookup or creating a specific route in the VPC route table does not provide the desired level of security and privacy, as the traffic may still traverse public internet routes.\n\nD. Using the publicly available ip-ranges.json file to obtain the private IP address of the S3 bucket's service API endpoint is not a recommended approach, as IP addresses can change over time, and it does not provide the same level of security as using VPC endpoints.","comment_id":"935531","timestamp":"1687878900.0","upvote_count":"2","poster":"cookieMr"},{"upvote_count":"1","poster":"abhishek2021","timestamp":"1686654960.0","comment_id":"922172","content":"Selected Answer: A\nsecurity group cannot be associated with Gateway Endpoint. so, the answer is A."},{"upvote_count":"3","poster":"smartegnine","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/create-interface-endpoint.html\n\nCreate a security group that allows the resources in your VPC to communicate with the endpoint network interfaces for the VPC endpoint. To ensure that tools such as the AWS CLI can make requests over HTTPS from resources in the VPC to the AWS service, the security group must allow inbound HTTPS traffic.\n\nFor Security groups, select the security groups to associate with the endpoint network interfaces for the VPC endpoint. By default, we associate the default security group for the VPC.","comment_id":"916780","timestamp":"1686102900.0"},{"timestamp":"1685581140.0","upvote_count":"3","comment_id":"911635","content":"Selected Answer: B\nYou cannot use Interface Endpoint for S3 or DynamoDB. It has to bee the Gateway endpoints. See the diagram: https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/what-are-vpc-endpoints.html","poster":"Peng001"},{"poster":"ErnShm","timestamp":"1685181600.0","comment_id":"907888","upvote_count":"1","content":"It's absolutely A, security group can't be attached to the VPC Endpoint gateway"},{"comment_id":"889355","content":"Selected Answer: A\nChatGPT:\n\nOption B is not the best solution because it involves creating a gateway VPC endpoint for Amazon S3. Gateway VPC endpoints only support Amazon S3 and DynamoDB and do not support private DNS. This means that requests to the S3 bucket would still be routed over the internet. On the other hand, an interface VPC endpoint, as described in option A, supports private DNS and allows traffic between the VPC and the service to remain within the Amazon network. This ensures that no API calls and no data are routed through public internet routes.","comments":[{"comment_id":"905640","upvote_count":"2","timestamp":"1684916640.0","content":"that answer is completely wrong!!!! Don't rely on ChatGPT, use the documentation available and think yourself. Reference: https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html (look into 'Considerations' section)","poster":"ruqui"}],"upvote_count":"2","poster":"Abhineet9148232","timestamp":"1683205080.0"},{"upvote_count":"3","timestamp":"1680941160.0","poster":"datz","content":"Selected Answer: B\nAnswer: B\n\nWhat is VPC gateway endpoint\nConsider a scenario where you have to access S3 from your EC2 instance in a public subnet. As the subnet has an internet gateway attached, the traffic to S3 will go through the public internet. However, the problem arises if your instance is in a private subnet and does not have any NAT gateway/instance attached or you cannot afford charges of NAT gateway. Currently, AWS S3 and DynamoDB are the only services supported by gateway endpoints. Using Gateway endpoints does not incur any data processing or hourly charges.\n\nhttps://digitalcloud.training/vpc-interface-endpoint-vs-gateway-endpoint-in-aws/","comment_id":"864539"},{"poster":"Steve_4542636","timestamp":"1677602520.0","upvote_count":"2","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3. Gateway endpoints use public s3 ip addresses","comment_id":"825039"},{"comment_id":"795071","content":"Answer is A is correct. U cannot attaach security group to Gateway Endpoint. Note that Gateway Endpoint do not create ENI in your subnet, hence no Security group can be attached. You can create IAM policy to allow only IAM Role to access to AWS. (https://aws.amazon.com/blogs/security/how-to-restrict-amazon-s3-bucket-access-to-a-specific-iam-role/)","poster":"kerl","upvote_count":"2","timestamp":"1675253100.0"},{"comment_id":"794975","timestamp":"1675244820.0","content":"Selected Answer: A\nA - Because we can not configure a SG on an gateway endpoint\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html","upvote_count":"1","poster":"JohnnyBG"},{"upvote_count":"1","comment_id":"766482","poster":"aba2s","timestamp":"1672912020.0","content":"Selected Answer: A\nInterface Endpoint use private IP adresses from VPC to acces S3. IE use private AWS PrivateLink"},{"comment_id":"763600","poster":"Zerotn3","timestamp":"1672648860.0","upvote_count":"1","comments":[{"upvote_count":"1","poster":"Zerotn3","comments":[{"timestamp":"1673230260.0","content":"Even Interface VPC endpoint can be use to access service such as S3 or SNS outside of the VPC. The reasoning in Option B is not correct.","comment_id":"769984","upvote_count":"1","poster":"Mahadeva"},{"comment_id":"796576","poster":"Bofi","upvote_count":"1","content":"You can access Amazon S3 from your VPC using gateway VPC endpoints. After you create the gateway endpoint, you can add it as a target in your route table for traffic destined from your VPC to Amazon S3.\n\nReason for B is absolutely wrong","timestamp":"1675385580.0"}],"content":"Attaching a resource policy to the S3 bucket allows you to specify which IAM entities are allowed to access the bucket and what actions they can perform on the bucket and its contents. In this case, you can specify that only the EC2 instance’s IAM role has access to the bucket.\n\nOption B is incorrect because a gateway VPC endpoint is used to access resources outside of the VPC, such as an on-premises data center. It is not used to access resources within the VPC.\n\nOption C is incorrect because the nslookup tool is used to find the IP address associated with a domain name. It is not used to obtain the private IP address of the S3 bucket’s service API endpoint.\n\nOption D is incorrect because the ip-ranges.json file contains the IP address ranges for all AWS services. It does not contain the private IP address of the S3 bucket’s service API endpoint. Additionally, using a publicly available IP address range to create a route in the VPC route table would not meet the requirement to ensure that no data is routed through public internet routes.","comment_id":"763601","timestamp":"1672648860.0"}],"content":"Selected Answer: A\nThe correct answer is A. Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.\n\nA VPC endpoint allows you to create a private connection between your VPC and another service without requiring access over the internet, a NAT device, or a VPN connection. An interface VPC endpoint is a network interface that you can create in your VPC that serves as an entry point for incoming traffic. You can use an interface VPC endpoint to access resources in the service, such as an Amazon S3 bucket."},{"timestamp":"1672190160.0","content":"Selected Answer: A\nFrom what I understand, you can create security groups for interface endpoints because they use an ENI, but you cannot create security groups for gateway endpoints as they do not use ENIs. So I would go with A","upvote_count":"3","comment_id":"759234","poster":"Mimikabs"},{"content":"B is wrong as it is not created in just an AZ, but specifically in a VPC","comment_id":"751605","upvote_count":"1","poster":"amsimann","timestamp":"1671576900.0"},{"poster":"romko","timestamp":"1671442980.0","upvote_count":"3","comments":[{"timestamp":"1673230920.0","upvote_count":"1","content":"Similarly to enable interface VPC endpoint, the Security Group must be attached, which is not mentioned in Option A. Actually both interface and gateway VPC endpoints can access AWS service outside of VPC.","comment_id":"769988","poster":"Mahadeva"}],"comment_id":"749685","content":"Selected Answer: A\nBoth (Gateway and Interface) VPC endpoints allow to access S3 privately over AWS network.\nVPC gateway usually is preferred when private access to S# is needed form EC2 in some VPC, because it free of charge, easy to set up and scalable.\n\nTo setup properly access via gateway VPC endpoint is required to edit route tables, but in answer choice it's not mentioned, so without it connection will not work.\n\nSo by elimination we may select A as correct answer."},{"comment_id":"747841","comments":[{"upvote_count":"2","timestamp":"1671566940.0","content":"I stated it incorrectly. B that says VPC Gateway end point is the right answer.","comment_id":"751424","poster":"career360guru"}],"timestamp":"1671261600.0","poster":"career360guru","content":"Selected Answer: A\nA Interface endpoint is the right answer.\nB is incorrect because though VPC endpoint keep the traffic within Amazon network, it will use S3 Public IP address which may not be acceptable in this case.","upvote_count":"1"},{"timestamp":"1671260760.0","content":"Selected Answer: A\nCorrect is: Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access. WHY: EC2 instance access S3 bucket directly over the AWS network without routing data over the public internet. VPC endpoint helps you to securely connect your VPC to another service.","comment_id":"747835","poster":"NikaCZ","upvote_count":"1"},{"comments":[{"poster":"KADSM","comment_id":"743599","timestamp":"1670907300.0","content":"VPC endpoints (Gateway or Interface) will not allow the data to traverse through internet.","upvote_count":"2"}],"poster":"Shasha1","timestamp":"1670852880.0","comment_id":"742866","content":"A\nOption A allow the EC2 instance to access the S3 bucket directly over the AWS network without routing data over the public internet.\nOption B is not correct because a gateway VPC endpoint for Amazon S3 will not provide the EC2 instance with direct access to the S3 bucket over the AWS network. Instead, a gateway VPC endpoint will route data over the public internet, which is not allowed in this scenario.","upvote_count":"1"},{"upvote_count":"3","comment_id":"732642","content":"VPC Endpoint helps you to securely connect your VPC to another service.\n\nThere are two types\n\nGateway endpoint\nInterface endpoint\nA Gateway endpoint:\n\nHelp you to securely connect to Amazon S3 and DynamoDB\nEndpoint serves as a target in your route table for traffic\nProvide access to endpoint (endpoint, identity and resource policies)\nAn Interface endpoint:","timestamp":"1669900560.0","poster":"DWISE1"},{"upvote_count":"1","poster":"JCH760310","timestamp":"1669753500.0","content":"I'm confused: see question #4 - gateway VPC endpoint","comment_id":"730827"},{"comments":[{"poster":"A_New_Guy","timestamp":"1671408060.0","upvote_count":"2","content":"It's support it:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/connect-s3-vpc-endpoint/","comment_id":"749309"}],"timestamp":"1669678920.0","content":"Selected Answer: A\nAnswer A . Gateway endpoint doent support Security group.","poster":"jambajuice","comment_id":"729719","upvote_count":"3"},{"content":"Selected Answer: A\nI choose A","comments":[{"comments":[{"content":"no SG for gateway","poster":"mj98","comment_id":"732016","timestamp":"1669844640.0","upvote_count":"2"}],"poster":"leonnnn","content":"I think it's B after some more considering.","upvote_count":"1","comment_id":"729756","timestamp":"1669682880.0"}],"comment_id":"729371","poster":"leonnnn","upvote_count":"1","timestamp":"1669652460.0"},{"content":"Selected Answer: B\nAnswer : B","comment_id":"729236","timestamp":"1669646280.0","upvote_count":"3","poster":"Nigma","comments":[{"timestamp":"1670930100.0","upvote_count":"1","content":"Provisions a gateway and must be used as a target in a route table (does not use security groups)","poster":"kmliuy73","comment_id":"743927"}]}],"answers_community":["A (58%)","B (42%)"],"answer_images":[],"answer":"A","timestamp":"2022-11-28 15:38:00","unix_timestamp":1669646280,"question_id":142,"url":"https://www.examtopics.com/discussions/amazon/view/89088-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"isMC":true,"topic":"1"},{"id":"ARlVU8QgG1bpoqYLaVQ4","choices":{"D":"Use the GetSessionToken API operation in AWS Security Token Service (AWS STS) to manage the session.","B":"Use session affinity (sticky sessions) of the ALB to manage session data.","A":"Use Amazon ElastiCache to manage and store session data.","C":"Use Session Manager from AWS Systems Manager to manage the session."},"url":"https://www.examtopics.com/discussions/amazon/view/89089-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"answer_ET":"A","question_id":143,"answer":"A","isMC":true,"discussion":[{"content":"Selected Answer: A\nThe correct answer is A. Use Amazon ElastiCache to manage and store session data.\n\nIn order to support distributed session data management in this scenario, it is necessary to use a distributed data store such as Amazon ElastiCache. This will allow the session data to be stored and accessed by multiple EC2 instances across multiple Availability Zones, which is necessary for a scalable and highly available architecture.\n\nOption B, using session affinity (sticky sessions) of the ALB, would not be sufficient because this would only allow the session data to be stored on a single EC2 instance, which would not be able to scale across multiple Availability Zones.\n\nOptions C and D, using Session Manager and the GetSessionToken API operation in AWS STS, are not related to session data management and would not be appropriate solutions for this scenario.","comment_id":"754407","upvote_count":"34","timestamp":"1687536420.0","poster":"Buruguduystunstugudunstuy"},{"timestamp":"1710830100.0","poster":"TariqKipkemei","comment_id":"1011053","comments":[{"poster":"Cloud_A","timestamp":"1720900560.0","comment_id":"1122067","content":"https://aws.amazon.com/elasticache/#:~:text=Store%20ephemeral%20session%20data%20to%20quickly%20personalize%20gaming%2C%20e%2Dcommerce%2C%20social%20media%2C%20and%20online%20applications%20with%20microsecond%20response%20times.","upvote_count":"2"}],"upvote_count":"5","content":"Selected Answer: A\nYap agree with go you guys, this is one of the use cases for Amazon ElastiCache.\nIt was designed to store ephemeral session data to quickly personalize gaming, e-commerce, social media, and online applications with microsecond response times.\nhttps://aws.amazon.com/elasticache/#:~:text=Store-,ephemeral,-session%20data%20to"},{"content":"Selected Answer: A\nA is the correct answer because it allows to manage distributed sessions","timestamp":"1730115660.0","comment_id":"1203494","poster":"Hkayne","upvote_count":"3"},{"timestamp":"1719836160.0","comment_id":"1111249","content":"Selected Answer: A\nA is in scope of question as company is willing to make code changes. \nB would have been correct if no code changes were allowed and scaling could be compromised.\nC is wrong technology (cloud management)\nD is also wrong technology (AWS IAM or account management).","poster":"awsgeek75","upvote_count":"5"},{"upvote_count":"3","content":"A is correct\nB is not correct as session affinity allow web user stick to a EC2 instance for a period time, that EC2 could go down then the session data will lost, so doesn't fit this use case\nC is wrong as Session Manager is for admins users to manage EC2 CLI access, it's not for web end users\nD is wrong as GetSessionToken API is for use case such as you need to grant user access to a S3 bucket with customized code","poster":"Michael_Li","comment_id":"1089916","timestamp":"1717721280.0"},{"timestamp":"1710188040.0","comment_id":"1005084","content":"Selected Answer: A\nThe correct answer is A. Use Amazon ElastiCache to manage and store session data.","poster":"Guru4Cloud","upvote_count":"2"},{"comment_id":"945531","poster":"cookieMr","timestamp":"1704626580.0","content":"Selected Answer: A\nElastiCache is a managed in-memory data store service that is well-suited for managing session data in a distributed architecture. It provides high-performance, scalable, and durable storage for session data, allowing multiple EC2 instances to access and share session data seamlessly. By using ElastiCache, the application can offload the session management workload from the EC2 instances and leverage the distributed caching capabilities of ElastiCache for improved scalability and performance.\n\nOption B, using session affinity (sticky sessions) of the ALB, is not the best choice for distributed session data management because it ties each session to a specific EC2 instance. As the instances scale up and down frequently, it can lead to uneven load distribution and may not provide optimal scalability.\n\nOptions C and D are not applicable for managing session data. AWS Systems Manager's Session Manager is primarily used for secure remote shell access to EC2 instances, and the AWS STS GetSessionToken API operation is used for temporary security credentials and not session data management.","upvote_count":"4"},{"comment_id":"935647","content":"ElastiCache is a managed in-memory data store service that is well-suited for managing session data in a distributed architecture. It provides high-performance, scalable, and durable storage for session data, allowing multiple EC2 instances to access and share session data seamlessly. By using ElastiCache, the application can offload the session management workload from the EC2 instances and leverage the distributed caching capabilities of ElastiCache for improved scalability and performance.\n\nOption B, using session affinity (sticky sessions) of the ALB, is not the best choice for distributed session data management because it ties each session to a specific EC2 instance. As the instances scale up and down frequently, it can lead to uneven load distribution and may not provide optimal scalability.\n\nOptions C and D are not applicable for managing session data. AWS Systems Manager's Session Manager is primarily used for secure remote shell access to EC2 instances, and the AWS STS GetSessionToken API operation is used for temporary security credentials and not session data management.","timestamp":"1703705580.0","poster":"cookieMr","upvote_count":"4"},{"content":"Selected Answer: A\nA. Use Amazon ElastiCache to manage and store session data.\n- Correct. - Session data is managed at the application-layer, and a distributed cache should be used\n\nB. Use session affinity (sticky sessions) of the ALB to manage session data.\n- Wrong. This tightly couples the individual EC2 instances to the session data, and requires additional logic in the ALB. When scale-in happens, the session data stored on individual EC2 instances is destroyed","timestamp":"1702967160.0","poster":"Abrar2022","upvote_count":"2","comment_id":"927108"},{"timestamp":"1689505980.0","upvote_count":"2","comment_id":"777671","poster":"techhb","content":"Selected Answer: A\ncorrect answer is A as instance are getting up and down."},{"comments":[{"timestamp":"1693051260.0","content":"https://www.examtopics.com/discussions/amazon/view/94992-exam-aws-certified-solutions-architect-associate-saa-c03/\n여기 임마","comment_id":"822484","upvote_count":"1","poster":"noche"}],"timestamp":"1686994020.0","comment_id":"748013","poster":"inseong","content":"야 근데 210문제는 어딧냐 ..?","upvote_count":"1"},{"poster":"NikaCZ","comment_id":"747606","upvote_count":"2","timestamp":"1686944340.0","content":"Selected Answer: A\nAmazon ElastiCache to manage and store session data."},{"upvote_count":"2","poster":"k1kavi1","timestamp":"1686835500.0","content":"Selected Answer: A\nhttps://www.examtopics.com/discussions/amazon/view/46412-exam-aws-certified-solutions-architect-associate-saa-c02/","comment_id":"746249"},{"upvote_count":"4","comment_id":"742872","timestamp":"1686570960.0","content":"A\nAmazon ElastiCache to manage and store session data. This solution will allow the application to automatically scale across multiple Availability Zones without losing session data, as the session data will be stored in a cache that is accessible from any EC2 instance. Additionally, using Amazon ElastiCache will enable the company to easily manage and scale the cache as needed, without requiring any changes to the application code. Option C is not correct because,Session Manager from AWS Systems Manager will not provide the necessary support for distributed session data management. Session Manager is a tool for managing and tracking sessions on EC2 instances, but it does not provide a mechanism for storing and managing session data in a distributed environment.","poster":"Shasha1"},{"poster":"TelaO","comment_id":"732095","content":"better justification found here...\nhttps://www.examtopics.com/discussions/amazon/view/46412-exam-aws-certified-solutions-architect-associate-saa-c02/","timestamp":"1685569560.0","upvote_count":"4"},{"content":"why not C?","poster":"kmaneith","upvote_count":"1","comment_id":"731089","timestamp":"1685413800.0"},{"comment_id":"729376","upvote_count":"4","poster":"leonnnn","timestamp":"1685283900.0","content":"Selected Answer: A\nALB sticky session can keep request accessing to the same backend application. But it says \"distributed session management\" and company \"will to change code\", so I think A is better"},{"upvote_count":"1","content":"Selected Answer: A\nAnswer : A","poster":"Nigma","comment_id":"729237","timestamp":"1685277600.0"}],"topic":"1","answer_description":"","unix_timestamp":1669646400,"exam_id":31,"question_text":"A solutions architect is designing the architecture of a new application being deployed to the AWS Cloud. The application will run on Amazon EC2 On-Demand Instances and will automatically scale across multiple Availability Zones. The EC2 instances will scale up and down frequently throughout the day. An Application Load Balancer (ALB) will handle the load distribution. The architecture needs to support distributed session data management. The company is willing to make changes to code if needed.\n\nWhat should the solutions architect do to ensure that the architecture supports distributed session data management?","timestamp":"2022-11-28 15:40:00","answers_community":["A (100%)"],"answer_images":[]},{"id":"YDX3n4TOyrxnqwQiJXmv","choices":{"A":"Use Amazon S3 to host the full website in different S3 buckets. Add Amazon CloudFront distributions. Set the S3 buckets as origins for the distributions. Store the order data in Amazon S3.","C":"Migrate the full application to run in containers. Host the containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use the Kubernetes Cluster Autoscaler to increase and decrease the number of pods to process bursts in traffic. Store the data in Amazon RDS for MySQL.","D":"Use an Amazon S3 bucket to host the website's static content. Deploy an Amazon CloudFront distribution. Set the S3 bucket as the origin. Use Amazon API Gateway and AWS Lambda functions for the backend APIs. Store the data in Amazon DynamoDB.","B":"Deploy the full website on Amazon EC2 instances that run in Auto Scaling groups across multiple Availability Zones. Add an Application Load Balancer (ALB) to distribute the website traffic. Add another ALB for the backend APIs. Store the data in Amazon RDS for MySQL."},"url":"https://www.examtopics.com/discussions/amazon/view/85195-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"answer_ET":"D","question_id":144,"answer":"D","isMC":true,"discussion":[{"poster":"Sinaneos","upvote_count":"47","content":"Selected Answer: D\nD because all of the components are infinitely scalable\ndynamoDB, API Gateway, Lambda, and of course s3+cloudfront","comment_id":"693746","timestamp":"1665650280.0"},{"comment_id":"759032","poster":"Buruguduystunstugudunstuy","timestamp":"1672172640.0","upvote_count":"21","content":"Selected Answer: D\nThe solution that will meet these requirements with the least operational overhead is D: Use an Amazon S3 bucket to host the website's static content, deploy an Amazon CloudFront distribution, set the S3 bucket as the origin, and use Amazon API Gateway and AWS Lambda functions for the backend APIs. Store the data in Amazon DynamoDB.\n\nUsing Amazon S3 to host static content and Amazon CloudFront to distribute the content can provide high performance and scale for websites with millions of requests each hour. Amazon API Gateway and AWS Lambda can be used to build scalable and highly available backend APIs to support the website, and Amazon DynamoDB can be used to store the data. This solution requires minimal operational overhead as it leverages fully managed services that automatically scale to meet demand.","comments":[{"comment_id":"759034","poster":"Buruguduystunstugudunstuy","comments":[{"comment_id":"1313856","content":"How to use dynmodb in a emcommerec trx it requrted sql databse","upvote_count":"1","poster":"try1260","timestamp":"1731905340.0"}],"content":"Option A is incorrect because using multiple S3 buckets to host the full website would not provide the required performance and scale for millions of requests each hour with millisecond latency.\n\nOption B is incorrect because deploying the full website on EC2 instances and using an Application Load Balancer (ALB) and an RDS database would require more operational overhead to maintain and scale the infrastructure.\n\nOption C is incorrect because while deploying the application in containers and hosting them on Amazon Elastic Kubernetes Service (EKS) can provide high performance and scale, it would require more operational overhead to maintain and scale the infrastructure compared to using fully managed services like S3 and CloudFront.","timestamp":"1672172700.0","upvote_count":"23"}]},{"comment_id":"1339807","timestamp":"1736750520.0","content":"Selected Answer: D\nMillisecond Latency = DynamoDB","upvote_count":"1","poster":"AshishDhole"},{"comment_id":"1334101","timestamp":"1735561020.0","content":"Selected Answer: D\nD as DynamoDB is only suitable because of its really fast milliseconds speed.","poster":"satyaammm","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\nRequirement analysis:\n- Build an e commerce application -> Typical 3 tiers app.\n- Deployment.\n- Scale quickly.\n- Least operational overhead.\n\nBased on what we get from the question, option D is quite self explanatory.\nS3 - Static resources storage, this can also used to deploy static web page if SPA is not desired\nCloudFront - Distribute application through edge locations\nAPI Gateway, Lambda, and DynamoDB - Simple application and db layers, scale quickly, serverless so no operational burden","comments":[{"comment_id":"1313854","content":"How to use dynmodb in a emcommerec trx it requrted sql databse","upvote_count":"1","poster":"try1260","timestamp":"1731905280.0"}],"timestamp":"1731651120.0","comment_id":"1312465","poster":"EzKkk"},{"poster":"PaulEkwem","content":"Option D:\nUse Amazon S3 to store the website’s static content (like images, HTML, etc.). Static content doesn’t change based on user input, so S3 is perfect because it’s highly scalable and can handle millions of requests.\nUse Amazon CloudFront to distribute the content globally, reducing latency by delivering it from servers close to the user.\nFor backend operations (like placing orders), use API Gateway and Lambda functions. API Gateway handles incoming requests, while Lambda runs code without needing servers (it’s serverless), which automatically scales to meet the traffic demand.\nStore the data in DynamoDB: DynamoDB is a fully managed, NoSQL database that can handle huge traffic spikes with very fast performance, which is important for millions of visitors.","upvote_count":"3","comment_id":"1296717","timestamp":"1728788460.0","comments":[]},{"timestamp":"1724993340.0","comment_id":"1274911","poster":"qmailmadrid","content":"My first answer is C. Coz it's high performance and high scalability.\nI didn't get the D answer: \n(1) So S3 can host static website? also is it mentioned on the question?\n(2) Lambda, S3, DynamoDB, all service managed by AWS, but so what, same with (1), which component host the main page?","upvote_count":"1"},{"timestamp":"1720885020.0","poster":"bishtr3","content":"D operational overhead\nLamda is a serverless computing let you run code without provisioning or managing service\nAPI Gateway -> Lamda -> Dynamo DB","upvote_count":"2","comment_id":"1247368"},{"poster":"otaku2398","timestamp":"1720647120.0","comment_id":"1245755","content":"can someone pls tell me how d is the answer. doesn't lambda time out in 15min","upvote_count":"3"},{"upvote_count":"4","poster":"ramkinkarpandey","content":"While everyone is voting for D but no where in the question it mentions that website is made of static pages. Other than not mentioning static, option D checks all the boxes.","timestamp":"1716740520.0","comment_id":"1219046"},{"content":"I struggled between A and D a little bit, then realize that A is not correct because it's hosting website in \"different\" buckets.","poster":"JohnZh","upvote_count":"4","timestamp":"1712020380.0","comment_id":"1187775"},{"content":"Selected Answer: D\nLeast operational overhead is only possible with managed services that deliver the required solution.\nA: Cannot store order data in S3 as there is no processing in S3\nB: Overhead of EC2 and RDS and ALB, too many moving parts\nC: Container management is overhead and RDS too\nD: S3 for static is best practice. CloudFront helps with scaling. API GW with Lambda is fully managed. DynamoDB for transactions is managed scalable solution.","comment_id":"1122027","upvote_count":"2","poster":"awsgeek75","timestamp":"1705177560.0"},{"comment_id":"1121630","poster":"A_jaa","content":"Selected Answer: D\nAnswer-D","timestamp":"1705149360.0","upvote_count":"1"},{"content":"Selected Answer: D\nD is the best asnwer for least operation","comment_id":"1102598","poster":"bujuman","upvote_count":"1","timestamp":"1703168040.0"},{"poster":"ddement0r","upvote_count":"1","timestamp":"1702088640.0","content":"Selected Answer: D\nD because it is the most logical solution","comment_id":"1091402"},{"comment_id":"1084884","content":"Selected Answer: D\ncorrect answer","timestamp":"1701398820.0","poster":"Avirexirex","upvote_count":"1"},{"comments":[{"content":"1 deal a day, which is a static content for 24 hours.","poster":"Charumathi","timestamp":"1704851880.0","comment_id":"1118031","upvote_count":"4"}],"content":"So in this question, how do you know FOR SURE that the website is static because it does not give you any clues. I know the API gateway makes the most sense with \"millions of requests each hour\", but it's very vague and leaves a grey area if the web site is static or not.","poster":"numark","timestamp":"1701258840.0","upvote_count":"1","comment_id":"1083394"},{"timestamp":"1698312600.0","upvote_count":"1","poster":"Ruffyit","comment_id":"1054423","content":"Using Amazon S3 to host static content and Amazon CloudFront to distribute the content can provide high performance and scale for websites with millions of requests each hour. Amazon API Gateway and AWS Lambda can be used to build scalable and highly available backend APIs to support the website, and Amazon DynamoDB can be used to store the data. This solution requires minimal operational overhead as it leverages fully managed services that automatically scale to meet demand."},{"poster":"danielpark99","comment_id":"1039086","content":"Selected Answer: D\nstatic cache in CloudFront can help to handle millions traffic and every 24 hours data can be in store DynamoDB to maintain data for past traffic to get analyzed","timestamp":"1696901820.0","upvote_count":"1"},{"comment_id":"968726","timestamp":"1690865880.0","poster":"TariqKipkemei","content":"Selected Answer: D\nAutoscale with least Ops = AWS managed services: Dynamo DB, API Gateway, Lambda, S3, CF.","upvote_count":"3"},{"comment_id":"965194","content":"So services fully managed by AWS usually deliver less operational overhead?","timestamp":"1690504080.0","upvote_count":"2","poster":"hsinchang"},{"poster":"Guru4Cloud","upvote_count":"2","comment_id":"958554","timestamp":"1689946380.0","content":"Selected Answer: D\nOption D leverages various serverless and managed services, minimizing the operational overhead compared to other options. The auto-scaling capabilities of Lambda, API Gateway, and DynamoDB ensure the system can handle the required peak traffic without requiring manual intervention in scaling infrastructure"},{"timestamp":"1689901320.0","content":"Selected Answer: D\nAnswer A \"host the full website in different S3 buckets\", remove A.\n\nAnswer B \"Deploy full website on EC2\", remove B.\n\nAnswer C, use Kubernetes is quite overhead, Amazon DynamoDB faster than Amazon RDS for MySQL.\n\nAnswer D is suitalbe in technical architect design, with Amazon S3, Amazon CloudFront, Amazon API Gateway, AWS Lambda, Amazon DynamoDB. for \"LEAD operational overhead\" (not mean migration/re-architect overhead, it is operational). Choose D.","comment_id":"957970","upvote_count":"1","poster":"james2033"},{"content":"Option D is the right answer for this.","comment_id":"953559","upvote_count":"1","poster":"miki111","timestamp":"1689532320.0"},{"comment_id":"926566","upvote_count":"3","poster":"cookieMr","timestamp":"1687078440.0","content":"Selected Answer: D\nUse an Amazon S3 bucket to host the website's static content. Deploy an Amazon CloudFront distribution. Set the S3 bucket as the origin. Use Amazon API Gateway and AWS Lambda functions for the backend APIs. Store the data in Amazon DynamoDB.\n\nThis solution leverages the scalability, low latency, and operational ease provided by AWS services.\n\nThis solution minimizes operational overhead because it leverages managed services, eliminating the need for manual scaling or management of infrastructure. It also provides the required scalability and low-latency response times to handle peak-hour traffic effectively.\n\nOptions A, B, and C involve more operational overhead and management responsibilities, such as managing EC2 instances, Auto Scaling groups, RDS for MySQL, containers, and Kubernetes clusters. These options require more manual configuration and maintenance compared to the serverless and managed services approach provided by option D."},{"timestamp":"1686244380.0","comment_id":"918506","content":"Selected Answer: D\nD is correct","poster":"Globus777","upvote_count":"1"},{"timestamp":"1684058880.0","content":"Selected Answer: D\nD is correct","comment_id":"897460","upvote_count":"1","poster":"cheese929"},{"content":"Selected Answer: D\nans: D\nkeywords: only one product on sale -- means static content\nmillions of requests each hour with millisecond latency -- dynamoDB\nLEAST operational overhead -- choose serverless architecture -- lambda/ API Gateway that handle millions of request in one go with cost effective manner","comment_id":"881337","poster":"MiteshB","upvote_count":"6","timestamp":"1682499420.0"},{"upvote_count":"8","poster":"PhucVuu","timestamp":"1680853380.0","comment_id":"863617","content":"Selected Answer: D\nKeywords:\n- Each day will feature exactly one product on sale for a period of 24 hours\n- Handle millions of requests each hour with millisecond latency during peak hours.\n- LEAST operational overhead\n\nA: Incorrect - We cannot store all the data to S3 because our data is dynamic (Each day will feature exactly one product on sale for a period of 24 hours)\nB: Incorrect - We don't have cache to improve performance (one product on sale for a period of 24 hours). Auto Scaling groups and RDS for MySQL need time to scale cannot scale immedidately.\nC: Incorrect - We don't have cache to improve performance (one product on sale for a period of 24 hours). Kubernetes Cluster Autoscaler can scale better than Auto Scaling groups but it also need time to scale. \nD: Correct - DynamoDB, S3, CloudFront, API Gateway are managed servers and they are highly scalable. CloudFront can cache static and dynamic data."},{"content":"Selected Answer: D\nOption D uses Amazon S3 to host the website's static content, which requires no servers to be provisioned or managed. Additionally, Amazon CloudFront can be used to improve the latency and scalability of the website. The backend APIs can be built using Amazon API Gateway and AWS Lambda, which can handle millions of requests with low operational overhead. Amazon DynamoDB can be used to store order data, which can scale to handle high request volumes with low latency.","poster":"gx2222","comment_id":"859372","timestamp":"1680473220.0","upvote_count":"1"},{"comment_id":"852754","poster":"apchandana","timestamp":"1679976780.0","upvote_count":"2","content":"Selected Answer: D\nthe most important key work is millisecond latency. only Dynamo DB can provide in this scale.\n\nobviously, S3, Lambda, Cloud front, etc has built in scaling"},{"comment_id":"842704","timestamp":"1679138820.0","poster":"cheese929","upvote_count":"2","content":"Selected Answer: D\nAnswer is D. All services proposed are managed services and auto scalable."},{"timestamp":"1671489660.0","comment_id":"750299","content":"Selected Answer: D\nhigh I/O = DynamoDB","poster":"pazabal","upvote_count":"2"},{"timestamp":"1671445380.0","content":"Selected Answer: D\nmillisecond latency --> DynamoDB","comment_id":"749716","poster":"psr83","upvote_count":"2"},{"comment_id":"740802","poster":"benaws","upvote_count":"1","timestamp":"1670663940.0","content":"Selected Answer: D\nonly all services in D are auto-scaling"},{"comment_id":"723494","upvote_count":"1","timestamp":"1669035120.0","poster":"Wpcorgan","content":"D is correct"},{"upvote_count":"1","content":"Selected Answer: D\nServerless technologies are better options","comment_id":"723174","poster":"ABCMail","timestamp":"1669007820.0"},{"poster":"Wajif","content":"Why not B? Application load balancer can accept millions of request/hr?","timestamp":"1668247260.0","comments":[{"poster":"keithkifo","timestamp":"1668388560.0","upvote_count":"2","comment_id":"717604","content":"For me, the keyword was millisecond latency. Option B suggests RDS as the database, but Option D is DynamoDB.\n\nDynamoDB - Fast, flexible NoSQL database service for single-digit millisecond performance at any scale","comments":[{"comment_id":"727393","content":"Yes, and also LEAST operational overhead. Scaling the application on EC2 instance is hard work require the very good architect.","comments":[{"comment_id":"732637","upvote_count":"2","poster":"JayBee65","timestamp":"1669900320.0","content":"And scaling takes time, so Auto Scaling groups cannot react instantly to a massive surge in demand"}],"poster":"TuLe","timestamp":"1669451820.0","upvote_count":"1"}]}],"upvote_count":"2","comment_id":"716629"},{"content":"D is the correct answer due to milliseconds latency which will involve cloud front.","upvote_count":"2","timestamp":"1668170820.0","poster":"sodyam","comment_id":"716053"},{"timestamp":"1667921760.0","upvote_count":"1","content":"D is the correct answer due to milliseconds latency which will involve cloud front.","comment_id":"713928","poster":"xeun88"},{"upvote_count":"1","poster":"17Master","content":"Selected Answer: D\nAns is correct D","timestamp":"1667168040.0","comment_id":"708063"},{"content":"Selected Answer: D\nD is the correct one.","poster":"GameDad09","timestamp":"1666037280.0","upvote_count":"1","comment_id":"697670"},{"upvote_count":"1","comment_id":"696466","content":"DDDDDDDDDDDDDDDD","poster":"queen101","timestamp":"1665948360.0"},{"upvote_count":"1","comment_id":"695065","content":"D: because of least operational overhead","poster":"ninjawrz","timestamp":"1665793260.0"},{"timestamp":"1665549180.0","upvote_count":"4","comment_id":"692629","poster":"BoboChow","content":"Selected Answer: D\nI feel like the scenario is not only static resource but also dynamic resources.\nAPI Gateway + Lambda has a good scalibility"},{"comment_id":"692444","poster":"Lilibell","timestamp":"1665526920.0","upvote_count":"2","content":"the answer is D"}],"topic":"1","answer_description":"","unix_timestamp":1665526920,"exam_id":31,"question_text":"An ecommerce company wants to launch a one-deal-a-day website on AWS. Each day will feature exactly one product on sale for a period of 24 hours. The company wants to be able to handle millions of requests each hour with millisecond latency during peak hours.\nWhich solution will meet these requirements with the LEAST operational overhead?","timestamp":"2022-10-12 00:22:00","answers_community":["D (100%)"],"answer_images":[]},{"id":"Jgzyffdqiw4g6yag0gBH","question_images":[],"isMC":true,"unix_timestamp":1673600640,"topic":"1","question_text":"A company offers a food delivery service that is growing rapidly. Because of the growth, the company’s order processing system is experiencing scaling problems during peak traffic hours. The current architecture includes the following:\n\n• A group of Amazon EC2 instances that run in an Amazon EC2 Auto Scaling group to collect orders from the application\n• Another group of EC2 instances that run in an Amazon EC2 Auto Scaling group to fulfill orders\n\nThe order collection process occurs quickly, but the order fulfillment process can take longer. Data must not be lost because of a scaling event.\n\nA solutions architect must ensure that the order collection process and the order fulfillment process can both scale properly during peak traffic hours. The solution must optimize utilization of the company’s AWS resources.\n\nWhich solution meets these requirements?","answer_ET":"D","question_id":145,"exam_id":31,"answers_community":["D (90%)","10%"],"answer_images":[],"timestamp":"2023-01-13 10:04:00","choices":{"A":"Use Amazon CloudWatch metrics to monitor the CPU of each instance in the Auto Scaling groups. Configure each Auto Scaling group’s minimum capacity according to peak workload values.","B":"Use Amazon CloudWatch metrics to monitor the CPU of each instance in the Auto Scaling groups. Configure a CloudWatch alarm to invoke an Amazon Simple Notification Service (Amazon SNS) topic that creates additional Auto Scaling groups on demand.","D":"Provision two Amazon Simple Queue Service (Amazon SQS) queues: one for order collection and another for order fulfillment. Configure the EC2 instances to poll their respective queue. Create a metric based on a backlog per instance calculation. Scale the Auto Scaling groups based on this metric.","C":"Provision two Amazon Simple Queue Service (Amazon SQS) queues: one for order collection and another for order fulfillment. Configure the EC2 instances to poll their respective queue. Scale the Auto Scaling groups based on notifications that the queues send."},"url":"https://www.examtopics.com/discussions/amazon/view/94992-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"timestamp":"1678109460.0","comment_id":"830840","upvote_count":"16","content":"Selected Answer: D\nWhen the backlog per instance reaches the target value, a scale-out event will happen. Because the backlog per instance is already 150 messages (1500 messages / 10 instances), your group scales out, and it scales out by five instances to maintain proportion to the target value.\nBacklog per instance: To calculate your backlog per instance, start with the ApproximateNumberOfMessages queue attribute to determine the length of the SQS queue (number of messages available for retrieval from the queue). Divide that number by the fleet's running capacity, which for an Auto Scaling group is the number of instances in the InService state, to get the backlog per instance.\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html","poster":"TungPham"},{"upvote_count":"12","timestamp":"1691546880.0","poster":"n43u435b543ht2b","comment_id":"976169","content":"Selected Answer: D\nC is incorrect as scaling based on the number of \"notifications\" doesn't make logical sense. This means that both the order collection and fulfilment instances would scale in parallel, but they have clearly said that the collection is processing quickly while the fulfilment is struggling. Therefore, we should scale the pool when there is a backlog building in a respective queue - not just based on the number of incoming requests."},{"timestamp":"1742874240.0","comment_id":"1409883","content":"Selected Answer: C\nI can understand you guy's explanation on D (the burden is on one queue only not both)\nbut i dont understand how D imply that the metric is monitoring on on side","upvote_count":"1","poster":"jerryl"},{"content":"Selected Answer: D\nSince only the order fulfillment requires scaling capacity so D is the most suitable here.","timestamp":"1739705640.0","poster":"satyaammm","upvote_count":"1","comment_id":"1357225"},{"comment_id":"1244624","timestamp":"1720485000.0","poster":"jatric","upvote_count":"1","content":"Selected Answer: C\nboth have their own queue. Instance processing order will be scale up based on the queue length that collect messages that collected by other queue."},{"poster":"lofzee","timestamp":"1716902400.0","content":"Selected Answer: D\nnot C as the questions state that only one system is struggling, so C doesnt really solve the problem.\nD does.","upvote_count":"2","comment_id":"1220285"},{"poster":"Uzbekistan","content":"Selected Answer: D\nDecoupling with Amazon SQS: By using Amazon SQS queues for order collection and order fulfillment, the system can decouple the components, ensuring that orders are not lost, even during scaling events. Orders are queued up and processed in a reliable and scalable manner.\nScalability Based on Queue Backlog: By creating a metric based on the backlog per instance calculation, the system can monitor the workload of each instance in the Auto Scaling groups. This allows for dynamic scaling based on the workload, ensuring that additional instances are launched when the backlog increases and terminated when the backlog decreases. Optimization of AWS Resources: This solution optimizes the utilization of AWS resources by dynamically scaling the Auto Scaling groups based on the actual workload, preventing over-provisioning or under-provisioning of instances. It ensures that the system can handle peak traffic efficiently without incurring unnecessary costs.","timestamp":"1712259360.0","upvote_count":"2","comment_id":"1189511"},{"timestamp":"1707385140.0","upvote_count":"2","poster":"bujuman","content":"Selected Answer: D\nD is the most appropriate response base on https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html","comment_id":"1144333"},{"upvote_count":"5","timestamp":"1694455200.0","comment_id":"1005071","content":"Selected Answer: D\nD. Provision two Amazon Simple Queue Service (Amazon SQS) queues: one for order collection and another for order fulfillment. Configure the EC2 instances to poll their respective queue. Create a metric based on a backlog per instance calculation. Scale the Auto Scaling groups based on this metric.","poster":"Guru4Cloud"},{"timestamp":"1687936620.0","content":"SQS auto-scales by default so I don't think we need to mention it explicitly. Option D should be correct.","comment_id":"936271","upvote_count":"2","poster":"argl1995"},{"upvote_count":"5","comment_id":"936203","timestamp":"1687931640.0","content":"Selected Answer: D\nA. This approach focuses solely on CPU utilization, which may not accurately reflect the scaling needs of the order collection and fulfillment processes. It does not address the need for decoupling and reliable message processing.\n\nB. While this approach incorporates alarms to trigger additional Auto Scaling groups, it lacks the decoupling and reliable message processing provided by using SQS queues. It may lead to inefficient scaling and potential data loss.\n\nC. Although using SQS queues is a step in the right direction, scaling solely based on queue notifications may not provide optimal resource utilization. It does not consider the backlog per instance and does not allow for fine-grained control over scaling.\n\nOverall, option D, which involves using SQS queues for order collection and fulfillment, creating a metric based on backlog per instance calculation, and scaling the Auto Scaling groups accordingly, is the most suitable solution to address the scaling problems while optimizing resource utilization and ensuring reliable message processing.","poster":"cookieMr"},{"content":"Selected Answer: D\nC is incorrect. \"based on notifications that the queues send\" SQS does not send notification","comment_id":"898681","upvote_count":"4","poster":"studynoplay","timestamp":"1684181580.0"},{"comment_id":"890047","comments":[{"poster":"pentium75","timestamp":"1703676540.0","comment_id":"1106744","upvote_count":"1","content":"\"You can use target tracking scaling policies\" but you don't with option C. What is \"scaling based on notifications that the queues send\"? Where do they send these notifications to?"}],"poster":"mandragon","upvote_count":"2","content":"Selected Answer: C\nD is not correct because it requires more operational overhead and complexity than option C which is simpler and more cost-effective. It uses the existing queue metrics that are provided by Amazon SQS and does not require creating or publishing any custom metrics. You can use target tracking scaling policies to automatically maintain a desired backlog per instance ratio without having to calculate or monitor it yourself.","timestamp":"1683292200.0"},{"timestamp":"1674487320.0","content":"Selected Answer: D\nScale based on queue length","comment_id":"785530","upvote_count":"3","poster":"JayBee65"},{"upvote_count":"3","content":"answer is D.\nread question again","timestamp":"1674038880.0","poster":"Rudraman","comment_id":"779886"},{"timestamp":"1674020760.0","content":"Selected Answer: D\nThe number of instances in your Auto Scaling group can be driven by how long it takes to process a message and the acceptable amount of latency (queue delay). \nThe solution is to use a backlog per instance metric with the target value being the acceptable backlog per instance to maintain.","poster":"LuckyAro","upvote_count":"2","comment_id":"779641"},{"content":"Selected Answer: D\nD is correct","upvote_count":"2","timestamp":"1673997780.0","poster":"Aseem8888","comment_id":"779392"},{"timestamp":"1673921700.0","comments":[],"upvote_count":"1","comment_id":"778469","poster":"Rudraman","content":"C\nNeed to Auto-\nScale Queue of SQS"},{"content":"Selected Answer: D\nI think its D as here we are creating new metric to calculate load on each EC2 instance.","comment_id":"777684","upvote_count":"3","poster":"techhb","timestamp":"1673875140.0"},{"poster":"techhb","content":"I think its D as here we are creating new metric to calculate load on each EC2 instance.","comment_id":"777682","upvote_count":"3","timestamp":"1673875080.0"},{"poster":"wmp7039","content":"Selected Answer: D\nC is incorrect as SQS doesn't send notifications and needs to be polled by the consumers","timestamp":"1673867880.0","comment_id":"777601","upvote_count":"4"},{"upvote_count":"2","poster":"KM01","content":"I think, D","comment_id":"776243","timestamp":"1673769720.0"},{"content":"Selected Answer: C\nı think c ,but ı m not sure ı think both of solve problem","upvote_count":"1","poster":"swolfgang","timestamp":"1673768760.0","comments":[{"timestamp":"1674487440.0","upvote_count":"4","comment_id":"785532","poster":"JayBee65","content":"No they don't. How exactly would you scale based on a queue sending a message? Scale up when it sends a message? Scale up every time it sends a message? This takes no account of how quickly messages are processed."}],"comment_id":"776239"},{"content":"Selected Answer: C\nI think C","comment_id":"775730","timestamp":"1673713920.0","poster":"mhmt4438","upvote_count":"2"},{"content":"Selected Answer: D\nD is correct","poster":"kbaruu","timestamp":"1673687400.0","comment_id":"775211","upvote_count":"2"},{"poster":"senthil21","content":"correct answer is D","comment_id":"774272","upvote_count":"2","timestamp":"1673600640.0"}],"answer_description":"","answer":"D"}],"exam":{"isImplemented":true,"isMCOnly":true,"numberOfQuestions":1019,"lastUpdated":"11 Apr 2025","provider":"Amazon","isBeta":false,"id":31,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":29},"__N_SSP":true}