{"pageProps":{"questions":[{"id":"K25Z0O1unyIMhMc3Wr3M","isMC":true,"exam_id":31,"choices":{"A":"Set up VPC peering connections between each VPC. Update each associated subnet’s route table","D":"Deploy VPN gateways in each VPC. Create a transit VPC in the networking team’s AWS account to connect to each VPC.","C":"Create an AWS Transit Gateway in the networking team’s AWS account. Configure static routes from each VPC.","B":"Configure a NAT gateway and an internet gateway in each VPC to connect each VPC through the internet"},"discussion":[{"upvote_count":"18","timestamp":"1706249340.0","poster":"hsinchang","content":"Selected Answer: C\nThe main difference between AWS Transit Gateway and VPC peering is that AWS Transit Gateway is designed to connect multiple VPCs together in a hub-and-spoke model, while VPC peering is designed to connect two VPCs together in a peer-to-peer model.\nAs we have several VPCs here, the answer should be C.","comment_id":"963331"},{"upvote_count":"7","timestamp":"1700399460.0","content":"Selected Answer: C\nAWS Transit Gateway is a highly scalable and centralized hub for connecting multiple VPCs, on-premises networks, and remote networks. It simplifies network connectivity by providing a single entry point and reducing the number of connections required. In this scenario, deploying an AWS Transit Gateway in the networking team's AWS account allows for efficient management and control over the network connectivity across multiple VPCs.","poster":"cloudenthusiast","comment_id":"901859"},{"poster":"awsgeek75","comment_id":"1126800","upvote_count":"2","content":"Selected Answer: C\nA: This option is suggesting hundreds of peering connection for EACH VPC. Nope!\nB: NAT gateway is for network translation not VPC interconnectivity so this is wrong\nC: Transit GW + static routes will connect all VPCs https://aws.amazon.com/transit-gateway/\nD: VPN gateway is for on-prem to VPN for a VPC. There is no on-prem here so this is wrong","timestamp":"1721398380.0"},{"upvote_count":"3","content":"Selected Answer: C\nConnect, Monitor and Manage Multiple VPCs in one place = AWS Transit Gateway","timestamp":"1715229000.0","poster":"TariqKipkemei","comment_id":"1066156"},{"upvote_count":"3","comment_id":"988309","content":"Selected Answer: C\nC is the most operationally efficient solution for connecting a large number of VPCs across accounts.\n\nUsing AWS Transit Gateway allows all the VPCs to connect to a central hub without needing to create a mesh of VPC peering connections between each VPC pair.\n\nThis significantly reduces the operational overhead of managing the network topology as new VPCs are added or changed.\n\nThe networking team can centrally manage the Transit Gateway routing and share it across accounts using Resource Access Manager.","poster":"Guru4Cloud","timestamp":"1708698420.0"},{"poster":"MirKhobaeb","upvote_count":"2","comment_id":"909473","content":"Answer is C","timestamp":"1701274140.0"},{"poster":"MirKhobaeb","timestamp":"1701274080.0","upvote_count":"3","comment_id":"909472","content":"A transit gateway is a network transit hub that you can use to interconnect your virtual private clouds (VPCs) and on-premises networks. As your cloud infrastructure expands globally, inter-Region peering connects transit gateways together using the AWS Global Infrastructure. Your data is automatically encrypted and never travels over the public internet."},{"timestamp":"1700390580.0","comment_id":"901771","upvote_count":"3","content":"Selected Answer: C\nI voted for c","comments":[{"timestamp":"1700407920.0","content":"An AWS Transit Gateway is a highly scalable and secure way to connect VPCs in multiple AWS accounts. It is a central hub that routes traffic between VPCs, on-premises networks, and AWS services.","upvote_count":"4","comment_id":"901970","poster":"nosense"}],"poster":"nosense"}],"answers_community":["C (100%)"],"timestamp":"2023-05-19 10:43:00","url":"https://www.examtopics.com/discussions/amazon/view/109690-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","answer":"C","question_id":471,"answer_images":[],"answer_description":"","question_images":[],"question_text":"A company needs to connect several VPCs in the us-east-1 Region that span hundreds of AWS accounts. The company's networking team has its own AWS account to manage the cloud network.\n\nWhat is the MOST operationally efficient solution to connect the VPCs?","unix_timestamp":1684485780,"answer_ET":"C"},{"id":"hBb8YR6CQI23opj3vNk4","question_id":472,"answers_community":["C (100%)"],"answer_images":[],"timestamp":"2023-05-19 10:43:00","exam_id":31,"answer":"C","choices":{"C":"Create a new launch template for the Auto Scaling group. Set the instances to Spot Instances. Set a policy to scale out based on CPU usage.","B":"Purchase a 1-year Reserved Instance for the specific instance type and operating system of the instances in the Auto Scaling group that the batch job uses.","D":"Create a new launch template for the Auto Scaling group. Increase the instance size. Set a policy to scale out based on CPU usage.","A":"Purchase a 1-year Savings Plan for Amazon EC2 that covers the instance family of the Auto Scaling group that the batch job uses."},"isMC":true,"discussion":[{"comment_id":"901862","upvote_count":"14","timestamp":"1700399640.0","poster":"cloudenthusiast","content":"Selected Answer: C\nPurchasing a 1-year Savings Plan (option A) or a 1-year Reserved Instance (option B) may provide cost savings, but they are more suitable for long-running, steady-state workloads. Since your batch jobs run for a specific period each day, using Spot Instances with the ability to scale out based on CPU usage is a more cost-effective choice."},{"comment_id":"988304","timestamp":"1708698300.0","content":"Selected Answer: C\nC is the most cost-effective solution in this scenario.\n\nUsing Spot Instances allows EC2 capacity to be purchased at significant discounts compared to On-Demand prices. The auto scaling group can scale out to add Spot Instances when needed for the batch jobs.\n\nIf Spot Instances become unavailable, regular On-Demand Instances will be launched instead to maintain capacity. The potential for interruptions is acceptable since failed jobs can be re-run.","poster":"Guru4Cloud","upvote_count":"7"},{"timestamp":"1729273020.0","comment_id":"1198060","content":"Selected Answer: C\nStateless, most cost-effective >> Spot","poster":"sandordini","upvote_count":"3"},{"poster":"awsgeek75","comment_id":"1117108","timestamp":"1720473360.0","upvote_count":"3","content":"Selected Answer: C\nYou don't need any scaling really as the job runs on another EC2 instance if it fails on first one. A. B. D are all more expensive than C due to spot instance being cheaper than reserved instances."},{"content":"Selected Answer: C\nSpot Instances to the rescue....whooosh","poster":"TariqKipkemei","upvote_count":"2","comment_id":"951253","timestamp":"1705217220.0"},{"content":"\" If a job fails on one instance, another instance will reprocess the job\". This ensures Spot Instances are enough for this case","comment_id":"933960","poster":"wRhlH","timestamp":"1703562840.0","upvote_count":"4"},{"upvote_count":"2","timestamp":"1701774600.0","poster":"Abrar2022","content":"Selected Answer: C\nSince your batch jobs run for a specific period each day, using Spot Instances with the ability to scale out based on CPU usage is a more cost-effective choice.","comment_id":"915258"},{"comment_id":"910082","upvote_count":"3","poster":"Blingy","content":"C FOR ME COS OF SPOT INSTACES","timestamp":"1701341520.0"},{"poster":"udo2020","content":"First I think it is B but because of cost saving I think it should be C spot instances.","upvote_count":"2","comment_id":"901964","timestamp":"1700407500.0"},{"content":"Selected Answer: C\nc for me","upvote_count":"2","poster":"nosense","comment_id":"901772","timestamp":"1700390580.0"}],"answer_description":"","topic":"1","unix_timestamp":1684485780,"url":"https://www.examtopics.com/discussions/amazon/view/109691-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"C","question_text":"A company has Amazon EC2 instances that run nightly batch jobs to process data. The EC2 instances run in an Auto Scaling group that uses On-Demand billing. If a job fails on one instance, another instance will reprocess the job. The batch jobs run between 12:00 AM and 06:00 AM local time every day.\n\nWhich solution will provide EC2 instances to meet these requirements MOST cost-effectively?","question_images":[]},{"id":"lw7I6HULZnsSlNbP3vFe","answer_description":"","isMC":true,"answer_ET":"C","exam_id":31,"answers_community":["C (91%)","9%"],"discussion":[{"upvote_count":"16","poster":"cloudenthusiast","comment_id":"901864","content":"Selected Answer: C\nThis approach allows users to upload files directly to S3 without passing through the application servers, reducing the load on the application and improving scalability. It leverages the client-side capabilities to handle the file uploads and offloads the processing to S3.","timestamp":"1700399700.0"},{"comment_id":"988293","timestamp":"1708697940.0","upvote_count":"5","content":"Selected Answer: C\nC is the best solution to meet the scalability requirements.\n\nGenerating S3 presigned URLs allows users to upload directly to S3 instead of application servers. This removes the application servers as a bottleneck for upload traffic.\n\nS3 can scale to handle very high volumes of uploads with no limits on storage or throughput. Using presigned URLs leverages this scalability.","poster":"Guru4Cloud"},{"upvote_count":"3","comment_id":"1184455","timestamp":"1727472300.0","content":"C - You may use presigned URLs to allow someone to upload an object to your Amazon S3 bucket. Using a presigned URL will allow an upload without requiring another party to have AWS security credentials or permissions.","poster":"hro"},{"comment_id":"1118894","timestamp":"1720626480.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html\n\"You can also use presigned URLs to allow someone to upload a specific object to your Amazon S3 bucket. This allows an upload without requiring another party to have AWS security credentials or permissions. \"","upvote_count":"2","poster":"awsgeek75"},{"timestamp":"1716516480.0","upvote_count":"3","poster":"Goutham4981","content":"Selected Answer: A\nS3 presigned url is used for sharing objects from an s3 bucket and not for uploading to an s3 bucket","comments":[{"content":"No. It allows to download and upload.\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html","upvote_count":"4","comment_id":"1093498","timestamp":"1718105580.0","poster":"Murtadhaceit"}],"comment_id":"1079017"},{"upvote_count":"2","poster":"TariqKipkemei","comment_id":"953809","content":"Selected Answer: C\nYou may use presigned URLs to allow someone to upload an object to your Amazon S3 bucket. Using a presigned URL will allow an upload without requiring another party to have AWS security credentials or permissions. \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/PresignedUrlUploadObject.html","timestamp":"1705471140.0"},{"comments":[{"upvote_count":"3","comment_id":"1111043","poster":"pentium75","content":"Both is wrong\nPresigned URLs can be used for upload\nThe solution is scalable because you can issue thousands of pre-signed URLs, and thousands of users can upload images at the same time.\n\nUser wants to upload picture -> server generates presigned URL and sends it to the app -> app uploads file","timestamp":"1719815700.0"}],"poster":"baba365","comment_id":"948618","content":"Hello Moderator. This question and answer should be rephrased because:\n\n1. S3 pre-signed URLs are used to share objects FROM S3 buckets \n2. How scalable are pre-signed URLs when they are time constrained? \n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html","upvote_count":"2","timestamp":"1704948420.0"},{"comment_id":"901773","poster":"nosense","timestamp":"1700390640.0","upvote_count":"4","content":"Selected Answer: C\nthe most scalable because it allows users to upload files directly to Amazon S3,"}],"choices":{"D":"Provision an Amazon Elastic File System (Amazon EFS) file system. Upload files directly from the user's browser to the file system.","C":"Generate Amazon S3 presigned URLs in the application. Upload files directly from the user's browser into an S3 bucket.","B":"Provision an AWS Storage Gateway file gateway. Upload files directly from the user's browser to the file gateway.","A":"Upload files from the user's browser to the application servers. Transfer the files to an Amazon S3 bucket."},"question_images":[],"topic":"1","timestamp":"2023-05-19 10:44:00","answer":"C","answer_images":[],"question_text":"A social media company is building a feature for its website. The feature will give users the ability to upload photos. The company expects significant increases in demand during large events and must ensure that the website can handle the upload traffic from users.\n\nWhich solution meets these requirements with the MOST scalability?","unix_timestamp":1684485840,"url":"https://www.examtopics.com/discussions/amazon/view/109692-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":473},{"id":"KdcrTBtgv4bB4KN6rOyP","unix_timestamp":1684376520,"exam_id":31,"answer":"A","topic":"1","discussion":[{"upvote_count":"21","poster":"cloudenthusiast","content":"Selected Answer: A\nUsing DynamoDB's global tables feature, you can achieve a globally consistent reservation database with low latency on updates, making it suitable for serving a global user base. The automatic replication provided by DynamoDB eliminates the need for manual synchronization between Regions.","timestamp":"1684495380.0","comment_id":"901869","comments":[{"content":"DynamoDB Global Tables rely on eventual consistency for replication between Regions. This means that updates in one Region may take milliseconds to seconds to propagate to other Regions. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html\n\nThe requirement specifies global consistency, which DynamoDB cannot guarantee.","upvote_count":"1","poster":"FlyingHawk","comment_id":"1325254","timestamp":"1733951580.0"}]},{"comment_id":"1126180","content":"Selected Answer: B\nAurora: less than 1 second: https://aws.amazon.com/rds/aurora/global-database/\nDynamoDB: from 0.5 to 2.5 second: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_HowItWorks.html","comments":[{"comment_id":"1175813","timestamp":"1710678720.0","poster":"TheLaPlanta","content":"B doesn't say Aurora Global","upvote_count":"11","comments":[{"upvote_count":"2","content":"DynamoDB doesn't meet the <1s req though.","timestamp":"1726303860.0","poster":"MatAlves","comment_id":"1283556"}]}],"poster":"upliftinghut","timestamp":"1705610400.0","upvote_count":"6"},{"comment_id":"1379932","upvote_count":"1","comments":[{"timestamp":"1741599840.0","content":"Global tables - multi-Region replication for DynamoDB\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GlobalTables.htmAmazon DynamoDB global tables are a fully managed, multi-Region, and multi-active database option that delivers fast and localized read and write performance for massively scaled global applications.","upvote_count":"1","poster":"tch","comment_id":"1379933"}],"content":"Selected Answer: A\nanswer should be A.\nwe can consider if B change to \"Amazon Aurora Global Database\"...","timestamp":"1741599780.0","poster":"tch"},{"poster":"Dantecito","upvote_count":"1","comment_id":"1355119","timestamp":"1739303640.0","content":"Selected Answer: A\nA is the only option that allows you to write from any reagion. I understand the < 1 second latency, but DynamoDB global tables use a last-writer-wins reconciliation between concurrent updates.\nB and C only supports read scaling, not low-latency global writes. It will be much much much much than 1 second to write on the databse.\nD I stopped reading at lambda so NO!."},{"upvote_count":"1","timestamp":"1738805940.0","poster":"zdi561","content":"Selected Answer: A\nDynamodb is consistent and read/write in all node, Aurora db , only the master is writable. For reservation , writing is criticle.","comment_id":"1352136"},{"timestamp":"1737790920.0","upvote_count":"1","content":"Selected Answer: A\nA is the correct answer","poster":"khatingarun","comment_id":"1346375"},{"timestamp":"1737522060.0","poster":"zdi561","upvote_count":"2","comment_id":"1344620","content":"Selected Answer: B\ndynamodb is not globally consistent. DynamoDB doesn't support strongly consistent reads across Regions. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_HowItWorks.html"},{"content":"Selected Answer: B\ncorrect answer bbbb","upvote_count":"1","timestamp":"1735551120.0","comment_id":"1334013","poster":"hilker1983"},{"upvote_count":"1","poster":"EllenLiu","content":"Selected Answer: A\nA: dynamoDB global table preview strong consistent \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/multi-region-strong-consistency-gt.html","timestamp":"1734596160.0","comment_id":"1328901"},{"timestamp":"1734029160.0","content":"Selected Answer: A\nAurora replicas have to be in the same region as primary \nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/aurora-replication-options/compare-solutions.html","poster":"Penjerla","comment_id":"1325808","upvote_count":"2"},{"upvote_count":"2","comment_id":"1325258","timestamp":"1733951700.0","poster":"FlyingHawk","content":"Selected Answer: B\nSince DynamoDB Global Tables allow writes in all Regions, conflicts can occur if the same item is updated simultaneously in multiple Regions. DynamoDB uses a \"last writer wins\" conflict resolution strategy, which may lead to data integrity issues: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_HowItWorks.html#V2globaltables_HowItWorks.conflict-resolution\nIf you require less than 1-second latency for write updates across Regions, DynamoDB may not consistently meet this requirement due to the asynchronous nature of its replication.\nFor this scenario, DynamoDB Global Tables do not fully meet the requirements due to their reliance on eventual consistency. If strong consistency is a must, go with Amazon Aurora Global Database."},{"content":"Selected Answer: B\nThe question asks \"Average latency must be less than 1 second on updates to the reservation database.\"\n\nA is incorrect:\n\" Changes to a DynamoDB global tables are replicated asynchronously, with typical latency of between 0.5 - 2.5 seconds between AWS Regions in the same geographic area.\"\n\nB is the answer:\n\"All Aurora Replicas return the same data for query results with minimal replica lag. This lag is usually much less than 100 milliseconds after the primary instance has written an update.\"","timestamp":"1726747320.0","comments":[{"upvote_count":"3","comment_id":"1283554","content":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html\n\nhttps://community.aws/content/2drxEND7MtTOb2bWs2J0NlCGewP/ddb-globaltables-lag?lang=en","timestamp":"1726303800.0","poster":"MatAlves"}],"upvote_count":"2","comment_id":"1283553","poster":"MatAlves"},{"upvote_count":"3","content":"Selected Answer: A\nHow can you update your database in the different regions with read replicas? You need to be able to read and write to the database from the different regions.","poster":"SVDK","timestamp":"1707422340.0","comment_id":"1144870"},{"comment_id":"1117146","content":"Selected Answer: A\nIn my Opinion it is A. The reason is that Aurora Read Replicas support up to 5 Read replicas in different regions . We don't have that limitation with Dynamo DB Global tables, hence I vote for A.","poster":"Milivoje","timestamp":"1704764340.0","upvote_count":"1"},{"comments":[{"comment_id":"1331097","timestamp":"1735039920.0","poster":"Salilgen","upvote_count":"1","content":"Answer is A.\nOption B is about cross-region Aurora replicas not about Aurora Global Database.\n\"Cross-region Aurora replicas have a lag that depends on transaction volume. Typically, a few seconds for most systems.\"\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/aurora-replication-options/compare-solutions.html\n\" In a global table, a newly written item is typically propagated to all replica tables within a second.\"\nhttps://aws.amazon.com/dynamodb/global-tables/"},{"poster":"pentium75","upvote_count":"5","content":"We need \"a single primary reservation database that is globally consistent\" -> A is out (DynamoDB is eventually consistent with \"last writer wins\" and \"usually\" updates \"within [not: less than] one second\"). D is out because it mentions multiple databases (and RDS Event Streams to not guarantee the order of events).\n\nC is out because RDS has higher replication delay, only Aurora can guarantee \"less than one second\". So we'd have \"a single primary reservation database that is globally consistent\" in one region, and we'd have read replicas with \"less than 1 second on updates\" latency in other regions.","comment_id":"1116431","timestamp":"1704692760.0"}],"content":"Selected Answer: B\nPurely from the wording, seems B.\nDynamoDB \"usually within one second\"\nAurora \"usually less than one second\"\nQuestion asks for \"less than one second\" thus Aurora","poster":"pentium75","upvote_count":"3","comment_id":"1111047","timestamp":"1704098520.0"},{"upvote_count":"1","timestamp":"1701021180.0","poster":"numark","comments":[{"poster":"pentium75","timestamp":"1704098220.0","comment_id":"1111044","upvote_count":"3","content":"So you can't write to DynamoDB tables at all because tables writes are transactions?"},{"timestamp":"1704909240.0","comment_id":"1118898","upvote_count":"2","content":"There are no assumptions about the application here. The choices are related to the database that has one primary source of truth but multi-region presence. No requirement for transaction is given or implied.","poster":"awsgeek75"}],"content":"\"a web application for travel ticketing\". This would be a transaction, so DynamoDB is not the answer.","comment_id":"1080926"},{"comment_id":"1079019","timestamp":"1700799360.0","upvote_count":"1","poster":"Goutham4981","content":"Selected Answer: A\nDynamo DB global table acts as a single table. It does not consist of primary and standby databases. It is one single global table which is synchronously updated. Users can write to any of the regional endpoints and the write will be automatically updated across regions. To have a single primary database that is consistent does not align with dynamo db global tables.\nOption B is even more dumb compared to A since read replicas does not provide failover capability or fast updates from the primary database.\nThe answer almost close to the requirement is Option A even though it is a misfit"},{"poster":"Goutham4981","content":"Selected Answer: A\nThe question mentions that the average latency on updates to the regional reservation databases should be less than 1sec. Read replicas provide asynchronous replication and hence the update times will be higher. Hence we can easily scrap all the options containing read replicas from the options. Moreover, a globally consistent database with millisecond latencies screams dynamo db global","timestamp":"1700360520.0","upvote_count":"2","comment_id":"1074406"},{"upvote_count":"5","timestamp":"1697629800.0","content":"Selected Answer: B\nI think the real difference is that DynamoDB is by default only eventually consistent however it has to be consistent. So it's B.\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","poster":"DDongi","comment_id":"1046867"},{"comment_id":"998582","timestamp":"1693833780.0","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Replication.CrossRegion.html \" average latency less than 1 second.\"","comments":[{"timestamp":"1695735960.0","poster":"kwang312","upvote_count":"1","comment_id":"1017818","content":"This is for Cluster"}],"poster":"jrestrepob","upvote_count":"3"},{"upvote_count":"1","comment_id":"997918","poster":"ibu007","timestamp":"1693770240.0","content":"Selected Answer: A\nAmazon DynamoDB global tables is a fully managed, serverless, multi-Region, and multi-active database. Global tables provide you 99.999% availability, increased application resiliency, and improved business continuity. As global tables replicate your Amazon DynamoDB tables automatically across your choice of AWS Regions, you can achieve fast, local read and write performance."},{"comment_id":"992304","timestamp":"1693233840.0","upvote_count":"2","comments":[{"timestamp":"1693234020.0","upvote_count":"2","poster":"Bennyboy789","comment_id":"992309","content":"While Amazon DynamoDB is a highly scalable NoSQL database, using a global table might introduce latency and might not be suitable for maintaining a single primary reservation database with globally consistent data."}],"poster":"Bennyboy789","content":"Selected Answer: B\nAmazon Aurora provides global databases that replicate your data with low latency to multiple regions. By using Aurora Read Replicas in each Region, the company can achieve low-latency access to the data while maintaining global consistency. The use of regional endpoints ensures that each deployment accesses the appropriate local replica, reducing latency. This solution allows the company to meet the requirement of serving a global user base while keeping average latency less than 1 second."},{"upvote_count":"2","poster":"Guru4Cloud","comment_id":"988247","content":"Selected Answer: B\nAurora Global DB provides native multi-master replication and automatic failover for high availability across regions.\nRead replicas in each region ensure low read latency by promoting a local replica to handle reads.\nA single Aurora primary region handles all writes to maintain data consistency.\nData replication and sync is managed automatically by Aurora Global DB.\nRegional endpoints minimize cross-region latency.\nAutomatic failover promotes a replica to be the new primary if the current primary region goes down.","timestamp":"1692790800.0"},{"upvote_count":"2","poster":"cd93","comment_id":"987869","timestamp":"1692755940.0","content":"Selected Answer: B\n\"the company must maintain a single primary reservation database that is globally consistent.\" --> Relational database, because it only allow writes from one regional endpoint\n\nDynamoDB global table allow BOTH reads and writes on all regions (“last writer wins”), so it is not single point of entry. You can set up IAM identity based policy to restrict write access for global tables that are not in NA but it is not mentioned."},{"upvote_count":"2","comment_id":"974369","content":"Selected Answer: B\nAdvantages of Amazon Aurora global databases\nBy using Aurora global databases, you can get the following advantages:\n\nGlobal reads with local latency – If you have offices around the world, you can use an Aurora global database to keep your main sources of information updated in the primary AWS Region. Offices in your other Regions can access the information in their own Region, with local latency.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html\n\nD. although D is also using Aurora Global Database, there is no need for Lambda function to sync data.","poster":"ralfj","timestamp":"1691380080.0"},{"timestamp":"1690917240.0","content":"Selected Answer: A\nIn real life, I would use Aurora Global Database. Because 1. it achieve less than 1 sec latency, 2. And ticketing system is a very typical traditional relational system.\nWhile, in the exam I would vote for A. Because Option B isn't using global database which means you have to provide the endpoint of primary region to a remote region for update and even the typical back and forth latency is 400ms but you have to have a lot of professional network setup to guarantee it, which option B doesn't mention.","poster":"bjexamprep","upvote_count":"3","comment_id":"969321"},{"comment_id":"969187","content":"ANs; B\n\nAmazon Aurora Global Database is designed for globally distributed applications, allowing a single Amazon Aurora database to span multiple AWS Regions. It replicates your data with no impact on database performance, enables fast local reads with low latency in each Region, and provides disaster recovery from Region-wide outages. \n\nRef: https://aws.amazon.com/rds/aurora/global-database/","timestamp":"1690905960.0","upvote_count":"2","poster":"BlueAIBird"},{"poster":"TariqKipkemei","timestamp":"1689567960.0","comment_id":"953823","upvote_count":"3","content":"Selected Answer: B\nLatency experienced in both DynamoDB and Aurora MySQL can be influenced by factors such as your chosen AWS region, the network connectivity between your application and the database, and the performance optimizations you have implemented in your application code.\nThis is the type of requirement where both DBs will server the purpose. In the real world it would be determined by whether the existing DB is SQL/NoSQL .\nBut for this case personally I prefer option B."},{"comments":[{"upvote_count":"2","poster":"manuelemg2007","timestamp":"1692658320.0","content":"DynamoDB is designed for single-digit millisecond latency","comment_id":"986952"}],"content":"Typical latency of Dynamo DB is 10 to 20 seconds and Aurora DB is less than 1 second. Thus correct Answer is B.","comment_id":"951860","poster":"EEK2k","timestamp":"1689371640.0","upvote_count":"3"},{"timestamp":"1688891220.0","poster":"Iragmt","upvote_count":"3","content":"Selected Answer: B\nB\nKey words here are \n- Average latency must be less than 1 second on updates to the reservation database.\n- single primary reservation database that is globally consistent\n\nDynamoDB - multi-region,multi-master\nAurora Global database - multi-region,single-master","comments":[{"timestamp":"1689047700.0","content":"option B. specifies Aurora MySQL database, not Aurora Global Database.","comment_id":"948656","upvote_count":"4","poster":"baba365"}],"comment_id":"947003"},{"timestamp":"1687632180.0","comment_id":"932846","upvote_count":"3","content":"B \"An Aurora Global Database uses storage-based replication to replicate a database across multiple Regions, with typical latency of less than one second\"","poster":"mattcl"},{"comment_id":"931552","upvote_count":"2","timestamp":"1687521360.0","content":"Selected Answer: B\nhttps://aws.amazon.com/rds/aurora/global-database/","poster":"live_reply_developers"},{"upvote_count":"3","comment_id":"916105","content":"Selected Answer: A\nhttps://aws.amazon.com/dynamodb/global-tables/","poster":"DrWatson","timestamp":"1686044880.0"},{"content":"Selected Answer: B\nIt's B:\n\nhttps://aws.amazon.com/blogs/architecture/using-amazon-aurora-global-database-for-low-latency-without-application-changes/","upvote_count":"2","comment_id":"915388","timestamp":"1685964420.0","poster":"antropaws","comments":[{"content":"There is no Aurora Global, but simple Aurora","upvote_count":"4","poster":"vrevkov","comment_id":"927676","timestamp":"1687191480.0"}]},{"timestamp":"1685956440.0","poster":"Abrar2022","comment_id":"915261","upvote_count":"1","content":"Selected Answer: A\nA. Convert the application to use Amazon DynamoDB. Use a global table for the center reservation table. Use the correct Regional endpoint in each Regional deployment."},{"comment_id":"910759","content":"BBBBBBBBBBBB","upvote_count":"2","poster":"omoakin","timestamp":"1685502480.0"},{"timestamp":"1684486380.0","comment_id":"901783","upvote_count":"3","content":"Selected Answer: B\nthis is why b for me","poster":"nosense"},{"upvote_count":"1","timestamp":"1684486200.0","comments":[{"comment_id":"925773","timestamp":"1686978420.0","content":"?????? DynamoDB is not scalable????????","upvote_count":"3","poster":"Abrar2022"}],"comment_id":"901780","poster":"nosense","content":"A is not scalable because Amazon DynamoDB is a NoSQL database that is not designed for global consistency.\nC This solution is not as scalable as Amazon Aurora because Amazon RDS for MySQL does not support read replicas in multiple Regions."},{"content":"Selected Answer: A\nA. Convert the application to use Amazon DynamoDB. Use a global table for the center reservation table. Use the correct Regional endpoint in each Regional deployment.","poster":"dacosa","upvote_count":"3","comment_id":"900711","timestamp":"1684376520.0","comments":[{"content":"For me same, Dynamo DB with global tables","timestamp":"1684414080.0","upvote_count":"1","poster":"Efren","comment_id":"901213"}]}],"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/109608-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":474,"isMC":true,"answer_images":[],"question_images":[],"choices":{"A":"Convert the application to use Amazon DynamoDB. Use a global table for the center reservation table. Use the correct Regional endpoint in each Regional deployment.","C":"Migrate the database to an Amazon RDS for MySQL database. Deploy MySQL read replicas in each Region. Use the correct Regional endpoint in each Regional deployment for access to the database.","B":"Migrate the database to an Amazon Aurora MySQL database. Deploy Aurora Read Replicas in each Region. Use the correct Regional endpoint in each Regional deployment for access to the database.","D":"Migrate the application to an Amazon Aurora Serverless database. Deploy instances of the database to each Region. Use the correct Regional endpoint in each Regional deployment to access the database. Use AWS Lambda functions to process event streams in each Region to synchronize the databases."},"answers_community":["A (51%)","B (49%)"],"question_text":"A company has a web application for travel ticketing. The application is based on a database that runs in a single data center in North America. The company wants to expand the application to serve a global user base. The company needs to deploy the application to multiple AWS Regions. Average latency must be less than 1 second on updates to the reservation database.\n\nThe company wants to have separate deployments of its web platform across multiple Regions. However, the company must maintain a single primary reservation database that is globally consistent.\n\nWhich solution should a solutions architect recommend to meet these requirements?","timestamp":"2023-05-18 04:22:00","answer_description":""},{"id":"xpZ5LcBhUA4WKyKyV14M","exam_id":31,"unix_timestamp":1684324560,"choices":{"E":"Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Specify the backup schedule to run twice daily. Copy on demand to us-west-2.","C":"Create backup vaults in us-west-1 and in us-west-2 by using AWS Backup. Create a backup plan for the EC2 instances based on tag values. Create an AWS Lambda function to run as a scheduled job to copy the backup data to us-west-2.","A":"Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Copy the image on demand.","D":"Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Define the destination for the copy as us-west-2. Specify the backup schedule to run twice daily.","B":"Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Configure the copy to the us-west-2 Region."},"discussion":[{"upvote_count":"10","comments":[{"upvote_count":"7","poster":"cloudenthusiast","content":"Both options automate the backup process and include copying the backups to the us-west-2 Region, ensuring data resilience in the event of a disaster. These solutions minimize administrative effort by leveraging automated backup and copy mechanisms provided by AWS services.","timestamp":"1700400480.0","comment_id":"901873"}],"poster":"cloudenthusiast","content":"Selected Answer: BD\nOption B suggests using an EC2-backed Amazon Machine Image (AMI) lifecycle policy to automate the backup process. By configuring the policy to run twice daily and specifying the copy to the us-west-2 Region, the company can ensure regular backups are created and copied to the alternate region.\n\nOption D proposes using AWS Backup, which provides a centralized backup management solution. By creating a backup vault and backup plan based on tag values, the company can automate the backup process for the EC2 instances. The backup schedule can be set to run twice daily, and the destination for the copy can be defined as the us-west-2 Region.","timestamp":"1700400480.0","comment_id":"901872"},{"content":"Selected Answer: BD\nLEAST admin overhead:\nA: On demand so wrong\nC: Lambda is overhead\nE: On-demand is wrong\n\nBD is the only choice. Although D seems to cover for B also, happy to be corrected.","upvote_count":"7","timestamp":"1721399820.0","comment_id":"1126816","poster":"awsgeek75"},{"poster":"pmlabs","timestamp":"1712130060.0","comment_id":"1023730","upvote_count":"2","content":"B D seems to meet the requiremnts fully"},{"upvote_count":"2","timestamp":"1708695000.0","poster":"Guru4Cloud","content":"Selected Answer: BD\nB and D are the options that meet the requirements with the least administrative effort.\n\nB uses EC2 image lifecycle policies to automatically create AMIs of the instances twice daily and copy them to the us-west-2 region. This automates regional backups.\n\nD leverages AWS Backup to define a backup plan that runs twice daily and copies backups to us-west-2. AWS Backup automates EC2 instance backups.\n\nTogether, these options provide automated, regional EC2 backup capabilities with minimal administrative overhead.","comment_id":"988236"},{"poster":"TariqKipkemei","timestamp":"1705473180.0","upvote_count":"2","comment_id":"953826","content":"Selected Answer: BD\noptions B and D will provide least administrative effort."},{"poster":"antropaws","timestamp":"1701783300.0","content":"Selected Answer: BD\nI also vote B and D.","comment_id":"915393","upvote_count":"2"},{"poster":"nosense","content":"Selected Answer: BD\nsolutions are both automated and require no manual intervention to create or copy backups","timestamp":"1700229360.0","comment_id":"900087","upvote_count":"5"}],"answer_images":[],"answer_description":"","timestamp":"2023-05-17 13:56:00","answers_community":["BD (100%)"],"question_images":[],"question_text":"A company has migrated multiple Microsoft Windows Server workloads to Amazon EC2 instances that run in the us-west-1 Region. The company manually backs up the workloads to create an image as needed.\n\nIn the event of a natural disaster in the us-west-1 Region, the company wants to recover workloads quickly in the us-west-2 Region. The company wants no more than 24 hours of data loss on the EC2 instances. The company also wants to automate any backups of the EC2 instances.\n\nWhich solutions will meet these requirements with the LEAST administrative effort? (Choose two.)","answer":"BD","url":"https://www.examtopics.com/discussions/amazon/view/109530-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"BD","topic":"1","isMC":true,"question_id":475}],"exam":{"name":"AWS Certified Solutions Architect - Associate SAA-C03","id":31,"isImplemented":true,"isBeta":false,"numberOfQuestions":1019,"isMCOnly":true,"provider":"Amazon","lastUpdated":"11 Apr 2025"},"currentPage":95},"__N_SSP":true}