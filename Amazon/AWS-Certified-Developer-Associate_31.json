{"pageProps":{"questions":[{"id":"2gUNJyFvmQPRzzOB61GP","isMC":true,"answer_description":"","question_id":151,"exam_id":25,"url":"https://www.examtopics.com/discussions/amazon/view/88819-exam-aws-certified-developer-associate-topic-1-question-234/","discussion":[{"timestamp":"1682456880.0","poster":"OtavioC","comment_id":"880861","content":"Selected Answer: BD\nA, C and E does not make sense:\n\nB. The function execution role does not allow access from Amazon S3: The execution role assigned to the Lambda function needs to have permissions to read from and write to the S3 bucket. If the execution role does not have the necessary permissions, the Lambda function will not be able to access the S3 bucket.\n\nD. The S3 bucket policy does not allow access from the Lambda function: The S3 bucket policy needs to allow the Lambda function to access the S3 bucket. If the policy does not allow access from the Lambda function, the Lambda function will not be able to read from or write to the S3 bucket.\n\nA and C are not possible reasons for this failure because they both refer to the function resource policy, which is not relevant to S3 bucket access. Similarly, E is not a possible reason because S3 bucket policies do not grant access to Lambda functions; they only control access to S3 resources.","upvote_count":"2"},{"poster":"anitauk","timestamp":"1676559180.0","content":"Selected Answer: CD\ncdcdcdcdcdcdcdcdcdcd","comment_id":"810783","upvote_count":"4"},{"timestamp":"1672564500.0","upvote_count":"3","comment_id":"763120","poster":"by116549","content":"Looks to be C and D:\nhttps://repost.aws/knowledge-center/lambda-execution-role-s3-bucket\n\nTo give your Lambda function access to an Amazon S3 bucket in the same AWS account, do the following:\n1. Create an AWS Identity and Access Management (IAM) role for the Lambda function that also grants access to the S3 bucket.\n2. Configure the IAM role as the Lambda function's execution role.\n3. Verify that the S3 bucket policy doesn't explicitly deny access to your Lambda function or its execution role."},{"timestamp":"1669826100.0","poster":"k1kavi1","comment_id":"731750","upvote_count":"3","content":"Selected Answer: CD\nChoosing C&D"},{"poster":"michaldavid","comment_id":"727284","content":"Selected Answer: CD\nShouldn't this be C and D?","timestamp":"1669441680.0","upvote_count":"3"}],"topic":"1","question_text":"A developer is troubleshooting a new AWS Lambda function. The function should run automatically each time a new object is uploaded to an Amazon S3 bucket. The function is supposed to read the object, make modifications, and overwrite the object with the new version. The developer finds that all calls failed within the function code.\n\nWhich of the following are possible reasons for this failure? (Choose two.)","answer_images":[],"timestamp":"2022-11-26 06:48:00","answer":"CD","question_images":[],"answer_ET":"CD","answers_community":["CD (83%)","BD (17%)"],"unix_timestamp":1669441680,"choices":{"B":"The function execution role does not allow access from Amazon S3.","E":"The S3 bucket policy does not allow access to the Lambda function.","D":"The S3 bucket policy does not allow access from the Lambda function.","C":"The function execution role does not allow access to Amazon S3.","A":"The function resource policy does not allow access from Amazon S3."}},{"id":"fdtIMyv5gCklS1Iq9UKF","unix_timestamp":1669364280,"discussion":[{"poster":"rcaliandro","timestamp":"1688057280.0","upvote_count":"1","comment_id":"938380","content":"Selected Answer: AC\nAC AC AC"},{"content":"It should be A and B !","timestamp":"1676888820.0","upvote_count":"1","comment_id":"815122","poster":"zek"},{"comment_id":"813617","poster":"Ankit1010","timestamp":"1676768160.0","upvote_count":"1","content":"A. Implement retries with exponential backoff: When the PutRecords API call fails, the application can implement retries with exponential backoff. This technique involves retrying the API call after a certain amount of time, with the duration of the wait increasing exponentially with each failed attempt.\n\nC. Reduce the frequency and/or size of the requests: The application can reduce the frequency and/or size of the requests sent to Kinesis. This technique can help reduce the amount of data processed by the Kinesis stream and prevent exceeding the provisioned throughput limit."},{"timestamp":"1669441800.0","poster":"michaldavid","upvote_count":"3","comment_id":"727286","content":"Selected Answer: AC\nhttps://www.examtopics.com/discussions/amazon/view/69142-exam-aws-certified-developer-associate-topic-1-question-370/"},{"upvote_count":"4","timestamp":"1669388280.0","poster":"k1kavi1","content":"Selected Answer: AC\nhttps://www.examtopics.com/discussions/amazon/view/69142-exam-aws-certified-developer-associate-topic-1-question-370/","comment_id":"726869"},{"content":"https://www.examtopics.com/discussions/amazon/view/69142-exam-aws-certified-developer-associate-topic-1-question-370/","upvote_count":"3","comment_id":"726498","poster":"kapil206001","timestamp":"1669364280.0"}],"question_images":["https://img.examtopics.com/aws-certified-developer-associate/image18.png"],"answer_ET":"AC","answer_description":"","timestamp":"2022-11-25 09:18:00","answer_images":[],"topic":"1","choices":{"A":"Implement retries with exponential backoff.","C":"Reduce the frequency and/or size of the requests.","E":"Reduce the number of KCL consumers.","B":"Use a PutRecord API instead of PutRecords.","D":"Use Amazon SNS instead of Kinesis."},"question_id":152,"question_text":"An application is processing clickstream data using Amazon Kinesis. The clickstream data feed into Kinesis experiences periodic spikes. The PutRecords API call occasionally fails and the logs show that the failed call returns the response shown below:\n\n//IMG//\n\n\nWhich techniques will help mitigate this exception? (Choose two.)","exam_id":25,"answers_community":["AC (100%)"],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/88637-exam-aws-certified-developer-associate-topic-1-question-235/","answer":"AC"},{"id":"iVdJUvKkEE5s9xtCq6UP","unix_timestamp":1669364520,"question_images":[],"discussion":[{"upvote_count":"1","timestamp":"1688057460.0","content":"Selected Answer: C\nC easy. We have to use ECS_ENABLE_TASK_IAM_ROLE to user roles in the containers. Then we have to grant access to Aurora to the first instance and DynamoDB to the second one.","comment_id":"938381","poster":"rcaliandro"},{"timestamp":"1677472260.0","poster":"pancman","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"823184","content":"But C in the exam didn't say Aurora, it said DynamoDB","timestamp":"1677472320.0","poster":"pancman"},{"timestamp":"1678863720.0","poster":"Dun6","content":"Was this DVA-C02","upvote_count":"1","comment_id":"839603"}],"comment_id":"823183","content":"This question was on the exam today (Feb 2023)"},{"comment_id":"811266","poster":"pancman","upvote_count":"1","timestamp":"1676595360.0","content":"Selected Answer: C\nC is correct."},{"upvote_count":"1","poster":"michaldavid","timestamp":"1669442040.0","comment_id":"727291","content":"Selected Answer: C\nAgree with C"},{"comment_id":"726882","content":"Selected Answer: C\nhttps://www.examtopics.com/discussions/amazon/view/29085-exam-aws-certified-developer-associate-topic-1-question-291/","upvote_count":"1","timestamp":"1669389660.0","comments":[{"timestamp":"1669866480.0","content":"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html","comment_id":"732219","poster":"k1kavi1","upvote_count":"3"}],"poster":"k1kavi1"},{"upvote_count":"1","poster":"kapil206001","timestamp":"1669364520.0","content":"https://www.examtopics.com/discussions/amazon/view/29085-exam-aws-certified-developer-associate-topic-1-question-291/","comment_id":"726501"}],"answer_ET":"C","answer_description":"","timestamp":"2022-11-25 09:22:00","answer_images":[],"topic":"1","choices":{"B":"Set ECS_ENABLE_TASK_IAM_ROLE to false on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.","A":"Set ECS_ENABLE_TASK_IAM_ROLE to false on EC2 instance boot in ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB.","D":"Set ECS_ENABLE_TASK_IAM_ROLE to true on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.","C":"Set ECS_ENABLE_TASK_IAM_ROLE to true on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB."},"question_id":153,"question_text":"Two containerized microservices are hosted on Amazon EC2 ECS. The first microservice reads an Amazon RDS Aurora database instance, and the second microservice reads an Amazon DynamoDB table.\n\nHow can each microservice be granted the minimum privileges?","exam_id":25,"answers_community":["C (100%)"],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/88638-exam-aws-certified-developer-associate-topic-1-question-236/","answer":"C"},{"id":"9UysS6ZIcxDCN5FgQb3z","answer_description":"","topic":"1","discussion":[{"comment_id":"938383","upvote_count":"2","timestamp":"1688057640.0","poster":"rcaliandro","content":"Selected Answer: C\nCI/CD - Use code commit as source control and use the other steps of the pipeline to build and deploy the app. C is the correct one."},{"comment_id":"811265","poster":"pancman","comments":[{"upvote_count":"2","timestamp":"1680679740.0","comment_id":"861839","poster":"shahs10","content":"How will the developers collaborate with each other?"},{"comment_id":"938382","poster":"rcaliandro","content":"It's written that a source control is needed","timestamp":"1688057580.0","upvote_count":"1"}],"timestamp":"1676595300.0","content":"Why not B using SAM? It is a serverless application after all","upvote_count":"1"},{"content":"Selected Answer: C\nC is the correct answer","comment_id":"743410","poster":"fabriciollf","upvote_count":"2","timestamp":"1670887320.0"},{"poster":"hamimelon","comment_id":"734116","upvote_count":"3","content":"C is automated. Also, in A, it says \"upload\", I don't know if it means pushing the code or literally upload it manually.","timestamp":"1670024100.0"},{"comment_id":"727292","timestamp":"1669442220.0","poster":"michaldavid","upvote_count":"4","content":"Selected Answer: C\nTorn between A and C but leaning towards C"},{"upvote_count":"3","content":"Selected Answer: C\nC - fewest number of manual steps","timestamp":"1669389840.0","comment_id":"726886","poster":"k1kavi1"}],"timestamp":"2022-11-25 16:24:00","isMC":true,"choices":{"A":"Build the code locally, and then upload the code into the source control system. When a release is needed, run AWS CodePipeline to extract the uploaded build and deploy the resources.","C":"Use AWS CodeBuild and AWS CodePipeline to invoke builds and corresponding deployments when configured source controlled branches have pull requests merged into them","D":"Use the Lambda console to upload a .zip file of the application that is created by the AWS Serverless Application Model (AWS SAM) CLI build command.","B":"Use the AWS Serverless Application Model (AWS SAM) CLI to build and deploy the application from the developer's local machine with the latest version checked out locally."},"answers_community":["C (100%)"],"unix_timestamp":1669389840,"question_id":154,"answer":"C","question_images":[],"question_text":"A developer is writing a new serverless application for a company. Several other developers must collaborate on the code for this application, and the company expects frequent changes to the code. The developer needs to deploy the code from source control to AWS Lambda with the fewest number of manual steps.\n\nWhich strategy for the build and deployment should the developer use to meet these requirements?","answer_ET":"C","exam_id":25,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/88717-exam-aws-certified-developer-associate-topic-1-question-237/"},{"id":"ERzXSGMyqm9gYWSXDarX","unix_timestamp":1669365000,"discussion":[{"timestamp":"1688058120.0","upvote_count":"2","comment_id":"938390","poster":"rcaliandro","content":"Selected Answer: D\nOne strategy to release a new version of the software as soon as a library is updated, is to create an AWS CodeArtifact repository, publish the .jar library to the repo and create a CloudWatch Event to monitor changes in the library and run the pipeline. I agree with you, D is the correct one."},{"timestamp":"1669866720.0","comment_id":"732221","content":"Selected Answer: D\nAgreed","upvote_count":"2","poster":"k1kavi1"},{"upvote_count":"2","comment_id":"727296","poster":"michaldavid","timestamp":"1669442400.0","content":"Selected Answer: D\nThis is D"},{"comment_id":"726514","timestamp":"1669365000.0","content":"D\nhttps://docs.aws.amazon.com/codeartifact/latest/ug/working-with-service-events.html","upvote_count":"2","poster":"kapil206001"}],"question_images":[],"answer_description":"","answer_ET":"D","answer_images":[],"timestamp":"2022-11-25 09:30:00","topic":"1","choices":{"A":"Create an Amazon S3 bucket to store the dependency .jar file. Publish the dependency .jar file to the S3 bucket. Use an Amazon Simple Notification Service (Amazon SNS) notification to start a CodePipeline pipeline build.","D":"Create an AWS CodeArtifact repository. Publish the dependency .jar file to the repository. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to start a CodePipeline pipeline build.","C":"Create an Amazon Elastic Container Registry (Amazon ECR) private repository. Publish the dependency .jar file to the repository. Use an Amazon Simple Notification Service (Amazon SNS) notification to start a CodePipeline pipeline build.","B":"Create an Amazon Elastic Container Registry (Amazon ECR) private repository. Publish the dependency jar file to the repository. Use an ECR source action to start a CodePipeline pipeline build."},"question_id":155,"question_text":"A developer is using an AWS CodePipeline pipeline to provide continuous integration and continuous delivery (CI/CD) support for a Java application. The developer needs to update the pipeline to support the introduction of a new application dependency .jar file. The pipeline must start a build when a new version of the .jar file becomes available.\n\nWhich solution will meet these requirements?","exam_id":25,"answers_community":["D (100%)"],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/88641-exam-aws-certified-developer-associate-topic-1-question-238/","answer":"D"}],"exam":{"lastUpdated":"11 Apr 2025","isMCOnly":true,"provider":"Amazon","name":"AWS Certified Developer Associate","isBeta":false,"numberOfQuestions":443,"id":25,"isImplemented":true},"currentPage":31},"__N_SSP":true}