{"pageProps":{"questions":[{"id":"V6GbMQKMaGqiFIc5lweV","topic":"1","question_text":"A company is using a centralized AWS account to store log data in various Amazon S3 buckets. A solutions architect needs to ensure that the data is encrypted at rest before the data is uploaded to the S3 buckets. The data also must be encrypted in transit.\n\nWhich solution meets these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/95031-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2023-01-13 13:14:00","answer_description":"","answers_community":["A (94%)","6%"],"answer_images":[],"discussion":[{"upvote_count":"29","timestamp":"1674132360.0","content":"Selected Answer: A\nhere keyword is \"before\" \"the data is encrypted at rest before the data is uploaded to the S3 buckets.\"","comment_id":"781136","poster":"techhb"},{"upvote_count":"5","comment_id":"776858","poster":"mhmt4438","content":"Selected Answer: A\nhttps://www.examtopics.com/discussions/amazon/view/53840-exam-aws-certified-solutions-architect-associate-saa-c02/","timestamp":"1673803140.0"},{"comment_id":"1351497","content":"Selected Answer: A\nFor those who are confused with the data also must be encrypted in transit, Amazon S3 TLS (Transport Layer Security) is used by default and you can't disable it.","timestamp":"1738687680.0","upvote_count":"2","poster":"Dantecito"},{"poster":"LeonSauveterre","timestamp":"1732519740.0","content":"Selected Answer: A\nAfter a little googling, for those who are confused by \"at rest\":\n\n1. *Encryption at Rest* refers to the encryption applied to the stored data. Encryption may be implemented at the source, where data is generated and stored at the origin.\n\n2. *Encryption in Transit* refers to encrypting data that is transferred between two nodes of the network.\n\n3. *End-to-End Encryption* refers to the combination of the encryption at rest and encryption in transit.","upvote_count":"3","comment_id":"1317358"},{"content":"A\nI believe the question is crafted to cause some confusion. At the same time it is simple to answer, since client side encryption answers the the requirements.","comment_id":"1298807","poster":"babayomi","upvote_count":"2","timestamp":"1729095660.0"},{"poster":"reviewmine","timestamp":"1708426980.0","comment_id":"1154646","content":"Selected Answer: A\nAnswer is A. Encrypt it first before uploading to S3.","upvote_count":"2"},{"timestamp":"1703833020.0","poster":"pentium75","comments":[{"comments":[{"poster":"awsgeek75","timestamp":"1705526760.0","upvote_count":"2","content":"For a moment I bought into your reasoning for C assuming that maybe the question is missing some grammar construct but realised that C does not really solve the encryption in transit issue like I originally thought. BUT good work!","comment_id":"1125347"}],"comment_id":"1108397","content":"On second thought, C would not enforce encryption in transit. Thus must be A indeed.","timestamp":"1703833620.0","upvote_count":"3","poster":"pentium75"}],"content":"Selected Answer: C\nI think the many votes for A are caused by misunderstanding the wording as\n\"Ensure that\nthe data is encrypted at rest before the data is uploaded\"\n\nBut that doesn't make sense, it means\n\n\"Ensure that the data is encrypted at rest\nbefore the data is uploaded\"\n\nSo, before you allow people to upload data, make sure that it gets encrypted.","comment_id":"1108387","upvote_count":"3"},{"comment_id":"1095961","timestamp":"1702520820.0","upvote_count":"3","poster":"Cyberkayu","content":"BCD, data not yet encrypted before landing on S3 bucket"},{"content":"Selected Answer: C\nHTTPs would encrypt in transe, SSE3 managed keys fulfills requirement for at rest. This is an aws exam, not a best practices exam.","poster":"palthainon","comments":[{"poster":"awsgeek75","comment_id":"1125351","upvote_count":"4","timestamp":"1705526940.0","content":"No. HTTPS is not enough for encryption in transit when it comes to S3.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingClientSideEncryption.html\n\n\"Client-side encryption is the act of encrypting your data locally to help ensure its security in transit and at rest. \""}],"timestamp":"1698244860.0","comment_id":"1053807","upvote_count":"1"},{"poster":"petertang224","upvote_count":"1","content":"Its_SaKar","comment_id":"1044294","timestamp":"1697386920.0"},{"comment_id":"1025220","upvote_count":"4","timestamp":"1696465140.0","poster":"prabhjot","content":"Ans is B - Server-Side Encryption (SSE): ensure data is encrypted at rest and also Encryption in Transit: When you upload data to Amazon S3 using standard HTTPS requests."},{"upvote_count":"2","comment_id":"1020446","timestamp":"1695961860.0","content":"Selected Answer: A\nUse client-side encryption to encrypt the data that is being uploaded to the S3 buckets","poster":"TariqKipkemei"},{"poster":"Guru4Cloud","comment_id":"1002493","upvote_count":"2","content":"Selected Answer: A\nA. Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets.","timestamp":"1694178060.0"},{"poster":"Guru4Cloud","content":"Selected Answer: A\nA. Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets.","timestamp":"1694025300.0","upvote_count":"2","comment_id":"1000883"},{"upvote_count":"4","content":"Selected Answer: A\ndata must be encrypted before uploaded , which means the client need to do it before uploading the data to S3","poster":"Abobaloyi","comment_id":"929160","timestamp":"1687332720.0"},{"poster":"datz","content":"Selected Answer: A\nA, would meet requirements.","comment_id":"865154","timestamp":"1680996000.0","upvote_count":"2"},{"upvote_count":"3","comment_id":"819540","content":"Selected Answer: A\nBecause the data must be encrypted while in transit","poster":"nder","timestamp":"1677176520.0"},{"upvote_count":"2","poster":"LuckyAro","timestamp":"1675286820.0","content":"Selected Answer: A\nA is correct IMO","comment_id":"795536"},{"timestamp":"1673737020.0","poster":"Aninina","content":"Selected Answer: A\nA. Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets.","upvote_count":"3","comment_id":"775999"},{"comments":[{"timestamp":"1690905720.0","poster":"Kesha","content":"B. With server-side encryption, it automatically encrypts the data at rest using encryption keys managed by AWS.","comment_id":"969183","upvote_count":"2"}],"upvote_count":"3","timestamp":"1673612040.0","poster":"bamishr","content":"Selected Answer: A\nUse client-side encryption to encrypt the data that is being uploaded to the S3 buckets","comment_id":"774431"}],"choices":{"C":"Create bucket policies that require the use of server-side encryption with S3 managed encryption keys (SSE-S3) for S3 uploads.","B":"Use server-side encryption to encrypt the data that is being uploaded to the S3 buckets.","D":"Enable the security option to encrypt the S3 buckets through the use of a default AWS Key Management Service (AWS KMS) key.","A":"Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets."},"question_images":[],"isMC":true,"question_id":211,"answer_ET":"A","answer":"A","unix_timestamp":1673612040,"exam_id":31},{"id":"p10P9oSe7w7y4n5j3uZg","choices":{"A":"Increase the minimum capacity for the Auto Scaling group.","B":"Increase the maximum capacity for the Auto Scaling group.","C":"Configure scheduled scaling to scale up to the desired compute level.","D":"Change the scaling policy to add more EC2 instances during each scaling operation."},"url":"https://www.examtopics.com/discussions/amazon/view/95018-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"C","topic":"1","question_id":212,"question_images":[],"exam_id":31,"timestamp":"2023-01-13 12:06:00","answers_community":["C (100%)"],"discussion":[{"upvote_count":"42","timestamp":"1707441300.0","comment_id":"802713","poster":"ManOnTheMoon","content":"GOOD LUCK EVERYONE :) YOU CAN DO THIS"},{"comment_id":"782294","timestamp":"1705758120.0","content":"Selected Answer: C\nC is correct. Goodluck everybody!","upvote_count":"16","poster":"david76x"},{"content":"Selected Answer: C\nConfiguring scheduled scaling actions allows the Auto Scaling group to scale up to the desired capacity at a scheduled time (1 AM in this case) when the batch jobs start. This ensures the desired compute capacity is reached immediately.\n\nThe Auto Scaling group can then scale down based on metrics after the batch jobs complete.","poster":"Guru4Cloud","comment_id":"1000878","upvote_count":"9","timestamp":"1725647220.0"},{"content":"Selected Answer: C\nThe time is given, use scheduled for optimal cost","comment_id":"960108","upvote_count":"4","timestamp":"1721712780.0","poster":"hsinchang"},{"content":"just scheduled my exam :)","poster":"qacollin","timestamp":"1713464220.0","comment_id":"873977","upvote_count":"7"},{"timestamp":"1707639900.0","poster":"awscerts023","upvote_count":"6","content":"Reached here ! Did anyone schedule the real exam now ? How was it ?","comment_id":"805080"},{"poster":"pal40sg","comment_id":"804346","timestamp":"1707571380.0","content":"Thanks to everyone who contributed with answers :)","upvote_count":"5"},{"upvote_count":"5","comment_id":"795199","content":"Selected Answer: C\nC. I'm here at the end, leaving this here for posterity sake 02/01/2023.","timestamp":"1706796000.0","poster":"ProfXsamson"},{"upvote_count":"5","comment_id":"787577","poster":"dedline","content":"GL ALL!","timestamp":"1706184300.0"},{"comment_id":"776860","poster":"mhmt4438","timestamp":"1705339200.0","content":"Selected Answer: C\nhttps://www.examtopics.com/discussions/amazon/view/27868-exam-aws-certified-solutions-architect-associate-saa-c02/","upvote_count":"2"},{"timestamp":"1705273140.0","comment_id":"776002","poster":"Aninina","content":"Selected Answer: C\nC. Configure scheduled scaling to scale up to the desired compute level.\n\nBy configuring scheduled scaling, the solutions architect can set the Auto Scaling group to automatically scale up to the desired compute level at a specific time (1AM) when the batch job starts and then automatically scale down after the job is complete. This will allow the desired EC2 capacity to be reached quickly and also help in reducing the cost.","upvote_count":"5"},{"content":"Selected Answer: C\nConfigure scheduled scaling to scale up to the desired compute level.","comment_id":"774429","timestamp":"1705147980.0","upvote_count":"2","poster":"bamishr"},{"poster":"Morinator","upvote_count":"5","content":"Selected Answer: C\npredictable = schedule scaling","timestamp":"1705143960.0","comment_id":"774361"}],"question_text":"A solutions architect observes that a nightly batch processing job is automatically scaled up for 1 hour before the desired Amazon EC2 capacity is reached. The peak capacity is the ‘same every night and the batch jobs always start at 1 AM. The solutions architect needs to find a cost-effective solution that will allow for the desired EC2 capacity to be reached quickly and allow the Auto Scaling group to scale down after the batch jobs are complete.\n\nWhat should the solutions architect do to meet these requirements?","unix_timestamp":1673607960,"answer_ET":"C","isMC":true,"answer_description":"","answer_images":[]},{"id":"oU1OugLqPRDTY9spX43C","url":"https://www.examtopics.com/discussions/amazon/view/99865-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"question_images":[],"answer":"B","timestamp":"2023-02-18 18:19:00","answer_description":"","question_id":213,"isMC":true,"unix_timestamp":1676740740,"choices":{"B":"Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to cache based on the Accept-Language request header.","A":"Replace the existing architecture with a website that is served from an Amazon S3 bucket. Configure an Amazon CloudFront distribution with the S3 bucket as the origin. Set the cache behavior settings to cache based on the Accept-Language request header.","C":"Create an Amazon API Gateway API that is integrated with the ALB. Configure the API to use the HTTP integration type. Set up an API Gateway stage to enable the API cache based on the Accept-Language request header.","D":"Launch an EC2 instance in each additional Region and configure NGINX to act as a cache server for that Region. Put all the EC2 instances and the ALB behind an Amazon Route 53 record set with a geolocation routing policy."},"answers_community":["B (100%)"],"discussion":[{"poster":"Yechi","comment_id":"813333","timestamp":"1676740740.0","upvote_count":"13","content":"Selected Answer: B\nConfiguring caching based on the language of the viewer\nIf you want CloudFront to cache different versions of your objects based on the language specified in the request, configure CloudFront to forward the Accept-Language header to your origin.\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/header-caching.html"},{"upvote_count":"3","content":"B\n\nIf you want CloudFront to cache different versions of your objects based on the language specified in the request, configure CloudFront to forward the Accept-Language header to your origin.\nIf you want CloudFront to cache different versions of your objects based on the country that the request came from, configure CloudFront to forward the CloudFront-Viewer-Country header to your origin. CloudFront automatically converts the IP address that the request came from into a two-letter country code. For an easy-to-use list of country codes, sortable by code and by country name, see the Wikipedia entry ISO 3166-1 alpha-2.","poster":"[Removed]","timestamp":"1718225880.0","comment_id":"1229501"},{"upvote_count":"2","comments":[{"comment_id":"1129064","content":"Cloudfront serves for both static and dynamic. If it was just static,then you can consider AWS S3.","timestamp":"1705959060.0","upvote_count":"5","poster":"Cloud_A"}],"content":"Isn't CloudFront for static websites though? Question specifically states the content is dynamic","poster":"Trains","timestamp":"1700365680.0","comment_id":"1074434"},{"content":"Selected Answer: B\nBy caching content based on the Accept-Language request header, CloudFront can serve the appropriate version of the website to users based on their language preferences. This solution allows the company to improve the website’s performance for users around the world without having to recreate the existing architecture in multiple Regions.","poster":"Guru4Cloud","timestamp":"1694024640.0","upvote_count":"4","comment_id":"1000876"},{"content":"Selected Answer: B\nCloudFront allows you to customize cache behavior based on various request headers. By setting the cache behavior to cache based on the Accept-Language request header, CloudFront can store and serve language-specific versions of the website content, reducing the need to repeatedly fetch the content from the ALB for users with the same language preference.","comment_id":"969486","upvote_count":"3","timestamp":"1690932840.0","poster":"A1975"},{"poster":"kraken21","comment_id":"857370","upvote_count":"1","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/header-caching.html#header-caching-web-language","timestamp":"1680289140.0"},{"content":"Selected Answer: B\nB is correct","upvote_count":"1","comment_id":"828143","poster":"vherman","timestamp":"1677862980.0"},{"content":"Selected Answer: B\nI think it's b","upvote_count":"2","poster":"Steve_4542636","comment_id":"827127","timestamp":"1677775920.0"},{"poster":"LuckyAro","upvote_count":"1","content":"Selected Answer: B\nB is the correct answer","timestamp":"1676893740.0","comment_id":"815182"}],"answer_images":[],"question_text":"A company serves a dynamic website from a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The website needs to support multiple languages to serve customers around the world. The website’s architecture is running in the us-west-1 Region and is exhibiting high request latency for users that are located in other parts of the world.\n\nThe website needs to serve requests quickly and efficiently regardless of a user’s location. However, the company does not want to recreate the existing architecture across multiple Regions.\n\nWhat should a solutions architect do to meet these requirements?","topic":"1","answer_ET":"B"},{"id":"QZZCKPYTPvyGe65iuURp","answer_ET":"B","answer_description":"","question_text":"A rapidly growing ecommerce company is running its workloads in a single AWS Region. A solutions architect must create a disaster recovery (DR) strategy that includes a different AWS Region. The company wants its database to be up to date in the DR Region with the least possible latency. The remaining infrastructure in the DR Region needs to run at reduced capacity and must be able to scale up if necessary.\n\nWhich solution will meet these requirements with the LOWEST recovery time objective (RTO)?","topic":"1","answer":"B","question_images":[],"isMC":true,"exam_id":31,"answer_images":[],"discussion":[{"comment_id":"813812","poster":"Yechi","content":"Selected Answer: B\nNote: The difference between pilot light and warm standby can sometimes be difficult to understand. Both include an environment in your DR Region with copies of your primary Region assets. The distinction is that pilot light cannot process requests without additional action taken first, whereas warm standby can handle traffic (at reduced capacity levels) immediately. The pilot light approach requires you to “turn on” servers, possibly deploy additional (non-core) infrastructure, and scale up, whereas warm standby only requires you to scale up (everything is already deployed and running). Use your RTO and RPO needs to help you choose between these approaches.\n\nhttps://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html","upvote_count":"28","timestamp":"1692422100.0"},{"poster":"nickolaj","timestamp":"1692373560.0","comment_id":"813347","upvote_count":"23","content":"Selected Answer: B\nOption A is incorrect because while Amazon Aurora global database is a good solution for disaster recovery, pilot light deployment provides only a minimalistic setup and would require manual intervention to make the DR Region fully operational, which increases the recovery time.\n\nOption B is a better choice than Option A as it provides a warm standby deployment, which is an automated and more scalable setup than pilot light deployment. In this setup, the database is replicated to the DR Region, and the standby instance can be brought up quickly in case of a disaster.\n\nOption C is incorrect because Multi-AZ DB instances provide high availability, not disaster recovery.\n\nOption D is a good choice for high availability, but it does not meet the requirement for DR in a different region with the least possible latency."},{"content":"Selected Answer: B\nB: Warm Standby is better when it comes to LOWEST RTO.\nhttps://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html","comment_id":"1125398","poster":"awsgeek75","timestamp":"1721248560.0","upvote_count":"2"},{"poster":"pentium75","timestamp":"1719638220.0","content":"Selected Answer: B\n\"Different Region\" rules out C and D (\"Multi-AZ\" is within a region)\n\"Run at reduced capacity\" = warm standby (while \"pilot light\" means that DR resources are shut down and are started manually in case of failover)","upvote_count":"4","comment_id":"1108408"},{"comment_id":"1020459","poster":"TariqKipkemei","content":"Selected Answer: B\nThe warm standby approach involves ensuring that there is a scaled down, but fully functional, copy of your production environment in another Region. \nWith the pilot light approach, you replicate your data from one Region to another and provision a copy of your core workload infrastructure. Resources required to support data replication and backup, such as databases and object storage, are always on. Other elements, such as application servers, are loaded with application code and configurations, but are \"switched off\".","timestamp":"1711695420.0","upvote_count":"3"},{"upvote_count":"2","poster":"Guru4Cloud","timestamp":"1709754660.0","comment_id":"1000860","content":"Selected Answer: B\nAn Amazon Aurora global database with a warm standby deployment provides continuous replication from one AWS Region to another, keeping the DR database up-to-date with minimal latency."},{"content":"Selected Answer: B\nIn a Pilot Light scenario, only an EC2 Instance and a DB may be running. In Warm Standby, however, everything is running — in a much smaller capacity. This means the load balancer, gateways, databases, all subnets, and everything else are ready to go on a moment's notice.\n\nwith reference to below statement Option B is a better choice than Option A. \n\"The remaining infrastructure in the DR Region needs to run at reduced capacity and must be able to scale up if necessary\".","timestamp":"1706839380.0","poster":"A1975","upvote_count":"2","comment_id":"969498"},{"content":"Selected Answer: D\nshould be D.","comments":[{"poster":"pentium75","upvote_count":"3","content":"\"Multi-AZ\" = multiple AZs in same region, but requirement is \"a different AWS Region\".","timestamp":"1719638160.0","comment_id":"1108404"},{"poster":"leoattf","comment_id":"817736","timestamp":"1692694560.0","upvote_count":"10","content":"No, my friend. The question asks for deployment in another Region. Hence, it cannot be C or D. \nThe answer is B because is Global (different regions) and Ward Standby has faster RTO than Pilot Light."}],"comment_id":"811334","upvote_count":"2","timestamp":"1692234120.0","poster":"krisfromtw"}],"timestamp":"2023-02-17 04:02:00","choices":{"C":"Use an Amazon RDS Multi-AZ DB instance with a pilot light deployment.","D":"Use an Amazon RDS Multi-AZ DB instance with a warm standby deployment.","A":"Use an Amazon Aurora global database with a pilot light deployment.","B":"Use an Amazon Aurora global database with a warm standby deployment."},"url":"https://www.examtopics.com/discussions/amazon/view/99505-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["B (97%)","3%"],"question_id":214,"unix_timestamp":1676602920},{"id":"vWsUV9r0cmTgc3bpSKg4","question_id":215,"question_text":"A company runs an application on Amazon EC2 instances. The company needs to implement a disaster recovery (DR) solution for the application. The DR solution needs to have a recovery time objective (RTO) of less than 4 hours. The DR solution also needs to use the fewest possible AWS resources during normal operations.\n\nWhich solution will meet these requirements in the MOST operationally efficient way?","answer_ET":"B","question_images":[],"topic":"1","discussion":[{"upvote_count":"11","comments":[{"poster":"NBone","upvote_count":"5","comment_id":"957792","content":"please how do you use chatGPT to study for these questions?","timestamp":"1689868860.0"}],"content":"Guys, sorry but I don't really have time to deepdive as my exam is soon. Based on chatGPT and my previous study the answer should be B\n\"Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS CloudFormation,\" would likely be the most suitable solution for the given requirements.\n\nThis option allows for the creation of Amazon Machine Images (AMIs) to back up the EC2 instances, which can then be copied to a secondary AWS region to provide disaster recovery capabilities. The infrastructure deployment in the secondary region can be automated using AWS CloudFormation, which can help to reduce the amount of time and resources needed for deployment and management.","poster":"NolaHOla","timestamp":"1676578800.0","comment_id":"811075"},{"content":"Selected Answer: B\nOption B would be the most operationally efficient solution for implementing a DR solution for the application, meeting the requirement of an RTO of less than 4 hours and using the fewest possible AWS resources during normal operations.\n\nBy creating Amazon Machine Images (AMIs) to back up the EC2 instances and copying them to a secondary AWS Region, the company can ensure that they have a reliable backup in the event of a disaster. By using AWS CloudFormation to automate infrastructure deployment in the secondary Region, the company can minimize the amount of time and effort required to set up the DR solution.","upvote_count":"9","timestamp":"1676742420.0","poster":"nickolaj","comment_id":"813350"},{"timestamp":"1704427560.0","poster":"djgodzilla","content":"OPtion E : Automate infrastructure deployment in the secondary Region by using terraform and ditch AWS CloudFormation 😬🤪.","comment_id":"1114244","upvote_count":"6"},{"upvote_count":"3","timestamp":"1703834400.0","poster":"pentium75","content":"Selected Answer: B\nA is not \"most operationally efficient\"\nC and D do not meet the \"use the fewest possible AWS resources during normal operations\" requirement","comment_id":"1108409"},{"upvote_count":"3","timestamp":"1695996540.0","poster":"vijaykamal","content":"Selected Answer: B\nOption D suggests launching EC2 instances in a secondary Availability Zone (AZ), but AZs are not separate AWS Regions. While it provides high availability within a Region, it doesn't offer geographic redundancy, which is essential for disaster recovery.","comment_id":"1020855"},{"comment_id":"1020461","content":"Selected Answer: B\nneeds to use the fewest possible AWS resources during normal operations = backup & restore","upvote_count":"3","timestamp":"1695963600.0","poster":"TariqKipkemei"},{"timestamp":"1694021640.0","poster":"Guru4Cloud","content":"Selected Answer: B\nCreate Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS CloudFormation","comment_id":"1000849","upvote_count":"2"},{"comment_id":"1000120","upvote_count":"2","poster":"AMYMY","content":"B SHOULD BE RIGHT","timestamp":"1693969200.0"},{"upvote_count":"2","content":"Selected Answer: B\nOption A: Add complexity and management overhead.\n\nOption B: Creating AMIs for backup and using AWS CloudFormation for infrastructure deployment in the secondary Region is a more streamlined and automated approach. CloudFormation allows you to define and provision resources in a declarative manner, making it easier to maintain and update your infrastructure. This solution is more operationally efficient compared to Option A.\n\nOption C: could be expensive and not fully aligned with the requirement of using the fewest possible AWS resources during normal operations.\n\nOption D: might not be sufficient for meeting the DR requirements, as Availability Zones are still within the same AWS Region and might be subject to the same regional-level failures.","timestamp":"1690935840.0","comment_id":"969509","poster":"A1975"},{"comment_id":"957804","content":"Please I would really appreciate clarification with this question. The community has voted 100% that the right answer is B. However, option D is shown to be the correct answer. So, who sets the correct answer? Which one should new comers like myself believe? the community's or the other (which am guessing is set by the moderators???) Please help.","comments":[{"poster":"Kaula","timestamp":"1711884060.0","comment_id":"1186735","content":"From Examtopics support:\nIn very few cases a conflict is raised between the provided and most-voted answers. \n\nIn case of conflict between the provided & most voted answers, we suggest our customers rely on the most voted answers and consider them most correct.","upvote_count":"2"}],"upvote_count":"2","timestamp":"1689869280.0","poster":"NBone"},{"poster":"SimiTik","comment_id":"876854","timestamp":"1682113680.0","upvote_count":"3","content":"C may satisfy the requirement of using the fewest possible AWS resources during normal operations, it may not be the most operationally efficient or cost-effective solution in the long term."},{"upvote_count":"2","timestamp":"1677251580.0","poster":"AlmeroSenior","comment_id":"820655","content":"So Weird , they have product for this > Elastic Disaster Recovery , but option is not given ."},{"upvote_count":"5","timestamp":"1676791620.0","comment_id":"813821","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/zh_cn/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html#backup-and-restore","poster":"Yechi"},{"upvote_count":"4","comment_id":"812654","content":"Selected Answer: B\nthe answer should be B\n--->recovery time objective (RTO) of less than 4 hours.\n\nhttps://docs.aws.amazon.com/zh_cn/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html#backup-and-restore","timestamp":"1676695920.0","comments":[{"comment_id":"1314708","upvote_count":"1","content":"English version: https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html","poster":"JA2018","timestamp":"1732026960.0"}],"poster":"Joan111edu"}],"answer_images":[],"answer":"B","choices":{"D":"Launch EC2 instances in a secondary Availability Zone. Keep the EC2 instances in the secondary Availability Zone active at all times.","C":"Launch EC2 instances in a secondary AWS Region. Keep the EC2 instances in the secondary Region active at all times.","B":"Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS CloudFormation.","A":"Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS Lambda and custom scripts."},"exam_id":31,"unix_timestamp":1676578800,"timestamp":"2023-02-16 21:20:00","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/99459-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","isMC":true}],"exam":{"provider":"Amazon","isImplemented":true,"lastUpdated":"11 Apr 2025","id":31,"numberOfQuestions":1019,"isBeta":false,"isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":43},"__N_SSP":true}