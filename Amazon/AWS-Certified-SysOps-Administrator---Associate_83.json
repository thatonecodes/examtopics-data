{"pageProps":{"questions":[{"id":"cO04pdRIqtyBE9FftETt","choices":{"B":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule to evaluate the required custom dimensions and send the metrics to Amazon Simple Notification Service (Amazon SNS).","D":"Create an append_dimensions field in the Amazon CloudWatch agent configuration file to collect the metrics.","A":"Create a custom shell script to extract the dimensions and collect the metrics using the Amazon CloudWatch agent.","C":"Create an AWS Lambda function to collect the metrics from AWS CloudTrail and send the metrics to an Amazon CloudWatch Logs group."},"question_text":"A data analytics application is running on an Amazon EC2 instance. A SysOps administrator must add custom dimensions to the metrics collected by the Amazon\nCloudWatch agent.\nHow can the SysOps administrator meet this requirement?","isMC":true,"discussion":[{"timestamp":"1709028720.0","comment_id":"823515","comments":[{"comment_id":"977536","timestamp":"1723286880.0","upvote_count":"1","poster":"jipark","content":"wow great !!"}],"content":"Selected Answer: D\nExample of CloudWatch agent configuration file:\n\"append_dimensions\" : {\n    \"ImageId\" : \"${aws:ImageId}\"\n    \"InstanceId\" : \"${aws:InstanceId}\"\n}","upvote_count":"15","poster":"Hisayuki"},{"upvote_count":"7","timestamp":"1693597800.0","content":"Selected Answer: D\nIn custom metrics, the --dimensions parameter is common. A dimension further clarifies what the metric is and what data it stores. You can have up to 30 dimensions assigned to one metric, and each dimension is defined by a name and value pair\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html","comment_id":"656632","poster":"princajen"},{"upvote_count":"1","content":"Selected Answer: D\nAnswer is D","timestamp":"1702559760.0","poster":"BietTuot","comment_id":"745103"},{"comment_id":"738693","content":"Selected Answer: D\nddddddddd","timestamp":"1702017000.0","poster":"michaldavid","upvote_count":"1"}],"answer_description":"","exam_id":34,"url":"https://www.examtopics.com/discussions/amazon/view/79168-exam-aws-certified-sysops-administrator-associate-topic-1/","question_id":411,"topic":"1","answer_images":[],"unix_timestamp":1662061800,"answers_community":["D (100%)"],"timestamp":"2022-09-01 21:50:00","answer":"D","question_images":[],"answer_ET":"D"},{"id":"DqPktMdGsL0LJfn7Qqza","question_id":412,"unix_timestamp":1730060580,"question_text":"A company is using AWS to deploy a critical application on a fleet of Amazon EC2 instances. The company is rewriting the application because the application failed a security review. The application will take 12 months to rewrite. While this rewrite happens, the company needs to rotate IAM access keys that the application uses.\n\nA SysOps administrator must implement an automated solution that finds and rotates IAM access keys that are at least 30 days old. The solution must then continue to rotate the IAM access keys every 30 days.\n\nWhich solution will meet this requirement with the MOST operational efficiency?","exam_id":34,"answer":"A","timestamp":"2024-10-27 21:23:00","isMC":true,"topic":"1","answer_images":[],"answer_description":"","answer_ET":"A","choices":{"A":"Use an AWS Config rule to identify IAM access keys that are at least 30 days old. Configure AWS Config to invoke an AWS Systems Manager Automation runbook to rotate the identified IAM access keys.","B":"Use AWS Trusted Advisor to identify IAM access keys that are at least 30 days old. Configure Trusted Advisor to invoke an AWS Systems Manager Automation runbook to rotate the identified IAM access keys.","D":"Create an AWS Lambda function that checks the age of IAM access keys and rotates them if they are at least 30 days old. Use an Amazon EventBridge rule to invoke the Lambda function every time a new IAM access key is created.","C":"Create a script that checks the age of IAM access keys and rotates them if they are at least 30 days old. Launch an EC2 instance. Schedule the script to run as a cron expression on the EC2 instance every day."},"question_images":[],"discussion":[{"comment_id":"1323193","timestamp":"1733588760.0","upvote_count":"1","content":"Selected Answer: A\nThis is the most operationally efficient solution as it automates the process of identifying and rotating IAM access keys that are at least 30 days old. AWS Config can continuously monitor and record AWS resource configurations, and in this case, it can detect IAM access keys that reach a certain age. With an AWS Systems Manager Automation runbook, the process can be automated to rotate these keys without manual intervention.","poster":"numark"},{"timestamp":"1730699940.0","content":"Selected Answer: A\nCorrection: Voting for A.","upvote_count":"1","poster":"Aamee","comment_id":"1306800"},{"upvote_count":"2","comment_id":"1303953","timestamp":"1730119020.0","poster":"siheom","content":"Selected Answer: A\nvote A"},{"content":"Selected Answer: B\nAlthough the suggested ans. shows option A is correct but I've a doubt if option B can be the possible correct answer here...","timestamp":"1730060580.0","comments":[{"content":"After reading it again, I believe option A is a more better choice here...","upvote_count":"2","comment_id":"1303736","poster":"Aamee","timestamp":"1730060640.0"}],"comment_id":"1303735","poster":"Aamee","upvote_count":"1"}],"answers_community":["A (80%)","B (20%)"],"url":"https://www.examtopics.com/discussions/amazon/view/150381-exam-aws-certified-sysops-administrator-associate-topic-1/"},{"id":"LEPNIzC6Ncn4YfSh2XYQ","unix_timestamp":1732019880,"choices":{"C":"Turn on Instance Metadata Service Version 2 (IMDSv2).","D":"Use an Amazon Machine Image (AMI) that is based on Amazon Linux.","A":"Use an Amazon Machine Image (AMI) that includes the CloudWatch agent.","B":"Turn on CloudWatch detailed monitoring."},"answer_description":"","question_images":[],"question_text":"A company receives an alert from an Amazon CloudWatch alarm. The alarm indicates that a web application that is running on Amazon EC2 instances is not responding to requests. The EC2 instances have a Red Hat Enterprise Linux operating system and are in an Auto Scaling group. The Auto Scaling group has a minimum capacity of 2 and a maximum capacity of 5.\n\nAn investigation reveals that the web application is experiencing out-of-memory errors. The company adds memory to the web application and wants to track operating system memory utilization. A CloudWatch memory metric does not currently exist for the EC2 instances in the Auto Scaling group.\n\nWhat should a SysOps administrator do to provide a CloudWatch memory metric for the EC2 instances?","question_id":413,"answer":"A","exam_id":34,"timestamp":"2024-11-19 13:38:00","url":"https://www.examtopics.com/discussions/amazon/view/151634-exam-aws-certified-sysops-administrator-associate-topic-1/","answers_community":["A (100%)"],"discussion":[{"poster":"numark","timestamp":"1733589000.0","upvote_count":"1","content":"Selected Answer: A\nBy default, Amazon CloudWatch does not collect memory and disk space metrics from EC2 instances. To collect these additional metrics, you need to install the CloudWatch agent on your instances. Once installed and configured, the CloudWatch agent can collect system-level metrics such as memory utilization, which are not available by default in CloudWatch.","comment_id":"1323198"},{"comment_id":"1314625","poster":"numark","timestamp":"1732019880.0","upvote_count":"1","content":"A>>>>Amazon CloudWatch does not provide memory utilization metrics for EC2 instances by default. To enable memory utilization monitoring for EC2 instances, including those in an Auto Scaling group, the SysOps administrator must install the CloudWatch Agent and configure it to send memory metrics to CloudWatch."}],"answer_images":[],"topic":"1","answer_ET":"A","isMC":true},{"id":"PTUqqOqkJazvIqW2CucF","answer_description":"","unix_timestamp":1728992820,"isMC":true,"question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/149544-exam-aws-certified-sysops-administrator-associate-topic-1/","discussion":[{"content":"Selected Answer: D\nThis directly addresses the issue. The FreeLocalStorage metric is tied to the instance size - larger instance classes come with more temporary storage. Upgrading the instance class would provide more temporary storage for operations like the weekly report.","poster":"dspd","timestamp":"1743876420.0","comment_id":"1548331","upvote_count":"1"},{"content":"Selected Answer: B\nB cause addresses storage issue.\nnot C because a read replica does not have more local storage and results in the same issue.","upvote_count":"2","timestamp":"1736964600.0","poster":"dev_stape","comment_id":"1341182"},{"upvote_count":"1","content":"Selected Answer: B\nThis option directly addresses the low temporary storage issue by allowing the database to scale its storage automatically as required, ensuring that the database can handle the demands of the weekly report without running out of temporary storage.","poster":"examaws","timestamp":"1735730760.0","comment_id":"1335177"},{"content":"Selected Answer: C\npredicted, only \"read\" for report - C","poster":"Grodgar","comment_id":"1330252","timestamp":"1734833640.0","upvote_count":"1"},{"comments":[{"upvote_count":"1","timestamp":"1736965020.0","poster":"dev_stape","comment_id":"1341187","content":"If the pants are tight buying a new pair of the same size would not solve an issue..."}],"comment_id":"1323200","timestamp":"1733589300.0","poster":"numark","content":"Selected Answer: B\nAmazon Aurora supports storage auto-scaling. By enabling this feature, the SysOps administrator can ensure that the Aurora PostgreSQL production database automatically scales its storage, reducing the risk of running out of free local storage. This is particularly useful in cases where it's difficult to predict storage requirements in advance, such as fluctuating workloads.Adding an Aurora read replica would offload read traffic from the primary database and could potentially alleviate performance issues. However, since the question indicates that temporary storage space is the problem, and not necessarily the performance of read operations, this might not resolve the issue of running out of storage. Moreover, if the report generation involves a significant amount of data writing, a read replica will not help because write operations cannot be offloaded to read replicas.","upvote_count":"1"},{"poster":"igor12ghsj577","content":"Selected Answer: B\nI would say B.","timestamp":"1732911600.0","comment_id":"1319905","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nC makes most sense compared to all others..","comment_id":"1304515","poster":"Aamee","timestamp":"1730216340.0"},{"content":"Selected Answer: C\nFor A sec id like to think adding a read replica, would solve this.","upvote_count":"3","comment_id":"1298210","poster":"kutesa1407","timestamp":"1728992820.0"}],"question_text":"A company is using an Amazon CloudWatch alarm to monitor the FreeLocalStorage metric for an Amazon Aurora PostgreSQL production database. The alarm goes into ALARM state and indicates that the database is running low on temporary storage. A SysOps administrator discovers that a weekly report is using most of the temporary storage that is currently allocated.\n\nWhat should the SysOps administrator do to solve this problem?","timestamp":"2024-10-15 13:47:00","topic":"1","answers_community":["C (45%)","B (45%)","9%"],"question_id":414,"exam_id":34,"choices":{"D":"Modify the DB instance class for each DB instance in the DB cluster to increase the instance size.","A":"Turn on Aurora PostgreSQL query plan management.","B":"Modify the configuration of the DB cluster to turn on storage auto scaling.","C":"Add an Aurora read replica to the DB cluster. Modify the report to use the new read replica."},"answer":"C","answer_ET":"C"},{"id":"GyANN28J7J7uyu1HsDeU","question_text":"A company is running a development application on an Amazon EC2 instance. The application uploads 500,000 files that are 1 GB in size into a target Amazon S3 bucket that has default encryption enabled. The EC2 instance is in the same AWS Region where the S3 bucket is deployed.\n\nThe company uses performance logging that is built into the application software. The logs show that the application is constantly waiting for the files to be written to the S3 bucket. A SysOps administrator needs to improve the application's throughput performance. The SysOps administrator validates that the networking on the EC2 instance is not constrained.\n\nWhat should the SysOps administrator do to improve the S3 upload performance?","choices":{"B":"Split the S3 write operations to use multiple bucket prefixes to write items in parallel.","D":"Configure AWS Global Accelerator in the Region. Turn off encryption on the S3 bucket.","C":"Configure AWS PrivateLink for Amazon S3. Turn off encryption on the S3 bucket.","A":"Enable S3 Transfer Acceleration on the S3 bucket."},"timestamp":"2024-10-29 16:56:00","answer_ET":"B","answer_description":"","question_id":415,"answer":"B","question_images":[],"answers_community":["B (75%)","A (25%)"],"isMC":true,"exam_id":34,"discussion":[{"timestamp":"1732260900.0","comment_id":"1316192","comments":[{"upvote_count":"1","content":"+ The EC2 instance is in the same AWS Region where the S3 bucket is deployed. \nanother option where S3 Tr Acc will be useless, so B is correct","poster":"Grodgar","timestamp":"1734834000.0","comment_id":"1330254"}],"upvote_count":"3","content":"Selected Answer: B\n\"The SysOps administrator validates that the networking on the EC2 instance is not constrained.\"","poster":"igor12ghsj577"},{"upvote_count":"1","poster":"numark","content":"ChatGPT stated A>>>To improve the S3 upload performance for the application, the SysOps administrator can optimize the application's S3 interaction by using parallelization and Amazon S3 Transfer Acceleration.","comment_id":"1314626","timestamp":"1732020120.0","comments":[{"poster":"numark","content":"Yeap Igor is right, it's B. Amazon S3 performance is optimized for high throughput, but one way to ensure maximum performance when writing large numbers of files is to structure the write requests to leverage parallelism. S3's architecture supports high request rates by using a combination of bucket and object naming strategies. By using multiple prefixes, the application can make concurrent upload requests, which can help improve throughput performance.This feature is designed to speed up transfers over long distances between the client and the S3 bucket. Since the EC2 instance and the S3 bucket are in the same AWS Region, enabling Transfer Acceleration wouldn't significantly improve the performance, as it is primarily for improving transfer speeds across long geographic distances.","upvote_count":"1","timestamp":"1733589600.0","comment_id":"1323202"}]},{"comment_id":"1304521","upvote_count":"1","timestamp":"1730217360.0","comments":[{"comment_id":"1304526","content":"Read the question again that makes me thing that the issue may not be resolved from network side via S3 Transfer Acceleration option since it clearly states this: \"The SysOps administrator validates that the networking on the EC2 instance is not constrained.\"\nThat makes me think now to go with option B as the issue is stemming up with the application's throughput level which can be resolved by using multiple prefixes for the write operations in the S3 bucket.","timestamp":"1730218200.0","upvote_count":"2","poster":"Aamee"}],"content":"Selected Answer: A\nShouldn't option A be the best choice here??... rather than complicating the operations via Prefixes method?.. Not sure if B is really right here so going with A.","poster":"Aamee"}],"topic":"1","unix_timestamp":1730217360,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/150456-exam-aws-certified-sysops-administrator-associate-topic-1/"}],"exam":{"name":"AWS Certified SysOps Administrator - Associate","numberOfQuestions":477,"isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":false,"id":34,"isBeta":false,"provider":"Amazon"},"currentPage":83},"__N_SSP":true}