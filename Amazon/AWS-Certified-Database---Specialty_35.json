{"pageProps":{"questions":[{"id":"eBi24rF25PODqyDLJVvi","choices":{"A":"Create an Amazon S3 event to invoke an AWS Lambda function. Configure the Lambda function to parse the .csv file and use a SQL client library to run INSERT statements to load the data into the tables.","D":"Create an Amazon S3 event to invoke AWS Step Functions to parse the .csv file and call the custom stored procedure to insert the data into the tables.","B":"Write a custom .NET app that is hosted on Amazon EC2. Configure the .NET app to load the .csv file and call the custom stored procedure to insert the data into the tables.","C":"Download the .csv file from Amazon S3 to the RDS D drive by using an AWS msdb stored procedure. Call the custom stored procedure to insert the data from the RDS D drive into the tables."},"question_text":"A company's database specialist is building an Amazon RDS for Microsoft SQL Server DB instance to store hundreds of records in CSV format. A customer service tool uploads the records to an Amazon S3 bucket.\nAn employee who previously worked at the company already created a custom stored procedure to map the necessary CSV fields to the database tables. The database specialist needs to implement a solution that reuses this previous work and minimizes operational overhead.\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/81109-exam-aws-certified-database-specialty-topic-1-question-252/","answer_images":[],"discussion":[{"comments":[{"timestamp":"1672913700.0","poster":"parle101","upvote_count":"4","content":"C is using the previous work","comment_id":"766515"}],"poster":"Usman0506","comment_id":"678362","upvote_count":"10","timestamp":"1664074260.0","content":"Selected Answer: D\n\"The database specialist needs to implement a solution that reuses this previous work\". Option D is to reuse previous work."},{"content":"Selected Answer: C\nexec msdb.dbo.rds_download_from_s3\n@s3_arn_of_file='arn:aws:s3:::<bucket_name>/<file_name>',\n@rds_file_path='D:\\S3\\<custom_folder_name>\\<file_name>',\n@overwrite_file=1;","upvote_count":"5","comment_id":"733121","poster":"Sab","comments":[{"poster":"ftrimmer","comment_id":"760381","content":"Already done really!","upvote_count":"1","timestamp":"1672265460.0"}],"timestamp":"1669930920.0"},{"content":"C is the right answer. D is wrong. S3 event cannot call step function directly. If we need to use AWS STEP we can setup s3 event call lambda and lamdba call step.","comment_id":"1094329","timestamp":"1702374480.0","upvote_count":"1","poster":"zWarez"},{"content":"Selected Answer: C\nThe msdb stored procedure in question is msdb.dbo.rds_download_from_s3.\n\nThe only piece missing is how to trigger the import...\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/User.SQLServer.Options.S3-integration.html#Appendix.SQLServer.Options.S3-integration.using","poster":"aviathor","timestamp":"1684915380.0","comment_id":"905625","upvote_count":"3"},{"comment_id":"850818","upvote_count":"2","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/User.SQLServer.Options.S3-integration.html#:~:text=RDS%20stored%20procedure-,msdb.dbo.rds_download_from_s3,-with%20the%20following","timestamp":"1679818200.0","poster":"dougporto1988"},{"upvote_count":"2","comment_id":"822881","poster":"Ddddppp16","timestamp":"1677438060.0","content":"Selected Answer: C\nThis solution is the best option as it reuses the custom stored procedure that was previously created and minimizes operational overhead. The data can be downloaded from Amazon S3 to the RDS instance and loaded into the database tables using the custom stored procedure. The use of an AWS msdb stored procedure can automate the downloading of the data to the RDS instance."},{"content":"Selected Answer: C\nDownload S3 File","timestamp":"1669999800.0","upvote_count":"2","poster":"examineme","comment_id":"733921"},{"poster":"awsexams","comment_id":"724543","content":"Selected Answer: C\nAlternative C allows the file to be downloaded to S3 and then a local copy with the stored procedure would work","timestamp":"1669140000.0","upvote_count":"2"},{"poster":"snehilsrcs","content":"Step 1: Download S3 Files\nAmazon RDS for SQL Server comes with several custom stored procedures and functions. These are located in the msdb database. The stored procedure to download files from S3 is \"rds_download_from_s3\". The syntax for this stored procedure is shown here:\n\nexec msdb.dbo.rds_download_from_s3 \n @s3_arn_of_file='arn:aws:s3:::<bucket_name>/<file_name>', \n @rds_file_path='D:\\S3\\<custom_folder_name>\\<file_name>', \n @overwrite_file=1;","timestamp":"1667915640.0","upvote_count":"3","comment_id":"713877"},{"content":"Selected Answer: C\nhttps://www.mssqltips.com/sqlservertip/6619/rds-sql-server-data-import-from-amazon-s3/\n\nAmazon Web Service (AWS) recently announced a new feature of its Relational Database Service (RDS) for SQL Server. This feature allows a native integration between Amazon RDS SQL Server and Amazon S3. With this integration, it's now possible to import files from an Amazon S3 bucket into a local folder of the RDS instance. Similarly, files from that folder can be exported to S3. The RDS local folder path is D:\\S3\\.","timestamp":"1667915520.0","comment_id":"713875","upvote_count":"3","poster":"snehilsrcs"},{"poster":"DBA_MJF","upvote_count":"2","timestamp":"1666282500.0","content":"Selected Answer: C\nI believe the answer is C based on the following article: https://www.mssqltips.com/sqlservertip/6619/rds-sql-server-data-import-from-amazon-s3/","comment_id":"700112"},{"content":"Selected Answer: A\nMinimum operational overhead would be for A.","poster":"mbar94","comment_id":"663188","timestamp":"1662616860.0","upvote_count":"2"}],"answer_description":"","answer":"C","isMC":true,"answer_ET":"C","timestamp":"2022-09-08 08:01:00","answers_community":["C (64%)","D (30%)","6%"],"exam_id":22,"topic":"1","question_images":[],"unix_timestamp":1662616860,"question_id":171},{"id":"CERK2DbQIUUNCyYJsXSq","answers_community":["B (100%)"],"answer_images":[],"question_text":"A company hosts a 2 TB Oracle database in its on-premises data center. A database specialist is migrating the database from on premises to an Amazon Aurora\nPostgreSQL database on AWS.\nThe database specialist identifies a problem that relates to compatibility Oracle stores metadata in its data dictionary in uppercase, but PostgreSQL stores the metadata in lowercase. The database specialist must resolve this problem to complete the migration.\nWhat is the MOST operationally efficient solution that meets these requirements?","question_id":172,"discussion":[{"comment_id":"663191","upvote_count":"6","poster":"mbar94","timestamp":"1662616980.0","content":"Selected Answer: B\nAgree with B - https://aws.amazon.com/premiumsupport/knowledge-center/dms-mapping-oracle-postgresql/"},{"comment_id":"876885","timestamp":"1682116200.0","poster":"SeemaDataReader","upvote_count":"1","content":"https://docs.aws.amazon.com/dms/latest/oracle-to-aurora-postgresql-migration-playbook/chap-oracle-aurora-pg.tables.case.html\n In most cases, you’ll want to use AWS DMS transformations to change schema, table, and column names to lower case."},{"poster":"lollyj","comment_id":"764162","timestamp":"1672707000.0","upvote_count":"1","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.CustomizingTasks.TableMapping.SelectionTransformation.Transformations.html"}],"answer_ET":"B","answer":"B","unix_timestamp":1662616980,"isMC":true,"choices":{"A":"Override the default uppercase format of Oracle schema by encasing object names in quotation marks during creation.","C":"Use the AWS Schema Conversion Tool conversion agent to convert the metadata from uppercase to lowercase.","B":"Use AWS Database Migration Service (AWS DMS) mapping rules with rule-action as convert-lowercase.","D":"Use an AWS Glue job that is attached to an AWS Database Migration Service (AWS DMS) replication task to convert the metadata from uppercase to lowercase."},"timestamp":"2022-09-08 08:03:00","url":"https://www.examtopics.com/discussions/amazon/view/81110-exam-aws-certified-database-specialty-topic-1-question-253/","topic":"1","answer_description":"","exam_id":22,"question_images":[]},{"id":"9630VthhEVeskFKX4khX","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/81113-exam-aws-certified-database-specialty-topic-1-question-254/","answer_description":"","answer_images":[],"answers_community":["AD (93%)","7%"],"question_images":[],"unix_timestamp":1662617340,"answer":"AD","question_text":"A financial company is running an Amazon Redshift cluster for one of its data warehouse solutions. The company needs to generate connection logs, user logs, and user activity logs. The company also must make these logs available for future analysis.\nWhich combination of steps should a database specialist take to meet these requirements? (Choose two.)","timestamp":"2022-09-08 08:09:00","discussion":[{"comment_id":"696241","upvote_count":"5","poster":"awsjjj","timestamp":"1665924360.0","content":"Selected Answer: AD\nhttps://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html\nhttps://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html"},{"timestamp":"1677437160.0","upvote_count":"2","comments":[{"timestamp":"1696693920.0","comment_id":"1027509","poster":"Germaneli","upvote_count":"3","content":"Please don't vote for answers if you cannot give a reason. That is useless for other users and contorts the votes. Thank you.\nNot against you but generally addressed to all who log in unsubstantiated answers."}],"poster":"Ddddppp16","comment_id":"822859","content":"The correct answer is A and B"},{"poster":"hogtrough","timestamp":"1667565240.0","upvote_count":"4","comment_id":"711134","content":"Selected Answer: AD\nAWS CloudWatch Logs are stored indefinitely and CloudWatch Log Insights is used to analyze the logs and query upon them.\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html\n\"Log retention – By default, logs are kept indefinitely and never expire. You can adjust the retention policy for each log group, keeping the indefinite retention, or choosing a retention period between 10 years and one day.\""},{"poster":"rags1482","content":"Anser: BD \nas S3 we can store logs for future analysis","upvote_count":"2","comment_id":"707300","timestamp":"1667058660.0"},{"comments":[{"comments":[{"timestamp":"1680977760.0","comment_id":"864920","content":"AD.\n For the user activity log, you must also enable the enable_user_activity_logging database parameter. If you enable only the audit logging feature, but not the associated parameter, the database audit logs log information for only the connection log and user log, but not for the user activity log. The enable_user_activity_logging parameter is not enabled (false) by default. You can set it to true to enable the user activity log. For more information, see Amazon Redshift parameter groups.","comments":[{"comment_id":"995265","comments":[{"timestamp":"1696694280.0","comment_id":"1027515","content":"Because the native application in AWS to keep and analyse logs is CloudWatch Logs. Storing them on S3 would incur additional manual effort and integration.","upvote_count":"1","poster":"Germaneli"}],"timestamp":"1693497540.0","upvote_count":"1","poster":"aqiao","content":"Why not B D"}],"poster":"Mintwater","upvote_count":"4"}],"timestamp":"1667931240.0","upvote_count":"2","poster":"JeanGat","comment_id":"714032","content":"Changing to A and D. For \"user activity logs\" we need D."}],"content":"Selected Answer: AB\nA and B\nFrom here: https://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html\n\n\"Audit logging is not turned on by default in Amazon Redshift. When you turn on logging on your cluster, Amazon Redshift exports logs to Amazon CloudWatch, or creates and uploads logs to Amazon S3, that capture data from the time audit logging is enabled to the present time. \"","poster":"JeanGat","comment_id":"681095","upvote_count":"1","timestamp":"1664305260.0"},{"upvote_count":"4","poster":"yxyj","content":"B & D, send to S3 for future use.","comment_id":"674654","timestamp":"1663722240.0"},{"comment_id":"663198","upvote_count":"4","timestamp":"1662617340.0","poster":"mbar94","content":"Selected Answer: AD\nI'd go for AD."}],"answer_ET":"AD","question_id":173,"exam_id":22,"choices":{"E":"Modify the system table to enable logging for each user.","A":"Edit the database configuration of the cluster by enabling audit logging. Direct the logging to a specified log group in Amazon CloudWatch Logs.","B":"Edit the database configuration of the cluster by enabling audit logging. Direct the logging to a specified Amazon S3 bucket","C":"Modify the cluster by enabling continuous delivery of AWS CloudTrail logs to Amazon S3.","D":"Create a new parameter group with the enable_user_activity_logging parameter set to true. Configure the cluster to use the new parameter group."},"isMC":true},{"id":"uWtb7czlcpP4c4WVVi6j","exam_id":22,"answers_community":["AD (100%)"],"answer_description":"","answer_ET":"AD","topic":"1","answer":"AD","url":"https://www.examtopics.com/discussions/amazon/view/81114-exam-aws-certified-database-specialty-topic-1-question-255/","timestamp":"2022-09-08 08:10:00","question_text":"A bank is using an Amazon RDS for MySQL DB instance in a proof of concept. A database specialist is evaluating automated database snapshots and cross-\n\nRegion snapshot copies as -\npart of this proof of concept. After validating three automated snapshots successfully, the database specialist realizes that the fourth snapshot was not created.\nWhich of the following are possible reasons why the snapshot was not created? (Choose two.)","question_id":174,"unix_timestamp":1662617400,"choices":{"A":"A copy of the automated snapshot for this DB instance is in progress within the same AWS Region.","C":"The RDS maintenance window is not specified.","E":"RDS event notifications have not been enabled.","B":"A copy of a manual snapshot for this DB instance is in progress for only certain databases within the DB instance.","D":"The DB instance is in the STORAGE_FULL state."},"question_images":[],"discussion":[{"comment_id":"805460","upvote_count":"2","content":"A+D are the ones","timestamp":"1676136420.0","poster":"guau"},{"upvote_count":"3","content":"Selected Answer: AD\nRefer question 118","poster":"snehilsrcs","comment_id":"713883","timestamp":"1667916360.0"},{"content":"Selected Answer: AD\nFrom here:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html\n\nAutomated backups follow these rules:\n\nYour DB instance must be in the AVAILABLE state for automated backups to occur. Automated backups don't occur while your DB instance is in a state other than AVAILABLE, for example STORAGE_FULL.\n\nAutomated backups don't occur while a DB snapshot copy is running in the same AWS Region for the same DB instance.","timestamp":"1664305440.0","comment_id":"681096","upvote_count":"4","poster":"JeanGat"},{"poster":"cloudsunriser","timestamp":"1664304840.0","upvote_count":"1","comment_id":"681088","content":"Selected Answer: AD\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html"},{"comment_id":"663199","poster":"mbar94","upvote_count":"1","content":"Selected Answer: AD\nAgree with AD.","timestamp":"1662617400.0"}],"answer_images":[],"isMC":true},{"id":"fGTB14pSVIL1Z56JK8B2","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/81143-exam-aws-certified-database-specialty-topic-1-question-256/","answer_description":"","answer_images":[],"answers_community":["A (75%)","C (25%)"],"question_images":[],"unix_timestamp":1662624660,"answer":"A","question_text":"A company recently migrated its line-of-business (LOB) application to AWS. The application uses an Amazon RDS for SQL Server DB instance as its database engine.\nThe company must set up cross-Region disaster recovery for the application. The company needs a solution with the lowest possible RPO and RTO.\nWhich solution will meet these requirements?","timestamp":"2022-09-08 10:11:00","discussion":[{"content":"Selected Answer: C\nOnly two options in sql server cross region replication. copy snapshots and DMS\nhttps://aws.amazon.com/blogs/database/cross-region-disaster-recovery-of-amazon-rds-for-sql-server/","timestamp":"1662740880.0","comment_id":"664800","upvote_count":"7","poster":"gairaj"},{"upvote_count":"6","timestamp":"1671416220.0","comment_id":"749373","poster":"RBSK","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/database/use-cross-region-read-replicas-with-amazon-relational-database-service-for-sql-server/\n\nNov 2022 - Release date hence \"A\" is a right choice as of now"},{"comment_id":"941420","content":"Selected Answer: A\nAs of November 2022, Amazon RDS for SQL Server supports cross-Region read replicas, refer to Use cross-Region read replicas with Amazon Relational Database Service for SQL Server to learn more.","timestamp":"1688358660.0","upvote_count":"3","poster":"FarhatRV"},{"comment_id":"905746","timestamp":"1684923060.0","poster":"aviathor","upvote_count":"5","content":"Selected Answer: A\nAWS does not seem overly keen on using DMS for heterogeneous replications, and seems to prefer native tools or replication."},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html#SQLServer.ReadReplicas.limitations.options:~:text=When%20you%20promote%20a%20SQL%20Server%20cross%2DRegion%20read%20replica%2C","poster":"dougporto1988","comment_id":"850825","upvote_count":"4","timestamp":"1679818800.0"},{"timestamp":"1671502920.0","upvote_count":"4","comment_id":"750406","content":"Selected Answer: A\nI'll go with A.\n\nAmazon Relational Database Service (Amazon RDS) for SQL Server now supports Cross Region Read Replica. Cross Region Read Replica enables managed disaster recovery capability for mission critical databases by allowing a read replica in another region be \"promoted\" as a new standalone production database.","poster":"khun"},{"poster":"examineme","content":"Selected Answer: A\nI will go with (A). https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-rds-sql-server-cross-region-read-replica/","upvote_count":"3","timestamp":"1670081220.0","comment_id":"734534"},{"content":"Selected Answer: A\nRDS for SQL Server now supports cross Region Replica. (released Nov 2022)\nhttps://aws.amazon.com/about-aws/whats-new/2022/11/amazon-rds-sql-server-cross-region-read-replica/","upvote_count":"3","poster":"Sab","comment_id":"733130","timestamp":"1669931580.0"},{"upvote_count":"1","poster":"VK1709PNP","comment_id":"697884","timestamp":"1666067820.0","content":"C, as cross-region read replica is not supported for RDS SQL Server"},{"comment_id":"681107","upvote_count":"1","content":"Selected Answer: C\nC, as per link","timestamp":"1664306280.0","poster":"JeanGat"},{"poster":"supratip","comments":[{"content":"Agree - Continuous replication\nTo meet very aggressive RPO and RTO requirements, your DR strategy needs to consider continuous replication capability from your source RDS SQL Server to the target RDS SQL Server in your DR Region.","poster":"mawsman","upvote_count":"1","comment_id":"874758","timestamp":"1681913040.0"}],"content":"Selected Answer: C\nDefinitely C is correct - https://aws.amazon.com/blogs/database/cross-region-disaster-recovery-of-amazon-rds-for-sql-server/","timestamp":"1663808040.0","upvote_count":"2","comment_id":"675631"},{"upvote_count":"2","comment_id":"663353","poster":"mbar94","content":"Selected Answer: A\nIt's A.","timestamp":"1662624660.0"}],"answer_ET":"A","question_id":175,"exam_id":22,"choices":{"B":"Set up SQL replication from the DB instance to an Amazon EC2 instance in the disaster recovery Region. Promote the EC2 instance as the primary server.","A":"Create a cross-Region read replica of the DB instance. Promote the read replica at the time of failover.","C":"Use AWS Database Migration Service (AWS KMS) for ongoing replication of the DB instance in the disaster recovery Region.","D":"Take manual snapshots of the DB instance in the primary Region. Copy the snapshots to the disaster recovery Region."},"isMC":true}],"exam":{"numberOfQuestions":359,"provider":"Amazon","isImplemented":true,"name":"AWS Certified Database - Specialty","isBeta":false,"id":22,"isMCOnly":false,"lastUpdated":"11 Apr 2025"},"currentPage":35},"__N_SSP":true}