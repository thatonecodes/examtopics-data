{"pageProps":{"questions":[{"id":"EhVpe5NyAHRzuXipkEqB","answers_community":["ADE (100%)"],"question_text":"A company's AWS CloudTrail logs are all centrally stored in an Amazon S3 bucket. The security team controls the company's AWS account. The security team must prevent unauthorized access and tampering of the CloudTrail logs.\nWhich combination of steps should the security team take? (Choose three.)","answer_ET":"ADE","answer_description":"","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/124648-exam-aws-certified-security-specialty-scs-c02-topic-1/","timestamp":"2023-10-26 07:58:00","choices":{"E":"Configure CloudTrail log file integrity validation.","B":"Compress log files with secure gzip.","F":"Configure Access Analyzer for S3.","A":"Configure server-side encryption with AWS KMS managed encryption keys (SSE-KMS).","C":"Create an Amazon EventBridge rule to notify the security team of any modifications on CloudTrail log files.","D":"Implement least privilege access to the S3 bucket by configuring a bucket policy."},"discussion":[{"upvote_count":"1","timestamp":"1735931220.0","poster":"youonebe","content":"Selected Answer: ADE\nOption B (compression) doesn't provide security benefits\nOption C is reactive rather than preventive\nOption F is a monitoring tool but doesn't directly prevent unauthorized access or tampering","comment_id":"1336121"},{"comment_id":"1209376","upvote_count":"1","timestamp":"1731250440.0","content":"ADE. Agreed","poster":"Zek"},{"timestamp":"1723209720.0","comment_id":"1145592","content":"Selected Answer: ADE\nADE\nWe agree.","poster":"Raphaello","upvote_count":"1"},{"poster":"Aamee","upvote_count":"3","timestamp":"1716348420.0","comment_id":"1076931","content":"Selected Answer: ADE\nHere's what it describes about the usage of log file integration and the SSE-KMS usecase scenario: \n\n\"If you use SSE-KMS and log file validation, and you have modified your Amazon S3 bucket policy to only allow SSE-KMS encrypted files, you will not be able to create trails that utilize that bucket unless you modify your bucket policy to specifically allow AES256 encryption, as shown in the following example policy line.\n\n\"StringNotEquals\": { \"s3:x-amz-server-side-encryption\": [\"aws:kms\", \"AES256\"] } \n\""},{"poster":"ahrentom","upvote_count":"4","comment_id":"1054317","content":"Selected Answer: ADE\nADE\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/best-practices-security.html","timestamp":"1714111080.0"}],"question_images":[],"topic":"1","exam_id":30,"question_id":236,"answer_images":[],"unix_timestamp":1698299880,"answer":"ADE"},{"id":"mBhV3rXHZiUjCbEFcXCU","timestamp":"2023-10-18 19:17:00","question_text":"A company has several petabytes of data. The company must preserve this data for 7 years to comply with regulatory requirements. The company's compliance team asks a security officer to develop a strategy that will prevent anyone from changing or deleting the data.\nWhich solution will meet this requirement MOST cost-effectively?","topic":"1","discussion":[{"content":"Selected Answer: C\nTo meet the requirement of preserving several petabytes of data for 7 years in a cost-effective manner while ensuring that the data cannot be changed or deleted, option C is the most suitable solution. Here's why:\n\nCreating a vault in Amazon S3 Glacier and implementing a Vault Lock policy ensures that the data is stored using a write-once-read-many (WORM) model, which prevents any changes or deletions during the specified retention period. S3 Glacier is designed for long-term storage of infrequently accessed data, making it a cost-effective choice for this use case. The Vault Lock policy will enforce compliance with regulatory requirements by ensuring that the data remains immutable for the entire retention period.\n\nThis approach leverages the cost benefits of S3 Glacier for long-term storage while providing the necessary security and compliance features to meet the company's requirements.","upvote_count":"2","comment_id":"1321382","poster":"IPLogic","timestamp":"1733232180.0"},{"comments":[{"upvote_count":"2","comment_id":"1283563","timestamp":"1726305480.0","poster":"Just_Ninja","content":"Its C:\nThe claim that S3 Glacier Vaults are only for existing customers using the original 2012 API is incorrect. While newer S3 Glacier Storage Classes have been introduced, S3 Glacier Vaults with Vault Lock are still fully supported and available for both new and existing customers.\n\nVault Lock remains a cost-effective option for securing data with WORM (Write Once, Read Many) compliance, making it ideal for long-term data storage with regulatory requirements. AWS continues to support this solution for all customers, including those setting up new Glacier Vaults.\n\nIn short, Vault Lock is not restricted to legacy customers and is available for current use."}],"content":"Selected Answer: A\nFor the folks voting for C with the link in the comment, it clearly says \"This page is only for existing customers of the S3 Glacier service using Vaults and the original REST API from 2012.\"","timestamp":"1721715300.0","poster":"BBR01","upvote_count":"1","comment_id":"1253444"},{"upvote_count":"2","poster":"Sodev","timestamp":"1712390820.0","content":"C. Right here !\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/getting-started-upload-archive.html","comment_id":"1190283"},{"content":"C.\nPetabytes of data takes a lot of storage, therefore require the cheapest storage: Glacier, if looking for a cost efficiency. The vault policy will keep it safe. \nD is not realistic. Uploading petabytes of data to a bucket would require a AWS Snowmobile","upvote_count":"2","timestamp":"1710801000.0","comment_id":"1176864","poster":"Boul"},{"timestamp":"1710721860.0","comment_id":"1176132","poster":"walter_white_008","upvote_count":"1","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/vault-lock-policy.html"},{"upvote_count":"1","timestamp":"1707492960.0","content":"Selected Answer: C\nThe data is already there, we just want to keep it for COMPLIANCE for SEVEN years.\nThere's no need to place the date in S3 bucket then use lifecycle to move it to Glacier.\nOption C is correct.","poster":"Raphaello","comment_id":"1145597"},{"content":"Exam on 2023-12-18","poster":"trashbox","timestamp":"1702979880.0","comment_id":"1100501","upvote_count":"1"},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/vault-lock-policy.html","timestamp":"1699637880.0","comment_id":"1067414","poster":"kejam","upvote_count":"1"},{"poster":"cjkuga","upvote_count":"4","comment_id":"1059807","content":"Selected Answer: C\nBoth A and C work here but C is the MOST cost-effective.","timestamp":"1698849600.0"},{"content":"Selected Answer: A\nQuestion doesn't ask for a backup solution, so Glacier is not a good fir here.","comments":[{"upvote_count":"1","comment_id":"1076935","poster":"Aamee","content":"No, it clearly states that \"The company must preserve this data for 7 years\"... so how would you keep such large data safe and specifically complianced with all the regulatory reqs. That's why going with C here.","timestamp":"1700631900.0"}],"timestamp":"1698430560.0","upvote_count":"2","poster":"pupsik","comment_id":"1055780"},{"timestamp":"1698006240.0","content":"Selected Answer: C\nCorrection, answer C","comment_id":"1051066","upvote_count":"2","poster":"100fold"},{"comment_id":"1049979","upvote_count":"2","poster":"AgboolaKun","content":"Selected Answer: C\nThe correct answer here is C. This option ticks all the boxes.\n\n Several petabytes of data + 7 years + Regulatory Compliance + MOST cost-effective solution.\n\nD is close but we don't S3 at all.","timestamp":"1697933280.0","comments":[{"comments":[{"content":"@100fold, I agree with your answer (C) in #49. There is no better option to C!!\n\nI upvoted your answer already!!","poster":"AgboolaKun","timestamp":"1699208100.0","upvote_count":"1","comment_id":"1063168","comments":[{"poster":"100fold","comment_id":"1064188","content":"@AgboolaKun, I sat the exam Friday and marked 926. 80% from this study were on my exam. 6-7 new questions, one related to AWS KMS keyrings. Good luck everyone!","timestamp":"1699298520.0","comments":[{"content":"Were most questions from examtopics aws-certified-security-specialty-scs-c02 ? or also the previous one for aws-certified-security-specialty-scs-c01 ?","comments":[{"upvote_count":"3","content":"@kejam I studied both SCS-C02 & SCS-01, but 80%+- were from this C02 study. You‚Äôll notice C01questions are merged. The other % were totally new questions. My access expires today so I can‚Äôt comment further, but good luck you‚Äôll be good with this C02 study üëç","comment_id":"1072500","poster":"100fold","timestamp":"1700146080.0"}],"timestamp":"1699638660.0","poster":"kejam","upvote_count":"1","comment_id":"1067425"},{"upvote_count":"1","content":"Wow!! Congratulations!! I am happy for you. I will be sitting for the exam soon. I will let you know!!","comments":[{"comment_id":"1072513","timestamp":"1700146980.0","content":"@AgboolKun. Awesome! All The Best wishes throughout your career üëç","upvote_count":"1","poster":"100fold"}],"comment_id":"1069853","poster":"AgboolaKun","timestamp":"1699920960.0"}],"upvote_count":"5"}]}],"poster":"100fold","upvote_count":"2","timestamp":"1698006120.0","content":"Thanks AgboolKun! What are your thoughts on #49?\nAgree with answer C as well. Can set the policy on Vault Lock that cannot be altered. \nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/vault-access-policy.html","comment_id":"1051063"}]},{"upvote_count":"1","comment_id":"1047097","content":"Selected Answer: A\nAnswer A.\nCompliance mode will prevent anyone from changing or deleting the data including the root user. Requested by the company's compliance team. \n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html","timestamp":"1697649420.0","poster":"100fold","comments":[{"upvote_count":"1","poster":"100fold","content":"Correction to Answer C.\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/vault-access-policy.html","comment_id":"1051064","timestamp":"1698006180.0"}]}],"answer":"C","answer_ET":"C","isMC":true,"choices":{"D":"Create an Amazon S3 bucket. Upload the data to the bucket. Use a lifecycle rule to transition the data to a vault in S3 Glacier. Create a Vault Lock policy that meets all the regulatory requirements.","A":"Create an Amazon S3 bucket. Configure the bucket to use S3 Object Lock in compliance mode. Upload the data to the bucket. Create a resource-based bucket policy that meets all the regulatory requirements.","C":"Create a vault in Amazon S3 Glacier. Create a Vault Lock policy in S3 Glacier that meets all the regulatory requirements. Upload the data to the vault.","B":"Create an Amazon S3 bucket. Configure the bucket to use S3 Object Lock in governance mode. Upload the data to the bucket. Create a user-based IAM policy that meets all the regulatory requirements."},"url":"https://www.examtopics.com/discussions/amazon/view/123982-exam-aws-certified-security-specialty-scs-c02-topic-1/","answer_images":[],"answer_description":"","exam_id":30,"question_id":237,"question_images":[],"answers_community":["C (76%)","A (24%)"],"unix_timestamp":1697649420},{"id":"zHrBx8VRhHpDVtFVSxqq","topic":"1","discussion":[{"upvote_count":"11","poster":"100fold","content":"Selected Answer: C\nAnswer C.\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_saml.html#troubleshoot_saml_invalid-metadata\nhttps://www.examtopics.com/discussions/amazon/view/69166-exam-aws-certified-security-specialty-topic-1-question-292/","timestamp":"1713461520.0","comment_id":"1047110"},{"content":"Selected Answer: C\nDownload the updated SAML metadata file from your identity service provider, then update it in AWS.","upvote_count":"3","poster":"Raphaello","comment_id":"1145606","timestamp":"1723210980.0"},{"content":"Selected Answer: C\nnice link by user: 100fold \nthanks bud","poster":"yorkicurke","upvote_count":"1","timestamp":"1719051120.0","comment_id":"1103350"},{"comment_id":"1086274","poster":"awssecuritynewbie","content":"Selected Answer: C\nC is the correct answer","timestamp":"1717333380.0","upvote_count":"1"}],"timestamp":"2023-10-18 19:32:00","answer_ET":"C","answer":"C","answer_images":[],"answer_description":"","question_text":"A-company uses a third-party identity provider and SAML-based SSO for its AWS accounts. After the third-party identity provider renewed an expired signing certificate, users saw the following message when trying to log in:\nError: Response Signature Invalid (Service: AWSSecurityTokenService; Status Code: 400; Error Code: InvalidIdentityToken)\nA security engineer needs to provide a solution that corrects the error and minimizes operational overhead.\nWhich solution meets these requirements?","choices":{"A":"Upload the third-party signing certificate‚Äôs new private key to the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS Management Console.","C":"Download the updated SAML metadata file from the identity service provider. Update the file in the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS CLI.","D":"Configure the AWS identity provider entity defined in AWS Identity and Access Management (IAM) to synchronously fetch the new public key by using the AWS Management Console.","B":"Sign the identity provider's metadata file with the new public key. Upload the signature to the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS CLI."},"question_id":238,"exam_id":30,"question_images":[],"unix_timestamp":1697650320,"answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/123983-exam-aws-certified-security-specialty-scs-c02-topic-1/","isMC":true},{"id":"M790WDEiPPdZ8uFDwfZq","answer":"A","answer_images":[],"question_text":"A company has several workloads running on AWS. Employees are required to authenticate using on-premises ADFS and SSO to access the AWS Management Console. Developers migrated an existing legacy web application to an Amazon EC2 instance. Employees need to access this application from anywhere on the internet, but currently, there is no authentication system built into the application.\nHow should the security engineer implement employee-only access to this system without changing the application?","answers_community":["A (100%)"],"choices":{"A":"Place the application behind an Application Load Balancer (ALB). Use Amazon Cognito as authentication for the ALB. Define a SAML-based Amazon Cognito user pool and connect it to ADFS.","D":"Create an AWS Lambda custom authorizer as the authenticator for a reverse proxy on Amazon EC2. Ensure the security group on Amazon EC2 only allows access from the Lambda function.","B":"Implement AWS IAM Identity Center (AWS Single Sign-On) in the management account and link it to ADFS as an identity provider. Define the EC2 instance as a managed resource, then apply an IAM policy on the resource.","C":"Define an Amazon Cognito identity pool, then install the connector on the Active Directory server. Use the Amazon Cognito SDK on the application instance to authenticate the employees using their Active Directory user names and passwords."},"question_id":239,"answer_description":"","timestamp":"2023-10-19 00:55:00","question_images":[],"discussion":[{"comment_id":"1047303","content":"Selected Answer: A\nAnswer A.\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-authenticate-users.html\nhttps://www.examtopics.com/discussions/amazon/view/30063-exam-aws-certified-security-specialty-topic-1-question-143/","upvote_count":"10","timestamp":"1713480900.0","poster":"100fold"},{"content":"Selected Answer: A\nAdd SAML IdP to Cognito user pool.\nhttps://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-configuring-federation-with-saml-2-0-idp.html","poster":"Raphaello","comment_id":"1145614","upvote_count":"2","timestamp":"1723211460.0"}],"isMC":true,"unix_timestamp":1697669700,"answer_ET":"A","exam_id":30,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/124001-exam-aws-certified-security-specialty-scs-c02-topic-1/"},{"id":"ap9y7ewNh6I1rUDX9opp","isMC":true,"exam_id":30,"question_images":[],"timestamp":"2023-10-21 01:45:00","answers_community":["A (41%)","D (36%)","B (22%)"],"url":"https://www.examtopics.com/discussions/amazon/view/124151-exam-aws-certified-security-specialty-scs-c02-topic-1/","answer":"A","answer_images":[],"answer_description":"","question_id":240,"choices":{"D":"Apply an SCP on the AWS account to allow the S3 actions only if the values of the aws:ResourceOrgID and aws:PrincipalOrgID condition keys match the company's values.","B":"Update the policy on the instance profile role to allow the S3 actions only if the value of the aws:ResourceOrgID condition key matches the company's value.","A":"Update the policy on the S3 gateway endpoint to allow the S3 actions only if the values of the aws:ResourceOrgID and aws:PrincipalOrgID condition keys match the company's values.","C":"Add a network ACL rule to the subnet of the EC2 instances to block outgoing connections on port 443."},"question_text":"A company is using AWS to run a long-running analysis process on data that is stored in Amazon S3 buckets. The process runs on a fleet of Amazon EC2 instances that are in an Auto Scaling group. The EC2 instances are deployed in a private subnet of a VPC that does not have internet access. The EC2 instances and the S3 buckets are in the same AWS account.\nThe EC2 instances access the S3 buckets through an S3 gateway endpoint that has the default access policy. Each EC2 instance is associated with an instance profile role that has a policy that explicitly allows the s3:GetObject action and the s3:PutObject action for only the required S3 buckets.\nThe company learns that one or more of the EC2 instances are compromised and are exfiltrating data to an S3 bucket that is outside the company's organization in AWS Organizations. A security engineer must implement a solution to stop this exfiltration of data and to keep the EC2 processing job functional.\nWhich solution will meet these requirements?","topic":"1","discussion":[{"content":"Selected Answer: D\nAnswer D based on the syntax of these answers.\n\nA. This could work, but you don't need aws:ResourceOrgID and aws:PrincipalOrgID You can add allowed buckets (internal or external) as needed which is much more flexible IMO. https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html#edit-vpc-endpoint-policy-s3\n\nB. This doesn't prevent S3 actions on external accounts.\n\nC. This does nothing as the S3 endpoint is inside the VPC.\n\nD. This solution matches the answer exactly.\nExample 3: https://aws.amazon.com/blogs/security/how-to-control-access-to-aws-resources-based-on-aws-account-ou-or-organization/","poster":"kejam","upvote_count":"14","comments":[{"poster":"NoCrapEva","comment_id":"1147929","timestamp":"1707730620.0","upvote_count":"2","content":"Also the question states the company has AWS Organisations - therefore any policy restrictions SHOULD be done at the Organisation level - In this case with a SCP"},{"comment_id":"1070990","upvote_count":"1","timestamp":"1700011260.0","poster":"AgboolaKun","content":"I agree totally. I have always thought that D is the correct answer but I could not locate any supported documentation online. Thank you for providing the link. The example 3 in the link as you pointed out tallies with the scenario in this question."},{"timestamp":"1708389900.0","upvote_count":"1","content":"In fact Example 3 Restrict access to AWS resources (in this case S3) within my organization, which means denying access from principals (e.g. EC2 instance roles) that do not belong to S3 Org. That example does not correspond to what we need to do here!\n\"Deny\",\n\"Action\": \"s3:*\",\n\"Resource\": \"arn:aws:s3:::*/*\",\n\"Condition\": { \"StringNotEquals\": { \"aws:ResourceOrgID\": \"${aws:PrincipalOrgID}\"}\nNote the \"PrincipalOrgID\" is a variable.\n\nWhereas, we basically want our own EC2 instances not to access S3 that belong to another account.\n\"Allow\",\n\"Action\": \"s3:*\",\n\"Resource\": \"arn:aws:s3:::*/*\",\n\"Condition\": {\"StringEquals\": {\"aws:PrincipalOrgID\": [ \"o-yyyyyyyyyy\" ]}\nOr\nmaybe even add an explicit deny statement if the \"aws:ResourceOrgID\" does not equal my Org ID \"0-yyyyyyyyyy\".","comment_id":"1154382","poster":"Raphaello"}],"timestamp":"1699644360.0","comment_id":"1067484"},{"content":"Selected Answer: B\nThe answer is B. You all missed the part that EC2 instance is compromised. The restriction has to be added to the instance profile of the ec2 instance to restrict which S3 buckets it can connect to. This question is about limiting access from EC2 to external S3 buckets.","timestamp":"1702664640.0","upvote_count":"6","poster":"1c7c461","comment_id":"1097575"},{"content":"Selected Answer: A\nThe correct answer is A. \n\nUpdate the policy on the S3 gateway endpoint to allow the S3 actions only if the values of the aws:ResourceOrgID and aws:PrincipalOrgID condition keys match the company's values.","poster":"AWSLoverLoverLoverLoverLover","timestamp":"1740133200.0","comment_id":"1359714","upvote_count":"1"},{"comment_id":"1358727","upvote_count":"1","timestamp":"1739967840.0","poster":"AWSLoverLoverLoverLoverLover","content":"Selected Answer: A\nWhy is updating the S3 Gateway Endpoint policy the best solution?\n\nS3 Gateway Endpoints control access at the VPC level, ensuring that all S3 traffic passes through a controlled path.\nBy modifying the endpoint policy to allow access only to S3 buckets within the company's AWS Organization, we prevent data exfiltration to external S3 buckets.\n\nD. Apply an SCP to the AWS account\nSCPs apply only to IAM identities (users, roles, accounts) and do not affect VPC Gateway Endpoints. This means compromised instances can still exfiltrate data through the endpoint."},{"upvote_count":"3","poster":"IPLogic","timestamp":"1733233140.0","comment_id":"1321388","content":"Selected Answer: A\nTo stop the exfiltration of data from compromised EC2 instances to external S3 buckets while keeping the EC2 processing job functional, the best solution is option A: Update the policy on the S3 gateway endpoint to allow the S3 actions only if the values of the aws:ResourceOrgID and aws:PrincipalOrgID condition keys match the company's values.\n\nThis approach ensures that only resources and principals within the company's AWS Organization can perform S3 actions, effectively blocking any attempts to exfiltrate data to S3 buckets outside the organization. By updating the S3 gateway endpoint policy, you can enforce this restriction at the network level, providing a robust and centralized control mechanism"},{"poster":"mzeynalli","timestamp":"1731151500.0","comment_id":"1309064","upvote_count":"3","content":"Selected Answer: A\nUsing Service Control Policies (SCPs) can be a part of a broader security strategy, but there are specific reasons why it may not be the most effective or immediate solution for the scenario where EC2 instances are compromised and exfiltrating data to an S3 bucket outside the company's organization:\n\n1. Scope of SCPs: SCPs are designed to manage permissions across AWS Organizations. They apply to AWS accounts rather than individual resources. If the compromised instances are operating under an IAM role that has certain permissions, an SCP may not have the granularity needed to effectively restrict access at the resource level."},{"upvote_count":"1","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/security/how-to-control-access-to-aws-resources-based-on-aws-account-ou-or-organization/","timestamp":"1730841000.0","poster":"jakie22332","comment_id":"1307565"},{"content":"Selected Answer: D\nSCP is the right choice. \nNot B: This is only effective if the nodes are replaced. The processing must not be interupted.\nNot A: THis does not do anything against the exfiltration\nNot C: THis will not work","poster":"icecool36","comment_id":"1208020","upvote_count":"1","timestamp":"1715114400.0"},{"poster":"9bb8cb3","upvote_count":"4","content":"Selected Answer: A\nBlocking at the network layer would allow you still have other workloads that can talk to other buckets outside of the account whereas the option D as others have suggested would mean no workload in the account would ever be able to talk to a bucket outside the org which is IMO too restrictive and the solution is not asking for a general solution just to this specific problem. You can also create additional VPC endpoints and bound them to other route tables which don't have this policy as to allow for other architectural possibilities mentioned above,","timestamp":"1713873300.0","comment_id":"1200710"},{"content":"The correct answer should be B, as it directly addresses the issue.\nOption D seems too broad, and might affect other roles in the Account.","poster":"ion_gee","upvote_count":"2","timestamp":"1712061060.0","comment_id":"1188034"},{"upvote_count":"2","poster":"Noexperience","timestamp":"1709337180.0","comment_id":"1163844","content":"Selected Answer: B\n\"Version\": \"2012-10-17\",\n \"Statement\": [\n {\n \"Effect\": \"Allow\",\n \"Action\": [\n \"s3:GetObject\",\n \"s3:PutObject\"\n ],\n \"Resource\": [\n \"arn:aws:s3:::bucket-name/*\", // Specific buckets to restrict\n \"arn:aws:s3:::another-bucket/*\" \n ],\n \"Condition\": {\n \"StringEquals\": {\n \"aws:ResourceOrgID\": \"YOUR_AWS_ORGANIZATION_ID\" \n }\n }\n }\n ]\n}"},{"content":"Selected Answer: A\nthe EC2 role S3 GET/PUT are restricted to the appropriate buckets, so the exfiltration bucket access is being granted by the default S3 gateway resource policy.\nHence restricting the EC2 attached IAM role to the given organization (B) will do nothing and B is incorrect.\nC would break everything.\nFor (D) - SCPs don't apply to resource policies, so exfiltration would continue through the S3 gateway.\nAnswer is A","poster":"bkbaws","comment_id":"1162820","timestamp":"1709226120.0","upvote_count":"2"},{"timestamp":"1707494580.0","poster":"Raphaello","content":"Selected Answer: B\nThe problem is that EC2 instance exfiltrating data to an S3 bucket that is outside the company's organization in AWS Organizations.\nSo we need to make sure those instance cannot put the data to an external account's bucket.\n\nTherefore, we need to restrict access ONLY to resources within an organization using condition \"aws:ResourceOrgID\".\n\nRemember, it is not about controlling access to our own S3 bucket. It is about stopping EC2 instances from exfiltrate our data to accounts outside our Org.\n\nOption B is the correct answer.","upvote_count":"1","comment_id":"1145619"},{"upvote_count":"2","comment_id":"1141293","comments":[{"upvote_count":"1","content":"https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html#edit-vpc-endpoint-policy-s3\nhttps://developer.squareup.com/blog/adopting-aws-vpc-endpoints-at-square/","timestamp":"1707152400.0","poster":"LazyAutonomy","comment_id":"1141296"}],"poster":"LazyAutonomy","timestamp":"1707152100.0","content":"Selected Answer: A\nAnswer is A.\nD is wrong because attackers wont use EC2 instance credentials to exfil data - no attacker is that stupid."},{"poster":"mark16dc","upvote_count":"1","comment_id":"1140555","timestamp":"1707083880.0","content":"Given the effectiveness and direct impact on preventing data exfiltration to external S3 buckets, Option D is the correct solution. It leverages the organizational control provided by AWS Organizations to enforce policy restrictions at the account level, ensuring that S3 actions are confined to the company's organizational boundaries, thus meeting the security requirements without disrupting the EC2 processing jobs."},{"poster":"RNan","upvote_count":"1","comment_id":"1113737","timestamp":"1704377700.0","content":"Answer: B\nThe compromised EC2 instances are exfiltrating data to an S3 bucket outside the company's organization. By updating the policy on the instance profile role, you can restrict the S3 actions to only allow access to the required S3 buckets within the company's organization."},{"upvote_count":"1","timestamp":"1704101820.0","comment_id":"1111065","poster":"Daniel76","content":"Selected Answer: D\nBetween A and D, A must be ruled out because:\n\"An endpoint policy does not override or replace identity-based policies or resource-based policies. \" So, either the compromised ec2 instance or the external s3 can override the endpoint policy.\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-access.html"},{"timestamp":"1703856360.0","comment_id":"1108709","upvote_count":"1","poster":"DebbieB67","content":"Selected Answer: D\nAnswer D"},{"upvote_count":"1","poster":"yorkicurke","content":"Selected Answer: A\nThis ensures that only resources from within the company's AWS Organization can access the S3 bucket through the endpoint. This prevents any exfiltration of data from compromised EC2 instances to external S3 buckets, while STILL allowing the processing job on the instances to function normally by accessing the company's internal S3 resources through the private endpoint.\nhttps://repost.aws/questions/QU2Qx3s51DQ9SyrlWueh9L_Q/restrict-access-to-s3-bucket","timestamp":"1703249100.0","comment_id":"1103364"},{"upvote_count":"1","content":"Answer B","comment_id":"1098256","timestamp":"1702738680.0","poster":"Oralinux"},{"comment_id":"1094477","content":"Selected Answer: A\nI will go with A although D is also a possible method.","upvote_count":"1","timestamp":"1702384380.0","poster":"WeepingMaplte"},{"timestamp":"1701801600.0","comment_id":"1088721","content":"Selected Answer: D\nD is the correct option.","poster":"Aamee","upvote_count":"2"},{"upvote_count":"1","timestamp":"1701561420.0","content":"D. I have seen this is many other practice tests.","poster":"snowmaggedon","comment_id":"1086484"},{"timestamp":"1701529800.0","upvote_count":"2","content":"Selected Answer: A\nif they are exfiltrating data via the EC2 to a S3 bucket, then ACL will not help either SCP, you would need to modify the S3 endpoint so allow access to only the Aws Org and not other S3 buckets in AWS. \nAnswer would be A:","poster":"awssecuritynewbie","comment_id":"1086277"},{"timestamp":"1701526620.0","poster":"marco25","upvote_count":"2","content":"Selected Answer: D\nChoosing between a and D, A has the issue of not able to prevent direct we access bypassing the gateway.So voted d","comment_id":"1086247"},{"comment_id":"1079256","content":"Does this Q mention any company resources needed to access the S3? EC2 access only through the S3 gateway endpoint. I think it should be A","poster":"marlonchin","timestamp":"1700829480.0","upvote_count":"1"},{"content":"Please disregard my previous answer to eliminate any confusion. Weighing out A or B. \n\nThe solution request is to stop exfiltration of data","upvote_count":"2","timestamp":"1698719220.0","comment_id":"1058414","poster":"100fold"},{"content":"Selected Answer: A\nPolicy should be applied on S3 Gateway policy, in such a way that it only allows to communicate with the buckets belonging to an organization.","comment_id":"1055785","upvote_count":"4","poster":"pupsik","timestamp":"1698431820.0"},{"comment_id":"1054339","timestamp":"1698302280.0","upvote_count":"3","poster":"ahrentom","content":"Selected Answer: B\nAnwser B\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_resource_account_data_exch.html"},{"poster":"100fold","upvote_count":"6","timestamp":"1697845500.0","comment_id":"1049185","content":"D\nhttps://aws.amazon.com/blogs/security/how-to-control-access-to-aws-resources-based-on-aws-account-ou-or-organization/"}],"answer_ET":"A","unix_timestamp":1697845500}],"exam":{"isBeta":false,"isImplemented":true,"id":30,"isMCOnly":true,"numberOfQuestions":288,"name":"AWS Certified Security - Specialty SCS-C02","lastUpdated":"11 Apr 2025","provider":"Amazon"},"currentPage":48},"__N_SSP":true}