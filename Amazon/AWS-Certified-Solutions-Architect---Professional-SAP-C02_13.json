{"pageProps":{"questions":[{"id":"qLet0Tqz51eZ4UmxOkBh","answers_community":["ACD (100%)"],"question_id":61,"answer":"ACD","unix_timestamp":1673883780,"url":"https://www.examtopics.com/discussions/amazon/view/95573-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"ACD","question_images":[],"question_text":"A company has deployed an application on AWS Elastic Beanstalk. The application uses Amazon Aurora for the database layer. An Amazon CloudFront distribution serves web requests and includes the Elastic Beanstalk domain name as the origin server. The distribution is configured with an alternate domain name that visitors use when they access the application.\n\nEach week, the company takes the application out of service for routine maintenance. During the time that the application is unavailable, the company wants visitors to receive an informational message instead of a CloudFront error message.\n\nA solutions architect creates an Amazon S3 bucket as the first step in the process.\n\nWhich combination of steps should the solutions architect take next to meet the requirements? (Choose three.)","exam_id":33,"answer_images":[],"topic":"1","isMC":true,"choices":{"A":"Upload static informational content to the S3 bucket.","E":"During the weekly maintenance, create a cache behavior for the S3 origin on the new distribution. Set the path pattern to \\ Set the precedence to 0. Delete the cache behavior when the maintenance is complete.","B":"Create a new CloudFront distribution. Set the S3 bucket as the origin.","F":"During the weekly maintenance, configure Elastic Beanstalk to serve traffic from the S3 bucket.","C":"Set the S3 bucket as a second origin in the original CloudFront distribution. Configure the distribution and the S3 bucket to use an origin access identity (OAI).","D":"During the weekly maintenance, edit the default cache behavior to use the S3 origin. Revert the change when the maintenance is complete."},"discussion":[{"content":"Selected Answer: ACD\nA. Upload static informational content to the S3 bucket.\nC. Set the S3 bucket as a second origin in the original CloudFront distribution. Configure the distribution and the S3 bucket to use an origin access identity (OAI).\nD. During the weekly maintenance, edit the default cache behavior to use the S3 origin. Revert the change when the maintenance is complete.\n\nStep 1: The solutions architect should upload static informational content to the S3 bucket, this content will be shown to the users when the application is down for maintenance.\n\nStep 2: The solutions architect should set the S3 bucket as a second origin in the original CloudFront distribution. To keep the S3 bucket secure, the solutions architect should configure the distribution and the S3 bucket to use an origin access identity (OAI). This will ensure that only CloudFront has access to the S3 bucket.","comment_id":"778197","timestamp":"1673899920.0","poster":"masetromain","comments":[{"comment_id":"778198","poster":"masetromain","content":"Step 3: During the weekly maintenance, the solutions architect should edit the default cache behavior of the CloudFront distribution to use the S3 origin. This will redirect all incoming traffic to the S3 bucket and show the static informational content to the users. Once the maintenance is complete, the solutions architect should revert the change back to the original Elastic Beanstalk origin.\n\nOption B: Creating a new CloudFront distribution and setting the S3 bucket as the origin is unnecessary and could cause confusion for the users.\nOption E: During the weekly maintenance, creating a cache behavior for the S3 origin on the new distribution is unnecessary, it is more complex and prone to human error.\nOption F: Configuring Elastic Beanstalk to serve traffic from the S3 bucket is not necessary because CloudFront is already being used as the web request server.","timestamp":"1673899920.0","upvote_count":"5"}],"upvote_count":"16"},{"timestamp":"1703777820.0","upvote_count":"1","poster":"carpa_jo","content":"Selected Answer: ACD\nFrom the given options ACD makes the most sense.\nIn real life the CloudFront feature to show custom error responses might make a lot more sense: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/GeneratingCustomErrorResponses.html#custom-error-pages-procedure\nThis would avoid the manual steps and by that is less prone to human errors.","comment_id":"1107923"},{"upvote_count":"1","timestamp":"1703396460.0","content":"Selected Answer: ACD\nA, C and D is correct.","comment_id":"1104460","poster":"career360guru"},{"upvote_count":"1","content":"Selected Answer: ACD\nCacheBehaviour defines path and origin","comment_id":"1072285","timestamp":"1700125800.0","poster":"severlight"},{"upvote_count":"1","comment_id":"942922","content":"Selected Answer: ACD\nACD morelikely","poster":"NikkyDicky","timestamp":"1688484420.0"},{"timestamp":"1687122420.0","upvote_count":"2","content":"Selected Answer: ACD\nA C D \nE is good option but is more overhead and propone error human then C is more accesible","comment_id":"926904","poster":"SkyZeroZx"},{"timestamp":"1686750060.0","comment_id":"923255","poster":"Jesuisleon","upvote_count":"1","content":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/high_availability_origin_failover.html"},{"timestamp":"1679901600.0","content":"Selected Answer: ACD\nACD is the best fit","upvote_count":"3","comment_id":"851852","poster":"mfsec"},{"upvote_count":"4","comments":[{"poster":"sam2ng","timestamp":"1729089540.0","comment_id":"1298783","content":"behavior precedence can be set to zero","upvote_count":"1"}],"timestamp":"1675796400.0","content":"Selected Answer: ACD\nAbout E, the lowest possible value for the \"Origin Priority\" field in AWS CloudFront is 1","poster":"Musk","comment_id":"801306"},{"timestamp":"1675045020.0","content":"Selected Answer: ACD\nACD is correct","poster":"zozza2023","comment_id":"792307","upvote_count":"4"},{"content":"ABD is correct","comment_id":"777883","comments":[{"poster":"zhangyu20000","upvote_count":"2","content":"ACD is correct","comment_id":"779234","timestamp":"1673981760.0"}],"timestamp":"1673883780.0","poster":"zhangyu20000","upvote_count":"1"}],"timestamp":"2023-01-16 16:43:00","answer_description":""},{"id":"8AhwFITlh0nCuiEHB06I","topic":"1","timestamp":"2023-01-16 16:47:00","url":"https://www.examtopics.com/discussions/amazon/view/95574-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"D":"Create a Lambda function alias. Modify the client application to use the function alias ARN. Reconfigure the Lambda alias to point to new versions of the function when the company finishes testing.","C":"Directly code the image processing parameters within the Lambda function and remove the environment variables. Publish a new function version when the company updates the parameters.","B":"Create an Amazon DynamoDB table to store the image processing parameters. Modify the Lambda function to retrieve the image processing parameters from the DynamoDB table.","A":"Directly modify the environment variables of the published Lambda function version. Use the SLATEST version to test image processing parameters."},"unix_timestamp":1673884020,"answers_community":["D (100%)"],"answer_ET":"D","question_images":[],"question_text":"A company gives users the ability to upload images from a custom application. The upload process invokes an AWS Lambda function that processes and stores the image in an Amazon S3 bucket. The application invokes the Lambda function by using a specific function version ARN.\n\nThe Lambda function accepts image processing parameters by using environment variables. The company often adjusts the environment variables of the Lambda function to achieve optimal image processing output. The company tests different parameters and publishes a new function version with the updated environment variables after validating results. This update process also requires frequent changes to the custom application to invoke the new function version ARN. These changes cause interruptions for users.\n\nA solutions architect needs to simplify this process to minimize disruption to users.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","exam_id":33,"isMC":true,"answer_images":[],"question_id":62,"discussion":[{"upvote_count":"12","poster":"tatdatpham","comment_id":"795578","timestamp":"1690924800.0","content":"Selected Answer: D\nD is correct\nBy using a function alias, the custom application invokes the latest version of the Lambda function without the need to modify the application code every time the company updates the image processing parameters. This reduces the risk of causing interruptions for users."},{"poster":"masetromain","upvote_count":"5","content":"Selected Answer: D\nD. Create a Lambda function alias. Modify the client application to use the function alias ARN. Reconfigure the Lambda alias to point to new versions of the function when the company finishes testing.\n\nCreating a Lambda function alias allows the solutions architect to change the version of the Lambda function that the alias points to without modifying the client application. This eliminates the need for frequent updates to the custom application and minimizes disruption to users. The solutions architect can test different parameters by using different versions of the function and reconfigure the alias to point to the new version after validating results. This allows the company to update the image processing parameters without affecting the users.","timestamp":"1689531300.0","comments":[{"poster":"masetromain","upvote_count":"2","content":"Option A: Directly modifying the environment variables of the published Lambda function version would cause all clients to use the updated environment variables immediately and would not allow for testing.\nOption B: Using DynamoDB to store image processing parameters increases complexity and operational overhead, and it would not eliminate the need for updating the custom application.\nOption C: Directly coding the image processing parameters within the Lambda function and publishing new versions would not eliminate the need for updating the custom application.","timestamp":"1689531300.0","comment_id":"778201"}],"comment_id":"778200"},{"poster":"career360guru","upvote_count":"1","content":"Selected Answer: D\nOption D has least operational overhead.","timestamp":"1719200820.0","comment_id":"1104463"},{"timestamp":"1717300260.0","comment_id":"1085724","poster":"edder","upvote_count":"1","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html"},{"comment_id":"985265","upvote_count":"1","poster":"SK_Tyagi","timestamp":"1708360440.0","content":"Selected Answer: D\nLook for ALIAS"},{"timestamp":"1704389340.0","poster":"NikkyDicky","content":"Selected Answer: D\nD\nB is ok, but more overhead","upvote_count":"1","comment_id":"942927"},{"poster":"SkyZeroZx","comment_id":"926905","timestamp":"1702940880.0","content":"Selected Answer: D\nkeyword = Lambda ALIAS\nthen D","upvote_count":"1"},{"content":"Selected Answer: D\nCreate a Lambda function alias.","comment_id":"851855","timestamp":"1695799320.0","poster":"mfsec","upvote_count":"1"},{"comment_id":"777891","poster":"zhangyu20000","upvote_count":"1","content":"D is correct","timestamp":"1689515220.0"}],"answer_description":"","answer":"D"},{"id":"HqcNrIs5gRjSebGlgDrD","unix_timestamp":1673891040,"choices":{"D":"Create an Amazon API Gateway API that is backed by AWS Lambda in one of the AWS Regions. Configure a Lambda function to route traffic to application deployments by using the round robin method. Create CNAME records for the apex domain to point to the API's URL.","C":"Create an AWS Global Accelerator accelerator with multiple endpoint groups that target endpoints in appropriate AWS Regions. Use the accelerator’s static IP address to create a record in public DNS for the apex domain.","A":"Migrate public DNS to Amazon Route 53. Create CNAME records for the apex domain to point to the ALB. Use a geolocation routing policy to route traffic based on user location.","B":"Place a Network Load Balancer (NLB) in front of the ALMigrate public DNS to Amazon Route 53. Create a CNAME record for the apex domain to point to the NLB’s static IP address. Use a geolocation routing policy to route traffic based on user location."},"exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/95605-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"C","question_text":"A global media company is planning a multi-Region deployment of an application. Amazon DynamoDB global tables will back the deployment to keep the user experience consistent across the two continents where users are concentrated. Each deployment will have a public Application Load Balancer (ALB). The company manages public DNS internally. The company wants to make the application available through an apex domain.\n\nWhich solution will meet these requirements with the LEAST effort?","discussion":[{"poster":"God_Is_Love","upvote_count":"22","comment_id":"838501","content":"Selected Answer: C\nNo, an apex domain cannot use CNAME records in AWS. This is because of the way DNS resolution works. A CNAME record specifies an alias for a domain name, which points to the canonical name of another domain. However, the DNS standard does not allow CNAME records for apex domains, as they should only have A or AAAA records.\n\nWhen you try to create a CNAME record for an apex domain in AWS Route 53, you will receive an error message indicating that the record set type is not valid for the apex domain. To work around this limitation, you can use an alias record instead.","timestamp":"1694651340.0"},{"poster":"zhangyu20000","content":"C is correct\nABD all have CNAME record that is not allowed for apex domain","timestamp":"1689522240.0","upvote_count":"10","comment_id":"778035"},{"content":"Selected Answer: C\nOption C","timestamp":"1719201240.0","comment_id":"1104464","poster":"career360guru","upvote_count":"2"},{"upvote_count":"3","poster":"yuliaqwerty","comment_id":"1099042","timestamp":"1718631180.0","content":"C https://aws.amazon.com/blogs/networking-and-content-delivery/solving-dns-zone-apex-challenges-with-third-party-dns-providers-using-aws/"},{"upvote_count":"1","poster":"[Removed]","comment_id":"1026131","content":"You can create alias record for apex domain in route 53 However the question is asking about least effort and the client is managing domain internally","timestamp":"1712366220.0"},{"poster":"Explorer_30","comment_id":"997377","timestamp":"1709454780.0","content":"The answer is C","upvote_count":"1"},{"comment_id":"942930","content":"Selected Answer: C\nC\nno CNAME for apex","timestamp":"1704389520.0","poster":"NikkyDicky","upvote_count":"2"},{"upvote_count":"1","poster":"SkyZeroZx","comment_id":"926907","content":"Selected Answer: C\nA , B no seems because reference geolocation \nD no seems because apex domain with API Gateway ? \nthen C Global Accelerator is good option","timestamp":"1702941000.0"},{"upvote_count":"4","poster":"chikorita","comment_id":"919003","content":"fun fact: CNAME records does not support APEX domain\nwhich simply rules out the options with CNAME in it\nanswer is C","timestamp":"1702113060.0"},{"comment_id":"851859","content":"Selected Answer: C\nCreate an AWS Global Accelerator accelerator with multiple endpoint groups that target endpoints in appropriate AWS Regions.","upvote_count":"3","timestamp":"1695799380.0","poster":"mfsec"},{"upvote_count":"5","comment_id":"778204","poster":"masetromain","content":"Selected Answer: C\nC. Create an AWS Global Accelerator accelerator with multiple endpoint groups that target endpoints in appropriate AWS Regions. Use the accelerator’s static IP address to create a record in public DNS for the apex domain.\n\nThis solution meets the requirements with the least effort because it uses AWS Global Accelerator, which automatically routes traffic to the optimal endpoint based on health and geography, eliminating the need for manual configuration or additional routing policies. It also eliminates the need to create a CNAME record for the apex domain to point to the ALB or NLB's IP address, which can be less efficient and less reliable.","timestamp":"1689531540.0","comments":[{"upvote_count":"1","comments":[{"comment_id":"778207","content":"D. Create an Amazon API Gateway API that is backed by AWS Lambda in one of the AWS Regions. Configure a Lambda function to route traffic to application deployments by using the round robin method. Create CNAME records for the apex domain to point to the API's URL.\n\nThis solution uses Amazon API Gateway and AWS Lambda to route traffic, but the round-robin method is not the best way to ensure optimal performance and availability for a multi-region deployment. Additionally, routing traffic through a Lambda function can introduce additional latency.\n\nAWS Global Accelerator is a more efficient solution that automatically routes traffic to the optimal endpoint based on health and geography, eliminating the need for manual configuration or additional routing policies.","timestamp":"1689531660.0","upvote_count":"1","poster":"masetromain"}],"timestamp":"1689531660.0","comment_id":"778206","content":"A. Migrate public DNS to Amazon Route 53. Create CNAME records for the apex domain to point to the ALB. Use a geolocation routing policy to route traffic based on user location.\nWhile this solution uses Route 53 and geolocation routing, it requires manual configuration and maintenance of the routing policy and could introduce additional latency as traffic is routed through the ALB first.\n\nB. Place a Network Load Balancer (NLB) in front of the ALB. Migrate public DNS to Amazon Route 53. Create a CNAME record for the apex domain to point to the NLB’s static IP address. Use a geolocation routing policy to route traffic based on user location.\nThis solution is similar to the first one, but it uses a Network Load Balancer (NLB) instead of an Application Load Balancer (ALB). It has the same downsides as the first solution.","poster":"masetromain"}]}],"topic":"1","timestamp":"2023-01-16 18:44:00","answer_images":[],"question_images":[],"answers_community":["C (100%)"],"answer_description":"","answer_ET":"C","isMC":true,"question_id":63},{"id":"anAcSR1OyxB5B5tyIds3","topic":"1","timestamp":"2023-01-16 01:58:00","url":"https://www.examtopics.com/discussions/amazon/view/95494-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"D":"Deploy the shared libraries, custom classes, and code for the API's Lambda functions to a Docker image. Upload the image to Amazon Elastic Container Registry (Amazon ECR). Configure the API's Lambda functions to use the Docker image as the deployment package.","C":"Deploy the shared libraries and custom classes to a Docker container in Amazon Elastic Container Service (Amazon ECS) by using the AWS Fargate launch type. Deploy the API's Lambda functions as Zip packages. Configure the packages to use the deployed container as a Lambda layer.","B":"Deploy the shared libraries and custom classes to a Docker image. Upload the image to Amazon Elastic Container Registry (Amazon ECR). Create a Lambda layer that uses the Docker image as the source. Deploy the API's Lambda functions as Zip packages. Configure the packages to use the Lambda layer.","A":"Deploy the shared libraries and custom classes into a Docker image. Store the image in an S3 bucket. Create a Lambda layer that uses the Docker image as the source. Deploy the API's Lambda functions as Zip packages. Configure the packages to use the Lambda layer."},"unix_timestamp":1673830680,"answers_community":["D (70%)","B (30%)"],"answer_ET":"D","question_images":[],"question_text":"A company is developing a new serverless API by using Amazon API Gateway and AWS Lambda. The company integrated the Lambda functions with API Gateway to use several shared libraries and custom classes.\n\nA solutions architect needs to simplify the deployment of the solution and optimize for code reuse.\n\nWhich solution will meet these requirements?","exam_id":33,"isMC":true,"question_id":64,"answer_images":[],"discussion":[{"content":"Selected Answer: D\nDon't understand why so many people are choosing B. Read up. A container image cannot be used with Lambda layers. That means A B C are out instantly. Its literally one of the first things they mention about Lamba layers. Answer is D and ABC simply impossible to configure.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html","upvote_count":"44","poster":"lunt","comment_id":"811101","comments":[{"upvote_count":"3","poster":"titi_r","content":"You can create a Lambda function from an ECR image, but you CANNOT create a Lambda function layer from an ECR image!","comment_id":"1207340","timestamp":"1715000400.0"},{"comment_id":"976119","timestamp":"1691541600.0","poster":"Gabehcoud","upvote_count":"3","content":"https://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/\n\nPreviously, Lambda functions were packaged only as .zip archives. This includes functions created in the AWS Management Console. You can now also package and deploy Lambda functions as container images.\n\nYou can use familiar container tooling such as the Docker CLI with a Dockerfile to build, test, and tag images locally. Lambda functions built using container images can be up to 10 GB in size. You push images to an Amazon Elastic Container Registry (ECR) repository, a managed AWS container image registry service. You create your Lambda function, specifying the source code as the ECR image URL from the registry."},{"timestamp":"1678467000.0","content":"https://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/","poster":"rtgfdv3","upvote_count":"3","comment_id":"835242"},{"content":"B suggests deploying the shared libraries and custom classes to a Docker image, uploading it to Amazon Elastic Container Registry (Amazon ECR), creating a Lambda layer that uses the Docker image as the source, and deploying the API's Lambda functions as Zip packages. Configuring the packages to use the Lambda layer simplifies deployment, and the Docker image allows for code reuse. This option takes advantage of the built-in features provided by AWS API Gateway and Lambda, making it the optimal solution.","comment_id":"812151","timestamp":"1676653560.0","poster":"c73bf38","upvote_count":"5","comments":[{"timestamp":"1677162600.0","comment_id":"819290","upvote_count":"4","content":"The requirement is code reuse: \nhttps://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/\nLambda functions packaged as container images do not support adding Lambda layers to the function configuration. However, there are a number of solutions to use the functionality of Lambda layers with container images. You take on the responsible for packaging your preferred runtimes and dependencies as a part of the container image during the build process.","poster":"c73bf38"}]},{"timestamp":"1684704420.0","content":"D does not seem a correct option because is suggests packaging everything into a lambda layer including the Lambda functions this will break the reusability of the deployment. All you need to package into images are the libraries and the custom classes and then build the layer from there. \nthe correct option is B, in my view.","upvote_count":"4","comment_id":"903548","poster":"rbm2023"}],"timestamp":"1676581500.0"},{"content":"Selected Answer: D\nOption A, B and C are wrong. An AWS Lambda Layer does not support a Docker image or a deployed container as the source.\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\nhttps://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/","timestamp":"1674914820.0","comment_id":"790645","upvote_count":"8","poster":"Untamables"},{"upvote_count":"1","poster":"albert_kuo","timestamp":"1741147860.0","content":"Selected Answer: D\nLambda Layer does not support Docker image.","comment_id":"1365256"},{"content":"Selected Answer: D\nIf any of you ever really worked in lambda with docker image, you will instantly choose D without hesitation.\n\nzipped package can be deployed straightaway and it doesn't need a container. Don't get those two things(lambda zip deployment vs lambda container deployment) mixed up","comment_id":"1262283","upvote_count":"1","poster":"kgpoj","timestamp":"1723083840.0"},{"timestamp":"1721736840.0","poster":"zolthar_z","content":"Selected Answer: D\nPlease read the requirement, \"simplify the deployment\" with D you need only to maintain the docker image, with B you need to maintain the docker image and the process to deploy the lambda as ZIP Packages.","comment_id":"1253641","upvote_count":"1"},{"timestamp":"1703425800.0","poster":"Nicoben","content":"Selected Answer: B\nOption B is the right one, see: https://docs.aws.amazon.com/lambda/latest/dg/images-create.html","upvote_count":"2","comment_id":"1104629"},{"comment_id":"1104466","timestamp":"1703397960.0","poster":"career360guru","upvote_count":"1","content":"Selected Answer: D\nOption D"},{"comment_id":"1072294","timestamp":"1700126880.0","upvote_count":"1","content":"Selected Answer: D\ncheck Iunt's answer","poster":"severlight"},{"timestamp":"1697263500.0","poster":"rlf","comment_id":"1043151","upvote_count":"2","content":"B. \n* A Lambda layer is a .zip file archive that contains supplementary code or data. Layers usually contain library dependencies, a custom runtime, or configuration files.\n* Lambda functions packaged as container images do not support adding Lambda layers to the function configuration.However, there are a number of solutions to use the functionality of Lambda layers with container images. You take on the responsible for packaging your preferred runtimes and dependencies as a part of the container image during the build process."},{"comment_id":"1003797","poster":"dkcloudguru","content":"Ans is D: https://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/#:~:text=Lambda%20functions%20packaged%20as%20container,Lambda%20layers%20with%20container%20images.","timestamp":"1694332680.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1692680400.0","comment_id":"987087","content":"https://www.youtube.com/watch?v=17R0vN8bt-0","poster":"vn_thanhtung"},{"comment_id":"965035","content":"Correct B.","timestamp":"1690492140.0","upvote_count":"2","poster":"ggrodskiy"},{"content":"Selected Answer: D\nD\nlayers not supported w container-based lambdas","timestamp":"1688485020.0","upvote_count":"1","poster":"NikkyDicky","comment_id":"942933"},{"comment_id":"933755","content":"Selected Answer: D\nDocker images cannot be used in Lambda layers.","upvote_count":"1","timestamp":"1687710480.0","poster":"pupsik"},{"upvote_count":"1","poster":"Jackhemo","comment_id":"928125","content":"Selected Answer: B\nFrom olabiba.ai: Overall, option B provides a streamlined approach to optimize code reuse by centralizing the shared code in a Docker image and using a Lambda layer to share it across multiple functions.","timestamp":"1687231020.0"},{"upvote_count":"1","poster":"Roontha","comment_id":"915727","content":"Answer : B","timestamp":"1685999580.0"},{"comment_id":"903560","content":"Selected Answer: B\n\"Lambda functions packaged as container images do not support adding Lambda layers to the function configuration. However, there are a number of solutions to use the functionality of Lambda layers with container images. You take on the responsible for packaging your preferred runtimes and dependencies as a part of the container image during the build process.\"\nhttps://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/","timestamp":"1684707960.0","poster":"rbm2023","upvote_count":"6"},{"comment_id":"891186","content":"Selected Answer: D\nAlthough the following URL says that you can deploy Lambda layers as container but this can't be used when the Lambda function in zip. The function will be created as another layer in the container image and it should use Lambda runtime environment.\nhttps://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/","timestamp":"1683440040.0","upvote_count":"3","poster":"AMEJack"},{"content":"Selected Answer: D\nB is incorrect.. Docker images uses Layers refer to other Docker images, You can refer to a Docker layer ONLY if you choose to run your code in a Docker container (not a ZIP)\n\nread this article:\nhttps://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/","comment_id":"866088","timestamp":"1681111620.0","poster":"dev112233xx","comments":[{"upvote_count":"2","comment_id":"866092","comments":[{"timestamp":"1681112520.0","content":"and\n\"Lambda functions packaged as container images do not support adding Lambda layers to the function configuration. However, there are a number of solutions to use the functionality of Lambda layers with container images. You take on the responsible for packaging your preferred runtimes and dependencies as a part of the container image during the build process.\"\nSo it's clearly not B","comment_id":"866094","upvote_count":"2","poster":"dev112233xx"}],"poster":"dev112233xx","timestamp":"1681112400.0","content":"Also read this article:\n\"You can use layers only with Lambda functions deployed as a .zip file archive. For functions defined as a container image, you package your preferred runtime and all code dependencies when you create the container image. For more information, see Working with Lambda layers and extensions in container images on the AWS Compute Blog.\"\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html"}],"upvote_count":"4"},{"timestamp":"1680272340.0","content":"Selected Answer: B\nThis page is in Japanese.\nhttps://michimani.net/post/aws-create-lambda-layers-with-docker/","comment_id":"857174","poster":"Asagumo","upvote_count":"3"},{"content":"Selected Answer: D\nB is correct.","upvote_count":"2","timestamp":"1680098820.0","poster":"[Removed]","comment_id":"854501"},{"comment_id":"851866","upvote_count":"3","content":"Selected Answer: D\nD seems a better choice. Docker images can be used to package and deploy Lambda functions directly, but not for Lambda layers.","timestamp":"1679902260.0","poster":"mfsec"},{"upvote_count":"2","poster":"taer","comment_id":"842716","content":"Selected Answer: B\nB. Deploy the shared libraries and custom classes to a Docker image. Upload the image to Amazon Elastic Container Registry (Amazon ECR). Create a Lambda layer that uses the Docker image as the source. Deploy the API's Lambda functions as Zip packages. Configure the packages to use the Lambda layer.","timestamp":"1679139600.0"},{"comment_id":"837339","poster":"God_Is_Love","timestamp":"1678649700.0","content":"Selected Answer: B\nLambda layers to package the common code and save it in ECR as a docker image and refer it from actual lambda function.\nBy using Lambda Layers, the shared libraries and custom classes can be reused across multiple Lambda functions, simplifying the deployment and management of the serverless API. The Lambda Layer can also be versioned, making it easy to update and manage changes to the shared code.\n\nAdditionally, the use of Lambda Layers can help reduce the size of the Lambda function packages, which can result in faster deployment times and lower costs.","upvote_count":"4"},{"poster":"hobokabobo","upvote_count":"1","comment_id":"837126","content":"Selected Answer: D\nAFAIK it is either-or. Either one uses a docker images or Lambda Layers as zip files. I may overlook something but I cannot see a way to have Lambda as zip together with libraries in a container.\nTo put it simple: a Lambda Layer is a zip file and not a docker container. \nYou can use a container instead of Lambda Layers - have a container image created from a cascade of different docker layers(image from ... image from ... image from).\nThat makes D the only valid option .","timestamp":"1678632660.0"},{"content":"D is correct, \nB is a overhead and is not supported in aws console","poster":"vherman","timestamp":"1678540440.0","upvote_count":"1","comment_id":"836019"},{"timestamp":"1678436460.0","poster":"sambb","comment_id":"834745","upvote_count":"2","content":"Selected Answer: D\nFrom my understanding, a lambda layer is a zip, not a docker image or a container. This exludes A, B and C. The D is valid because the whole package with the shared libs and the code is a single docker image, this would work."},{"timestamp":"1677439560.0","poster":"kiran15789","comment_id":"822890","upvote_count":"2","content":"Selected Answer: B\nAn AWS Lambda Layer is a distribution mechanism for libraries, custom runtimes, or other function dependencies. With Lambda Layers, you can manage in a central place your in-house or third-party code that you want to share across multiple functions or even multiple teams. By providing this functionality, Lambda Layers allow you to reduce the size of your deployment package, simplify your development process, and enable code reuse across multiple functions.\n\nWhen you create a layer, you can specify runtime dependencies that your functions require, and then attach those dependencies to your functions at runtime. This allows you to write less code and reuse the same code across multiple functions, and simplifies the process of managing and updating the dependencies of your functions."},{"comment_id":"797760","poster":"jojom19980","upvote_count":"1","timestamp":"1675501140.0","content":"Selected Answer: B\nhttps://aws.amazon.com/premiumsupport/knowledge-center/lambda-layer-simulated-docker/#:~:text=(Optional)%20To%20use%20the%20Docker,package%20without%20creating%20a%20layer."},{"upvote_count":"4","content":"Selected Answer: B\n\"use several shared libraries and custom classes\" => Use Lambda layer to optimize code reuse.\n=> A & B are matched but A is saving Image into S3, not good. Should use ECR.\nSo the answer is B","timestamp":"1675294620.0","poster":"tatdatpham","comment_id":"795586"},{"content":"Selected Answer: B\nAfter reading comment , I guess B makes more sens than D","upvote_count":"2","comment_id":"792319","poster":"zozza2023","timestamp":"1675045800.0"},{"comment_id":"778210","poster":"masetromain","comments":[{"upvote_count":"1","poster":"masetromain","comment_id":"778212","content":"A. Deploy the shared libraries and custom classes into a Docker image. Store the image in an S3 bucket. Create a Lambda layer that uses the Docker image as the source. Deploy the API's Lambda functions as Zip packages. Configure the packages to use the Lambda layer.\n\nThis solution is similar to option B, but it uses S3 bucket to store the Docker image instead of Amazon Elastic Container Registry (ECR). Using S3 for storing the image may be less secure and less manageable than using ECR.\n\nC. Deploy the shared libraries and custom classes to a Docker container in Amazon Elastic Container Service (Amazon ECS) by using the AWS Fargate launch type. Deploy the API's Lambda functions as Zip packages. Configure the packages to use the deployed container as a Lambda layer.\n\nThis solution is using a more complex service (ECS) and launch type (Fargate) which is not necessary, it will also increase the complexity of the deployment process and make it harder to manage.","comments":[{"comment_id":"778213","content":"D. Deploy the shared libraries, custom classes, and code for the API's Lambda functions to a Docker image. Upload the image to Amazon Elastic Container Registry (Amazon ECR). Configure the API's Lambda functions to use the Docker image as the deployment package.\n\nThis solution is using a single image to contain all the shared libraries, custom classes, and the code for the API's Lambda functions, which makes it harder to manage and update the shared libraries and custom classes. It also increases the size of the image and make it harder to reuse the common code.","timestamp":"1673900640.0","upvote_count":"3","poster":"masetromain"}],"timestamp":"1673900640.0"}],"content":"Selected Answer: B\nB. Deploy the shared libraries and custom classes to a Docker image. Upload the image to Amazon Elastic Container Registry (Amazon ECR). Create a Lambda layer that uses the Docker image as the source. Deploy the API's Lambda functions as Zip packages. Configure the packages to use the Lambda layer.\n\nThis solution will simplify the deployment of the solution and optimize for code reuse as it utilizes Lambda Layers to share common code and dependencies. By using Amazon Elastic Container Registry (ECR) to store the Docker image, it allows for easy management and versioning of the shared libraries and custom classes. This way the common code can be reused across multiple Lambda functions and are only deployed once.","timestamp":"1673900580.0","upvote_count":"4"},{"timestamp":"1673830680.0","poster":"zhangyu20000","content":"B: is correct. use Lambda layer. Layer source is docker images on ECR","upvote_count":"1","comment_id":"777228"}],"answer_description":"","answer":"D"},{"id":"1pxbhAX9Wa097WaXygGc","question_images":[],"unix_timestamp":1675353420,"topic":"1","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/97669-exam-aws-certified-solutions-architect-professional-sap-c02/","isMC":true,"answer_description":"","discussion":[{"poster":"God_Is_Love","upvote_count":"19","comment_id":"837347","content":"Selected Answer: B\nOffline operation: AWS IoT Greengrass supports offline operation by enabling devices to continue processing data even when they are disconnected from the internet.","timestamp":"1694540700.0"},{"poster":"Appon","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/machine-learning/anomaly-detection-with-amazon-sagemaker-edge-manager-using-aws-iot-greengrass-v2/","timestamp":"1691652480.0","upvote_count":"5","comment_id":"804173"},{"upvote_count":"1","poster":"career360guru","content":"Selected Answer: B\nOption B","timestamp":"1719202320.0","comment_id":"1104467"},{"timestamp":"1710172440.0","comment_id":"1004879","poster":"dkcloudguru","upvote_count":"1","content":"Option B: Greengrass supports offline operation"},{"comment_id":"985288","comments":[{"comment_id":"985296","timestamp":"1708363500.0","upvote_count":"1","poster":"SK_Tyagi","content":"If you can't commission your sensors\nConsider the following questions.\n\nDoes the mobile phone running the Amazon Monitron App have a stable internet connection?\n\nhttps://docs.aws.amazon.com/Monitron/latest/user-guide/troubleshooting.html\n\nFor commissioning a sensor, the mobile phone running the Amazon Monitron App should have internet connectivity."}],"timestamp":"1708363020.0","upvote_count":"2","poster":"SK_Tyagi","content":"Selected Answer: B\nOffline = IoT Greengrass"},{"poster":"NikkyDicky","content":"Selected Answer: B\nB for offline","comment_id":"942939","upvote_count":"1","timestamp":"1704390060.0"},{"content":"Selected Answer: B\nkeyword = WS IoT Greengrass","poster":"SkyZeroZx","upvote_count":"1","timestamp":"1702941120.0","comment_id":"926909"},{"content":"Selected Answer: B\nCan't be D.\nAmazon Monitron requires Internet connection.Q: Can I use Amazon Monitron when it is not connected to the AWS Region or in a disconnected environment?\n\nA: Amazon Monitron Sensors and Gateways, and their use with the Amazon Monitron service, rely on connectivity over internet to the AWS Region. \nhttps://aws.amazon.com/monitron/faqs/\nAmazon Monitron Sensors and Gateways are not designed for disconnected operations or environments with no connectivity. We recommend that customers have highly available internet connectivity.","poster":"consultornetwork","upvote_count":"3","timestamp":"1701100140.0","comment_id":"908026"},{"poster":"Diego1414","comment_id":"893352","timestamp":"1699561800.0","upvote_count":"1","content":"Selected Answer: B\nAWS IoT Greengrass is software that extends cloud capabilities to local devices. This enables devices to collect and analyze data closer to the source of information, react autonomously to local events, and communicate securely with each other on local networks. Local devices can also communicate securely with AWS IoT Core and export IoT data to the AWS Cloud. AWS IoT Greengrass developers can use AWS Lambda functions and prebuilt connectors to create serverless applications that are deployed to devices for local execution."},{"upvote_count":"3","timestamp":"1695800400.0","content":"Selected Answer: B\nThe ML model is run locally, so it can still provide feedback when the internet is down.","poster":"mfsec","comment_id":"851881"},{"comment_id":"837105","upvote_count":"1","content":"Selected Answer: D\nQuote \"The company must be able to provide this feedback even if the factory’s internet connectivity is down\"\nSo everything that needs internet can be ignored. Leaves D.\nWhile there is a lot of garbage text about how they process date with SargeMaker, the question only asks for a solution to detect failures in the equipment. Amazon Monitron does this plus it can work even when internet is down.\n\nAll other options provide solutions for things, the question didn't ask for and/or already in place and need internet.","timestamp":"1694521200.0","poster":"hobokabobo"},{"poster":"Untamables","upvote_count":"2","timestamp":"1691637600.0","comment_id":"803990","content":"Selected Answer: B\nThe point is how to offload ML workloads to the local."},{"poster":"Musk","timestamp":"1691511360.0","upvote_count":"1","content":"Selected Answer: B\nMonitron is something different","comment_id":"802373"},{"timestamp":"1690986840.0","upvote_count":"4","poster":"bititan","comment_id":"796232","content":"Selected Answer: B\nthis is taking about detecting defects from an image that is taken from a camera. I would go for running a ML model on IoT greengras pc and transfer it to IoT core, then store it in s3 bucket, which can be called by api function via lambda to send it to users. \noption D would monitor only sensor data of machines."},{"upvote_count":"2","content":"Selected Answer: D\nAmazon Monitron is a machine-learning based end-to-end condition monitoring system that detects potential failures within equipment. You can use it to implement a predictive maintenance program and reduce lost productivity from unplanned machine downtime. Amazon Monitron includes purpose-built sensors to capture vibration and temperature data, as well as gateways to automatically transfer data to the AWS Cloud. It also comes with an application in two versions. The mobile application handles system setup, analytics, and notiﬁcation when tracking equipment conditions. The web application provides all the same functions as the mobile app except setup. Reliability managers can quickly deploy Amazon Monitron to track the machine health of industrial equipment, such as such as bearings, motors, gearboxes, and pumps, without any development work or specialized training.","comments":[{"content":"B is correct.\nAWS IoT Greengrass enables ML inference locally using models that are created, trained, and optimized in the cloud using Amazon SageMaker, AWS Deep Learning AMI, or AWS Deep Learning Containers, and deployed on the edge devices","poster":"schalke04","comments":[{"poster":"youngprinceton","content":"when do you take the exam man i would like to see if everything is still valid after you test","comment_id":"800044","upvote_count":"1","timestamp":"1691337720.0"}],"comment_id":"797416","upvote_count":"3","timestamp":"1691092320.0"},{"timestamp":"1691327940.0","comment_id":"799892","poster":"schalke04","upvote_count":"2","content":"B is wrong, D is correct."}],"timestamp":"1690984620.0","poster":"schalke04","comment_id":"796193"}],"answer_ET":"B","question_text":"A manufacturing company is building an inspection solution for its factory. The company has IP cameras at the end of each assembly line. The company has used Amazon SageMaker to train a machine learning (ML) model to identify common defects from still images.\n\nThe company wants to provide local feedback to factory workers when a defect is detected. The company must be able to provide this feedback even if the factory’s internet connectivity is down. The company has a local Linux server that hosts an API that provides local feedback to the workers.\n\nHow should the company deploy the ML model to meet these requirements?","choices":{"B":"Deploy AWS IoT Greengrass on the local server. Deploy the ML model to the Greengrass server. Create a Greengrass component to take still images from the cameras and run inference. Configure the component to call the local API when a defect is detected.","D":"Deploy Amazon Monitron devices on each IP camera. Deploy an Amazon Monitron Gateway on premises. Deploy the ML model to the Amazon Monitron devices. Use Amazon Monitron health state alarms to call the local API from an AWS Lambda function when a defect is detected.","A":"Set up an Amazon Kinesis video stream from each IP camera to AWS. Use Amazon EC2 instances to take still images of the streams. Upload the images to an Amazon S3 bucket. Deploy a SageMaker endpoint with the ML model. Invoke an AWS Lambda function to call the inference endpoint when new images are uploaded. Configure the Lambda function to call the local API when a defect is detected.","C":"Order an AWS Snowball device. Deploy a SageMaker endpoint the ML model and an Amazon EC2 instance on the Snowball device. Take still images from the cameras. Run inference from the EC2 instance. Configure the instance to call the local API when a defect is detected."},"timestamp":"2023-02-02 16:57:00","question_id":65,"exam_id":33,"answers_community":["B (93%)","7%"],"answer":"B"}],"exam":{"provider":"Amazon","numberOfQuestions":529,"isImplemented":true,"isMCOnly":true,"lastUpdated":"11 Apr 2025","isBeta":false,"id":33,"name":"AWS Certified Solutions Architect - Professional SAP-C02"},"currentPage":13},"__N_SSP":true}