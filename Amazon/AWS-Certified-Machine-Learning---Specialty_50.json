{"pageProps":{"questions":[{"id":"i144kXm5vnnOtMPYHbNi","timestamp":"2021-03-11 07:17:00","choices":{"D":"Normalization transformation","A":"Binarization","B":"One-hot encoding","C":"Tokenization"},"answer":"B","discussion":[{"poster":"omar_bahrain","comment_id":"307640","content":"I choose b","timestamp":"1666030800.0","upvote_count":"17"},{"comment_id":"343441","timestamp":"1666736640.0","content":"Correct answer is B.\nExample:\nMon | Tue | Wed ....\n1 0 0\n0 1 0","poster":"Juka3lj","upvote_count":"9"},{"upvote_count":"2","content":"Selected Answer: B\nEasy Peasy","comment_id":"964996","timestamp":"1722109080.0","poster":"kaike_reis"},{"comment_id":"906128","content":"Selected Answer: B\nAny categorical feature needs to be converted using One Hot Encoding and NOT label encoding.","timestamp":"1716579780.0","upvote_count":"1","poster":"earthMover"},{"poster":"Tomatoteacher","content":"Originally I put A, (believing to be able to format it as (0,1,2,3,4,5,6), or something as it mentioned it to convert the column, but later I realized Binarization is only designed for continuous or numerical data. Even though one-hot encoding will create 6 more columns it is correct. B is correct.","upvote_count":"1","timestamp":"1705336920.0","comment_id":"776820"},{"timestamp":"1702078500.0","comment_id":"739584","poster":"Peeking","content":"B\n1000000 = Mon\n0100000 = Tue\n0010000 = Wed\n0001000 = Thur\n0000100 = Fri\n0000010 = Sat\n0000001=Sun","upvote_count":"2"},{"poster":"benliu1974","content":"why not A? 001 010, 011","comments":[{"timestamp":"1729137480.0","content":"i thought of this at first, but chatgpt's explanation changed my mind\n\nIn summary, if the names of days represent nominal categorical variables, one-hot encoding is generally the preferred choice. It maintains distinctiveness, is interpretable, and ensures that each day is clearly represented as a separate binary feature. Binary encoding may be considered for memory efficiency, especially when dealing with a large number of ordinal categories, but it should be used with caution as it introduces an ordinal relationship between categories, which may or may not align with the nature of the data. Ultimately, the choice between the two methods should align with the specific needs of your analysis and the data's characteristics.","comment_id":"1045505","upvote_count":"1","poster":"JDKJDKJDK"}],"comment_id":"672887","timestamp":"1695094980.0","upvote_count":"2"},{"poster":"apprehensive_scar","timestamp":"1675445040.0","content":"B is the obvious answer","upvote_count":"2","comment_id":"539849"},{"comment_id":"528815","content":"Binary encoding would've been a correct answer but it is not here & Binarization is used for continuous variables. leaving w/ option B","timestamp":"1674248640.0","upvote_count":"1","poster":"bitsplease"},{"poster":"Zhubajie","comment_id":"484250","content":"B is wrong. You do not need to one hot encode the variable in random trees. If you do so, you tree must be very deep, which is not efficient. The correct answer is C!","timestamp":"1669124760.0","upvote_count":"1","comments":[{"content":"\"The Specialist want to convert the Day Of Week column in the dataset to binary values.\" You are misreading the question. The answer is B.","poster":"gmnk999","comment_id":"581122","timestamp":"1680684120.0","upvote_count":"4"},{"comment_id":"487596","content":"Stop misleading people, the question already asked to convert the data into binary. C is not even remotely close to be correct","timestamp":"1669491660.0","upvote_count":"13","poster":"zach288"}]}],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/46347-exam-aws-certified-machine-learning-specialty-topic-1/","answer_description":"","answer_images":[],"topic":"1","unix_timestamp":1615443420,"exam_id":26,"answer_ET":"B","answers_community":["B (100%)"],"question_images":["https://www.examtopics.com/assets/media/exam-media/04145/0002100001.png"],"question_id":246,"question_text":"Machine Learning Specialist is working with a media company to perform classification on popular articles from the company's website. The company is using random forests to classify how popular an article will be before it is published. A sample of the data being used is below.\n//IMG//\n\nGiven the dataset, the Specialist wants to convert the Day_Of_Week column to binary values.\nWhat technique should be used to convert this column to binary values?"},{"id":"N5kzqffMSw3LnMMhjIuC","answer_images":[],"unix_timestamp":1710391380,"choices":{"B":"Configure the VPC that contains the SageMaker notebook instances to use VPC interface endpoints to establish connections for training and hosting. Modify any existing security groups that are associated with the VPC interface endpoint to allow only outbound connections for training and hosting.","A":"Connect the SageMaker notebook instances that are in the VPC by using AWS Site-to-Site VPN to encrypt all internet-bound traffic. Configure VPC flow logs. Monitor all network traffic to detect and prevent any malicious activity.","D":"Create VPC security groups to prevent all incoming and outgoing traffic. Assign the security groups to the SageMaker notebook instances.","C":"Create an IAM policy that prevents access the internet. Apply the IAM policy to an IAM role. Assign the IAM role to the SageMaker notebook instances in addition to any IAM roles that are already assigned to the instances."},"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/135991-exam-aws-certified-machine-learning-specialty-topic-1/","question_text":"A company decides to use Amazon SageMaker to develop machine learning (ML) models. The company will host SageMaker notebook instances in a VPC. The company stores training data in an Amazon S3 bucket. Company security policy states that SageMaker notebook instances must not have internet connectivity.\n\nWhich solution will meet the company’s security requirements?","answers_community":["B (100%)"],"answer_ET":"B","answer":"B","question_id":247,"isMC":true,"topic":"1","exam_id":26,"discussion":[{"poster":"Peter_Hsieh","upvote_count":"2","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/inter-network-privacy.html","comment_id":"1187498","timestamp":"1727794680.0"},{"upvote_count":"1","poster":"vkbajoria","content":"Selected Answer: B\nVPC interface Endpoints will do the trick.","comment_id":"1176188","timestamp":"1726616700.0"},{"timestamp":"1726281780.0","comment_id":"1173110","upvote_count":"1","content":"Selected Answer: B\n- VPC Interface Endpoints allow notbook instances to communicate with sagemaker services without public internet traffic\n- Security groups allow outbound connections for training and hosting but block all other traffic","poster":"AIWave"}],"answer_description":"","timestamp":"2024-03-14 05:43:00"},{"id":"z9XxbczVafu05VxUOuMI","unix_timestamp":1710394320,"choices":{"D":"Use multiple jobs in parallel for the hyperparameter tuning job.","A":"Use a warm start hyperparameter tuning job.","C":"Use the same random seed for the hyperparameter tuning job.","B":"Use a checkpointing hyperparameter tuning job."},"timestamp":"2024-03-14 06:32:00","discussion":[{"poster":"Peter_Hsieh","upvote_count":"1","comment_id":"1187494","timestamp":"1727794200.0","content":"https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-warm-start.html"},{"poster":"vkbajoria","timestamp":"1726616580.0","content":"Selected Answer: A\nusing warm start allows to reuse the results of previous tune run","comment_id":"1176185","upvote_count":"1"},{"poster":"AIWave","comment_id":"1173139","content":"Selected Answer: A\nA: Yes - Warm start allows you to reuse the results from a previously performed hyperparameter tuning job\nB: No - is related to saving intermediate model checkpoints during training\nC: No - won’t directly impact the tuning job time\nD: No - would increase computational resources but won’t necessarily reduce time","upvote_count":"1","timestamp":"1726284720.0"}],"question_images":[],"answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/135994-exam-aws-certified-machine-learning-specialty-topic-1/","answers_community":["A (100%)"],"answer":"A","question_id":248,"question_text":"A machine learning (ML) engineer uses Bayesian optimization for a hyperpara meter tuning job in Amazon SageMaker. The ML engineer uses precision as the objective metric.\n\nThe ML engineer wants to use recall as the objective metric. The ML engineer also wants to expand the hyperparameter range for a new hyperparameter tuning job. The new hyperparameter range will include the range of the previously performed tuning job.\n\nWhich approach will run the new hyperparameter tuning job in the LEAST amount of time?","topic":"1","answer_ET":"A","isMC":true,"exam_id":26},{"id":"irc6lByyaYQULpMSWpM6","topic":"1","answers_community":["B (100%)"],"exam_id":26,"url":"https://www.examtopics.com/discussions/amazon/view/136022-exam-aws-certified-machine-learning-specialty-topic-1/","answer_images":[],"timestamp":"2024-03-14 18:18:00","question_text":"A news company is developing an article search tool for its editors. The search tool should look for the articles that are most relevant and representative for particular words that are queried among a corpus of historical news documents.\n\nThe editors test the first version of the tool and report that the tool seems to look for word matches in general. The editors have to spend additional time to filter the results to look for the articles where the queried words are most important. A group of data scientists must redesign the tool so that it isolates the most frequently used words in a document. The tool also must capture the relevance and importance of words for each document in the corpus.\n\nWhich solution meets these requirements?","isMC":true,"choices":{"B":"Build a term frequency for each word in the articles that is weighted with the article's length. Build an inverse document frequency for each word that is weighted with all articles in the corpus. Define a final highlight score as the product of both of these frequencies. Configure the tool to retrieve the articles where this highlight score is higher for the queried words.","C":"Download a pretrained word-embedding lookup table. Create a titles-embedding table by averaging the title's word embedding for each article in the corpus. Define a highlight score for each word as inversely proportional to the distance between its embedding and the title embedding. Configure the tool to retrieve the articles where this highlight score is higher for the queried words.","D":"Build a term frequency score table for each word in each article of the corpus. Assign a score of zero to all stop words. For any other words, assign a score as the word’s frequency in the article. Configure the tool to retrieve the articles where this frequency score is higher for the queried words.","A":"Extract the topics from each article by using Latent Dirichlet Allocation (LDA) topic modeling. Create a topic table by assigning the sum of the topic counts as a score for each word in the articles. Configure the tool to retrieve the articles where this topic count score is higher for the queried words."},"question_id":249,"discussion":[{"upvote_count":"1","content":"Selected Answer: B\nThis approach uses the TF-IDF method, which effectively captures the relevance and importance of words in each document, meeting the requirements specified.","timestamp":"1727095980.0","comment_id":"1288124","poster":"MultiCloudIronMan"},{"content":"Selected Answer: B\nTF-IDF","comment_id":"1186091","upvote_count":"1","poster":"vkbajoria","timestamp":"1711802760.0"},{"upvote_count":"2","content":"Selected Answer: B\nTF captures the importance of a term within an individual document, while IDF captures the importance of a term across the entire corpus. Multiplying TF by IDF gives higher weights to terms that are frequent within a document but rare across the entire corpus, thus highlighting terms that are both relevant and distinctive.","poster":"AIWave","timestamp":"1710436680.0","comment_id":"1173590"}],"answer_description":"","unix_timestamp":1710436680,"answer_ET":"B","answer":"B","question_images":[]},{"id":"y8tNff7c6VqBoHTYh4qJ","question_id":250,"choices":{"B":"Use the SageMaker auto scaling feature for the hosted recommendation models.","A":"Deploy multiple instances for each endpoint in a VPC that spans at least two Regions.","C":"Deploy multiple instances for each production endpoint in a VPC that spans least two subnets that are in a second Availability Zone.","D":"Frequently generate backups of the production recommendation model. Deploy the backups in a second Region."},"answer_images":[],"answer_ET":"C","timestamp":"2024-03-14 18:39:00","answers_community":["C (100%)"],"discussion":[{"timestamp":"1729414260.0","upvote_count":"1","poster":"MultiCloudIronMan","content":"Selected Answer: C\nOptions A and D involve more complex configurations and higher operational overhead. Option B, while useful for scaling, does not directly address the need for high availability across multiple Availability Zones","comment_id":"1300368"},{"poster":"vkbajoria","timestamp":"1710725700.0","content":"Selected Answer: C\ntwo different AZ will provide highly available deployment","upvote_count":"2","comment_id":"1176180"},{"comment_id":"1174005","upvote_count":"3","timestamp":"1710471840.0","poster":"butaman","content":"Selected Answer: C\nThis solution meets the requirements because it provides high availability by deploying multiple instances across different subnets in a second Availability Zone. This approach ensures that if one Availability Zone goes down, the other can continue to serve requests, achieving the desired recovery time objective (RTO) of 5 minutes. This solution requires the least effort compared to the others because it doesn’t involve managing resources across multiple regions or frequent backups, and it’s more directly targeted at high availability compared to auto-scaling.\n\nPlease note that while auto-scaling (option B) can help handle increased load, it doesn’t directly address high availability in terms of uptime or recovery time objectives. Options A and D involve multiple regions, which can add complexity and may not be necessary for achieving the desired high availability and RTO."},{"content":"Selected Answer: C\nA: No - Multi region setup unnecessary\nB: No - Auto scaling is for capacity not for failovers\nC: Yes - Multiple instances running in separate subnets in two different AZ's provide quick failover\nD: No - Backups are for DR, not production failover","comment_id":"1173599","upvote_count":"1","timestamp":"1710437940.0","poster":"AIWave"}],"exam_id":26,"question_images":[],"answer":"C","topic":"1","isMC":true,"unix_timestamp":1710437940,"question_text":"A growing company has a business-critical key performance indicator (KPI) for the uptime of a machine learning (ML) recommendation system. The company is using Amazon SageMaker hosting services to develop a recommendation model in a single Availability Zone within an AWS Region.\n\nA machine learning (ML) specialist must develop a solution to achieve high availability. The solution must have a recovery time objective (RTO) of 5 minutes.\n\nWhich solution will meet these requirements with the LEAST effort?","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/136023-exam-aws-certified-machine-learning-specialty-topic-1/"}],"exam":{"isImplemented":true,"name":"AWS Certified Machine Learning - Specialty","id":26,"numberOfQuestions":369,"isMCOnly":false,"lastUpdated":"11 Apr 2025","isBeta":false,"provider":"Amazon"},"currentPage":50},"__N_SSP":true}