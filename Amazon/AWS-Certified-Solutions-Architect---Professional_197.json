{"pageProps":{"questions":[{"id":"k7C8BCDz1tg7kssPT6fk","answer":"ACE","url":"https://www.examtopics.com/discussions/amazon/view/89381-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"unix_timestamp":1669811940,"answer_description":"","discussion":[{"comment_id":"908119","upvote_count":"1","content":"Selected Answer: ACE\nhttps://repost.aws/knowledge-center/kinesis-readprovisionedthroughputexceeded\nFollow Data Streams best practices\nTo mitigate ReadProvisionedThroughputExceeded exceptions, apply these best practices:\n• Reshard your stream to increase the number of shards in the stream.\n• Use consumers with enhanced fan-out. For more information about enhanced fan-out, see Developing custom consumers with dedicated throughput (enhanced fan-out).\n• Use an error retry and exponential backoff mechanism in the consumer logic if ReadProvisionedThroughputExceeded exceptions are encountered. For consumer applications that use an AWS SDK, the requests are retried by default.","timestamp":"1685207640.0","poster":"rbm2023"},{"poster":"Jesuisleon","timestamp":"1684410000.0","comment_id":"901148","content":"Selected Answer: ACE\nB is wrong, KPL is aimed to help devs to achieve high write throughtput into Kinesis data stream. Current bottleneck is at read side not write side.\nD is wrong. Each shard can support up to five read transactions per second. When we increase shard we not only increase write but also increate read. https://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html\nF is wrong, Dynamic partitioning is for Kinesis Firehose, \"Partitioning your data minimizes the amount of data scanned, optimizes performance, and reduces costs of your analytics queries on Amazon S3\", see https://docs.aws.amazon.com/firehose/latest/dev/dynamic-partitioning.html.","upvote_count":"1"},{"poster":"dev112233xx","content":"Selected Answer: ABC\nABC:\nA- Reshard your stream to increase the number of shards\nB- adjust the polling frequency \nC- enhanced fan-out feature\nhttps://repost.aws/knowledge-center/kinesis-readprovisionedthroughputexceeded","upvote_count":"1","comment_id":"885007","timestamp":"1682843280.0"},{"upvote_count":"3","content":"Selected Answer: ACE\nace are the correct ans","timestamp":"1674997980.0","poster":"zozza2023","comment_id":"791651"},{"comment_id":"746989","upvote_count":"2","poster":"nyunyu","timestamp":"1671181380.0","content":"Selected Answer: ACE\nCorecct ACE"},{"poster":"Kende","upvote_count":"2","comment_id":"746170","timestamp":"1671113760.0","content":"ACE are the ones.\nA: Increase shards.\nC: Fan-Out.\nE: Exponential Backoff Mechanism"},{"comments":[{"timestamp":"1669812000.0","content":"D:\nWe need to reduce the number of shards in the stream.\n\nA single shard can ingest up to 1 MB of data per second (including partition keys) or 1,000 records per second for writes. Similarly, if you scale your stream to 5,000 shards, the stream can ingest up to 5 GB per second or 5 million records per second. If you need more ingest capacity, you can easily scale up the number of shards in the stream using the AWS Management Console or the UpdateShardCount API.\n\nhttps://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html","comment_id":"731462","upvote_count":"1","poster":"masetromain"}],"poster":"masetromain","comment_id":"731461","timestamp":"1669811940.0","content":"Selected Answer: BCD\nI go with BCD\n\nReadProvisionedThroughputExceeded \nhttps://aws.amazon.com/premiumsupport/knowledge-center/kinesis-readprovisionedthroughputexceeded/\n\nFollow data flow best practices to mitigate ReadProvisionedThroughputExceeded exceptions, use the following best practices:\n\n* Resize your stream to increase the number of partitions in the stream.\n* Reduce the size of GetRecords requests. You can do this by configuring the limit setting or by reducing the frequency of GetRecords requests.\n* Distribute read and write operations as evenly as possible across all partitions in Data Streams.\n* Use consumer applications with the enhanced distribution. For more information on enhanced distribution, see, Developing Custom Consumer Applications with Dedicated Throughput (Enhanced Distribution).\n* Use error retry and exponential backoff mechanism in consumer logic in case of ReadProvisionedThroughputExceeded exceptions. For consumer applications that use an AWS SDK, requests are retried by default.","upvote_count":"2"}],"answer_images":[],"topic":"1","choices":{"F":"Configure the stream to use dynamic partitioning.","E":"Use an error retry and exponential backoff mechanism in the consumer logic.","C":"Use consumers with the enhanced fan-out feature.","A":"Reshard the stream to increase the number of shards in the stream.","D":"Reshard the stream to reduce the number of shards in the stream.","B":"Use the Kinesis Producer Library (KPL). Adjust the polling frequency."},"question_images":[],"question_id":981,"isMC":true,"answers_community":["ACE (70%)","BCD (20%)","10%"],"question_text":"A company has IoT sensors that monitor traffic patterns throughout a large city. The company wants to read and collect data from the sensors and perform aggregations on the data.\n\nA solutions architect designs a solution in which the IoT devices are streaming to Amazon Kinesis Data Streams. Several applications are reading from the stream. However, several consumers are experiencing throttling and are periodically encountering a ReadProvisionedThroughputExceeded error.\n\nWhich actions should the solutions architect take to resolve this issue? (Choose three.)","timestamp":"2022-11-30 13:39:00","answer_ET":"ACE"},{"id":"H8d9g031N4u6goMUTOZj","answer_description":"","answers_community":["C (71%)","D (29%)"],"answer":"C","choices":{"D":"Associate an AWS WAF web ACL with the CloudFront distribution. Configure AWS WAF to add a custom header to the requests that are sent to the ALB. Configure advanced routing on the ALB to only forward requests that include the custom header that is set by CloudFront.","C":"Associate an AWS WAF web ACL with the CloudFront distribution. Configure CloudFront to add a custom header to the requests that are sent to the ALB. Configure advanced routing on the ALB to only forward requests that include the custom header that is set by CloudFront.","A":"Migrate the ALB to a private subnet. Associate an AWS WAF web ACL with the ALB. Update inbound rules on the ALB security group to allow traffic on port 443 only from CloudFront IP addresses.","B":"Associate an AWS WAF web ACL with the CloudFront distribution. Configure an origin access identity (OAI) on the ALB to drop access attempts that do not originate from CloudFront."},"unix_timestamp":1669813140,"answer_ET":"C","answer_images":[],"exam_id":32,"discussion":[{"poster":"FlyingHawk","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/restrict-access-to-load-balancer.html\nTo prevent users from directly accessing an Application Load Balancer and allow access only through CloudFront, complete these high-level steps:\nConfigure CloudFront to add a custom HTTP header to requests that it sends to the Application Load Balancer.\nConfigure the Application Load Balancer to only forward requests that contain the custom HTTP header.","comment_id":"1342371","timestamp":"1737156600.0","upvote_count":"1"},{"comment_id":"985155","content":"Selected Answer: C\nhttps://aws.amazon.com/vi/blogs/security/how-to-enhance-amazon-cloudfront-origin-security-with-aws-waf-and-aws-secrets-manager/","poster":"vn_thanhtung","timestamp":"1692445080.0","upvote_count":"1","comments":[{"content":"https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-action.html#:~:text=Allow%20%E2%80%93%20AWS%20WAF%20allows%20the%20request%20to%20be%20forwarded%20to%20the%20protected%20AWS%20resource%20for%20processing%20and%20response.%20This%20is%20a%20terminating%20action.%20In%20rules%20that%20you%20define%2C%20you%20can%20insert%20custom%20headers%20into%20the%20request%20before%20forwarding%20it%20to%20the%20protected%20resource.","timestamp":"1692445380.0","poster":"vn_thanhtung","comment_id":"985159","upvote_count":"1"}]},{"upvote_count":"1","content":"Selected Answer: D\nI agree it's D\nhttps://aws.amazon.com/about-aws/whats-new/2021/03/aws-waf-adds-support-request-header-insertion/","comment_id":"885026","poster":"dev112233xx","timestamp":"1682844060.0"},{"content":"Selected Answer: C\nSet the custom header on CloudFront","timestamp":"1682335080.0","comment_id":"879256","upvote_count":"3","poster":"vietbui"},{"timestamp":"1677992640.0","upvote_count":"1","poster":"andras","comment_id":"829641","content":"Selected Answer: D\nAWS Shield, a DDoS protection service, is enabled by default on Amazon CloudFront and automatically protects against Network/Transport layer DDoS attacks. The automatic protection feature by AWS Shield Standard is available to all AWS customers at no additional cost. Customers can also use AWS WAF (Web Application Firewall) to protect against application layer DDoS attacks.\nThe difference between them is that AWS WAF (Web Application Firewall) provides protection on the application layer and AWS Shield protects the infrastructure layers of the OSI model."},{"upvote_count":"2","content":"Option D is incorrect because it mentions configuring AWS WAF to add a custom header to the requests, but it is the CloudFront distribution that should add the custom header to the requests that are sent to the ALB, not AWS WAF. The custom header is used to identify requests that originated from CloudFront and allow them to pass through the ALB, while blocking requests that do not include the custom header. Option C is the correct answer, as it mentions configuring CloudFront to add a custom header to the requests and configuring advanced routing on the ALB to only forward requests that include the custom header that is set by CloudFront.","poster":"davidy2020","timestamp":"1676299020.0","comment_id":"807489"},{"timestamp":"1675878000.0","comment_id":"802322","comments":[{"content":"Let me correct myself ,forget about C , both WAF and Cloudfront can add custom headers and in this case D is best see this new feature as of 2021 : https://aws.amazon.com/about-aws/whats-new/2021/03/aws-waf-adds-support-request-header-insertion/ \n\nBy associating an AWS WAF web ACL with the CloudFront distribution, the company can protect against common attack techniques, including cross-site scripting and volumetric denial-of-service attacks. Additionally, by configuring AWS WAF to add a custom header to the requests sent to the ALB, the company can add an extra layer of security. The ALB can be configured to only forward requests that include the custom header, which ensures that only legitimate traffic is passed through.","comment_id":"802387","timestamp":"1675880700.0","upvote_count":"2","poster":"coolt2"}],"upvote_count":"1","poster":"coolt2","content":"C makes more logic ref : https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/restrict-access-to-load-balancer.html"},{"upvote_count":"1","content":"Selected Answer: C\ni go for C as there is a contradiction with D no?","timestamp":"1674998940.0","poster":"zozza2023","comment_id":"791663"},{"comment_id":"779816","upvote_count":"1","content":"Selected Answer: C\nI believe in C over D\n\nD kind of contradicts itself, it says that WAF adds the custom header and then mentions the header set by CloudFront?","poster":"ccort","timestamp":"1674034560.0"},{"timestamp":"1671102360.0","comment_id":"745976","poster":"Kende","content":"D: We need WAF too.","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: D\nI thinks is D, because we need to have DDoS protection with WAF (https://aws.amazon.com/premiumsupport/knowledge-center/waf-mitigate-ddos-attacks/)\nSolutions under C, do not provide DDoS protection.","poster":"Spavanko","comment_id":"732776","timestamp":"1669909080.0"},{"timestamp":"1669813140.0","comment_id":"731487","content":"Selected Answer: C\nI go with C:\nhttps://blogs.halodoc.io/implementation-of-custom-header-to-origin-requests/\nhttps://jayendrapatil.com/aws-cloudfront-security/","poster":"masetromain","upvote_count":"3"}],"question_text":"A company has deployed its corporate website in a VPC on two Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances are deployed in private subnets. The ALB is in a public subnet. A route to an internet gateway exists in the public subnet route table. The company has deployed an Amazon CloudFront distribution with the ALB as the origin.\n\nThe company's security team recently identified that malicious traffic is accessing the ALB directly. The company must deploy security controls to prevent common attack techniques, including cross-site scripting, and to protect against volumetric denials of service.\n\nWhich strategy should a solutions architect recommend to meet these requirements?","timestamp":"2022-11-30 13:59:00","url":"https://www.examtopics.com/discussions/amazon/view/89387-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"question_id":982,"topic":"1","question_images":[]},{"id":"hKyIgLeKzSFFMntu9p6E","exam_id":32,"unix_timestamp":1669813800,"topic":"1","answer_description":"","answer":"B","question_images":[],"question_text":"A company has millions of objects in an Amazon S3 bucket. The objects are in the S3 Standard storage class. All the S3 objects are accessed frequently. The number of users and applications that access the objects is increasing rapidly. The objects are encrypted with server-side encryption with AWS KMS keys (SSE-KMS).\n\nA solutions architect reviews the company's monthly AWS invoice and notices that AWS KMS costs are increasing because of the high number of requests from Amazon S3. The solutions architect needs to optimize costs with minimal changes to the application.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"A":"Create a new S3 bucket that has server-side encryption with customer-provided keys (SSE-C) as the encryption type. Copy the existing objects to the new S3 bucket. Specify SSE-C.","D":"Use the S3 Intelligent-Tiering storage class for the S3 bucket. Create an S3 Intelligent-Tiering archive configuration to transition objects that are not accessed for 90 days to S3 Glacier Deep Archive.","C":"Use AWS CloudHSM to store the encryption keys. Create a new S3 bucket. Use S3 Batch Operations to copy the existing objects to the new S3 bucket. Encrypt the objects by using the keys from CloudHSM.","B":"Create a new S3 bucket that has server-side encryption with Amazon S3 managed keys (SSE-S3) as the encryption type. Use S3 Batch Operations to copy the existing objects to the new S3 bucket. Specify SSE-S3."},"question_id":983,"url":"https://www.examtopics.com/discussions/amazon/view/89388-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"upvote_count":"7","comment_id":"731494","poster":"masetromain","content":"Selected Answer: B\nI go with B :\nTo reduce the volume of Amazon S3 calls to AWS KMS, use Amazon S3 bucket keys, which are protected encryption keys that are reused for a limited time in Amazon S3. Bucket keys can reduce costs for AWS KMS requests by up to 99%. You can configure a bucket key for all objects in an Amazon S3 bucket, or for a specific object in an Amazon S3 bucket.\nhttps://docs.aws.amazon.com/fr_fr/kms/latest/developerguide/services-s3.html","timestamp":"1669813800.0"},{"content":"Correct B.","upvote_count":"2","poster":"ggrodskiy","comment_id":"949179","timestamp":"1689095280.0"},{"comment_id":"934710","content":"Selected Answer: B\nA) is viable but more overhead\nB ) native SS3 -S3 encript sounds good less overhead. and use batch operations for all objets encript \nC) why Cloud HSM? more overhead\nD) not is need S3 Intelligent Tiering and glacier for KMS Cost","upvote_count":"1","poster":"SkyZeroZx","timestamp":"1687803420.0"},{"poster":"zozza2023","timestamp":"1674999960.0","upvote_count":"1","content":"Selected Answer: B\nshould be B (chatgpt give me D witch don't relate to the issue I think)","comment_id":"791680"}],"answers_community":["B (100%)"],"isMC":true,"timestamp":"2022-11-30 14:10:00","answer_ET":"B","answer_images":[]},{"id":"rXID4stnT276W2VQ6Nes","choices":{"B":"Turn on AWS CloudTrail logging for the AWS account. Use AWS Identity and Access Management Access Analyzer to generate IAM access policies based on the activity recorded in the CloudTrail log. Review the generated policies to ensure that they meet the company's business requirements.","C":"Turn on AWS CloudTrail logging for the AWS account. Create a script to parse the CloudTrail log, search for AWS API calls by Lambda execution role, and create a summary report. Review the report. Create IAM access policies that provide more restrictive permissions for each Lambda function.","A":"Set up Amazon CodeGuru to profile the Lambda functions and search for AWS API calls. Create an inventory of the required API calls and resources for each Lambda function. Create new IAM access policies for each Lambda function. Review the new policies to ensure that they meet the company's business requirements.","D":"Turn on AWS CloudTrail logging for the AWS account. Export the CloudTrail logs to Amazon S3. Use Amazon EMR to process the CloudTrail logs in Amazon S3 and produce a report of API calls and resources used by each execution role. Create a new IAM access policy for each role. Export the generated roles to an S3 bucket. Review the generated policies to ensure that they meet the company's business requirements."},"topic":"1","question_images":[],"isMC":true,"answer_description":"","answer_images":[],"unix_timestamp":1669819080,"exam_id":32,"discussion":[{"upvote_count":"1","comment_id":"1133938","content":"Selected Answer: B\nhttps://aws.amazon.com/about-aws/whats-new/2022/10/iam-access-analyzer-cloudtrail-history-identify-actions-140-aws-services-fine-grained-policies/#:~:text=When%20developers%20request%20a%20policy,CloudFormation%20permissions%20to%20create%20resources.","timestamp":"1706431440.0","poster":"Ezes"},{"upvote_count":"2","timestamp":"1689095640.0","comment_id":"949189","poster":"ggrodskiy","content":"correct B"},{"timestamp":"1673271900.0","upvote_count":"3","content":"Selected Answer: B\nYou will need to use access analyzer.","poster":"syaldram","comment_id":"770463"},{"comment_id":"745965","timestamp":"1671101760.0","poster":"Kende","upvote_count":"3","content":"B is less effort than C."},{"timestamp":"1669819080.0","comment_id":"731605","poster":"masetromain","content":"I have a doubt I will answer B but C seems possible.\n\nIAM Access Analyzer helps you identify the resources in your organization and accounts, such as Amazon S3 buckets or IAM roles, shared with an external entity. This lets you identify unintended access to your resources and data, which is a security risk. IAM Access Analyzer identifies resources shared with external principals by using logic-based reasoning to analyze the resource-based policies in your AWS environment.\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html","upvote_count":"2"}],"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/89409-exam-aws-certified-solutions-architect-professional-topic-1/","question_text":"An external audit of a company's serverless application reveals IAM policies that grant too many permissions. These policies are attached to the company's AWS Lambda execution roles. Hundreds of the company's Lambda functions have broad access permissions, such as full access to Amazon S3 buckets and Amazon DynamoDB tables. The company wants each function to have only the minimum permissions that the function needs to complete its task.\n\nA solutions architect must determine which permissions each Lambda function needs.\n\nWhat should the solutions architect do to meet this requirement with the LEAST amount of effort?","answer_ET":"B","question_id":984,"answer":"B","timestamp":"2022-11-30 15:38:00"},{"id":"4ZF7jYcb8Si9CgWojN2n","url":"https://www.examtopics.com/discussions/amazon/view/89410-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["D (100%)"],"answer_ET":"D","question_id":985,"answer_images":[],"discussion":[{"timestamp":"1669824480.0","poster":"masetromain","content":"Selected Answer: D\nI go with D:\nYou can share non-default subnets with other accounts within your organization. To share subnets, you must first create a Resource Share with the subnets to be shared and the AWS accounts, organizational units, or an entire organization that you want to share the subnets with.\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-sharing.html","comment_id":"731617","upvote_count":"9"},{"content":"correct D","upvote_count":"1","poster":"ggrodskiy","comment_id":"949193","timestamp":"1689095820.0"},{"upvote_count":"1","content":"Selected Answer: D\nI go with D:\nYou can share non-default subnets with other accounts within your organization. To share subnets, you must first create a Resource Share with the subnets to be shared and the AWS accounts, organizational units, or an entire organization that you want to share the subnets with.\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-sharing.html","comment_id":"934703","poster":"SkyZeroZx","timestamp":"1687802820.0"}],"isMC":true,"exam_id":32,"question_text":"A company uses AWS Organizations. The company creates a central VPC in an AWS account that is designated for networking in a single AWS Region. The central VPC has an AWS Site-to-Site VPN connection to the company's on-premises network. A solutions architect must create another AWS account that uses the same networking resources that the central VPC uses.\n\nWhich solution meets these requirements MOST cost-effectively?","answer_description":"","question_images":[],"choices":{"B":"Use AWS Resource Access Manager to share the VPN connection in the central VPC with the new AWS account.","A":"Create a VPC in the new AWS account. Create a new Site-to-Site VPN connection for the on-premises connection.","C":"Create a VPC in the new AWS account. Configure a virtual private gateway to connect to the central VPC.","D":"Use AWS Resource Access Manager to share the subnets in the central VPC with the new AWS account."},"timestamp":"2022-11-30 15:46:00","answer":"D","topic":"1","unix_timestamp":1669819560}],"exam":{"id":32,"name":"AWS Certified Solutions Architect - Professional","isMCOnly":false,"provider":"Amazon","lastUpdated":"11 Apr 2025","isBeta":false,"isImplemented":true,"numberOfQuestions":1019},"currentPage":197},"__N_SSP":true}