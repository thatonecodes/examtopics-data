{"pageProps":{"questions":[{"id":"uJGQDnkPB4DpqXMtN02e","question_id":471,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/5140-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"topic":"1","answer_description":"","answer":"AD","discussion":[{"comments":[{"upvote_count":"2","content":"How below requirement satisfy by option D.\n Implementing a detailed chargeback mechanism to ensure that each company pays for the resources it uses.","comments":[{"timestamp":"1632814800.0","poster":"chaudh","comments":[{"poster":"petebear55","timestamp":"1634582040.0","upvote_count":"1","content":"u mean a and e :)","comment_id":"246410"}],"comment_id":"14831","upvote_count":"3","content":"My understanding: Consolidated Billing will show the bills for all member accounts, tags should used for AWS resources, not account. A & D are my choices."}],"timestamp":"1632647700.0","poster":"leeo","comment_id":"14219"},{"timestamp":"1634870640.0","comment_id":"279261","content":"You are ignoring the first requirement here and everybody is upvoting without checking ....\nYou have chosen D over E but E has what D offers as consolidated billing is active by default when using a multi-account strategy. What is missing is a tagging solution for chargeback mechanism, like \"Activate propagation of necessary cost allocation tags to consolidated billing\" which is provided in E.\nBased on that, A and E are the correct answers.\nRef: https://aws.amazon.com/blogs/architecture/handling-aws-chargebacks-for-enterprise-customers/","poster":"shammous","upvote_count":"8","comments":[{"upvote_count":"5","poster":"student2020","comments":[{"content":"I agree. Tagging is only required for a single account strategy, not a multi-account strategy.","comment_id":"444646","timestamp":"1635954720.0","upvote_count":"3","poster":"Viper57"}],"timestamp":"1635685260.0","comment_id":"413125","content":"A and D are correct. There is no need for tagging. Each AWS account is separate and there is no connection between the VPCs. The AWS bill will just show the charge for each account."}]}],"content":"AD\nB: VPC is not enough, you need a separate account for each company.\nC: IAM is per account based and hence does not satisfy “a single identity store”.\nE: Consolidated billing is the correct answer for this part.","poster":"donathon","comment_id":"11738","timestamp":"1632288480.0","upvote_count":"43"},{"poster":"Moon","content":"I do support \"A & D\".\nseparate accounts, and single identity store.","timestamp":"1632437880.0","upvote_count":"13","comment_id":"13452"},{"content":"\"AnyCompany can pay for AWS services for all its companies through a single invoice\" this is the key, if you don't use consolidating billing like B and E, each account per company will end with their separate invoice with billing no matter what tag they use. So A is right;\n\"A single identity store is used to authenticate Developers across all companies\" indicates D is right, \nSo A, D is the answer.","poster":"Jesuisleon","comment_id":"919501","timestamp":"1686332220.0","upvote_count":"1"},{"poster":"Dionenonly","timestamp":"1663384200.0","comment_id":"671219","content":"Selected Answer: AD\nAD self explanatory","upvote_count":"1"},{"comment_id":"577982","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1677516300.0","content":"how do you satisfy this \"A single identity store is used to authenticate Developers across all companies.\"","comment_id":"823962","poster":"Amac1979"}],"content":"Having extensively reviewed the question. A and B are the correct answer, I shifted my position from A and D.\nHow so? Follow me \n\n1. Create a multi-account strategy with a virtual private cloud (VPC) for each company- This is a multi-account strategy , Different account, with associated VPCs\nIt meets the requirement of “The CIO of AnyCompany wishes to maintain a separation of resources for each acquired”\n\n2. \nReduce impact across companies by not creating any VPC peering links- This requirement of separating resources is met by not peering VPCs\n\n3. As everything is in a single account- As this is one organisation, it’s best practice to implement AWS organisation for consolidated billing, so assume was organisation is implemented here.\n\n\n4. Use tagging to create a detailed bill for each company. Tagging with help create detailed bill for each company. The key word is detailed. AWS Control tower will give you the bill per company, but you will still need tagging to ensure the cost are detailed for each company.","timestamp":"1648611120.0","poster":"bfal"},{"upvote_count":"1","comment_id":"504606","timestamp":"1639883820.0","poster":"vbal","content":"D&E is perfect."},{"comment_id":"496735","timestamp":"1638960120.0","upvote_count":"1","poster":"cldy","content":"A. Create a multi-account strategy with an account per company. Use consolidated billing to ensure that AnyCompany needs to pay a single bill only.\nD. Create a federated identity store against the companyג€™s Active Directory. Create IAM roles with appropriate permissions and set the trust relationships with AWS and the identity store. Use AWS STS to grant users access based on the groups they belong to in the identity store."},{"timestamp":"1638732240.0","poster":"AzureDP900","content":"AD is perfect answer","upvote_count":"2","comment_id":"494589"},{"comment_id":"447997","upvote_count":"1","content":"AD is correct","poster":"moon2351","timestamp":"1635973440.0"},{"content":"AAA DDD\n---","upvote_count":"1","timestamp":"1635896520.0","comment_id":"435728","poster":"tgv"},{"poster":"zolthar_z","upvote_count":"1","content":"One is D. I have the doubt between A and E, even E has the best practice option (use tags) missed the requirement of set-up a single invoice. So, It's A & E","comment_id":"428594","timestamp":"1635855720.0"},{"comment_id":"410491","timestamp":"1635661020.0","poster":"WhyIronMan","upvote_count":"2","content":"I'll go with A,D"},{"content":"it's AD","comment_id":"346140","upvote_count":"3","timestamp":"1635602880.0","poster":"Waiweng"},{"timestamp":"1635495420.0","poster":"digimaniac","comment_id":"345234","content":"E is redundant, in OU and consolidate billing, we already know the detailed billing of sub companies.","upvote_count":"1"},{"upvote_count":"7","timestamp":"1635203040.0","poster":"trap","content":"Correct Answer:D,E\nConsolidated billing is enabled by default in AWS Organizations (multi-account strategy need AWS Organization)\n\n\nhttps://aws.amazon.com/organizations/faqs/\n\nQ: Which central governance and management capabilities does AWS Organizations enable?\nAWS Organizations enables the following capabilities:\n\nAutomate AWS account creation and management, and provision resources with AWS CloudFormation Stacksets\nMaintain a secure environment with policies and management of AWS security services\nGovern access to AWS services, resources, and regions\nCentrally manage policies across multiple AWS accounts\nAudit your environment for compliance \nView and manage costs with consolidated billing \nConfigure AWS services across multiple accounts","comment_id":"320386"},{"upvote_count":"6","timestamp":"1635200700.0","comment_id":"294156","poster":"kiev","content":"I got DE but reading this forum many people went with AD but surely tagging is a better way of separating resources?"},{"content":"I will go with D,E trust relationship+STS and Tags. E is more convincing to me than A","timestamp":"1635160740.0","upvote_count":"4","comment_id":"291378","poster":"Kian1"},{"comment_id":"286764","poster":"Ebi","upvote_count":"2","timestamp":"1634875500.0","content":"Ad my choice"},{"poster":"Bulti","upvote_count":"1","comment_id":"257245","timestamp":"1634859120.0","content":"Very tricky question. It not clear if the multi account strategy is using AWS organization to create a management and member accounts . If not then consolidated billing is not possible. Should we assume that's the case. If so then A and D is correct. Else D and E is correct."},{"poster":"Britts","timestamp":"1634836680.0","content":"Will go with D & E. Multi account strategy implies at least consolidated billing (if not all features). E in addition provides tagging","comment_id":"251484","upvote_count":"3"},{"timestamp":"1634771340.0","comment_id":"246433","poster":"petebear55","upvote_count":"1","comments":[{"comment_id":"333513","poster":"sarah_t","timestamp":"1635237180.0","content":"A does not meet the chargeback requirements. E does. \nConsolidated billing is enabled for all organizations anyway (you couldn't disable it anyway).","upvote_count":"1"}],"content":"Weve all agreed on A .. But i Believe its E given these two statements from the question ... indeed TAGGING would follow best practice from latest AWS guidelines and also reiterate the answers from previous similar questions!! ✑ 1) Implementing a detailed chargeback mechanism to ensure that each company pays for the resources it uses.\n\n\n✑ Developers in an acquired company should not be able to affect resources in their company only.\nthus a and e .. but again i think the question is written very badly ... sadly this does come up on the exam :("},{"poster":"rcher","comment_id":"243337","upvote_count":"2","content":"Is it just me?\n\nThis sentence below sound like bad phrasing that try to trick us. \nWho is their? The developers are the parent company?\n\n✑ Developers in an acquired company should not be able to affect resources in their company only","timestamp":"1634565480.0"},{"comment_id":"243026","poster":"T14102020","timestamp":"1634450100.0","upvote_count":"1","content":"AD is correct. STS and consolidated billing"},{"content":"A & D is correct","upvote_count":"1","comment_id":"236193","timestamp":"1634434320.0","poster":"Bulti"},{"timestamp":"1634284920.0","content":"I'll go with A,D","comment_id":"230751","upvote_count":"2","poster":"jackdryan"},{"comment_id":"230044","timestamp":"1634198700.0","poster":"gookseang","content":"seems AD","upvote_count":"1"},{"comment_id":"196565","upvote_count":"1","timestamp":"1634181660.0","content":"A and D for the win.","poster":"Paitan"},{"upvote_count":"1","poster":"Ganfeng","comment_id":"175431","content":"A/D for me","timestamp":"1634067600.0"},{"timestamp":"1633993320.0","upvote_count":"2","poster":"fullaws","comment_id":"150383","content":"A and D"},{"upvote_count":"2","comment_id":"133050","content":"AD for sure","poster":"NikkyDicky","timestamp":"1633957860.0"},{"poster":"mat2020","upvote_count":"2","timestamp":"1633946640.0","content":"Answer : A,D","comment_id":"132564"},{"timestamp":"1633765500.0","content":"There is a typo in the question\n✑ Developers in an acquired company should be able to affect resources in their company only.","upvote_count":"1","poster":"oatif","comment_id":"130175"},{"content":"It's A,D for me.","poster":"easytoo","upvote_count":"2","comment_id":"127314","timestamp":"1633756920.0"},{"comment_id":"94821","poster":"FreeSwan","content":"A,D are correct.","timestamp":"1633541340.0","upvote_count":"1"},{"content":"The key is \"Developers in an acquired company should not be able to affect resources in their company only.\" We should take int o account developers may create resources on other accounts. BD is more plausible.","upvote_count":"1","timestamp":"1633305120.0","poster":"[Removed]","comments":[{"comment_id":"93464","timestamp":"1633508820.0","comments":[{"content":"me too E would follow best practice","poster":"petebear55","comment_id":"246412","timestamp":"1634596620.0","upvote_count":"1"}],"content":"Two contradictory statements are there - \n✑ Developers in each acquired company have access to resources in their company only.\n✑ Developers in an acquired company should not be able to affect resources in their company only.\nI think AE is correct","poster":"VrushaliD","upvote_count":"2"}],"comment_id":"88246"},{"timestamp":"1633281000.0","comment_id":"83120","poster":"jgtran","upvote_count":"1","content":"The Solutions Architect is tasked with designing an AWS architecture that allows AnyCompany to achieve the following:\n✑ Implementing a detailed chargeback mechanism to ensure that each company pays for the resources it uses. -> E. However, from Organization billing dashboard, you should be able to see how much each account is consuming. You can charges back each companies if they all have their own account.\n✑ AnyCompany can pay for AWS services for all its companies through a single invoice. ->A\n✑ Developers in each acquired company have access to resources in their company only. ->D\n✑ Developers in an acquired company should not be able to affect resources in their company only. -> D\n✑ A single identity store is used to authenticate Developers across all companies. -> D\n\nI choose A&D"},{"comments":[{"content":"yes i think e too","comment_id":"246411","timestamp":"1634583660.0","upvote_count":"1","poster":"petebear55"}],"content":"why not E instead of D? the line below will need E (unless the \"not\" in it is a typo) : \"Developers in an acquired company should not be able to affect resources in their company only.\"","comment_id":"61690","upvote_count":"2","poster":"youq","timestamp":"1633071420.0"},{"comment_id":"56230","timestamp":"1633043640.0","upvote_count":"3","content":"Consolidated billing with a payer account will take care of the one invoice requirement ( https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html ) while we're still able to establish a chargeback mechanism as each member in consolidated billing passes his billing information to the payer, so payer sees exactly what each account generates in terms of costs and will be able to charge back. Central identity federation from our AD guarantees that we manage permissions in one place (single identity store). Only A & D are sufficient enough.","poster":"MrP"},{"upvote_count":"2","poster":"amog","content":"Should be A,D","comment_id":"51253","timestamp":"1633004760.0"},{"comment_id":"44435","poster":"dumma","content":"A and D are correct","upvote_count":"3","timestamp":"1633000920.0"},{"upvote_count":"3","content":"A,D Wins clearly","timestamp":"1632910920.0","comment_id":"32587","poster":"cinopi"},{"comment_id":"25953","content":"ad is correct answer","poster":"examacc","timestamp":"1632862920.0","upvote_count":"4"},{"timestamp":"1632817380.0","content":"I also think A&D are correct answers, but does consolidated billing meet chargeback mechanism requirement?","poster":"huhupai","comment_id":"17579","upvote_count":"3"},{"poster":"awsec2","content":"a,d is my view","timestamp":"1632372060.0","upvote_count":"5","comment_id":"12276"},{"upvote_count":"1","poster":"Xiaoyao2000","timestamp":"1632187560.0","comment_id":"11486","content":"why not a d?"},{"upvote_count":"2","comment_id":"10987","timestamp":"1632157380.0","content":"c, e could be","poster":"awsec2"}],"timestamp":"2019-09-13 13:04:00","question_text":"AnyCompany has acquired numerous companies over the past few years. The CIO for AnyCompany would like to keep the resources for each acquired company separate. The CIO also would like to enforce a chargeback model where each company pays for the AWS services it uses.\nThe Solutions Architect is tasked with designing an AWS architecture that allows AnyCompany to achieve the following:\n✑ Implementing a detailed chargeback mechanism to ensure that each company pays for the resources it uses.\n✑ AnyCompany can pay for AWS services for all its companies through a single invoice.\n✑ Developers in each acquired company have access to resources in their company only.\n✑ Developers in an acquired company should not be able to affect resources in their company only.\n✑ A single identity store is used to authenticate Developers across all companies.\nWhich of the following approaches would meet these requirements? (Choose two.)","choices":{"B":"Create a multi-account strategy with a virtual private cloud (VPC) for each company. Reduce impact across companies by not creating any VPC peering links. As everything is in a single account, there will be a single invoice. Use tagging to create a detailed bill for each company.","C":"Create IAM users for each Developer in the account to which they require access. Create policies that allow the users access to all resources in that account. Attach the policies to the IAM user.","D":"Create a federated identity store against the company's Active Directory. Create IAM roles with appropriate permissions and set the trust relationships with AWS and the identity store. Use AWS STS to grant users access based on the groups they belong to in the identity store.","E":"Create a multi-account strategy with an account per company. For billing purposes, use a tagging solution that uses a tag to identify the company that creates each resource.","A":"Create a multi-account strategy with an account per company. Use consolidated billing to ensure that AnyCompany needs to pay a single bill only."},"question_images":[],"answer_ET":"AD","answers_community":["AD (100%)"],"exam_id":32,"unix_timestamp":1568372640},{"id":"l4qGI7RSJGJvQmw2xrnp","answers_community":["CE (100%)"],"answer_ET":"CE","topic":"1","choices":{"B":"Use weighted routing and configure each record set with a weight of 50. Configure an HTTP health check for each region, and attach it to the record set for that region.","C":"Use latency-based routing for both record sets. Configure a health check for each region and attach it to the record set for that region.","D":"Configure an Amazon CloudWatch alarm for the health checks in us-east-1, and have it invoke an AWS Lambda function that promotes the read replica in eu- west-1.","A":"Use failover routing and configure the us-east-1 record set as primary and the eu-west-1 record set as secondary. Configure an HTTP health check for the web application in us-east-1, and associate it to the us-east-1 record set.","E":"Configure Amazon RDS event notifications to react to the failure of the database in us-east-1 by invoking an AWS Lambda function that promotes the read replica in eu-west-1."},"question_id":472,"question_text":"A company deployed a three-tier web application in two regions: us-east-1 and eu-west-1. The application must be active in both regions at the same time. The database tier of the application uses a single Amazon RDS Aurora database globally, with a master in us-east-1 and a read replica in eu-west-1. Both regions are connected by a VPN.\nThe company wants to ensure that the application remains available even in the event of a region-level failure of all of the application's components. It is acceptable for the application to be in read-only mode for up to 1 hour. The company plans to configure two Amazon Route 53 record sets, one for each of the regions.\nHow should the company complete the configuration to meet its requirements while providing the lowest latency for the application end-users? (Choose two.)","answer_images":[],"exam_id":32,"answer":"CE","answer_description":"","timestamp":"2019-09-16 12:20:00","url":"https://www.examtopics.com/discussions/amazon/view/5230-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"unix_timestamp":1568629200,"discussion":[{"content":"I would go for C, E.","comment_id":"11256","upvote_count":"26","poster":"huhupai","comments":[{"content":"With E, failover execute only when DB failed. What if just application fail but DB not ?","comments":[{"timestamp":"1639242960.0","poster":"rb39","content":"then C will take care of using web servers in the other region.","upvote_count":"2","comment_id":"499553","comments":[{"upvote_count":"1","poster":"SureNot","content":"if applications health check satus code depends on DB connection status...","timestamp":"1670415240.0","comment_id":"737833"}]}],"poster":"aws_arn_name","upvote_count":"3","timestamp":"1635440280.0","comment_id":"349257"},{"comment_id":"358291","upvote_count":"11","timestamp":"1635604200.0","content":"Ans is CD.\nFor E: RDS event does not support regional failure events. RDS event can only send to SNS.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.Messages.html\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.Subscribing.html","poster":"LCC92"},{"comment_id":"990613","content":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.overview.html#:~:text=in%20the%20filter.-,Basic%20process%20for%20subscribing%20to%20Amazon%20RDS%20event%20notifications,-The%20process%20for","poster":"vn_thanhtung","upvote_count":"1","timestamp":"1693042200.0"}],"timestamp":"1632133320.0"},{"upvote_count":"24","comment_id":"11739","timestamp":"1632149460.0","content":"CD.\nA\\B: This would not be based on latency.\nE: Amazon RDS uses the Amazon Simple Notification Service (Amazon SNS) to provide notification when an Amazon RDS event occurs. These notifications can be in any notification form supported by Amazon SNS for an AWS Region, such as an email, a text message, or a call to an HTTP endpoint. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html","comments":[{"comment_id":"11847","timestamp":"1632150300.0","content":"Yep CD. E only send notification, can't invoke lambda","comments":[{"content":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/monitoring-health-checks.html you can use SNS and lambda on the SNS topic","poster":"Warrenn","timestamp":"1632382080.0","comments":[{"upvote_count":"1","poster":"joanneli77","timestamp":"1665585000.0","content":"...then the answer should say to use RDS to send to SNS to invoke Lambda. RDS can't directly invoke lambda as-written.","comment_id":"693166"}],"comment_id":"19408","upvote_count":"3"}],"poster":"dpvnme","upvote_count":"8"},{"upvote_count":"5","content":"I will go for C, E.\n\nD: Configure an Amazon CloudWatch alarm for the health checks in us-east-1, and have it invoke an AWS Lambda function that promotes the read replica in eu- west-1.\n\nHow a alarm configured in \n\nHow can a alarm configured in one region invoking function in another region in case of the region itself is in a failure state?","comment_id":"29579","timestamp":"1632403800.0","comments":[{"poster":"cinopi","comment_id":"32588","upvote_count":"1","content":"I am also with C,E\n\nI can see few RDS events regarding failure, which I don't see in CloudWAtch\n\nExample:\nfailure\n\nRDS-EVENT-0031\nThe DB instance has failed due to an incompatible configuration or an underlying storage issue. Begin a point-in-time-restore for the DB instance.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html","timestamp":"1632471480.0"},{"timestamp":"1635726180.0","comments":[{"comments":[{"poster":"kirrim","comment_id":"459638","timestamp":"1636230540.0","content":"RDS events also have to use SNS to trigger Lambda:\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/services-rds.html\n\n\"Amazon RDS sends notifications to an Amazon Simple Notification Service (Amazon SNS) topic, which you can configure to invoke a Lambda function. Amazon SNS wraps the message from Amazon RDS in its own event document and sends it to your function.\"","upvote_count":"1"}],"poster":"Kopa","comment_id":"430639","upvote_count":"2","content":"For me its C,E. D need SNS to trigger Lambda. Answer E AWS RDS events trigger Lambda directly.","timestamp":"1636214520.0"}],"upvote_count":"1","poster":"Kopa","comment_id":"396622","content":"Using Amazon CloudWatch alarms, you can set up metric thresholds and send alerts to Amazon Simple Notification Service (SNS). SNS can send notifications using e-mail, HTTP(S) endpoints, and Short Message Service (SMS) messages to mobile phones, and it can even trigger a Lambda function. \n\nhttps://aws.amazon.com/blogs/developer/send-real-time-amazon-cloudwatch-alarm-notifications-to-amazon-chime/"},{"poster":"b3llman","comment_id":"183648","content":"You can configure Route53 to trigger alarms and send notifications to SNS when health checks report unhealthy and have SNS to trigger a Lambda function to do stuff. So, D definitely works.","timestamp":"1633759380.0","upvote_count":"3","comments":[{"comment_id":"243342","timestamp":"1634426880.0","poster":"rcher","upvote_count":"2","comments":[{"timestamp":"1635023700.0","upvote_count":"1","content":"@rcher\nThat's for a great point.\nWas so confused on why D is not right even if E is correct.","comment_id":"296189","poster":"gpark"}],"content":"Well the key is, Cloudwatch Alarm is invoking Lambda directly (based on Ans D and i think its not supported now), so i think it doesn't work?"}]},{"timestamp":"1635806760.0","poster":"TiredDad","upvote_count":"1","comment_id":"415383","content":"https://aws.amazon.com/blogs/mt/customize-amazon-cloudwatch-alarm-notifications-to-your-local-time-zone-part-1/"},{"content":"E defeats the purpose of cross-region failover. \nIf the region is down then there will not be any event triggered in that region.","poster":"sarah_t","upvote_count":"10","timestamp":"1635396300.0","comment_id":"333517"}],"poster":"tan9"}],"poster":"donathon"},{"comments":[{"comment_id":"990614","upvote_count":"1","timestamp":"1693042260.0","content":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.overview.html#:~:text=in%20the%20filter.-,Basic%20process%20for%20subscribing%20to%20Amazon%20RDS%20event%20notifications,-The%20process%20for","poster":"vn_thanhtung"}],"poster":"SkyZeroZx","comment_id":"930695","content":"Selected Answer: CE\nFor my correct is CE","upvote_count":"1","timestamp":"1687444920.0"},{"comment_id":"871858","poster":"romiao106","upvote_count":"1","content":"A is incorrect as it only considers health check for IAD. not the EU-west-1 region.\nFor A to work, it needs to set up failover routing, then configure health checks for both regions.","timestamp":"1681656600.0"},{"poster":"AYANtheGLADIATOR","comment_id":"656912","timestamp":"1662088680.0","content":"C D bcz rds event notification can't invoke the lambda if its down.","upvote_count":"1"},{"timestamp":"1651072380.0","upvote_count":"2","poster":"bobsmith2000","content":"Selected Answer: CE\nC for latency-based routing\nE. Amazon RDS event -> EventBridge -> Lambda","comment_id":"593259"},{"upvote_count":"5","comment_id":"544321","comments":[{"timestamp":"1648289280.0","comment_id":"575461","poster":"Burhan521","upvote_count":"1","content":"because what would happen if the EU region was down. The users in EU wouldnt be routed to US"}],"timestamp":"1644472380.0","poster":"jyrajan69","content":"Not sure why no one here is even considering A as an answer, when you can configure it as ACTIVE-ACTIVE (https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html) and given that we have an hour then E is the next part of the solution. So for me , it is definitely AE. There is nothing here that even talks about Latency"},{"content":"C,E. When there is any issue with the primary RDS, a RDS event about replication will occur and send a SNS. The health check for each region in R53 can include the health check of database, application and others in all.","comment_id":"516191","upvote_count":"1","timestamp":"1641261780.0","poster":"frankzeng"},{"comment_id":"494597","upvote_count":"1","poster":"AzureDP900","content":"CE is my answer","timestamp":"1638732780.0"},{"poster":"cldy","timestamp":"1638706620.0","comment_id":"494320","content":"C. Use latency-based routing for both record sets. Configure a health check for each region and attach it to the record set for that region.\nD. Configure an Amazon CloudWatch alarm for the health checks in us-east-1, and have it invoke an AWS Lambda function that promotes the read replica in eu- west-1.","upvote_count":"1"},{"content":"C and D for me.\nE does not cover the region failure or web/app tier failures.","upvote_count":"1","comment_id":"492452","poster":"wahlbergusa","timestamp":"1638447780.0"},{"content":"I will go for C and D. E does not cover other application component failure","comment_id":"469022","upvote_count":"2","poster":"nsei","timestamp":"1636286160.0"},{"content":"I suppose for D, it meant for the Route53 health check, i.e, \"Configure an Amazon CloudWatch alarm for the (Route53) health checks in us-east-1, and have it invoke an AWS Lambda function that promotes the read replica in eu-west-1. \". This makes more sense https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/monitoring-health-checks.html","timestamp":"1636232340.0","poster":"wannaaws","comment_id":"459865","upvote_count":"1"},{"comment_id":"427779","timestamp":"1636139160.0","poster":"kevin1024","upvote_count":"1","content":"It look likes B, C\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html"},{"upvote_count":"1","timestamp":"1636092480.0","comment_id":"425074","content":"C and E\n \nCreate Eventbridge Rule that triggers on RDS Aurora event.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-cloud-watch-events.html","poster":"Madhu654"},{"comment_id":"418180","poster":"DerekKey","content":"C&D correct\nUse latency-based routing for both record sets - \"The application must be active in both regions at the same time\" & \"while providing the lowest latency for the application end-users\"\nConfigure a health check for each region - \"the application remains available even in the event of a region-level failure\"\nIt is acceptable for the application to be in read-only mode for up to 1 hour - \"Configure an Amazon CloudWatch alarm for the health checks in us-east-1, and have it invoke an AWS Lambda function that promotes the read replica in eu-west-1.\"\nE wrong - RDS can only send event to SNS. Lambda must subscribe to that SNS to be invoked","timestamp":"1635876540.0","upvote_count":"3"},{"comment_id":"415477","content":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-cloud-watch-events.html","poster":"TiredDad","upvote_count":"1","timestamp":"1635847800.0"},{"upvote_count":"2","timestamp":"1635785760.0","poster":"WhyIronMan","comment_id":"410492","content":"I'll go with C,D"},{"upvote_count":"2","comment_id":"397692","timestamp":"1635763560.0","content":"Must be CD as RDS health check is regional and won’t respond to a regional failure as it will be down.","poster":"Pb55"},{"poster":"rsr20","comment_id":"392695","upvote_count":"3","timestamp":"1635715020.0","content":"A is ruled out because it doesnt support ACTIVE /ACTIVE as required in question"},{"poster":"zolthar_z","content":"The answer is C and E. D can be done but you need some services between cloudwatch alarm and lambda. RDS notification can trigger lambda direcly","comments":[{"content":"Read documentation properly. RDS Event Notifications also rely on SNS. https://docs.aws.amazon.com/lambda/latest/dg/services-rds.html","poster":"wahlbergusa","comment_id":"492455","timestamp":"1638447840.0","upvote_count":"1"}],"timestamp":"1635694920.0","comment_id":"371210","upvote_count":"1"},{"upvote_count":"1","poster":"vivektiwari","comment_id":"356522","timestamp":"1635574920.0","content":"C & E.\nD: CloudWatch Alarm cannot directly trigger the Lambda Function. It has to be through CloudWatch Event or SNS."},{"timestamp":"1635424560.0","upvote_count":"5","comment_id":"346148","poster":"Waiweng","content":"It's C,E"},{"content":"For those who are voting for D : \nCan a Cloudwatch Alarm trigger Lambda function directly ?\n\nAnswer seems to be C and E.","comment_id":"335603","timestamp":"1635421080.0","poster":"Amitv2706","upvote_count":"2"},{"timestamp":"1635400980.0","content":"E doesn't cover regional outage: if the region is down then a health check IN that region won't work.","upvote_count":"3","comment_id":"333519","poster":"sarah_t"},{"upvote_count":"2","poster":"Pupu86","comment_id":"317634","content":"I agree with C due to latency concerns but E has my doubts. After researching on the Aurora RDS notification events - https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html#USER_Events.Messages.\n\nThere isn’t a particular event ID relating to the failure of a database or failover of a database to a different region so I don’t see how I can correlate a regional health check using RDS event notification. I’m more inclined to choose D as my secondary option.","timestamp":"1635278340.0"},{"comment_id":"315536","upvote_count":"2","poster":"ItsmeP","content":"Ans is CE\n A/B will not work for DB write.","timestamp":"1635142800.0"},{"comment_id":"304611","content":"Should be CE. D will require SNS to trigger lamda: \nUsing Amazon CloudWatch alarms, you can set up metric thresholds and send alerts to Amazon Simple Notification Service (SNS). SNS can send notifications using e-mail, HTTP(S) endpoints, and Short Message Service (SMS) messages to mobile phones, and it can even trigger a Lambda function.","comments":[{"timestamp":"1635137040.0","comment_id":"313644","poster":"CKW","content":"SNS can invoke Lambda function: https://docs.aws.amazon.com/sns/latest/dg/sns-lambda-as-subscriber.html.","upvote_count":"2"}],"timestamp":"1635103440.0","poster":"awsnoob","upvote_count":"1"},{"timestamp":"1635034080.0","content":"For D to be correct,\nat least SNS would be needed between RDS and Lambda.","upvote_count":"1","comment_id":"296191","poster":"gpark"},{"content":"I will go with C,D for now, latency and cloudWatch as is designed for health check and failover. assuming E could possibly work too.","poster":"Kian1","comment_id":"291444","upvote_count":"1","timestamp":"1635018600.0"},{"upvote_count":"5","poster":"Ebi","timestamp":"1634959260.0","content":"My answer is CE","comment_id":"280297"},{"content":"A/B/C: I would go for C as we are looking for the lowest latency. I the event when one of the region is down, this will also work as a failover-mechanism. Option A would not work in the event of a region-level failure in eu-west-1. (Traffic will still be sent to it)\nD/E: I would go for E as it is recommended to use native events versus CW events if available, like in RDS and S3.","poster":"shammous","upvote_count":"1","timestamp":"1634959020.0","comment_id":"279284"},{"poster":"gookseang","timestamp":"1634844540.0","comment_id":"278198","upvote_count":"1","content":"I change My answer to C,E"},{"comment_id":"272177","content":"CE.\nD clearly mentioned us-east-1 (master) failure then invoke eu-west-1 (rr) promoted, but the question stated \"regional-level failure of all of the application's components\", which means CloudWatch / SNS / Lambda might fail too. So this put triggering Lambda (regional) in eu-west-1 and us-east-1 in question. \nTrigger Lambda from Aurora is possible:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Integrating.Lambda.html\nPeople could code on the event like this on read-replica to detect master failed:\nhttps://aws.amazon.com/blogs/database/failover-with-amazon-aurora-postgresql/","poster":"zanhsieh","timestamp":"1634840520.0","upvote_count":"2"},{"poster":"Bulti","comment_id":"257285","content":"The answer is C and D. Cloudwatch is a cross region and cross account service and can create an alarm on events received from another region in this case the one that is going down. The same is not true with RDS event as it can be sent to an SNS topic in the same region.","timestamp":"1634712240.0","upvote_count":"5"},{"timestamp":"1634657460.0","poster":"petebear55","content":"I will further go for E having seen this https://docs.aws.amazon.com/cli/latest/reference/rds/promote-read-replica.html","upvote_count":"1","comment_id":"246749"},{"poster":"petebear55","upvote_count":"1","comments":[{"content":"i mean c and e","timestamp":"1634689800.0","poster":"petebear55","upvote_count":"1","comment_id":"246750"}],"comment_id":"246741","content":"D AND E AFTER READING THIS ALTHOUGH D COULD BE RIGHT https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html","timestamp":"1634445180.0"},{"comment_id":"243395","poster":"T14102020","content":"Correct AE. failover for DNS and RDS event notifications","comments":[{"upvote_count":"2","timestamp":"1665346200.0","poster":"wassb","comment_id":"690517","content":"The application must be active in both regions at the same time"}],"timestamp":"1634431260.0","upvote_count":"1"},{"comment_id":"236208","poster":"Bulti","content":"A and D is the right answer. First of all Aurora ensure automatic failover only if read replicas are in the same region. In case of a Global Aurora DB, the failover to another region needs to be programmed or has to be manually performed. Although E is another option to enable automatic failover to another region, D is a better choice as CloudWatch alarms ensure that there is a false-positive as it requires a valid state change to trigger an event via an SNS topic. However with RDS event we would need to do this programmatically and will require more effort.","timestamp":"1634346000.0","upvote_count":"1"},{"poster":"jackdryan","comment_id":"230771","timestamp":"1634336760.0","upvote_count":"2","content":"I'll go with C,D"},{"upvote_count":"1","content":"seems CD","timestamp":"1634307000.0","comment_id":"230048","poster":"gookseang"},{"upvote_count":"1","timestamp":"1634177940.0","poster":"liono","content":"Guys ''The company wants to ensure that the application remains available even in the event of a region-level failure of all of the application's components''. They are not only asking for RDS specifically, so D fulfills the requirement instead of E","comment_id":"206989"},{"poster":"liono","timestamp":"1634048280.0","upvote_count":"2","content":"C & D\nhttps://aws.amazon.com/about-aws/whats-new/2019/11/amazon-cloudwatch-launches-cross-account-cross-region-dashboards/","comment_id":"206984"},{"content":"C, D\nCloudWatch Alarm is one of best health check.","comment_id":"206292","poster":"NNHAN","upvote_count":"1","timestamp":"1633996140.0"},{"upvote_count":"1","comment_id":"195351","timestamp":"1633989840.0","poster":"SanjeevB","content":"Nobody seems to have considered the scenario when EU region is down?"},{"upvote_count":"1","content":"Correction, C & E is for sure, which RDS metric can be use to determine rds failure....","timestamp":"1633694640.0","poster":"fullaws","comment_id":"150412"},{"content":"C and E, if the wording is cloudwatch event instead of alarm will be C and D","comment_id":"150404","upvote_count":"1","timestamp":"1633603860.0","poster":"fullaws"},{"content":"It clearly says the application can be in read-only mode for up to an hour (not sure what this app does). Not sure why do we even need to worry about promoting read replica to be the master using Lambda etc? It can be done manually! Point is to have the application available and be able to READ the data from READ Replica for an hour in case of regional level failure. I am looking at B and C as answers. Any thoughts or someone disagrees?","timestamp":"1633528500.0","upvote_count":"3","comment_id":"144098","poster":"IAmNotLambda"},{"content":"Guys its Cloudwatch alarm not event. We would need event to trigger lambda. Better to go with C,E. As RDS Aurora has the ability to send SNS event notification to invoke lambda.","timestamp":"1633483380.0","poster":"Anila_Dhharisi","upvote_count":"1","comment_id":"143195"},{"timestamp":"1633332000.0","poster":"NikkyDicky","comment_id":"133084","upvote_count":"4","content":"CE\nD is tricky. you could use CloudWatch event to trigger lambda, but not CloudWatch alarm"},{"content":"Answer C,E","poster":"mat2020","comment_id":"132563","timestamp":"1633329420.0","upvote_count":"1"},{"comments":[{"comment_id":"141026","poster":"IAmNotLambda","timestamp":"1633349700.0","content":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Integrating.Lambda.html\n\nAmazon RDS Aurora can invoke Lambda Function.","upvote_count":"1"},{"poster":"easytoo","upvote_count":"1","timestamp":"1633321560.0","content":"https://docs.aws.amazon.com/lambda/latest/dg/services-rds.html\n\nYou can use AWS Lambda to process event notifications from an Amazon Relational Database Service (Amazon RDS) database. Amazon RDS sends notifications to an Amazon Simple Notification Service (Amazon SNS) topic, which you can configure to invoke a Lambda function. Amazon SNS wraps the message from Amazon RDS in its own event document and sends it to your function.","comment_id":"127316"}],"poster":"Imy","upvote_count":"1","content":"looks like RDS events cannot trigger Lambda so it has to be C & D.","timestamp":"1633222860.0","comment_id":"121944"},{"upvote_count":"2","comment_id":"101536","timestamp":"1633180380.0","content":"C & E\nCloudWatch is a regional service and cannot invoke a Lambda in another region:\nhttps://stackoverflow.com/questions/44787306","poster":"[Removed]"},{"content":"I would fo for C and E\nI eliminated D because Cloudwatch is per region, and if the us-east-1 is down, than cloudwatch in us-east-1 can't do anything: \"Configure an Amazon CloudWatch alarm for the health checks in us-east-1\"","poster":"AShahine21","comment_id":"98655","upvote_count":"3","comments":[{"comments":[{"content":"Good point. That's why you don't rely on a regional service like RDS but a global service like Route53 to do that. Route53 health checks are flexible enough to allow monitoring on any endpoints, even RDS's. It can then trigger failover across regions.\n\nOne thing to be aware, option D does not involve CloudWatch explicitly. The alarm in that option refers to the alarm notification in Route53 health checks that will trigger when a health check reports unhealthy.","timestamp":"1633927080.0","poster":"b3llman","upvote_count":"2","comment_id":"183683"}],"content":"This is a key point that I don't think others have considered. If us-east-1 is truly and completely down (i.e., CloudWatch in us-east-1 is also down along with Amazon RDS), then you need us-west-1 to realize that on its own, and promote it's database. That can only be done by Amazon RDS event notifications from us-west-1, making E the correct answer and not D. Please upvote if you agree.","upvote_count":"8","poster":"LunchTime","comment_id":"122855","timestamp":"1633318680.0"}],"timestamp":"1633150200.0"},{"comment_id":"94827","timestamp":"1633045920.0","poster":"FreeSwan","content":"A,D are correct.","upvote_count":"2"},{"timestamp":"1632981420.0","upvote_count":"1","comment_id":"93371","content":"D is a general reaction to a health check failure....If the front end fails doer want to promote the other regions DB to master? Whereas E is specific to a DB Failure. Latency Based routing is obvious","poster":"Merlin1"},{"content":"CE: \nQ: Do my AWS Lambda functions need to be in the same region as my Amazon SNS usage?\nYou can subscribe your AWS Lambda functions to an Amazon SNS topic in any region.","timestamp":"1632933360.0","upvote_count":"1","poster":"tccusa","comment_id":"86673"},{"timestamp":"1632916020.0","comment_id":"85705","poster":"fw","upvote_count":"1","content":"I will go for C & E."},{"content":"C & E . Alarm can not trigger Lambda but event can","comment_id":"76595","timestamp":"1632879540.0","upvote_count":"1","poster":"Joeylee"},{"comments":[{"comment_id":"70870","timestamp":"1632757320.0","upvote_count":"3","poster":"Smart","content":"Agree about D & E. Both are eventually triggering Lambda Function through SNS Notification. The question is about which is optimal. \n\nD will infer based on metrics and conclude whether DB has failed or not. How will CW alarms interpret temporary outages due to reboots and etc.? Perhaps, setup a CW alarm that gets triggered after there is 'insufficient data' for 30 minutes indicating there is DB instance issue. \n\nOn the other hand, E will come to a decision that DB failed and then send notification. Does it appropriately recognize all types of DB failures? RDS-EVENT-0031: The DB instance has failed due to an incompatible configuration or an underlying storage issue. Begin a point-in-time-restore for the DB instance. I think this should do it. \n\nFor now, I will go with C & E. \n\nhttps://aws.amazon.com/blogs/database/amazon-rds-under-the-hood-single-az-instance-recovery/"}],"comment_id":"63733","timestamp":"1632755040.0","poster":"Jshuen","content":"I will go for C and D. ANS C instead of A/B is agreed by everyone here.\nBetween D and E, I think both ways can trigger Lambda functions, so the question is about Cloudwatch or RDS event is a better option for detect DB issue.\n\nCheck the following page but looks most of events are talking about the status change or Aurora DB, but didn't see any one can imply for DB dead.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html#USER_Events.Messages\n\nInstead, from the following page - https://aws.amazon.com/blogs/apn/key-metrics-for-amazon-aurora/ \nIt says some metrics such as read/write thoughput, latency, sounds a better way to measure the actual status of DB, from the application point of view, and switchover is requried, so i would perfer to use Cloudwatch and pick ANS D.","upvote_count":"1"},{"content":"C & D\nC: Use latency-based routing for both record sets ==> providing the lowest latency for the application end-users\nD: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-cloud-watch-events.html","timestamp":"1632723540.0","comment_id":"63248","upvote_count":"1","poster":"paulwang"},{"content":"CE for me, https://docs.aws.amazon.com/lambda/latest/dg/services-rds.html","comment_id":"61039","poster":"mandrakenet","upvote_count":"1","timestamp":"1632694620.0"},{"content":"Should be C,E","poster":"amog","timestamp":"1632591540.0","comment_id":"51267","upvote_count":"1"},{"upvote_count":"1","poster":"AWSPro24","content":"I'm confused by both D and E. Aurora is supposed to automatically promote its replicas to masters if the primary goes down.\n\n\"To increase database availability, simply create 1 to 15 replicas, in any of 3 AZs, and Amazon RDS will automatically include them in failover primary selection in the event of a database outage.\" https://aws.amazon.com/rds/aurora/faqs/ (Do a find on 'automatically' it's about half way down the page)","comment_id":"45012","comments":[{"upvote_count":"3","timestamp":"1632618660.0","comment_id":"53220","poster":"Gorha","content":"Disaster recovery across regions is a manual process for Aurora, where you promote a secondary region to take read/write workloads!"}],"timestamp":"1632590820.0"},{"upvote_count":"1","timestamp":"1632552300.0","content":"Out of D and E, in D, I believe health check is for the application tier, since it is already configured in option C. So, this health check is not correct to use for Database failover. As mentioned in option E, we are having readily available options for send notifications according to the RDS events and lambda can subscribe to RDS event notifications.","poster":"Vallivel","comment_id":"37128"},{"timestamp":"1632520140.0","poster":"Vallivel","content":"My Answer is C and E.\nOut of A, B and C, C is the best option as we need latency based routing\nOut of D and E, in D, I believe health check is for the application tier, since it is already configured in option C. So, this health check is not correct to use for Database failover. As mentioned in option E, we are having readily available options for send notifications according to the RDS events and lambda can subscribe to RDS event notifications.","comment_id":"37124","upvote_count":"5"},{"poster":"huhupai","comment_id":"17598","comments":[{"content":"Exactly, which event notification in RDS will notify for region failures?","poster":"b3llman","upvote_count":"1","timestamp":"1633789920.0","comment_id":"183655"}],"content":"C, E, You can use AWS Lambda to process event notifications from an Amazon Relational Database Service (Amazon RDS) database. Amazon RDS sends notifications to an Amazon Simple Notification Service (Amazon SNS) topic, which you can configure to invoke a Lambda function. https://docs.aws.amazon.com/lambda/latest/dg/services-rds.html","upvote_count":"8","timestamp":"1632247860.0"},{"timestamp":"1632225420.0","content":"I do support answers \"C\" & \"D\".\nfor latency best answer is C.\nfor recovery of RDS-DB, use CloudWatch to invoke Lambda.\nE: does not detailed the notification! Moreover, if region is down, then what notification is expected!","upvote_count":"8","comment_id":"13451","poster":"Moon"}],"isMC":true},{"id":"8P950jL9KSugztmZ8k94","timestamp":"2019-09-29 16:49:00","exam_id":32,"answer_images":[],"isMC":true,"question_images":[],"question_text":"A company runs a Windows Server host in a public subnet that is configured to allow a team of administrators to connect over RDP to troubleshoot issues with hosts in a private subnet. The host must be available at all times outside of a scheduled maintenance window, and needs to receive the latest operating system updates within 3 days of release.\nWhat should be done to manage the host with the LEAST amount of administrative effort?","url":"https://www.examtopics.com/discussions/amazon/view/5844-exam-aws-certified-solutions-architect-professional-topic-1/","answer":"C","answers_community":["C (60%)","B (40%)"],"discussion":[{"poster":"Moon","content":"I would go with \"C\".\nThe least administrative, and most available is min/max 1 autoscaling. Hardened images are available in Market place. Patch manager is a service to patch windows with updates.","timestamp":"1632104520.0","upvote_count":"40","comment_id":"13450"},{"upvote_count":"22","timestamp":"1632123960.0","content":"B, least amount of effort.\nhttps://docs.aws.amazon.com/workspaces/latest/adminguide/workspace-maintenance.html\nA\\C: Does not make sense\nD: a lot more work than B.","comments":[{"content":"No point in setting up an entire workspace along with directory inside a VPC to connect private instance.","comment_id":"70877","poster":"Smart","upvote_count":"5","timestamp":"1633005840.0"},{"content":"Why C doesn't make sense?","poster":"Kopa","upvote_count":"2","comment_id":"450152","timestamp":"1636180800.0"},{"poster":"DashL","upvote_count":"3","content":"Looks like Workspace is not a good option as a bastion host. It doesn't support security groups: https://aviatrix.com/learn-center/answered-access/how-to-use-aws-workspaces-as-jumphosts-for-secure-remote-access/.\nAlso, I couldn't find any info which says that Amazon WorkSpaces Application Manager (WAM) can be used to automatic windows patching. Patching can be scheduled manually, but not automatically every 3 days.","timestamp":"1635846900.0","comment_id":"401131"},{"comment_id":"81224","upvote_count":"11","timestamp":"1633171260.0","poster":"likku","content":"\"manage the host with the LEAST amount of administrative effort\" read the important point manage the host which means we have take the managing of host into account. Option is C."},{"poster":"Jupi","upvote_count":"6","comment_id":"418345","timestamp":"1635971100.0","content":"Workspace dont support windows server host."}],"poster":"donathon","comment_id":"13672"},{"comment_id":"1115345","content":"Selected Answer: C\nB seems correct except that WAM is used for application deployment not host hardening. Its a trick answer.\n\"Amazon WorkSpaces Application Manager (Amazon WAM) offers a fast, flexible, and secure way for you to deploy and manage applications for Amazon WorkSpaces with Windows.\"","timestamp":"1704563160.0","upvote_count":"1","poster":"3a632a3"},{"comment_id":"930710","upvote_count":"1","timestamp":"1687445520.0","poster":"SkyZeroZx","content":"Selected Answer: C\nDefinitely C\nas \"Amazon WorkSpaces Application Manager (Amazon WAM) is reaching end of life and will no longer be available starting on September 1, 2023 — the End of Life (EOL) date\" from https://docs.aws.amazon.com/wam/latest/adminguide/what_is.html"},{"poster":"Jesuisleon","upvote_count":"1","comment_id":"919522","content":"Selected Answer: C\nDefinitely C\nas \"Amazon WorkSpaces Application Manager (Amazon WAM) is reaching end of life and will no longer be available starting on September 1, 2023 — the End of Life (EOL) date\" from https://docs.aws.amazon.com/wam/latest/adminguide/what_is.html","timestamp":"1686333360.0"},{"timestamp":"1681600920.0","comment_id":"871371","content":"Selected Answer: B\nc is incorrect as there is no guarantee that the hardened image will be available on aws market place within 3 days of release.","upvote_count":"1","poster":"romiao106"},{"poster":"Dionenonly","content":"Selected Answer: B\nIf you are going to just consider what is asked B is the solution with the least amount of efforts.","upvote_count":"1","comments":[{"timestamp":"1666014120.0","content":"WorkSpaces doesn't use Windows Server, just client OS. It can't run on WorkSpaces so B is automatically out","poster":"redipa","comments":[{"comment_id":"746278","timestamp":"1671119640.0","upvote_count":"1","poster":"masetromain","content":"https://aws.amazon.com/fr/about-aws/whats-new/2021/08/amazon-workspaces-renews-windows-desktop-experience-windows-server-2019-bundles-64-bit-microsoft-office-2019/"}],"upvote_count":"1","comment_id":"697436"}],"timestamp":"1665818520.0","comment_id":"695248"},{"content":"I like C but not sure how would an ASG serve any purpose in this scenario. Plus, WorkSpaces makes even less sense. Firstly, it's not cheap especially to just be used as a host server.","poster":"Jonfernz","comments":[{"content":"It ensures one is always running. This handles AZ failure.","upvote_count":"2","comment_id":"693174","timestamp":"1665585660.0","poster":"joanneli77"}],"upvote_count":"1","comment_id":"690210","timestamp":"1665321900.0"},{"upvote_count":"2","content":"As per tutorials dojo answer is C - workspace","comment_id":"672774","timestamp":"1663540620.0","poster":"linuxmaster007"},{"content":"Selected Answer: C\nWorkspaces is for desktops and not for servers","timestamp":"1660027200.0","poster":"Santo99","comment_id":"644375","upvote_count":"2"},{"content":"Selected Answer: B\nVoting for B, https://docs.aws.amazon.com/workspaces/latest/adminguide/workspace-maintenance.html I this document there's a link to MS site to configure Group policy for patching: https://docs.microsoft.com/en-us/windows-server/administration/windows-server-update-services/deploy/4-configure-group-policy-settings-for-automatic-updates","upvote_count":"2","poster":"lurker8000","comment_id":"575848","timestamp":"1648340640.0"},{"upvote_count":"1","timestamp":"1643535180.0","content":"CCCCCCCCC","comment_id":"536045","poster":"cannottellname"},{"comment_id":"525148","timestamp":"1642356960.0","upvote_count":"1","poster":"pititcu667","content":"Selected Answer: C\nc just because they mention server. it's misleading because b workspace seems right except it's just the desktop."},{"poster":"tkanmani76","comment_id":"508896","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"741625","timestamp":"1670757540.0","content":"For always on workspaces, default maintenance window is from 00:00~04h00 on Sunday morning but the user can have manual maintenance which can change the the window","poster":"spencer_sharp"}],"content":"In Workspace FAQ check the query - How will my Amazon WorkSpaces be patched with software updates? \nThe updates are automatically managed and delivered every Sunday - there is no mention of ability to change this earlier like 3 days. Hence WAM is not an option and the right choice should be C.","timestamp":"1640388480.0"},{"comment_id":"494600","timestamp":"1638732960.0","content":"I'll go with C","poster":"AzureDP900","upvote_count":"1"},{"comment_id":"486153","timestamp":"1637777040.0","poster":"pcops","upvote_count":"1","content":"I will go with C."},{"timestamp":"1636298820.0","upvote_count":"1","comment_id":"457088","content":"I rejected B as I couldn't find any docs/links to prove WAM can be used to harden Workspaces. WAM purpose is different. https://aws.amazon.com/workspaces/applicationmanager/. Hence choosing C.","poster":"StelSen"},{"upvote_count":"1","poster":"nodogoshi","timestamp":"1636046820.0","content":"B provide LEAST amount of administrative effort.","comment_id":"449806"},{"poster":"blackgamer","comment_id":"346558","timestamp":"1635824760.0","upvote_count":"2","content":"C is my answer. It supports high availability by using auto scaling group, system patch manager can help on patching of server automatically as well."},{"comment_id":"335371","content":"Prefer C.\nBut B is also working, isn't it?\nA\nI don't think Elastic Beanstalk is used for this.\nThere are two kinds of environments, web server or worker.\nIt's not for bastion host.\n\nD\nAWS OpsWorks Stacks does not provide a way to apply updates to online Windows instances.\nhttps://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-os-windows.html","poster":"01037","upvote_count":"1","timestamp":"1635436620.0"},{"upvote_count":"2","content":"C is my answer.\nB cannot be the answer due to below two reasons\n1. AWS workspace is a desktop service. You cannot have windows server host\n2. WAM is for application deployment to workspace, not to harden the workspace","comment_id":"308592","timestamp":"1635345960.0","poster":"ajeeshb"},{"content":"going with C","upvote_count":"2","poster":"Kian1","comment_id":"291447","timestamp":"1635315240.0"},{"content":"I go with C","comment_id":"280335","upvote_count":"5","poster":"Ebi","timestamp":"1635309360.0"},{"poster":"petebear55","timestamp":"1635143100.0","content":"c ... keep it simple guys","comment_id":"246773","upvote_count":"2"},{"timestamp":"1634932800.0","comment_id":"243401","poster":"T14102020","content":"Correct answer is C. Auto Scaling group and Systems Manager Patch Manager.","upvote_count":"2"},{"timestamp":"1634707380.0","upvote_count":"3","poster":"Bulti","content":"Answer is C because AWS beanstalk doesn't support custom AMi on windows server host. Other 2 options are not related to the question.","comment_id":"242868"},{"comment_id":"230775","content":"I'll go with C","poster":"jackdryan","timestamp":"1634632800.0","upvote_count":"3"},{"upvote_count":"1","poster":"gookseang","comment_id":"230052","content":"I will go B","comments":[{"upvote_count":"1","poster":"gookseang","content":"change to C","comment_id":"278294","timestamp":"1635304380.0"}],"timestamp":"1634600340.0"},{"upvote_count":"2","comment_id":"182988","poster":"ipindado2020","content":"I go for C.\nBastion HA with scaling group + system manager for patches","timestamp":"1634424360.0"},{"comment_id":"150427","poster":"fullaws","timestamp":"1634241480.0","content":"C is correct, agree with inf viewpoint","upvote_count":"2"},{"comment_id":"135615","content":"Part 2\nAnswer: C\nB - incorrect - ... Note: using WAM for hardening is possible, but requires a custom package created from a build & capture EC2 instance - fair bit of administrative overhead. WAM takes a snapshot before/after changes applied to the capture machine, and packges the deltas which can be pushed to the Workspace instance.\nC - correct - technically feasible - may require a wrapper to manage termination policies to prevent ASG cycling the EC2 instance if the health check fails whilst updating/rebooting. Between A and C, its the only viable solution\nD - incorrect - Upgrade Operating System stack is applicable to Linux only. Not Windows.\n(ref for A - https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.customenv.html)","timestamp":"1634175600.0","upvote_count":"6","poster":"inf"},{"upvote_count":"7","content":"Part 1\nAnswer: C\nA - incorrect - Reason being the use of a \"custom AMI\" (won't work) and if it did, would lead to administrative overhead. \"AMIs that aren't managed by Elastic Beanstalk aren't supported for Windows Server-based Elastic Beanstalk platforms.\" - a community Windows AMI cannot be used. Some additional info - single instance implies an ASG with a min/max of 1 (no diff to C). Single instance EC2 is deployed with a [public] Elastic IP address - only one that implies a public address. \nB - incorrect - Updates running every 3 days doesn't mean an update is applied 3 days after release. It could be deployed 1 day after release if the next update cycle falls on that day. Also, Workspaces deploys Windows 10 desktop \"experience\" instances (1-to-1 mapping of user to host/instance) - we want a Bastion host that serves multiple users sessions simultaneously - not possible without BYOL and a physical host in AWS (complicated). ...","poster":"inf","timestamp":"1634133360.0","comment_id":"135613"},{"timestamp":"1634096460.0","comment_id":"133096","comments":[{"upvote_count":"1","comment_id":"335363","timestamp":"1635381600.0","content":"I prefer C.\nBut WAM does update OS","poster":"01037"}],"upvote_count":"3","poster":"NikkyDicky","content":"C\nB is tricky - WAM doesn't patch the host, only apps"},{"comment_id":"132561","upvote_count":"1","timestamp":"1634068620.0","content":"Answer: C","poster":"mat2020"},{"poster":"94xychen","upvote_count":"2","timestamp":"1633722360.0","content":"In my opinion, only option C provides high availabilities which the Topic mentioned.","comment_id":"110757"},{"upvote_count":"2","comment_id":"107857","content":"It should be A","timestamp":"1633414260.0","poster":"VrushaliD"},{"content":"C looks like the right answer, with ASG min/max = 1 instance satisfies the availability factor.","comment_id":"106283","poster":"meenu2225","upvote_count":"1","timestamp":"1633369260.0"},{"content":"A\nB is for Workspace, which is primarily for desktop\nC- Auto scaling with 1 server. What is the need os auto scaling ( A looks better option with EB)\nD - Opsworks is for app deployment. not pathching","poster":"JAWS1600","comments":[{"comment_id":"135621","upvote_count":"1","content":"EB single instance uses auto scaling of 1-1-1 (min-desired-max). A and C function the same with regards to autoscaling.","timestamp":"1634219880.0","poster":"inf"}],"timestamp":"1633231320.0","upvote_count":"1","comment_id":"98428"},{"upvote_count":"4","comment_id":"76597","comments":[{"poster":"cloud4gr8","timestamp":"1633802580.0","comment_id":"121490","upvote_count":"1","content":"Amazon WorkSpaces is a managed, secure Desktop-as-a-Service (DaaS) solution. You can use Amazon WorkSpaces to provision either Windows or Linux desktops in just a few minutes and quickly scale to provide thousands of desktops to workers across the globe.","comments":[{"timestamp":"1633889160.0","upvote_count":"1","content":"Amazon WAM accelerates software deployment, upgrades, patching, and retirement by packaging Microsoft Windows desktop applications into virtualized application containers. These applications run on the end-user’s Amazon WorkSpaces instance as though they are natively installed.","poster":"cloud4gr8","comment_id":"121491"}]},{"timestamp":"1633926780.0","comment_id":"122951","poster":"LunchTime","content":"The link also contains the following statement “This set up poses one major challenge: How do you control which AWS network spaces each Workspace instance can access? AWS Security Groups are not supported on Workspaces. It is even more challenging when you consider the fact that Workspace instances run in an AWS-managed VPC.” \nThey then recommend their proprietary solution for that issue. As such, C is a better answer.\n\nAlso, A does not meet the requirement of \"the host must be available at all times\" as it runs just a single instance. Again, C has that covered (auto scaling group) and is the best answer.","upvote_count":"1"}],"content":"B\nhttps://a.aviatrix.com/answers/how-to-use-aws-workspaces-as-jumphosts-for-secure-remote-access/","poster":"Joeylee","timestamp":"1633134660.0"},{"upvote_count":"2","comment_id":"73368","timestamp":"1633017660.0","content":"B is for software installation and patch","poster":"Danao"},{"content":"C, it is a bastion host.","upvote_count":"2","poster":"NNHAN","timestamp":"1632910920.0","comment_id":"64313"},{"comment_id":"61041","content":"its A for me\ni think that C is invalid, because if you update patch de OS, and then the instance is replaced by ASG with the base AMI it will not have the updates","poster":"mandrakenet","timestamp":"1632705780.0","comments":[{"timestamp":"1632937380.0","comment_id":"70872","content":"Yeah but there won't be high availability with a single-instance EB env without ASG. If you setup EB with ASG, it is same thing then.","upvote_count":"1","comments":[{"content":"With Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without having to learn about the infrastructure that runs those applications. Elastic Beanstalk reduces management complexity without restricting choice or control. You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","timestamp":"1635161160.0","upvote_count":"1","poster":"Firststack","comment_id":"270830","comments":[{"timestamp":"1635182220.0","comment_id":"270833","upvote_count":"1","poster":"Firststack","content":"Option A for me"}]}],"poster":"Smart"},{"poster":"Smart","content":"Also, remember patch manager can run on scheduled basis through maintenance window.","upvote_count":"3","timestamp":"1632999120.0","comment_id":"70874"}],"upvote_count":"3"},{"timestamp":"1632484920.0","poster":"amog","comment_id":"51270","content":"Should be C\nNo need more effort in case of server failure","upvote_count":"4"},{"timestamp":"1632410520.0","comment_id":"45003","content":"A. Windows Server is supported on EB https://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/platforms/platforms-supported.html\nHost needs to be available at all times outside a scheduled maintenance window which Patch Manager can accommodate \"You can install patches on a regular basis by scheduling patching to run as a Systems Manager maintenance window task\" https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-patch.html","upvote_count":"1","poster":"AWSPro24"},{"timestamp":"1632285180.0","comment_id":"42704","comments":[{"comment_id":"44992","timestamp":"1632336900.0","content":"EB does support Windows Server https://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/platforms/platforms-supported.html","upvote_count":"1","poster":"AWSPro24"},{"comment_id":"98424","content":"Ops works support Windows since 2015.\nhttps://aws.amazon.com/blogs/aws/aws-opsworks-for-windows/\nThe following doc shows you how to run on windows\nhttps://docs.aws.amazon.com/opsworks/latest/userguide/cookbooks-101-opsworks-opsworks-windows.html","poster":"JAWS1600","timestamp":"1633212960.0","upvote_count":"1"}],"upvote_count":"2","poster":"Biswaji","content":"My Option A\nA: uses beanstalk env. creating a custom ami with option to use ssm.\nB. Workspaces do no support windows server\nC. there is nothing called hardened machine image in marketplace\nd. opsworks command supports only linux"},{"timestamp":"1632259320.0","poster":"siasiasia","comment_id":"37290","content":"C is the right answer, WAM is not for hardening Workspaces.","comments":[{"timestamp":"1632696120.0","poster":"Gorha","upvote_count":"1","comment_id":"53223","content":"WAM does patching: https://aws.amazon.com/workspaces/applicationmanager/"}],"upvote_count":"6"},{"upvote_count":"1","timestamp":"1632083580.0","poster":"MGM","comment_id":"13168","content":"Why B , any suggestion?"}],"question_id":473,"topic":"1","answer_description":"","answer_ET":"C","choices":{"C":"Run the host in an Auto Scaling group with a minimum and maximum instance count of 1. Use a hardened machine image from AWS Marketplace. Apply system updates with AWS Systems Manager Patch Manager.","A":"Run the host in a single-instance AWS Elastic Beanstalk environment. Configure the environment with a custom AMI to use a hardened machine image from AWS Marketplace. Apply system updates with AWS Systems Manager Patch Manager.","B":"Run the host on AWS WorkSpaces. Use Amazon WorkSpaces Application Manager (WAM) to harden the host. Configure Windows automatic updates to occur every 3 days.","D":"Run the host in AWS OpsWorks Stacks. Use a Chief recipe to harden the AMI during instance launch. Use an AWS Lambda scheduled event to run the Upgrade Operating System stack command to apply system updates."},"unix_timestamp":1569768540},{"id":"EQ4FIo7HbJClJqYerlVm","unix_timestamp":1568758920,"discussion":[{"timestamp":"1632511260.0","content":"A\nQ: How should I choose between Snowmobile and Snowball?\n\nTo migrate large datasets of 10PB or more in a single location, you should use Snowmobile. For datasets less than 10PB or distributed in multiple locations, you should use Snowball. In addition, you should evaluate the amount of available bandwidth in your network backbone. If you have a high speed backbone with hundreds of Gb/s of spare throughput, then you can use Snowmobile to migrate the large datasets all at once. If you have limited bandwidth on your backbone, you should consider using multiple Snowballs to migrate the data incrementally.","upvote_count":"29","poster":"MGM","comment_id":"13170"},{"content":"I support answer \"A\".\nSnowmobile, is used for PB of data, Snowball can't support that. (so A, or B).\nThen, A is more cost effective.","upvote_count":"12","poster":"Moon","timestamp":"1632693180.0","comments":[{"timestamp":"1632710520.0","upvote_count":"2","content":"for snowball edge, it support 100TB, then you may need 100 of them to make 10PB. So better to have Snowmobile.","comment_id":"13447","poster":"Moon","comments":[{"timestamp":"1633697940.0","poster":"[Removed]","upvote_count":"2","content":"even less than that. Snowball Edge has 83TB of usable disk space.","comment_id":"88654"}]}],"comment_id":"13446"},{"upvote_count":"1","poster":"SkyZeroZx","comment_id":"930723","content":"Selected Answer: A\nA\nQ: How should I choose between Snowmobile and Snowball?\n\nTo migrate large datasets of 10PB or more in a single location, you should use Snowmobile. For datasets less than 10PB or distributed in multiple locations, you should use Snowball. In addition, you should evaluate the amount of available bandwidth in your network backbone. If you have a high speed backbone with hundreds of Gb/s of spare throughput, then you can use Snowmobile to migrate the large datasets all at once. If you have limited bandwidth on your backbone, you should consider using multiple Snowballs to migrate the data incrementally.","timestamp":"1687446300.0"},{"timestamp":"1658156040.0","comment_id":"633067","content":"never mind, we can do autoscaling with spot instance pooling as the link. It should be A\nhttps://aws.amazon.com/getting-started/hands-on/ec2-auto-scaling-spot-instances/","upvote_count":"1","poster":"Student1950"},{"poster":"Student1950","timestamp":"1658155680.0","content":"with A, Can we apply autoscaling on spot instances ? I believe it should be B then\nMinimize costs using Reserved Instances for master and core nodes and Spot Instances for task nodes, and auto scale task nodes based on Amazon CloudWatch metrics","upvote_count":"1","comment_id":"633066"},{"upvote_count":"1","timestamp":"1654735380.0","poster":"Anhdd","content":"Selected Answer: A\nA for sure, no doubt","comment_id":"613556"},{"poster":"CGJoon","comment_id":"538603","timestamp":"1643799720.0","upvote_count":"1","content":"The question says: \"The present cluster is available 24 hours a day\". Doesn't that mean that using spot instances for task nodes in option B might not give you 24 hours a day availability? In that case, wouldn't the correct answer be option A?"},{"timestamp":"1640870640.0","comment_id":"513399","upvote_count":"1","content":"A. Snowmobile for PB data.","poster":"cldy"},{"comments":[{"comment_id":"507003","poster":"Ni_yot","timestamp":"1640170980.0","content":"You also want to use spot instances for batch jobs","upvote_count":"1"}],"upvote_count":"1","content":"A for me. Snowmobile supports PBs of data","timestamp":"1640170800.0","poster":"Ni_yot","comment_id":"506998"},{"poster":"AzureDP900","timestamp":"1638733140.0","content":"A is right","upvote_count":"1","comment_id":"494601"},{"comment_id":"410496","upvote_count":"2","poster":"WhyIronMan","timestamp":"1636204140.0","content":"I'll go with A"},{"comment_id":"346158","upvote_count":"3","content":"it's A","poster":"Waiweng","timestamp":"1635958800.0"},{"timestamp":"1635919260.0","upvote_count":"1","comment_id":"291448","content":"going with A","poster":"Kian1"},{"upvote_count":"3","content":"Answer is A not C,\nSnowmobile is for data sets over 10PB","timestamp":"1635904680.0","comment_id":"280344","poster":"Ebi"},{"content":"Guys, A and C are same answer","upvote_count":"1","comment_id":"265959","comments":[{"poster":"Justu","content":"SnowMobile is not the same as SnowBall!!! Over 10PB of data -> USE SnowMobile! -> A","timestamp":"1635736080.0","comment_id":"269653","upvote_count":"2"}],"poster":"Ashodwbi","timestamp":"1635699540.0"},{"comments":[{"content":"Sorry, my misunderstanding ... A is correct. A is SnowMobile, C is SnowBall. Except that all are the same. A is only correct.","timestamp":"1635377040.0","comment_id":"253334","poster":"consultsk","upvote_count":"1"}],"upvote_count":"1","timestamp":"1635283380.0","comment_id":"253333","poster":"consultsk","content":"I am not sure if anyone noticed. A and C both are having the same verbiage. Word to Word. I am not sure of the arguments made here. A is correct and eventually C also. :) A or C."},{"timestamp":"1634871780.0","comment_id":"246788","content":"I was initailly drawn to C ,, however it is clearly A having read this","poster":"petebear55","upvote_count":"2"},{"content":"Correct answer is A. Snowmobile and Spot instances","timestamp":"1634839200.0","poster":"T14102020","upvote_count":"2","comment_id":"243406"},{"upvote_count":"1","content":"Answer is a snowmobile and not snowball is solution as we need to move more than 10PB of data.","comment_id":"242874","poster":"Bulti","timestamp":"1634581500.0"},{"comment_id":"230799","timestamp":"1634526300.0","upvote_count":"3","poster":"jackdryan","content":"I'll go with A*"},{"timestamp":"1634492160.0","poster":"gookseang","upvote_count":"1","comment_id":"230053","comments":[{"poster":"gookseang","upvote_count":"2","comment_id":"278212","timestamp":"1635760860.0","content":"change to A"}],"content":"C for sure"},{"timestamp":"1634052660.0","upvote_count":"3","poster":"cpd","comments":[{"poster":"smithyt","content":"The question says that grows roughly, meaning its not a known figure, so purchasing 200 more instance when you only need 150 would not be cost effective","upvote_count":"1","timestamp":"1634481840.0","comment_id":"210672"},{"content":"i do agree it is B , we cant use spot instances for all tasks including analytics, there is a chance they won't be available","poster":"user0001","comment_id":"605042","upvote_count":"1","timestamp":"1653173220.0"}],"content":"This does NOT require autoscale; we already know the cluster requires 200 more instances every quarter. 6 months down the line, why would we want 400 spot instances running?\nB is the only option that allows to buy 200 RI each quarter.","comment_id":"205385"},{"upvote_count":"2","timestamp":"1634045400.0","comment_id":"151658","poster":"fullaws","content":"A is correct"},{"poster":"NikkyDicky","upvote_count":"2","content":"A for sure","timestamp":"1634012820.0","comment_id":"133102"},{"poster":"cloud4gr8","upvote_count":"1","comment_id":"121488","content":"Correct Answer is A, as snowmobile is economical to transfer more than 10 PB data","timestamp":"1633973940.0"},{"poster":"meenu2225","upvote_count":"1","timestamp":"1633848360.0","comment_id":"106303","content":"C is the answer, \nQ: How should I choose between Snowmobile and Snowball?\n\nTo migrate large datasets of 10PB or more in a single location, you should use Snowmobile. For datasets less than 10PB or distributed in multiple locations, you should use Snowball. In addition, you should evaluate the amount of available bandwidth in your network backbone. If you have a high speed backbone with hundreds of Gb/s of spare throughput, then you can use Snowmobile to migrate the large datasets all at once. If you have limited bandwidth on your backbone, you should consider using multiple Snowballs to migrate the data incrementally. (https://aws.amazon.com/snowmobile/faqs/?nc1=h_ls)","comments":[{"poster":"meenu2225","content":"Typo, I meant A is the answer.","comment_id":"106305","upvote_count":"2","timestamp":"1633891320.0"}]},{"comment_id":"95073","timestamp":"1633828320.0","upvote_count":"6","content":"One requirement is \"limit the impact of loosing cluster nodes\" along with cost savings. SPOT instances do not qualify the \"loosing\" requirement. RI does. Option B is the way to go","poster":"JAWS1600"},{"poster":"Divine","content":"I will go for A","comment_id":"85246","upvote_count":"1","timestamp":"1633302780.0"},{"timestamp":"1633182300.0","content":"Answer is A","poster":"amog","comment_id":"51271","upvote_count":"3"},{"comment_id":"31065","poster":"JayK","upvote_count":"5","timestamp":"1632962280.0","content":"A has autoscaling feature , so, 24/7 can be possible.\nSo my answer is A"},{"timestamp":"1632840240.0","content":"Answer is B. it is running 24/7. so spot instances cannot be option here.","comment_id":"26199","upvote_count":"8","poster":"examacc","comments":[{"comment_id":"32590","poster":"cinopi","upvote_count":"4","content":"Read - Minimize costs using Reserved Instances for master and core nodes and Spot Instances for task nodes, and auto scale task nodes based on Amazon CloudWatch metrics\n\nIt implies REserved instance for Master + Core Nodes. Task nodes are spot instances, generally spot instances are Cheapest than Reserved Instabces also","timestamp":"1633048320.0"}]},{"content":"Because , solution need to be less expensive","upvote_count":"2","comment_id":"12941","timestamp":"1632416220.0","poster":"AdityaM"},{"upvote_count":"4","comment_id":"11482","timestamp":"1632228420.0","poster":"awsgcpazure","content":"Why is C not A. Please advise.\n#How should I choose between Snowmobile and Snowball?\nhttps://aws.amazon.com/snowmobile/faqs/?nc1=h_ls"}],"url":"https://www.examtopics.com/discussions/amazon/view/5331-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"timestamp":"2019-09-18 00:22:00","question_text":"A company has a large on-premises Apache Hadoop cluster with a 20 PB HDFS database. The cluster is growing every quarter by roughly 200 instances and 1\nPB. The company's goals are to enable resiliency for its Hadoop data, limit the impact of losing cluster nodes, and significantly reduce costs. The current cluster runs 24/7 and supports a variety of analysis workloads, including interactive queries and batch processing.\nWhich solution would meet these requirements with the LEAST expense and down time?","answer_description":"To migrate large datasets of 10 PB or more in a single location, you should use Snowmobile. For datasets less than 10 PB or distributed in multiple locations, you should use Snowball. In addition, you should evaluate the amount of available bandwidth in your network backbone. If you have a high speed backbone with hundreds of Gb/s of spare throughput, then you can use Snowmobile to migrate the large datasets all at once. If you have limited bandwidth on your backbone, you should consider using multiple Snowballs to migrate the data incrementally.","question_id":474,"topic":"1","isMC":true,"exam_id":32,"answer_ET":"A","choices":{"B":"Use AWS Snowmobile to migrate the existing cluster data to Amazon S3. Create a persistent Amazon EMR cluster of a similar size and configuration to the current cluster. Store the data on EMRFS. Minimize costs by using Reserved Instances. As the workload grows each quarter, purchase additional Reserved Instances and add to the cluster.","C":"Use AWS Snowball to migrate the existing cluster data to Amazon S3. Create a persistent Amazon EMR cluster initially sized to handle the interactive workloads based on historical data from the on-premises cluster. Store the data on EMRFS. Minimize costs using Reserved Instances for master and core nodes and Spot Instances for task nodes, and auto scale task nodes based on Amazon CloudWatch metrics. Create job-specific, optimized clusters for batch workloads that are similarly optimized.","A":"Use AWS Snowmobile to migrate the existing cluster data to Amazon S3. Create a persistent Amazon EMR cluster initially sized to handle the interactive workload based on historical data from the on-premises cluster. Store the data on EMRFS. Minimize costs using Reserved Instances for master and core nodes and Spot Instances for task nodes, and auto scale task nodes based on Amazon CloudWatch metrics. Create job-specific, optimized clusters for batch workloads that are similarly optimized.","D":"Use AWS Direct Connect to migrate the existing cluster data to Amazon S3. Create a persistent Amazon EMR cluster initially sized to handle the interactive workload based on historical data from the on-premises cluster. Store the data on EMRFS. Minimize costs using Reserved Instances for master and core nodes and Spot Instances for task nodes, and auto scale task nodes based on Amazon CloudWatch metrics. Create job-specific, optimized clusters for batch workloads that are similarly optimized."},"answer":"A","answers_community":["A (100%)"],"question_images":[]},{"id":"mj9ZSohdudNBzriPd5SX","answer":"C","answer_ET":"C","question_images":[],"answers_community":["C (100%)"],"answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/5333-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"2019-09-18 03:02:00","choices":{"A":"Migrate the web servers to Amazon EC2 instances in an Auto Scaling group that is running .NET. Migrate the existing Cassandra database to Amazon Aurora with multiple read replicas, and run both in a Multi-AZ mode.","B":"Migrate the web servers to an AWS Elastic Beanstalk environment that is running the .NET platform in a Multi-AZ Auto Scaling configuration. Migrate the Cassandra database to Amazon EC2 instances that are running in a Multi-AZ configuration.","C":"Migrate the web servers to an AWS Elastic Beanstalk environment that is running the .NET platform in a Multi-AZ Auto Scaling configuration. Migrate the existing Cassandra database to Amazon DynamoDB.","D":"Migrate the web servers to Amazon EC2 instances in an Auto Scaling group that is running .NET. Migrate the existing Cassandra database to Amazon DynamoDB."},"isMC":true,"exam_id":32,"discussion":[{"content":"C\nA\\B\\D: Not the least complicated to manage.","upvote_count":"35","timestamp":"1632349080.0","poster":"donathon","comment_id":"11751"},{"timestamp":"1633533360.0","poster":"MrP","content":"Apache Cassandra is NoSQL ( http://cassandra.apache.org/ ), which limits us to other NoSQL solutions (DynamoDB). Beanstalk supports .Net, so C is the only one fulfilling both requirements of LEAST complexity for DB and application migration - and also post-migration efforts (which was the main question).","comment_id":"56250","upvote_count":"16"},{"upvote_count":"1","content":"Probably C, but in reality it depends especially with Windows environments. If it is simple then it should be straight forward. But for large .net applications I find easier to move to EC2 as once you start using beanstalk advanced configurations it becomes a headache.","timestamp":"1704563940.0","comment_id":"1115357","poster":"3a632a3"},{"timestamp":"1658592480.0","poster":"CloudHandsOn","upvote_count":"1","comment_id":"635679","content":"C. EASIEST plays a big part in this question. Beanstalk and DynamoDB (excluding configuring an EC2 instance) would be ideal here."},{"timestamp":"1647506520.0","poster":"KennethTam","upvote_count":"3","content":"Selected Answer: C\nC is correct","comment_id":"569568"},{"content":"C. Migrate the web servers to an AWS Elastic Beanstalk environment that is running the .NET platform in a Multi-AZ Auto Scaling configuration. Migrate the existing Cassandra database to Amazon DynamoDB.","upvote_count":"1","poster":"cldy","timestamp":"1638960660.0","comment_id":"496744"},{"timestamp":"1638733380.0","upvote_count":"1","comment_id":"494603","poster":"AzureDP900","content":"IT staff wishes to decrease the amount of time spent on capacity management and infrastructure maintenance ---- So C is correct"},{"poster":"WhyIronMan","timestamp":"1636227840.0","comment_id":"410499","content":"I'll go with C","upvote_count":"2"},{"timestamp":"1636223520.0","poster":"blackgamer","upvote_count":"1","comment_id":"346562","content":"I will go with C as it is easier to maintian."},{"poster":"Waiweng","content":"it's C","timestamp":"1636072380.0","upvote_count":"4","comment_id":"346161"},{"upvote_count":"2","content":"going with C","comment_id":"291449","timestamp":"1635827400.0","poster":"Kian1"},{"timestamp":"1635803700.0","content":"I go with C","poster":"Ebi","comment_id":"280352","upvote_count":"5"},{"comment_id":"251771","content":"Answer is C. Elastic beanstalk and Dynamo DB are both managed services and the question mentioned that the developers are ready to refactor the application. Other options are not AWS managed options and come with overhead.","timestamp":"1635565200.0","upvote_count":"1","poster":"Bulti"},{"upvote_count":"2","timestamp":"1635494520.0","content":"Correct is C. Easy. Elastic Beanstalk for .NET and DynamoDB for CASSANDRA","poster":"T14102020","comment_id":"243415"},{"content":"I'll go with C","comment_id":"230800","upvote_count":"5","poster":"jackdryan","timestamp":"1635248400.0"},{"timestamp":"1635144060.0","comments":[{"comment_id":"278218","timestamp":"1635705420.0","content":"change to C","upvote_count":"1","poster":"gookseang"}],"poster":"gookseang","comment_id":"230058","content":"seems D， my friend said C ..... so complex question, I think C is not avalliable for Large product","upvote_count":"1"},{"content":"I vote C. D is not reducing the management effort as well.","upvote_count":"3","comment_id":"152961","poster":"Spiri79","timestamp":"1634892300.0"},{"upvote_count":"1","poster":"enk","comments":[{"content":"It is C...\n\nD is just an scaling group... no load balancer, not multizone....\nrequirement to \"improve service reliability\"","upvote_count":"1","timestamp":"1634930640.0","poster":"ipindado2020","comment_id":"182994"}],"comment_id":"152191","timestamp":"1634579220.0","content":"D is the answer\n'Large application' - Beanstalk shouldn't be used for large production applications therefore B&C are bad choices."},{"comment_id":"151660","poster":"fullaws","timestamp":"1634539020.0","upvote_count":"2","content":"C is correct"},{"timestamp":"1634021460.0","poster":"Ritzu","content":"Answer should be D because it did not specifically say Multi-Az high availability","comment_id":"135694","comments":[{"timestamp":"1634206140.0","comment_id":"137253","content":"\"LEAST complex to manage after the migration\"","poster":"vulypa","upvote_count":"1"}],"upvote_count":"2"},{"timestamp":"1634005800.0","content":"C - for sure","comment_id":"133104","poster":"NikkyDicky","upvote_count":"2"},{"content":"Easy, C is the best option. EB for .NET and Dynamodb for CASSANDRA","upvote_count":"1","timestamp":"1633953660.0","comment_id":"106302","poster":"meenu2225"},{"content":"B is correct.","timestamp":"1633565340.0","comment_id":"94846","upvote_count":"2","poster":"FreeSwan"},{"poster":"amog","comment_id":"51272","content":"Agree with C","upvote_count":"3","timestamp":"1633513380.0"},{"upvote_count":"3","content":"C is correct","poster":"dumma","comment_id":"44438","timestamp":"1633494420.0"},{"poster":"Scunningham99","upvote_count":"5","timestamp":"1633239660.0","comment_id":"27860","content":"agree with c"},{"upvote_count":"7","content":"Answer \"C\".\nCassandra to be migrated to DynamoDB. Also, it is best to use Elastic Beanstalk for ease of management.","poster":"Moon","comment_id":"13444","timestamp":"1632624420.0"},{"poster":"dpvnme","comments":[{"timestamp":"1632849360.0","poster":"TechGuru","content":"This suggest option 'C'","comment_id":"17885","upvote_count":"3"}],"upvote_count":"1","timestamp":"1632595980.0","comment_id":"11856","content":"B.\nhttps://aws.amazon.com/blogs/database/migrate-apache-cassandra-databases-to-amazon-dynamodb-more-easily/"},{"comment_id":"11752","timestamp":"1632356880.0","upvote_count":"5","content":"Also forgot to add the DB should be DynamoDB: https://aws.amazon.com/blogs/database/migrate-apache-cassandra-databases-to-amazon-dynamodb-more-easily/","poster":"donathon"},{"comment_id":"11487","timestamp":"1632281700.0","poster":"Xiaoyao2000","content":"why not C?","upvote_count":"3"}],"question_text":"A company is running a large application on premises. Its technology stack consists of Microsoft .NET for the web server platform and Apache Cassandra for the database. The company wants to migrate this application to AWS to improve service reliability. The IT team also wants to reduce the time it spends on capacity management and maintenance of this infrastructure. The Development team is willing and available to make code changes to support the migration.\nWhich design is the LEAST complex to manage after the migration?","topic":"1","unix_timestamp":1568768520,"question_id":475}],"exam":{"isMCOnly":false,"name":"AWS Certified Solutions Architect - Professional","provider":"Amazon","id":32,"numberOfQuestions":1019,"isImplemented":true,"isBeta":false,"lastUpdated":"11 Apr 2025"},"currentPage":95},"__N_SSP":true}