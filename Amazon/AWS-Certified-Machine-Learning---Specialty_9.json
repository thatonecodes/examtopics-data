{"pageProps":{"questions":[{"id":"3K1slilkQD8yFL4DrOyW","answer":"C","unix_timestamp":1650764340,"isMC":true,"timestamp":"2022-04-24 03:39:00","url":"https://www.examtopics.com/discussions/amazon/view/74279-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","discussion":[{"content":"Selected Answer: C\nThis is correct according to official documentation.\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/nbi-software-updates.html","upvote_count":"17","comment_id":"590843","poster":"cron0001","timestamp":"1682300340.0"},{"upvote_count":"1","poster":"Mickey321","comment_id":"991281","timestamp":"1724743380.0","content":"Selected Answer: C\nAmazon SageMaker periodically tests and releases software that is installed on notebook instances, such as Jupyter Notebook, security patches, AWS SDK updates, and so on. To ensure that you have the most recent software updates, you need to stop and restart your notebook instance, either in the SageMaker console or by calling StopNotebookInstance."},{"content":"Selected Answer: C\nBy stopping and restarting the SageMaker notebook instance, it will automatically apply the latest security and software updates provided by SageMaker. This process refreshes the underlying infrastructure, ensuring that the notebook instance is running with the most up-to-date software and security patches. It is a simple and effective way to comply with the security team's mandate for using the latest updates.","comment_id":"967942","timestamp":"1722419100.0","upvote_count":"1","poster":"ccpmad"},{"comment_id":"943261","content":"C per Developer Documentation https://gmoein.github.io/files/Amazon%20SageMaker.pdf Page44","timestamp":"1720148100.0","upvote_count":"1","poster":"ADVIT"}],"exam_id":26,"question_images":[],"question_id":41,"choices":{"C":"Stop and then restart the SageMaker notebook instance","B":"Create a new SageMaker notebook instance and mount the Amazon Elastic Block Store (Amazon EBS) volume from the original instance","A":"Call the CreateNotebookInstanceLifecycleConfig API operation","D":"Call the UpdateNotebookInstanceLifecycleConfig API operation"},"answers_community":["C (100%)"],"answer_ET":"C","answer_images":[],"answer_description":"","question_text":"A data scientist has been running an Amazon SageMaker notebook instance for a few weeks. During this time, a new version of Jupyter Notebook was released along with additional software updates. The security team mandates that all running SageMaker notebook instances use the latest security and software updates provided by SageMaker.\nHow can the data scientist meet this requirements?"},{"id":"lyE3chznQHcSzMUpGaEf","timestamp":"2022-04-22 01:15:00","exam_id":26,"url":"https://www.examtopics.com/discussions/amazon/view/74070-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"poster":"knightknt","comment_id":"589635","content":"A Images passed to Amazon Rekognition API operations may be stored and used to improve the service unless you unless you have opted out by visiting the AI services opt-out policy page and following the process explained there\nhttps://docs.aws.amazon.com/rekognition/latest/dg/security-data-encryption.html","comments":[{"content":"So the answer is A","timestamp":"1653447180.0","comment_id":"607007","poster":"tgaos","upvote_count":"1"},{"poster":"BoroJohn","content":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html","upvote_count":"2","comment_id":"750177","timestamp":"1671476880.0"},{"content":"Yes, but server-side encryption doesn't protect at transit. Only client-side encryption can do it.","upvote_count":"2","poster":"mirik","comments":[{"poster":"mirik","timestamp":"1688812860.0","upvote_count":"4","comment_id":"946405","content":"Ok, I see \"encryption in transit\" mean HTTPS:\nAmazon Rekognition API endpoints only support secure connections over HTTPS. All communication is encrypted with Transport Layer Security (TLS)."}],"comment_id":"946402","timestamp":"1688812380.0"}],"upvote_count":"9","timestamp":"1650582900.0"},{"poster":"ovokpus","content":"Selected Answer: A\nAbsolutely A. Rekognition API endpoints only support secure connections over HTTPS and all communication is encrypted in transit with TLS","timestamp":"1656513180.0","upvote_count":"6","comment_id":"624704"},{"poster":"ef12052","comment_id":"1398794","content":"Selected Answer: A\nhttps://aws.amazon.com/rekognition/faqs/?nc1=h_ls","upvote_count":"1","timestamp":"1742025360.0"},{"comment_id":"1267250","timestamp":"1723824420.0","upvote_count":"1","poster":"72cc81d","content":"Selected Answer: B\nB is correct one"},{"timestamp":"1708446720.0","comment_id":"1154843","content":"Selected Answer: A\nclient-side encryption requires you to manage the encryption and decryption of your data yourself and is an overkill.\nWill go with Server side encryption. Recognition already encrypts data in transit","poster":"AIWave","upvote_count":"2"},{"poster":"kpr2022","content":"Selected Answer: B\nB \nhttps://docs.aws.amazon.com/rekognition/latest/dg/collections.html\nYou can opt-out of AI data usage of aws through organizations settings.","comment_id":"1132747","upvote_count":"1","timestamp":"1706293680.0"},{"content":"Selected Answer: A\nOption A is correct","poster":"Mickey321","timestamp":"1693121160.0","upvote_count":"1","comment_id":"991282"},{"upvote_count":"2","content":"Selected Answer: D\nAlso, when the images are used with Amazon Rekognition. they need to be encrypted in transit\n\nA server-site encryption doesn't encrypt images in transit. onyly when they are already uploaded to the S3. Only client-side encryption can encrypt the images before they are moving to AWS cloud.","poster":"mirik","timestamp":"1688804400.0","comment_id":"946323","comments":[{"comments":[{"comment_id":"1116400","timestamp":"1704688680.0","poster":"rav009","content":"client side encryption means the key is stored on the client side. AWS has no key, how can they train?","upvote_count":"1"}],"comment_id":"975895","poster":"kaike_reis","timestamp":"1691516700.0","upvote_count":"1","content":"You forgot about removing the possibility of Rekognition training."}]},{"content":"According to Rekognition FAQs, You may opt out of having your image and video inputs used to improve or develop the quality of Amazon Rekognition and other Amazon machine-learning/artificial-intelligence technologies by using an AWS Organizations opt-out policy.\nhttps://aws.amazon.com/rekognition/faqs/","timestamp":"1679169240.0","upvote_count":"1","comment_id":"843119","poster":"blanco750"},{"content":"how is it A???","timestamp":"1671155760.0","comment_id":"746688","upvote_count":"1","poster":"mlcert1"}],"unix_timestamp":1650582900,"question_images":[],"question_text":"A library is developing an automatic book-borrowing system that uses Amazon Rekognition. Images of library members' faces are stored in an Amazon S3 bucket.\nWhen members borrow books, the Amazon Rekognition CompareFaces API operation compares real faces against the stored faces in Amazon S3.\nThe library needs to improve security by making sure that images are encrypted at rest. Also, when the images are used with Amazon Rekognition. they need to be encrypted in transit. The library also must ensure that the images are not used to improve Amazon Rekognition as a service.\nHow should a machine learning specialist architect the solution to satisfy these requirements?","answers_community":["A (71%)","14%","14%"],"choices":{"A":"Enable server-side encryption on the S3 bucket. Submit an AWS Support ticket to opt out of allowing images to be used for improving the service, and follow the process provided by AWS Support.","C":"Switch to using the AWS GovCloud (US) Region for Amazon S3 to store images and for Amazon Rekognition to compare faces. Set up a VPN connection and only call the Amazon Rekognition API operations through the VPN.","D":"Enable client-side encryption on the S3 bucket. Set up a VPN connection and only call the Amazon Rekognition API operations through the VPN.","B":"Switch to using an Amazon Rekognition collection to store the images. Use the IndexFaces and SearchFacesByImage API operations instead of the CompareFaces API operation."},"topic":"1","isMC":true,"answer":"A","answer_ET":"A","question_id":42,"answer_description":"","answer_images":[]},{"id":"2J7JPyImzaIdvDcot2nF","url":"https://www.examtopics.com/discussions/amazon/view/74926-exam-aws-certified-machine-learning-specialty-topic-1/","answer":"D","timestamp":"2022-04-29 21:09:00","question_images":[],"choices":{"C":"Build a custom model in Amazon SageMaker to recognize the number of people in an image. Install cameras compatible with Amazon Kinesis Video Streams in the restaurant. Write an AWS Lambda function to take an image. Use the SageMaker endpoint to call the model to count people. Send an Amazon Simple Notification Service (Amazon SNS) notification if the line is too long.","A":"Install cameras compatible with Amazon Kinesis Video Streams to stream the data to AWS over the restaurant's existing internet connection. Write an AWS Lambda function to take an image and send it to Amazon Rekognition to count the number of faces in the image. Send an Amazon Simple Notification Service (Amazon SNS) notification if the line is too long.","B":"Deploy AWS DeepLens cameras in the restaurant to capture video. Enable Amazon Rekognition on the AWS DeepLens device, and use it to trigger a local AWS Lambda function when a person is recognized. Use the Lambda function to send an Amazon Simple Notification Service (Amazon SNS) notification if the line is too long.","D":"Build a custom model in Amazon SageMaker to recognize the number of people in an image. Deploy AWS DeepLens cameras in the restaurant. Deploy the model to the cameras. Deploy an AWS Lambda function to the cameras to use the model to count people and send an Amazon Simple Notification Service (Amazon SNS) notification if the line is too long."},"isMC":true,"topic":"1","question_text":"A company is building a line-counting application for use in a quick-service restaurant. The company wants to use video cameras pointed at the line of customers at a given register to measure how many people are in line and deliver notifications to managers if the line grows too long. The restaurant locations have limited bandwidth for connections to external services and cannot accommodate multiple video streams without impacting other operations.\nWhich solution should a machine learning specialist implement to meet these requirements?","answer_images":[],"discussion":[{"timestamp":"1651259340.0","poster":"spaceexplorer","content":"Selected Answer: D\nAnswer is D: \nA is not correct since restaurant has limited bandwidth\nB is not correct since cannot enable Rekognition service on DeepLens\nC is not correct the same reason as A","comment_id":"594656","comments":[{"comments":[{"upvote_count":"2","comment_id":"762535","poster":"RLai","timestamp":"1672472340.0","content":"In this blog, rekognition service is not running on Deeplens. It said \"After you deploy the sample object detection project into AWS DeepLens, you need to change the inference (edge) Lambda function to upload image frames to Amazon S3. ... and Rekognition would do its work from the Cloud to image frames on S3.\"... It would still consume lots of bandwidth. So B is NOT correct."}],"timestamp":"1657690560.0","content":"B is correct with Rekognition integrated with Deeplens and no extra configuration needed. (https://aws.amazon.com/blogs/machine-learning/building-a-smart-garage-door-opener-with-aws-deeplens-and-amazon-rekognition/)","poster":"muralipr","comment_id":"630785","upvote_count":"6"},{"poster":"dunhill","content":"I also agree with D. B is incorrect due to that it's no need to do \"person is recognized\". It just needs to count the number of people.","comment_id":"712413","timestamp":"1667748420.0","upvote_count":"2"}],"upvote_count":"17"},{"comment_id":"751225","poster":"wjohnny","comments":[{"upvote_count":"2","content":"aws doesn't allow use in production but in evaluation. can we accept counting number of people as an evaluation?","poster":"alp_ileri","timestamp":"1678255980.0","comment_id":"832585"},{"timestamp":"1674890040.0","comment_id":"790373","upvote_count":"3","content":"https://aws.amazon.com/deeplens/device-terms-of-use/","poster":"BTRYING"}],"timestamp":"1671554760.0","content":"Selected Answer: C\nAWS will not recommend to use Deeplense in production. From https://aws.amazon.com/deeplens/device-terms-of-use/","upvote_count":"8"},{"timestamp":"1739703900.0","content":"Selected Answer: A\nSorry guys, not B, C or D. Reasons? Deeplens is a deprecated product, not suitable for being used in real production environment (as clearly stated in its T&C), thus B & D option are out.\n\nBetween A & C, the clearly option is A. C implies the creation of a custom ML model. Making a custom model is very expensive, time consuming, error prone and a highly specialized task. Option A uses a well-known, key-in-hand service as AWS Rekognition which implies very little effort in comparison with uses a custom-made one. \n\nI know, this option does not follow the flock, but I think that I am right.","comment_id":"1357213","upvote_count":"3","poster":"santi1975"},{"comment_id":"1299670","content":"Selected Answer: B\nYes, Amazon Rekognition can be integrated with AWS DeepLens. You can use AWS DeepLens to capture video and perform initial processing on the device. For more advanced image and video analysis, you can send frames from DeepLens to Amazon Rekognition","poster":"MultiCloudIronMan","timestamp":"1729255440.0","upvote_count":"1"},{"content":"Selected Answer: D\nThe best solution for building a line-counting application for use in a quick-service restaurant is to usethe following steps:Build a custom model in Amazon SageMaker to recognize the number of people in an image. AmazonSageMaker is a fully managed service that provides tools and workflows for building, training, anddeploying machine learning models. A custom model can be tailored to the specific use case of line\u0002counting and achieve higher accuracy than a generic model1 Deploy AWS DeepLens cameras in therestaurant to capture video","upvote_count":"3","comment_id":"1147536","poster":"kyuhuck","timestamp":"1707671940.0"},{"poster":"CloudHandsOn","content":"Selected Answer: B\nB. AWS DeepLens with Local Amazon Rekognition and AWS Lambda: AWS DeepLens is designed for local processing and can run models at the edge (i.e., on the device itself). This setup would enable local analysis of the video feed without the need to stream the video to the cloud, thus conserving bandwidth. Amazon Rekognition and Lambda can then be used to analyze the footage and send notifications. This option aligns well with the bandwidth limitations.\n\nD. Custom Model on AWS DeepLens with AWS Lambda: Deploying a custom model built in SageMaker to AWS DeepLens allows for local processing of video data. This option also avoids the bandwidth issue by processing data on the device. However, developing a custom model might be more complex than using pre-built solutions like Amazon Rekognition.","timestamp":"1704815280.0","comment_id":"1117616","upvote_count":"1"},{"poster":"vikaspd","comment_id":"1086873","content":"Selected Answer: D\nRekognition is a managed service. It uses API's and can't be deployed locally on devices. What we need here is local inference on the camera. AWS DeepLens comes pre-installed with a high performance, efficient, optimized inference engine for deep learning using Apache MXNet.","upvote_count":"2","timestamp":"1701614640.0"},{"comment_id":"1046583","upvote_count":"1","content":"Selected Answer: A\nI would go with A,\nAs DeepLenght is not for production workloads, we are left with A or C. A requires less effort.","poster":"DimLam","timestamp":"1697606220.0"},{"timestamp":"1697195040.0","comment_id":"1042599","content":"Selected Answer: B\nB : https://aws.amazon.com/ko/blogs/machine-learning/building-a-smart-garage-door-opener-with-aws-deeplens-and-amazon-rekognition/","upvote_count":"1","poster":"seifskl"},{"content":"Selected Answer: D\nBased on the requirements, the best solution is option D. This option uses AWS DeepLens cameras to capture video and process it locally on the device, without sending any video streams to external services. This reduces the bandwidth consumption and avoids impacting other operations in the restaurant. The option also uses a custom model built in Amazon SageMaker to recognize the number of people in an image, which can be more accurate and tailored to the specific use case than a generic face detection model. The option also deploys an AWS Lambda function to the cameras to use the model to count people and send an Amazon Simple Notification Service (Amazon SNS) notification if the line is too long.","upvote_count":"1","comment_id":"991287","poster":"Mickey321","timestamp":"1693121400.0"},{"poster":"ccpmad","timestamp":"1690879380.0","upvote_count":"1","content":"Selected Answer: D\nit is D. \"The restaurant locations have limited bandwidth for connections to external services and cannot accommodate multiple video streams without impacting other operations.\"\nSo, using Amazon Kinesis Video Streams is not a solution here.\nOk, DeepLens dissapears in 2024...but this questions is for 2022...\nIn the real world, the restaurant would buy good signal internet and use answer C, which is better solution.","comment_id":"968893"},{"comment_id":"963358","upvote_count":"1","poster":"TQM__9MD","content":"Selected Answer: C\nC is Answer","timestamp":"1690347420.0"},{"timestamp":"1688822940.0","content":"Selected Answer: C\nAWS DeepLens will reach end-of-ilfe in 31/01/2024 so, I don't think this question will even appear in the exam.","upvote_count":"5","comment_id":"946518","poster":"mirik"},{"upvote_count":"3","content":"Selected Answer: D\nDeeplens + lambda + model inference","poster":"Mllb","timestamp":"1680534240.0","comment_id":"860054"},{"content":"After giving this some thought, I am thinking D. Tricky, my initial answer was C. But D is a better solution - given DeepLens and counting the number of people.","poster":"fez_2312","upvote_count":"1","comment_id":"840971","timestamp":"1678971720.0"},{"content":"Selected Answer: B\nhttps://aws.amazon.com/ko/blogs/machine-learning/building-a-smart-garage-door-opener-with-aws-deeplens-and-amazon-rekognition/","poster":"SANDEEP_AWS","comment_id":"837596","timestamp":"1678678560.0","comments":[{"comment_id":"839605","timestamp":"1678864080.0","poster":"Amit11011996","upvote_count":"1","content":"According to this link,\nAnswer should be D, because we can directly deploy model in Deep lense to count the number of people instead a use of rekognition."}],"upvote_count":"3"},{"poster":"lizlizliz","content":"https://aws.amazon.com/blogs/machine-learning/optimize-workforce-in-your-store-using-amazon-rekognition/\nB","timestamp":"1671216600.0","comment_id":"747509","upvote_count":"3"},{"poster":"Ob1KN0B","content":"Selected Answer: B\nB is the most suitable answer. A and C can be ignored because of requirement to use Amazon Video Streams which will not go well with low internet bandwidth. DeepLens is already compatible with Rekognition so better to use it rather than creating a custom model on SageMaker.","upvote_count":"6","comment_id":"649357","timestamp":"1660987920.0","comments":[{"poster":"Ob1KN0B","timestamp":"1661020320.0","content":"https://aws.amazon.com/deeplens/community-projects/Customer_Counter/","comment_id":"649519","upvote_count":"1"}]},{"comment_id":"633530","timestamp":"1658231940.0","poster":"KlaudYu","content":"Selected Answer: B\nB is possible. not stream only send detected.\nhttps://aws.amazon.com/ko/blogs/machine-learning/building-a-smart-garage-door-opener-with-aws-deeplens-and-amazon-rekognition/","upvote_count":"2"},{"poster":"f4bi4n","comment_id":"625818","timestamp":"1656688920.0","content":"Selected Answer: C\nI would go with C. It seems that it not transfers the hole stream and all others make no sense. AWS will never recommend to use Deeplense in production. From https://aws.amazon.com/deeplens/device-terms-of-use/\n\na. Permitted Uses and Limited Licence. Subject to your compliance with this Agreement, and\nyour payment of any applicable fees: (i) you may use the AWS DeepLens Device for personal,\neducational, evaluation, development, and testing purposes, and not to process your production workloads;","upvote_count":"5"},{"timestamp":"1651501260.0","comment_id":"596080","content":"I would go with C. Eliminate A because it won't be able to support/handle video streams. Eliminate DeepLens options\n due to limited bandwidth and no support for external connections. SIDE NOTE: AWS DeepLens integrates with Amazon Rekognition for advanced image analysis, Amazon SageMaker for training models, and with Amazon Polly to create speech-enabled projects. The device also connects securely to AWS IoT, Amazon SQS, Amazon SNS, Amazon S3, Amazon DynamoDB, and more.","upvote_count":"1","poster":"rohit07cf"}],"answer_description":"","exam_id":26,"question_id":43,"answer_ET":"D","answers_community":["D (42%)","C (30%)","B (22%)","6%"],"unix_timestamp":1651259340},{"id":"qGlBu4XdAO61cTZefedk","exam_id":26,"answer_ET":"D","isMC":true,"topic":"1","question_images":[],"discussion":[{"upvote_count":"14","timestamp":"1682301240.0","comment_id":"590848","content":"Selected Answer: D\nI believe this is a problem to do with scaling out (increasing the number of instances), cooldown period should be increased.\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html","poster":"cron0001"},{"content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/machine-learning/configuring-autoscaling-inference-endpoints-in-amazon-sagemaker/","comment_id":"1046594","poster":"DimLam","upvote_count":"1","timestamp":"1729230240.0"},{"comment_id":"991288","upvote_count":"1","content":"Selected Answer: D\nOption D","timestamp":"1724743860.0","poster":"Mickey321"},{"comments":[{"comment_id":"810049","poster":"AjoseO","upvote_count":"2","content":"Option D, which suggests increasing the cooldown period for the scale-out activity, could potentially help to address this issue by ensuring that the new instances are not launched too quickly. \n\nOption A, which suggests decreasing the cooldown period for the scale-in activity and increasing the maximum capacity of instances, is not an appropriate solution to the problem described. Decreasing the cooldown period for scale-in activity would result in instances being terminated too quickly, and increasing the maximum capacity of instances would not necessarily prevent new instances from being launched too quickly.","timestamp":"1708036380.0"}],"content":"Selected Answer: D\nThe issue is related to scaling out, specifically the fact that new instances are being launched before the existing ones are ready.\n\nTo address this issue, the ML team could consider increasing the minimum number of instances, reducing the target value for CPU utilization, or increasing the warm-up time for the instances. These actions can help to ensure that new instances are not launched until the existing ones have reached a stable state, which can prevent performance issues and ensure the reliability of the service.","comment_id":"810047","timestamp":"1708036260.0","poster":"AjoseO","upvote_count":"2"},{"poster":"ystotest","upvote_count":"1","comment_id":"726091","timestamp":"1700847960.0","content":"Selected Answer: D\nAgreed with D. should be increased not decreased"},{"upvote_count":"1","comment_id":"677033","timestamp":"1695466980.0","poster":"ryuhei","content":"Selected Answer: D\nAnswer is \"D\""},{"timestamp":"1683841440.0","poster":"SDikeman62","content":"Selected Answer: D\nDefinitely D.","upvote_count":"2","comment_id":"600334"}],"choices":{"D":"Increase the cooldown period for the scale-out activity.","B":"Replace the current endpoint with a multi-model endpoint using SageMaker.","C":"Set up Amazon API Gateway and AWS Lambda to trigger the SageMaker inference endpoint.","A":"Decrease the cooldown period for the scale-in activity. Increase the configured maximum capacity of instances."},"question_id":44,"answers_community":["D (100%)"],"answer_images":[],"question_text":"A company has set up and deployed its machine learning (ML) model into production with an endpoint using Amazon SageMaker hosting services. The ML team has configured automatic scaling for its SageMaker instances to support workload changes. During testing, the team notices that additional instances are being launched before the new instances are ready. This behavior needs to change as soon as possible.\nHow can the ML team solve this issue?","answer":"D","timestamp":"2022-04-24 03:54:00","url":"https://www.examtopics.com/discussions/amazon/view/74280-exam-aws-certified-machine-learning-specialty-topic-1/","answer_description":"","unix_timestamp":1650765240},{"id":"bqWNK1dZ6RcaZ5eNWkF8","answer_ET":"C","question_id":45,"answers_community":["C (58%)","A (42%)"],"choices":{"B":"Configure two SageMaker hosted endpoints that serve the different versions of the model. Create an Application Load Balancer (ALB) to route traffic to both endpoints based on the TargetVariant query string parameter. Reconfigure the app to send the TargetVariant query string parameter for users who subscribed to the preview feature. When the new version of the model is ready for release, change the ALB's routing algorithm to weighted until all users have the updated version.","A":"Update the ProductionVariant data type with the new version of the model by using the CreateEndpointConfig operation with the InitialVariantWeight parameter set to 0. Specify the TargetVariant parameter for InvokeEndpoint calls for users who subscribed to the preview feature. When the new version of the model is ready for release, gradually increase InitialVariantWeight until all users have the updated version.","C":"Update the DesiredWeightsAndCapacity data type with the new version of the model by using the UpdateEndpointWeightsAndCapacities operation with the DesiredWeight parameter set to 0. Specify the TargetVariant parameter for InvokeEndpoint calls for users who subscribed to the preview feature. When the new version of the model is ready for release, gradually increase DesiredWeight until all users have the updated version.","D":"Configure two SageMaker hosted endpoints that serve the different versions of the model. Create an Amazon Route 53 record that is configured with a simple routing policy and that points to the current version of the model. Configure the mobile app to use the endpoint URL for users who subscribed to the preview feature and to use the Route 53 record for other users. When the new version of the model is ready for release, add a new model version endpoint to Route 53, and switch the policy to weighted until all users have the updated version."},"topic":"1","answer":"C","answer_description":"","timestamp":"2022-04-29 19:49:00","question_text":"A telecommunications company is developing a mobile app for its customers. The company is using an Amazon SageMaker hosted endpoint for machine learning model inferences.\nDevelopers want to introduce a new version of the model for a limited number of users who subscribed to a preview feature of the app. After the new version of the model is tested as a preview, developers will evaluate its accuracy. If a new version of the model has better accuracy, developers need to be able to gradually release the new version for all users over a fixed period of time.\nHow can the company implement the testing model with the LEAST amount of operational overhead?","isMC":true,"exam_id":26,"discussion":[{"upvote_count":"19","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html","comments":[{"comment_id":"611848","content":"after reviewing it maybe C not A","timestamp":"1654436340.0","upvote_count":"10","poster":"ayatkhrisat"},{"content":"https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_endpoints/a_b_testing/a_b_testing.html\n\nShould be A","poster":"RLai","comment_id":"750559","timestamp":"1671517500.0","upvote_count":"2"}],"comment_id":"597452","poster":"ayatkhrisat","timestamp":"1651782180.0"},{"timestamp":"1651254540.0","upvote_count":"11","poster":"spaceexplorer","comment_id":"594626","content":"Selected Answer: C\nAnswer is C, hosting two models under single endpoint has less operational overheads than two hosting endpoints"},{"upvote_count":"1","poster":"ef12052","timestamp":"1744033200.0","content":"Selected Answer: C\nin option A it's mentioned that we set initial_weight to 0 which isn't true as the value should be 1 -> C","comment_id":"1558585"},{"upvote_count":"2","comment_id":"1299699","timestamp":"1729258680.0","content":"Selected Answer: A\nWhile Option C is a viable method, Option A is generally more straightforward and aligns well with common practices for deploying and managing model versions in SageMaker. Supported by Copilot","poster":"MultiCloudIronMan"},{"timestamp":"1723639620.0","poster":"ML_2","comment_id":"1265752","content":"Selected Answer: A\nThe Answer is A. \nThe question says \"Developers want to introduce a new version of the model for a limited number of users who subscribed to a...\" In order to introduce a new production version with least overhead you have to create a production variant by using CreateEndpointConfig operation and set the InitialVariantWeight to 0. You then specify the TargetVariant parameter for InvokeEndpoint calls for users who subscribed to the preview feature and gradually update the weight.\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html\npreview feature of the app","upvote_count":"2"},{"content":"Selected Answer: A\n-CreateEndPointConfig with initial weight to 0 prohibits any traffic to new variant\n- TargetVariant Parameter in the endpoint calls made by selected users ensures new variant be used\n- Change of InitialWeight causes gradual release of new variant","timestamp":"1708477380.0","poster":"AIWave","comment_id":"1155116","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nObviously C","timestamp":"1699032480.0","comment_id":"1061629","poster":"giustino98"},{"comment_id":"1046651","timestamp":"1697612400.0","upvote_count":"1","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/deployment-best-practices.html\n\nYou can modify an endpoint without taking models that are already deployed into production out of service. For example, you can add new model variants, update the ML Compute instance configurations of existing model variants, or change the distribution of traffic among model variants. To modify an endpoint, you provide a new endpoint configuration. SageMaker implements the changes without any downtime. For more information see, UpdateEndpoint and UpdateEndpointWeightsAndCapacities.\nAccording to this doc, new variants can be deployed with UpdateEndpoint, and weights can be updated with UpdateEndpointWeightsAndCapacities. \n\nThough for using UpdateEndpoint we need to create an endpoint config. \nI will go with C","poster":"DimLam"},{"comment_id":"997173","upvote_count":"1","content":"Selected Answer: A\nThe company can implement the testing model with the least amount of operational overhead by using Option A. The developers can update the ProductionVariant data type with the new version of the model by using the CreateEndpointConfig operation with the InitialVariantWeight parameter set to 0. They can specify the TargetVariant parameter for InvokeEndpoint calls for users who subscribed to the preview feature. When the new version of the model is ready for release, they can gradually increase InitialVariantWeight until all users have the updated version","poster":"Shenannigan","timestamp":"1693694100.0"},{"timestamp":"1693126080.0","upvote_count":"1","poster":"Mickey321","comment_id":"991305","content":"Selected Answer: C\nThe best option for the company to implement the testing model with the least amount of operational overhead is option C. Option C uses the SageMaker feature of production variants, which allows the company to test multiple models on a single endpoint and control the traffic distribution between them. By setting the DesiredWeight parameter to 0 for the new version of the model, the company can ensure that only users who subscribed to the preview feature will invoke the new version by specifying the TargetVariant parameter. When the new version of the model is ready for release, the company can gradually increase the DesiredWeight parameter until all users have the updated version. This option minimizes the operational overhead by avoiding the need to create and manage additional endpoints, load balancers, or DNS records."},{"poster":"kukreti18","upvote_count":"2","timestamp":"1685959800.0","content":"C is correct.\nThe existing model will be updated using parameter DesiredWeightAndCapacity for new production variant and lead to less operational effort.","comment_id":"915310"},{"poster":"dkx","comment_id":"897858","content":"This one is tricky, but I think it is testing the difference between UpdateEndpointWeightsAndCapacities and ProductionVariant\n\nUpdateEndpointWeightsAndCapacities: \nUpdates variant weight of one or more variants associated with an existing endpoint, or capacity of one variant associated with an existing endpoint\n\nhttps://docs.aws.amazon.com/sagemaker/latest/APIReference/API_UpdateEndpointWeightsAndCapacities.html\n\nProductionVariant: \nIdentifies a model that you want to host and the resources chosen to deploy for hosting it. If you are deploying multiple models, tell SageMaker how to distribute traffic among the models by specifying variant weights.\n\nhttps://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ProductionVariant.html\n\nSo it must be A, because the variant must exist before it is updated\n\nThis link gave me confidence to choose A\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html","timestamp":"1684091640.0","upvote_count":"4"},{"comment_id":"855705","poster":"Zhechen0912","upvote_count":"3","content":"Selected Answer: C\nI agree with C.","timestamp":"1680177660.0"},{"poster":"SANDEEP_AWS","timestamp":"1678679640.0","content":"Selected Answer: C\nPlease see step 4: https://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html & in option A it's mentioned that we set initial_weight to 0 which isn't true as the value should be 1.","upvote_count":"3","comment_id":"837611"},{"timestamp":"1658836860.0","content":"Selected Answer: C\nI did not found the InitialVariantWeight, only DesiredWeight, therefore is C:\nhttps://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DesiredWeightAndCapacity.html","poster":"matteocal","upvote_count":"5","comment_id":"637384"},{"timestamp":"1658228400.0","comment_id":"633502","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html\nStep 4: Increase traffic to the best model\nNow that we have determined that Variant2 performs better than Variant1, we shift more traffic to it. We can continue to use TargetVariant to invoke a specific model variant, but a simpler approach is to update the weights assigned to each variant by calling UpdateEndpointWeightsAndCapacities.","upvote_count":"8","comments":[{"content":"Update should be the correct action to this change.","timestamp":"1668132240.0","upvote_count":"2","comment_id":"715693","poster":"VinceCar"}],"poster":"KlaudYu"}],"answer_images":[],"unix_timestamp":1651254540,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/74921-exam-aws-certified-machine-learning-specialty-topic-1/"}],"exam":{"isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":369,"provider":"Amazon","isBeta":false,"id":26,"name":"AWS Certified Machine Learning - Specialty","isMCOnly":false},"currentPage":9},"__N_SSP":true}