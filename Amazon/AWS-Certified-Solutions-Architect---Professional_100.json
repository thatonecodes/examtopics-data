{"pageProps":{"questions":[{"id":"YhZuxR0bcZBlHZuIgsMm","choices":{"A":"Trigger AWS Lambda based on an S3 event notification to create additional metadata using Amazon Rekognition. Use Amazon DynamoDB to store the metadata and Amazon ES to create an index. Use a web front-end to provide search capabilities backed by Amazon ES.","D":"Trigger AWS Lambda based on an S3 event notification to create additional metadata using Amazon Rekognition. Use Amazon RDS MySQL Multi-AZ to store the metadata information and use Lambda to create an index. Use a web front-end with search capabilities backed by Lambda.","C":"Start an Amazon SQS queue based on S3 event notifications. Then have Amazon SQS send the metadata information to Amazon DynamoDB. An application running on Amazon EC2 extracts data from Amazon Rekognition using the API and adds data to DynamoDB and Amazon ES. Use a web front-end to provide search capabilities backed by Amazon ES.","B":"Use Amazon Kinesis to stream data based on an S3 event. Use an application running in Amazon EC2 to extract metadata from the images. Then store the data on Amazon DynamoDB and Amazon CloudSearch and create an index. Use a web front-end with search capabilities backed by CloudSearch."},"discussion":[{"content":"A is answer","timestamp":"1633236120.0","upvote_count":"14","poster":"nitinz","comment_id":"317729"},{"upvote_count":"1","poster":"SkyZeroZx","content":"Selected Answer: A\nA - It makes no sense to use a relational database for this use case.","timestamp":"1687456980.0","comment_id":"930876"},{"comment_id":"698190","content":"Selected Answer: A\nA is the answer","timestamp":"1666093740.0","poster":"Vizz5585","upvote_count":"1"},{"poster":"joanneli77","content":"I may need to search based on more than one metadata field. DynamoDB searches can't do every field. RDS. I literally had this use case IRL. D.","upvote_count":"1","comment_id":"693221","timestamp":"1665589500.0"},{"comment_id":"686564","upvote_count":"1","timestamp":"1664944260.0","poster":"aqiao","content":"why need ES, why not search from ddb directly?"},{"poster":"epomatti","upvote_count":"1","comment_id":"660651","content":"Selected Answer: A\nA - It makes no sense to use a relational database for this use case.\n\nNot sure why ES, it should be CloudSearch??","timestamp":"1662426180.0"},{"content":"Selected Answer: A\nA is answer","upvote_count":"1","timestamp":"1651380960.0","poster":"pankajrawat","comment_id":"595436"},{"upvote_count":"1","content":"A it is","comment_id":"515263","timestamp":"1641163920.0","poster":"Buggie"},{"comment_id":"511172","poster":"RVivek","upvote_count":"1","timestamp":"1640699880.0","content":"A is correct\nhttps://github.com/aws-samples/lambda-refarch-imagerecognition"},{"timestamp":"1638791580.0","upvote_count":"1","content":"A. Trigger AWS Lambda based on an S3 event notification to create additional metadata using Amazon Rekognition. Use Amazon DynamoDB to store the metadata and Amazon ES to create an index. Use a web front-end to provide search capabilities backed by Amazon ES.","comment_id":"495093","poster":"cldy"},{"comment_id":"494644","upvote_count":"2","content":"A is right","timestamp":"1638736620.0","poster":"AzureDP900"},{"comment_id":"491491","content":"A is more cost effective and no need of streams!","upvote_count":"1","poster":"AzureDP900","timestamp":"1638351900.0"},{"comment_id":"488845","upvote_count":"1","poster":"backfringe","timestamp":"1638076020.0","content":"I'd go with A\nDynamoDB and Rekognition"},{"timestamp":"1637893320.0","content":"Selected Answer: A\nA is correct.","comment_id":"487045","upvote_count":"1","poster":"RVD"},{"poster":"backfringe","upvote_count":"1","content":"I go with A","comment_id":"484916","timestamp":"1637660400.0"},{"timestamp":"1637453400.0","upvote_count":"1","comment_id":"482933","poster":"acloudguru","content":"Selected Answer: A\nrefer to the blog.https://aws.amazon.com/blogs/machine-learning/find-distinct-people-in-a-video-with-amazon-rekognition/"},{"comment_id":"450787","poster":"Kopa","upvote_count":"1","content":"Im going for A, Dynamo DB and Amazon Rekognition makes the difference.","timestamp":"1635442200.0"},{"comment_id":"411147","upvote_count":"1","timestamp":"1635345840.0","poster":"WhyIronMan","content":"I'll go with A"},{"content":"A is best answer","timestamp":"1634598480.0","upvote_count":"1","poster":"vkbajoria","comment_id":"366743"},{"upvote_count":"1","poster":"victordun","comment_id":"356797","content":"A is the answer\nD is wrong as Lambda doesn't have search capabilities like ES or CloudSearch","timestamp":"1634231160.0"},{"poster":"Waiweng","content":"A is the answer","comment_id":"348260","timestamp":"1634046600.0","upvote_count":"1"},{"comment_id":"346740","timestamp":"1633277580.0","poster":"blackgamer","upvote_count":"1","content":"A is the answer"},{"poster":"CarisB","comment_id":"337517","content":"I also support A. For instance: https://aws.amazon.com/blogs/machine-learning/build-your-own-face-recognition-service-using-amazon-rekognition/","timestamp":"1633236540.0","upvote_count":"3"},{"upvote_count":"2","comment_id":"316573","timestamp":"1633163040.0","poster":"awsexamprep47","content":"A is the answer\nS-3 Event Notification Lambda to trigger AWS Rekognition & DynamoDB to store metadata"},{"timestamp":"1632442980.0","upvote_count":"1","poster":"Nguyenhau","comment_id":"309730","content":"I go with A"},{"timestamp":"1632260700.0","poster":"ajeeshb","upvote_count":"1","content":"Answer is A","comment_id":"309288"}],"exam_id":32,"answer_ET":"A","answer_description":"","answer":"A","question_id":496,"url":"https://www.examtopics.com/discussions/amazon/view/46810-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"question_text":"A photo-sharing and publishing company receives 10,000 to 150,000 images daily. The company receives the images from multiple suppliers and users registered with the service. The company is moving to AWS and wants to enrich the existing metadata by adding data using Amazon Rekognition.\nThe following is an example of the additional data:\n//IMG//\n\nAs part of the cloud migration program, the company uploaded existing image data to Amazon S3 and told users to upload images directly to Amazon S3.\nWhat should the Solutions Architect do to support these requirements?","topic":"1","question_images":["https://www.examtopics.com/assets/media/exam-media/04241/0034700001.png"],"timestamp":"2021-03-13 01:12:00","answer_images":[],"answers_community":["A (100%)"],"unix_timestamp":1615594320},{"id":"cNAdwroNSY906VBInCDT","question_images":[],"topic":"1","timestamp":"2019-09-10 10:40:00","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/4994-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["D (54%)","A (46%)"],"discussion":[{"upvote_count":"18","poster":"AWSPro24","timestamp":"1632844320.0","comment_id":"42658","comments":[{"upvote_count":"2","comment_id":"71525","poster":"Smart","timestamp":"1633063380.0","content":"Can \"rewrite the app\" means switching from VDI to App Streaming?"}],"content":"I believe the answer should be A. There are examples of filling in the dynamic elements of S3 websites with Lambda. \n\nhttps://aws.amazon.com/blogs/architecture/create-dynamic-contact-forms-for-s3-static-websites-using-aws-lambda-amazon-api-gateway-and-amazon-ses/\nhttps://aws.amazon.com/getting-started/projects/build-serverless-web-app-lambda-apigateway-s3-dynamodb-cognito/\n\nI feel the words \"wants to rewrite the application\" are key. They aren't looking to move the same code to AppStreah which is App streaming, similar to VDI but scoped at the App level. \n\nB - EC2 will be more expensive and \"EC2 user data\" is just silly and wrong\nC - RDS isn't the best choice for a user store and there is no blue/green requirement\nD - Don't believe AppStream can be launched from S3. Too Dynamic. Might be possible with Lambda."},{"comments":[{"poster":"timmysixstrings","comment_id":"733940","timestamp":"1670001660.0","upvote_count":"1","content":"I agree the answer is A. But per your explanation about D, using RDS auth to secure access to S3 is possible. Once authenticated the backend can provide S3-signed URLs. The bucket resource policy could then restrict access to the EC2 instance role"}],"timestamp":"1634194920.0","comment_id":"137732","content":"Answer: A\nA - correct - solution will work and with low cost and management. No infrastructure to manage.\nB - incorrect - cost of running and managing infrastructure expensive - not easy to maintain\nC - incorrect - cost of running and managing infrastructure expensive - blue/green more so which requires the database to be external to the environment or data will be lost.\nD - incorrect - RDS for authentication/authorisation to provide secure access to S3? possible? plus cost of running infrastructure, and AppStream is the same tech as the current streaming solution\n\nLight reading\nhttps://stackoverflow.com/questions/49782492/cognito-user-authorization-to-access-an-s3-object\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_s3_cognito-bucket.html","poster":"inf","upvote_count":"9"},{"timestamp":"1736869320.0","content":"Selected Answer: D\nD is correct. Option A requires API Gateway","upvote_count":"1","poster":"spinatram","comment_id":"1340413"},{"timestamp":"1687457280.0","comment_id":"930881","comments":[{"comment_id":"930882","poster":"SkyZeroZx","timestamp":"1687457280.0","content":"The architecture is also easy to manage because it uses AWS CloudFormation templates. AWS CloudFormation templates are a way to define and deploy AWS resources in a repeatable and consistent way. This makes it easy for the Solutions Architect to make changes to the architecture in the future.\n\nThe other options are not as cost-effective, secure, or easy to manage as option A. Option B uses Amazon EC2, which is a more expensive option than Amazon S3. Option C uses AWS Elastic Beanstalk, which is a managed platform for deploying and scaling web applications. However, Elastic Beanstalk is not as cost-effective as option A because it charges for the EC2 instances that are used to run the application. Option D uses Amazon AppStream, which is a managed service for streaming applications to users' desktops. However, AppStream is not as secure as option A because it does not use Amazon Cognito to manage user authentication and authorization.","upvote_count":"1"}],"upvote_count":"1","content":"Selected Answer: A\nThe answer is A. Run a website from an Amazon S3 bucket with a separate S3 bucket for images and messaging data. Call AWS Lambda functions from embedded JavaScript to manage the dynamic content, and use Amazon Cognito for user and sharing management.\n\nThis architecture is the most cost-effective because it uses serverless technologies like Amazon S3, AWS Lambda, and Amazon Cognito. These technologies are pay-as-you-go, so the Solutions Architect will only be charged for the resources that they use. The architecture is also secure because it uses Amazon Cognito to manage user authentication and authorization. Amazon Cognito provides a number of features that help to protect user data, such as multi-factor authentication and session management.","poster":"SkyZeroZx"},{"content":"Selected Answer: D\nSaaS app \"offers both security and ease of management\" == AppStream\nImagine you run such SaaS app from static website where all the logic exists in the user browser. not a good idea in terms of security","timestamp":"1681391880.0","upvote_count":"1","poster":"dev112233xx","comment_id":"869435"},{"timestamp":"1668267180.0","comment_id":"716785","upvote_count":"1","content":"Selected Answer: A\nAns: A\nYou can Invoke a Lambda function from a browser using the SDK for JavaScript. \n\nhttps://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/cross_LambdaForBrowser_javascript_topic.html","poster":"et22s"},{"comment_id":"715382","content":"Selected Answer: A\nDefinitely A as it is the simplest one.","poster":"MarianKowalskiExam","upvote_count":"1","timestamp":"1668097500.0"},{"timestamp":"1667119200.0","upvote_count":"1","content":"Selected Answer: A\nA) Java script trigger lambda, S3 is cost effective, cognito for auth\nhttps://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/using-lambda-functions.html\nB,C) costly and others explained already\nD) App stream support user pool /sso/federated users not RDS, not cheap although pasy as u go, ques wants to refactor app from desktop not migrate to another desktop steaming solution","poster":"nsvijay04b1","comment_id":"707707"},{"upvote_count":"1","timestamp":"1666715460.0","comment_id":"704029","content":"Selected Answer: A\nA is right. Easy question ya 3azeezy","poster":"kharakbeer"},{"poster":"joanneli77","content":"A has no database of record - where is the data? I went with D since it has a DB.","upvote_count":"2","comment_id":"693227","timestamp":"1665589800.0"},{"poster":"tomosabc1","timestamp":"1664718060.0","content":"Selected Answer: D\nA(wrong): AWS Lambda function cannot be called by embedded JavaScript directly, API Gateway is required, which is not mentioned by the option.\nB/C(wrong): These two options involve the use of EC2(EC2 is in used even in the case of Elastic Beanstalk), not cost effective, compared with D.","comment_id":"684840","upvote_count":"2"},{"upvote_count":"3","timestamp":"1664718000.0","comments":[{"upvote_count":"1","content":"Someone might argue that, as the question mentioned, the development operation team wants to move away from using VDI...I doubt whether moving away from VDI means the same as moving away from AppStream 2.0.","comment_id":"684842","poster":"tomosabc1","timestamp":"1664718120.0"},{"upvote_count":"3","poster":"tomosabc1","comment_id":"684839","timestamp":"1664718000.0","content":"D(correct): AppStream 2.0 manages the AWS resources required to host and run your applications, scales automatically, and provides access to your users on demand...With AppStream 2.0, you can easily add your existing desktop applications to AWS and enable your users to instantly stream them(*** ease of management ***)...Your applications run on AWS compute resources, and data is never stored on users' devices, which means they always get a high performance, secure experience((*** secure ***)). Unlike traditional on-premises solutions for desktop application streaming, AppStream 2.0 offers pay-as-you-go pricing, with no upfront investment and no infrastructure to maintain(*** Cost effective ***). You can scale instantly and globally, ensuring that your users always have the best possible experience.\nhttps://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html"}],"content":"Selected Answer: D\nA(wrong): AWS Lambda function cannot be called by embedded JavaScript directly, API Gateway is required, which is not mentioned by the option.\nB/C(wrong): These two options involve the use of EC2(EC2 is in used even in the case of Elastic Beanstalk), not cost effective, compared with D.","poster":"tomosabc1","comment_id":"684838"},{"upvote_count":"1","poster":"Dionenonly","comment_id":"671839","content":"Selected Answer: A\nA is the answer for me","timestamp":"1663455000.0"},{"comments":[{"timestamp":"1640305620.0","upvote_count":"1","comment_id":"508206","content":"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/using-lambda-functions.html","poster":"vbal"}],"content":"A is the right Answer. Cognito Identity Pool would help run Lambda using AWS SDK for Javascript.","timestamp":"1640304960.0","comment_id":"508200","upvote_count":"1","poster":"vbal"},{"content":"A. Run a website from an Amazon S3 bucket with a separate S3 bucket for images and messaging data. Call AWS Lambda functions from embedded JavaScript to manage the dynamic content, and use Amazon Cognito for user and sharing management.","upvote_count":"1","poster":"cldy","timestamp":"1639060320.0","comment_id":"497799"},{"timestamp":"1638352200.0","comment_id":"491497","upvote_count":"1","poster":"AzureDP900","content":"A is right because they want to discontinue VDI solutions."},{"content":"A is correct","comment_id":"450672","poster":"AWSum1","upvote_count":"1","timestamp":"1636287780.0"},{"content":"Option A is wrong. JavaScript is run on client-side and cannot load Lambda without api gateway. They don't mention api gateway anywhere.\nI prefer option D. Even though it's not perfect. Considering the question require \"offers both security and ease of management\", It matches AppStream better than others.","poster":"Bigbearcn","timestamp":"1635939300.0","comment_id":"450547","upvote_count":"2"},{"content":"A. \nCognito as a keyword narrows down to A/B. CloudFormation is not the case so not B.","timestamp":"1635721080.0","poster":"38745","comment_id":"449239","upvote_count":"1"},{"upvote_count":"1","poster":"tgv","timestamp":"1635711660.0","comment_id":"435731","content":"AAA\n---"},{"upvote_count":"1","poster":"DerekKey","comment_id":"425251","content":"A should be OK \nB is wrong - \"that offers both security and ease of management\" -> \"EC2 user data to install and configure the application\"\nC is wrong - \"Amazon RDS database for user accounts and sharing\"\nD is wrong - \"The Development Operations team wants to move away from using VDI and wants to rewrite the application.\"","timestamp":"1635605460.0"},{"comment_id":"411152","poster":"WhyIronMan","upvote_count":"1","content":"I'll go with A","timestamp":"1635569400.0"},{"content":"it's A","timestamp":"1635550200.0","poster":"Waiweng","comment_id":"348263","upvote_count":"2"},{"timestamp":"1635500760.0","content":"I will go with A","upvote_count":"1","poster":"blackgamer","comment_id":"346754"},{"comment_id":"337423","content":"D. As it's Desktop application, AppStream is the best choice.","poster":"ppshein","timestamp":"1635472620.0","upvote_count":"2"},{"upvote_count":"1","poster":"awsexamprep47","content":"A is the answer\nMost cost effective, looking to move away from VDI is the key to rule out AppStream","timestamp":"1635343560.0","comment_id":"316576"},{"upvote_count":"3","comment_id":"291732","poster":"Kian1","content":"going with A","timestamp":"1635240540.0"},{"timestamp":"1635069360.0","upvote_count":"1","content":"I go with A","poster":"Ebi","comment_id":"279773"},{"comment_id":"278612","timestamp":"1634876220.0","content":"seems A, we need cognito","upvote_count":"1","poster":"gookseang"},{"comment_id":"253540","content":"D \nA is not a feasible option, since it cannot manage sharing.\n\"... Both applications use a shared database to manage user accounts and sharing...\"","poster":"MichaelHuang","comments":[{"comment_id":"271521","timestamp":"1634663940.0","content":"Amazon Cognito is a simple user identity and data synchronization service that helps you securely manage and synchronize app data for your users across their mobile devices. You can create unique identities for your users through a number of public login providers (Amazon, Facebook, and Google) and also support unauthenticated guests. You can save app data locally on users’ devices allowing your applications to work even when the devices are offline. With Amazon Cognito, you can save any kind of data in the AWS Cloud, such as app preferences or game state, without writing any backend code or managing any infrastructure. This means you can focus on creating great app experiences instead of having to worry about building and managing a backend solution to handle identity management, network state, storage, and sync.\nhttps://aws.amazon.com/about-aws/whats-new/2014/07/10/introducing-amazon-cognito/","poster":"Firststack","upvote_count":"1"}],"timestamp":"1634661660.0","upvote_count":"1"},{"poster":"Bulti","comment_id":"252293","upvote_count":"3","timestamp":"1634600460.0","content":"A is the right answer. D is a trick option but you should note that the question is not asking you to replace VDI with another streaming solution but instead a SaaS solution and Option A meets all the requirements."},{"upvote_count":"1","comment_id":"243550","timestamp":"1634481780.0","content":"Correct si D. AppStream","poster":"T14102020"},{"poster":"jackdryan","upvote_count":"2","comment_id":"230868","timestamp":"1634456940.0","content":"I'll go with A"},{"timestamp":"1634257500.0","upvote_count":"1","poster":"fullaws","comment_id":"151942","content":"A is correct, MOST security and cost effective, refer to lunchtime and inf"},{"comment_id":"137731","upvote_count":"7","timestamp":"1634169840.0","poster":"inf","content":"Answer: A\nThey want to \"rewrite the application\", as a SaaS solution, and not a streaming solution. AppStream is a streaming solution, using VDIs or servers as the backend - its Amazon's Citrix - which means managing the underlying infrastructure - deployment/patching/scaling/security. Streaming is more expensive than client-side rendering. \n\nRDS has a price, so try not to use it on the solution. You may well be able to authenticate with RDS but to access content on S3 without an STS token or similar won't be possible (if security is paramount). \n\nThe second S3 bucket is important. We use the user's federated ID as a variable in the IAM policy/role assumed by the user (ie token) to grant access to their data only using prefix, plus through Cognito grant access to other data through use of different policies. Not sure you can do this with user accounts in an RDS database."},{"upvote_count":"1","content":"A makes sense","poster":"NikkyDicky","timestamp":"1634155500.0","comment_id":"133207"},{"content":"I believe A is the answer they are looking for.\nA is the only option that suggests splitting the messaging data and images into two separate buckets, which increases security (you can set up separate policies for them). You can run a dynamic website off of S3 by using a front-end framework such as Angular, React, Vue, etc. Cognito is also going to provide the most secure and cleanest mechanism for managing user accounts and security. Option A may be more expensive to develop, but it should be the least expensive to run and maintain.","comment_id":"125123","timestamp":"1633944780.0","poster":"LunchTime","upvote_count":"4"},{"comments":[{"timestamp":"1633765140.0","content":"An addon: forgot but api gateway should be considered for JS.","poster":"hobokabobo","upvote_count":"1","comment_id":"110064"}],"upvote_count":"3","poster":"hobokabobo","content":"Question asks for cheapest solution:\nD: They want to move AWAY from VDI so appstream isn't much use - is it? Also accounts in RDS when there are answers with cognito. Also where does the application run? \nCosts: appstream + s3 + rds + unknown for application.\n\nC: Again user data in RDS. Not when Congnito is an option. Costs: EB +CF + ELB + unknown for app.\nB: works. costs: EC2 +S3 and Cognito for access\nA: works. cost Lambda + S3 and Cognito for access\n\nWith focus on costs A is cheaper then B for reasonable loads. But Lambda won't work for excessive loads and it needs to be doable in JS(they want to rewrite it: question says so - but can it be rewritten for JS: don't know!)\n\n-> A is the cheapest.","timestamp":"1633747980.0","comment_id":"110049"},{"timestamp":"1633549680.0","comment_id":"107122","content":"I would say it must be B. AppStream looks perfect but with SaaS Cognito / user pools are a must - RDS is a red flag that disqualifies C and D. A is trying to use S3 for dynamic content.\nhttps://aws.amazon.com/blogs/apn/managing-saas-users-with-amazon-cognito/","poster":"Wira","upvote_count":"2"},{"upvote_count":"2","timestamp":"1633391040.0","poster":"Oleksandr","comment_id":"104280","content":"I think it's D.\nAppStream is the key I believe. Despite A is workable, but it will be too expensive to rework the whole application"},{"comment_id":"93328","poster":"VrushaliD","timestamp":"1633225440.0","content":"It should be A","upvote_count":"1"},{"timestamp":"1633166160.0","content":"A would be the answer, supported by https://aws.amazon.com/appstream2/getting-started/isv-workshops/saas/","upvote_count":"1","comment_id":"81822","poster":"davidjb"},{"upvote_count":"1","content":"A should be alright","poster":"Joeylee","comment_id":"76737","timestamp":"1633164360.0"},{"timestamp":"1632986700.0","poster":"exam2019","content":"I agree with AWSPro24' explanation.\n\nAppStream supports two kinds of user authentication methods.\nOne is the AppStream 2.0 user pool, another is SAML 2.0. I think Amazon RDS won't work in this case. So D is wrong.\nhttps://aws.amazon.com/appstream2/faqs/?nc=sn&loc=7","upvote_count":"2","comment_id":"61094"},{"content":"A is the correct answer. \nhttps://aws.amazon.com/appstream2/getting-started/isv-workshops/saas/","upvote_count":"2","poster":"SamuelK","comment_id":"53526","timestamp":"1632982380.0"},{"content":"Agree D","comment_id":"51692","timestamp":"1632965460.0","poster":"amog","upvote_count":"1"},{"poster":"dumma","upvote_count":"1","comment_id":"44454","timestamp":"1632938460.0","content":"D is correct"},{"content":"D is right","comment_id":"30746","upvote_count":"3","timestamp":"1632760500.0","poster":"dojo"},{"comment_id":"28101","poster":"Scunningham99","upvote_count":"4","content":"agree with d","timestamp":"1632751440.0"},{"content":"A\nS3, lambda, and Congnito are cost effective managed services. Lambda for dynamic content.\nB/C: not cost effective\nD: AppStream is cost-effective compared to VM's but not browser. Maintaining user DB un RDS is a lot of on-going maint lost password, compliance, etc.","comment_id":"27332","poster":"johannes756","upvote_count":"5","timestamp":"1632719100.0"},{"upvote_count":"3","poster":"awsec2","content":"d , https://docs.aws.amazon.com/appstream2/latest/developerguide/managing-images.html","comments":[{"upvote_count":"5","comment_id":"35102","timestamp":"1632817560.0","content":"this 'image' doesn't mean picture","poster":"neorayer"}],"comment_id":"12658","timestamp":"1632343320.0"},{"timestamp":"1632300600.0","comments":[{"timestamp":"1632627180.0","upvote_count":"6","poster":"donathon","comment_id":"13662","content":"D, change of mind after reading the question again, it seems to emphasis on cost instead.\nA: S3 are usually used only for static webpages and not dynamic webpages. https://forums.aws.amazon.com/thread.jspa?messageID=702832\nB: Not cost effective as the EC2 will always needs to be running.\nC: Even more expensive then B.\nD: AppStream is like Citrix so it deliver virtual Apps on demand so this should be cheapest. Your instances run only when users are streaming applications. Idle instances that are available for streaming are in a stopped state. Use an On-Demand fleet to optimize your streaming charges and provide your users with access to their applications after a 1-2 minute wait. https://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html","comments":[{"upvote_count":"1","content":"In regards to B & D, doesn't AppStream also run EC2 fleet underneath?","timestamp":"1633024560.0","poster":"Smart","comment_id":"71503"}]}],"upvote_count":"2","comment_id":"11706","poster":"donathon","content":"B\nA: S3 are usually used only for static webpages and not dynamic webpages. https://forums.aws.amazon.com/thread.jspa?messageID=702832\nC\\D: Should use Cognito for user accounts because this is SaaS."},{"comment_id":"10418","poster":"awsec2","upvote_count":"4","timestamp":"1632251820.0","content":"should be \"d\""}],"question_text":"A Solutions Architect is redesigning an image-viewing and messaging platform to be delivered as SaaS. Currently, there is a farm of virtual desktop infrastructure\n(VDI) that runs a desktop image-viewing application and a desktop messaging application. Both applications use a shared database to manage user accounts and sharing. Users log in from a web portal that launches the applications and streams the view of the application on the user's machine. The Development Operations team wants to move away from using VDI and wants to rewrite the application.\nWhat is the MOST cost-effective architecture that offers both security and ease of management?","exam_id":32,"unix_timestamp":1568104800,"answer_images":[],"answer_description":"","isMC":true,"question_id":497,"answer":"D","choices":{"B":"Run a website from Amazon EC2 Linux servers, storing the images in Amazon S3, and use Amazon Cognito for user accounts and sharing. Create AWS CloudFormation templates to launch the application by using EC2 user data to install and configure the application.","C":"Run a website as an AWS Elastic Beanstalk application, storing the images in Amazon S3, and using an Amazon RDS database for user accounts and sharing. Create AWS CloudFormation templates to launch the application and perform blue/green deployments.","D":"Run a website from an Amazon S3 bucket that authorizes Amazon AppStream to stream applications for a combined image viewer and messenger that stores images in Amazon S3. Have the website use an Amazon RDS database for user accounts and sharing.","A":"Run a website from an Amazon S3 bucket with a separate S3 bucket for images and messaging data. Call AWS Lambda functions from embedded JavaScript to manage the dynamic content, and use Amazon Cognito for user and sharing management."}},{"id":"eAER3HgsBdvEFVUpWDMv","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/6007-exam-aws-certified-solutions-architect-professional-topic-1/","answer_description":"Reference:\nhttps://lumigo.io/blog/aws-lambda-timeout-best-practices/","discussion":[{"poster":"donathon","timestamp":"1632179460.0","upvote_count":"32","content":"BD\nhttps://lumigo.io/blog/aws-lambda-timeout-best-practices/\nA: While this will improve the situation, it may not be enough.\nB: Memory – The amount of memory available to the function during execution. Choose an amount between 128 MB and 3,008 MB in 64 MB increments. Lambda allocates CPU power linearly in proportion to the amount of memory configured. At 1,792 MB, a function has the equivalent of 1 full vCPU (one vCPU-second of credits per second).\nAll calls made to AWS Lambda must complete execution within 900 seconds. The default timeout is 3 seconds, but you can set the timeout to any value between 1 and 900 seconds.\nC: The problem is not with the DB.\nD: AWS API Gateway has a max timeout of 29 seconds for all integration types, which includes Lambda as well. It means that any API call coming through API Gateway cannot exceed 29 seconds. It makes sense for most of the APIs except for few high computational ones.\nE: Increase the memory not CPU.","comment_id":"13644"},{"content":"Selected Answer: BD\nYou cannot config container being reused or not","comment_id":"626389","upvote_count":"2","timestamp":"1656817800.0","poster":"aandc"},{"comment_id":"548339","timestamp":"1644993360.0","poster":"cannottellname","content":"A. https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/ (Remember, you can’t depend on a container being reused, since it’s Lambda’s prerogative to create a new one instead.)\n\nB. Increase Memory is good option. (https://lumigo.io/learn/aws-lambda-timeout-best-practices/)\n\nC. No DynamoDB\n\nD. Sounds good to have less load on Lambda. Caching always gives things faster and better, lesser computation for Lambda. (https://lumigo.io/learn/aws-lambda-timeout-best-practices/)\n\nE. Not possible. Increase Memory to Increase CPU.","upvote_count":"2"},{"upvote_count":"1","comment_id":"526294","timestamp":"1642479120.0","content":"A and B are right - as they help optimize and improve Lambda performance.","poster":"tkanmani76","comments":[{"timestamp":"1644927720.0","content":"Changing to B and D.","poster":"tkanmani76","upvote_count":"1","comment_id":"547742"}]},{"timestamp":"1638352500.0","upvote_count":"1","poster":"AzureDP900","content":"Before even looking answers I decided to go with B,D . It is most appropriate.","comment_id":"491503"},{"poster":"nsei","timestamp":"1636303980.0","comment_id":"470051","upvote_count":"1","content":"B & D are the answers"},{"poster":"wakame","comment_id":"436297","content":"A B is correct!","upvote_count":"1","timestamp":"1636117140.0"},{"content":"https://lumigo.io/blog/aws-lambda-timeout-best-practices/\nA: While this will improve the situation, it may not be enough.\nB: Memory – The amount of memory available to the function during execution. Choose an amount between 128 MB and 3,008 MB in 64 MB increments. Lambda allocates CPU power linearly in proportion to the amount of memory configured. At 1,792 MB, a function has the equivalent of 1 full vCPU (one vCPU-second of credits per second).\nAll calls made to AWS","upvote_count":"1","timestamp":"1636107240.0","poster":"kyoneyam","comment_id":"435131"},{"upvote_count":"1","comment_id":"411155","timestamp":"1636016340.0","poster":"WhyIronMan","content":"I'll go with B,D"},{"upvote_count":"1","content":"it's B,D","comment_id":"348266","timestamp":"1636002060.0","poster":"Waiweng"},{"upvote_count":"1","comment_id":"330410","comments":[{"timestamp":"1636113060.0","comment_id":"435163","upvote_count":"1","content":"Agree with you !\nAPI Cache is a feature that improves request latency.\nBut, If there is no cache, call Lambda.\nEven if API Cache reduces calls to your Lambda, it often doesn't reduce the processing time of Lambda function.\n\nOn the other hand, A is correct. It is also mentioned in best practices.\nhttps://docs.aws.amazon.com/lambda/latest/dg/best-practices.html","poster":"wakame"}],"content":"A B looks correct. This question is asking to reduce execution time. D will only help if caching is applicable, not always.","poster":"SD13","timestamp":"1635921720.0"},{"poster":"Kian1","comment_id":"291733","upvote_count":"1","timestamp":"1635624900.0","content":"will go with BD"},{"comment_id":"290027","content":"B and D is correct","timestamp":"1635177900.0","poster":"ujizane","upvote_count":"1"},{"upvote_count":"1","content":"B is correct","poster":"ujizane","comment_id":"290026","timestamp":"1635158820.0"},{"timestamp":"1635127020.0","comment_id":"279777","poster":"Ebi","content":"I go with BD","upvote_count":"1"},{"comment_id":"252300","upvote_count":"3","timestamp":"1635124920.0","content":"Answer is B and D.\nA- incorrect because there is no configuration in Lambda to reuse the same sandbox/contain\nB- is correct because when memory size increases, the total time decreases. It means AWS keeps its promise and gives proportional CPU to your function.\nC:- there is no need to use ElasticCache as the problem is not related to caching data from DB.\nD- This makes sense as it will increase performance and put less load on Lambda function.\nE- You need to increase memory and not CPU.","poster":"Bulti"},{"comment_id":"249474","poster":"petebear55","content":"B AND D ... BUT ANOTHER EXAMPLE OF SHI** AMAZON TYPE QUESTION PERSECUTING US !!! .. A WOULD BE CORRECT https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html BUT IT MENTIONS containers NOT WHAT IS SPECIFIED IN THE LINK ... SO A AND D FOR ME","upvote_count":"2","timestamp":"1634714040.0"},{"content":"Correct is BD. increase Lambda memory + API cache","poster":"T14102020","upvote_count":"1","comment_id":"243554","timestamp":"1634563200.0"},{"upvote_count":"4","poster":"jackdryan","timestamp":"1634519280.0","content":"I'll go with B,D","comment_id":"230872"},{"comment_id":"230156","content":"seems BD","poster":"gookseang","timestamp":"1634334360.0","upvote_count":"2"},{"timestamp":"1634244360.0","content":"B and D, increase memory to reduce execution time, enable API cache to increase performance, and only reduced those method they do not required longer timeout, the remaining will be set to the API method benchmark/high execution time. If the A mention provisioning concurrency, it will be considerable. However most of the time increase memory of lambda will allow the API method to be completed within 29 seconds at the most due to API Gateway constraint.","comment_id":"151968","upvote_count":"1","poster":"fullaws"},{"content":"BD for sure","upvote_count":"1","poster":"NikkyDicky","comment_id":"133211","timestamp":"1634211300.0"},{"upvote_count":"1","content":"Answer : B &D","comment_id":"132393","poster":"mat2020","timestamp":"1634117820.0"},{"poster":"94xychen","comment_id":"110799","content":"For Option D, I understood that enabling API cache would help, but why override the TTL for methods that require lower TTL can work? \nBecause, In my understanding, the TTL should be overridden for methods which require higher TTL...","upvote_count":"1","timestamp":"1634000640.0"},{"content":"In terms of A - to my understanding you can't explicitly 'configure Lambda to reuse containers' - you can apply best practices to would increase the re-usability or provision concurrency. The language of this answer is a bit off hence I would agree with the B and D options (despite actual provisioned concurrency being the clear winner for fixing the problem!)","timestamp":"1633606620.0","upvote_count":"3","poster":"Wira","comment_id":"107459","comments":[{"comment_id":"110443","timestamp":"1633918200.0","upvote_count":"2","poster":"meenu2225","content":"From: https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html\nTake advantage of execution context reuse to improve the performance of your function. Initialize SDK clients and database connections outside of the function handler, and cache static assets locally in the /tmp directory. Subsequent invocations processed by the same instance of your function can reuse these resources. This saves execution time and cost."}]},{"poster":"meenu2225","upvote_count":"2","comments":[{"timestamp":"1635934260.0","content":"\"Lambda may choose\" : no configuration is needed and/or possible (rules out A) -> BD","poster":"dijesim222","upvote_count":"1","comment_id":"341415"}],"content":"I was inclined towards B and D, But I think it is A, B.\nWill AWS Lambda reuse function instances?\n\nTo improve performance, AWS Lambda may choose to retain an instance of your function and reuse it to serve a subsequent request, rather than creating a new copy. To learn more about how Lambda reuses function instances, visit our documentation. Your code should not assume that this will always happen. (https://aws.amazon.com/lambda/faqs/)","comment_id":"106384","timestamp":"1633573440.0"},{"timestamp":"1633462260.0","comment_id":"97345","poster":"qianhaopower","content":"A is not something you can configure","upvote_count":"2"},{"content":"agree with AB, \nD is for the issue with API gateway but not lambda.","poster":"koalasy","upvote_count":"4","comment_id":"84355","timestamp":"1633407000.0","comments":[{"timestamp":"1633437300.0","upvote_count":"1","poster":"Ibranthovic","comment_id":"92700","content":"So what ? you are avoiding running of lambda function using API Gateway Cache.\nIs it B and D"}]},{"timestamp":"1632790920.0","content":"Should be A & B. API gateway caching may improve the performance but nothing to do with Lambda timeout - still timeout in case of a cache miss","poster":"Joeylee","upvote_count":"4","comment_id":"76741"},{"comment_id":"53448","upvote_count":"3","poster":"Gorha","content":"A and B make more sense. both targeting the performance of lambda itself. The gateway caching could be the next step if these two solution didn't fix the problem.","timestamp":"1632426420.0"},{"comment_id":"51697","poster":"amog","timestamp":"1632351000.0","content":"Should be A,B","upvote_count":"4"},{"poster":"dumma","timestamp":"1632314460.0","content":"Option A as writing functions to reuse containers would help reduce initialization time and improve performance. Make sure any externalized configuration or dependencies that your code retrieves are stored and referenced locally after initial execution. Limit the re-initialization of variables/objects on every invocation. Instead use static initialization/constructor, global/static variables and singletons. Keep alive and reuse connections (HTTP, database, etc.) that were established during a previous invocation.\n\nOption B as Lambda allocates compute power in proportion to the memory you allocate to your function. This means you can over provision memory to run your functions faster and potentially reduce your costs. You should benchmark your use case to determine where the breakeven point is for running faster and using more memory vs running slower and using less memory.","upvote_count":"3","comment_id":"42690"},{"poster":"cinopi","content":"Answer is A, B:","upvote_count":"4","timestamp":"1632275640.0","comment_id":"32573"},{"poster":"larryaws","upvote_count":"3","content":"I prefer B,D","comment_id":"17619","timestamp":"1632273300.0"},{"comment_id":"16245","timestamp":"1632251340.0","comments":[{"poster":"Smart","timestamp":"1632496620.0","comment_id":"71600","content":"My understanding is that when your lambda function is invoked successfully, sandbox is maintained for a certain period of time. This certain period of time cannot be configured - it is decided by AWS. There is no way to extended that unless there is a repeat lambda function invocation. \n\nNowadays, you can setup provisioned capacity to avoid cold starts.","upvote_count":"5"}],"content":"why not A\nhttps://aws.amazon.com/blogs/compute/container-reuse-in-lambda/","poster":"chaudh","upvote_count":"4"}],"timestamp":"2019-10-03 02:00:00","answers_community":["BD (100%)"],"answer_ET":"BD","answer":"BD","answer_images":[],"question_id":498,"question_images":[],"question_text":"A company would like to implement a serverless application by using Amazon API Gateway, AWS Lambda, and Amazon DynamoDB. They deployed a proof of concept and stated that the average response time is greater than what their upstream services can accept. Amazon CloudWatch metrics did not indicate any issues with DynamoDB but showed that some Lambda functions were hitting their timeout.\nWhich of the following actions should the Solutions Architect consider to improve performance? (Choose two.)","topic":"1","unix_timestamp":1570060800,"choices":{"B":"Increase the amount of memory and adjust the timeout on the Lambda function. Complete performance testing to identify the ideal memory and timeout configuration for the Lambda function.","D":"Enable API cache on the appropriate stage in Amazon API Gateway, and override the TTL for individual methods that require a lower TTL than the entire stage.","C":"Create an Amazon ElastiCache cluster running Memcached, and configure the Lambda function for VPC integration with access to the Amazon ElastiCache cluster.","A":"Configure the AWS Lambda function to reuse containers to avoid unnecessary startup time.","E":"Increase the amount of CPU, and adjust the timeout on the Lambda function. Complete performance testing to identify the ideal CPU and timeout configuration for the Lambda function."},"exam_id":32},{"id":"knUqVkzE73ntgzq16xt0","question_text":"An AWS customer runs a public blogging website. The site users upload two million blog entries a month. The average blog entry size is 200 KB. The access rate to blog entries drops to negligible 6 months after publication and users rarely access a blog entry 1 year after publication. Additionally, blog entries have a high update rate during the first 3 months following publication, this drops to no updates after 6 months. The customer wants to use CloudFront to improve his user's load times.\nWhich of the following recommendations would you make to the customer?","answer_images":[],"answer_description":"","question_id":499,"unix_timestamp":1581585660,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/13996-exam-aws-certified-solutions-architect-professional-topic-1/","topic":"1","question_images":[],"exam_id":32,"timestamp":"2020-02-13 10:21:00","answer":"C","isMC":true,"choices":{"B":"Create a CloudFront distribution with ג€US Europeג€ price class for US/Europe users and a different CloudFront distribution with ג€All Edge Locationsג€ for the remaining users.","D":"Create a CloudFront distribution with Restrict Viewer Access Forward Query string set to true and minimum TTL of 0.","A":"Duplicate entries into two different buckets and create two separate CloudFront distributions where S3 access is restricted only to Cloud Front identity","C":"Create a CloudFront distribution with S3 access restricted only to the CloudFront identity and partition the blog entry's location in S3 according to the month it was uploaded to be used with CloudFront behaviors."},"discussion":[{"poster":"BillyC","upvote_count":"17","timestamp":"1632223080.0","comment_id":"49908","content":"Hi, Is C the correct answer?","comments":[{"upvote_count":"2","comment_id":"599784","content":"it is the only option that make sense","timestamp":"1652223240.0","poster":"user0001"}]},{"upvote_count":"9","poster":"Gorha","comment_id":"51431","content":"Yes, C is correct!","timestamp":"1632442080.0"},{"poster":"amministrazione","content":"C. Create a CloudFront distribution with S3 access restricted only to the CloudFront identity and partition the blog entry's location in S3 according to the month it was uploaded to be used with CloudFront behaviors.","timestamp":"1723751220.0","upvote_count":"1","comment_id":"1266647"},{"upvote_count":"2","comment_id":"927731","poster":"SkyZeroZx","timestamp":"1687194480.0","content":"Selected Answer: C\nkeyword = S3 according to the month"},{"comment_id":"496624","content":"C. Create a CloudFront distribution with S3 access restricted only to the CloudFront identity and partition the blog entry's location in S3 according to the month it was uploaded to be used with CloudFront behaviors.","timestamp":"1638950760.0","upvote_count":"1","poster":"cldy"},{"content":"j'espere to have such simple question in my exam","comment_id":"483860","poster":"acloudguru","upvote_count":"1","timestamp":"1637555580.0"},{"comment_id":"347772","poster":"01037","content":"Yes it's C.\nThought the question is about S3 storage class at first","upvote_count":"1","timestamp":"1635423900.0"},{"comment_id":"326296","upvote_count":"1","content":"C is correct","timestamp":"1634416740.0","poster":"AJ41185"},{"content":"C seems correct of all.","poster":"cldy","comment_id":"325497","upvote_count":"1","timestamp":"1634415000.0"},{"poster":"bustedd","content":"ccccccc","comment_id":"293739","timestamp":"1634041200.0","upvote_count":"1"},{"content":"Why does \"partition the blog entry's location in S3 according to the month it was uploaded\" help?","comments":[{"timestamp":"1634937480.0","content":"To improve request rate.\nyour application can achieve at least 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket.","comment_id":"347771","upvote_count":"5","poster":"01037"}],"upvote_count":"1","comment_id":"211252","timestamp":"1633640940.0","poster":"newme"},{"poster":"fullaws","upvote_count":"2","comment_id":"143882","content":"C is correct","timestamp":"1633437840.0"},{"timestamp":"1632948300.0","comment_id":"131130","poster":"noisonnoiton","content":"go with C","upvote_count":"2"}],"answers_community":["C (100%)"]},{"id":"qyksikPJu3t50cT7W8GH","discussion":[{"poster":"donathon","content":"B. As Storage Gateway is not a managed service","comment_id":"10548","timestamp":"1632260580.0","upvote_count":"28"},{"poster":"dpvnme","content":"B would be my choice","comment_id":"9326","upvote_count":"10","timestamp":"1632173280.0"},{"timestamp":"1687457820.0","upvote_count":"1","poster":"SkyZeroZx","content":"Selected Answer: B\nB. \"Highly durable and available\"\n The company needs to store large, important documents S3 is better Option","comment_id":"930897"},{"content":"Selected Answer: B\nB looks better\nA-> I don't know if storage gateway to AWS in file gateway mode is able to use Amazon EBS volume.","upvote_count":"1","timestamp":"1672234380.0","poster":"evargasbrz","comment_id":"759885","comments":[{"comment_id":"759890","content":"I think the main point here is \"migration\", but the option A is confusing, it tells file gateway mode and also volume gateway to use EBS.","poster":"evargasbrz","upvote_count":"1","timestamp":"1672234740.0"}]},{"timestamp":"1656358860.0","poster":"kangtamo","upvote_count":"1","content":"Selected Answer: B\nAgree with B: S3 HTTPS","comment_id":"623468"},{"content":"B. Use Amazon S3 with a bucket policy to enforce HTTPS for connections to the bucket and to enforce server-side encryption and AWS KMS for object encryption.","comment_id":"497646","upvote_count":"2","timestamp":"1639047540.0","poster":"cldy"},{"comment_id":"491505","upvote_count":"1","timestamp":"1638352620.0","content":"I will pick B.","poster":"AzureDP900"},{"timestamp":"1636238460.0","poster":"AWSum1","upvote_count":"1","content":"B. \"Highly durable and available\"","comment_id":"450676"},{"content":"I'll go with B","timestamp":"1636196760.0","comment_id":"411156","poster":"WhyIronMan","upvote_count":"1"},{"content":"Definitely B","poster":"KittuCheeku","upvote_count":"1","comment_id":"396358","timestamp":"1636172520.0"},{"comment_id":"348267","timestamp":"1636075260.0","content":"it's B","upvote_count":"2","poster":"Waiweng"},{"upvote_count":"1","content":"B for sure.","timestamp":"1636059900.0","poster":"blackgamer","comment_id":"346764"},{"poster":"KnightVictor","upvote_count":"1","timestamp":"1636039980.0","content":"Should be B","comment_id":"330021"},{"content":"i go with B","timestamp":"1635977040.0","upvote_count":"1","poster":"alisyech","comment_id":"321771"},{"poster":"awsexamprep47","timestamp":"1635869340.0","upvote_count":"2","content":"B is the answer\nAll the encryption requirements are satisfied using S-3 bucket policy","comment_id":"316578"},{"timestamp":"1635763440.0","poster":"kiev","comment_id":"299741","upvote_count":"4","content":"B for me. In fact I don't even worry to read when a question talks about storage that's fully managed and cost effective, I just for S3"},{"poster":"Kian1","timestamp":"1635724620.0","content":"going with B","comment_id":"291736","upvote_count":"2"},{"timestamp":"1635691920.0","content":"B is collect","poster":"ujizane","upvote_count":"2","comment_id":"290025"},{"poster":"Ebi","upvote_count":"4","timestamp":"1635690000.0","content":"Answer is B for sure","comment_id":"279780"},{"content":"The answer is B","timestamp":"1635604920.0","poster":"Firststack","upvote_count":"1","comment_id":"279703"},{"timestamp":"1635537480.0","comment_id":"269972","poster":"kopper2019","upvote_count":"2","content":"b: Use Amazon S3 with a bucket policy to enforce HTTPS for connections to the bucket and to enforce server-side encryption and AWS KMS for object encryption."},{"timestamp":"1635514080.0","poster":"SD13","comment_id":"262822","upvote_count":"1","content":"D : Since the question mentions large important documents within the application. It cant be S3"},{"poster":"Bulti","upvote_count":"1","content":"B is correct.","comment_id":"252302","timestamp":"1635432420.0"},{"timestamp":"1635262320.0","comment_id":"249488","poster":"petebear55","content":"b guys dont get confused with A .. when the questions mentioned durable storage always look for S3 where you at select encryption at rest as well","upvote_count":"1"},{"comment_id":"243559","timestamp":"1635203820.0","content":"Correct is B. S3","upvote_count":"1","poster":"T14102020"},{"upvote_count":"3","content":"I'll go with B","timestamp":"1634733120.0","comment_id":"230873","poster":"jackdryan"},{"poster":"gookseang","content":"BBBBBBBBBBBBBBBBBBBBBBBBBBBBBB","comment_id":"230161","upvote_count":"3","timestamp":"1634506440.0"},{"comment_id":"215571","upvote_count":"1","poster":"kopper2019","content":"A and D has EBS which is not durable like S3 so B is the best option","timestamp":"1634482260.0"},{"content":"B is correct","comment_id":"152268","timestamp":"1634208420.0","upvote_count":"1","poster":"fullaws"},{"comment_id":"133213","content":"B for sure","timestamp":"1634081040.0","poster":"NikkyDicky","upvote_count":"1"},{"comment_id":"107467","content":"B\nYou can't use EBS encryption on file gateway volumes https://docs.aws.amazon.com/storagegateway/latest/userguide/encryption.html","timestamp":"1633736340.0","poster":"Wira","upvote_count":"1"},{"poster":"JAWS1600","comment_id":"96991","upvote_count":"3","content":"A is wrong. File gateway uses S3 in the back end not EBS. B is the right one.","timestamp":"1633652280.0"},{"upvote_count":"1","content":"B is correct","poster":"FreeSwan","comment_id":"94684","timestamp":"1633559400.0"},{"timestamp":"1633433460.0","upvote_count":"2","content":"Should be B","comment_id":"51700","poster":"amog"},{"content":"B\nThe data must be highly durable and available.","upvote_count":"3","comment_id":"46290","poster":"ashp","timestamp":"1633102140.0"},{"poster":"AWSPro24","content":"B.\nA. Storage Gateway is not a managed service and File Gateway mode doesn't use EBS it maps all volume objects to S3 files which use SSE-S3 or SSE-KMS.","comment_id":"42636","upvote_count":"4","timestamp":"1633050900.0"},{"timestamp":"1632829620.0","poster":"VMHarry","content":"is document transferring and it is not web application I don't see HTTPS work here","upvote_count":"1","comment_id":"29898","comments":[{"poster":"MichaelR","content":"enforce https in bucket policy: https://aws.amazon.com/premiumsupport/knowledge-center/s3-bucket-policy-for-config-rule/","upvote_count":"1","timestamp":"1635089460.0","comment_id":"233303"}]},{"poster":"Teri","comment_id":"20039","content":"my choice is B.","upvote_count":"3","timestamp":"1632665940.0"},{"timestamp":"1632594420.0","comment_id":"19538","upvote_count":"4","poster":"rasagulla","content":"I feel B is the correct answer. Check out the link,\nhttps://aws.amazon.com/blogs/security/how-to-use-bucket-policies-and-apply-defense-in-depth-to-help-secure-your-amazon-s3-data/"},{"upvote_count":"1","timestamp":"1632398400.0","comment_id":"13162","content":"After reviewing, \"A\" would be a better choice.","comments":[{"content":"I mean \"B\" is a better choice :).\nThe File Gateway is not stored in EBS. So the answer is not correct.\nAlso, the HTTPS can be enforced in S3.","comments":[{"comment_id":"13178","timestamp":"1632538380.0","poster":"omar_bahrain","upvote_count":"1","content":"cant find any statement calrifying that he File Gateway is not stored in EBS"}],"comment_id":"13163","poster":"Moon","upvote_count":"12","timestamp":"1632478680.0"}],"poster":"Moon"},{"upvote_count":"1","comment_id":"11013","comments":[{"comment_id":"95124","timestamp":"1633613460.0","poster":"JAWS1600","upvote_count":"4","content":"A is not fully managed service. Storage gateway needs management onsite."},{"upvote_count":"1","poster":"RVivek","comment_id":"525378","content":"A is wrong . S3-Managed Encryption Keys (SSE-S3) does not match the The encryption key must be controlled and changed on a regular basis by the business.","timestamp":"1642381740.0"}],"content":"A, is better option: \nAs in AWS: All data transferred between the gateway and AWS storage is encrypted using SSL. By default, all data stored in S3 is encrypted server-side with Amazon S3-Managed Encryption Keys (SSE-S3). For each file share you can optionally configure to have your objects encrypted with AWS KMS-Managed Keys using SSE-KMS.\n\nhttps://aws.amazon.com/storagegateway/faqs/","timestamp":"1632319260.0","poster":"Moon"}],"unix_timestamp":1567440420,"answer":"B","timestamp":"2019-09-02 18:07:00","question_id":500,"url":"https://www.examtopics.com/discussions/amazon/view/4572-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["B (100%)"],"isMC":true,"question_text":"A company is migrating an application to AWS. It wants to use fully managed services as much as possible during the migration. The company needs to store large, important documents within the application with the following requirements:\n✑ The data must be highly durable and available.\n✑ The data must always be encrypted at rest and in transit.\n✑ The encryption key must be managed by the company and rotated periodically.\nWhich of the following solutions should the Solutions Architect recommend?","answer_ET":"B","question_images":[],"answer_images":[],"exam_id":32,"topic":"1","answer_description":"","choices":{"C":"Use Amazon DynamoDB with SSL to connect to DynamoDB. Use an AWS KMS key to encrypt DynamoDB objects at rest.","D":"Deploy instances with Amazon EBS volumes attached to store this data. Use EBS volume encryption using an AWS KMS key to encrypt the data.","B":"Use Amazon S3 with a bucket policy to enforce HTTPS for connections to the bucket and to enforce server-side encryption and AWS KMS for object encryption.","A":"Deploy the storage gateway to AWS in file gateway mode. Use Amazon EBS volume encryption using an AWS KMS key to encrypt the storage gateway volumes."}}],"exam":{"isBeta":false,"isImplemented":true,"isMCOnly":false,"provider":"Amazon","id":32,"numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Professional","lastUpdated":"11 Apr 2025"},"currentPage":100},"__N_SSP":true}