{"pageProps":{"questions":[{"id":"UDkR14KqdAJvl5Ex93w0","url":"https://www.examtopics.com/discussions/amazon/view/126765-exam-aws-certified-solutions-architect-professional-sap-c02/","topic":"1","choices":{"F":"Create an AWS Lambda function. Program the Lambda function to normalize the logs in the member accounts and to write the logs to the security tool.","A":"Create a destination Amazon Kinesis data stream in the central logging account.","C":"Create an IAM role that grants Amazon CloudWatch Logs the permission to add data to the Amazon Kinesis data stream. Create a trust policy. Specify the trust policy in the IAM role. In each member account, create a subscription filter for each log group to send data to the Kinesis data stream.","D":"Create an IAM role that grants Amazon CloudWatch Logs the permission to add data to the Amazon Simple Queue Service (Amazon SQS) queue. Create a trust policy. Specify the trust policy in the IAM role. In each member account, create a single subscription filter for all log groups to send data to the SQS queue.","E":"Create an AWS Lambda function. Program the Lambda function to normalize the logs in the central logging account and to write the logs to the security tool.","B":"Create a destination Amazon Simple Queue Service (Amazon SQS) queue in the central logging account."},"question_id":266,"answers_community":["ACE (100%)"],"answer_ET":"ACE","answer_description":"","timestamp":"2023-11-21 22:03:00","exam_id":33,"answer_images":[],"isMC":true,"discussion":[{"comment_id":"1082732","upvote_count":"8","content":"Selected Answer: ACE\nCloud Watch logs -> Kinesis Data Streams -> Lambda - > Security Tool\nACE","timestamp":"1701189180.0","poster":"shaaam80"},{"comment_id":"1110399","poster":"carpa_jo","content":"A vs B: Kinesis data stream is a possible destination of CloudWatch Logs subscriptions, SQS isn't --> A\nC vs. D: As we had to choose Kinesis only C makes sense.\nE vs. F: Difference is that E runs the Lambda function in the central logging account while F runs the Lambda function in the member accounts. So clearly E, as we have streamed the logs to the central accounts Kinesis, which easily can use Lambda for the final processing etc.","timestamp":"1704012660.0","upvote_count":"5"},{"comment_id":"1317134","timestamp":"1732468800.0","upvote_count":"1","content":"While SQS does not fit the bill as it is not a direct location to send CW logs, KDS too does not fit the bill because it cannot scale automatically with load and one has to keep adding shards to increase the throughput. The authors themselves are not that knowledgeable. Only KDF seems to be the most correct thing to do(not mentioned in the options) as it can scale automatically as well has the transformation feature.","poster":"daveshell"},{"upvote_count":"1","comment_id":"1290659","content":"BDE\nWhy would you write to the member account? makes no sense. \nWhy would you use kinesis it says nothing about real time. BD","poster":"NoDoubkevo","timestamp":"1727530920.0","comments":[{"timestamp":"1730630580.0","comment_id":"1306486","poster":"ZAK_11","content":"Kinesis data stream is a possible destination of CloudWatch Logs subscriptions, but SQS isn't","upvote_count":"1"}]},{"poster":"career360guru","content":"Selected Answer: ACE\nA, C and E","comment_id":"1117772","timestamp":"1704827640.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1703105040.0","content":"ACE Kinesis for sure","poster":"yuliaqwerty","comment_id":"1101929"},{"content":"Selected Answer: ACE\nI vote for ACE","poster":"salazar35","comment_id":"1080022","timestamp":"1700919240.0","upvote_count":"4"},{"upvote_count":"4","comment_id":"1078158","content":"Selected Answer: ACE\nDefinitely - ACE","poster":"HunkyBunky","timestamp":"1700723040.0"},{"poster":"devalenzuela86","comment_id":"1076680","content":"Selected Answer: ACE\nACE for sure","timestamp":"1700600580.0","upvote_count":"4"}],"question_images":[],"question_text":"A company needs to aggregate Amazon CloudWatch logs from its AWS accounts into one central logging account. The collected logs must remain in the AWS Region of creation. The central logging account will then process the logs, normalize the logs into standard output format, and stream the output logs to a security tool for more processing.\n\nA solutions architect must design a solution that can handle a large volume of logging data that needs to be ingested. Less logging will occur outside normal business hours than during normal business hours. The logging solution must scale with the anticipated load. The solutions architect has decided to use an AWS Control Tower design to handle the multi-account logging process.\n\nWhich combination of steps should the solutions architect take to meet the requirements? (Choose three.)","answer":"ACE","unix_timestamp":1700600580},{"id":"0DFAJ1WxrQFMuJaj2ev6","answers_community":["DE (58%)","AD (30%)","9%"],"url":"https://www.examtopics.com/discussions/amazon/view/126766-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"DE","question_id":267,"exam_id":33,"answer_images":[],"choices":{"C":"Export the VM images to an AWS Snowball Edge Storage Optimized device.","B":"Use VM Import/Export to import the application server VM.","D":"Use an AWS Server Migration Service (AWS SMS) replication job to migrate the application server VM to AWS.","E":"Use an AWS Database Migration Service (AWS DMS) replication instance to migrate the database to an Amazon RDS DB instance.","A":"Use an AWS Server Migration Service (AWS SMS) replication job to migrate the database server VM to AWS."},"topic":"1","unix_timestamp":1700600700,"answer_description":"","discussion":[{"comments":[{"timestamp":"1709398380.0","comment_id":"1164226","content":"It does not actually say that the DB itself is 500TB, but that its the total size of storage for both VMs. I really do not like this question. The information provided leaves a lot of room for assumptions.","upvote_count":"4","poster":"hogtrough"},{"comment_id":"1090441","poster":"m1xa","upvote_count":"1","content":"Where did you get that? 16TB\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#Concepts.Storage.GeneralSSD","comments":[{"upvote_count":"1","poster":"water314","content":"on the page you mentioned\n\nVolume size \n100 GiB–64 TiB (16 TiB on RDS for SQL Server)\n\n20 GiB–64 TiB (16 TiB on RDS for SQL Server)\n\n20 GiB–64 TiB (16 TiB on RDS for SQL Server)","timestamp":"1703791740.0","comment_id":"1108065"}],"timestamp":"1701966360.0"}],"poster":"water314","comment_id":"1089812","content":"Selected Answer: AD\nAD, RDS Database has max size of less than 500TB, cannot use RDS!","upvote_count":"8","timestamp":"1701902040.0"},{"poster":"salazar35","content":"Selected Answer: DE\nShould be DE \"LEAST amount of downtime\"","timestamp":"1701186360.0","upvote_count":"8","comment_id":"1082706"},{"timestamp":"1730831100.0","upvote_count":"4","content":"FYI: Server Migration Service (AWS SMS) has been discontinued. \nAWS now recommends the AWS Application Migration Service as the primary migration service.","poster":"Woody1848","comment_id":"1307503"},{"poster":"Danm86","comment_id":"1304441","timestamp":"1730204820.0","content":"Answer is AD. This is a crazy question with lot of ambiguity, the question prepared just based of one blog with no clear information :) \nReference: https://aws.amazon.com/blogs/compute/learn-about-hourly-replication-in-server-migration-service-and-the-ability-to-migrate-large-data-volumes/","upvote_count":"1"},{"timestamp":"1714728060.0","comment_id":"1206012","poster":"seetpt","content":"Selected Answer: DE\nDE for me","upvote_count":"1"},{"upvote_count":"2","timestamp":"1713190680.0","content":"Selected Answer: DE\nD and E - \"LEAST amount of downtime\".","poster":"titi_r","comment_id":"1196071"},{"timestamp":"1712382180.0","upvote_count":"3","comment_id":"1190248","content":"Selected Answer: DE\n3 limit here:\nRDS volume - 16TB\nDMS - 30TB\nEBS - 64TB\nnone of them matching the 500TB of size.\nso only possible here:\nwrite forgot the size limit but made the question only focus on comparision between DX and Snowball.\nOr, the 500TB size of file is no db or not a single file which can be split to different volumes. And in either case above, DE would be the answer that author is looking for, Simple as Do you know what DMS is.","poster":"pangchn"},{"timestamp":"1711373460.0","comment_id":"1182511","poster":"TonytheTiger","upvote_count":"1","content":"Selected Answer: AC\nOption ACE. You need to create a transit gateway, set up at routing table for communication route rules and finally, create a transit gateway attachment to a VPN .\n\nOption E - https://docs.aws.amazon.com/vpc/latest/tgw/tgw-vpn-attachments.html\nOption A&C - https://docs.aws.amazon.com/vpc/latest/tgw/transit-gateway-isolated.html"},{"upvote_count":"2","content":"Selected Answer: DE\nOption D & E","poster":"career360guru","timestamp":"1710125820.0","comment_id":"1170746"},{"comments":[{"content":"Change of mind: DE.","comment_id":"1179636","timestamp":"1711054140.0","upvote_count":"2","poster":"Dgix"}],"timestamp":"1710006060.0","upvote_count":"1","poster":"Dgix","comment_id":"1169687","content":"Selected Answer: AD\nThere is no requirement to migrate to RDS, hence VMs only."},{"comments":[{"content":"Changing to AD\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Limits.html","comments":[{"content":"That is temporary storage as a staging area until it replicates to the target server. You can replicate more than 30TB to a target VM using DMS.\n\n\"The 30,000-GB quota for storage applies to all your AWS DMS replication instances in a given AWS Region. This storage is used to cache changes if a target can't keep up with a source, and for storing log information.\"","upvote_count":"1","poster":"hogtrough","comment_id":"1164234","timestamp":"1709399340.0"}],"timestamp":"1709053200.0","poster":"TheCloudGuruu","upvote_count":"1","comment_id":"1160843"}],"comment_id":"1160838","upvote_count":"3","content":"Selected Answer: DE\nD, E SMS and DMS","poster":"TheCloudGuruu","timestamp":"1709053020.0"},{"poster":"dankositzke","upvote_count":"5","comment_id":"1152904","content":"Selected Answer: DE\nI vote DE","timestamp":"1708210620.0"},{"poster":"07c2d2a","content":"A is wrong. For least downtime you will migrate a Database with DMS. \nD & E is the correct answer.","comment_id":"1145855","upvote_count":"3","timestamp":"1707521340.0"},{"content":"Selected Answer: AD\nhttps://www.amazonaws.cn/en/server-migration-service/faqs/\nQ: What is the difference between EC2 VM Import and Amazon Server Migration Service?\nAmazon Server Migration Service is a significant enhancement of EC2 VM Import. The Amazon Server Migration Service provides automated, live incremental server replication and Amazon Web Services Console support. For customers using EC2 VM Import for migration, we recommend using Amazon Server Migration Service.","comment_id":"1139179","upvote_count":"1","poster":"ele","timestamp":"1706958660.0"},{"content":"Answer: DE\nBoth AWS SMS and AWS DMS offer continuous replication, allowing the application and database to be kept in sync with their AWS counterparts during the migration process. This enables a switchover with minimal downtime.","poster":"vibzr2023","timestamp":"1704928620.0","upvote_count":"1","comment_id":"1119141"},{"upvote_count":"3","poster":"career360guru","content":"Selected Answer: BE\nMigrate application using VM Export/Import \nAs DB is MS SQL running on VM, use DMS to Migrate to RDS.","comment_id":"1117779","timestamp":"1704828060.0"},{"comment_id":"1113825","upvote_count":"1","timestamp":"1704383160.0","content":"https://aws.amazon.com/blogs/compute/learn-about-hourly-replication-in-server-migration-service-and-the-ability-to-migrate-large-data-volumes/","poster":"duriselvan"},{"timestamp":"1704287640.0","poster":"Maygam","comment_id":"1112775","content":"Selected Answer: AD\nThe maximum storage size for SQL Server DB instances is the following:\n General Purpose (SSD) storage – 16 TiB for all editions\n Provisioned IOPS storage – 16 TiB for all editions\n Magnetic storage – 1 TiB for all editions\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_SQLServer.html#SQLServer.Concepts.General.FeatureSupport.Limits","upvote_count":"2"},{"content":"d,e ans https://aws.amazon.com/blogs/publicsector/how-migrate-on-premises-workloads-aws-application-migration-service/","timestamp":"1703762640.0","upvote_count":"2","comment_id":"1107699","poster":"duriselvan"},{"comment_id":"1091716","content":"Selected Answer: AD\n@water314 is right - RDS SQL maximum storage is 16TB. So we need to move the VM\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","timestamp":"1702115640.0","upvote_count":"4","poster":"ayadmawla"},{"timestamp":"1701190260.0","content":"Selected Answer: DE\nThere is a Direct Connect from on-prem to AWS which is currently unused. Makes sense to go with Server and Database Migration Services. D&E","upvote_count":"4","poster":"shaaam80","comment_id":"1082752"},{"poster":"PouyaK","content":"DE - LEAST amount of downtime","upvote_count":"3","timestamp":"1701186000.0","comment_id":"1082701"},{"timestamp":"1701048180.0","upvote_count":"2","comment_id":"1081103","content":"Selected Answer: BE\nBE . see https://aws.amazon.com/ec2/vm-import/","poster":"Teebo"},{"upvote_count":"2","poster":"Teebo","content":"BE . see https://aws.amazon.com/ec2/vm-import/","timestamp":"1701047820.0","comment_id":"1081100"},{"poster":"devalenzuela86","upvote_count":"3","timestamp":"1700600700.0","comment_id":"1076684","content":"Selected Answer: DE\nDE for sure"}],"answer":"DE","question_text":"A company is migrating a legacy application from an on-premises data center to AWS. The application consists of a single application server and a Microsoft SQL Server database server. Each server is deployed on a VMware VM that consumes 500 TB of data across multiple attached volumes.\n\nThe company has established a 10 Gbps AWS Direct Connect connection from the closest AWS Region to its on-premises data center. The Direct Connect connection is not currently in use by other services.\n\nWhich combination of steps should a solutions architect take to migrate the application with the LEAST amount of downtime? (Choose two.)","timestamp":"2023-11-21 22:05:00","question_images":[],"isMC":true},{"id":"jvf7D6DPxQA9SCNZjbH9","question_id":268,"url":"https://www.examtopics.com/discussions/amazon/view/91463-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_description":"","topic":"1","question_text":"A company has created an OU in AWS Organizations for each of its engineering teams. Each OU owns multiple AWS accounts. The organization has hundreds of AWS accounts.\nA solutions architect must design a solution so that each OU can view a breakdown of usage costs across its AWS accounts.\nWhich solution meets these requirements?","answer_images":[],"question_images":[],"answer":"B","answers_community":["B (86%)","11%"],"timestamp":"2022-12-13 17:00:00","choices":{"D":"Create an AWS Cost and Usage Report (CUR) by using AWS Systems Manager. Allow each team to visualize the CUR through Systems Manager OpsCenter dashboards.","A":"Create an AWS Cost and Usage Report (CUR) for each OU by using AWS Resource Access Manager. Allow each team to visualize the CUR through an Amazon QuickSight dashboard.","C":"Create an AWS Cost and Usage Report (CUR) in each AWS Organizations member account. Allow each team to visualize the CUR through an Amazon QuickSight dashboard.","B":"Create an AWS Cost and Usage Report (CUR) from the AWS Organizations management account. Allow each team to visualize the CUR through an Amazon QuickSight dashboard."},"discussion":[{"comment_id":"774832","content":"Selected Answer: B\nB is the correct answer. The solution would be to create an AWS Cost and Usage Report (CUR) from the AWS Organizations management account. This would allow the management account to view the usage costs across all the member accounts, and the teams can visualize the CUR through an Amazon QuickSight dashboard. This allows the organization to have a centralized place to view the cost breakdown and the teams to access the cost breakdown in an easy way.","timestamp":"1673641980.0","upvote_count":"20","poster":"masetromain"},{"poster":"85b5b55","comment_id":"1348181","timestamp":"1738096020.0","content":"Selected Answer: B\nusing OU Management Account, create a CUR using OU Management account and allow each AWS account to view through Amazon QuickSight.","upvote_count":"2"},{"upvote_count":"1","comment_id":"1281705","poster":"AWSum1","timestamp":"1725991500.0","content":"Selected Answer: B\nOption B: it must be done from the management accoint"},{"poster":"amministrazione","comment_id":"1275477","content":"B. Create an AWS Cost and Usage Report (CUR) from the AWS Organizations management account. Allow each team to visualize the CUR through an Amazon QuickSight dashboard.","timestamp":"1725093420.0","upvote_count":"1"},{"upvote_count":"4","poster":"TonytheTiger","content":"Selected Answer: C\nOption C: I hate this questions because you have 2 correct answers however only ONE real correct answer. I have to read the question like 20x until I understood it, the questions is asking for \" solution so the EACH OU can VIEW a breakdown of usage across ITS account\". \nIts only asking for each OU breakdown for its members can see the usage cost and NOT the organization. Prior to Dec 2020 Option B would be correct however after its Option C: \n\nRead the following AWS Update - https://aws.amazon.com/about-aws/whats-new/2020/12/cost-and-usage-report-now-available-to-member-linked-accounts/?pg=ln&sec=uc","comment_id":"1205132","comments":[{"poster":"ParamD","comment_id":"1399055","timestamp":"1742074200.0","upvote_count":"1","content":"No, ask if for OU level report, not member level. Hence B."}],"timestamp":"1714574340.0"},{"timestamp":"1710628560.0","content":"Selected Answer: B\nB. Create an AWS Cost and Usage Report (CUR) from the AWS Organizations management account. Allow each team to visualize the CUR through an Amazon QuickSight dashboard.","upvote_count":"1","poster":"gofavad926","comment_id":"1175369"},{"upvote_count":"1","comment_id":"1158014","timestamp":"1708788540.0","poster":"Rajarshi","content":"C\nAs target is to design a solution so that each OU can view a breakdown of usage costs across its AWS accounts"},{"comment_id":"1145817","comments":[{"upvote_count":"3","timestamp":"1707515760.0","content":"Sorry, I'm wrong, RAM can't create a Cost Report.","poster":"acordovam","comment_id":"1145818"}],"upvote_count":"1","timestamp":"1707515520.0","poster":"acordovam","content":"Selected Answer: A\nThe question specifies that each OU should only view their own AWS accounts, not all accounts in the organization. While creating the solution in the management account might offer a centralized approach, it violates this crucial requirement."},{"poster":"abeb","timestamp":"1701021600.0","comment_id":"1080931","content":"B From management account of each account","upvote_count":"1"},{"content":"AWS Resource Access Manager has nothing to do with creating CUR.\nAnswer B is correct. Use AWS Organization management account","upvote_count":"1","poster":"daz2023","comment_id":"1022702","timestamp":"1696205100.0"},{"timestamp":"1692024120.0","comment_id":"980882","poster":"duriselvan","upvote_count":"1","content":"https://aws.amazon.com/blogs/mt/visualize-and-gain-insights-into-your-aws-cost-and-usage-with-cloud-intelligence-dashboards-using-amazon-quicksight/"},{"comment_id":"937364","content":"Selected Answer: B\nB by elimination","timestamp":"1688003820.0","poster":"NikkyDicky","upvote_count":"1"},{"content":"Selected Answer: B\nB As AWS Organizations Management account is only correct option","poster":"gameoflove","timestamp":"1683625560.0","comment_id":"892956","upvote_count":"1"},{"comment_id":"873240","poster":"leehjworking","comments":[{"comment_id":"884848","content":"AWS Resource Access Manager has nothing to do with creating CURs. It's for sharing resources with other accounts.","timestamp":"1682825700.0","upvote_count":"4","poster":"scuzzy2010"}],"timestamp":"1681785120.0","upvote_count":"1","content":"Can anyone explain why A is wrong? Thank you."},{"upvote_count":"2","comment_id":"852948","content":"Selected Answer: B\nB. Create an AWS Cost and Usage Report (CUR) from the AWS Organizations management account.","poster":"mfsec","timestamp":"1679988360.0"},{"timestamp":"1670947200.0","poster":"masetromain","upvote_count":"3","comment_id":"744252","content":"Selected Answer: B\nhttps://www.examtopics.com/discussions/amazon/view/71951-exam-aws-certified-solutions-architect-professional-topic-1/"}],"exam_id":33,"answer_ET":"B","isMC":true,"unix_timestamp":1670947200},{"id":"uYaGo9egZzsbxjtZrmba","discussion":[{"comment_id":"1101156","timestamp":"1703040900.0","upvote_count":"16","content":"Selected Answer: ABC\nAs transit gateway follows a hub and spoke model connecting all VPCs and VPNs to it makes more sense. Moreover, between VPCs and VPNs is invalid.","poster":"HappyPrince"},{"upvote_count":"11","poster":"HunkyBunky","timestamp":"1700733420.0","comments":[{"upvote_count":"3","poster":"devalenzuela86","comment_id":"1080116","timestamp":"1700926260.0","content":"Option E proposes configuring attachments between the VPCs and VPNs. This option is necessary to connect the VPCs and VPNs to the transit gateway."}],"comment_id":"1078307","content":"Selected Answer: ACE\nI guess ACE. The company wants to control which VPC will communicate with other VPC, that means that we don't need to setup attachment for all VPCs"},{"timestamp":"1730518980.0","content":"why i dont choose:\nD - VPC peering not feasible for hundreds of VPCs\nE and F, the attachments and route tables should be done on the transit gateways, not on the VPCs and VPNs.","comment_id":"1306052","poster":"Daniel76","upvote_count":"3"},{"content":"Answer ABC is correct. Since C has route tables, which gives Organization to control which VPC can communicate","comment_id":"1304447","upvote_count":"1","timestamp":"1730205900.0","poster":"Danm86"},{"upvote_count":"1","content":"Selected Answer: ABC\nFor those who think that, in relation to the requirement \"The company wants to control which VPCs can communicate with other VPCs\", option E would be correct, in fact this will be possible through letter C, therefore the answer is A, B, C.","timestamp":"1728521940.0","poster":"JoeTromundo","comment_id":"1295345"},{"comment_id":"1253714","timestamp":"1721743980.0","upvote_count":"1","content":"Selected Answer: ABC\nC is correct instea of E because all VPCs and VPN attach to Transit-GW","poster":"vip2"},{"timestamp":"1720241640.0","comments":[{"poster":"053081f","content":"Sorry I think ACE is correct, not ABC.","timestamp":"1720241700.0","comment_id":"1243185","upvote_count":"1"}],"upvote_count":"1","comment_id":"1243184","poster":"053081f","content":"Selected Answer: ACE\nThe question and opitons include (or lack) some typo errors.\n\nE should be \"Configure 'transit gateway' attachments between the VPCs and VPNs.\"\n\nThen, I think ABE is correct, not ABC.\n\nThe company wants to control \"which VPCs can communicate with other VPCs.\" It doesn't say \"all VPCs and VPNs.\"."},{"content":"Selected Answer: ABC\nABC for me","poster":"seetpt","comment_id":"1206015","timestamp":"1714728120.0","upvote_count":"3"},{"timestamp":"1710905820.0","comment_id":"1177897","content":"Selected Answer: ACE\nWe don't need \"all\"","upvote_count":"3","poster":"VerRi"},{"timestamp":"1709736480.0","content":"Selected Answer: ABC\nE. You don't configure attachments between VPCs and VPNs, you configure attachments to both VPCs and VPN from the transit gateway, thus B.","comment_id":"1167239","poster":"hogtrough","upvote_count":"6"},{"poster":"arberod","comment_id":"1148595","timestamp":"1707768780.0","upvote_count":"1","content":"Selected Answer: ACE\nIt is ACE"},{"comment_id":"1123186","poster":"tmlong18","upvote_count":"4","timestamp":"1705308060.0","content":"Selected Answer: ABC\nI go ABC"},{"content":"My Answer \"ACE\" Why B is correct? The question asks \"The company wants to control which VPCs can communicate with other VPCs\" Saying that Option B is \"Involves attaching every single VPC and VPN within the organization directly to the Transit Gateway\" where as Option C focuses on \"establishing attachments only between the VPCs that need to communicate with each other and the VPN gateway\" \nCan one explain why B is correct?","comment_id":"1119132","timestamp":"1704927900.0","upvote_count":"1","comments":[{"timestamp":"1704927960.0","upvote_count":"1","comment_id":"1119135","content":"Typo... I mean Option E\nOption E... focuses on \"establishing attachments only between the VPCs that need to communicate with each other and the VPN gateway\"\nCan anyone explain why B is correct?","poster":"vibzr2023"}],"poster":"vibzr2023"},{"content":"Selected Answer: ABC\nOption A, B, C. Option E looks feasible instead of B but that is not a requirement as company only wants to control VPC to VPC communication.","poster":"career360guru","timestamp":"1704828900.0","upvote_count":"6","comment_id":"1117789"},{"timestamp":"1702116780.0","content":"Selected Answer: ABC\nABC - we need to read the answers as a combination of steps.","upvote_count":"5","comments":[{"upvote_count":"1","comments":[{"comment_id":"1100687","poster":"ayadmawla","content":"This article suggests the use of NACL to control inter-vpc traffic but that option is not available in the question (although there is another question that brings it up)\n\nhttps://intuitive.cloud/blog/securing-multi-vpc-connectivity-with-aws-transit-gateway-#:~:text=Use%20security%20groups%20and%20NACLs,connected%20to%20the%20Transit%20Gateway.","timestamp":"1702995240.0","upvote_count":"1"}],"comment_id":"1100683","poster":"ayadmawla","timestamp":"1702995000.0","content":"One issue though that in order to control which VPC talks to which one, we need to setup route tables on each VPC (E) and not on the transit VPC (C) as that need to be light. So I am thinking that the choice should be ABE and not ABC. \n\nThe specific use case is not mentioned here but this link should give an idea of how route tables need to be configured. https://docs.aws.amazon.com/vpc/latest/tgw/TGW_Scenarios.html"}],"comment_id":"1091725","poster":"ayadmawla"},{"timestamp":"1701833700.0","poster":"shaaam80","upvote_count":"5","comment_id":"1088988","content":"Selected Answer: ABC\nAnswer - ABC"},{"comment_id":"1082758","poster":"shaaam80","comments":[{"timestamp":"1701833640.0","upvote_count":"2","comment_id":"1088987","content":"I stand corrected! Answer should be ABC.\nB- Configure attachments to all VPCs and VPNs. This is the TGW attachments to all VPCs and VPNs. \nE - Configure attachments between the VPCs and VPNs - WRONG!!","poster":"shaaam80"}],"content":"Selected Answer: ACE\nACE. Option B mentions attaching 'all' VPCs, might not suggest control of what VPCs the company wants to include communcation","timestamp":"1701190740.0","upvote_count":"3"},{"timestamp":"1701020640.0","content":"Selected Answer: ABC\ni'd go for abc as well.","poster":"jpes","upvote_count":"5","comment_id":"1080914"},{"timestamp":"1700919600.0","comment_id":"1080027","upvote_count":"3","content":"Selected Answer: ACE\nI guess ACE","poster":"salazar35"},{"timestamp":"1700600880.0","upvote_count":"6","poster":"devalenzuela86","content":"Selected Answer: ABC\nABC for sure","comment_id":"1076690"}],"timestamp":"2023-11-21 22:08:00","unix_timestamp":1700600880,"answer_description":"","isMC":true,"question_text":"A company operates a fleet of servers on premises and operates a fleet of Amazon EC2 instances in its organization in AWS Organizations. The company's AWS accounts contain hundreds of VPCs. The company wants to connect its AWS accounts to its on-premises network. AWS Site-to-Site VPN connections are already established to a single AWS account. The company wants to control which VPCs can communicate with other VPCs.\n\nWhich combination of steps will achieve this level of control with the LEAST operational effort? (Choose three.)","answer_ET":"ABC","question_id":269,"question_images":[],"answer_images":[],"exam_id":33,"choices":{"C":"Setup transit gateway route tables. Associate the VPCs and VPNs with the route tables.","D":"Configure VPC peering between the VPCs.","B":"Configure attachments to all VPCs and VPNs.","A":"Create a transit gateway in an AWS account. Share the transit gateway across accounts by using AWS Resource Access Manager (AWS RAM).","E":"Configure attachments between the VPCs and VPNs.","F":"Setup route tables on the VPCs and VPNs."},"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/126768-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"ABC","answers_community":["ABC (73%)","ACE (28%)"]},{"id":"mtuBYSwepTuPZrzd83nm","discussion":[{"comment_id":"1093353","upvote_count":"8","poster":"GaryQian","content":"Selected Answer: D\nAurora Serverless designed to be handling heavy and unpredictable load while Aurora global table is more on low-lantency connection","timestamp":"1702289520.0"},{"upvote_count":"6","poster":"salazar35","timestamp":"1700920200.0","comment_id":"1080037","content":"Selected Answer: D\nAurora Serverless v1 provides a relatively simple, cost-effective option for infrequent, intermittent, or unpredictable workloads"},{"timestamp":"1724304120.0","comment_id":"1270503","upvote_count":"1","content":"Selected Answer: B\nI guess this is a very old question; as of today, Aurora Serverless v1 is going EOL by December, 2024. So, invalid question. But if we still had to make a decision with D, it will be B.","poster":"asquared16"},{"content":"Selected Answer: D\nOption D. This question looks incomplete as it does not give options for cost savings opportunity for application layer.","comment_id":"1117795","timestamp":"1704829140.0","poster":"career360guru","upvote_count":"2"},{"comment_id":"1088990","content":"Selected Answer: D\nAnswer D\nAurora Serverless can scale better to handle heavy loads","timestamp":"1701833820.0","upvote_count":"2","poster":"shaaam80"},{"timestamp":"1701401760.0","poster":"Russs99","comment_id":"1084916","upvote_count":"2","content":"Selected Answer: D\nPer scenario, the application is write intensive and the load varies due to burst. Aurora Serverless with compute saving plans is the correct answer"},{"content":"Selected Answer: D\nD for sure","poster":"devalenzuela86","comments":[{"comment_id":"1080111","timestamp":"1700925660.0","content":"Change to C. Its most cost effective","poster":"devalenzuela86","upvote_count":"1"}],"upvote_count":"3","comment_id":"1076697","timestamp":"1700601120.0"}],"url":"https://www.examtopics.com/discussions/amazon/view/126769-exam-aws-certified-solutions-architect-professional-sap-c02/","question_id":270,"answer_images":[],"question_images":[],"exam_id":33,"answer":"D","answer_ET":"D","answers_community":["D (96%)","4%"],"question_text":"A company needs to optimize the cost of its application on AWS. The application uses AWS Lambda functions and Amazon Elastic Container Service (Amazon ECS) containers that run on AWS Fargate. The application is write-heavy and stores data in an Amazon Aurora MySQL database.\n\nThe load on the application is not consistent. The application experiences long periods of no usage, followed by sudden and significant increases and decreases in traffic. The database runs on a memory optimized DB instance that cannot handle the load.\n\nA solutions architect must design a solution that can scale to handle the changes in traffic.\n\nWhich solution will meet these requirements MOST cost-effectively?","topic":"1","answer_description":"","unix_timestamp":1700601120,"isMC":true,"timestamp":"2023-11-21 22:12:00","choices":{"D":"Migrate the database to Aurora Serverless v1. Purchase Compute Savings Plans.","B":"Migrate the database to an Aurora DB cluster that has multiple writer instances. Purchase Instance Savings Plans.","C":"Migrate the database to an Aurora global database. Purchase Compute Savings Plans and RDS Reserved instances.","A":"Add additional read replicas to the database. Purchase Instance Savings Plans and RDS Reserved Instances."}}],"exam":{"name":"AWS Certified Solutions Architect - Professional SAP-C02","lastUpdated":"11 Apr 2025","isMCOnly":true,"isBeta":false,"isImplemented":true,"provider":"Amazon","id":33,"numberOfQuestions":529},"currentPage":54},"__N_SSP":true}