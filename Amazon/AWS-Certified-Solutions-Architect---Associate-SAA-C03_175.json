{"pageProps":{"questions":[{"id":"SAFdPNvqOl9CysgdjI05","question_id":871,"question_text":"A company's near-real-time streaming application is running on AWS. As the data is ingested, a job runs on the data and takes 30 minutes to complete. The workload frequently experiences high latency due to large amounts of incoming data. A solutions architect needs to design a scalable and serverless solution to enhance performance.\n\nWhich combination of steps should the solutions architect take? (Choose two.)","answer_images":[],"topic":"1","answer_ET":"AE","discussion":[{"poster":"xBUGx","upvote_count":"5","comments":[{"upvote_count":"1","comments":[{"comment_id":"1320460","upvote_count":"1","timestamp":"1733030880.0","content":"but that will introduce additional overhead.","poster":"JA2018"}],"comment_id":"1289545","poster":"JoeTromundo","content":"But through Step Functions it would be possible to divide a long task, lasting more than 15 minutes, into multiple Lambda invocations with a maximum duration of 15 minutes.","timestamp":"1727363460.0"}],"timestamp":"1712180700.0","comment_id":"1188918","content":"Selected Answer: AE\nLambda maxed to 15mins"},{"upvote_count":"2","comment_id":"1301839","content":"Eliminate B because lambda max handle 15minutes.","poster":"mk168898","timestamp":"1729651620.0"},{"content":"Selected Answer: AE\nAnswerAE\n\nAmazon Kinesis data firehose for data ingesting, and hence output cannot go to EC2, hence Fargate with ECS.","upvote_count":"3","poster":"Scheldon","timestamp":"1717156260.0","comment_id":"1222114"},{"poster":"Hkayne","upvote_count":"3","content":"Selected Answer: AE\nA is correct for ingesting data.\nB or E both choises are serverless but the difference is the lambda maximum execution time is 15 minutes. So the right option is E.\nA and E","comment_id":"1198577","timestamp":"1713527100.0"},{"poster":"Awsbeginner87","content":"Selected Answer: AE\nA-ingesting real-time data\nE- serverless option ECS+fargate","timestamp":"1712188620.0","comment_id":"1188982","upvote_count":"4"},{"comment_id":"1188756","timestamp":"1712161140.0","poster":"AlvinC2024","upvote_count":"3","content":"Selected Answer: AE\nThe maximum run time for lambda is 15 mins."}],"unix_timestamp":1712161140,"url":"https://www.examtopics.com/discussions/amazon/view/137829-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"AE","timestamp":"2024-04-03 18:19:00","answer_description":"","exam_id":31,"isMC":true,"question_images":[],"choices":{"A":"Use Amazon Kinesis Data Firehose to ingest the data.","C":"Use AWS Database Migration Service (AWS DMS) to ingest the data.","B":"Use AWS Lambda with AWS Step Functions to process the data.","D":"Use Amazon EC2 instances in an Auto Scaling group to process the data.","E":"Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data."},"answers_community":["AE (100%)"]},{"id":"nl0HZWvhWBxuo5bGqOLA","discussion":[{"upvote_count":"2","comment_id":"1301840","content":"not allowed to access internet, and need to access S3 => gateway VPC endpoint","timestamp":"1729651740.0","poster":"mk168898"},{"content":"Selected Answer: A\nAnswerA","poster":"Scheldon","comment_id":"1222119","timestamp":"1717156560.0","upvote_count":"2"},{"poster":"sandordini","comment_id":"1204144","upvote_count":"3","timestamp":"1714411860.0","content":"Selected Answer: A\nno internet, S3 > gateway VPC endpoint"},{"poster":"Tanidanindo","content":"Selected Answer: A\nVPC endpoint","upvote_count":"2","comment_id":"1191947","timestamp":"1712636520.0"},{"poster":"Mikado211","comment_id":"1189549","timestamp":"1712265360.0","upvote_count":"2","content":"Selected Answer: A\n\"data cannot be sent over the public internet.\" == VPC Endpoint"},{"timestamp":"1712188500.0","content":"Selected Answer: A\nOption A","comment_id":"1188981","upvote_count":"2","poster":"Awsbeginner87"}],"answer":"A","choices":{"C":"Deploy the S3 bucket inside the VPCreate a route in the VPC route table to the bucket.","B":"Create an internal Network Load Balancer that has the S3 bucket as the target.","A":"Create a gateway VPC endpoint for Amazon S3. Create a route in the VPC route table to the endpoint.","D":"Create an AWS Direct Connect connection between the VPC and an S3 regional endpoint."},"answers_community":["A (100%)"],"exam_id":31,"answer_description":"","answer_ET":"A","isMC":true,"unix_timestamp":1712188500,"answer_images":[],"question_images":[],"question_text":"A company runs a web application on multiple Amazon EC2 instances in a VPC. The application needs to write sensitive data to an Amazon S3 bucket. The data cannot be sent over the public internet.\n\nWhich solution will meet these requirements?","timestamp":"2024-04-04 01:55:00","question_id":872,"url":"https://www.examtopics.com/discussions/amazon/view/137855-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1"},{"id":"r1D2vxxDPZdOvQ2B4q5y","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/137854-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1712188500,"exam_id":31,"discussion":[{"content":"Selected Answer: D\nSince need analyze the current EBS volume cost and to recommend optimizations, so have to use AWS compute optimizer","comment_id":"1231332","timestamp":"1718536980.0","poster":"KennethNg923","upvote_count":"2"},{"upvote_count":"4","content":"Selected Answer: D\nAnswerD\n\nAWS Compute Optimizer helps avoid overprovisioning and underprovisioning four types of AWS resources—Amazon Elastic Compute Cloud (EC2) instance types, Amazon Elastic Block Store (EBS) volumes, Amazon Elastic Container Service (ECS) services on AWS Fargate, and AWS Lambda functions—based on your utilization data.\nhttps://aws.amazon.com/compute-optimizer/","timestamp":"1717156680.0","comment_id":"1222120","poster":"Scheldon"},{"poster":"Hkayne","timestamp":"1713527280.0","upvote_count":"3","content":"Selected Answer: D\nGet recommendations to optimize your use of AWS resources","comment_id":"1198578"},{"comment_id":"1188980","upvote_count":"2","timestamp":"1712188500.0","content":"Selected Answer: D\nAWS Compute Optimizer helps avoid overprovisioning and underprovisioning four types of AWS resources—Amazon Elastic Compute Cloud (EC2) instance types, Amazon Elastic Block Store (EBS) volumes, Amazon Elastic Container Service (ECS) services on AWS Fargate, and AWS Lambda functions—based on your utilization data.","poster":"Awsbeginner87"}],"timestamp":"2024-04-04 01:55:00","answer_images":[],"isMC":true,"choices":{"B":"Use AWS Systems Manager reporting to determine EBS volume recommendations for optimization.","D":"Use AWS Compute Optimizer to generate EBS volume recommendations for optimization.","C":"Use Amazon CloudWatch metrics reporting to determine EBS volume recommendations for optimization.","A":"Use Amazon Inspector reporting to generate EBS volume recommendations for optimization."},"question_images":[],"answers_community":["D (100%)"],"answer_ET":"D","answer":"D","question_id":873,"answer_description":"","question_text":"A company runs its production workload on Amazon EC2 instances with Amazon Elastic Block Store (Amazon EBS) volumes. A solutions architect needs to analyze the current EBS volume cost and to recommend optimizations. The recommendations need to include estimated monthly saving opportunities.\n\nWhich solution will meet these requirements?"},{"id":"nSw8jBPMYWQaVABtsS26","exam_id":31,"answer":"B","timestamp":"2024-04-03 23:50:00","answer_description":"","answer_ET":"B","unix_timestamp":1712181000,"question_text":"A global company runs its workloads on AWS. The company's application uses Amazon S3 buckets across AWS Regions for sensitive data storage and analysis. The company stores millions of objects in multiple S3 buckets daily. The company wants to identify all S3 buckets that are not versioning-enabled.\n\nWhich solution will meet these requirements?","question_id":874,"topic":"1","choices":{"B":"Enable IAM Access Analyzer for S3 to identify all S3 buckets that are not versioning-enabled across Regions.","A":"Use Amazon S3 Storage Lens to identify all S3 buckets that are not versioning-enabled across Regions.","C":"Create an S3 Multi-Region Access Point to identify all S3 buckets that are not versioning-enabled across Regions."},"isMC":true,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/137847-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"poster":"joseantoniopolo","upvote_count":"10","timestamp":"1728284040.0","comment_id":"1190805","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/aws/s3-storage-lens/"},{"poster":"nadeerm","comment_id":"1379819","upvote_count":"1","timestamp":"1741592220.0","content":"Selected Answer: B\nAnswer is B\nOption A: Set up an AWS CloudTrail event that has a rule to identify all S3 buckets that are not versioning-enabled across Regions."},{"timestamp":"1735631340.0","poster":"LeonSauveterre","comment_id":"1334686","upvote_count":"3","content":"Selected Answer: B\nFYI, the missing Option A: Set up an AWS CloudTrail event that has a rule to identify all S3 buckets that are not versioning-enabled across Regions.\n\nA - CloudTrail is meant for audit logs, not for analyzing bucket configurations directly.\nB - Storage Lens can provide an overview of all S3 buckets and their versioning status across Regions. Those built-in features that can directly tackle your problems should be your top preferences.\nC - IAM Access Analyzer is designed for access management, not storage configuration analysis.\nD - S3 Multi-Region Access Points allow applications to access S3 buckets across Regions using a single global endpoint. So not relevant as well."},{"poster":"sandordini","content":"Correct answer: A\nA: You can use an AWS Config managed rule to identify Amazon S3 buckets that do not have versioning enabled.","comment_id":"1204154","upvote_count":"2","timestamp":"1730231100.0","comments":[{"upvote_count":"1","comment_id":"1325977","timestamp":"1734058140.0","poster":"JA2018","content":"Potential Option A could \"Use AWS Config rules to identify all S3 buckets that are not versioning-enabled across Regions \""},{"poster":"sandordini","upvote_count":"8","comment_id":"1204643","timestamp":"1730309580.0","content":"Question #889 contains all the answers including A, which is cloudtrail and obviously wrong.\nOn the other hand S3 Storage Lens: \nYou can use the Versioning-enabled bucket count metric to see which buckets use S3 Versioning. Then, you can take action in the S3 console to enable S3 Versioning for other buckets. So correct answer: B"}]},{"upvote_count":"2","timestamp":"1727999160.0","comment_id":"1188978","content":"Where is option A","poster":"Awsbeginner87"},{"comment_id":"1188920","timestamp":"1727992200.0","content":"where is option A?","poster":"xBUGx","upvote_count":"2"}],"answers_community":["B (100%)"],"question_images":[]},{"id":"kcJoR45c29LIEPskY3no","answer_ET":"A","topic":"1","answer":"A","isMC":true,"answer_images":[],"unix_timestamp":1712501700,"answers_community":["A (100%)"],"answer_description":"","exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/138082-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"C":"Create a flow by using Amazon AppFlow. Send the orders to the flow. Configure an AWS Lambda function as the target to process the orders.","B":"Create an Amazon Simple Notification Service (Amazon SNS) standard topic. Publish all the orders to the SNS standard topic. Configure the application as a notification target.","D":"Configure AWS X-Ray in the application to track the order requests. Configure the application to process the orders by pulling the orders from Amazon CloudWatch.","A":"Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Put all the orders in the SQS queue. Configure an AWS Lambda function as the target to process the orders."},"timestamp":"2024-04-07 16:55:00","question_text":"A company wants to enhance its ecommerce order-processing application that is deployed on AWS. The application must process each order exactly once without affecting the customer experience during unpredictable traffic surges.\n\nWhich solution will meet these requirements?","question_id":875,"discussion":[{"comment_id":"1301841","poster":"mk168898","timestamp":"1729652040.0","upvote_count":"2","content":"Must process at least once => SQS"},{"content":"Selected Answer: A\n\"Standard queues support at-least-once message delivery, and FIFO queues support exactly-once message processing and high-throughput mode.\"\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html#sqs-benefits","poster":"MatAlves","upvote_count":"2","comment_id":"1287149","timestamp":"1726892700.0"},{"content":"Selected Answer: A\nmust process each order exactly once -> FIFO queue","comment_id":"1231333","timestamp":"1718537220.0","poster":"KennethNg923","upvote_count":"2"},{"content":"Selected Answer: A\nAnswerA\nSQS with FIFO queue will allow to read every customer order in order in which they came and only once.","poster":"Scheldon","comment_id":"1222133","upvote_count":"2","timestamp":"1717157280.0"},{"comment_id":"1198583","content":"Selected Answer: A\nFIFO queue is the solution","timestamp":"1713527460.0","poster":"Hkayne","upvote_count":"2"},{"poster":"Tanidanindo","comment_id":"1191950","upvote_count":"2","content":"Selected Answer: A\nSQS and FIFO","timestamp":"1712636760.0"},{"comment_id":"1191076","timestamp":"1712510220.0","content":"Selected Answer: A\nFIFO > SQS","upvote_count":"2","poster":"Kaula"},{"comment_id":"1191020","timestamp":"1712501700.0","content":"Selected Answer: A\nThe application must process each order exactly once == SQS + FIFO","poster":"Mikado211","upvote_count":"2"}],"question_images":[]}],"exam":{"id":31,"provider":"Amazon","isMCOnly":true,"numberOfQuestions":1019,"isBeta":false,"lastUpdated":"11 Apr 2025","isImplemented":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":175},"__N_SSP":true}