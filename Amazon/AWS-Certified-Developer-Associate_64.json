{"pageProps":{"questions":[{"id":"oN6QM8SQtTDlpM6nggfQ","answer_images":[],"answers_community":["B (83%)","A (17%)"],"answer_description":"","unix_timestamp":1674552180,"exam_id":25,"topic":"1","question_text":"Deploy the image to the production Amazon Elastic Container Service (Amazon ECS) cluster by using AWS CodeDeploy.\n\nRecently, the CodeDeploy deployments began failing in Stage 4. The deployments are unable to perform rollbacks. The developer must minimize the number of failures that reach production without slowing down the pipeline.\n\nWhich solution will meet these requirements?","answer":"B","question_id":316,"timestamp":"2023-01-24 10:23:00","url":"https://www.examtopics.com/discussions/amazon/view/96728-exam-aws-certified-developer-associate-topic-1-question-383/","isMC":true,"choices":{"C":"Replace Stage 4 with a manual deployment until the developer can add more quality tests to the automation.","D":"Modify Stage 3 so that it uses Amazon ECS and CodeDeploy.","A":"Add a human review and approval stage between Stage 3 and Stage 4.","B":"Perform a more comprehensive test before Stage 2 by adding a test for the CodeCommit trigger in Stage 1."},"discussion":[{"comment_id":"798914","poster":"Drey","content":"Selected Answer: B\nIt's B. A and C would slow the pipeline down. D might also be possible","upvote_count":"1","timestamp":"1675609020.0"},{"timestamp":"1675515540.0","content":"Selected Answer: B\nAdding manual/human trigger will slow down the pipeline by alot. Adding more tests will help detection of bugs before production.","upvote_count":"2","comment_id":"797958","poster":"Smartiup"},{"comment_id":"795250","poster":"tieyua","upvote_count":"1","timestamp":"1675264980.0","content":"How's A any different from C? But looks like 2/3 of the question is probably missing, we have to let this go for now."},{"content":"Selected Answer: A\nGoing with A, you can't add I think B is wrong because stage1 is per-requisite gathering and can't add test functionalities there","poster":"breathingcloud","comment_id":"787312","upvote_count":"1","timestamp":"1674627180.0"},{"comment_id":"786348","timestamp":"1674552180.0","poster":"JagpreetLM10","upvote_count":"2","content":"Selected Answer: B\nShould be B"}],"question_images":[],"answer_ET":"B"},{"id":"9UxibJS6wAfMW2QWdoAi","question_id":317,"exam_id":25,"choices":{"D":"Amazon Kinesis Streams","B":"Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application","C":"Amazon Kinesis Firehose","A":"Amazon SNS with fanout to an SQS queue for each application"},"question_text":"An application is real-time processing millions of events that are received through an API.\n\nWhat service could be used to allow multiple consumers to process the data concurrently and MOST cost-effectively?","topic":"1","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/96561-exam-aws-certified-developer-associate-topic-1-question-384/","timestamp":"2023-01-23 05:05:00","answers_community":["D (80%)","C (20%)"],"discussion":[{"poster":"AsmaZoheb","timestamp":"1705768920.0","comment_id":"1127399","upvote_count":"2","content":"Selected Answer: D\nI will go with D as kinesis stream is processing custom data , real time analytics while firehose is for stream data to other aws services, there is not shard to ingest data in firehose, not streaming real time data, so for me D is correct answer"},{"upvote_count":"1","timestamp":"1696946400.0","poster":"llw33","comment_id":"1039579","content":"Selected Answer: C\nC, 'cause Firehose also can process data, and it is more cost-effective than Data Streams."},{"upvote_count":"4","poster":"joanneli77","content":"Key phrase: Real-time. Queueing is not real time.","timestamp":"1676930400.0","comment_id":"815924"},{"timestamp":"1674446700.0","poster":"JagpreetLM10","comment_id":"784956","upvote_count":"2","content":"Selected Answer: D\nD. https://www.examtopics.com/discussions/amazon/view/5485-exam-aws-certified-developer-associate-topic-1-question-78/"}],"answer_images":[],"unix_timestamp":1674446700,"answer":"D","isMC":true,"answer_description":"","question_images":[]},{"id":"vq89wsDkAsmiIWlNzCWF","topic":"1","exam_id":25,"discussion":[{"content":"Selected Answer: C\nThis solution will improve the performance and cost of the function in the following ways:\n\n Declaring the Amazon S3 SDK and object request outside of the function handler will prevent the function from having to initialize the SDK and create a new object request for every invocation. This will save time and resources.\n Configuring provisioned concurrency will ensure that there are always enough Lambda instances available to handle incoming requests. This will help to reduce latency and improve the overall performance of the function.\n\nThe other options are not as effective or cost-effective.\n\n Storing the geospatial dataset on Amazon EFS instead of on Amazon S3 will increase the cost of the function. EFS is a more expensive storage service than S3.\n Caching the data in the /tmp directory for use with every invocation is not a good solution for a large geospatial dataset. The /tmp directory is a temporary directory that is cleared between invocations.\n Increasing the memory capacity of the function will increase the cost of the function. It is also not necessary to increase the memory capacity of the function to improve the performance of the function.\n\nTherefore, the best answer is C.","comment_id":"1067396","timestamp":"1699635660.0","poster":"kyoharo","upvote_count":"1"},{"content":"Selected Answer: C\nThe question says that the data set is large so I will assume that the set may be > 10Gb and creating EFS for large amount of data will not be the \"...faster with the least possible cost...\" (key requirement).\n\n I will go with C, it takes advantage of reusing the SDK client and object request across many invocations and eliminates initializing the SDK and object request with every invocation which is cool and cheap. :)","comment_id":"917239","upvote_count":"1","poster":"rlnd2000","timestamp":"1686142620.0"},{"content":"Selected Answer: C\nC, there is a large geospatial dataset. It's costly to use EFS with large files.","upvote_count":"2","poster":"Drey","timestamp":"1675698600.0","comment_id":"799924"},{"timestamp":"1675523640.0","content":"Selected Answer: B\nThe question is a bit vague. What is the size of the geospatial dataset? If it is less than 512 MB the answer would be B. If it is bigger than 512 MB, /tmp can't be used. But would I call a file of 512 MB size \"a big dataset\"? Probably not.","upvote_count":"1","comments":[{"timestamp":"1676467440.0","upvote_count":"6","comment_id":"809578","content":"/tmp can be 10G","poster":"tieyua"}],"poster":"pancman","comment_id":"798090"},{"upvote_count":"2","comment_id":"797972","poster":"Smartiup","content":"Selected Answer: A\nThe problem here is aquiring the large data set BEFORE processing it so C increassing the memory/cpu will not help us, provision will if the function is not constantly runing but we should focus on the LARGE dataset. \nThe /tmp has a 500mb limit. If the dataset is larger then that option B might not be possible. Leaves us with option A.","comments":[{"poster":"raaja090","content":"Temp can store 10G","upvote_count":"2","timestamp":"1693018920.0","comment_id":"990482"},{"poster":"tony554556","comment_id":"799482","content":"Thanks, large means 500MB limit will not be enough. So A is correct","upvote_count":"1","timestamp":"1675666920.0"},{"poster":"hcsaba1982","content":"/tmp is 10G, so still could be B, but lambda is ephemeral, so how it could use the caching function in the next invocation ? I believe this is why EFS usage is better, so A.","upvote_count":"1","comment_id":"1061388","timestamp":"1699010820.0"}],"timestamp":"1675516440.0"},{"comment_id":"795269","timestamp":"1675266780.0","content":"Selected Answer: C\nI think C is a better solution, minimal change to existing code, and depends on traffic, keep a low provisioned concurrency, data will always be warm and available.\n\nThe problems with EFS are: It cost extra and \"geospatial dataset\" may not be compatible with file system","upvote_count":"3","poster":"tieyua"},{"upvote_count":"2","timestamp":"1674552300.0","comment_id":"786349","poster":"JagpreetLM10","content":"Selected Answer: B\nBBBBB ."},{"timestamp":"1674367440.0","upvote_count":"3","comment_id":"783953","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/compute/choosing-between-aws-lambda-data-storage-options-in-web-apps/","poster":"Phinx"}],"answer":"C","question_text":"A logistics company built an asset-tracking microservice by using the AWS Serverless Application Model (AWS SAM). One of the microserviceâ€™s AWS Lambda functions needs to import a large geospatial dataset from Amazon S3 before the function can process the requests. The import of the dataset requires significant time and is causing the function to take too long to finish running. The results are increased latency and cost.\n\nA developer needs to optimize the function to process requests faster with the least possible cost.\n\nWhich solution will meet these requirements?","answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/96428-exam-aws-certified-developer-associate-topic-1-question-385/","answer_description":"","question_images":[],"question_id":318,"choices":{"C":"Declare the Amazon S3 SDK and object request outside of the function handler. Configure provisioned concurrency for the function.","A":"Store the geospatial dataset on Amazon Elastic File System (Amazon EFS) instead of on Amazon S3. Attach the EFS file system to the function. Retrieve the dataset by accessing the file system for every invocation.","D":"Declare the Amazon S3 SDK and object request outside of the function handler. Increase memory capacity of the function to 1,769 MB.","B":"Store the geospatial dataset on Amazon Elastic File System (Amazon EFS) instead of on Amazon S3. Attach the EFS file system to the function. Cache the data in the /tmp directory for use with every invocation."},"timestamp":"2023-01-22 07:04:00","unix_timestamp":1674367440,"isMC":true,"answers_community":["C (47%)","B (40%)","13%"],"answer_images":[]},{"id":"E2dkfxAl2cLALgZiVo4h","choices":{"C":"Configure the CodeBuild agent to build the code in the local system.","B":"Configure CodeBuild jobs on AWS for each branch build process.","D":"Configure a Jenkins plugin for CodeBuild to run the code build process.","A":"Configure an Amazon EC2 instance with the CodeBuild agent to build the code."},"answer":"B","unix_timestamp":1674367560,"answer_images":[],"answer_description":"","exam_id":25,"url":"https://www.examtopics.com/discussions/amazon/view/96429-exam-aws-certified-developer-associate-topic-1-question-386/","question_text":"A company set up a continuous build process that uses AWS CodeBuild and AWS CodeCommit. During the development phase, developers are frequently pushing code and causing significant build failures. The company wants a solution that will build code before the developers push the code to the main branch.\n\nWhich solution meets these requirements MOST cost-effectively?","answers_community":["B (59%)","C (41%)"],"discussion":[{"timestamp":"1699635840.0","content":"Selected Answer: B\nThe most cost-effective solution is to configure CodeBuild jobs on AWS for each branch build process. This is because CodeBuild is a fully managed service that scales automatically, so you only pay for the resources you use.\n\nConfiguring an Amazon EC2 instance with the CodeBuild agent would be more expensive, as you would need to pay for the EC2 instance even when it is not in use. Configuring the CodeBuild agent to build the code in the local system would not be feasible, as it would require each developer to have a local machine that is powerful enough to build the code. Configuring a Jenkins plugin for CodeBuild would also be more expensive, as you would need to pay for a Jenkins license.\n\nTherefore, the most cost-effective solution is to configure CodeBuild jobs on AWS for each branch build process. This will allow you to build your code before it is pushed to the main branch, without incurring any additional costs.\n\nSo the answer is (B).","poster":"kyoharo","upvote_count":"3","comment_id":"1067398"},{"timestamp":"1679538960.0","content":"it'c C clearly.","comment_id":"847706","upvote_count":"1","poster":"JuanFe"},{"comment_id":"847645","content":"Answer is C:\nCOST is the key word here\nhttps://docs.aws.amazon.com/codebuild/latest/userguide/use-codebuild-agent.html","timestamp":"1679533140.0","upvote_count":"2","poster":"iamunstopable"},{"content":"Selected Answer: B\nBut configuring CodeBuild jobs on AWS for each branch build process is the most cost-effective solution as it will allow developers to build code before pushing it to the main branch. This way, developers can identify and resolve any issues in the code before it is merged into the main branch, reducing the number of build failures and increasing the efficiency of the build process. Additionally, CodeBuild is a fully managed service, so there is no need to set up and manage additional infrastructure, making it a cost-effective solution.","poster":"Drey","comment_id":"798934","timestamp":"1675610880.0","upvote_count":"3"},{"comment_id":"798098","timestamp":"1675524120.0","poster":"pancman","upvote_count":"2","content":"Selected Answer: C\nMOST cost-effectively is the keyword here. The answer is C."},{"timestamp":"1675267980.0","upvote_count":"4","comment_id":"795284","content":"Selected Answer: B\nFrom real life experience, you may not own the entire pipeline and not always possible to clone everything and build locally. Plus, the question is asking \"before push code to main branch\". \n\nA normal setup is to have gated checkin on feature branch, so changes only made it to source if build succeeded. Then use pull request to merge feature into dev/master. Can't guarantee that's the exam is trying to ask, but that's how it's done.","poster":"tieyua","comments":[{"content":"100% Agree. Do code in feature branch do a pull request for a main branch. Triger on PR to build the code from feature branch and test it before the merge with main. That is how it should be in real software Development projects. For me B it is.","poster":"Smartiup","timestamp":"1675517640.0","comment_id":"797994","upvote_count":"1"}]},{"timestamp":"1674552420.0","poster":"JagpreetLM10","comment_id":"786351","content":"Selected Answer: C\nCCCCCCCC","upvote_count":"3"},{"upvote_count":"2","poster":"Phinx","content":"Selected Answer: C\nhttps://www.examtopics.com/discussions/amazon/view/68892-exam-aws-certified-developer-associate-topic-1-question-429/","timestamp":"1674367560.0","comment_id":"783955"}],"question_id":319,"isMC":true,"question_images":[],"answer_ET":"B","topic":"1","timestamp":"2023-01-22 07:06:00"},{"id":"4ctiA2STNqLGh5SILYrW","answers_community":["D (77%)","C (15%)","8%"],"answer_description":"","answer_images":[],"timestamp":"2023-01-22 07:15:00","answer_ET":"D","unix_timestamp":1674368100,"exam_id":25,"answer":"D","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/96432-exam-aws-certified-developer-associate-topic-1-question-387/","question_text":"A company uses AWS CloudFormation to deploy an application that uses an Amazon API Gateway REST API with AWS Lambda function integration. The application uses Amazon DynamoDB for data persistence. The application has three stages: development, testing, and production. Each stage uses its own DynamoDB table.\n\nThe company has encountered unexpected issues when promoting changes to the production stage. The changes were successful in the development and testing stages. A developer needs to route 20% of the traffic to the new production stage API with the next production release. The developer needs to route the remaining 80% of the traffic to the existing production stage. The solution must minimize the number of errors that any single customer experiences.\n\nWhich approach should the developer take to meet these requirements?","question_id":320,"choices":{"A":"Update 20% of the planned changes to the production stage. Deploy the new production stage. Monitor the results. Repeat this process five times to test all planned changes.","B":"Update the Amazon Route 53 DNS record entry for the production stage API to use a weighted routing policy. Set the weight to a value of 80. Add a second record for the production domain name. Change the second routing policy to a weighted routing policy. Set the weight of the second policy to a value of 20. Change the alias of the second policy to use the testing stage API.","C":"Deploy an Application Load Balancer (ALB) in front of the REST API. Change the production API Amazon Route 53 record to point traffic to the ALB. Register the production and testing stages as targets of the ALB with weights of 80% and 20%, respectively.","D":"Configure canary settings for the production stage API. Change the percentage of traffic directed to canary deployment to 20%. Make the planned updates to the production stage. Deploy the changes."},"topic":"1","discussion":[{"poster":"DrDopey","content":"Selected Answer: B\nOption B is the best approach to meet the requirements. With this approach, you can update the Amazon Route 53 DNS record entry for the production stage API to use a weighted routing policy. You can set the weight of the first policy to 80, which will route 80% of the traffic to the existing production stage. You can then add a second record for the production domain name and change the routing policy to a weighted routing policy, with a weight of 20. You can then change the alias of the second policy to use the testing stage API, which will route 20% of the traffic to the new production stage API. By doing so, you can minimize the number of errors that any single customer experiences and test the new production stage API before directing more traffic to it.\n\nThe question never states its intention to move the rest of the traffic over once the testing is complete which would indicate a Canary deployment, so D assumes too much","upvote_count":"1","comment_id":"823000","timestamp":"1677448620.0"},{"timestamp":"1675699440.0","content":"Selected Answer: D\nIt's D.","comment_id":"799938","poster":"Drey","upvote_count":"2"},{"comments":[{"poster":"joanneli77","content":"API Gateway can be in front of an ALB. An ALB cannot be in front of an API Gateway.","upvote_count":"1","timestamp":"1676931120.0","comment_id":"815948"}],"comment_id":"798109","timestamp":"1675524900.0","content":"I am inbetween C and D. The question seems like a canary deployment will be appropriate, so D looks good. But I can see that C could also work in this situation.","upvote_count":"1","poster":"pancman"},{"upvote_count":"4","comment_id":"798001","timestamp":"1675518000.0","poster":"Smartiup","content":"Selected Answer: D\nThe typical Canary deployment. First the 20% of trafic then route all of it to the new stage if all went well."},{"timestamp":"1675268940.0","upvote_count":"2","poster":"tieyua","content":"Selected Answer: D\nGateway can handle canary deployment for testing.\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/canary-release.html","comment_id":"795294"},{"comments":[{"comment_id":"812106","poster":"rlnd2000","content":"In my opinion you are right and the solution you suggest will work but the canary option is cheaper, and much easier to implement. So in my opinion D is the correct choice not because is the only right but because is the best.","timestamp":"1676650080.0","upvote_count":"1"}],"upvote_count":"2","poster":"JagpreetLM10","content":"Selected Answer: C\nC. Deploy an Application Load Balancer (ALB) in front of the REST API. Change the production API Amazon Route 53 record to point traffic to the ALB. Register the production and testing stages as targets of the ALB with weights of 80% and 20%, respectively.\n\nThis approach would route 20% of the traffic to the new production stage API, and 80% of the traffic to the existing production stage, using the weights configured on the ALB. This would allow for a gradual roll-out of the changes, and minimize the number of errors that any single customer might experience.","comment_id":"788496","timestamp":"1674719220.0"},{"poster":"JagpreetLM10","comment_id":"784961","content":"Selected Answer: D\nD . Canary","upvote_count":"1","timestamp":"1674446880.0","comments":[{"upvote_count":"1","timestamp":"1674552540.0","poster":"JagpreetLM10","content":"Moving to CCCCCC","comment_id":"786354"}]},{"comment_id":"783964","poster":"Phinx","upvote_count":"1","timestamp":"1674368100.0","content":"Selected Answer: D\nI think it's D."}],"question_images":[]}],"exam":{"name":"AWS Certified Developer Associate","lastUpdated":"11 Apr 2025","provider":"Amazon","numberOfQuestions":443,"id":25,"isImplemented":true,"isBeta":false,"isMCOnly":true},"currentPage":64},"__N_SSP":true}