{"pageProps":{"questions":[{"id":"xrtvOC9qsL9EUHP673ZP","topic":"1","answer_description":"","choices":{"B":"Increase the run time of the Lambda functions to the maximum. Create a retry mechanism in the code that stores the customer data in the database.","D":"Store the customer data in an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Create a new Lambda function that polls the queue and stores the customer data in the database.","A":"Provision an Amazon RDS proxy to sit between the Lambda functions and the database. Configure the Lambda functions to connect to the RDS proxy.","C":"Persist the customer data to Lambda local storage. Configure new Lambda functions to scan the local storage to save the customer data to the database."},"timestamp":"2022-10-12 22:44:00","question_images":[],"question_text":"A company hosts an application on AWS Lambda functions that are invoked by an Amazon API Gateway API. The Lambda functions save customer data to an Amazon Aurora MySQL database. Whenever the company upgrades the database, the Lambda functions fail to establish database connections until the upgrade is complete. The result is that customer data is not recorded for some of the event.\nA solutions architect needs to design a solution that stores customer data that is created during database upgrades.\nWhich solution will meet these requirements?","isMC":true,"answers_community":["D (62%)","A (38%)"],"question_id":876,"discussion":[{"upvote_count":"57","timestamp":"1665843360.0","comment_id":"695461","comments":[{"poster":"SaurabhTiwari1","comment_id":"1099869","timestamp":"1702917660.0","upvote_count":"44","content":"The original question was about handling a situation where the database is unavailable due to an upgrade, not a failover situation. During a database upgrade, the database instance is not available, and RDS Proxy would not be able to connect to a new database instance because there isn’t one.\n\nIn this specific scenario, using Amazon SQS as described in option D provides a buffer for the incoming data during the period when the database is unavailable. This ensures that no data is lost, and it can be written to the database once the upgrade is complete."},{"timestamp":"1716811740.0","comment_id":"1219534","poster":"lofzee","content":"so many upvotes for an incorrect answer.\nthe question doesnt mention having more than one DB so how does RDS proxy help here?","upvote_count":"10"},{"poster":"PassNow1234","timestamp":"1672097580.0","comment_id":"757932","upvote_count":"5","comments":[{"comments":[{"comment_id":"1105262","timestamp":"1703506980.0","poster":"pentium75","upvote_count":"4","content":"But still RDS proxy won't help because during upgrades there is no database that it could proxy to."}],"timestamp":"1681588560.0","comment_id":"871254","upvote_count":"6","poster":"Robrobtutu","content":"It literally says RDS Proxy is available for Aurora MySQL on the link in the comment you're replying to."}],"content":"This is MySQL Database. RDS proxy = no no"},{"timestamp":"1669203780.0","upvote_count":"6","poster":"attila9778","content":"Aurora supports RDS proxy!\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-proxy.html","comment_id":"725089"}],"poster":"brushek","content":"Selected Answer: A\nhttps://aws.amazon.com/rds/proxy/\n\nRDS Proxy minimizes application disruption from outages affecting the availability of your database by automatically connecting to a new database instance while preserving application connections. When failovers occur, RDS Proxy routes requests directly to the new database instance. This reduces failover times for Aurora and RDS databases by up to 66%."},{"upvote_count":"34","comments":[{"poster":"gcmrjbr","timestamp":"1669283640.0","comment_id":"725714","upvote_count":"8","content":"You can use RDS Proxy with Aurora Serverless v2 clusters but not with Aurora Serverless v1 clusters. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-proxy.html"},{"upvote_count":"1","content":"It does, according to that link","timestamp":"1671438180.0","comment_id":"749620","poster":"JayBee65"},{"upvote_count":"2","poster":"adeyinkaamole","content":"This not RDS supports Aurora mysl database. All the limitations listed in the link you posted above are not related to the question, hence the answer is B","timestamp":"1692953940.0","comments":[{"poster":"adeyinkaamole","content":"I meant the answer answer is A","upvote_count":"1","timestamp":"1692954000.0","comment_id":"989870"}],"comment_id":"989869"},{"comment_id":"722689","comments":[{"comment_id":"859369","upvote_count":"6","content":"The question doesn't say the RDS is deployed in a Mutli-AZ mode. which means RDS is not accessible during upgrade anyway. RDS proxy couldn't resolve the DB HA issue. The question is looking for a solution to store the data during DB upgrade. I don't know RDS proxy very well, but the RDS proxy introduction doesn't mention it has the capability of storing data. So, answer A couldn't store the data created during the DB upgrade. \nI'm assuming this is a bad question design. The expected answer is A, but the question designer missed some important information.","poster":"Duke_YU","timestamp":"1680472680.0","comments":[{"upvote_count":"1","comment_id":"894728","content":"https://aws.amazon.com/rds/proxy/, if you go down the page, you will see that RDS is deployed in Multi-AZ (mazon RDS Proxy is highly available and deployed over multiple Availability Zones (AZs) to protect you from infrastructure failure. Each AZ runs on its own physically distinct, independent infrastructure and is engineered to be highly reliable. In the unlikely event of an infrastructure failure, the RDS Proxy endpoint remains online and consistent allowing your application to continue to run database operations.) from the link.","poster":"rismail","timestamp":"1683790440.0"}]}],"poster":"tinyfoot","timestamp":"1668954000.0","content":"Actually RDS Proxy supports Aurora DBs running on PostgreSQL and MySQL.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Concepts.Aurora_Fea_Regions_DB-eng.Feature.RDS_Proxy.html\n\nWith RDS proxy, you only expose a single endpoint for request to hit and any failure of the primary DB in a Multi-AZ configuration is will be managed automatically by RDS Proxy to point to the new primary DB. Hence RDS proxy is the most efficient way of solving the issue as additional code change is required. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-proxy.howitworks.html","upvote_count":"11"}],"poster":"123jhl0","content":"Selected Answer: D\nThe answer is D.\nRDS Proxy doesn't support Aurora DBs. See limitations at:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-proxy.html","comment_id":"698238","timestamp":"1666096620.0"},{"content":"Selected Answer: D\nAns D: This is the best solution. By using an SQS FIFO queue, you can store customer data reliably even when the database is temporarily unavailable. The Lambda function can immediately write the data to the queue when the database is not available. A second Lambda function can then poll the queue and process the customer data when the database becomes available again. This ensures that no data is lost, and processing happens in an orderly manner.","upvote_count":"1","timestamp":"1743007980.0","poster":"dattateja8","comment_id":"1410485"},{"comment_id":"1358430","upvote_count":"1","poster":"Vandaman","timestamp":"1739908800.0","content":"Selected Answer: D\nScenario describes 1 DB and when it's unavailable due to an upgrade. Best solution is to queue incoming data until DB is available."},{"poster":"Dharmarajan","content":"Selected Answer: D\nInitially I voted A. But thats wrong for one reason. RDS proxy wont help if there is no more than 1 database, but again - if there is just one database, the application is down during the downtime anyways, there is nothing that can be done.\nHowever, a SQS queue is a better option for the reason that the messages persist until marked processed. That guarantee alone is good enough to make D a better choice.\n\nBut jeez! talk about trickery!! deceptively misleading!","timestamp":"1738176600.0","upvote_count":"2","comment_id":"1348711"},{"comment_id":"1347227","timestamp":"1737952500.0","upvote_count":"1","poster":"zdi561","content":"Selected Answer: A\nD does not work. because the during db upgrade the connection is disrupted for a while during which the request in SQS will be consumed and lost"},{"poster":"zdi561","timestamp":"1737952320.0","comment_id":"1347226","content":"Selected Answer: A\nGoogle does aws aurora db proxy help db upgrade, proxy will cache transaction,","upvote_count":"1"},{"timestamp":"1736915040.0","comment_id":"1340671","content":"Selected Answer: D\ndecouple the application so that we can save the failed transactions and then pull after the upgrades complete, so D should be the correct answer (SQS Queue)","poster":"AshishDhole","upvote_count":"1"},{"comment_id":"1309918","upvote_count":"1","poster":"jayessh","timestamp":"1731316740.0","content":"Selected Answer: D\nthis is not failover situation so no need to use rds proxy. i dont remember rds proxy to hold data incase for db unavailability"},{"timestamp":"1729207440.0","upvote_count":"2","comment_id":"1299482","content":"Selected Answer: A\nA for sure","poster":"ChymKuBoy"},{"poster":"lixep","content":"Selected Answer: D\nIt's not a failover situation, it's just temporarily unavailable.","timestamp":"1727902260.0","upvote_count":"1","comment_id":"1292522"},{"content":"Selected Answer: D\nAns D - as excellently explained by SaurabhTiwari1 (9 mth ago) \"The original question was about handling a situation where the database is unavailable due to an upgrade, not a failover situation. During a database upgrade, the database instance is not available, and RDS Proxy would not be able to connect to a new database instance because there isn’t one.\"\n\nIn this specific scenario, using Amazon SQS as described in option D provides a buffer for the incoming data during the period when the database is unavailable. This ensures that no data is lost, and it can be written to the database once the upgrade is complete","upvote_count":"4","timestamp":"1726405080.0","comment_id":"1284120","poster":"PaulGa"},{"upvote_count":"1","timestamp":"1724593440.0","poster":"rpmaws","comment_id":"1272158","content":"Selected Answer: D\nA is incorrect"},{"poster":"d7d08dc","upvote_count":"2","comment_id":"1269615","timestamp":"1724173920.0","content":"the answer is D:\nThis solution ensures that customer data is not lost during database upgrades. The data is stored in the FIFO queue until the database is available again. The new Lambda function can then process the data from the queue and store it in the database. This design provides a buffer for the customer data and decouples the data ingestion from the data processing, increasing the resilience of the system during database upgrades."},{"comment_id":"1252678","content":"Selected Answer: D\nBy using Amazon RDS Proxy, you can allow your applications to pool and share database connections to improve their ability to scale. RDS Proxy makes applications more resilient to database failures by automatically connecting to a standby DB instance while preserving application connections. Using RDS Proxy, you can handle unpredictable surges in database traffic. Otherwise, these surges might cause issues due to oversubscribing connections or new connections being created at a fast rate.","upvote_count":"2","timestamp":"1721590320.0","poster":"ChinthaGurumurthi"},{"content":"Selected Answer: D\nD is the correct answer because it offers storage for the data while the database is updating, using SQS is better than using RDS proxy, because SQS is an independent service and it decouples the system, while RDS proxy might also face some trouble connecting to the database while it's updating.","comment_id":"1252409","timestamp":"1721562180.0","poster":"jaradat02","upvote_count":"5"},{"comment_id":"1229470","poster":"Duckydoo","timestamp":"1718222640.0","upvote_count":"6","content":"Selected Answer: D\nMy reasoning for selecting D and not A is because while RDS proxy can decouple the lambda->proxy and proxy-db connections, it cannot hold that beyond the lifetime of the lambda. If the DB upgrade lasts more than say 15 mins, the lambda will timeout and the data will be lost forever. The only way to be sure is to use an SQS queue with a retention time that is reasonably longer than the upgrade time, so if the lambda times out, the data will remain in the queue until it is successfully inserted into the DB later and then removed from the queue."}],"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/85319-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"unix_timestamp":1665607440,"answer":"D","exam_id":31},{"id":"t0dQYKxEscCD7ydWwhNj","choices":{"C":"Create an IAM role in the Production account. Define a trust policy that specifies the Development account. Allow developers to assume the role.","B":"Create an IAM role in the Development account. Grant the IAM role access to the Production account. Allow developers to assume the role.","A":"Create two policy documents by using the AWS Management Console in each account. Assign the policy to developers who need access.","D":"Create an IAM group in the Production account. Add the group as a principal in a trust policy that specifies the Production account. Add developers to the group."},"question_images":[],"answers_community":["C (71%)","D (24%)","6%"],"exam_id":31,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/137848-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"discussion":[{"poster":"FlyingHawk","timestamp":"1736581380.0","content":"Selected Answer: C\n1. Creating an IAM role in the Production account with a trust relationship to the Development account.\n\n2. Grant the sts:AssumeRole permission to the specific developers (or groups) who need access to the Production account.\n3. During the beta phase, you can easily add more developers to the IAM group or policy in the Development account that allows them to assume the role in the Production account. \n4. In the Alpha phase, grant AssumeRole Permission to the groups of Two Senior Developers only","upvote_count":"2","comment_id":"1339089"},{"upvote_count":"2","comments":[{"timestamp":"1735634640.0","poster":"LeonSauveterre","upvote_count":"1","comment_id":"1334702","content":"To \"assume\" a role in AWS means that you (a developer) temporarily take on the permissions associated with that role. This is done using the AWS Security Token Service (STS), which generates temporary credentials.\n\nBrief steps of option C:\n1. Sets up a trust policy that allows entities from the Development account to assume the role. Attaches permissions for the required resources (in this case, access to specific services).\n2. Attach an IAM policy to your user or role, allowing you to call \"sts:AssumeRole\".\n3. Assume the role by doing this:\n\naws sts assume-role \\\n --role-arn \"arn:aws:iam::PRODUCTION_ACCOUNT_ID:role/ROLE_NAME\" \\\n --role-session-name \"MySessionName\"\n\n4. Use the temporary credentials to access the resources in the Production account during the session duration."}],"poster":"LeonSauveterre","content":"Selected Answer: C\nA - We need secure cross-account access between the Development and Production accounts. Option A did nothing about that.\nB - This setup violates the AWS best practice for cross-account access, which recommends creating roles in the account being accessed (aka Production env).\nC - As more developers need access, you can grant permissions in the Development account without modifying the role in Production. Also, access is granted through temporary credentials generated when the role is assumed, reducing the risk of long-term credential exposure.\nD - Groups cannot establish trust between accounts. It didn't provide any mechanism for Development account users to access the Production account.","timestamp":"1735634400.0","comment_id":"1334700"},{"upvote_count":"2","content":"Selected Answer: C\nIt should be C, groups can't be used in trust policy.","comment_id":"1317167","poster":"AMEJack","timestamp":"1732474020.0"},{"poster":"Mayank0502","comment_id":"1243495","content":"Selected Answer: D\nanswer should be D","upvote_count":"1","timestamp":"1720291320.0"},{"upvote_count":"3","poster":"f07ed8f","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html","timestamp":"1716366420.0","comment_id":"1215566"},{"comment_id":"1214707","upvote_count":"1","content":"Selected Answer: D\nWeird question, but D is actually the only one that allow you to select which developer got access and when, so will go for D","poster":"TwinSpark","timestamp":"1716264120.0","comments":[{"content":"Agree, as C will let any developers assume the role without control","poster":"KennethNg923","upvote_count":"1","timestamp":"1718537400.0","comments":[{"comment_id":"1231337","timestamp":"1718537520.0","upvote_count":"4","poster":"KennethNg923","content":"I check here: https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html, and yes it should be use IAM role, I correct my choice to C"}],"comment_id":"1231335"}]},{"comment_id":"1202783","content":"Selected Answer: A\nyou can't assign groups as principals, b and c don't specify only the senior devs, a is the only one that works here","poster":"03beafc","upvote_count":"1","comments":[{"upvote_count":"1","content":"edit, none of these answers are right....","comment_id":"1202784","poster":"03beafc","timestamp":"1714158660.0"}],"timestamp":"1714158600.0"},{"content":"Selected Answer: D\nIf you want ALL the developers to assume the role in the production, then C using a trust policy to assume the role in production is perfect BUT \n\nYou could allow users in development account to assume the role in production, but in the end you will maintain potentially a big trust policy depending of the total number of users.\n\nHere you want only some developers to connect to the production (others will follow without knowing if they all can connect and without knowing the number) so managing a separate group will give you a little more maintenance but will allow you to have different rights between the users.\n\nI'd say D","upvote_count":"1","poster":"Mikado211","comment_id":"1198828","timestamp":"1713557700.0"},{"comment_id":"1197907","upvote_count":"3","poster":"802c4ff","timestamp":"1713439680.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html"},{"upvote_count":"1","timestamp":"1712181120.0","comment_id":"1188922","content":"Selected Answer: D\ni think D is better","poster":"xBUGx"}],"unix_timestamp":1712181120,"question_id":877,"answer_images":[],"answer_ET":"C","question_text":"A company has two AWS accounts: Production and Development. The company needs to push code changes in the Development account to the Production account. In the alpha phase, only two senior developers on the development team need access to the Production account. In the beta phase, more developers will need access to perform testing.\n\nWhich solution will meet these requirements?","answer_description":"","answer":"C","timestamp":"2024-04-03 23:52:00"},{"id":"qXMYtp5tcbl7QVcIGSv7","unix_timestamp":1712936340,"answer_description":"","answer":"A","answer_images":[],"question_text":"A company wants to restrict access to the content of its web application. The company needs to protect the content by using authorization techniques that are available on AWS. The company also wants to implement a serverless architecture for authorization and authentication that has low login latency.\n\nThe solution must integrate with the web application and serve web content globally. The application currently has a small user base, but the company expects the application's user base to increase.\n\nWhich solution will meet these requirements?","choices":{"D":"Configure AWS Directory Service for Microsoft Active Directory for authentication. Implement Lambda@Edge for authorization. Use AWS Elastic Beanstalk to serve the web application globally.","B":"Configure AWS Directory Service for Microsoft Active Directory for authentication. Implement AWS Lambda for authorization. Use an Application Load Balancer to serve the web application globally.","A":"Configure Amazon Cognito for authentication. Implement Lambda@Edge for authorization. Configure Amazon CloudFront to serve the web application globally.","C":"Configure Amazon Cognito for authentication. Implement AWS Lambda for authorization. Use Amazon S3 Transfer Acceleration to serve the web application globally."},"question_id":878,"exam_id":31,"isMC":true,"topic":"1","answers_community":["A (100%)"],"discussion":[{"timestamp":"1736103120.0","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/authorizationedge-how-to-use-lambdaedge-and-json-web-tokens-to-enhance-web-application-security/","comment_id":"1336841","upvote_count":"1","poster":"Salilgen"},{"comment_id":"1231340","poster":"KennethNg923","upvote_count":"3","timestamp":"1718537700.0","content":"Authen: Cognito\nGlobally: Lambda@Edge + cloudfront"},{"timestamp":"1713530280.0","upvote_count":"4","comment_id":"1198608","content":"Selected Answer: A\nServe content globally means the use of Cloudfront","poster":"Hkayne"},{"content":"Selected Answer: A\nImplementación a nivel global ==> AWS Cloud Front","poster":"Danges","timestamp":"1712936340.0","upvote_count":"2","comment_id":"1194406"}],"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/138553-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"timestamp":"2024-04-12 17:39:00"},{"id":"cJydCScxTEmWBdumCWwj","answer_description":"","answer_ET":"D","question_text":"A development team uses multiple AWS accounts for its development, staging, and production environments. Team members have been launching large Amazon EC2 instances that are underutilized. A solutions architect must prevent large instances from being launched in all accounts.\n\nHow can the solutions architect meet this requirement with the LEAST operational overhead?","question_id":879,"answers_community":["D (100%)"],"isMC":true,"answer_images":[],"topic":"1","timestamp":"2024-04-19 14:44:00","answer":"D","discussion":[{"upvote_count":"6","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html","poster":"Hkayne","comment_id":"1198612","timestamp":"1713530640.0"},{"content":"Selected Answer: D\nA - You would need to update and maintain separate IAM policies in each account, which is too much trouble.\nB - AWS Resource Access Manager (RAM) is primarily for resource sharing and does not directly restrict resource launches.\nC - IAM roles are better suited for granting access rather than imposing restrictions. You would also need to create and maintain these roles in every account, even more trouble than option A.\nD - SCPs are powerful here because they apply at the root account level, meaning that even if a developer has direct IAM permissions to launch large instances, the SCP will override and prevent it.\n\nAlso, there's no need to create or manage multiple IAM policies or roles across accounts. Once the SCP is defined and applied, it enforces the restriction automatically.","timestamp":"1735635240.0","upvote_count":"1","comment_id":"1334706","poster":"LeonSauveterre"},{"comments":[{"comment_id":"1326984","content":"Updating IAM policies must be done separately in each account, and policies for each user must be maintained, which will cause high operation overhead, so D.","timestamp":"1734283020.0","poster":"78b9037","upvote_count":"1"}],"comment_id":"1261033","content":"why is it not A? If the goal is only to prevent launch of EC2s","upvote_count":"2","poster":"744fdad","timestamp":"1722855000.0"},{"comment_id":"1247175","timestamp":"1720856880.0","upvote_count":"3","poster":"example_","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples.html"}],"exam_id":31,"choices":{"B":"Define a resource in AWS Resource Access Manager that prevents the launch of large EC2 instances.","C":"Create an IAM role in each account that denies the launch of large EC2 instances. Grant the developers IAM group access to the role.","D":"Create an organization in AWS Organizations in the management account with the default policy. Create a service control policy (SCP) that denies the launch of large EC2 instances, and apply it to the AWS accounts.","A":"Update the IAM policies to deny the launch of large EC2 instances. Apply the policies to all users."},"unix_timestamp":1713530640,"url":"https://www.examtopics.com/discussions/amazon/view/139180-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[]},{"id":"BL0id728KMpwAaCDFe2a","answer_images":[],"unix_timestamp":1712187060,"topic":"1","answer":"B","question_text":"A company has migrated a fleet of hundreds of on-premises virtual machines (VMs) to Amazon EC2 instances. The instances run a diverse fleet of Windows Server versions along with several Linux distributions. The company wants a solution that will automate inventory and updates of the operating systems. The company also needs a summary of common vulnerabilities of each instance for regular monthly reviews.\n\nWhat should a solutions architect recommend to meet these requirements?","exam_id":31,"discussion":[{"poster":"TwinSpark","upvote_count":"5","content":"Selected Answer: B\nAWS Security Hub performs security best practice checks, aggregates alerts, and enables automated remediation.\nAmazon Inspector scan workload for vulnerabilities\nGuardduty threat detection for malicious activity in all account\nAWS Shield DDOS \nRegarding security B and D can be right (maybe D a little too much). For patching B is the only valid option.","timestamp":"1716264720.0","comment_id":"1214709"},{"timestamp":"1729652640.0","upvote_count":"2","comment_id":"1301843","poster":"mk168898","content":"Inspector is for checking vulnerabilities, so B"},{"poster":"KennethNg923","upvote_count":"2","timestamp":"1718537820.0","comment_id":"1231341","content":"Selected Answer: B\nInspector for Common vulnerabilities so it is B"},{"upvote_count":"4","comment_id":"1204379","content":"inspector for instances and software vulnerabilities","poster":"maxhg","timestamp":"1714460340.0"},{"comment_id":"1198616","content":"Selected Answer: B\nAWS Systems Manager Patch Manager to automate the process of installing security-related updates for both the operating system and applications.\nAmazon Inspector for Automated and continual vulnerability management at scale","upvote_count":"2","timestamp":"1713531060.0","poster":"Hkayne"},{"poster":"Alagong","timestamp":"1712644260.0","upvote_count":"1","comment_id":"1192052","content":"Selected Answer: A\nCreate an Auto Scaling group and an ELB in the DR Region, configuring the DynamoDB table as a global table, and setting up DNS failover to the new ELB. This approach allows for quick failover since the infrastructure is already in place and only DNS needs to be updated to redirect traffic."},{"poster":"Tanidanindo","content":"Selected Answer: B\nInspector for vulnerability scanning","upvote_count":"3","comment_id":"1191954","timestamp":"1712637060.0"},{"content":"Selected Answer: B\nOption b","timestamp":"1712187060.0","poster":"Awsbeginner87","upvote_count":"3","comment_id":"1188971"}],"question_id":880,"answer_ET":"B","question_images":[],"choices":{"B":"Set up AWS Systems Manager Patch Manager to manage all the EC2 instances. Deploy Amazon Inspector, and configure monthly reports.","A":"Set up AWS Systems Manager Patch Manager to manage all the EC2 instances. Configure AWS Security Hub to produce monthly reports.","D":"Set up Amazon GuardDuty in the account to monitor all EC2 instances. Deploy AWS Config to automate patch installations on the EC2 instances.","C":"Set up AWS Shield Advanced, and configure monthly reports. Deploy AWS Config to automate patch installations on the EC2 instances."},"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/137853-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["B (94%)","6%"],"timestamp":"2024-04-04 01:31:00","answer_description":""}],"exam":{"numberOfQuestions":1019,"isBeta":false,"id":31,"lastUpdated":"11 Apr 2025","isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","provider":"Amazon","isImplemented":true},"currentPage":176},"__N_SSP":true}