{"pageProps":{"questions":[{"id":"AgOoX5fOGKApyTTeNUvK","exam_id":33,"timestamp":"2023-11-21 20:26:00","choices":{"C":"Create new Amazon DynamoDB tables for the application with on-demand capacity. Use an interface VPC endpoint for DynamoDB to connect to the DynamoDB tables.","B":"Create new Amazon DynamoDB tables for the application with on-demand capacity. Use a gateway VPC endpoint for DynamoDB to connect to the DynamoDB tables.","A":"Create new Amazon DocumentDB (with MongoDB compatibility) tables for the application with Provisioned IOPS volumes. Use the instance endpoint to connect to Amazon DocumentDB.","D":"Create new Amazon DocumentDB (with MongoDB compatibility) tables for the application with Provisioned IOPS volumes. Use the cluster endpoint to connect to Amazon DocumentDB."},"answer":"B","question_images":[],"answer_ET":"B","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/126754-exam-aws-certified-solutions-architect-professional-sap-c02/","unix_timestamp":1700594760,"answers_community":["B (50%)","D (38%)","12%"],"discussion":[{"content":"The database must be able to scale based on demand, so Provisioned IOPS volume is out because they will be throttled. A and D are out.\nEC2 hosted in a private subnet without an internet connection, have to use VPC Endpoint, for DynamoDB, it must be Gateway VPC endpoint.\nB is the answer.","comment_id":"1084561","timestamp":"1701362640.0","poster":"Pilot","upvote_count":"21"},{"content":"Selected Answer: D\nD is right option. Instance endpoint is for connecting specific instance (primary or replica) and not recommended.","comment_id":"1076979","timestamp":"1700633940.0","upvote_count":"6","poster":"career360guru","comments":[{"comments":[{"poster":"Josh1217","timestamp":"1719101580.0","upvote_count":"2","content":"It does not say you need automated scaling. You can manually scale DynanoDB with provisioned IOPS.","comment_id":"1235652"}],"poster":"JMAN1","timestamp":"1705219440.0","comment_id":"1122370","content":"This time you are wrong. A and D option use provisioned IOPS which is not scalable.\nBetween B and C. DynamoDB only works with gateway endpoint. Answer is B.","upvote_count":"4"}]},{"timestamp":"1739184420.0","content":"Selected Answer: D\nMongoDB (document DB) and DynamoDB (key-value) are different. The question says the app uses MongoDB *as* a key-value store, which is odd. Migrating to DynamoDB means data model changes.\n\nOptions A and D include Provisioned IOPS, which is pricey, but the question doesn't mention cost optimization. AWS says DocumentDB scales, so PIOPS likely fits the \"scale on demand\" requirement. I lean towards D.\n\nIf key-value is all that matters, you could use DynamoDB, but that means app changes. With AWS PrivateLink for DynamoDB, B and C are basically the same, making them invalid.\n\nSo, D seems best, but it's not a slam dunk.","upvote_count":"1","poster":"kyo","comment_id":"1354422"},{"upvote_count":"1","timestamp":"1735051320.0","content":"Selected Answer: D\nShould be D\nDocument DB is good for MongoDB\nManual Scale limit to 15 read replica is not the issue. DynamoDB is not good compatible with MongoDB .... So, what's next if Dynamo is not support Mongo","comment_id":"1331155","poster":"PSPaul"},{"content":"Selected Answer: C\nThere seems to be a typo in the answer. The correct answer is DocumentDB with VPC endpoint, making \"C\" the right choice.","timestamp":"1734339660.0","upvote_count":"1","comment_id":"1327241","poster":"deepakR20"},{"content":"Selected Answer: C\nShould be option C.\nWhile gateway endpoints can be secured, they still expose the database to the internet, albeit indirectly.\nDynamoDB can use Interface VPC endpoint to connect to DynamoDB Tables.","comment_id":"1320837","timestamp":"1733127600.0","poster":"TomTom","upvote_count":"1"},{"comment_id":"1313809","timestamp":"1731899940.0","upvote_count":"1","poster":"AzureDP900","content":"B is correct\nUsing a gateway VPC endpoint for DynamoDB (option B) does provide secure communication between your VPC and DynamoDB, and it meets the company's requirement for encrypted connectivity.\nIn fact, using a gateway VPC endpoint can help you achieve several benefits, including:\nSecurely communicate with DynamoDB without exposing your EC2 instances to the public internet\nEncrypt all outgoing traffic from your VPC to DynamoDB\nMeet security compliance requirements by controlling access to DynamoDB"},{"comment_id":"1305364","timestamp":"1730367780.0","content":"Selected Answer: B\nJust summarizing from comments :)\nA and D out because provisioned IOPS is not considered scalable.\nC is out because DynamoDB only works with gateway vpc endpoint.\nB works, because MongoDB only used as key value store, it make sense to replace it with DynamoDB with little impact to the requirements.","upvote_count":"4","poster":"Daniel76"},{"poster":"AloraCloud","content":"The key here is Can you use Amazon Dynamodb to replace a MongoDB used as a key-value database and the answer is YES!\n\nAmazon DynamoDB supports interface VPC endpoints (AWS PrivateLink). This allows you to securely connect to DynamoDB from your VPC without the need for an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.","timestamp":"1728595860.0","comment_id":"1295751","upvote_count":"2"},{"content":"Selected Answer: D\nD. This is the correct answer. Amazon DocumentDB (with MongoDB compatibility) meets the requirements:\n\n1. It can be hosted in a private subnet without an internet connection, as required by the technical guidelines.\n2. Connectivity between the application and the database can be encrypted, as stated in the requirements.\n3. Amazon DocumentDB can scale based on demand, which is another requirement mentioned in the question.\n4. The use of the cluster endpoint to connect to Amazon DocumentDB is the appropriate approach, as it provides a single, highly available endpoint for the database cluster.\n\nTherefore, option D is the solution that best meets the given requirements.","upvote_count":"1","comment_id":"1288803","poster":"KenieOh","timestamp":"1727217540.0","comments":[{"upvote_count":"2","content":"DocumentDB's scaling is limited to 15 read replicas and requires manual intervention.","timestamp":"1729755240.0","comment_id":"1302348","poster":"sashenka"}]},{"comment_id":"1281676","poster":"Syre","comments":[{"upvote_count":"2","content":"While the application currently uses MongoDB, DynamoDB is suitable for key-value database workloads.","poster":"sashenka","timestamp":"1729755420.0","comment_id":"1302349"}],"timestamp":"1725987060.0","upvote_count":"3","content":"Selected Answer: D\nDynamoDB isn't compatible withMongo"},{"content":"Selected Answer: B\nEC2 has no such concept called `cluster endpoint`. has to be B","poster":"kgpoj","comment_id":"1264103","timestamp":"1723377660.0","upvote_count":"2"},{"timestamp":"1717277280.0","content":"Correct ans: D","upvote_count":"1","comment_id":"1222915","poster":"9f02c8d"},{"comments":[{"poster":"mns0173","content":"You don't need MongoDB compatibility as it is used as key-value, not as a document db","upvote_count":"1","comment_id":"1249398","timestamp":"1721194800.0"}],"poster":"paderni","content":"D :Compatibility: Amazon DocumentDB, which is compatible with MongoDB, is an ideal choice. This ensures that the application can be migrated with minimal changes.\nScalability: can automatically scale the storage and supports read scaling by adding more replicas. This meets the requirement for the database to scale based on demand.\nEncryption: DocumentDB supports encryption at rest and in transit, ensuring that all data connectivity is encrypted as per the company's guidelines.\nPrivate Connectivity: Amazon DocumentDB can be accessed within a VPC using a cluster endpoint, and it does not require internet connectivity, making it suitable for private subnet deployments.\n\nOption B: DynamoDB is a managed NoSQL database service that could meet the key-value requirement and scalability. However, it is not MongoDB-compatible, which means significant changes to the application code might be required","timestamp":"1716653580.0","upvote_count":"2","comment_id":"1218438"},{"content":"D. Create new Amazon DocumentDB (with MongoDB compatibility) tables for the application with Provisioned IOPS volumes. Use the cluster endpoint to connect to Amazon DocumentDB.","comment_id":"1218435","poster":"paderni","upvote_count":"1","timestamp":"1716653460.0"},{"poster":"Keval12345","upvote_count":"2","content":"I guess the key par here is key-value . That kind of confirms that we can use DynamoDB here and hence B looks more promisin now.\n\nD seems good but Provisioned IOPS is a red flag regarding scaling","comment_id":"1191508","timestamp":"1712572080.0"},{"content":"Selected Answer: C\nDocumentDB is not DynamoDB.\nGateway Endpoint does not support DocumentDB.","comment_id":"1185606","poster":"VerRi","upvote_count":"2","timestamp":"1711734480.0","comments":[{"upvote_count":"1","timestamp":"1711983480.0","content":"My bad, B is using DynamoDB, so it is B","poster":"VerRi","comment_id":"1187502"}]},{"content":"Selected Answer: B\nB: If MongoDB is used as a key-value store, then a gateway endpoint is the way to connect to DynamoDB, which is a straight-up key-value store.","timestamp":"1710945600.0","upvote_count":"2","comment_id":"1178382","poster":"Dgix"},{"poster":"dankositzke","timestamp":"1708207920.0","upvote_count":"3","content":"Selected Answer: B\nB b/c needs to scale based on demand and Gateway VPC endpoint with DynamoDB goes together like peanut butter and jelly","comment_id":"1152870"},{"comment_id":"1139111","content":"Selected Answer: D\nD is the right option.\n- It's legacy application, so re-factoring to dynamodb hardly possible.\n- D is scalable and compatible, cluster endpoint is right choise.\n- Provisioned IOPS volumes are for he application, not for database, so database is still scalable.","upvote_count":"3","timestamp":"1706950440.0","comments":[{"timestamp":"1707031920.0","poster":"chelbsik","comment_id":"1139868","upvote_count":"1","content":"How are IOPS volumes not for the database? The sentence is: \"Create new Amazon DocumentDB (with MongoDB compatibility) tables for the application with Provisioned IOPS volumes\", which means that the DB is provisioned for the application, but it's still DB with IOPS volumes."}],"poster":"ele"},{"comment_id":"1121056","timestamp":"1705087920.0","poster":"vibzr2023","content":"Answer: D\nB and C are ruled out since they are using DynamoDB which is a NoSQL database service, and may not be a direct replacement for MongoDB if the application specifically requires MongoDB compatibility when you have Document DB.\nSo the answer should be either A or D. Why D? because Amazon DocumentDB provides a cluster endpoint that can be used for connecting to the cluster. This endpoint is accessible from within your Virtual Private Cloud (VPC) but doesn't require internet access. It aligns with the guideline of hosting instances in private subnets.","upvote_count":"5"},{"timestamp":"1704705480.0","poster":"JMAN1","comment_id":"1116504","content":"Selected Answer: B\nSorry. Answer is B. Gateway endpoint use private internet.","upvote_count":"3"},{"upvote_count":"2","timestamp":"1704421620.0","comment_id":"1114204","poster":"JMAN1","content":"Selected Answer: C\nC. Because gateway endpoint use public internet."},{"timestamp":"1703330400.0","content":"b ANShttps://repost.aws/knowledge-center/connect-s3-vpc-endpoint","poster":"duriselvan","comment_id":"1103987","upvote_count":"1"},{"content":"Selected Answer: B\nB - good spot on the Provisioned Capacity vs On Demand. I must admit that I have missed it","comment_id":"1099152","upvote_count":"3","poster":"ayadmawla","timestamp":"1702839060.0"},{"timestamp":"1701197520.0","content":"instance endpoint to connect is for public conenction","comment_id":"1082857","upvote_count":"3","poster":"abeb"},{"poster":"shaaam80","comment_id":"1082645","upvote_count":"3","timestamp":"1701181680.0","content":"Selected Answer: B\nB is the answer. DynamoDB provisioned in on-demand capacity can scale. And instances in the private subnet can access DynamoDB securely via VPC Gateway end point."},{"comments":[],"content":"Selected Answer: B\nThe correct answer is B. The question states \"The database must be able to scale based on demand\" Therefore, this solution would meet the need for scalability on demand while operating within a private subnet, ensuring encrypted connectivity between the application and the database, and utilizing DynamoDB's on-demand capacity provisioning.","poster":"BECAUSE","timestamp":"1701005880.0","comment_id":"1080668","upvote_count":"6"},{"content":"Selected Answer: D\nAnswer D","upvote_count":"5","poster":"devalenzuela86","comment_id":"1080201","timestamp":"1700933520.0"},{"content":"Correct Answer is B","comment_id":"1077764","poster":"321swa","timestamp":"1700683500.0","upvote_count":"1"},{"comment_id":"1077438","content":"Correct is D.\nCluster endpoint\nA cluster endpoint is an endpoint for an Amazon DocumentDB cluster that connects to the current primary instance for the cluster. Each Amazon DocumentDB cluster has a single cluster endpoint and one primary instance. In case of a failover, the cluster endpoint is remapped to the new primary instance.","poster":"Totoroha","timestamp":"1700662980.0","upvote_count":"4"},{"timestamp":"1700648640.0","comment_id":"1077211","content":"I choose A","poster":"lokiroo","upvote_count":"1"},{"comment_id":"1076584","content":"Correct Answer is A","timestamp":"1700594760.0","upvote_count":"1","poster":"cypkir"}],"answer_description":"","question_text":"A company is migrating a legacy application from an on-premises data center to AWS. The application uses MongoDB as a key-value database. According to the company's technical guidelines, all Amazon EC2 instances must be hosted in a private subnet without an internet connection. In addition, all connectivity between applications and databases must be encrypted. The database must be able to scale based on demand.\n\nWhich solution will meet these requirements?","isMC":true,"answer_images":[],"question_id":251},{"id":"V6G6cQo3Z78rCYCWUNlU","question_text":"A company is running an application on Amazon EC2 instances in the AWS Cloud. The application is using a MongoDB database with a replica set as its data tier. The MongoDB database is installed on systems in the company’s on-premises data center and is accessible through an AWS Direct Connect connection to the data center environment.\n\nA solutions architect must migrate the on-premises MongoDB database to Amazon DocumentDB (with MongoDB compatibility).\n\nWhich strategy should the solutions architect choose to perform this migration?","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/126816-exam-aws-certified-solutions-architect-professional-sap-c02/","isMC":true,"timestamp":"2023-11-22 07:23:00","answers_community":["B (100%)"],"answer_ET":"B","question_id":252,"topic":"1","discussion":[{"content":"B is right \nThe company is migrating from MongoDB to Amazon DocumentDB, which requires a database migration service.\nAWS Database Migration Service (AWS DMS) provides a managed service that can perform this type of migration.\nUsing AWS DMS allows the solutions architect to create a source endpoint for the on-premises MongoDB database using change data capture (CDC), which captures changes made to the original database and replicates them to the target database in real-time.\nThis approach ensures minimal downtime and minimal data loss during the migration process.","poster":"AzureDP900","upvote_count":"2","timestamp":"1731899520.0","comment_id":"1313806"},{"upvote_count":"1","content":"Selected Answer: B\nOption B","comment_id":"1117702","timestamp":"1704819900.0","poster":"career360guru"},{"upvote_count":"2","poster":"edder","comment_id":"1091011","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/documentdb/latest/developerguide/docdb-migration.html","timestamp":"1702034820.0"},{"upvote_count":"2","content":"Selected Answer: B\nB is straightforward. Use DMS to migrate to a Mongo DB Compatible Document DB instance on AWS. Correct!","poster":"shaaam80","comment_id":"1082652","timestamp":"1701181980.0"},{"content":"Selected Answer: B\nB is correct","upvote_count":"2","poster":"salazar35","timestamp":"1700909160.0","comment_id":"1079933"},{"content":"Correct is B","upvote_count":"2","comment_id":"1077439","poster":"Totoroha","timestamp":"1700663220.0"},{"content":"Selected Answer: B\nB is right option.","timestamp":"1700634180.0","upvote_count":"3","poster":"career360guru","comment_id":"1076983"}],"exam_id":33,"answer_images":[],"answer_description":"","unix_timestamp":1700634180,"answer":"B","choices":{"A":"Create a fleet of EC2 instances. Install MongoDB Community Edition on the EC2 instances, and create a database. Configure continuous synchronous replication with the database that is running in the on-premises data center.","D":"Create a source endpoint for the on-premises MongoDB database by using AWS Glue crawlers. Configure continuous asynchronous replication between the MongoDB database and the Amazon DocumentDB database.","B":"Create an AWS Database Migration Service (AWS DMS) replication instance. Create a source endpoint for the on-premises MongoDB database by using change data capture (CDC). Create a target endpoint for the Amazon DocumentDB database. Create and run a DMS migration task.","C":"Create a data migration pipeline by using AWS Data Pipeline. Define data nodes for the on-premises MongoDB database and the Amazon DocumentDB database. Create a scheduled task to run the data pipeline."}},{"id":"Tz7tQsQBTCL1wAjWjfUc","answers_community":["B (54%)","A (46%)"],"timestamp":"2023-11-22 07:27:00","answer_images":[],"question_id":253,"url":"https://www.examtopics.com/discussions/amazon/view/126818-exam-aws-certified-solutions-architect-professional-sap-c02/","question_text":"A company is rearchitecting its applications to run on AWS. The company’s infrastructure includes multiple Amazon EC2 instances. The company's development team needs different levels of access. The company wants to implement a policy that requires all Windows EC2 instances to be joined to an Active Directory domain on AWS. The company also wants to implement enhanced security processes such as multi-factor authentication (MFA). The company wants to use managed AWS services wherever possible.\n\nWhich solution will meet these requirements?","question_images":[],"exam_id":33,"topic":"1","discussion":[{"poster":"HappyPrince","timestamp":"1703036100.0","content":"Selected Answer: B\nI support B as well per this link where EC2 is recommended:\nhttps://docs.aws.amazon.com/workspaces/latest/adminguide/directory_administration.html","upvote_count":"12","comment_id":"1101116"},{"comment_id":"1087671","timestamp":"1701697320.0","poster":"nublit","upvote_count":"10","content":"Selected Answer: B\nB is correct. The question mention \"Windows EC2\", no \"Windows user desktops\". Maybe the Windows EC2 can be Windows Servers."},{"poster":"kyo","content":"Selected Answer: A\nThe question does mention EC2 specifically, which makes the WorkSpaces solution a little less direct. However, the requirement to use managed AWS services \"wherever possible\" strongly suggests WorkSpaces for MFA. It's the most managed way to get that done.\n\nSo, while EC2 is mentioned, the emphasis on managed services and the need for MFA makes WorkSpaces the most likely answer. It's a trade-off, but the question is probably prioritizing managed services over strict adherence to only using EC2 for everything.","upvote_count":"1","comment_id":"1354429","timestamp":"1739185260.0"},{"content":"Selected Answer: A\nuse AWS managed services wherever possible.\nWhile both A and B are feasible, A matches the question at most.","timestamp":"1738135080.0","poster":"GabrielShiao","upvote_count":"1","comment_id":"1348407"},{"poster":"FZA24","timestamp":"1737103440.0","content":"Selected Answer: A\nThe company wants to use managed AWS services wherever possible.\nhttps://docs.aws.amazon.com/workspaces/latest/adminguide/directory_administration.html\n\nYou'll perform most administrative tasks for your WorkSpaces directory using directory management tools, such as the Active Directory Administration Tools. However, you'll use the WorkSpaces console to perform some directory-related tasks.","upvote_count":"1","comment_id":"1342057"},{"content":"B is right\nThe company wants to join all Windows EC2 instances to an Active Directory domain on AWS, which requires a full-featured Active Directory service.\nUsing AWS Directory Service for Microsoft Active Directory (Enterprise edition) meets this requirement by providing a managed directory service that can be used to manage and secure EC2 instances.\nLaunching an EC2 instance allows the development team to configure and test domain security configurations in a controlled environment, which is essential for ensuring the correct configuration of the Active Directory","timestamp":"1731899280.0","poster":"AzureDP900","comment_id":"1313805","upvote_count":"1"},{"timestamp":"1731362520.0","comment_id":"1310343","content":"Selected Answer: A\nOption A meets the requirements by using AWS Directory Service for Microsoft Active Directory, a managed service for hosting a full Active Directory domain. It also leverages Amazon WorkSpaces, a managed desktop service supporting MFA, for secure administrative access to configure the Active Directory domain, aligning with the company's preference for managed AWS services.\n\nOption B: While creating an AWS Directory Service for Microsoft Active Directory implementation is correct, launching an EC2 instance for domain security configuration tasks is not the most suitable approach. EC2 instances require additional management overhead, and the company wants to use managed services wherever possible.","poster":"0b43291","upvote_count":"1"},{"content":"Selected Answer: B\nAdd a vote to B as it is dangerously swaying to A.\n\nThe EC2 instances referred to should be the managed domain controller to manage EC2 instances that join the domain, to push down GPO policies etc. You can launch more than one for HA.\n\nhttps://aws.amazon.com/blogs/security/how-to-increase-the-redundancy-and-performance-of-your-aws-directory-service-for-microsoft-ad-directory-by-adding-domain-controllers/","upvote_count":"1","comment_id":"1306035","poster":"Daniel76","timestamp":"1730510040.0"},{"content":"Selected Answer: A\nAnswer is A: \nAmazon WorkSpaces is a managed desktop-as-a-service solution that aligns with the requirement to use managed services:\n- Provides a managed alternative to running EC2 instances\n- Integrates seamlessly with AWS Managed Microsoft AD. \n- Reduces administrative overhead compared to managing EC2 instances","timestamp":"1729756200.0","poster":"sashenka","upvote_count":"1","comment_id":"1302353"},{"timestamp":"1722042420.0","poster":"ctrue","upvote_count":"1","content":"B is correct, it is application infrastructure, not for desktop.","comment_id":"1255936"},{"upvote_count":"1","content":"I will go for A based on this \"RADIUS MFA is applicable only to authenticate access to the AWS Management Console, or to Amazon Enterprise applications and services such as WorkSpaces, Amazon QuickSight, or Amazon Chime. It does not provide MFA to Windows workloads running on EC2 instances, or for signing into an EC2 instance\" https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ad_connector_mfa.html","timestamp":"1720966320.0","poster":"junehc","comment_id":"1247800"},{"timestamp":"1718206680.0","poster":"Win007","comment_id":"1229274","upvote_count":"1","content":"A is correct"},{"comment_id":"1228755","upvote_count":"3","timestamp":"1718153880.0","poster":"trungtd","content":"Selected Answer: A\nTechnically, you can use AWS Workspace for domain security configuration tasks. So A is correct"},{"poster":"9f02c8d","timestamp":"1717277640.0","comment_id":"1222920","content":"A is right answer","upvote_count":"1"},{"upvote_count":"1","timestamp":"1716660000.0","comment_id":"1218479","content":"A is right answer as the Amazon WorkSpaces provides a managed desktop-as-a-service solution that allows you to access a Windows desktop environment in the AWS Cloud","poster":"9f02c8d"},{"poster":"paderni","comment_id":"1218440","upvote_count":"1","content":"A. Amazon WorkSpaces is more secure and managed,","timestamp":"1716653880.0"},{"upvote_count":"1","content":"You can managed AD Admin tasks from Workspace. The requirement is to use AWS Managed Services where possible. So answer is A - nothing you can manage AD wise on EC2 that you can't do on the Windows Workspace","poster":"markovr6","comment_id":"1206695","timestamp":"1714862340.0"},{"comment_id":"1195861","poster":"titi_r","upvote_count":"1","content":"Selected Answer: A\nA - correct.","timestamp":"1713165060.0"},{"content":"Selected Answer: A\nOption A - Three requirements, 1. join AD domain, 2. enable MFA, 3. Use AWS managed service. Nothing about cost or any additional requirements. Option A checks all the boxes from the article information - https://aws.amazon.com/blogs/security/how-to-enable-multi-factor-authentication-for-amazon-workspaces-and-amazon-quicksight-by-using-microsoft-ad-and-on-premises-credentials/","timestamp":"1711113960.0","poster":"TonytheTiger","upvote_count":"5","comment_id":"1180070"},{"upvote_count":"1","timestamp":"1710003720.0","content":"Selected Answer: A\nBecause managed services.","comment_id":"1169669","poster":"Dgix"},{"poster":"dankositzke","upvote_count":"3","content":"Selected Answer: A\nI would choose A over B because of the last requirement: “The company wants to use managed AWS services wherever possible.”","comment_id":"1152880","timestamp":"1708208280.0"},{"timestamp":"1707518340.0","upvote_count":"3","poster":"07c2d2a","comment_id":"1145836","content":"\"The company wants to implement a policy that requires all Windows EC2 instances to be joined to an Active Directory domain on AWS\". Workspaces are automatically domain joined. EC2 aren't going to be automatically domain joined without some extra steps. I feel like that's what they're getting at here..."},{"comments":[{"timestamp":"1707033060.0","content":"Additionally, you can apply Group Policies to Windows Workspaces, which is a domain security task, though there are some limitations https://docs.aws.amazon.com/workspaces/latest/adminguide/group_policy.html","upvote_count":"2","comment_id":"1139881","poster":"chelbsik"}],"comment_id":"1139874","poster":"chelbsik","upvote_count":"3","content":"Selected Answer: A\nA seems better, as it uses managed Workspaces, which we can apply different security controls to despite what some people here say https://docs.aws.amazon.com/whitepapers/latest/best-practices-deploying-amazon-workspaces/security.html","timestamp":"1707032520.0"},{"timestamp":"1704820860.0","comment_id":"1117710","upvote_count":"1","content":"Selected Answer: B\nOption B. Workspace Windows servers can not be used for Domain Security tasks.","poster":"career360guru"},{"content":"It can't be an EC2. It says to use AWS services. I'm even torn on wether or not we should use simple AD","comment_id":"1107765","comments":[{"content":"Indeed, EC2 is an AWS service - I guess you meant it isn't aws managed.","comment_id":"1143741","poster":"rodygogan","upvote_count":"1","timestamp":"1707334800.0"}],"poster":"Jay_2pt0_1","upvote_count":"1","timestamp":"1703767440.0"},{"content":"What in the vague is this? I'm not sure.","comment_id":"1085150","timestamp":"1701427620.0","poster":"Jay_2pt0_1","upvote_count":"3"},{"poster":"knark446","comment_id":"1084049","upvote_count":"5","content":"Selected Answer: B\nI would vote B, it doesn't say anywhere that the windows ec2 instances are \"user desktops\", if that was the case A for sure.","timestamp":"1701328140.0"},{"comment_id":"1082655","timestamp":"1701182400.0","poster":"shaaam80","comments":[{"timestamp":"1701892020.0","content":"I did the same thing and asked to GPT why B is wrong, this is the answer. . .\n\nI apologize for any confusion. Upon closer examination, I realize that I made an error in my response. I appreciate your patience. Let's reevaluate the options:\n\nOption A is incorrect because Amazon Workspaces is a managed, secure cloud desktop service, but it is not the appropriate service for domain security configuration tasks. Workspaces is more suited for providing a cloud-based desktop experience to end-users.\n\nThe correct option for the given requirements is:\n\nB. Create an AWS Directory Service for Microsoft Active Directory implementation. Launch an EC2 instance. Connect to and use the EC2 instance for domain security configuration tasks.","poster":"tiagobs","upvote_count":"4","comments":[{"comment_id":"1139879","upvote_count":"2","timestamp":"1707032880.0","content":"This just means you shouldn't blindly trust ChatGPT, it likes to change shoes while walking all the time","poster":"chelbsik"}],"comment_id":"1089718"}],"upvote_count":"2","content":"Selected Answer: A\nGPT - Launch an Amazon Workspace, which is a fully managed, secure desktop-as-a-service (DaaS) solution. Use the Workspace for domain security configuration tasks. Answer A"},{"content":"A, becoz of the managed service wording","comment_id":"1081171","upvote_count":"1","poster":"[Removed]","timestamp":"1701055440.0"},{"content":"Selected Answer: B\nB is correct","upvote_count":"2","comment_id":"1080190","poster":"devalenzuela86","timestamp":"1700932620.0"},{"content":"B is correct","comment_id":"1079124","upvote_count":"3","poster":"tiagobs","timestamp":"1700813580.0"},{"content":"Selected Answer: A\nOption A","timestamp":"1700634420.0","comment_id":"1076990","upvote_count":"3","poster":"career360guru"}],"choices":{"B":"Create an AWS Directory Service for Microsoft Active Directory implementation. Launch an EC2 instance. Connect to and use the EC2 instance for domain security configuration tasks.","D":"Create an AWS Directory Service Simple AD implementation. Launch an Amazon Workspace. Connect to and use the Workspace for domain security configuration tasks.","C":"Create an AWS Directory Service Simple AD implementation. Launch an EC2 instance. Connect to and use the EC2 instance for domain security configuration tasks.","A":"Create an AWS Directory Service for Microsoft Active Directory implementation. Launch an Amazon Workspace. Connect to and use the Workspace for domain security configuration tasks."},"unix_timestamp":1700634420,"answer_ET":"B","answer_description":"","answer":"B","isMC":true},{"id":"gZVGKfxWk0br2XUqC9wH","choices":{"C":"Create two Amazon DynamoDB global tables. Use one global table to host the product data. Use the other global table to host the user session data. Use DynamoDB Accelerator (DAX) for caching.","A":"Create an Amazon RDS DB instance with separate schemas to host the product data and the user session data. Configure a read replica for the DB instance in another Region.","B":"Create an Amazon RDS DB instance to host the product data. Configure a read replica for the DB instance in another Region. Create a global datastore in Amazon ElastiCache for Memcached to host the user session data.","D":"Create an Amazon RDS DB instance to host the product data. Configure a read replica for the DB instance in another Region. Create an Amazon DynamoDB global table to host the user session data."},"exam_id":33,"timestamp":"2023-11-21 20:28:00","answer":"D","answer_ET":"D","question_images":[],"topic":"1","unix_timestamp":1700594880,"answers_community":["D (50%)","C (37%)","13%"],"url":"https://www.examtopics.com/discussions/amazon/view/126755-exam-aws-certified-solutions-architect-professional-sap-c02/","discussion":[{"comments":[{"poster":"titi_r","timestamp":"1716583680.0","content":"\"C\" should be wrong. \"B\" should be correct.\n\n\"A traditional relational database management system (RDBMS) stores data in a normalized relational structure.\n[...]\nAs a NON-relational database service, DynamoDB offers many advantages over traditional relational database management systems.\"\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-relational-modeling.html","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"1267392","timestamp":"1723855980.0","poster":"helloworldabc","content":"just D"}],"comment_id":"1217813"}],"comment_id":"1109843","poster":"kadavahuhu","timestamp":"1703955120.0","upvote_count":"16","content":"Selected Answer: C\nC - DynamoDB is for structured, semi-structured and unstructured data. So it can also hold the product data. Indeed many e-commerce shops use DynamoDB to save the product catalogue. There is nothing in the questin that would exclude DynamoDB for the product data. C has caching with DAX so it definitely has a higher performance than D which does not have caching and even no read replica in the same region."},{"content":"Selected Answer: D\nStructured Data = RDS","comment_id":"1148573","timestamp":"1707767640.0","poster":"Wardove","upvote_count":"8"},{"upvote_count":"2","poster":"saptati","timestamp":"1735387320.0","content":"Selected Answer: D\nOption C is suboptimal because using DynamoDB for structured product data may be less efficient and more costly than RDS, especially for complex relationships and large datasets. It also adds unnecessary complexity and reduces query flexibility compared to relational databases. In contrast, option D offers a better solution by using RDS for structured product data and DynamoDB for session data, providing an optimal balance of performance, cost-effectiveness, and appropriate technology choices for different data types, while meeting the requirements for decoupling and cross-region replication. Thus, the correct answer is D.","comment_id":"1332935"},{"content":"Selected Answer: C\nDynamoDB provide microseconds to single digit latency read/write also DynamoDB support structured data just fine","timestamp":"1735198140.0","comment_id":"1331825","poster":"Miquella_The_Rizzler","upvote_count":"1"},{"comment_id":"1320856","content":"Selected Answer: C\nOption C, provide highest performance.\nCreating two Amazon DynamoDB global tables—one for product data and another for user session data—while utilizing DynamoDB Accelerator (DAX) for caching. This setup allows for low-latency access and high throughput, making it ideal for applications with demanding performance requirements. Additionally, DynamoDB's global tables offer built-in replication across regions, ensuring disaster recovery capabilities without compromising performance.","poster":"TomTom","timestamp":"1733130840.0","upvote_count":"2"},{"poster":"alexbraila","comment_id":"1320685","content":"Selected Answer: C\nThis\n\nhttps://docs.aws.amazon.com/whitepapers/latest/big-data-analytics-options/amazon-dynamodb.html\n\nmentions indeed \"DynamoDB stores structured data in tables\". Based on the question, I would go with C","upvote_count":"1","timestamp":"1733083860.0"},{"upvote_count":"1","timestamp":"1732214640.0","comment_id":"1315961","poster":"0b43291","content":"Selected Answer: C\nOption C (using two DynamoDB global tables with DAX caching) provides the highest performance by leveraging the scalability, low latency, and caching capabilities of DynamoDB, while also meeting the requirements of data separation and replication for disaster recovery.\n\nThe other options have limitations or drawbacks:\n\nOption A: While separate schemas in an Amazon RDS DB instance can separate the data, it lacks the performance and scalability of DynamoDB. Setting up replication across Regions for RDS is also more complex than using DynamoDB global tables.\n\nOption B: This option separates the data and provides replication, but using Amazon ElastiCache for Memcached for user session data may not match DynamoDB's performance for structured data. Managing two different data stores (RDS and ElastiCache) can also add complexity.\n\nOption D: While separating the data and providing replication, using RDS for the product data may not be as performant as DynamoDB for structured data, especially with high-traffic workloads."},{"comment_id":"1313804","content":"D is correct\nDecouples the product data from the user session data by using separate storage mechanisms (RDS and DynamoDB).\nProvides replication in another AWS Region for disaster recovery, which is necessary.\nDynamodb provides low latency reads and writes making it suitable for this application and high traffic application\nAnd DynamoDB has built-in features to automatically handle the replication of the user session data across regions.","poster":"AzureDP900","timestamp":"1731898920.0","upvote_count":"1"},{"timestamp":"1722437100.0","upvote_count":"3","comment_id":"1258938","content":"Selected Answer: D\nAnswer is D, Elasticache Global data Store only supports Redis","poster":"zolthar_z"},{"content":"I think D. ElastiCache for Memcached and DAX are good for read-heavy so they can improve performance, but not a good choice for read and write, and also Memcached – no replication","comment_id":"1247898","timestamp":"1720979820.0","upvote_count":"2","poster":"junehc"},{"content":"Selected Answer: D\nQuerying structured data on DynamoDB does not provide as good performance as RDS","poster":"trungtd","comment_id":"1228759","timestamp":"1718154480.0","upvote_count":"1"},{"timestamp":"1716660600.0","content":"C - To meet Disaster Recovery requirements & get high performance with DAX","poster":"9f02c8d","upvote_count":"1","comment_id":"1218483"},{"poster":"paderni","comment_id":"1218443","upvote_count":"1","timestamp":"1716654060.0","content":"D. Structure Data so Amazon RDS and Amazon DynamoDB is well-suited for handling session data and can provide low-latency access.\nNot C because Dynamo is not for structured data"},{"content":"Selected Answer: B\nI did not like \"Create 2 DynamoDB global tables\", but as soon as the question is asking for the HIGHEST performance it's poining to DAX. C is the correct answer.","comment_id":"1205932","poster":"mifune","timestamp":"1714713000.0","upvote_count":"1"},{"content":"Selected Answer: B\nAns B.\n\"ElastiCache and RDS provide applications a combination of the top-tier speed of an in-memory cache with the reliability of a relational database. When provisioning an Aurora or RDS database using the RDS console, you now have the option to create and attach an associated ElastiCache cluster at the same time.\"\n\nhttps://aws.amazon.com/about-aws/whats-new/2023/04/amazon-elasticache-cache-rds-databases-console/","comment_id":"1195872","timestamp":"1713166140.0","upvote_count":"1","poster":"titi_r"},{"comments":[{"poster":"Zas1","timestamp":"1713891600.0","content":"D is correct","comment_id":"1200836","upvote_count":"1"}],"poster":"Zas1","content":"B - In general, SQL databases are better suited for traditional, structured data, while NoSQL databases are better suited for handling large volumes of unstructured or semi-structured data.","comment_id":"1190967","upvote_count":"1","timestamp":"1712496300.0"},{"upvote_count":"2","timestamp":"1710567120.0","content":"Selected Answer: D\nD is correct","poster":"yog927","comment_id":"1174747"},{"content":"Selected Answer: D\nThe database for the application stores structured product data and temporary user session data, therefore. option D","timestamp":"1708709160.0","comment_id":"1157333","upvote_count":"4","poster":"Russs99"},{"upvote_count":"3","content":"Selected Answer: C\nThe HIGHEST performance is C. Structured data does not means \"SQL\". Dynamodb can handle structured data with no issues.","comment_id":"1139127","poster":"ele","timestamp":"1706952300.0"},{"content":"Selected Answer: D\nB talks about Global Datastore for memcached while memcached doesnt support global datastore, hence B is ruled out and D is the answer.","timestamp":"1705711380.0","upvote_count":"3","comment_id":"1127019","poster":"SeemaDataReader"},{"upvote_count":"1","content":"Selected Answer: C\nC - DynamoDB with DAX is for structured data and the highest performance.","timestamp":"1705303080.0","poster":"tmlong18","comment_id":"1123134"},{"upvote_count":"2","content":"Answer: D\nB also works but you will endup doing lot of custom stuff to deploy multiple ElastiCache for Memcached clusters in different Availability Zones. Pay attention to the question which says \"The company also needs to implement replication in another AWS Region for disaster recovery\"","timestamp":"1705086540.0","comment_id":"1121040","poster":"vibzr2023"},{"comment_id":"1117719","content":"Choice is between B and D. Application information about how it is deployed in second region is missing for this question. B does not address cross region replication requirement for user sessions and assuming that is needed, option D is the right answer.","poster":"career360guru","upvote_count":"3","timestamp":"1704821580.0"},{"timestamp":"1704520020.0","content":"B ans \nhttps://aws.amazon.com/about-aws/whats-new/2023/04/amazon-elasticache-cache-rds-databases-console/","poster":"duriselvan","upvote_count":"3","comment_id":"1114989"},{"content":"Selected Answer: B\nFor those who voted D as the answer, your argument is that ElastiCache doesn’t support Multi-AZ and cross region deployment. But the question doesn’t ask for Multi-AZ and cross region session data replication. In a typical design, temporary data can be abandoned, which means when DR happens, you can create a new ElastiCache for Memcache in the DR region. If you argue that the question implies a DR setup, then none of the answers addresses the deployment of application instances. In the end, considering cross region deployment for the temporary data replication is not relevant to the question.","poster":"bjexamprep","upvote_count":"3","comment_id":"1113313","timestamp":"1704337320.0"},{"poster":"nublit","timestamp":"1701697740.0","content":"Selected Answer: D\nD is the best answer. RDS with read replica (cross-region) for product data + Global DynamoDB for sessions data.","comment_id":"1087677","upvote_count":"3"},{"timestamp":"1701182820.0","upvote_count":"4","poster":"shaaam80","content":"Selected Answer: D\nB is wrong, Elasticache with Memached does not support Multi-AZ or global datastores. Redis will be needed. Answer is D to use DynamoDB for session data.","comment_id":"1082659"},{"timestamp":"1701017580.0","content":"Selected Answer: B\nB seems to have better performance than D","comment_id":"1080843","poster":"jpes","upvote_count":"2"},{"upvote_count":"2","comment_id":"1080228","content":"Selected Answer: B\nThe combination of RDS and ElastiCache also allows the company to decouple the product data from the user session data, another one of the company’s requirements","timestamp":"1700935440.0","poster":"Russs99"},{"upvote_count":"4","timestamp":"1700909580.0","poster":"salazar35","content":"Selected Answer: D\nGlobal datastore supports for Redis only, not Memcached","comment_id":"1079940"},{"upvote_count":"2","content":"Is it really B? Because ElastiCache global database avaliable only for Redis and not for Memcached","timestamp":"1700718780.0","comment_id":"1078102","poster":"HunkyBunky"},{"poster":"Totoroha","comments":[{"poster":"Totoroha","comments":[{"content":"Thanks for your answer! I was convinced of B being right before this","timestamp":"1710325620.0","poster":"federikinho","upvote_count":"1","comment_id":"1172432"}],"timestamp":"1701219240.0","upvote_count":"2","comment_id":"1083036","content":"Amazon ElastiCache for Memcached does not support Multi-AZ (Availability Zone) deployments or global datastores in the same way as Amazon ElastiCache for Redis."}],"comment_id":"1077446","content":"Answer is B. ( or D). Option D suggests using RDS for product data and DynamoDB for user session data. This could work, but it may not provide the same level of performance and decoupling as Option B.","timestamp":"1700663760.0","upvote_count":"2"},{"upvote_count":"1","poster":"cypkir","comment_id":"1076587","timestamp":"1700594880.0","content":"Correct Answer B"}],"answer_description":"","question_text":"A company wants to migrate its on-premises application to AWS. The database for the application stores structured product data and temporary user session data. The company needs to decouple the product data from the user session data. The company also needs to implement replication in another AWS Region for disaster recovery.\n\nWhich solution will meet these requirements with the HIGHEST performance?","isMC":true,"answer_images":[],"question_id":254},{"id":"rnWjxJy5Yi3bEJ2PF0Th","timestamp":"2023-11-22 15:44:00","exam_id":33,"choices":{"B":"Create a custom detective control (guardrail) in AWS Control Tower. Configure the control (guardrail) to allow the deployment of only burstable instances and to disallow services that are not relevant. Apply the control (guardrail) to the development OU.","A":"Create a custom SCP in AWS Organizations to allow the deployment of only burstable instances and to disallow services that are not relevant. Apply the SCP to the development OU.","D":"Create an AWS Config rule in the AWS Control Tower account. Configure the AWS Config rule to allow the deployment of only burstable instances and to disallow services that are not relevant. Deploy the AWS Config rule to the development OU by using AWS CloudFormation StackSets.","C":"Create a custom preventive control (guardrail) in AWS Control Tower. Configure the control (guardrail) to allow the deployment of only burstable instances and to disallow services that are not relevant. Apply the control (guardrail) to the development OU."},"answer":"C","question_images":[],"answer_ET":"C","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/126923-exam-aws-certified-solutions-architect-professional-sap-c02/","answers_community":["C (60%)","A (40%)"],"unix_timestamp":1700664240,"discussion":[{"comment_id":"1091127","poster":"edder","upvote_count":"10","content":"Selected Answer: C\nI don't think it's appropriate to make SCP changes from Organization to an OU managed by Control Tower, as it will cause drift.\nThe recommended method is to set it as Preventive.\n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/controls.html\nhttps://docs.aws.amazon.com/controltower/latest/userguide/governance-drift.html","timestamp":"1702044180.0"},{"timestamp":"1719100200.0","content":"Selected Answer: C\nCannot be A. SCP will create drift and SCPs are used for denying any specific action, not allow as stated in option A.","upvote_count":"7","comment_id":"1235650","poster":"Josh1217"},{"comment_id":"1559658","upvote_count":"1","content":"Selected Answer: A\nAll the people that have selected C have never used guardrails in control tower.\n\nThere is no such guardrail to do this, plus you do not have the option to create custom guardrails.","poster":"BelloMio","timestamp":"1744305480.0"},{"timestamp":"1732215000.0","comment_id":"1315965","poster":"0b43291","content":"Selected Answer: C\nBy using a custom preventive control (guardrail) in AWS Control Tower, the company can effectively enforce the deployment of only burstable instances and disallow the use of irrelevant services in the development OU, optimizing costs and ensuring compliance.\n\nThe other options are less effective or inappropriate:\n\nOption A: SCPs in AWS Organizations lack the granularity of AWS Control Tower guardrails for this specific use case.\n\nOption B: A detective control would detect non-compliant resources after deployment, not prevent it as required.\n\nOption D: Creating an AWS Config rule and deploying via CloudFormation StackSets is more complex than using purpose-built AWS Control Tower guardrails.","upvote_count":"1"},{"comment_id":"1313803","upvote_count":"1","content":"C is right.\nA preventive control (guardrail) is designed to prevent users from taking specific actions if they don't meet the defined criteria. In this case, creating a custom preventive control would allow you to:\nDefine rules for what types of EC2 instances and RDS instances can be deployed in the development OU.\nSpecify which services are allowed or disallowed.\nThis approach provides real-time enforcement of desired resource usage patterns, helping the company prevent non-compliant resources from being created in the first place","poster":"AzureDP900","timestamp":"1731898680.0"},{"comment_id":"1309157","content":"Selected Answer: C\nC.\n\nCannot be A as SCPs are for deny policies only but the answer specifies creating an SCP to allow and deny.","poster":"Halliphax","timestamp":"1731174420.0","upvote_count":"2"},{"comment_id":"1300529","content":"Selected Answer: A\nAs long as you do not update the policies that Control Tower manages, this is fine: \n\n> Don't use AWS Organizations to update service control policies (SCPs) attached to an OU that is registered with AWS Control Tower. Doing so could result in the controls entering an unknown state, which will require you to reset your landing zone or re-register your OU in AWS Control Tower. Instead, you can create new SCPs and attach those to the OUs rather than editing the SCPs that AWS Control Tower has created.","timestamp":"1729436160.0","upvote_count":"1","poster":"that1guy"},{"upvote_count":"2","content":"Selected Answer: C\nPreventive guardrails deployed by AWS Control Tower are implemented via service control policies (SCPs). \nhttps://docs.aws.amazon.com/wellarchitected/latest/management-and-governance-guide/controls.html","timestamp":"1728511380.0","poster":"fabriciollf","comment_id":"1295299"},{"poster":"ahrentom","timestamp":"1727766240.0","upvote_count":"2","content":"Selected Answer: C\nI go with C, because of https://docs.aws.amazon.com/controltower/latest/userguide/governance-drift.html#drift-scp-attached-ou","comment_id":"1291837"},{"timestamp":"1721196300.0","comment_id":"1249415","upvote_count":"1","content":"SCP and \"allow\" are always incompatible","poster":"mns0173"},{"timestamp":"1716654360.0","content":"A -because SCPs are a more straightforward and integrated solution within AWS Organizations for this purpose than preventive controls in Control Tower","poster":"paderni","comment_id":"1218447","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"1267393","content":"just c","timestamp":"1723856160.0","poster":"helloworldabc"}]},{"upvote_count":"4","poster":"BrijMohan08","timestamp":"1714265940.0","comment_id":"1203335","content":"Selected Answer: A\nApplying the custom SCP to the development OU will enforce the restrictions on all the accounts within that OU, effectively limiting the developers to using only the allowed resources and services.\n\nAWS Control Tower guardrails (options B and C) are not the ideal solution in this case because they are primarily used for governance and compliance purposes, rather than granular service-level restrictions."},{"upvote_count":"1","comment_id":"1195903","content":"Selected Answer: C\nC - correct.","poster":"titi_r","timestamp":"1713169320.0"},{"comment_id":"1180111","upvote_count":"2","timestamp":"1711117980.0","content":"Selected Answer: A\nOption A - The preventive controls are implemented using Service Control Policies (SCPs), which are part of AWS Organizations\n\nRead \" Implementation of control behavior\" section \nhttps://docs.aws.amazon.com/controltower/latest/userguide/controls.html","poster":"TonytheTiger"},{"poster":"yog927","timestamp":"1710566280.0","upvote_count":"2","comment_id":"1174742","content":"Selected Answer: A\nAnwer is A. \"Custom SCP\"\nDrift is caused if you edit the existing SCP. \n\nDon't use AWS Organizations to update service control policies (SCPs) attached to an OU that is registered with AWS Control Tower. Doing so could result in the controls entering an unknown state, which will require you to repair your landing zone or re-register your OU in AWS Control Tower. Instead, you can create new SCPs and attach those to the OUs rather than editing the SCPs that AWS Control Tower has created.\nhttps://docs.aws.amazon.com/controltower/latest/userguide/orgs-guidance.html"},{"comment_id":"1169670","content":"Selected Answer: A\nCustom preventive guardrails in CT can't do this. The correct answer is A.","poster":"Dgix","upvote_count":"2","timestamp":"1710004260.0"},{"content":"Answer : C\nbecause A said the SCP will apply to \" AWS Organizations\" not the OU.","upvote_count":"3","poster":"adelynllllllllll","timestamp":"1708112880.0","comment_id":"1152206"},{"comment_id":"1139135","poster":"ele","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"1152616","timestamp":"1708181700.0","poster":"ele","content":"A is right: https://docs.aws.amazon.com/controltower/latest/userguide/orgs-guidance.html\nDon't use AWS Organizations to update service control policies (SCPs) attached to an OU that is registered with AWS Control Tower. Doing so could result in the controls entering an unknown state, which will require you to repair your landing zone or re-register your OU in AWS Control Tower. Instead, you can create new SCPs and attach those to the OUs rather than editing the SCPs that AWS Control Tower has created."}],"content":"Selected Answer: A\nAWS Control Tower offers an abstracted, automated, and prescriptive experience on top of AWS Organizations. It automatically sets up AWS Organizations as the underlying AWS service to organize accounts and implement preventive controls using service control policies (SCPs). \nUsing AWS Organizations, you can further create and attach custom SCPs that centrally control the use of AWS services and resources across multiple AWS accounts.\n\nhttps://aws.amazon.com/controltower/faqs/","timestamp":"1706952900.0"},{"content":"Selected Answer: C\nAnswer C:\nI know its usually safe to choose the SCP answer, but according to the docs that would create drift with Control Tower and need to be remediated.\n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/drift.html#scp-invariance-scans","comment_id":"1134624","timestamp":"1706497740.0","poster":"kejam","upvote_count":"3"},{"timestamp":"1705085340.0","content":"Answer C: \nAWS Control tower already using and preventive control (guardrail) is the key","comment_id":"1121024","upvote_count":"4","poster":"vibzr2023"},{"comment_id":"1117722","content":"Selected Answer: C\nC is the best option. A is possible but given that customer is using Control Tower it option A will cause a drift in landing zone.","upvote_count":"4","poster":"career360guru","timestamp":"1704821940.0"},{"content":"a ans \nHere's why this solution is optimal and why the other options are not as suitable:\n\n1. Enforcement:\n\nSCPs (Service Control Policies) are the most effective way to centrally enforce service and instance restrictions across multiple accounts within an OU.\nDetective controls (guardrails) in Control Tower only detect and report violations, not prevent them.\nAWS Config rules are for configuration compliance, not access control.\n2. Granular Control:\n\nSCPs allow fine-grained control over specific services and instance types, enabling the specific allowance of burstable instances and restriction of other services.\n3. Ease of Management:\n\nSCPs are managed centrally within AWS Organizations, making it efficient to apply and update policies across multiple accounts.\n4. Alignment with Control Tower:\n\nSCPs integrate seamlessly with AWS Control Tower, ensuring consistent governance within the multi-account environment.","upvote_count":"1","comment_id":"1104082","timestamp":"1703343780.0","poster":"duriselvan"},{"content":"still following the aws rule: see OU or managenet account, choose answer with SCP keyword","poster":"GaryQian","comment_id":"1092446","timestamp":"1702206660.0","upvote_count":"1"},{"comment_id":"1091639","poster":"ayadmawla","content":"A = C\ncustom preventive control (guardrail) = SCP\ncustom detective control (guardrail) = AWS Config\n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/controls.html","upvote_count":"3","timestamp":"1702112280.0","comments":[{"upvote_count":"2","timestamp":"1702848300.0","content":"Q: How does AWS Control Tower interoperate with AWS Organizations?\nAWS Control Tower offers an abstracted, automated, and prescriptive experience on top of AWS Organizations. It automatically sets up AWS Organizations as the underlying AWS service to organize accounts and implement preventive controls using service control policies (SCPs). Using AWS Organizations, you can further create and attach custom SCPs that centrally control the use of AWS services and resources across multiple AWS accounts. \n\nhttps://aws.amazon.com/controltower/faqs/","poster":"ayadmawla","comment_id":"1099256"}]},{"content":"The SCP is only to deny actions. A say \"allow to...\"","upvote_count":"3","comment_id":"1087680","timestamp":"1701697920.0","poster":"nublit"},{"poster":"shaaam80","content":"Selected Answer: A\nA is correct! Best practice for OU's is to configure restrictions at the SCP.","comment_id":"1082673","timestamp":"1701183780.0","upvote_count":"3"},{"timestamp":"1700935860.0","upvote_count":"2","poster":"Russs99","comment_id":"1080232","content":"Selected Answer: A\nAnswer is A, you cannot use control tower to control services that can be ran, it only a guard rail"},{"poster":"salazar35","comment_id":"1079982","content":"Selected Answer: A\nI choose A","timestamp":"1700913600.0","upvote_count":"2"},{"content":"Answer is A. Best practice","poster":"Totoroha","upvote_count":"3","timestamp":"1700664240.0","comment_id":"1077452"}],"answer_description":"","question_text":"A company orchestrates a multi-account structure on AWS by using AWS Control Tower. The company is using AWS Organizations, AWS Config, and AWS Trusted Advisor. The company has a specific OU for development accounts that developers use to experiment on AWS. The company has hundreds of developers, and each developer has an individual development account.\n\nThe company wants to optimize costs in these development accounts. Amazon EC2 instances and Amazon RDS instances in these accounts must be burstable. The company wants to disallow the use of other services that are not relevant.\n\nWhat should a solutions architect recommend to meet these requirements?","isMC":true,"answer_images":[],"question_id":255}],"exam":{"isMCOnly":true,"provider":"Amazon","id":33,"isBeta":false,"isImplemented":true,"numberOfQuestions":529,"name":"AWS Certified Solutions Architect - Professional SAP-C02","lastUpdated":"11 Apr 2025"},"currentPage":51},"__N_SSP":true}