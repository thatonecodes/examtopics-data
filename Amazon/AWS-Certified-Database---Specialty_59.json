{"pageProps":{"questions":[{"id":"PrR4j8pLwKTYlKMFwtvP","url":"https://www.examtopics.com/discussions/amazon/view/26355-exam-aws-certified-database-specialty-topic-1-question-37/","discussion":[{"poster":"BillyMadison","comment_id":"140536","timestamp":"1632501840.0","content":"I'm going with D based on the following links.\nhttps://aws.amazon.com/blogs/database/amazon-dynamodb-gaming-use-cases-and-design-patterns/\n\"EA uses the user ID as the partition key and primary key (a 1:1 modeling pattern).\"\nhttps://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/\n\"Partition key and sort key: Referred to as a composite primary key, this type of key is composed of two attributes. The first attribute is the partition key, and the second attribute is the sort key.\"","upvote_count":"19"},{"comment_id":"253181","timestamp":"1633468620.0","upvote_count":"10","poster":"JobinAkaJoe","content":"D is the best choice of keys for below requirements.\n\n✑ Update scores in real time whenever a player is playing the game. -- user_id being partition key\n✑ Retrieve a player's score details for a specific game session. -- game_id sort key"},{"upvote_count":"1","comment_id":"1121322","content":"Selected Answer: D\nI go for D\n- user_ID for global score\n- user_ID (PK) + game_id (SK) for a session","timestamp":"1705124580.0","poster":"MultiAZ"},{"upvote_count":"3","timestamp":"1702132680.0","content":"Selected Answer: C\n- game_id must reflect the game session and not the actual game, because if not even user_id + game_id would not be unique. Saying that, game_id will have higher cardinality.\n- about the query... if it is to get the details of one specific player, both c and d will work, if we want to get the details of all players for a game, only c works.\n\nHaving this said, for me C) is the only answer that will work for all cases, having a higher cardinality value as partition key.\n\nBut let me say that these types of questions must be better elaborated, because at some times it dependends on the interpretation","comment_id":"1091850","poster":"silvaa360"},{"timestamp":"1685919240.0","upvote_count":"1","comment_id":"914945","content":"this is my humble contribution to the solution:\n\n If we want to get the high score for a player for a certain game, user_id should be our partition key and game_id should be our sort key, which is D, but to find out what the highest score ever was for a certain game, we would need game_id to be a partition key and 'score' to be the sort key, which is not in the options. \n\nI mean that cardinality can be decided according to the objective of the query but it is not given explicitly in the question.","poster":"dnelub"},{"poster":"jthuma","upvote_count":"2","timestamp":"1672169940.0","comments":[{"comment_id":"911128","poster":"Paulv82003","timestamp":"1685531400.0","content":"\"each game has a unique game_id\" what are you talking about \"Game_id would have lower cardinality than user_id\"? both unique.","upvote_count":"2"}],"content":"D. Game_id would have lower cardinality than user_id. Say the gaming company only had 4 games with 2m users. You would want your partition to be by higher cardinality and your secondary with lower.","comment_id":"758969"},{"comment_id":"728210","upvote_count":"3","timestamp":"1669553040.0","poster":"fserrano","content":"I'm going with C, for queries and updates game_id and user_id are always used, in addition, game_id has more high cardinality and avoids \"hot\" partitions if used as the partition key."},{"poster":"JeanGat","comments":[{"timestamp":"1686795900.0","upvote_count":"1","comment_id":"923651","poster":"TiredDad","content":"each game has a unique game_id.. meaning if you play same game (e.g. car racing) two times, each time you play the game, it will have a unique game id.. that is what I understand from the question.. because you can't have just one game id for car racing then how will you store data for same user id playing same game multiple times?"}],"content":"Selected Answer: D\nD. There are going to be more user_ids than game_ids, hence user_id will be the higher cardinality value = the better partition key. For those of you saying \"C\", are you telling me Electronic Arts has more unique games than they have users!!??!\nhttps://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/","timestamp":"1664545800.0","upvote_count":"5","comment_id":"683625"},{"poster":"praffuln","content":"Selected Answer: C\nIf there will be player_id it will cause of hot partitioning. So D is wrong. \nC is correct as game_id will have more high cardinality","comment_id":"606373","timestamp":"1653350820.0","upvote_count":"2"},{"content":"C is the answer.\n✑ Scores should be updated in real time anytime a player is engaged in the game. -> game_id is the partition key\n✑ Retrieve the information of a player's score for a certain gaming session. - > game_id and user_id is the primary key (i.e. user_id is the sort key)","comment_id":"603781","poster":"khchan123","upvote_count":"3","timestamp":"1652955420.0"},{"comment_id":"595369","poster":"novice_expert","upvote_count":"2","comments":[{"content":"Scores should be updated in real time anytime a player is engaged in the game. in this case, query will be based on user_id and game_id.. otherwise you will end up fetching all records for that user_id","timestamp":"1686796080.0","upvote_count":"1","comment_id":"923653","poster":"TiredDad"}],"timestamp":"1651365480.0","content":"Selected Answer: D\nuse cases:\n✑ Scores should be updated in real time anytime a player is engaged in the game. (query based on user_id only => user_id partition key)\n✑ Retrieve the information of a player's score for a certain gaming session.(query based on user_id + game_id=> user_id partition key, and game_id sort key)\n\nD. Create a composite primary key with user_id as the partition key and game_id as the sort key"},{"upvote_count":"2","timestamp":"1649722260.0","content":"Answer is C, partition key must have high cardinality ie. game_id as there may be multiple instances of games played by each user.","poster":"randss","comment_id":"584454"},{"comment_id":"575432","poster":"ugo009","timestamp":"1648284120.0","upvote_count":"1","content":"I chose D. GSI does not support strong consistency."},{"upvote_count":"1","timestamp":"1635278640.0","content":"For me, both C and D can be used but C is better.\n✑ Update scores in real time whenever a player is playing the game.\n=> Query by the game_id first, then update relevant user_id with his relevant score. \n✑ Retrieve a playerג€™s score details for a specific game session => game_id can be used to query then specify the user_id\nD can do the same as above. But for the query such as: Top score player for each game, C is better.\nD is for the query such as: This player plays how many games and the score of each.","comment_id":"426194","poster":"ChauPhan"},{"timestamp":"1634229600.0","poster":"uupadhyay","upvote_count":"1","comments":[{"poster":"jove","content":"Partition key should have high cardinality. Therefore user id is better than game id as the partition key.. Answer is D","timestamp":"1640360280.0","upvote_count":"5","comment_id":"508559"}],"content":"Why not C ? Any idea ?","comment_id":"380716"},{"comment_id":"364743","content":"I would go with A.\nReason, Need user_id as partition key for main table and global secondary index with game_id as partition key since we want to update via user_id and also retrieve via game_id. Both these options do not exists in any of the options so A seems to be nearest correct answer.","timestamp":"1633816020.0","poster":"Dip11","comments":[{"content":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html\nGameScores is identified by a partition key (UserId) and a sort key (GameTitle). A query that specified the key attributes (UserId and GameTitle) would be very efficient\nComposite primary key is the answer. For building a leader board we need global secondar index","timestamp":"1640620860.0","upvote_count":"1","comment_id":"510441","poster":"nideesh"}],"upvote_count":"2"},{"comment_id":"314843","content":"Answer D","upvote_count":"3","timestamp":"1633543560.0","poster":"LMax"},{"comment_id":"216008","content":"I was going to say A since the article states game_id as the secondary index, but I think D is the answer, since you need a composite key.","upvote_count":"3","timestamp":"1633400880.0","poster":"edmondme"},{"poster":"Ashoks","comment_id":"212073","timestamp":"1632882480.0","content":"D is the answer.","upvote_count":"3"},{"comment_id":"153923","timestamp":"1632791220.0","content":"Ans D:\nComposite Key has two attributes (=partition/hash key + sort/range key)","upvote_count":"1","poster":"firbhat"},{"timestamp":"1632704880.0","poster":"BillyC","content":"Ans D I think too","upvote_count":"1","comment_id":"144901"}],"question_images":[],"topic":"1","choices":{"B":"Create a global secondary index with user_id as the partition key","A":"Create a global secondary index with game_id as the partition key","D":"Create a composite primary key with user_id as the partition key and game_id as the sort key","C":"Create a composite primary key with game_id as the partition key and user_id as the sort key"},"answer_ET":"D","exam_id":22,"timestamp":"2020-07-21 21:06:00","answer_description":"","isMC":true,"question_text":"An online gaming company is planning to launch a new game with Amazon DynamoDB as its data store. The database should be designated to support the following use cases:\n✑ Update scores in real time whenever a player is playing the game.\n✑ Retrieve a player's score details for a specific game session.\nA Database Specialist decides to implement a DynamoDB table. Each player has a unique user_id and each game has a unique game_id.\nWhich choice of keys is recommended for the DynamoDB table?","unix_timestamp":1595358360,"question_id":291,"answer_images":[],"answers_community":["D (62%)","C (38%)"],"answer":"D"},{"id":"oXcSKDa322MJC3zlNqYG","question_id":292,"question_text":"A Database Specialist migrated an existing production MySQL database from on-premises to an Amazon RDS for MySQL DB instance. However, after the migration, the database needed to be encrypted at rest using AWS KMS. Due to the size of the database, reloading, the data into an encrypted database would be too time-consuming, so it is not an option.\nHow should the Database Specialist satisfy this new requirement?","exam_id":22,"unix_timestamp":1594733880,"answer_description":"","choices":{"C":"Restore an unencrypted snapshot into a MySQL RDS DB instance that is encrypted.","B":"Modify the RDS DB instance. Enable the AWS KMS encryption option that leverages the AWS CLI.","A":"Create a snapshot of the unencrypted RDS DB instance. Create an encrypted copy of the unencrypted snapshot. Restore the encrypted snapshot copy.","D":"Create an encrypted read replica of the RDS DB instance. Promote it the master."},"answers_community":["A (100%)"],"answer_ET":"A","isMC":true,"answer":"A","answer_images":[],"topic":"1","discussion":[{"upvote_count":"16","timestamp":"1632205980.0","comment_id":"140550","poster":"BillyMadison","content":"Agree with A. This blog post also says the same steps as Micky's link.\n\"However, because you can encrypt a copy of an unencrypted DB snapshot, you can effectively add encryption to an unencrypted DB instance. That is, you can create a snapshot of your DB instance, and then create an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot, and thus you have an encrypted copy of your original DB instance. For more information, see Copying a Snapshot.\"\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html"},{"content":"Selected Answer: A\nEncrypt your existing AWS RDS:\n - Take snapshot\n - Copy Snapshot with Enable encryption\n - Change unencrypted instance name\nEncrypt your existing AWS RDS:\n - Take snapshot\n - Copy Snapshot with Enable encryption\n - Change unencrypted instance name\n - Restore Snapshot (DB Instance Identifier field must contain the name of your previous database before renaming it)\nhttps://blog.theodo.com/2019/11/encrypt-existing-aws-rds-database/","upvote_count":"1","timestamp":"1690962660.0","comment_id":"969894","poster":"IhorK"},{"comment_id":"595243","upvote_count":"2","poster":"novice_expert","comments":[{"timestamp":"1680995340.0","poster":"Mintwater","comment_id":"865148","upvote_count":"4","content":"Limitations of Amazon RDS encrypted DB instances\nThe following limitations exist for Amazon RDS encrypted DB instances:\n\nYou can only encrypt an Amazon RDS DB instance when you create it, not after the DB instance is created.\n\nHowever, because you can encrypt a copy of an unencrypted snapshot, you can effectively add encryption to an unencrypted DB instance. That is, you can create a snapshot of your DB instance, and then create an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot, and thus you have an encrypted copy of your original DB instance. For more information, see Copying a DB snapshot.\n\nYou can't turn off encryption on an encrypted DB instance.\n\nYou can't create an encrypted snapshot of an unencrypted DB instance."}],"content":"Selected Answer: A\nsnapshot -> encrypted snapshot -> Restore the encrypted snapshot copy.","timestamp":"1651348260.0"},{"content":"Selected Answer: A\nA is an obvious choice here","comment_id":"585165","poster":"kret","upvote_count":"2","timestamp":"1649849280.0"},{"content":"Here source database is in on premises ? How we can access snapshot of on-premises database from AWS console ? How A is possible ?","upvote_count":"1","timestamp":"1636089540.0","comment_id":"380718","comments":[{"timestamp":"1636169820.0","poster":"Scunningham99","comment_id":"459582","upvote_count":"2","content":"its talking about the database has already been migrated to RDS, but they want to know how to encrypt it after the migration - hence a is correct"}],"poster":"uupadhyay"},{"timestamp":"1636074660.0","comment_id":"314849","upvote_count":"2","content":"Answer A","poster":"LMax"},{"timestamp":"1635980040.0","comment_id":"297994","content":"Ans: A","poster":"myutran","upvote_count":"1"},{"timestamp":"1634121060.0","poster":"Roontha","content":"Answer: A","upvote_count":"1","comment_id":"279771"},{"upvote_count":"1","content":"I guess It should be D: As per this document it is possible to do replication from unencrypted to encrypted read replica.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-encrypt-instance-mysql-mariadb/","poster":"ppravesh","timestamp":"1633762020.0","comment_id":"253757","comments":[{"poster":"GeeBeeEl","content":"This is for MariaDB!!!","timestamp":"1634411640.0","comment_id":"290979","upvote_count":"1"},{"timestamp":"1634743980.0","poster":"Exia","comment_id":"293141","upvote_count":"1","content":"You cannot create an encrypted Read Replica from an unencrypted DB instance."}]},{"upvote_count":"1","comments":[{"upvote_count":"2","content":"To have an encrypted read-replica, primary instance must be encrypted","comment_id":"253203","poster":"JobinAkaJoe","timestamp":"1633395420.0"}],"poster":"rootkim","comment_id":"246092","content":"If you become D, do you really need to do A?\nHow do you fix data inconsistencies?\nD is possible, so I think it's best.","timestamp":"1632731040.0"},{"content":"A is correct","poster":"BillyC","timestamp":"1632302520.0","comment_id":"144903","upvote_count":"1"},{"upvote_count":"4","comment_id":"134885","poster":"Mickysingh","timestamp":"1632165420.0","content":"A is correct answer \nhttps://blog.theodo.com/2019/11/encrypt-existing-aws-rds-database/"}],"url":"https://www.examtopics.com/discussions/amazon/view/25724-exam-aws-certified-database-specialty-topic-1-question-38/","question_images":[],"timestamp":"2020-07-14 15:38:00"},{"id":"Ujda82rMWyAK6UrI6bTy","answer_ET":"D","topic":"1","unix_timestamp":1636662660,"answer_description":"","question_text":"A Database Specialist is planning to create a read replica of an existing Amazon RDS for MySQL Multi-AZ DB instance. When using the AWS Management\nConsole to conduct this task, the Database Specialist discovers that the source RDS DB instance does not appear in the read replica source selection box, so the read replica cannot be created.\nWhat is the most likely reason for this?","url":"https://www.examtopics.com/discussions/amazon/view/65852-exam-aws-certified-database-specialty-topic-1-question-39/","timestamp":"2021-11-11 21:31:00","answer":"D","discussion":[{"content":"Selected Answer: D\n(D) is correct\nIn order to create a read replica\n- Automated Backups MUST be enabled\nAdditionally for SQL Server\n- Source MUST be Multi-AZ deployment with Always On Availability Groups (AG)","timestamp":"1646532360.0","poster":"RotterDam","upvote_count":"6","comment_id":"561739"},{"poster":"novice_expert","content":"Selected Answer: D\nD. Automated backups are not enabled on the source DB instance.\n\nIn order to create a read replica\n- Automated Backups MUST be enabled\nAdditionally for SQL Server\n- Source MUST be Multi-AZ deployment with Always On Availability Groups (AG)","comment_id":"595649","timestamp":"1651420080.0","upvote_count":"5"},{"poster":"Pranava_GCP","content":"Selected Answer: D\nD. Automated backups are not enabled on the source DB instance.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_MultiAZDBCluster_ReadRepl.html\n\n\n\"You must turn on automatic backups on the source DB instance by setting the backup retention period to a value other than 0.\"","comment_id":"995059","timestamp":"1693481760.0","upvote_count":"1"},{"content":"Ans: D","poster":"awsmonster","comment_id":"533806","timestamp":"1643292120.0","upvote_count":"2"},{"timestamp":"1636662660.0","upvote_count":"2","content":"D.\n>Your source DB instance must have backup retention enabled. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBInstanceReadReplica.html","comment_id":"476497","poster":"avland"}],"choices":{"C":"The minor MySQL version in the source DB instance does not support read replicas.","B":"Enhanced Monitoring is not enabled on the source DB instance.","D":"Automated backups are not enabled on the source DB instance.","A":"The source DB instance has to be converted to Single-AZ first to create a read replica from it."},"isMC":true,"exam_id":22,"question_images":[],"question_id":293,"answers_community":["D (100%)"],"answer_images":[]},{"id":"1oBlrPvCv5f77nDA19Ws","answers_community":["B (100%)"],"isMC":true,"choices":{"B":"Instruct the Data Analysts to download the root certificate and use the SSL certificate on the connection string to connect.","D":"Modify the Data Analysts' local client firewall to allow network traffic to AWS.","C":"Add explicit mappings between the Data Analysts' IP addresses and the instance in the security group assigned to the DB cluster.","A":"Restart the DB cluster to apply the SSL change."},"answer_ET":"B","question_images":[],"question_id":294,"exam_id":22,"question_text":"A company is deploying a solution in Amazon Aurora by migrating from an on-premises system. The IT department has established an AWS Direct Connect link from the company's data center. The company's Database Specialist has selected the option to require SSL/TLS for connectivity to prevent plaintext data from being set over the network. The migration appears to be working successfully, and the data can be queried from a desktop machine.\nTwo Data Analysts have been asked to query and validate the data in the new Aurora DB cluster. Both Analysts are unable to connect to Aurora. Their user names and passwords have been verified as valid and the Database Specialist can connect to the DB cluster using their accounts. The Database Specialist also verified that the security group configuration allows network from all corporate IP addresses.\nWhat should the Database Specialist do to correct the Data Analysts' inability to connect?","discussion":[{"content":"Selected Answer: B\nB. Instruct the Data Analysts to download the root certificate and use the SSL certificate on the connection string to connect.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/ssl-certificate-rotation-aurora-postgresql.html","timestamp":"1694722980.0","poster":"Pranava_GCP","upvote_count":"3","comment_id":"1007912"},{"upvote_count":"4","content":"Author from the Udemy.com practice test says B is the correct answer.","comment_id":"778878","poster":"SteveMartin9","timestamp":"1673957160.0"},{"content":"Selected Answer: B\nB is the right one","poster":"sirfans","comment_id":"703970","timestamp":"1666710300.0","upvote_count":"1"},{"upvote_count":"1","content":"B is the answer","timestamp":"1663933080.0","comment_id":"677064","poster":"niteshdba"},{"upvote_count":"2","poster":"novice_expert","content":"Selected Answer: B\nB. Instruct the Data Analysts to download the root certificate and use the SSL certificate on the connection string to connect.\n\n To connect using SSL:\n• Provide the SSLTrust certificate (can be downloaded from AWS)\n• Provide SSL options when connecting to database\n• Not using SSL on a DB that enforces SSL would result in error\n\nB - Need root certificate and then need to specify --sql-ca = cert.pem --ssl-mode=verify_identity for example mysql\n\nWhen the require_secure_transport parameter is set to ON for a DB cluster, a database client can connect to it if it can establish an encrypted connection. Otherwise, an error message similar to the following is returned to the client:\n\nMySQL Error 3159 (HY000): Connections using insecure transport are prohibited while --require_secure_transport=ON.","comment_id":"595372","timestamp":"1651365960.0"},{"upvote_count":"3","content":"The answer is (B). what I am beginning to REALLY dislike about some of these questions is the terrible grammar. This question is very similar to another question bank where the Database specialist is able to connect to the Aurora Cluster. The english they are using is \"Specialist MAY use their account to log in\" - this is artificially vague. in the pressure of time - such english just leaves a bad taste and its clear many of the questions are not written by native english language speakers - which makes it frustrating","poster":"RotterDam","comment_id":"562154","timestamp":"1646586660.0"},{"poster":"Shunpin","content":"Selected Answer: B\nMy point: Usually, you have no privileges to modify local firewall policy in a big cooperate. In the question, it has mentioned the connection can be made from desktop that means local firewall rules allow to access RDS.","timestamp":"1640685000.0","upvote_count":"3","comment_id":"510962"},{"upvote_count":"1","content":"its B, SSL issue.","comment_id":"434483","poster":"aws4myself","timestamp":"1636285260.0"},{"content":"Correct Answer ==>> B","upvote_count":"1","comment_id":"429432","poster":"guru_ji","timestamp":"1636142340.0"},{"content":"B, you need a cert","comment_id":"414739","upvote_count":"1","poster":"Dr_Kiko","timestamp":"1636059660.0"},{"poster":"LMax","upvote_count":"3","content":"Must be B, SSL issue.","comment_id":"314121","timestamp":"1636000260.0"},{"comment_id":"313339","upvote_count":"1","poster":"jnassp1","content":"B\n\n• To connect using SSL:\n• Provide the SSLTrust certificate (can be downloaded from AWS)\n• Provide SSL options when connecting to database\n• Not using SSL on a DB that enforces SSL would result in error","timestamp":"1635998580.0"},{"upvote_count":"1","content":"D is not right this. The questions is on SSL/TLS encryption in transit - \n\nB - Need root certificate and then need to specify --sql-ca = cert.pem --ssl-mode=verify_identity for example mysql","poster":"jnassp1","comment_id":"313335","timestamp":"1635116400.0"},{"poster":"myutran","upvote_count":"1","comment_id":"296287","timestamp":"1634894400.0","content":"Ans: D"},{"comment_id":"292049","upvote_count":"1","poster":"Exia","content":"When the require_secure_transport parameter is set to ON for a DB cluster, a database client can connect to it if it can establish an encrypted connection. Otherwise, an error message similar to the following is returned to the client:\n\nMySQL Error 3159 (HY000): Connections using insecure transport are prohibited while --require_secure_transport=ON.","timestamp":"1634833080.0"},{"upvote_count":"2","content":"D. Aurora MySQL DB clusters must be created in an Amazon Virtual Private Cloud (VPC). To control which devices and Amazon EC2 instances can open connections to the endpoint and port of the DB instance for Aurora MySQL DB clusters in a VPC, you use a VPC security group. These endpoint and port connections can be made using Secure Sockets Layer (SSL). In addition, firewall rules at your company can control whether devices running at your company can open connections to a DB instance.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Security.html","comment_id":"292042","poster":"Exia","timestamp":"1634770500.0"},{"content":"Answer is B\nAs SSL parameter can be used in string \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/ssl-certificate-rotation-aurora-postgresql.html","timestamp":"1634443800.0","comment_id":"171045","poster":"goodh32","upvote_count":"3"},{"upvote_count":"3","poster":"Ebi","content":"Answer B","comment_id":"167381","timestamp":"1634131140.0"},{"comment_id":"160745","timestamp":"1634102760.0","content":"of course you can use a cert on the connection string\nhttps://www.connectionstrings.com/mysql-connector-odbc-5-1/using-ssl/","poster":"[Removed]","upvote_count":"2"},{"upvote_count":"4","comment_id":"160741","content":"I will go with B too. While certificates are not part of the connection string, it won't even get that far if the connection is not trusted.\nThe wording on D sounds off - traffic to aws? how can a local firewall disallow traffic to AWS, that would have had to be intentionally done? then they would not have access to anything in AWS. Looks like a distractor to me leaving B the only viable answer.","poster":"[Removed]","timestamp":"1634051460.0"},{"poster":"firbhat","content":"I will go with B.\nthere is hint in the quest: \nThe company's Database Specialist has selected the option to require SSL/TLS for connectivity","comment_id":"153091","timestamp":"1633875060.0","upvote_count":"4"},{"upvote_count":"2","poster":"szmulder","timestamp":"1633197720.0","comments":[{"comments":[{"timestamp":"1634361060.0","content":"That's a good point.","poster":"szmulder","upvote_count":"1","comment_id":"170303"}],"content":"It's D because apart from coporate network firewalls, there can also be local firewalls such as those from the operating system of each Data analyst.","comment_id":"150364","upvote_count":"2","timestamp":"1633801740.0","poster":"et88"}],"content":"It's B.\nWhy is not D, because he Database Specialist can connect to the DB cluster using their accounts. So it's not the problem for the company network.","comment_id":"149481"},{"poster":"BillyMadison","upvote_count":"1","content":"D seems plausible \nhttps://aws.amazon.com/premiumsupport/knowledge-center/troubleshoot-connecting-aurora/\n\"The DB instance security group, ACLs, or a local firewall are blocking the connection from the source instance or its IP addresses.\"","timestamp":"1632708360.0","comment_id":"138972"},{"poster":"k115","content":"B is the right answer. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/ssl-certificate-rotation-aurora-mysql.html","upvote_count":"4","comment_id":"136048","timestamp":"1632608100.0","comments":[{"upvote_count":"2","poster":"et88","timestamp":"1633536300.0","content":"B is not the correct answer as SSL certificate is not used in the connection string. Downloaded certificates are saved locally in certificate store for verification of SSL connection.","comment_id":"150362"}]},{"content":"Yes, D","timestamp":"1632562560.0","comment_id":"134138","upvote_count":"2","poster":"BillyC"},{"poster":"chicagomassageseeker","timestamp":"1632546540.0","upvote_count":"3","comments":[{"upvote_count":"1","poster":"Dr_Kiko","content":"wrong: Their user names and passwords have been verified as valid and the Database Specialist can connect to the DB cluster using their accounts.","comment_id":"414741","timestamp":"1636062780.0"}],"comment_id":"129084","content":"Answer D\nIts most liely the security group of DB instance issue. However the queestion already says the \"security group configuration allows network from all corporate IP addresses\" . so you can eliminate C.\n\nFirewall rules at your company can control whether devices running at your company can open connections to a DB instance. Hence D."}],"unix_timestamp":1594136040,"topic":"1","answer_description":"","answer_images":[],"timestamp":"2020-07-07 17:34:00","url":"https://www.examtopics.com/discussions/amazon/view/25029-exam-aws-certified-database-specialty-topic-1-question-4/","answer":"B"},{"id":"NIrduq1bRaofbgVYeCtn","timestamp":"2020-07-13 17:48:00","question_id":295,"unix_timestamp":1594655280,"exam_id":22,"question_text":"A Database Specialist has migrated an on-premises Oracle database to Amazon Aurora PostgreSQL. The schema and the data have been migrated successfully.\nThe on-premises database server was also being used to run database maintenance cron jobs written in Python to perform tasks including data purging and generating data exports. The logs for these jobs show that, most of the time, the jobs completed within 5 minutes, but a few jobs took up to 10 minutes to complete. These maintenance jobs need to be set up for Aurora PostgreSQL.\nHow can the Database Specialist schedule these jobs so the setup requires minimal maintenance and provides high availability?","isMC":true,"question_images":[],"answers_community":["C (100%)"],"discussion":[{"content":"Answer should be C but below link confuses\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/events/Create-CloudWatch-Events-Scheduled-Rule.html\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/schedule-jobs-for-amazon-rds-and-aurora-postgresql-using-lambda-and-secrets-manager.html\n\n a job for data extraction or a job for data purging can easily be scheduled using cron. For these jobs, database credentials are typically either hard-coded or stored in a properties file. However, when you migrate to Amazon Relational Database Service (Amazon RDS) or Amazon Aurora PostgreSQL, you lose the ability to log in to the host instance to schedule cron jobs. \n\nThis pattern describes how to use AWS Lambda and AWS Secrets Manager to schedule jobs for Amazon RDS and Aurora PostgreSQL databases after migration. \n\nit confirms that answer is C","comments":[{"content":"I agree with C via your second link:\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/schedule-jobs-for-amazon-rds-and-aurora-postgresql-using-lambda-and-secrets-manager.html","timestamp":"1632569340.0","comment_id":"140562","poster":"BillyMadison","upvote_count":"3"},{"timestamp":"1632628800.0","upvote_count":"2","poster":"waterh30","comment_id":"242194","content":"https://medium.com/better-programming/cron-job-patterns-in-aws-126fbf54a276"}],"poster":"Mickysingh","upvote_count":"13","timestamp":"1632462300.0","comment_id":"134560"},{"timestamp":"1693482420.0","comment_id":"995069","upvote_count":"1","poster":"Pranava_GCP","content":"Selected Answer: C\nC. Create AWS Lambda functions to run the maintenance jobs and schedule them with Amazon CloudWatch Events."},{"upvote_count":"2","poster":"IhorK","content":"Selected Answer: C\n- You can also use CloudWatch Events to schedule automated actions that self-initiate at certain times using cron or rate expressions.\n- Lambda supports Python.\n- CloudWatch Events can call Lambda functions.\n- Less then 15 min job.\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/schedule-jobs-for-amazon-rds-for-postgresql-and-aurora-postgresql-by-using-lambda-and-secrets-manager.html","comment_id":"969923","timestamp":"1690964040.0"},{"poster":"RotterDam","timestamp":"1646505840.0","comments":[{"upvote_count":"2","poster":"im_not_robot","content":"It depends on how long the job run. Because lambda has 15 minutes limitation.\nIf the job needs more than 15 minutes to run, then can consider AWS Batch, ECS, EC2","comment_id":"800483","timestamp":"1675738140.0"}],"upvote_count":"4","comment_id":"561579","content":"Selected Answer: C\nC. Whenever its asked to create Cron Jobs Lambda vs EC2 : Its ALWAYS Lambda!!"},{"poster":"GMartinelli","upvote_count":"1","timestamp":"1638460860.0","comment_id":"492650","content":"Selected Answer: C\nOption C"},{"content":"Correct Answer ==>> C","comment_id":"430189","timestamp":"1635894780.0","poster":"guru_ji","upvote_count":"2"},{"poster":"ChauPhan","upvote_count":"1","content":"C is correct. \nA B is not HA.\nD, there is no such maintenance JOB for CW Events. CW Events has to trigger the other functions (Lambda/SSM/Step Function/ Batch) to do the task.","timestamp":"1635784260.0","comment_id":"426217","comments":[{"content":"Correct Answer: C","comment_id":"438331","timestamp":"1636054740.0","upvote_count":"1","poster":"guru_ji"}]},{"upvote_count":"2","comment_id":"364762","poster":"Dip11","content":"Answer should be C. I don't think there is anything like CloudWatch job scheduling plugin. Internet search doesn't show anything like this.","timestamp":"1635111120.0"},{"comment_id":"314863","content":"Agree with Answer C","poster":"LMax","upvote_count":"2","timestamp":"1634084820.0"},{"content":"Agree with Answer C","upvote_count":"2","comment_id":"314862","poster":"LMax","timestamp":"1633690260.0"},{"timestamp":"1633348440.0","upvote_count":"1","content":"C for me","comment_id":"299042","poster":"Windy"},{"poster":"myutran","content":"Ans: C","upvote_count":"2","comment_id":"298004","timestamp":"1633148940.0"},{"content":"C is the best answer.\nEventbridge would have been a better choice to schedule lambda.\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/events/RunLambdaSchedule.html","upvote_count":"2","poster":"JobinAkaJoe","comment_id":"253210","timestamp":"1633094160.0"},{"content":"Ans is C. CloudWatch scheduling and Lambda execution and this option should be fine as long as job completes within 15 minutes.","comment_id":"212077","upvote_count":"4","timestamp":"1632576600.0","poster":"Ashoks"},{"upvote_count":"4","content":"Answer should be C","comment_id":"140273","poster":"BillyC","timestamp":"1632539100.0"},{"comment_id":"134056","timestamp":"1632238860.0","poster":"[Removed]","content":"The document referenced has no mention of job scheduling plugin for cloudwatch.... it is for systems manager. \nI will have to go with C.","upvote_count":"2"}],"answer_images":[],"answer_description":"","answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/25619-exam-aws-certified-database-specialty-topic-1-question-40/","answer_ET":"C","choices":{"C":"Create AWS Lambda functions to run the maintenance jobs and schedule them with Amazon CloudWatch Events.","D":"Create the maintenance job using the Amazon CloudWatch job scheduling plugin.","B":"Connect to the Aurora host and create cron jobs to run the maintenance jobs following the required schedule.","A":"Create cron jobs on an Amazon EC2 instance to run the maintenance jobs following the required schedule."},"topic":"1"}],"exam":{"numberOfQuestions":359,"isImplemented":true,"id":22,"provider":"Amazon","isBeta":false,"name":"AWS Certified Database - Specialty","lastUpdated":"11 Apr 2025","isMCOnly":false},"currentPage":59},"__N_SSP":true}