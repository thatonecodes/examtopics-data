{"pageProps":{"questions":[{"id":"aNAEgkO3CtskjsdPpokr","timestamp":"2023-05-15 13:45:00","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/109281-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","discussion":[{"comment_id":"898235","poster":"nosense","content":"Selected Answer: AB\nidentity-based policy used for role and group","upvote_count":"18","timestamp":"1700055900.0"},{"poster":"pentium75","content":"Selected Answer: AB\nIsn't the content of the policy completely irrelevant? IAM policies are applied to users, groups or roles ...","timestamp":"1719737520.0","comment_id":"1110468","upvote_count":"7"},{"comment_id":"1167876","poster":"dkw2342","timestamp":"1725696420.0","upvote_count":"2","content":"AB is correct, but the question is misleading because, according to the AWS IAM documentation, groups are not considered principals: \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/intro-structure.html#intro-structure-principal.\""},{"timestamp":"1708898520.0","comment_id":"990374","upvote_count":"3","poster":"Guru4Cloud","content":"Selected Answer: AB\nA. Role\nB. Group"},{"timestamp":"1701931440.0","upvote_count":"3","comment_id":"916862","content":"Selected Answer: AB\nRole or group","poster":"TariqKipkemei"}],"answer_ET":"AB","choices":{"E":"Amazon EC2 resource","A":"Role","B":"Group","C":"Organization","D":"Amazon Elastic Container Service (Amazon ECS) resource"},"exam_id":31,"question_id":381,"topic":"1","isMC":true,"unix_timestamp":1684151100,"question_images":["https://img.examtopics.com/aws-certified-solutions-architect-associate-saa-c03/image4.png"],"answer":"AB","answers_community":["AB (100%)"],"question_text":"A solutions architect wants to use the following JSON text as an identity-based policy to grant specific permissions:\n\n//IMG//\n\n\nWhich IAM principals can the solutions architect attach this policy to? (Choose two.)"},{"id":"6dXCEpAFyFsUvKKZrAth","question_text":"A company is running a custom application on Amazon EC2 On-Demand Instances. The application has frontend nodes that need to run 24 hours a day, 7 days a week and backend nodes that need to run only for a short time based on workload. The number of backend nodes varies during the day.\n\nThe company needs to scale out and scale in more instances based on workload.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_images":[],"answers_community":["B (63%)","A (37%)"],"url":"https://www.examtopics.com/discussions/amazon/view/109283-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","choices":{"B":"Use Reserved Instances for the frontend nodes. Use Spot Instances for the backend nodes.","C":"Use Spot Instances for the frontend nodes. Use Reserved Instances for the backend nodes.","A":"Use Reserved Instances for the frontend nodes. Use AWS Fargate for the backend nodes.","D":"Use Spot Instances for the frontend nodes. Use AWS Fargate for the backend nodes."},"answer_description":"","question_id":382,"answer_ET":"B","unix_timestamp":1684151880,"question_images":[],"discussion":[{"comments":[{"timestamp":"1704578460.0","upvote_count":"6","poster":"awsgeek75","content":"Fargate is serverless EKS so it cannot manage EC2 nodes","comment_id":"1115463"}],"comment_id":"1024846","poster":"Ramdi1","timestamp":"1696427100.0","upvote_count":"17","content":"Selected Answer: A\nHas to be A, It can scale down if required and you will be charged for what you use with fargate. Secondly they have not said the backend can have timeouts or can be down for a little period of time or something. So it has to rule out any spot instances even though they are cheaper."},{"upvote_count":"15","comment_id":"898244","timestamp":"1684151880.0","poster":"nosense","content":"Selected Answer: B\nReserved+ spot .\nFargate for serverless"},{"poster":"zdi561","comment_id":"1351697","timestamp":"1738728420.0","upvote_count":"1","content":"Selected Answer: A\nI think in A it should be Fargat spot, B means standard spot. The former uses auto scaling and the later does not"},{"poster":"zdi561","comment_id":"1343083","timestamp":"1737304260.0","upvote_count":"1","content":"Selected Answer: A\nThe requirement is to have an autoscaling , and fargate can do that. Spot instance only works when the work load is fault tolerant. Furthermore it is told to use on-demand instance."},{"content":"I will go with A.\nWhere does the question mentions that the workload interruptions are accepted.","upvote_count":"3","timestamp":"1728870000.0","comment_id":"1297169","poster":"Mayur_B"},{"upvote_count":"3","poster":"mussha","comment_id":"1167105","timestamp":"1709722980.0","content":"Selected Answer: B\nB) because firegate is containser"},{"comment_id":"1161037","content":"so what ive make up from this scenario is: the key word right here is \"backend nodes\" you cant use a serverless compute service with nodes and you need to use EC2s\nso if we had ECS EC2 lunch type or on-demand EC2s as an options for the backend, they would be true?","timestamp":"1709073240.0","upvote_count":"2","poster":"noircesar25"},{"timestamp":"1704618840.0","content":"Selected Answer: B\n24-7 usage for fe -> reserved instance\nirregular workload for be -> spot instance","upvote_count":"4","poster":"mwwt2022","comment_id":"1115667"},{"timestamp":"1704021840.0","content":"Selected Answer: B\nNot A because Fargate runs containers, not EC2 instances. But we have no indication that the workload would be containerized; it runs \"on EC2 instances\".\nNot C and D because frontend must run 24/7, can't use Spot.\n\nThus B, yes, Spot instances are risky, but as they need to run \"only for a short time\" it seems acceptable.\n\nTechnically ideal option would be Reserved Instances for frontend nodes and On-demand instances for backend nodes, but that is not an option here.","upvote_count":"8","comment_id":"1110480","poster":"pentium75"},{"content":"Selected Answer: B\nNot sure the application can be containerized","comment_id":"1088151","upvote_count":"3","poster":"[Removed]","timestamp":"1701743580.0"},{"comments":[{"comment_id":"1126269","timestamp":"1705617600.0","upvote_count":"2","content":"Fargate = containers\nA is wrong","poster":"awsgeek75"}],"comment_id":"1085778","poster":"AwsZora","upvote_count":"1","content":"Selected Answer: A\nit is safe","timestamp":"1701499080.0"},{"comments":[{"content":"Option A (Use Reserved Instances for the frontend nodes. Use AWS Fargate for the backend nodes): AWS Fargate is a serverless compute engine for containers, and it may not be the best fit for the described backend workload, especially if the number of backend nodes varies during the day.","comment_id":"1084341","upvote_count":"1","timestamp":"1701347280.0","poster":"meowruki"}],"timestamp":"1701347220.0","poster":"meowruki","upvote_count":"2","comment_id":"1084340","content":"Selected Answer: B\nReserved Instances (RIs) for Frontend Nodes: Since the frontend nodes need to run continuously (24/7), using Reserved Instances for them makes sense. RIs provide significant cost savings compared to On-Demand Instances for steady-state workloads.\n\n Spot Instances for Backend Nodes: Spot Instances are suitable for short-duration workloads and can be significantly cheaper than On-Demand Instances. Since the number of backend nodes varies during the day, Spot Instances can help you take advantage of spare capacity at a lower cost. Keep in mind that Spot Instances may be interrupted if the capacity is needed elsewhere, so they are best suited for stateless and fault-tolerant workloads."},{"timestamp":"1700704920.0","poster":"Goutham4981","upvote_count":"3","comment_id":"1077981","content":"Selected Answer: B\nAWS Fargate is a serverless compute engine for containers that allows you to run containers without having to manage the underlying infrastructure. It simplifies the process of deploying and managing containerized applications by abstracting away the complexities of server management, scaling, and cluster orchestration.\nNo containerized application requirements are mentioned in the question. Plain EC2 instances. So Fargate is not actually an option"},{"poster":"thanhnv142","comment_id":"1048833","content":"A is fargate, which is none sense. B seems more OK (though none-sense)","timestamp":"1697809380.0","upvote_count":"4"},{"comment_id":"1021426","content":"Selected Answer: A\nFargate for backend node","timestamp":"1696074780.0","poster":"dilaaziz","comments":[{"content":"Fargate is for containers not EC2 so A is wrong","upvote_count":"2","timestamp":"1705617660.0","poster":"awsgeek75","comment_id":"1126270"}],"upvote_count":"2"},{"timestamp":"1695500640.0","content":"Selected Answer: A\n(B) would take chance, though unlikely (A) is server-less auto-scaling. In case backend is idle, it might scale down, save money but no need to worry for interruption by Spot instance.","comment_id":"1015315","upvote_count":"3","poster":"Wayne23Fang"},{"upvote_count":"3","comment_id":"977843","timestamp":"1691681640.0","content":"Selected Answer: A\nIf you will use spot instances you must assumme lost any job in course. This scenary has not explicit mentions about aaplication can tolerate this situations, then, on my opinion, option A is the most suitable.","poster":"Ale1973","comments":[{"poster":"pentium75","content":"But the app is not containerized, it can't run on Fargate without significant changes.","timestamp":"1704021660.0","comment_id":"1110478","upvote_count":"1"}]},{"timestamp":"1689937740.0","content":"Selected Answer: B\nQuestion keyword \"scale out and scale in more instances\". Therefore not related Kubernetes. Choose B, reserved instance for front-end and spot instance for back-end.","comment_id":"958369","poster":"james2033","upvote_count":"2"},{"timestamp":"1688125380.0","comments":[{"comment_id":"977840","content":"Totally agree, lose job in course is an assumption for use spot instances and scenary has not explicit mentions about","upvote_count":"1","timestamp":"1691681520.0","poster":"Ale1973"}],"comment_id":"939056","content":"im on the fence for SPOT because you could lose your spot during a workload and it doesnt mention that, that is acceptable.. Business needs to define requirements and document acceptability for this or you lose your job..","poster":"Gooniegoogoo","upvote_count":"1"},{"poster":"TariqKipkemei","upvote_count":"3","timestamp":"1686113700.0","comment_id":"916870","content":"Option B will meet this requirement:\n\nFrontend nodes that need to run 24 hours a day, 7 days a week = Reserved Instances\nBackend nodes run only for a short time = Spot Instances"},{"comments":[],"content":"But Spot Instances are not based on workloads! Maybe it should be A...!?","timestamp":"1685595480.0","comment_id":"911739","upvote_count":"3","poster":"udo2020"},{"content":"Selected Answer: B\nshort time = SPOT","upvote_count":"5","poster":"alvinnguyennexcel","timestamp":"1684926240.0","comment_id":"905775"},{"comment_id":"898781","timestamp":"1684195800.0","content":"Selected Answer: B\nAgreed","upvote_count":"3","poster":"Efren"}],"isMC":true,"answer":"B","timestamp":"2023-05-15 13:58:00","exam_id":31},{"id":"i5YQ4eHsP0bg3Ot0oq0L","question_text":"A company uses high block storage capacity to runs its workloads on premises. The company's daily peak input and output transactions per second are not more than 15,000 IOPS. The company wants to migrate the workloads to Amazon EC2 and to provision disk performance independent of storage capacity.\n\nWhich Amazon Elastic Block Store (Amazon EBS) volume type will meet these requirements MOST cost-effectively?","answer_description":"","discussion":[{"content":"Selected Answer: C\nGp3 $ 0.08 usd per gb\nGp2 $ 0.10 usd per gb","comment_id":"898243","timestamp":"1684151820.0","upvote_count":"15","poster":"nosense"},{"content":"Selected Answer: C\nBoth GP2 and GP3 has max IOPS 16000 but GP3 is cost effective.\nhttps://aws.amazon.com/blogs/storage/migrate-your-amazon-ebs-volumes-from-gp2-to-gp3-and-save-up-to-20-on-costs/","comment_id":"902599","poster":"Yadav_Sanjay","timestamp":"1684589940.0","upvote_count":"12"},{"content":"Selected Answer: C\nOK, and is this something I should know to prepare for the exam...","poster":"LeonSauveterre","comment_id":"1321290","upvote_count":"1","timestamp":"1733214480.0"},{"timestamp":"1692987600.0","upvote_count":"4","poster":"Guru4Cloud","content":"Selected Answer: C\nC. GP3 volume type","comment_id":"990310"},{"timestamp":"1689938460.0","comment_id":"958389","content":"Selected Answer: C\nQuote \"customers can scale up to 16,000 IOPS and\" at https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-new-amazon-ebs-general-purpose-volumes-gp3/","upvote_count":"3","poster":"james2033"},{"upvote_count":"2","poster":"alexandercamachop","comment_id":"914032","content":"Selected Answer: C\nThe GP3 (General Purpose SSD) volume type in Amazon Elastic Block Store (EBS) is the most cost-effective option for the given requirements. GP3 volumes offer a balance of price and performance and are suitable for a wide range of workloads, including those with moderate I/O needs.\n\nGP3 volumes allow you to provision performance independently from storage capacity, which means you can adjust the baseline performance (measured in IOPS) and throughput (measured in MiB/s) separately from the volume size. This flexibility allows you to optimize your costs while meeting the workload requirements.\n\nIn this case, since the company's daily peak input and output transactions per second are not more than 15,000 IOPS, GP3 volumes provide a suitable and cost-effective option for their workloads.","timestamp":"1685842380.0"},{"comments":[{"comment_id":"953187","poster":"somsundar","content":"@maver144 - That's the case with GP2 volumes. With GP3 we can define IOPS independent of storage capacity.","timestamp":"1689497160.0","upvote_count":"4"}],"upvote_count":"2","poster":"maver144","content":"Selected Answer: B\nIt is not C pals. The company wants to migrate the workloads to Amazon EC2 and to provision disk performance independent of storage capacity. With GP3 we have to increase storage capacity to increase IOPS over baseline. \n\nYou can only chose IOPS independetly with IO family and IO2 is in general better then IO1.","timestamp":"1685358060.0","comment_id":"909306"},{"comment_id":"905025","poster":"Joselucho38","timestamp":"1684854720.0","upvote_count":"2","content":"Selected Answer: C\nTherefore, the most suitable and cost-effective option in this scenario is the GP3 volume type (option C)."},{"content":"Selected Answer: C\nGPS3 allows 16000 IOPS","timestamp":"1684195980.0","comment_id":"898782","upvote_count":"4","poster":"Efren"}],"url":"https://www.examtopics.com/discussions/amazon/view/109282-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"C","timestamp":"2023-05-15 13:57:00","unix_timestamp":1684151820,"answer":"C","answer_images":[],"exam_id":31,"answers_community":["C (96%)","4%"],"question_id":383,"isMC":true,"choices":{"C":"GP3 volume type","B":"io2 volume type","A":"GP2 volume type","D":"io1 volume type"},"question_images":[],"topic":"1"},{"id":"Bnf5kUI0kD9djxxYWzec","answer_ET":"A","answer":"A","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/109278-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company needs to store data from its healthcare application. The application’s data frequently changes. A new regulation requires audit access at all levels of the stored data.\n\nThe company hosts the application on an on-premises infrastructure that is running out of storage capacity. A solutions architect must securely migrate the existing data to AWS while satisfying the new regulation.\n\nWhich solution will meet these requirements?","unix_timestamp":1684149480,"answer_images":[],"choices":{"C":"Use Amazon S3 Transfer Acceleration to move the existing data to Amazon S3. Use AWS CloudTrail to log data events.","B":"Use AWS Snowcone to move the existing data to Amazon S3. Use AWS CloudTrail to log management events.","A":"Use AWS DataSync to move the existing data to Amazon S3. Use AWS CloudTrail to log data events.","D":"Use AWS Storage Gateway to move the existing data to Amazon S3. Use AWS CloudTrail to log management events."},"answer_description":"","exam_id":31,"question_id":384,"timestamp":"2023-05-15 13:18:00","discussion":[{"timestamp":"1697809740.0","upvote_count":"14","content":"A is better because: \n- Data sync is used for migrate. Storage gw is used to connect on-prem to AWS. \n- dataevents is to log for access, management events is for config or management","comment_id":"1048838","poster":"thanhnv142"},{"comment_id":"1110487","timestamp":"1704022320.0","content":"Selected Answer: A\nWe need to log \"access at all levels\" aka \"data events\", thus B and D are out (logging only \"management events\" like granting permissions or changing the access tier).\nC, S3 Transfer Acceleration is to increase upload performance from widespread sources or over unreliable networks, but it just provides an endpoint, it does not upload anything itself.","poster":"pentium75","upvote_count":"11"},{"upvote_count":"2","content":"Selected Answer: A\ndata management shows management operations that are performed on resources in your AWS account so, D is wrong\nhttps://repost.aws/knowledge-center/cloudtrail-data-management-events","timestamp":"1735953540.0","poster":"hpirnaj","comment_id":"1336217"},{"poster":"JA2018","upvote_count":"2","comment_id":"1316313","content":"Selected Answer: A\nKeys in STEM:\n\nA company needs to store data from its healthcare application. The application’s data frequently changes. A new regulation requires audit access at all levels of the stored data.\n\n1. Must securely migrate the existing data to AWS while satisfying the new regulation.\n\n2. Logs access at all data levels","timestamp":"1732280400.0"},{"upvote_count":"3","comment_id":"1260804","poster":"1e22522","content":"Selected Answer: A\nTypical DataSync scenario me thinks!","timestamp":"1722804600.0"},{"timestamp":"1709564760.0","upvote_count":"4","content":"Selected Answer: A\nUse AWS DataSync to migrate existing data to Amazon S3https://aws.amazon.com/datasync/faqs/","poster":"osmk","comment_id":"1165734"},{"poster":"NayeraB","content":"Selected Answer: A\nIt's DataSync for me","comment_id":"1153179","timestamp":"1708250820.0","upvote_count":"3"},{"content":"Selected Answer: D\nStorage Gateway integration with CloudTrail :\nhttps://docs.aws.amazon.com/filegateway/latest/filefsxw/logging-using-cloudtrail.html\n\nwhereas DataSync can be monitored with Amazon CloudWatch:\nhttps://docs.aws.amazon.com/datasync/latest/userguide/monitor-datasync.html","upvote_count":"2","poster":"frmrkc","comment_id":"1137799","timestamp":"1706809200.0","comments":[{"content":"and here are all Storage Gateway actions monitored by CloudTrail:\nhttps://docs.aws.amazon.com/storagegateway/latest/APIReference/API_Operations.html","poster":"frmrkc","upvote_count":"1","timestamp":"1706810580.0","comment_id":"1137810"}]},{"comment_id":"1115472","upvote_count":"4","timestamp":"1704579240.0","poster":"awsgeek75","content":"Selected Answer: A\nB and C don't solve the problem\nA is extending the data and management events are for administrative actions only (tracking account creation, user security actions etc.).\nC uses DataSync to move all the data and logs data events which include S3 file uploads and downloads.\n\nManagement events: User logs into an EC2 instance, creates an S3 IAM role\nData events: User uploads a file to S3"},{"poster":"benacert","upvote_count":"2","content":"A- DataSync secure fast data transfer","comment_id":"1115355","timestamp":"1704563880.0"},{"poster":"ZZZ_Sleep","timestamp":"1703037840.0","comment_id":"1101131","comments":[{"timestamp":"1704022140.0","upvote_count":"6","comment_id":"1110483","poster":"pentium75","content":"\"Securely migrate the existing data to AWS\" -> move data away fron on-premises storage to AWS. Plus, D logs only management events, not \"access at all levels\"."}],"content":"Selected Answer: D\n*Keyword* of this question = running out of storage capacity\n\nAWS Storage Gateway = extend the on-premises storage\nAWS DataSync = copy data between on-premises storage\n\nSo, the answer should be D (AWS Storage Gateway)","upvote_count":"6"},{"comments":[{"poster":"pentium75","upvote_count":"1","comment_id":"1110488","timestamp":"1704022380.0","content":"Thus it is wrong, but more because of the incorrect logging option in this answer."}],"comment_id":"1093727","timestamp":"1702317060.0","poster":"aws94","upvote_count":"1","content":"Selected Answer: D\nAWS DataSync is designed for fast, simple, and secure data transfer, but it focuses more on data synchronization rather than on-premises migration."},{"content":"Selected Answer: A\nAWS DataSync is suitable for data transfer and synchronization\n\nOption D (Use AWS Storage Gateway to move the existing data to Amazon S3. Use AWS CloudTrail to log management events): AWS Storage Gateway is typically used for hybrid cloud storage solutions and may introduce additional complexity for a one-time data migration task. It might not be as straightforward as using AWS Snowcone for this specific scenario.","poster":"meowruki","timestamp":"1701347520.0","upvote_count":"2","comment_id":"1084344"},{"content":"Selected Answer: A\nboth DataSync and Storage Gateway are fine to sync data...but to \"audit access at all levels of the stored data\" ...it should be data events(data plane operation)..management event is some account level things.\nSo answer should be A","timestamp":"1700714760.0","poster":"chikuwan","comment_id":"1078067","upvote_count":"3"},{"content":"Selected Answer: D\nWhile both DataSync and Storage Gateway allow syncing of data between on-premise and cloud, DataSync is built for rapid shifting of data into a cloud environment, not specifically for continued use in on-premise servers.","poster":"bogobob","upvote_count":"2","comment_id":"1072968","timestamp":"1700187000.0"},{"content":"Selected Answer: A\nAWS DataSync is an online data transfer service that simplifies, automates, and accelerates the process of copying large amounts of data to and from AWS storage services over the Internet or over AWS Direct Connect.","comment_id":"1063106","upvote_count":"2","comments":[{"content":"This is where AWS CloudTrail comes into play.","upvote_count":"1","poster":"JA2018","comment_id":"1316314","timestamp":"1732280520.0"}],"timestamp":"1699201140.0","poster":"potomac"},{"poster":"canonlycontainletters1","upvote_count":"2","timestamp":"1698279420.0","comment_id":"1054172","content":"Selected Answer: A\nA seems to be more convincing to me."},{"content":"Selected Answer: A\ntabbyDolly 1 month ago is right. Also Data Sync is designed for data changes.","comment_id":"1048237","poster":"Wayne23Fang","upvote_count":"3","timestamp":"1697746200.0"},{"content":"Selected Answer: D\nThe company hosts applications on on-premises infrastructure, so they should use a Storage Gateway solution.","poster":"brian202308","upvote_count":"2","timestamp":"1697674080.0","comments":[],"comment_id":"1047370"},{"comments":[],"upvote_count":"3","content":"Selected Answer: D\nNeeds access to all data hence I have put D. if it said migrating to AWS and then an audit or something then I would of chosen datasync","poster":"Ramdi1","comment_id":"1024850","timestamp":"1696427340.0"},{"poster":"bsbs1234","comment_id":"1020920","timestamp":"1696003140.0","upvote_count":"2","content":"A,\nB) snowcone will interrupt app, or need additional step to copy data generate during transfer\nC,D) are not for migrate data\n\nAnd cloudTrail can log data plane events"},{"comment_id":"1016892","poster":"Ramdi1","content":"Selected Answer: A\nA - The way I look at this after some other questions a helpful comment was migrate use Data Sync if you need to still retain on site and move to cloud then storage/volume gateways.","upvote_count":"2","timestamp":"1695652380.0"},{"comment_id":"1011591","upvote_count":"2","content":"The answer is storage gateway as per cloudguru. Data synch is for one time migration for continuous synch storage gateway","poster":"michalf84","timestamp":"1695145560.0"},{"poster":"tabbyDolly","upvote_count":"2","comment_id":"1010864","timestamp":"1695071280.0","content":"A\naudit access at all levels of the stored data -> data event is more suitable than management event\nhttps://repost.aws/knowledge-center/cloudtrail-data-management-events"},{"poster":"ssa03","content":"Selected Answer: D\n1- The application’s data frequently changes, so we need to keep the data updated on AWS\n2- Running out of storage capacity, we need a new storage capacity on-premise","upvote_count":"4","comment_id":"996416","timestamp":"1693603440.0","comments":[{"comment_id":"1110492","content":"No, they want to MIGRATE the data to AWS. D does not meet the logging requirement.","timestamp":"1704022440.0","upvote_count":"2","poster":"pentium75"}]},{"content":"Selected Answer: D\nAWS Storage Gateway allows secure migration of on-premises data to S3 while integrating with existing infrastructure. Storage Gateway can be configured in gateway-cached mode to provide low-latency access to frequently changed data.\n\nEnabling AWS CloudTrail logging of management events will capture the required audit data for all API actions taken on the S3 bucket and objects.","poster":"Guru4Cloud","comments":[],"comment_id":"990305","upvote_count":"2","timestamp":"1692987180.0"},{"poster":"TariqKipkemei","upvote_count":"3","comment_id":"917771","content":"Selected Answer: A\nFor a scenario where they want to maintain some/all of the data on prem then AWS Storage Gateway would be the option to offer hybrid cloud storage.\nIn this case they want to migrate all the data to the cloud so AWS Datasync is the best option.","timestamp":"1686196080.0"},{"timestamp":"1685842680.0","content":"Selected Answer: A\nDatasync, this way we can monitor and audit all of the data at all times. \nWith Snowcone / Snowball we lose access to audit the data while it arrives into AWS Data centers / Region / Availability Zone.","comment_id":"914037","comments":[{"upvote_count":"2","comment_id":"914039","content":"AWS DataSync is a data transfer service that simplifies and accelerates moving large amounts of data to and from AWS. It is designed to securely and efficiently migrate data from on-premises storage systems to AWS services like Amazon S3.\n\nIn this scenario, the company needs to securely migrate its healthcare application data to AWS while satisfying the new regulation for audit access. By using AWS DataSync, the existing data can be securely transferred to Amazon S3, ensuring the data is stored in a scalable and durable storage service.\n\nAdditionally, using AWS CloudTrail to log data events ensures that all access and activity related to the data stored in Amazon S3 is audited. This helps meet the regulatory requirement for audit access at all levels of the stored data.","timestamp":"1685842800.0","poster":"alexandercamachop"}],"upvote_count":"2","poster":"alexandercamachop"},{"upvote_count":"2","content":"DataSync can be used to backup data from one AWS storage service into another. Services such as Amazon S3 already has built-in tools for automatic data replication from one bucket to another. However, the replication only occurs for new data added to the bucket after the replication setting was turned on. So, is it possible to use datasync from onpremisse to aws ?","timestamp":"1685804100.0","poster":"Felix_br","comment_id":"913710"},{"poster":"omoakin","comment_id":"909677","comments":[{"timestamp":"1685390040.0","comments":[{"upvote_count":"1","comment_id":"909679","content":"Sorry i meant D","timestamp":"1685390040.0","poster":"omoakin"}],"content":"BBBBBBBBBBBBBB","upvote_count":"1","poster":"omoakin","comment_id":"909678"}],"content":"Use AWS Storage Gateway to move the existing data to Amazon S3. Use AWS CloudTrail to log management events.","upvote_count":"1","timestamp":"1685389980.0"},{"upvote_count":"2","content":"A. Datasync = keyword = migrate/move","timestamp":"1684642860.0","poster":"kanekichan","comment_id":"902877"},{"timestamp":"1684590480.0","comment_id":"902603","poster":"EA100","content":"A. Use AWS DataSync to move the existing data to Amazon S3. Use AWS CloudTrail to log data events.\n\nAWS DataSync is a service designed specifically for securely and efficiently transferring large amounts of data between on-premises storage systems and AWS services like Amazon S3. It provides a reliable and optimized way to migrate data while maintaining data integrity.\n\nAWS CloudTrail, on the other hand, is a service that logs and monitors management events in your AWS account. While it can capture data events for certain services, its primary focus is on tracking management actions like API calls and configuration changes.\n\nTherefore, using AWS DataSync to transfer the existing data to Amazon S3 and leveraging AWS CloudTrail to log data events aligns with the requirement of securely migrating the data and ensuring audit access at all levels, as specified by the new regulation.","upvote_count":"2"},{"timestamp":"1684547640.0","poster":"hiroohiroo","comment_id":"902316","upvote_count":"2","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/ja_jp/datasync/latest/userguide/encryption-in-transit.html"},{"timestamp":"1684406820.0","content":"A\nAWS DataSync is a data transfer service that simplifies and accelerates moving large amounts of data between on-premises storage systems and Amazon S3. It provides secure and efficient data transfer while ensuring data integrity during the migration process.\n\nBy using AWS DataSync, you can securely transfer the data from the on-premises infrastructure to Amazon S3, meeting the requirement for securely migrating the data. Additionally, AWS CloudTrail can be used to log data events, allowing audit access at all levels of the stored data.","comment_id":"901082","upvote_count":"2","poster":"cloudenthusiast"},{"timestamp":"1684196040.0","content":"Selected Answer: A\nOne time synch, its Data Sync. Dont bother for greyrose answers, they are usually wrong","poster":"Efren","comment_id":"898783","upvote_count":"3"},{"upvote_count":"2","poster":"nosense","timestamp":"1684152060.0","content":"Selected Answer: A\nEasy transfer data to s3 + encrypted","comment_id":"898246"},{"content":"Selected Answer: D\nDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD","comment_id":"898211","upvote_count":"3","timestamp":"1684149480.0","poster":"greyrose"}],"topic":"1","answers_community":["A (69%)","D (31%)"],"question_images":[]},{"id":"Qr6ew27UTi9q1WoToCaA","isMC":true,"choices":{"A":"Deploy the application in AWS Lambda. Configure an Amazon API Gateway API to connect with the Lambda functions.","D":"Launch an Amazon EC2 instance. Install a MySQL server on the EC2 instance. Configure the application on the server. Create an AMI. Use the AMI to create a launch template with an Auto Scaling group.","C":"Migrate the database to Amazon ElastiCache. Configure the ElastiCache security group to allow access from the application.","B":"Deploy the application by using AWS Elastic Beanstalk. Configure a load-balanced environment and a rolling deployment policy."},"url":"https://www.examtopics.com/discussions/amazon/view/109279-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","exam_id":31,"question_images":[],"answer_ET":"B","question_text":"A solutions architect is implementing a complex Java application with a MySQL database. The Java application must be deployed on Apache Tomcat and must be highly available.\n\nWhat should the solutions architect do to meet these requirements?","discussion":[{"poster":"cloudenthusiast","comment_id":"901084","content":"B\nAWS Elastic Beanstalk provides an easy and quick way to deploy, manage, and scale applications. It supports a variety of platforms, including Java and Apache Tomcat. By using Elastic Beanstalk, the solutions architect can upload the Java application and configure the environment to run Apache Tomcat.","timestamp":"1684406880.0","upvote_count":"11"},{"upvote_count":"2","poster":"KennethNg923","timestamp":"1718515140.0","comment_id":"1231209","content":"Selected Answer: B\nBeanstalk for sure"},{"poster":"zinabu","timestamp":"1713327840.0","content":"By using Elastic Beanstalk, the solutions architect can upload the Java application and configure the environment to run Apache Tomcat.","upvote_count":"3","comment_id":"1196979"},{"poster":"wizcloudifa","upvote_count":"3","comment_id":"1196562","timestamp":"1713268980.0","content":"Selected Answer: B\nThe key word here from the question if you notice is \"The Java application must be DEPLOYED...\" hence Elastic Beanstalk, it is a serverless deployment service and supports a variety of platforms(apache Tomcat in our situation), and it will scale automatically with less operational overhead(unlike option D with a lot of operation overhead)"},{"comment_id":"1126271","poster":"awsgeek75","content":"Selected Answer: B\nhttps://aws.amazon.com/elasticbeanstalk/details/","timestamp":"1705618080.0","upvote_count":"2"},{"comment_id":"990298","content":"Selected Answer: B\nB. Deploy the application by using AWS Elastic Beanstalk. Configure a load-balanced environment and a rolling deployment policy.","upvote_count":"4","timestamp":"1692986580.0","poster":"Guru4Cloud"},{"upvote_count":"3","content":"Selected Answer: B\nKeyword \"AWS Elastic Beanstalk\" for re-architecture from Java web-app inside Apache Tomcat to AWS Cloud.","comment_id":"958414","timestamp":"1689940020.0","poster":"james2033"},{"timestamp":"1686196200.0","comment_id":"917773","poster":"TariqKipkemei","upvote_count":"2","content":"Selected Answer: B\nDefinitely B"},{"timestamp":"1685451480.0","upvote_count":"2","poster":"antropaws","comment_id":"910250","content":"Selected Answer: B\nClearly B."},{"poster":"nosense","upvote_count":"3","timestamp":"1684152360.0","comment_id":"898251","content":"Selected Answer: B\nEasy deploy, management and scale"},{"poster":"greyrose","comment_id":"898213","content":"Selected Answer: B\nBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB","upvote_count":"1","timestamp":"1684149540.0"}],"timestamp":"2023-05-15 13:19:00","answer":"B","question_id":385,"answer_images":[],"answers_community":["B (100%)"],"answer_description":"","unix_timestamp":1684149540}],"exam":{"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Associate SAA-C03","id":31,"isImplemented":true,"numberOfQuestions":1019,"provider":"Amazon","isMCOnly":true,"isBeta":false},"currentPage":77},"__N_SSP":true}