{"pageProps":{"questions":[{"id":"Eo6AhWX16kmYzUz0ECx9","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/76152-exam-aws-certified-sysops-administrator-associate-topic-1/","answer_images":[],"answer_ET":"A","isMC":true,"exam_id":34,"answers_community":["A (81%)","Other"],"discussion":[{"timestamp":"1668383400.0","upvote_count":"20","content":"Selected Answer: A\nThe vendor is required to host the S3 bucket. It holds the company's data.\nThe vendor wants to use a company-provided key to encrypt the data.\nSo the company needs to create the new key and then provide access to that key from the IAM role which was provided by the vendor. (Answer: A)\n\nD - Can't be D as that would mean the company is hosting the data (not the vendor). D is hosting the data at the company and providing access to the data to the vendor.","comment_id":"717584","poster":"fedorian"},{"content":"Correct Answer: A\nOption A is correct because it specifies creating a new KMS key and explicitly adding the vendor's IAM role ARN to the key policy. This approach allows the vendor to use the KMS key for encryption while ensuring access control and security through the key policy. By providing the KMS key ARN to the vendor, they can use it to encrypt the data in the S3 bucket hosted in their account.\n\nOther Options:\n\nOption B creates an unnecessary IAM user and an inline policy, adding complexity without directly addressing KMS encryption needs.\nOption C suggests using the KMS-managed S3 key, which is controlled by AWS and does not provide the flexibility of adding external roles to the key policy.\nOption D configures encryption using the KMS-managed S3 key but adds the vendor's role to the S3 bucket policy rather than the KMS key policy, which would not grant the needed access to use the key for encryption.","upvote_count":"1","poster":"gehadg","comment_id":"1304602","timestamp":"1730221140.0"},{"poster":"Andrew_A","timestamp":"1686753480.0","upvote_count":"2","content":"Selected Answer: A\nBy creating a new KMS key, the SysOps administrator is ensuring that the key used to encrypt the company's data is distinct and managed separately.\n\nThe key policy is the primary resource-based policy that controls who can access and manage the key. By adding the vendor's IAM role ARN to the KMS key policy, the SysOps administrator is giving the vendor permissions to use the key, while keeping the control of the key.\n\nBy providing the ARN of the new KMS key to the vendor, the vendor will be able to use that key to encrypt the company's data stored in the S3 bucket in the vendor's account.","comment_id":"923304"},{"poster":"fts_cevans","comment_id":"911202","content":"Selected Answer: A\nThe provided answer links to an outside practice question - But if you go to that link **THE QUESTION** is different. It's as if ExamTopics has the wrong answer assigned to this question or they've pasted the wrong question into it.\n\nAs the question is written now, it's DEFINITELY *NOT* D. As others said - The S3 bucket needs to be in the vendor's account - So you would obviously not create one in YOUR account for this use.","upvote_count":"2","timestamp":"1685534100.0"},{"content":"Selected Answer: A\nYou need to create a new KMS from the question","upvote_count":"2","timestamp":"1681280820.0","poster":"englishborn","comment_id":"867978"},{"poster":"caputmundi666","comment_id":"856955","content":"Selected Answer: A\nkms is in company's account. S3 is in vendor's account. Company must allow encrypt/decrypt vendor's IAM role in the KMS policy. Company should share KMS ARN of KMS.\nManaged S3 KMS cannot be shared, you cannot edit its policy","upvote_count":"3","timestamp":"1680261000.0"},{"timestamp":"1678969560.0","poster":"michele_scar","comment_id":"840945","content":"Selected Answer: A\nThe vendor has to host the S3, not your own company","upvote_count":"2"},{"poster":"braveheart22","timestamp":"1677344760.0","content":"A is the right option from my point of view","upvote_count":"2","comment_id":"821683"},{"poster":"Pacoca","content":"I agree with Fedorian\nSo the company needs to create the new key and then provide access to that key from the IAM role which was provided by the vendor","comment_id":"814016","upvote_count":"1","timestamp":"1676806680.0"},{"poster":"noahsark","comment_id":"786272","content":"Selected Answer: A\nhttps://www.filecloud.com/supportdocs/fcdoc/latest/server/filecloud-administrator-guide/filecloud-site-setup/storage-settings/filecloud-managed-storage/s3-storage-encryption-with-aws-cross-account-kms-key","timestamp":"1674546060.0","upvote_count":"1"},{"poster":"BietTuot","content":"Selected Answer: A\nI vote for A. \nC. INCORRECT: You can't modify KMS managed S3 key policy.\nD. INCORRECT: Because the bucket is in the vendor's account not in the company's account. Moreover, bucket policy doesn't allow Role encrypt/decrypt data. You need to use KMS Key policy.","comment_id":"746104","upvote_count":"3","timestamp":"1671110220.0"},{"poster":"MrMLB","content":"Selected Answer: A\nA. Create a new KMS key. Add the vendor's IAM role ARN to the KMS key policy. Provide the new KMS key ARN to the vendor.","comment_id":"745509","timestamp":"1671057420.0","upvote_count":"2"},{"timestamp":"1670990640.0","content":"Selected Answer: A\nVote for A","comment_id":"744696","poster":"tyfta6","upvote_count":"1"},{"timestamp":"1670572800.0","upvote_count":"2","content":"Selected Answer: A\nGoing for A","comment_id":"739905","poster":"michaldavid"},{"comment_id":"720835","poster":"Liongeek","upvote_count":"1","content":"Ans: A","timestamp":"1668716580.0"},{"upvote_count":"3","poster":"[Removed]","comment_id":"706509","content":"Selected Answer: A\nIt's A guys.","comments":[{"poster":"zhangyu20000","comment_id":"713345","content":"question clearly ask to use KMS","upvote_count":"1","timestamp":"1667860980.0"}],"timestamp":"1666965240.0"},{"content":"Bucket is in vendor's account, encrypted using company's key. So the vendor will require permission to use key to access data.","timestamp":"1666882620.0","poster":"Surferbolt","upvote_count":"2","comment_id":"705672"},{"content":"Selected Answer: A\nThe explanation alludes to A","comment_id":"686455","poster":"Kinetix","timestamp":"1664921280.0","upvote_count":"3"},{"upvote_count":"1","timestamp":"1664661060.0","poster":"bakjeeone","comment_id":"684498","content":"Selected Answer: D\nAnswer is D"},{"comment_id":"677817","timestamp":"1664022840.0","content":"Selected Answer: A\nI would choose A","poster":"azure_kai","upvote_count":"1"},{"upvote_count":"1","poster":"softarts","content":"C=> can't modify KMS managed S3 key policy\nD=> not mention about the Role encrypt/decrypt data(bucket policy can't do that)\nI choose A","comment_id":"648436","timestamp":"1660828260.0"},{"content":"Selected Answer: D\nThe answer is D => \"S3 Bucket Policy\"","timestamp":"1657410300.0","poster":"Goozian","comment_id":"629377","upvote_count":"3"},{"upvote_count":"1","poster":"221898","content":"Selected Answer: C\nNote that KMS policies cant be edited after creation, as its read-only.","comment_id":"621488","timestamp":"1656055260.0"},{"upvote_count":"3","poster":"CodePoet","timestamp":"1653361740.0","comment_id":"606454","content":"Selected Answer: D\nThe answer is D"},{"timestamp":"1653349800.0","content":"Selected Answer: C\nC - https://aws.amazon.com/premiumsupport/knowledge-center/cross-account-access-denied-error-s3/\n\nNote that KMS policies cant be edited after creation, as its read-only.","upvote_count":"1","comments":[{"content":"in the link you shared, it clearly mentions \"Bucket Policy\" but you chose C ?! \nAnswer is D","comment_id":"629376","upvote_count":"2","timestamp":"1657410240.0","poster":"Goozian"}],"comment_id":"606365","poster":"Finger41"},{"poster":"Mikilo","content":"Selected Answer: C\nGoing with C","timestamp":"1653294240.0","upvote_count":"2","comment_id":"605919"}],"question_id":446,"choices":{"A":"Create a new KMS key. Add the vendor's IAM role ARN to the KMS key policy. Provide the new KMS key ARN to the vendor.","B":"Create a new KMS key. Create a new IAM key. Add the vendor's IAM role ARN to an inline policy that is attached to the IAM user. Provide the new IAM user ARN to the vendor.","C":"Configure encryption using the KMS managed S3 key. Add the vendor's IAM role ARN to the KMS key policy. Provide the KMS managed S3 key ARN to the vendor.","D":"Configure encryption using the KMS managed S3 key. Create an S3 bucket. Add the vendor's IAM role ARN to the S3 bucket policy. Provide the S3 bucket ARN to the vendor."},"question_images":[],"answer":"A","timestamp":"2022-05-23 10:24:00","unix_timestamp":1653294240,"topic":"1","question_text":"A company is partnering with an external vendor to provide data processing services. For this integration, the vendor must host the company's data in an Amazon\nS3 bucket in the vendor's AWS account. The vendor is allowing the company to provide an AWS Key Management Service (AWS KMS) key to encrypt the company's data. The vendor has provided an IAM role Amazon Resources Name (ARN) to the company for this integration.\nWhat should a SysOps administrator do to configure this integration?"},{"id":"HkrYXBgiSDQYCVHPCAKt","question_id":447,"isMC":true,"discussion":[{"comment_id":"656829","timestamp":"1725242220.0","upvote_count":"14","poster":"princajen","content":"Selected Answer: B\nBy default, AWS Systems Manager doesn't have permission to perform actions on your instances. Grant access by using an AWS Identity and Access Management (IAM) instance profile. An instance profile is a container that passes IAM role information to an Amazon Elastic Compute Cloud (Amazon EC2) instance at launch. You can create an instance profile for Systems Manager by attaching one or more IAM policies that define the necessary permissions to a new role or to a role you already created.\n\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/setup-instance-profile.html"},{"content":"Selected Answer: B\nbbbbbbbbb","comment_id":"739916","timestamp":"1733732460.0","poster":"michaldavid","upvote_count":"1"},{"content":"Ans: B","comment_id":"720841","poster":"Liongeek","upvote_count":"1","timestamp":"1731875400.0"}],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/79230-exam-aws-certified-sysops-administrator-associate-topic-1/","answers_community":["B (100%)"],"exam_id":34,"unix_timestamp":1662083820,"answer_ET":"B","answer_description":"","answer":"B","timestamp":"2022-09-02 03:57:00","answer_images":[],"choices":{"B":"Attach an IAM instance profile with access to Systems Manager to the instances.","A":"Add an inbound rule to the instances' security group.","D":"Manually specify the instances to patch instead of using tag-based selection.","C":"Create a Systems Manager activation. Then activate the fleet of instances."},"question_text":"A SysOps administrator is using AWS Systems Manager Patch Manager to patch a fleet of Amazon EC2 instances. The SysOps administrator has configured a patch baseline and a maintenance window. The SysOps administrator also has used an instance tag to identify which instances to patch.\nThe SysOps administrator must give Systems Manager the ability to access the EC2 instances.\nWhich additional action must the SysOps administrator perform to meet this requirement?","question_images":[]},{"id":"2PZZwnETssU3iXRaJffV","answer_description":"","choices":{"C":"Create a VPN connection between the two Regions. Add the private IP address range of the instances to the outbound rule of the database security group.","D":"Create a VPN connection between the two Regions. Add the security group of the instances in eu-central-1 to the inbound rule of the database security group.","A":"Create a VPC peering connection between the two Regions. Add the private IP address range of the instances to the inbound rule of the database security group.","B":"Create a VPC peering connection between the two Regions. Add the security group of the instances in eu-central-1 to the outbound rule of the database security group."},"question_images":[],"exam_id":34,"discussion":[{"comment_id":"656832","content":"Selected Answer: A\nCorrect answer is A!\nVPN options are out of the question.\nWe are left with add the IP address or a security group rule, but since you cannont create a security group rule that references a peer VPC security group, than the answer is clearly A.","poster":"princajen","timestamp":"1693620120.0","comments":[{"timestamp":"1698441660.0","comments":[{"poster":"pablo23449","timestamp":"1698713220.0","comments":[{"poster":"caputmundi666","timestamp":"1711883760.0","comment_id":"856959","upvote_count":"3","content":"VPC and SG are regional resources: they can't inter-operate if spread on multiple regions. So, answer is A also for this reason"},{"upvote_count":"1","timestamp":"1708258680.0","content":"you can't peer a VPN, only VPC.","poster":"Phinx","comment_id":"812934"}],"upvote_count":"4","comment_id":"708103","content":"yes, you can use SGs from peering VPNs but since it says to use in outbound the choice is A."}],"upvote_count":"1","poster":"rod1234","content":"https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-security-groups.html","comment_id":"705935"}],"upvote_count":"8"},{"upvote_count":"5","content":"A is correct. \nB is wrong for 2 reasons:\na) You cannot reference the security group of a peer VPC that's in a different Region. Instead, use the CIDR block of the peer VPC. \nb) its refers to outbound rule of database not the inbound rule.\nhttps://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-security-groups.html","poster":"student2020","timestamp":"1705441740.0","comment_id":"778317"},{"comment_id":"1087244","timestamp":"1733273820.0","upvote_count":"2","content":"Selected Answer: A\nVPC Peering and adding to inbound is key word","poster":"Mangesh_XI_mumbai"},{"timestamp":"1732786080.0","upvote_count":"2","poster":"Hatem08","comment_id":"1082341","content":"Selected Answer: A\nA -> initiate connection inbound"},{"upvote_count":"2","content":"Selected Answer: A\nThis line has the answer: but the database must remain only in us-east-1. Hence us-east-1 region vpc SG need to allow the connection.","poster":"callspace","timestamp":"1727860560.0","comment_id":"1022955"},{"timestamp":"1723383120.0","comment_id":"978659","poster":"jipark","upvote_count":"4","content":"Selected Answer: A\nwhy not B : security groups are typically associated within the same VPC\nwhy A : across different Regions, VPC peering is the preferred"},{"timestamp":"1711467360.0","content":"A is the correct answer.\nB is totally wrong because adding the security group of the instances in eu-central-1 to the outbound rule of the database security group is logically adding the security group of The instances to outbound rule of database sg. Adding an INBOUND RULE to OUTBOUND RULE(outgoing traffic of the database) cannot be used to establish a VPC peering connection.","upvote_count":"1","poster":"braveheart22","comment_id":"851088"},{"timestamp":"1702699980.0","upvote_count":"2","comment_id":"746792","poster":"MrMLB","content":"Selected Answer: B\nBy creating a VPC peering connection between the two Regions and adding the security group of the instances in eu-central-1 to the outbound rule of the database security group, you can establish a direct network connection between the two VPCs and allow the instances in eu-central-1 to communicate with the database in us-east-1. This is the most operationally efficient solution because it allows for faster and more efficient communication between the two VPCs"},{"poster":"michaldavid","comment_id":"739917","content":"Selected Answer: A\naaaaaaaaa","timestamp":"1702110120.0","upvote_count":"3"},{"content":"Ans: A","comment_id":"720843","poster":"Liongeek","upvote_count":"1","timestamp":"1700253060.0"}],"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/79232-exam-aws-certified-sysops-administrator-associate-topic-1/","isMC":true,"topic":"1","question_text":"A company hosts its website on Amazon EC2 instances in the us-east-1 Region. The company is preparing to extend its website into the eu-central-1 Region, but the database must remain only in us-east-1. After deployment, the EC2 instances in eu-central-1 are unable to connect to the database in us-east-1.\nWhat is the MOST operationally efficient solution that will resolve this connectivity issue?","answers_community":["A (91%)","9%"],"timestamp":"2022-09-02 04:02:00","answer_images":[],"unix_timestamp":1662084120,"question_id":448,"answer":"A"},{"id":"V7znA2akxccIhNbMjHKH","isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/78523-exam-aws-certified-sysops-administrator-associate-topic-1/","exam_id":34,"answers_community":["A (100%)"],"question_images":[],"unix_timestamp":1661898300,"answer":"A","question_id":449,"answer_description":"","answer_images":[],"timestamp":"2022-08-31 00:25:00","discussion":[{"comment_id":"978672","timestamp":"1723383840.0","comments":[{"content":"A is correct, related to SCPs and configuring them are not taught in SOA exam only theory is covered.","upvote_count":"1","comment_id":"1087247","poster":"Mangesh_XI_mumbai","timestamp":"1733274000.0"}],"poster":"jipark","content":"Selected Answer: A\nwhy A : AWS Config Rule: AWS Config rule that checks for security groups\n\nwhy not D : SCPs are more suited for controlling access to AWS services and actions, not for specific security group configuration checks","upvote_count":"7"},{"poster":"Nrn143","content":"A is the correct answer","timestamp":"1717256460.0","upvote_count":"1","comment_id":"912233"},{"timestamp":"1709725740.0","comment_id":"830761","poster":"gcmrjbr","upvote_count":"2","content":"A. https://docs.aws.amazon.com/config/latest/developerguide/vpc-sg-open-only-to-authorized-ports.html"},{"timestamp":"1702110240.0","poster":"michaldavid","content":"Selected Answer: A\naaaaaa","comment_id":"739919","upvote_count":"3"},{"poster":"Liongeek","content":"Ans: A","comment_id":"720844","timestamp":"1700253120.0","upvote_count":"2"},{"upvote_count":"3","comment_id":"695481","content":"Selected Answer: A\nA. It's a job for Config.","timestamp":"1697381040.0","poster":"Surferbolt"},{"comment_id":"654473","content":"Selected Answer: A\nA. Create an AWS Config rule to detect noncompliant security groups. Set up automatic remediation to change the 0.0.0.0/0 source address to the approved CIDR block?","upvote_count":"2","poster":"Rick365","timestamp":"1693434300.0"}],"choices":{"C":"Create an AWS Lambda function to inspect new and existing security groups. Check for a noncompliant 0.0.0.0/0 source address and change the source address to the approved CIDR block.","B":"Create an IAM policy to deny the creation of security groups that have 0.0.0.0/0 as the source address. Attach this IAM policy to every user in the company.","A":"Create an AWS Config rule to detect noncompliant security groups. Set up automatic remediation to change the 0.0.0.0/0 source address to the approved CIDR block.","D":"Create a service control policy (SCP) for the organizational unit (OU) to deny the creation of security groups that have the 0.0.0.0/0 source address. Set up automatic remediation to change the 0.0.0.0/0 source address to the approved CIDR block."},"answer_ET":"A","question_text":"A company wants to create an automated solution for all accounts managed by AWS Organizations to detect any security groups that use 0.0.0.0/0 as the source address for inbound traffic. The company also wants to automatically remediate any noncompliant security groups by restricting access to a specific CIDR block that corresponds with the company's intranet.\nWhich set of actions should the SysOps administrator take to create a solution?"},{"id":"MPn7Vts5H9XAzHT05V66","url":"https://www.examtopics.com/discussions/amazon/view/78878-exam-aws-certified-sysops-administrator-associate-topic-1/","discussion":[{"content":"Selected Answer: A\nOption B is incorrect because AWS CloudTrail Processing Library helps developers to read, process, and analyze AWS CloudTrail data but doesn't provide the functionality to validate the integrity of CloudTrail log files.","comment_id":"923564","timestamp":"1686775140.0","poster":"Andrew_A","upvote_count":"6"},{"timestamp":"1730771880.0","comment_id":"1307168","poster":"XXXXXlNN","content":"Why no one select D?","upvote_count":"1"},{"poster":"pekalyok","content":"Selected Answer: D\nWhile the other options have their uses, they don't directly meet the requirement as effectively as option D:\n\nA and B (Log File Integrity Validation): Enabling log file integrity validation is important for ensuring that the logs have not been tampered with. However, this feature is more about post-event validation rather than real-time monitoring or alerting. It requires manual initiation (using the AWS CLI or CloudTrail Processing Library) to validate the integrity of log files, which does not provide immediate notifications of modifications or deletions.\n\nC (CloudTrail Insights): CloudTrail Insights is designed to identify unusual operational activity within your AWS account, not specifically to monitor log file integrity or alert on log file modifications or deletions. It is more focused on detecting anomalous API activity rather than changes to the log files themselves.","timestamp":"1712187420.0","comment_id":"1188975","upvote_count":"1"},{"upvote_count":"2","poster":"McEgowan2023","timestamp":"1699758060.0","comment_id":"1068275","content":"To determine whether a log file was modified, deleted, or unchanged after CloudTrail delivered it, you can use CloudTrail log file integrity validation. This feature is built using industry standard algorithms: SHA-256 for hashing and SHA-256 with RSA for digital signing. This makes it computationally infeasible to modify, delete or forge CloudTrail log files without detection. You can use the AWS CLI to validate the files in the location where CloudTrail delivered them.\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-intro.html"},{"poster":"Christina666","upvote_count":"2","timestamp":"1690671600.0","comment_id":"966692","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-cli.html\n\nTo validate logs with the AWS Command Line Interface, use the CloudTrail validate-logs command. The command uses the digest files delivered to your Amazon S3 bucket to perform the validation. For information about digest files, see CloudTrail digest file structure.\n\nThe AWS CLI allows you to detect the following types of changes:\n\nModification or deletion of CloudTrail log files\n\nModification or deletion of CloudTrail digest files\n\nModification or deletion of both of the above"},{"upvote_count":"2","timestamp":"1679838780.0","poster":"braveheart22","content":"AAAA is the correct answer.\nTo determine whether a log file was modified, deleted, or unchanged after CloudTrail delivered it, you can use CloudTrail log file integrity validation. This feature is built using industry standard algorithms: SHA-256 for hashing and SHA-256 with RSA for digital signing. This makes it computationally infeasible to modify, delete or forge CloudTrail log files without detection. You can use the AWS CLI to validate the files in the location where CloudTrail delivered them.\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-intro.html","comment_id":"851106"},{"poster":"braveheart22","content":"I agree with foreverlearner, the correct answer is AAAAA.","timestamp":"1677359280.0","upvote_count":"1","comment_id":"821833"},{"poster":"zolthar_z","upvote_count":"3","timestamp":"1671462000.0","content":"Selected Answer: A\nThe answer is A, the cloud trail processing library is only to process logs, not check integrity","comment_id":"749944"},{"upvote_count":"1","content":"Selected Answer: B\nB\n\nOption A is incorrect because it does not specify how to validate the log files. Option C is incorrect because CloudTrail Insights is a feature that allows you to analyze CloudTrail log data, but it does not provide a way to validate log file integrity. Option D is incorrect because Amazon CloudWatch Logs is a service that allows you to monitor, store, and access your log data, but it does not provide a way to validate log file integrity.","timestamp":"1671164280.0","poster":"MrMLB","comment_id":"746795","comments":[{"timestamp":"1671640620.0","upvote_count":"6","poster":"foreverlearner","content":"Another wrong ChatGPT answer.. \"To validate the integrity of CloudTrail log files, you can use the AWS CLI or create your own solution\" (https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-intro.html )","comment_id":"752571"}]},{"comment_id":"739920","content":"Selected Answer: A\naaaaaa","poster":"michaldavid","upvote_count":"2","timestamp":"1670574300.0"},{"content":"A is the answer.","upvote_count":"2","poster":"Surferbolt","timestamp":"1665845100.0","comment_id":"695482"},{"comment_id":"663095","content":"Selected Answer: A\nYes it is A","upvote_count":"3","timestamp":"1662611340.0","poster":"AAAaat"},{"poster":"haxaffee","upvote_count":"3","content":"Selected Answer: A\nAnswer can only be A. How to use CLI -> https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-cli.html","comment_id":"659142","timestamp":"1662283560.0"},{"poster":"princajen","comments":[{"timestamp":"1671276060.0","content":"princajen, your response describes answer B.","upvote_count":"1","poster":"[Removed]","comment_id":"748010"}],"upvote_count":"3","timestamp":"1662084540.0","content":"Selected Answer: A\nThe answer is A! \nThe CloudTrail Processing Library is a Java library that provides an easy way to process AWS CloudTrail logs. You provide configuration details about your CloudTrail SQS queue and write code to process events. The CloudTrail Processing Library does the rest. It polls your Amazon SQS queue, reads and parses queue messages, downloads CloudTrail log files, parses events in the log files, and passes the events to your code as Java objects.\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/use-the-cloudtrail-processing-library.html","comment_id":"656840"},{"poster":"Flosuccess","content":"Looks like the answer is A \nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-intro.html","comment_id":"655706","timestamp":"1662000600.0","upvote_count":"2"}],"isMC":true,"answer_description":"","timestamp":"2022-09-01 04:50:00","answer":"A","topic":"1","choices":{"C":"Use CloudTrail Insights to monitor the log files for modifications.","A":"Enable log file integrity validation. Use the AWS CLI to validate the log files.","D":"Use Amazon CloudWatch Logs to monitor the log files for modifications.","B":"Enable log file integrity validation. Use the AWS CloudTrail Processing Library to validate the log files."},"question_text":"A company requires that all activity in its AWS account be logged using AWS CloudTrail. Additionally, a SysOps administrator must know when CloudTrail log files are modified or deleted.\nHow should the SysOps administrator meet these requirements?","question_id":450,"unix_timestamp":1662000600,"question_images":[],"answer_ET":"A","exam_id":34,"answers_community":["A (92%)","4%"],"answer_images":[]}],"exam":{"lastUpdated":"11 Apr 2025","id":34,"numberOfQuestions":477,"isMCOnly":false,"isBeta":false,"isImplemented":true,"provider":"Amazon","name":"AWS Certified SysOps Administrator - Associate"},"currentPage":90},"__N_SSP":true}