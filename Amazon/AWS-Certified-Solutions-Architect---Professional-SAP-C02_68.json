{"pageProps":{"questions":[{"id":"vMxfbijbqroi9EOeA6Zw","discussion":[{"comment_id":"1081185","content":"Selected Answer: BE\nB and E is the answer. Was really torn about option D....\n\nD involves hosting Lambda functions outside the VPC and creating a VPC endpoint for the Neptune database. The key issue here is that while AWS supports VPC endpoints for several services, as of my last update in April 2023, Amazon Neptune does not support VPC endpoints. Without VPC endpoint support for Neptune, Lambda functions outside the VPC cannot access the Neptune DB cluster in this way.\n\nSo it must be B and E !","poster":"heatblur","timestamp":"1701057060.0","upvote_count":"11"},{"upvote_count":"6","poster":"Dgix","comment_id":"1178522","content":"Selected Answer: BE\nThe only thing to remember with this question is that the two alternatives are SEPARATE. They are complete on their own and are not in conjunction.","timestamp":"1710953700.0"},{"content":"For B: \nWhy do we need to route internet traffic through a NAT gateway??","upvote_count":"2","comment_id":"1297875","timestamp":"1728951360.0","poster":"AloraCloud","comments":[{"poster":"alexbraila","timestamp":"1733346420.0","content":"To access DynamoDB over public internet","comment_id":"1322089","upvote_count":"2"}]},{"timestamp":"1710911340.0","comment_id":"1177932","poster":"djangoUnchained","upvote_count":"1","content":"Selected Answer: AE\nFor B how will the Lambda access DynamoDB from a Private subnet and without an IGW? Should be A."},{"comment_id":"1177835","upvote_count":"3","poster":"pangchn","content":"Selected Answer: BE\ntill March 2024 \n\"its endpoints are only accessible within that VPC\"\nhttps://docs.aws.amazon.com/neptune/latest/userguide/security-vpc.html\nso any answer outside the VPC is wrong\napparently you won't choose A to have it public","timestamp":"1710893880.0"},{"content":"Selected Answer: BE\nB and E","comment_id":"1168937","timestamp":"1709914560.0","poster":"career360guru","upvote_count":"1"},{"comment_id":"1093283","timestamp":"1702285200.0","upvote_count":"4","poster":"ayadmawla","content":"Amazon Neptune only allows connections from clients located in the same VPC as the Neptune cluster. So we have to use a load balancer or proxy inside the vpc to give us access. The following Github article show architectural designs that outline the approach.\n\nhttps://aws-samples.github.io/aws-dbs-refarch-graph/src/connecting-using-a-load-balancer/#:~:text=your%20Neptune%20cluster.-,Amazon%20Neptune%20only%20allows%20connections%20from%20clients%20located%20in%20the,via%20an%20Application%20Load%20Balancer."},{"upvote_count":"2","comment_id":"1078535","content":"Selected Answer: BE\nB. Create three private subnets in the Neptune VPC, route internet traffic through a NAT gateway, and host the Lambda functions in the new private subnets.\nE. Create three private subnets in the Neptune VPC, host the Lambda functions in these subnets, and create a VPC endpoint for DynamoDB.","timestamp":"1700753640.0","poster":"heatblur"},{"timestamp":"1700709420.0","upvote_count":"1","comment_id":"1078026","content":"Selected Answer: BE\nopções B e E são as mais viáveis","poster":"Jonalb"},{"timestamp":"1700709360.0","poster":"Jonalb","upvote_count":"2","content":"Portanto, as opções B e E são as mais viáveis para permitir que as funções Lambda acessem tanto o cluster de banco de dados Amazon Neptune quanto as tabelas do Amazon DynamoDB.","comment_id":"1078025"},{"upvote_count":"3","poster":"thala","comment_id":"1077936","content":"Selected Answer: BE\nhttps://www.examtopics.com/discussions/amazon/view/81635-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"1700698020.0"},{"timestamp":"1700687460.0","upvote_count":"1","content":"Selected Answer: DE\nAnswer DE","poster":"devalenzuela86","comments":[{"comment_id":"1078854","content":"It's true BE","poster":"devalenzuela86","upvote_count":"1","timestamp":"1700776440.0"}],"comment_id":"1077819"},{"timestamp":"1700637540.0","content":"Selected Answer: BE\nAnswer: B E","poster":"cypkir","comment_id":"1077064","upvote_count":"1"}],"choices":{"C":"Host the Lambda functions outside the VPUpdate the Neptune security group to allow access from the IP ranges of the Lambda functions.","A":"Create three public subnets in the Neptune VPC, and route traffic through an internet gateway. Host the Lambda functions in the three new public subnets.","D":"Host the Lambda functions outside the VPC. Create a VPC endpoint for the Neptune database, and have the Lambda functions access Neptune over the VPC endpoint.","B":"Create three private subnets in the Neptune VPC, and route internet traffic through a NAT gateway. Host the Lambda functions in the three new private subnets.","E":"Create three private subnets in the Neptune VPC. Host the Lambda functions in the three new isolated subnets. Create a VPC endpoint for DynamoDB, and route DynamoDB traffic to the VPC endpoint."},"question_images":[],"isMC":true,"answer_description":"","question_text":"A company is running a serverless application that consists of several AWS Lambda functions and Amazon DynamoDB tables. The company has created new functionality that requires the Lambda functions to access an Amazon Neptune DB cluster. The Neptune DB cluster is located in three subnets in a VPC.\n\nWhich of the possible solutions will allow the Lambda functions to access the Neptune DB cluster and DynamoDB tables? (Choose two.)","timestamp":"2023-11-22 08:19:00","topic":"1","answer_images":[],"answers_community":["BE (93%)","3%"],"unix_timestamp":1700637540,"question_id":336,"exam_id":33,"answer_ET":"BE","answer":"BE","url":"https://www.examtopics.com/discussions/amazon/view/126856-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"whuzbLST39OgkGf1xrB1","answers_community":["D (77%)","B (23%)"],"discussion":[{"comments":[{"upvote_count":"1","comment_id":"1101826","content":"and A is just silly","poster":"ayadmawla","timestamp":"1703096580.0"},{"poster":"ayadmawla","timestamp":"1703096520.0","content":"and of course C would be wrong because for glacier, it would take more than 5 minutes to get the files out","comment_id":"1101825","upvote_count":"2"}],"comment_id":"1101823","content":"Selected Answer: D\nAnswer is D = S3 File Gateway.\nFor those that have chosen B, they are right of course as FSx File Gateway will work as well. But if you read the requirements (The company wants to store the copy on AWS. The company needs the ability to use SMB to access the data from either the data center or AWS if a disaster occurs. The copy of the data is rarely accessed but must be available within 5 minutes.) it is only about storing the data with rare access. So why would you choose option B that has a Multi-AZ + SSD over a cheaper option for DR?","upvote_count":"12","poster":"ayadmawla","timestamp":"1703096340.0"},{"comment_id":"1140701","timestamp":"1707112860.0","content":"Selected Answer: D\nVote for D:\n1. Amazon S3 File Gateway is suitable for SMB file share https://docs.aws.amazon.com/filegateway/latest/files3/CreatingAnSMBFileShare.html\n2. S3 One Zone-IA is for data that is accessed less frequently, but requires rapid access when needed. https://aws.amazon.com/s3/storage-classes/","poster":"chelbsik","upvote_count":"7"},{"timestamp":"1731367740.0","content":"Option D is correct because it:\nDeploys an Amazon S3 File Gateway, which enables SMB access to stored objects in Amazon S3.\nConfigures the S3 File Gateway to use:\nAmazon S3 Standard-Infrequent Access (S3 Standard-IA) for both metadata and image files, providing fast access and reducing storage costs.","comment_id":"1310370","upvote_count":"1","poster":"AzureDP900"},{"comment_id":"1206041","poster":"seetpt","upvote_count":"1","content":"Selected Answer: D\nD for me","timestamp":"1714732080.0"},{"timestamp":"1709915340.0","comment_id":"1168946","comments":[{"timestamp":"1710136320.0","upvote_count":"4","poster":"djangoUnchained","content":"I wouldnt waste tons of money to host data that a rarely accessed on FSx. S3 IA will do just fine.","comment_id":"1170833"}],"poster":"career360guru","upvote_count":"2","content":"Selected Answer: B\nOption B is right."},{"poster":"master9","content":"Selected Answer: D\nAmazon S3 File Gateway provides a seamless way to connect to the cloud to store application data files and backup images as durable objects in Amazon S3 cloud storage. Amazon S3 File Gateway offers SMB or NFS-based access to data in Amazon S3 with local caching. It can be used for on-premises data-intensive Amazon EC2-based applications that need file protocol access to S3 object storage.\n\nhttps://aws.amazon.com/storagegateway/file/s3/","comment_id":"1134653","upvote_count":"3","timestamp":"1706502720.0"},{"content":"https://www.amazonaws.cn/en/storagegateway/faqs/\n\nWith S3 File Gateway, your configured S3 buckets will be available as Network File System (NFS) mount points or Server Message Block (SMB) file shares. Your applications read and write files and directories over NFS or SMB, interfacing to the gateway as a file server. In turn, the gateway translates these file operations into object requests on your S3 buckets.","timestamp":"1705930380.0","upvote_count":"1","poster":"lanjr01","comment_id":"1128678"},{"content":"Selected Answer: B\nOption B. - Requirement states that company needs SMB protocol access to it in case of Disaster in AWS, this is only possible with Fsx Filegateway.","comment_id":"1120103","upvote_count":"3","timestamp":"1705000320.0","poster":"career360guru"},{"comment_id":"1108164","content":"While S3 File Gateway options (C and D) are cost-effective for long-term storage, they introduce retrieval delays that don't meet the 5-minute availability requirement.","upvote_count":"1","timestamp":"1703804700.0","poster":"CProgrammer"},{"content":"Selected Answer: B\nAnswer is B. Although S3 filegateway supports both NFS and SMB, D cannot be the right answer since question does not mention it to be cost efficient.","poster":"Help_please","timestamp":"1702734240.0","upvote_count":"2","comment_id":"1098206"},{"upvote_count":"3","content":"Selected Answer: D\nAnswer D - User S3 file GW with S3 Infreq Access for metadata and image files","poster":"shaaam80","timestamp":"1701315540.0","comment_id":"1083967"},{"poster":"heatblur","comment_id":"1078537","upvote_count":"3","timestamp":"1700753760.0","content":"Selected Answer: D\nAmazon S3 File Gateway supports SMB and can be used to store and retrieve files in Amazon S3 using file-based interfaces. Using S3 Standard-Infrequent Access for both metadata and image files ensures that the data is available within the required 5 minutes while optimizing costs for infrequently accessed data."},{"content":"Selected Answer: D\nD. Implantar um gateway de arquivos Amazon S3. Configure o S3 File Gateway para usar o Amazon S3 Standard-Infrequent Access (S3 Standard-IA) para os arquivos de metadados e arquivos de imagem.","timestamp":"1700708400.0","comments":[{"comments":[{"comment_id":"1081226","poster":"oomwowww","content":"GPT ? lol","timestamp":"1701063300.0","upvote_count":"1"},{"timestamp":"1704305760.0","content":"D is correct --- option B is incorrect, FSx File Gateway with Multi-AZ SSD: Offers high performance but is more expensive for infrequently accessed data.","comment_id":"1113010","poster":"vibzr2023","upvote_count":"1"}],"poster":"devalenzuela86","comment_id":"1078845","content":"D is incorrect because deploying an Amazon S3 File Gateway and configuring the S3 File Gateway to use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) for the metadata files and image files does not provide the ability to use SMB to access the data from either the data center or AWS if a disaster occurs.","timestamp":"1700775780.0","upvote_count":"4"}],"poster":"Jonalb","comment_id":"1078016","upvote_count":"4"},{"timestamp":"1700687640.0","comment_id":"1077822","poster":"devalenzuela86","upvote_count":"3","content":"Selected Answer: B\nB for sure"}],"answer":"D","question_text":"A company wants to design a disaster recovery (DR) solution for an application that runs in the company’s data center. The application writes to an SMB file share and creates a copy on a second file share. Both file shares are in the data center. The application uses two types of files: metadata files and image files.\n\nThe company wants to store the copy on AWS. The company needs the ability to use SMB to access the data from either the data center or AWS if a disaster occurs. The copy of the data is rarely accessed but must be available within 5 minutes.","unix_timestamp":1700687640,"answer_images":[],"timestamp":"2023-11-22 22:14:00","isMC":true,"exam_id":33,"question_images":[],"question_id":337,"choices":{"A":"Deploy AWS Outposts with Amazon S3 storage. Configure a Windows Amazon EC2 instance on Outposts as a file server.","C":"Deploy an Amazon S3 File Gateway. Configure the S3 File Gateway to use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) for the metadata files and to use S3 Glacier Deep Archive for the image files.","B":"Deploy an Amazon FSx File Gateway. Configure an Amazon FSx for Windows File Server Multi-AZ file system that uses SSD storage.","D":"Deploy an Amazon S3 File Gateway. Configure the S3 File Gateway to use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) for the metadata files and image files."},"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/126960-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"D","answer_description":""},{"id":"tUWLrIwpLMh7IFMZM0ze","answer":"C","question_images":[],"isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/126961-exam-aws-certified-solutions-architect-professional-sap-c02/","question_id":338,"answers_community":["C (88%)","9%"],"question_text":"A company is creating a solution that can move 400 employees into a remote working environment in the event of an unexpected disaster. The user desktops have a mix of Windows and Linux operating systems. Multiple types of software, such as web browsers and mail clients, are installed on each desktop.\n\nA solutions architect needs to implement a solution that can be integrated with the company’s on-premises Active Directory to allow employees to use their existing identity credentials. The solution must provide multifactor authentication (MFA) and must replicate the user experience from the existing desktops.\n\nWhich solution will meet these requirements?","answer_ET":"C","answer_images":[],"answer_description":"","choices":{"B":"Use Amazon AppStream 2.0 as an application streaming service. Configure Desktop View for the employees. Set up a VPN connection to the on-premises network. Set up Active Directory Federation Services (AD FS) on premises. Connect the VPC network to AD FS through the VPN connection.","D":"Use Amazon AppStream 2.0 as an application streaming service. Set up Active Directory Federation Services on premises. Configure MFA to grant users access on AppStream 2.0.","C":"Use Amazon WorkSpaces for the cloud desktop service. Set up a VPN connection to the on-premises network. Create an AD Connector, and connect to the on-premises Active Directory. Configure a RADIUS server for MFA.","A":"Use Amazon WorkSpaces for the cloud desktop service. Set up a VPN connection to the on-premises network. Create an AD Connector, and connect to the on-premises Active Directory. Activate MFA for Amazon WorkSpaces by using the AWS Management Console."},"discussion":[{"comment_id":"1086148","timestamp":"1717323120.0","upvote_count":"19","content":"Selected Answer: C\nC is the only way to implement MFA. \"To enable MFA for AWS services such as Amazon WorkSpaces and QuickSight, a key requirement is an MFA solution that is a Remote Authentication Dial-In User Service (RADIUS) server or a plugin to a RADIUS server already implemented in your on-premises infrastructure. \" https://aws.amazon.com/it/blogs/security/how-to-enable-multi-factor-authentication-for-amazon-workspaces-and-amazon-quicksight-by-using-microsoft-ad-and-on-premises-credentials/","poster":"PAUGURU"},{"upvote_count":"8","comments":[{"upvote_count":"3","poster":"JPSWS","content":"So true! I was about to write the exact same thing... Disaster can often equals no more Datacenter so no AD to \"connect\" to for the AD connector.","comment_id":"1207097","timestamp":"1730856480.0"}],"timestamp":"1723093320.0","comment_id":"1144177","poster":"07c2d2a","content":"C. is the answer, but really none of the answers are right. The real flaw here is that they're using an AD connector as a backup. They should be using a managed AD or have an EC2 AD server. If there's an actual disaster, relying on a VPN and a server that might be unreachable well architected."},{"upvote_count":"1","poster":"ma23","comment_id":"1123902","content":"Selected Answer: C\nAnswer C. \nhttps://aws.amazon.com/workspaces/\n\"maximize user experience\" is the keyword to decide Option C.","timestamp":"1721102460.0"},{"content":"Selected Answer: C\nOption C","timestamp":"1720718340.0","comment_id":"1120107","upvote_count":"1","poster":"career360guru"},{"content":"Selected Answer: D\nA and C are out because these options require implementing a RADIUS server on-premise. \nSo, B or D. \nI would prefer B because it is a more secure solution, but since there is no mention of traffic security, I choose D.\nUsing SAML2 you can set MFA for users. \nhttps://docs.aws.amazon.com/appstream2/latest/developerguide/external-identity-providers-further-info.html","poster":"m1xa","timestamp":"1719513780.0","comment_id":"1107196","upvote_count":"1"},{"timestamp":"1717091760.0","comment_id":"1084729","poster":"siasiasia","upvote_count":"2","content":"Selected Answer: C\nyou enable MFA through RADIUS not AWS Console. so A is out.\nthere is no AppStream Linux so B and D are out.","comments":[{"timestamp":"1721003460.0","poster":"thotwielder","content":"Amazon AppStream 2.0 Introduces Linux Application Streaming\nhttps://aws.amazon.com/about-aws/whats-new/2021/11/amazon-appstream-2-0-linux-application-streaming/","upvote_count":"1","comment_id":"1123012"}]},{"poster":"geekgirl007","upvote_count":"2","timestamp":"1716843000.0","content":"Selected Answer: C\nTo enable MFA for AWS services such as Amazon WorkSpaces and QuickSight, a key requirement is an MFA solution that is RADIUS","comment_id":"1081996"},{"content":"why answer is D: https://aws.amazon.com/appstream2/?p=pm&c=euc&pd=appstream2&z=4","timestamp":"1716811020.0","comment_id":"1081614","poster":"Totoroha","upvote_count":"1"},{"comment_id":"1080887","poster":"salazar35","upvote_count":"3","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/security/how-to-enable-multi-factor-authentication-for-amazon-workspaces-and-amazon-quicksight-by-using-microsoft-ad-and-on-premises-credentials/","timestamp":"1716736740.0"},{"poster":"Jonalb","upvote_count":"2","comment_id":"1078013","content":"Selected Answer: C\nC. Use Amazon WorkSpaces para o serviço de desktop em nuvem. Configure uma conexão VPN com a rede local. Crie um conector AD e conecte-se ao Active Directory local. Configure um servidor RADIUS para MFA.","timestamp":"1716425640.0","comments":[{"upvote_count":"1","timestamp":"1716493140.0","content":"incorrect because it requires you to configure a RADIUS server for MFA, which is not required for this solution","comment_id":"1078843","poster":"devalenzuela86"}]},{"content":"Selected Answer: A\nA for sure","upvote_count":"3","poster":"devalenzuela86","timestamp":"1716405420.0","comment_id":"1077824"}],"timestamp":"2023-11-22 22:17:00","unix_timestamp":1700687820,"exam_id":33},{"id":"wDSkTO5mdAGPe7MH6KuJ","exam_id":33,"answer_ET":"A","answer_images":[],"answers_community":["A (88%)","12%"],"unix_timestamp":1700688180,"answer_description":"","choices":{"B":"Use a Contact Lens for Amazon Connect rule that will look for spam calls. Use an Amazon DynamoDB table to store the spam numbers. Modify the contact flows to look for the rule and to invoke an AWS Lambda function to read and write to the DynamoDB table.","C":"Use an Amazon DynamoDB table to store the spam numbers. Create a quick connect that the agents can transfer the spam call to from the Contact Control Panel (CCP). Modify the quick connect contact flow to invoke an AWS Lambda function to write to the DynamoDB table.","D":"Modify the initial contact flow to ask for caller input. If the agent does not receive input, the agent should mark the caller as spam. Use an Amazon DynamoDB table to store the spam numbers. Use an AWS Lambda function to read and write to the DynamoDB table.","A":"Customize the Contact Control Panel (CCP) by adding a flag call button that will invoke an AWS Lambda function that calls the UpdateContactAttributes API. Use an Amazon DynamoDB table to store the spam numbers. Modify the contact flows to look for the updated attribute and to use a Lambda function to read and write to the DynamoDB table."},"question_images":[],"topic":"1","question_text":"A company has deployed an Amazon Connect contact center. Contact center agents are reporting large numbers of computer-generated calls. The company is concerned about the cost and productivity effects of these calls. The company wants a solution that will allow agents to flag the call as spam and automatically block the numbers from going to an agent in the future.\n\nWhat is the MOST operationally efficient solution to meet these requirements?","timestamp":"2023-11-22 22:23:00","question_id":339,"answer":"A","discussion":[{"poster":"ma23","comment_id":"1123883","content":"Selected Answer: A\nSorry. It should be Answer A as per AWS URL. \nhttps://repost.aws/knowledge-center/connect-deny-list-numbers","upvote_count":"5","timestamp":"1721100600.0"},{"content":"D, operationally efficient also.\nhttps://aws.amazon.com/blogs/contact-center/deter-spam-callers-using-amazon-connect/","comment_id":"1195407","upvote_count":"2","timestamp":"1728896160.0","poster":"dman"},{"timestamp":"1722503580.0","poster":"ftaws","comment_id":"1137561","upvote_count":"2","content":"why not C ?"},{"content":"Selected Answer: C\nSurely Answer C. \nhttps://repost.aws/knowledge-center/connect-deny-list-numbers","comment_id":"1123875","upvote_count":"1","poster":"ma23","timestamp":"1721099280.0"},{"upvote_count":"3","timestamp":"1717059780.0","poster":"shaaam80","content":"Selected Answer: A\nAnswer A. Create a Lambda function to store spam /denied numbers in the DynamDB table. Create a second Lambda function to check the table against any incoming number and take appropriate action. \nhttps://repost.aws/knowledge-center/connect-deny-list-numbers","comment_id":"1084268"},{"timestamp":"1716775620.0","comment_id":"1081190","poster":"heatblur","content":"Selected Answer: A\nA is the most operationally efficient solution. It directly empowers agents to flag spam calls with minimal disruption, automates the blocking process via contact flows, and effectively utilizes AWS Lambda and DynamoDB for real-time processing and storage. This approach is both agent-friendly and technically robust, aligning well with the requirements.","upvote_count":"2"},{"timestamp":"1716424680.0","upvote_count":"1","comment_id":"1078004","content":"Selected Answer: C\nC. Use uma tabela do Amazon DynamoDB para armazenar os números de spam. Crie uma conexão rápida para a qual os agentes possam transferir a chamada de spam a partir do Painel de controle de contato (CCP). Modifique o fluxo de contato de conexão rápida para invocar uma função do AWS Lambda para gravar na tabela do DynamoDB.","poster":"Jonalb"},{"timestamp":"1716416580.0","upvote_count":"4","poster":"thala","comment_id":"1077940","content":"Selected Answer: A\nThe most operationally efficient solution to allow agents to flag calls as spam and automatically block these numbers from reaching agents in the future in an Amazon Connect contact center involves a combination of Amazon Connect's features, AWS Lambda, and Amazon DynamoDB. Let's evaluate the options:\n\nA. Customize CCP and Use Lambda with DynamoDB:\n\nCustomizing the Contact Control Panel (CCP) by adding a 'flag call' button allows agents to easily mark calls as spam.\nThe button can invoke an AWS Lambda function, which calls the UpdateContactAttributes API to flag the call.\nUsing an Amazon DynamoDB table to store spam numbers is an effective way to maintain a blocklist.\nModifying contact flows to check for the spam attribute and interact with the DynamoDB table via Lambda ensures that future calls from these numbers are blocked.\nThis solution provides a seamless experience for agents and integrates efficiently with Amazon Connect and AWS services."},{"timestamp":"1716405780.0","poster":"devalenzuela86","upvote_count":"1","comment_id":"1077834","content":"Selected Answer: A\nAnswer A"}],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/126962-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"UBaBJtFA173HnwPI4vfM","isMC":true,"unix_timestamp":1700638020,"answer_images":[],"discussion":[{"upvote_count":"1","content":"Selected Answer: C\nOption C.","poster":"career360guru","timestamp":"1725808860.0","comment_id":"1168993"},{"timestamp":"1720798260.0","upvote_count":"1","comment_id":"1120962","poster":"bjexamprep","content":"Selected Answer: B\nNear real time analysis needs a long running function, while Lambda can only run about 15mins. So, none of the Lamda function answers should be in the picture.\nIOT streaming can be done by Kinesis solution or MSK. \nB: Since this is a continuously running analysis, trigger is not required.\nD: The answer doesn’t mention what solution is used to stream data to Kinesis Data Analytics. And Kinesis Data Analytics itself is a real time analytics tool, which means the ECS is not required.\nNone of B and D is flawless. I vote B because B has less flaws.","comments":[{"content":"B is wrong when you see it use SES for notification","timestamp":"1726871160.0","poster":"pangchn","comment_id":"1178874","upvote_count":"5"}]},{"upvote_count":"2","timestamp":"1720719000.0","content":"Selected Answer: C\nOption C. D is possible but requirement does not state the notification over e-mail.","poster":"career360guru","comment_id":"1120117"},{"timestamp":"1717059960.0","upvote_count":"4","poster":"shaaam80","content":"Selected Answer: C\nAnswer C. Use Kinesis Data streams to ingest data streams in real-time and use a AWS Lambda function to analyze data. Use SNS to send notifications to the factory Operations team.","comment_id":"1084270"},{"poster":"salazar35","upvote_count":"2","timestamp":"1716737100.0","content":"Selected Answer: C\nC is answer","comment_id":"1080893"},{"content":"Selected Answer: C\nC. Transmita os dados para um fluxo de dados do Amazon Kinesis. Crie uma função AWS Lambda para consumir o fluxo de dados do Kinesis e analisar os dados. Use o Amazon Simple Notification Service (Amazon SNS) para notificar a equipe de operações.","poster":"Jonalb","upvote_count":"1","timestamp":"1716424440.0","comment_id":"1078002"},{"timestamp":"1716416760.0","poster":"thala","upvote_count":"3","comment_id":"1077941","content":"Selected Answer: C\nStreaming data to an Amazon Kinesis data stream and using an AWS Lambda function for consuming and analyzing the data in real-time is a robust solution.\nAWS Lambda can process the data stream efficiently and trigger immediate actions.\nUsing Amazon SNS for notifications ensures quick and effective communication with the operations team.\nThis solution is likely to provide the real-time analysis and immediate notification required."},{"timestamp":"1716405900.0","upvote_count":"1","content":"Selected Answer: C\nAnswer c","comment_id":"1077838","poster":"devalenzuela86"},{"poster":"cypkir","upvote_count":"1","timestamp":"1716355620.0","comment_id":"1077073","content":"Selected Answer: C\nAnswer: C"}],"answer_description":"","answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/126857-exam-aws-certified-solutions-architect-professional-sap-c02/","exam_id":33,"question_images":[],"answer_ET":"C","answers_community":["C (94%)","6%"],"topic":"1","question_text":"A company has mounted sensors to collect information about environmental parameters such as humidity and light throughout all the company's factories. The company needs to stream and analyze the data in the AWS Cloud in real time. If any of the parameters fall out of acceptable ranges, the factory operations team must receive a notification immediately.\n\nWhich solution will meet these requirements?","choices":{"B":"Stream the data to an Amazon Managed Streaming for Apache Kafka (Amazon MSK) cluster. Set up a trigger in Amazon MSK to invoke an AWS Fargate task to analyze the data. Use Amazon Simple Email Service (Amazon SES) to notify the operations team.","D":"Stream the data to an Amazon Kinesis Data Analytics application. Use an automatically scaled and containerized service in Amazon Elastic Container Service (Amazon ECS) to consume and analyze the data. Use Amazon Simple Email Service (Amazon SES) to notify the operations team.","C":"Stream the data to an Amazon Kinesis data stream. Create an AWS Lambda function to consume the Kinesis data stream and to analyze the data. Use Amazon Simple Notification Service (Amazon SNS) to notify the operations team.","A":"Stream the data to an Amazon Kinesis Data Firehose delivery stream. Use AWS Step Functions to consume and analyze the data in the Kinesis Data Firehose delivery stream. Use Amazon Simple Notification Service (Amazon SNS) to notify the operations team."},"question_id":340,"timestamp":"2023-11-22 08:27:00"}],"exam":{"id":33,"name":"AWS Certified Solutions Architect - Professional SAP-C02","isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":529,"provider":"Amazon","isMCOnly":true,"isBeta":false},"currentPage":68},"__N_SSP":true}