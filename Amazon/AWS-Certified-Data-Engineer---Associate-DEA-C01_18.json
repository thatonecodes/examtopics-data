{"pageProps":{"questions":[{"id":"YKWBx8WhsNM21bSTJXWq","answer_images":[],"answer_description":"","unix_timestamp":1730004000,"isMC":true,"question_id":86,"url":"https://www.examtopics.com/discussions/amazon/view/150344-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","choices":{"A":"Use the existing AWS KMS key to encrypt connections from QuickSight to the S3 bucket.","E":"Add the KMS key as a resource that the QuickSight service role can access.","B":"Add the S3 bucket as a resource that the QuickSight service role can access.","C":"Use AWS Resource Access Manager (AWS RAM) to share the S3 bucket with the BI-Account account.","D":"Add an IAM policy to the QuickSight service role to give QuickSight access to the KMS key that encrypts the S3 bucket."},"answer_ET":"E","timestamp":"2024-10-27 05:40:00","answer":"E","question_text":"A company uses Amazon S3 to store data and Amazon QuickSight to create visualizations,\n\nThe company has an S3 bucket in an AWS account named Hub-Account. The S3 bucket is encrypted by an AWS Key Management Service (AWS KMS) key. The company's QuickSight instance is in a separate account named BI-Account.\n\nThe company updates the S3 bucket policy to grant access to the QuickSight service role. The company wants to enable cross-account access to allow QuickSight to interact with the S3 bucket.\n\nWhich combination of steps will meet this requirement? (Choose two.)","answers_community":["E (60%)","B (30%)","10%"],"exam_id":21,"question_images":[],"discussion":[{"poster":"Ell89","upvote_count":"1","content":"Selected Answer: E\nB & E. the issue isnt with sharing the bucket as the bucket policy does that already to the service role. its an encryption issue.","comment_id":"1362759","timestamp":"1740696540.0"},{"content":"Selected Answer: B\nBD :\nB - To ensure QS has permissions to access the S3\nD - To ensure QS has permission for KMS to decrypt date in S3","comment_id":"1355063","upvote_count":"1","poster":"fnuuu","timestamp":"1739294580.0"},{"comment_id":"1344683","content":"Selected Answer: B\nBD\nConclusion: To enable cross-account access for both (1) the Amazon S3 bucket and (2) the KMS key used to encrypt that bucket, the QuickSight service role must be granted the appropriate permissions. Among the provided options, the following two steps are essential:\n\nB. Add the S3 bucket as a resource the QuickSight service role can access\n(→ Allows cross-account access to the S3 bucket)\n\nD. Add an IAM policy to the QuickSight service role that grants access to the KMS key\n(→ Allows decryption of data encrypted by the KMS key)","poster":"YUICH","upvote_count":"1","timestamp":"1737535800.0"},{"comment_id":"1341566","content":"Selected Answer: D\nS3 bucket policy is already updated from the question. Hence KMS key policy and IAM policy need to be altered to allow QuickSight service account to access KMS key.","timestamp":"1737016740.0","upvote_count":"1","poster":"stevejake"},{"content":"Selected Answer: B\nGiven that the question states “Update the S3 bucket policy to allow access for the QuickSight service role” and, from the perspective of “enabling cross-account access so that QuickSight can interact with the S3 bucket,” is asking what additional steps are needed, we can conclude that:\n\n(B) “Add the S3 bucket as a resource accessible by the QuickSight service role”\n(E) “Add the KMS key as a resource accessible by the QuickSight service role”\n\ntogether most succinctly represent the final actions required.","poster":"YUICH","timestamp":"1736229120.0","comment_id":"1337458","upvote_count":"1"},{"content":"Selected Answer: E\nD & E\nS3 bucket policy is already updated from the question. Hence KMS key policy and IAM policy need to be altered to allow QuickSight service account to access KMS key.","comment_id":"1316915","poster":"devan007","timestamp":"1732423320.0","upvote_count":"4"},{"comment_id":"1313970","poster":"michele_scar","timestamp":"1731931920.0","upvote_count":"1","content":"Selected Answer: E\nB for bucket access\nE for KMS key policy"},{"upvote_count":"2","comment_id":"1309326","content":"It is BD","poster":"Eleftheriia","timestamp":"1731223620.0"},{"poster":"kupo777","timestamp":"1730760900.0","comment_id":"1307130","content":"Correct Answer: DE","upvote_count":"3"},{"content":"Answer BE: Step to enable cross-account access:\n1. update S3 bucket policy in Hub-account (B)\n2. Update the KMS key Policy in Hub-Account(E)\n3. Config QuickSight to access S3","poster":"truongnguyen86","upvote_count":"3","comment_id":"1305441","timestamp":"1730379360.0"},{"poster":"pikuantne","content":"Answer: BD","comment_id":"1305410","timestamp":"1730377860.0","upvote_count":"3"},{"timestamp":"1730269200.0","poster":"2022MMTT","comment_id":"1304879","upvote_count":"4","content":"Answer : DE"},{"content":"Answer:BE","comment_id":"1303486","poster":"Parandhaman_Margan","upvote_count":"1","timestamp":"1730004000.0"}],"topic":"1"},{"id":"w2KDm0X9XXzewsZ4Sfg1","exam_id":21,"question_id":87,"isMC":true,"question_images":[],"answer_description":"","topic":"1","answer_ET":"D","answers_community":["D (100%)"],"timestamp":"2024-11-25 06:17:00","unix_timestamp":1732511820,"question_text":"A car sales company maintains data about cars that are listed for sale in an area. The company receives data about new car listings from vendors who upload the data daily as compressed files into Amazon S3. The compressed files are up to 5 KB in size. The company wants to see the most up-to-date listings as soon as the data is uploaded to Amazon S3.\n\nA data engineer must automate and orchestrate the data processing workflow of the listings to feed a dashboard. The data engineer must also provide the ability to perform one-time queries and analytical reporting. The query solution must be scalable.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_images":[],"answer":"D","discussion":[{"comment_id":"1332024","timestamp":"1735233900.0","content":"Selected Answer: D\nI don't particularly like the formulation where AWS Lambda and S3 Event Notifications are described as being responsible for orchestrating any workflow. However, I believe Athena is a much more suitable solution in this case compared to AWS Redshift, so going with option D seems to be a reasonable choice at some point","poster":"axantroff","upvote_count":"3"},{"timestamp":"1734951420.0","content":"Selected Answer: D\nseems like C could be the answer but setting up redshift cluster takes much longer to get the same thing like Athena. so D","comment_id":"1330786","upvote_count":"2","poster":"HagarTheHorrible"},{"timestamp":"1732511820.0","upvote_count":"1","comment_id":"1317334","poster":"emupsx1","content":"https://aws.amazon.com/tw/blogs/big-data/build-an-etl-process-for-amazon-redshift-using-amazon-s3-event-notifications-and-aws-step-functions/"}],"url":"https://www.examtopics.com/discussions/amazon/view/151942-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","choices":{"C":"Use AWS Glue to process incoming data. Use AWS Step Functions to orchestrate workflows. Use Amazon Redshift Spectrum for one-time queries and analytical reporting. Use OpenSearch Dashboards in Amazon OpenSearch Service for the dashboard.","D":"Use AWS Glue to process incoming data. Use AWS Lambda and S3 Event Notifications to orchestrate workflows. Use Amazon Athena for one-time queries and analytical reporting. Use Amazon QuickSight for the dashboard.","A":"Use an Amazon EMR cluster to process incoming data. Use AWS Step Functions to orchestrate workflows. Use Apache Hive for one-time queries and analytical reporting. Use Amazon OpenSearch Service to bulk ingest the data into compute optimized instances. Use OpenSearch Dashboards in OpenSearch Service for the dashboard.","B":"Use a provisioned Amazon EMR cluster to process incoming data. Use AWS Step Functions to orchestrate workflows. Use Amazon Athena for one-time queries and analytical reporting. Use Amazon QuickSight for the dashboard."}},{"id":"TlCaQjzRe83al2pwlzQo","exam_id":21,"question_id":88,"isMC":true,"question_images":[],"answer_description":"","topic":"1","answer_ET":"D","answers_community":["D (67%)","A (17%)","C (17%)"],"timestamp":"2024-12-02 11:44:00","unix_timestamp":1733136240,"question_text":"A company has AWS resources in multiple AWS Regions. The company has an Amazon EFS file system in each Region where the company operates. The company’s data science team operates within only a single Region. The data that the data science team works with must remain within the team's Region.\n\nA data engineer needs to create a single dataset by processing files that are in each of the company's Regional EFS file systems. The data engineer wants to use an AWS Step Functions state machine to orchestrate AWS Lambda functions to process the data.\n\nWhich solution will meet these requirements with the LEAST effort?","answer_images":[],"answer":"D","discussion":[{"upvote_count":"1","timestamp":"1734951540.0","poster":"HagarTheHorrible","content":"Selected Answer: C\nData Sync is for large scale migration, Lambdas would do just fine here... C","comment_id":"1330787"},{"poster":"Vidhi212","timestamp":"1734353160.0","comment_id":"1327352","content":"Selected Answer: D\nUsing AWS DataSync in Option D achieves the desired data consolidation efficiently while keeping the workflow simple and cost-effective. It aligns with the data locality requirement and reduces engineering effort.","upvote_count":"3"},{"content":"Selected Answer: D\nPeer the VPC introduce complexity, D is a much better solution","upvote_count":"1","poster":"7a1d491","timestamp":"1734352800.0","comment_id":"1327349"},{"poster":"emupsx1","timestamp":"1733136240.0","comment_id":"1320895","content":"Selected Answer: A\nmaybe A?","upvote_count":"1"}],"url":"https://www.examtopics.com/discussions/amazon/view/152459-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","choices":{"B":"Configure each of the Regional EFS file systems to replicate data to the data science team's Region. In the data science team’s Region, configure the Lambda functions to mount the replica file systems. Use the Lambda functions to process the data.","D":"Use AWS DataSync to transfer files from each of the Regional EFS files systems to the file system that is in the data science team's Region. Configure the Lambda functions in the data science team's Region to mount the file system that is in the same Region. Use the Lambda functions to process the data.","A":"Peer the VPCs that host the EFS file systems in each Region with the VPC that is in the data science team’s Region. Enable EFS file locking. Configure the Lambda functions in the data science team's Region to mount each of the Region specific file systems. Use the Lambda functions to process the data.","C":"Deploy the Lambda functions to each Region. Mount the Regional EFS file systems to the Lambda functions. Use the Lambda functions to process the data. Store the output in an Amazon S3 bucket in the data science team’s Region."}},{"id":"wGXMuDpdC0zdpLuZ1irI","question_images":[],"answer_description":"","exam_id":21,"unix_timestamp":1732516020,"choices":{"A":"Store self-managed certificates on the EC2 instances.","D":"Use Amazon Elastic Container Service (Amazon ECS) Service Connect.","B":"Use AWS Certificate Manager (ACM).","C":"Implement custom automation scripts in AWS Secrets Manager."},"timestamp":"2024-11-25 07:27:00","answer_images":[],"isMC":true,"answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/151944-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","question_text":"A company hosts its applications on Amazon EC2 instances. The company must use SSL/TLS connections that encrypt data in transit to communicate securely with AWS infrastructure that is managed by a customer.\n\nA data engineer needs to implement a solution to simplify the generation, distribution, and rotation of digital certificates. The solution must automatically renew and deploy SSL/TLS certificates.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","topic":"1","discussion":[{"timestamp":"1736965620.0","comment_id":"1341193","poster":"MerryLew","content":"Selected Answer: B\nACM takes care of creating, storing, and renewing SSL/TLS certificates and keys","upvote_count":"1"},{"poster":"emupsx1","content":"Selected Answer: B\nhttps://aws.amazon.com/tw/certificate-manager/","timestamp":"1732516020.0","upvote_count":"2","comment_id":"1317345"}],"answer":"B","answers_community":["B (100%)"],"question_id":89},{"id":"rA03G01qEHG3yJgVhShr","answer_ET":"B","timestamp":"2024-01-20 12:02:00","isMC":true,"question_id":90,"answers_community":["B (100%)"],"answer_images":[],"unix_timestamp":1705748520,"discussion":[{"timestamp":"1706821740.0","comment_id":"1137938","poster":"TonyStark0122","upvote_count":"9","content":"B. Turn on concurrency scaling at the workload management (WLM) queue level in the Redshift cluster.\n\nExplanation:\nConcurrency scaling in Amazon Redshift allows the cluster to automatically add and remove compute resources in response to workload demands. Enabling concurrency scaling at the workload management (WLM) queue level allows you to specify which queues can benefit from concurrency scaling based on the query workload."},{"poster":"saransh_001","timestamp":"1739458500.0","content":"Selected Answer: B\nConcurrency Scaling in Amazon Redshift is a feature that automatically adds temporary clusters to handle spikes in query traffic, providing additional read and write capacity.\nThis feature is enabled through Workload Management (WLM) at the queue level in Redshift. Each queue can be configured to use concurrency scaling for handling queries that exceed the capacity of the main cluster.\nWhy option A is incorrect:\nTurn on concurrency scaling in workload management (WLM) for Redshift Serverless workgroups: This option is for Redshift Serverless rather than clusters on RA3 nodes. Serverless clusters handle scaling differently and don't require manual concurrency scaling settings like the RA3 clusters.","comment_id":"1356174","upvote_count":"4"},{"content":"B\"You can manage which queries are sent to the concurrency-scaling cluster by configuring WLM queues. You're charged for concurrency-scaling clusters only for the time they're actively running queries.\"\nhttps://docs.aws.amazon.com/redshift/latest/dg/concurrency-scaling.html","upvote_count":"1","timestamp":"1730980500.0","poster":"lsj900605","comment_id":"1308348"},{"poster":"San_Juan","comment_id":"1270610","content":"Selected answer: B\nB. According to documentation, the \"concurrency scaling\" is set up in workload management queue (see comment below).\n\nA. discarted, because redshift serverless scales automatically (it doesn't need enable \"concurrency scaling\").","timestamp":"1724320620.0","upvote_count":"2"},{"timestamp":"1714964040.0","comment_id":"1207141","upvote_count":"1","poster":"d8945a1","content":"Selected Answer: B\nB. Turn on concurrency scaling at the workload management (WLM) queue level in the Redshift cluster."},{"timestamp":"1714193580.0","comment_id":"1202962","upvote_count":"1","content":"Selected Answer: B\nAnswer is B.\nB. Turn on concurrency scaling at the workload management (WLM) queue level in the Redshift cluster.","poster":"khchan123"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/redshift/latest/dg/concurrency-scaling-queues.html","poster":"milofficial","timestamp":"1705748520.0","comment_id":"1127219","upvote_count":"4"}],"answer":"B","exam_id":21,"url":"https://www.examtopics.com/discussions/amazon/view/131680-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","answer_description":"","topic":"1","choices":{"D":"Turn on concurrency scaling for the daily usage quota for the Redshift cluster.","A":"Turn on concurrency scaling in workload management (WLM) for Redshift Serverless workgroups.","C":"Turn on concurrency scaling in the settings during the creation of any new Redshift cluster.","B":"Turn on concurrency scaling at the workload management (WLM) queue level in the Redshift cluster."},"question_text":"A company uses an Amazon Redshift cluster that runs on RA3 nodes. The company wants to scale read and write capacity to meet demand. A data engineer needs to identify a solution that will turn on concurrency scaling.\nWhich solution will meet this requirement?","question_images":[]}],"exam":{"numberOfQuestions":207,"isImplemented":true,"provider":"Amazon","isMCOnly":true,"id":21,"isBeta":false,"name":"AWS Certified Data Engineer - Associate DEA-C01","lastUpdated":"11 Apr 2025"},"currentPage":18},"__N_SSP":true}