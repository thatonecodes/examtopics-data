{"pageProps":{"questions":[{"id":"cOrWuT2kaLv92zqRRmUy","question_id":86,"question_images":[],"answer_ET":"AC","unix_timestamp":1727912280,"timestamp":"2024-10-03 01:38:00","choices":{"E":"In the Account B VPC, verify that the S3 bucket policy allows the s3:PutObjectAcl action for cross-account use. In the Account B VPC, create a gateway VPC endpoint for Amazon S3. For the gateway VPC endpoint, create a resource policy that allows the s3:GetObject, s3:ListBucket, and s3:PutObject actions for the S3 bucket.","D":"In the Account B VPC, create an interface VPC endpoint for AWS KMS. For the interface VPC endpoint, create a resource policy that allows the kms:Encrypt, kms:Decrypt, and kms:GenerateDataKey actions for the KMS key. Ensure that private DNS is turned off for the endpoint.","C":"In the Account B VPC, create an interface VPC endpoint for AWS KMS. For the interface VPC endpoint, create a resource policy that allows the kms:Encrypt, kms:Decrypt, and kms:GenerateDataKey actions for the KMS key. Ensure that private DNS is turned on for the endpoint.","A":"In the Account B VPC, create a gateway VPC endpoint for Amazon S3. For the gateway VPC endpoint, create a resource policy that allows the s3:GetObject, s3:ListBucket, s3:PutObject, and s3:PutObjectAcl actions for the S3 bucket.","B":"In the Account B VPC, create an interface VPC endpoint for Amazon S3. For the interface VPC endpoint, create a resource policy that allows the s3:GetObject, s3:ListBucket, s3:PutObject, and s3:PutObjectAcl actions for the S3 bucket."},"url":"https://www.examtopics.com/discussions/amazon/view/148576-exam-aws-certified-security-specialty-scs-c02-topic-1/","exam_id":30,"answer":"AC","answer_images":[],"topic":"1","discussion":[{"comment_id":"1344380","timestamp":"1737494460.0","upvote_count":"1","poster":"nznzwell","content":"Selected Answer: AC\nAll the comments regarding s3 cannot be accessed by an interface endpoint is wrong - instead, s3 can use both gateway endpoints and interface endpoints: https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html\n\nB is not correct as the question does not mention any connectivity between Account A and B so private routing is not possible."},{"timestamp":"1732646760.0","content":"Selected Answer: AC\nA and C","poster":"jdx000","upvote_count":"1","comment_id":"1318254"},{"timestamp":"1730189040.0","comment_id":"1304334","upvote_count":"2","poster":"komik_101","content":"Selected Answer: AC\nI will going to AC, when I look at the question , I saw \"fleet of EC2\" this means Account B have many EC2. Go to link. you will see many topology, and you will understand what I mean. \nhttps://aws.amazon.com/tr/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/"},{"content":"AC: Amazon S3 uses a gateway VPC endpoint rather than an interface VPC endpoint for access from a VPC.","comment_id":"1302056","upvote_count":"1","timestamp":"1729687380.0","poster":"3e88bd8"},{"poster":"div05jkjl","upvote_count":"1","comment_id":"1299168","content":"BC.\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html","timestamp":"1729162800.0"},{"timestamp":"1728655080.0","comment_id":"1296125","upvote_count":"1","content":"AC . B is wrong no interface endpoint for s3","poster":"VPNalumni"},{"comments":[{"upvote_count":"3","comment_id":"1292548","poster":"mikelord","content":"Actually changed the answer to AC.\nAmazon S3 uses a gateway VPC endpoint rather than an interface VPC endpoint for access from a VPC. Gateway endpoints are specifically designed for services like S3 and DynamoDB, allowing efficient, private access.","timestamp":"1727912340.0"}],"upvote_count":"1","content":"BC for me as well.","poster":"mikelord","timestamp":"1727912280.0","comment_id":"1292545"}],"answer_description":"","question_text":"A company has a batch-processing system that uses Amazon S3, Amazon EC2, and AWS Key Management Service (AWS KMS). The system uses two AWS accounts: Account A and Account B.\n\nAccount A hosts an S3 bucket that stores the objects that will be processed. The S3 bucket also stores the results of the processing. All the S3 bucket objects are encrypted by a KMS key that is managed in Account A.\n\nAccount B hosts a VPC that has a fleet of EC2 instances that access the S3 bucket in Account A by using statements in the bucket policy. The VPC was created with DNS hostnames enabled and DNS resolution enabled.\n\nA security engineer needs to update the design of the system without changing any of the system's code. No AWS API calls from the batch-processing EC2 instances can travel over the internet.\n\nWhich combination of steps will meet these requirements? (Choose two.)","isMC":true,"answers_community":["AC (100%)"]},{"id":"zcrg69pqL9GyXIQegCFm","unix_timestamp":1727912520,"answer":"A","question_id":87,"timestamp":"2024-10-03 01:42:00","choices":{"A":"In AWS CloudTrail, create a trail for management events. Run the script with the existing AWS managed IAM policies. Use IAM Access Analyzer to generate a new IAM policy that is based on access activity in the trail. Replace the existing AWS managed IAM policies with the generated IAM policy for the role.","C":"Create an account analyzer in IAM Access Analyzer. Create an archive rule that has a filter that checks whether the PrincipalArn value matches the ARN of the role. Run the script. Remove the existing AWS managed IAM policies from the role.","B":"Remove the existing AWS managed IAM policies from the role. Attach the IAM Access Analyzer Role Policy Generator to the role. Run the script. Return to IAM Access Analyzer and generate a least privilege IAM policy. Attach the new IAM policy to the role.","D":"In AWS CloudTrail, create a trail for management events. Remove the existing AWS managed IAM policies from the role. Run the script. Find the authorization failure in the trail event that is associated with the script. Create a new IAM policy that includes the action and resource that caused the authorization failure. Repeat the process until the script succeeds. Attach the new IAM policy to the role."},"exam_id":30,"answer_ET":"A","question_images":[],"answers_community":["A (100%)"],"topic":"1","answer_images":[],"isMC":true,"answer_description":"","discussion":[{"poster":"IPLogic","timestamp":"1733257860.0","upvote_count":"1","comment_id":"1321536","content":"Selected Answer: A\nThe most operationally efficient way to construct a least privilege IAM policy for the script is Option A:\n\nA. In AWS CloudTrail, create a trail for management events. Run the script with the existing AWS managed IAM policies. Use IAM Access Analyzer to generate a new IAM policy that is based on access activity in the trail. Replace the existing AWS managed IAM policies with the generated IAM policy for the role.\n\nAWS CloudTrail logs all API calls, which provides a comprehensive record of the actions performed by the script.\nIAM Access Analyzer can analyze these logs to automatically generate a least privilege policy based on the actual access patterns1. This minimizes the manual effort required to identify necessary permissions.\nThis approach ensures that the new policy includes only the permissions that are actually used, adhering to the principle of least privilege."},{"timestamp":"1728655560.0","upvote_count":"2","poster":"VPNalumni","content":"A\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access-analyzer-policy-generation.html","comment_id":"1296127"},{"upvote_count":"2","timestamp":"1727912520.0","content":"Option A provides the most operationally efficient solution by leveraging AWS CloudTrail to log access activity and IAM Access Analyzer to automatically generate a least privilege policy based on that activity. This approach minimizes manual intervention and ensures that the resulting IAM policy grants only the permissions necessary for the script to function, adhering to the principle of least privilege.","poster":"mikelord","comment_id":"1292551"}],"question_text":"A security engineer is designing an IAM policy for a script that will use the AWS CLI. The script currently assumes an IAM role that is attached to three AWS managed IAM policies: AmazonEC2FullAccess, AmazonDynamoDBFullAccess, and AmazonVPCFullAccess.\n\nThe security engineer needs to construct a least privilege IAM policy that will replace the AWS managed IAM policies that are attached to this role.\n\nWhich solution will meet these requirements in the MOST operationally efficient way?","url":"https://www.examtopics.com/discussions/amazon/view/148577-exam-aws-certified-security-specialty-scs-c02-topic-1/"},{"id":"riXatD1gr9LG1BvpWEmV","answers_community":["D (100%)"],"answer_images":[],"topic":"1","isMC":true,"timestamp":"2024-10-03 01:44:00","answer_description":"","question_images":[],"exam_id":30,"discussion":[{"content":"Selected Answer: D\nThe best solution to meet these requirements is:\n\nD. Deploy the tokenization code onto AWS Nitro Enclaves that are hosted on EC2 instances.\n\nAWS Nitro Enclaves provide an isolated environment that is ideal for processing sensitive data, such as credit card numbers. They offer strong security guarantees by isolating the tokenization process from other components of the application, ensuring that sensitive data is protected and inaccessible to unauthorized components","timestamp":"1733258160.0","poster":"IPLogic","comment_id":"1321537","upvote_count":"1"},{"content":"D. Deploy the tokenization code onto AWS Nitro Enclaves that are hosted on EC2 instances.\n\nExplanation:\nAWS Nitro Enclaves provide isolated compute environments to process highly sensitive data, ensuring that other components cannot access the credit card numbers.\nNitro Enclaves are specifically designed for secure processing of confidential information, making them ideal for tokenization tasks.\nhttps://aws.amazon.com/ec2/nitro/nitro-enclaves/","comment_id":"1296128","upvote_count":"1","timestamp":"1728655860.0","poster":"VPNalumni"},{"timestamp":"1727912640.0","poster":"mikelord","comment_id":"1292553","upvote_count":"1","content":"Option D, deploying the tokenization component onto AWS Nitro Enclaves, is the best solution. Nitro Enclaves provide a highly secure, isolated environment that can handle the encryption, storage, and tokenization of sensitive information without exposing it to other parts of the application, meeting the requirements for both isolation and data security."}],"unix_timestamp":1727912640,"choices":{"C":"Create a separate VPDeploy new EC2 instances into the separate VPC to support the data tokenization.","A":"Use EC2 Dedicated Instances for the tokenization component of the application.","D":"Deploy the tokenization code onto AWS Nitro Enclaves that are hosted on EC2 instances.","B":"Place the EC2 instances that manage the tokenization process into a partition placement group."},"question_id":88,"question_text":"A security engineer is designing a cloud architecture to support an application. The application runs on Amazon EC2 instances and processes sensitive information, including credit card numbers.\n\nThe application will send the credit card numbers to a component that is running in an isolated environment. The component will encrypt, store, and decrypt the numbers. The component then will issue tokens to replace the numbers in other parts of the application.\n\nThe component of the application that manages the tokenization process will be deployed on a separate set of EC2 instances. Other components of the application must not be able to store or access the credit card numbers.\n\nWhich solution will meet these requirements?","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/148578-exam-aws-certified-security-specialty-scs-c02-topic-1/","answer":"D"},{"id":"Eimp6xU51lPtZWfgphTG","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/148579-exam-aws-certified-security-specialty-scs-c02-topic-1/","unix_timestamp":1727912760,"answer_description":"","choices":{"C":"Add an aws:MultiFactorAuthPresent condition to the session policy.","B":"Add an aws MultiFactorAuthPresent condition to the roleâ€™s trust policy.","D":"Add an aws:MultiFactorAuthPresent condition to the S3 bucket policies.","A":"Add an aws:MultiFactorAuthPresent condition to the role's permissions policy."},"answer":"B","answers_community":["B (100%)"],"exam_id":30,"answer_ET":"B","question_images":[],"timestamp":"2024-10-03 01:46:00","topic":"1","question_id":89,"discussion":[{"upvote_count":"1","timestamp":"1735884660.0","poster":"TareDHakim","content":"Selected Answer: B\nChatGPT Explanation: The trust policy determines who can assume the IAM role. Adding an aws:MultiFactorAuthPresent condition to the trust policy ensures that only sessions authenticated with MFA can assume the role.","comment_id":"1335905"},{"poster":"723993f","content":"Selected Answer: B\nI think about Trust policy as a \"Resource Policy\" for IAM role, just as a matter of understanding and remembering, not how AWS wants us to think about it\n\nso just like any other resource where we add a resource policy (if available) when you want to protect the resource, you do the same for iam role","comment_id":"1317745","timestamp":"1732565460.0","upvote_count":"1"},{"upvote_count":"3","poster":"mikelord","content":"Option B is the correct answer because adding the aws:MultiFactorAuthPresent condition to the role's trust policy enforces MFA for role assumption, ensuring that only users who have authenticated with MFA can assume the role. This solution meets the requirement effectively and with minimal changes.","timestamp":"1727912760.0","comment_id":"1292554"}],"isMC":true,"question_text":"A company has two AWS accounts: Account A and Account B. Account A has an IAM role that IAM users in Account B assume when they need to upload sensitive documents to Amazon S3 buckets in Account A.\n\nA new requirement mandates that users can assume the role only if they are authenticated with multi-factor authentication (MFA). A security engineer must recommend a solution that meets this requirement with minimum risk and effort.\n\nWhich solution should the security engineer recommend?"},{"id":"Vj02Q6c5b7SYJz236Bgk","url":"https://www.examtopics.com/discussions/amazon/view/124547-exam-aws-certified-security-specialty-scs-c02-topic-1/","unix_timestamp":1698127020,"question_text":"A company uses several AWS CloudFormation stacks to handle the deployment of a suite of applications. The leader of the company's application development team notices that the stack deployments fail with permission errors when some team members try to deploy the stacks. However, other team members can deploy the stacks successfully.\nThe team members access the account by assuming a role that has a specific set of permissions that are necessary for the job responsibilities of the team members. All team members have permissions to perform operations on the stacks.\nWhich combination of steps will ensure consistent deployment of the stacks MOST securely? (Choose three.)","question_id":90,"answer_ET":"BDE","timestamp":"2023-10-24 07:57:00","answers_community":["BDE (43%)","BD (23%)","BE (20%)","15%"],"question_images":[],"answer_images":[],"answer":"BDE","discussion":[{"upvote_count":"13","poster":"PareshBPatel","comment_id":"1147615","timestamp":"1707680340.0","content":"BEF are the correct selection\nThought to consistent deployment of CloudFormation stacks would actually be\nB. Create a service role that has cloudformation.amazonaws.com as the service principal. Configure the role to allow the sts:AssumeRole action.\nE. Update each stack to use the service role.\nF. Add a policy to each member role to allow the iam:PassRole action. Set the policy's resource field to the ARN of the service role.\nThese steps ensure that CloudFormation has the necessary permissions through a service role designed specifically for it (B), that each stack is configured to use this service role for deployments (E), and that users have the permission to pass this role to CloudFormation (F), aligning with best practices for security and consistency."},{"timestamp":"1718731080.0","content":"Selected Answer: BDE\nB. Create a service role that has cloudformation.amazonaws.com as the service principal. Configure the role to allow the sts\naction.\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html\nD. For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each service that needs the permissions in the resource field of the corresponding policy.\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-servicerole.html#using-iam-servicerole-add\nE. Update each stack to use the service role.\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-servicerole.html","poster":"cumzle_com","comment_id":"1232544","upvote_count":"7"},{"content":"Selected Answer: BDE\nWhy Not A, C, or F?\nOption Reason for Rejection\nA A composite principal is unnecessary here. CloudFormation is the only service assuming the role, so we only need cloudformation.amazonaws.com.\nC Adding CloudFormation stack ARNs in the resource field is incorrect because policies should apply to the services being provisioned, not to CloudFormation stacks themselves.\nF iam:PassRole is only needed when a user or service is delegating a role to another AWS service (e.g., EC2 assuming an IAM role). CloudFormation assumes the role directly, so this step is not required.","timestamp":"1738823280.0","upvote_count":"1","comment_id":"1352204","poster":"FlyingHawk"},{"content":"Selected Answer: BD\nBDF\nOption E: It's not necessary to explicitly update each stack to use the service role. CloudFormation automatically assumes the specified service role when performing stack operations, as long as the role is properly configured with the necessary permissions and trust relationships.","comment_id":"1335861","timestamp":"1735870380.0","upvote_count":"1","poster":"youonebe"},{"upvote_count":"2","comment_id":"1325124","poster":"ahirri","content":"Selected Answer: BCE\nAnyone that voted \"D\", how can you add \"Service Arn\" (not Resource ARN) to the \"Resource\" field in an IAM policy?","timestamp":"1733938560.0"},{"timestamp":"1733495340.0","content":"Selected Answer: BE\nBEF IS THE RIGHT ANSWER FOR THIS SCENARIO","comment_id":"1322787","upvote_count":"2","poster":"IPLogic"},{"content":"In a scenario where E and F are combined as one choice (E) as someone stated then the correct answer would be BCE.","comment_id":"1276791","upvote_count":"1","poster":"hb0011","timestamp":"1725286320.0"},{"timestamp":"1725285660.0","upvote_count":"1","poster":"hb0011","content":"Selected Answer: BE\nThe voting buttons are messed up so it's showing the wrong answer. The answer is 100% definitely BEF but you can't vote for BEF.","comment_id":"1276778"},{"poster":"HunkyBunky","comment_id":"1274153","content":"Selected Answer: BDE\nFor me - BDE looks good.","upvote_count":"1","timestamp":"1724856240.0"},{"timestamp":"1724263500.0","upvote_count":"1","poster":"FunkyFresco","comment_id":"1270327","content":"Selected Answer: BD\nBDF make more sense to me."},{"upvote_count":"3","poster":"shyam87","comment_id":"1270007","timestamp":"1724233260.0","content":"B - the CloudFormation service to needs to assume the role to create the resources\nE - the stacks needs to use the role to gain permissions\nF - the IAM user needs the iam:PassRole permission to pass the role to the CloudFormation service"},{"timestamp":"1721043000.0","comment_id":"1248300","content":"Selected Answer: BDE\nB, D, E.","poster":"5409b91","upvote_count":"5"},{"upvote_count":"1","comment_id":"1220450","timestamp":"1716917100.0","content":"Selected Answer: BE\nBEF are the correct answers.","poster":"shailvardhan"},{"comment_id":"1196933","timestamp":"1713318180.0","upvote_count":"4","poster":"CloudHell","content":"Selected Answer: BCE\nB ensures that CloudFormation has the necessary permissions through a dedicated service role.\nC restricts the permissions to the specific stacks, following the principle of least privilege.\nE ensures that each stack uses the service role during deployment."},{"poster":"Snape","upvote_count":"4","comment_id":"1196285","timestamp":"1713230040.0","content":"Selected Answer: BE\nBEF is correct"},{"comment_id":"1145864","comments":[{"poster":"Raphaello","content":"Ok, looking again at the options of this question, option D is a bit tricky.\nYes you need to create permissions to CF service role, but there's nothing like \"ARN of each service\" to be added to the resource field. ARN's belong to resources not services, and in CF service role, resource element usually takes \"*\"; but even if you want to specify a resource it will be something like (arn:aws:s3:::my_bucket/*) NOT ARN OF EACH SERVICE!\nARN <--> Resource..not service.\n\nFor that, I would go with BEF.\n\"F\" (users being able to iam:PassRole) is important and the option is worded correctly.\nD is not worded correctly, as it starts with a correct part, but ended it with bogus!\n\nBEF.","upvote_count":"3","comment_id":"1154070","timestamp":"1708356360.0"}],"poster":"Raphaello","upvote_count":"1","timestamp":"1707523620.0","content":"Selected Answer: BDE\nBDE\nCreate a service role to be used by CloudFormation.\nFor each service to be used by the CF stack, create the associated set of permissions.\nAssign the service role to the stack.\n\nThe question does not feel right though, since it mentions all user assume an IAM role to access the account, therefore the stack they launch should use the permissions given to that IAM role, therefore the result should be the same for all users either (they don't launch the stack using their individual IAM users)."},{"poster":"mynickc","upvote_count":"4","content":"I took the exam today (Jan/28) and the choices E & F are two separate as per this question. In some of the comments, it was mentioned that E&F are considered as one choice.","comment_id":"1134239","timestamp":"1706456760.0"},{"content":"Yes, Correct answer is B D F, based on numbers of linked already provided and passrole from ChatGpt.","poster":"brpjp","comment_id":"1110949","upvote_count":"1","timestamp":"1704078360.0"},{"upvote_count":"3","poster":"WeepingMaplte","comment_id":"1100112","content":"Selected Answer: BD\nAns: B D F. \nIn Cloud formation, you select the required role during a new creation. The team members will deploy using the new role. updating the current stacks is not a priority as compared to IAM:PassRole.","timestamp":"1702942080.0"},{"timestamp":"1702521000.0","upvote_count":"2","poster":"Raphaello","content":"B D E\n\nTo be able to update each stack to use the service role (E), user needs to be able to pass the role using iam:PassRole (F).\nBut it is done once.\n\nI would go with E along side B & D.","comment_id":"1095962"},{"comment_id":"1095150","content":"why not A , dont we need a composite principal","upvote_count":"2","timestamp":"1702445280.0","poster":"vincentsr7"},{"comments":[{"poster":"Daniel76","upvote_count":"2","comment_id":"1110965","content":"Consider this article to justify F: passrole is needed so that team member who has limited permission by their own role, can run the stack using service role's permissions.\nhttps://medium.com/@sapna.mandhare/demystifying-iam-passrole-permission-d62a2dc69778","timestamp":"1704085260.0"}],"content":"Selected Answer: BD\nB,D and F.\nhttps://blog.awsfundamentals.com/aws-cloudformation-execution-permissions","timestamp":"1700359260.0","comment_id":"1074398","upvote_count":"1","poster":"Daniel76"},{"timestamp":"1699849440.0","poster":"Ciara123456","upvote_count":"3","content":"BDF, https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-servicerole.html","comment_id":"1069019"},{"comment_id":"1065490","upvote_count":"1","content":"B D And F","timestamp":"1699435680.0","poster":"Lunga778"},{"comment_id":"1059697","content":"BEF\n- Create a CloudFormation service role\n- Update your stack using the role when deploying\n- ensure iam:passrole","comments":[{"timestamp":"1698842640.0","comment_id":"1059698","poster":"Karamen","content":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-servicerole.html","upvote_count":"2"}],"timestamp":"1698842640.0","upvote_count":"3","poster":"Karamen"},{"upvote_count":"3","timestamp":"1698835500.0","content":"Selected Answer: BD\nBDF \nBy creating a service role specifically for AWS CloudFormation, you can limit the permissions to just what CloudFormation needs, and this reduces the risk of excessive permissions or accidental permission conflicts.","poster":"Christina666","comment_id":"1059603"},{"upvote_count":"2","poster":"[Removed]","content":"Selected Answer: BDE\nB, D, E & F (E&F show up as a single option?)\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/least-privilege-cloudformation/service-roles-for-cloudformation.html","timestamp":"1698800820.0","comment_id":"1059292"},{"poster":"KR693","content":"B, D and F","timestamp":"1698127020.0","comment_id":"1052579","upvote_count":"1"}],"exam_id":30,"answer_description":"","topic":"1","choices":{"E":"Update each stack to use the service role.\nF Add a policy to each member role to allow the iam:PassRole action. Set the policy's resource field to the ARN of the service role.","A":"Create a service role that has a composite principal that contains each service that needs the necessary permissions. Configure the role to allow the sts:AssumeRole action.","C":"For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each CloudFormation stack in the resource field of each policy.","D":"For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each service that needs the permissions in the resource field of the corresponding policy.","B":"Create a service role that has cloudformation.amazonaws.com as the service principal. Configure the role to allow the sts:AssumeRole action."},"isMC":true}],"exam":{"provider":"Amazon","isMCOnly":true,"name":"AWS Certified Security - Specialty SCS-C02","isImplemented":true,"id":30,"numberOfQuestions":288,"isBeta":false,"lastUpdated":"11 Apr 2025"},"currentPage":18},"__N_SSP":true}