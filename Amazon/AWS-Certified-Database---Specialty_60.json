{"pageProps":{"questions":[{"id":"vYCylbMgNfFKj2G2NJmV","answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/25680-exam-aws-certified-database-specialty-topic-1-question-41/","answer":"C","unix_timestamp":1594713540,"isMC":true,"question_text":"A company has an Amazon RDS Multi-AZ DB instances that is 200 GB in size with an RPO of 6 hours. To meet the company's disaster recovery policies, the database backup needs to be copied into another Region. The company requires the solution to be cost-effective and operationally efficient.\nWhat should a Database Specialist do to copy the database backup into a different Region?","answers_community":["C (100%)"],"topic":"1","discussion":[{"content":"Answer is C\n\nA. Use Amazon RDS automated snapshots and use AWS Lambda to copy the snapshot into another Region\nAutomated snapshots are taken once per day only, RPO is 6 hours, so not an option\n\nB. Use Amazon RDS automated snapshots every 6 hours and use Amazon S3 cross-Region replication to copy the snapshot into another Region\nYou can not take automated snapshots every 6 hours \n\nC. Create an AWS Lambda function to take an Amazon RDS snapshot every 6 hours and use a second Lambda function to copy the snapshot into another Region\nOnly possible option \n\nD. Create a cross-Region read replica for Amazon RDS in another Region and take an automated snapshot of the read replica\nNot cost-effective, replica is the most expensive DR option.","poster":"Ebi","comment_id":"155253","timestamp":"1632977340.0","comments":[{"comment_id":"157606","timestamp":"1633175160.0","content":"It's hard to choose. A is correct is RDS can restore to point in time, so we don't need to do a snapshot every 6 hours.","upvote_count":"1","poster":"szmulder"},{"timestamp":"1633214220.0","poster":"zanhsieh","upvote_count":"3","comment_id":"159128","content":"Agreed with C. Any options mention / use 'automated snapshot' should be dropped, so no ABD. Verified via AWS console in RDS. Change time interval for RDS automatic backup period to 0 means disable automatic backup. See:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html"}],"upvote_count":"27"},{"content":"Selected Answer: C\nAnser is C.\nD is not the most cost-effective\nA and B are not OK because automated snapshots are only once a day and you need one every 6 hours","upvote_count":"1","poster":"MultiAZ","comment_id":"1121325","timestamp":"1705125060.0"},{"comment_id":"1024243","poster":"SuriSagar","upvote_count":"2","content":"C is the correct answer","timestamp":"1696368540.0"},{"upvote_count":"1","timestamp":"1685601420.0","content":"It would be so much easier to use cross-region backup replication...\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReplicateBackups.html","poster":"aviathor","comment_id":"911809"},{"content":"Copying 200 Gb of snapshot every 6 hours across region will be costlier approach and ensuring lambda to finish job of coping 200gb snapshot with 15 mins is also not viable. \nSo i think D is best choice.","poster":"sachin","timestamp":"1657435260.0","upvote_count":"3","comment_id":"629461"},{"upvote_count":"1","content":"c is right .","comment_id":"605453","timestamp":"1653221880.0","poster":"awsguys"},{"upvote_count":"1","poster":"novice_expert","content":"Selected Answer: C\nx A & B out: only automated snapshot per day allowed we need 4\nC. Create an AWS Lambda function to take an Amazon RDS snapshot every 6 hours and use a second Lambda function to copy the snapshot into another Region (cost effective)\nD. Create a cross-Region read replica for Amazon RDS in another Region and take an automated snapshot of the read replica (costly)","timestamp":"1651349220.0","comment_id":"595250"},{"comment_id":"562194","upvote_count":"1","timestamp":"1646590320.0","content":"Selected Answer: C\nDefinitely (C) - also a question in the pfficial sample exam discussed by Stephen Maarek and Riyaz in their Udemy course","poster":"RotterDam"},{"poster":"Shunpin","comment_id":"510884","content":"Selected Answer: C\nSystem snapshot can't fulfill 6 hours requirement. You need to control it by script\nhttps://aws.amazon.com/blogs/database/%C2%AD%C2%AD%C2%ADautomating-cross-region-cross-account-snapshot-copies-with-the-snapshot-tool-for-amazon-aurora/","upvote_count":"1","timestamp":"1640676660.0"},{"content":"Anyone planning for exam?\nWe can share study material with each other, it would be beneficial for both. You can email me on \"awsdbguru at gmail\"","comment_id":"434026","poster":"guru_ji","timestamp":"1636209120.0","upvote_count":"1"},{"content":"Correct Answer is ==>> C. any idea how much Q we will get in real exam from Q available here? anyone is preparing for this exam and want to do group study with us, comment with mail id.","timestamp":"1636038000.0","upvote_count":"1","poster":"guru_ji","comment_id":"428752"},{"timestamp":"1635943260.0","upvote_count":"1","poster":"ChauPhan","content":"https://aws.amazon.com/blogs/database/implementing-a-disaster-recovery-strategy-with-amazon-rds/\nAutomated Backup is daily, so 6 hour RPO is not possible.\nOnly C is correct.","comment_id":"426225"},{"content":"Answer is C. Reason for eliminating D is that RDS SQL SERVER does not support cross-region read replica and the question does not state which database engine used in RDS.","comment_id":"364770","poster":"Dip11","upvote_count":"1","timestamp":"1635704400.0"},{"poster":"LMax","comment_id":"314880","upvote_count":"2","timestamp":"1635554400.0","content":"Agree with C"},{"upvote_count":"1","timestamp":"1635469740.0","comment_id":"299049","poster":"Windy","content":"I think it is C."},{"comment_id":"298008","timestamp":"1635331020.0","content":"Ans: D with key \"operationally efficient\".\nWith option C, it is necessary to copy 200GB of data from one region to another every 6 hours.","poster":"myutran","upvote_count":"2","comments":[{"timestamp":"1694629560.0","poster":"Germaneli","upvote_count":"1","comment_id":"1006905","content":"With C, it would be required for a Lambda function to copy 200 GB in 15 mins (max execution time) - every 6 hours. It might be feasible given a decent throughput (cross-region!), but that's not guaranteed and there's no mention of the available throughput."}]},{"content":"A - wrong - I guess you cannot copy automated snapshots to another region. You must create a copy of automated snapshot in the same region first.\nB - wrong - automated snapshots are taken once in a day which alone wouldnt meet proposed RPO of 6hrs\nC - best answer for the requirement in hand.\nD - best option for cross region DR. However having a read-replica in another region is costlier than option C","timestamp":"1635276660.0","upvote_count":"1","comment_id":"253214","poster":"JobinAkaJoe"},{"poster":"waterh30","comments":[{"comment_id":"242200","timestamp":"1635251460.0","poster":"waterh30","upvote_count":"1","content":"change to C"}],"content":"ANS: B\nDatabase snapshots are manual (user-initiated) backups of your complete DB instance that serve as full backups. They’re stored in Amazon S3, and are retained until you explicitly delete them. These snapshots can be copied and shared to different Regions and accounts. \nand region replication is fast way. not sure how much cost","timestamp":"1635226620.0","upvote_count":"1","comment_id":"241316"},{"upvote_count":"2","comment_id":"226209","poster":"SAAbbas","timestamp":"1634989680.0","content":"Keep in mind key of \"operational efficient\" two lamda function may be hard to manage. so D."},{"timestamp":"1634724300.0","poster":"Ashoks","content":"C should be.\nSnapshot solution is cost efficient compare to replica. Two lambdas to execute since copy may take long time","comment_id":"212080","upvote_count":"3"},{"poster":"saryu","upvote_count":"2","timestamp":"1634614080.0","comment_id":"191402","content":"C is correct"},{"comments":[{"poster":"jove","upvote_count":"1","comment_id":"508152","content":"Your concern is about RTO, the question asks about RPO.","timestamp":"1640295960.0"}],"comment_id":"187282","content":"The problem with C is creating a snapshot at the last minute/hour and copying to another region. This takes time. What if the main region goes down during this? RPO will not be met. \n\nD seems only possibility then...","upvote_count":"1","poster":"Smart","timestamp":"1634575380.0"},{"poster":"AWSCert2020","content":"Answer is C\nAutomated snapshot are not visible","upvote_count":"2","comment_id":"168173","timestamp":"1634519040.0"},{"comment_id":"153927","content":"Ans A:\nhttps://lgallardo.com/2017/02/11/usando-aws-lambda-para-copiar-snapshots-de-rds-entre-regiones/","poster":"firbhat","upvote_count":"1","timestamp":"1632759240.0"},{"poster":"BillyC","comment_id":"147402","timestamp":"1632503640.0","content":"A is correct","upvote_count":"1"},{"content":"D is wrong because read replicas are too expensive per the table in the following link. A is cheapest according to the table. \nhttps://aws.amazon.com/blogs/database/implementing-a-disaster-recovery-strategy-with-amazon-rds/\nhttps://aws.amazon.com/blogs/database/implementing-a-disaster-recovery-strategy-with-amazon-rds/","upvote_count":"1","comments":[{"comment_id":"161536","content":"Changing answer to C because automated snapshots occur once per day and the RPO goal here is 6 hours.","timestamp":"1633311720.0","poster":"BillyMadison","upvote_count":"4"}],"poster":"BillyMadison","timestamp":"1632406860.0","comment_id":"140572"},{"content":"Ans D is correct while it does not satisfy cost effective.","comment_id":"134671","upvote_count":"1","timestamp":"1632195360.0","poster":"Mickysingh"}],"answer_description":"","question_images":[],"exam_id":22,"timestamp":"2020-07-14 09:59:00","answer_images":[],"question_id":296,"choices":{"D":"Create a cross-Region read replica for Amazon RDS in another Region and take an automated snapshot of the read replica","C":"Create an AWS Lambda function to take an Amazon RDS snapshot every 6 hours and use a second Lambda function to copy the snapshot into another Region","A":"Use Amazon RDS automated snapshots and use AWS Lambda to copy the snapshot into another Region","B":"Use Amazon RDS automated snapshots every 6 hours and use Amazon S3 cross-Region replication to copy the snapshot into another Region"}},{"id":"RorI9LRAhHcogggDirF3","answer_images":[],"unix_timestamp":1595046420,"isMC":true,"timestamp":"2020-07-18 06:27:00","answer_description":"","question_text":"An Amazon RDS EBS-optimized instance with Provisioned IOPS (PIOPS) storage is using less than half of its allocated IOPS over the course of several hours under constant load. The RDS instance exhibits multi-second read and write latency, and uses all of its maximum bandwidth for read throughput, yet the instance uses less than half of its CPU and RAM resources.\nWhat should a Database Specialist do in this situation to increase performance and return latency to sub-second levels?","choices":{"A":"Increase the size of the DB instance storage","D":"Change the DB instance to an instance class with a higher maximum bandwidth","C":"Disable EBS optimization on the DB instance","B":"Change the underlying EBS storage type to General Purpose SSD (gp2)"},"question_id":297,"answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/26019-exam-aws-certified-database-specialty-topic-1-question-42/","answer":"D","question_images":[],"topic":"1","exam_id":22,"discussion":[{"upvote_count":"13","content":"I think this is D\nhttps://docs.amazonaws.cn/en_us/AmazonRDS/latest/UserGuide/CHAP_BestPractices.html\n\"If you are already using Provisioned IOPS storage, provision additional throughput capacity.\" Does D sound right?","comment_id":"140582","timestamp":"1632552960.0","poster":"BillyMadison"},{"upvote_count":"1","comment_id":"1121328","poster":"MultiAZ","timestamp":"1705125180.0","content":"Selected Answer: D\nDefinitely D\nA will not help with the bottleneck, B and C will do things worse"},{"timestamp":"1694689080.0","upvote_count":"2","content":"Selected Answer: D\nD. Change the DB instance to an instance class with a higher maximum bandwidth\n\nthe performance issue in this case is not related to storage nor cpu nor RAM, it is related to network bandwidth.","poster":"Pranava_GCP","comment_id":"1007503"},{"upvote_count":"1","comment_id":"970460","content":"Selected Answer: D\nWe need to understand the difference between throughput and IOPS.\nIOPS – Count of read/write operations per second.\nThroughput – Count of read/write bits per second (bps). This measures the amount of time it takes for a disk to read and write data. Throughput is typically the best storage metric when measuring data that needs to be streamed rapidly, such as images and video files.\nSo it's not about the size (A).\nProvisioned IOPS storage to General Purpose SSD (gp2) (B) - rather worse performance judging by data from https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html\nDisable EBS optimization (E) - rather, it should be activated, if there is such a thing.\nInstance class with a higher maximum bandwidth (D) - we have \"uses all of its maximum bandwidth for read throughput\" in the question. \nWe need to choose another instance class with a higher bandwidth - D.","timestamp":"1691001360.0","poster":"IhorK"},{"content":"Selected Answer: D\nCorrect answer I think","upvote_count":"1","timestamp":"1671464880.0","poster":"lollyj","comment_id":"750003"},{"upvote_count":"2","content":"Selected Answer: D\nObjective is to handle maximum bandwidth for read throughput used\n\nx A. Increase the size of the DB instance storage (unrelated)\nx B. Change the underlying EBS storage type to General Purpose SSD (gp2) (will slow down)\nx C. Disable EBS optimization on the DB instance (will slow down)\nD. Change the DB instance to an instance class with a higher maximum bandwidth\n\nhttps://docs.amazonaws.cn/en_us/AmazonRDS/latest/UserGuide/CHAP_BestPractices.html","poster":"novice_expert","comment_id":"595581","timestamp":"1651405860.0"},{"timestamp":"1649833620.0","comment_id":"585066","upvote_count":"3","content":"Selected Answer: D\nA. Increase the size of the DB instance storage - nonsense; instance is using EBS\nB. Change the underlying EBS storage type to General Purpose SSD (gp2) -> nonsense; GP2 is slower than IO2\nC. Disable EBS optimization on the DB instance -> nonsense; nothing like this exist \n\nD is the answer","poster":"kret"},{"timestamp":"1635241320.0","comment_id":"430196","upvote_count":"1","content":"Correct Answer ==>> D","poster":"guru_ji"},{"upvote_count":"1","content":"My answer is D","poster":"LMax","timestamp":"1634243220.0","comment_id":"314888"},{"timestamp":"1634037000.0","comment_id":"298010","upvote_count":"1","content":"Ans: D","poster":"myutran"},{"poster":"RSSRAO","upvote_count":"1","content":"Answer is D","comment_id":"286288","timestamp":"1633918800.0"},{"poster":"JobinAkaJoe","comment_id":"253219","content":"D is the right answer","timestamp":"1633783080.0","upvote_count":"1"},{"timestamp":"1633664940.0","poster":"Ashoks","content":"D. For high throughput.","comment_id":"212083","upvote_count":"2"},{"upvote_count":"1","comment_id":"168177","content":"D here! Throughput is related to Size/Type of Instance\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html","poster":"AWSCert2020","timestamp":"1633599120.0"},{"upvote_count":"1","comment_id":"168175","poster":"AWSCert2020","timestamp":"1633138860.0","content":"Throughput is related to Size/Type of Instance\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html"},{"poster":"BillyC","content":"Sorry i mean D","upvote_count":"2","comment_id":"144908","timestamp":"1632810780.0"},{"content":"Ans B here","timestamp":"1632694380.0","upvote_count":"1","poster":"BillyC","comment_id":"141354"}],"answer_ET":"D"},{"id":"TksflS3TQoPftFC6k3bE","question_id":298,"choices":{"D":"The production DB instance is using a custom option group","B":"The production DB instance is using a custom parameter group","A":"The restored DB instance does not have Enhanced Monitoring enabled","C":"The restored DB instance is using the default security group"},"answers_community":["C (88%)","13%"],"timestamp":"2020-07-15 15:01:00","question_images":[],"answer":"C","topic":"1","discussion":[{"timestamp":"1633132920.0","comments":[{"poster":"BillyMadison","upvote_count":"3","content":"C, agree.","comment_id":"140588","timestamp":"1633223700.0"}],"poster":"learnaws","comment_id":"137636","upvote_count":"12","content":"C.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.html"},{"content":"C is correct","upvote_count":"5","timestamp":"1632554520.0","poster":"BillyC","comment_id":"135718"},{"timestamp":"1696512480.0","upvote_count":"1","comment_id":"1025703","poster":"Sathish_dbs","content":"is it misleading us to assume that the DB connected for first three days?"},{"upvote_count":"1","content":"Selected Answer: C\nC is correct","comment_id":"1021393","poster":"narvaez","timestamp":"1696069380.0"},{"comment_id":"936469","content":"Selected Answer: C\nhow do we know what parameter or option groups source rds is using so assuming security group mismatch because even parameter or option group mismatch also if securrity group is correct one we can make the connections","timestamp":"1687946700.0","upvote_count":"1","poster":"saikarthikeya777"},{"content":"Selected Answer: C\nIt is C.","poster":"Kodoma","comment_id":"904512","timestamp":"1684811400.0","upvote_count":"1"},{"comment_id":"630527","poster":"Chirantan","content":"When you restore a DB instance, the default virtual private cloud (VPC), DB subnet group, and VPC security group are associated with the restored instance, unless you choose different ones.","upvote_count":"3","timestamp":"1657629540.0"},{"poster":"novice_expert","content":"Selected Answer: B\nC and B both have incomplete info, would go with B assuming that PROD is the source, and custom parameter group not selected or changed from default for restored one\n\nx A. Enhanced Monitoring enabled (unrelated - for performance check)\nB. The production DB instance is using a custom parameter group (would be correct if it was the source)\nx C. The restored DB instance is using the default security group (but would not be issue if source also had default)\nx D. The production DB instance is using a custom option group (unrelated - it can specify features, called options, that are available for a particular Amazon RDS DB instance)\n\nhttps://aws.amazon.com/about-aws/whats-new/2018/10/specify-parameter-groups-when-restoring-amazon-rds-backups/","comment_id":"595576","comments":[{"comment_id":"595578","upvote_count":"2","poster":"novice_expert","content":"Correction: Ans is C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.html\n\nWhen you restore a DB instance, the default virtual private cloud (VPC), DB subnet group, and VPC security group are associated with the restored instance, unless you choose different ones.","timestamp":"1651405500.0"}],"timestamp":"1651405320.0","upvote_count":"1"},{"content":"Selected Answer: C\nSG is most typically the cause of an connection issue","poster":"kret","comment_id":"585067","upvote_count":"4","timestamp":"1649833680.0"},{"timestamp":"1643477460.0","comment_id":"535621","upvote_count":"1","poster":"soyyodario","content":"C, but B........\n\nParameter group considerations\n\nWe recommend that you retain the DB parameter group for any DB snapshots you create, so that you can associate your restored DB instance with the correct parameter group.\n\nThe default DB parameter group is associated with the restored instance, unless you choose a different one. No custom parameter settings are available in the default parameter group.\n\nYou can specify the parameter group when you restore the DB instance."},{"timestamp":"1635869700.0","content":"Omit B, D regarding PROD DB\nA is not relevant.\nC is correct.","comment_id":"426229","poster":"ChauPhan","upvote_count":"3"},{"comments":[{"comment_id":"414336","poster":"gelsm","upvote_count":"1","timestamp":"1635811080.0","content":"https://aws.amazon.com/premiumsupport/knowledge-center/rds-cannot-connect/"}],"poster":"gelsm","upvote_count":"2","comment_id":"414329","timestamp":"1635029160.0","content":"C. The restored DB instance is using the default security group\n\nThis is likely the cause of the problem since security groups control the connectivity to the DB instance."},{"content":"Answer C","timestamp":"1634956320.0","poster":"LMax","comment_id":"314889","upvote_count":"4"},{"upvote_count":"2","content":"Ans: C","timestamp":"1634825400.0","poster":"myutran","comment_id":"298014"},{"content":"C is correct","poster":"kubilay","comment_id":"295049","timestamp":"1634042340.0","upvote_count":"2"},{"comment_id":"253223","poster":"JobinAkaJoe","content":"C is the correct answer","timestamp":"1633929060.0","upvote_count":"2"},{"upvote_count":"3","content":"yes. C. SG controls the access.","comment_id":"212085","poster":"Ashoks","timestamp":"1633910460.0"},{"upvote_count":"2","content":"C Here","poster":"AWSCert2020","comment_id":"168179","timestamp":"1633388280.0"}],"answer_description":"","unix_timestamp":1594818060,"question_text":"After restoring an Amazon RDS snapshot from 3 days ago, a company's Development team cannot connect to the restored RDS DB instance. What is the likely cause of this problem?","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/25820-exam-aws-certified-database-specialty-topic-1-question-43/","exam_id":22,"answer_images":[],"answer_ET":"C"},{"id":"HkKyhzhVQRzy2GPe61dx","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/67555-exam-aws-certified-database-specialty-topic-1-question-44/","question_images":[],"choices":{"A":"Enable cluster mode on the existing ElastiCache cluster and configure separate shards for the Sorted Set across all nodes in the cluster.","B":"Increase the size of the ElastiCache cluster nodes to a larger instance size.","D":"Use the EXPIRE command and set a higher time to live (TTL) after each call to increment a given key.","C":"Create an additional ElastiCache cluster and load-balance traffic between the two clusters."},"discussion":[{"upvote_count":"5","comment_id":"595245","timestamp":"1651348620.0","poster":"novice_expert","content":"Selected Answer: B\ncannot enable Cluster Mode on an existing cluster, With cluster mode disabled it will allow only vertical scaling."},{"comment_id":"1091177","timestamp":"1702051800.0","upvote_count":"3","content":"Selected Answer: A\nElasticache now supports enabling cluster mode on existing clusters.\nhttps://aws.amazon.com/about-aws/whats-new/2023/05/amazon-elasticache-redis-cluster-mode-configuration-existing-clusters/#:~:text=Amazon%20ElastiCache%20for%20Redis%20now%20supports%20enabling%20Cluster%20Mode%20configuration%20on%20existing%20clusters,-Posted%20On%3A%20May&text=You%20can%20now%20update%20your,data%2C%20or%20affect%20application%20availability.","poster":"rrshah83"},{"poster":"luckybme","upvote_count":"3","timestamp":"1698399600.0","content":"Selected Answer: A\nElasticache now supports enabling cluster mode on existing clusters. \nhttps://aws.amazon.com/about-aws/whats-new/2023/05/amazon-elasticache-redis-cluster-mode-configuration-existing-clusters/#:~:text=Amazon%20ElastiCache%20for%20Redis%20now%20supports%20enabling%20Cluster%20Mode%20configuration%20on%20existing%20clusters,-Posted%20On%3A%20May&text=You%20can%20now%20update%20your,data%2C%20or%20affect%20application%20availability.","comment_id":"1055393"},{"timestamp":"1693570320.0","content":"Selected Answer: B\nB. Increase the size of the ElastiCache cluster nodes to a larger instance size.\n\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Scaling.RedisReplGrps.html","comment_id":"996030","poster":"Pranava_GCP","upvote_count":"1"},{"poster":"nehacool29","content":"Selected Answer: C\nC is correct","timestamp":"1688217480.0","comment_id":"939975","upvote_count":"1"},{"content":"Option B (increasing the size of cluster nodes) can provide some level of scaling, but it may have limitations in terms of the maximum capacity it can handle. Additionally, simply increasing the node size may not fully address the anticipated higher write load during the gaming event.\nOption C: Creating an additional ElastiCache cluster and load-balancing traffic between the clusters allows for distributing the write load across multiple clusters, effectively scaling the capacity and handling increased demand. This approach provides horizontal scalability and helps mitigate the potential performance limitations of a single cluster.\n\nWhy not C?","timestamp":"1685994480.0","poster":"dnelub","comment_id":"915708","upvote_count":"1"},{"comment_id":"702481","content":"B\n\nRedis (cluster mode disabled) supports scaling. You can scale read capacity by adding or deleting replica nodes, or you can scale capacity by scaling up to a larger node type.","poster":"rags1482","upvote_count":"2","timestamp":"1666560960.0"},{"comment_id":"620959","poster":"ryuhei","content":"Selected Answer: B\nAnswer:B","upvote_count":"1","timestamp":"1655986320.0"},{"poster":"RotterDam","timestamp":"1646590080.0","content":"Selected Answer: B\nB is correct. You cannot enable Cluster Mode on an existing cluster","upvote_count":"4","comments":[{"comment_id":"1096910","poster":"NishithShah","upvote_count":"1","content":"Cluster mode configuration can only be changed from cluster mode disabled to cluster mode enabled. Reverting this configuration is not possible.\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/modify-cluster-mode.html","timestamp":"1702597620.0"}],"comment_id":"562191"},{"poster":"mayank830","upvote_count":"1","content":"https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Replication.Redis-RedisCluster.html\n\nReads v. writes – If the primary load on your cluster is applications reading data, you can scale a Redis (cluster mode disabled) cluster by adding and deleting read replicas. However, there is a maximum of 5 read replicas. If the load on your cluster is write-heavy, you can benefit from the additional write endpoints of a Redis (cluster mode enabled) cluster with multiple shards.","timestamp":"1645390140.0","comment_id":"552275"},{"poster":"jeyp12","comment_id":"542944","content":"I think answer is B. With cluster mode disabled it will allow only vertical scaling. So going with B","upvote_count":"2","timestamp":"1644310560.0"},{"comments":[{"poster":"VPup","upvote_count":"2","timestamp":"1644261600.0","content":"you can not enable the cluster mode on the already running Elasticache cluster. Have to provision a new cluster with the Cluster mode enabled and restore the backed up data from S3.","comment_id":"542628"}],"content":"A is the correct answer\nEnabling Cluster Mode provides a number of additional benefits in scaling your cluster. In short, it allows you to scale in or out the number of shards (horizontal scaling) versus scaling up or down the node type (vertical scaling). This means that Cluster Mode can scale to very large amounts of storage (potentially 100s of terabytes) across up to 90 shards, whereas a single node can only store as much data in memory as the instance type has capacity for.\nhttps://aws.amazon.com/blogs/database/work-with-cluster-mode-on-amazon-elasticache-for-redis/","upvote_count":"2","comment_id":"498598","timestamp":"1639138440.0","poster":"2025flakyt"}],"question_text":"A gaming company has implemented a leaderboard in AWS using a Sorted Set data structure within Amazon ElastiCache for Redis. The ElastiCache cluster has been deployed with cluster mode disabled and has a replication group deployed with two additional replicas. The company is planning for a worldwide gaming event and is anticipating a higher write load than what the current cluster can handle.\nWhich method should a Database Specialist use to scale the ElastiCache cluster ahead of the upcoming event?","answers_community":["B (61%)","A (33%)","6%"],"answer_images":[],"topic":"1","question_id":299,"timestamp":"2021-12-10 13:14:00","isMC":true,"exam_id":22,"unix_timestamp":1639138440,"answer":"B","answer_ET":"B"},{"id":"AjDTcRUpSfZK9X9sCKl0","answer_ET":"D","unix_timestamp":1595364000,"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/26361-exam-aws-certified-database-specialty-topic-1-question-45/","isMC":true,"question_text":"An ecommerce company has tasked a Database Specialist with creating a reporting dashboard that visualizes critical business metrics that will be pulled from the core production database running on Amazon Aurora. Data that is read by the dashboard should be available within 100 milliseconds of an update.\nThe Database Specialist needs to review the current configuration of the Aurora DB cluster and develop a cost-effective solution. The solution needs to accommodate the unpredictable read workload from the reporting dashboard without any impact on the write availability and performance of the DB cluster.\nWhich solution meets these requirements?","answers_community":["D (92%)","8%"],"topic":"1","discussion":[{"upvote_count":"7","timestamp":"1651178280.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html\n\nreplica lag < 100 ms\n\nOption A would take time","comment_id":"594043","poster":"novice_expert"},{"upvote_count":"3","poster":"Pranava_GCP","comment_id":"996046","timestamp":"1693571280.0","content":"Selected Answer: D\nD. Add an automatic scaling policy to the DB cluster to add Aurora Replicas to the cluster based on CPU consumption.\n\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html"},{"comment_id":"913776","content":"agree it's D...there is no 'serverless turn on ' option exist\nFor example, take a scaling policy that uses the predefined average CPU utilization metric. Such a policy can keep CPU utilization at, or close to, a specified percentage of utilization, such as 40 percent.","timestamp":"1685808000.0","poster":"manig","upvote_count":"3"},{"upvote_count":"1","timestamp":"1671499260.0","comment_id":"750378","poster":"IBANGA007","content":"Selected Answer: C\nC. Create a separate DB cluster for the new workload, refresh from the source DB cluster, and set up ongoing replication using AWS DMS change data capture (CDC)."},{"content":"Selected Answer: D\nEven though replication is asynchronous I believe it is within the 100 ms requirement. It is also cost effective with autoscaling.","timestamp":"1671469020.0","upvote_count":"1","comment_id":"750057","poster":"lollyj"},{"timestamp":"1651889520.0","upvote_count":"1","content":"Selected Answer: D\nOption A? How can you use serverless and scale in the same statement","comment_id":"597943","poster":"KaranGandhi30"},{"poster":"VPup","upvote_count":"3","timestamp":"1644194640.0","comment_id":"542093","content":"Answer D\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html\n\n\"As a result, all Aurora Replicas return the same data for query results with minimal replica lag. This lag is usually much less than 100 milliseconds after the primary instance has written an update. \""},{"timestamp":"1635785160.0","content":"Option D makes most sense.","upvote_count":"2","poster":"Dip11","comment_id":"364812"},{"content":"Answer D","timestamp":"1635610140.0","comment_id":"314902","upvote_count":"4","poster":"LMax"},{"poster":"myutran","content":"Ans: D","comment_id":"298020","timestamp":"1635259740.0","upvote_count":"3"},{"poster":"Robbb","upvote_count":"3","timestamp":"1635175680.0","content":"A is a ridiculous answer. If you say A, don't bother taking the test.","comment_id":"277439","comments":[{"comments":[{"content":"The answer is saying \"Turn on Serverless option on the cluster\". There's no such thing.","timestamp":"1646524980.0","upvote_count":"1","comment_id":"561703","poster":"RotterDam"},{"poster":"[Removed]","upvote_count":"5","content":"you can't turn on serverless option.you need to take a snapshot and restore it to Aurora Serverless. A is definitely wrong","timestamp":"1635665040.0","comment_id":"352391"}],"upvote_count":"4","content":"Oh, I love this your response...... Option A seems to make the most sense to me and I will take the test\nHere is a link to help with the correct response -- https://aws.amazon.com/rds/aurora/faqs/ \n\nAmazon Aurora Serverless is an on-demand, autoscaling configuration for the MySQL-compatible and PostgreSQL-compatible editions of Amazon Aurora. An Aurora Serverless DB cluster automatically starts up, shuts down, and scales capacity up or down based on your application's needs. Aurora Serverless provides a relatively simple, cost-effective option for infrequent, intermittent, or unpredictable workloads. \nThe question is focused on unpredictable workloads","timestamp":"1635250140.0","comment_id":"291354","poster":"GeeBeeEl"}]},{"comments":[{"comment_id":"479416","poster":"toppic26","upvote_count":"1","content":"it says read workload, not write.","timestamp":"1637071440.0"}],"upvote_count":"1","poster":"Robbb","timestamp":"1635055680.0","content":"Also it says that the new workload is unpredictable, and yet should have no impact on the current operations. It takes time to adjust to unpredictable workloads, so D does not solve the stated problem.","comment_id":"277438"},{"content":"B is the best choice. A cloned Cluster will use the existing DB cluster until those items are written over, so that will have the fastest, immediate response. The best solution, of course, is to dedicate a read replica to the team and use an instance endpoint. D does not directly address the issue.","timestamp":"1634823660.0","comment_id":"277435","comments":[{"comment_id":"364822","upvote_count":"3","content":"Clone is a one time copy, it does not continuously replicate which is a requirement here.","timestamp":"1636006380.0","poster":"Dip11"}],"upvote_count":"1","poster":"Robbb"},{"content":"Why can't B be an option? Create a clone of the Aurora cluster and use the clone for data read on the Dashboard?","upvote_count":"1","comment_id":"272847","timestamp":"1634322300.0","poster":"Glendon","comments":[{"upvote_count":"1","poster":"AM","content":"B is not an option since clone does not support read scaling of the same cluster. This question is on read scaling of Aurora cluster. Only achieved with Read replicas. Serverless as pointed out is not available as an option. Correct an D.","comment_id":"277391","timestamp":"1634704800.0"}]},{"timestamp":"1634113260.0","poster":"Faz","comment_id":"257234","content":"Ans is D.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html#:~:text=The%20scaling%20policy%20defines%20the,CloudWatch%20metrics%20and%20target%20values.","upvote_count":"2"},{"timestamp":"1633975620.0","content":"D is the best choice","upvote_count":"2","comment_id":"253235","poster":"JobinAkaJoe"},{"comment_id":"246914","poster":"kilkar","timestamp":"1633753800.0","upvote_count":"3","content":"Ashoks is right. There is no turn on option to Serverless, it needs migration"},{"content":"Within A or D. I prefer A as an answer. \nSince the problem-statement is about a cost-effective solution with less than 100-millisecond read latency. AWS highlight Serverless as the most cost-effective solution (even though the pricing model looks high)\n\nhttps://www.youtube.com/results?search_query=Aurora+AWS","poster":"kilkar","comments":[{"timestamp":"1640208180.0","poster":"jove","upvote_count":"1","content":"There is no such a \"serverless option\" to turn on or off for an existing Aurora cluster. \nCorrect answer is D","comment_id":"507393"}],"upvote_count":"1","comment_id":"246683","timestamp":"1633731240.0"},{"content":"D should be. Serverless requires migration and no turn on option","comment_id":"212093","upvote_count":"2","poster":"Ashoks","timestamp":"1633696620.0"},{"timestamp":"1633624320.0","upvote_count":"1","content":"D Here, because the Aurora Serverless is a different models that require a new cluster with related data import.","poster":"AWSCert2020","comment_id":"168216"},{"poster":"awscamus","content":"D is the answer.","upvote_count":"2","comment_id":"158637","timestamp":"1633331940.0"},{"timestamp":"1633059960.0","content":"A is not correct: you can not enable serverless as an option. Serverless is a type of cluster not an option to enable/disable.\nCorrect answer is D.","upvote_count":"4","poster":"Ebi","comment_id":"156271"},{"comment_id":"154010","poster":"sonobab","content":"A is not the answer. \nhttps://aws.amazon.com/rds/aurora/faqs/\nQ: Can I migrate an existing Aurora DB cluster to Aurora Serverless?\n\nYes, you can restore a snapshot taken from an existing Aurora provisioned cluster into an Aurora Serverless DB Cluster (and vice versa).\n\n\nAurora autoscaling is the option.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html","timestamp":"1632797220.0","upvote_count":"3"},{"timestamp":"1632744960.0","upvote_count":"1","poster":"BillyC","content":"A is correct for me","comment_id":"145811"},{"poster":"SaulGoodman","timestamp":"1632709260.0","upvote_count":"1","comment_id":"141738","content":"well none of the answers are correct.\nWe should take a snapshot of Aurora and then create the serverless Aurora based on that snapshot. And we have to take care of the version.\nhttps://aws.amazon.com/rds/aurora/faqs/?nc=sn&loc=6"},{"comment_id":"141599","content":"A and D can do it, A is better.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless.how-it-works.html\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html#Aurora.Integrating.AutoScaling.Add","timestamp":"1632278460.0","upvote_count":"2","poster":"lui"},{"timestamp":"1632174240.0","content":"A actually seems correct.\nhttps://aws.amazon.com/rds/aurora/serverless/\nThoughts?","poster":"BillyMadison","comment_id":"140609","comments":[{"timestamp":"1633513860.0","comment_id":"161560","content":"Switching answer to D. Serverless isn't an option to enable or disable. It is another completely different database option. Since there already is an aurora database, we should simply add an autoscaling policy. \n\"To meet your connectivity and workload requirements, Aurora Auto Scaling dynamically adjusts the number of Aurora Replicas provisioned for an Aurora DB cluster using single-master replication. Aurora Auto Scaling is available for both Aurora MySQL and Aurora PostgreSQL. Aurora Auto Scaling enables your Aurora DB cluster to handle sudden increases in connectivity or workload. When the connectivity or workload decreases, Aurora Auto Scaling removes unnecessary Aurora Replicas so that you don't pay for unused provisioned DB instances.\"\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless.html#aurora-serverless.limitations","comments":[{"comment_id":"164415","timestamp":"1633540320.0","content":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html#Aurora.Integrating.AutoScaling.Concepts","upvote_count":"1","poster":"cloud4gr8"}],"upvote_count":"7","poster":"BillyMadison"}],"upvote_count":"2"}],"answer_description":"","question_images":[],"exam_id":22,"timestamp":"2020-07-21 22:40:00","answer_images":[],"choices":{"B":"Provision a clone of the existing DB cluster for the new Application team.","D":"Add an automatic scaling policy to the DB cluster to add Aurora Replicas to the cluster based on CPU consumption.","A":"Turn on the serverless option in the DB cluster so it can automatically scale based on demand.","C":"Create a separate DB cluster for the new workload, refresh from the source DB cluster, and set up ongoing replication using AWS DMS change data capture (CDC)."},"question_id":300}],"exam":{"provider":"Amazon","id":22,"lastUpdated":"11 Apr 2025","name":"AWS Certified Database - Specialty","numberOfQuestions":359,"isImplemented":true,"isBeta":false,"isMCOnly":false},"currentPage":60},"__N_SSP":true}