{"pageProps":{"questions":[{"id":"9O6Uf63ehTGqTOxjWIE7","question_id":751,"timestamp":"2024-02-06 18:21:00","isMC":true,"question_images":[],"unix_timestamp":1707240060,"answer_ET":"C","discussion":[{"comment_id":"1195707","content":"Selected Answer: C\nA. Enable termination protection for the EC2 instance.\nNo. Termination protection is about avoid accidentally delete the instance\n\nB. Configure the EC2 instance for Multi-AZ deployment.\nNo. Question says \"cannot run on more than one instance\"\n\nC. Create an Amazon CloudWatch alarm to recover the EC2 instance in case of failure.\nYes. CloudWatch can be used to recover the instance: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/UsingAlarmActions.html#AddingRecoverActions\n\nD. Launch the EC2 instance with two Amazon Elastic Block Store (Amazon EBS) volumes that use RAID configurations for storage redundancy.\nNo. Raid could be helpful to increase resilience, but does not help with \"improve the recovery time\"","upvote_count":"15","poster":"[Removed]","timestamp":"1713132780.0"},{"upvote_count":"8","poster":"Andy_09","content":"Option C","comments":[{"comment_id":"1151818","content":"i think D is the answer.\nCause the question asks for a resilient solution and EBS with RAID config can balance between the performance and redundancy. EBS can also help with faster launch.","upvote_count":"2","poster":"Typewriter101","comments":[{"poster":"MatAlves","comment_id":"1286026","upvote_count":"2","content":"But how does that \"improve the recovery time for the system\"?","timestamp":"1726697760.0"},{"upvote_count":"3","comment_id":"1157999","content":"Your solution can't resolve the problem","poster":"_mavik_","timestamp":"1708787160.0"}],"timestamp":"1708071180.0"}],"comment_id":"1142404","timestamp":"1707240060.0"},{"poster":"buzzinmumbai","comment_id":"1190082","upvote_count":"1","timestamp":"1712350200.0","content":"Option should be B .They are not asking about storage anywhere. In muti-AZ you application runs on the primary and the secondary is kept in sync."},{"poster":"mohammadthainat","timestamp":"1712201940.0","comment_id":"1189054","content":"Selected Answer: C\nQuestion about \"\"\"improve the recovery time for the system\"\"\" RAID improves data resilience, but won't recover the instance if the system itself fails. it's 100% C","upvote_count":"5"},{"upvote_count":"3","comment_id":"1184885","content":"Pretty sure option D is NOT correct.\n\n> RAID 5 and RAID 6 are not recommended for Amazon EBS (...).\n> RAID 1 is also not recommended for use with Amazon EBS.\n\nhttps://docs.aws.amazon.com/ebs/latest/userguide/raid-config.html#raid-config-options","timestamp":"1711643220.0","comments":[{"content":"So what is the answer?","upvote_count":"2","comments":[{"timestamp":"1735802280.0","comment_id":"1335385","upvote_count":"1","comments":[{"comment_id":"1335391","poster":"Salilgen","content":"Sorry. Answer is C.\nIn multi-AZ deployment you must have at least one instance per AZ","timestamp":"1735803660.0","upvote_count":"1"}],"poster":"Salilgen","content":"IMO answer is B.\nYou could set Max desired capacity to 1 in autoscaling group then you always have one instance running"},{"comment_id":"1202589","upvote_count":"3","timestamp":"1714135500.0","content":"C: You can create an Amazon CloudWatch alarm that monitors an Amazon EC2 instance and automatically recovers the instance if it becomes impaired due to an underlying hardware failure or a problem that requires AWS involvement to repair. Terminated instances cannot be recovered. A recovered instance is identical to the original instance, including the instance ID, private IP addresses, Elastic IP addresses, and all instance metadata.","poster":"sandordini"}],"poster":"Awsbeginner87","comment_id":"1188047","timestamp":"1712062740.0"}],"poster":"dkw2342"},{"content":"For those who choose C, the question asks that \"must design a resilient solution\".. C may improve recovery time but it has nothing to do with resiliency.","timestamp":"1710518580.0","comments":[{"poster":"JackyCCK","comment_id":"1188127","content":"\"resilient solution that can improve the recovery time for the system\" , resiliency here means only","timestamp":"1712070840.0","upvote_count":"2"}],"upvote_count":"1","poster":"haci","comment_id":"1174365"},{"comment_id":"1157998","content":"Option C","upvote_count":"2","timestamp":"1708787040.0","poster":"_mavik_"},{"comment_id":"1154735","poster":"stephensimudemy","content":"Selected Answer: C\nCan only run 1 instance.\nimprove recovery time.","timestamp":"1708435140.0","upvote_count":"2"},{"comment_id":"1154731","content":"Option B.\nQuestion never ask anything about storage.","poster":"stephensimudemy","timestamp":"1708434960.0","upvote_count":"1"},{"timestamp":"1708228140.0","poster":"osmk","comment_id":"1153022","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/raid-config.html","upvote_count":"6"}],"answer":"C","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/133082-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","answers_community":["C (79%)","D (21%)"],"exam_id":31,"question_text":"A company is running a legacy system on an Amazon EC2 instance. The application code cannot be modified, and the system cannot run on more than one instance. A solutions architect must design a resilient solution that can improve the recovery time for the system.\n\nWhat should the solutions architect recommend to meet these requirements?","answer_description":"","choices":{"D":"Launch the EC2 instance with two Amazon Elastic Block Store (Amazon EBS) volumes that use RAID configurations for storage redundancy.","B":"Configure the EC2 instance for Multi-AZ deployment.","A":"Enable termination protection for the EC2 instance.","C":"Create an Amazon CloudWatch alarm to recover the EC2 instance in case of failure."}},{"id":"v9ZBXPjPnCLrK891mdP4","question_text":"A company wants to deploy its containerized application workloads to a VPC across three Availability Zones. The company needs a solution that is highly available across Availability Zones. The solution must require minimal changes to the application.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","unix_timestamp":1707166200,"url":"https://www.examtopics.com/discussions/amazon/view/132948-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"A":"Use Amazon Elastic Container Service (Amazon ECS). Configure Amazon ECS Service Auto Scaling to use target tracking scaling. Set the minimum capacity to 3. Set the task placement strategy type to spread with an Availability Zone attribute.","C":"Use Amazon EC2 Reserved Instances. Launch three EC2 instances in a spread placement group. Configure an Auto Scaling group to use target tracking scaling. Set the minimum capacity to 3.","D":"Use an AWS Lambda function. Configure the Lambda function to connect to a VPC. Configure Application Auto Scaling to use Lambda as a scalable target. Set the minimum capacity to 3.","B":"Use Amazon Elastic Kubernetes Service (Amazon EKS) self-managed nodes. Configure Application Auto Scaling to use target tracking scaling. Set the minimum capacity to 3."},"answer_description":"","answer_images":[],"answers_community":["A (100%)"],"exam_id":31,"answer":"A","timestamp":"2024-02-05 21:50:00","question_images":[],"question_id":752,"topic":"1","isMC":true,"answer_ET":"A","discussion":[{"upvote_count":"9","poster":"osmk","timestamp":"1708229520.0","content":"Selected Answer: A\nAmazon EKS self-managed nodes require you to manually install and configure the Kubernetes node components, such as kubelet, kube-proxy, and Docker, on your Amazon EC2 instances. You also need to manage the security group, IAM role, and subnet for your node group. Amazon ECS handles these tasks for you when you use the Amazon EC2 launch type .","comment_id":"1153030","comments":[{"comment_id":"1239052","upvote_count":"1","poster":"EdricHoang","content":"but it requires minimum change in application. I believe when changing to ECS, its a huge change","timestamp":"1719639780.0"}]},{"content":"Selected Answer: A\nContainerized.. = ECS","timestamp":"1725893820.0","comment_id":"1280995","poster":"ajwksdldfgdsg","upvote_count":"1"},{"comment_id":"1168097","poster":"1dd","content":"why not lambda?","timestamp":"1709822220.0","comments":[{"content":"Containerized... The solution must require minimal changes to the application.","timestamp":"1714659660.0","poster":"Sergiuss95","comment_id":"1205640","upvote_count":"1"},{"poster":"khoahoang","timestamp":"1712038260.0","content":"lamda dont have containerized","comment_id":"1187877","upvote_count":"2"}],"upvote_count":"1"},{"upvote_count":"2","content":"Option A","timestamp":"1707166200.0","comment_id":"1141467","poster":"Andy_09"}]},{"id":"fB1A7pmM0y0i33tYGK8K","answer_description":"","exam_id":31,"timestamp":"2024-02-05 21:52:00","isMC":true,"answers_community":["B (55%)","C (36%)","9%"],"answer":"B","choices":{"D":"Store newer movie video files in S3 Standard. Store older movie video files in S3 Glacier Flexible Retrieval. When a user orders an older movie, retrieve the video file by using bulk retrieval.","A":"Store all media content in Amazon S3. Use S3 Lifecycle policies to move media data into the Infrequent Access tier when the demand for a movie decreases.","C":"Store newer movie video files in S3 Intelligent-Tiering. Store older movie video files in S3 Glacier Flexible Retrieval. When a user orders an older movie, retrieve the video file by using expedited retrieval.","B":"Store newer movie video files in S3 Standard. Store older movie video files in S3 Standard-infrequent Access (S3 Standard-IA). When a user orders an older movie, retrieve the video file by using standard retrieval."},"unix_timestamp":1707166320,"answer_images":[],"question_text":"A media company stores movies in Amazon S3. Each movie is stored in a single video file that ranges from 1 GB to 10 GB in size.\n\nThe company must be able to provide the streaming content of a movie within 5 minutes of a user purchase. There is higher demand for movies that are less than 20 years old than for movies that are more than 20 years old. The company wants to minimize hosting service costs based on demand.\n\nWhich solution will meet these requirements?","question_images":[],"answer_ET":"B","discussion":[{"upvote_count":"16","poster":"Freddie26","timestamp":"1708044360.0","content":"Technically, expedited retrieval for files is not guaranteed within 1-5 minutes for files larger than 250 MB+. See https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html.","comment_id":"1151655"},{"timestamp":"1708230960.0","content":"Selected Answer: B\nS3 Standard-IA is for data that is accessed less frequently, but requires rapid access when needed. S3 Standard-IA offers the high durability, high throughput, and low latency of S3 Standard, with a low per GB storage price and per GB retrieval chargehttps://aws.amazon.com/s3/storage-classes/","upvote_count":"12","comment_id":"1153033","poster":"osmk"},{"upvote_count":"1","poster":"tch","comment_id":"1366224","timestamp":"1741345080.0","content":"Selected Answer: C\nS3 Standard-infrequent Access (S3 Standard-IA) do not come with retrieval options??\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html"},{"upvote_count":"1","timestamp":"1739249280.0","poster":"zdi561","content":"Selected Answer: C\nGlacier flex expedited retrieval takes 1-5 min.","comment_id":"1354844"},{"content":"Selected Answer: B\nS3 Glacier Flexible Retrieval cannot grant the retrieval within 5 minutes even with expedited retrieval. Intellgent-Tiering is for unknow pattern, however, we already know higher demand for movies that are less than 20 years old than for movies that are more than 20 years old.","poster":"FlyingHawk","upvote_count":"1","timestamp":"1737669600.0","comment_id":"1345688"},{"poster":"LeonSauveterre","comment_id":"1331040","content":"Selected Answer: B\nA - Cost optimization for > 20-yr-old files is insufficient.\nB - Good. Although, S3 Standard-IA is still relatively expensive compared to archival classes.\nC - Glacier Flexible Retrieval may not consistently meet the 5-minute streaming requirement. Could be minutes, could be hours.\nD - Bulk retrieval typically takes hours, let alone 5 minutes.","comments":[{"comment_id":"1402137","poster":"tch","timestamp":"1742711100.0","upvote_count":"1","content":"this is the reason we choose C as answer! S3 Glacier Flexible Retrieval has option with 5 minutes time called expedited retrieval.\n S3 Standard-IA do not come with option to retrieve data.... please check ..... \nhttps://aws.amazon.com/s3/storage-classes/glacier/"}],"timestamp":"1735021320.0","upvote_count":"3"},{"upvote_count":"1","poster":"Arad","timestamp":"1732757280.0","comment_id":"1318976","content":"Selected Answer: C\nC is the correct answer."},{"upvote_count":"2","content":"A is most correct ✅","comment_id":"1268219","timestamp":"1724016900.0","poster":"Abdullah2004"},{"comment_id":"1239055","poster":"EdricHoang","content":"Selected Answer: B\n\"Expedited Retrieval, you can retrieve small amounts of data (up to 250 MB per request) within 1-5 minutes.\"\nCannot C","upvote_count":"8","timestamp":"1719640080.0"},{"poster":"NSA_Poker","comment_id":"1231115","upvote_count":"6","timestamp":"1718482140.0","content":"Selected Answer: B\n(A) is eliminated. Demand metric is popularly based & cannot be configured with Lifecycle policies. Ex: an old movie can have resurgent demand 20 years after it's sequel is released.\n(C) is eliminated. Expedited retrieval is for all but the largest archived objects (250 MB+). \n(D) is eliminated. Bulk retrieval takes hours.\n(B) is more expensive than S3 Glacier Flexible Retrieval but it's the only one that works."},{"poster":"bujuman","timestamp":"1715095500.0","comment_id":"1207927","upvote_count":"1","content":"Selected Answer: C\nAS the pattern is uncertain- Customer could not, in advance, segregate data, the pattern will be determined on the fly - and with regard of the following S3 feature:\nS3 Intelligent-Tiering is an additional storage class that provides flexibility for data with unknown or changing access patterns. It automates the movement of your objects between storage classes to optimize cost.\nC will be the most cost effective for this use case.","comments":[{"upvote_count":"3","content":"More insight:\nS3 Glacier Flexible Retrieval for the most flexible retrieval options that balance cost with access times ranging from minutes to hours. Your retrieval options permit you to access all the archives you need, when you need them, for one low storage price. This storage class comes with multiple retrieval options: \n- Expedited retrievals (restore in 1–5 minutes)\n- Standard retrievals (restore in 3–5 hours)\n- Bulk retrievals (restore in 5–12 hours). Bulk retrievals are available at no additional charge","timestamp":"1715095620.0","comment_id":"1207929","poster":"bujuman"}]},{"upvote_count":"2","poster":"Sergiuss95","comment_id":"1205652","timestamp":"1714660080.0","content":"Selected Answer: C\nExpedited 1-5min and for new files intelligent tier is a good option"},{"poster":"mohammadthainat","content":"Selected Answer: C\nAll old files should be in--> Glacier Flexible Retrieval takes (1-5 minutes) to retrieve the file. \nNew files should not stay in Standard Storage class forever --> Intelligent-Tiering","comment_id":"1189060","timestamp":"1712202900.0","upvote_count":"3"},{"poster":"JackyCCK","timestamp":"1711970820.0","content":"I don't think C is an option, S3 Glacier Flexible takes hour to retrieve the data.\nOption A is actually valid, but the way the option A describe it does not consider \"demand patterns based on time\"\n\nSo it should be B","comments":[{"timestamp":"1711970940.0","content":"expedited retrieval should not be used in that way as well","comment_id":"1187377","upvote_count":"1","poster":"JackyCCK"}],"upvote_count":"2","comment_id":"1187373"},{"poster":"Drew3000","timestamp":"1711838820.0","content":"Selected Answer: A\nThere is something I like about option A. It's the only one that deals with what happens with a movie that goes from \"new\" to \"old\". With other options, new movies will be new forever.","comment_id":"1186439","upvote_count":"2"},{"upvote_count":"4","timestamp":"1711720320.0","content":"Option B makes the most sense.\n\nWhy not option C:\n\n1. This is not an archival use case, the company runs a video streaming service, so objects are still accessed regularly. Accelerated Retrieval is designed for \"occasional urgent requests for a subset of archives\".\n2. The 5 minute timeframe does not apply to items of 250+ MB.\n3. Even if the timeframe were valid, it's not guaranteed (\"typically\")\n4. Expedited retrieval is expensive if used frequently ($10.00 per 1,000 requests) - depending on access patterns, this may more than offset the savings in storage costs.\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html","comment_id":"1185457","poster":"dkw2342"},{"upvote_count":"1","poster":"TruthWS","timestamp":"1711432800.0","content":"Option C","comment_id":"1183064"},{"content":"Selected Answer: C\nExpedited Retrievals (1-5 minutes)\nIntelligent-Tiering cost","poster":"[Removed]","upvote_count":"1","timestamp":"1711191600.0","comment_id":"1180802"},{"poster":"alawada","content":"Selected Answer: C\nExpedited Retrievals (1-5 minutes) - Intelligent-Tiering cost","timestamp":"1711139340.0","upvote_count":"2","comment_id":"1180299"},{"upvote_count":"1","comment_id":"1175209","content":"Selected Answer: C\nI go with C","poster":"xBUGx","timestamp":"1710616380.0"},{"poster":"lenotc","comment_id":"1175130","content":"Selected Answer: C\nC -> Expedited Retrievals (1-5 minutes) - Intelligent-Tiering cost (cost effective)\nD -> Bulk retrievals (5-12 hours)\nA -> does not consider demand patterns\nB -> It's ok, but \"C\" is more good fit to access patterns","timestamp":"1710608400.0","upvote_count":"2"},{"upvote_count":"3","comment_id":"1161055","timestamp":"1709077140.0","comments":[{"poster":"Drew3000","timestamp":"1709905740.0","comment_id":"1168841","upvote_count":"1","content":"It is possible to upload directly to standard IA."}],"content":"Selected Answer: A\noption A is most correct\noption B..for moving files to standard IA , it needs to stay in S3 standard for minimum 30 days.\noption C..expedited retrieval does not necessarily guarantee big size file retrieval in <=5 minutes.\noption D... is also wrong as it would take time in hours.\nsam","poster":"jaswantn"},{"timestamp":"1708243320.0","poster":"haci","comment_id":"1153099","content":"Selected Answer: C\nExpedited retrievals is typically made available within 1–5 minutes. Each unit of capacity provides that at least three Expedited retrievals can be performed every 5 minutes and provides up to 150 megabytes per second (MBps) of retrieval throughput.\n\nThere are some limitations but the bottom line is 5 minutes and I believe this leads us to Expedited retrievals.\n\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/downloading-an-archive-two-steps.html#api-downloading-an-archive-two-steps-retrieval-expedited-capacity","upvote_count":"5"},{"content":"option B","comment_id":"1152294","poster":"jaswantn","timestamp":"1708128900.0","upvote_count":"3"},{"poster":"Andy_09","upvote_count":"4","timestamp":"1707166320.0","comment_id":"1141468","content":"Option C"}],"url":"https://www.examtopics.com/discussions/amazon/view/132949-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":753,"topic":"1"},{"id":"t94t3U3dwXtTuWNEKXJG","discussion":[{"timestamp":"1666097040.0","content":"Selected Answer: B\nDMS is for databases and here refers to “JSON files”. Public internet is not reliable. So best option is B.","poster":"ArielSchivo","comment_id":"698245","upvote_count":"38"},{"comments":[{"upvote_count":"14","timestamp":"1671590280.0","content":"***WRONG***\nOption A, AWS DataSync over the public internet, is not as reliable as using Direct Connect, as it can be subject to potential network issues or congestion. \n\nOption C, AWS Database Migration Service (DMS) over the public internet, is not a suitable solution for transferring large amounts of data, as it is designed for migrating databases rather than transferring large amounts of data from a storage area network (SAN). \n\nOption D, AWS DMS over AWS Direct Connect, is also not a suitable solution, as it is designed for migrating databases and may not be efficient for transferring large amounts of data from a SAN.","comment_id":"751802","comments":[{"comment_id":"789484","content":"explanation about D option is good","upvote_count":"1","poster":"doorahmie","timestamp":"1674812760.0"}],"poster":"Buruguduystunstugudunstuy"}],"upvote_count":"21","comment_id":"751801","content":"Selected Answer: B\n***CORRECT***\nThe most reliable solution for transferring the data in a secure manner would be option B: AWS DataSync over AWS Direct Connect.\n\nAWS DataSync is a data transfer service that uses network optimization techniques to transfer data efficiently and securely between on-premises storage systems and Amazon S3 or other storage targets. When used over AWS Direct Connect, DataSync can provide a dedicated and secure network connection between your on-premises data center and AWS. This can help to ensure a more reliable and secure data transfer compared to using the public internet.","poster":"Buruguduystunstugudunstuy","timestamp":"1671590280.0"},{"poster":"satyaammm","content":"Selected Answer: B\nAWS DataSync supports Encryption and Compression and it is much more safer over a Direct Connect.","upvote_count":"1","comment_id":"1336061","timestamp":"1735916700.0"},{"upvote_count":"2","content":"Selected Answer: B\nAns B - keep it simple... private netwk + direct connection","timestamp":"1726398060.0","comment_id":"1284067","poster":"PaulGa"},{"comment_id":"1122738","poster":"awsgeek75","content":"Selected Answer: B\nnear-real-time + large data + secure = DataSync over DirectConnect\nA: Less secure due to public internet\nC: Slow and not secure\nD: Slow even if more secure\nDC may not even work as we don't know if there is a DB on other side but even if it was there, it is less preferred way","timestamp":"1705255080.0","upvote_count":"3"},{"poster":"JTruong","content":"Any DMS related-service will not be efficient because DMS can only process JSON files UPTO 2 MB in size\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.CustomizingTasks.TableMapping.SelectionTransformation.html\nso B is CORRECT","comment_id":"1108989","upvote_count":"2","timestamp":"1703874180.0"},{"poster":"Ruffyit","content":"AWS DataSync is a data transfer service that uses network optimization techniques to transfer data efficiently and securely between on-premises storage systems and Amazon S3 or other storage targets. When used over AWS Direct Connect, DataSync can provide a dedicated and secure network connection between your on-premises data center and AWS. This can help to ensure a more reliable and secure data transfer compared to using the public internet.","timestamp":"1698462240.0","upvote_count":"4","comment_id":"1055953"},{"content":"Selected Answer: B\nSecure and Most reliable transfer = AWS DataSync over AWS Direct Connect","poster":"TariqKipkemei","comment_id":"981290","upvote_count":"3","timestamp":"1692074940.0"},{"poster":"Guru4Cloud","upvote_count":"3","content":"Selected Answer: B\nAWS DataSync is designed for large scale, high speed data transfer between on-prem and S3.\nUsing AWS Direct Connect provides a dedicated, private connection for reliable, consistent data transfer.\nDataSync seamlessly handles data replication, encryption, recovery etc.","timestamp":"1691693400.0","comment_id":"978002"},{"comment_id":"952093","upvote_count":"1","poster":"MNotABot","content":"Not over public hence AC out / DMS is for databases and here refers to “JSON files”.","timestamp":"1689404100.0"},{"timestamp":"1687363860.0","comment_id":"929710","poster":"cookieMr","upvote_count":"3","content":"Selected Answer: B\nDataSync is a service specifically designed for data transfer and synchronization between on-premises storage systems and AWS storage services like S3. It provides reliable and efficient data transfer capabilities, ensuring the secure movement of large volumes of data.\n\nBy leveraging Direct Connect, which establishes a dedicated network connection between the on-premises data center and AWS, the data transfer is conducted over a private and dedicated network link. This approach offers increased reliability, lower latency, and consistent network performance compared to transferring data over the public internet.\n\nDatabase Migration Service is primarily focused on database migration and replication, and it may not be the most appropriate tool for general-purpose data transfer like JSON files.\n\nTransferring data over the public internet may introduce potential security risks and performance variability due to factors like network congestion, latency, and potential interruptions."},{"upvote_count":"1","poster":"beginnercloud","comment_id":"903817","content":"Best option and correct is B","timestamp":"1684740540.0"},{"timestamp":"1684563720.0","upvote_count":"1","content":"Selected Answer: B\nas Ariel suggested and rightly so.....DMS is for databases and here refers to “JSON files”. Public internet is not reliable. so B","comment_id":"902387","poster":"Abrar2022"},{"comment_id":"749357","upvote_count":"1","poster":"career360guru","timestamp":"1671415080.0","content":"Selected Answer: B\nOption B"},{"poster":"career360guru","comment_id":"747697","upvote_count":"1","timestamp":"1671237000.0","content":"Selected Answer: B\nOption B. DMS is not needed as there is no Database migration requirement."},{"poster":"Wajif","content":"Selected Answer: B\nPublic internet options automatically out being best-effort. DMS is for database migration service and here they have to just transfer the data to S3. Hence B.","comment_id":"728877","upvote_count":"2","timestamp":"1669623660.0"},{"content":"B is correct","comment_id":"723661","upvote_count":"1","timestamp":"1669042800.0","poster":"Wpcorgan"},{"content":"B\n\n- A SAN presents storage devices to a host such that the storage appears to be locally attached. ( NFS is, or can be, a SAN - https://serverfault.com/questions/499185/is-san-storage-better-than-nfs )\n- AWS Direct Connect does not encrypt your traffic that is in transit by default. But the connection is private (https://docs.aws.amazon.com/directconnect/latest/UserGuide/encryption-in-transit.html)","upvote_count":"4","timestamp":"1666452060.0","comment_id":"701610","poster":"yd_h"}],"answer":"B","unix_timestamp":1666097040,"answer_ET":"B","choices":{"B":"AWS DataSync over AWS Direct Connect","A":"AWS DataSync over public internet","C":"AWS Database Migration Service (AWS DMS) over public internet","D":"AWS Database Migration Service (AWS DMS) over AWS Direct Connect"},"question_images":[],"answer_description":"","question_text":"A company receives 10 TB of instrumentation data each day from several machines located at a single factory. The data consists of JSON files stored on a storage area network (SAN) in an on-premises data center located within the factory. The company wants to send this data to Amazon S3 where it can be accessed by several additional systems that provide critical near-real-time analytics. A secure transfer is important because the data is considered sensitive.\nWhich solution offers the MOST reliable data transfer?","answer_images":[],"exam_id":31,"timestamp":"2022-10-18 14:44:00","question_id":754,"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/85801-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","isMC":true},{"id":"MqJt3iftGZkBVomJXTJv","answers_community":["C (94%)","6%"],"exam_id":31,"answer_images":[],"answer_description":"","answer_ET":"C","isMC":true,"timestamp":"2024-02-05 21:54:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/132950-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"C","question_images":[],"choices":{"A":"Create an AWS Lambda function that uses the Docker container image with an Amazon S3 mounted volume that has more than 50 GB of space.","B":"Create an AWS Lambda function that uses the Docker container image with an Amazon Elastic Block Store (Amazon EBS) volume that has more than 50 GB of space.","C":"Create an Amazon Elastic Container Service (Amazon ECS) cluster that uses the AWS Fargate launch type. Create a task definition for the container image with an Amazon Elastic File System (Amazon EFS) volume. Create a service with that task definition.","D":"Create an Amazon Elastic Container Service (Amazon ECS) cluster that uses the Amazon EC2 launch type with an Amazon Elastic Block Store (Amazon EBS) volume that has more than 50 GB of space. Create a task definition for the container image. Create a service with that task definition."},"question_id":755,"discussion":[{"poster":"stephensimudemy","content":"Selected Answer: C\nOptions A and B involve AWS Lambda, which is suitable for event-driven, short-lived compute tasks, but it's NOT ideal for long-running containerized applications and managing large volumes of data.","timestamp":"1708436280.0","upvote_count":"7","comment_id":"1154744"},{"comments":[{"comment_id":"1144891","content":"Why C and not B?","timestamp":"1707423960.0","comments":[{"comments":[{"timestamp":"1714137000.0","poster":"sandordini","upvote_count":"2","content":"RIC: Runtime interface clients","comment_id":"1202602"}],"upvote_count":"3","content":"Not B because your lambda container needs the RIC and the image is already provided, presumably without the RIC (or else it would have mentioned it)","timestamp":"1713881820.0","comment_id":"1200783","poster":"03beafc"},{"timestamp":"1707581700.0","poster":"hajra313","upvote_count":"2","comment_id":"1146428","content":"the infrastructure must be serverless"},{"timestamp":"1707574740.0","poster":"Cali182","upvote_count":"4","content":"Creating an AWS Lambda function that uses the Docker container image with an Amazon S3 mounted volume might not be suitable because Lambda functions have limitations on execution duration (15 minutes) and storage size (maximum 512 MB in the /tmp directory).","comments":[{"timestamp":"1711721760.0","poster":"dkw2342","upvote_count":"3","content":"There's no indication of runtime, so that's not the reason.\n\nA is wrong because \"S3 volumes\" do not exist. If the question were about S3 buckets: while it is possible to mount an S3 bucket using FUSE, this is completely unsupported by AWS and definitely won't work in a container running on Lambda (you can't assign SYS_ADMIN cap and mount /dev/fuse).\n\nB is wrong because you can't use EBS volumes with Lambda.\n\nAs an aside, Lambda supports up to 10 GB of ephemeral storage (configurable).","comment_id":"1185470"}],"comment_id":"1146349"}],"upvote_count":"1","poster":"nj1999"}],"content":"Option C","comment_id":"1141471","poster":"Andy_09","timestamp":"1707166440.0","upvote_count":"6"},{"timestamp":"1735021740.0","comment_id":"1331043","content":"Selected Answer: C\nA - Technically, temporary file access in Lambda is limited to the /tmp directory with a 512 MB limit.\nB - AWS Lambda does not natively support mounting EBS volumes.\nC - Looks good to me.\nD - ECS with EC2 is not serverless.\n\nFYI - Serverless infrastructure: Solutions must not involve managing servers or underlying infrastructure. AWS Fargate and AWS Lambda are serverless options, while Amazon ECS with EC2 launch type involves managing EC2 instances.","poster":"LeonSauveterre","upvote_count":"1"},{"comment_id":"1234452","content":"Selected Answer: C\nC is right answer.","timestamp":"1718979060.0","poster":"dragongoseki","upvote_count":"2"},{"timestamp":"1718942160.0","comment_id":"1234181","poster":"DZRomero","content":"Selected Answer: C\nThe combination of ECS with Fargate and EFS (option C) provides a serverless solution that can run Docker containers and meet the storage requirements, all while minimizing operational overhead. You don't need to manage any servers, and the storage will automatically scale as needed. This makes it the best fit for the given requirements.","upvote_count":"2"},{"upvote_count":"4","timestamp":"1714137360.0","poster":"sandordini","content":"Selected Answer: C\nLambda would need Runtime interface clients (RIC) to host a container workload. \nAlso Lambda storage limit: 10GB \nFargate is Serverless >> C","comment_id":"1202609"},{"timestamp":"1714020840.0","content":"Selected Answer: B\nthe key word here is {\" serverless + temporary file''}\nA: it uses S3 for storage that is not a temporary file storage system\nC: that was good using ECS with farget for serverless part but is uses EFS file system still it is a durable file system not temporary\nD: Using EBS was good to use for temporary file system but it is mounted on EC2 which is not serverless. so that we are left with ''B'' which uses [ lambda(serverless) + EBS(temporary storage)]","comment_id":"1201749","poster":"zinabu","upvote_count":"1"},{"comment_id":"1201748","upvote_count":"1","content":"the key word here is {\" serverless + temporary file''}\nA: it uses S3 for storage that is not a temporary file storage system\nC: that was good using ECS with farget for serverless part but is uses EFS file system still it is a durable file system not temporary\nD: Using EBS was good to use for temporary file system but it is mounted on EC2 which is not serverless. so that we are left with ''B'' which uses [ lambda(serverless) + EBS(temporary storage)]","timestamp":"1714020720.0","poster":"zinabu"}],"question_text":"A solutions architect needs to design the architecture for an application that a vendor provides as a Docker container image. The container needs 50 GB of storage available for temporary files. The infrastructure must be serverless.\n\nWhich solution meets these requirements with the LEAST operational overhead?","unix_timestamp":1707166440}],"exam":{"isImplemented":true,"provider":"Amazon","isBeta":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Associate SAA-C03","id":31,"numberOfQuestions":1019,"isMCOnly":true},"currentPage":151},"__N_SSP":true}