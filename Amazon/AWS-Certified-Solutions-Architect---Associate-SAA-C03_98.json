{"pageProps":{"questions":[{"id":"gkUmCgkDbCg0J4WdLEW7","answer":"A","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/109721-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["A (100%)"],"exam_id":31,"isMC":true,"topic":"1","answer_ET":"A","question_id":486,"discussion":[{"upvote_count":"12","poster":"cloudenthusiast","comment_id":"901926","content":"Selected Answer: A\nEnabling storage autoscaling allows RDS to automatically adjust the storage capacity based on the application's needs. When the storage usage exceeds a predefined threshold, RDS will automatically increase the allocated storage without requiring manual intervention or causing downtime. This ensures that the RDS database has sufficient disk space to handle the increasing storage requirements.","timestamp":"1684499880.0"},{"upvote_count":"2","comment_id":"1236676","timestamp":"1719284220.0","content":"Selected Answer: A\nAutoscaling.... without downtime...","poster":"Gape4"},{"comment_id":"1063434","poster":"potomac","upvote_count":"3","content":"Selected Answer: A\nAmazon RDS for MariaDB, Amazon RDS for MySQL, Amazon RDS for PostgreSQL, Amazon RDS for SQL Server and Amazon RDS for Oracle support RDS Storage Auto Scaling. RDS Storage Auto Scaling automatically scales storage capacity in response to growing database workloads, with zero downtime.","timestamp":"1699232940.0"},{"content":"Selected Answer: A\nThis question is so obvious","comment_id":"988147","poster":"Guru4Cloud","timestamp":"1692783120.0","upvote_count":"4"},{"content":"Selected Answer: A\nRDS Storage Auto Scaling continuously monitors actual storage consumption, and scales capacity up automatically when actual utilization approaches provisioned storage capacity. Auto Scaling works with new and existing database instances. You can enable Auto Scaling with just a few clicks in the AWS Management Console. There is no additional cost for RDS Storage Auto Scaling. You pay only for the RDS resources needed to run your applications.\n\nhttps://aws.amazon.com/about-aws/whats-new/2019/06/rds-storage-auto-scaling/#:~:text=of%20the%20rest.-,RDS%20Storage%20Auto%20Scaling,-continuously%20monitors%20actual","poster":"TariqKipkemei","comment_id":"957130","upvote_count":"3","timestamp":"1689828840.0"},{"upvote_count":"3","comments":[{"timestamp":"1689664980.0","content":"Hello moderator, please help me delete this discussion, I already add content before this comment.","upvote_count":"1","poster":"james2033","comment_id":"955098"}],"poster":"james2033","comment_id":"955092","timestamp":"1689664860.0","content":"Selected Answer: A\nQuote \"Amazon RDS now supports Storage Auto Scaling\" and \"... with zero downtime.\" (Jun 20th 2019) at https://aws.amazon.com/about-aws/whats-new/2019/06/rds-storage-auto-scaling/"},{"poster":"james2033","comment_id":"953331","content":"Selected Answer: A\nSee “Amazon RDS now supports Storage Auto Scaling. Posted On: Jun 20, 2019. Starting today, Amazon RDS for MariaDB, Amazon RDS for MySQL, Amazon RDS for PostgreSQL, Amazon RDS for SQL Server and Amazon RDS for Oracle support RDS Storage Auto Scaling. RDS Storage Auto Scaling automatically scales storage capacity in response to growing database workloads, with zero downtime.” at https://aws.amazon.com/about-aws/whats-new/2019/06/rds-storage-auto-scaling/","upvote_count":"3","timestamp":"1689512940.0"},{"content":"Selected Answer: A\nA is the best answer. \nB will not work for increasing disk space, it only improve the IO performance. \nC will not work because it will cause downtime.\nD is too complicated and need much operational effort.","upvote_count":"2","poster":"haoAWS","timestamp":"1687813740.0","comment_id":"934793"},{"upvote_count":"2","content":"https://aws.amazon.com/about-aws/whats-new/2019/06/rds-storage-auto-scaling/","poster":"[Removed]","timestamp":"1684919220.0","comment_id":"905682"},{"comment_id":"903218","upvote_count":"3","poster":"Anmol_1010","content":"The key word is No Down time. A would be bewt option","timestamp":"1684672920.0"}],"timestamp":"2023-05-19 14:38:00","choices":{"A":"Enable storage autoscaling in RDS","B":"Increase the RDS database instance size","C":"Change the RDS database instance storage type to Provisioned IOPS","D":"Back up the RDS database, increase the storage capacity, restore the database, and stop the previous instance"},"unix_timestamp":1684499880,"answer_description":"","question_images":[],"question_text":"An application uses an Amazon RDS MySQL DB instance. The RDS database is becoming low on disk space. A solutions architect wants to increase the disk space without downtime.\n\nWhich solution meets these requirements with the LEAST amount of effort?"},{"id":"XFKIyiee9qfg3nQ9e0ux","answer_description":"","answers_community":["B (100%)"],"timestamp":"2023-05-19 14:39:00","topic":"1","question_id":487,"unix_timestamp":1684499940,"exam_id":31,"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/109722-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"question_text":"A consulting company provides professional services to customers worldwide. The company provides solutions and tools for customers to expedite gathering and analyzing data on AWS. The company needs to centrally manage and deploy a common set of solutions and tools for customers to use for self-service purposes.\n\nWhich solution will meet these requirements?","answer_ET":"B","isMC":true,"question_images":[],"choices":{"C":"Create AWS Systems Manager templates for the customers.","A":"Create AWS CloudFormation templates for the customers.","D":"Create AWS Config items for the customers.","B":"Create AWS Service Catalog products for the customers."},"discussion":[{"poster":"cloudenthusiast","comment_id":"901928","comments":[{"comments":[{"comment_id":"1316564","upvote_count":"1","poster":"JA2018","timestamp":"1732338000.0","content":"for this use case, in order to access the self-service functions, customers must have some form of AWS identities (e.g. accounts, users, user groups or roles) already setup in the service provider's AWS organisation."}],"upvote_count":"1","poster":"Oblako","content":"\"within your organization\" => not for customers","timestamp":"1701106440.0","comment_id":"1081831"}],"content":"Selected Answer: B\nAWS Service Catalog allows you to create and manage catalogs of IT services that can be deployed within your organization. With Service Catalog, you can define a standardized set of products (solutions and tools in this case) that customers can self-service provision. By creating Service Catalog products, you can control and enforce the deployment of approved and validated solutions and tools.","timestamp":"1684499940.0","upvote_count":"10"},{"upvote_count":"5","poster":"Guru4Cloud","content":"Selected Answer: B\nSome key advantages of using Service Catalog:\n\nCentralized management - Products can be maintained in a single catalog for easy discovery and governance.\nSelf-service access - Customers can deploy the solutions on their own without manual intervention.\nStandardization - Products provide pre-defined templates for consistent deployment.\nAccess control - Granular permissions can be applied to restrict product visibility and access.\nReporting - Service Catalog provides detailed analytics on product usage and deployments.","comment_id":"988146","timestamp":"1692782940.0"},{"poster":"hsinchang","timestamp":"1690352280.0","content":"Selected Answer: B\nCloudFormation: a code as infrastructure service\nSystems Manager: management solution for resources\nConfig: assess, audit and evaluate configurations\nOther options does not fit this scenario.","upvote_count":"2","comment_id":"963439"},{"content":"Selected Answer: B\nAWS Service Catalog lets you centrally manage your cloud resources to achieve governance at scale of your infrastructure as code (IaC) templates, written in CloudFormation or Terraform. With AWS Service Catalog, you can meet your compliance requirements while making sure your customers can quickly deploy the cloud resources they need.\n\nhttps://aws.amazon.com/servicecatalog/#:~:text=How%20it%20works-,AWS%20Service%20Catalog,-lets%20you%20centrally","upvote_count":"2","comment_id":"957133","timestamp":"1689829260.0","poster":"TariqKipkemei"},{"timestamp":"1685099760.0","upvote_count":"3","poster":"Yadav_Sanjay","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/servicecatalog/latest/adminguide/introduction.html","comment_id":"907298"}]},{"id":"RB7jtpyP4AdIaPAD0KrF","unix_timestamp":1665571320,"topic":"1","discussion":[{"upvote_count":"33","content":"Selected Answer: C\nEFS is a standard file system, it scales automatically and is highly available.","comment_id":"698131","timestamp":"1666090680.0","poster":"ArielSchivo"},{"upvote_count":"11","content":"I have absolutely no idea...\n\nOutput files that vary in size from tens of gigabytes to hundreds of terabytes\n\nSimit size for a single object:\nS3 5To TiB\nhttps://aws.amazon.com/fr/blogs/aws/amazon-s3-object-size-limit/\nEBS 64 Tib\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/volume_constraints.html\nEFS 47.9 TiB\nhttps://docs.aws.amazon.com/efs/latest/ug/limits.html","comments":[{"timestamp":"1670802480.0","comment_id":"742217","upvote_count":"6","poster":"RBSK","content":"None meets 100s of TB / file. Bit confusing / misleading"},{"upvote_count":"2","comment_id":"811638","content":"The answer to that is \nLimit size for a single object:\nS3, 5TiB is per object but you can have more than one object in a bucket, meaning infinity \nhttps://aws.amazon.com/fr/blogs/aws/amazon-s3-object-size-limit/\nEBS 64 Tib is per block of storage \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/volume_constraints.html\nEFS 47.9 TiB per file and in the questions its says Files the 's'\nhttps://docs.aws.amazon.com/efs/latest/ug/limits.html","timestamp":"1676622540.0","poster":"Help2023"},{"content":"S3 and EBS are block storage but you are looking to store files, so EFS is the correct option.","poster":"JayBee65","comment_id":"736018","upvote_count":"4","comments":[{"timestamp":"1673610120.0","content":"S3 is object storage.","comment_id":"774396","upvote_count":"14","poster":"Ello2023"},{"upvote_count":"4","timestamp":"1700271600.0","comment_id":"1073757","content":"A lil correction,S3 is Object storage not Block Storage","poster":"OmegaLambda7XL9"}],"timestamp":"1670251380.0"}],"poster":"masetromain","timestamp":"1665571320.0","comment_id":"692956"},{"comment_id":"1400455","poster":"SirDNS","content":"Selected Answer: C\nC: The only option with file system","upvote_count":"1","timestamp":"1742378820.0"},{"comment_id":"1348787","poster":"AwsAbhiKumar","content":"Selected Answer: C\nHOW EFS is suitable here as it has a maximum file size limit of 52 TiB, so it cannot store a single file that exceeds this size. But in question it has mentioned that output files may vary in size from tens of gigabytes to hundreds of terabytes. Isn't it contradictory?","timestamp":"1738186380.0","upvote_count":"1"},{"comment_id":"1347606","poster":"Dharmarajan","upvote_count":"1","timestamp":"1738016700.0","content":"Selected Answer: C\nThe question is not clear. None of the options suit the 100s of TB requirements.\nEFS max file size is clearly specified as 49.5TB.\nBut lets assume for a minute that the app is capable of multipart files, then EFS would be a great fit. (requirement: Must be a file system)"},{"comment_id":"1335214","poster":"satyaammm","upvote_count":"1","content":"Selected Answer: C\nEFS is the only file system structure here so it it most suitable.","timestamp":"1735745160.0"},{"poster":"trinh_le","timestamp":"1731798840.0","content":"Selected Answer: C\nKeyword\nMust store in standard file system -> ignore A\nMinimum operational -> ignore B\nScalable + Terabytes-> pick C","upvote_count":"1","comment_id":"1313299"},{"timestamp":"1726055580.0","content":"Selected Answer: C\nAns C - S3 unlimited storage in both scope and size of individual objects","upvote_count":"1","comment_id":"1282065","poster":"PaulGa"},{"comment_id":"1249792","content":"C : EFS as It is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files.\n\nMultiple compute instances, including Amazon EC2, Amazon ECS, and AWS Lambda,\ncan access an Amazon EFS file system at the same time, providing a common data source\nfor workloads.","poster":"bishtr3","upvote_count":"2","timestamp":"1721233380.0"},{"comment_id":"1205829","poster":"HectorCosta","timestamp":"1714684800.0","content":"Selected Answer: C\nKey words: Standard File System and Scales Automatically.\nS3 is object Store, hence if fails with the \"Standard File System\" requirement, so we can discard A.\nEBS does not scale automatically, failing with the \"Scales Automatically\" requirement, so we can discard B and D","upvote_count":"3"},{"content":"C is the only option which supports standard file system when we talk about high availability. EBS scope is within a availability zone but EFS has scope of a region.","upvote_count":"2","comment_id":"1159809","timestamp":"1708955580.0","poster":"sidharthwader"},{"comment_id":"1122567","timestamp":"1705240440.0","poster":"awsgeek75","content":"Selected Answer: C\nStandard file system that is highly available: EFS \nAutoscaling highly available system: EC2 or ECS or EKS can work\n\nA: Not suitable due to S3 which is BLOB not file system\nB: EKS is ok but EBS is not HA\nD: EBS is not HA\n\nSo by elimination, C is best option.","upvote_count":"2"},{"comment_id":"1105101","poster":"pentium75","timestamp":"1703491320.0","upvote_count":"3","content":"Selected Answer: C\n\"File system structure\" = EFS, which also meets all the other requirements."},{"comment_id":"1084008","upvote_count":"4","poster":"Mikado211","timestamp":"1701321180.0","content":"Selected Answer: C\nTechnically the A could work, ECS is often recommended by AWS in case of minimum operational overhead, and S3 is durable and highly scalable BUT it is not a \"traditional\" file system structure. In an S3 bucket, there is no real file structure, only files and prefixes that simulate a structure.\n\nB is wrong because of EKS which require more management\n\nEFS is recommended for minimum operational overhead instead of EBS.\n\nSo C (EC2 + EFS) is recommended here over D (EC2 + EBS)."},{"content":"Selected Answer: C\nPalabras clave: autoescalado y ficheros","poster":"wantu","comment_id":"1082613","timestamp":"1701179160.0","upvote_count":"1"},{"upvote_count":"2","content":"The key is Multi-AZ ,EBS does not support it.","timestamp":"1700848260.0","poster":"leosmal","comment_id":"1079470"},{"content":"Selected Answer: C\nStandard file system structure, scales automatically, requires minimum operational overhead = Amazon Elastic File System (Amazon EFS)","poster":"TariqKipkemei","comment_id":"974423","upvote_count":"2","timestamp":"1691387040.0"},{"poster":"miki111","content":"Option C is the correct answer","comment_id":"956750","upvote_count":"1","timestamp":"1689779340.0"},{"timestamp":"1687344720.0","content":"Selected Answer: C\nEFS provides a scalable and fully managed file system that can be easily mounted to multiple EC2. It allows you to store and access files using the standard file system structure, which aligns with the company's requirement for a standard file system. EFS automatically scales with the size of your data.\n\nA suggests using ECS for container orchestration and S3 for storage. ECS doesn't offer a native file system storage solution. S3 is an object storage service and may not be the most suitable option for a standard file system structure.\n\nB suggests using EKS for container orchestration and EBS for storage. Similar to A, EBS is block storage and not optimized for file system access. While EKS can manage containers, it doesn't specifically address the file storage requirements.\n\nD suggests using EC2 with EBS for storage. While EBS can provide block storage for EC2, it doesn't inherently offer a scalable file system solution like EFS. You would need to manage and provision EBS volumes manually, which may introduce operational overhead.","poster":"cookieMr","upvote_count":"7","comment_id":"929361"},{"upvote_count":"1","timestamp":"1685964060.0","comment_id":"915382","content":"Selected Answer: C\nOption C meets the requirements.","poster":"Bmarodi"},{"timestamp":"1682822580.0","comment_id":"884837","content":"Selected Answer: C\nKeywords: file system structure, scales automatically, highly available, and minimal operational overhead","upvote_count":"1","poster":"joshnort"},{"upvote_count":"1","poster":"harirkmusa","timestamp":"1676220600.0","comment_id":"806581","content":"standard file system structure is the KEYWORD here, the S3 and EBS are not file based storage. EFS is. so the automatic answer is C"},{"timestamp":"1674833100.0","poster":"NitiATOS","comment_id":"789733","content":"Selected Answer: C\nI will go with C as If the app is deployed in MultiAZ, computes are different but the Storage needs to be common. \nEFS is easist way to configure shared storage as compared to SHARED EBS. \n Hence C Suits the best.","upvote_count":"1"},{"upvote_count":"2","timestamp":"1673509020.0","poster":"Strk18","content":"Selected Answer: C\nC. Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic File System (Amazon EFS) for storage.","comment_id":"773225"},{"comment_id":"768192","upvote_count":"1","content":"Selected Answer: C\nMigrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic File System (Amazon EFS) for storage.","timestamp":"1673056140.0","poster":"SilentMilli"},{"comment_id":"752852","upvote_count":"1","content":"Selected Answer: C\nC = File storage system, Multi AZ ASG lets you maintain high availability\nNot A, B or D because they don't meet the requirement of file system storage","poster":"pazabal","timestamp":"1671664800.0"},{"timestamp":"1671552120.0","poster":"Buruguduystunstugudunstuy","content":"Selected Answer: C\nC. Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic File System (Amazon EFS) for storage.\n\nTo meet the requirements, a solution that would allow the company to migrate its on-premises application to AWS and scale automatically, be highly available, and require minimum operational overhead would be to migrate the application to Amazon Elastic Compute Cloud (Amazon EC2) instances in a Multi-AZ (Availability Zone) Auto Scaling group.","comment_id":"751161","upvote_count":"2","comments":[{"content":"The Auto Scaling group would allow the application to automatically scale up or down based on demand, ensuring that the application has the required capacity to handle incoming requests. To store the data produced by the application, the company could use Amazon Elastic File System (Amazon EFS), which is a file storage service that allows the company to store and access file data in a standard file system structure. Amazon EFS is highly available and scales automatically to support the workload of the application, making it a good choice for storing the data produced by the application.","upvote_count":"2","comment_id":"751162","poster":"Buruguduystunstugudunstuy","comments":[{"content":"my only question is : since EFS is also highly available and scalable, why not use EFS alone in this case? Is there any suggestion for using Auto Scaling as a must.","upvote_count":"1","timestamp":"1683569640.0","poster":"Futurebones","comment_id":"892425"}],"timestamp":"1671552120.0"}]},{"content":"Selected Answer: C\nOption C. Using EBS as storage is not a right option as it will not scale automatically.\nUsing ECS and EKS for running the application is not a requirement here and it is not clearly mentioned that application can be containerized or not.","poster":"career360guru","timestamp":"1671420420.0","comment_id":"749412","upvote_count":"2"},{"poster":"benaws","comment_id":"741515","timestamp":"1670745960.0","upvote_count":"3","content":"Selected Answer: C\nHighly available & Autoscales == Multi-AZ Auto Scaling group. \nStandard File System == Amazon Elastic File System (Amazon EFS)"},{"content":"C is correct","poster":"Wpcorgan","upvote_count":"1","timestamp":"1669038900.0","comment_id":"723566"},{"upvote_count":"1","comment_id":"715210","timestamp":"1668082980.0","poster":"pspinelli19","content":"Selected Answer: C\nhttps://www.examtopics.com/discussions/amazon/view/84147-exam-aws-certified-solutions-architect-associate-saa-c02/"},{"content":"Selected Answer: C\nstandard file system => EFS rather than S3","upvote_count":"2","poster":"BoboChow","comment_id":"700391","timestamp":"1666310220.0"},{"poster":"Kikiokiki","content":"EBS doesn't offer high availability, data is stored in one AZ.","comment_id":"698204","upvote_count":"2","timestamp":"1666094400.0"},{"content":"cCCCCCCCCCC","comment_id":"697628","poster":"queen101","upvote_count":"1","timestamp":"1666031820.0"},{"poster":"oxfordcommaa","content":"Selected Answer: C\nchose this due to the key word \"standard file system\"","timestamp":"1665762780.0","comment_id":"694887","upvote_count":"6"}],"answer":"C","choices":{"C":"Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic File System (Amazon EFS) for storage.","D":"Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic Block Store (Amazon EBS) for storage.","B":"Migrate the application to run as containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use Amazon Elastic Block Store (Amazon EBS) for storage.","A":"Migrate the application to run as containers on Amazon Elastic Container Service (Amazon ECS). Use Amazon S3 for storage."},"answer_images":[],"timestamp":"2022-10-12 12:42:00","answer_description":"","isMC":true,"question_images":[],"question_text":"A company wants to migrate its on-premises application to AWS. The application produces output files that vary in size from tens of gigabytes to hundreds of terabytes. The application data must be stored in a standard file system structure. The company wants a solution that scales automatically. is highly available, and requires minimum operational overhead.\nWhich solution will meet these requirements?","exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/85265-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["C (100%)"],"answer_ET":"C","question_id":488},{"id":"RHciB2qeG5GQMDaFqylI","timestamp":"2023-05-17 14:44:00","unix_timestamp":1684327440,"answer_images":[],"topic":"1","choices":{"B":"Configure DynamoDB in on-demand mode by using the DynamoDB Standard table class.","A":"Configure DynamoDB with provisioned read and write by using the DynamoDB Standard table class. Set DynamoDB auto scaling to a maximum defined capacity.","D":"Configure DynamoDB in on-demand mode by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class.","C":"Configure DynamoDB with provisioned read and write by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class. Set DynamoDB auto scaling to a maximum defined capacity."},"question_text":"A company is designing a new web application that will run on Amazon EC2 Instances. The application will use Amazon DynamoDB for backend data storage. The application traffic will be unpredictable. The company expects that the application read and write throughput to the database will be moderate to high. The company needs to scale in response to application traffic.\n\nWhich DynamoDB table configuration will meet these requirements MOST cost-effectively?","answer":"B","question_id":489,"url":"https://www.examtopics.com/discussions/amazon/view/109539-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"answer_ET":"B","answers_community":["B (74%)","A (22%)","2%"],"question_images":[],"exam_id":31,"answer_description":"","discussion":[{"content":"B for me. Provisioned if we know how much traffic will come, but its unpredictable, so we have to go for on-demand","comment_id":"901234","upvote_count":"12","timestamp":"1684415520.0","poster":"Efren","comments":[{"upvote_count":"3","comment_id":"945344","poster":"VellaDevil","content":"Spot On","timestamp":"1688708160.0"}]},{"content":"Selected Answer: B\nDynamoDB offers two table classes designed to help you optimize for cost. \nThe DynamoDB Standard table class is the default, and is recommended for the vast majority of workloads. \nThe DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA) table class is optimized for tables where storage is the dominant cost. For example, tables that store infrequently accessed data, such as application logs, old social media posts, e-commerce order history, and past gaming achievements, are good candidates for the Standard-IA table class.","comment_id":"1387227","upvote_count":"1","poster":"tch","timestamp":"1741652280.0"},{"content":"Selected Answer: B\nCan someone answer why the standard class is a better choice to standard IA?","comments":[],"upvote_count":"1","timestamp":"1735121280.0","comment_id":"1331494","poster":"fdae619"},{"timestamp":"1719624840.0","poster":"emakid","comment_id":"1238982","upvote_count":"3","content":"Selected Answer: B\nConfigure DynamoDB in on-demand mode by using the DynamoDB Standard table class.\n\n This option allows DynamoDB to automatically adjust to varying traffic patterns, which is ideal for unpredictable workloads. The Standard table class is suitable for applications with moderate to high read and write throughput, and on-demand mode ensures that you are billed based on the actual usage, providing cost efficiency for variable traffic patterns."},{"timestamp":"1719284400.0","comment_id":"1236677","content":"Selected Answer: B\nKey word : On demand. So I think B.","poster":"Gape4","upvote_count":"2"},{"content":"Selected Answer: B\nOn demand\nhttps://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/capacity.html\n\n\"With on-demand capacity mode, DynamoDB charges you for the data reads and writes your application performs on your tables. You do not need to specify how much read and write throughput you expect your application to perform because DynamoDB instantly accommodates your workloads as they ramp up or down.\"","upvote_count":"3","timestamp":"1704920400.0","poster":"awsgeek75","comment_id":"1119025"},{"timestamp":"1704111180.0","upvote_count":"4","content":"Selected Answer: B\nNot A because of \"unpredictable\" traffic\nNot C and D because we are expecting \"moderate to high\" traffic","comment_id":"1111140","poster":"pentium75"},{"timestamp":"1702239360.0","comment_id":"1092820","poster":"leonliu4","content":"Selected Answer: B\nLeaning towards B, it's hard to predict the capacity for A, and autoscaling doesn't respond fast","upvote_count":"3"},{"upvote_count":"2","comments":[],"timestamp":"1701327900.0","comment_id":"1084046","content":"Selected Answer: A\nit's A. \nremember that : \nhe company expects that the application read and write throughput to the database will be moderate to high\n\nprovisioned throughput is cheaper than ondemand capacity right ?","poster":"peekingpicker"},{"poster":"dilaaziz","timestamp":"1699962900.0","content":"Selected Answer: D\nData storage: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.tableclasses.html","comment_id":"1070333","upvote_count":"1","comments":[{"content":"Actually, this link confirmed \"B\" for me...","poster":"Mr_Marcus","comment_id":"1221324","upvote_count":"2","timestamp":"1717025100.0"}]},{"poster":"potomac","timestamp":"1699233360.0","upvote_count":"3","content":"Selected Answer: B\nOn-demand mode is great for unpredictable traffic","comment_id":"1063446"},{"upvote_count":"2","timestamp":"1696894500.0","comment_id":"1039019","content":"I choose B\nI think the items stored in the table in this question has large size. So each read/write, a big chunk of data pass through. A capacity unit is used to describe data throughput. provision to the high capacity units will be a waste because unpredicted traffic pattern.","poster":"bsbs1234"},{"comment_id":"992392","content":"Selected Answer: B\nUnpredictable= on demand","poster":"Bennyboy789","timestamp":"1693240260.0","upvote_count":"3"},{"upvote_count":"2","content":"Selected Answer: B\nThe key factors are:\n\nWith On-Demand mode, you only pay for what you use instead of over-provisioning capacity. This avoids idle capacity costs.\nDynamoDB Standard provides the fastest performance needed for moderate-high traffic apps vs Standard-IA which is for less frequent access.\nAuto scaling with provisioned capacity can also work but requires more administrative effort to tune the scaling thresholds.","comment_id":"988144","timestamp":"1692782700.0","poster":"Guru4Cloud"},{"comment_id":"964455","timestamp":"1690441440.0","upvote_count":"2","poster":"msdnpro","content":"Selected Answer: B\nSupport for B from AWS:\n\nOn-demand mode is a good option if any of the following are true:\n-You create new tables with unknown workloads.\n-You have unpredictable application traffic.\n-You prefer the ease of paying for only what you use.\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html"},{"content":"Selected Answer: B\nTechnically both options A and B will work. But this statement 'traffic will be unpredictable' rules out option A, because 'provisioned mode' was made for scenarios where traffic is predictable. \nSo I will stick with B, because 'on-demand mode' is made for unpredictable traffic and instantly accommodates workloads as they ramp up or down.","upvote_count":"3","comment_id":"958031","timestamp":"1689911760.0","poster":"TariqKipkemei"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html","timestamp":"1689496200.0","comment_id":"953171","poster":"0628atv","upvote_count":"4"},{"comment_id":"936375","content":"Selected Answer: C\nNot B for sure, \"The company needs to scale in response to application traffic.\"\nBetween A and C, I would choose C. Because it's a new application, and the traffic will be from moderate to high. So by choosing C, it's both cost-effecitve and scalable","timestamp":"1687942200.0","poster":"wRhlH","upvote_count":"1"},{"comment_id":"934120","content":"Selected Answer: A\n\"With provisioned capacity mode, you specify the number of reads and writes per second that you expect your application to require, and you are billed based on that. Furthermore if you can forecast your capacity requirements you can also reserve a portion of DynamoDB provisioned capacity and optimize your costs even further.\n\nWith provisioned capacity you can also use auto scaling to automatically adjust your table’s capacity based on the specified utilization rate to ensure application performance, and also to potentially reduce costs. To configure auto scaling in DynamoDB, set the minimum and maximum levels of read and write capacity in addition to the target utilization percentage.\"\n\nhttps://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/capacity.html","poster":"live_reply_developers","timestamp":"1687761480.0","upvote_count":"3"},{"timestamp":"1687599060.0","poster":"F629","upvote_count":"1","comment_id":"932400","content":"Selected Answer: A\nI think it's A. B is on-demand, but it may not save money. If it's a not-busy application, on-demand may save money, but to a medium to high busy level application, I prefer a provisioned."},{"content":"Selected Answer: B\nunpredictable = on-demand","upvote_count":"4","timestamp":"1684653540.0","poster":"Rob1L","comment_id":"902990"},{"comment_id":"901934","poster":"cloudenthusiast","timestamp":"1684500660.0","content":"Selected Answer: B\nAWS Service Catalog allows you to create and manage catalogs of IT services that can be deployed within your organization. With Service Catalog, you can define a standardized set of products (solutions and tools in this case) that customers can self-service provision. By creating Service Catalog products, you can control and enforce the deployment of approved and validated solutions and tools.","comments":[{"upvote_count":"5","poster":"cloudenthusiast","comment_id":"901935","content":"On-Demand Mode: With on-demand mode, DynamoDB automatically scales its capacity to handle the application's traffic. \nDynamoDB Standard Table Class: The DynamoDB Standard table class provides a balance between cost and performance. \nCost-Effectiveness: By using on-demand mode, the company only pays for the actual read and write requests made to the table, rather than provisioning and paying for a fixed amount of capacity units in advance.","timestamp":"1684500720.0"}],"upvote_count":"3"},{"timestamp":"1684327440.0","poster":"nosense","comment_id":"900143","comments":[{"upvote_count":"1","content":"changed for C.\nOption A: need to purchase more capacity than they actually need This would lead to unnecessary costs.\nOption B: company's application is expected to have moderate to high read and write throughput, so this option would not be sufficient.\nC Configure DynamoDB with provisioned read and write by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class. Set DynamoDB auto scaling to a maximum defined capacity.","timestamp":"1684505220.0","poster":"nosense","comment_id":"901996"}],"upvote_count":"1","content":"Selected Answer: A\na for me"}]},{"id":"3URLXGlXlCtpp3s25aKN","timestamp":"2023-05-19 11:58:00","url":"https://www.examtopics.com/discussions/amazon/view/109703-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","question_images":[],"answers_community":["C (100%)"],"unix_timestamp":1684490280,"question_id":490,"choices":{"B":"In every business account, create an IAM user that has programmatic access. Configure the application to use the correct IAM user access key ID and secret access key to authenticate and read the DynamoDB table. Manually rotate IAM access keys every 30 days.","D":"Integrate DynamoDB with AWS Certificate Manager (ACM). Generate identity certificates to authenticate DynamoDB. Configure the application to use the correct certificate to authenticate and read the DynamoDB table.","A":"Integrate DynamoDB with AWS Secrets Manager in the inventory application account. Configure the application to use the correct secret from Secrets Manager to authenticate and read the DynamoDB table. Schedule secret rotation for every 30 days.","C":"In every business account, create an IAM role named BU_ROLE with a policy that gives the role access to the DynamoDB table and a trust policy to trust a specific role in the inventory application account. In the inventory account, create a role named APP_ROLE that allows access to the STS AssumeRole API operation. Configure the application to use APP_ROLE and assume the crossaccount role BU_ROLE to read the DynamoDB table."},"isMC":true,"answer":"C","answer_images":[],"answer_ET":"C","discussion":[{"poster":"cloudenthusiast","timestamp":"1684501080.0","upvote_count":"31","comment_id":"901938","content":"Selected Answer: C\nIAM Roles: IAM roles provide a secure way to grant permissions to entities within AWS. By creating an IAM role in each business account named BU_ROLE with the necessary permissions to access the DynamoDB table, the access can be controlled at the IAM role level.\nCross-Account Access: By configuring a trust policy in the BU_ROLE that trusts a specific role in the inventory application account (APP_ROLE), you establish a trusted relationship between the two accounts.\nLeast Privilege: By creating a specific IAM role (BU_ROLE) in each business account and granting it access only to the required DynamoDB table, you can ensure that each team's table is accessed with the least privilege principle.\nSecurity Token Service (STS): The use of STS AssumeRole API operation in the inventory application account allows the application to assume the cross-account role (BU_ROLE) in each business account.","comments":[{"poster":"TariqKipkemei","comment_id":"958034","upvote_count":"3","content":"Well broken down..thank you :)","timestamp":"1689912300.0"}]},{"comment_id":"1231525","upvote_count":"5","timestamp":"1718567520.0","poster":"MandAsh","content":"C because they have taken effort to explain it in details.. lol"},{"timestamp":"1693240500.0","comment_id":"992398","content":"Selected Answer: C\nKeyword: IAM ROLES","upvote_count":"4","poster":"Bennyboy789"},{"upvote_count":"3","poster":"Guru4Cloud","content":"Selected Answer: C\nC is the most secure option to meet the requirements.\n\nUsing cross-account IAM roles and role chaining allows the inventory application to securely access resources in other accounts. The roles provide temporary credentials and can be permissions controlled.","timestamp":"1692729000.0","comment_id":"987687"},{"upvote_count":"4","content":"Selected Answer: C\nLooks complex, but IAM role seems more probable, I go with C.","comment_id":"963569","poster":"hsinchang","timestamp":"1690365300.0"},{"comment_id":"932939","poster":"mattcl","comments":[{"poster":"awsgeek75","timestamp":"1704920820.0","upvote_count":"2","comment_id":"1119031","content":"A is wrong because it is incomplete. Just integrating with secrets manager doesn't give any access to DynamoDB."}],"timestamp":"1687641660.0","content":"Why not A?","upvote_count":"3"},{"comment_id":"930264","content":"Selected Answer: C\nIt's complex, but looks C.","upvote_count":"2","poster":"antropaws","timestamp":"1687420260.0"},{"content":"i'll go with C .. coming from two minds","poster":"eehhssaan","upvote_count":"3","timestamp":"1684570260.0","comment_id":"902437"},{"poster":"nosense","timestamp":"1684490280.0","comment_id":"901823","upvote_count":"2","comments":[{"timestamp":"1684639020.0","comment_id":"902859","poster":"omoakin","content":"CCCCCCCCCCC","upvote_count":"2"}],"content":"a or c. C looks like a more secure"}],"exam_id":31,"question_text":"A retail company has several businesses. The IT team for each business manages its own AWS account. Each team account is part of an organization in AWS Organizations. Each team monitors its product inventory levels in an Amazon DynamoDB table in the team's own AWS account.\n\nThe company is deploying a central inventory reporting application into a shared AWS account. The application must be able to read items from all the teams' DynamoDB tables.\n\nWhich authentication option will meet these requirements MOST securely?","topic":"1"}],"exam":{"isImplemented":true,"isBeta":false,"name":"AWS Certified Solutions Architect - Associate SAA-C03","id":31,"isMCOnly":true,"provider":"Amazon","numberOfQuestions":1019,"lastUpdated":"11 Apr 2025"},"currentPage":98},"__N_SSP":true}