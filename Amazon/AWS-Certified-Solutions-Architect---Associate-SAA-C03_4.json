{"pageProps":{"questions":[{"id":"US4Be4q9u7wKeShbNZjJ","url":"https://www.examtopics.com/discussions/amazon/view/148817-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":16,"answer_description":"","isMC":true,"answer":"AC","unix_timestamp":1728304140,"answer_ET":"AC","answer_images":[],"topic":"1","discussion":[{"content":"Selected Answer: AC\nsecurely integrate Amazon S3 with the application:\nhttps://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.html\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html#types-of-vpc-endpoints-for-s3","comment_id":"1313093","poster":"bujuman","upvote_count":"7","timestamp":"1731768840.0"},{"content":"Selected Answer: AC\nAn Amazon Cognito identity pool allows you to generate temporary AWS credentials (e.g., access tokens) for authenticated users. These credentials can be used to securely access AWS services like Amazon S3.\n\nBy creating an identity pool, the application can generate secure Amazon S3 access tokens for users after they successfully log in, ensuring that only authenticated users can upload or access documents in the S3 bucket.","comment_id":"1342896","upvote_count":"1","timestamp":"1737271020.0","poster":"FlyingHawk","comments":[{"upvote_count":"1","content":"C_ A VPC endpoint for Amazon S3 allows private connectivity between the application (hosted in a private subnet) and the S3 bucket. This ensures that data transfer between the application and S3 stays within the AWS network, improving security and performance.","comment_id":"1342898","poster":"FlyingHawk","timestamp":"1737271020.0"}]},{"content":"Selected Answer: AC\nA - Amazon Cognito identity pools provide temporary AWS credentials for authenticated users.\nB - User pools are for authentication (who the user is). Identity pools are for authorization (what the user can do).\nC - Traffic between your VPC and S3 stays within the AWS network, good. This also removes the need for a NAT Gateway for S3 access.\nD - Unnecessary and not secure.\nE - Users' IP addresses can change frequently (especially mobile users).","upvote_count":"2","comment_id":"1339070","timestamp":"1736575260.0","poster":"LeonSauveterre"},{"content":"respuesta correcta : A - B","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"1327980","timestamp":"1734448260.0","poster":"dragossky","content":"identity pool - authorization\nuser pool - authentication, in this case something needs to modify docs, so authorization"},{"poster":"luther77","content":"B doesnt make sense here. because user pools are used for authentication, not authorization","upvote_count":"2","timestamp":"1731950400.0","comment_id":"1314095"}],"timestamp":"1731006060.0","poster":"viejito","comment_id":"1308512"}],"exam_id":31,"question_images":[],"choices":{"C":"Create an Amazon S3 VPC endpoint in the same VPC where the company hosts the application.","A":"Create an Amazon Cognito identity pool to generate secure Amazon S3 access tokens for users when they successfully log in.","E":"Attach a policy to the S3 bucket that allows access only from the users' IP addresses.","B":"Use the existing Amazon Cognito user pool to generate Amazon S3 access tokens for users when they successfully log in.","D":"Create a NAT gateway in the VPC where the company hosts the application. Assign a policy to the S3 bucket to deny any request that is not initiated from Amazon Cognito."},"timestamp":"2024-10-07 14:29:00","question_text":"A company hosts an application in a private subnet. The company has already integrated the application with Amazon Cognito. The company uses an Amazon Cognito user pool to authenticate users.\n\nThe company needs to modify the application so the application can securely store user documents in an Amazon S3 bucket.\n\nWhich combination of steps will securely integrate Amazon S3 with the application? (Choose two.)","answers_community":["AC (100%)"]},{"id":"DzUMDe5qCWqC4zIT4Nom","unix_timestamp":1728304560,"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/148818-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"answer_images":[],"discussion":[{"upvote_count":"2","poster":"LeonSauveterre","content":"Selected Answer: D\nJust scale base on how many tasks left in the queue. CPU utilization is not an accurate metric. There could be just one task but it takes quite a while to process, in which case scaling is unnecessary.","timestamp":"1736575740.0","comment_id":"1339071"},{"upvote_count":"2","content":"Selected Answer: D\nThe bottleneck is at the processing tier, B and C are incorrect, processing tier instances are running at 100% CPU usage, and the SQS queue fills up. Because the peak times are variable and unpredictable, we should use the EC2 Auto Scaling target tracking policy to scale out the processing tier instances based on the size of the queue, A uses scheduled scaling for Amazon EC2 Auto Scaling is incorrect.","comment_id":"1335756","timestamp":"1735851780.0","poster":"FlyingHawk"},{"comment_id":"1335527","upvote_count":"1","poster":"GOTJ","content":"Selected Answer: D\nCheck this out:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html","timestamp":"1735817160.0"},{"poster":"EllenLiu","timestamp":"1735211820.0","upvote_count":"3","content":"Selected Answer: D\nThe bottleneck is from the processing tier.","comment_id":"1331890"},{"poster":"dragossky","upvote_count":"1","comment_id":"1327985","timestamp":"1734448560.0","comments":[{"comment_id":"1339429","upvote_count":"1","content":"The problem is from application tier","timestamp":"1736673900.0","poster":"Salilgen"},{"content":"Agree. But this \"SQS queue fill up\" (remember, SQS is meant for decouple web and processing tiers) suggest that the bottleneck is produced by the processing CPU bottleneck because web servers are sending more requests to the queue than the processing servers are able to process from the queue. As the first approach, I would try option D","comment_id":"1335503","upvote_count":"1","poster":"GOTJ","timestamp":"1735813800.0"},{"upvote_count":"1","content":"DynamoDB Accelerator is cache for dynamoDB","comment_id":"1331888","poster":"EllenLiu","timestamp":"1735211580.0"}],"content":"Selected Answer: B\nYes, ElastiCache can be used with DynamoDB to improve the performance and scalability of read-heavy or frequently accessed workloads. Amazon ElastiCache is a fully managed in-memory data store that supports popular caching engines such as Memcached and Redis."},{"upvote_count":"2","content":"Selected Answer: D\nAnswer is D","timestamp":"1729290960.0","poster":"aragon_saa","comment_id":"1299821"}],"answers_community":["D (91%)","9%"],"question_id":17,"answer_description":"","topic":"1","question_images":[],"choices":{"C":"Add an Amazon CloudFront distribution to cache the responses for the web tier. Use HTTP latency as a metric to determine when to scale.","D":"Use an Amazon EC2 Auto Scaling target tracking policy to scale out the processing tier instances. Use the ApproximateNumberOfMessages attribute to determine when to scale.","A":"Use scheduled scaling for Amazon EC2 Auto Scaling to scale out the processing tier instances for the duration of peak usage times. Use the CPU Utilization metric to determine when to scale.","B":"Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier. Use target utilization as a metric to determine when to scale."},"exam_id":31,"answer_ET":"D","question_text":"A company has a three-tier web application that processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer. The processing tier consists of EC2 instances. The company decoupled the web tier and processing tier by using Amazon Simple Queue Service (Amazon SQS). The storage layer uses Amazon DynamoDB.\n\nAt peak times, some users report order processing delays and halls. The company has noticed that during these delays, the EC2 instances are running at 100% CPU usage, and the SQS queue fills up. The peak times are variable and unpredictable.\n\nThe company needs to improve the performance of the application.\n\nWhich solution will meet these requirements?","timestamp":"2024-10-07 14:36:00"},{"id":"gV9Os0HmIHUz7vHtglu0","answer":"A","answer_description":"","timestamp":"2024-10-07 14:43:00","question_text":"A company's production environment consists of Amazon EC2 On-Demand Instances that run constantly between Monday and Saturday. The instances must run for only 12 hours on Sunday and cannot tolerate interruptions. The company wants to cost-optimize the production environment.\n\nWhich solution will meet these requirements MOST cost-effectively?","url":"https://www.examtopics.com/discussions/amazon/view/148819-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["A (100%)"],"topic":"1","unix_timestamp":1728304980,"question_images":[],"isMC":true,"answer_images":[],"question_id":18,"choices":{"B":"Purchase Convertible Reserved Instances for the EC2 instances that run for only 12 hours on Sunday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday.","C":"Use Spot Instances for the EC2 instances that run for only 12 hours on Sunday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday.","A":"Purchase Scheduled Reserved Instances for the EC2 instances that run for only 12 hours on Sunday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday.","D":"Use Spot Instances for the EC2 instances that run for only 12 hours on Sunday. Purchase Convertible Reserved Instances for the EC2 instances that run constantly between Monday and Saturday."},"discussion":[{"comment_id":"1339072","timestamp":"1736576100.0","content":"Selected Answer: A\nScheduled Reserved Instance: Perfect for workloads with predictable and recurring schedules (like 12 hours on Sunday). This is cost-efficient and ensures uninterrupted instances.\n\nConvertible Reserved Instance: Allows flexibility to change instance types, sizes, or OS during the term. However, they are not ideal for short, predictable schedules like 12 hours on Sunday. Scheduled Reserved Instances are a better fit.\n\nSpot Instances can be interrupted at any time. They do not guarantee uninterrupted operations.","upvote_count":"3","poster":"LeonSauveterre"},{"content":"Selected Answer: A\nas the instance cannot tolerate interryptions, so spot instances are out, C and D are incorrect, leave only A and B, Scheduled RI or Convertible RI, based on the AWS doc, Purchasing Reserved Instances on a recurring schedule lets you pay for compute capacity by the hour and obtain a capacity reservation ahead of time for only the time periods you will need it. as it only 12 hours on Sunday, so A will be cheaper than B\nhttps://aws.amazon.com/ec2/pricing/reserved-instances/pricing/.","timestamp":"1735856040.0","poster":"FlyingHawk","comments":[{"poster":"FlyingHawk","upvote_count":"1","timestamp":"1735856280.0","content":"Not the minimum commit for RI is one year, if you want the flexibility of change instance type within one year, B might be a better choice, however, considering the flexibility, saving plan for computing is a recommended solution over RIs, I guess this question should not appear in the exam if AWS wants to advocate the saving plan.","comment_id":"1335784"}],"upvote_count":"1","comment_id":"1335780"},{"upvote_count":"1","poster":"GOTJ","content":"Selected Answer: A\n\"A\" is the most straightforward option. However, I'm afraid this feature could be eventually removed and substituted by On-Demand Capacity Reservations and Savings Plans. If you try to use scheduled reservation in the EC2 console, you'll get the following banner:\n\n\"We recommend Savings Plans over Reserved Instances. Savings Plans are the easiest and most flexible way to save money on your AWS compute costs and offer lower prices (up to 72% off) just like Reserved Instances. To learn more and get started with Savings Plans click here\"","timestamp":"1735812360.0","comment_id":"1335480"},{"content":"Selected Answer: A\nScheduled reserved instances are purchase of reserved Instances on a recurring schedule\nhttps://aws.amazon.com/ec2/pricing/reserved-instances/buyer/","poster":"EllenLiu","comment_id":"1331899","upvote_count":"1","timestamp":"1735213800.0"},{"comment_id":"1313101","upvote_count":"3","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","timestamp":"1731770700.0","poster":"bujuman"},{"content":"Selected Answer: A\nstandard reserved instance is cheaper than convertible reserved instance","comment_id":"1298966","upvote_count":"4","timestamp":"1729114380.0","poster":"8621a7c"}],"exam_id":31,"answer_ET":"A"},{"id":"rNKBj4OcjOOXEDOtZxhR","discussion":[{"poster":"Ell89","content":"Selected Answer: B\nB- because all other answers mention EC2 which goes against the company not wanting to manage the underlying infrastructure.","comment_id":"1558330","timestamp":"1743963600.0","upvote_count":"1"},{"content":"Selected Answer: B\nA & C - Spot Instances are cost-effective but are subject to interruptions. \"The solution must also reduce the manual tasks.\"\nB - AWS Batch is a fully managed service for batch processing, ideal for workloads like image processing. It scales automatically, handles job scheduling, and eliminates the need to manage infrastructure. Step Functions provides robust orchestration with built-in support for retries, error handling, and dependencies, reducing manual tasks in the workflow.\nD - Using EC2 instances requires managing the underlying infrastructure. Also, EBS is not as scalable or cost-effective as S3 when you want to store large, growing numbers of files.","upvote_count":"3","poster":"LeonSauveterre","timestamp":"1736576400.0","comment_id":"1339076"},{"content":"Selected Answer: B\nA. Use Amazon Elastic Container Service (Amazon ECS) complexity \nC. Amazon FSx is not an ideal compared to s3\nD. Use a group of Amazon EC2 instances do not scalable","upvote_count":"4","timestamp":"1733059920.0","comment_id":"1320566","poster":"trinh_le"},{"content":"Selected Answer: B\nAnswer is B","upvote_count":"4","timestamp":"1729290900.0","comment_id":"1299820","poster":"aragon_saa"}],"answer":"B","question_id":19,"isMC":true,"question_images":[],"timestamp":"2024-10-07 14:51:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/148820-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"B","answer_images":[],"answers_community":["B (100%)"],"exam_id":31,"question_text":"A digital image processing company wants to migrate its on-premises monolithic application to the AWS Cloud. The company processes thousands of images and generates large files as part of the processing workflow.\n\nThe company needs a solution to manage the growing number of image processing jobs. The solution must also reduce the manual tasks in the image processing workflow. The company does not want to manage the underlying infrastructure of the solution.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","answer_description":"","unix_timestamp":1728305460,"choices":{"D":"Deploy a group of Amazon EC2 instances to process the images. Use AWS Step Functions to orchestrate the workflow. Store the processed files in an Amazon Elastic Block Store (Amazon EBS) volume.","B":"Use AWS Batch jobs to process the images. Use AWS Step Functions to orchestrate the workflow. Store the processed files in an Amazon S3 bucket.","C":"Use AWS Lambda functions and Amazon EC2 Spot Instances to process the images. Store the processed files in Amazon FSx.","A":"Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 Spot Instances to process the images. Configure Amazon Simple Queue Service (Amazon SQS) to orchestrate the workflow. Store the processed files in Amazon Elastic File System (Amazon EFS)."}},{"id":"LWtkXQwq7DIQhng06QoG","unix_timestamp":1728306780,"question_text":"A company's image-hosting website gives users around the world the ability to up load, view, and download images from their mobile devices. The company currently hosts the static website in an Amazon S3 bucket.\n\nBecause of the website's growing popularity, the website's performance has decreased. Users have reported latency issues when they upload and download images.\n\nThe company must improve the performance of the website.\n\nWhich solution will meet these requirements with the LEAST implementation effort?","choices":{"D":"Configure AWS Global Accelerator for the S3 bucket to improve network performance. Create an endpoint for the application to use Global Accelerator instead of the S3 bucket.","C":"Configure an Amazon CloudFront distribution that uses the S3 bucket as an origin to improve the download performance. Configure the application to use CloudFront to upload images to improve the upload performance. Create S3 buckets in multiple AWS Regions. Configure replication rules for the buckets to replicate users' data based on the users' location. Redirect downloads to the S3 bucket that is closest to each user's location.","A":"Configure an Amazon CloudFront distribution for the S3 bucket to improve the download performance. Enable S3 Transfer Acceleration to improve the upload performance.","B":"Configure Amazon EC2 instances of the right sizes in multiple AWS Regions. Migrate the application to the EC2 instances. Use an Application Load Balancer to distribute the website traffic equally among the EC2 instances. Configure AWS Global Accelerator to address global demand with low latency."},"topic":"1","exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/148821-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"answer_ET":"A","answers_community":["A (100%)"],"answer_images":[],"question_id":20,"discussion":[{"poster":"FlyingHawk","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1737272460.0","comment_id":"1342910","poster":"FlyingHawk","content":"Option C (Configure CloudFront for downloads, use CloudFront for uploads, create S3 buckets in multiple Regions, and configure replication rules):\nWhile this option improves performance, it requires significant effort to configure multiple S3 buckets, replication rules, and redirection logic. It is more complex than necessary for the company’s requirements."}],"timestamp":"1737272460.0","comment_id":"1342909","content":"Selected Answer: A\nA - By configuring a CloudFront distribution for the S3 bucket, the company can significantly improve download performance for users by serving images from the nearest edge location. S3 Transfer Acceleration uses CloudFront’s globally distributed edge locations to accelerate upload performance. It optimizes the path between the user’s device and the S3 bucket, reducing latency and improving upload speeds."},{"upvote_count":"1","timestamp":"1735597560.0","comment_id":"1334448","content":"Selected Answer: A\nObvious.","poster":"Denise123"},{"content":"Selected Answer: A\nAnswer is A","poster":"aragon_saa","upvote_count":"2","timestamp":"1729290900.0","comment_id":"1299819"}],"answer":"A","question_images":[],"timestamp":"2024-10-07 15:13:00","answer_description":""}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"isMCOnly":true,"isImplemented":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","id":31,"provider":"Amazon"},"currentPage":4},"__N_SSP":true}