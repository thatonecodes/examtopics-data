{"pageProps":{"questions":[{"id":"MIHJ1aNzB62endqSwMC3","unix_timestamp":1665994380,"exam_id":31,"question_text":"A company has applications that run on Amazon EC2 instances in a VPC. One of the applications needs to call the Amazon S3 API to store and read objects. According to the company's security regulations, no traffic from the applications is allowed to travel across the internet.\nWhich solution will meet these requirements?","answers_community":["A (100%)"],"isMC":true,"answer":"A","answer_description":"","discussion":[{"poster":"ArielSchivo","timestamp":"1665994380.0","comment_id":"697103","content":"Selected Answer: A\nGateway endpoints provide reliable connectivity to Amazon S3 and DynamoDB without requiring an internet gateway or a NAT device for your VPC. It should be option A.\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html","upvote_count":"33"},{"content":"Selected Answer: A\n***CORRECT***\nThe correct solution is Option A (Configure an S3 gateway endpoint.)\n\nA gateway endpoint is a VPC endpoint that you can use to connect to Amazon S3 from within your VPC. Traffic between your VPC and Amazon S3 never leaves the Amazon network, so it doesn't traverse the internet. This means you can access Amazon S3 without the need to use a NAT gateway or a VPN connection.\n\n***WRONG***\nOption B (creating an S3 bucket in a private subnet) is not a valid solution because S3 buckets do not have subnets.\n\nOption C (creating an S3 bucket in the same AWS Region as the EC2 instances) is not a requirement for meeting the given security regulations.\n\nOption D (configuring a NAT gateway in the same subnet as the EC2 instances) is not a valid solution because it would allow traffic to leave the VPC and travel across the Internet.","poster":"Buruguduystunstugudunstuy","timestamp":"1671648840.0","upvote_count":"19","comment_id":"752651"},{"poster":"PaulGa","upvote_count":"2","timestamp":"1726406580.0","content":"Selected Answer: A\nAns A - S3 gateway endpoint: dedicated end-end and private","comment_id":"1284145"},{"timestamp":"1721573640.0","content":"Selected Answer: A\nA is the correct answer","comment_id":"1252512","poster":"jaradat02","upvote_count":"1"},{"poster":"effiecancode","timestamp":"1720497780.0","upvote_count":"1","content":"it's definitely A","comment_id":"1244664"},{"upvote_count":"2","poster":"JohnZh","timestamp":"1711755780.0","comment_id":"1185749","content":"A. Configure an S3 gateway endpoint.\nCorrect: https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html\nWith a gateway endpoint, you can access Amazon S3 from your VPC, without requiring an internet gateway or NAT device for your VPC.\nAdditional you need to configure the route table for the subnet that EC2 stays, but we have the key word here.\n\nB. Create an S3 bucket in a private subnet.\nI am not aware that we can create S3 bucket in certain subnet.\n\nC. Create an S3 bucket in the same AWS Region as the EC2 instances.\nNot enough. Without VPC gateway endpoint, access will through go out to the internet.\n\nD. Configure a NAT gateway in the same subnet as the EC2 instances.\nNAT gateway outbound traffic should also go out to the internet."},{"comment_id":"1127766","content":"Selected Answer: A\nYou can access Amazon S3 from your VPC using gateway VPC endpoints. After you create the gateway endpoint, you can add it as a target in your route table for traffic destined from your VPC to Amazon S3.\n\nThere is no additional charge for using gateway endpoints.\n\nAmazon S3 supports both gateway endpoints and interface endpoints. With a gateway endpoint, you can access Amazon S3 from your VPC, without requiring an internet gateway or NAT device for your VPC, and with no additional cost. However, gateway endpoints do not allow access from on-premises networks, from peered VPCs in other AWS Regions, or through a transit gateway. For those scenarios, you must use an interface endpoint, which is available for an additional cost. \n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html","upvote_count":"2","timestamp":"1705835160.0","poster":"Charumathi"},{"timestamp":"1705268760.0","comment_id":"1122889","poster":"awsgeek75","content":"Selected Answer: A\nEC2 to S3 without public interne = S3 gatewat\nB: Cannot be implemented\nC: Even if you create EC2 and S3 in same region, without a S3 gateway it will use the public internet\nD: Makes no sense, NAT gateway in the subnet as EC2 instance to do what?","upvote_count":"2"},{"timestamp":"1698561900.0","poster":"Ruffyit","content":"A gateway endpoint is a VPC endpoint that you can use to connect to Amazon S3 from within your VPC. Traffic between your VPC and Amazon S3 never leaves the Amazon network, so it doesn't traverse the internet. This means you can access Amazon S3 without the need to use a NAT gateway or a VPN connection","upvote_count":"2","comment_id":"1056623"},{"comment_id":"1026800","timestamp":"1696609680.0","content":"Selected Answer: A\nAnswer \"A\" is correct because an endpoint create a way for the data to travel in the VPC","upvote_count":"2","poster":"David_Ang"},{"content":"Selected Answer: A\nPrevent traffic from traversing the internet = Gateway VPC endpoint for S3.","timestamp":"1692679500.0","poster":"TariqKipkemei","upvote_count":"2","comment_id":"987077"},{"poster":"Guru4Cloud","timestamp":"1691764320.0","comment_id":"978720","upvote_count":"1","content":"Selected Answer: A\nConfigure an S3 gateway endpoint"},{"timestamp":"1688226540.0","upvote_count":"2","poster":"tamefi5512","comment_id":"940131","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html"},{"content":"B. Creating an S3 in a private subnet restricts direct internet access to the bucket but does not provide a direct and secure connection between the EC2and the S3. The application would still need to traverse the internet to access the S3 API.\n\nC. Creating an S3 in the same Region as the EC2 does not inherently prevent traffic from traversing the internet.\n\nD. Configuring a NAT gateway allows outbound internet connectivity for resources in private subnets, but it does not provide a direct and secure connection to the S3 service. The traffic from the EC2 to the S3 API would still traverse the internet.\n\nThe most suitable solution is to configure an S3 gateway endpoint (option A). It provides a secure and private connection between the VPC and the S3 service without requiring the traffic to traverse the internet. With an S3 gateway endpoint, the EC2 can access the S3 API directly within the VPC, meeting the security requirement of preventing traffic from traveling across the internet.","upvote_count":"3","comment_id":"930217","timestamp":"1687416180.0","poster":"cookieMr"},{"content":"Selected Answer: A\nConfigure an S3 gateway endpoint is answer.","upvote_count":"2","comment_id":"903336","poster":"Bmarodi","timestamp":"1684680060.0"},{"timestamp":"1672605480.0","comment_id":"763334","upvote_count":"2","content":"Selected Answer: A\nS3 Gateway Endpoint is a VPC endpoint,","poster":"gustavtd"},{"comment_id":"737390","poster":"langiac","timestamp":"1670383860.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html","upvote_count":"2"},{"content":"A is correct","timestamp":"1669049220.0","upvote_count":"1","poster":"Wpcorgan","comment_id":"723757"}],"question_images":[],"answer_images":[],"answer_ET":"A","topic":"1","question_id":921,"url":"https://www.examtopics.com/discussions/amazon/view/85667-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2022-10-17 10:13:00","choices":{"D":"Configure a NAT gateway in the same subnet as the EC2 instances.","C":"Create an S3 bucket in the same AWS Region as the EC2 instances.","B":"Create an S3 bucket in a private subnet.","A":"Configure an S3 gateway endpoint."}},{"id":"OcLGZDHwSlY7uQLF72Ap","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/144971-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"timestamp":"1723893480.0","poster":"[Removed]","content":"Selected Answer: B\nB. Enable detailed monitoring on all EC2 instances. Use Amazon CloudWatch metrics to perform further analysis.","comment_id":"1267658","upvote_count":"2"},{"timestamp":"1723485060.0","poster":"muhammadahmer36","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html","comment_id":"1264747","upvote_count":"2"},{"content":"Selected Answer: B\nEnabling detailed monitoring on EC2 instances provides metrics at a 1-minute granularity, which is well within the required 2-minute granularity for performance analysis.","comment_id":"1261084","upvote_count":"2","timestamp":"1722866460.0","poster":"officedepotadmin"},{"poster":"komorebi","content":"Selected Answer: B\nAnswer is B","timestamp":"1722806220.0","upvote_count":"2","comment_id":"1260813"}],"choices":{"B":"Enable detailed monitoring on all EC2 instances. Use Amazon CloudWatch metrics to perform further analysis.","D":"Send EC2 logs to Amazon S3. Use Amazon Redshift to fetch logs from the S3 bucket to process raw data for further analysis with Amazon QuickSight.","A":"Send Amazon CloudWatch logs to Amazon Redshift. Use Amazon QuickS ght to perform further analysis.","C":"Create an AWS Lambda function to fetch EC2 logs from Amazon CloudWatch Logs. Use Amazon CloudWatch metrics to perform further analysis."},"exam_id":31,"topic":"1","answer_description":"","timestamp":"2024-08-04 08:26:00","answer":"B","question_images":[],"question_text":"A company hosts its multi-tier, public web application in the AWS Cloud. The web application runs on Amazon EC2 instances, and its database runs on Amazon RDS. The company is anticipating a large increase in sales during an upcoming holiday weekend. A solutions architect needs to build a solution to analyze the performance of the web application with a granularity of no more than 2 minutes.\n\nWhat should the solutions architect do to meet this requirement?","answers_community":["B (100%)"],"answer_images":[],"question_id":922,"unix_timestamp":1722752760,"isMC":true},{"id":"yH4aNWTnNOjp3TibKDpQ","discussion":[{"timestamp":"1740922260.0","poster":"ieffiong","comment_id":"1363960","content":"Selected Answer: C\nTake a sip of water and smile, you're almost there.","upvote_count":"1"},{"timestamp":"1723893660.0","upvote_count":"3","content":"Selected Answer: C\nC. Configure an S3 event notification to invoke an AWS Lambda function each time a user uploads a new photo to the application. Configure the Lambda function to generate a thumbnail and to upload the thumbnail to the second S3 bucket.","poster":"[Removed]","comment_id":"1267660"},{"upvote_count":"2","poster":"swati1508","timestamp":"1723057560.0","content":"C is correct","comment_id":"1262202"},{"poster":"komorebi","timestamp":"1722806280.0","comment_id":"1260814","content":"Selected Answer: C\nAnswer is C","upvote_count":"2"}],"answers_community":["C (100%)"],"exam_id":31,"unix_timestamp":1722753120,"topic":"1","answer_description":"","question_text":"A company runs an application that stores and shares photos. Users upload the photos to an Amazon S3 bucket. Every day, users upload approximately 150 photos. The company wants to design a solution that creates a thumbnail of each new photo and stores the thumbnail in a second S3 bucket.\n\nWhich solution will meet these requirements MOST cost-effectively?","timestamp":"2024-08-04 08:32:00","answer_ET":"C","answer_images":[],"choices":{"C":"Configure an S3 event notification to invoke an AWS Lambda function each time a user uploads a new photo to the application. Configure the Lambda function to generate a thumbnail and to upload the thumbnail to the second S3 bucket.","D":"Configure S3 Storage Lens to invoke an AWS Lambda function each time a user uploads a new photo to the application. Configure the Lambda function to generate a thumbnail and to upload the thumbnail to a second S3 bucket.","A":"Configure an Amazon EventBridge scheduled rule to invoke a script every minute on a long-running Amazon EMR cluster. Configure the script to generate thumbnails for the photos that do not have thumbnails. Configure the script to upload the thumbnails to the second S3 bucket.","B":"Configure an Amazon EventBridge scheduled rule to invoke a script every minute on a memory-optimized Amazon EC2 instance that is always on. Configure the script to generate thumbnails for the photos that do not have thumbnails. Configure the script to upload the thumbnails to the second S3 bucket."},"question_id":923,"isMC":true,"answer":"C","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/144972-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"Nyedic5H6gCX03fsFveZ","isMC":true,"exam_id":31,"discussion":[{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/batch-ops.html","timestamp":"1736254800.0","poster":"Salilgen","comment_id":"1337552","upvote_count":"1"},{"comment_id":"1335936","poster":"LeonSauveterre","content":"Selected Answer: D\nTakeaways:\n1. S3 Inventory provides a flat file report of the objects in an S3 bucket, including metadata such as storage class, size, and last modified date. Now you can easily find files \"older than 3 years\".\n2. The Lambda function can be used to filter objects based on the company's requirements (excluding the subset of data to retain) and to delete the objects programmatically.\n3. S3 Batch Operations allow the execution of bulk operations (e.g., delete operations) on a large number of S3 objects.\n\nA - Running a script on an EC2 instance is not serverless.\nB - AWS Batch is designed for batch computing workloads, not operations like deleting S3 objects.\nC - AWS Glue crawlers are designed to extract metadata and schema from data stored in S3 for querying and ETL processes, not for managing or deleting objects.","upvote_count":"1","timestamp":"1735891440.0"},{"upvote_count":"2","content":"yes D is the right answer","timestamp":"1727568300.0","poster":"agbor_tambe","comment_id":"1290871"},{"poster":"[Removed]","content":"Selected Answer: D\nD sounds right","timestamp":"1723893780.0","upvote_count":"2","comment_id":"1267661"},{"upvote_count":"3","comment_id":"1264750","poster":"muhammadahmer36","timestamp":"1723485360.0","content":"Selected Answer: D\nEnable S3 Inventory. Create an AWS Lambda function to filter and delete objects. Invoke the Lambda function with S3 Batch Operations to delete objects by using the inventory reports."},{"comment_id":"1262203","timestamp":"1723057620.0","content":"D is correct","upvote_count":"2","poster":"swati1508"}],"answer_ET":"D","choices":{"C":"Provision an AWS Glue crawler to query objects older than 3 years. Save the manifest file of old objects. Create a script to delete objects in the manifest.","A":"Use S3 Inventory to list all objects. Use the AWS CLI to create a script that runs on an Amazon EC2 instance that deletes objects from the inventory list.","B":"Use AWS Batch to delete objects older than 3 years except for the data that must be retained.","D":"Enable S3 Inventory. Create an AWS Lambda function to filter and delete objects. Invoke the Lambda function with S3 Batch Operations to delete objects by using the inventory reports."},"question_text":"A company has stored millions of objects across multiple prefixes in an Amazon S3 bucket by using the Amazon S3 Glacier Deep Archive storage class. The company needs to delete all data older than 3 years except for a subset of data that must be retained. The company has identified the data that must be retained and wants to implement a serverless solution.\n\nWhich solution will meet these requirements?","timestamp":"2024-08-07 21:07:00","answers_community":["D (100%)"],"answer_images":[],"topic":"1","answer":"D","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/145209-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","unix_timestamp":1723057620,"question_id":924},{"id":"zh0fmlihLWHHS1u2cUjy","exam_id":31,"isMC":true,"answers_community":["C (100%)"],"answer_description":"","choices":{"C":"Create individual IAM roles for each Lambda function. Grant the IAM roles access to the S3 bucket. Assign each IAM role as the Lambda execution role for its corresponding Lambda function.","A":"Grant full S3 bucket access to all Lambda functions through a shared IAM role.","B":"Configure the Lambda functions to run within a VPC. Configure a bucket policy to grant access based on the Lambda functions' VPC endpoint IP addresses.","D":"Configure a bucket policy granting access to the Lambda functions based on their function ARNs."},"unix_timestamp":1723057680,"discussion":[{"content":"Selected Answer: C\nA - Full access? No!\nB - Theoretically possible but IP-based policies are harder to manage and not as secure as IAM roles.\nC - By creating separate IAM roles for each Lambda function, permissions can be narrowly scoped to each function's specific needs.\nD - This would actually work. It's just that bucket policies based on function ARNs are less flexible and scalable compared to IAM roles, especially when you need to manage permissions for multiple Lambda functions or add new functions.","comments":[{"comment_id":"1335941","upvote_count":"1","poster":"LeonSauveterre","timestamp":"1735892220.0","content":"Out of my instinct, least privilege leads to individually managing each function."}],"poster":"LeonSauveterre","timestamp":"1735892160.0","comment_id":"1335940","upvote_count":"1"},{"poster":"56ce46c","comment_id":"1286783","upvote_count":"2","timestamp":"1726831260.0","content":"i think D is also right\nS3 Bucket Policy: Use an S3 bucket policy that grants access to the specific Lambda functions based on their function ARNs. This ensures that only the authorized Lambda functions can retrieve data from the S3 bucket."},{"content":"Selected Answer: C\nC sounds right","upvote_count":"2","poster":"[Removed]","comment_id":"1267665","timestamp":"1723894020.0"},{"timestamp":"1723057680.0","poster":"swati1508","upvote_count":"2","comment_id":"1262204","content":"A, B and D wrong only C is right"}],"answer_images":[],"question_text":"A company is building an application on AWS. The application uses multiple AWS Lambda functions to retrieve sensitive data from a single Amazon S3 bucket for processing. The company must ensure that only authorized Lambda functions can access the data. The solution must comply with the principle of least privilege.\n\nWhich solution will meet these requirements?","topic":"1","timestamp":"2024-08-07 21:08:00","question_id":925,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/145210-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"answer":"C"}],"exam":{"name":"AWS Certified Solutions Architect - Associate SAA-C03","isImplemented":true,"id":31,"numberOfQuestions":1019,"provider":"Amazon","lastUpdated":"11 Apr 2025","isBeta":false,"isMCOnly":true},"currentPage":185},"__N_SSP":true}