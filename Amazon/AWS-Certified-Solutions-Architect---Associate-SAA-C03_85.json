{"pageProps":{"questions":[{"id":"M0vvsClQvktQ0toE3EEg","answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/85264-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"timestamp":"2022-10-12 12:02:00","question_text":"A company has an application that provides marketing services to stores. The services are based on previous purchases by store customers. The stores upload transaction data to the company through SFTP, and the data is processed and analyzed to generate new marketing offers. Some of the files can exceed 200 GB in size.\nRecently, the company discovered that some of the stores have uploaded files that contain personally identifiable information (PII) that should not have been included. The company wants administrators to be alerted if PII is shared again. The company also wants to automate remediation.\nWhat should a solutions architect do to meet these requirements with the LEAST development effort?","question_id":421,"choices":{"C":"Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain PII, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain PII.","B":"Use an Amazon S3 bucket as a secure transfer point. Use Amazon Macie to scan the objects in the bucket. If objects contain PII, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain PII.","A":"Use an Amazon S3 bucket as a secure transfer point. Use Amazon Inspector to scan the objects in the bucket. If objects contain PII, trigger an S3 Lifecycle policy to remove the objects that contain PII.","D":"Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain PII, use Amazon Simple Email Service (Amazon SES) to trigger a notification to the administrators and trigger an S3 Lifecycle policy to remove the meats that contain PII."},"answers_community":["B (63%)","D (36%)","1%"],"discussion":[{"timestamp":"1668295020.0","comment_id":"716972","upvote_count":"48","poster":"Gatt","content":"I have a problem with answer B. The question says: \"automate remediation\". B says that you inform the administrator and he removes the data manually, that's not automating remediation. Very weird, that would mean that D is correct - but it's so much harder to implement.","comments":[{"poster":"ronaldchow","timestamp":"1671830940.0","content":"By \"automate remediation\", I thought it meant to use Amazon Macie to automate discovery on personally identifiable information.\nhttps://aws.amazon.com/macie/\n- Discover sensitive data across your S3 environment to increase visibility and automated remediation of data security risks.","upvote_count":"6","comment_id":"754556"},{"timestamp":"1715662980.0","upvote_count":"7","content":"The answer is B because it requires the \"LEAST development effort\".\nThe confusing part is that remediation is NOT automated because the solution alerts the administrators but still requires manual action. Its a bad question.","comment_id":"1211220","poster":"wamy1738","comments":[{"comments":[{"content":"What kind of life cycle policy removes meat ?. Life cycle only removes objects that exceeds programmed time.","comment_id":"1222194","poster":"3680113","timestamp":"1717164840.0","upvote_count":"2"}],"comment_id":"1222193","upvote_count":"2","content":"B Correct, a bad and selfish question indeed. AWS doesn't care if they actually follow through on the standards they created, they are only interested in us answering the question right . MIND YOU ALL THE OPTIKNS REQUIRE MANUAL COMPLETION OF PROCESS.","timestamp":"1717164720.0","poster":"3680113"}]},{"comment_id":"883084","poster":"Maxpayne009","upvote_count":"7","comments":[{"timestamp":"1703484540.0","content":"You're confusing \"files to retrieve samples from\" with \"files to analyze\". Macie can analyze 20 GB files.","upvote_count":"5","comment_id":"1105049","poster":"pentium75"}],"content":"Macie has file size limit and clearly question mentions 200GB filesizes are possible. Lambda is the way to go ..","timestamp":"1682634960.0"},{"comment_id":"766836","content":"Pay attention to the entire question as in What should a solutions architect do to meet these requirements with the LEAST development effort? That is why Macie is used. Answer is B","upvote_count":"9","poster":"Joxtat","timestamp":"1672936560.0"}]},{"upvote_count":"24","content":"Selected Answer: B\nAmazon Macie is a data security and data privacy service that uses machine learning (ML) and pattern matching to discover and protect your sensitive data","timestamp":"1668346740.0","comments":[{"timestamp":"1668347040.0","poster":"grzeev","content":"Macie automatically detects a large and growing list of sensitive data types, including personally identifiable information (PII) such as names, addresses, and credit card numbers. It also gives you constant visibility of the data security and data privacy of your data stored in Amazon S3","upvote_count":"13","comment_id":"717337"}],"poster":"grzeev","comment_id":"717333"},{"poster":"MundiChor","comment_id":"1463047","content":"Selected Answer: B\nAlthough I selected B on the account of \"Least Developmental Effort\", However I feel the question itself is wrong. In lieu of being a difficult and tricky question, it contradicts itself too many times.\n1. Macie has a S3 file limitation of 20 GB (in case of ZIP archive), here the files are exceeding 200 GB with no indication of breaking the file or compression.\n2. The question states that the customer wants to automate remediation; now the word remediation means \"to solve\" and automate remediation means that there should not be any manual effort. But none of the options provide any solution for that.\n\nI would rate the trust of this question pretty low.","upvote_count":"1","timestamp":"1743763800.0"},{"upvote_count":"1","comment_id":"1410311","timestamp":"1742983920.0","content":"Selected Answer: C\nCan't be B Macie has a 5Gb limit\nC is better than D Lambda can be set up to remove data immediately and AWS state their #1 priority is security.","poster":"MPG1970"},{"upvote_count":"1","timestamp":"1741174500.0","comment_id":"1365371","content":"Selected Answer: B\nYou can also leverage Macie integration with Amazon EventBridge and AWS Security Hub to monitor, process, and remediate findings by using other services, applications, and systems.","poster":"LovaP"},{"poster":"Vandaman","comment_id":"1358190","upvote_count":"1","timestamp":"1739868360.0","content":"Selected Answer: D\nThe remediation must be automated"},{"timestamp":"1738601340.0","comment_id":"1351038","content":"Selected Answer: B\nI think \"The company wants administrators to be alerted if PII is shared again\" is the key here.. so B is correct answer.","upvote_count":"1","poster":"Panknil"},{"poster":"kyd0nix","timestamp":"1738527600.0","content":"Selected Answer: B\nNone are correct. \nA does not alert the admins.\nB does not automate solution.\nC and D imply dev effort.","upvote_count":"1","comment_id":"1350639"},{"timestamp":"1738151100.0","upvote_count":"1","comment_id":"1348500","content":"Selected Answer: D\nMacie has file limitation of 5 GB whereas Custom Lambda function allows you to handle files larger than 5 GB, overcoming Macie’s limitation.","poster":"AwsAbhiKumar"},{"upvote_count":"1","comment_id":"1347515","poster":"Dharmarajan","timestamp":"1738002660.0","content":"Selected Answer: B\nB appears most appropriate out of the given option, however it does not address automation of remediation.\nHowever in the view of remediation, the other options do not address it either, so B is most appropriate."},{"timestamp":"1737715440.0","comment_id":"1346064","poster":"dariar","content":"Selected Answer: D\nThe good anwser is D, even if \"sensitive data\" = \"macie\". \nMacie has imits for analythins files, so 200GB won't pass :\n------\nSize of an individual file to analyze:\nAdobe Portable Document Format (.pdf) file: 1,024 MB\nApache Avro object container (.avro) file: 8 GB\nApache Parquet (.parquet) file: 8 GB\nEmail message (.eml) file: 20 GB\nGNU Zip compressed archive (.gz or .gzip) file: 8 GB\nMicrosoft Excel workbook (.xls or .xlsx) file: 512 MB\nMicrosoft Word document (.doc or .docx) file: 512 MB\nNon-binary text file: 20 GB\nTAR archive (.tar) file: 20 GB\nZIP compressed archive (.zip) file: 8 GB\n-------\nAlso, the anwser B doesn't provide an auto-remediation, the admin still needs to remove the file manually.\nVery tricky question, but I think the right fit is D.","upvote_count":"1"},{"comment_id":"1339845","comments":[{"poster":"AwsAbhiKumar","upvote_count":"1","comment_id":"1348501","timestamp":"1738151160.0","content":"Well this is correct but not in this situation where some file can exceed 200 GB (Macie has limit of 5GB)"}],"upvote_count":"1","timestamp":"1736759640.0","content":"Selected Answer: B\nPII + S3 == Amazon Macie","poster":"AshishDhole"},{"timestamp":"1736546700.0","comment_id":"1338989","poster":"Rcosmos","content":"Selected Answer: B\nNotificações com Amazon SNS:\n\nQuando o Macie detecta PII, ele pode ser configurado para acionar uma notificação via SNS, alertando os administradores para tomar as ações necessárias.\nAutomação parcial:\n\nEmbora o Macie não remova automaticamente os objetos, ele permite que administradores sejam informados para realizar a correção manualmente, garantindo controle sobre os dados.\nMínimo esforço de desenvolvimento:\n\nEssa abordagem utiliza serviços nativos da AWS sem necessidade de scripts ou funções personalizadas, reduzindo significativamente o tempo e o custo de implementação.","upvote_count":"1"},{"timestamp":"1735668720.0","comment_id":"1334970","upvote_count":"1","poster":"satyaammm","content":"Selected Answer: B\nUsing Amazon Macie is most suitable for a S3 bucket and using SNS is also suitable as both of these services resolve the issues with least operational overhead."},{"upvote_count":"1","content":"Selected Answer: B\nAmazon macie is used to fish out pii","timestamp":"1735598040.0","comment_id":"1334457","poster":"oluwafemiapara"},{"content":"Selected Answer: D\nI would say the answer is D - Macie maximum file size is 20GB (If a file is larger than the applicable quota, Macie doesn't analyze any data in the file. according to AWS documentation:\nhttps://docs.aws.amazon.com/macie/latest/user/macie-quotas.html\n\nAlso, B option doesn´t meet the requirement of automate remediation.","upvote_count":"2","timestamp":"1734009780.0","comment_id":"1325624","poster":"Trevisan"},{"timestamp":"1729441080.0","content":"B is closest, but Macie should trigger Lambda for remediation","comment_id":"1300562","poster":"rudyydmitrij","upvote_count":"3"}],"unix_timestamp":1665568920,"question_images":[],"topic":"1","exam_id":31,"answer_description":"","answer_ET":"B","answer_images":[]},{"id":"B1zGpLdmptd2AZwZ8BPR","exam_id":31,"answer_description":"","answers_community":["C (100%)"],"topic":"1","question_images":[],"question_id":422,"question_text":"A company wants to securely exchange data between its software as a service (SaaS) application Salesforce account and Amazon S3. The company must encrypt the data at rest by using AWS Key Management Service (AWS KMS) customer managed keys (CMKs). The company must also encrypt the data in transit. The company has enabled API access for the Salesforce account.","isMC":true,"answer_images":[],"choices":{"C":"Create Amazon AppFlow flows to transfer the data securely from Salesforce to Amazon S3.","B":"Create an AWS Step Functions workflow. Define the task to transfer the data securely from Salesforce to Amazon S3.","D":"Create a custom connector for Salesforce to transfer the data securely from Salesforce to Amazon S3.","A":"Create AWS Lambda functions to transfer the data securely from Salesforce to Amazon S3."},"discussion":[{"poster":"cloudenthusiast","content":"Selected Answer: C\nAmazon AppFlow is a fully managed integration service that allows you to securely transfer data between different SaaS applications and AWS services. It provides built-in encryption options and supports encryption in transit using SSL/TLS protocols. With AppFlow, you can configure the data transfer flow from Salesforce to Amazon S3, ensuring data encryption at rest by utilizing AWS KMS CMKs.","upvote_count":"15","comment_id":"901292","timestamp":"1684419720.0"},{"comment_id":"989082","timestamp":"1692872880.0","upvote_count":"8","content":"Selected Answer: C\n° Amazon AppFlow can securely transfer data between Salesforce and Amazon S3.\n° AppFlow supports encrypting data at rest in S3 using KMS CMKs.\n° AppFlow supports encrypting data in transit using HTTPS/TLS.\n° AppFlow provides built-in support and templates for Salesforce and S3, requiring less custom configuration than solutions like Lambda, Step Functions, or custom connectors.\n° So Amazon AppFlow is the easiest way to meet all the requirements of securely transferring data between Salesforce and S3 with encryption at rest and in transit.","poster":"Guru4Cloud"},{"upvote_count":"2","content":"Selected Answer: C\ni do like myself some appflow flow","timestamp":"1722873300.0","comment_id":"1261107","poster":"1e22522"},{"content":"SAAS=aws appflow","comment_id":"1191357","poster":"zinabu","upvote_count":"4","timestamp":"1712550900.0"},{"upvote_count":"3","content":"Ans : C\nSalesforce --------> Amazon AppFlow -----> S3","timestamp":"1704816900.0","comment_id":"1117659","poster":"cvoiceip"},{"poster":"hsinchang","comment_id":"962740","content":"securely transfer data between Software-as-a-Service (SaaS) applications and AWS -> AppFlow","upvote_count":"3","timestamp":"1690290420.0"},{"comment_id":"924837","timestamp":"1686888840.0","poster":"TariqKipkemei","upvote_count":"2","content":"Selected Answer: C\nWith Amazon AppFlow automate bi-directional data flows between SaaS applications and AWS services in just a few clicks"},{"timestamp":"1685969760.0","upvote_count":"3","comment_id":"915453","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/appflow/latest/userguide/what-is-appflow.html","poster":"DrWatson"},{"timestamp":"1685869500.0","poster":"Abrar2022","comment_id":"914276","upvote_count":"3","content":"All you need to know is that AWS AppFlow securely transfers data between different SaaS applications and AWS services"},{"comment_id":"902259","timestamp":"1684538160.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/appflow/latest/userguide/salesforce.html","poster":"hiroohiroo","upvote_count":"4"},{"comment_id":"900048","poster":"Efren","content":"Selected Answer: C\nSaas with another service, AppFlow","timestamp":"1684323060.0","upvote_count":"2"}],"timestamp":"2023-05-17 13:31:00","unix_timestamp":1684323060,"answer_ET":"C","answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/109525-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"pVhxWXcXReL9bFTJ0fby","answer_description":"","exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/109446-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"B","answer":"B","choices":{"A":"Use AWS Global Accelerator to create an accelerator. Create an Application Load Balancer (ALB) behind an accelerator endpoint that uses Global Accelerator integration and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the ALB.","D":"Create an Amazon CloudFront content delivery network (CDN) endpoint. Create an Application Load Balancer (ALB) behind the endpoint and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the ALB. Update CloudFront to use the ALB as the origin.","B":"Use AWS Global Accelerator to create an accelerator. Create a Network Load Balancer (NLB) behind an accelerator endpoint that uses Global Accelerator integration and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the NLB.","C":"Create an Amazon CloudFront content delivery network (CDN) endpoint. Create a Network Load Balancer (NLB) behind the endpoint and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the NLB. Update CloudFront to use the NLB as the origin."},"question_text":"A company is developing a mobile gaming app in a single AWS Region. The app runs on multiple Amazon EC2 instances in an Auto Scaling group. The company stores the app data in Amazon DynamoDB. The app communicates by using TCP traffic and UDP traffic between the users and the servers. The application will be used globally. The company wants to ensure the lowest possible latency for all users.\n\nWhich solution will meet these requirements?","question_images":[],"unix_timestamp":1684260060,"discussion":[{"upvote_count":"3","comment_id":"1197110","timestamp":"1729155480.0","poster":"sandordini","content":"Selected Answer: B\nMobile gaming, UDP > AWS Global Accelarator + NLB"},{"content":"TCP/UDP/IP based communication with server =NLB \nfor global low latency communication if IP/udp/tCP based = aws global accelarator","upvote_count":"4","comment_id":"1191360","timestamp":"1728362340.0","poster":"zinabu"},{"content":"Selected Answer: B\nUDP == NLB\nNLB can't be used with Cloudfront, so we have to play with AWS Global accelerator","timestamp":"1718636400.0","comment_id":"1099095","upvote_count":"4","poster":"Mikado211"},{"comment_id":"989080","upvote_count":"3","timestamp":"1708777500.0","content":"Selected Answer: B\nUse AWS Global Accelerator to create an accelerator. Create a Network Load Balancer (NLB) behind an accelerator endpoint that uses Global Accelerator integration and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the NLB","poster":"Guru4Cloud"},{"timestamp":"1703057040.0","comment_id":"928172","upvote_count":"3","poster":"TariqKipkemei","content":"Selected Answer: B\nTCP and UDP = global accelerator and Network Load Balancer"},{"poster":"antropaws","upvote_count":"2","comment_id":"915220","timestamp":"1701772260.0","content":"Selected Answer: B\nClearly B."},{"comment_id":"903581","upvote_count":"4","timestamp":"1700618100.0","poster":"eddie5049","content":"Selected Answer: B\nNLB + Accelerator"},{"comment_id":"902258","upvote_count":"4","poster":"hiroohiroo","timestamp":"1700442840.0","content":"Selected Answer: B\nAWS Global Accelerator+NLB"},{"content":"Selected Answer: B\nUDP, Global Accelerator plus NLB","upvote_count":"2","comment_id":"900581","poster":"Efren","timestamp":"1700273280.0"},{"upvote_count":"4","poster":"nosense","comment_id":"899470","timestamp":"1700164860.0","content":"Selected Answer: B\nAWS Global Accelerator is a better solution for the mobile gaming app than CloudFront"}],"isMC":true,"answers_community":["B (100%)"],"timestamp":"2023-05-16 20:01:00","question_id":423,"answer_images":[],"topic":"1"},{"id":"ic427enHCBHrZM7zedL7","answer_ET":"B","question_id":424,"unix_timestamp":1684420080,"answer_description":"","choices":{"D":"Write orders to an Amazon Simple Queue Service (Amazon SQS) queue when the EC2 instance reaches CPU threshold limits. Use scheduled scaling of EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SQS queue and process orders into the database.","A":"Increase the instance size of the EC2 instance when traffic is high. Write orders to Amazon Simple Notification Service (Amazon SNS). Subscribe the database endpoint to the SNS topic.","C":"Write orders to Amazon Simple Notification Service (Amazon SNS). Subscribe the database endpoint to the SNS topic. Use EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SNS topic.","B":"Write orders to an Amazon Simple Queue Service (Amazon SQS) queue. Use EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SQS queue and process orders into the database."},"isMC":true,"discussion":[{"poster":"cloudenthusiast","timestamp":"1700324880.0","content":"Selected Answer: B\nBy decoupling the write operation from the processing operation using SQS, you ensure that the orders are reliably stored in the queue, regardless of the processing capacity of the EC2 instances. This allows the processing to be performed at a scalable rate based on the available EC2 instances, improving the overall reliability and speed of order processing.","comment_id":"901295","upvote_count":"12"},{"comment_id":"1124544","poster":"omarshaban","timestamp":"1721161560.0","content":"IN MY EXAM","upvote_count":"9"},{"content":"Selected Answer: B\nDecoupling the order processing from the application using Amazon SQS and leveraging Auto Scaling to handle the processing of orders based on the workload in the SQS queue is indeed the most efficient and scalable approach. This architecture addresses both reliability and performance concerns during traffic spikes.","timestamp":"1708777440.0","upvote_count":"4","comment_id":"989079","poster":"Guru4Cloud"},{"poster":"TariqKipkemei","content":"Selected Answer: B\nWrite orders to an Amazon Simple Queue Service (Amazon SQS) queue. Use EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SQS queue and process orders into the database.","upvote_count":"3","comment_id":"928173","timestamp":"1703057220.0"},{"timestamp":"1701772380.0","comment_id":"915222","upvote_count":"3","poster":"antropaws","content":"Selected Answer: B\n100% B."},{"comment_id":"910648","timestamp":"1701307500.0","content":"BBBBBBBBBB","upvote_count":"3","poster":"omoakin"}],"url":"https://www.examtopics.com/discussions/amazon/view/109653-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"answers_community":["B (100%)"],"exam_id":31,"question_text":"A company has an application that processes customer orders. The company hosts the application on an Amazon EC2 instance that saves the orders to an Amazon Aurora database. Occasionally when traffic is high the workload does not process orders fast enough.\n\nWhat should a solutions architect do to write the orders reliably to the database as quickly as possible?","timestamp":"2023-05-18 16:28:00","answer_images":[],"answer":"B","topic":"1"},{"id":"gOEbZJ6uaDSKK1l9nyWj","choices":{"A":"Use AWS Glue with a Scala job","C":"Use AWS Lambda with a Python script","D":"Use AWS Glue with a PySpark job","B":"Use Amazon EMR with an Apache Spark script"},"answer":"C","question_text":"An IoT company is releasing a mattress that has sensors to collect data about a user’s sleep. The sensors will send data to an Amazon S3 bucket. The sensors collect approximately 2 MB of data every night for each mattress. The company must process and summarize the data for each mattress. The results need to be available as soon as possible. Data processing will require 1 GB of memory and will finish within 30 seconds.\n\nWhich solution will meet these requirements MOST cost-effectively?","unix_timestamp":1684313760,"timestamp":"2023-05-17 10:56:00","url":"https://www.examtopics.com/discussions/amazon/view/109501-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["C (100%)"],"answer_ET":"C","exam_id":31,"answer_description":"","discussion":[{"upvote_count":"7","content":"Selected Answer: C\nAWS Lambda charges you based on the number of invocations and the execution time of your function. Since the data processing job is relatively small (2 MB of data), Lambda is a cost-effective choice. You only pay for the actual usage without the need to provision and maintain infrastructure.","comments":[{"comments":[{"poster":"BillaRanga","upvote_count":"3","content":"Lambda can support upto 10 GB, But 512M is under free tier","comment_id":"1146021","timestamp":"1723276200.0"},{"timestamp":"1706482020.0","upvote_count":"3","poster":"nilandd44gg","comment_id":"965822","content":"C is valid.\nLambda quotas: \nMemory - 128 MB to 10,240 MB, in 1-MB increments.\n\nNote: Lambda allocates CPU power in proportion to the amount of memory configured. You can increase or decrease the memory and CPU power allocated to your function using the Memory (MB) setting. At 1,769 MB, a function has the equivalent of one vCPU.\n\nFunction timeout 900 seconds (15 minutes)\n\n4 KB, for all environment variables associated with the function, in aggregate\nhttps://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html"}],"timestamp":"1703035140.0","comment_id":"928020","upvote_count":"2","poster":"joechen2023","content":"but the question states \"Data processing will require 1 GB of memory and will finish within 30 seconds.\" so it can't be C as Lambda support maximum 512M"}],"comment_id":"901297","timestamp":"1700325000.0","poster":"cloudenthusiast"},{"timestamp":"1708721340.0","content":"Selected Answer: C\nThe data processing is lightweight, only requiring 1 GB memory and finishing in under 30 seconds. Lambda is designed for short, transient workloads like this.\nLambda scales automatically, invoking the function as needed when new data arrives. No servers to manage.\nLambda has a very low cost. You only pay for the compute time used to run the function, billed in 100ms increments. Much cheaper than provisioning EMR or Glue.\nProcessing can begin as soon as new data hits the S3 bucket by triggering the Lambda function. Provides low latency.","poster":"Guru4Cloud","comment_id":"988611","upvote_count":"5"},{"poster":"Chiquitabandita","timestamp":"1714790280.0","comment_id":"1061897","comments":[{"content":"That's the point here, technically all the options are good and will work, but since we are on a small amount of data Lambda will be the cheapest one, usually Glue or EMR will be kept for a big amount of data.\n\nHere is a topic where people did a comparison in comments : https://www.reddit.com/r/aws/comments/9umxv1/aws_glue_vs_lambda_costbenefit/","timestamp":"1718027760.0","poster":"Mikado211","upvote_count":"4","comment_id":"1092617"}],"upvote_count":"4","content":"I understand C is a common answer \"throw Lambda\" seems to be a common theme for questions that need processing under 15 minutes for the test. but in reality, can the other solutions be viable options as well?"},{"comment_id":"1060316","poster":"TariqKipkemei","timestamp":"1714624560.0","content":"Selected Answer: C\n\"processing will require 1 GB of memory and will finish within 30 seconds\", perfect for AWS Lambda.","upvote_count":"4"},{"upvote_count":"3","poster":"antropaws","comment_id":"915226","content":"Selected Answer: C\nI reckon C, but I would consider other well founded options.","timestamp":"1701772500.0"},{"content":"Selected Answer: C\nc anyway the MOST cost-effectively","upvote_count":"3","poster":"nosense","comment_id":"899893","timestamp":"1700218560.0"}],"question_id":425,"topic":"1","question_images":[],"isMC":true,"answer_images":[]}],"exam":{"name":"AWS Certified Solutions Architect - Associate SAA-C03","numberOfQuestions":1019,"lastUpdated":"11 Apr 2025","isBeta":false,"isImplemented":true,"isMCOnly":true,"provider":"Amazon","id":31},"currentPage":85},"__N_SSP":true}