{"pageProps":{"questions":[{"id":"gDnOXWW9tNbjB5DoX2W2","question_text":"A company has many separate AWS accounts and uses no central billing or management. Each AWS account hosts services for different departments in the company. The company has a Microsoft Azure Active Directory that is deployed.\n\nA solutions architect needs to centralize billing and management of the company’s AWS accounts. The company wants to start using identity federation instead of manual user management. The company also wants to use temporary credentials instead of long-lived access keys.\n\nWhich combination of steps will meet these requirements? (Choose three.)","answers_community":["ACE (100%)"],"answer_ET":"ACE","discussion":[{"poster":"gd1","upvote_count":"14","content":"Selected Answer: ACE\nYes ACE - A for a new Management account: C for SSO; E for permissions to IAM","comment_id":"932587","timestamp":"1719236100.0"},{"content":"Selected Answer: ACE\nA) Creating a master account to manage organizations on AWS and invite them sounds like a good idea and is recommended.\nB) Has no sense\nC ) In AWS Single Sign On adding Azure AD as trust sounds like a good idea and it is the usual way to do it as well as creating users and groups\nD ) Create an AD in AWS and share it? it doesn't make sense because there already exists one in azure which we will use\nE ) Creating the corresponding permission set and attaching it to the groups that were created usually makes sense.\nF ) again an AD created in AWS is not necessary because it already exists in Azure and you do not want to have another one again","timestamp":"1719603540.0","poster":"SkyZeroZx","comment_id":"937086","upvote_count":"6"},{"upvote_count":"1","timestamp":"1732460160.0","poster":"salazar35","content":"Selected Answer: ACE\nACE make sense.","comment_id":"1079383"},{"content":"Selected Answer: ACE\nA C and E options.","upvote_count":"1","comment_id":"1078027","timestamp":"1732331880.0","poster":"career360guru"},{"timestamp":"1721669400.0","comment_id":"959722","content":"Correct ACE.","poster":"ggrodskiy","upvote_count":"1"},{"comment_id":"946329","poster":"Piccaso","upvote_count":"1","content":"Selected Answer: ACE\nD must be wrong.","timestamp":"1720427880.0"},{"poster":"NikkyDicky","upvote_count":"2","timestamp":"1720384680.0","content":"Selected Answer: ACE\nACE IT!","comment_id":"945987"},{"content":"Selected Answer: ACE\nthis question scored an ACE","timestamp":"1720254780.0","poster":"YodaMaster","upvote_count":"1","comment_id":"944447"},{"comment_id":"934847","timestamp":"1719442560.0","content":"Selected Answer: ACE\nACE - Management account, AWS SSO with Azure AD and permission sets","poster":"SmileyCloud","upvote_count":"1"},{"timestamp":"1719343440.0","upvote_count":"1","comment_id":"933846","poster":"SkyZeroZx","content":"Selected Answer: ACE\nYes ACE - A for a new Management account: C for SSO; E for permissions to IAM"},{"content":"Selected Answer: ACE\nA, C and E","comment_id":"932357","poster":"PhuocT","upvote_count":"1","timestamp":"1719217980.0"},{"upvote_count":"1","poster":"MoussaNoussa","timestamp":"1719138060.0","content":"ACE is the right answer","comment_id":"931461"},{"upvote_count":"1","comment_id":"929261","content":"Selected Answer: ACE\nCorrect Answer is ACE","poster":"psyx21","timestamp":"1718961240.0"}],"unix_timestamp":1687338840,"choices":{"B":"Configure each AWS account's email address to be aws+@example.com so that account management email messages and invoices are sent to the same place.","A":"Create a new AWS account to serve as a management account. Deploy an organization in AWS Organizations. Invite each existing AWS account to join the organization. Ensure that each account accepts the invitation.","D":"Deploy an AWS Managed Microsoft AD directory in the management account. Share the directory with all other accounts in the organization by using AWS Resource Access Manager (AWS RAM).","E":"Create AWS IAM Identity Center (AWS Single Sign-On) permission sets. Attach the permission sets to the appropriate IAM Identity Center groups and AWS accounts.","C":"Deploy AWS IAM Identity Center (AWS Single Sign-On) in the management account. Connect IAM Identity Center to the Azure Active Directory. Configure IAM Identity Center for automatic synchronization of users and groups.","F":"Configure AWS Identity and Access Management (IAM) in each AWS account to use AWS Managed Microsoft AD for authentication and authorization."},"timestamp":"2023-06-21 11:14:00","isMC":true,"answer_images":[],"question_images":[],"topic":"1","question_id":181,"exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/112796-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"ACE","answer_description":""},{"id":"4cm2fzKcDQSrdffSs0HI","topic":"1","answer_images":[],"choices":{"C":"Deploy AWS Elastic Beanstalk for each application with Auto Scaling to ensure that all requests have sufficient resources. Monitor each AWS Elastic Beanstalk deployment by using CloudWatch alarms.","D":"Deploy a new Amazon EC2 instance cluster that co-hosts all applications by using EC2 Auto Scaling and Application Load Balancers. Scale cluster size based on a custom metric set on instance memory utilization. Purchase 3-year Reserved Instance reservations equal to the GroupMaxSize parameter of the Auto Scaling group.","B":"Deploy Amazon ECS containers on Amazon EC2 with Auto Scaling configured for memory utilization of 75%. Deploy an ECS task for each application being migrated with ECS task scaling. Monitor services and hosts by using Amazon CloudWatch.","A":"Deploy a separate AWS Lambda function for each application. Use AWS CloudTrail logs and Amazon CloudWatch alarms to verify completion of critical jobs."},"answers_community":["B (86%)","14%"],"exam_id":33,"answer_description":"","unix_timestamp":1687338960,"discussion":[{"content":"Selected Answer: B\nHours = lambda out\nReserve instance max size = D out\nC: beanstalk still use EC2, if beanstalk = each application, it could be each app get its own EC2, which will cost more than the ECS on EC2 in B.\nSo B is cheaper","poster":"nexus2020","comment_id":"933543","upvote_count":"19","timestamp":"1687695180.0"},{"timestamp":"1713112380.0","poster":"SKS","upvote_count":"1","comments":[{"comment_id":"1268952","upvote_count":"1","content":"just B","timestamp":"1724106000.0","poster":"helloworldabc"},{"upvote_count":"1","poster":"SKS","timestamp":"1713112440.0","content":"This option provides more control over the infrastructure and can accommodate the varying resource requirements of different applications. By utilizing EC2 Auto Scaling and Application Load Balancers, you can efficiently manage resources based on demand. Purchasing Reserved Instances can provide cost savings over the long term.","comment_id":"1195616"}],"content":"option D seems most cost effective solution","comment_id":"1195614"},{"poster":"career360guru","comment_id":"1171556","upvote_count":"2","content":"Selected Answer: C\nGo with C as it provides standard deployment process for each App.\nOne can right size each App using appropriate EC2 sizing for each Application and I feel this approach can be as cost effective as using option B (ECS).","timestamp":"1710234180.0"},{"upvote_count":"1","timestamp":"1708158540.0","comment_id":"1152445","content":"Selected Answer: B\nB is the answer.\nElastic Beanstalk is a PaaS offering by AWS, which automates the deployment and scaling of web applications. It abstracts the underlying infrastructure, making it easier to manage, but it may have some limitations in terms of customization. \nEC2, on the other hand, is an infrastructure as a service (IaaS) offering that provides more control over the virtual servers running your applications. \nWith EC2, you have the flexibility to customize the infrastructure to your exact needs, but it requires more manual management. In general, if you require more control and customization, EC2 may be more cost-effective in the long run.","poster":"ele"},{"content":"Selected Answer: C\nBetween B & C, I'll go with C .\nBoth options are using EC2, the cost will be the same. Additional requirement is \"standardizing by using a single deployment methodology\" , and this is about Beanstalk.","timestamp":"1706345100.0","comment_id":"1133179","poster":"ele","upvote_count":"3"},{"comment_id":"1091512","upvote_count":"2","poster":"duriselvan","content":"C: ans \n\nThe most cost-effective solution is C. Deploy AWS Elastic Beanstalk for each application with Auto Scaling to ensure that all requests have sufficient resources. Monitor each AWS Elastic Beanstalk deployment by using CloudWatch alarms.\n\nHere's why:\n\nCost efficiency:\n\nElastic Beanstalk: Provides managed application deployment and scaling, reducing operational overhead and potential configuration errors.\nAuto Scaling: Ensures that resources are available only when needed, minimizing idle costs.\nReserved Instances: Purchasing 3-year Reserved Instances can offer significant discounts compared to on-demand instances.","timestamp":"1702109700.0"},{"upvote_count":"1","content":"Selected Answer: B\nOption B","timestamp":"1700710560.0","comment_id":"1078036","poster":"career360guru"},{"content":"Selected Answer: B\nMany of you have already explain the reasons why other options are not a good fit. but i will explain optionD bit further.\nD-> Wrong\nNot only for using Custom Metric but Co-hosting all applications on a single EC2 instance cluster means that the resources (CPU, memory, storage) of the instances would need to be shared among all the applications. This lead to resource contention and inefficient resource allocation, especially when some applications have peak memory requirements of up to 2.5 GB. It may result in underutilization of resources for applications with low usage and performance issues during peak processing times.","comment_id":"1051547","timestamp":"1698045840.0","upvote_count":"4","poster":"yorkicurke"},{"upvote_count":"1","content":"Selected Answer: B\nB 100% sure","poster":"softarts","comment_id":"982218","timestamp":"1692164520.0"},{"timestamp":"1690046580.0","poster":"ggrodskiy","comment_id":"959717","content":"Correct B.","upvote_count":"1"},{"poster":"NikkyDicky","comment_id":"945992","content":"Selected Answer: B\nB since the emphasis is on cost, no operational overhead. containers should be a bit more cost-effective as they are more granular per app\na: hours-> no lambda","timestamp":"1688762760.0","upvote_count":"2"},{"timestamp":"1687820280.0","upvote_count":"1","poster":"SmileyCloud","comment_id":"934850","content":"Selected Answer: B\nB is correct."},{"comment_id":"933467","timestamp":"1687688880.0","poster":"Alabi","content":"Selected Answer: B\nB for sure","upvote_count":"1"},{"timestamp":"1687594560.0","comment_id":"932345","content":"Selected Answer: B\nA is incorrect due to lambda 15mins constraint\nB is Correct","poster":"shree2023","upvote_count":"1"},{"content":"Selected Answer: B\nCorrect Answer is B","upvote_count":"1","comment_id":"929262","poster":"psyx21","timestamp":"1687338960.0"}],"answer_ET":"B","question_images":[],"question_id":182,"url":"https://www.examtopics.com/discussions/amazon/view/112797-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"B","question_text":"A company wants to manage the costs associated with a group of 20 applications that are infrequently used, but are still business-critical, by migrating to AWS. The applications are a mix of Java and Node.js spread across different instance clusters. The company wants to minimize costs while standardizing by using a single deployment methodology.\n\nMost of the applications are part of month-end processing routines with a small number of concurrent users, but they are occasionally run at other times. Average application memory consumption is less than 1 GB. though some applications use as much as 2.5 GB of memory during peak processing. The most important application in the group is a billing report written in Java that accesses multiple data sources and often runs for several hours.\n\nWhich is the MOST cost-effective solution?","isMC":true,"timestamp":"2023-06-21 11:16:00"},{"id":"0xAE5Lq4IbWyo56iIMM8","isMC":true,"answer_ET":"D","answer_images":[],"timestamp":"2023-06-21 11:19:00","exam_id":33,"question_text":"A solutions architect needs to review the design of an Amazon EMR cluster that is using the EMR File System (EMRFS). The cluster performs tasks that are critical to business needs. The cluster is running Amazon EC2 On-Demand Instances at all times for all task, primary, and core nodes. The EMR tasks run each morning, starting at 1:00 AM. and take 6 hours to finish running. The amount of time to complete the processing is not a priority because the data is not referenced until late in the day.\n\nThe solutions architect must review the architecture and suggest a solution to minimize the compute costs.\n\nWhich solution should the solutions architect recommend to meet these requirements?","unix_timestamp":1687339140,"choices":{"C":"Continue to launch all nodes on On-Demand Instances. Terminate the cluster, including all instances, when the processing is completed. Purchase Compute Savings Plans to cover the On-Demand Instance usage.","A":"Launch all task, primary, and core nodes on Spot Instances in an instance fleet. Terminate the cluster, including all instances, when the processing is completed.","D":"Launch the primary and core nodes on On-Demand Instances. Launch the task nodes on Spot Instances in an instance fleet. Terminate only the task node instances when the processing is completed. Purchase Compute Savings Plans to cover the On-Demand Instance usage.","B":"Launch the primary and core nodes on On-Demand Instances. Launch the task nodes on Spot Instances in an instance fleet. Terminate the cluster, including all instances, when the processing is completed. Purchase Compute Savings Plans to cover the On-Demand Instance usage."},"url":"https://www.examtopics.com/discussions/amazon/view/112798-exam-aws-certified-solutions-architect-professional-sap-c02/","question_id":183,"question_images":[],"topic":"1","answer":"D","answers_community":["D (58%)","B (42%)","1%"],"answer_description":"","discussion":[{"poster":"aviathor","content":"Selected Answer: D\nThe problem statement says:\n\"The EMR tasks run each morning, starting at 1:00 AM. and take 6 hours to finish running. The amount of time to complete the processing is not a priority because *the data is not referenced until late in the day.*\"\n\nSo later in the day, clients will be using the cluster to read data. Therefore my understanding is that core and primary nodes need to be available, but the task nodes can be terminated once the tasks have finished their daily run.","comments":[{"upvote_count":"2","poster":"sashenka","comment_id":"1301335","content":"One does not need the cluster to read the data. MRFS enables storing persistent data in Amazon S3. This means data remains available even after an EMR cluster is terminated, allowing for cost savings and data reuse across multiple clusters.","timestamp":"1729555680.0"}],"timestamp":"1693218360.0","upvote_count":"27","comment_id":"992050"},{"comments":[{"upvote_count":"1","timestamp":"1729555800.0","comment_id":"1301336","content":"One chooses the usage commitment when purchasing a Compute Savings Plan. So, one can base it on the fact that the on-demand nodes will only need to run for a min amount of time. In this case for 6 hrs a day.","poster":"sashenka"}],"upvote_count":"15","timestamp":"1688110500.0","comment_id":"938896","poster":"javitech83","content":"Selected Answer: D\nCorrect Answer is D. In B it has no sense to temrinate primary instance if we have already purchase a saving plan."},{"comment_id":"1410021","content":"Selected Answer: B\nI go with B, once all the data is processed, there is no point in keeping the cluster running.","timestamp":"1742904300.0","upvote_count":"1","poster":"LeoSantos121212121212121"},{"poster":"youonebe","timestamp":"1732582860.0","upvote_count":"2","content":"Selected Answer: B\nB - Correct answer\nD - Keeping the cluster running with only task nodes terminated wastes resources\nUnnecessary costs incurred by maintaining primary and core nodes when not needed","comment_id":"1317852"},{"timestamp":"1729555620.0","comment_id":"1301334","upvote_count":"3","comments":[{"upvote_count":"1","content":"The question specifically references that the EMR cluster is built with MRFS vs the default of HDFS which is not persistent. This approach of using EMRFS with transient clusters is not only possible but is considered the recommended architecture pattern for EMR deployments.","timestamp":"1731254280.0","poster":"sashenka","comment_id":"1309522"}],"poster":"sashenka","content":"Selected Answer: B\nMRFS enables storing persistent data in Amazon S3. This means data remains available even after an EMR cluster is terminated, allowing for cost savings and data reuse across multiple clusters."},{"comment_id":"1300049","poster":"pk0619","upvote_count":"2","content":"Selected Answer: B\nJust B","timestamp":"1729349520.0"},{"comment_id":"1300012","upvote_count":"1","content":"Selected Answer: B\nB, with EMRFS we can decouple storage from the nodes and write directly to S3, no need to keep all the nodes running.\n\nIf you were to use HDFS you would have to keep the core nodes running as they store the data for HDFS.","timestamp":"1729342200.0","poster":"that1guy"},{"upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1724106120.0","content":"just D","comment_id":"1268953","poster":"helloworldabc"},{"content":"Changing my mind to B as the process is business critical and you shouldn´t use spot instances for any critical processing but the cluster can be terminated as the data is in S3 once it's processed.","timestamp":"1718194620.0","upvote_count":"1","comment_id":"1228985","poster":"teo2157"}],"comment_id":"1208859","timestamp":"1715260020.0","poster":"teo2157","content":"Selected Answer: A\nThe key point here is \"Amazon EMR cluster that is using the EMR File System (EMRFS)\", the EMR File System use S3 as persistent storage, so one the cluster finished the processing of data, the data is ready for the users but the cluster is no longer needed and it can be terminated without any issue."},{"upvote_count":"1","timestamp":"1714725120.0","comment_id":"1205995","poster":"seetpt","content":"Selected Answer: D\nD for me"},{"upvote_count":"1","content":"B - we should not terminate the cluster.\nD - once task is done can terminate the node.\n\nso my answer is D","poster":"43c89f4","comment_id":"1204743","timestamp":"1714518060.0"},{"upvote_count":"2","timestamp":"1712931480.0","content":"Selected Answer: D\nOption D: How To / Use Case\n\nhttps://aws.amazon.com/blogs/big-data/strategies-for-reducing-your-amazon-emr-costs/","poster":"TonytheTiger","comment_id":"1194385"},{"comment_id":"1190870","timestamp":"1712480880.0","content":"Selected Answer: D\nTerminating all instances make sense as these are not frequent jobs. They are run on once a day \n\nhttps://www.cloudforecast.io/blog/aws-emr-cost-optimization-guide/","poster":"Keval12345","upvote_count":"2"},{"content":"Selected Answer: D\nD\nfor the one who chose B, the computer savings plan is a hourly commitment for consistent usage pattern. You will be charged even you shutdown the whole stack","upvote_count":"2","poster":"pangchn","timestamp":"1712347200.0","comment_id":"1190069","comments":[{"upvote_count":"1","poster":"altonh","timestamp":"1740556080.0","content":"But your hourly commitment will be lower.","comment_id":"1361820"}]},{"upvote_count":"5","timestamp":"1711166820.0","content":"Selected Answer: B\nWe can terminate the cluster and then read results from S3.\nRefer below EMR faq:\nQ: How does Amazon EMR use Amazon EC2 and Amazon S3?\n\nYou can upload your input data and a data processing application into Amazon S3. Amazon EMR then launches a number of Amazon EC2 instances that you specified. The service begins the cluster execution while pulling the input data from Amazon S3 using S3 URI scheme into the launched Amazon EC2 instances. Once the cluster is finished, Amazon EMR transfers the output data to Amazon S3, where you can then retrieve it or use as input in another cluster.\nhttps://aws.amazon.com/emr/faqs/","comment_id":"1180531","poster":"yog927"},{"comment_id":"1177550","poster":"Dgix","content":"Selected Answer: B\nWe _can_ terminate the entire cluster, as EMRFS is specified – which stores the computational results in S3. Therefore, the cluster is not required after processing.","upvote_count":"3","timestamp":"1710867300.0"},{"timestamp":"1710234420.0","comment_id":"1171558","poster":"career360guru","content":"Selected Answer: D\nOption D because processed data is used later in the day.","upvote_count":"2"},{"upvote_count":"3","comment_id":"1165719","poster":"a54b16f","content":"Selected Answer: D\nThe difference between D and B is that whether to terminate whole EMR cluster, or do we need the EMR cluster after the 6 hour processing. The answer is yes, \" the data is not referenced until late in the day\" , EMRFS can't be access without EMR cluster. You may argue that you can access the underlying s3 directly. But, you would loss the benefits of EMR/EMRFS, which provide security control, and most importantly, performance and system throughput related to big data","comments":[{"timestamp":"1725694680.0","content":"Yes, EMRFS can be accessed without an active EMR cluster because EMRFS stores data in Amazon S3, which is a persistent object storage service independent of the EMR cluster.\n\nHere's how it works:\n\nEMRFS is essentially an extension of Amazon S3, allowing EMR clusters to use S3 as a storage layer for data.\nWhen you terminate an EMR cluster, the data in S3 remains intact and accessible","comment_id":"1279922","upvote_count":"1","poster":"Syre"}],"timestamp":"1709563380.0"},{"comment_id":"1156278","timestamp":"1708594740.0","content":"Selected Answer: B\nOnce the Amazon EMR cluster completes processing data in S3 why do you need it ? Does processed data stored on cluster EC2s . There is a specific settings The auto-termination policy terminates the cluster after a specific amount of idle time. \nYou will not need the cluster until the next run .","upvote_count":"2","poster":"sat2008"},{"upvote_count":"2","poster":"sat2008","content":"Selected Answer: B\nOnce the Data process is complete is there a need for EMR Cluster ? you can use The auto-termination policy terminates the cluster after a specific amount of idle time.\nThe processed data is in S3 for later queries so my thoughts would be do no need to EMR Cluster till the next run .","timestamp":"1708594200.0","comment_id":"1156271"},{"content":"Selected Answer: D\nD\nMakes no sense to kill the whole cluster when someone would access it later same day","comment_id":"1139587","poster":"chelbsik","timestamp":"1706992260.0","upvote_count":"4"},{"upvote_count":"1","comment_id":"1133192","poster":"ele","content":"Selected Answer: B\nB is the right answer. \nTransient clusters is the best suits for this use case. Data processes by EMR stored in s3, and referenced there. No need to keep any nodes up.\n Besides, EMR File System (EMRFS) is best suited for transient clusters as the data resides irrespective of the lifetime of the cluster.","timestamp":"1706345700.0"},{"poster":"duriselvan","timestamp":"1702222980.0","content":"d ANS\nCost optimization: Using Spot Instances for task nodes significantly reduces costs compared to On-Demand Instances. Spot Instances can offer substantial discounts, especially when running workloads with flexible start and stop times.\n\nMinimal impact: By terminating only the task nodes after processing, the primary and core nodes remain available for future job submissions without requiring a complete cluster restart. This minimizes downtime and maximizes resource utilization.\n\nAvailability and stability: On-Demand Instances for primary and core nodes ensure high availability and stability for critical tasks. This eliminates the risk of interruptions due to Spot Instance price fluctuations or availability constraints.\n\nSavings Plans: Purchasing Compute Savings Plans for On-Demand Instances can provide further cost savings by offering discounts based on a committed level of usage.","upvote_count":"2","comment_id":"1092606"},{"timestamp":"1701938160.0","comment_id":"1090072","upvote_count":"4","content":"Selected Answer: B\nD is appealing and makes sense due to the indicated critical nature of the cluster. B however is associated with EMRFS (S3) which is typically used with transient EMR Cluster (see: https://bluexp.netapp.com/blog/optimizing-aws-emr-best-practices) \n\nSince the objective is to save money, then terminating the cluster, and cloning its configuration to launch a new one on a daily basis only takes a few minutes would be an appropriate option. \n\njust my two pennies worth :)","poster":"ayadmawla"},{"upvote_count":"6","content":"Selected Answer: B\nB is the best answer: It provides a balanced approach by using Spot Instances for task nodes to reduce costs and On-Demand Instances for primary and core nodes to ensure cluster stability. Terminating the cluster after processing and purchasing Compute Savings Plans for the On-Demand usage further optimizes costs while maintaining the reliability needed for critical business tasks.\n\nThe data can also be accessed via S3 if the cluster is not running, so it's ok to terminate it once the processing completes.","timestamp":"1701228480.0","poster":"heatblur","comment_id":"1083083"},{"timestamp":"1700711280.0","poster":"career360guru","upvote_count":"1","comment_id":"1078046","content":"Selected Answer: B\nB -> Because cluster is using EMRFS we can shutdown all node."},{"poster":"severlight","timestamp":"1700382720.0","content":"Selected Answer: B\ndon't see any proper reason to not shutdown cluster","comment_id":"1074532","upvote_count":"2"},{"comment_id":"1066230","poster":"Andres123456","upvote_count":"3","content":"Selected Answer: B\nB, not D... minimize means shutdown all. no point of having an idle cluster incur costs\n1. data stored through EMRFS on s3 may be referenced directly using s3 APIs\n2. it don't take long to launch a (smaller) cluster if it's needed for referencing. then shut it down again\n3. not even clear from the documentation task nodes can be scaled down without affecting core nodes\n4. savings plan does not mean no cost for idle instances, just less cost","timestamp":"1699516560.0"},{"upvote_count":"3","content":"D.\nno need to terminate primary, core instance under compute savings plan commitment( even if you terminate the instances, you pay the commitment, consistent usage of savings plan). Thus for accessing the processed data at the end of the day, it is better to maintain core and primary instances.","poster":"rlf","timestamp":"1697460180.0","comment_id":"1044951"},{"content":"Selected Answer: B\nB https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-fs.html","poster":"magmichal05","upvote_count":"1","comment_id":"1027848","timestamp":"1696757460.0"},{"poster":"covabix879","content":"After completion of the task, results can be stored in S3. Since EMRFS is used, data persists past the lifetime of the cluster. Terminating the cluster is the most cost effective solution.","upvote_count":"2","timestamp":"1696074780.0","comments":[{"upvote_count":"2","comment_id":"1027847","timestamp":"1696757340.0","content":"The EMR File System (EMRFS) is an implementation of HDFS that all Amazon EMR clusters use for reading and writing regular files from Amazon EMR directly to Amazon S3. EMRFS provides the convenience of storing persistent data in Amazon S3 for use with Hadoop while also providing features like data encryption.\nhttps://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-fs.html\nIt means you SHOULD terminate all the instances and there will be no data loss","poster":"magmichal05"}],"comment_id":"1021425"},{"comment_id":"1020870","upvote_count":"3","poster":"duriselvan","content":"D - ans:-EMR job will run task particular time after instance should down","timestamp":"1695998160.0"},{"upvote_count":"1","poster":"carbita","content":"It's \"B\". Note that the scenario mentioned that use \"EMRFS\" so in that case the data comes from S3. You do not need to keep the cluster on.","comment_id":"1018126","timestamp":"1695754440.0"},{"content":"Selected Answer: B\nI will go with B.","timestamp":"1695657720.0","comment_id":"1016961","upvote_count":"1","poster":"FunkyFresco"},{"comment_id":"997337","poster":"cmoreira","content":"Selected Answer: B\nAgreed with santi.\nFrom EMR best practices, Treat all clusters as transient resources.\nhttps://aws.github.io/aws-emr-best-practices/reliability/best_practices/","timestamp":"1693719000.0","upvote_count":"2"},{"content":"Selected Answer: B\nbbbbbbbbbbbb","timestamp":"1693620360.0","upvote_count":"1","poster":"774dayo","comment_id":"996498"},{"timestamp":"1693458960.0","upvote_count":"5","comment_id":"994773","content":"Selected Answer: D\nThe cluster needs to be present later at the day to serve the data that was processed. So I choose D.","poster":"Gabehcoud"},{"timestamp":"1692620880.0","poster":"SK_Tyagi","upvote_count":"2","content":"Selected Answer: B\nIf the core, master nodes had to be running, RI would have been a better choice over On-Demand. Here all nodes need to be terminated","comment_id":"986487","comments":[{"comment_id":"996050","content":"you think need terminate manage node?","upvote_count":"1","poster":"vn_thanhtung","timestamp":"1693571400.0"}]},{"timestamp":"1691778000.0","poster":"chico2023","content":"Selected Answer: B\nOption B. Pretty for what NikkyDicky correctly put in his comment.","comment_id":"978878","upvote_count":"3"},{"comment_id":"968093","timestamp":"1690806180.0","content":"Selected Answer: B\nOption B provides the most cost-effective approach by combining On-Demand Instances for critical nodes with Spot Instances for non-critical task nodes. Additionally, using Compute Savings Plans further optimizes the cost structure for the primary and core node instances","poster":"Asds","upvote_count":"1"},{"poster":"ggrodskiy","comment_id":"959549","content":"Correct B.","upvote_count":"1","timestamp":"1690032060.0"},{"timestamp":"1688764080.0","upvote_count":"5","content":"Selected Answer: B\nB, not D... minimize means shutdown all. no point of having an idle cluster incur costs\n1. data stored through EMRFS on s3 may be referenced directly using s3 APIs\n2. it don't take long to launch a (smaller) cluster if it's needed for referencing. then shut it down again\n3. not even clear from the documentation task nodes can be scaled down without affecting core nodes\n4. savings plan does not mean no cost for idle instances, just less cost","comment_id":"946001","poster":"NikkyDicky","comments":[{"timestamp":"1693571340.0","content":"you think need terminate manage node?","poster":"vn_thanhtung","upvote_count":"1","comment_id":"996048"}]},{"timestamp":"1688347320.0","comment_id":"941347","poster":"SkyZeroZx","content":"Selected Answer: D\nOption D provides a cost-effective solution while ensuring the cluster's critical tasks are completed within the desired timeframe\n\nOption B suggests launching primary and core nodes on On-Demand Instances, launching task nodes on Spot Instances, and terminating the entire cluster, including all instances when processing is completed. Although using Spot Instances for task nodes can save costs, terminating the entire cluster would result in longer delays for accessing the data later in the day.","upvote_count":"6","comments":[{"content":"Option B.\n\nEMRFS allows you to access its content from a S3 bucket transparently (so decoupling computer from storage). The cluster can be terminated, with all its results safely stored in a S3 bucket... Not sure why it \"would result in longer delays for accessing the data later\". Please check: \n\nhttps://aws.github.io/aws-emr-best-practices/reliability/best_practices/","poster":"santi1975","comment_id":"960238","upvote_count":"3","timestamp":"1690101000.0"}]},{"comment_id":"939010","upvote_count":"2","timestamp":"1688121600.0","poster":"itsmeSuren","content":"Selected Answer: D\nOption D - This is the most cost effective working solution.\nNot Option B - This is also a workable solution, but it will be expensive than D. So D is the best option."},{"upvote_count":"1","poster":"nexus2020","content":"Selected Answer: B\nIf the question is asking about which is the highest avaiability option, then D. \nBut the question is asking about which is the cheapest, therefore B. B might not be the best, but does fit for the requirement (min cost). \n\nregarding the delay on starting instances, instance scheduler can be used to start the instance at defined time before 1AM.","comment_id":"936814","timestamp":"1687965240.0"},{"comment_id":"934852","upvote_count":"6","timestamp":"1687820820.0","poster":"SmileyCloud","content":"Selected Answer: D\nD - the cluster is used all the time, EMR is used between 1AM and 7AM. \nB - doesn't make sense. Why would you terminate on-demand instances if you already paid for the savings plan.","comments":[{"upvote_count":"1","poster":"nexus2020","comments":[{"content":"you turn off the task node when complete and use again in the morning, its ctritical","poster":"rxhan","upvote_count":"1","timestamp":"1688220960.0","comment_id":"940043"}],"content":"compute savings plan $ amount is mentioned, so we can not assume the savings plan is very big and we can leave the on-demand instances running when there is no load. if savings plan is $10, then when on-demand running it cost $20, then it make sense to turn them off when the tasks are done, as $10 savings plan will not cover the $20 on-demand cost.\n\nKey word in B: turn off when \"the processing is completed\".no point to keep things running when work is done","comment_id":"936808","timestamp":"1687964880.0"}]},{"content":"Selected Answer: D\nOption D provides a cost-effective solution while ensuring the cluster's critical tasks are completed within the desired timeframe\n\nOption B suggests launching primary and core nodes on On-Demand Instances, launching task nodes on Spot Instances, and terminating the entire cluster, including all instances when processing is completed. Although using Spot Instances for task nodes can save costs, terminating the entire cluster would result in longer delays for accessing the data later in the day.","timestamp":"1687689300.0","poster":"Alabi","comment_id":"933473","upvote_count":"4"},{"upvote_count":"1","content":"Selected Answer: B\nGPT: EMR cluster is composed of one master node, core nodes, and optional task nodes. The master node manages the cluster and runs the YARN ResourceManager service, JobHistory Server, and the Hadoop MapReduce and Spark schedulers. Core nodes are managed by the master node and run the YARN NodeManager daemon and the Hadoop Distributed File System (HDFS) DataNode daemon. Task nodes are optional and can be added to a cluster to perform tasks, but do not contain the HDFS DataNode daemon.\n\nBecause the master and core nodes are critical for the functioning of the EMR cluster, they should be run on On-Demand Instances to ensure they do not get terminated due to Spot Instance price fluctuations.","comment_id":"932602","poster":"gd1","timestamp":"1687614240.0"},{"content":"Selected Answer: B\nUsing On-Demand Instances for the primary and core nodes provides a level of stability for the cluster. Core nodes are essential to the cluster as they store data in the Hadoop Distributed File System (HDFS) across the life of the cluster, and primary nodes run essential services.\n\nTask nodes are optional and are meant to perform computational tasks but do not store data in HDFS. As such, task nodes are stateless and can be safely terminated and re-spawned without any data loss. These characteristics make task nodes a perfect fit for Spot Instances, which are significantly cheaper than On-Demand Instances, but can be terminated by AWS when the spot price exceeds the maximum price you specified.\n\nThe recommendation to terminate the entire cluster (all instances, including primary, core, and task nodes) after processing is completed, and to use Compute Savings Plans for On-Demand Instances, would help further reduce costs as you only pay for what you use.","upvote_count":"1","timestamp":"1687606320.0","comment_id":"932498","poster":"i_am_robot"},{"content":"Selected Answer: B\nTerminate cluster after processing is key between B and D. So, B is correct","timestamp":"1687595400.0","comment_id":"932355","upvote_count":"1","poster":"shree2023"},{"timestamp":"1687544280.0","content":"Selected Answer: B\nI go with B\nTask nodes can be spot as data in them is NOT persistent. question asks for saving costs. So terminating cluster after processing helps","comments":[{"content":"Changing to D. questions says cluster is used all the time, but EMR TASKS are run for 6 hours. So in my opinion terminating cluster (option B) is NOT a good idea","comment_id":"939202","timestamp":"1688140320.0","poster":"bhanus","upvote_count":"2"}],"poster":"bhanus","comment_id":"931856","upvote_count":"3"},{"content":"Selected Answer: D\nCorrect Answer is D","upvote_count":"3","timestamp":"1687339140.0","poster":"psyx21","comment_id":"929264"}]},{"id":"0r2he7ZV1sWblJjn2sme","answer_description":"","timestamp":"2023-06-21 11:20:00","isMC":true,"answer_images":[],"answer":"C","unix_timestamp":1687339200,"exam_id":33,"answer_ET":"C","discussion":[{"timestamp":"1692718740.0","poster":"AMohanty","comment_id":"987562","content":"Isn't NAT Gateway AWS managed\nWhy do we need to check if NAT GW is healthy ?","upvote_count":"8"},{"timestamp":"1687544640.0","upvote_count":"6","poster":"bhanus","content":"Selected Answer: C\nI go with C\nA is incorrect because you dont need 3 nat gateways\nB does not make sense to replace ALB\nD - you cannot assign elastic ip to ALB","comment_id":"931861","comments":[{"poster":"gd1","content":"A NAT (Network Address Translation) Gateway enables instances in a private subnet to connect to the internet or other AWS services but prevents the internet from initiating a connection with those instances. By using a single NAT gateway with the provided Elastic IP address, all outbound traffic will appear to come from the single, whitelisted IP address that the company allows.","upvote_count":"3","comment_id":"932610","timestamp":"1687614540.0"}]},{"poster":"career360guru","timestamp":"1710234900.0","upvote_count":"2","comment_id":"1171567","content":"Selected Answer: C\nOption C is best. As there is only one IP address that can be used Option A = 3 NAT gateways are not needed."},{"comment_id":"1078058","poster":"career360guru","upvote_count":"5","timestamp":"1700712960.0","comments":[{"poster":"Daniel76","comment_id":"1262731","content":"The design should \"gives the application the ability to communicate with the on-premises systems\", so it is outbound.","upvote_count":"1","timestamp":"1723172880.0"}],"content":"Selected Answer: C\nThis question is little unclear. It does not state whether the communication between on-premise system and AWS is out bond or in bound in nature. If it is outbound then C makes sense."},{"comment_id":"1066814","content":"also think about B option to assign an IP address to NLB","upvote_count":"2","poster":"alonis2201","timestamp":"1699570380.0"},{"timestamp":"1690031520.0","content":"Correct C.","comment_id":"959537","poster":"ggrodskiy","upvote_count":"1"},{"comments":[{"poster":"chikorita","timestamp":"1692602160.0","upvote_count":"2","content":"Elastic IPs itself are public\nwhether you choose B or C\nOption C is perfect for this use-case unless you associate ALB as target for NLB","comment_id":"986279"}],"comment_id":"954003","content":"All seemed good for option C) till I encountered this sentence - \"The company’s security team is bringing only one IP address from its internal IP address range to the cloud.\" - Please note internal IP not external IP. Which seems to imply there is a connectivity between on-premises & Cloud (either through Site-to-Site VPN or DX), though not explicitly mentioned in the question.\n\nIn such a case, NAT gateway with Public subnet will not help. Option B) will become a viable solution in this case.","timestamp":"1689583080.0","upvote_count":"2","poster":"study_aws1"},{"poster":"NikkyDicky","upvote_count":"1","comment_id":"946003","content":"Selected Answer: C\nC makes some sense","timestamp":"1688764380.0"},{"poster":"SmileyCloud","upvote_count":"2","timestamp":"1687821240.0","comment_id":"934855","content":"Selected Answer: C\nC - single NAT if only one Elastic IP is available."},{"comment_id":"933476","upvote_count":"3","poster":"Alabi","content":"Selected Answer: C\noption C provides the most appropriate solution by using a single NAT gateway, monitoring its health with CloudWatch, and invoking a Lambda function to create a new NAT gateway if necessary.","timestamp":"1687689540.0"},{"content":"Selected Answer: C\nC is the answer single NAT is needed","poster":"shree2023","comment_id":"932366","upvote_count":"1","timestamp":"1687596180.0"},{"comment_id":"932365","content":"I think it's C.","upvote_count":"1","timestamp":"1687596120.0","poster":"PhuocT"},{"content":"Selected Answer: C\nCorrect Answer is C","poster":"psyx21","upvote_count":"1","comment_id":"929267","timestamp":"1687339200.0"}],"question_id":184,"choices":{"D":"Assign the Elastic IP address to the ALB. Create an Amazon Route 53 simple record with the Elastic IP address as the value. Create a Route 53 health check. In the case of a failed health check, recreate the ALB in different subnets.","B":"Replace the ALB with a Network Load Balancer (NLB). Assign the Elastic IP address to the NLTurn on health checks for the NLIn the case of a failed health check, redeploy the NLB in different subnets.","C":"Deploy a single NAT gateway in a public subnet. Assign the Elastic IP address to the NAT gateway. Use Amazon CloudWatch with a custom metric to monitor the NAT gateway. If the NAT gateway is unhealthy, invoke an AWS Lambda function to create a new NAT gateway in a different subnet. Assign the Elastic IP address to the new NAT gateway.","A":"Deploy three NAT gateways, one in each public subnet. Assign the Elastic IP address to the NAT gateways. Turn on health checks for the NAT gateways. If a NAT gateway fails a health check, recreate the NAT gateway and assign the Elastic IP address to the new NAT gateway."},"question_text":"A company has migrated a legacy application to the AWS Cloud. The application runs on three Amazon EC2 instances that are spread across three Availability Zones. One EC2 instance is in each Availability Zone. The EC2 instances are running in three private subnets of the VPC and are set up as targets for an Application Load Balancer (ALB) that is associated with three public subnets.\n\nThe application needs to communicate with on-premises systems. Only traffic from IP addresses in the company's IP address range are allowed to access the on-premises systems. The company’s security team is bringing only one IP address from its internal IP address range to the cloud. The company has added this IP address to the allow list for the company firewall. The company also has created an Elastic IP address for this IP address.\n\nA solutions architect needs to create a solution that gives the application the ability to communicate with the on-premises systems. The solution also must be able to mitigate failures automatically.\n\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/112799-exam-aws-certified-solutions-architect-professional-sap-c02/","question_images":[],"topic":"1","answers_community":["C (100%)"]},{"id":"al4iCTDykc1XtXZQzNkk","discussion":[{"content":"Selected Answer: BEF\nB - Remove\nE - Invite\nF - Verify\nhttps://repost.aws/knowledge-center/organizations-move-accounts","timestamp":"1719443880.0","comments":[{"timestamp":"1723718760.0","poster":"Khannas","comment_id":"981555","upvote_count":"5","content":"Excellent Explanation"}],"comment_id":"934857","upvote_count":"19","poster":"SmileyCloud"},{"comment_id":"1051613","content":"no one talked about;\n\"All accounts are set up with all the required information so that each account can be operated as a standalone account.\"\nWouldnt that make Option B invalid? \ncan some one clarify that plz.","comments":[{"content":"No, it's to confirm that B is valid. Removing accounts from organization effectively makes them standalone accounts. The statement you cited, says that they have all info, permissions.. to operate as standalone account thus make B feasible.","timestamp":"1730310720.0","comment_id":"1058127","upvote_count":"2","poster":"joleneinthebackyard"},{"timestamp":"1733002440.0","content":"You can remove an account from your organization only if the account is configured with the information required to operate as a standalone account.","comment_id":"1084787","poster":"shaaam80","upvote_count":"1"}],"poster":"yorkicurke","upvote_count":"1","timestamp":"1729673340.0"},{"poster":"khksoma","timestamp":"1721924100.0","upvote_count":"2","comment_id":"962875","content":"BEF is correct.\nhttps://aws.amazon.com/blogs/mt/aws-organizations-moving-an-organization-member-account-to-another-organization-part-1/#:~:text=Moving%20an%20account%20between%20organizations,and%20services%20continue%20to%20operate."},{"comment_id":"959534","content":"correct BEF.","poster":"ggrodskiy","upvote_count":"1","timestamp":"1721653860.0"},{"timestamp":"1720878300.0","content":"Selected Answer: BEF\nits BEF","comment_id":"950703","poster":"Jonalb","upvote_count":"2"},{"content":"Selected Answer: BEF\nits BEF","comment_id":"946007","upvote_count":"1","poster":"NikkyDicky","timestamp":"1720387260.0"},{"poster":"nexus2020","upvote_count":"2","comment_id":"933631","content":"Selected Answer: BEF\nremove from org, invite from org, verify from invidual. BEF","timestamp":"1719321840.0"},{"comment_id":"932620","timestamp":"1719237420.0","content":"Selected Answer: BEF\nGPT 4.0 corrected BEF are the answers. A is not feasible.","upvote_count":"3","poster":"gd1"},{"comments":[],"timestamp":"1719237180.0","poster":"gd1","content":"Selected Answer: AEF\nGPT: In AWS Organizations, moving an account to a new organization is a two-step process. First, the account has to be removed from the old organization. This can be done using the MoveAccount operation from the old organization's management account (Option A). \nSecond, the account has to be invited to the new organization. The new organization's management account should use the InviteAccountToOrganization operation to send an invitation to the account (Option E).Finally, to accept the invitation to join a new organization, the account owner (in this case, each developer) must sign in to their account and accept the invitation (Option F).","upvote_count":"1","comment_id":"932613"},{"timestamp":"1719229200.0","poster":"i_am_robot","upvote_count":"1","comment_id":"932508","content":"Selected Answer: ABF\nTo move an account between organizations, you need to remove the account from the current organization (using RemoveAccountFromOrganization) and then the individual account holders must accept an invitation to join the new organization (using the MoveAccount operation and then manually confirming the invitation to join the new organization)."},{"timestamp":"1719219360.0","poster":"shree2023","upvote_count":"3","content":"Selected Answer: BEF\nA is incorrect not an option to MoveOperation not across org\nB - remove account from org\nE - Invite the dev account\nF - Confirm","comment_id":"932381"},{"comment_id":"932369","content":"B, E, and F, I think","upvote_count":"1","timestamp":"1719218760.0","poster":"PhuocT"},{"content":"Selected Answer: BDE\nolabiba.ai says BDE","timestamp":"1719202560.0","comments":[{"comment_id":"967568","upvote_count":"1","poster":"rxhan","timestamp":"1722379560.0","content":"olabiba.ai is wrong"}],"poster":"Jackhemo","upvote_count":"1","comment_id":"932151"},{"poster":"bhanus","upvote_count":"3","comment_id":"931872","timestamp":"1719168120.0","content":"Selected Answer: BEF\nI go with BEF\nhttps://aws.amazon.com/blogs/mt/aws-organizations-moving-an-organization-member-account-to-another-organization-part-1/\nThe above doc clearly says \"Moving an account between organizations requires you to remove the account from an organization, making the account standalone, and then you accepting an invite to join another organization\"\nA is incorrect as per above statement\nB Correct\nC is incorrect because individual account cannot remove itself from an organization. This operation must be performed by the management account of the organization.\nD is incorrect because there is NO need for placeholder\nE is correct . The management account should INVITE its member account\nF is correct - The member account should ACCEPT invitation"},{"comment_id":"929268","timestamp":"1718961660.0","upvote_count":"1","content":"Selected Answer: BDE\nCorrect Answer is BDE","poster":"psyx21"}],"answer_description":"","answer_ET":"BEF","question_text":"A company uses AWS Organizations to manage more than 1,000 AWS accounts. The company has created a new developer organization. There are 540 developer member accounts that must be moved to the new developer organization. All accounts are set up with all the required information so that each account can be operated as a standalone account.\n\nWhich combination of steps should a solutions architect take to move all of the developer accounts to the new developer organization? (Choose three.)","answers_community":["BEF (89%)","5%"],"exam_id":33,"unix_timestamp":1687339260,"question_id":185,"choices":{"A":"Call the MoveAccount operation in the Organizations API from the old organization's management account to migrate the developer accounts to the new developer organization.","C":"From each developer account, remove the account from the old organization using the RemoveAccountFromOrganization operation in the Organizations API.","B":"From the management account, remove each developer account from the old organization using the RemoveAccountFromOrganization operation in the Organizations API.","E":"Call the InviteAccountToOrganization operation in the Organizations API from the new developer organization's management account to send invitations to the developer accounts.","D":"Sign in to the new developer organization's management account and create a placeholder member account that acts as a target for the developer account migration.","F":"Have each developer sign in to their account and confirm to join the new developer organization."},"answer_images":[],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/112800-exam-aws-certified-solutions-architect-professional-sap-c02/","topic":"1","isMC":true,"answer":"BEF","timestamp":"2023-06-21 11:21:00"}],"exam":{"isBeta":false,"isMCOnly":true,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Professional SAP-C02","provider":"Amazon","isImplemented":true,"id":33,"numberOfQuestions":529},"currentPage":37},"__N_SSP":true}