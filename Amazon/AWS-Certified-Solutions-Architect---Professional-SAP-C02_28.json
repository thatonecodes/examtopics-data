{"pageProps":{"questions":[{"id":"WKbWiGfASZuJwLQJ5rhm","topic":"1","exam_id":33,"answer":"ACE","question_text":"A company has IoT sensors that monitor traffic patterns throughout a large city. The company wants to read and collect data from the sensors and perform aggregations on the data.\n\nA solutions architect designs a solution in which the IoT devices are streaming to Amazon Kinesis Data Streams. Several applications are reading from the stream. However, several consumers are experiencing throttling and are periodically encountering a ReadProvisionedThroughputExceeded error.\n\nWhich actions should the solutions architect take to resolve this issue? (Choose three.)","isMC":true,"timestamp":"2023-06-21 19:52:00","choices":{"E":"Use an error retry and exponential backoff mechanism in the consumer logic.","C":"Use consumers with the enhanced fan-out feature.","D":"Reshard the stream to reduce the number of shards in the stream.","F":"Configure the stream to use dynamic partitioning.","B":"Use the Kinesis Producer Library (KPL). Adjust the polling frequency.","A":"Reshard the stream to increase the number of shards in the stream."},"question_images":[],"answer_ET":"ACE","answer_images":[],"unix_timestamp":1687369920,"url":"https://www.examtopics.com/discussions/amazon/view/112851-exam-aws-certified-solutions-architect-professional-sap-c02/","answers_community":["ACE (100%)"],"answer_description":"","discussion":[{"upvote_count":"17","poster":"easytoo","timestamp":"1703360820.0","comment_id":"931829","content":"To resolve the issue of throttling and ReadProvisionedThroughputExceeded errors in the Amazon Kinesis Data Streams scenario, the solutions architect should take the following actions:\n\n1. A. Reshard the stream to increase the number of shards in the stream: By increasing the number of shards, you can increase the overall throughput capacity of the stream, allowing for more concurrent consumers to read from the stream without being throttled.\n\n2. C. Use consumers with the enhanced fan-out feature: Enhanced fan-out allows for multiple consumers to read from the same shard concurrently, without being limited by the read capacity of the shard. This helps distribute the load and reduces the chances of throttling.\n\n3. E. Use an error retry and exponential backoff mechanism in the consumer logic: Implementing an error retry mechanism with exponential backoff in the consumer logic will help handle throttling errors gracefully. When a ReadProvisionedThroughputExceeded error occurs, the consumer can retry the read operation after a certain delay, gradually increasing the delay between retries to avoid overwhelming the system."},{"poster":"yorkicurke","content":"Selected Answer: ACE\nthis link will explain it all. looks like this question was taken from here. \nhttps://repost.aws/knowledge-center/kinesis-readprovisionedthroughputexceeded","timestamp":"1713704160.0","upvote_count":"9","comment_id":"1049493"},{"upvote_count":"1","content":"Selected Answer: ACE\nAnswer ACE","comment_id":"1084471","timestamp":"1717073400.0","poster":"shaaam80"},{"comment_id":"1078836","upvote_count":"1","content":"Selected Answer: ACE\nA, C, E Options","timestamp":"1716492660.0","poster":"career360guru"},{"poster":"totten","timestamp":"1712824200.0","content":"Selected Answer: ACE\nOption (D) \"Reshard the stream to reduce the number of shards\" is generally not a recommended solution because it reduces the capacity of the stream, which might lead to more throttling issues. Reducing shards should only be considered if you're overprovisioned, and reducing capacity will not negatively impact your consumers.\n\nOption (B) \"Use the Kinesis Producer Library (KPL) and adjust the polling frequency\" may not be directly related to solving the throttling issue. The KPL is primarily used for producing data into the Kinesis stream, not consuming it.\n\nOption (F) \"Configure the stream to use dynamic partitioning\" can be beneficial for even distribution of data but is not directly related to resolving throttling issues. Dynamic partitioning is more about balancing the data across shards and does not increase overall read capacity.\n\nSo, the most relevant actions to address the throttling issue are (A), (C), and (E).","comments":[{"timestamp":"1718929800.0","upvote_count":"1","comment_id":"1102111","content":"Nice way to explain the reasons other way round :-)","poster":"GoKhe"}],"upvote_count":"4","comment_id":"1040370"},{"poster":"ggrodskiy","comment_id":"960725","upvote_count":"1","content":"Correct ACE.","timestamp":"1706041380.0"},{"content":"Selected Answer: ACE\nACE it","upvote_count":"1","timestamp":"1704513180.0","poster":"NikkyDicky","comment_id":"944228"},{"timestamp":"1704301080.0","content":"Selected Answer: ACE\nACE is correct","comment_id":"941962","poster":"SkyZeroZx","upvote_count":"1"},{"timestamp":"1703296440.0","content":"Selected Answer: ACE\nEliminate B, KPL is for writing. \"The Kinesis Producer Library (KPL) simplifies producer application development, allowing developers to achieve high write throughput to a Kinesis data stream. \" The error was reading.\n\nF, dynamic partitioning is used for different use cases.https://docs.aws.amazon.com/firehose/latest/dev/dynamic-partitioning.html","upvote_count":"3","comment_id":"931121","poster":"SmileyCloud"},{"poster":"psyx21","timestamp":"1703199660.0","upvote_count":"1","comment_id":"929926","content":"Selected Answer: ACE\nACE is correct"},{"upvote_count":"1","timestamp":"1703188320.0","content":"Selected Answer: ACE\nnot sure about E, but I would go with AC","comment_id":"929791","poster":"nexus2020"}],"question_id":136},{"id":"BTZ9DNSZTr4MWbhZByVK","question_text":"A company uses AWS Organizations to manage its AWS accounts. The company needs a list of all its Amazon EC2 instances that have underutilized CPU or memory usage. The company also needs recommendations for how to downsize these underutilized instances.\n\nWhich solution will meet these requirements with the LEAST effort?","timestamp":"2023-06-21 19:56:00","unix_timestamp":1687370160,"discussion":[{"timestamp":"1703437680.0","poster":"Maria2023","content":"Actually, the right answer is to use Compute Optimizer, I don't understand why it was not part of the choices here\nhttps://aws.amazon.com/compute-optimizer/","comment_id":"932694","upvote_count":"13"},{"content":"Selected Answer: B\nAWS Cost Explorer provides resource optimization recommendations, including rightsizing EC2 instances based on historical usage data. These recommendations are generated for each account in the organization's management account, so you can obtain insights for all accounts centrally.\n\nOption A introduces complexity by requiring the company to install a third-party tool on all EC2 instances, and then manually develop and maintain a custom script for identifying underutilized instances.\n\nOption C would require you to retrieve recommendations separately for each account within the organization, increasing the administrative overhead compared to a centralized management approach.\n\nOption D, while using native AWS services for data collection, involves creating and maintaining additional AWS services, which is more complex than the straightforward combination of CloudWatch and AWS Cost Explorer.","comment_id":"1040377","timestamp":"1712824740.0","poster":"totten","upvote_count":"7"},{"comment_id":"1093651","upvote_count":"1","poster":"duriselvan","timestamp":"1718114820.0","content":"Let's analyze each option based on effort:\n\nA. Marketplace tool:\n\nEffort: High\nRequires manual installation of a third-party tool on all instances.\nNeeds custom script development to identify underutilized instances.\nManual effort needed to reference pricing information for downsizing.\nB. Cost Explorer in Org Management Account:\n\nEffort: Low\nLeverages existing tools (CloudWatch agent & Cost Explorer) already available.\nRecommendations readily available in the management account.\nDownsizing options directly available within Cost Explorer."},{"comment_id":"1078839","upvote_count":"1","poster":"career360guru","content":"Selected Answer: B\nOption B","timestamp":"1716492780.0"},{"poster":"SK_Tyagi","upvote_count":"1","comment_id":"986133","timestamp":"1708482060.0","content":"Selected Answer: B\nIMO it could be done with either B or D. But the differentiator is \"Least Effort\" that makes it B"},{"content":"Selected Answer: B\nits a B","upvote_count":"1","comment_id":"944230","poster":"NikkyDicky","timestamp":"1704513240.0"},{"content":"Selected Answer: B\nThough I vote B. No better choice. This is worst ques. How can cost explorer provide recommendations?. Its should be cost optimizer","poster":"bhanus","comment_id":"938766","upvote_count":"3","timestamp":"1703913780.0"},{"timestamp":"1703526000.0","poster":"SkyZeroZx","content":"Selected Answer: B\nClassic usage de Cloudwatch metrics and AWS Organization in master account .\nC not because more overhead each account for example 100 accounts.\nNote : Compute Optimizer is more apropiate in this case but no exist option","upvote_count":"1","comment_id":"933727"},{"upvote_count":"2","comment_id":"931831","content":"B. Install the Amazon CloudWatch agent on all the EC2 instances using AWS Systems Manager. Retrieve the resource optimization recommendations from AWS Cost Explorer in the organization's management account. Use the recommendations to downsize underutilized instances in all accounts of the organization.\n\nThis solution leverages the capabilities of AWS CloudWatch and AWS Cost Explorer to monitor and analyze the CPU and memory usage of EC2 instances. By installing the CloudWatch agent, you can collect the necessary metrics for monitoring. AWS Cost Explorer provides resource optimization recommendations, which can be accessed from the organization's management account. These recommendations can then be used to identify underutilized instances and make informed decisions about downsizing.\n\nThis solution requires minimal effort as it utilizes existing AWS services and tools, eliminating the need for additional installations or custom scripts. It also provides a centralized approach by retrieving recommendations from the organization's management account, allowing for efficient management of all accounts within the organization.","poster":"easytoo","timestamp":"1703361060.0"},{"timestamp":"1703296620.0","upvote_count":"3","content":"Selected Answer: B\nB. That's why you have the management account so you don't have to go to 1000+ accounts and get metrics.","comment_id":"931123","poster":"SmileyCloud"},{"poster":"bhanus","upvote_count":"1","comment_id":"929950","content":"Selected Answer: B\nB - Management account is the key word","timestamp":"1703200920.0"},{"content":"Selected Answer: B\nB. the standard way AWS recommended","poster":"nexus2020","upvote_count":"1","comment_id":"929800","timestamp":"1703188560.0"}],"question_images":[],"answer":"B","question_id":137,"answer_description":"","choices":{"A":"Install a CPU and memory monitoring tool from AWS Marketplace on all the EC2 instances. Store the findings in Amazon S3. Implement a Python script to identify underutilized instances. Reference EC2 instance pricing information for recommendations about downsizing options.","B":"Install the Amazon CloudWatch agent on all the EC2 instances by using AWS Systems Manager. Retrieve the resource optimization recommendations from AWS Cost Explorer in the organization’s management account. Use the recommendations to downsize underutilized instances in all accounts of the organization.","C":"Install the Amazon CloudWatch agent on all the EC2 instances by using AWS Systems Manager. Retrieve the resource optimization recommendations from AWS Cost Explorer in each account of the organization. Use the recommendations to downsize underutilized instances in all accounts of the organization.","D":"Install the Amazon CloudWatch agent on all the EC2 instances by using AWS Systems Manager. Create an AWS Lambda function to extract CPU and memory usage from all the EC2 instances. Store the findings as files in Amazon S3. Use Amazon Athena to find underutilized instances. Reference EC2 instance pricing information for recommendations about downsizing options."},"url":"https://www.examtopics.com/discussions/amazon/view/112853-exam-aws-certified-solutions-architect-professional-sap-c02/","topic":"1","answer_images":[],"exam_id":33,"answers_community":["B (100%)"],"isMC":true,"answer_ET":"B"},{"id":"u6I2Shw6JoMAuyLvnW2L","question_text":"A company wants to run a custom network analysis software package to inspect traffic as traffic leaves and enters a VPC. The company has deployed the solution by using AWS CloudFormation on three Amazon EC2 instances in an Auto Scaling group. All network routing has been established to direct traffic to the EC2 instances.\n\nWhenever the analysis software stops working, the Auto Scaling group replaces an instance. The network routes are not updated when the instance replacement occurs.\n\nWhich combination of steps will resolve this issue? (Choose three.)","answer_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/112972-exam-aws-certified-solutions-architect-professional-sap-c02/","answers_community":["BDE (100%)"],"isMC":true,"exam_id":33,"unix_timestamp":1687456020,"question_images":[],"answer_ET":"BDE","answer":"BDE","answer_description":"","question_id":138,"timestamp":"2023-06-22 19:47:00","choices":{"B":"Update the CloudFormation template to install the Amazon CloudWatch agent on the EC2 instances. Configure the CloudWatch agent to send process metrics for the application.","C":"Update the CloudFormation template to install AWS Systems Manager Agent on the EC2 instances. Configure Systems Manager Agent to send process metrics for the application.","F":"In the CloudFormation template, write a condition that updates the network routes when a replacement instance is launched.","E":"Create an AWS Lambda function that responds to the Amazon Simple Notification Service (Amazon SNS) message to take the instance out of service. Update the network routes to point to the replacement instance.","D":"Create an alarm for the custom metric in Amazon CloudWatch for the failure scenarios. Configure the alarm to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic.","A":"Create alarms based on EC2 status check metrics that will cause the Auto Scaling group to replace the failed instance."},"discussion":[{"upvote_count":"9","content":"Selected Answer: BDE\nCW agent->CW metric->CW alarm->Lambda action","poster":"NikkyDicky","comment_id":"944235","timestamp":"1688608800.0"},{"timestamp":"1707072420.0","upvote_count":"8","comment_id":"1140431","poster":"bjexamprep","content":"Selected Answer: BDE\nThis is a bad question design.\nThe question is looking for a solution for “The network routes are not updated when the instance replacement occurs.”, which means the ASG already has the capability to detect the failure node. With this assumption, there is NO need to install a CloudWatch agent on the EC2 instance, cause the CloudWatch agent in B is doing the same thing. \nThe correct solution is to use the ASG Lifecycle Hook to invoke the Lambda to update the route. \nA better solution is to create a loadbalancer targeting the ASG, and update the route to point to the loadbalancer. With this solution, there is no need to update the route anymore."},{"poster":"chris_spencer","comment_id":"1297000","upvote_count":"1","content":"Selected Answer: BDE\nBDE.. but a professional should use ASG Lifecycle hooks https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html","timestamp":"1728835740.0"},{"comments":[{"content":"why can't you update CloudFormation templates?","poster":"chris_spencer","comment_id":"1296997","upvote_count":"1","timestamp":"1728835620.0"}],"timestamp":"1726221180.0","comment_id":"1283096","upvote_count":"1","poster":"NoDoubkevo","content":"you cannot update templates you can version them. \nADE"},{"upvote_count":"1","comment_id":"1084474","content":"Answer - BDE\nInstall CW agent on all instances using CF template\nConfigure CW to send out metrics to SNS\nConfigure Lambda as SNS target to terminate instance and update n/w routes on the new instances","timestamp":"1701356220.0","poster":"shaaam80"},{"timestamp":"1700775480.0","poster":"career360guru","upvote_count":"2","content":"Selected Answer: BDE\nB, D, E","comment_id":"1078842"},{"comment_id":"941617","poster":"Piccaso","timestamp":"1688371800.0","content":"Selected Answer: BDE\nA and F must be wrong.","upvote_count":"2"},{"upvote_count":"3","timestamp":"1687584360.0","comment_id":"932198","content":"Selected Answer: BDE\nB, D and E","poster":"PhuocT"},{"timestamp":"1687543320.0","upvote_count":"2","comment_id":"931839","content":"b-d-e seems reasonable.","poster":"easytoo"},{"content":"Selected Answer: BDE\nA is redundant because \"Whenever the analysis software stops working, the Auto Scaling group replaces an instance.\"\nC is not correct. AWS System Manager Agebt is not used \"to send process metrics for the application.\"\n\nSo, B, D and E because they make a flow.","poster":"SmileyCloud","timestamp":"1687478820.0","upvote_count":"4","comment_id":"931126"},{"upvote_count":"1","poster":"james55","content":"Selected Answer: BDE\nb----d----e","comment_id":"930859","timestamp":"1687456020.0"}]},{"id":"MlgbP7L3lgS9yH94819s","question_text":"A company is developing a new on-demand video application that is based on microservices. The application will have 5 million users at launch and will have 30 million users after 6 months. The company has deployed the application on Amazon Elastic Container Service (Amazon ECS) on AWS Fargate. The company developed the application by using ECS services that use the HTTPS protocol.\n\nA solutions architect needs to implement updates to the application by using blue/green deployments. The solution must distribute traffic to each ECS service through a load balancer. The application must automatically adjust the number of tasks in response to an Amazon CloudWatch alarm.\n\nWhich solution will meet these requirements?","answer_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/112864-exam-aws-certified-solutions-architect-professional-sap-c02/","answers_community":["D (91%)","9%"],"isMC":true,"exam_id":33,"unix_timestamp":1687383180,"question_images":[],"answer_ET":"D","answer":"D","answer_description":"","timestamp":"2023-06-21 23:33:00","question_id":139,"choices":{"C":"Configure the ECS services to use the blue/green deployment type and an Application Load Balancer. Implement an Auto Scaling group for each ECS service by using the Cluster Autoscaler.","B":"Configure the ECS services to use the blue/green deployment type and a Network Load Balancer. Implement Auto Scaling group for each ECS service by using the Cluster Autoscaler.","A":"Configure the ECS services to use the blue/green deployment type and a Network Load Balancer. Request increases to the service quota for tasks per service to meet the demand.","D":"Configure the ECS services to use the blue/green deployment type and an Application Load Balancer. Implement Service Auto Scaling for each ECS service."},"discussion":[{"content":"Selected Answer: D\nA and B are out, it says the app uses HTTPS. \nC is out because we have Fargate and there is no Cluster Auto Scaling there. \nSo, it's D because we have Service Auto Scaling. -> https://repost.aws/knowledge-center/ecs-fargate-service-auto-scaling","comment_id":"931129","poster":"SmileyCloud","comments":[{"content":"NLB supports HTTPS so why excluding A?","comment_id":"935419","poster":"emiliocb4","comments":[{"timestamp":"1720031040.0","upvote_count":"9","comment_id":"942124","poster":"SmileyCloud","content":"Unlike a Classic Load Balancer or an Application Load Balancer, a Network Load Balancer can't have application layer (layer 7) HTTP or HTTPS listeners. It only supports transport layer (layer 4) TCP listeners. HTTP and HTTPS traffic can be routed to your environment over TCP.\n\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environments-cfg-nlb.html#"}],"timestamp":"1719495300.0","upvote_count":"1"}],"timestamp":"1719101580.0","upvote_count":"15"},{"poster":"career360guru","comment_id":"1078850","upvote_count":"1","timestamp":"1732398540.0","content":"Selected Answer: D\nOption D"},{"timestamp":"1721758800.0","comment_id":"960721","content":"Correct D.","poster":"ggrodskiy","upvote_count":"1"},{"timestamp":"1721598600.0","content":"Selected Answer: D\nAnswer is D. For those voting C, remember that it's on Fargate, so there is no such cluster autoscaling.","poster":"Hypercuber","comment_id":"958985","upvote_count":"4"},{"poster":"nicecurls","upvote_count":"2","comment_id":"946365","content":"Selected Answer: D\nselect D. for Fargate there is no Cluster Auto Scaling there.","timestamp":"1720432320.0"},{"comments":[{"upvote_count":"1","poster":"vjp_training","content":"D is correct but you can use NLB for ECS. Key word is Service Auto Scaling\nhttps://docs.aws.amazon.com/AmazonECS/latest/userguide/create-network-load-balancer.html","timestamp":"1723817100.0","comment_id":"982651"}],"comment_id":"944237","upvote_count":"2","timestamp":"1720231440.0","poster":"NikkyDicky","content":"Selected Answer: D\nD\nno NLB for ECS, no Cluster for Fargate"},{"comment_id":"934640","upvote_count":"2","content":"Selected Answer: D\n@MODERATOR, PLEASE remove my previous comment as I mentioned C. \nAs per comment from SmileyCloud , C is not correct because there is no Cluster Auto Scaling. D is the answer.\nThank you @SmileyCloud for clarifying\n\nD is the answer","poster":"bhanus","timestamp":"1719420180.0"},{"poster":"SkyZeroZx","comment_id":"933730","upvote_count":"2","content":"Selected Answer: D\nhttps://repost.aws/knowledge-center/ecs-fargate-service-auto-scaling","timestamp":"1719330240.0"},{"timestamp":"1719165960.0","content":"d-d-d-d-d-d-d","poster":"easytoo","upvote_count":"1","comment_id":"931848"},{"comment_id":"930865","timestamp":"1719078720.0","poster":"james55","content":"Selected Answer: D\n\"Amazon ECS cluster auto scaling is only supported with Auto Scaling group capacity providers. For Amazon ECS workloads that are hosted on AWS Fargate, see AWS Fargate capacity providers.\"","upvote_count":"2"},{"timestamp":"1719005580.0","comments":[{"timestamp":"1719721920.0","upvote_count":"2","poster":"bhanus","comment_id":"938814","content":"changing my vote to D as SmileyCloud pointed. for Fargate there is no Cluster Auto Scaling there."}],"upvote_count":"3","content":"Selected Answer: C\nAB are eliminated because of NLB\nC has Auto Scaling Group with Cluster Autoscaler: As per ChatGPT - By implementing an Auto Scaling group for each ECS service using the Cluster Autoscaler, you can automatically adjust the number of tasks (containers) based on the demand. The Cluster Autoscaler scales the ECS tasks in response to CloudWatch alarms, allowing you to scale the infrastructure up or down to handle the increasing number of users.","comment_id":"929957","poster":"bhanus"}]},{"id":"5bSn9jCz2ITGbg867Sp0","isMC":true,"unix_timestamp":1687330260,"discussion":[{"comment_id":"1058921","comments":[{"timestamp":"1727169600.0","comment_id":"1181473","upvote_count":"3","content":"Problem with this approach is, if you scan only what's pushed, and it has a zero-day vulnerability, you won't see it. Since you are scanning only when you are pushing, you won't detect the vulnerability ever. IMO, scanning periodically gives a better shot. Ideally it should be scanning both on push and periodically.","poster":"kz407"}],"timestamp":"1714480440.0","upvote_count":"10","content":"Selected Answer: A\nYou want to look for \"scan on push\" solution, as scanning periodically is not enough, damage might have been done -> C, D is out, only A, B\nA sounds complex, but B even worse, how can you put result in SQS? wording is so bad if they means sending message to SQS. Notifying by SES is a straight red flag that AWS exams like to use. \nOnly A makes sense.","poster":"joleneinthebackyard"},{"comment_id":"1181476","upvote_count":"2","poster":"kz407","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html\n\nIn a nutshell, 2 types of scans.\n\nBasic: Scanned against CVE DB, \"ON PUSH\" or a manual scan. Don't see any way of notifying anywhere.\nEnhanced: Ongoing scanning with Amazon Inspector, findings delivered via EventBridge notifications.\n\nClosest answer would be A.","timestamp":"1727169900.0"},{"poster":"shaaam80","upvote_count":"1","comment_id":"1084485","content":"Selected Answer: A\nAnswer A.","timestamp":"1717074960.0"},{"content":"Selected Answer: A\nOption A","comment_id":"1078856","timestamp":"1716494040.0","poster":"career360guru","upvote_count":"2"},{"timestamp":"1704514440.0","comment_id":"944239","poster":"NikkyDicky","upvote_count":"3","content":"Selected Answer: A\nA, but I think step function need to call Lambda to delete tag. there is not direct ecr integration"},{"timestamp":"1703531220.0","comment_id":"933776","upvote_count":"2","poster":"SkyZeroZx","content":"Selected Answer: A\nUse the building feature if you can, so scan on push.\nI go with A because other options are not good B - you cannot use SES."},{"upvote_count":"1","content":"Selected Answer: A\nI vote A since I tested it and confirm it's achievable. As for B - I couldn't find any option to publish the result of the scan to SQS so I stopped there","poster":"Maria2023","comment_id":"932790","timestamp":"1703444280.0"},{"poster":"elanelans","content":"Selected Answer: A\nA meet the requirements.\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/ecr-eventbridge.html","comment_id":"931152","timestamp":"1703301720.0","upvote_count":"2"},{"poster":"SmileyCloud","timestamp":"1703298180.0","upvote_count":"2","comment_id":"931137","content":"Selected Answer: A\nC and D are out because they are not automatic but rather scheduled. \nB is out because you don't need SQS for this and def don't need SES. \nA makes sense because it's much leaner solution."},{"upvote_count":"1","comment_id":"930763","poster":"nexus2020","content":"Selected Answer: A\nUse the building feature if you can, so scan on push. And A make more sense","timestamp":"1703268600.0"},{"upvote_count":"2","comment_id":"929963","poster":"bhanus","content":"Selected Answer: A\nI go with A because other options are not good\nB - you cannot use SES. SES is generally used to send Bulk/marketing emails.\nC- schedule Lambda to scan every hour is not a good approach\nD - like B you cannot use SES for this use case.\nSo A sounds reasonable","timestamp":"1703202060.0"},{"content":"why not A ?","comment_id":"929135","upvote_count":"1","poster":"emiliocb4","timestamp":"1703148660.0"}],"exam_id":33,"answer_ET":"A","question_text":"A company is running a containerized application in the AWS Cloud. The application is running by using Amazon Elastic Container Service (Amazon ECS) on a set of Amazon EC2 instances. The EC2 instances run in an Auto Scaling group.\n\nThe company uses Amazon Elastic Container Registry (Amazon ECR) to store its container images. When a new image version is uploaded, the new image version receives a unique tag.\n\nThe company needs a solution that inspects new image versions for common vulnerabilities and exposures. The solution must automatically delete new image tags that have Critical or High severity findings. The solution also must notify the development team when such a deletion occurs.\n\nWhich solution meets these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/112772-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"C":"Schedule an AWS Lambda function to start a manual image scan every hour. Configure Amazon EventBridge to invoke another Lambda function when a scan is complete. Use the second Lambda function to delete the image tag for images that have Critical or High severity findings. Notify the development team by using Amazon Simple Notification Service (Amazon SNS).","A":"Configure scan on push on the repository. Use Amazon EventBridge to invoke an AWS Step Functions state machine when a scan is complete for images that have Critical or High severity findings. Use the Step Functions state machine to delete the image tag for those images and to notify the development team through Amazon Simple Notification Service (Amazon SNS).","B":"Configure scan on push on the repository. Configure scan results to be pushed to an Amazon Simple Queue Service (Amazon SQS) queue. Invoke an AWS Lambda function when a new message is added to the SQS queue. Use the Lambda function to delete the image tag for images that have Critical or High severity findings. Notify the development team by using Amazon Simple Email Service (Amazon SES).","D":"Configure periodic image scan on the repository. Configure scan results to be added to an Amazon Simple Queue Service (Amazon SQS) queue. Invoke an AWS Step Functions state machine when a new message is added to the SQS queue. Use the Step Functions state machine to delete the image tag for images that have Critical or High severity findings. Notify the development team by using Amazon Simple Email Service (Amazon SES)."},"question_id":140,"answer_images":[],"answers_community":["A (100%)"],"question_images":[],"answer_description":"","topic":"1","timestamp":"2023-06-21 08:51:00","answer":"A"}],"exam":{"lastUpdated":"11 Apr 2025","isImplemented":true,"isMCOnly":true,"provider":"Amazon","isBeta":false,"id":33,"name":"AWS Certified Solutions Architect - Professional SAP-C02","numberOfQuestions":529},"currentPage":28},"__N_SSP":true}