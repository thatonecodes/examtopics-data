{"pageProps":{"questions":[{"id":"xPskSG34p2cN2oZuySdv","isMC":true,"discussion":[{"poster":"tapan666","comment_id":"1056572","upvote_count":"8","timestamp":"1698553140.0","content":"Selected Answer: BD\nhttps://www.examtopics.com/discussions/amazon/view/88855-exam-aws-certified-developer-associate-topic-1-question-289/"},{"timestamp":"1706293920.0","content":"Selected Answer: BD\nB. Immutable: In an immutable deployment, AWS Elastic Beanstalk deploys the application version to a fresh group of instances in a new Auto Scaling group. Once the new instances pass health checks, they are moved to the existing Auto Scaling group, and the old instances are terminated. This approach ensures that new instances are used for the deployment, minimizing the impact on the existing environment.\n\nD. Blue/Green: Blue/green deployment involves deploying the new version of the application to a separate environment (the \"green\" environment). Once the new environment is ready and tested, the traffic is switched from the old environment (the \"blue\" environment) to the new one. This type of deployment is effective for ensuring that the new version is deployed on new instances and provides a straightforward way to rollback if needed.","poster":"SerialiDr","upvote_count":"5","comment_id":"1132751"},{"comment_id":"1402345","poster":"otabek94_30","timestamp":"1742744580.0","content":"Selected Answer: BE\nWhy BD? As Blue/Green is related to CodeDeploy, must not it be BE?","upvote_count":"1"},{"timestamp":"1727083080.0","comment_id":"1288048","poster":"preachr","upvote_count":"1","content":"Selected Answer: BD\ncorrect options : B and D"},{"upvote_count":"2","timestamp":"1723679940.0","poster":"Saurabh04","comments":[{"comment_id":"1288046","poster":"preachr","upvote_count":"1","content":"did you check the link: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.deploy-existing-version.html\nthere is a table at the bottom: \"The following table compares deployment method properties.\"","timestamp":"1727082960.0"},{"comment_id":"1288047","timestamp":"1727083020.0","content":"option E is wong:\n\nRolling with an additional batch --> New **and** existing instances","upvote_count":"1","poster":"preachr"}],"content":"Selected Answer: BE\nImmutable:\nAn immutable deployment launches a full set of new instances running the updated version of the application alongside the existing instances.\nIt ensures that the old instances remain untouched until the new ones pass health checks.\nOnce validated, the old instances are terminated, resulting in minimal downtime.\nRolling with additional batch:\nIn a rolling deployment with an additional batch, Elastic Beanstalk launches a new batch of instances before taking any existing instances out of service.\nThis maintains full capacity during deployments.\nAfter successful deployment, the additional batch of instances is terminated.","comment_id":"1266083"},{"timestamp":"1716496320.0","comment_id":"1217005","poster":"65703c1","content":"Selected Answer: BD\nBD is the correct answer.","upvote_count":"1"},{"comment_id":"1098457","timestamp":"1702754220.0","upvote_count":"2","content":"Selected Answer: BD\nBD - https://www.examtopics.com/discussions/amazon/view/88855-exam-aws-certified-developer-associate-topic-1-question-289/","poster":"Certified101"},{"timestamp":"1698537420.0","upvote_count":"2","content":"B. Immutable\nD. Blue/green","comment_id":"1056495","poster":"Claire_KMT"}],"timestamp":"2023-10-29 01:57:00","topic":"1","question_id":166,"question_images":[],"answer_description":"","answers_community":["BD (85%)","BE (15%)"],"unix_timestamp":1698537420,"exam_id":24,"url":"https://www.examtopics.com/discussions/amazon/view/124859-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer":"BD","question_text":"A company is using AWS Elastic Beanstalk to manage web applications that are running on Amazon EC2 instances. A developer needs to make configuration changes. The developer must deploy the changes to new instances only.\n\nWhich types of deployment can the developer use to meet this requirement? (Choose two.)","choices":{"C":"Rolling","D":"Blue/green","A":"All at once","E":"Rolling with additional batch","B":"Immutable"},"answer_images":[],"answer_ET":"BD"},{"id":"5rICCrbtZwGwweucFM1c","unix_timestamp":1698537540,"discussion":[{"upvote_count":"1","content":"B is correct, yes it is seems D from the first look but the keyword is a \"customer\" not \"aws\" because says the key compony generated","comment_id":"1306164","timestamp":"1730549760.0","poster":"Saudis"},{"poster":"65703c1","comment_id":"1217007","content":"Selected Answer: B\nB is the correct answer.","upvote_count":"2","timestamp":"1716496380.0"},{"timestamp":"1707115620.0","upvote_count":"2","poster":"joshnort","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/database/bring-your-own-encryption-keys-to-amazon-dynamodb/","comment_id":"1140720"},{"poster":"SerialiDr","comment_id":"1132758","timestamp":"1706294280.0","content":"Selected Answer: B\nThis option allows the developer to use a customer-managed key in AWS KMS for encryption at rest in DynamoDB. The customer-managed key offers more flexibility and control over the key management compared to AWS managed keys. When creating the DynamoDB table, the developer can specify the KMS key to be used for encryption.","upvote_count":"4"},{"content":"Selected Answer: B\nhttps://www.examtopics.com/discussions/amazon/view/78943-exam-aws-certified-developer-associate-topic-1-question-23/","upvote_count":"3","comment_id":"1056573","poster":"tapan666","timestamp":"1698553260.0"},{"comment_id":"1056497","timestamp":"1698537540.0","content":"B. Store the key by using AWS Key Management Service (AWS KMS). Choose an AWS KMS customer managed key during the creation of the DynamoDB table. Provide the Amazon Resource Name (ARN) of the AWS KMS key.","upvote_count":"3","poster":"Claire_KMT"}],"answer_images":[],"question_text":"A developer needs to use Amazon DynamoDB to store customer orders. The developerâ€™s company requires all customer data to be encrypted at rest with a key that the company generates.\n\nWhat should the developer do to meet these requirements?","choices":{"C":"Store the key by using AWS Key Management Service (AWS KMS). Create the DynamoDB table with default encryption. Include the kms:Encrypt parameter with the Amazon Resource Name (ARN) of the AWS KMS key when using the DynamoDB software development kit (SDK).","B":"Store the key by using AWS Key Management Service (AWS KMS). Choose an AWS KMS customer managed key during creation of the DynamoDB table. Provide the Amazon Resource Name (ARN) of the AWS KMS key.","D":"Store the key by using AWS Key Management Service (AWS KMS). Choose an AWS KMS AWS managed key during creation of the DynamoDB table. Provide the Amazon Resource Name (ARN) of the AWS KMS key.","A":"Create the DynamoDB table with encryption set to None. Code the application to use the key to decrypt the data when the application reads from the table. Code the application to use the key to encrypt the data when the application writes to the table."},"url":"https://www.examtopics.com/discussions/amazon/view/124860-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer_description":"","exam_id":24,"isMC":true,"answer":"B","timestamp":"2023-10-29 01:59:00","question_images":[],"answer_ET":"B","topic":"1","answers_community":["B (100%)"],"question_id":167},{"id":"KoMMTGs1bmRd52eP2Z5u","topic":"1","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/103510-exam-aws-certified-developer-associate-dva-c02-topic-1/","answers_community":["C (96%)","4%"],"question_id":168,"answer_images":[],"answer_ET":"C","unix_timestamp":1679432820,"question_images":[],"isMC":true,"answer":"C","discussion":[{"content":"Selected Answer: C\nMulti-AZ is for disaster recovery, not read scalability or performance.","upvote_count":"7","comment_id":"893300","poster":"Devon_Fazekas","timestamp":"1683650340.0"},{"timestamp":"1734781080.0","content":"Selected Answer: C\nA) & B) - Eliminated - Multi-AZ deployments are designed for high availability and failover, not for scaling read performance.\n\nD) Eliminated - significant operational overhead to set up and maintain replication between the primary database and the EC2 instance","upvote_count":"2","comment_id":"1329973","poster":"sumanshu"},{"poster":"trieudo","content":"Selected Answer: C\nkeyword: read-heavy workloads, LEAST current and future effort\n\n==> discard A, B: multiAZ, just only make high availibity, option A: it make you can handler bigger cocurency request, option B you can access to secondary RDS in normal case by modifying code. Both are not help for 'read-heavy workloads'\n==> discard D: take time to execute, maintain, ... when use not-intergated source, violate 'LEAST current and future effort'\n\nC is best choice","comment_id":"1326309","timestamp":"1734139980.0","upvote_count":"3"},{"upvote_count":"1","content":"Selected Answer: C\nIt should be C as we need to update the URL of the rds endpoint as it is needed to connect the application to use the read replicas for read queries.","timestamp":"1733985000.0","poster":"Piku2","comment_id":"1325432"},{"poster":"tomchandler077","content":"Option C provides the most straightforward and effective solution for improving read performance with minimal changes to the current application code and the least ongoing maintenance effort. Deploying read replicas allows for scaling read capacity and distributing read traffic efficiently.","upvote_count":"3","comment_id":"1243911","timestamp":"1720367400.0"},{"poster":"nkroker","upvote_count":"1","content":"Option C is wrong because deploying a read replica will be more effort then just enabling the multi-AZ with RDS and also the multi-AZ is meant for high availability that's why option B is correct.","timestamp":"1720115820.0","comment_id":"1242227","comments":[{"comment_id":"1310658","upvote_count":"1","content":"No, multi AZ is vor desaster recovery.","timestamp":"1731422940.0","poster":"JonasKahnwald"}]},{"poster":"65703c1","content":"Selected Answer: C\nC is the correct answer.","comment_id":"1215038","timestamp":"1716303000.0","upvote_count":"1"},{"timestamp":"1713990060.0","upvote_count":"1","poster":"Vaibs099","content":"Option A and B are both talking about Multi AZ RDS instance which gives Primary and Secondary(Non Read Replica). This is good for high availability but will not help in reads. Read replica or Multi AZ Cluster deployment is the only option to achieve high reads.","comment_id":"1201622"},{"comment_id":"1198141","content":"C it is as it clearly mentions they want to achieve optimum read performance","upvote_count":"2","poster":"Dikshika","timestamp":"1713469620.0"},{"timestamp":"1712769000.0","content":"Selected Answer: C\nC forever","comment_id":"1193176","upvote_count":"1","poster":"dan_bj"},{"content":"Selected Answer: C\nC... No Question","poster":"badsati","comment_id":"1191782","timestamp":"1712602980.0","upvote_count":"1"},{"comment_id":"1190649","poster":"vinfo","content":"Selected Answer: C\nC. El uso de replicas de lectura, aliviana las consultas intensivas sobre la BD principal","timestamp":"1712443500.0","upvote_count":"1"},{"comments":[{"timestamp":"1711537320.0","comment_id":"1184014","poster":"mghectorenjoyer69","upvote_count":"1","content":"ni mada ra"}],"comment_id":"1102568","timestamp":"1703166240.0","upvote_count":"2","poster":"xdkonorek2","content":"Selected Answer: B\neasiest solution is to use multi-az rds deployment with 2 readable standby instances\nsetting up read replica is more effort than checking a single option"},{"content":"Selected Answer: C\nRead heavy access need read replicas as the right solution.","upvote_count":"4","comment_id":"1015673","timestamp":"1695550980.0","poster":"Skywalker23"},{"timestamp":"1693743540.0","content":"Selected Answer: C\nKeyword: heavy read","comment_id":"997599","upvote_count":"3","poster":"Tony88"},{"content":"Selected Answer: C\nRead Replicas for high performance read operations","timestamp":"1692749220.0","upvote_count":"2","comment_id":"987831","poster":"Akash619"},{"upvote_count":"2","comment_id":"977028","poster":"jayvarma","timestamp":"1691615820.0","content":"Keyword: Achieve Optimum read performance for queries.\nAnswer: Use Read Replicas and use that specific URL for read queries."},{"timestamp":"1683266940.0","poster":"Malkia","content":"Selected Answer: C\nC answer","comment_id":"889821","upvote_count":"1"},{"comment_id":"876283","content":"Selected Answer: C\nC answer","upvote_count":"3","timestamp":"1682065020.0","poster":"Rpod"},{"upvote_count":"2","comment_id":"862050","timestamp":"1680694680.0","content":"Selected Answer: C\nIt's C.","poster":"Krok"},{"poster":"Dun6","content":"Selected Answer: C\nHeavy reads, use read replica","upvote_count":"3","comment_id":"848679","timestamp":"1679606100.0"},{"content":"Selected Answer: C\nC\nhttps://aws.amazon.com/rds/features/read-replicas/","upvote_count":"4","comment_id":"847932","timestamp":"1679556660.0","poster":"Untamables"},{"poster":"March2023","comment_id":"847795","timestamp":"1679545740.0","upvote_count":"2","content":"Selected Answer: C\nIt is C"},{"upvote_count":"2","timestamp":"1679481120.0","comment_id":"846935","poster":"Ajaykumarlp","content":"It is C"},{"poster":"svrnvtr","upvote_count":"2","content":"Selected Answer: C\nSeems like it is C","comment_id":"846351","timestamp":"1679432820.0"}],"timestamp":"2023-03-21 22:07:00","exam_id":24,"question_text":"A company is migrating an on-premises database to Amazon RDS for MySQL. The company has read-heavy workloads. The company wants to refactor the code to achieve optimum read performance for queries.\nWhich solution will meet this requirement with LEAST current and future effort?","choices":{"B":"Use a multi-AZ Amazon RDS deployment. Modify the code so that queries access the secondary RDS instance.","A":"Use a multi-AZ Amazon RDS deployment. Increase the number of connections that the code makes to the database or increase the connection pool size if a connection pool is in use.","D":"Use open source replication software to create a copy of the MySQL database on an Amazon EC2 instance. Modify the application code so that queries use the IP address of the EC2 instance.","C":"Deploy Amazon RDS with one or more read replicas. Modify the application code so that queries use the URL for the read replicas."}},{"id":"tNoJBYD5S4pe7Gn3IBsm","isMC":true,"discussion":[{"upvote_count":"2","content":"Selected Answer: D\nD is the correct answer.","timestamp":"1732401360.0","comment_id":"1217008","poster":"65703c1"},{"timestamp":"1722063840.0","poster":"SerialiDr","upvote_count":"3","comment_id":"1133196","content":"Selected Answer: D\nAmazon API Gateway supports canary release deployments, which are specifically designed for this type of scenario. By configuring canary settings, the developer can gradually roll out changes to a small percentage of users (20% in this case) while still serving the majority of users (80%) with the current production stage. This approach helps in minimizing the impact of potential issues with new deployments."},{"content":"Selected Answer: D\nD is correct","poster":"ansobimat","timestamp":"1716204720.0","upvote_count":"3","comment_id":"1075429"},{"upvote_count":"2","comment_id":"1056499","content":"D. Configure canary settings for the production stage API. Change the percentage of traffic directed to canary deployment to 20%. Make the planned updates to the production stage. Deploy the changes","poster":"Claire_KMT","timestamp":"1714345320.0"}],"timestamp":"2023-10-29 02:02:00","topic":"1","question_id":169,"question_images":[],"answer_description":"","answers_community":["D (100%)"],"unix_timestamp":1698537720,"exam_id":24,"answer":"D","question_text":"A company uses AWS CloudFormation to deploy an application that uses an Amazon API Gateway REST API with AWS Lambda function integration. The application uses Amazon DynamoDB for data persistence. The application has three stages: development, testing, and production. Each stage uses its own DynamoDB table.\n\nThe company has encountered unexpected issues when promoting changes to the production stage. The changes were successful in the development and testing stages. A developer needs to route 20% of the traffic to the new production stage API with the next production release. The developer needs to route the remaining 80% of the traffic to the existing production stage. The solution must minimize the number of errors that any single customer experiences.\n\nWhich approach should the developer take to meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/124861-exam-aws-certified-developer-associate-dva-c02-topic-1/","choices":{"C":"Deploy an Application Load Balancer (ALB) in front of the REST API. Change the production API Amazon Route 53 record to point traffic to the ALB. Register the production and testing stages as targets of the ALB with weights of 80% and 20%, respectively.","D":"Configure canary settings for the production stage API. Change the percentage of traffic directed to canary deployment to 20%. Make the planned updates to the production stage. Deploy the changes","B":"Update the Amazon Route 53 DNS record entry for the production stage API to use a weighted routing policy. Set the weight to a value of 80. Add a second record for the production domain name. Change the second routing policy to a weighted routing policy. Set the weight of the second policy to a value of 20. Change the alias of the second policy to use the testing stage API.","A":"Update 20% of the planned changes to the production stage. Deploy the new production stage. Monitor the results. Repeat this process five times to test all planned changes."},"answer_images":[],"answer_ET":"D"},{"id":"KbgvHXHzsA3GRSWCSIoh","timestamp":"2023-10-29 02:05:00","answer_ET":"A","exam_id":24,"question_text":"A developer has created a data collection application that uses Amazon API Gateway, AWS Lambda, and Amazon S3. The applicationâ€™s users periodically upload data files and wait for the validation status to be reflected on a processing dashboard. The validation process is complex and time-consuming for large files.\n\nSome users are uploading dozens of large files and have to wait and refresh the processing dashboard to see if the files have been validated. The developer must refactor the application to immediately update the validation result on the userâ€™s dashboard without reloading the full dashboard.\n\nWhat is the MOST operationally efficient solution that meets these requirements?","topic":"1","answers_community":["A (84%)","D (16%)"],"answer":"A","isMC":true,"unix_timestamp":1698537900,"question_id":170,"question_images":[],"choices":{"D":"Save the user-uploaded file and user detail to Amazon DynamoDB. Use Amazon DynamoDB Streams with Amazon Simple Notification Service (Amazon SNS) push notifications to send updates to the browser to update the user interface.","A":"Integrate the client with an API Gateway WebSocket API. Save the user-uploaded files with the WebSocket connection ID. Push the validation status to the connection ID when the processing is complete to initiate an update of the user interface.","C":"Save the userâ€™s email address along with the user-uploaded file. When the validation process is complete, send an email notification through Amazon Simple Notification Service (Amazon SNS) to the user who uploaded the file.","B":"Launch an Amazon EC2 micro instance, and set up a WebSocket server. Send the user-uploaded file and user detail to the EC2 instance after the user uploads the file. Use the WebSocket server to send updates to the user interface when the uploaded file is processed."},"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/124862-exam-aws-certified-developer-associate-dva-c02-topic-1/","discussion":[{"content":"Selected Answer: A\nOption B involves setting up a WebSocket server on an EC2 instance, which is more manual and may require additional management overhead. Option C relies on email notifications, which might introduce delays and may not provide the desired real-time updates. Option D involves DynamoDB and SNS, which may add complexity without the direct support for real-time updates that WebSocket provides.\n\nSo, Option A","upvote_count":"8","timestamp":"1714551120.0","comment_id":"1059555","poster":"PrakashM14"},{"content":"Selected Answer: A\nA is the correct answer.","timestamp":"1732409160.0","poster":"65703c1","comment_id":"1217071","upvote_count":"1"},{"timestamp":"1725349860.0","upvote_count":"1","comment_id":"1164676","poster":"KarBiswa","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api.html\nThe use case says the option"},{"poster":"SerialiDr","upvote_count":"3","comment_id":"1133365","timestamp":"1722079200.0","content":"Selected Answer: A\nThis approach leverages the real-time capabilities of WebSocket connections managed by Amazon API Gateway. When a user uploads a file, the application can associate the file with the user's WebSocket connection ID. Once the file validation process completes, the application can send the status directly to the connected client, allowing immediate updates to the dashboard without the need for manual refreshes."},{"timestamp":"1718153100.0","content":"Selected Answer: D\nBased on ChatGPT: D.","comment_id":"1094033","poster":"tqiu654","upvote_count":"1"},{"poster":"ansobimat","timestamp":"1716204960.0","content":"Selected Answer: A\nA. Integrate the client with an API Gateway WebSocket API. Save the user-uploaded files with the WebSocket connection ID. Push the validation status to the connection ID when the processing is complete to initiate an update of the user interface.","upvote_count":"3","comment_id":"1075434"},{"upvote_count":"2","poster":"tapan666","content":"Selected Answer: D\nOption C could work for notifying users, it doesn't provide immediate updates on the user's dashboard. Users would need to check their email to see the validation status, which may not be as user-friendly as real-time updates on the dashboard.\nIt adds complexity with email notifications and may result in longer delays before users see the validation results.\n\nOption D (using DynamoDB Streams and Amazon SNS) is preferred because it offers a more operationally efficient and real-time solution without the need for WebSocket management, email notifications, or a constantly running EC2 instance. It provides immediate updates on the user's dashboard while keeping operational complexity and costs to a minimum.","timestamp":"1714357800.0","comment_id":"1056576"},{"poster":"Claire_KMT","content":"B. Launch an Amazon EC2 micro instance, and set up a WebSocket server. Send the user-uploaded file and user detail to the EC2 instance after the user uploads the file. Use the WebSocket server to send updates to the user interface when the uploaded file is processed.\nOR\nD. Save the user-uploaded file and user detail to Amazon DynamoDB. Use Amazon DynamoDB Streams with Amazon Simple Notification Service (Amazon SNS) push notifications to send updates to the browser to update the user interface.","upvote_count":"1","timestamp":"1714345500.0","comment_id":"1056502"}],"answer_images":[]}],"exam":{"lastUpdated":"11 Apr 2025","isBeta":false,"numberOfQuestions":551,"provider":"Amazon","isMCOnly":true,"id":24,"name":"AWS Certified Developer - Associate DVA-C02","isImplemented":true},"currentPage":34},"__N_SSP":true}