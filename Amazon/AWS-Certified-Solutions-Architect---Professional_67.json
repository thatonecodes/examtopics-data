{"pageProps":{"questions":[{"id":"dRrrGGILcz6bDD3w3fkz","question_id":331,"topic":"1","discussion":[{"content":"Selected Answer: B\nB, its du","comment_id":"543170","timestamp":"1644335220.0","poster":"jj22222","upvote_count":"1"},{"timestamp":"1640943300.0","poster":"cldy","upvote_count":"1","content":"B: du and stat.","comment_id":"513993"},{"comment_id":"363251","content":"B du and stat \nhttps://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html","upvote_count":"2","timestamp":"1634374080.0","poster":"Skdbc"}],"exam_id":32,"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/53304-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"B","unix_timestamp":1621626000,"question_text":"Amazon Elastic File System (EFS) provides information about the space used for an object by using the space _ used attribute of the Network File System Version\n4.1 (NFSv4.1). The attribute includes the object's current metered data size and not the metadata size. Which of the following utilities will you use to measure the amount of disk that is used of a file?","answer":"B","choices":{"D":"pydf utility","C":"sfdisk utility","A":"blkid utility","B":"du utility"},"timestamp":"2021-05-21 21:40:00","isMC":true,"answer_description":"Amazon EFS reports file system sizes and sizes of objects within a file system. Using the NFSv4.1 space _ used attribute for measuring the space used for an object, it reports only the object's current metered data size and not the metadata size. There are two utilities available for measuring disk usage of a file, the du and stat utilities.\nReference:\nhttps://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html","answer_images":[],"question_images":[]},{"id":"XtOIYVJemoCVW0MzAOdc","answers_community":["CE (100%)"],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/5667-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"CE","discussion":[{"poster":"Moon","content":"Answer: C, E.\nC: it is great solution to use SQS as it spread the write load, and absorb the high load per second, which allow for less read and write capacity on DynamoDB.\nD: There is no high reparative access to similar data, so we would cache them using ElastiCache!! it is once per morning, where the user see the report of last night.\n\nE: Comparing to deleting the table every morning after storing the information on S3, which would save DyB capacity, and reduce cost!!\n\nany other ideas?","comment_id":"12541","upvote_count":"29","comments":[{"content":"Agree C E reducing the size of DynamoDb reduces the required RCU and WCU","timestamp":"1632460800.0","upvote_count":"4","comment_id":"17396","poster":"Warrenn"},{"poster":"hilft","timestamp":"1658966100.0","content":"No idea. CE is the perfect combo","upvote_count":"1","comment_id":"638361"},{"poster":"RVivek","upvote_count":"2","content":"Makes perfect sens","timestamp":"1640850360.0","comment_id":"513120"}],"timestamp":"1632346020.0"},{"upvote_count":"1","comment_id":"1266488","poster":"amministrazione","timestamp":"1723731120.0","content":"C. Introduce an Amazon SQS queue to buffer writes to the Amazon DynamoDB table and reduce provisioned write throughput.\nE. Create a new Amazon DynamoDB table each day and drop the one for the previous day after its data is on Amazon S3."},{"poster":"2cool2touch","upvote_count":"1","content":"Dropping DB table every day is a horrible idea and has a lot of management overhead. This wont be a recommended approach at all.\nD still make sense. New data is uploaded everyday but there is no mention of caching on the mobile devices. Meaning if a user is looking everyday at their data, its likely pulling historic data as well where Read cache could come into play and reduce provisioned read throughput cost.\nC, D should be answers","timestamp":"1710258720.0","comment_id":"1171806"},{"comment_id":"1115642","content":"Selected Answer: CE\nC: SQS is good to throttle writes to DynamodDB: https://newsletter.simpleaws.dev/p/sqs-throttle-database-writes-dynamodb\nD: ruled out as there is only a \"one-off\" read of the data each morning to get the data. Caching is not needed in that case\nE: This is a good cost optimization tip as the db is not used anymore after data is processed and persisted in an S3 bucket","timestamp":"1704614820.0","upvote_count":"1","poster":"shammous"},{"poster":"TigerInTheCloud","timestamp":"1671287400.0","comment_id":"748120","content":"Selected Answer: CE\nagree with bobsmith2000","upvote_count":"1"},{"content":"Selected Answer: CE\nI'm more inclined to choose CE.\nA) Accessing S3 is much more cheaper, than DDB. Moreover it gonna be used a few times per user or cached on a mobile device. S3 lifecycle is gonna be more useful in that case.\nB) Redshift is a red herring.\nC) Even though 1 WCU = 1KB, we have to spread the load to not depleting all WCU capacity.\nD) There's no reason to pay for ElastiCache because the data is read once and then is put in S3.\nE) Creating new DDB and dropping the previous one makes sense as long as you put data in S3. In reduces a query/scan volume and consumes less RCU.","comment_id":"607934","timestamp":"1653631500.0","poster":"bobsmith2000","upvote_count":"2"},{"upvote_count":"1","timestamp":"1652471880.0","poster":"ghfalcon7","comment_id":"601336","content":"C,E: https://stackoverflow.com/questions/32813873/avoid-throttle-dynamodb"},{"content":"C and E.","timestamp":"1641012960.0","comment_id":"514367","poster":"cldy","upvote_count":"2"},{"comment_id":"511829","upvote_count":"2","poster":"seanfang","content":"Selected Answer: CE\nI'll go with C&E.\nD it is not necessary","timestamp":"1640756880.0"},{"poster":"Tan0k","content":"Selected Answer: CE\nC & E is correct","upvote_count":"2","timestamp":"1639577220.0","comment_id":"502220"},{"poster":"01037","upvote_count":"2","comment_id":"344663","timestamp":"1636136040.0","content":"C & E for sure"},{"upvote_count":"1","poster":"hihismkskks","comment_id":"329298","timestamp":"1635652260.0","content":"C & E is right"},{"content":"ElastiCache won't work as the data is scanned once, nothing needs to be cached.","comment_id":"294605","timestamp":"1635594660.0","poster":"Madwyn","upvote_count":"1"},{"comment_id":"232840","comments":[{"upvote_count":"1","comment_id":"232846","poster":"ChauPhan","content":"Sorry I consider D as well, because as question, we need to scan the table and aggregate the result. So read CU is also important. So maybe D,E. We ignore write CU because SQS does not help to reduce write CU","timestamp":"1635261120.0"}],"upvote_count":"1","poster":"ChauPhan","timestamp":"1635179940.0","content":"Agree with C and E. \nDynamoDB will charge based on 02 things: the table you stored on disk based on capacity Gb and Read/Write throughput. So after querying and processing the table, storing the result in S3, you can remove old table. The user will read from S3 result, you don't need to keep old data 100k user every 5 mins 5k each.\nTo reduce the write throughput, C can be used. We don't need to use Elasticcache to reduce the read throughput because we read from S3 where we stored processed result."},{"comment_id":"226284","poster":"qkhanhpro","upvote_count":"1","timestamp":"1635097560.0","content":"I disagree with C\nSQS is not free, neither is the poller need to be employed since there is no direct free SQS - DynamoDB integration yet\nThe workload is also highly stable for SQS to do anything meaningful here","comments":[{"poster":"01037","upvote_count":"1","content":"The point is SQS is much cheaper comparing to write capacity of DynamoDB.","timestamp":"1636065300.0","comment_id":"344662"}]},{"comments":[{"upvote_count":"1","poster":"lalitsrana","content":"I think they are assuming that there is a processor between SQL and DynamoDB.\nSo data would be processed before writing to DynamoDB and not after storing to DB (the processes results are again assumed to be stored in Dynamo DB).","comment_id":"276909","timestamp":"1635463680.0"}],"poster":"newme","upvote_count":"3","content":"Why C.\nAfter all, the amount of data to write to Dynamodb is the same, isn't it?\nSo needed write capacity doesn't change, and it's not free to use SQS.","comment_id":"210250","timestamp":"1635025860.0"},{"content":"C & E is correct","comment_id":"190205","upvote_count":"1","timestamp":"1634931180.0","poster":"srknbngl"},{"content":"C,E - both options will reduce cost.","timestamp":"1634895060.0","comment_id":"170308","poster":"Bulti","upvote_count":"1"},{"content":"C & E is correct","comment_id":"143443","timestamp":"1634889240.0","poster":"fullaws","upvote_count":"1"},{"poster":"noisonnoiton","timestamp":"1634624580.0","comment_id":"127382","content":"go with C,E","upvote_count":"3"},{"timestamp":"1634550300.0","comment_id":"116926","content":"C: SQS to manage write capacity.\nE: Cost of S3 is always lower than other storage options. So deleting tables from DB once stored on S3 is better option.","poster":"manoj101","upvote_count":"2"},{"timestamp":"1633466820.0","comment_id":"66119","poster":"Smart","upvote_count":"3","content":"Option C automatically assumes there is a processor between SQS & DynamoDB right?"},{"comment_id":"54277","comments":[{"poster":"RogerRabbit","content":"The problem with D is that you are introducing a caching layer for data that is effectively only read once to do aggregation in the morning. That alone eliminates this as an option","upvote_count":"2","comment_id":"86584","timestamp":"1633989780.0"}],"poster":"virtual","timestamp":"1633451760.0","upvote_count":"1","content":"\"optimize the architecture of the backend system to lower cost\". I think the right responses are CD because you can reduce table throughput in the 2 answers."},{"poster":"kamonegi","timestamp":"1633053540.0","content":"I agree C,E.\nIf there is necessary to read many times from DB, D is also correct answer?","upvote_count":"3","comment_id":"53758"},{"upvote_count":"4","poster":"BillyC","timestamp":"1632934440.0","comment_id":"49663","content":"C and E"},{"comment_id":"37721","comments":[{"content":"About E, that would be useful to compensate write peaks without having to provision a higher write capacity, but the write demand is completely stable and predictable, and we won't have time in the morning to catch up because then the reports need to be created. I think B is a better option.","comment_id":"40687","upvote_count":"1","timestamp":"1632636900.0","comments":[{"content":"Or actually A, to save S3 costs achieving the same.","timestamp":"1632695040.0","comment_id":"40688","upvote_count":"2","poster":"Musk"}],"poster":"Musk"}],"upvote_count":"3","content":"Answer is C,E\nC: Data is stored on S3, we can delete this to reduce cost\nE: SQS to match write capacity and reduce the write cost","poster":"amog","timestamp":"1632512760.0"}],"question_id":332,"exam_id":32,"answer_images":[],"topic":"1","timestamp":"2019-09-25 03:55:00","question_text":"You are the new IT architect in a company that operates a mobile sleep tracking application.\nWhen activated at night, the mobile app is sending collected data points of 1 kilobyte every 5 minutes to your backend.\nThe backend takes care of authenticating the user and writing the data points into an Amazon DynamoDB table.\nEvery morning, you scan the table to extract and aggregate last night's data on a per user basis, and store the results in Amazon S3. Users are notified via\nAmazon SNS mobile push notifications that new data is available, which is parsed and visualized by the mobile app.\nCurrently you have around 100k users who are mostly based out of North America.\nYou have been tasked to optimize the architecture of the backend system to lower cost.\nWhat would you recommend? (Choose two.)","answer_description":"","unix_timestamp":1569376500,"isMC":true,"answer":"CE","choices":{"C":"Introduce an Amazon SQS queue to buffer writes to the Amazon DynamoDB table and reduce provisioned write throughput.","B":"Write data directly into an Amazon Redshift cluster replacing both Amazon DynamoDB and Amazon S3.","A":"Have the mobile app access Amazon DynamoDB directly Instead of JSON files stored on Amazon S3.","D":"Introduce Amazon Elasticache to cache reads from the Amazon DynamoDB table and reduce provisioned read throughput.","E":"Create a new Amazon DynamoDB table each day and drop the one for the previous day after its data is on Amazon S3."}},{"id":"Tex6fQWbIisC3pzXGOzX","answer":"A","exam_id":32,"question_id":333,"answer_images":[],"answer_ET":"A","question_text":"You have custom Network File System (NFS) client settings for your Amazon Elastic File System (EFS). It takes up to three seconds for an Amazon Elastic\nCompute Cloud (EC2) instance to see a write operation performed on a file system from another Amazon EC2 instance.\nWhich of the following actions should you take to solve the custom NFS settings from causing delays in the write operation?","timestamp":"2020-05-13 18:16:00","question_images":[],"answers_community":["A (100%)"],"unix_timestamp":1589386560,"discussion":[{"timestamp":"1686951060.0","poster":"SkyZeroZx","upvote_count":"1","comment_id":"925562","content":"Selected Answer: A\nA\nbecause it's de pinacle of engineer reset the system\n\nDoc \nhttps://docs.aws.amazon.com/efs/latest/ug/troubleshooting-efs-general.html"},{"upvote_count":"1","timestamp":"1646454000.0","poster":"pal40sg","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/efs/latest/ug/troubleshooting-efs-general.html","comment_id":"561172"},{"content":"A\nhttps://docs.aws.amazon.com/efs/latest/ug/troubleshooting-efs-general.html","timestamp":"1644467940.0","poster":"cloudude","comment_id":"544301","upvote_count":"1"},{"upvote_count":"3","content":"it is A. i changed my answer\nbecause of this: Unmount and remount the file system with the noac option to disable attribute caching.","comment_id":"485313","poster":"ryu10_09","timestamp":"1637692140.0"},{"upvote_count":"1","timestamp":"1637692020.0","poster":"ryu10_09","comment_id":"485311","content":"I believe it is D : Run the write operation from a different user ID on the same Amazon EC2 instance.\nhttps://docs.aws.amazon.com/efs/latest/ug/troubleshooting-efs-general.html"},{"comment_id":"88370","timestamp":"1633840980.0","poster":"Merlin1","upvote_count":"3","content":"https://docs.aws.amazon.com/efs/latest/ug/troubleshooting-efs-general.html"}],"url":"https://www.examtopics.com/discussions/amazon/view/20492-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"topic":"1","choices":{"D":"Run the write operation from a different user ID on the same Amazon EC2 instance.","B":"Reduce the number of active users that have files open simultaneously on the instances.","A":"Unmount and remount the file system with the noac option to disable attribute caching.","C":"Verify that the IP address of the specified mount target is valid."},"answer_description":"When you set up custom NFS client settings, it takes up to three seconds for an Amazon EC2 instance to see a write operation being performed on a file system from another Amazon EC2 instance. To solve this issue, you must unmount and remount your file system with the noac option to disable attribute caching if the\nNFS client on the Amazon EC2 instance that is reading the data has attribute caching activated. Attribute cache can also be cleared on demand by using a programming language that is compatible with the NFS procedures. To do this, you must send an ACCESS procedure request immediately before a read request.\nReference:\nhttp://docs.aws.amazon.com/efs/latest/ug/troubleshooting.html#custom-nfs-settings-write-delays"},{"id":"6IyGNj48tDqqw7N3RSlG","answers_community":["D (100%)"],"isMC":true,"choices":{"D":"Allow inbound traffic to the Network File System (NFS) port (2049) from the on-premises server.","B":"Set up a Point-To-Point Tunneling Protocol Server (PPTP) to allow secure connection.","C":"Permit secure traffic to the Kerberos port 88 from the on-premises server.","A":"Configure an NFS proxy between Amazon EFS and the on-premises server to route traffic."},"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/9024-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"answer_ET":"D","question_text":"Which of the following rules must be added to a mount target security group to access Amazon Elastic File System (EFS) from an on-premises server?","answer_description":"By mounting an Amazon EFS file system on an on-premises server, on-premises data can be migrated into the AWS Cloud. Any one of the mount targets in your\nVPC can be used as long as the subnet of the mount target is reachable by using the AWS Direct Connect connection. To access Amazon EFS from an on- premises server, a rule must be added to the mount target security group to allow inbound traffic to the NFS port (2049) from the on-premises server.\nReference:\nhttp://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","discussion":[{"comment_id":"925564","poster":"SkyZeroZx","timestamp":"1686951240.0","content":"Selected Answer: D\nD is correct","upvote_count":"1"},{"content":"My Answer: D","poster":"challenger1","upvote_count":"1","comment_id":"499008","timestamp":"1639179720.0"},{"timestamp":"1637227260.0","upvote_count":"1","content":"D is your choice","comment_id":"480553","poster":"ryu10_09"},{"poster":"Kelvin","timestamp":"1633095600.0","comment_id":"334728","content":"D is correct","upvote_count":"1"},{"comment_id":"24137","poster":"2g","timestamp":"1633044660.0","upvote_count":"1","content":"answer: D"}],"timestamp":"2019-11-24 21:31:00","exam_id":32,"unix_timestamp":1574627460,"question_id":334,"topic":"1","question_images":[]},{"id":"0j64skbKSrQhRhDaym36","unix_timestamp":1615792680,"isMC":true,"question_images":[],"answer_description":"Amazon EBS encryption uses AWS Key Management Service (AWS KMS) master keys when creating encrypted volumes and any snapshots created from your encrypted volumes.\nReference:\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html","discussion":[{"timestamp":"1650380520.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/kms/latest/developerguide/concepts.html\n“\nAWS KMS is replacing the term customer master key (CMK) with AWS KMS key\n…\nYou create KMS keys in AWS KMS.\n“","upvote_count":"2","comment_id":"588246","poster":"Alexey79"},{"content":"D is correct. as per ar2000","timestamp":"1646487900.0","upvote_count":"2","comment_id":"561444","poster":"Ni_yot"},{"content":"D https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html","timestamp":"1634765580.0","comment_id":"321549","upvote_count":"2","poster":"ExtHo"},{"content":"CMKs are created in AWS KMS","poster":"ar2000","comment_id":"311217","upvote_count":"1","timestamp":"1633742880.0"}],"exam_id":32,"answer_ET":"D","timestamp":"2021-03-15 08:18:00","answer_images":[],"question_id":335,"answer":"D","topic":"1","question_text":"Which of the following is true of Amazon EBS encryption keys?","choices":{"D":"Amazon EBS encryption uses the AWS Key Management Service (AWS KMS) master key to create a Customer Master Key (CMK).","A":"Amazon EBS encryption uses the Customer Master Key (CMK) to create an AWS Key Management Service (AWS KMS) master key.","B":"Amazon EBS encryption uses the EBS Magnetic key to create an AWS Key Management Service (AWS KMS) master key.","C":"Amazon EBS encryption uses the EBS Magnetic key to create a Customer Master Key (CMK)."},"answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/47147-exam-aws-certified-solutions-architect-professional-topic-1/"}],"exam":{"id":32,"isMCOnly":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Professional","isBeta":false,"numberOfQuestions":1019,"isImplemented":true,"provider":"Amazon"},"currentPage":67},"__N_SSP":true}