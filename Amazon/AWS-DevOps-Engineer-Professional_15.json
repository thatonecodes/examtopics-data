{"pageProps":{"questions":[{"id":"L571IgQts0yKgeIi7iO7","answer_ET":"A","question_images":[],"timestamp":"2023-01-15 14:52:00","exam_id":35,"answer_images":[],"choices":{"A":"Create a log group in Amazon CloudWatch Logs. Configure the VPC flow log to capture accepted traffic and to send the data to the log group. Create an Amazon CloudWatch metric filter for IP addresses on the deny list. Create a CloudWatch alarm with the metric filter as input. Set the period to 5 minutes and the datapoints to alarm to 1. Use an Amazon Simple Notification Service (Amazon SNS) topic to send alarm notices to the security team.","B":"Create an Amazon S3 bucket for log files. Configure the VPC flow log to capture all traffic and to send the data to the S3 bucket. Configure Amazon Athena to return all log files in the S3 bucket for IP addresses on the deny list. Configure Amazon QuickSight to accept data from Athena and to publish the data as a dashboard that the security team can access. Create a threshold alert of 1 for successful access. Configure the alert to automatically notify the security team as frequently as possible when the alert threshold is met.","D":"Create a log group in Amazon CloudWatch Logs. Create an Amazon S3 bucket to hold query results. Configure the VPC flow log to capture all traffic and to send the data to the log group. Deploy an Amazon Athena CloudWatch connector in AWS Lambda. Connect the connector to the log group. Configure Athena to periodically query for all accepted traffic from the IP addresses on the deny list and to store the results in the S3 bucket. Configure an S3 event notification to automatically notify the security team through an Amazon Simple Notification Service (Amazon SNS) topic when new objects are added to the S3 bucket.","C":"Create an Amazon S3 bucket for log files. Configure the VPC flow log to capture accepted traffic and to send the data to the S3 bucket. Configure an Amazon OpenSearch Service duster and domain for the log files. Create an AWS Lambda function to retrieve the logs from the S3 bucket, format the logs, and load the logs into the OpenSearch Service cluster. Schedule the Lambda function to run every 5 minutes. Configure an alert and condition in OpenSearch Service to send alerts to the security team through an Amazon Simple Notification Service (Amazon SNS) topic when access from the IP addresses on the deny list is detected."},"answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/95430-exam-aws-devops-engineer-professional-topic-1-question-162/","answers_community":["A (86%)","14%"],"question_text":"A company has deployed an application in a production VPC in a single AWS account. The application is popular and is experiencing heavy usage. The company's security team wants to add additional security, such as AWS WAF, to the application deployment. However, the application's product manager is concerned about cost and does not want to approve the change unless the security team can prove that additional security is necessary.\n\nThe security team believes that some of the application's demand might come from users that have IP addresses that are on a deny list. The security team provides the deny list to a DevOps engineer. If any of the IP addresses on the deny list access the application, the security team wants to receive automated notification in near real time so that the security team can document that the application needs additional security. The DevOps engineer creates a VPC flow log for the production VPC.\n\nWhich set of additional steps should the DevOps engineer take to meet these requirements MOST cost-effectively?","topic":"1","isMC":true,"answer_description":"","question_id":71,"unix_timestamp":1673790720,"discussion":[{"upvote_count":"1","content":"A. All other alternatives are not cost-efficient, which is the most important factor here.","poster":"Dgix","timestamp":"1697820960.0","comment_id":"1048959"},{"poster":"BlissfulCheetah","upvote_count":"1","timestamp":"1692803520.0","comment_id":"988426","content":"Selected Answer: B\nAs much as keeping costs low is a priority, near real time notifications is also important. \n\nB seems to get the balance. A, C and D talk about \"5 minutes\" or periodic checks (far from real time)"},{"comment_id":"849409","poster":"asfsdfsdf","timestamp":"1679669520.0","content":"Selected Answer: A\nB - wrong - no need to capture all logs only incoming also no need to use quicksight\nC - wrong - no need to use openseach cluster - very expensive \nD - no need to capture all traffic + expensive why to use lambda to scan log groups if we can use it on a bucket?\nA - the only correct answer incoming traffic will be will be captured to a log group, metric filter will be set and an alarm will be triggered based on it + SNS.","upvote_count":"2"},{"timestamp":"1678035300.0","upvote_count":"1","content":"Selected Answer: A\nA - Simple, near real time (5 mins) and cheapest of all 4 options","comment_id":"830112","poster":"bgc1"},{"content":"Selected Answer: B\nA and C are eliminated, because \"5 minutes\" are not near real time.\nBetween B and D, B is cheaper, because D configures Anthena to periodically query.","comment_id":"807201","timestamp":"1676277540.0","upvote_count":"1","poster":"Piccaso"},{"timestamp":"1674927120.0","upvote_count":"3","comment_id":"790863","poster":"Bulti","content":"A is the right answer."},{"comment_id":"783783","timestamp":"1674339780.0","poster":"Christina666","content":"Selected Answer: A\nmost cost-effectively, so I choose A","upvote_count":"3"},{"upvote_count":"2","comment_id":"783146","content":"Selected Answer: A\nA for me","poster":"saeidp","timestamp":"1674294360.0"},{"upvote_count":"2","comment_id":"779291","timestamp":"1673985180.0","content":"Selected Answer: A\nA sure","poster":"Dimidrol"},{"poster":"Oleg_gol","timestamp":"1673790720.0","content":"Selected Answer: A\ni think A","upvote_count":"2","comment_id":"776632"}]},{"id":"tplnDgOEhtzqbdpyJKc8","question_images":[],"exam_id":35,"answer_images":[],"discussion":[{"poster":"ParagSanyashiv","comment_id":"891279","timestamp":"1683453120.0","content":"Selected Answer: B\nB is more suitable","upvote_count":"1"},{"comment_id":"807207","upvote_count":"1","poster":"Piccaso","timestamp":"1676278140.0","content":"Selected Answer: B\nB, obviously, https://docs.aws.amazon.com/codecommit/latest/userguide/how-to-amazon-codeguru-reviewer.html\nNo idea why C is suggested as \"correct answer\"."},{"content":"Selected Answer: B\nB is correct","poster":"Bulti","timestamp":"1674927720.0","comment_id":"790874","upvote_count":"1"},{"comment_id":"783788","upvote_count":"1","poster":"saeidp","timestamp":"1674340080.0","content":"Selected Answer: B\nB for me"},{"poster":"Oleg_gol","comment_id":"776610","upvote_count":"2","content":"Selected Answer: B\nB- https://aws.amazon.com/ru/blogs/aws/codeguru-reviewer-secrets-detector-identify-hardcoded-secrets/","timestamp":"1673789880.0"}],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/95426-exam-aws-devops-engineer-professional-topic-1-question-163/","answer_description":"","question_text":"A company has developed a serverless web application that is hosted on AWS. The application consists of Amazon S3. Amazon API Gateway, several AWS Lambda functions, and an Amazon RDS for MySQL database. The company is using AWS CodeCommit to store the source code. The source code is a combination of AWS Serverless Application Model (AWS SAM) templates and Python code.\n\nA security audit and penetration test reveal that user names and passwords for authentication to the database are hardcoded within CodeCommit repositories. A DevOps engineer must implement a solution to automatically detect and prevent hardcoded secrets.\n\nWhat is the MOST secure solution that meets these requirements?","timestamp":"2023-01-15 14:38:00","unix_timestamp":1673789880,"answer":"B","isMC":true,"answers_community":["B (100%)"],"choices":{"C":"Enable Amazon CodeGuru Profiler. Decorate the handler function with @with lambda profiler(). Manually review the recommendation report. Choose the option to protect the secret. Update the SAM templates and the Python code to pull the secret from AWS Secrets Manager.","B":"Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Manually check the code review for any recommendations. Choose the option to protect the secret. Update the SAM templates and the Python code to pull the secret from AWS Secrets Manager.","A":"Enable Amazon CodeGuru Profiler. Decorate the handler function with @with_lambda_profiler(). Manually review the recommendation report. Write the secret to AWS Systems Manager Parameter Store as a secure string. Update the SAM templates and the Python code to pull the secret from Parameter Store.","D":"Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Manually check the code review for any recommendations. Write the secret to AWS Systems Manager Parameter Store as a string. Update the SAM templates and the Python code to pull the secret from Parameter Store."},"question_id":72,"answer_ET":"B"},{"id":"oSOiaD42lrWOHioLO7Fx","isMC":true,"choices":{"B":"Create a target tracking auto scaling policy for the Redis cluster's ElastiCachePrimaryEngineCPUUtilization metric. Configure the auto scaling policy to increase and decrease shards to the Redis cluster. Update the recommendation applications to use the cluster's read replica endpoint to access Redis.","A":"Create a target tracking auto scaling policy for the Redis cluster's ElastiCachePrimaryEngineCPUUtilization metric. Configure the auto scaling policy to increase and decrease shards to the Redis cluster. Update the recommendation applications to use the clusters configuration endpoint to access Redis.","C":"Create a scheduled auto scaling policy for the Redis cluster's ElastiCachePrimaryEngineCPUUtilization metric. Configure the auto scaling policy to add read replicas to the Redis cluster. Update the recommendation applications to use the clusters configuration endpoint to access Redis.","D":"Create a scheduled auto scaling policy for the Redis cluster's ElastiCachePrimaryEngineCPUUtilization metric. Configure the auto scaling policy to add read replicas to the Redis cluster. Update the recommendation applications to use the database's read replica endpoint instead of Redis."},"question_id":73,"discussion":[{"timestamp":"1673993280.0","upvote_count":"5","comment_id":"779365","poster":"Dimidrol","content":"Selected Answer: B\nI think between A and B. Choose B because no need to write.https://aws.amazon.com/ru/about-aws/whats-new/2019/06/amazon-elasticache-launches-reader-endpoint-for-redis/"},{"timestamp":"1720636680.0","content":"A - ElastiCache cluster with configuration endpoint ensures writes go to the primary and reads go to the replica shards. \n\nThe cache needs to be written to as well, and read too","poster":"auxwww","upvote_count":"1","comment_id":"1245682"},{"upvote_count":"1","content":"A. \n\nRedis clusters do not support read replicas, which are mentioned in all other options.","timestamp":"1697821320.0","comment_id":"1048962","poster":"Dgix"},{"upvote_count":"1","comment_id":"830300","timestamp":"1678048320.0","poster":"harrura","content":"what is this crap? robot answers are different from the user poll. this sucks. what is the correct answer damn it!!"},{"poster":"bgc1","upvote_count":"2","content":"Selected Answer: A\nIts A based on this - https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html\nRedis (cluster mode enabled) clusters, use the cluster's Configuration Endpoint for all operations that support cluster mode enabled commands.","timestamp":"1678036440.0","comment_id":"830123"},{"comment_id":"814494","poster":"Piccaso","content":"Selected Answer: B\nNo idea why D is suggested by this web. \nAre the peak periods come regularly every day ?","timestamp":"1676837580.0","upvote_count":"1"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html","comment_id":"813379","timestamp":"1676744460.0","poster":"LoveToronto","upvote_count":"2"},{"comment_id":"807231","upvote_count":"2","poster":"Piccaso","timestamp":"1676279640.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html"},{"content":"Selected Answer: D\nA & B - wrong - cluster mode is turned-off - it means that there is only one shard (one primary and up to 5 secondary nodes), it can not be changed - you can not increase/decrease shards\nC - wrong - configuration endpoint is for cluster enabled Redis\nD - correct - the recommendation app should use read replica endpoint","timestamp":"1675507620.0","comments":[{"poster":"USalo","content":"regarding cluster mode, ready attentively:\nA DevOps engineer already has created a new ElastiCache for Redis cluster with cluster mode enabled.","upvote_count":"1","timestamp":"1675695120.0","comment_id":"799863"}],"poster":"DerekKey","upvote_count":"3","comment_id":"797838"},{"comment_id":"791608","comments":[{"poster":"USalo","upvote_count":"4","comment_id":"792730","content":"In the same link:\n\"Reader endpoints work with ElastiCache for Redis clusters with cluster-mode disabled.\" But it the question it was clearly mentioned that new Redis cluster was created with cluster mode ENABLED.\nAlso please read another URL:\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html\n\nRedis (cluster mode disabled) clusters, use the Primary Endpoint for all write operations. Use the Reader Endpoint to evenly split incoming connections to the endpoint between all read replicas. \n\nRedis (cluster mode enabled) clusters, use the cluster's Configuration Endpoint for all operations that support cluster mode enabled commands. \n\nThe answer should be \"A\"","timestamp":"1675081680.0"},{"poster":"dailydoseofDevops","comment_id":"1085376","timestamp":"1701451920.0","content":"Cluster mode is turned off thus disabled, as a result the Read Replica Endpoint is correct.\n\nStandalone Node \no One endpoint for read and write operations.\nCluster Mode Disabled Cluster \no Primary Endpoint – for all write operations. \no Reader Endpoint – Split read operations across all read replicas evenly.\no Node Endpoint – for read operations.\nCluster Mode Enabled Cluster \no Configuration Endpoint –for all read/write operations that support Cluster Mode Enabled commands. (way to connect to cluster)\no Node Endpoint –for read operations.","upvote_count":"1"}],"content":"Selected Answer: B\nI think the answer is B from link: https://aws.amazon.com/ru/about-aws/whats-new/2019/06/amazon-elasticache-launches-reader-endpoint-for-redis/. \"You can now use a single reader endpoint to connect to your Redis read replicas\"","upvote_count":"3","poster":"Zek","timestamp":"1674994020.0"},{"poster":"Bulti","timestamp":"1674929520.0","content":"Selected Answer: A\nA is the right answer. use Cluster configuration endpoint and when target tracking scaling policy is used with a predefined metric of ElastiCachePrimaryEngineCPUUtilization it scale out the shards and not the replicas.","upvote_count":"3","comment_id":"790917"},{"timestamp":"1674375660.0","poster":"saeidp","comment_id":"784074","content":"Selected Answer: A\nA for me\ncluster mode is enabled.\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html\nanswere B is good for cluster mode disabled","comments":[{"content":"By the way cluster mode disabled only uses one shard","comment_id":"792076","poster":"saeidp","upvote_count":"1","timestamp":"1675027500.0"}],"upvote_count":"3"},{"comment_id":"783789","content":"Selected Answer: B\nread replicas endpoint for traffic","upvote_count":"4","timestamp":"1674340260.0","poster":"Christina666"},{"comment_id":"780889","timestamp":"1674116460.0","upvote_count":"2","content":"Selected Answer: A\nI agree the answer is either A or B but I don't see \"cluster's read replica\" in the question. So, I select A","poster":"devops7"}],"answer_ET":"A","timestamp":"2023-01-17 23:08:00","answers_community":["A (47%)","B (43%)","10%"],"unix_timestamp":1673993280,"answer":"A","topic":"1","question_images":[],"answer_description":"","exam_id":35,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/95748-exam-aws-devops-engineer-professional-topic-1-question-164/","question_text":"A company has an application that monitors user activity on the company's website and mobile apps. The application uses Amazon ElastiCache for Redis as a write-through cache and uses an Amazon RDS for PostgreSQL database for longer storage. When the application receives a request to record a user's action, the application writes to the Redis cluster and the database at the same time. Internal recommendation applications consume the data to produce content recommendations for each user.\n\nDuring peak periods, the recommendation applications cannot generate recommendations for users because of stale and missing data. The Redis cache is configured with cluster mode turned off, and the database is configured with a single read replica.\n\nThe company wants to ensure that the recommendation applications can generate content recommendations during peak periods. A DevOps engineer already has created a new ElastiCache for Redis cluster with cluster mode enabled.\n\nWhat should the DevOps engineer do next to meet the company's requirements?"},{"id":"arXgwIJj7NcAnFWQnZzK","discussion":[{"comment_id":"776572","poster":"Oleg_gol","content":"Selected Answer: C\nagree C\nhttps://aws.amazon.com/ru/blogs/database/dynamodb-streams-use-cases-and-design-patterns/","timestamp":"1673788320.0","upvote_count":"6"},{"comment_id":"1245686","content":"Selected Answer: A\nA - if order of delivery is not important. EventBus can archive events as well for replay\nC - Incorrect, You might as well enable Kinesis Streams On the Table instead. Sounds like an unnecessary engineering effort and twice the cost to have two streams - DDB Change Stream + Kinesis Data Stream","timestamp":"1720637340.0","upvote_count":"1","poster":"auxwww"},{"upvote_count":"1","poster":"Dgix","content":"A.\n\nKinesis is not an option here.","timestamp":"1697821440.0","comment_id":"1048963"},{"content":"Selected Answer: C\nhttps://aws.amazon.com/ru/blogs/database/dynamodb-streams-use-cases-and-design-patterns/","timestamp":"1692385380.0","comment_id":"984739","poster":"n_d1","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nB - wrong - SQS has one tiem message delivery, once read by a customer it will not be available anymore","timestamp":"1675508520.0","poster":"DerekKey","comments":[{"poster":"mrbig00","upvote_count":"1","comment_id":"810558","timestamp":"1676544420.0","content":"Wrong. The messages are still available after reading them (they do have a visibility timeout, though). But in order to disappear from the queue, they need to be deleted.\n\nAltogether, SQS is not the answer to this question."}],"comment_id":"797850"},{"upvote_count":"1","comment_id":"790940","timestamp":"1674931080.0","content":"Selected Answer: C\nC is a better option than A because it's more operationality efficient. Option B is wrong because EventBrige Bus doesn't have a persistent store whereas KDS does. So there won't be a loss of data.","poster":"Bulti"},{"timestamp":"1674377820.0","upvote_count":"1","comments":[{"comments":[{"comment_id":"821201","content":"because of this SQS is wrong in this scenario\nC is the correct answere","poster":"saeidp","timestamp":"1677301380.0","upvote_count":"2"}],"comment_id":"784103","upvote_count":"1","timestamp":"1674378540.0","content":"Only drawback with B is if an aplication process the event data then it will be deleted from the Queue","poster":"saeidp"}],"poster":"saeidp","content":"Selected Answer: B\nYou don't need lambda to send data from streams to kinesis stream. It can be done automatically\nI go with B","comment_id":"784095"},{"upvote_count":"2","poster":"Dimidrol","content":"Selected Answer: C\nC for me","timestamp":"1673986020.0","comment_id":"779301"}],"url":"https://www.examtopics.com/discussions/amazon/view/95414-exam-aws-devops-engineer-professional-topic-1-question-165/","unix_timestamp":1673788320,"question_images":[],"topic":"1","question_id":74,"choices":{"D":"Configure the DynamoDB table to use on-demand capacity mode. Increase the memory of the Lambda functions. Configure the Lambda functions to use provisioned concurrency.","B":"Create an Amazon Simple Queue Service (Amazon SOS) queue. Create a new Lambda function that uses the existing DynamoDB stream as an event source. Configure the new Lambda function to post those events to the SOS queue. Update the original Lambda functions to react to entries in the SOS queue. As other applications need the events, configure the applications to use the SOS queue as an event source.","A":"Create an Amazon EventBridge event bus. Create a new Lambda function that uses the existing DynamoDB stream as an event source. Configure the new Lambda function to post those events to the event bus. Update the original Lambda functions to react to events in the event bus. As other applications need the events, configure the applications to use the event bus as an event source.","C":"Create an Amazon Kinesis data stream. Create a new Lambda function that uses the existing DynamoDB stream as an event source. Configure the new Lambda function to post those events to the Kinesis data stream. Update the original Lambda functions to subscribe to records in the Kinesis data stream. As other applications need the events, configure the applications to use the Kinesis data stream as an event source."},"answer_images":[],"timestamp":"2023-01-15 14:12:00","question_text":"A company stores purchase history in an Amazon DynamoDB table. The company needs other workloads that run on AWS to react to data changes in the table.\n\nThe company has enabled a DynamoDB stream on the table. Three existing AWS Lambda functions have an event source mapping configured for the DynamoDB stream. The company's application developers plan to add other applications that will need to react to changes in the table. A DevOps engineer must design an architecture that will give the additional consumers this functionality.\n\nWhich solution will meet these requirements in the MOST operationally efficient way?","answers_community":["C (85%)","Other"],"isMC":true,"exam_id":35,"answer":"C","answer_ET":"C","answer_description":""},{"id":"dSAokuaLlcMVuhiwDnwg","choices":{"D":"Configure AWS Support integration with AWS CloudTrail. Create a CloudTrail lookup event to invoke an AWS Lambda function to pass EC2 maintenance notifications to Amazon Simple Notification Service (Amazon SNS). Configure Amazon SNS to target the Slack channel and the shared inbox.","A":"Integrate AWS Trusted Advisor with AWS Config. Configure a custom AWS Config rule to invoke an AWS Lambda function to publish notifications to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe a Slack channel endpoint and the shared inbox to the topic.","C":"Create an AWS Lambda function that sends EC2 maintenance notifications to the Slack channel and the shared inbox. Monitor EC2 health events by using Amazon CloudWatch metrics. Configure a CloudWatch alarm that invokes the Lambda function when a maintenance notification is received.","B":"Use Amazon EventBridge to monitor for AWS Health events. Configure the maintenance events to target an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe an AWS Lambda function to the SNS topic to send notifications to the Slack channel and the shared inbox."},"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/95413-exam-aws-devops-engineer-professional-topic-1-question-166/","question_id":75,"exam_id":35,"isMC":true,"timestamp":"2023-01-15 13:48:00","answers_community":["B (100%)"],"question_text":"A media company has several thousand Amazon EC2 instances in an AWS account. The company is using Slack and a shared email inbox for team communications and important updates. A DevOps engineer needs to send all AWS-scheduled EC2 maintenance notifications to the Slack channel and the shared inbox. The solution must include the instances' Name and Owner tags.\n\nWhich solution will meet these requirements?","question_images":[],"topic":"1","discussion":[{"upvote_count":"6","poster":"Oleg_gol","content":"Selected Answer: B\nB\nhttps://docs.aws.amazon.com/health/latest/ug/cloudwatch-events-health.html","timestamp":"1673786880.0","comment_id":"776552"},{"poster":"Piccaso","content":"Selected Answer: B\nI think everyone is agree with B.","upvote_count":"1","comment_id":"807242","timestamp":"1676281020.0"},{"upvote_count":"1","content":"Selected Answer: B\nB for me","comment_id":"784733","timestamp":"1674425520.0","poster":"saeidp"}],"answer_images":[],"unix_timestamp":1673786880,"answer_description":"","answer_ET":"B"}],"exam":{"name":"AWS DevOps Engineer Professional","lastUpdated":"11 Apr 2025","id":35,"isBeta":false,"isImplemented":true,"numberOfQuestions":208,"provider":"Amazon","isMCOnly":false},"currentPage":15},"__N_SSP":true}