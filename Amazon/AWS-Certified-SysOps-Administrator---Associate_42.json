{"pageProps":{"questions":[{"id":"v6HjhDnFOlAHGUfE6GqO","url":"https://www.examtopics.com/discussions/amazon/view/108991-exam-aws-certified-sysops-administrator-associate-topic-1/","answer_images":[],"answer_ET":"D","discussion":[{"comment_id":"1110459","upvote_count":"3","content":"Selected Answer: D\nWhile SSE-S3 is convenient, it doesn't allow the company to have control over key management or maintain a detailed audit trail for key usage. AWS KMS provides detailed audit logs through AWS CloudTrail, which allows you to monitor and log all API calls related to key usage","poster":"nharaz","timestamp":"1719736500.0"},{"upvote_count":"1","content":"Answer D: with SSE-KMS, you have more control over your keys than you do with SSE-S3. For example, you can follow the keys in AWS Cloud Trail.","poster":"Learning4life","timestamp":"1717075320.0","comment_id":"1084490"},{"poster":"kondratyevmn","timestamp":"1699733580.0","upvote_count":"3","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#auditing_key_use","comment_id":"895282","comments":[{"timestamp":"1708334160.0","upvote_count":"3","content":"why not B : SSE-S3 do not provide detailed audit.","poster":"jipark","comment_id":"985031"}]}],"question_images":[],"unix_timestamp":1683828780,"topic":"1","isMC":true,"answers_community":["D (100%)"],"timestamp":"2023-05-11 20:13:00","choices":{"A":"Use client-side encryption with client-provided keys. Upload the encrypted user data to Amazon S3.","C":"Use server-side encryption with customer-provided encryption keys (SSE-C) to encrypt the user data on Amazon S3.","B":"Use server-side encryption with S3 managed encryption keys (SSE-S3) to encrypt the user data on Amazon S3.","D":"Use server-side encryption with AWS KMS managed encryption keys (SSE-KMS) to encrypt the user data on Amazon S3."},"exam_id":34,"question_id":206,"answer_description":"","question_text":"A company is building an interactive application for personal finance. The application stores financial data in Amazon S3, and the data must be encrypted. The company does not want to provide its own encryption keys. However, the company wants to maintain an audit trail that shows when an encryption key was used and who used the key.\n\nWhich solution will meet these requirements?","answer":"D"},{"id":"1HIbRGgyTxKUWYsyMUAo","topic":"1","isMC":true,"answers_community":["AC (100%)"],"discussion":[{"content":"Options B, D, and E are not relevant to the CloudFormation stack creation failure for an S3 bucket. Option B is related to CloudFormation StackSets, not individual stacks. Option D and E are related to specific S3 bucket actions (list and put) and are not directly related to the stack creation process.\n\nTherefore, the correct answers are A and C.","comment_id":"960917","timestamp":"1706058840.0","poster":"trvtrinh","upvote_count":"10"},{"content":"Selected Answer: AC\nThe failure of the CloudFormation stack creation can be due to several factors related to IAM policies and S3 bucket permissions. Let's go through the options:\n\nA. The user’s IAM policy does not allow the cloudformation:CreateStack action.\n\nThis could definitely cause the stack creation to fail, as the user needs permission to create CloudFormation stacks.\nB. The user’s IAM policy does not allow the cloudformation:CreateStackSet action.\n\nThis action is related to stack sets, not individual stacks. Since the question is about stack creation, this is less likely to be the cause of the failure.\nC. The user’s IAM policy does not allow the s3:CreateBucket action.\n\nThis is a crucial permission because the CloudFormation template is creating an S3 bucket. If the user doesn't have permission to create S3 buckets, the stack creation will fail.","upvote_count":"2","poster":"joshnort","comment_id":"1188896","timestamp":"1727987760.0","comments":[{"upvote_count":"1","content":"D. The user’s IAM policy explicitly denies the s3:ListBucket action.\n\nWhile this could cause issues with certain operations on the bucket, it's not directly related to the creation of the bucket itself during the stack creation process.\nE. The user’s IAM policy explicitly denies the s3:PutObject action.\n\nThis is related to adding objects to the bucket, not creating the bucket itself during stack creation.\nSo, the two factors that could cause the failure of the stack creation are:\nA. The user’s IAM policy does not allow the cloudformation:CreateStack action.\nC. The user’s IAM policy does not allow the s3:CreateBucket action.","timestamp":"1727987820.0","comment_id":"1188898","poster":"joshnort"}]},{"timestamp":"1719558660.0","upvote_count":"2","content":"Selected Answer: AC\nOptions B, D, and E are less likely to be directly related to the failure of stack creation:\n\n B. The user’s IAM policy does not allow the cloudformation:CreateStackSet action.\n Stack sets are generally used for deploying stacks across multiple accounts and regions, and it might not be directly related to a stack creation failure in a single account.\n\n D. The user’s IAM policy explicitly denies the s3:ListBucket action.\n While s3:ListBucket is needed for some S3 operations, it's not necessarily required for creating an S3 bucket.\n\n E. The user’s IAM policy explicitly denies the s3:PutObject action.\n Denying s3:PutObject would prevent the user from uploading objects to an existing S3 bucket. It's not a direct factor for creating a new S3 bucket.","poster":"r2c3po","comment_id":"1107589"}],"timestamp":"2023-07-24 01:14:00","url":"https://www.examtopics.com/discussions/amazon/view/116239-exam-aws-certified-sysops-administrator-associate-topic-1/","question_id":207,"question_text":"A company has an AWS CloudFormation template that creates an Amazon S3 bucket. A user authenticates to the corporate AWS account with their Active Directory credentials and attempts to deploy the CloudFormation template. However, the stack creation fails.\n\nWhich factors could cause this failure? (Choose two.)","answer_ET":"AC","unix_timestamp":1690154040,"answer_description":"","question_images":[],"exam_id":34,"choices":{"D":"The user’s IAM policy explicitly denies the s3:ListBucket action.","E":"The user’s IAM policy explicitly denies the s3:PutObject action.","C":"The user’s IAM policy does not allow the s3:CreateBucket action.","A":"The user’s IAM policy does not allow the cloudformation:CreateStack action.","B":"The user’s IAM policy does not allow the cloudformation:CreateStackSet action."},"answer_images":[],"answer":"AC"},{"id":"eCyMOHALQ6s8pVCKVUwb","topic":"1","answers_community":["AC (100%)"],"question_id":208,"answer_images":[],"question_images":[],"question_text":"An Amazon RDS for PostgreSQL DB cluster has automated backups turned on with a 7-day retention period. A SysOps administrator needs to create a new RDS DB cluster by using data that is no more than 24 hours old from the original DB cluster.\n\nWhich solutions will meet these requirements with the LEAST operational overhead? (Choose two.)","answer":"AC","answer_description":"","discussion":[{"poster":"Christina666","content":"Selected Answer: AC\nOption A - Automated Snapshot: Since automated backups are enabled with a 7-day retention period, you can easily identify the most recent automated snapshot taken within the last 24 hours. You can use this snapshot to restore a new RDS DB cluster. This process is straightforward and does not require much operational overhead.\n\nOption C - Read Replica and Promotion: By creating a read replica in the original RDS DB cluster, you ensure that the replica stays up-to-date with the source database in near real-time. To meet the requirement of having data no more than 24 hours old, you can promote the read replica to a standalone DB cluster within the desired time frame. This option leverages the replication mechanism and is also relatively simple to implement.","comment_id":"964171","timestamp":"1706310900.0","upvote_count":"6"},{"content":"Selected Answer: AC\nThere are actually CLI commands defined to do both \"A\" and \"C\". I believe the DB Migration Service is used to migrate and reformat external databases to AWS. I see no references to it being used to copy/migrate data within AWS. Anyway, here are the CLI examples I mentioned which I found online:\n# Promotes specified read replica to become a standalone DB cluster.\naws rds promote-read-replica-db-cluster --db-cluster-identifier mydbcluster-1\n\n# Creates a new DB cluster by resoring a DB cluster snapshot named test-instance-snapshot.\naws rds restore-db-cluster-from-snapshot --db-cluster-identifier newdbcluster --snapshot-identifier test-instance-snapshot --engine aurora-postgresql --engine-version 10.7","timestamp":"1698960120.0","poster":"Gomer","comment_id":"887828","upvote_count":"5"},{"content":"Selected Answer: AC\nOptions B, D, and E involve additional steps and may have more operational overhead:\n\n B. Back up the database to Amazon S3 by using native database backup tools. Create a new RDS DB cluster and restore the data to the new RDS DB cluster.\n This involves manual steps and might have more operational overhead.\n\n D. Create a new RDS DB cluster. Use AWS Database Migration Service (AWS DMS) to migrate data from the current RDS DB cluster to the newly created RDS DB cluster.\n AWS DMS is a powerful tool but may introduce more complexity, especially if the goal is a relatively straightforward copy of data within a short time frame.\n\n E. Use the pg_dump utility to export data from the original RDS DB cluster to an Amazon EC2 instance. Create a new RDS DB cluster. Use the pg_restore utility to import the data from the EC2 instance to the new RDS DB cluster.\n This involves manual export/import steps and may not be as efficient as using automated snapshot restoration or read replica promotion.","comment_id":"1107611","upvote_count":"2","poster":"r2c3po","timestamp":"1719558960.0"},{"poster":"jipark","upvote_count":"2","content":"Selected Answer: AC\nbackup, migration require \"Read\" Transaction - cause \"Operational Overhead\".","timestamp":"1708334880.0","comment_id":"985041"},{"upvote_count":"2","timestamp":"1704292140.0","content":"Selected Answer: AC\nCreate new from backup or read replica","poster":"guau","comment_id":"941826"},{"content":"Selected Answer: AC\nA - https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html\n\nC - You can promote a read replica into a standalone DB instance. When you promote a read replica, the DB instance is rebooted before it becomes available.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html","upvote_count":"3","timestamp":"1699771860.0","poster":"kondratyevmn","comment_id":"895642"},{"timestamp":"1699112040.0","comment_id":"889379","upvote_count":"3","poster":"tts1234","content":"Selected Answer: AC\nA C looks good"}],"url":"https://www.examtopics.com/discussions/amazon/view/108319-exam-aws-certified-sysops-administrator-associate-topic-1/","timestamp":"2023-05-02 21:22:00","unix_timestamp":1683055320,"answer_ET":"AC","isMC":true,"exam_id":34,"choices":{"A":"Identify the most recent automated snapshot. Restore the snapshot to a new RDS DB cluster.","E":"Use the pg_dump utility to export data from the original RDS DB cluster to an Amazon EC2 instance. Create a new RDS DB cluster. Use the pg_restore utility to import the data from the EC2 instance to the new RDS DB cluster.","C":"Create a read replica instance in the original RDS DB cluster. Promote the read replica to a standalone DB cluster.","B":"Back up the database to Amazon S3 by using native database backup tools. Create a new RDS DB cluster and restore the data to the new RDS DB cluster.","D":"Create a new RDS DB cluster. Use AWS Database Migration Service (AWS DMS) to migrate data from the current RDS DB cluster to the newly created RDS DB cluster."}},{"id":"0pK8iLaggQkKJrhJZgXa","topic":"1","isMC":true,"answers_community":["BD (100%)"],"timestamp":"2023-05-02 22:19:00","discussion":[{"content":"Selected Answer: BD\nB. The DNS is still pointing to the ALB instead of the CloudFront distribution.\nExplanation: If the DNS is still directing user traffic directly to the ALB instead of the CloudFront distribution, then the requests will not be served through CloudFront, and there won't be any reduction in the web server load.\n\nD. The default, minimum, and maximum Time to Live (TTL) are set to 0 seconds on the CloudFront distribution.\nExplanation: If the Time to Live (TTL) settings are set to 0 seconds, it means that CloudFront will not cache any responses from the ALB and will forward each request directly to the ALB. This will result in the ALB still serving all the requests, and there won't be any offloading of the web server load.","upvote_count":"6","comments":[{"timestamp":"1722028920.0","comment_id":"964177","poster":"Christina666","upvote_count":"1","content":"C. The ALB security group is not permitting inbound traffic from CloudFront.\nExplanation: If inbound traffic from CloudFront is not allowed in the ALB security group, CloudFront won't be able to access the ALB to fetch content. However, this issue would lead to an authentication or connectivity problem, and CloudFront would not be able to serve any requests, rather than selectively not reducing the load on the web servers.\n\nE. The target groups associated with the ALB are configured for sticky sessions.\nExplanation: Sticky sessions make the ALB route user requests from the same client to the same target during a session. This might affect the load distribution among the targets but should not prevent CloudFront from serving requests or offloading the server load."}],"timestamp":"1722028920.0","poster":"Christina666","comment_id":"964176"},{"upvote_count":"1","poster":"jipark","timestamp":"1724052720.0","content":"Selected Answer: BD\nwhy not E : sticky option cannot reduce but not stop all incoming traffics.\n\"requests are still being served by the ALB\"","comment_id":"985043"},{"timestamp":"1721523180.0","poster":"eboehm","comment_id":"957968","content":"Selected Answer: BD\nBD, OAI does not apply to alb, instead you would use custom headers to restrict access\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/restrict-access-to-load-balancer.html","upvote_count":"1"},{"upvote_count":"2","comment_id":"930551","content":"Selected Answer: BD\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesMinTTL","timestamp":"1719061920.0","poster":"noahsark"},{"timestamp":"1717016100.0","upvote_count":"1","poster":"Julio98","comment_id":"909717","content":"A and B"},{"comment_id":"887877","timestamp":"1714681140.0","upvote_count":"2","poster":"Gomer","content":"I believe \"B\" is correct. However, I can't decide between \"A\" or \"D\" because I know the OAI setting is necessary to enforce users to go through CloudFront. However, the question isn't clearly stating that. The ALB needs to clearly be configured as the Origin. The way they state the question is muddying up the distinction between \"Origin\" and \"Origin Access Identity\" which I distinguish as a setting in CloudFront.\n\nIn regards to \"D\", as I looked into it, the \"TTL\" of 0 (zero) only means the edge passes on every request to the origin to see if the object has changed. If not, then the object is not recent. This setting would still impact the origin to some degree, but not anything like if they object were not being cashed at all. Weighing that against the OAI presumably not being enabled (as in \"A\"), I see not having OAI not being enabled as far more of a problem as users can bypass CloudFront. Now I'm back trying to figure out if \"A\" is really stating that, or just trying to make a confused statement as a trick response.\n\nAppreciate more informed thoughts on this from others.","comments":[{"upvote_count":"2","poster":"Gomer","content":"I changed my mind on this. As I've better come to understand it, the OAI/OAC are only applicable to S3 as CF origin (not ALB as CF origin). \"B\" is obvious, and doesn't need much discussion as it could cause CF to be bypassed. In regards to \"D\", with TTL=0, every request for the object is passed on to the origin to see if the object has changed (or not). That is going to cause unnecessary high utilization on the web server (even if new object is rarely forwarded). As I'm understanding it in my mind, the TTL=0 may be appropriate for individual objects, but not as a general setting for the entire CloudFront distribution (all objects)","comments":[{"timestamp":"1716497340.0","content":"If you set the TTL=0 as a general setting for everything on CloudFront distribution (including objects that don't have a high rate of change), then your going to generate a lot of unnecessary traffic back to the origin and have higher web server utilization than is necessary just saying \"no, nothing has changed\" over and over. I believe if your going to use TTL=0, it should only be set in metadata for individual objects that have a high rate of change.","comment_id":"905222","poster":"Gomer","upvote_count":"2"},{"comment_id":"957966","content":"I agree with this answer OAI is used with S3 and custom HTTP headers are used for restricting ALB access to only come from CF","timestamp":"1721523120.0","upvote_count":"1","poster":"eboehm"}],"timestamp":"1716496440.0","comment_id":"905215"}]}],"question_text":"A company is managing a website with a global user base hosted on Amazon EC2 with an Application Load Balancer (ALB). To reduce the load on the web servers, a SysOps administrator configures an Amazon CloudFront distribution with the ALB as the origin. After a week of monitoring the solution, the administrator notices that requests are still being served by the ALB and there is no change in the web server load.\n\nWhat are possible causes for this problem? (Choose two.)","url":"https://www.examtopics.com/discussions/amazon/view/108324-exam-aws-certified-sysops-administrator-associate-topic-1/","answer_ET":"BD","question_id":209,"unix_timestamp":1683058740,"answer_description":"","question_images":[],"exam_id":34,"answer":"BD","answer_images":[],"choices":{"E":"The target groups associated with the ALB are configured for sticky sessions.","A":"CloudFront does not have the ALB configured as the origin access identity.","C":"The ALB security group is not permitting inbound traffic from CloudFront.","D":"The default, minimum, and maximum Time to Live (TTL) are set to 0 seconds on the CloudFront distribution.","B":"The DNS is still pointing to the ALB instead of the CloudFront distribution."}},{"id":"Sp0fnBinc19HbVuNijtt","answers_community":["CD (63%)","BC (25%)","13%"],"unix_timestamp":1683059700,"exam_id":34,"timestamp":"2023-05-02 22:35:00","answer_ET":"CD","question_images":[],"isMC":true,"answer_images":[],"discussion":[{"comment_id":"985046","timestamp":"1724053680.0","content":"Selected Answer: CD\nalias for root/sub domain point to ALB cname.\n(name for root domain not possible)","upvote_count":"1","poster":"jipark"},{"timestamp":"1722029160.0","comments":[{"comment_id":"964601","upvote_count":"2","content":"To route domain traffic to an ELB load balancer, use Amazon Route 53 to create an alias record that points to your load balancer. An alias record is a Route 53 extension to DNS. It's similar to a CNAME record, but you can create an alias record both for the root domain, such as example.com, and for subdomains, such as www.example.com. (You can create CNAME records only for subdomains.)\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-elb-load-balancer.html","poster":"[Removed]","timestamp":"1722076500.0"},{"content":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-elb-load-balancer.html","upvote_count":"1","comment_id":"964180","timestamp":"1722029280.0","poster":"Christina666"}],"upvote_count":"2","comment_id":"964179","poster":"Christina666","content":"Selected Answer: BC\nC. Configure an alias record for example.com to point to the CNAME of the ALB.\nExplanation: Amazon Route 53 supports alias records, which allow you to map your root domain (example.com) to the ALB directly without using an IP address. To do this, you would create an alias record for example.com and select the ALB's CNAME as the alias target.\n\nB. Configure an A record for www.example.com to point to the IP address of the ALB.\nExplanation: For the www subdomain (www.example.com), you typically use an A record to map it to an IP address. In this case, you would create an A record for www.example.com and set its value to the IP address of the ALB."},{"comment_id":"908224","timestamp":"1716855060.0","content":"Selected Answer: CD\nAlias to the ALB in both cases, not A record to ALB IP address.","poster":"landsamboni","upvote_count":"2"},{"upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"895805","poster":"kondratyevmn","timestamp":"1715507460.0","content":"Typo\n\nA, B - - wrong, - there is no such a thing as IP address for ALB, as it's hidden for user and you only have an ALB DNS name, therefore it's not A&B."}],"timestamp":"1715507400.0","comment_id":"895803","poster":"kondratyevmn","content":"Selected Answer: CD\n:) No correct answer here, but the clothes you can lean - C, D.\n\nC, D - wrong, - there is no such a thing as IP address for ALB, as it's hidden for user and you only have an ALB DNS name, therefore it's not A&B.\n\nE - wrong, as you can't create CNAME for apex (example.com).\n\nC, D - well, you are creating record type A, not alias, but once you create record type A, you use ALB alias to route traffic to ALB endpoint (DNS)."},{"poster":"Gomer","upvote_count":"1","content":"Selected Answer: AD\nI vote A and D because I believe you have to have an \"A\" record pointing to an IP for the domain name, and that the you just need an \"www\" alias to point to the \"A\" record so they both return same results to browser.","timestamp":"1714682100.0","comment_id":"887890","comments":[{"timestamp":"1720561680.0","poster":"[Removed]","content":"You are correct that an A record typically points to an IP address. However, in the case of an Application Load Balancer (ALB), you cannot use an A record with an IP address because the IP addresses of an ALB can change over time. Instead, you can use an alias record to point to the DNS name of the ALB. An alias record is a Route 53 extension to DNS that allows you to route traffic to selected AWS resources, such as an ALB, by using a friendly DNS name, such as example.com, instead of the resource’s IP address or DNS name.\n\nTherefore, the correct answers are CD.","upvote_count":"1","comment_id":"947568"},{"upvote_count":"1","poster":"wooyourdaddy","comments":[{"poster":"wooyourdaddy","timestamp":"1715902260.0","comment_id":"899617","content":"Look at these questions which help to understand the answer B & B: (Questions #5 and #23)","upvote_count":"1"},{"upvote_count":"1","timestamp":"1715791740.0","content":"I meant C.","comment_id":"898524","poster":"wooyourdaddy"}],"content":"I think it is B, not A. \n\nRecently I needed to point a domain apex to an Application Load Balancer created in an AWS environment. The only problem here was that the domain apex or root domain cannot point to an Application Load Balancer’s endpoint. If we talk about in terms of DNS records, we cannot add a CNAME record against the apex. We can map an IP address to the apex as an A record.\n \nSo, all we needed was a static IP address for our load balancer which we could map to our root domain and point it to the Load Balancer. The small issue was that Application Load Balancer does not have static IP addresses. So, I looked for methods to assign a static IP (elastic IP) address to the load balancer and found an AWS service named Global Accelerator which made it super-easy to assign static IP to the load balancer.\n \nRef link: https://kavishbaghel.com/how-to-point-domain-apex-to-an-application-load-balancer-88a7b82d19e9","comment_id":"898523","timestamp":"1715791680.0"}]}],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/108326-exam-aws-certified-sysops-administrator-associate-topic-1/","choices":{"A":"Configure an A record for example.com to point to the IP address of the ALB.","C":"Configure an alias record for example.com to point to the CNAME of the ALB.","B":"Configure an A record for www.example.com to point to the IP address of the ALB.","E":"Configure a CNAME record for example.com to point to the CNAME of the ALB.","D":"Configure an alias record for www.example.com to point to the Route 53 example.com record."},"answer":"CD","answer_description":"","question_id":210,"question_text":"A SysOps administrator needs to configure the Amazon Route 53 hosted zone for example.com and www.example.com to point to an Application Load Balancer (ALB).\n\nWhich combination of actions should the SysOps administrator take to meet these requirements? (Choose two.)"}],"exam":{"isImplemented":true,"isMCOnly":false,"numberOfQuestions":477,"id":34,"provider":"Amazon","lastUpdated":"11 Apr 2025","isBeta":false,"name":"AWS Certified SysOps Administrator - Associate"},"currentPage":42},"__N_SSP":true}