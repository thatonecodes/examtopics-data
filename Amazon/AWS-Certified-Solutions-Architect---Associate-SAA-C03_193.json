{"pageProps":{"questions":[{"id":"R2lpztewzLJZVEpbgJab","answer_description":"","answers_community":["A (100%)"],"unix_timestamp":1723915440,"timestamp":"2024-08-17 19:24:00","answer_ET":"A","discussion":[{"upvote_count":"6","poster":"[Removed]","content":"Selected Answer: A\nCustom Endpoints:\n\nCustom endpoints in Amazon Aurora allow you to group specific replicas together and route traffic only to those replicas. This is particularly useful when you have replicas with different compute and memory specifications and want to direct specific workloads, such as reporting queries, to those replicas.\nBy creating a custom endpoint, you can include the three specific Aurora Replicas that have the required compute and memory configurations, ensuring that your near-real-time reporting queries are automatically distributed among these replicas.","timestamp":"1723915440.0","comment_id":"1267794"},{"upvote_count":"1","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Endpoints.Custom.html\nA custom endpoint for an Aurora cluster represents a set of DB instances that you choose. When you connect to the endpoint, Aurora performs connection balancing and chooses one of the instances in the group to handle the connection. You define which instances this endpoint refers to, and you decide what purpose the endpoint serves.","comments":[{"poster":"FlyingHawk","content":"custom endpoint for an Aurora cluster represents a set of DB instances that you choose. When you connect to the endpoint, Aurora performs connection balancing and chooses one of the instances in the group to handle the connection. You define which instances this endpoint refers to, and you decide what purpose the endpoint serves.\n\nAn Aurora DB cluster has no custom endpoints until you create one. You can create up to five custom endpoints for each provisioned Aurora cluster or Aurora Serverless v2 cluster. You can't use custom endpoints for Aurora Serverless v1 clusters.\n\nThe custom endpoint provides balanced database connections based on criteria other than the read-only or read/write capability of the DB instances.","comment_id":"1346260","upvote_count":"1","timestamp":"1737761340.0"}],"timestamp":"1737761340.0","poster":"FlyingHawk","comment_id":"1346259"},{"content":"Selected Answer: A\nA - You can assign the three replicas with different compute and memory specifications to the custom endpoint, ensuring that queries are distributed only among these replicas.\nB - Expensive, cumbersome, and unnecessary. The clone has separate storage and compute resources.\nC - You can't target just the three replicas you want.\nD - The reader endpoint automatically distributes read queries across *ALL* Aurora Replicas in the cluster.","poster":"LeonSauveterre","comment_id":"1336641","upvote_count":"2","timestamp":"1736054640.0"},{"comment_id":"1320948","content":"Selected Answer: A\nThis is why I choose Option A:\n\nUsing a Custom endpoint: This allows you to specify a specific set of Aurora replicas be used for the reporting queries, enabling you to target the three replicas with different compute and memory specifications while distributing the workload across them.","comments":[{"poster":"JA2018","comment_id":"1320949","upvote_count":"1","timestamp":"1733143860.0","content":"Why the other options are not ideal:\n\n- #B. Create a three-node cluster clone and use the reader endpoint: While you can create a separate cluster, using the \"reader endpoint\" would distribute queries across all replicas in that cluster, not just the three you want to target with different specs.\n- #C. Use any of the instance endpoints for the selected three nodes: This approach would require manual connection management to each specific replica, not providing automatic load balancing across the chosen three nodes.\n- #D. Use the reader endpoint to automatically distribute the read-only workload: The standard \"reader endpoint\" distributes reads across all Aurora replicas in the cluster, not just the selected three with specific configurations."}],"upvote_count":"1","timestamp":"1733143860.0","poster":"JA2018"}],"answer":"A","answer_images":[],"choices":{"D":"Use the reader endpoint to automatically distribute the read-only workload","C":"Use any of the instance endpoints for the selected three nodes","B":"Create a three-node cluster clone and use the reader endpoint","A":"Create and use a custom endpoint for the workload"},"question_images":[],"question_text":"A company runs its production workload on an Amazon Aurora MySQL DB cluster that includes six Aurora Replicas. The company wants near-real-time reporting queries from one of its departments to be automatically distributed across three of the Aurora Replicas. Those three replicas have a different compute and memory specification from the rest of the DB cluster.\n\nWhich solution meets these requirements?","isMC":true,"exam_id":31,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/145919-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":961},{"id":"AgHTvgBGuN2Oen3MKJxy","exam_id":31,"answer":"B","question_id":962,"answer_images":[],"unix_timestamp":1723915620,"url":"https://www.examtopics.com/discussions/amazon/view/145920-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","choices":{"B":"Store the database credentials as a secret in AWS Secrets Manager. Configure Secrets Manager to automatically rotate the credentials every 30 days. Update the Lambda function to retrieve the credentials from the secret.","D":"Store the database credentials as a key in AWS Key Management Service (AWS KMS). Configure automatic rotation for the key. Update the Lambda function to retneve the credentials from the KMS key.","A":"Store the database credentials as a parameter in AWS Systems Manager Parameter Store Configure Parameter Store to automatically rotate the secrets every 30 days. Update the Lambda function to retrieve the credentials from the parameter.","C":"Store the database credentials as an encrypted Lambda environment variable. Write a custom Lambda function to rotate the credentials. Schedule the Lambda function to run every 30 days."},"isMC":true,"answer_ET":"B","answers_community":["B (100%)"],"answer_description":"","timestamp":"2024-08-17 19:27:00","question_images":[],"discussion":[{"poster":"LeonSauveterre","comment_id":"1336648","upvote_count":"2","content":"Selected Answer: B\nA - Parameter Store doesn't support automatic rotation.\nC - Don't write a custom function when you can use off-the-rack ones.\nD - AWS KMS is a service for managing encryption keys, not for managing secrets like database credentials. Also it doesn't provide direct support for managing or rotating database credentials.","timestamp":"1736055180.0"},{"timestamp":"1723944540.0","comment_id":"1267902","upvote_count":"1","content":"Selected Answer: B\nAnswer is B","poster":"aragon_saa"},{"upvote_count":"4","timestamp":"1723915620.0","comment_id":"1267795","poster":"[Removed]","content":"Selected Answer: B\nSecrets Manager:\n\nAWS Secrets Manager is specifically designed to store and manage sensitive information like database credentials. It provides built-in functionality for securely storing, retrieving, and automatically rotating credentials.\nAutomatic Rotation:\n\nSecrets Manager can be configured to automatically rotate the database credentials at regular intervals (e.g., every 30 days). This reduces operational overhead by eliminating the need for manual credential rotation or custom rotation logic.\nIntegration with Lambda:\n\nLambda functions can easily retrieve credentials stored in Secrets Manager by calling the Secrets Manager API, which simplifies the application code and enhances security."}],"question_text":"A company runs a Node js function on a server in its on-premises data center. The data center stores data in a PostgreSQL database. The company stores the credentials in a connection string in an environment variable on the server. The company wants to migrate its application to AWS and to replace the Node.js application server with AWS Lambda. The company also wants to migrate to Amazon RDS for PostgreSQL and to ensure that the database credentials are securely managed.\n\nWhich solution will meet these requirements with the LEAST operational overhead?"},{"id":"SxEu1nbiZIAGjvTUC3UF","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/144936-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company wants to replicate existing and ongoing data changes from an on-premises Oracle database to Amazon RDS for Oracle. The amount of data to replicate varies throughout each day. The company wants to use AWS Database Migration Service (AWS DMS) for data replication. The solution must allocate only the capacity that the replication instance requires.\n\nWhich solution will meet these requirements?","exam_id":31,"answer_description":"","question_id":963,"answer":"B","timestamp":"2024-08-03 11:06:00","answers_community":["B (93%)","7%"],"answer_ET":"B","answer_images":[],"discussion":[{"comment_id":"1268049","upvote_count":"8","poster":"[Removed]","timestamp":"1723983360.0","content":"Selected Answer: B\nB. Create an AWS DMS Serverless replication task to analyze and replicate the data while provisioning the required capacity.\n\nExplanation:\nAWS DMS Serverless is designed to automatically allocate and manage the necessary compute and memory resources based on the demand of the data replication workload. It scales capacity up or down according to the data replication requirements without manual intervention.\nThis approach ensures that the replication task uses only the required capacity at any given time, optimizing costs and resources, especially given that the amount of data to replicate varies throughout the day."},{"comment_id":"1260191","upvote_count":"5","content":"Selected Answer: B\nCorrect answer is B since the question need to allocate only the capacity that the replication instance requires","timestamp":"1722675960.0","poster":"JunsK1e"},{"poster":"EllenLiu","upvote_count":"1","comment_id":"1331486","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Serverless.html","timestamp":"1735120200.0"},{"poster":"pujithacg8","timestamp":"1723375500.0","upvote_count":"2","comment_id":"1264058","content":"correct answer could be \"B\""},{"comment_id":"1260204","upvote_count":"1","timestamp":"1722678060.0","poster":"komorebi","content":"Selected Answer: A\nAnswer is A"}],"unix_timestamp":1722675960,"topic":"1","choices":{"B":"Create an AWS DMS Serverless replication task to analyze and replicate the data while provisioning the required capacity.","A":"Configure the AWS DMS replication instance with a Multi-AZ deployment to provision instances across multiple Availability Zones.","C":"Use Amazon EC2 Auto Scaling to scale the size of the AWS DMS replication instance up or down based on the amount of data toreplicate.","D":"Provision AWS DMS replication capacity by using Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type to analyze and replicate the data while provisioning the required capacity."},"isMC":true},{"id":"WnTjrWekCbF3PwicaCVy","question_images":[],"isMC":true,"choices":{"D":"Use AWS PrivateLink to create a private connection between the application's VPC and the third-party SaaS provider.","C":"Configure AWS PrivateLink to allow only outbound traffic from the VPC without enabling the third-party SaaS provider to establish.","B":"Deploy AWS Transit Gateway to manage and route traffic between the application's VPC and the third-party SaaS provider.","A":"Implement an AWS Site-to-Site VPN to establish a secure connection with the third-party SaaS provider."},"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/144937-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["D (100%)"],"topic":"1","timestamp":"2024-08-03 11:07:00","discussion":[{"upvote_count":"3","timestamp":"1736055720.0","comment_id":"1336650","poster":"LeonSauveterre","content":"Selected Answer: D\nC - PrivateLink exists because of its main benefit of bidirectional communication for secure access without public internet exposure. By doing this, you're restricting the SaaS provider's ability to establish sessions. Option C is misleading and just plain wrong. Option D alone is enough."},{"upvote_count":"4","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/integrate-third-party-services/architecture-1.html\nIt is limited to only TCP traffic and unidirectional communication. The third-party workloads cannot initiate communication back to your account.","timestamp":"1727659920.0","poster":"spoved","comment_id":"1291350"},{"timestamp":"1726585440.0","comment_id":"1285312","upvote_count":"1","poster":"56ce46c","content":"I think C is corret\n2. Restrict Inbound Traffic via Security Groups:\nTo prevent the third-party SaaS provider from establishing inbound connections to your VPC, use Security Groups attached to the VPC Endpoint Interface.\n\nOutbound Traffic Allowed: Ensure that your security groups allow outbound traffic to the SaaS provider’s IP ranges or endpoints.\nRestrict Inbound Traffic: You should block all inbound traffic on the VPC Endpoint Interface by configuring the security group rules. For example:\nInbound Rules: Block all traffic (or leave it empty).\nOutbound Rules: Allow outbound connections to the IP addresses or ports specified by the SaaS provider."},{"comment_id":"1260205","timestamp":"1722678120.0","poster":"komorebi","upvote_count":"3","content":"Selected Answer: D\nAnswer is D"},{"upvote_count":"2","content":"Selected Answer: D\nD is correct","timestamp":"1722676020.0","comment_id":"1260192","poster":"JunsK1e"}],"answer_images":[],"exam_id":31,"question_id":964,"answer_description":"","unix_timestamp":1722676020,"answer_ET":"D","question_text":"A company has a multi-tier web application. The application's internal service components are deployed on Amazon EC2 instances. The internal service components need to access third-party software as a service (SaaS) APIs that are hosted on AWS.\n\nThe company needs to provide secure and private connectivity from the application's internal services to the third-party SaaS application. The company needs to ensure that there is minimal public internet exposure.\n\nWhich solution will meet these requirements?"},{"id":"DFlMuSnn0heNDNOf75Fh","answer_description":"","isMC":true,"question_text":"An application allows users at a company's headquarters to access product data. The product data is stored in an Amazon RDS MySQL DB instance. The operations team has isolated an application performance slowdown and wants to separate read traffic from write traffic. A solutions architect needs to optimize the application's performance quickly.\nWhat should the solutions architect recommend?","question_id":965,"answer":"D","answer_ET":"D","answers_community":["D (99%)","1%"],"question_images":[],"topic":"1","answer_images":[],"discussion":[{"upvote_count":"29","content":"Selected Answer: D\nThe solutions architect should recommend option D: Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.\n\nCreating read replicas allows the application to offload read traffic from the source database, improving its performance. The read replicas should be configured with the same compute and storage resources as the source database to ensure that they can handle the read workload effectively.","timestamp":"1671651060.0","comment_id":"752689","poster":"Buruguduystunstugudunstuy"},{"poster":"cookieMr","content":"Selected Answer: D\nA. In a Multi-AZ deployment, a standby replica of the database is created in a different AZ for high availability and automatic failover purposes. However, serving read requests from the primary AZ alone would not effectively separate read and write traffic. Both read and write traffic would still be directed to the primary database instance, which might not fully optimize performance.\n\nB. The secondary instance in a Multi-AZ deployment is intended for failover and backup purposes, not for actively serving read traffic. It operates in a standby mode and is not optimized for handling read queries efficiently.\n\nC. Configuring the read replicas with half of the compute and storage resources as the source database might not be optimal. It's generally recommended to configure the read replicas with the same compute and storage resources as the source database to ensure they can handle the read workload effectively.\n\nD. Configuring the read replicas with the same compute and storage resources as the source database ensures that they can handle the read workload efficiently and provide the required performance boost.","upvote_count":"8","comment_id":"930275","timestamp":"1687421280.0"},{"poster":"Dharmarajan","content":"Selected Answer: D\nThe read replica should be created with same capacity so it serves as a failover site as well, improving the availability of the database.","timestamp":"1738177620.0","upvote_count":"1","comment_id":"1348721"},{"timestamp":"1736697480.0","content":"Selected Answer: D\nA criação de réplicas de leitura com os mesmos recursos de computação e armazenamento que o banco de dados de origem resolve o problema de forma eficiente, pois:\n\nTráfego de leitura separado:\n\nDirecionar o tráfego de leitura para as réplicas reduz a carga na instância primária, otimizando o desempenho geral.\nManutenção da performance:\n\nGarantir que as réplicas tenham os mesmos recursos evita gargalos, mesmo sob tráfego intenso.\nImplementação rápida:\n\nA configuração de réplicas de leitura no Amazon RDS é rápida e gerenciada, permitindo uma solução quase imediata.\nEssa abordagem atende à necessidade da empresa de otimizar o desempenho do aplicativo de forma rápida e escalável.","comment_id":"1339597","poster":"Rcosmos","upvote_count":"1"},{"upvote_count":"1","comment_id":"1336765","timestamp":"1736082600.0","poster":"satyaammm","content":"Selected Answer: D\nMulti-AZ's offer availability but Read Replicas offers read performance."},{"poster":"PaulGa","comment_id":"1284155","upvote_count":"3","content":"Selected Answer: D\nAns D - can't be C because we don't know how much CPU write/read respectively consumes; we'll have to monitor to find out...","timestamp":"1726407840.0"},{"content":"Selected Answer: D\nD makes the most sense.","timestamp":"1721576940.0","poster":"jaradat02","comment_id":"1252548","upvote_count":"1"},{"comments":[{"timestamp":"1715793000.0","poster":"drich22","upvote_count":"4","comment_id":"1212057","content":"By default, a read replica is created with the same storage type as the source DB instance.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html"}],"upvote_count":"5","timestamp":"1712610420.0","poster":"MehulKapadia","content":"Selected Answer: D\nKeyword: \"separate read traffic from write traffic\" = Read Replica = Option A and B are not the correct answer.\nOption C: Why would you try to have half the resource for read replicas ?. It must be equal resources to ensure read load can be served consistently. \n\nCorrect Answer is D: Read replica with same compute power as source database instance.","comment_id":"1191838"},{"upvote_count":"3","poster":"awsgeek75","content":"Selected Answer: D\nA: This will not have any change as you are still reading from same instance as you are writing to\nB: Not possible (https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html)\nC: Why would you do that even if that was possible? No one asked to save on cost\nD: Read replicas are normally for handling read-only traffic","comment_id":"1122905","timestamp":"1705270140.0"},{"poster":"ignajtpolandstrong","content":"Selected Answer: D\nIn a Multi-AZ deployment, the standby instance is kept in sync with the primary instance and is used for failover purposes only. You cannot read data from the standby instance in a Multi-AZ deployment. If you need to offload read traffic from the primary instance, you can create one or more Read Replicas. Read Replicas are read-only copies of your database that can be used to offload read traffic from the primary instance, which can help improve performance","upvote_count":"3","timestamp":"1703777340.0","comment_id":"1107914"},{"upvote_count":"3","poster":"Ruffyit","content":"D. Configuring the read replicas with the same compute and storage resources as the source database ensures that they can handle the read workload efficiently and provide the required performance boost.","comment_id":"1056646","timestamp":"1698565560.0"},{"poster":"TariqKipkemei","comment_id":"988821","upvote_count":"1","content":"Selected Answer: B\nBoth B and D would work.\n\nAmazon RDS now offers Multi-AZ deployments with readable standby instances (also called Multi-AZ DB cluster deployments) . You should consider using Multi-AZ DB cluster deployments with two readable DB instances if you need additional read capacity in your Amazon RDS Multi-AZ deployment and if your application workload has strict transaction latency requirements such as single-digit milliseconds transactions.\n\nhttps://aws.amazon.com/blogs/database/readable-standby-instances-in-amazon-rds-multi-az-deployments-a-new-high-availability-option/#:~:text=read%20replicas.-,Amazon%20RDS,-now%20offers%20Multi","timestamp":"1692850800.0"},{"poster":"Guru4Cloud","content":"Selected Answer: D\nThe best solution is to create read replicas for the database and configure them with the same compute and storage resources as the source database.\n\nThe key requirements are to quickly optimize performance by isolating reads from writes.\n\nRead replicas allow read-only workloads to be directed to one or more replicas of the source RDS instance. This separates reporting or analytics queries from transactional workloads.\n\nThe read replicas should have the same compute and storage as the source to provide equivalent performance for reads. Scaling down the replicas would limit read performance.\n\nUsing Multi-AZ alone does not achieve read/write separation. The secondary AZ instance is for disaster recovery, not performance.","upvote_count":"5","timestamp":"1691765940.0","comment_id":"978739"},{"content":"Read replica + Same resources as we may need to turn replica to primary in few cases","poster":"MNotABot","upvote_count":"1","timestamp":"1689410580.0","comment_id":"952187"},{"content":"Selected Answer: D\nD meets the requiremets.","upvote_count":"1","comment_id":"903405","timestamp":"1684688820.0","poster":"Bmarodi"},{"content":"Option C suggests creating read replicas for the database and configuring them with half of the compute and storage resources as the source database. This is a better option as it allows read traffic to be offloaded from the primary database, separating read traffic from write traffic. Configuring the read replicas with half the resources will also save on costs.","poster":"Adeshina","timestamp":"1683743580.0","comments":[{"poster":"NSA_Poker","upvote_count":"1","timestamp":"1715698140.0","comment_id":"1211507","content":"If the source database is already 40% full, the read replica's performance will degrade as it is @ 80% capacity. This will not optimize the apps performance."},{"timestamp":"1685238960.0","poster":"Charlesleeee","comment_id":"908278","upvote_count":"5","content":"Err, just curious, what if the production database is 51% full? Your half storage read replica would explode…?"}],"upvote_count":"1","comment_id":"894275"},{"upvote_count":"5","comment_id":"853214","content":"Can anyone explain why B is not an option?","poster":"Oldman2023","comments":[{"poster":"draum010","timestamp":"1680109440.0","upvote_count":"4","comment_id":"854712","content":"CHATGPT says:\n\nTo optimize the application's performance and separate read traffic from write traffic, the solutions architect should recommend creating read replicas for the database and configuring them to serve read requests. Option C and D both suggest creating read replicas, but option D is a better choice because it configures the read replicas with the same compute and storage resources as the source database.\n\nOption A and B suggest changing the existing database to a Multi-AZ deployment, which would provide high availability by replicating the database across multiple Availability Zones. However, it would not separate read and write traffic, so it is not the best solution for optimizing application performance in this scenario."},{"poster":"caffee","comment_id":"867466","upvote_count":"3","timestamp":"1681228860.0","content":"Multi-AZ: Synchronous replication occurs, meaning that synchronizing data between DB instances immediately can slow down application's performance. But this method increases High Availability.\nRead Replicas: Asynchronous replication occurs, meaning that replicating data in other moments rather than in the writing will maintain application's performance. Although the data won't be HA as Multi-AZ kind of deployment, this method increases Scalability. Good for read heavy workloads."}],"timestamp":"1680005280.0"},{"comment_id":"841581","poster":"SuketuKohli","timestamp":"1679028120.0","content":"You can create up to 15 read replicas from one DB instance within the same Region. For replication to operate effectively, each read replica should have the same amount of compute and storage resources as the source DB instance. If you scale the source DB instance, also scale the read replicas.","upvote_count":"2","comments":[{"content":"I think for RDS it is 5 read replicas. 15 is for aurora serverless","upvote_count":"1","timestamp":"1684581960.0","poster":"dhuno","comment_id":"902539"}]},{"content":"Selected Answer: D\nOption D","timestamp":"1669485660.0","upvote_count":"1","comment_id":"727733","poster":"DivaLight"},{"content":"D is correct","poster":"Wpcorgan","comment_id":"723762","timestamp":"1669049580.0","upvote_count":"2"},{"comment_id":"712840","poster":"Nigma","content":"D\n\nhttps://www.examtopics.com/discussions/amazon/view/46461-exam-aws-certified-solutions-architect-associate-saa-c02/","timestamp":"1667801940.0","upvote_count":"1"},{"upvote_count":"2","poster":"Hunkie","timestamp":"1667349720.0","comment_id":"709492","content":"Selected Answer: D\nIf you scale the source DB instance, also scale the read replicas."},{"comment_id":"698963","upvote_count":"4","poster":"ArielSchivo","content":"Selected Answer: D\nD is correct.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_MySQL.Replication.ReadReplicas.html","timestamp":"1666178580.0"}],"unix_timestamp":1666178580,"url":"https://www.examtopics.com/discussions/amazon/view/85906-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"timestamp":"2022-10-19 13:23:00","choices":{"C":"Create read replicas for the database. Configure the read replicas with half of the compute and storage resources as the source database.","D":"Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.","B":"Change the existing database to a Multi-AZ deployment. Serve the read requests from the secondary Availability Zone.","A":"Change the existing database to a Multi-AZ deployment. Serve the read requests from the primary Availability Zone."}}],"exam":{"provider":"Amazon","isImplemented":true,"isMCOnly":true,"isBeta":false,"id":31,"numberOfQuestions":1019,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":193},"__N_SSP":true}