{"pageProps":{"questions":[{"id":"gDF2VBbTcpk7TW5L2mlI","exam_id":31,"timestamp":"2023-05-16 14:49:00","topic":"1","answer_ET":"CEF","unix_timestamp":1684241340,"discussion":[{"upvote_count":"8","poster":"awsgeek75","comments":[{"timestamp":"1720360320.0","poster":"awsgeek75","content":"C is badly worded IMHO because of this part \" Refactor the application to host the web tier, application tier, and database tier.\" The database tier tier just makes it confusing when you don't read E and F.","comment_id":"1115984","upvote_count":"2"}],"content":"Selected Answer: CEF\nThe wording on this question makes things ambiguous for C. But, remember well-architected so:\nA: Not ideal as it is suggesting using existing architecture but with autoscaling EC2. Doesn't leave room for improvement on scaling or reliability on each tier.\nB: Single RDS, not well-architected\nD: Again, single RDS\nE,F are good options and C is only remaining good one.","timestamp":"1720360260.0","comment_id":"1115983"},{"poster":"Abrar2022","content":"Selected Answer: CEF\nC-scalable and resilient\nE-high availability of the application\nF-Multi-AZ configuration provides high availability","timestamp":"1701680100.0","comment_id":"914222","upvote_count":"6"},{"timestamp":"1727498400.0","comment_id":"1184593","content":"remove singles and remove network ACLs","upvote_count":"3","poster":"Burrito69"},{"content":"i would flag this on the test and do it last.","timestamp":"1721868180.0","upvote_count":"5","comment_id":"1131276","poster":"jjcode"},{"poster":"argl1995","upvote_count":"2","comments":[{"upvote_count":"2","timestamp":"1704566280.0","poster":"argl1995","comment_id":"944845","content":"So, CEF is the right answer"}],"timestamp":"1704566280.0","comment_id":"944844","content":"option A cannot be the answer as Security group is at instance level whereas a NACL is at the subnet level. Having said that option C is the right one as the VPC cannot span across the regions and here it is mentioned two AZs for which I am guessing it is a default VPC which is created in each region with a subnet in each AZ."},{"content":"How can you create a VPC across 2 AZ? i only see EF here.. if they mean 2 separate VPC then that is different but a VPC cannot span two AZ..","upvote_count":"1","poster":"Gooniegoogoo","comment_id":"939178","timestamp":"1703957100.0","comments":[{"content":"A VPC most definitely can span across 2 AZ. You may be thinking of subnets.","poster":"lemur88","timestamp":"1708901100.0","comment_id":"990396","upvote_count":"3"}]},{"poster":"marufxplorer","upvote_count":"1","comment_id":"926404","timestamp":"1702877460.0","content":"I also agree with CEF but chatGPT answer is ACE. A and C is the similar \nAnother Logic F is not True because in the question not mentioned about DB","comments":[{"poster":"awsgeek75","comment_id":"1126287","upvote_count":"3","timestamp":"1721338560.0","content":"ChatGPT is a language parser. It is not an AWS solution architect!"}]},{"poster":"TariqKipkemei","content":"Selected Answer: CEF\nCEF is best","timestamp":"1702620120.0","upvote_count":"2","comment_id":"923692"},{"comment_id":"915204","timestamp":"1701770520.0","content":"Selected Answer: CEF\nIt's clearly CEF.","poster":"antropaws","upvote_count":"2"},{"poster":"omoakin","upvote_count":"1","content":"B- to control access to database\nC-scalable and resilient \nE-high availability of the application","comment_id":"909757","timestamp":"1701303540.0"},{"timestamp":"1700984940.0","content":"Selected Answer: CEF\nCEF\nA: application's existing architecture is wrong (single AZ)\nB: single AZ\nD: Single AZ","comment_id":"907093","poster":"lucdt4","upvote_count":"2"},{"comments":[{"timestamp":"1720358700.0","upvote_count":"2","poster":"mwwt2022","content":"good explanation","comment_id":"1115961"}],"comment_id":"901221","timestamp":"1700319540.0","content":"C.\nThis solution follows the recommended architecture pattern of separating the web, application, and database tiers into different subnets. It provides better security, scalability, and fault tolerance.\nE.By using Elastic Load Balancers (ELBs), you can distribute traffic to multiple instances of the web tier, increasing scalability and availability. Controlling access through security groups allows for fine-grained control and ensures only authorized traffic reaches each layer.\nF. \nDeploying an Amazon RDS database in a Multi-AZ configuration provides high availability and automatic failover. Placing the database in private subnets enhances security. Allowing database access only from the application tier security groups limits exposure and follows the principle of least privilege.","upvote_count":"5","poster":"cloudenthusiast"},{"timestamp":"1700146140.0","content":"Selected Answer: CEF\nOnly this valid for best practices and well architected","comment_id":"899197","poster":"nosense","upvote_count":"5"}],"question_text":"A company has a three-tier web application that is in a single server. The company wants to migrate the application to the AWS Cloud. The company also wants the application to align with the AWS Well-Architected Framework and to be consistent with AWS recommended best practices for security, scalability, and resiliency.\n\nWhich combination of solutions will meet these requirements? (Choose three.)","url":"https://www.examtopics.com/discussions/amazon/view/109406-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"answer_images":[],"isMC":true,"answer_description":"","choices":{"B":"Set up security groups and network access control lists (network ACLs) to control access to the database layer. Set up a single Amazon RDS database in a private subnet.","C":"Create a VPC across two Availability Zones. Refactor the application to host the web tier, application tier, and database tier. Host each tier on its own private subnet with Auto Scaling groups for the web tier and application tier.","D":"Use a single Amazon RDS database. Allow database access only from the application tier security group.","A":"Create a VPC across two Availability Zones with the application's existing architecture. Host the application with existing architecture on an Amazon EC2 instance in a private subnet in each Availability Zone with EC2 Auto Scaling groups. Secure the EC2 instance with security groups and network access control lists (network ACLs).","F":"Use an Amazon RDS database Multi-AZ cluster deployment in private subnets. Allow database access only from application tier security groups.","E":"Use Elastic Load Balancers in front of the web tier. Control access by using security groups containing references to each layer's security groups."},"question_id":411,"answers_community":["CEF (100%)"],"answer":"CEF"},{"id":"i1AjiWW7ylcPwqa7ONZg","exam_id":31,"timestamp":"2023-05-16 14:56:00","answer_ET":"BCF","topic":"1","unix_timestamp":1684241760,"discussion":[{"comment_id":"1110612","content":"Selected Answer: BCF\nADE = AWS responsibility","timestamp":"1719748740.0","upvote_count":"10","poster":"pentium75"},{"poster":"awsgeek75","comment_id":"1126539","content":"Selected Answer: BCF\nJust to clarify on F. Direct Connect is an ISP and AWS offering, I consider it as a physical connection just like you get from your ISP at home. There is not security on it until you build security on the connection. AWS provides Direct Connect but it does not provide encryption level security on data movement through it by default. It's the customer's responsibility.","timestamp":"1721371560.0","upvote_count":"9"},{"poster":"Guru4Cloud","upvote_count":"5","timestamp":"1708792080.0","comment_id":"989263","content":"Selected Answer: BCF\nB: Creating an RDS instance and configuring the maintenance window is done by the customer.\n\nC: Adding monitoring, logging, etc on ECS is managed by the customer.\n\nF: Encrypting Direct Connect traffic is handled by the customer."},{"comment_id":"957995","content":"Selected Answer: BCF\nIn question has 3 keyword \"Amazon ECS\", \"AWS Direct Connect\", \"Amazon RDS\". With per Amazon services, choose 1 according answer. Has 6 items, need pick 3 items.\n\nECS --> choose C.\n\nDirect Connect --> choose F.\n\nRDS --> Excluse A (by keyword \"infrastructure layer\"), Choose B. Exclusive D (by keyword \"patches for all minor and major database versions for Amazon RDS\"). Exclusive E (by keyword \"Ensure the physical security of the Amazon RDS\"). Easy question.","upvote_count":"5","poster":"james2033","timestamp":"1705809540.0"},{"comment_id":"928682","poster":"kapit","content":"BC & F ( no automatic encryption with direct connect","upvote_count":"2","timestamp":"1703103600.0"},{"poster":"TariqKipkemei","timestamp":"1702620840.0","upvote_count":"1","comment_id":"923699","comments":[{"content":"Plus C (we were asked for three). Configuration (!) of components for monitoring, log management etc.; those services exist from AWS but you need to configure them (which logs do you want to store for how long etc.).","timestamp":"1719748680.0","comment_id":"1110611","poster":"pentium75","upvote_count":"2"}],"content":"Selected Answer: BF\nAmazon ECS is a fully managed service, the ops team only focus on building their applications, not the environment.\nOnly option B and F makes sense."},{"timestamp":"1701770580.0","poster":"antropaws","comment_id":"915205","content":"Selected Answer: BCF\n100% BCF.","upvote_count":"2"},{"upvote_count":"5","content":"Selected Answer: BCF\nBCF\nB: Mentioned RDS\nC: Mentioned ECS\nF: Mentioned Direct connect","comment_id":"907102","timestamp":"1700986140.0","poster":"lucdt4"},{"poster":"hiroohiroo","upvote_count":"2","timestamp":"1700444100.0","content":"Selected Answer: BCF\nYes BCF","comment_id":"902267"},{"timestamp":"1700352120.0","comment_id":"901518","upvote_count":"2","content":"I agree BCF","poster":"omoakin"},{"comment_id":"899203","content":"Selected Answer: BCF\nBcf for me","timestamp":"1700146560.0","poster":"nosense","upvote_count":"3"}],"question_text":"A company is migrating its applications and databases to the AWS Cloud. The company will use Amazon Elastic Container Service (Amazon ECS), AWS Direct Connect, and Amazon RDS.\n\nWhich activities will be managed by the company's operational team? (Choose three.)","url":"https://www.examtopics.com/discussions/amazon/view/109408-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"isMC":true,"answer_images":[],"answer_description":"","question_id":412,"choices":{"C":"Configuration of additional software components on Amazon ECS for monitoring, patch management, log management, and host intrusion detection","D":"Installation of patches for all minor and major database versions for Amazon RDS","F":"Encryption of the data that moves in transit through Direct Connect","E":"Ensure the physical security of the Amazon RDS infrastructure in the data center","A":"Management of the Amazon RDS infrastructure layer, operating system, and platforms","B":"Creation of an Amazon RDS DB instance and configuring the scheduled maintenance window"},"answers_community":["BCF (98%)","2%"],"answer":"BCF"},{"id":"krayzzZEyjf5173oaa5v","choices":{"C":"Use AWS App2Container (A2C) to containerize the job. Install the container in the existing Amazon Machine Image (AMI). Ensure that the schedule stops the container when the task finishes.","D":"Configure the existing schedule to stop the EC2 instance at the completion of the job and restart the EC2 instance when the next job starts.","B":"Copy the code into an AWS Lambda function that has 1 GB of memory. Create an Amazon EventBridge scheduled rule to run the code each hour.","A":"Use AWS App2Container (A2C) to containerize the job. Run the job as an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate with 0.5 virtual CPU (vCPU) and 1 GB of memory."},"isMC":true,"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/109521-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":413,"answer_images":[],"question_images":[],"unix_timestamp":1684322280,"answer_description":"","question_text":"A company runs a Java-based job on an Amazon EC2 instance. The job runs every hour and takes 10 seconds to run. The job runs on a scheduled interval and consumes 1 GB of memory. The CPU utilization of the instance is low except for short surges during which the job uses the maximum CPU available. The company wants to optimize the costs to run the job.\n\nWhich solution will meet these requirements?","discussion":[{"comment_id":"1124541","upvote_count":"9","poster":"omarshaban","timestamp":"1705443840.0","content":"THIS WAS IN MY EXAM"},{"poster":"awsgeek75","timestamp":"1705654320.0","content":"Selected Answer: B\nNever done it myself but apparently you can run Java in Lambda all the way to latest version\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-java.html","comment_id":"1126543","upvote_count":"6"},{"comment_id":"1308568","upvote_count":"2","timestamp":"1731017700.0","content":"Selected Answer: B\nkey -The company wants to optimize the costs to run the job.\nthe answer is B because lambda provides the most cost-effective,easy to mange and scalable solution.it minimizes the need to manage infrastructure because you only pay for the compute time used during job execution","poster":"Danilus"},{"comments":[{"timestamp":"1711723200.0","poster":"bujuman","upvote_count":"4","comment_id":"1185491","content":"Statement: A company runs a Java-based job on an Amazon EC2 instance\nRequirement: The company wants to optimize the costs to run the job\nRegarding option A: App2Container is more likely for migratiing legacy application to conatiner based application. \nWhich is not the main purpose of this use case.\nWe are asked to reduce cost on a application that is already running under EC2 instance.\nSo option B has the hight weight, cause lambda could perfectly do the job with the minimal cost","comments":[{"upvote_count":"1","comment_id":"1316346","timestamp":"1732285440.0","poster":"JA2018","content":"you only need to pay for the compute resources consumed as and when each Lambda function is actually running (for the running duration)"}]}],"timestamp":"1709120400.0","upvote_count":"4","poster":"noircesar25","comment_id":"1161571","content":"can someone explain what makes A wrong, im aware that C hasnt covered all the requirements but A seems good with fargate serverless and autoscaling functionalities, plus AWS app2container is for .NET and JAVA"},{"poster":"Murtadhaceit","comment_id":"1091188","upvote_count":"3","timestamp":"1702053060.0","content":"Selected Answer: B\nThis question is intended for Lambda. Just searched for Lambda with Event bridge. I"},{"timestamp":"1699210560.0","poster":"potomac","upvote_count":"2","content":"Selected Answer: B\nLambda allows you to allocate memory for your functions in increments of 1 MB, ranging from a minimum of 128 MB to a maximum of 10,240 MB (10 GB).","comment_id":"1063185"},{"timestamp":"1692886560.0","poster":"Guru4Cloud","comment_id":"989252","upvote_count":"6","content":"Selected Answer: B\nRemember - AWS Lambda function can go up to 10 GB of memory, instead of free tier only allow 512MB."},{"poster":"james2033","timestamp":"1689946680.0","upvote_count":"2","comment_id":"958560","content":"Selected Answer: B\n\"AWS Batch jobs as EventBridge targets\" at https://docs.aws.amazon.com/batch/latest/userguide/batch-cwe-target.html \n\nAWS Batch + Amazon EventBridge https://docs.aws.amazon.com/batch/latest/userguide/batch-cwe-target.html .\n\nAWS Lambda just for a point of time per period. Choose B."},{"upvote_count":"3","comment_id":"923700","content":"Selected Answer: B\n10 seconds to run, optimize the costs, consumes 1 GB of memory = AWS Lambda function.","timestamp":"1686802740.0","poster":"TariqKipkemei"},{"timestamp":"1685903760.0","poster":"alexandercamachop","comment_id":"914874","upvote_count":"2","content":"Selected Answer: B\nAWS Lambda automatically scales resources to handle the workload, so you don't have to worry about managing the underlying infrastructure. It provisions the necessary compute resources based on the configured memory size (1 GB in this case) and executes the job in a serverless environment.\n\nBy using Amazon EventBridge, you can create a scheduled rule to trigger the Lambda function every hour, ensuring that the job runs on the desired interval."},{"upvote_count":"3","poster":"Yadav_Sanjay","timestamp":"1684722960.0","content":"Selected Answer: B\nB - Within 10 sec and 1 GB Memory (Lambda Memory 128MB to 10GB)","comment_id":"903676","comments":[{"content":"https://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html","comment_id":"903677","upvote_count":"2","timestamp":"1684723020.0","poster":"Yadav_Sanjay"}]},{"content":"Selected Answer: B\nAgreed, B Lambda","upvote_count":"3","poster":"Efren","comment_id":"900033","timestamp":"1684322280.0"}],"exam_id":31,"answers_community":["B (100%)"],"timestamp":"2023-05-17 13:18:00","answer_ET":"B","topic":"1"},{"id":"eCdwpwMWDKyUn3xLMlzr","discussion":[{"comments":[{"comment_id":"946902","poster":"cmbt","timestamp":"1688881980.0","upvote_count":"4","content":"Finally I understood!"},{"upvote_count":"8","comment_id":"933605","timestamp":"1687698120.0","poster":"joshnort","content":"Great analogy"}],"poster":"Efren","comment_id":"900035","timestamp":"1684322340.0","content":"D, Governance is like the goverment, they can do things you cannot , like delete files or backups :D Compliance, nobody can!","upvote_count":"39"},{"timestamp":"1684242420.0","upvote_count":"5","content":"Selected Answer: D\nD bcs in governance we can delete backup","comment_id":"899211","poster":"nosense"},{"timestamp":"1731018360.0","upvote_count":"2","poster":"Danilus","content":"Selected Answer: D\nkey-The company must not alter the files for the duration of the retention period\nthe answer is D because backup with vault lock in compliance mode make sure that the files when are locked they cannot be deleted or modified for the specified retention period it makes the files immutable\nwhy is not A? because the governance mode... with this mode backups allows flexibility to alter or delete backups","comment_id":"1308571"},{"content":"Selected Answer: D\nD. Use AWS Backup to create a backup vault that has a vault lock in compliance mode. Create the required backup plan","poster":"f2e2419","comment_id":"1119392","timestamp":"1704952620.0","upvote_count":"3"},{"comment_id":"989248","upvote_count":"3","poster":"Guru4Cloud","content":"Selected Answer: D\nD. Use AWS Backup to create a backup vault that has a vault lock in compliance mode. Create the required backup plan","timestamp":"1692886140.0"},{"content":"Selected Answer: D\nUse AWS Backup to create a backup vault that has a vault lock in compliance mode. Create the required backup plan","timestamp":"1692885960.0","upvote_count":"3","poster":"Guru4Cloud","comment_id":"989246"},{"comment_id":"967205","content":"Selected Answer: D\nCompliance mode","upvote_count":"2","timestamp":"1690727040.0","poster":"ccat91"},{"content":"Selected Answer: D\nMust not alter the files for the duration of the retention period = Compliance Mode","comment_id":"924821","timestamp":"1686885480.0","upvote_count":"2","poster":"TariqKipkemei"},{"poster":"antropaws","comment_id":"915206","content":"Selected Answer: D\nD for sure.","upvote_count":"2","timestamp":"1685952480.0"},{"upvote_count":"3","poster":"dydzah","comment_id":"907000","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/aws-backup/latest/devguide/vault-lock.html","timestamp":"1685068560.0"},{"upvote_count":"4","timestamp":"1684416960.0","comment_id":"901249","poster":"cloudenthusiast","content":"Selected Answer: D\ncompliance mode"}],"isMC":true,"question_images":[],"unix_timestamp":1684242420,"timestamp":"2023-05-16 15:07:00","question_text":"A company wants to implement a backup strategy for Amazon EC2 data and multiple Amazon S3 buckets. Because of regulatory requirements, the company must retain backup files for a specific time period. The company must not alter the files for the duration of the retention period.\n\nWhich solution will meet these requirements?","question_id":414,"answer_images":[],"answer":"D","answer_ET":"D","answer_description":"","exam_id":31,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/109410-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["D (100%)"],"choices":{"A":"Use AWS Backup to create a backup vault that has a vault lock in governance mode. Create the required backup plan.","D":"Use AWS Backup to create a backup vault that has a vault lock in compliance mode. Create the required backup plan.","B":"Use Amazon Data Lifecycle Manager to create the required automated snapshot policy.","C":"Use Amazon S3 File Gateway to create the backup. Configure the appropriate S3 Lifecycle management."}},{"id":"6qxQw4EZlmSllGR6ukJj","choices":{"D":"Use AWS X-Ray to view the workload details. Build architecture diagrams with relationships.","C":"Use Workload Discovery on AWS to generate architecture diagrams of the workloads.","B":"Use AWS Step Functions to collect workload details. Build architecture diagrams of the workloads manually.","A":"Use AWS Systems Manager Inventory to generate a map view from the detailed view report."},"answer_description":"","answer":"C","isMC":true,"unix_timestamp":1684257240,"question_text":"A company has resources across multiple AWS Regions and accounts. A newly hired solutions architect discovers a previous employee did not provide details about the resources inventory. The solutions architect needs to build and map the relationship details of the various workloads across all accounts.\n\nWhich solution will meet these requirements in the MOST operationally efficient way?","question_id":415,"answer_images":[],"topic":"1","answers_community":["C (97%)","3%"],"timestamp":"2023-05-16 19:14:00","discussion":[{"timestamp":"1731019020.0","content":"Key - Build and map the relationship details of the various workloads.\nKey - MOST operationally efficient way.\nThe answer is C because Workload Discovery is a tool that allows you to find automatically the workloads on the cloud, giving you a visual representation of the infrastructure and the relationship between the resources through different accounts.","comment_id":"1308578","poster":"Danilus","upvote_count":"2"},{"poster":"zinabu","content":"workload discovery=architecture diagram","timestamp":"1712549880.0","upvote_count":"3","comment_id":"1191348"},{"timestamp":"1705332660.0","upvote_count":"3","comment_id":"1123488","poster":"osmk","content":"https://docs.aws.amazon.com/solutions/latest/workload-discovery-on-aws/solution-overview.htmlWorkload Discovery on AWS is a visualization tool that automatically generates architecture diagrams of your workload on AWS. You can use this solution to build, customize, and share detailed workload visualizations based on live data from AWS"},{"timestamp":"1704661200.0","upvote_count":"4","comment_id":"1116157","comments":[{"upvote_count":"3","poster":"NayeraB","content":"Even if B is possible, it has \"manually\" in it which we won't do because we're lazy in this question","timestamp":"1708258440.0","comment_id":"1153247"}],"content":"Selected Answer: C\nA: Systems Manager Inventory -> Metadata\nB: Not possible (correct me if I'm wrong) \nD: X-Ray is for application debugging\nC: Workload Discovery is purpose built tool for this type of usage","poster":"awsgeek75"},{"upvote_count":"3","timestamp":"1699210680.0","comment_id":"1063186","poster":"potomac","content":"Selected Answer: C\nWorkload Discovery on AWS (formerly called AWS Perspective) is a tool to visualize AWS Cloud workloads. Use Workload Discovery on AWS to build, customize, and share detailed architecture diagrams of your workloads based on live data from AWS."},{"content":"Selected Answer: C\nuse Workload Discovery on AWS","poster":"TariqKipkemei","comment_id":"1059362","timestamp":"1698814980.0","upvote_count":"3"},{"poster":"Guru4Cloud","content":"Selected Answer: C\nWorkload Discovery is purpose-built to automatically generate visual mappings of architectures across accounts and Regions. This makes it the most operationally efficient way to meet the requirements.","timestamp":"1692885900.0","upvote_count":"4","comment_id":"989245"},{"comment_id":"926210","timestamp":"1687029900.0","content":"Selected Answer: C\nOption A: AWS SSM offers \"Software inventory\": Collect software catalog and configuration for your instances.\nOption C: Workload Discovery on AWS: is a tool for maintaining an inventory of the AWS resources across your accounts and various Regions and mapping relationships between them, and displaying them in a web UI.","poster":"MrAWSAssociate","upvote_count":"4"},{"comments":[{"timestamp":"1704031260.0","content":"That is C","poster":"pentium75","upvote_count":"2","comment_id":"1110621"}],"upvote_count":"1","comment_id":"915270","poster":"DrWatson","timestamp":"1685957220.0","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/mt/visualizing-resources-with-workload-discovery-on-aws/"},{"upvote_count":"3","content":"Selected Answer: C\nAWS Workload Discovery - create diagram, map and visualise AWS resources across AWS accounts and Regions","timestamp":"1685868360.0","poster":"Abrar2022","comment_id":"914260"},{"timestamp":"1685868180.0","upvote_count":"2","poster":"Abrar2022","content":"Workload Discovery on AWS can map AWS resources across AWS accounts and Regions and visualize them in a UI provided on the website.","comment_id":"914258"},{"content":"Selected Answer: C\nhttps://aws.amazon.com/jp/builders-flash/202209/workload-discovery-on-aws/?awsf.filter-name=*all","timestamp":"1684539120.0","poster":"hiroohiroo","upvote_count":"3","comment_id":"902265"},{"comment_id":"901523","upvote_count":"3","poster":"omoakin","timestamp":"1684448100.0","content":"Only C makes sense"},{"timestamp":"1684417140.0","comment_id":"901250","poster":"cloudenthusiast","content":"Selected Answer: C\nWorkload Discovery on AWS is a service that helps visualize and understand the architecture of your workloads across multiple AWS accounts and Regions. It automatically discovers and maps the relationships between resources, providing an accurate representation of the architecture.","upvote_count":"3"},{"content":"Not sure here tbh\n\nTo efficiently build and map the relationship details of various workloads across multiple AWS Regions and accounts, you can use the AWS Systems Manager Inventory feature in combination with AWS Resource Groups. Here's a solution that can help you achieve this:\n\n AWS Systems Manager Inventory:","comment_id":"900036","timestamp":"1684322460.0","poster":"Efren","upvote_count":"1"},{"upvote_count":"2","comment_id":"899408","poster":"nosense","timestamp":"1684257240.0","content":"Selected Answer: C\nonly c mapping relationships"}],"exam_id":31,"answer_ET":"C","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/109433-exam-aws-certified-solutions-architect-associate-saa-c03/"}],"exam":{"name":"AWS Certified Solutions Architect - Associate SAA-C03","provider":"Amazon","isMCOnly":true,"isImplemented":true,"lastUpdated":"11 Apr 2025","isBeta":false,"numberOfQuestions":1019,"id":31},"currentPage":83},"__N_SSP":true}