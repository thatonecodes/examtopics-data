{"pageProps":{"questions":[{"id":"cErVkECaP0EeLSAMizkp","answer_images":[],"exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/85446-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["B (66%)","A (34%)"],"answer":"B","isMC":true,"timestamp":"2022-10-14 08:05:00","answer_description":"","unix_timestamp":1665727500,"discussion":[{"upvote_count":"47","timestamp":"1680379140.0","comment_id":"858256","comments":[{"poster":"nhaastrup","upvote_count":"5","timestamp":"1735022280.0","comment_id":"1331044","content":"No B. if you go to the aws site(https://aws.amazon.com/appflow/) -AppFlow is a fully managed integration service that helps you securely transfer data between software as a service (SaaS) applications such as Salesforce, SAP, Google Analytics, Facebook Ads, and ServiceNow, and AWS services such as Amazon Simple Storage Service (S3) and Amazon Redshift in just a \"few clicks\". remember the question is asking for \"the LEAST operational overhead\", While Auto Scaling improves performance, it still involves managing EC2 instances, which adds operational overhead compared to a managed service like AppFlow."},{"comment_id":"1217097","upvote_count":"2","content":"Agreed, I hesitated a long time exactly for this reason. However, the requirement is to improve the performance as much as possible. I cannot guarantee the same performance with EC2 than with managed services. That's why I eventually voted B.","poster":"the_mellie","timestamp":"1716506700.0"},{"timestamp":"1703483700.0","content":"\"Operational overhead\" refers to operation of the solution once it's deployed, it's not about setting it up. EC2 instances that retrieve data from A and write it to B are nonsense, that's what cloud services are meant for.","comment_id":"1105042","poster":"pentium75","upvote_count":"13"},{"poster":"awsgeek75","comment_id":"1122470","upvote_count":"9","timestamp":"1705229700.0","content":"With AWS, a managed service is \"less operational overhead\" regardless of the complexity of the setup. AppFlow management is less of a headache when compared to EC2 management so A cannot be correct. EC2 has a setup overhead of OS/Application/Code hooks, security etc. continuous patching/upgrading seems like more than what you'll need to do with SaaS.\nB is the correct answer."}],"content":"Selected Answer: A\nIt says \"LEAST operational overhead\" (ie do it in a way it's the less work for me).\nIf you know a little Amazon AppFlow (see the some videos) you'll see you'll need time to configure and test it, and at the end cope with the errors during the extraction and load the info to the target.\nThe customer in the example ALREADY has some EC2 that do the work, the only problem is the performance, that WILL be improved scaling out and adding a queue (SNS) to decouple the work of notify the user.\nThe operational load of doing this is LESS that configuring AppFlow.","poster":"jdr75"},{"comments":[{"comment_id":"703181","timestamp":"1666627320.0","upvote_count":"23","content":"configuring Auto-Scaling also takes time when compared to AppFlow,\nin AWS's words \"in just a few clicks\"\n> Amazon AppFlow is a fully managed integration service that enables you to securely transfer data between Software-as-a-Service (SaaS) applications like Salesforce, SAP, Zendesk, Slack, and ServiceNow, and AWS services like Amazon S3 and Amazon Redshift, in just a few clicks","poster":"Six_Fingered_Jose"}],"content":"Selected Answer: B\nThis question just screams AppFlow (SaaS integration)\nhttps://aws.amazon.com/appflow/","poster":"Six_Fingered_Jose","upvote_count":"40","comment_id":"703180","timestamp":"1666627140.0"},{"comment_id":"1411016","upvote_count":"1","poster":"Kazmin","timestamp":"1743106440.0","content":"Selected Answer: A\nA is correct"},{"poster":"Itachi28","timestamp":"1742593200.0","upvote_count":"1","comment_id":"1401703","content":"Selected Answer: B\nOption A: Auto Scaling EC2 instances\n\nHigh operational overhead (still managing EC2 instances).\nNot eliminating bottlenecks (EC2 instance is still the data processor).\n🔴 Option C: EventBridge Rules\n\nComplex event-driven setup instead of direct integration.\nRequires custom event rules for each SaaS source, increasing operational burden.\n🔴 Option D: ECS with CloudWatch Events\n\nMigrating to ECS introduces complexity and doesn’t directly improve transfer speeds.\nStill processes data manually, adding an unnecessary layer.\n\nAmazon AppFlow (Option B) is the best choice because it is fully managed, removes EC2 dependencies, and simplifies integration while improving performance."},{"timestamp":"1738000500.0","content":"Selected Answer: B\nInitially I was inclined towards A, but then I read about AppFlow, which is a specific service to collect SAAS data sources. Also with A, there will be additional maintenance activities for EC2and application, but AppFlow will completely eliminate that work!","poster":"Dharmarajan","comment_id":"1347493","upvote_count":"1"},{"timestamp":"1736564460.0","upvote_count":"1","comment_id":"1339045","poster":"Skyskilo","content":"Selected Answer: A\nKey words here is Least Operational Overhead so A for me"},{"content":"Selected Answer: B\nThe answer is B, because for answer A you will have to manage the EC2 infrastructure, while AppFlow is a serverless service, you will not need to manage the infrastructure","upvote_count":"3","timestamp":"1734934140.0","comment_id":"1330686","poster":"vuongdo"},{"upvote_count":"2","content":"Selected Answer: B\ni support AppFlow, the original can be saas, and the target can be s3.","timestamp":"1734307680.0","poster":"llccing","comment_id":"1327108"},{"upvote_count":"2","comment_id":"1311030","timestamp":"1731462600.0","poster":"f51a8bd","content":"B. Cree un flujo de Amazon AppFlow para transferir datos entre cada fuente de SaaS y el depósito de S3. Configure una notificación de eventos de S3 para enviar eventos a un tema de Amazon Simple Notification Service (Amazon SNS) cuando se complete la carga al depósito de S3.\nExplicación:\nAmazon AppFlow permite la integración directa con múltiples fuentes de SaaS y automatiza el flujo de datos hacia Amazon S3, eliminando la necesidad de instancias de EC2 para recibir y cargar datos. Esto reduce la carga en las instancias de EC2 y simplifica el proceso de integración y recolección de datos.\n\nNotificación de eventos de S3 y SNS : Configurar eventos en Amazon S3 permite enviar notificaciones directamente a un tema de Amazon SNS cuando los datos se han cargado, lo cual asegura que los usuarios recibirán notificaciones sin necesidad de código personalizado en EC2."},{"timestamp":"1728935100.0","poster":"ChymKuBoy","upvote_count":"1","comment_id":"1297802","content":"Selected Answer: B\nB for sure"},{"upvote_count":"1","comment_id":"1294884","poster":"rar75024","timestamp":"1728426000.0","content":"direct connect maybe correct answer but we are making too many assumptions regarding direct connect network requirements."},{"comment_id":"1244092","content":"Has to be appflow because of the SaaS integration","timestamp":"1720414800.0","poster":"effiecancode","upvote_count":"2"},{"poster":"jatric","content":"Selected Answer: B\nFirst i thought it would be A but with more stydy found if its Saas and need to choose between EC2 and aws managed service one should always choose AWS managed service. So AppFlow seems more appropriate here.","upvote_count":"4","comment_id":"1238991","timestamp":"1719630300.0"},{"content":"Selected Answer: B\nAmazon AppFlow is a fully managed integration service that helps you securely transfer data between software as a service (SaaS) applications such as Salesforce, SAP, Google Analytics, Facebook Ads, and ServiceNow, and AWS services such as Amazon Simple Storage Service (S3) and Amazon Redshift in just a few clicks. \nhttps://aws.amazon.com/appflow/","timestamp":"1707410100.0","upvote_count":"5","comment_id":"1144715","poster":"SMALLE"},{"poster":"awsgeek75","timestamp":"1705229760.0","upvote_count":"6","comment_id":"1122472","content":"Selected Answer: B\nhttps://aws.amazon.com/appflow/\n\"With Amazon AppFlow automate bi-directional data flows between SaaS applications and AWS services in just a few clicks.\"\n\nIf you want to pass the exam, choose B, regardless of your personal experience! Always use AWS managed services for \"least operational overhead\""},{"upvote_count":"2","content":"SaaS - AppFlow","timestamp":"1700504820.0","poster":"[Removed]","comment_id":"1075706"},{"comment_id":"1072978","content":"Yea , I think this question is looking for Amazon Appflow.I also feel like it would be easier to set up Autoscaling for the already existing EC2 instances in the short term but then the fact that this software integrates with a lot of SAAS services means using Amazon Appflow will work reduce operational overhead in the long term","timestamp":"1700188500.0","poster":"OmegaLambda7XL9","upvote_count":"5"},{"comment_id":"1055042","content":"https://docs.aws.amazon.com/appflow/latest/userguide/what-is-appflow.html","upvote_count":"2","poster":"Ruffyit","timestamp":"1698371100.0"},{"timestamp":"1697828880.0","poster":"sweetheatmn","content":"Selected Answer: B\nhttps://aws.amazon.com/appflow/","comment_id":"1049051","upvote_count":"2"},{"content":"Selected Answer: B\nB suits the requirement","poster":"ACloud_Guru15","comment_id":"1043205","timestamp":"1697269260.0","upvote_count":"1"},{"timestamp":"1696844040.0","poster":"tom_cruise","content":"Selected Answer: A\nThe problem with A is you need to add ALB or ELB in front of ASG, and update DNS for your application, so B seems like a better choice.","comment_id":"1028695","upvote_count":"2"},{"poster":"awashenko","content":"This is a tough one. If they were not already using EC2 the answer would for sure be AppFlow (B). The question says \"least operational overheard\" so I feel like it takes more work to configure AppFlow than it does to create auto scaling in EC2. \n\nIf I had this question on the test, I would likely go with AppFlow so B","upvote_count":"2","comment_id":"1023445","timestamp":"1696279620.0"},{"poster":"Techi47","content":"Selected Answer: A\nWhile option B utilizes managed services and can be a valid approach, it's important to note that Amazon AppFlow is primarily designed for data integration and synchronization between various SaaS applications and AWS services. It may introduce an additional layer of complexity compared to directly handling the uploads with EC2 instances.\n\nUltimately, the choice between Option A and Option B depends on specific factors such as the existing architecture, the nature of data transfers, and any potential advantages offered by using Amazon AppFlow for data integration.\n\nIf the primary concern is to improve performance for data uploads and user notifications without introducing new services, Option A (Auto Scaling group with S3 event notifications) would likely be the simpler and more operationally efficient choice. However, if data integration between SaaS sources and the S3 bucket is a critical aspect of the application, Option B might be a more suitable approach.","upvote_count":"3","timestamp":"1695291120.0","comment_id":"1012974"},{"comment_id":"971672","upvote_count":"2","timestamp":"1691121960.0","poster":"TariqKipkemei","content":"Selected Answer: B\nSaaS Integration = Amazon AppFlow"},{"content":"Selected Answer: B\nSaaS -> AppFlow","poster":"hsinchang","comment_id":"965266","timestamp":"1690516920.0","upvote_count":"1"},{"comment_id":"953722","content":"Option B is the right answer.","upvote_count":"1","timestamp":"1689551940.0","poster":"miki111"},{"timestamp":"1687094340.0","comment_id":"926715","upvote_count":"8","poster":"cookieMr","content":"Selected Answer: B\nOption A suggests using an Auto Scaling group to scale out EC2 instances, but it does not address the potential bottleneck of slow application performance and the notification process.\n\nOption C involves using Amazon EventBridge (CloudWatch Events) rules for data output and S3 uploads, but it introduces additional complexity with separate rules and does not specifically address the slow application performance.\n\nOption D suggests containerizing the application and using Amazon Elastic Container Service (Amazon ECS) with CloudWatch Container Insights, which may involve more operational overhead and setup compared to the simpler solution provided by Amazon AppFlow.\n\nTherefore, option B offers the most streamlined solution with the least operational overhead by utilizing Amazon AppFlow for data transfer, configuring S3 event notifications for upload completion, and leveraging Amazon SNS for notifications without requiring additional infrastructure management."},{"timestamp":"1684315260.0","upvote_count":"1","content":"So true, This question just screams AppFlow (Saas integration)","comment_id":"899915","poster":"Abrar2022"},{"comment_id":"886710","content":"With Amazon AppFlow automate bi-directional data flows between SaaS applications and AWS services in just a few clicks.So B is the right answer","upvote_count":"2","timestamp":"1682972820.0","poster":"Rahulbit34"},{"poster":"cheese929","upvote_count":"4","content":"Selected Answer: B\nAmazon AppFlow is a fully-managed integration service that enables you to securely exchange data between software as a service (SaaS) applications, such as Salesforce, and AWS services, such as Amazon Simple Storage Service (Amazon S3) and Amazon Redshift. \nThe use of Appflow helps to remove the ec2 as the middle layer which slows down the process of data transmission and introduce an additional variable. \nAppflow is also a fully managed AWS service, thus reducing the operational overhead. \n\nhttps://docs.aws.amazon.com/appflow/latest/userguide/what-is-appflow.html","comment_id":"864355","timestamp":"1680920760.0"},{"poster":"piavik","timestamp":"1680728460.0","content":"Selected Answer: B\nKeywords:\nSaaS --> AppFlow\nOperational overhead (B) vs configuration overhead (A)","upvote_count":"4","comment_id":"862469"},{"timestamp":"1680458880.0","upvote_count":"3","poster":"xalien","comment_id":"859220","content":"Selected Answer: B\nAppFlow is for SaaS integrations:\nhttps://aws.amazon.com/appflow/"},{"timestamp":"1680269700.0","content":"Selected Answer: B\nAmazon AppFlow is a fully managed integration service that can help transfer data between SaaS applications and S3 buckets, making it an ideal solution for data collection from multiple sources. By using Amazon AppFlow, the company can remove the burden of creating and maintaining custom integrations, allowing them to focus on the core of their application. Additionally, by using S3 event notifications to trigger an Amazon SNS topic, the company can improve notification delivery times by removing the dependency on the EC2 instances.","poster":"linux_admin","comment_id":"857122","upvote_count":"4"},{"timestamp":"1674337620.0","content":"Selected Answer: A\nThis solution allows the EC2 instances to scale out as needed to handle the data processing and uploading, which will improve performance. Additionally, by configuring an S3 event notification to send a notification to an SNS topic when the upload is complete, the company can still receive the necessary notifications, but it eliminates the need for the same EC2 instance that is processing and uploading the data to also send the notifications, which further improves performance. This solution has less operational overhead as it only requires configuring S3 event notifications, SNS topic and AutoScaling group.","comment_id":"783752","upvote_count":"4","poster":"bullrem"},{"comment_id":"768163","timestamp":"1673052600.0","poster":"SilentMilli","content":"Selected Answer: B\nAmazon AppFlow is a fully managed integration service that enables the secure and easy transfer of data between popular software-as-a-service (SaaS) applications and AWS services. By using AppFlow, the company can easily set up integrations between SaaS sources and the S3 bucket, and the service will automatically handle the data transfer and transformation. The S3 event notification can then be used to send a notification to the user when the upload is complete, without the need to manage additional infrastructure or code. This solution would provide the required performance improvement and require minimal management, making it the most operationally efficient choice.","upvote_count":"4"},{"comment_id":"764659","poster":"techhb","timestamp":"1672751100.0","content":"Selected Answer: B\nAppflow only","upvote_count":"1"},{"comment_id":"759070","timestamp":"1672175820.0","comments":[{"timestamp":"1672175880.0","poster":"Buruguduystunstugudunstuy","upvote_count":"6","comment_id":"759071","content":"***INCORRECT ANSWERS***\n\nOption A is incorrect because creating an Auto Scaling group and configuring an S3 event notification does not address the root cause of the slow application performance, which is related to the data transfer process.\n\nOption C is incorrect because creating multiple EventBridge (CloudWatch Events) rules and configuring them to send events to an SNS topic is more complex and involves additional operational overhead.\n\nOption D is incorrect because creating a Docker container and hosting it on ECS does not address the root cause of the slow application performance, which is related to the data transfer process."}],"poster":"Buruguduystunstugudunstuy","content":"Selected Answer: B\nTo meet the requirements with the least operational overhead, the company could consider the following solution:\n\nOption B. Create an Amazon AppFlow flow to transfer data between each SaaS source and the S3 bucket. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete.\n\nAmazon AppFlow is a fully managed service that enables you to easily and securely transfer data between your SaaS applications and Amazon S3. By creating an AppFlow flow to transfer the data between the SaaS sources and the S3 bucket, the company can improve the performance of the application by offloading the data transfer process to a managed service.","upvote_count":"4"},{"timestamp":"1671562560.0","comment_id":"751358","upvote_count":"2","content":"Selected Answer: B\nB, AppFlow is a fuly managed integration service that automatically handles data transfer and transformation, so it's the one that requires the least opp overhead","poster":"pazabal"},{"timestamp":"1671428940.0","content":"Selected Answer: B\nOption B. App Flow usecase","comment_id":"749496","upvote_count":"1","poster":"career360guru"},{"comment_id":"747538","upvote_count":"2","poster":"NikaCZ","timestamp":"1671219780.0","content":"Selected Answer: B\nAppFlow = managed service SAAS"},{"upvote_count":"1","comment_id":"747537","timestamp":"1671219720.0","content":"AppFlow = managed service SAAS","poster":"NikaCZ"},{"comment_id":"723539","timestamp":"1669037160.0","upvote_count":"1","content":"B is Correct","poster":"Wpcorgan"},{"upvote_count":"1","timestamp":"1668923220.0","comment_id":"722413","poster":"Wajif","content":"Selected Answer: B\nChoosing B as it sounds simpler."},{"comment_id":"710205","upvote_count":"4","timestamp":"1667444520.0","content":"Selected Answer: B\nAppFlow is made for SaaS","poster":"peneloco"},{"comment_id":"709367","upvote_count":"4","poster":"rob74","timestamp":"1667326380.0","content":"Selected Answer: B\nAppFlow , managed service SAAS-->Least effort"},{"content":"Appflow works very well with SaaS platforms, makes a lot more sense in this scenario. Using an ASG might improve the performance, but here it asks for THE BEST PERFORMANCE, hence ASG might not fix the underlying issue in an efficient manner.","timestamp":"1666600020.0","comment_id":"702831","upvote_count":"1","poster":"Sinaneos"},{"content":"A is the answer, as it is the LEAST ops. overhead as asked. Minimal changes on current system.","comment_id":"701877","poster":"dave9994","timestamp":"1666494540.0","upvote_count":"1"},{"comment_id":"698328","poster":"yd_h","content":"Amazon AppFlow is a bi-directional data transfer service; however, not all source-destination combinations are currently supported. The question does not imply any SaaS providers. It could be any SaaS provider (https://docs.aws.amazon.com/appflow/latest/userguide/requirements.html)","comments":[{"poster":"yd_h","upvote_count":"1","comment_id":"698330","content":"I will go with A. LEAST operational overhead to add an ASG to the existing ec2 instances let S3 handle the notification part.","timestamp":"1666108080.0"}],"upvote_count":"1","timestamp":"1666107960.0"},{"comment_id":"697038","content":"Selected Answer: B\nAmazon AppFlow is a fully managed integration service that enables you to securely transfer data between Software-as-a-Service (SaaS) applications like Salesforce, SAP, Zendesk, Slack, and ServiceNow, and AWS services like Amazon S3 and Amazon Redshift, in just a few clicks.\nhttps://aws.amazon.com/appflow/","poster":"123jhl0","upvote_count":"2","timestamp":"1665990960.0"},{"content":"Amazon AppFlow is a fully managed integration service that enables you to securely transfer data between Software-as-a-Service (SaaS) applications like Salesforce, Marketo, Slack, and ServiceNow, and AWS services like Amazon S3 and Amazon Redshift, in just a few clicks. With AppFlow, you can run data flows at nearly any scale at the frequency you choose - on a schedule, in response to a business event, or on demand.","poster":"KVK16","upvote_count":"2","timestamp":"1665847440.0","comment_id":"695499"},{"timestamp":"1665727500.0","poster":"BoboChow","upvote_count":"2","comments":[{"timestamp":"1665728160.0","comments":[{"content":"Yes I agree it is B.","poster":"alvarez100","timestamp":"1665864660.0","comment_id":"695698","upvote_count":"2"}],"poster":"BoboChow","comment_id":"694541","upvote_count":"4","content":"I chang to B\nhttps://aws.amazon.com/appflow/?nc1=h_ls"}],"comment_id":"694534","content":"Selected Answer: A\nHow EventBridge loads data to S3?"}],"answer_ET":"B","question_id":366,"question_images":[],"question_text":"A company's application integrates with multiple software-as-a-service (SaaS) sources for data collection. The company runs Amazon EC2 instances to receive the data and to upload the data to an Amazon S3 bucket for analysis. The same EC2 instance that receives and uploads the data also sends a notification to the user when an upload is complete. The company has noticed slow application performance and wants to improve the performance as much as possible.\nWhich solution will meet these requirements with the LEAST operational overhead?","topic":"1","choices":{"D":"Create a Docker container to use instead of an EC2 instance. Host the containerized application on Amazon Elastic Container Service (Amazon ECS). Configure Amazon CloudWatch Container Insights to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete.","B":"Create an Amazon AppFlow flow to transfer data between each SaaS source and the S3 bucket. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete.","C":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule for each SaaS source to send output data. Configure the S3 bucket as the rule's target. Create a second EventBridge (Cloud Watch Events) rule to send events when the upload to the S3 bucket is complete. Configure an Amazon Simple Notification Service (Amazon SNS) topic as the second rule's target.","A":"Create an Auto Scaling group so that EC2 instances can scale out. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete."}},{"id":"e5Qaylcx3ZuV1P6wPB6G","answer_ET":"B","question_id":367,"question_images":[],"topic":"1","discussion":[{"poster":"Buruguduystunstugudunstuy","timestamp":"1711399920.0","comment_id":"850452","upvote_count":"12","content":"Selected Answer: B\nThe solution that will meet the requirement of ensuring that all data that is written to the EBS volumes is encrypted at rest is B. Create the EBS volumes as encrypted volumes and attach the encrypted EBS volumes to the EC2 instances.\n\nWhen you create an EBS volume, you can specify whether to encrypt the volume. If you choose to encrypt the volume, all data written to the volume is automatically encrypted at rest using AWS-managed keys. You can also use customer-managed keys (CMKs) stored in AWS KMS to encrypt and protect your EBS volumes. You can create encrypted EBS volumes and attach them to EC2 instances to ensure that all data written to the volumes is encrypted at rest.\n\nAnswer A is incorrect because attaching an IAM role to the EC2 instances does not automatically encrypt the EBS volumes.\n\nAnswer C is incorrect because adding an EC2 instance tag does not ensure that the EBS volumes are encrypted."},{"comment_id":"1056265","timestamp":"1730133720.0","poster":"Kds53829","content":"B is the answer","upvote_count":"2"},{"comment_id":"992343","poster":"Guru4Cloud","timestamp":"1724859420.0","content":"Selected Answer: B\nB. Create the EBS volumes as encrypted volumes. Attach the EBS volumes to the EC2 instances.","upvote_count":"2"},{"content":"Selected Answer: B\nWindows client = Amazon FSx for Windows File Server","comments":[{"upvote_count":"5","poster":"TariqKipkemei","comment_id":"1053498","timestamp":"1729835820.0","content":"ignore this, mind stuck on last question hhhhhh.\nJust create the EBS volumes as encrypted volumes then attach the EBS volumes to the EC2 instances."}],"timestamp":"1716612480.0","upvote_count":"2","comment_id":"906359","poster":"TariqKipkemei"},{"timestamp":"1711857780.0","upvote_count":"2","comment_id":"856582","poster":"elearningtakai","content":"Selected Answer: B\nThe other options either do not meet the requirement of encrypting data at rest (A and C) or do so in a more complex or less efficient manner (D)."},{"content":"Why not D, EBS encryption require the use of KMS key","comment_id":"846258","comments":[{"content":"Answer D is incorrect because creating a KMS key policy that enforces EBS encryption does not automatically encrypt EBS volumes. You need to create encrypted EBS volumes and attach them to EC2 instances to ensure that all data written to the volumes are encrypted at rest.","comment_id":"850450","upvote_count":"10","timestamp":"1711399800.0","poster":"Buruguduystunstugudunstuy"}],"timestamp":"1711047120.0","poster":"Bofi","upvote_count":"1"},{"upvote_count":"3","comment_id":"844545","content":"Selected Answer: B\nCreate encrypted EBS volumes and attach encrypted EBS volumes to EC2 instances..","poster":"WherecanIstart","timestamp":"1710910380.0"},{"poster":"sitha","comment_id":"836038","content":"Use Amazon EBS encryption as an encryption solution for your EBS resources associated with your EC2 instances.Select KMS Keys either default or custom","upvote_count":"2","timestamp":"1710164040.0"},{"timestamp":"1710130320.0","comment_id":"835647","content":"Answer B. You can enable encryption for EBS volumes while creating them.","upvote_count":"2","poster":"Ruhi02"},{"content":"Selected Answer: B\nbbbbbbbb","poster":"[Removed]","comment_id":"835221","timestamp":"1710087960.0","upvote_count":"2"}],"answers_community":["B (100%)"],"unix_timestamp":1678465560,"choices":{"D":"Create an AWS Key Management Service (AWS KMS) key policy that enforces EBS encryption in the account. Ensure that the key policy is active.","B":"Create the EBS volumes as encrypted volumes. Attach the EBS volumes to the EC2 instances.","C":"Create an EC2 instance tag that has a key of Encrypt and a value of True. Tag all instances that require encryption at the EBS level.","A":"Create an IAM role that specifies EBS encryption. Attach the role to the EC2 instances."},"url":"https://www.examtopics.com/discussions/amazon/view/102187-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company is deploying a new application on Amazon EC2 instances. The application writes data to Amazon Elastic Block Store (Amazon EBS) volumes. The company needs to ensure that all data that is written to the EBS volumes is encrypted at rest.\n\nWhich solution will meet this requirement?","isMC":true,"answer_description":"","answer":"B","answer_images":[],"exam_id":31,"timestamp":"2023-03-10 17:26:00"},{"id":"xGFZBw5yCNY8LWZvbpF1","question_id":368,"choices":{"A":"Amazon DynamoDB","B":"Amazon RDS for MySQL","C":"MySQL-compatible Amazon Aurora Serverless","D":"MySQL deployed on Amazon EC2 in an Auto Scaling group"},"question_images":[],"discussion":[{"timestamp":"1696222740.0","content":"Selected Answer: C\nC: Aurora Serverless is a MySQL-compatible relational database engine that automatically scales compute and memory resources based on application usage. no upfront costs or commitments required. \nA: DynamoDB is a NoSQL\nB: Fixed cost on RDS class\nD: More operation requires","upvote_count":"12","poster":"channn","comment_id":"858528"},{"timestamp":"1695667560.0","poster":"Buruguduystunstugudunstuy","comment_id":"850449","upvote_count":"6","content":"Selected Answer: C\nAnswer C, MySQL-compatible Amazon Aurora Serverless, would be the best solution to meet the company's requirements.\n\nAurora Serverless can be a cost-effective option for databases with sporadic or unpredictable usage patterns since it automatically scales up or down based on the current workload. Additionally, Aurora Serverless is compatible with MySQL, so it does not require any modifications to the application's database code."},{"comment_id":"1053511","upvote_count":"4","poster":"TariqKipkemei","timestamp":"1714026000.0","content":"Selected Answer: C\nThe is a huge demand for auto-scaling which Amazon RDS cannot do. This contributes to the cost savings as Aurora serverless would scale done in low peak times, this contributes to low costs."},{"poster":"JKevin778","timestamp":"1711513320.0","upvote_count":"1","comments":[{"upvote_count":"5","comment_id":"1110411","poster":"pentium75","timestamp":"1719732600.0","content":"RDS is cheaper than Aurora if you have a fixed instance size, but NOT if you have \"unpredictable\" usage patterns, then Aurora Serverless (!) is cheaper."}],"content":"Selected Answer: B\nRDS is cheaper than Aurora.","comment_id":"1018356"},{"timestamp":"1709229720.0","content":"Selected Answer: C\nAnswer C, MySQL-compatible Amazon Aurora Serverless, would be the best solution to meet the company's requirements.","poster":"Guru4Cloud","upvote_count":"2","comment_id":"993245"},{"content":"Selected Answer: C\nSince we have sporadic & unpredictable usage for DB, Aurora Serverless would be fit more cost-efficient for this case scenario than RDS MySQL. https://www.techtarget.com/searchcloudcomputing/answer/When-should-I-use-Amazon-RDS-vs-Aurora-Serverless","comment_id":"930921","upvote_count":"1","poster":"MrAWSAssociate","timestamp":"1703277300.0"},{"poster":"antropaws","content":"Selected Answer: C\nC for sure.","comment_id":"910020","upvote_count":"3","timestamp":"1701337260.0"},{"comments":[{"poster":"klayytech","timestamp":"1696194540.0","content":"sorry i will change to C , because\n\nAmazon RDS for MySQL is a fully-managed relational database service that makes it easy to set up, operate, and scale MySQL deployments in the cloud. Amazon Aurora Serverless is an on-demand, auto-scaling configuration for Amazon Aurora (MySQL-compatible edition), where the database will automatically start up, shut down, and scale capacity up or down based on your application’s needs. It is a simple, cost-effective option for infrequent, intermittent, or unpredictable workloads.","upvote_count":"3","comment_id":"858292"}],"timestamp":"1695632640.0","poster":"klayytech","content":"Selected Answer: B\nAmazon RDS for MySQL is a cost-effective database platform that will not require database modifications. It makes it easier to set up, operate, and scale MySQL deployments in the cloud. With Amazon RDS, you can deploy scalable MySQL servers in minutes with cost-efficient and resizable hardware capacity². \n\nAmazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. DynamoDB is a good choice for applications that require low-latency data access¹.\n\nMySQL-compatible Amazon Aurora Serverless is an on-demand, auto-scaling configuration for Amazon Aurora (MySQL-compatible edition), where the database will automatically start up, shut down, and scale capacity up or down based on your application's needs³.\n\nSo, Amazon RDS for MySQL is the best option for your requirements.","upvote_count":"2","comment_id":"850054"},{"upvote_count":"4","timestamp":"1694874600.0","poster":"boxu03","comment_id":"841182","content":"Selected Answer: C\nAmazon Aurora Serverless : a simple, cost-effective option for infrequent, intermittent, or unpredictable workloads"},{"timestamp":"1694356140.0","poster":"[Removed]","comment_id":"835223","content":"Selected Answer: C\ncccccccccccccccccccc","upvote_count":"2"}],"unix_timestamp":1678465740,"exam_id":31,"answer_description":"","answer_images":[],"answer":"C","question_text":"A company has a web application with sporadic usage patterns. There is heavy usage at the beginning of each month, moderate usage at the start of each week, and unpredictable usage during the week. The application consists of a web server and a MySQL database server running inside the data center. The company would like to move the application to the AWS Cloud, and needs to select a cost-effective database platform that will not require database modifications.\n\nWhich solution will meet these requirements?","topic":"1","timestamp":"2023-03-10 17:29:00","url":"https://www.examtopics.com/discussions/amazon/view/102188-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"C","isMC":true,"answers_community":["C (92%)","8%"]},{"id":"7dDxbH3fCGuCONiACtA5","unix_timestamp":1678465800,"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/102189-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"An image-hosting company stores its objects in Amazon S3 buckets. The company wants to avoid accidental exposure of the objects in the S3 buckets to the public. All S3 objects in the entire AWS account need to remain private.\n\nWhich solution will meet these requirements?","exam_id":31,"timestamp":"2023-03-10 17:30:00","answer_ET":"D","answer_images":[],"answers_community":["D (96%)","4%"],"choices":{"A":"Use Amazon GuardDuty to monitor S3 bucket policies. Create an automatic remediation action rule that uses an AWS Lambda function to remediate any change that makes the objects public.","B":"Use AWS Trusted Advisor to find publicly accessible S3 buckets. Configure email notifications in Trusted Advisor when a change is detected. Manually change the S3 bucket policy if it allows public access.","D":"Use the S3 Block Public Access feature on the account level. Use AWS Organizations to create a service control policy (SCP) that prevents IAM users from changing the setting. Apply the SCP to the account.","C":"Use AWS Resource Access Manager to find publicly accessible S3 buckets. Use Amazon Simple Notification Service (Amazon SNS) to invoke an AWS Lambda function when a change is detected. Deploy a Lambda function that programmatically remediates the change."},"topic":"1","isMC":true,"discussion":[{"timestamp":"1678508580.0","comment_id":"835651","poster":"Ruhi02","content":"Answer is D ladies and gentlemen. While guard duty helps to monitor s3 for potential threats its a reactive action. We should always be proactive and not reactive in our solutions so D, block public access to avoid any possibility of the info becoming publicly accessible","upvote_count":"21"},{"upvote_count":"10","comment_id":"850447","content":"Selected Answer: D\nAnswer D is the correct solution that meets the requirements. The S3 Block Public Access feature allows you to restrict public access to S3 buckets and objects within the account. You can enable this feature at the account level to prevent any S3 bucket from being made public, regardless of the bucket policy settings. AWS Organizations can be used to apply a Service Control Policy (SCP) to the account to prevent IAM users from changing this setting, ensuring that all S3 objects remain private. This is a straightforward and effective solution that requires minimal operational overhead.","timestamp":"1679776680.0","poster":"Buruguduystunstugudunstuy"},{"content":"its 1 aws account, how could D be the answer?","poster":"noircesar25","comments":[{"poster":"JA2018","content":"make no difference, 1 AWS account, 10 AWS accounts or > 100 AWS accounts, SCP enforces the same guard rails","upvote_count":"2","timestamp":"1732168380.0","comment_id":"1315665"}],"upvote_count":"1","comment_id":"1160985","timestamp":"1709067720.0"},{"upvote_count":"2","timestamp":"1698297180.0","comment_id":"1054291","poster":"TariqKipkemei","content":"Selected Answer: D\nUse the S3 Block Public Access feature on the account level. Use AWS Organizations to create a service control policy (SCP) that prevents IAM users from changing the setting. Apply the SCP to the account"},{"upvote_count":"2","comment_id":"992199","content":"Selected Answer: D\nUse the S3 Block Public Access feature on the account level. Use AWS Organizations to create a service control policy (SCP) that prevents IAM users from changing the setting. Apply the SCP to the account","timestamp":"1693227960.0","poster":"Guru4Cloud"},{"content":"Selected Answer: A\nA is correct!","comments":[{"content":"No, first it would not remove any existing public access (only detect changes), second it would just detect and then remediate, but in the meantime someone could access the objects. It's clearly D.","upvote_count":"3","poster":"pentium75","comment_id":"1110412","timestamp":"1704015120.0"}],"upvote_count":"1","poster":"MrAWSAssociate","timestamp":"1687460280.0","comment_id":"930938"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html","upvote_count":"4","comment_id":"902542","poster":"Yadav_Sanjay","timestamp":"1684582680.0"},{"content":"Selected Answer: D\nThis is the most effective solution to meet the requirements.","comment_id":"856917","poster":"elearningtakai","upvote_count":"3","timestamp":"1680259380.0"},{"upvote_count":"3","comment_id":"846262","content":"Selected Answer: D\nOption D provided real solution by using bucket policy to restrict public access. Other options were focus on detection which wasn't what was been asked","poster":"Bofi","timestamp":"1679425320.0"}],"question_images":[],"question_id":369,"answer_description":""},{"id":"jYAiLIhSom4WlSrenB3d","answer":"B","topic":"1","isMC":true,"choices":{"D":"Create a separate application tier using EC2 instances dedicated to email processing. Place the instances in an Auto Scaling group.","A":"Create a separate application tier using EC2 instances dedicated to email processing.","B":"Configure the web instance to send email through Amazon Simple Email Service (Amazon SES).","C":"Configure the web instance to send email through Amazon Simple Notification Service (Amazon SNS)."},"answer_images":[],"question_id":370,"timestamp":"2023-03-10 17:32:00","discussion":[{"timestamp":"1696070760.0","poster":"elearningtakai","comment_id":"856923","content":"Selected Answer: B\nAmazon SES is a cost-effective and scalable email service that enables businesses to send and receive email using their own email addresses and domains. Configuring the web instance to send email through Amazon SES is a simple and effective solution that can reduce the time spent resolving complex email delivery issues and minimize operational overhead.","upvote_count":"11"},{"poster":"Buruguduystunstugudunstuy","comment_id":"850439","content":"Selected Answer: B\nThe best option for addressing the company's needs of minimizing operational overhead and reducing time spent resolving email delivery issues is to use Amazon Simple Email Service (Amazon SES).\n\nAnswer A of creating a separate application tier for email processing may add additional complexity to the architecture and require more operational overhead.\n\nAnswer C of using Amazon Simple Notification Service (Amazon SNS) is not an appropriate solution for sending marketing and order confirmation emails since Amazon SNS is a messaging service that is designed to send messages to subscribed endpoints or clients.\n\nAnswer D of creating a separate application tier using EC2 instances dedicated to email processing placed in an Auto Scaling group is a more complex solution than necessary and may result in additional operational overhead.","timestamp":"1695666180.0","upvote_count":"6"},{"upvote_count":"2","comment_id":"1195116","timestamp":"1728848880.0","poster":"waldirlsantos","content":"Selected Answer: B\nB meet these requirements"},{"upvote_count":"3","poster":"TariqKipkemei","content":"Selected Answer: B\nAmazon Simple Email Service (Amazon SES) lets you reach customers confidently without an on-premises Simple Mail Transfer Protocol (SMTP) email server using the Amazon SES API or SMTP interface.","timestamp":"1714109100.0","comment_id":"1054297"},{"comment_id":"992183","poster":"Guru4Cloud","content":"Selected Answer: B\nB. Configure the web instance to send email through Amazon Simple Email Service (Amazon SES)","timestamp":"1709131800.0","upvote_count":"2"},{"content":"Answer is B","comment_id":"840704","poster":"nileshlg","upvote_count":"2","timestamp":"1694846760.0"},{"upvote_count":"5","content":"Answer B.. SES is meant for sending high volume e-mail efficiently and securely.\nSNS is meant as a channel publisher/subscriber service","timestamp":"1694399100.0","poster":"Ruhi02","comment_id":"835653"},{"content":"Selected Answer: B\nbbbbbbbb","timestamp":"1694356320.0","upvote_count":"2","comment_id":"835228","poster":"[Removed]"}],"unix_timestamp":1678465920,"url":"https://www.examtopics.com/discussions/amazon/view/102190-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"answer_description":"","question_text":"An ecommerce company is experiencing an increase in user traffic. The company’s store is deployed on Amazon EC2 instances as a two-tier web application consisting of a web tier and a separate database tier. As traffic increases, the company notices that the architecture is causing significant delays in sending timely marketing and order confirmation email to users. The company wants to reduce the time it spends resolving complex email delivery issues and minimize operational overhead.\n\nWhat should a solutions architect do to meet these requirements?","answers_community":["B (100%)"],"question_images":[],"answer_ET":"B"}],"exam":{"isMCOnly":true,"isBeta":false,"name":"AWS Certified Solutions Architect - Associate SAA-C03","provider":"Amazon","lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"id":31,"isImplemented":true},"currentPage":74},"__N_SSP":true}