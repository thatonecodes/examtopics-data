{"pageProps":{"questions":[{"id":"J8oOKhYHFZI2cGgb68LA","question_images":[],"question_id":781,"isMC":true,"discussion":[{"comment_id":"826246","content":"Selected Answer: A\nsat on this one for a while but i think ill settle for A.\nif you want to exclude regions you can use the SCP however some services a global resources so you use the Notaction to exempt the global services. If you want to allow roles to bypass the policy you can use the ArnNotLike and exclude certain admin roles from the SCP policy. This is NOT what we want to achieve, the goal is to block access to other regions, hence the System Manager roles should not be exempt. Where i'm slightly confused is how are we mandating the use of SSM? Users will be able to use any services within EU-WEST-2 including SSM.","poster":"[Removed]","upvote_count":"2","timestamp":"1677702780.0"},{"content":"Selected Answer: B\nSession Manager does not support cross-account access. You will need to assume a Role in account B (for example, from your user/role in account A) before starting the session.\n... it seems to be B...","upvote_count":"1","comment_id":"824991","timestamp":"1677599700.0","poster":"andras"},{"comment_id":"714756","timestamp":"1668013860.0","content":"A for me, does what is asked","upvote_count":"1","poster":"mrgreatness"},{"comment_id":"711139","upvote_count":"2","poster":"SureNot","content":"Selected Answer: A\nChoosing between A and B..\nCan't see a condition or any reason SSM should AVOID region restriction - so A.","timestamp":"1667565720.0"},{"content":"Selected Answer: B\nA) SSM not handled.\nB) region + SSM handled in SCP at root level ( ques says 'mandated')\nC) region handled at root with SCP + SSM left for accounts to handle( not 'mandated') and permission boundary cannot give perm if SCP denies it\nD) not at all centrally managed , needs SCP","comment_id":"705206","upvote_count":"2","poster":"nsvijay04b1","timestamp":"1666843140.0"},{"comment_id":"631832","comments":[{"comment_id":"631833","upvote_count":"1","timestamp":"1657897440.0","poster":"asfsdfsdf","content":"if question was stated the \nThe company's security team has required that all AWS accounts utilize AWS Systems Manager Session Manager on all regions - I would choose B"}],"content":"Selected Answer: A\nD will not work for sure - its applied to session manager only\nC will not work also its aagain applied to SSM profile and it will not grant access\nits either A or B - for B it means we will allow the SSM ARN role to work on all regions\nonly A left as the correct option - it will deny access to all regions with exception of eu-west-2 no need to do anything else as SSM is already allowed by SCP by default\nA - means we deny all access to other regions -","timestamp":"1657897380.0","upvote_count":"2","poster":"asfsdfsdf"},{"comment_id":"616325","poster":"Ddssssss","timestamp":"1655227260.0","upvote_count":"1","content":"Its not B because that would apply the SCP for all users except The session manager IAM which would allow that account to do whatever it wants. I would say \"D\", why cant a simple permissions boundary simply deny access for sessions manager to all other regions? Why does it need an SCP?"},{"content":"I am not too convinced with C nor A. How about B? SCP will have deny to run EC2 with condition ArnNotLike the session-manager-profile-role","timestamp":"1646258340.0","poster":"DLML","comment_id":"559706","upvote_count":"3"},{"upvote_count":"2","comments":[{"comment_id":"602236","comments":[{"upvote_count":"1","timestamp":"1656297360.0","comments":[{"comment_id":"622900","poster":"SeanQi","timestamp":"1656297540.0","upvote_count":"1","content":"I mean: choose B over C to reduce the complexity"}],"content":"yes, C is missing granting permission from iam role, but it's not the point here. choosing C over B is to reduce the complexity of the setup","comment_id":"622897","poster":"SeanQi"}],"timestamp":"1652637180.0","content":"C doesn't grant permission and don't override SCP","upvote_count":"2","poster":"bobsmith2000"},{"content":"B\nC is not a scalable solution, plus the root account can change it","upvote_count":"2","poster":"user0001","comment_id":"599815","timestamp":"1652232780.0"},{"timestamp":"1655227020.0","comment_id":"616321","upvote_count":"3","content":"Boundaries restrict access, they do not allow access.","poster":"Ddssssss"}],"content":"It's C.\n\n1. Create SCP policy to privent denies access to any operations outside of the specified Region.\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_general.html#example-scp-deny-region\n\n2. Create IAM Policy in each account from making certain changes\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html\n“\nsecurity team has required that all AWS accounts utilize AWS Systems Manager Session Manager \n“\nIAM must be configured to allow access.","poster":"Alexey79","comment_id":"555149","timestamp":"1645693140.0"},{"content":"It's C.","timestamp":"1643429100.0","upvote_count":"2","comment_id":"535165","poster":"Bigbearcn","comments":[{"content":"Permission boundaries don't grant permission and don't override SCP","upvote_count":"2","poster":"bobsmith2000","comment_id":"602238","timestamp":"1652637240.0"}]},{"upvote_count":"1","timestamp":"1642599480.0","comments":[{"timestamp":"1643351100.0","content":"why not C?","comments":[],"upvote_count":"1","comment_id":"534458","poster":"timlow84"},{"upvote_count":"3","timestamp":"1645561620.0","content":"Because in A there is no solution for Session managers. C answer cover both Regional restriction and Session managers.","poster":"usmanbaigmughal","comment_id":"553992"}],"comment_id":"527536","content":"why A?","poster":"GeniusMikeLiu"}],"answers_community":["A (67%)","B (33%)"],"answer_images":[],"question_text":"A company has a large number of AWS accounts in an organization in AWS Organizations. A different business group owns each account. All the AWS accounts are bound by legal compliance requirements that restrict all operations outside the eu-west-2 Region.\nThe company's security team has mandated the use of AWS Systems Manager Session Manager across all AWS accounts.\nWhich solution should a solutions architect recommend to meet these requirements?","topic":"1","timestamp":"2022-01-19 14:38:00","answer":"A","exam_id":32,"unix_timestamp":1642599480,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/70297-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"A":"Create an SCP that denies access to all requests that do not target eu-west-2. Use the NotAction element to exempt global services from the restriction. In AWS Organizations, apply the SCP to the root of the organization.","D":"For each AWS account, create an IAM permissions boundary that denies access to all requests that do not target eu-west-2. For each AWS account, apply the permissions boundary to the IAM role that is associated with the Session Manager instance profile.","B":"Create an SCP that denies access to all requests that do not target eu-west-2. Use the NotAction element to exempt global services from the restriction. For each AWS account, use the AmNotLike condition key to add the ARN of the IAM role that is associated with the Session Manager instance profile to the condition element of the SCP. In AWS Organizations apply, the SCP to the root of the organization.","C":"Create an SCP that denies access to all requests that do not target eu-west-2. Use the NotAction element to exempt global services from the restriction. In AWS Organizations, apply the SCP to the root of the organization. In each AWS account, create an IAM permissions boundary that allows access to the IAM role that is associated with the Session Manager instance profile."},"answer_ET":"A"},{"id":"DmjEiI3kF1YitFZZIIbi","question_text":"A company uses AWS Organizations. The company has an organization that has a central management account. The company plans to provision multiple AWS accounts for different departments. All department accounts must be a member of the company's organization.\nCompliance requirements state that each account must have only one VPC. Additionally, each VPC must have an identical network security configuration that includes fully configured subnets, gateways, network ACLs, and security groups.\nThe company wants this security setup to be automatically applied when a new department account is created. The company wants to use the central management account for all security operations, but the central management account should not have the security setup.\nWhich approach meets these requirements with the LEAST amount of setup?","question_images":[],"choices":{"D":"Invite department accounts to the company's organization. From the central management account, create an AWS CloudFormation template that includes the VPC and the network security configurations. Create an AWS Lambda function that will deploy the VPC and the network security setup to the newly created account. Create an event that watches for account creation. Configure the event to invoke the pipeline.","B":"Create a new organization with the central management account. Invite all AWS department accounts into the new organization. From the central management account, create an AWS CloudFormation template that includes the VPC and the network security configurations. Create a CloudFormation stack that is based on this template. Apply the CloudFormation stack to the newly created organization.","A":"Create an OU within the company's organization. Add department accounts to the OU. From the central management account, create an AWS CloudFormation template that includes the VPC and the network security configurations. Create a CloudFormation stack set by using this template file with automated deployment enabled. Apply the CloudFormation stack set to the OU.","C":"Invite department accounts to the company's organization. From the central management account, create an AWS CloudFormation template that includes the VPC and the network security configurations. Create an AWS CodePipeline pipeline that will deploy the network security setup to the newly created account. Specify the creation of an account as an event hook. Apply the event hook to the pipeline."},"timestamp":"2022-01-06 13:55:00","answer":"A","isMC":true,"answer_ET":"A","discussion":[{"upvote_count":"3","timestamp":"1664906340.0","content":"Selected Answer: A\nA\nC&D mention inviting accounts into the org. it doesnt state anywhere this needs to be done, says new accounts are to be provisioned.\nB mentions creating an org, but there already is one.\nleaves A by default.","comment_id":"686362","poster":"Ell89"},{"upvote_count":"4","poster":"asfsdfsdf","content":"Selected Answer: A\nonly A mention CF automatic deployment - Also the organization already has a management accounts and it about to create new ones \"The organization intends to create many Amazon Web Services accounts for various departments\" so no need to invite or create a new ORG","timestamp":"1657897980.0","comment_id":"631836"},{"upvote_count":"1","poster":"cannottellname","comment_id":"536003","timestamp":"1643530620.0","content":"AAAAAA"},{"timestamp":"1642841040.0","comment_id":"529696","comments":[{"poster":"tkanmani76","comment_id":"529699","timestamp":"1642841220.0","content":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-orgs-manage-auto-deployment.html","upvote_count":"2"}],"poster":"tkanmani76","upvote_count":"4","content":"A - https://aws.amazon.com/blogs/aws/new-use-aws-cloudformation-stacksets-for-multiple-accounts-in-an-aws-organization/"},{"timestamp":"1642092000.0","upvote_count":"2","content":"https://aws.amazon.com/blogs/security/how-to-use-aws-organizations-to-automate-end-to-end-account-creation/","poster":"CloudChef","comment_id":"522951"},{"content":"B \"automated deployment enabled\"? Not seeing how this is possible in answer A.","comment_id":"522949","comments":[{"comment_id":"695688","timestamp":"1665864240.0","upvote_count":"1","content":"I think it's possible : https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-orgs-manage-auto-deployment.html","poster":"wassb"}],"poster":"CloudChef","upvote_count":"2","timestamp":"1642091940.0"},{"upvote_count":"2","timestamp":"1641886200.0","comment_id":"521351","poster":"pititcu667","content":"i will go with a since the the aws organization is already configured why make a new one when you can just add an OU?"},{"comment_id":"518231","content":"Why not A?","timestamp":"1641473700.0","comments":[{"timestamp":"1641905220.0","poster":"Tokyoboy","comment_id":"521536","content":"Existing accounts have to be invited into the OU.","upvote_count":"2"}],"poster":"GeniusMikeLiu","upvote_count":"2"}],"answer_description":"","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/69584-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"exam_id":32,"question_id":782,"topic":"1","unix_timestamp":1641473700},{"id":"yt8ZCNBQLsItdlT5JMQ4","question_text":"A company owns a chain of travel agencies and is running an application in the AWS Cloud. Company employees use the application to search for information about travel destinations. Destination content is updated four times each year.\nTwo fixed Amazon EC2 instances serve the application. The company uses an Amazon Route 53 public hosted zone with a multivalue record of travel.example.com that returns the Elastic IP addresses for the EC2 instances. The application uses Amazon DynamoDB as its primary data store. The company uses a self-hosted Redis instance as a caching solution.\nDuring content updates, the load on the EC2 instances and the caching solution increases drastically. This increased load has led to downtime on several occasions. A solutions architect must update the application so that the application is highly available and can handle the load that is generated by the content updates.\nWhich solution will meet these requirements?","question_images":[],"choices":{"A":"Set up DynamoDB Accelerator (DAX) as in-memory cache. Update the application to use DAX. Create an Auto Scaling group for the EC2 instances. Create an Application Load Balancer (ALB). Set the Auto Scaling group as a target for the ALB. Update the Route 53 record to use a simple routing policy that targets the ALB's DNS alias. Configure scheduled scaling for the EC2 instances before the content updates.","C":"Set up Amazon ElastiCache for Memcached. Update the application to use ElastiCache Create an Auto Scaling group for the EC2 instances. Create an Application Load Balancer (ALB). Set the Auto Scaling group as a target for the ALB. Update the Route 53 record to use a simple routing policy that targets the ALB's DNS alias. Configure scheduled scaling for the application before the content updates.","B":"Set up Amazon ElastiCache for Redis. Update the application to use ElastiCache. Create an Auto Scaling group for the EC2 instances. Create an Amazon CloudFront distribution, and set the Auto Scaling group as an origin for the distribution. Update the Route 53 record to use a simple routing policy that targets the CloudFront distribution's DNS alias. Manually scale up EC2 instances before the content updates.","D":"Set up DynamoDB Accelerator (DAX) as in-memory cache. Update the application to use DAX. Create an Auto Scaling group for the EC2 instances. Create an Amazon CloudFront distribution, and set the Auto Scaling group as an origin for the distribution. Update the Route 53 record to use a simple routing policy that targets the CloudFront distribution's DNS alias. Manually scale up EC2 instances before the content updates."},"timestamp":"2022-01-31 20:27:00","answer":"A","isMC":true,"answer_ET":"A","discussion":[{"content":"Answer is A. DynamoDB Accelerator (DAX) is a fully managed, custom cache for DynamoDB. ElastiCache supports both Redis and Memcached and typically used to cache results from relational databases","upvote_count":"7","comment_id":"548254","poster":"AndySH","timestamp":"1644978780.0"},{"comments":[{"content":"I was wrong. I didn't notice:\n-> Create an Amazon CloudFront distribution, and set the Auto Scaling group as an origin for the distribution.\n\nYou can't have an ASG as an origin, which disqualifies this answer.","timestamp":"1710716280.0","upvote_count":"1","poster":"minmax","comment_id":"1176106"}],"comment_id":"1176098","upvote_count":"1","content":"Selected Answer: B\nCorrect answer is B\n-> During content updates, the load on the EC2 instances and the caching solution increases drastically\n\nThe EC2 and Redis are the components that are in most need of an upgrade.","timestamp":"1710715320.0","poster":"minmax"},{"poster":"evargasbrz","timestamp":"1672682820.0","content":"Selected Answer: A\nI'll go with A\nIt's not possible to configure an Auto Scaling group as an origin for the distribution, so B is wrong.","upvote_count":"1","comment_id":"763898"},{"content":"Selected Answer: B\nKey points \n-> he company uses a self-hosted Redis instance as a caching solution. ( Managed Redis is obvious choice as you would make use of existing redis cache data migrated , DAX is overkill here micro secs latency ? really? )\n-> During content updates, the load on the EC2 instances and the caching solution increases drastically. ( Need cloudfront as well, as load is on EC2 too not only DB)","upvote_count":"1","timestamp":"1666846800.0","comment_id":"705236","poster":"nsvijay04b1","comments":[{"content":"A: The load is during *update* and on EC2 and Redis because the EC2 instance is writing to both Redis as well as DynamoDB for each update. DAX is a write through cache = 1 write only.\n\nhttps://aws.amazon.com/blogs/database/amazon-dynamodb-accelerator-dax-a-read-throughwrite-through-cache-for-dynamodb/\n\nCloudfront won't help here.","upvote_count":"1","poster":"Byrney","timestamp":"1667949120.0","comment_id":"714150"}]},{"timestamp":"1657898400.0","content":"Selected Answer: A\nCF cant point to an ASG so B and D are out - MemCached is not HA so its out only A left","comment_id":"631837","poster":"asfsdfsdf","upvote_count":"4"},{"poster":"Bigbearcn","comments":[{"content":"Yet the content is \"static\" because it only gets updated 4 times a year? A makes sense but b and d are good alternatives. Go with A.","upvote_count":"2","timestamp":"1648627620.0","poster":"adsdadasdad","comment_id":"578137"}],"upvote_count":"2","content":"Selected Answer: A\nIt's A. B or D is wrong because cloudfront is not needed in this case.","timestamp":"1643657220.0","comment_id":"537360"}],"answer_description":"","answers_community":["A (78%)","B (22%)"],"url":"https://www.examtopics.com/discussions/amazon/view/70883-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"exam_id":32,"question_id":783,"topic":"1","unix_timestamp":1643657220},{"id":"NLMBfEJrOL0tny6dw6kk","answer_ET":"ABC","question_text":"A medical company is building a data lake on Amazon S3. The data must be encrypted in transit and at rest. The data must remain protected even if S3 bucket is inadvertently made public.\nWhich combination of steps will meet these requirements? (Choose three.)","exam_id":32,"isMC":true,"answers_community":["ABC (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/69086-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"content":"Selected Answer: ABC\nis ABC \nnot ACD\nwhy ? the option C \"force\" choose the B by \"aws:kms\" condition","comment_id":"946841","upvote_count":"1","timestamp":"1688868840.0","poster":"SkyZeroZx"},{"comment_id":"631839","upvote_count":"4","poster":"asfsdfsdf","timestamp":"1657899180.0","content":"ABC - must use CMK to avoid public access of an unauthorized users (no access to the key)\nMust enforce header of aws:KMS in order to make sure all object are encrypted with CMK (SSE-KMS) \nFinally need to make sure aws:SecureTransport is set to true which means SSL"},{"comment_id":"577926","content":"In order to enforce object encryption, create an S3 bucket policy that denies any S3 Put request that does not include the x-amz-server-side-encryption header. There are two possible values for the x-amz-server-side-encryption header: AES256, which tells S3 to use S3-managed keys, and aws:kms, which tells S3 to use AWS KMS–managed keys.","upvote_count":"1","timestamp":"1648596360.0","poster":"RVD"},{"upvote_count":"1","comment_id":"569511","timestamp":"1647502380.0","poster":"kenchou73","content":"Selected Answer: ABC\nDue to the requirement of the Data Lake, ABC is better than ADE. That needs SSE-KMS but not SSE-S3.\nhttps://aws.amazon.com/blogs/big-data/build-secure-encrypted-data-lakes-with-aws-lake-formation/"},{"timestamp":"1647462120.0","content":"A,B,C is correct. In my opinion, If you are using SSE-S3 since you have access to the bucket, S3 service will automatically decrypt the file for you, but with SSE-KMS we have:\n\"To upload an object encrypted with an AWS KMS key to Amazon S3, you need kms:GenerateDataKey permissions on the key. To download an object encrypted with an AWS KMS key, you need kms:Decrypt permissions.\", from https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingKMSEncryption.html\nThen, just making the S3 bucket public is not enough to have access to files, you also need access to KMS.","comment_id":"569304","upvote_count":"2","poster":"Serial_X25"},{"content":"I'll go ABC\nA - to use encryption at rest SSL should be enabled\nB - Create Key\nC - Require Key on PutObject","timestamp":"1643198760.0","comment_id":"532864","upvote_count":"1","poster":"panton"},{"poster":"wahlbergusa","comment_id":"513543","content":"A,B,C is correct. Reason SSE-S3 is not appropriate is that if the user has access privileges to S3 then they will automatically have access to the S3 key as well.","timestamp":"1640883900.0","comments":[{"upvote_count":"3","timestamp":"1642046340.0","comments":[{"content":"Not sure I understand. There is segregation of duties on SSE-KMS, you can assign a key policy to the KMS Key. Hence the reason it is more secure in terms of access controls to the service.","poster":"wahlbergusa","upvote_count":"1","comment_id":"528834","timestamp":"1642718460.0"}],"poster":"Bigbearcn","comment_id":"522617","content":"I don't agree. SSE-S3 and SSE-KMS are same secure. The difference is who manage the key. ABC is a combination solution, but D isn't."}],"upvote_count":"1"}],"answer_description":"To determine HTTP or HTTPS requests in a bucket policy, use a condition that checks for the key \"aws:SecureTransport\". When this key is true, then request is sent through HTTPS. To comply with the s3-bucket-ssl-requests-only rule, create a bucket policy that explicitly denies access when the request meets the condition \"aws:SecureTransport\": \"false\". This policy explicitly denies access to HTTP requests.\nWhen you create an object, you can specify the use of server-side encryption with AWS Key Management Service (AWS KMS) keys to encrypt your data. This is true when you are either uploading a new object or copying an existing object. This encryption is known as SSE-KMS.\nEnforce object encryption, create an S3 bucket policy that denies any S3 Put request that does not include the x-amz-server-side-encryption header.\nReference:\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-bucket-policy-for-config-rule/ https://docs.aws.amazon.com/AmazonS3/latest/userguide/specifying-kms-encryption.html https://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/","unix_timestamp":1640883900,"choices":{"C":"Ensure that each S3 bucket has a bucket policy that includes a Deny statement for PutObject actions if the request does not include an ג€s3:x-amz-server-side- encryptionג€:ג€aws:kmsג€ condition.","F":"Turn on AWS Config. Use the s3-bucket-public-read-prohibited, s3-bucket-public-write-prohibited, and s3-bucket-ssl-requests-only AWS Config managed rules to monitor the S3 buckets.","B":"Create a CMK in AWS Key Management Service (AWS KMS). Turn on server-side encryption (SSE) on the S3 buckets, select SSE-KMS for the encryption type, and use the CMK as the key.","E":"Ensure that each S3 bucket has a bucket policy that includes a Deny statement for PutObject actions if the request does not include an ג€s3:x-amz-server-side- encryptionג€:ג€AES256ג€ condition.","A":"Ensure that each S3 bucket has a bucket policy that includes a Deny statement if the aws:SecureTransport condition is not present.","D":"Turn on server-side encryption (SSE) on the S3 buckets and select SSE-S3 for the encryption type."},"topic":"1","question_id":784,"question_images":[],"timestamp":"2021-12-30 18:05:00","answer_images":[],"answer":"ABC"},{"id":"6IqKhSl0WaJqpS6plDSJ","unix_timestamp":1641321300,"answer_images":[],"answer":"AC","url":"https://www.examtopics.com/discussions/amazon/view/69470-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"timestamp":"1641321300.0","comment_id":"516901","content":"Answer is A & C","poster":"Smartphone","upvote_count":"13"},{"comment_id":"1299492","timestamp":"1729210260.0","upvote_count":"1","poster":"Sin_Dan","content":"Selected Answer: AC\nI don't know why people are voting for B and especially D. You don't need to add operational complexity and cost by adding an entire stack."},{"content":"Selected Answer: BC\nRS Proxy is supported by Aurora Serverless v2!\nHowever, the question is asking about improvements to latency. That's why E is not correct. \n\nAlso, there's no such thing as Transfer Acceleration signed URL's.","upvote_count":"1","timestamp":"1697206680.0","poster":"kiwtirApp","comments":[{"content":"Yes there is, https://stackoverflow.com/questions/37437782/aws-transfer-acceleration-with-pre-signed-urls-using-javascript-sdk","comment_id":"1112936","timestamp":"1704299760.0","poster":"jpa8300","upvote_count":"1"}],"comment_id":"1042739"},{"upvote_count":"1","content":"You would not be storing the uploads in the same bucket as the static website run out of, as you cannot use KMS encryption and the bucket has to have public access enabled etc, thus this would be a separate uploads bucket being used, thus Transfer Acceleration would be appropriate\n\nObjects in the bucket must be publicly accessible.\nS3 bucket policy must allow access to the s3:GetObject action.\nThe AWS account that owns the bucket must also own the object.\nObjects can't be encrypted by AWS Key Management Service (AWS KMS).\nObjects that are requested must exist in the S3 bucket.\nAmazon S3 Block Public Access must be disabled on the bucket and account level.","comment_id":"912859","timestamp":"1685713320.0","poster":"Darkhorse_79"},{"upvote_count":"2","comment_id":"905032","timestamp":"1684854840.0","poster":"dev112233xx","content":"Selected Answer: CD\nA is wrong! can someone explain what they mean by \"Ensure that the web application uses the Transfer Acceleration signed URLs\"??? it's definitely a trap ... most of you will pick this answer just because of this \"S3 Transfer Acceleration\" but the second part is a wrong. That's why you always need to read every word of the answer...\nB: is also wrong, can't use Global Accelerator with CF\nE: is also wrong!. RDS Proxy doesn't support Aurora Serverless"},{"content":"Selected Answer: AC\nD is wrong because question asked for improvement. nor re-architect.\nB is not apt here although it improves networking performance because use case here is for S3 uploads.\nE is wrong because there is no need of RDS proxy which can help improve performance","comments":[{"poster":"God_Is_Love","timestamp":"1677957360.0","content":"RDS proxy improves connection pooling mainly","comment_id":"829297","upvote_count":"1"}],"timestamp":"1677957300.0","poster":"God_Is_Love","comment_id":"829296","upvote_count":"2"},{"timestamp":"1677704520.0","comments":[{"comment_id":"911748","poster":"chathur","timestamp":"1685596320.0","content":"Aurora serverless supports Global Databases\nhttps://aws.amazon.com/rds/aurora/serverless/#:~:text=Highly%20available,and%20read%20replicas.","upvote_count":"3"}],"poster":"[Removed]","upvote_count":"2","comment_id":"826270","content":"Selected Answer: AC\nD + E are out as per AWS documentation, B doesnt make snense, already using CF. A & C make the most sense \n\nAurora Serverless v1 doesn't support the following features:\n\nAurora global databases\n\nAurora Replicas\n\nAWS Identity and Access Management (IAM) database authentication\n\nBacktracking in Aurora\n\nDatabase activity streams\n\nKerberos authentication\n\nPerformance Insights\n\nRDS Proxy\n\nViewing logs in the AWS Management Console"},{"poster":"Ni_yot","content":"A and C for me. S3 Transfer speeds up the transfer and optimized edge endpoint reduces latency","timestamp":"1666274460.0","upvote_count":"1","comment_id":"699999"},{"timestamp":"1657900080.0","upvote_count":"4","comment_id":"631844","poster":"asfsdfsdf","content":"Selected Answer: AC\nAC\nGA is excluded since it cannot point to CF also no need GA if we use CF - this exclude B\nD is not needed too complicated\nso only ACE left - C for sure help, S3 transfer can help with upload times across the world\nE - will help if there were errors connecting to the DB and not latency issues\nso AC it is"},{"poster":"jj22222","comment_id":"577897","content":"Selected Answer: AC\nC and A look right here","timestamp":"1648592580.0","upvote_count":"2"},{"poster":"lifebegins","timestamp":"1646540220.0","upvote_count":"3","content":"It cannot be Global Accelerator. CloudFront and GA are diffrent services and diffrent purposes. \nhttps://aws.amazon.com/global-accelerator/faqs/","comment_id":"561776"},{"upvote_count":"1","poster":"lifebegins","comment_id":"561774","comments":[{"upvote_count":"2","poster":"tobstar86","comment_id":"561792","content":"https://aws.amazon.com/global-accelerator/faqs/\nGA good fit for.. \"as well as for HTTP use cases that specifically require static IP addresses or deterministic, fast regional failover.\"","timestamp":"1646546460.0"}],"content":"Global Accelerator is only for Non-HTTP Services such as UDP. Not for Http Apps","timestamp":"1646540160.0"},{"timestamp":"1645675320.0","comment_id":"555059","content":"For those choosing B, please justify your answer. Global Accelerator and CloudFront are 2 separate services, how can you attach a Global Accelerator to CF? That option is not available as far as I can see. So based on elimination have to go with A and C","upvote_count":"4","poster":"jyrajan69"},{"poster":"Bigbearcn","content":"Selected Answer: AC\nAAA CCC","comment_id":"546213","timestamp":"1644724440.0","upvote_count":"3"},{"comment_id":"540439","poster":"Clandestine60","upvote_count":"4","timestamp":"1643981760.0","content":"Selected Answer: BD\ni`ll go with BD. Global accelerators don`t have cloudfront as their endpoints\n\"For standard accelerators, the endpoints are Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses. For custom routing accelerators, endpoints are virtual private cloud (VPC) subnets with one or more EC2 instances. The static IP addresses accept incoming traffic onto the AWS global network from the edge location that is closest to your users.\"\nhttps://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-how-it-works.html"},{"upvote_count":"1","timestamp":"1643900640.0","content":"Why not D?","comment_id":"539775","poster":"vampiret","comments":[{"comment_id":"697218","timestamp":"1665998460.0","poster":"Cloudxie","upvote_count":"1","content":"No global aurora serverless db"}]},{"timestamp":"1643521800.0","upvote_count":"2","content":"Accelerator can attach to ALB or NLB but not cloudfront\nI vote for A and C","comment_id":"535960","poster":"saeidp"},{"upvote_count":"1","poster":"Trueguy","timestamp":"1642912920.0","comment_id":"530252","content":"BC it seems"},{"content":"BC - An edge-optimized API endpoint is best for geographically distributed clients. API requests are routed to the nearest CloudFront Point of Presence (POP). This is the default endpoint type for API Gateway REST APIs.","comment_id":"528268","poster":"tkanmani76","timestamp":"1642668660.0","upvote_count":"3"},{"poster":"pititcu667","comment_id":"525851","content":"Selected Answer: BC\ni think b and c is correct. Because s3 is not exposed directly and we already use cf and there is no talk about provisioning in new regios hence not d.","upvote_count":"1","timestamp":"1642430640.0"},{"comment_id":"522268","upvote_count":"1","content":"B,D. Not A since there is a deployed CF distribution","poster":"lucesarano","timestamp":"1642002000.0","comments":[{"content":"I meant B,C.","timestamp":"1642002060.0","comment_id":"522270","upvote_count":"1","poster":"lucesarano"}]}],"question_images":[],"choices":{"D":"Provision the entire stack in two other locations that are spread across the world. Use global databases on the Aurora Serverless cluster.","E":"Add an Amazon RDS proxy between the Lambda functions and the Aurora Serverless database.","C":"Change the API Gateway Regional endpoints to edge-optimized endpoints.","A":"Enable S3 Transfer Acceleration on the S3 bucket. Ensure that the web application uses the Transfer Acceleration signed URLs.","B":"Create an accelerator in AWS Global Accelerator. Attach the accelerator to the CloudFront distribution."},"timestamp":"2022-01-04 19:35:00","topic":"1","exam_id":32,"question_text":"A company is building an electronic document management system in which users upload their documents. The application stack is entirely serverless and runs on AWS in the eu-central-1 Region. The system includes a web application that uses an Amazon CloudFront distribution for delivery with Amazon S3 as the origin.\nThe web application communicates with Amazon API Gateway Regional endpoints. The API Gateway APIs call AWS Lambda functions that store metadata in an\nAmazon Aurora Serverless database and put the documents into an S3 bucket.\nThe company is growing steadily and has completed a proof of concept with its largest customer. The company must improve latency outside of Europe\nWhich combination of actions will meet these requirements? (Choose two.)","question_id":785,"answer_description":"","answer_ET":"AC","isMC":true,"answers_community":["AC (64%)","BD (18%)","Other"]}],"exam":{"lastUpdated":"11 Apr 2025","isMCOnly":false,"name":"AWS Certified Solutions Architect - Professional","isBeta":false,"numberOfQuestions":1019,"id":32,"isImplemented":true,"provider":"Amazon"},"currentPage":157},"__N_SSP":true}