{"pageProps":{"questions":[{"id":"KnRjmKcKNmSvEtNtyuXN","timestamp":"2021-11-15 16:27:00","question_id":61,"topic":"1","answer_description":"","question_text":"A company released a mobile game that quickly grew to 10 million daily active users in North America. The game's backend is hosted on AWS and makes extensive use of an Amazon DynamoDB table that is configured with a TTL attribute.\nWhen an item is added or updated, its TTL is set to the current epoch time plus 600 seconds. The game logic relies on old data being purged so that it can calculate rewards points accurately. Occasionally, items are read from the table that are several hours past their TTL expiry.\nHow should a database specialist fix this issue?","exam_id":22,"answer_ET":"B","isMC":true,"discussion":[{"poster":"toppic26","upvote_count":"8","content":"Answer is B https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/howitworks-ttl.html","comment_id":"478773","timestamp":"1636990020.0"},{"upvote_count":"2","comment_id":"701603","poster":"Satprave","content":"Selected Answer: B\nB\nItems that have expired, but haven’t yet been deleted by TTL, still appear in reads, queries, and scans. If you do not want expired items in the result set, you must filter them out. To do this, use a filter expression that returns only items where the Time to Live expiration value is greater than the current time in epoch format. For more information, see Filter expressions for scan.","timestamp":"1666451760.0"},{"comment_id":"594770","content":"Selected Answer: B\nTTL expires recs, but delete process may run later","poster":"novice_expert","upvote_count":"1","timestamp":"1651281420.0"},{"upvote_count":"2","comment_id":"555707","timestamp":"1645757100.0","poster":"tugboat","content":"Selected Answer: B\nasync deletes via tel"},{"content":"Selected Answer: B\noption B","comment_id":"490579","upvote_count":"2","poster":"GMartinelli","timestamp":"1638267900.0"},{"content":"Selected Answer: B\nAnswer is B","comment_id":"490285","timestamp":"1638231420.0","poster":"jove","upvote_count":"2"}],"answer":"B","unix_timestamp":1636990020,"answers_community":["B (100%)"],"choices":{"D":"Create a local secondary index on the TTL attribute.","C":"Set the ConsistentRead parameter to true when querying the table.","B":"Include a query filter expression to ignore items with an expired TTL.","A":"Use a client library that supports the TTL functionality for DynamoDB."},"url":"https://www.examtopics.com/discussions/amazon/view/66079-exam-aws-certified-database-specialty-topic-1-question-153/","question_images":[],"answer_images":[]},{"id":"Bxy8ckdIuZImIhG5YY01","question_text":"A development team at an international gaming company is experimenting with Amazon DynamoDB to store in-game events for three mobile games. The most popular game hosts a maximum of 500,000 concurrent users, and the least popular game hosts a maximum of 10,000 concurrent users. The average size of an event is 20 KB, and the average user session produces one event each second. Each event is tagged with a time in milliseconds and a globally unique identifier.\nThe lead developer created a single DynamoDB table for the events with the following schema:\n✑ Partition key: game name\n✑ Sort key: event identifier\n✑ Local secondary index: player identifier\n✑ Event time\nThe tests were successful in a small-scale development environment. However, when deployed to production, new events stopped being added to the table and the logs show DynamoDB failures with the ItemCollectionSizeLimitExceededException error code.\nWhich design change should a database specialist recommend to the development team?","answer_description":"","topic":"1","isMC":true,"answer_images":[],"answer":"D","question_images":[],"answer_ET":"D","timestamp":"2021-11-21 22:11:00","choices":{"A":"Use the player identifier as the partition key. Use the event time as the sort key. Add a global secondary index with the game name as the partition key and the event time as the sort key.","D":"Create one table for each game. Use the player identifier as the partition key. Use the event time as the sort key.","C":"Replace the sort key with a compound value consisting of the player identifier collated with the event time, separated by a dash. Add a local secondary index with the player identifier as the sort key.","B":"Create two tables. Use the game name as the partition key in both tables. Use the event time as the sort key for the first table. Use the player identifier as the sort key for the second table."},"answers_community":["D (79%)","A (21%)"],"discussion":[{"upvote_count":"7","content":"Selected Answer: D\nItemCollectionSizeLimitExceededException\nMessage: Collection size exceeded.\nFor a table with a local secondary index, a group of items with the same partition key value has exceeded the maximum size limit of 10 GB. For more information on item collections, see Item Collections.\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html\n\nProblem is too much data in partition cause issues with LocalSecondaryIndex.\none game_id had 500K users with 20K data per event = 10GB/event\n\nSolution is separate table for game and partition by player_id\nEach table will have max 500000 partitions\neach partition gets 3600 events per hour * 20KB/events = 72 MB... so it can store data for 10GB/72 MB = 13 hours data before ItemCollectionSizeLimitExceededException for option D design. For game I guess TTL would be set to avoid it","timestamp":"1651372140.0","comments":[{"content":"Are you asking the developers to rewrite the application as changing from 1 table to 3 tables ?","comment_id":"660265","timestamp":"1662388140.0","upvote_count":"3","poster":"Stteve","comments":[{"upvote_count":"1","content":"should not be that difficult because the original code is possible with \"...from table X where game_id=?\" and table X could be a dynamic parameter -- maybe the programer even don't need to change the code.","timestamp":"1680039780.0","comment_id":"853733","comments":[{"upvote_count":"1","poster":"Germaneli","timestamp":"1695562740.0","content":"The partition key was obviously chosen wrong (game name has low cardinality as there are only 3 distinct games). This leads to overloading their partitions.\nThe solution and best practice is to choose a partition key with high cardinality --> user name.\n\nhttps://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/","comment_id":"1015836"}],"poster":"Mintwater"}]}],"comment_id":"595404","poster":"novice_expert"},{"comment_id":"861644","timestamp":"1680655500.0","upvote_count":"1","poster":"aqiao","content":"Selected Answer: D\nI' will go with D, for A you can consider GSI as table, if you still use game name as partition key, guess it will raise the same exception"},{"timestamp":"1671912060.0","poster":"lollyj","upvote_count":"1","content":"Selected Answer: D\nChose D because the partition key is to have high cardinality. Option A and C are out of the question because it is inferring to modify the table which is not possible on the fly. Option B also didn't seem to feasible","comment_id":"755114"},{"timestamp":"1670000220.0","poster":"Sab","content":"Selected Answer: D\nB and C is out of question. Between A and D, problem with A is the global index with game name as the partition key. This will create hot partitions since one game has over 500000 concurrent users. So better to have 3 tables, with players are partition key.","upvote_count":"1","comment_id":"733927"},{"poster":"RotterDam","upvote_count":"1","content":"Got this question in my exam. (i cleared it). But this is one of those questions I dont know if I got it right...I chose (D)","comment_id":"562590","timestamp":"1646654640.0"},{"comments":[{"content":"Actually GSI will also have a problem with very low cardinality as game name is a terrible choice for partition key. I will go with (D) - damn this is a tough one","upvote_count":"1","poster":"RotterDam","comment_id":"562146","timestamp":"1646585580.0"}],"timestamp":"1646582160.0","comment_id":"562107","poster":"RotterDam","content":"Selected Answer: A\nI feel its A\nLSI is the problem here with Low cardinality. But remember the question is asking about doing queries using game name. So you do need some form of index for that and GSI will solve it. This isnt being addressed in (D)","upvote_count":"1"},{"comments":[{"poster":"RotterDam","content":"Is the Global Secondary Index having a very low cardinality also an issue?","comment_id":"562099","comments":[{"poster":"RBSK","comments":[{"content":"Hence \"A\" should be a right ans too. With A, we do not need to change the application like \"D\". Hence my vote will be to \"A\"","poster":"RBSK","timestamp":"1671795840.0","upvote_count":"1","comment_id":"754162"}],"comment_id":"754159","upvote_count":"1","content":"No, 10GB limit does not apply to GSI. \n\nThe maximum size of any item collection for a table which has one or more local secondary indexes is 10 GB. This does not apply to item collections in tables without local secondary indexes, and also does not apply to item collections in global secondary indexes. Only tables that have one or more local secondary indexes are affected.","timestamp":"1671795720.0"}],"upvote_count":"1","timestamp":"1646580960.0"}],"poster":"soyyodario","upvote_count":"2","timestamp":"1644001560.0","comment_id":"540592","content":"Selected Answer: D\nI vote for D\nAn item collection is too large. This exception is only returned for tables that have one or more local secondary indexes.\nhttps://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/DynamoDB/Types/ItemCollectionSizeLimitExceededException.html"},{"poster":"szl0144","content":"I think D is correct","timestamp":"1642095660.0","upvote_count":"2","comment_id":"522981"},{"content":"Selected Answer: D\nI'd go with option D","comment_id":"508788","upvote_count":"3","timestamp":"1640374380.0","poster":"jove"},{"comments":[{"timestamp":"1640373660.0","upvote_count":"2","comment_id":"508772","poster":"jove","content":"Why not option D?"}],"timestamp":"1638094320.0","content":"Selected Answer: A\nI think A make sense to me as the document mention: \"The maximum size of any item collection is 10 GB. This limit does not apply to tables without local secondary indexes; only tables that have one or more local secondary indexes are affected\", avoid to use local secondary index will be the better solution.","poster":"AlexChih","upvote_count":"3","comment_id":"489049"},{"timestamp":"1637529060.0","upvote_count":"2","content":"C Makes sense to me","poster":"johnconnor","comment_id":"483668"}],"exam_id":22,"unix_timestamp":1637529060,"question_id":62,"url":"https://www.examtopics.com/discussions/amazon/view/66501-exam-aws-certified-database-specialty-topic-1-question-154/"},{"id":"GVhAUSVw3EbPnJdjLlt1","discussion":[{"upvote_count":"6","poster":"alwaysAstudent","comment_id":"474599","content":"Ans B,C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html","timestamp":"1636429260.0"},{"content":"B, C \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html","poster":"jove","upvote_count":"5","timestamp":"1640205780.0","comment_id":"507371"},{"poster":"testhello","comment_id":"960718","timestamp":"1690136280.0","content":"Selected Answer: BC\nB. Ensure that automatic backups are enabled for the source DB instance: Before creating a read replica, it is essential to have automatic backups enabled on the source DB instance. This ensures that the read replica can be created from a recent snapshot of the source DB instance.\n\nC. Ensure that the source DB instance is a Multi-AZ deployment with Always ON Availability Groups: To create a read replica for a SQL Server DB instance, the source DB instance must be configured as a Multi-AZ deployment with Always ON Availability Groups. This ensures high availability and data synchronization between the primary and standby replicas.","upvote_count":"1"},{"content":"Selected Answer: BC\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html","comment_id":"918152","timestamp":"1686221580.0","upvote_count":"1","poster":"aviathor"},{"content":"BC is right","poster":"tsk9921","comment_id":"893477","timestamp":"1683672600.0","upvote_count":"1"},{"timestamp":"1672073640.0","upvote_count":"1","comment_id":"757660","content":"Ans B, C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html\n\nBefore a DB instance can serve as a source instance for replication, you must enable automatic backups on the source DB instance. To do so, you set the backup retention period to a value other than 0. The source DB instance must be a Multi-AZ deployment with Always On Availability Groups (AGs). Setting this type of deployment also enforces that automatic backups are enabled.","poster":"parle101"},{"timestamp":"1671913440.0","poster":"lollyj","upvote_count":"1","content":"Selected Answer: BC\nMakes the most sense to me","comment_id":"755124"},{"timestamp":"1651174080.0","content":"Selected Answer: BC\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html","poster":"novice_expert","upvote_count":"1","comment_id":"594011"},{"upvote_count":"3","content":"Selected Answer: BC\nBefore a DB instance can serve as a source instance for replication, you must enable automatic backups on the source DB instance. To do so, you set the backup retention period to a value other than 0. The source DB instance must be a Multi-AZ deployment with Always On Availability Groups (AGs). Setting this type of deployment also enforces that automatic backups are enabled.","comment_id":"587180","timestamp":"1650192960.0","poster":"megadba"},{"content":"B & C\nBefore a DB instance can serve as a source instance for replication, you must enable automatic backups on the source DB instance. To do so, you set the backup retention period to a value other than 0. The source DB instance must be a Multi-AZ deployment with Always On Availability Groups (AGs). Setting this type of deployment also enforces that automatic backups are enabled.","poster":"mnzsql365","upvote_count":"2","comment_id":"504601","timestamp":"1639883100.0"}],"unix_timestamp":1636429260,"timestamp":"2021-11-09 04:41:00","isMC":true,"answers_community":["BC (100%)"],"question_text":"An ecommerce company recently migrated one of its SQL Server databases to an Amazon RDS for SQL Server Enterprise Edition DB instance. The company expects a spike in read traffic due to an upcoming sale. A database specialist must create a read replica of the DB instance to serve the anticipated read traffic.\nWhich actions should the database specialist take before creating the read replica? (Choose two.)","answer":"BC","answer_ET":"BC","question_images":[],"answer_images":[],"question_id":63,"topic":"1","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/65689-exam-aws-certified-database-specialty-topic-1-question-155/","exam_id":22,"choices":{"D":"Ensure that the source DB instance is a Multi-AZ deployment with SQL Server Database Mirroring (DBM).","B":"Ensure that automatic backups are enabled for the source DB instance.","C":"Ensure that the source DB instance is a Multi-AZ deployment with Always ON Availability Groups.","E":"Modify the read replica parameter group setting and set the value to 1.","A":"Identify a potential downtime window and stop the application calls to the source DB instance."}},{"id":"kzxCJlNbJAc3vSdhgZlD","answers_community":["ACD (88%)","13%"],"question_images":[],"answer":"ACD","unix_timestamp":1637376540,"discussion":[{"timestamp":"1646459460.0","comment_id":"561249","content":"ACL is used ONLY WITH S3. AC are absolutely correct but the question seems flawed. Enhanced Monitoring WONT help with a developer from deleting the instance","poster":"RotterDam","upvote_count":"7"},{"comment_id":"1064758","poster":"ArturoZapatero","upvote_count":"1","timestamp":"1699358280.0","content":"The answers should be:\n- Grant least privilege to groups, users, and roles\n- Allow all users to restore a database from a backup that will reduce the overall downtime to restore the database\n- Enable multi-factor authentication for sensitive operations to access sensitive resources and API operations\n- Use policy conditions to restrict access to selective IP addresses\n- Use AccessList Controls policy type to restrict users for database instance deletion\n- Enable AWS CloudTrail logging and Enhanced Monitoring"},{"poster":"chen0305_099","content":"ＷＨＹ Ｄ？","upvote_count":"1","timestamp":"1694239680.0","comment_id":"1002966"},{"upvote_count":"1","timestamp":"1686221760.0","content":"Selected Answer: ACD\nB and E are not preventive measures. A, C, D are.","poster":"aviathor","comment_id":"918155"},{"poster":"Sab","timestamp":"1670000580.0","upvote_count":"3","comment_id":"733928","content":"ACL is not supported with RDS\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/security_iam_service-with-iam.html\n\nAccess control lists (ACLs) in Amazon RDS\nSupports access control lists (ACLs) - No"},{"content":"Selected Answer: ACD\nLeast Priv\nDelete Protection\nAccess control","poster":"novice_expert","comment_id":"594684","timestamp":"1651264020.0","upvote_count":"3"},{"comment_id":"567145","timestamp":"1647199020.0","poster":"Dantas","upvote_count":"1","content":"Selected Answer: AC\nThere's no 3rd correct option."},{"timestamp":"1645740180.0","comment_id":"555597","content":"Selected Answer: ACD\nAC\nD with IAM not ACL","poster":"tugboat","upvote_count":"3"},{"upvote_count":"4","timestamp":"1640326860.0","comment_id":"508350","content":"There are only 2 right answers here.. question or answer need to be corrected ..A nad C only are right","poster":"suhasraj"},{"timestamp":"1639713120.0","comments":[{"poster":"jove","comment_id":"505732","content":"Do you mean there is a typo in option D? Should it be \"Use an IAM policy to ... \" ?","upvote_count":"1","timestamp":"1640042160.0"}],"comment_id":"503338","poster":"mnzsql365","content":"A, C & D.\nC - ACL is the IAM policy, preventing users\n from deleting a specific DB instance.","upvote_count":"1"},{"poster":"2025flakyt","upvote_count":"1","timestamp":"1639013640.0","comments":[{"content":"How can you use AWS CloudTrail logging and Enhanced Monitoring to restrict users from DB instance deletion?","comments":[{"content":"Minimize the risk, not restrict users...","poster":"ArturoZapatero","comment_id":"1058551","upvote_count":"1","timestamp":"1698738660.0"}],"poster":"jove","comment_id":"505731","timestamp":"1640042040.0","upvote_count":"2"},{"timestamp":"1683672900.0","poster":"tsk9921","upvote_count":"1","comment_id":"893479","content":"You are right, ACL is not for user level access control."}],"content":"ACE is the correct answer.\nYou can't use ACL policy to restrict users. You can only use IAM policy to restrict users","comment_id":"497271"},{"content":"The answer is ACD","upvote_count":"2","timestamp":"1637376540.0","comment_id":"482229","comments":[{"timestamp":"1638042300.0","comment_id":"488467","upvote_count":"3","comments":[],"poster":"jove","content":"A & C is clear but how can you use an ACL policy to restrict users from DB instance deletion?"}],"poster":"GaryY"}],"answer_description":"","topic":"1","question_text":"A company is running a two-tier ecommerce application in one AWS account. The application is backed by an Amazon RDS for MySQL Multi-AZ DB instance. A developer mistakenly deleted the DB instance in the production environment. The company restores the database, but this event results in hours of downtime and lost revenue.\nWhich combination of changes would minimize the risk of this mistake occurring in the future? (Choose three.)","choices":{"D":"Use an ACL policy to restrict users from DB instance deletion.","B":"Allow all users to restore a database from a backup.","C":"Enable deletion protection on existing production DB instances.","A":"Grant least privilege to groups, IAM users, and roles.","E":"Enable AWS CloudTrail logging and Enhanced Monitoring."},"answer_ET":"ACD","question_id":64,"answer_images":[],"timestamp":"2021-11-20 03:49:00","exam_id":22,"url":"https://www.examtopics.com/discussions/amazon/view/66370-exam-aws-certified-database-specialty-topic-1-question-156/","isMC":true},{"id":"6V0O9ArFPQMkhDAsdtD1","answers_community":["D (93%)","7%"],"question_images":[],"answer":"D","discussion":[{"poster":"Dantas","timestamp":"1647043560.0","upvote_count":"6","content":"Selected Answer: D\nKey rotation ✓ \nKey deletion ✓ \nMinimal overhead ✓","comment_id":"565849"},{"poster":"Pranava_GCP","upvote_count":"2","comment_id":"1007566","content":"Selected Answer: D\nD. AWS Key Management Service (AWS KMS) CMK with customer-provided material \n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#key-mgmt\n\n\"The KMS keys that you create are customer managed keys. Customer managed keys are KMS keys in your AWS account that you create, own, and manage. You have full control over these KMS keys, including establishing and maintaining their key policies, IAM policies, and grants, enabling and disabling them, rotating their cryptographic material, adding tags, creating aliases that refer to the KMS keys, and scheduling the KMS keys for deletion. \"","timestamp":"1694693160.0"},{"comments":[{"comment_id":"1015844","content":"Overhead for CloudHSM is exorbitant. This is not an option.","timestamp":"1695563160.0","poster":"Germaneli","upvote_count":"1"}],"timestamp":"1689098340.0","upvote_count":"1","poster":"SamDDD","comment_id":"949224","content":"Could be A: https://aws.amazon.com/blogs/security/aws-cloudhsm-is-now-integrated-with-amazon-rds-for-oracle-and-provides-enhanced-management-tools/\nHesitant as I cannot figure out how to rotate the keys in CloudHSM"},{"content":"Selected Answer: C\nIt was a toss between C and D however SSE provides less overhead and maintenance than D. I could be wrong.","comment_id":"755130","poster":"lollyj","upvote_count":"1","timestamp":"1671914400.0"},{"upvote_count":"3","poster":"rags1482","comment_id":"709404","content":"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#key-mgmt\n\nCustomer managed keys are KMS keys in your AWS account that you create, own, and manage. You have full control over these KMS keys, including establishing and maintaining their key policies, IAM policies, and grants, enabling and disabling them, rotating their cryptographic material, adding tags, creating aliases that refer to the KMS keys, and scheduling the KMS keys for deletion.\n\nAnswer D","timestamp":"1667331360.0"},{"poster":"shammous","timestamp":"1660384680.0","content":"For those mentioning HSM: \"You cannot use an Oracle instance in Amazon Relational Database Service (Amazon RDS) to integrate with AWS CloudHSM. You must install Oracle Database on an Amazon EC2 instance.\" Ref: https://docs.aws.amazon.com/cloudhsm/latest/userguide/oracle-tde.html\nThis eliminates answer A.\nThe key words that would make me choose answer D is \"Rotate encryption key on demand\". Only CMK allows to do that. AWS managed key are automatically rotated every 1 year and the organization can't change that.","comment_id":"646267","upvote_count":"3"},{"upvote_count":"1","content":"Could be A \n\nEnable transparent data encryption (TDE) for Oracle databases\nCopy Plain Link[] l : t - s[] t - s - l\nSome versions of Oracle's database software offer a feature called Transparent Data Encryption (TDE). With TDE, the database software encrypts data before storing it on disk. The data in the database's table columns or tablespaces is encrypted with a table key or tablespace key. These keys are encrypted with the TDE master encryption key. You can store the TDE master encryption key in the HSMs in your AWS CloudHSM cluster, which provides additional security.\nhttps://docs.aws.amazon.com/cloudhsm/latest/userguide/use-cases.html#transparent-data-encryption","poster":"Chirantan","timestamp":"1657427040.0","comment_id":"629429"},{"content":"Could be A because Cloud HSM is recently added to Oracle RDS \nhttps://aws.amazon.com/blogs/security/aws-cloudhsm-is-now-integrated-with-amazon-rds-for-oracle-and-provides-enhanced-management-tools/","comments":[{"timestamp":"1679754540.0","comment_id":"850193","upvote_count":"1","poster":"backbencher2022","content":"Sachin, please read the update on Nov 24 2021 for the same blog post (https://aws.amazon.com/blogs/security/aws-cloudhsm-is-now-integrated-with-amazon-rds-for-oracle-and-provides-enhanced-management-tools/). AWS CloudHSM Classic used to support RDS Oracle however, AWS CloudHSM Classic has been discontinued and replaced by AWS CloudHSM which supports HSM with EC2 only not RDS. First paragraph of this blog clearly says it - November 24, 2021: This blog post announced a feature of AWS CloudHSM Classic which integrated with Amazon RDS for Oracle to provide customers with an easy integration for Transparent Data Encryption (TDE). The AWS CloudHSM team have since released AWS CloudHSM, and this feature is no longer available. For updated options, please see out this blog post: https://aws.amazon.com/blogs/security/architecting-for-database-encryption-on-aws/."}],"comment_id":"619928","timestamp":"1655826840.0","poster":"sachin","upvote_count":"1"},{"comment_id":"619925","content":"Will go with D","timestamp":"1655826660.0","upvote_count":"2","poster":"sachin"},{"comment_id":"594547","content":"Selected Answer: D\nKMS CMK","upvote_count":"3","poster":"novice_expert","timestamp":"1651245780.0"},{"poster":"mike3g2000","timestamp":"1646227500.0","content":"This one A for me:\nhttps://docs.aws.amazon.com/cloudhsm/latest/userguide/use-cases.html","upvote_count":"1","comment_id":"559435","comments":[{"comments":[{"comment_id":"616241","upvote_count":"2","timestamp":"1655211780.0","content":"Sure? https://aws.amazon.com/de/blogs/security/aws-cloudhsm-is-now-integrated-with-amazon-rds-for-oracle-and-provides-enhanced-management-tools/","poster":"DevoteamAnalytix"}],"comment_id":"568330","poster":"mike3g2000","timestamp":"1647344460.0","upvote_count":"2","content":"You can't use cloudHSM with RDS, database has to be on ec2. D is the correct answer."}]},{"timestamp":"1645662120.0","poster":"tugboat","comment_id":"554976","content":"Selected Answer: D\nPer - https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html\nYou must manage different keys for each encryption method.","upvote_count":"3"},{"upvote_count":"2","content":"D - CMK","timestamp":"1645656180.0","poster":"kped21","comment_id":"554931"},{"content":"Look at rotation: Customer managed have on demand. Question asks for it https://docs.aws.amazon.com/whitepapers/latest/kms-best-practices/aws-managed-and-customer-managed-cmks.html","upvote_count":"3","timestamp":"1636963980.0","poster":"toppic26","comment_id":"478533"},{"timestamp":"1636787220.0","upvote_count":"3","comment_id":"477330","poster":"hemantr","content":"D. https://docs.aws.amazon.com/whitepapers/latest/kms-best-practices/aws-managed-and-customer-managed-cmks.html"},{"poster":"leunamE","timestamp":"1636498320.0","upvote_count":"4","content":"D. AWS Key Management Service (AWS KMS) CMK with customer-provided material","comment_id":"475110"}],"unix_timestamp":1636498320,"topic":"1","answer_description":"","choices":{"A":"AWS CloudHSM","B":"AWS Key Management Service (AWS KMS) with an AWS managed key","C":"AWS Key Management Service (AWS KMS) with server-side encryption","D":"AWS Key Management Service (AWS KMS) CMK with customer-provided material"},"question_text":"A financial services company uses Amazon RDS for Oracle with Transparent Data Encryption (TDE). The company is required to encrypt its data at rest at all times. The key required to decrypt the data has to be highly available, and access to the key must be limited. As a regulatory requirement, the company must have the ability to rotate the encryption key on demand. The company must be able to make the key unusable if any potential security breaches are spotted. The company also needs to accomplish these tasks with minimum overhead.\nWhat should the database administrator use to set up the encryption to meet these requirements?","answer_ET":"D","question_id":65,"answer_images":[],"exam_id":22,"timestamp":"2021-11-09 23:52:00","url":"https://www.examtopics.com/discussions/amazon/view/65738-exam-aws-certified-database-specialty-topic-1-question-157/","isMC":true}],"exam":{"lastUpdated":"11 Apr 2025","isMCOnly":false,"numberOfQuestions":359,"isBeta":false,"provider":"Amazon","name":"AWS Certified Database - Specialty","id":22,"isImplemented":true},"currentPage":13},"__N_SSP":true}