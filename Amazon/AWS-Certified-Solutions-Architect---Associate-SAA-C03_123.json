{"pageProps":{"questions":[{"id":"7menIAKkmjGZFMoKaLyC","isMC":true,"answers_community":["C (91%)","9%"],"answer_images":[],"answer":"C","choices":{"A":"Create a script that runs locally on an Amazon EC2 Reserved Instance that is triggered by a cron job.","B":"Create an AWS Lambda function triggered by an Amazon EventBridge scheduled event.","D":"Use an Amazon Elastic Container Service (Amazon ECS) task running on Amazon EC2 triggered by an Amazon EventBridge scheduled event.","C":"Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge scheduled event."},"answer_description":"","timestamp":"2023-11-07 01:44:00","answer_ET":"C","exam_id":31,"unix_timestamp":1699317840,"topic":"1","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/125542-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A solutions architect is creating a data processing job that runs once daily and can take up to 2 hours to complete. If the job is interrupted, it has to restart from the beginning.\n\nHow should the solutions architect address this issue in the MOST cost-effective manner?","discussion":[{"content":"Selected Answer: C\nA: Nonsense\nB: Lambda max running time is 15 mins\nD: EC2 is more expensive than Fargate for 2 hours duration as EC2 instance will be billed.","comments":[{"poster":"awsgeek75","content":"A is also nonsense because an EC2 reserved instance will cost the most for the period when the 2 hour job is not running!","comment_id":"1127213","timestamp":"1705748040.0","upvote_count":"4"}],"timestamp":"1705080300.0","comment_id":"1120956","poster":"awsgeek75","upvote_count":"10"},{"timestamp":"1704202020.0","content":"Selected Answer: C\nNot B because of running time","poster":"pentium75","comment_id":"1111932","upvote_count":"5"},{"content":"Selected Answer: C\nEC2 expensive than Fargate or Lambda, but Lambda has 15 mins limit, so only could choose Fargate for micro service which is C.\nI think no one will create script for that by the way","upvote_count":"2","poster":"KennethNg923","timestamp":"1718586000.0","comment_id":"1231604"},{"content":"Selected Answer: C\nAWS Fargate will bill you based on the amount of vCPU, RAM, OS, CPU architecture, and storage that your containerized apps consume while running on EKS or ECS.","timestamp":"1701341640.0","poster":"TariqKipkemei","upvote_count":"2","comment_id":"1084262"},{"comment_id":"1083323","poster":"cevin93","timestamp":"1701250620.0","content":"Selected Answer: C\nshould be C","upvote_count":"3"},{"comment_id":"1076150","content":"Selected Answer: C\nLambda function have a limit timeout about 15 minutes, so cannot be B.\nAnswer is C","upvote_count":"3","timestamp":"1700558100.0","poster":"Alex1atd"},{"comment_id":"1070082","upvote_count":"2","timestamp":"1699945140.0","content":"Selected Answer: C\nLamda function have a limit timeout about 15 minutes","poster":"hungta"},{"upvote_count":"3","comment_id":"1067517","poster":"cciesam","timestamp":"1699648560.0","content":"Selected Answer: B\nI think it should be B. Considering the Cost.","comments":[{"upvote_count":"5","timestamp":"1702557240.0","comment_id":"1096460","content":"Lambda times out after 15 minutes. This job requires a 2-hour time without interruption block. So, definitely not B.","poster":"Murtadhaceit"},{"comment_id":"1070036","poster":"zhdetn","content":"Lambda Maximum execution time: 900 seconds (15 minutes)","upvote_count":"6","timestamp":"1699941000.0"}]},{"upvote_count":"3","timestamp":"1699317840.0","content":"Selected Answer: C\nI guess it is C","comment_id":"1064384","poster":"potomac"}],"question_id":611},{"id":"ca0MOLSDIy1OTNahOCoB","isMC":true,"exam_id":31,"answer_ET":"B","answer_description":"","question_text":"A social media company wants to store its database of user profiles, relationships, and interactions in the AWS Cloud. The company needs an application to monitor any changes in the database. The application needs to analyze the relationships between the data entities and to provide recommendations to users.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"A":"Use Amazon Neptune to store the information. Use Amazon Kinesis Data Streams to process changes in the database.","C":"Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Amazon Kinesis Data Streams to process changes in the database.","B":"Use Amazon Neptune to store the information. Use Neptune Streams to process changes in the database.","D":"Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Neptune Streams to process changes in the database."},"answer":"B","question_id":612,"url":"https://www.examtopics.com/discussions/amazon/view/125113-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"topic":"1","answers_community":["B (88%)","13%"],"discussion":[{"comments":[{"comments":[{"upvote_count":"2","content":"I come looking for one of you guys comments. Nice.","poster":"MatAlves","comment_id":"1284986","timestamp":"1726533600.0"}],"comment_id":"1120958","content":"Also, Neptune Streams can monitor changes in the data and create a changelog","timestamp":"1705080480.0","poster":"awsgeek75","upvote_count":"6"}],"content":"Selected Answer: B\nRelationships between entities = Graph data = Neptune","upvote_count":"7","comment_id":"1111944","poster":"pentium75","timestamp":"1704203700.0"},{"upvote_count":"7","comment_id":"1084267","timestamp":"1701342060.0","poster":"TariqKipkemei","content":"Selected Answer: B\nAmazon Neptune Database is a serverless graph database designed for superior scalability and availability. Neptune Database provides built-in security, continuous backups, and integrations with other AWS services. Suitable for social media. With the Neptune Streams feature, you can generate a complete sequence of change-log entries that record every change made to your graph data as it happens."},{"content":"Selected Answer: B\nNeptune is optimized for storing billions of relationships and querying the graph with milliseconds latence. Neptune Streams logs every change to your graph as it happens, in the order that it is made, in a fully managed way.\nAmazon Quantum Ledger Database (QLDB) is a purpose-built ledger database that provides a complete and cryptographically verifiable history of all changes made to your application data.","timestamp":"1738385160.0","poster":"FlyingHawk","upvote_count":"1","comment_id":"1349749"},{"content":"Selected Answer: B\nNormally Amazon Quantum Ledger Database use in blockchain DB more. So i will go for B using Neptune and Neptune Stream for relationship between entities.","poster":"KennethNg923","timestamp":"1718586240.0","upvote_count":"2","comment_id":"1231605"},{"comment_id":"1169783","timestamp":"1710014880.0","upvote_count":"1","poster":"haci","content":"Selected Answer: C\nAmazon QLDB tracks and maintains a sequential history of every application data change using an immutable and transparent log. It trusts the integrity of your data. Built-in cryptographic authentication provides third-party verification of data changes. QLDB ACID transactions can create accurate, event-driven systems with support for real-time streaming to Amazon Kinesis."},{"content":"Selected Answer: B\nB\n\nSocial network -> Graph Structure -> Neptune","timestamp":"1699582320.0","poster":"NickGordon","upvote_count":"3","comment_id":"1066887"},{"comment_id":"1065672","content":"Selected Answer: B\nKeyword: analyze the relationships\nWith Amazon Neptune, you can create sophisticated, interactive graph applications that can query billions of relationships in milliseconds.\n\nhttps://aws.amazon.com/neptune/features/","upvote_count":"5","poster":"ekisako","timestamp":"1699451880.0"},{"content":"Selected Answer: C\nAmazon Neptune is primarily used for managing highly connected graph data, making it well-suited for graph-based applications. \n\nIn contrast, Amazon QLDB is designed for applications that require an immutable and auditable transaction history to ensure data integrity.","upvote_count":"3","comment_id":"1064389","poster":"potomac","timestamp":"1699318500.0","comments":[]},{"comment_id":"1063240","poster":"warp","content":"Selected Answer: B\nNeptune is a graph type database and Neptune streams provides view on changes into the database: https://docs.aws.amazon.com/neptune/latest/userguide/streams.html","timestamp":"1699215420.0","upvote_count":"3"},{"comments":[{"comment_id":"1127215","upvote_count":"2","timestamp":"1705748160.0","content":"AQLB is like a blockchain database. Are you sure this is the correct option for graph data?","poster":"awsgeek75"}],"upvote_count":"2","comment_id":"1059846","poster":"AF_1221","timestamp":"1698851100.0","content":"C is the correct answer \nprovides a well-suited, managed, and scalable solution for storing and monitoring the database with the least operational overhead, meeting the requirements of the social media company."}],"question_images":[],"timestamp":"2023-11-01 16:05:00","unix_timestamp":1698851100},{"id":"7mAPGyjZRDfTvj2edM28","discussion":[{"upvote_count":"6","content":"Selected Answer: C\nMultiple Linux instances = Amazon Elastic File System (Amazon EFS) with multiple mount targets.","comment_id":"1084269","poster":"TariqKipkemei","timestamp":"1732964700.0"},{"poster":"AF_1221","timestamp":"1730473620.0","upvote_count":"5","content":"C is correct \nShared File System: Amazon EFS allows multiple Amazon EC2 instances to mount the same file system simultaneously, making it easy for multiple instances to access and modify the data concurrently.","comment_id":"1059847"},{"upvote_count":"2","content":"Selected Answer: C\nS3 Glacier (flexible retrieval) is not compatible with hourly job\nEBS can be shared only in same AZ (B and D are out)","poster":"Salilgen","comment_id":"1332899","timestamp":"1735379820.0"},{"upvote_count":"4","comment_id":"1064391","poster":"potomac","content":"Selected Answer: C\nC is correct","timestamp":"1730941020.0"}],"exam_id":31,"question_id":613,"answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/125114-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"answers_community":["C (100%)"],"unix_timestamp":1698851220,"question_text":"A company is creating a new application that will store a large amount of data. The data will be analyzed hourly and will be modified by several Amazon EC2 Linux instances that are deployed across multiple Availability Zones. The needed amount of storage space will continue to grow for the next 6 months.\n\nWhich storage solution should a solutions architect recommend to meet these requirements?","topic":"1","isMC":true,"answer_description":"","answer_ET":"C","timestamp":"2023-11-01 16:07:00","choices":{"B":"Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the application instances.","C":"Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances.","A":"Store the data in Amazon S3 Glacier. Update the S3 Glacier vault policy to allow access to the application instances.","D":"Store the data in an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS volume shared between the application instances."},"question_images":[]},{"id":"ItPoo4MfjJmnfEibTujd","question_images":[],"exam_id":31,"isMC":true,"answer_images":[],"discussion":[{"poster":"TariqKipkemei","comment_id":"1084273","timestamp":"1717060260.0","content":"Selected Answer: C\nA Multi-AZ DB instance Creates a primary DB instance with one standby DB instance in a different Availability Zone. Using a Multi-AZ DB instance provides high availability, but the standby DB instance doesn't support connections for read workloads.\nTherefore you will need to create a read replica from the source DB instance then serve read traffic from the read replica.","upvote_count":"7"},{"content":"Selected Answer: C\nRead replica split for read traffic will distribute the overall load and improve the performance.\n\nA: Standby replica cannot serve traffic (Correct me if I am wrong here)\nB: Transfer Accelerator is to speed up S3 traffic. Not the case here\nD: Kiensis will increase concurrency but won't solve the DB performance issues","comment_id":"1121507","upvote_count":"5","poster":"awsgeek75","timestamp":"1720859220.0"},{"upvote_count":"3","content":"Selected Answer: C\nyou can’t read from the standby DB instance. If applications require more read capacity, you should create or add additional read replicas.","poster":"potomac","comment_id":"1064394","timestamp":"1715036460.0"},{"poster":"warp","timestamp":"1714985280.0","comment_id":"1063744","content":"Selected Answer: C\nAfter you create a read replica from a source DB instance, the source becomes the primary DB instance. When you make updates to the primary DB instance, Amazon RDS copies them asynchronously to the read replica. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html","upvote_count":"4"}],"answer":"C","question_text":"A company manages an application that stores data on an Amazon RDS for PostgreSQL Multi-AZ DB instance. Increases in traffic are causing performance problems. The company determines that database queries are the primary reason for the slow performance.\n\nWhat should a solutions architect do to improve the application's performance?","question_id":614,"answer_description":"","choices":{"D":"Use Amazon Kinesis Data Firehose between the application and Amazon RDS to increase the concurrency of database requests.","A":"Serve read traffic from the Multi-AZ standby replica.","C":"Create a read replica from the source DB instance. Serve read traffic from the read replica.","B":"Configure the DB instance to use Transfer Acceleration."},"unix_timestamp":1699267680,"timestamp":"2023-11-06 11:48:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/125513-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"C","answers_community":["C (100%)"]},{"id":"5KCgWvaMbrTrvu8bbVB9","question_images":[],"isMC":true,"question_text":"A company collects 10 GB of telemetry data daily from various machines. The company stores the data in an Amazon S3 bucket in a source data account.\n\nThe company has hired several consulting agencies to use this data for analysis. Each agency needs read access to the data for its analysts. The company must share the data from the source data account by choosing a solution that maximizes security and operational efficiency.\n\nWhich solution will meet these requirements?","answer_description":"","answer_images":[],"answer":"C","topic":"1","question_id":615,"choices":{"B":"Make the S3 bucket public for a limited time. Inform only the agencies.","C":"Configure cross-account access for the S3 bucket to the accounts that the agencies own.","D":"Set up an IAM user for each analyst in the source data account. Grant each user access to the S3 bucket.","A":"Configure S3 global tables to replicate data for each agency."},"discussion":[{"timestamp":"1719922620.0","upvote_count":"9","poster":"pentium75","content":"Selected Answer: C\nA doesn't exist\nB is a big \"hell no\"\nD is a bad practice, even with IAM you'd use groups","comment_id":"1111953"},{"timestamp":"1726019340.0","comments":[{"content":"then we politely tell them \"no.\"","upvote_count":"9","comment_id":"1172930","timestamp":"1726257900.0","poster":"chickenmf"}],"comment_id":"1170785","upvote_count":"7","content":"What if other agencies don't have an aws account?","poster":"xBUGx"},{"upvote_count":"5","timestamp":"1720859460.0","comment_id":"1121510","content":"Selected Answer: C\nOthers have given reason by ABD are wrong. In case you need it, here is an AWS example exercise of understanding option C\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-walkthroughs-managing-access-example2.html","poster":"awsgeek75"},{"timestamp":"1717060680.0","poster":"TariqKipkemei","content":"Selected Answer: C\nWith cross-account bucket permissions Account A—can grant another AWS account, Account B, permission to access its resources such as buckets and objects. Account B can then delegate those permissions to users in its account.\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-walkthroughs-managing-access-example2.html#:~:text=4%3A%20Clean%20up-,An%20AWS%20account,-%E2%80%94for%20example%2C%20Account","comment_id":"1084282","upvote_count":"3"},{"upvote_count":"3","comment_id":"1066892","content":"Selected Answer: C\nC is the best answer","poster":"NickGordon","timestamp":"1715300220.0"},{"upvote_count":"1","comments":[{"content":"\"consulting agencies\" means some companies which may have one or more analysts each. Making IAM users for each individual to manage permissions is not well-architected. You would at least create groups and assign it to users. \nD will work as it is possible but it won't minimize \"operational efficiency\"","comment_id":"1121514","upvote_count":"2","poster":"awsgeek75","timestamp":"1720859700.0"},{"comment_id":"1066890","timestamp":"1715300160.0","content":"in that case, an analyst user group should be created and the access should be assigned to the group. So C is better","upvote_count":"3","poster":"NickGordon"}],"content":"Selected Answer: D\nC may not correct as it's doesn't say if the analyst are using AWS services","timestamp":"1715258280.0","comment_id":"1066478","poster":"cciesam"},{"upvote_count":"2","poster":"potomac","timestamp":"1715037060.0","comment_id":"1064396","content":"Selected Answer: C\nI think it is C"}],"answer_ET":"C","timestamp":"2023-11-07 02:11:00","url":"https://www.examtopics.com/discussions/amazon/view/125544-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1699319460,"answers_community":["C (96%)","4%"],"exam_id":31}],"exam":{"provider":"Amazon","lastUpdated":"11 Apr 2025","isImplemented":true,"isMCOnly":true,"isBeta":false,"id":31,"numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":123},"__N_SSP":true}