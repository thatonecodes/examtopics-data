{"pageProps":{"questions":[{"id":"QN3STr2aCyjdCMYji7XO","answer_description":"","question_id":76,"discussion":[{"upvote_count":"16","comment_id":"599102","content":"A : The data has label. So what we need to do is to enforce accuracy by reviewing low confidence ones internally","poster":"LydiaGom","timestamp":"1652109540.0","comments":[{"content":"Not A, bounding box should be a feature of Ground Truth.\nhttps://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/sms-bounding-box.html","upvote_count":"1","comments":[{"poster":"wolfsong","content":"It's A. \nSee https://aws.amazon.com/rekognition/custom-labels-features/. \nIt says \"The Rekognition Custom Labels console provides a visual interface to make labeling your images fast and simple. The interface allows you to apply a label to the entire image or to identify and label specific objects in images using bounding boxes with a simple click-and-drag interface.\"\nWe are not using semantic segmentation, as it applies a label to every pixel. We don't want that, we want labels to bounding boxes.","upvote_count":"2","comments":[{"timestamp":"1683119040.0","comment_id":"888540","poster":"ZSun","upvote_count":"3","content":"1. you didn't understand what Rekognition is about. Rekognition is a CV model, not labeling tools.\n2. you didn't read carefully about the document, just below your quote, it said \"Alternately, if you have a large data set, you can use Amazon SageMaker Ground Truth to efficiently label your images at scale.\" Rekognition label function is for individual cases.\n3. finally, you really sure this is an object detection, not pixel-level object classification? original model is object detection and it didn't work. semantic segmentation might be a solution and it is good for self-driving."}],"timestamp":"1676547480.0","comment_id":"810598"}],"comment_id":"737344","timestamp":"1670376180.0","poster":"VinceCar"}]},{"content":"Selected Answer: D\nD; B is using MTurk which uses public workforce which violates the requirements that videos need to be kept private","timestamp":"1651350060.0","poster":"spaceexplorer","comments":[{"comment_id":"645715","timestamp":"1660276680.0","upvote_count":"1","poster":"Sidekick","content":"A quick google search on SageMaker ground truth will show you that you can indeed create your own private labelers workforce and send them labelling jobs through GroundTruth. \n\n \"You have options to work with labelers inside and outside your organization. For example, you can send labeling jobs to your own labelers, or you can access a workforce of over 500,000 independent contractors who are already performing ML-related tasks through Amazon Mechanical Turk. If your data requires confidentiality or special skills, you can also use vendors that are pre-screened by AWS for quality and security procedures.\"","comments":[{"comment_id":"645723","poster":"Sidekick","content":"Nevermind My bad. Just realized that you are referring particularly to Mechanical Turk being used as the labelers force for Ground Truth, which is what answer B referring to.","timestamp":"1660278120.0","upvote_count":"1"}]},{"comment_id":"645735","timestamp":"1660278900.0","comments":[{"upvote_count":"3","poster":"uninit","content":"There is a Ground Truth for Semantic Segmentation labelling task - https://docs.aws.amazon.com/sagemaker/latest/dg/sms-semantic-segmentation.html.\n\nTherefore, D is correct.","comment_id":"796439","timestamp":"1675371240.0"},{"poster":"Sidekick","upvote_count":"1","content":"https://docs.aws.amazon.com/sagemaker/latest/dg/sms-video.html","timestamp":"1660278900.0","comment_id":"645737"},{"poster":"Sidekick","timestamp":"1660279680.0","comment_id":"645743","content":"And Semantic segmentation is object classification done at the pixel level. Isnt that something only machines can do? Unless labelers are directing a machine to do the semantic segmentation for them, I think labelers are no use for it.","upvote_count":"1"}],"poster":"Sidekick","upvote_count":"2","content":"The Problem with Answer D though is that there is no \"semantic segmentation labeling task\" within the very limited list of Ground Truth type of jobs it offers. \n\nThere is a video classification Job type, and there is Video Frame labeling job type, which includes \"video frame object detection job\" and \"video frame object tracking job. However, there is no Semantic Segmentation Labeling Job\""},{"poster":"VinceCar","comment_id":"714316","upvote_count":"1","content":"Agreed. Option A used Amazon Augmented AI (Amazon A2I), not a good way to review confidential data.","timestamp":"1667971860.0"}],"upvote_count":"14","comment_id":"595265"},{"poster":"ef12052","upvote_count":"1","timestamp":"1743828960.0","content":"Selected Answer: D\n\"However, the object detection model cannot clearly demarcate the yellow line, the passengers who cross the yellow line, and the trains.\" ---> D","comment_id":"1513971"},{"timestamp":"1728353100.0","content":"IMHO, the answer is D: image segmentation.\nAs the question say: \"However, the object detection model cannot clearly demarcate the yellow line, the passengers who cross the yellow line, and the trains.\"\nYou will get a better accuracy with segmentation in this case.","upvote_count":"3","comment_id":"1294526","poster":"amlgeek"},{"content":"Selected Answer: A\nsemantic segmentation may not be the right choice for labelling, instead Rekognition is ideal for this scenario and private workforce + A2I to validate the labelling.","upvote_count":"1","timestamp":"1714556640.0","comment_id":"1204980","poster":"rookiee1111"},{"poster":"Denise123","comment_id":"1171549","timestamp":"1710232740.0","upvote_count":"3","content":"Selected Answer: D\nWhile Amazon Rekognition Custom Labels with Amazon A2I could be used for object detection, semantic segmentation provides more detailed information about the spatial layout of objects in an image, making it potentially more suitable for tasks like demarcating safety lines."},{"content":"Selected Answer: D\nSemantic segmentation will provide the precise pixel-level labeling required to demarcate the yellow safety line accurately, passengers, and trains. A private workforce will ensure that the video data remains confidential. As the original model canâ€™t correctly identify the line, semantic segmentation might offer the needed precision. So D is right.","poster":"Stokvisss","comment_id":"1161388","upvote_count":"1","timestamp":"1709107860.0"},{"comment_id":"1158327","timestamp":"1708832400.0","content":"Selected Answer: D\nAmazon Rekognition does not support creation of private workforce. Between A & D, D is the only option that allows its creation. Semantic segmnentation can easily identify the yellow line.","upvote_count":"1","poster":"AIWave"},{"comment_id":"1148811","upvote_count":"1","timestamp":"1707785160.0","poster":"kyuhuck","content":"Selected Answer: D\nGiven the requirements of the task and the need for confidentiality, the best approach would be:\n\nD. Use an Amazon SageMaker Ground Truth semantic segmentation labeling task with a private workforce. Semantic segmentation will provide the precise pixel-level labeling required to demarcate the yellow safety line accurately, passengers, and trains. A private workforce will ensure that the video data remains confidential."},{"upvote_count":"1","comment_id":"1120015","comments":[{"comment_id":"1330335","upvote_count":"1","timestamp":"1734860640.0","content":"Choose D. Just to be exactly, it's essential for training a robust \"Semantic Segmentation\" model :)","poster":"LeoD"}],"timestamp":"1704994380.0","poster":"CloudHandsOn","content":"Selected Answer: D\nD. Use an Amazon SageMaker Ground Truth semantic segmentation labeling task. Use a private workforce as the labeling workforce.\n\nHere's why this approach is suitable:\n\n Semantic Segmentation Labeling: Semantic segmentation involves labeling each pixel in the image, which is more granular than bounding boxes. This approach is ideal for accurately demarcating the yellow line, which might be difficult with just bounding boxes. It also allows for precise detection of passengers and trains.\n\n Private Workforce: Given the requirement for confidentiality, using a private workforce ensures that the data is handled by trusted, authorized personnel. This addresses the concern of keeping the video data confidential.\n\n Amazon SageMaker Ground Truth: This service provides tools for efficient and accurate labeling of image data, which is essential for training a robust object detection model."},{"upvote_count":"1","content":"Selected Answer: A\nA:\n\nD is too complicated.\nOption D suggests using SageMaker Ground Truth with a semantic segmentation labeling task and a private workforce. Semantic segmentation can be useful for delineating the yellow line clearly. However, it might be more complex than necessary for this scenario, and object detection might be more suitable. In my opinion, A is a better option.","poster":"[Removed]","comment_id":"1088569","timestamp":"1701787020.0"},{"comment_id":"1082466","upvote_count":"1","poster":"endeesa","content":"Selected Answer: D\nRekognition is not guaranteed no to use your data to improve their models. Similarly, mechanical turk will not keep data private. Only viable option is D","timestamp":"1701169680.0"},{"timestamp":"1699095840.0","comment_id":"1062029","poster":"giustino98","upvote_count":"1","content":"Selected Answer: A\nB and C excluded since use public workforce. D excluded since question is asking for \"labeling approach for THIS model\" it means you don't want to switch to a semantic segmentation problem. Therefore A is the correct answer"},{"content":"Selected Answer: D\nGiven that the video data must remain confidential, options that use public workforces like Amazon Mechanical Turk or third-party AWS Marketplace vendors would not be suitable.\noption A relies on object detection (bounding boxes) and doesn't switch to semantic segmentation. semantic segmentation provides precise labels, especially when distinguishing between closely placed objects like the yellow line and the passengers.","upvote_count":"1","comment_id":"1045005","timestamp":"1697462580.0","poster":"seifskl"},{"upvote_count":"1","content":"A: Using Amazon Rekognition Custom Labels you can do the same of Ground Truth\nthis answer is complete with all steps.","poster":"jopaca1216","comment_id":"1009230","timestamp":"1694886180.0"},{"comment_id":"1005801","timestamp":"1694525520.0","upvote_count":"1","content":"Selected Answer: A\nThe company can use Amazon Rekognition Custom Labels to label the dataset and create a custom Amazon Rekognition object detection model. They can create a private workforce and use Amazon Augmented AI (Amazon A2I) to review the low-confidence predictions and retrain the custom Amazon Rekognition model. This approach will help the company improve the model as it allows them to train a custom model that is specific to their business needs. The custom model can be trained to detect the yellow line, passengers who cross the yellow line, and trains in the video feeds. The private workforce ensures that the video data remains confidential, while Amazon A2I helps to improve the accuracy of the model by reviewing low-confidence predictions and retraining the model.\nwhich make A is more suitable than D using the Sagemaker Ground Truth semantic segmentation.","poster":"teka112233"},{"timestamp":"1694092680.0","upvote_count":"1","content":"The question asks for what labelling solution do you suggest, so based on that how can A be an answer? It is a solution that brings in a human review to the problem, while answer D is direct to the requirement","poster":"jyrajan69","comment_id":"1001599"},{"comment_id":"1001542","content":"Selected Answer: A\nA. Leverage pre-trained Amazon Rekognition and has the tools for creating bounding boxes\nB. Images are already labeled, the problem is not enough data for good accuracy\nC. Use of AWS Marketplace vendor does not satisfy privacy requirements\nD. Same issue as B","poster":"loict","timestamp":"1694089500.0","upvote_count":"1"},{"timestamp":"1693584780.0","poster":"kaike_reis","comment_id":"996240","upvote_count":"1","content":"Selected Answer: D\nWe want to categorize the images for object detection while keeping the content confidential. That said, Letters B and C are false as they breach confidentiality. To generate labels, it is recommended to use Ground Truth. Letter A is wrong as it misuses AWS Rekognition! By elimination, alternative D. He spoke about the labeling process, he spoke about AWS Ground Truth."},{"content":"Selected Answer: D\nOption D","poster":"Mickey321","upvote_count":"1","comment_id":"993444","timestamp":"1693336020.0"},{"comment_id":"991474","timestamp":"1693142760.0","content":"Selected Answer: D\nD not A","poster":"Mickey321","upvote_count":"1"},{"timestamp":"1692853740.0","upvote_count":"1","content":"Selected Answer: D\neither A or D but going with D","comment_id":"988846","poster":"Mickey321"},{"timestamp":"1691678880.0","comment_id":"977778","upvote_count":"1","content":"Selected Answer: A\nWe want to categorize the images for object detection while keeping the content confidential. That said, Letters B and C are false as they breach confidentiality. To generate labels, it is recommended to use Ground Truth, however Semantic Segmentation is different from object detection, so Letter D is wrong. Letter A is correct by elimination.","poster":"kaike_reis"},{"upvote_count":"2","timestamp":"1690747320.0","content":"Selected Answer: D\nSemantic segmentation is a fine-grained, pixel-level approach to identifying the contents of an image. It tags every pixel in an image with a class label from a predefined set of classes. This can help the model to clearly demarcate the yellow line, the passengers who cross the yellow line, and the trains in the video feeds.","comment_id":"967474","poster":"Mickey321"},{"upvote_count":"5","timestamp":"1679222340.0","poster":"blanco750","comment_id":"843642","content":"Selected Answer: A\nA looks a better option. as pointed by @tagos https://aws.amazon.com/blogs/machine-learning/using-amazon-rekognition-custom-labels-and-amazon-a2i-for-detecting-pizza-slices-and-augmenting-predictions/\nAlso some ppl mentioned in comments that A2I cant be used for confidentail data. From FAQs\nQ: Can Amazon Augmented AI third-party service providers process customer confidential data?\n\nA: Yes, Amazon Augmented AI service providers can process customer confidential data. The Standard Service Agreement between AWS customers and the third-party service provider contains clauses to protect your confidential"},{"upvote_count":"2","content":"Selected Answer: D\nD is correct, we need private workforce to label the dataset. A2I won't help with confidential data.","timestamp":"1678867260.0","comment_id":"839649","poster":"Amit11011996"},{"content":"Selected Answer: A\nIt says yellow line so semantic segmentation not helpful","timestamp":"1678019520.0","poster":"Chelseajcole","upvote_count":"2","comment_id":"829912"},{"poster":"AjoseO","upvote_count":"4","content":"Selected Answer: A\nSince the object detection model cannot clearly demarcate the yellow line, passengers who cross the yellow line, and the trains, it requires further fine-tuning with labeled data. Amazon Rekognition Custom Labels can help the company to label the dataset with bounding boxes and create a custom object detection model. Creating a private workforce will ensure the data privacy of the confidential video feeds. Amazon A2I can be used to review the low-confidence predictions and improve the model. By using this approach, the company can improve the accuracy of the model and address the specific requirements of the task.","timestamp":"1676819160.0","comment_id":"814199"},{"timestamp":"1675298220.0","upvote_count":"3","poster":"Jerry84","comment_id":"795627","content":"Selected Answer: A\nThere are two key information in the question. \n1. \"bounding box to label the sample data and uses an object detection model.\"\n2. \"The video data must remain confidential\"\n\nFor key point 1, we could rule out D as \"semantic segmentation labeling\" is a totally different labeling task from object detection labeling task. (see details in https://docs.aws.amazon.com/sagemaker/latest/dg/sms-label-images.html )\n\nFor key point 2, we could rule out B(Amazon Mechanical Turk), C(workforce with a third-party AWS Marketplace vendor). (see details in https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step1.html )"},{"content":"Selected Answer: D\nPrivate workforce is required. In A, Rekognition Custom Label is not for object labeling but for training.","timestamp":"1670705040.0","comment_id":"741226","poster":"Peeking","upvote_count":"1"},{"comment_id":"713978","upvote_count":"2","poster":"aScientist","content":"Selected Answer: A\nRekognition custom labels allows you to identify the objects and scenes in images that are specific to your business needs. For example, you can find your logo in social media posts, identify your products on store shelves etc. \nhttps://aws.amazon.com/rekognition/custom-labels-features/","timestamp":"1667925000.0"},{"content":"Link clearly states Mechanical Turk should not be used fo confidential data.\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-management-public.html","upvote_count":"1","timestamp":"1665011160.0","comment_id":"687303","poster":"31Rishab"},{"timestamp":"1663246680.0","content":"https://docs.aws.amazon.com/sagemaker/latest/dg/sms-semantic-segmentation.html","comment_id":"669938","upvote_count":"1","poster":"example_"},{"comment_id":"621391","content":"Selected Answer: A\nI say A because:\nAugmented AI can, but will not access Mechanical Turk in this instance. They used a private workforce instead.\n\nMechanical Turk is public, which disqualifies B. This also disqualifies C, which wants to use a 3rd party AWS vendor (not private).\n\nD is out because the problem is not one of semantic segmentation, it is object detection.","upvote_count":"10","poster":"ovokpus","timestamp":"1656032520.0"},{"comment_id":"607133","poster":"tgaos","content":"Answer A. From the example: https://aws.amazon.com/blogs/machine-learning/using-amazon-rekognition-custom-labels-and-amazon-a2i-for-detecting-pizza-slices-and-augmenting-predictions/","timestamp":"1653469560.0","upvote_count":"7"}],"topic":"1","answers_community":["D (51%)","A (49%)"],"timestamp":"2022-04-30 22:21:00","question_images":[],"answer":"D","choices":{"A":"Use Amazon Rekognition Custom Labels to label the dataset and create a custom Amazon Rekognition object detection model. Create a private workforce. Use Amazon Augmented AI (Amazon A2I) to review the low-confidence predictions and retrain the custom Amazon Rekognition model.","C":"Use Amazon Rekognition Custom Labels to label the dataset and create a custom Amazon Rekognition object detection model. Create a workforce with a third-party AWS Marketplace vendor. Use Amazon Augmented AI (Amazon A2I) to review the low-confidence predictions and retrain the custom Amazon Rekognition model.","B":"Use an Amazon SageMaker Ground Truth object detection labeling task. Use Amazon Mechanical Turk as the labeling workforce.","D":"Use an Amazon SageMaker Ground Truth semantic segmentation labeling task. Use a private workforce as the labeling workforce."},"isMC":true,"exam_id":26,"answer_ET":"D","question_text":"A company has video feeds and images of a subway train station. The company wants to create a deep learning model that will alert the station manager if any passenger crosses the yellow safety line when there is no train in the station. The alert will be based on the video feeds. The company wants the model to detect the yellow line, the passengers who cross the yellow line, and the trains in the video feeds. This task requires labeling. The video data must remain confidential.\nA data scientist creates a bounding box to label the sample data and uses an object detection model. However, the object detection model cannot clearly demarcate the yellow line, the passengers who cross the yellow line, and the trains.\nWhich labeling approach will help the company improve this model?","unix_timestamp":1651350060,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/74997-exam-aws-certified-machine-learning-specialty-topic-1/"},{"id":"G8qkC6dhm2Ri0ldlMvjc","answers_community":["BC (88%)","12%"],"url":"https://www.examtopics.com/discussions/amazon/view/75262-exam-aws-certified-machine-learning-specialty-topic-1/","timestamp":"2022-05-07 10:47:00","question_images":[],"isMC":true,"discussion":[{"poster":"ayatkhrisat","comment_id":"598665","content":"Selected Answer: BC\nB,C should be the answer","timestamp":"1652035440.0","upvote_count":"18"},{"upvote_count":"1","poster":"MultiCloudIronMan","timestamp":"1727185500.0","content":"Selected Answer: BC\nApply principal component analysis (PCA) (Option B): PCA is a dimensionality reduction technique that transforms the original features into a smaller set of uncorrelated components, which can help in reducing the redundancy caused by highly correlated features.\nRemove a portion of highly correlated features from the dataset (Option C): By removing some of the highly correlated features, the data engineer can simplify the model and reduce multicollinearity, which can improve the modelâ€™s performance and interpretability","comment_id":"1288624"},{"comment_id":"1164258","comments":[{"content":"I change my mind to B and C now","upvote_count":"1","timestamp":"1711930740.0","poster":"vkbajoria","comment_id":"1187104"}],"content":"BD should be the answer","poster":"vkbajoria","timestamp":"1709401320.0","upvote_count":"1"},{"poster":"DimLam","upvote_count":"2","comment_id":"1047776","timestamp":"1697708760.0","content":"Selected Answer: BD\nPCA is sensitive to the variance of features, so it's a common practice to standardize (e.g., z-score normalization) or scale (e.g., min-max scaling) the features before applying PCA. If the features are on different scales, it can distort which principal components are viewed as the most important."},{"poster":"kaike_reis","comments":[{"comment_id":"1047775","content":"Agree. \nAs a question asks us what steps to perform, then it is logical to say: \"Scale features and apply PCA\"\n\nwe can't answer \"remove a portion of correlated features and then apply PCA\", or vice versa. as it doesn't make sense.\n\nIt would make some sense if we were asked \"What technics engineer can apply\", or smth similar","poster":"DimLam","upvote_count":"1","timestamp":"1697708580.0"}],"timestamp":"1691679180.0","upvote_count":"2","comment_id":"977783","content":"Selected Answer: BD\nWell, first time that I go with the Suggested Answer. D - B is the way: We want to solve the base correlation problem. That said, Letters A - E don't solve this problem, so they're wrong. Letter C partially solves the problem, so it is wrong. As we want steps, the correct alternatives are: D (ensure that all variables are on the same scale) and B (apply PCA that removes all correlation from the base while keeping most of the information).\n\nAgain, from my perspective (C) is vague and using (B) removes the necessity of drop highly correlated features."},{"content":"Selected Answer: BC\nthe most effective steps to address the issue of high correlation among the features in the dataset are removing a portion of highly correlated features and applying principal component analysis (PCA) for dimensionality reduction. These steps will help improve the data quality and predictive performance of the model.","comment_id":"967477","upvote_count":"1","poster":"Mickey321","timestamp":"1690747500.0"},{"upvote_count":"2","comment_id":"814434","timestamp":"1676835000.0","poster":"AjoseO","content":"Selected Answer: BC\nPCA is a widely used technique for reducing the dimensionality of high-dimensional datasets while retaining as much of the original variability as possible. It is particularly useful when dealing with highly correlated features.\n\nRemoving a portion of highly correlated features can be another effective way to address the issue of high correlation. By removing some of the correlated features, the model can become less complex and less prone to overfitting."},{"poster":"ovokpus","timestamp":"1656207300.0","upvote_count":"3","content":"Selected Answer: BC\nMinMax scaling does nothing to fix the issue here","comment_id":"622307"},{"content":"Selected Answer: BC\nBC for me, minmax scaler cannot remove multicollinearity?","upvote_count":"4","timestamp":"1651913220.0","poster":"ckkobe24","comment_id":"598042"}],"answer_ET":"BC","question_text":"A data engineer at a bank is evaluating a new tabular dataset that includes customer data. The data engineer will use the customer data to create a new model to predict customer behavior. After creating a correlation matrix for the variables, the data engineer notices that many of the 100 features are highly correlated with each other.\nWhich steps should the data engineer take to address this issue? (Choose two.)","unix_timestamp":1651913220,"answer_description":"","topic":"1","answer_images":[],"choices":{"A":"Use a linear-based algorithm to train the model.","B":"Apply principal component analysis (PCA).","E":"Apply one-hot encoding category-based variables.","D":"Apply min-max feature scaling to the dataset.","C":"Remove a portion of highly correlated features from the dataset."},"question_id":77,"exam_id":26,"answer":"BC"},{"id":"2HCwFrw80IL8nSxEavc3","answer":"C","answer_images":[],"exam_id":26,"timestamp":"2022-04-30 22:45:00","isMC":true,"topic":"1","answer_description":"","question_text":"A company is building a new version of a recommendation engine. Machine learning (ML) specialists need to keep adding new data from users to improve personalized recommendations. The ML specialists gather data from the users' interactions on the platform and from sources such as external websites and social media.\nThe pipeline cleans, transforms, enriches, and compresses terabytes of data daily, and this data is stored in Amazon S3. A set of Python scripts was coded to do the job and is stored in a large Amazon EC2 instance. The whole process takes more than 20 hours to finish, with each script taking at least an hour. The company wants to move the scripts out of Amazon EC2 into a more managed solution that will eliminate the need to maintain servers.\nWhich approach will address all of these requirements with the LEAST development effort?","url":"https://www.examtopics.com/discussions/amazon/view/74998-exam-aws-certified-machine-learning-specialty-topic-1/","choices":{"C":"Create an AWS Glue job. Convert the scripts to PySpark. Execute the pipeline. Store the results in Amazon S3.","A":"Load the data into an Amazon Redshift cluster. Execute the pipeline by using SQL. Store the results in Amazon S3.","B":"Load the data into Amazon DynamoDB. Convert the scripts to an AWS Lambda function. Execute the pipeline by triggering Lambda executions. Store the results in Amazon S3.","D":"Create a set of individual AWS Lambda functions to execute each of the scripts. Build a step function by using the AWS Step Functions Data Science SDK. Store the results in Amazon S3."},"question_images":[],"discussion":[{"comments":[{"poster":"ckkobe24","content":"but C requires some coding efforts","comments":[{"upvote_count":"1","timestamp":"1699364340.0","content":"I think C is correct, because pyspark are also a kind of Python, and it only require a little code change.","poster":"daidaidai","comment_id":"891346"}],"timestamp":"1667882160.0","comment_id":"598412","upvote_count":"1"}],"poster":"spaceexplorer","comment_id":"595281","upvote_count":"15","timestamp":"1667169900.0","content":"Selected Answer: C\nC; Lambda execution time has hard limit of 15 mins which might not be enough for data processing"},{"upvote_count":"1","poster":"Stokvisss","comment_id":"1161390","content":"Selected Answer: C\nD is wrong as AWS Lambda has a maximum execution time of 15 minutes, which may not be sufficient for some of the scripts. C is right as it's serverless and not a lot of work.","timestamp":"1724825880.0"},{"poster":"endeesa","upvote_count":"1","comment_id":"1082457","content":"Selected Answer: C\nRedshift is definitely going to require some effort to setup, lambda just won't cut it performance-wise if the EC2 instance can't. Guess whats left?","timestamp":"1716886980.0"},{"comment_id":"1062033","upvote_count":"1","timestamp":"1714813740.0","content":"Selected Answer: C\nC seems the most correct but it misses the part of importing data in AWS","poster":"giustino98"},{"timestamp":"1710258120.0","poster":"teka112233","upvote_count":"1","comment_id":"1005804","content":"Selected Answer: C\noption c fit all requirements since, it provides the least development effort using AWS Glue, and convert the python to pyspark which provide the most performance.\noption D is not suitable because lambda function has a limitation of only 15 minutes ruining while the script needs 1 hour."},{"comment_id":"977788","poster":"kaike_reis","content":"Selected Answer: C\nWe want to eliminate server management and reduce development effort. That said, Letter A is wrong, as it brings effort to refactor code. Letter B is wrong as DynamoDB asks for server management. Letter D is wrong, because despite the services being serverless (Lambda and Step Functions), the maximum timeout of a Lambda function is 15 minutes, which would be less than the desired one (1 hour). Letter C is correct, even if there is a pure Python code conversion effort â†’ PySpark, this is the solution that fits the requirements.","upvote_count":"1","timestamp":"1707584340.0"},{"timestamp":"1706657100.0","comment_id":"967522","upvote_count":"1","content":"Selected Answer: C\nOption C is the best option because it allows you to use the existing Python scripts without having to convert them to a different language or framework. AWS Glue is a managed service that makes it easy to prepare data for analysis. PySpark is a Python library that allows you to use Spark to process data. This approach would address all of the requirements with the least development effort and would be able to handle large-scale data processing.","poster":"Mickey321"},{"comment_id":"967510","upvote_count":"1","content":"Selected Answer: D\nOverall, option C with AWS Glue and PySpark is the most efficient approach, as it requires the least amount of development effort while effectively addressing all the requirements, including moving away from EC2 maintenance and handling large-scale data processing.","timestamp":"1706655660.0","comments":[{"upvote_count":"1","comment_id":"988848","poster":"Mickey321","timestamp":"1708758660.0","content":"corrected to option c"}],"poster":"Mickey321"},{"poster":"AjoseO","content":"Selected Answer: C\nThe data pipeline involves cleaning, transforming, enriching, and compressing terabytes of data and storing the data in Amazon S3. \n\nAWS Glue is an ETL service that makes it easy to move data between data stores. The Glue job allows you to use PySpark scripts to perform ETL tasks. With AWS Glue, you do not need to provision and manage servers, which eliminates the need to maintain servers, as required by the company. \n\nTherefore, AWS Glue would address all of the company's requirements with the least development effort.","upvote_count":"3","timestamp":"1692466560.0","comment_id":"814441"},{"upvote_count":"1","timestamp":"1690730700.0","comment_id":"793097","content":"Selected Answer: D\n1) eliminate the need to maintain servers - Lambda is serverless 2) the least development effort - python scripts do no need to be rewritten for Lambda function","poster":"maxkm","comments":[{"comment_id":"818626","upvote_count":"5","content":"\"with each script taking at least an hour\" - lambda would be time-out during taking job.","poster":"GiyeonShin","timestamp":"1692746640.0"}]},{"comment_id":"638279","content":"Selected Answer: C\nC as for Redshift I need to build a new pipeline","poster":"milan_ml","timestamp":"1674851700.0","upvote_count":"1"},{"comment_id":"622506","poster":"ovokpus","timestamp":"1672060740.0","upvote_count":"2","content":"Selected Answer: C\nConverting python scripts to pyspark is less coding effort than writing up SQL, which is somewhat limited in the types of transformations it can do.\n\nLambda function responses are a deadend for reason already given (timeout)"}],"unix_timestamp":1651351500,"answer_ET":"C","answers_community":["C (93%)","7%"],"question_id":78},{"id":"l87iz8aZLDtadEpSWKIL","question_text":"An employee found a video clip with audio on a company's social media feed. The language used in the video is Spanish. English is the employee's first language, and they do not understand Spanish. The employee wants to do a sentiment analysis.\nWhat combination of services is the MOST efficient to accomplish the task?","question_id":79,"answer_images":[],"answer_ET":"A","question_images":[],"choices":{"C":"Amazon Transcribe, Amazon Translate, and Amazon SageMaker Neural Topic Model (NTM)","B":"Amazon Transcribe, Amazon Comprehend, and Amazon SageMaker seq2seq","A":"Amazon Transcribe, Amazon Translate, and Amazon Comprehend","D":"Amazon Transcribe, Amazon Translate and Amazon SageMaker BlazingText"},"discussion":[{"poster":"DonaldCMLIN","timestamp":"1632099000.0","comment_id":"21888","content":"the MOST efficient means to you don't need to coding, building infra\nAll of sevices are manage by AWS is good,\nTranscribe, Amazon Translate, and Amazon Comprehend \n\nAnswer is A","upvote_count":"43","comments":[{"upvote_count":"9","poster":"WWODIN","timestamp":"1632700920.0","comment_id":"34337","content":"Agree, Answer is A"}]},{"comment_id":"730131","content":"A is not 100% correct. You don't need to translate Spanish. Amazon Comprehend supports Spanish.","comments":[{"poster":"cpal012","comments":[{"poster":"tonton3","content":"I think there is no need to use Amazon translate because sometimes the translation is not accurate.\nIt means some information gets lost.","timestamp":"1687725720.0","upvote_count":"1","comment_id":"933884","comments":[{"content":"Given the question, I believe that is necessary: look at the enphase of not understanding spanish. besides that, even with some information lost, you will at least understand something.","poster":"kaike_reis","timestamp":"1690389180.0","comment_id":"963977","upvote_count":"1"}]}],"upvote_count":"2","timestamp":"1679257080.0","comment_id":"844206","content":"Arguably, you still need a translation since the person doesn't speak Spanish."}],"timestamp":"1669712280.0","upvote_count":"8","poster":"Pg690"},{"content":"Selected Answer: A\nA. Amazon Transcribe, Amazon Translate, and Amazon Comprehend\nExplanation of the Process:\nAmazon Transcribe â€“ Converts the Spanish audio in the video into text.\nAmazon Translate â€“ Translates the Spanish text to English.\nAmazon Comprehend â€“ Performs sentiment analysis on the translated English text.","comment_id":"1357339","timestamp":"1739731920.0","poster":"JonSno","upvote_count":"2"},{"timestamp":"1727164500.0","comment_id":"935835","upvote_count":"2","content":"It's A:\n1.Amazon Transcribe - to convert Spanish speech to Spanish text.\n2.Amazon Translate - to translate Spanish text to English text\n3.Amazon Comprehend - to analyze text for sentiments","poster":"ADVIT"},{"content":"Selected Answer: A\nA. YES - Comprehend is supervised so user must understand through Translate\nB. NO - seq2seq is for generation and not classification\nC. NO - Amazon SageMaker Neural Topic Model is unsupervised topic extraction, will not give sentiment against user-defined classes\nD. NO - BlazingText is word2vec, does not give sentiment classes","upvote_count":"1","timestamp":"1727164500.0","comment_id":"1006371","poster":"loict"},{"poster":"Mickey321","content":"Selected Answer: A\nIt's A:\n1.Amazon Transcribe - to convert Spanish speech to Spanish text.\n2.Amazon Translate - to translate Spanish text to English text\n3.Amazon Comprehend - to analyze text for sentiments","timestamp":"1727164500.0","upvote_count":"2","comment_id":"973127"},{"poster":"DavidRou","comment_id":"968168","content":"It's A 100%","timestamp":"1690812360.0","upvote_count":"1"},{"poster":"CKS1210","timestamp":"1687161180.0","upvote_count":"1","comment_id":"927281","content":"Transcribe: Speech to text\nTranslate: Any language to any language\nComprehend: offers a range of capabilities for extracting insights and meaning from unstructured text data. Ex: Sentiment analysis, entity recognition, KeyPhrase Extraction, Language Detection, Document Classification"},{"content":"absolutely need STT(transcribe), translation(translate), and sentimental analysis(comprehend)","upvote_count":"1","timestamp":"1686095100.0","comment_id":"916717","poster":"soonmo"},{"poster":"gnolam","content":"Selected Answer: A\nA - confirmed by ACG","timestamp":"1662551460.0","upvote_count":"2","comment_id":"662430"},{"content":"Selected Answer: A\nI agree that the answer is A","timestamp":"1640903580.0","poster":"KM226","upvote_count":"1","comment_id":"513761"},{"upvote_count":"1","content":"Selected Answer: A\nanswer is a","comment_id":"494098","timestamp":"1638684480.0","poster":"in4976"},{"comment_id":"433752","upvote_count":"1","content":"A; D is wrong because The Amazon SageMaker BlazingText algorithm provides highly optimized implementations of the Word2vec and text classification algorithms.","timestamp":"1636115400.0","poster":"Dr_Kiko"},{"upvote_count":"1","comment_id":"260672","timestamp":"1635713520.0","content":"The Question/Anwser is not poorly as someone mentioned.\n--Even though Comprehend can do the analysis directly on Spanish (no need of translate) but if comprehend does analysis and the resulting words are still in spanish , it will no help the employee as he doesnt know Spanish.So the transalate after transcribe will help Employee understand what is being analyzed by Comprehend in next step.\nSo read the question carefully before jumping to conclusions. it will save you an Exam :)","poster":"harmanbirstudy"},{"poster":"senseikimoji","content":"I don't get this question. Comprehend supports Spanish natively. There is no need for Translate, and translate would actually reduce effectiveness of sentimental analysis. However, BCD are all invalid choices.","timestamp":"1635534660.0","comment_id":"229556","upvote_count":"3"},{"content":"A\nbecause Comprehend can provide sentiment analysis","timestamp":"1635400020.0","upvote_count":"2","poster":"ybad","comment_id":"223868"},{"poster":"FastTrack","upvote_count":"4","content":"A,\nhttps://aws.amazon.com/getting-started/hands-on/analyze-sentiment-comprehend/","comment_id":"176539","timestamp":"1634725500.0"},{"content":"Amazon Comprehend is needed for sure; answer is A 100%","poster":"syu31svc","upvote_count":"3","timestamp":"1634592120.0","comment_id":"165071"},{"comment_id":"150477","timestamp":"1634458020.0","poster":"hans1234","content":"You actually do not need Translate. Comprehend can do sentiment analysis on spanish language. But in this case it is A.","upvote_count":"2","comments":[{"timestamp":"1635648900.0","content":"You are right but since the employee doesn't know Spanish it would be good if he has an insight into how well the sentiments were captured by comprehend.","poster":"Aanish","comment_id":"252565","upvote_count":"2"}]},{"timestamp":"1633947540.0","upvote_count":"3","comment_id":"108340","poster":"Antriksh","content":"These answers are clearly misleading. The correct answer is A"},{"upvote_count":"3","poster":"roytruong","comment_id":"98685","content":"it's A","timestamp":"1633623420.0"},{"comment_id":"58346","content":"Answer is A.","poster":"AKT","timestamp":"1633502640.0","upvote_count":"3"},{"upvote_count":"7","content":"Definitely A.","poster":"Phong","comment_id":"50895","timestamp":"1633461300.0"},{"timestamp":"1633361880.0","comment_id":"47973","upvote_count":"1","content":"should be D\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html","comments":[{"content":"A is more efficient because if using sagemaker we still need to build a model first, but amazon comprehen is pre-build model so A is more efficient. CMIIW","comment_id":"128654","poster":"eji","timestamp":"1634389260.0","upvote_count":"7"},{"comment_id":"222397","upvote_count":"2","poster":"h_sahu","content":"It shouldn't be D as per me. Blazing text is used for classification. This can indirectly help in sentiment analysis no doubt. I believer A is the answer. Because, transcribe will be used to convert speech to text, translate will be used to translate those texts received from transcribe and Comprehend is a complete NLP tool from amazon out-of-the-box which is capable of sentiment analysis.","timestamp":"1635238980.0"}],"poster":"grandgale"}],"url":"https://www.examtopics.com/discussions/amazon/view/8306-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","unix_timestamp":1573871040,"exam_id":26,"answers_community":["A (100%)"],"timestamp":"2019-11-16 03:24:00","answer":"A","answer_description":"","isMC":true},{"id":"sZL9ymI3zpcgBO7i0rcM","question_text":"A retail company is selling products through a global online marketplace. The company wants to use machine learning (ML) to analyze customer feedback and identify specific areas for improvement. A developer has built a tool that collects customer reviews from the online marketplace and stores them in an Amazon S3 bucket. This process yields a dataset of 40 reviews. A data scientist building the ML models must identify additional sources of data to increase the size of the dataset.\nWhich data sources should the data scientist use to augment the dataset of reviews? (Choose three.)","answer_ET":"ABD","answers_community":["ABD (100%)"],"unix_timestamp":1651177800,"url":"https://www.examtopics.com/discussions/amazon/view/74809-exam-aws-certified-machine-learning-specialty-topic-1/","question_id":80,"answer_description":"","discussion":[{"comment_id":"595239","content":"Selected Answer: ABD\nABD; Email exchange between customer and customer service would be valuable data source.","timestamp":"1682884020.0","upvote_count":"29","poster":"spaceexplorer"},{"comment_id":"977792","content":"Selected Answer: ABD\nEveryone explained correct.","timestamp":"1723302120.0","upvote_count":"2","poster":"kaike_reis"},{"upvote_count":"2","comment_id":"967525","content":"Selected Answer: ABD\nIn conclusion, the data scientist should use customer service emails, social media posts, and publicly available customer reviews to augment the dataset of reviews for the analysis of customer feedback and identifying specific areas for improvement.","timestamp":"1722374940.0","poster":"Mickey321"},{"comment_id":"814458","poster":"AjoseO","content":"Selected Answer: ABD\nA: Emails exchanged by customers and the company's customer service agents can provide additional customer feedback and opinions about the products or services. This data can be used to improve the ML model.\n\nB: Social media posts containing the name of the company or its products can provide additional customer feedback and opinions about the products or services, which can be used to improve the ML model.\n\nD: A publicly available collection of customer reviews can be used to augment the existing dataset of reviews and increase the size of the dataset. This can help to improve the accuracy of the ML model.","comments":[{"content":"C: A publicly available collection of news articles and F: Instruction manuals for the company's products are not directly related to customer feedback and may not be relevant for improving the ML model in this context.\n\nE: Product sales revenue figures for the company can provide valuable insights into the company's financial performance, but this data is not directly related to customer feedback and may not be useful for improving the ML model in this context.","comment_id":"814459","timestamp":"1708371960.0","poster":"AjoseO","upvote_count":"2"}],"timestamp":"1708371960.0","upvote_count":"4"},{"poster":"f4bi4n","comments":[{"comment_id":"977793","content":"Don't overthink conrad.","upvote_count":"1","timestamp":"1723302180.0","poster":"kaike_reis"},{"comment_id":"746689","poster":"Sonoko","timestamp":"1702691820.0","content":"ABE makes more sense here.","upvote_count":"2"},{"content":"That's exactly the point though, we want more volume of reviews, or anything resembling reviews as is the case with email exchanges.","timestamp":"1696584360.0","upvote_count":"1","comment_id":"687641","poster":"AdolinKholin"}],"content":"I think ABE or maybe(!) ABF\nA & B -> for sure\nC -> No glue how this should help\nD -> We have already reviews!?\nE -> Could help to find correlations between negative / positive reviews and sales\nF -> non-sense in the first moment and second as well, but maybe it could help to combine the information of Email, Social and Reviews to some problems.","upvote_count":"3","timestamp":"1687171680.0","comment_id":"618643"},{"timestamp":"1682713800.0","content":"BDF - correct answer","poster":"bluer1","upvote_count":"1","comment_id":"594039"}],"choices":{"B":"Social media posts containing the name of the company or its products","A":"Emails exchanged by customers and the company's customer service agents","C":"A publicly available collection of news articles","D":"A publicly available collection of customer reviews","E":"Product sales revenue figures for the company","F":"Instruction manuals for the company's products"},"question_images":[],"topic":"1","timestamp":"2022-04-28 22:30:00","answer_images":[],"answer":"ABD","exam_id":26,"isMC":true}],"exam":{"isMCOnly":false,"isBeta":false,"name":"AWS Certified Machine Learning - Specialty","isImplemented":true,"provider":"Amazon","id":26,"numberOfQuestions":369,"lastUpdated":"11 Apr 2025"},"currentPage":16},"__N_SSP":true}