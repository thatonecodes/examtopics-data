{"pageProps":{"questions":[{"id":"7hquPoLU0rX3MkMu28T6","answer_images":[],"choices":{"C":"Use the reader endpoint for one application and an instance endpoint for the other application.","A":"Use a different instance endpoint for each application.","B":"Use the reader endpoint for both applications.","D":"Use different custom endpoints for each application."},"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/103965-exam-aws-certified-database-specialty-topic-1-question-289/","question_text":"A company is using Amazon Aurora with Aurora Replicas. A database specialist needs to split up two read-only applications so that each application connects to a different set of DB instances. The database specialist wants to implement load balancing and high availability for the read-only applications.\n\nWhich solution meets these requirements?","timestamp":"2023-03-26 15:53:00","question_id":211,"isMC":true,"exam_id":22,"question_images":[],"answer_description":"","topic":"1","answers_community":["D (100%)"],"answer_ET":"D","unix_timestamp":1679838780,"discussion":[{"content":"A : instance endpoint\n An instance endpoint connects to a specific DB instance within an Aurora cluster. Each DB instance in a DB cluster has its own unique instance endpoint\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html","comment_id":"1011644","timestamp":"1695151440.0","upvote_count":"1","poster":"zyjp"},{"poster":"Pranava_GCP","comment_id":"1004748","timestamp":"1694433960.0","content":"Selected Answer: D\nD. Use different custom endpoints for each application. \n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Overview.Endpoints.Types:~:text=The%20custom%20endpoints,the%20same%20endpoint.","upvote_count":"2"},{"timestamp":"1689761100.0","poster":"Windy","upvote_count":"1","comment_id":"956499","content":"It's D"},{"timestamp":"1684475160.0","poster":"AWS_SJ","comment_id":"901667","upvote_count":"1","content":"B\nAs per the doc, If the cluster contains one or more Aurora Replicas, the reader endpoint load-balances each connection request among the Aurora Replicas. I\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Overview.Endpoints.Types"},{"upvote_count":"2","comments":[{"comment_id":"907447","timestamp":"1685111760.0","content":"has to be D as \"each application connects to a different set of DB instances\"","poster":"cnmc","upvote_count":"3"}],"comment_id":"851105","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Overview.Endpoints.Types","poster":"rdiaz","timestamp":"1679838780.0"}]},{"id":"cPHxsJoN1xOKx9pL8I3f","answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/67416-exam-aws-certified-database-specialty-topic-1-question-29/","answer_description":"","question_images":[],"question_id":212,"unix_timestamp":1639058040,"discussion":[{"upvote_count":"9","poster":"grekh001","timestamp":"1639408320.0","content":"\"To ensure that your data was migrated accurately from the source to the target, we highly recommend that you use data validation.\" \nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_BestPractices.html\n\nAnswer is D.","comment_id":"500679"},{"upvote_count":"1","content":"Selected Answer: D\nDMS supports the validation between source and target data. But SCT does not support it.","poster":"Hisayuki","comment_id":"1110977","timestamp":"1704089040.0"},{"content":"table metrics of the AWS DMS can be verified manully for DMS task. There is no mechanism which provided an automated for reading these metric and providing confirmation if every thing went well. If you are working 100+ tables then DMS Data Validation is the only option. \nD is best fit","upvote_count":"2","poster":"sachin","comment_id":"624367","timestamp":"1656467880.0"},{"upvote_count":"2","comment_id":"595014","content":"Selected Answer: D\nD would run select queries on source & target to compare rows, so some load\n\nB is also good candidate, rather better but it needed \"The data validation option in the DMS task has to be activated before DMS \"\nYou can find individual table metrics on the Table statistics tab for each individual task. These metrics include these numbers:\nRows loaded during the full load.\nInserts, updates, and deletes since the task started.\nDDL operations since the task started.\n\nB. Use the table metrics of the AWS DMS task created for migrating the data to verify the statistics for the tables being migrated and to verify that the data definition language (DDL) statements are completed.\n\nD. Enable AWS DMS data validation on the task so the AWS DMS task compares the source and target records, and reports any mismatches.","timestamp":"1651323540.0","poster":"novice_expert"},{"poster":"tugboat","timestamp":"1645758420.0","upvote_count":"3","comment_id":"555721","content":"Selected Answer: D\nD for data validation"},{"upvote_count":"1","comment_id":"509699","timestamp":"1640535540.0","comments":[{"poster":"awsmonster","upvote_count":"3","timestamp":"1641887880.0","comment_id":"521365","content":"Answer should be D:\n\nThe data validation option in the DMS task has to be activated before DMS performs what SMAZ has written. B does not mention anything about enabling it."}],"poster":"SMAZ","content":"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Validating.html\nDuring data validation, AWS DMS compares each row in the source with its corresponding row at the target, verifies the rows contain the same data, and reports any mismatches. To accomplish this AWS DMS issues appropriate queries to retrieve the data. Note that these queries will consume additional resources at the source and target as well as additional network resources.\n\nSo Answer should be B"},{"poster":"SMAZ","timestamp":"1640441520.0","comments":[{"comment_id":"561552","poster":"RotterDam","content":"No datavalidation can ONLY be done using Task Validation and it has to be enabled before DMS tasks start and after migration is finished. Its a very common question. D is the correct choice","timestamp":"1646502240.0","upvote_count":"1"}],"comment_id":"509144","upvote_count":"2","content":"'The migration should have a negligible effect on the source database's performance.'\nI believe answer should be 'B'\nTable metrics\nYou can find individual table metrics on the Table statistics tab for each individual task. These metrics include these numbers:\nRows loaded during the full load.\nInserts, updates, and deletes since the task started.\nDDL operations since the task started."},{"poster":"2025flakyt","timestamp":"1639058040.0","comment_id":"497768","content":"D is the correct answer","upvote_count":"3"}],"answer":"D","choices":{"C":"Enable the AWS Schema Conversion Tool (AWS SCT) premigration validation and review the premigration checklist to make sure there are no issues with the conversion.","B":"Use the table metrics of the AWS DMS task created for migrating the data to verify the statistics for the tables being migrated and to verify that the data definition language (DDL) statements are completed.","D":"Enable AWS DMS data validation on the task so the AWS DMS task compares the source and target records, and reports any mismatches.","A":"Use the AWS Schema Conversion Tool (AWS SCT) to convert source Oracle database schemas to the target Aurora DB cluster. Verify the datatype of the columns."},"topic":"1","question_text":"A company wants to migrate its existing on-premises Oracle database to Amazon Aurora PostgreSQL. The migration must be completed with minimal downtime using AWS DMS. A Database Specialist must validate that the data was migrated accurately from the source to the target before the cutover. The migration must have minimal impact on the performance of the source database.\nWhich approach will MOST effectively meet these requirements?","isMC":true,"answer_ET":"D","answer_images":[],"timestamp":"2021-12-09 14:54:00","exam_id":22},{"id":"KSxDCoLn485ZA5uaVTRc","question_text":"A company uses an Amazon DynamoDB table to store data for an application. The application requires full access to the table. Some employees receive direct access to the table, but a security policy restricts their access to only certain fields. The company wants to begin using a DynamoDB Accelerator (DAX) cluster on top of the DynamoDB table.\n\nHow can the company ensure that the security policy is maintained after the implementation of the DAX cluster?","url":"https://www.examtopics.com/discussions/amazon/view/103967-exam-aws-certified-database-specialty-topic-1-question-290/","question_id":213,"answer_description":"","timestamp":"2023-03-26 16:06:00","isMC":true,"answer":"D","unix_timestamp":1679839560,"answer_images":[],"discussion":[{"upvote_count":"3","comment_id":"1122365","timestamp":"1705218840.0","content":"Selected Answer: D\nD\n\"The application requires full access to the table. Some employees receive direct access to the table, but a security policy restricts their access to only certain fields\"\nTherefore, the app will use DAX, and the employees can access the table directly.","poster":"MultiAZ"},{"upvote_count":"2","timestamp":"1694697540.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.access-control.html","comment_id":"1007683","poster":"DanShone"},{"timestamp":"1693505520.0","upvote_count":"2","poster":"Pranava_GCP","content":"Selected Answer: D\nD. Modify the IAM policies for the employees. Allow the employees to access the DynamoDB table without allowing the employees to access the DAX cluster. \n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.access-control.html\n\n\"If you are currently using IAM roles and policies to restrict access to DynamoDB tables data, then the use of DAX can subvert those policies. For example, a user could have access to a DynamoDB table via DAX but not have explicit access to the same table accessing DynamoDB directly\"","comment_id":"995388"},{"upvote_count":"1","comment_id":"977715","content":"What is the final correct answer D or C ? I am split between the two - 50-50 at the moment.","timestamp":"1691673060.0","poster":"Monknil"},{"comment_id":"956038","poster":"Windy","content":"It's D.","timestamp":"1689725040.0","upvote_count":"1"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.access-control.html\nAccoding to the Docs, D would be correct, since we won't be able to restrict users from accessing some parts of DAX while allowing the application to access all parts.","poster":"Kodoma","upvote_count":"2","comment_id":"908940","timestamp":"1685319660.0"},{"comment_id":"906602","timestamp":"1685014260.0","content":"Selected Answer: D\nxA. Already in place...\nxB. User-level separation not supported by DAX\nxC. Users of the DAX cluster \"inherit\" the DynamoDB policy of DAX\nD. The employees need to continue to access the Table directly from DynamoDB, while the applications use DAX.\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.access-control.html","upvote_count":"4","comments":[{"poster":"cnmc","upvote_count":"1","timestamp":"1685119020.0","comment_id":"907503","content":"D is correct. Answer C is wrong because DAX doesn't allow attribute-level access control.\n\nFor example, you can create a user role that only allows the user to perform read-only actions on a particular DynamoDB table. (For more information, see Identity and Access Management for Amazon DynamoDB.) By comparison, the DAX security model focuses on cluster security, and the ability of the cluster to perform DynamoDB API actions on your behalf."}],"poster":"aviathor"},{"upvote_count":"4","timestamp":"1679839560.0","comment_id":"851117","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.access-control.html","poster":"rdiaz"}],"answer_ET":"D","question_images":[],"choices":{"B":"Modify the IAM policies for the IAM service role of the DAX cluster. Implement user-level separation to allow access to DynamoDB.","C":"Modify the IAM policies for the employees. Allow the employees to access the DAX cluster without allowing the employees to access the DynamoDB table.","A":"Modify the IAM policies for the employees. Implement user-level separation that allows the employees to access the DAX cluster.","D":"Modify the IAM policies for the employees. Allow the employees to access the DynamoDB table without allowing the employees to access the DAX cluster."},"exam_id":22,"answers_community":["D (76%)","C (24%)"],"topic":"1"},{"id":"Z8p7CofhPoE4YMIRUa0L","answer":"A","question_images":[],"exam_id":22,"question_id":214,"discussion":[{"poster":"rdiaz","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/redshift/latest/dg/r_SVL_QLOG.html","comments":[{"poster":"Mintwater","comment_id":"860931","upvote_count":"2","content":"table column - abported:\n\"\nIf a query was stopped by the system or canceled by the user, this column contains 1. If the query ran to completion, this column contains 0. Queries that are canceled for workload management purposes and subsequently restarted also have a value of 1 in this column.\"","timestamp":"1680606840.0"}],"timestamp":"1679839800.0","comment_id":"851121","upvote_count":"5"},{"content":"Selected Answer: A\nSVL_QLOG view","timestamp":"1705216560.0","comment_id":"1122337","poster":"MultiAZ","upvote_count":"1"},{"timestamp":"1693505940.0","comment_id":"995393","upvote_count":"2","content":"Selected Answer: A\nA. Look for the terminated queries in the SVL_QLOG view.","poster":"Pranava_GCP"},{"content":"Selected Answer: A\nA is the correct option. We can query SVL_QLOG table to check for aborted queries\n\nselect query, elapsed, trim(label) querylabel from svl_qlog where aborted=1;","comment_id":"857140","timestamp":"1680270720.0","poster":"backbencher2022","upvote_count":"2"}],"unix_timestamp":1679839800,"topic":"1","answer_ET":"A","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/103968-exam-aws-certified-database-specialty-topic-1-question-291/","answer_images":[],"timestamp":"2023-03-26 16:10:00","answer_description":"","question_text":"A company uses an Amazon Redshift cluster to support its business intelligence (BI) team. The cluster has a maintenance window that overlaps with some business report jobs that run long-running queries on the cluster. During a recent maintenance window, the cluster went offline and restarted for an update. The BI team wants to know which queries were terminated during the maintenance window.\n\nWhat should a database specialist do to obtain this information?","choices":{"B":"Look for the terminated queries in the SVL_QUERY_REPORT view.","D":"Use a federated query to find the terminated queries.","A":"Look for the terminated queries in the SVL_QLOG view.","C":"Write a scalar SQL user-defined function to find the terminated queries."},"answers_community":["A (100%)"]},{"id":"NA5Qwfg5s3gc4kdZkYMF","discussion":[{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy-managing.html#rds-proxy-connection-pooling-tuning.maxidleconnectionspercent","poster":"rdiaz","upvote_count":"5","timestamp":"1679840340.0","comment_id":"851132","comments":[{"poster":"Mintwater","upvote_count":"2","timestamp":"1680607620.0","comment_id":"860944","content":"MaxIdleConnectionsPercent\n\"You can control the number of idle database connections that RDS Proxy can keep in the connection pool. RDS Proxy considers a database connection in it's pool to be idle when there's been no activity on the connection for five minutes.\n\nYou specify the limit as a percentage of the maximum connections available for your database. The default value is 50 percent of MaxConnectionsPercent, and the upper limit is the value of MaxConnectionsPercent. With a high value, the proxy leaves a high percentage of idle database connections open. With a low value, the proxy closes a high percentage of idle database connections. If your workloads are unpredictable, consider setting a high value for MaxIdleConnectionsPercent. Doing so means that RDS Proxy can accommodate surges in activity without opening a lot of new database connections.\""}]},{"upvote_count":"1","poster":"DanShone","comment_id":"1007685","timestamp":"1694697720.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy-managing.html#rds-proxy-connection-pooling-tuning.maxidleconnectionspercent"},{"content":"It's C.","timestamp":"1689724620.0","comment_id":"956033","upvote_count":"1","poster":"Windy"}],"answers_community":["C (100%)"],"topic":"1","isMC":true,"timestamp":"2023-03-26 16:19:00","exam_id":22,"question_images":[],"answer_images":[],"answer":"C","answer_description":"","unix_timestamp":1679840340,"question_id":215,"choices":{"B":"Use CALL mysql.rds_kill(thread-id) for the IDLE threads that are returned from the SHOW FULL PROCESSLIST command.","A":"Modify the MaxConnectionsPercent parameter through the RDS Proxy console.","C":"Modify the MaxIdleConnectionsPercent parameter for the RDS proxy.","D":"Modify the max_connections configuration setting for the DB instance. Modify the ConnectionBorrowTimeout parameter for the RDS proxy."},"answer_ET":"C","question_text":"A database specialist observes several idle connections in an Amazon RDS for MySQL DB instance. The DB instance is using RDS Proxy. An application is configured to connect to the proxy endpoint.\n\nWhat should the database specialist do to control the idle connections in the database?","url":"https://www.examtopics.com/discussions/amazon/view/103971-exam-aws-certified-database-specialty-topic-1-question-292/"}],"exam":{"name":"AWS Certified Database - Specialty","id":22,"isBeta":false,"isMCOnly":false,"numberOfQuestions":359,"provider":"Amazon","isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":43},"__N_SSP":true}