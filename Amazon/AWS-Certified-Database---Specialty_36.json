{"pageProps":{"questions":[{"id":"sPW9ngCDScfroxaBYBwE","question_id":176,"answer":"ACE","discussion":[{"timestamp":"1665494040.0","content":"Selected Answer: ACE\nMigration using backup and restore. https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/replatform-sql-server.html\n\nBx: Not STS, Dx: Not RDS, Fx: Not DMS","comment_id":"692135","poster":"Changwha","upvote_count":"5"},{"comment_id":"1027742","content":"Okay the Key is \"hundreds of database\", wondering why can't we simply use DMS but that's hectic, as we can simply backup and restore but the answer E slightly mislead saying \"Start Migration\" instead of backup and restore, great learning","timestamp":"1696743420.0","poster":"Sathish_dbs","upvote_count":"1"},{"content":"Selected Answer: ACE\nWhy not B, D or F?\nB. You don't want to convert the schema (using AWS Schema Conversion Tool) because you're just replatforming SQL Server on-prem to SQL Server on AWS.\nD. AN RDS for SQL Server instance doesn't have an OS that you can modify. It'S just RDS (Platform as a service).\nF. The task is to re-platform from Windows to Linux, not simply to migrate the data. For this, (E) is better suited.","upvote_count":"1","timestamp":"1696695360.0","poster":"Germaneli","comment_id":"1027524"},{"comment_id":"993472","timestamp":"1693338900.0","content":"Selected Answer: ACE\nhttps://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/replatform-sql-server.html\n\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/migrate-an-on-premises-microsoft-sql-server-database-to-microsoft-sql-server-on-amazon-ec2-running-linux.html","poster":"Pranava_GCP","upvote_count":"1"},{"timestamp":"1676390100.0","poster":"guau","content":"Selected Answer: ACE\nAfter reading the doc we need to use windows to linux tool","upvote_count":"1","comment_id":"808546"},{"content":"https://d1.awsstatic.com/events/reinvent/2019/REPEAT_1_Leverage_automation_to_re-platform_SQL_Server_to_Linux_WIN322-R1.pdf\n\nAnswer ACE","timestamp":"1667079120.0","poster":"rags1482","comment_id":"707500","upvote_count":"2"},{"upvote_count":"3","content":"Selected Answer: ACE\nACE as many databases to migrate","poster":"gairaj","comment_id":"664847","timestamp":"1662746040.0"}],"question_images":[],"answer_ET":"ACE","answer_images":[],"question_text":"A company runs hundreds of Microsoft SQL Server databases on Windows servers in its on-premises data center. A database specialist needs to migrate these databases to Linux on AWS.\nWhich combination of steps should the database specialist take to meet this requirement? (Choose three.)","unix_timestamp":1662746040,"answers_community":["ACE (100%)"],"timestamp":"2022-09-09 19:54:00","exam_id":22,"answer_description":"","topic":"1","choices":{"B":"Use AWS Systems Manager Run Command to install and configure the AWS Schema Conversion Tool on the on-premises servers.","F":"On the AWS Management Console, set up AWS Database Migration Service (AWS DMS) by entering details of the source SQL Server database and the destination SQL Server database on AWS. Start migration.","E":"Open the Windows to Linux replatforming assistant tool. Enter configuration details of the source and destination databases. Start migration.","D":"On the AWS Management Console, set up Amazon RDS for SQL Server DB instances with Linux as the operating system. Install AWS Systems Manager Agent on the DB instances by using an options group.","A":"Install AWS Systems Manager Agent on the on-premises servers. Use Systems Manager Run Command to install the Windows to Linux replatforming assistant for Microsoft SQL Server Databases.","C":"On the Amazon EC2 console, launch EC2 instances and select a Linux AMI that includes SQL Server. Install and configure AWS Systems Manager Agent on the EC2 instances."},"url":"https://www.examtopics.com/discussions/amazon/view/81449-exam-aws-certified-database-specialty-topic-1-question-257/","isMC":true},{"id":"lYqZkYl06GgQDjt2Bqzb","url":"https://www.examtopics.com/discussions/amazon/view/81144-exam-aws-certified-database-specialty-topic-1-question-258/","choices":{"A":"Create a read replica of the DB instance, and enable encryption. When the read replica is available, promote the read replica and update the endpoint that is used by the application. Delete the unencrypted DB instance.","D":"Convert the DB instance to an Amazon Aurora DB cluster, and enable encryption. When the DB cluster is available, update the endpoint that is used by the application to the cluster endpoint. Delete the unencrypted DB instance.","C":"Create a new encrypted DB instance. Perform an initial data load, and set up logical replication between the two DB instances When the new DB instance is in sync with the source DB instance, update the endpoint that is used by the application. Delete the unencrypted DB instance.","B":"Take a snapshot of the DB instance. Make an encrypted copy of the snapshot. Restore the encrypted snapshot. When the new DB instance is available, update the endpoint that is used by the application. Delete the unencrypted DB instance."},"exam_id":22,"timestamp":"2022-09-08 10:13:00","question_images":[],"answer":"C","isMC":true,"question_text":"A company is running a blogging platform. A security audit determines that the Amazon RDS DB instance that is used by the platform is not configured to encrypt the data at rest. The company must encrypt the DB instance within 30 days.\nWhat should a database specialist do to meet this requirement with the LEAST amount of downtime?","question_id":177,"answer_ET":"C","topic":"1","discussion":[{"comment_id":"692110","timestamp":"1665492060.0","poster":"Changwha","upvote_count":"5","content":"Selected Answer: C\nWhen the new, encrypted copy of the DB instance becomes available, you can point your applications to the new database. However, if your project doesn’t allow for significant downtime for this activity, you need an alternate approach that helps minimize the downtime. This pattern uses the AWS Database Migration Service (AWS DMS) to migrate and continuously replicate the data so that the cutover to the new, encrypted database can be done with minimal downtime."},{"timestamp":"1693340460.0","comment_id":"993491","poster":"Pranava_GCP","upvote_count":"1","content":"Selected Answer: C\nC. Create a new encrypted DB instance. Perform an initial data load, and set up logical replication between the two DB instances When the new DB instance is in sync with the source DB instance, update the endpoint that is used by the application. Delete the unencrypted DB instance.\n\n\"However, if your project doesn’t allow for significant downtime for this activity, you need an alternate approach that helps minimize the downtime. This pattern uses the AWS Database Migration Service (AWS DMS) to migrate and continuously replicate the data so that the cutover to the new, encrypted database can be done with minimal downtime. \"\n\n\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/encrypt-an-existing-amazon-rds-for-postgresql-db-instance.html"},{"timestamp":"1684924200.0","comment_id":"905751","content":"Selected Answer: C\nB would work too, but there would be (significantly) more downtime.","poster":"aviathor","upvote_count":"2"},{"comment_id":"853440","content":"Selected Answer: B\nIt says : the LEAST amount of downtime. Creating a replication is much more effort than copying the snapshot. So it is B.","comments":[{"comment_id":"967011","poster":"Isio05","upvote_count":"3","timestamp":"1690710360.0","content":"It's not about effort but downtime. B has more downtime than C. Thus C is the correct answer"}],"upvote_count":"2","poster":"redman50","timestamp":"1680021360.0"},{"timestamp":"1667057880.0","content":"https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/encrypt-an-existing-amazon-rds-for-postgresql-db-instance.html\n\nAnswer : B","upvote_count":"3","poster":"rags1482","comments":[{"upvote_count":"1","comment_id":"1027529","timestamp":"1696695900.0","content":"Given the above link, it would be B.\n\n\"However, if your project doesn’t allow for significant downtime for this activity, you need an alternate approach that helps minimize the downtime. This pattern uses the AWS Database Migration Service (AWS DMS) to migrate and continuously replicate the data so that the cutover to the new, encrypted database can be done with minimal downtime.\"\n\nThat leads to C.","poster":"Germaneli"}],"comment_id":"707294"},{"timestamp":"1665925560.0","upvote_count":"2","poster":"awsjjj","content":"Selected Answer: C\nminimum downtime. \nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/encrypt-an-existing-amazon-rds-for-postgresql-db-instance.html","comment_id":"696248"},{"upvote_count":"3","poster":"cloudsunriser","content":"Selected Answer: C\nSolution expects minimal downtime. \n\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/encrypt-an-existing-amazon-rds-for-postgresql-db-instance.html","comment_id":"681103","timestamp":"1664305920.0"},{"upvote_count":"1","poster":"SonamDhingra","timestamp":"1663149600.0","content":"Selected Answer: B\nB is correct","comment_id":"668864"},{"timestamp":"1662741600.0","upvote_count":"3","comment_id":"664806","poster":"gairaj","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.Enabling"},{"upvote_count":"3","poster":"hcltechaws","timestamp":"1662643620.0","comment_id":"663655","content":"My choice is B"},{"content":"Selected Answer: C\nAgree with C.","comment_id":"663356","upvote_count":"1","timestamp":"1662624780.0","poster":"mbar94"}],"answers_community":["C (70%)","B (30%)"],"answer_images":[],"answer_description":"","unix_timestamp":1662624780},{"id":"PH5WV7GGLs2jlJMh8Vsg","unix_timestamp":1669932840,"choices":{"A":"Use Aurora MySQL with the primary DB cluster in us-west-2 and a cross-Region Aurora Replica in eu-west-1","C":"Use an Aurora MySQL global database with the primary DB cluster in us-west-2 and the secondary DB cluster in eu-west-1","B":"Use Aurora MySQL with the primary DB cluster in us-west-2 and binlog-based external replication to eu-west-1","D":"Use Aurora MySQL with the primary DB cluster in us-west-2. Use AWS Database Migration Service (AWS DMS) change data capture (GDC) replication to the secondary DB cluster in eu-west-1"},"url":"https://www.examtopics.com/discussions/amazon/view/89714-exam-aws-certified-database-specialty-topic-1-question-259/","question_id":178,"timestamp":"2022-12-01 23:14:00","question_images":[],"question_text":"A database specialist is planning to migrate a MySQL database to Amazon Aurora. The database specialist wants to configure the primary DB cluster in the us-west-2 Region and the secondary DB cluster in the eu-west-1 Region. In the event of a disaster recovery scenario, the database must be available in eu-west-1 with an RPO of a few seconds. Which solution will meet these requirements?","answer":"C","answer_ET":"C","discussion":[{"comment_id":"733141","upvote_count":"8","poster":"Sab","content":"Selected Answer: C\nRecovery point objective (RPO) – The amount of data that can be lost (measured in time). For an Aurora global database, RPO is typically measured in seconds. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database-disaster-recovery.html","timestamp":"1669932840.0"},{"poster":"MultiAZ","timestamp":"1705226220.0","upvote_count":"1","content":"Selected Answer: C\nI believe both A and C meet all the requirements.\nGenerally, C is the preferred option.","comment_id":"1122439"}],"answer_description":"","answers_community":["C (100%)"],"exam_id":22,"topic":"1","isMC":true,"answer_images":[]},{"id":"71iUl6gpozmd2XFLsk4M","timestamp":"2020-07-11 11:51:00","answer_images":[],"answer_ET":"BEF","isMC":true,"unix_timestamp":1594461060,"discussion":[{"poster":"Ebi","content":"Answer is BEF\nDatabase does not need to be in private subnet (there is no requirement in the question) disabling public accessibility will remove public IP address associated from the instance.","comment_id":"153506","upvote_count":"14","timestamp":"1633307280.0"},{"upvote_count":"8","content":"B E F are the answers.\nD is not correct because there is on-premise network, VPC peering is for AWS VPC - AWS VPC\nC is not correct. DMS is using for DB migration, not subnet modification","timestamp":"1635142800.0","comments":[{"content":"Correct Answer ==>> B,E,F","timestamp":"1635976740.0","comment_id":"430160","upvote_count":"1","poster":"guru_ji"}],"comment_id":"423701","poster":"ChauPhan"},{"upvote_count":"1","content":"Selected Answer: BEF\nhttps://kloudle.com/academy/how-to-restrict-access-to-your-publicly-accessible-rds-instance/\nAfter publicly accessible setting disable no need to move the DB instance to a private subnet.\nWe do not change the conf file settings, instead we change the security group where we configure the IP addresses from which access is required.\nVPC peering only inside AWS.\nYou need to select the third item, nothing but \"Connect to the DB instance using private IPs and a VPN\" is suitable.","comment_id":"969136","poster":"IhorK","timestamp":"1690899600.0"},{"timestamp":"1676863980.0","upvote_count":"1","comment_id":"814782","content":"BEF for sure","poster":"ankurlibra"},{"comments":[{"upvote_count":"1","poster":"kush_sumit","content":"You cant ssh directly into rds how would you connect using private IP's?","timestamp":"1656848460.0","comment_id":"626533"}],"upvote_count":"1","poster":"novice_expert","comment_id":"594782","content":"Selected Answer: BEF\nx A. RDS you don't edit config files directly\nB. Modify the security group. Add the required corporate network IPs and remove the unwanted IPs\nx C. sunet change by DMS?\nx D. VPC peering is within AWS only\nE. disable publicly accessible\nF. .Connect to the DB instance using private IPs and a VPN.","timestamp":"1651282500.0"},{"timestamp":"1646490120.0","comment_id":"561470","upvote_count":"2","poster":"RotterDam","content":"Selected Answer: BEF\n1) Security Groups HAS to be done to restrict DB access to specific IPS\n2) Public accessibility has to be removed\n3) Corp to AWS VPN has to be enabled to secure traffic"},{"timestamp":"1645757340.0","poster":"tugboat","comment_id":"555710","upvote_count":"2","content":"Selected Answer: BEF\nagree with others"},{"poster":"awsmonster","timestamp":"1642683600.0","content":"F is incorrect. RDS uses endpoint, not IP address.\n\nI vote for BCE","upvote_count":"3","comment_id":"528409"},{"content":"Selected Answer: BEF\nB, E & F","poster":"GMartinelli","timestamp":"1638268320.0","upvote_count":"3","comment_id":"490584"},{"comment_id":"342862","upvote_count":"2","poster":"manan728","content":"B,C and E are correct. You need to migrate the database to private subnet before you can disable the publicly accessible setting in the console.","timestamp":"1635107940.0"},{"comment_id":"298703","poster":"Windy","timestamp":"1634888760.0","content":"BEF for me","upvote_count":"3"},{"content":"Ans: BEF","comment_id":"297907","poster":"myutran","upvote_count":"3","timestamp":"1634613300.0"},{"poster":"JobinAkaJoe","content":"I will go with BEF.\nIdeally db should be moved to private subnet.But using DMS for that makes C a wrong choice","comment_id":"253143","upvote_count":"4","timestamp":"1634559780.0"},{"timestamp":"1634534340.0","comment_id":"246497","poster":"kilkar","upvote_count":"1","comments":[{"comment_id":"424092","upvote_count":"1","poster":"ChauPhan","content":"VPC peering is between AWS VPCs, not between on-primise network and AWS VPC","timestamp":"1635359280.0"}],"content":"BDF\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-connectivity-instance-subnet-vpc/\nhttps://docs.aws.amazon.com/vpn/latest/s2svpn/VPC_VPN.html"},{"content":"F- Connect to DB instance using VPC peering - At which point in this question does it mention the need to connect to other VPC's? Best practices in AWS doco state that (see the Note) - - https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html#USER_VPC.Hiding","timestamp":"1634338980.0","upvote_count":"1","poster":"[Removed]","comment_id":"221527"},{"poster":"Ashoks","timestamp":"1634012940.0","content":"B,C,E,F are probable answers. \nC - database needs to moved private to public subnet, however, migration can be done through snapshot instead dms. \nSo BEF would be the answers","comment_id":"212024","upvote_count":"2"},{"poster":"Manmohan","timestamp":"1633829340.0","upvote_count":"1","content":"BEF for me","comment_id":"209983"},{"content":"BEF the most correct","timestamp":"1633415340.0","upvote_count":"1","poster":"halol","comment_id":"196487"},{"comment_id":"150726","upvote_count":"1","poster":"szmulder","content":"BEF for me. I don't think we need using the DMS to move it to the private subnet. Just using the snapshot will do. And why we need move it to private subnet","timestamp":"1633218540.0","comments":[{"content":"A database must be in a private subnet","comment_id":"151183","timestamp":"1633272840.0","upvote_count":"2","poster":"BillyC","comments":[{"comments":[{"content":"Agree with all points. BEF for me.","comment_id":"314794","timestamp":"1634940240.0","poster":"LMax","upvote_count":"1"}],"upvote_count":"3","poster":"MultiAZ","content":"This is veru good practice, indeed, but is not requirement here. And using DMS to move it (instead of snapshot or RR) is very, very strange. That's why C stinks. BEF for me","timestamp":"1634594640.0","comment_id":"272615"}]}]},{"upvote_count":"1","content":"Sorry BCF","poster":"BillyC","comment_id":"147358","timestamp":"1632758160.0"},{"upvote_count":"3","poster":"BillyMadison","comment_id":"139875","timestamp":"1632654420.0","content":"Leaning towards BEF"},{"poster":"lui","content":"BCF for me","timestamp":"1632603480.0","comment_id":"139620","upvote_count":"1"},{"content":"BCE for me","upvote_count":"3","timestamp":"1632536220.0","poster":"BillyC","comment_id":"134221"},{"comments":[{"content":"BCE for me (based on the following)\nhttps://aws.amazon.com/getting-started/tutorials/create-connect-postgresql-db/ \n\"Public accessibility: Choose Yes. This will allocate an IP address for your database instance so you can directly connect to the database from your own device.\"","upvote_count":"1","comment_id":"148866","poster":"grinbuddy","timestamp":"1632876840.0"}],"comment_id":"131996","content":"BCF for me\nVPC peering with the corporate network is nonsense. Also, I'm not sure what \"public setting\" means.","upvote_count":"2","timestamp":"1632153780.0","poster":"[Removed]"}],"topic":"1","question_id":179,"choices":{"A":"Modify the pg_hba.conf file. Add the required corporate network IPs and remove the unwanted IPs.","B":"Modify the associated security group. Add the required corporate network IPs and remove the unwanted IPs.","F":"Connect to the DB instance using private IPs and a VPN.","E":"Disable the publicly accessible setting.","D":"Enable VPC peering between the application host running on the corporate network and the VPC associated with the DB instance.","C":"Move the DB instance to a private subnet using AWS DMS."},"answers_community":["BEF (100%)"],"question_text":"A media company is using Amazon RDS for PostgreSQL to store user data. The RDS DB instance currently has a publicly accessible setting enabled and is hosted in a public subnet. Following a recent AWS Well-Architected Framework review, a Database Specialist was given new security requirements.\n✑ Only certain on-premises corporate network IPs should connect to the DB instance.\n✑ Connectivity is allowed from the corporate network only.\nWhich combination of steps does the Database Specialist need to take to meet these new requirements? (Choose three.)","exam_id":22,"answer":"BEF","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/25406-exam-aws-certified-database-specialty-topic-1-question-26/","answer_description":""},{"id":"uXcqnvMZfG0AHG8k1vZR","question_id":180,"topic":"1","question_images":[],"discussion":[{"upvote_count":"3","content":"Selected Answer: D\nD. An Amazon RDS Custom for SQL Server and grant elevated privileges for both the database instance and the host operating system.\n\n\"Amazon RDS Custom is a managed database service for legacy, custom, and packaged applications that require access to the underlying operating system and database environment. Amazon RDS Custom automates setup, operation, and scaling of databases in the cloud while granting customers access to the database and underlying operating system to configure settings, install patches, and enable native features to meet the dependent application's requirements.\"\n\nhttps://aws.amazon.com/rds/custom/faqs/","timestamp":"1693361100.0","poster":"Pranava_GCP","comment_id":"993645"},{"comment_id":"954284","content":"Selected Answer: D\nD. Amazon RDS Custom","poster":"Zdujgfr567783ff","upvote_count":"2","timestamp":"1689603960.0"},{"upvote_count":"4","poster":"aviathor","comment_id":"905753","content":"Selected Answer: A\nAssuming that the CRM application must run on the same host as the database server to \"manipulate files and packages\", the DB server will have to run on an EC2 instance. So the only question is what level of privileges the application will need to have on that EC2 instance","timestamp":"1684924620.0"},{"comment_id":"750420","timestamp":"1671504420.0","poster":"khun","content":"Selected Answer: D\nD. Amazon RDS Custom","upvote_count":"2"},{"content":"Selected Answer: D\nAmazon RDS Custom is supported for the Oracle and Microsoft SQL Server database engines","upvote_count":"1","comment_id":"733902","timestamp":"1669997640.0","poster":"examineme"},{"comment_id":"733146","upvote_count":"2","poster":"Sab","timestamp":"1669933020.0","content":"Selected Answer: D\nAmazon RDS Custom automates database administration tasks and operations. RDS Custom makes it possible for you as a database administrator to access and customize your database environment and operating system. With RDS Custom, you can customize to meet the requirements of legacy, custom, and packaged applications."}],"answer_images":[],"question_text":"An ecommerce company is planning to launch a custom customer relationship management (CRM) application on AWS. The development team selected Microsoft SQL Server as the database engine for this deployment. The CRM application will require operating system access because the application will manipulate files and packages on the server hosting the database. A senior database engineer must help the application team select a suitable deployment model for SQL Server. The deployment model should be optimized for the workload requirements.\n\nWhich deployment option should the database engineer choose that involves the LEAST operational overhead?","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/89715-exam-aws-certified-database-specialty-topic-1-question-260/","answer":"D","choices":{"D":"An Amazon RDS Custom for SQL Server and grant elevated privileges for both the database instance and the host operating system.","C":"Run SQL Server on Amazon EC2 and grant elevated privileges for the database instance.","B":"Amazon RDS for SQL Server and grant elevated privileges for both the database instance and the host operating system.","A":"Run SQL Server on Amazon EC2 and grant elevated privileges for both the database instance and the host operating system."},"answer_ET":"D","unix_timestamp":1669933020,"timestamp":"2022-12-01 23:17:00","exam_id":22,"answers_community":["D (71%)","A (29%)"],"isMC":true}],"exam":{"id":22,"lastUpdated":"11 Apr 2025","isImplemented":true,"provider":"Amazon","isBeta":false,"name":"AWS Certified Database - Specialty","isMCOnly":false,"numberOfQuestions":359},"currentPage":36},"__N_SSP":true}