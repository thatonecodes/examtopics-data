{"pageProps":{"questions":[{"id":"CWmTLGVbeNXbi6T0hMbH","question_text":"A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML, CSS, client-side JavaScript, and images.\nWhich method is the MOST cost-effective for hosting the website?","answers_community":["B (100%)"],"question_id":266,"answer_images":[],"discussion":[{"upvote_count":"35","timestamp":"1665557220.0","poster":"masetromain","content":"Selected Answer: B\nGood answer is B: client-side JavaScript. the website is static, so it must be S3.","comment_id":"692782"},{"poster":"BoboChow","content":"Selected Answer: B\nHTML, CSS, client-side JavaScript, and images are all static resources.","timestamp":"1665554880.0","comment_id":"692737","upvote_count":"10"},{"poster":"dattateja8","timestamp":"1742985660.0","upvote_count":"1","content":"Selected Answer: B\nAns B: Don't get confused by looking at JavaScript which can be dynamic. It is Client-side JavaScript. Means it get's executed at the Client side in a web browser. So it is all static and S3 is the cheapest option to host a static website.","comment_id":"1410316"},{"poster":"satyaammm","comment_id":"1334718","upvote_count":"1","timestamp":"1735637160.0","content":"Selected Answer: B\nS3 is the most suitable option for hosting static websites."},{"upvote_count":"1","poster":"PaulGa","content":"Selected Answer: B\nI had initially thought Ans A... but its Ans C -- \"cookieMr\" makes it clear: \nAns A \"Containerising the website and hosting with AWS Fargate involves additional complexity and costs associated with managing the container environment and scaling resources.\"\nSo it has to be... \nAns B: \"...Amazon S3 to host the website, take advantage of its durability, scalability, and low-cost pricing model. Only pay for the storage and data transfer associated with your website, without the need for managing and maintaining web servers or containers. This reduces the operational overhead and infrastructure costs.\"","comment_id":"1274077","timestamp":"1724851380.0"},{"upvote_count":"3","timestamp":"1705185420.0","poster":"awsgeek75","comment_id":"1122091","content":"Selected Answer: B\nCheapest Static site hosting = S3"},{"content":"Selected Answer: B\nAnswer-B","timestamp":"1705149660.0","poster":"A_jaa","comment_id":"1121646","upvote_count":"2"},{"timestamp":"1698332040.0","comment_id":"1054682","upvote_count":"1","poster":"Ruffyit","content":"HTML, CSS, client-side JavaScript, and images are all static resources."},{"comment_id":"1048052","poster":"AWSStudyBuddy","content":"The MOST cost-effective method for hosting a website is to:\nCreate an Amazon S3 bucket and host the website there.\nAmazon S3 is a highly scalable and cost-effective object storage service. It is a good option for hosting static websites, such as the website in this scenario.\nTo host a static website on Amazon S3, you would first need to create an S3 bucket. Then, you would need to upload the website files to the bucket. Once the files are uploaded, you can configure the bucket to serve as a website.","upvote_count":"2","timestamp":"1697728020.0"},{"timestamp":"1693985040.0","upvote_count":"1","comment_id":"1000337","content":"Selected Answer: B\nStatic website should work fine with S3","poster":"hungpm"},{"timestamp":"1692458160.0","poster":"KawtarZ","comment_id":"985286","content":"Selected Answer: B\nthe website is static because the backend runs on client side.","upvote_count":"2"},{"poster":"evanhongo","upvote_count":"1","content":"Selected Answer: B\nall static resources.","timestamp":"1691586060.0","comment_id":"976664"},{"upvote_count":"3","poster":"TariqKipkemei","comment_id":"970722","content":"Selected Answer: B\nstatic website, cost-effective = S3 web hosting","timestamp":"1691035380.0"},{"timestamp":"1689752880.0","content":"Selected Answer: B\nJust all static content HTML, CSS, client-side JavaScript, images. Amazon S3 is good enough.","upvote_count":"1","poster":"james2033","comment_id":"956395"},{"upvote_count":"1","poster":"miki111","comment_id":"953608","content":"Option B is the right answer for this.","timestamp":"1689538440.0"},{"comment_id":"950879","poster":"Kaab_B","timestamp":"1689267720.0","upvote_count":"1","content":"Selected Answer: B\nS3 is amongst the cheapest services offered by AWS."},{"poster":"karloscetina007","timestamp":"1688480880.0","upvote_count":"1","comment_id":"942870","content":"Selected Answer: B\nB is the correct answer."},{"timestamp":"1687086840.0","upvote_count":"7","comment_id":"926637","content":"Selected Answer: B\nBy using Amazon S3 to host the website, you can take advantage of its durability, scalability, and low-cost pricing model. You only pay for the storage and data transfer associated with your website, without the need for managing and maintaining web servers or containers. This reduces the operational overhead and infrastructure costs.\n\nContainerizing the website and hosting it in AWS Fargate (option A) would involve additional complexity and costs associated with managing the container environment and scaling resources. Deploying a web server on an Amazon EC2 instance (option C) would require provisioning and managing the EC2 instance, which may not be cost-effective for a static website. Configuring an Application Load Balancer with an AWS Lambda target (option D) adds unnecessary complexity and may not be the most efficient solution for hosting a static website.","poster":"cookieMr"},{"content":"Selected Answer: B\nOption B is the MOST cost-effective for hosting the website.","poster":"Bmarodi","upvote_count":"1","comment_id":"912775","timestamp":"1685705580.0"},{"upvote_count":"1","timestamp":"1684311600.0","content":"Selected Answer: B\nstatic website = B","comment_id":"899854","poster":"beginnercloud"},{"comment_id":"886655","poster":"Rahulbit34","upvote_count":"1","content":"Since all are static, S3 can be use to host it","timestamp":"1682969280.0"},{"timestamp":"1681834260.0","poster":"kamx44","comment_id":"873840","upvote_count":"1","content":"Selected Answer: B\nstatic website B"},{"comment_id":"861293","upvote_count":"1","content":"Selected Answer: B\nstatic website so B","timestamp":"1680625860.0","poster":"DIptyParashar"},{"comment_id":"857057","poster":"linux_admin","content":"Selected Answer: B\nWith S3, the company can store and serve its website contents, such as HTML, CSS, client-side JavaScript, and images, as static content. The cost of hosting a website on S3 is relatively low as compared to other options because S3 pricing is based on storage and data transfer usage, which is generally less expensive than other hosting options like EC2 instances or containers. Additionally, there is no charge for serving data from an S3 bucket, so there are no additional costs associated with traffic.","timestamp":"1680265620.0","upvote_count":"2"},{"timestamp":"1678111560.0","upvote_count":"1","content":"Selected Answer: B\nThe most cost-effective method for hosting the website is option B: Create an Amazon S3 bucket and host the website there.","poster":"bilel500","comment_id":"830870"},{"content":"Selected Answer: B\nThe most cost-effective method for hosting the website is option B: Create an Amazon S3 bucket and host the website there.","poster":"SilentMilli","upvote_count":"2","comment_id":"768101","timestamp":"1673042220.0"},{"comment_id":"754016","timestamp":"1671783000.0","content":"Selected Answer: B\nstatic content thru S3","poster":"orionizzie","upvote_count":"1"},{"comment_id":"751145","upvote_count":"1","poster":"pazabal","content":"Selected Answer: B\nIn general, it is more cost-effective to use S3 for hosting static website content because it is a lower-cost storage service compared to Fargate, which is a compute service","timestamp":"1671551040.0"},{"poster":"Buruguduystunstugudunstuy","comments":[{"poster":"Buruguduystunstugudunstuy","upvote_count":"1","timestamp":"1671504540.0","comment_id":"750423","content":"Hosting a website in an Amazon S3 bucket is generally more cost-effective than hosting it on an Amazon EC2 instance or using a containerized solution like AWS Fargate, as it does not require you to pay for compute resources. It is also more cost-effective than configuring an Application Load Balancer with an AWS Lambda target that uses the Express.js framework, as this approach would require you to pay for both compute resources and the use of the Application Load Balancer and AWS Lambda.\n\nIn summary, hosting a website in an Amazon S3 bucket is the most cost-effective method for hosting a website that consists of HTML, CSS, client-side JavaScript, and images."}],"upvote_count":"1","timestamp":"1671504540.0","content":"Selected Answer: B\nThe most cost-effective method for hosting a website that consists of HTML, CSS, client-side JavaScript, and images would be to create an Amazon S3 bucket and host the website there.\n\nAmazon S3 (Simple Storage Service) is an object storage service that enables you to store and retrieve data over the internet. It is a highly scalable, reliable, and low-cost storage service that is well-suited for hosting static websites. You can use Amazon S3 to host a website by creating a bucket, uploading your website content to the bucket, and then configuring the bucket as a static website hosting location.","comment_id":"750422"},{"content":"Selected Answer: B\nOption B","upvote_count":"1","comment_id":"749539","timestamp":"1671431640.0","poster":"career360guru"},{"timestamp":"1671218280.0","poster":"NikaCZ","upvote_count":"1","content":"Selected Answer: B\nStatic website = S3","comment_id":"747521"},{"timestamp":"1671009420.0","upvote_count":"1","poster":"k1kavi1","content":"Selected Answer: B\nB looks correct","comment_id":"744920"},{"poster":"Wpcorgan","upvote_count":"1","comment_id":"723507","content":"B is correct","timestamp":"1669035780.0"},{"content":"Selected Answer: B\nIs correct","upvote_count":"1","poster":"17Master","comment_id":"708101","timestamp":"1667176860.0"},{"upvote_count":"3","poster":"ninjawrz","comment_id":"695116","timestamp":"1665799200.0","content":"Selected Answer: B\nB: Host static website in S3"},{"timestamp":"1665529140.0","upvote_count":"2","comment_id":"692467","content":"The answer is B","poster":"Lilibell"}],"question_images":[],"answer_ET":"B","isMC":true,"answer":"B","choices":{"A":"Containerize the website and host it in AWS Fargate.","D":"Configure an Application Load Balancer with an AWS Lambda target that uses the Express.js framework.","B":"Create an Amazon S3 bucket and host the website there.","C":"Deploy a web server on an Amazon EC2 instance to host the website."},"timestamp":"2022-10-12 00:59:00","exam_id":31,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/85199-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1665529140,"answer_description":""},{"id":"OpsTPX4ljcPcUHZdMJvj","answer_ET":"A","isMC":true,"discussion":[{"timestamp":"1677048900.0","poster":"LuckyAro","upvote_count":"15","content":"Selected Answer: A\nA: is the solution for the company's requirements. Publishing data to Amazon Kinesis Data Streams can support ingestion rates as high as 1 MB/s and provide real-time data processing. Kinesis Data Analytics can query the ingested data in real-time with low latency, and the solution can scale as needed to accommodate increases in ingestion rates or querying needs. This solution also ensures minimal data loss in the event of an EC2 instance reboot since Kinesis Data Streams has a persistent data store for up to 7 days by default.","comment_id":"817542"},{"comments":[{"comment_id":"1090635","upvote_count":"2","timestamp":"1701985680.0","poster":"Ernestokoro","content":"You are very correct. see supporting link https://jayendrapatil.com/aws-kinesis-data-streams-vs-kinesis-firehose/#:~:text=vs%20Kine...-,Purpose,into%20AWS%20products%20for%20processing."}],"comment_id":"1071430","poster":"bogobob","content":"Selected Answer: B\nThe fact they specifically mention \"near real-time\" twice tells me the correct answer is KDF. On top of which its easier to setup and maintain. KDS is really only needed if you need real-time. Also using redshift will mean permanent data retention. The data in A could be lost after a year. Redshift queries are slow but you're still querying near real-time data","upvote_count":"6","timestamp":"1700051460.0"},{"upvote_count":"1","comment_id":"1351913","timestamp":"1738765740.0","content":"Selected Answer: A\nAlso A because \"The company’s data science team wants to query ingested data in near-real time\" and kinesis data analytics is doing that. With option B we query the tada once is in the data lake.","poster":"Dantecito"},{"content":"Selected Answer: A\nOption a for me. I will assume that the EC2 instance is responsible for placing the data into the correct database. Therefore, we just need to wait for the instance to reboot. Since we can store the data in Kinesis Data Streams for up to 7 days, we are covered in that regard.\n\nFor option B, we are forced to use Amazon Redshift, and the problem statement does not mention anything related to that. I would choose option A because it does not affect the original requirements, and it helps us avoid in-flight data loss as requested.","comment_id":"1351912","poster":"Dantecito","timestamp":"1738765440.0","upvote_count":"1"},{"timestamp":"1735482060.0","upvote_count":"1","poster":"wwwxxch","comment_id":"1333537","content":"Selected Answer: B\nnear-real time --> Kinesis Data Firehose\nAnd retention day of Kinesis Data Streams cannot be longer than 365 days"},{"timestamp":"1734438000.0","poster":"EllenLiu","content":"Selected Answer: A\nA: focus on performing complex data processing without in-flight data lost, not mention data persistence\nB: focus on data persist for later analysis","upvote_count":"1","comment_id":"1327879"},{"poster":"LeonSauveterre","timestamp":"1732715640.0","content":"Selected Answer: A\nInstance store & ElasiCache are all temporary storages, which cannot address data loss. That rules out C & D.\n\nB: Kinesis Data Firehose is optimized for batch processing rather than real-time querying. It can indeed deliver data to S3 or Redshift, but there's a good chance the delay between ingestion and query availability cannot meet the \"near-real-time\" requirement.","upvote_count":"1","comment_id":"1318697"},{"content":"Selected Answer: B\nhttps://aws.amazon.com/pm/kinesis/?gclid=CjwKCAjwvIWzBhAlEiwAHHWgvRQuJmBubZDnO2GasDWwc2iBapfVD6GBeIgj2JV6qkldm-K_CmMzmxoCdCwQAvD_BwE&trk=ee1218b7-7c10-4762-97df-274836a44566&sc_channel=ps&ef_id=CjwKCAjwvIWzBhAlEiwAHHWgvRQuJmBubZDnO2GasDWwc2iBapfVD6GBeIgj2JV6qkldm-K_CmMzmxoCdCwQAvD_BwE:G:s&s_kwcid=AL!4422!3!651510255264!p!!g!!kinesis%20stream!19836376690!149589222920","timestamp":"1717674660.0","upvote_count":"2","poster":"Lin878","comment_id":"1225455"},{"comment_id":"1140857","upvote_count":"2","timestamp":"1707124800.0","poster":"ray320x","content":"Option A is actually correct. The question ask for minimal data loss and that query of data should be near real time, not the ingestion. Kinesis data analytics is near real time.\n\nRecent changes to Redshift actually make B correct as well, but A is also correct.","comments":[{"upvote_count":"2","content":"Streaming ingestion provides low-latency, high-speed ingestion of stream data from Amazon Kinesis Data Streams and Amazon Managed Streaming for Apache Kafka into an Amazon Redshift provisioned or Amazon Redshift Serverless materialized view.[1] \n\nOption B mentions Kinesis Data Firehose (now just Firehose), so this won't work.\n\nOption A is the correct answer.\n\n[1]https://docs.aws.amazon.com/redshift/latest/dg/materialized-view-streaming-ingestion.html","poster":"dkw2342","comment_id":"1164083","timestamp":"1709379060.0"}]},{"upvote_count":"3","timestamp":"1706341080.0","comment_id":"1133137","content":"Selected Answer: A\nComparison to other options:\n\nB. Kinesis Data Firehose with Redshift: While Redshift is scalable, it doesn't offer real-time querying capabilities. Data needs to be loaded into Redshift from Firehose, introducing latency.\nC. EC2 instance store with Kinesis Data Firehose and S3: Storing data in an EC2 instance store is not persistent and data will be lost during reboots. EBS volumes are more appropriate for persistent storage, but the architecture becomes more complex.\nD. EBS volume with ElastiCache and Redis: While ElastiCache offers fast in-memory storage, it's not designed for high-volume data ingestion like 1 MB/s. It might struggle with scalability and persistence.","poster":"farnamjam"},{"poster":"Firdous586","comment_id":"1119743","timestamp":"1704977640.0","content":"I don't understand why people are giving wrong information \nin the QUESTION its clearly mentioned near Real Time \nKinesis Data Streams is for Real time \nWhere are Kinesis Datafirehose is for Near real time there for answer is B only","upvote_count":"5"},{"upvote_count":"1","content":"Selected Answer: A\nRead the question: near real-time querying of data.... it is more about real-time data query once the data is ingested, It does not mention how long time the data needs to be stored. A is better option. B introduces delay of data buffer before it can be queried in redshift","comment_id":"1091992","timestamp":"1702149300.0","poster":"Marco_St"},{"upvote_count":"3","comments":[{"poster":"pentium75","content":"Says who? They want to \"query ingested data in near-real time\", it does not say anything about historical data.","comment_id":"1108761","timestamp":"1703859480.0","upvote_count":"2"}],"timestamp":"1699883640.0","poster":"practice_makes_perfect","comment_id":"1069357","content":"Selected Answer: B\nA is not correct because Kinesis can only store data up to 1 year. The solution need to support querying ALL data instead of \"recent\" data."},{"timestamp":"1699877820.0","poster":"Ruffyit","comment_id":"1069294","content":"A: is the solution for the company's requirements. Publishing data to Amazon Kinesis Data Streams can support ingestion rates as high as 1 MB/s and provide real-time data processing. Kinesis Data Analytics can query the ingested data in real-time with low latency, and the solution can scale as needed to accommodate increases in ingestion rates or querying needs. This solution also ensures minimal data loss in the event of an EC2 instance reboot since Kinesis Data Streams has a persistent data store for up to 7 days by default.","upvote_count":"2"},{"comment_id":"1028502","upvote_count":"3","timestamp":"1696827000.0","poster":"TariqKipkemei","content":"Selected Answer: A\nPublish data to Amazon Kinesis Data Streams, Use Kinesis Data Analytics to query the data"},{"content":"Selected Answer: A\n• Provide near-real-time data ingestion into Kinesis Data Streams with the ability to handle the 1 MB/s ingestion rate. Data would be stored redundantly across shards.\n• Enable near-real-time querying of the data using Kinesis Data Analytics. SQL queries can be run directly against the Kinesis data stream.\n• Minimize data loss since data is replicated across shards. If an EC2 instance is rebooted, the data stream is still accessible.\n• Scale seamlessly to handle varying ingestion and query rates.","upvote_count":"4","poster":"Guru4Cloud","timestamp":"1693921680.0","comment_id":"999570"},{"comment_id":"991589","timestamp":"1693155240.0","content":"Selected Answer: A\nAnswer is A as it will provide a more streamlined solution. \nUsing B (Firehose + Redshift) will involve sending the data to an S3 bucket first and then copying the data to Redshift which will take more time.\nhttps://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html","poster":"Nikki013","upvote_count":"5"},{"timestamp":"1685209140.0","upvote_count":"2","poster":"nublit","comments":[{"content":"Redshift is a Data Warehouse in the first place, but the question says nothing about storing the data. They want to analyze it in near-real time, nobody says they need to store or access or analyze historical data.","upvote_count":"2","comment_id":"1108764","poster":"pentium75","timestamp":"1703859600.0"}],"comment_id":"908131","content":"Selected Answer: B\nAmazon Kinesis Data Firehose can deliver data in real-time to Amazon Redshift, making it immediately available for queries. Amazon Redshift, on the other hand, is a powerful data analytics service that allows fast and scalable querying of large volumes of data."},{"timestamp":"1682792580.0","upvote_count":"3","comment_id":"884597","poster":"kruasan","content":"Selected Answer: A\n• Provide near-real-time data ingestion into Kinesis Data Streams with the ability to handle the 1 MB/s ingestion rate. Data would be stored redundantly across shards.\n• Enable near-real-time querying of the data using Kinesis Data Analytics. SQL queries can be run directly against the Kinesis data stream.\n• Minimize data loss since data is replicated across shards. If an EC2 instance is rebooted, the data stream is still accessible.\n• Scale seamlessly to handle varying ingestion and query rates.","comments":[{"upvote_count":"4","timestamp":"1682792580.0","comments":[{"content":"I voted A as well, although not 100% sure why B is not correct. I just selected what seems the most simple solution between A and B.\n\nReason Kruasan gave \"Redshift would lack real-time capabilities.\" This is not true. Redshift could do real-time. evidence https://aws.amazon.com/blogs/big-data/real-time-analytics-with-amazon-redshift-streaming-ingestion/","upvote_count":"1","timestamp":"1686908280.0","poster":"joechen2023","comment_id":"925032"}],"comment_id":"884598","poster":"kruasan","content":"The other options would not fully meet the requirements:\nB) Kinesis Firehose + Redshift would introduce latency since data must be loaded from Firehose into Redshift before querying. Redshift would lack real-time capabilities.\nC) An EC2 instance store and Kinesis Firehose to S3 with Athena querying would risk data loss from instance store if an instance reboots. Athena querying data in S3 also lacks real-time capabilities. \nD) Using EBS storage, Kinesis Firehose to Redis and subscribing to Redis may provide near-real-time ingestion and querying but risks data loss if an EBS volume or EC2 instance fails. Recovery requires re-hydrating data from a backup which impacts real-time needs."}]},{"timestamp":"1676839500.0","poster":"jennyka76","content":"ANSWER - A\nhttps://docs.aws.amazon.com/kinesisanalytics/latest/dev/what-is.html","upvote_count":"1","comment_id":"814523"},{"comment_id":"813150","upvote_count":"3","timestamp":"1676732460.0","poster":"cloudbusting","content":"near-real-time data querying = Kinesis analytics"},{"comment_id":"812719","content":"Selected Answer: A\nAnswer is A","timestamp":"1676701860.0","upvote_count":"1","poster":"zTopic"}],"topic":"1","answer_description":"","unix_timestamp":1676701860,"exam_id":31,"question_id":267,"url":"https://www.examtopics.com/discussions/amazon/view/99752-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"A","timestamp":"2023-02-18 07:31:00","question_text":"A company is using a fleet of Amazon EC2 instances to ingest data from on-premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in-flight is lost. The company’s data science team wants to query ingested data in near-real time.\n\nWhich solution provides near-real-time data querying that is scalable with minimal data loss?","answers_community":["A (74%)","B (26%)"],"answer_images":[],"question_images":[],"choices":{"D":"Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data.","A":"Publish data to Amazon Kinesis Data Streams, Use Kinesis Data Analytics to query the data.","B":"Publish data to Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.","C":"Store ingested data in an EC2 instance store. Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data."}},{"id":"nLMBzZHa3w5iruJuL4Is","question_images":[],"discussion":[{"upvote_count":"15","comment_id":"812171","comments":[{"upvote_count":"1","content":"Thank you!","comment_id":"845271","timestamp":"1695239340.0","poster":"Grace83"}],"content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/#:~:text=Solution%20overview","poster":"bdp123","timestamp":"1692286620.0"},{"timestamp":"1709653560.0","comment_id":"999568","upvote_count":"6","content":"Selected Answer: D\nThe x-amz-server-side-encryption header is used to specify the encryption method that should be used to encrypt objects uploaded to an Amazon S3 bucket. By updating the bucket policy to deny if the PutObject does not have this header set, the solutions architect can ensure that all objects uploaded to the bucket are encrypted.","poster":"Guru4Cloud"},{"poster":"awsgeek75","comment_id":"1112955","upvote_count":"4","timestamp":"1720019340.0","content":"Selected Answer: D\nRelated reading because (as of Jan 2023) S3 buckets have encryption enabled by default.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html\n\n\"If you require your data uploads to be encrypted using only Amazon S3 managed keys, you can use the following bucket policy. For example, the following bucket policy denies permissions to upload an object unless the request includes the x-amz-server-side-encryption header to request server-side encryption:\""},{"comments":[{"poster":"kruasan","comment_id":"884922","upvote_count":"5","content":"The other options would not enforce encryption:\nA) Requiring an s3:x-amz-acl header does not mandate encryption. This header controls access permissions.\nB) Requiring an s3:x-amz-acl header set to private also does not enforce encryption. It only enforces private access permissions.\nC) Requiring an aws:SecureTransport header ensures uploads use SSL but does not specify that objects must be encrypted. Encryption is not required when using SSL transport.","timestamp":"1698654420.0"}],"poster":"kruasan","comment_id":"884921","timestamp":"1698654420.0","upvote_count":"4","content":"To encrypt an object at the time of upload, you need to add a header called x-amz-server-side-encryption to the request to tell S3 to encrypt the object using SSE-C, SSE-S3, or SSE-KMS. The following code example shows a Put request using SSE-S3.\nhttps://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/"},{"content":"Selected Answer: D\nTo encrypt an object at the time of upload, you need to add a header called x-amz-server-side-encryption to the request to tell S3 to encrypt the object using SSE-C, SSE-S3, or SSE-KMS. The following code example shows a Put request using SSE-S3.\nhttps://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/","timestamp":"1698654360.0","comment_id":"884920","poster":"kruasan","upvote_count":"2"},{"poster":"Sbbh","timestamp":"1695438180.0","comments":[{"content":"That's true","poster":"Guru4Cloud","upvote_count":"2","comment_id":"999565","timestamp":"1709653440.0"}],"comment_id":"847821","content":"Confusing question. It doesn't state clearly if the object needs to be encrypted at-rest or in-transit","upvote_count":"6"},{"content":"Selected Answer: D\nI vote d","comment_id":"828201","upvote_count":"2","timestamp":"1693756020.0","poster":"Steve_4542636"},{"poster":"LuckyAro","upvote_count":"4","content":"Selected Answer: D\nTo ensure that all objects uploaded to an Amazon S3 bucket are encrypted, the solutions architect should update the bucket policy to deny any PutObject requests that do not have an x-amz-server-side-encryption header set. This will prevent any objects from being uploaded to the bucket unless they are encrypted using server-side encryption.","timestamp":"1692680220.0","comment_id":"817545"},{"comment_id":"814514","upvote_count":"2","content":"answer - D","poster":"jennyka76","timestamp":"1692470160.0"},{"content":"Selected Answer: D\nAnswer is D","upvote_count":"2","timestamp":"1692333240.0","comment_id":"812720","poster":"zTopic"},{"comment_id":"812160","upvote_count":"2","timestamp":"1692285660.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/amazon-s3-policy-keys.html","poster":"Neorem"}],"timestamp":"2023-02-17 18:21:00","answer_images":[],"question_text":"What should a solutions architect do to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?","answer_description":"","question_id":268,"url":"https://www.examtopics.com/discussions/amazon/view/99685-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"B":"Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set to private.","A":"Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set.","C":"Update the bucket policy to deny if the PutObject does not have an aws:SecureTransport header set to true.","D":"Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set."},"topic":"1","answer_ET":"D","exam_id":31,"isMC":true,"answers_community":["D (100%)"],"answer":"D","unix_timestamp":1676654460},{"id":"GEIQ25L5njFsT9e0YnFr","isMC":true,"answer_images":[],"timestamp":"2023-02-18 07:36:00","question_text":"A solutions architect is designing a multi-tier application for a company. The application's users upload images from a mobile device. The application generates a thumbnail of each image and returns a message to the user to confirm that the image was uploaded successfully.\n\nThe thumbnail generation can take up to 60 seconds, but the company wants to provide a faster response time to its users to notify them that the original image was received. The solutions architect must design the application to asynchronously dispatch requests to the different application tiers.\n\nWhat should the solutions architect do to meet these requirements?","answer":"C","question_id":269,"url":"https://www.examtopics.com/discussions/amazon/view/99753-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"content":"Selected Answer: C\nI've noticed there are a lot of questions about decoupling services and SQS is almost always the answer.","poster":"Steve_4542636","upvote_count":"32","timestamp":"1693763880.0","comment_id":"828340"},{"poster":"Neha999","upvote_count":"13","timestamp":"1692358860.0","comment_id":"813024","content":"D\nSNS fan out"},{"poster":"LoXoL","comment_id":"1146017","content":"They don't look like real answers from the official exam...","timestamp":"1723275960.0","upvote_count":"1"},{"timestamp":"1721301540.0","poster":"awsgeek75","content":"Selected Answer: C\nEach option is badly worded:\nA: \"generate the thumbnail and alert the user\" doesn't sound sequential so could alert the user during, before or after the thumbnail generation whichever way you interpret it.\nB: this is sequential and won't alert until the steps are complete\nD: Could work without with the risk of notification loss so C is better but this is also ok","upvote_count":"2","comment_id":"1125875"},{"timestamp":"1720019640.0","content":"Selected Answer: C\nSafe answer is C but B is so badly worded that it can mean anything to confuse people. Step functions to use tiers. What if on of the step is to inform to the user and move on to next step. Anyway, I'll chose C for the exam as it is cleaner.","upvote_count":"2","poster":"awsgeek75","comment_id":"1112958"},{"timestamp":"1713339360.0","content":"... asynchronously dispatch ... => Amazon SQS","upvote_count":"7","comment_id":"1045656","poster":"wsdasdasdqwdaw"},{"comment_id":"1040179","timestamp":"1712808420.0","upvote_count":"5","content":"Selected Answer: C\nAsynchronous, Decoupling = Amazon Simple Queue Service","poster":"TariqKipkemei"},{"poster":"Guru4Cloud","timestamp":"1709653320.0","upvote_count":"2","content":"Selected Answer: C\nSQS is a fully managed message queuing service that can be used to decouple different parts of an application.","comment_id":"999564"},{"content":"Selected Answer: C\nAnswers B and D alert the user when thumbnail generation is complete. Answer C alerts the user through an application message that the image was received.","timestamp":"1695781020.0","comment_id":"851629","poster":"Zox42","upvote_count":"5"},{"timestamp":"1695437820.0","upvote_count":"1","poster":"Sbbh","comment_id":"847818","content":"B:\nUse cases for Step Functions vary widely, from orchestrating serverless microservices, to building data-processing pipelines, to defining a security-incident response. As mentioned above, Step Functions may be used for synchronous and asynchronous business processes."},{"comment_id":"830981","poster":"AlessandraSAA","content":"why not B?","upvote_count":"4","timestamp":"1694009520.0"},{"poster":"Wael216","timestamp":"1693729320.0","upvote_count":"2","content":"Selected Answer: C\nCreating an Amazon Simple Queue Service (SQS) message queue and placing messages on the queue for thumbnail generation can help separate the image upload and thumbnail generation processes.","comment_id":"827868"},{"content":"C\nThe key here is \"a faster response time to its users to notify them that the original image was received.\" i.e user needs to be notified when image was received and not after thumbnail was created.","upvote_count":"3","comment_id":"826404","poster":"vindahake","timestamp":"1693614600.0"},{"comment_id":"821216","timestamp":"1692934500.0","upvote_count":"2","content":"Selected Answer: C\nA looks like the best way , but its essentially replacing the mentioned app , that's not the ask","poster":"AlmeroSenior"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-s3-tutorial.html","poster":"Mickey321","comment_id":"820610","timestamp":"1692880740.0","upvote_count":"1"},{"comment_id":"818186","poster":"bdp123","upvote_count":"2","timestamp":"1692720780.0","content":"Selected Answer: C\nC is the only one that makes sense"},{"timestamp":"1692680760.0","upvote_count":"3","comment_id":"817555","content":"Selected Answer: A\nUse a custom AWS Lambda function to generate the thumbnail and alert the user. Lambda functions are well-suited for short-lived, stateless operations like generating thumbnails, and they can be triggered by various events, including image uploads. By using Lambda, the application can quickly confirm that the image was uploaded successfully and then asynchronously generate the thumbnail. When the thumbnail is generated, the Lambda function can send a message to the user to confirm that the thumbnail is ready.\n\nC proposes to use an Amazon Simple Queue Service (Amazon SQS) message queue to process image uploads and generate thumbnails. SQS can help decouple the image upload process from the thumbnail generation process, which is helpful for asynchronous processing. However, it may not be the most suitable option for quickly alerting the user that the image was received, as the user may have to wait until the thumbnail is generated before receiving a notification.","comments":[{"upvote_count":"3","comment_id":"1108791","timestamp":"1719665160.0","poster":"pentium75","content":"You understood C wrong. You place the message on the SQS queue and then you alert the user."}],"poster":"LuckyAro"},{"timestamp":"1692639840.0","upvote_count":"1","poster":"Bhrino","comment_id":"817086","comments":[{"comment_id":"1108793","poster":"pentium75","content":"\"It can take up to 60 seconds\" but that doesn't matter as you're decoupling the workflow. You alert the user immediately after RECEIVING the file and placing it to the queue. It will be processed in the background.","timestamp":"1719665220.0","upvote_count":"2"},{"comment_id":"841104","upvote_count":"1","timestamp":"1694870700.0","comments":[{"comment_id":"852278","upvote_count":"3","timestamp":"1695832680.0","poster":"MssP","content":"15 min."}],"poster":"CapJackSparrow","content":"Does Lambda not time out after 15 seconds?"}],"content":"Selected Answer: A\nThis is A because SNS and SQS dont work because it can take up to 60 seconds and b is just more complex than a"},{"upvote_count":"2","content":"answer - c","comment_id":"814512","timestamp":"1692470040.0","poster":"jennyka76"},{"comment_id":"813618","poster":"rrharris","upvote_count":"1","timestamp":"1692399540.0","content":"Answer is C"},{"comment_id":"812722","content":"Selected Answer: C\nThe solutions architect can use Amazon Simple Queue Service (SQS) to manage the messages and dispatch the requests in a scalable and decoupled manner. Therefore, the correct answer is C.","poster":"zTopic","timestamp":"1692333360.0","upvote_count":"3"}],"choices":{"A":"Write a custom AWS Lambda function to generate the thumbnail and alert the user. Use the image upload process as an event source to invoke the Lambda function.","B":"Create an AWS Step Functions workflow. Configure Step Functions to handle the orchestration between the application tiers and alert the user when thumbnail generation is complete.","D":"Create Amazon Simple Notification Service (Amazon SNS) notification topics and subscriptions. Use one subscription with the application to generate the thumbnail after the image upload is complete. Use a second subscription to message the user's mobile app by way of a push notification after thumbnail generation is complete.","C":"Create an Amazon Simple Queue Service (Amazon SQS) message queue. As images are uploaded, place a message on the SQS queue for thumbnail generation. Alert the user through an application message that the image was received."},"exam_id":31,"unix_timestamp":1676702160,"question_images":[],"topic":"1","answers_community":["C (93%)","7%"],"answer_ET":"C","answer_description":""},{"id":"GSaNLhapK715puLqZtQ5","answer_ET":"B","isMC":true,"choices":{"A":"Launch an Amazon EC2 instance to serve as the HTTPS endpoint and to process the messages. Configure the EC2 instance to save the results to an Amazon S3 bucket.","B":"Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.","D":"Create a gateway VPC endpoint for Amazon S3. Configure a Site-to-Site VPN connection from the facility network to the VPC so that sensor data can be written directly to an S3 bucket by way of the VPC endpoint.","C":"Use Amazon Route 53 to direct incoming sensor messages to an AWS Lambda function. Configure the Lambda function to process the messages and save the results to an Amazon DynamoDB table."},"answer":"B","timestamp":"2023-02-17 20:23:00","url":"https://www.examtopics.com/discussions/amazon/view/99699-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"exam_id":31,"question_id":270,"discussion":[{"upvote_count":"22","timestamp":"1714458900.0","comment_id":"884925","poster":"kruasan","content":"Selected Answer: B\n- Option A would not provide high availability. A single EC2 instance is a single point of failure. \n- Option B provides a scalable, highly available solution using serverless services. API Gateway and Lambda can scale automatically, and DynamoDB provides a durable data store.\n- Option C would expose the Lambda function directly to the public Internet, which is not a recommended architecture. API Gateway provides an abstraction layer and additional features like access control.\n- Option D requires configuring a VPN to AWS which adds complexity. It also saves the raw sensor data to S3, rather than processing it and storing the results."},{"content":"Selected Answer: B\nHighly available = Serverless\nThe readers send a message over HTTPS = HTTPS endpoint in Amazon API Gateway\nProcess these messages from the sensors = AWS Lambda function","upvote_count":"8","poster":"TariqKipkemei","timestamp":"1728619920.0","comment_id":"1040183"},{"timestamp":"1725543420.0","poster":"Guru4Cloud","content":"Selected Answer: B\nThe correct answer is B. Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.\n\nHere are the reasons why:\n\nAPI Gateway is a highly scalable and available service that can be used to create and expose RESTful APIs.\nLambda is a serverless compute service that can be used to process events and data.\nDynamoDB is a NoSQL database that can be used to store data in a scalable and highly available way.","upvote_count":"4","comment_id":"999562"},{"content":"Selected Answer: B\nI vote B","comment_id":"828345","poster":"Steve_4542636","upvote_count":"2","timestamp":"1709496060.0"},{"timestamp":"1708727520.0","upvote_count":"2","content":"It is option \"B\" \nOption \"B\" can provide a system with highly scalable, fault-tolerant, and easy to manage.","comment_id":"819840","poster":"KZM"},{"poster":"LuckyAro","upvote_count":"4","comment_id":"817564","content":"Selected Answer: B\nDeploy Amazon API Gateway as an HTTPS endpoint and AWS Lambda to process and save the messages to an Amazon DynamoDB table. This option provides a highly available and scalable solution that can easily handle large amounts of data. It also integrates with other AWS services, making it easier to analyze and visualize the data for the security team.","timestamp":"1708585980.0"},{"poster":"zTopic","timestamp":"1708238340.0","content":"Selected Answer: B\nB is Correct","upvote_count":"4","comment_id":"812726"}],"answer_images":[],"question_text":"A company’s facility has badge readers at every entrance throughout the building. When badges are scanned, the readers send a message over HTTPS to indicate who attempted to access that particular entrance.\n\nA solutions architect must design a system to process these messages from the sensors. The solution must be highly available, and the results must be made available for the company’s security team to analyze.\n\nWhich system architecture should the solutions architect recommend?","answers_community":["B (100%)"],"unix_timestamp":1676661780,"topic":"1","answer_description":""}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","id":31,"isMCOnly":true,"provider":"Amazon","name":"AWS Certified Solutions Architect - Associate SAA-C03","isImplemented":true,"numberOfQuestions":1019},"currentPage":54},"__N_SSP":true}