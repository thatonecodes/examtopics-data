{"pageProps":{"questions":[{"id":"L1lsyIgOK5CMDXjPsJ9b","question_images":[],"unix_timestamp":1689120240,"discussion":[{"upvote_count":"8","timestamp":"1689120240.0","comment_id":"949378","poster":"juanvepe","content":"A-C \nAn SAP HANA system with XS advanced runtime can be installed in a single-host or multi-host environment using the SAP HANA database lifecycle manager (HDBLCM).\n\nAWS Launch Wizard for SAP is a service that guides you through the sizing, configuration, and deployment of SAP applications on AWS, and follows AWS cloud application best practices.\n\nAWS Launch Wizard reduces the time it takes to deploy SAP applications on AWS."},{"comment_id":"1104560","poster":"thuyeinaung","content":"Selected Answer: AC\nadd for AC","timestamp":"1703417520.0","upvote_count":"1"},{"upvote_count":"3","timestamp":"1690950480.0","poster":"kaishin0527","content":"Selected Answer: CD\nC,D: AWS Launch Wizard for SAP is a service that helps customers more easily deploy SAP applications on AWS by guiding through the sizing, configuration, and deployment process. This reduces the time and effort taken to install and provision resources for SAP HANA system.\n\nAdditionally, AWS CloudFormation templates can be used to provision AWS resources. AWS CloudFormation provides a common language for you to describe and provision all the infrastructure resources in your cloud environment. This allows you to automate and standardize the setup process.","comment_id":"969669"},{"upvote_count":"4","comment_id":"951703","poster":"[Removed]","content":"Selected Answer: AC\nLaunch Wizard + XS runtime","timestamp":"1689355560.0"}],"choices":{"A":"Install XS Advanced runtime by using the SAP HANA database lifecycle manager (HDBLCM).","E":"Evaluate and identify the certified Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS) volume types for SAP HANA.","C":"Use AWS Launch Wizard for SAP.","B":"Provision AWS resources by using the AWS Management Console. Install SAP HANA by using the SAP HANA database lifecycle manager (HDBLCM).","D":"Develop and use AWS CloudFormation templates to provision the AWS resources."},"question_text":"A company is planning to implement its production SAP HANA database with an XS Advanced runtime environment on AWS. The company must provision the necessary AWS resources and install the SAP HANA database within 1 day to meet an urgent business request. The company must implement a solution that minimizes operational effort.\n\nWhich combination of steps should the company take to meet these requirements? (Choose two.)","exam_id":28,"timestamp":"2023-07-12 02:04:00","answer_ET":"AC","answers_community":["AC (63%)","CD (38%)"],"question_id":106,"answer_images":[],"answer_description":"","isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/114910-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/","answer":"AC"},{"id":"Z1lAQflntf5VYwR0AjbU","question_text":"A global company is planning to migrate its SAP S/4HANA workloads and SAP BW/4HANA workloads to AWS. The company’s database will not grow more than 3 TB for the next 3 years. The company's production SAP HANA system has been designed for high availability (HA) and disaster recovery (DR) with the following configurations:\n\n• HA: SAP HANA system replication configured with SYNC mode and LOGREPLAY operation mode across two Availability Zones with the same size SAP HANA node\n• DR: SAP HANA system replication configured with ASYNC mode and LOGREPLAY operation mode across AWS Regions with the same size SAP HANA node\n\nAll the SAP HANA nodes in the current configuration are the same size. For HA, the company wants an RPO of 0 and an RTO of 5 minutes. For DR, the company wants an RPO of 0 and an RTO of 3 hours.\n\nHow should the company design this solution to meet the RPO and RTO requirements MOST cost-effectively?","topic":"1","answer_images":[],"answer":"B","question_id":107,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/115188-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/","timestamp":"2023-07-14 19:41:00","discussion":[{"content":"Selected Answer: B\nBBBBB Cost optimized - https://docs.aws.amazon.com/sap/latest/sap-hana/hana-ops-ha-dr-hsr.html","upvote_count":"2","poster":"Demianwholovesjudo","comment_id":"1109357","timestamp":"1703905860.0"},{"poster":"zzw890827","content":"Selected Answer: B\nA is wrong sincer turn on the preload is not cost-effective.","comment_id":"976598","upvote_count":"3","timestamp":"1691581740.0"},{"comment_id":"969663","poster":"kaishin0527","content":"Selected Answer: A\nA: Maintain HA with SAP HANA system replication configured with SYNC mode and table preload turned on across two Availability Zones. In each Availability Zone, use the same size SAP HANA node. Decrease the size of the DR node to at least 64 GiB of memory or the row store size plus 20 GiB, whichever is higher, with ASYNC mode and table preload turned on. Increase the size of the DR node during a DR event.\n\nFor high availability (HA) scenarios, the SAP HANA system replication is typically configured in SYNC mode to ensure zero Recovery Point Objective (RPO). For optimal Recovery Time Objective (RTO), table preload can be turned on.\n\nFor disaster recovery (DR), you can use smaller instance types, since they are only used during actual disaster recovery and not for serving normal production load. If you are using system replication for DR, you can use ASYNC mode. The \"table preload\" option can be turned on to minimize RTO.","upvote_count":"4","timestamp":"1690950300.0"},{"poster":"Frankong","content":"What's the difference between A and B?","upvote_count":"1","timestamp":"1690883520.0","comment_id":"968928"},{"comment_id":"951713","upvote_count":"2","poster":"[Removed]","timestamp":"1689356460.0","content":"Selected Answer: B\nOption B is correct because it suggests using ASYNC mode for DR with table preload turned off which will meet the RPO requirement of 0 seconds and an RTO of 3 hours for DR\n\nOption A is incorrect because it suggests using SYNC mode for DR which is not cost-effective.\n\nOption C is incorrect because it suggests using SYNC mode for HA and preload turned on which may not cost-effective\n\nOption D is incorrect because it suggests using ASYNC mode for DR with table preload turned off which will not meet the RPO requirement of 0 seconds1."}],"question_images":[],"isMC":true,"answers_community":["B (64%)","A (36%)"],"answer_ET":"B","exam_id":28,"choices":{"C":"Maintain HA with SAP HANA system replication across two Availability Zones. Decrease the size of the HA secondary node to at least 64 GiB of memory or the row store size plus 20 GiB, whichever is higher, with SYNC mode and table preload turned on. Increase the size of the HA secondary node during an HA event. Decrease the size of the DR node to at least 64 GiB of memory or the row store size plus 20 GiB, whichever is higher, with table preload turned on. Increase the size of the DR node during a DR event.","B":"Maintain HA with SAP HANA system replication configured with SYNC mode and table preload turned on across two Availability Zones. In each Availability Zone, use the same size SAP HANA node. Decrease the size of the DR node to at least 64 GiB of memory or the row store size plus 20 GiB, whichever is higher, with ASYNC mode and table preload turned off. Increase the size of the DR node during a DR event.","A":"Maintain HA with SAP HANA system replication configured with SYNC mode and table preload turned on across two Availability Zones. In each Availability Zone, use the same size SAP HANA node. Decrease the size of the DR node to at least 64 GiB of memory or the row store size plus 20 GiB, whichever is higher, with ASYNC mode and table preload turned on. Increase the size of the DR node during a DR event.","D":"Maintain HA with SAP HANA system replication across two Availability Zones. Decrease the size of the HA secondary node to at least 64 GiB of memory or the row store size plus 20 GiB, whichever is higher, with SYNC mode and table preload turned on. Increase the size of the HA secondary node during an HA event. Decrease the size of the DR node to at least 64 GiB of memory or the row store size plus 20 GiB, whichever is higher, with table preload turned off. Increase the size of the DR node during a DR event."},"unix_timestamp":1689356460},{"id":"kP66EEZNGsiKWPAxF1R0","exam_id":28,"isMC":true,"question_images":[],"topic":"1","question_id":108,"discussion":[{"comment_id":"950079","poster":"juanvepe","content":"Answer.C \nEvery SAP system needs a central license, which is determined by the environment of the message server. Since SAP's high-availability (HA) solution stipulates 2 or more cluster nodes (host machines) where the message server is enabled to run, you have to order as many license keys as you have cluster nodes.\n\nWhen we receive confirmation from your vendor that you are implementing a switchover environment, we provide the required license keys for your system, 1 key for each machine.\n\nSAP has implemented a license mechanism for transparent and easy use with switchover solutions and clustered environments. Your customer key is calculated on the basis of local information on the message server host. This is the host machine where the ABAP central services instance (ASCS instance) runs. There is no license problem when only the database is switched over.","upvote_count":"5","timestamp":"1689185520.0"},{"content":"C. After failover you're expected to run with the temp license. \n Otherwise, a separate permanent license is needed on the DR instance. \n https://docs.aws.amazon.com/sap/latest/general/slas-licenses.html","upvote_count":"2","poster":"Jeanz501","comment_id":"1059901","timestamp":"1698855540.0"},{"timestamp":"1693557720.0","content":"Selected Answer: C\nC... Each ASCS node needs separate license..","upvote_count":"3","poster":"ArtanisAM91","comment_id":"995862"},{"content":"Selected Answer: B\nB: This option is incorrect because SAP licenses are typically bound to a system ID (SID), and are not bound to a specific machine or instance. In a High Availability setup, the SAP system, including the ASCS instances, has the same SID on both the primary and secondary nodes. Therefore, the same license should work for both nodes. SAP does not require separate licenses for each ASCS instance in each Availability Zone.\n\nThe licensing of SAP systems is based on the SAPS (SAP Application Performance Standard) capacity of the system and the number of users that will be accessing the system, not the number of instances or servers that the system is running on. Therefore, having separate ASCS instances in different Availability Zones for High Availability purposes should not require additional SAP licenses.","poster":"kaishin0527","comments":[{"upvote_count":"1","content":"I mistakenly posted the reason why it is not C.\nI will repost it.","timestamp":"1690961100.0","poster":"kaishin0527","comments":[{"comment_id":"969877","poster":"kaishin0527","content":"The correct answer is B. \"The cluster configuration is not correct.\"\n\nIn a properly configured High Availability (HA) setup, SAP license keys (which are bound to the SAP System ID, not to a specific server or IP address) should remain valid after failover. If the license becomes invalid after failover, it likely indicates an issue with the cluster configuration. A common problem might be that the Secondary node was not properly recognized as a part of the cluster and thus when failover happened, it couldn't recognize the valid license.","timestamp":"1690961160.0","upvote_count":"1"}],"comment_id":"969875"}],"comment_id":"969872","upvote_count":"1","timestamp":"1690960980.0"},{"upvote_count":"2","poster":"[Removed]","content":"Selected Answer: C\nDifferent hard will generate a different hardware key which can invalidate a license key","comment_id":"951717","timestamp":"1689356760.0"}],"answer_images":[],"choices":{"A":"The company needs to apply SAP licenses after each failover.","B":"The cluster configuration is not correct.","C":"The company needs two separate sets of licenses for ASCS instances in each Availability Zone.","D":"The company stopped and restarted the secondary node as part of the last maintenance."},"answers_community":["C (83%)","B (17%)"],"question_text":"A company has implemented its ERP system on SAP S/4HANAon AWS. The system is based on Enqueue Standalone Architecture (ENSA2) and is highly available.\n\nAs part of an availability test, the company failed over its system to secondary nodes in the second Availability Zone. When the system failed over, the initial licenses were no longer valid.\n\nWhat could be the reason for this behavior?","unix_timestamp":1689185520,"answer":"C","timestamp":"2023-07-12 20:12:00","answer_ET":"C","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/114996-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/"},{"id":"OV6jBB6qaNvNZ9LTgM7T","exam_id":28,"answer_description":"","question_text":"A company is running an SAP ERP Central Component (SAP ECC) system on an SAP HANA database that is 10 TB in size. The company is receiving notifications about long-running database backups every day. The company uses AWS Backint Agent for SAP HANA (AWS Backint agent) on an Amazon EC2 instance to back up the database. An SAP NetWeaver administrator needs to troubleshoot the problem and propose a solution.\nWhich solution will help resolve this problem?","answer_ET":"B","isMC":true,"topic":"1","question_images":[],"question_id":109,"url":"https://www.examtopics.com/discussions/amazon/view/96800-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/","answer":"B","answers_community":["B (100%)"],"timestamp":"2023-01-25 05:43:00","discussion":[{"poster":"juanvepe","comment_id":"911372","timestamp":"1685544480.0","content":"B: \nhttps://docs.aws.amazon.com/sap/latest/sap-hana/aws-backint-agent-troubleshooting.html\n\nRoot Cause: The connection between AWS Backint agent and S3 fails due to high throughput.\n\nResolution: Use the following steps to troubleshoot this issue.\n\nUpdate AWS Backint agent to version 1.02 or higher.\n\nLower the following backup and restore parameters:\n\nBackup\n\nUploadConcurrency\n\nUploadChannelSize\n\nRestore\n\nMaximumConcurrentFilesForRestore\n\nDownloadConcurrency\n\nThese values reduce concurrency and parallelism used by AWS Backint agent to achieve high performance during backup and restore.\n\nReview network setup and configuration.\n\nPerform trace route to see if Amazon S3 traffic goes through firewall package scanners or any other software that could significantly increase network latency.","upvote_count":"1"},{"content":"Selected Answer: B\nB is fine.","poster":"schalke04","comment_id":"800445","timestamp":"1675736100.0","upvote_count":"3"},{"comment_id":"800137","upvote_count":"2","timestamp":"1675709160.0","poster":"SMALLAM","content":"I think B"},{"timestamp":"1675539660.0","upvote_count":"3","comment_id":"798304","poster":"Hyperdanny","content":"B:\n The performance of backup and restore depends on many factors, such as the type of EC2 instance used, the EBS volumes, and the number of SAP HANA channels. If your database size is less than 128 GB, SAP HANA defaults to a single channel, or your SAP HANA parameter parallel_data_backup_backint_channels is set to 1."},{"timestamp":"1675514580.0","poster":"Grillppl","upvote_count":"4","content":"B. Check the UploadChannelSize parameter\nThe UploadChannelSize parameter is used to determine how many files can be uploaded in parallel to the S3 bucket during backups.\n\nhttps://docs.aws.amazon.com/sap/latest/sap-hana/aws-backint-agent-installing-configuring.html","comment_id":"797941"},{"poster":"kk8s","comment_id":"791731","upvote_count":"2","content":"Maybe B\n\nhttps://docs.aws.amazon.com/sap/latest/sap-hana/aws-backint-agent-troubleshooting.html","timestamp":"1675003200.0"},{"timestamp":"1674621780.0","upvote_count":"4","comment_id":"787272","content":"Selected Answer: B\nI think B","poster":"sagsgg"}],"answer_images":[],"choices":{"A":"Ensure that AWS Backint agent is configured to send the backups to an Amazon S3 bucket over the internet. Ensure that the EC2 instance is configured to access the internet through a NAT gateway.","B":"Check the UploadChannelSize parameter for AWS Backint agent. Increase this value in the aws-backint-agent-config.yaml configuration file based on the EC2 instance type and storage configurations.","C":"Check the MaximumConcurrentFilesForRestore parameter for AWS Backint agent. Increase the parameter from 5 to 10 by using the aws-backint-agent-config.yaml configuration file.","D":"Ensure that the backups are compressed. If necessary, configure AWS Backint agent to compress the backups and send them to an Amazon S3 bucket."},"unix_timestamp":1674621780},{"id":"fPFbzG9Kx9VuayZ5asxT","exam_id":28,"answer_description":"","question_text":"A company has deployed SAP workloads on AWS. The company's SAP applications use an IBM Db2 database and an SAP HANA database. An SAP solutions architect needs to create a solution to back up the company's databases.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_ET":"C","isMC":true,"question_id":110,"question_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/114247-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/","answer":"C","answers_community":["C (67%)","B (33%)"],"timestamp":"2023-07-06 13:18:00","discussion":[{"content":"Selected Answer: C\nC: AWS Backint Agent for SAP HANA is an SAP-certified backup and restore solution for SAP HANA workloads running on Amazon EC2 instances. It allows the user to directly backup the database to Amazon S3 and supports important features such as backup catalog, automatic backups and log backups. However, AWS Backint Agent does not support IBM Db2 databases.\n\nFor the IBM Db2 database, you can first store the backups on an Amazon Elastic Block Store (Amazon EBS) volume. Then, you can run a script periodically to move these backups to Amazon S3 for longer term storage and to delete the backups from the EBS volume. Amazon S3 offers cost-effective storage compared to EBS volumes, especially for data that isn't accessed frequently.\n\nTherefore, the most cost-effective solution is to use the Backint Agent for the SAP HANA database backups, and an EBS volume with periodic data transfer to S3 for the IBM Db2 database backups.","upvote_count":"5","timestamp":"1690949940.0","comment_id":"969657","poster":"kaishin0527"},{"upvote_count":"1","timestamp":"1707374340.0","poster":"awsmonster","comment_id":"1144161","content":"Selected Answer: C\nIt is C.\n\nAWS Backint Agent is dedicated to SAP HANA only. Option B will not work."},{"upvote_count":"1","comment_id":"965741","timestamp":"1690567440.0","poster":"tonatiuhop","content":"Selected Answer: B\nB\nWith third party backint tools— There are many third-party tools from partners like Commvault and Veritas that use SAP backint interface and store backups directly in Amazon S3 buckets."},{"content":"Selected Answer: C\nOption B wouldn't work because Backint doesn't support Db2. So using EBS for temporary storage and then moving the backups to S3 is a reasonable approach.\nIt is C.","timestamp":"1689859500.0","comment_id":"957619","upvote_count":"3","poster":"zzw890827"},{"content":"Selected Answer: B\nIt's B","upvote_count":"2","comment_id":"956980","timestamp":"1689808320.0","poster":"ADVIT"},{"timestamp":"1689357180.0","comment_id":"951723","upvote_count":"3","poster":"[Removed]","content":"Selected Answer: B\nB CORRECT. AWS Backint Agent for SAP HANA is an SAP-certified backup and restore solution for SAP HANA workloads running on Amazon EC2 instances. AWS Backint Agent backs up your SAP HANA database to Amazon S3 and restores it using SAP management tools, such as SAP HANA Cockpit, SAP HANA Studio, or SQL commands. Always avoid using manual scripts or writing your own logic.","comments":[{"upvote_count":"1","poster":"[Removed]","comment_id":"951724","content":"Option A is incorrect because it uses an Amazon Elastic Block Store (Amazon EBS) volume to store backups for the databases. It runs a periodic script to move the backups to Amazon S3 and to delete the backups from the EBS volume. This option is not cost-effective because it requires additional storage space and resources.\n\nOption C is incorrect because it uses an Amazon Elastic Block Store (Amazon EBS) volume to store backups for the Db2 database. It runs periodic scripts to move the backups to Amazon S3 and to delete the backups from the EBS volume. For the SAP HANA database, it uses AWS Backint Agent for SAP HANA to move the backups directly to Amazon S3. This option is not cost-effective because it requires additional storage space and resources.\n\nOption D is incorrect because it uses Amazon Elastic File System (Amazon EFS) to store backups for the databases. This option is not cost-effective because it requires additional storage space and resources.","timestamp":"1689357180.0"}]},{"timestamp":"1688642280.0","content":"Selected Answer: C\nI thinks the correct one é C.","comment_id":"944570","poster":"tatarevick","upvote_count":"3"}],"answer_images":[],"choices":{"A":"Use an Amazon Elastic Block Store (Amazon EBS) volume to store backups for the databases. Run a periodic script to move the backups to Amazon S3 and to delete the backups from the EBS volume.","D":"Use Amazon Elastic File System (Amazon EFS) to store backups for the databases.","B":"Use AWS Backint Agent for SAP HANA to move the backups for the databases directly to Amazon S3.","C":"Use an Amazon Elastic Block Store (Amazon EBS) volume to store backups for the Db2 database. Run periodic scripts to move the backups to Amazon S3 and to delete the backups from the EBS volume. For the SAP HANA database, use AWS Backint Agent for SAP HANA to move the backups directly to Amazon S3."},"unix_timestamp":1688642280}],"exam":{"provider":"Amazon","id":28,"numberOfQuestions":130,"isMCOnly":true,"name":"AWS Certified SAP on AWS - Specialty PAS-C01","isBeta":false,"isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":22},"__N_SSP":true}