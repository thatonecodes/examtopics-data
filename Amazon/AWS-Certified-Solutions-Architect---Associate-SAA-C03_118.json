{"pageProps":{"questions":[{"id":"3HtOVkfndUaQdoRO0E61","answer_images":[],"discussion":[{"poster":"pentium75","comment_id":"1111802","timestamp":"1719911880.0","content":"Selected Answer: A\nWAF, you can have 100 \"rule sets\" per account, each with up to 10,000 IP addresses.\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/limits.html","upvote_count":"8"},{"timestamp":"1728541680.0","poster":"Karls","content":"Selected Answer: C\nAWS Lambda and DynamoDB to dynamically manage and validate incoming requests based on registered IP addresses.\nhttps://docs.aws.amazon.com/lambda/latest/dg/services-alb.html","upvote_count":"1","comment_id":"1192747"},{"upvote_count":"4","comment_id":"1127039","poster":"ferdzcruz","timestamp":"1721439420.0","content":"web services and HTTPS = WAF"},{"timestamp":"1720770300.0","poster":"awsgeek75","comment_id":"1120662","upvote_count":"3","content":"Selected Answer: A\nB: Looks like an incomplete solution for something different\nC: Not workable as Lambda for IP filtering means you have already allowed the request to pass through\nD NACL with entries for each registered IP is not possible."},{"comment_id":"1082251","content":"Selected Answer: A\nendpoint restriction by IP addresses = AWS WAF","timestamp":"1716873660.0","poster":"TariqKipkemei","upvote_count":"4"},{"timestamp":"1713086460.0","poster":"Passexam4sure_com","content":"Selected Answer: A\nAssociate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses.","comment_id":"1043298","upvote_count":"4"},{"comment_id":"1016676","timestamp":"1711367040.0","content":"Selected Answer: A\nAWS WAF cannot be directly associated with a Web Application. But, can only be associated with Application Load Balancer, CloudFront and API Gateway.","poster":"Sugarbear_01","upvote_count":"4"},{"comments":[{"content":"WAF allows 100 rule sets, each with up to 10,000 IP addresses, per account.","poster":"pentium75","comment_id":"1111804","upvote_count":"2","timestamp":"1719911940.0"},{"poster":"potomac","timestamp":"1715026380.0","comment_id":"1064301","content":"10,000 IP addresses\nFor the latest version of AWS WAF, see AWS WAF. If you want to allow or block web requests based on the IP addresses that the requests originate from, create one or more IP match conditions. An IP match condition lists up to 10,000 IP addresses or IP address ranges that your requests originate from.","upvote_count":"2"},{"content":"I will choose this answer if it is API Gateway. But I cannot figure out how to do lambda authentication on ALB. I will go A","comments":[{"timestamp":"1713035160.0","comment_id":"1042904","poster":"taustin2","upvote_count":"2","content":"You are right. I don't know of a way to use Lambda with ALB in this way. Answer is A.","comments":[{"comment_id":"1064302","comments":[{"upvote_count":"3","timestamp":"1715026860.0","content":"WAF seems still better","poster":"potomac","comment_id":"1064305"}],"timestamp":"1715026560.0","upvote_count":"1","poster":"potomac","content":"ALB invokes Lambda function, sending the incoming data in JSON format. Lambda function performs task, returns HTTP response to ALB."}]}],"poster":"bsbs1234","timestamp":"1712856600.0","comment_id":"1040967","upvote_count":"2"}],"upvote_count":"3","poster":"taustin2","timestamp":"1711294740.0","content":"Selected Answer: C\nChanging answer to C because of \"20000\" IP addresses. Use Lambda with ALB.","comment_id":"1015837"},{"comment_id":"1015301","upvote_count":"3","content":"Selected Answer: A\nA. Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses.","poster":"Guru4Cloud","timestamp":"1711230720.0"},{"timestamp":"1711149120.0","poster":"taustin2","content":"Selected Answer: A\nWAF meets the requirements.","comment_id":"1014514","upvote_count":"3"}],"timestamp":"2023-09-22 23:12:00","unix_timestamp":1695417120,"question_id":586,"answer":"A","answer_ET":"A","question_text":"A company has an application that serves clients that are deployed in more than 20.000 retail storefront locations around the world. The application consists of backend web services that are exposed over HTTPS on port 443. The application is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). The retail locations communicate with the web application over the public internet. The company allows each retail location to register the IP address that the retail location has been allocated by its local ISP.\n\nThe company's security team recommends to increase the security of the application endpoint by restricting access to only the IP addresses registered by the retail locations.\n\nWhat should a solutions architect do to meet these requirements?","isMC":true,"topic":"1","question_images":[],"exam_id":31,"answer_description":"","answers_community":["A (91%)","9%"],"url":"https://www.examtopics.com/discussions/amazon/view/121216-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"C":"Store the IP addresses in an Amazon DynamoDB table. Configure an AWS Lambda authorization function on the ALB to validate that incoming requests are from the registered IP addresses.","B":"Deploy AWS Firewall Manager to manage the ALConfigure firewall rules to restrict traffic to the ALModify the firewall rules to include the registered IP addresses.","D":"Configure the network ACL on the subnet that contains the public interface of the ALB. Update the ingress rules on the network ACL with entries for each of the registered IP addresses.","A":"Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses."}},{"id":"o6Tc4gxxDbMaaIFvBjhL","timestamp":"2023-09-22 11:33:00","answers_community":["B (100%)"],"answer_images":[],"answer_ET":"B","question_text":"A company is building a data analysis platform on AWS by using AWS Lake Formation. The platform will ingest data from different sources such as Amazon S3 and Amazon RDS. The company needs a secure solution to prevent access to portions of the data that contain sensitive information.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","isMC":true,"question_id":587,"question_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/121162-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"C":"Create an AWS Lambda function that removes sensitive information before Lake Formation ingests the data.","D":"Create an AWS Lambda function that periodically queries and removes sensitive information from Lake Formation tables.","A":"Create an IAM role that includes permissions to access Lake Formation tables.","B":"Create data filters to implement row-level security and cell-level security."},"topic":"1","answer":"B","unix_timestamp":1695375180,"discussion":[{"comments":[{"timestamp":"1705053600.0","comment_id":"1120676","content":"https://docs.aws.amazon.com/lake-formation/latest/dg/data-filters-about.html","upvote_count":"2","poster":"awsgeek75"}],"timestamp":"1695498600.0","comment_id":"1015298","poster":"Guru4Cloud","upvote_count":"10","content":"Selected Answer: B\nThe key reasons are:\n\nLake Formation data filters allow restricting access to rows or cells in data tables based on conditions. This allows preventing access to sensitive data.\nData filters are implemented within Lake Formation and do not require additional coding or Lambda functions.\nLambda functions to pre-process data or purge tables would require ongoing development and maintenance.\nIAM roles only provide user-level permissions, not row or cell level security.\nData filters give granular access control over Lake Formation data with minimal configuration, avoiding complex custom code."},{"upvote_count":"2","content":"Selected Answer: B\nB. Create data filters to implement row-level security and cell-level security.\nExplanation:\n\n Row-Level and Cell-Level Security: AWS Lake Formation provides built-in support for row-level and cell-level security. By using data filters, you can define policies that control access to specific rows and cells within your tables. This allows you to restrict access to sensitive information without needing to manually filter or remove data.\n\n Least Operational Overhead: This solution leverages built-in Lake Formation capabilities, reducing the need for additional infrastructure or custom code. Once the data filters are set up, they automatically enforce the security policies, minimizing ongoing operational overhead.","comment_id":"1239479","poster":"emakid","timestamp":"1719712140.0"},{"timestamp":"1718579700.0","poster":"KennethNg923","content":"Selected Answer: B\nAs it said “prevent access to portions of the data that contain sensitive information”, not the access to S3, so data filter is enough","comment_id":"1231568","upvote_count":"3"},{"content":"Selected Answer: B\nFocus on the exact wordings: \"to prevent access to portions of the data that contain sensitive information.\"\nOnly option B restricts the platform to access sensitive data, option A restrict users to restrict access that doesn't serve the req here, C and D are talking about removing the sensitive data which is not the ask here","upvote_count":"2","comment_id":"1208026","poster":"wizcloudifa","timestamp":"1715115780.0"},{"poster":"ferdzcruz","content":"portions of the data that contain sensitive information = Filtered data.","comment_id":"1127040","upvote_count":"2","timestamp":"1705721880.0"},{"content":"Selected Answer: B\nA is possible but it does not secure the data properly and only provides table level access control (if any).\nCD are too much overhead\nB is exactly for this purpose and is a built-in feature of Lake formation","upvote_count":"2","comment_id":"1120675","timestamp":"1705053480.0","poster":"awsgeek75"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/lake-formation/latest/dg/data-filters-about.html","poster":"potomac","upvote_count":"3","timestamp":"1699309800.0","comment_id":"1064309"},{"comment_id":"1014516","poster":"taustin2","content":"Selected Answer: B\nYou can create data filters based on the values of columns in a Lake Formation table. Easy. Lowest operational overhead.","timestamp":"1695417300.0","upvote_count":"3"},{"comment_id":"1013914","upvote_count":"3","poster":"nnecode","timestamp":"1695375180.0","content":"Selected Answer: B\nThe best solution to meet the requirements with the least operational overhead is to create data filters to implement row-level security and cell-level security.\n\nData filters are a feature of Lake Formation that allow you to restrict access to data based on row and column values. This can be used to implement row-level security and cell-level security.\n\nTo implement row-level security, you would create a data filter that only allows users to access rows where the values in certain columns meet certain criteria. For example, you could create a data filter that only allows users to access rows where the value in the customer_id column matches the user's own customer ID."}],"exam_id":31},{"id":"XFtUREuJLv07sxcVTNHL","timestamp":"2022-10-16 10:49:00","answers_community":["C (100%)"],"answer_images":[],"answer_ET":"C","question_text":"A company is developing a two-tier web application on AWS. The company's developers have deployed the application on an Amazon EC2 instance that connects directly to a backend Amazon RDS database. The company must not hardcode database credentials in the application. The company must also implement a solution to automatically rotate the database credentials on a regular basis.\nWhich solution will meet these requirements with the LEAST operational overhead?","isMC":true,"question_id":588,"question_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/85580-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"A":"Store the database credentials in the instance metadata. Use Amazon EventBridge (Amazon CloudWatch Events) rules to run a scheduled AWS Lambda function that updates the RDS credentials and instance metadata at the same time.","D":"Store the database credentials as encrypted parameters in AWS Systems Manager Parameter Store. Turn on automatic rotation for the encrypted parameters. Attach the required permission to the EC2 role to grant access to the encrypted parameters.","B":"Store the database credentials in a configuration file in an encrypted Amazon S3 bucket. Use Amazon EventBridge (Amazon CloudWatch Events) rules to run a scheduled AWS Lambda function that updates the RDS credentials and the credentials in the configuration file at the same time. Use S3 Versioning to ensure the ability to fall back to previous values.","C":"Store the database credentials as a secret in AWS Secrets Manager. Turn on automatic rotation for the secret. Attach the required permission to the EC2 role to grant access to the secret."},"topic":"1","answer":"C","unix_timestamp":1665910140,"discussion":[{"content":"Selected Answer: C\nSecrets manager supports Autorotation unlike Parameter store.","poster":"KVK16","comments":[{"content":"Parameter store does not support autorotation.","comment_id":"700282","poster":"JesseeS","upvote_count":"10","timestamp":"1666297680.0"}],"timestamp":"1665910140.0","upvote_count":"24","comment_id":"696108"},{"poster":"Buruguduystunstugudunstuy","upvote_count":"16","comments":[{"timestamp":"1671556140.0","upvote_count":"10","comment_id":"751264","content":"Option A, storing the database credentials in the instance metadata and using a Lambda function to update them, would not meet the requirement of not hardcoding the credentials in the application. \n\nOption B, storing the database credentials in an encrypted S3 bucket and using a Lambda function to update them, would also not meet this requirement, as the application would still need to access the credentials from the configuration file. \n\nOption D, storing the database credentials as encrypted parameters in AWS Systems Manager Parameter Store, would also not meet this requirement, as the application would still need to access the encrypted parameters in order to use them.","poster":"Buruguduystunstugudunstuy"}],"timestamp":"1671556140.0","content":"Selected Answer: C\nThe correct solution is C. Store the database credentials as a secret in AWS Secrets Manager. Turn on automatic rotation for the secret. Attach the required permission to the EC2 role to grant access to the secret.\n\nAWS Secrets Manager is a service that enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. By storing the database credentials as a secret in Secrets Manager, you can ensure that they are not hardcoded in the application and that they are automatically rotated on a regular basis. To grant the EC2 instance access to the secret, you can attach the required permission to the EC2 role. This will allow the application to retrieve the secret from Secrets Manager as needed.","comment_id":"751263"},{"timestamp":"1739848320.0","comment_id":"1358102","content":"Selected Answer: C\n- automatically rotate credentials on regular basis -> AWS Secret Manager","upvote_count":"1","poster":"DatNX"},{"content":"Selected Answer: C\nKeyword: database credentials.\n\nAWS secrets managers will handle it.","comment_id":"1348431","upvote_count":"1","poster":"Kyleskii","timestamp":"1738139700.0"},{"timestamp":"1735811400.0","upvote_count":"1","content":"Selected Answer: C\nRotating the credentials is a feature provided by AWS Secrets Manager","poster":"satyaammm","comment_id":"1335464"},{"timestamp":"1726058820.0","content":"Selected Answer: C\nAns C - Secrets Manager, provides rotation - and also a lot more API calls","poster":"PaulGa","upvote_count":"1","comment_id":"1282105"},{"comment_id":"1184129","poster":"soufiyane","upvote_count":"1","timestamp":"1711545900.0","content":"Selected Answer: C\nparameter store does not have auto rotation"},{"comment_id":"1152452","upvote_count":"2","timestamp":"1708159200.0","poster":"Atul6969","content":"Selected Answer: C\ntest kjlshfjkh jfskjfnkj kj bskjfb kj kjs bfkjs b kjf"},{"poster":"awsgeek75","timestamp":"1705246980.0","upvote_count":"1","comment_id":"1122640","content":"Selected Answer: C\nSecrets Manager is purpose built for this scenario\n\nAB are wrong and insecure way of doing this\nD Parameter store with encrypted string can be used for this but is not ideal choice and AFAIK it does not support automatic rotation without extra programming"},{"poster":"1Alpha1","content":"Selected Answer: C\nC - \"Auto Rotation\"","comment_id":"1103830","timestamp":"1703298120.0","upvote_count":"1"},{"comment_id":"1055154","timestamp":"1698388320.0","content":"AWS Secrets Manager is a service that enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. By storing the database credentials as a secret in Secrets Manager, you can ensure that they are not hardcoded in the application and that they are automatically rotated on a regular basis. To grant the EC2 instance access to the secret, you can attach the required permission to the EC2 role.","upvote_count":"1","poster":"Ruffyit"},{"comment_id":"977581","upvote_count":"1","content":"Selected Answer: C\nStoring the credentials in AWS Secrets Manager and enabling automatic rotation meets the requirements with the least operational overhead. The EC2 instance role just needs permission to access the secret, and Secrets Manager handles rotating the credentials automatically on a schedule.","poster":"Guru4Cloud","timestamp":"1691667600.0"},{"timestamp":"1691470980.0","content":"Selected Answer: C\nKey Autorotation = AWS Secrets Manager","comment_id":"975210","upvote_count":"2","poster":"TariqKipkemei"},{"poster":"miki111","upvote_count":"1","timestamp":"1689781620.0","comment_id":"956782","content":"Option C is the right answer."},{"poster":"cookieMr","upvote_count":"2","content":"Selected Answer: C\nStoring the credentials in Secrets Manager provides dedicated and secure management. With automatic rotation enabled, Secrets Manager handles the credential updates automatically. Attaching the necessary permissions to the EC2 role allows the application to securely access the secret.\n\nThis approach minimizes operational overhead and provides a secure and managed solution for credential management.","timestamp":"1687347300.0","comment_id":"929419"},{"poster":"Bmarodi","timestamp":"1685982120.0","content":"Selected Answer: C\nThe solution that meets the requirements with the least operational overhead, is option C.","upvote_count":"1","comment_id":"915569"},{"comment_id":"902463","poster":"Bmarodi","upvote_count":"1","timestamp":"1684573140.0","content":"Selected Answer: C\nMy choice is c."},{"comment_id":"797817","upvote_count":"1","poster":"AndyMartinez","timestamp":"1675505880.0","content":"Selected Answer: C\nThe right option is C."},{"comment_id":"795808","poster":"Adios_Amigo","content":"C is the most correct answer. Automatic replacement must be performed by the secret manager.","timestamp":"1675318680.0","upvote_count":"1"},{"poster":"career360guru","content":"Selected Answer: C\nOption C - As the requirement is to rotate the secrets Secrets manager is the one that can support it.","upvote_count":"1","comment_id":"749374","timestamp":"1671416280.0"},{"content":"C is correct","poster":"Wpcorgan","upvote_count":"2","comment_id":"723594","timestamp":"1669040460.0"},{"upvote_count":"3","poster":"BoboChow","comment_id":"700512","content":"Selected Answer: C\nAWS Secrets Manager is a newer service than SSM Parameter store","timestamp":"1666327440.0"},{"timestamp":"1666093020.0","poster":"ArielSchivo","upvote_count":"3","comment_id":"698174","content":"Selected Answer: C\nOption C.\n\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/create_database_secret.html"}],"exam_id":31},{"id":"rZIdt8HS1jd0BwxWqmBL","exam_id":31,"question_images":[],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/121217-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"B","choices":{"B":"Deploy a gateway VPC endpoint for Amazon S3. Set up an AWS Direct Connect connection between the on-premises network and the VPC.","C":"Set up an AWS Transit Gateway connection from the VPC to the S3 buckets. Create an AWS Site-to-Site VPN connection between the company and the VPC.","D":"Set up proxy EC2 instances that have routes to NAT gateways. Configure the proxy EC2 instances to fetch S3 data and feed the application instances.","A":"Deploy an interface VPC endpoint for Amazon EC2. Create an AWS Site-to-Site VPN connection between the company and the VPC."},"answer_images":[],"unix_timestamp":1695417540,"answer_description":"","timestamp":"2023-09-22 23:19:00","question_id":589,"discussion":[{"poster":"taustin2","comment_id":"1014517","content":"Selected Answer: B\nGateway VPC Endpoint = no internet to access S3. Direct Connect = secure access to VPC.","timestamp":"1695417540.0","upvote_count":"10"},{"poster":"awsgeek75","upvote_count":"6","content":"Selected Answer: B\nNo public internet != encrypted public internet (VPN)\nDirect connect is the only option.","timestamp":"1705053900.0","comment_id":"1120683"},{"comment_id":"1353233","timestamp":"1738991340.0","upvote_count":"1","content":"Selected Answer: A\nWhile not as ideal for high-traffic scenarios, a properly configured Site-to-Site VPN can also create a private connection between your on-premise network and AWS. Gateway endpoint is not working for on-premise","poster":"zdi561"},{"timestamp":"1726506120.0","upvote_count":"2","comment_id":"1284871","content":"Selected Answer: B\nDeploy a gateway VPC endpoint for Amazon S3 = so traffic between EC2 and S3 doesn't live AWS private network.\n\nSet up an AWS Direct Connect connection between the on-premises network and the VPC = servers on-premises can consume the output from ec2 instances via private connection.","poster":"MatAlves"},{"upvote_count":"3","timestamp":"1704509700.0","content":"Selected Answer: B\nA gateway VPC endpoint for Amazon S3 allows the EC2 instances within the VPC to access Amazon S3 buckets without using the public internet. The traffic between the VPC and S3 is routed within the AWS network.\nAWS Direct Connect establishes a private connection between the on-premises data center and AWS infrastructure, avoiding data transfer over the public internet and ensuring compliance with the specified requirements. It provides a dedicated network link with higher bandwidth options and potentially more consistent network performance than internet-based connections.\nWhereas Option A uses Site-to-Site VPN connection which is secure. However it typically runs over the public internet, which would not meet the company's requirement of avoiding public internet data transit.","comment_id":"1114912","poster":"OSHOAIB"},{"timestamp":"1704195120.0","upvote_count":"2","content":"Selected Answer: B\nI think the last sentence (\"Servers in the company's on-premises data center will consume the output from an application that runs on the EC2 instances\") refers to a different application. Purely from the wording, it does NOT seem to refer to the data 'loaded into S3 buckets so that it can be processed in the future' before. So the EC2 instances could write to S3, the on-premises servers can talk to the EC2 application, and data would not be transmitted over the public internet.\n\nNot A: There's no such thing as a \"VPC endpoint for Amazon EC2 (!)\"\nNot C: Transit Gateway is not for EC2->S3, VPN is over public internet\nNot D: Would address only the first part and use public Internet","poster":"pentium75","comments":[{"timestamp":"1715116620.0","upvote_count":"2","poster":"wizcloudifa","comment_id":"1208035","content":"Interface endpoint is a thing, the only reason A is not true is because of the presence of site-to-site vpn which is essentially accessing public internet"}],"comment_id":"1111814"},{"content":"Selected Answer: A\nI would go for A, for two reasons:\n1) \"S3 gateway endpoints do not currently support access from resources in a different Region, different VPC, or from an on-premises (non-AWS) environment. \n2) we tryna access an output from an application hosted in e2 instances and not to access the s3 stored data so ideally we should use Interface Endpoints for the applications running in ec2.","upvote_count":"3","poster":"ale_brd_111","comment_id":"1107885","comments":[{"poster":"MatAlves","upvote_count":"2","timestamp":"1726506240.0","comment_id":"1284872","content":"You forgot the traffic from EC2 to S3. Without the Gateway Endpoint, that would go via public internet.\n\n1. Deploy a gateway VPC endpoint for Amazon S3 = so traffic between EC2 and S3 doesn't live AWS private network.\n\n2. Set up an AWS Direct Connect connection between the on-premises network and the VPC = servers on-premises can consume the output from ec2 instances via private connection."},{"timestamp":"1704195180.0","upvote_count":"3","comments":[{"upvote_count":"2","content":"exists, check the docs, interface VPS endpoint != gateway VPC endpoint, they have different range of services","comment_id":"1282273","poster":"elmyth","timestamp":"1726077360.0"}],"poster":"pentium75","comment_id":"1111815","content":"Plus, in A you deploy a VPC endpoint \"for EC2\" (!) which doesn't exist"},{"content":"\"Data must not be transmitted over the public internet\", as it would with A (VPN).","poster":"pentium75","upvote_count":"3","comment_id":"1111808","timestamp":"1704194640.0"}],"timestamp":"1703775840.0"},{"upvote_count":"1","poster":"ftaws","comments":[{"content":"there's no such things a 'VPC endpoint for EC2', and it uses public Internet","poster":"pentium75","upvote_count":"2","timestamp":"1704195480.0","comment_id":"1111819"}],"content":"I standhood answer is B, but why not A?","comment_id":"1103108","timestamp":"1703214900.0"},{"timestamp":"1701363600.0","upvote_count":"4","poster":"achechen","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-amazon-s3/ According to this document, \" S3 gateway endpoints do not currently support access from resources in a different Region, different VPC, or from an on-premises (non-AWS) environment. However, if you’re willing to manage a complex custom architecture, you can use proxies. In all those scenarios, where access is from resources external to VPC, S3 interface endpoints access S3 in a secure way.\" so, the answer is A.","comment_id":"1084573","comments":[{"content":"interface VPC endpoint works with PrivateLink, so it can be connected to huge amount of services, and to EC2. Gateway VPC endpoint can't work for on-prem","timestamp":"1726077180.0","poster":"elmyth","upvote_count":"2","comment_id":"1282272"}]},{"content":"Selected Answer: B\ndata must not be transmitted over the public internet = gateway VPC endpoint for Amazon S3 and AWS Direct Connect connection between the on-premises network and the VPC.","comment_id":"1082263","poster":"TariqKipkemei","timestamp":"1701156780.0","upvote_count":"2"},{"timestamp":"1695498480.0","content":"Selected Answer: B\nGateway VPC Endpoint = no internet to access S3. Direct Connect = secure access to VPC\nI agree with you @taustin2- Happy Learning all","upvote_count":"5","comment_id":"1015295","poster":"Guru4Cloud"}],"answer_ET":"B","question_text":"A company deploys Amazon EC2 instances that run in a VPC. The EC2 instances load source data into Amazon S3 buckets so that the data can be processed in the future. According to compliance laws, the data must not be transmitted over the public internet. Servers in the company's on-premises data center will consume the output from an application that runs on the EC2 instances.\n\nWhich solution will meet these requirements?","topic":"1","answers_community":["B (79%)","A (21%)"]},{"id":"7kfqxau0Bf57yukwBpON","question_images":[],"answer_images":[],"discussion":[{"poster":"Guru4Cloud","upvote_count":"7","comment_id":"1015293","content":"Selected Answer: A\nThe key reasons are:\n\nKinesis Data Streams provides an auto-scaling stream that can handle large amounts of streaming data ingestion and throughput. This removes the bottlenecks around receiving the data.\nAWS Lambda can process and store the data in a scalable serverless manner, avoiding EC2 capacity limits.\nAPI Gateway adds API management capabilities but does not improve the underlying scalability of the EC2 application.\nSNS is for event publishing/notifications, not large scale data ingestion. ECS still relies on EC2 capacity.","timestamp":"1711230360.0"},{"content":"Selected Answer: A\nFor near-real time data ingest and processing, Kinesis and Lambda are most scalable choice.","upvote_count":"5","timestamp":"1711149960.0","poster":"taustin2","comment_id":"1014521"},{"content":"Selected Answer: B\nA change the whole architect, B adding a API gateway to make the app more scalable not perfect as in A it may not be possible within budget, deadline, Yes, AWS API Gateway significantly contributes to making an application more scalable by handling a large volume of concurrent API requests, automatically managing traffic distribution, it can cache response and allow asyn call","timestamp":"1738992900.0","comment_id":"1353239","poster":"zdi561","upvote_count":"1"},{"timestamp":"1721439900.0","content":"A.\nKinesis Data Streams = near realtime and scalable\nAWS Lambda functions = scalable","comment_id":"1127042","poster":"ferdzcruz","upvote_count":"3"},{"poster":"TariqKipkemei","content":"Selected Answer: A\nmore scalable solution? = serverless = Amazon Kinesis Data Streams and AWS Lambda functions","upvote_count":"3","timestamp":"1716874680.0","comment_id":"1082268"},{"upvote_count":"2","poster":"wsdasdasdqwdaw","comment_id":"1057040","timestamp":"1714405320.0","content":"Only A is pure serverless which means scale. A for sure."}],"exam_id":31,"topic":"1","answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/121218-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2023-09-22 23:26:00","answer_description":"","choices":{"B":"Use Amazon API Gateway on top of the existing application. Create a usage plan with a quota limit for the third-party vendor.","A":"Use Amazon Kinesis Data Streams to ingest the data. Process the data using AWS Lambda functions.","C":"Use Amazon Simple Notification Service (Amazon SNS) to ingest the data. Put the EC2 instances in an Auto Scaling group behind an Application Load Balancer.","D":"Repackage the application as a container. Deploy the application using Amazon Elastic Container Service (Amazon ECS) using the EC2 launch type with an Auto Scaling group."},"unix_timestamp":1695417960,"answers_community":["A (94%)","6%"],"question_id":590,"isMC":true,"answer":"A","question_text":"A company has an application with a REST-based interface that allows data to be received in near-real time from a third-party vendor. Once received, the application processes and stores the data for further analysis. The application is running on Amazon EC2 instances.\n\nThe third-party vendor has received many 503 Service Unavailable Errors when sending data to the application. When the data volume spikes, the compute capacity reaches its maximum limit and the application is unable to process all requests.\n\nWhich design should a solutions architect recommend to provide a more scalable solution?"}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","id":31,"isImplemented":true,"isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","provider":"Amazon","numberOfQuestions":1019},"currentPage":118},"__N_SSP":true}