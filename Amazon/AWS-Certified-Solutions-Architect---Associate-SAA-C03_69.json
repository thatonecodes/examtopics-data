{"pageProps":{"questions":[{"id":"2TuQEk7nmBMaPHaAaIux","isMC":true,"unix_timestamp":1678459740,"timestamp":"2023-03-10 15:49:00","discussion":[{"comment_id":"904589","upvote_count":"14","timestamp":"1700724660.0","poster":"TariqKipkemei","content":"Selected Answer: D\nSecurity group defaults block all inbound traffic..Add an inbound rule to the security group of the database tier’s RDS instance to allow traffic from the web tiers security group"},{"timestamp":"1703406900.0","comment_id":"932261","upvote_count":"5","poster":"smartegnine","content":"Selected Answer: D\nSecurity Groups are tied on instance where as network ACL are tied to Subnet."},{"timestamp":"1727270160.0","content":"Selected Answer: D\nFor those questioning why the answer is not A:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html\n\nDefault NACLs allow all traffic, and in this question NACLs, SGs and route tables are in their default states.","comment_id":"1182588","upvote_count":"5","poster":"ExamGuru727"},{"upvote_count":"1","timestamp":"1726928340.0","comment_id":"1179401","content":"Selected Answer: A\nI think the answer should be A. Sine the services are in different subnets, the NACL would by default block all the incoming traffic to the subnet. Security group rule wouldn't be able to override NACL rule.","poster":"hgjdsh"},{"poster":"njufi","upvote_count":"2","content":"I selected option D as well, but I have a question regarding option A. Considering that the EC2 instances and the RDS are located in different subnets, shouldn't the network ACLs for each subnet allow traffic from one another as well? Given that the default settings for network ACLs typically block all traffic, wouldn't it be necessary to explicitly permit communication between the subnets?","timestamp":"1726668900.0","comment_id":"1176622"},{"poster":"elearningtakai","upvote_count":"4","content":"Selected Answer: D\nBy default, all inbound traffic to an RDS instance is blocked. Therefore, an inbound rule needs to be added to the security group of the RDS instance to allow traffic from the security group of the web tier's EC2 instances.","comment_id":"855900","timestamp":"1696086360.0"},{"upvote_count":"2","content":"Selected Answer: D\nD is the correct answer","timestamp":"1695646320.0","poster":"Russs99","comment_id":"850219"},{"content":"D\nhttps://www.examtopics.com/discussions/amazon/view/81445-exam-aws-certified-solutions-architect-associate-saa-c02/","comment_id":"836900","poster":"aragon_saa","timestamp":"1694506620.0","upvote_count":"2"},{"comment_id":"836843","poster":"KAUS2","timestamp":"1694503260.0","upvote_count":"2","content":"Selected Answer: D\nD is correct option"},{"poster":"[Removed]","content":"Selected Answer: D\nddddddd","upvote_count":"3","comment_id":"835124","timestamp":"1694350140.0"}],"exam_id":31,"answer_description":"","question_images":[],"question_text":"A company is deploying a two-tier web application in a VPC. The web tier is using an Amazon EC2 Auto Scaling group with public subnets that span multiple Availability Zones. The database tier consists of an Amazon RDS for MySQL DB instance in separate private subnets. The web tier requires access to the database to retrieve product information.\n\nThe web application is not working as intended. The web application reports that it cannot connect to the database. The database is confirmed to be up and running. All configurations for the network ACLs, security groups, and route tables are still in their default states.\n\nWhat should a solutions architect recommend to fix the application?","topic":"1","answer":"D","answer_images":[],"question_id":341,"url":"https://www.examtopics.com/discussions/amazon/view/102156-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"B":"Add a route in the VPC route table to allow traffic between the web tier’s EC2 instances and the database tier.","D":"Add an inbound rule to the security group of the database tier’s RDS instance to allow traffic from the web tiers security group.","C":"Deploy the web tier's EC2 instances and the database tier’s RDS instance into two separate VPCs, and configure VPC peering.","A":"Add an explicit rule to the private subnet’s network ACL to allow traffic from the web tier’s EC2 instances."},"answers_community":["D (97%)","3%"],"answer_ET":"D"},{"id":"uvdEaDw5rrzUORsg7VIu","answers_community":["A (100%)"],"answer":"A","topic":"1","discussion":[{"content":"Selected Answer: A\nreporting queries to run without impacting the write operations -> read replicas","comment_id":"1113726","upvote_count":"4","poster":"mwwt2022","timestamp":"1720094760.0"},{"timestamp":"1709301180.0","upvote_count":"4","comment_id":"996017","poster":"Guru4Cloud","content":"Selected Answer: A\nA) Deploy RDS read replicas to process the business reporting queries.\n\nThe key points are:\n\nRDS read replicas allow read-only copies of the production DB instance to be created\nQueries to the read replica don't affect the source DB instance performance\nThis isolates reporting queries from production traffic and write operations\nSo using RDS read replicas is the best way to meet the requirements of running reporting queries without impacting production write operations."},{"content":"Selected Answer: A\n\"single AZ\", \"large dataset\", \"Amazon RDS for MySQL database\". Want \"business report queries\". --> Solution \"Read replicas\", choose A.","timestamp":"1705798920.0","poster":"james2033","comment_id":"957925","upvote_count":"2"},{"poster":"antropaws","content":"Selected Answer: A\nNo doubt A.","timestamp":"1701331500.0","comment_id":"909960","upvote_count":"3"},{"comments":[{"upvote_count":"2","content":"reports=read replica","poster":"TariqKipkemei","comment_id":"1047496","timestamp":"1713499020.0"}],"content":"Load balance read operations = read replicas","upvote_count":"2","comment_id":"904591","poster":"TariqKipkemei","timestamp":"1700724840.0"},{"upvote_count":"3","comment_id":"836842","timestamp":"1694503200.0","poster":"KAUS2","content":"Selected Answer: A\nOption \"A\" is the right answer . Read replica use cases - You have a production database \nthat is taking on normal load & You want to run a reporting application to run some analytics\n• You create a Read Replica to run the new workload there\n• The production application is unaffected\n• Read replicas are used for SELECT (=read) only kind of statements (not INSERT, UPDATE, DELETE)"},{"content":"Selected Answer: A\naaaaaaaaaaa","timestamp":"1694391780.0","poster":"[Removed]","comment_id":"835577","upvote_count":"2"},{"upvote_count":"4","poster":"cegama543","comment_id":"835411","timestamp":"1694370540.0","content":"Selected Answer: A\noption A is the best solution for ensuring that business reporting queries can run without impacting write operations to the production DB instance."}],"unix_timestamp":1678460040,"isMC":true,"answer_description":"","timestamp":"2023-03-10 15:54:00","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/102157-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"question_id":342,"answer_ET":"A","question_images":[],"choices":{"A":"Deploy RDS read replicas to process the business reporting queries.","D":"Deploy the DB instance in multiple Availability Zones to process the business reporting queries.","C":"Scale up the DB instance to a larger instance type to handle write operations and queries.","B":"Scale out the DB instance horizontally by placing it behind an Elastic Load Balancer."},"question_text":"A company has a large dataset for its online advertising business stored in an Amazon RDS for MySQL DB instance in a single Availability Zone. The company wants business reporting queries to run without impacting the write operations to the production DB instance.\n\nWhich solution meets these requirements?"},{"id":"P4VJYoigpCN4WUAfqJSc","answer":"A","question_id":343,"unix_timestamp":1665244500,"isMC":true,"answer_ET":"A","exam_id":31,"answer_images":[],"choices":{"B":"Change the DB instance to a memory optimized instance class.","C":"Change the DB instance to a burstable performance instance class.","D":"Enable Multi-AZ RDS read replicas with MySQL native asynchronous replication.","A":"Change the storage type to Provisioned IOPS SSD."},"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/84748-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"upvote_count":"42","timestamp":"1671560280.0","poster":"pazabal","comment_id":"751327","content":"Selected Answer: A\nA: Made for high levels of I/O opps for consistent, predictable performance.\nB: Can improve performance of insert opps, but it's a storage performance rather than processing power problem\nC: for moderate CPU usage\nD: for scale read-only replicas and doesn't improve performance of insert opps on the primary DB instance"},{"content":"Selected Answer: A\nOption B (changing the DB instance to a memory optimized instance class) focuses on improving memory capacity but may not directly address the storage performance issue.\n\nOption C (changing the DB instance to a burstable performance instance class) is suitable for workloads with varying usage patterns and burstable performance needs, but it may not provide consistent and predictable performance for heavy write workloads.\n\nOption D (enabling Multi-AZ RDS read replicas with MySQL native asynchronous replication) is a solution for high availability and read scaling but does not directly address the storage performance issue.\n\nTherefore, option A is the most appropriate solution to address the performance issue by leveraging Provisioned IOPS SSD storage type, which provides consistent and predictable I/O performance for the Amazon RDS for MySQL database.","poster":"cookieMr","upvote_count":"25","timestamp":"1687092000.0","comment_id":"926688"},{"upvote_count":"1","poster":"JA2018","timestamp":"1731078360.0","comment_id":"1308839","content":"Selected Answer: A\nHint in the stem: DB insert operations taking 10 seconds or longer => current General Purpose SSD storage cannot providing sufficient IOPS required for the workload. Provisioned IOPS SSD can significantly improve storage performance and reduce latency for DB operations.\n\nProvisioned IOPS SSD: Designed to deliver fast, predictable, and consistent I/O performance. This type of performance is very crucial for databases with high transaction rates and frequent updates. It allows users to provision a specific level of IOPS to meet the performance requirements of their specific workload."},{"timestamp":"1725378660.0","upvote_count":"3","content":"Selected Answer: A\nAns A, as per stephyfresh13: \n\"Provisioned IOPS SSD: This storage type is designed to deliver fast, predictable, and consistent I/O performance, which is crucial for databases with high transaction rates and frequent updates. It allows you to provision a specific level of IOPS to meet the performance requirements of your workload.\"","comment_id":"1277705","poster":"PaulGa"},{"poster":"stephyfresh13","upvote_count":"4","content":"A. Change the storage type to Provisioned IOPS SSD.\n\nHere's why:\n\nProvisioned IOPS SSD: This storage type is designed to deliver fast, predictable, and consistent I/O performance, which is crucial for databases with high transaction rates and frequent updates. It allows you to provision a specific level of IOPS to meet the performance requirements of your workload.\n\nCurrent Issue: The problem with insert operations taking 10 seconds or longer indicates that the current General Purpose SSD storage is not providing sufficient IOPS for the workload. Provisioned IOPS SSD can significantly improve storage performance and reduce latency for database operations.","timestamp":"1719938400.0","comment_id":"1240896"},{"timestamp":"1714430400.0","comment_id":"1204229","content":"B is the answer, if the company decided that storage is the problem then an IOPS SSD (storage) is the solution and not a memory optimiser.","poster":"sudohogan","upvote_count":"1"},{"poster":"TilTil","content":"Selected Answer: B\nA. IOPS is about increasing the number of input connections so you can handle more requests. Which may not be the issue.\nB. Having a memory optimized class provides more RAM to execute the queries which take upto 10 secs to complete. More RAM means they can execute faster.\nC and D are distractors. They deal with high availability and timely scalability which are not issues here.","upvote_count":"2","comment_id":"1176333","timestamp":"1710747420.0"},{"upvote_count":"2","comment_id":"1122117","timestamp":"1705187460.0","poster":"awsgeek75","content":"Selected Answer: A\nDatabase storage is issue so\nBD is irrelevant\nC is for performance boost (CPU) which won't help with storage issues\nA Fix the storage issue"},{"comment_id":"1121656","upvote_count":"1","timestamp":"1705149840.0","content":"Selected Answer: A\nAnswer-A","poster":"A_jaa"},{"comment_id":"1102644","content":"Selected Answer: B\nDo not misconsider \"database storage performance is the problem\". I beleive the correct asnwer is B Due too the fact that Mmemory Optimized EC2 instance family is designed for DB servers perf.","poster":"bujuman","comments":[{"poster":"pentium75","upvote_count":"6","timestamp":"1703483280.0","comment_id":"1105038","content":"But the stem clearly says that storage performance, NOT memory performance, is the problem. More memory won't increase storage performance."}],"timestamp":"1703171280.0","upvote_count":"1"},{"content":"Selected Answer: A\nA is correct answer because it is talking about storage and transaction speed is slow due to it, should change to iops storage instead.","poster":"aptx4869","upvote_count":"2","timestamp":"1698574560.0","comment_id":"1056738"},{"comments":[{"comment_id":"1222602","poster":"Rhydian25","timestamp":"1717240680.0","content":"Copy-paste from pazabal's answer...","upvote_count":"1"}],"content":"A: Made for high levels of I/O opps for consistent, predictable performance.\nB: Can improve performance of insert opps, but it's a storage performance rather than processing power problem\nC: for moderate CPU usage\nD: for scale read-only replicas and doesn't improve performance of insert opps on the primary DB instance","upvote_count":"1","comment_id":"1054733","timestamp":"1698336060.0","poster":"Ruffyit"},{"upvote_count":"3","comment_id":"1048139","timestamp":"1697735220.0","poster":"AWSStudyBuddy","content":"I go with option A. Using Amazon Provisioned IOPS (PIOPS) SSD storage is the best way to solve the performance issue of insert operations taking 10 seconds or longer on an Amazon RDS for MySQL database table with more than 10 million rows and 2 TB of General Purpose SSD storage.\n\n\nA high-performance storage solution with reliable throughput and minimal latency is PIOPS SSD storage. Workloads like insert operations, which demand high I/O performance, are ideally suited for it."},{"comment_id":"1028343","content":"Selected Answer: A\nKey: database storage performance is the problem.","upvote_count":"1","timestamp":"1696806780.0","poster":"tom_cruise"},{"content":"Selected Answer: A\nOption A is answer - A. Change the storage type to Provisioned IOPS SSD. \nThe company's issue is related to storage performance, specifically with insert operations. This suggests that the I/O operations are the bottleneck.\n\nProvisioned IOPS SSD storage type is designed to handle the kind of workload the company is experiencing and should help improve the performance of insert operations.","timestamp":"1696507260.0","comment_id":"1025612","upvote_count":"3","poster":"awsleffe"},{"upvote_count":"2","comment_id":"1023440","content":"Selected Answer: A\n\"The company has determined that the database storage performance is the problem.\" \nThis is the key statement in the question. Otherwise I would have selected B but this statement here makes A correct.","poster":"awashenko","timestamp":"1696278240.0"},{"poster":"David_Ang","upvote_count":"2","content":"Selected Answer: A\nyeah \"A\" is correct is the most suitable option for this scenario, because you need to improve the speed of the reading and writing of the storage system.","comment_id":"1018817","timestamp":"1695820320.0"},{"upvote_count":"4","timestamp":"1691525820.0","poster":"Guru4Cloud","content":"Selected Answer: A\nThe best solution would be to change the storage type to Provisioned IOPS SSD. This allows you to specify a higher level of IOPS provisioned for your workload's needs.Therefore, switching to Provisioned IOPS SSD storage is the most direct way to resolve the storage performance bottleneck causing the slow insert times. The ability to provision high IOPS makes it the best solution for high throughput transactional workloads like this one.","comment_id":"976024"},{"upvote_count":"1","comment_id":"971658","poster":"TariqKipkemei","timestamp":"1691121240.0","content":"Selected Answer: A\nProvisioned IOPS SSD it is."},{"timestamp":"1689763020.0","comment_id":"956517","upvote_count":"1","poster":"Suvam90","content":"Option A is correct"},{"upvote_count":"3","content":"Selected Answer: A\nKeyword \"Provisioned IOPS SSD\" https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/provisioned-iops.html","comment_id":"956376","timestamp":"1689751260.0","poster":"james2033"},{"timestamp":"1689637440.0","poster":"Monu11394","comment_id":"954714","upvote_count":"2","content":"who decides what the correct answer is? \nthe question clearly says \"company determined storage issue\""},{"upvote_count":"1","timestamp":"1689540000.0","comment_id":"953635","content":"Option A is the right answer for this.","poster":"miki111"},{"upvote_count":"3","poster":"Jayendra0609","comment_id":"949923","timestamp":"1689173640.0","content":"Selected Answer: B\nMemory-optimized instances are helpful for efficient performance in the case of workloads that handle huge data sets in memory.\nhttps://www.projectpro.io/article/aws-rds-instance-types/749#:~:text=Memory%20Optimized%20AWS%20RDS%20Instances,%2C%20X2g)%2C%20and%20Z1d."},{"upvote_count":"1","content":"Selected Answer: A\nneed I/O","comment_id":"934103","poster":"omerap12","timestamp":"1687760520.0"},{"content":"A makes sense","upvote_count":"1","poster":"Mehkay","comment_id":"929770","timestamp":"1687368300.0"},{"content":"Selected Answer: A\nA is correct answer","upvote_count":"1","comment_id":"900770","timestamp":"1684387680.0","poster":"Sunil0320"},{"poster":"beginnercloud","timestamp":"1684318980.0","comment_id":"899989","content":"Selected Answer: A\nGeneral purpose SSD is not optimal for database that requires high performance. Answer A is correct","upvote_count":"1"},{"timestamp":"1684236660.0","poster":"nyschoi","content":"A\nOption B (changing the DB instance to a memory optimized instance class) focuses on increasing the available memory for the database, but it may not directly address the storage performance issue.\n\nOption C (changing the DB instance to a burstable performance instance class) is not the optimal choice since burstable performance instances are designed for workloads with bursty traffic patterns, and they may not provide the sustained performance needed for heavy update operations.\n\nOption D (enabling Multi-AZ RDS read replicas with MySQL native asynchronous replication) is primarily used for high availability and read scaling rather than addressing storage performance issues.","comment_id":"899113","upvote_count":"3"},{"content":"They're using General purpose SSD?? Provisioned IOPS SSD willl fix the performance issue described.","comment_id":"898910","poster":"Abrar2022","upvote_count":"1","timestamp":"1684217220.0"},{"content":"Selected Answer: A\nHow is the answer B? A is blatantly the correct answer... provisioned IOPS SSD is a given faster choice.","upvote_count":"2","poster":"acuaws","timestamp":"1681775460.0","comment_id":"873176"},{"poster":"ChanghyeonYoon","content":"Question said \"The company has determined that the database storage performance is the problem.\"\nSo answer is A.","timestamp":"1681619940.0","comment_id":"871460","upvote_count":"2"},{"poster":"cheese929","comment_id":"863647","content":"Selected Answer: A\nGeneral purpose SSD is not optimal for database that requires high performance. Answer is A","timestamp":"1680855060.0","upvote_count":"1"},{"poster":"channn","timestamp":"1680423720.0","content":"Selected Answer: A\nchange my mind from B to A as this statement 'There are millions of updates against this data every day'.","comment_id":"858638","upvote_count":"2"},{"upvote_count":"1","timestamp":"1680268980.0","content":"Selected Answer: A\nProvisioned IOPS SSD storage provides a guaranteed level of input/output operations per second (IOPS) that can help improve the performance of write-intensive database workloads. This solution can be cost-effective since you only pay for the amount of storage and IOPS provisioned. The performance of the storage will be stable, and it will provide predictable results.","comment_id":"857113","poster":"linux_admin"},{"timestamp":"1678199640.0","poster":"bilel500","content":"Selected Answer: A\nProvisioned IOPS SSD (io1) is a high-performance storage option that is designed for I/O-intensive workloads, such as databases that require a high number of read and write operations per second. It allows you to provide a specific number of input/output operations per second (IOPS) for your Amazon RDS for MySQL database instance, which can improve the performance of insert operations that require high levels of I/O.","upvote_count":"1","comment_id":"832003"},{"comment_id":"803684","poster":"K0nAn","upvote_count":"1","content":"Selected Answer: A\nChange the storage type to Provisioned IOPS SSD would likely address the performance issue described.","timestamp":"1675977120.0"},{"content":"Selected Answer: A\nhttps://aws.amazon.com/ebs/features/\n\"Provisioned IOPS volumes are backed by solid-state drives (SSDs) and are the highest performance\nEBS volumes designed for your critical, I/O intensive database applications.\nThese volumes are ideal for both IOPS-intensive and throughput-intensive workloads that require\nextremely low latency.\"\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","poster":"bdp123","comment_id":"801170","timestamp":"1675790220.0","upvote_count":"1"},{"comment_id":"784002","content":"general puRpose SSD oes not fluent with Mysql\nbut provission IOPS SSD are more flexible with the Mysql","poster":"kdinesh95","upvote_count":"3","timestamp":"1674370980.0"},{"content":"Selected Answer: A\nA is correct as the Provisioned IOPS is meant for it","comment_id":"774757","timestamp":"1673632740.0","upvote_count":"2","poster":"remand"},{"content":"Selected Answer: A\nA is correct","upvote_count":"1","poster":"vinhle","timestamp":"1673158200.0","comment_id":"769113"},{"upvote_count":"1","poster":"SilentMilli","timestamp":"1673045820.0","comment_id":"768131","content":"Selected Answer: A\nChanging the storage type to Provisioned IOPS SSD would address this performance issue. Provisioned IOPS SSD (io1) is a high-performance storage option designed for I/O-intensive workloads such as databases. It provides a consistent level of IOPS performance, regardless of the size of the data set. By using Provisioned IOPS SSD, the company can ensure that the database has the required level of I/O performance to handle the high volume of updates. This option would provide the best performance improvement for this workload, as it specifically addresses the issue of slow insert operations due to insufficient I/O performance."},{"content":"A is correct !","comment_id":"757469","upvote_count":"1","timestamp":"1672061280.0","poster":"Zerotn3"},{"comments":[{"poster":"Buruguduystunstugudunstuy","upvote_count":"2","content":"Answer B & C (not correct), Changing the DB instance to a memory-optimized instance class or a burstable performance instance class would not address the performance issue, as these instance classes are not optimized for storage performance.\n\nAnswer D (not correct), Enabling Multi-AZ RDS to read replicas with MySQL native asynchronous replication would not address the performance issue, as read replicas are used for read-heavy workloads and do not improve the performance of write operations on the primary database instance.","comment_id":"750454","timestamp":"1671507720.0"}],"upvote_count":"2","content":"Selected Answer: A\nThe correct answer is A: Change the storage type to Provisioned IOPS SSD.\n\nProvisioned IOPS SSD (io1) is a high-performance storage option that is designed for I/O-intensive workloads, such as databases that require a high number of read and write operations per second. It allows you to provide a specific number of input/output operations per second (IOPS) for your Amazon RDS for MySQL database instance, which can improve the performance of insert operations that require high levels of I/O.\n\nIn this case, the company has noticed that some insert operations are taking 10 seconds or longer, and the database has 2 TB of General Purpose SSD storage, which is not designed for high-performance workloads. Changing the storage type to Provisioned IOPS SSD will address the performance issue by providing a higher number of IOPS, which will improve the performance of the insert operations.","timestamp":"1671507720.0","poster":"Buruguduystunstugudunstuy","comment_id":"750453"},{"timestamp":"1671463680.0","poster":"Morinator","upvote_count":"1","comment_id":"749981","content":"Selected Answer: A\nA with no doubt"},{"timestamp":"1671433380.0","comment_id":"749569","poster":"career360guru","content":"Selected Answer: A\nOption A","upvote_count":"1"},{"comment_id":"739351","upvote_count":"1","timestamp":"1670525700.0","poster":"parku","content":"Selected Answer: A\nfast iops required."},{"comment_id":"736841","timestamp":"1670332920.0","upvote_count":"1","poster":"AlaN652","content":"Selected Answer: A\nAnswer is A since it is a transaction delay issue"},{"upvote_count":"1","poster":"hpipit","content":"Selected Answer: A\nA is the correct","comment_id":"732771","timestamp":"1669908600.0"},{"poster":"Wpcorgan","upvote_count":"1","comment_id":"723524","content":"A is correct","timestamp":"1669036140.0"},{"comment_id":"720948","content":"Selected Answer: A\nSSD is correct","timestamp":"1668726120.0","poster":"17Master","upvote_count":"1"},{"comment_id":"718521","upvote_count":"1","content":"SSD is correct","timestamp":"1668491460.0","poster":"TonyghostR05"},{"comment_id":"714248","upvote_count":"1","poster":"luvincanada","content":"A is correct.","timestamp":"1667963700.0"},{"upvote_count":"1","poster":"backbencher2022","content":"Selected Answer: A\nA is the correct answer","comment_id":"710830","timestamp":"1667519460.0"},{"timestamp":"1666626600.0","content":"Selected Answer: A\n> The company has determined that the database storage performance is the problem.\nA seems to be the most feasible answer here","upvote_count":"1","comment_id":"703176","poster":"Six_Fingered_Jose"},{"upvote_count":"1","timestamp":"1666302240.0","content":"i is indicating that its storage solution has a problem, so i think A should be correct.","poster":"Sarvar89","comment_id":"700323"},{"timestamp":"1666218420.0","comment_id":"699385","upvote_count":"1","content":"Selected Answer: A\nA\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","poster":"Anon9132656"},{"comment_id":"695815","poster":"Incognito013","timestamp":"1665882000.0","upvote_count":"1","content":"Answer: A"},{"timestamp":"1665801180.0","comment_id":"695137","content":"Selected Answer: A\nA: IOPS\nProvisioned IOPS – Provisioned IOPS storage is designed to meet the needs of I/O-intensive workloads, particularly database workloads, that require low I/O latency and consistent I/O throughput.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","poster":"ninjawrz","upvote_count":"4"},{"poster":"pooppants","content":"Selected Answer: A\nA https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","upvote_count":"2","comment_id":"691185","timestamp":"1665408540.0"},{"timestamp":"1665408480.0","comments":[],"poster":"pooppants","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","upvote_count":"2","comment_id":"691183"},{"comment_id":"690651","timestamp":"1665367560.0","upvote_count":"4","poster":"tuloveu","comments":[{"poster":"BoboChow","upvote_count":"1","timestamp":"1665725700.0","content":"You hit the point","comment_id":"694525"}],"content":"Selected Answer: A\nThere are millions of updates against this data every day. The storage Provisioned IOPS SSD should be served."},{"poster":"CloudGuru99","upvote_count":"2","timestamp":"1665244500.0","content":"A is the correct answer","comment_id":"689486"}],"timestamp":"2022-10-08 17:55:00","topic":"1","answers_community":["A (94%)","6%"],"question_text":"A company maintains a searchable repository of items on its website. The data is stored in an Amazon RDS for MySQL database table that contains more than 10 million rows. The database has 2 TB of General Purpose SSD storage. There are millions of updates against this data every day through the company's website.\nThe company has noticed that some insert operations are taking 10 seconds or longer. The company has determined that the database storage performance is the problem.\nWhich solution addresses this performance issue?","answer_description":""},{"id":"fWoYcGvdOGIFIM6ez9hd","answers_community":["AD (39%)","BD (31%)","AB (28%)","2%"],"topic":"1","answer":"AD","question_images":[],"answer_images":[],"unix_timestamp":1678480020,"answer_description":"","question_text":"A company hosts a three-tier ecommerce application on a fleet of Amazon EC2 instances. The instances run in an Auto Scaling group behind an Application Load Balancer (ALB). All ecommerce data is stored in an Amazon RDS for MariaDB Multi-AZ DB instance.\n\nThe company wants to optimize customer session management during transactions. The application must store session data durably.\n\nWhich solutions will meet these requirements? (Choose two.)","isMC":true,"choices":{"C":"Deploy an Amazon Cognito user pool to manage user session information.","B":"Use an Amazon DynamoDB table to store customer session information.","A":"Turn on the sticky sessions feature (session affinity) on the ALB.","E":"Use AWS Systems Manager Application Manager in the application to manage user session information.","D":"Deploy an Amazon ElastiCache for Redis cluster to store customer session information."},"question_id":344,"exam_id":31,"timestamp":"2023-03-10 21:27:00","answer_ET":"AD","url":"https://www.examtopics.com/discussions/amazon/view/102213-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"upvote_count":"28","comments":[{"timestamp":"1729858980.0","content":"Thanks,\nFirst consider the durability requirement of a session. It's never meant to be kept after the session terminates, tha5 said. You wouldn't need a pamanent database for a session. You would only require a catche, so that it can expire after a while when the session has already completed. That is why D is correct. A is required in the first place in order to initialize the use of the catche.","comment_id":"1302852","upvote_count":"2","poster":"babayomi"},{"timestamp":"1704627180.0","content":"This doesn't say anything about durability","poster":"pentium75","comments":[],"comment_id":"1115767","upvote_count":"4"}],"poster":"fruto123","comment_id":"836703","timestamp":"1678592100.0","content":"Selected Answer: AD\nIt is A and D. Proof is in link below.\n\nhttps://aws.amazon.com/caching/session-management/"},{"timestamp":"1702736700.0","content":"Selected Answer: BD\nI did not get why A is most voted? The question did not mention anything about fixed routing target so the ALB should route traffic randomly to each server. Then we just need to provide cache session management to avoid session lost issue instead of using sticky session.","poster":"Marco_St","comment_id":"1098234","upvote_count":"14","comments":[{"poster":"babayomi","upvote_count":"1","comment_id":"1302853","content":"AD\nFirst consider the durability requirement of a session. It's never meant to be kept after the session terminates, tha5 said. You wouldn't need a pamanent database for a session. You would only require a catche, so that it can expire after a while when the session has already completed. That is why D is correct. A is required in the first place in order to initialize the use of the catche.","timestamp":"1729859040.0"}]},{"upvote_count":"1","content":"Selected Answer: BD\nAvoid sticky sessions:\nWhile using sticky sessions on an Application Load Balancer (ALB) might seem like a solution, it can hinder scalability as it ties a user to a specific instance, which could become a bottleneck if traffic spikes. \nDynamodb and Elastic cache are best i think","poster":"bigjft","comment_id":"1363148","timestamp":"1740758280.0"},{"timestamp":"1738644780.0","upvote_count":"1","comment_id":"1351198","content":"Selected Answer: BD\nA is not right, the question is to where to save user session, the sticky session is used for ALB to send the request of the same client to the same target.","poster":"zdi561"},{"timestamp":"1733117100.0","content":"Selected Answer: BD\nPeople select AD because they think it is combine A and D to make a final solution. if the expectation is that each selected option should independently meet the requirements, then B and D. I think \"Which solutions will meet these requirements?\" should mean two independent solutions.","upvote_count":"1","comment_id":"1320788","poster":"FlyingHawk"},{"content":"Selected Answer: BD\nsession management during transaction ---> DynamoDB and ElastiCache","comment_id":"1315868","poster":"Arad","upvote_count":"1","timestamp":"1732199460.0"},{"poster":"Sergantus","comment_id":"1306758","upvote_count":"2","comments":[{"comment_id":"1320789","content":"I agree with your comments","poster":"FlyingHawk","timestamp":"1733117160.0","upvote_count":"1"}],"timestamp":"1730692140.0","content":"Selected Answer: BD\nWe are not looking here for a combination of options, just two independent solutions.\nBecause of the \"durability\" requirement -\nB - DynamoDB is durable\nD - ElastiCache for Redis although mostly used as in-memory cache, ElastiCache for Redis provides options for data persistence - RDB (Redis Database Backup) and AOF (Append-Only File). RDB periodically saves a snapshot of the dataset to disk, while AOF logs every write operation and replays it in case of a restart. ElastiCache for Redis also allows configuring replication groups with Multi-AZ and read replicas, providing additional redundancy and failover options."},{"upvote_count":"1","timestamp":"1729859160.0","poster":"babayomi","comment_id":"1302856","content":"AD\nFirst consider the durability requirement of a session. It's never meant to be kept after the session terminates, tha5 said. You wouldn't need a pamanent database for a session. You would only require a catche, so that it can expire after a while when the session has already completed. That is why D is correct. A is required in the first place in order to initialize the use of the catche."},{"comment_id":"1166810","content":"Selected Answer: BD\nOption A suggests using sticky sessions (session affinity) on the Application Load Balancer (ALB). While sticky sessions can help route requests from the same client to the same backend server, it doesn't directly address the requirement for durable storage of session data. Sticky sessions are typically used to maintain session state at the load balancer level, but they do not provide data durability in case of server failures or restarts.\nOption A - is not correct ! ! ! \n\nSo answer is option B and D ! ! !","timestamp":"1709680200.0","poster":"Uzbekistan","comments":[{"poster":"babayomi","timestamp":"1729859100.0","comment_id":"1302854","upvote_count":"1","content":"First consider the durability requirement of a session. It's never meant to be kept after the session terminates, tha5 said. You wouldn't need a pamanent database for a session. You would only require a catche, so that it can expire after a while when the session has already completed. That is why D is correct. A is required in the first place in order to initialize the use of the catche."}],"upvote_count":"3"},{"upvote_count":"4","poster":"jjcode","content":"why does it matter to store user sessions durably? they EXPIRE, why would a company care about storing user sessions, thats not something thats done in the real world, those things are usually data dumped, or overwritten with new session tokens LOL, this whole question is &^%&*^$#@%^","timestamp":"1708492680.0","comment_id":"1155260"},{"timestamp":"1706612340.0","upvote_count":"1","comment_id":"1135699","poster":"tuso","content":"I think the question is intended to mean \"Combination of services\", as some answers say \"to store\" or \"to manage\". So i am going for A+B, as sticky sessions are intended to manage the sessions and DynamoDB to store durably."},{"comment_id":"1110306","poster":"pentium75","comments":[{"poster":"dkw2342","upvote_count":"3","timestamp":"1709717700.0","comment_id":"1167041","content":"I agree that ElastiCache for Redis is not a durable KV store. \n\nBut what about the phrasing?\n\n\"Which solutions will meet these requirements? (Choose two.)\" Solutions (plural) implies two ways to *independently* fulfill the requirements. If you're supposed to select a combination of options, it's usually phrased like this: \"Which combination of solutions ...\""},{"timestamp":"1704727140.0","upvote_count":"2","comment_id":"1116721","content":"https://aws.amazon.com/blogs/developer/elasticache-as-an-asp-net-session-store/\n\nAmazon ElastiCache for Redis is highly suited as a session store to manage session information such as user authentication tokens, session state, and more. Simply use ElastiCache for Redis as a fast key-value store with appropriate TTL on session keys to manage your session information. Session management is commonly required for online applications, including games, e-commerce websites, and social media platforms.","comments":[{"poster":"avdxeqtr","upvote_count":"3","content":"Correct link: https://aws.amazon.com/elasticache/redis/","comment_id":"1116722","timestamp":"1704727140.0"}],"poster":"avdxeqtr"}],"content":"Selected Answer: AB\nGoing for AB. Sticky Sessions to \"optimize customer session management during transactions\" and DynamoDB to \"store session data durably\".\n\nD, ElastiCache does NOT allow \"durable\" storage. Just because there's an article that contains both words \"ElastiCache\" and \"durable\" does not prove the contrary.\n\nC and E, Cognito and Systems Manager, have nothing to do with the issue.","timestamp":"1704003660.0","upvote_count":"5"},{"upvote_count":"6","timestamp":"1701788880.0","content":"Selected Answer: BD\nI don't understand what Sticky Session has to do with session storage. For the intent of the problem, I think DynamoDB and Redis are appropriate.","poster":"m_y_s","comment_id":"1088588","comments":[{"poster":"pentium75","upvote_count":"4","content":"\"Session storage\" is not the only requirement here. It is about 'optimizing customer session management during transactions', obviously it makes sense to host customer sessions on same node to easy the session management.","timestamp":"1704003360.0","comment_id":"1110304","comments":[{"poster":"Sergantus","content":"Up until that node fails","timestamp":"1730691660.0","upvote_count":"2","comment_id":"1306754"}]}]},{"upvote_count":"4","comment_id":"1051426","timestamp":"1698034980.0","content":"Selected Answer: BD\nChatgpt4 says B and D\nOption A (Sticky sessions) is more for ensuring that a client's requests are sent to the same target once a session is established, but it doesn't provide a mechanism for durable session data storage across multiple instances. Option C (Amazon Cognito) is more for user identity management rather than session data storage during transactions. Option E (AWS Systems Manager Application Manager) is not a suitable or standard choice for session management in applications.","comments":[{"poster":"pentium75","content":"Answers starting with \"ChatGPT says ...\" are usually wrong.\n\nIn that case, B and D solve the same part of the requirement (storing session data), just B is durable (as required) while D is not durable (thus failing to meet the requirement). We still need to 'optimize customer session management'.","upvote_count":"4","comment_id":"1110305","timestamp":"1704003420.0"}],"poster":"daniel1"},{"poster":"TariqKipkemei","content":"Selected Answer: AD\nWell, this documentation says it all. Option A is obvious, and D ElastiCache for Redis, can even support replication in case of node failure/session data loss.\nhttps://aws.amazon.com/caching/session-management/","comments":[{"comment_id":"1115769","comments":[{"content":"You can configure Redis with persistence options","timestamp":"1730691780.0","upvote_count":"2","comment_id":"1306756","poster":"Sergantus"}],"poster":"pentium75","content":"ElastiCache can be HA and supports replication, but it remains a cache, which is by definition not durable.","upvote_count":"3","timestamp":"1704627300.0"}],"timestamp":"1697688480.0","comment_id":"1047504","upvote_count":"4"},{"poster":"Guru4Cloud","content":"Selected Answer: AD\nIt is A and D. Proof is in link below.\n\nhttps://aws.amazon.com/caching/session-management/","comment_id":"996000","comments":[],"timestamp":"1693568040.0","upvote_count":"2"},{"timestamp":"1691358600.0","upvote_count":"5","poster":"coolkidsclubvip","content":"Selected Answer: AB\ncache is not durable...at all","comment_id":"974252"},{"upvote_count":"1","comment_id":"963940","poster":"mrsoa","content":"Selected Answer: AD\ngo for AD","timestamp":"1690387260.0"},{"poster":"Kaiden123","content":"Selected Answer: B\ngo with B","comment_id":"961032","upvote_count":"2","timestamp":"1690163880.0"},{"comments":[{"upvote_count":"2","poster":"dkw2342","content":"Elsewhere they state: \"Redis was not built to be a durable and consistent database. If you need a durable, Redis-compatible database, consider Amazon MemoryDB for Redis. Because MemoryDB uses a durable transactional log that stores data across multiple Availability Zones (AZs), you can use it as your primary database. MemoryDB is purpose-built to enable developers to use the Redis API without worrying about managing a separate cache, database, or the underlying infrastructure.\" \n\nhttps://aws.amazon.com/redis/","comment_id":"1167029","timestamp":"1709716500.0"}],"upvote_count":"2","timestamp":"1689641220.0","comment_id":"954757","poster":"msdnpro","content":"Selected Answer: AD\nFor D : \"Amazon ElastiCache for Redis is highly suited as a session store to manage session information such as user authentication tokens, session state, and more.\"\nhttps://aws.amazon.com/elasticache/redis/"},{"content":"B and D: \"The application must store session data durably\" with Sticky sessions the application doesn't store anything.","upvote_count":"4","comments":[{"poster":"pentium75","content":"Why would sticky sessions stop applicaton from storing anything?","timestamp":"1704627360.0","comment_id":"1115772","upvote_count":"2"}],"timestamp":"1687215900.0","comment_id":"928013","poster":"mattcl"},{"comment_id":"921805","poster":"Axeashes","comments":[{"poster":"pentium75","upvote_count":"2","content":"The opposite is true: \"ElastiCache is ideally suited as a front end for AWS services like Amazon RDS and DynamoDB, providing extremely low latency for high-performance applications and offloading some of the request volume while these services (!!!) provide long-lasting data durability.\"\n\nElastiCache can serve as a cache for DynamoDB and provide low latency while DynamoDB (!) provides durability.","timestamp":"1704627420.0","comment_id":"1115774"}],"content":"An option for data persistence for ElastiCache:\nhttps://aws.amazon.com/elasticache/faqs/#:~:text=Q%3A%20Does%20Amazon%20ElastiCache%20for%20Redis%20support%20Redis%20persistence%3F%0AAmazon%20ElastiCache%20for%20Redis%20doesn%E2%80%99t%20support%20the%20AOF%20(Append%20Only%20File)%20feature%20but%20you%20can%20achieve%20persistence%20by%20snapshotting%20your%20Redis%20data%20using%20the%20Backup%20and%20Restore%20feature.%20Please%20see%20here%20for%20details.","timestamp":"1686611940.0","upvote_count":"2"},{"upvote_count":"4","timestamp":"1685600880.0","comment_id":"911800","poster":"dpaz","content":"Selected Answer: AB\nElastiCache is not durable so session info has to be stored in DynamoDB."},{"poster":"Alizade","content":"Selected Answer: AD\nA. Turn on the sticky sessions feature (session affinity) on the ALB.\nD. Deploy an Amazon ElastiCache for Redis cluster to store customer session information.","upvote_count":"1","comment_id":"884311","timestamp":"1682771220.0"},{"timestamp":"1681958520.0","comment_id":"875238","upvote_count":"4","content":"https://aws.amazon.com/es/caching/session-management/\nSticky sessions, also known as session affinity, allow you to route a site user to the particular web server that is managing that individual user’s session\nIn order to address scalability and to provide a shared data storage for sessions that can be accessible from any individual web server, you can abstract the HTTP sessions from the web servers themselves. A common solution to for this is to leverage an In-Memory Key/Value store such as Redis and Memcached.","poster":"Lalo"},{"poster":"pmd2023","comment_id":"872306","timestamp":"1681703280.0","upvote_count":"2","content":"Redis was not built to be a durable and consistent database. If you need a durable, Redis-compatible database, consider Amazon MemoryDB for Redis. Because MemoryDB uses a durable transactional log that stores data across multiple Availability Zones (AZs), you can use it as your primary database. MemoryDB is purpose-built to enable developers to use the Redis API without worrying about managing a separate cache, database, or the underlying infrastructure. https://aws.amazon.com/redis/"},{"poster":"maver144","comments":[{"upvote_count":"1","poster":"Fizbo","comments":[{"poster":"pentium75","comments":[{"poster":"jjcode","upvote_count":"3","timestamp":"1708488180.0","content":"Thats why you store it in dynamo DB, thats durable :)","comment_id":"1155222"}],"comment_id":"1110303","upvote_count":"2","content":"The link says NOTHING about data durability. It says that ElastiCache can help with SESSION durability but nothing else.","timestamp":"1704003300.0"}],"comment_id":"1073539","timestamp":"1700246220.0","content":"It can.\nhttps://aws.amazon.com/caching/session-management/"}],"content":"Selected Answer: AB\nElastiCache is cache it cannot store sessions durably","upvote_count":"8","timestamp":"1680618360.0","comment_id":"861167"},{"content":"Selected Answer: AD\noptimize customer session management during transactions. Since the session store will be during the transaction and we have another DB for pre/post transaction storage(Maria DB).","comment_id":"858941","timestamp":"1680447120.0","upvote_count":"1","poster":"kraken21"},{"poster":"test_devops_aws","content":"D is incorrect but dyamodb not support mariaDB. can someone explain?","timestamp":"1679423820.0","comments":[{"poster":"Keglic","upvote_count":"3","comment_id":"852059","content":"DynamoDB here is a new DB just for the purpose of storing session data... MariaDB is for eCommerce data.","timestamp":"1679917500.0"}],"comment_id":"846244","upvote_count":"1"},{"poster":"COTIT","comment_id":"842223","content":"Selected Answer: AB\nThe company wants to optimize customer session management during transactions -> \nA. Turn on the sticky sessions feature (session affinity) on the ALB.\nSticky sessions for your Application Load Balancer\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/sticky-sessions.html\n\nThe application must \"store\" session data \"durably\" not in memory.\nB. Use an Amazon DynamoDB table to store customer session information.","upvote_count":"5","comments":[{"poster":"kraken21","content":"\"optimize customer session management during transactions\":' During transactions' is the key here. DynamoDB will create another hop and increase latency.","timestamp":"1680447060.0","comment_id":"858936","upvote_count":"2"}],"timestamp":"1679078880.0"},{"upvote_count":"6","content":"Selected Answer: AB\nThe application must store session data durably : DynamoDB","poster":"Karlos99","comment_id":"837081","timestamp":"1678629540.0"},{"timestamp":"1678501560.0","poster":"[Removed]","upvote_count":"3","content":"Selected Answer: BD\nbdbdbdbdbd","comments":[{"comment_id":"837551","content":"care to explain?","timestamp":"1678674120.0","poster":"fkie4","upvote_count":"2"}],"comment_id":"835580"},{"comments":[{"content":"ElastiCache for Redis is HA but NOT durable.","timestamp":"1704627480.0","comment_id":"1115775","upvote_count":"2","poster":"pentium75"}],"upvote_count":"4","content":"Selected Answer: AD\nA. Turn on the sticky sessions feature (session affinity) on the ALB.\nD. Deploy an Amazon ElastiCache for Redis cluster to store customer session information.\n\nThe best solution for optimizing customer session management during transactions is to turn on the sticky sessions feature (session affinity) on the ALB to ensure that each client request is routed to the same web server in the Auto Scaling group. This will ensure that the customer session is maintained throughout the transaction.\n\nIn addition, the company should deploy an Amazon ElastiCache for Redis cluster to store customer session information durably. This will ensure that the customer session information is readily available and easily accessible during a transaction.","comment_id":"835410","timestamp":"1678480080.0","poster":"cegama543"},{"comment_id":"835409","poster":"cegama543","timestamp":"1678480020.0","upvote_count":"2","content":"Selected Answer: AD\nA company hosts a three-tier ecommerce application on a fleet of Amazon EC2 instances. The instances run in an Auto Scaling group behind an Application Load Balancer (ALB). All ecommerce data is stored in an Amazon RDS for MariaDB Multi-AZ DB instance.\n\nThe company wants to optimize customer session management during transactions. The application must store session data durably.\n\nWhich solutions will meet these requirements? (Choose two.)\n\nA. Turn on the sticky sessions feature (session affinity) on the ALB.\nB. Use an Amazon DynamoDB table to store customer session information.\nC. Deploy an Amazon Cognito user pool to manage user session information.\nD. Deploy an Amazon ElastiCache for Redis cluster to store customer session information.\nE. Use AWS Systems Manager Application Manager in the application to manage user session information."}]},{"id":"hKbSZGMEat3AYNfbECco","answer_ET":"C","question_id":345,"question_text":"A company needs a backup strategy for its three-tier stateless web application. The web application runs on Amazon EC2 instances in an Auto Scaling group with a dynamic scaling policy that is configured to respond to scaling events. The database tier runs on Amazon RDS for PostgreSQL. The web application does not require temporary local storage on the EC2 instances. The company’s recovery point objective (RPO) is 2 hours.\n\nThe backup strategy must maximize scalability and optimize resource utilization for this environment.\n\nWhich solution will meet these requirements?","choices":{"A":"Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances and database every 2 hours to meet the RPO.","D":"Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances every 2 hours. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.","C":"Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.","B":"Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO."},"question_images":[],"exam_id":31,"isMC":true,"timestamp":"2023-03-10 21:25:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/102212-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","answer":"C","answer_images":[],"answers_community":["C (88%)","10%"],"discussion":[{"comment_id":"842523","content":"Selected Answer: C\nthat if there is no temporary local storage on the EC2 instances, then snapshots of EBS volumes are not necessary. Therefore, if your application does not require temporary storage on EC2 instances, using AMIs to back up the web and application tiers is sufficient to restore the system after a failure.\n\nSnapshots of EBS volumes would be necessary if you want to back up the entire EC2 instance, including any applications and temporary data stored on the EBS volumes attached to the instances. When you take a snapshot of an EBS volume, it backs up the entire contents of that volume. This ensures that you can restore the entire EC2 instance to a specific point in time more quickly. However, if there is no temporary data stored on the EBS volumes, then snapshots of EBS volumes are not necessary.","upvote_count":"35","poster":"elearningtakai","comments":[{"poster":"MssP","timestamp":"1679818800.0","comments":[{"content":"Look at the first paragraph. https://repost.aws/knowledge-center/instance-store-vs-ebs","poster":"MssP","upvote_count":"2","comments":[{"timestamp":"1726112160.0","comment_id":"1282417","upvote_count":"2","poster":"MatAlves","content":"Considering it's a \"stateless web application\", that would still be no reason to back up the EBS volumes."}],"comment_id":"850831","timestamp":"1679819280.0"}],"comment_id":"850824","content":"I think \"temporal local storage\" refers to \"instance store\", no instance store is required. EBS is durable storage, not temporal.","upvote_count":"4"}],"timestamp":"1679121660.0"},{"poster":"CloudForFun","upvote_count":"14","comment_id":"840131","content":"Selected Answer: C\nThe web application does not require temporary local storage on the EC2 instances => No EBS snapshot is required, retaining the latest AMI is enough.","timestamp":"1678902840.0"},{"comment_id":"1093789","content":"Selected Answer: C\nThe web application does not require temporary local storage on the EC2 instances so we do not care about ECS.\nWe only need two things here , the image of the instance (AMI) and a database backup.\n\nC","poster":"Mikado211","upvote_count":"3","timestamp":"1702323840.0"},{"upvote_count":"2","poster":"TariqKipkemei","comment_id":"1051400","content":"Selected Answer: C\n\"The web application does not require temporary local storage on the EC2 instances\" rules out any option to back up the EC2 EBS volumes.","timestamp":"1698032340.0"},{"timestamp":"1690743300.0","upvote_count":"2","poster":"darekw","comment_id":"967430","content":"Question says: ...stateless web application.. that means application doesn't store any data, so no EBS required"},{"comment_id":"886384","upvote_count":"4","poster":"kruasan","timestamp":"1682951040.0","content":"Selected Answer: C\nSince the application has no local data on instances, AMIs alone can meet the RPO by restoring instances from the most recent AMI backup. When combined with automated RDS backups for the database, this provides a complete backup solution for this environment.\nThe other options involving EBS snapshots would be unnecessary given the stateless nature of the instances. AMIs provide all the backup needed for the app tier.\n\nThis uses native, automated AWS backup features that require minimal ongoing management:\n- AMI automated backups provide point-in-time recovery for the stateless app tier.\n- RDS automated backups provide point-in-time recovery for the database."},{"poster":"neosis91","content":"Selected Answer: B\nBBBBBBBBBB","comment_id":"876158","comments":[{"timestamp":"1704004320.0","upvote_count":"2","content":"Why back up EBS volumes of the autoscaled instances?","comment_id":"1110310","poster":"pentium75"}],"upvote_count":"1","timestamp":"1682046300.0"},{"content":"Selected Answer: D\nI vote for D","poster":"Rob1L","comments":[],"timestamp":"1679652000.0","upvote_count":"1","comment_id":"849183"},{"comment_id":"842381","upvote_count":"3","poster":"CapJackSparrow","timestamp":"1679099340.0","content":"Selected Answer: C\nmakes more sense."},{"content":"Selected Answer: C\nAnswer is C. Keyword to notice \"Stateless\"","upvote_count":"3","poster":"nileshlg","timestamp":"1679030700.0","comment_id":"841620"},{"comment_id":"839964","upvote_count":"4","poster":"cra2yk","timestamp":"1678890120.0","content":"Selected Answer: C\nwhy B? I mean \"stateless\" and \"does not require temporary local storage\" have indicate that we don't need to take snapshot for ec2 volume."},{"comments":[{"content":"Why back up EBS volumes of the autoscaled instances?\n\n\"Retaining the latest Amazon Machine Images (AMIs) of the web and application tiers (Option C) would provide only an image backup and not a data backup, which is required for the database tier.\" False because option C also includes \"automated backups in Amazon RDS\".","timestamp":"1704004380.0","upvote_count":"2","poster":"pentium75","comment_id":"1110312"}],"content":"Selected Answer: B\nOption B is the most appropriate solution for the given requirements.\n\nWith this solution, a snapshot lifecycle policy can be created to take Amazon Elastic Block Store (Amazon EBS) snapshots periodically, which will ensure that EC2 instances can be restored in the event of an outage. Additionally, automated backups can be enabled in Amazon RDS for PostgreSQL to take frequent backups of the database tier. This will help to minimize the RPO to 2 hours.\n\nTaking snapshots of Amazon EBS volumes of the EC2 instances and database every 2 hours (Option A) may not be cost-effective and efficient, as this approach would require taking regular backups of all the instances and volumes, regardless of whether any changes have occurred or not. Retaining the latest Amazon Machine Images (AMIs) of the web and application tiers (Option C) would provide only an image backup and not a data backup, which is required for the database tier. Taking snapshots of Amazon EBS volumes of the EC2 instances every 2 hours and enabling automated backups in Amazon RDS and using point-in-time recovery (Option D) would result in higher costs and may not be necessary to meet the RPO requirement of 2 hours.","timestamp":"1678528440.0","upvote_count":"4","comment_id":"835804","poster":"ktulu2602"},{"comment_id":"835407","upvote_count":"3","comments":[{"content":"No need to back up the EBS volumes of autoscaled instances.","timestamp":"1704004440.0","upvote_count":"3","comment_id":"1110314","poster":"pentium75"}],"content":"Selected Answer: B\nB. Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO.\n\nThe best solution is to configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots, and enable automated backups in Amazon RDS to meet the RPO. An RPO of 2 hours means that the company needs to ensure that the backup is taken every 2 hours to minimize data loss in case of a disaster. Using a snapshot lifecycle policy to take Amazon EBS snapshots will ensure that the web and application tier can be restored quickly and efficiently in case of a disaster. Additionally, enabling automated backups in Amazon RDS will ensure that the database tier can be restored quickly and efficiently in case of a disaster. This solution maximizes scalability and optimizes resource utilization because it uses automated backup solutions built into AWS.","timestamp":"1678479900.0","poster":"cegama543"}],"unix_timestamp":1678479900}],"exam":{"lastUpdated":"11 Apr 2025","id":31,"provider":"Amazon","name":"AWS Certified Solutions Architect - Associate SAA-C03","isMCOnly":true,"isImplemented":true,"numberOfQuestions":1019,"isBeta":false},"currentPage":69},"__N_SSP":true}