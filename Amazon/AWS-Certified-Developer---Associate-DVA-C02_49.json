{"pageProps":{"questions":[{"id":"FhxAMVJRBdpmImbNbYwb","answer_description":"","timestamp":"2024-02-18 12:17:00","question_id":241,"question_images":[],"discussion":[{"comment_id":"1153210","content":"Selected Answer: A\nAlways consider TTL when trying to ditch from DynamoDB.","timestamp":"1723972620.0","upvote_count":"7","poster":"tgv"},{"content":"Selected Answer: A\nTime To Live","poster":"vkovilam","upvote_count":"2","timestamp":"1733598840.0","comment_id":"1226289"},{"upvote_count":"2","comment_id":"1217646","timestamp":"1732468980.0","poster":"65703c1","content":"Selected Answer: A\nA is the correct answer."},{"content":"Selected Answer: A\nIt should be TTL enabled","comment_id":"1165314","poster":"KarBiswa","upvote_count":"2","timestamp":"1725419280.0"},{"content":"Selected Answer: A\nA is right","timestamp":"1724302020.0","upvote_count":"2","poster":"CrescentShared","comment_id":"1156184"}],"topic":"1","unix_timestamp":1708255020,"question_text":"A company built an online event platform. For each event, the company organizes quizzes and generates leaderboards that are based on the quiz scores. The company stores the leaderboard data in Amazon DynamoDB and retains the data for 30 days after an event is complete. The company then uses a scheduled job to delete the old leaderboard data.\n\nThe DynamoDB table is configured with a fixed write capacity. During the months when many events occur, the DynamoDB write API requests are throttled when the scheduled delete job runs.\n\nA developer must create a long-term solution that deletes the old leaderboard data and optimizes write throughput.\n\nWhich solution meets these requirements?","isMC":true,"answer_images":[],"answer_ET":"A","answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/134133-exam-aws-certified-developer-associate-dva-c02-topic-1/","exam_id":24,"choices":{"C":"Use AWS Step Functions to schedule and delete the leaderboard data.","A":"Configure a TTL attribute for the leaderboard data.","D":"Set a higher write capacity when the scheduled delete job runs.","B":"Use DynamoDB Streams to schedule and delete the leaderboard data."},"answers_community":["A (100%)"]},{"id":"RPfvpLXqGghvM4XtKwLd","answer":"D","answers_community":["D (88%)","8%"],"choices":{"C":"Configure Lambda event filtering to process two messages from Amazon SQS at every invocations.","D":"Configure a maximum concurrency of two on the Amazon SQS event source mapping for the Lambda function.","A":"Configure a provisioned concurrency of two on the Lambda function.","B":"Configure a batch size of two on the Amazon SQS event source mapping for the Lambda function."},"unix_timestamp":1708255080,"discussion":[{"upvote_count":"7","poster":"monishvster","comment_id":"1162086","timestamp":"1709166600.0","content":"Selected Answer: D\nShould be D. Source: https://aws.amazon.com/blogs/compute/introducing-maximum-concurrency-of-aws-lambda-functions-when-using-amazon-sqs-as-an-event-source/"},{"comment_id":"1183155","comments":[{"upvote_count":"2","timestamp":"1722050280.0","comment_id":"1255979","poster":"albert_kuo","content":"aws lambda create-event-source-mapping \\\n --function-name YourLambdaFunctionName \\\n --batch-size 2 \\\n --maximum-batching-window-in-seconds 5 \\\n --event-source-arn arn:aws:sqs:region:account-id:queue-name \\\n --maximum-concurrency 2"}],"poster":"DeaconStJohn","upvote_count":"5","content":"Selected Answer: D\nDidn't like the wording.\n\nA - provisioned concurrency keeps 2 functions on warm standby for critical work. this is a minimum. question is asking about a maximum of 2.\nB - Batch of 2 is fine. latency could see this fall flat on it's face though. lambda invocations between function and SQS are limited to 2, not strictly between lambda and vendor API.\nC - event filtering is completely irrelevant here.\nD - Maximum is what the question is asking for. this will limit the amount of requests made to the vendor API. I would much prefer to set the reserved concurrency at the lambda level but this can be overridden at the SQS event source mapping level so I guess this is the best answer.","timestamp":"1711444440.0"},{"timestamp":"1732237620.0","content":"Selected Answer: D\nSqs event source mapping","comment_id":"1316094","upvote_count":"1","poster":"ShakthiGCP"},{"comment_id":"1217647","upvote_count":"1","timestamp":"1716564540.0","content":"Selected Answer: D\nD is the correct answer.","poster":"65703c1"},{"timestamp":"1710000720.0","comment_id":"1169635","poster":"Abdullah22","upvote_count":"3","content":"Selected Answer: D\ngoing with D"},{"upvote_count":"2","content":"Selected Answer: A\nControlled Execution: Provisioned concurrency ensures that a minimum number of Lambda execution environments are always available. Setting it to two guarantees that only two Lambda function instances can process messages from the SQS queue concurrently.\nIndependent of Message Batch Size: Even if the SQS event source mapping delivers a batch of messages exceeding two, the provisioned concurrency limits the number of Lambda invocations happening simultaneously.","timestamp":"1709979300.0","comment_id":"1169402","poster":"SerialiDr"},{"comment_id":"1156186","content":"Selected Answer: B\nconfiguring a maximum concurrency of two on the SQS event source mapping, is not a valid option. The concept of maximum concurrency is not directly applicable to SQS event source mappings. Concurrency in the context of Lambda functions and SQS is controlled by the batch size and the function's reserved concurrency settings.","poster":"CrescentShared","upvote_count":"1","timestamp":"1708584660.0"},{"poster":"tgv","comment_id":"1153213","content":"Selected Answer: D\nCorrect answer is D. The maximum concurrency setting on the Amazon SQS event source mapping for the Lambda function controls how many messages are sent to the Lambda function concurrently. By setting it to two, you ensure that only two messages are processed concurrently, preventing the Lambda function from overwhelming the third-party API with more than two concurrent requests.","upvote_count":"5","timestamp":"1708255080.0"}],"answer_description":"","answer_images":[],"timestamp":"2024-02-18 12:18:00","url":"https://www.examtopics.com/discussions/amazon/view/134135-exam-aws-certified-developer-associate-dva-c02-topic-1/","exam_id":24,"answer_ET":"D","isMC":true,"question_id":242,"topic":"1","question_text":"A company uses an AWS Lambda function that reads messages from an Amazon Simple Queue Service (Amazon SQS) standard queue. The Lambda function makes an HTTP call to a third-party API for each message. The company wants to ensure that the Lambda function does not overwhelm the third-party API with more than two concurrent requests.\n\nWhich solution will meet these requirements?","question_images":[]},{"id":"g6mFFfrWBG6Zr4Oiygp6","choices":{"A":"Set up a mock integration request in API Gateway. Configure the method's integration request and integration response to associate a response with a given status code.","C":"Set up a gateway response for the API in API Gateway. Configure response headers with hardcoded HTTP status codes and responses.","B":"Set up the request validators in the API's OpenAPI definition file. Import the OpenAPI definitions into API Gateway to test the API.","D":"Set up a request parameter-based Lambda authorizer to control access to the API. Configure the Lambda function with the necessary mapping template."},"url":"https://www.examtopics.com/discussions/amazon/view/134136-exam-aws-certified-developer-associate-dva-c02-topic-1/","unix_timestamp":1708255200,"question_images":[],"answer_ET":"A","question_id":243,"exam_id":24,"answer_description":"","answer":"A","timestamp":"2024-02-18 12:20:00","question_text":"A company is using Amazon API Gateway to develop an API for its application on AWS. A developer needs to test and generate API responses. Other teams are required to test the API immediately.\n\nWhat should the developer do to meet these requirements?","discussion":[{"content":"Selected Answer: A\nThe mock integration should do it here","upvote_count":"9","poster":"tgv","timestamp":"1723972800.0","comment_id":"1153215"},{"timestamp":"1732469460.0","content":"Selected Answer: A\nA is the correct answer.","comment_id":"1217648","poster":"65703c1","upvote_count":"1"}],"answer_images":[],"isMC":true,"topic":"1","answers_community":["A (100%)"]},{"id":"Bl5eS2aprtfgzwYD3htQ","question_id":244,"topic":"1","choices":{"C":"Validation status","A":"Username","B":"Submission date","D":"Rating of the process on a scale of 1 to 5"},"url":"https://www.examtopics.com/discussions/amazon/view/134343-exam-aws-certified-developer-associate-dva-c02-topic-1/","timestamp":"2024-02-22 07:53:00","question_text":"A company is releasing a new feature. Users can request early access to the new feature by using an application form. The company expects a surge of requests when the application form becomes available. Each request will be stored as an item in an Amazon DynamoDB table.\n\nEach item will contain the user's username, the submission date, and a validation status of UNVALIDATED. VALID, or NOT VALID. Each item also will contain the user's rating of the process on a scale of 1 to 5.\n\nEach user can submit one request. For the DynamoDB table, the developer must choose a partition key that will give the workload well-distributed records across partitions.\n\nWhich DynamoDB attribute will meet these requirements?","answer_description":"","isMC":true,"answer_ET":"A","answer_images":[],"answers_community":["A (93%)","7%"],"discussion":[{"content":"Selected Answer: A\nIt's A of course. This question got me wondering, who choses default right answers here","poster":"Dzok5050","comment_id":"1215663","upvote_count":"5","timestamp":"1716373680.0"},{"timestamp":"1730693700.0","poster":"Saudis","content":"Selected Answer: A\npartition key should be Unique so the A is a best choice","comment_id":"1306766","upvote_count":"1"},{"comment_id":"1266269","poster":"Saurabh04","upvote_count":"1","timestamp":"1723704180.0","content":"Selected Answer: B\nThe submission date could be a good choice if it has high cardinality (many distinct values).\nHowever, if multiple requests occur simultaneously (e.g., during the surge), it might still lead to hot partitions"},{"poster":"65703c1","upvote_count":"2","content":"Selected Answer: A\nA is the correct answer.","comment_id":"1217649","timestamp":"1716564720.0"},{"timestamp":"1709529300.0","comment_id":"1165321","poster":"KarBiswa","upvote_count":"1","content":"Selected Answer: A\nUsername beyond doubt"},{"timestamp":"1709240880.0","comment_id":"1163020","poster":"nder","content":"Selected Answer: A\nUsername avoids a hot partition key","upvote_count":"3"},{"content":"Selected Answer: A\nrest is not even distributed.","upvote_count":"2","comment_id":"1156188","timestamp":"1708584780.0","poster":"CrescentShared"}],"exam_id":24,"unix_timestamp":1708584780,"answer":"A","question_images":[]},{"id":"NbVYF7EM6TduqkmndgbS","answers_community":["A (86%)","7%"],"answer":"A","question_images":[],"question_id":245,"isMC":true,"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/134344-exam-aws-certified-developer-associate-dva-c02-topic-1/","unix_timestamp":1708584840,"exam_id":24,"discussion":[{"comment_id":"1306767","upvote_count":"1","poster":"Saudis","content":"Selected Answer: A\nthe access to S3 Always by two ways OAC or OAI \nIn cloud front we access by OAC","timestamp":"1730693880.0"},{"comment_id":"1217652","upvote_count":"1","content":"Selected Answer: A\nA is the correct answer.","timestamp":"1716565140.0","poster":"65703c1"},{"upvote_count":"3","poster":"DeaconStJohn","timestamp":"1711444620.0","comment_id":"1183157","content":"Selected Answer: A\nThink back to every beginner cloud project you have completed/read about/ignored."},{"comments":[{"timestamp":"1710003480.0","upvote_count":"2","content":"changing to A. Origin access identity is now considered a legacy solution. The official AWS documentation now recommends that Origin Access Control is used instead.","poster":"Abdullah22","comment_id":"1169666"}],"content":"Selected Answer: B\nwhy not B","upvote_count":"1","timestamp":"1710003180.0","poster":"Abdullah22","comment_id":"1169664"},{"upvote_count":"4","comment_id":"1163027","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html","poster":"nder","timestamp":"1709241540.0"},{"poster":"monishvster","comments":[{"poster":"DeaconStJohn","upvote_count":"1","timestamp":"1711444740.0","comment_id":"1183159","content":"Option C requires public access to the bucket to be allowed.\n\n\"The users of this application must not be able to access the application content directly from an S3 bucket. All content must be served through the Amazon CloudFront distribution.\"\n\nOAC allows us to turn this feature off and still access the bucket contents via cloudfront."}],"content":"Selected Answer: C\nWe don't want to provide write access to CloudFront since it's a static website. S3 should suffice","timestamp":"1709166900.0","comment_id":"1162089","upvote_count":"1"},{"comment_id":"1156191","poster":"CrescentShared","timestamp":"1708584840.0","upvote_count":"3","content":"Selected Answer: A\nWhile enabling the block all public access setting in Amazon S3 is a good security practice and necessary for this scenario, simply allowing CloudFront \"write access\" is not relevant since the scenario involves serving static assets, not writing to the S3 bucket. This option also doesn't specify using an OAC or a similar method to ensure exclusive access through CloudFront."}],"choices":{"B":"Update the S3 bucket settings. Enable the block all public access setting in Amazon S3. Configure the CloudFront distribution's with Amazon S3 as the origin. Update the S3 bucket policy to allow CloudFront write access.","D":"Update the CloudFront distribution's origin to send a custom header. Update the S3 bucket policy with a condition by using the aws:RequestTag/tag-key key. Configure the tag-key as the custom header name, and the value being matched is the header's value.","A":"Create a new origin access control (OAC) in CloudFront. Configure the CloudFront distribution's origin to use the new OAC. Update the S3 bucket policy to allow CloudFront OAC with read and write access to access Amazon S3 as the origin.","C":"Update the S3 bucket's static website settings. Enable static website hosting and specifying index and error documents. Update the CloudFront origin to use the S3 bucket's website endpoint."},"answer_description":"","answer_images":[],"question_text":"A developer is creating a publicly accessible enterprise website consisting of only static assets. The developer is hosting the website in Amazon S3 and serving the website to users through an Amazon CloudFront distribution. The users of this application must not be able to access the application content directly from an S3 bucket. All content must be served through the Amazon CloudFront distribution.\n\nWhich solution will meet these requirements?","timestamp":"2024-02-22 07:54:00","topic":"1"}],"exam":{"isBeta":false,"isImplemented":true,"name":"AWS Certified Developer - Associate DVA-C02","lastUpdated":"11 Apr 2025","provider":"Amazon","numberOfQuestions":551,"isMCOnly":true,"id":24},"currentPage":49},"__N_SSP":true}