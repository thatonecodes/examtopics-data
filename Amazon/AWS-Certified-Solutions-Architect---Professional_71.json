{"pageProps":{"questions":[{"id":"WuEdfqMTNJxXTPcUOdjN","answer_ET":"B","question_images":[],"question_text":"In Amazon CloudWatch, you can publish your own metrics with the put-metric-data command. When you create a new metric using the put-metric-data command, it can take up to two minutes before you can retrieve statistics on the new metric using the get-metric-statistics command.\nHow long does it take before the new metric appears in the list of metrics retrieved using the list- metrics command?","unix_timestamp":1610066820,"answer":"B","answers_community":[],"exam_id":32,"discussion":[{"poster":"snegha","content":"When you create a metric, it can take up to 2 minutes before you can retrieve statistics for the new metric using the get-metric-statistics command. However, it can take up to 15 minutes before the new metric appears in the list of metrics retrieved using the list-metrics command.","upvote_count":"13","comment_id":"262234","timestamp":"1633728660.0"},{"timestamp":"1663314780.0","poster":"jujumomma","comment_id":"670589","content":"B\n\"After you create a metric, allow up to 15 minutes before the metric appears.\"\nhttps://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/list-metrics.html","upvote_count":"1"},{"timestamp":"1639051800.0","poster":"cldy","upvote_count":"1","content":"B. Up to 15 minutes","comment_id":"497698"},{"poster":"janvandermerwer","timestamp":"1635329400.0","content":"Note from AWS:\nWhen you create a metric, it can take up to 2 minutes before you can retrieve statistics for the new metric using the get-metric-statistics command. However, it can take up to 15 minutes before the new metric appears in the list of metrics retrieved using the list-metrics command. \nRef: \nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html","comment_id":"438711","upvote_count":"3"}],"url":"https://www.examtopics.com/discussions/amazon/view/41792-exam-aws-certified-solutions-architect-professional-topic-1/","question_id":351,"answer_images":[],"choices":{"C":"More than an hour","D":"Within a minute","A":"After 2 minutes","B":"Up to 15 minutes"},"topic":"1","timestamp":"2021-01-08 01:47:00","answer_description":"You can publish your own metrics to CloudWatch with the put-metric-data command (or its Query API equivalent PutMetricData). When you create a new metric using the put-metric-data command, it can take up to two minutes before you can retrieve statistics on the new metric using the get-metric-statistics command.\nHowever, it can take up to fifteen minutes before the new metric appears in the list of metrics retrieved using the list-metrics command.\nReference:\nhttp://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/publishingMetrics.html","isMC":true},{"id":"A40eT8cwqYAeOslGrFl2","answer_ET":"B","timestamp":"2019-09-09 14:18:00","answers_community":["B (100%)"],"question_text":"A company runs a legacy system on a single m4.2xlarge Amazon EC2 instance with Amazon EBS storage. The EC2 instance runs both the web server and a self- managed Oracle database. A snapshot is made of the EBS volume every 12 hours, and an AMI was created from the fully configured EC2 instance.\nA recent event that terminated the EC2 instance led to several hours of downtime. The application was successfully launched from the AMI, but the age of the\nEBS snapshot and the repair of the database resulted in the loss of 8 hours of data. The system was also down for 4 hours while the Systems Operators manually performed these processes.\nWhat architectural changes will minimize downtime and reduce the chance of lost data?","answer_images":[],"choices":{"A":"Create an Amazon CloudWatch alarm to automatically recover the instance. Create a script that will check and repair the database upon reboot. Subscribe the Operations team to the Amazon SNS message generated by the CloudWatch alarm.","B":"Run the application on m4.xlarge EC2 instances behind an Elastic Load Balancer/Application Load Balancer. Run the EC2 instances in an Auto Scaling group across multiple Availability Zones with a minimum instance count of two. Migrate the database to an Amazon RDS Oracle Multi-AZ DB instance.","C":"Run the application on m4.2xlarge EC2 instances behind an Elastic Load Balancer/Application Load Balancer. Run the EC2 instances in an Auto Scaling group across multiple Availability Zones with a minimum instance count of one. Migrate the database to an Amazon RDS Oracle Multi-AZ DB instance.","D":"Increase the web server instance count to two m4.xlarge instances and use Amazon Route 53 round-robin load balancing to spread the load. Enable Route 53 health checks on the web servers. Migrate the database to an Amazon RDS Oracle Multi-AZ DB instance."},"exam_id":32,"question_id":352,"isMC":true,"answer":"B","topic":"1","answer_description":"Reference:\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","unix_timestamp":1568031480,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/4942-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"comment_id":"31361","upvote_count":"32","comments":[{"comment_id":"69637","upvote_count":"9","timestamp":"1632834240.0","poster":"Smart","content":"Completely agree. Also, others selecting m4.2xL becoz of legacy system, remember we are offloading DB from that instance - most likely, there is no need for 2xL size."}],"poster":"LunchTime","timestamp":"1632630180.0","content":"B is correct.\nA: Does not address a loss of data since the last backup.\nB: Ensures that there are at least two EC instances, each of which is in a different AZ. It also ensures that the database spans multiple AZs. Hence this meets all the criteria.\nC: Having auto scaling set to a minimum instance count of one means that if there is just one instance and there is a problem, that instance will need to be restarted, meaning there would an outage during that restart time. As such, B is a better answer. \nD: Does not indicate that the two EC2 instances will be in different availability zones. If they are in the same AZ, that entire zone could theoretically have an outage. Given that, I would select B instead of D. Apart from that consideration D does the trick."},{"comments":[{"timestamp":"1632956400.0","poster":"JAWS1600","upvote_count":"4","content":"B wont work for Legacy. How do you know taht application can run on a smaller instance, for a legacy system. Legacy system are typically lift shift models.","comment_id":"100485"}],"upvote_count":"16","content":"B\nThere are 2 problems here. Firstly, the EBS snapshot is too old and secondly, the outage resulted in DB issues and data loss. Using 2 instances installed with the web server and using Route 53 load balancing should help with the first problem and RDS Multi-AZ DB would help in the second.\nA: This will not reduce the chances of lost data and downtime could still be significant and risky.\nB\\D: I chose this simply because of the LB\\Auto Scaling. While Route 53 can do similar function, it does not auto heal the instance to bring it back to healthy state.\nC: There is only 1 active instance, there should be at least 2.","comment_id":"13537","poster":"donathon","timestamp":"1632448560.0"},{"timestamp":"1656726120.0","poster":"jyrajan69","comment_id":"625896","upvote_count":"1","content":"Those who jumped on B are not considering the legacy app and the downtime, the app needs to be tested if you are downsizing the instance, yes its one instance, downtime will be the time it takes to respawn"},{"upvote_count":"1","content":"Selected Answer: B\nEnsures that there are at least two EC instances","poster":"pal40sg","timestamp":"1646360100.0","comment_id":"560476"},{"upvote_count":"1","comment_id":"514387","content":"B correct.","poster":"cldy","timestamp":"1641015540.0"},{"upvote_count":"5","timestamp":"1636293000.0","content":"The choice is clearly between B & C. I choose C for the following reasons-\n - You cannot downsize the EC2 instance m4.2xlarge to m4.xlarge and assume the legacy application will run fine. What if the legacy application requires minimum 32GB of memory to run or need minimum of 8 cores to run? You might break the legacy application if you downsize.\n - Similarly, you cannot assume that legacy application would work fine in an AutoScaling group. What about authentication, sessions and host of other adjustments you would need to make?\n - The question asks architectural changes to minimize downtime and reduce the chance of lost data and C accomplishes both - \n - It reduces downtime because the manual system operator's process would be automated with an AutoScaling Group. It will not be eliminated but minimized for sure.\n - It reduces the chance of losing data because the database is migrated to RDS.","comments":[{"content":"Nice explanation. Thanks.\nAgree with the rationale.","poster":"mnsait","comment_id":"1322873","timestamp":"1733507520.0","upvote_count":"1"}],"poster":"uninit","comment_id":"455032"},{"upvote_count":"1","content":"It's B","comment_id":"449840","poster":"andylogan","timestamp":"1636098480.0"},{"comments":[{"timestamp":"1635996480.0","poster":"01037","content":"I think we are looking for the best solution to meet requirements of the question.\nSo it should be B.","upvote_count":"2","comment_id":"384239"},{"comment_id":"410924","content":"For C , it will takes time to spin up a new instance after the single instance is unhealthy. \nBut for B, it only takes seconds for ALB to redirect to the other instance. Remember the goal of the questions is \"minimize downtime\"","timestamp":"1636009800.0","upvote_count":"2","poster":"tiffanny"}],"timestamp":"1635996000.0","comment_id":"352875","poster":"NarendraNK","content":"Should be C. We need to minimize the downtime, not looking to provide HA capability. \nAutoscaling with 1 minimum will ensure, a new instance will be launched if something goes wrong.","upvote_count":"3"},{"content":"I'll go with B","timestamp":"1635902520.0","upvote_count":"4","comment_id":"333949","poster":"WhyIronMan"},{"content":"I think B is correct.","comment_id":"290379","poster":"wind","timestamp":"1635851640.0","upvote_count":"2"},{"upvote_count":"3","comment_id":"289344","poster":"Kian1","timestamp":"1635813120.0","content":"going with B"},{"poster":"Ebi","timestamp":"1635750480.0","upvote_count":"3","content":"I go with B, the question is about HA, with two instances in two different AZd behind ALB it is achieved","comment_id":"281170"},{"poster":"Joaster","comment_id":"271928","timestamp":"1635725820.0","upvote_count":"2","content":"I would say B.Ensures that there are at least two EC instances, each of which is in a different AZ. It also ensures that the database spans multiple AZs. Hence this meets all the criteria."},{"content":"C looks better.. as option B and D are trying to run smaller instance for Legacy application. Legacy application doesnt support cluster because of session handling. SO C is not best option as it involve some downtime due to cooldown period but there will no data loss (which is the key) and this is best amongst given options.","timestamp":"1635703500.0","poster":"vipgcp","upvote_count":"4","comment_id":"253784"},{"content":"BBBBBBBBBBBBBBBBBBB","poster":"sarofi","timestamp":"1635646620.0","upvote_count":"2","comment_id":"252309"},{"upvote_count":"3","content":"The answer should be B.\nThe reasons are:\n1) For minimum downtime -- Run the EC2 instances in an Auto Scaling group across multiple Availability Zones with a minimum instance count of two; \n2) For avoiding loss of data -- Migrate the database to an Amazon RDS Oracle Multi-AZ DB instance.","comment_id":"246931","poster":"MichaelHuang","timestamp":"1635613320.0"},{"timestamp":"1635573060.0","content":"B. Data loss is addressed with Oracle Multi AZ RDZ. Downtime minimized with ALB+ ASG of MINIMUM 2. \n\nC is having minimum of 1. D is not having ASG and inability to respawn instances.","comment_id":"244562","upvote_count":"2","poster":"happpieee"},{"poster":"T14102020","content":"I think B is correct","upvote_count":"1","comment_id":"241824","timestamp":"1635420000.0"},{"poster":"lydia_young","timestamp":"1635228360.0","upvote_count":"2","comment_id":"231958","content":"B agree"},{"timestamp":"1635124860.0","upvote_count":"1","poster":"petebear55","comment_id":"231213","content":"B ... LOOK FOR CLUES SUCH AS autoscaling MENTIONED HERE as that will help avoid loss etc"},{"timestamp":"1635031380.0","comment_id":"228019","poster":"Sapens","content":"I'll go with B","upvote_count":"2"},{"poster":"jackdryan","upvote_count":"3","timestamp":"1635025440.0","content":"I'll go with B","comment_id":"227185"},{"content":"Here is one more thought from my perspective. It is reasonable to presume that why originally the instance has to be 2xlarge is because two applications (Web and DB) are running together. Essentially, the compute resource is more occupied by DB instead of Web. As a result, Option #B is better than #C due to DB will be migrated to RDS (some of the workloads will be offloaded accordingly).","timestamp":"1634980200.0","upvote_count":"3","poster":"TerrenceC","comment_id":"226731"},{"comment_id":"220892","upvote_count":"3","content":"It's a legacy system and we don't know if the application runs correctly with m4xlarge instances. \nThus the better option is C, because we will have an ASG and we can scale as needed.","timestamp":"1634918460.0","poster":"kj07"},{"upvote_count":"3","poster":"Bulti","timestamp":"1634817240.0","comment_id":"206791","content":"The best answer is B and the next best is C. B because of high availability and due to the assumption that the application without the database can run effectively on m4xlarge which has 1/2 the capacity of m42xlarge.\n\nC would also work bit it will not be a highly available solution as there is only one instance of the application at minimum."},{"poster":"Ganfeng","timestamp":"1634602800.0","content":"I would go to C as the we can not assume the legacy system worka on the m4.xlarge","upvote_count":"3","comment_id":"174400"},{"poster":"bossgandy","timestamp":"1634565240.0","content":"The answer is 'D' because no other options mention health checks because the problem we are trying to solve is that the app went down without notice.","comment_id":"173426","upvote_count":"2","comments":[{"comment_id":"451880","poster":"kirrim","upvote_count":"1","timestamp":"1636272540.0","content":"The ELB/ALB approach will have health checks on by default. The default health check will be the EC2 status of the instance, only. Nothing fancy, but it will know it the EC2 instance is reporting as unhealthy, at the very least.\n\nIn addition, D has another problem with relying solely on DNS for the failover. If the web client's DNS provider (or the web client OS itself) caches DNS responses and doesn't respect the TTL of your A record to properly age out the cached entry, then the client might not failover to the new IP address, because their provider could continue to reference its cached DNS entry pointing to the failed instance."}]},{"comment_id":"170901","poster":"Neive","upvote_count":"2","content":"C is the correct answer.","timestamp":"1634560260.0"},{"timestamp":"1634493840.0","upvote_count":"2","poster":"uyungdong","comment_id":"156296","content":"Go with D. What application means for option B and C? Both web server and db server, right? Imho"},{"content":"B is correct, \"no minimize cost\", and not all legacy system does not support more than one instance concurrently, ELB and autoscaling is a better choice compare to Route 53 with 2 instance as the situation here stated that the application is able to configuration and baked as AMI. (Conclusion: application is able run concurrently and support provision through readily AMI.)","timestamp":"1634472300.0","upvote_count":"1","poster":"fullaws","comment_id":"148383"},{"upvote_count":"2","poster":"Anila_Dhharisi","comment_id":"137698","timestamp":"1633881240.0","content":"C is best as they're available in each AZ & no need to downgrade the machines."},{"timestamp":"1633873080.0","content":"C more likely. legacy system may not run on multiple instances or on downgraded specs\nquestion is about minimizing downtime not eliminating","comment_id":"134074","upvote_count":"4","poster":"NikkyDicky"},{"poster":"noisonnoiton","upvote_count":"1","comments":[{"upvote_count":"2","poster":"noisonnoiton","comment_id":"143143","content":"C acceptable,,,","timestamp":"1634003220.0"}],"comment_id":"133504","content":"go with B","timestamp":"1633710180.0"},{"upvote_count":"2","content":"answer : B","poster":"mat2020","comment_id":"133266","timestamp":"1633702080.0"},{"content":"B. recommended AWS HA and reliability architecture","timestamp":"1633560000.0","upvote_count":"1","comment_id":"124873","poster":"ar2000"},{"comment_id":"101873","poster":"meenu2225","upvote_count":"1","comments":[{"content":"Answer: B \nThe cost of the compute of a m4.xlarge is half the price of an m4.2xlarge. Thus the costs are effectively the same, minus storage, which will be minimal for a legacy web app. The compute capacity the same, plus now the load is split across two AZs providing better resilience, availability.\nUltimately the question does not mention cost.","poster":"inf","comment_id":"130480","upvote_count":"2","timestamp":"1633573740.0"}],"content":"I will go with C. \nB & C could both be the solution, but I won't just downgrade the EC2 type for a legacy application. Moreover, minimum of 1 instances in ASG means it is cheaper thn Option B.","timestamp":"1633030860.0"},{"comment_id":"100483","upvote_count":"2","content":"Finally I re-read the question. The clue is \"minimize the downtime\" .\nC fits better than B in that case. Because if we inmplement option B and one of teh instance goes down ( m4xl). system may experience degradation/downtime, due to insufficient capacity of CPU/MEM resources.\nOn the other hand C should not have that issue. I\nSince Cost is not teh limit. I would go with C","comments":[{"poster":"jay1ram2","content":"C is a more expensive option. D is a good option since it is simpler. However, given that the application is legacy and may involve session managements which route53 does not support (i.e. sticky sessions).","timestamp":"1633190400.0","comments":[{"comment_id":"110405","content":"The right answer is B as it is the most cost effective and resilient option.","timestamp":"1633243080.0","poster":"jay1ram2","upvote_count":"1"}],"comment_id":"110404","upvote_count":"2"},{"timestamp":"1633371780.0","upvote_count":"3","comment_id":"116616","content":"I believe you are overlooking that in C, the minimum instance count is set to 1. That means if that instance has to be restarted, downtime will be guaranteed during the restart process. B avoids that issue and is therefore the best answer.","poster":"LunchTime"},{"timestamp":"1633529940.0","comment_id":"120112","content":"We need a chrome plugin to basically hide all of this dudes comments! my god","poster":"wlc90210","upvote_count":"6"}],"timestamp":"1632933900.0","poster":"JAWS1600"},{"comment_id":"100482","content":"C looks an overkill as compared to B, with m4.2xl, and autoscaler minimum instance count to 1. ( max and desired could be set - unknown) . So technically application can run across 2 m4.2xl with over capacity.\nIn B. we have split the instance in half ( m4.xl) , but two instance running in parallel. Chance is that application may not perform well on a smaller instance if memory requirement is more than what m4.xl provide. . B may not be the best option in that case. \nB and C are two close choice, both could work. I guess some more clue in question could have helped","upvote_count":"1","poster":"JAWS1600","timestamp":"1632881460.0"},{"content":"B.\nD is Incorrect - There is single AZ for both instances","poster":"JAWS1600","comment_id":"100479","timestamp":"1632837360.0","upvote_count":"2"},{"timestamp":"1632816300.0","poster":"amog","upvote_count":"2","comment_id":"44718","content":"Answer is B"},{"poster":"JayK","upvote_count":"5","comments":[{"poster":"JHtest","timestamp":"1632590880.0","comment_id":"30511","upvote_count":"2","content":"Same here. Since it's legacy system, it usually means not support to scalable architecture. D is not a best practice though."},{"comment_id":"101909","upvote_count":"1","poster":"aduda","content":"If the minimum instance count = 1, then you won't have High Availability and the ASG wouldn't use another AZ to create another instance.","comments":[{"timestamp":"1634648280.0","poster":"maximoh","upvote_count":"1","comment_id":"184342","content":"ASG will deploy a new instance in the surviving AZ, you cannot do any better with a legacy application."}],"timestamp":"1633102260.0"}],"timestamp":"1632567720.0","comment_id":"29863","content":"I will go with C, as its is not metioned that the current instance size is not utilized properly, so, no need to downgrade the size. also, there should be one always up and running with the minimum count = 1."},{"content":"For me answer is B.\n\nThe question is : \"What architectural changes will minimize downtime and reduce the chance of lost data?\"\nIt is not indicated the least expensive or the fastest to set up.\n\nThe others solutions doesn't can be help us to reduce the downtime vs B.\nD can be a good solution but I think round-robin isn't a configuration available into Route53 (https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html)","comments":[{"comment_id":"236889","poster":"MANIKANDANS","content":". Does Amazon Route 53 support Weighted Round Robin (WRR)?\n\nYes. Weighted Round Robin allows you to assign weights to resource record sets in order to specify the frequency with which different responses are served. You may want to use this capability to do A/B testing, sending a small portion of traffic to a server on which you’ve made a software change. For instance, suppose you have two record sets associated with one DNS name—one with weight 3 and one with weight 1. In this case, 75% of the time Route 53 will return the record set with weight 3 and 25% of the time Route 53 will return the record set with weight 1. Weights can be any number between 0 and 255.","upvote_count":"1","timestamp":"1635415260.0"}],"comment_id":"24398","upvote_count":"4","timestamp":"1632543540.0","poster":"2g"},{"timestamp":"1632535200.0","poster":"Rockeye","comment_id":"24216","upvote_count":"2","content":"I will pick B as the correct answer."},{"poster":"manhmaluc","timestamp":"1632508440.0","content":"I think the answer should be B due to Route 53 can't re-run new instance when fail","upvote_count":"3","comment_id":"13933"},{"content":"As it is Legacy system , the answer would be D","poster":"SivaG","timestamp":"1632363180.0","comment_id":"12633","upvote_count":"2"},{"timestamp":"1632169920.0","poster":"DalianYifang","upvote_count":"7","comment_id":"10276","comments":[{"poster":"dpvnme","timestamp":"1632181680.0","comments":[{"poster":"AMKazi","content":"C also has ELB","timestamp":"1644018720.0","upvote_count":"1","comment_id":"540702"}],"content":"I would go with B here because of ELB.","comment_id":"11210","upvote_count":"9"},{"timestamp":"1634401740.0","poster":"MultiAZ","comment_id":"144236","content":"Two reasons. First, question is about preventing data loss, not downtime. Second, you cannot know if the legacy app can run active/active on 2 instances - what about session management or 1000 other things that can go wrong\nC addresses the data loss in most cost-efficient manner of all the given answers (although it can get even better)","upvote_count":"1"}],"content":"Any comments on why B is incorrect? Downgarde instance type from m4.2xlarge to m4.xlarge?"}]},{"id":"FueDCu4FVIbtFnKEVdpp","unix_timestamp":1569991920,"isMC":true,"topic":"1","choices":{"C":"Use Spot Instances for the web and application tiers, and Reserved Instances for the database tier.","B":"Use On-Demand Instances for the web and application tiers, and Reserved Instances for the database tier.","D":"Use Reserved Instances for the web, application, and database tiers.","A":"Use Spot Instances for the web tier, On-Demand Instances for the application tier, and Reserved Instances for the database tier."},"question_images":[],"answer_ET":"B","answer_images":[],"answers_community":["B (100%)"],"answer_description":"","discussion":[{"timestamp":"1632616020.0","content":"B\nA\\C: You cannot use spot instances if not the application will go down.\nD: You should not use reserved instances as you are going to shutdown the instance after 6 months.","comment_id":"14081","poster":"donathon","upvote_count":"28"},{"content":"Selected Answer: B\nB. Use On-Demand Instances for the web and application tiers, and Reserved Instances for the database tier.\nBecause in six mounth remove EC2 server and use lambdas and API GateWay , only mantain Database tier","timestamp":"1686953220.0","upvote_count":"1","poster":"SkyZeroZx","comment_id":"925581"},{"upvote_count":"2","comment_id":"662314","poster":"nano2nd","content":"if you sold the web and app tier RI's after 6 months wouldn't that make D the MOST cost effective?","timestamp":"1662543900.0"},{"timestamp":"1662106080.0","comment_id":"657161","poster":"Network_1","content":"B is the correct option. In 6 months, Web and application tiers would be replaced with API Gateway and lambda respectively. Only DB tier would still be maintained","upvote_count":"3"},{"poster":"cldy","upvote_count":"1","content":"B. Use On-Demand Instances for the web and application tiers, and Reserved Instances for the database tier.","timestamp":"1639138860.0","comment_id":"498605"},{"timestamp":"1636261020.0","poster":"andylogan","comment_id":"449841","content":"It's B","upvote_count":"2"},{"content":"Correct Answer is B \nAverage discount for 1 year for reserved vs on demand is 40%. so for 6 month on demand should be preferred option","poster":"sergza","timestamp":"1636253460.0","comment_id":"449643","upvote_count":"2"},{"timestamp":"1636250280.0","comment_id":"428886","upvote_count":"1","content":"B, using spot instances are for jobs that are easily reproducible. Reserved instances for web and app wont work because its a minimum of a year, and they want to change this in 6 months.","poster":"AWS_Noob"},{"timestamp":"1636219020.0","comment_id":"347258","upvote_count":"1","content":"The correct Answer is B","poster":"macshild"},{"timestamp":"1636076160.0","content":"I'll go with B","upvote_count":"2","comment_id":"334004","poster":"WhyIronMan"},{"comment_id":"290381","upvote_count":"2","timestamp":"1635881460.0","poster":"wind","content":"B is correct."},{"timestamp":"1635785280.0","upvote_count":"2","content":"Ans B on demand reliable, reserved cost effective","poster":"Kian1","comment_id":"289347"},{"timestamp":"1635783600.0","content":"D cannot be the correct answer, with RI you can save more than 50% only for 3-year term.\nWith 1-year term saving is always less than 50%, so does not make sense to buy RI for pieces that you are going to remove in 6 months","upvote_count":"2","comment_id":"281174","poster":"Ebi"},{"comment_id":"280785","timestamp":"1635637080.0","poster":"certainly","upvote_count":"2","content":"agree B is winner for me"},{"content":"The correct answer is B. The keyword is within 6 months. If the app is deployed in less than 6 months time, it is definitely cheaper to use on-demand instance rather than RI.","timestamp":"1635591180.0","upvote_count":"2","comment_id":"245318","poster":"ju0n"},{"poster":"gookseang","timestamp":"1635443340.0","content":"I will go B","comment_id":"242226","upvote_count":"2"},{"upvote_count":"2","timestamp":"1635308640.0","comment_id":"241829","content":"B is the correct answer.","poster":"T14102020"},{"timestamp":"1634806680.0","content":"B : Front end will not exist in 6 months ... the database will so b as it can benefit from reserved instances..","upvote_count":"2","poster":"petebear55","comment_id":"231226"},{"content":"I'll go with B","poster":"jackdryan","upvote_count":"3","comment_id":"227179","timestamp":"1634734860.0"},{"comment_id":"227069","poster":"JK2","upvote_count":"2","content":"B is the correct answer.","timestamp":"1634720040.0"},{"poster":"petebear55","comment_id":"220285","timestamp":"1634581620.0","content":"B ... Given that reserved instances are for a minimum of one or maximum of 3 years then d is not appropriate here ... difficult question though ... typical of the shitty way AWS certifications like to persecute people just trying to better themselves !!!","upvote_count":"2"},{"poster":"Bulti","upvote_count":"2","comment_id":"206798","timestamp":"1634440200.0","content":"Answer is B it's more cost effective than D."},{"comment_id":"202510","poster":"Ivandrago","comments":[{"upvote_count":"1","content":"Answer should be D. As with aws you consolidate as much as possible. And the question said the app would the deployed within 6 months and to me it means it will be running in 6 months","timestamp":"1635981660.0","comment_id":"306436","poster":"ramseycon"}],"content":"A--> Spot Instances Not Reliable Reject\nB--> On Demand & RI for DB (--> Reliable but costly --> Good Candidate\nC --> Spot Instance --> Not Reliable --> Reject\nD--> RI --> Reliable & cost effective --> Prefered \n\nAnswer : D","upvote_count":"3","timestamp":"1634270640.0"},{"comment_id":"170905","upvote_count":"3","timestamp":"1634195280.0","content":"The Answer is definitely B. \nThey are not residing the database tier. So Reserve Instance for DB for 1-3 years is good choice. Once they implement the web&app tier with API and Lambda after 6 months, they can terminate the on demand Ec2 instances used for for web&app.","poster":"Neive"},{"timestamp":"1634076420.0","poster":"uyungdong","comment_id":"156312","content":"Absolutely B, for maintaining realibility you should use on demand for web n app. For db side should stick with RI for long term use.","upvote_count":"3"},{"timestamp":"1633764060.0","comment_id":"148385","content":"B is correct, refer to inf answer (save 60%), which mean use RI if you want to use more than 7.2 months","upvote_count":"1","poster":"fullaws"},{"poster":"learner4ever","timestamp":"1633667520.0","content":"D. Those who all misread the question, they didn't say that they will shutdown the app after 6 months. They want to launch it with in 6 months.","comment_id":"143327","upvote_count":"3"},{"content":"Ans should be B, \n- As the requirement states most-cost effective solution while maintaining reliability. \n- Options A & C uses spot instances which is not reliable\n- Option D is not cost-effective comparing with option B","poster":"shputhan","upvote_count":"2","timestamp":"1633532460.0","comment_id":"141028"},{"comment_id":"134076","content":"B for sure","timestamp":"1633365720.0","poster":"NikkyDicky","upvote_count":"1"},{"comment_id":"133505","poster":"noisonnoiton","timestamp":"1633360020.0","content":"go with B","upvote_count":"1"},{"comment_id":"133265","content":"ANSWER: b","timestamp":"1633282140.0","upvote_count":"1","poster":"mat2020"},{"content":"Answer: B\nNNHAN is almost correct saying D is the right answer, except the average savings is 40% over an on-demand instance for a 1 year period (eg 60% the cost). If you purchased an on-demand EC2 instance running 24/7 at effectively $100 for 6 months, an equivalent 1yr reserved instance at 60% would cost you $120 (60% of $200)","poster":"inf","upvote_count":"3","comment_id":"125620","timestamp":"1633209780.0"},{"content":"Answer is D\nSave money even 6 months.","timestamp":"1633081080.0","poster":"NNHAN","comments":[{"timestamp":"1633186380.0","content":"https://www.prosperops.com/blog/know-your-ri-break-even-point/\ndoesn't seem like it","poster":"ayhoung","upvote_count":"2","comment_id":"99074"},{"comment_id":"107243","content":"You cant have RI for 6 months. RI for DB is OK, because new infra ( PIG and Lambda) will still need the DB.","poster":"JAWS1600","timestamp":"1633201140.0","upvote_count":"1"}],"upvote_count":"1","comment_id":"96876"},{"content":"The Right Answer is B,\nRDS will be permanent hence, use Reserved instance\nWEB app will just stay for 6 months, and you can't purchase reserved instance for 6 months only.","timestamp":"1632918060.0","upvote_count":"3","poster":"AShahine21","comment_id":"95252"},{"content":"Why some people are prefering B\nIf the D problem is the RI period between 1 and 3 years, then you are facing the same problem with B","poster":"Ibranthovic","comment_id":"93132","upvote_count":"1","timestamp":"1632789180.0","comments":[{"upvote_count":"3","comment_id":"154439","content":"It's only the web & App tiers being redesigned, so it makes sense to run these as On demand as they will be gone after 6 months. The DB tier will remain and so using RI's makes sense.","timestamp":"1633913100.0","poster":"Stec1980"}]},{"comments":[{"content":"There's big differences. New infra ( PIG and Lambda) will still need the DB. Web and application will be terminate.","upvote_count":"2","comment_id":"148973","timestamp":"1633864500.0","poster":"AICOO"}],"comment_id":"82876","poster":"bertman","content":"Pretty certain is D : there is no difference between EC2 / RDS as regards what reserved offers i.e. payment for 1 or 3 year term with approx. 70% max discount. So you would benefit even for running only 6 months … Plus projects never run on schedule anyway :-)","upvote_count":"1","timestamp":"1632770820.0"},{"content":"D - aren't you using the servers for more than 1200 hours which would benefit from reserved instance pricing?","comment_id":"80031","upvote_count":"1","timestamp":"1632732360.0","poster":"palomino","comments":[{"content":"B - reserved instances are purchased for 1 or 3 years - this is for 6 months","timestamp":"1632776340.0","comment_id":"84758","upvote_count":"3","poster":"palomino"}]},{"content":"I agree for B","poster":"2g","timestamp":"1632713880.0","upvote_count":"4","comment_id":"24399"},{"content":"Agreed that it should be B","timestamp":"1632709920.0","upvote_count":"4","comment_id":"19110","poster":"skywalker"},{"timestamp":"1632252360.0","poster":"donathon","content":"Sorry pasted wrongly","comment_id":"13536","upvote_count":"2"},{"timestamp":"1632112440.0","poster":"donathon","comment_id":"13535","upvote_count":"3","content":"B\nThere are 2 problems here. Firstly, the EBS snapshot is too old and secondly, the outage resulted in DB issues and data loss. Using 2 instances installed with the web server and using Route 53 load balancing should help with the first problem and RDS Multi-AZ DB would help in the second.\nA: This will not reduce the chances of lost data and downtime could still be significant and risky.\nB\\D: I chose this simply because of the LB\\Auto Scaling. While Route 53 can do similar function, it does not auto heal the instance to bring it back to healthy state.\nC: There is only 1 active instance, there should be at least 2."}],"question_id":353,"answer":"B","question_text":"A Solutions Architect is working with a company that operates a standard three-tier web application in AWS. The web and application tiers run on Amazon EC2 and the database tier runs on Amazon RDS. The company is redesigning the web and application tiers to use Amazon API Gateway and AWS Lambda, and the company intends to deploy the new application within 6 months. The IT Manager has asked the Solutions Architect to reduce costs in the interim.\nWhich solution will be MOST cost effective while maintaining reliability?","exam_id":32,"timestamp":"2019-10-02 06:52:00","url":"https://www.examtopics.com/discussions/amazon/view/5956-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"Xdug6O0D7GpS5O4ypZuV","answer_images":[],"isMC":true,"unix_timestamp":1573711680,"answer":"B","discussion":[{"timestamp":"1632691680.0","comments":[{"content":"I found the same Cloud G U R U\n \nJayendra Patil is wrong. B is the right answer","poster":"JAWS1600","comment_id":"105667","timestamp":"1634077260.0","upvote_count":"2"}],"content":"So i googled and found this on A nother Cloud G u r u site:\nB is the correct answer.\n\nThe key line of the question is - \"thousands of instances running in the VPC\" .\n\nOption C does not confirm that the incoming traffic is passed through the IDS/IPS before reaching the host, which is one of the primary feature/requirement of any IDS/IPS. THe traffic will need to pass through the IDS so that any vulnerability could be assessed. Moreover in Option C, you can not expect to manage thousands and thousands of Servers through host based routing.\n\nOption A is invalid as promiscuous mode is not supported in AWS.\n\nOption D does not meet the IPS requirement and moreover although it can perform IDS activities but again it is not a scalable solution.\n\nSO, OPTION B is the correct ANSWER.","upvote_count":"29","comment_id":"32857","poster":"ReggieR2"},{"upvote_count":"7","comments":[{"poster":"nitinz","comment_id":"314341","timestamp":"1635448680.0","upvote_count":"1","content":"D is correct answer. you can scale IDS/IPS depending on the volume."}],"timestamp":"1632125460.0","comment_id":"21431","content":"I will go for \"B\" as this is how IDS/IPS are being deploy.\n\n\"D\" not possible as this will create additional CPU workload which should be prevent.","poster":"skywalker"},{"upvote_count":"1","content":"D is the correct answer","timestamp":"1727270520.0","comment_id":"1289010","poster":"Chinta"},{"upvote_count":"1","content":"B. Create a second VPC and route all traffic from the primary application VPC through the second VPC where the scalable virtualized IDS/IPS platform resides.","poster":"amministrazione","comment_id":"1266368","timestamp":"1723717920.0"},{"content":"Its says within a VPC . So best option is D . configuring each host with an agent that collects and sends network traffic to a centralized IDS/IPS platform (option D) is the best approach for achieving scalable and effective intrusion detection and prevention in a VPC","comment_id":"1248386","poster":"Narendragpt","upvote_count":"1","timestamp":"1721050560.0"},{"content":"Configure each host with an agent that collects all network traffic and sends that traffic to the IDS/IPS platform for inspection.","comment_id":"1229736","timestamp":"1718271840.0","poster":"Bereket","upvote_count":"1"},{"poster":"Andy85","upvote_count":"1","content":"Answer: b","timestamp":"1691608380.0","comment_id":"976969"},{"content":"Selected Answer: B\nIt has to be 'B'","timestamp":"1691045580.0","upvote_count":"1","comment_id":"970825","poster":"autobahn"},{"content":"Selected Answer: B\nBy creating a second VPC and routing all traffic from the primary application VPC through the second VPC where the scalable virtualized IDS/IPS platform resides. By separating the IDS/IPS platform into its own VPC, you can control the network traffic flow and apply security measures effectively. This architecture allows for scalability by handling the traffic from the primary application VPC through the dedicated IDS/IPS VPC, where the virtualized IDS/IPS platform can analyze and monitor the traffic.","timestamp":"1684854780.0","comment_id":"905027","upvote_count":"1","poster":"Tarila79"},{"content":"Selected Answer: B\nB is correct","upvote_count":"1","timestamp":"1683267360.0","poster":"zmfly","comment_id":"889827"},{"content":"Selected Answer: B\nA. Not scalable \nB. Doable,\nC. Traffic reaches the hosts before IDS/IPS processing, IDS may be okay but not IPS\nD. The same issue as C, and scalability is not mentioned.\n\nSo my choice is C","upvote_count":"1","poster":"TigerInTheCloud","timestamp":"1670018700.0","comment_id":"734086"},{"timestamp":"1666090860.0","poster":"Snip","upvote_count":"1","comment_id":"698135","content":"Only B can be the right answer, IDS/IPS must analyze traffic BEFORE the traffic reach the instance"},{"poster":"skywalker","content":"B... \nSecurity Team need a clean room or network for IDS/IPS.. Seperate VPC is the answer","comment_id":"657901","timestamp":"1662160920.0","upvote_count":"2"},{"poster":"aandc","upvote_count":"1","comment_id":"626134","content":"B, Gateway Load Balancer is needed\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/gateway/getting-started.html","timestamp":"1656764760.0"},{"timestamp":"1656333120.0","content":"B.\nThere was a similar question and its answer was such as B.","poster":"[Removed]","comment_id":"623267","upvote_count":"1"},{"timestamp":"1649841060.0","comment_id":"585116","content":"Selected Answer: D\nThere's same question at official exam from AWS.","poster":"HellGate","upvote_count":"1"},{"upvote_count":"2","timestamp":"1648745880.0","comment_id":"579063","poster":"bkrish","comments":[{"timestamp":"1648746000.0","poster":"bkrish","comment_id":"579064","content":"Typo with the above option. It's B.","comments":[{"poster":"orwolfstein","content":"https://aws.amazon.com/elasticloadbalancing/gateway-load-balancer/\nAWS mentions this as a use case in the GLB webpage. this is definitely the correct approach","comment_id":"985646","timestamp":"1692520440.0","upvote_count":"1"}],"upvote_count":"2"}],"content":"D --> This architecture is better suited for HIPAA compliance customers where they make use of the Gateway Load balancer. CISCO NGFW integration with Gateway Load Balancer is a classic example for this type of scenario."},{"upvote_count":"1","content":"Selected Answer: D\nD. Configure each host with an agent that collects all network traffic and sends that traffic to the IDS/IPS platform for inspection.","timestamp":"1648573020.0","poster":"jj22222","comment_id":"577741"},{"timestamp":"1643823420.0","content":"Routing traffic from1 VPC to other is older method. I work in an organization and we use Agent based monitoring only. D seems correct.","upvote_count":"1","comment_id":"539036","poster":"cannottellname"},{"comment_id":"532317","poster":"shotty1","upvote_count":"1","timestamp":"1643133780.0","content":"Selected Answer: B\nB is correct imo"},{"upvote_count":"3","comment_id":"500000","content":"I honestly do not understand this question","poster":"KiraguJohn","timestamp":"1639312860.0"},{"upvote_count":"1","poster":"Shap","timestamp":"1636290360.0","content":"I will go for B.","comment_id":"423939"},{"timestamp":"1636230660.0","comment_id":"405773","content":"B Correct","upvote_count":"1","poster":"Akhil254"},{"content":"In 2021 we should be using AWS Network firewall","comment_id":"387406","poster":"Comoks","upvote_count":"1","timestamp":"1636108140.0"},{"upvote_count":"3","comment_id":"342277","content":"B\nIt sounds more like a Gateway Load Balancer introduced in Nov 2020. https://docs.aws.amazon.com/elasticloadbalancing/latest/gateway/getting-started.html#overview\nGateway Load Balancers enable you to deploy, scale, and manage virtual appliances, such as firewalls, intrusion detection and prevention systems, and deep packet inspection systems. It combines a transparent network gateway (that is, a single entry and exit point for all traffic) and distributes traffic while scaling your virtual appliances with the demand.","timestamp":"1635797100.0","poster":"DashL"},{"timestamp":"1635762300.0","upvote_count":"2","poster":"anandbabu","content":"D is correct","comment_id":"327949"},{"comment_id":"323185","timestamp":"1635649020.0","upvote_count":"1","content":"I'll go for B","poster":"01037"},{"poster":"Madwyn","content":"A. Wrong as sniffing is not supported.\nB. Wrong as the questions says in the deployed VPC, not to create a new one.\nC. Wrong, doesn't make sense, use route command?\nD. Correct, each host only can listen to its own traffic, using the agent is the way.","comment_id":"292913","upvote_count":"2","timestamp":"1635298080.0"},{"content":"B - create another VPC for IDS/IPS purpose\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/securing-egress-using-ids-ips-leveraging-transit-gateway/","upvote_count":"2","comments":[{"comment_id":"364505","poster":"01037","upvote_count":"1","timestamp":"1635893220.0","content":"Yes, exactly what the question is asking for."}],"timestamp":"1635186900.0","comment_id":"251151","poster":"liteup"},{"upvote_count":"1","timestamp":"1635176880.0","comment_id":"216135","poster":"dede59100","content":"Answer is D.\nReason: https://jayendrapatil.com/aws-intrusion-detection-prevention-idsips"},{"poster":"pianissiomo","upvote_count":"2","comment_id":"200855","timestamp":"1635051960.0","content":"D.\n\nConfigure each host with an agent that collects all network traffic and sends that traffic to the IDS/IPS platform for inspection.\n\nabove is complete sentence for this question"},{"content":"Answer is B","comment_id":"190066","upvote_count":"1","poster":"srknbngl","timestamp":"1634817360.0"},{"upvote_count":"1","comment_id":"189929","content":"The usual approach to this at scale is a separate peered VPC in a sandwich architecture. Answer B. D is valid but not at scale which was emphasised in the question","poster":"cpal012","timestamp":"1634558760.0"},{"comment_id":"189756","timestamp":"1634466180.0","content":"B is correct","poster":"un","upvote_count":"1"},{"poster":"ipindado2020","upvote_count":"1","content":"I go for D... \nFor B option I miss at least VPC peering enabled","comment_id":"182277","timestamp":"1634461440.0"},{"timestamp":"1634444640.0","content":"B sounds like AWS Whitepaper on security, however the text \"route all traffic *FROM* the primary application VPC through the second VPC\" is really the wrong way round. If you are implementing a 'choke-point IDS/IPS you'd route traffic *TO* the application through the ISD/IPS VPC. Given an IPS must be placed inline in order to drop packets B is really the only option, even if badly worded.","poster":"soksy","comment_id":"175008","upvote_count":"2"},{"poster":"kaush","content":"https://aws.amazon.com/blogs/networking-and-content-delivery/securing-egress-using-ids-ips-leveraging-transit-gateway/","timestamp":"1634432220.0","comment_id":"170474","upvote_count":"1"},{"timestamp":"1634318640.0","comment_id":"166194","content":"B definitely...","upvote_count":"1","poster":"GTI9982"},{"comment_id":"143147","upvote_count":"1","content":"B is correct","timestamp":"1634162400.0","poster":"fullaws"},{"timestamp":"1634140380.0","upvote_count":"1","comments":[{"comment_id":"207097","timestamp":"1635149520.0","poster":"cpal012","upvote_count":"1","content":"It does say to redirect from the primary to the secondary. It says to route the traffic to the primary through the secondary. In other words - hit the secondary first and then the primary","comments":[{"upvote_count":"1","content":"Sorry typo - I mean't to write that it doesnt say to redirect from the primary to the secondary","poster":"cpal012","timestamp":"1635154800.0","comment_id":"207099"}]}],"poster":"askAditya","content":"Answer should be D. B would not be considered as write as traffic redirected from primary to secondary, if traffic from secondary to Primary then answer should be ok as all filter to be applied at secondary VPC before redirecting to primary VPC","comment_id":"138987"},{"timestamp":"1634128440.0","comment_id":"122357","content":"go with B","upvote_count":"1","poster":"noisonnoiton"},{"upvote_count":"2","poster":"JAWS1600","content":"D\nhttps://jayendrapatil.com/aws-intrusion-detection-prevention-idsips/","timestamp":"1633688940.0","comment_id":"98548"},{"upvote_count":"1","poster":"Hypermasterd","content":"I would go for D, since I do not see how B could be done. \nhttps://jayendrapatil.com/aws-intrusion-detection-prevention-idsips/ comes to a similar conclusion, while also providing more details.","timestamp":"1633394820.0","comment_id":"92935","comments":[{"upvote_count":"1","comment_id":"364507","poster":"01037","content":"https://aws.amazon.com/blogs/networking-and-content-delivery/securing-egress-using-ids-ips-leveraging-transit-gateway/","timestamp":"1635986820.0"}]},{"content":"I mean , B sounds nice, but how would you actually route the traffic through a different VPC, where the IDS/IPS somewhere sits and then forwards the traffic to the actual destination.?","upvote_count":"1","timestamp":"1633254360.0","comment_id":"92933","comments":[{"content":"https://aws.amazon.com/blogs/networking-and-content-delivery/securing-egress-using-ids-ips-leveraging-transit-gateway/","timestamp":"1636072800.0","comment_id":"364508","upvote_count":"2","poster":"01037"}],"poster":"Hypermasterd"},{"content":"Option B is correct. This EXACT scenario is described in the DolfinEd course preparation for this CSA Professional exam (best course.. 53 hours, very detailed). Creating a Network/Security VPC that acts as a proxy is also design mentioned as a best practice and recommended by AWS in the white papers, and it's also mentioned on \"hub \n& spoke\" patterns (reinvent: https://youtu.be/3Gv47NASmU4?t=2127). Also, D is not desirable (no longer) because in IDS/IPS you don't want to get the traffic in the hosts so then you can analyze them (or collect with an agent), you want to \"Detect\" and \"Prevent\" it before. Make sure you understood option B correct: traffic from the internet enters thru the hardened (mentioned as \"second\" in the option) VPC, goes thru the IDS/IPS, then if approved, goes to the other VPC and finally to the application. Unfortunately, the way it was written might make you understand that it goes to the application VPC, then to the new one (second IDS/IPS) then back.... which is not the case.","comment_id":"83721","upvote_count":"4","poster":"GuentherSehn","timestamp":"1633246500.0"},{"timestamp":"1633159920.0","upvote_count":"2","content":"Correct answer: \"B\"","poster":"shahul_rahila_raisa","comment_id":"74158"},{"comment_id":"51323","upvote_count":"1","content":"D is correct! although the full text is not there. install IPS/IDS agent in the base image . so all new instance should be spun up of that base image.","timestamp":"1633092660.0","poster":"Gorha","comments":[{"upvote_count":"1","content":"the instances are already running and spun up...","timestamp":"1634213820.0","comments":[{"comment_id":"166192","content":"we are trying to protect an already deployed VPC with thousands of already running instances...","upvote_count":"2","poster":"GTI9982","timestamp":"1634309820.0"}],"poster":"GTI9982","comment_id":"166190"}]},{"content":"B is Correct","comment_id":"49613","upvote_count":"3","poster":"BillyC","timestamp":"1632788160.0"},{"comment_id":"36308","content":"Answer is B\nhttps://acloud.guru/forums/aws-certified-solutions-architect-associate/discussion/-KSModQtvq7YxmsCIPVS/question_for_aws_saa","upvote_count":"4","timestamp":"1632754380.0","poster":"AnNguyen"},{"timestamp":"1632722640.0","comment_id":"33647","content":"so it is B. I agree","poster":"Musk","upvote_count":"2"},{"upvote_count":"2","comment_id":"32853","content":"For me...and i am not 100% sure, its A. In order to scale, it requires making the least amount of changes at the highest level. With A you have one instance running the ENI. In C and D you have to touch each server which is not scaling as we know it. B is possible i am not sure that's a valid VPC configuration though. That would require additional layer 3 routing it seems.","timestamp":"1632555300.0","poster":"ReggieR2"},{"poster":"JayK","comment_id":"29468","upvote_count":"2","timestamp":"1632372420.0","content":"I will go with B,"},{"upvote_count":"5","timestamp":"1632354900.0","poster":"tan9","comments":[{"poster":"30th","timestamp":"1633198440.0","comment_id":"75924","comments":[{"upvote_count":"1","comment_id":"364503","poster":"01037","timestamp":"1635868920.0","content":"I don't think \"VPC Traffic Mirroring\" is the answer here.\nThough \"VPC Traffic Mirroring\" can do IDS, it can't do IPS."}],"content":"I suppose this questions is older than the traffic mirroring feature. The answer \"B\" implies the routing of the traffic \"through\" the second VPC. It is not the same as \"mirroring\". I would vote for \"D\".","upvote_count":"1"}],"comment_id":"27603","content":"I will go for \"B\", and AWS now has official support for the very same thing called \"VPC Traffic Mirroring\" ( https://aws.amazon.com/blogs/aws/new-vpc-traffic-mirroring/ )."},{"poster":"Danao","timestamp":"1632345780.0","upvote_count":"1","comments":[{"content":"my view 2nd VPC is not required, also this brings some configuration which may create scalability issues. scalable solution can be implemented in same VPC","timestamp":"1632479460.0","upvote_count":"1","poster":"sam422","comment_id":"30166"}],"content":"Why B is not scalable?","comment_id":"26091"},{"comment_id":"26090","upvote_count":"3","timestamp":"1632301620.0","poster":"Danao","content":"D is not possible for IPS"},{"poster":"Smartphone","upvote_count":"1","timestamp":"1632258900.0","content":"My answer is D.","comment_id":"24176"},{"upvote_count":"2","timestamp":"1632249960.0","content":"D is right. Option B is not scalable solution.","poster":"examacc","comment_id":"22903"}],"topic":"1","question_images":[],"answers_community":["B (71%)","D (29%)"],"exam_id":32,"question_id":354,"timestamp":"2019-11-14 07:08:00","answer_description":"","choices":{"B":"Create a second VPC and route all traffic from the primary application VPC through the second VPC where the scalable virtualized IDS/IPS platform resides.","A":"Configure an instance with monitoring software and the elastic network interface (ENI) set to promiscuous mode packet sniffing to see an traffic across the VPC.","D":"Configure each host with an agent that collects all network traffic and sends that traffic to the IDS/IPS platform for inspection.","C":"Configure servers running in the VPC using the host-based 'route' commands to send all traffic through the platform to a scalable virtualized IDS/IPS."},"question_text":"A web company is looking to implement an intrusion detection and prevention system into their deployed VPC. This platform should have the ability to scale to thousands of instances running inside of the VPC.\nHow should they architect their solution to achieve these goals?","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/8164-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"buwWXkEdLWQxAo0pvN5S","topic":"1","question_id":355,"isMC":true,"timestamp":"2021-03-17 19:29:00","discussion":[{"timestamp":"1635266100.0","poster":"cldy","comment_id":"323943","content":"A. \n1 a new CT trail + 1 new S3 bucket + global services option selected + IAM roles + bucket policies + MFA Delete.","upvote_count":"9"},{"comment_id":"1266493","content":"A. Create a new CloudTrail trail with one new S3 bucket to store the logs and with the global services option selected. Use IAM roles S3 bucket policies and Multi Factor Authentication (MFA) Delete on the S3 bucket that stores your logs.","timestamp":"1723731360.0","upvote_count":"1","poster":"amministrazione"},{"content":"Selected Answer: A\nA.\n1 a new CT trail + 1 new S3 bucket + global services option selected + IAM roles + bucket policies + MFA Delete.","upvote_count":"1","poster":"SkyZeroZx","timestamp":"1686365460.0","comment_id":"919749"},{"comment_id":"577863","poster":"jj22222","upvote_count":"1","content":"Selected Answer: A\nA. Create a new CloudTrail trail with one new S3 bucket to store the logs and with the global services option selected. Use IAM roles S3 bucket policies and Multi Factor Authentication (MFA) Delete on the S3 bucket that stores your logs.","timestamp":"1648587900.0"},{"content":"A Correct","timestamp":"1636032900.0","comment_id":"406199","poster":"Akhil254","upvote_count":"1"},{"comments":[{"comment_id":"418262","timestamp":"1636111860.0","poster":"blackgamer","content":"Yes, A is correct. Global services option is not needed to select when creates using AWS console, but it will need to set --is-multi-region-trail true to enable global services if you create from aws cli.","upvote_count":"1"},{"timestamp":"1664892480.0","comment_id":"686236","content":"\"Durability\" i think. In case of using a new region","poster":"wassb","upvote_count":"1"}],"comment_id":"344977","timestamp":"1635790680.0","poster":"01037","upvote_count":"2","content":"A.\nBut why is global services option needed.\nThere is only one region, isn't it?"},{"poster":"ExtHo","content":"A is correct one","comment_id":"313517","upvote_count":"4","timestamp":"1634573280.0"}],"unix_timestamp":1616005740,"exam_id":32,"answers_community":["A (100%)"],"answer_description":"","question_images":[],"answer":"A","answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/47575-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"B":"Create a new CloudTrail with one new S3 bucket to store the logs Configure SNS to send log file delivery notifications to your management system. Use IAM roles and S3 bucket policies on the S3 bucket mat stores your logs.","A":"Create a new CloudTrail trail with one new S3 bucket to store the logs and with the global services option selected. Use IAM roles S3 bucket policies and Multi Factor Authentication (MFA) Delete on the S3 bucket that stores your logs.","C":"Create a new CloudTrail trail with an existing S3 bucket to store the logs and with the global services option selected. Use S3 ACLs and Multi Factor Authentication (MFA). Delete on the S3 bucket that stores your logs.","D":"Create three new CloudTrail trails with three new S3 buckets to store the logs one for the AWS Management console, one for AWS SDKs and one for command line tools. Use IAM roles and S3 bucket policies on the S3 buckets that store your logs."},"question_text":"You currently operate a web application. In the AWS US-East region. The application runs on an auto-scaled layer of EC2 instances and an RDS Multi-AZ database. Your IT security compliance officer has tasked you to develop a reliable and durable logging solution to track changes made to your EC2.IAM And RDS resources. The solution must ensure the integrity and confidentiality of your log data.\nWhich of these solutions would you recommend?","answer_images":[]}],"exam":{"numberOfQuestions":1019,"isMCOnly":false,"id":32,"isImplemented":true,"lastUpdated":"11 Apr 2025","isBeta":false,"name":"AWS Certified Solutions Architect - Professional","provider":"Amazon"},"currentPage":71},"__N_SSP":true}