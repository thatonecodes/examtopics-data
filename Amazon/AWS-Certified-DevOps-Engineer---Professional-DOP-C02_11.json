{"pageProps":{"questions":[{"id":"TnOhMmmYOtybAyRONhwb","answer_ET":"B","topic":"1","question_id":51,"isMC":true,"discussion":[{"timestamp":"1723031760.0","upvote_count":"6","content":"Selected Answer: B\nB is correct: for unit test, we need codebuild \nA: codeguru is for code analysis, not unit test\nC: This option mentions pushing reports to CodeArtifact repository, which is incorrect\nD: This option push reports to S3, which is incorrect. We should upload report to codebuild report group","comment_id":"1143370","poster":"thanhnv142"},{"content":"Selected Answer: B\nB is correct","poster":"zain1258","timestamp":"1716902100.0","upvote_count":"3","comment_id":"1082681"},{"content":"I think B as per link:\nhttps://docs.aws.amazon.com/codebuild/latest/userguide/test-reporting.html","comment_id":"1081596","upvote_count":"3","timestamp":"1716810000.0","poster":"KobraKai"},{"poster":"tom_cat","comment_id":"1079503","content":"Selected Answer: B\nI think it should be B","upvote_count":"3","timestamp":"1716569580.0"},{"content":"Selected Answer: B\nB is corrected","comment_id":"1078234","poster":"vandergun","timestamp":"1716445800.0","upvote_count":"4"}],"answer_description":"","answer_images":[],"timestamp":"2023-11-23 09:30:00","exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/126990-exam-aws-certified-devops-engineer-professional-dop-c02/","answer":"B","question_text":"A company has an application that includes AWS Lambda functions. The Lambda functions run Python code that is stored in an AWS CodeCommit repository. The company has recently experienced failures in the production environment because of an error in the Python code. An engineer has written unit tests for the Lambda functions to help avoid releasing any future defects into the production environment.\n\nThe company's DevOps team needs to implement a solution to integrate the unit tests into an existing AWS CodePipeline pipeline. The solution must produce reports about the unit tests for the company to view.\n\nWhich solution will meet these requirements?","choices":{"C":"Create a new AWS CodeArtifact repository. Create a new AWS CodeBuild project. In the CodePipeline pipeline, configure a test stage that uses the new CodeBuild project. Create an appspec.yml file in the original CodeCommit repository. In the appspec.yml file, define the actions to run the unit tests with an output of CUCUMBERJSON in the build phase section. Configure the tests reports to be sent to the new CodeArtifact repository.","B":"Create a new AWS CodeBuild project. In the CodePipeline pipeline, configure a test stage that uses the new CodeBuild project. Create a CodeBuild report group. Create a buildspec.yml file in the CodeCommit repository. In the buildspec.yml file, define the actions to run the unit tests with an output of JUNITXML in the build phase section. Configure the test reports to be uploaded to the new CodeBuild report group.","A":"Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Create a new AWS CodeBuild project. In the CodePipeline pipeline, configure a test stage that uses the new CodeBuild project. Create a buildspec.yml file in the CodeCommit repository. In the buildspec yml file, define the actions to run a CodeGuru review.","D":"Create a new AWS CodeBuild project. In the CodePipeline pipeline, configure a test stage that uses the new CodeBuild project. Create a new Amazon S3 bucket. Create a buildspec.yml file in the CodeCommit repository. In the buildspec yml file, define the actions to run the unit tests with an output of HTML in the phases section. In the reports section, upload the test reports to the S3 bucket."},"answers_community":["B (100%)"],"unix_timestamp":1700728200,"question_images":[]},{"id":"8mMMCjV43XVLyPpehdot","question_text":"A company manages multiple AWS accounts in AWS Organizations. The companyâ€™s security policy states that AWS account root user credentials for member accounts must not be used. The company monitors access to the root user credentials.\n\nA recent alert shows that the root user in a member account launched an Amazon EC2 instance. A DevOps engineer must create an SCP at the organization's root level that will prevent the root user in member accounts from making any AWS service API calls.\n\nWhich SCP will meet these requirements?","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/127130-exam-aws-certified-devops-engineer-professional-dop-c02/","timestamp":"2023-11-24 20:00:00","question_images":[],"topic":"1","answer_images":[],"discussion":[{"poster":"tom_cat","content":"Selected Answer: C\nI believe it should be C\nhttps://docs.aws.amazon.com/organizations/latest/userguide/best-practices_member-acct.html#bp_member-acct_use-scp","timestamp":"1700852400.0","comment_id":"1079511","upvote_count":"8"},{"poster":"thanhnv142","content":"Selected Answer: C\nC is correct: < will prevent the root user in member accounts> this means deny action\nA and D: irrelevant (mention allow statement)\nB: scp does not have principal element. only condition","upvote_count":"7","comment_id":"1143377","timestamp":"1707314940.0"},{"content":"Selected Answer: C\nA slightly more consise version of \"C\" is a \"strongly recommended\" control to deny root access in member accounts. See the example:\nhttps://docs.aws.amazon.com/controltower/latest/controlreference/strongly-recommended-controls.html#disallow-root-auser-actions","upvote_count":"1","comment_id":"1237113","poster":"Gomer","timestamp":"1719354180.0"},{"timestamp":"1713888600.0","comment_id":"1200810","poster":"c3518fc","upvote_count":"1","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/organizations/latest/userguide/best-practices_member-acct.html#bp_member-acct_use-scp"},{"timestamp":"1710604380.0","poster":"DanShone","comment_id":"1175068","content":"Selected Answer: C\nC is correct","upvote_count":"1"},{"poster":"[Removed]","content":"Selected Answer: C\nC no debate","upvote_count":"2","comment_id":"1163118","timestamp":"1709252580.0"},{"comment_id":"1091497","poster":"manman7","timestamp":"1702108020.0","content":"It's C, based on the documentation :\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_general.html#example-scp-root-user","upvote_count":"4"},{"content":"Selected Answer: C\nC looks correct","upvote_count":"2","comment_id":"1082682","poster":"zain1258","timestamp":"1701184560.0"}],"answers_community":["C (100%)"],"unix_timestamp":1700852400,"answer_description":"","exam_id":23,"answer_ET":"C","question_id":52,"answer":"C","choices":{"D":"","C":"","B":"","A":""}},{"id":"EyqvigRoypU1T2Y2Ai8h","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/127013-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_images":[],"answer_description":"","question_text":"A company uses AWS and has a VPC that contains critical compute infrastructure with predictable traffic patterns. The company has configured VPC flow logs that are published to a log group in Amazon CloudWatch Logs.\n\nThe company's DevOps team needs to configure a monitoring solution for the VPC flow logs to identify anomalies in network traffic to the VPC over time. If the monitoring solution detects an anomaly, the company needs the ability to initiate a response to the anomaly.\n\nHow should the DevOps team configure the monitoring solution to meet these requirements?","unix_timestamp":1700742360,"timestamp":"2023-11-23 13:26:00","answers_community":["B (71%)","A (29%)"],"discussion":[{"content":"Selected Answer: B\nI think it's B, Amazon Lookout for metrics can detect anomalies from S3 bucket and trigger Lambda\nhttps://aws.amazon.com/lookout-for-metrics/","upvote_count":"7","comment_id":"1106313","timestamp":"1703618040.0","poster":"giovanna_mag"},{"timestamp":"1738975500.0","upvote_count":"1","comment_id":"1353168","poster":"ce0df07","content":"Selected Answer: A\nUsing KDA for anomaly detection, means you can use the built-in RCF (Random Cut Forest) ML algorithm. \nOption B: Firehose and S3 adds latency. Further, Amazon Lookout for Metrics is more suitable for business metrics than network traffic. \nOptions C&D require you to implement your own Lambda function, which means more error prone and more maintenance."},{"upvote_count":"1","comment_id":"1269349","poster":"[Removed]","content":"Selected Answer: B\nB for me","timestamp":"1724149740.0"},{"comment_id":"1260177","content":"Selected Answer: B\n- Data Streaming: Use Amazon Kinesis Data Firehose to deliver VPC flow logs from CloudWatch Logs to an Amazon S3 bucket.\n- Anomaly Detection: Amazon Lookout for Metrics will monitor the data in the S3 bucket and automatically detect anomalies in the network traffic.\n- Event Response: When Lookout for Metrics detects an anomaly, it triggers an AWS Lambda function. The Lambda function will then publish an event to the Amazon EventBridge event bus, which can further initiate automated responses, notifications, or alerts.","upvote_count":"4","poster":"jamesf","timestamp":"1722673020.0"},{"poster":"trungtd","upvote_count":"2","content":"Selected Answer: B\nAlthough option A uses Kinesis Data Analytics for anomaly detection, setting up and maintaining custom analytics and anomaly detection logic is more complex and less efficient compared to using a managed service like Lookout for Metrics.","timestamp":"1720567620.0","comment_id":"1245198"},{"poster":"xdkonorek2","content":"Selected Answer: B\nA is wrong because kinesis data analytics output must be either kinesis data stream or firehose, can't be lambda directly so there is a missing component","upvote_count":"2","timestamp":"1720035780.0","comment_id":"1241623"},{"content":"I've reviewed most of the comments, and it seems like everyone is just repeating themselves. I've \"googled\" and looked at the references. I found examples of both kinesis data streams, kinesis data analytics and firehose. The one step in \"A\" I have a problem with is \"Create an AWS Lambda function to use as the output of the data stream.\" How can Lambda be an output of a data stream \"over time\"? I don't think you can identify an anomaly \"over time\" unless you've got persistent storage for the data (which can be reparsed as necessary to compare past with present). I'm leaning towards \"B\" unless someone can convince me otherwise (and not by just repeating what others have already said).","poster":"Gomer","upvote_count":"3","comment_id":"1237142","timestamp":"1719362340.0"},{"comment_id":"1232721","content":"Selected Answer: A\nOption B involves using Amazon Lookout for Metrics, which is not designed for real-time anomaly detection.","upvote_count":"2","comments":[{"poster":"Gomer","comment_id":"1237144","content":"I see the \"over time\" requirement as implying some ability to parse the past with the present in order for ML to assess an anomaly. I don't see the words \"real time\" in the requirements. The \"over time\" requirement is not specific enough, but until there are more specifics, it would be reasonable to presume it means your trying to discover current anomalies by comparing traffic from against days, weeks or months ago.","timestamp":"1719363000.0","upvote_count":"1"}],"poster":"tsangckl","timestamp":"1718774640.0"},{"content":"Selected Answer: B\ni think B","upvote_count":"2","timestamp":"1714650720.0","comment_id":"1205485","poster":"seetpt"},{"comment_id":"1200819","poster":"c3518fc","upvote_count":"3","timestamp":"1713889560.0","content":"Selected Answer: B\nLookout for Metrics automatically detects and diagnoses anomalies (outliers from the norm) in business and operational data. Itâ€™s a fully managed ML service, which uses specialized ML models to detect anomalies based on the characteristics of your data. You donâ€™t need ML experience to use Lookout for Metrics.\n\nKinesis Data Analytics Studio provides an interactive notebook experience powered by Apache Zeppelin and Apache Flink to analyze streaming data. It also helps productionize your analytics application by building and deploying code as a Kinesis data analytics application straight from the notebook. https://aws.amazon.com/blogs/machine-learning/smart-city-traffic-anomaly-detection-using-amazon-lookout-for-metrics-and-amazon-kinesis-data-analytics-studio/"},{"comment_id":"1184607","timestamp":"1711611360.0","upvote_count":"1","poster":"stoy123","content":"Selected Answer: A\nA. If you google \"detecting anomalies in vpc flow logs\" every article suggests Kinesis Data Analytics"},{"comment_id":"1176411","timestamp":"1710761700.0","poster":"CloudHandsOn","content":"Selected Answer: A\nI'll go with A. Mainly because Kinesis data analytics has anomoly detection using a random cut forest function: https://docs.aws.amazon.com/kinesisanalytics/latest/dev/app-anomaly-detection.html","upvote_count":"2"},{"timestamp":"1710604260.0","content":"Selected Answer: B\nB - Amazon Lookout for Metrics Automatically detect anomalies within metrics and identify their root causes. So would fit the requirements","comment_id":"1175067","upvote_count":"3","poster":"DanShone"},{"comment_id":"1174889","upvote_count":"1","content":"Selected Answer: A\nOption A is preferable for scenarios requiring real-time processing and anomaly detection in streaming data, such as VPC flow logs, with the capability to quickly initiate responses to detected anomalies. It offers a more streamlined and immediate approach to monitoring and responding to network traffic anomalies, making it highly suitable for the company's needs regarding their critical compute infrastructure with predictable traffic patterns.\n\nOption B might still be considered if the company's workflow is more adapted to batch processing and the delays inherent in data delivery and processing are acceptable. However, for immediate anomaly detection and response, Option A stands out as the more appropriate solution.","poster":"ogerber","timestamp":"1710583140.0"},{"timestamp":"1709421780.0","content":"Selected Answer: A\nKinesis Data Firehose determines how often to write to S3 by buffer settings, which is not realtime enough to handle VPC flow log, which can be fatal depending on the content of the `CRITICAL compute infrastructure`. Kinesis Data Analytics has machine learning solutions such as RANDOM_CUT_FOREST in addition to fixed detection by normal SQL.","comment_id":"1164416","upvote_count":"3","poster":"dzn"},{"content":"Selected Answer: B\nB without a doubt","timestamp":"1709252640.0","comment_id":"1163119","poster":"[Removed]","upvote_count":"3"},{"poster":"fdoxxx","content":"Option B is the most suitable for the scenario.\nKinesis Data Firehose: It allows the streaming of data to an S3 bucket, providing a durable storage solution.\nLookout for Metrics: It is designed to detect anomalies in your data and can be configured to monitor the data stored in the S3 bucket for anomalies.","comment_id":"1159956","timestamp":"1708967400.0","upvote_count":"3"},{"comment_id":"1159245","poster":"Seoyong","content":"Question keyword :\n- predictable traffic patterns\n- anomalies\n\nThus, B.","timestamp":"1708901280.0","upvote_count":"4"},{"timestamp":"1708435380.0","comment_id":"1154738","upvote_count":"2","poster":"kyuhuck","content":"Selected Answer: A\nb is not corret Option A is the most suitable approach to meet the requirements. It leverages Amazon Kinesis Data Stream for real-time data ingestion, Amazon Kinesis Data Analytics for efficient and scalable anomaly detection in real-time, and AWS Lambda to initiate a response when anomalies are detected. This setup provides a robust, scalable, and real-time monitoring solution for VPC flow logs, with the ability to initiate responses to anomalies through integration with Amazon EventBridge."},{"content":"Selected Answer: B\nB is correct: <needs to configure a monitoring solution for the VPC flow logs to identify anomalies> means Amazon Lookout for Metrics. \nA, C and D dont mention Amazon Lookout for Metrics","timestamp":"1707315420.0","poster":"thanhnv142","comment_id":"1143386","upvote_count":"4"},{"content":"Selected Answer: B\nBoth A (RCF) and B should detect anomalies. A didn't mention using RCF, also Kinesis data stream usually refers to real-time detection, while firehose is not about real-time. There is a keyword \"overtime\" in the description, so B.","poster":"a54b16f","upvote_count":"3","comment_id":"1119895","timestamp":"1704986640.0"},{"content":"Selected Answer: B\nI will go for B","timestamp":"1704832980.0","poster":"davdan99","comment_id":"1117837","upvote_count":"3"},{"poster":"bnagaraja9099","upvote_count":"4","timestamp":"1703168040.0","comment_id":"1102596","content":"Selected Answer: B\nAmazon lookout , AI anomalies identification"},{"content":"It could be B by using Lookout for metrics. Indeed, it should be even easier to configure the detection","upvote_count":"3","comment_id":"1098050","timestamp":"1702721040.0","poster":"a16a848"},{"comment_id":"1082685","upvote_count":"2","timestamp":"1701184620.0","poster":"zain1258","content":"Selected Answer: A\nA is correct"},{"timestamp":"1700742360.0","comment_id":"1078417","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/kinesisanalytics/latest/dev/app-anomaly-detection.html A should be correct","poster":"vandergun","upvote_count":"3"}],"answer":"B","answer_ET":"B","choices":{"C":"Create an AWS Lambda function to detect anomalies. Configure the Lambda function to publish an event to the default Amazon EventBridge event bus if the Lambda function detects an anomaly. Subscribe the Lambda function to the log group.","B":"Create an Amazon Kinesis Data Firehose delivery stream that delivers events to an Amazon S3 bucket. Subscribe the log group to the delivery stream. Configure Amazon Lookout for Metrics to monitor the data in the S3 bucket for anomalies. Create an AWS Lambda function to run in response to Lookout for Metrics anomaly findings. Configure the Lambda function to publish to the default Amazon EventBridge event bus.","A":"Create an Amazon Kinesis data stream. Subscribe the log group to the data stream. Configure Amazon Kinesis Data Analytics to detect log anomalies in the data stream. Create an AWS Lambda function to use as the output of the data stream. Configure the Lambda function to write to the default Amazon EventBridge event bus in the event of an anomaly finding.","D":"Create an Amazon Kinesis data stream. Subscribe the log group to the data stream. Create an AWS Lambda function to detect log anomalies. Configure the Lambda function to write to the default Amazon EventBridge event bus if the Lambda function detects an anomaly. Set the Lambda function as the processor for the data stream."},"exam_id":23,"question_images":[],"topic":"1","question_id":53},{"id":"iogWLpwHTRBUPBxfCVqg","question_images":[],"answers_community":["C (61%)","D (36%)","2%"],"discussion":[{"comment_id":"1079947","timestamp":"1700909940.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_access.html#orgs_manage_accounts_create-cross-account-role","upvote_count":"6","poster":"radev"},{"comment_id":"1143392","content":"Selected Answer: C\nC is correct: <assume the role in Example Corp's new member account> means this role has not been properly configured (or even not created)\nA: only mention assuming the role, not create it.\nB: scp has nothing to do here\nD: only mention create trust relationship","upvote_count":"5","timestamp":"1707315780.0","poster":"thanhnv142"},{"poster":"AC2021","comment_id":"1345736","comments":[{"content":"The role would not be automatically created in accounts that are added through invitation (as opposed to accounts created within the organization).","poster":"ce0df07","timestamp":"1738976220.0","upvote_count":"1","comment_id":"1353170"}],"timestamp":"1737679080.0","content":"Selected Answer: D\nThe role is already there. Why create a new one?","upvote_count":"2"},{"timestamp":"1734854880.0","content":"Selected Answer: D\nCorrect Answer is D \nRole Trust Policy Issue:\nWhen a new account is invited and joins an AWS Organization, the OrganizationAccountAccessRole is typically created automatically.\nThis role allows the management account to access member accounts, but its trust policy must explicitly grant the management account permission to assume the role.\nIf this trust policy is not configured correctly, the management account cannot assume the role, leading to the error message.","poster":"Simba84","comments":[{"timestamp":"1738976280.0","poster":"ce0df07","content":"Incorrect. See https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_access.html#orgs_manage_accounts_create-cross-account-role\n\"When you create a member account using AWS Organizations, Organizations automatically creates an IAM role in the account that grants administrator access to the management account. For invited member accounts, you must manually create the role.\"","upvote_count":"1","comment_id":"1353171"}],"upvote_count":"4","comment_id":"1330308"},{"timestamp":"1733241780.0","comment_id":"1321439","content":"Selected Answer: C\nI've spent like 30 mins, and now I've got the most full explanation.\n\nCorrect answer is \"C\"\nWhile \"D\" is NOT FULLY describing what needs to be done (so it's wrong).\n\nThe thing you need to know to answer this question is the following:\n* if account is generated (meaning NEW account CREATED) within the Org, then this account will automatically have a proper role \"OrganizationAccountAccessRole\"\n* if account is invited (meaning EXISTING account ADDED) to Org, then this account will NOT have such role\n\nQuestion says, that Management Account tries to assume a role called \"OrganizationAccountAccessRole\" from member account, but it gets an error saying like \"there is no such thing which you request\".\n\nSo to fix an error you need:\n1) Create a IAM Role \"OrganizationAccountAccessRole\" in a member account\n2) Give it FullAccess Policy\n3) Allow Management Account to assume this role via its Trust Relationship","poster":"eugene2owl","upvote_count":"4"},{"upvote_count":"2","poster":"hamzaBennis","comment_id":"1312491","content":"member accounts that you invite to join your organization do not automatically get an administrator role created.\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_create-cross-account-role.html","timestamp":"1731659760.0"},{"upvote_count":"3","comment_id":"1307673","poster":"VerRi","timestamp":"1730869260.0","content":"Selected Answer: D\n\"IAM user that assumes a role that is named OrganizationAccountAccessRole\", the role is already there"},{"upvote_count":"3","content":"Selected Answer: D\nThe question states that the role already exists with full access policy. This role exists in the new member account. We need the IAM user from the management account the ability to assume it.","comment_id":"1288395","timestamp":"1727152200.0","poster":"heff_bezos"},{"comments":[{"content":"\"By default, if you create a member account as part of your organization, AWS automatically creates a role in the account that grants administrator permissions to IAM users in the management account who can assume the role. By default, that role is named OrganizationAccountAccessRole\"\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_create-cross-account-role.html","timestamp":"1727152500.0","comment_id":"1288400","upvote_count":"1","poster":"heff_bezos"}],"comment_id":"1280840","content":"Selected Answer: D\nThis role is created by default in member accounts. See:\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_access.html","timestamp":"1725880440.0","poster":"aws_god","upvote_count":"2"},{"content":"Selected Answer: C\nTo create an AWS Organizations administrator role in a member account\nSign in to the IAM console at https://console.aws.amazon.com/iam/. You must sign in as an IAM user, assume an IAM role, or sign in as the root user (not recommended) in the member account. The user or role must have permission to create IAM roles and policies.\n\nIn the IAM console, navigate to Roles and then choose Create role.\n\nChoose AWS account, and then select Another AWS account.\n\nEnter the 12-digit account ID number of the management account that you want to grant administrator access to. Under Options, please note the following:\n\nOn the Add permissions page, choose the AWS managed policy named AdministratorAccess and then choose. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_access.html#orgs_manage_accounts_create-cross-account-role","comment_id":"1200823","timestamp":"1713890280.0","upvote_count":"4","poster":"c3518fc"},{"timestamp":"1712645460.0","comment_id":"1192066","poster":"Andy11234912","content":"Selected Answer: D\nnot c, the role is already created","comments":[{"content":"From reading the question, I'm not sure.","poster":"Jay_2pt0_1","timestamp":"1718698980.0","comment_id":"1232322","upvote_count":"1"}],"upvote_count":"2"},{"comment_id":"1191520","upvote_count":"1","timestamp":"1712573280.0","poster":"sirronido","content":"D.. the role is already created, what is needed is just update the trust policy"},{"comment_id":"1175064","content":"C is correct","poster":"DanShone","timestamp":"1710604140.0","upvote_count":"1"},{"timestamp":"1705510620.0","comment_id":"1125151","content":"Selected Answer: C\nC is correct","poster":"twogyt","upvote_count":"4"},{"timestamp":"1701184680.0","upvote_count":"4","content":"Selected Answer: C\nC is correct","poster":"zain1258","comment_id":"1082686"},{"timestamp":"1700853180.0","comment_id":"1079521","poster":"tom_cat","upvote_count":"2","comments":[{"poster":"tom_cat","timestamp":"1700853240.0","content":"So I believe it's C.","comment_id":"1079523","upvote_count":"2"}],"content":"For invited accounts the OrganizationAccountAccessRole needs to be created:\nMember accounts that you invite to join your organization do not automatically get an administrator role created. You have to do this manually, as shown in the following procedure. This essentially duplicates the role automatically set up for created accounts. We recommend that you use the same name, OrganizationAccountAccessRole, for your manually created roles for consistency and ease of remembering."},{"content":"Selected Answer: A\nA should be correct","timestamp":"1700730000.0","poster":"vandergun","comment_id":"1078271","upvote_count":"1"}],"unix_timestamp":1700730000,"question_text":"AnyCompany is using AWS Organizations to create and manage multiple AWS accounts. AnyCompany recently acquired a smaller company, Example Corp. During the acquisition process, Example Corp's single AWS account joined AnyCompany's management account through an Organizations invitation. AnyCompany moved the new member account under an OU that is dedicated to Example Corp.\n\nAnyCompany's DevOps engineer has an IAM user that assumes a role that is named OrganizationAccountAccessRole to access member accounts. This role is configured with a full access policy. When the DevOps engineer tries to use the AWS Management Console to assume the role in Example Corp's new member account, the DevOps engineer receives the following error message: \"Invalid information in one or more fields. Check your information or contact your administrator.\"\n\nWhich solution will give the DevOps engineer access to the new member account?","choices":{"C":"In the new member account, create a new IAM role that is named OrganizationAccountAccessRole. Attach the AdministratorAccess AWS managed policy to the role. In the role's trust policy, grant the management account permission to assume the role.","B":"In the management account, create a new SCP. In the SCP, grant the DevOps engineer's IAM user full access to all resources in the new member account. Attach the SCP to the OU that contains the new member account.","D":"In the new member account, edit the trust policy for the OrganizationAccountAccessRole IAM role. Grant the management account permission to assume the role.","A":"In the management account, grant the DevOps engineer's IAM user permission to assume the OrganizationAccountAccessRole IAM role in the new member account."},"answer_images":[],"answer_description":"","answer":"C","timestamp":"2023-11-23 10:00:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/126991-exam-aws-certified-devops-engineer-professional-dop-c02/","isMC":true,"exam_id":23,"question_id":54,"answer_ET":"C"},{"id":"TnJ7ymbGUZ2uDNgk0XHx","exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/126992-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_ET":"B","answer_images":[],"isMC":true,"answer":"B","unix_timestamp":1700730120,"question_text":"A DevOps engineer is designing an application that integrates with a legacy REST API. The application has an AWS Lambda function that reads records from an Amazon Kinesis data stream. The Lambda function sends the records to the legacy REST API.\n\nApproximately 10% of the records that the Lambda function sends from the Kinesis data stream have data errors and must be processed manually. The Lambda function event source configuration has an Amazon Simple Queue Service (Amazon SQS) dead-letter queue as an on-failure destination. The DevOps engineer has configured the Lambda function to process records in batches and has implemented retries in case of failure.\n\nDuring testing, the DevOps engineer notices that the dead-letter queue contains many records that have no data errors and that already have been processed by the legacy REST API. The DevOps engineer needs to configure the Lambda function's event source options to reduce the number of errorless records that are sent to the dead-letter queue.\n\nWhich solution will meet these requirements?","question_images":[],"choices":{"A":"Increase the retry attempts.","D":"Decrease the maximum age of record.","C":"Increase the concurrent batches per shard.","B":"Configure the setting to split the batch when an error occurs."},"timestamp":"2023-11-23 10:02:00","discussion":[{"content":"Selected Answer: B\nWhen consuming records from a Kinesis data stream using AWS Lambda, the function can process records in batches. By default, if any record in the batch fails to process, the entire batch is sent to the dead-letter queue.\nTo avoid sending errorless records to the dead-letter queue, the Lambda function's event source options should be configured to split the batch when an error occurs. This setting is called batchWindow and can be configured in the event source mapping for the Lambda function.\nWhen batchWindow is set to TRIM_HORIZON, the Lambda function will split the batch at the first record that causes an error and send only the failed records to the dead-letter queue. The remaining errorless records in the batch will continue to be processed by the function.","comment_id":"1200856","comments":[{"timestamp":"1719375240.0","comment_id":"1237182","upvote_count":"1","poster":"Gomer","content":"Seemingly very good explanation, though I had trouble finding any references other than this:\n\"BisectBatchOnFunctionError\" \"If the function returns an error, split the batch in two and retry. The default value is false.\"\naws lambda update-event-source-mapping --bisect-batch-on-function-error [...]"}],"upvote_count":"11","timestamp":"1713892560.0","poster":"c3518fc"},{"poster":"zolthar_z","timestamp":"1701359580.0","comment_id":"1084518","upvote_count":"7","content":"Selected Answer: B\nB: https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html#services-kinesis-eventsourcemapping"},{"comment_id":"1263642","content":"B: \nhttps://aws.amazon.com/blogs/big-data/best-practices-for-consuming-amazon-kinesis-data-streams-using-aws-lambda/","upvote_count":"1","poster":"tinyshare","timestamp":"1723326660.0"},{"content":"B is correct: <(Amazon SQS) dead-letter queue as an on-failure destination>: split the batch into 2 parts: success ones and error ones. error ones come to dead queue","poster":"thanhnv142","timestamp":"1707317160.0","upvote_count":"3","comment_id":"1143419"},{"upvote_count":"4","content":"Selected Answer: B\nB is correct","poster":"zain1258","timestamp":"1700764860.0","comment_id":"1078660"},{"content":"Selected Answer: B\nB is corrected","poster":"vandergun","upvote_count":"5","timestamp":"1700730120.0","comment_id":"1078272"}],"topic":"1","answers_community":["B (100%)"],"question_id":55,"answer_description":""}],"exam":{"name":"AWS Certified DevOps Engineer - Professional DOP-C02","isMCOnly":true,"lastUpdated":"11 Apr 2025","isImplemented":true,"isBeta":false,"id":23,"numberOfQuestions":355,"provider":"Amazon"},"currentPage":11},"__N_SSP":true}