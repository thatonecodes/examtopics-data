{"pageProps":{"questions":[{"id":"CyBwi9qhT0IuKhoywaUj","answers_community":["D (67%)","A (33%)"],"discussion":[{"upvote_count":"1","comment_id":"1196022","content":"Answer is D\n\nIncrease the maximum connections to your DB instance\nIncrease the maximum number of connections to your DB instance using the following methods:\n\nScale the instance up to a DB instance class with more memory. Note: Scaling the DB instance class causes an outage.\nSet a larger value for the max_connections parameter using a custom instance-level parameter group. Increasing the max_connections parameter doesn't cause an outage, but if your DB instance is using a default parameter group, then change the parameter group to a custom parameter group. Changing the parameter group causes an outage. For more information, see Working with DB parameter groups.\n\nhttps://repost.aws/knowledge-center/aurora-mysql-max-connection-errors","timestamp":"1713184500.0","poster":"grekh001"},{"timestamp":"1712813820.0","upvote_count":"1","content":"Selected Answer: A\nAmazon Aurora Serverless is an on-demand, auto-scaling version of Amazon Aurora, where the database will automatically start up, shut down, and scale capacity up or down based on your application’s needs. It enables you to run your database in the cloud without managing any database instances. It’s a simple, cost-effective option for infrequent, intermittent, or unpredictable workloads.\n\nGiven the unpredictable surges in traffic that overwhelm the database with too many connection requests, a serverless database would be able to handle the variability in demand more effectively. Additionally, Aurora Serverless is more resilient to database failures as it automatically scales compute capacity and can quickly recover from physical storage failures.","poster":"tsangckl","comment_id":"1193458"},{"comment_id":"1188935","upvote_count":"1","poster":"koki2847","timestamp":"1712183520.0","content":"Selected Answer: A\nD is incorrect. Manually modifying parameter isn't scalable but Aurora Severless is. It is hence A."},{"poster":"stream3652","timestamp":"1708416300.0","comment_id":"1154561","content":"Selected Answer: D\nI think the correct answer is D. Because A's serverless scales slowly.","upvote_count":"2"},{"timestamp":"1706977980.0","poster":"Skarlex77","comments":[{"upvote_count":"1","comment_id":"1139461","content":"Sorry meant A","timestamp":"1706978040.0","poster":"Skarlex77"}],"upvote_count":"2","comment_id":"1139460","content":"Selected Answer: D\n\"The company needs to implement a scalable solution that is more resilient to database failures\" i would go for D"},{"upvote_count":"2","timestamp":"1705157580.0","comment_id":"1121763","content":"Selected Answer: D\nD will allow for more connections","poster":"MultiAZ"},{"content":"Selected Answer: A\nA is True, for aurora serverless","timestamp":"1702703760.0","poster":"KikiNoviandi","comment_id":"1097925","upvote_count":"1"},{"timestamp":"1700974260.0","upvote_count":"2","comment_id":"1080484","content":"I think A.\n\nWhich solution meets cost-effectively? As it says, Amazon Aurora Serverless is good for unmeasurable traffic spikes.","poster":"marll88"},{"upvote_count":"3","comment_id":"1080410","timestamp":"1700960400.0","poster":"marll88","content":"Why not D?\nIf you increase the size of the instance class, max_connections can be increased."},{"timestamp":"1700749680.0","content":"may be A ?","comment_id":"1078482","poster":"narvaez","upvote_count":"2"}],"timestamp":"2023-11-23 15:28:00","answer_description":"","isMC":true,"answer":"D","question_text":"A company has a web application that uses Amazon API Gateway to route HTTPS requests to AWS Lambda functions. The application uses an Amazon Aurora MySQL database for its data storage. The application has experienced unpredictable surges in traffic that overwhelm the database with too many connection requests. The company needs to implement a scalable solution that is more resilient to database failures as quickly as possible.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_ET":"D","answer_images":[],"question_id":266,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/127021-exam-aws-certified-database-specialty-topic-1-question-338/","choices":{"D":"Increase the instance class for the Aurora database with more memory. Set a larger value for the max_connections parameter.","C":"Create an Amazon EventBridge rule that invokes a Lambda function. Code the function to iterate over all existing connections and to call MySQL queries to end any connections in the sleep state.","B":"Migrate the Aurora MySQL database to Amazon DynamoDB tables by using AWS Database Migration Service (AWS DMS). Change the endpoint in the Lambda functions to use the new database.","A":"Migrate the Aurora MySQL database to Amazon Aurora Serverless by restoring a snapshot. Change the endpoint in the Lambda functions to use the new database."},"topic":"1","unix_timestamp":1700749680,"exam_id":22},{"id":"HUgxxn3MDUOVzgqKmyiY","timestamp":"2023-11-26 05:21:00","choices":{"C":"Set the enable_user_activity_logging parameter to false in the database parameter group.","A":"Set the use_fips_ssl parameter to true in the database parameter group.","D":"Disable audit logging on the Redshift cluster.","B":"Turn off the query monitoring rule in the Redshift cluster's workload management (WLM)."},"exam_id":22,"url":"https://www.examtopics.com/discussions/amazon/view/127225-exam-aws-certified-database-specialty-topic-1-question-339/","answer_description":"","isMC":true,"question_text":"A company has an Amazon Redshift cluster with database audit logging enabled. A security audit shows that raw SQL statements that run against the Redshift cluster are being logged to an Amazon S3 bucket. The security team requires that authentication logs are generated for use in an intrusion detection system (IDS), but the security team does not require SQL queries.\n\nWhat should a database specialist do to remediate this issue?","topic":"1","answer_ET":"C","question_images":[],"discussion":[{"poster":"KikiNoviandi","comment_id":"1097926","timestamp":"1702703940.0","upvote_count":"2","content":"Selected Answer: C\nSet the enable_user_activity_logging parameter to false in the database parameter group."},{"timestamp":"1701195540.0","upvote_count":"4","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html#db-auditing-enable-logging","poster":"Ram_xyz","comment_id":"1082825"},{"timestamp":"1700972460.0","content":"I think B.\n\nThe security team does not need SQL queries.\nTurn off query monitoring.","poster":"marll88","upvote_count":"1","comment_id":"1080474"}],"unix_timestamp":1700972460,"answer":"C","question_id":267,"answers_community":["C (100%)"],"answer_images":[]},{"id":"q8qqTg0mgOItREcroYQq","timestamp":"2020-07-14 15:28:00","answer_description":"","answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/25720-exam-aws-certified-database-specialty-topic-1-question-34/","question_id":268,"choices":{"A":"Configure both of the Aurora Replicas to the same instance class as the primary DB instance. Enable cache coherence on the DB cluster, set the primary DB instance failover priority to tier-0, and assign a failover priority of tier-1 to the replicas.","C":"Configure one Aurora Replica to have the same instance class as the primary DB instance. Implement Aurora PostgreSQL DB cluster cache management. Set the failover priority to tier-0 for the primary DB instance and one replica with the same instance class. Set the failover priority to tier-1 for the other replicas.","B":"Deploy an AWS Lambda function that calls the DescribeDBInstances action to establish which instance has failed, and then use the PromoteReadReplica operation to promote one Aurora Replica to be the primary DB instance. Configure an Amazon RDS event subscription to send a notification to an Amazon SNS topic to which the Lambda function is subscribed.","D":"Configure both Aurora Replicas to have the same instance class as the primary DB instance. Implement Aurora PostgreSQL DB cluster cache management. Set the failover priority to tier-0 for the primary DB instance and to tier-1 for the replicas."},"discussion":[{"timestamp":"1672286100.0","upvote_count":"5","poster":"RBSK","comment_id":"760563","content":"Selected Answer: C\nTier-0 is a requirement for CCM to work. Also having more than 1 read replica with Tier-0 also disables CCM - https://docs.amazonaws.cn/en_us/AmazonRDS/latest/AuroraUserGuide/aurora_ccm_status.html\n\nThis clearly eliminates Option-D"},{"content":"Selected Answer: C\n\"Cluster cache management is active on an Aurora PostgreSQL DB cluster when the cluster has an Aurora Reader instance configured as follows:\nThe Aurora Reader instance uses same DB instance class type and size as the cluster's Writer instance.\nThe Aurora Reader instance is configured as Tier-0 for the cluster. If the cluster has more than one Reader, this is its only Tier-0 Reader.\nSetting more than one Reader to Tier-0 disables CCM.\"\nhttps://docs.amazonaws.cn/en_us/AmazonRDS/latest/AuroraUserGuide/aurora_ccm_status.html","timestamp":"1690960860.0","comment_id":"969870","poster":"IhorK","upvote_count":"1","comments":[{"comment_id":"1079852","upvote_count":"1","poster":"jitesh_k","content":"Why do we need to set promotion tier for writer instance? It is already being used and failover will occur when it fails. When writer instance fails, reader replica will be promoted to writer instance. The writer instance that failed is not going to be removed from cluster - correct?","timestamp":"1700901780.0"}]},{"content":"Selected Answer: C\nC\n\nfor CCM to work\n1- you need to have one RR with the same instance class type and size as the writer instance\n2- you need to set promotion priority to 0 for both writer and RR you need\n\nthe details here https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.cluster-cache-mgmt.html","timestamp":"1666183680.0","poster":"sayed","upvote_count":"4","comment_id":"699040"},{"content":"C is correct. \nhttps://aws.amazon.com/blogs/database/introduction-to-aurora-postgresql-cluster-cache-management/","upvote_count":"1","poster":"sachin","comment_id":"620737","timestamp":"1655955720.0"},{"upvote_count":"2","timestamp":"1651260240.0","content":"Selected Answer: C\nOne Aurora Replica of same instance class as the primary DB\n -> Aurora PostgreSQL DB cluster cache management \n-> failover priority to tier-0 for the primary DB instance and one replica with the same instance class\n-> failover priority to tier-1 for the other replicas","comment_id":"594663","poster":"novice_expert"},{"upvote_count":"4","poster":"RotterDam","timestamp":"1646457060.0","comment_id":"561221","content":"Selected Answer: C\nC is correct. Cluster Cache Management needs these three:\n- Set One Replica to have same priority as Primary\n- Set its instance class same as Primary"},{"poster":"tugboat","comment_id":"555590","content":"C is economical, but priorities don't need to be set as largest replica will always be first target option for failovers","timestamp":"1645739580.0","upvote_count":"2"},{"comment_id":"540572","upvote_count":"4","poster":"VPup","content":"Selected Answer: C\nCCM can be set to only one replica. That's why we put it to tier-0 to guarantee the fail over to the CCM enabled replica.","timestamp":"1643999340.0"},{"upvote_count":"4","content":"Answer is D. The replicas must be the same size as the primary when cluster cache management is used.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.cluster-cache-mgmt.html","poster":"thelad","timestamp":"1643731920.0","comments":[{"comment_id":"594664","content":"No all replicas but one where you want to fail over to, so ans is C","upvote_count":"3","timestamp":"1651260420.0","poster":"novice_expert"}],"comment_id":"538012"},{"upvote_count":"2","timestamp":"1638401460.0","comments":[{"poster":"thelad","timestamp":"1643731740.0","content":"From that link - \"Cluster cache management requires that the designated reader instance have the same instance class type and size (db.r5.2xlarge or db.r5.xlarge, for example) as the writer\"\nTherefore both replicas are required to be the same size as the primary. I'm going for Answer D","comments":[{"comment_id":"594665","content":"not both, just one is good","upvote_count":"1","poster":"novice_expert","timestamp":"1651260480.0"}],"comment_id":"538006","upvote_count":"1"}],"comment_id":"492006","content":"Selected Answer: C\nAnswer is C. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.cluster-cache-mgmt.html","poster":"shuraosipov"},{"content":"Selected Answer: C\nOption C","upvote_count":"2","comment_id":"485891","timestamp":"1637753160.0","poster":"GMartinelli"},{"comment_id":"364709","upvote_count":"2","content":"Ans is C. Because this doc https://aws.amazon.com/blogs/database/introduction-to-aurora-postgresql-cluster-cache-management/ says to set priority of primary and one replica to zero. Which is not the case with D.","timestamp":"1635564060.0","poster":"Dip11"},{"timestamp":"1635348240.0","content":"C Answer\nTier Priority 0 is the clue to eliminate D:","poster":"shantest1","upvote_count":"2","comment_id":"328032","comments":[{"comments":[{"timestamp":"1675737000.0","content":"CCM requires one replica has tier 0.","upvote_count":"1","poster":"im_not_robot","comment_id":"800461"}],"comment_id":"337711","content":"The priority of 0 has nothing to do with it since more than one replica can have the same priority. The only difference appears to be cost and C will be cheaper. \n\n\"You can customize the order in which your Aurora Replicas are promoted to the primary instance after a failure by assigning each replica a priority. Priorities range from 0 for the first priority to 15 for the last priority. If the primary instance fails, Amazon RDS promotes the Aurora Replica with the better priority to the new primary instance. You can modify the priority of an Aurora Replica at any time. Modifying the priority doesn't trigger a failover.\n\nMore than one Aurora Replica can share the same priority, resulting in promotion tiers. If two or more Aurora Replicas share the same priority, then Amazon RDS promotes the replica that is largest in size. If two or more Aurora Replicas share the same priority and size, then Amazon RDS promotes an arbitrary replica in the same promotion tier. \"","upvote_count":"2","timestamp":"1635364800.0","poster":"anon9002"}]},{"upvote_count":"1","poster":"LMax","content":"C and D look equally good to address the problem, but D would cost more as you upgrade all read replicas, not just 1. So for cost saving reasons would go with Answer C.","comment_id":"314838","timestamp":"1635246300.0"},{"comment_id":"299022","upvote_count":"1","poster":"Windy","content":"C for me.","timestamp":"1635216960.0"},{"content":"Ans: C","comment_id":"297985","timestamp":"1635127860.0","upvote_count":"1","poster":"myutran"},{"comment_id":"253172","upvote_count":"1","poster":"JobinAkaJoe","content":"I am torn between C &D.\nPerformance issue after failover lasts only for a short duration which means it has more to do with cache management than instance sizing. CCM definitely is the solution.\nBetween C & D, I will go with C considering the fact that originally read-replicas were of lower configuration for cost-saving, so its ideal to have one read-replica matching primary instance size and others with lower configuration if cost is a concern.","timestamp":"1634585340.0"},{"upvote_count":"3","poster":"Billhardy","content":"Has to be C\n\nSetting the promotion tier priority for a reader DB instance\nYou set one reader DB instance for cluster cache management. To do so, choose a reader from the Aurora PostgreSQL cluster that is the same instance class as the writer DB instance. Then set its promotion tier priority to 0.","timestamp":"1634558220.0","comment_id":"226110"},{"upvote_count":"3","poster":"Ashoks","timestamp":"1634080920.0","content":"C\nPrimary and one replica will have large instance type, high failover tier 0 and cluster cache management","comment_id":"212044"},{"content":"C is right!\nhttps://aws.amazon.com/blogs/database/introduction-to-aurora-postgresql-cluster-cache-management/","upvote_count":"2","timestamp":"1633964220.0","poster":"Rahu","comment_id":"169309"},{"comment_id":"163645","upvote_count":"2","content":"C is correct. \nSee 'Configuring Cluster Cache Management' part in the following document.\nIt shows how to config cluster cache management and promotion tier priority.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.cluster-cache-mgmt.html","timestamp":"1633496880.0","poster":"exam2019"},{"comment_id":"154317","upvote_count":"2","content":"Answer is C\nFor enabling cache management writer instance and replica with same class must have tier-0 as promotion priority,\nAnswer D is NOT correct, both reader instances have tier-1 as promotion priority which is wrong.","timestamp":"1633459860.0","poster":"Ebi"},{"content":"i think C, im not complety sure","timestamp":"1633095120.0","upvote_count":"3","poster":"BillyC","comment_id":"145771"},{"poster":"BillyMadison","content":"Either C or D. Cache Cluster Management definitely has to be in the answer\nhttps://aws.amazon.com/about-aws/whats-new/2019/06/amazon-aurora-with-postgresql-compatibility-supports-cluster-cache-management/#:~:text=With%20cluster%20cache%20management%2C%20you,the%20read%2Dwrite%20instance's%20cache.","timestamp":"1632929520.0","upvote_count":"2","comment_id":"140279","comments":[{"comments":[{"poster":"guru_ji","upvote_count":"1","timestamp":"1636126200.0","comment_id":"438089","content":"Answer C"},{"comment_id":"152731","poster":"szmulder","content":"It's D not C. the D include both Aurora Replicas to have the same instance class. C only config one replica have the same size, and if the failover happen twice in a row?","upvote_count":"1","timestamp":"1633272240.0","comments":[{"content":"The doc clearly mentions that you need to designate one of the replicas (not all).\nhttps://aws.amazon.com/blogs/database/introduction-to-aurora-postgresql-cluster-cache-management/#:~:text=The%20cluster%20cache%20management%20(CCM,replica%20as%20the%20failover%20target.\n\"The cluster cache management (CCM) feature improves the performance of the new primary/writer instance after failover occurs. The replica preemptively reads frequently accessed buffers cached from the primary/writer instance. With CCM, you can designate a specific Aurora PostgreSQL replica as the failover target. CCM ensures that data in the designated replica’s cache is synchronized with the data in the primary DB instance’s cache.\"","poster":"RDSBot","upvote_count":"3","comment_id":"180080","comments":[{"timestamp":"1635872820.0","upvote_count":"1","poster":"guru_ji","comment_id":"438087","content":"Answer C"},{"content":"This is the key why not D. In case of D Aurora will chose one of the tier-1 replicas arbitrarily (since they are the same instance class) and there is a 50% probability it won't be the same instance as configured in CCM. \nAnswer is C.","upvote_count":"1","poster":"VPup","comment_id":"517833","timestamp":"1641420540.0"}],"timestamp":"1634041320.0"}]}],"poster":"steves","upvote_count":"4","timestamp":"1633020060.0","comment_id":"144344","content":"Has to be C.\nAmazon Aurora with PostgreSQL compatibility now supports cluster cache management, providing a faster path to full performance if there's a failover. With cluster cache management, you designate a specific reader DB instance in your Aurora PostgreSQL cluster as the failover target. Cluster cache management keeps the data in the designated reader's cache synchronized with the data in the read-write instance's cache. If a failover occurs, the designated reader is promoted to be the new read-write instance, and workloads benefit immediately from the data in its cache."}]},{"poster":"Mickysingh","timestamp":"1632486600.0","content":"Ans D is correct","comment_id":"134873","upvote_count":"4"}],"exam_id":22,"answer_images":[],"answers_community":["C (100%)"],"unix_timestamp":1594733280,"question_text":"A company is using an Amazon Aurora PostgreSQL DB cluster with an xlarge primary instance master and two large Aurora Replicas for high availability and read-only workload scaling. A failover event occurs and application performance is poor for several minutes. During this time, application servers in all Availability\nZones are healthy and responding normally.\nWhat should the company do to eliminate this application performance issue?","isMC":true,"question_images":[],"answer_ET":"C","topic":"1"},{"id":"XZaM32A1V9qCsdwTuU6U","timestamp":"2023-11-26 03:09:00","answer_images":[],"answer_ET":"A","answer":"A","answer_description":"","discussion":[{"content":"Selected Answer: A\nOption A: Add a transformation rule to the DMS task to ignore the column from the source data endpoint.\n\nAWS Database Migration Service (DMS) allows you to specify transformation rules that change the schema and table definitions of the source data before it is migrated to the target. By adding a transformation rule to ignore the specific column (in this case, the credit card number), you can ensure that this data is not written to the S3 bucket during the continuous replication process.\n\nThis approach does not require changes to the source database schema (as in Option D), does not involve masking the data (as in Option B), and does not rely on encryption to protect the data (as in Option C). It simply prevents the unwanted data from being written to the S3 bucket, which is the most direct and operationally efficient solution to the problem.","poster":"tsangckl","timestamp":"1712814600.0","upvote_count":"1","comment_id":"1193467"},{"comment_id":"1093392","timestamp":"1702293180.0","upvote_count":"4","content":"Selected Answer: A\nA for sure.\n\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.CustomizingTasks.TableMapping.SelectionTransformation.Transformations.html","poster":"silvaa360"},{"poster":"marll88","upvote_count":"3","comment_id":"1080437","timestamp":"1700964540.0","content":"Not C.\nKMS encryption is secure, but it is not a procedure to prevent S3 writes"}],"topic":"1","question_text":"A company performs an audit on various data stores and discovers that an Amazon S3 bucket is storing a credit card number. The S3 bucket is the target of an AWS Database Migration Service (AWS DMS) continuous replication task that uses change data capture (CDC). The company determines that this field is not needed by anyone who uses the target data. The company has manually removed the existing credit card data from the S3 bucket.\n\nWhat is the MOST operationally efficient way to prevent new credit card data from being written to the S3 bucket?","isMC":true,"question_id":269,"exam_id":22,"answers_community":["A (100%)"],"unix_timestamp":1700964540,"url":"https://www.examtopics.com/discussions/amazon/view/127221-exam-aws-certified-database-specialty-topic-1-question-340/","question_images":[],"choices":{"C":"Configure the target S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS).","D":"Remove the credit card number column from the data source so that the DMS task does not need to be altered.","B":"Add a transformation rule to the DMS task to mask the column by using a simple SQL query.","A":"Add a transformation rule to the DMS task to ignore the column from the source data endpoint."}},{"id":"Gpq68dvUiLsoJv5965xv","question_images":[],"answer":"B","choices":{"B":"Create a global datastore in ElastiCache for Redis. Then create replica clusters in two other Regions. Promote one of the replica clusters as primary when DR is required.","D":"Create a snapshot of ElastiCache for Redis in the primary Region and copy it to the failover Region. Use the snapshot to restore the cluster from the failover Region when DR is required.","C":"Disable cluster mode in ElastiCache for Redis. Then create multiple replication groups across Regions and replicate the cache data by using AWS Database Migration Service (AWS DMS). Promote a replication group in the failover Region to primary when DR is required.","A":"Enable cluster mode in ElastiCache for Redis. Then create multiple clusters across Regions and replicate the cache data by using AWS Database Migration Service (AWS DMS). Promote a cluster in the failover Region to handle production traffic when DR is required."},"answers_community":["B (100%)"],"question_id":270,"question_text":"A large financial services company uses Amazon ElastiCache for Redis for its new application that has a global user base. A database administrator must develop a caching solution that will be available across AWS Regions and include low-latency replication and failover capabilities for disaster recovery (DR). The company's security team requires the encryption of cross-Region data transfers.\n\nWhich solution meets these requirements with the LEAST amount of operational effort?","url":"https://www.examtopics.com/discussions/amazon/view/127226-exam-aws-certified-database-specialty-topic-1-question-341/","timestamp":"2023-11-26 05:29:00","topic":"1","isMC":true,"discussion":[{"poster":"Skarlex77","comment_id":"1139481","timestamp":"1706980020.0","content":"Selected Answer: B\nFor sure B","upvote_count":"1"},{"comment_id":"1121725","poster":"MultiAZ","content":"Selected Answer: B\nB\nElasticache Global DataStore allows for one master and two read replica regions, and manual failover in case of disaster. RPO <1sec and RTO <1 min","timestamp":"1705155840.0","upvote_count":"2"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Redis-Global-Datastore.html","timestamp":"1701195960.0","poster":"Ram_xyz","upvote_count":"4","comment_id":"1082834"},{"comment_id":"1080477","upvote_count":"3","timestamp":"1700972940.0","content":"I think B.\n\nIn the unlikely event of regional degradation, one of the healthy cross-region replica clusters can be promoted to become the primary cluster with full read/write capabilities. Once initiated, the promotion typically completes in less than a minute, allowing your applications to remain available. \nhttps://aws.amazon.com/about-aws/whats-new/2020/03/amazon-elasticache-for-redis-announces-global-datastore/","poster":"marll88"}],"unix_timestamp":1700972940,"exam_id":22,"answer_ET":"B","answer_images":[],"answer_description":""}],"exam":{"name":"AWS Certified Database - Specialty","lastUpdated":"11 Apr 2025","id":22,"isBeta":false,"isMCOnly":false,"numberOfQuestions":359,"provider":"Amazon","isImplemented":true},"currentPage":54},"__N_SSP":true}