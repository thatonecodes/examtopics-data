{"pageProps":{"questions":[{"id":"i2d0RVXinFAdKkxLOgm4","answer_images":[],"answer_description":"","answers_community":["C (52%)","B (40%)","8%"],"answer":"C","answer_ET":"C","discussion":[{"comment_id":"733962","upvote_count":"7","timestamp":"1670004240.0","content":"Selected Answer: B\nB - If you do not use Amazon Route 53 to manage your public DNS records, contact your DNS provider to find out how to add records. If you lack authority to edit your domain's DNS database, you must use email validation instead.\n\nA - DNS validation is not required to be only route53\nC - We know nothing about the actual domain. Other than 3rd party.\nD - Dns validate requires a CNAME record - Confirmed in question 349.","poster":"AdamWest"},{"upvote_count":"1","content":"Selected Answer: C\nThe question asks about dns validation process. Your domain does not have to be in route53 for this.","comment_id":"1126064","timestamp":"1705596300.0","poster":"YR4591"},{"poster":"Anuragksslr","upvote_count":"1","comment_id":"933827","content":"Selected Answer: A\nDNS not with Route53. Validation only happens with active DNS, which is 3rd party","timestamp":"1687719180.0"},{"comment_id":"930758","poster":"Green53","content":"Selected Answer: C\nI'd have to go with C here.\n\nIt isn't A, the records just have to exist. See:\nhttps://docs.aws.amazon.com/acm/latest/userguide/dns-validation.html\n\n\"If you do not use Amazon Route 53 to manage your public DNS records, contact your DNS provider to find out how to add records.\"\n\nI can't see it being B. Notice we're not trying to automatically renew a certificate, we're trying to issue a new one (the *old* certificates are near expiration). I see nothing on:\nhttps://docs.aws.amazon.com/acm/latest/userguide/troubleshooting-renewal.html\nto suggest it requires to be hosted in Route53 (unless you want to click the 'create DNS' option in ACM).\n\nWe then have D, which is incorrect, see https://docs.aws.amazon.com/acm/latest/userguide/dns-validation.html\n\nC seems the most plausible, given:\nhttps://docs.aws.amazon.com/acm/latest/userguide/dns-renewal-validation.html\n\n\"ACM sends AWS Health events and Amazon EventBridge events when it cannot automatically validate a domain during renewal (for example, because of the presence of CAA record)\"","upvote_count":"3","timestamp":"1687449480.0"},{"content":"C\nIf you are not using Route 53 as your DNS provider, you need to manually enter CNAME records provided by ACM into your provider's database, usually through a website. CNAME records are used for a number of purposes, including as redirect mechanisms and as containers for vendor-specific metadata. For ACM, these records allow initial domain ownership validation and ongoing automated certificate renewal.\nhttps://docs.aws.amazon.com/acm/latest/userguide/dns-validation.html\n'C' is the only valid choice","timestamp":"1685896440.0","poster":"6_8ftwin","upvote_count":"1","comment_id":"914815"},{"poster":"pal40sg","upvote_count":"1","comment_id":"908386","timestamp":"1685256960.0","content":"Selected Answer: B\nB: Automatic renewal for domain validation requires the domain to be hosted on Amazon Route 53.\n\nWhen using AWS Certificate Manager (ACM) for automatic renewal, the domain validation process requires the domain to be hosted on Amazon Route 53, which is Amazon Web Services' (AWS) DNS service. This means that the company's DNS hosting provider, which is a third-party provider, is not compatible with the automatic renewal process.","comments":[{"content":"Option C, which states that the domain has Certification Authority Authorization (CAA) DNS records that allow only specific certificate authorities, is not the root cause of the issue mentioned in the scenario. While CAA records can restrict which certificate authorities are allowed to issue certificates for a domain, it does not directly relate to the failure of DNS validation when adding a CNAME record.\n\nIn the given scenario, the problem lies with the requirement for automatic renewal with ACM, which specifically requires the domain to be hosted on Amazon Route 53 (option B). This means that using a third-party DNS hosting provider is not compatible with the automatic renewal process offered by ACM.","timestamp":"1685257020.0","poster":"pal40sg","upvote_count":"1","comment_id":"908387"}]},{"poster":"reji07","comment_id":"856136","content":"Selected Answer: C\nWith DNS validation, you write a CNAME record to your DNS configuration to establish control of your domain name. After you have configured the CNAME record, ACM can automatically renew DNS-validated certificates before they expire, as long as the DNS record has not changed. To make it even easier to validate your domain, ACM can update your DNS configuration for you if you manage your DNS records with Amazon Route 53. If tou are not using Route53 you need to ensure that CNAME record exists for the certificate in the hosted domain","timestamp":"1680204060.0","upvote_count":"1"},{"comment_id":"842921","upvote_count":"1","poster":"c73bf38","content":"Selected Answer: A\nDocumentation is clear on this:\nIt's recommend using DNS validation over email validation for the following reasons:\nACM automatically renews DNS-validated certificates for as long as a certificate remains in use and the DNS record is in place.\n\nTo be renewed, email-validated certificates require an action by the domain owner. ACM begins sending renewal notices 45 days before expiration, using the domain's WHOIS mailbox addresses and five common administrator addressess. The notifications contain a link that the domain owner can click for easy renewal. Once all listed domains are validated, ACM issues a renewed certificate with the same ARN.","timestamp":"1679155440.0","comments":[{"poster":"c73bf38","timestamp":"1679155560.0","comment_id":"842922","upvote_count":"1","content":"B is correct as R53 is not required."}]},{"content":"A When using AWS Certificate Manager (ACM) to request and manage SSL/TLS certificates, the DNS validation process requires that the domain be hosted on Amazon Route 53. If the company is using a third-party DNS hosting provider, the CNAME record created during the validation process will not be recognized by ACM, resulting in a validation failure.\n\nTo resolve this issue, the company can either transfer their domain to Amazon Route 53, or they can use one of the other validation methods supported by ACM, such as email validation or HTTP validation.","timestamp":"1678407000.0","comment_id":"834519","upvote_count":"2","poster":"awsguru1998"},{"comment_id":"821430","timestamp":"1677325080.0","poster":"SergioP","upvote_count":"1","content":"why not A?"},{"comment_id":"809237","timestamp":"1676445900.0","upvote_count":"2","poster":"PatrickLi","content":"Selected Answer: C\nC. There is no requirement the domain name is hosted with R53 whatsoever."},{"comment_id":"781657","poster":"Nocky24","timestamp":"1674167040.0","upvote_count":"2","content":"Selected Answer: C\nC out of these choices based on this article: https://aws.amazon.com/premiumsupport/knowledge-center/acm-troubleshoot-caa-errors/\n\nB is incorrect, your zone doesn't need to be in R53 at all for auto renewal, it just needs to be accessible via public DNS: https://docs.aws.amazon.com/acm/latest/userguide/dns-renewal-validation.html"},{"timestamp":"1672746840.0","upvote_count":"2","poster":"jishrajesh","content":"Selected b","comment_id":"764598"},{"timestamp":"1671825000.0","poster":"Fyssy","upvote_count":"4","content":"Selected Answer: C\nThis is of of the ways certificate validation can fail. \nhttps://aws.amazon.com/premiumsupport/knowledge-center/acm-troubleshoot-caa-errors/\nhttps://aws.amazon.com/blogs/security/easier-certificate-validation-using-dns-with-aws-certificate-manager/","comment_id":"754475"},{"comment_id":"733985","poster":"kerar","content":"Selected Answer: B\nAutomatic renewal through DNS happens only when you are using R53 to manage your domains.\n\nhttps://repost.aws/questions/QU4uFrU2dDT4u2-Xsglm-qAg/help-i-am-not-technical-my-aws-certificate-manager-acm-was-unable-to-renew-the-certificate-automatically-using-dns-validation-how-can-i-solve-this?sc_ichannel=ha&sc_ilang=en&sc_isite=repost&sc_iplace=hp&sc_icontent=QU4uFrU2dDT4u2-Xsglm-qAg&sc_ipos=7","upvote_count":"2","timestamp":"1670005980.0"}],"isMC":true,"unix_timestamp":1670004240,"choices":{"C":"The domain has Certification Authority Authorization (CAA) DNS records that allow only specific certificate authorities.","B":"Automatic renewal for domain validation requires the domain to be hosted on Amazon Route 53.","A":"DNS validation requires the domain to be hosted on Amazon Route 53.","D":"DNS validation requires a TXT record instead of a CNAME record."},"url":"https://www.examtopics.com/discussions/amazon/view/89800-exam-aws-certified-security-specialty-topic-1-question-446/","question_text":"A company is using HTTPS for all its public endpoints. A third-party certificate authority (CA) issues the certificates. The company imports the certificates and attaches the certificates to an Elastic Load Balancer or an Amazon CloudFront distribution. The company also is using a third-party DNS hosting provider.\n\nThe certificates are near expiration. The company wants to migrate to AWS Certificate Manager (ACM) with automatic renewal. When the company adds the CNAME record during DNS validation, the certificate status changes to Failed.\n\nWhat is the root cause of this issue?","timestamp":"2022-12-02 19:04:00","question_id":386,"exam_id":29,"question_images":[],"topic":"1"},{"id":"eaanIoJVUuOvuAdCMTpU","exam_id":29,"question_id":387,"discussion":[{"poster":"Balki","timestamp":"1670778960.0","content":"Selected Answer: ADF\nTough question. Instead of exposing your S3 bucket publicly to allow CloudFront to download objects, it is best to keep your bucket private using CloudFront Origin Access Identity (OAI). OAI is a special CloudFront user that is associated with an S3 origin and given the necessary permissions to access to objects within the bucket. Currently, OAI only supports SSE-S3, which means customers cannot use SSE-KMS with OAI.","upvote_count":"18","comment_id":"741923"},{"content":"Selected Answer: ADF\nADF : https://aws.amazon.com/blogs/networking-and-content-delivery/serving-sse-kms-encrypted-content-from-s3-using-cloudfront/","poster":"wmp7039","timestamp":"1688890440.0","comment_id":"946990","upvote_count":"2"},{"comment_id":"933348","content":"Selected Answer: ACF\nACF should be correct","timestamp":"1687678800.0","poster":"OCHT","upvote_count":"2"},{"timestamp":"1684215240.0","content":"Selected Answer: ACF\nOption D is not selected since deleting the OAI configuration will expose the S3 content directly, which isn't ideal considering the security requirements.","upvote_count":"3","comments":[{"upvote_count":"1","poster":"Tofu13","content":"It should be ADF since u cannot use OAI with KMS customer managed keys (see blog post posted by other users)\nWith OAC it is now possible to use KMS.\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/amazon-cloudfront-introduces-origin-access-control-oac/","comment_id":"925915","timestamp":"1686998940.0"}],"comment_id":"898893","poster":"OCHT"},{"timestamp":"1672746840.0","poster":"jishrajesh","upvote_count":"2","comment_id":"764600","content":"Selected adf"},{"poster":"Teknoklutz","upvote_count":"2","comment_id":"763295","content":"Selected Answer: ADF\nADF should be answer","timestamp":"1672597920.0"},{"upvote_count":"3","poster":"ajajajaj","timestamp":"1671174420.0","content":"Please don't give us this question because we won't use OAI anymore!!\nWe can use OAC instead and don't need to worry how to manage KMS.\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html","comment_id":"746894"},{"upvote_count":"3","content":"Selected Answer: ADF\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/serving-sse-kms-encrypted-content-from-s3-using-cloudfront/","comment_id":"737629","timestamp":"1670403900.0","poster":"piter8111"},{"content":"Selected Answer: ADF\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/serving-sse-kms-encrypted-content-from-s3-using-cloudfront/","comment_id":"737283","poster":"Teknoklutz","upvote_count":"2","timestamp":"1670369700.0"},{"comment_id":"736498","timestamp":"1670296380.0","content":"Selected Answer: ADF\ni choose A,D,F\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/serving-sse-kms-encrypted-content-from-s3-using-cloudfront/","poster":"tainh","upvote_count":"4"},{"upvote_count":"1","content":"For the ability to decrypt, I am considering ADF after reading the following: https://aws.amazon.com/blogs/networking-and-content-delivery/serving-sse-kms-encrypted-content-from-s3-using-cloudfront/","comment_id":"736423","poster":"Wilson_S","timestamp":"1670285940.0"},{"timestamp":"1670091240.0","comments":[{"poster":"Phongsanth","timestamp":"1670934240.0","comment_id":"743989","upvote_count":"1","content":"ADF guy\nCheck with this link \n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/serving-sse-kms-encrypted-content-from-s3-using-cloudfront/"}],"comment_id":"734616","upvote_count":"3","content":"Selected Answer: ADE\nADE -\nIf your origin is an Amazon S3 bucket configured as a website endpoint, you must set it up with CloudFront as a custom origin. That means you can't use OAC (or OAI). However, you can restrict access to a custom origin by setting up custom headers and configuring the origin to require them.","poster":"AdamWest"}],"answers_community":["ADF (79%)","13%","8%"],"answer":"ADF","unix_timestamp":1670091240,"url":"https://www.examtopics.com/discussions/amazon/view/89896-exam-aws-certified-security-specialty-topic-1-question-447/","answer_images":[],"question_images":[],"question_text":"A company is designing a solution to serve content from an Amazon CloudFront distribution that will have an Amazon S3 bucket as the origin. A security engineer needs to encrypt S3 data at rest with an AWS Key Management Service (KMS) customer managed key rather than with an S3 managed key. The solution must minimize operational overhead.\n\nWhich combination of steps should the security engineer take to meet these requirements? (Choose three.)","answer_description":"","timestamp":"2022-12-03 19:14:00","answer_ET":"ADF","isMC":true,"choices":{"F":"Create a Lambda@Edge function that runs for origin request events and reads from the S3 bucket by using the customer managed KMS key.","B":"Create the S3 bucket. Configure server-side encryption with customer-provided encryption keys (SSE-C).","E":"Configure the CloudFront distribution cache to encrypt data at rest by using the customer managed KMS key.","D":"Create the CloudFront distribution. Use the S3 bucket as the origin. Delete the origin access identity (OAI) configuration.","C":"Create the CloudFront distribution. Use the S3 bucket as the origin. Configure the distribution to use an origin access identity (OAI).","A":"Create the S3 bucket. Configure server-side encryption with a customer managed KMS key."},"topic":"1"},{"id":"YZq9ePfmlJ6Wtqo21uEV","isMC":true,"choices":{"C":"Modify the aws-auth-cm.yaml file to include the IAM role for the security engineer.","B":"Configure the AWS CLI to use us-east-1.","A":"Obtain a new authorization token.","D":"Activate AWS Security Token Service (AWS STS) in us-east-1."},"url":"https://www.examtopics.com/discussions/amazon/view/89803-exam-aws-certified-security-specialty-topic-1-question-448/","topic":"1","answer_images":[],"answers_community":["B (100%)"],"question_images":[],"answer":"B","question_text":"A security engineer is attempting to push a Linux-based container image to an Amazon Elastic Container Registry (Amazon ECR) repository that is in the us-east-1 Region. The security engineer has retrieved an authentication token by using the aws ecr get-login-password AWS CLI command within the last 4 hours. The security engineer has confirmed that the correct permissions are in place to push the container image to the repository.\n\nWhen the security engineer tries to push the container image, the security engineer receives the following error: “no basic auth credentials”.\n\nWhat should the security engineer do to resolve this error?","answer_description":"","question_id":388,"answer_ET":"B","unix_timestamp":1670006940,"timestamp":"2022-12-02 19:49:00","discussion":[{"content":"Selected Answer: B\nAuthentication requests are tied to specific regions, and cannot be used across regions. To resolve the issue, ensure that you have retrieved an authentication token from the same Region your repository exists in.\n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/common-errors-docker.html#error-403","poster":"kerar","timestamp":"1670006940.0","comment_id":"733996","upvote_count":"9"},{"comment_id":"908391","content":"Selected Answer: B\nHTTP 403 Errors or \"no basic auth credentials\" error when pushing to repository\nThere are times when you may receive an HTTP 403 (Forbidden) error, or the error message no basic auth credentials from the docker push or docker pull commands, even if you have successfully authenticated to Docker using the aws ecr get-login-password command. The following are some known causes of this issue:\n\nYou have authenticated to a different region\nAuthentication requests are tied to specific regions, and cannot be used across regions. For example, if you obtain an authorization token from US West (Oregon), you cannot use it to authenticate against your repositories in US East (N. Virginia). To resolve the issue, ensure that you have retrieved an authentication token from the same Region your repository exists in. For more information, see Private registry authentication.","upvote_count":"3","poster":"pal40sg","timestamp":"1685257440.0"},{"poster":"Balki","upvote_count":"2","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/common-errors-docker.html#error-403","timestamp":"1670779200.0","comment_id":"741925"}],"exam_id":29},{"id":"Tbvv36BqOLDD3nOKq58T","answer_ET":"BE","answer_images":[],"answer":"BE","question_text":"A security engineer is trying to use Amazon EC2 Image Builder to create an image of an EC2 instance. The security engineer has configured the pipeline to send logs to an Amazon S3 bucket. When the security engineer runs the pipeline, the build fails with the following error: “AccessDenied: Access Denied status code: 403”.\n\nThe security engineer must resolve the error by implementing a solution that complies with best practices for least privilege access.\n\nWhich combination of steps will meet these requirements? (Choose two.)","discussion":[{"comment_id":"739998","poster":"BK__","comments":[{"timestamp":"1670582100.0","poster":"BK__","content":"The engineer is not the one that needs the permissions but the EC2 instance","comment_id":"740000","upvote_count":"4"}],"timestamp":"1670582040.0","upvote_count":"9","content":"Selected Answer: BE\nANS is BE\n\nFor those supporting \"A\", the instance profile is an IAM role for the EC2 instance. A says the IAM role attached to the engineer and this is wrong. B is instance profile which is the same as IAM role for the EC2 instance."},{"timestamp":"1673165280.0","comment_id":"769181","poster":"secdaddy","upvote_count":"8","content":"The rights are clearly listed here, supporting BE\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/image-builder-setting-up.html#image-builder-IAM-prereq","comments":[{"poster":"AzureDP900","upvote_count":"2","timestamp":"1677983700.0","comment_id":"829571","content":"Thx for sharing link"}]},{"timestamp":"1692096540.0","content":"Selected Answer: AD\n\nTo meet the requirements of resolving the \"Access Denied\" error with Amazon EC2 Image Builder while adhering to best practices for least privilege access, the following steps should be taken:\n\nA. Ensure that the following policies are attached to the IAM role that the security engineer is using: EC2InstanceProfileForImageBuilder, EC2InstanceProfileForImageBuilderECRContainerBuilds, and AmazonSSMManagedInstanceCore.\n\nD. Ensure that the security engineer’s IAM role has the s3:PutObject permission for the S3 bucket.","poster":"Noexperience","upvote_count":"1","comment_id":"981557"},{"comment_id":"940361","poster":"jeff001","content":"Selected Answer: BE\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/troubleshooting.html#ts-access-denied","timestamp":"1688254560.0","upvote_count":"2"},{"upvote_count":"1","comment_id":"933694","poster":"francinetanzx","content":"Selected Answer: BE\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/troubleshooting.html","timestamp":"1687704060.0"},{"comment_id":"894714","content":"Selected Answer: AD\nIn the context of the scenario, the best combination would be A and D.\n\nHere's why:\n\nThe IAM role that the security engineer is using to interact with Amazon EC2 Image Builder needs to have the right policies attached. The policies mentioned in Option A (EC2InstanceProfileForImageBuilder, EC2InstanceProfileForImageBuilderECRContainerBuilds, and AmazonSSMManagedInstanceCore) provide the necessary permissions to create and manage EC2 instances for Image Builder, build and test the image, and use Systems Manager capabilities.\n\nOption D ensures that the security engineer's IAM role has the permissions needed to write logs to the S3 bucket. It's crucial for the role used to run the pipeline to have this permission, as the pipeline's logs are being sent to an S3 bucket.","timestamp":"1683790080.0","poster":"OCHT","upvote_count":"1","comments":[{"content":"The other combinations have a key issue - they suggest attaching the necessary permissions to the instance profile for the EC2 instance (Options B and E). However, the permissions needed to run the pipeline and write logs to the S3 bucket should be attached to the IAM role that the security engineer is using to interact with EC2 Image Builder, not the instance profile for the EC2 instance itself.","timestamp":"1683790200.0","comment_id":"894717","poster":"OCHT","upvote_count":"1"}]},{"comment_id":"828067","upvote_count":"4","poster":"bwestpha","timestamp":"1677856020.0","content":"Selected Answer: BE\ni checked BE"},{"timestamp":"1676446440.0","upvote_count":"1","comment_id":"809246","content":"Selected Answer: BE\nVote for BE. The permission of the user who runs the pipeline is irrelevant.","poster":"PatrickLi"},{"timestamp":"1672597980.0","upvote_count":"1","content":"Selected Answer: BE\nBE Correct Answer","comment_id":"763296","poster":"Teknoklutz"},{"comment_id":"737601","upvote_count":"6","timestamp":"1670402640.0","content":"Selected Answer: BE\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/troubleshooting.html - Access denied – status code 403","poster":"piter8111"},{"timestamp":"1670297160.0","comment_id":"736500","upvote_count":"4","content":"Selected Answer: BE\nB,E are correct\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/troubleshooting.html#ts-access-denied","poster":"tainh"},{"poster":"Wilson_S","content":"Link supporting A and E: https://docs.aws.amazon.com/imagebuilder/latest/userguide/image-builder-setting-up.html","comments":[{"upvote_count":"2","content":"Sorry! B and E.","timestamp":"1671565800.0","poster":"Wilson_S","comment_id":"751413"}],"comment_id":"736434","upvote_count":"1","timestamp":"1670286900.0"},{"upvote_count":"5","timestamp":"1670258700.0","poster":"AdamWest","comment_id":"736114","content":"Selected Answer: AE\nAE is the answer -\nE = The instance profile role is missing permissions that are required for logging to Amazon S3. Most commonly, this occurs when the instance profile role does not have PutObject permissions for your S3 buckets.\n\nA = An instance profile is a container for an IAM role that you can use to pass role information to an Amazon EC2 instance when the instance starts. You can tag instance profiles when you use the AWS CLI or AWS API. You can use IAM tag key-value pairs to add custom attributes to an instance profile. \nThe IAM role that you associate with your instance profile must have permissions to run the build and test components included in your image. The following IAM role policies must be attached to the IAM role that is associated with the instance profile:\nEC2InstanceProfileForImageBuilder\nEC2InstanceProfileForImageBuilderECRContainerBuilds\nAmazonSSMManagedInstanceCore\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/security_iam_service-with-iam.html"},{"content":"BE\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/troubleshooting.html#troubleshooting-pipelines\nThe instance profile is the one which should have the perm","poster":"Saklani","comment_id":"734766","timestamp":"1670114940.0","upvote_count":"2"},{"timestamp":"1670007300.0","comment_id":"734001","content":"Selected Answer: AE\nInstance profile is missing managed policies – Add the missing policies to your instance profile role. Then run the pipeline again.\n\nInstance profile is missing write permissions for S3 bucket – Add a policy to your instance profile role that grants PutObject permissions to write to your S3 bucket. Then run the pipeline again.\n\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/troubleshooting.html#troubleshooting-pipelines","upvote_count":"5","poster":"kerar"},{"comment_id":"732614","timestamp":"1669898700.0","poster":"kishore1212","upvote_count":"1","content":"Selected Answer: BE\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/troubleshooting.html#troubleshooting-pipelines\n Instance profile should have permissions"},{"upvote_count":"4","timestamp":"1669847100.0","comment_id":"732055","poster":"[Removed]","content":"Answer should be A,E"}],"timestamp":"2022-11-30 23:25:00","question_images":[],"choices":{"D":"Ensure that the security engineer’s IAM role has the s3:PutObject permission for the S3 bucket.","E":"Ensure that the instance profile for the EC2 instance has the s3:PutObject permission for the S3 bucket.","B":"Ensure that the following policies are attached to the instance profile for the EC2 instance: EC2InstanceProfileForImageBuilder, EC2InstanceProfileForImageBuilderECRContainerBuilds, and AmazonSSMManagedInstanceCore.","C":"Ensure that the AWSImageBuilderFullAccess policy is attached to the instance profile for the EC2 instance.","A":"Ensure that the following policies are attached to the IAM role that the security engineer is using: EC2InstanceProfileForImageBuilder, EC2InstanceProfileForImageBuilderECRContainerBuilds, and AmazonSSMManagedInstanceCore."},"unix_timestamp":1669847100,"isMC":true,"question_id":389,"url":"https://www.examtopics.com/discussions/amazon/view/89465-exam-aws-certified-security-specialty-topic-1-question-449/","topic":"1","answer_description":"","exam_id":29,"answers_community":["BE (73%)","AE (25%)","3%"]},{"id":"TbOAsrCP1rSWsAb9SZCN","exam_id":29,"answers_community":["B (100%)"],"topic":"1","timestamp":"2019-06-29 09:08:00","isMC":true,"answer_ET":"B","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/2062-exam-aws-certified-security-specialty-topic-1-question-45/","question_id":390,"discussion":[{"upvote_count":"54","comment_id":"17922","timestamp":"1633297260.0","content":"Answer : Send the local text log files to CloudWatch Logs and configure a CloudWatch metric filter. Trigger cloudWatch alarms based on the metrics.\n\nExplanation Answer – B One can send the log files to Cloudwatch Logs. Log files can also be sent from On-premise servers. You can then specify metrics to search the logs for any specific values. And then create alarms based on these metrics. Option A is invalid because this will be just a long over drawn process to achieve this requirement Option C is invalid because AWS Inspector cannot be used to monitor for security related messages. Option D is invalid because files cannot be exported to AWS Cloudtrail For more information on Cloudwatch logs agent, please visit the below URL https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html","poster":"sarava"},{"timestamp":"1632711000.0","upvote_count":"26","comment_id":"12935","comments":[{"poster":"Mike_1","content":"B is the ans assuming it is an Ec2 instance!!","timestamp":"1635306780.0","upvote_count":"2","comment_id":"213536"}],"poster":"josellama2000","content":"B is correct, \nYou can set your application to send logs and cloudwatch to receive them using the cloudwatrch agent. A Lambda is not necessary\nhttps://aws.amazon.com/blogs/devops/new-how-to-better-monitor-your-custom-application-metrics-using-amazon-cloudwatch-agent/"},{"timestamp":"1709692260.0","upvote_count":"1","comment_id":"1166887","poster":"Raphaello","content":"Selected Answer: B\nCW Logs + CW metric filter + CW alarm (and possibly +Lambda function in some other cases).\nB is the correct answer"},{"upvote_count":"1","timestamp":"1689614940.0","comment_id":"954443","content":"B\n\nCorrect. You can see all of your logs, regardless of their source, as a single and consistent flow of events ordered in time by using CloudWatch Logs. You can query and sort your logs based on other dimensions, group them by specific fields, create custom computations by using a query language, and visualize log data on the dashboards.\n\nFor more information about CloudWatch Logs, see What is Amazon CloudWatch Logs? \n\nFor more information about CloudWatch metric filters, see Creating metrics from log events using filters.","poster":"osojg"},{"timestamp":"1683544560.0","content":"Selected Answer: B\nB is correct.","poster":"bbddmm","upvote_count":"1","comment_id":"892061"},{"poster":"pearl15","comments":[{"upvote_count":"1","content":"true!!","poster":"Andrii223","comment_id":"933636","timestamp":"1687699620.0"}],"timestamp":"1674002160.0","comment_id":"779428","content":"It's wrongly worded question. No where the question says that Application is running on EC2 instance. Had the application been running on EC2 instances, it's no brainer that B is correct. But in the current form of Question, answer can be D as well.","upvote_count":"4"},{"comment_id":"772857","content":"Selected Answer: B\nB the right one. no discussion.","timestamp":"1673467920.0","upvote_count":"1","poster":"xplusfb"},{"timestamp":"1668962220.0","upvote_count":"1","content":"B is correct","poster":"skillz2investor","comment_id":"722794"},{"upvote_count":"1","poster":"arae","comment_id":"691405","content":"B it is","timestamp":"1665425520.0"},{"comment_id":"635270","content":"Selected Answer: B\nB makes sense to me as the simple way to do it.","timestamp":"1658505180.0","poster":"dcasabona","upvote_count":"1"},{"comment_id":"615684","content":"Selected Answer: B\nThis is what CloudWatch logs agent is designed for","timestamp":"1655104440.0","upvote_count":"2","poster":"Kurp"},{"content":"Selected Answer: B\nmakes more sense","timestamp":"1654216560.0","comment_id":"610843","poster":"remyy","upvote_count":"1"},{"comment_id":"551375","timestamp":"1645309800.0","poster":"RaySmith","content":"B is correct","upvote_count":"1"},{"comment_id":"548507","upvote_count":"1","content":"Selected Answer: B\nCloudwatch logs agent is the best way to achieve this","poster":"amaltare","timestamp":"1645009260.0"},{"content":"Selected Answer: B\nB makes most sense","timestamp":"1644770520.0","poster":"MoreOps","comment_id":"546581","upvote_count":"1"},{"content":"\"Least Effort\" B is the most correct answer.","comment_id":"531820","upvote_count":"1","poster":"fortune","timestamp":"1643084040.0"},{"content":"Selected Answer: B\nB is correct","timestamp":"1642689960.0","comment_id":"528490","upvote_count":"1","poster":"lotfi50"},{"comment_id":"522327","upvote_count":"1","poster":"SaucyVip3r","timestamp":"1642007100.0","content":"Selected Answer: B\nB One can send the log files to Cloudwatch Logs. Log files can also be sent from On-premise servers. You can then specify metrics to search the logs for any specific values. And then create alarms based on these metrics. Option A is invalid because this will be just a long over drawn process to achieve this requirement Option C is invalid because AWS Inspector cannot be used to monitor for security related messages. Option D is invalid because files cannot be exported to AWS Cloudtrail For more information on Cloudwatch logs agent, please visit the below URL https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html"},{"timestamp":"1641072180.0","upvote_count":"1","content":"B seems like least effort","comment_id":"514689","poster":"jj22222"},{"timestamp":"1640709780.0","comment_id":"511346","content":"B. Install and configure the Amazon CloudWatch Logs agent on the applicationג€™s EC2 instance. Create a CloudWatch metric filter to monitor the application logs. Set up CloudWatch alerts based on the metrics.","poster":"jj22222","upvote_count":"1"},{"timestamp":"1636174620.0","content":"B is my answer.!","comment_id":"437306","poster":"hk436","upvote_count":"1"},{"upvote_count":"1","timestamp":"1636161900.0","poster":"Kdosec","comment_id":"397954","content":"the requirements with MINIMUM effort, so B is correct one, the Cloudwatch log agent could be run on-premise server or EC2. But the case if App is running on a serverless service, there is no correct answer. The question's information is not clear, and A is really a complicated solution."},{"content":"A is more appropriate as there was no reference to the application running in AWS. If it's on-prem or AWS, option A should work.\n\nOption B will work only if the application is in AWS.","upvote_count":"2","comment_id":"358846","comments":[{"poster":"Daniel76","upvote_count":"2","content":"Option B - CloudWatch agent can be installed on instances running on prem (outside AWS).\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/install-CloudWatch-Agent-on-premise.html","comment_id":"369094","timestamp":"1636149180.0"}],"poster":"awscerti","timestamp":"1636070280.0"},{"timestamp":"1635859920.0","upvote_count":"1","content":"Ans: B 100%","comment_id":"353896","poster":"sanjaym"},{"upvote_count":"1","content":"B is the correct answer","poster":"Edgecrusher77","timestamp":"1635559380.0","comment_id":"314055"},{"poster":"GVGREAT","upvote_count":"1","comment_id":"281765","content":"B is the answer. Application should send the logs for continuous monitoring, not a scheduled collection of logs.","timestamp":"1635546480.0"},{"comment_id":"276203","content":"B is Correct","upvote_count":"2","timestamp":"1635539100.0","poster":"NANDY666"},{"upvote_count":"1","content":"B; textbook case.","comment_id":"240583","poster":"blaker00","timestamp":"1635532980.0"},{"upvote_count":"1","poster":"EricR17","content":"I believe B is the answer. This is a text-book use-case for CloudWatch Logs and Metrics.","comment_id":"236890","timestamp":"1635524460.0"},{"comments":[{"comment_id":"229838","timestamp":"1635379200.0","content":"I meant B.","upvote_count":"1","poster":"shooricg"}],"poster":"shooricg","timestamp":"1635378840.0","upvote_count":"1","comment_id":"229837","content":"I only say A, because of the previous question and how it was answered. Normally would say C, deploy a CloudWatch agent."},{"upvote_count":"1","timestamp":"1635344820.0","comment_id":"221896","content":"Ans > B","poster":"devjava"},{"timestamp":"1635276240.0","comment_id":"207459","upvote_count":"1","comments":[{"poster":"ChinkSantana","content":"How do you copy application logfiles to Cloudtrail? Never heard of that so C is completely wrong","upvote_count":"1","timestamp":"1635702540.0","comment_id":"319743"}],"content":"Ans (C)","poster":"AfricanCloudGuru"},{"timestamp":"1634998800.0","comment_id":"207458","poster":"AfricanCloudGuru","content":"Ans (C)","upvote_count":"1"},{"upvote_count":"1","poster":"Ayusef","content":"B..is the best answer due to simplicity of the solution. A.. Is Also applicable but it overly complicate.","comment_id":"199849","timestamp":"1634876640.0"},{"comment_id":"99263","content":"B is a minimum affort","poster":"wzlinux","timestamp":"1634740800.0","upvote_count":"1"},{"poster":"ADVIT","content":"B is a minimum affort","comment_id":"78699","timestamp":"1634636340.0","upvote_count":"2"},{"poster":"RaySmith","content":"B is correct","comment_id":"76026","upvote_count":"2","timestamp":"1634625120.0"},{"poster":"ssubbu","upvote_count":"3","comment_id":"72180","content":"B, that enables continuous monitoring of application logs.","timestamp":"1634598840.0"},{"upvote_count":"2","timestamp":"1634388600.0","poster":"tomtom2020","comment_id":"70755","content":"it's B. the CW agent can collect the log for analyzing"},{"upvote_count":"3","content":"B. https://www.youtube.com/watch?v=vAnIhIwE5hY","poster":"LA1985","timestamp":"1634187660.0","comment_id":"55174"},{"content":"continous monitoring and you guys choose A?\nhave you no shame, or brain, or both?","upvote_count":"9","comment_id":"47962","timestamp":"1634119920.0","comments":[{"timestamp":"1634677140.0","upvote_count":"1","poster":"TechGuru","content":"hehe.... :)","comment_id":"79724"},{"poster":"samCarson","comment_id":"104343","content":"omg kinda harsh... But \"B\" is the answer guys. Goodluck for those who will be taking the exam.","upvote_count":"1","timestamp":"1634790780.0"}],"poster":"AdamSmith"},{"upvote_count":"2","comment_id":"47009","poster":"NanaO","timestamp":"1634062740.0","content":"B is the answer. Its better to use CloudWatch Agent to monitor continuoulsy. Then filter the logs and create alerts."},{"content":"B with minimal effort.","comment_id":"45676","upvote_count":"2","poster":"RakeshTaninki","timestamp":"1633763640.0"},{"timestamp":"1633738200.0","comment_id":"43081","upvote_count":"1","content":"B is the correct answer for the minimal efforts.\nJust need to configure cloudwatch logs agent, cloudwatch metric filter on above logs, setup alarm.","poster":"RakeshTaninki"},{"timestamp":"1633730880.0","content":"I think the answer is B for MINIMUM effort\nIf A, you need to write a schedule process to copy log to S3, configure an S3 bucket, write an Lambda function to analyze the log file...","upvote_count":"3","comment_id":"35278","poster":"AnNguyen"},{"comment_id":"30503","comments":[{"timestamp":"1634702940.0","upvote_count":"1","poster":"inf","comment_id":"89958","content":"indeed - the MOST important statement. Its a security requirement and must be real-time."}],"content":"\"logs must be continuously monitored for security incidents \" : we can not achieve it using scheduled process .\ntherefore , i think B Should be correct answer","timestamp":"1633627560.0","poster":"Raj1510","upvote_count":"4"},{"upvote_count":"2","poster":"Raj1510","comment_id":"30502","timestamp":"1633389180.0","content":"\"logs must be continuously monitored for security incidents \" : we can achieve it using scheduled process .\ntherefore , i think B Should be correct answer"},{"comment_id":"23674","content":"A is correct","poster":"Danao","timestamp":"1633382760.0","upvote_count":"1","comments":[{"timestamp":"1634684580.0","poster":"Firststack","comment_id":"81240","upvote_count":"1","content":"I agree. B is the answer.\nHowever, are there situations where is more efficient to use lambda over cloud cloud-watch agent for logs reporting?"}]},{"timestamp":"1633139220.0","comment_id":"13378","upvote_count":"14","poster":"exams","content":"B is correct answer. Cloudwatch agent does all this work of moving data to S3 and lambda. We don't have to create create custom scheduler. and the solution is scalable as well"},{"comments":[{"poster":"EricJason","comment_id":"13924","content":"i dont think setup a Lambda and S3 is MINIMUM effort.","timestamp":"1633180920.0","upvote_count":"1"},{"upvote_count":"1","poster":"Henrydred","timestamp":"1634658720.0","comment_id":"78912","content":"because of scalability?...hope u re aware u introduced scalability into the scenario as it was not mentioned in the question....Minimum effort shd be over key word hence d ans is"}],"content":"sorry. The most efficient way, because of scalability for the fleet is A.\nSo correct is A. Agreed with ISNAR","comment_id":"12936","poster":"josellama2000","upvote_count":"2","timestamp":"1632718320.0"},{"content":"A is the correct answer for sure","upvote_count":"1","timestamp":"1632642180.0","poster":"INASR","comment_id":"10835"},{"content":"A or B?","timestamp":"1632549300.0","upvote_count":"1","poster":"duduga40","comment_id":"10663","comments":[{"timestamp":"1632696120.0","comment_id":"12774","upvote_count":"12","content":"B is right.","poster":"cloudguy365"}]},{"poster":"Osemk","comments":[{"comment_id":"213535","timestamp":"1635278580.0","content":"B is the ans assuming it is an Ec2 instance","poster":"Mike_1","upvote_count":"1"}],"timestamp":"1632450060.0","comment_id":"10371","upvote_count":"1","content":"To me the answer is A. This is the least invasive solution"},{"comment_id":"10358","poster":"Osemk","timestamp":"1632389640.0","content":"A is the answer to me","upvote_count":"1"},{"content":"sorry made a mistake I meant to say Answer is B.","timestamp":"1632342180.0","upvote_count":"7","poster":"polo","comment_id":"9356"},{"upvote_count":"2","comments":[{"upvote_count":"2","content":"Option B doesnt have CloudTrail stated, where do u see it? or the options has been changed??","poster":"ugreenhost","comment_id":"9959","timestamp":"1632360660.0"}],"poster":"polo","timestamp":"1632217860.0","comment_id":"9354","content":"C.\n\nHow can it be B? Cloudtrail is for APIs and I cant find anywhere where it says you can push logs to cloud trail. You can push logs to CLoudwatch tho"},{"poster":"dpvnme","content":"A does way more work than B. So B would be minimal effort. Cloudtrail is for API log, not application log.","timestamp":"1632173880.0","comment_id":"5595","upvote_count":"5"},{"comment_id":"5430","poster":"rm29","timestamp":"1632095220.0","upvote_count":"1","content":"A. It'e essentially a custom application that outputs its own logs. Therefore, the best adaptation is to shove the logs into an s3 bucket then set up CloudWatch metrics with alerts. You can't shove logs directly into CloudTrail and expect it to adapt."},{"comment_id":"3311","timestamp":"1632082140.0","poster":"sensor","upvote_count":"2","content":"I beleave is C"}],"answer":"B","question_text":"An application outputs logs to a text file. The logs must be continuously monitored for security incidents.\nWhich design will meet the requirements with MINIMUM effort?","answer_description":"","unix_timestamp":1561792080,"choices":{"A":"Create a scheduled process to copy the component's logs into Amazon S3. Use S3 events to trigger a Lambda function that updates Amazon CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics.","C":"Create a scheduled process to copy the application log files to AWS CloudTrail. Use S3 events to trigger Lambda functions that update CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics.","B":"Install and configure the Amazon CloudWatch Logs agent on the application's EC2 instance. Create a CloudWatch metric filter to monitor the application logs. Set up CloudWatch alerts based on the metrics.","D":"Create a file watcher that copies data to Amazon Kinesis when the application writes to the log file. Have Kinesis trigger a Lambda function to update Amazon CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics."},"answer_images":[]}],"exam":{"isImplemented":true,"isBeta":false,"provider":"Amazon","id":29,"numberOfQuestions":509,"isMCOnly":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Security - Specialty"},"currentPage":78},"__N_SSP":true}