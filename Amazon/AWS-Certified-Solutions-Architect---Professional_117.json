{"pageProps":{"questions":[{"id":"VzgpgSjN5piSqAdmf4An","url":"https://www.examtopics.com/discussions/amazon/view/28290-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"C","answer_images":[],"answer":"C","exam_id":32,"answers_community":["C (100%)"],"discussion":[{"upvote_count":"21","poster":"Nemer","content":"C. Create CMK with origin EXTERNAL.\nhttps://aws.amazon.com/blogs/security/how-to-byok-bring-your-own-key-to-aws-kms-for-less-than-15-00-a-year-using-aws-cloudhsm/","timestamp":"1632368820.0","comment_id":"156522"},{"content":"C is my choice","timestamp":"1634547420.0","upvote_count":"6","comment_id":"285327","poster":"Ebi"},{"poster":"et22s","comment_id":"717190","upvote_count":"1","content":"Selected Answer: C\nC: KMS keys designed for imported key material have an origin value of EXTERNAL that cannot be changed. You cannot convert a KMS key for imported key material to use key material from any other source, including AWS KMS.\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html#importing-keys-considerations","timestamp":"1668329280.0"},{"upvote_count":"1","poster":"pankajrawat","content":"Selected Answer: C\nC is the correct answer","timestamp":"1651379040.0","comment_id":"595430"},{"poster":"AzureDP900","timestamp":"1638912240.0","content":"I will go with C","comment_id":"496340","upvote_count":"1"},{"comment_id":"495095","content":"C. Create a CMK in AWS KMS with no key material and an origin of EXTERNAL. Import the key material generated from the on-premises HSMs into the CMK using the public key and import token provided by AWS. Configure a bucket policy on the logging bucket that disallows uploads of non-encrypted data and requires that the encryption source be AWS KMS.","timestamp":"1638791700.0","poster":"cldy","upvote_count":"1"},{"upvote_count":"1","comment_id":"491089","content":"C is correct answer !","poster":"AzureDP900","timestamp":"1638318840.0"},{"timestamp":"1637660760.0","poster":"backfringe","upvote_count":"1","comment_id":"484919","content":"I go with C"},{"comment_id":"482939","timestamp":"1637453880.0","poster":"acloudguru","upvote_count":"2","content":"Selected Answer: C\nC,https://aws.amazon.com/blogs/security/how-to-byok-bring-your-own-key-to-aws-kms-for-less-than-15-00-a-year-using-aws-cloudhsm/"},{"timestamp":"1636217220.0","upvote_count":"1","poster":"tgv","content":"CCC\n---","comment_id":"436133"},{"content":"C is the answer.","poster":"blackgamer","comment_id":"433182","timestamp":"1636197000.0","upvote_count":"1"},{"poster":"WhyIronMan","comment_id":"413237","upvote_count":"1","content":"I'll go with C","timestamp":"1634790240.0"},{"poster":"Waiweng","timestamp":"1634789940.0","comment_id":"353669","upvote_count":"3","content":"it;s C"},{"poster":"kopper2019","comment_id":"269787","timestamp":"1634270040.0","upvote_count":"5","content":"it's C\n\nStep 1: Create the CMK with no key material associated\nBegin by creating a customer master key (CMK) in AWS KMS that has no key material associated. The CLI command to create the CMK is as follows:\n\n$ aws kms create-key --origin EXTERNAL --region us-east-1\n\nIf successful, you’ll see an output on the CLI similar to below. The KeyState will be PendingImport and the Origin will be EXTERNAL."},{"upvote_count":"1","poster":"T14102020","timestamp":"1633359420.0","comment_id":"244747","content":"Correct is C. Create CMK with origin EXTERNAL."},{"upvote_count":"4","content":"I'll go with C","comment_id":"232420","timestamp":"1632829020.0","poster":"jackdryan"},{"upvote_count":"2","timestamp":"1632693720.0","poster":"CYL","comment_id":"208550","content":"C. https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys-create-cmk.html"},{"comment_id":"205443","poster":"Bulti","content":"Answer is C","upvote_count":"1","timestamp":"1632561360.0"}],"isMC":true,"question_text":"A financial services company logs personally identifiable information to its application logs stored in Amazon S3. Due to regulatory compliance requirements, the log files must be encrypted at rest. The security team has mandated that the company's on-premises hardware security modules (HSMs) be used to generate the\nCMK material.\nWhich steps should the solutions architect take to meet these requirements?","choices":{"C":"Create a CMK in AWS KMS with no key material and an origin of EXTERNAL. Import the key material generated from the on-premises HSMs into the CMK using the public key and import token provided by AWS. Configure a bucket policy on the logging bucket that disallows uploads of non-encrypted data and requires that the encryption source be AWS KMS.","D":"Create a new CMK in AWS KMS with AWS-provided key material and an origin of AWS_KMS. Disable this CMK, and overwrite the key material with the key material from the on-premises HSM using the public key and import token provided by AWS. Re-enable the CMK. Enable automatic key rotation on the CMK with a duration of 1 year. Configure a bucket policy on the logging bucket that disallows uploads of non-encrypted data and requires that the encryption source be AWS KMS.","B":"Provision an AWS Direct Connect connection, ensuring there is no overlap of the RFC 1918 address space between on-premises hardware and the VPCs. Configure an AWS bucket policy on the logging bucket that requires all objects to be encrypted. Configure the logging application to query the on-premises HSMs from the AWS environment for the encryption key material, and create a unique CMK for each logging event.","A":"Create an AWS CloudHSM cluster. Create a new CMK in AWS KMS using AWS_CloudHSM as the source for the key material and an origin of AWS_CLOUDHSM. Enable automatic key rotation on the CMK with a duration of 1 year. Configure a bucket policy on the logging bucket that disallows uploads of unencrypted data and requires that the encryption source be AWS KMS."},"timestamp":"2020-08-12 16:39:00","question_images":[],"question_id":581,"answer_description":"","unix_timestamp":1597243140,"topic":"1"},{"id":"tjn5yzOhI5pTLNhD8v0o","url":"https://www.examtopics.com/discussions/amazon/view/28311-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"comment_id":"156596","timestamp":"1632075240.0","poster":"Nemer","content":"B.\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/integrating_cloudformation.html","upvote_count":"23"},{"upvote_count":"1","content":"Selected Answer: B\nB. Create a new AWS Secrets Manager secret resource in the CloudFormation template to be used as the database password. Configure the application to retrieve the password from Secrets Manager when needed. Reference the secret resource for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using a dynamic reference.","comment_id":"940398","poster":"SkyZeroZx","timestamp":"1688261400.0"},{"poster":"maxh8086","comments":[{"comment_id":"768308","content":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html\n\nFor example, suppose in your template you specify the MasterPassword property of an AWS::RDS::DBInstance resource to be a secretsmanager dynamic reference, and then create a stack from the template. You later update that secret's value in Secrets Manager, but don't update the AWS::RDS::DBInstance resource in your template. In this case, even if you perform a stack update, the secret value in the MasterPassword property isn't updated, and remains the previous secret value.","timestamp":"1673077260.0","poster":"maxh8086","comments":[{"upvote_count":"1","content":"https://docs.aws.amazon.com/secretsmanager/latest/userguide/cfn-example_RDSsecret.html\n\ni do not see parameteres defined under User Data property, rather i see Dynamic reference object under template - B","poster":"maxh8086","timestamp":"1673077740.0","comment_id":"768321"}],"upvote_count":"1"}],"content":"Key : securely manage the configuration of the application's database credentials (not the create template for password rotation)\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/security-best-practices.html#creds\n\nUpdating a secret in Secrets Manager doesn't automatically update the secret in CloudFormation. In order for CloudFormation to update a secretsmanager dynamic reference, you must perform a stack update that updates the resource containing the dynamic reference, either by updating the resource property that contains the secretsmanager dynamic reference, or updating another of the resource's properties.","comment_id":"768307","timestamp":"1673077260.0","upvote_count":"1"},{"upvote_count":"2","comment_id":"603292","content":"Selected Answer: B\nB no-brainer.\nRDS creds, rotation - Secret Manager","poster":"bobsmith2000","timestamp":"1652878740.0"},{"comment_id":"497575","content":"B. Create a new AWS Secrets Manager secret resource in the CloudFormation template to be used as the database password. Configure the application to retrieve the password from Secrets Manager when needed. Reference the secret resource for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using a dynamic reference.","poster":"cldy","timestamp":"1639044360.0","upvote_count":"1"},{"timestamp":"1638912480.0","upvote_count":"1","content":"B is right","comment_id":"496341","poster":"AzureDP900"},{"comment_id":"436136","content":"BBB\n---","poster":"tgv","timestamp":"1636203420.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1636152900.0","comment_id":"413241","content":"I'll go with B","poster":"WhyIronMan"},{"comment_id":"384147","content":"B.\nC hardcodes the passwords in the script and the new password will be lost after 60 days","upvote_count":"3","timestamp":"1635928140.0","poster":"Balki"},{"upvote_count":"2","poster":"blackgamer","content":"The solution is B as it is required for password rotation too.","comment_id":"357556","timestamp":"1635612900.0"},{"poster":"Waiweng","upvote_count":"3","comment_id":"353673","content":"it's B","timestamp":"1635163020.0"},{"comment_id":"342066","timestamp":"1635045060.0","poster":"Amitv2706","upvote_count":"1","content":"B. For Secret Rotation which is provided only by Secret Manager"},{"timestamp":"1634967000.0","comment_id":"303233","poster":"AJBA","upvote_count":"3","content":"B https://aws.amazon.com/blogs/security/how-to-create-and-retrieve-secrets-managed-in-aws-secrets-manager-using-aws-cloudformation-template/#aws-comment-trigger-8922:~:text=The%20secret%20(username%20and%20password%20for,BackupRetentionPeriod%3A%200"},{"timestamp":"1634901120.0","content":"C is correct. good option with Ref function ( https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-secretsmanager-secrettargetattachment.html ) ; for B, Dynamic references for secure values, such as ssm-secure and secretsmanager, are not currently supported;","comment_id":"296564","upvote_count":"2","comments":[{"timestamp":"1636297560.0","content":"You definitely CAN use a dynamic reference for secretsmanager for an RDS DB password, even with rotation:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html\n\nBut I'm not saying you're wrong, it appears from that document you referenced, you definitely CAN do this with the Ref function as well.\n\nSo it appears B and C are both feasible answers. It would come down to which one you think is the better answer. And that might be a matter of personal preference?","poster":"kirrim","upvote_count":"1","comment_id":"462125"}],"poster":"natpilot"},{"upvote_count":"2","comment_id":"292602","timestamp":"1634595600.0","poster":"Kian1","content":"going with B"},{"content":"Answer is B","poster":"Ebi","upvote_count":"4","comment_id":"267650","timestamp":"1634579760.0"},{"upvote_count":"3","poster":"Bulti","timestamp":"1634446320.0","comment_id":"253871","content":"Answer is B. You need to reference secret from secret manager dynamically in the CloudFormation template where the RDS resource is configured. Loading it as part of the userdata script is not secure."},{"comment_id":"244749","content":"Correct is B. Secrets Manager + dynamic function","poster":"T14102020","upvote_count":"1","timestamp":"1634412120.0"},{"timestamp":"1633952760.0","comments":[{"upvote_count":"3","timestamp":"1634042280.0","comment_id":"241046","poster":"arulrajjayaraj","content":"C - organization-level solution and Existing logs are kept"}],"content":"B. Configure CloudTrail in each member account to deliver log events to a central S3 bucket. Ensure the central S3 bucket policy allows PutObject access from the member accounts. Migrate existing logs to the central S3 bucket. Set up an Amazon CloudWatch alarm to alert if CloudTrail is not configured properly.\n\nC. Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Migrate the existing CloudTrail logs from each member account to the central S3 bucket. Delete the existing CloudTrail and logs in the member accounts.\n\nD. Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Configure CloudTrail in each member account to deliver log events to the central S3 bucket.","comment_id":"237663","upvote_count":"1","poster":"karoth_p"},{"poster":"karoth_p","timestamp":"1633950120.0","content":"Sorry, it's the only way to submit NEW QUESTION:\n\nA company uses AWS Organizations to manage one parent account and nine member accounts. The number of member accounts is expected to grow as the business grows. A security engineer has requested consolidation of AWS CloudTrail logs into the parent account for compliance purposes. Existing logs currently stored in Amazon S3 buckets in each individual member account should not be lost. Future member accounts should comply with the logging strategy.\n\nWhich operationally efficient solution meets these requirements?\n\nA. Create an AWS Lambda function in each member account with a cross-account role. Trigger the Lambda functions when new CloudTrail logs are created and copy the CloudTrail logs to a centralized S3 bucket. Set up an Amazon CloudWatch alarm to alert if CloudTrail is not configured properly.","comment_id":"237662","upvote_count":"1"},{"timestamp":"1633834080.0","content":"B is correct, referencing parameters in the \"launch configuration UserData property\" is never a good idea because it's not easily mantainable, so A,C,D are to be discarded.","poster":"PAUGURU","comment_id":"237090","upvote_count":"1"},{"timestamp":"1633705980.0","poster":"jackdryan","content":"I'll go with B","comment_id":"232425","upvote_count":"3"},{"comment_id":"208552","poster":"CYL","upvote_count":"1","content":"B. Has to be an application setting so that key can be rotated using AWS Secret Manager.","timestamp":"1633688340.0"},{"comment_id":"205434","content":"B is the correct answer.","poster":"Bulti","timestamp":"1633598040.0","upvote_count":"1"},{"timestamp":"1632977580.0","content":"B is the correct answer so the password is updated dynamically when it rotates every 60days. With C it is static and would require a new EC2 re-provisioning to be updated, therefore extra orchestration and possible issues. C is also less secured.","upvote_count":"1","poster":"wsw","comment_id":"173808"},{"upvote_count":"1","comment_id":"167408","timestamp":"1632873300.0","poster":"b3llman","content":"B. the app can get the secret securely from Secrets Manager and configure RDS using dynamic reference. \nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html\nC is not correct because referencing the secret in UserData might expose the secret in env var and it is not secure."},{"poster":"[Removed]","content":"C is correct","comment_id":"167140","upvote_count":"1","timestamp":"1632696360.0"},{"timestamp":"1632642240.0","poster":"directconnect","comments":[{"timestamp":"1633433760.0","content":"Your answer B is correct, secrets manager is available for dynamic reference https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html","poster":"sam422","upvote_count":"1","comment_id":"185262"},{"upvote_count":"1","timestamp":"1633567860.0","content":"# The secret (username and password for the superuser) will be dynamically --says dynamic reference","poster":"sam422","comment_id":"185265"}],"upvote_count":"3","comment_id":"159385","content":"My final answer is C. From the reference doc https://aws.amazon.com/blogs/security/how-to-create-and-retrieve-secrets-managed-in-aws-secrets-manager-using-aws-cloudformation-template/, The join Intrinsic function is what is used to reference the secret in AWS::RDS::DBInstance\n\n# Create a MySQL database of size t2.micro.\n# The secret (username and password for the superuser) will be dynamically \n# referenced. This ensures CloudFormation will not log or persist the resolved \n# value. \n MyDBInstance:\n Type: AWS::RDS::DBInstance\n Properties:\n AllocatedStorage: 20\n DBInstanceClass: db.t2.micro\n Engine: mysql\n MasterUsername: !Join ['', ['{{resolve:secretsmanager:', !Ref MyRDSInstanceRotationSecret, ':SecretString:username}}' ]]\n MasterUserPassword: !Join ['', ['{{resolve:secretsmanager:', !Ref MyRDSInstanceRotationSecret, ':SecretString:password}}' ]]\n BackupRetentionPeriod: 0\n DBInstanceIdentifier: 'rotation-instance'"},{"comment_id":"159382","upvote_count":"3","poster":"directconnect","content":"B instead. Secrets manager will user a dynamic reference.","timestamp":"1632548100.0"},{"timestamp":"1632433500.0","poster":"directconnect","comment_id":"159380","upvote_count":"1","content":"https://aws.amazon.com/blogs/security/how-to-create-and-retrieve-secrets-managed-in-aws-secrets-manager-using-aws-cloudformation-template/"},{"comments":[{"timestamp":"1633094700.0","upvote_count":"1","poster":"sam422","content":"secrets manager is available only as dynamic reference https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html","comment_id":"185258"}],"comment_id":"159378","upvote_count":"1","poster":"directconnect","content":"C.\nThe launched EC2 instances in the Autoscaling Group need to connect to Secrets Manager at runtime. And Intrinsic functions are used for dynamic references not available until runtime.","timestamp":"1632316380.0"},{"content":"B is correct.","comment_id":"157885","poster":"Anila_Dhharisi","timestamp":"1632163680.0","upvote_count":"4"}],"unix_timestamp":1597248840,"answers_community":["B (100%)"],"timestamp":"2020-08-12 18:14:00","question_images":[],"answer_description":"","answer_images":[],"answer_ET":"B","question_text":"A solutions architect is implementing infrastructure as code for a two-tier web application in an AWS CloudFormation template. The web frontend application will be deployed on Amazon EC2 instances in an Auto Scaling group. The backend database will be an Amazon RDS for MySQL DB instance. The database password will be rotated every 60 days.\nHow can the solutions architect MOST securely manage the configuration of the application's database credentials?","exam_id":32,"choices":{"A":"Provide the database password as a parameter in the CloudFormation template. Create an initialization script in the Auto Scaling group's launch configuration UserData property to reference the password parameter using the Ref intrinsic function. Store the password on the EC2 instances. Reference the parameter for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using the Ref intrinsic function.","D":"Create a new AWS Systems Manager Parameter Store parameter in the CloudFormation template to be used as the database password. Create an initialization script in the Auto Scaling group's launch configuration UserData property to reference the parameter. Reference the parameter for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using the Fn::GetAtt intrinsic function.","C":"Create a new AWS Secrets Manager secret resource in the CloudFormation template to be used as the database password. Create an initialization script in the Auto Scaling group's launch configuration UserData property to reference the secret resource using the Ref intrinsic function. Reference the secret resource for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using the Ref intrinsic function.","B":"Create a new AWS Secrets Manager secret resource in the CloudFormation template to be used as the database password. Configure the application to retrieve the password from Secrets Manager when needed. Reference the secret resource for the value of the MasterUserPassword property in the AWS::RDS::DBInstance resource using a dynamic reference."},"question_id":582,"isMC":true,"topic":"1","answer":"B"},{"id":"4ES5X1zFC4JP2kH1kKLA","topic":"1","question_id":583,"choices":{"A":"Create an alias for every new deployed version of the Lambda function. Use the AWS CLI update-alias command with the routing-config parameter to distribute the load.","B":"Deploy the application into a new CloudFormation stack. Use an Amazon Route 53 weighted routing policy to distribute the load.","C":"Create a version for every new deployed Lambda function. Use the AWS CLI update-function-configuration command with the routing-config parameter to distribute the load.","D":"Configure AWS CodeDeploy and use CodeDeployDefault.OneAtATime in the Deployment configuration to distribute the load."},"answer_images":[],"isMC":true,"exam_id":32,"answer_description":"","unix_timestamp":1597249680,"answer_ET":"C","timestamp":"2020-08-12 18:28:00","question_images":[],"answers_community":["A (100%)"],"discussion":[{"timestamp":"1632091260.0","content":"A. Alias traffic shifting.\nhttps://aws.amazon.com/blogs/compute/implementing-canary-deployments-of-aws-lambda-functions-with-alias-traffic-shifting/","comment_id":"156608","upvote_count":"23","poster":"Nemer"},{"upvote_count":"1","comment_id":"917471","poster":"claymannain","timestamp":"1686160560.0","content":"A.\n\nLambda aliases are a way to point to multiple versions of a Lambda function. This can be useful for testing new versions of a function before rolling them out to production, or for running multiple versions of a function in parallel to test different approaches.\n\nWhen you create a Lambda alias, you can specify a routing configuration. This configuration determines how traffic is routed between the alias and the function versions it points to.\n\nThere are two types of routing configurations:\n\nStatic routing: With static routing, you specify a fixed percentage of traffic that is routed to each function version.\nCanary routing: With canary routing, you specify a starting percentage of traffic that is routed to a new function version. Over time, the percentage of traffic routed to the new function version increases, while the percentage of traffic routed to the old function version decreases."},{"content":"A is My answer.","comment_id":"768179","poster":"BlueSpark","upvote_count":"1","timestamp":"1673054580.0"},{"poster":"Sumit_Kumar","upvote_count":"4","comment_id":"651711","timestamp":"1661416620.0","content":"# Update $LATEST version of function\naws lambda update-function-code --function-name myfunction ….\n\n# Publish new version of function\naws lambda publish-version --function-name myfunction\n\n# Point alias to new version, weighted at 5% (original version at 95% of traffic)\naws lambda update-alias --function-name myfunction --name myalias --routing-config '{\"AdditionalVersionWeights\" : {\"2\" : 0.05} }'\n\n# Verify that the new version is healthy\n…\n# Set the primary version on the alias to the new version and reset the additional versions (100% weighted)\naws lambda update-alias --function-name myfunction --name myalias --function-version 2 --routing-config '{}'\nThis is begging to be automate"},{"upvote_count":"1","poster":"Jughead","timestamp":"1660281420.0","content":"Selected Answer: A\nA is the answer","comment_id":"645745"},{"poster":"bobsmith2000","timestamp":"1652630580.0","content":"NONE of them is correct.\nB and D are nonsense.\nB - there's no point to deploy a new Lambda every time and edit rte\nD - Look it up here. https://docs.amazonaws.cn/en_us/codedeploy/latest/userguide/deployment-configurations.html\n\nBetween A and C.\nA is wrong because \"Create an alias for every new deployed version\". The alias it's the same, the weight between the versions for the alias it's different. You point out to the alias and then operate with version.\nC it's wrong because you have to use update-alias instead of update-function-configuration.\n\nSo it's either A and C phrasing is messed up or none of them is correct.","comment_id":"602177","upvote_count":"3"},{"comment_id":"496649","content":"A. Create an alias for every new deployed version of the Lambda function. Use the AWS CLI update-alias command with the routing-config parameter to distribute the load.","poster":"cldy","upvote_count":"1","timestamp":"1638952440.0"},{"content":"Correct Answer A. there is no second thoughts also!","upvote_count":"1","timestamp":"1638319260.0","comment_id":"491095","poster":"AzureDP900"},{"content":"AAA\n---","upvote_count":"1","comment_id":"436137","poster":"tgv","timestamp":"1636270440.0"},{"content":"I'll go with A","upvote_count":"1","comment_id":"413242","poster":"WhyIronMan","timestamp":"1635513780.0"},{"timestamp":"1635347400.0","poster":"blackgamer","comment_id":"357664","upvote_count":"3","content":"A is the answer. Refer below link for details explanation on how Lambda Alias works.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html"},{"timestamp":"1635235080.0","upvote_count":"2","content":"it's A","comment_id":"353675","poster":"Waiweng"},{"comment_id":"292605","content":"going with A","timestamp":"1634971500.0","upvote_count":"2","poster":"Kian1"},{"poster":"lechuk","upvote_count":"2","timestamp":"1634702700.0","content":"Maybe a Typo but it's not need to create an ALIAS for every every function deployment...","comment_id":"290072"},{"poster":"Ebi","upvote_count":"3","comment_id":"267657","timestamp":"1634671080.0","content":"A is my answer"},{"content":"A is the correct option for Serverless.","poster":"Bulti","comment_id":"253875","upvote_count":"2","timestamp":"1634487300.0"},{"timestamp":"1634334060.0","upvote_count":"1","content":"Correct is A . Update alias traffic","poster":"T14102020","comment_id":"244754"},{"timestamp":"1634194620.0","content":"I'll go with A","poster":"jackdryan","upvote_count":"3","comment_id":"232428"},{"comment_id":"208556","timestamp":"1634022720.0","content":"A. Use alias to switch traffic.","poster":"CYL","upvote_count":"1"},{"poster":"Bulti","timestamp":"1634011920.0","content":"Answer is A.","upvote_count":"1","comment_id":"205295"},{"poster":"wsw","timestamp":"1632852360.0","content":"Agree, A. It is a little primitive, but all researches redirect to the same blog page for using Alias. D. is wrong, CodeDeployDefault.OneAtATime is only available for EC2/on-premise, not Lambda","upvote_count":"4","comment_id":"173821"}],"answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/28312-exam-aws-certified-solutions-architect-professional-topic-1/","question_text":"A company built an application based on AWS Lambda deployed in an AWS CloudFormation stack. The last production release of the web application introduced an issue that resulted in an outage lasting several minutes. A solutions architect must adjust the deployment process to support a canary release.\nWhich solution will meet these requirements?"},{"id":"VJGBFU1kI9OiMPzfOXS7","topic":"1","choices":{"B":"Enable Amazon S3 cross-Region replication on the buckets that contain static assets.","C":"Enable multi-Region targets on the Elastic Load Balancer and target Amazon EC2 instances in both Regions.","F":"Enable Amazon S3 versioning on the source and destination buckets containing static assets to ensure there is a rollback version available in the event of data corruption.","D":"Enable DynamoDB global tables to achieve a multi-Region table replication.","E":"Enable Amazon CloudWatch and create CloudWatch alarms that route traffic to the disaster recovery site when application latency exceeds the desired threshold.","A":"Enable Amazon Route 53 health checks to determine if the primary site is down, and route traffic to the disaster recovery site if there is an issue."},"question_id":584,"answer_images":[],"isMC":true,"exam_id":32,"answer_description":"","unix_timestamp":1597148220,"timestamp":"2020-08-11 14:17:00","answer_ET":"ABD","question_images":[],"answers_community":["ABD (100%)"],"discussion":[{"upvote_count":"28","comment_id":"156800","poster":"Konnon","timestamp":"1632508380.0","content":"The answer is ABD."},{"poster":"Nemer","content":"ABD is right. \n Route 53 + S3 CRR + DynDB global tables.","upvote_count":"16","timestamp":"1632590520.0","comment_id":"156921"},{"poster":"sodasu","upvote_count":"1","content":"why not E ?","comment_id":"673796","comments":[{"poster":"sodasu","timestamp":"1663649520.0","comment_id":"673798","content":"BD is right.\n \ni wanna know how about E? \nThanks!","upvote_count":"1","comments":[{"comment_id":"708622","timestamp":"1667239200.0","content":"The first issue with E is that its based on latency.\nSecond , cloud watch alarms don't just switch traffic and they need to trigger a lambda function to do that which is not mentioned \nThird , even if lambda was mentioned why would you use this option if its supported natively in route 53 without the need to implement this long process \nRemember that in the professional exam some option could be done technically but you are asked for the *Best option \nso in this case A is better to do this and more reliable","upvote_count":"2","poster":"Cal88"}]}],"timestamp":"1663649340.0"},{"timestamp":"1655788980.0","upvote_count":"1","comment_id":"619602","content":"ABD it is","poster":"KiraguJohn"},{"comment_id":"580853","timestamp":"1649091960.0","poster":"roka_ua","content":"Selected Answer: ABD\nVote ABD","upvote_count":"1"},{"content":"AB &D for me. Slightly tricky question. But R53 will cover the DR requirement. S3 CRR means there is another copy of the data in another region and Global tables ensure multiple copies of the data in case of site down.","upvote_count":"1","comment_id":"564884","poster":"Ni_yot","timestamp":"1646929620.0"},{"poster":"shotty1","content":"Selected Answer: ABD\nit is ABD","timestamp":"1643191620.0","comment_id":"532772","upvote_count":"1"},{"upvote_count":"2","comment_id":"491100","timestamp":"1638319380.0","poster":"AzureDP900","content":"Selected Answer: ABD\nABD is correct answer!"},{"comment_id":"448840","poster":"moon2351","timestamp":"1636247760.0","upvote_count":"1","content":"Answer is ADB"},{"comment_id":"436143","poster":"tgv","content":"AAA BBB DDD\n---","timestamp":"1635427080.0","upvote_count":"1"},{"upvote_count":"3","timestamp":"1635325740.0","comment_id":"413244","poster":"WhyIronMan","content":"I'll go with A,B,D"},{"content":"The answer is ABD for sure.","upvote_count":"1","poster":"blackgamer","comment_id":"357669","timestamp":"1635020700.0"},{"poster":"Waiweng","upvote_count":"3","comment_id":"351859","timestamp":"1634654940.0","content":"it's ABD"},{"timestamp":"1634613300.0","content":"ABD, seems right but it doesn't fully answer the question: \"Which combination of actions, while meeting all the requirements?\" as it's not stating anything about the application layer.\n\nHowever, another picks are not correct either. So I would answer ABD :D\n\nC: There's no multi-region targets in ELB. However you can load balance traffic with the IP addresses, so you could do it.","poster":"Justu","comment_id":"268808","upvote_count":"3"},{"poster":"Ebi","comment_id":"267661","timestamp":"1634446380.0","content":"ABD is my answer","upvote_count":"3"},{"upvote_count":"2","timestamp":"1633965300.0","poster":"Bulti","comment_id":"253882","content":"It's not clear if versioning is enabled on S3 buckets in source and destination region. Without that CRR will not work. So I will go with A,D, F. Static content will not change. So no need to sync up but in case someone deletes it or gets corrupted you can go to the previous version.","comments":[{"poster":"student22","timestamp":"1636218900.0","upvote_count":"1","content":"A,B,D\nNot F because the requirement is for a DR site.","comment_id":"437496"},{"upvote_count":"2","poster":"Bulti","comment_id":"258751","content":"On second thought I will go with ABD. B is correct and F is wrong because if cross region replication is enabled then versioning is enabled as well without which cross region replication is not possible.","timestamp":"1634251860.0"}]},{"poster":"T14102020","comment_id":"244759","content":"Correct is ABD. Route 53 + S3 CRR + DynDB global tables.","timestamp":"1633958400.0","upvote_count":"2"},{"poster":"jackdryan","upvote_count":"4","timestamp":"1633189560.0","content":"I'll go with A,B,D","comment_id":"232451"},{"comment_id":"208563","poster":"CYL","timestamp":"1632657720.0","upvote_count":"1","content":"ABD. Need to have Route 53 to sense issue and switch to the DR site. Need to have S3 replication to have static content synced up. Global Table in Dynamo DB to synchronize NoSQL data content."},{"poster":"Anila_Dhharisi","upvote_count":"5","timestamp":"1632637140.0","comment_id":"157895","content":"its ABD"},{"comment_id":"155421","timestamp":"1632313440.0","content":"Here CEF given as answer...but I guess answer seems to be ABD... really disappointed","poster":"shakthi000005","upvote_count":"3"},{"content":"All seems to be wrong answers.... really disappointed with examtopics as answers are fully wrong most of the times","upvote_count":"6","poster":"shakthi000005","timestamp":"1632179820.0","comment_id":"155420","comments":[{"comment_id":"234135","timestamp":"1633332300.0","content":"Yes i do wonder what is going on .. its very sad and i dont know why they allow this ..","upvote_count":"2","poster":"petebear55"},{"content":"remember no dump site will give you 100% right answer you cannot have it all you have to learn in the process as well, answer A,B and D","upvote_count":"1","comment_id":"258800","poster":"kopper2019","timestamp":"1634375520.0"}]}],"answer":"ABD","url":"https://www.examtopics.com/discussions/amazon/view/28096-exam-aws-certified-solutions-architect-professional-topic-1/","question_text":"A manufacturing company is growing exponentially and has secured funding to improve its IT infrastructure and ecommerce presence. The company's ecommerce platform consists of:\n✑ Static assets primarily comprised of product images stored in Amazon S3.\n✑ Amazon DynamoDB tables that store product information, user information, and order information.\n✑ Web servers containing the application's front-end behind Elastic Load Balancers.\nThe company wants to set up a disaster recovery site in a separate Region.\nWhich combination of actions should the solutions architect take to implement the new design while meeting all the requirements? (Choose three.)"},{"id":"XxsTA3mJTfikBunRSOWS","topic":"1","choices":{"A":"Use Amazon Kinesis Data Firehouse to collect the inbound sensor data, analyze the data with Kinesis clients, and save the results to an Amazon RDS instance.","C":"Use Amazon S3 to collect the inbound device data, analyze the data from Amazon SQS with Kinesis, and save the results to an Amazon Redshift cluster.","B":"Use Amazon Kinesis Data Streams to collect the inbound sensor data, analyze the data with Kinesis clients, and save the results to an Amazon Redshift cluster using Amazon EMR.","D":"Use an Amazon API Gateway to put requests into an Amazon SQS queue, analyze the data with an AWS Lambda function, and save the results to an Amazon Redshift cluster using Amazon EMR."},"question_id":585,"answer_images":[],"isMC":true,"exam_id":32,"answer_description":"","unix_timestamp":1597291200,"timestamp":"2020-08-13 06:00:00","answer_ET":"B","question_images":[],"answers_community":["B (100%)"],"discussion":[{"comment_id":"156926","timestamp":"1632196560.0","poster":"Nemer","content":"B is right. Kinesis streams / EMR / Redshift.","upvote_count":"24"},{"upvote_count":"5","content":"I will go with B","comment_id":"268574","poster":"Ebi","timestamp":"1634826780.0"},{"comment_id":"713618","upvote_count":"1","poster":"Heer","timestamp":"1667898060.0","content":"Near real time =Kinesis Streams\nDataware house:Redshift"},{"content":"I chose A, but then I noticed that it is sending results to RDS, oops!","poster":"WayneYi","upvote_count":"3","comment_id":"689114","timestamp":"1665214800.0"},{"content":"B is correct ans. like this one","comment_id":"650945","upvote_count":"1","poster":"Ni_yot","timestamp":"1661278560.0"},{"comment_id":"537618","timestamp":"1643685840.0","poster":"HellGate","content":"B\nreal-time requirement = Kinesis","upvote_count":"1"},{"content":"Selected Answer: B\nB for sure !","poster":"AzureDP900","timestamp":"1638319680.0","upvote_count":"1","comment_id":"491103"},{"timestamp":"1637088960.0","content":"Ascertain that the data is adaptable, parallel, and durable is very tempting to S3, but most probably its B with Kinesis","comment_id":"479582","poster":"Kopa","upvote_count":"1"},{"content":"BBB\n---","poster":"tgv","upvote_count":"1","timestamp":"1636191720.0","comment_id":"436147"},{"content":"I'll go with B","poster":"WhyIronMan","upvote_count":"1","timestamp":"1635826680.0","comment_id":"413245"},{"timestamp":"1635335100.0","upvote_count":"2","poster":"KittuCheeku","content":"B is the correct answer as it is best suited amongst 4 given options. KDS (Analytics) + Redshift (Data Warehouse) + Using Elastic MapReduce","comment_id":"404195"},{"poster":"Waiweng","timestamp":"1635170520.0","comment_id":"351861","upvote_count":"2","content":"it's B"},{"timestamp":"1635134220.0","upvote_count":"1","comment_id":"349064","content":"I think C is correct too. B is an overkill. 8KB per second is really low data rate.","comments":[{"timestamp":"1635291840.0","comment_id":"371420","content":"near-real-time, always think of Kinesis","poster":"TonyGe","upvote_count":"2"}],"poster":"digimaniac"},{"upvote_count":"3","comment_id":"253892","poster":"Bulti","timestamp":"1634198760.0","content":"answer is B"},{"upvote_count":"2","content":"Correct is D. Kinesis data streams + EMR + Redshift.","comment_id":"244764","timestamp":"1633717380.0","poster":"T14102020"},{"poster":"jackdryan","timestamp":"1633674660.0","content":"I'll go with B","comment_id":"232456","upvote_count":"3"},{"upvote_count":"4","content":"B. Redshift is the data-warehouse. EMR to do the data transformation. Kinesis for real-time data transfer.","comment_id":"208564","poster":"CYL","timestamp":"1632919980.0"},{"poster":"Anila_Dhharisi","timestamp":"1632519600.0","content":"B is correct.","upvote_count":"2","comment_id":"157896"}],"answer":"B","question_text":"A company is developing a gene reporting device that will collect genomic information to assist researchers will collecting large samples of data from a diverse population. The device will push 8 KB of genomic data every second to a data platform that will need to process and analyze the data and provide information back to researchers. The data platform must meet the following requirements:\n✑ Provide near-real-time analytics of the inbound genomic data\n✑ Ensure the data is flexible, parallel, and durable\n✑ Deliver results of processing to a data warehouse\nWhich strategy should a solutions architect use to meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/28384-exam-aws-certified-solutions-architect-professional-topic-1/"}],"exam":{"isMCOnly":false,"isBeta":false,"isImplemented":true,"id":32,"numberOfQuestions":1019,"provider":"Amazon","name":"AWS Certified Solutions Architect - Professional","lastUpdated":"11 Apr 2025"},"currentPage":117},"__N_SSP":true}