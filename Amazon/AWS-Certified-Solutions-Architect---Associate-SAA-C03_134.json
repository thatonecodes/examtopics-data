{"pageProps":{"questions":[{"id":"vQl2WcrKDJ8ZBhvrWhJE","answer_ET":"A","question_id":666,"timestamp":"2023-12-29 17:26:00","answers_community":["A (100%)"],"unix_timestamp":1703867160,"isMC":true,"answer_images":[],"exam_id":31,"question_images":[],"discussion":[{"comment_id":"1108903","comments":[{"upvote_count":"4","content":"Actually this is not fully correct:\n\n\"By setting up an AWS DataSync task with the transfer mode set to transfer only data that has changed, you ensure that only the new or modified files are copied. \"\n\n\"Transfer only data that has changed ... copies only the data and metadata that differs between the source and destination location.\" \n\nSo, if we have a source with existing items and an empty destination (like in this example), \"transfer only data that has changed\" will transfer all the existing items though in the true sense of the word they have not \"changed\".","comment_id":"1112844","poster":"pentium75","timestamp":"1720009620.0"}],"timestamp":"1719671160.0","upvote_count":"5","content":"AWS DataSync (Option A): AWS DataSync is designed for efficient and reliable copying of data between different storage solutions. By setting up an AWS DataSync task with the transfer mode set to transfer only data that has changed, you ensure that only the new or modified files are copied. This minimizes data transfer and operational overhead.","poster":"meenkaza"},{"comment_id":"1184540","content":"Selected Answer: A\nDataSync will do an Initial Scan of both S3 buckets. Identifying Differences. Then, Transferring Changes, so technically DataSync will transfer All the data at first run then it will only transfer newly added/modified objects subsequently.","poster":"mohammadthainat","upvote_count":"4","timestamp":"1727487840.0"},{"timestamp":"1726729740.0","content":"Have always did this using B, guess now that I know A is less operational","comment_id":"1177152","upvote_count":"4","poster":"Kezuko"},{"content":"Selected Answer: A\nBD are more operation overhead although B can work in principle\nAC uses managed service to transfer data. A fulfils the requirement of \"copied files should be overwritten only if the source file changes\" so A is correct. B will just copy regardless of the change","upvote_count":"2","poster":"awsgeek75","comment_id":"1121909","timestamp":"1720884540.0","comments":[{"comment_id":"1121910","poster":"awsgeek75","content":"Meant C will transfer everything and copy data without comparing for change","upvote_count":"2","timestamp":"1720884600.0"}]},{"timestamp":"1720009680.0","upvote_count":"4","comment_id":"1112845","content":"Selected Answer: A\nTransfer only data that has changed – DataSync copies only the data and metadata that differs between the source and destination location.\n\nTransfer all data – DataSync copies everything in the source to the destination without comparing differences between the locations.\n\nhttps://docs.aws.amazon.com/datasync/latest/userguide/configure-metadata.html\n\n(B would work too but is more \"operational overhead.\")","poster":"pentium75"},{"timestamp":"1719772620.0","content":"Selected Answer: A\nans: A","poster":"cciesam","upvote_count":"3","comment_id":"1109961"}],"topic":"1","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/129722-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A solutions architect needs to copy files from an Amazon S3 bucket to an Amazon Elastic File System (Amazon EFS) file system and another S3 bucket. The files must be copied continuously. New files are added to the original S3 bucket consistently. The copied files should be overwritten only if the source file changes.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"B":"Create an AWS Lambda function. Mount the file system to the function. Set up an S3 event notification to invoke the function when files are created and changed in Amazon S3. Configure the function to copy files to the file system and the destination S3 bucket.","D":"Launch an Amazon EC2 instance in the same VPC as the file system. Mount the file system. Create a script to routinely synchronize all objects that changed in the origin S3 bucket to the destination S3 bucket and the mounted file system.","A":"Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer only data that has changed.","C":"Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer all data."},"answer":"A"},{"id":"ac1Jae6MmA1TwMvdmSav","question_id":667,"answer_ET":"A","answers_community":["A (88%)","13%"],"question_text":"A company uses Amazon EC2 instances and stores data on Amazon Elastic Block Store (Amazon EBS) volumes. The company must ensure that all data is encrypted at rest by using AWS Key Management Service (AWS KMS). The company must be able to control rotation of the encryption keys.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","isMC":true,"answer_images":[],"unix_timestamp":1703867280,"question_images":[],"discussion":[{"content":"Selected Answer: A\n\"Able to control rotation of the encryption keys\" = customer managed key (created by AWS but managed by the customer in KMS)","poster":"pentium75","comment_id":"1112849","timestamp":"1720009920.0","upvote_count":"5"},{"poster":"AAbirdy","content":"Selected Answer: A\nThe company must be able to control rotation of the encryption keys = customer managed key","comment_id":"1123806","upvote_count":"5","timestamp":"1721085720.0"},{"upvote_count":"1","timestamp":"1739617200.0","content":"Selected Answer: B\nThe company must ensure encryption at rest using AWS KMS and must control key rotation with minimal operational overhead.\n\nAWS Managed Keys are automatically managed by AWS, including automatic key rotation every year.\nThis approach eliminates manual key management, reducing administrative effort.","comment_id":"1356817","poster":"Chen77"},{"poster":"awsgeek75","content":"Selected Answer: A\n\"The company must be able to control rotation of the encryption keys.\"\nBD does not allow company owned keys\nC is too much operational overhead","comment_id":"1121913","timestamp":"1720884720.0","upvote_count":"4"},{"upvote_count":"2","comment_id":"1118741","poster":"dikshya1233","timestamp":"1720617300.0","comments":[{"upvote_count":"3","content":"AWS Manged keys don't meet the requirements \"The company must be able to control rotation of the encryption keys.\"","comment_id":"1121915","timestamp":"1720884780.0","poster":"awsgeek75"}],"content":"Selected Answer: B\nThe solution that meets the requirements with the LEAST operational overhead is:\n\nB. Use an AWS managed key to encrypt the EBS volumes. Use the key to configure automatic key rotation.\n\nWith AWS managed keys (AWS managed CMKs), AWS takes care of key management tasks, including key rotation. This reduces operational overhead as AWS automatically handles key rotation without requiring manual intervention. It is a convenient option for users who want to ensure encryption at rest with minimal effort in managing encryption keys."},{"upvote_count":"2","timestamp":"1720161060.0","content":"Selected Answer: A\nA is correct option","comment_id":"1114348","poster":"Shobhit2021"},{"poster":"fea9bdf","content":"Answer is C\nDetails are on this link below: \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/default-bucket-encryption.html\nAmazon S3 buckets have bucket encryption enabled by default, and new objects are automatically encrypted by using server-side encryption with Amazon S3 managed keys (SSE-S3). This encryption applies to all new objects in your Amazon S3 buckets, and comes at no cost to you.\n\nIf you need more control over your encryption keys, such as managing key rotation and access policy grants, you can elect to use server-side encryption with AWS Key Management Service (AWS KMS) keys (SSE-KMS), or dual-layer server-side encryption with AWS KMS keys (DSSE-KMS). For more information about SSE-KMS, see Specifying server-side encryption with AWS KMS (SSE-KMS). For more information about DSSE-KMS, see Using dual-layer server-side encryption with AWS KMS keys (DSSE-KMS).","timestamp":"1719760140.0","upvote_count":"1","comment_id":"1110716","comments":[{"comment_id":"1112847","content":"How does this relate to answer C? With \"imported key material\" you cannot \"control rotation of the encryption keys\" (except by importing new keys). SSE-KMS (as mentioned in your explanation = customer managed key = A","timestamp":"1720009860.0","poster":"pentium75","upvote_count":"2"}]},{"upvote_count":"2","comment_id":"1109435","poster":"Riajul","content":"Should be option A","timestamp":"1719718800.0"},{"timestamp":"1719711240.0","content":"option B is the correct answer with least operational overhead on admins","upvote_count":"1","poster":"Naijaboy99","comment_id":"1109370","comments":[{"content":"AWS managed keys do allow for automatic rotation, but the company does NOT have control over the rotation - AWS manages this automatically without company intervention.","comment_id":"1116308","poster":"OSHOAIB","timestamp":"1720395540.0","upvote_count":"2"},{"comment_id":"1109383","timestamp":"1719711960.0","upvote_count":"3","content":"@meenkaza was right the answer is A","poster":"Naijaboy99"}]},{"upvote_count":"5","timestamp":"1719671280.0","content":"Selected Answer: A\noption A (Create a customer managed key. Use the key to encrypt the EBS volumes) is the most suitable option with the least operational overhead for the given requirements.","comment_id":"1108904","poster":"meenkaza"}],"answer":"A","topic":"1","choices":{"A":"Create a customer managed key. Use the key to encrypt the EBS volumes.","B":"Use an AWS managed key to encrypt the EBS volumes. Use the key to configure automatic key rotation.","D":"Use an AWS owned key to encrypt the EBS volumes.","C":"Create an external KMS key with imported key material. Use the key to encrypt the EBS volumes."},"exam_id":31,"answer_description":"","timestamp":"2023-12-29 17:28:00","url":"https://www.examtopics.com/discussions/amazon/view/129723-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"zT7mEUfiB0qOLRpCYN2q","question_id":668,"answer_ET":"A","answers_community":["A (96%)","4%"],"isMC":true,"question_text":"A company needs a solution to enforce data encryption at rest on Amazon EC2 instances. The solution must automatically identify noncompliant resources and enforce compliance policies on findings.\n\nWhich solution will meet these requirements with the LEAST administrative overhead?","answer_images":[],"unix_timestamp":1703867520,"question_images":[],"discussion":[{"poster":"meenkaza","timestamp":"1719671520.0","upvote_count":"13","comment_id":"1108907","content":"Selected Answer: A\nIAM Policy and AWS Config (Option A): By creating an IAM policy that allows users to create only encrypted EBS volumes, you proactively prevent the creation of unencrypted volumes. Using AWS Config, you can set up rules to detect noncompliant resources, and AWS Systems Manager Automation can be used for automated remediation. This approach provides a proactive and automated solution."},{"timestamp":"1734236820.0","poster":"LeonSauveterre","upvote_count":"1","comment_id":"1326692","content":"Selected Answer: A\nNot B - because when you want to detect unencrypted EBS volumes using Lambda and EventBridge, the codes you'll need to compose is so much more than you think. Just leave that whole shebang to AWS Config and then you'll choose A accordingly."},{"comment_id":"1206014","poster":"88f8032","upvote_count":"1","content":"Selected Answer: B\nIsn't B simpler?","timestamp":"1730632920.0"},{"comment_id":"1121917","timestamp":"1720884960.0","poster":"awsgeek75","upvote_count":"2","content":"Selected Answer: A\nB: Too much work\nC: Macie is for PII and sensitive data not for encrypted volumes\nD: Inspector for OS patching and vulnerability detections"},{"upvote_count":"1","content":"why not B?","timestamp":"1720818660.0","comment_id":"1121167","poster":"f2e2419"},{"poster":"OSHOAIB","content":"Selected Answer: A\nOption A - enforces the creation of encrypted volumes via IAM policies and uses AWS Config for detection and AWS Systems Manager for remediation with the LEAST administrative overhead.","comment_id":"1116315","timestamp":"1720395960.0","upvote_count":"3"},{"content":"Selected Answer: A\nA as exactly described here: https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automatically-encrypt-existing-and-new-amazon-ebs-volumes.html\n\nNot B, that could in theory work but would be massive operational overhead\n\nNot C, Macie detects PII data, not unencrypted volumes\n\nNot D, Inspector detects vulnerabilities, not unencrypted volumes","timestamp":"1720010220.0","comment_id":"1112857","upvote_count":"4","poster":"pentium75"}],"answer":"A","topic":"1","choices":{"A":"Use an IAM policy that allows users to create only encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Config and AWS Systems Manager to automate the detection and remediation of unencrypted EBS volumes.","B":"Use AWS Key Management Service (AWS KMS) to manage access to encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Lambda and Amazon EventBridge to automate the detection and remediation of unencrypted EBS volumes.","D":"Use Amazon inspector to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes.","C":"Use Amazon Macie to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes."},"exam_id":31,"answer_description":"","timestamp":"2023-12-29 17:32:00","url":"https://www.examtopics.com/discussions/amazon/view/129724-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"ccZNy6QAsHRXaQ1cw5wF","unix_timestamp":1703867640,"question_id":669,"isMC":true,"question_text":"A company is migrating its multi-tier on-premises application to AWS. The application consists of a single-node MySQL database and a multi-node web tier. The company must minimize changes to the application during the migration. The company wants to improve application resiliency after the migration.\n\nWhich combination of steps will meet these requirements? (Choose two.)","answer_images":[],"question_images":[],"answer":"AC","answers_community":["AC (100%)"],"answer_ET":"AC","discussion":[{"upvote_count":"11","comment_id":"1108910","content":"Selected Answer: AC\nWeb Tier Migration (Option A): Migrating the web tier to Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB) provides horizontal scalability, automatic scaling, and improved resiliency. Auto Scaling helps in managing and maintaining the desired number of EC2 instances based on demand, and the ALB distributes incoming traffic across multiple instances.\n\nDatabase Migration to Amazon RDS Multi-AZ (Option C): Migrating the database to Amazon RDS in a Multi-AZ deployment provides high availability and automatic failover. In a Multi-AZ deployment, Amazon RDS maintains a standby replica in a different Availability Zone, and in the event of a failure, it automatically promotes the replica to the primary instance. This enhances the resiliency of the database.","timestamp":"1719671640.0","poster":"meenkaza"},{"poster":"pentium75","content":"Selected Answer: AC\nA - ALB is ideal for web application\nB - NLB would work too but ALB is better\nC - same functionality as on-premises just with 'improved resiliency'\nD - would require significant \"changes to the application\"\nE - would require significant \"changes to the application\"","upvote_count":"5","comment_id":"1112858","timestamp":"1720010460.0"},{"content":"Also Dynamo DB is noSQL, that can not be an option here","timestamp":"1719759540.0","comment_id":"1110713","upvote_count":"3","poster":"fea9bdf"},{"poster":"Naijaboy99","upvote_count":"1","content":"option A C","timestamp":"1719711420.0","comment_id":"1109374"}],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/129725-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"choices":{"D":"Migrate the web tier to an AWS Lambda function.","B":"Migrate the database to Amazon EC2 instances in an Auto Scaling group behind a Network Load Balancer.","E":"Migrate the database to an Amazon DynamoDB table.","A":"Migrate the web tier to Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer.","C":"Migrate the database to an Amazon RDS Multi-AZ deployment."},"topic":"1","timestamp":"2023-12-29 17:34:00"},{"id":"zzSGF33Opp2w0PjY650u","discussion":[{"content":"Selected Answer: B\n\"AWS Local Zones are a type of AWS infrastructure deployment that place compute, storage, database, and other select services closer to large population, industry, and IT centers, enabling you to deliver applications that require single-digit millisecond latency to end-users.\"\n\nA and C tell us to \"deploy the applications in eu-central-1\" which is exactly what we're not supposed to do.\n\nAWS Wavelength zones are AWS deployments in CSP's networks, has nothing to do with this question.\n\nhttps://aws.amazon.com/about-aws/global-infrastructure/localzones/features/?nc1=h_ls","poster":"pentium75","comment_id":"1112868","timestamp":"1720011360.0","upvote_count":"9"},{"content":"Selected Answer: B\nAC is not right \"Because of regulations, the company cannot launch some of its applications in eu-central-1\"\nD: AWS Wavelength is for mobile network\nB: Local Zones can be used to launch apps close to a region but not in a region like EUC1 so this works","poster":"awsgeek75","timestamp":"1720885260.0","upvote_count":"7","comment_id":"1121923"},{"comment_id":"1162211","content":"Correct B:\nAWS Local Zones are an extension of AWS infrastructure and bring AWS services closer to end-users, providing ultra-low latency for applications that require single-digit millisecond latencies. By deploying the applications in AWS Local Zones, the company can meet the latency requirements while also complying with regulations that prevent certain applications from being hosted in the eu-central-1 Region.","upvote_count":"6","poster":"bodakrishna","timestamp":"1724898180.0"},{"content":"Selected Answer: B\nOption B - AWS Local Zones place AWS compute, storage, database, and other select services closer to end-users. This would allow the company to deploy applications within geographic proximity to eu-central-1 without being directly in the region, potentially meeting regulatory requirements and achieving low latency.\n\nWhereas Option D - AWS Wavelength Zones are designed to provide developers the ability to build applications that deliver single-digit millisecond latencies to MOBILE and connected devices. And it's more focused on 5G Apps and may not be directly relevant to Web Apps hosting.","poster":"OSHOAIB","comment_id":"1116325","timestamp":"1720396800.0","upvote_count":"2"},{"poster":"pdragon1981","upvote_count":"2","comment_id":"1114387","timestamp":"1720163880.0","content":"Selected Answer: B\nI would go also for B, was in doubt from B or D but I aggree with pentium75 the wavelenght zones are not designed for this use case however AWS local zones can provide single-digit milisecond latency as described in the link\nhttps://aws.amazon.com/about-aws/global-infrastructure/localzones/"},{"poster":"Naijaboy99","upvote_count":"4","timestamp":"1719711360.0","content":"option B","comment_id":"1109372"},{"content":"Selected Answer: D\nAWS Wavelength (Option D): AWS Wavelength Zones bring AWS services to the edge of the 5G network, providing ultra-low latency for applications that require single-digit millisecond latencies. Deploying applications in Wavelength Zones allows the company to extend its VPC from the eu-central-1 Region to the chosen Wavelength Zone, providing the required low-latency access.","comment_id":"1108911","poster":"meenkaza","timestamp":"1719671820.0","comments":[{"comment_id":"1113391","timestamp":"1720070760.0","content":"It looks like D is correct from diagram in the following url.\nhttps://docs.aws.amazon.com/wavelength/latest/developerguide/how-wavelengths-work.html","upvote_count":"1","poster":"Roger_Liu"},{"poster":"pentium75","content":"\"Wavelength Zones are AWS infrastructure deployments that embed AWS compute and storage services within communications service providers’ (CSP) 5G networks\". They reduce latency for mobile users in the CSP's network, but this is not asked here. Local Zones provide \"single-digit millisecond latency\".","timestamp":"1720011480.0","upvote_count":"3","comment_id":"1112870"}],"upvote_count":"6"}],"answer_ET":"B","exam_id":31,"unix_timestamp":1703867820,"choices":{"C":"Deploy the applications in eu-central-1. Extend the company’s VPC from eu-central-1 to the regional edge caches in Amazon CloudFront.","D":"Deploy the applications in AWS Wavelength Zones by extending the company’s VPC from eu-central-1 to the chosen Wavelength Zone.","A":"Deploy the applications in eu-central-1. Extend the company’s VPC from eu-central-1 to an edge location in Amazon CloudFront.","B":"Deploy the applications in AWS Local Zones by extending the company's VPC from eu-central-1 to the chosen Local Zone."},"topic":"1","isMC":true,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/129726-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":670,"timestamp":"2023-12-29 17:37:00","question_images":[],"answer_description":"","question_text":"A company wants to migrate its web applications from on premises to AWS. The company is located close to the eu-central-1 Region. Because of regulations, the company cannot launch some of its applications in eu-central-1. The company wants to achieve single-digit millisecond latency.\n\nWhich solution will meet these requirements?","answer":"B","answers_community":["B (77%)","D (23%)"]}],"exam":{"isMCOnly":true,"isImplemented":true,"isBeta":false,"provider":"Amazon","id":31,"lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":134},"__N_SSP":true}