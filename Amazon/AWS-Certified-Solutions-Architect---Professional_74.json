{"pageProps":{"questions":[{"id":"kbBlJo4hJTM0vqvBUSty","answer_images":[],"answer":"C","unix_timestamp":1616033160,"question_id":366,"timestamp":"2021-03-18 03:06:00","answer_description":"","answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/47613-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"D":"Use reduced redundancy storage (RRS) for all data in Amazon S3. Add Spot Instances to Amazon EMR jobs. Use Reserved Instances for Amazon Redshift.","B":"Use reduced redundancy storage (RRS) for PDF and .csv data in S3. Add Spot Instances to EMR jobs. Use Spot Instances for Amazon Redshift.","A":"Use reduced redundancy storage (RRS) for all data In S3. Use a combination of Spot Instances and Reserved Instances for Amazon EMR jobs. Use Reserved Instances for Amazon Redshift.","C":"Use reduced redundancy storage (RRS) for PDF and .csv data In Amazon S3. Add Spot Instances to Amazon EMR jobs. Use Reserved Instances for Amazon Redshift."},"question_text":"Your department creates regular analytics reports from your company's log files All log data is collected in Amazon S3 and processed by daily Amazon Elastic\nMapReduce (EMR) jobs that generate daily PDF reports and aggregated tables in CSV format for an Amazon Redshift data warehouse.\nYour CFO requests that you optimize the cost structure for this system.\nWhich of the following alternatives will lower costs without compromising average performance of the system or data integrity for the raw data?","answers_community":["C (100%)"],"topic":"1","isMC":true,"discussion":[{"poster":"tkanmani76","upvote_count":"6","timestamp":"1642557000.0","content":"C - Due to the fault-tolerant nature of big data workloads on EMR, they can continue processing, even when interrupted. Running EMR on Spot Instances drastically reduces the cost of big data, allows for significantly higher compute capacity, and reduces the time to process big data sets.","comment_id":"527143"},{"upvote_count":"1","content":"Selected Answer: C\nc is the only logic answer","poster":"SkyZeroZx","timestamp":"1687185240.0","comment_id":"927607"},{"comment_id":"684261","upvote_count":"2","content":"Selected Answer: C\nc is the only logic answer","poster":"davideccc","timestamp":"1664633880.0"},{"content":"C\nFirst of all this question is outdated, since as of 2020, RRS is not one of the available object classes for S3. So, this question will never come in certification exam.\nhttps://aws.amazon.com/ec2/spot/use-case/emr/ provides an use case for EC2 sport instances \"Amazon EMR on EC2 Spot Instances\". Due to the fault-tolerant nature of big data workloads on EMR, they can continue processing, even when interrupted. Running EMR on Spot Instances drastically reduces the cost of big data, allows for significantly higher compute capacity, and reduces the time to process big data sets. Also, if Raw data is available all processing can be redone.","poster":"DashL","timestamp":"1636049700.0","comment_id":"409082","upvote_count":"2"},{"poster":"01037","comment_id":"345003","upvote_count":"1","timestamp":"1635813900.0","content":"C.\nAs long as the original data exist, you can always generate reports."},{"timestamp":"1635407760.0","upvote_count":"1","poster":"blackgamer","comment_id":"336035","content":"I believe the answer is C. The requirement is not to compromise performance and integrity of Raw data. The raw data should still be in Standard Storage. ue to the fault-tolerant nature of big data workloads on EMR, they can continue processing, even when interrupted. Running EMR on Spot Instances drastically reduces the cost of big data, allows for significantly higher compute capacity, and reduces the time to process big data sets."},{"upvote_count":"3","poster":"aws_arn_name","comment_id":"334444","content":"Why use RRS instead of S3 Standard . The S3 Standard storage class is more cost effective https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html#sc-freq-data-access","timestamp":"1634950620.0"},{"content":"A.\nthe \"creates regular analytics reports\" requirement, you cannot achieve it with only spot instances.","timestamp":"1633987740.0","comment_id":"324920","upvote_count":"3","comments":[{"upvote_count":"1","poster":"bobsmith2000","comment_id":"590085","timestamp":"1650640980.0","content":"Pay attention to \"without compromising data integrity for the raw data\". Which means that you cannot store raw data using RRS storage class.\nAns. seems to be C"}],"poster":"cldy"},{"timestamp":"1632781020.0","comment_id":"313729","content":"Correct Ans is A as Spot instance in all other options will effect performance","poster":"ExtHo","upvote_count":"1"}],"question_images":[],"exam_id":32},{"id":"LjhmL0P8SOkdJ4afJoW5","answer_images":[],"unix_timestamp":1568082840,"discussion":[{"content":"Looks like B, C and D are correct. But I prefer B since SQS provides reliability & Lambda gives scalability.\nC (an ECS container) & D (EC2 instances) don't give HA & scale.","timestamp":"1632445980.0","upvote_count":"18","comment_id":"16149","poster":"chaudh"},{"poster":"donathon","upvote_count":"8","comment_id":"13373","comments":[{"comment_id":"14065","comments":[{"timestamp":"1633883280.0","content":"Amazon Kinesis is differentiated from Amazon's Simple Queue Service (SQS) in that Kinesis is used to enable real-time processing of streaming big data. SQS, on the other hand, is used as a message queue to store messages transmitted between distributed application components","poster":"oatif","upvote_count":"6","comment_id":"117999"}],"upvote_count":"1","timestamp":"1632295500.0","poster":"donathon","content":"Additional info: Q: How does Amazon Kinesis Data Streams differ from Amazon SQS?\n\nAmazon Kinesis Data Streams enables real-time processing of streaming big data. It provides ordering of records, as well as the ability to read and/or replay records in the same order to multiple Amazon Kinesis Applications. The Amazon Kinesis Client Library (KCL) delivers all records for a given partition key to the same record processor, making it easier to build multiple applications reading from the same Amazon Kinesis data stream (for example, to perform counting, aggregation, and filtering).\nhttps://aws.amazon.com/kinesis/data-streams/faqs/\nhttps://aws.amazon.com/blogs/big-data/unite-real-time-and-batch-analytics-using-the-big-data-lambda-architecture-without-servers/"},{"content":"SQS sceptical to duplicates? When I receive order I create a message in SQS and I can process it from Lambda. Where this duplicates issues comes from? Even if duplicates occurs due to app functionality, the issue will be at Kinesis as well. Also FIFO is not required. The order of the ORDER is not an issue as long as the order gets processed. If ordering is an issue, this will be problem in Kinesis as well, I think.","poster":"StelSen","comment_id":"440650","upvote_count":"2","timestamp":"1636104840.0"}],"content":"A: It’s no reliable even with auto-scaling, it may not be able to meet sudden demand unless there are very good effort done on a schedule to spin up instances ahead of the demand. Still, it’s difficult to know how much you need.\nB: SQS suitable and reliable initially. But remember that this is an order processing application SQS is sceptical to duplicates and you would not want duplicates in order processing. You need to choose FIFO SQS which is not in the answer.\nC: Step Functions replaces SWF but a workflow is not needed here. What we need is a reliable storage like SQS to store the huge surge in orders that may occur during campaigns.\nD: Kinesis Streams recently was just able to auto scale to demand so this should be it. https://aws.amazon.com/blogs/big-data/scaling-amazon-kinesis-data-streams-with-aws-application-auto-scaling/\nhttps://aws.amazon.com/kinesis/data-streams/faqs/","timestamp":"1632292440.0"},{"upvote_count":"3","content":"Key here is \"loosely coupled\", its a common pattern to use a Queue to decouple apps, in this casa SQS is the best choice, so the answer is B.","poster":"superuser784","comment_id":"706641","timestamp":"1666976220.0"},{"upvote_count":"2","timestamp":"1648592280.0","comment_id":"577893","content":"Selected Answer: B\nB looks right","poster":"jj22222"},{"timestamp":"1640857620.0","upvote_count":"1","comment_id":"513196","poster":"cldy","content":"B is correct."},{"comment_id":"491251","content":"B is right","upvote_count":"1","timestamp":"1638332580.0","poster":"AzureDP900"},{"poster":"andylogan","timestamp":"1636210980.0","upvote_count":"1","comment_id":"449978","content":"It's B"},{"comment_id":"445798","timestamp":"1636175700.0","poster":"Kopa","content":"keyword loosely coupled, im going for B","upvote_count":"1"},{"comment_id":"428899","poster":"AWS_Noob","content":"B, major key word there being Loosely coupled","upvote_count":"1","timestamp":"1635954000.0"},{"comment_id":"426338","content":"I go with B","upvote_count":"1","poster":"Kopa","timestamp":"1635943680.0"},{"upvote_count":"1","comment_id":"347295","timestamp":"1635868620.0","content":"the answer is B","poster":"macshild"},{"comment_id":"335348","content":"I'll go with B","timestamp":"1635782340.0","upvote_count":"1","poster":"WhyIronMan"},{"timestamp":"1635776880.0","content":"I would seek out the keywords such as HA, Sporadic (irregular intervals) and loosely coupled and determine suitable services as SQS, Lamda, Lamda@edge to be used so my answer is B","poster":"Pupu86","comment_id":"306868","upvote_count":"1"},{"poster":"Kian1","comment_id":"289429","timestamp":"1635765240.0","content":"Ans B 100%","upvote_count":"2"},{"content":"B is the answer the key word is that processing order thus SQS is the real deal here..","comment_id":"284626","poster":"LoganIsh","timestamp":"1635628140.0","upvote_count":"2"},{"content":"B is my choice\nFor those who picked D, although technically possible but what AWS is evaluating you as well is to pick the right service for the right use case. Kenisis is not the right choice for queues, it is best for streaming","timestamp":"1635606420.0","upvote_count":"7","comment_id":"283980","poster":"Ebi"},{"upvote_count":"1","comment_id":"283727","content":"Step functions are typical use cases for Order processing where it may take different flows and manual workflows. But in the scope of this question to receive and store in async fashion, SQS is good enough for \"simple\" requirement. \nI ll go with B","timestamp":"1635517920.0","poster":"bnagaraja9099"},{"upvote_count":"1","poster":"Satya1405","content":"The application has a sporadic traffic pattern and should be able to scale during marketing campaigns to process the orders.\n\nI could see auto scaling could be possible only with SQS.","comment_id":"281463","timestamp":"1635404100.0"},{"poster":"sanjaym","upvote_count":"1","timestamp":"1635294060.0","comment_id":"262928","content":"It's B"},{"comment_id":"261537","content":"Ans is D - \"application is responsible for receiving and processing orders before storing them \" . so kinesis can do data analytics before store in to dynamoDB","timestamp":"1635278100.0","upvote_count":"1","poster":"jayakumarchellam"},{"upvote_count":"1","content":"High availability takes out the EC2 answers so B","comment_id":"259032","poster":"kopper2019","timestamp":"1635248280.0"},{"content":"seems B","timestamp":"1635173460.0","comment_id":"242332","poster":"gookseang","upvote_count":"1"},{"comment_id":"241937","timestamp":"1635131160.0","content":"Correct answer is B. Key is SQS","poster":"T14102020","upvote_count":"1"},{"content":"B ... THEY KEY HERE IS THE WORDING \"LOOSELY COUPLED\" The problem is AWS has got us all so wound up looking for trick questions etc .. that we sometimes forget they do give us easy ones !! .. AWS has traumatised us all :0 :)","timestamp":"1634845020.0","comment_id":"232050","upvote_count":"1","poster":"petebear55"},{"timestamp":"1634747460.0","content":"I'll Go with B","comment_id":"228535","upvote_count":"3","poster":"jackdryan"},{"upvote_count":"1","poster":"Bulti","comment_id":"226982","timestamp":"1634647800.0","content":"Answer is B"},{"timestamp":"1634566860.0","poster":"petebear55","upvote_count":"2","comment_id":"221032","content":"Answer B: I realy wish the author here would only put the correct answer if he is 100 percent correct .. The answer is B .. D is unsuitable as this environment as previously mentioned uses the term \"loosely coupled\" so SQS would be appropriate. Kinesis is not suitable for such a simple build. if it was an IOT application processing \"streams\" of data then kinesis would be suitable ... but not in this case!! ... I'm beginning to think this site is ran b Amazon to deliberately throw people off :("},{"comment_id":"216456","content":"My answer is B. Kinesis does not auto scale and we need to provison the shards beforehand. So the statement in the question The application has a sporadic traffic pattern and should be able to scale during marketing campaigns - cannot be accomodated. As AWS SQS is a fully managed app and scales transparently, we can choose B","upvote_count":"1","timestamp":"1634539020.0","poster":"jjp123"},{"timestamp":"1634416740.0","upvote_count":"1","comment_id":"215718","poster":"vjt","content":"B is the answer. \nBetween B and D, B is better and scale automatically.\nFor C, you cannot use step function state machine to directly ingest incoming orders. So it wont work."},{"poster":"ishuiyutian","timestamp":"1634362740.0","content":"B is correct.","upvote_count":"1","comment_id":"207508"},{"content":"For simple solution B is the best option.","timestamp":"1634206440.0","poster":"Paitan","upvote_count":"1","comment_id":"198362"},{"timestamp":"1634177400.0","poster":"SlinkySideWinder","content":"C sounds feasible but mentions Amazon ECS which is more complex than B, requirements flag 'Simple'","comment_id":"148714","upvote_count":"2"},{"comment_id":"148563","comments":[{"timestamp":"1634074440.0","poster":"fullaws","comment_id":"148564","content":"https://www.amazonaws.cn/en/kinesis/data-streams/faqs/ - \"note, however, that you'll need to provision enough shards ahead of time\"","upvote_count":"1"}],"upvote_count":"1","content":"B is correct, SQS is more reliable, 1) in term of scalability compare to Kinesis Data stream require provisioning enough of shard beforehand in order for it to scale which SQS does not required. 2) In term of data retention if anything goes wrong, kinesis data stream store lesser day than SQS","timestamp":"1634004900.0","poster":"fullaws"},{"poster":"IAmNotLambda","timestamp":"1634000580.0","content":"B. D can't be it:\n\nhttps://aws.amazon.com/kinesis/data-streams/faqs/ (Read When should I use Kinesis and SQS). Question asks for \"reliable\".\n\nB for me until and unless someone has a better explanation?","upvote_count":"1","comment_id":"138428"},{"timestamp":"1633978620.0","poster":"NikkyDicky","upvote_count":"1","comment_id":"134126","content":"B more likely"},{"timestamp":"1633923180.0","content":"answer :B","poster":"mat2020","comment_id":"133255","upvote_count":"1"},{"timestamp":"1633895460.0","poster":"ricoyao","content":"I go for \"B\". It is not necessary to use FIFO SQS. The \"order\" in question is not for \"sort\".","comment_id":"126195","upvote_count":"1"},{"timestamp":"1633739340.0","content":"Answer B. SQS -> reliable; Lambda -> Scalable/HA","upvote_count":"2","poster":"Shawn1","comment_id":"110117"},{"poster":"meenu2225","content":"B makes sense, reliable and SQS will make sure that message is processed.","timestamp":"1633680660.0","comment_id":"109857","upvote_count":"3"},{"upvote_count":"1","content":"\"The application has a sporadic traffic pattern and should be able to scale\"\nAmong B and D . B would satisfy this condition more","poster":"JAWS1600","timestamp":"1633657620.0","comment_id":"107275"},{"comments":[{"timestamp":"1633760100.0","upvote_count":"2","poster":"roger8978","comment_id":"112882","content":"ec2 is the consumer. https://aws.amazon.com/kinesis/data-streams/?nc=sn&loc=0"}],"content":"d is not correct :- ec2 is not the consumer for kinesis data streams.","comment_id":"104296","poster":"pgarg","upvote_count":"4","timestamp":"1633588020.0"},{"comment_id":"99763","poster":"NKnab","timestamp":"1633567620.0","upvote_count":"1","content":"i go with B. loosely coupled, scalable . Problem with D -no autoscaling"},{"comment_id":"90070","upvote_count":"3","timestamp":"1633433040.0","poster":"JAWS1600","content":"SQS- Key Words here are \"Loosley Coupled\" and \"reliable\" architecture, which is SQS. There is no requirement for FIFO ( sequencing). In the real-world, the Kinesis solution will be a better solution and also use FIFO with SQS. However, we need to focus on the requirements, not the approach of providing them best enterprise solution."},{"comment_id":"75514","upvote_count":"3","poster":"frankzeng","comments":[{"content":"I believe it's B.\nAs frankzeng said, Kinesis is for different purpose, and isn't the best fit here.\nAnd D without ASG doesn't provide auto scalability.","poster":"newme","upvote_count":"1","timestamp":"1635127200.0","comment_id":"239162"}],"timestamp":"1633377540.0","content":"not D,\nhttps://docs.aws.amazon.com/streams/latest/dev/introduction.html\nWhat Can I Do with Kinesis Data Streams?\nYou can use Kinesis Data Streams for rapid and continuous data intake and aggregation. The type of data used can include IT infrastructure log data, application logs, social media, market data feeds, and web clickstream data. Because the response time for the data intake and processing is in real time, the processing is typically lightweight."},{"timestamp":"1633324740.0","comment_id":"69662","upvote_count":"2","content":"B seems correct. SQS provides Message Persistence (Reliability) & Scalability along with Lambda service as Order Processor. This can also be setup through Step Functions service if needed. I don't understand why I would need Kinesis here when there is no Big Data or Real-Time process. Asynchronous Processing should work.","poster":"Smart"},{"poster":"IsaacTeh","upvote_count":"5","content":"answer is b \nbecause \"loosely coupled order processing application\"","timestamp":"1633306560.0","comment_id":"57151"},{"timestamp":"1633049700.0","content":"I believe the answer is B and that the Lambda function should be written to be idempotent (Lambda handles looking for duplicates and not processing them). It is a best practice.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/lambda-function-idempotent/","comment_id":"51330","comments":[{"upvote_count":"2","poster":"AWSPro24","comment_id":"51331","content":"It can poll the DDB table to see if the transaction id exists before executing. If exists - do nothing Else process the order.","timestamp":"1633146060.0"}],"upvote_count":"2","poster":"AWSPro24"},{"upvote_count":"3","poster":"amog","timestamp":"1632994260.0","content":"Answer is B\nLambda for HA and scalable.","comment_id":"44826"},{"comment_id":"41592","poster":"CloudFloater","upvote_count":"1","timestamp":"1632891720.0","content":"Inclined towards C\n(simple solution would be SQS but in reality the solutions would be usually comprehensive)\n-Step functions can include SQS, ECS, Dynamodb as service tasks for order processing and storage solutions\n-Step Functions are the most durable/reliable with 1-year duration for each work flow step\n-Each Step Function workflow step can Scale independently\n\nreference:\nhttps://aws.amazon.com/step-functions/faqs/\n\"While you can use Amazon SQS to build basic workflows to coordinate your distributed application, you can get this facility out-of-the-box with Step Functions, alongside other application-level capabilities.\""},{"comment_id":"41167","poster":"markpark","upvote_count":"2","content":"answer is B","timestamp":"1632875400.0"},{"poster":"cinopi","comment_id":"32503","timestamp":"1632556020.0","upvote_count":"3","content":"\"MOST reliable approach\" implies SQS (data can be retained in it for 14 days)\nKinesis (at max 7 days)\n\nAns: B"},{"upvote_count":"1","comment_id":"30432","content":"I go with B\nReading Kinesis for order processing is not good, if the application needs to scale then multiple clients on multiple EC2 will be needed and Kinesis uses checkpoint which will provide copy of each order to every EC2 client. \n\nOption B is most appropriate.","timestamp":"1632490440.0","poster":"dojo"},{"upvote_count":"4","timestamp":"1632328020.0","comments":[{"timestamp":"1634198100.0","upvote_count":"1","content":"I think the mention here is reliability, SQS isn't it","comment_id":"183632","poster":"sam422"},{"poster":"LunchTime","content":"Moon's analysis makes a lot of sense and I agree with \"C\" being the answer. The problem with \"B\", as donathon mentioned, is that in an order processing application you want to ensure you don't process an order more then once. That can only be guaranteed with SQS if it's FIFO SQS and B does not indicate this. Therefore I would rule out B. Also, the link https://aws.amazon.com/step-functions/faqs/ seems to also support AWS Step Functions in the answer to \"Q: When should I use AWS Step Functions vs. Amazon SQS?\".","timestamp":"1632854400.0","comments":[{"poster":"SamuelK","upvote_count":"1","content":"it's processing order, it doesn't have to be in order. Lambda function needs to delete the queue once an order has been processed. I would go with B","comment_id":"53889","timestamp":"1633198200.0"}],"comment_id":"34600","upvote_count":"1"}],"content":"I would go with answer \"C\". Step function.\nC: step function is meant for simple, loosely coupled, spike handling ordering system.\nfor spikes handling, check slide 26 in AWS presentation:\nhttps://www.slideshare.net/AmazonWebServices/building-business-workflows-with-aws-step-functions\nThe question is saying that the application is responsible for processing, and storing the data. So Step function, can forward the requests to ECS for processing, then take them back to DynamoDB for storing.\nB: SQS does not have logic for processing and storing!\nD: Kinesis can not do both automatically!\n\nFinally, Step Function is the MOST Reliable, as it has a built in correction!","comment_id":"14636","poster":"Moon"},{"upvote_count":"1","poster":"huhupai","comment_id":"12979","timestamp":"1632291420.0","content":"I prefer B, the EC2 instances without ASG in multi-AZ in option D is not reliable"},{"poster":"awsec2","upvote_count":"2","comment_id":"12454","content":"d is right https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html","timestamp":"1632204960.0"},{"comment_id":"10543","poster":"One_picese","upvote_count":"2","content":"I think that D is a right answer,please refer to following article.\nhttps://www.examtopics.com/discussions/amazon/view/4976-exam-aws-certified-solutions-architect-professional-topic-2/\nhttps://docs.aws.amazon.com/step-functions/latest/dg/welcome.html\nhttps://docs.aws.amazon.com/streams/latest/dev/introduction.html","timestamp":"1632100260.0"},{"timestamp":"1632078000.0","upvote_count":"5","comment_id":"10379","comments":[{"comments":[{"poster":"maximoh","content":"Sporadic: lambda functions are only paid when used.\nSimple: SQS instead of Kinesis.\nAlso EC2 isn't in any way as escalable as Lambda.","upvote_count":"1","comment_id":"202985","timestamp":"1634326500.0"}],"upvote_count":"11","timestamp":"1632157860.0","content":"I agree. B is the best choice","poster":"dpvnme","comment_id":"10949"}],"content":"why not \"b\"","poster":"awsec2"}],"exam_id":32,"answer":"B","topic":"1","answers_community":["B (100%)"],"answer_ET":"B","question_id":367,"timestamp":"2019-09-10 04:34:00","question_text":"An e-commerce company is revamping its IT infrastructure and is planning to use AWS services. The company's CIO has asked a Solutions Architect to design a simple, highly available, and loosely coupled order processing application. The application is responsible for receiving and processing orders before storing them in an Amazon DynamoDB table. The application has a sporadic traffic pattern and should be able to scale during marketing campaigns to process the orders with minimal delays.\nWhich of the following is the MOST reliable approach to meet the requirements?","choices":{"D":"Receive the orders in Amazon Kinesis Data Streams and use Amazon EC2 instances to process them.","B":"Receive the orders in an Amazon SQS queue and trigger an AWS Lambda function to process them.","C":"Receive the orders using the AWS Step Functions program and trigger an Amazon ECS container to process them.","A":"Receive the orders in an Amazon EC2-hosted database and use EC2 instances to process them."},"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/4976-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"question_images":[]},{"id":"qZde3WQ3lgLZCdG1oszF","question_id":368,"timestamp":"2019-09-24 12:43:00","answer":"A","choices":{"B":"Employ a user data script to install the framework but compress the installation files to make them smaller.","D":"Configure an AWS OpsWorks cookbook that installs the framework instead of employing user data. Use this cookbook as a base for all deployments.","A":"Create a pipeline to build a custom AMI with the framework installed and use this AMI as a baseline for application deployments.","C":"Create a pipeline to parallelize the installation tasks and call this pipeline from a user data script."},"answer_ET":"A","isMC":true,"answer_images":[],"exam_id":32,"question_images":[],"answer_description":"","unix_timestamp":1569321780,"answers_community":["A (100%)"],"discussion":[{"content":"A\nB: Does not solve the problem.\nC\\D: This still does not solve the problem because it still needs 30minutes to install the framework.","upvote_count":"31","poster":"donathon","comment_id":"13377","timestamp":"1632424680.0","comments":[{"timestamp":"1633434300.0","upvote_count":"4","content":"The bottleneck is inbstalling the framework, so to solve this, pre-built the image with desired framework. (AMI buidling)","poster":"achambok","comment_id":"163596"},{"comments":[{"timestamp":"1636020120.0","poster":"AWSum1","upvote_count":"2","comment_id":"444758","content":"Opsworks is used for Chef and Puppet"},{"timestamp":"1635906420.0","comment_id":"440651","poster":"StelSen","upvote_count":"3","content":"Technically D works. But how about 30 mins duration? Can this be done faster with OpsWorks? Option-A seems correct."}],"upvote_count":"3","timestamp":"1634271060.0","content":"D solves the problem. \"Ops Works can build or update Framework based on a few configurations that can be externalized. More automated way and less error-prone. The most recent way.\" I agree with consultsk below.","comment_id":"279960","poster":"shammous"}]},{"upvote_count":"9","timestamp":"1632164280.0","content":"a should be","poster":"awsec2","comment_id":"12455"},{"timestamp":"1686245520.0","content":"A.\nApplication changes frequently while its dependency framework never changes.\nSo bake a custom AMI with framework installed to save your time.","comment_id":"918519","poster":"Jesuisleon","upvote_count":"1"},{"timestamp":"1684353000.0","upvote_count":"1","comment_id":"900479","content":"A is the answer","poster":"tkasa"},{"content":"Selected Answer: A\nAgree with A.","upvote_count":"1","timestamp":"1668262680.0","poster":"DarthYoda","comment_id":"716737"},{"poster":"DasguptaS","content":"Selected Answer: A\nshould be A","upvote_count":"1","comment_id":"715076","timestamp":"1668071400.0"},{"upvote_count":"2","comment_id":"526020","poster":"Ni_yot","timestamp":"1642446360.0","content":"Its A. if you pre build the image then deploy, its much faster and time is saved"},{"poster":"vinodkp","upvote_count":"3","comment_id":"517159","timestamp":"1641356040.0","content":"Selected Answer: A\ncustom ami is the best solution"},{"poster":"cldy","timestamp":"1641018000.0","content":"A correct.","comment_id":"514396","upvote_count":"1"},{"comment_id":"506361","timestamp":"1640112240.0","poster":"AzureDP900","upvote_count":"1","content":"A is the correct answer."},{"timestamp":"1639192440.0","poster":"challenger1","upvote_count":"1","content":"My Answer: A\nCustom AMI","comment_id":"499063"},{"comment_id":"450885","timestamp":"1636257540.0","upvote_count":"1","poster":"moon2351","content":"Answer is A"},{"content":"It's A - The bottleneck is installing the framework, so to solve this, pre-built the image with desired framework. (AMI building)","upvote_count":"1","timestamp":"1636041540.0","poster":"andylogan","comment_id":"449993"},{"poster":"Mzehk","comment_id":"423120","timestamp":"1635724140.0","upvote_count":"1","content":"A should be the right answer"},{"poster":"01037","upvote_count":"2","content":"A\n\nhttps://aws.amazon.com/image-builder/","timestamp":"1635693720.0","comment_id":"386237"},{"upvote_count":"1","comment_id":"366415","timestamp":"1635540240.0","content":"Even Opsworks can install automatically it will the whole installation process, so it will no differ from the script, with a pre-built image you only need to install the framework one time, so answer is A","poster":"zolthar_z"},{"poster":"Radhaghosh","content":"Main phrase \"30 Mins\" Bottleneck for framework installation \nOnly pre-build AMI is the option.\nI will go with A","comment_id":"362485","timestamp":"1635432480.0","upvote_count":"2"},{"timestamp":"1635289560.0","poster":"victordun","comment_id":"349841","upvote_count":"1","content":"A - key point is framework installation, precook it with codepipeline to get the AMI ready. (Precooking an AMI is not ideal if the configs are quick)"},{"upvote_count":"1","content":"A is the correct answer.","poster":"blackgamer","timestamp":"1635115920.0","comment_id":"343766"},{"comment_id":"335349","timestamp":"1635092940.0","upvote_count":"2","poster":"WhyIronMan","content":"I'll go with A"},{"upvote_count":"1","poster":"alisyech","comment_id":"322392","timestamp":"1635022680.0","content":"A is the correct answer"},{"poster":"cloudinvader","upvote_count":"3","comment_id":"310263","content":"Correct option \"A\": The main bottleneck is framework installation. If we create AMI, next time onward we can reduce launching the application on the EC2 to a few min. We can use Userdata as a bootstrap script when launching the Application.","timestamp":"1634716500.0"},{"upvote_count":"2","poster":"wind","content":"go with A","comment_id":"290738","timestamp":"1634460840.0"},{"timestamp":"1634460420.0","upvote_count":"6","content":"A is the answer,\nD still possible but does not address 30 min bottleneck, framework still has to be installed on each deployment but instead of userdata opsworks runbooks will be used.\nDefinitely A","poster":"Ebi","comment_id":"283982"},{"timestamp":"1634186280.0","upvote_count":"1","content":"A to me","poster":"sanjaym","comment_id":"262934"},{"poster":"consultsk","comments":[{"timestamp":"1634419320.0","content":"I don't understand how using Ops work will make the deployment faster. The question is about how to speed up the process. ? A seems to be logical","poster":"bnagaraja9099","comment_id":"283731","upvote_count":"2"}],"upvote_count":"5","comment_id":"247979","content":"Based on the conversations, either A or D. \nKey Words: Framework, quick deployment with minimal downtime\nA: This is an option and the AMI is to be built with the framework. Perform framework changes, recreate AMI, and make it ready.\nD- OpsWorks: \nOps Works can build or update Framework based on a few configurations that can be externalized. More automated way and less error-prone. The most recent way. \nhttps://aws.amazon.com/opsworks/stacks/\nhttps://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook.html\nhttps://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook-installingcustom-repo.html\n\nMy final answer: D","timestamp":"1634120280.0"},{"upvote_count":"1","timestamp":"1634094360.0","content":"A is correct answer. Key is already prepared AMI","comment_id":"241940","poster":"T14102020"},{"poster":"jackdryan","upvote_count":"3","comment_id":"228537","content":"I'll go with A","timestamp":"1633947720.0"},{"comment_id":"226983","timestamp":"1633894200.0","content":"Answer is A","poster":"Bulti","upvote_count":"2"},{"content":"IMO, A to speed up the Framework installation , as per requested by the question. Application deploy in itself is not managed that way, with A we just speed up the framework deployement","poster":"Edgecrusher77","timestamp":"1633789260.0","upvote_count":"1","comment_id":"223557"},{"comment_id":"221441","content":"A cannot be answer. AMI is a machine image that you install as part of setting up EC2. Oppsworks Stacks provides solution for application deployments.\nThe answer should be D","poster":"srinivasa","upvote_count":"3","timestamp":"1633651980.0","comments":[{"comment_id":"223295","upvote_count":"2","content":"How will this help in reducing framework installation time? Ask is to speed up the process. IMO it s should be A.","timestamp":"1633707480.0","poster":"Rajeev"}]},{"upvote_count":"3","timestamp":"1633626780.0","poster":"kj07","content":"You need to prepare an AMI with the framework installed. This way you can speed up the process.\n\nAnswer: A","comment_id":"221063"},{"timestamp":"1633446060.0","upvote_count":"1","poster":"petebear55","content":"A...................","comment_id":"221041"},{"timestamp":"1633439820.0","upvote_count":"1","content":"A framework installation takes 30 minutes = AMI","poster":"raj0101","comment_id":"180599"},{"timestamp":"1633305120.0","upvote_count":"1","comment_id":"148565","content":"A is correct","poster":"fullaws"},{"timestamp":"1633236720.0","upvote_count":"1","content":"A for sure","poster":"NikkyDicky","comment_id":"134129"},{"comment_id":"133557","poster":"noisonnoiton","upvote_count":"2","content":"go with A\nAMI, F/W installed","timestamp":"1633153560.0"},{"poster":"JAWS1600","comment_id":"107276","content":"D - cookbooks","timestamp":"1633153440.0","upvote_count":"4"},{"comments":[{"upvote_count":"2","comment_id":"76703","content":"indeed you can parallelize the task, however you are talking of dependent sub-tasks, first install the framework and then install the app, even if the tasks are parallel on of them should wait till the other one finished, otherwise errors may occur during test stage or compile in a pipeline job if the framework is missing during app installation","timestamp":"1633110420.0","poster":"juanC1917"}],"timestamp":"1632771180.0","content":"Correct Answer: C\nParallel Execution\nYou can use CodePipeline to model your build, test, and deployment actions to run in parallel in order to increase your workflow speeds.\nhttps://aws.amazon.com/codepipeline/features/?nc=sn&loc=2","upvote_count":"2","poster":"NNHAN","comment_id":"61762"},{"comment_id":"44828","upvote_count":"2","content":"Answer is A","poster":"amog","timestamp":"1632748080.0"},{"upvote_count":"1","comment_id":"41168","poster":"markpark","content":"answer is A","timestamp":"1632656820.0"},{"poster":"DJTau","comment_id":"14817","content":"A\nhttps://aws.amazon.com/codepipeline/features/?nc=sn&loc=2","timestamp":"1632630900.0","upvote_count":"4"}],"question_text":"A company has an application written using an in-house software framework. The framework installation takes 30 minutes and is performed with a user data script. Company Developers deploy changes to the application frequently. The framework installation is becoming a bottleneck in this process.\nWhich of the following would speed up this process?","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/5643-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"W4Cin1d1ygT7gr7MnI0i","exam_id":32,"unix_timestamp":1568747460,"timestamp":"2019-09-17 21:11:00","question_id":369,"choices":{"A":"Create individual accounts for each business unit and add the account to an OU in AWS Organizations. Modify the OU to ensure that the particular services are blocked. Federate each account with an IdP, and create separate roles for the business units and the Security team.","B":"Create individual accounts for each business unit. Federate each account with an IdP and create separate roles and policies for business units and the Security team.","D":"Create one shared account for the entire company. Create individual IAM policies and resource tags for each business unit. Federate the account with an IdP, and create separate roles for the business units and the Security team.","C":"Create one shared account for the entire company. Create separate VPCs for each business unit. Create individual IAM policies and resource tags for each business unit. Federate each account with an IdP, and create separate roles for the business units and the Security team."},"answer_description":"","answer_ET":"A","question_text":"A company wants to ensure that the workloads for each of its business units have complete autonomy and a minimal blast radius in AWS. The Security team must be able to control access to the resources and services in the account to ensure that particular services are not used by the business units.\nHow can a Solutions Architect achieve the isolation requirements?","discussion":[{"upvote_count":"30","content":"This question is made for A.","timestamp":"1632160860.0","poster":"dpvnme","comment_id":"11475"},{"comment_id":"13381","content":"A\nThe best way is to use SCP and individual account.\nB: This is difficult to manage.\nC\\D: Does not reduce the blast radius.","timestamp":"1632686940.0","poster":"donathon","upvote_count":"15"},{"upvote_count":"1","content":"Selected Answer: A\nKEYWORD == AWS Organizations","comment_id":"929799","poster":"SkyZeroZx","timestamp":"1687370160.0"},{"content":"Selected Answer: A\nA no brainer","upvote_count":"1","timestamp":"1661982120.0","poster":"epomatti","comment_id":"655512"},{"upvote_count":"1","comment_id":"649333","content":"I choose d, because others are all saying that an idp with each accounts.","timestamp":"1660984200.0","poster":"tracyli"},{"upvote_count":"2","timestamp":"1639146840.0","poster":"cldy","comment_id":"498702","content":"A. Create individual accounts for each business unit and add the account to an OU in AWS Organizations. Modify the OU to ensure that the particular services are blocked. Federate each account with an IdP, and create separate roles for the business units and the Security team."},{"upvote_count":"1","comment_id":"493413","content":"I'll go with A","timestamp":"1638574920.0","poster":"AzureDP900"},{"timestamp":"1636293060.0","upvote_count":"1","content":"A \n---","comment_id":"452713","poster":"student22"},{"comment_id":"449995","poster":"andylogan","content":"It's A","timestamp":"1636194480.0","upvote_count":"2"},{"content":"In question it is specifying security team wants to control resources and services.. from scp you cannot control resources.. so answer should be B","comment_id":"407726","poster":"Shran","upvote_count":"1","timestamp":"1636048140.0"},{"poster":"victordun","timestamp":"1636009800.0","content":"A - SCP hidden deliberately, OU and multiaccount strategy is the key to reduce blast radius","upvote_count":"1","comment_id":"349844"},{"upvote_count":"1","poster":"WhyIronMan","content":"I'll go with A","comment_id":"336855","timestamp":"1636003260.0"},{"comment_id":"289433","content":"going with A","poster":"Kian1","upvote_count":"2","timestamp":"1635796920.0"},{"poster":"Ebi","upvote_count":"4","comment_id":"283983","timestamp":"1635779760.0","content":"My answer is A"},{"poster":"bnagaraja9099","timestamp":"1635417180.0","content":"Poorly written responses. Even without responses all of us know OU with SCP is the best way to handle it.","upvote_count":"1","comment_id":"283769"},{"timestamp":"1635296940.0","content":"A for sure.","comment_id":"262936","poster":"sanjaym","upvote_count":"1"},{"poster":"Lance_D","comment_id":"251217","content":"Ans A is the most sensible choice here","upvote_count":"1","timestamp":"1634868300.0"},{"timestamp":"1634466720.0","content":"Correct answer is A\nSCP will help to restrict accwss using deny list strategy","comment_id":"245070","poster":"rscloud","upvote_count":"1"},{"poster":"gookseang","upvote_count":"1","content":"seems A","comment_id":"242352","timestamp":"1634349240.0"},{"comment_id":"241941","content":"Correct answer is A. SCP will help","timestamp":"1634334240.0","poster":"T14102020","upvote_count":"1"},{"poster":"jackdryan","upvote_count":"2","timestamp":"1634123700.0","comment_id":"228545","content":"I'll go with A"},{"poster":"Bulti","content":"A is correct.","comment_id":"226984","upvote_count":"1","timestamp":"1633919220.0"},{"poster":"fullaws","comment_id":"148569","timestamp":"1633631700.0","upvote_count":"1","content":"A is correct, using SCP to block the resource/services, Security team able to control access the particular service on the account, by creating role for security team that have the permission to OU related tasks."},{"timestamp":"1633485540.0","content":"A for sure","upvote_count":"1","comment_id":"134130","poster":"NikkyDicky"},{"comment_id":"133565","upvote_count":"1","content":"go with A\nSCP's Blacklist is suitable to avoid using certain services","timestamp":"1633449540.0","poster":"noisonnoiton"},{"poster":"mat2020","timestamp":"1633399260.0","content":"answer : A","comment_id":"133254","upvote_count":"1"},{"poster":"rsn","timestamp":"1633164060.0","comments":[{"poster":"inf","comment_id":"130587","upvote_count":"5","content":"Answer: A\nA states \"Modify the OU to ensure that the particular services are blocked\" - the question is vague on purpose but you can modify an OU by attaching an SCP to block access to services.","timestamp":"1633374420.0"},{"content":"Have you ever heard about Control Tower? When you start working in a multi-account environment you will soon understand that B is completely unuseable","comment_id":"408861","upvote_count":"2","timestamp":"1636063020.0","poster":"DerekKey"}],"comment_id":"114856","content":"I don't think \"A\" is the answer. Firstly it does not explicitly say anything about SCPs. I am not sure if we can imply modifying OUs as \"add an SCP\". The other reason is the problem statement here is to ensure that business units must not have access to particular resources and the security team must be able to control the same. So SCPs are not going to work in this case.\n\nD is ruled as out as it is talking about a Shared account which does not address the blast radius issue\n\nC has the same problem. All the VPCs are created in the shared account which does not address the blast radius issue.\n\nSo, I would go for B","upvote_count":"1"},{"comment_id":"90077","timestamp":"1633147680.0","poster":"JAWS1600","content":"A. The keyword is \"Blast radius\". This means multiple AWS accounts.\nhttps://www.slideshare.net/AmazonWebServices/aws-reinvent-2016-reduce-your-blast-radius-by-using-multiple-aws-accounts-per-region-and-service-sec304","upvote_count":"5"},{"comment_id":"41169","content":"answer is A","upvote_count":"3","timestamp":"1632833520.0","poster":"markpark"},{"comments":[{"poster":"9Ow30","content":"SCP cannot restrict. It can only allow.","upvote_count":"2","comments":[{"content":"Sorry I was wrong. Yes, SCP.","upvote_count":"1","comment_id":"31431","timestamp":"1632754380.0","poster":"9Ow30"}],"comment_id":"27922","timestamp":"1632745020.0"},{"comment_id":"163600","upvote_count":"1","poster":"achambok","content":"There is also wording for a clear seperation, this involves creating a OU with SCP","timestamp":"1633861920.0"},{"upvote_count":"1","content":"yes, the default SCP is Allow All, so you create deny rules to block services","timestamp":"1635335580.0","poster":"kopper2019","comment_id":"271731"}],"content":"I agree with that this question is made for A, but how to modify the OU to ensure that the particular services are blocked? via SCP?","upvote_count":"2","poster":"huhupai","timestamp":"1632458520.0","comment_id":"12985"}],"answer":"A","answer_images":[],"topic":"1","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/5329-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"answers_community":["A (100%)"]},{"id":"z4WhrBH3NqlSWNwOlp6B","question_images":[],"exam_id":32,"url":"https://www.examtopics.com/discussions/amazon/view/5644-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["A (80%)","D (20%)"],"answer_images":[],"answer_description":"","question_text":"A company is migrating a subset of its application APIs from Amazon EC2 instances to run on a serverless infrastructure. The company has set up Amazon API\nGateway, AWS Lambda, and Amazon DynamoDB for the new application. The primary responsibility of the Lambda function is to obtain data from a third-party\nSoftware as a Service (SaaS) provider. For consistency, the Lambda function is attached to the same virtual private cloud (VPC) as the original EC2 instances.\nTest users report an inability to use this newly moved functionality, and the company is receiving 5xx errors from API Gateway. Monitoring reports from the SaaS provider shows that the requests never made it to its systems. The company notices that Amazon CloudWatch Logs are being generated by the Lambda functions. When the same functionality is tested against the EC2 systems, it works as expected.\nWhat is causing the issue?","unix_timestamp":1569321840,"timestamp":"2019-09-24 12:44:00","answer":"A","choices":{"D":"API Gateway does not have the necessary permissions to invoke Lambda.","B":"The end-user application is misconfigured to continue using the endpoint backed by EC2 instances.","C":"The throttle limit set on API Gateway is too low and the requests are not making their way through.","A":"Lambda is in a subnet that does not have a NAT gateway attached to it to connect to the SaaS provider."},"question_id":370,"discussion":[{"comment_id":"16151","content":"My answer is A\n- Note that testing on EC2 working --> problem comes from Lambda.\n- If API doesn't have permission to invoke Lambda then Lambda cannot generate CW Logs but in the question, there is the fact that the Lambda was already get invoked and generate CW Logs.\n- 5xx usually happens when there is a timeout with your call and if there is a delay with your lambda execution. If Lambda is accessing an external resource such as Dynamo DB or an external network call, just make sure Lambda will have ability to do that, otherwise it will be timeout.","upvote_count":"63","poster":"chaudh","comments":[{"poster":"skywalker","timestamp":"1632675120.0","content":"Agreed with you.. Since Lambda has already generated logs, then its possible that API/Lambda did in fact being triggered. Here there is no mentioned of logs from the NAT and thus Is is likely \"A\".","comment_id":"19128","upvote_count":"4"},{"upvote_count":"2","timestamp":"1635779880.0","poster":"Geetar","content":"A is correct:\nhttps://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/","comment_id":"395548"},{"poster":"AWSPro24","upvote_count":"2","comment_id":"51322","comments":[{"upvote_count":"1","comment_id":"362494","content":"Hope you read this steps:\n Create your VPC components\n\n Create two or more new subnets in your VPC. During creation, for Name tag, add a name to help you identify which subnet is public and which subnets are private. For example, name one Public Subnet and the other Private Lambda (or Private Lambda 1, Private Lambda 2, and so on, for multiple private subnets).\n Note: It's a best practice to create multiple private subnets across different Availability Zones for redundancy and so that Lambda can maintain high availability for your function.\n Create an internet gateway and attach it to your VPC.\n Create a NAT gateway. During creation, for Subnet, choose the subnet that you want to make public. (For example, Public Subnet if you named it earlier.)\n Note: For help with testing your NAT gateway after creation, see Testing a NAT Gateway.","timestamp":"1635378120.0","poster":"Radhaghosh"}],"content":"Because the Lambda logs exist they must be being triggered. \nThis references the NAT Gateway need for Lambda internet access directly. \n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/","timestamp":"1632871260.0"},{"poster":"vbal","comment_id":"508880","upvote_count":"1","timestamp":"1640384520.0","content":"https://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/"}],"timestamp":"1632645840.0"},{"comment_id":"14633","poster":"Moon","timestamp":"1632469320.0","upvote_count":"19","content":"Answer \"D\".\nA: NAT gateway does not need to be attached to the Lambda subnet! it is only a routing to NAT gateway that allow public access.\nB: does not make sense.\nC: this means at least some times it should pass.\nD: refer to the below link:\nhttps://aws.amazon.com/premiumsupport/knowledge-center/500-error-lambda-api-gateway/","comments":[{"comment_id":"15561","timestamp":"1632559740.0","content":"D\nThe reason is we have to explicitly specify the ARN of an IAM role for API Gateway to assume when invoking a Lambda function. If none is specified, resource-based permissions are needed.\nhttps://jun711.github.io/aws/aws-api-gateway-invoke-lambda-function-permission/","comments":[{"upvote_count":"3","poster":"Chinmoy","comment_id":"61170","content":"Permission error logged in cloudtrail ..Ans is A\nhttps://aws.amazon.com/premiumsupport/knowledge-center/lambda-troubleshoot-function-failures/","timestamp":"1632893820.0"}],"upvote_count":"6","poster":"donathon"},{"upvote_count":"1","timestamp":"1634909940.0","poster":"Mansur","comment_id":"290607","content":"Answer D make sense after I refer to the link provided by Moon. A satisfying explanation. Thanks."},{"timestamp":"1635206700.0","upvote_count":"2","comment_id":"328835","poster":"tiffanny","content":"A because When you connect a function to a VPC in your account, the function can't access the internet unless your VPC provides access.\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-internet"},{"comments":[{"poster":"Jesuisleon","comment_id":"918541","timestamp":"1686246420.0","upvote_count":"1","content":"Bro You have a very good observation, answer A makes sense."}],"timestamp":"1635111540.0","comment_id":"307730","poster":"ajeeshb","content":"When it says NAT gateway is not attached to the subnet it means a route to internet via NAT Gateway. The answer should be A. \nD --> If API gateway does not have the permission to invoke Lambda, how does lambda function generate cloudwatch logs?!","upvote_count":"4"}]},{"poster":"SkyZeroZx","content":"Selected Answer: A\nThe issue in this scenario is most likely caused by option A: Lambda is in a subnet that does not have a NAT gateway attached to it to connect to the SaaS provider.\n\nWhen a Lambda function is configured to access resources outside the VPC, such as the third-party SaaS provider in this case, it requires internet access. By default, Lambda functions within a VPC do not have internet connectivity. To enable internet access for the Lambda function, it needs to be placed in a private subnet that has a NAT gateway attached.","comment_id":"925607","timestamp":"1686957660.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\nB & C are dogshit answers\nD would throw 4xx errors\n\nAAAAAAA it is","comment_id":"836464","poster":"milofficial","timestamp":"1678565220.0"},{"comment_id":"772103","upvote_count":"1","poster":"Prasadvd","timestamp":"1673417040.0","content":"Selected Answer: D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/500-error-lambda-api-gateway/"},{"timestamp":"1666377900.0","upvote_count":"1","content":"D would give 4XX error, 5XX for server , from reading I'll go with A","poster":"mrgreatness","comment_id":"701105"},{"content":"Unclear question, but 2 clear points though:\nIf Lambda is generating logs, then it is being invoked by API GW - hence D is thrown out\nA is the choice - under the assumption the choice meant ROUTETABLE/ROUTING to NAT vs \"attached\" to NAT GW","comment_id":"684123","timestamp":"1664617440.0","upvote_count":"1","poster":"Biden"},{"upvote_count":"1","comment_id":"655518","content":"Selected Answer: A\nA is correct because Lambda is generating logs, and D is incorrect.\n\nB and C are dumb.","timestamp":"1661982480.0","poster":"epomatti"},{"comment_id":"648355","upvote_count":"1","timestamp":"1660810680.0","poster":"MikeyJ","content":"Selected Answer: A\nI'll say A too.\n\nTo give your function access to the internet, route outbound traffic to a NAT gateway in a public subnet. The NAT gateway has a public IP address and can connect to the internet through the VPC's internet gateway.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/foundation-networking.html#foundation-nw-connecting"},{"timestamp":"1658873760.0","content":"A. It doesn't have internet?","upvote_count":"1","poster":"hilft","comment_id":"637650"},{"content":"Nothing here indicates that the resources are in a private subnet, so why do we need NAT? Lambda can generate CW logs because it has the required permission but it API Gateway does not, so answer is D","timestamp":"1657421940.0","comments":[{"content":"Lambda will not generate logs if its not called!!\nPermission to generate logs is not relevant here\nThe fact that the logs are there means lambda was invoked\nSo A is the correct answer because lambda will fail and cause a 5XX error if it can’t reach the sas service","poster":"Cal88","comment_id":"706815","upvote_count":"1","timestamp":"1666999800.0"}],"comment_id":"629417","poster":"jyrajan69","upvote_count":"1"},{"timestamp":"1657246140.0","content":"D.\nLambda and EC2 are in the same VPC. EC2 can, but Lambda can't.","poster":"hilft","upvote_count":"1","comment_id":"628580"},{"poster":"AzureDP900","content":"A Correct.","upvote_count":"2","timestamp":"1640112600.0","comment_id":"506364"},{"poster":"cldy","content":"A. Lambda is in a subnet that does not have a NAT gateway attached to it to connect to the SaaS provider.","upvote_count":"1","comment_id":"498707","timestamp":"1639147380.0"},{"comment_id":"452716","timestamp":"1636233660.0","upvote_count":"1","content":"A \n---","poster":"student22"},{"comment_id":"449999","poster":"andylogan","upvote_count":"1","content":"It's A","timestamp":"1636117140.0"},{"comment_id":"447455","timestamp":"1635920580.0","poster":"nodogoshi","content":"A Correct. It's VPC LAMBDA","upvote_count":"1"},{"comment_id":"392797","timestamp":"1635593940.0","content":"A\nhttps://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/","poster":"nik_aws","upvote_count":"2"},{"content":"Could be lambda related https://docs.aws.amazon.com/apigateway/api-reference/handling-errors/ 4XX for authentication and throtlle 5XX is due to backend","timestamp":"1635485400.0","poster":"tvs","comment_id":"379688","upvote_count":"1"},{"poster":"zolthar_z","content":"The Answer is A\n\nB and C aren't the response, and D if API gateway can't execute lambda due permissions the lambda function will not generate logs","timestamp":"1635466920.0","upvote_count":"1","comment_id":"366618"},{"comment_id":"362493","content":"Option A","poster":"Radhaghosh","upvote_count":"1","timestamp":"1635277560.0"},{"poster":"tafy","comment_id":"350607","timestamp":"1635257700.0","upvote_count":"3","content":"I will go with A. Lambda is generating logs which shows its being successfully invoked so D would be inappropriate"},{"poster":"WhyIronMan","content":"I'll go with A\nwhen you face the issue by yourself its easy to understand.\n\nWhen not connected to a vpc aws gives the lambda function an ip address so lambda can make request to internet.\nwhen in a vpc you do need a nat.... ec2 can have a public ip, that's why they work while lambda not","comment_id":"336863","timestamp":"1635254700.0","upvote_count":"1"},{"timestamp":"1634991720.0","comment_id":"307047","poster":"Pupu86","content":"I'm inclined to choose A by assuming that the NAT gateway has been provisioned in a subnet that resides with the pre-existing EC2 instances while differing from the subnet where the Lamda f(x) resides","upvote_count":"2"},{"timestamp":"1634972880.0","content":"A.\nIt cannot be D.\nAPI Gateway executed Lamda function.\n\"The company notices that Amazon CloudWatch Logs are being generated by the Lambda functions.\"","upvote_count":"1","poster":"gpark","comment_id":"294653"},{"comment_id":"289434","poster":"Kian1","upvote_count":"2","timestamp":"1634870820.0","content":"I go with A"},{"comment_id":"289026","poster":"bnagaraja9099","content":"A: The question sates Lambda is the same VPC as EC2 not subnet. Each subnet needs to be connected to NAT to get to the Internet. If D is the issue, then how is lambda invoked and logs are generated in cloud watch? D cannot be the right answer","timestamp":"1634812140.0","upvote_count":"1"},{"upvote_count":"6","poster":"Ebi","comment_id":"283985","content":"My answer is A","timestamp":"1634785920.0"},{"upvote_count":"2","comment_id":"262944","timestamp":"1634747700.0","content":"A for sure.","poster":"sanjaym"},{"comment_id":"246222","poster":"happpieee","upvote_count":"1","timestamp":"1634684280.0","content":"typo. A is correct. For Lamda to reach out to a internet service SaaS or public AWS services, you need a NAT gateway or instance.\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/"},{"upvote_count":"1","comment_id":"246221","content":"D. For Lamda to reach out to a internet service SaaS or public AWS services, you need a NAT gateaay or instance.\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/","timestamp":"1634651700.0","poster":"happpieee"},{"content":"seems A","poster":"gookseang","upvote_count":"1","timestamp":"1634545200.0","comment_id":"242356"},{"upvote_count":"1","poster":"T14102020","content":"A is correct answer. Key is NAT","timestamp":"1634514420.0","comment_id":"241942"},{"timestamp":"1634373360.0","poster":"exam_prep","upvote_count":"1","content":"A is the answer.","comment_id":"238904"},{"upvote_count":"1","content":"API Gateway throws 5xx errors when backend service is failing to send proper response.\nIn this case it is Lambda that fails to provide proper response due to its failure.\nIt should be A","timestamp":"1634331600.0","comment_id":"237750","comments":[{"upvote_count":"1","content":"But D is actually more common as it also generates 5xx\nhttps://stackoverflow.com/questions/39905255/how-can-i-grant-permission-to-api-gateway-to-invoke-lambda-functions-through-clo","poster":"Cantaloupe","comment_id":"237751","timestamp":"1634361480.0"}],"poster":"Cantaloupe"},{"comment_id":"228605","comments":[{"poster":"jackdryan","upvote_count":"1","content":"I am changing to D","comment_id":"233535","timestamp":"1634166060.0"}],"upvote_count":"2","timestamp":"1634165820.0","content":"I'll go with A","poster":"jackdryan"},{"content":"Answer is A. Refer to this link.https://aws.amazon.com/blogs/compute/error-handling-patterns-in-amazon-api-gateway-and-aws-lambda/","poster":"Bulti","comment_id":"226992","upvote_count":"1","timestamp":"1634143020.0"},{"comment_id":"223563","poster":"Edgecrusher77","timestamp":"1634135100.0","comments":[{"upvote_count":"1","timestamp":"1635855840.0","content":"If in the same VPC, EC2 may be in a public subnet which gives it internet access. But Lambda cannot work in a public subnet, it cannot be given a public IP address. It needs to be in a private subnet with a route to a NAT GW for internet access","poster":"student2020","comment_id":"402976"}],"content":"I guess D. I was thinking that A could fit, but as lambda and EC2 are using the same network config (VPC), and EC2 can call the Saas provider, it cant be A.\nMy 2 cents!","upvote_count":"1"},{"poster":"petebear55","content":"D ....... JUST BECAUSE The company notices that Amazon CloudWatch Logs are being generated by the Lambda functions. does not mean this should rule out D ..... we see applications start up or processes start up all the time in logs .. but often fail with invalid permissions etc .... MQSeries logs are a classic example of this. so D","upvote_count":"1","comment_id":"221061","timestamp":"1634074920.0"},{"poster":"vjt","content":"for a lambda in VPC to access internet, it needs to be deployed in a private subnet and a NAT connectivity needs to be defined for internet. Please note that you cannot deploy labda in public subnet and expects it to connect internet as it is in public.\nA is correct choice for the question.","upvote_count":"2","comment_id":"214005","timestamp":"1634007360.0"},{"content":"For sure its B as in the question it mentioned it was tested using EC2 and worked. By using same configurations of VPC, Lambda should also be worked but it didn't. And its not mentioned about internet connection for EC2. So, it might be using endpoint service. And finally there is misconfiguration.","comment_id":"210312","poster":"Anila_Dhharisi","timestamp":"1633881360.0","upvote_count":"2"},{"content":"My ans is B\nA: incorrect since it worked with “original EC2 instances”, that means there was a connection to the “third-party Software as a Service (SaaS) provider”. In addition, Lambda does not need to be in a subnet that has a NAT gateway. The subnet only need to have a routing to the NAT gateway in the VPC.\nC/D: incorrect since it worked with the “when the same functionality is tested against the EC2 systems”","comments":[{"poster":"smithyt","comment_id":"203371","upvote_count":"1","content":"That is incorrect a lambda inside a VPC has a network interface that needs to put inside a Subnet","timestamp":"1633871820.0"}],"timestamp":"1633838280.0","upvote_count":"3","comment_id":"185173","poster":"Kayode"},{"comment_id":"179193","content":"Agreed with A","timestamp":"1633696800.0","upvote_count":"1","poster":"Ganfeng"},{"comment_id":"160914","timestamp":"1633641000.0","content":"I think the answer is B.\nA: Its a matter of routing from private to public subnet to access the NATGw\nC/D: As some of you indicated lambda will not generate logs if no requests reach it.\nThe other reason i think its B, there is no mention that the EC2 was using the NAT GW to reach the internet it could be accessing Internet via a private link with an interface endpoint.","upvote_count":"2","poster":"dman"},{"comment_id":"148575","content":"A is correct, Lambda had send log to cloudwatch (API gateway had permission to invoke lambda), Throttle limit should had some good request.","poster":"fullaws","timestamp":"1633629900.0","upvote_count":"1"},{"comment_id":"134133","timestamp":"1633450020.0","content":"A for sure","poster":"NikkyDicky","upvote_count":"1"},{"content":"go with A\n\nCloudWatch Logs are created by lambda function, and when connected externally from lambda NAT Gateway required","upvote_count":"1","timestamp":"1633436820.0","comment_id":"133568","poster":"noisonnoiton"},{"comment_id":"126150","content":"certainly A:\n* errors are produced by lambda, which means api gateway could execute it and hes permissions to do so\n* subnet of lambda needs to explicitly be given internet access so that lambda can access SaaS endpoints","poster":"jimmy_sticks","timestamp":"1633344540.0","upvote_count":"1"},{"content":"A.\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html\nBy default, Lambda runs your functions in a secure VPC with access to AWS services and the internet. The VPC is owned by Lambda and does not connect to your account's default VPC. When you connect a function to a VPC in your account, it does not have access to the internet unless your VPC provides access.","upvote_count":"2","comment_id":"125929","timestamp":"1633341000.0","poster":"inlwop"},{"upvote_count":"2","comment_id":"125876","timestamp":"1633276620.0","content":"B: \nAs Monitoring reports from the SaaS provider shows that the requests never made it to its systems so it can not be permission issue for Lambda function.","poster":"manoj101"},{"upvote_count":"1","timestamp":"1633204380.0","poster":"tones","content":"A. Take note that the question only says the lambda is only attached to the same VPC as the EC2. Not necessarily in the same subnet. Being able to route out to the internet is entirely dependent on the route tables attached to the subnet. In this case, the EC2 instances were able to route out, however the lambda was placed in a subnet that is not able to. Hence configuring a NAT gateway will resolve the connectivity issue for the lambda.","comment_id":"110396"},{"comments":[{"poster":"oatif","comment_id":"118026","timestamp":"1633212300.0","content":"APi is giving out an error. that it is unable to fulfill the request. I would go with D.","upvote_count":"2"}],"upvote_count":"2","comment_id":"107602","timestamp":"1633180680.0","poster":"SaulGoodman","content":"5xx means Server errors so it is Lambda.\nfor me, A is the correct answer as the Lambda error can be triggered by no connectivity."},{"content":"D is the answer","poster":"JAWS1600","timestamp":"1633146300.0","comment_id":"107279","upvote_count":"1"},{"content":"The correct answer is C because API gateway lambda has returned 5xx error which is related to the throttle limit, timeout expired, etc.","poster":"Jeb","upvote_count":"1","comment_id":"96777","timestamp":"1633097700.0"},{"content":"A. Keyword \"requests never made to its system\". It means it had left the API gateway and Lambda ( as shown by CW logs). However, a lambda could not make to SAAS. Connection to SAAS can either be provided using NAT or VPC private link ( NLB and EIP) . In this case, it is NAT. So possible issue with routing to NAT. Answer is A.","upvote_count":"4","comment_id":"90088","poster":"JAWS1600","timestamp":"1633014180.0"},{"comment_id":"85239","poster":"fw","timestamp":"1632967380.0","content":"A. The link belows shows how to give internet access to Lambda function in a VPC. Including NAT Gateway and route table changes.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/","upvote_count":"2"},{"timestamp":"1632941160.0","poster":"Smart","content":"D (Invalid): Lambda function is generating CW Logs.\nC (Invalid): Some requests should at least go through.\nB (Invalid): API Gateway & Lambda Functions is getting used.\nA (Valid): https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-internet","comment_id":"69669","upvote_count":"11"},{"timestamp":"1632868440.0","comment_id":"41171","content":"my answer is A","upvote_count":"4","poster":"markpark"},{"comment_id":"22514","comments":[{"poster":"9Ow30","comment_id":"31434","timestamp":"1632853080.0","content":"> The company notices that Amazon CloudWatch Logs are being generated by the Lambda functions\n\nLogs of Lambda can be started only if it started. So Apgigateway should have permissions to start. If it did not had the log of Lambda will not be generated. So, I am more for A here.","upvote_count":"7"}],"upvote_count":"3","poster":"pra276","content":"here understand these key points \n1. Monitoring reports from the SaaS provider shows that the requests never made it to its systems.\n2. The company notices that Amazon CloudWatch Logs are being generated by the Lambda functions.\n\nbasically saas provider never gets a request to its systems and cloudwatch logs are generated by lambda function (Lambda will try to trigger by api gateway and received an errors and logged in cloudwatch logs as some permission issue). \n\nMy answer is D: \n\nA cannot be because api gateway will invoke the lambda not the saas provider directly connect to lambda","timestamp":"1632819960.0"},{"content":"This is the only reason why internet based query (SAAS) fails while EC2 works as expected.\nB: This does not make sense?\nC: This may slow it down but should not fail unless it time out. Even so it should not fail all the time.\nD: Then why did the EC2 pass and not the SAAS?","comment_id":"13382","poster":"donathon","timestamp":"1632385320.0","upvote_count":"1","comments":[{"content":"\"D: Then why did the EC2 pass and not the SAAS?\" bc api gateway is for the new stuff \"The company has set up Amazon API Gateway, AWS Lambda, and Amazon DynamoDB for the new application\"","upvote_count":"4","comment_id":"26905","poster":"johannes756","timestamp":"1632853080.0"},{"timestamp":"1633459980.0","content":"From the question:\n\"The company notices that Amazon CloudWatch Logs are being generated by the Lambda functions.\"\n--> Therefore Lambda is being invoked. This means B, C and D are not viable answers\n\n\"For consistency, the Lambda function is attached to the same virtual private cloud (VPC) as the original EC2 instances... When the same functionality is tested against the EC2 systems, it works as expected.\"\n--> This is a challenge. We need to call external SaaS provider, so NAT GW is needed. But if EC2 works, then we have the NAT GW working fine. The only option I see is the Lambda functions to be deployed in different subnet in the same VPC, which is partially A\nsee https://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/","poster":"MultiAZ","upvote_count":"8","comment_id":"144095"}]},{"poster":"awsdog","comment_id":"12899","comments":[{"poster":"awspro","content":"I need reason. So why choice A?? Could you explain for me","upvote_count":"1","comment_id":"12976","timestamp":"1632341880.0"}],"content":"i think A","timestamp":"1632267240.0","upvote_count":"3"},{"comment_id":"12456","comments":[{"comment_id":"315288","content":"Lambda by default can *NOT* go to internet it needs NAT to go out of VPC. So A is correct answer.","poster":"nitinz","timestamp":"1635193200.0","upvote_count":"1"}],"content":"why b","poster":"awsec2","timestamp":"1632202920.0","upvote_count":"1"}],"isMC":true,"answer_ET":"A","topic":"1"}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","isMCOnly":false,"id":32,"provider":"Amazon","name":"AWS Certified Solutions Architect - Professional","isImplemented":true,"numberOfQuestions":1019},"currentPage":74},"__N_SSP":true}