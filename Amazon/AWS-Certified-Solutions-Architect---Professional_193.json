{"pageProps":{"questions":[{"id":"rZWeMxfpHh96sgrw5jgF","isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/79636-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"D":"Configure VPC default security group outbound rules to prevent connectivity between the subnets in the development account and the production account.","E":"Use AWS RAM to share three subnets in different Availability Zones with the development account. Additionally, use AWS RAM to share the same three subnets with the production account.","A":"In the shared services VPC, create three subnets for three Availability Zones. Create one subnet in each Availability Zone.","B":"In the shared services VPC, create six subnets for three Availability Zones. Create two subnets in each Availability Zone.","F":"Use AWS RAM to share three subnets in different Availability Zones with the development account. Additionally, use AWS RAM to share three other subnets in different Availability Zones with the production account.","C":"Configure network ACLs to prevent connectivity between the subnets in the development account and the production account."},"question_id":961,"answers_community":["BCF (77%)","ACE (23%)"],"answer_description":"","question_images":[],"timestamp":"2022-09-03 02:09:00","exam_id":32,"answer_images":[],"discussion":[{"comment_id":"657922","content":"BCF\nB - Better HA\nC - ACL applied at subnet level while security group at instance\nF - Requirement that no connection between development and production","upvote_count":"19","poster":"SGES","timestamp":"1662163740.0"},{"upvote_count":"6","poster":"astalavista1","content":"Selected Answer: BCF\nB - HA for Dev and Prod\nC - NACL to lock down subnet.\nF - Use RAM to prevent both env access.","timestamp":"1663930740.0","comment_id":"677029"},{"upvote_count":"1","content":"Selected Answer: BCF\nA - cannot meet the requirement of isolation as inter subnet communication cannot be controlled.\nD - cannot meet the requirement of isolation as the accounts can create their own SGs and may not use the parent SG.","comment_id":"1118599","timestamp":"1704894360.0","poster":"3a632a3"},{"upvote_count":"1","comment_id":"934798","timestamp":"1687814700.0","content":"Selected Answer: BCF\nA) Not HA in comparation B\nB ) OK it's HA\nC) sounds goods ACL in level VPC\nD) Security Group in level VPC not exist \nE ) same subnet in production and development not is required\nF ) differents subnet in production and development not is required","poster":"SkyZeroZx"},{"comment_id":"916140","poster":"AMEJack","content":"Selected Answer: BCF\nB C F Remember to separate workloads","upvote_count":"1","timestamp":"1686047160.0"},{"poster":"hobokabobo","content":"Selected Answer: BCF\nWe always need a pair of subnets in every AZ in order to strictly separate dev and prod environments. \nHence F and B and not A or E.\nIf you want to block something you need ACL, sec groups allow - and ACL are on subnet level while sec. groups are on resources.","comment_id":"859765","upvote_count":"1","timestamp":"1680514920.0"},{"timestamp":"1678164660.0","poster":"TajSidKazi","content":"ACE\nOption A is required to ensure that workloads in each account are deployed to at least three Availability Zones.\n\nOption C is required to ensure that there is no direct communication between the development and production workloads.\n\nOption E is required to configure access between the shared services VPC and the development and production accounts. By sharing three subnets in different Availability Zones with each account, workloads in each account can be deployed to at least three Availability Zones.","upvote_count":"1","comment_id":"831561"},{"timestamp":"1666176780.0","upvote_count":"6","poster":"psou7","comment_id":"698938","content":"i would go with BCF"},{"comment_id":"687879","poster":"Biden","upvote_count":"3","timestamp":"1665065460.0","content":"Selected Answer: ACE\nA - Shared Services with Public Subnets in each AZ - dont need 3 more\nE - The same 3 subnets shared with each account - Prod and Dev\nC - Yes, controls at Subnet Level vs Security Group which is incoming & at instance level"}],"answer_ET":"BCF","question_text":"A company has an organization in AWS Organizations. The company has enabled trusted access between Organizations and AWS Resource Access Manager\n(AWS RAM). The organization includes three AWS accounts, one each for shared services, development, and production. The shared services account has a\nVPC.\nA solutions architect needs to meet the following requirements:\n* Configure access between the shared services VPC and the development and production accounts.\n* Ensure that workloads in each account are deployed to at least three Availability Zones.\n* Ensure that there is no direct communication between the development and production workloads.\nWhich combination of steps will meet these requirements? (Choose three.)","answer":"BCF","unix_timestamp":1662163740},{"id":"gKwUAML5fwXQJVCsDOFP","answer_ET":"DE","unix_timestamp":1676342700,"isMC":true,"answer_description":"","question_text":"A solutions architect has deployed a web application that serves users across two AWS Regions under a custom domain. The application uses Amazon Route 53 latency-based routing. The solutions architect has associated weighted record sets with a pair of web servers in separate Availability Zones for each Region.\n\nThe solutions architect runs a disaster recovery scenario. When all the web servers in one Region are stopped. Route 53 does not automatically redirect users to the other Region.\n\nWhich of the following are possible root causes of this issue? (Choose two.)","choices":{"D":"The setting to evaluate target health is not turned on for the latency alias resource record set that is associated with the domain in the Region where the web servers were stopped.","E":"An HTTP health check has not been set up for one or more of the weighted resource record sets associated with the stopped web servers.","C":"Latency resource record sets cannot be used in combination with weighted resource record sets.","A":"The weight for the Region where the web servers were stopped is higher than the weight for the other Region.","B":"One of the web servers in the secondary Region did not pass its HTTP health check."},"discussion":[{"poster":"Jesuisleon","comment_id":"895464","comments":[{"comment_id":"908774","timestamp":"1685295480.0","content":"\"In this configuration, both of the following must be true before Route 53 will return the applicable value for a weighted record:\n\n The health check associated with the latency alias record must pass.\n\n At least one weighted record must be considered healthy, either because it's associated with a health check that passes or because it's not associated with a health check. In the latter case, Route 53 always considers the weighted record healthy.\n\" in the link above","poster":"Jesuisleon","upvote_count":"1"}],"upvote_count":"5","timestamp":"1683846060.0","content":"Selected Answer: DE\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html"},{"poster":"hobokabobo","comment_id":"854044","upvote_count":"3","content":"Selected Answer: BD\nif latency routing is used, thats the one to decide which region to serve while weighted may be used additionally *within* the region.\nAs the failover to the other region is the problem and not within a region. Even if no health check on the weighted records is set up, the failover to the other region should happen as the weighted matter only for within the region. Therefore I think its B and D.","timestamp":"1680068580.0"},{"comment_id":"827983","poster":"andras","upvote_count":"4","content":"Selected Answer: DE\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html\nEither the \"evaluate target health\" was not set to yes, or no health check was associated to the target in the original region.","timestamp":"1677848640.0"},{"poster":"NYB","comment_id":"808009","timestamp":"1676342700.0","upvote_count":"2","content":"The possible root causes of the issue are:\n\nB. One of the web servers in the secondary Region did not pass its HTTP health check.\nD. The setting to evaluate target health is not turned on for the latency alias resource record set that is associated with the domain in the Region where the web servers were stopped.\n\nExplanation:\n\nOption A is incorrect because weighted record sets are used to distribute traffic between regions, not within regions.\n\nOption C is incorrect because the question explicitly states that latency-based routing is being used in conjunction with weighted record sets.\n\nOption E is incorrect because an HTTP health check is not necessary for weighted record sets, which are associated with the stopped web servers.\n\nOption B is a possible cause of the issue because if one of the web servers in the secondary Region fails its health check, then Route 53 will not redirect traffic to that Region.\n\nOption D is another possible cause of the issue because if the setting to evaluate target health is not turned on, then Route 53 will not know that the web servers in one Region are down and will not redirect traffic to the other Region."}],"timestamp":"2023-02-14 03:45:00","question_id":962,"answer_images":[],"answer":"DE","exam_id":32,"question_images":[],"topic":"1","answers_community":["DE (75%)","BD (25%)"],"url":"https://www.examtopics.com/discussions/amazon/view/99126-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"sJBGBgH9h6jEOGGldRqB","answer":"D","topic":"1","timestamp":"2022-11-21 15:12:00","question_text":"A company hosts an application that uses several Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). During the initial startup of the EC2 instances, the EC2 instances run user data scripts to download critical content for the application from an Amazon S3 bucket.\n\nThe EC2 instances are launching correctly. However, after a period of time, the EC2 instances are terminated with the following error message: \"An instance was taken out of service in response to an ELB system health check failure.\" EC2 instances continue to launch and be terminated because of Auto Scaling events in an endless loop.\n\nThe only recent change to the deployment is that the company added a large amount of critical content to the S3 bucket. The company does not want to alter the user data scripts in production.\n\nWhat should a solutions architect do so that the production environment can deploy successfully?","answers_community":["D (50%)","C (50%)"],"url":"https://www.examtopics.com/discussions/amazon/view/88207-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1669039920,"isMC":true,"choices":{"D":"Increase the health check grace period for the Auto Scaling group.","B":"Increase the health check timeout for the ALB.","C":"Change the health check path for the ALB.","A":"Increase the size of the EC2 instances."},"discussion":[{"comment_id":"723583","timestamp":"1669039920.0","poster":"ggrodskiy","content":"D - correct\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/health-check-grace-period.html","upvote_count":"8"},{"poster":"AzureDP900","upvote_count":"1","timestamp":"1732746180.0","content":"Selected Answer: D\nD is right","comment_id":"1318940"},{"upvote_count":"1","comment_id":"1025866","timestamp":"1696527000.0","poster":"Pr44","content":"Selected Answer: C\nhealth check grace period is the choice by loking at the error message we need to give more time to EC2"},{"poster":"loustitech","comment_id":"920552","timestamp":"1686477900.0","upvote_count":"2","content":"Selected Answer: C\n\"The EC2 instances are launching correctly\" which means the user data script was executed correctly as well. Though, the new instances failed to check their health so the ELB considers they're not healthy to worth be terminated and the ASG be triggered. Therefore, have to seek the ELB."},{"timestamp":"1680071400.0","comments":[{"upvote_count":"2","comments":[{"timestamp":"1684400280.0","poster":"MikelH93","comments":[{"comment_id":"910097","upvote_count":"1","timestamp":"1685437920.0","content":"after reading carefully, i change to D because what hobokabobo say is good but I think that according to the statement , the only thing that has changed is the number of files to download into the s3 bucket, so it takes longer.\n\nSO Anwser D but if it wasn't that then it would be C","poster":"MikelH93"}],"comment_id":"900956","upvote_count":"1","content":"agree with that"}],"timestamp":"1680514380.0","comment_id":"859756","content":"on second thought: what does \"after a period of time\" mean?\nAs there is the hint to to the userdata it may mean that the userdata takes a long time. In that case the state of the machine stays in initializing state until userdata is done so do not \"launch correctly\" as they never change state to \"running\". \nIf that is the scenario(or similar): D would be the solution.\n(But if they never reach running its really bad wording: no they do not launch correctly, they never finish initializing ).","poster":"hobokabobo"}],"upvote_count":"1","poster":"hobokabobo","content":"Selected Answer: C\nI would change the path. Reason from the description there seems to be some changing content on the page( that comes from S3 ) Problem seems to occur whenever such content changes.\nFrom architectual point of view I don't want a health to depend on particalar content so the health check should point to something independend of it.\n(Of course: one could argue that it is bad user experience as sometimes they will also see content not delivered in such situations. Then again: none of the answers addresses the root cause. If the root cause is acceptable behavior we should nod have a check that depends on it. Increasing timeout may not help if content vanishes or ...)","comment_id":"854081"},{"content":"D\nIncreasing the health check grace period for the Auto Scaling group would give the instances more time to run the user data scripts and download critical content from the S3 bucket, which would prevent them from being terminated due to health check failures\n\n B Incorrect\nIncreasing the health check timeout would only give the instances more time to respond to the health checks, but it would not solve the underlying issue. In fact, it could potentially increase the response time of the ALB and cause longer load times for users.","comment_id":"831581","timestamp":"1678166700.0","poster":"TajSidKazi","upvote_count":"2"},{"timestamp":"1676210880.0","poster":"davidy2020","upvote_count":"1","comment_id":"806402","content":"B. Increase the health check timeout for the ALB.\n\nIncreasing the health check timeout for the ALB can help resolve the issue of the EC2 instances being terminated prematurely in this scenario. If the EC2 instances are taking a long time to download the content from the S3 bucket, this may cause the ALB health check to time out and mark the instances as unhealthy. By increasing the health check timeout, you give the EC2 instances more time to complete the download of the content from S3 and become fully operational before being checked by the ALB health check. This can prevent the instances from being marked as unhealthy and terminated prematurely."},{"poster":"zozza2023","comment_id":"791786","timestamp":"1675007160.0","content":"Selected Answer: D\nI agree with D","upvote_count":"3"}],"answer_ET":"C","exam_id":32,"question_images":[],"answer_description":"","answer_images":[],"question_id":963},{"id":"WaLrVM4OQ9uj8R1Hk6Cw","exam_id":32,"isMC":true,"question_images":[],"choices":{"E":"Use S3 Transfer Acceleration to provide lower latency to users.","A":"Evaluate and adjust the RCUs for the DynamoDB tables.","D":"Add an Amazon Simple Queue Service (Amazon SQS) queue and reprocessing logic between Amazon S3 and the Lambda functions.","B":"Evaluate and adjust the WCUs for the DynamoDB tables.","C":"Add an Amazon ElastiCache layer to increase the performance of Lambda functions."},"answer":"BD","question_text":"A media storage application uploads user photos to Amazon S3 for processing by AWS Lambda functions. Application state is stored in Amazon DynamoDB tables. Users are reporting that some uploaded photos are not being processed properly. The application developers trace the logs and find that Lambda is experiencing photo processing issues when thousands of users upload photos simultaneously. The issues are the result of Lambda concurrency limits and the performance of DynamoDB when data is saved.\n\nWhich combination of actions should a solutions architect take to increase the performance and reliability of the application? (Choose two.)","answer_images":[],"answer_ET":"BD","answers_community":["BD (100%)"],"question_id":964,"url":"https://www.examtopics.com/discussions/amazon/view/101741-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1678167900,"topic":"1","answer_description":"","discussion":[{"poster":"TajSidKazi","timestamp":"1678167900.0","content":"BD\nThe issue is related to the performance of DynamoDB when data is saved, which can be addressed by evaluating and adjusting the WCUs (Write Capacity Units) for the DynamoDB tables. Increasing the WCUs will increase the write capacity of the tables, which can help handle the increased load of photo uploads. Adding an Amazon SQS queue and reprocessing logic can also help with managing the load.","comment_id":"831587","upvote_count":"5"},{"upvote_count":"2","comment_id":"934790","content":"Selected Answer: BD\nBD\nThe issue is related to the performance of DynamoDB when data is saved, which can be addressed by evaluating and adjusting the WCUs (Write Capacity Units) for the DynamoDB tables. Increasing the WCUs will increase the write capacity of the tables, which can help handle the increased load of photo uploads. Adding an Amazon SQS queue and reprocessing logic can also help with managing the load.","poster":"SkyZeroZx","timestamp":"1687813560.0"}],"timestamp":"2023-03-07 06:45:00"},{"id":"xZOcDM465kVtSqKVkPaG","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/20444-exam-aws-certified-solutions-architect-professional-topic-1/","question_text":"You have an application running on an EC2 Instance which will allow users to download flies from a private S3 bucket using a pre-signed URL. Before generating the URL the application should verify the existence of the file in S3.\nHow should the application use AWS credentials to access the S3 bucket securely?","answer_ET":"C","answers_community":["C (100%)"],"discussion":[{"comment_id":"1266998","timestamp":"1723806300.0","upvote_count":"1","poster":"amministrazione","content":"C. Create an IAM role for EC2 that allows list access to objects in the S3 bucket. Launch the instance with the role, and retrieve the role's credentials from the EC2 Instance metadata"},{"timestamp":"1690993980.0","comment_id":"970371","poster":"TravelKo","upvote_count":"1","content":"Selected Answer: C\nC is clear choice"},{"poster":"kaushik9845","timestamp":"1663474800.0","content":"What does retrieving credentials in instance data mean..is it really needed?","comments":[{"content":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html","timestamp":"1667744220.0","poster":"NathanvB99","comment_id":"712352","upvote_count":"1"}],"comment_id":"671975","upvote_count":"1"},{"comment_id":"370586","timestamp":"1635764940.0","upvote_count":"2","content":"CCCCCCC","poster":"01037"},{"content":"C.\nrepeated question 85.","timestamp":"1634894820.0","upvote_count":"3","comment_id":"329245","poster":"cldy"},{"upvote_count":"3","content":"same as question 85.","comment_id":"114826","poster":"ricoyao","timestamp":"1634754900.0"},{"upvote_count":"3","comment_id":"97702","poster":"oatif","content":"C looks correct to me since we should create roles for services to take on","timestamp":"1632430020.0"},{"poster":"qianhaopower","upvote_count":"2","content":"C is correct! Duplicate question.","comment_id":"87992","timestamp":"1632348120.0"}],"answer":"C","topic":"1","answer_description":"","question_id":965,"choices":{"D":"Create an IAM user for the application with permissions that allow list access to the S3 bucket. The application retrieves the IAM user credentials from a temporary directory with permissions that allow read access only to the application user.","A":"Use the AWS account access Keys the application retrieves the credentials from the source code of the application.","C":"Create an IAM role for EC2 that allows list access to objects in the S3 bucket. Launch the instance with the role, and retrieve the role's credentials from the EC2 Instance metadata","B":"Create an IAM user for the application with permissions that allow list access to the S3 bucket launch the instance as the IAM user and retrieve the IAM user's credentials from the EC2 instance user data."},"timestamp":"2020-05-13 01:18:00","exam_id":32,"answer_images":[],"question_images":[],"unix_timestamp":1589325480}],"exam":{"lastUpdated":"11 Apr 2025","isImplemented":true,"provider":"Amazon","numberOfQuestions":1019,"id":32,"name":"AWS Certified Solutions Architect - Professional","isBeta":false,"isMCOnly":false},"currentPage":193},"__N_SSP":true}