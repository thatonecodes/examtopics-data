{"pageProps":{"questions":[{"id":"2GWzEL4nOpNlDDjzxK3f","exam_id":26,"question_images":[],"discussion":[{"timestamp":"1710959880.0","upvote_count":"6","content":"Selected Answer: A\nSMOTE for minority class for unbalanced data","comment_id":"845153","poster":"blanco750"},{"comment_id":"1005516","timestamp":"1726125780.0","poster":"loict","content":"Selected Answer: A\nA. YES - we want to oversample the minority class = Fraud\nB. NO - we want more fraudulent cases\nC. NO - we want more fraudulent cases\nD. NO - we want more fraudulent cases","upvote_count":"3"},{"comment_id":"987333","poster":"Mickey321","content":"Selected Answer: A\nBy applying SMOTE, you can balance the class distribution and increase the diversity of your data, which can help your model learn better and reduce overfitting1. You can use the imbalanced-learn library in Python to implement SMOTE on your data2.","timestamp":"1724322000.0","upvote_count":"1"},{"poster":"sevosevo","comment_id":"842793","upvote_count":"2","content":"Selected Answer: A\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjLkqfb1OX9AhXkQ0EAHYlVDq0QFnoECBMQAw&url=https%3A%2F%2Ftowardsdatascience.com%2F5-smote-techniques-for-oversampling-your-imbalance-data-b8155bdbe2b5&usg=AOvVaw1FdrxDEbLDjNhacXn3d-Tu","timestamp":"1710767640.0"}],"answer_images":[],"unix_timestamp":1679145240,"timestamp":"2023-03-18 14:14:00","topic":"1","question_text":"A credit card company wants to identify fraudulent transactions in real time. A data scientist builds a machine learning model for this purpose. The transactional data is captured and stored in Amazon S3. The historic data is already labeled with two classes: fraud (positive) and fair transactions (negative). The data scientist removes all the missing data and builds a classifier by using the XGBoost algorithm in Amazon SageMaker. The model produces the following results:\n\n• True positive rate (TPR): 0.700\n• False negative rate (FNR): 0.300\n• True negative rate (TNR): 0.977\n• False positive rate (FPR): 0.023\n• Overall accuracy: 0.949\n\nWhich solution should the data scientist use to improve the performance of the model?","answer_ET":"A","answers_community":["A (100%)"],"choices":{"C":"Undersample the minority class.","A":"Apply the Synthetic Minority Oversampling Technique (SMOTE) on the minority class in the training dataset. Retrain the model with the updated training data.","D":"Oversample the majority class.","B":"Apply the Synthetic Minority Oversampling Technique (SMOTE) on the majority class in the training dataset. Retrain the model with the updated training data."},"question_id":151,"url":"https://www.examtopics.com/discussions/amazon/view/103032-exam-aws-certified-machine-learning-specialty-topic-1/","isMC":true,"answer":"A","answer_description":""},{"id":"nCC38Awft0sbW65daWyN","answer_description":"","answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/103033-exam-aws-certified-machine-learning-specialty-topic-1/","choices":{"A":"Use File mode in SageMaker to copy the dataset from the S3 buckets to the ML instance storage.","B":"Create an Amazon FSx for Lustre file system. Link the file system to the S3 buckets.","C":"Create an Amazon Elastic File System (Amazon EFS) file system. Mount the file system to the training instances.","D":"Use FastFile mode in SageMaker to stream the files on demand from the S3 buckets."},"topic":"1","timestamp":"2023-03-18 14:16:00","answer_images":[],"question_text":"A company is training machine learning (ML) models on Amazon SageMaker by using 200 TB of data that is stored in Amazon S3 buckets. The training data consists of individual files that are each larger than 200 MB in size. The company needs a data access solution that offers the shortest processing time and the least amount of setup.\n\nWhich solution will meet these requirements?","question_images":[],"question_id":152,"answers_community":["D (70%)","B (30%)"],"isMC":true,"answer_ET":"D","exam_id":26,"discussion":[{"upvote_count":"13","poster":"mawsman","timestamp":"1697543220.0","comment_id":"872657","content":"Selected Answer: D\nWhen to use fast file mode:\n\nFor larger datasets with larger files (more than 50 MB per file), the first option is to try fast file mode, which is more straightforward to use than FSx for Lustre because it doesn't require creating a file system, or connecting to a VPC. Fast file mode is ideal for large file containers (more than 150 MB), and might also do well with files more than 50 MB.\n\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html#model-access-training-data-best-practices"},{"poster":"Gmishra","content":"Selected Answer: D\nhttps://aws.amazon.com/about-aws/whats-new/2021/10/amazon-sagemaker-fast-file-mode/","timestamp":"1728220080.0","upvote_count":"1","comment_id":"1190409"},{"upvote_count":"1","poster":"endeesa","content":"Selected Answer: D\nLeast setup is D, B could work but requires more setup!","timestamp":"1716916320.0","comment_id":"1082870"},{"upvote_count":"1","poster":"geoan13","comment_id":"1071993","timestamp":"1715807040.0","content":"D\nAmazon SageMaker now supports Fast File Mode for accessing data in training jobs. This enables high performance data access by streaming directly from Amazon S3 with no code changes from the existing File Mode. For example, training a K-Means clustering model on a 100GB dataset took 28 minutes with File Mode but only 5 minutes with Fast File Mode (82% decrease).\nhttps://aws.amazon.com/about-aws/whats-new/2021/10/amazon-sagemaker-fast-file-mode/"},{"content":"B. Yes\n\nPlease, look this link (https://aws.amazon.com/blogs/aws/enhanced-amazon-s3-integration-for-amazon-fsx-for-lustre/)","comment_id":"1010099","poster":"jopaca1216","timestamp":"1710721080.0","upvote_count":"1"},{"poster":"loict","upvote_count":"2","content":"Selected Answer: D\nA. NO - the files are too big and will fill the instance storage for no reason\nB. NO - Lustre create stripes for each file on different hard drives, maximizing throughput; our challenge is more about the volume of data to be made available on the training instance, not throughput\nC. NO - EFS support File semantic, but does not change any system property\nD. YES - FastFile allows training to start before the full file has been downloaded (like Pipe Mode) but does not require code change","timestamp":"1710236760.0","comment_id":"1005521"},{"comment_id":"992822","poster":"Mickey321","upvote_count":"1","content":"Selected Answer: D\nchanging to D","timestamp":"1709193840.0"},{"poster":"Mickey321","comment_id":"987343","timestamp":"1708605060.0","upvote_count":"1","content":"Selected Answer: B\nalthough D is very tempting but leaning towards B"},{"timestamp":"1699922760.0","comment_id":"897086","poster":"dkx","upvote_count":"2","content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/machine-learning/ensure-efficient-compute-resources-on-amazon-sagemaker/"},{"poster":"daidaidai","content":"Selected Answer: D\nWhen to use fast file mode\nFor larger datasets with larger files (more than 50 MB per file), the first option is to try fast file mode, which is more straightforward to use than FSx for Lustre because it doesn't require creating a file system, or connecting to a VPC. Fast file mode is ideal for large file containers (more than 150 MB), and might also do well with files more than 50 MB. Because fast file mode provides a POSIX interface, it supports random reads (reading non-sequential byte-ranges). However, this is not the ideal use case, and your throughput might be lower than with the sequential reads. However, if you have a relatively large and computationally intensive ML model, fast file mode might still be able to saturate the effective bandwidth of the training pipeline and not result in an IO bottleneck.","comment_id":"889348","upvote_count":"2","timestamp":"1699108680.0"},{"upvote_count":"3","poster":"Mllb","timestamp":"1696150620.0","comments":[{"timestamp":"1696251360.0","poster":"Mllb","upvote_count":"2","content":"B because we have 200TB\nhttps://saturncloud.io/blog/using-aws-sagemaker-input-modes-amazon-s3-efs-or-fsx/","comment_id":"858848"}],"comment_id":"857767","content":"Selected Answer: B\nOption D, FastFile mode, streams files on demand from S3 buckets to the training instance, which can be efficient for small datasets but may not be optimal for large datasets. Moreover, this solution does not provide a file system that is optimized for high performance, and it may require additional development effort to set up"},{"upvote_count":"4","comment_id":"845158","timestamp":"1695228540.0","content":"Selected Answer: D\nFast File Mode combines the ease of use of the existing File Mode with the performance of Pipe Mode. This provides convenient access to data as if it was downloaded locally, while offering the performance benefit of streaming the data directly from Amazon S3.\nNo code change required or no lengthy setup","poster":"blanco750"},{"content":"Selected Answer: B\nThe solution that meets the requirements of the company is B, which involves creating an Amazon FSx for Lustre file system and linking it to the S3 buckets. Amazon FSx for Lustre is a fully managed, high-performance file system optimized for compute-intensive workloads, such as machine learning training. It is designed to provide low latencies and high throughput for processing large data sets, and it can directly access data from S3 buckets without any data movement or copying. This solution requires minimal setup and provides the shortest processing time since the data can be accessed in parallel by multiple instances.","timestamp":"1695153360.0","poster":"oso0348","comment_id":"844282","upvote_count":"4"},{"poster":"austinoy","comment_id":"844248","timestamp":"1695150120.0","upvote_count":"3","content":"I will go with D\nhttps://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html"},{"content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/machine-learning/speed-up-training-on-amazon-sagemaker-using-amazon-efs-or-amazon-fsx-for-lustre-file-systems/","poster":"sevosevo","upvote_count":"3","timestamp":"1695035760.0","comment_id":"842794"}],"unix_timestamp":1679145360},{"id":"KJU1iJKZM5lRECEbLF0d","answer_ET":"C","topic":"1","answers_community":["C (100%)"],"question_id":153,"question_images":[],"isMC":true,"unix_timestamp":1679145660,"timestamp":"2023-03-18 14:21:00","answer":"C","url":"https://www.examtopics.com/discussions/amazon/view/103035-exam-aws-certified-machine-learning-specialty-topic-1/","exam_id":26,"answer_description":"","discussion":[{"comment_id":"1124979","timestamp":"1721214060.0","content":"Selected Answer: C\nC. Quantile binning: Quantile binning (or discretization) involves dividing a continuous variable into bins based on quantiles. This can be useful for handling skewed data by distributing the data more evenly across the bins. However, this method transforms the numerical feature into a categorical one, which might not be ideal for preserving the ordinal nature and the detailed variance of the 'duration' feature in a regression model.\n\nIf the choice must be made from the given options, Option C (Quantile binning) might be the most suitable, albeit not ideal, as it can at least help in dealing with skewed distributions by distributing the data across bins more evenly. However, the data scientist should consider logarithmic or polynomial transformations for a more direct approach to addressing non-linearity.","upvote_count":"5","poster":"CloudHandsOn"},{"timestamp":"1695036060.0","comment_id":"842798","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/machine-learning/latest/dg/data-transformations-reference.html","poster":"sevosevo","upvote_count":"5"},{"content":"Selected Answer: C\nA. NO - One-hot encoding is for featurization of categories\nB. NO - \nC. YES - Quantile binning can make data linear (https://docs.aws.amazon.com/machine-learning/latest/dg/data-transformations-reference.html#quantile-binning-transformation)\nD. NO - Normalization will recenter the data, not change the relationship","poster":"loict","comment_id":"1005526","timestamp":"1710237000.0","upvote_count":"2"},{"comment_id":"987348","upvote_count":"1","poster":"Mickey321","content":"Selected Answer: C\nquantile binning","timestamp":"1708605300.0"},{"comment_id":"847666","content":"C is correct","poster":"jackzhao","timestamp":"1695425340.0","upvote_count":"3"},{"poster":"blanco750","timestamp":"1695232380.0","comment_id":"845186","content":"Selected Answer: C\nC is the best answer I guess","upvote_count":"3"},{"content":"Selected Answer: C\nthe correct answer is C, Quantile binning. This transformation divides the data into quantiles (equal-sized intervals) based on the values of the feature (in this case, duration) and replaces the values with the bin number. This transformation can help capture non-linear relationships between features by creating more representative categories for skewed data. The transformed data can then be used to train a non-linear regression model, such as a polynomial regression, to better predict future book sales.","upvote_count":"4","comment_id":"844279","poster":"oso0348","timestamp":"1695153240.0"}],"answer_images":[],"choices":{"A":"One-hot encoding","B":"Cartesian product transformation","C":"Quantile binning","D":"Normalization"},"question_text":"An online store is predicting future book sales by using a linear regression model that is based on past sales data. The data includes duration, a numerical feature that represents the number of days that a book has been listed in the online store. A data scientist performs an exploratory data analysis and discovers that the relationship between book sales and duration is skewed and non-linear.\n\nWhich data transformation step should the data scientist take to improve the predictions of the model?"},{"id":"OtaGA9YlNdn65xuucdrO","url":"https://www.examtopics.com/discussions/amazon/view/103036-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","answer_description":"","unix_timestamp":1679146200,"timestamp":"2023-03-18 14:30:00","choices":{"D":"Create a single S3 bucket that includes two folders to separate the sensitive datasets from the non-sensitive datasets. Set the policy for the S3 bucket to allow only the Finance department user group to access the folder that contains the sensitive datasets. Allow all three department user groups to access the folder that contains the non-sensitive datasets.","B":"Create an S3 bucket for each dataset. For each S3 bucket that contains a sensitive dataset, set the bucket policy to allow access only from the Finance department user group. Allow all three department user groups to access each S3 bucket that contains a non-sensitive dataset.","A":"Create an S3 bucket for each dataset. Create an ACL for each S3 bucket. For each S3 bucket that contains a sensitive dataset, set the ACL to allow access only from the Finance department user group. Allow all three department user groups to access each S3 bucket that contains a non-sensitive dataset.","C":"Create a single S3 bucket that includes two folders to separate the sensitive datasets from the non-sensitive datasets. For the Finance department user group, attach an IAM policy that provides access to both folders. For the Marketing and Human Resources department user groups, attach an IAM policy that provides access to only the folder that contains the non-sensitive datasets."},"question_id":154,"question_text":"A company's data engineer wants to use Amazon S3 to share datasets with data scientists. The data scientists work in three departments: Finance. Marketing, and Human Resources. Each department has its own IAM user group. Some datasets contain sensitive information and should be accessed only by the data scientists from the Finance department.\n\nHow can the data engineer set up access to meet these requirements?","answer":"C","exam_id":26,"discussion":[{"poster":"CloudGyan","comment_id":"1341373","timestamp":"1737002220.0","content":"Selected Answer: D\nThe goal is to provide secure and efficient access to datasets stored in Amazon S3. Sensitive datasets should be accessible only to the Finance department, while non-sensitive datasets should be accessible to all user groups. S3 bucket policies are the most effective and scalable solution for implementing access control in this scenario.","upvote_count":"1"},{"comment_id":"1242095","upvote_count":"2","content":"Selected Answer: D\nFor the Marketing and Human Resources department user groups, attach an IAM policy that provides access to only the folder that contains the non-sensitive datasets.\nFinance department user also need access to non-sensitive datasets.","poster":"sheetalconect","timestamp":"1720098540.0"},{"timestamp":"1701199140.0","content":"Selected Answer: C\nI think attaching the policy is more flexible, in case this pattern needs to be repeated for another s3 bucket?","comment_id":"1082879","poster":"endeesa","upvote_count":"1"},{"poster":"geoan13","content":"Selected Answer: C\nYou cannot identify a user group as a principal in a policy (such as a resource-based policy) because groups relate to permissions, not authentication, and principals are authenticated IAM entities. an Amazon S3 bucket policy cannot have a user group as the principal directly. \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_principal.html\nI stand corrected. I retract my previous answer.","timestamp":"1700460000.0","upvote_count":"4","comment_id":"1075175"},{"timestamp":"1700091120.0","poster":"geoan13","comment_id":"1072011","content":"D\nUse a bucket policy. User group cannot be a principal in IAM policy. adding each individual user to the policy is not practical","upvote_count":"2"},{"content":"Selected Answer: C\nAccording to the AWS documentation, you cannot specify an IAM group as a principal in an S3 bucket policy. This is because groups relate to permissions, not authentication, and principals are authenticated IAM entities. You can only specify the following principals in a policy:\n\nAWS account and root user\nIAM user\nFederated user\nIAM role .\nIf you want to grant permission to an IAM group, you can add the ARNs of all the IAM users in that group to the S3 bucket policy instead.\nso it is C to create 2 IAM roles and attach them to different groups you have","poster":"teka112233","upvote_count":"2","timestamp":"1694902500.0","comments":[{"timestamp":"1694902560.0","content":"REF:\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-bucket-user-policy-specifying-principal-intro.html","upvote_count":"1","comment_id":"1009356","poster":"teka112233"}],"comment_id":"1009355"},{"timestamp":"1693349280.0","content":"https://docs.aws.amazon.com/AmazonS3/latest/userguide/walkthrough1.html\n\nit does not show any option to use iam group based s3 bucket policy. (so D cannot be the right answer)","comment_id":"993553","upvote_count":"2","poster":"ashii007"},{"comment_id":"992830","content":"Selected Answer: C\nchanging to C","poster":"Mickey321","upvote_count":"3","timestamp":"1693289640.0"},{"poster":"Mickey321","timestamp":"1692700800.0","upvote_count":"1","content":"Selected Answer: D\nOption D suggests creating a single S3 bucket that includes two folders to separate the sensitive datasets from the non-sensitive datasets. This option is helpful because it can simplify the data management and reduce the cost of using multiple S3 buckets. You can use a single S3 bucket to store all your datasets and use folders to organize them by their sensitivity level1. You can also use the Amazon S3 console or the AWS CLI to create and manage your folders2.","comment_id":"987352"},{"content":"First it is more efficient to use one single bucket, S3 has limit of 100 buckets by default, answer C creates two policies while for answer D , it is done with one, and use Deny on the sensitive folder to the two groups not finance, and have an allow to the non sensitive, knowing that deny takes precendence","timestamp":"1689472740.0","upvote_count":"1","poster":"jyrajan69","comment_id":"952880"},{"poster":"ADVIT","upvote_count":"1","content":"Selected Answer: C\nIn S3 bucket Policy you CANNOT specify IAM Group as Principal, but you can specify IAM Users.\nSo it's C.","comment_id":"945929","timestamp":"1688754600.0"},{"poster":"injoho","timestamp":"1682399160.0","content":"Option C\n\nhttps://stackoverflow.com/questions/35944349/iam-aws-s3-to-restrict-to-a-specific-sub-folder\n\nhttps://aws.amazon.com/blogs/security/how-to-restrict-amazon-s3-bucket-access-to-a-specific-iam-role/","comment_id":"879958","upvote_count":"2"},{"upvote_count":"3","comment_id":"877749","poster":"staskrocket","content":"Selected Answer: C\nI will choose C","timestamp":"1682213100.0"},{"poster":"jackzhao","timestamp":"1679534400.0","content":"I will choose C","upvote_count":"3","comment_id":"847660"},{"poster":"blanco750","content":"Both B and D look apparently correct but they are not because in s3 bucket policy , IAM Group cant be the principal. In other words you cant give access to a User group to s3 buckets using s3 bucket policy. It can only be an IAM user or role.https://stackoverflow.com/questions/30667678/s3-bucket-policy-how-to-allow-a-iam-group-from-another-account\nI would go for C","timestamp":"1679343120.0","comment_id":"845202","upvote_count":"4"},{"poster":"blanco750","upvote_count":"1","comment_id":"845194","timestamp":"1679342400.0","comments":[{"content":"Actually this is not possible. I will go for C","comments":[{"content":"https://stackoverflow.com/questions/30667678/s3-bucket-policy-how-to-allow-a-iam-group-from-another-account","comment_id":"933602","poster":"RC2020","timestamp":"1687697820.0","upvote_count":"1"}],"comment_id":"845199","poster":"blanco750","upvote_count":"3","timestamp":"1679342940.0"}],"content":"Selected Answer: D\nsingle bucket looks a better option. Ease of management and still secure"},{"poster":"oso0348","content":"Selected Answer: D\nCreating a single S3 bucket that includes two folders to separate the sensitive datasets from the non-sensitive datasets would be the best approach. The policy of the S3 bucket can be set to allow only the Finance department user group to access the folder that contains the sensitive datasets. The folder that contains non-sensitive datasets can be made available to all three department user groups. This approach will ensure that sensitive datasets are only accessible to users who need access to them.","comment_id":"844277","upvote_count":"1","timestamp":"1679262600.0"},{"poster":"austinoy","comment_id":"844265","content":"I'll go with D","timestamp":"1679261340.0","upvote_count":"1","comments":[{"comment_id":"858953","poster":"austinoy","content":"I stand corrected - it's C","upvote_count":"3","timestamp":"1680448020.0"}]},{"content":"Selected Answer: B\nhttps://stackoverflow.com/questions/47815526/s3-bucket-policy-vs-access-control-list","comment_id":"842804","poster":"sevosevo","upvote_count":"1","timestamp":"1679146200.0"}],"answers_community":["C (67%)","D (29%)","5%"],"answer_ET":"C","answer_images":[],"isMC":true,"question_images":[]},{"id":"nmdVynDDv4d7KwVW34TR","topic":"1","answer_images":[],"answers_community":["B (100%)"],"question_images":[],"answer_description":"","discussion":[{"timestamp":"1732821780.0","poster":"endeesa","comment_id":"1082881","content":"Selected Answer: B\nA and B the only options to consider, A talks about Rekognition which is not well suited for video so B","upvote_count":"1"},{"timestamp":"1724323440.0","upvote_count":"2","comment_id":"987360","content":"Selected Answer: B\nAmazon Kinesis Video Streams is a fully managed service that makes it easy to ingest, store, and analyze streaming video data.\nThe built-in HTTP live streaming (HLS) capability allows the security team to view the data in real time.\nAmazon Kinesis Video Streams is a pay-per-use service, so the company will only be charged for the amount of data that it ingests, stores, and analyzes.","poster":"Mickey321"},{"poster":"kaike_reis","timestamp":"1723901760.0","upvote_count":"1","comment_id":"983685","content":"Selected Answer: B\nIt's B\nreal time video ingestion = KVS (C and D are wrong)\nwatch the footage = HLS (rekognition would be for ML, which is not required so A is wrong)"},{"poster":"ADVIT","upvote_count":"1","timestamp":"1720377240.0","content":"Selected Answer: B\nNo any ML involved here, so it's B.","comment_id":"945932"},{"comment_id":"925985","poster":"SandeepGun","timestamp":"1718631240.0","content":"Selected Answer: B\nSelected B as per https://aws.amazon.com/about-aws/whats-new/2018/07/kinesis-video-adds-hls-support/","upvote_count":"1"}],"answer":"B","question_text":"A company operates an amusement park. The company wants to collect, monitor, and store real-time traffic data at several park entrances by using strategically placed cameras. The company’s security team must be able to immediately access the data for viewing. Stored data must be indexed and must be accessible to the company’s data science team.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_ET":"B","choices":{"B":"Use Amazon Kinesis Video Streams to ingest, index, and store the data. Use the built-in HTTP live streaming (HLS) capability for viewing by the security team.","C":"Use Amazon Rekognition Video and the GStreamer plugin to ingest the data for viewing by the security team. Use Amazon Kinesis Data Streams to index and store the data.","A":"Use Amazon Kinesis Video Streams to ingest, index, and store the data. Use the built-in integration with Amazon Rekognition for viewing by the security team.","D":"Use Amazon Kinesis Data Firehose to ingest, index, and store the data. Use the built-in HTTP live streaming (HLS) capability for viewing by the security team."},"timestamp":"2023-06-17 15:34:00","unix_timestamp":1687008840,"url":"https://www.examtopics.com/discussions/amazon/view/112449-exam-aws-certified-machine-learning-specialty-topic-1/","question_id":155,"isMC":true,"exam_id":26}],"exam":{"numberOfQuestions":369,"isBeta":false,"provider":"Amazon","id":26,"lastUpdated":"11 Apr 2025","name":"AWS Certified Machine Learning - Specialty","isImplemented":true,"isMCOnly":false},"currentPage":31},"__N_SSP":true}