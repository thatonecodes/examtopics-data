{"pageProps":{"questions":[{"id":"o7mDUh3ztScS3Zkkqkxr","question_id":676,"question_images":[],"answer":"D","answer_ET":"D","timestamp":"2019-09-06 15:30:00","isMC":true,"choices":{"A":"Replace the Auto Scaling launch configuration to include c3.8xlarge instances; those instances can potentially yield a network throuthput of 10gbps.","D":"Re-architect your ingest pattern, have the app authenticate against your identity provider, and use your identity provider as a broker fetching temporary AWS credentials from AWS Secure Token Service (GetFederationToken). Securely pass the credentials and S3 endpoint/prefix to your app. Implement client-side logic that used the S3 multipart upload API to directly upload the file to Amazon S3 using the given credentials and S3 prefix.","B":"Re-architect your ingest pattern, have the app authenticate against your identity provider, and use your identity provider as a broker fetching temporary AWS credentials from AWS Secure Token Service (GetFederationToken). Securely pass the credentials and S3 endpoint/prefix to your app. Implement client-side logic to directly upload the file to Amazon S3 using the given credentials and S3 prefix.","C":"Re-architect your ingest pattern, and move your web application instances into a VPC public subnet. Attach a public IP address for each EC2 instance (using the Auto Scaling launch configuration settings). Use Amazon Route 53 Round Robin records set and HTTP health check to DNS load balance the app requests; this approach will significantly reduce the cost by bypassing Elastic Load Balancing."},"answer_images":[],"answer_description":"","topic":"1","exam_id":32,"question_text":"Your company hosts a social media website for storing and sharing documents. The web application allows user to upload large files while resuming and pausing the upload as needed. Currently, files are uploaded to your PHP front end backed by Elastic Load Balancing and an autoscaling fleet of Amazon Elastic Compute\nCloud (EC2) instances that scale upon average of bytes received (NetworkIn). After a file has been uploaded, it is copied to Amazon Simple Storage Service (S3).\nAmazon EC2 instances use an AWS Identity and Access Management (IAM) role that allows Amazon S3 uploads. Over the last six months, your user base and scale have increased significantly, forcing you to increase the Auto Scaling group's Max parameter a few times. Your CFO is concerned about rising costs and has asked you to adjust the architecture where needed to better optimize costs.\nWhich architecture change could you introduce to reduce costs and still keep your web application secure and scalable?","discussion":[{"comment_id":"9919","poster":"DalianYifang","upvote_count":"17","timestamp":"1632446460.0","content":"Ans is D."},{"content":"D. Re-architect your ingest pattern, have the app authenticate against your identity provider, and use your identity provider as a broker fetching temporary AWS credentials from AWS Secure Token Service (GetFederationToken). Securely pass the credentials and S3 endpoint/prefix to your app. Implement client-side logic that used the S3 multipart upload API to directly upload the file to Amazon S3 using the given credentials and S3 prefix.","comment_id":"1266684","timestamp":"1723754880.0","poster":"amministrazione","upvote_count":"1"},{"upvote_count":"1","timestamp":"1677561900.0","poster":"sr987654","comment_id":"824408","content":"Selected Answer: D\nD is correct"},{"upvote_count":"2","content":"Selected Answer: D\nA: May increase costs\nB: Sounds good eliminate the cost on EC2\nC: Reduce some costs by sacrificing security\nD: Beter than B with multipart upload to address the request of resuming and pausing.","timestamp":"1671590700.0","poster":"TigerInTheCloud","comment_id":"751803"},{"poster":"sha999","upvote_count":"1","comment_id":"740497","content":"C can't be the answer because removing ELB will take away scalability and loss of customers as the numbers grow over the next few months. Totally unacceptable solution for any company that is growing.","timestamp":"1670624460.0"},{"timestamp":"1653215400.0","content":"Selected Answer: D\nB od D.\nIt's for big files, so multi-part upload. Which means D","upvote_count":"2","poster":"bobsmith2000","comment_id":"605343"},{"timestamp":"1648398660.0","poster":"omishaaaa","content":"I find D correct too, since the app allows to upload \"big files\", hence multi part uploads will add a great value here.","upvote_count":"1","comment_id":"576333"},{"upvote_count":"2","timestamp":"1639140480.0","poster":"cldy","comment_id":"498629","content":"D. Re-architect your ingest pattern, have the app authenticate against your identity provider, and use your identity provider as a broker fetching temporary AWS credentials from AWS Secure Token Service (GetFederationToken). Securely pass the credentials and S3 endpoint/prefix to your app. Implement client-side logic that used the S3 multipart upload API to directly upload the file to Amazon S3 using the given credentials and S3 prefix."},{"content":"D Correct","poster":"Akhil254","comment_id":"406345","timestamp":"1636191000.0","upvote_count":"1"},{"comment_id":"368331","upvote_count":"1","content":"D for sure","poster":"rain_wu","timestamp":"1635958500.0"},{"timestamp":"1635835500.0","poster":"01037","content":"D for sure","comments":[{"upvote_count":"2","poster":"01037","content":"resuming and pausing the upload is needed, so multi part upload is necessary","comment_id":"360289","timestamp":"1635843240.0"}],"upvote_count":"1","comment_id":"360276"},{"comment_id":"325789","upvote_count":"1","timestamp":"1635692340.0","content":"D.\nto \"reduce costs and still keep your web application secure and scalable\".","poster":"cldy"},{"content":"dddddddddddddd","upvote_count":"1","poster":"bustedd","timestamp":"1635480240.0","comment_id":"298167"},{"poster":"RomanTsai","timestamp":"1635232680.0","upvote_count":"2","comment_id":"297194","content":"Ans is D. \nC definitely wrong."},{"comment_id":"176298","upvote_count":"2","content":"Ans is D","poster":"ashendy","timestamp":"1635058860.0"},{"comment_id":"150472","timestamp":"1634864820.0","content":"Answer should be D, using S3 pre-signed URL and Multipart upload is the recommended way for direct uploads to bucket","poster":"kratnesh","upvote_count":"3"},{"comment_id":"144018","poster":"fullaws","upvote_count":"2","timestamp":"1634850660.0","content":"D, multi upload, large file, support pause and resume"},{"comment_id":"118004","poster":"manoj101","content":"To reduce the cost we need to remove EC2 instances from the middle. S3 is scalable & with HA so for just loading & Saving files it's most cost effective solution.","timestamp":"1634574600.0","upvote_count":"2"},{"poster":"ripntear","comment_id":"59406","content":"Not sure I agree: Note: Multivalue answer routing is not a substitute for Elastic Load Balancing (ELB). Route 53 randomly selects any eight records. When you perform dig (on Linux) or nslookup (on Windows) on your domain name multiple times, you might notice that the IP addresses rotate. This rotation improves availability and provides some load balancing functionality. Your operating system performs this round-robin DNS for cached responses, not Route 53.","timestamp":"1634278020.0","upvote_count":"1"},{"timestamp":"1634058060.0","comment_id":"53563","content":"Answer is D - multipart upload and resume feature","upvote_count":"4","poster":"miracle"},{"content":"D is correct!","poster":"Gorha","timestamp":"1633781040.0","upvote_count":"2","comment_id":"50750"},{"comment_id":"37959","content":"Answer is D","poster":"amog","upvote_count":"2","timestamp":"1633164720.0"},{"content":"D is the answer","upvote_count":"2","timestamp":"1633130640.0","comment_id":"32511","poster":"rocmac"},{"timestamp":"1633025940.0","comment_id":"18829","upvote_count":"3","content":"D is the answer as it support multipart upload for large files.","poster":"skywalker"},{"upvote_count":"3","poster":"Teri","comment_id":"18329","timestamp":"1633017420.0","content":"D here"},{"timestamp":"1632893280.0","content":"answer is D","poster":"Warrenn","upvote_count":"3","comment_id":"17505"},{"comment_id":"13033","content":"Ans is D as it is multipart upload","timestamp":"1632882960.0","poster":"SivaG","upvote_count":"4"},{"comment_id":"10843","timestamp":"1632453420.0","content":"Yes D here","upvote_count":"4","poster":"dpvnme"}],"answers_community":["D (100%)"],"unix_timestamp":1567776600,"url":"https://www.examtopics.com/discussions/amazon/view/4808-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"xrJOsjwGXvK6oFZVJVpr","answer_ET":"A","question_id":677,"question_images":[],"unix_timestamp":1616037480,"timestamp":"2021-03-18 04:18:00","url":"https://www.examtopics.com/discussions/amazon/view/47618-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"topic":"1","choices":{"C":"Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in one AWS Region and three Availability Zones. Configure an Amazon DocumentDB table in front of a Multi-AZ Amazon Aurora MySQL DB cluster. Move the WordPress shared files to Amazon EFS. Configure Amazon CloudFront with the ALB as the origin, and select a price class that includes all global locations.","B":"Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in two AWS Regions and two Availability Zones in each Region. Configure an Amazon ElastiCache cluster in front of a global Amazon Aurora MySQL database. Move the WordPress shared files to Amazon EFS. Configure Amazon CloudFront with the ALB as the origin, and select a price class that includes the US and Europe. Configure EFS cross- Region replication.","D":"Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in two AWS Regions and three Availability Zones in each Region. Configure an Amazon ElastiCache cluster in front of a global Amazon Aurora MySQL database. Move the WordPress shared files to Amazon FSx with cross-Region synchronization. Configure Amazon CloudFront with the ALB as the origin and a price class that includes the US and Europe.","A":"Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in one AWS Region and three Availability Zones. Configure an Amazon ElastiCache cluster in front of a Multi-AZ Amazon Aurora MySQL DB cluster. Move the WordPress shared files to Amazon EFS. Configure Amazon CloudFront with the ALB as the origin, and select a price class that includes the US and Europe."},"isMC":true,"answer_description":"","answers_community":["A (80%)","B (20%)"],"question_text":"A European online newspaper service hosts its public-facing WordPress site in a collocated data center in London. The current WordPress infrastructure consists of a load balancer, two web servers, and one MySQL database server. A solutions architect is tasked with designing a solution with the following requirements:\n✑ Improve the website's performance\n✑ Make the web tier scalable and stateless\n✑ Improve the database server performance for read-heavy loads\n✑ Reduce latency for users across Europe and the US\n✑ Design the new architecture with a goal of 99.9% availability\nWhich solution meets these requirements while optimizing operational efficiency?","answer_images":[],"discussion":[{"upvote_count":"32","comment_id":"316582","timestamp":"1632318120.0","poster":"certainly","content":"Correct choice is A. \nB and D are eliminated since Auto Scaling spans across multiple Availability Zones within the same region but cannot span across regions. C doesn't make sense by DocumentDB infront of another database.","comments":[{"content":"thanks for the comment, you are right. All LB are regional resources. you need route 53 to do it at global level.","upvote_count":"3","poster":"nitinz","comment_id":"319507","timestamp":"1633009140.0"}]},{"upvote_count":"1","timestamp":"1684719720.0","poster":"Jesuisleon","comment_id":"903624","content":"Selected Answer: A\nA is correct.\nB and D are out beacuse ALB can't across regions, justlimit to one region.\nC is out due to ElastiCache is suitable for read-heavy loads and users across Europe and the US so not need to select a price class that includes all global locations"},{"upvote_count":"1","timestamp":"1677318420.0","comment_id":"821352","content":"Selected Answer: B\nou need to sync the DB between regions: global Amazon Aurora MySQL database\n\"B\" says ALB in each regions\n->B","poster":"andras"},{"timestamp":"1669585980.0","content":"Selected Answer: A\nAt first sight it looks like an active-active cluster with all requirements - D fits well.\nBut then you read it two more times and realize there is a mistake. Blame on question maker! =)","poster":"SureNot","comment_id":"728643","upvote_count":"1"},{"poster":"astalavista1","content":"Selected Answer: A\nBD - Wrong as you can't configure ALB across regions but across AZ, need R53 first for multi-region config before moving to ALB.\nC - Wrong once it starts mentioning DocumentDB.\nA- Correct as it's a single Region with ALB across Multi-AZ, Cache in front of DB and Multi-AZ DB. Which satisfies all the requirements.","comment_id":"662536","upvote_count":"2","timestamp":"1662557400.0"},{"comment_id":"635804","poster":"hilft","timestamp":"1658620560.0","content":"A for me\nFor B, regarding EFS cross region replication feature. As of 2022 Jan, AWS support EFS cross-region replication\nhttps://aws.amazon.com/blogs/aws/new-replication-for-amazon-elastic-file-system-efs/","upvote_count":"2"},{"upvote_count":"1","content":"A for me","poster":"Ni_yot","comment_id":"557560","timestamp":"1645990260.0"},{"timestamp":"1638881040.0","content":"A. Use an Application Load Balancer (ALB) in front of an Auto Scaling group of WordPress Amazon EC2 instances in one AWS Region and three Availability Zones. Configure an Amazon ElastiCache cluster in front of a Multi-AZ Amazon Aurora MySQL DB cluster. Move the WordPress shared files to Amazon EFS. Configure Amazon CloudFront with the ALB as the origin, and select a price class that includes the US and Europe.","poster":"cldy","upvote_count":"1","comment_id":"495992"},{"timestamp":"1638448320.0","content":"A is right","upvote_count":"1","comment_id":"492468","poster":"AzureDP900"},{"comment_id":"436557","poster":"tgv","timestamp":"1636072800.0","content":"AAA\n---","upvote_count":"1"},{"comment_id":"413970","poster":"WhyIronMan","timestamp":"1636038060.0","upvote_count":"2","content":"I'll go with A"},{"comment_id":"385618","timestamp":"1634984400.0","content":"A is my answer.!","upvote_count":"1","poster":"hk436"},{"upvote_count":"1","comment_id":"366901","content":"A, B is not operational efficiency.","poster":"mustpassla","timestamp":"1634979120.0"},{"timestamp":"1633955580.0","comments":[{"poster":"SkyZeroZx","upvote_count":"1","comment_id":"939483","timestamp":"1688175240.0","content":"https://aws.amazon.com/es/blogs/aws/new-replication-for-amazon-elastic-file-system-efs/#:~:text=Configuring%20Replication,(Regional%20or%20One%20Zone)."}],"upvote_count":"2","poster":"LCC92","comment_id":"362031","content":"B is wrong \"Configure EFS cross- Region replication.\" is not possible, can only use Datasync to replicate EFS."},{"comment_id":"357178","upvote_count":"3","poster":"Waiweng","timestamp":"1633698240.0","content":"it's A"},{"comment_id":"334249","upvote_count":"1","timestamp":"1633586040.0","content":"A is the right option","poster":"Ziegler"},{"timestamp":"1632639780.0","comment_id":"316648","poster":"SD13","content":"D for me","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1633476360.0","poster":"SD13","comment_id":"329668","content":"Changing it to A"}]},{"comment_id":"313774","upvote_count":"2","poster":"nitinz","timestamp":"1632264000.0","content":"B works for me.","comments":[{"timestamp":"1632809100.0","upvote_count":"1","poster":"nitinz","comment_id":"319505","content":"changing to A."}]}],"answer":"A"},{"id":"V8AkGXLOaJ9EobPfAcDK","topic":"1","answer_description":"","timestamp":"2021-03-17 16:22:00","answer":"ABD","url":"https://www.examtopics.com/discussions/amazon/view/47553-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"exam_id":32,"answers_community":["ABD (100%)"],"question_images":[],"unix_timestamp":1615994520,"question_text":"A company built an ecommerce website on AWS using a three-tier web architecture. The application is Java-based and composed of an Amazon CloudFront distribution, an Apache web server layer of Amazon EC2 instances in an Auto Scaling group, and a backend Amazon Aurora MySQL database.\nLast month, during a promotional sales event, users reported errors and timeouts while adding items to their shopping carts. The operations team recovered the logs created by the web servers and reviewed Aurora DB cluster performance metrics. Some of the web servers were terminated before logs could be collected and the Aurora metrics were not sufficient for query performance analysis.\nWhich combination of steps must the solutions architect take to improve application performance visibility during peak traffic events? (Choose three.)","isMC":true,"question_id":678,"discussion":[{"upvote_count":"22","comment_id":"313388","comments":[{"poster":"kpcert","content":"A,B and D are correct answers.","timestamp":"1634652240.0","comment_id":"352637","upvote_count":"3"}],"timestamp":"1632489720.0","poster":"wasabidev","content":"ABD for me"},{"timestamp":"1633249020.0","comments":[{"content":"ABD is correct.","upvote_count":"2","comment_id":"340090","timestamp":"1633882380.0","poster":"Kelvin"}],"comment_id":"338340","upvote_count":"11","content":"Yes, ABD:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_LogAccess.Concepts.MySQL.html#USER_LogAccess.MySQLDB.PublishAuroraMySQLtoCloudWatchLogs\nhttps://aws.amazon.com/blogs/mt/simplifying-apache-server-logs-with-amazon-cloudwatch-logs-insights/\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-dotnet-messagehandler.html\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-java-sqlclients.html","poster":"CarisB"},{"comment_id":"714974","poster":"janvandermerwer","timestamp":"1668062280.0","upvote_count":"1","content":"Selected Answer: ABD\nGoing with everyone elses suggestions.\nA - DB cluster level logs, which cloudwatch will collate for later revision.\nB - Xray is great for tracing requests/queries\nD - need some method to send logs from the instances to cloudwatch, this is where the agent can come in."},{"upvote_count":"3","comment_id":"693141","poster":"Blair77","timestamp":"1665582960.0","content":"Selected Answer: ABD\nABD! Let's GO!"},{"timestamp":"1648573680.0","upvote_count":"1","comment_id":"577749","content":"Selected Answer: ABD\nABD looks right","poster":"jj22222"},{"upvote_count":"1","content":"Selected Answer: ABD\ni think it is abd","poster":"shotty1","comment_id":"532321","timestamp":"1643134020.0"},{"poster":"pititcu667","comment_id":"521552","content":"Selected Answer: ABD\nabd for me","upvote_count":"1","timestamp":"1641907320.0"},{"comment_id":"496967","timestamp":"1638982680.0","poster":"AzureDP900","content":"I'll go with A,B,D","upvote_count":"1"},{"content":"Answer is ABD","upvote_count":"1","poster":"moon2351","timestamp":"1636190880.0","comment_id":"449304"},{"content":"It's A B D","timestamp":"1635752100.0","comment_id":"446876","poster":"andylogan","upvote_count":"1"},{"content":"AAA BBB DDD\n---","timestamp":"1635524640.0","poster":"tgv","comment_id":"436564","upvote_count":"2"},{"timestamp":"1635430920.0","comment_id":"434005","poster":"blackgamer","content":"ABD for me as well.","upvote_count":"1"},{"comment_id":"413978","poster":"WhyIronMan","content":"I'll go with A,B,D","upvote_count":"2","timestamp":"1635369600.0"},{"upvote_count":"1","content":"ABD, use case of X-Ray. Send custom logs out using CW agent.","timestamp":"1635353760.0","poster":"mustpassla","comment_id":"366920"},{"upvote_count":"2","poster":"Waiweng","timestamp":"1634761980.0","comment_id":"357738","content":"it's A,B,D"},{"content":"Yes, ABD","comment_id":"343337","poster":"blackgamer","upvote_count":"2","timestamp":"1634005320.0"},{"comment_id":"316594","content":"ABD sounds good.","upvote_count":"2","poster":"certainly","timestamp":"1633006800.0"},{"content":"Yes I agree ABD.","poster":"nitinz","timestamp":"1632821220.0","upvote_count":"4","comment_id":"313777"}],"choices":{"F":"Enable Aurora MySQL DB cluster performance benchmarking and publish the stream to AWS X-Ray.","D":"Install and configure an Amazon CloudWatch Logs agent on the EC2 instances to send the Apache logs to CloudWatch Logs.","C":"Configure the Aurora MySQL DB cluster to stream slow query and error logs to Amazon Kinesis","A":"Configure the Aurora MySQL DB cluster to publish slow query and error logs to Amazon CloudWatch Logs.","E":"Enable and configure AWS CloudTrail to collect and analyze application activity from Amazon EC2 and Aurora.","B":"Implement the AWS X-Ray SDK to trace incoming HTTP requests on the EC2 instances and implement tracing of SQL queries with the X-Ray SDK for Java."},"answer_ET":"ABD"},{"id":"9OEqceaYrietg8RCdhxm","timestamp":"2021-03-18 04:32:00","url":"https://www.examtopics.com/discussions/amazon/view/47619-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["A (63%)","B (38%)"],"question_text":"A solutions architect has an operational workload deployed on Amazon EC2 instances in an Auto Scaling group. The VPC architecture spans two Availability\nZones (AZ) with a subnet in each that the Auto Scaling group is targeting. The VPC is connected to an on-premises environment and connectivity cannot be interrupted. The maximum size of the Auto Scaling group is 20 instances in service. The VPC IPv4 addressing is as follows:\n\nVPC CIDR: 10.0.0.0/23 -\n\nAZ1 subnet CIDR: 10.0.0.0/24 -\n\nAZ2 subnet CIDR: 10.0.1.0/24 -\nSince deployment, a third AZ has become available in the Region. The solutions architect wants to adopt the new AZ without adding additional IPv4 address space and without service downtime.\nWhich solution will meet these requirements?","question_images":[],"choices":{"D":"Update the Auto Scaling group to use the AZ2 subnet only. Update the AZ1 subnet to have the previous address space. Adjust the Auto Scaling group to also use the AZ1 subnet again. When the instances are healthy, adjust the Auto Scaling group to use the AZ1 subnet only. Update the current AZ2 subnet and assign the second half of the address space from the original AZ1 subnet. Create a new AZ3 subnet using half the original AZ2 subnet address space, then update the Auto Scaling group to target all three new subnets.","A":"Update the Auto Scaling group to use the AZ2 subnet only. Delete and re-create the AZ1 subnet using half the previous address space. Adjust the Auto Scaling group to also use the new AZ1 subnet. When the instances are healthy, adjust the Auto Scaling group to use the AZ1 subnet only. Remove the current AZ2 subnet. Create a new AZ2 subnet using the second half of the address space from the original AZ1 subnet. Create a new AZ3 subnet using half the original AZ2 subnet address space, then update the Auto Scaling group to target all three new subnets.","B":"Terminate the EC2 instances in the AZ1 subnet. Delete and re-create the AZ1 subnet using half the address space. Update the Auto Scaling group to use this new subnet. Repeat this for the second AZ. Define a new subnet in AZ3, then update the Auto Scaling group to target all three new subnets.","C":"Create a new VPC with the same IPv4 address space and define three subnets, with one for each AZ. Update the existing Auto Scaling group to target the new subnets in the new VPC."},"discussion":[{"comment_id":"322632","content":"A\n-------------------------\nhttps://aws.amazon.com/premiumsupport/knowledge-center/vpc-ip-address-range/?nc1=h_ls\nIt's not possible to modify the IP address range of an existing virtual private cloud (VPC) or subnet. You must delete the VPC or subnet, and then create a new VPC or subnet with your preferred CIDR block.","poster":"KevinZhong","upvote_count":"21","timestamp":"1632407100.0"},{"content":"A sounds like it","upvote_count":"6","comment_id":"313779","poster":"nitinz","timestamp":"1632073020.0"},{"comment_id":"761221","timestamp":"1672329120.0","upvote_count":"1","poster":"evargasbrz","content":"Selected Answer: A\nI'll go with A!"},{"timestamp":"1656102900.0","content":"Selected Answer: A\nAgree with A.","upvote_count":"4","comment_id":"621861","poster":"kangtamo"},{"content":"Selected Answer: B\nYou need to terminate the instances before you can delete the subnet which option B states. \nIf you no longer need a subnet, you can delete it. You cannot delete a subnet if it contains any network interfaces. For example, you must terminate any instances in a subnet before you can delete it. \nlink: https://docs.aws.amazon.com/vpc/latest/userguide/working-with-subnets.html\nA: It says delete and recreate, however you need to terminate instances as well which option B points out clearly.\nC: does not allow to use this approach as VPC is physically attached to on-prem\nD: Modify is not allowed, you need to delete and create subnets","upvote_count":"3","comment_id":"587202","timestamp":"1650196980.0","poster":"dev10","comments":[{"comment_id":"698090","content":"You do not need to terminate instances as when you update ASG only use AZ1, it will automatically recreate instances in AZ1, once all the instances created in AZ1, then you can delete the subnet. Tested it in my lab. \nSo answer is A.","upvote_count":"4","timestamp":"1666086180.0","poster":"fanq10"}]},{"upvote_count":"1","comment_id":"496969","timestamp":"1638982740.0","content":"It is A","poster":"AzureDP900"},{"comment_id":"446875","timestamp":"1635997560.0","upvote_count":"2","poster":"andylogan","content":"It's A - cannot modify"},{"upvote_count":"1","comment_id":"436565","content":"AAA\n---","poster":"tgv","timestamp":"1635880320.0"},{"poster":"WhyIronMan","timestamp":"1635448380.0","upvote_count":"2","comment_id":"413982","content":"I'll go with A"},{"upvote_count":"3","poster":"mustpassla","comment_id":"366923","timestamp":"1635013020.0","content":"A, no downtime, D is incorrect as CIDR cant be updated in this case."},{"timestamp":"1633654560.0","content":"it is A, cannot modify CIDR block","poster":"vkbajoria","upvote_count":"2","comment_id":"363891"},{"comment_id":"357744","upvote_count":"3","poster":"Waiweng","content":"it's A","timestamp":"1632689400.0"},{"content":"The answer is A because we cannot modify the IPv4 CIDR for the subnet so we need to delete and recreate","poster":"eji","comment_id":"318602","upvote_count":"4","timestamp":"1632402720.0"}],"question_id":679,"answer_ET":"A","topic":"1","isMC":true,"answer":"A","unix_timestamp":1616038320,"exam_id":32,"answer_images":[],"answer_description":""},{"id":"cj2ogThk4oQvTJ3SAiMa","question_text":"A company is storing data on premises on a Windows file server. The company produces 5 GB of new data daily.\nThe company migrated part of its Windows-based workload to AWS and needs the data to be available on a file system in the cloud. The company already has established an AWS Direct Connect connection between the on-premises network and AWS.\nWhich data migration strategy should the company use?","discussion":[{"timestamp":"1632653580.0","comment_id":"315488","upvote_count":"22","poster":"awsnoob","content":"B is correct, the workload on cloud relies on the Windows based storage"},{"timestamp":"1633374480.0","comment_id":"319493","upvote_count":"6","comments":[{"upvote_count":"4","comment_id":"326943","content":"Going with B. While I believe my initial comment is correct, the questions asks for data migration strategy.","comments":[{"content":"A is wrong - question asks about migrating a portion of workloads, no replacement of Windows server","upvote_count":"4","poster":"rb39","timestamp":"1639224840.0","comment_id":"499382"}],"poster":"chris1025","timestamp":"1634027760.0"}],"poster":"chris1025","content":"I believe it's A. DataSync is for initial migration but it's not meant for ongoing. The better answer would be to use DataSync first then file gateway."},{"poster":"sumaju","timestamp":"1702710960.0","comment_id":"1097973","upvote_count":"1","content":"Selected Answer: B\n\"Migration\" is the keyword here. For \"Migration\" use DataSync and for \"Integration\" use Storage Gateway.\n\nhttps://tutorialsdojo.com/aws-datasync-vs-storage-gateway/"},{"comment_id":"873023","upvote_count":"1","timestamp":"1681758300.0","content":"Selected Answer: A\nA \nFSx Storage gateway:\nhttps://bluexp.netapp.com/blog/aws-fsxo-blg-fsx-gateway-amazon-fsx-for-windows-at-on-premises-speed#:~:text=FSx%20File%20Gateway%20is%20a,FSx%20for%20Windows%20File%20Server.","poster":"dev112233xx"},{"poster":"Heer","upvote_count":"1","comment_id":"793780","timestamp":"1675150920.0","content":"For those who have selected Option B :\n\nThe company can use AWS Storage Gateway to migrate the data from the Windows file server to AWS. AWS Storage Gateway can be deployed on-premises as a virtual machine (VM) and configured as a file gateway to provide a file interface to Amazon S3. The company can use the AWS Direct Connect connection to transfer data from the on-premises Windows file server to the AWS Storage Gateway, and then from the gateway to Amazon S3.\n\nThe right option is A"},{"comment_id":"773441","timestamp":"1673527020.0","poster":"syaldram","upvote_count":"1","content":"Are most Windows based file system always FSx?"},{"timestamp":"1669586880.0","poster":"SureNot","comment_id":"728648","content":"Selected Answer: B\ndata migration strategy","upvote_count":"2"},{"comment_id":"712152","timestamp":"1667710680.0","poster":"alxjandroleiva","content":"Selected Answer: B\nB: \"and needs the data to be available on a file system in the cloud. \"\nNo, access like a file system....on a file system","upvote_count":"1"},{"content":"It is clear that we need Amazon Fx on the AWS side. For the on-prem, we can achieve this with DataSync or with Amazon FSx File Gateway (https://aws.amazon.com/storagegateway/file/fsx/). Option A is incomplete, cannot decide between A and B","timestamp":"1664443200.0","poster":"JohnPi","comment_id":"682495","upvote_count":"2"},{"comment_id":"641897","upvote_count":"1","content":"if the company already relocated its workload to the cloud then storage gateway is the way...A make sense tho","poster":"gondohwe","timestamp":"1659531540.0"},{"comment_id":"628798","content":"Selected Answer: B\nHave to choose B - Windows based share file system + Question clearly states \"requires data to be accessible through a cloud file system\".\nA - cannot be right since it will use NFS/SMB protocol to cache & transfer files to an S3 bucket which is not a FS.","timestamp":"1657288980.0","poster":"asfsdfsdf","comments":[{"content":"The Storage Gateway can be an FSx File GW, that way the file share data is synchronized with an FSx file system in the cloud.","poster":"Naj_64","upvote_count":"1","timestamp":"1665689520.0","comment_id":"694235"}],"upvote_count":"2"},{"content":"Selected Answer: A\nthe statement says \"Relocated\" which means the migration has already happened and now what they want is just access to the data on-prem. So has to be storage gateway.","comment_id":"613570","timestamp":"1654738440.0","poster":"Harry_01","upvote_count":"2"},{"poster":"Anhdd","comment_id":"609967","upvote_count":"1","content":"Selected Answer: A\nIt's say that \"relocated a portion of its Windows-based workload to AWS\". So in this case we have to use Storage Gateway, because we need to access data both from on-premis and on AWS. So we can't use DataSync which is used for transfer 100% data to AWS and keep no data remain on-premis. That's my opinion, so the answer should be ANH","comments":[{"timestamp":"1654048260.0","poster":"Anhdd","comment_id":"609968","content":"so the answer should be A* (my miss spell :D )","upvote_count":"1"}],"timestamp":"1654048140.0"},{"content":"Selected Answer: B\naggreed with hansmong","upvote_count":"1","comment_id":"607637","timestamp":"1653568140.0","poster":"Racinely"},{"upvote_count":"3","content":"A - access file on s3 from on-prem\nC - datapipeline is an ETL tool, should be datasync in this case\nD - efs does not support Windows https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AmazonEFS.html","poster":"hansmong","timestamp":"1641212940.0","comments":[{"poster":"Duke_YU","comments":[{"comment_id":"583288","poster":"GatesChi","upvote_count":"1","content":"You will need to re-write whatever program using the file share.","timestamp":"1649504880.0"}],"comment_id":"521192","upvote_count":"1","content":"Why \"access file on S3 from on-prem\" is not an option? I don't like it but don't think it is impossible.","timestamp":"1641858060.0"}],"comment_id":"515691"},{"poster":"vbal","content":"You can use AWS DataSync to migrate on-premises data to Amazon S3, Amazon EFS, and Amazon FSx for Windows File Server. Configure DataSync to make an initial copy of your entire dataset, and schedule subsequent incremental transfers of changing data until the final cut-over from on-premises to AWS.","timestamp":"1639508280.0","upvote_count":"1","comment_id":"501620"},{"content":"B is right","poster":"AzureDP900","timestamp":"1638982800.0","upvote_count":"1","comment_id":"496970"},{"content":"B. Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx","comment_id":"494216","comments":[{"content":"B is wrong in this case , A is right","comment_id":"597881","upvote_count":"2","poster":"user0001","timestamp":"1651870380.0"}],"upvote_count":"2","timestamp":"1638699360.0","poster":"cldy"},{"upvote_count":"1","poster":"andylogan","comment_id":"446929","timestamp":"1636240920.0","content":"It's B"},{"timestamp":"1636018620.0","poster":"student22","upvote_count":"1","comment_id":"439641","content":"B\n'needs the data to be available on a file system in the cloud'"},{"upvote_count":"1","content":"BBB\n---","timestamp":"1635972780.0","poster":"tgv","comment_id":"435308"},{"poster":"WhyIronMan","content":"I'll go with B","comment_id":"413984","upvote_count":"1","timestamp":"1635629760.0"},{"poster":"Pb55","content":"B.\nhttps://aws.amazon.com/storagegateway/file/","timestamp":"1634947860.0","comment_id":"398423","upvote_count":"3"},{"comment_id":"360943","content":"A is wrong. key point: company moved windows based workload to AWS, which requires an instance of Windows based file system in the cloud. File Gateway uses S3 in the cloud.","comments":[{"upvote_count":"2","content":"Your argument sounds like S3 doesn't support windows. But actually it does. https://docs.aws.amazon.com/systems-manager/latest/userguide/prereqs-operating-systems.html#prereqs-os-windows-server","poster":"Duke_YU","timestamp":"1641858000.0","comment_id":"521191"},{"comment_id":"597883","timestamp":"1651870440.0","poster":"user0001","content":"b is wrong , we are not doing migration . A is write in this case since cloud and prem need to access the data , dont just reed other comment and repeat the same","upvote_count":"1"}],"poster":"digimaniac","upvote_count":"3","timestamp":"1634858940.0"},{"upvote_count":"4","content":"it's B","poster":"Waiweng","comment_id":"357754","timestamp":"1634631420.0"},{"poster":"AJBA","upvote_count":"2","content":"B\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-files-to-fsx-datasync.html","comment_id":"330031","timestamp":"1634293140.0"},{"content":"Both A and B are workable solutions. However running file storage gateway has lesser operational overheads compared to maintaining a daily backup schedule.","timestamp":"1634082300.0","upvote_count":"2","poster":"Pupu86","comment_id":"328654"},{"timestamp":"1633702500.0","comment_id":"323504","upvote_count":"2","poster":"tiffanny","content":"B is correct, since they want to migrate Windows File Server, then it will work with Fsx."},{"timestamp":"1633020420.0","upvote_count":"3","poster":"eji","comments":[{"upvote_count":"1","timestamp":"1633119300.0","comment_id":"318607","poster":"eji","content":"*file server"}],"comment_id":"318605","content":"I think B is correct. the key is file system for windows so Amazon FSx is required"},{"poster":"SD13","content":"B seems a better option","timestamp":"1632714900.0","comment_id":"316517","upvote_count":"3"},{"content":"I think A is correct.","upvote_count":"2","poster":"nitinz","comments":[{"comment_id":"319545","poster":"nitinz","timestamp":"1633416000.0","content":"I agree B is better options.","upvote_count":"2"}],"timestamp":"1632183960.0","comment_id":"313781"}],"topic":"1","isMC":true,"exam_id":32,"choices":{"C":"Use AWS Data Pipeline to schedule a daily task to replicate data between the on-premises Windows file server and Amazon Elastic File System (Amazon EFS)","B":"Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx","D":"Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon Elastic File System (Amazon EFS)","A":"Use the file gateway option in AWS Storage Gateway to replace the existing Windows file server, and point the existing file share to the new file gateway"},"answers_community":["B (64%)","A (36%)"],"unix_timestamp":1616038380,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/47620-exam-aws-certified-solutions-architect-professional-topic-1/","question_id":680,"timestamp":"2021-03-18 04:33:00","answer_ET":"B","answer":"B","answer_description":"","answer_images":[]}],"exam":{"isMCOnly":false,"name":"AWS Certified Solutions Architect - Professional","isBeta":false,"id":32,"isImplemented":true,"numberOfQuestions":1019,"lastUpdated":"11 Apr 2025","provider":"Amazon"},"currentPage":136},"__N_SSP":true}