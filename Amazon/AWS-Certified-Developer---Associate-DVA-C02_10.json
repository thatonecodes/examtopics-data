{"pageProps":{"questions":[{"id":"zZ80z0eElcL11cjX4f4p","question_images":[],"answer_images":[],"answer":"C","answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/102741-exam-aws-certified-developer-associate-dva-c02-topic-1/","timestamp":"2023-03-15 23:34:00","question_text":"A financial company must store original customer records for 10 years for legal reasons. A complete record contains personally identifiable information (PII). According to local regulations, PII is available to only certain people in the company and must not be shared with third parties. The company needs to make the records available to third-party organizations for statistical analysis without sharing the PII.\nA developer wants to store the original immutable record in Amazon S3. Depending on who accesses the S3 document, the document should be returned as is or with all the PII removed. The developer has written an AWS Lambda function to remove the PII from the document. The function is named removePii.\nWhat should the developer do so that the company can meet the PII requirements while maintaining only one copy of the document?","topic":"1","unix_timestamp":1678919640,"isMC":true,"choices":{"D":"Create an S3 access point from the S3 console. Use the access point name to call the GetObjectLegalHold S3 API function. Pass in the removePii function name to access the object without PII.","C":"Create an S3 Object Lambda access point from the S3 console. Select the removePii function. Use S3 Access Points to access the object without PII.","A":"Set up an S3 event notification that invokes the removePii function when an S3 GET request is made. Call Amazon S3 by using a GET request to access the object without PII.","B":"Set up an S3 event notification that invokes the removePii function when an S3 PUT request is made. Call Amazon S3 by using a PUT request to access the object without PII."},"question_id":46,"answer_description":"","discussion":[{"comment_id":"1071735","upvote_count":"19","comments":[{"upvote_count":"2","poster":"Skip","comment_id":"1235711","timestamp":"1719125460.0","content":"Thanks for the info. Great heads up!"}],"poster":"gcmrjbr","timestamp":"1700070120.0","content":"An S3 Object Lambda access point is a new type of access point that you can create to invoke your own AWS Lambda function to modify the content of an S3 object. You can use S3 Object Lambda access points to transform data as it is being retrieved from an S3 bucket, without modifying the original data stored in the bucket"},{"comment_id":"845567","poster":"Untamables","content":"Selected Answer: C\nC\nhttps://aws.amazon.com/s3/features/object-lambda/","timestamp":"1679378820.0","upvote_count":"13"},{"poster":"sumanshu","comment_id":"1329811","upvote_count":"2","content":"Selected Answer: C\nA) Eliminated - function cannot be invoked when a GET request is made.\nB) Eliminated - It will either create two copies or overwrite existing copy\nD) Eliminated - GetObjectLegalHold this API is used to check if an object is under a legal hold. It has nothing to do with dynamically modifying or removing PII from documents.","timestamp":"1734755400.0"},{"content":"Selected Answer: C\n=> Discard A: S3 event notification not support GET\n=> Discard B: violate this rule 'keyword: only one copy of the document'. S3 event notification with PUT, make a copy (without PII) beside original record\n\n=> Dsiscard D: API GetObjectLegelHold is s3 GET API to know s3 object is editable, it can't update/ edit s3 object. Lambda can't auto be called by this API\n\nC: Lambda access point is intermediary s3 object and end-user, it modifies a copy of data (delete PII) then return user, then delete this data from local lambda memory","timestamp":"1734048660.0","poster":"trieudo","upvote_count":"1","comment_id":"1325911"},{"content":"Selected Answer: C\nhttps://aws.amazon.com/s3/features/object-lambda/\nWith S3 Object Lambda, you can add your own code to S3 GET, HEAD, and LIST requests to modify and process data as it is returned to an application. You can use custom code to modify the data returned by S3 GET requests to filter rows, dynamically resize images, redact confidential data, and much more.","poster":"ahadh7621","upvote_count":"2","comment_id":"1249274","timestamp":"1721166900.0"},{"upvote_count":"1","poster":"Anandesh","comment_id":"1248796","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html","timestamp":"1721122680.0"},{"content":"Selected Answer: C\nC is the correct answer.","comment_id":"1214989","timestamp":"1716299460.0","upvote_count":"1","poster":"65703c1"},{"timestamp":"1710054900.0","poster":"KarBiswa","upvote_count":"1","comment_id":"1170091","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/olap-create.html"},{"content":"Why is it C?","poster":"pagyabeng","timestamp":"1683820740.0","upvote_count":"3","comment_id":"895204"},{"upvote_count":"2","comment_id":"890872","poster":"geekdamsel","timestamp":"1683390420.0","content":"Correct answer is C."},{"comment_id":"875501","upvote_count":"1","poster":"Rpod","content":"Selected Answer: C\nC answer","timestamp":"1681988760.0"},{"timestamp":"1680358620.0","comment_id":"858005","upvote_count":"3","content":"Selected Answer: C\nIt is C","poster":"ihta_2031"},{"comment_id":"840374","upvote_count":"7","timestamp":"1678919640.0","content":"C\nhttps://www.examtopics.com/discussions/amazon/view/88229-exam-aws-certified-developer-associate-topic-1-question-174/","poster":"aragon_saa"}],"exam_id":24,"answers_community":["C (100%)"]},{"id":"UYj6KgGog4cEjqjuJpKq","isMC":true,"timestamp":"2023-08-08 06:27:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/117574-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"unix_timestamp":1691468820,"answer_description":"","answer_images":[],"discussion":[{"upvote_count":"10","timestamp":"1692895440.0","poster":"love777","content":"Selected Answer: D\nOption D is the best approach for resolving the merge conflicts with minimal development effort. Here's how it works:\n\nStop Pull from Main: By stopping the pull from the main branch to the feature branch, the developer can prevent the introduction of new conflicts while they are resolving the existing ones.\n\nRebase the Feature Branch: After stopping the pull, the developer can rebase the feature branch onto the main branch. This essentially replays the feature branch's changes on top of the main branch's latest changes. This allows the developer to resolve conflicts one commit at a time, addressing any conflicts that arise from the difference between the feature branch and the main branch.","comment_id":"989340"},{"content":"Most people say D, but option D does not cover the fixing of conflict, but option C at lease says \"fix the conflicts\" so this is a complete answer, no?","timestamp":"1730024580.0","comment_id":"1303546","poster":"9d8dd9c","upvote_count":"1"},{"upvote_count":"1","comment_id":"1216143","poster":"65703c1","content":"Selected Answer: D\nD is the correct answer.","timestamp":"1716427620.0"},{"timestamp":"1709411040.0","comment_id":"1164359","poster":"maurice2005","content":"Selected Answer: C\nHow on earth non-visualize way is easier? And I've never seen a rebase that happened commit-by-commit! Resolving the merge should happened in one go, merge or rebase. just rebase appear(!) more isolated. (which in practice it's not!). Also rebase is cleaner but the effort is even more since there is a level of isolation! \nThe only point here is visualizing which makes it easier.","upvote_count":"2"},{"upvote_count":"1","content":"Selected Answer: D\nD. Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch: Rebasing the feature branch from the main branch is an effective way to resolve merge conflicts. This approach involves updating the feature branch with the latest changes from the main branch and then applying the feature branch's changes on top of it. Rebasing can simplify the process of resolving conflicts and is generally less effort-intensive compared to creating new branches and transferring changes.\n\nC. Use the Commit Visualizer view to compare the commits when a feature was added. Fix the merge conflicts: Using tools like Commit Visualizer to understand the changes and conflicts can be helpful. However, this step alone doesnâ€™t resolve the conflicts. The developer still needs to manually resolve the conflicts in the code.","comment_id":"1125265","poster":"SerialiDr","timestamp":"1705520880.0"},{"timestamp":"1697274720.0","upvote_count":"1","poster":"Passexam4sure_com","content":"D\nD. Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch.","comment_id":"1043280"},{"content":"D. Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch.","upvote_count":"1","comment_id":"1043098","poster":"Claire_KMT","timestamp":"1697250780.0"},{"timestamp":"1694468040.0","comment_id":"1005172","upvote_count":"3","poster":"Iamtany","content":"Selected Answer: D\nRebasing the feature branch from the main branch would apply the changes from the main branch directly onto the feature branch, effectively bringing it up to date. This would resolve the conflicts in a way that minimizes manual effort."},{"timestamp":"1693240980.0","comment_id":"992403","upvote_count":"2","poster":"[Removed]","content":"Selected Answer: D\nOption D is the best approach for resolving the merge conflicts"},{"content":"Selected Answer: D\nUsing the git rebase command to rebase a repository changes the history of a repository, which might cause commits to appear out of order.\n\nhttps://docs.aws.amazon.com/codecommit/latest/userguide/how-to-view-commit-details.html","poster":"[Removed]","timestamp":"1691692740.0","comment_id":"977999","upvote_count":"1"},{"content":"Selected Answer: C\nComparing commits in the Commit Visualizer view can provide a clear overview of the changes made over time and aid in understanding the context of the conflicts. This approach can help you pinpoint where conflicts arose and assist you in making informed decisions about how to resolve them.","poster":"AWSdeveloper08","timestamp":"1691669520.0","upvote_count":"4","comment_id":"977625"},{"comments":[{"poster":"Cerakoted","upvote_count":"1","comment_id":"1041294","timestamp":"1697077560.0","comments":[{"timestamp":"1709410800.0","upvote_count":"1","comment_id":"1164358","poster":"maurice2005","content":"because visualizing make it harder? You have to fix the conflict anyway! rebase or merge. in both resolve the conflict will happened in one go (unlike the comments I see which they say rebase is commit by commit). I don't think those who pick rebase ever used it before in practice!"}],"content":"I think C would take huge development effort"}],"upvote_count":"1","content":"Selected Answer: C\nAnswer D won't fix the problem","timestamp":"1691468820.0","comment_id":"975176","poster":"worseforwear"}],"answers_community":["D (72%)","C (28%)"],"question_id":47,"choices":{"B":"Create a new branch. Apply the changes from the previous branch.","D":"Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch.","C":"Use the Commit Visualizer view to compare the commits when a feature was added. Fix the merge conflicts.","A":"Clone the repository. Create a new branch. Update the branch with the changes."},"answer":"D","question_text":"A company has an application that uses AWS CodePipeline to automate its continuous integration and continuous delivery (CI/CD) workflow. The application uses AWS CodeCommit for version control. A developer who was working on one of the tasks did not pull the most recent changes from the main branch. A week later, the developer noticed merge conflicts.\n\nHow can the developer resolve the merge conflicts in the developer's branch with the LEAST development effort?","answer_ET":"D","exam_id":24},{"id":"LqnPRdIOa1vIGCg5O4gh","answer_ET":"B","question_text":"A developer wants to add request validation to a production environment Amazon API Gateway API. The developer needs to test the changes before the API is deployed to the production environment. For the test, the developer will send test requests to the API through a testing tool.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","topic":"1","choices":{"B":"Modify the existing API to add request validation. Deploy the updated API to a new API Gateway stage. Perform the tests. Deploy the updated API to the API Gateway production stage.","D":"Clone the existing API. Modify the new API to add request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production.","A":"Export the existing API to an OpenAPI file. Create a new API. Import the OpenAPI file. Modify the new API to add request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production.","C":"Create a new API. Add the necessary resources and methods, including new request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production"},"answer_images":[],"question_images":[],"question_id":48,"answers_community":["B (100%)"],"isMC":true,"answer":"B","timestamp":"2023-08-10 14:13:00","url":"https://www.examtopics.com/discussions/amazon/view/117797-exam-aws-certified-developer-associate-dva-c02-topic-1/","unix_timestamp":1691669580,"discussion":[{"comment_id":"977628","timestamp":"1707574380.0","poster":"AWSdeveloper08","content":"Selected Answer: B\nIn this option, you are making changes directly to the existing API, adding request validation. Then, you deploy the updated API to a new API Gateway stage, which allows you to test the changes without affecting the production environment. After performing the tests and ensuring everything works as expected, you can then deploy the updated API to the production stage, thus minimizing operational overhead.","upvote_count":"12"},{"poster":"65703c1","content":"Selected Answer: B\nB is the correct answer.","upvote_count":"1","comment_id":"1216145","timestamp":"1732332600.0"},{"comment_id":"1125659","timestamp":"1721288040.0","content":"Selected Answer: B\nB. Modify the existing API to add request validation. Deploy the updated API to a new API Gateway stage. Perform the tests. Deploy the updated API to the API Gateway production stage: This is a more streamlined approach. By deploying the updated API to a new stage, the developer can test the changes in an environment that closely mirrors production without affecting the current production traffic. Once testing is complete, the changes can be deployed to the production stage. This approach minimizes operational overhead.","poster":"SerialiDr","upvote_count":"2"},{"content":"Selected Answer: B\nIt looks Correct","timestamp":"1710523860.0","comment_id":"1008558","poster":"imyashkale","upvote_count":"2"}],"answer_description":"","exam_id":24},{"id":"H67rkHerqVUVJNJTZTNB","answer_description":"","question_text":"An online food company provides an Amazon API Gateway HTTP API to receive orders for partners. The API is integrated with an AWS Lambda function. The Lambda function stores the orders in an Amazon DynamoDB table.\n\nThe company expects to onboard additional partners. Some of the partners require additional Lambda functions to receive orders. The company has created an Amazon S3 bucket. The company needs to store all orders and updates in the S3 bucket for future analysis.\n\nHow can the developer ensure that all orders and updates are stored to Amazon S3 with the LEAST development effort?","answer_images":[],"answer":"C","choices":{"B":"Use Amazon Kinesis Data Streams to create a new data stream. Modify the Lambda function to publish orders to the data stream. Configure the data stream to write to the S3 bucket.","C":"Enable DynamoDB Streams on the DynamoDB table. Create a new Lambda function. Associate the streamâ€™s Amazon Resource Name (ARN) with the Lambda function. Configure the Lambda function to write to the S3 bucket as records appear in the table's stream.","A":"Create a new Lambda function and a new API Gateway API endpoint. Configure the new Lambda function to write to the S3 bucket. Modify the original Lambda function to post updates to the new API endpoint.","D":"Modify the Lambda function to publish to a new Amazon Simple Notification Service (Amazon SNS) topic as the Lambda function receives orders. Subscribe a new Lambda function to the topic. Configure the new Lambda function to write to the S3 bucket as updates come through the topic."},"isMC":true,"question_id":49,"exam_id":24,"answers_community":["C (100%)"],"unix_timestamp":1691669700,"discussion":[{"content":"Selected Answer: C\nBy enabling DynamoDB Streams on the DynamoDB table, you can capture changes (orders and updates) to the table. Whenever a new order or an update is made to the table, a stream record is generated. You can then create a new Lambda function, associate the stream's ARN with this Lambda function, and configure it to write the stream records (orders and updates) to the S3 bucket. This approach leverages built-in features of DynamoDB and Lambda, minimizing the development effort required to achieve the desired outcome.","poster":"AWSdeveloper08","timestamp":"1707574500.0","upvote_count":"9","comment_id":"977629"},{"comment_id":"1216146","poster":"65703c1","content":"Selected Answer: C\nC is the correct answer.","timestamp":"1732332660.0","upvote_count":"1"},{"content":"Selected Answer: C\nThis is a streamlined and effective approach. Enabling DynamoDB Streams captures modifications to the DynamoDB table (such as new orders) and triggers a new Lambda function. This function can then write these changes to the S3 bucket. This approach requires minimal changes to the existing setup and leverages the integration between DynamoDB Streams and Lambda.","comment_id":"1125701","timestamp":"1721289780.0","upvote_count":"2","poster":"SerialiDr"},{"timestamp":"1710023760.0","poster":"Dushank","upvote_count":"3","content":"Selected Answer: C\nEnabling DynamoDB Streams on the existing DynamoDB table and associating a new Lambda function to it would be a straightforward way to capture all changes (new orders and updates) in the DynamoDB table. The new Lambda function would automatically be triggered when a new record appears in the table's stream and could be configured to write this data to the S3 bucket. This is likely the least effort-intensive approach for meeting the requirement.","comment_id":"1003495"}],"url":"https://www.examtopics.com/discussions/amazon/view/117798-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answer_ET":"C","timestamp":"2023-08-10 14:15:00","topic":"1"},{"id":"qxx1TdRV2bIFuQwKy6ET","answer_ET":"DE","discussion":[{"upvote_count":"2","comment_id":"1216147","content":"Selected Answer: DE\nDE is the correct answer.","poster":"65703c1","timestamp":"1732332720.0"},{"timestamp":"1721290140.0","content":"Selected Answer: DE\nD. Create an Amazon CloudFront distribution to cache the static content: This is an effective solution. Amazon CloudFront is a content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency and high transfer speeds. Using CloudFront to cache static content closer to users can significantly reduce latency.\n\nE. Store the applicationâ€™s static content in Amazon S3: This is another effective solution. Amazon S3 can serve as a highly durable and scalable storage solution for static content. When combined with Amazon CloudFront, it provides an efficient way to manage and deliver static content with reduced latency.\n\nThe combination of steps that will best resolve the latency issue is:\n\nD. Create an Amazon CloudFront distribution to cache the static content.\nE. Store the applicationâ€™s static content in Amazon S3.","upvote_count":"3","comment_id":"1125709","poster":"SerialiDr"},{"content":"Selected Answer: DE\nOption (D), creating an Amazon CloudFront distribution to cache static content, is the most recommended solution. CloudFront is a global content delivery network (CDN) that can cache static content on servers distributed around the world. This can help significantly reduce latency for users around the world. Option (E), storing your application's static content in Amazon S3, can also help reduce latency. S3 is a high-performance object storage service that can be used to store static content.","timestamp":"1712399040.0","poster":"Digo30sp","upvote_count":"4","comment_id":"1026423"}],"question_id":50,"question_images":[],"exam_id":24,"timestamp":"2023-10-06 12:24:00","topic":"1","unix_timestamp":1696587840,"question_text":"A companyâ€™s website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours.\n\nWhich combination of steps will resolve the latency issue? (Choose two.)","answer_description":"","answer_images":[],"answer":"DE","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/122655-exam-aws-certified-developer-associate-dva-c02-topic-1/","answers_community":["DE (100%)"],"choices":{"B":"Host the application code on AWS Lambda.","D":"Create an Amazon CloudFront distribution to cache the static content.","C":"Scale vertically by resizing the EC2 instances.","A":"Double the Auto Scaling groupâ€™s maximum number of servers.","E":"Store the applicationâ€™s static content in Amazon S3."}}],"exam":{"name":"AWS Certified Developer - Associate DVA-C02","isImplemented":true,"provider":"Amazon","id":24,"isMCOnly":true,"isBeta":false,"lastUpdated":"11 Apr 2025","numberOfQuestions":551},"currentPage":10},"__N_SSP":true}