{"pageProps":{"questions":[{"id":"gGMKP7DlQ8U8TyUFXsSZ","answers_community":["C (69%)","B (22%)","8%"],"answer_images":[],"question_text":"A company operates quick-service restaurants. The restaurants follow a predictable model with high sales traffic for 4 hours daily. Sales traffic is lower outside of those peak hours.\n\nThe point of sale and management platform is deployed in the AWS Cloud and has a backend that is based on Amazon DynamoDB. The database table uses provisioned throughput mode with 100,000 RCUs and 80,000 WCUs to match known peak resource consumption.\n\nThe company wants to reduce its DynamoDB cost and minimize the operational overhead for the IT staff.\n\nWhich solution meets these requirements MOST cost-effectively?","unix_timestamp":1687338180,"answer_ET":"C","choices":{"B":"Change the DynamoDB table to use on-demand capacity.","A":"Reduce the provisioned RCUs and WCUs.","D":"Purchase 1-year reserved capacity that is sufficient to cover the peak load for 4 hours each day.","C":"Enable Dynamo DB auto scaling for the table."},"answer_description":"","question_images":[],"discussion":[{"upvote_count":"8","comments":[{"poster":"helloworldabc","comment_id":"1269823","upvote_count":"1","timestamp":"1724215140.0","content":"just C"},{"upvote_count":"1","timestamp":"1712781600.0","poster":"titi_r","content":"\"C\" is correct, because the question states a \"\n\nYou can use auto scaling to adjust your table’s provisioned capacity automatically in response to traffic changes. Provisioned mode is a good option if any of the following are true:\n- You have PREDICTABLE application traffic.\n\nOn-demand mode is a good option if any of the following are true:\n- You have unpredictable application traffic.\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.OnDemand","comment_id":"1193292"}],"comment_id":"1141209","poster":"saggy4","content":"Selected Answer: B\nThe correct answer is B: On Demand\nAutoscaling with the current RCU and WCU will not make sense since it is defined for peak loads","timestamp":"1707145740.0"},{"poster":"career360guru","timestamp":"1700435520.0","content":"Selected Answer: C\nQuestion itself is bit unclear as it does not state difference in load for peak vs non-peak. Choice of most cost-effective depends on this between Reserved vs on-demands vs autoscaling. Overall autoscaling looks safest option.","upvote_count":"7","comment_id":"1075007"},{"poster":"sammyhaj","comment_id":"1326262","content":"Selected Answer: C\nOn demand is $$$\nprovisioned all the time is $$$\nbut autoscaling works with provisioned to scale write and read when needed","timestamp":"1734129000.0","upvote_count":"1"},{"poster":"0b43291","upvote_count":"1","comment_id":"1309313","timestamp":"1731218340.0","content":"Selected Answer: B\nIf your workload has predictable peak periods and relatively stable traffic patterns during off-peak times, as in the case of the quick-service restaurant scenario, on-demand capacity mode may be more cost-effective and require less operational overhead than Auto Scaling. \n\nOption C (Enabling DynamoDB auto scaling) can help manage capacity during peak periods, but it still requires provisioned capacity and may not be as cost-effective as on-demand capacity mode for workloads with predictable peak periods."},{"timestamp":"1721802060.0","comment_id":"1254164","poster":"vip2","content":"Selected Answer: C\nC is correct one\nDynamoDB auto-scaling for predictable \nDynamoDB on-demand for un-predictable","upvote_count":"2"},{"timestamp":"1720852800.0","comment_id":"1247149","upvote_count":"2","content":"Selected Answer: C\nBy implementing DynamoDB Auto Scaling, you can achieve the following benefits:\n\n Cost savings: During non-peak hours, the provisioned capacity will automatically scale down, reducing the cost of provisioned throughput.\n Consistent performance: During peak hours, the provisioned capacity will automatically scale up to handle the increased workload, ensuring consistent performance.\n Reduced operational overhead: Auto Scaling eliminates the need for manual capacity management, reducing the operational burden on the IT staff.","poster":"mark_232323"},{"poster":"michele_scar","upvote_count":"2","content":"Selected Answer: B\nIf you know that the peak is in the 4hour you can use autoscaling.\nBUT, if you want to reduce operation IT, and if the peak goes higher in other moment, on-demand is the way","comment_id":"1220758","timestamp":"1716969840.0"},{"poster":"titi_r","upvote_count":"2","comment_id":"1193291","timestamp":"1712781540.0","content":"\"C\" is correct, because the question states \"a predictable module\".\n\nYou can use auto scaling to adjust your table’s provisioned capacity automatically in response to traffic changes. Provisioned mode is a good option if any of the following are true:\n- You have PREDICTABLE application traffic.\n\nOn-demand mode is a good option if any of the following are true:\n- You have unpredictable application traffic.\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.OnDemand"},{"timestamp":"1709826720.0","comment_id":"1168147","poster":"Russs99","upvote_count":"2","content":"Selected Answer: C\nC is the correct answer. On Demand is out since it is only fully used for 4 hours daily"},{"content":"Selected Answer: C\nAnswer C:\nhttps://aws.amazon.com/blogs/database/amazon-dynamodb-auto-scaling-performance-and-cost-optimization-at-any-scale/","timestamp":"1705874160.0","comment_id":"1128187","upvote_count":"2","poster":"kejam"},{"poster":"duriselvan","content":"B ia ans\nhttps://dynobase.dev/dynamodb-on-demand-vs-provisioned-scaling/","upvote_count":"1","comment_id":"1098327","timestamp":"1702745220.0"},{"content":"Selected Answer: D\nWhen it's predictable i go for reserved capacity that have up to 77% cost reduction. https://aws.amazon.com/dynamodb/reserved-capacity/. I'll go for D.","upvote_count":"4","comment_id":"993788","timestamp":"1693378920.0","poster":"Arnaud92","comments":[{"poster":"ayadmawla","timestamp":"1702807140.0","comment_id":"1098779","content":"You are right but if you reserve the capacity based on the peak requirement, you only use that capacity for 4 / 24 hours per day. Whilst if you provision to guarantee availability and auto-scale to that level you will save 20 hours of low usage. As @career360guru said, we will need more information as to what that balance of 72% savings on 4 hours would be when compared to provisioned+auto-scaled means for the savings on 20 hours (per day).","upvote_count":"1"}]},{"comment_id":"946102","upvote_count":"3","timestamp":"1688784840.0","content":"Selected Answer: C\nits C for predictable scaling","poster":"NikkyDicky"},{"content":"Selected Answer: C\nC - Autoscaling. \"In addition, you can leverage auto-scaling to adjust the table's capacity based on the application’s utilization, thereby enforcing cost optimization measures. It is a good fit for workloads with predictable traffic. \"\nhttps://www.finout.io/blog/how-to-optimize-usage-and-reduce-dynamodb-pricing","poster":"SkyZeroZx","upvote_count":"5","comment_id":"941379","timestamp":"1688350980.0"},{"poster":"SmileyCloud","upvote_count":"5","content":"Selected Answer: C\nC - Autoscaling. \"In addition, you can leverage auto-scaling to adjust the table's capacity based on the application’s utilization, thereby enforcing cost optimization measures. It is a good fit for workloads with predictable traffic. \"\nhttps://www.finout.io/blog/how-to-optimize-usage-and-reduce-dynamodb-pricing","timestamp":"1687886040.0","comment_id":"935631"},{"upvote_count":"3","timestamp":"1687663680.0","poster":"shree2023","content":"Selected Answer: C\nC is correct answer with predictable pattern auto scaling is good enough and not on demand","comment_id":"933157"},{"content":"C : https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html","upvote_count":"2","timestamp":"1687368720.0","comments":[{"comment_id":"932741","poster":"gd1","upvote_count":"1","content":"C is correct A, B and D do not meet needs.","timestamp":"1687623180.0"}],"comment_id":"929777","poster":"Don2021"},{"poster":"psyx21","content":"Selected Answer: C\nC is the correct Option","comment_id":"929245","upvote_count":"2","timestamp":"1687338180.0"}],"exam_id":33,"question_id":206,"timestamp":"2023-06-21 11:03:00","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/112782-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"C","topic":"1"},{"id":"mF0vJKHZljWYqcqe2aWu","choices":{"D":"Change the concurrency limit of the Lambda functions to lower the API response time.","C":"Use AWS AppSync and leverage WebSockets to deliver comments.","B":"Modify the blog application code to request GET/comments/{commentId} every 10 seconds.","A":"Use edge-optimized API with Amazon CloudFront to cache API responses."},"timestamp":"2023-06-21 11:04:00","answer":"C","question_text":"A company hosts a blog post application on AWS using Amazon API Gateway, Amazon DynamoDB, and AWS Lambda. The application currently does not use API keys to authorize requests. The API model is as follows:\n\nGET /posts/{postId}: to get post details\nGET /users/{userId}: to get user details\nGET /comments/{commentId}: to get comments details\n\nThe company has noticed users are actively discussing topics in the comments section, and the company wants to increase user engagement by making the comments appear in real time.\n\nWhich design should be used to reduce comment latency and improve user experience?","discussion":[{"content":"Selected Answer: C\nOption C (Use AWS AppSync and leverage WebSockets to deliver comments) is the most appropriate solution for real-time comments. AWS AppSync is a fully managed service that simplifies real-time data synchronization and offline capabilities for applications. It supports WebSockets, which enables real-time communication between clients and the server. By leveraging AppSync and WebSockets, the comments can be delivered instantly to users as they are posted, reducing comment latency and improving user engagement.","upvote_count":"8","timestamp":"1703548140.0","poster":"Alabi","comment_id":"933900"},{"comment_id":"946103","timestamp":"1704689820.0","poster":"NikkyDicky","content":"Selected Answer: C\nC. websockets ==realtime","upvote_count":"6"},{"timestamp":"1721592120.0","comment_id":"1128194","upvote_count":"3","poster":"kejam","content":"Selected Answer: C\nAnswer C:\nhttps://docs.aws.amazon.com/appsync/latest/devguide/aws-appsync-real-time-data.html"},{"upvote_count":"1","comment_id":"935634","content":"Selected Answer: C\nC - Correct. https://advancedweb.hu/real-time-data-with-appsync-subscriptions/","poster":"SmileyCloud","timestamp":"1703704620.0"},{"timestamp":"1703482440.0","poster":"shree2023","content":"Selected Answer: C\nC is correct others are not real time and cost effective","comment_id":"933158","upvote_count":"2"},{"upvote_count":"3","content":"Selected Answer: C\nAWS AppSync is a managed service that uses GraphQL to make it easy for applications to get exactly the data they need. With AppSync, you can build scalable applications, including those requiring real-time updates, on a range of data sources such as NoSQL data stores, relational databases, HTTP APIs, and your custom data sources with AWS Lambda.","timestamp":"1703441820.0","comment_id":"932743","poster":"gd1"},{"content":"Selected Answer: C\nCorrect Answer is C","comment_id":"929246","poster":"psyx21","timestamp":"1703156640.0","upvote_count":"1"}],"topic":"1","answer_description":"","exam_id":33,"question_images":[],"answers_community":["C (100%)"],"question_id":207,"unix_timestamp":1687338240,"answer_images":[],"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/112783-exam-aws-certified-solutions-architect-professional-sap-c02/","isMC":true},{"id":"bZdMMWPJWhNAq6FsZLq8","url":"https://www.examtopics.com/discussions/amazon/view/112784-exam-aws-certified-solutions-architect-professional-sap-c02/","answers_community":["B (95%)","5%"],"question_images":[],"isMC":true,"question_text":"A company manages hundreds of AWS accounts centrally in an organization in AWS Organizations. The company recently started to allow product teams to create and manage their own S3 access points in their accounts. The S3 access points can be accessed only within VPCs, not on the internet.\n\nWhat is the MOST operationally efficient way to enforce this requirement?","topic":"1","answer_ET":"B","discussion":[{"upvote_count":"5","poster":"SmileyCloud","comments":[{"upvote_count":"1","poster":"softarts","comment_id":"982540","timestamp":"1692189000.0","content":"don't think there is so called \"S3 access point resource policy\" no matter it is 1 or 100 accounts. it is either identity or bucket resource policy"}],"comment_id":"935641","timestamp":"1687886820.0","content":"Selected Answer: B\nB - Since you have 100s of accounts. If it was a single account, then A.\nhttps://aws.amazon.com/blogs/storage/managing-amazon-s3-access-with-vpc-endpoints-and-s3-access-points/"},{"upvote_count":"1","comment_id":"1107133","poster":"CProgrammer","content":"@duriselvan \"the\" access point \nwhich one bro.. all of them ? ==>\nhundreds of AWS accounts centrally in an organization in AWS Organizations. company recently started to allow product teams to create and manage their own S3 access points in their accounts. \nregarding Minimal impact? was that constraint perhaps from some other question ?\nMOST operationally efficient way to enforce this requirement\nLastly Resource policies inherently apply to actions performed on a specific resource. To control the creation of a resource like an access point, a broader policy mechanism is needed.","timestamp":"1703706480.0"},{"comment_id":"1095321","upvote_count":"1","timestamp":"1702458960.0","poster":"duriselvan","content":"A. Set the S3 access point resource policy to deny the s3:CreateAccessPoint action unless the s3:AccessPointNetworkOrigin condition key evaluates to VPC.\n\nHere's why:\n\nGranularity: Enforcing the restriction within the access point resource policy itself offers the most granular control. It applies directly to the access point creation action, preventing unauthorized configuration at the source.\nCentralized management: Implementing the policy at the access point level allows for centralized management and avoids the need to manage individual IAM policies in each account. This simplifies operation and reduces maintenance overhead.\nMinimal impact: This approach doesn't require additional infrastructure or services like Service Control Policies (SCPs) or CloudFormation StackSets, minimizing setup and complexity."},{"poster":"career360guru","timestamp":"1700436600.0","content":"Selected Answer: B\nAs customer is using Organizations B is right.","upvote_count":"2","comment_id":"1075012"},{"content":"Selected Answer: B\nB. SCP for scale","timestamp":"1688785140.0","upvote_count":"3","poster":"NikkyDicky","comment_id":"946104"},{"content":"Selected Answer: B\nB is correct SCP at Org level","upvote_count":"3","comment_id":"933870","poster":"SkyZeroZx","timestamp":"1687724460.0"},{"timestamp":"1687667280.0","poster":"shree2023","comment_id":"933198","content":"Selected Answer: B\nB is correct SCP at Org level","upvote_count":"3"},{"upvote_count":"2","timestamp":"1687623780.0","content":"Selected Answer: B\nSCP is a type of policy that you can use to manage permissions in your organization, allowing you to control AWS service actions across multiple AWS accounts. By creating the SCP at the root level, you ensure that all accounts within the organization are subjected to this policy. This is an efficient way to enforce the requirement across all accounts as it requires a single policy change instead of individual changes in every account.","comment_id":"932750","poster":"gd1"},{"comment_id":"932425","content":"Selected Answer: B\nB\nwhen the question mention AWS Organizations, use SCP always the good choice.","upvote_count":"2","timestamp":"1687601280.0","poster":"PhuocT"},{"timestamp":"1687528560.0","upvote_count":"1","poster":"MoussaNoussa","comment_id":"931674","content":"of course answer B"},{"upvote_count":"2","poster":"Don2021","content":"B - This approach ensures centralized policy management and consistent enforcement across all AWS accounts within the organization. It avoids the need for configuring bucket policies or access point resource policies in each individual account, making it operationally efficient.","timestamp":"1687369920.0","comment_id":"929792"},{"comment_id":"929247","timestamp":"1687338300.0","upvote_count":"1","poster":"psyx21","comments":[{"content":"just B","timestamp":"1724215320.0","comment_id":"1269824","poster":"helloworldabc","upvote_count":"1"},{"poster":"rxhan","timestamp":"1690832820.0","content":"yeah be careful, you skewing the numbers on the vote, we are trying to help others.","comment_id":"968462","upvote_count":"4"},{"content":"you always provided wrong answer, not sure if you do that on purpose.","upvote_count":"10","timestamp":"1687601220.0","comment_id":"932424","poster":"PhuocT"},{"comment_id":"933901","content":"Why do you always provide wrong answers? Please do your research before making a comment, as you re misleading others","upvote_count":"7","timestamp":"1687729980.0","poster":"Alabi"}],"content":"Selected Answer: A\nCorrect Answer is A"}],"question_id":208,"answer_description":"","answer_images":[],"exam_id":33,"answer":"B","unix_timestamp":1687338300,"choices":{"B":"Create an SCP at the root level in the organization to deny the s3:CreateAccessPoint action unless the s3:AccessPointNetworkOrigin condition key evaluates to VPC.","C":"Use AWS CloudFormation StackSets to create a new IAM policy in each AWS account that allows the s3:CreateAccessPoint action only if the s3:AccessPointNetworkOrigin condition key evaluates to VPC.","D":"Set the S3 bucket policy to deny the s3:CreateAccessPoint action unless the s3:AccessPointNetworkOrigin condition key evaluates to VPC.","A":"Set the S3 access point resource policy to deny the s3:CreateAccessPoint action unless the s3:AccessPointNetworkOrigin condition key evaluates to VPC."},"timestamp":"2023-06-21 11:05:00"},{"id":"LGSn3o42MUC0nLOcNWim","exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/112785-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_description":"","answer_ET":"B","topic":"1","answer_images":[],"answer":"B","answers_community":["B (100%)"],"discussion":[{"comment_id":"932754","upvote_count":"10","poster":"gd1","timestamp":"1703442360.0","content":"Selected Answer: B\nAWS Elastic Beanstalk provides a Swap Environment URLs option for performing a blue/green deployment. This operation swaps the CNAME records of two environments, thus rerouting traffic from the original environment (blue) to the new environment (green)."},{"poster":"duriselvan","upvote_count":"3","content":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html","comment_id":"1098352","timestamp":"1718551980.0"},{"timestamp":"1716154500.0","poster":"career360guru","comment_id":"1075013","upvote_count":"3","content":"Selected Answer: B\nOption B."},{"timestamp":"1705800660.0","comment_id":"957946","upvote_count":"1","poster":"ggrodskiy","content":"Correct B."},{"poster":"NikkyDicky","upvote_count":"2","content":"Selected Answer: B\nits a B","comment_id":"946105","timestamp":"1704690000.0"},{"timestamp":"1703710620.0","poster":"Jonalb","comment_id":"935743","upvote_count":"2","content":"Selected Answer: B\nB\n\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html"},{"poster":"SmileyCloud","content":"Selected Answer: B\nB - Look at the link, step 5 -> https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html","comment_id":"935645","upvote_count":"2","timestamp":"1703705400.0"},{"comment_id":"933872","content":"Selected Answer: B\nB. Select the Swap Environment URLs option.","poster":"SkyZeroZx","upvote_count":"2","timestamp":"1703543100.0"},{"poster":"shree2023","timestamp":"1703486760.0","content":"Selected Answer: B\nB to swap from blue to green","comment_id":"933210","upvote_count":"1"},{"comment_id":"931976","poster":"bhanus","timestamp":"1703376120.0","content":"Selected Answer: B\nB elastic beanstalk has Swap Environment URLs feature\nhttps://docs.aws.amazon.com/whitepapers/latest/blue-green-deployments/swap-the-environment-of-an-elastic-beanstalk-application.html","upvote_count":"2"},{"timestamp":"1703347140.0","poster":"MoussaNoussa","comment_id":"931677","content":"B of course","upvote_count":"1"},{"comment_id":"929249","upvote_count":"1","content":"Selected Answer: B\nCorrect Answer is B","poster":"psyx21","timestamp":"1703156760.0"}],"choices":{"A":"Redirect to the new environment using Amazon Route 53.","C":"Replace the Auto Scaling launch configuration.","D":"Update the DNS records to point to the green environment.","B":"Select the Swap Environment URLs option."},"isMC":true,"question_text":"A solutions architect must update an application environment within AWS Elastic Beanstalk using a blue/green deployment methodology. The solutions architect creates an environment that is identical to the existing application environment and deploys the application to the new environment.\n\nWhat should be done next to complete the update?","unix_timestamp":1687338360,"question_id":209,"timestamp":"2023-06-21 11:06:00","question_images":[]},{"id":"OJj7ztKEjvOwzQQxZiMp","choices":{"C":"Store the uploaded images in an Amazon S3 bucket and configure an S3 bucket event notification to send a message to the Amazon Simple Queue Service (Amazon SQS) queue. Create a fleet of Amazon EC2 instances to pull messages from the SQS queue to process the images and place them in another S3 bucket. Use Amazon CloudWatch metrics for queue depth to scale out EC2 instances. Enable Amazon CloudFront and configure the origin to be the S3 bucket that contains the processed images.","B":"Store the uploaded images in an Amazon S3 bucket and configure an S3 bucket event notification to send a message to Amazon Simple Notification Service (Amazon SNS). Create a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB) to pull messages from Amazon SNS to process the images and place them in Amazon Elastic File System (Amazon EFS). Use Amazon CloudWatch metrics for the SNS message volume to scale out EC2 instances. Enable Amazon CloudFront and configure the origin to be the ALB in front of the EC2 instances.","D":"Store the uploaded images on a shared Amazon Elastic Block Store (Amazon EBS) volume mounted to a fleet of Amazon EC2 Spot instances. Create an Amazon DynamoDB table that contains information about each uploaded image and whether it has been processed. Use an Amazon EventBridge rule to scale out EC2 instances. Enable Amazon CloudFront and configure the origin to reference an Elastic Load Balancer in front of the fleet of EC2 instances.","A":"Store the uploaded images in Amazon Elastic File System (Amazon EFS). Send application log information about each image to Amazon CloudWatch Logs. Create a fleet of Amazon EC2 instances that use CloudWatch Logs to determine which images need to be processed. Place processed images in another directory in Amazon EFS. Enable Amazon CloudFront and configure the origin to be the one of the EC2 instances in the fleet."},"exam_id":33,"topic":"1","question_id":210,"answers_community":["C (100%)"],"discussion":[{"comment_id":"933903","upvote_count":"5","content":"Selected Answer: C\nOption C (Store the uploaded images in an S3 bucket and use S3 event notification with SQS queue) is the most suitable design. Amazon S3 provides highly scalable and durable storage for the uploaded images. Configuring S3 event notifications to send messages to an SQS queue allows for decoupling the processing of images from the upload process. A fleet of EC2 instances can pull messages from the SQS queue to process the images and store them in another S3 bucket. Scaling out the EC2 instances based on SQS queue depth using CloudWatch metrics ensures efficient utilization of resources. Enabling Amazon CloudFront with the origin set to the S3 bucket containing the processed images improves the global availability and performance of image delivery.","timestamp":"1719352620.0","poster":"Alabi"},{"poster":"nexus2020","comment_id":"934530","timestamp":"1719410460.0","upvote_count":"5","content":"Selected Answer: C\nALB – B is out\nS3 is good enough, EFS and EBS are too much for image processing"},{"poster":"career360guru","content":"Selected Answer: C\nOption C","timestamp":"1732059540.0","comment_id":"1075014","upvote_count":"1"},{"timestamp":"1721518140.0","comment_id":"957945","upvote_count":"1","content":"Correct C.","poster":"ggrodskiy"},{"timestamp":"1720407720.0","comment_id":"946106","content":"Selected Answer: C\nits a C","upvote_count":"1","poster":"NikkyDicky"},{"timestamp":"1719509640.0","upvote_count":"4","poster":"SmileyCloud","comment_id":"935649","content":"Selected Answer: C\nC - no doubt, SQS and CloudFront for processed image retrieval"},{"content":"Selected Answer: C\nC without doubt","timestamp":"1719347400.0","upvote_count":"1","comment_id":"933877","poster":"SkyZeroZx"},{"poster":"shree2023","timestamp":"1719292080.0","content":"Selected Answer: C\nC indeed","upvote_count":"1","comment_id":"933225"},{"upvote_count":"2","comment_id":"931680","content":"C without doubt","poster":"MoussaNoussa","timestamp":"1719151260.0"},{"comment_id":"929250","upvote_count":"1","poster":"psyx21","content":"Selected Answer: C\nCorrect Answer is C","timestamp":"1718960820.0"}],"isMC":true,"question_text":"A company is building an image service on the web that will allow users to upload and search random photos. At peak usage, up to 10,000 users worldwide will upload their images. The will then overlay text on the uploaded images, which will then be published on the company website.\n\nWhich design should a solutions architect implement?","timestamp":"2023-06-21 11:07:00","answer_images":[],"answer":"C","question_images":[],"answer_description":"","unix_timestamp":1687338420,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/112786-exam-aws-certified-solutions-architect-professional-sap-c02/"}],"exam":{"numberOfQuestions":529,"isBeta":false,"name":"AWS Certified Solutions Architect - Professional SAP-C02","id":33,"provider":"Amazon","isMCOnly":true,"isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":42},"__N_SSP":true}