{"pageProps":{"questions":[{"id":"oVeGjnMWSS2IsYajl6ZI","url":"https://www.examtopics.com/discussions/amazon/view/88848-exam-aws-devops-engineer-professional-topic-1-question-92/","unix_timestamp":1669463100,"answer_description":"","question_images":[],"discussion":[{"upvote_count":"2","comment_id":"956634","timestamp":"1689770940.0","content":"Selected Answer: D\nPretty sure B would work, but D is the most sustainable solution.","poster":"BlissfulCheetah"},{"upvote_count":"1","content":"Correct answer is D.\nAll options can work but the key part of the question is finding the solution that will be the MOST maintainable. AWS CodeBuild provides a fully managed build service which eliminates the need to set up, patch, and maintain your own build servers, which Jenkins on Amazon EC2 requires. AWS CodeBuild is essentially a \"serverless\" build service, where you only pay for the build time you use, and it scales automatically to meet the needs of your builds.\n\nCodeBuild also has built-in support for producing encrypted build artifacts. This would satisfy the compliance officer's request for encrypting build artifacts containing intellectual property. By managing both the build process and artifact encryption within a single service, the solution remains simple and maintainable.","timestamp":"1689200520.0","poster":"buiquangbk90","comment_id":"950220"},{"content":"Selected Answer: B\nCorrect answer is B...\ncontainerized ::: ECS would be the best and most maintainable..\nWe don't have to replace jenkins, company is already using jenkins man..","poster":"bakamon","comment_id":"924788","upvote_count":"2","timestamp":"1686881040.0"},{"timestamp":"1678932900.0","content":"B \ndeploying Jenkins to an Amazon ECS cluster and copying build artifacts to an Amazon S3 bucket with default encryption enabled provides a straightforward solution that aligns with the current workflow and requires minimal changes. This option provides a more maintainable solution that satisfies the compliance officer's request for encrypting build artifacts.","upvote_count":"1","comment_id":"840504","poster":"easytoo"},{"poster":"Bulti","timestamp":"1674433800.0","comment_id":"784820","content":"Selected Answer: D\nD is the correct answer.","upvote_count":"3"},{"content":"B = \" MOST maintainable manner\"","timestamp":"1673629980.0","upvote_count":"1","poster":"[Removed]","comment_id":"774704","comments":[{"comment_id":"803067","content":"Jenkins gets all of the intellectual properties.","poster":"Piccaso","timestamp":"1675937580.0","upvote_count":"1"},{"comment_id":"829187","poster":"bgc1","upvote_count":"1","timestamp":"1677950760.0","content":"A and B rely on out of box encryption at rest but the requirement is to encrypt the artifact from client side before storing it. D covers this scenario."}]},{"comment_id":"735650","timestamp":"1670213580.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/codebuild/latest/userguide/security-encryption.html","poster":"Maygam","upvote_count":"3"},{"comment_id":"732273","timestamp":"1669871580.0","poster":"SmileyCloud","content":"Selected Answer: D\nD is the correct answer.","upvote_count":"1"},{"content":"Selected Answer: D\nBuild artifact encryption - CodeBuild requires access to an AWS KMS CMK in order to encrypt its build output artifacts. By default, CodeBuild uses an AWS Key Management Service CMK for Amazon S3 in your AWS account. If you do not want to use this CMK, you must create and configure a customer-managed CMK.","upvote_count":"3","timestamp":"1669463100.0","poster":"adozoo","comment_id":"727481"}],"topic":"1","choices":{"B":"Deploy Jenkins to an Amazon ECS cluster and copy build artifacts to an Amazon S3 bucket with default encryption enabled.","A":"Automate patching and upgrading using AWS Systems Manager on EC2 instances and encrypt Amazon EBS volumes by default.","D":"Use AWS CodeBuild with artifact encryption to replace the Jenkins instance running on Amazon EC2.","C":"Leverage AWS CodePipeline with a build action and encrypt the artifacts using AWS Secrets Manager."},"answer_ET":"D","answer_images":[],"timestamp":"2022-11-26 12:45:00","answers_community":["D (86%)","14%"],"question_id":201,"answer":"D","exam_id":35,"question_text":"A company has containerized all of its in-house quality control applications. The company is running Jenkins on Amazon EC2, which requires patching and upgrading. The compliance officer has requested a DevOps engineer begin encrypting build artifacts since they contain company intellectual property.\n\nWhat should the DevOps engineer do to accomplish this in the MOST maintainable manner?","isMC":true},{"id":"l7iYoVkNqHXFVFTRwjys","answers_community":["D (89%)","11%"],"answer_images":[],"answer":"D","timestamp":"2022-11-26 12:52:00","exam_id":35,"question_text":"A production account has a requirement that any Amazon EC2 instance that has been logged into manually must be terminated within 24 hours. All applications in the production account are using Auto Scaling groups with Amazon CloudWatch Logs agent configured.\n\nHow can this process be automated?","unix_timestamp":1669463520,"discussion":[{"timestamp":"1669872300.0","poster":"SmileyCloud","upvote_count":"5","comment_id":"732280","comments":[{"timestamp":"1673630400.0","comment_id":"774712","comments":[{"comment_id":"829200","upvote_count":"1","timestamp":"1677951360.0","content":"also could not find step functions as an option for cw log subscription filter target - https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters.html","poster":"bgc1"},{"upvote_count":"1","poster":"bgc1","comment_id":"829197","timestamp":"1677951180.0","content":"I could not find CW logs in this list - https://docs.aws.amazon.com/step-functions/latest/dg/concepts-invoke-sfn.html"}],"content":"Yes D seems to be a more direct approach but it is possible to create a log subscription to an AWS Step Functions application. CloudWatch Logs can be configured to send log data to a Step Functions state machine, which can then be used to process the log data and perform various actions based on the contents of the log data","upvote_count":"1","poster":"[Removed]"}],"content":"Selected Answer: D\nA - You can't create a log subscription to AWS Step Function. Only OpenSearch, Kinesis, Kinesis Firehouse and Lambda.\nB - is a manual process. It needs to be automated.\nC - Too complex. Architecture doesn't make any sense.\nD - Correct."},{"upvote_count":"1","comment_id":"924810","content":"Selected Answer: D\nwhenever you have to terminate instances, prefer using tags.. so option D is correct","poster":"bakamon","timestamp":"1686883380.0"},{"poster":"spikeme","comment_id":"892527","upvote_count":"1","timestamp":"1683582300.0","content":"Agree D"},{"poster":"Piccaso","content":"Selected Answer: B\nB is the most AWS-managed option","comment_id":"803096","upvote_count":"1","timestamp":"1675939320.0"},{"comment_id":"784824","timestamp":"1674434160.0","content":"D is the correct answer. A is an overkill, B is not automated and C idoesnt make any sense as it does not address how EC2 instances will be terminated.","upvote_count":"1","poster":"Bulti"},{"content":"DDDDDDDDDDDDDDD","poster":"Imstack","timestamp":"1671785880.0","comment_id":"754063","upvote_count":"1"},{"comment_id":"727484","content":"Selected Answer: D\nDoes CloudWatch alarm that will trigger on the login event have such an event?Step function it s use to step like batch exe,just two lambda.no needed","poster":"adozoo","upvote_count":"2","timestamp":"1669463520.0"}],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/88849-exam-aws-devops-engineer-professional-topic-1-question-93/","question_images":[],"topic":"1","question_id":202,"choices":{"A":"Create a CloudWatch Logs subscription to an AWS Step Functions application. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Then create a CloudWatch Events rule to trigger a second AWS Lambda function once a day that will terminate all instances with this tag.","C":"Create a CloudWatch alarm that will trigger on the login event. Configure the alarm to send to an Amazon SQS queue. Use a group of worker instances to process messages from the queue, which then schedules the Amazon CloudWatch Events rule to trigger.","B":"Create a CloudWatch alarm that will trigger on the login event. Send the notification to an Amazon SNS topic that the operations team is subscribed to, and have them terminate the EC2 instance within 24 hours.","D":"Create a CloudWatch Logs subscription in an AWS Lambda function. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Create a CloudWatch Events rule to trigger a daily Lambda function that terminates all instances with this tag."},"answer_ET":"D","answer_description":""},{"id":"sJDvDqmWUrlZh4E8GGMA","answer_ET":"A","topic":"1","exam_id":35,"answers_community":["A (69%)","B (23%)","8%"],"url":"https://www.examtopics.com/discussions/amazon/view/88850-exam-aws-devops-engineer-professional-topic-1-question-94/","choices":{"C":"Use an Auto Scaling lifecycle hook to verify that the previous instance is operational before allowing the DevOps engineer's selected instance to terminate.","A":"Update the CloudFormation template to include the UpdatePolicy attribute with the AutoScalingRollingUpdate policy.","D":"Use an Auto Scaling lifecycle hook to confirm there are at least four running instances before allowing the DevOps engineer's selected instance to terminate.","B":"Update the CloudFormation template to include the UpdatePolicy attribute with the AutoScalingReplacingUpdate policy."},"answer_description":"","unix_timestamp":1669464060,"answer_images":[],"answer":"A","question_id":203,"question_text":"A company's application is running on Amazon EC2 instances in an Auto Scaling group. A DevOps engineer needs to ensure there are at least four application servers running at all times. Whenever an update has to be made to the application, the engineer creates a new AMI with the updated configuration and updates the AWS CloudFormation template with the new AMI ID. After the stack update finishes, the engineer manually terminates the old instances one by one, verifying that the new instance is operational before proceeding. The engineer needs to automate this process.\n\nWhich action will allow for the LEAST number of manual steps moving forward?","discussion":[{"timestamp":"1681460520.0","poster":"daheck","upvote_count":"2","content":"Selected Answer: A\nhttps://repost.aws/knowledge-center/auto-scaling-group-rolling-updates\n\nOption B is incorrect because the AutoScalingReplacingUpdate policy terminates all instances in the Auto Scaling group simultaneously and creates new instances, which does not satisfy the requirement of having at least four application servers running at all times.","comment_id":"870060"},{"comment_id":"840508","upvote_count":"2","poster":"easytoo","timestamp":"1678933260.0","content":"its A like for Apple."},{"upvote_count":"2","timestamp":"1677535020.0","content":"Selected Answer: A\nA is correct\n\nAutoscaling Rolling Update:\n\nAutoscaling Rolling Update is a mechanism that allows for updates to be applied to instances in an autoscaling group in a rolling fashion. This means that a few instances are taken down at a time, updated, and then brought back up before the next set of instances are taken down. This process continues until all instances have been updated. Autoscaling Rolling Update helps to ensure that there is no downtime and that the application remains available throughout the update process.\n\nAutoscaling Replacing Update:\n\nAutoscaling Replacing Update is a mechanism that replaces the entire set of instances in an autoscaling group with new instances. Unlike Autoscaling Rolling Update, this method takes down all the old instances at once and replaces them with new instances. Autoscaling Replacing Update is faster than Autoscaling Rolling Update since it replaces all instances at once, but there is a period of downtime during the update process.","poster":"devopsbro","comment_id":"824188"},{"timestamp":"1676824560.0","poster":"Piccaso","comments":[{"upvote_count":"6","poster":"AkaAka4","timestamp":"1680191280.0","comment_id":"855928","content":"Please think twice before you comment, so that people won't get confused by all your comments..."}],"upvote_count":"1","content":"Selected Answer: B\nOnly B satisfies the scenario: \"After the stack update finishes, the engineer manually terminates the old instances one by one, verifying that the new instance is operational before proceeding. \"\n https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatepolicy.html#cfn-attributes-updatepolicy-replacingupdate","comment_id":"814266"},{"upvote_count":"1","timestamp":"1675939800.0","content":"Selected Answer: D\nBoth A and B cannot guarantee that \"at least four application servers running at all times\".\nC is involved by D.","poster":"Piccaso","comments":[{"timestamp":"1675939860.0","content":"I changed my mind from D to A because of comment of adozoo","comment_id":"803103","poster":"Piccaso","upvote_count":"1"}],"comment_id":"803101"},{"comment_id":"803019","content":"Selected Answer: B\nB - correct (in my opinion) - requirement: LEAST number of manual steps moving forward\nSolution: use AutoScalingReplacingUpdate policy and set\n\"AutoScalingReplacingUpdate\" : {\n \"WillReplace\" : \"true\"\n}\nThe AutoScalingReplacingUpdate will be terminating instances ONLY after new instances are available and stable. \nA - also correct to some extent but the potential problem is related to roll back - with the rolling update you have to take care of auto scaling group configuration\nNote: If an unexpected scaling action changes the state of the Auto Scaling group during a rolling update, the update can fail. The failure can result from an inconsistent view of the Auto Scaling group by AWS CloudFormation.","timestamp":"1675933500.0","upvote_count":"2","poster":"DerekKey"},{"upvote_count":"1","comment_id":"784838","poster":"Bulti","content":"Selected Answer: A\nA is correct because of the ability to specify MinInstanceInService attributes on the autoscalinggroup update policy.","comments":[{"upvote_count":"1","comment_id":"796676","timestamp":"1675393980.0","content":"I think the answer is B not A. With AutoScalingReplacing updatePolicy we specify whether an Auto Scaling group and the instances it contains are replaced during an update. During replacement, CloudFormation retains the old group ( 4 instances that were originally present) until it finishes creating the new one. If the update fails, CloudFormation can roll back to the old Auto Scaling group and delete the new Auto Scaling group.\n\nWhile CloudFormation creates the new group, it doesn't detach or attach any instances. After successfully creating the new Auto Scaling group, CloudFormation deletes the old Auto Scaling group during the cleanup process.","poster":"Bulti"}],"timestamp":"1674436320.0"},{"poster":"Imstack","comment_id":"754069","upvote_count":"1","content":"AAAAAAAAAAAAAA","timestamp":"1671786300.0"},{"timestamp":"1669464060.0","comment_id":"727492","content":"Selected Answer: A\nFor rolling updates, you can specify whether AWS CloudFormation updates the instances in the Auto Scaling group in batches, or all instances at once.","poster":"adozoo","upvote_count":"4"}],"timestamp":"2022-11-26 13:01:00","isMC":true,"question_images":[]},{"id":"zoSs2L30Qi9wEu1rG3gF","question_text":"A company using AWS CodeCommit for source control wants to automate its continuous integration and continuous delivery pipeline on AWS in its development environment. The company has three requirements:\n\n1. There must be a legal and a security review of any code change to make sure sensitive information is not leaked through the source code.\n2. Every change must go through unit testing.\n3. Every change must go through a suite of functional testing to ensure functionality.\n\nIn addition, the company has the following requirements for automation:\n\n1. Code changes should automatically trigger the CI/CD pipeline.\n2. Any failure in the pipeline should notify devops-admin@xyz.com.\n3. There must be an approval to stage the assets to Amazon S3 after tests have been performed.\n\nWhat should a DevOps Engineer do to meet all of these requirements while following Cl/CD best practices?","answer_images":[],"isMC":true,"answers_community":["C (100%)"],"answer_ET":"C","topic":"1","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/89782-exam-aws-devops-engineer-professional-topic-1-question-95/","exam_id":35,"answer":"C","question_id":204,"question_images":[],"choices":{"B":"Commit to mainline and trigger AWS CodePipeline from mainline. Make an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval. Use AWS CloudTrail logs to detect changes in pipeline stages and Amazon SNS for emailing devops-admin@xyz.com.","D":"Commit to mainline and trigger AWS CodePipeline from mainline. Make an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval. Use Amazon CloudWatch Events to detect changes in pipeline stages and Amazon SES for emailing devops-admin@xyz.com.","A":"Commit to the development branch and trigger AWS CodePipeline from the development branch. Make an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval. Use Amazon CloudWatch metrics to detect changes in pipeline stages and Amazon SES for emailing devops-admin@xyz.com.","C":"Commit to the development branch and trigger AWS CodePipeline from the development branch. Make an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval. Use Amazon CloudWatch Events to detect changes in pipeline stages and Amazon SNS for emailing devops-admin@xyz.com."},"discussion":[{"content":"Selected Answer: C\nAlways Commit to the development branch not on mainline and trigger AWS CodePipeline from the development branch. \nMake an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval.\nAmazon CloudWatch Events to detect changes in pipeline \"CodePipeline Stage Execution State Change\" and Target a Amazon SNS topic.","timestamp":"1669982700.0","comment_id":"733703","upvote_count":"6","poster":"nsvijay04b1"},{"timestamp":"1679428260.0","upvote_count":"1","content":"c-c-c-c-c-c-c--c-c-c-","comment_id":"846289","poster":"easytoo"},{"content":"Selected Answer: C\nB and D: what is \"from mainline\" ?\nA: CloudWatch metrics does not help to detect changes in pipeline stages","poster":"Piccaso","upvote_count":"2","comment_id":"803124","timestamp":"1675941060.0"},{"content":"Selected Answer: C\nC is correct.","poster":"Bulti","comment_id":"784841","upvote_count":"2","timestamp":"1674437040.0"},{"comment_id":"754071","upvote_count":"1","content":"CCCCCCCCCCCCCCCCCCCCCCCC","poster":"Imstack","timestamp":"1671786480.0"},{"comment_id":"746011","content":"Selected Answer: C\nA and D - SES instead of SNS\nB - Cloudtrail does not logs for failed pipeline runs\nC - is the correct answer, SNS for email and Cloudwatch Events for failed triggers","timestamp":"1671104340.0","poster":"saggy4","upvote_count":"2"}],"timestamp":"2022-12-02 13:05:00","unix_timestamp":1669982700},{"id":"KcVE2zIW7AALbyafScyE","unix_timestamp":1669464480,"isMC":true,"discussion":[{"poster":"merki","comment_id":"860044","timestamp":"1680533340.0","content":"Selected Answer: C\nChatgpt said: C. The MOST secure solution to correct this issue would be to remove unauthenticated access from the S3 bucket with a bucket policy and use the AWS CLI to download the database population script using temporary security credentials obtained through an IAM role attached to the CodeBuild project.\n\nOption C partially addresses this by removing unauthenticated access from the S3 bucket and modifying the service role for the CodeBuild project to include Amazon S3 access. However, it does not address the need for secure access to the S3 bucket using temporary security credentials obtained through an IAM role attached to the CodeBuild project.\nTherefore, the correct answer is C with the addition of using temporary security credentials obtained through an IAM role attached to the CodeBuild project to access the S3 bucket.","upvote_count":"1"},{"upvote_count":"1","comment_id":"845700","timestamp":"1679390040.0","poster":"Netcom1999","content":"C Is the correct answer with this assessment you will get free access https://www.netcomlearning.com/en-us/assessment/36703/devops-engineering-aws.html?advid=1356"},{"timestamp":"1679360880.0","upvote_count":"1","poster":"easytoo","content":"C is the way.","comment_id":"845422"},{"poster":"Bulti","upvote_count":"4","content":"Selected Answer: C\nC is correct. IAM role is a better practice than using IAM access key and secret access key.","comment_id":"784885","timestamp":"1674441780.0"},{"poster":"[Removed]","content":"D is the correct answer.Option C is also a secure way to correct the issue.However, using an IAM access key and secret access key in addition to modifying the service role for the CodeBuild project is a more secure way to ensure that the CodeBuild project has the necessary permissions to access the S3 bucket.","comment_id":"775050","upvote_count":"1","timestamp":"1673664900.0"},{"comment_id":"754074","upvote_count":"1","timestamp":"1671786660.0","poster":"Imstack","content":"CCCCCCCCCCCCCCCCCC"},{"comment_id":"743809","poster":"Kapello10","timestamp":"1670923380.0","content":"B is the correct answer","upvote_count":"1"},{"timestamp":"1669873320.0","upvote_count":"4","content":"Selected Answer: C\nC is correct. You need a role to access other AWS services.\n\nhttps://docs.aws.amazon.com/codebuild/latest/userguide/setting-up.html#setting-up-service-role","poster":"SmileyCloud","comment_id":"732288"},{"poster":"adozoo","comment_id":"727498","content":"Selected Answer: C\nbest practices","timestamp":"1669464480.0","upvote_count":"2"}],"question_images":[],"question_id":205,"question_text":"A security review has identified that an AWS CodeBuild project is downloading a database population script from an Amazon S3 bucket using an unauthenticated request. The security team does not allow unauthenticated requests to S3 buckets for this project.\n\nHow can this issue be corrected in the MOST secure manner?","url":"https://www.examtopics.com/discussions/amazon/view/88854-exam-aws-devops-engineer-professional-topic-1-question-96/","answer_ET":"C","topic":"1","timestamp":"2022-11-26 13:08:00","choices":{"B":"Modify the S3 bucket settings to enable HTTPS basic authentication and specify a token. Update the build spec to use cURL to pass the token and download the database population script.","D":"Remove unauthenticated access from the S3 bucket with a bucket policy. Use the AWS CLI to download the database population script using an IAM access key and a secret access key.","C":"Remove unauthenticated access from the S3 bucket with a bucket policy. Modify the service role for the CodeBuild project to include Amazon S3 access. Use the AWS CLI to download the database population script.","A":"Add the bucket name to the AllowedBuckets section of the CodeBuild project settings. Update the build spec to use the AWS CLI to download the database population script."},"answer_images":[],"answer":"C","answer_description":"","exam_id":35,"answers_community":["C (100%)"]}],"exam":{"numberOfQuestions":208,"name":"AWS DevOps Engineer Professional","isMCOnly":false,"isBeta":false,"isImplemented":true,"id":35,"lastUpdated":"11 Apr 2025","provider":"Amazon"},"currentPage":41},"__N_SSP":true}