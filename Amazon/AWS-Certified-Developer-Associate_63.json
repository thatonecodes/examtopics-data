{"pageProps":{"questions":[{"id":"nzqjzGThjaNo5OsVgU3G","topic":"1","isMC":true,"choices":{"D":"Add an SSM parameter to the CloudFormation template that resolves the RDS DB cluster endpoint value at deployment time by using the ssm dynamic reference. Update the Lambda function resource in CloudFormation to create an environment variable that references the newly created SSM parameter.","A":"Move the code that is reading the SSM parameter value outside the Lambda function handler. Store the RDS DB cluster endpoint value in a global variable. Use the endpoint value inside the Lambda function handler.","B":"Move the code that is reading the SSM parameter value outside the Lambda function handler. Store the RDS DB cluster endpoint value in an environment variable. Use the endpoint value inside the Lambda function handler.","C":"Request a service quota increase for the Systems Manager GetParameter rate quota value to match the Lambda function's concurrency."},"answer_ET":"D","question_id":311,"unix_timestamp":1674364740,"answer_images":[],"exam_id":25,"answer_description":"","question_text":"A company’s infrastructure team is using AWS CloudFormation to deploy common infrastructure resources such as VPCs, subnets, Amazon RDS DB cluster endpoints, and Amazon DynamoDB tables for other teams to use. The CloudFormation templates also create AWS Systems Manager Parameter Store parameters to store information about these resources for application developers. The parameters include elements such as RDS DB cluster endpoints for clusters that the templates create.\n\nA developer creates a CloudFormation template that includes an AWS Lambda function that reads the SSM parameter value to access RDS DB cluster endpoints. The Lambda function has reserved concurrency configured to match the value of the Parameter Store maximum throughput (transactions per second) quota for the account and the AWS Region that hosts the account.\n\nThe developer wants to prepare for a potential load increase. The developer expects the Lambda function’s concurrent invocation rate to be two times more than the Parameter Store maximum throughput quota value.\n\nWhich solution will prepare for the load increase MOST cost-effectively?","timestamp":"2023-01-22 06:19:00","answer":"D","answers_community":["D (55%)","B (25%)","A (20%)"],"url":"https://www.examtopics.com/discussions/amazon/view/96423-exam-aws-certified-developer-associate-topic-1-question-379/","discussion":[{"upvote_count":"7","comment_id":"788491","timestamp":"1674718860.0","content":"Selected Answer: D\n. Add an SSM parameter to the CloudFormation template that resolves the RDS DB cluster endpoint value at deployment time by using the ssm dynamic reference. Update the Lambda function resource in CloudFormation to create an environment variable that references the newly created SSM parameter. This solution will prepare for the load increase most cost-effectively because it eliminates the need to make a request for a service quota increase and it ensures that the SSM parameter is resolved at deployment time, reducing the number of SSM calls made by the Lambda function.","poster":"JagpreetLM10"},{"comment_id":"905713","upvote_count":"1","poster":"pranay_2406","content":"Selected Answer: B\nIt's B\nBy storing the RDS DB cluster endpoint value in an environment variable, you can avoid making repeated calls to the Systems Manager Parameter Store (SSM) within the Lambda function handler. Instead, the Lambda function can retrieve the value once during initialization and store it in memory, reducing the overhead of additional API calls.\n\nHere's how the solution would work:\n\nRetrieve the RDS DB cluster endpoint value from the SSM Parameter Store outside the Lambda function handler, preferably during the initialization phase of the Lambda function.\nStore the retrieved value in an environment variable.\nAccess the environment variable within the Lambda function handler to use the RDS DB cluster endpoint value.\nBy following this approach, the Lambda function can reuse the stored value from the environment variable for subsequent invocations, eliminating the need to make additional API calls to the SSM Parameter Store.","comments":[{"comment_id":"905714","upvote_count":"1","timestamp":"1684920600.0","poster":"pranay_2406","content":"Option A is not recommended because storing the RDS DB cluster endpoint value in a global variable within the Lambda function handler may not persist across different invocations, leading to unnecessary API calls to the SSM Parameter Store.\n\nOption C is not necessary in this scenario. Requesting a service quota increase for the Systems Manager GetParameter rate quota is not required since the Lambda function's concurrency can be managed independently.\n\nOption D introduces unnecessary complexity. While using an SSM parameter in the CloudFormation template and referencing it in the Lambda function's environment variable is possible, it adds extra steps and dependencies, which are not needed when a simple environment variable can fulfill the requirement."}],"timestamp":"1684920540.0"},{"poster":"sdafadsfa","content":"Selected Answer: B\nthis is the answer","comment_id":"854050","upvote_count":"1","timestamp":"1680069000.0"},{"content":"Selected Answer: B\nTentatively changing my mind to B. The question seems assuming buggy code to begin with, and worrying about lambda making too many calls to parameter store. So it calls SSM store outside handler, set env variables, and read it from inside handler. Although this has a serious flaw, as it implies trying to initialize RDS using the endpoint value, from inside the handler.\n\nFor the alternatives, B: variables set outside handler is global in scope, but not sure if we can call it global variables; D: seems lock down db info at deployment time, that seems defeat the purpose of SSM","upvote_count":"1","comment_id":"809485","poster":"tieyua","comments":[{"comment_id":"809490","timestamp":"1676464200.0","poster":"tieyua","content":"Sorry, I mean \"For the alternatives, A: ...\"","upvote_count":"1"}],"timestamp":"1676464020.0"},{"content":"Selected Answer: A\nA makes sense. After retrieving the endpoint value from SSM, we need to store it in a global variable. Lambda environment variables are not suitable in this case, as we wouldn't need to get it from SSM if we wanted to use the environment variables anyway.","upvote_count":"2","comments":[{"poster":"tieyua","upvote_count":"1","content":"Can you call a variable declared outside handler \"global variable\"? I can't find any reference to that.","comment_id":"809473","timestamp":"1676463480.0"}],"comment_id":"800408","timestamp":"1675731660.0","poster":"pancman"},{"timestamp":"1675706700.0","content":"Selected Answer: D\nD is the most cost-effective and scalable solution to resolve the issue, as it involves resolving the RDS DB cluster endpoint value at deployment time and referencing it in an environment variable in the Lambda function, which reduces the number of calls to the Systems Manager Parameter Store.","comments":[{"timestamp":"1676463600.0","poster":"tieyua","upvote_count":"2","comment_id":"809476","content":"What if you need to switch db endpoint later on? Isn't that the point of having parameter store to begin with?"}],"poster":"Drey","upvote_count":"2","comment_id":"800053"},{"upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1676463660.0","poster":"tieyua","content":"I might have changed my mind, tempting B","comment_id":"809478"}],"comment_id":"794639","content":"Selected Answer: D\nHas to agree with D. \n\nThe whole setup has nothing to do with SSM, throughput, quota, reserved concurrency ... It's a simple nested stack, no developer is dummy enough to talk about potential load. Can't guarantee that's the intention of the examiner though. Good luck","timestamp":"1675201080.0","poster":"tieyua"},{"timestamp":"1675097160.0","poster":"michele_scar","comment_id":"793057","content":"Selected Answer: A\nGlobal var is more efficient how is explained in the doc. \nhttps://docs.aws.amazon.com/lambda/latest/operatorguide/global-scope.html\n\nGiven the data from SSM are not \"confidential\" or \"private\" should stay outside the handler: connection db string and aws-region.","upvote_count":"2"},{"upvote_count":"2","comment_id":"783926","poster":"Phinx","content":"Selected Answer: B\nI think this is B","timestamp":"1674364740.0"}],"question_images":[]},{"id":"FwAfsAcy4x55PocxkiNv","question_id":312,"question_images":[],"answer":"B","isMC":true,"topic":"1","timestamp":"2019-12-03 00:15:00","unix_timestamp":1575328500,"answer_ET":"B","question_text":"A company is running a Docker application on Amazon ECS. The application must scale based on user load in the last 15 seconds.\nHow should a Developer instrument the code so that the requirement can be met?","discussion":[{"comments":[{"poster":"Alekshar","upvote_count":"18","timestamp":"1635681480.0","content":"from the link above : \nStandard resolution, with data having a one-minute granularity\nHigh resolution, with data at a granularity of one second","comment_id":"211320"}],"comment_id":"26102","poster":"Dev1","content":"Ans: B\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html#high-resolution-metrics","upvote_count":"17","timestamp":"1632207300.0"},{"poster":"sumanshu","comment_id":"1327482","upvote_count":"1","timestamp":"1734363060.0","content":"Selected Answer: B\nB) Correct - Amazon CloudWatch high-resolution metrics support granularity down to 1 second (as opposed to standard-resolution metrics, which have a granularity of 1 minute).\nTo scale based on user activity from the last 15 seconds, high-resolution metrics are essential because standard-resolution metrics would not provide the necessary granularity."},{"poster":"AsmaZoheb","timestamp":"1705294920.0","upvote_count":"1","comment_id":"1123069","content":"Selected Answer: B\nanswer is B"},{"content":"Selected Answer: B\nIt is B, we need an high resolution CloudWatch metric in order to generate data each second (instead of each minute with the standard resolution). We are able to publish data every 5 second and analyze the user load data for the last 15 seconds.","timestamp":"1687890900.0","upvote_count":"1","comment_id":"935716","poster":"rcaliandro"},{"poster":"imvb88","timestamp":"1684160340.0","comment_id":"898380","upvote_count":"1","content":"Selected Answer: B\nStandard-resolution of CloudWatch is 1 minute, you need high-resolution for timespan smaller than 1 minute so C, D are out\n\nA only give you data after 30 sec while you need last 15 sec -> B is the answer."},{"content":"Option D recommends publishing data every 5 seconds, but using a standard-resolution metric. While this may capture user activity data frequently enough, it may not provide the necessary level of detail for accurate scaling decisions.\n\nTherefore, the best option is to create a high-resolution custom CloudWatch metric for user activity data and publish it every 5 seconds. This will provide accurate and frequent data points that can be used to make scaling decisions based on user load in the last 15 seconds.","poster":"BATSIE","upvote_count":"1","timestamp":"1682923380.0","comment_id":"885925"},{"poster":"BATSIE","comment_id":"885924","timestamp":"1682923320.0","upvote_count":"1","content":"Option A and C recommend creating a custom CloudWatch metric for user activity data and publishing it every 30 seconds, which may not be frequent enough to capture user activity data within the last 15 seconds accurately"},{"poster":"Dominicwild12","content":"Selected Answer: B\nTo scale the Docker application on Amazon ECS based on user load in the last 15 seconds, a high-resolution custom Amazon CloudWatch metric for user activity data should be created, and data should be published every 5 seconds.\n\nOption B is the correct answer because high-resolution custom metrics have a finer resolution than standard-resolution custom metrics, with data points that can be as frequent as 1 second. The user activity data needs to be measured in near-real-time to accurately reflect the current user load, and publishing the data every 5 seconds will provide the necessary frequency. This will allow Amazon ECS to scale the Docker application appropriately based on the user load.\n\nOption A, C, and D do not provide the required frequency for the user activity data, and therefore may not be accurate enough to scale the Docker application in a timely manner.","comment_id":"817225","upvote_count":"2","timestamp":"1677017280.0"},{"upvote_count":"1","timestamp":"1676535480.0","poster":"MMaquis","content":"Selected Answer: B\nit's B. 30 seconds is not correct as your metrics will be published after 30 sec, and the required is 15.","comment_id":"810425"},{"comment_id":"723085","content":"Selected Answer: B\nBBBBBB","poster":"dark_cherrymon","upvote_count":"1","timestamp":"1668987840.0"},{"timestamp":"1635838740.0","content":"Answer: B","comment_id":"351956","poster":"VAG1595","upvote_count":"2"},{"comments":[{"content":"\"The application must scale based on user load in the last 15 seconds\". \n- The app needs to scale based on load in the last 15 secs\n- If data was published every 30 seconds, this criteria wouldn't be fulfilled as it'd have to wait for the remaining 15 sec, whereas with 5 secs publishing, data can be received every 5 sec enabling the app to scale at the required time","timestamp":"1635836520.0","comments":[{"comment_id":"536834","upvote_count":"3","timestamp":"1643625420.0","poster":"_Ujin","content":"Thanks for deep explaination"}],"upvote_count":"12","comment_id":"317932","poster":"hulala"}],"timestamp":"1635686280.0","poster":"Aparna_acc","content":"why 5 seconds is correct and not option of 30 seconds can someone plz tell","upvote_count":"1","comment_id":"317070"},{"comment_id":"192336","timestamp":"1635238080.0","poster":"Chinta","upvote_count":"1","content":"B is the right answer"},{"content":"B is correct","poster":"saeidp","timestamp":"1635194700.0","upvote_count":"1","comment_id":"173633"},{"comment_id":"139174","content":"B. Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds","upvote_count":"1","poster":"wackyGuru","timestamp":"1634688960.0"},{"content":"Resp: B","timestamp":"1633378140.0","poster":"Scarback","upvote_count":"1","comment_id":"127793"},{"content":"B. Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds","poster":"kinetic1g","upvote_count":"1","timestamp":"1633083180.0","comment_id":"67694"},{"upvote_count":"4","poster":"awscertified","timestamp":"1632314820.0","comment_id":"46624","content":"B. Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds"}],"answers_community":["B (100%)"],"choices":{"D":"Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds","C":"Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds","B":"Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds","A":"Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds"},"exam_id":25,"answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/9624-exam-aws-certified-developer-associate-topic-1-question-38/"},{"id":"y5IiHIMixtiKhLa9Uag3","answer_images":[],"answer":"C","choices":{"C":"Create a trust policy that specifies the EC2 service principal. Associate the role with the policy.","B":"Modify the IAM policy to include the dynamodb:* action.","A":"Modify the IAM policy resource to be “arn:aws:dynamodb-us-west-2:account-id:table/*”","D":"Create a trust relationship between the role and dynamodb.amazonaws.com."},"answer_ET":"C","topic":"1","discussion":[{"content":"I Think it'c, because maybe the EC2 instance has the necessary role to perform actions to DynamoDB Table, but it has not the permission to assume the role (trust policy).","timestamp":"1679434800.0","poster":"JuanFe","upvote_count":"2","comment_id":"846388"},{"timestamp":"1675527180.0","upvote_count":"2","poster":"pancman","content":"Selected Answer: C\nThe most reasonable answer here is C. But I think the question is missing some information.\nhttps://aws.amazon.com/blogs/security/how-to-use-trust-policies-with-iam-roles/","comment_id":"798150"},{"content":"Selected Answer: C\nABD are apparently wrong, but I can't fully explain C. \n\nI'm guessing C implies it's a trust policy from the account/db owner to the EC2 role principal. Consider us-west-2 is mentioned out of nowhere, this might originally be a cross account question getting chopped off.\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/access-control-overview.html#access-control-resource-ownership","comment_id":"794649","timestamp":"1675202340.0","poster":"tieyua","upvote_count":"4"},{"content":"Selected Answer: C\nCCCCCCCCCCCCC","timestamp":"1674400140.0","poster":"BobAWS23","upvote_count":"2","comment_id":"784422"}],"answers_community":["C (100%)"],"exam_id":25,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/96497-exam-aws-certified-developer-associate-topic-1-question-380/","unix_timestamp":1674400140,"timestamp":"2023-01-22 16:09:00","answer_description":"","question_images":["https://img.examtopics.com/aws-certified-developer-associate/image25.png"],"question_text":"A developer is troubleshooting an application that uses Amazon DynamoDB in the us-west-2 Region. The application is deployed to an Amazon EC2 instance. The application requires read-only permissions to a table that is named Cars. The EC2 instance has an attached IAM role that contains the following IAM policy:\n\n//IMG//\n\n\nWhen the application tries to read from the Cars table, an Access Denied error occurs.\n\nHow can the developer resolve this error?","question_id":313},{"id":"77gOMPovsgN9SDEQFGoW","unix_timestamp":1674233880,"question_id":314,"question_images":[],"topic":"1","discussion":[{"upvote_count":"4","poster":"tieyua","comment_id":"795164","content":"Selected Answer: AC\nA&C should be correct. In practice, B&C doing the same thing, but technically, x-ray is included with beanstalk, so there's no download/install, just enable.","timestamp":"1675257780.0"},{"comment_id":"787110","timestamp":"1674606300.0","upvote_count":"3","poster":"JagpreetLM10","content":"Selected Answer: AC\nA. Instrument the code by using the AWS X-Ray software development kit (SDK) for Java.\nC. Enable the AWS X-Ray daemon in the Elastic Beanstalk console."},{"timestamp":"1674517500.0","upvote_count":"1","comment_id":"785981","poster":"slavan","content":"Selected Answer: AC\nshould be A and C"},{"comment_id":"784446","comments":[{"content":"Whoops AC","comment_id":"784449","poster":"BobAWS23","upvote_count":"1","timestamp":"1674401940.0"}],"timestamp":"1674401880.0","upvote_count":"1","content":"Selected Answer: AB\nB and A","poster":"BobAWS23"},{"upvote_count":"1","comment_id":"783932","comments":[{"timestamp":"1674365760.0","upvote_count":"1","poster":"Phinx","comment_id":"783936","content":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/incident-response.html"}],"poster":"Phinx","content":"Selected Answer: CD\nI think it's C and D","timestamp":"1674365580.0"},{"timestamp":"1674236220.0","poster":"JulietHsu","content":"Selected Answer: CD\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-beanstalk.html\nC & D","upvote_count":"1","comment_id":"782587"},{"timestamp":"1674233880.0","comment_id":"782536","comments":[{"comment_id":"784356","poster":"KT_Yu","timestamp":"1674395460.0","upvote_count":"3","content":"changed my mind, should be A and C"},{"content":"B and C does the same thing by enabling the AWS X-Ray daemon. The question states \"combination of steps.\" Thus, the answer should be C and D.","upvote_count":"1","timestamp":"1674365700.0","comment_id":"783935","poster":"Phinx"}],"upvote_count":"1","content":"Selected Answer: BC\nÁnswer B and C\nhttps://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-beanstalk.html","poster":"KT_Yu"}],"exam_id":25,"answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/96193-exam-aws-certified-developer-associate-topic-1-question-381/","answer_ET":"AC","answer":"AC","question_text":"A developer has created a Java application that runs on AWS Elastic Beanstalk with the default Elastic Beanstalk instance profile. The developer needs to visualize a map of the application’s interactions with AWS services to help identify and debug issues with the application.\n\nWhich combination of steps should the developer take to meet this requirement with the LEAST operational effort? (Choose two.)","isMC":true,"choices":{"C":"Enable the AWS X-Ray daemon in the Elastic Beanstalk console.","D":"Enable Elastic Beanstalk enhanced health reporting.","B":"Create an Elastic Beanstalk configuration file to download and install the AWS X-Ray daemon on the underlying Amazon EC2 instances.","A":"Instrument the code by using the AWS X-Ray software development kit (SDK) for Java.","E":"Configure AWS CloudTrail to visualize the services map."},"timestamp":"2023-01-20 17:58:00","answers_community":["AC (67%)","CD (17%)","Other"]},{"id":"KNxPlaSaxo9r2Qg4iOxT","discussion":[{"comment_id":"1061366","timestamp":"1699008660.0","upvote_count":"1","content":"Selected Answer: A\nI believe this is A. The A record in SOA can be just IP address, domain name is not possible, so it cannot be B.\nAs I see for Cloudfront an Alias configuration is required : \"Important : You must create an Alias record for the CloudFront distribution to work.\"\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfront-distribution.html","poster":"hcsaba1982"},{"comment_id":"821557","poster":"pancman","content":"Selected Answer: B\nB is correct","upvote_count":"2","timestamp":"1677335580.0"},{"content":"AAAAAA","timestamp":"1674446520.0","comments":[{"upvote_count":"6","comment_id":"787111","poster":"JagpreetLM10","timestamp":"1674606360.0","content":"B . Create a CloudFront origin access identity (OAI). Associate the OAI with the CloudFront distribution. Modify the S3 bucket policy to allow access from only the OAI. Update the Route 53 records to point the website domain to the CloudFront domain name.\n\nThis solution meets the requirements because creating an OAI and associating it with the CloudFront distribution will restrict access to the S3 bucket to only CloudFront. Modifying the S3 bucket policy to allow access from only the OAI will prevent direct access to the S3 bucket. Updating the Route 53 records to point the website domain to the CloudFront domain name will ensure that users can only access the images through the website's domain."}],"upvote_count":"1","comment_id":"784955","poster":"JagpreetLM10"},{"timestamp":"1674395580.0","poster":"KT_Yu","upvote_count":"3","content":"Selected Answer: B\nB I guess","comment_id":"784360"},{"poster":"Phinx","timestamp":"1674366300.0","comment_id":"783939","content":"Selected Answer: B\nB is the way to go.","upvote_count":"3"}],"topic":"1","exam_id":25,"answer_images":[],"answer_ET":"B","answer":"B","unix_timestamp":1674366300,"answers_community":["B (89%)","11%"],"isMC":true,"answer_description":"","timestamp":"2023-01-22 06:45:00","question_id":315,"url":"https://www.examtopics.com/discussions/amazon/view/96425-exam-aws-certified-developer-associate-topic-1-question-382/","question_images":[],"choices":{"A":"Create a CloudFront origin access identity (OAI). Associate the OAI with the CloudFront distribution. Modify the S3 bucket policy to allow access from only the OAI. Create an alias in Route 53 that points the website domain to the S3 bucket.","B":"Create a CloudFront origin access identity (OAI). Associate the OAI with the CloudFront distribution. Modify the S3 bucket policy to allow access from only the OAI. Update the Route 53 records to point the website domain to the CloudFront domain name.","C":"Block public access in the S3 bucket policy. Configure CloudFront to use the S3 bucket endpoint. Create an alias in Route 53 that points the website domain to the S3 bucket.","D":"Block public access in the S3 bucket policy. Configure CloudFront to use the S3 bucket endpoint. Create an alias in Route 53 that points the website domain to the CloudFront domain name."},"question_text":"A developer is creating a photo website. Amazon Route 53 hosts the website’s domain. The developer wants to store the application code and images in an Amazon S3 bucket. The developer also wants to use Amazon CloudFront to deliver the images to users.\n\nThe developer has created the S3 bucket and a CloudFront distribution. The developer wants the images to be accessed only through the website’s domain. Users must not use the S3 URLs.\n\nWhich solution will meet these requirements?"}],"exam":{"isBeta":false,"numberOfQuestions":443,"isImplemented":true,"id":25,"name":"AWS Certified Developer Associate","lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":true},"currentPage":63},"__N_SSP":true}