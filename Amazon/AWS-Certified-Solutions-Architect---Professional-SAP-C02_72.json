{"pageProps":{"questions":[{"id":"B0Wiu4SVOHW3uhAVa3fL","question_images":[],"answer_description":"","timestamp":"2024-02-05 19:22:00","choices":{"D":"Enable AWS Security Hub for the organization in AWS Organizations. Designate one AWS account as the delegated administrator for Security Hub.","C":"From the AWS Control Tower management account, deploy an AWS CloudFormation stack set that uses the automatic deployment option to enable Amazon Detective for the organization.","B":"Enable Amazon Detective for the organization in AWS Organizations. Designate one AWS account as the delegated administrator for Detective.","A":"From the AWS Control Tower management account, use AWS CloudFormation StackSets to deploy an AWS Config conformance pack to all accounts in the organization."},"answer_ET":"D","answer":"D","answer_images":[],"unix_timestamp":1707157320,"discussion":[{"comment_id":"1310346","timestamp":"1731363000.0","upvote_count":"1","content":"option D meets the requirements of providing a centralized view of the security state of all accounts:\nCentralized view: AWS Security Hub provides a unified view of security findings across multiple AWS services and accounts, making it easy to monitor the security posture of your organization.\nDelegated administration: By designating one account as the delegated administrator for Security Hub, you can centralize the management of Security Hub across all accounts in the organization.\nIntegration with AWS Organizations: Enabling Security Hub at the organization level allows you to see the security findings from all member accounts in a single view.","poster":"AzureDP900"},{"comment_id":"1184040","timestamp":"1711540800.0","upvote_count":"2","content":"Selected Answer: D\nOption D: Enable AWS Security Hub and use Central Configuration for multiple AWS account and delegated Sec Hub Admin. \"Central configuration is a Security Hub feature that helps you set up and manage Security Hub across multiple AWS accounts and AWS Regions & From the delegated Security Hub administrator account, you can specify how the Security Hub service, security standards, and security controls are configured in your organization accounts and organizational units (OUs) across Regions\"\n\n(1) https://docs.aws.amazon.com/securityhub/latest/userguide/central-configuration-intro.html\n(2) https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-setup-prereqs.html","poster":"TonytheTiger"},{"poster":"career360guru","content":"Selected Answer: D\nOption D","comment_id":"1169341","timestamp":"1709972760.0","upvote_count":"1"},{"content":"Selected Answer: D\ncentralized view == security hub","comment_id":"1160762","upvote_count":"3","timestamp":"1709047260.0","poster":"a54b16f"},{"comment_id":"1149330","upvote_count":"2","poster":"adelynllllllllll","content":"D\n\nhttps://aws.amazon.com/blogs/mt/centralized-dashboard-for-aws-config-and-aws-security-hub/","timestamp":"1707839580.0"},{"content":"Correct Answer A\nhttps://aws.amazon.com/blogs/mt/extend-aws-control-tower-governance-using-aws-config-conformance-packs/","timestamp":"1707220440.0","poster":"onlyvimal2103","comment_id":"1142113","upvote_count":"1"},{"upvote_count":"3","poster":"kejam","timestamp":"1707198840.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_integrate_delegated_admin.html","comment_id":"1141812"},{"timestamp":"1707157320.0","poster":"alexis123456","content":"Correct Answer is D","comment_id":"1141332","upvote_count":"3"}],"url":"https://www.examtopics.com/discussions/amazon/view/132897-exam-aws-certified-solutions-architect-professional-sap-c02/","isMC":true,"topic":"1","question_text":"A company creates an AWS Control Tower landing zone to manage and govern a multi-account AWS environment. The company's security team will deploy preventive controls and detective controls to monitor AWS services across all the accounts. The security team needs a centralized view of the security state of all the accounts.\n\nWhich solution will meet these requirements?","question_id":356,"exam_id":33,"answers_community":["D (100%)"]},{"id":"ZchvK0W4IRt4uwNoGihP","answer_ET":"D","isMC":true,"unix_timestamp":1673644380,"question_images":[],"answers_community":["D (96%)","2%"],"question_text":"A solutions architect needs to advise a company on how to migrate its on-premises data processing application to the AWS Cloud. Currently, users upload input files through a web portal. The web server then stores the uploaded files on NAS and messages the processing server over a message queue. Each media file can take up to 1 hour to process. The company has determined that the number of media files awaiting processing is significantly higher during business hours, with the number of files rapidly declining after business hours.\n\nWhat is the MOST cost-effective migration recommendation?","timestamp":"2023-01-13 22:13:00","choices":{"A":"Create a queue using Amazon SQS. Configure the existing web server to publish to the new queue. When there are messages in the queue, invoke an AWS Lambda function to pull requests from the queue and process the files. Store the processed files in an Amazon S3 bucket.","D":"Create a queue using Amazon SQS. Configure the existing web server to publish to the new queue. Use Amazon EC2 instances in an EC2 Auto Scaling group to pull requests from the queue and process the files. Scale the EC2 instances based on the SQS queue length. Store the processed files in an Amazon S3 bucket.","C":"Create a queue using Amazon MQ. Configure the existing web server to publish to the new queue. When there are messages in the queue, invoke an AWS Lambda function to pull requests from the queue and process the files. Store the processed files in Amazon EFS.","B":"Create a queue using Amazon MQ. Configure the existing web server to publish to the new queue. When there are messages in the queue, create a new Amazon EC2 instance to pull requests from the queue and process the files. Store the processed files in Amazon EFS. Shut down the EC2 instance after the task is complete."},"question_id":357,"exam_id":33,"topic":"1","answer_description":"","discussion":[{"upvote_count":"24","poster":"masetromain","timestamp":"1673806440.0","comment_id":"776912","content":"Selected Answer: D\nThe correct answer would be option D.\n\nThis option suggests creating a queue using Amazon SQS, configuring the existing web server to publish to the new queue, and using EC2 instances in an EC2 Auto Scaling group to pull requests from the queue and process the files. The EC2 instances can be scaled based on the SQS queue length, which ensures that the resources are available during peak usage times and reduces costs during non-peak times.\n\nOption A is not correct because it suggests using AWS Lambda which has a maximum execution time of 15 minutes.\nOption B is not correct because it suggests creating a new EC2 instance for each message in the queue, which is not cost-effective.\nOption C is not correct because it suggests using Amazon EFS, which is not a suitable option for long-term storage of large files."},{"poster":"ninomfr64","content":"Selected Answer: D\nNot A - Lambda max execution time is 15 minutes, image processing can take up to 1 hour\nNot B - Amazon MQ is not needed (more expensive then SQS) and EFS is more expensive then S3\nNot C - Amazon MQ is not needed (more expensive then SQS) and Lambda max execution time is 15 minutes, image processing can take up to 1 hour\n\nD does the job with the lower cost thanks to SQS, S3 and EC2 Auto Scaling Group","comment_id":"1104679","timestamp":"1703430360.0","upvote_count":"7"},{"timestamp":"1730389740.0","poster":"mohan_cv","content":"Exam AWS Certified Solutions Architect - Professional SAP-C02 topic 1 question 42 discussion","upvote_count":"1","comment_id":"1305520"},{"poster":"Malcnorth59","content":"Selected Answer: D\nLambda will not work, so A is not possible.\nD is going to be the most cost-effective as the resources will scale based on queue length.","upvote_count":"1","comment_id":"1214953","timestamp":"1716295800.0"},{"content":"Selected Answer: D\nGiven the need to process files that can take up to 1 hour each and the variability in workload, option D (Amazon SQS, EC2 Auto Scaling, and S3) appears to be the most cost-effective and practical solution. It leverages SQS for queue management, enabling efficient handling of the processing queue's variability. EC2 Auto Scaling allows for flexible and cost-effective scaling of processing capacity, ramping up during high-demand periods and scaling down when demand wanes, thus optimizing costs. Finally, Amazon S3 offers a highly durable and cost-effective solution for storing the processed media files. This option provides the necessary flexibility for long processing tasks while efficiently managing the variable demand and optimizing storage costs.","poster":"mav3r1ck","comment_id":"1180375","upvote_count":"1","timestamp":"1711146840.0"},{"poster":"Simon523","content":"Selected Answer: D\nSimple Queuing Service\nSQS is based on pull model. Here are some of the important features:\n\nReliable, scalable, fully-managed message queuing service\nHigh availability\nUnlimited scaling\nAuto scale to process billions of messages per day\nLow cost (Pay for use)","upvote_count":"1","timestamp":"1694394720.0","comment_id":"1004388"},{"poster":"aviathor","timestamp":"1693465560.0","content":"Selected Answer: D\nThis is quite simple. Any answer (A and C) consisting of using Lambda for processing the files is out because of the 15 minutes limit on Lambda processes.\n\nB is out because using EFS is expensive and it does not specify how to launch and terminate the EC2 instances. Amazon MQ is not required either.\n\nThis leaves D which uses SQS, Auto Scaling Groups and publishes the resulting files to S3.","comment_id":"994870","upvote_count":"2"},{"upvote_count":"1","comment_id":"972789","content":"Selected Answer: D\nAnswer: D\n\nYou can eliminate A and C right in the beginning: Lambda functions can run up to 15 minutes.\nB won't help much as you need to create new EC2 instances (manually, apparently) and EFS is more expensive than S3.","poster":"chico2023","timestamp":"1691222100.0"},{"content":"Selected Answer: D\nd for sure","upvote_count":"1","comment_id":"939268","poster":"NikkyDicky","timestamp":"1688144280.0"},{"upvote_count":"1","content":"Selected Answer: D\nBecause of \"Each media file can take up to 1 hour to process\" and we know Lambda has a limit in 15 minutes, The correct answer is D","timestamp":"1686925860.0","comment_id":"925270","poster":"ailves"},{"upvote_count":"1","timestamp":"1685352180.0","comment_id":"909243","content":"D - https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html","poster":"EricZhang"},{"poster":"huanaws088","content":"Selected Answer: B\nI sure is B , becauce\n1. SQS , SNS are \" cloud - native \" services : proprietary protocols from AWS \n2. Traditional applications running from on - premises may use open protocols such as : MQTT , AMQP ,.., so When migrating to the cloud , instead of re-engineering the application to use SQS and SNS will very expensive, we can use Amazon MQ.\n3. Amazon MQ doesn't \" scale \" as much as SQS / SNS Amazon MQ runs on servers but Amazon MQ has both queue feature ( ~ SQS ) and topic features ( ~ SNS )\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-difference-from-amazon-mq-sns.html","timestamp":"1681306680.0","upvote_count":"1","comment_id":"868414","comments":[{"timestamp":"1688652300.0","content":"In terms of cost (which is a point on the question), Amazon SQS is generally more cost-effective compared to Amazon MQ for this specific use case. SQS pricing is based on the number of requests and message data transfer, whereas Amazon MQ pricing includes additional costs associated with broker instances and data transfer.","comment_id":"944741","poster":"hexie","upvote_count":"1"}]},{"timestamp":"1680395760.0","upvote_count":"2","poster":"takecoffe","comment_id":"858389","content":"Selected Answer: D\nSQS and autoscaling no doubt answer is D"},{"upvote_count":"2","poster":"mfsec","timestamp":"1679991120.0","comment_id":"852999","content":"Selected Answer: D\nSQS and Auto Scaling"},{"upvote_count":"4","poster":"dev112233xx","content":"Selected Answer: D\nD - makes sense.. Lambda can’t run more than 15m.\nAnd Amazon MQ is only recommended when migrating existing message brokers that rely on compatibility with APIs such as JMS or protocols such as AMQP, MQTT, OpenWire, and STOMP.. in the question there is no mention for these services ..","comment_id":"840395","timestamp":"1678921020.0"},{"upvote_count":"2","poster":"God_Is_Love","content":"A and C are out because lambda does not support more than 15 min. B says, to create an EC2 for each new message which is certainly not cost effective and bad design as well. So answer is D","timestamp":"1677298260.0","comment_id":"821178"},{"comment_id":"810230","timestamp":"1676519520.0","poster":"c73bf38","upvote_count":"2","content":"Selected Answer: D\nThe most cost-effective migration recommendation to handle peak loads during business hours is to use Amazon SQS to create a queue, configure the existing web server to publish to the new queue, and use Amazon EC2 instances in an EC2 Auto Scaling group to pull requests from the queue and process the files. The EC2 instances should be scaled based on the SQS queue length. Storing the processed files in an Amazon S3 bucket will help in reducing the storage cost. This approach is scalable and can handle peak loads during business hours, while still being cost-effective during non-business hours. Option A is also a possible solution, but using EC2 instances in an EC2 Auto Scaling group is a more scalable and cost-effective solution. Options B and C involve using Amazon EFS, which can be more expensive than Amazon S3."},{"content":"Selected Answer: D\nD is the right answer","comment_id":"793019","upvote_count":"2","poster":"zozza2023","timestamp":"1675095120.0"},{"timestamp":"1675004700.0","upvote_count":"2","content":"Selected Answer: D\nBecause A is not valid due to time","comment_id":"791753","poster":"Musk"},{"content":"D will be correct.","poster":"pravi1","timestamp":"1674967380.0","upvote_count":"1","comment_id":"791394"},{"timestamp":"1673790780.0","upvote_count":"1","comment_id":"776636","content":"D is correct because it took 1 hour to process the file. Lambda only run 15 minutes","poster":"zhangyu20000"},{"content":"Selected Answer: A\nA. Create a queue using Amazon SQS. Configure the existing web server to publish to the new queue. When there are messages in the queue, invoke an AWS Lambda function to pull requests from the queue and process the files. Store the processed files in an Amazon S3 bucket.\nThis approach will be the most cost-effective as it uses serverless AWS Lambda to process the files, which only incurs charges while the function is running, and is therefore well suited for workloads with variable and unpredictable usage patterns. Additionally, using Amazon S3 for storage is a cost-effective option as it allows for the storage of large amounts of data at a low cost.","poster":"masetromain","comment_id":"774859","upvote_count":"1","timestamp":"1673644380.0","comments":[{"upvote_count":"1","poster":"Atila50","comment_id":"776918","timestamp":"1673806980.0","content":"Although this answer is the most cost-effective, AWS Lambda only allows functions to run up to 15 minutes.","comments":[{"comment_id":"776921","content":"correct ans is D","upvote_count":"2","poster":"Atila50","timestamp":"1673807220.0"}]},{"comments":[{"poster":"masetromain","content":"https://www.examtopics.com/discussions/amazon/view/36333-exam-aws-certified-solutions-architect-professional-topic-1/\n\nyou are right, I was wrong despite the fact that I already knew this question. sorry","timestamp":"1673804160.0","comment_id":"776879","upvote_count":"3"}],"content":"You cannot use Lambda function since the question mentioned \"process time take up to 1 hour for processing\" Aws Lambda functions can run only 15 minutes per function.","comment_id":"776207","upvote_count":"1","timestamp":"1673764620.0","poster":"andctygr"}]}],"answer_images":[],"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/95090-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"chjBUNb5MUPAErKW9ILA","timestamp":"2024-02-05 19:26:00","isMC":true,"question_images":[],"answers_community":["A (100%)"],"question_id":358,"question_text":"A company that develops consumer electronics with offices in Europe and Asia has 60 TB of software images stored on premises in Europe. The company wants to transfer the images to an Amazon S3 bucket in the ap-northeast-1 Region. New software images are created daily and must be encrypted in transit. The company needs a solution that does not require custom development to automatically transfer all existing and new software images to Amazon S3.\n\nWhat is the next step in the transfer process?","unix_timestamp":1707157560,"answer_ET":"A","answer":"A","answer_description":"","topic":"1","choices":{"B":"Configure Amazon Kinesis Data Firehose to transfer the images using S3 Transfer Acceleration.","C":"Use an AWS Snowball device to transfer the images with the S3 bucket as the target.","D":"Transfer the images over a Site-to-Site VPN connection using the S3 API with multipart upload.","A":"Deploy an AWS DataSync agent and configure a task to transfer the images to the S3 bucket."},"discussion":[{"poster":"kejam","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/storage/synchronizing-your-data-to-amazon-s3-using-aws-datasync/","comment_id":"1141815","upvote_count":"9","timestamp":"1707199080.0"},{"upvote_count":"5","content":"Selected Answer: A\nAWS DataSync - is a managed data transfer service that simplifies, automates, and accelerates moving data between on-premises storage systems and AWS storage services, as well as between AWS storage services. It supports encryption in transit and can be configured to transfer data to Amazon S3 automatically, handling both existing and new files efficiently. DataSync can be set up without requiring any custom development, making it a strong fit for the company's requirements. However Snowball it is not suited for the ongoing daily transfer of new software images due to the physical shipment of the device involved.","timestamp":"1707559740.0","comment_id":"1146028","poster":"nharaz"},{"content":"Option A is right\nEasy to use: DataSync makes it easy to transfer large datasets from on-premises locations to Amazon S3 without requiring custom development.\nHigh-speed data transfer: DataSync can achieve speeds of up to 10 Gbps, which is much faster than other methods like S3 API with multipart upload (which was my initial answer).\nEfficient data transfer: DataSync is designed for large-scale data transfers and can handle many concurrent transfers, making it an ideal solution for this scenario.\nLow maintenance: Once configured, DataSync requires minimal maintenance, which aligns well with the company's need to not require custom development.","comment_id":"1310344","timestamp":"1731362820.0","upvote_count":"1","poster":"AzureDP900"},{"upvote_count":"1","content":"Selected Answer: A\nOption A: Additional info on AWS DataSync and S3 transfer \n\nhttps://aws.amazon.com/blogs/storage/migrating-hundreds-of-tb-of-data-to-amazon-s3-with-aws-datasync/","comment_id":"1184045","timestamp":"1711541280.0","poster":"TonytheTiger"},{"comment_id":"1169344","content":"Selected Answer: A\nOption A. Option D is feasible but this needs custom development that company does not want to do.","timestamp":"1709973120.0","upvote_count":"1","poster":"career360guru"},{"comment_id":"1164407","poster":"a54b16f","timestamp":"1709420100.0","content":"Selected Answer: A\nEasy to pick A as the answer, since all others are invalid. Though, the images are in on premise, the solution should at least mention VPN or direct connect.","upvote_count":"2"},{"upvote_count":"1","poster":"alexis123456","comment_id":"1141337","content":"Correct Answer is A","timestamp":"1707157560.0"}],"url":"https://www.examtopics.com/discussions/amazon/view/132898-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_images":[],"exam_id":33},{"id":"ezNjTSAgucWyOub70W20","timestamp":"2024-02-05 19:29:00","topic":"1","question_images":[],"answer_images":[],"unix_timestamp":1707157740,"answers_community":["B (100%)"],"answer_description":"","answer_ET":"B","question_text":"A company has a web application that uses Amazon API Gateway. AWS Lambda, and Amazon DynamoDB. A recent marketing campaign has increased demand. Monitoring software reports that many requests have significantly longer response times than before the marketing campaign.\n\nA solutions architect enabled Amazon CloudWatch Logs for API Gateway and noticed that errors are occurring on 20% of the requests. In CloudWatch, the Lambda function Throttles metric represents 1% of the requests and the Errors metric represents 10% of the requests. Application logs indicate that, when errors occur, there is a call to DynamoDB.\n\nWhat change should the solutions architect make to improve the current response times as the web application becomes more popular?","discussion":[{"comment_id":"1356453","upvote_count":"1","poster":"juanife","timestamp":"1739542980.0","content":"Selected Answer: B\nwithout any doubt it's b, since the error is related to calls against dynamodb when traffic spike ocurrs"},{"upvote_count":"1","content":"Option B is right. Auto scaling for DynamoDB can help ensure that your table is always provisioned with enough capacity to handle incoming requests, which in turn can help prevent throttle limit exceeds. By automatically adjusting the provisioned capacity of your table based on actual usage patterns, you can maintain optimal performance and responsiveness, even during periods of high traffic or demand.","comment_id":"1310305","timestamp":"1731356280.0","poster":"AzureDP900"},{"comment_id":"1169346","timestamp":"1709973180.0","content":"Selected Answer: B\nOption B","upvote_count":"1","poster":"career360guru"},{"content":"Selected Answer: B\nAnswer is B","comment_id":"1143554","poster":"HunkyBunky","timestamp":"1707325620.0","upvote_count":"2"},{"upvote_count":"4","poster":"kejam","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html","comment_id":"1142840","timestamp":"1707262620.0"},{"upvote_count":"4","content":"Correct Answer is B","timestamp":"1707157740.0","comment_id":"1141341","poster":"alexis123456"}],"answer":"B","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/132901-exam-aws-certified-solutions-architect-professional-sap-c02/","question_id":359,"choices":{"A":"Increase the concurrency limit of the Lambda function.","D":"Re-create the DynamoDB table with a better-partitioned primary index.","C":"Increase the API Gateway throttle limit.","B":"Implement DynamoDB auto scaling on the table."},"exam_id":33},{"id":"GL0nTxIE79dhft3rmXOm","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/132903-exam-aws-certified-solutions-architect-professional-sap-c02/","question_text":"A company has an application that has a web frontend. The application runs in the company's on-premises data center and requires access to file storage for critical data. The application runs on three Linux VMs for redundancy. The architecture includes a load balancer with HTTP request-based routing.\n\nThe company needs to migrate the application to AWS as quickly as possible. The architecture on AWS must be highly available.\n\nWhich solution will meet these requirements with the FEWEST changes to the architecture?","answer":"B","isMC":true,"choices":{"D":"Migrate the application to Amazon EC2 instances in three AWS Regions. Use Amazon Elastic Block Store (Amazon EBS) for file storage. Enable Cross-Region Replication (CRR) for all three EC2 instances. Use an Application Load Balancer to direct traffic to the EC2 instances.","A":"Migrate the application to Amazon Elastic Container Service (Amazon ECS) containers that use the Fargate launch type in three Availability Zones. Use Amazon S3 to provide file storage for all three containers. Use a Network Load Balancer to direct traffic to the containers.","B":"Migrate the application to Amazon EC2 instances in three Availability Zones. Use Amazon Elastic File System (Amazon EFS) for file storage. Mount the file storage on all three EC2 instances. Use an Application Load Balancer to direct traffic to the EC2 instances.","C":"Migrate the application to Amazon Elastic Kubernetes Service (Amazon EKS) containers that use the Fargate launch type in three Availability Zones. Use Amazon FSx for Lustre to provide file storage for all three containers. Use a Network Load Balancer to direct traffic to the containers."},"timestamp":"2024-02-05 19:31:00","discussion":[{"poster":"AzureDP900","comment_id":"1310304","content":"Option B meets the requirements with the fewest changes to the architecture:\nMigrate the application to Amazon EC2 instances in three Availability Zones: This is a straightforward migration of the existing Linux VMs to AWS EC2 instances, which provides high availability and redundancy.\nUse Amazon Elastic File System (Amazon EFS) for file storage: Amazon EFS is a scalable file system that can be mounted on multiple EC2 instances, providing access to shared files without modifying the application's architecture.\nMount the file storage on all three EC2 instances: This ensures that all three EC2 instances have access to the critical data stored in Amazon EFS.\nUse an Application Load Balancer to direct traffic to the EC2 instances: The existing load balancer with HTTP request-based routing can be replaced with an AWS Application Load Balancer, which provides better performance and scalability.","timestamp":"1731356040.0","upvote_count":"2"},{"content":"Selected Answer: B\nOption B - \"Amazon EFS provides scalable file storage for use with Amazon EC2. You can use an EFS file system as a common data source for workloads and applications running on multiple instances.\"\n\n https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEFS.html","timestamp":"1711542000.0","comment_id":"1184065","upvote_count":"1","poster":"TonytheTiger"},{"timestamp":"1709973420.0","upvote_count":"1","comment_id":"1169348","poster":"career360guru","content":"Selected Answer: B\nOption B"},{"poster":"nharaz","content":"Selected Answer: B\nB - is the best solution to meet the requirements with the fewest changes to the architecture. It maintains the application's architecture by using EC2 instances for compute, EFS for shared file storage across instances (mirroring on-premises file storage capabilities), and an ALB for HTTP request-based routing, ensuring a smooth transition to AWS with high availability.","comment_id":"1146101","upvote_count":"4","timestamp":"1707561240.0"},{"timestamp":"1707325560.0","upvote_count":"2","poster":"HunkyBunky","comment_id":"1143553","content":"Selected Answer: B\nAnswer - B"},{"timestamp":"1707262980.0","poster":"kejam","upvote_count":"3","content":"Selected Answer: B\nAnswer B: FEWEST changes to the architecture","comment_id":"1142842"},{"upvote_count":"4","timestamp":"1707157860.0","content":"Correct Answer is B","poster":"alexis123456","comment_id":"1141344"}],"topic":"1","question_images":[],"unix_timestamp":1707157860,"exam_id":33,"answer_images":[],"answers_community":["B (100%)"],"answer_description":"","question_id":360}],"exam":{"numberOfQuestions":529,"isBeta":false,"id":33,"name":"AWS Certified Solutions Architect - Professional SAP-C02","lastUpdated":"11 Apr 2025","isMCOnly":true,"provider":"Amazon","isImplemented":true},"currentPage":72},"__N_SSP":true}