{"pageProps":{"questions":[{"id":"o66kVsjuWuHDyq0mWwCq","question_images":[],"exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/132889-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":706,"answer_images":[],"answer":"A","question_text":"A company runs a real-time data ingestion solution on AWS. The solution consists of the most recent version of Amazon Managed Streaming for Apache Kafka (Amazon MSK). The solution is deployed in a VPC in private subnets across three Availability Zones.\n\nA solutions architect needs to redesign the data ingestion solution to be publicly available over the internet. The data in transit must also be encrypted.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","timestamp":"2024-02-05 18:12:00","topic":"1","answers_community":["A (96%)","4%"],"answer_description":"","answer_ET":"A","discussion":[{"poster":"haci","timestamp":"1708114680.0","upvote_count":"11","content":"Selected Answer: A\nSince we are talking about real-time data (UDP packets) ALB is not a viable solution. You don't need to listen HTTPS, so D is eliminated. If you create a new VPC, you must create link between the old one and this is not mentioned in B. So It is A for me.","comment_id":"1152213"},{"poster":"Dantecito","timestamp":"1739825040.0","comment_id":"1357978","upvote_count":"1","content":"Selected Answer: D\nD. NLB forward traffic from the internet to private subnet where the cluster is. MSK use layer 4.\nA. B. use public subnets exposing the cluster\nC. Similar to D but MSK requires a Layer 4."},{"comments":[{"timestamp":"1738366320.0","upvote_count":"1","comments":[{"content":"Unauthenticated access control must be off and at least one of the following access-control methods must be on: SASL/IAM, SASL/SCRAM, mTLS. For information about how to update the access-control method of a cluster, see Update security settings of a Amazon MSK cluster.","comment_id":"1349706","timestamp":"1738366320.0","poster":"FlyingHawk","upvote_count":"1"}],"content":"To turn on public access to an MSK Provisioned cluster, first ensure that the cluster meets all of the following conditions:\n\nThe subnets that are associated with the cluster must be public. Each public subnet has a public IPv4 address associated with it and public IPv4 addresses are priced as shown in Amazon VPC pricing page. This means that the subnets must have an associated route table with an internet gateway attached. For information about how to create and attach an internet gateway, see Enable VPC internet access using internet gateways in the Amazon VPC User Guide.","poster":"FlyingHawk","comment_id":"1349705"}],"comment_id":"1349704","content":"Selected Answer: A\nFor MSK to get public access, you must associate it with a public subnet, so rule out C and D, B is to create a new VPC, which is more complicated and more operations, so A is correct.","timestamp":"1738366260.0","upvote_count":"1","poster":"FlyingHawk"},{"comments":[{"comment_id":"1285520","timestamp":"1726620000.0","content":"There is no reference to a NEW VPC being required in the documentation. We can simply configure subnets in the existing VPC.","upvote_count":"2","poster":"MatAlves"}],"upvote_count":"4","poster":"MatAlves","content":"Selected Answer: A\n\"You can turn on public access to an MSK cluster at no additional cost... \n\nTo turn on public access to a cluster, first ensure that the cluster meets all of the following conditions:\n\n- The subnets that are associated with the cluster must be public.\n- Unauthenticated access control must be off and at least one of the following access-control methods must be on: SASL/IAM, SASL/SCRAM, mTLS.\n- ...\"\n\nhttps://docs.aws.amazon.com/msk/latest/developerguide/public-access.html","timestamp":"1726620000.0","comment_id":"1285519"},{"content":"Selected Answer: A\nAnswerA\n\nI need to agree that answer will probably be Option A.","comment_id":"1238197","upvote_count":"1","timestamp":"1719496080.0","poster":"Scheldon"},{"poster":"Indrasis","timestamp":"1708494600.0","upvote_count":"2","comment_id":"1155277","content":"Selected Answer: A\nA is correct"},{"comment_id":"1149288","poster":"Marunio","content":"Selected Answer: A\nA, since Kafka is loadbalancing itself. - https://dattell.com/data-architecture-blog/load-balancing-with-kafka/#:~:text=Load%20balancing%20with%20Kafka%20is,partitions%20while%20preserving%20message%20ordering.\n\nB - why create new VPC?\n\nC / D - Kafka is loadbalacing itself, also NLB can't handle HTTPS.","timestamp":"1707837900.0","upvote_count":"3"},{"comment_id":"1141300","content":"Option A","timestamp":"1707153120.0","poster":"Andy_09","upvote_count":"4"}],"choices":{"D":"Deploy a Network Load Balancer (NLB) that uses private subnets. Configure an NLB listener for HTTPS communication over the internet.","B":"Create a new VPC that has public subnets. Deploy an MSK cluster in the public subnets. Update the MSK cluster security settings to enable mutual TLS authentication.","C":"Deploy an Application Load Balancer (ALB) that uses private subnets. Configure an ALB security group inbound rule to allow inbound traffic from the VPC CIDR block for HTTPS protocol.","A":"Configure public subnets in the existing VPC. Deploy an MSK cluster in the public subnets. Update the MSK cluster security settings to enable mutual TLS authentication."},"unix_timestamp":1707153120,"isMC":true},{"id":"A8W3Z7nFhk5Sx690flSM","question_images":[],"choices":{"C":"Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon Elastic File System (Amazon EFS) storage. Create an AWS Step Functions state machine to process order files. Use Amazon EventBridge Scheduler to invoke the state machine to periodically check Amazon EFS for order files.","B":"Create an AWS Transfer Family SFTP internet-facing server in one Availability Zone. Use Amazon Elastic File System (Amazon EFS) storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workflow to invoke the Lambda function.","D":"Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workflow to invoke the Lambda function.","A":"Create an AWS Transfer Family SFTP internet-facing server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use S3 Event Notifications to send s3:ObjectCreated:* events to the Lambda function."},"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/132890-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2024-02-05 18:22:00","discussion":[{"comments":[{"upvote_count":"2","comments":[{"upvote_count":"2","comment_id":"1221804","poster":"Mr_Marcus","timestamp":"1717099080.0","content":"\"The company already has an AWS account that has connectivity to the on-premises network.\" Internal Server."}],"content":"If the legacy application needs to ingest customer order files from an on-premises ERP system and upload them to an SFTP server, an internet-facing AWS Transfer Family SFTP server would be the appropriate choice.\n\nIn this scenario, the SFTP server needs to be accessible from the internet to facilitate the file transfer between the on-premises system and AWS. Therefore, an internet-facing server is required to securely receive the files.","comment_id":"1147234","timestamp":"1707656520.0","poster":"hajra313"}],"upvote_count":"11","content":"Selected Answer: D\nD looks more secure over existing on-prem to AWS connection\n-Transfer Family SFTP internal server in two Availability Zones.\n-Use Amazon S3 storage. \n-Use a Transfer Family managed workflow to invoke the Lambda function\"","timestamp":"1707301800.0","poster":"anikolov","comment_id":"1143236"},{"comment_id":"1345211","poster":"FlyingHawk","upvote_count":"1","comments":[{"poster":"FlyingHawk","timestamp":"1737621360.0","content":"AWS Transfer Family supports managed workflows for file processing. With managed workflows, you can kick off a workflow after a file has been transferred over SFTP, FTPS, or FTP. Using this feature, you can securely and cost effectively meet your compliance requirements for business-to-business (B2B) file exchanges by coordinating all the necessary steps required for file processing. In addition, you benefit from end-to-end auditing and visibility.\nhttps://aws.amazon.com/blogs/storage/customize-file-delivery-notifications-using-aws-transfer-family-managed-workflows/","upvote_count":"1","comment_id":"1345213"}],"timestamp":"1737621240.0","content":"Selected Answer: D\nA and D are similar, but A internet-facing server is less secure than D, also no need to use S3 Event Notifications to send s3:ObjectCreated:* events to the Lambda function because Transfer Family managed workflows can directly invoke Lambda..\nhttps://docs.aws.amazon.com/transfer/latest/userguide/transfer-workflows.html"},{"content":"Selected Answer: D\nA and B is out since it is public facing and we don't need public facing SFTP since Company already have Connection to AWS thro ON-PREMISES. \n\nInitially i thought it will C since it was doing scheduled as they were doing scheduled job every hour on on-premises. Then the read thro question and saw they are saying with new solution, they want to process the file immediately after it is uploaded so D is correct since it will trigger the Lambda file as soon as file appears on S3.","poster":"ckhemani","comment_id":"1317621","upvote_count":"3","timestamp":"1732551300.0"},{"poster":"Scheldon","content":"Selected Answer: D\nAnswer D","timestamp":"1719496620.0","comment_id":"1238210","upvote_count":"2"},{"poster":"sandordini","timestamp":"1714062120.0","upvote_count":"3","content":"Selected Answer: D\n\"order files from an on-premises enterprise resource planning (ERP)\" - Therefore Internal Endpoint is enough, no need for Internet-facing, although Internet-facing also handles on-prem connections as well, but \"most secure\". Even tho we are talking about SecureFTP.... Very bad wording of the question... :(\nDefinitely S3 against EFS, so D should be the answer...","comment_id":"1202143","comments":[{"comment_id":"1202144","content":"Also: With managed workflows, you can kick off a workflow after a file has been transferred over SFTP","poster":"sandordini","upvote_count":"2","timestamp":"1714062300.0"}]},{"upvote_count":"3","timestamp":"1711956720.0","comment_id":"1187272","poster":"Hung23","content":"Selected Answer: A\nCorrect answer is A because must support integration with existing erp system we need to choose sftp internal-facing"},{"upvote_count":"1","poster":"buzzinmumbai","content":"Answer is D . Both A&D are right but the question says it must support integration with existing erp system. I believe you can use transfer family for the existing job onprem as well to check for files.","timestamp":"1711588860.0","comment_id":"1184498"},{"content":"Selected Answer: D\nhas an AWS account that has connectivity to the on-premises network.","timestamp":"1711126020.0","comment_id":"1180190","poster":"alawada","upvote_count":"2"},{"content":"Selected Answer: D\nThe company already has an AWS account that has connectivity to the on-premises network. So no need internet.","timestamp":"1709927940.0","comment_id":"1169074","poster":"xBUGx","upvote_count":"3"},{"content":"I would go in D as it's internal network.","upvote_count":"2","comment_id":"1154072","timestamp":"1708356480.0","poster":"67a3f49"},{"poster":"NayeraB","content":"Selected Answer: A\nI think A makes more sense","timestamp":"1708349280.0","upvote_count":"2","comment_id":"1153938"},{"upvote_count":"3","poster":"Andy_09","comment_id":"1141302","content":"A is the correct option","timestamp":"1707153720.0"}],"question_text":"A company wants to migrate an on-premises legacy application to AWS. The application ingests customer order files from an on-premises enterprise resource planning (ERP) system. The application then uploads the files to an SFTP server. The application uses a scheduled job that checks for order files every hour.\n\nThe company already has an AWS account that has connectivity to the on-premises network. The new application on AWS must support integration with the existing ERP system. The new application must be secure and resilient and must use the SFTP protocol to process orders from the ERP system immediately.\n\nWhich solution will meet these requirements?","answers_community":["D (83%)","A (17%)"],"question_id":707,"answer":"D","exam_id":31,"answer_description":"","isMC":true,"topic":"1","unix_timestamp":1707153720,"answer_ET":"D"},{"id":"i4waFb2SqoNAm3WiWBfQ","question_text":"A company’s applications use Apache Hadoop and Apache Spark to process data on premises. The existing infrastructure is not scalable and is complex to manage.\n\nA solutions architect must design a scalable solution that reduces operational complexity. The solution must keep the data processing on premises.\n\nWhich solution will meet these requirements?","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/132891-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["C (86%)","14%"],"question_id":708,"question_images":[],"answer_description":"","timestamp":"2024-02-05 18:24:00","exam_id":31,"choices":{"D":"Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Create an Amazon EMR cluster to process the data.","B":"Use AWS DataSync to connect to the on-premises Hadoop Distributed File System (HDFS) cluster. Create an Amazon EMR cluster to process the data.","C":"Migrate the Apache Hadoop application and the Apache Spark application to Amazon EMR clusters on AWS Outposts. Use the EMR clusters to process the data.","A":"Use AWS Site-to-Site VPN to access the on-premises Hadoop Distributed File System (HDFS) data and application. Use an Amazon EMR cluster to process the data."},"topic":"1","unix_timestamp":1707153840,"answer_ET":"C","isMC":true,"answer":"C","discussion":[{"comment_id":"1143238","upvote_count":"14","timestamp":"1707301920.0","poster":"anikolov","content":"Selected Answer: C\nC cover requirement: The solution must keep the data processing on premises"},{"poster":"Andy_09","upvote_count":"9","comment_id":"1141305","timestamp":"1707153840.0","content":"I would go for option C, as data processing has to be done on premise."},{"poster":"Scheldon","timestamp":"1719496560.0","comment_id":"1238208","upvote_count":"2","content":"Selected Answer: C\nAnswer C"},{"poster":"sandordini","upvote_count":"2","timestamp":"1714062480.0","content":"Selected Answer: C\nOnly solution to keep the processing on-prem.","comment_id":"1202147"},{"comments":[{"content":"Selected response : C","comment_id":"1248792","upvote_count":"2","poster":"example_","timestamp":"1721121840.0"}],"comment_id":"1187275","content":"Selected Answer: B\nCreate an Amazon EMR Cluster: With the data now available in Amazon S3, the company can create an Amazon EMR cluster for data processing. EMR provides scalable Hadoop and Spark clusters that can process data stored in S3, enabling the company to leverage cloud-based processing resources while still keeping the data processing on premises.","poster":"Hung23","timestamp":"1711956900.0","upvote_count":"3"}]},{"id":"nflzGYzKdIEi8V0lEuoc","question_images":[],"answer":"B","question_text":"A company is migrating a large amount of data from on-premises storage to AWS. Windows, Mac, and Linux based Amazon EC2 instances in the same AWS Region will access the data by using SMB and NFS storage protocols. The company will access a portion of the data routinely. The company will access the remaining data infrequently.\n\nThe company needs to design a solution to host the data.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","topic":"1","discussion":[{"poster":"ogerber","upvote_count":"18","content":"Selected Answer: B\nAmazon FsX for NetAPP ONTAP feature: Multi-protocol access to data using the Network File System (NFS), Server Message Block (SMB), and Internet Small Computer Systems Interface (iSCSI) protocols","timestamp":"1708242360.0","comment_id":"1153090"},{"comments":[{"comment_id":"1345229","content":"Initially I thought C is correct, but Windows, Mac, and Linux based Amazon EC2 instances in the same AWS Region will access the data by using SMB and NFS storage protocols, S3 does not provide the smb and NFS access to these ec2 instances, so c is incorrect, B is correct.","upvote_count":"3","timestamp":"1737622200.0","poster":"FlyingHawk"},{"comment_id":"1285524","comments":[{"content":"The company is MIGRATING data from on-premises to AWS. \n\nAmazon FSx for NetApp ONTAP offers high-performance file storage that’s broadly accessible from Linux, Windows, and macOS compute instances via the industry-standard NFS, SMB, iSCSI, and NVMe-over-TCP protocols.\n\nhttps://aws.amazon.com/fsx/netapp-ontap/features/","poster":"MatAlves","comment_id":"1285525","timestamp":"1726621020.0","upvote_count":"3"}],"upvote_count":"2","content":"\"S3 File Gateway is used for on-premises data intensive applications that need file protocol access to objects in S3. \"\n\nhttps://aws.amazon.com/storagegateway/file/s3/","poster":"MatAlves","timestamp":"1726620960.0"}],"poster":"jaswantn","content":"option C .... SMB and NFS storage protocols ->S3 file gateway","timestamp":"1707614880.0","comment_id":"1146914","upvote_count":"7"},{"timestamp":"1719496560.0","upvote_count":"2","content":"Selected Answer: B\nAnswer B","poster":"Scheldon","comment_id":"1238207"},{"upvote_count":"1","poster":"rjjkc","content":"Selected Answer: C\nI think it is \"C\"\nNot \"B\" - The question never indicates the company is using \"NetApp ONTAP file systems\", so I am not sure what it means by \"Migrate the data to the FSx for ONTAP volume\". Please correct if misunderstood.\n\"C\" clearly indicates how to migrate the data to S3, the S3 Intelligent-Tiering addressed the access pattern in the question and you can SMB/NFS mount S3 bucket \nhttps://docs.aws.amazon.com/filegateway/latest/files3/using-smb-fileshare.html\nhttps://docs.aws.amazon.com/filegateway/latest/files3/GettingStartedAccessFileShare.html","comment_id":"1215852","timestamp":"1716396180.0"},{"content":"Selected Answer: B\nFSx for ONTAP support NFS and SMB Protocol, even AWS Storage Gateway Amazon S3 File Gateway support them but it is used to connect on premises devices to file on s3, not to connect ec2 instances in the same aws region","poster":"TwinSpark","comment_id":"1212988","upvote_count":"3","timestamp":"1715967300.0"},{"poster":"Linuslin","content":"Selected Answer: B\nAmazon FSx for NetApp ONTAP provides fully managed shared storage in the AWS Cloud with the popular data access and management capabilities of ONTAP.\nMove workloads running on NetApp or other NFS/SMB/iSCSI servers to AWS without modifying application code or how you manage data.\nAnd FsX for NetAPP ONTAP support \"Reducing storage costs with automatic and intelligent storage tiering.\"\n\nhttps://aws.amazon.com/tw/fsx/netapp-ontap/faqs/#product-faqs#netapp-ontap-faq#reducing-storage-costs-with-automatic-and-intelligent-storage-tiering","timestamp":"1715750880.0","upvote_count":"4","comment_id":"1211766"},{"comment_id":"1184933","upvote_count":"1","content":"it's C","timestamp":"1711649400.0","poster":"camps"},{"content":"B - FSx for ONTAP support SMB and NFS","timestamp":"1711372980.0","poster":"TruthWS","comment_id":"1182491","upvote_count":"2"},{"poster":"alawada","comment_id":"1180200","timestamp":"1711126500.0","content":"Selected Answer: B\nAmazon FsX for NetAPP ONTAP feature: Multi-protocol access to data using the Network File System (NFS), Server Message Block (SMB), and Internet Small Computer Systems Interface (iSCSI) protocols\nOption C: make no sense I see it as a distractor","upvote_count":"2"},{"comment_id":"1177496","upvote_count":"2","timestamp":"1710862200.0","comments":[{"comment_id":"1190460","upvote_count":"1","content":"The company will access the remaining data infrequently.\"","poster":"rondelldell","timestamp":"1712416920.0"},{"content":"https://www.amazonaws.cn/en/storagegateway/faqs/#:~:text=The%20Amazon%20S3%20File%20Gateway,be%20directly%20accessed%20in%20S3.","upvote_count":"1","timestamp":"1710862260.0","comments":[{"poster":"dkw2342","timestamp":"1711296960.0","comment_id":"1181844","content":"It's B, option C makes no sense. \n\n1. \"Migrate the data to the S3 bucket using an AWS Storage Gateway Amazon S3 File Gateway.\" -> Nothing about running the gateway to access the files via SMB and NFS afterwards.\n\n2. Even if you ignore this, the S3 File Gateway requires a virtual appliance to be deployed (on EC2 in this case), which contradicts the \"LEAST operational overhead\" requirement.","upvote_count":"2"}],"poster":"Kezuko","comment_id":"1177497"}],"content":"Selected Answer: C\nBoth B and C works, but it seems like C has a least operational overhead","poster":"Kezuko"},{"timestamp":"1708495140.0","comment_id":"1155284","content":"Selected Answer: C\nOption C looks correct.\n\"The company will access a portion of the data routinely. The company will access the remaining data infrequently.\"","poster":"Indrasis","upvote_count":"3"},{"upvote_count":"2","comment_id":"1153920","timestamp":"1708346880.0","poster":"Appon","content":"Selected Answer: B\noption B"},{"poster":"MattBJ","timestamp":"1707821880.0","upvote_count":"3","comment_id":"1149106","content":"Selected Answer: C\nC is correct"},{"poster":"hajra313","upvote_count":"5","content":"Option A and D do not support SMB and NFS file system . Option b looks correvt","timestamp":"1707658140.0","comment_id":"1147250"},{"comment_id":"1141306","upvote_count":"1","poster":"Andy_09","content":"Option with S3 usage looks corrcet","timestamp":"1707153960.0"}],"unix_timestamp":1707153960,"answer_ET":"B","answers_community":["B (80%)","C (20%)"],"exam_id":31,"question_id":709,"answer_description":"","timestamp":"2024-02-05 18:26:00","url":"https://www.examtopics.com/discussions/amazon/view/132892-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"isMC":true,"choices":{"A":"Create an Amazon Elastic File System (Amazon EFS) volume that uses EFS Intelligent-Tiering. Use AWS DataSync to migrate the data to the EFS volume.","B":"Create an Amazon FSx for ONTAP instance. Create an FSx for ONTAP file system with a root volume that uses the auto tiering policy. Migrate the data to the FSx for ONTAP volume.","C":"Create an Amazon S3 bucket that uses S3 Intelligent-Tiering. Migrate the data to the S3 bucket by using an AWS Storage Gateway Amazon S3 File Gateway.","D":"Create an Amazon FSx for OpenZFS file system. Migrate the data to the new volume."}},{"id":"tfd1SlygGLY17FqTWwc7","discussion":[{"upvote_count":"46","content":"Selected Answer: D\n***CORRECT***\nThe correct answer is Option D. Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.\n\nBy deploying an S3 VPC gateway endpoint, the application can access the S3 buckets over a private network connection within the VPC, eliminating the need for data transfer over the internet. This can help reduce data transfer fees as well as improve the performance of the application. The endpoint policy can be used to specify which S3 buckets the application has access to.","poster":"Buruguduystunstugudunstuy","timestamp":"1671578280.0","comments":[{"poster":"Buruguduystunstugudunstuy","upvote_count":"13","content":"***WRONG***\nOption A, deploying Amazon API Gateway into a public subnet and adjusting the route table, would not address the issue of data transfer fees as the application would still be transferring data over the internet. \n\nOption B, deploying a NAT gateway into a public subnet and attaching an endpoint policy, would not address the issue of data transfer fees either as the NAT gateway is used to enable outbound internet access for instances in a private subnet, rather than for connecting to S3. \n\nOption C, deploying the application into a public subnet and allowing it to route through an internet gateway, would not reduce data transfer fees as the application would still be transferring data over the internet.","timestamp":"1671578280.0","comment_id":"751628"}],"comment_id":"751627"},{"content":"Selected Answer: D\nTo reduce costs get rid of NAT Gateway , VPC endpoint to S3","upvote_count":"24","comment_id":"696260","poster":"KVK16","timestamp":"1665927120.0"},{"upvote_count":"1","content":"D is the correct answer","timestamp":"1731008040.0","poster":"Gizmo2022","comment_id":"1308521"},{"timestamp":"1726395300.0","content":"Selected Answer: D\nAns D - remove the internet connection by using a more efficient private VPC direct to S3","upvote_count":"2","poster":"PaulGa","comment_id":"1284045"},{"content":"Selected Answer: D\nS3 VPC Gateway is the cheapest solution as it does not use any billable traffic within same region","timestamp":"1705253640.0","comment_id":"1122720","poster":"awsgeek75","upvote_count":"2"},{"timestamp":"1692073260.0","comment_id":"981276","poster":"TariqKipkemei","content":"Selected Answer: D\nPrevent traffic from traversing the internet = Gateway VPC endpoint for S3.","upvote_count":"1"},{"comment_id":"977972","content":"Selected Answer: D\nThe best solution to reduce data transfer costs for an application frequently accessing S3 buckets in the same region is option D - Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.\n\nThe key points:\n- S3 gateway endpoints allow private connections between VPCs and S3 without going over the public internet.\n- This avoids data transfer fees for traffic between the VPC and S3 within the same region.\n- An endpoint policy controls access to specific S3 buckets.","timestamp":"1691689920.0","upvote_count":"3","poster":"Guru4Cloud"},{"timestamp":"1687357200.0","content":"Selected Answer: D\nA. API Gateway can serve as a proxy for S3 requests, it adds unnecessary complexity and additional costs compared to a direct VPC endpoint.\n\nB. Using a NAT gateway for accessing S3 introduces unnecessary data transfer costs as traffic would still flow over the internet.\n\nC. This approach would incur data transfer fees as the traffic would go through the public internet.\n\nIn comparison, option D using an S3 VPC gateway endpoint provides a direct and cost-effective solution for accessing S3 buckets within the same Region. By keeping the data transfer within the AWS network infrastructure, it helps reduce data transfer fees and provides secure access to the S3 resources.","upvote_count":"3","comment_id":"929617","poster":"cookieMr"},{"content":"Selected Answer: D\nOption D is correct answer.","upvote_count":"1","comment_id":"916163","timestamp":"1686049140.0","poster":"Bmarodi"},{"upvote_count":"1","comment_id":"794102","content":"To answer this question, I need to know the comparison of the types of gateway of costs, please give me a tip about that issue.","timestamp":"1675167120.0","poster":"Erbug"},{"upvote_count":"1","timestamp":"1671414540.0","comment_id":"749347","poster":"career360guru","content":"Selected Answer: D\nOption D"},{"poster":"9014","comment_id":"741854","content":"Selected Answer: D\nThe answer is D:- Actually, the Application (EC2) is running in the same region...instead of going to the internet, data can be copied through the VPC endpoint...so there will be no cost because data is not leaving the AWS infra","upvote_count":"1","timestamp":"1670773560.0"},{"timestamp":"1670400180.0","poster":"JayBee65","upvote_count":"2","comment_id":"737556","comments":[{"poster":"SR0611","content":"Yes correct","upvote_count":"1","timestamp":"1670495820.0","comment_id":"738897"}],"content":"Can somebody please explain this question? Are we assuming the application is running in AWS and that adding the gateway endpoint avoids the need for the EC2 instance to access the internet and thus avoid costs? Thanks a lot."},{"poster":"Wpcorgan","upvote_count":"1","comment_id":"723649","content":"D is correct","timestamp":"1669042560.0"},{"content":"Selected Answer: D\nFYI : \n-There is no additional charge for using gateway endpoints.\n-Interface endpoints are priced at ~ $0.01/per AZ/per hour. Cost depends on the Region\n- S3 Interface Endpoints resolve to private VPC IP addresses and are routable from outside the VPC (e.g via VPN, Direct Connect, Transit Gateway, etc). S3 Gateway Endpoints use public IP ranges and are only routable from resources within the VPC.","comment_id":"701580","upvote_count":"5","timestamp":"1666449000.0","poster":"yd_h"},{"comment_id":"697537","poster":"123jhl0","timestamp":"1666021560.0","upvote_count":"3","content":"Selected Answer: D\nClose question to the Question #4, with same solution."}],"answer_ET":"D","answer":"D","answers_community":["D (100%)"],"question_images":[],"answer_description":"","isMC":true,"timestamp":"2022-10-16 15:32:00","question_id":710,"url":"https://www.examtopics.com/discussions/amazon/view/85604-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"question_text":"A company runs a photo processing application that needs to frequently upload and download pictures from Amazon S3 buckets that are located in the same AWS Region. A solutions architect has noticed an increased cost in data transfer fees and needs to implement a solution to reduce these costs.\nHow can the solutions architect meet this requirement?","choices":{"C":"Deploy the application into a public subnet and allow it to route through an internet gateway to access the S3 buckets.","D":"Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.","B":"Deploy a NAT gateway into a public subnet and attach an endpoint policy that allows access to the S3 buckets.","A":"Deploy Amazon API Gateway into a public subnet and adjust the route table to route S3 calls through it."},"unix_timestamp":1665927120,"exam_id":31,"topic":"1"}],"exam":{"provider":"Amazon","isImplemented":true,"lastUpdated":"11 Apr 2025","id":31,"name":"AWS Certified Solutions Architect - Associate SAA-C03","numberOfQuestions":1019,"isBeta":false,"isMCOnly":true},"currentPage":142},"__N_SSP":true}