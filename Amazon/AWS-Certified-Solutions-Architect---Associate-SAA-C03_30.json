{"pageProps":{"questions":[{"id":"3STokfscXKVNgEQDd6rf","exam_id":31,"isMC":true,"topic":"1","choices":{"D":"Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag.","A":"Use AWS CloudTrail to generate a list of resources with the application tag.","C":"Run a query in Amazon CloudWatch Logs Insights to report on the components with the application tag.","B":"Use the AWS CLI to query each service across all Regions to report the tagged components."},"question_text":"A company hosts multiple production applications. One of the applications consists of resources from Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service (Amazon SNS), and Amazon Simple Queue Service (Amazon SQS) across multiple AWS Regions. All company resources are tagged with a tag name of “application” and a value that corresponds to each application. A solutions architect must provide the quickest solution for identifying all of the tagged components.\n\nWhich solution meets these requirements?","unix_timestamp":1673670420,"question_id":146,"discussion":[{"comment_id":"936344","upvote_count":"25","content":"Selected Answer: D\nA is not the quickest solution because CloudTrail primarily focuses on capturing and logging API activity. While it can provide information about resource changes, it may not provide a comprehensive and quick way to identify all the tagged components across multiple services and Regions.\n\nB involves manually querying each service using the AWS CLI, which can be time-consuming and cumbersome, especially when dealing with multiple services and Regions. It is not the most efficient solution for quickly identifying tagged components.\n\nC is focused on analyzing logs rather than directly identifying the tagged components. While CloudWatch Logs Insights can help extract information from logs, it may not provide a straightforward and quick way to gather a consolidated list of all tagged components across different services and Regions.\n\nD is the quickest solution as it leverages the Resource Groups Tag Editor, which is specifically designed for managing and organizing resources based on tags. It offers a centralized and efficient approach to generate a report of tagged components across multiple services and Regions.","poster":"cookieMr","timestamp":"1687941300.0"},{"timestamp":"1739805720.0","poster":"satyaammm","comment_id":"1357832","upvote_count":"1","content":"Selected Answer: D\nD is the most suitable here."},{"comment_id":"1314015","poster":"JA2018","content":"Selected Answer: D\nTo use the AWS Resource Groups Tag Editor to locate resources with specific tags, you can:\n\n1. Open the Tag Editor console\n2. Select the AWS regions to search in\n3. Choose a resource type\n4. Enter a tag key or key and value pair in the Tags fields\n5. Select Add or press Enter to finish \n\nhttps://docs.aws.amazon.com/tag-editor/latest/userguide/find-resources-to-tag.html#:~:text=To%20find%20resources%20to%20tag,are%20returned%20by%20the%20query.","upvote_count":"2","timestamp":"1731937440.0"},{"poster":"TariqKipkemei","upvote_count":"3","timestamp":"1695187380.0","content":"Selected Answer: D\nTags are key and value pairs that act as metadata for organizing your AWS resources","comment_id":"1011939"},{"poster":"Guru4Cloud","upvote_count":"4","timestamp":"1694455080.0","comment_id":"1005070","content":"Selected Answer: D\nD. Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag"},{"poster":"Bmarodi","timestamp":"1685076120.0","upvote_count":"3","content":"Selected Answer: D\nA solutions architect can provide the quickest solution for identifying all of the tagged components by running running a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag, hence the option D is right answer.","comment_id":"907042"},{"timestamp":"1678827540.0","content":"Selected Answer: D\nThe answer is D","upvote_count":"3","comment_id":"839281","poster":"Dondozzy"},{"timestamp":"1674986580.0","content":"Selected Answer: D\nD가 맞습니다.","upvote_count":"2","comment_id":"791535","poster":"sh0811"},{"upvote_count":"4","poster":"Training4aBetterLife","comment_id":"789141","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/tag-editor/latest/userguide/tagging.html","timestamp":"1674771180.0"},{"content":"Answer is D.","upvote_count":"2","comment_id":"779888","poster":"Rudraman","timestamp":"1674039000.0"},{"content":"Selected Answer: D\nvalidated \nhttps://docs.aws.amazon.com/tag-editor/latest/userguide/tagging.html","timestamp":"1673875260.0","poster":"techhb","comment_id":"777688","upvote_count":"2"},{"timestamp":"1673687520.0","comment_id":"775212","poster":"kbaruu","upvote_count":"2","content":"Selected Answer: D\nD is correct"},{"upvote_count":"2","content":"Selected Answer: D\nhttps://www.examtopics.com/discussions/amazon/view/51352-exam-aws-certified-solutions-architect-associate-saa-c02/","timestamp":"1673670420.0","poster":"waiyiu9981","comment_id":"775084"}],"answer_images":[],"answer_ET":"D","question_images":[],"answers_community":["D (100%)"],"answer":"D","answer_description":"","timestamp":"2023-01-14 05:27:00","url":"https://www.examtopics.com/discussions/amazon/view/95145-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"bt4rs1Vrk2e9OkpjP35i","unix_timestamp":1673714940,"discussion":[{"timestamp":"1673875500.0","poster":"techhb","upvote_count":"21","comments":[{"poster":"Devsin2000","upvote_count":"6","content":"https://aws.amazon.com/getting-started/hands-on/getting-started-using-amazon-s3-intelligent-tiering/","timestamp":"1683503820.0","comment_id":"891727"}],"comment_id":"777695","content":"Selected Answer: A\nS3 Intelligent-Tiering monitors access patterns and moves objects that have not been accessed for 30 consecutive days to the Infrequent Access tier and after 90 days of no access to the Archive Instant Access tier."},{"content":"Selected Answer: A\nI think it cannot be clearly answered because we know that the 'access pattern is variable and changes rapidly', but ultimately it depends on the total number and volume of accesses. All four options meet the \"not increase retrieval time\" requirement (even Glacier Instant Retrieval has \"the same latency and access time as S3 Standard\"). If data would be rarely accessed, B would be cheapest. If it would be constantly accessed, C would be cheapest (we'd pay the Intelligent Tiering fee but it would never move anything to a cheaper tier). Inbetween it would be D.\n\nBut I guess the key is Amazon's clear recommendation to use Intelligent Tiering (A) for \"unknown or changing access\" patterns, which matches the statement in the question.","upvote_count":"10","comment_id":"1106756","poster":"pentium75","timestamp":"1703678340.0"},{"poster":"satyaammm","comment_id":"1357833","upvote_count":"1","timestamp":"1739805840.0","content":"Selected Answer: A\nS3 intelligent tiering is the most suitable for unpredictable workloads."},{"timestamp":"1737921840.0","content":"Selected Answer: A\nS3 Intelligent-Tiering dynamically optimizes storage costs for changing access patterns, ensuring immediate availability and cost-efficiency, which makes it the best fit for the given requirements.\n\nWhy not the other options?\n\nB. S3 Glacier Instant Retrieval:\nWhile it provides low retrieval latency, Glacier storage classes are optimized for archival data with infrequent access, not for variable and potentially high-frequency access patterns.\n\nC. S3 Standard:\nThis provides immediate availability but is more expensive than Intelligent-Tiering for data with unpredictable access patterns.\n\nD. S3 Standard-Infrequent Access (S3 Standard-IA):\nS3 Standard-IA is optimized for data that is accessed infrequently but requires immediate availability. However, if the access pattern is variable or frequent, it could lead to higher costs due to retrieval and access fees.","upvote_count":"1","comment_id":"1347087","poster":"iamroyalty_k"},{"upvote_count":"2","timestamp":"1737678900.0","poster":"skybrink","content":"Selected Answer: D\nA. S3 Intelligent-Tiering:\n\nIntelligent-Tiering automatically moves data between storage tiers based on access patterns. However, it incurs additional monitoring and automation costs. For data with a short, predictable retention period (3 months), S3 Standard-IA is more cost-effective.\nB. S3 Glacier Instant Retrieval:\n\nAlthough Glacier Instant Retrieval offers low-latency access at a lower cost than Standard-IA, it is more suited for archival workloads where retrieval is rare. It is not ideal for workloads with variable access patterns like this one.\nC. S3 Standard:\n\nS3 Standard provides low-latency access, but it is more expensive than S3 Standard-IA for infrequently accessed data. It is better suited for frequently accessed data.","comment_id":"1345732"},{"timestamp":"1724463840.0","upvote_count":"1","comment_id":"1271489","poster":"ensbrvsnss","content":"Selected Answer: B\nInstant"},{"timestamp":"1716902700.0","poster":"lofzee","comment_id":"1220290","content":"Selected Answer: A\nunknown / changing access patterns = intelligent tiering. memorise","upvote_count":"4"},{"timestamp":"1714920000.0","upvote_count":"3","content":"Selected Answer: A\nUnpredictable access pattern - Intelligent tiering","poster":"ManikRoy","comment_id":"1206928"},{"timestamp":"1713102900.0","poster":"MehulKapadia","upvote_count":"3","comment_id":"1195551","content":"Selected Answer: A\nCorrect Answer A:\nWhen data access pattern is not known then Intelligent-tiering can help by monitoring data-access pattern and move object internally accordingly an still ensure faster retrieval. Also There is no object retrieval fees/changes for S3 Intelligent Tier(So cost savings).\n\nOption C is not a valid answer because name itself says Infrequent Access(IA): S3 Standard-IA is for data that is accessed less frequently."},{"comment_id":"1182843","timestamp":"1711410840.0","content":"Selected Answer: C\nImmediate Availability: S3 Standard provides immediate access to the data upon upload. This ensures that the exported database is immediately available for other teams to access without any retrieval delays.\n\nVariable Access Pattern: S3 Standard is designed to handle variable access patterns efficiently. It can accommodate rapid changes in access patterns without any impact on performance or latency.\n\nRetention Period: S3 Standard is suitable for storing data that needs to remain accessible for up to 3 months. It does not have any retrieval fees or delays, making it ideal for this scenario where immediate access is required.","upvote_count":"3","poster":"Uzbekistan"},{"upvote_count":"1","timestamp":"1710250680.0","comments":[{"upvote_count":"2","comment_id":"1171736","content":"Given just the uncertain access patterns AND limited storage time, I would argue in favor of simple S3 Standard.\nIf the question mentioned that the pattern of access varies across objects, but is relatively consistent for the individual objects, intelligent tiering may be worth it. Otherwise you just pay more to have objects monitored for Infrequent Access, and then suddenly become popular after being moved.","timestamp":"1710251160.0","poster":"escalibran"}],"comment_id":"1171730","content":"Feels like half the scenario or answers are missing. Where's the \"remove objects after 90 days\"? Intelligent Tiering has an upcharge for the provided convenience - does it even make sense, when objects won't remain long enough to be archived? \nOther classes trade storage cost for request costs. Dependent on how often objects are queried, IA might make sense. Even Glacier Instant Retrieval could come out ahead, given minimal access (and it has 90 days minimum storage duration, exact fit for the description).\n\nWith no further details provided, this is just throwing darts blindly.","poster":"escalibran"},{"content":"A is the perfect answer - The S3 access pattern for the data is variable and changes rapidly.","upvote_count":"2","comment_id":"1148016","timestamp":"1707737520.0","poster":"MrPCarrot"},{"upvote_count":"2","timestamp":"1707396780.0","content":"Selected Answer: A\nWith regard to \"The S3 access pattern for the data is variable and changes rapidly\" \nEven though Answer B cooudl fifull some requirements, Answer A is For long-lived data that have unpredictable access patterns.","poster":"bujuman","comment_id":"1144455"},{"comment_id":"1124589","content":"Selected Answer: B\n\"immediately available\" =>\nD is not immediately, and for cost B < A/C","upvote_count":"3","poster":"theochan","timestamp":"1705449120.0"},{"upvote_count":"3","content":"Selected Answer: B\nhttps://aws.amazon.com/s3/storage-classes/glacier/instant-retrieval/\n\"Amazon S3 Glacier Instant Retrieval is an archive storage class that delivers the lowest-cost storage for long-lived data that is rarely accessed and requires retrieval in milliseconds\"","comment_id":"1064626","poster":"VladanO","timestamp":"1699345260.0"},{"content":"Selected Answer: A\nA. El patrón de acceso a los datos es variable y cambia rápidamente = S3 Intelligent-Tiering","poster":"ivan_riqueros12","comment_id":"1048993","timestamp":"1697824680.0","upvote_count":"1"},{"timestamp":"1697098620.0","upvote_count":"4","content":"very important note , S3 Intelligent-Tiering got no retrival charges","poster":"Abdou1604","comment_id":"1041546"},{"content":"Selected Answer: A\naccess pattern for the data is variable and changes rapidly = S3 Intelligent-Tiering","poster":"TariqKipkemei","comment_id":"1011941","timestamp":"1695187620.0","upvote_count":"4"},{"content":"Selected Answer: C\nThere are 2 viable options A and C. \nThe Intelligent tearing(A) might put your data in the archive or Infrequent Acces if it is not used for 80 days and then used as crazy for the last 10 days of the period which will cause delays in retrieval or the costs associated with traffic.\nOption C can be optimised with the Time To Live policy of 90 days and will e the most efficient and reliable solution to satisfy the needs.","upvote_count":"4","comments":[{"content":"Lifecycle policies apply to all tiers, you can have data deleted or archived after 3 months regardless whether it is in Standard or Intelligent-Tiering.","upvote_count":"2","timestamp":"1703678400.0","poster":"pentium75","comment_id":"1106759"}],"comment_id":"994847","timestamp":"1693463700.0","poster":"Sultanoid"},{"upvote_count":"2","poster":"mtmayer","comment_id":"969432","content":"Has to be C. S3 Intelligent-Tiering is for data with varying or unknown access needs. Not the case here. We know data must be highly available for 30 days.","comments":[{"upvote_count":"3","comment_id":"1106760","poster":"pentium75","content":"Isn't \"varying or unknown access needs\" the same as \"the access pattern is variable and changes rapidly\"?","timestamp":"1703678460.0"}],"timestamp":"1690926660.0"},{"timestamp":"1688552100.0","poster":"maheshudara","upvote_count":"2","comment_id":"943568","content":"Selected Answer: A\nkey - \"Changing access patterns\"","comments":[{"poster":"maheshudara","timestamp":"1688552280.0","comment_id":"943570","upvote_count":"2","content":"\"The S3 access pattern for the data is variable and changes rapidly\""}]},{"upvote_count":"4","timestamp":"1687941420.0","comment_id":"936351","poster":"cookieMr","content":"Selected Answer: A\nOption A is designed for objects with changing access patterns, but it may not be the most cost-effective solution for long-term storage of the data, especially if the access pattern is variable and changes rapidly.\n\nOption B is optimized for long-term archival storage and may not provide the immediate accessibility required by the company. Retrieving data from Glacier storage typically incurs a longer retrieval time compared to other storage classes.\n\nOption C is the appropriate choice for immediate availability and quick access to the data. It offers high durability, availability, and low latency access, making it suitable for the company's needs. However, it is not the most cost-effective option for long-term storage.\n\nOption D is a more cost-effective storage class compared to S3 Standard, especially for data that is accessed less frequently. However, since the access pattern for the data is variable and changes rapidly, S3 Standard-IA may not be the most cost-effective solution, as it incurs additional retrieval fees for frequent access."},{"comment_id":"926322","timestamp":"1687043460.0","content":"Answer A: S3 Intelligent-Tiering is the recommended storage class for data with unknown, changing, or unpredictable access patterns, independent of object size or retention period, such as data lakes, data analytics, and new applications.","upvote_count":"2","poster":"markw92"},{"upvote_count":"2","poster":"AlankarJ","content":"The questions specifically says, data should me immediately available. So D can’t be true as S3 Infrequent access is for data which is not accessed frequently. Don’t forget upto 3 months.","timestamp":"1686051900.0","comment_id":"916194"},{"timestamp":"1684920480.0","content":"Selected Answer: A\nAmazon S3 Intelligent-Tiering is the only cloud storage class that delivers automatic storage cost savings when data access patterns change, without performance impact or operational overhead","comment_id":"905712","upvote_count":"2","poster":"ruqui"},{"poster":"ErfanKh","comments":[{"comment_id":"898702","timestamp":"1684182780.0","content":"ChatGPT is not always correct. Use your intelligence to answer questions","poster":"studynoplay","upvote_count":"3"},{"timestamp":"1686354840.0","poster":"mahejosh","comment_id":"919687","content":"ChatGpt is cheeks, eff that","upvote_count":"1"},{"comment_id":"935976","timestamp":"1687916460.0","upvote_count":"1","poster":"ALLVCAP01","content":"chatgpt isn't perfect yet. Most of them are wrong when it comes to problems."}],"timestamp":"1681186860.0","upvote_count":"1","comment_id":"866913","content":"Selected Answer: D\nI think D and ChatGPT says D as well"},{"content":"Definitely A","comment_id":"844442","upvote_count":"2","timestamp":"1679279580.0","poster":"Grace83"},{"poster":"Russs99","timestamp":"1678830720.0","content":"Selected Answer: D\nD is the correct answer for this use case","comment_id":"839330","upvote_count":"1"},{"poster":"neosis91","comments":[{"comment_id":"1106761","upvote_count":"2","poster":"pentium75","timestamp":"1703678520.0","content":"Intelligent Tiering does NOT 'introduce additional latency' at least within 3 month.\n\nAlso, we know that access is 'variable and changes rapidly', we do NOT know if it is \"infrequent\"."}],"upvote_count":"3","timestamp":"1675931340.0","comment_id":"802974","content":"Selected Answer: D\nResponse D, not A\nS3 Intelligent-Tiering is a cost-optimized storage class that automatically moves data to the most cost-effective access tier based on changing access patterns. Although it offers cost savings, it also introduces additional latency and retrieval time into the data retrieval process, which may not meet the requirement of \"immediately available\" data.\n\nOn the other hand, S3 Standard-Infrequent Access (S3 Standard-IA) provides low cost storage with low latency and high throughput performance. It is designed for infrequently accessed data that can be recreated if lost, and can be retrieved in a timely manner if required. It is a cost-effective solution that meets the requirement of immediately available data and remains accessible for up to 3 months."},{"timestamp":"1674039120.0","content":"Changes rapidly and immidiately available so Answe is AAAAA.","upvote_count":"5","poster":"Rudraman","comment_id":"779890"},{"timestamp":"1673880240.0","poster":"Aninina","content":"Selected Answer: A\nA looks correct","upvote_count":"4","comment_id":"777792"},{"upvote_count":"5","comment_id":"775966","content":"Selected Answer: A\n\"The S3 access pattern for the data is variable and changes rapidly\" => Use S3 intelligent tiering with smart enough to transit the prompt storage class.","poster":"Parsons","timestamp":"1673734200.0"},{"timestamp":"1673714940.0","comments":[{"comment_id":"779577","content":"The correct answer is A.\nThe S3 access pattern for the data is variable and changes rapidly.","poster":"Joxtat","upvote_count":"6","timestamp":"1674012660.0"}],"content":"Selected Answer: D\nD. S3 Standard-Infrequent Access (S3 Standard-IA)\n\nS3 Standard-IA is the most cost-effective storage class that meets the company's requirements. It provides immediate access to the data, and the data remains accessible for up to 3 months. S3 Standard-IA is optimized for infrequently accessed data, which is suitable for the company's use case of exporting the database once a day. This storage class also has a lower retrieval fee compared to S3 Glacier, which is important for the company as the S3 access pattern for the data is variable and changes rapidly. S3 Intelligent-Tiering and S3 Standard are not the best choice in this case because they are designed for frequently accessed data and have higher retrieval fees","upvote_count":"2","poster":"mhmt4438","comment_id":"775746"}],"url":"https://www.examtopics.com/discussions/amazon/view/95300-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"A","answers_community":["A (77%)","10%","8%"],"question_id":147,"answer_images":[],"topic":"1","choices":{"A":"S3 Intelligent-Tiering","B":"S3 Glacier Instant Retrieval","C":"S3 Standard","D":"S3 Standard-Infrequent Access (S3 Standard-IA)"},"answer_ET":"A","question_images":[],"timestamp":"2023-01-14 17:49:00","exam_id":31,"answer_description":"","isMC":true,"question_text":"A company needs to export its database once a day to Amazon S3 for other teams to access. The exported object size varies between 2 GB and 5 GB. The S3 access pattern for the data is variable and changes rapidly. The data must be immediately available and must remain accessible for up to 3 months. The company needs the most cost-effective solution that will not increase retrieval time.\n\nWhich S3 storage class should the company use to meet these requirements?"},{"id":"qZ85FusKn9cdl00p0tlq","answer_description":"","answer":"A","unix_timestamp":1673715360,"discussion":[{"content":"Selected Answer: A\nBy configuring AWS WAF rules and associating them with the ALB, the company can filter and block malicious traffic before it reaches the application. AWS WAF offers pre-configured rule sets and allows custom rule creation to protect against common vulnerabilities like XSS and SQL injection.\n\nOption B does not provide the necessary security and traffic filtering capabilities to protect against application-level attacks. It is more suitable for hosting static content rather than implementing security measures.\n\nOption C is focused on DDoS protection rather than application-level attacks like XSS or SQL injection. While AWS Shield Advanced does not address the specific requirements mentioned in the scenario.\n\nOption D involves maintaining and securing additional infrastructure, which goes against the requirement of reducing responsibility and relying on minimal operational staff.","comment_id":"936363","poster":"cookieMr","upvote_count":"19","timestamp":"1687941840.0"},{"content":"Selected Answer: C\nC --- Read and understand the question. *The company needs to reduce its share of responsibility in managing, updating, and securing servers for its AWS environment* Go with AWS Shield advanced --This is a managed service that includes AWS WAF, custom mitigations, and DDoS insight.","poster":"ShinobiGrappler","timestamp":"1673924760.0","comment_id":"778499","comments":[{"content":"I dont know how this comment gets 11x upvotes.\nA.To filter traffic and protect against application attacks like cross-site scripting and SQL injection, the company can use AWS Web Application Firewall with managed rules on the Application Load Balancer. This provides security with minimal infrastructure and operations overhead.","upvote_count":"30","poster":"Guru4Cloud","timestamp":"1694455020.0","comment_id":"1005066"},{"poster":"pentium75","timestamp":"1703678700.0","content":"Read the understand the question. The company needs protection \"against common application-level (!) attacks\" which is provided by a Layer 7 service like WAF. AWS Shield Advanced protects from network-level (!) attacks.","comment_id":"1106764","upvote_count":"8"},{"comment_id":"1273433","upvote_count":"4","poster":"AWSSURI","content":"Have you read and understood the question first!! It says application-level attacks such as cross -site scripting, SQL injection which automatically points to AWS WAF \nGo to this link and look at AWS WAF benefits https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html","timestamp":"1724763360.0"},{"poster":"abriggy","comment_id":"1253642","content":"WRONG. Answer is A. Don't let all these upvotes fool you","upvote_count":"4","timestamp":"1721737020.0"},{"poster":"arjundevops","comment_id":"876107","timestamp":"1682040120.0","upvote_count":"4","content":"Brother answer is A, Read the question once again or ask CHATGPT for more in-depth analysis"},{"content":"I agree, both A and C answer the first demand ,where A is answer to the technical request., but for reducing responsibility you will need shield advance - meaning C.","upvote_count":"2","comment_id":"1055408","timestamp":"1698400440.0","comments":[{"poster":"pentium75","timestamp":"1703678760.0","comment_id":"1106766","upvote_count":"4","content":"No because this is about application-level attacks wich requires WAF aka answer A."}],"poster":"rokeus"},{"timestamp":"1677615960.0","content":"You stated, \"This is a managed service that includes AWS WAF, custom mitigations, and DDoS insight.\" and you are correct. However, the service you would actually have to setup to prevent SQL injection attacks is WAF.","poster":"Steve_4542636","comments":[{"upvote_count":"4","content":"exactly, thats like saying lets implemented NEtwork firewall Manager to manage WAF, absurd!","poster":"darn","timestamp":"1682196300.0","comment_id":"877636"}],"upvote_count":"11","comment_id":"825241"}],"upvote_count":"19"},{"comment_id":"1357834","content":"Selected Answer: A\nAWS WAF is the most suitable for Application Level attacks like Cross Site Scripting and SQL Injection attacks.","poster":"satyaammm","timestamp":"1739805960.0","upvote_count":"1"},{"poster":"toyaji","timestamp":"1724030700.0","upvote_count":"2","comment_id":"1268295","content":"Selected Answer: C\nMost of all, A and C are both available technically, right? So the point of question is not about technical posibility. Its about \"share of the respoinsibility\" which is intended to ask of which service provides \"Support Plan\" - AWS Shield Response Team (SRT)"},{"timestamp":"1719462180.0","upvote_count":"2","comment_id":"1237870","poster":"ChymKuBoy","content":"Selected Answer: A\nA for sure"},{"content":"Selected Answer: A\nAWS Shield Advanced for DDoS Attacks and not SQL injection which is protected by AWS WAF","comment_id":"1235346","poster":"a7md0","upvote_count":"2","timestamp":"1719054540.0"},{"timestamp":"1714920120.0","poster":"ManikRoy","comment_id":"1206929","content":"Selected Answer: A\nAWS WAF with managed rules.","upvote_count":"2"},{"timestamp":"1714885800.0","poster":"Solomon2001","upvote_count":"3","content":"Explanation:\n\nOption A:\nAWS WAF (Web Application Firewall) provides protection against common web exploits by allowing you to create rules that block common attack patterns such as SQL injection and cross-site scripting (XSS).\nBy associating AWS WAF rules with the ALB, you can protect your application from these types of attacks without managing, updating, and securing servers yourself.\nAWS WAF is a managed service, so it reduces the operational overhead for the company.\n\nOption C:\n\nAWS Shield Advanced provides DDoS protection, but it doesn't include application-level protection like AWS WAF does.","comment_id":"1206779"},{"upvote_count":"2","timestamp":"1712759820.0","content":"If you read SQL Injection, Cross-site scripting >>> Always look for: WAF","comment_id":"1193079","poster":"sandordini"},{"upvote_count":"3","poster":"bujuman","comment_id":"1144601","content":"Selected Answer: A\nThis is confusing \"The company needs to reduce its share of the responsibility in managing, updating, and securing servers for its AWS environment.\" But could be acheived when using WAF and AWS managed Rules.","timestamp":"1707404760.0"},{"timestamp":"1706698080.0","upvote_count":"2","comment_id":"1136688","content":"Selected Answer: A\nA is the answer.","poster":"thewalker"},{"content":"Selected Answer: A\nAWS Shield Advanced does not directly protect against XSS (cross-site scripting) or SQL injection attacks. It focuses on defending against Distributed Denial of Service (DDoS) attacks, which aim to overwhelm resources and disrupt availability.","poster":"farnamjam","comment_id":"1126506","timestamp":"1705648680.0","upvote_count":"2"},{"timestamp":"1704119400.0","upvote_count":"3","content":"Selected Answer: A\nS makes more sense as Shield Advanced (which actually contains WAF) doesn't provide any additional benefits apart from networks protection. WAF will still have to be configured. So just use WAF to fulfil the requirements.","poster":"awsgeek75","comment_id":"1111258"},{"poster":"pentium75","comment_id":"1106772","timestamp":"1703679060.0","content":"Selected Answer: A\nYou need to \"configure AWS WAF rules and associate them with the ALB\" which is A. AWS Shield Advance INTEGRATES with WAF, so you can manage WAF through Shield Advanced, but still you would need to set it up and configure rules, which C does not mention.","upvote_count":"5"},{"comment_id":"1094806","timestamp":"1702403580.0","upvote_count":"1","comments":[{"timestamp":"1703678880.0","upvote_count":"2","comment_id":"1106771","poster":"pentium75","content":"\"Shield Advanced provides ... integration (!) with AWS WAF\", but you still need WAF. And you need WAF rules, whereever you configure them."}],"poster":"[Removed]","content":"AWS Shield is not only DDos and it handle Layer 3 and layer 4 including AWS WAF so C should match."},{"content":"Selected Answer: A\nAWS WAF helps you protect against common web exploits and bots that can affect availability, compromise security, or consume excessive resources. Protect against vulnerabilities and exploits such as SQL injection or Cross site scripting attacks.","comment_id":"1011943","upvote_count":"6","poster":"TariqKipkemei","timestamp":"1695187980.0"},{"upvote_count":"3","poster":"Undisputed","content":"Selected Answer: A\nTo achieve proper traffic filtering and protect the Application Load Balancer (ALB) against common application-level attacks, such as cross-site scripting (XSS) or SQL injection, while minimizing infrastructure and operational overhead, the company can consider using AWS Web Application Firewall (WAF) with AWS Managed Rules.","timestamp":"1690505160.0","comment_id":"965199"},{"upvote_count":"4","poster":"vini15","comment_id":"954712","timestamp":"1689637380.0","content":"A-- Keywords(cross-site scripting or SQL injection)"},{"timestamp":"1688396340.0","upvote_count":"2","poster":"animefan1","comment_id":"941964","content":"Selected Answer: A\nWAF benefits are rules, SQL injection & XSS protection"},{"upvote_count":"5","content":"Selected Answer: A\nNot C because- WS Shield Advanced provides DDoS protection, it does not specifically address application-level attacks such as XSS or SQL injection","timestamp":"1688139360.0","comment_id":"939190","poster":"sbnpj"},{"poster":"fishy_resolver","content":"Selected Answer: C\nWith Shield advanced you get centralized protection management; this allows you to use AWS firewall manager (included in AWS Shield) with policies automatically apply WAF to appliances. Massive sales pitch, see the link: https://aws.amazon.com/shield/features/","upvote_count":"1","comment_id":"918992","timestamp":"1686293100.0"},{"content":"Selected Answer: A\nShield is not aimed to handle SQL injection.","upvote_count":"2","timestamp":"1684460460.0","comment_id":"901597","poster":"Terry_123"},{"poster":"studynoplay","upvote_count":"4","timestamp":"1684183080.0","content":"Selected Answer: A\nWAF = cross-site scripting or SQL injection\nShield/Shield Advanced = DDoS","comment_id":"898705"},{"upvote_count":"4","comment_id":"889362","content":"Selected Answer: A\nEven with AWS Shield Advanced, you would still need to configure AWS WAF (only it's costing is included with Shield Adv.) rules to protect against common application-level attacks such as cross-site scripting or SQL injection. \n\nSince, there is no mention of protection against DDoS attacks, C is a more costly and not useful.","timestamp":"1683205620.0","poster":"Abhineet9148232"},{"timestamp":"1682387520.0","comment_id":"879818","upvote_count":"3","content":"Selected Answer: A\nWAF == application-level attacks, such as cross-site scripting or SQL injection\nA","poster":"SkyZeroZx"},{"content":"Selected Answer: A\nAnswer is A, WAF will protect the infra from CSS typing of injections\nwhile Sheild will be used to protect Infra from DDOS attacks\n\nDont get Confused.\n\nonly trick to get the right answer for the question is\nread the question multiple times even when you are very confident about the answer you chose on first attempt","poster":"arjundevops","upvote_count":"5","timestamp":"1682040060.0","comment_id":"876105"},{"upvote_count":"2","content":"Answer is A","poster":"Kenzo","timestamp":"1680327240.0","comment_id":"857600"},{"content":"Selected Answer: A\nAWS WAF projects against SQL injection.","upvote_count":"1","timestamp":"1680190020.0","comment_id":"855914","poster":"[Removed]"},{"content":"CCCCCCCCCCCCCCCCCCCCC","timestamp":"1680066120.0","poster":"supppp","comment_id":"854018","upvote_count":"1"},{"comment_id":"851268","upvote_count":"2","timestamp":"1679848740.0","poster":"MssP","content":"Selected Answer: A\nLook at this https://repost.aws/knowledge-center/waf-rule-prevent-sqli-xss"},{"content":"Using AWS WAF has several benefits:\n.... \nPresence of SQL code that is likely to be malicious (known as SQL injection).\nPresence of a script that is likely to be malicious (known as cross-site scripting).","upvote_count":"2","poster":"udo2020","comment_id":"848016","timestamp":"1679563860.0"},{"poster":"ashu089","comment_id":"846738","upvote_count":"2","timestamp":"1679467200.0","content":"A...AWS WAF is a managed service that allows companies to protect their web applications from web exploits that might affect their applications, including SQL injection and cross-site scripting. It provides an easy-to-use interface to configure, monitor, and manage web access control for applications running on AWS. AWS WAF works with Amazon CloudFront and Application Load Balancer, making it easy to deploy security policies for your web applications."},{"poster":"Grace83","comment_id":"844446","timestamp":"1679280360.0","upvote_count":"2","content":"AAAAAAA. WAF - CF Application Load Balancer, API Gateway & AWS AppSync"},{"poster":"CapJackSparrow","comment_id":"839038","upvote_count":"2","content":"reading up on AWS Shield Advanced, and I don't see anything regarding them help with managing or updating servers. Yes WAF integrates with SA for free but when all you need is WAF, and IF SA does not help with reducing your server management, why pay for SA... it is very expensive.","timestamp":"1678811520.0"},{"timestamp":"1678205520.0","comment_id":"832091","poster":"Nel8","upvote_count":"4","content":"Selected Answer: A\nSelected Answer: A\n\"The company must implement proper traffic filtering to protect its Application Load Balancer (ALB) against common application-level attacks, such as cross-site scripting or SQL injection.\" --- WAF monitors the Application Load Balancer or CloudFront will either allow this content to be received or give an HTTP 403 status code. Also, WAF protects the Layer 7 (the Application Layer).\n\nWhile AWS Shield Advanced, provides enhanced protections for applications running on Elastic Load Balancer, CloudFront, and Route 53 against DDoS attack. Also, Shield protects the Layer 3 and 4, these layers are not for Application Layer. And most of all, Shield Advance is expensive, it costs $3,000 USD per month.\n\nSo, the answer should be A -- AWS WAF."},{"content":"Selected Answer: A\nWaf is for application attacks. Shield advanced is for ddos","comment_id":"825059","timestamp":"1677603960.0","upvote_count":"4","poster":"Steve_4542636"},{"timestamp":"1677407400.0","comment_id":"822250","upvote_count":"5","content":"Selected Answer: A\n\"against common application-level attacks, such as cross-site scripting or SQL injection\" Shield is for DDOS Protection... Answer A","poster":"nder"},{"poster":"Nel8","upvote_count":"4","comment_id":"818509","content":"Selected Answer: A\n\"The company must implement proper traffic filtering to protect its Application Load Balancer (ALB) against common application-level attacks, such as cross-site scripting or SQL injection.\" --- WAF monitors the Application Load Balancer or CloudFront will either allow this content to be received or give an HTTP 403 status code. Also, WAF protects the Layer 7 (the Application Layer).\n\nWhile AWS Shield Advanced, provides enhanced protections for applications running on Elastic Load Balancer, CloudFront, and Route 53 against DDoS attack. Also, Shield protects the Layer 3 and 4, these layers are not for Application Layer. And most of all, Shield Advance is expensive, it costs $3,000 USD per month.\n\nSo, the answer should be A -- AWS WAF.","timestamp":"1677106200.0"},{"upvote_count":"2","content":"Selected Answer: A\nAWS WAF comes with Managed rule groups which are collections of predefined, ready-to-use rules \nhttps://docs.aws.amazon.com/waf/latest/developerguide/waf-managed-rule-groups.html","timestamp":"1676398320.0","poster":"bdp123","comment_id":"808666"},{"comment_id":"802982","content":"Selected Answer: A\nA\nA solutions architect should recommend option A, which is to configure AWS WAF rules and associate them with the ALB. This will allow the company to apply traffic filtering at the application layer, which is necessary for protecting the ALB against common application-level attacks such as cross-site scripting or SQL injection. AWS WAF is a managed service that makes it easy to protect web applications from common web exploits that could affect application availability, compromise security, or consume excessive resources. The company can easily manage and update the rules to ensure the security of its application.","timestamp":"1675931700.0","upvote_count":"3","poster":"neosis91"},{"timestamp":"1675728780.0","comment_id":"800380","poster":"LuckyAro","upvote_count":"2","content":"Selected Answer: C\nhttps://aws.amazon.com/shield/features/\n\nShield Advanced provides additional detection and mitigation against large and sophisticated DDoS attacks, near real-time visibility into attacks, and integration with AWS WAF, a web application firewall. Shield Advanced also gives you 24/7 access to the AWS Shield Response Team (SRT) and protection against DDoS-related spikes in your EC2, ELB, CloudFront, Global Accelerator, and Route 53 charges."},{"poster":"JohnnyBG","upvote_count":"4","content":"Selected Answer: A\nWAF = Application level defense\nShield = L4 DDOS protection","comment_id":"797797","timestamp":"1675504860.0"},{"timestamp":"1675495680.0","content":"Selected Answer: A\nAnswer should be A, because It has asked only for application-level attacks, shield advanced costs are very high, why would you use such a high cost solution just to mitigate application level attacks?","poster":"aakashkumar1999","upvote_count":"3","comment_id":"797698"},{"comment_id":"795185","content":"Selected Answer: C\nThe company needs to reduce its share of responsibility in managing, updating, and securing servers for its AWS environment* Go with AWS Shield advanced","upvote_count":"1","timestamp":"1675258920.0","poster":"damirbek369"},{"upvote_count":"2","content":"Selected Answer: A\nAWS WAF offers the following protections to prevent SQLi and XSS attacks:\n\nBuilt-in SQLi and XSS engines\nAWS Managed Rules available for SQLi and XSS injection attacks\nTo configure these protections, be sure that you have set up AWS WAF and created a web ACL.\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/waf-rule-prevent-sqli-xss/","comment_id":"791982","timestamp":"1675020240.0","poster":"devonwho"},{"upvote_count":"1","poster":"skondey","timestamp":"1674899580.0","content":"Selected Answer: C\nC - is the correct answer in this case base on the question: the company nee to reduce its share of responsibility in managing, so Shield is the best choice for this question. \nShield is a fully managed service.","comment_id":"790488"},{"upvote_count":"4","poster":"JayBee65","content":"Selected Answer: C\n\"With AWS WAF, **YOU**can create security rules that control bot traffic and block common attack patterns such as SQL injection or cross-site scripting (XSS).\" The \"company needs to reduce its share of the responsibility in managing\". So yes A will provide the protection, but it does not meet the requirement for the company needs to reduce its share of the responsibility in managing, so C.","comment_id":"785566","timestamp":"1674488760.0"},{"content":"Selected Answer: C\nFocus: The company has #minimal #infrastructure and #operational #staff. The company needs to REDUCE its SHARE of the RESPONSIBILITY in #managing, #updating, and #securing #servers for its AWS environment.\n\nAWS Shield is a #MANAGED DDoS protection service that safeguards apps running on AWS.\n\nAWS WAF (for common application-level attacks, such as cross-site scripting or SQL injection) is available AT NO EXTRA CHARGE for usage on resources protected by AWS Shield Advanced (protected resource = ALB).","poster":"Training4aBetterLife","upvote_count":"2","comment_id":"784487","timestamp":"1674405420.0"},{"upvote_count":"1","poster":"brownest","content":"Selected Answer: C\nShield advanced contains WAF. https://aws.amazon.com/shield/","timestamp":"1674398400.0","comment_id":"784399"},{"poster":"Rudraman","upvote_count":"3","comment_id":"779893","content":"cross site scripting and SQL injection so WAF on ALB is the answer so AAAAA.","timestamp":"1674039300.0"},{"timestamp":"1673880540.0","poster":"Aninina","content":"Selected Answer: A\nA looks correct","comment_id":"777795","upvote_count":"4"},{"content":"Selected Answer: A\nWAF does the job here cross-site scriptiong & SQL injections.","comment_id":"777699","upvote_count":"4","timestamp":"1673875620.0","poster":"techhb"},{"upvote_count":"4","content":"Selected Answer: A\nThe correct answer is A.","timestamp":"1673715360.0","poster":"mhmt4438","comment_id":"775754"}],"topic":"1","question_text":"A company is developing a new mobile app. The company must implement proper traffic filtering to protect its Application Load Balancer (ALB) against common application-level attacks, such as cross-site scripting or SQL injection. The company has minimal infrastructure and operational staff. The company needs to reduce its share of the responsibility in managing, updating, and securing servers for its AWS environment.\n\nWhat should a solutions architect recommend to meet these requirements?","question_id":148,"isMC":true,"choices":{"D":"Create a new ALB that directs traffic to an Amazon EC2 instance running a third-party firewall, which then passes the traffic to the current ALB.","C":"Deploy AWS Shield Advanced and add the ALB as a protected resource.","B":"Deploy the application using Amazon S3 with public hosting enabled.","A":"Configure AWS WAF rules and associate them with the ALB."},"answer_images":[],"exam_id":31,"answer_ET":"A","question_images":[],"timestamp":"2023-01-14 17:56:00","answers_community":["A (79%)","C (21%)"],"url":"https://www.examtopics.com/discussions/amazon/view/95301-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"suGcCZPeubykMffFGrXT","exam_id":31,"question_id":149,"answer_description":"","answers_community":["B (100%)"],"discussion":[{"comment_id":"775169","poster":"Babba","content":"Selected Answer: B\nIt looks like AWS Glue allows fully managed CSV to Parquet conversion jobs: https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/three-aws-glue-etl-job-types-for-converting-data-to-apache-parquet.html","comments":[{"timestamp":"1719837180.0","upvote_count":"2","comment_id":"1111260","content":"A text book use case: https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/three-aws-glue-etl-job-types-for-converting-data-to-apache-parquet.html#three-aws-glue-etl-job-types-for-converting-data-to-apache-parquet-epics\n\nB is the correct answer.","poster":"awsgeek75"}],"timestamp":"1689313800.0","upvote_count":"20"},{"content":"Selected Answer: B\nAWS Glue is a fully managed ETL service that simplifies the process of preparing and transforming data for analytics. Using AWS Glue requires minimal development effort compared to the other options.\n\nOption A requires more development effort as it involves writing a Spark application to transform the data. It also introduces additional infrastructure management with the EMR cluster.\n\nOption C requires writing and managing custom Bash scripts for data transformation. It requires more manual effort and does not provide the built-in capabilities of AWS Glue for data transformation.\n\nOption D requires developing and managing a custom Lambda for data transformation. While Lambda can handle the transformation, it requires more effort compared to AWS Glue, which is specifically designed for ETL operations.\n\nTherefore, option B provides the easiest and least development effort by leveraging AWS Glue's capabilities for data discovery, transformation, and output to the transformed data bucket.","timestamp":"1703760420.0","comment_id":"936369","poster":"cookieMr","upvote_count":"10"},{"upvote_count":"1","content":"Selected Answer: B\nAWS Glue is designed for ETL and this scenario.","timestamp":"1739806080.0","comment_id":"1357835","poster":"satyaammm"},{"comment_id":"1347093","upvote_count":"1","poster":"iamroyalty_k","timestamp":"1737922500.0","content":"Selected Answer: B\nAWS Glue offers a serverless, automated, and cost-effective solution with minimal development and operational effort, making it the best choice for this use case.\n\nWhy not the other options?\nA. Amazon EMR cluster with Apache Spark:\nWhile EMR and Spark can handle this task, it requires more setup, maintenance, and development effort compared to AWS Glue. Managing the cluster introduces operational overhead.\n\nC. AWS Batch with Bash job definition:\nUsing AWS Batch for this would require creating custom Bash scripts for the transformation and managing jobs. This introduces more complexity and development effort than AWS Glue\n\nD. AWS Lambda with S3 event notifications:\nLambda is suitable for lightweight, real-time processing. However, converting hundreds of .csv files into Parquet format could exceed Lambda's execution time and resource limits, leading to scalability challenges."},{"poster":"lofzee","content":"Selected Answer: B\nAWS Glue and parquet go hand in hand","timestamp":"1732808100.0","comment_id":"1220296","upvote_count":"2"},{"content":"i will go with answer B cause: You can use AWS Glue to write ETL jobs in a Python shell environment. You can also create both batch and streaming ETL jobs by using Python (PySpark) or Scala in a managed Apache Spark environment.\nApache Parquet is built to support efficient compression and encoding schemes. It can speed up your analytics workloads because it stores data in a columnar fashion. Converting data to Parquet can save you storage space, cost, and time in the longer run","upvote_count":"3","comment_id":"1188682","poster":"zinabu","timestamp":"1727960940.0"},{"comment_id":"1124390","content":"D\nI think people are forgetting the question says \"Low Overhead\".","upvote_count":"1","timestamp":"1721143860.0","poster":"Rido4good","comments":[{"content":"Pray tell, how is a Lambda less overhead than B or even A?","poster":"awsgeek75","comment_id":"1124945","timestamp":"1721211960.0","upvote_count":"3"}]},{"upvote_count":"4","comment_id":"1014814","timestamp":"1711196940.0","poster":"nileeka97","content":"Selected Answer: B\nParquet format ========> Amazon Glue"},{"comment_id":"1005057","upvote_count":"3","poster":"Guru4Cloud","timestamp":"1710186600.0","content":"Selected Answer: B\nB. Create an AWS Glue crawler to discover the data. Create an AWS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step."},{"upvote_count":"4","comment_id":"926334","content":"Least development effort means lambda. Glue also works but more overhead and cost. A simple lambda like this https://github.com/ayshaysha/aws-csv-to-parquet-converter/blob/main/csv-parquet-converter.py \ncan be used to convert as soon as you see files in s3 bucket.","poster":"markw92","timestamp":"1702864080.0"},{"upvote_count":"3","timestamp":"1694034660.0","poster":"achevez85","comment_id":"831367","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/three-aws-glue-etl-job-types-for-converting-data-to-apache-parquet.html"},{"content":"Selected Answer: B\nS3 provides a single control to automatically encrypt all new objects in a bucket with SSE-S3 or SSE-KMS. Unfortunately, these controls only affect new objects. If your bucket already contains millions of unencrypted objects, then turning on automatic encryption does not make your bucket secure as the unencrypted objects remain. \n\nFor S3 buckets with a large number of objects (millions to billions), use Amazon S3 Inventory to get a list of the unencrypted objects, and Amazon S3 Batch Operations to encrypt the large number of old, unencrypted files.","comments":[{"timestamp":"1690124520.0","comment_id":"785630","content":"Versioning:\n\nWhen you overwrite an S3 object, it results in a new object version in the bucket. However, this will not remove the old unencrypted versions of the object. If you do not delete the old version of your newly encrypted objects, you will be charged for the storage of both versions of the objects. \n\nS3 Lifecycle \n\nIf you want to remove these unencrypted versions, use S3 Lifecycle to expire previous versions of objects. When you add a Lifecycle configuration to a bucket, the configuration rules apply to both existing objects and objects added later. C is missing this step, which I believe is what makes B the better choice. B includes the functionality of encrypting the old unencrypted objects via Batch Operations, whereas, Versioning does not address the old unencrypted objects.","poster":"Training4aBetterLife","upvote_count":"1","comments":[{"poster":"Training4aBetterLife","content":"Please delete this. I was meaning to place this response on a different question.","comment_id":"785633","timestamp":"1690124700.0","upvote_count":"2"}]}],"upvote_count":"2","poster":"Training4aBetterLife","timestamp":"1690124460.0","comment_id":"785629"},{"upvote_count":"4","timestamp":"1689670560.0","poster":"Rudraman","content":"ETL = Glue","comment_id":"779895"},{"content":"Selected Answer: B\nB is the correct answer","poster":"Aninina","comment_id":"777797","upvote_count":"2","timestamp":"1689511800.0"},{"poster":"techhb","upvote_count":"2","timestamp":"1689507300.0","comment_id":"777710","content":"Selected Answer: B\nAWS Glue Crawler is for ETL"},{"content":"Selected Answer: B\nThe correct answer is B","comment_id":"777248","poster":"kbaruu","upvote_count":"2","timestamp":"1689464460.0"},{"timestamp":"1689452880.0","poster":"Mamiololo","comment_id":"777123","upvote_count":"3","content":"B is the answer"},{"timestamp":"1689403620.0","poster":"swolfgang","comment_id":"776288","content":"Selected Answer: B\nıt should be b","upvote_count":"2"},{"timestamp":"1689364380.0","poster":"marcioicebr","comment_id":"775959","upvote_count":"1","content":"Selected Answer: B\nDe acordo com a documentação, a resposta certa é B.\n\nhttps://docs.aws.amazon.com/pt_br/prescriptive-guidance/latest/patterns/three-aws-glue-etl-job-types-for-converting-data-to-apache-parquet.html"},{"comment_id":"775783","content":"B is the ans","timestamp":"1689348840.0","upvote_count":"2","poster":"AHUI"},{"poster":"mhmt4438","timestamp":"1689346860.0","upvote_count":"2","content":"Selected Answer: B\nAnswer is B","comment_id":"775758"},{"upvote_count":"2","poster":"Kayamables","timestamp":"1689339300.0","comment_id":"775542","content":"Option B sounds more plausible to me."}],"choices":{"C":"Use AWS Batch to create a job definition with Bash syntax to transform the data and output the data to the transformed data bucket. Use the job definition to submit a job. Specify an array job as the job type.","A":"Create an Amazon EMR cluster with Apache Spark installed. Write a Spark application to transform the data. Use EMR File System (EMRFS) to write files to the transformed data bucket.","D":"Create an AWS Lambda function to transform the data and output the data to the transformed data bucket. Configure an event notification for the S3 bucket. Specify the Lambda function as the destination for the event notification.","B":"Create an AWS Glue crawler to discover the data. Create an AWS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step."},"answer_ET":"B","question_images":[],"timestamp":"2023-01-14 08:50:00","url":"https://www.examtopics.com/discussions/amazon/view/95154-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"B","isMC":true,"topic":"1","answer_images":[],"unix_timestamp":1673682600,"question_text":"A company’s reporting system delivers hundreds of .csv files to an Amazon S3 bucket each day. The company must convert these files to Apache Parquet format and must store the files in a transformed data bucket.\n\nWhich solution will meet these requirements with the LEAST development effort?"},{"id":"83Yms6h9grMteq3CWOrk","topic":"1","exam_id":31,"timestamp":"2023-01-13 09:09:00","question_images":[],"answer":"A","isMC":true,"choices":{"A":"Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.","B":"Deploy a VPN connection between the data center and Amazon VPC. Use the AWS CLI to copy the data from on premises to Amazon S3 Glacier.","D":"Use AWS DataSync to transfer the data and deploy a DataSync agent on premises. Use the DataSync task to copy files from the on-premises NAS storage to Amazon S3 Glacier.","C":"Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive."},"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/94983-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"question_id":150,"question_text":"A company has 700 TB of backup data stored in network attached storage (NAS) in its data center. This backup data need to be accessible for infrequent regulatory requests and must be retained 7 years. The company has decided to migrate this backup data from its data center to AWS. The migration must be complete within 1 month. The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer.\n\nWhat should a solutions architect do to migrate and store the data at the LOWEST cost?","discussion":[{"timestamp":"1688970240.0","content":"Selected Answer: A\nhundreds of Terabytes => always use Snowball","poster":"voccer","comment_id":"947810","upvote_count":"14"},{"poster":"TariqKipkemei","content":"Selected Answer: A\nTerabytes, low costs, limited time = AWS snowball devices","upvote_count":"10","timestamp":"1695188940.0","comment_id":"1011953"},{"comment_id":"1395721","content":"Selected Answer: A\n70TB = AWS Snowball","poster":"sjb009","timestamp":"1741986360.0","upvote_count":"1"},{"content":"Selected Answer: B\nResumo:\nA Opção B é a solução mais eficiente, pois:\n\nGarante a criptografia automática de todos os objetos futuros com configurações de criptografia padrão no bucket.\nUsa o Inventário do S3 e trabalhos de operações em lote para criptografar objetos existentes sem esforço manual significativo ou movimentação de dados desnecessária.","comment_id":"1341831","upvote_count":"1","poster":"Rcosmos","timestamp":"1737057120.0"},{"content":"It took me quite some time to do the mental math for realising that the data can't be transferred in 30 days. Also, note the MBps (Megabits) and not Megabytes. 500Mbps is like 60MBps. That's a lame connection to transfer anything!","comments":[{"poster":"lofzee","timestamp":"1716904200.0","comment_id":"1220306","content":"well.. standard internet connections are measured in Mbps and 500 Mbps is pretty decent to be fair (by english standards).\neven still at that speed it would take you about 4 months to upload 700 TB. So the only option here is to use snowball.\nAnswer is A","upvote_count":"3"}],"poster":"awsgeek75","upvote_count":"7","comment_id":"1111274","timestamp":"1704120300.0"},{"upvote_count":"3","comment_id":"1106777","content":"Selected Answer: A\nB and D would use existing 500 mbps Internet connection which cannot transfer more than ca. 160 TB in a month. C would cost a lot, take weeks to deliver, and still not provide more bandwidth. Thus A is the simply the only option, thus also the one with \"lowest cost\".","poster":"pentium75","timestamp":"1703679540.0"},{"poster":"Guru4Cloud","content":"Selected Answer: A\nA. Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.","comment_id":"1005055","upvote_count":"2","timestamp":"1694454420.0"},{"poster":"gosai90786","upvote_count":"2","comment_id":"939495","comments":[{"upvote_count":"1","poster":"JA2018","content":"From Google search: \"do I need to pay to ship back aws snow devices back to AWS?\"\n\nNo, you don't need to pay to ship back an AWS Snowball Edge device to AWS. The device comes with a prepaid UPS shipping label on the E Ink display that contains the correct address for return. You can arrange for UPS to pick up the device or drop it off at a UPS package drop-off facility.","comment_id":"1314021","timestamp":"1731938460.0"},{"comment_id":"989961","content":"your math is wrong mate, and they have 0.5Gbps connection, not 10GBps\n500Mpbs = roughly 60MBps\n30x24x3600x0.06TB = roughly 155TB\nthis is way short of 700TB","upvote_count":"7","timestamp":"1692960360.0","poster":"slackbot"}],"timestamp":"1688176860.0","content":"one DataSync agent can use 10GBps and can setup a bandwidth.\nSo total time = (700X1000)GB/10GBps = 70000 sec = 19.4 days.\nUsing Multiple Snowball devices will involve ordering them from AWS, setting them up on your data-center for copy and then incurring the shipping cost for too and fro movement to your AWS cloud.\nif time constraint was critical , say 1 week then snowball would have been a viable option. But here we have 30 days, so DataSync will be less costly(takes `19days)"},{"content":"Selected Answer: A\nBy ordering Snowball devices, the company can transfer the 700 TB of backup data from its data center to AWS. Once the data is transferred to S3, a lifecycle policy can be applied to automatically transition the files from the S3 Standard storage class to the cost-effective Amazon S3 Glacier Deep Archive storage class.\n\nOption B would require continuous data transfer over the public internet, which could be time-consuming and costly given the large amount of data. It may also require significant bandwidth allocation.\n\nOption C would involve additional costs for provisioning and maintaining the dedicated connection, which may not be necessary for a one-time data migration.\n\nOption D could be a viable option, but it may incur additional costs for deploying and managing the DataSync agent.\n\nTherefore, option A is the recommended choice as it provides a secure and efficient data transfer method using Snowball devices and allows for cost optimization through lifecycle policies by transitioning the data to S3 Glacier Deep Archive for long-term storage.","poster":"cookieMr","timestamp":"1687942560.0","comment_id":"936381","upvote_count":"4"},{"timestamp":"1682040660.0","comment_id":"876115","upvote_count":"3","content":"A is the correct answer.\neven though they have 500mbps internetspeed, it will take around 130days to transfer the data from on premises to AWS\n\nso they have only 1 option which is Snowball devices","poster":"arjundevops"},{"timestamp":"1680970380.0","upvote_count":"2","poster":"Paras043","content":"Selected Answer: A\nA is the correct one","comment_id":"864841"},{"content":"Q: What is AWS Snowball Edge?\n\nAWS Snowball Edge is an edge computing and data transfer device provided by the AWS Snowball service. It has on-board storage and compute power that provides select AWS services for use in edge locations. Snowball Edge comes in two options, Storage Optimized and Compute Optimized, to support local data processing and collection in disconnected environments such as ships, windmills, and remote factories. Learn more about its features here.\n\nQ: What happened with the original 50 TB and 80 TB AWS Snowball devices?\n\nThe original Snowball devices were transitioned out of service and Snowball Edge Storage Optimized are now the primary devices used for data transfer.\n\nQ: Can I still order the original Snowball 50 TB and 80 TB devices?\n\nNo. For data transfer needs now, please select the Snowball Edge Storage Optimized devices.","timestamp":"1678812120.0","comment_id":"839047","upvote_count":"2","poster":"CapJackSparrow"},{"comment_id":"827876","poster":"vherman","timestamp":"1677839700.0","content":"Selected Answer: A\nSnowball","upvote_count":"1"},{"comment_id":"811708","poster":"KZM","comments":[{"content":"700TB of Data can not be transferred through a 500Mbps link within one month.\n\nTotal data that can be transferred in one month = bandwidth x time\n= (500 Mbps / 8 bits per byte) x (30 days x 24 hours x 3600 seconds per hour)\n= 648,000 GB or 648 TB\nThis is calculated theoretically with the maximum available situation. Due to a number of factors, the actual total transferred Data may be less than 645 TB.","poster":"KZM","upvote_count":"4","comments":[{"comment_id":"891250","upvote_count":"4","content":"Good thinking. Agree with the solution. Only the calculation is wrong. It should give 162tb as a result","poster":"mandragon","timestamp":"1683448680.0"}],"comment_id":"811719","timestamp":"1676628240.0"}],"upvote_count":"3","timestamp":"1676627400.0","content":"9 Snowball devices are needed to migrate the 700TB of data."},{"content":"Snow ball Devices the answe is AAAAA.","timestamp":"1674039600.0","upvote_count":"3","poster":"Rudraman","comment_id":"779899"},{"comments":[{"poster":"wmp7039","comment_id":"777607","upvote_count":"6","timestamp":"1673869140.0","content":"Ignore please, miscalculated time to transfer, it will take 129 days and will breach the 1 month requirement. A is correct."}],"upvote_count":"1","comment_id":"777606","content":"A is incorrect as DC is an expensive option. Correct answer should be C as the company already has 500Mbps that can be used for data transfer. By consuming all the available internet bandwidth, data transfer will complete in 3 hours 6 mins - https://www.omnicalculator.com/other/data-transfer","timestamp":"1673868900.0","poster":"wmp7039"},{"poster":"kbaruu","timestamp":"1673833320.0","comment_id":"777249","content":"Selected Answer: A\nA is correct","upvote_count":"2"},{"poster":"swolfgang","comments":[{"content":"Does not work in a month","upvote_count":"2","poster":"pentium75","comment_id":"1106776","timestamp":"1703679420.0"}],"content":"a is correct but not less expensive.I think,should be D.","timestamp":"1673773020.0","comment_id":"776298","upvote_count":"1"},{"poster":"Parsons","upvote_count":"2","comments":[{"comment_id":"790630","content":"yes you can - https://docs.aws.amazon.com/datasync/latest/userguide/create-s3-location.html#using-storage-classes","poster":"PDR","upvote_count":"2","timestamp":"1674913800.0"}],"comment_id":"775962","timestamp":"1673733600.0","content":"Selected Answer: A\nA is correct.\n\nCannot copy files directly from on-prem to S3 Glacier with DataSync. It should be S3 standard first, then configuration S3 Lifecycle to transit to Glacier => Exclude D."},{"content":"Selected Answer: A\nThe correct answer is A","comment_id":"775765","upvote_count":"2","timestamp":"1673716260.0","poster":"mhmt4438"},{"upvote_count":"2","comment_id":"774229","content":"Less expensive = Data Sync i guess (D)","poster":"Morinator","comments":[{"poster":"Pindol","timestamp":"1674591480.0","upvote_count":"3","comment_id":"786914","content":"\"The migration must be complete within 1 month\" you can't complete this with transfer 500Mb/s. With that speed we need 129days to transfer. Snowball is only way to do it in desired time."}],"timestamp":"1673597340.0"}],"unix_timestamp":1673597340,"answers_community":["A (98%)","2%"],"answer_description":""}],"exam":{"name":"AWS Certified Solutions Architect - Associate SAA-C03","provider":"Amazon","isBeta":false,"isImplemented":true,"id":31,"isMCOnly":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":1019},"currentPage":30},"__N_SSP":true}