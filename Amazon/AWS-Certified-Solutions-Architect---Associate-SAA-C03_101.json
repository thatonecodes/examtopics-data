{"pageProps":{"questions":[{"id":"Ev6WlXcFavcRUVR8RgmQ","question_text":"A company needs to integrate with a third-party data feed. The data feed sends a webhook to notify an external service when new data is ready for consumption. A developer wrote an AWS Lambda function to retrieve data when the company receives a webhook callback. The developer must make the Lambda function available for the third party to call.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","unix_timestamp":1686160980,"answer_description":"","exam_id":31,"answer_ET":"A","isMC":true,"question_images":[],"question_id":501,"timestamp":"2023-06-07 20:03:00","choices":{"D":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Attach the queue to the Lambda function. Provide the public hostname of the SQS queue to the third party for the webhook.","B":"Deploy an Application Load Balancer (ALB) in front of the Lambda function. Provide the ALB URL to the third party for the webhook.","C":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Attach the topic to the Lambda function. Provide the public hostname of the SNS topic to the third party for the webhook.","A":"Create a function URL for the Lambda function. Provide the Lambda function URL to the third party for the webhook."},"answer_images":[],"answers_community":["A (100%)"],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/111430-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"poster":"TariqKipkemei","upvote_count":"9","comment_id":"961175","timestamp":"1690177920.0","content":"Selected Answer: A\nA function URL is a dedicated HTTP(S) endpoint for your Lambda function. When you create a function URL, Lambda automatically generates a unique URL endpoint for you."},{"content":"Selected Answer: A\nKeyword \"Lambda function\" and \"webhook\". See https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-saas-furls.html#create-stripe-cfn-stack","timestamp":"1689679920.0","upvote_count":"6","comment_id":"955321","poster":"james2033"},{"comment_id":"1239264","upvote_count":"2","content":"Selected Answer: A\nAWS Lambda can provide a URL to call using Function URLs. This is a relatively new feature in AWS Lambda that allows you to create HTTPS endpoints for your Lambda functions, making it easy to invoke the function directly over the web.\nKey Features of Lambda Function URLs:\n\n Direct Access: Provides a simple and direct way to call a Lambda function via an HTTP(S) request.\n Easy Configuration: You can create a function URL for a Lambda function using the AWS Management Console, AWS CLI, or AWS SDKs.\n Managed Service: AWS manages the infrastructure for you, handling scaling, patching, and maintenance.\n Security: You can configure authentication and authorization using AWS IAM or AWS Lambda function URL settings.","timestamp":"1719664680.0","poster":"emakid"},{"timestamp":"1704923040.0","upvote_count":"3","content":"Selected Answer: A\nApart from simplest and most operational, I think A is the only option that will work! \nBCD cannot even be implemented in real world imho. Happy to be corrected","comment_id":"1119060","poster":"awsgeek75"},{"upvote_count":"1","content":"B is the answerThe best solution to make the Lambda function available for the third party to call with the MOST operational efficiency is to deploy an Application Load Balancer (ALB) in front of the Lambda function and provide the ALB URL to the third party for the webhook. This solution is the most efficient because it allows the third party to call the Lambda function without having to worry about managing the Lambda function's availability or scaling. The ALB will automatically distribute traffic across multiple Lambda functions, if necessary, and will also provide redundancy in case of a failure.","timestamp":"1700665980.0","comments":[{"timestamp":"1712432520.0","content":"I believe you are correct. Lambda functions as targets - implementing ALBs\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/lambda-functions.html","poster":"hro","comment_id":"1190596","upvote_count":"1"}],"comment_id":"1077475","poster":"Orit"},{"comment_id":"987596","content":"Selected Answer: A\nThe key points:\n\nA Lambda function needs to be invoked by a third party via a webhook.\nUsing a function URL provides a direct invoke endpoint for the Lambda function. This is simple and efficient.\nOptions B, C, and D insert unnecessary components like ALB, SNS, SQS between the webhook and the Lambda function. These add complexity without benefit.\nA function URL can be generated and provided to the third party quickly without additional infrastructure.","upvote_count":"5","poster":"Guru4Cloud","timestamp":"1692720420.0"},{"content":"Selected Answer: A\nkey word: Lambda function URLs","poster":"Abrar2022","timestamp":"1687060920.0","comment_id":"926411","upvote_count":"3"},{"upvote_count":"2","poster":"maver144","comment_id":"921348","timestamp":"1686566640.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-urls.html"},{"comment_id":"920815","timestamp":"1686497760.0","poster":"jkhan2405","content":"Selected Answer: A\nIt's A","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: A\nA would seem like the correct one but not sure.","timestamp":"1686160980.0","comment_id":"917487","poster":"alexandercamachop"}],"answer":"A"},{"id":"mb3acJDDy3Yx6Rc6Nphq","discussion":[{"content":"Step A involves registering the required domain in a registrar and creating a wildcard custom domain name in a Route 53 hosted zone. This allows you to map individual and secure URLs for all customers to your API Gateway endpoints.\n\nStep D is to request a wildcard certificate from AWS Certificate Manager (ACM) that matches the custom domain name you created in Step A. This wildcard certificate will cover all subdomains and ensure secure HTTPS communication.\n\nStep F is to create a custom domain name in API Gateway for your REST API. This allows you to associate the custom domain name with your API Gateway endpoints and import the certificate from ACM for secure communication.","comment_id":"924080","poster":"AshishRocks","timestamp":"1686824520.0","upvote_count":"9"},{"timestamp":"1692720180.0","poster":"Guru4Cloud","content":"Selected Answer: ADF\nThe key points:\n\nUsing a wildcard domain and certificate avoids managing individual domains/certs per customer. This is more efficient.\nThe domain, hosted zone, and certificate should all be in the same region as the API Gateway REST API for simplicity.\nCreating multiple API endpoints per customer (Option E) adds complexity and is not required.\nOption B and C add unnecessary complexity by separating domains, certificates, and hosted zones.","upvote_count":"8","comment_id":"987590"},{"comments":[{"comment_id":"1323107","upvote_count":"1","poster":"LeonSauveterre","timestamp":"1733576940.0","content":"My guess on why C is not ideal: Creating individual hosted zones for each customer is too much. It definitely increases operational overhead, while using a wildcard domain eliminates this need (which is more ideal)."}],"upvote_count":"3","poster":"awsgeek75","content":"ADF looks right but not sure why C is wrong:\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-api-gateway.html#routing-to-api-gateway-config","timestamp":"1705696200.0","comment_id":"1126955"},{"poster":"ukivanlamlpi","content":"Selected Answer: ADF\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/AboutHZWorkingWith.html","upvote_count":"5","timestamp":"1690631640.0","comment_id":"966377"},{"comment_id":"946482","upvote_count":"3","content":"Selected Answer: ADF\nADF - makes sense","poster":"jaydesai8","timestamp":"1688820960.0"},{"content":"Selected Answer: ADF\nIt's ADF","comment_id":"920816","upvote_count":"3","timestamp":"1686497880.0","poster":"jkhan2405"},{"timestamp":"1686310800.0","poster":"MAMADOUG","upvote_count":"3","content":"For me AFD","comment_id":"919245"},{"upvote_count":"3","comment_id":"917500","poster":"alexandercamachop","content":"Selected Answer: ADF\nADF - One to create the custom domain in Route 53 (Amazon DNS)\nSecond to request wildcard certificate from ADM\nThirds to import the certificate from ACM.","timestamp":"1686161580.0"},{"comment_id":"916962","timestamp":"1686121020.0","poster":"AncaZalog","upvote_count":"2","content":"is ADF"}],"unix_timestamp":1686121020,"question_images":[],"answer":"ADF","url":"https://www.examtopics.com/discussions/amazon/view/111382-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"ADF","topic":"1","answer_images":[],"timestamp":"2023-06-07 08:57:00","choices":{"B":"Request a wildcard certificate that matches the domains in AWS Certificate Manager (ACM) in a different Region.","C":"Create hosted zones for each customer as required in Route 53. Create zone records that point to the API Gateway endpoint.","A":"Register the required domain in a registrar. Create a wildcard custom domain name in a Route 53 hosted zone and record in the zone that points to the API Gateway endpoint.","E":"Create multiple API endpoints for each customer in API Gateway.","D":"Request a wildcard certificate that matches the custom domain name in AWS Certificate Manager (ACM) in the same Region.","F":"Create a custom domain name in API Gateway for the REST API. Import the certificate from AWS Certificate Manager (ACM)."},"answers_community":["ADF (100%)"],"isMC":true,"question_id":502,"answer_description":"","question_text":"A company has a workload in an AWS Region. Customers connect to and access the workload by using an Amazon API Gateway REST API. The company uses Amazon Route 53 as its DNS provider. The company wants to provide individual and secure URLs for all customers.\n\nWhich combination of steps will meet these requirements with the MOST operational efficiency? (Choose three.)","exam_id":31},{"id":"Mb1FGWxaEbfHP72RsxOd","exam_id":31,"choices":{"D":"Use Amazon GuardDuty. Create an Amazon EventBridge rule to filter the CRITICAL event type from GuardDuty findings and to send an Amazon Simple Queue Service (Amazon SQS) notification to the security team.","C":"Use Amazon Macie. Create an Amazon EventBridge rule to filter the SensitiveData:S3Object/Personal event type from Macie findings and to send an Amazon Simple Queue Service (Amazon SQS) notification to the security team.","A":"Use Amazon Macie. Create an Amazon EventBridge rule to filter the SensitiveData event type from Macie findings and to send an Amazon Simple Notification Service (Amazon SNS) notification to the security team.","B":"Use Amazon GuardDuty. Create an Amazon EventBridge rule to filter the CRITICAL event type from GuardDuty findings and to send an Amazon Simple Notification Service (Amazon SNS) notification to the security team."},"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/111432-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"A","topic":"1","answers_community":["A (87%)","13%"],"question_images":[],"question_id":503,"discussion":[{"timestamp":"1686161700.0","comment_id":"917502","upvote_count":"15","poster":"alexandercamachop","content":"Selected Answer: A\nB and D are discarted as Macie is to identify PII. \nNow that we have between A and C.\nSNS is more suitable for this option as a pub/sub service, we subscribe the security team and then they will receive the notifications."},{"timestamp":"1733577120.0","content":"Selected Answer: A\nMacie + SNS = Identify PII + Notification","poster":"LeonSauveterre","comment_id":"1323108","upvote_count":"1"},{"comment_id":"1119079","timestamp":"1704923760.0","poster":"awsgeek75","upvote_count":"2","content":"Selected Answer: A\nBD: Wrong products\nAC: Uses Macie which is the right product but C uses SQS to notify security team which is an incomplete solution (what's listening to SQS?)"},{"timestamp":"1704115860.0","comment_id":"1111194","poster":"pentium75","upvote_count":"4","content":"Selected Answer: A\nDetect PII -> Macie, A or C\nNotify security team -> SNS, A or B"},{"poster":"potomac","timestamp":"1699278840.0","upvote_count":"4","content":"Selected Answer: A\nC is SQS, not SNS","comment_id":"1063892"},{"timestamp":"1693418400.0","upvote_count":"2","comment_id":"994379","poster":"Wayne23Fang","content":"SQS mentioned in C."},{"poster":"Ale1973","upvote_count":"2","comment_id":"976715","content":"Selected Answer: A\nAmazon SQS is typically used for decoupling and managing messages between distributed application components. It's not typically used for sending notifications directly to humans. On my opinion C isn't a best practice","timestamp":"1691589240.0"},{"upvote_count":"3","content":"Those who say C , please read carefully (I made the same mistake lol). Teams can't be notified with SQS hence A.","timestamp":"1690691820.0","poster":"Kp88","comment_id":"966854"},{"comment_id":"966355","upvote_count":"3","content":"Selected Answer: C\nthere are different type of sensitive data: https://docs.aws.amazon.com/macie/latest/user/findings-types.html. if the question only focus on PII, then C is the answer. however, in reality, you will use A, because you will not want bank card, credential...etc all sensitive data , not only PII","poster":"ukivanlamlpi","timestamp":"1690629180.0"},{"comment_id":"962311","timestamp":"1690257240.0","upvote_count":"2","poster":"TariqKipkemei","content":"Selected Answer: A\nAutomatically detect PII in S3 buckets = Amazon Macie\nNotify security team = Amazon SNS\nTrigger notification based on SensitiveData event type from Macie findings = EventBridge"},{"comment_id":"946794","content":"Selected Answer: C\nThere are different types of Sensitive Data. Here we are only referring to PII. Hence SensitiveData:S3Object/Personal. to use SNS, the security team must subscribe. SQS sends the information as designed","poster":"NASHDBA","timestamp":"1688860680.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1688840520.0","comment_id":"946676","content":"Selected Answer: C\nSensitiveData:S3Object/Personal","poster":"narddrer"},{"content":"Selected Answer: A\nSensitive = MACIE, and SNS to sent notification to the Security Team","timestamp":"1688821020.0","upvote_count":"3","comment_id":"946483","poster":"jaydesai8"},{"comment_id":"946359","content":"C. Because the question mentioned PII only, there are other Sensitive Data aside from PII. \nreference: https://docs.aws.amazon.com/macie/latest/user/findings-publish-event-schemas.html look for Event example for a sensitive data finding","poster":"Iragmt","upvote_count":"2","timestamp":"1688809440.0","comments":[{"comment_id":"976714","content":"But Amazon SQS is typically used for decoupling and managing messages between distributed application components. It's not typically used for sending notifications directly to humans!","timestamp":"1691589180.0","upvote_count":"3","poster":"Ale1973"}]},{"poster":"kapit","upvote_count":"2","comment_id":"928494","timestamp":"1687270200.0","content":"AAAAAAA"},{"comments":[],"content":"C https://docs.aws.amazon.com/macie/latest/user/findings-types.html\nand notice the ensitiveData:S3Object/Personal\nThe object contains personally identifiable information (such as mailing addresses or driver's license identification numbers), personal health information (such as health insurance or medical identification numbers), or a combination of the two.","comment_id":"922950","poster":"jack79","upvote_count":"3","timestamp":"1686736440.0"},{"comment_id":"919249","poster":"MAMADOUG","content":"I vote for A, Sensitive = MACIE, and SNS to prevent Security Team","timestamp":"1686310980.0","upvote_count":"4"}],"answer_description":"","answer_ET":"A","answer_images":[],"timestamp":"2023-06-07 20:15:00","unix_timestamp":1686161700,"question_text":"A company stores data in Amazon S3. According to regulations, the data must not contain personally identifiable information (PII). The company recently discovered that S3 buckets have some objects that contain PII. The company needs to automatically detect PII in S3 buckets and to notify the company’s security team.\n\nWhich solution will meet these requirements?"},{"id":"mYHuYG7TzLBy6Yw4gZ31","discussion":[{"upvote_count":"18","timestamp":"1686161880.0","comment_id":"917514","comments":[{"poster":"MAMADOUG","comment_id":"919254","upvote_count":"3","timestamp":"1686311100.0","content":"Agree with you"}],"poster":"alexandercamachop","content":"Selected Answer: C\nC seems the most sutiable. \nIs the lowest cost. \nAfter 30 days is backup only, doesn't specify frequent access. \nTherefor we must transition the items after 30 days to Glacier Flexible Retrieval.\n\nAlso it says deletion after 90 days, so all answers specifying a transition after 90 days makes no sense."},{"timestamp":"1693585680.0","poster":"deechean","comment_id":"996256","upvote_count":"10","content":"Selected Answer: A\nThe Glacier min storage duration is 90 days. All the options using Glacier are wrong. Only A is feasible.","comments":[{"comments":[{"poster":"awsgeek75","content":"But the objects are deleted after 90 days so how is this charge applicable?","comment_id":"1126968","timestamp":"1705697880.0","upvote_count":"2"}],"upvote_count":"3","comment_id":"1017765","content":"S3 Standard is priced at $0.023 per GB for the first 50 TB stored per month\nS3 Glacier Flexible Retrieval costs $0.0036 per GB stored per month\nIf you move or delete data in Glacier within 90-days since their creation, you will pay an additional charge, that is called an early deletion fee. In US East you will pay $0.004/GB if you have deleted 1 GB in 2 months, $0.008/GB if you have deleted 1 GB in 1 month and $0.012 if you have deleted 1 GB within 3 months.\n\nEven with the early deletion fee, it appears to me that answer 'A' would still be cheaper.","timestamp":"1695731940.0","poster":"daniel33"},{"poster":"pentium75","upvote_count":"4","comment_id":"1111210","content":"But why 'transition to the S3 Standard storage class', aren't they there already by default?","timestamp":"1704116520.0"}]},{"content":"Selected Answer: C\nA: When logs are created, they are initially automatically created to S3 Standard. What are you transitioning anyway?\nB & D: You could've just deleted logs after 90 days. No need to move them somewhere else then delete them. That's just money down the drain.","comment_id":"1323111","upvote_count":"1","poster":"LeonSauveterre","timestamp":"1733578140.0"},{"comment_id":"1119085","content":"Selected Answer: C\nC: Lowest cost","poster":"awsgeek75","timestamp":"1704924240.0","comments":[{"upvote_count":"2","comment_id":"1119087","poster":"awsgeek75","timestamp":"1704924300.0","content":"A: Standard storage is default so this is wrong.\nB: Looks wrong because it moves object to S3GFR after 90 days when they could just be deleted so extra cost\nD: Same problem as B"}],"upvote_count":"2"},{"poster":"pentium75","timestamp":"1704117720.0","comment_id":"1111232","comments":[{"timestamp":"1719142080.0","comment_id":"1235798","poster":"Rhydian25","upvote_count":"3","content":"I guess you wanted to write \"Not B or D\""}],"upvote_count":"3","content":"Selected Answer: C\nNot A: Objects are created in S3 Standard, so it doesn't make sense to 'transition' them there \"30 days after creation\"\nNot B or C: No need to \"move all objects to the S3 Glacier Flexible Retrieval storage class after 90 days\" because we want to delete, not archive, them. Even if we would delete them right after moving, we would pay 90 days minimum storage duration. Plus, we are using \"Infrequent Access\" classes here, but we have no access at all."},{"upvote_count":"1","timestamp":"1703128620.0","poster":"ftaws","comment_id":"1102146","content":"Selected Answer: A\nrequirement : frequently analysis\n search cost : S3 STD 0.0004 vs IA 0.001\nso IA is more expensive than STD(A)"},{"poster":"EdenWang","upvote_count":"3","content":"Selected Answer: C\nC is most cost-effective","timestamp":"1700215920.0","comment_id":"1073194"},{"timestamp":"1693399800.0","upvote_count":"5","comment_id":"994107","content":"Selected Answer: C\nThings to note are: 30 days frequent access and 90 days after creation, so you only need to do 2 things, not 3. Objects in S3 will be stored by default for 30 days before you can move it to somewhere else, so C is the answer.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-transition-general-considerations.html","poster":"Hades2231"},{"timestamp":"1693023600.0","poster":"rjbihari","upvote_count":"2","content":"C is the correct one .\nAs after 30 days it doesn't says about access / retrieval , only backup so move items after 30 days to Glacier Flexible Retrieval.\nAnd after it says deletion , so expiration action will ensure that the objects are deleted after 90 days, even if they are not accessed","comment_id":"990509"},{"comments":[{"timestamp":"1704117540.0","upvote_count":"3","poster":"pentium75","content":"\"After 90 days, the logs can be moved to the S3 Glacier Flexible Retrieval storage class. This is the most cost-effective storage class for long-term archiving.\" yeah but we don't need long-term archiving, we want to delete them after 90 days.","comment_id":"1111231"}],"content":"Selected Answer: B\nI think - it is B\nThe first 30 days, the logs need to be highly available for frequent analysis. The S3 Standard storage class is the most expensive storage class, but it also provides the highest availability.\nAfter 30 days, the logs still need to be retained for backup purposes, but they do not need to be accessed frequently. The S3 Standard-IA storage class is a good option for this, as it is less expensive than the S3 Standard storage class.\nAfter 90 days, the logs can be moved to the S3 Glacier Flexible Retrieval storage class. This is the most cost-effective storage class for long-term archiving.\nThe expiration action will ensure that the objects are deleted after 90 days, even if they are not accessed","poster":"Guru4Cloud","upvote_count":"2","timestamp":"1692719760.0","comment_id":"987585"},{"content":"Selected Answer: C\nC is the most cost effective solution.","comment_id":"962314","upvote_count":"2","timestamp":"1690257540.0","poster":"TariqKipkemei"},{"timestamp":"1687439040.0","upvote_count":"2","poster":"antropaws","comment_id":"930542","content":"Selected Answer: C\nC most likely."},{"comments":[{"poster":"y0eri","comment_id":"924700","upvote_count":"4","timestamp":"1686878340.0","content":"I take that back. Moderator, please delete my comment."}],"comment_id":"924696","timestamp":"1686878220.0","content":"Selected Answer: A\nQuestion says \"All logs must be highly available for 30 days for frequent analysis\" I think the answer is A. Glacier is not made for frequent access.","upvote_count":"2","poster":"y0eri"},{"timestamp":"1686636000.0","comment_id":"921959","content":"Selected Answer: B\nI think B","poster":"KMohsoe","upvote_count":"1"}],"url":"https://www.examtopics.com/discussions/amazon/view/111434-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["C (69%)","A (25%)","6%"],"answer_images":[],"answer_description":"","exam_id":31,"unix_timestamp":1686161880,"choices":{"C":"Transition objects to the S3 Glacier Flexible Retrieval storage class 30 days after creation. Write an expiration action that directs Amazon S3 to delete objects after 90 days.","A":"Transition objects to the S3 Standard storage class 30 days after creation. Write an expiration action that directs Amazon S3 to delete objects after 90 days.","D":"Transition objects to the S3 One Zone-Infrequent Access (S3 One Zone-IA) storage class 30 days after creation. Move all objects to the S3 Glacier Flexible Retrieval storage class after 90 days. Write an expiration action that directs Amazon S3 to delete objects after 90 days.","B":"Transition objects to the S3 Standard-Infrequent Access (S3 Standard-IA) storage class 30 days after creation. Move all objects to the S3 Glacier Flexible Retrieval storage class after 90 days. Write an expiration action that directs Amazon S3 to delete objects after 90 days."},"answer":"C","topic":"1","answer_ET":"C","isMC":true,"timestamp":"2023-06-07 20:18:00","question_images":[],"question_id":504,"question_text":"A company wants to build a logging solution for its multiple AWS accounts. The company currently stores the logs from all accounts in a centralized account. The company has created an Amazon S3 bucket in the centralized account to store the VPC flow logs and AWS CloudTrail logs. All logs must be highly available for 30 days for frequent analysis, retained for an additional 60 days for backup purposes, and deleted 90 days after creation.\n\nWhich solution will meet these requirements MOST cost-effectively?"},{"id":"Q9A0wHuI4rfZmWGkkZHG","answer_description":"","choices":{"D":"Create a new AWS Key Management Service (AWS KMS) key with the alias/aws/ebs alias. Enable default Amazon Elastic Block Store (Amazon EBS) volume encryption for the account.","C":"Create the Amazon EKS cluster with default options. Use the Amazon Elastic Block Store (Amazon EBS) Container Storage Interface (CSI) driver as an add-on.","B":"Create a new AWS Key Management Service (AWS KMS) key. Enable Amazon EKS KMS secrets encryption on the Amazon EKS cluster.","A":"Create a new AWS Key Management Service (AWS KMS) key. Use AWS Secrets Manager to manage, rotate, and store all secrets in Amazon EKS."},"timestamp":"2023-06-07 09:14:00","answer_ET":"B","discussion":[{"timestamp":"1724337360.0","upvote_count":"7","comment_id":"987513","poster":"Guru4Cloud","content":"Selected Answer: B\nB is the correct solution to meet the requirement of encrypting secrets in the etcd store for an Amazon EKS cluster.\n\nThe key points:\n\nCreate a new KMS key to use for encryption.\nEnable EKS secrets encryption using that KMS key on the EKS cluster. This will encrypt secrets in the Kubernetes etcd store.\nOption A uses Secrets Manager which does not encrypt the etcd store.\nOption C uses EBS CSI which is unrelated to etcd encryption.\nOption D enables EBS encryption but does not address etcd encryption."},{"content":"Selected Answer: B\nEKS supports using AWS KMS keys to provide envelope encryption of Kubernetes secrets stored in EKS. Envelope encryption adds an addition, customer-managed layer of encryption for application secrets or user data that is stored within a Kubernetes cluster.\n\nhttps://eksctl.io/usage/kms-encryption/","comment_id":"962320","timestamp":"1721880420.0","upvote_count":"6","poster":"TariqKipkemei"},{"content":"Selected Answer: B\nThe problem is to ensure all secrets in Amazon EKS be encrypted, so the correct solution is to enable the secret encryption on the EKS cluster with a new AWS Key:\neksctl utils enable-secrets-encryption \\\n --cluster my-cluster \\\n --key-arn arn:aws:kms:region-code:account:key/key\nhttps://docs.aws.amazon.com/en_en/eks/latest/userguide/enable-kms.html","poster":"FlyingHawk","upvote_count":"1","timestamp":"1737590520.0","comment_id":"1345008"},{"upvote_count":"1","content":"Selected Answer: B\n\"must be encrypted in the Kubernetes etcd key-value store\" - that leaves B only.","comment_id":"1323114","timestamp":"1733578440.0","poster":"LeonSauveterre"},{"comment_id":"935927","poster":"manuh","timestamp":"1719534240.0","comments":[{"comment_id":"962323","timestamp":"1721880840.0","content":"option A does not enable Amazon EKS KMS secrets encryption on the Amazon EKS cluster","upvote_count":"2","poster":"TariqKipkemei"}],"upvote_count":"1","content":"Selected Answer: A\nWhy not a"},{"content":"Selected Answer: B\nB is the right option.\nhttps://docs.aws.amazon.com/eks/latest/userguide/enable-kms.html","timestamp":"1718893980.0","comment_id":"928510","upvote_count":"5","poster":"MrAWSAssociate"},{"upvote_count":"5","timestamp":"1717784460.0","poster":"alexandercamachop","comment_id":"917516","content":"Selected Answer: B\nIt is B, because we need to encrypt inside of the EKS cluster, not outside.\nAWS KMS is to encrypt at rest."},{"timestamp":"1717744440.0","poster":"AncaZalog","content":"is B, not D","upvote_count":"2","comment_id":"916971"}],"exam_id":31,"unix_timestamp":1686122040,"url":"https://www.examtopics.com/discussions/amazon/view/111385-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"question_id":505,"topic":"1","answer":"B","isMC":true,"answers_community":["B (96%)","4%"],"question_images":[],"question_text":"A company is building an Amazon Elastic Kubernetes Service (Amazon EKS) cluster for its workloads. All secrets that are stored in Amazon EKS must be encrypted in the Kubernetes etcd key-value store.\n\nWhich solution will meet these requirements?"}],"exam":{"isMCOnly":true,"isImplemented":true,"numberOfQuestions":1019,"provider":"Amazon","id":31,"lastUpdated":"11 Apr 2025","isBeta":false,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":101},"__N_SSP":true}