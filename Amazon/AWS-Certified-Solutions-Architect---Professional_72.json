{"pageProps":{"questions":[{"id":"CUtYeP14aDgacurIMdom","isMC":true,"topic":"1","answers_community":["A (100%)"],"discussion":[{"comment_id":"13934","content":"A true\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpce-gateway.html\n```\nEndpoint connections cannot be extended out of a VPC. Resources on the other side of a VPN connection, VPC peering connection, AWS Direct Connect connection, or ClassicLink connection in your VPC cannot use the endpoint to communicate with resources in the endpoint service.\n```","upvote_count":"39","poster":"manhmaluc","timestamp":"1632443880.0"},{"content":"I go with A","timestamp":"1635328200.0","comment_id":"281178","upvote_count":"10","poster":"Ebi"},{"content":"A - VPC EndPoint+ S3 Policy with condition\nThe main objective here is to prevent a malicious insider set up an EC2 instance in \"another\" VPC.","timestamp":"1669461120.0","poster":"evargasbrz","upvote_count":"1","comment_id":"727456"},{"content":"Answer is A, Stephane's discussion in Udemy about exact same scenario.","timestamp":"1667218680.0","poster":"resnef","comment_id":"708398","upvote_count":"1"},{"comment_id":"700453","upvote_count":"1","content":"Selected Answer: A\nI go with A","poster":"Cloud_noob","timestamp":"1666316160.0"},{"comment_id":"653593","upvote_count":"3","poster":"epomatti","content":"Selected Answer: A\nA - VPC Endpoint + S3 Policy","timestamp":"1661797800.0"},{"poster":"hilft","timestamp":"1658765640.0","upvote_count":"1","content":"A. Use endpoint.","comment_id":"636816"},{"content":"Selected Answer: A\nkeyword \"in another VPC\"","timestamp":"1656827340.0","upvote_count":"2","comment_id":"626435","poster":"aandc"},{"content":"Answer is B. You access from another VPC, you can either access through the internet or use S3 VPC endpoints. so in this case, S3 VPC endpoints would not come into the equation, as you won't need to create one, unless if you want access to the S3 buckets via AWS backbone, so any answer with S3 vpc endpoints is incorrect","upvote_count":"2","comment_id":"581119","timestamp":"1649148060.0","comments":[{"upvote_count":"2","comment_id":"581123","timestamp":"1649148120.0","poster":"bfal","content":"it says in \"another\"vpc, not the same VPC"}],"poster":"bfal"},{"content":"A for me. since its within a VPC access, seems logical to use a VPC endpoint and ACL to control access","poster":"Ni_yot","timestamp":"1646166540.0","upvote_count":"1","comment_id":"559001"},{"upvote_count":"1","poster":"shotty1","timestamp":"1643185980.0","content":"Selected Answer: A\nWhile in real life I would always suggest first looking into B, the customers concern in this question will be addressed by A","comment_id":"532702"},{"comment_id":"498282","content":"Correct Answer is A, \nB looks correct, but the roles are global & they can be attached to the ec2 in different VPC as well that will rule out option B.","poster":"fais1985","upvote_count":"3","timestamp":"1639110180.0"},{"comment_id":"458665","poster":"chaconerw","upvote_count":"2","timestamp":"1635989220.0","content":"The correct answer is A"},{"timestamp":"1635831420.0","upvote_count":"2","content":"It's A","comment_id":"449843","poster":"andylogan"},{"timestamp":"1635577020.0","comment_id":"362458","upvote_count":"2","poster":"Radhaghosh","content":"A is the most secured answer"},{"poster":"macshild","upvote_count":"1","content":"The correct Answer is A","comment_id":"347261","timestamp":"1635556620.0"},{"timestamp":"1635414240.0","comment_id":"334006","upvote_count":"2","content":"I'll go with A","poster":"WhyIronMan"},{"timestamp":"1635387420.0","upvote_count":"4","content":"Ans A for me","comment_id":"289348","poster":"Kian1"},{"comments":[{"poster":"01037","content":"An instance profile can be applied to an EC2 instance in another VPC","timestamp":"1635680760.0","upvote_count":"1","comment_id":"384243"}],"upvote_count":"1","timestamp":"1635309900.0","comment_id":"262846","poster":"sanjaym","content":"confuse between A & B. Need to do POC."},{"timestamp":"1635075900.0","comment_id":"259526","upvote_count":"2","poster":"cox1960","content":"A it is. Example:\n{\n \"Version\": \"2012-10-17\",\n \"Id\": \"Policy1415115909152\",\n \"Statement\": [\n {\n \"Sid\": \"Access-to-specific-VPCE-only\",\n \"Principal\": \"*\",\n \"Action\": \"s3:*\",\n \"Effect\": \"Deny\",\n \"Resource\": [\"arn:aws:s3:::my_secure_bucket\",\n \"arn:aws:s3:::my_secure_bucket/*\"],\n \"Condition\": {\n \"StringNotEquals\": {\n \"aws:sourceVpce\": \"vpce-1a2b3c4d\"\n }\n }\n }\n ]\n}"},{"timestamp":"1634998920.0","upvote_count":"5","content":"Answer is A. The keywrod is controlling access to S3 from a specific VPC.\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies-vpc-endpoint.html","comment_id":"245323","poster":"ju0n"},{"content":"A for sure","poster":"gookseang","comment_id":"242229","timestamp":"1634875980.0","upvote_count":"2"},{"comment_id":"241834","upvote_count":"2","poster":"T14102020","timestamp":"1634856840.0","content":"Correct answer is A. VPC endpoint is unique."},{"comment_id":"234556","timestamp":"1634578440.0","upvote_count":"2","content":"A.\nFind something interesting.\nI set a bucket policy to limit access only from vpce.\nAnd then associate vpce only with a custom route table.\nI thought EC2 instances in subnets only using main route table can NOT access S3.\nBut actually, those EC2 instances can access S3.\n\nThen, I associate vpce only with the main route table.\nEC2 instances under subnets only using the custom route table can NOT access S3.\n\nI guess main route table is a little special.","poster":"newme"},{"content":"A https://aws.amazon.com/blogs/aws/new-vpc-endpoint-for-amazon-s3/","poster":"petebear55","upvote_count":"1","timestamp":"1634506320.0","comment_id":"231287"},{"upvote_count":"2","timestamp":"1634311140.0","poster":"jackdryan","content":"I'll go with A","comment_id":"227182"},{"poster":"petebear55","comment_id":"220300","upvote_count":"2","content":"A .. as B would need a cross account role https://aws.amazon.com/premiumsupport/knowledge-center/s3-instance-access-bucket/","timestamp":"1634285520.0"},{"poster":"Bulti","comment_id":"206801","timestamp":"1634214180.0","upvote_count":"1","content":"A is the right answer"},{"comment_id":"148387","poster":"fullaws","content":"A is correct, Malicious insider refer to authority AWS user in the company","timestamp":"1634028360.0","upvote_count":"2"},{"comment_id":"134077","timestamp":"1633982820.0","content":"A for sure","poster":"NikkyDicky","upvote_count":"2"},{"poster":"noisonnoiton","upvote_count":"2","content":"go with A A","timestamp":"1633890180.0","comment_id":"133511"},{"upvote_count":"2","content":"A is answer. S3 bucket policy can be configured to allow traffic only from Vpc Endpoint.","poster":"chicagomassageseeker","comment_id":"117468","timestamp":"1633836780.0"},{"content":"A is the answer","poster":"arunkumar","timestamp":"1633447680.0","upvote_count":"2","comment_id":"38819"},{"timestamp":"1632990180.0","comment_id":"31090","content":"A should be the answer","poster":"dojo","upvote_count":"2"},{"comments":[{"comment_id":"73779","content":"I think B should work with EC2s in private subnet too as the route entry in private RT enables that. The problem with B is that the same users would have ability to reuse that instance profile elsewhere (unless strict conditions are set).","poster":"Smart","upvote_count":"2","timestamp":"1633677540.0"}],"comment_id":"16146","upvote_count":"2","timestamp":"1632584520.0","content":"I would go with A. Bucket policy restrict only accessed by VPC endpoint.\nB doesn't work if EC2 in private subnet.","poster":"chaudh"},{"timestamp":"1632562920.0","content":"A for sure\n\"If you're using an endpoint to Amazon S3, you can also use Amazon S3 bucket policies to control access to buckets from specific endpoints, or specific VPCs. For more information, see Using Amazon S3 Bucket Policies. \"","upvote_count":"2","poster":"DJTau","comment_id":"14795"},{"content":"Answer A because VPC endpoints are unique to a VPC and can't be shared","upvote_count":"4","poster":"route53","comment_id":"13964","timestamp":"1632525120.0"},{"timestamp":"1632436380.0","comments":[{"content":"Answer is A, Endpoint connections cannot be extended out of a VPC. This is a nail","timestamp":"1634059320.0","upvote_count":"1","comment_id":"181981","poster":"sam422"},{"content":"Dont think the your reason for A not being right is valid, \"Endpoint connections cannot be extended out of a VPC. Resources on the other side of a VPN connection, VPC peering connection, transit gateway, AWS Direct Connect connection, or ClassicLink connection in your VPC cannot use the endpoint to communicate with resources in the endpoint service.\" \nAnswer it think is A","upvote_count":"10","poster":"dman","timestamp":"1633720860.0","comment_id":"98650"}],"upvote_count":"2","poster":"donathon","content":"B\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-access.html\nhttps://aws.amazon.com/blogs/security/how-to-restrict-amazon-s3-bucket-access-to-a-specific-iam-role/\nA: This will allow any VPC that is allowed to access the VPN endpoint to also access the S3 bucket.\nB: This ensures only the instance that has the role can access the S3.\nC\\D: This does not solve the problem since it only encrypt the data and never store keys in instance metadata.","comment_id":"13523"}],"answer":"A","answer_ET":"A","question_id":356,"question_text":"A company uses Amazon S3 to store documents that may only be accessible to an Amazon EC2 instance in a certain virtual private cloud (VPC). The company fears that a malicious insider with access to this instance could also set up an EC2 instance in another VPC to access these documents.\nWhich of the following solutions will provide the required protection?","exam_id":32,"unix_timestamp":1569982680,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/5953-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"question_images":[],"choices":{"D":"Use S3 server-side encryption and protect the key with an encryption context.","B":"Use EC2 instance profiles and an S3 bucket policy to limit access to the role attached to the instance profile.","A":"Use an S3 VPC endpoint and an S3 bucket policy to limit access to this VPC endpoint.","C":"Use S3 client-side encryption and store the key in the instance metadata."},"timestamp":"2019-10-02 04:18:00"},{"id":"y4xOWGAZjYzFglijaORZ","url":"https://www.examtopics.com/discussions/amazon/view/5147-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"choices":{"C":"Parse VPC Flow Logs to determine if there is packet loss between the Lambda function and S3.","D":"Parse AWS X-Ray traces and analyze HTTP methods to determine the root cause of the HTTP errors.","A":"Parse HTTP logs in Amazon API Gateway for HTTP errors to determine the root cause of the errors.","E":"Parse S3 access logs to determine if objects being accessed are from specific IP addresses to narrow the scope to geographic latency issues.","B":"Parse Amazon CloudWatch Logs to determine processing times for requested images at specified intervals."},"unix_timestamp":1568394960,"answers_community":["BD (100%)"],"exam_id":32,"discussion":[{"comment_id":"31366","content":"B and D are correct.\nFirstly “A 504 Gateway Timeout Error means your web server didn't receive a timely response from another server upstream when it attempted to load one of your web pages. Put simply, your web servers aren't communicating with each other fast enough”.\nThis specific issue is addressed in the AWS article “Tracing, Logging and Monitoring an API Gateway API”. https://docs.amazonaws.cn/en_us/apigateway/latest/developerguide/monitoring_overview.html\nThe article specifically discusses using AWS X-Ray, AWS CloudTrail and AWS CloudWatch as the tools to utilized for debugging in this scenario.\nThe two options that encompass using AWS CloudWatch and AWS X-Ray are B and D respectively. AWS CloudTrail is not mentioned in any of the answers.","comments":[{"timestamp":"1636242300.0","poster":"student22","upvote_count":"2","content":"Also, http errors checked by A is already covered by D. Another reason to select B over A.","comment_id":"452313","comments":[{"poster":"student22","comment_id":"452315","timestamp":"1636276560.0","content":"Answer B,D","upvote_count":"1"}]},{"upvote_count":"1","comment_id":"889103","content":"The doc url was updated: https://docs.amazonaws.cn/en_us/apigateway/latest/developerguide/security-monitoring.html","timestamp":"1683167340.0","poster":"rockc"}],"poster":"LunchTime","upvote_count":"36","timestamp":"1632527700.0"},{"content":"The correct answers are BD.\nhttps://docs.aws.amazon.com/en_pv/apigateway/latest/developerguide/monitoring_overview.html","comment_id":"11341","upvote_count":"22","poster":"sb333","timestamp":"1632139740.0"},{"upvote_count":"1","poster":"SkyZeroZx","timestamp":"1686953400.0","comment_id":"925583","content":"Selected Answer: BD\nThe optimal steps for debugging the application issues are as follows:\n\nB. Parse Amazon CloudWatch Logs to determine processing times for requested images at specified intervals.\nBy analyzing the CloudWatch Logs, you can identify the processing times for requested images. This will help in identifying any performance bottlenecks or delays in processing the dynamic images.\n\nD. Parse AWS X-Ray traces and analyze HTTP methods to determine the root cause of the HTTP errors.\nBy using AWS X-Ray, you can trace and analyze the execution of your application components. Analyzing the X-Ray traces will provide insights into the execution flow and help identify any issues with the HTTP methods that could be causing the 504 Gateway Timeout errors."},{"comment_id":"801980","content":"OPTION A & D \n\nOUTPUT from Chat GBT \n\nBoth options of parsing the HTTP logs in Amazon API Gateway and parsing Amazon CloudWatch Logs are valuable for debugging the issues in the serverless application.\n\nParsing the HTTP logs in Amazon API Gateway is useful for identifying and resolving the 504 Gateway Timeout error, as it provides information about the specific requests that are timing out and any related error messages.\n\nParsing Amazon CloudWatch Logs is useful for identifying performance bottlenecks and resolving slowdowns in the application components, as it provides information about the processing times for the images and can help identify any potential issues with processing speed.\n\nIt may be best to implement both options to gain a comprehensive understanding of the issues and effectively resolve them.","timestamp":"1675858200.0","poster":"Heer","upvote_count":"1"},{"poster":"jj22222","comment_id":"577797","timestamp":"1648576380.0","upvote_count":"2","content":"Selected Answer: BD\nb and d look right"},{"timestamp":"1638330420.0","comment_id":"491223","content":"B,D is right","upvote_count":"1","poster":"AzureDP900"},{"timestamp":"1636234200.0","upvote_count":"2","comment_id":"450871","content":"Answer is B＆D","poster":"moon2351"},{"poster":"andylogan","timestamp":"1636151520.0","content":"It's B D","upvote_count":"1","comment_id":"449846"},{"content":"The correct answer is BD","comment_id":"347267","upvote_count":"1","poster":"macshild","timestamp":"1636144500.0"},{"content":"I'll go with B,D","timestamp":"1636074480.0","comment_id":"334022","upvote_count":"2","poster":"WhyIronMan"},{"timestamp":"1635621540.0","upvote_count":"1","comment_id":"323097","poster":"AJBA","content":"https://aws.amazon.com/premiumsupport/knowledge-center/api-gateway-504-errors/"},{"timestamp":"1635550620.0","comment_id":"289349","content":"Ans B,D for me","upvote_count":"3","poster":"Kian1"},{"poster":"bnagaraja9099","upvote_count":"2","comment_id":"283540","timestamp":"1635433740.0","content":"D for sure. X-Ray is basic for performance monitoring. \nBetween A and B, 504 is the gateway timeout returned by the API gateway. But B talks about processing time in other components which most likely is what caused the time out. So I vote for B. B& D\nB & D"},{"upvote_count":"3","content":"Answer is BD\nE is irrelevant","comment_id":"281179","timestamp":"1635340980.0","poster":"Ebi"},{"timestamp":"1634789580.0","content":"B & D is the correct answer.","comment_id":"258164","poster":"SachinJha","upvote_count":"3"},{"upvote_count":"1","comment_id":"242232","timestamp":"1634678040.0","content":"I will go B&D","poster":"gookseang"},{"poster":"T14102020","upvote_count":"2","content":"Correct answer is BD","comment_id":"241848","timestamp":"1634631540.0"},{"comment_id":"231294","upvote_count":"1","timestamp":"1634415420.0","content":"B AND D I WOULD GO WITH https://docs.amazonaws.cn/en_us/apigateway/latest/developerguide/monitoring_overview.html","poster":"petebear55"},{"content":"I'll go with B,D","poster":"jackdryan","comment_id":"227974","upvote_count":"3","timestamp":"1634127960.0"},{"content":"B&D correct answers","poster":"JK2","comment_id":"227075","upvote_count":"2","timestamp":"1634121780.0"},{"timestamp":"1634094180.0","comment_id":"218200","upvote_count":"2","content":"B and D is the correct answer","poster":"Bulti"},{"upvote_count":"2","poster":"ola12","timestamp":"1634036700.0","comment_id":"211317","content":"B,D final answer"},{"content":"Answer is BD\nE is NOT the answer, error is \"504 Gateway Timeout\" has nothing to do with network latency","upvote_count":"1","poster":"Ebi","comment_id":"203604","timestamp":"1633852560.0"},{"upvote_count":"1","content":"The correct answers are BD.","poster":"df1228","comment_id":"182009","timestamp":"1633799940.0"},{"timestamp":"1633581360.0","content":"B&D is correct answer","poster":"Neive","upvote_count":"1","comment_id":"170940"},{"comment_id":"163756","timestamp":"1633473240.0","poster":"briantod1970","upvote_count":"1","content":"go with B,D for sure ,"},{"timestamp":"1633404840.0","comment_id":"148399","content":"A and D is correct, references from Exam_boy, 500 series errors caused by internal failures will not generate logs, so using A will help to generate log for troubleshoot. https://docs.aws.amazon.com/apigateway/latest/developerguide/rest-api-monitor.htm AWS X-Ray will show the request flow which help in troubleshoot.","upvote_count":"1","poster":"fullaws"},{"content":"go with B,D","timestamp":"1633368840.0","comment_id":"133514","poster":"noisonnoiton","upvote_count":"2"},{"content":"It's BD.\nA is wrong for two reasons\n1: \"Parse HTTP logs in Amazon API Gateway...\" - there are no HTTP logs in API gwy. Both the API access and execution logs are in CloudWatch logs. \n2: \"...for HTTP errors to determine the root cause\"... There is no root cause information in any API logs","comment_id":"131005","poster":"NikkyDicky","timestamp":"1633366320.0","comments":[{"poster":"micahdevops","content":"yeah, i agree with you. as the doc mentioned \"500 series errors caused by internal failures will not generate logs\".So,\"Parse HTTP logs in Amazon API Gateway...\" won't help to find the cause of 504 timeout error","upvote_count":"1","timestamp":"1633862280.0","comment_id":"206073"}],"upvote_count":"4"},{"content":"D is for sure. There is a debate between A or B . In my opinion both are valid options. Yes API logs can be ingested into cloud watch. However key point here is which one is going to give you more troubleshooting info, as question is looking for. Of course, A is the clear choice there. We need to look at API logs to find the root cause of HTTP errors, than looking in to the timings of errors in option B. (I dont understand, why does AWS give these \"detective\" type of questions). The following Logging parameters will give you the required information:\n$context.error.message \nA string that contains an API Gateway error message. -","upvote_count":"4","timestamp":"1633350240.0","comment_id":"95648","poster":"JAWS1600"},{"poster":"Exam_boy","comment_id":"85052","content":"AE \n\nAPI Gateway might not generate logs and metrics in the following cases:\n500 series errors caused by internal failures\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/rest-api-monitor.html","upvote_count":"1","timestamp":"1633328580.0"},{"poster":"koalasy","timestamp":"1633031340.0","content":"A&D,\nD is agreed by all of us. \nJust need check difference between A & B, \nnormally we use AWS X-Ray, AWS CloudTrail and AWS CloudWatch for troubleshooting, \nwe can use cloudwatch to find out issue when we try to see the 500 series error from DynamoDB server, but this time there is no issue with DynamoDB, this 504 error is from API gateway we assume, then there is no ERR log can be seen in cloudwatch, thus we have to go to API gateway to check - this is HPPT logs in API gateway. \nNote:\nAPI Gateway might not generate logs and metrics in the following cases:\n413 Request Entity Too Large errors\nExcessive 429 Too Many Requests errors\n400 series errors from requests sent to a custom domain that has no API mapping\n500 series errors caused by internal failures\nthe key point is we have to go inside API gateway to check out API gateway's issue.","upvote_count":"5","comment_id":"83334"},{"content":"I think D & E","comment_id":"75467","poster":"Joeylee","upvote_count":"1","comments":[{"upvote_count":"1","content":"Sorry B and D. X-ray obvious, and CloudWatch log for api gateway","poster":"Joeylee","comment_id":"75468","timestamp":"1632784440.0"}],"timestamp":"1632756060.0"},{"comment_id":"55474","timestamp":"1632632700.0","content":"B & D correct, 504 is server side error that is related to lambda function in this scenario. CloudWatch and X-ray will do the work.","poster":"Gorha","upvote_count":"6"},{"comment_id":"44742","content":"Should be A&D\nNot C,E because it not relate to static image or loading time\nAs donathon mention, B is not correct","poster":"amog","upvote_count":"2","timestamp":"1632590160.0"},{"timestamp":"1632563400.0","upvote_count":"4","comment_id":"41157","content":"My answer is B,D","poster":"markpark"},{"comment_id":"30425","upvote_count":"4","content":"I go with BE, D is not valid because we are assuming the X-Ray is enabled. B can diagnose if there are any Lambda level delays in processing. E will ensure if it is due to some specific customer or IP latency","timestamp":"1632400800.0","poster":"dojo"},{"comment_id":"27637","timestamp":"1632364020.0","upvote_count":"4","content":"I support BD, logs from Api gateway is stored in cloudwatch. X-ray is obvious.","poster":"broffer"},{"poster":"pra276","timestamp":"1632359580.0","content":"Answer is AD","upvote_count":"3","comment_id":"21829"},{"content":"AD\nBoth A and D seems to be doing the same thing but may have different result. This is why I chose them.\nA: https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-api-gateway-supports-access-logging/ \nB: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-504-gateway-timeout.html >> 504 already indicates problem at the origin, why do we want to still determine the processing time?\nC: This is not useful as 504 error points to timeout between the frontend and the backend (origin).\nD: https://docs.aws.amazon.com/en_pv/apigateway/latest/developerguide/apigateway-xray.html\nE: This is not a latency issue. It’s the Cloudfront unable to download from origin.","comments":[{"content":"BD\nAPI gateway doesn't host their HTTP logs but logging can be enabled to write logs to CloudWatch Logs.\nRef: https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-logging.html\nBased on that, A is ruled out and B is the right answer.\nEverybody agrees on D (X-Ray).","upvote_count":"1","timestamp":"1635130260.0","comment_id":"280393","poster":"shammous"},{"timestamp":"1634868240.0","comment_id":"266297","upvote_count":"1","content":"Why you talk about CloudFront when there is no mention of it in the question? It could be that the lambda is returning an S3 signed URL for the image, then you don't need CloudFront to download the image.\n\nAlso, in B, you may want to know if the image processing is the one taking most of the time, or what part of the processing is taking more time than use to. I would go with B&D","poster":"sarofi"}],"upvote_count":"16","poster":"donathon","comment_id":"13520","timestamp":"1632306720.0"},{"poster":"Moon","content":"I think D & E","timestamp":"1632118320.0","comments":[{"poster":"tan9","content":"I will go for D, E too.\n\nAll reported failures related to images retrieving, and not all users suffer from the same issuer, there must be something wrong between the flow requesting the image. And the flow may have multiple API gateways and Lambda functions, so AWS X-Ray (option D) is the only place can gather the complete trace information. Option A and B seems not able to provide something useful, since we already there is a latency in requests to images. Option C is a bit too low-level, and once there is some wrong in the link, we can spot it from the X-Ray.","upvote_count":"6","timestamp":"1632390600.0","comment_id":"29482"}],"comment_id":"11012","upvote_count":"6"}],"timestamp":"2019-09-13 19:16:00","answer":"BD","question_text":"The Solutions Architect manages a serverless application that consists of multiple API gateways, AWS Lambda functions, Amazon S3 buckets, and Amazon\nDynamoDB tables. Customers say that a few application components slow while loading dynamic images, and some are timing out with the `504 Gateway\nTimeout` error. While troubleshooting the scenario, the Solutions Architect confirms that DynamoDB monitoring metrics are at acceptable levels.\nWhich of the following steps would be optimal for debugging these application issues? (Choose two.)","isMC":true,"answer_description":"","answer_images":[],"question_id":357,"answer_ET":"BD","topic":"1"},{"id":"dAVHio4PPIrRedMoT608","unix_timestamp":1568690760,"discussion":[{"upvote_count":"37","timestamp":"1632093480.0","comment_id":"11358","poster":"sb333","content":"Could this be CE? EBS with PIOPS has max of 80,000 IOPS/instance. Ephemeral storage is > 100,000 IOPS/instance. The question doesn't really mention other requirements other than static file content, which doesn't mean durable or temporary. AWS site says Ephemeral Storage is ideal \"for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers.\" Without more specifics, I would think C&E fit the bill of actual requirements of the question. Trying not to think of what I would use personally. https://docs.aws.amazon.com/en_pv/AWSEC2/latest/UserGuide/InstanceStorage.html"},{"comments":[{"comment_id":"211707","timestamp":"1633782720.0","content":"D doesn't seems to be answer for Provisioned IOPS SSD (io2)\n16384 : Size (GiB) (Min: 4 GiB, Max: 16384 GiB) \nIOPS: 64000 (Min: 100 IOPS, Max: 64000 IOPS) \nVolumes with greater than 32000 IOPS must be attached to a Nitro based instance to achieve p\nrovisioned performance.","upvote_count":"2","poster":"GopiSivanathan"},{"upvote_count":"1","poster":"porlarowl","comment_id":"204884","timestamp":"1633660560.0","content":"I agree with you.\nalso mentioned EBS volume\"s\" on D"},{"poster":"WillCloud","comment_id":"446160","timestamp":"1635841140.0","upvote_count":"5","content":"CE. \n\n1. Only io2 Block Express in Provisioned IOPS SSD can support 100K iops. io1 & io2 can only support up-to 64K iops.\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html\n\n2. io2 Block Express volumes are supported with R5b instances only.\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html\n\n3. The new R5b instance is powered by the AWS Nitro System to provide the best network-attached storage performance available on EC2. And the minimum requirement for 100k iops is r5b.12xlarge, which is 48 vCPUs and 384 GiB, too expensive and not realistic for most cases.\nhttps://aws.amazon.com/blogs/aws/new-amazon-ec2-r5b-instances-providing-3x-higher-ebs-performance/\n\n4. Instance store can provide high iops with much lower cost. E.g. i3.2xlarge can provide 180k write IOPS, which has 8 vCPU and 61GiB. \n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html#i2-instances-diskperf\nhttps://aws.amazon.com/ec2/instance-types/i3/"}],"upvote_count":"15","timestamp":"1633545060.0","comment_id":"185112","content":"C,D\nProvisioned IOPS has max of 160,000 IOPS/instance. 80,000 IOPS/instance is for previous generation volume type.\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html","poster":"blaubee"},{"poster":"mrgreatness","upvote_count":"2","content":"Answer is c and D. With Ephermal storage ( instance store) the data will be lost if instance stops for example. CD is 100% right answer","timestamp":"1666292820.0","comment_id":"700224"},{"content":"C,D.\n\nProvisioned IOPS can support uto 260K IOPS\nhttps://aws.amazon.com/ebs/features/","poster":"ashii007","comment_id":"696586","upvote_count":"2","timestamp":"1665954900.0"},{"timestamp":"1665880320.0","poster":"mrgreatness","content":"It says FIXED storage! Ephermanl will be lost if instance is stopped. C & D for me","upvote_count":"3","comment_id":"695808"},{"upvote_count":"1","poster":"jujumomma","content":"C, E\nC. EFS - POSIX file system ([https://docs.aws.amazon.com/ko_kr/efs/latest/ug/creating-using.html](https://docs.aws.amazon.com/ko_kr/efs/latest/ug/creating-using.html))\nD. Amazon EBS volumes with Provisioned IOPS is 64K. ([https://aws.amazon.com/ko/ebs/provisioned-iops/](https://aws.amazon.com/ko/ebs/provisioned-iops/))\n\nE. [https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/storage-optimized-instances.html](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/storage-optimized-instances.html)","timestamp":"1663325700.0","comment_id":"670714"},{"comment_id":"625139","poster":"TechX","timestamp":"1656579480.0","upvote_count":"3","content":"Selected Answer: CE\nCause the question not mention to be HA, so we could choose C over D. With D, we only have max IOPs 160k with INSTANCE, while with VOLUMN IOPs maximum is 64k","comments":[{"poster":"TechX","content":"my typo, we could choose E over D*","timestamp":"1656579540.0","upvote_count":"1","comment_id":"625140"}]},{"upvote_count":"2","content":"Selected Answer: CE\nCE look right","poster":"jj22222","comment_id":"577820","timestamp":"1648578060.0"},{"upvote_count":"1","comment_id":"513112","timestamp":"1640849940.0","poster":"cldy","content":"C and E."},{"poster":"student22","upvote_count":"2","timestamp":"1636300440.0","content":"C,E\n---","comment_id":"452680"},{"timestamp":"1635915840.0","comment_id":"449897","upvote_count":"1","content":"It's C E","poster":"andylogan"},{"poster":"AWS_Noob","comment_id":"438828","timestamp":"1635713340.0","content":"Going forward it might be C & D \nBlock express is GA now and no longer under preview \n\nhttps://aws.amazon.com/about-aws/whats-new/2021/07/aws-announces-general-availability-amazon-ebs-block-express-volumes/","upvote_count":"3"},{"comment_id":"423043","content":"The original answer is CE, but now D also meets requirement. So the answers are either CD or CE. If it appears in the exam, I will go with CE.","comments":[{"content":"Ephemeral storage\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html\n\nEBS volume\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html","poster":"walkwolf3","upvote_count":"1","comment_id":"423045","timestamp":"1635711960.0"}],"timestamp":"1635649740.0","upvote_count":"3","poster":"walkwolf3"},{"comment_id":"418651","timestamp":"1635610380.0","poster":"jobe42","content":"C and D (IOPS in RAID)","upvote_count":"1"},{"poster":"RichMnz","comment_id":"405617","upvote_count":"4","timestamp":"1635577500.0","content":"C - Yes. EFS supports Posix, and designed for multiple instances.\nD? - No. EBS max IOPS is 64k per volume, io2 Block Express is only available in preview. \nE - Yes. Ephemeral storage is also block storage and meets the IOPS requirement."},{"content":"Im going for CD, i dont understand why should be E while you can choose Provisioned IO2\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html","comment_id":"387704","comments":[{"content":"Yup you are correct, io2 Block Express can now go upto 256,000 IOPS\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html","comment_id":"395600","poster":"DeathFrmAbv","comments":[{"comment_id":"402884","timestamp":"1635553140.0","content":"io2 Block Express is a feature in preview. AWS does not test on features that are still in preview.","upvote_count":"2","poster":"student2020"}],"timestamp":"1635540600.0","upvote_count":"2"}],"timestamp":"1635437340.0","poster":"Kopa","upvote_count":"3"},{"content":"I think some of you need to read up on what ephemeral storage is\nanswer is C&D","comment_id":"382071","poster":"wem","timestamp":"1635167400.0","upvote_count":"3"},{"comment_id":"380377","timestamp":"1635028500.0","content":"C abd D, Please check io2 Block Express. 256,000 IOPS","comments":[{"timestamp":"1635315480.0","comment_id":"385850","poster":"01037","content":"CE\n\nhttps://docs.aws.amazon.com/whitepapers/latest/aws-storage-services-overview/amazon-ec2-instance-storage.html\nAmazon EC2 Instance Storage supports more than 100k iops\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html#io2-block-express\n‡ io2 Block Express volumes are available as an opt-in preview only.\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html\nvery few instance supports more than 100k iops","upvote_count":"1"}],"upvote_count":"1","poster":"amithbti416"},{"timestamp":"1634950440.0","poster":"Radhaghosh","content":"with io2 you can get 100K+ IOPS (which was not the case with io1).\nSo from current capability point of view answer is C, D","upvote_count":"1","comment_id":"362461"},{"upvote_count":"1","content":"for Data layer always use EFS for service layer with IOPS greater than 100K well EBS IO2 with block express delivers up to 260K IOPS whiles Ephemeral storage (instance store) delivers more than 260K IOPS since this question didn't give a hard limit on the IOPS or emphasize the need for persistent storage then the correct answer is CE","timestamp":"1634949660.0","comment_id":"347269","poster":"macshild"},{"poster":"WhyIronMan","timestamp":"1634883360.0","content":"I'll go with C, D","comment_id":"334641","upvote_count":"2"},{"content":"the corect answer is CD for persistent block storage use EBS and for persistent shared network file storage use EFS","comment_id":"329951","timestamp":"1634868780.0","poster":"macshild","upvote_count":"1"},{"poster":"wind","comment_id":"290685","content":"prefer CD, Ephemeral Storage will lost the data.","upvote_count":"1","timestamp":"1634751540.0"},{"content":"C, E - It would be good if they can update the answer after seeing so many folks providing feedback.","upvote_count":"2","comment_id":"287130","poster":"LB","timestamp":"1634687760.0"},{"timestamp":"1634583780.0","poster":"Ebi","comment_id":"281194","content":"I go with CE,","upvote_count":"2"},{"timestamp":"1634500740.0","comment_id":"281190","content":"With minimum data provided this is one of the BAD questions from AWS.","upvote_count":"3","poster":"Ebi"},{"comment_id":"262845","upvote_count":"1","content":"CE for sure.","poster":"sanjaym","timestamp":"1634493480.0"},{"timestamp":"1634477400.0","upvote_count":"1","comment_id":"242233","poster":"gookseang","content":"seems CE"},{"timestamp":"1634419740.0","comment_id":"241888","upvote_count":"1","poster":"T14102020","content":"Correct is CE."},{"timestamp":"1634370000.0","poster":"newme","content":"Checked all comments, but still can't decided it's D or E.\nMaybe it's just an old question when EBS didn't support 100k iops.","comment_id":"235493","upvote_count":"1"},{"comment_id":"234616","content":"C,E as no mention of data persistency\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","timestamp":"1634343420.0","upvote_count":"1","poster":"cloudgc"},{"comments":[{"upvote_count":"2","poster":"jackdryan","timestamp":"1634325540.0","comment_id":"233490","content":"I changed to C,D. I don't know what I was thinking. It is obvious. Thanks peterbear55"}],"timestamp":"1634147700.0","comment_id":"231308","upvote_count":"4","content":"Not E because data will be lost when instance is terminated .. https://cloud.netapp.com/blog/backing-up-ephemeral-storage-to-aws-ebs#:~:text=Ephemeral%3A%20Instance%20store%20volumes%20also,type%20is%20ephemeral%20by%20default.","poster":"petebear55"},{"timestamp":"1634013180.0","comments":[{"content":"Sorry C because of Posix support on EFS, not because of high IO. It was a copy paste error","poster":"jackdryan","upvote_count":"1","comment_id":"228025","timestamp":"1634043480.0"}],"upvote_count":"1","poster":"jackdryan","comment_id":"228023","content":"I'll go with C,E\nC: Because of Posix support on EFS and capable of high IO\nE: Ephemeral has max of 1.6million IOPS. It is Block storage and capable of high IO"},{"comment_id":"220413","timestamp":"1634012340.0","poster":"petebear55","upvote_count":"1","content":"C because s3 does not support POSIX file system also d"},{"timestamp":"1633980420.0","poster":"YouYouYou","upvote_count":"2","comment_id":"220215","content":"C&D \nC is obvious Posix support is only on EFS\nD is confusing because some commenters here are thinking block level support which can go to 64000 IOPs in the best case. but the keyword is application is running on EC2 instance so he is giving a hint for a max IOPS per the instance instead which can go 160K IOPS per instance the link is already shared in previous comments."},{"comment_id":"219401","timestamp":"1633952580.0","content":"C & D. Max IOPS/Instance: 160,000 for io2\nhttps://aws.amazon.com/ebs/volume-types/","poster":"Possum4Fun","upvote_count":"2"},{"poster":"Bulti","comment_id":"218235","upvote_count":"1","timestamp":"1633887060.0","content":"https://aws.amazon.com/ebs/features/\nThe above link indicates that pIOPS support upto 16000 oops/ instance and considering that the storage is for static files I would go with C and D"},{"comment_id":"213901","content":"C and E for sure. \nD is not correct as max iops per volume is 64K. For people thinking it is 160K, that is per instance and you need to attach multiple volume in RAID config.","timestamp":"1633866420.0","upvote_count":"1","poster":"vjt"},{"timestamp":"1633645740.0","content":"The question is not what the actual right answer is, it is what the exam marking systems or robot has been programmed to match the \"right\" answer. This is the question I always have in mind that nobody can answer. The question was set in the at the point where 80k was the max EBS IOPS, but it has been improved, but has the exam marking robot has also been improved ;-) ???","poster":"AlwaysLearning2020","upvote_count":"4","comments":[{"poster":"lydia_young","upvote_count":"1","timestamp":"1634319840.0","comment_id":"231969","content":"That's a good point."}],"comment_id":"189658"},{"poster":"Phat","upvote_count":"1","content":"In the question it mentions about \"block storage\" so it should be EBS as Sdee1013 points out. D Right?","timestamp":"1633542960.0","comment_id":"165276"},{"comment_id":"148403","poster":"fullaws","timestamp":"1633511940.0","content":"C and E is correct","upvote_count":"1"},{"timestamp":"1633432980.0","content":"CD\nE - Ephemeral storage is for temporary storage for data that changes frequently which is not the case here - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","upvote_count":"4","comment_id":"139709","poster":"dummrocks"},{"content":"C and D. E does not make sense as question specifically asks for static content. Ephemeral Storage is for transient kind of data i.e. temporary. \n\nI see people mentioning Maximum IOPS of 80,000 but that is per instance. This storage layer is still in design phase :)","poster":"IAmNotLambda","comment_id":"138344","timestamp":"1633318860.0","upvote_count":"7"},{"upvote_count":"1","content":"Its C,E as its 100k above IOPS which is achieved by instance stores not by EBS.","timestamp":"1633296900.0","poster":"Anila_Dhharisi","comment_id":"137701"},{"content":"CE, since no mention of RAID","upvote_count":"1","comment_id":"134081","timestamp":"1633279740.0","poster":"NikkyDicky"},{"poster":"noisonnoiton","comment_id":"133526","upvote_count":"2","timestamp":"1633239960.0","comments":[{"comment_id":"143157","content":"revised,, C,E","poster":"noisonnoiton","timestamp":"1633506000.0","upvote_count":"1"}],"content":"go with C,D\nhttps://aws.amazon.com/ebs/features/"},{"poster":"mat2020","timestamp":"1633212840.0","content":"ANS: C & E","upvote_count":"1","comment_id":"133264"},{"poster":"MasterFox","timestamp":"1633177320.0","content":"C,\n\nD, Provisioned IOPS to 100k plus, \ngo to the below link and you can manually add 100K IOPS \n\nhttps://aws.amazon.com/ebs/pricing/\nhttps://aws.amazon.com/about-aws/whats-new/2012/07/31/announcing-provisioned-iops-for-amazon-ebs/","upvote_count":"1","comment_id":"121223"},{"content":"CE .\nD is wrong. EBS maximum IOPS is 80 K, which is also limited by Instance network throughput ( EBS is network attached)\nE is Block storage - capable of high IO","comment_id":"107251","comments":[{"poster":"inf","comment_id":"117588","upvote_count":"2","timestamp":"1633050420.0","content":"Answer: C,D\nIt asks for static file content - ephemeral is temporary. Both EBS PIOPS and Ephemeral (instance store) storage can use RAID, thus EBS is the only answer."}],"poster":"JAWS1600","upvote_count":"1","timestamp":"1633048860.0"},{"poster":"sdee1013","content":"It does mention \"block storage\" volumes so maybe c and d","comment_id":"103568","timestamp":"1632943500.0","upvote_count":"2"},{"timestamp":"1632892560.0","upvote_count":"3","content":"CD is correct answer","poster":"sunilrch","comment_id":"103512"},{"poster":"CloudYogi","timestamp":"1632875160.0","upvote_count":"3","content":"CD is correct answer","comment_id":"98441"},{"comments":[{"content":"We can easily implement RAID 0 for multiple EBS PIOPS to achieve > 100K IOPS. Instance store is NOT for persistent data (well, you may argue that you can easily restore the static data... your choice!)","timestamp":"1632818340.0","comment_id":"79888","poster":"Justiono","upvote_count":"3","comments":[{"poster":"JAWS1600","comment_id":"96880","upvote_count":"2","content":"Yes RAID0 can add up but they did not mention RAID 0. I guess ephermal will best suit the answer","timestamp":"1632829380.0"}]}],"timestamp":"1632715740.0","content":"Answer is C,E\nThe keyword is \"more than 100k IOPS\" => EBS cannot deal with that (max 80000)","comment_id":"44751","upvote_count":"5","poster":"amog"},{"content":"my choice is C,E","comment_id":"41158","poster":"markpark","timestamp":"1632691380.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1632684900.0","poster":"Scunningham99","content":"agree with c and e","comment_id":"28189"},{"content":"C\nD: EBS with PIOPS has max of 80,000 IOPS/instance.\nE: Ephemeral has max of 1.6million IOPS.\nhttps://aws.amazon.com/ebs/features/\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html","comment_id":"13519","comments":[{"timestamp":"1632544500.0","content":"CE\nA\\B: S3 is not POSIX file system, it’s object based storage. POSIX file system is to unify the Unix\\Linux world so they can share data. The solution is NFS base file sharing.\nD: EBS with PIOPS has max of 80,000 IOPS/instance.\nE: Ephemeral has max of 1.6million IOPS.\nhttps://aws.amazon.com/ebs/features/\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html","poster":"donathon","upvote_count":"20","comment_id":"14079"}],"poster":"donathon","upvote_count":"6","timestamp":"1632518280.0"}],"isMC":true,"question_id":358,"timestamp":"2019-09-17 05:26:00","answers_community":["CE (100%)"],"question_images":[],"exam_id":32,"answer_images":[],"topic":"1","choices":{"C":"Data layer ג€\" Amazon EFS","D":"Service layer ג€\" Amazon EBS volumes with Provisioned IOPS","E":"Service layer ג€\" Amazon EC2 Ephemeral Storage","B":"Data layer ג€\" Amazon EC2 Ephemeral Storage","A":"Data layer ג€\" Amazon S3"},"answer_description":"","answer_ET":"CE","answer":"CE","question_text":"A Solutions Architect is designing the storage layer for a recently purchased application. The application will be running on Amazon EC2 instances and has the following layers and requirements:\n✑ Data layer: A POSIX file system shared across many systems.\n✑ Service layer: Static file content that requires block storage with more than 100k IOPS.\nWhich combination of AWS services will meet these needs? (Choose two.)","url":"https://www.examtopics.com/discussions/amazon/view/5280-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"dHt3Rf6caVLTpmdrvoL5","timestamp":"2019-09-27 18:25:00","question_images":[],"answer":"AB","isMC":true,"exam_id":32,"choices":{"C":"Create a script that checks the load on all web servers and terminates unnecessary On-Demand instances.","B":"Use On-Demand instances for baseline capacity requirements and use Spot Fleet instances for the demand spikes. [1]","A":"Purchase Reserved instances for baseline capacity requirements and use On-Demand instances for the demand spikes. [1]"},"unix_timestamp":1569601500,"answers_community":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/5776-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"timestamp":"1632233760.0","content":"A company has an application that runs a web service on Amazon EC2 instances and stores .jpg images in Amazon S3. The web traffic has a predictable baseline, but often demand spikes unpredictably for short periods of time. The application is loosely coupled and stateless. The .jpg images stored in Amazon S3 are accessed frequently for the first 15 to 20 days, they are seldom accessed thereafter but always need to be immediately available. The CIO has asked to find ways to reduce costs.\n\nWhich of the following options will reduce costs? (Choose two.)\n\nA. Purchase Reserved instances for baseline capacity requirements and use On-Demand instances for the demand spikes.\nB. Configure a lifecycle policy to move the .jpg images on Amazon S3 to S3 IA after 30 days.\nC. Use On-Demand instances for baseline capacity requirements and use Spot Fleet instances for the demand spikes.\nD. Configure a lifecycle policy to move the .jpg images on Amazon S3 to Amazon Glacier after 30 days\nE. Create a script that checks the load on all web servers and terminates unnecessary On-Demand instances.\n\nMy choice is AB","comment_id":"13864","upvote_count":"78","poster":"awsgcpazure","comments":[{"content":"AB\nA: This make a lot of sense\nB\\D: This would allow the files to be immediately accessible still vs Glacier.\nC: Spot instance is not guaranteed so is not suitable.\nE: This should be done on CloudWatch.","timestamp":"1632308760.0","poster":"donathon","comment_id":"14094","upvote_count":"7"},{"timestamp":"1635965460.0","comment_id":"385851","poster":"01037","content":"Yes it is AB\n\nBut depending on how seldom and how immediately it requires, Glacier could be an option","upvote_count":"2"}]},{"timestamp":"1664215740.0","comment_id":"680043","poster":"Ni_yot","content":"Its A and B. The other just dont fit the bill as an answer.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1662165180.0","comment_id":"657929","content":"A and B for sure there is no other option suitable.","poster":"AYANtheGLADIATOR"},{"poster":"cldy","upvote_count":"1","comment_id":"513115","content":"A and B.","timestamp":"1640850120.0"},{"comment_id":"497638","timestamp":"1639047300.0","poster":"cldy","content":"A. Purchase Reserved instances for baseline capacity requirements and use On-Demand instances for the demand spikes.\nB. Configure a lifecycle policy to move the .jpg images on Amazon S3 to S3 IA after 30 days","upvote_count":"1"},{"content":"It's A B","comment_id":"449900","upvote_count":"1","poster":"andylogan","timestamp":"1636187820.0"},{"comments":[{"content":"S3 Standard-IA and S3 One Zone-IA objects are available for millisecond access (similar to the S3 Standard storage class) -> A,B","poster":"tekkart","upvote_count":"1","timestamp":"1635909420.0","comment_id":"376765"}],"upvote_count":"1","content":"At first, A,B\nThen the question \"how to stop the on-demand instances if the spikes go unpredictably\", ,plus the images need always to be immediately available. Then, the answer may be A,E","poster":"tekkart","timestamp":"1635690000.0","comment_id":"376660"},{"timestamp":"1635668400.0","comment_id":"334650","upvote_count":"1","poster":"WhyIronMan","content":"I'll go with A,B"},{"upvote_count":"1","timestamp":"1635469860.0","comment_id":"290691","content":"go with AB.","poster":"wind"},{"comment_id":"289373","timestamp":"1635451500.0","upvote_count":"2","content":"Ans A,B","poster":"Kian1"},{"comment_id":"281196","timestamp":"1635451200.0","content":"my answer is AB","poster":"Ebi","upvote_count":"1"},{"comment_id":"269082","content":"A and B for sure","timestamp":"1635247260.0","upvote_count":"1","poster":"kopper2019"},{"upvote_count":"1","poster":"sanjaym","timestamp":"1635179340.0","comment_id":"262844","content":"AB for sure."},{"content":"I will go with AB","timestamp":"1635176640.0","upvote_count":"1","poster":"SachinJha","comment_id":"258167"},{"timestamp":"1634982480.0","comment_id":"252692","upvote_count":"3","poster":"sarofi","content":"predictable baseline -> reserved (cheaper than on-demand) -> A\nunpredictable for short periods -> on demand -> A\ninfrequent access after 20 days but needs immediately available -> S3 to S3 IA -> B"},{"comment_id":"242234","content":"AB for sure","timestamp":"1634871060.0","poster":"gookseang","upvote_count":"1"},{"poster":"newme","content":"Reserved and Spot instances are the best combination.\nIt's hard to say which is better, A or C.\nDepends on how often demand spikes happen and how many instances are needed at the time, and of course how long the company is going to run the website.","comment_id":"235529","timestamp":"1634865960.0","comments":[{"upvote_count":"1","poster":"sarofi","comment_id":"252690","timestamp":"1634920140.0","content":"Reserved is cheaper than on-demand.. predictable baseline -> reserved for baseline. unpredictable spikes -> on-demand or spot both works. Considering the \"traffic unpredictably for short periods of time\" overall cost should be A cheaper than C and more durable (plus)"}],"upvote_count":"1"},{"poster":"lydia_young","content":"I'll go with AB","timestamp":"1634862540.0","upvote_count":"1","comment_id":"231971"},{"poster":"jackdryan","timestamp":"1634851500.0","comment_id":"228028","upvote_count":"1","content":"I'll go with A,B"},{"poster":"petebear55","comment_id":"220424","content":"a because these reserved are 75 percent cheaper than on demand instances","timestamp":"1634565840.0","upvote_count":"1"},{"poster":"Bulti","upvote_count":"2","comment_id":"218236","timestamp":"1634423820.0","content":"A and B"},{"comment_id":"210300","upvote_count":"1","timestamp":"1634346660.0","comments":[{"poster":"DashL","upvote_count":"2","comment_id":"391542","content":"BC\nI fully agree with using spot instances. Since there is no guarantee that the app will be running for 1 year or 3 years on EC2 instances, creating a solution with reserved instance will be bad architecture.","timestamp":"1636090920.0"}],"poster":"Anila_Dhharisi","content":"As the application is stateless, loosely coupled and rely on persistent storage, its a natural fit for Spot instances.\nhttps://aws.amazon.com/blogs/compute/running-web-applications-on-amazon-ec2-spot-instances/\nStateless web applications are a natural fit for Spot Instances as they are fault tolerant, used to handle interruptions through scale-in events in an Auto Scaling group, and commonly run across multiple Availability Zones"},{"upvote_count":"1","comment_id":"202497","timestamp":"1634317680.0","content":"I will prefer C(i.e. spot instances) over A because the application is loosely coupled and stateless.","poster":"Amitv2706"},{"comment_id":"177131","content":"A company has an application that runs a web service on Amazon EC2 instances and stores .jpg images in Amazon S3. The web traffic has a predictable baseline, but often demand spikes unpredictably for short periods of time. The application is loosely coupled and stateless.\nThe .jpg images stored in Amazon S3 are accessed frequently for the first 15 to 20 days, they are seldom accessed thereafter but always need to be immediately available. The CIO has asked to find ways to reduce costs.\nWhich of the following options will reduce costs? (Choose two.)\n\nCorrect Answer: BC \n\nA. Purchase Reserved instances for baseline capacity requirements and use On-Demand instances for the demand spikes.\nB. Configure a lifecycle policy to move the .jpg images on Amazon S3 to S3 IA after 30 days.\nC. Use On-Demand instances for baseline capacity requirements and use Spot Fleet instances for the demand spikes.\nD. Configure a lifecycle policy to move the .jpg images on Amazon S3 to Amazon Glacier after 30 days.\nE. Create a script that checks the load on all web servers and terminates unnecessary On-Demand instances.","poster":"samsun","timestamp":"1634173200.0","upvote_count":"3"},{"content":"A and B is correct","poster":"fullaws","upvote_count":"1","comment_id":"148404","timestamp":"1634107140.0"},{"poster":"learner4ever","timestamp":"1634072400.0","content":"I don't see full question and answers. only A, C, E are visible.","comment_id":"143386","upvote_count":"1"},{"poster":"NikkyDicky","upvote_count":"1","timestamp":"1633986540.0","content":"AB for sure","comment_id":"134082"},{"comment_id":"133523","upvote_count":"1","timestamp":"1633866180.0","content":"go with A,B","poster":"noisonnoiton"},{"content":"A, B for me.","timestamp":"1633773240.0","comment_id":"119934","poster":"easytoo","upvote_count":"3"},{"timestamp":"1633501500.0","poster":"kallori","comment_id":"102539","content":"Sorry should B and D S3 IA and reserved instances","upvote_count":"1"},{"upvote_count":"1","comment_id":"102536","timestamp":"1633422660.0","content":"You have to pay for S3 IA each time you retrieve the data, so its not sot effective","poster":"kallori"},{"poster":"arunkumar","content":"We don't the baseline EC2 instance count here. It can be 10 or 100. Using on-demand instances for baseline is not cost-effective. We need to use RI. \nMy Choice is AB","timestamp":"1633206240.0","upvote_count":"1","comment_id":"95009"},{"content":"I'd go with AB for this question since no further information is provided. In real life situation you can consider spot instances if responding to spikes are not profitable or don't change customer experience significantly.","timestamp":"1633121760.0","poster":"[Removed]","upvote_count":"1","comment_id":"85494"},{"upvote_count":"4","content":"I go with A B. Spot instances need to be bid and may not available if above your bidder price so C is incorrect","poster":"Joeylee","comment_id":"75472","timestamp":"1633053540.0","comments":[{"content":"https://aws.amazon.com/blogs/compute/new-amazon-ec2-spot-pricing/\nNew Amazon EC2 Spot pricing model: Simplified purchasing without bidding and fewer interruptions.","upvote_count":"1","comment_id":"86751","timestamp":"1633142820.0","poster":"easytoo"}]},{"poster":"Smartphone","upvote_count":"3","comment_id":"73608","content":"Answer BC is correct","timestamp":"1632957660.0","comments":[{"upvote_count":"2","poster":"Stec1980","comment_id":"154451","content":"Definitely A over C as it's more cost effective to use RI's for your baseline and On-Demand for spikes than it is to use a combination of On Demand and Spot. B is correct for the storage requirement however so A & B are correct.","timestamp":"1634127900.0"}]},{"timestamp":"1632815400.0","comment_id":"54535","upvote_count":"2","content":"I disagree, I'd go for BC (Reduce cost by moving to S3 IA, and as appli is loosely coupled and stateless, we can use spot).","poster":"virtual"},{"poster":"amog","timestamp":"1632655920.0","comment_id":"44756","upvote_count":"2","content":"Answer is A,B"},{"poster":"markpark","comment_id":"41159","upvote_count":"1","timestamp":"1632379980.0","content":"my choice is A,B"},{"content":"in the storage options if you see S3 intelligent tier , may be that makes more sense than S3-IA","poster":"JayK","upvote_count":"1","timestamp":"1632311940.0","comment_id":"29865"},{"poster":"Vin","comment_id":"12939","content":"Is there any part missing in the questions?","upvote_count":"3","timestamp":"1632076680.0"}],"topic":"1","question_text":"[1]\n[1]\nare accessed frequently for the first 15 to 20 days, they are seldom accessed thereafter but always need to be immediately available. The CIO has asked to find ways to reduce costs.\nWhich of the following options will reduce costs? (Choose two.)","question_id":359,"answer_ET":"AB","answer_images":[]},{"id":"mGnBL4TNWt01QiCUOnSs","timestamp":"2019-08-26 15:47:00","question_id":360,"answer_description":"","answer_images":[],"question_images":[],"choices":{"A":"Use AWS Direct Connect to each data center from different ISPs, and configure routing to failover to the other data center's Direct Connect if one fails. Ensure that no VPC CIDR blocks overlap one another or the on-premises network.","D":"Use AWS Direct Connect and a VPN as backup, and configure both to use the same virtual private gateway and BGP. Ensure that no VPC CIDR blocks overlap one another or the on-premises network.","B":"Use multiple hardware VPN connections to AWS from the on-premises data center. Route different subnet traffic through different VPN connections. Ensure that no VPC CIDR blocks overlap one another or the on-premises network.","C":"Use a software VPN with clustering both in AWS and the on-premises data center, and route traffic through the cluster. Ensure that no VPC CIDR blocks overlap one another or the on-premises network."},"unix_timestamp":1566827220,"topic":"1","discussion":[{"content":"Due to unique legacy applications, NAT cannot be used\nMeans outbound connection to internet is not possible, so VPN is not possible.\n\nCorrect answer has to be A","comments":[{"timestamp":"1633475640.0","upvote_count":"1","poster":"LunchTime","content":"Great point.","comment_id":"116701"},{"upvote_count":"1","content":"A is correct - reliable with high bandwith means failover to another DX, VPN as secondary would reduce it","poster":"rb39","timestamp":"1639325520.0","comment_id":"500110"},{"comment_id":"238069","content":"This have to be upvoted more. D will not be possible with VPN as a backup that required an internet interface (IPSec)","upvote_count":"1","timestamp":"1634466000.0","poster":"rcher"},{"timestamp":"1635444720.0","poster":"macshild","upvote_count":"3","comment_id":"347277","content":"A VPN connection between AWS and on prem networks doesn't utiize the NAT gate it done through Transit Gateway with VPN extentions or Virtual Private Gateway, but then again your answer is correct just letting the masses no NAT gateway is not involved in VPN on the AWS side"},{"timestamp":"1634877600.0","content":"Moreover, using VPN over with a Public VIF(using same DX connection) still give you a single point of failure, if the DX ever goes down.","poster":"rcher","upvote_count":"4","comment_id":"276021"}],"upvote_count":"67","timestamp":"1633138560.0","poster":"Joeylee","comment_id":"75479"},{"upvote_count":"13","timestamp":"1632226620.0","comment_id":"13517","poster":"donathon","content":"A\nhttps://aws.amazon.com/answers/networking/aws-multiple-data-center-ha-network-connectivity/\nA: This is the best way for HA and high bandwidth.\nB\\C: VPN even if it is redundant does not allow high bandwidth where it has a limit of 1.25Gbps. https://aws.amazon.com/vpn/faqs/\nD: This is not multi-region and not as highly available. Remember VPN has only 1.25Gbps."},{"timestamp":"1668062940.0","content":"Selected Answer: A\nA - seems to be the \"best\" option.\nUnable to use NAT i.e VPN- So that rules out B, C, D","upvote_count":"1","poster":"janvandermerwer","comment_id":"714982"},{"timestamp":"1667726160.0","comment_id":"712220","upvote_count":"1","poster":"Ni_yot","content":"Selected Answer: A\nA good choice here. if you cant use NAT then Direct connect is the best solution."},{"upvote_count":"1","comment_id":"686238","poster":"JayF88","timestamp":"1664892540.0","content":"Selected Answer: A\nA makes more sense, VPN solution on D not possible"},{"timestamp":"1663328760.0","upvote_count":"1","comment_id":"670766","poster":"jujumomma","content":"Ans: A\nD is wrong. \nhttps://aws.amazon.com/directconnect/faqs/?nc1=h_ls\nQ: Can I use AWS Site-to-Site VPN as a backup for my AWS Direct Connect link to an AWS Local Zone?\n\nNo. Unlike connectivity to a Region, you cannot use an AWS Site-to-Site VPN as a backup to your AWS Direct Connect connection to an AWS Local Zone. For redundancy, you must use two or more AWS Direct Connect connections.","comments":[{"content":"This answer is to AWS Local Zone. But this question does not mention AWS local zone at all.","comment_id":"767448","timestamp":"1672996200.0","upvote_count":"2","poster":"hollie"}]},{"content":"Selected Answer: A\nI agree on option A. There is no mention of cost reduction in the question so using a secondary connect direct connection will be better","upvote_count":"1","comment_id":"668219","timestamp":"1663084320.0","poster":"bihani"},{"upvote_count":"1","timestamp":"1656488760.0","content":"Selected Answer: A\nA is correct - reliable with high bandwidth means failover to another DX, VPN as secondary would reduce it.","comment_id":"624492","poster":"Serial_X25"},{"poster":"[Removed]","timestamp":"1642111020.0","comment_id":"523153","content":"D is incorrect, you cannot attach a direct connect to a Virtual Private Gateway, you need a Direct Connect Gateway.\nA is the only viable option","upvote_count":"1"},{"timestamp":"1640850660.0","comment_id":"513122","poster":"cldy","upvote_count":"1","content":"A: CORRECT"},{"timestamp":"1638333960.0","content":"I'd with A cause the question says multi region","poster":"backfringe","comment_id":"491268","upvote_count":"1"},{"comment_id":"482994","upvote_count":"1","poster":"acloudguru","content":"Selected Answer: A\nDue to unique legacy applications, NAT cannot be used\nMeans outbound connection to internet is not possible, so VPN is not possible.\n\nCorrect answer has to be A","timestamp":"1637465100.0"},{"poster":"andylogan","content":"It's A","upvote_count":"1","timestamp":"1636143000.0","comment_id":"449901"},{"poster":"StelSen","upvote_count":"2","content":"Requirement is: Secure, Highly available, High bandwidth and a multi-region deployment post-migration\nOption-A: Fulfils last 3 req\nOption-B: Partial security, Less bandwidth, Not HA, Can meet Multi-Region.\n\nSo, I will go with A","timestamp":"1636013880.0","comment_id":"440623"},{"content":"It's A, are linked together with private fiber points to DX","comment_id":"436573","poster":"denccc","upvote_count":"2","timestamp":"1635913440.0"},{"comment_id":"426578","upvote_count":"1","timestamp":"1635783360.0","content":"D. Make more sense as it is multi region deployment you need Virtual private Gateway to connect with multiple VPC of different region at AWS side","poster":"FERIN_01"},{"upvote_count":"1","timestamp":"1635715140.0","poster":"student2020","comment_id":"402891","content":"A and D mention using DX which is not secure, traffic in DX is not encrypted. Option C is better as it ticks all the requirements. VPN is secure, it uses instances so the throughput is limited by the instance type (not 1.25mbps for AWS VPN). It can also scale to different regions by just creating a new EC2 VPN cluster in the new region"},{"poster":"01037","content":"A.\n\nWithout consideration of cost, multiple Direct Connect to multiple DCs, is a better solution than D.","comment_id":"386177","timestamp":"1635624060.0","upvote_count":"1"},{"poster":"blackgamer","timestamp":"1635355380.0","upvote_count":"1","content":"I will go with A.","comment_id":"343443"},{"content":"I'll go with A","timestamp":"1635305580.0","comment_id":"334652","upvote_count":"1","poster":"WhyIronMan"},{"poster":"Amitv2706","upvote_count":"2","content":"Answer should be A \n\nVPNs do not support high bandwidth data transfer as these operate over the public internet infrastructure. But the question mentions it needs high bandwidth solution","comment_id":"329324","timestamp":"1635273120.0"},{"upvote_count":"1","comment_id":"307558","timestamp":"1635172920.0","comments":[{"upvote_count":"2","poster":"nitinz","comment_id":"315241","content":"Read the AWS whitepaper, AWS like option A. They have a product called AWS VPN Cloud Hub. Hub - Spoke design.","timestamp":"1635220080.0"}],"poster":"RomanTsai","content":"Based my past experience, it should be D due to if one of multiple private data centers without any DX location or partners support, VPN connection is only a solution as a backup plan."},{"upvote_count":"2","poster":"Pupu86","content":"It fulfils high availability by failing over to a different ISP. By indicating that they are using different ISPs for different DX shows that if one ISP service goes down, the other DX will not be affected. If you really want secure \"secure\" - add 3PP vendor solutions to fulfil what's lacking in C.I.A but that would once again require NAT to be used. So answer is A","comment_id":"306715","timestamp":"1635118560.0"},{"timestamp":"1635079800.0","poster":"wind","content":"A is correct.","upvote_count":"1","comment_id":"290697"},{"upvote_count":"2","poster":"Kian1","comment_id":"289378","content":"Ans A for me","timestamp":"1635020640.0"},{"upvote_count":"3","poster":"Ebi","content":"I go with A","comment_id":"281810","timestamp":"1634947140.0"},{"comment_id":"242237","poster":"gookseang","timestamp":"1634870040.0","content":"seems A","upvote_count":"1"},{"timestamp":"1634706840.0","content":"The question does not mention cost. Correct answer is A.","poster":"T14102020","comment_id":"241902","upvote_count":"1"},{"upvote_count":"2","comments":[{"timestamp":"1634509860.0","poster":"yyy","comments":[{"timestamp":"1635629580.0","content":"Direct Connect does not provide an encrypted tunnel. so the answer is D.","comment_id":"390799","upvote_count":"1","poster":"Training"}],"content":"D: is not secure because VPN as backup","comment_id":"238596","upvote_count":"1"}],"content":"D .. a is tempting but it mentions secure in the requirement so having read this i think D and NOT A https://aws.amazon.com/vpn/faqs/","poster":"petebear55","comment_id":"231314","timestamp":"1634395620.0"},{"comment_id":"228244","content":"Answer is D. Please note \"hybrid network architecture that is secure and highly available\"","upvote_count":"3","timestamp":"1634279460.0","poster":"Shabari","comments":[{"timestamp":"1634460840.0","content":"I think \"hybrid\" just means on-premises + cloud, not VPN+direct connect if I am not wrong.\nAlso, question called for high bandwidth. So I choose A instead of D\n\n\" Coexistence of on-premises and cloud resources is called hybrid cloud and the common network connecting them is referred to as a hybrid network.\"\n\nhttps://docs.aws.amazon.com/whitepapers/latest/hybrid-connectivity/introduction.html","comment_id":"237005","poster":"George88","upvote_count":"1"}]},{"comment_id":"228039","content":"I'll go with A","poster":"jackdryan","upvote_count":"1","timestamp":"1634215080.0"},{"comment_id":"220440","content":"D .. this question is very similar to one which provides the correct answer in wizzlabs tests","timestamp":"1634180460.0","poster":"petebear55","upvote_count":"1"},{"timestamp":"1634112420.0","comment_id":"219310","content":"Answer is A","upvote_count":"1","poster":"Bulti"},{"upvote_count":"1","poster":"fullaws","comment_id":"148410","timestamp":"1634053860.0","content":"A is correct, multi-region deployment, high reliable"},{"content":"I prefer A - as D cant satisfy multi region connections.","upvote_count":"1","comment_id":"136307","timestamp":"1633959360.0","poster":"sweand","comments":[{"timestamp":"1634007540.0","poster":"IAmNotLambda","comment_id":"138347","upvote_count":"1","content":"One can have DX connected to multi-region. Public VIF can also be used to create VPN with other regions.\n\nhttps://www.edge-cloud.net/2019/09/06/dx-gateway-deep-dive/#:~:text=AWS%20Direct%20Connect%20Gateway%20allows,Connect%20Gateway%20per%20DX%20location."}]},{"poster":"NikkyDicky","timestamp":"1633802940.0","comment_id":"134084","content":"A more likely","upvote_count":"1"},{"timestamp":"1633795680.0","poster":"noisonnoiton","content":"go with A\nVPN is not possible.","upvote_count":"1","comment_id":"133531"},{"content":"answer A","upvote_count":"1","timestamp":"1633675020.0","poster":"mat2020","comment_id":"133262"},{"upvote_count":"1","comment_id":"133261","content":"Correct Answer: A","timestamp":"1633633140.0","poster":"mat2020"},{"upvote_count":"1","comment_id":"123074","poster":"oatif","timestamp":"1633494180.0","content":"virtual private gateway does not do multi-region deployment so A is the correct answer."},{"poster":"cloudlabadm","content":"First I chose A, but the question asks for hybrid network architecture, so I changed it to D.","comment_id":"87508","upvote_count":"1","timestamp":"1633358340.0"},{"upvote_count":"3","poster":"jgtran","content":"A is the correct answer. We're currently using multiple Direct Connect to our data centers right now. We added VPN as backup connection for each of the Direct Connect to our data centers.","comment_id":"80532","timestamp":"1633256160.0"},{"upvote_count":"3","poster":"samcs","timestamp":"1632964800.0","comment_id":"57365","content":"Option A - We are leveraging similar set up today with two redundant Direct Connect connections and believe me, it isn't expensive."},{"comment_id":"54539","content":"\"many applications will need access to other applications in both the data centers and AWS\". I go for D because of the VPN backup.","poster":"virtual","upvote_count":"1","timestamp":"1632905460.0"},{"comment_id":"44759","upvote_count":"1","timestamp":"1632802980.0","poster":"amog","content":"Should be A"},{"poster":"markpark","content":"my choice is A","upvote_count":"1","comment_id":"41160","timestamp":"1632564600.0"},{"content":"I think it should be D\nI think it cannot be A because it says \"Use AWS Direct Connect to each data center from different ISPs\" => my understanding is AWS Direct Connect is an option to prevent 'reliance' on any ISP.\n\nhttps://aws.amazon.com/answers/networking/aws-multiple-data-center-ha-network-connectivity/\n\n\"Considerations\nThis configuration relies on the Internet to carry traffic between on-premises networks and VPC. Although AWS leverages multiple Internet Service Providers (ISPs), and even if the customer leverages multiple ISPs, an Internet service disruption can still affect the availability of VPN network connectivity due to the interdependence of ISPs and Internet routing. The only way to control the exact network path of your traffic is to provision private network connectivity with AWS Direct Connect (see the next option).\"\n\n\"AWS Direct Connect with Backup VPN Connection\nSome AWS customers would like the benefits of one or more AWS Direct Connect connections for their primary connectivity to AWS, coupled with a lower-cost backup connection.\"","poster":"CloudFloater","upvote_count":"3","timestamp":"1632560820.0","comment_id":"38053","comments":[{"poster":"CloudFloater","timestamp":"1632733560.0","comment_id":"41574","content":"choosing A - on further consideration\n- ISP's provide the Direct Connect connection service - so does not mean internet connectivity. \n- also, multiple ISPs would mean backup Direct Connect Connections => High Availability and Security and Bandwidth over VPN","upvote_count":"5"}]},{"poster":"LunchTime","content":"D is correct.\nThe key to the question, I believe, is the use of the words “post-migration” in “…that allows for high bandwidth and a multi-region deployment post-migration”. Post-migration would, I’m assuming, mean that there would be just one on-premise data center. If there was just one data center there would not be the “private fiber” linkages between data centers since there would be just data center remaining. In order to have a backup connection you would need to implement a VPN (or order a second Direct Connect connection), which is why D is correct.\nI believe B would be correct if “post-migration” was removed from the questions wording.","comment_id":"31373","upvote_count":"5","timestamp":"1632540060.0","comments":[{"poster":"LunchTime","content":"A is correct.\nI did not appreciate the fact that A says \"...different ISPs\" meaning that there would be 2 direct connect connections to each data centre. As such, I concur with others that A is correct.","comment_id":"71513","upvote_count":"1","timestamp":"1633056480.0"},{"content":"D doesn't offer HA and high bandwidth, which is a requirement from Question","timestamp":"1634067300.0","comment_id":"181977","upvote_count":"1","poster":"sam422"}]},{"comment_id":"28193","content":"agree with a on this one","upvote_count":"1","timestamp":"1632468180.0","poster":"Scunningham99"},{"poster":"Warrenn","upvote_count":"4","comment_id":"18859","timestamp":"1632350820.0","comments":[{"timestamp":"1632366840.0","poster":"examacc","comment_id":"24027","content":"It is not only about security. we need high bandwidth and relaibility. which internet does not provide. so A will make sense here.","upvote_count":"1"},{"comment_id":"29485","upvote_count":"4","poster":"tan9","content":"Option A involves only Direct Connects, and Option D uses Direct Connect primarily and uses VPN as backup. If Direct Connection in option A has security concerns, how do you ensure the Direct Connect with VPN in option D is safer than option A?","timestamp":"1632479220.0","comments":[{"timestamp":"1634184540.0","content":"keep in mind something everyone overlook Direct connect is not secure by design it still needs a vpn tunnel on top of it to allow end to end encryption.","comment_id":"220442","poster":"YouYouYou","upvote_count":"1"}]}],"content":"The problem with A is the that it only deals with High availability not security the question asks for both high availability as well as security so I think D is still a good answer"},{"content":"I prefer A.\n\nVPN doesn' have high bandwidth","comment_id":"13936","timestamp":"1632309180.0","poster":"manhmaluc","upvote_count":"2"},{"comment_id":"8366","comments":[{"comment_id":"11224","comments":[{"upvote_count":"7","comments":[{"comment_id":"101898","timestamp":"1633417620.0","poster":"meenu2225","content":"I agree it should be A","upvote_count":"2"}],"poster":"sb333","content":"The question does not mention cost. The business could very well justify the cost. They already can afford private fiber linking their current data centers. If reducing costs were part of the question, I would agree. But without that requirement, I would go with \"A\" based on the requirements listed in the question.","timestamp":"1632149640.0","comment_id":"11451"}],"poster":"dpvnme","upvote_count":"2","timestamp":"1632139800.0","content":"at the bottom of this document, it mentions direct connect with vpn, which is answer D. also, the question mentions multiple datacenters, with option A, there will be multiple direct connections, which will not be cost effective and not recommended."},{"content":"I mean VPN on top of internet is not possible, which is the context of VPN here","poster":"Joeylee","timestamp":"1633230180.0","upvote_count":"1","comment_id":"75480"}],"content":"I think it should be A with https://aws.amazon.com/answers/networking/aws-multiple-data-center-ha-network-connectivity/","timestamp":"1632128160.0","poster":"Huy","upvote_count":"2"}],"exam_id":32,"url":"https://www.examtopics.com/discussions/amazon/view/4106-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"question_text":"A hybrid network architecture must be used during a company's multi-year data center migration from multiple private data centers to AWS. The current data centers are linked together with private fiber. Due to unique legacy applications, NAT cannot be used. During the migration period, many applications will need access to other applications in both the data centers and AWS.\nWhich option offers a hybrid network architecture that is secure and highly available, that allows for high bandwidth and a multi-region deployment post-migration?","answers_community":["A (100%)"],"answer_ET":"A","answer":"A"}],"exam":{"numberOfQuestions":1019,"lastUpdated":"11 Apr 2025","isBeta":false,"provider":"Amazon","name":"AWS Certified Solutions Architect - Professional","isImplemented":true,"isMCOnly":false,"id":32},"currentPage":72},"__N_SSP":true}