{"pageProps":{"questions":[{"id":"1e301wQyuJTQTicR2m5D","topic":"1","question_id":286,"answer_ET":"B","question_text":"A solutions architect must create a disaster recovery (DR) plan for a high-volume software as a service (SaaS) platform. All data for the platform is stored in an Amazon Aurora MySQL DB cluster.\n\nThe DR plan must replicate data to a secondary AWS Region.\n\nWhich solution will meet these requirements MOST cost-effectively?","isMC":true,"answer_images":[],"answer":"B","choices":{"B":"Set up an Aurora global database for the DB cluster. When setup is complete, remove the DB instance from the secondary Region.","C":"Use AWS Database Migration Service (AWS DMS) to continuously replicate data to an Aurora cluster in the secondary Region. Remove the DB instance from the secondary Region.","D":"Set up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region.","A":"Use MySQL binary log replication to an Aurora cluster in the secondary Region. Provision one DB instance for the Aurora cluster in the secondary Region."},"exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/99758-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"comment_id":"1113024","content":"Selected Answer: B\nI originally went for D but now I think B is correct. D is active-active cluster so whereas B is active-passive (headless cluster) so it is cheaper than D.\n\nhttps://aws.amazon.com/blogs/database/achieve-cost-effective-multi-region-resiliency-with-amazon-aurora-global-database-headless-clusters/","timestamp":"1704306600.0","poster":"awsgeek75","upvote_count":"19"},{"poster":"jennyka76","comments":[{"poster":"ChrisG1454","comment_id":"830690","upvote_count":"1","timestamp":"1678095120.0","comments":[{"upvote_count":"1","comment_id":"830691","timestamp":"1678095600.0","poster":"ChrisG1454","content":"The question is asking for the most cost-effective solution.\nAurora global databases are more expensive.\n\nhttps://aws.amazon.com/rds/aurora/pricing/"}],"content":"The question states \" The DR plan must replicate data to a \"secondary\" AWS Region.\"\n\nIn addition to Aurora Replicas, you have the following options for replication with Aurora MySQL:\n\nAurora MySQL DB clusters in different AWS Regions.\n\nYou can replicate data across multiple Regions by using an Aurora global database. For details, see High availability across AWS Regions with Aurora global databases\n\nYou can create an Aurora read replica of an Aurora MySQL DB cluster in a different AWS Region, by using MySQL binary log (binlog) replication. Each cluster can have up to five read replicas created this way, each in a different Region.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html"},{"content":"On this same URL you provided, there is a note highlighted, stating the following:\n\"Replication from the primary DB cluster to all secondaries is handled by the Aurora storage layer rather than by the database engine, so lag time for replicating changes is minimal—typically, less than 1 second. Keeping the database engine out of the replication process means that the database engine is dedicated to processing workloads. It also means that you don't need to configure or manage the Aurora MySQL binlog (binary logging) replication.\"\n\nSo, answer should be A","upvote_count":"2","comment_id":"820924","timestamp":"1677271200.0","comments":[{"content":"Correction: So, answer should be D","timestamp":"1677271260.0","poster":"leoattf","upvote_count":"3","comment_id":"820925"}],"poster":"leoattf"}],"upvote_count":"9","comment_id":"813367","content":"Answer - A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Replication.CrossRegion.html\n-----------------------------------------------------------------------------\nBefore you begin\nBefore you can create an Aurora MySQL DB cluster that is a cross-Region read replica, you must turn on binary logging on your source Aurora MySQL DB cluster. Cross-region replication for Aurora MySQL uses MySQL binary replication to replay changes on the cross-Region read replica DB cluster.","timestamp":"1676743920.0"},{"poster":"tch","content":"Selected Answer: D\nAnswer could be D, as this is DR plan, answer B is ask to remove the DB instance which might not suitable for DR plan….. if you remove it… how to replicate data again? you setup again for next replication ?","comment_id":"1388127","upvote_count":"1","timestamp":"1741827300.0"},{"comment_id":"1344469","poster":"FlyingHawk","upvote_count":"1","content":"Selected Answer: D\nGiving the requirement is the DR plan for a high-volume software as a service (SaaS) platform, the RTO and RPO should be small, needs a quick recovery, D(warm standby) is a better choice than A ( cold standby, pilot light)","timestamp":"1737502680.0"},{"poster":"LeonSauveterre","content":"Selected Answer: D\nA - No. Higher cost & higher latency.\nB - No. A DB instance is mandatory in each Region for the global database to function.\nC - Removing would make DR incomplete, because the secondary Region cannot process failovers or support read replicas.\nD - Cost slightly higher, yes, but feasible & cost less than A.\n\nOverall, I don't like this question ...","upvote_count":"1","timestamp":"1732871160.0","comment_id":"1319639"},{"content":"Selected Answer: B\nAurora Global Databases offer a cost-effective way to replicate data to a secondary region for disaster recovery. By removing the secondary DB instance after setup, you only pay for storage and minimal compute resources.","poster":"theamachine","comment_id":"1228536","upvote_count":"2","timestamp":"1718124540.0"},{"comments":[{"timestamp":"1705590900.0","comment_id":"1125997","poster":"awsgeek75","upvote_count":"2","content":"Wrong, while D will work, B is cheaper. This question is about DR, not cross region scaling"}],"poster":"thewalker","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html#aurora-global-database.advantages","upvote_count":"1","timestamp":"1705396620.0","comment_id":"1124044"},{"upvote_count":"3","content":"Selected Answer: D\nB is more cost-effective however because this is DR so when the region fails => still need a DB to fail over and if setting up a DB from snapshot at the time of failure will be risky => D is the answer","poster":"upliftinghut","timestamp":"1704737280.0","comment_id":"1116866"},{"content":"Selected Answer: B\n\"Achieve cost-effective multi-Region resiliency with Amazon Aurora Global Database headless clusters\" is exactly the topic here. \"A headless secondary Amazon Aurora database cluster is one without a database instance. This type of configuration can lower expenses for an Aurora global database.\"\n\nhttps://aws.amazon.com/blogs/database/achieve-cost-effective-multi-region-resiliency-with-amazon-aurora-global-database-headless-clusters/","poster":"pentium75","timestamp":"1703868360.0","comment_id":"1108915","upvote_count":"8"},{"content":"shd be D i guess .. . Migrating the database to Amazon Aurora MySQL allows for improved replication performance and higher scalability compared to Amazon RDS for MySQL. Aurora Replicas provide faster replication, reducing the replication lag, and Aurora Auto Scaling ensures that there are enough Aurora Replicas to handle the incoming traffic. Additionally, Aurora MySQL native functions can replace the stored procedures, reducing the load on the database and improving performance.\n\nOption B is not the best solution since adding an ElastiCache for Redis cluster does not address the replication lag issue, and the cache may not have the most up-to-date information. Additionally, replacing the stored procedures with AWS Lambda functions adds additional complexity and may not improve performance.","comment_id":"1069336","upvote_count":"2","poster":"minagaboya","timestamp":"1699882440.0","comments":[{"poster":"pentium75","upvote_count":"4","content":"This is about a different question","timestamp":"1703863980.0","comment_id":"1108851"}]},{"timestamp":"1697082960.0","content":"Selected Answer: D\nSet up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region","comment_id":"1041339","upvote_count":"1","poster":"TariqKipkemei"},{"upvote_count":"2","poster":"vini15","timestamp":"1690300380.0","comment_id":"962859","content":"should be B for most cost effective solution.\nsee the link - Achieve cost-effective multi-Region resiliency with Amazon Aurora Global Database headless clusters\nhttps://aws.amazon.com/blogs/database/achieve-cost-effective-multi-region-resiliency-with-amazon-aurora-global-database-headless-clusters/"},{"timestamp":"1684679220.0","comments":[{"timestamp":"1695581880.0","upvote_count":"2","comment_id":"1016111","poster":"bsbs1234","content":"upvoted your message, but still think D is correct. Because the question is to design a DR plan.In case of DR, B need to create an instance in DR region manually."}],"content":"Selected Answer: B\nMOST cost-effective --> B\nSee section \"Creating a headless Aurora DB cluster in a secondary Region\" on the link https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html\n\"Although an Aurora global database requires at least one secondary Aurora DB cluster in a different AWS Region than the primary, you can use a headless configuration for the secondary cluster. A headless secondary Aurora DB cluster is one without a DB instance. This type of configuration can lower expenses for an Aurora global database. In an Aurora DB cluster, compute and storage are decoupled. Without the DB instance, you're not charged for compute, only for storage. If it's set up correctly, a headless secondary's storage volume is kept in-sync with the primary Aurora DB cluster.\"","comment_id":"903326","poster":"luisgu","upvote_count":"7"},{"timestamp":"1678360920.0","content":"Selected Answer: D\nD: With Amazon Aurora Global Database, you pay for replicated write I/Os between the primary Region and each secondary Region (in this case 1). \n\nNot A because it achieves the same, would be equally costly and adds overhead.","comment_id":"833897","upvote_count":"3","poster":"Abhineet9148232"},{"timestamp":"1678032060.0","upvote_count":"3","comment_id":"830058","content":"Selected Answer: C\nCCCCCC","poster":"[Removed]"},{"poster":"Steve_4542636","comments":[{"upvote_count":"1","poster":"fkie4","content":"very true. Amazon wanna everyone to use AWS, why do they sell for MySQL?","timestamp":"1678347420.0","comment_id":"833681"}],"upvote_count":"3","comment_id":"828435","timestamp":"1677879240.0","content":"Selected Answer: D\nI think Amazon is looking for D here. I don' think A is intended because that would require knowledge of MySQL, which isn't what they are testing us on. Not option C because the question states large volume. If the volume were low, then DMS would be better. This question is not a good question."},{"comment_id":"818876","timestamp":"1677134460.0","poster":"LuckyAro","content":"Selected Answer: D\nD provides automatic replication","upvote_count":"3"},{"upvote_count":"1","content":"Selected Answer: D\nActually I change my answer to 'D' because of following:\nAn Aurora DB cluster can contain up to 15 Aurora Replicas. The Aurora Replicas can be distributed across the Availability Zones that a DB cluster spans WITHIN an AWS Region.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.htmhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html\nYou can replicate data across multiple Regions by using an Aurora global database","comment_id":"818270","timestamp":"1677092820.0","poster":"bdp123"},{"comment_id":"818253","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Replication.MySQL.html Global database is for specific versions - they did not tell us the version\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html","upvote_count":"2","timestamp":"1677092040.0","poster":"bdp123"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html\n\nCheckout the part Recovery from Region-wide outages","upvote_count":"1","poster":"doodledreads","timestamp":"1677009180.0","comment_id":"817092"},{"comments":[{"timestamp":"1703864100.0","upvote_count":"2","content":"A native function of a 3rd party software is NEVER a correct answer ;)","poster":"pentium75","comment_id":"1108853"}],"poster":"zTopic","content":"Selected Answer: A\nAnswer is A","timestamp":"1676706840.0","upvote_count":"2","comment_id":"812769"}],"timestamp":"2023-02-18 08:54:00","answers_community":["B (58%)","D (31%)","6%"],"question_images":[],"answer_description":"","unix_timestamp":1676706840},{"id":"udYXdlS2zOQeVa7vQVyJ","answers_community":["C (100%)"],"question_id":287,"question_text":"A company has a custom application with embedded credentials that retrieves information from an Amazon RDS MySQL DB instance. Management says the application must be made more secure with the least amount of programming effort.\n\nWhat should a solutions architect do to meet these requirements?","isMC":true,"question_images":[],"topic":"1","discussion":[{"poster":"cloudbusting","comment_id":"812959","content":"Parameter Store does not provide automatic credential rotation.","upvote_count":"16","timestamp":"1676724840.0"},{"content":"Selected Answer: C\nC. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.\n\nhttps://www.examtopics.com/discussions/amazon/view/46483-exam-aws-certified-solutions-architect-associate-saa-c02/","upvote_count":"11","comment_id":"812302","timestamp":"1676663580.0","poster":"Bhawesh"},{"comment_id":"1315335","poster":"JA2018","upvote_count":"1","content":"Selected Answer: C\nManagement says the application must be made more secure with the least amount of programming effort.\n\nIMHO, this will rule out Lambda for this STEM.","timestamp":"1732115520.0"},{"upvote_count":"2","timestamp":"1719251040.0","comment_id":"1236525","content":"Selected Answer: C\ncredentials from Secrets Manager...","poster":"Gape4"},{"timestamp":"1711728180.0","poster":"d401c0d","content":"question is asking for \"more secure with the least amount of programming effort.\" = Secrets Manager + Secretes Manager's built in rotation schedule instead of Lambda.","upvote_count":"2","comment_id":"1185564"},{"upvote_count":"2","comment_id":"1113027","content":"Selected Answer: C\nA KMS is for encryption keys specifically so this is a long way of doing the credentials storage\nB is too much work for rotation\nC exactly what secrets manager is designed for\nD You can do that if C wasn't an option","timestamp":"1704307260.0","poster":"awsgeek75"},{"upvote_count":"2","timestamp":"1693914720.0","content":"Selected Answer: C\nStore the RDS credentials in Secrets Manager\nConfigure the application to retrieve the credentials from Secrets Manager\nUse Secrets Manager's built-in rotation to rotate the RDS credentials automatically","poster":"Guru4Cloud","comment_id":"999447"},{"content":"Selected Answer: C\nSecrets Manager can handle the rotation, so no need for Lambda to rotate the keys.","comment_id":"992294","timestamp":"1693233480.0","upvote_count":"2","poster":"Hades2231"},{"content":"WHY NOT B ?","timestamp":"1692686820.0","upvote_count":"1","poster":"chen0305_099","comment_id":"987155"},{"comment_id":"980390","poster":"StacyY","comments":[{"comment_id":"991685","content":"It is not needed for certain types RDS, including MySQL as Secrets Manager has built-in rotation capabilities for it: https://aws.amazon.com/blogs/security/rotate-amazon-rds-database-credentials-automatically-with-aws-secrets-manager/","timestamp":"1693178820.0","poster":"Nikki013","upvote_count":"3"}],"content":"B, we need lambda for password rotation, confirmed!","upvote_count":"2","timestamp":"1691978040.0"},{"poster":"Abrar2022","upvote_count":"2","timestamp":"1686463200.0","comment_id":"920450","content":"Selected Answer: C\nIf you need your DB to store credentials then use AWS Secret Manager. System Manager Paramater Store is for CloudFormation (no rotation)"},{"timestamp":"1678197780.0","comment_id":"831973","comments":[{"content":"It is asking for credentials, not for encryption keys.","upvote_count":"7","comment_id":"852387","poster":"MssP","comments":[{"poster":"PoisonBlack","timestamp":"1683247560.0","upvote_count":"3","comment_id":"889714","content":"So credentials rotation is secrets manager and key rotation is KMS?"}],"timestamp":"1679942040.0"}],"content":"why it's not A?","upvote_count":"4","poster":"AlessandraSAA"},{"poster":"bdp123","timestamp":"1677248700.0","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/security/rotate-amazon-rds-database-credentials-automatically-with-aws-secrets-manager/","comment_id":"820597","upvote_count":"2"},{"content":"Selected Answer: C\nC is a valid solution for securing the custom application with the least amount of programming effort. It involves creating credentials on the RDS for MySQL database for the application user and storing them in AWS Secrets Manager. The application can then be configured to load the database credentials from Secrets Manager. Additionally, the solution includes setting up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager, which will automatically rotate the credentials at a specified interval without requiring any programming effort.","comment_id":"818889","timestamp":"1677135480.0","upvote_count":"4","poster":"LuckyAro"},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/create_database_secret.html","poster":"bdp123","timestamp":"1677094680.0","upvote_count":"3","comment_id":"818305"},{"upvote_count":"4","poster":"jennyka76","content":"Answer - C\nhttps://ws.amazon.com/blogs/security/rotate-amazon-rds-database-credentials-automatically-with-aws-secrets-manager/","comment_id":"813343","timestamp":"1676741760.0"}],"exam_id":31,"timestamp":"2023-02-17 20:53:00","url":"https://www.examtopics.com/discussions/amazon/view/99705-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"B":"Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Create an AWS Lambda function that rotates the credentials in Secret Manager.","C":"Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.","A":"Use AWS Key Management Service (AWS KMS) to create keys. Configure the application to load the database credentials from AWS KMS. Enable automatic key rotation.","D":"Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store."},"answer_images":[],"unix_timestamp":1676663580,"answer_ET":"C","answer_description":"","answer":"C"},{"id":"6MZsKSE9XzASnC2y7R0M","question_id":288,"topic":"1","answer_images":[],"answer_ET":"B","discussion":[{"comment_id":"702901","timestamp":"1666605660.0","poster":"airraid2010","content":"Selected Answer: B\nCloudTrail - Track user activity and API call history.\nConfig - Assess, audits, and evaluates the configuration and relationships of tag resources.\n\nTherefore, the answer is B","upvote_count":"40"},{"comment_id":"1334721","timestamp":"1735638060.0","poster":"satyaammm","content":"Selected Answer: B\nAWS Config for configuration changes and AWS CloudTrail for API activities.","upvote_count":"2"},{"content":"Selected Answer: B","timestamp":"1732389660.0","upvote_count":"1","poster":"SBS2","comment_id":"1316783"},{"comment_id":"1122097","content":"Selected Answer: B\nConfig = Governance, auditing of AWS resource\nCloudTrail = API call tracking\nB is correct","timestamp":"1705185840.0","poster":"awsgeek75","upvote_count":"4"},{"timestamp":"1705149720.0","poster":"A_jaa","content":"Selected Answer: B\nAnswer-B","comment_id":"1121648","upvote_count":"1"},{"comment_id":"1054694","poster":"Ruffyit","content":"Correct Answer- Option B. Here's why\n\nAWS Config for Configuration Changes: AWS Config is a service that tracks changes to resource configurations over time. It provides a history of configuration changes to your AWS resources and helps with compliance and auditing by allowing you to assess how resource configurations have changed over time.\n\nAWS CloudTrail for API Calls: AWS CloudTrail is designed specifically for recording API calls made to AWS resources. It captures detailed information about who made each API call, the actions taken, and the resources affected. This is essential for auditing and security purposes.","upvote_count":"3","timestamp":"1698333240.0"},{"content":"Correct Answer- Option B. Here's why \n\nAWS Config for Configuration Changes: AWS Config is a service that tracks changes to resource configurations over time. It provides a history of configuration changes to your AWS resources and helps with compliance and auditing by allowing you to assess how resource configurations have changed over time.\n\nAWS CloudTrail for API Calls: AWS CloudTrail is designed specifically for recording API calls made to AWS resources. It captures detailed information about who made each API call, the actions taken, and the resources affected. This is essential for auditing and security purposes.\n\nWhile Amazon CloudWatch can be used to monitor and gather metrics, it is not designed for recording API calls or tracking configuration changes. AWS Config and AWS CloudTrail are purpose-built for these specific tasks and are the best services to use for the described requirements.","upvote_count":"4","comment_id":"1048077","timestamp":"1697730540.0","poster":"AWSStudyBuddy"},{"timestamp":"1697730480.0","poster":"AWSStudyBuddy","content":"Selected Answer: B\nAlthough tracking configuration changes and recording API calls are not intended uses for Amazon CloudWatch, it can be utilized for monitoring and collecting data. AWS CloudTrail and AWS Config are purpose-built for these specific tasks and are the best services to use for the described requirements.","comment_id":"1048074","upvote_count":"1"},{"poster":"TariqKipkemei","content":"Selected Answer: B\nCloudWatch is a monitoring service for AWS resources and applications. CloudTrail is a web service that records API activity in your AWS account.","timestamp":"1691036340.0","comment_id":"970729","upvote_count":"2"},{"content":"Selected Answer: B\nCONFIG - AWS CONFIG\nRECORD API CALLS - CLOUDTRAIL","poster":"Bogs123456711","comment_id":"967571","upvote_count":"3","timestamp":"1690757700.0"},{"timestamp":"1690514400.0","poster":"hsinchang","content":"Selected Answer: B\nCloudWatch is mainly uesd to monitor AWS services with metrics, not recoding actions inside the AWS environments. It can also monitor CloudTrail logged events.\nFor recording API calls it requires CloudTrail.","upvote_count":"2","comment_id":"965250"},{"comment_id":"956411","poster":"james2033","upvote_count":"3","content":"Selected Answer: B\nKeyword \"Amazon CloudWatch\" is not for this case, remove C and D.\n\nUse AWS Config first to track configuration changes, Second is AWS CloudTrai to record API calls. (Answer B, and correct answer). Answer A is reversed order of B, and not accepted.","timestamp":"1689754140.0"},{"upvote_count":"1","timestamp":"1689538920.0","poster":"miki111","content":"Option B is the right answer for this.","comment_id":"953615"},{"content":"Selected Answer: B\nB is the answer with no doubts","upvote_count":"1","poster":"karloscetina007","timestamp":"1688481600.0","comment_id":"942879"},{"comment_id":"930353","upvote_count":"1","timestamp":"1687427160.0","poster":"minhpn","content":"Selected Answer: B\nconfig => AWS config\nrecord API calls => AWS CloudTrail"},{"comment_id":"926642","upvote_count":"3","timestamp":"1687087440.0","poster":"cookieMr","content":"Selected Answer: B\nTo meet the requirement of tracking configuration changes on AWS resources and recording a history of API calls, a solutions architect should recommend option B: Use AWS Config to track configuration changes and AWS CloudTrail to record API calls.\n\nOption A (using CloudTrail to track configuration changes and Config to record API calls) is incorrect because CloudTrail is specifically designed to capture API call history, while Config is designed for tracking configuration changes.\n\nOption C (using Config to track configuration changes and CloudWatch to record API calls) is not the recommended approach. While CloudWatch can be used for monitoring and logging, it does not provide the same level of detail and compliance tracking as CloudTrail for recording API calls.\n\nOption D (using CloudTrail to track configuration changes and CloudWatch to record API calls) is not the optimal choice because CloudTrail is the appropriate service for tracking configuration changes, while CloudWatch is not specifically designed for recording API call history."},{"upvote_count":"1","comment_id":"912793","content":"Selected Answer: B\nOption B meets ruirements.","timestamp":"1685707140.0","poster":"Bmarodi"},{"upvote_count":"4","timestamp":"1680267180.0","comment_id":"857084","content":"Selected Answer: B\nAWS Config is a fully managed service that allows the company to assess, audit, and evaluate the configurations of its AWS resources. It provides a detailed inventory of the resources in use and tracks changes to resource configurations. AWS Config can detect configuration changes and alert the company when changes occur. It also provides a historical view of changes, which is essential for compliance and governance purposes.\n\nAWS CloudTrail is a fully managed service that provides a detailed history of API calls made to the company's AWS resources. It records all API activity in the AWS account, including who made the API call, when the call was made, and what resources were affected by the call. This information is critical for security and auditing purposes, as it allows the company to investigate any suspicious activity that might occur on its AWS resources.","poster":"linux_admin"},{"timestamp":"1678120620.0","comment_id":"831008","upvote_count":"2","poster":"bilel500","content":"Selected Answer: B\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. It provides a history of configuration changes made to your resources and can be used to track changes made to your resources over time.\n\nAWS CloudTrail is a service that enables you to record API calls made to your AWS resources. It provides a history of API calls made to your resources, including the identity of the caller, the time of the call, the source of the call, and the response element returned by the service."},{"comment_id":"831007","upvote_count":"1","poster":"bilel500","content":"Selected Answer: B\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. It provides a history of configuration changes made to your resources and can be used to track changes made to your resources over time.\n\nAWS CloudTrail is a service that enables you to record API calls made to your AWS resources. It provides a history of API calls made to your resources, including the identity of the caller, the time of the call, the source of the call, and the response element returned by the service.","timestamp":"1678120500.0"},{"poster":"Mcmono","comment_id":"814277","content":"Selected Answer: B\nAWS Config is basically used to track config changes, while cloudtrail is to monitor API calls","timestamp":"1676825160.0","upvote_count":"1"},{"timestamp":"1674401940.0","poster":"bullrem","comment_id":"784448","content":"Selected Answer: A\nA. Use AWS CloudTrail to track configuration changes and AWS Config to record API calls. This option is the best because it utilizes both AWS CloudTrail and AWS Config, which are both designed for tracking and recording different types of information related to AWS resources and API calls. AWS CloudTrail is used to track user activity and API call history, and AWS Config is used to assess, audit, and evaluate the configuration and relationships of tag resources. Together, they provide a comprehensive and robust solution for compliance, governance, auditing, and security.","upvote_count":"1","comments":[{"content":"why not the B?. \nAWS Config is primarily used to assess, audit, and evaluate the configuration and relationships of resources in your AWS environment. It does not record the history of API calls made to these resources. On the other hand, AWS CloudTrail is used to track user activity and API call history. Together, AWS Config and CloudTrail provide a complete picture of the configuration and activity on your AWS resources, which is necessary for compliance, governance, auditing, and security. Therefore, option A is the best choice.","comment_id":"784451","timestamp":"1674402000.0","poster":"bullrem","upvote_count":"1"}]},{"content":"Selected Answer: B\nCloudTrail tracks user activity as well as any API calls (think of bread crumbs leading to an culprit). Config is exactly what it sounds like; configuration. So think audits, config changes ect.","poster":"BakedBacon","comment_id":"777178","timestamp":"1673826060.0","upvote_count":"1"},{"poster":"pazabal","upvote_count":"1","comment_id":"751213","content":"Selected Answer: B\nauditing = cloudtrail","timestamp":"1671554340.0"},{"comments":[{"content":"Together, AWS Config and AWS CloudTrail can be used to meet the requirements for compliance, governance, auditing, and security by tracking configuration changes and recording a history of API calls made to your AWS resources.\n\nAmazon CloudWatch is a monitoring service for AWS resources and the applications you run on the cloud. It is not specifically designed for tracking configuration changes or recording a history of API calls.","poster":"Buruguduystunstugudunstuy","timestamp":"1671505440.0","upvote_count":"1","comment_id":"750432"}],"comment_id":"750431","poster":"Buruguduystunstugudunstuy","content":"Selected Answer: B\nThe correct answer is B: Use AWS Config to track configuration changes and AWS CloudTrail to record API calls.\n\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. It provides a history of configuration changes made to your resources and can be used to track changes made to your resources over time.\n\nAWS CloudTrail is a service that enables you to record API calls made to your AWS resources. It provides a history of API calls made to your resources, including the identity of the caller, the time of the call, the source of the call, and the response element returned by the service.","upvote_count":"2","timestamp":"1671505380.0"},{"poster":"IBANGA007","timestamp":"1671499380.0","upvote_count":"1","comment_id":"750379","content":"Selected Answer: B\nB. Use AWS Config to track configuration changes and AWS CloudTrail to record API calls.\n\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. It can track configuration changes to your AWS resources and record a history of these changes. AWS CloudTrail is a service that records API calls made to AWS resources and logs the API calls in a CloudTrail event."},{"upvote_count":"1","comment_id":"750049","timestamp":"1671468600.0","content":"B. ans :https://aws.amazon.com/about-aws/whats-new/2016/07/aws-cloudtrail-now-access-configuration-history-of-resources-referenced-in-your-api-calls/","poster":"duriselvan"},{"timestamp":"1671432180.0","content":"Selected Answer: B\nOption B","upvote_count":"1","comment_id":"749546","poster":"career360guru"},{"upvote_count":"1","content":"Correct Answer is A \nCloudTrail to track configuration changes and AWS Config to record API calls which Records the configuration state for the resource provided in the request. (AWS Config is a service that records the configuration of your AWS resources and maintains a history of changes made to these resources)AWS CloudTrail, on the other hand, is a service that records API calls made on your AWS account and delivers the log files to you. This service can be used to track configuration changes on your AWS resources in real time. Therefore, the correct solution is to use AWS CloudTrail to track configuration changes and AWS Config to record API calls.","poster":"Shasha1","comment_id":"743817","timestamp":"1670923920.0"},{"upvote_count":"1","content":"Selected Answer: B\nThe answer is B","poster":"AlaN652","comment_id":"736663","timestamp":"1670317680.0"},{"poster":"Wpcorgan","timestamp":"1669035840.0","upvote_count":"1","comment_id":"723512","content":"B is correct"},{"comment_id":"700982","timestamp":"1666361340.0","content":"Selected Answer: B\nThe answer is B","upvote_count":"2","poster":"bansalhp"},{"comment_id":"699192","timestamp":"1666197180.0","poster":"Evangelia","content":"bbbbbbbb","upvote_count":"3"},{"upvote_count":"4","content":"Selected Answer: B\nbbbbbbbb","timestamp":"1665555480.0","comment_id":"692749","poster":"tubtab"},{"content":"The answer is B","comment_id":"692473","upvote_count":"2","timestamp":"1665529440.0","poster":"Lilibell"}],"question_images":[],"answers_community":["B (99%)","1%"],"isMC":true,"question_text":"A company hosts its multi-tier applications on AWS. For compliance, governance, auditing, and security, the company must track configuration changes on its AWS resources and record a history of API calls made to these resources.\nWhat should a solutions architect do to meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/85202-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"unix_timestamp":1665529440,"choices":{"A":"Use AWS CloudTrail to track configuration changes and AWS Config to record API calls.","C":"Use AWS Config to track configuration changes and Amazon CloudWatch to record API calls.","D":"Use AWS CloudTrail to track configuration changes and Amazon CloudWatch to record API calls.","B":"Use AWS Config to track configuration changes and AWS CloudTrail to record API calls."},"answer_description":"","timestamp":"2022-10-12 01:04:00","answer":"B"},{"id":"zqEnrjOc4Gga6Ib5IOZG","url":"https://www.examtopics.com/discussions/amazon/view/99708-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","answers_community":["A (100%)"],"discussion":[{"content":"Selected Answer: A\nA. Use AWS WAF in front of the ALB. Associate the appropriate web ACLs with AWS WAF.\n\nSQL Injection - AWS WAF\nDDoS - AWS Shield","timestamp":"1708200000.0","poster":"Bhawesh","comment_id":"812313","upvote_count":"23"},{"timestamp":"1708277220.0","content":"Answer - A\nhttps://aws.amazon.com/premiumsupport/knowledge-center/waf-block-common-attacks/#:~:text=To%20protect%20your%20applications%20against,%2C%20query%20string%2C%20or%20URI.\n-----------------------------------------------------------------------------------------------------------------------\nProtect against SQL injection and cross-site scripting\nTo protect your applications against SQL injection and cross-site scripting (XSS) attacks, use the built-in SQL injection and cross-site scripting engines. Remember that attacks can be performed on different parts of the HTTP request, such as the HTTP header, query string, or URI. Configure the AWS WAF rules to inspect different parts of the HTTP request against the built-in mitigation engines.","comment_id":"813336","upvote_count":"8","poster":"jennyka76"},{"content":"AWS WAF - for SQL Injection ---> A\n\nAWS Shield - for DDOS\nAmazon Inspector - for automated security assessment, like known vulnerability","poster":"wsdasdasdqwdaw","upvote_count":"3","comment_id":"1045781","timestamp":"1729158900.0"},{"content":"Selected Answer: A\n° Use AWS WAF in front of the Application Load Balancer\n° Configure appropriate WAF web ACLs to detect and block SQL injection patterns\nThe key points:\n° Website hosted on EC2 behind an ALB with Aurora database\n° Application is vulnerable to SQL injection attacks\n° AWS WAF is designed to detect and block SQL injection and other common web exploits. It can be placed in front of the ALB to inspect all incoming requests. WAF rules can identify malicious SQL patterns and block them.","timestamp":"1725536760.0","upvote_count":"2","comment_id":"999438","poster":"Guru4Cloud"},{"timestamp":"1716365100.0","poster":"KMohsoe","comment_id":"903843","upvote_count":"2","content":"Selected Answer: A\nSQL injection -> WAF"},{"comment_id":"875518","content":"Selected Answer: A\nWAF is the right one","upvote_count":"2","timestamp":"1713612300.0","poster":"lexotan"},{"poster":"akram_akram","content":"Selected Answer: A\nSQL Injection - AWS WAF\nDDoS - AWS Shield","comment_id":"864938","timestamp":"1712601180.0","upvote_count":"2"},{"content":"Answer C - Shield Advanced (WAF + Firewall Manager)","timestamp":"1711172820.0","comment_id":"847850","poster":"movva12","upvote_count":"1"},{"upvote_count":"2","comment_id":"833685","timestamp":"1709970480.0","poster":"fkie4","content":"Selected Answer: A\nIt is A. I am happy to see Amazon gives out score like this..."},{"comments":[{"comment_id":"818902","poster":"LuckyAro","content":"B, C, and D are not the best solutions for this issue. Replying to SQL injections with a fixed response \n(B) is not a recommended approach as it does not actually fix the vulnerability, but only masks the issue. Subscribing to AWS Shield Advanced \n(C) is useful to protect against DDoS attacks but does not protect against SQL injection vulnerabilities. Amazon Inspector \n(D) is a vulnerability assessment tool and can identify vulnerabilities but cannot block attacks in real-time.","timestamp":"1708672260.0","upvote_count":"3"}],"timestamp":"1708672140.0","comment_id":"818899","poster":"LuckyAro","upvote_count":"3","content":"Selected Answer: A\nAWS WAF is a managed service that protects web applications from common web exploits that could affect application availability, compromise security, or consume excessive resources. AWS WAF enables customers to create custom rules that block common attack patterns, such as SQL injection attacks.\n\nBy using AWS WAF in front of the ALB and associating the appropriate web ACLs with AWS WAF, the company can protect its website application from SQL injection attacks. AWS WAF will inspect incoming traffic to the website application and block requests that match the defined SQL injection patterns in the web ACLs. This will help to prevent SQL injection attacks from reaching the application, thereby improving the overall security posture of the application."},{"upvote_count":"2","timestamp":"1708457880.0","poster":"pbpally","content":"Selected Answer: A\nBhawesh answers it perfect so I'm avoiding redundancy but agree on it being A.","comment_id":"815741"}],"isMC":true,"answer":"A","choices":{"D":"Set up Amazon Inspector to block all SQL injection attempts automatically.","A":"Use AWS WAF in front of the ALB. Associate the appropriate web ACLs with AWS WAF.","B":"Create an ALB listener rule to reply to SQL injections with a fixed response.","C":"Subscribe to AWS Shield Advanced to block all SQL injection attempts automatically."},"topic":"1","question_images":[],"question_text":"A media company hosts its website on AWS. The website application’s architecture includes a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB) and a database that is hosted on Amazon Aurora. The company’s cybersecurity team reports that the application is vulnerable to SQL injection.\n\nHow should the company resolve this issue?","exam_id":31,"timestamp":"2023-02-17 21:00:00","unix_timestamp":1676664000,"answer_images":[],"question_id":289,"answer_ET":"A"},{"id":"GI6Og4cv1S4DdPVeo3SN","answer_ET":"D","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/99710-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"question_id":290,"unix_timestamp":1676664240,"answer_images":[],"answers_community":["D (100%)"],"question_text":"A company has an Amazon S3 data lake that is governed by AWS Lake Formation. The company wants to create a visualization in Amazon QuickSight by joining the data in the data lake with operational data that is stored in an Amazon Aurora MySQL database. The company wants to enforce column-level authorization so that the company’s marketing team can access only a subset of columns in the database.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","discussion":[{"timestamp":"1692393480.0","comment_id":"813562","content":"Selected Answer: D\nThis solution leverages AWS Lake Formation to ingest data from the Aurora MySQL database into the S3 data lake, while enforcing column-level access control for QuickSight users. Lake Formation can be used to create and manage the data lake's metadata and enforce security and governance policies, including column-level access control. This solution then uses Amazon Athena as the data source in QuickSight to query the data in the S3 data lake. This solution minimizes operational overhead by leveraging AWS services to manage and secure the data, and by using a standard query service (Amazon Athena) to provide a SQL interface to the data.","poster":"K0nAn","upvote_count":"13"},{"content":"Answer - D\nhttps://aws.amazon.com/blogs/big-data/enforce-column-level-authorization-with-amazon-quicksight-and-aws-lake-formation/","timestamp":"1692320160.0","comment_id":"812582","upvote_count":"10","poster":"jennyka76"},{"poster":"awsgeek75","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/lake-formation/latest/dg/workflows-about.html","timestamp":"1721309160.0","upvote_count":"2","comment_id":"1126001"},{"poster":"Guru4Cloud","content":"Selected Answer: D\nUse a Lake Formation blueprint to ingest data from the Aurora database into the S3 data lake\nLeverage Lake Formation to enforce column-level access control for the marketing team\nUse Amazon Athena as the data source in QuickSight\nThe key points:\n\nNeed to join S3 data lake data with Aurora MySQL data\nRequire column-level access controls for marketing team in QuickSight\nMinimize operational overhead","upvote_count":"4","timestamp":"1709646060.0","comment_id":"999434"},{"poster":"LuckyAro","comment_id":"818908","timestamp":"1692768060.0","upvote_count":"5","content":"Selected Answer: D\nUsing a Lake Formation blueprint to ingest the data from the database to the S3 data lake, using Lake Formation to enforce column-level access control for the QuickSight users, and using Amazon Athena as the data source in QuickSight. This solution requires the least operational overhead as it utilizes the features provided by AWS Lake Formation to enforce column-level authorization, which simplifies the process and reduces the need for additional configuration and maintenance."},{"timestamp":"1692295440.0","upvote_count":"3","comment_id":"812319","poster":"Bhawesh","content":"Selected Answer: D\nD. Use a Lake Formation blueprint to ingest the data from the database to the S3 data lake. Use Lake Formation to enforce column-level access control for the QuickSight users. Use Amazon Athena as the data source in QuickSight.\n\nhttps://www.examtopics.com/discussions/amazon/view/80865-exam-aws-certified-solutions-architect-associate-saa-c02/"}],"answer":"D","choices":{"A":"Use Amazon EMR to ingest the data directly from the database to the QuickSight SPICE engine. Include only the required columns.","C":"Use AWS Glue Elastic Views to create a materialized view for the database in Amazon S3. Create an S3 bucket policy to enforce column-level access control for the QuickSight users. Use Amazon S3 as the data source in QuickSight.","B":"Use AWS Glue Studio to ingest the data from the database to the S3 data lake. Attach an IAM policy to the QuickSight users to enforce column-level access control. Use Amazon S3 as the data source in QuickSight.","D":"Use a Lake Formation blueprint to ingest the data from the database to the S3 data lake. Use Lake Formation to enforce column-level access control for the QuickSight users. Use Amazon Athena as the data source in QuickSight."},"question_images":[],"timestamp":"2023-02-17 21:04:00","topic":"1","answer_description":""}],"exam":{"lastUpdated":"11 Apr 2025","id":31,"provider":"Amazon","name":"AWS Certified Solutions Architect - Associate SAA-C03","isImplemented":true,"isBeta":false,"numberOfQuestions":1019,"isMCOnly":true},"currentPage":58},"__N_SSP":true}