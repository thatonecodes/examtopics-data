{"pageProps":{"questions":[{"id":"e3Wl5NcZSwqrNgTtkOJm","answer_ET":"D","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/95329-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"comment_id":"776575","upvote_count":"13","timestamp":"1689419760.0","poster":"mhmt4438","content":"Selected Answer: D\nD. Route incoming requests to Amazon Simple Queue Service (Amazon SQS). Configure an EC2 Auto Scaling group based on queue size. Update the software to read from the queue.\n\nBy routing incoming requests to Amazon SQS, the company can decouple the job requests from the processing instances. This allows them to scale the number of instances based on the size of the queue, providing more resources when needed. Additionally, using an Auto Scaling group based on the queue size will automatically scale the number of instances up or down depending on the workload. Updating the software to read from the queue will allow it to process the job requests in a more efficient manner, improving the performance of the system."},{"poster":"b1e2cbe","comment_id":"1197160","timestamp":"1729160880.0","content":"D is correct","upvote_count":"2"},{"upvote_count":"2","timestamp":"1723569720.0","poster":"Pangian","content":"Selected Answer: D\nThe based on the queue size doesn't seem a perfect approach though","comment_id":"1149510"},{"content":"Selected Answer: D\nD: Because this whole exam seems to be selling more and more SQS solutions...","upvote_count":"3","comment_id":"1111363","timestamp":"1719847980.0","poster":"awsgeek75"},{"timestamp":"1711438560.0","poster":"TariqKipkemei","content":"Selected Answer: D\nRoute incoming requests to Amazon Simple Queue Service (Amazon SQS). Configure an EC2 Auto Scaling group based on queue size. Update the software to read from the queue","comment_id":"1017402","upvote_count":"2"},{"content":"Selected Answer: D\nD. Route incoming requests to Amazon Simple Queue Service (Amazon SQS). Configure an EC2 Auto Scaling group based on queue size. Update the software to read from the queue.","poster":"Guru4Cloud","comment_id":"1004782","upvote_count":"2","timestamp":"1710167340.0"},{"poster":"Kill3rasp3r","comment_id":"986522","upvote_count":"4","timestamp":"1708527780.0","content":"Selected Answer: D\nI would vote A if it was ALB targeting an EC2 auto scaling group.\nI would vote D if the auto scaling group was based on CPU utilization rather than queue size.\nSo I think both answers are wrong but D is okay enough."},{"content":"Selected Answer: D\nA. Creating a copy of the instance and placing all instances behind an ALB does not address the high CPU utilization issue or provide scalability based on user load.\n\nB. Creating an S3 VPC endpoint for S3 and updating the software to reference the endpoint improves network performance but does not address the high CPU utilization or provide scalability based on user load.\n\nC. Stopping the EC2 instances and modifying the instance type to one with a more powerful CPU and more memory may improve performance, but it does not address scalability based on user load.\n\nD. Routing incoming requests to SQS, configuring an EC2 ASG based on queue size, and updating the software to read from the queue improves system performance and provides scalability based on user load.\n\nTherefore, option D is the correct choice as it addresses the high CPU utilization, improves system performance, and enables scalability based on user load.","upvote_count":"3","poster":"cookieMr","comment_id":"937594","timestamp":"1703836920.0"},{"content":"Selected Answer: D\nAutoscaling Group and SQS solves the problem. \nSQS - Decouples the process\nASG - Autoscales the EC2 instances based on usage","poster":"WherecanIstart","upvote_count":"2","timestamp":"1694578440.0","comment_id":"837677"},{"upvote_count":"1","comments":[{"poster":"wRhlH","comment_id":"905466","content":"You don't \"scale the system by load\" by choosing A","timestamp":"1700806740.0","upvote_count":"4"}],"comment_id":"828698","timestamp":"1693799100.0","poster":"ak1ak","content":"Selected Answer: A\nits definitely A"},{"comment_id":"775940","poster":"AHUI","upvote_count":"4","timestamp":"1689362460.0","content":"D is correct. Decouple the process. autoscale the EC2 based on query size. best choice"},{"comment_id":"775884","upvote_count":"1","poster":"Aninina","content":"I think it's A \" A. Create a copy of the instance. Place all instances behind an Application Load Balancer.","timestamp":"1689357780.0"}],"answer":"D","isMC":true,"choices":{"A":"Create a copy of the instance. Place all instances behind an Application Load Balancer.","C":"Stop the EC2 instances. Modify the instance type to one with a more powerful CPU and more memory. Restart the instances.","B":"Create an S3 VPC endpoint for Amazon S3. Update the software to reference the endpoint.","D":"Route incoming requests to Amazon Simple Queue Service (Amazon SQS). Configure an EC2 Auto Scaling group based on queue size. Update the software to read from the queue."},"unix_timestamp":1673726580,"question_images":[],"topic":"1","question_text":"A company runs analytics software on Amazon EC2 instances. The software accepts job requests from users to process data that has been uploaded to Amazon S3. Users report that some submitted data is not being processed Amazon CloudWatch reveals that the EC2 instances have a consistent CPU utilization at or near 100%. The company wants to improve system performance and scale the system based on user load.\n\nWhat should a solutions architect do to meet these requirements?","answers_community":["D (97%)","3%"],"question_id":186,"answer_description":"","exam_id":31,"timestamp":"2023-01-14 21:03:00"},{"id":"pqZwMU4Y7V0ocrHC1Mr1","timestamp":"2023-01-13 11:24:00","unix_timestamp":1673605440,"answer_images":[],"question_id":187,"question_images":[],"answer_description":"","answer":"D","answers_community":["D (97%)","3%"],"topic":"1","discussion":[{"content":"Selected Answer: D\nSMB + fully managed = fsx for windows imo","upvote_count":"20","poster":"Morinator","timestamp":"1673605440.0","comment_id":"774330"},{"upvote_count":"7","content":"Selected Answer: D\nAmazon FSx has native support for Windows file system features and for the industry-standard Server Message Block (SMB) protocol to access file storage over a network.\n\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html","comment_id":"792238","poster":"devonwho","timestamp":"1675041420.0","comments":[{"content":"As implied in the question, \"The solution must be fully managed\". Storage Gateway's SMB support is valid but not the best choice for this fully AWS-hosted and fully managed requirement.\n\nStorage Gateway requires the deployment of a gateway appliance (hardware or virtual). While AWS manages the back end (S3), setting up and maintaining the gateway appliance requires some operational effort, so it's not fully managed compared to FSx for Windows File Server.\n\nStorage Gateway is ideal for hybrid environments but adds unnecessary complexity if the workload is fully cloud-based. Not to mention that Storage Gateway File Gateway is focused on storing objects in S3, not providing a shared file system for direct collaboration or use by applications.","comment_id":"1316589","timestamp":"1732343940.0","poster":"LeonSauveterre","upvote_count":"2"}]},{"timestamp":"1741075500.0","poster":"kg508","upvote_count":"1","content":"Selected Answer: D\n뜬금없이 windows가 나와 당황하고 왜 굳이 fsx for windows여야 했나 싶지만\nD는 문제의 요구사항에 모두 적합합니다","comment_id":"1364796"},{"comment_id":"1236171","content":"Selected Answer: A\nAll the answers are wrong here by people. We don't know whether the user is using Windows based applications. AWS Storage Gateway also supports SMB protocol. This is the answer.","upvote_count":"2","timestamp":"1719213000.0","poster":"0xE8D4A51000"},{"upvote_count":"5","poster":"pentium75","content":"Selected Answer: D\nA: Volume Gateway provides virtual disks iSCSI, not SMB\nB: Tape Gateway provides virtual tapes via iSCSI, not SMB\nC: Not \"fully managed\"","comment_id":"1107745","timestamp":"1703765820.0"},{"content":"Selected Answer: D\nSMB = Amazon FSx for Windows File Server","poster":"TariqKipkemei","comment_id":"1017408","timestamp":"1695706860.0","upvote_count":"5"},{"content":"Selected Answer: D\nD. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system","comment_id":"1004742","poster":"Guru4Cloud","upvote_count":"3","timestamp":"1694433780.0","comments":[{"content":"All who selected D. are correct - see more details from our community","comment_id":"1004745","upvote_count":"2","poster":"Guru4Cloud","timestamp":"1694433840.0"}]},{"poster":"animefan1","content":"Selected Answer: D\nFsx is fully managed. Plus it supports SMB protocol","timestamp":"1688387580.0","comment_id":"941831","upvote_count":"2"},{"poster":"cookieMr","comment_id":"937595","timestamp":"1688018640.0","upvote_count":"6","content":"Selected Answer: D\nA. involves using Storage Gateway, but it does not specifically mention support for SMB clients. It may not meet the requirement of using SMB clients to access data.\n\nB. involves using Storage Gateway with tape gateway configuration, which is primarily used for archiving data to S3. It does not provide native support for SMB clients to access data.\n\nC. involves manually setting up and configuring a Windows file share on an EC2 Windows instance. While it allows SMB clients to access data, it is not a fully managed solution as it requires manual setup and maintenance.\n\nD. involves creating an FSx for Windows File Server file system, which is a fully managed Windows file system that supports SMB clients. It provides an easy-to-use shared storage solution with native SMB support.\n\nBased on the requirements of using SMB clients and needing a fully managed solution, option D is the most suitable choice."},{"upvote_count":"2","poster":"LuckyAro","comment_id":"782066","timestamp":"1674207840.0","content":"Selected Answer: D\nAmazon FSx for Windows File Server file system"},{"comment_id":"779190","content":"amazon fsx for smb connectivity.","upvote_count":"2","timestamp":"1673979720.0","poster":"techhb"},{"comment_id":"778154","timestamp":"1673897460.0","upvote_count":"2","content":"Selected Answer: D\nFSX is the ans","poster":"Aninina"},{"comment_id":"776582","upvote_count":"3","timestamp":"1673788980.0","poster":"mhmt4438","content":"Selected Answer: D\nhttps://www.examtopics.com/discussions/amazon/view/81115-exam-aws-certified-solutions-architect-associate-saa-c02/"},{"content":"Selected Answer: D\nD. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.","poster":"bamishr","comment_id":"774476","timestamp":"1673613960.0","upvote_count":"2"}],"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/95006-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"question_text":"A company is implementing a shared storage solution for a media application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed.\n\nWhich AWS solution meets these requirements?","choices":{"C":"Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.","A":"Create an AWS Storage Gateway volume gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.","D":"Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.","B":"Create an AWS Storage Gateway tape gateway. Configure tapes to use Amazon S3. Connect the application server to the tape gateway."},"isMC":true},{"id":"sVBlaM5UkzujcaNrKtNd","answer_ET":"D","answer_images":[],"exam_id":31,"discussion":[{"content":"Selected Answer: D\nA - refactoring can be a solution, BUT requires a LOT of effort - not the answer\nB - DynamoDB is NoSQL and Aurora is SQL, so it requires a DB migration... again a LOT of effort, so no the answer\nC and D are similar in structure, but...\nC uses SNS, which would notify the 2nd Lambda function... provoking the same bottleneck... not the solution\nD uses SQS, so the 2nd lambda function can go to the queue when responsive to keep with the DB load process. \nUsually the app decoupling helps with the performance improvement by distributing load. In this case, the bottleneck is solved by uses queues... so D is the answer.","timestamp":"1665931680.0","upvote_count":"99","poster":"123jhl0","comment_id":"696302"},{"poster":"PhucVuu","comment_id":"864337","upvote_count":"20","content":"Selected Answer: D\nKeywords: \n- Company has to increase the Lambda quotas significantly to handle the high volumes of data that the company needs to load into the database.\n- Improve scalability and minimize the configuration effort.\n\nA: Incorrect - Lambda is Serverless and automatically scale - EC2 instance we have to create load balancer, auto scaling group,.. a lot of things. using native Java Database Connectivity (JDBC) drivers don't improve the performance.\nB: Incorrect - a lot of things to changes and DynamoDB Accelerator use for cache(read) not for write.\nC: Incorrect - SNS is use for send notification (e-mail, SMS).\nD: Correct - with SQS we can scale application well by queuing the data.","timestamp":"1680916680.0"},{"comment_id":"1265355","poster":"PaulGa","content":"Selected Answer: D\nIt could be C or D, but Ans D wins because \n–SNS is Push Mechanism - ‘Other Lambda’ function is forced to take message when it might not be ready (or refuse it) \n–SQS is Pull Mechanism – ‘Other Lambda’ function can take next message when its ready to do so \nSQS is simple and allows better de-coupling.","timestamp":"1723581240.0","upvote_count":"2"},{"content":"Selected Answer: D\nuses SQS","poster":"rodrigoleoncio","comment_id":"1208898","timestamp":"1715264100.0","upvote_count":"1"},{"content":"If the throughput is so high that lambda concurrency needs to go beyond 1000, we need to set up a queue to throttle the request.","timestamp":"1712021220.0","upvote_count":"3","comment_id":"1187785","poster":"JohnZh"},{"upvote_count":"2","content":"Selected Answer: D\nD. Set up two Lambda functions, one for receiving information and another for loading data into the database. Integrate them using an Amazon SQS queue. This approach allows for better scalability, maintains the serverless paradigm, and minimizes manual configuration effort. It leverages Amazon SQS as a reliable message queue between Lambda functions.\n\nOptions A and B introduce complexities and changes in architecture, while Option C introduces an additional service that may not be as suitable for decoupling processes in this scenario.","timestamp":"1707940440.0","comment_id":"1150465","poster":"TheFivePips"},{"content":"Selected Answer: D\nSQS will help Lambda scale even more. \nA EC2 + Tomcat will be slower than Lambda for this usecase\nB is wrong because the problem is with Lambda scaling not the DB\nC SNS is not the best option for this usecase when SQS is an option","comment_id":"1122043","timestamp":"1705178880.0","poster":"awsgeek75","upvote_count":"5"},{"comment_id":"1121637","upvote_count":"1","timestamp":"1705149420.0","poster":"A_jaa","content":"Selected Answer: D\nAnswer-D"},{"comment_id":"1091407","timestamp":"1702089180.0","upvote_count":"1","content":"Selected Answer: D\nD : other ones just don’t make sense","poster":"ddement0r"},{"timestamp":"1700381100.0","upvote_count":"2","poster":"pedestrianlove","comment_id":"1074515","comments":[{"timestamp":"1704555120.0","poster":"mohamedsambo","content":"i think it is clear that he want to enhance the lambda even more than \"The default concurrency limit across all functions per region in a given account is 1,000\"\ncause sqs can scale and store the data till new available revoked lambda consume it","comment_id":"1115272","upvote_count":"3"}],"content":"Sorry, but the question does not make sense by itself. What are you asking for more scalability from an already scalable Lambda function? \n\nIf you're concerned about the concurrency limits of Lambda function, decoupling just doesn't make sense, since it'll keep even more lambda instances running in a given time period(including 2 phases of execution for each request, let alone the cold start issues).\n\nIf you're concerned about bottleneck database induced, that'll even be more ridiculous since you're supposed to resolve the scalability issue of the database(e.g. Aurora) instead of decoupling the Lambda function to improve the throughput of this entire data flow."},{"comment_id":"1054476","content":"Lambda and SQS are serverless. No involvement will be required in execution.","upvote_count":"2","poster":"Ruffyit","timestamp":"1698317580.0"},{"content":"Selected Answer: B\nI think B would be better solution.\nHow splitting one function into 2 increase scalability when company already increased service quota? Effectively they will have same compute time.\nChanging Aurora to DAX will shorten the time for data loads by ~100x requiring way less time for data loading, and it's most time consuming thing this lambda does. DAX has better scaling than aurora and is better fit with lambda","timestamp":"1697976300.0","comment_id":"1050532","upvote_count":"2","poster":"xdkonorek2"},{"content":"Lambda Functions: A review \nRun your code in response to events \n\nYou can build chatbots using Lambda functions to process user input, execute business logic, and generate responses. \nScales automatically \nThey can be triggered in response to API events \nLambda functions can process files as they are uploaded to S3 buckets. This is often used for tasks like image resizing, data extraction, or file validation.","comment_id":"999811","timestamp":"1693939560.0","poster":"MakaylaLearns","upvote_count":"1"},{"timestamp":"1693842540.0","comment_id":"998656","upvote_count":"1","poster":"[Removed]","content":"AWS Cost Explorer is a tool that enables you to view and analyze your costs and usage. You can explore your usage and costs using the main graph, the Cost Explorer cost and usage reports, or the Cost Explorer RI reports. You can view data for up to the last 12 months, forecast how much you're likely to spend for the next 12 months, and get recommendations for what Reserved Instances to purchase.\nAns: B is correct\nhttps://docs.aws.amazon.com/cost-management/latest/userguide/ce-what-is.html"},{"upvote_count":"2","poster":"doujones","content":"Do you all have to take the whole practice exam on here, in order to pass AWS SAA C03","timestamp":"1691418960.0","comment_id":"974773"},{"poster":"TariqKipkemei","content":"Increase Lambda quotas = Set up two Lambda functions. Improve scalability = Amazon Simple Queue Service.","timestamp":"1690950360.0","comment_id":"969665","comments":[{"comment_id":"969666","upvote_count":"1","content":"Selected answer D","poster":"TariqKipkemei","timestamp":"1690950360.0"}],"upvote_count":"1"},{"poster":"miki111","comment_id":"953565","upvote_count":"1","timestamp":"1689533040.0","content":"Option D is the right answer for this."},{"timestamp":"1689244980.0","comment_id":"950569","content":"Selected Answer: D\nLambda and SQS are serverless. No involvement will be required in execution.","upvote_count":"3","poster":"Kaab_B"},{"poster":"Thornessen","comments":[{"timestamp":"1689648300.0","poster":"ichwilldoit","content":"By, @cookieMr [https://www.examtopics.com/user/cookieMr/]\n\"By dividing the functionality into two Lambda functions, one for receiving the information and the other for loading it into the database, you can independently scale and optimize each function based on their specific requirements. This approach allows for more efficient resource allocation and reduces the potential impact of high volumes of data on the overall system.\"","comment_id":"954844","upvote_count":"2"}],"upvote_count":"2","content":"This threw me off - because ideally, I see no need for two lambdas. It can be done with one: APIGW -> SQS -> Lambda.","timestamp":"1689222120.0","comment_id":"950321"},{"timestamp":"1687079700.0","content":"Selected Answer: D\nOption D, setting up two Lambda functions and integrating them using an SQS, would be the most suitable solution to improve scalability and minimize configuration effort in this scenario.\n\nBy dividing the functionality into two Lambda functions, one for receiving the information and the other for loading it into the database, you can independently scale and optimize each function based on their specific requirements. This approach allows for more efficient resource allocation and reduces the potential impact of high volumes of data on the overall system.\n\nIntegrating the Lambda functions using an SQS adds another layer of scalability and reliability. The receiving function can push the information to the SQS, and the loading function can retrieve messages from the queue and process them independently. This asynchronous decoupling ensures that the receiving function can handle high volumes of incoming requests without overwhelming the loading function. Additionally, SQS provides built-in retries and guarantees message durability, ensuring that no data is lost during processing.","comment_id":"926582","upvote_count":"5","poster":"cookieMr"},{"poster":"TienHuynh","content":"Selected Answer: D\nD is correct, SQS can queue data","comment_id":"924488","upvote_count":"1","timestamp":"1686854040.0"},{"poster":"Bmarodi","content":"Selected Answer: D\nTo improve scalability and minimize the configuration effort. Solutions architect can choose option D.","comment_id":"912600","timestamp":"1685690460.0","upvote_count":"1"},{"content":"To improve scalability and minimize configuration efforts you can set up 2 lambda functions, one to receive the other to load. Then integrate the lambda functions using SQS.","upvote_count":"1","poster":"Abrar2022","comment_id":"897290","timestamp":"1684043760.0"},{"comment_id":"873630","timestamp":"1681822560.0","poster":"kakka22","content":"Is the question wrong? Amazon Aurora use it's own DB not PostgreSQL, you need to provision an rds instance for that..","upvote_count":"1"},{"poster":"Freddie26","upvote_count":"1","timestamp":"1681676520.0","comment_id":"872146","content":"The question ask you to improve scalability and minimize the configuration effort. While SNS is a fair answer, SQS is better. \"SQS scales elastically, and there is no limit to the number of messages per queue.\" See https://aws.amazon.com/blogs/compute/choosing-between-messaging-services-for-serverless-applications/."},{"poster":"linux_admin","timestamp":"1680261240.0","content":"Selected Answer: D\no improve scalability and minimize configuration effort, the recommended solution is to use an event-driven architecture with AWS Lambda functions. This will allow the company to handle high volumes of data without worrying about scaling the infrastructure.\n\nOption C and D both propose an event-driven architecture using Lambda functions, but option D is better suited for this use case because it uses an Amazon SQS queue to decouple the receiving and loading of information into the database. This will provide better fault tolerance and scalability, as messages can be stored in the queue until they are processed by the second Lambda function. In contrast, using SNS for this use case might cause some events to be missed, as it only guarantees the delivery of messages to subscribers, not to the Lambda function.","upvote_count":"3","comment_id":"856958"},{"comment_id":"768067","upvote_count":"1","content":"Selected Answer: D\nBy using two Lambda functions, you can separate the tasks of receiving the information and loading the information into the database. This will allow you to scale each function independently, improving scalability.","poster":"SilentMilli","timestamp":"1673037300.0"},{"poster":"Buruguduystunstugudunstuy","comment_id":"759044","upvote_count":"3","timestamp":"1672173060.0","comments":[{"timestamp":"1672173120.0","comment_id":"759045","content":"Option A, refactoring the Lambda function code to Apache Tomcat code that runs on Amazon EC2 instances and connecting the database using native JDBC drivers, is not a good choice because it would require significant effort to redesign and refactor the code and would not improve scalability.\n\nOption B, changing the platform from Aurora to Amazon DynamoDB and provisioning a DynamoDB Accelerator (DAX) cluster, is not a good choice because it would require significant effort to redesign and refactor the code and would not improve scalability.\n\nOption C, integrating the Lambda functions using Amazon SNS, is not a good choice because it does not provide the decoupling and scaling benefits of using an Amazon SQS queue.","poster":"Buruguduystunstugudunstuy","upvote_count":"2"}],"content":"Selected Answer: D\nThe solution that will meet these requirements is D: Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue.\n\nUsing separate Lambda functions for receiving and loading the information can help improve scalability and minimize the configuration effort. By using an Amazon SQS queue to integrate the Lambda functions, you can decouple the functions and allow them to scale independently. This can help reduce the burden on the receiving function, improving its performance and scalability."},{"content":"It's D (100%)","poster":"Zerotn3","upvote_count":"1","timestamp":"1672056960.0","comment_id":"757386"},{"upvote_count":"1","timestamp":"1671537600.0","content":"Selected Answer: D\nimprove scalability = SQS","comment_id":"750815","poster":"pazabal"},{"content":"Selected Answer: D\nThe solution that will meet these requirements is D: Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue.\n\nUsing separate Lambda functions for receiving and loading the information can help improve scalability and minimize the configuration effort. By using an Amazon SQS queue to integrate the Lambda functions, you can decouple the functions and allow them to scale independently. This can help reduce the burden on the receiving function, improving its performance and scalability.","comments":[{"upvote_count":"2","poster":"Buruguduystunstugudunstuy","comment_id":"750398","content":"Option A, refactoring the Lambda function code to Apache Tomcat code that runs on Amazon EC2 instances and connecting the database using native JDBC drivers, is not a good choice because it would require significant effort to redesign and refactor the code and would not improve scalability.\n\nOption B, changing the platform from Aurora to Amazon DynamoDB and provisioning a DynamoDB Accelerator (DAX) cluster, is not a good choice because it would require significant effort to redesign and refactor the code and would not improve scalability.\n\nOption C, integrating the Lambda functions using Amazon SNS, is not a good choice because it does not provide the decoupling and scaling benefits of using an Amazon SQS queue.","timestamp":"1671501840.0"}],"comment_id":"750396","poster":"Buruguduystunstugudunstuy","timestamp":"1671501840.0","upvote_count":"2"},{"timestamp":"1669035360.0","content":"D is correct","comment_id":"723498","upvote_count":"1","poster":"Wpcorgan"},{"timestamp":"1669011360.0","poster":"ABCMail","content":"Selected Answer: D\nTwo single responsibility functions offer a better solution.","upvote_count":"2","comment_id":"723204"},{"poster":"akosigengen","content":"D. Keyword is to handle load which will be taking care of by SQS.","timestamp":"1668838260.0","upvote_count":"2","comment_id":"721796"},{"timestamp":"1665554100.0","upvote_count":"2","content":"Selected Answer: D\nProcess of elimination, D","poster":"Ajai23","comment_id":"692707"},{"timestamp":"1665551400.0","upvote_count":"1","poster":"BoboChow","content":"Selected Answer: D\nAtually I'm really confused by those options.\nA is not right obiously, but the remaining options don't make sense, either...","comment_id":"692659","comments":[{"comment_id":"743382","upvote_count":"1","timestamp":"1670884080.0","poster":"Vickysss","content":"The idea is to avoid bottleneck on processing data by splitting the processes in two stages using two different Lambda and insert an SQS as intermediary so to crate an asynchronous process"}]},{"poster":"Lilibell","content":"the answer is D","comment_id":"692448","timestamp":"1665527460.0","upvote_count":"2"}],"answer_description":"","topic":"1","question_images":[],"timestamp":"2022-10-12 00:31:00","choices":{"B":"Change the platform from Aurora to Amazon DynamoDProvision a DynamoDB Accelerator (DAX) cluster. Use the DAX client SDK to point the existing DynamoDB API calls at the DAX cluster.","C":"Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using Amazon Simple Notification Service (Amazon SNS).","D":"Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue.","A":"Refactor the Lambda function code to Apache Tomcat code that runs on Amazon EC2 instances. Connect the database by using native Java Database Connectivity (JDBC) drivers."},"question_id":188,"question_text":"A company is designing an application. The application uses an AWS Lambda function to receive information through Amazon API Gateway and to store the information in an Amazon Aurora PostgreSQL database.\nDuring the proof-of-concept stage, the company has to increase the Lambda quotas significantly to handle the high volumes of data that the company needs to load into the database. A solutions architect must recommend a new design to improve scalability and minimize the configuration effort.\nWhich solution will meet these requirements?","isMC":true,"answers_community":["D (99%)","1%"],"url":"https://www.examtopics.com/discussions/amazon/view/85197-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1665527460,"answer":"D"},{"id":"c3MKo5akaB0vFYo9bhUZ","choices":{"A":"Use Amazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days","C":"Use AWS CloudTrail as the target. Configure CloudTrail to save to an Amazon S3 bucket, and enable S3 Intelligent-Tiering.","D":"Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days.","B":"Use Amazon Kinesis as the target. Configure the Kinesis stream to always retain the logs for 90 days."},"discussion":[{"timestamp":"1688018880.0","poster":"cookieMr","upvote_count":"10","content":"Selected Answer: D\nA. suggests using CloudWatch as the target for VPC Flow Logs. However, it does not provide a mechanism for managing the retention of the logs for 90 days and then accessing them intermittently.\n\nB. suggests using Kinesis as the target for VPC Flow Logs. While it can retain the logs for 90 days, it does not address the requirement for intermittent access to the logs.\n\nC. suggests using CloudTrail as the target for VPC Flow Logs. However, CloudTrail is designed for auditing and monitoring API activity, not for capturing network traffic logs. It does not meet the requirement of capturing VPC Flow Logs.\n\nD. suggests using S3 as the target for VPC Flow Logs and leveraging S3 Lifecycle policies to transition the logs to a cost-effective storage class after 90 days. It meets the requirement of retaining the logs for 90 days and provides the flexibility for intermittent access while optimizing storage costs.","comment_id":"937600"},{"timestamp":"1674208020.0","upvote_count":"6","content":"Selected Answer: D\nD is the correct answer.","poster":"LuckyAro","comment_id":"782070"},{"timestamp":"1729269600.0","comment_id":"1299746","poster":"manabpokhrel7","upvote_count":"2","content":"Selected Answer: D\nD is the correct answer"},{"timestamp":"1708539060.0","content":"Selected Answer: A\nA is correct\nYou can change the log data retention setting for CloudWatch logs. By default, logs are kept indefinitely and never expire. You can adjust the retention policy for each log group, keeping the indefinite retention, or choosing a retention period between 10 years and one day.\nhttps://docs.aws.amazon.com/managedservices/latest/userguide/log-customize-retention.html","upvote_count":"1","poster":"RicardoD","comments":[{"upvote_count":"1","comment_id":"1410382","content":"you need random access after 90 days but option A is removing the logs","poster":"jerryl","timestamp":"1742996760.0"}],"comment_id":"1155767"},{"timestamp":"1695707040.0","comment_id":"1017409","upvote_count":"2","poster":"TariqKipkemei","content":"Selected Answer: D\nUse Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days"},{"timestamp":"1694433780.0","comment_id":"1004741","poster":"Guru4Cloud","upvote_count":"2","content":"Selected Answer: D\nD. Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days."},{"poster":"animefan1","content":"Selected Answer: D\nS3 will store logs. With life cycle, we can move it to different class. With Option A, log groups expiration will simply remove the logs and failing the 2nd request in question","comment_id":"941836","timestamp":"1688387700.0","upvote_count":"3"},{"timestamp":"1687195260.0","poster":"markw92","comment_id":"927751","content":"A doesn't solve \"90 days and then accessed intermittently\" this statement. It sets expire after 90. Not sure otherwise A seems to be right choice since you can create dashboards etc.","upvote_count":"2"},{"timestamp":"1685519820.0","poster":"Bmarodi","comments":[{"comment_id":"1107747","content":"\"Expiration of 90 days\", but you need to access the log AFTER 90 days, just \"intermittently\".","poster":"pentium75","timestamp":"1703765940.0","upvote_count":"4"}],"content":"Selected Answer: A\nOption A meets these requirements.","comment_id":"910977","upvote_count":"1"},{"timestamp":"1675836900.0","comment_id":"801702","poster":"ocbn3wby","upvote_count":"4","content":"Selected Answer: D\nThere's a table here that specifies that VPC Flow logs can go directly to S3. Does not need to go via CloudTrail and then to S3. Nor via CW. \n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AWS-logs-and-resource-policy.html#AWS-logs-infrastructure-S3"},{"comment_id":"779196","timestamp":"1673980140.0","upvote_count":"3","poster":"techhb","content":"Selected Answer: D\nwe need to preserve logs hence D\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CloudWatchLogsConcepts.html"},{"timestamp":"1673897040.0","comment_id":"778150","upvote_count":"3","content":"Selected Answer: D\nD...agree that retention is the key word","poster":"mp165"},{"poster":"swolfgang","timestamp":"1673810640.0","upvote_count":"3","content":"Selected Answer: D\na is not,retantion means delete after 90 days but questions say rarely access.","comment_id":"776983"},{"comment_id":"776604","poster":"mhmt4438","content":"Selected Answer: D\nD. Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days.\n\nBy using Amazon S3 as the target for the VPC Flow Logs, the logs can be easily stored and accessed by the security team. Enabling an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days will automatically move the logs to a storage class that is optimized for infrequent access, reducing the storage costs for the company. The security team will still be able to access the logs as needed, even after they have been transitioned to S3 Standard-IA, but the storage cost will be optimized.","timestamp":"1673789760.0","upvote_count":"5"},{"content":"Selected Answer: D\nI prefer D\n\"accessed intermittently\" need logs after 90 days","upvote_count":"2","timestamp":"1673784540.0","poster":"laicos","comment_id":"776508"},{"comment_id":"776069","poster":"Parsons","timestamp":"1673743380.0","upvote_count":"3","content":"Selected Answer: D\nNo, D should be is correct.\n\"The logs will be frequently accessed for 90 days and then accessed intermittently.\" => We still need to store instead of deleting as the answer A."},{"timestamp":"1673727720.0","poster":"Aninina","comment_id":"775898","content":"Selected Answer: D\nD looks correct. This will meet the requirements of frequently accessing the logs for the first 90 days and then intermittently accessing them after that. S3 standard-IA is a storage class that is less expensive than S3 standard for infrequently accessed data, so it would be a more cost-effective option for storing the logs after the first 90 days.","upvote_count":"2"},{"timestamp":"1673605500.0","comments":[],"comment_id":"774331","poster":"Morinator","content":"Selected Answer: A\nCloudwatch for this\n\nhttps://www.examtopics.com/discussions/amazon/view/59983-exam-aws-certified-solutions-architect-associate-saa-c02/","upvote_count":"1"}],"question_images":[],"answer_images":[],"question_text":"A company’s security team requests that network traffic be captured in VPC Flow Logs. The logs will be frequently accessed for 90 days and then accessed intermittently.\n\nWhat should a solutions architect do to meet these requirements when configuring the logs?","answer":"D","unix_timestamp":1673605500,"url":"https://www.examtopics.com/discussions/amazon/view/95007-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_ET":"D","question_id":189,"isMC":true,"answer_description":"","exam_id":31,"topic":"1","answers_community":["D (94%)","6%"],"timestamp":"2023-01-13 11:25:00"},{"id":"R1DXYImV9wp9mO0c32NP","question_id":190,"answer":"B","unix_timestamp":1673610120,"discussion":[{"timestamp":"1689421320.0","comments":[{"poster":"Manjunathkb","timestamp":"1697126580.0","content":"NAT gateway does not allow internet on it's own. It needs internet gateway too. None of the answers make sense","comment_id":"868527","upvote_count":"10","comments":[{"comment_id":"1107751","timestamp":"1719570060.0","upvote_count":"3","poster":"pentium75","content":"B says \"place it in a public subnet\", a public subnet needs an Internet Gateway so that is included in the answer."},{"comments":[{"timestamp":"1716577560.0","poster":"TOR_0511","content":"lol, thats for 'private connections'","comment_id":"1079605","upvote_count":"1"}],"timestamp":"1697126700.0","comment_id":"868529","poster":"Manjunathkb","upvote_count":"3","content":"refer below link\nhttps://aws.amazon.com/about-aws/whats-new/2021/06/aws-removes-nat-gateways-dependence-on-internet-gateway-for-private-communications/"}]}],"content":"Selected Answer: B\nB. Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.\n\nThis approach will allow the EC2 instance to access the internet and download the monthly security updates while still being located in a private subnet. By creating a NAT gateway and placing it in a public subnet, it will allow the instances in the private subnet to access the internet through the NAT gateway. And then, configure the private subnet route table to use the NAT gateway as the default route. This will ensure that all outbound traffic is directed through the NAT gateway, allowing the EC2 instance to access the internet while still maintaining the security of the private subnet.","comment_id":"776616","poster":"mhmt4438","upvote_count":"10"},{"timestamp":"1727432580.0","comment_id":"1184076","poster":"Uzbekistan","upvote_count":"2","content":"Selected Answer: B\nB. Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.\n\nExplanation:\n\nNAT Gateway: NAT (Network Address Translation) gateway is a managed service provided by AWS that allows EC2 instances in private subnets to access the internet while preventing inbound traffic from directly accessing them. You place the NAT gateway in a public subnet with an associated internet gateway, allowing it to send traffic to the internet.\n\nPrivate Subnet Route Table: Configure the route table of the private subnet to route all outbound traffic (0.0.0.0/0) through the NAT gateway. This allows instances in the private subnet to access the internet through the NAT gateway while maintaining their private IP addresses and security."},{"comment_id":"1107755","upvote_count":"3","poster":"pentium75","content":"Selected Answer: B\nA - if you \"configure the private subnet route table to use the internet gateway\" then it's no longer a private subnet\nB - Correct (you place NAT GW in a public subnet and add it to the private subnet's route table)\nC - NAT instance is deprecated, and it would still in a private subnet where it doesn't have Internet access\nD - NAT instance is deprecated, and in that answer it is created but not even used","timestamp":"1719570360.0"},{"content":"yes, the nat gateway on its own does not allow connection to the internet. But the question specifies that it has been placed in a public subnet. public subnets are public because they have access to the internet via an internet gateway.","timestamp":"1717837800.0","upvote_count":"2","comment_id":"1091002","poster":"EtherealBagel"},{"poster":"xdkonorek2","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/vpc/latest/userguide/configure-subnets.html\nPublic subnet – The subnet has a direct route to an internet gateway. Resources in a public subnet can access the public internet.\nPrivate subnet – The subnet does not have a direct route to an internet gateway. Resources in a private subnet require a NAT device to access the public internet.\n\nBoth B and C have caveats but are both viable:\nC - NAT Instance is used as a NAT device instead of NAT gateway, but it's still viable option\nB - Have 2 redundant components - IGW and public subnet, and NAT gateway still would route traffic to IGW, and if VPC is a custom VPC routing has to be set up","timestamp":"1716540180.0","comments":[{"upvote_count":"2","content":"\"NAT instance in the same subnet where the EC2 instance is located\", how would you \"use the NAT instance as the default route\" when it's in the same subnet?","poster":"pentium75","timestamp":"1719570120.0","comment_id":"1107752"}],"upvote_count":"1","comment_id":"1079188"},{"content":"Selected Answer: D\nA NAT Gateway should have one interface in each network it is connected to. I don't understand what it means when they say it is located either in the private or in the public network. It should be in both. Therefore, B and D do not really make sense.\nI choose D over B because there is a requirement to access the internet and although it is possible for the NAT to exist without an internet gateway, the later is still needed when internet access is required which is the case in this scenario.","comment_id":"1046238","upvote_count":"1","comments":[{"comment_id":"1107754","poster":"pentium75","upvote_count":"2","content":"NAT Gateway must be in a public subnet as it needs Internet access. It can be specified in a private subnet's route table as a destination.\n\nD doesn't make sense because you created an (outdated) NAT instance but don't use it (you point the route table to the Internet Gateway).","timestamp":"1719570240.0"}],"poster":"oluolope","timestamp":"1713375480.0"},{"poster":"TariqKipkemei","content":"Selected Answer: B\nInternet Gateway is required anyway to access the internet.\nOption B makes more sense: Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.","upvote_count":"2","comment_id":"1017424","timestamp":"1711439760.0"},{"timestamp":"1710167160.0","content":"Selected Answer: B\nB. Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.","comment_id":"1004775","upvote_count":"2","poster":"Guru4Cloud"},{"poster":"cookieMr","timestamp":"1703837520.0","upvote_count":"4","content":"A. provides direct internet access to the private subnet, which is not desired in this case as the goal is to restrict outbound internet access.\n\nB. allows the EC2 in the private subnet to access the internet through the NAT gateway, which acts as a proxy. It provides controlled outbound internet access while maintaining the security of the private subnet.\n\nC. is similar to using a NAT gateway, but it involves using a NAT instance. NAT instances require more manual configuration and management compared to NAT gateways, making them a less preferred option.\n\nD. combines the use of an internet gateway and a NAT instance, which is not necessary. It introduces unnecessary complexity and adds a NAT instance that requires additional management.\n\nOverall, option B is the most appropriate solution as it utilizes a NAT gateway placed in a public subnet to enable controlled outbound internet access for the EC2 instance in the private subnet.\n\nNAT Gateways are preferred over NAT Instances by AWS and in general.","comment_id":"937602"},{"poster":"Bmarodi","timestamp":"1701347220.0","upvote_count":"2","comment_id":"911094","content":"Selected Answer: B\nOption B meets the reqiurements, hence B is right choice."},{"poster":"Manjunathkb","upvote_count":"2","content":"D would have been the answer if NAT gateway is installed in public subnet and not where EC2 is located. None of the answers are correct.","timestamp":"1697126760.0","comment_id":"868531"},{"poster":"AlessandraSAA","comments":[{"comment_id":"838783","content":"Because NAT Gateways are preferred over NAT Instances by AWS and in general.\n\nI have yet to find a situation where a NAT Instance would be more applicable than NAT Gateway which is fully managed and is overall an easier solution to implement - both in AWS questions or the real world.","upvote_count":"3","poster":"UnluckyDucky","timestamp":"1694683920.0"}],"upvote_count":"1","comment_id":"833965","content":"why not C?","timestamp":"1694256540.0"},{"content":"Selected Answer: B\nRequire NAT gateway","upvote_count":"2","comment_id":"802958","poster":"TungPham","timestamp":"1691560800.0"},{"comment_id":"779369","content":"Selected Answer: B\nAnswer explained here https://medium.com/@tshemku/aws-internet-gateway-vs-nat-gateway-vs-nat-instance-30523096df22","upvote_count":"2","poster":"techhb","timestamp":"1689624780.0"},{"content":"Selected Answer: B\nNAT Gateway is right choice","comment_id":"779254","timestamp":"1689614460.0","poster":"techhb","upvote_count":"2"},{"comment_id":"774398","content":"Selected Answer: B\nhttps://www.examtopics.com/discussions/amazon/view/59966-exam-aws-certified-solutions-architect-associate-saa-c02/","upvote_count":"3","poster":"bamishr","timestamp":"1689241320.0"}],"question_text":"An Amazon EC2 instance is located in a private subnet in a new VPC. This subnet does not have outbound internet access, but the EC2 instance needs the ability to download monthly security updates from an outside vendor.\n\nWhat should a solutions architect do to meet these requirements?","answer_ET":"B","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/95023-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"choices":{"B":"Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.","C":"Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the NAT instance as the default route.","D":"Create an internet gateway, and attach it to the VPC. Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the internet gateway as the default route.","A":"Create an internet gateway, and attach it to the VPC. Configure the private subnet route table to use the internet gateway as the default route."},"timestamp":"2023-01-13 12:42:00","answer_images":[],"answers_community":["B (94%)","3%"],"answer_description":"","topic":"1","question_images":[]}],"exam":{"lastUpdated":"11 Apr 2025","id":31,"numberOfQuestions":1019,"provider":"Amazon","isImplemented":true,"isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","isBeta":false},"currentPage":38},"__N_SSP":true}