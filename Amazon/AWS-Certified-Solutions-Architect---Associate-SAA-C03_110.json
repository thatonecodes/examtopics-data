{"pageProps":{"questions":[{"id":"CILZwISPhi0M5RZ27DBU","timestamp":"2023-08-02 03:09:00","exam_id":31,"answer":"C","question_id":546,"url":"https://www.examtopics.com/discussions/amazon/view/117029-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["C (100%)"],"unix_timestamp":1690938540,"choices":{"A":"Provision an Amazon DynamoDB database with default read and write capacity settings.","D":"Provision an Amazon RDS for MySQL database with 2 GiB of memory.","C":"Provision an Amazon Aurora Serverless v2 database with a minimum capacity of 1 Aurora capacity unit (ACU).","B":"Provision an Amazon Aurora database with a minimum capacity of 1 Aurora capacity unit (ACU)."},"question_images":[],"discussion":[{"poster":"Guru4Cloud","content":"Selected Answer: C\nThe key reasons:\n\nAurora Serverless v2 provides auto-scaling so the database can handle inconsistent workloads and spikes automatically without admin intervention.\nIt can scale down to zero when not in use to minimize costs.\nThe minimum 1 ACU capacity is sufficient to replace the on-prem 2 GiB database based on the info given.\nServerless capabilities reduce admin overhead for capacity management.\nDynamoDB lacks MySQL compatibility and requires more hands-on management.\nRDS and provisioned Aurora require manually resizing instances to scale, increasing admin overhead.","comment_id":"986550","timestamp":"1692625080.0","upvote_count":"11","comments":[{"comment_id":"1177131","upvote_count":"2","poster":"dkw2342","content":"> It can scale down to zero when not in use to minimize costs.\nThis part is not correct. Aurora Serverless v1 was able to scale to zero.","timestamp":"1710837600.0"}]},{"poster":"kambarami","comment_id":"1010593","comments":[{"poster":"foha2012","comments":[{"comment_id":"1120226","timestamp":"1705010580.0","upvote_count":"7","content":"Yes, I agree. I have been reading the pro questions and these are copy paste. On the bright side, it prepares you for the next step!","poster":"awsgeek75"}],"comment_id":"1114199","timestamp":"1704421020.0","upvote_count":"3","content":"I dont think these are associate exam questions rather are from AWS professional exam"}],"content":"the questions are hard from 500 +","upvote_count":"7","timestamp":"1695040440.0"},{"poster":"emakid","content":"Selected Answer: C\nC. Provision an Amazon Aurora Serverless v2 database with a minimum capacity of 1 Aurora capacity unit (ACU).\n\n Suitability: Amazon Aurora Serverless v2 is a good option for applications with variable workloads because it automatically adjusts capacity based on demand. It can handle MySQL-compatible databases and supports auto-scaling. You can set the minimum and maximum capacity based on your needs, making it highly suitable for handling unexpected workload increases with minimal administrative overhead.","timestamp":"1719704580.0","upvote_count":"2","comment_id":"1239442"},{"content":"Selected Answer: C\nLEAST administrative overhead = Aurora Serverless","upvote_count":"3","comment_id":"1120223","poster":"awsgeek75","timestamp":"1705010460.0"},{"content":"Selected Answer: C\nLEAST administrative overhead = Serverless","poster":"TariqKipkemei","upvote_count":"2","comment_id":"1077205","timestamp":"1700648040.0"},{"content":"Selected Answer: C\nserverless = LEAST overhead","upvote_count":"3","poster":"ibu007","comment_id":"981216","timestamp":"1692064800.0"},{"timestamp":"1691332020.0","upvote_count":"2","content":"Why not D?","poster":"D10SJoker","comments":[{"timestamp":"1714677180.0","content":"no autoscaling with RDS","comment_id":"1205790","upvote_count":"2","poster":"wizcloudifa"},{"poster":"awsgeek75","upvote_count":"2","timestamp":"1705010520.0","content":"Because \"LEAST administrative overhead\" is a requirement. RDS configured with mem requirements is an admin overhead","comment_id":"1120224"}],"comment_id":"973921"},{"comment_id":"971348","content":"Selected Answer: C\nC seems to be the right answer \n\nInstead of provisioning and managing database servers, you specify Aurora capacity units (ACUs). Each ACU is a combination of approximately 2 gigabytes (GB) of memory, corresponding CPU, and networking. Database storage automatically scales from 10 gibibytes (GiB) to 128 tebibytes (TiB), the same as storage in a standard Aurora DB cluster\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v1.how-it-works.html\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html","upvote_count":"2","poster":"mrsoa","timestamp":"1691084100.0"},{"poster":"Bmaster","comment_id":"969533","upvote_count":"3","content":"C is correct.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.how-it-works.html#aurora-serverless-v2.how-it-works.capacity","timestamp":"1690938540.0"}],"question_text":"A company runs an application on AWS. The application receives inconsistent amounts of usage. The application uses AWS Direct Connect to connect to an on-premises MySQL-compatible database. The on-premises database consistently uses a minimum of 2 GiB of memory.\n\nThe company wants to migrate the on-premises database to a managed AWS service. The company wants to use auto scaling capabilities to manage unexpected workload increases.\n\nWhich solution will meet these requirements with the LEAST administrative overhead?","isMC":true,"answer_ET":"C","topic":"1","answer_images":[],"answer_description":""},{"id":"bax4Vg1buld6WMVol5q1","choices":{"D":"Configure Lambda SnapStart.","A":"Configure Lambda provisioned concurrency.","B":"Increase the timeout of the Lambda functions.","C":"Increase the memory of the Lambda functions."},"topic":"1","timestamp":"2023-07-31 18:41:00","question_images":[],"answer_ET":"D","question_text":"A company wants to use an event-driven programming model with AWS Lambda. The company wants to reduce startup latency for Lambda functions that run on Java 11. The company does not have strict latency requirements for the applications. The company wants to reduce cold starts and outlier latencies when a function scales up.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_description":"","answers_community":["D (100%)"],"discussion":[{"comment_id":"986548","poster":"Guru4Cloud","upvote_count":"15","timestamp":"1708529520.0","content":"Selected Answer: D\nThe key reasons:\n\nSnapStart keeps functions initialized and ready to respond quickly, eliminating cold starts.\nSnapStart is optimized for applications without aggressive latency needs, reducing costs.\nIt scales automatically to match traffic spikes, eliminating outliers when scaling up.\nSnapStart is a native Lambda feature with no additional charges, keeping costs low.\nProvisioned concurrency incurs charges for always-on capacity reserved. More costly than SnapStart.\nIncreasing timeout and memory do not directly improve startup performance like SnapStart."},{"upvote_count":"5","poster":"anikety123","content":"Selected Answer: D\nBoth Lambda SnapStart and provisioned concurrency can reduce cold starts and outlier latencies when a function scales up. SnapStart helps you improve startup performance by up to 10x at no extra cost. Provisioned concurrency keeps functions initialized and ready to respond in double-digit milliseconds. Configuring provisioned concurrency incurs charges to your AWS account. Use provisioned concurrency if your application has strict cold start latency requirements. You can't use both SnapStart and provisioned concurrency on the same function version.","timestamp":"1708456140.0","comment_id":"985945"},{"timestamp":"1720728300.0","comment_id":"1120228","upvote_count":"5","comments":[{"upvote_count":"2","comment_id":"1120229","timestamp":"1720728420.0","poster":"awsgeek75","content":"Also\nA: Solves concurrency issues not startup\nB is for execution timeout (don't think that possible if I understand the option correctly)\nC Memory is not the issue here"}],"poster":"awsgeek75","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/lambda/latest/dg/snapstart.html\n\n\"Lambda SnapStart for Java can improve startup performance for latency-sensitive applications by up to 10x at no extra cost, typically with no changes to your function code.\""},{"comments":[{"content":"only because its a Java 11 app...if it were any other besides Java I believe Provisioned concurrency could help.","timestamp":"1716366240.0","upvote_count":"2","poster":"TariqKipkemei","comment_id":"1077213"}],"upvote_count":"2","content":"Selected Answer: D\nLambda SnapStart it is.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/snapstart.html#:~:text=RSS-,Lambda%20SnapStart,-for%20Java%20can","timestamp":"1716366120.0","poster":"TariqKipkemei","comment_id":"1077210"},{"upvote_count":"3","content":"Selected Answer: D\nLambda SnapStart for Java can improve startup performance for latency-sensitive applications by up to 10x at no extra cost, typically with no changes to your function code.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/snapstart.html","comment_id":"1064063","timestamp":"1715006400.0","poster":"potomac"},{"upvote_count":"2","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/lambda/latest/dg/snapstart.html","timestamp":"1709072460.0","poster":"BrijMohan08","comment_id":"991643"},{"comment_id":"987689","content":"Selected Answer: D\nD is correct\nLambda SnapStart for Java can improve startup performance for latency-sensitive applications by up to 10x at no extra cost, typically with no changes to your function code. The largest contributor to startup latency (often referred to as cold start time) is the time that Lambda spends initializing the function, which includes loading the function's code, starting the runtime, and initializing the function code.\n\nWith SnapStart, Lambda initializes your function when you publish a function version. Lambda takes a Firecracker microVM snapshot of the memory and disk state of the initialized execution environment, encrypts the snapshot, and caches it for low-latency access. When you invoke the function version for the first time, and as the invocations scale up, Lambda resumes new execution environments from the cached snapshot instead of initializing them from scratch, improving startup latency.","timestamp":"1708634340.0","poster":"skyphilip","upvote_count":"2"},{"content":"\"SnapStart does not support provisioned concurrency, the arm64 architecture, Amazon Elastic File System (Amazon EFS), or ephemeral storage greater than 512 MB.\" The question says \"The company wants to reduce cold starts\" This means provisioned concurrency. I'm a little bit confused with D.","poster":"avkya","comment_id":"979280","upvote_count":"3","timestamp":"1707737220.0"},{"upvote_count":"2","comment_id":"977332","poster":"Woodlawn5700","timestamp":"1707552120.0","content":"D\nhttps://docs.aws.amazon.com/lambda/latest/dg/snapstart.html"},{"upvote_count":"3","poster":"mrsoa","timestamp":"1706989440.0","comment_id":"971352","content":"Selected Answer: D\nD is the answer \n\n\nLambda SnapStart for Java can improve startup performance for latency-sensitive applications by up to 10x at no extra cost, typically with no changes to your function code. The largest contributor to startup latency (often referred to as cold start time) is the time that Lambda spends initializing the function, which includes loading the function's code, starting the runtime, and initializing the function code.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/snapstart.html"},{"poster":"Bmaster","timestamp":"1706844120.0","upvote_count":"4","comment_id":"969542","comments":[{"poster":"Bmaster","timestamp":"1706844180.0","content":"misspell.... lambda snapstart","comment_id":"969543","upvote_count":"2"}],"content":"D is best!!\nA is not MOST cost effectly. \nlambda snapshot is new feature for lambda.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/snapstart.html"},{"upvote_count":"3","poster":"RaksAWS","timestamp":"1706726460.0","content":"why not D \nIt should work","comment_id":"968318"}],"isMC":true,"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/116925-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"unix_timestamp":1690821660,"question_id":547,"answer_images":[]},{"id":"vCGetH050Y2wfO0eXxMS","question_id":548,"answers_community":["A (92%)","8%"],"answer":"A","choices":{"B":"Migrate the existing RDS for MySQL database to an Aurora MySQL database cluster.","C":"Migrate the existing RDS for MySQL database to an Amazon EC2 instance that runs MySQL. Purchase an instance reservation for the EC2 instance.","D":"Migrate the existing RDS for MySQL database to an Amazon Elastic Container Service (Amazon ECS) cluster that uses MySQL container images to run tasks.","A":"Migrate the existing RDS for MySQL database to an Aurora Serverless v2 MySQL database cluster."},"answer_description":"","exam_id":31,"isMC":true,"question_text":"A financial services company launched a new application that uses an Amazon RDS for MySQL database. The company uses the application to track stock market trends. The company needs to operate the application for only 2 hours at the end of each week. The company needs to optimize the cost of running the database.\n\nWhich solution will meet these requirements MOST cost-effectively?","discussion":[{"content":"Selected Answer: A\nThe key reasons are:\n\nAurora Serverless v2 scales compute capacity automatically based on actual usage, down to zero when not in use. This minimizes costs for intermittent usage.\nSince it only runs for 2 hours per week, the application is ideal for a serverless architecture like Aurora Serverless.\nAurora Serverless v2 charges per second when the database is active, unlike RDS which charges hourly.\nAurora Serverless provides higher availability than self-managed MySQL on EC2 or ECS.\nUsing reserved EC2 instances or ECS still incurs charges when not in use versus the fine-grained scaling of serverless.\nStandard Aurora clusters have a minimum capacity unlike the auto-scaling serverless architecture.","comments":[{"upvote_count":"2","poster":"dkw2342","comment_id":"1177139","timestamp":"1710837960.0","content":"A is correct, but Aurora Serverless v2 only scales down to 0.5 ACU, not to zero."}],"comment_id":"986525","poster":"Guru4Cloud","upvote_count":"13","timestamp":"1692623220.0"},{"timestamp":"1704179520.0","comment_id":"1111669","content":"Selected Answer: A\n2 hours per week = Serverless = A. Recommended for \"infrequent, intermittent, or unpredictable workloads\"","poster":"pentium75","upvote_count":"5"},{"comment_id":"1323945","poster":"LeonSauveterre","upvote_count":"1","timestamp":"1733736420.0","content":"Selected Answer: A\nA: Aurora Serverless v2 offers the most cost-effective and operationally efficient solution for intermittent workloads like this.\n\nB: over-provisioned and too expensive for this workload\nC: Also expensive. You gotta pay for the instance 24/7, regardless of usage.\nD: Introduces complexity and operational overhead for database management tasks. Overall, ECS is never easy to handle."},{"poster":"awsgeek75","timestamp":"1705010940.0","comment_id":"1120232","content":"Selected Answer: A\nB is wrong because Aurora MySQL cluster will just keep on running for the rest of the week and will be costly.\nC and D have too much infra bloating so costly","upvote_count":"2"},{"content":"Selected Answer: A\nAnswer is A. \nHere are the key distinctions:\n\nAmazon Aurora: provides built-in security, continuous backups, serverless compute, up to 15 read replicas, automated multi-Region replication, and integrations with other AWS services.\n\nAmazon Aurora Serverless: is an on-demand, auto-scaling configuration for Aurora where the database automatically starts up, shuts down, and scales capacity up or down based on your application's needs.\n\nWith serverless the db will shut down when not in use.","upvote_count":"5","poster":"TariqKipkemei","timestamp":"1700649420.0","comment_id":"1077241"},{"timestamp":"1692551040.0","comment_id":"985943","upvote_count":"3","poster":"anikety123","content":"Selected Answer: A\nOption is A"},{"content":"Selected Answer: A\n### Aurora Serverless\n\n- Automated database instantiation and auto-scaling based on actual usage\n- Good for infrequent, intermittent or unpredictable workloads\n- No capacity planning needed\n- Pay per second, can be more cost-effective","timestamp":"1692423060.0","upvote_count":"3","comment_id":"984993","poster":"hachiri"},{"poster":"vini15","content":"will go with A\nAmazon Aurora Serverless v2 is suitable for the most demanding, highly variable workloads. For example, your database usage might be heavy for a short period of time, followed by long periods of light activity or no activity at all.","comment_id":"978208","upvote_count":"3","timestamp":"1691719860.0"},{"upvote_count":"3","poster":"msdnpro","comment_id":"975268","timestamp":"1691477280.0","content":"Selected Answer: A\n\"Amazon Aurora Serverless v2 is suitable for the most demanding, highly variable workloads. For example, your database usage might be heavy for a short period of time, followed by long periods of light activity or no activity at all. \"\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.how-it-works.html"},{"poster":"ersin13","timestamp":"1691473560.0","content":"A. Migrate the existing RDS for MySQL database to an Aurora Serverless v2 MySQL database cluster.","upvote_count":"2","comment_id":"975245"},{"poster":"mrsoa","comments":[{"poster":"Chef_couincouin","upvote_count":"3","comment_id":"1067259","timestamp":"1699623780.0","content":"according to the link, i understand that Aurora Serverless is ideal for sudden peaks in database usage with moderate or minimal usage during other periods of the day. So Answear is A"},{"upvote_count":"1","content":"True but due to autoscaling - it will be cheaper...check example#1 in the your link.","comment_id":"989533","poster":"Smart","timestamp":"1692918300.0","comments":[{"timestamp":"1692918360.0","content":"Correct Answer is A","poster":"Smart","upvote_count":"2","comment_id":"989535"}]},{"content":"Provisioned RDS (as in B) is good for steady (not \"predictable\") workloads. In this case, the workload is predictable, but the prediction is that it will be used only 2 hours per week.","comment_id":"1111668","upvote_count":"3","poster":"pentium75","comments":[],"timestamp":"1704179400.0"}],"timestamp":"1691085300.0","upvote_count":"3","content":"Selected Answer: B\nB seems to be the correct answer, because if we have a predictable workload Aurora database seems to be most cost effective however if we have unpredictable workload aurora serverless seems to be more cost effective because our database will scale up and down\n\nfor more informations please read this article \nhttps://medium.com/trackit/aurora-or-aurora-serverless-v2-which-is-more-cost-effective-bcd12e172dcf","comment_id":"971359"}],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/117272-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2023-08-03 19:55:00","topic":"1","answer_ET":"A","unix_timestamp":1691085300,"question_images":[]},{"id":"B1TDV6bPXhgTJlMSOQPu","isMC":true,"discussion":[{"content":"Selected Answer: C\nRDS Multi-AZ DB cluster deployments provide high availability, automatic failover, and increased read capacity.\nA multi-AZ cluster automatically handles replicating data across AZs in a single region.\nThis maintains operational efficiency as it is natively managed by RDS without needing external replication.\nDynamoDB global tables involve complex provisioning and requires app changes.\nRDS read replicas require manual setup and management of replication.\nRDS Multi-AZ clustering is purpose-built by AWS for HA PostgreSQL deployments and balancing read workloads.","poster":"Guru4Cloud","timestamp":"1692622620.0","upvote_count":"9","comment_id":"986518"},{"timestamp":"1690879260.0","upvote_count":"5","comment_id":"968891","poster":"luiscc","content":"Selected Answer: C\nDB cluster deployment can scale read workloads by adding read replicas. This provides increased capacity for read workloads without impacting the write workload."},{"timestamp":"1726466040.0","upvote_count":"2","content":"Selected Answer: C\n\"A Multi-AZ DB cluster deployment is a semisynchronous, high availability deployment mode of Amazon RDS with two readable replica DB instances.\"","comment_id":"1284499","poster":"MatAlves"},{"upvote_count":"2","timestamp":"1706122560.0","poster":"upliftinghut","comment_id":"1131029","content":"Selected Answer: C\nmulti-AZ addresses both HA & increased read capacity with synchronous data replication between main DB & standby. Read replica is not enough because only increased read capacity not enabling HA, besides the data replication is async"},{"upvote_count":"2","poster":"awsgeek75","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html\n\"A Multi-AZ DB cluster deployment is a semisynchronous, high availability deployment mode of Amazon RDS with two readable standby DB instances\"\nA: DynamoDB is not Postgres\nB: Although HA is achieve but it does not increase the read capacity as much as C without additional operational complexity\nD: Cross region is not a requirement and won't solve the same region HA or read issues","timestamp":"1705011240.0","comment_id":"1120238"},{"upvote_count":"2","comment_id":"1095483","poster":"aws94","content":"Selected Answer: C\nMulti-AZ DB Cluster Deployment = Aurora","timestamp":"1702473120.0"},{"comment_id":"1077248","poster":"TariqKipkemei","content":"Selected Answer: C\nMulti-AZ DB cluster deployments provides two readable DB instances if you need additional read capacity","upvote_count":"2","timestamp":"1700649600.0"},{"upvote_count":"2","poster":"potomac","content":"Selected Answer: C\nC is correct","comment_id":"1064064","timestamp":"1699288980.0"},{"timestamp":"1691833140.0","upvote_count":"2","comment_id":"979288","content":"Selected Answer: C\nMulti-AZ DB clusters provide high availability, increased capacity for read workloads, and lower write latency when compared to Multi-AZ DB instance deployments.","poster":"avkya"},{"timestamp":"1691197020.0","comment_id":"972603","content":"Selected Answer: C\nCCCCCCCCCcCCcCcCCCCccccCc","poster":"mrsoa","upvote_count":"2"}],"answer_ET":"C","unix_timestamp":1690879260,"answers_community":["C (100%)"],"choices":{"C":"Create an Amazon RDS database with Multi-AZ DB cluster deployment.","A":"Create an Amazon DynamoDB database table configured with global tables.","D":"Create an Amazon RDS database configured with cross-Region read replicas.","B":"Create an Amazon RDS database with Multi-AZ deployments."},"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/116969-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company deploys its applications on Amazon Elastic Kubernetes Service (Amazon EKS) behind an Application Load Balancer in an AWS Region. The application needs to store data in a PostgreSQL database engine. The company wants the data in the database to be highly available. The company also needs increased capacity for read workloads.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","answer":"C","question_images":[],"exam_id":31,"answer_description":"","timestamp":"2023-08-01 10:41:00","answer_images":[],"question_id":549},{"id":"0lNUO5p0Anoy4TcakIMC","exam_id":31,"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/116906-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","topic":"1","timestamp":"2023-07-31 15:14:00","answer_images":[],"question_images":[],"answer_ET":"D","isMC":true,"question_id":550,"question_text":"A company is building a RESTful serverless web application on AWS by using Amazon API Gateway and AWS Lambda. The users of this web application will be geographically distributed, and the company wants to reduce the latency of API requests to these users.\n\nWhich type of endpoint should a solutions architect use to meet these requirements?","choices":{"B":"Regional endpoint","D":"Edge-optimized endpoint","C":"Interface VPC endpoint","A":"Private endpoint"},"unix_timestamp":1690809240,"answers_community":["D (100%)"],"discussion":[{"comment_id":"971365","timestamp":"1706990580.0","content":"Selected Answer: D\nThe correct answer is D \n\nAPI Gateway - Endpoint Types\n • Edge-Optimized (default): For global clients\n • Requests are routed through the CloudFront Edge locations (improves latency)\n • The API Gateway still lives in only one region\n• Regional:\n • For clients within the same region\n • Could manually combine with CloudFront (more control over the caching\n strategies and the distribution)\n• Private:\n • Can only be accessed from your VPC using an interface VPC endpoint (ENI)\n • Use a resource policy to define access","poster":"mrsoa","upvote_count":"8"},{"comment_id":"1064068","content":"Selected Answer: D\nAn edge-optimized API endpoint typically routes requests to the nearest CloudFront Point of Presence (POP), which could help in cases where your clients are geographically distributed. This is the default endpoint type for API Gateway REST APIs.\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html","timestamp":"1715006940.0","poster":"potomac","upvote_count":"5"},{"comment_id":"1127010","timestamp":"1721424840.0","poster":"awsgeek75","upvote_count":"2","content":"Selected Answer: D\ngeographically distributed users + low latency = Edge optimized ednpoint"},{"poster":"TariqKipkemei","content":"Selected Answer: D\nAn edge-optimized API endpoint typically routes requests to the nearest CloudFront Point of Presence (POP), which could help in cases where your clients are geographically distributed. This is the default endpoint type for API Gateway REST APIs.\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html#:~:text=API%20endpoint%20typically-,routes,-requests%20to%20the","upvote_count":"3","comment_id":"1077265","timestamp":"1716367680.0"},{"poster":"dilaaziz","upvote_count":"3","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html","timestamp":"1715058000.0","comment_id":"1064565"},{"poster":"Guru4Cloud","upvote_count":"3","timestamp":"1708527060.0","content":"Selected Answer: D\nEdge-optimized endpoint","comment_id":"986512"},{"comment_id":"968139","timestamp":"1706714040.0","content":"Correct D.\n\nEdge-optimized API endpoints\nAn edge-optimized API endpoint is best for geographically distributed clients. API requests are routed to the nearest CloudFront Point of Presence (POP). This is the default endpoint type for API Gateway REST APIs.","upvote_count":"3","poster":"Josantru"}]}],"exam":{"name":"AWS Certified Solutions Architect - Associate SAA-C03","isBeta":false,"numberOfQuestions":1019,"lastUpdated":"11 Apr 2025","isMCOnly":true,"id":31,"isImplemented":true,"provider":"Amazon"},"currentPage":110},"__N_SSP":true}