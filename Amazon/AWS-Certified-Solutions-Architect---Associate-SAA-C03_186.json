{"pageProps":{"questions":[{"id":"JHJap6XPqCflmCpiYw2K","exam_id":31,"isMC":true,"timestamp":"2024-08-07 21:11:00","answer":"B","discussion":[{"upvote_count":"2","timestamp":"1724131200.0","comment_id":"1269081","content":"Selected Answer: B\nB sounds right","poster":"[Removed]"},{"comment_id":"1264753","poster":"muhammadahmer36","timestamp":"1723485780.0","upvote_count":"2","content":"Selected Answer: B\nAnswer is B"},{"poster":"komorebi","comment_id":"1262227","upvote_count":"3","timestamp":"1723064400.0","content":"Selected Answer: B\nAnswer is B"},{"upvote_count":"1","timestamp":"1723057860.0","content":"Answer is D","poster":"swati1508","comments":[{"content":"B is correct sorry","comment_id":"1262206","timestamp":"1723057920.0","poster":"swati1508","upvote_count":"4"}],"comment_id":"1262205"}],"question_text":"A company has developed a non-production application that is composed of multiple microservices for each of the company's business units. A single development team maintains all the microservices.\n\nThe current architecture uses a static web frontend and a Java-based backend that contains the application logic. The architecture also uses a MySQL database that the company hosts on an Amazon EC2 instance.\n\nThe company needs to ensure that the application is secure and available globally.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","url":"https://www.examtopics.com/discussions/amazon/view/145211-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["B (100%)"],"unix_timestamp":1723057860,"choices":{"B":"Use Amazon CloudFront and Amazon S3 to host the static web frontend. Refactor the microservices to use AWS Lambda functions that the microservices access by using Amazon API Gateway. Migrate the MySQL database to Amazon RDS for MySQL.","A":"Use Amazon CloudFront and AWS Amplify to host the static web frontend. Refactor the microservices to use AWS Lambda functions that the microservices access by using Amazon API Gateway. Migrate the MySQL database to an Amazon EC2 Reserved Instance.","C":"Use Amazon CloudFront and Amazon S3 to host the static web frontend. Refactor the microservices to use AWS Lambda functions that are in a target group behind a Network Load Balancer. Migrate the MySQL database to Amazon RDS for MySQL.","D":"Use Amazon S3 to host the static web frontend. Refactor the microservices to use AWS Lambda functions that are in a target group behind an Application Load Balancer. Migrate the MySQL database to an Amazon EC2 Reserved Instance."},"question_id":926,"answer_description":"","answer_ET":"B","answer_images":[],"question_images":[],"topic":"1"},{"id":"frB95YVyg2O9oYaombqX","discussion":[{"content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/database/building-a-real-time-gaming-leaderboard-with-amazon-elasticache-for-redis/","timestamp":"1736269020.0","upvote_count":"1","comment_id":"1337640","poster":"Salilgen"},{"timestamp":"1735892640.0","comment_id":"1335943","poster":"LeonSauveterre","upvote_count":"1","content":"Selected Answer: C\nTo be more exact, you should use Amazon ElastiCache for Redis with AOF (Append-Only File) persistence. BTW, all the \"duster\"s in the options should be \"cluster\"s."},{"poster":"Bwhizzy","comment_id":"1296547","content":"Selected Answer: C\nREDIS\n• Multi AZ with Auto-Failover\n• Read Replicas to scale reads and\nhave high availability\n• Data Durability using AOF\npersistence\n• Backup and restore features\n• Supports Sets and Sorted Sets","timestamp":"1728741120.0","upvote_count":"2"},{"timestamp":"1723894560.0","upvote_count":"2","comment_id":"1267673","poster":"[Removed]","content":"Selected Answer: C\nC sounds right"},{"comment_id":"1262092","content":"Selected Answer: C\nAmazon ElastiCache for Redis provides in-memory caching which ensures low latency and high throughput, perfect for near real-time access to player reviews and rankings.\n\nRedis supports data persistence by snapshotting data to disk (RDB snapshots) and appending changes to a log (AOF), ensuring that the data is not lost even if the application restarts.","upvote_count":"4","timestamp":"1723033080.0","poster":"officedepotadmin"}],"isMC":true,"answer_ET":"C","answer":"C","choices":{"B":"Create Amazon EC2 instances in multiple AWS Regions. Store the player data on the EC2 instances. Configure Amazon Route 53 with geolocation records to direct users to the closest EC2 instance.","C":"Deploy an Amazon ElastiCache for Redis duster. Store the player data in the ElastiCache cluster.","A":"Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin. Store the player data in the S3 bucket.","D":"Deploy an Amazon ElastiCache for Memcached duster. Store the player data in the ElastiCache cluster."},"unix_timestamp":1723033080,"timestamp":"2024-08-07 14:18:00","question_images":[],"exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/145201-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","answer_images":[],"answers_community":["C (100%)"],"question_id":927,"answer_description":"","question_text":"A video game company is deploying a new gaming application to its global users. The company requires a solution that will provide near real-time reviews and rankings of the players.\n\nA solutions architect must design a solution to provide fast access to the data. The solution must also ensure the data persists on disks in the event that the company restarts the application.\n\nWhich solution will meet these requirements with the LEAST operational overhead?"},{"id":"bCXrbVYOBDfVB2T6AFJs","answer_images":[],"answer_description":"","timestamp":"2024-08-07 14:22:00","topic":"1","question_id":928,"answers_community":["D (100%)"],"choices":{"D":"Create separate AWS KMS keys for each customer's data that have granular access control and logging enabled.","A":"Generate a unique encryption key for each customer. Store the keys in an Amazon S3 bucket. Enable server-side encryption.","C":"Create a single AWS KMS key to encrypt all sensitive data across the application.","B":"Deploy a hardware security appliance in the AWS environment that securely stores customer-provided encryption keys. Integrate the security appliance with AWS KMS to encrypt the sensitive data in the application."},"url":"https://www.examtopics.com/discussions/amazon/view/145202-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"D","discussion":[{"comment_id":"1262094","poster":"officedepotadmin","upvote_count":"7","content":"Selected Answer: D\nWhile enabling server-side encryption in S3 can manage encryption, it does not offer the same level of control and auditing as AWS KMS. Managing individual keys manually in S3 would also increase operational overhead.","timestamp":"1723033320.0"},{"upvote_count":"2","timestamp":"1725645540.0","poster":"Jeyaluxshan","comment_id":"1279733","content":"D is with less management overhead"},{"content":"Selected Answer: D\nD is more secure","timestamp":"1724286120.0","upvote_count":"2","poster":"dhewa","comment_id":"1270431"},{"poster":"[Removed]","content":"Selected Answer: D\nD sounds right","comment_id":"1267676","upvote_count":"2","timestamp":"1723894800.0"},{"poster":"progounick","content":"Selected Answer: D\nit is obvious that D is correct","timestamp":"1723834920.0","comment_id":"1267311","upvote_count":"1"},{"timestamp":"1723486020.0","upvote_count":"2","comment_id":"1264755","poster":"muhammadahmer36","content":"Selected Answer: D\nhile enabling server-side encryption in S3 can manage encryption, it does not offer the same level of control and auditing as AWS KMS. Managing individual keys manually in S3 would also increase operational overhead."},{"poster":"nebajp","content":"Selected Answer: D\nD is the correct Answer","comment_id":"1263602","upvote_count":"2","timestamp":"1723315560.0"}],"question_images":[],"question_text":"A company is designing an application on AWS that processes sensitive data. The application stores and processes financial data for multiple customers.\n\nTo meet compliance requirements, the data for each customer must be encrypted separately at rest by using a secure, centralized key management solution. The company wants to use AWS Key Management Service (AWS KMS) to implement encryption.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","unix_timestamp":1723033320,"exam_id":31,"isMC":true,"answer_ET":"D"},{"id":"4n1SIlQMiQs3MneTtzNG","choices":{"C":"Use a Gateway Load Balancer (GWLB) to manage web traffic. Use Amazon Elastic Container Service (Amazon ECS) to receive and process customer orders. Use the GWLB to capture and store unprocessed orders. Use Amazon DynamoDB to store processed customer orders.","D":"Use an Application Load Balancer to manage web traffic. Use Amazon EC2 Auto Scaling groups to receive and process customer orders. Use Amazon Simple Queue Service (Amazon SQS) to store unprocessed orders. Use Amazon RDS with a Multi-AZ deployment to store processed customer orders.","B":"Use a Network Load Balancer (NLB) to manage web traffic. Use an Application Load Balancer to receive customer orders from the NLUse Amazon Redshift with a Multi-AZ deployment to store unprocessed and processed customer orders.","A":"Use a NAT gateway to manage web traffic. Use Amazon EC2 Auto Scaling groups to receive, process, and store processed customer orders. Use an AWS Lambda function to capture and store unprocessed orders."},"answer_ET":"D","answer_images":[],"question_text":"A company needs to design a resilient web application to process customer orders. The web application must automatically handle increases in web traffic and application usage without affecting the customer experience or losing customer orders.\n\nWhich solution will meet these requirements?","discussion":[{"poster":"Cpso","upvote_count":"1","content":"Selected Answer: D\nD is right. But explaining is unclear. should have 2 group of ec2. one for accept order to queue. another to process and store to DB.","timestamp":"1732752780.0","comment_id":"1318964"},{"timestamp":"1723895100.0","poster":"[Removed]","upvote_count":"2","content":"Selected Answer: D\nD sounds right","comment_id":"1267677"},{"content":"D is perfect","upvote_count":"2","comment_id":"1263577","timestamp":"1723306440.0","poster":"pujithacg8"},{"content":"Selected Answer: D\nAnswer is D","comment_id":"1262228","timestamp":"1723064460.0","upvote_count":"3","poster":"komorebi"},{"poster":"swati1508","timestamp":"1723058400.0","upvote_count":"2","comment_id":"1262208","content":"Answer is D"}],"exam_id":31,"answers_community":["D (100%)"],"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/145212-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1723058400,"topic":"1","timestamp":"2024-08-07 21:20:00","question_id":929,"question_images":[],"isMC":true,"answer_description":""},{"id":"lBSpVsT5z6yS0caAhiyz","question_images":[],"answer_ET":"A","question_text":"A company is using AWS DataSync to migrate millions of files from an on-premises system to AWS. The files are 10 KB in size on average.\n\nThe company wants to use Amazon S3 for file storage. For the first year after the migration, the files will be accessed once or twice and must be immediately available. After 1 year, the files must be archived for at least 7 years.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_description":"","answer_images":[],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/145420-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"A","answers_community":["A (54%)","D (44%)","2%"],"exam_id":31,"choices":{"B":"Use an archive tool to group the files into large objects. Use DataSync to copy the objects to S3 Standard-Infrequent Access (S3 Standard-IA). Use a lifecycle configuration to transition the files to S3 Glacier Instant Retrieval after 1 year with a retention period of 7 years.","D":"Configure a DataSync task to transfer the files to S3 Standard-Infrequent Access (S3 Standard-IA). Use a lifecycle configuration to transition the files to S3 Deep Archive after 1 year with a retention period of 7 years.","A":"Use an archive tool to group the files into large objects. Use DataSync to migrate the objects. Store the objects in S3 Glacier Instant Retrieval for the first year. Use a lifecycle configuration to transition the files to S3 Glacier Deep Archive after 1 year with a retention period of 7 years.","C":"Configure the destination storage class for the files as S3 Glacier Instant Retrieval. Use a lifecycle policy to transition the files to S3 Glacier Flexible Retrieval after 1 year with a retention period of 7 years."},"topic":"1","unix_timestamp":1723315800,"discussion":[{"upvote_count":"11","comments":[{"upvote_count":"1","timestamp":"1739264280.0","comment_id":"1354916","poster":"GOTJ","content":"Correct during the first year (online period). Incorrect during years 2-8 (archive period). Go check the numbers in price calculator yourself with the following scenarios for the archive period (S3 Glacier Deep Archive): \n\n* For small files: 100,000,000 files of 10KB (1000GB aprox). Considering both, the transition cost of 100,000,000 files to the Glacier Deep Archive class and the maintenance cost of 7 years for those 100,000,000 files: $6,940,34\n* For big files: 1000 files of 1000MB (1000GB aprox). Considering both, the transition cost of 1,000 files to the Glacier Deep Archive class and the maintenance cost of 7 years for those 1,000 files: $83,23"}],"content":"Selected Answer: D\nD simplifies the process by directly using S3 Standard-IA and then transitioning to S3 Glacier Deep Archive, which aligns well with access patterns and cost requirements. Option A sounds right but using an archive tool to group files into large objects adds complexity and operational overhead. This step isn’t necessary if you can directly manage the files with S3 lifecycle policies.","poster":"dhewa","timestamp":"1724287200.0","comment_id":"1270435"},{"content":"Selected Answer: A\nIts A, took some research but A is correct Per Amazon S# glacier page: \"Amazon S3 Glacier Instant Retrieval is an archive storage class that delivers the lowest-cost storage for long-lived data that is rarely accessed and requires retrieval in milliseconds. With S3 Glacier Instant Retrieval, you can save up to 68% on storage costs compared to using the S3 Standard-Infrequent Access (S3 Standard-IA) storage class, when your data is accessed once per quarter.\" After the one year move it to Deep archive.","poster":"blehbleh","comment_id":"1281524","timestamp":"1725970920.0","upvote_count":"5"},{"poster":"ad2dj28","upvote_count":"1","comment_id":"1399505","timestamp":"1742177940.0","content":"Selected Answer: D\n10/10 TIMES STANDARD INFREQUENT ACCESS IS CHEAPER THAN USING GLACIER INSTANT RETRIEVAL WHEN COMPARING COSTS WITH PRICING CALCULATOR"},{"comment_id":"1366457","timestamp":"1741398360.0","comments":[{"content":"Amazon S3 Glacier Instant Retrieval is an archive storage class that delivers the lowest-cost storage for long-lived data that is rarely accessed and requires retrieval in milliseconds. \n\nWith Amazon S3 Glacier Instant Retrieval, you can save up to 68% on storage costs compared to using the S3 Standard-Infrequent Access (S3 Standard-IA) storage class, when your data is accessed once per quarter.\" After the one year move it to S3 Glacier Deep archive.","upvote_count":"1","timestamp":"1741398600.0","poster":"tch","comment_id":"1366458"}],"content":"Selected Answer: A\nB & C are out","poster":"tch","upvote_count":"1"},{"timestamp":"1737626160.0","comments":[{"poster":"GOTJ","upvote_count":"1","comment_id":"1354921","timestamp":"1739264820.0","content":"Correct, but they mention that the files must be \"immediately available\" during the first year. So any option involving archive tools should be discarded for this period, due to the extra steps needed to accessing the files: figuring out which archive contains the file you are looking for, download the archive file and extract the desired file. I think this simple requirement explains the almost 50%-50% consensus for this particular question."}],"content":"Selected Answer: A\n10KB/file x millions of files = insane unnecessary cost when each is charged at 128KB/object\nNo one is talking about operational overhead, they just want cost-effectiveness","poster":"Mistwalker","upvote_count":"2","comment_id":"1345286"},{"content":"Selected Answer: A\n- Each file is 10 KB in size. \n- S3 charges a minimum of 128 KB per object.\n-Total number of files: millions of files.\n- Files are accessed twice in the first year.\n- After 1 year, files are archived for 7 years\n- S3 Glacier: Minimum charge for 40 KB per object.\n S3 Standard-IA and S3 One Zone-IA storage have a minimum billable object size of 128 KB. Smaller objects may be stored but will be charged for 128 KB of storage at the appropriate storage class rate Option D does not group those files into big object, so 1 million files will be charged as 1 million objects(128KB).\n https://aws.amazon.com/s3/pricing/","poster":"FlyingHawk","comment_id":"1341282","timestamp":"1736985840.0","upvote_count":"2","comments":[{"content":"Note\nThe S3 Standard-IA and S3 One Zone-IA storage classes are suitable for objects larger than 128 KB that you plan to store for at least 30 days. If an object is less than 128 KB, Amazon S3 charges you for 128 KB. If you delete an object before the end of the 30-day minimum storage duration period, you are charged for 30 days. Objects that are deleted, overwritten, or transitioned to a different storage class before 30 days will incur the normal storage usage charge plus a pro-rated charge for the remainder of the 30-day minimum. For pricing information, see Amazon S3 pricing. https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html","poster":"FlyingHawk","upvote_count":"2","comment_id":"1341285","timestamp":"1736986200.0"}]},{"content":"Selected Answer: D\nAbout option A: For data stored in the S3 Glacier Instant Retrieval storage class, there is indeed a minimum object size of 128 KB. If the objects are smaller than 128 KB, AWS still charges for 128 KB per object, which can significantly impact cost efficiency when dealing with a large number of small files, such as the 10 KB files in the given scenario.\n\nOne more thing: once or twice a year is perfect for Infrequent Access. It also provides instant availability for the objects stored in it.","poster":"LeonSauveterre","comments":[{"poster":"LeonSauveterre","timestamp":"1735896420.0","upvote_count":"1","comment_id":"1335964","content":"I believe Standard-IA remains the most straightforward and cost-effective choice for small files (10 KB average) that are accessed 1~2 times in the first year without aggregation."}],"comment_id":"1335962","timestamp":"1735896180.0","upvote_count":"1"},{"upvote_count":"2","comments":[{"content":"sorry, choose D","timestamp":"1735053360.0","comment_id":"1331165","upvote_count":"1","poster":"EllenLiu"}],"content":"Selected Answer: A\nS3 Glacier Instant Retrieval is more expensive than S3 Standard-IA for the first year when immediate availability is required.","timestamp":"1735053300.0","poster":"EllenLiu","comment_id":"1331164"},{"timestamp":"1734208260.0","poster":"dragossky","comment_id":"1326603","upvote_count":"2","content":"Selected Answer: A\nFor sure A, has amazing retrieval - Store the objects in S3 Glacier Instant Retrieval"},{"poster":"jfedotov","timestamp":"1734093960.0","content":"Selected Answer: D\nD is correct.\nA is not correct, because Amazon S3 Glacier Instant Retrieval min object size is 128KB, in question 10KB","upvote_count":"2","comment_id":"1326119"},{"timestamp":"1732818600.0","poster":"AMEJack","content":"Selected Answer: D\nThere is no need to use archive tool to migrate small files, DataSync is enough.","comment_id":"1319409","upvote_count":"2"},{"timestamp":"1727399460.0","comment_id":"1289781","poster":"Ez1tap","upvote_count":"4","content":"Selected Answer: A\ncorrect answer is A you need 2 separate lifecycle policy"},{"comments":[{"poster":"blehbleh","content":"Wrong, it says 1-2 times in the first year and Amazon states that s3 glacier isn’t at retrieval can save up to 68% compared to s3 infrequent access.","comment_id":"1295017","timestamp":"1728458640.0","upvote_count":"2"}],"timestamp":"1726215600.0","comment_id":"1283071","upvote_count":"3","poster":"Abhiiinav","content":"Selected Answer: D\nanswer is D. Storing the objects in S3 Glacier Instant Retrieval for the first year is more expensive than S3 Standard-IA for data that is accessed infrequently."},{"poster":"Abdullah2004","content":"Selected Answer: D\nD is most cost effective","timestamp":"1724927820.0","comment_id":"1274453","upvote_count":"3"},{"poster":"progounick","upvote_count":"2","content":"Selected Answer: A\nChatGPT agrees with me and selected A","timestamp":"1724919840.0","comments":[{"upvote_count":"3","timestamp":"1733383140.0","poster":"youkarthik","content":"My intance of chatgpt says it is D","comment_id":"1322259"}],"comment_id":"1274414"},{"upvote_count":"2","poster":"dhewa","content":"Selected Answer: A\nD simplifies the process by directly using S3 Standard-IA and then transitioning to S3 Glacier Deep Archive, which aligns well with access patterns and cost requirements. Option A sounds right but using an archive tool to group files into large objects adds complexity and operational overhead. This step isn’t necessary if you can directly manage the files with S3 lifecycle policies.","comment_id":"1270434","timestamp":"1724287020.0"},{"content":"Selected Answer: A\nA looks good","comment_id":"1269083","upvote_count":"2","poster":"[Removed]","timestamp":"1724131500.0"},{"timestamp":"1723486980.0","upvote_count":"2","comment_id":"1264759","poster":"muhammadahmer36","content":"Selected Answer: A\nAnswer is A"},{"upvote_count":"1","comment_id":"1263680","timestamp":"1723337340.0","poster":"komorebi","content":"Selected Answer: B\nAnswer is B"},{"comment_id":"1263603","upvote_count":"2","content":"Selected Answer: A\nCorrect Answer is A\nGlacier Deep Archive - For long term achieving \nGlacier Instant Retrieval - Availability for once or twice","timestamp":"1723315800.0","poster":"nebajp"}],"question_id":930,"timestamp":"2024-08-10 20:50:00"}],"exam":{"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Associate SAA-C03","isBeta":false,"isMCOnly":true,"isImplemented":true,"provider":"Amazon","id":31,"numberOfQuestions":1019},"currentPage":186},"__N_SSP":true}