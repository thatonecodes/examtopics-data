{"pageProps":{"questions":[{"id":"LEKDjSm42Woi25oUUrf9","question_images":[],"discussion":[{"content":"Selected Answer: B\nApplication-level audits are monitored by using CloudWatch. To enble ECS on Fargate to send logs on Amazon CloudWatch, we need to configure the awslogs log drive in the task definition. B is the correct answer","comment_id":"939042","upvote_count":"1","timestamp":"1688124240.0","poster":"rcaliandro"},{"timestamp":"1670933640.0","comment_id":"743977","poster":"mrbig00","content":"Selected Answer: B\nThe correct solution is option B. Configuring the awslogs log driver in the ECS task definition will allow the application to store the logs centrally on AWS. The awslogs log driver sends logs to Amazon CloudWatch Logs, which is a managed service that provides search and analysis of log data. This solution will meet the requirements of storing the logs centrally on AWS and making them searchable. Installing the Amazon CloudWatch agent on the Amazon EC2 host or installing the ECS logs collector on the ECS hosts will not work because the application is running on AWS Fargate and not on Amazon EC2. AWS CloudTrail is not a suitable solution because it is used to record API calls made to AWS services, not application-level API calls.","upvote_count":"4"},{"poster":"fabriciollf","timestamp":"1670845620.0","comment_id":"742727","upvote_count":"1","content":"Selected Answer: B\nReference documentation:\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html"},{"timestamp":"1669890060.0","poster":"k1kavi1","upvote_count":"1","content":"Selected Answer: B\nChoosing B","comment_id":"732490"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonECS/latest/userguide/using_awslogs.html\n\nUsing the awslogs log driver:\nYou can configure the containers in your tasks to send log information to CloudWatch Logs. If you do this, you can view the logs from the containers in your Fargate tasks.","upvote_count":"1","timestamp":"1669728900.0","comment_id":"730454","poster":"DrCloud"},{"poster":"JohnStanley","timestamp":"1669650900.0","content":"Selected Answer: B\nB\n\nhttps://www.datadoghq.com/blog/tools-for-collecting-aws-fargate-metrics/","upvote_count":"1","comment_id":"729347"},{"poster":"kapil206001","upvote_count":"1","comment_id":"727419","content":"D\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/logging-using-cloudtrail.html","comments":[{"upvote_count":"1","comment_id":"729861","poster":"geetha0489","content":"unable to find why D is the answer in this reference. Can you please explain","timestamp":"1669689120.0","comments":[{"timestamp":"1669731900.0","upvote_count":"1","poster":"DrCloud","comment_id":"730498","content":"Geetha: \"D\" is not correct. Reason: AWS Fargate is a managed service. We can't install at host level. https://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html"}]}],"timestamp":"1669455600.0"}],"isMC":true,"unix_timestamp":1669455600,"answer_ET":"B","answer_images":[],"topic":"1","choices":{"D":"Install the ECS logs collector on the ECS hosts.","B":"Configure the awslogs log driver in the ECS task definition.","C":"Configure AWS CloudTrail for the ECS containers.","A":"Install the Amazon CloudWatch agent on the Amazon EC2 host that runs Fargate."},"answers_community":["B (100%)"],"timestamp":"2022-11-26 10:40:00","question_text":"A business intelligence application runs on Amazon Elastic Container Service (Amazon ECS) on AWS Fargate. Application-level audits require a searchable log of all API calls from users to the application. The applicationâ€™s developers must store the logs centrally on AWS.\n\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/88835-exam-aws-certified-developer-associate-topic-1-question-301/","question_id":226,"answer_description":"","exam_id":25,"answer":"B"},{"id":"TR6xaDlpqcm8Gc75gaDB","answer_description":"","question_id":227,"discussion":[{"comment_id":"939048","upvote_count":"1","timestamp":"1688124360.0","poster":"rcaliandro","content":"Selected Answer: C\nC is the correct answer. Since fonts and other files are blocked from S3, we have to configure CORS policies on the S3 bucket to allow access from third-part entities"},{"comment_id":"730467","timestamp":"1669729380.0","upvote_count":"2","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/cors.html\n\nUsing cross-origin resource sharing (CORS):\nCross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.","poster":"DrCloud"},{"comment_id":"727528","poster":"k1kavi1","upvote_count":"1","content":"Selected Answer: C\nI agree","timestamp":"1669468560.0"},{"poster":"michaldavid","content":"Selected Answer: C\nC agreed","comment_id":"727508","upvote_count":"1","timestamp":"1669465980.0"}],"answer_ET":"C","timestamp":"2022-11-26 13:33:00","isMC":true,"question_text":"A company hosts a client-side web application for one of its subsidiaries on Amazon S3. The web application can be accessed through Amazon CloudFront from https://www.example.com. After a successful rollout, the company wants to host three more client-side web applications for its remaining subsidiaries on three separate S3 buckets.\n\nTo achieve this goal, a developer moves all the common JavaScript files and web fonts to a central S3 bucket that serves the web applications. However, during testing, the developer notices that the browser blocks the JavaScript files and web fonts.\n\nWhat should the developer do to prevent the browser from blocking the JavaScript files and web fonts?","question_images":[],"answers_community":["C (100%)"],"answer_images":[],"unix_timestamp":1669465980,"answer":"C","exam_id":25,"topic":"1","choices":{"A":"Create four access points that allow access to the central S3 bucket. Assign an access point to each web application bucket.","D":"Create a Content-MD5 header that provides a message integrity check for the central S3 bucket. Insert the Content-MD5 header for each web application request.","C":"Create a cross-origin resource sharing (CORS) configuration that allows access to the central S3 bucket. Add the CORS configuration to the central S3 bucket.","B":"Create a bucket policy that allows access to the central S3 bucket. Attach the bucket policy to the central S3 bucket."},"url":"https://www.examtopics.com/discussions/amazon/view/88856-exam-aws-certified-developer-associate-topic-1-question-302/"},{"id":"ZawpOpC4AZzGIuuRe6Es","timestamp":"2022-11-26 10:45:00","answer":"B","question_text":"A company has a new application. The company needs to secure sensitive configuration data such as database connection strings, application license codes, and API keys that the application uses to access external resources. The company must track access to the configuration data for auditing purposes. The resources are managed outside the application.\n\nThe company is not required to manage rotation of the connection strings, license codes, and API keys in the application. The company must implement a solution to securely store the configuration data and to give the application access to the configuration data. The solution must comply with security best practices.\n\nWhich solution will meet these requirements MOST cost-effectively?","exam_id":25,"question_images":[],"answers_community":["B (93%)","7%"],"answer_images":[],"isMC":true,"question_id":228,"answer_ET":"B","topic":"1","answer_description":"","choices":{"D":"Store the configuration data in AWS Secrets Manager. Grant the application access by using IAM policies.","B":"Store the configuration data in AWS Systems Manager Parameter Store. Grant the application access by using IAM policies.","A":"Store the configuration data in an encrypted file on the source code bundle. Grant the application access by using IAM policies.","C":"Store the configuration data on an Amazon Elastic Block Store (Amazon EBS) encrypted volume. Attach the EBS volume to an Amazon EC2 instance to provide the application with access to the data."},"discussion":[{"poster":"rcaliandro","content":"Selected Answer: B\nWe can use AWS Secrets Managager but, since it is more expensive and we don't have to manage rotation, we can simply use Systems Manager Parameter Store that is cost-effective and gives us the possibility to store hierarchical parameters in a secure way. To add another level of security and to achieve the requirements, we have to configure IAM policies as well. So, B is the correct way to go","upvote_count":"2","comment_id":"939052","timestamp":"1688124720.0"},{"content":"Selected Answer: B\nB because of what DrCloud showed. Can someone tell me how \"The company is not required to manage rotation\" AND \"The solution must comply with security best practices\" can co-exist?","poster":"captainpike","upvote_count":"1","comment_id":"862243","timestamp":"1680709080.0"},{"timestamp":"1671014160.0","content":"Selected Answer: B\nB\nSystem manager parameter is cost effective since customer doesnot want rotation .","poster":"fabriciollf","upvote_count":"2","comment_id":"744970"},{"content":"Selected Answer: B\nThe correct solution is option B. Storing the configuration data in AWS Systems Manager Parameter Store and granting the application access using IAM policies will meet the requirements of securely storing the configuration data and giving the application access to it. AWS Systems Manager Parameter Store is a managed service that provides a secure store for configuration data and allows for auditing of access to the data. This solution will be cost-effective because it does not require the company to manage the rotation of the connection strings, license codes, and API keys. Storing the data in an encrypted file on the source code bundle or on an Amazon EBS encrypted volume may not be secure enough to protect sensitive data. Using AWS Secrets Manager would be an appropriate solution, but it may not be as cost-effective as using AWS Systems Manager Parameter Store.","upvote_count":"4","comment_id":"743979","timestamp":"1670933760.0","poster":"mrbig00"},{"upvote_count":"3","timestamp":"1669816140.0","comment_id":"731545","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store/\n\nhttps://docs.aws.amazon.com/managedservices/latest/userguide/sys-man-param-store.html\nAWS Systems Manager Parameter Store (AMS SSPS):\nAWS Systems Manager Parameter Store provides secure, hierarchical storage for configuration data management and secrets management. You can store data such as passwords, database strings, and license codes as parameter values.","poster":"DrCloud"},{"comment_id":"727531","upvote_count":"2","timestamp":"1669468740.0","poster":"k1kavi1","content":"Selected Answer: B\nChoosing B"},{"timestamp":"1669466100.0","content":"Selected Answer: D\nThis is D","poster":"michaldavid","upvote_count":"1","comment_id":"727509"},{"upvote_count":"2","poster":"kapil206001","timestamp":"1669455900.0","content":"B\nSystem manager parameter is cost effective since customer doesnot want rotation .","comment_id":"727422"}],"url":"https://www.examtopics.com/discussions/amazon/view/88836-exam-aws-certified-developer-associate-topic-1-question-303/","unix_timestamp":1669455900},{"id":"OfEEPizJtm1rWuuvx6ZS","timestamp":"2022-11-24 14:12:00","topic":"1","answer_images":[],"unix_timestamp":1669295520,"url":"https://www.examtopics.com/discussions/amazon/view/88527-exam-aws-certified-developer-associate-topic-1-question-304/","question_images":[],"question_id":229,"isMC":true,"choices":{"B":"Process the messages on one EC2 instance instead of three instances.","D":"Increase the DelaySeconds value on the current SQS queue.","A":"Modify the SQS standard queue to an SQS FIFO queue.","C":"Create a new SQS FIFO queue. Point the application to the new queue."},"answer":"C","question_text":"A developer deploys a custom application to three Amazon EC2 instances. The application processes messages from an Amazon Simple Queue Service (Amazon SQS) standard queue with default settings. When the developer runs a load test on the Amazon SQS queue, the developer discovers that the application processes many messages multiple times.\n\nHow can the developer ensure that the application processes each message exactly once?","answer_description":"","discussion":[{"timestamp":"1669295520.0","comment_id":"725847","poster":"DrCloud","upvote_count":"5","content":"Ans: C\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-moving.html\nMoving from a standard queue to a FIFO queue:\nIf you have an existing application that uses standard queues and you want to take advantage of the ordering or exactly-once processing features of FIFO queues, you need to configure the queue and your application correctly.\nNote:\nYou can't convert an existing standard queue into a FIFO queue. To make the move, you must either create a new FIFO queue for your application or delete your existing standard queue and recreate it as a FIFO queue."},{"upvote_count":"3","timestamp":"1688124960.0","poster":"rcaliandro","comment_id":"939053","content":"Selected Answer: C\nSQS FIFO Queues are designed for:\n 1 - Process the data in order\n 2 - Avoid duplicate messages\nAnother important aspect about standard SQS Queues is that once created cannot be changed to SQS FIFO Queues. So, to meet the requirements it is possible to create another SQS FIFO Q and update the application to point at this one. C is the right answer."},{"timestamp":"1680151620.0","content":"Selected Answer: C\nCreate a new SQS queue, try to edit it and you'll notice that you cannot change it to FIFO.","comment_id":"855265","poster":"capesignalfreer","upvote_count":"1"},{"upvote_count":"1","timestamp":"1676226060.0","comment_id":"806659","content":"Selected Answer: C\nC is correct. Standard queues allow duplicate processing. They need a FIFO queue so that there won't be any duplicate processing. However, you can't convert an existing standard queue into a FIFO queue. To change the queue type from Standard to FIFO, you must delete the existing standard queue and create a FIFO queue.","poster":"pancman"},{"poster":"tieyua","timestamp":"1675013160.0","content":"Don't think there's a right answer here. \"processes many messages multiple times\" sounds like application retried. FIFO guarantee deliver once, but won't prevent retries. The likely true cause is not enough time to finish process, should have an option to increase visibility timeout.","comments":[{"poster":"captainpike","timestamp":"1679921400.0","comment_id":"852113","content":"I see your point, but, unfortunately, not all questions are without a flaw. I find useful to me not to overthink and go simple.","upvote_count":"1"}],"comment_id":"791881","upvote_count":"2"},{"comment_id":"752875","poster":"Nosal","content":"Selected Answer: C\nYou can't convert an existing standard queue into a FIFO queue. To make the move, you must either create a new FIFO queue for your application or delete your existing standard queue and recreate it as a FIFO queue.","upvote_count":"2","timestamp":"1671666300.0"},{"timestamp":"1670934000.0","comment_id":"743983","upvote_count":"1","content":"Selected Answer: A\nThe correct solution is option A. Modifying the SQS standard queue to an SQS FIFO queue will ensure that the application processes each message exactly once. SQS FIFO queues guarantee that messages are delivered and processed in the order in which they are sent, and that each message is processed exactly once. Using three EC2 instances to process messages may cause some messages to be processed multiple times. Creating a new SQS FIFO queue and pointing the application to it would work, but modifying the existing queue is a simpler solution. Increasing the DelaySeconds value on the queue would not help because it would not change the fact that messages may be processed multiple times.","poster":"mrbig00"},{"comment_id":"727534","content":"Selected Answer: C\nCreate new FIFO queue","upvote_count":"3","timestamp":"1669468800.0","poster":"k1kavi1"},{"content":"Selected Answer: D\nD is correct. Order of the messaged isn't the issues here DrCloud","upvote_count":"2","poster":"michaldavid","comments":[{"timestamp":"1676225880.0","comment_id":"806655","poster":"pancman","upvote_count":"3","content":"DelaySeconds sets the initial visibility delay. So the tasks in the queue become visible to EC2 instances that process them, after n seconds. It has no effect on duplicate processing. D is not correct."}],"timestamp":"1669466340.0","comment_id":"727510"}],"answers_community":["C (77%)","D (15%)","8%"],"exam_id":25,"answer_ET":"C"},{"id":"6UsHd5vV0okxcZErxLhP","answer":"A","question_text":"A company is running its website on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group. A developer needs to secure the internet-facing connection with HTTPS. The developer uses AWS Certificate Manager (ACM) to issue an X.509 certificate.\n\nWhat should the developer do to secure the connection?","question_images":[],"timestamp":"2022-11-24 14:27:00","answer_images":[],"exam_id":25,"discussion":[{"content":"Ans: A\nhttps://aws.amazon.com/premiumsupport/knowledge-center/configure-acm-certificates-ec2/\nhttps://aws.amazon.com/premiumsupport/knowledge-center/associate-acm-certificate-alb-nlb/\nConfiguring an Amazon Issued ACM public certificate for a website that's hosted on an EC2 instance requires exporting the certificate. However, you can't export the certificate because ACM manages the private key that signs and creates the certificate. \nInstead, you can associate an ACM certificate with a load balancer or an ACM SSL/TLS certificate with a CloudFront distribution.\nAssociate an ACM SSL certificate with an Application Load Balancer\nOpen the Amazon EC2 console.\nIn the navigation pane, choose Load Balancers, and then choose your Application Load Balancer.\nChoose Add listener.\nFor Protocol, choose HTTPS.\nFor port, choose 443.\nFor Default action(s), choose Forward to, and then select your ALB target group from the dropdown list.\nFor Default SSL certificate, choose From ACM (recommended) and then choose the ACM certificate.\nChoose Save.","poster":"DrCloud","timestamp":"1669296420.0","comment_id":"725850","upvote_count":"5"},{"upvote_count":"2","timestamp":"1688125320.0","comment_id":"939054","content":"Selected Answer: A\nA is the correct one, we need to install the certificate to the Load Balancer, and it is possible to do it by AWS Management Console since it is already present in Amazon Certificate Manager","poster":"rcaliandro"},{"poster":"mrbig00","content":"Selected Answer: A\nThe correct solution is option A. Configuring the ALB to use the X.509 certificate will secure the internet-facing connection with HTTPS. The developer can use the AWS Management Console to configure the ALB to use the X.509 certificate that was issued by ACM. This will ensure that the connection between the user's web browser and the ALB is encrypted using HTTPS. Configuring each EC2 instance to use the same X.509 certificate would not be necessary because the ALB will handle the SSL/TLS termination and encrypt the connection to the instances. Exporting the root key of the X.509 certificate to an S3 bucket and configuring the ALB or the EC2 instances to use it from the S3 bucket would not work because ACM certificates are managed by AWS and cannot be exported.","comment_id":"743991","upvote_count":"4","timestamp":"1670934360.0"},{"content":"Selected Answer: A\nChoosing A","upvote_count":"1","comment_id":"727537","timestamp":"1669468980.0","poster":"k1kavi1"},{"content":"Selected Answer: A\nI go with A","comment_id":"727511","upvote_count":"1","poster":"michaldavid","timestamp":"1669466460.0"}],"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/88528-exam-aws-certified-developer-associate-topic-1-question-305/","answers_community":["A (100%)"],"answer_description":"","question_id":230,"isMC":true,"choices":{"D":"Export the root key of the X.509 certificate to an Amazon S3 bucket. Configure the ALB to use the X.509 certificate from the S3 bucket.","A":"Configure the ALB to use the X.509 certificate by using the AWS Management Console.","B":"Configure each EC2 instance to use the same X.509 certificate by using the AWS Management Console.","C":"Export the root key of the X.509 certificate to an Amazon S3 bucket. Configure each EC2 instance to use the same X.509 certificate from the S3 bucket."},"unix_timestamp":1669296420,"topic":"1"}],"exam":{"numberOfQuestions":443,"name":"AWS Certified Developer Associate","provider":"Amazon","isMCOnly":true,"isImplemented":true,"id":25,"isBeta":false,"lastUpdated":"11 Apr 2025"},"currentPage":46},"__N_SSP":true}