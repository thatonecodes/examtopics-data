{"pageProps":{"questions":[{"id":"dSTL25ZWLr2q1rKj5Ffq","discussion":[{"timestamp":"1632125640.0","upvote_count":"13","comment_id":"134201","content":"Yes, C its correct!","poster":"BillyC"},{"poster":"novice_expert","timestamp":"1651256340.0","content":"Selected Answer: C\nC. Enable Amazon RDS Performance Insights will give you metric specifically for database with the dashboard \n\nD. Enhanced monitoring is for OS info","comment_id":"594638","upvote_count":"5"},{"upvote_count":"3","comment_id":"1008117","poster":"Pranava_GCP","timestamp":"1694751660.0","content":"Selected Answer: C\nC. Enable Amazon RDS Performance Insights and review the appropriate dashboard\n\n\n\nhttps://aws.amazon.com/rds/performance-insights/"},{"content":"Answer: C\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.UsingDashboard.AnalyzeDBLoad.html","poster":"renfdo","comment_id":"788091","timestamp":"1674676500.0","upvote_count":"2"},{"upvote_count":"1","poster":"SachinGoel","content":"Selected Answer: C\nAnswer - C","timestamp":"1673697360.0","comment_id":"775324"},{"upvote_count":"1","timestamp":"1655876820.0","poster":"sachin","comment_id":"620193","content":"My take is B"},{"comment_id":"619451","comments":[],"poster":"Balki","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.UsingDashboard.AnalyzeDBLoad.html","timestamp":"1655755200.0","upvote_count":"2"},{"upvote_count":"2","poster":"tugboat","comment_id":"555563","content":"Selected Answer: C\nPerformance Insights will give you required info","timestamp":"1645736940.0"},{"upvote_count":"1","content":"C>>> Enable Amazon RDS Performance Insights will give you metric specifically for database with the dashboard to navigate visually around to see database performance activities","timestamp":"1635573060.0","poster":"astood","comment_id":"441072"},{"poster":"aws4myself","timestamp":"1635518220.0","comment_id":"434515","upvote_count":"2","content":"C is correct"},{"upvote_count":"2","poster":"guru_ji","comment_id":"430116","content":"Correct Answer ==>> C","timestamp":"1634898300.0"},{"timestamp":"1634708760.0","comment_id":"416444","poster":"damaldon","content":"When you use RDS Performance Insights, you can visualize the database load and filter the load by waits, SQL statements, hosts, or users. This way, you can identify which queries are causing issues and view the wait type and wait events associated to that query.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-mysql-db-performance/","upvote_count":"1"},{"timestamp":"1634338620.0","upvote_count":"1","poster":"dcabib","content":"Amazon RDS does not gave Fault injection - Just Aurora has this feature ... Answer is B.","comment_id":"317400"},{"content":"Answer C","comment_id":"314766","upvote_count":"2","poster":"LMax","timestamp":"1634333100.0"},{"poster":"myutran","comment_id":"297886","timestamp":"1633976160.0","content":"Ans: C","upvote_count":"1"},{"poster":"JobinAkaJoe","upvote_count":"2","content":"C, no doubt","timestamp":"1633953540.0","comment_id":"253116"},{"poster":"BillyMadison","upvote_count":"3","timestamp":"1632265680.0","comment_id":"139730","content":"C as well.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.Enabling.html\nhttps://aws.amazon.com/rds/performance-insights/\nhttps://aws.amazon.com/blogs/database/tuning-amazon-rds-for-mysql-with-performance-insights/"}],"answer_description":"","exam_id":22,"answer_images":[],"question_images":[],"answer_ET":"C","timestamp":"2020-07-13 20:21:00","question_id":101,"unix_timestamp":1594664460,"isMC":true,"choices":{"D":"Enable Enhanced Monitoring will the appropriate settings","C":"Enable Amazon RDS Performance Insights and review the appropriate dashboard","B":"Create appropriate Amazon CloudWatch dashboards to contain specific periods of time","A":"Enable the option to push all database logs to Amazon CloudWatch for advanced analysis"},"question_text":"A team of Database Specialists is currently investigating performance issues on an Amazon RDS for MySQL DB instance and is reviewing related metrics. The team wants to narrow the possibilities down to specific database wait events to better understand the situation.\nHow can the Database Specialists accomplish this?","answer":"C","topic":"1","answers_community":["C (85%)","B (15%)"],"url":"https://www.examtopics.com/discussions/amazon/view/25643-exam-aws-certified-database-specialty-topic-1-question-19/"},{"id":"bCgXpXQMGH3x49EK0JlH","answer_images":[],"answers_community":["C (61%)","B (22%)","D (17%)"],"topic":"1","unix_timestamp":1662176460,"question_text":"Application developers have reported that an application is running slower as more users are added. The application database is running on an Amazon Aurora\nDB cluster with an Aurora Replica. The application is written to take advantage of read scaling through reader endpoints. A database specialist looks at the performance metrics of the database and determines that, as new users were added to the database, the primary instance CPU utilization steadily increased while the Aurora Replica CPU utilization remained steady.\nHow can the database specialist improve database performance while ensuring minimal downtime?","exam_id":22,"choices":{"B":"Modify the primary instance to a larger instance size that offers more CPU capacity.","C":"Modify a replica to a larger instance size that has more CPU capacity. Then, promote the modified replica.","D":"Restore the Aurora DB cluster to one that has an instance size with more CPU capacity. Then, swap the names of the old and new DB clusters.","A":"Modify the Aurora DB cluster to add more replicas until the overall load stabilizes. Then, reduce the number of replicas once the application meets service level objectives."},"timestamp":"2022-09-03 05:41:00","question_id":102,"url":"https://www.examtopics.com/discussions/amazon/view/79669-exam-aws-certified-database-specialty-topic-1-question-190/","question_images":[],"answer_ET":"C","answer_description":"","discussion":[{"comments":[{"timestamp":"1663139700.0","comment_id":"668700","poster":"SonamDhingra","content":"Promotion of the read replica will cause downtime, there will be no downtime with option D.","upvote_count":"1","comments":[{"poster":"awsjjj","timestamp":"1665843300.0","content":"D will result in data loss. C is correct","upvote_count":"2","comment_id":"695456"},{"content":"True, but as soon as you \"restore\" something, that is old data. How can you flip to old data (i.e. your backup) while the system is still up and running? Aren't you potentially losing transactions?","comment_id":"683788","poster":"JeanGat","timestamp":"1664561160.0","upvote_count":"3"}]}],"content":"Selected Answer: C\nMinimal downtime - operations first on replica and then promotion - Answer C.","comment_id":"658034","upvote_count":"5","poster":"mbar94","timestamp":"1662176460.0"},{"content":"Selected Answer: C\nA+D appear to be distractors,\nSo there's an agreement that the DB instance class must be vertically up-scaled.\nThe difference between B+C is that B applies it directlty to the Primary Instance and C to a Reader (replica) instance first.\nI believe that C is the wa to do it.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Performance.html#Aurora.Managing.Performance.InstanceScaling","poster":"Germaneli","timestamp":"1696177980.0","comment_id":"1022469","upvote_count":"1"},{"poster":"aviathor","upvote_count":"1","content":"Selected Answer: C\nThe thing here is that it is not stated whether we are looking at a Multi-AZ deployment. If that were to be the case, I understand that upgrading the type of the primary instance would cause very little downtime - just the time it would take to failover to the (upgraded) standby instance.","timestamp":"1684756560.0","comment_id":"904006"},{"poster":"SeemaDataReader","timestamp":"1682292540.0","comment_id":"878864","content":"Selected Answer: C\nYou can also modify DB instances in a DB cluster to accomplish tasks such as changing its DB instance class \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Modifying.html#Aurora.Modifying.Instance\nHence, C can be apt for minimum downtime.","upvote_count":"1"},{"comments":[{"poster":"dougporto1988","upvote_count":"2","timestamp":"1679801820.0","content":"Wrong answer \n\nIt will cause downtime:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Modifying.html#:~:text=specified%20DB%20instance-,An%20outage%20occurs%20during%20this%20change.,-DB%20instance%20identifier","comment_id":"850706"},{"comment_id":"867086","poster":"Mintwater","content":"Please be very careful using ChatGPT for AWS, it is very helpful, but it is not always correct.\nit could not have deep comprehension.\nThe correct answer is C","timestamp":"1681200660.0","upvote_count":"1"},{"upvote_count":"1","poster":"zWarez","content":"Remember, garbage in garbage out. ChatGPT is the future but we are not there yet. When required to associate facts and reasoning by itself, it behaves like a high schooler. Keep talking never say I don't know. C is the better answer.","timestamp":"1702228920.0","comment_id":"1092684"}],"upvote_count":"1","comment_id":"844325","content":"Selected Answer: B\nAnswer from ChatGPT4 \n\n\nBased on the given scenario, the primary instance's CPU utilization is increasing, while the Aurora Replica CPU utilization remains steady. This indicates that the write workload has increased, whereas read queries are already well-distributed using the reader endpoint. To improve the database performance with minimal downtime, you can implement the following steps:\n1. Scale the primary instance vertically by increasing its instance size:\n - Identify the appropriate Amazon Aurora DB instance size that can handle the increased workload and CPU utilization.\n - Modify the primary instance within the Aurora DB cluster to the new instance size. The failover process will cause a short downtime during the upgrade.\n\n\nThe short downtime will smaller than the replica","timestamp":"1679267400.0","poster":"dougporto1988"},{"upvote_count":"3","poster":"lollyj","content":"Selected Answer: B\nThe question reports that the CPU issue is on the primary instance and not on the RR.","timestamp":"1672020840.0","comment_id":"756133"},{"comment_id":"725994","content":"C is wrong , You can't \"Modify\" to a large instance, You have to drop exist one then re-create a newer replica . so D is better than C","upvote_count":"2","poster":"Jiang_aws1","timestamp":"1669302960.0","comments":[{"content":"It is true. For gaining high cpu, you have to recreate instance , no way to “modify”","upvote_count":"1","timestamp":"1681766700.0","comment_id":"873106","poster":"Mintwater"}]},{"timestamp":"1665843180.0","content":"Selected Answer: C\nD is incorrect due to the possible higher RTO and RPO(higher Downtime). C is correct","poster":"awsjjj","upvote_count":"2","comment_id":"695454"},{"upvote_count":"1","timestamp":"1664561400.0","comments":[{"timestamp":"1664561460.0","content":"The only issue is that D potentially NOT up to date with the latest transactions (i.e. you used a backup).","upvote_count":"1","poster":"JeanGat","comment_id":"683793"}],"poster":"JeanGat","comment_id":"683790","content":"Selected Answer: C\nC. There is minimal downtime with C, but NO downtime with D. The only issue is that D potentially up to date with the latest transactions (i.e. you used a backup)."},{"poster":"SonamDhingra","content":"Selected Answer: D\nD is correct","comment_id":"658336","upvote_count":"3","timestamp":"1662200640.0"}],"answer":"C","isMC":true},{"id":"JL0PmfCqPnpaQIJBcyoz","question_text":"A company's development team needs to have production data restored in a staging AWS account. The production database is running on an Amazon RDS for\nPostgreSQL Multi-AZ DB instance, which has AWS KMS encryption enabled using the default KMS key. A database specialist planned to share the most recent automated snapshot with the staging account, but discovered that the option to share snapshots is disabled in the AWS Management Console.\nWhat should the database specialist do to resolve this?","isMC":true,"unix_timestamp":1662186660,"answer_ET":"B","timestamp":"2022-09-03 08:31:00","answers_community":["B (100%)"],"exam_id":22,"answer_images":[],"answer_description":"","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/79691-exam-aws-certified-database-specialty-topic-1-question-191/","question_id":103,"answer":"B","choices":{"D":"Copy the automated snapshot while keeping the default KMS key. Share both the snapshot and the default KMS key with the staging account. Restore the snapshot in the staging account.","C":"Modify the DB instance to use a custom KMS encryption key. Share both the automated snapshot and the custom KMS encryption key with the staging account. Restore the snapshot in the staging account.","A":"Disable automated backups in the DB instance. Share both the automated snapshot and the default KMS key with the staging account. Restore the snapshot in the staging account and enable automated backups.","B":"Copy the automated snapshot specifying a custom KMS encryption key. Share both the copied snapshot and the custom KMS encryption key with the staging account. Restore the snapshot to the staging account within the same Region."},"discussion":[{"upvote_count":"8","timestamp":"1662186660.0","comment_id":"658129","content":"Selected Answer: B\nAgree with B - https://aws.amazon.com/premiumsupport/knowledge-center/rds-snapshots-share-account/","poster":"mbar94"},{"poster":"cloudsunriser","upvote_count":"1","content":"Selected Answer: B\nB is correct","timestamp":"1664126340.0","comment_id":"679030"},{"content":"Selected Answer: B\nB is correct","poster":"SonamDhingra","upvote_count":"1","timestamp":"1662200880.0","comment_id":"658337"}],"topic":"1"},{"id":"KR5wn7Qley0BV2a8nPHd","answer_images":[],"answers_community":["D (100%)"],"answer":"D","question_images":[],"choices":{"D":"Use Amazon CloudWatch Logs Insights to search and analyze the logs when the logs are automatically uploaded by the DB cluster.","B":"Download the logs from the DB cluster and store them in Amazon S3 by using manual scripts. Use Amazon Athena and Amazon QuickSight to search and analyze the logs.","C":"Use an AWS Lambda function to ship database logs to an Amazon S3 bucket. Use Amazon Elasticsearch Service (Amazon ES) and Kibana to search and analyze the logs.","A":"Use an AWS Lambda function to ship database logs to an Amazon S3 bucket. Use Amazon Athena and Amazon QuickSight to search and analyze the logs."},"timestamp":"2022-09-03 08:34:00","question_text":"A software-as-a-service (SaaS) company is using an Amazon Aurora Serverless DB cluster for its production MySQL database. The DB cluster has general logs and slow query logs enabled. A database engineer must use the most operationally efficient solution with minimal resource utilization to retain the logs and facilitate interactive search and analysis.\nWhich solution meets these requirements?","answer_description":"","question_id":104,"isMC":true,"topic":"1","unix_timestamp":1662186840,"exam_id":22,"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/79692-exam-aws-certified-database-specialty-topic-1-question-192/","discussion":[{"upvote_count":"5","poster":"cloudsunriser","comment_id":"679755","content":"Selected Answer: D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/aurora-serverless-logs-enable-view/","timestamp":"1664196600.0"},{"content":"A, B , C are trap as you don't need manual scripts to publish the logs to S3 in RDS or Aurora, it can be done by settings and options","poster":"Sathish_dbs","comment_id":"1026912","upvote_count":"2","timestamp":"1696618620.0"},{"upvote_count":"1","poster":"SonamDhingra","content":"Selected Answer: D\nD is correct","comment_id":"658338","timestamp":"1662200940.0"},{"poster":"mbar94","upvote_count":"4","content":"Selected Answer: D\nMinimal resource utilization - I'd go with D - https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html","comment_id":"658130","timestamp":"1662186840.0"}]},{"id":"HtRLa9LwcKCs4ofqRvP6","question_text":"A retail company uses Amazon Redshift Spectrum to run complex analytical queries on objects that are stored in an Amazon S3 bucket. The objects are joined with multiple dimension tables that are stored in an Amazon Redshift database. The company uses the database to create monthly and quarterly aggregated reports. Users who attempt to run queries are reporting the following error message: error: Spectrum Scan Error: Access throttled\nWhich solution will resolve this error?","question_images":[],"isMC":true,"unix_timestamp":1662187020,"exam_id":22,"topic":"1","discussion":[{"content":"Selected Answer: C\nC for sure according to the link - https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-troubleshooting.html","poster":"mbar94","comment_id":"658131","timestamp":"1662187020.0","upvote_count":"8"},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-troubleshooting.html","timestamp":"1706890500.0","comment_id":"1138710","poster":"Skarlex77","upvote_count":"1"},{"timestamp":"1704202080.0","content":"Selected Answer: C\nIf your Redshift Spectrum requests frequently get throttled by Amazon S3, reduce the number of Amazon S3 GET/HEAD requests that Redshift Spectrum makes to Amazon S3. To do this, try merging small files into larger files. We recommend using file sizes of 64 MB or larger.\nhttps://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-troubleshooting.html","poster":"missipssamarsh","comment_id":"1111933","upvote_count":"1"},{"content":"Selected Answer: D\nOption D suggests reviewing and optimizing the queries to submit a large aggregation step to Redshift Spectrum. This is the most appropriate solution to resolve the error, as it directly addresses the root cause of the issue. By optimizing the queries, it is possible to reduce the amount of data scanned by Redshift Spectrum, which will reduce the number of scan requests and prevent throttling.","comment_id":"821294","poster":"OCHT","timestamp":"1677313200.0","upvote_count":"1"},{"upvote_count":"1","poster":"TL12345","comment_id":"706647","content":"C.\nhttps://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-troubleshooting.html#spectrum-troubleshooting-access-throttled","timestamp":"1666976700.0"},{"content":"Selected Answer: C\nC. Both S3 and AWS KMS can throttle..the fix is always the same...larger/less files.\nhttps://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-troubleshooting.html","timestamp":"1664561820.0","poster":"JeanGat","upvote_count":"4","comment_id":"683796"},{"comment_id":"679757","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-troubleshooting.html#spectrum-troubleshooting-access-throttled","upvote_count":"3","poster":"cloudsunriser","timestamp":"1664196780.0"},{"comment_id":"661269","content":"Selected Answer: A\nA is correct","upvote_count":"1","timestamp":"1662470880.0","poster":"Adi_M"},{"upvote_count":"1","content":"Selected Answer: A\nA is correct \nhttps://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-troubleshooting.html","timestamp":"1662201000.0","poster":"SonamDhingra","comment_id":"658344","comments":[{"comment_id":"668704","upvote_count":"3","timestamp":"1663140120.0","content":"Sorry, the documentation points to C.","comments":[{"timestamp":"1696179360.0","poster":"Germaneli","comment_id":"1022513","content":"Yes, \"To do this, try merging small files into larger files. We recommend using file sizes of 64 MB or larger.\" --> C.","upvote_count":"1"}],"poster":"SonamDhingra"}]}],"answer_images":[],"question_id":105,"answer":"C","answers_community":["C (85%)","Other"],"answer_ET":"C","timestamp":"2022-09-03 08:37:00","choices":{"A":"Check file sizes of fact tables in Amazon S3, and look for large files. Break up large files into smaller files of equal size between 100 MB and 1 GB","D":"Review and optimize queries that submit a large aggregation step to Redshift Spectrum.","B":"Reduce the number of queries that users can run in parallel.","C":"Check file sizes of fact tables in Amazon S3, and look for small files. Merge the small files into larger files of at least 64 MB in size."},"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/79693-exam-aws-certified-database-specialty-topic-1-question-193/"}],"exam":{"numberOfQuestions":359,"isImplemented":true,"lastUpdated":"11 Apr 2025","isBeta":false,"name":"AWS Certified Database - Specialty","isMCOnly":false,"provider":"Amazon","id":22},"currentPage":21},"__N_SSP":true}