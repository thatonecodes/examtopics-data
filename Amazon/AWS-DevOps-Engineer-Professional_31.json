{"pageProps":{"questions":[{"id":"KX5oJltMXZxkL0CwvrP3","discussion":[{"poster":"LB","upvote_count":"14","timestamp":"1632232920.0","content":"The answer is B. We need to use AWS config rules.","comment_id":"356340"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/config/latest/developerguide/ec2-ebs-encryption-by-default.html\nrefer the link","upvote_count":"5","timestamp":"1655966940.0","poster":"ishitat","comment_id":"620812"},{"comment_id":"1046245","content":"Selected Answer: B\nThe answer is be. AWS Config give you the availability to scan your reasorces and find non compliance resources.","poster":"YR4591","upvote_count":"1","timestamp":"1697564880.0"},{"poster":"ParagSanyashiv","comment_id":"886478","timestamp":"1682958120.0","content":"Selected Answer: B\nB is more suitable for this scenario","upvote_count":"1"},{"upvote_count":"1","timestamp":"1677937440.0","content":"Selected Answer: B\nIf compliance then config","poster":"okm1997_2","comment_id":"829000"},{"poster":"Piccaso","comments":[{"content":"It is not about preventing the creation... It. Is about checking the compliance status, so you use config..","poster":"itbrpl","upvote_count":"1","timestamp":"1677595500.0","comment_id":"824918"}],"comment_id":"798902","timestamp":"1675608120.0","upvote_count":"1","content":"Selected Answer: C\nC looks most AWS managed"},{"poster":"Bulti","comment_id":"778351","upvote_count":"1","content":"Answe is B. When it comes to compliance checks go with AWS Config. Also note that AWS config is used at an organization level.","timestamp":"1673909220.0"},{"comments":[{"comment_id":"773731","upvote_count":"1","timestamp":"1673542800.0","poster":"[Removed]","content":"intent should be to \"prevent\"\nC seems a better option"}],"comment_id":"748327","upvote_count":"2","timestamp":"1671304800.0","content":"If the question was to prevent the volumes from being created instead of marking non compliant would it have been C?","poster":"neta1o"},{"poster":"blueorca","content":"Selected Answer: B\nneed Config to detect compliance","comment_id":"543351","upvote_count":"2","timestamp":"1644355800.0"},{"timestamp":"1640446860.0","poster":"Jack9573","content":"Selected Answer: B\nAnswer B","upvote_count":"1","comment_id":"509168"},{"comment_id":"508878","poster":"szl0144","content":"answer is B","upvote_count":"1","timestamp":"1640383380.0"},{"content":"Selected Answer: B\nBBBBBBBBBB","poster":"vpupkin","comment_id":"503901","upvote_count":"1","timestamp":"1639774260.0"},{"timestamp":"1635702900.0","content":"BBBBB B","comment_id":"433950","poster":"thisdump","upvote_count":"1"},{"timestamp":"1634495760.0","upvote_count":"2","poster":"D2","comment_id":"389173","content":"Answer B"},{"timestamp":"1633350600.0","comment_id":"361949","content":"BBBBBBBBBBB","poster":"MrCarter","upvote_count":"3"}],"answer":"B","choices":{"B":"Create an AWS Config organizational rule to check whether EBS encryption is enabled and deploy the rule using the AWS CLI. Create and apply an SCP to prohibit stopping and deleting AWS Config across the organization.","A":"Create an AWS CloudFormation template that defines an AWS Inspector rule to check whether EBS encryption is enabled. Save the template to an Amazon S3 bucket that has been shared with all accounts within the company. Update the account creation script pointing to the CloudFormation template in Amazon S3.","D":"Deploy an IAM role to all accounts from a single trusted account. Build a pipeline with AWS CodePipeline with a stage in AWS Lambda to assume the IAM role, and list all EBS volumes in the account. Publish a report to Amazon S3.","C":"Create an SCP in Organizations. Set the policy to prevent the launch of Amazon EC2 instances without encryption on the EBS volumes using a conditional expression. Apply the SCP to all AWS accounts. Use Amazon Athena to analyze the AWS CloudTrail output, looking for events that deny an ec2:RunInstances action."},"answer_images":[],"isMC":true,"timestamp":"2021-05-13 13:56:00","topic":"1","question_text":"A company uses AWS Organizations to manage multiple accounts. Information security policies require that all unencrypted Amazon EBS volumes be marked as non-compliant. A DevOps engineer needs to automatically deploy the solution and ensure that this compliance check is always present.\nWith solution will accomplish this?","answer_ET":"B","answers_community":["B (92%)","8%"],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/52621-exam-aws-devops-engineer-professional-topic-1-question-47/","question_id":151,"unix_timestamp":1620906960,"answer_description":"","exam_id":35},{"id":"QRcq5yVgdBmlzRmoxoVr","question_text":"A company develops and maintains a web application using Amazon EC2 instances and an Amazon RDS for SQL Server DB instance in a single Availability\nZone. The resources need to run only when new deployments are being tested using AWS CodePipeline. Testing occurs one or more times a week and each test takes 2-3 hours to run. A DevOps engineer wants a solution that does not change the architecture components.\nWhich solution will meet these requirements in the MOST cost-effective manner?","answer_description":"","unix_timestamp":1616403180,"choices":{"A":"Convert the RDS database to an Amazon Aurora Serverless database. Use an AWS Lambda function to start and stop the EC2 instances before and after tests.","C":"Replace the EC2 instances with EC2 Spot Instances and the RDS database with an RDS Reserved Instance.","B":"Put the EC2 instances into an Auto Scaling group. Schedule scaling to run at the start of the deployment tests.","D":"Subscribe Amazon CloudWatch Events to CodePipeline to trigger AWS Systems Manager Automation documents that start and stop all EC2 and RDS instances before and after deployment tests."},"timestamp":"2021-03-22 09:53:00","exam_id":35,"isMC":true,"topic":"1","answers_community":["D (100%)"],"question_id":152,"discussion":[{"comment_id":"317192","comments":[{"comment_id":"674003","poster":"syaldram","timestamp":"1663667400.0","upvote_count":"3","content":"This link perfectly describes the solution."}],"timestamp":"1635891660.0","poster":"1234567J","upvote_count":"26","content":"ans: D\nhttps://aws.amazon.com/blogs/mt/systems-manager-automation-documents-manage-instances-cut-costs-off-hours/"},{"upvote_count":"6","poster":"devopp","timestamp":"1635950820.0","content":"D \nRevealed B is wrong since breaking requirement to not change architecture components.","comment_id":"331025"},{"upvote_count":"1","comment_id":"1046247","poster":"YR4591","timestamp":"1697565060.0","content":"Selected Answer: D\nAnswer is D.\nAurora server less is not cost effective. \nRevered RDS is not cost effective since you pay for it regardless the fact its stopeed or turned on."},{"comment_id":"906173","upvote_count":"1","poster":"easytoo","timestamp":"1684967460.0","content":"d-d-d-d-dd-d-d-d-"},{"timestamp":"1684889640.0","poster":"easytoo","comment_id":"905374","content":"d-d-d-d-dd-d-d-d-","upvote_count":"1"},{"content":"D is the correct answer. Its AWS best practice to use Cloudwatch event against CodePipeline Deployment actions to trigger AWS System Manager automation documents to start and stop resources such as EC2 and RDS.","comment_id":"778354","upvote_count":"1","timestamp":"1673909520.0","poster":"Bulti"},{"comment_id":"770092","upvote_count":"1","poster":"ddev3737","timestamp":"1673247180.0","content":"Why not A?\nUses an AWS Lambda function to start and stop the EC2 instances before and after tests.\nBy converting the RDS database to an Amazon Aurora Serverless database, you can take advantage of the pay-per-use pricing model, \nwhich charges only for the database capacity that is actually used. This can help to reduce costs compared to using a standard RDS instance.\n\nD would require the use of AWS Systems Manager Automation, which incurs additional charges."},{"poster":"neta1o","content":"Selected Answer: D\nD is good, small caveat is that RDS can only be stopped for 7 days then itâ€™ll automatically start.","comment_id":"748330","upvote_count":"2","timestamp":"1671305100.0"},{"poster":"ohcn","timestamp":"1662579000.0","comment_id":"662828","upvote_count":"2","content":"D - You can stop RDS instances for up to 7 days. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_StopInstance.html"},{"content":"Selected Answer: D\nD looks better to me","timestamp":"1644439200.0","upvote_count":"3","comment_id":"544089","poster":"blueorca"},{"upvote_count":"2","comments":[{"content":"RDS can be stopped to save cost: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_StopInstance.html","comment_id":"732187","upvote_count":"2","poster":"kyozanuro","timestamp":"1669862820.0"},{"content":"What is the problem if we stop the server but do not terminate. D can be an anwer.","poster":"sg0206","timestamp":"1641080520.0","upvote_count":"2","comment_id":"514744"}],"poster":"Jaxjd","comment_id":"508474","content":"A Require a lot of code change\nB They have mentioned about EC2 but nothing about RDS\nC This could be an answer - task require for 2 or 3 hours and reserve the RDS instance to save the cost\nD won't- you cannot stop SQL RDS instance","timestamp":"1640347260.0"},{"timestamp":"1639834860.0","poster":"devonqo","content":"It's D.","comment_id":"504238","upvote_count":"2"},{"comment_id":"465191","upvote_count":"3","poster":"okida","timestamp":"1636268520.0","content":"It's D. Both EC2, RDS should be launched on-demand for the most cost saving."},{"timestamp":"1636249680.0","comment_id":"331305","upvote_count":"3","content":"note Revealed B is wrong for lowering costs since RDS is presumably then always running.","poster":"devopp"},{"timestamp":"1635421800.0","poster":"WhyIronMan","upvote_count":"1","comment_id":"316981","content":"it does not sounds like the efficient way"}],"answer_images":[],"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/47930-exam-aws-devops-engineer-professional-topic-1-question-48/","question_images":[],"answer":"D"},{"id":"dSmjuBDr1mY1pX0yK7wv","question_images":[],"discussion":[{"comment_id":"361337","upvote_count":"14","content":"B for me","poster":"Wrd123456789","timestamp":"1636018380.0"},{"content":"I'll go with B","poster":"WhyIronMan","upvote_count":"9","timestamp":"1632898680.0","comment_id":"325275"},{"timestamp":"1715779140.0","poster":"apcertification","upvote_count":"1","comment_id":"1211953","content":"B for me"},{"upvote_count":"1","content":"Selected Answer: B\nBuckets limit is per account.","poster":"YR4591","comment_id":"1056354","timestamp":"1698514200.0"},{"poster":"YR4591","content":"Selected Answer: B\nI will go with B","upvote_count":"1","timestamp":"1697565120.0","comment_id":"1046249"},{"poster":"ParagSanyashiv","comment_id":"886504","upvote_count":"1","timestamp":"1682959020.0","content":"B is more precise for this scenario"},{"timestamp":"1675754640.0","content":"Selected Answer: D\nA is eliminated, single repository is not a good idea.\nC is eliminated, region is not the point.\nD is neater than B","comment_id":"800648","poster":"Piccaso","comments":[{"timestamp":"1675754760.0","comment_id":"800652","upvote_count":"1","poster":"Piccaso","content":"Sorry, D is wrong. Buckets limit is on each account, not each project."}],"upvote_count":"2"},{"content":"I will go with B as well","upvote_count":"2","comment_id":"795307","timestamp":"1675269540.0","poster":"Hamza5"},{"upvote_count":"2","poster":"Bulti","timestamp":"1673909640.0","comment_id":"778355","content":"B is the right answer"},{"timestamp":"1665986820.0","content":"Selected Answer: B\nI'll go with B","comment_id":"696971","upvote_count":"3","poster":"ducluanxutrieu"},{"upvote_count":"5","poster":"Rajarshi","comment_id":"309758","timestamp":"1632610680.0","content":"ans is B"}],"answers_community":["B (71%)","D (29%)"],"exam_id":35,"question_id":153,"answer_images":[],"choices":{"A":"Combine the multiple separate code repositories into a single one, and deploy using an AWS CodePipeline that has logic for each project.","C":"Create a new pipeline in a different region for each project to bypass the service limits for S3 buckets in a single region.","D":"Create a new pipeline and S3 bucket for each project by using the AWS API or AWS CLI to bypass the service limits for S3 buckets in a single account.","B":"Create new pipelines by using the AWS API or AWS CLI, and configure them to use a single S3 bucket with separate prefixes for each project."},"timestamp":"2021-03-13 15:14:00","answer_ET":"B","question_text":"The Development team has grown substantially in recent months and so has the number of projects that use separate code repositories. The current process involves configuring AWS CodePipeline manually. There have been service limit alerts regarding the number of Amazon S3 buckets that exist.\nWhich pipeline option will reduce S3 bucket sprawl alerts?","answer_description":"","isMC":true,"unix_timestamp":1615644840,"answer":"B","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/46890-exam-aws-devops-engineer-professional-topic-1-question-49/"},{"id":"eInIptIwVjmU9qZmCeVc","choices":{"C":"Create IAM access keys for the on-premises machines to interact with AWS Systems Manager.","F":"Use AWS Systems Manager Maintenance Windows to schedule a patch window.","B":"Attach an IAM role to the EC2 instances, allowing them to be managed by AWS Systems Manager.","D":"Execute an AWS Systems Manager Automation document to patch the systems every hour.","E":"Use Amazon CloudWatch Events scheduled events to schedule a patch window.","A":"Add the physical machines into AWS Systems Manager using Systems Manager Hybrid Activations."},"question_id":154,"isMC":true,"discussion":[{"timestamp":"1636261200.0","content":"I'll go with A,B,F","comment_id":"224515","poster":"jackdryan","upvote_count":"15"},{"timestamp":"1725605220.0","content":"A B F are my answers","poster":"[Removed]","upvote_count":"9","comment_id":"1279419"},{"upvote_count":"1","comment_id":"883804","content":"Selected Answer: ABF\nABF for this one","poster":"DWsk","timestamp":"1682704740.0"},{"comment_id":"755423","content":"A,B and F is the right answer","upvote_count":"1","poster":"Bulti","timestamp":"1671947280.0"},{"poster":"Bulti","comment_id":"727228","upvote_count":"1","timestamp":"1669432020.0","content":"A,B,F https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-managed-instance-activation.html"},{"upvote_count":"1","content":"While ABF is correct, where is Patch Manager?","timestamp":"1644527040.0","poster":"blueorca","comment_id":"544877"},{"timestamp":"1635244620.0","content":"A B F are my answers","upvote_count":"2","comment_id":"209862","poster":"ChauPhan"},{"timestamp":"1634943720.0","comment_id":"201437","upvote_count":"2","content":"Answer: ABF\nC - no, the best practice is to use IAM roles\nD - no, you need a maintenance window\nE- no, you don't need CW in this scenario","poster":"kj07"},{"upvote_count":"4","comments":[{"timestamp":"1676315940.0","comment_id":"807739","upvote_count":"1","content":"unless it is already installed, amazon Linux 2 has it already.","poster":"[Removed]"}],"timestamp":"1634675940.0","poster":"halfway","comment_id":"163575","content":"ABF\nB is required by SSM agent to perform patch actions"},{"upvote_count":"2","timestamp":"1633056900.0","comment_id":"155553","poster":"jxp09","comments":[{"poster":"jxp09","timestamp":"1633633020.0","content":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-managedinstances.html","upvote_count":"1","comment_id":"155554"}],"content":"my answer is FAB"}],"unix_timestamp":1597155540,"topic":"1","answer_description":"","answer":"ABF","answer_ET":"ABF","answer_images":[],"timestamp":"2020-08-11 16:19:00","url":"https://www.examtopics.com/discussions/amazon/view/28128-exam-aws-devops-engineer-professional-topic-1-question-5/","answers_community":["ABF (100%)"],"exam_id":35,"question_text":"A company runs an application with an Amazon EC2 and on-premises configuration. A DevOps Engineer needs to standardize patching across both environments. Company policy dictates that patching only happens during non-business hours.\nWhich combination of actions will meet these requirements? (Choose three.)","question_images":[]},{"id":"qAujiL7AI3HFDDarNWwp","exam_id":35,"answer_description":"","choices":{"A":"Activate the user-defined cost allocation tags in each AWS account.","C":"Define each line of business (LOB) in AWS Budgets. Assign the required tag to each resource.","E":"Use the budget report to find untagged resources. Assign the required tag to each resource.","D":"Scan all accounts with Tag Editor. Assign the required tag to each resource.","B":"Create and attach an SCP that requires a specific tag."},"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/80129-exam-aws-devops-engineer-professional-topic-1-question-50/","discussion":[{"timestamp":"1662317520.0","upvote_count":"15","comment_id":"659464","content":"Selected Answer: BD\nMight be B and D - SCP to prevent resources to be created without mandatory tags and Tag Editor to scan resources are not tagged.\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_tagging.html\n\nhttps://aws.amazon.com/about-aws/whats-new/2015/02/19/aws-console-tag-editor-now-supports-not-tagged-and-empty-value-resource-search/","poster":"ohcn"},{"timestamp":"1700839620.0","poster":"DucSiu","comment_id":"1079404","upvote_count":"1","content":"BD is my answer"},{"comment_id":"905383","upvote_count":"1","poster":"easytoo","content":"b-d-b-d-b-d-b-d-b-d-b-d-b-d","timestamp":"1684890300.0"},{"content":"Selected Answer: AC\nD is eliminated","poster":"Piccaso","comment_id":"800705","timestamp":"1675759380.0","upvote_count":"1"},{"poster":"Bulti","content":"Answer is B and D.","upvote_count":"1","comments":[{"timestamp":"1675534320.0","comment_id":"798240","content":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/custom-tags.html","upvote_count":"1","poster":"Bulti"}],"timestamp":"1673909880.0","comment_id":"778358"},{"timestamp":"1673246760.0","upvote_count":"3","comment_id":"770089","content":"Why not AB?","poster":"ddev3737"},{"comment_id":"753395","upvote_count":"1","poster":"luk3k0","timestamp":"1671720240.0","content":"Selected Answer: BD\nDB for sure"},{"content":"Answer is BD","comment_id":"753180","timestamp":"1671703980.0","poster":"Chinta","upvote_count":"1"},{"content":"Answer is CD","comment_id":"753178","timestamp":"1671703860.0","upvote_count":"1","poster":"Chinta"},{"poster":"MikeyJ","content":"Selected Answer: BD\nI agree with ohcn.","timestamp":"1663044480.0","comment_id":"667659","upvote_count":"2"}],"answers_community":["BD (95%)","5%"],"question_images":[],"question_text":"A company runs several applications across multiple AWS accounts in an organization in AWS Organizations. Some of the resources are not tagged properly and the company's finance team cannot determine which costs are associated with which applications. A DevOps engineer must remediate this issue and prevent this issue from happening in the future.\nWhich combination of actions should the DevOps engineer take to meet these requirements? (Choose two.)","answer_images":[],"topic":"1","unix_timestamp":1662317520,"answer":"BD","timestamp":"2022-09-04 20:52:00","question_id":155,"answer_ET":"BD"}],"exam":{"provider":"Amazon","numberOfQuestions":208,"isMCOnly":false,"name":"AWS DevOps Engineer Professional","isImplemented":true,"isBeta":false,"lastUpdated":"11 Apr 2025","id":35},"currentPage":31},"__N_SSP":true}