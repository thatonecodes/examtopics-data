{"pageProps":{"questions":[{"id":"CYZgEZrUQ3psg6EkPxq7","choices":{"A":"Organize common and environmental-specific parameters hierarchically in the AWS Systems Manager Parameter Store, then reference the parameters dynamically from an AWS CloudFormation template. Deploy the CloudFormation stack using the environment name as a parameter.","D":"Create an AWS Lambda function that builds the required objects using an AWS SDK. Set the required parameter values in a test event in the Lambda console for each environment that the Application team can modify, as needed. Deploy the infrastructure by triggering the test event in the console.","B":"Create a parameterized AWS CloudFormation template that builds the required objects. Keep separate environment parameter files in separate Amazon S3 buckets. Provide an AWS CLI command that deploys the CloudFormation stack directly referencing the appropriate parameter bucket.","C":"Create a parameterized AWS CloudFormation template that builds the required objects. Import the template into the CloudFormation interface in the AWS Management Console. Make the required changes to the parameters and deploy the CloudFormation stack."},"isMC":true,"answer_images":[],"exam_id":22,"question_id":306,"answer_ET":"A","unix_timestamp":1594416060,"discussion":[{"comments":[{"poster":"BillyMadison","comment_id":"141257","content":"Is it A based off this? \nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html","upvote_count":"3","timestamp":"1633367220.0"},{"timestamp":"1633990680.0","upvote_count":"5","comment_id":"145297","content":"A is correct\nhttps://aws.amazon.com/blogs/mt/integrating-aws-cloudformation-with-aws-systems-manager-parameter-store/","poster":"pan24"}],"upvote_count":"10","comment_id":"131756","timestamp":"1632567720.0","poster":"chicagomassageseeker","content":"A. AWS Systems Manager Parameter Store"},{"comment_id":"1157773","upvote_count":"1","content":"C is also possible. However, A is better than C.","poster":"kyo","timestamp":"1708769040.0"},{"upvote_count":"1","timestamp":"1696369620.0","content":"The answer is A","comment_id":"1024248","poster":"SuriSagar"},{"timestamp":"1671479160.0","upvote_count":"3","poster":"lollyj","comment_id":"750201","content":"Selected Answer: A\nParameter store to separate the environments"},{"comment_id":"629531","upvote_count":"1","poster":"sachin","timestamp":"1657450860.0","content":"Mapping should have been the right approach for handing environment and it related setting but that option is not there.. \nWe can still achieve setting as using parameters. \nA"},{"content":"Selected Answer: A\nA. Organize common and environmental-specific parameters hierarchically in the AWS Systems Manager Parameter Store, then reference the parameters dynamically from an AWS CloudFormation template. Deploy the CloudFormation stack using the environment name as a parameter.","upvote_count":"3","comment_id":"595641","timestamp":"1651418880.0","poster":"novice_expert"},{"upvote_count":"2","content":"The only reasonable answer is A","poster":"LMax","comment_id":"314936","timestamp":"1636183860.0"},{"comment_id":"298669","content":"Ans: A","poster":"myutran","timestamp":"1636099140.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1636068420.0","comment_id":"253267","poster":"JobinAkaJoe","content":"Not sure. I will go with A"},{"content":"I would select A","timestamp":"1635017340.0","upvote_count":"2","poster":"Ashoks","comment_id":"212412"},{"poster":"Manmohan","upvote_count":"2","timestamp":"1634868360.0","comment_id":"210971","content":"I will go with B"},{"comment_id":"168257","timestamp":"1634731620.0","upvote_count":"1","content":"For me is C or B because on DynamoDB probably i need different configuration (for example RCU and WCU) between Dev and Prod environment. Probably i choose C because CLI not support parameters on S3 but only the body template.","poster":"AWSCert2020"},{"timestamp":"1634353080.0","content":"A is correct","upvote_count":"2","poster":"BillyC","comment_id":"145820"}],"answer":"A","answers_community":["A (100%)"],"answer_description":"","timestamp":"2020-07-10 23:21:00","question_images":[],"question_text":"A Database Specialist is creating Amazon DynamoDB tables, Amazon CloudWatch alarms, and associated infrastructure for an Application team using a development AWS account. The team wants a deployment method that will standardize the core solution components while managing environment-specific settings separately, and wants to minimize rework due to configuration errors.\nWhich process should the Database Specialist recommend to meet these requirements?","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/25382-exam-aws-certified-database-specialty-topic-1-question-50/"},{"id":"AG7tv8NgwvqRjVTKYOhR","answer_images":[],"question_text":"A company runs online transaction processing (OLTP) workloads on an Amazon RDS for PostgreSQL Multi-AZ DB instance. Tests were run on the database after work hours, which generated additional database logs. The free storage of the RDS DB instance is low due to these additional logs.\nWhat should the company do to address this space constraint issue?","discussion":[{"upvote_count":"7","poster":"BillyMadison","comments":[{"poster":"trietnv","comment_id":"620792","upvote_count":"1","content":"Reason: DB logs (error files) that are retained for too long.\nBecause by default, PostgreSQL error log files have a retention value of 4,320 minutes (three days). Large log files can use more space because of higher workloads. You can change the retention period for system logs using the rds.log_retention_period parameter in the DB parameter group associated with your DB instance. For example, if you set the value to 1440, then logs are retained for one day\nRef: https://aws.amazon.com/premiumsupport/knowledge-center/diskfull-error-rds-postgresql/","timestamp":"1655963520.0"}],"content":"I cant find anything for the other answers, so I'm going with B based off \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_LogAccess.Concepts.PostgreSQL.html\n\"To set the retention period for system logs, use the rds.log_retention_period parameter. You can find rds.log_retention_period in the DB parameter group associated with your DB instance. The unit for this parameter is minutes. For example, a setting of 1,440 retains logs for one day. The default value is 4,320 (three days).\"\n\"If storage gets too low, Aurora might delete compressed PostgreSQL logs before the retention period expires. If logs are deleted early, you get a message like the following.\nThe oldest PostgreSQL log files were deleted due to local storage constraints.\"","comment_id":"141266","timestamp":"1632834540.0"},{"timestamp":"1687592940.0","poster":"adelcold","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Concepts.PostgreSQL.html","upvote_count":"1","comment_id":"932324"},{"comments":[{"content":"There is no function named rds_rotate_error_log(). It is just a distractor. Check this link:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Concepts.PostgreSQL.html","comment_id":"1082084","upvote_count":"1","poster":"jitesh_k","timestamp":"1701140340.0"}],"timestamp":"1679481420.0","content":"In this scenario, the company is facing a low storage issue due to additional logs. To address this issue, they can rotate the logs to free up storage space using the stored procedure rds_rotate_error_log(). This procedure rotates the current log file and starts a new one. The rotated logs are compressed and stored in the log directory, freeing up space in the main storage.\n\nOption A is incorrect because removing log files manually is not recommended, as it may cause issues and loss of data.\n\nOption B is incorrect because changing the log retention period will not delete the existing logs immediately, and the company needs to wait for up to 24 hours for the logs to be deleted.\n\nOption C is incorrect because AWS support does not provide log deletion services.","poster":"redman50","upvote_count":"3","comment_id":"846937"},{"upvote_count":"1","poster":"SachinGoel","timestamp":"1665465660.0","comment_id":"691765","content":"Selected Answer: B\nB is correct"},{"comment_id":"594494","content":"Selected Answer: B\nreduce rds.log_retention_period parameter and wait","upvote_count":"2","timestamp":"1651239180.0","poster":"novice_expert"},{"content":"Selected Answer: B\ncorrect","comment_id":"554945","poster":"tugboat","timestamp":"1645659360.0","upvote_count":"1"},{"content":"B is correct Answer.\n\nTo set the retention period for system logs, use the rds.log_retention_period parameter. You can find rds.log_retention_period in the DB parameter group associated with your DB instance. The unit for this parameter is minutes. For example, a setting of 1,440 retains logs for one day. The default value is 4,320 (three days). The maximum value is 10,080 (seven days).","upvote_count":"3","poster":"AmitB","comment_id":"515709","timestamp":"1641213900.0"},{"poster":"guru_ji","content":"B is Correct.\n==> Anyone planning for exam?\nWe can share study material with each other, it would be beneficial for both. You can email me on \"awsdbguru at gmail\"","upvote_count":"3","comment_id":"434025","timestamp":"1635789480.0"},{"content":"Correct Answer is ==>> B\nany idea how much Q we will get in real exam from Q available here?\nanyone is preparing for this exam and want to do group study with us, comment with mail_id.","comment_id":"428746","poster":"guru_ji","timestamp":"1635717720.0","upvote_count":"2"},{"poster":"LMax","content":"My choice is B","timestamp":"1635336420.0","upvote_count":"2","comment_id":"317526"},{"content":"B here\nThe SELECT rds_rotate_error_log() does not exist on RDS","timestamp":"1634637540.0","poster":"AWSCert2020","upvote_count":"2","comment_id":"168260"},{"poster":"BillyC","content":"B is correct","timestamp":"1633446480.0","comment_id":"145822","upvote_count":"3"}],"question_images":[],"answer_description":"","timestamp":"2020-07-22 18:33:00","unix_timestamp":1595435580,"topic":"1","isMC":true,"exam_id":22,"choices":{"A":"Log in to the host and run the rm $PGDATA/pg_logs/* command","C":"Create a ticket with AWS Support to have the logs deleted","B":"Modify the rds.log_retention_period parameter to 1440 and wait up to 24 hours for database logs to be deleted","D":"Run the SELECT rds_rotate_error_log() stored procedure to rotate the logs"},"question_id":307,"answer_ET":"B","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/26423-exam-aws-certified-database-specialty-topic-1-question-51/","answer":"B"},{"id":"jZttGoyAyolQhZXEbcwL","unix_timestamp":1639135500,"url":"https://www.examtopics.com/discussions/amazon/view/67549-exam-aws-certified-database-specialty-topic-1-question-52/","choices":{"B":"Create an Amazon DocumentDB cluster","C":"Create an Amazon DynamoDB table with on-demand capacity mode","D":"Create an Amazon Aurora Serverless DB cluster","A":"Create an Amazon DynamoDB table with provisioned capacity mode"},"timestamp":"2021-12-10 12:25:00","question_text":"A user has a non-relational key-value database. The user is looking for a fully managed AWS service that will offload the administrative burdens of operating and scaling distributed databases. The solution must be cost-effective and able to handle unpredictable application traffic.\nWhat should a Database Specialist recommend for this user?","discussion":[{"comment_id":"509858","timestamp":"1640556000.0","content":"Selected Answer: C\nKey-value database -> DynamoDB\nCapable of dealing with unexpected application traffic -> on-demand capacity mode","upvote_count":"6","poster":"jove"},{"upvote_count":"1","timestamp":"1693478520.0","poster":"Pranava_GCP","comment_id":"995020","content":"Selected Answer: C\nC. Create an Amazon DynamoDB table with on-demand capacity mode\n\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.OnDemand"},{"comment_id":"912044","content":"Selected Answer: A\n\"With provisioned capacity you can also use auto scaling to automatically adjust your table’s capacity based on the specified utilization rate to ensure application performance, and also to potentially reduce costs. To configure auto scaling in DynamoDB, set the minimum and maximum levels of read and write capacity in addition to the target utilization percentage.\"\n\nhttps://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/capacity.html","poster":"aviathor","comments":[{"upvote_count":"1","timestamp":"1692346560.0","comment_id":"984281","poster":"ajndcjeandca","content":"If auto scaling was mentioned in the option then that would’ve been the most cost effective solution but since it is not mentioned C seems to be more appropriate"}],"upvote_count":"1","timestamp":"1685620680.0"},{"poster":"novice_expert","content":"Selected Answer: C\nC. Create an Amazon DynamoDB table with on-demand capacity mode","comment_id":"595228","timestamp":"1651346460.0","upvote_count":"1"},{"timestamp":"1639135500.0","upvote_count":"2","comment_id":"498556","poster":"2025flakyt","content":"C is the answer\nA key-value database is a type of nonrelational database that uses a simple key-value method to store data. A key-value database stores data as a collection of key-value pairs in which a key serves as a unique identifier.\nOn-demand mode is a good option to create new tables with unknown workloads.\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.OnDemand"}],"isMC":true,"answer_images":[],"answer_description":"","question_id":308,"answers_community":["C (89%)","11%"],"answer":"C","question_images":[],"answer_ET":"C","exam_id":22,"topic":"1"},{"id":"NuFGOeE45O9d06zDdOyR","topic":"1","question_id":309,"answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/65859-exam-aws-certified-database-specialty-topic-1-question-53/","question_text":"A gaming company is designing a mobile gaming app that will be accessed by many users across the globe. The company wants to have replication and full support for multi-master writes. The company also wants to ensure low latency and consistent performance for app users.\nWhich solution meets these requirements?","unix_timestamp":1636670940,"exam_id":22,"answers_community":["A (100%)"],"question_images":[],"answer_ET":"A","discussion":[{"comments":[{"comment_id":"995050","poster":"Pranava_GCP","upvote_count":"1","content":"https://aws.amazon.com/dynamodb/global-tables/","timestamp":"1693481040.0"}],"poster":"Pranava_GCP","timestamp":"1693480500.0","comment_id":"995048","upvote_count":"2","content":"Selected Answer: A\nA. Use Amazon DynamoDB global tables for storage and enable DynamoDB automatic scaling"},{"poster":"novice_expert","upvote_count":"3","comment_id":"594679","timestamp":"1651262400.0","content":"Selected Answer: A\nDynamoDB global tables have read and write in all regions, so these are kind of multi master like Aurora Multi Master\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_HowItWorks.html"},{"upvote_count":"1","poster":"jove","timestamp":"1640041200.0","comment_id":"505725","content":"Option A"},{"comment_id":"487357","poster":"GMartinelli","upvote_count":"1","content":"Selected Answer: A\nOption A. I was looking for Aurora Multi-Master or DynamoDB Global Tables, there is only one of them.","timestamp":"1637930880.0"},{"comment_id":"476545","poster":"leunamE","timestamp":"1636670940.0","content":"Option A. worldwide, multi-master writes, minimal latency","upvote_count":"1"}],"isMC":true,"answer":"A","timestamp":"2021-11-11 23:49:00","choices":{"D":"Use Amazon Neptune for storage","B":"Use Amazon Aurora for storage and enable cross-Region Aurora Replicas","A":"Use Amazon DynamoDB global tables for storage and enable DynamoDB automatic scaling","C":"Use Amazon Aurora for storage and cache the user content with Amazon ElastiCache"}},{"id":"b9lcUpcYWw0hL5Psu2ig","isMC":true,"answer_description":"","unix_timestamp":1594274040,"answers_community":["A (100%)"],"question_images":[],"answer_images":[],"question_text":"A Database Specialist needs to speed up any failover that might occur on an Amazon Aurora PostgreSQL DB cluster. The Aurora DB cluster currently includes the primary instance and three Aurora Replicas.\nHow can the Database Specialist ensure that failovers occur with the least amount of downtime for the application?","answer":"A","topic":"1","timestamp":"2020-07-09 07:54:00","exam_id":22,"url":"https://www.examtopics.com/discussions/amazon/view/25201-exam-aws-certified-database-specialty-topic-1-question-54/","discussion":[{"upvote_count":"13","content":"Ans: A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.BestPractices.html#AuroraPostgreSQL.BestPractices.FastFailover.TCPKeepalives","timestamp":"1632394860.0","comment_id":"130372","poster":"pan24","comments":[{"poster":"gelsm","timestamp":"1634528640.0","content":"A\n\"Enabling TCP keepalive parameters and setting them aggressively ensures that if your client is no longer able to connect to the database, then any active connections are quickly closed. This action allows the application to react appropriately, such as by picking a new host to connect to.\"","upvote_count":"3","comments":[{"content":"Correct Answer: A","poster":"guru_ji","timestamp":"1634529180.0","comment_id":"438540","upvote_count":"2"}],"comment_id":"414432"}]},{"comment_id":"932330","timestamp":"1687593600.0","poster":"adelcold","upvote_count":"3","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.BestPractices.FastFailover.html"},{"comment_id":"595571","timestamp":"1651404720.0","poster":"novice_expert","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.BestPractices.html#AuroraPostgreSQL.BestPractices.FastFailover.TCPKeepalives\n\nYou need to set the following TCP keepalive parameters:\n\ntcp_keepalive_time controls the time, in seconds, after which a keepalive packet is sent when no data has been sent by the socket (ACKs are not considered data). We recommend the following setting:\n\ntcp_keepalive_time = 1\n\ntcp_keepalive_intvl controls the time, in seconds, between sending subsequent keepalive packets after the initial packet is sent (set using the tcp_keepalive_time parameter). We recommend the following setting:\n\ntcp_keepalive_intvl = 1\n\ntcp_keepalive_probes is the number of unacknowledged keepalive probes that occur before the application is notified. We recommend the following setting:\n\ntcp_keepalive_probes = 5\n\nThese settings should notify the application within five seconds when the database stops responding.","upvote_count":"4"},{"timestamp":"1635243540.0","comment_id":"438541","poster":"guru_ji","upvote_count":"1","content":"Correct Answer: A"},{"content":"Answer A","poster":"LMax","timestamp":"1634514780.0","upvote_count":"2","comment_id":"314951"},{"timestamp":"1633180020.0","upvote_count":"1","comment_id":"298685","content":"Ans: A","poster":"myutran"},{"poster":"JobinAkaJoe","comment_id":"253282","timestamp":"1633154520.0","content":"Option A","upvote_count":"1"},{"comment_id":"212421","timestamp":"1633070640.0","poster":"Ashoks","content":"Yes. It is A","upvote_count":"2"},{"content":"A is correct","upvote_count":"1","comment_id":"145825","poster":"BillyC","timestamp":"1632607380.0"},{"upvote_count":"2","poster":"Mickysingh","comment_id":"134916","timestamp":"1632593160.0","content":"Ans A because we can reduce it by keeping low value of TCP among other parameter."},{"timestamp":"1632572940.0","content":"Answer A","poster":"chicagomassageseeker","upvote_count":"1","comment_id":"131803"}],"question_id":310,"answer_ET":"A","choices":{"D":"Start a database activity stream on the DB cluster","A":"Set the TCP keepalive parameters low","B":"Call the AWS CLI failover-db-cluster command","C":"Enable Enhanced Monitoring on the DB cluster"}}],"exam":{"name":"AWS Certified Database - Specialty","id":22,"isImplemented":true,"isMCOnly":false,"numberOfQuestions":359,"lastUpdated":"11 Apr 2025","isBeta":false,"provider":"Amazon"},"currentPage":62},"__N_SSP":true}