{"pageProps":{"questions":[{"id":"WbfucGxj2GUnHcpwU0jI","choices":{"B":"Include a policy statement for the data scientist's IAM user that allows the IAM user to perform the sagemaker:InvokeEndpoint action.","F":"Perform a user remapping in SageMaker to map the IAM user to another IAM user that is on the hosted endpoint.","E":"Include the SQL statement \"USING EXTERNAL FUNCTION ml_function_name'' in the Athena SQL query.","D":"Include a policy statement for the data scientist’s IAM user that allows the IAM user to perform the sagemaker:GetRecord action.","C":"Include an inline policy for the data scientist’s IAM user that allows SageMaker to read S3 objects.","A":"Attach the AmazonAthenaFullAccess AWS managed policy to the user identity."},"answer_ET":"BCE","url":"https://www.examtopics.com/discussions/amazon/view/133250-exam-aws-certified-machine-learning-specialty-topic-1/","question_id":216,"answer_description":"","answer_images":[],"unix_timestamp":1707297900,"timestamp":"2024-02-07 10:25:00","isMC":true,"question_images":[],"topic":"1","discussion":[{"poster":"Certified101","upvote_count":"1","timestamp":"1740657060.0","content":"Selected Answer: ABE\nWhy on earth would you \"update data scientist’s IAM USER that allows SageMaker to read S3 objects\" - you cant update an IAM user to give a service access to another service?\n\nIf this said \"Sagemaker IAM role to access S3\" then i would undertsand, but it doesnt say that.\n\nAt the same time, giving AthenaFullAccess is not best practise and not least privalage. ill go with ABE","comment_id":"1362502"},{"poster":"MultiCloudIronMan","content":"Selected Answer: ABC\n(Option B). This is essential for invoking the endpoint1.\n (Option C). This ensures that the model can access the necessary data stored in S32.\nOption A). This grants the necessary permissions to query datasets using Athena","comment_id":"1288739","upvote_count":"1","timestamp":"1727203320.0"},{"poster":"vkbajoria","upvote_count":"1","timestamp":"1712964360.0","content":"Selected Answer: BCE\ndata scientist already was querying the athena plus invoking sagemaker endpoint issue would not solve. therefore, A is not a good choice","comment_id":"1194579"},{"content":"Selected Answer: BCE\nA: NO - not needed as user already has Athena access (he is already querying Athena by SQL)\nB: Yes - sagemaker:InvokeEndpoint permission is needed to invoke endpoint\nC: Yes - needed for IAM user context to read S3 bucket\nD: No - sagemaker:GetRecord has no relevance in this question\nE: Yes - used to call an external function, in this case, the ML function deployed on the SageMaker endpoint, within the Athena SQL query\nF: No - irrelevant","upvote_count":"3","timestamp":"1709839860.0","poster":"AIWave","comment_id":"1168312"},{"upvote_count":"2","poster":"rav009","comment_id":"1155331","timestamp":"1708499400.0","content":"Selected Answer: ABE\nABE\nC is wrong. Why sagemaker need access S3? Sagemaker receive data and request via the endpoint."},{"poster":"Untamables","comment_id":"1147172","upvote_count":"2","content":"Selected Answer: ABE\nhttps://docs.aws.amazon.com/athena/latest/ug/querying-mlmodel.html\nhttps://docs.aws.amazon.com/athena/latest/ug/machine-learning-iam-access.html","timestamp":"1707649560.0"},{"poster":"kyuhuck","upvote_count":"2","content":"Selected Answer: BCE\nThe correct combination of actions to enable the data scientist's IAM user to invoke the SageMaker\nendpoint is B, C, and E, because they ensure that the IAM user has the necessary permissions, access,\nand syntax to query the ML model from Athena. These actions have the following benefits:\nB: Including a policy statement for the IAM user that allows the sagemaker:InvokeEndpoint action\ngrants the IAM user the permission to call the SageMaker Runtime InvokeEndpoint API, which is used\nto get inferences from the model hosted at the endpoint1.","comment_id":"1143102","timestamp":"1707297900.0"}],"answers_community":["BCE (50%)","ABE (42%)","8%"],"question_text":"A data scientist stores financial datasets in Amazon S3. The data scientist uses Amazon Athena to query the datasets by using SQL.\n\nThe data scientist uses Amazon SageMaker to deploy a machine learning (ML) model. The data scientist wants to obtain inferences from the model at the SageMaker endpoint. However, when the data scientist attempts to invoke the SageMaker endpoint, the data scientist receives SQL statement failures. The data scientist’s IAM user is currently unable to invoke the SageMaker endpoint.\n\nWhich combination of actions will give the data scientist’s IAM user the ability to invoke the SageMaker endpoint? (Choose three.)","answer":"BCE","exam_id":26},{"id":"Z1b0q4KJIzCvG1Fpq6LR","question_text":"A data scientist is building a linear regression model. The scientist inspects the dataset and notices that the mode of the distribution is lower than the median, and the median is lower than the mean.\n\nWhich data transformation will give the data scientist the ability to apply a linear regression model?","timestamp":"2024-02-07 11:13:00","question_id":217,"exam_id":26,"answer_ET":"B","answer_images":[],"question_images":[],"isMC":true,"choices":{"D":"Sinusoidal transformation","C":"Polynomial transformation","B":"Logarithmic transformation","A":"Exponential transformation"},"unix_timestamp":1707300780,"answers_community":["B (100%)"],"answer_description":"","topic":"1","discussion":[{"timestamp":"1727203440.0","comment_id":"1288740","content":"Selected Answer: B\nThe distribution described (mode < median < mean) indicates a positively skewed distribution. To normalize such data and make it more suitable for linear regression, a logarithmic transformation is often used. This transformation can help stabilize variance and make the data more normally distributed.","poster":"MultiCloudIronMan","upvote_count":"1"},{"comment_id":"1162512","poster":"Stokvisss","content":"Selected Answer: B\nThe fact that the mode is lower than the median, and the median is lower than the mean, suggests that the data is positively skewed (i.e., has a long right tail). In such cases, a logarithmic transformation is often used to reduce skewness and make the data more symmetric. Therefore, the correct answer is B. Logarithmic transformation.","upvote_count":"3","timestamp":"1709208720.0"},{"upvote_count":"2","timestamp":"1707300780.0","content":"Selected Answer: B\nExplanation:\nA logarithmic transformation is a suitable data transformation for a linear regression model when the\ndata has a skewed distribution, such as when the mode is lower than the median and the median is\nlower than the mean. A logarithmic transformation can reduce the skewness and make the data\nmore symmetric and normally distributed, which are desirable properties for linear regression. A\nlogarithmic transformation can also reduce the effect of outliers and heteroscedasticity (unequal\nvariance) in the data. An exponential transformation would have the opposite effect of increasing the\nskewness and making the data more asymmetric. A polynomial transformation may not be able to\ncapture the nonlinearity in the data and may introduce multicollinearity among the transformed\nvariables. A sinusoidal transformation is not appropriate for data that does not have a periodic","poster":"kyuhuck","comment_id":"1143213"}],"url":"https://www.examtopics.com/discussions/amazon/view/133253-exam-aws-certified-machine-learning-specialty-topic-1/","answer":"B"},{"id":"oSQSU89bsJKbviXK1Smc","question_id":218,"timestamp":"2024-02-07 10:18:00","unix_timestamp":1707297480,"answer_images":[],"discussion":[{"content":"Selected Answer: C\nD is the better answer, except for the part that says \"for all other outcome categories\". It should say, \"for all outcome categories\" including the ones we categorized with partial information. Because of this flaw, i go C.","comment_id":"1399432","timestamp":"1742163900.0","upvote_count":"1","poster":"2eb8df0"},{"upvote_count":"1","poster":"CW0106","content":"Selected Answer: D\nShould be D","comment_id":"1283060","timestamp":"1726213560.0"},{"comment_id":"1206896","timestamp":"1714913580.0","content":"Selected Answer: D\nFor the outcome categories with partial information (3 or 4 out of 200 categories), supervised learning can be used to classify claims into those categories based on the available claim contents.\nFor the remaining outcome categories without partial information, forecasting techniques using claim IDs and dates can be employed to predict the expected number of claims in each category every month.","poster":"Peter_Hsieh","upvote_count":"2"},{"comment_id":"1203531","content":"While the argument for option C is valid in terms of using claim IDs and dates for forecasting, it does not address the scenario where partial information on claim contents is available for some outcome categories. By ignoring this information, option C may miss an opportunity to improve the accuracy of predictions for those categories through classification techniques.\n\nFurthermore, various machine learning resources and best practices recommend combining different techniques, such as classification and forecasting, when dealing with complex datasets that contain both structured and unstructured data. This hybrid approach can often lead to more accurate and robust solutions.","timestamp":"1714302840.0","upvote_count":"1","poster":"F1Fan"},{"poster":"AIWave","upvote_count":"2","comment_id":"1168356","timestamp":"1709845380.0","content":"Selected Answer: C\nA: No - not a classification problem\nB: No - Reinforcement learning does not apply to the situation - adding positive reinforcement/negative penalty to train the system does not apply\nC: Yes - leverages historical data (claim IDs and dates from the previous 3 years) to forecast future claim counts\nD: Not a classification problem\nC:"},{"comment_id":"1165235","timestamp":"1709518020.0","upvote_count":"2","content":"Selected Answer: C\nthis is forecasting problem","poster":"vkbajoria"},{"poster":"kyuhuck","timestamp":"1707297480.0","comment_id":"1143092","upvote_count":"2","content":"Selected Answer: C\nC directly addresses the need to forecast the number of claims in each outcome category on a monthly basis, leveraging historical data patterns without the need for classifying individual claim records based on their content."}],"question_images":[],"answer":"C","answers_community":["C (70%)","D (30%)"],"choices":{"B":"Perform reinforcement learning by using claim IDs and dates. Instruct the insurance agents who submit the claim records to estimate the expected number of claims in each outcome category every month.","D":"Perform classification by using supervised learning of the outcome categories for which partial information on claim contents is provided. Perform forecasting by using claim IDs and dates for all other outcome categories.","A":"Perform classification every month by using supervised learning of the 200 outcome categories based on claim contents.","C":"Perform forecasting by using claim IDs and dates to identify the expected number of claims in each outcome category every month."},"topic":"1","question_text":"A data scientist receives a collection of insurance claim records. Each record includes a claim ID. the final outcome of the insurance claim, and the date of the final outcome.\n\nThe final outcome of each claim is a selection from among 200 outcome categories. Some claim records include only partial information. However, incomplete claim records include only 3 or 4 outcome categories from among the 200 available outcome categories. The collection includes hundreds of records for each outcome category. The records are from the previous 3 years.\n\nThe data scientist must create a solution to predict the number of claims that will be in each outcome category every month, several months in advance.\n\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/133248-exam-aws-certified-machine-learning-specialty-topic-1/","isMC":true,"exam_id":26,"answer_description":"","answer_ET":"C"},{"id":"kwJvRL10dsOCUshCSEBC","discussion":[{"timestamp":"1725736560.0","poster":"AIWave","comment_id":"1168363","content":"Selected Answer: BDF\nA: No - Athena queries require much more operational overhead\nB: Yes - Glue crawlers are made to discover schema\nC: No - redshift high setup and operational overhead\nD: Yes - Glue workflows and jobs are made for this\nE: No - redshift high setup and operational overhead\nF: Yes - Amazon fraud detector is designed for this","upvote_count":"3"},{"timestamp":"1725736500.0","poster":"AIWave","upvote_count":"1","content":"A: No - Athena queries require much more operational overhead\nB: Yes - Glue crawlers are made to discover schema\nC: No - redshift high setup and operational overhead\nD: Yes - Glue workflows and jobs are made for this\nE: No - redshift high setup and operational overhead\nF: Amazon fraud detector is designed for this","comment_id":"1168362"},{"comment_id":"1162518","timestamp":"1724926620.0","upvote_count":"1","poster":"Stokvisss","content":"Selected Answer: BDF\nB, D and F combined bring a serverless solution with the least operational overhead."},{"content":"Selected Answer: BDF\nI go with B, D, and F","upvote_count":"1","timestamp":"1724755680.0","poster":"Adzz","comment_id":"1160592"},{"content":"Selected Answer: BDF\nNo need to use Redshift. Serverless solution is with least operational effort.","comment_id":"1155341","poster":"rav009","timestamp":"1724218560.0","upvote_count":"1"}],"exam_id":26,"question_id":219,"question_images":[],"answer_description":"","choices":{"A":"Use Amazon Athena to scan the data and identify the schema.","E":"Use Amazon Redshift ML to train a model to detect fraud.","D":"Use AWS Glue workflows and AWS Glue jobs to perform data transformations.","F":"Use Amazon Fraud Detector to train a model to detect fraud.","B":"Use AWS Glue crawlers to scan the data and identify the schema.","C":"Use Amazon Redshift to store procedures to perform data transformations."},"answer_ET":"BDF","isMC":true,"answer_images":[],"question_text":"A retail company stores 100 GB of daily transactional data in Amazon S3 at periodic intervals. The company wants to identify the schema of the transactional data. The company also wants to perform transformations on the transactional data that is in Amazon S3.\n\nThe company wants to use a machine learning (ML) approach to detect fraud in the transformed data.\n\nWhich combination of solutions will meet these requirements with the LEAST operational overhead? (Choose three.)","answers_community":["BDF (100%)"],"timestamp":"2024-02-21 08:36:00","answer":"BDF","url":"https://www.examtopics.com/discussions/amazon/view/134301-exam-aws-certified-machine-learning-specialty-topic-1/","unix_timestamp":1708500960,"topic":"1"},{"id":"hmEomLGIu6uZBXq0eKqa","answer_images":[],"discussion":[{"content":"Selected Answer: D\nEventBridge provide least development effort because we can just configure and trigger based on dataset drops in S3.\n\nLambda will require some development effort","upvote_count":"2","poster":"vkbajoria","comment_id":"1186733","timestamp":"1727694960.0"},{"comment_id":"1168369","content":"Selected Answer: D\nD requires minimal effort as it involves configuring EventBridge to monitor the S3 bucket for new data uploads and automatically triggering the SageMaker pipeline to perform the transformations on the new data while leveraging native Eventbridge -> Pipeline integration.","timestamp":"1725737280.0","poster":"AIWave","upvote_count":"1"},{"comment_id":"1155342","upvote_count":"2","poster":"rav009","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/automating-sagemaker-with-eventbridge.html","timestamp":"1724218980.0"},{"poster":"kyuhuck","upvote_count":"4","timestamp":"1723025580.0","content":"Selected Answer: D\nAnswer: D\nExplanation:\nThe best solution is to configure Amazon EventBridge to run a predefined SageMaker pipeline to\nperform the transformations when a new data is detected in the S3 bucket. This solution requires the\nleast development effort because it leverages the native integration between EventBridge and\nSageMaker Pipelines, which allows you to trigger a pipeline execution based on an event rule.\nEventBridge can monitor the S3 bucket for new data uploads and invoke the pipeline that contains\nthe same transformations and feature engineering steps that were defined in SageMaker Data\nWrangler. The pipeline can then ingest the transformed data into the online feature store for training\nand inference.","comment_id":"1143306"}],"topic":"1","question_text":"A data scientist uses Amazon SageMaker Data Wrangler to define and perform transformations and feature engineering on historical data. The data scientist saves the transformations to SageMaker Feature Store.\n\nThe historical data is periodically uploaded to an Amazon S3 bucket. The data scientist needs to transform the new historic data and add it to the online feature store. The data scientist needs to prepare the new historic data for training and inference by using native integrations.\n\nWhich solution will meet these requirements with the LEAST development effort?","question_images":[],"answer_ET":"D","timestamp":"2024-02-07 13:13:00","answer":"D","question_id":220,"url":"https://www.examtopics.com/discussions/amazon/view/133265-exam-aws-certified-machine-learning-specialty-topic-1/","choices":{"A":"Use AWS Lambda to run a predefined SageMaker pipeline to perform the transformations on each new dataset that arrives in the S3 bucket.","C":"Use Apache Airflow to orchestrate a set of predefined transformations on each new dataset that arrives in the S3 bucket.","B":"Run an AWS Step Functions step and a predefined SageMaker pipeline to perform the transformations on each new dataset that arrives in the S3 bucket.","D":"Configure Amazon EventBridge to run a predefined SageMaker pipeline to perform the transformations when a new data is detected in the S3 bucket."},"unix_timestamp":1707307980,"isMC":true,"exam_id":26,"answers_community":["D (100%)"],"answer_description":""}],"exam":{"isImplemented":true,"name":"AWS Certified Machine Learning - Specialty","isBeta":false,"isMCOnly":false,"numberOfQuestions":369,"lastUpdated":"11 Apr 2025","provider":"Amazon","id":26},"currentPage":44},"__N_SSP":true}