{"pageProps":{"questions":[{"id":"LxUb5KMTBdO3oIeH0DcG","discussion":[{"comment_id":"1558293","poster":"Srikantha","content":"Selected Answer: A\nAWS Config Managed Rule (CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK):\nThe CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK is a built-in AWS Config rule that automatically detects drift on resources managed by CloudFormation. Drift refers to manual changes made to CloudFormation-managed resources, and this rule identifies such changes.\nEventBridge Rule:\nYou can create an EventBridge rule that listens for NON_COMPLIANT events triggered by the AWS Config rule when drift is detected. This will ensure that whenever there are manual modifications on CloudFormation-managed resources, the event will be captured.\nSNS Notification:\nUsing Amazon SNS, you can set up an email notification for the DevOps lead whenever the event is triggered. Subscribing the DevOps lead to the SNS topic ensures that they are immediately notified without requiring manual intervention.","upvote_count":"1","timestamp":"1743952020.0"},{"timestamp":"1734366240.0","poster":"Ky_24","upvote_count":"3","content":"Selected Answer: A\nKey Requirements:\n\n 1. Detect manual modification of CloudFormation-managed resources.\n 2. Send an alert to the DevOps lead when such changes are detected.\n 3. Achieve this with minimal operational effort.","comment_id":"1327499"},{"content":"Selected Answer: A\nLeast operational overhead always will involve using AWS-Managed services instead of developing code, for example. So, A in my opinion.","comment_id":"1325019","poster":"luisfsm_111","upvote_count":"3","timestamp":"1733920380.0"},{"timestamp":"1732454340.0","comment_id":"1317050","content":"Selected Answer: A\nA is less complex by just using SNS for notifying, instead of creating a lambda function just to do that.","upvote_count":"3","poster":"Impromptu"},{"poster":"uncledana","comment_id":"1314553","timestamp":"1732011420.0","upvote_count":"1","content":"Selected Answer: D\nOption D is the most efficient and least operationally complex solution because it uses AWS Config’s drift detection rule, integrates with EventBridge for event handling, and leverages a Lambda function to send notifications. This approach directly addresses the need to detect manual changes in CloudFormation-managed resources and alert the DevOps lead."}],"question_images":[],"topic":"1","answer_description":"","answers_community":["A (91%)","9%"],"answer":"A","answer_images":[],"exam_id":23,"question_text":"A company is using AWS CloudFormation to perform deployments of its application environment. A deployment failed during a recent update to the existing CloudFormation stack. A DevOps engineer discovered that some resources in the stack were manually modified.\n\nThe DevOps engineer needs a solution that detects manual modification of resources and sends an alert to the DevOps lead.\n\nWhich solution will meet these requirements with the LEAST operational effort?","choices":{"A":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the DevOps lead to the topic by using an email address. Create an AWS Config managed rule that has the CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK identifier. Create an Amazon EventBridge rule that is invoked on the NON_COMPLIANT resources status. Set the SNS topic as the rule target.","C":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the DevOps lead to the topic by using an email address. Create an AWS Config managed rule that has the CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK identifier. Create an Amazon EventBridge rule that is invoked on the COMPLIANT resources status. Set the SNS topic as the rule target.","B":"Tag all CloudFormation resources with a specific tag. Create an AWS Config custom rule by using the AWS Config Rules Development Kit Library (RDKlib) that checks all resource changes that have the specific tag. Configure the custom rule to mark all the tagged resource changes as NON_COMPLIANT when the change is not performed by CloudFormation. Create an Amazon EventBridge rule that is invoked on the NON_COMPUANT resources status. Create an AWS Lambda function that sends an email message to the DevOps lead. Set the Lambda function as the rule target.","D":"Create an AWS Config managed rule that has the CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK identifier. Create an Amazon EventBridge rule that is invoked on the NON_COMPLIANT resources status. Create an AWS Lambda function that sends an email message to the DevOps lead. Set the Lambda function as the rule target."},"timestamp":"2024-11-19 11:17:00","isMC":true,"unix_timestamp":1732011420,"url":"https://www.examtopics.com/discussions/amazon/view/151623-exam-aws-certified-devops-engineer-professional-dop-c02/","question_id":276,"answer_ET":"A"},{"id":"cEDKFnDH259zPMtFMl0g","choices":{"C":"Create individual AWS CloudFormation templates that align to a guardrail. Store the templates in an AWS CodeCommit repository. Create an AWS::ControlTower::EnableControl logical resource in the template for each OU in the organization. Configure an AWS CodePipeline pipeline in the security team's account that an Amazon EventBridge rule will invoke for the security team's CodeCommit changes.","D":"Configure an AWS CodePipeline pipeline in the security team's account that an Amazon EventBridge rule will invoke for PutObject events to an Amazon S3 bucket. Create individual AWS CloudFormation templates that align to a guardrail. Store the templates in the S3 bucket. Create an AWS::ControlTower::EnableControl logical resource in the template for each OU in the organization.","A":"Create individual AWS CloudFormation templates that align to a guardrail. Store the templates in an AWS CodeCommit repository. Create an AWS::ControlTower::EnableControl logical resource in the template for each OU in the organization. Configure an AWS Code Build project that an Amazon EventBridge rule will invoke for the security team's AWS CodeCommit changes.","B":"Create individual AWS CloudFormation templates that align to a guardrail. Store the templates in an AWS CodeCommit repository. Create an AWS::ControlTower::EnableControl logical resource in the template for each account in the organization. Configure an AWS CodePipeline pipeline in the security team's account. Advise the security team to invoke the pipeline and provide these parameters when starting the pipeline."},"timestamp":"2024-11-19 11:22:00","answers_community":["C (83%)","D (17%)"],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/151624-exam-aws-certified-devops-engineer-professional-dop-c02/","question_text":"A DevOps engineer deployed multiple AWS accounts by using AWS Control Tower to support different business, technical, and administrative units in a company. A security team needs the DevOps engineer to automate AWS Control Tower guardrails for the company. The guardrails must be applied to all accounts in an OU of the company's organization in AWS Organizations.\n\nThe security team needs a solution that has version control and can be reviewed and rolled back if necessary. The security team will maintain the management of the solution in its OU. The security team wants to limit the type of guardrails that are allowed and allow only new guardrails that are approved by the security team.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","question_id":277,"answer":"C","answer_ET":"C","answer_images":[],"topic":"1","question_images":[],"answer_description":"","discussion":[{"comment_id":"1558294","content":"Selected Answer: C\nVersion control is managed easily with CodeCommit, and the changes to the guardrails can be reviewed and rolled back if necessary.\nApproval and governance are built into the process, with the security team controlling the changes and ensuring that only approved guardrails are applied.\nAutomation through CodePipeline and EventBridge ensures that the guardrails are applied to the correct OUs automatically, without the need for manual processes or additional operational overhead.\nThe solution is scalable as it can be applied to multiple OUs and accounts.","poster":"Srikantha","upvote_count":"1","timestamp":"1743952080.0"},{"content":"Selected Answer: D\nD is not right because solution should be like AWS CodePipeline pipeline must be invooked by security team commits. But in D, PutObject events to an Amazon S3 bucket is used to invoke CodePipeline.\nA is using AWS Code Build unnecesaarily on Amazon EventBridge rule. It does not say anything automated and involve manual efforts.\nB is completely manual steps mentioned in the line so can't be efficient.\n\nC is completely automated so its a right answer.","upvote_count":"1","comment_id":"1352956","poster":"c87b433","timestamp":"1738927020.0"},{"comment_id":"1314556","content":"Selected Answer: C\nOption C is the most efficient and scalable solution for automating AWS Control Tower guardrails while meeting the security team’s requirements for version control, approval, and rollback, with minimal operational overhead. It uses CodeCommit, CodePipeline, and EventBridge, leveraging the best AWS services for this purpose.","timestamp":"1732011720.0","upvote_count":"4","poster":"uncledana"}],"exam_id":23,"unix_timestamp":1732011720},{"id":"4QsQMz7aHspoWZTjyuEC","answer_ET":"A","answer_images":[],"question_images":[],"answers_community":["A (88%)","13%"],"discussion":[{"comment_id":"1558295","timestamp":"1743952200.0","upvote_count":"1","content":"Selected Answer: A\nOption A is the most efficient solution because it directly monitors blocked requests through a custom CloudWatch metric and uses CloudWatch anomaly detection to identify significant deviations, which is precisely what the company needs to monitor.","poster":"Srikantha"},{"poster":"CHRIS12722222","upvote_count":"3","content":"Selected Answer: A\nI go with option A\nif we want to detect SUDDEN change in blocked request, we cant do so in 1hr period as that would be too long a time and what if the blocked request normalised quickly within that 1hr. I think using anomaly detection will provide some upper and lower limit and free us from defining and tuning a static threshold","timestamp":"1735493400.0","comment_id":"1333643"},{"comment_id":"1333114","timestamp":"1735411980.0","poster":"Slays","upvote_count":"1","content":"Selected Answer: C\nUnc the question said: \"The company does not want to receive alerts for other changes in AWS WAF log behavior\"\n\nThey only want notifications when blocked traffic increase, so anomaly detection doesn't fit the requirements.\n\nGotta be C"},{"content":"Selected Answer: A\nOption A provides the most precise and scalable solution to meet the company’s requirements. It focuses on blocked requests, uses anomaly detection for adaptive monitoring, and provides alerting through SNS when a sudden change in blocked traffic occurs.","comments":[],"poster":"uncledana","timestamp":"1732011840.0","upvote_count":"3","comment_id":"1314558"}],"url":"https://www.examtopics.com/discussions/amazon/view/151626-exam-aws-certified-devops-engineer-professional-dop-c02/","question_id":278,"answer":"A","isMC":true,"unix_timestamp":1732011840,"timestamp":"2024-11-19 11:24:00","choices":{"B":"Create a CloudWatch anomaly detector for the log group. Create a CloudWatch alarm by using metrics that the CloudWatch anomaly detector publishes. Use the high setting for the LogAnomalyPriority metric. Configure the alarm to go into alarm state if a static threshold of one anomaly is detected. Configure the alarm to notify the SNS topic to alert the DevOps engineer.","D":"Create a CloudWatch anomaly detector for the log group. Create a CloudWatch alarm by using metrics that the CloudWatch anomaly detector publishes. Use the medium setting for the LogAnomalyPriority metric. Configure the alarm to go into alarm state if a sum of anomalies over 1 hour is greater than an expected value. Configure the alarm to notify the SNS topic to alert the DevOps engineer.","A":"Create a CloudWatch Logs metrics filter for blocked requests on the AWS WAF log group to create a custom metric. Create a CloudWatch alarm by using CloudWatch anomaly detection and the published custom metric. Configure the alarm to notify the SNS topic to alert the DevOps engineer.","C":"Create a CloudWatch metrics filter for counted requests on the AWS WAF log group to create a custom metric. Create a CloudWatch alarm that activates when the sum of blocked requests in the custom metric during a period of 1 hour is greater than a static estimate for the acceptable number of blocked requests in 1 hour. Configure the alarm to notify the SNS topic to alert the DevOps engineer."},"exam_id":23,"question_text":"A company runs a web application on Amazon Elastic Kubernetes Service (Amazon EKS). The company uses Amazon CloudFront to distribute the application. The company recently enabled AWS WAF. The company set up Amazon CloudWatch Logs to send logs to an aws-waf-logs log group.\n\nThe company wants a DevOps engineer to receive alerts if there are sudden changes in blocked traffic. The company does not want to receive alerts for other changes in AWS WAF log behavior. The company will tune AWS WAF rules over time.\n\nThe DevOps engineer is currently subscribed to an Amazon Simple Notification Service (Amazon SNS) topic in the environment.\n\nWhich solution will meet these requirements?","answer_description":"","topic":"1"},{"id":"9MXz55PinFdtq5uoqtTh","isMC":true,"timestamp":"2023-04-14 20:03:00","topic":"1","answer_ET":"A","question_text":"A company uses AWS Storage Gateway in file gateway mode in front of an Amazon S3 bucket that is used by multiple resources. In the morning when business begins, users do not see the objects processed by a third party the previous evening. When a DevOps engineer looks directly at the S3 bucket, the data is there, but it is missing in Storage Gateway.\nWhich solution ensures that all the updated third-party files are available in the morning?","answer_images":[],"answer":"A","answers_community":["A (97%)","3%"],"answer_description":"","unix_timestamp":1681495380,"exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/106199-exam-aws-certified-devops-engineer-professional-dop-c02/","choices":{"A":"Configure a nightly Amazon EventBridge event to invoke an AWS Lambda function to run the RefreshCache command for Storage Gateway.","D":"Use S3 Same-Region Replication to replicate any changes made directly in the S3 bucket to Storage Gateway.","B":"Instruct the third party to put data into the S3 bucket using AWS Transfer for SFTP.","C":"Modify Storage Gateway to run in volume gateway mode."},"question_id":279,"discussion":[{"poster":"tartarus23","content":"Selected Answer: A\nExplanation:\n\nAWS Storage Gateway's file gateway mode provides a bridge between your on-premises servers and Amazon S3. File gateway caches frequently accessed files in your on-premises environment to provide low-latency access. However, if the S3 bucket's data is modified by another service, the cache does not automatically refresh. Thus, to ensure all the updated third-party files are available in the morning, you can use an AWS Lambda function triggered by Amazon EventBridge to run the RefreshCache command for Storage Gateway. This will ensure the cache is updated with the latest changes.","comment_id":"927922","timestamp":"1703026140.0","upvote_count":"16"},{"poster":"ele","timestamp":"1697380440.0","comments":[{"upvote_count":"3","comment_id":"1071461","timestamp":"1715771460.0","poster":"robertohyena","content":"Thanks for this.\nAlso found https://repost.aws/knowledge-center/storage-gateway-automate-refreshcache\n\nStorage Gateway allows you to automate the RefreshCache operation based on a Time To Live (TTL) value. TTL is the length of time since the last refresh. When a user accesses the file directory after the TTL value, the file gateway refreshes the directory's contents from the S3 bucket. Valid TTL values for automating the RefreshCache operation range from 300 seconds to 2,592,000 seconds (5 minutes to 30 days)."}],"comment_id":"870992","content":"Selected Answer: A\nA: refresh cache: https://repost.aws/knowledge-center/storage-gateway-s3-changes-not-showing","upvote_count":"12"},{"upvote_count":"1","comment_id":"1221911","content":"Selected Answer: A\nRead and concede:\n\"Configure an automated cache refresh schedule using AWS Lambda with an Amazon CloudWatch rule\"\nhttps://docs.aws.amazon.com/filegateway/latest/files3/refresh-cache.html#auto-refresh-lambda-procedure","timestamp":"1732943520.0","poster":"Gomer"},{"poster":"bhond","content":"where is it saying files are written directly to s3 ?","comments":[{"comment_id":"1078695","timestamp":"1716484920.0","poster":"yorkicurke","upvote_count":"3","content":"You do make a point but if you read the phrase \" When a DevOps engineer looks directly at the S3 bucket \" it kinda implies besides you dont have any other better choice anyway. if you look at user \"ele\" comments and follow the link below it will get clear[hope that helps];\nhttps://repost.aws/knowledge-center/storage-gateway-s3-changes-not-showing"}],"upvote_count":"1","timestamp":"1708012740.0","comment_id":"981736"},{"timestamp":"1707822120.0","upvote_count":"1","content":"A is right.\nStorage Gateway updates the file share cache automatically when you write files to the cache\nlocally using the file share. However, Storage Gateway doesn't automatically update the cache\nwhen you upload a file directly to Amazon S3. When you do this, you must perform a\nRefreshCache operation to see the changes on the file share.","poster":"ixdb","comment_id":"979872"},{"comment_id":"924214","upvote_count":"1","poster":"madperro","content":"Selected Answer: A\nA is the answer.","timestamp":"1702653000.0"},{"timestamp":"1698897840.0","upvote_count":"2","poster":"haazybanj","content":"Selected Answer: A\nThe issue appears to be related to the Storage Gateway cache not being updated. To ensure that all the updated third-party files are available in the morning, you can use the RefreshCache API to manually refresh the cache or configure automatic cache refresh.\n\nOption A is a possible solution to configure automatic cache refresh, but it is not necessary to run the RefreshCache command every night if you can ensure that cache refresh occurs frequently enough to meet your requirements.","comment_id":"886962"},{"content":"Selected Answer: A\nA is correct","timestamp":"1697320560.0","comment_id":"870500","poster":"alce2020","upvote_count":"1"},{"poster":"jqso234","content":"Selected Answer: B\nOption B appears to be the correct choice. Configuring the third party to put data into the S3 bucket using AWS Transfer for SFTP would ensure that the data is immediately available in both the S3 bucket and Storage Gateway, avoiding any potential caching issues. Option A of configuring a nightly event to refresh the cache may not be an optimal solution as it could result in stale data being served during the day.","comment_id":"870387","upvote_count":"1","comments":[{"upvote_count":"1","content":"Transfer SFTP has the same effect in this case as adding files to S3 with PutObject. The cache in the storage gateway would not be updated, requiring the same refresh as in option A.","poster":"bcx","timestamp":"1701370560.0","comment_id":"910449"}],"timestamp":"1697306580.0"}],"question_images":[]},{"id":"UHE8zSjZkaL8yQL3nwQ4","timestamp":"2024-11-19 11:35:00","isMC":true,"question_text":"A video platform company is migrating its video catalog to AWS. The company will host MP4 videos files in an Amazon S3 bucket. The company will use Amazon CloudFront and Amazon EC2 instances to serve the video files.\n\nUsers first connect to a frontend application that redirects to a video URL. The video URL contains an authorization token in CloudFront. The cache is activated on the CloudFront distribution. Authorization token check activity needs to be logged in Amazon CloudWatch.\n\nThe company wants to prevent direct access to video files on CloudFront and Amazon S3 and wants to implement checks of the authorization token that the frontend application provides. The company also wants to perform regular rolling updates of the code that checks the authorization token signature.\n\nWhich solution will meet these requirements with the LEAST operational effort?","answer_ET":"B","topic":"1","answer_images":[],"answer":"B","answer_description":"","answers_community":["B (88%)","13%"],"exam_id":23,"unix_timestamp":1732012500,"url":"https://www.examtopics.com/discussions/amazon/view/151628-exam-aws-certified-devops-engineer-professional-dop-c02/","question_id":280,"choices":{"C":"Implement an authorization token check in the application code that is installed on the EC2 instances. Install the CloudWatch agent on the EC2 instances. Configure the application to log to the CloudWatch agent. Implement a second CloudFront distribution. Migrate the traffic from the first CloudFront distribution by using Amazon Route 53 weighted routing.","D":"Implement an authorization token check in CloudFront Functions. Enable CloudWatch logging for the CloudFront function. Attach the CloudFront function to the CloudFront distribution. Implement a second CloudFront distribution. Migrate the traffic from the first CloudFront distribution by using Amazon Route 53 weighted routing.","B":"Implement an authorization token check in CloudFront Functions. Enable CloudWatch logging for the CloudFront function. Attach the CloudFront function to the CloudFront distribution. Implement CloudFront continuous deployment to perform updates.","A":"Implement an authorization token check in Lambda@Edge as a trigger on the CloudFront distribution. Enable CloudWatch logging for the Lambda@Edge function. Attach the Lambda@Edge function to the CloudFront distribution. Implement CloudFront continuous deployment to perform updates."},"discussion":[{"upvote_count":"1","content":"Selected Answer: B\nOption B is the most efficient and operationally effective solution. It uses CloudFront Functions to check the authorization token directly at the edge, minimizing latency, and integrates seamlessly with CloudWatch for logging. Additionally, CloudFront continuous deployment simplifies updates, making it the optimal solution for the company’s requirements.","timestamp":"1743952380.0","poster":"Srikantha","comment_id":"1558296"},{"comment_id":"1334187","content":"Selected Answer: A\nOption A is correct. Here's why:\nLambda@Edge:\n\nPerfect for token authorization checks\nSupports CloudWatch logging\nCan handle complex validation logic\nBuilt for CloudFront integration\nRolling updates via continuous deployment","timestamp":"1735568820.0","upvote_count":"1","poster":"matt200"},{"upvote_count":"3","comment_id":"1316557","content":"Selected Answer: B\nCloudFront Functions is a lightweight JavaScript-based environment that runs at the edge and is designed for high performance with low latency. It's ideal for simple tasks like authorization checks.\nEnabling CloudWatch logging for CloudFront Functions ensures that the authorization token check activities are logged, providing visibility into the process.\n Implementing CloudFront continuous deployment simplifies the process of rolling updates for the function, ensuring that new code can be deployed quickly and seamlessly.","timestamp":"1732335000.0","poster":"f4b18ba"},{"content":"Selected Answer: B\nOption B provides the most efficient solution with the least operational overhead. It uses CloudFront Functions for token validation, enables CloudWatch logging, and supports continuous deployment for easy updates, meeting the company’s requirements in a scalable and cost-effective manner.","upvote_count":"3","poster":"uncledana","comment_id":"1314567","timestamp":"1732012500.0"}],"question_images":[]}],"exam":{"id":23,"isMCOnly":true,"isBeta":false,"lastUpdated":"11 Apr 2025","provider":"Amazon","numberOfQuestions":355,"name":"AWS Certified DevOps Engineer - Professional DOP-C02","isImplemented":true},"currentPage":56},"__N_SSP":true}