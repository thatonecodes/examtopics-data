{"pageProps":{"questions":[{"id":"wBIFXQcSee44mi5sx0WV","timestamp":"2022-11-24 16:48:00","isMC":true,"question_text":"A company is using AWS CodePipeline pipelines to deploy development Amazon EC2 instances for multiple teams. All the pipelines are using the same AWS CloudFormation template to deploy the EC2 instances and create dedicated CloudFormation stacks for each team. Each pipeline passes a parameter that is named TeamName to the CloudFormation stack to tag resources with the appropriate team’s name.\n\nThe company discovers that each team's usage of EC2 instances is not consistent with the type of EC2 instances that the teams are deploying. The company needs to allow the teams to deploy different types of EC2 instances.\n\nWhich solution will meet this requirement with the LEAST change to the pipelines?","choices":{"D":"Update the CloudFormation template by adding a map for the instance types to the Mappings section. Create a list of all the teams. Configure the required instance type for each team in the map.","B":"For each team, use a dedicated CloudFormation template that includes an InstanceType parameter and a value that is specific to the team's requirement. Update CodePipeline to use the dedicated template for each team","C":"Update the CloudFormation template by creating an InstanceType parameter. Update CodePipeline to pass the InstanceType parameter value that is specific to the team's requirement.","A":"For each team, use a dedicated CloudFormation template that includes different types of EC2 instances. Update CodePipeline to use the dedicated template for each team."},"discussion":[{"timestamp":"1669629900.0","poster":"JohnStanley","content":"Selected Answer: D\n\"LEAST change to the pipeline\" , so using a mapping section within cloudformation template seems best","upvote_count":"11","comment_id":"728956"},{"comment_id":"1123591","content":"Selected Answer: D\nThe main issue here is that the sentence \"The company needs to allow the teams to deploy different types of EC2 instances.\" has different interpretations. Some may understand it as granting each team the ability to modify the EC2 instance type themselves by inputting their parameters into the CodePipeline (leading to answer C). However, considering the requirement for the \"LEAST change to the pipeline,\" we can understand the sentence as asking for the CodePipeline's capability to deploy various EC2 instance types for each team. This suggests that we can specify different EC2 instance types for each team in the mapping based on their historical usage data. Therefore, the preferable answer is D.","poster":"cherkaar","timestamp":"1705346700.0","upvote_count":"1"},{"timestamp":"1702655940.0","comment_id":"1097464","upvote_count":"2","poster":"xdkonorek2","content":"Selected Answer: D\noption D is worse than C but require not pipeline changes"},{"content":"Selected Answer: C\nI vote for C as I think C + parameter store does not need any code change...","timestamp":"1699424460.0","poster":"CrescentShared","upvote_count":"1","comment_id":"1065348"},{"content":"Selected Answer: C\nGo with C( ChatGPT4 said )\nC. This is the most streamlined approach. By updating the CloudFormation template to have an InstanceType parameter, you can easily change the instance type for each team by simply passing a different parameter value through the pipeline. The pipeline itself only needs a minor change: passing a different parameter value based on the team.\n---------------------------\nD. While the Mappings section would allow for a team-specific instance type, it's a more complex solution compared to just using a parameter. The mappings section is typically used for values that are consistent across different environments or regions, not for dynamic values that might change regularly.","comment_id":"1040623","poster":"nmc12","upvote_count":"2","timestamp":"1697026800.0"},{"content":"Selected Answer: D\nGo with D","poster":"sweetheatmn","timestamp":"1696867800.0","upvote_count":"1","comment_id":"1038805"},{"upvote_count":"1","poster":"Rpod","comment_id":"888987","timestamp":"1683150360.0","content":"Selected Answer: C\nshould be C"},{"timestamp":"1681531020.0","poster":"Syre","comment_id":"870596","upvote_count":"2","content":"Selected Answer: B\nAll three options (B, C, and D) could work to meet the requirement, but option B would be the best answer with the least amount of change to the pipelines."},{"upvote_count":"1","comment_id":"860076","content":"Selected Answer: D\nIt's D.","poster":"Krok","timestamp":"1680535560.0"},{"timestamp":"1679491800.0","comment_id":"847101","upvote_count":"1","content":"Selected Answer: C\n\"The company needs to allow the teams to deploy different types of EC2 instances.\" means it has to be flexible. You don't know what the instances are so you have to parameterize","poster":"captainpike"},{"upvote_count":"1","content":"Selected Answer: D\nD -> The key in the question is ... with the LEAST change to the pipelines? So C is out since you need to update CodePipeline to pass the InstanceType. For me Creating Mappings for the instances in CloudFormation is the answer.","timestamp":"1677178620.0","poster":"rlnd2000","comment_id":"819590"},{"content":"D -> The key in the question is ... with the LEAST change to the pipelines? So C is out since you need to update CodePipeline to pass the InstanceType. For me Creating Mappings for the instances in CloudFormation is the answer.","upvote_count":"1","timestamp":"1677178500.0","poster":"rlnd2000","comment_id":"819584"},{"poster":"pancman","comment_id":"814799","timestamp":"1676865360.0","upvote_count":"2","content":"Selected Answer: C\nSince the question is asking for the solution \"with the LEAST change to the pipelines\", creating a new parameter instead of a mapping makes more sense."},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html","comment_id":"812216","upvote_count":"1","poster":"ShriniW","timestamp":"1676658540.0"},{"poster":"Krt5894","content":"Selected Answer: D\nD. Least changes to pipeline","upvote_count":"1","comment_id":"804721","timestamp":"1676060160.0"},{"comment_id":"786502","poster":"sichilam","upvote_count":"2","content":"We need a map the instance types to each team\nD it is","timestamp":"1674562860.0"},{"poster":"hb0011","content":"Selected Answer: C\nPassing the EC2 instance type as a parameter in the pipeline and using it in the CloudFormation template requires the least change to the pipeline. This way, you do not need to update the pipeline with a new mapping or any other additional configuration. The pipeline can continue to pass the TeamName parameter as before and add an additional parameter for the EC2 instance type. This way, the pipeline does not need to be modified and only the CloudFormation template will be updated to use the new parameter.","timestamp":"1674353760.0","upvote_count":"3","comment_id":"783884"},{"content":"Selected Answer: D\nD is the answer","comment_id":"757904","timestamp":"1672094460.0","poster":"fabriciollf","upvote_count":"2"},{"upvote_count":"1","comment_id":"754893","timestamp":"1671888180.0","poster":"Kapello10","content":"Selected Answer: C\nD is the answer"},{"upvote_count":"1","timestamp":"1670283900.0","poster":"rrrrrrrrrr1","content":"its D ofcoures it d","comment_id":"736399"},{"upvote_count":"3","poster":"SoMaL69","timestamp":"1669905000.0","comment_id":"732713","content":"Selected Answer: D\nAgreed with D. It is about least changes to pipeline, not to the template"},{"comment_id":"726637","poster":"k1kavi1","timestamp":"1669371180.0","content":"Selected Answer: C\nChoosing C","upvote_count":"1"},{"poster":"michaldavid","timestamp":"1669365300.0","comment_id":"726522","upvote_count":"1","content":"C agreed"},{"comment_id":"726023","upvote_count":"3","content":"Selected Answer: C\nC because of this: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html","poster":"saysamsuf","timestamp":"1669304880.0"}],"answer_description":"","answer_ET":"D","question_images":[],"answer_images":[],"topic":"1","answer":"D","unix_timestamp":1669304880,"question_id":121,"exam_id":25,"url":"https://www.examtopics.com/discussions/amazon/view/88553-exam-aws-certified-developer-associate-topic-1-question-207/","answers_community":["D (56%)","C (39%)","5%"]},{"id":"LEDRRvFAz072RJC2Ejn3","isMC":true,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/88665-exam-aws-certified-developer-associate-topic-1-question-208/","timestamp":"2022-11-25 10:50:00","discussion":[{"poster":"maurice2005","content":"Selected Answer: A\nDuh!!!","comment_id":"1164879","timestamp":"1709479020.0","upvote_count":"1"},{"timestamp":"1688052060.0","upvote_count":"1","content":"Selected Answer: A\nA because we only authorize read to the specific file in the bucket. Writes to the doc.txt and all the other resources in the bucket are protected","poster":"rcaliandro","comment_id":"938304"},{"comment_id":"907266","timestamp":"1685094600.0","content":"recent exam this question came","upvote_count":"1","poster":"Ramya009"},{"timestamp":"1680351060.0","content":"Selected Answer: A\nA provides least privilege","comment_id":"857879","upvote_count":"1","poster":"ihta_2031"},{"timestamp":"1676658900.0","poster":"ShriniW","upvote_count":"1","comment_id":"812222","content":"Selected Answer: A\nC is wrong \"Least privilege\" , hence A"},{"upvote_count":"1","content":"Selected Answer: A\nA to give least privileage","comment_id":"804720","poster":"Krt5894","timestamp":"1676060160.0"},{"poster":"michele_scar","content":"Selected Answer: A\nObv A :)","timestamp":"1674829320.0","comment_id":"789673","upvote_count":"2"},{"content":"Selected Answer: A\nA provides least privilege","timestamp":"1669371360.0","comment_id":"726640","upvote_count":"2","poster":"k1kavi1"},{"content":"I'd go with A on this one","comment_id":"726606","timestamp":"1669369800.0","poster":"michaldavid","upvote_count":"1"}],"unix_timestamp":1669369800,"question_id":122,"exam_id":25,"answer_ET":"A","answer_images":[],"choices":{"C":"","D":"","B":"","A":""},"question_text":"A developer is creating an application for a company. The application needs to read the file doc txt that is placed in the root folder of an Amazon S3 bucket that is named DOC-EXAMPLE-BUCKET. The company’s security team requires the principle of least privilege to be applied to the application’s IAM policy.\n\nWhich IAM policy statement will meet these security requirements?","topic":"1","answers_community":["A (100%)"],"answer_description":"","answer":"A"},{"id":"vCZh1KZJtYFaVeBDs3Xu","answers_community":["D (94%)","6%"],"answer_images":[],"question_id":123,"discussion":[{"upvote_count":"2","content":"Selected Answer: D\nSQS FIFO queue are suitable for this scenarion given that the requirements say that we have to avoid duplicate and guarantee also the order. Definitely D.","timestamp":"1688052360.0","poster":"rcaliandro","comment_id":"938308"},{"upvote_count":"2","poster":"MrTee","comment_id":"881561","content":"Selected Answer: D\nOption D is the best solution because it meets the requirements of avoiding duplicate shipping requests and processing the requests in the order that they arrive. This is achieved by using an Amazon Simple Queue Service (Amazon SQS) FIFO (First-In-First-Out) queue. FIFO queues are designed to ensure that the order in which messages are sent and received is strictly preserved and that each message is delivered once and remains available until a consumer processes and deletes it.\nBy creating an AWS Lambda function to process the requests and setting the SQS FIFO queue as an event source for the Lambda function, the application can write the requests to the SQS queue and the Lambda function will process them in the order that they arrive, without any duplicates. This improves the reliability of the delivery and processing of the requests.","timestamp":"1682509500.0"},{"content":"Selected Answer: C\nThis question is tricky, answer is C.\nOption D suggests using an Amazon SQS FIFO queue to process the requests, which guarantees that the messages are processed in the order in which they are received. However, it does not address the issue of duplicate messages arriving. FIFO queues do not prevent duplicate messages from being sent, but they ensure that they are processed in the order that they are received.\n\nTo prevent duplicates, the application needs to be modified to implement deduplication logic. Option C suggests using an AWS Lambda function to process the requests and an Amazon SQS standard queue as an event source. With this configuration, the application can enable deduplication on the queue to ensure that messages are not duplicated. Therefore, option C is a better solution than option D for this scenario.","upvote_count":"1","comment_id":"870601","poster":"Syre","timestamp":"1681531500.0","comments":[{"comment_id":"988127","upvote_count":"1","content":"The company must avoid duplicate shipping requests and must process the requests in the order that the requests arrive <<< it's (D) bro pls read question again","timestamp":"1692781560.0","poster":"YanisGTR"}]},{"poster":"Jay1299","comment_id":"834672","timestamp":"1678428180.0","upvote_count":"1","content":"Definitely D\nI was expecting a deduplication ID as well in this option but it is fine since 'FIFO' is mentioned"},{"comment_id":"814802","poster":"pancman","timestamp":"1676865480.0","upvote_count":"1","content":"Selected Answer: D\nYou need an SQS FIFO queue to avoid duplicates. SQS Standard queue can introduce duplicates."},{"upvote_count":"1","poster":"A_Q","content":"Selected Answer: D\nThe question is asking \"avoid duplicate shipping requests and must process the requests in the order that the requests arrive\" which definitely means it's SQS FIFO.","timestamp":"1676283120.0","comment_id":"807278"},{"timestamp":"1676060100.0","poster":"Krt5894","content":"Selected Answer: D\nSQS FIFO. It is D","upvote_count":"1","comment_id":"804719"},{"upvote_count":"3","timestamp":"1671229260.0","poster":"Nosal","content":"Selected Answer: D\nD is the correct answer","comment_id":"747650"},{"poster":"k1kavi1","comment_id":"726644","upvote_count":"3","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-exactly-once-processing.html\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-message-order.html","timestamp":"1669371600.0"},{"content":"Selected Answer: D\nWe need SQS FIFO for this","comment_id":"726623","timestamp":"1669370340.0","poster":"michaldavid","upvote_count":"3"}],"exam_id":25,"question_images":[],"answer_description":"","question_text":"A company has migrated an application to Amazon EC2 instances. Automatic scaling is working well for the application user interface. However, the process to deliver shipping requests to the company's warehouse staff is encountering issues. Duplicate shipping requests are arriving, and some requests are lost or arrive out of order.\n\nThe company must avoid duplicate shipping requests and must process the requests in the order that the requests arrive. Requests are never more than 250 KB in size and take 5-10 minutes to process. A developer needs to rearchitect the application to improve the reliability of the delivery and processing of the requests.\n\nWhat should the developer do to meet these requirements?","timestamp":"2022-11-25 10:59:00","answer":"D","choices":{"C":"Create an AWS Lambda function to process the requests. Create an Amazon Simple Queue Service (Amazon SQS) standard queue. Set the SQS queue as an event source for the Lambda function. Modify the application to write the requests to the SQS queue.","A":"Create an Amazon Kinesis Data Firehose delivery stream to process the requests. Create an Amazon Kinesis data stream. Modify the application to write the requests to the Kinesis data stream.","B":"Create an AWS Lambda function to process the requests. Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the Lambda function to the SNS topic. Modify the application to write the requests to the SNS topic.","D":"Create an AWS Lambda function to process the requests. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the SQS queue as an event source for the Lambda function. Modify the application to write the requests to the SQS queue."},"isMC":true,"unix_timestamp":1669370340,"url":"https://www.examtopics.com/discussions/amazon/view/88667-exam-aws-certified-developer-associate-topic-1-question-209/","topic":"1","answer_ET":"D"},{"id":"TUZ0o34G2bR9Ah3Fwt0M","question_images":[],"discussion":[{"timestamp":"1662192600.0","content":"Selected Answer: C\nFor Aws CLI Command, we need access key and secret access key","poster":"sidvic","comment_id":"658219","upvote_count":"7"},{"poster":"sumanshu","content":"Selected Answer: C\nC - Correct - The AWS CLI requires an access key and secret key, not a username and password.\n\nThe AWS CLI does not require an SDK or an X.509 certificate for configuration","comment_id":"1326939","upvote_count":"1","timestamp":"1734276240.0"},{"poster":"Maddy_123","timestamp":"1722100560.0","upvote_count":"1","content":"It is C\nhttps://docs.aws.amazon.com/cli/latest/userguide/welcome-examples.html","comment_id":"1256375"},{"upvote_count":"1","content":"C option","comment_id":"1125197","poster":"gilleep_17","timestamp":"1705514280.0"},{"poster":"AsmaZoheb","timestamp":"1705273680.0","content":"Selected Answer: C\nfor sure C, no doubt","comment_id":"1122951","upvote_count":"1"},{"content":"Selected Answer: C\nOf course C. We need first to install AWS cli. For the client we can't use username and psw to login, but we need to generate access key and secret key instead. They can be configured lanching aws configure, can be set as env variables or can be passed as parameter","poster":"rcaliandro","comment_id":"935622","upvote_count":"1","timestamp":"1687885380.0"},{"content":"Selected Answer: C\nC should be the correct approach","comment_id":"804765","upvote_count":"1","poster":"Krt5894","timestamp":"1676061000.0"},{"content":"Selected Answer: C\nC for sure","comment_id":"801120","upvote_count":"1","poster":"Ashish_Mishra","timestamp":"1675786800.0"},{"timestamp":"1674408720.0","poster":"tapsshore","content":"C is the correct answer. \nIn summary, to complete the task of writing an AWS CloudFormation template on a local machine and deploying a CloudFormation stack to AWS, the developer must install the AWS CLI and configure it by using their IAM user access key and secret key.","upvote_count":"1","comment_id":"784540"},{"poster":"G4Exams","timestamp":"1669345800.0","upvote_count":"1","content":"Selected Answer: C\nIt's C","comment_id":"726363"},{"content":"C for sure","upvote_count":"1","timestamp":"1666369800.0","poster":"cwit63","comment_id":"701060"}],"topic":"1","answers_community":["C (100%)"],"answer_description":"","exam_id":25,"question_id":124,"timestamp":"2022-09-03 10:10:00","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/79721-exam-aws-certified-developer-associate-topic-1-question-21/","choices":{"D":"Install an AWS software development kit (SDK). Configure the SDK by using an X.509 certificate.","A":"Install the AWS CLI. Configure the AWS CLI by using an IAM user name and password.","C":"Install the AWS CLI. Configure the AWS CLI by using an IAM user access key and secret key.","B":"Install the AWS CLI. Configure the AWS CLI by using an SSH key."},"answer_ET":"C","isMC":true,"answer":"C","question_text":"A developer needs to write an AWS CloudFormation template on a local machine and deploy a CloudFormation stack to AWS.\nWhat must the developer do to complete these tasks?","unix_timestamp":1662192600},{"id":"hmEY1RfQAwxAq4X3hwBa","url":"https://www.examtopics.com/discussions/amazon/view/88670-exam-aws-certified-developer-associate-topic-1-question-210/","isMC":true,"discussion":[{"poster":"xdkonorek2","upvote_count":"1","comment_id":"1097492","content":"Selected Answer: B\nYou can't change load balancer type while cloning environment","timestamp":"1702659240.0"},{"poster":"CrescentShared","content":"Selected Answer: C\nUnderstand that Beanstalk does not support changing of loader balancer type, that's why we clone an existing environment instead of editing it directly (like D).","upvote_count":"1","timestamp":"1699425240.0","comment_id":"1065351"},{"poster":"YanisGTR","timestamp":"1692782040.0","upvote_count":"1","content":"Currently, Beanstalk does not support changing of Load Balancer type. If you want to change the Load Balancer type, you need to create a new environment with the desired Load Balancer type.\n\nI see you have made changes to the environment resources out-of-band which is not recommended as it might break the environment like the issue that you are encountering. Therefore, to fix this issue, the only option we have is to create a new environment. <<< This answer from AWS support team link Below \nhttps://repost.aws/questions/QUEemsrTM_TPG3r_HdoG08EQ/how-to-remove-or-change-a-load-balancer-type-with-elastic-beanstalk","comment_id":"988135"},{"upvote_count":"1","content":"Is there even correct answer? For me it looks like it doesn't. B is closes, but 2nd step looks incorrect, since we need to deploy to new version of the app, don't we?","timestamp":"1688056800.0","comment_id":"938374","poster":"Sardor_uz"},{"timestamp":"1688052600.0","upvote_count":"1","poster":"rcaliandro","content":"Selected Answer: B\nIf we clone we also clone the type of load balancer. If we want an Application Load Balancer, we have to create a new environmment with the same configurations, deploy the application that is current running on the classic load balancer then use swap-environment-cnames action to point the same url to the new ALB","comment_id":"938309"},{"content":"c,The Elastic Beanstalk environment is designed to abstract the underlying resources used to run the application. When the load balancer type is changed, the entire environment must be recreated with the new load balancer.\n\nTherefore, to migrate an Elastic Beanstalk environment from a Classic Load Balancer to an Application Load Balancer, the recommended steps are to clone the existing environment and associate it with the Application Load Balancer. After cloning, the same application version as used in the original environment is deployed to the new environment. Finally, the swap-environment-cnames action is run to swap the environment URLs so that the new environment takes over the traffic.","comment_id":"893016","timestamp":"1683629580.0","poster":"BATSIE","upvote_count":"1"},{"comment_id":"881564","timestamp":"1682509680.0","poster":"MrTee","upvote_count":"1","content":"Selected Answer: C\nBy cloning the existing environment and changing the associated load balancer type, the developers can create a new environment with an Application Load Balancer. They can then deploy the same application version as used in the original environment and run the swap-environment-cnames action to switch traffic from the old environment to the new one."},{"poster":"Syre","content":"Selected Answer: C\nC is the correct answer here.\nOption B is incorrect because creating a new environment is not necessary and can result in additional cost and maintenance overhead.","comment_id":"870603","timestamp":"1681531860.0","upvote_count":"2"},{"upvote_count":"1","content":"Selected Answer: B\nyou need to create a new environment with the desired Load Balancer type.","comment_id":"807281","poster":"A_Q","timestamp":"1676283240.0"},{"content":"Selected Answer: B\nhttps://repost.aws/questions/QUEemsrTM_TPG3r_HdoG08EQ/how-to-remove-or-change-a-load-balancer-type-with-elastic-beanstalk","timestamp":"1676060100.0","upvote_count":"1","poster":"Krt5894","comment_id":"804718"},{"upvote_count":"1","poster":"hb0011","timestamp":"1674354540.0","content":"Selected Answer: B\nNever mind. Cloning will clone it with a classic load balancer. Won't let you change it. B it is.","comment_id":"783890"},{"poster":"hb0011","upvote_count":"2","content":"Why B over C? Cloning the environment is a valid option","timestamp":"1674354420.0","comment_id":"783888"},{"comment_id":"732723","upvote_count":"1","poster":"SoMaL69","content":"Selected Answer: B\nhttps://repost.aws/questions/QUEemsrTM_TPG3r_HdoG08EQ/how-to-remove-or-change-a-load-balancer-type-with-elastic-beanstalk","timestamp":"1669905540.0"},{"poster":"k1kavi1","content":"Selected Answer: B\nWill need to create a new application to change the ELB type","upvote_count":"3","comment_id":"726650","timestamp":"1669371900.0","comments":[{"timestamp":"1669823640.0","poster":"k1kavi1","comment_id":"731705","content":"https://www.examtopics.com/discussions/amazon/view/6571-exam-aws-certified-developer-associate-topic-1-question-200/","upvote_count":"1"}]}],"question_images":[],"exam_id":25,"unix_timestamp":1669371900,"timestamp":"2022-11-25 11:25:00","question_text":"A team of developers must migrate an application running inside an AWS Elastic Beanstalk environment from a Classic Load Balancer to an Application Load Balancer.\n\nWhich steps should be taken to accomplish the task using the AWS Management Console?","answer_images":[],"topic":"1","answer_description":"","question_id":125,"answer_ET":"B","answer":"B","answers_community":["B (69%)","C (31%)"],"choices":{"A":"1. Update the application code in the existing deployment.\n2. Select a new load balancer type before running the deployment\n3. Deploy the new version of the application code to the environment","D":"1. Edit the environment definitions in the existing deployment.\n2. Change the associated load balancer type according to the requirements.\n3. Rebuild the environment with the new load balancer type.","C":"1. Clone the existing environment, changing the associated load balancer type.\n2. Deploy the same application version as used in the original environment.\n3. Run the swap-environment-cnames action","B":"1. Create a new environment with the same configurations except for the load balancer type.\n2. Deploy the same application version as used in the original environment.\n3. Run the swap-environment-cnames action"}}],"exam":{"isMCOnly":true,"isBeta":false,"provider":"Amazon","numberOfQuestions":443,"id":25,"name":"AWS Certified Developer Associate","lastUpdated":"11 Apr 2025","isImplemented":true},"currentPage":25},"__N_SSP":true}