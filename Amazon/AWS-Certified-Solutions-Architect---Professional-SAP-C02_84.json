{"pageProps":{"questions":[{"id":"8I78XXWeVNfq9fWtNT3b","isMC":true,"answer_images":[],"answer_description":"","question_text":"An ecommerce company runs an application on AWS. The application has an Amazon API Gateway API that invokes an AWS Lambda function. The data is stored in an Amazon RDS for PostgreSQL DB instance.\n\nDuring the companyâ€™s most recent flash sale, a sudden increase in API calls negatively affected the application's performance. A solutions architect reviewed the Amazon CloudWatch metrics during that time and noticed a significant increase in Lambda invocations and database connections. The CPU utilization also was high on the DB instance.\n\nWhat should the solutions architect recommend to optimize the application's performance?","unix_timestamp":1710861540,"choices":{"B":"Add an Amazon ElastiCache for Redis cluster to store the frequently accessed data from the RDS database.","A":"Increase the memory of the Lambda function. Modify the Lambda function to close the database connections when the data is retrieved.","D":"Modify the Lambda function to connect to the database outside of the function's handler. Check for an existing database connection before creating a new connection.","C":"Create an RDS proxy by using the Lambda console. Modify the Lambda function to use the proxy endpoint."},"exam_id":33,"answers_community":["C (75%)","D (15%)","5%"],"timestamp":"2024-03-19 16:19:00","discussion":[{"comments":[{"comment_id":"1205933","content":"Create a new database not RDS proxy!\nUse an existing database\nCreate a new database","timestamp":"1714713240.0","upvote_count":"1","poster":"YOUSSEFSWAID"}],"poster":"titi_r","upvote_count":"11","timestamp":"1714120260.0","comment_id":"1202474","content":"Selected Answer: C\nSome guys got confused whether it's possible to create a DB proxy from the Lambda console Yes, you CAN create a proxy from within the Lambda console: open a function -> Configuration -> RDS databases -> Add Proxy, then select a radio button with two options:\n- Create a new database proxy\n- Choose an existing database proxy\n\nSaid that, \"C\" is correct."},{"content":"Selected Answer: C\nhttps://repost.aws/knowledge-center/lambda-rds-database-proxy","poster":"oayoade","timestamp":"1710880740.0","comment_id":"1177722","upvote_count":"7"},{"poster":"altonh","upvote_count":"1","content":"Selected Answer: B\nI think B will solve the database connection and the DB CPU utilization.","timestamp":"1740046680.0","comment_id":"1359195"},{"upvote_count":"1","timestamp":"1737920040.0","content":"Selected Answer: B\nAs for me, the correct answer is B. \n\"The CPU utilization also was high on the DB instance\" - DB Utilization can be high due to unoptimized queries. Opening a new connection for PG is not a complex operation (it does not consume many resources).\nAdding connection pooling will not help in this situation, IMHO, because even one unoptimized query is enough to consume all CPU resources on the database layer.\nElastiCache will allow query offloading from the DB layer.","poster":"skydev","comment_id":"1347078"},{"comment_id":"1316091","upvote_count":"2","timestamp":"1732237560.0","content":"Selected Answer: A\nThe first part is a significant increase in Lambda invocation and database connection. So, increasing the Lambda function's memory is the quickest solution. \nThis will allow the function to handle more concurrent requests and reduce cold start times, immediately improving response times.","poster":"TomTom"},{"timestamp":"1731207360.0","comment_id":"1309294","upvote_count":"1","poster":"AzureDP900","content":"Creating an RDS proxy by using the Lambda console and modifying the Lambda function to use the proxy endpoint can help improve performance during peak usage periods like flash sales. This approach has several advantages:\n\nC is right\n\nReduced Database Load: By using a connection pool provided by the RDS proxy, you can reduce the number of database connections and queries, which can help decrease CPU utilization and improve overall system performance.\n\nImproved Response Times: With an RDS proxy, your application can respond more quickly to user requests, as it doesn't need to wait for database queries to complete."},{"comment_id":"1296624","upvote_count":"2","timestamp":"1728764520.0","poster":"JoeTromundo","content":"Selected Answer: C\n\"Step 3\n1. Open the Functions page in the LAMBDA CONSOLE.\n2. In Functions, choose your Lambda function.\n3. Choose Configuration, and then choose ADD DATABASE PROXIES.\n4. Enter the following variables:\nProxy identifier: The name of the proxy.\nRDS DB instance: A supported MySQL or PostgreSQL DB instance or cluster.\nSecret: The Secrets Manager that you created.\nIAM role: The IAM role that you created.\nAuthentication: Choose Password to connect with database credentials or choose Execution role to use the function's IAM credentials for authentication.\n5. Choose Add.\""},{"content":"Selected Answer: D\nWith the current options for my is D, because you can't create a RDS Proxy from Lmabda function console, unless the C is misspelled and the answer is only AWS Console","poster":"zolthar_z","upvote_count":"1","comment_id":"1261079","timestamp":"1722864840.0"},{"timestamp":"1719755700.0","upvote_count":"1","content":"Selected Answer: D\nVote D because answer C is incorrect without mention increasing db server qty increase behind proxy. No improvement by just changing endpoint from db to db proxy. \nD can help by reusing the db connection instead of one connection per thread. Lambda by default is parallel run inside the handler.","comment_id":"1239671","poster":"Helpnosense"},{"upvote_count":"2","content":"Selected Answer: D\nC, is wrong \nCreating Proxy: Within the RDS console, find the \"Proxies\" section and click on \"Create proxy\".","comment_id":"1221688","timestamp":"1717083960.0","poster":"iulian0585"},{"content":"Selected Answer: C\nOption C: Read AWS Blog - Using Amazon RDS Proxy w/ AWS Lambda \nhttps://aws.amazon.com/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/\n\nRead Section \" Create and attach a proxy to a Lambda function \"\nNext, use the Lambda console to Add a Database proxy to a Lambda function.\n\nSign into the AWS Lambda console and open the Lambda function you would like to enable RDS Proxy. This Lambda function needs to be configured for access to the same VPC and Subnets as your RDS database.","comment_id":"1204561","poster":"TonytheTiger","upvote_count":"3","timestamp":"1714480140.0"},{"comment_id":"1199996","content":"C, is wrong \nCreating Proxy: Within the RDS console, find the \"Proxies\" section and click on \"Create proxy\".","poster":"YOUSSEFSWAID","upvote_count":"2","timestamp":"1713766680.0"},{"upvote_count":"1","timestamp":"1713153000.0","comments":[{"comment_id":"1219985","timestamp":"1716870240.0","content":"I've changed my mind as it's possible to create an RDS proxy by using the Lambda console and regarding the D option, this will improve the lambda performance but not the RDS so going for option C definitely.","upvote_count":"1","poster":"teo2157"}],"poster":"teo2157","comment_id":"1195786","content":"Selected Answer: D\nA) Incorrect because the issue is at database level\nB) Partially correct but there's one step missed because you have to modify endpoint for the lambda function\nC) This is the tricky one, it's almost correct and the best option except for one comment, it's said \"Create an RDS proxy by using the Lambda console\" the RDS proxy is not created in the lambda console but in the RDS console....\nD) Totally correct, https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html\n\nSaid that, going for D but I found this question very tricky...."},{"upvote_count":"3","content":"Selected Answer: C\nBCD all looks good.\nI vote for C","poster":"pangchn","comment_id":"1183519","timestamp":"1711478220.0","comments":[{"comment_id":"1183525","poster":"pangchn","comments":[{"content":"umm, NVM\nhttps://newsletter.simpleaws.dev/p/elasticache-redis-cache-rds","poster":"pangchn","comment_id":"1183534","timestamp":"1711479120.0","upvote_count":"2"}],"upvote_count":"1","content":"not B, redis is NOSQL so no relevant to this question","timestamp":"1711478280.0"}]},{"poster":"djangoUnchained","content":"Almost answered C before realizing it was a trap. You don't create RDS Proxies from the LAMBDA console, it is done from the RDS console. D is the best answer.","comment_id":"1180058","comments":[{"content":"It's not a trap. It _is_ possible to create the RDS Proxy from within the lambda console.","upvote_count":"3","timestamp":"1711387620.0","poster":"gustori99","comment_id":"1182682"}],"timestamp":"1711112280.0","upvote_count":"2"},{"poster":"Dgix","content":"Selected Answer: C\nC, for the reasons oayoade links to. \nD is a trap: moving the DB connection outside of the handler obviates the need for keeping track of DB connections. However, C is an even better alternative.","upvote_count":"4","comment_id":"1178824","timestamp":"1710974940.0"},{"comment_id":"1177484","content":"Selected Answer: D\ncheck to re-use any existing DB connection across multiple invocations of Lambda function","timestamp":"1710861540.0","upvote_count":"1","poster":"CMMC"}],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/136655-exam-aws-certified-solutions-architect-professional-sap-c02/","question_id":416,"answer":"C","answer_ET":"C","topic":"1"},{"id":"tETYZoCodMkF4QyYZa0y","answer":"C","topic":"1","answers_community":["C (100%)"],"question_images":[],"unix_timestamp":1710862020,"answer_images":[],"answer_ET":"C","question_id":417,"timestamp":"2024-03-19 16:27:00","url":"https://www.examtopics.com/discussions/amazon/view/136656-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"C":"Migrate the individual applications as microservices to Amazon Elastic Kubernetes Service (Amazon EKS) containers that use AWS Fargate. Migrate the retail MySQL database to Amazon Aurora Serverless MySQL. Migrate the analytics database to Amazon Redshift Serverless. Use Amazon EventBridge to send all the incoming data to the microservices and the analytics database.","B":"Create an Auto Scaling group for each application. Specify the necessary number of EC2 instances in each Auto Scaling group. Migrate the retail MySQL database and the analytics database to Amazon Aurora MySQL. Use Amazon Simple Notification Service (Amazon SNS) to send all the incoming data to the correct EC2 instances and the analytics database.","D":"Migrate the individual applications as microservices to Amazon AppStream 2.0. Migrate the retail MySQL database to Amazon Aurora MySQL. Migrate the analytics database to Amazon Redshift Serverless. Use AWS IoT Core to send all the incoming data to the microservices and the analytics database.","A":"Migrate the individual applications as microservices to Amazon Elastic Container Service (Amazon ECS) containers that use AWS Fargate. Keep the retail MySQL database on Amazon EC2. Move the analytics database to Amazon Neptune. Use Amazon Simple Queue Service (Amazon SQS) to send all the incoming data to the microservices and the analytics database."},"question_text":"A retail company wants to improve its application architecture. The company's applications register new orders, handle returns of merchandise, and provide analytics. The applications store retail data in a MySQL database and an Oracle OLAP analytics database. All the applications and databases are hosted on Amazon EC2 instances.\n\nEach application consists of several components that handle different parts of the order process. These components use incoming data from different sources. A separate ETL job runs every week and copies data from each application to the analytics database.\n\nA solutions architect must redesign the architecture into an event-driven solution that uses serverless services. The solution must provide updated analytics in near real time.\n\nWhich solution will meet these requirements?","answer_description":"","discussion":[{"upvote_count":"5","poster":"CMMC","timestamp":"1710862020.0","comment_id":"1177493","content":"Selected Answer: C\n#A - SQS is not for near real time. MySQL on EC2 is not serverless\n#B is not serverless\n#D is incorrect - Appstream for desktop app streaming and IoT Core for IoT"},{"upvote_count":"1","poster":"AzureDP900","content":"C is right. This solution involves migrating individual applications as microservices to Amazon EKS containers that use Fargate, moving the retail MySQL database to Amazon Aurora Serverless MySQL, and migrating the analytics database to Amazon Redshift Serverless. Using Amazon EventBridge allows you to send all incoming data to the microservices and the analytics database in near real time.","timestamp":"1731207120.0","comment_id":"1309293"},{"upvote_count":"3","comment_id":"1178825","content":"Selected Answer: C\nC is serverless. \nD is rubbish.","poster":"Dgix","timestamp":"1710975060.0"},{"poster":"oayoade","content":"Selected Answer: C\n\"serverless\"","timestamp":"1710880560.0","upvote_count":"2","comment_id":"1177719"}],"isMC":true,"exam_id":33},{"id":"F5UKMUo6DOphaQkqElRN","question_images":[],"question_text":"A company is planning a migration from an on-premises data center to the AWS Cloud. The company plans to use multiple AWS accounts that are managed in an organization in AWS Organizations. The company will create a small number of accounts initially and will add accounts as needed. A solutions architect must design a solution that turns on AWS CloudTrail in all AWS accounts.\n\nWhat is the MOST operationally efficient solution that meets these requirements?","answer_ET":"B","answer_description":"","timestamp":"2024-03-19 16:30:00","answer_images":[],"question_id":418,"url":"https://www.examtopics.com/discussions/amazon/view/136658-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"D":"Create an AWS Systems Manager Automation runbook that creates a CloudTrail trail in all AWS accounts in the organization. Invoke the automation by using Systems Manager State Manager.","C":"Create a new CloudTrail trail in all AWS accounts in the organization. Create new trails whenever a new account is created. Define an SCP that prevents deletion or modification of trails. Apply the SCP to the root OU.","B":"Create a new CloudTrail trail in the organization's management account. Configure the trail to log all events for all AWS accounts in the organization.","A":"Create an AWS Lambda function that creates a new CloudTrail trail in all AWS accounts in the organization. Invoke the Lambda function daily by using a scheduled action in Amazon EventBridge."},"answers_community":["B (100%)"],"unix_timestamp":1710862200,"exam_id":33,"answer":"B","discussion":[{"poster":"juanife","comment_id":"1355082","content":"Selected Answer: B\nI agree with option B, since the other ones are not operationally efficient. About letter C, I undoubtedly think that it is not needed for you to create avery single aws cloudtrail trail on each account to apply it","upvote_count":"1","timestamp":"1739298060.0"},{"comment_id":"1256646","poster":"Santoshhhhh","upvote_count":"1","content":"B is correct","timestamp":"1722154080.0"},{"poster":"pangchn","content":"Selected Answer: B\nB\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","upvote_count":"3","comment_id":"1183542","timestamp":"1711479660.0"},{"poster":"Dgix","comment_id":"1178826","upvote_count":"1","content":"Selected Answer: B\nB is correct.","timestamp":"1710975120.0"},{"upvote_count":"4","poster":"CMMC","timestamp":"1710862200.0","comment_id":"1177495","content":"Selected Answer: B\n#B is the most operational efficient"}],"topic":"1","isMC":true},{"id":"rNv6BATfm0exQAeNRg4v","answer_description":"","choices":{"D":"Create an Amazon WorkLink endpoint. Configure integration between Amazon WorkLink and AD DS. Enable MFA in Amazon WorkLink. Use AWS Client VPN to establish a VPN connection.","A":"Create an AWS Site-to-Site VPN connection. Configure integration between a VPN and AD DS. Use an Amazon WorkSpaces client with MFA support enabled to establish a VPN connection.","B":"Create an AWS Client VPN endpoint. Create an AD Connector directory for integration with AD DS. Enable MFA for AD Connector. Use AWS Client VPN to establish a VPN connection.","C":"Create multiple AWS Site-to-Site VPN connections by using AWS VPN CloudHub. Configure integration between AWS VPN CloudHub and AD DS. Use AWS Copilot to establish a VPN connection."},"answers_community":["B (100%)"],"question_id":419,"question_text":"A software development company has multiple engineers who are working remotely. The company is running Active Directory Domain Services (AD DS) on an Amazon EC2 instance. The company's security policy states that all internal, nonpublic services that are deployed in a VPC must be accessible through a VPN. Multi-factor authentication (MFA) must be used for access to a VPN.\n\nWhat should a solutions architect do to meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/136659-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"B","answer_ET":"B","question_images":[],"topic":"1","answer_images":[],"isMC":true,"unix_timestamp":1710862980,"timestamp":"2024-03-19 16:43:00","exam_id":33,"discussion":[{"comment_id":"1309290","upvote_count":"1","timestamp":"1731206460.0","poster":"AzureDP900","content":"This is no brainer question, B is perfect"},{"upvote_count":"1","poster":"kgpoj","content":"Selected Answer: B\nACD are wrong.\n\nBut for B, it is also not perfect. AD Connector is for connecting between ADDS on premises and AWS. In this case, the ADDS is on AWS's EC2. Do you really need AD Connector?","timestamp":"1723724820.0","comment_id":"1266436"},{"poster":"Helpnosense","content":"No doubt that answer B will collect all the events from accounts in the organizations. But the requirement is \"A solutions architect must design a solution that turns on AWS CloudTrail in all AWS accounts.\" Can answer B turn on AWS CloudTrail in all AWS accounts.?","timestamp":"1720873620.0","comment_id":"1247302","upvote_count":"1"},{"poster":"Fu7ed","comment_id":"1202631","content":"Answer is B. \n\nClient VPN provides Active Directory support by integrating with AWS Directory Service. Client VPN supports multi-factor authentication (MFA) when it's enabled for AWS Managed Microsoft AD or AD Connector.\nhttps://docs.aws.amazon.com/vpn/latest/clientvpn-admin/ad.html\n\nC. WHY Copilot?\nD. Worklink is Provide secure mobile access to your internal websites and web apps.","timestamp":"1714138680.0","upvote_count":"1"},{"poster":"Dgix","timestamp":"1710975420.0","comment_id":"1178831","upvote_count":"4","content":"Selected Answer: B\nA: Site-to-Site VPN is for connecting networks, not giving users access.\nB is correct.\nC is rubbish: AWS Copilot is for deploying containers (and it's bloody good!)\nD is also rubbish: WorkLink is for website and webapp access, not VPN access."},{"comment_id":"1177713","timestamp":"1710880380.0","poster":"oayoade","content":"Selected Answer: B\nhas to be B","upvote_count":"2"},{"content":"Selected Answer: B\n#A - workspaces client for remote desktop access and not for VPN\n#C - AWS VPN CloudHub for connecting multiple on-premises or offices, and not for individual VPN connection\n#D - WorkLink for secure access from mobile devices and not for VPN connection","poster":"CMMC","timestamp":"1710862980.0","comment_id":"1177506","upvote_count":"4"}]},{"id":"khsZ37hMJApjhZkhMvI8","answers_community":["ACE (85%)","Other"],"choices":{"B":"Rehost the Apache web server of the frontend on Amazon EC2 instances that are in an Auto Scaling group. Use a load balancer in front of the Auto Scaling group. Use Amazon Elastic File System (Amazon EFS) to host the static assets that the Apache web server needs.","D":"Refactor the Java application, Develop a Docker container to run the Java application. Use AWS Fargate to host the container.","C":"Rehost the Java application in an AWS Elastic Beanstalk environment that includes auto scaling.","A":"Refactor the frontend so that static assets can be hosted on Amazon S3. Use Amazon CloudFront to serve the frontend to customers. Connect the frontend to the Java application.","E":"Use AWS Database Migration Service (AWS DMS) to replatform the PostgreSQL database to an Amazon Aurora PostgreSQL database. Use Aurora Auto Scaling for read replicas.","F":"Rehost the PostgreSQL database on an Amazon EC2 instance that has twice as much memory as the on-premises server."},"answer_ET":"ACE","answer_description":"","discussion":[{"timestamp":"1728987780.0","poster":"chris_spencer","content":"Selected Answer: ACE\nI would preferred container over beanstalk but this are examen questions ACE","upvote_count":"3","comment_id":"1298181"},{"comment_id":"1286695","content":"The question says they have incoming campaigns in NEAR future. Doesn't this means Rehost options are better?","upvote_count":"1","poster":"wbedair","timestamp":"1726815660.0"},{"poster":"backbencher2022","comment_id":"1272177","upvote_count":"1","content":"Selected Answer: ACE\nA, C & E. For A - You can connect S3 with backend Java application. It is a known pattern and also published here - https://aws.amazon.com/blogs/storage/extending-java-applications-to-directly-access-files-in-amazon-s3-without-recompiling/","timestamp":"1724596500.0"},{"upvote_count":"4","poster":"blackname","timestamp":"1716494760.0","comment_id":"1216986","content":"Selected Answer: ACE\nA -> Correct. Frontend could be hosted on s3 so we don't need a EC2\nB -> False. That's expensive, and requires operational effort (ex: patches, ...)\nC -> Correct. Elastic Beanstalk would reduce operational effort of patches and other stuff and also support native scaling\nD -> False. Would be a great answer if it mentioned \"Service Autoscaling\" for fargate. Since it does not mention, we have to assume that would be only 1 fargate task.\nE -> Correct. Aurora RDS would reduce operational effort and would also allow scaling read replicas.\nF -> False. Requires very operational effort to allow DB reads scaling\nF"},{"poster":"Dawson75","comment_id":"1210705","upvote_count":"1","timestamp":"1715576340.0","content":"Selected Answer: ACE\nACE best choices"},{"timestamp":"1714454940.0","content":"BCF is correct","poster":"Dawson75","upvote_count":"1","comment_id":"1204362"},{"poster":"Fu7ed","comment_id":"1202623","content":"Selected Answer: ACE\nI chose ACE, but I don't know why it's not D. If you tried to reduce the development effort, it wouldn't have been D, but if you want to reduce the operation effort, I think D is definitely the answer to some extent. However, I chose C because I thought using app refactoring -> java container development -> EKS Fargate was cumbersome.","upvote_count":"3","timestamp":"1714138200.0","comments":[{"poster":"blackname","comment_id":"1216983","upvote_count":"1","content":"A single fargate task will not handle peak traffic. In this options it's not mentioned \"Service Autoscaling\" for fargate, so as is it means that would be a single fargate task\n\nhttps://repost.aws/knowledge-center/ecs-fargate-service-auto-scaling","timestamp":"1716494340.0"}]},{"timestamp":"1713585840.0","comment_id":"1198933","content":"Selected Answer: ACE\n1. AWS CloudFront (CDN)\n2. AWS Elastic Beanstalk\n3. DMS \n4. Aurora Auto Scaling","poster":"4555894","upvote_count":"1"},{"timestamp":"1713424860.0","upvote_count":"1","content":"BDE\nB for Web Servers ASG with EFS for scale to share Linux apache servers\nD for App Servers - Fargate reduces ops efforts\nE for DB","poster":"tushar321","comment_id":"1197769"},{"content":"Selected Answer: A\nThis is what my company does, and there is no mention here of enabling S3 static web hosting","timestamp":"1713220260.0","comment_id":"1196230","upvote_count":"1","poster":"AwsZora"},{"upvote_count":"2","timestamp":"1713168120.0","comment_id":"1195895","content":"Selected Answer: BCE\nA is incorrect because you canÂ´t connect a bucket S3 to a Java application so going with Apcache Web Servers with autoscaling. Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services. It supports Java applications and can automatically handle the details of capacity provisioning, load balancing, scaling, and application health monitoring. The using of Aurora PostgreSQL is pretty obvious. Said that going for BCE.","poster":"teo2157","comments":[{"upvote_count":"1","comment_id":"1272176","content":"You can connect S3 with backend Java application. It is a known pattern and also published here - https://aws.amazon.com/blogs/storage/extending-java-applications-to-directly-access-files-in-amazon-s3-without-recompiling/","poster":"backbencher2022","timestamp":"1724596440.0"}]},{"comment_id":"1195061","timestamp":"1713027900.0","upvote_count":"4","content":"Selected Answer: ACE\nIn general, Beanstalk is the best option if your priorities are SIMPLICITY and low cost.\nMeanwhile, Fargate is better if you want more control over how your application is hosted, your budget is not especially tight, and your application can be containerized.","poster":"Zas1"},{"comment_id":"1194874","timestamp":"1713004500.0","content":"ACE are correct","poster":"devnv","upvote_count":"1"}],"answer_images":[],"answer":"ACE","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/138593-exam-aws-certified-solutions-architect-professional-sap-c02/","exam_id":33,"unix_timestamp":1713004500,"question_id":420,"isMC":true,"question_text":"A company is running a three-tier web application in an on-premises data center. The frontend is served by an Apache web server, the middle tier is a monolithic Java application, and the storage tier is a PostgreSQL database.\n\nDuring a recent marketing promotion, customers could not place orders through the application because the application crashed. An analysis showed that all three tiers were overloaded. The application became unresponsive, and the database reached its capacity limit because of read operations. The company already has several similar promotions scheduled in the near future.\n\nA solutions architect must develop a plan for migration to AWS to resolve these issues. The solution must maximize scalability and must minimize operational effort\n\nWhich combination of steps will meet these requirements? (Choose three.)","timestamp":"2024-04-13 12:35:00","question_images":[]}],"exam":{"isBeta":false,"provider":"Amazon","lastUpdated":"11 Apr 2025","isImplemented":true,"name":"AWS Certified Solutions Architect - Professional SAP-C02","id":33,"isMCOnly":true,"numberOfQuestions":529},"currentPage":84},"__N_SSP":true}