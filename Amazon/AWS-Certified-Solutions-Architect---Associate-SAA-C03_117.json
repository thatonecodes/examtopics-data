{"pageProps":{"questions":[{"id":"l69zN8KaAq3JJVbHQ9f4","isMC":true,"question_images":[],"answer_images":[],"answer_ET":"B","exam_id":31,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/121211-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company recently migrated to the AWS Cloud. The company wants a serverless solution for large-scale parallel on-demand processing of a semistructured dataset. The data consists of logs, media files, sales transactions, and IoT sensor data that is stored in Amazon S3. The company wants the solution to process thousands of items in the dataset in parallel.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","choices":{"D":"Use several AWS Lambda functions to process the data in parallel.","C":"Use AWS Glue to process the data in parallel.","B":"Use the AWS Step Functions Map state in Distributed mode to process the data in parallel.","A":"Use the AWS Step Functions Map state in Inline mode to process the data in parallel."},"unix_timestamp":1695414720,"answers_community":["B (96%)","4%"],"answer_description":"","discussion":[{"comment_id":"1015233","poster":"Guru4Cloud","content":"Selected Answer: B\nAWS Step Functions allows you to orchestrate and scale distributed processing using the Map state. The Map state can process items in a large dataset in parallel by distributing the work across multiple resources.\nUsing the Map state in Distributed mode will automatically handle the parallel processing and scaling. Step Functions will add more workers to process the data as needed.\nStep Functions is serverless so there are no servers to manage. It will scale up and down automatically based on demand.","upvote_count":"9","timestamp":"1695494940.0"},{"upvote_count":"1","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/step-functions/latest/dg/sample-dist-map-s3data-process.html\nWith Step Functions, you can orchestrate large-scale parallel workloads to perform tasks, such as on-demand processing of semi-structured data. These parallel workloads let you concurrently process large-scale data sources stored in Amazon S3. For example, you might process a single JSON or CSV file that contains large amounts of data. Or you might process a large set of Amazon S3 objects.","poster":"FlyingHawk","comments":[{"comment_id":"1345075","content":"A - AWS Step Function Map State in inline mode accepts only a JSON array as input and supports up to 40 concurrent iterations.","poster":"FlyingHawk","upvote_count":"1","timestamp":"1737603960.0"}],"comment_id":"1345074","timestamp":"1737603780.0"},{"timestamp":"1720482900.0","comment_id":"1244613","upvote_count":"2","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/step-functions/latest/dg/use-dist-map-orchestrate-large-scale-parallel-workloads.html","poster":"Sandy1254"},{"timestamp":"1719654900.0","content":"Selected Answer: C\nUsing step functions will be overwill from my point of view. I would use Glue, it’s serverless and purposely designed for such use case","upvote_count":"1","comment_id":"1239197","poster":"bogdannb"},{"upvote_count":"3","poster":"Lin878","timestamp":"1719107820.0","content":"Selected Answer: B\nSimple - user Lambda / Complex - user Step Functions","comment_id":"1235670"},{"timestamp":"1706132880.0","content":"A Map in Inline mode can support concurrency of 40 parallel branches and execution history limits of 25,000 events or approximately 6,500 state transitions in a workflow. With the Distributed mode, you can run at concurrency of up to 10,000 parallel branches. So I believe if it has to process thousands of items in parallel Distributed Mode is more appropriate","comment_id":"1131152","poster":"Lx016","upvote_count":"4"},{"upvote_count":"3","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/aws/step-functions-distributed-map-a-serverless-solution-for-large-scale-parallel-data-processing/\nhttps://docs.aws.amazon.com/step-functions/latest/dg/sample-dist-map-s3data-process.html","timestamp":"1705050180.0","poster":"awsgeek75","comment_id":"1120596"},{"upvote_count":"3","timestamp":"1701081720.0","comment_id":"1081415","content":"Selected Answer: B\nThe Distributed Map has been optimized for Amazon S3.,helping you more easily iterate over objects in an S3 bucket. With the Distributed mode, you can run at concurrency of up to 10,000 parallel branches.\n\nhttps://aws.amazon.com/step-functions/faqs/#:~:text=A%20Map%20in%20Inline%20mode,up%20to%2010%2C000%20parallel%20branches.","poster":"TariqKipkemei"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/step-functions/latest/dg/concepts-orchestrate-large-scale-parallel-workloads.html","upvote_count":"2","comment_id":"1016666","timestamp":"1695634200.0","poster":"Sugarbear_01"},{"poster":"taustin2","comment_id":"1014501","content":"Selected Answer: B\nWith Step Functions, you can orchestrate large-scale parallel workloads to perform tasks, such as on-demand processing of semi-structured data. These parallel workloads let you concurrently process large-scale data sources stored in Amazon S3. https://docs.aws.amazon.com/step-functions/latest/dg/concepts-orchestrate-large-scale-parallel-workloads.html","upvote_count":"3","timestamp":"1695415920.0","comments":[{"comment_id":"1015519","poster":"Sugarbear_01","timestamp":"1695535860.0","upvote_count":"2","content":"After going through the link I confirmed the answer is B"}]},{"timestamp":"1695414720.0","comment_id":"1014491","upvote_count":"2","poster":"[Removed]","content":"Large Scale + Parallel = Distributed Step Function\n\nhttps://docs.aws.amazon.com/step-functions/latest/dg/concepts-inline-vs-distributed-map.html"}],"answer":"B","timestamp":"2023-09-22 22:32:00","question_id":581},{"id":"3rD9Ju2lgK4yX7LDp7nq","isMC":true,"question_id":582,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/121186-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2023-09-22 16:12:00","choices":{"D":"Order multiple AWS Snowball devices. Copy the data to the devices. Send the devices to AWS to copy the data to Amazon S3.","A":"Configure AWS DataSync to migrate the data to Amazon S3 and to automatically verify the data.","B":"Use rsync to transfer the data directly to Amazon S3.","C":"Use the AWS CLI and multiple copy processes to send the data directly to Amazon S3."},"answers_community":["D (93%)","7%"],"topic":"1","unix_timestamp":1695391920,"discussion":[{"content":"7 Years, 5 Months, 3 Weeks, 5 Days required to transfer 10PB on 400 Mbps. Finger cross the upload don't drop or timeout on year 7.","comments":[{"content":"As a data engineer, this comment made both laugh and shudder at the same time -- hits too close to home","poster":"zits88","timestamp":"1724065380.0","upvote_count":"2","comment_id":"1268592"}],"timestamp":"1703068320.0","poster":"Cyberkayu","upvote_count":"12","comment_id":"1101441"},{"comment_id":"1081420","poster":"TariqKipkemei","timestamp":"1701081840.0","content":"Selected Answer: D\nPB = snowball","upvote_count":"6"},{"comment_id":"1162756","upvote_count":"3","content":"Selected Answer: D\nTo calculate the total time required in weeks, we can use the result we obtained earlier, which was approximately \n6.26\n×\n1\n0\n10\n6.26×10 \n10\n weeks.\n\nSo, the total time required to transfer 10 PB of data to Amazon S3, given a 500 Mbps uplink, would be approximately \n6.26\n×\n1\n0\n10\n6.26×10 \n10\n weeks. However, this is an extremely large value and not practically feasible.\n\nIt's important to note that the result obtained might not accurately reflect real-world scenarios due to various factors such as network limitations, bandwidth constraints, and other practical considerations. Additionally, this calculation assumes a constant transfer rate and does not consider potential optimizations or parallelization techniques that could be employed to expedite the data transfer process.","poster":"Ravan","timestamp":"1709220000.0"},{"poster":"awsgeek75","comment_id":"1120609","comments":[{"poster":"awsgeek75","timestamp":"1705050720.0","upvote_count":"7","content":"Answer is D! not A! Fiddly fingers!","comment_id":"1120612"}],"upvote_count":"2","content":"Selected Answer: A\n10PB on 80% of 500Mbps (Megabits not Megabytes) will take 6.5 years. But for the sake of exam when you cannot use calculators etc, just use snowball for petabytes of transfer if it is an option!","timestamp":"1705050660.0"},{"content":"D, but even if you do not know, all 3 option (A,B and C) have the same nature ( transfer via bandwidth ) and we know that there is only one correct answer => D.","timestamp":"1698600420.0","poster":"wsdasdasdqwdaw","upvote_count":"4","comment_id":"1057026"},{"content":"Selected Answer: D\nsnowball for sure","poster":"iwannabeawsgod","comment_id":"1047314","upvote_count":"3","timestamp":"1697670480.0"},{"timestamp":"1696381440.0","upvote_count":"3","comment_id":"1024311","content":"Selected Answer: D\n1Gbps will roughly do 7 TB in 24 hours. This means 400Mbps will only do 3x42TB.","poster":"joshik"},{"poster":"Xin123","content":"D\n1Gbps will roughly do 7 TB in 24 hours. This means 400Mbps will only do 3x42TB.","upvote_count":"3","timestamp":"1695771480.0","comment_id":"1018265"},{"poster":"Sugarbear_01","upvote_count":"3","comment_id":"1016669","timestamp":"1695634260.0","content":"Selected Answer: D\nD\n1Gbps will roughly do 7 TB in 24 hours. This means 400Mbps will only do 3x42TB."},{"comment_id":"1015372","timestamp":"1695511980.0","poster":"Devsin2000","content":"D\n1Gbps will roughly do 7 TB in 24 hours. This means 400Mbps will only do 3x42TB.","upvote_count":"2"},{"upvote_count":"2","poster":"Guru4Cloud","content":"Selected Answer: D\nD. Order multiple AWS Snowball devices. Copy the data to the devices. Send the devices to AWS to copy the data to Amazon S3.","timestamp":"1695499740.0","comment_id":"1015309"},{"content":"Selected Answer: D\n10 PB = It's Snowballs.","upvote_count":"5","poster":"taustin2","comment_id":"1014505","timestamp":"1695416160.0"},{"poster":"kambarami","timestamp":"1695391920.0","comment_id":"1014192","upvote_count":"3","content":"Answer is DDDDD"}],"answer_images":[],"answer_description":"","answer_ET":"D","answer":"D","exam_id":31,"question_text":"A company will migrate 10 PB of data to Amazon S3 in 6 weeks. The current data center has a 500 Mbps uplink to the internet. Other on-premises applications share the uplink. The company can use 80% of the internet bandwidth for this one-time migration task.\n\nWhich solution will meet these requirements?"},{"id":"NsPGozkA52jXGDmTV0Nj","question_text":"A company has several on-premises Internet Small Computer Systems Interface (ISCSI) network storage servers. The company wants to reduce the number of these servers by moving to the AWS Cloud. A solutions architect must provide low-latency access to frequently used data and reduce the dependency on on-premises servers with a minimal number of infrastructure changes.\n\nWhich solution will meet these requirements?","discussion":[{"comment_id":"1015307","timestamp":"1711231740.0","content":"Selected Answer: D\nThe key reasons are:\n\nThe Storage Gateway volume gateway provides iSCSI block storage using cached volumes. This allows replacing the on-premises iSCSI servers with minimal changes.\nCached volumes store frequently accessed data locally for low latency access, while storing less frequently accessed data in S3.\nThis reduces the number of on-premises servers while still providing low latency access to hot data.\nEBS does not provide iSCSI support to replace the existing servers.\nS3 File Gateway is for file storage, not block storage.\nStored volumes would store all data on-premises, not in S3.","upvote_count":"9","poster":"Guru4Cloud"},{"timestamp":"1720768560.0","content":"Selected Answer: D\nLow latency = always look for cache or local storage.\nA: Doesn't address low latency\nB: Don't think this is possible\nCD are both low latency but D is better:\nhttps://aws.amazon.com/storagegateway/faqs/#:~:text=In%20the%20cached%20mode%2C%20your,asynchronously%20backed%20up%20to%20AWS.","upvote_count":"3","comment_id":"1120619","poster":"awsgeek75"},{"content":"Selected Answer: D\nlow-latency access to frequently used data = cached volumes","poster":"TariqKipkemei","upvote_count":"4","comment_id":"1081421","timestamp":"1716799560.0"},{"comment_id":"1015540","timestamp":"1711270080.0","upvote_count":"2","poster":"Sugarbear_01","content":"Answer D \n\nHere is the link ; \nhttps://docs.aws.amazon.com/storagegateway/latest/vgw/WhatIsStorageGateway.html"},{"comment_id":"1014509","content":"Selected Answer: D\nISCI=Volume Gateway. \nlow-latency access to frequently used data = cached volumes","timestamp":"1711148280.0","poster":"taustin2","upvote_count":"4"},{"comment_id":"1014493","timestamp":"1711147200.0","upvote_count":"2","poster":"[Removed]","content":"\"low-latency access to FREQUENTLY used data\" = Cached AWS Storage Gateway volumes"},{"timestamp":"1711112100.0","upvote_count":"3","comment_id":"1013995","content":"Selected Answer: D\nAn AWS Storage Gateway volume gateway is a hybrid storage solution that connects your on-premises applications to your cloud storage. It provides low-latency access to frequently used data while storing your entire dataset in the cloud.\n\nWhen you configure an AWS Storage Gateway volume gateway with cached volumes, the gateway stores a copy of frequently accessed data locally. This allows you to provide low-latency access to your frequently accessed data while reducing your dependency on on-premises servers.","poster":"nnecode"}],"question_images":[],"topic":"1","answer_description":"","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/121170-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2023-09-22 12:55:00","answer":"D","choices":{"C":"Deploy an AWS Storage Gateway volume gateway that is configured with stored volumes.","B":"Deploy Amazon Elastic Block Store (Amazon EBS) storage with backups to Amazon S3.","A":"Deploy an Amazon S3 File Gateway.","D":"Deploy an AWS Storage Gateway volume gateway that is configured with cached volumes."},"answer_images":[],"exam_id":31,"answers_community":["D (100%)"],"question_id":583,"unix_timestamp":1695380100,"isMC":true},{"id":"zR85RhKvbgIyFNCpaTA7","question_text":"A solutions architect is designing an application that will allow business users to upload objects to Amazon S3. The solution needs to maximize object durability. Objects also must be readily available at any time and for any length of time. Users will access objects frequently within the first 30 days after the objects are uploaded, but users are much less likely to access objects that are older than 30 days.\n\nWhich solution meets these requirements MOST cost-effectively?","choices":{"D":"Store all the objects in S3 Intelligent-Tiering with an S3 Lifecycle rule to transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.","B":"Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.","A":"Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 Glacier after 30 days.","C":"Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days."},"unix_timestamp":1695416520,"exam_id":31,"answer_images":[],"answer_ET":"B","isMC":true,"answers_community":["B (78%)","C (22%)"],"answer":"B","answer_description":"","topic":"1","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/121214-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"timestamp":"1695586080.0","comment_id":"1016150","upvote_count":"5","content":"Selected Answer: B\nMinimum Days for Transition to S3 Standard-IA or S3 One Zone-IA\n\nBefore you transition objects to S3 Standard-IA or S3 One Zone-IA, you must store them for at least 30 days in Amazon S3. For example, you cannot create a Lifecycle rule to transition objects to the S3 Standard-IA storage class one day after you create them. Amazon S3 doesn't support this transition within the first 30 days because newer objects are often accessed more frequently or deleted sooner than is suitable for S3 Standard-IA or S3 One Zone-IA storage.\n\nSimilarly, if you are transitioning noncurrent objects (in versioned buckets), you can transition only objects that are at least 30 days noncurrent to S3 Standard-IA or S3 One Zone-IA storage.\n\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-transition-general-considerations.html","poster":"Sugarbear_01"},{"comments":[{"content":"No, both Standard-IA and OZ-IA have SAME durability. What differs it the availability.\n\nDurability is calculated based on how many times the data is copied and made redundant, inherently by the service itself. But that redundancy can be across one building (AZ) or multiple availability zones.","upvote_count":"2","timestamp":"1726505100.0","poster":"MatAlves","comment_id":"1284866"}],"upvote_count":"3","timestamp":"1722257460.0","content":"Answer is B. \n\nC is wrong because one-zone doesn't maximize durability, it compromises it.","comment_id":"1257484","poster":"abriggy"},{"poster":"TheLaPlanta","timestamp":"1710724140.0","upvote_count":"4","comment_id":"1176155","content":"Selected Answer: C\nI believe it's C. The following link mentions One Zone-IA offers 99.999999999% durability. Questions says nothing about HA"},{"comment_id":"1087285","content":"B\nIntelligent tiering will automatically transition to S3 One Zone-IA which is not needed for durability.","timestamp":"1701657360.0","upvote_count":"2","poster":"SHAAHIBHUSHANAWS"},{"comment_id":"1082241","content":"Selected Answer: B\n'Objects also must be readily available at any time and for any length of time'…definitely option B.","timestamp":"1701155040.0","upvote_count":"3","poster":"TariqKipkemei"},{"upvote_count":"2","poster":"potomac","content":"Selected Answer: B\nB is correct","comment_id":"1064292","timestamp":"1699307760.0"},{"comment_id":"1050770","poster":"thanhnv142","content":"B is correct\nC is not correct because data must be durable. C is only for data that can be regenerated.","timestamp":"1697986500.0","upvote_count":"4"},{"upvote_count":"2","comment_id":"1018335","timestamp":"1695778140.0","poster":"Xin123","content":"Selected Answer: B\nDurability. Available any time for any duration => B"},{"upvote_count":"4","poster":"Devsin2000","timestamp":"1695512520.0","content":"A\nS3 Glacier is most cost effective","comments":[{"timestamp":"1705051260.0","content":"Between A & B, this is the tie-breaker:\n\"Objects also must be readily available at any time and for any length of time\"\n\nWhile Glacier IS more cost effective but it won't make the objects readily available at any time for any duration.... this is only possible with IA.","poster":"awsgeek75","upvote_count":"2","comment_id":"1120623"}],"comment_id":"1015375"},{"comment_id":"1014510","poster":"taustin2","content":"Selected Answer: B\nB meets the requirements. No need for intelligent Tiering because of 30 days.","timestamp":"1695416520.0","upvote_count":"2"}],"timestamp":"2023-09-22 23:02:00","question_id":584},{"id":"AufKUDdVTb4xYQEHCsuJ","topic":"1","answer":"C","answer_images":[],"answers_community":["C (100%)"],"isMC":true,"question_text":"A company has migrated a two-tier application from its on-premises data center to the AWS Cloud. The data tier is a Multi-AZ deployment of Amazon RDS for Oracle with 12 TB of General Purpose SSD Amazon Elastic Block Store (Amazon EBS) storage. The application is designed to process and store documents in the database as binary large objects (blobs) with an average document size of 6 MB.\n\nThe database size has grown over time, reducing the performance and increasing the cost of storage. The company must improve the database performance and needs a solution that is highly available and resilient.\n\nWhich solution will meet these requirements MOST cost-effectively?","question_id":585,"exam_id":31,"answer_ET":"C","question_images":[],"discussion":[{"comment_id":"1120629","content":"Selected Answer: C\nWhen using BLOB, always try to pick a solution with S3.","poster":"awsgeek75","upvote_count":"5","timestamp":"1720769040.0"},{"poster":"ferdzcruz","timestamp":"1721439300.0","comment_id":"1127038","content":"process and store documents as objects. S3 is known for object storage.","upvote_count":"4"},{"upvote_count":"3","comment_id":"1082248","poster":"TariqKipkemei","content":"Selected Answer: C\nMOST cost-effectively = store the objects in S3, and object metadata in the existing DB.","timestamp":"1716873360.0"},{"upvote_count":"3","content":"DynamoDB's limit on the size of each record is 400KB, so D is wrong.","timestamp":"1711293960.0","comment_id":"1015823","poster":"taustin2"},{"poster":"Guru4Cloud","content":"Selected Answer: C\nC. Create an Amazon S3 bucket. Update the application to store documents in the S3 bucket. Store the object metadata in the existing database.","timestamp":"1711231440.0","upvote_count":"4","comment_id":"1015304"},{"upvote_count":"4","poster":"taustin2","comment_id":"1014511","timestamp":"1711148640.0","content":"Selected Answer: C\nStoring the blobs in the db is more expensive than s3 with references in the db."}],"url":"https://www.examtopics.com/discussions/amazon/view/121215-exam-aws-certified-solutions-architect-associate-saa-c03/","choices":{"D":"Create an Amazon DynamoDB table. Update the application to use DynamoDB. Use AWS Database Migration Service (AWS DMS) to migrate data from the Oracle database to DynamoDB.","A":"Reduce the RDS DB instance size. Increase the storage capacity to 24 TiB. Change the storage type to Magnetic.","B":"Increase the RDS DB instance size. Increase the storage capacity to 24 TiChange the storage type to Provisioned IOPS.","C":"Create an Amazon S3 bucket. Update the application to store documents in the S3 bucket. Store the object metadata in the existing database."},"unix_timestamp":1695416640,"timestamp":"2023-09-22 23:04:00","answer_description":""}],"exam":{"id":31,"name":"AWS Certified Solutions Architect - Associate SAA-C03","isMCOnly":true,"lastUpdated":"11 Apr 2025","provider":"Amazon","numberOfQuestions":1019,"isBeta":false,"isImplemented":true},"currentPage":117},"__N_SSP":true}