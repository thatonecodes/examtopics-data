{"pageProps":{"questions":[{"id":"A3mOx75tDYebLZqzebQb","timestamp":"2022-10-26 12:49:00","url":"https://www.examtopics.com/discussions/amazon/view/86460-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"question_text":"An Amazon EC2 administrator created the following policy associated with an IAM group containing several users:\n//IMG//\n\nWhat is the effect of this policy?","answers_community":["C (72%)","D (28%)"],"topic":"1","question_id":976,"answer_description":"","answer":"C","choices":{"B":"Users can terminate an EC2 instance with the IP address 10.100.100.1 in the us-east-1 Region.","D":"Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.","A":"Users can terminate an EC2 instance in any AWS Region except us-east-1.","C":"Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254."},"exam_id":31,"discussion":[{"upvote_count":"71","poster":"Joxtat","timestamp":"1672847940.0","comment_id":"765848","comments":[{"poster":"KMohsoe","content":"Nice explanation. Thanks","timestamp":"1683857580.0","upvote_count":"4","comment_id":"895590"}],"content":"What the policy means:\n1. Allow termination of any instance if user’s source IP address is 100.100.254.\n2. Deny termination of instances that are not in the us-east-1 Combining this two, you get:\n“Allow instance termination in the us-east-1 region if the user’s source IP address is 10.100.100.254. Deny termination operation on other regions.”"},{"comments":[{"timestamp":"1684691340.0","content":"A good explanation!","upvote_count":"3","comment_id":"903434","poster":"Bmarodi"}],"upvote_count":"35","content":"C is correct.\n0.0/24 , the following five IP addresses are reserved:\n0.0: Network address.\n0.1: Reserved by AWS for the VPC router.\n0.2: Reserved by AWS. The IP address of the DNS server is the base of the VPC network range plus two. ...\n0.3: Reserved by AWS for future use.\n0.255: Network broadcast address.","timestamp":"1669953840.0","comment_id":"733433","poster":"Subh_fidelity"},{"upvote_count":"1","content":"Selected Answer: C\nIt is C. Because the keyword \"SourceIp\". Thats what distinguishes C and D.","timestamp":"1738177980.0","comment_id":"1348727","poster":"Dharmarajan"},{"upvote_count":"1","comment_id":"1347811","timestamp":"1738056420.0","poster":"itsmeDiyan","content":"Selected Answer: C\nUncle Trump says so"},{"content":"Selected Answer: C\nAns C - must be in us-east-1 region and CIDR address is in allowable range (/24)","upvote_count":"2","timestamp":"1726426260.0","poster":"PaulGa","comment_id":"1284244"},{"content":"Selected Answer: C\nThe first rule allows users with the specified IP CIDR to terminate instances, and the second rule specifies that the region must be us-east-1 for the termination process to be allowed, hence C is the correct answer.","upvote_count":"2","timestamp":"1721577420.0","poster":"jaradat02","comment_id":"1252555"},{"comment_id":"1241150","poster":"jatric","timestamp":"1719981240.0","upvote_count":"3","content":"Selected Answer: C\npolicy allow us-east-1 and with the specific IP address in the range"},{"comment_id":"1231798","poster":"ChymKuBoy","timestamp":"1718607300.0","upvote_count":"1","content":"Selected Answer: C\nC for sure"},{"comment_id":"1189570","poster":"jhoiti","upvote_count":"2","content":"Selected Answer: D\nD. Users cannot terminate an EC2 instance in the us-east-1 region when the user's source IP is 10.100.100.254.\n\nThis option corresponds to the second statement in the policy, where all EC2 actions in the \"us-east-1\" region are denied permission when the user's source IP is \"10.100.100.254\".","timestamp":"1712273340.0","comments":[{"upvote_count":"4","timestamp":"1716813600.0","comment_id":"1219550","poster":"lofzee","content":"but it says \"StringNotEquals\" meaning everything is denied apart from us-east-1"}]},{"upvote_count":"5","content":"Selected Answer: C\nClearly the answer is C.\nD is 'Deny' 'String NOT equal' == only allow us-east-1","timestamp":"1708066680.0","comment_id":"1151787","poster":"vip2"},{"poster":"awsgeek75","content":"Selected Answer: C\nHere is how I interpreted this\nfirst part: terminate instance is allowed for the given CIDR block\nsecond part: deny all ec2 actions when region is not us-east-1\n\nso second part is like double negative which means allow for us-east-1 region\n\nYou combine both (remember deny always take priority which is why this is written in double negative) and you get:\n[allow us-east-region1 to do any action on ec2] when [action is terminate instance and CIDR block is match]\nso C is the answer\nD is there to confuse you with the double negative","timestamp":"1705270620.0","comment_id":"1122916","upvote_count":"3"},{"timestamp":"1703510280.0","comment_id":"1105293","poster":"pentium75","upvote_count":"4","content":"Selected Answer: C\nDeny takes precedence over Allow. Thus the flow is as follows:\n\nIF region of the EC2 instance is not \"us-east-1\" -> Deny\nELSE if request is coming from 10.100.100.0/24 -> Allow\nELSE: implicit deny (what is not allowed is denied)"},{"comment_id":"1089238","poster":"Cyberkayu","timestamp":"1701861180.0","upvote_count":"5","content":"if\nIP = 10.100.100.0/24\nallow terminate EC2\n\nElse\nDeny EC2 termination permission\n- with the condition \"String NOT equal\" to us-east-1\n\nAnswer C"},{"content":"Selected Answer: D\nThe first statement allows users to terminate EC2 instances (ec2:TerminateInstances) from any IP address within the range 10.100.100.0/24.\nThe second statement denies users the ability to perform any EC2 actions (ec2:*) in any region other than us-east-1.\nSo, the correct interpretation is:\n\nD. Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254","comments":[{"timestamp":"1703510160.0","comment_id":"1105292","poster":"pentium75","content":"D denies \"the ability to perform any actions in any region OTHER than us-east-1\". Thus the user CAN terminate instances IN us-east-1. Thus C.","upvote_count":"2"}],"upvote_count":"1","timestamp":"1700428260.0","poster":"Bjfikky","comment_id":"1074931"},{"poster":"sweetheatmn","comment_id":"1049779","upvote_count":"1","content":"Selected Answer: C\nC because the explicit deny blocks other regions than us-east-1","timestamp":"1697916660.0"},{"poster":"tom_cruise","timestamp":"1696963800.0","comment_id":"1039781","content":"Selected Answer: C\nThe first statement is a subset of the second statement.","upvote_count":"1"},{"poster":"prabhjot","timestamp":"1696562460.0","comment_id":"1026198","upvote_count":"1","content":"ans D - This policy denies EC2 instance termination for users with the source IP address 10.100.100.254 in the us-east-1 Region."},{"content":"D is not because of Deny & NOT Equals","upvote_count":"1","timestamp":"1695490980.0","comment_id":"1015149","poster":"Subhrangsu"},{"comment_id":"995223","poster":"Valder21","content":"I went for C for obvious reasons\n\nWondering though; this policy also allows to terminate EC2 instances in US-east-1 even if your source IP is not the 10.100.100.254, right? \nThe idea is that since I do not deny this for the other source IP addresses, the Allow action is a obsolete?","upvote_count":"2","timestamp":"1693494360.0"},{"timestamp":"1692851160.0","poster":"TariqKipkemei","comment_id":"988827","upvote_count":"1","content":"Selected Answer: C\nDeny all actions on the EC2 instances in the us-east1 region, but let anyone with source IP 10.100.100.254 be able to terminate the EC2 instances."},{"upvote_count":"2","comment_id":"974758","content":"Answer C:\nExample 4: Granting access to a specific version of an object\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/amazon-s3-policy-keys.html","poster":"prudhvi08","timestamp":"1691417220.0"},{"upvote_count":"5","poster":"RupeC","comment_id":"957355","timestamp":"1689845640.0","comments":[{"poster":"JoeGuan","comment_id":"976638","content":"The Deny statement 'will not' take effect, because the Deny statement is StringNotEquals to US-East-1. That means that any other region that DOES NOT EQUAL Us-East-1 will be denied, if the region is NOT Us-East-1, then DENY. So Us-East-1 is allowed!","upvote_count":"3","comments":[{"timestamp":"1695490920.0","poster":"Subhrangsu","comment_id":"1015148","content":"oh, ok got it now.","upvote_count":"1"}],"timestamp":"1691583780.0"}],"content":"Selected Answer: D\nThe effect of the policy is:\n\nD. Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.\n\nThe policy allows users to terminate EC2 instances only when their source IP is within the range 10.100.100.0/24.\nHowever, there is a Deny statement that blocks users from terminating any EC2 instance in regions other than us-east-1.\nSo, when a user tries to terminate an EC2 instance from the IP 10.100.100.254 in the us-east-1 region, the Deny statement will take effect, and the action will be denied. However, if the user tries to terminate an instance from the 10.100.100.0/24 IP range in any region other than us-east-1, the Deny statement will not apply, and the Allow statement will permit the action."},{"comment_id":"952200","upvote_count":"1","content":"https://cidr.xyz/","timestamp":"1689411180.0","poster":"MNotABot"},{"content":"Selected Answer: C\nUsers can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254. Option C is correct","upvote_count":"2","timestamp":"1684757940.0","poster":"beginnercloud","comment_id":"904021"},{"comment_id":"903422","poster":"Bmarodi","content":"Selected Answer: C\nUsers can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254. Option C is right one.","upvote_count":"3","timestamp":"1684690920.0"},{"upvote_count":"1","poster":"Moccorso","comment_id":"895073","timestamp":"1683809400.0","content":"I think D"},{"upvote_count":"2","comment_id":"877324","poster":"darn","timestamp":"1682171700.0","content":"Selected Answer: C\nits C\nDeny & NOT Equal = CAN (basic logic folks)"},{"content":"Selected Answer: C\nOh... tricky.. TT... C is correct ...","comment_id":"866312","timestamp":"1681133820.0","upvote_count":"1","poster":"shinejh0528"},{"content":"It's C:\ndeny all ec2 if StringEquals: means deny everything unless the region is us-east-1","upvote_count":"1","timestamp":"1680528120.0","comment_id":"859944","poster":"xalien"},{"upvote_count":"1","poster":"alexiscloud","content":"Answer C:","timestamp":"1680074280.0","comment_id":"854115"},{"comment_id":"840643","poster":"Hemanthgowda1932","content":"C is correct answer","upvote_count":"1","timestamp":"1678952400.0"},{"timestamp":"1678869060.0","comments":[{"upvote_count":"1","timestamp":"1681610220.0","poster":"Robrobtutu","comment_id":"871407","content":"The deny rule blocks everyone EXCEPT us-east-1 from deleting EC2 instances."}],"comment_id":"839685","poster":"Mainroad4822","content":"Selected Answer: D\n10.100.100.254 is within the allowed CIDR block. However, it's in us-eas-1 region and deny rules all","upvote_count":"4"},{"timestamp":"1675778280.0","poster":"UnluckyDucky","content":"Selected Answer: C\nIAM Conditions mean you can choose to grant/deny access to principals only if specified conditions are met.\n\nIn our case, StringNotEquals \"us-east-1\" means deny everything unless the region is us-east-1\n\nAn easier way to understand it but less effective ofcourse to achieve the same result would be configuring deny all ec2 if StringEquals: *state any other region except for us-east-1*\n\nCorrect answer is C","upvote_count":"1","comment_id":"800966"},{"timestamp":"1675157160.0","poster":"Chalamalli","comment_id":"793905","content":"D is correct","upvote_count":"2"},{"poster":"Ello2023","content":"Selected Answer: D\nDeny overrules Allow. The first statement allows 100.100.254. but the second statement is denied which is the region us-east-1.","upvote_count":"3","timestamp":"1673811600.0","comment_id":"777003","comments":[{"poster":"bobeagle","content":"StringNotEqual","upvote_count":"4","comment_id":"858030","timestamp":"1680360720.0"},{"upvote_count":"1","poster":"Robrobtutu","content":"The deny applies to all regions that are not us-east-1, therefore, us-east-1 is allowed.","comment_id":"871408","timestamp":"1681610340.0"}]},{"upvote_count":"2","timestamp":"1673811540.0","comment_id":"777002","poster":"Ello2023","content":"Deny overrules Allow. The first statement allows 100.100.254. but the second statement is denied which is the region us-east-1."},{"upvote_count":"2","poster":"imisioluwa","content":"Please disregard the initial answer. D is the CORRECT answer.","comment_id":"772428","timestamp":"1673436120.0"},{"poster":"imisioluwa","content":"C is the correct answer.","comment_id":"772426","timestamp":"1673435940.0","upvote_count":"3"},{"upvote_count":"2","comment_id":"763205","poster":"HayLLlHuK","timestamp":"1672580760.0","content":"as the policy prevents anyone from doing any EC2 action on any region except us-east-1 and allows only users with source ip 10.100.100.0/24 to terminate instances. So user with source ip 10.100.100.254 can terminate instances in us-east-1 region."},{"poster":"techhb","content":"please read carefuly ,it says policy denies all EC2 actions in the if region doesn't not equals us-east-1 region,hence its deny for all regions except us-east-1.,now 1st deny is good but its not applicable for us-east-1,this deny is conditional,hence It will allow us-east-1 with source ip 10.100.100.254","timestamp":"1672187520.0","upvote_count":"1","comment_id":"759197"},{"poster":"Buruguduystunstugudunstuy","comment_id":"752698","comments":[{"content":"Wrong ans guy. You are using ChatGPT. Correct answer is C.","comment_id":"861764","timestamp":"1680671460.0","upvote_count":"2","poster":"jcramos"},{"timestamp":"1671652260.0","upvote_count":"3","comments":[{"content":"You are correct. \"Deny\" overrides \"Allow\". D is the definitely correct answer.\nCIDR discussion is pointless.","poster":"Tys","timestamp":"1672104540.0","comments":[{"timestamp":"1674894720.0","content":"You are correct, pal! \n\nPlease check the detailed answer here: \n\nhttps://stackoverflow.com/questions/46062084/how-to-provide-multiple-stringnotequals-conditions-in-aws-policy/71531863#71531863","upvote_count":"1","comment_id":"790400","poster":"ocbn3wby"},{"timestamp":"1675051020.0","content":"\"StringNotEquals\" is a condition operator used in AWS Identity and Access Management (IAM) policies. It checks if a string value is not equal to the specified string value in the policy statement. If the condition evaluates to true, the action in the policy statement is allowed. If the condition evaluates to false, the action is denied.\nHence, if the condition specified in the \"Condition\" block of a policy statement evaluates to true, then the action defined in the \"Effect\" block (Deny or Allow) will take effect.\n Buruguduystunstugudunstuy is right D","upvote_count":"1","comment_id":"792363","comments":[{"content":"I'm afraid you and Burugudu are not correct on this one. The effect is to deny the action if the string is not us-east-1, hence, us-east-1 is allowed to terminate EC2 instances.","comment_id":"871411","timestamp":"1681610820.0","upvote_count":"2","poster":"Robrobtutu"}],"poster":"gogod2"}],"comment_id":"758043","upvote_count":"1"}],"poster":"Buruguduystunstugudunstuy","comment_id":"752700","content":"***Other Options are WRONG***\n\nOption A is incorrect because the policy does not allow users to terminate EC2 instances in any region. Instead, the policy denies all EC2 actions in all regions except for the us-east-1 region.\n\nOption B is incorrect because the policy does not restrict actions to a specific IP address or to the us-east-1 region. Instead, the policy allows users to terminate any EC2 instance as long as their source IP address is within the range of 10.100.100.0/24, and it denies all EC2 actions in all regions except for the us-east-1 region.\n\nOption C is incorrect because the policy does not allow users to terminate EC2 instances in the us-east-1 region when their source IP is 10.100.100.254. Instead, the policy denies all EC2 actions in the us-east-1 region when the user's source IP is 10.100.100.254."}],"content":"Selected Answer: D\nThe correct answer is D. Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.\n\nThe policy contains two statements. The first statement allows users to terminate any EC2 instance as long as the user's source IP address is within the range of 10.100.100.0/24. \n\nThe second statement denies all EC2 actions (indicated by the \"ec2:\" action) for all resources (\"\") except in the us-east-1 region. Since the second statement has a higher priority than the first statement, users who have a source IP address of 10.100.100.254 will not be able to terminate an EC2 instance in the us-east-1 region.","timestamp":"1671652020.0","upvote_count":"4"},{"content":"Selected Answer: C\nC is correct","timestamp":"1671403380.0","comment_id":"749258","upvote_count":"2","poster":"career360guru"},{"content":"A : Should be 'Users can terminate an EC2 instance in us-east-1.' \nB : 10.100.100.0 / 10.100.100.1 / 10.100.100.2 / 10.100.100.3 / 10.100.100.255 are reserved\nC : correct\nD : Users 'can' terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.","timestamp":"1671302700.0","comment_id":"748301","upvote_count":"3","poster":"Ouk"},{"timestamp":"1669049760.0","upvote_count":"2","comment_id":"723764","poster":"Wpcorgan","content":"C is correct"},{"content":"Selected Answer: C\nOption C is the correct answer. \n\n if CIDR block 10.100.100.0/24, then reserved IP addresses are:\n• 10.100.100.0 – Network Address\n• 10.100.100.1 – reserved by AWS for the VPC router\n• 10.100.100.2 – reserved by AWS for mapping to Amazon-provided DNS\n• 10.100.100.3 – reserved by AWS for future use\n• 10.100.100.255 – Network Broadcast Address. AWS does not support broadcast in a VPC,\n\nThe above numbers cannot be used. This rules out the option B","upvote_count":"6","comment_id":"719187","poster":"rjam","timestamp":"1668555960.0"},{"timestamp":"1668370440.0","upvote_count":"2","comment_id":"717500","poster":"Jtic","content":"Selected Answer: C\nshould be Last IP 10.100.100.254 \n\nNot an option\n10.100.100.1: Reserved by AWS for the VPC router"},{"timestamp":"1666781340.0","content":"Selected Answer: C\nhttps://www.examtopics.com/discussions/amazon/view/27814-exam-aws-certified-solutions-architect-associate-saa-c02/","comment_id":"704585","upvote_count":"5","poster":"masetromain"}],"question_images":["https://img.examtopics.com/aws-certified-solutions-architect-associate-saa-c03/image1.png"],"answer_ET":"C","unix_timestamp":1666781340,"isMC":true},{"id":"MBZB3ntLvFqJBJsrCFHr","answers_community":["A (82%)","B (18%)"],"answer_ET":"A","question_text":"A consumer survey company has gathered data for several years from a specific geographic region. The company stores this data in an Amazon S3 bucket in an AWS Region.\n\nThe company has started to share this data with a marketing firm in a new geographic region. The company has granted the firm's AWS account access to the S3 bucket. The company wants to minimize the data transfer costs when the marketing firm requests data from the S3 bucket.\n\nWhich solution will meet these requirements?","topic":"1","isMC":true,"answer_images":[],"answer_description":"","choices":{"C":"Configure AWS Resource Access Manager to share the S3 bucket with the marketing firm AWS account.","D":"Configure the company’s S3 bucket to use S3 Intelligent-Tiering Sync the S3 bucket to one of the marketing firm’s S3 buckets.","A":"Configure the Requester Pays feature on the company’s S3 bucket.","B":"Configure S3 Cross-Region Replication (CRR) from the company’s S3 bucket to one of the marketing firm’s S3 buckets."},"question_id":977,"unix_timestamp":1723378500,"timestamp":"2024-08-11 14:15:00","discussion":[{"comment_id":"1336978","timestamp":"1736142240.0","upvote_count":"1","content":"Selected Answer: A\nRead again - \"The company wants to minimize the data transfer costs when the marketing firm requests data from the S3 bucket.\"\n\nSo as long as the company saves money, bravo. We don't care about the marketing firm. When enabling Requester Pays, the marketing firm (requester) pays for the costs of data requests and data transfer out of the S3 bucket, instead of the data owner (the consumer survey company).\n\nB - CRR does not inherently reduce costs. In fact, replication incurs additional storage and transfer costs for the data owner, who would still bear the cost of replication, which contradicts the requirement to minimize their own data transfer costs.\nC - RAM is used to share resources like S3 buckets, but it doesn't affect data transfer costs.\nD - This helps reduce storage costs by moving objects between storage classes based on access patterns, but it doesn't reduce data transfer costs for requests made by the marketing firm.","poster":"LeonSauveterre"},{"comment_id":"1332143","content":"Selected Answer: B\nThe correct answer is B. Configure S3 Cross-Region Replication (CRR) from the company’s S3 bucket to one of the marketing firm’s S3 buckets.\n\nExplanation:\n\nOption A: Incorrect. The Requester Pays feature can help distribute the cost of data requests by billing the requestor, but it does not reduce the overall data transfer costs. It only shifts who pays for the data transfer, not the amount.\n\nOption B: Correct. S3 Cross-Region Replication (CRR) replicates the data to a bucket in the marketing firm's region. This allows the marketing firm to access the data from a local region, minimizing cross-region data transfer charges each time data is accessed.","timestamp":"1735252920.0","upvote_count":"1","poster":"Anyio"},{"comment_id":"1320425","timestamp":"1733021040.0","content":"Selected Answer: B\nThis is the same question as question 88. One difference is \"it's data transfer costs\" in question 88. Here it is \"minimize the data transfer costs\". A or B can be correct based on whether they are asking for reducing data transfer costs for survey company or both of them.","upvote_count":"1","poster":"ARV14"},{"poster":"AMEJack","comment_id":"1319580","timestamp":"1732862640.0","upvote_count":"1","content":"Selected Answer: A\nSorry that was for the next question."},{"content":"Selected Answer: A\nA. Configure the Requester Pays feature on the company's S3 bucket.\n\nExplanation:\n\nA. Configuring the Requester Pays feature on the company's S3 bucket is the most appropriate solution. With Requester Pays, the marketing firm's AWS account will be responsible for the data transfer costs when accessing the data in the S3 bucket, minimizing the data transfer costs for the consumer survey company.\n\nB. Configuring S3 Cross-Region Replication (CRR) from the company's S3 bucket to one of the marketing firm's S3 buckets would not be the most cost-effective solution, as the company would still be responsible for the data transfer costs.","timestamp":"1728475020.0","upvote_count":"3","poster":"martinadurcakova1","comment_id":"1295129"},{"poster":"MatAlves","content":"The Requester Pays feature allows the bucket owner to offload the data transfer costs to the requester. When this feature is enabled, the marketing firm would pay for the data transfer when they access the data in the survey company's S3 bucket, which effectively minimizes costs for the survey company.\n\nThis means that the most cost-effective solution for the survey company, given that the marketing firm is accessing the data, is \"A\"","timestamp":"1727114520.0","comment_id":"1288266","upvote_count":"2"},{"poster":"[Removed]","content":"Answer B seems to be more logic, the question didn't mention which account will pay","timestamp":"1724549040.0","comments":[{"upvote_count":"1","content":"question ask for method to reduce cost in survey company, so A will do it","poster":"Abdullah2004","timestamp":"1725125880.0","comment_id":"1275700"}],"comment_id":"1271963","upvote_count":"1"},{"poster":"[Removed]","content":"Selected Answer: A\nA sounds right","timestamp":"1724003220.0","comment_id":"1268181","upvote_count":"2"},{"timestamp":"1723454760.0","comment_id":"1264575","upvote_count":"2","content":"Selected Answer: A\nLetter A","poster":"JunsK1e"},{"upvote_count":"4","poster":"pujithacg8","timestamp":"1723378500.0","comment_id":"1264115","content":"A is the correct answer \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html"}],"exam_id":31,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/145552-exam-aws-certified-solutions-architect-associate-saa-c03/","answer":"A"},{"id":"KqNKSe9rUuyDLI06Sr4H","question_text":"A company uses AWS to host its public ecommerce website. The website uses an AWS Global Accelerator accelerator for traffic from the internet. The Global Accelerator accelerator forwards the traffic to an Application Load Balancer (ALB) that is the entry point for an Auto Scaling group.\n\nThe company recently identified a DDoS attack on the website. The company needs a solution to mitigate future attacks.\n\nWhich solution will meet these requirements with the LEAST implementation effort?","answers_community":["C (85%)","A (15%)"],"exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/145442-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","unix_timestamp":1723344000,"discussion":[{"timestamp":"1724077560.0","comment_id":"1268771","upvote_count":"9","poster":"[Removed]","content":"Selected Answer: C\nC as AWS WAF cannot be used directly on global accelerator","comments":[{"comment_id":"1327561","poster":"dragossky","content":"it can be used, but to block HTTP/HTTPS requests.","timestamp":"1734372300.0","upvote_count":"1"}]},{"timestamp":"1726327680.0","upvote_count":"5","comment_id":"1283692","poster":"rpmaws","content":"Selected Answer: C\nWAF can be applied on ALB, API gateway or cloud front."},{"content":"Selected Answer: C\nAnswer is C.\nNote: AWS Global Accelerator itself doesn't support AWS WAF.\n\nhttps://repost.aws/knowledge-center/globalaccelerator-aws-waf-filter-layer7-traffic","poster":"sOI852POL","timestamp":"1725779100.0","upvote_count":"5","comment_id":"1280230"},{"timestamp":"1724186280.0","upvote_count":"1","comment_id":"1269676","poster":"dhewa","content":"Selected Answer: A\nConfiguring the WAF directly on the Global Accelerator ensures that malicious traffic is blocked before it reaches the Application Load Balancer, providing an additional layer of protection."},{"poster":"officedepotadmin","comment_id":"1268137","upvote_count":"2","timestamp":"1723995480.0","content":"Selected Answer: A\nGlobal Accelerator can be integrated with AWS WAF to provide protection at the edge, meaning malicious traffic can be blocked before it reaches your Application Load Balancer (ALB) or other resources in your AWS environment."},{"poster":"AWS_Debu","upvote_count":"1","comment_id":"1267733","content":"Answer is A\n\nAWS Global Accelerator (GA) can be used with AWS Web Application Firewall (WAF) to protect applications from web exploits and DDoS attacks: \nBlock HTTP method and header attacks\nGA, WAF, and the Application Load Balancer can block access to Layer 7 HTTP method and headers. WAF uses web access control list (web ACL) rules with the load balancer to evaluate incoming traffic and only forward requests that comply with the rules to the endpoint. \nDetect and mitigate web application layer request floods\nGA can protect web applications running on Application Load Balancer, and when used with WAF, it can also detect and mitigate web application layer request floods. \nPrevent DDoS attacks","comments":[{"content":"Unfortunately, AWS WAF cannot protect such a resource, according to this link: https://docs.aws.amazon.com/waf/latest/developerguide/waf-chapter.html. \n\nCurrently supported resources are:\no Amazon CloudFront distribution\no Amazon API Gateway REST API\no Application Load Balancer\no AWS AppSync GraphQL API\no Amazon Cognito user pool\no AWS App Runner service\no AWS Verified Access instance","upvote_count":"1","poster":"GOTJ","comment_id":"1350004","timestamp":"1738431600.0"}],"timestamp":"1723902900.0"},{"comment_id":"1264149","upvote_count":"1","content":"Selected Answer: A\nAnswer is A","timestamp":"1723380360.0","poster":"komorebi"},{"upvote_count":"4","poster":"nebajp","timestamp":"1723344000.0","comment_id":"1263712","content":"Selected Answer: C\nCorrect answer C.\nGlobal Accelerator does not work with WAF as it is suitable for TCP/UDP where as WAF is integrates with Application Load Balancer which is on Layer 7 on OSI model, suitable for Web app (Http/Https)"}],"choices":{"B":"Configure an AWS Lambda function to read the ALB metrics to block attacks by updating a VPC network ACL","C":"Configure an AWS WAF web ACL on the ALB to block traffic by using rate-based rules","A":"Configure an AWS WAF web ACL for the Global Accelerator accelerator to block traffic by using rate-based rules","D":"Configure an Amazon CloudFront distribution in front of the Global Accelerator accelerator"},"question_images":[],"answer_description":"","timestamp":"2024-08-11 04:40:00","answer":"C","isMC":true,"answer_images":[],"question_id":978,"answer_ET":"C"},{"id":"MHDGId66TB0tKTPQjMko","isMC":true,"discussion":[{"upvote_count":"6","poster":"toyaji","comment_id":"1281994","timestamp":"1726036440.0","content":"Selected Answer: B\nDynamoDB export connector literally \"exports\" table snapshot to s3 as dynamoDB-json object, then process on it. So it does not affect on read / write capacity on dynamoDB itself.\nBut Athena query directly on dynamoDB so affects on read / write capacity"},{"content":"Selected Answer: B\nThe trick here is to avoid, by any means, interact with the original DynamoDB table because doing so would affect the provisioned capacity. Option \"B\" is the only one that interacts with an EXPORTED COPY of the table. So, the question is: would provisioned capacity be affected by the DynamoDB export process? The answer is: NO! (https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect-dynamodb-home.html):\n\n\"DynamoDB export to S3 allows you to export both full and incremental data from your DynamoDB table. Exports do not consume any read capacity units (RCUs) and have no impact on table performance and availability\"","comment_id":"1349995","timestamp":"1738430580.0","poster":"GOTJ","upvote_count":"2"},{"poster":"LeonSauveterre","content":"Selected Answer: B\nA - Athena allows you to use standard SQL, but it doesn't guarantee minimal impact on the table.\nB - It minimizes direct read/write operations on the table because the exported data can be processed separately (for example, export to S3 then do the processing).\nC - Cool but there's no native connector to directly pull data from DynamoDB. You must export the data to S3 or another source first, adding complexity.\nD - EMR impacts throughput significantly.","upvote_count":"3","timestamp":"1736149560.0","comment_id":"1337008"},{"poster":"Anyio","content":"Selected Answer: B\nThe correct answer is B. Use an AWS Glue job with the AWS Glue DynamoDB export connector to calculate performance metrics on a recurring schedule.\n\nExplanation:\n\nOption B: Correct. AWS Glue offers an efficient method to extract, transform, and load (ETL) data from DynamoDB to Amazon S3, without affecting the table’s provisioned throughput as significantly. Once data is in S3, it can be further processed or queried using AWS Glue or other analytics services, without impacting DynamoDB's immediate R/W provisioning.","upvote_count":"2","comment_id":"1332660","timestamp":"1735338480.0"},{"poster":"rockyykrish","content":"Selected Answer: A\nExplanation:\nAmazon Athena with DynamoDB Connector:\n\nAthena is a serverless interactive query service that allows you to run SQL queries directly on data in various storage systems, including DynamoDB, through the Athena DynamoDB connector.\nThis setup minimizes the impact on the provisioned read and write capacity of the DynamoDB table because the connector reads data efficiently without directly querying the table.\nPerformance Metrics Calculation:\n\nAthena provides SQL capabilities to compute performance metrics on the data fetched via the DynamoDB connector.\nThe queries can be scheduled using Amazon EventBridge or other automation tools to run daily.\nMinimal Operational Overhead:\n\nAthena requires no infrastructure to manage, making it a low-maintenance solution.\nIt is cost-effective since you pay only for the queries you run.","upvote_count":"1","comment_id":"1322471","timestamp":"1733421120.0"},{"poster":"tonybuivannghia","content":"Selected Answer: A\nI think A is correct. We can query the data from DynamoDB by Amazon Athena DynamoDB connector directly, not via S3 Bucket.","comment_id":"1307264","upvote_count":"2","timestamp":"1730796720.0","comments":[{"poster":"Salilgen","content":"You can query the data from DynamoDB by Amazon Athena DynamoDB connector directly but this effect on the table's provisioned read and write capacity.","timestamp":"1736519460.0","comment_id":"1338837","upvote_count":"1"},{"upvote_count":"1","poster":"tonybuivannghia","content":"https://docs.aws.amazon.com/athena/latest/ug/connectors-dynamodb.html","comment_id":"1307265","timestamp":"1730796720.0"}]},{"poster":"spoved","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/big-data/accelerate-amazon-dynamodb-data-access-in-aws-glue-jobs-using-the-new-aws-glue-dynamodb-elt-connector/","upvote_count":"3","comment_id":"1291411","timestamp":"1727674020.0"},{"comment_id":"1289743","upvote_count":"3","timestamp":"1727392020.0","poster":"JoeTromundo","content":"Selected Answer: B\nThe DynamoDB export connector allows you to export data from DynamoDB to other storage solutions like Amazon S3 without consuming the table's provisioned read capacity, ensuring minimal impact on the performance of the table."},{"timestamp":"1726194660.0","upvote_count":"2","comment_id":"1282934","content":"B.\nInstead, the new AWS Glue DynamoDB export connector reads DynamoDB data from the snapshot, which is exported from DynamoDB tables. This approach has following benefits:\n\nIt doesn’t consume read capacity units of the source DynamoDB tables","poster":"Bogey"},{"timestamp":"1725345540.0","upvote_count":"2","content":"To calculate performance metrics for customer device data on a daily basis with minimal effect on the table’s provisioned read and write capacity, the best solution would be:\n\nA. Use an Amazon Athena SQL query with the Amazon Athena DynamoDB connector to calculate performance metrics on a recurring schedule. This approach allows you to run SQL queries directly on the data stored in DynamoDB without impacting the provisioned throughput, as Athena queries are serverless and do not consume DynamoDB read or write capacity1.","comment_id":"1277333","poster":"AbhiBK"},{"poster":"RealPro111","upvote_count":"3","timestamp":"1724774460.0","comment_id":"1273550","content":"Selected Answer: B\nThe right answer is B"},{"poster":"siheom","upvote_count":"2","timestamp":"1724626200.0","comment_id":"1272319","content":"VOTE B"},{"upvote_count":"2","timestamp":"1724307300.0","content":"why is B wrong.. Glue DynamoDB export connector will read data from PITR instead of DynamoDB directly..","poster":"ksdpmx","comment_id":"1270531"},{"upvote_count":"2","content":"I go with A","timestamp":"1724186700.0","comment_id":"1269678","poster":"dhewa"}],"unix_timestamp":1724186700,"answer":"B","answer_ET":"B","answers_community":["B (88%)","12%"],"timestamp":"2024-08-20 22:45:00","topic":"1","question_text":"A company uses an Amazon DynamoDB table to store data that the company receives from devices. The DynamoDB table supports a customer-facing website to display recent activity on customer devices. The company configured the table with provisioned throughput for writes and reads.\n\nThe company wants to calculate performance metrics for customer device data on a daily basis. The solution must have minimal effect on the table's provisioned read and write capacity.\n\nWhich solution will meet these requirements?","answer_description":"","question_id":979,"choices":{"A":"Use an Amazon Athena SQL query with the Amazon Athena DynamoDB connector to calculate performance metrics on a recurring schedule.","D":"Use an Amazon EMR job with an Apache Hive external table to calculate performance metrics on a recurring schedule.","B":"Use an AWS Glue job with the AWS Glue DynamoDB export connector to calculate performance metrics on a recurring schedule.","C":"Use an Amazon Redshift COPY command to calculate performance metrics on a recurring schedule."},"question_images":[],"exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/146188-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[]},{"id":"KYgsEtU11IEXylWPn9Sk","answer_ET":"C","timestamp":"2024-08-20 18:40:00","choices":{"A":"Create an Amazon Simple Notification Service (Amazon SNS) topic to send the jobs that need to be processed. Create an Auto Scaling group by using the launch template with the scaling policy set to add and remove EC2 instances based on CPU usage.","C":"Create an Amazon Simple Queue Service (Amazon SQS) queue to hold the jobs that need to be processed. Create an Auto Scaling group by using the launch template with the scaling policy set to add and remove EC2 instances based on the number of items in the SQS queue.","B":"Create an Amazon Simple Queue Service (Amazon SQS) queue to hold the jobs that need to be processed. Create an Auto Scaling group by using the launch template with the scaling policy set to add and remove EC2 instances based on network usage.","D":"Create an Amazon Simple Notification Service (Amazon SNS) topic to send the jobs that need to be processed. Create an Auto Scaling group by using the launch template with the scaling policy set to add and remove EC2 instances based on the number of messages published to the SNS topic."},"question_text":"A solutions architect is designing the cloud architecture for a new stateless application that will be deployed on AWS. The solutions architect created an Amazon Machine Image (AMI) and launch template for the application.\n\nBased on the number of jobs that need to be processed, the processing must run in parallel while adding and removing application Amazon EC2 instances as needed. The application must be loosely coupled. The job items must be durably stored.\n\nWhich solution will meet these requirements?","answers_community":["C (100%)"],"answer_description":"","isMC":true,"unix_timestamp":1724172000,"discussion":[{"comment_id":"1337036","poster":"LeonSauveterre","content":"Selected Answer: C\nSQS for sure, but I actually swaying between B and C. After a while, I can say now I'm sure that scaling based on network usage doesn't directly have anything to do with the number of jobs in the queue. Or worse, this could result in burst-caused downtime or other poor scaling decisions.","timestamp":"1736153460.0","upvote_count":"2"},{"timestamp":"1724186880.0","upvote_count":"3","comment_id":"1269679","content":"Answer is C: SQS is your first cue then scaling based on the number of requests","poster":"dhewa"},{"poster":"[Removed]","timestamp":"1724172000.0","upvote_count":"2","comment_id":"1269602","content":"Selected Answer: C\n\"Based on the number of jobs that need to be processed\""}],"exam_id":31,"question_id":980,"url":"https://www.examtopics.com/discussions/amazon/view/146180-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"answer":"C","answer_images":[],"topic":"1"}],"exam":{"provider":"Amazon","isImplemented":true,"isMCOnly":true,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Associate SAA-C03","isBeta":false,"id":31,"numberOfQuestions":1019},"currentPage":196},"__N_SSP":true}