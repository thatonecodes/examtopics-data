{"pageProps":{"questions":[{"id":"u1YdCQdWqfm28IiXbnz6","answers_community":["A (97%)","3%"],"question_text":"An adventure company has launched a new feature on its mobile app. Users can use the feature to upload their hiking and rafting photos and videos anytime. The photos and videos are stored in Amazon S3 Standard storage in an S3 bucket and are served through Amazon CloudFront.\n\nThe company needs to optimize the cost of the storage. A solutions architect discovers that most of the uploaded photos and videos are accessed infrequently after 30 days. However, some of the uploaded photos and videos are accessed frequently after 30 days. The solutions architect needs to implement a solution that maintains millisecond retrieval availability of the photos and videos at the lowest possible cost.\n\nWhich solution will meet these requirements?","discussion":[{"poster":"masetromain","comment_id":"776247","upvote_count":"15","comments":[{"comment_id":"776248","poster":"masetromain","content":"Option B is not correct as it only moves data to S3 Glacier Deep Archive after 30 days, which would still require additional steps to retrieve the data.\nOption C is not correct because Amazon Elastic File System (Amazon EFS) is a file storage service for use with Amazon EC2 instances, it does not provide a cost-effective solution for storing and retrieving large amounts of data.\nOption D is not correct because adding a Cache-Control: max-age header only controls the caching behavior of the objects and does not address the cost optimization requirements.","upvote_count":"3","comments":[{"poster":"jhonivy","timestamp":"1690683300.0","comments":[{"upvote_count":"1","comment_id":"792822","timestamp":"1690716180.0","poster":"youngprinceton","content":"take the test then tell us if your answers are valid, if they are share them with us ;)"}],"comment_id":"792380","content":"Option D works for the reduction cost on retrieval request","upvote_count":"1"}],"timestamp":"1689401520.0"}],"timestamp":"1689401520.0","content":"Selected Answer: A\nThe correct answer is A. Configure S3 Intelligent-Tiering on the S3 bucket.\n\nAmazon S3 Intelligent-Tiering is a storage class that automatically moves objects between two access tiers based on changing access patterns. Objects that are accessed frequently are stored in the frequent access tier and objects that are accessed infrequently are stored in the infrequent access tier. This allows for cost optimization without requiring manual intervention. This makes it an ideal solution for the scenario described, as it can automatically move objects that are infrequently accessed after 30 days to a lower-cost storage tier while still maintaining millisecond retrieval availability."},{"content":"A is right\nB S3 Glacier Deep Archive after 30 days is not correct, retrieval takes time so incorrect.","timestamp":"1724574300.0","poster":"Vsos_in29","comment_id":"1158538","upvote_count":"1","comments":[{"content":"Another option with S3 Glacier instant retrieval would have made the question very interesting.","comment_id":"1399882","timestamp":"1742252940.0","upvote_count":"1","poster":"ParamD"}]},{"upvote_count":"1","timestamp":"1714065180.0","poster":"Sandeep_B","comment_id":"1053906","content":"Selected Answer: A\nmillisecond retrieval availability"},{"poster":"wookchan","upvote_count":"2","content":"A, no brainer","timestamp":"1712568060.0","comment_id":"1027844"},{"timestamp":"1709631780.0","upvote_count":"1","poster":"uC6rW1aB","comment_id":"999229","content":"Selected Answer: A\nA. Configure S3 Intelligent-Tiering on the S3 bucket: This option would automatically move objects to different storage tiers based on their access patterns. For objects that are infrequently accessed, this would help to reduce storage costs. For those that continue to be accessed frequently, they would remain in a higher-cost but faster-access tier. This should be the option that meets the requirements.\n\nB. Configure an S3 Lifecycle policy to transition image and video objects from S3 Standard to S3 Glacier Deep Archive after 30 days: This option would significantly lower storage costs, but the retrieval time for Glacier Deep Archive could take several hours, which does not meet the millisecond retrieval requirement."},{"upvote_count":"1","comment_id":"977521","poster":"CuteRunRun","content":"Selected Answer: A\nA is right","timestamp":"1707568080.0"},{"poster":"aviathor","content":"Selected Answer: A\nB is wrong due to the Glacier Deep Archive part which is not warranted by the question.\n\nC is wrong due to the cost of EFS and because it would require some kind of EC2 instance.\n\nD would help caching the objects on proxies and clients, but other than that...","timestamp":"1706172600.0","upvote_count":"1","comment_id":"962414"},{"content":"Selected Answer: A\nA of course","poster":"NikkyDicky","timestamp":"1704234000.0","comment_id":"941215","upvote_count":"1"},{"content":"Selected Answer: A\nI was hesitating between A and D and D looks like a really good option but it's missing one part - we do not do anything with the storage class in this option - we only update the cache TTL which would possibly reduce some costs, however, we keep paying the same price for storage. Hence I switched to A","poster":"Maria2023","upvote_count":"1","comment_id":"929407","timestamp":"1703165040.0"},{"comment_id":"850992","content":"Selected Answer: A\nA - easy question","upvote_count":"1","poster":"mfsec","timestamp":"1695731340.0"},{"poster":"dev112233xx","content":"Selected Answer: A\nA - S3 Intelligent-Tiering can fit the requirement","timestamp":"1695159120.0","comment_id":"844337","upvote_count":"1"},{"timestamp":"1693850340.0","poster":"God_Is_Love","comments":[{"upvote_count":"1","content":"*I meant even after 30 days (not downloads in above comment)","timestamp":"1693850400.0","poster":"God_Is_Love","comment_id":"829356"}],"comment_id":"829353","upvote_count":"4","content":"Selected Answer: A\nFirst half of question drags you to answer B but SA found that some media is being used even after downloads. so data is being accessed in unknown patterns. Way to go is Intelligent tier."},{"comment_id":"814959","content":"Selected Answer: D\nThis is my open. The question ask us maintains millisecond retrieval ability. It means we can't use cold storage (So, A, B is not answer). EFS is expensive and not durable. If we use client cache (Ignore client's volume), we can reduce network costs(actually s3's storage costs is really cheap). It means that we can reduce costs too.","poster":"JungMun","upvote_count":"1","comments":[{"timestamp":"1692510240.0","content":"There are lots of wrong types. Please forgive me. English is not familiar with me yet.","comments":[{"poster":"c73bf38","comment_id":"820154","content":"The keyword is millisecond retrieval time, which rules everything out except A.","upvote_count":"2","timestamp":"1692849900.0"}],"upvote_count":"2","comment_id":"814962","poster":"JungMun"}],"timestamp":"1692510120.0"},{"comment_id":"809688","content":"Selected Answer: A\nbc A solutions architect discovers that most of the uploaded photos and videos are accessed infrequently after 30 days. However, some of the uploaded photos and videos are accessed frequently after 30 days.","upvote_count":"1","poster":"klog","timestamp":"1692106320.0"},{"timestamp":"1690744860.0","upvote_count":"2","content":"Selected Answer: A\ntypico A S3 Intelligent-Tiering","poster":"zozza2023","comment_id":"793358"},{"timestamp":"1690683720.0","upvote_count":"1","comment_id":"792388","content":"D it will reduce the cost on retrieval requests","poster":"jhonivy"}],"answer_description":"","isMC":true,"exam_id":33,"topic":"1","answer_images":[],"choices":{"B":"Configure an S3 Lifecycle policy to transition image objects and video objects from S3 Standard to S3 Glacier Deep Archive after 30 days.","A":"Configure S3 Intelligent-Tiering on the S3 bucket.","C":"Replace Amazon S3 with an Amazon Elastic File System (Amazon EFS) file system that is mounted on Amazon EC2 instances.","D":"Add a Cache-Control: max-age header to the S3 image objects and S3 video objects. Set the header to 30 days."},"question_images":[],"unix_timestamp":1673770320,"answer":"A","question_id":511,"url":"https://www.examtopics.com/discussions/amazon/view/95376-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"A","timestamp":"2023-01-15 09:12:00"},{"id":"BL39YNjxOlHRs18PLQUx","timestamp":"2023-01-15 09:16:00","isMC":true,"question_text":"A company uses Amazon S3 to store files and images in a variety of storage classes. The company's S3 costs have increased substantially during the past year.\n\nA solutions architect needs to review data trends for the past 12 months and identity the appropriate storage class for the objects.\n\nWhich solution will meet these requirements?","answer_images":[],"question_images":[],"topic":"1","answer_ET":"C","answers_community":["C (78%)","13%","9%"],"exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/95377-exam-aws-certified-solutions-architect-professional-sap-c02/","unix_timestamp":1673770560,"question_id":512,"discussion":[{"comment_id":"842427","content":"Selected Answer: C\nStorage class: After you configure a filter, you'll start seeing data analysis based on the filter in the Amazon S3 console in 24 to 48 hours. However, storage class analysis observes the access patterns of a filtered data set for 30 days or longer to gather information for analysis before giving a result\n\nStorage Lens: All S3 Storage Lens metrics are retained for a period of 15 months. However, metrics are only available for queries for a specific duration, which depends on your metrics selection. This duration can't be modified. Free metrics are available for queries for a 14-day period, and advanced metrics are available for queries for a 15-month period.\n\nYou have to upgrade regardless to query up to 12 months","timestamp":"1679105820.0","upvote_count":"14","poster":"zejou1"},{"comments":[{"poster":"zozza2023","timestamp":"1675113840.0","content":"agree with u gess aws want us to know about Lens","upvote_count":"3","comment_id":"793361"}],"timestamp":"1674921180.0","content":"Selected Answer: C\nBoth B and C are good.\nI guess AWS wants clients to use S3 Storage Lens... Hence I vote C.","poster":"Untamables","upvote_count":"7","comment_id":"790769"},{"poster":"gfhbox0083","upvote_count":"1","content":"C, for sure.","timestamp":"1720435680.0","comment_id":"1244303"},{"comment_id":"1215807","upvote_count":"1","timestamp":"1716389160.0","content":"B ..S3 Storage Class Analysis is specifically designed to help you analyze storage access patterns. It monitors the access patterns of objects and provides insights into when it is appropriate to transition objects to different storage classes .","poster":"naylinu"},{"content":"Selected Answer: C\nC, S3 Storage Lens offers comprehensive visibility into storage usage and activity trends across the AWS Organization, facilitating informed decisions on cost optimization and storage efficiency","upvote_count":"1","poster":"gofavad926","comment_id":"1175842","timestamp":"1710681300.0"},{"upvote_count":"1","content":"Selected Answer: C\nOption C refers to using Amazon S3 Storage Lens, which provides organization-wide visibility into object storage usage and activity trends. By upgrading to include advanced metrics and recommendations, users can access detailed insights that help optimize storage costs across their S3 resources. S3 Storage Lens offers dashboard views and metrics that can directly inform on the appropriate storage class based on actual usage patterns, making it a comprehensive solution for the stated requirements.","comment_id":"1149535","poster":"8608f25","timestamp":"1707854100.0"},{"poster":"AWSPro1234","timestamp":"1706057520.0","content":"Amazon S3 Storage Class Analysis:\n\nAmazon S3 provides a Storage Class Analysis tool that helps you analyze access patterns to your S3 objects over time. You can enable it on your S3 bucket to collect data on object access patterns.","comment_id":"1130122","upvote_count":"1"},{"content":"Answer is B.","comment_id":"1130119","poster":"AWSPro1234","upvote_count":"1","timestamp":"1706057340.0"},{"comment_id":"1125085","poster":"ninomfr64","timestamp":"1705504500.0","upvote_count":"1","content":"Selected Answer: C\nTo me here the key sentence is \"review data trends for the past 12 months\"\nA = CUR provides detailed usage data but it is not the best tool for this job\nB = S3 storage class analysis provides recommendation for Standard and Standard IA storage classes, but does not provide data trends\nC = correct\nD = Access Analyzer provides visibility for buckets that are configured to allow access to anyone on the internet or other AWS accounts"},{"comment_id":"1098768","timestamp":"1702804860.0","content":"Selected Answer: B\nB is the right answer, because it suffices a bucket analysis --> https://docs.aws.amazon.com/AmazonS3/latest/userguide/analytics-storage-class.html\nC instead is a solution for a more organization-wide analysis of bucket --> https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens.html","poster":"Nicoben","upvote_count":"1"},{"upvote_count":"1","timestamp":"1699946400.0","content":"Selected Answer: C\nsee AMohanty answer","poster":"severlight","comment_id":"1070099"},{"content":"Selected Answer: B\nS3 Storage Class Analysis enables you to monitor access patterns across objects to help you decide when to transition data to the right storage class to optimize costs.","poster":"Simon523","comments":[{"timestamp":"1704302040.0","comment_id":"1112957","upvote_count":"1","content":"Storage Class is only used for recommendation for Standard to Standard IA","poster":"jpa8300"}],"timestamp":"1695014880.0","upvote_count":"2","comment_id":"1010284"},{"upvote_count":"4","content":"C\nStorage Class is only used for recommendation for Standard to Standard IA","poster":"AMohanty","timestamp":"1694270760.0","comment_id":"1003319"},{"timestamp":"1693901100.0","content":"Selected Answer: C\nOption B: Amazon S3's Storage Class Analysis function is mainly used to analyze the access patterns of objects in S3 buckets so that you can transfer these objects to the most cost-effective storage class. However, this feature does not provide detailed historical data for the past 12 months; it is more about observing current usage patterns and making the best storage class decisions based on those patterns.\n\nIf you need detailed storage trends and object status over the past 12 months, option C (using Amazon S3 Storage Lens) may be a better choice. Amazon S3 Storage Lens provides comprehensive storage analysis, including historical trends and advanced metrics, which may be more suitable for analyzing long-term data and storage conditions.","comment_id":"999245","upvote_count":"2","poster":"uC6rW1aB"},{"content":"I choose C.\nB. Storage class analysis only provides recommendations for Standard to Standard IA classes. The company uses a variety of storage classes.","upvote_count":"1","poster":"YodaMaster","comment_id":"942336","timestamp":"1688437020.0"},{"timestamp":"1688330700.0","upvote_count":"1","content":"Selected Answer: C\na hard one ... I guess C, but could be B :/","poster":"NikkyDicky","comment_id":"941221"},{"timestamp":"1686137040.0","upvote_count":"1","comment_id":"917150","poster":"Limlimwdwd","content":"Selected Answer: B\nBy using Amazon S3 analytics Storage Class Analysis you can analyze storage access patterns to help you decide when to transition the right data to the right storage class. This new Amazon S3 analytics feature observes data access patterns to help you determine when to transition less frequently accessed STANDARD storage to the STANDARD_IA (IA, for infrequent access) storage class. \n\nSo it meet the qn objective of identify the appropriate storage class for the objects"},{"content":"Selected Answer: C\nSCAs recommendations are based on the previous 30-90 days. https://aws.amazon.com/s3/faqs","comment_id":"895895","poster":"leehjworking","timestamp":"1683893940.0","upvote_count":"1"},{"upvote_count":"4","comment_id":"881873","poster":"Maria2023","content":"The question asks for analysis 12 months back. Reading the documentation storage class analysis works from the action onwards. Same with advanced metrics for lens. Or this is not a real question or the only option remains A...","timestamp":"1682529420.0"},{"comment_id":"870981","content":"Selected Answer: C\nAmazon S3 Storage Lens is the best choice in this case.\n\nhttps://aws.amazon.com/pt/getting-started/hands-on/amazon-s3-storage-lens/","poster":"Cassa","upvote_count":"2","timestamp":"1681568220.0"},{"poster":"OCHT","timestamp":"1680961860.0","content":"Selected Answer: C\nThe solutions architect can upgrade the default dashboard to include advanced metrics for storage trends. (Option C)\n\nAmazon S3 Storage Lens provides organization-wide visibility into object storage usage and activity trends. The default dashboard provides a summary of storage usage and activity metrics, and the advanced metrics option provides additional insights into data access patterns and data transfer costs. By analyzing these metrics, the solutions architect can identify trends and determine the appropriate storage class for the objects to optimize costs.","upvote_count":"3","comment_id":"864726"},{"comment_id":"853761","content":"Selected Answer: C\nC - storage lens","poster":"Amac1979","upvote_count":"2","timestamp":"1680042600.0"},{"timestamp":"1679833800.0","content":"Selected Answer: C\nC - storage lens","upvote_count":"2","comment_id":"850994","poster":"mfsec"},{"content":"Selected Answer: C\nC - https://aws.amazon.com/blogs/storage/5-ways-to-reduce-costs-using-amazon-s3-storage-lens/","upvote_count":"2","comment_id":"844059","poster":"Damijo","timestamp":"1679247600.0"},{"comment_id":"830740","upvote_count":"1","poster":"andras","timestamp":"1678100880.0","content":"S3 is not among the cost optimization in trusted Advisor:\nhttps://docs.aws.amazon.com/awssupport/latest/user/cost-optimization-checks.html"},{"content":"Selected Answer: C\nC - Storage Lens","upvote_count":"2","poster":"spd","timestamp":"1676850360.0","comment_id":"814668"},{"content":"Selected Answer: C\no review data trends and identify the appropriate storage class for the objects, the solutions architect can use the Amazon S3 Storage Lens feature. Amazon S3 Storage Lens provides organization-wide visibility into object storage, access, and usage patterns, making it easier to identify cost optimization opportunities and enforce compliance policies.\n\nThe architect can use the Storage Lens dashboard to view trends and metrics for the past 12 months, such as storage utilization, object size distribution, and access patterns. Based on these insights, the architect can determine the appropriate storage class for each object.","upvote_count":"2","poster":"[Removed]","timestamp":"1676578440.0","comment_id":"811068"},{"comments":[{"comment_id":"817369","upvote_count":"2","timestamp":"1677031380.0","poster":"c73bf38","content":"Storage class analysis only provides recommendations for Standard to Standard IA classes."}],"upvote_count":"2","timestamp":"1676242680.0","poster":"CloudFloater","content":"Selected Answer: A\nnot B because there is no cost information from this.\nnot C because it cannot analyze past access trends if you just activate storage lens\nnot D because you are just enabling it \nchoosing A because it will do the job. now.","comment_id":"806880"},{"upvote_count":"1","content":"OPTION C:\n\nIf you have an increasing number of Amazon S3 buckets, spread across tens or even hundreds of accounts, you might be in search of a tool that makes it easier to manage your growing storage footprint and improve cost efficiencies. S3 Storage Lens is an analytics feature built-in to the S3 console to help you gain organization-wide visibility into your object storage usage and activity trends, and to identify cost savings opportunities. S3 Storage Lens is available for all S3 accounts, free of charge. You can also upgrade to advanced metrics to receive additional metrics, insights, and an extended data retention period.","timestamp":"1675607640.0","comment_id":"798895","poster":"Heer"},{"upvote_count":"4","content":"Selected Answer: A\nB or C won't analyze anything from before enabling it. You are simply late. If you want to anlayze previous 12 months, go for A.","poster":"Musk","timestamp":"1675270080.0","comment_id":"795325","comments":[{"comment_id":"825275","timestamp":"1677618120.0","content":"This is the correct answer.","poster":"SuperP43","upvote_count":"1"}]},{"comment_id":"795310","upvote_count":"2","poster":"tatdatpham","timestamp":"1675269600.0","content":"Selected Answer: C\nBoth B and C can do that, but the question did not mention about cost so I vote for C because It has UI friendly :). \nAdvanced metrics in S3 Storage Lens help Generate metrics that can help you manage and optimize your storage costs, such as lifecycle rule counts for transitions, expirations, and incomplete multipart uploads. Data is available for queries for 15 months"},{"comment_id":"795304","upvote_count":"1","content":"It can't be B. When you upgrade AWS S3 Storage Lens to get advanced metrics, metrics data is only preserved since the date when you upgraded, not for the previous 15 months before you upgraded. The request is to review the previous data for the last 12 months.","poster":"Musk","timestamp":"1675269420.0"},{"comment_id":"786626","timestamp":"1674571920.0","poster":"vsk12","content":"Answer B makes more sense as using QS, data can be analyzed further.","upvote_count":"1"},{"timestamp":"1674479040.0","upvote_count":"2","poster":"masssa","content":"I vote C \"S3 Storage Lens\".\nfree metrics cannot provide recommendation, but upgrade metrics can provide recommendation.","comment_id":"785362"},{"upvote_count":"4","comment_id":"781213","poster":"AjayD123","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens.html","timestamp":"1674137400.0"},{"poster":"masetromain","timestamp":"1673770560.0","comments":[{"timestamp":"1673770560.0","upvote_count":"1","comments":[{"poster":"ly007","timestamp":"1681349280.0","content":"Storage Lens is providing data trends according to AWS\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens.html","comment_id":"868977","upvote_count":"1"}],"content":"Option C, Using Amazon S3 Storage Lens and upgrading the default dashboard to include advanced metrics for storage trends, will provide information on S3 usage but does not provide data trends that allow the architect to determine the appropriate storage class for the objects.\n\nOption D, Using Access Analyzer for S3, and downloading the Access Analyzer for S3 report for the last 12 months and importing the .csv file to an Amazon QuickSight dashboard, is not relevant as it is used to analyze access controls and permissions to S3 resources, and it does not provide data trends that allow the architect to determine the appropriate storage class for the objects.","poster":"masetromain","comment_id":"776252"}],"upvote_count":"4","content":"Selected Answer: B\nThe correct answer is B. The solution of using S3 storage class analysis and importing data trends into an Amazon QuickSight dashboard will allow the solutions architect to review data trends for the past 12 months and identify the appropriate storage class for the objects. This solution will allow the architect to see which objects are frequently accessed, which objects are infrequently accessed, and the costs associated with the different storage classes.\n\nOption A, Downloading AWS Cost and Usage Reports for the last 12 months of S3 usage and reviewing AWS Trusted Advisor recommendations for cost savings, will provide information on S3 costs but does not provide data trends that allow the architect to determine the appropriate storage class for the objects.","comment_id":"776251"}],"answer":"C","answer_description":"","choices":{"C":"Use Amazon S3 Storage Lens. Upgrade the default dashboard to include advanced metrics for storage trends.","D":"Use Access Analyzer for S3. Download the Access Analyzer for S3 report for the last 12 months. Import the .csv file to an Amazon QuickSight dashboard.","B":"Use S3 storage class analysis. Import data trends into an Amazon QuickSight dashboard to analyze storage trends.","A":"Download AWS Cost and Usage Reports for the last 12 months of S3 usage. Review AWS Trusted Advisor recommendations for cost savings."}},{"id":"dTeD6I1yFqsOKMCny9t2","url":"https://www.examtopics.com/discussions/amazon/view/95378-exam-aws-certified-solutions-architect-professional-sap-c02/","timestamp":"2023-01-15 09:19:00","answer":"C","question_id":513,"question_text":"A company has its cloud infrastructure on AWS. A solutions architect needs to define the infrastructure as code. The infrastructure is currently deployed in one AWS Region. The company’s business expansion plan includes deployments in multiple Regions across multiple AWS accounts.\n\nWhat should the solutions architect do to meet these requirements?","question_images":[],"unix_timestamp":1673770740,"answer_ET":"C","exam_id":33,"topic":"1","answer_images":[],"answers_community":["C (100%)"],"choices":{"C":"Use AWS Organizations and AWS CloudFormation StackSets. Deploy a Cloud Formation template from an account that has the necessary IAM permissions.","A":"Use AWS CloudFormation templates. Add IAM policies to control the various accounts, Deploy the templates across the multiple Regions.","B":"Use AWS Organizations. Deploy AWS CloudFormation templates from the management account Use AWS Control Tower to manage deployments across accounts.","D":"Use nested stacks with AWS CloudFormation templates. Change the Region by using nested stacks."},"discussion":[{"timestamp":"1689401940.0","poster":"masetromain","content":"Selected Answer: C\nThe correct answer is C. Use AWS Organizations and AWS CloudFormation StackSets.\nAWS Organizations allows the management of multiple AWS accounts as a single entity and AWS CloudFormation StackSets allows creating, updating, and deleting stacks across multiple accounts and regions in an organization. This solution allows creating a single CloudFormation template that can be deployed across multiple accounts and regions, and also allows for the management of access and permissions for the different accounts through the use of IAM roles and policies in the management account.","upvote_count":"16","comments":[{"content":"Option A and D both use AWS CloudFormation, but do not take into account the management of multiple accounts and regions. Option B uses AWS Organizations but doesn't include the use of CloudFormation StackSets, which is necessary for managing deployments across multiple accounts and regions.","poster":"masetromain","comment_id":"776256","upvote_count":"6","timestamp":"1689401940.0","comments":[{"comment_id":"1112962","timestamp":"1720020000.0","upvote_count":"1","poster":"jpa8300","content":"I agree with what you say here, C is a good choice, but in B they mention Control Tower which is also used to manage multiple accounts, couldn't it be a correct answer also?"}]}],"comment_id":"776255"},{"content":"Selected Answer: C\nA = cloud work but it is hard\nB = Control Tower cannot manage stack deployments across accounts\nC = correct\nD = nested stack allows to provision resources by using different CloudFormation templates","comment_id":"1125095","upvote_count":"3","poster":"ninomfr64","timestamp":"1721223660.0"},{"timestamp":"1712049720.0","poster":"totten","content":"Selected Answer: C\nOption C is the most suitable. Here's why:\n\nAWS Organizations: AWS Organizations helps you centrally manage multiple AWS accounts, which is especially useful when dealing with multiple Regions and accounts. You can organize your accounts into an organizational structure, apply policies across accounts, and manage billing.\n\nAWS CloudFormation StackSets: StackSets is a CloudFormation feature that enables you to deploy CloudFormation stacks across multiple accounts and Regions with a single CloudFormation template. This simplifies the process of deploying and managing infrastructure consistently across your organization.","upvote_count":"1","comment_id":"1022962"},{"timestamp":"1704235560.0","poster":"NikkyDicky","content":"Selected Answer: C\nC no doubt","comment_id":"941222","upvote_count":"2"},{"content":"Selected Answer: C\nkeywords = AWS Organizations && AWS CloudFormation StackSets.","timestamp":"1702924020.0","upvote_count":"1","poster":"SkyZeroZx","comment_id":"926799"},{"timestamp":"1699461960.0","upvote_count":"3","comment_id":"892264","poster":"rbm2023","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/aws/new-use-aws-cloudformation-stacksets-for-multiple-accounts-in-an-aws-organization/\nCloud Formation Stack Sets allow you to roll out Cloud Formation stacks over multiple AWS accounts and in multiple Regions with just a couple of clicks. When we launched Stack Sets, grouping accounts was primarily for billing purposes. Since the launch of AWS Organizations, you can centrally manage multiple AWS accounts across diverse business needs including billing, access control, compliance, security, and resource sharing."},{"comment_id":"850995","upvote_count":"2","poster":"mfsec","timestamp":"1695731460.0","content":"Selected Answer: C\nUse AWS Organizations and AWS CloudFormation StackSets"},{"content":"Selected Answer: C\nThe correct answer is C","upvote_count":"4","comment_id":"793369","poster":"zozza2023","timestamp":"1690745280.0"}],"isMC":true,"answer_description":""},{"id":"mjArr8rWt1rAxM9BJxB4","exam_id":33,"unix_timestamp":1673770800,"choices":{"D":"Use nested stacks with AWS CloudFormation templates. Change the Region by using nested stacks.","A":"Use AWS CloudFormation templates. Add IAM policies to control the various accounts, Deploy the templates across the multiple Regions.","C":"Use AWS Organizations and AWS CloudFormation StackSets. Deploy a Cloud Formation template from an account that has the necessary IAM permissions.","B":"Use AWS Organizations. Deploy AWS CloudFormation templates from the management account Use AWS Control Tower to manage deployments across accounts."},"question_id":514,"answer_images":[],"discussion":[{"comment_id":"776257","timestamp":"1705306800.0","content":"same question of \"Questions #84\"","poster":"masetromain","upvote_count":"17"},{"timestamp":"1730398500.0","comment_id":"1059126","content":"These Site Moderators getting lazy boy!","poster":"yorkicurke","upvote_count":"6"},{"upvote_count":"2","timestamp":"1719953220.0","poster":"NikkyDicky","comment_id":"941224","content":"Selected Answer: C\nC. a dup question"},{"content":"Selected Answer: C\nThis question is duplicated in the Exam Topics site. Question 85 is the same as Question 84","timestamp":"1715181180.0","poster":"rbm2023","upvote_count":"1","comment_id":"892285"},{"poster":"bordy20","upvote_count":"1","comment_id":"889688","timestamp":"1714864920.0","content":"C:\nhttps://sanderknape.com/2017/07/cloudformation-stacksets-automated-cross-account-region-deployments/#:~:text=A%20StackSet%20is%20a%20set,deploying%20to%20multiple%20accounts%2Fregions."},{"content":"Thought that my internet was intertupted. then i was wrong =)))","upvote_count":"4","poster":"Nguyen25183","comment_id":"861250","timestamp":"1712245380.0"},{"upvote_count":"2","content":"This is repeated :-(","comment_id":"795338","poster":"Musk","timestamp":"1706806680.0"},{"comment_id":"795312","content":"Selected Answer: C\nDuplicate question with #84","poster":"tatdatpham","timestamp":"1706805720.0","upvote_count":"3"},{"poster":"zhangyu20000","comment_id":"777137","content":"C is correct answer","timestamp":"1705358340.0","upvote_count":"3"}],"answers_community":["C (100%)"],"topic":"1","answer_description":"","question_text":"A company has its cloud infrastructure on AWS. A solutions architect needs to define the infrastructure as code. The infrastructure is currently deployed in one AWS Region. The company’s business expansion plan includes deployments in multiple Regions across multiple AWS accounts.\n\nWhat should the solutions architect do to meet these requirements?","timestamp":"2023-01-15 09:20:00","url":"https://www.examtopics.com/discussions/amazon/view/95379-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"C","isMC":true,"question_images":[],"answer":"C"},{"id":"UI2gFmU00tYbu1k3ScO5","isMC":true,"answer":"B","unix_timestamp":1673771040,"question_text":"A company plans to refactor a monolithic application into a modern application design deployed on AWS. The CI/CD pipeline needs to be upgraded to support the modern design for the application with the following requirements:\n\n• It should allow changes to be released several times every hour.\n• It should be able to roll back the changes as quickly as possible.\n\nWhich design will meet these requirements?","exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/95380-exam-aws-certified-solutions-architect-professional-sap-c02/","timestamp":"2023-01-15 09:24:00","answers_community":["B (100%)"],"question_images":[],"answer_ET":"B","question_id":515,"choices":{"C":"Use AWS Systems Manager to re-provision the infrastructure for each deployment. Update the Amazon EC2 user data to pull the latest code artifact from Amazon S3 and use Amazon Route 53 weighted routing to point to the new environment.","A":"Deploy a CI/CD pipeline that incorporates AMIs to contain the application and their configurations. Deploy the application by replacing Amazon EC2 instances.","B":"Specify AWS Elastic Beanstalk to stage in a secondary environment as the deployment target for the CI/CD pipeline of the application. To deploy, swap the staging and production environment URLs.","D":"Roll out the application updates as part of an Auto Scaling event using prebuilt AMIs. Use new versions of the AMIs to add instances. and phase out all instances that use the previous AMI version with the configured termination policy during a deployment event."},"answer_description":"","topic":"1","answer_images":[],"discussion":[{"content":"Selected Answer: B\nThe correct answer is B. Specifying AWS Elastic Beanstalk to stage in a secondary environment as the deployment target for the CI/CD pipeline of the application and swapping the staging and production environment URLs. This approach allows the company to deploy updates several times an hour and quickly roll back changes as needed.\n\nOption A, Deploying a CI/CD pipeline that incorporates AMIs to contain the application and their configurations. Deploy the application by replacing Amazon EC2 instances, while it may provide a way to roll back changes by replacing instances with previous versions, it may not allow for rapid deployment of updates multiple times per hour.","poster":"masetromain","timestamp":"1673771040.0","upvote_count":"17","comment_id":"776259","comments":[{"comments":[{"upvote_count":"1","content":"Good explanation, but concerning option C it is not quite right, you say that 'may not be able to roll back changes as quickly.', but since it is using Route 53 weighted configuration, in case of failure of the new instances, you just need to change again the weighted configuration to point 100% to the old instances while you replace again the new instances by old instances.","comment_id":"1112977","poster":"jpa8300","timestamp":"1704303360.0"}],"poster":"masetromain","comment_id":"776260","content":"Option C, Using AWS Systems Manager to re-provision the infrastructure for each deployment. Updating the Amazon EC2 user data to pull the latest code artifact from Amazon S3 and using Amazon Route 53 weighted routing to point to the new environment, would require more time-consuming steps and may not be able to roll back changes as quickly.\n\nOption D, Rolling out the application updates as part of an Auto Scaling event using prebuilt AMIs. Using new versions of the AMIs to add instances and phasing out all instances that use the previous AMI version with the configured termination policy during a deployment event, while it may be a way to roll back changes, it doesn't allow for rapid deployment of updates multiple times per hour.","upvote_count":"5","timestamp":"1673771040.0"}]},{"content":"Selected Answer: B\nB, for sure.\nUsing AWS Elastic Beanstalk environment Swap.\nhttps://docs.aws.amazon.com/whitepapers/latest/blue-green-deployments/swap-the-environment-of-an-elastic-beanstalk-application.html","comment_id":"1247656","timestamp":"1720940760.0","upvote_count":"1","poster":"gfhbox0083"},{"content":"Selected Answer: B\nA = replacing existing EC2 instances does not allow for roll back the changes as quickly as possible\nB = correct (tough Beanstalk is not the best service for releasing several times every hour)\nC = could work, but here you are combining SSM and user data to achieve what beanstalk does natively\nD = this would not work as you need to build AMIs (AMI Builder not mentioned) and also rapid rollback is better achieved avoiding termination of old AMI version","timestamp":"1705506900.0","upvote_count":"1","comment_id":"1125100","poster":"ninomfr64"},{"upvote_count":"1","poster":"NikkyDicky","content":"Selected Answer: B\nprobably B","comment_id":"941227","timestamp":"1688331000.0"},{"timestamp":"1683559320.0","upvote_count":"1","poster":"rbm2023","comment_id":"892290","content":"Selected Answer: B\nImagine the cost for replacing AMIs and EC2 or re-provision infrastructure several times per day. Although cost effectiveness is not part the requirement in the question. the only option that seems correct is B."},{"comment_id":"850999","upvote_count":"1","content":"Selected Answer: B\nB. Specify AWS Elastic Beanstalk","timestamp":"1679833920.0","poster":"mfsec"},{"poster":"Untamables","comment_id":"785014","upvote_count":"3","timestamp":"1674452400.0","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html"}]}],"exam":{"name":"AWS Certified Solutions Architect - Professional SAP-C02","lastUpdated":"11 Apr 2025","isMCOnly":true,"numberOfQuestions":529,"id":33,"isImplemented":true,"provider":"Amazon","isBeta":false},"currentPage":103},"__N_SSP":true}