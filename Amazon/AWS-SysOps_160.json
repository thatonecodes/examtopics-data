{"pageProps":{"questions":[{"id":"bLiKH3dRwISBqiuLcVN0","answer":"B","timestamp":"2020-05-11 03:23:00","exam_id":36,"url":"https://www.examtopics.com/discussions/amazon/view/20258-exam-aws-sysops-topic-1-question-819-discussion/","question_id":796,"isMC":true,"answer_images":[],"answer_ET":"B","question_images":[],"question_text":"A SysOps Administrator working on an Amazon EC2 instance has misconfigured the clock by one hour. The EC2 instance is sending data to Amazon CloudWatch through the CloudWatch agent. The timestamps on the logs are 45 minutes in the future.\nWhat will be the result of this configuration?","answer_description":"","topic":"1","discussion":[{"poster":"nicat","timestamp":"1663708140.0","comment_id":"86856","comments":[{"timestamp":"1665455520.0","poster":"4007","upvote_count":"3","comment_id":"126322","content":"Src: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html"}],"content":"B. Amazon CloudWatch will accept the custom metric data and record it. \n\nThe time stamp sent by the user can be up to two weeks in the past and up to two hours into the future.","upvote_count":"25"},{"comment_id":"959180","upvote_count":"1","poster":"albert_kuo","content":"Selected Answer: B\nAmazon CloudWatch does not strictly enforce the chronological order of custom metric data submissions. It accepts and records the data regardless of whether the timestamps are in the past, present, or future. CloudWatch simply uses the provided timestamps to organize and display the data, allowing you to analyze the metrics over time.\n\nWhile it is important to have accurate timestamps for metrics to facilitate meaningful analysis and troubleshooting, CloudWatch will not reject or discard metric data based on future timestamps.","timestamp":"1721625240.0"},{"comment_id":"317437","content":"B :->Each metric data point must be associated with a time stamp. The time stamp can be up to two weeks in the past and up to two hours into the future. If you do not provide a time stamp, CloudWatch creates a time stamp for you based on the time the data point was received.","poster":"arvsrv","timestamp":"1667394960.0","upvote_count":"2"},{"upvote_count":"3","poster":"abhishek_m_86","content":"B. Amazon CloudWatch will accept the custom metric data and record it.\n\nThe time stamp sent by the user can be up to two weeks in the past and up to two hours into the future.","comment_id":"270548","timestamp":"1667188260.0"},{"poster":"jackdryan","comment_id":"243938","content":"I'll go with B","timestamp":"1667104080.0","upvote_count":"1"},{"upvote_count":"2","poster":"ImranR","comment_id":"213483","content":"B. The time stamp sent by the user can be up to two weeks in the past and up to two hours into the future.","timestamp":"1665862380.0"}],"unix_timestamp":1589160180,"choices":{"A":"Amazon CloudWatch will not capture the data because it is in the future.","B":"Amazon CloudWatch will accept the custom metric data and record it.","C":"The Amazon CloudWatch agent will check the Network Time Protocol (NTP) server before sending the data, and the agent will correct the time.","D":"The Amazon CloudWatch agent will check the Network Time Protocol (NTP) server, and the agent will not send the data because it is more than 30 minutes in the future."},"answers_community":["B (100%)"]},{"id":"4V0hJnPC2vsNODPEKkCe","discussion":[{"timestamp":"1730600700.0","poster":"hou0220","upvote_count":"1","content":"SQS supports FIFO queue. https://aws.amazon.com/sqs/features/\nJust that, other options are incorrect. (B) is the best answer. Especially (C), you don't need SWF to do this.","comment_id":"409891"},{"content":"B\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/stand\nard-queues.html\nA standard queue makes a best effort to preserve the order of messages, but more than one copy of a message might be delivered out of order. If your system requires that order be preserved, we recommend using a FIFO (First-In-First-Out) queue or adding sequencing information in each message so you can reorder the messages when they're received.","upvote_count":"2","timestamp":"1729255440.0","poster":"AMohanty","comment_id":"378293"},{"content":"Correct Answer: B \nSince there's no option using FIFO Queues, Sequencing information is the only alternative.","upvote_count":"1","comment_id":"365794","timestamp":"1728998880.0","poster":"TroyMcLure"},{"comment_id":"151954","content":"You can use FIFO SQS (which is slower than normal SQS), but seeing as thats not an option.... then sequencing is your only alternative","poster":"NoCrapEva","upvote_count":"2","timestamp":"1728792420.0"},{"comment_id":"67105","poster":"amrtandre","upvote_count":"1","content":"A standard queue makes a best effort to preserve the order of messages, but more than one copy of a message might be delivered out of order. If your system requires that order be preserved, we recommend using a FIFO (First-In-First-Out) queue or adding sequencing information in each message so you can reorder the messages when they're received.","timestamp":"1727926680.0"},{"content":"B. You can use sequencing information on each message","upvote_count":"4","comment_id":"58451","timestamp":"1727555820.0","poster":"awscertified"},{"comment_id":"32623","poster":"Chirantan","content":"this is now sys ops quection","upvote_count":"1","timestamp":"1727206800.0"},{"poster":"karmaah","content":"The tricky part of the question is \"messages in the same sequence\". Usually we think Delivery which means FIFO & Standard Method to deliver exactly once or at least once. But the requirement is sequence..","upvote_count":"3","comment_id":"19628","comments":[{"poster":"karmaah","timestamp":"1726935000.0","content":"Additional Info :\nAmazon SQS offers standard as the default queue type. Standard queues support at-least-once message delivery.","upvote_count":"2","comment_id":"29626"}],"timestamp":"1726815180.0"}],"url":"https://www.examtopics.com/discussions/amazon/view/7447-exam-aws-sysops-topic-1-question-82-discussion/","answer":"B","question_images":[],"question_text":"You are building an online store on AWS that uses SQS to process your customer orders. Your backend system needs those messages in the same sequence the customer orders have been put in. How can you achieve that?","question_id":797,"timestamp":"2019-10-29 17:19:00","choices":{"D":"Messages will arrive in the same order by default","A":"It is not possible to do this with SQS","C":"You can do this with SQS but you also need to use SWF","B":"You can use sequencing information on each message"},"answer_description":"Amazon SQS is engineered to always be available and deliver messages. One of the resulting tradeoffs is that SQSdoes not guarantee first in, first out delivery of messages. For many distributed applications, each message can stand on its own, and as long as all messages are delivered, the order is not important. If your system requires that order be preserved, you can place sequencing information in each message, so that you can reorder the messages when the queue returns them.","isMC":true,"answer_images":[],"unix_timestamp":1572365940,"answers_community":[],"topic":"1","answer_ET":"B","exam_id":36},{"id":"pWb7JJsptqrHR2kru5L1","timestamp":"2020-05-11 03:24:00","isMC":true,"question_id":798,"exam_id":36,"answer_description":"","question_images":[],"answer":"D","choices":{"C":"the AWS IAM team","D":"a SysOps Administrator","A":"AWS Premium Support","B":"the Amazon ES team"},"answers_community":["D (100%)"],"topic":"1","answer_ET":"A","unix_timestamp":1589160240,"discussion":[{"poster":"nicat","comment_id":"86858","timestamp":"1664119620.0","upvote_count":"10","content":"D. a SysOps Administrator"},{"upvote_count":"8","timestamp":"1664716800.0","poster":"MinisterKlaus","content":"D. SysOps Administrator, this is what we've been studying all along.","comment_id":"126831"},{"poster":"albert_kuo","comment_id":"959182","timestamp":"1721625300.0","upvote_count":"1","content":"Selected Answer: D\nIn the case of Amazon Elasticsearch Service (Amazon ES), AWS manages the underlying infrastructure, including patching, scaling, and high availability of the Elasticsearch cluster. However, it is the responsibility of the customer (company) to configure and manage access control for their Elasticsearch domain."},{"poster":"sapien45","upvote_count":"5","timestamp":"1667700120.0","comment_id":"428715","content":"It was previous SysOps Administrator, until he lost his job because of this error"},{"poster":"YH2021","comments":[{"content":"SysOps is responsible to configure the access policy. hence this fall under sysops responsibility","timestamp":"1667305140.0","poster":"kenkct","upvote_count":"1","comment_id":"293935"}],"content":"A. Amazon Elasticsearch Service is a fully managed service that makes it easy for you to deploy, secure, and run Elasticsearch cost effectively at scale. \nhttps://aws.amazon.com/elasticsearch-service/","comment_id":"259174","upvote_count":"1","timestamp":"1667128080.0"},{"poster":"jackdryan","timestamp":"1665774000.0","comment_id":"243939","content":"I'll go with D","upvote_count":"2"},{"content":"This is basic shared responsibility model. If you can configure it, then it's your responsibility.","timestamp":"1665640680.0","comment_id":"201711","upvote_count":"4","poster":"vob"},{"upvote_count":"1","timestamp":"1665411120.0","comment_id":"153225","poster":"lgh9527","content":"D. for sure. I am doubting AWS would care/help on this issue"},{"poster":"teosinh","timestamp":"1665355860.0","comment_id":"148571","upvote_count":"1","content":"D only .."},{"upvote_count":"1","comment_id":"111202","poster":"professor","timestamp":"1664632560.0","content":"Ans: D This is Obvious"},{"comment_id":"93822","upvote_count":"1","timestamp":"1664266860.0","content":"i would go with D","poster":"gretch"}],"url":"https://www.examtopics.com/discussions/amazon/view/20259-exam-aws-sysops-topic-1-question-820-discussion/","question_text":"A company recently performed a security audit of all its internal applications developed in house. Certain business-critical applications that handle sensitive data were flagged because they use Amazon ES clusters that are open for read/write to a wider user group that intended.\nWho is responsible for correcting the issue?","answer_images":[]},{"id":"AstAG4JOOvRiJCHcF7hb","timestamp":"2021-07-05 11:49:00","isMC":true,"question_text":"A SysOps Administrator has created a new Amazon S3 bucket named mybucket for the Operations team. Members of the team are part of an IAM group to which the following IAM policy has been assigned:\n//IMG//\n\nWhich of the following actions will be allowed on the bucket? (Choose two.)","answer_ET":"BD","answers_community":[],"answer_description":"","discussion":[{"timestamp":"1730689560.0","upvote_count":"2","poster":"Huy","comment_id":"408683","content":"It is clearly B & D"},{"content":"Is it B and D?","timestamp":"1727203080.0","comments":[{"upvote_count":"5","poster":"saturdaysunday","timestamp":"1729376100.0","content":"Looks like it. The policy has GetObject which allows you to download an object and DeleteObject which allows you to delete an object. Someone please correct me if I'm wrong.","comment_id":"400357"}],"upvote_count":"4","poster":"USR","comment_id":"399063"}],"question_images":["https://www.examtopics.com/assets/media/exam-media/03859/0043100001.png"],"question_id":799,"topic":"1","exam_id":36,"answer":"BD","choices":{"A":"Get the bucket's region.","E":"List all the buckets in the account.","B":"Delete an object.","C":"Delete the bucket.","D":"Download an object."},"answer_images":[],"unix_timestamp":1625478540,"url":"https://www.examtopics.com/discussions/amazon/view/57158-exam-aws-sysops-topic-1-question-821-discussion/"},{"id":"xjd1z2nOsC4KvHIH5h2H","timestamp":"2020-05-11 03:26:00","question_id":800,"isMC":true,"exam_id":36,"answer_description":"","question_images":[],"answer":"B","choices":{"B":"Create a VPC endpoint for the S3 bucket, and create a S3 bucket policy that conditionally limits all S3 actions on the bucket to the VPC endpoint as the source.","A":"Create a VPC endpoint for the S3 bucket, and create an IAM policy that conditionally limits all S3 actions on the bucket to the VPC endpoint as the source.","C":"Create a service-linked role for Amazon EC2 that allows the EC2 instances to interact directly with Amazon S3, and attach an IAM policy to the role that allows the EC2 instances full access to the S3 bucket.","D":"Create a NAT gateway in the VPC, and modify the VPC route table to route all traffic destined for Amazon S3 through the NAT gateway."},"topic":"1","answers_community":["B (100%)"],"answer_ET":"B","unix_timestamp":1589160360,"discussion":[{"content":"B. Create a VPC endpoint for the S3 bucket, and create a S3 bucket policy that conditionally limits all S3 actions on the bucket to the VPC endpoint as the source.","poster":"nicat","comment_id":"86859","timestamp":"1663684200.0","upvote_count":"18"},{"content":"Selected Answer: B\nTo restrict access to an Amazon S3 bucket to Amazon EC2 instances in a VPC and ensure all traffic remains over the AWS private network, you should use a VPC endpoint for S3 and a bucket policy.","timestamp":"1721626440.0","poster":"albert_kuo","comment_id":"959197","upvote_count":"1"},{"poster":"RicardoD","content":"B is the answer","upvote_count":"1","timestamp":"1667816520.0","comment_id":"366246"},{"content":"I'll go with B","timestamp":"1667469660.0","comment_id":"243940","upvote_count":"2","poster":"jackdryan"},{"content":"B.\nNot D because you can't route to S3 through a private link via a NAT gateway specifically and on its own.\nC is required but in itself it won't restrict the bucket and it won't force going via the private link. https://aws.amazon.com/premiumsupport/knowledge-center/ec2-instance-access-s3-bucket/#:~:text=To%20connect%20to%20your%20S3,need%20to%20do%20the%20following%3A&text=Create%20and%20attach%20an%20AWS,have%20a%20policy%20denying%20access.\nB will restrict the bucket to that VPC via the private link (still have to configure the endpoint policy even though this is not mentioned), hence this is the right answer.\nA is similar but wrong because bucket access is limited by bucket policies, not IAM policies (which go on users, groups or roles).","timestamp":"1666956720.0","comment_id":"201718","upvote_count":"4","poster":"vob"},{"upvote_count":"3","timestamp":"1666780320.0","comment_id":"136382","content":"B. https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies-vpc-endpoint.html#example-bucket-policies-restrict-accesss-vpc-endpoint","poster":"yli"},{"content":"my bad, option C is not talking about restricting access on S3 and is ONLY talking about providing access to EC2 instances. B is best suited here.","timestamp":"1666050360.0","poster":"narayanan010","comment_id":"130009","upvote_count":"2"},{"upvote_count":"1","timestamp":"1663728000.0","content":"Option B doesn't talk about EC2 instances at all, but limits access to the S3 bucket from the VPC endpoint. Can anyone please explain why option C is incorrect?","poster":"narayanan010","comment_id":"130006","comments":[{"timestamp":"1666821660.0","comment_id":"166801","content":"The EC2 instances are in the VPC. The VPC has a route to the S3 VPC Endpoint. You just need to allow the bucket policy to allow access from the VPC.","upvote_count":"1","poster":"shimmy"}]}],"url":"https://www.examtopics.com/discussions/amazon/view/20260-exam-aws-sysops-topic-1-question-822-discussion/","answer_images":[],"question_text":"A company needs to restrict access to an Amazon S3 bucket to Amazon EC2 instances in a VPC only. All traffic must be over the AWS private network.\nWhat actions should the SysOps Administrator take to meet these requirements?"}],"exam":{"lastUpdated":"11 Apr 2025","name":"AWS-SysOps","isImplemented":true,"isMCOnly":false,"isBeta":false,"numberOfQuestions":928,"provider":"Amazon","id":36},"currentPage":160},"__N_SSP":true}