{"pageProps":{"questions":[{"id":"wgj7lReJX8aq27jBazyT","answers_community":["A (100%)"],"unix_timestamp":1690493760,"exam_id":28,"choices":{"D":"Move the less frequently accessed data that is 3-6 years old to a warm tier on Amazon Elastic File System (Amazon EFS) by using data aging.","A":"Keep the frequently accessed data from the last 2 years in a hot tier on an SAP HANA certified Amazon EC2 instance.","C":"Move the less frequently accessed data that is 3-6 years old to a warm tier on Amazon Elastic File System (Amazon EFS) by using SAP HANA dynamic tiering.","B":"Move the frequently accessed data from the last 2 years to SAP Information Life Cycle Management (ILM) with SAP IQ.","F":"Move the rarely accessed data that is more than 6 years old to a cold tier on SAP BW Near Line Storage (NLS) with Apache Hadoop.","E":"Move the rarely accessed data that is more than 6 years old to a cold tier on Amazon S3 by using SAP Data Hub."},"answer_images":[],"question_text":"A company wants to migrate a native SAP HANA database to AWS. The database ingests large amounts of data every month, and the size of the database is growing rapidly.\n\nThe company needs to store data for 10 years to meet a regulatory requirement. The company uses data from the last 2 years frequently in several reports. This recent data is critical and must be accessed quickly. The data that is 3-6 years old is used a few times a year and can be accessed in a longer time frame. The data that is more than 6 years old is rarely used and also can be accessed in a longer time frame.\n\nWhich combination of steps will meet these requirements? (Choose three.)","answer":"A","topic":"1","timestamp":"2023-07-27 23:36:00","url":"https://www.examtopics.com/discussions/amazon/view/116637-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/","discussion":[{"timestamp":"1700790900.0","comments":[{"poster":"LocalHero","upvote_count":"2","timestamp":"1705500600.0","comment_id":"1125031","content":"this is correct choice!"}],"comment_id":"1078974","upvote_count":"6","content":"Selected Answer: A\nACE\nhttps://docs.aws.amazon.com/sap/latest/sap-hana/sap-data-tiering.html","poster":"Untamables"},{"comment_id":"970381","timestamp":"1690994580.0","content":"It should be A,B,F","upvote_count":"1","poster":"G4Exams","comments":[{"upvote_count":"2","timestamp":"1690994700.0","comment_id":"970386","poster":"G4Exams","content":"sorry sorry A,C,E."}]},{"comment_id":"965065","poster":"tonatiuhop","content":"Selected Answer: A\nI believe it is ACE","timestamp":"1690493760.0","upvote_count":"3"}],"answer_ET":"A","answer_description":"","question_images":[],"isMC":true,"question_id":6},{"id":"cyY5XndNewqXlOsaJzRC","unix_timestamp":1690494180,"exam_id":28,"isMC":true,"answer_images":[],"question_images":[],"answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/116638-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/","choices":{"B":"For /hana/data, use one 2,400 GB General Purpose SSD (gp3) EBS volume that is configured with the required IOPS. For /hana/log, use one 512 GB gp3 EBS volume that is configured with the required throughput.","C":"For /hana/data use two 1,200 GB Provisioned IOPS SSD (io2) EBS volumes that are configured with RAID 0 striping and the required IOPS. For /hana/log, use one 525 GB io2 EBS volume that is configured with the required throughput.","D":"For /hana/data, use two 1,200 GB General Purpose SSD (gp3) EBS volumes that are configured with RAID 0 striping and the required IOPS. For /hana/log, use one 512 GB gp3 EBS volume that is configured with the required throughput.","A":"For /hana/data, use two 900 GB Provisioned IOPS SSD (io1) EBS volumes that are configured with RAID 0 striping and the required IOPS. For /hana/log, use one 512 GB General Purpose SSD (gp3) EBS volume that is configured with the required throughput."},"answer":"B","discussion":[{"upvote_count":"2","comment_id":"1141499","content":"Selected Answer: D\nD is correct.\n\nB. The one single EBS, 2400 GB and 9000 IOPS costs 346.49 USD\nD. Each EBS gp3, 1200 GB an 4500 IOPS * 2 costs 335.97 USD","timestamp":"1707168360.0","poster":"awsmonster"},{"content":"https://calculator.aws/#/createCalculator/EBS","comment_id":"1125038","timestamp":"1705501200.0","upvote_count":"1","poster":"LocalHero"},{"comment_id":"1113843","timestamp":"1704384060.0","poster":"khchan123","content":"D is correct, because of the the 9000 IOPS requirement.\n\nIn RAID0, you buy 1500 IOPS for each of the 1,200 GB EBS volumes. So each volume provides 4500 IOPS, and add up to 9000 IOPS under RAID0 striping.\n\nFor B, you have to buy extra 6000 IOPS.","upvote_count":"1"},{"timestamp":"1694502180.0","comment_id":"1005486","upvote_count":"3","poster":"junrun3","content":"Selected Answer: B\nSpecifically, Amazon EBS general-purpose SSDs (gp3) are user-specifiable in terms of IOPS and throughput and offer a good balance of performance and price. Provisioned IOPS SSDs (io1, io2) are ideal for high-load workloads that require high IOPS, but cost correspondingly more. This requirement calls for 9,000 IOPS for data storage and 300 MBps throughput for log storage. To meet these performance requirements while keeping costs down, gp3 volumes are the best choice. The storage requirements of 2,400 GB for /hana/data and 512 GB for /hana/log can also be provided by a single gp3 volume."},{"upvote_count":"2","content":"Selected Answer: D\nB could be the answer but most likely D because of the 9000IOPS requirement.","comment_id":"998128","timestamp":"1693795560.0","poster":"G4Exams"},{"timestamp":"1690914120.0","poster":"kaishin0527","upvote_count":"2","comment_id":"969293","content":"B: SAP S/4HANA system requires two different types of storage: one for data and one for logs, each with specific performance requirements.\n\nFor /hana/data, the system needs 2,400 GB of storage with 9,000 IOPS. The new General Purpose SSD (gp3) EBS volume can provide this configuration at a lower cost compared to Provisioned IOPS SSD (io1 or io2) EBS volumes. With gp3, you can provision IOPS independently from storage capacity.\n\nFor /hana/log, the system requires 512 GB of storage with a throughput of 300 MBps. Again, a gp3 EBS volume can be configured to provide the required throughput.\n\nBy using gp3 EBS volumes for both data and log storage, you can meet the requirements most cost-effectively. The other options either use more expensive io1/io2 volumes or involve RAID 0 striping which adds complexity without providing additional benefits in this case."},{"upvote_count":"3","timestamp":"1690494180.0","comment_id":"965073","poster":"tonatiuhop","content":"Selected Answer: B\nI think B"}],"answer_description":"","question_id":7,"question_text":"An SAP engineer is designing a storage configuration for an SAP S/4HANA production system on AWS. The system will run on an Amazon EC2 instance with a memory size of 2 TB. The SAP HANA sizing report recommends storage of 2,400 GB for data and 512 GB for logs. The system requires 9,000 IOPS for data storage and throughput of 300 MBps for log storage.\n\nWhich Amazon Elastic Block Store (Amazon EBS) volume configuration will meet these requirements MOST cost-effectively?","answers_community":["B (60%)","D (40%)"],"topic":"1","timestamp":"2023-07-27 23:43:00"},{"id":"wP4b7CqTDc0hSD2zoRGj","timestamp":"2023-07-28 20:42:00","answers_community":["D (86%)","14%"],"question_id":8,"choices":{"A":"Use General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volumes as the archive destination. Use Amazon S3 for backups. Use S3 Glacier for long-term retention of the archives.","C":"Use Provisioned IOPS SSD (io1) Amazon Elastic Block Store (Amazon EBS) volumes as the archive destination. Use Amazon S3 for backups. Use S3 Glacier for long-term retention of the archives.","D":"Use Cold HDD (sc1) Amazon Elastic Block Store (Amazon EBS) volumes as the archive destination. Use Amazon S3 for backups. Use S3 Glacier for long-term retention or the archives.","B":"Use Provisioned IOPS SSD (io1) Amazon Elastic Block Store (Amazon EBS) volumes as the archive destination. Back up the archives to Cold HDD (sc1) EBS volumes."},"discussion":[{"content":"Selected Answer: D\nI am also going for D because its most cost effective and there is not mentioned that the lower performance is an issue in this scenario.","timestamp":"1693624620.0","poster":"G4Exams","upvote_count":"3","comment_id":"996520"},{"content":"Selected Answer: D\nSc1 is used for archiving and is the cheapest of the options","upvote_count":"1","comment_id":"970944","timestamp":"1691054700.0","poster":"Kash12345"},{"comment_id":"969290","timestamp":"1690913940.0","content":"Selected Answer: D\nD: The use of Cold HDD (sc1) Amazon Elastic Block Store (Amazon EBS) volumes as the archive destination is most cost-effective for storing large amounts of data that is infrequently accessed, making it a good choice for storing SAP HANA archive files.\n\nFor backups, Amazon S3 is used. Amazon S3 provides high durability and is cost-effective, making it an excellent choice for storing backups.\n\nFor long-term retention of the archives, S3 Glacier is used. S3 Glacier is a low-cost storage service that makes it cost-effective for long-term retention of data.\n\nThe combination of these services allows for a cost-effective solution for storing SAP HANA archive files, backing them up, and retaining them over the long term. This solution meets the company's needs while also being cost-effective.","poster":"kaishin0527","upvote_count":"2"},{"content":"Selected Answer: A\nIT looks like A","poster":"tonatiuhop","timestamp":"1690569720.0","upvote_count":"1","comment_id":"965765"}],"answer_description":"","answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/116697-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/","question_text":"A company is running SAP on premises and is using hard disk drive (HDD) cost-optimized storage to store SAP HANA archive files. The company directly mounts these disks as local file systems. The company also backs up the archives on a regular basis.\n\nThe company needs to migrate this setup to AWS.\n\nWhich solution will meet these requirements MOST cost-effectively?","exam_id":28,"unix_timestamp":1690569720,"isMC":true,"question_images":[],"answer_images":[],"topic":"1","answer_ET":"D"},{"id":"vSoH37Qz45eryUymkdFr","timestamp":"2023-07-27 23:49:00","answers_community":["C (80%)","D (20%)"],"question_id":9,"choices":{"D":"The password of the DDIC user in client 000","B":"The password of the SAP* user in client 000","A":"The password of the adm operating system user","C":"The password of the administrator user of the database"},"discussion":[{"upvote_count":"1","poster":"acethetest1000","content":"Selected Answer: D\nIn both scenarios, export and backup, SWPM will ask for the DDIC password on client 000.","comment_id":"1129716","timestamp":"1706022840.0"},{"content":"Selected Answer: C\nforgot to vote","comment_id":"969675","upvote_count":"2","poster":"kaishin0527","timestamp":"1690951080.0"},{"poster":"kaishin0527","content":"C: The SAP consultant should obtain the password of the administrator user of the database before initiating the export or backup. This is because the system copy procedure typically requires administrative access to the database to perform its tasks.","timestamp":"1690913820.0","comment_id":"969289","upvote_count":"3"},{"poster":"tonatiuhop","upvote_count":"2","content":"Selected Answer: C\nI would assume C as it is DB data","comment_id":"965079","timestamp":"1690494540.0"}],"answer_description":"","answer":"C","question_text":"An SAP consultant is planning a migration of an on-premises SAP landscape to AWS. The landscape includes databases from Oracle, IBM Db2, and Microsoft SQL Server. The system copy procedure accesses the copied data on the destination system to complete the copy.\n\nWhich password must the SAP consultant obtain from the source system before the SAP consultant initiates the export or backup?","url":"https://www.examtopics.com/discussions/amazon/view/116639-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/","exam_id":28,"unix_timestamp":1690494540,"isMC":true,"question_images":[],"answer_images":[],"topic":"1","answer_ET":"C"},{"id":"sBXGhoh4FlC4OMX4Ckhg","isMC":true,"discussion":[{"poster":"G4Exams","timestamp":"1695008160.0","comment_id":"1010216","upvote_count":"1","content":"Selected Answer: B\nIts B."},{"poster":"G4Exams","content":"Selected Answer: B\nIts B.","upvote_count":"1","comment_id":"1006142","timestamp":"1694573880.0"},{"upvote_count":"2","poster":"kaishin0527","comment_id":"969286","timestamp":"1690913700.0","content":"Selected Answer: B\nB: When an EC2 instance is stopped and then restarted, the public IP address associated with the instance changes. If the SAProuter configuration uses this public IP address, the connectivity will fail when the EC2 instance is restarted because the public IP address will have changed. However, an Elastic IP address is a static, public IPv4 address, which remains associated with the EC2 instance even when it is stopped and restarted. Thus, by assigning an Elastic IP address to the EC2 instance and updating the SAProuter configuration with the Elastic IP address, the company can ensure that the SAP Support team will be able to establish connectivity with SAProuter whenever necessary."},{"timestamp":"1690494600.0","comment_id":"965080","content":"Selected Answer: B\nB\nhttps://docs.aws.amazon.com/sap/latest/sap-hana/hana-ops-support.html","upvote_count":"1","poster":"tonatiuhop"}],"question_id":10,"exam_id":28,"timestamp":"2023-07-27 23:50:00","answer":"B","unix_timestamp":1690494600,"choices":{"A":"Re-install SAProuter on an EC2 instance in a private subnet. Update the SAProuter configuration with the instance's private IP address. Deploy a managed NAT gateway for AWS. Route SAP connectivity through the NAT gateway.","D":"Update the SAProuter configuration with the private IP address of the EC2 instance that hosts SAProuter.","B":"Allocate an Elastic IP address to the EC2 instance that hosts SAProuter. Update the SAP router configuration with the Elastic IP address.","C":"Modify the security group that is associated with the EC2 instance that hosts SAProuter to allow access to all ports from the 0.0.0.0/0 CIDR block."},"question_text":"A company recently migrated its SAP workload to AWS. The company's SAP engineer implements SAProuter on an Amazon EC2 instance that runs SUSE Linux Enterprise Server. The EC2 instance is in a public subnet and is an On-Demand Instance. The SAP engineer performs all the necessary configurations for SAProuter, security groups, and route tables.\n\nThe SAProuter system needs to be online and available only when SAP Support is needed. The SAP engineer performs an initial test to validate SAP Support connectivity with SAProuter. The test is successful, and the SAP engineer stops the EC2 instance.\n\nWhen an event occurs that causes the company to need SAP Support, the company starts the EC2 instance that hosts SAProuter. After the EC2 instance is running, the SAP Support team cannot establish connectivity with SAProuter.\n\nWhat should the SAP engineer do to permanently resolve this issue?","topic":"1","answer_description":"","question_images":[],"answer_ET":"B","answer_images":[],"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/116640-exam-aws-certified-sap-on-aws-specialty-pas-c01-topic-1/"}],"exam":{"lastUpdated":"11 Apr 2025","isMCOnly":true,"name":"AWS Certified SAP on AWS - Specialty PAS-C01","numberOfQuestions":130,"isBeta":false,"isImplemented":true,"provider":"Amazon","id":28},"currentPage":2},"__N_SSP":true}