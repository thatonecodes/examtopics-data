{"pageProps":{"questions":[{"id":"3LSguBN1RCW4mFyeCX53","question_text":"A DevOps engineer wants to deploy a serverless web application that is based on AWS Lambda. The deployment must meet the following requirements:\n✑ Provide staging and production environments.\n✑ Restrict developers from accessing the production environment.\n✑ Avoid hardcoding passwords in the Lambda functions.\n✑ Store source code in AWS CodeCommit.\n✑ Use AWS CodePipeline to automate the deployment.\nWhat is the MOST operationally efficient solution that meets these requirements?","unix_timestamp":1662158160,"question_id":166,"topic":"1","question_images":[],"answers_community":["B (61%)","D (32%)","7%"],"choices":{"C":"Define tagging conventions for staging and production environments to segregate deployment targets. Use AWS Key Management Service (AWS KMS) to store environment-specific values. Use CodePipeline to automate deployments with AWS CodeDeploy.","D":"Define tagging conventions for staging and production environments to segregate deployment targets. Use Lambda environment variables to store environment-specific values. Use CodePipeline to automate deployments with AWS CodeDeploy.","A":"Create separate staging and production accounts to segregate deployment targets. Use AWS Key Management Service (AWS KMS) to store environment- specific values. Use CodePipeline to automate deployments with AWS CodeDeploy.","B":"Create separate staging and production accounts to segregate deployment targets. Use Lambda environment variables to store environment-specific values. Use CodePipeline to automate deployments with AWS CodeDeploy."},"answer_images":[],"timestamp":"2022-09-03 00:36:00","discussion":[{"timestamp":"1669990020.0","content":"Selected Answer: B\nYou can't use tagging to segregate deployment targets for Lambda. The docu here only says EC2 https://docs.aws.amazon.com/codedeploy/latest/userguide/instances-tagging.html","poster":"Jichu","upvote_count":"9","comment_id":"733802"},{"poster":"RightAnswers","timestamp":"1664056260.0","content":"Selected Answer: B\nLambda aliases should be used to sperate deplyment stateg. However, with the given options, the best way may be to use different accounts.\nA: Incorrect - KMS can't be used to store environment specific variable. Those are stored as environment variables, but can be encrypted with a KMS key.\nB: Correct\nC and D: Incorrect - Tagging can't be used to segregate deployment targets with Lambda","comment_id":"678259","upvote_count":"6"},{"poster":"DucSiu","timestamp":"1700842020.0","content":"My answer is D","comment_id":"1079419","upvote_count":"1"},{"upvote_count":"1","poster":"DaddyDee","content":"I would go with B as the question asks for MOST operational efficiency: https://aws.amazon.com/blogs/mt/multi-account-strategy-for-small-and-medium-businesses/\n\n- In the Well Architected framework staging and prod should be separated for security and risk management (Limit scope of impact from adverse events)\nhttps://docs.aws.amazon.com/whitepapers/latest/organizing-your-aws-environment/benefits-of-using-multiple-aws-accounts.html","comment_id":"973427","timestamp":"1691278740.0"},{"poster":"Flyingdagger","upvote_count":"1","content":"with option d, it will be very hardto restrict developers to access production environment.\nSo correct answer is b","timestamp":"1685331000.0","comment_id":"909007"},{"comment_id":"888143","content":"Selected Answer: B\nB is more suitable here.","timestamp":"1683088560.0","upvote_count":"1","poster":"ParagSanyashiv"},{"upvote_count":"1","content":"KMS is an encryption service, it is not secrets manager.. So you cannot store anything in KMS.. you can either segregate environments using accounts or using tags via policies.. So it would be either B or D.. I think I would go wi B.","timestamp":"1677656760.0","poster":"itbrpl","comment_id":"825617"},{"upvote_count":"2","comment_id":"819861","content":"Selected Answer: A\nA is correct because it suggests to use separate accounts and KMS for secrets","timestamp":"1677192840.0","poster":"DevOpsJagadGuru"},{"poster":"LoveToronto","comment_id":"817241","content":"One of the requirements is this: Restrict developers from accessing the production environment.\nD alone does not restrict users.\nB. meets all requirements.","upvote_count":"1","timestamp":"1677018900.0"},{"comment_id":"800897","timestamp":"1675774800.0","poster":"Piccaso","content":"Selected Answer: A\nC and D are eliminated because we need two accounts. Tagging are not strict enough.\nAWS KMS is more efficient than Lambda environment variables.\nI used GCP KMS to manage environment-specific values.\nAWS KMS can also be used to manage environment-specific values. https://medium.com/cloudfordummies/securing-cloud-functions-part-1-using-aws-kms-for-environment-variables-1409597a38ba","upvote_count":"1"},{"timestamp":"1673921940.0","upvote_count":"2","poster":"Bulti","content":"B is the right answer and not D because we want to restrict developer access to the production environment and therefore having a separate account for production makes it more manageble.","comment_id":"778475"},{"content":"B is correct. This is a serverless deployment","poster":"saeidp","upvote_count":"1","timestamp":"1672651140.0","comment_id":"763610"},{"upvote_count":"4","content":"Selected Answer: B\nOne of the requirements is this: Restrict developers from accessing the production environment.\nD alone does not restrict users.\nB. meets all requirements.","comment_id":"741773","poster":"ericzaj","timestamp":"1670768100.0"},{"comment_id":"727609","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/instances-tagging.html","poster":"Maygam","timestamp":"1669476600.0","upvote_count":"2","comments":[{"comment_id":"874183","content":"only for ec2 and on-prem","timestamp":"1681861080.0","poster":"scottytoohotty","upvote_count":"1"}]},{"upvote_count":"3","comment_id":"724852","content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/security/guidelines-for-when-to-use-accounts-users-and-groups/\nAlways prefer to use tag to segregate environment rather than using multiple accounts","poster":"kyozanuro","timestamp":"1669173060.0"},{"poster":"mgm7","comment_id":"693857","upvote_count":"2","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_tags.html \nOne can use tags and condition statements in policies to restrict access to specific resources.","timestamp":"1665661860.0"},{"comment_id":"664987","content":"Selected Answer: D\nA,C are wrong. Since KSM can't store environment variable.\nThe difference between B and D is separate environments by account or tagging. Per the requirement - the MOST operationally efficient, I will choice D.","comments":[{"content":"do you have any reference/example showing deployment based on tagging ?!","upvote_count":"1","timestamp":"1663754580.0","comment_id":"674989","poster":"Goozian"}],"timestamp":"1662765780.0","poster":"MichaelExam","upvote_count":"4"},{"timestamp":"1662524760.0","upvote_count":"3","comment_id":"661970","content":"Selected Answer: B\nAns: B Account level segregating","poster":"SamHan"},{"poster":"network_zeal","content":"A is correct. D(segregating using tags) cannot be the most operationally efficient versus having an account level segregation.","upvote_count":"1","timestamp":"1662348480.0","comments":[{"upvote_count":"2","content":"Sorry it is B. KMS wont store store variables, they will need to be stored in Lambda env variables.","poster":"network_zeal","comment_id":"659702","timestamp":"1662348900.0","comments":[{"comment_id":"809006","timestamp":"1676425980.0","poster":"HP0510","upvote_count":"2","content":"You are correct that KMS does not store variables directly. However, KMS can be used to encrypt and decrypt environment variables that are stored in Lambda functions, which is what Option A in the original question suggests."}]}],"comment_id":"659700"},{"timestamp":"1662323340.0","content":"Selected Answer: B\nB - I suspect D is not the correct answer. Lambda uses ALIAS to segregate deployments. According to AWS documentation that is the deployment group definition for a Lambda deployment: \"A CodeDeploy deployment group on an AWS Lambda compute platform identifies a collection of one or more AppSpec files. Each AppSpec file can deploy one Lambda function version. A deployment group also defines a set of configuration options for future deployments, such as alarms and rollback configurations.\". https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-steps-lambda.html\nIt means AppSpec is going to be responsible to guide which environment Codedeploy will deploy the lambda function. \nhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-resources.html","comment_id":"659518","upvote_count":"4","poster":"ohcn"},{"upvote_count":"1","poster":"helloworldabc","content":"dDDDDDDDDDD","comment_id":"658919","timestamp":"1662258600.0"},{"upvote_count":"3","comment_id":"657880","content":"Selected Answer: D\nD is the optimal solution.","poster":"Goozian","timestamp":"1662158160.0"}],"isMC":true,"exam_id":35,"answer":"B","answer_description":"","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/79621-exam-aws-devops-engineer-professional-topic-1-question-60/"},{"id":"b1d7Er9bbQ2aiyKY13yk","question_text":"A company wants to use AWS development tools to replace its current bash deployment scripts. The company currently deploys a LAMP application to a group of\nAmazon EC2 instances behind an Application Load Balancer (ALB). During the deployments, the company unit tests the committed application, stops and starts services, unregisters and re-registers instances with the load balancer, and updates file permissions. The company wants to maintain the same deployment functionality through the shift to using AWS services.\nWhich solution will meet these requirements?","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/52608-exam-aws-devops-engineer-professional-topic-1-question-61/","topic":"1","answers_community":["D (67%)","B (33%)"],"answer":"D","isMC":true,"timestamp":"2021-05-13 12:30:00","question_images":[],"question_id":167,"discussion":[{"timestamp":"1632732540.0","comments":[{"poster":"happydaze","content":"You can test with codedeploy: https://aws.amazon.com/blogs/devops/how-to-test-and-debug-aws-codedeploy-locally-before-you-ship-your-code/#:~:text=You%20can%20test%20application%20code,local%20server%20or%20EC2%20instance.","timestamp":"1634337900.0","upvote_count":"1","comments":[{"comment_id":"536503","upvote_count":"3","content":"You can test application **code packages** (NOT application) on any machine that has the CodeDeploy agent installed before you deploy it through the service. Likewise, to debug locally, you just need to install the CodeDeploy agent on any machine, including your local server or EC2 instance.\nWhere as CodeBuild compiles your source code, runs unit tests, and produces artifacts that are ready to deploy.\nThe correct answer is D","timestamp":"1643579820.0","poster":"RightAnswers"}],"comment_id":"373753"}],"content":"D is the correct answer. CodeBuild to test the appliction.","upvote_count":"15","poster":"LB","comment_id":"356257"},{"content":"why not A ?","poster":"Goozian","comment_id":"681327","upvote_count":"5","timestamp":"1664327580.0"},{"content":"Requirement is to replace the current bash script. Answer A and D are out because the solution uses the script. Between B and C, the answer is B","comment_id":"1172090","poster":"jyrajan69","timestamp":"1710283920.0","upvote_count":"1"},{"content":"My answer is D","upvote_count":"1","poster":"DucSiu","comment_id":"1081689","timestamp":"1701097980.0"},{"poster":"bugincloud","upvote_count":"1","content":"Selected Answer: D\nyou should use codebuild for testing","timestamp":"1696043700.0","comment_id":"1021227"},{"comment_id":"960147","upvote_count":"1","poster":"availgopi","content":"which is correct, Correct answer or most votted.. bit confusing","timestamp":"1690093200.0"},{"comment_id":"868514","comments":[{"upvote_count":"1","content":"I think it is better to assume that CodeDeploy agent is installed on EC2 it order to test the code with CodeDeploy than to go against the main requirement for replacement its current bash scripts, so that's why I marked B as an answer.","timestamp":"1681315140.0","poster":"daheck","comment_id":"868522"}],"content":"Selected Answer: B\nSince the company wants to use AWS development tools to replace its current bash deployment scripts I don't see any point to choose D.","poster":"daheck","timestamp":"1681314780.0","upvote_count":"1"},{"poster":"krr_aws","comment_id":"834388","upvote_count":"1","content":"D is the most appropriate. However, the company wants to replace bash deployment scripts. D suggests using them. hence B serves the company's requirements.","timestamp":"1678394160.0"},{"content":"Selected Answer: B\nOption B is the most appropriate solution because it uses AWS CodePipeline to move the application from the AWS CodeCommit repository to AWS CodeDeploy, which can test the application, unregister and re-register instances with the ALB, and restart services. The appspec.yml file can be used to update the permissions without a custom script.","timestamp":"1677193320.0","poster":"DevOpsJagadGuru","upvote_count":"2","comment_id":"819864"},{"poster":"Bulti","comment_id":"778479","timestamp":"1673922180.0","content":"D is correct.","upvote_count":"1"},{"timestamp":"1671799980.0","content":"d is correct","poster":"Chinta","comment_id":"754209","upvote_count":"2"},{"timestamp":"1664101020.0","upvote_count":"3","poster":"RightAnswers","comment_id":"678692","content":"Selected Answer: D\nThough Codedeploy can be used for unit testing applications, it requires Codedeploy agents installed on the machine (https://aws.amazon.com/blogs/devops/how-to-test-and-debug-aws-codedeploy-locally-before-you-ship-your-code/#:~:text=You%20can%20test%20application%20code,local%20server%20or%20EC2%20instance). However, the correct approach is to use Codebuild for unit testing.\nA: Incorrect: There is no deployment pipeline. Uses only Codebuild\nB and C: Incorrect: Codebuild is used for testing - not Codedeploy\nD: Correct. Has Codepipeline, Codebuild for unit testing and Codedeploy"},{"comment_id":"545381","timestamp":"1644591000.0","upvote_count":"2","content":"Selected Answer: D\nD, use CodeBuild for unit tests, CodeDeploy to run scripts","poster":"blueorca"},{"timestamp":"1636048800.0","comment_id":"403038","upvote_count":"3","poster":"nsei","content":"D is correct. Unit testing should be done with CodeBuild"},{"poster":"D2","upvote_count":"2","content":"D is correct","comment_id":"383061","timestamp":"1635801240.0"},{"comments":[{"comment_id":"510006","content":"If the question doesn't say the agent is installed, you assume it is not.","timestamp":"1640578080.0","comments":[{"upvote_count":"2","comment_id":"800920","poster":"Piccaso","content":"Gee ......","timestamp":"1675775940.0"}],"poster":"GreatFunana","upvote_count":"3"}],"upvote_count":"5","comment_id":"373755","poster":"happydaze","content":"B is correct, you can test with codedeploy as long as the agent is installed..","timestamp":"1635754380.0"}],"exam_id":35,"answer_ET":"D","unix_timestamp":1620901800,"choices":{"B":"Use AWS CodePipeline to move the application from the AWS CodeCommit repository to AWS CodeDeploy. Use CodeDeploy's deployment group to test the application, unregister and re-register instances with the ALB, and restart services. Use the appspec.yml file to update the permissions without a custom script.","C":"Use AWS CodePipeline to move the application source code from the AWS CodeCommit repository to AWS CodeDeploy. Use CodeDeploy to test the application. Use CodeDeploy's appspec.yml file to restart services and update permissions without a custom script. Use AWS CodeBuild to unregister and re- register instances with the ALB.","A":"Use AWS CodeBuild to test the application. Use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services, and deregister and register instances with the ALB. Use the appspec.yml file to update file permissions without a custom script.","D":"Use AWS CodePipeline to trigger AWS CodeBuild to test the application. Use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services. Unregister and re-register the instances in the AWS CodeDeploy deployment group with the ALB. Update the appspec.yml file to update file permissions without a custom script."},"answer_description":""},{"id":"us2zD9A3JnDw0Rw1X2w1","question_text":"A company gives its employees limited rights to AWS. DevOps engineers have the ability to assume an administrator role. For tracking purposes, the security team wants to receive a near-real-time notification when the administrator role is assumed.\nHow should this be accomplished?","unix_timestamp":1620906420,"answers_community":["D (70%)","C (30%)"],"exam_id":35,"answer":"D","answer_description":"","timestamp":"2021-05-13 13:47:00","url":"https://www.examtopics.com/discussions/amazon/view/52620-exam-aws-devops-engineer-professional-topic-1-question-62/","isMC":true,"topic":"1","answer_images":[],"choices":{"B":"Configure Amazon GuardDuty to monitor when the administrator role is assumed and send a notification to the security team.","C":"Create an Amazon EventBridge (Amazon CloudWatch Events) event rule using an AWS Management Console sign-in events event pattern that publishes a message to an Amazon SNS topic if the administrator role is assumed.","D":"Create an Amazon EventBridge (Amazon CloudWatch Events) events rule using an AWS API call that uses an AWS CloudTrail event pattern to trigger an AWS Lambda function that publishes a message to an Amazon SNS topic if the administrator role is assumed.","A":"Configure AWS Config to publish logs to an Amazon S3 bucket. Use Amazon Athena to query the logs and send a notification to the security team when the administrator role is assumed."},"question_id":168,"discussion":[{"timestamp":"1633609980.0","comments":[{"timestamp":"1633782900.0","content":"This is the most convincing answer. Thanks D2","comment_id":"429929","upvote_count":"1","poster":"StelSen"}],"upvote_count":"19","content":"D should be right answer as it covers all methods of assuming admin role - not just management console","comment_id":"389170","poster":"D2"},{"poster":"LB","upvote_count":"13","comments":[{"poster":"justfmm","upvote_count":"3","timestamp":"1635672480.0","comments":[{"content":"The questions says Near Real time and not real time","timestamp":"1672152780.0","poster":"saggy4","comment_id":"758660","upvote_count":"2"}],"content":"Why is D the answer ? CloudTrail takes up to 15mins whereby question ask for near real time.","comment_id":"465665"}],"comment_id":"356332","content":"D is the answer here","timestamp":"1633043400.0"},{"upvote_count":"1","comment_id":"819870","content":"Selected Answer: D\nThe correct answer is option D.\n\nExplanation:\nTo track the assumption of an AWS administrator role in near real-time, you can use Amazon CloudWatch Events and AWS CloudTrail.\n\nAmazon CloudWatch Events allows you to create rules that can match incoming events and take action on them. You can use an AWS CloudTrail event pattern to match the event where the administrator role is assumed.\n\nWhen an event rule matches an incoming event, it triggers an AWS Lambda function. You can configure the Lambda function to publish a message to an Amazon SNS topic that notifies the security team.\n\nTherefore, option D is the correct answer as it provides a near-real-time notification to the security team when the administrator role is assumed by using Amazon EventBridge (CloudWatch Events) events rule, AWS CloudTrail event pattern, AWS Lambda function, and Amazon SNS.","poster":"DevOpsJagadGuru","timestamp":"1677193680.0"},{"poster":"Sabreen_Salama","content":"I think it is D","timestamp":"1676119440.0","upvote_count":"1","comment_id":"805205"},{"comment_id":"800935","poster":"Piccaso","upvote_count":"1","timestamp":"1675776480.0","content":"Selected Answer: C\nD must be doable. C is much easier."},{"upvote_count":"3","poster":"damians106","timestamp":"1674596760.0","content":"Selected Answer: D\nD is the asnwer.\n\nExample:\n \"detail\": {\n \"eventVersion\": \"1.08\",\n \"userIdentity\": {\n \"type\": \"AssumedRole\",\n \"principalId\": \"XYZZYOR:admin\",\n \"arn\": \"arn:aws:sts::123456789012:role/admin\",\n \"accountId\": \"123456789012\",\n \"accessKeyId\": \"XYZZY\",\n \"sessionContext\": {\n \"sessionIssuer\": {\n \"type\": \"Role\",\n \"principalId\": \"XYZZYOR\",\n \"arn\": \"arn:aws:iam::123456789012:role/Admin\",\n \"accountId\": \"123456789012\",\n \"userName\": \"Admin\"\n },\n \"webIdFederationData\": {},\n \"attributes\": {\n \"creationDate\": \"2022-02-17T09:41:02Z\",\n \"mfaAuthenticated\": \"false\"\n }\n }\n },","comment_id":"786995"},{"comment_id":"778488","upvote_count":"4","content":"Answer is D. Based on the article below, assuming Role using STS ( IAM switchRole feature) is not considered as one of the AWS Console Sign-in events. Only direct sign-in using root and IAM user along with federated sign-in using AWS SSO are considered to be AWS Console Sign-in events. But once you sign in, any role switching performed to login as an administrator in the master account is not considered a sign-in event. Also as it's possible to Assume role using STS: AssumeRole or AssumeRoleWithSAML API and therefore such events will not be logged in as Console Sign-in events even if my above explanation of Console Sign-in events is not accurate. As a result the correct answer is D.","comments":[{"timestamp":"1673923440.0","comment_id":"778491","upvote_count":"1","content":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-aws-console-sign-in-events.html","poster":"Bulti"}],"timestamp":"1673923440.0","poster":"Bulti"},{"upvote_count":"1","comment_id":"770762","content":"Selected Answer: D\nCloudTrail is near real time","poster":"nnope","timestamp":"1673289120.0"},{"comment_id":"754294","content":"Selected Answer: D\nREF : https://aws.amazon.com/blogs/mt/monitor-and-notify-on-aws-account-root-user-activity/","upvote_count":"1","timestamp":"1671806160.0","poster":"Arkarter"},{"content":"Selected Answer: D\nCloud trail - 'NEAR' real time is the key word","timestamp":"1670682960.0","poster":"SatenderRathee","comment_id":"741050","upvote_count":"1"},{"upvote_count":"2","timestamp":"1668986760.0","content":"Selected Answer: C\nC is right answer.","comment_id":"723078","poster":"bartekb3d"},{"content":"Selected Answer: D\nI go for D Since Cloudtrail deals with taking note of who or what accesses any API(in this instance login and assume roles API)","upvote_count":"1","timestamp":"1668370740.0","comment_id":"717504","poster":"flavins"},{"timestamp":"1667001240.0","comment_id":"706828","upvote_count":"1","poster":"keigan","content":"D\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html#cloudtrail-integration_apis"},{"upvote_count":"3","timestamp":"1664101920.0","content":"Selected Answer: D\nThe requirement is to track whenever the DevOps engineer assumes Admin role (not the console sign-in events as mentioned in answer C).\nCloudTrail logs attempts to sign into the AWS Management Console (https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-aws-console-sign-in-events.html). CloudTrail can be configured to send events to CloudWatch Logs, and CloudWatch sends an SNS notification.\nThe requirement is for a NEAR real time - unfortunately CloudTrail typically delivers logs within an average of about 15 minutes of an API call. This time is not guaranteed.","poster":"RightAnswers","comment_id":"678701"},{"upvote_count":"1","timestamp":"1660810140.0","content":"Selected Answer: C\nYou can use sns topic as an event bridge target. There’s no need to put lambda in between. This solution is easier to implement, cheaper and more straight forward.","comment_id":"648352","poster":"hubekpeter"},{"comment_id":"632483","upvote_count":"2","timestamp":"1658041200.0","comments":[{"upvote_count":"2","comment_id":"648354","timestamp":"1660810260.0","poster":"hubekpeter","content":"Actually there’s https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-aws-console-sign-in-events.html"}],"content":"Selected Answer: D\nThe answer is D \nThere is nothing like an AWS Management Console sign-in events event trigger","poster":"adebisiayo"},{"content":"Selected Answer: C\nhttps://aws.amazon.com/premiumsupport/knowledge-center/root-user-account-eventbridge-rule/\nrefer this link","poster":"ishitat","timestamp":"1655966160.0","upvote_count":"2","comment_id":"620809"},{"content":"Selected Answer: D\nD is the answer. \n\nAWS Management Console sign-in events have nothing to do with assuming role.","upvote_count":"1","poster":"monkalways","comment_id":"617370","timestamp":"1655406360.0"},{"upvote_count":"2","poster":"cox1960","content":"C, no need for Lambda. Note that both C and D are pretty slow as both use CloudTrail. C uses the event called \"AWS Console Sign In via CloudTrail\". Easier than D to configure and again no need for Lambda.","timestamp":"1652962740.0","comment_id":"603884"},{"upvote_count":"3","comment_id":"464850","content":"Based on this https://aws.amazon.com/blogs/mt/monitor-and-notify-on-aws-account-root-user-activity/ \nI believe D is the correct answer and yes I know not exactly the same scenario","poster":"Shenannigan","timestamp":"1634554020.0"},{"upvote_count":"4","content":"C is the right answer we can create a custom log filter on AWS Cloud trail events and send it SNS topic.\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html","timestamp":"1633352280.0","poster":"Sagardonthineni","comment_id":"382452","comments":[{"upvote_count":"1","timestamp":"1636585920.0","poster":"francisco_guerra","content":"Yes but the answer do not say anything about use a cloudWatch alarm to call the sns topic so the answer is D","comment_id":"475840"}]}],"answer_ET":"D","question_images":[]},{"id":"0mEMmK0v4owlZH55UOpQ","url":"https://www.examtopics.com/discussions/amazon/view/28676-exam-aws-devops-engineer-professional-topic-1-question-63/","discussion":[{"timestamp":"1633282020.0","poster":"Smart","comment_id":"158831","upvote_count":"13","content":"D is correct (https://aws.amazon.com/premiumsupport/knowledge-center/ec2-instance-retirement/)"},{"timestamp":"1675777200.0","content":"Selected Answer: D\nA is eliminated. Once a week may be not enough.\nB is eliminated. Recovery does not match this scenario.\nC is eliminated. Reboot does not match this scenario.","poster":"Piccaso","comment_id":"800941","upvote_count":"1"},{"poster":"Bulti","content":"D is the right answer.","upvote_count":"1","comment_id":"778492","timestamp":"1673923680.0"},{"upvote_count":"4","timestamp":"1664197500.0","comment_id":"679769","poster":"RightAnswers","content":"Selected Answer: D\nHere is the link:\nhttps://aws.amazon.com/blogs/mt/automate-remediation-actions-for-amazon-ec2-notifications-and-beyond-using-ec2-systems-manager-automation-and-aws-health/"},{"upvote_count":"3","content":"will go with D","poster":"gmandala","comment_id":"253120","timestamp":"1634705820.0"},{"upvote_count":"4","comment_id":"224467","content":"I'll go with D","poster":"jackdryan","timestamp":"1634466300.0"},{"timestamp":"1634073480.0","comment_id":"209803","content":"D is correct","upvote_count":"1","poster":"ChauPhan"}],"timestamp":"2020-08-15 21:00:00","answer_images":[],"exam_id":35,"answer_description":"","question_text":"An ecommerce company uses a large number of Amazon EBS backed Amazon EC2 instances. To decrease manual work across all the instances, a DevOps\nEngineer is tasked with automating restart actions when EC2 instance retirement events are scheduled.\nHow can this be accomplished?","answers_community":["D (100%)"],"answer":"D","answer_ET":"D","unix_timestamp":1597518000,"question_id":169,"topic":"1","question_images":[],"choices":{"A":"Create a scheduled Amazon CloudWatch Events rule to execute an AWS Systems Manager automation document that checks if any EC2 instances are scheduled for retirement once a week. If the instance is scheduled for retirement, the automation document will hibernate the instance.","D":"Set up an AWS Health Amazon CloudWatch Events rule to execute AWS Systems Manager automation documents that stop and start the EC2 instance when a retirement scheduled event occurs.","C":"Reboot all EC2 instances during an approved maintenance window that is outside of standard business hours. Set up Amazon CloudWatch alarms to send a notification in case any instance is failing EC2 instance status checks.","B":"Enable EC2 Auto Recovery on all of the instances. Create an AWS Config rule to limit the recovery to occur during a maintenance window only."},"isMC":true},{"id":"aHBxqo0Ue3VWih9tAqrP","url":"https://www.examtopics.com/discussions/amazon/view/47010-exam-aws-devops-engineer-professional-topic-1-question-64/","discussion":[{"timestamp":"1633478280.0","content":"I'll go with C\n\nReference: https://aws.amazon.com/blogs/mt/controlling-your-aws-costs-by-deleting-unused-amazon-ebs-volumes/","comments":[{"comment_id":"350612","comments":[{"upvote_count":"5","poster":"MBJames","comment_id":"401845","timestamp":"1635372420.0","content":"I'd go with D.\nThe way C is described, it would run daily and tag unattached EBS volumes with current date. This means that unattached EBS volumes will keep receiving the current date every day, and the date will never become 14 days old to be deleted. To be correct, C should have said that volumes already having the tag would not be tagged again, but that's not indicated.\nD is a much cleaner way of doing things as it does not relies on these logic faults."}],"poster":"JohnnieWalker","upvote_count":"10","content":"There are two correct answers in this question and not much of a reason to pick one over another, very poorly put. I will go with C.\n A. AWS Config nope\n B. Data Lifecycle Manager nope\n C. Lambda does the job and completely remove, no snapshots. The question says \"stale and no longer needed\", so I think that is the way to go.\nTrust Advisor and Lambda works too, but the difference here is that this one creates a snapshot, so should we keep or not? If the question says \"stale and no longer needed\" I don't think we should.","timestamp":"1634211540.0"}],"upvote_count":"27","poster":"WhyIronMan","comment_id":"325973"},{"poster":"Wrd123456789","upvote_count":"10","timestamp":"1634688900.0","comment_id":"362854","content":"D: https://github.com/aws/Trusted-Advisor-Tools/tree/master/UnderutilzedEBSVolumes\n\nThis is a serverless (Lambda) application that reacts to Trusted Advisor warnings via CloudWatch rules to detect and delete Underutilized EBS volumes - volumes that have been unattached or had low I/O for a number of days. The app will only delete idle, unattached volumes after successfully taking a snapshot. It sends an email with information on how to recover the volume from the snapshot.","comments":[{"comment_id":"467249","upvote_count":"3","content":"https://docs.aws.amazon.com/awssupport/latest/user/trusted-advisor-check-reference.html#underutilized-amazon-ebs-volumes","poster":"justfmm","timestamp":"1635744780.0"}]},{"timestamp":"1691379120.0","comment_id":"974360","upvote_count":"1","content":"I will go with C: Here are tolls that can be used to automate this: https://catalog.workshops.aws/msft-costopt/en-US/storage/ebs/unattached-ebs-volumes\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/delete-unused-amazon-elastic-block-store-amazon-ebs-volumes-by-using-aws-config-and-aws-systems-manager.html\n\nB is not correct because Amazon Data Lifecycle Manager manages EBS snapshots not volumes and EBS backed AMIs https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","poster":"DaddyDee"},{"upvote_count":"1","poster":"lunt","content":"Selected Answer: C\nA - only checks if volume or related instance is marked for termination/deletion. Nope.\nB. DLM cannot detect unattached volumes. Go actually try & configure it. You filter on tag & say delete volume after 14 days but you cannot specify if its attach or not - just tag filtering.\nD. Does not work.\nC. Only viable option.","comment_id":"968321","timestamp":"1690821960.0"},{"timestamp":"1677702900.0","content":"Selected Answer: C\nForce to choose C\nA. will not work correctly.\nB. DLM can work only with snapshots\nC. Correct\nD. Trusted advisor cannot check for unattached EBS for 14 days - it can only check for underutilized volumes - those volumes can also be attached and the check is for 7 days.\n\"Yellow: A volume is unattached or had less than 1 IOPS per day for the past 7 days.\"","comment_id":"826248","upvote_count":"3","poster":"asfsdfsdf"},{"timestamp":"1675777680.0","comment_id":"800951","upvote_count":"1","poster":"Piccaso","content":"Selected Answer: B\nData Lifecycle Manager is the most straightforward solution https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html"},{"content":"Correct answer is C. D is incorrect because Trusted Advisor detects only under provisioned and over provisioned EBS volume meaning utilization. If the EBS volume is already deattached and not utilized by any EC2 instance, then I don't think Trusted Advisor would detect that. I am not very sure about it but that's my guess. C seems logically correct. Some folks didn't select C because they thought Lambda will tag the unattached EBS volume each day ( again and again). But thats not true. Lambda will do so only once per EBS volume and therefore will be able to detect if a specifc volume was unused for 14 days and then delete it.","poster":"Bulti","comment_id":"778497","upvote_count":"2","timestamp":"1673924580.0"},{"upvote_count":"1","comment_id":"771460","poster":"PepsNick","content":"Selected Answer: C\nIt should be C not B. Data Lifecycle Manager is for EBS snapshots not the volume. https://aws.amazon.com/blogs/storage/automating-amazon-ebs-snapshot-and-ami-management-using-amazon-dlm/","timestamp":"1673358000.0"},{"poster":"saeidp","comment_id":"764073","timestamp":"1672698180.0","content":"Selected Answer: C\nI'll go with C","upvote_count":"2"},{"comment_id":"741054","upvote_count":"2","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/mt/controlling-your-aws-costs-by-deleting-unused-amazon-ebs-volumes/","timestamp":"1670683620.0","poster":"SatenderRathee"},{"upvote_count":"2","poster":"tinyflame","comment_id":"714235","timestamp":"1667961660.0","content":"Selected Answer: C\nAmazon Data Lifecycle Manager cannot discover unattached disks and AWS Trusted Advisor can only discover currently unattached disks\n\nThis question has a complicated request, so I have no choice but to rely on the Lambda function"},{"comment_id":"713541","poster":"srikanth923","upvote_count":"3","timestamp":"1667889900.0","content":"I will go with C\nA. AWS Config Checks if EBS volumes are attached to EC2 instances. If the volume is 'available state', then you configure CloudWatch Event to invoke a Lambda function. Lambda function will take care of deletion. Note that Config does not only trigger unused EBS volumes for 14 days, but every unused EBS volume(irrespective of the number of days its been unused). Though it can be made work, its not the most efficient solution\nB. Data Lifecycle Manager only looks at EBS snapshot lifecycle. Not the EBS volumes itself\nC. Lambda function triggered periodically and tagging the new volumes and checking if already tagged volumes are >= 14 days old. If it finds any >= 14 days old, Lambda will delete them\n4. Trusted advisor does not check for unused volumes, it checks for under utilised EBS volumes\nSo C is the best answer in this context."},{"content":"Selected Answer: A\nAt first I thought Ans D seems the best option - but this answers creates a snapshot. creating a snapshot is not a requirement.\nSo, A seems to be the best option.","upvote_count":"1","poster":"RightAnswers","timestamp":"1664198520.0","comment_id":"679784"},{"timestamp":"1663578120.0","content":"Though few of the the answers are poorly worded, D seems to be best of the lot. With A it is not clear how config will identify it is 14 days since volume was unattached, B works with lifecycle of snapshots, not directly with lifecycle of volume, C has a logic flaw if date is updated D. That leaves D(though it is not clear how D will be automated and why it is creating snapshots before delete when not asked in Qs.)","poster":"network_zeal","upvote_count":"2","comments":[{"content":"With C, the lambda will update date tag daily with current date","timestamp":"1663578120.0","upvote_count":"2","poster":"network_zeal","comment_id":"673102"}],"comment_id":"673101"},{"upvote_count":"1","content":"Selected Answer: B\nhonestly there is no correct ans here.\n\nthe closest is C, it would hv been logically doable if the tagging of current date is mentioned AFTER the function/logic that detects & delete 14 days old EBS.\n\nI choose B still. Though tt \"Use Amazon EC2 and Amazon Data Lifecycle Manager to configure a volume lifecycle policy\" line sounds so wrong.","comment_id":"671887","timestamp":"1663460880.0","poster":"colinquek"},{"comment_id":"662905","content":"D makes more sense. Trusted Advisor is designed to give you information about underutilized ebs volumes.","upvote_count":"1","timestamp":"1662586200.0","poster":"ohcn"},{"comment_id":"654569","upvote_count":"2","poster":"jexam211","content":"Selected Answer: C\nD maybe is valid, but i don't see any way to create a automatic way to detect, the C option at least is performing a daily task to validate the volumes","timestamp":"1661906760.0"},{"comment_id":"653081","poster":"vagobago","content":"Selected Answer: B\nAmazon Data Lifecycle Manager is normally the tool for performing cleaning of EBS Snapshots. So, I would got with B","upvote_count":"1","timestamp":"1661710620.0"},{"content":"For C, what if the volume get re-attached some day and detached. Will the Lambda noticed it? no.","timestamp":"1659860400.0","comment_id":"643634","upvote_count":"1","poster":"cox1960"},{"poster":"toma","content":"it is A defiantly.","comment_id":"638345","upvote_count":"1","timestamp":"1658959200.0"},{"comment_id":"636827","upvote_count":"1","poster":"nebojsaMa","content":"Selected Answer: B\nB is correct see the link https://aws.amazon.com/about-aws/whats-new/2018/07/introducing-amazon-data-lifecycle-manager-for-ebs-snapshots/?nc1=h_ls","timestamp":"1658767080.0"},{"content":"Selected Answer: B\nB is correct https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","upvote_count":"1","comment_id":"630155","poster":"nebojsaMa","timestamp":"1657561680.0"},{"content":"Selected Answer: C\nVote C","comment_id":"622415","timestamp":"1656232500.0","upvote_count":"1","poster":"nqthien041292"},{"poster":"friendofpenguin","content":"B\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","comment_id":"583725","timestamp":"1649599320.0","upvote_count":"1"},{"comment_id":"560534","timestamp":"1646368740.0","upvote_count":"2","content":"Selected Answer: A\nec2-volume-inuse-check managed rule is the best . \nOption D creates a snapshot , strange.","poster":"[Removed]"},{"poster":"blueorca","timestamp":"1644439380.0","comment_id":"544091","content":"Selected Answer: C\nI'd pick C","upvote_count":"1"},{"poster":"Bad_Mat","content":"If we need to delete a volume, what point to create a snapshot?","timestamp":"1636076760.0","comment_id":"470918","upvote_count":"1"},{"timestamp":"1633992780.0","content":"C or D :D https://github.com/aws/Trusted-Advisor-Tools/tree/master/UnderutilzedEBSVolumes","comment_id":"338313","poster":"twanc","upvote_count":"1"},{"timestamp":"1632947700.0","content":"Correct Answer: d","upvote_count":"2","comment_id":"322389","poster":"aws_Tamilan"},{"poster":"yyy","content":"I will go with C: because the lambda runs each day","comment_id":"318304","timestamp":"1632531120.0","upvote_count":"3"},{"poster":"Jordanro","content":"I will go with C","timestamp":"1632332280.0","comment_id":"313195","upvote_count":"3"},{"content":"ans: A","poster":"Rajarshi","comment_id":"310312","upvote_count":"5","timestamp":"1632233280.0"}],"answer_images":[],"timestamp":"2021-03-14 07:03:00","exam_id":35,"answer_description":"","question_text":"A company that runs many workloads on AWS has an Amazon EBS spend that has increased over time. The DevOps team notices there are many unattached\nEBS volumes. Although there are workloads where volumes are detached, volumes over 14 days old are stale and no longer needed. A DevOps engineer has been tasked with creating automation that deletes unattached EBS volumes that have been unattached for 14 days.\nWhich solution will accomplish this?","answers_community":["C (65%)","B (22%)","13%"],"answer":"C","answer_ET":"C","unix_timestamp":1615701780,"question_id":170,"topic":"1","question_images":[],"choices":{"A":"Configure the AWS Config ec2-volume-inuse-check managed rule with a configuration changes trigger type and an Amazon EC2 volume resource target. Create a new Amazon CloudWatch Events rule scheduled to execute an AWS Lambda function in 14 days to delete the specified EBS volume.","B":"Use Amazon EC2 and Amazon Data Lifecycle Manager to configure a volume lifecycle policy. Set the interval period for unattached EBS volumes to 14 days and set the retention rule to delete. Set the policy target volumes as *.","C":"Create an Amazon CloudWatch Events rule to execute an AWS Lambda function daily. The Lambda function should find unattached EBS volumes and tag them with the current date, and delete unattached volumes that have tags with dates that are more than 14 days old.","D":"Use AWS Trusted Advisor to detect EBS volumes that have been detached for more than 14 days. Execute an AWS Lambda function that creates a snapshot and then deletes the EBS volume."},"isMC":true}],"exam":{"provider":"Amazon","lastUpdated":"11 Apr 2025","isMCOnly":false,"name":"AWS DevOps Engineer Professional","id":35,"numberOfQuestions":208,"isBeta":false,"isImplemented":true},"currentPage":34},"__N_SSP":true}