{"pageProps":{"questions":[{"id":"o5FgaAKSUqD3hyfZ29BZ","answer":"AD","topic":"1","question_id":391,"discussion":[{"upvote_count":"9","poster":"AdamWest","comment_id":"734610","comments":[{"content":"AD is right, I agree. Question is too big for killing time","poster":"AzureDP900","timestamp":"1677983940.0","upvote_count":"1","comment_id":"829574"}],"timestamp":"1670089800.0","content":"Selected Answer: AD\nAD - Use macie for sensitive data discovery.\nUse Athena for API searches. Using Athena with CloudTrail logs is a powerful way to enhance your analysis of AWS service activity. For example, you can use queries to identify trends and further isolate activity by attributes, such as Access Keys\n\nA common application is to use CloudTrail logs to analyze operational activity for security and compliance"},{"poster":"selim507","content":"Selected Answer: AD\nI got tired of reading the question...","comment_id":"789415","upvote_count":"6","timestamp":"1674806580.0"},{"timestamp":"1681835160.0","content":"I am not sure why people chose D. As D shows querying on DOC-Example-Bucket2 while the question is answering if any objects in DOC-EXAMPLE-BUCKET1 were accessed. So with that in mind, C and D is out. You left A, B, and E. B is out due to Cloudtrail has not been configured to send logs to the CloudWatch Logs. We are left with A and E.","comments":[{"content":"Nevermind, I change my answer to A D. Because Cloudtrail was configured previously, hence will be sending the logs that shows the API calls that used the access key to access the object","comment_id":"878601","poster":"Kezuko","upvote_count":"1","timestamp":"1682266980.0"}],"upvote_count":"1","poster":"Kezuko","comment_id":"873853"},{"poster":"Balki","timestamp":"1670780100.0","comment_id":"741936","upvote_count":"2","content":"Selected Answer: AD\nOnly reason why we cannot choose B is , Cloudtrail doesnt log to Cloudwatch. Else, we can choose that. So, A&D"}],"answers_community":["AD (100%)"],"timestamp":"2022-12-03 18:50:00","choices":{"A":"Configure Amazon Macie to identify any objects in DOC-EXAMPLE-BUCKET1 that contain PII and that were available to the access key.","C":"Use Amazon OpenSearch Service (Amazon Elasticsearch Service) to query the CloudTrail logs in DOC-EXAMPLE-BUCKET2 for API calls that used the access key to access an object that contained PII.","D":"Use Amazon Athena to query the CloudTrail logs in DOC-EXAMPLE-BUCKET2 for any API calls that used the access key to access an object that contained PII.","B":"Use Amazon CloudWatch Logs Insights to identify any objects in DOC-EXAMPLE-BUCKET1 that contain PII and that were available to the access key.","E":"Use AWS Identity and Access Management Access Analyzer to identify any API calls that used the access key to access objects that contained PII in DOC-EXAMPLE-BUCKET1."},"answer_ET":"AD","question_text":"A company has a legacy application that runs on a single Amazon EC2 instance. A security audit shows that the application has been using an IAM access key within its code to access an Amazon S3 bucket that is named DOC-EXAMPLE-BUCKET1 in the same AWS account. This access key pair has the s3:GetObject permission to all objects in only this S3 bucket. The company takes the application offline because the application is not compliant with the company’s security policies for accessing other AWS resources from Amazon EC2.\n\nA security engineer validates that AWS CloudTrail is turned on in all AWS Regions. CloudTrail is sending logs to an S3 bucket that is named DOC-EXAMPLE-BUCKET2. This S3 bucket is in the same AWS account as DOC-EXAMPLE-BUCKET1. However, CloudTrail has not been configured to send logs to Amazon CloudWatch Logs.\n\nThe company wants to know if any objects in DOC-EXAMPLE-BUCKET1 were accessed with the IAM access key in the past 60 days. If any objects were accessed, the company wants to know if any of the objects that are text files (.txt extension) contained personally identifiable information (PII).\n\nWhich combination of steps should the security engineer take to gather this information? (Choose two.)","url":"https://www.examtopics.com/discussions/amazon/view/89893-exam-aws-certified-security-specialty-topic-1-question-450/","exam_id":29,"answer_description":"","answer_images":[],"unix_timestamp":1670089800,"question_images":[],"isMC":true},{"id":"rWhMXxVVMfrrNoarGA0f","url":"https://www.examtopics.com/discussions/amazon/view/89514-exam-aws-certified-security-specialty-topic-1-question-451/","question_text":"An international company has established a new business entity in South Korea. The company also has established a new AWS account to contain the workload for the South Korean region. The company has set up the workload in the new account in the ap-northeast-2 Region. The workload consists of three Auto Scaling groups of Amazon EC2 instances. All workloads that operate in this Region must keep system logs and application logs for 7 years.\n\nA security engineer must implement a solution to ensure that no logging data is lost for each instance during scaling activities. The solution also must keep the logs for only the required period of 7 years.\n\nWhich combination of steps should the security engineer take to meet these requirements? (Choose three.)","discussion":[{"upvote_count":"7","content":"Selected Answer: ABC\nABC - Agree Cloudwatch logs can be stored for 10 years. Its more expensive than S3 but thats not what the ask it.","poster":"AdamWest","comment_id":"734605","timestamp":"1670089080.0"},{"upvote_count":"1","timestamp":"1710974280.0","content":"F and B are not valid \nAWS CloudWatch log retention - Log retention – By default, logs are kept indefinitely and never expire. You can adjust the retention policy for each log group, keeping the indefinite retention, or choosing a retention period between 10 years and one day.","poster":"hro","comment_id":"1178815"},{"content":"I appeared for the exam on 02/14/2024 and there were barely 14 questions in the exam from this bank. Folks, please be careful and don’t rely on this question bank. Do your own prep otherwise you will definitely not clear it if you just rely on this alone.","comment_id":"1154160","upvote_count":"2","timestamp":"1708364700.0","poster":"MikeRach"},{"poster":"createchange","timestamp":"1677096840.0","content":"Selected Answer: ABC\nThe answers are separated cleanly. 3 refer to CloudWatch, whereas the other 3 refer to S3. \n\nAnswer E talks about \"periodically bundling the logs\" before sending to S3. This does not accomplish ensuring that no logs are lost, as bundling could not have occurred for a period of time before a scale-in event. As such, the answer must be ABC.","comment_id":"818360","upvote_count":"4"},{"content":"Selected abc","timestamp":"1672746840.0","comment_id":"764601","upvote_count":"2","poster":"jishrajesh"},{"comment_id":"739797","upvote_count":"2","poster":"Isaias","timestamp":"1670560860.0","content":"ABC Agree.. It could not send logs to s3 directly from an Instance or app instance"},{"comment_id":"732313","upvote_count":"3","poster":"D2","content":"Selected Answer: ABC\nAnswer ABC","timestamp":"1669874640.0"}],"answer_description":"","answer_ET":"ABC","question_id":392,"topic":"1","unix_timestamp":1669874640,"answer":"ABC","isMC":true,"choices":{"F":"Configure an Amazon S3 Lifecycle policy on the target S3 bucket to expire objects after 7 years.","C":"Attach an IAM role to the launch configuration or launch template that the Auto Scaling groups use. Configure the role to provide the necessary permissions to forward logs to Amazon CloudWatch Logs.","E":"Ensure that a log forwarding application is installed on all the EC2 instances that the Auto Scaling groups launch. Configure the log forwarding application to periodically bundle the logs and forward the logs to Amazon S3.","B":"Set the log retention for desired log groups to 7 years.","D":"Attach an IAM role to the launch configuration or launch template that the Auto Scaling groups use. Configure the role to provide the necessary permissions to forward logs to Amazon S3.","A":"Ensure that the Amazon CloudWatch agent is installed on all the EC2 instances that the Auto Scaling groups launch. Generate a CloudWatch agent configuration file to forward the required logs to Amazon CloudWatch Logs."},"question_images":[],"timestamp":"2022-12-01 07:04:00","answers_community":["ABC (100%)"],"answer_images":[],"exam_id":29},{"id":"eiLgNJW8eRzu2PTgW8TT","answer":"D","topic":"1","question_id":393,"discussion":[{"comment_id":"730173","upvote_count":"8","timestamp":"1669714920.0","content":"Answer D\nhttps://docs.aws.amazon.com/waf/latest/developerguide/ddos-cloudwatch-metrics.html","poster":"D2"},{"comment_id":"829577","upvote_count":"1","content":"D is right","timestamp":"1677984180.0","poster":"AzureDP900"},{"upvote_count":"2","content":"Selected Answer: D\nAWS Shield Advanced is specifically made to prevent DDoS attacks. AWS Firewall Manager is used to manage firewall roles, got nothing to do with the DDoS","comment_id":"768814","timestamp":"1673116140.0","poster":"Greyer"},{"comment_id":"734602","timestamp":"1670088780.0","poster":"AdamWest","content":"Selected Answer: D\nD - is the answer.","upvote_count":"4"}],"answers_community":["D (100%)"],"timestamp":"2022-11-29 10:42:00","answer_ET":"D","choices":{"C":"Create an Amazon CloudWatch alarm that monitors Firewall Manager metrics for an active DDoS event.","D":"Create an Amazon CloudWatch alarm that monitors Shield Advanced metrics for an active DDoS event.","B":"Use Amazon Inspector to review resources and to invoke Amazon CloudWatch alarms for any resources that are vulnerable to DDoS attacks.","A":"Use Macie to detect an active DDoS event. Create Amazon CloudWatch alarms that respond to Macie findings."},"question_text":"A company is using Amazon Macie, AWS Firewall Manager, Amazon Inspector, and AWS Shield Advanced in its AWS account. The company wants to receive alerts if a DDoS attack occurs against the account.\n\nWhich solution will meet this requirement?","url":"https://www.examtopics.com/discussions/amazon/view/89223-exam-aws-certified-security-specialty-topic-1-question-452/","exam_id":29,"answer_description":"","answer_images":[],"unix_timestamp":1669714920,"question_images":[],"isMC":true},{"id":"2ZNsw27qdVyIoJe17NaF","isMC":true,"answer_ET":"AC","answers_community":["AC (100%)"],"answer_description":"","question_text":"A company accidentally deleted the private key for an Amazon Elastic Block Store (Amazon EBS)-backed Amazon EC2 instance. A security engineer needs to regain access to the instance.\n\nWhich combination of steps will meet this requirement? (Choose two.)","question_id":394,"topic":"1","answer_images":[],"choices":{"A":"Stop the instance. Detach the root volume. Generate a new key pair.","B":"Keep the instance running. Detach the root volume. Generate a new key pair.","C":"When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new public key. Move the volume back to the original instance. Start the instance.","D":"When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new private key. Move the volume back to the original instance. Start the instance.","E":"When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new public key. Move the volume back to the original instance that is running."},"answer":"AC","timestamp":"2022-11-29 10:52:00","unix_timestamp":1669715520,"question_images":[],"discussion":[{"comments":[{"comments":[{"poster":"cherry23","upvote_count":"1","comment_id":"942866","timestamp":"1688480760.0","content":"Got it. It's ec2 key pair not kms key"}],"poster":"cherry23","content":"Answer is correct but how does generating a new key pair recovers data encrypted by old key?","timestamp":"1688480520.0","comment_id":"942859","upvote_count":"1"},{"content":"Agreed","upvote_count":"1","timestamp":"1677984360.0","poster":"AzureDP900","comment_id":"829579"}],"content":"Selected Answer: AC\nIf you lose the private key for an EBS-backed instance, you can regain access to your instance. You must stop the instance, detach its root volume and attach it to another instance as a data volume, modify the authorized_keys file with a new public key, move the volume back to the original instance, and restart the instance. \n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#replacing-lost-key-pai","poster":"kerar","comment_id":"733857","timestamp":"1669993680.0","upvote_count":"8"},{"comment_id":"1039659","poster":"[Removed]","upvote_count":"1","timestamp":"1696956900.0","content":"Selected Answer: AC\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#replacing-lost-key-pair\n\nStep 1: Create a new key pair\nStep 2: Get information about the original instance and its root volume\nStep 3: Stop the original instance\nStep 4: Launch a temporary instance\nStep 5: Detach the root volume from the original instance and attach it to the temporary instance\nStep 6: Add the new public key to authorized_keys on the original volume mounted to the temporary instance\nStep 7: Unmount and detach the original volume from the temporary instance, and reattach it to the original instance\nStep 8: Connect to the original instance using the new key pair\nStep 9: Clean up"},{"content":"Selected Answer: AC\nIf you lose the private key for an EBS-backed instance, you can regain access to your instance. You must stop the instance, detach its root volume and attach it to another instance as a data volume, modify the authorized_keys file with a new public key, move the volume back to the original instance, and restart the instance. For more information about launching, connecting to, and stopping instances, see Instance lifecycle.\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#replacing-lost-key-pair","timestamp":"1674560760.0","upvote_count":"2","comment_id":"786477","poster":"ygen"},{"comment_id":"730191","timestamp":"1669715520.0","poster":"D2","upvote_count":"4","content":"Selected Answer: AC\nAnswer AC\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#replacing-lost-key-pair"}],"exam_id":29,"url":"https://www.examtopics.com/discussions/amazon/view/89226-exam-aws-certified-security-specialty-topic-1-question-453/"},{"id":"L5yTrCHLJWzv7SUpnBaT","url":"https://www.examtopics.com/discussions/amazon/view/89227-exam-aws-certified-security-specialty-topic-1-question-454/","answer_images":[],"answer_description":"","isMC":true,"answer_ET":"B","answers_community":["B (85%)","D (15%)"],"exam_id":29,"answer":"B","timestamp":"2022-11-29 10:54:00","unix_timestamp":1669715640,"choices":{"C":"","A":"","B":"","D":""},"discussion":[{"poster":"Singhh","comment_id":"731615","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies-vpc-endpoint.html","upvote_count":"7","timestamp":"1669819380.0"},{"comment_id":"928992","timestamp":"1687315860.0","poster":"Green53","content":"Selected Answer: B\nThe policy must *deny* all access, so it's B. If the 'D' policy is used, an entity with an IAM policy allowing access to the bucket would be granted access.\nOnly an explicit deny will stop this.","upvote_count":"2"},{"timestamp":"1686736440.0","poster":"kuber2023","upvote_count":"2","content":"Selected Answer: D\nWhy not D, explicit allow.\nB is an explicit deny if vpce does not match, but where is the allow?","comment_id":"922948"},{"content":"Selected Answer: B\nB makes sense","poster":"Toptip","upvote_count":"1","comment_id":"915317","timestamp":"1685960040.0"},{"timestamp":"1677984480.0","comment_id":"829580","upvote_count":"2","poster":"AzureDP900","content":"B is correct"},{"upvote_count":"1","comment_id":"730194","poster":"D2","content":"Selected Answer: B\nAnswer B","timestamp":"1669715640.0"}],"topic":"1","question_text":"A security engineer needs to configure an Amazon S3 bucket policy to restrict access to an S3 bucket that is named DOC-EXAMPLE-BUCKET. The policy must allow access to only DOC-EXAMPLE-BUCKET from only the following endpoint: vpce-1a2b3c4d. The policy must deny all access to DOC-EXAMPLE-BUCKET if the specified endpoint is not used.\n\nWhich bucket policy statement meets these requirements?","question_images":[],"question_id":395}],"exam":{"name":"AWS Certified Security - Specialty","numberOfQuestions":509,"isImplemented":true,"id":29,"lastUpdated":"11 Apr 2025","isBeta":false,"provider":"Amazon","isMCOnly":false},"currentPage":79},"__N_SSP":true}