{"pageProps":{"questions":[{"id":"HOhbQrhFzh34m8FHxwbw","question_text":"A company is building a sensor data collection pipeline in which thousands of sensors write data to an Amazon Simple Queue Service (Amazon SQS) queue every minute. The queue is processed by an AWS Lambda function that extracts a standard set of metrics from the sensor data. The company wants to send the data to Amazon CloudWatch. The solution should allow for viewing individual and aggregate sensor metrics and interactively querying the sensor log data using\nCloudWatch Logs Insights.\nWhat is the MOST cost-effective solution that meets these requirements?","answer":"A","answer_ET":"C","question_id":701,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/47267-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1615858200,"choices":{"B":"Write the processed data to CloudWatch Logs. Then write the data to CloudWatch by using the PutMetricData API call.","D":"Configure the CloudWatch Logs agent for AWS Lambda. Output the metrics for each sensor in statsd format with tags to uniquely identify a sensor. Write the processed data to CloudWatch Logs.","A":"Write the processed data to CloudWatch Logs in the CloudWatch embedded metric format.","C":"Write the processed data to CloudWatch Logs in a structured format. Create a CloudWatch metric filter to parse the logs and publish the metrics to CloudWatch with dimensions to uniquely identify a sensor."},"answer_description":"","timestamp":"2021-03-16 02:30:00","topic":"1","answers_community":["A (100%)"],"answer_images":[],"discussion":[{"timestamp":"1632224880.0","comment_id":"311899","content":"A\nThe CloudWatch embedded metric format is a JSON specification used to instruct CloudWatch Logs to automatically extract metric values embedded in structured log events. You can use CloudWatch to graph and create alarms on the extracted metric values.","upvote_count":"22","poster":"sek12324"},{"timestamp":"1686324960.0","poster":"claymannain","comment_id":"919436","content":"A\nInstall the CloudWatch agent on the host where the processed data is generated.\nConfigure the CloudWatch agent to collect the processed data in the CloudWatch embedded metric format.\nStart the CloudWatch agent.\nThe CloudWatch agent will collect the processed data and send it to CloudWatch Logs. CloudWatch Logs will store the data in a log group. You can then use CloudWatch Metrics to graph and analyze the data.\n\nHere is an example of a CloudWatch embedded metric log event:\n\nCode snippet\n{\n \"timestamp\": \"2023-06-09T11:23:45Z\",\n \"message\": \"Processed data: 1234567890\",\n \"metric\": {\n \"name\": \"processed_data\",\n \"value\": 1234567890\n }\n}","upvote_count":"1"},{"poster":"kangtamo","comment_id":"613023","upvote_count":"2","timestamp":"1654654260.0","content":"Selected Answer: A\nGo with A"},{"upvote_count":"2","content":"A is right\n\nhttps://aws.amazon.com/about-aws/whats-new/2019/11/amazon-cloudwatch-launches-embedded-metric-format/","comment_id":"497072","poster":"AzureDP900","timestamp":"1638988380.0"},{"poster":"andylogan","content":"It's A","timestamp":"1636221720.0","comment_id":"447556","upvote_count":"1"},{"poster":"tgv","comment_id":"435348","timestamp":"1635313860.0","upvote_count":"1","content":"AAA\n---"},{"content":"A is the answer.","poster":"blackgamer","timestamp":"1635181620.0","upvote_count":"1","comment_id":"434296"},{"comment_id":"414085","upvote_count":"2","timestamp":"1634910240.0","content":"I'll go with A","poster":"WhyIronMan"},{"poster":"Waiweng","timestamp":"1634270280.0","content":"it's A","upvote_count":"3","comment_id":"359192"},{"timestamp":"1632948600.0","comment_id":"340178","upvote_count":"2","content":"A is correct. https://aws.amazon.com/about-aws/whats-new/2019/11/amazon-cloudwatch-launches-embedded-metric-format/","poster":"Kelvin"},{"content":"A.\nhttps://aws.amazon.com/about-aws/whats-new/2019/11/amazon-cloudwatch-launches-embedded-metric-format/","upvote_count":"3","comment_id":"329998","poster":"Pupu86","timestamp":"1632615900.0"},{"upvote_count":"1","content":"Going with A","timestamp":"1632402480.0","comment_id":"321514","poster":"champcloud"}],"question_images":[],"exam_id":32},{"id":"jhbLJsOrs7gNfrtgMU69","question_text":"A car rental company has built a serverless REST API to provide data to its mobile app. The app consists of an Amazon API Gateway API with a Regional endpoint, AWS Lambda functions, and an Amazon Aurora MySQL Serverless DB cluster. The company recently opened the API to mobile apps of partners. A significant increase in the number of requests resulted, causing sporadic database memory errors. Analysis of the API traffic indicates that clients are making multiple HTTP GET requests for the same queries in a short period of time. Traffic is concentrated during business hours, with spikes around holidays and other events.\nThe company needs to improve its ability to support the additional usage while minimizing the increase in costs associated with the solution.\nWhich strategy meets these requirements?","answer":"A","isMC":true,"question_images":[],"discussion":[{"comments":[{"poster":"certainly","content":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html","comment_id":"319705","timestamp":"1632637500.0","upvote_count":"3"}],"poster":"certainly","content":"it is A for me. you can enabled cached on API gateway. no need for extra cache layer for additional cost. also changing to Edge-optimized endpoint would also help caching content base on Cookie https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Cookies.html","timestamp":"1632233160.0","upvote_count":"14","comment_id":"319703"},{"poster":"rahulrajtiwari","timestamp":"1667025240.0","content":"Selected Answer: A\nit's A","comment_id":"707028","upvote_count":"1"},{"poster":"tkanmani76","comment_id":"522532","timestamp":"1642031220.0","upvote_count":"1","content":"Was inclined to B but it does add additional cost for Elasticache. Using API gateway caching helps.\n\nYou can enable API caching in Amazon API Gateway to cache your endpoint's responses. With caching, you can reduce the number of calls made to your endpoint and also improve the latency of requests to your API.\n\nWhen you enable caching for a stage, API Gateway caches responses from your endpoint for a specified time-to-live (TTL) period, in seconds. API Gateway then responds to the request by looking up the endpoint response from the cache instead of making a request to your endpoint. The default TTL value for API caching is 300 seconds. The maximum TTL value is 3600 seconds. TTL=0 means caching is disabled."},{"timestamp":"1639028100.0","poster":"cldy","upvote_count":"1","comment_id":"497357","content":"A. Convert the API Gateway Regional endpoint to an edge-optimized endpoint. Enable caching in the production stage."},{"content":"A is for sure","poster":"AzureDP900","timestamp":"1638988680.0","comment_id":"497076","upvote_count":"1"},{"timestamp":"1636282980.0","poster":"andylogan","content":"It's A","upvote_count":"1","comment_id":"447567"},{"timestamp":"1636254660.0","comment_id":"437052","content":"AAA\n---","upvote_count":"2","poster":"tgv"},{"poster":"denccc","comment_id":"431588","timestamp":"1636097040.0","content":"It's A","upvote_count":"1"},{"poster":"WhyIronMan","comment_id":"414092","timestamp":"1636051500.0","upvote_count":"2","content":"I'll go with A"},{"upvote_count":"2","timestamp":"1636020840.0","content":"B is classic, but A works better to minimize cost and overhead. So A","poster":"vimgoru24","comment_id":"400506"},{"comment_id":"375070","poster":"cmthiru","timestamp":"1634670720.0","upvote_count":"1","content":"Will got for B.\nhttps://aws.amazon.com/blogs/database/latency-reduction-of-hybrid-architectures-with-amazon-elasticache/"},{"upvote_count":"2","poster":"Waiweng","comment_id":"359195","content":"it's A","timestamp":"1633842240.0"},{"upvote_count":"1","poster":"ppshein","timestamp":"1633232400.0","comment_id":"338650","content":"it should be A.\nB = costly"},{"poster":"anandbabu","timestamp":"1633189260.0","upvote_count":"3","comment_id":"334587","content":"its B as it was mentioned \"same Queries\""},{"poster":"Pupu86","content":"Default endpoint setting is usually edge-optimised to support cookie forwarding which in turn caches multiple identical reads in its cloudfront cache. Thus reducing the need to keep fetching identical data from the origin. While B is viable but implemented persistent memory based caching is definitely more costly. So Iâ€™m inclined to move towards A.","upvote_count":"2","timestamp":"1633063500.0","comment_id":"330004"},{"upvote_count":"3","content":"Correct option A. B is not an option for me because API gateway caching will eliminate lambda invocations and costs associated with it.","poster":"SD13","comment_id":"328697","timestamp":"1632902820.0","comments":[{"content":"Neal Davis exam also selected this option as the correct one.","upvote_count":"4","timestamp":"1632949980.0","comments":[{"timestamp":"1635401100.0","content":"yessir Neal Davis ftw","poster":"MrCarter","upvote_count":"3","comment_id":"396249"}],"poster":"SD13","comment_id":"328699"}]},{"content":"B: https://aws.amazon.com/getting-started/hands-on/real-time-leaderboard-amazon-aurora-serverless-elasticache/","poster":"kejam","timestamp":"1632715260.0","comment_id":"322823","upvote_count":"1"},{"poster":"awsnoob","comment_id":"315566","timestamp":"1632197580.0","upvote_count":"3","content":"Should be B"},{"poster":"sek12324","content":"B for me","timestamp":"1632078660.0","upvote_count":"3","comment_id":"315117"}],"answer_images":[],"unix_timestamp":1616183640,"exam_id":32,"answer_ET":"A","answer_description":"Reference:\nhttps://aws.amazon.com/getting-started/projects/build-serverless-web-app-lambda-apigateway-s3-dynamodb-cognito/module-4/","timestamp":"2021-03-19 20:54:00","question_id":702,"choices":{"A":"Convert the API Gateway Regional endpoint to an edge-optimized endpoint. Enable caching in the production stage.","D":"Enable throttling in the API Gateway production stage. Set the rate and burst values to limit the incoming calls.","C":"Modify the Aurora Serverless DB cluster configuration to increase the maximum amount of available memory.","B":"Implement an Amazon ElastiCache for Redis cache to store the results of the database calls. Modify the Lambda functions to use the cache."},"answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/47753-exam-aws-certified-solutions-architect-professional-topic-1/","topic":"1"},{"id":"IzqdhRCteX0HXInIP56y","answer_images":[],"answers_community":["D (86%)","14%"],"discussion":[{"poster":"kalyan_krishna742020","content":"D seems to be correct","timestamp":"1632314940.0","upvote_count":"33","comment_id":"308836"},{"content":"For those that don't know if answer is C or D. They say they want to support the increase demand... MultiAZ doesn't help with that, MuliAZ it's meant for HA, but read replicas are meant for increased demand... that's why ans is D","comments":[{"content":"Also C doesnt handle scaling on the containers. Best to go with Fargate","timestamp":"1677801840.0","poster":"[Removed]","comment_id":"827554","upvote_count":"1"}],"comment_id":"435704","upvote_count":"18","poster":"Liongeek","timestamp":"1635879420.0"},{"content":"Selected Answer: D\nAns D.\nSolution is here.\nhttps://aws.amazon.com/blogs/big-data/power-your-kafka-streams-application-with-amazon-msk-and-aws-fargate/\nFargate+Amazon MSK\n\nA. Running container on EC2 is more expensive compared to Fargate\nB. Same as above + higher Multi AZ costs.\nC. same as B.","upvote_count":"2","poster":"cen007","comment_id":"636475","timestamp":"1658729760.0"},{"content":"I would vote for C.\nRDS support auto-scaling -> less operating cost \nhttps://aws.amazon.com/about-aws/whats-new/2019/06/rds-storage-auto-scaling/#:~:text=RDS%20Storage%20Auto%20Scaling%20continuously,in%20the%20AWS%20Management%20Console.\nRDS-Multi-AZ- To support sync R/W in case of failures since more write load for DB with new orders","comment_id":"631957","timestamp":"1657930860.0","upvote_count":"3","poster":"Student1950"},{"comment_id":"630787","poster":"hahaaaaa","timestamp":"1657691160.0","content":"it's C\n- B : not denotes about container \n- D : Fargate is managed Service. no use EC2","comments":[{"timestamp":"1662315060.0","content":"AWS Fargate with Amazon EKS is available in all Amazon EKS Regions except AWS GovCloud (US-East) and AWS GovCloud (US-West).\nfrom https://docs.aws.amazon.com/eks/latest/userguide/fargate.html","poster":"ArreRaja","upvote_count":"1","comment_id":"659442"}],"upvote_count":"1"},{"timestamp":"1652713980.0","upvote_count":"1","comment_id":"602632","poster":"Niaj","content":"Selected Answer: D\nD is the right answer here"},{"comment_id":"564025","content":"Cannot be D, as Fargate is part of ECS and not EKS\nB - looks correct \n1, Cost saving with ASG\n2. Storage Auto Scaling for Volume\n3, Multi AZ for better support /availability","timestamp":"1646828700.0","upvote_count":"2","poster":"Sonujunko","comments":[{"comment_id":"587075","timestamp":"1650176580.0","poster":"wsyh","content":"Amazon EKS support run Kubernetes pods on AWS Fargate\nhttps://docs.aws.amazon.com/eks/latest/userguide/fargate.html","upvote_count":"1"},{"poster":"Hasitha99","comment_id":"582102","upvote_count":"2","content":"Fargate support for both ECS and EKS.\nRef : https://docs.aws.amazon.com/eks/latest/userguide/fargate.html","timestamp":"1649295000.0"}]},{"content":"D seems right to me as well since `deploying the DB instance in Multi-AZ mode and enable storage auto scaling` seems like a huge manual effort. DBs are not advised to have storage autoscaling.","timestamp":"1646415720.0","upvote_count":"1","poster":"omishaaaa","comment_id":"560927"},{"timestamp":"1646393580.0","upvote_count":"1","comment_id":"560727","poster":"Mechanic","content":"Selected Answer: C\nI guess it's C.\nNot B? because Kinesis and S3 will make an extra costs in addition to the burden of modifying the apps to use Kinesis.\nNot D? because EKS will charge more cost."},{"comment_id":"529810","upvote_count":"1","content":"C-- Latency based to direct to the reagion close to the user and failover for resilency\nE- DB repplication Instance back up","timestamp":"1642854000.0","comments":[{"content":"Sorry commented on a wrong question and unbale to delete","upvote_count":"1","timestamp":"1643630640.0","comment_id":"536942","poster":"RVivek"}],"poster":"RVivek"},{"timestamp":"1640023800.0","comment_id":"505609","upvote_count":"1","poster":"faisalshani001","content":"D seems right. Because I think auto-storage scaling is a feature of DynamoDB and/or Aurora."},{"content":"D seems right option, I am only thinking about read-write not mentioned in this option as per question there is big rise in order volume","poster":"AzureDP900","upvote_count":"1","timestamp":"1638989040.0","comment_id":"497079"},{"comment_id":"494373","poster":"cldy","content":"D. Deploy the application on Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate and enable auto scaling behind an Application Load Balancer. Create additional read replicas for the DB instance. Create an Amazon Managed Streaming for Apache Kafka cluster and configure the application services to use the cluster. Store static content in Amazon S3 behind an Amazon CloudFront distribution.","upvote_count":"1","timestamp":"1638711480.0"},{"upvote_count":"3","content":"Selected Answer: D\nD - better product release support, using PROD v1 and PROD v2 namespace in kubernetes to support product release lifecycle; better scalability with lower cost of maintaining own fleet of ec2","timestamp":"1637893140.0","comment_id":"487042","poster":"cakriwut"},{"poster":"backfringe","upvote_count":"1","timestamp":"1637570880.0","content":"I go with D","comment_id":"483971"},{"content":"It's D","comment_id":"448038","poster":"andylogan","upvote_count":"1","timestamp":"1636185420.0"},{"timestamp":"1636045080.0","poster":"tgv","comment_id":"436609","upvote_count":"1","content":"DDD\n---"},{"comment_id":"434298","upvote_count":"2","poster":"blackgamer","timestamp":"1635656400.0","content":"It is D for sure. Amazon MSK to orchestrate Kafka."},{"content":"Keyword \"reduce operational overhead\" = Fargate. Its D","poster":"Kopa","timestamp":"1635272280.0","upvote_count":"3","comment_id":"415234"},{"timestamp":"1634651460.0","poster":"WhyIronMan","upvote_count":"1","comment_id":"414096","content":"I'll go with D"},{"poster":"vimgoru24","timestamp":"1634595240.0","comment_id":"400508","content":"The all good enough and correct, but given the current tech stack and requirements - D is the most correct one (although Iâ€™d throw in a multi AZ setup for DR, but it is what it is)","upvote_count":"1"},{"content":"D is my answer.!!","poster":"hk436","upvote_count":"1","timestamp":"1634544360.0","comment_id":"385693"},{"content":"D for sure. A is not the best fit for containerized apps.","timestamp":"1634410500.0","upvote_count":"1","poster":"mustpassla","comment_id":"367655"},{"comment_id":"364431","poster":"vkbajoria","timestamp":"1634242800.0","upvote_count":"1","content":"It is D, => it is not highly available as far as DB goes but the question didn't ask for it"},{"upvote_count":"4","content":"it's D","poster":"Waiweng","comment_id":"359197","timestamp":"1634232720.0"},{"content":"Going with D","comment_id":"354239","poster":"KnightVictor","upvote_count":"1","timestamp":"1632752100.0"},{"upvote_count":"2","poster":"teo2157","comments":[{"content":"https://docs.aws.amazon.com/eks/latest/userguide/fargate-getting-started.html","poster":"tvs","comment_id":"355535","timestamp":"1632887100.0","upvote_count":"1"},{"content":"It does:\nhttps://docs.aws.amazon.com/eks/latest/userguide/fargate.html\n- AWS Fargate with Amazon EKS is available in all Amazon EKS Regions except China (Beijing), China (Ningxia), AWS GovCloud (US-East), and AWS GovCloud (US-West).","upvote_count":"4","timestamp":"1632932460.0","poster":"StanM","comment_id":"357684"}],"comment_id":"352010","timestamp":"1632642060.0","content":"D canÂ´t be as EKS doesnÂ´t support Fargate, ECS supports Fargate. Correct answer is B"},{"comment_id":"343277","upvote_count":"1","poster":"blackgamer","timestamp":"1632450960.0","content":"Yes, clearly it is D. Containerized."},{"upvote_count":"3","timestamp":"1632399900.0","content":"D for me","poster":"nitinz","comment_id":"313842"},{"timestamp":"1632352320.0","content":"D for me","poster":"wasabidev","upvote_count":"3","comment_id":"312338"}],"timestamp":"2021-03-12 13:49:00","isMC":true,"question_images":[],"question_text":"A company has application services that have been containerized and deployed on multiple Amazon EC2 instances with public IPs. An Apache Kafka cluster has been deployed to the EC2 instances. A PostgreSQL database has been migrated to Amazon RDS for PostgreSQL. The company expects a significant increase of orders on its platform when a new version of its flagship product is released.\nWhat changes to the current architecture will reduce operational overhead and support the product release?","topic":"1","unix_timestamp":1615553340,"answer":"D","answer_ET":"D","choices":{"B":"Create an EC2 Auto Scaling group behind an Application Load Balancer. Deploy the DB instance in Multi-AZ mode and enable storage auto scaling. Create Amazon Kinesis data streams and configure the application services to use the data streams. Store and serve static content directly from Amazon S3.","D":"Deploy the application on Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate and enable auto scaling behind an Application Load Balancer. Create additional read replicas for the DB instance. Create an Amazon Managed Streaming for Apache Kafka cluster and configure the application services to use the cluster. Store static content in Amazon S3 behind an Amazon CloudFront distribution.","C":"Deploy the application on a Kubernetes cluster created on the EC2 instances behind an Application Load Balancer. Deploy the DB instance in Multi-AZ mode and enable storage auto scaling. Create an Amazon Managed Streaming for Apache Kafka cluster and configure the application services to use the cluster. Store static content in Amazon S3 behind an Amazon CloudFront distribution.","A":"Create an EC2 Auto Scaling group behind an Application Load Balancer. Create additional read replicas for the DB instance. Create Amazon Kinesis data streams and configure the application services to use the data streams. Store and serve static content directly from Amazon S3."},"url":"https://www.examtopics.com/discussions/amazon/view/46693-exam-aws-certified-solutions-architect-professional-topic-1/","answer_description":"","exam_id":32,"question_id":703},{"id":"T2xf7QjgxeuwqtP40FjH","question_images":[],"answer_description":"","question_id":704,"unix_timestamp":1616045700,"choices":{"A":"Create a scheduled AWS Config rule to trigger an AWS Lambda function to call the GetServiceQuota API. If any service utilization is above 80%, publish a message to an Amazon Simple Notification Service (Amazon SNS) topic to alert the cloud team. Create an AWS CloudFormation template and deploy the necessary resources to each account.","D":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule that triggers an AWS Lambda function to refresh the AWS Trusted Advisor service limits checks and retrieve the most current utilization and service limit data. If the current utilization is above 80%, use Amazon Pinpoint to send an alert to the cloud team. Create an AWS CloudFormation template and deploy the necessary resources to each account.","B":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule that triggers an AWS Lambda function to refresh the AWS Trusted Advisor service limits checks and retrieve the most current utilization and service limit data. If the current utilization is above 80%, publish a message to an Amazon Simple Notification Service (Amazon SNS) topic to alert the cloud team. Create AWS CloudFormation StackSets that deploy the necessary resources to all Organizations accounts.","C":"Create an Amazon CloudWatch alarm that triggers an AWS Lambda function to call the Amazon CloudWatch GetInsightRuleReport API to retrieve the most current utilization and service limit data. If the current utilization is above 80%, publish an Amazon Simple Email Service (Amazon SES) notification to alert the cloud team. Create AWS CloudFormation StackSets that deploy the necessary resources to all Organizations accounts."},"answers_community":["B (100%)"],"timestamp":"2021-03-18 06:35:00","answer_images":[],"isMC":true,"answer_ET":"B","answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/47627-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"question_text":"A company recently completed a large-scale migration to AWS. Development teams that support various business units have their own accounts in AWS\nOrganizations. A central cloud team is responsible for controlling which services and resources can be accessed, and for creating operational strategies for all teams within the company. Some teams are approaching their account service quotas. The cloud team needs to create an automated and operationally efficient solution to proactively monitor service quotas. Monitoring should occur every 15 minutes and send alerts when a team exceeds 80% utilization.\nWhich solution will meet these requirements?","discussion":[{"comments":[{"content":"agree with B","poster":"certainly","upvote_count":"3","timestamp":"1633283220.0","comment_id":"319721"}],"content":"B is correct.\nA: Lambda should be invoked by cloudwatch on a schedule, not by Config.\nC & D : does not make much sense to me.","poster":"SD13","timestamp":"1633094460.0","comment_id":"316345","upvote_count":"14"},{"timestamp":"1634456640.0","upvote_count":"5","content":"Going with B. Verified this in Neal Davis sample questions","poster":"KnightVictor","comments":[{"upvote_count":"1","poster":"9xnine","content":"What's Neal Davis sample questions?","comments":[{"content":"Google Neal Davis and you will find out","poster":"Chibuzo1","timestamp":"1635637260.0","comment_id":"405269","upvote_count":"3"}],"comment_id":"393350","timestamp":"1634965200.0"}],"comment_id":"357516"},{"content":"Selected Answer: B\nIt must be B because of the EventBridge + Lambda+ TrustAdvisor + SNS \neven though Trust Advisor require a Business/Enterprise support plan but i guess this question is very old and as i remember few years ago Business/Enterprise support plan wasn't a requirement","poster":"dev112233xx","upvote_count":"1","timestamp":"1681821300.0","comment_id":"873612"},{"poster":"bobsmith2000","content":"Selected Answer: B\nNo-brainer","timestamp":"1653562860.0","upvote_count":"2","comment_id":"607600"},{"timestamp":"1642100580.0","content":"Selected Answer: B\ni agree it's b","poster":"pititcu667","comment_id":"523018","upvote_count":"1"},{"upvote_count":"1","poster":"cldy","content":"B is correct.","timestamp":"1640942760.0","comment_id":"513985"},{"poster":"Tan0k","comment_id":"497589","timestamp":"1639045020.0","content":"Selected Answer: B\nBBB\n\n...","upvote_count":"1"},{"timestamp":"1638989280.0","content":"I will go with B. Amzon Pinpoint is not relevant to this question\n\nAmazon Pinpoint is a flexible and scalable outbound and inbound marketing communications service. You can connect with customers over channels like email, SMS, push, voice or in-app messaging. Amazon Pinpoint is easy to set up, easy to use, and is flexible for all marketing communication scenarios. Segment your campaign audience for the right customer and personalize your messages with the right content. Delivery and campaign metrics in Amazon Pinpoint measure the success of your communications. Amazon Pinpoint can grow with you and scales globally to billions of messages per day across channels.","poster":"AzureDP900","comment_id":"497080","upvote_count":"1"},{"content":"It's B.\nService Limits ---> Trusted Advisor","poster":"andylogan","timestamp":"1636195020.0","comment_id":"448045","upvote_count":"1"},{"timestamp":"1636176060.0","poster":"Kopa","content":"B for sure, Trusted Advisor","comment_id":"438523","upvote_count":"2"},{"poster":"tgv","content":"BBB\n---","comment_id":"436611","timestamp":"1636023300.0","upvote_count":"1"},{"upvote_count":"3","comment_id":"434300","content":"B, trusted advisor to check service limits.","poster":"blackgamer","timestamp":"1635829620.0"},{"poster":"WhyIronMan","timestamp":"1635805260.0","content":"I'll go with B","comment_id":"414100","upvote_count":"3"},{"content":"B.\nService Limits ---> Trusted Advisor","upvote_count":"1","timestamp":"1634754480.0","comment_id":"375299","poster":"Amitv2706"},{"content":"it's B","upvote_count":"4","timestamp":"1634579100.0","comment_id":"359207","poster":"Waiweng"},{"content":"why not c?","comment_id":"354678","poster":"[Removed]","upvote_count":"2","timestamp":"1634370840.0"},{"upvote_count":"1","content":"The answer is A - service quotas were introduced in 2019 so B is not correct","comment_id":"332983","poster":"gsw","timestamp":"1634012520.0"},{"content":"B: https://docs.aws.amazon.com/solutions/latest/limit-monitor/architecture.html","poster":"kejam","upvote_count":"2","timestamp":"1633938120.0","comment_id":"322835"},{"poster":"champcloud","comment_id":"321512","upvote_count":"3","content":"Going with B","timestamp":"1633655520.0"},{"upvote_count":"2","poster":"awsnoob","timestamp":"1633018560.0","content":"The link posted in the solution points to B lol","comment_id":"315579"},{"comment_id":"315010","upvote_count":"1","comments":[{"upvote_count":"1","poster":"sek12324","comment_id":"322057","timestamp":"1633770060.0","content":"sorry B"}],"poster":"sek12324","timestamp":"1632887820.0","content":"C is my answer\nhttps://aws.amazon.com/blogs/mt/introducing-service-quotas-view-and-manage-your-quotas-for-aws-services-from-one-central-location/"},{"upvote_count":"1","content":"A is my answer","timestamp":"1632699240.0","poster":"nitinz","comment_id":"313844","comments":[{"timestamp":"1633554900.0","upvote_count":"1","poster":"nitinz","comment_id":"320553","content":"changing to B. B is more relevant."}]}],"topic":"1"},{"id":"r3tKSRBcDT6fGwIjASXe","isMC":true,"topic":"1","timestamp":"2021-03-15 16:25:00","url":"https://www.examtopics.com/discussions/amazon/view/47201-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["B (100%)"],"answer_description":"","unix_timestamp":1615821900,"exam_id":32,"answer_ET":"B","answer":"B","answer_images":[],"discussion":[{"content":"B should be correct. When EC2 instances reach third-party API through internet, their privates IP addresses will be masked by NAT Gateway public IP address.","poster":"heyheyhei","timestamp":"1632187680.0","comment_id":"311550","upvote_count":"22"},{"comment_id":"312298","poster":"wasabidev","content":"B. instances in private subnets use NAT, not ELB","timestamp":"1632236580.0","upvote_count":"9"},{"timestamp":"1681824600.0","content":"Selected Answer: B\nenableDnsSupport is enabled by default BUT enableDnsHostnames is NOT enabled by default (unless you use the default VPC which not mentioned in the question!)\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html","comment_id":"873664","poster":"dev112233xx","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: B\nB IMHO","poster":"Mimek","comment_id":"577278","timestamp":"1648534560.0"},{"upvote_count":"2","poster":"tkanmani76","content":"D also works.","comments":[{"upvote_count":"3","poster":"Sonujunko","content":"ALB is for connections coming in not going out. EC2 will respond to sessions coming through ALB for 80 and 443, for EC2 initiate anything from 3rd party source on internet it need NAT G/W","comment_id":"556948","timestamp":"1645904160.0"}],"comment_id":"532557","timestamp":"1643163360.0"},{"comment_id":"514005","upvote_count":"1","timestamp":"1640944080.0","content":"B s correct.","poster":"cldy"},{"comment_id":"497081","upvote_count":"1","timestamp":"1638989460.0","poster":"AzureDP900","content":"B seems right choice."},{"poster":"andylogan","timestamp":"1636087320.0","content":"It's B","upvote_count":"1","comment_id":"448048"},{"timestamp":"1635920580.0","upvote_count":"1","poster":"tgv","content":"BBB\n---","comment_id":"436614"},{"content":"B obviously.","comment_id":"434301","poster":"blackgamer","timestamp":"1635186360.0","upvote_count":"1"},{"upvote_count":"4","timestamp":"1635063960.0","poster":"WhyIronMan","comment_id":"414101","content":"I'll go with B"},{"poster":"zapper1234","content":"Why not C? C is the only answer that meets the solution criteria by only have \"one\" IP.","comments":[{"comment_id":"400511","upvote_count":"1","poster":"vimgoru24","content":"There is no such criteria. The criteria is to have calling IP in the predefined CIDR range. The B covers that.","timestamp":"1634009880.0"},{"upvote_count":"3","content":"You cannot assign an elastic IP address to an ALB, only NLBs.","comment_id":"459604","timestamp":"1636112640.0","poster":"Viper57"}],"comment_id":"393722","timestamp":"1633945500.0","upvote_count":"1"},{"poster":"hk436","timestamp":"1633440000.0","content":"B is my answer!!","comment_id":"385699","upvote_count":"1"},{"content":"it's B","timestamp":"1633369320.0","upvote_count":"4","comment_id":"359210","poster":"Waiweng"},{"content":"Agree with B. NAT.","timestamp":"1633247100.0","comment_id":"343287","poster":"blackgamer","upvote_count":"2"},{"poster":"SD13","upvote_count":"2","content":"B looks like a good option compared to others.","timestamp":"1633084560.0","comment_id":"328706"},{"poster":"kejam","upvote_count":"4","comment_id":"322838","timestamp":"1632254880.0","content":"B: https://aws.amazon.com/blogs/networking-and-content-delivery/introducing-bring-your-own-ip-byoip-for-amazon-vpc/"}],"question_images":[],"choices":{"A":"Associate a block of customer-owned public IP addresses to the VPC. Enable public IP addressing for public subnets in the VPC.","B":"Register a block of customer-owned public IP addresses in the AWS account. Create Elastic IP addresses from the address block and assign them to the NAT gateways in the VPC.","C":"Create Elastic IP addresses from the block of customer-owned IP addresses. Assign the static Elastic IP addresses to the ALB.","D":"Register a block of customer-owned public IP addresses in the AWS account. Set up AWS Global Accelerator to use Elastic IP addresses from the address block. Set the ALB as the accelerator endpoint."},"question_id":705,"question_text":"An AWS customer has a web application that runs on premises. The web application fetches data from a third-party API that is behind a firewall. The third party accepts only one public CIDR block in each client's allow list.\nThe customer wants to migrate their web application to the AWS Cloud. The application will be hosted on a set of Amazon EC2 instances behind an Application\nLoad Balancer (ALB) in a VPC. The ALB is located in public subnets. The EC2 instances are located in private subnets. NAT gateways provide internet access to the private subnets.\nHow should a solutions architect ensure that the web application can continue to call the third-party API after the migration?"}],"exam":{"id":32,"name":"AWS Certified Solutions Architect - Professional","isMCOnly":false,"provider":"Amazon","isBeta":false,"isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":1019},"currentPage":141},"__N_SSP":true}