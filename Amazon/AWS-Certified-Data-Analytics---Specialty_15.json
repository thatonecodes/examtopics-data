{"pageProps":{"questions":[{"id":"Bpzto6b9qrfuFy9WyrNi","isMC":true,"answers_community":["C (100%)"],"answer_images":[],"question_id":71,"choices":{"C":"Create an Athena workgroup for each division. Configure a data usage control for each workgroup and a time period of 1 day. Configure an action to send notifications to an Amazon Simple Notification Service (Amazon SNS) topic.","D":"Create an AWS account for each division. Configure an AWS Glue Data Catalog in each account. Set an Amazon CloudWatch alarm to monitor Athena usage. Use Amazon Simple Notification Service (Amazon SNS) to send notifications.","A":"Use a CREATE TABLE AS SELECT (CTAS) statement to create separate tables for each product division. Use AWS Budgets to track Athena usage. Configure a threshold for the budget. Use Amazon Simple Notification Service (Amazon SNS) to send notifications when thresholds are breached.","B":"Create an AWS account for each division. Provide cross-account access to an AWS Glue Data Catalog to all the accounts. Set an Amazon CloudWatch alarm to monitor Athena usage. Use Amazon Simple Notification Service (Amazon SNS) to send notifications."},"unix_timestamp":1650527880,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/73992-exam-aws-certified-data-analytics-specialty-topic-1-question/","answer":"C","answer_description":"","timestamp":"2022-04-21 09:58:00","discussion":[{"timestamp":"1650527880.0","content":"Selected Answer: C\nUse workgroups to separate users, teams, applications, or workloads, to set limits on amount of data each query or the entire workgroup can process, and to track costs.","comment_id":"589198","poster":"rb39","upvote_count":"14"},{"upvote_count":"2","poster":"juanife","comment_id":"937266","content":"it's C. No doubts at all. Workgroups offers data usage control and management of query quotas.","timestamp":"1687996800.0"},{"timestamp":"1682970900.0","poster":"pk349","upvote_count":"1","content":"C: I passed the test","comment_id":"886694"},{"comment_id":"693631","poster":"bp339","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/athena/latest/ug/manage-queries-control-costs-with-workgroups.html","timestamp":"1665638640.0","upvote_count":"1"},{"content":"Selected Answer: C\nSelected Answer: C","upvote_count":"1","timestamp":"1658986860.0","comment_id":"638497","poster":"rocky48"},{"comment_id":"604848","timestamp":"1653132120.0","content":"Selected Answer: C\nMy Answer is C","poster":"Bik000","upvote_count":"1"},{"upvote_count":"1","comment_id":"590745","content":"C is right","timestamp":"1650738240.0","poster":"CHRIS12722222"}],"exam_id":20,"topic":"1","question_images":[],"question_text":"An ecommerce company ingests a large set of clickstream data in JSON format and stores the data in Amazon S3. Business analysts from multiple product divisions need to use Amazon Athena to analyze the data. The company's analytics team must design a solution to monitor the daily data usage for Athena by each product division. The solution also must produce a warning when a division exceeds its quota.\nWhich solution will meet these requirements with the LEAST operational overhead?"},{"id":"TodD5ALGp8l4K0jJYc10","choices":{"D":"Modify the Amazon Redshift cluster from the console and enable encryption using the HSM option.","C":"Enable HSM encryption in Amazon Redshift using the command line.","B":"Modify the DB parameter group with the appropriate encryption settings and then restart the cluster.","A":"Create a new HSM-encrypted Amazon Redshift cluster and migrate the data to the new cluster."},"isMC":true,"answer_images":[],"unix_timestamp":1650527700,"exam_id":20,"answer_description":"","discussion":[{"upvote_count":"9","content":"Selected Answer: A\nTo migrate an unencrypted cluster to a cluster encrypted using a hardware security module (HSM), you create a new encrypted cluster and move your data to the new cluster. You can't migrate to an HSM-encrypted cluster by modifying the cluster.\n\nhttps://docs.aws.amazon.com/redshift/latest/mgmt/changing-cluster-encryption.html","timestamp":"1672171440.0","poster":"minhld","comment_id":"758995"},{"comment_id":"886695","upvote_count":"2","timestamp":"1682970900.0","content":"A: I passed the test","poster":"pk349"},{"upvote_count":"3","content":"Selected Answer: A\nYou can't enable hardware security module (HSM) encryption by modifying the cluster. Instead, create a new, HSM-encrypted cluster and migrate your data to the new cluster. \nhttps://docs.aws.amazon.com/redshift/latest/mgmt/changing-cluster-encryption.html","timestamp":"1671115560.0","comment_id":"746206","poster":"nadavw"},{"content":"Selected Answer: A\nAnswer-A","poster":"rocky48","upvote_count":"1","comment_id":"634944","timestamp":"1658455140.0"},{"poster":"jrheen","comment_id":"595318","content":"Answer-A","upvote_count":"1","timestamp":"1651356600.0"},{"poster":"astalavista1","content":"Selected Answer: A\nA - New Cluster needs to be created as Encryption only available during Cluster creation.","comment_id":"591106","upvote_count":"3","timestamp":"1650810000.0"},{"upvote_count":"2","comment_id":"589194","timestamp":"1650527700.0","poster":"rb39","content":"Selected Answer: A\nEncryption can only be enabled when creating the cluster"}],"answers_community":["A (100%)"],"question_images":[],"question_id":72,"timestamp":"2022-04-21 09:55:00","answer":"A","answer_ET":"A","topic":"1","question_text":"A banking company is currently using Amazon Redshift for sensitive data. An audit found that the current cluster is unencrypted. Compliance requires that a database with sensitive data must be encrypted using a hardware security module (HSM) with customer managed keys.\nWhich modifications are required in the cluster to ensure compliance?","url":"https://www.examtopics.com/discussions/amazon/view/73990-exam-aws-certified-data-analytics-specialty-topic-1-question/"},{"id":"DRlmAjC1c59ey0t4FZV4","exam_id":20,"question_id":73,"isMC":true,"discussion":[{"content":"B: I passed the test","upvote_count":"3","comment_id":"886696","timestamp":"1682970960.0","poster":"pk349"},{"timestamp":"1676437860.0","upvote_count":"1","poster":"Merrick","comment_id":"809122","content":"B over A - a simpler GRANT/REVOKE permissions model"},{"content":"Selected Answer: B\nB is right answer","comment_id":"634374","upvote_count":"4","timestamp":"1658381100.0","poster":"rocky48"},{"comment_id":"627897","poster":"dushmantha","content":"Selected Answer: A\nIsn't it meant by saying \"Data lake is many year old\" that it was not produced by Lake Formation (introduced on 2018). And trick us to select our choice by forgeting this fact?","timestamp":"1657110840.0","comments":[{"comment_id":"736460","content":"It doesn't matter. You can add the S3 bucket at a later time to Lake Formation.","timestamp":"1670291100.0","poster":"chdorrego","upvote_count":"3"}],"upvote_count":"1"},{"content":"Answer: B","upvote_count":"1","timestamp":"1651349940.0","comment_id":"595262","poster":"jrheen"},{"content":"Selected Answer: B\nYou can grant access to your data by using AWS Glue methods or by using AWS Lake Formation grants. The AWS Glue methods use AWS Identity and Access Management (IAM) policies to achieve fine-grained access control. Lake Formation uses a simpler GRANT/REVOKE permissions model similar to the GRANT/REVOKE commands in a relational database system.\n\nhttps://docs.aws.amazon.com/glue/latest/dg/access-control-overview.html","timestamp":"1651147380.0","upvote_count":"3","comment_id":"593791","poster":"CHRIS12722222"},{"upvote_count":"4","comment_id":"593776","poster":"Teraxs","timestamp":"1651145580.0","content":"Selected Answer: B\nTextbook use case for AWS Lake Formation"},{"content":"Selected Answer: A\npermission","upvote_count":"1","comment_id":"592637","poster":"[Removed]","timestamp":"1650999360.0"},{"timestamp":"1650993300.0","comment_id":"592593","upvote_count":"1","content":"Selected Answer: B\nB is right answer","poster":"AWSRanger"}],"answer_images":[],"topic":"1","choices":{"C":"Manage AWS Glue and S3 permissions by using bucket policies","B":"Use AWS Lake Formation permissions","D":"Use Amazon Cognito user pools","A":"Set AWS Identity and Access Management (IAM) permissions for AWS Glue"},"answers_community":["B (86%)","14%"],"answer_ET":"B","unix_timestamp":1650993300,"answer":"B","timestamp":"2022-04-26 19:15:00","question_text":"An advertising company has a data lake that is built on Amazon S3. The company uses AWS Glue Data Catalog to maintain the metadata. The data lake is several years old and its overall size has increased exponentially as additional data sources and metadata are stored in the data lake. The data lake administrator wants to implement a mechanism to simplify permissions management between Amazon S3 and the Data Catalog to keep them in sync.\nWhich solution will simplify permissions management with minimal development effort?","question_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/74619-exam-aws-certified-data-analytics-specialty-topic-1-question/"},{"id":"BErxLt1URsQW7vgs4N1O","question_id":74,"answer_images":[],"question_text":"A team of data scientists plans to analyze market trend data for their company's new investment strategy. The trend data comes from five different data sources in large volumes. The team wants to utilize Amazon Kinesis to support their use case. The team uses SQL-like queries to analyze trends and wants to send notifications based on certain significant patterns in the trends. Additionally, the data scientists want to save the data to Amazon S3 for archival and historical re- processing, and use AWS managed services wherever possible. The team wants to implement the lowest-cost solution.\nWhich solution meets these requirements?","exam_id":20,"topic":"1","question_images":[],"answers_community":["B (85%)","C (15%)"],"answer_description":"","discussion":[{"upvote_count":"50","timestamp":"1632355140.0","comment_id":"154106","content":"B any thoughts ?\nMultiple applications can consume from a single Kinesis Stream\nKinesis Analytics for sql like queries for analysis\nKinesis firhose can directly transfer the data into S3 from the same data stream","poster":"Priyanka_01"},{"upvote_count":"5","poster":"cloudlearnerhere","content":"Selected Answer: B\nCorrect answer is B as a single Kinesis Data Streams can be configured for data ingestion. The stream can be consumed by Kinesis Data Firehose to store the data in S3 for archival. The stream can also be consumed by kinesis Data Analytics for analysis and use Lambda and SNS for notifications.\n\nOption A is wrong as KCL solution is not ideal for executing SQL-like queries to analyze trends.\n\nOptions C & D are wrong as two Kinesis Data Streams is not needed.","comment_id":"711276","timestamp":"1667582700.0"},{"content":"Option B\nMultiple applications can consume from a single Kinesis Stream\nKinesis Analytics for sql like queries for analysis & the Output can be sent to lambda to send SNs Trigger\nhttps://docs.aws.amazon.com/kinesisanalytics/latest/dev/how-it-works-output-lambda.html\nKinesis firehose can directly transfer the data into S3 from the same data stream","timestamp":"1692947820.0","upvote_count":"1","poster":"nroopa","comment_id":"989762"},{"comment_id":"969292","content":"Selected Answer: B\nits a B","poster":"NikkyDicky","upvote_count":"1","timestamp":"1690914060.0"},{"poster":"pk349","comment_id":"886281","upvote_count":"1","timestamp":"1682947140.0","content":"B: I passed the test"},{"content":"Selected Answer: B\nI would also suggest B","comment_id":"810565","upvote_count":"1","timestamp":"1676544840.0","poster":"[Removed]"},{"upvote_count":"1","content":"Correct Answer-B","comment_id":"729817","timestamp":"1669684620.0","poster":"henom"},{"poster":"renfdo","content":"Selected Answer: C\nI think it's C. We need Two D Data Stream. One to consume RAW data and another one to send Agregated data after Kinesis Data Analytics.\nhttps://aws.amazon.com/blogs/big-data/building-a-real-time-notification-system-with-amazon-kinesis-data-streams-for-amazon-dynamodb-and-amazon-kinesis-data-analytics-for-apache-flink/","timestamp":"1669327260.0","upvote_count":"2","comment_id":"726233"},{"content":"Answer is B. Using Kinesis analytics, we can analyse the trends using sql like queries. Same data stream would be a source to Firehose to put the data in s3.","timestamp":"1666693020.0","poster":"thirukudil","upvote_count":"1","comment_id":"703768"},{"poster":"Arka_01","content":"Selected Answer: B\nKDA is best applied in this scenario. Also we do not need multiple Kinesis streams to ingest from different data sources. Any custom application will add additional development and testing overhead.","upvote_count":"1","timestamp":"1664080680.0","comment_id":"678420"},{"timestamp":"1658885820.0","poster":"rocky48","upvote_count":"1","content":"Selected Answer: B","comment_id":"637731"},{"upvote_count":"1","comment_id":"604837","timestamp":"1653131340.0","poster":"Bik000","content":"Selected Answer: B\nAnswer is B"},{"comment_id":"570261","upvote_count":"2","timestamp":"1647581640.0","poster":"jmensah60","content":"Selected Answer: B\nKinesis Analytics for sql like queries for analysis"},{"comment_id":"485401","timestamp":"1637698860.0","upvote_count":"3","poster":"aws2019","content":"The answer is B."},{"upvote_count":"2","poster":"SGES","timestamp":"1635982320.0","comment_id":"385096","content":"B is preferable because:\nKinesis firhose can directly transfer the data into S3 from the same data stream in addition to cost effectiveness specified"},{"upvote_count":"1","content":"KCL is self-service, so A and D are out. If you want multiple consumers for the same stream, just make sure you have enough shards to deal with the read-write throughput. A stream is different from a queue in that one can traverse back and forth in a stream, where in a queue one can only process one by one.","timestamp":"1635961020.0","comment_id":"383739","poster":"Shraddha"},{"comment_id":"383709","poster":"gunjan4392","content":"B seems okay","upvote_count":"1","timestamp":"1635884280.0"},{"timestamp":"1635800760.0","poster":"leliodesouza","upvote_count":"2","comment_id":"360916","content":"The answer is B."},{"timestamp":"1635664200.0","content":"B.\n\nA. Huge workload with KCL.\nC,D. One Kinesis Data Streams is enough.","comment_id":"285189","poster":"Exia","upvote_count":"1"},{"comment_id":"274259","timestamp":"1635525660.0","upvote_count":"1","content":"B is the right answer","poster":"lostsoul07"},{"poster":"mendelthegreat","comment_id":"255896","upvote_count":"1","content":"B. Easy one here","timestamp":"1634780280.0"},{"comment_id":"251052","upvote_count":"1","content":"B. Messages published to Kinesis streams can be picked up by multiple consumers. No need of 2 streams. No need of custom KCL to analyze as user wants to use AWS services. Kinesis data analytics can do the job","timestamp":"1634487360.0","poster":"saabji"},{"upvote_count":"1","content":"B is correct for me","comment_id":"216815","timestamp":"1634454840.0","poster":"BillyC"},{"comment_id":"204687","upvote_count":"1","poster":"sanjaym","content":"B without any doubt.","timestamp":"1633747260.0"},{"comment_id":"191369","poster":"syu31svc","upvote_count":"1","content":"Answer is B\nKinesis Data Analytics for analysis and Firehose to stream into S3\nHaving 2 streams is unnecessary","timestamp":"1633597140.0"},{"timestamp":"1632951720.0","upvote_count":"1","content":"Option B, keyword to look for are lowest cost and managed solutions","poster":"Karan_Sharma","comment_id":"177485"},{"timestamp":"1632767340.0","poster":"Paitan","comment_id":"175268","content":"B is perfect here. I did a hands on a similar scenario and can vouch for this solution (although I never received the SNS message on my configured mobile :-) )","upvote_count":"3"},{"upvote_count":"1","timestamp":"1632483480.0","comment_id":"174088","content":"will go with B","poster":"GauravM17"},{"comment_id":"160757","upvote_count":"1","timestamp":"1632432840.0","poster":"abhineet","content":"B is correct"},{"comment_id":"155597","upvote_count":"2","content":"Will go with B. lowest cost solution","timestamp":"1632372600.0","poster":"Prodip"}],"isMC":true,"timestamp":"2020-08-10 06:48:00","url":"https://www.examtopics.com/discussions/amazon/view/27845-exam-aws-certified-data-analytics-specialty-topic-1-question/","choices":{"B":"Publish data to one Kinesis data stream. Deploy Kinesis Data Analytic to the stream for analyzing trends, and configure an AWS Lambda function as an output to send notifications using Amazon SNS. Configure Kinesis Data Firehose on the Kinesis data stream to persist data to an S3 bucket.","C":"Publish data to two Kinesis data streams. Deploy Kinesis Data Analytics to the first stream for analyzing trends, and configure an AWS Lambda function as an output to send notifications using Amazon SNS. Configure Kinesis Data Firehose on the second Kinesis data stream to persist data to an S3 bucket.","D":"Publish data to two Kinesis data streams. Deploy a custom application using the Kinesis Client Library (KCL) to the first stream for analyzing trends, and send notifications using Amazon SNS. Configure Kinesis Data Firehose on the second Kinesis data stream to persist data to an S3 bucket.","A":"Publish data to one Kinesis data stream. Deploy a custom application using the Kinesis Client Library (KCL) for analyzing trends, and send notifications using Amazon SNS. Configure Kinesis Data Firehose on the Kinesis data stream to persist data to an S3 bucket."},"unix_timestamp":1597034880,"answer":"B","answer_ET":"B"},{"id":"FtYQZvo1ll0J0u9H7o7P","question_id":75,"answer_images":[],"discussion":[{"content":"B.\nAWS DMS is not for this purpose, so A dropped. C would be costly since it literally replicates all data. There’s no “resource policies” in AWS Glue, so D dropped.","comment_id":"159220","poster":"zanhsieh","comments":[{"poster":"Huy","upvote_count":"2","content":"I agree with you that D is wrong but my ideas is you shouldn't based on a property that is not available for the service. Instead, think in-depth about what is the answer actually suggest. https://docs.aws.amazon.com/glue/latest/dg/glue-resource-policies.html\nHere, the answer wants AWS Glue to use Data Catalog from different region which is not supported.","timestamp":"1636162140.0","comment_id":"388056"},{"comment_id":"605096","poster":"certificationJunkie","comments":[{"timestamp":"1653702540.0","poster":"certificationJunkie","content":"No, glue crawler is not restricted to a region and can catalogue data in other regions. And then Athena can use the catalogue and generate results. I have seen this happening in my project","upvote_count":"5","comment_id":"608223"}],"timestamp":"1653187740.0","upvote_count":"2","content":"glue crawler will simply generate the metadata on top of s3 files. But the Athena running in another region will still not have access to the first region files. Also, even glue crawler might not have permission to crawl in another region s3 files. Hence replication is the only option."},{"poster":"JoellaLi","content":"There is 'resource policies':\nhttps://docs.aws.amazon.com/glue/latest/dg/glue-policy-examples-resource-policies.html","comment_id":"697287","upvote_count":"3","timestamp":"1666001760.0"}],"timestamp":"1632295500.0","upvote_count":"30"},{"comment_id":"711283","poster":"cloudlearnerhere","upvote_count":"14","content":"Selected Answer: B\nB is correct as AWS Glue can crawl data in different AWS Regions. When you define an Amazon S3 data store to crawl, you can choose whether to crawl a path in your account or another account.\n\nThe output of the crawler is one or more metadata tables defined in the AWS Glue Data Catalog. A table is created for one or more files found in your data store. If all the Amazon S3 files in a folder have the same schema, the crawler creates one table. Also, if the Amaazon S3 object is partitioned, only one metadata table is created.\n\n\nA is wrong because you can't use AWS DMS with AWS Glue Data Catalog.\n\nC is incorrect because replicating the data in S3 means that your storage costs will also double.\n\n\nD is wrong because a resource-based policy is primarily used to provide IAM users and roles granular access to metadata definitions of databases, tables, connections, and user-defined functions, and not the actual S3 data.","timestamp":"1667583120.0"},{"comment_id":"1102972","timestamp":"1703193480.0","content":"A: DMS is not required to migrate data from one region to another. It can even be used to migrate data from an S3 bucket to another bucket in another account, but there are better and cheaper ways to do this (considering the volume of data, of course).\n\nB: It is the correct alternative. Glue crawlers can catalog data that is in different regions. It's simple to set up and not expensive.\n\nC: Cross-region works for data replication, but it will be duplicated unnecessarily.\n\nD: This type of permissions is best suited for LakeFormation and would not help catalog data that is in different regions.","poster":"GCPereira","upvote_count":"1"},{"content":"Option D\nhttps://aws.amazon.com/blogs/big-data/configure-cross-region-table-access-with-the-aws-glue-catalog-and-aws-lake-formation/","upvote_count":"1","timestamp":"1692950040.0","poster":"nroopa","comment_id":"989796"},{"comment_id":"969296","timestamp":"1690914360.0","upvote_count":"1","content":"Selected Answer: B\ngoing w B","poster":"NikkyDicky"},{"timestamp":"1683448740.0","comment_id":"891251","upvote_count":"1","poster":"Cloudbert","content":"Selected Answer: B\nB. Source: https://docs.aws.amazon.com/glue/latest/dg/crawler-data-stores.html. You can choose to crawl a path in your account or in another account. Crawlers use an AWS Identity and Access Management (IAM) role for permission to access your data stores. The role you pass to the crawler must have permission to access Amazon S3 paths and Amazon DynamoDB tables that are crawled. Another source: https://docs.aws.amazon.com/athena/latest/ug/querying-across-regions.html. Athena can query cross-region Athena supports the ability to query Amazon S3 data in an AWS Region that is different from the Region in which you are using Athena. Querying across Regions can be an option when moving the data is not practical or permissible, or if you want to query data across multiple regions. Even if Athena is not available in a particular Region, data from that Region can be queried from another Region in which Athena is available."},{"poster":"Debi_mishra","comment_id":"890976","timestamp":"1683401880.0","upvote_count":"2","content":"B is correct for context of this question but will be a bad implementation in real life. D can be good pattern but with help of Lakeformation."},{"comment_id":"886283","content":"B: I passed the test","timestamp":"1682947200.0","poster":"pk349","upvote_count":"2"},{"poster":"austinoy","timestamp":"1675952700.0","content":"the data is not encrypted so moving data is not \"practical or permissible\"?","upvote_count":"1","comment_id":"803309"},{"comment_id":"802304","content":"D should be...","timestamp":"1675877100.0","poster":"Ashoks","upvote_count":"1"},{"content":"A, B, D simply wouldn't work because of lacking connection to the data source. The only thing that I am not sure is about the 'lowest cost'. It can be option B if the wording implies that the connectivity exits \nhttps://aws.amazon.com/blogs/big-data/create-cross-account-and-cross-region-aws-glue-connections/","timestamp":"1675506480.0","comment_id":"797826","upvote_count":"1","poster":"mulder1989"},{"content":"D.\n\nSee: https://docs.aws.amazon.com/glue/latest/dg/cross-account-access.html","timestamp":"1674499140.0","upvote_count":"1","comment_id":"785721","poster":"Nicoben"},{"upvote_count":"2","poster":"Chelseajcole","comment_id":"767235","content":"That's why D is wrong? Each AWS account owns a single catalog in an AWS Region whose catalog ID is the same as the AWS account ID\n\nhttps://docs.aws.amazon.com/glue/latest/dg/glue-resource-policies.html","timestamp":"1672975320.0"},{"content":"Selected Answer: B\nBoth B and D will work. The answer is B because option D is a bit more expensive.","upvote_count":"1","poster":"Haimett","timestamp":"1666544100.0","comment_id":"702338"},{"comment_id":"691797","poster":"LukeTran3206","timestamp":"1665468120.0","content":"Selected Answer: D\nMust be D","upvote_count":"2"},{"comment_id":"690643","upvote_count":"1","content":"Selected Answer: B\nB is correct\nD is wrong because there is no resource policies but only trust policy.","timestamp":"1665366420.0","comments":[{"comment_id":"693132","content":"It has https://docs.aws.amazon.com/glue/latest/dg/glue-resource-policies.html","upvote_count":"2","timestamp":"1665582480.0","poster":"VishalSingh"}],"poster":"rav009"},{"comment_id":"678422","timestamp":"1664080800.0","upvote_count":"1","poster":"Arka_01","content":"Selected Answer: B\nThe lowest cost option is B. All other options are involved with greater cost, as data migration between regions costs more."},{"comment_id":"677520","timestamp":"1663977480.0","upvote_count":"1","comments":[{"poster":"JoellaLi","content":"why not B ?","comment_id":"697392","timestamp":"1666009860.0","upvote_count":"1"}],"content":"Selected Answer: D\ntextbook question, should be d","poster":"he11ow0rId"},{"comment_id":"667468","upvote_count":"2","content":"D is correct.\nhttps://docs.aws.amazon.com/athena/latest/ug/querying-across-regions.html","comments":[],"poster":"renfdo","timestamp":"1663017540.0"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/glue/latest/dg/glue-resource-policies.html","upvote_count":"1","poster":"ystotest","comment_id":"662609","timestamp":"1662561900.0"},{"content":"Selected Answer: B\nVerified the answer B, by crawling S3 (us-east-1) by a crawler (ap-southeast-2) and running a query from Athena (in ap-southeast-2) and returning records from S3 bucket in us-east-1. It does work.","comment_id":"660676","poster":"Abep","timestamp":"1662428400.0","upvote_count":"4"},{"upvote_count":"1","comment_id":"637097","timestamp":"1658805780.0","content":"Selected Answer: B\nSelected Answer: B","poster":"rocky48"},{"content":"Selected Answer: B\nAthena can't query cross region but crawler can","comment_id":"635632","poster":"girish123456","comments":[{"comment_id":"712263","content":"Dont think so,https://docs.aws.amazon.com/athena/latest/ug/querying-across-regions.html","timestamp":"1667734560.0","upvote_count":"1","poster":"abgz887"}],"upvote_count":"2","timestamp":"1658586600.0"},{"comment_id":"619746","upvote_count":"2","poster":"Ramshizzle","content":"Selected Answer: D\nMigrating/Replicating data is usually more costly then just querying the data directly. So not A/C. \nhttps://aws.amazon.com/blogs/big-data/query-cross-account-aws-glue-data-catalogs-using-amazon-athena/ \nIn this link I find: \"Cross-Region Data Catalog queries are not supported.\" So this rules out option B. \nLeaves option D. As is described here: https://aws.amazon.com/blogs/big-data/query-cross-account-aws-glue-data-catalogs-using-amazon-athena/","comments":[{"content":"Came just to confirm that D seem the right answer for the very same webpage. zanhseih reasoning was nice, but the drop is B not D, because of what you (Ramshizzle) said.","poster":"javibq92","upvote_count":"2","comments":[{"comments":[{"poster":"JoellaLi","comment_id":"697400","upvote_count":"1","timestamp":"1666010160.0","content":"Yes, from articel we know that for Athena, 'Cross-Region Data Catalog queries are not supported.' \nBut it does not mean that it is not supported for AWS Clue crawler. \nCan you help to explain it?"}],"comment_id":"639028","content":"@javibq92 You should read articles more careful when posting.\nFor answer D, the article you posted is about cross-account queries.\ncross-region queries are still not possible, see : https://aws.amazon.com/blogs/big-data/query-cross-account-aws-glue-data-catalogs-using-amazon-athena/#:~:text=Cross%2DRegion%20Data%20Catalog%20queries%20are%20not%20supported","poster":"Kastian","upvote_count":"1","timestamp":"1659075720.0"}],"comment_id":"620904","timestamp":"1655980140.0"}],"timestamp":"1655804940.0"},{"content":"Selected Answer: B\nGlue crawler can run in different regions ..","comment_id":"613539","poster":"CloudTimes","timestamp":"1654731360.0","upvote_count":"1"},{"timestamp":"1644200040.0","comment_id":"542107","upvote_count":"2","poster":"vkbajoria","content":"Option C is my answer. B is expensive in long run"},{"comment_id":"493848","timestamp":"1638638640.0","content":"i am confused with most of people saying Crawler need NAT gateway to get data from S3 in another region but why it need NAT gateway to communicate S3 since S3 is not inside VPC","poster":"arun004","upvote_count":"1","comments":[{"upvote_count":"1","poster":"JoellaLi","comment_id":"697295","timestamp":"1666002180.0","content":"https://docs.aws.amazon.com/glue/latest/dg/glue-policy-examples-resource-policies.html"}]},{"content":"B is the answer\n\nhttps://docs.aws.amazon.com/athena/latest/ug/other-notable-limitations.html","timestamp":"1637466900.0","upvote_count":"1","poster":"aws2019","comment_id":"483001"},{"poster":"iconara","upvote_count":"3","content":"Option B would mean paying to transfer the data between regions on each query, but replication like in C means paying only once. B couldend up being astronomically expensive and could only be less expensive than C if only a small part of the dataset was queried and rarely enough to not add up to the size of the whole.","timestamp":"1636229220.0","comment_id":"435502"},{"comment_id":"386253","poster":"Donell","timestamp":"1635929700.0","content":"Answer is B.","upvote_count":"2"},{"comment_id":"383742","timestamp":"1635887280.0","content":"This one is confusing. Source says Athena supports cross-region query, while official docs says it is not supported. The official docs were updated to reflect its support on cross-region query, so B should be the most cost-effective. C could work but is too costly.","upvote_count":"1","poster":"Shraddha"},{"content":"Answer is C correct one and it is low cost when compared to B. B involves setting up NAT gateway https://aws.amazon.com/blogs/big-data/create-cross-account-and-cross-region-aws-glue-connections/ which comes out costlier when compared to S3 cross region replication costs.\n1 TB data processed through NAT gateway per month comes around $80 including NAT charges. S3 charges for same 1 TB comes around $50 per month.","poster":"SuperSundra","comment_id":"335927","upvote_count":"3","timestamp":"1635700680.0"},{"upvote_count":"1","poster":"SuperSundra","content":"Question says \"low cost\". With B, setting up NAT Gateway and IGW is required. NAT has charges and also cross region data transfer charges. With C, S3 storage cost along with cross region data transfer charges. I believe if data volume is not high, then C would work out as low cost.","comment_id":"335922","timestamp":"1635237360.0"},{"content":"B is the answer i finalized after some research ... \nhttps://aws.amazon.com/blogs/big-data/create-cross-account-and-cross-region-aws-glue-connections/","poster":"SuperSundra","timestamp":"1634825460.0","upvote_count":"3","comment_id":"335055"},{"content":"B cannot be answer. AWS Crawler cant crawl the cross region. I have tried it. So C should be the answer here.","poster":"SuperSundra","upvote_count":"1","timestamp":"1634790420.0","comments":[{"comment_id":"589064","poster":"CHRIS12722222","timestamp":"1650512460.0","upvote_count":"2","content":"Not correct. Crawler can crawl s3 buckets in different region. I have done this myself."}],"comment_id":"335044"},{"timestamp":"1634606880.0","poster":"Aquavk","upvote_count":"1","content":"B works fine ..tried it practically","comment_id":"312919"},{"timestamp":"1634414580.0","comment_id":"280395","poster":"jay1ram2","upvote_count":"1","content":"I am inclined to C. Even though B works, since data is queried directly from us-east-1, there will be data transfer cost incurred every time you run the query, and the performance will also be lower because the data is transferred between east to west."},{"comment_id":"280076","poster":"Naresh_Dulam","content":"Answer is B. Refer this link for more details https://aws.amazon.com/blogs/big-data/create-cross-account-and-cross-region-aws-glue-connections/","timestamp":"1634378400.0","upvote_count":"1"},{"content":"B - \nAthena allows data to be queried from cross regions so once glue catalogs it - Athena should be able to run it. \n\nFrom the document - \nYou can query data in regions other than the region where you run Athena. Standard inter-region data transfer rates for Amazon S3 apply in addition to standard Athena charges.","poster":"Pruthvi","upvote_count":"2","timestamp":"1634227020.0","comment_id":"277544"},{"content":"B is the right answer","poster":"lostsoul07","upvote_count":"1","timestamp":"1634069520.0","comment_id":"274263"},{"poster":"codefreak","upvote_count":"1","comment_id":"269710","content":"To my knowledge, the glue crawler can catalog across different stores. For it to access across the region it must be configured in a VPC. I will stick with Option C","timestamp":"1634008080.0"},{"timestamp":"1633830000.0","poster":"BillyC","comment_id":"216809","content":"B is correct for me","upvote_count":"1"},{"upvote_count":"1","comments":[{"upvote_count":"3","poster":"jove","comment_id":"206000","content":"This page has been updated 2 days ago (10/23) .. Now it says : Athena supports queries across only the following Regions. Queries across other Regions may produce the error message InvalidToken: The provided token is malformed or otherwise invalid.","timestamp":"1633805400.0"},{"poster":"KingD","comment_id":"320423","timestamp":"1634655360.0","upvote_count":"2","content":"The documentation in the link above never states that cross-region queries are not supported. it rather clearly lists the regions across which cross-region queries are supported and on the other hand, AWS Glue handles that part of cataloged data so i dont see why we should be having problems with Athena. The right answer is B like it or not."}],"comment_id":"204752","timestamp":"1633750980.0","poster":"sanjaym","content":"Answer is C. Cannot be B\nCross-region queries – Cross-region queries are not supported. If you create an Athena table in one AWS Region and attempt to query data in an Amazon S3 bucket in another AWS Region, you may receive the error message InvalidToken: The provided token is malformed or otherwise invalid.\nhttps://docs.aws.amazon.com/athena/latest/ug/other-notable-limitations.html"},{"comment_id":"192115","timestamp":"1633344060.0","poster":"askblr","upvote_count":"1","content":"I see both B and C possible. Is 'C' dropped due to cost involved in replication?"},{"content":"Option B, Glue Crawler crawls the data from different region and create catalog in the same region as of Athena","timestamp":"1633246320.0","poster":"Karan_Sharma","upvote_count":"3","comment_id":"177499"},{"timestamp":"1633003920.0","comment_id":"176256","upvote_count":"4","content":"Athena does not support cross region queries. How is B possible?\nhttps://docs.aws.amazon.com/athena/latest/ug/other-notable-limitations.html","poster":"GauravM17","comments":[{"comment_id":"177322","comments":[{"comment_id":"186285","poster":"GeeBeeEl","content":"No I do not agree......","timestamp":"1633326420.0","upvote_count":"1"},{"comment_id":"332463","upvote_count":"1","poster":"raj0101","timestamp":"1634700600.0","content":"data will still be sitting in the other region - even if the catalog is updated."}],"timestamp":"1633035900.0","poster":"rnc21","content":"True as in doc: \"Cross-region queries – Cross-region queries are not supported. If you create an Athena table in one AWS Region and attempt to query data in an Amazon S3 bucket in another AWS Region, you may receive the error message InvalidToken: The provided token is malformed or otherwise invalid.\"\nhowever athena is querying using Glue data catalog in same region and that works. just try it. so answer is B","upvote_count":"5"},{"poster":"GeeBeeEl","timestamp":"1633312080.0","upvote_count":"1","content":"I agree with you Guarav, the answer is definitely not B. You dont have to go with the popular opinion, group think is not always right.......","comments":[{"poster":"Glendon","comment_id":"259996","timestamp":"1633930140.0","upvote_count":"3","content":"Then you'd have to justify why you do not agree... Simplify by expressing your disagreement does not contribute to a constructive discussion. \n\nAnswer to this question should be B as explained by rnc21. The cross-region aspect of being taken care of by AWS Glue, whereas the Athena operation is taking place in the same region."}],"comment_id":"186284"}]},{"upvote_count":"2","timestamp":"1632769260.0","comment_id":"175271","poster":"Paitan","content":"AWS Glue crawler can catalog datasets across Regions. So option B for the win."},{"timestamp":"1632535260.0","poster":"carol1522","comment_id":"160135","upvote_count":"2","content":"B is the simplest way"}],"answers_community":["B (82%)","D (18%)"],"answer_description":"","answer":"B","exam_id":20,"timestamp":"2020-08-16 14:25:00","url":"https://www.examtopics.com/discussions/amazon/view/28718-exam-aws-certified-data-analytics-specialty-topic-1-question/","isMC":true,"choices":{"B":"Run the AWS Glue crawler in us-west-2 to catalog datasets in all Regions. Once the data is crawled, run Athena queries in us-west-2.","A":"Use AWS DMS to migrate the AWS Glue Data Catalog from us-east-1 to us-west-2. Run Athena queries in us-west-2.","D":"Update AWS Glue resource policies to provide us-east-1 AWS Glue Data Catalog access to us-west-2. Once the catalog in us-west-2 has access to the catalog in us-east-1, run Athena queries in us-west-2.","C":"Enable cross-Region replication for the S3 buckets in us-east-1 to replicate data in us-west-2. Once the data is replicated in us-west-2, run the AWS Glue crawler there to update the AWS Glue Data Catalog in us-west-2 and run Athena queries."},"topic":"1","question_text":"A company currently uses Amazon Athena to query its global datasets. The regional data is stored in Amazon S3 in the us-east-1 and us-west-2 Regions. The data is not encrypted. To simplify the query process and manage it centrally, the company wants to use Athena in us-west-2 to query data from Amazon S3 in both\nRegions. The solution should be as low-cost as possible.\nWhat should the company do to achieve this goal?","question_images":[],"unix_timestamp":1597580700,"answer_ET":"B"}],"exam":{"isImplemented":true,"provider":"Amazon","name":"AWS Certified Data Analytics - Specialty","id":20,"lastUpdated":"11 Apr 2025","numberOfQuestions":164,"isBeta":false,"isMCOnly":true},"currentPage":15},"__N_SSP":true}