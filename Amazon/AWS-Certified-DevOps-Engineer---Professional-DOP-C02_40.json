{"pageProps":{"questions":[{"id":"oUckWriuVPc01sNMwu3s","choices":{"C":"Create an Amazon EventBridge rule that is associated with the default EventBridge event bus. Configure the rule to react to all object create events for the existing S3 bucket. Define a new S3 bucket as the target for the rule. Create an EventBridge input transformation to customize the event before passing the event to the rule target.","D":"Create an Amazon Kinesis Data Firehose delivery stream that is configured with an AWS Lambda transformer. Specify the existing S3 bucket as the destination. Change the Network Firewall logging destination from Amazon S3 to Kinesis Data Firehose.","A":"Create an AWS Lambda function to transform the data and to write a new object to the existing S3 bucket. Configure the Lambda function with an S3 trigger for the existing S3 bucket. Specify all object create events for the event type. Acknowledge the recursive invocation.","B":"Enable Amazon EventBridge notifications on the existing S3 bucket. Create a custom EventBridge event bus. Create an EventBridge rule that is associated with the custom event bus. Configure the rule to react to all object create events for the existing S3 bucket and to invoke an AWS Step Functions workflow. Configure a Step Functions task to transform the data and to write the data into a new S3 bucket."},"question_id":196,"question_images":[],"answer":"D","answers_community":["D (100%)"],"question_text":"A company sends its AWS Network Firewall flow logs to an Amazon S3 bucket. The company then analyzes the flow logs by using Amazon Athena.\n\nThe company needs to transform the flow logs and add additional data before the flow logs are delivered to the existing S3 bucket.\n\nWhich solution will meet these requirements?","topic":"1","exam_id":23,"timestamp":"2024-07-06 13:08:00","answer_ET":"D","isMC":true,"unix_timestamp":1720264080,"url":"https://www.examtopics.com/discussions/amazon/view/143412-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_images":[],"answer_description":"","discussion":[{"comment_id":"1258875","content":"Selected Answer: D\nAmazon Kinesis Data Firehose:\nKinesis Data Firehose is designed for real-time streaming data delivery and transformation. It can ingest data, process it with a Lambda function, and deliver the transformed data to destinations like Amazon S3, Redshift, or Elasticsearch.\nhttps://aws.amazon.com/firehose/faqs/\n\nAWS Lambda Transformer:\nBy configuring a Lambda function as a transformer within Kinesis Data Firehose, you can implement custom logic to transform the flow logs and add any additional data required before the logs are written to the existing S3 bucket.","upvote_count":"4","timestamp":"1722431160.0","comments":[{"upvote_count":"3","timestamp":"1722431220.0","comment_id":"1258877","poster":"jamesf","content":"keywords: transform, flow logs"}],"poster":"jamesf"},{"upvote_count":"3","poster":"d9iceguy","comment_id":"1253803","timestamp":"1721754660.0","content":"Selected Answer: D\nD for me"},{"comment_id":"1248060","content":"Selected Answer: D\nD for me","upvote_count":"4","timestamp":"1721015340.0","poster":"trungtd"},{"upvote_count":"3","content":"Dhttps://aws.amazon.com/firehose/faqs/","poster":"getadroit","comment_id":"1243586","timestamp":"1720305060.0"}]},{"id":"yp4fP86Ah1JUluIy0x3n","choices":{"D":"Update the image build pipeline stage to output an imagedefinitions.json file that references the new image tag.","F":"Write a script that runs integration tests against the service. Upload the script to an Amazon S3 bucket. Integrate the script in the S3 bucket with CodePipeline by using an S3 action stage.","A":"Add a deploy stage to the pipeline. Configure Amazon ECS as the action provider.","B":"Add a deploy stage to the pipeline. Configure AWS CodeDeploy as the action provider.","E":"Create an AWS Lambda function that runs connectivity checks and API calls against the service. Integrate the Lambda function with CodePipeline by using a Lambda action stage.","C":"Add an appspec.yml file to the CodeCommit repository."},"answer_images":[],"answers_community":["ADE (100%)"],"topic":"1","answer_description":"","unix_timestamp":1720263840,"timestamp":"2024-07-06 13:04:00","answer_ET":"ADE","exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/143411-exam-aws-certified-devops-engineer-professional-dop-c02/","answer":"ADE","question_images":[],"isMC":true,"question_text":"A DevOps engineer needs to implement integration tests into an existing AWS CodePipeline CI/CD workflow for an Amazon Elastic Container Service (Amazon ECS) service. The CI/CD workflow retrieves new application code from an AWS CodeCommit repository and builds a container image. The Cl/CD workflow then uploads the container image to Amazon Elastic Container Registry (Amazon ECR) with a new image tag version.\n\nThe integration tests must ensure that new versions of the service endpoint are reachable and that various API methods return successful response data. The DevOps engineer has already created an ECS cluster to test the service.\n\nWhich combination of steps will meet these requirements with the LEAST management overhead? (Choose three.)","discussion":[{"content":"Selected Answer: ADE\nADE\nhttps://docs.aws.amazon.com/codepipeline/latest/userguide/ecs-cd-pipeline.html","upvote_count":"7","poster":"xdkonorek2","comment_id":"1243336","timestamp":"1720263840.0"},{"timestamp":"1735269540.0","upvote_count":"2","poster":"youonebe","comment_id":"1332199","content":"Selected Answer: ADE\nADE for sure"},{"timestamp":"1722997500.0","comment_id":"1261907","content":"Selected Answer: ADE\nkeywords: LEAST management overhead\n\nA. Add a deploy stage to the pipeline. Configure Amazon ECS as the action provider.\n- Directly deploys the container image to ECS, ensuring the service is updated with the latest code without unnecessary complexity.\n\nD. Update the image build pipeline stage to output an image definitions.json file that references the new image tag.\n- Necessary for ECS to recognize and deploy the new image version, facilitating automated updates.\n\nE. Create an AWS Lambda function that runs connectivity checks and API calls against the service. Integrate the Lambda function with CodePipeline by using a Lambda action stage.\n- Provides a low-management solution for running integration tests, leveraging AWS Lambda's serverless capabilities.","upvote_count":"3","poster":"jamesf"}],"question_id":197},{"id":"2duCGT6opoWMqJ5zJKnc","unix_timestamp":1720263540,"discussion":[{"timestamp":"1720930740.0","poster":"raycomh","comment_id":"1247603","upvote_count":"5","content":"Selected Answer: BDE\nTo meet the requirements of the scenario, the company should take the following steps:\n\nCreate an Amazon FSx for NetApp ONTAP Multi-AZ file system (Option B): Amazon FSx for NetApp ONTAP supports both SMB (for Windows) and NFS (for Linux), and it provides sub-millisecond latencies. It also supports Multi-AZ configurations for high availability and durability.\nUpdate the user data for each application’s launch template to mount the file system (Option D): This ensures that every new instance launched by the Auto Scaling group will have the file system mounted.\nPerform an instance refresh on each Auto Scaling group (Option E): This will update the existing instances with the new launch template configuration, ensuring that they have the file system mounted."},{"upvote_count":"2","poster":"VerRi","comment_id":"1308392","timestamp":"1730989560.0","content":"Selected Answer: BDE\nD has updated UserData, new EC2 should be auto-mounted, why F?"},{"timestamp":"1724800020.0","content":"Selected Answer: BDF\nOption B: Create an Amazon FSx for NetApp ONTAP Multi-AZ file system. This provides high-performance storage with support for both SMB and NFS protocols.\n\nOption D: Update the user data for each application’s launch template to mount the file system. This ensures that the file system is automatically mounted when new instances are launched.\n\nOption F: Update the EC2 instances for each application to mount the file system when new instances are launched. This ensures that all instances can read and write data to the file system","upvote_count":"1","poster":"limelight04","comment_id":"1273704"},{"poster":"[Removed]","upvote_count":"2","timestamp":"1724171760.0","content":"Selected Answer: BDE\nBDE for me","comment_id":"1269599"},{"comments":[{"timestamp":"1722433380.0","comment_id":"1258909","upvote_count":"1","content":"Not A. Amazon EFS as supports only NFS, not SMB support for Windows.\n\nNot C. Amazon EBS volume not natively support SMB or NFS, and EBS is block storage devices that attach to individual EC2 instances and do not support being shared directly across multiple instances.","poster":"jamesf"},{"content":"Not Option F \"Update the EC2 instances for each application to mount the file system when new instances are launched.\"\n- because this is more about ensuring that future instances have the correct configuration, without immediately affecting running instances. It sets the stage for consistency moving forward but does not address existing instances.\n- and future instances also take care by Option D","comment_id":"1258914","poster":"jamesf","timestamp":"1722433620.0","upvote_count":"1"}],"poster":"jamesf","upvote_count":"3","comment_id":"1258907","timestamp":"1722433320.0","content":"Selected Answer: BDE\nafter review and check, BDE will be better\nOption E focuses on updating existing instances with the new configurations by replacing them with new instances based on the updated launch template. This is particularly useful when you want all instances, including those currently running, to immediately adhere to new configurations.\n\nB. Amazon FSx for NetApp ONTAP Multi-AZ file system.\n- SMB and NFS Support\n- Sub-Millisecond Latency\n- Multi-AZ Availability: ensures HA and fault tolerance, as the data is replicated across multiple Availability Zones, which aligns with the requirement for a durable storage solution.\n\nD. Update the user data for each application’s launch template to mount the file system.\n- Automated Mounting the FSx file system at startup\n- Protocol-Specific Commands: For Windows instances, mount the SMB share, while for Linux instances, mount the NFS share"},{"upvote_count":"1","content":"Selected Answer: BDF\nB. Amazon FSx for NetApp ONTAP Multi-AZ file system.\n- SMB and NFS Support\n- Sub-Millisecond Latency\n- Multi-AZ Availability: ensures HA and fault tolerance, as the data is replicated across multiple Availability Zones, which aligns with the requirement for a durable storage solution.\n\nD. Update the user data for each application’s launch template to mount the file system.\n- Automated Mounting the FSx file system at startup\n- Protocol-Specific Commands: For Windows instances, mount the SMB share, while for Linux instances, mount the NFS share\n\nF. Update the EC2 instances for each application to mount the file system when new instances are launched.\n- Configuration Consistency: ensures that every new instance launched as part of the Auto Scaling group auto mounts the FSx file system.\n- Ease of Management: By automating the mounting process, you reduce the administrative overhead and potential for errors, ensuring a consistent and reliable setup.","timestamp":"1722432420.0","poster":"jamesf","comments":[{"upvote_count":"1","comment_id":"1258900","comments":[{"upvote_count":"1","timestamp":"1722433440.0","comment_id":"1258910","poster":"jamesf","content":"Hi Moderator, please delete this comment, thank you."}],"timestamp":"1722432600.0","poster":"jamesf","content":"Not A. Amazon EFS as supports only NFS, not SMB support for Windows. \n\nNot C. Amazon EBS volume not natively support SMB or NFS, and EBS is block storage devices that attach to individual EC2 instances and do not support being shared directly across multiple instances. \n\nNot E, Perform an instance refresh on each Auto Scaling group.\n- Not Necessary for Mounting: An instance refresh primarily updates instances in the Auto Scaling group to use new configurations or launch templates. While useful in other scenarios, it doesn't directly relate to mounting the file system or affect the requirement for shared storage.\n- Redundant with Updated Launch Templates: If launch templates and user data scripts are updated correctly, new instances will automatically mount the file system, making a manual refresh unnecessary unless other updates are needed."}],"comment_id":"1258898"},{"content":"---> BDE","upvote_count":"2","poster":"tgv","comment_id":"1248326","timestamp":"1721046180.0"},{"comment_id":"1248069","timestamp":"1721016360.0","poster":"trungtd","upvote_count":"3","content":"Selected Answer: BDE\nBDE for me"},{"upvote_count":"2","timestamp":"1720753920.0","poster":"siheom","comment_id":"1246443","content":"Selected Answer: BDF\nVOTE BDF"},{"timestamp":"1720263540.0","comments":[{"poster":"pepedaruiz999","comment_id":"1246265","content":"why not BDF?","upvote_count":"1","timestamp":"1720721880.0"}],"poster":"xdkonorek2","content":"Selected Answer: BDE\nBDE\nNetApp ONTAP for SMB and NFS at the same time","comment_id":"1243335","upvote_count":"3"}],"question_text":"A company runs applications on Windows and Linux Amazon EC2 instances. The instances run across multiple Availability Zones in an AWS Region. The company uses Auto Scaling groups for each application.\n\nThe company needs a durable storage solution for the instances. The solution must use SMB for Windows and must use NFS for Linux. The solution must also have sub-millisecond latencies. All instances will read and write the data.\n\nWhich combination of steps will meet these requirements? (Choose three.)","answer_description":"","timestamp":"2024-07-06 12:59:00","choices":{"E":"Perform an instance refresh on each Auto Scaling group.","C":"Create a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume to use for shared storage.","F":"Update the EC2 instances for each application to mount the file system when new instances are launched.","A":"Create an Amazon Elastic File System (Amazon EFS) file system that has targets in multiple Availability Zones.","B":"Create an Amazon FSx for NetApp ONTAP Multi-AZ file system.","D":"Update the user data for each application’s launch template to mount the file system."},"question_images":[],"answer_images":[],"answer_ET":"BDE","answers_community":["BDE (82%)","BDF (18%)"],"topic":"1","answer":"BDE","url":"https://www.examtopics.com/discussions/amazon/view/143410-exam-aws-certified-devops-engineer-professional-dop-c02/","isMC":true,"exam_id":23,"question_id":198},{"id":"oh67tY5DQiTYTeKo8oWV","question_images":["https://img.examtopics.com/aws-certified-devops-engineer-professional-dop-c02/image26.png"],"unix_timestamp":1724246400,"answer_ET":"D","question_id":199,"discussion":[{"upvote_count":"3","timestamp":"1732278480.0","comment_id":"1316301","content":"Selected Answer: D\nA and B do not work. SCPs do not apply to the management account. \nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_best-practices_mgmt-acct.html\nBest practice is to limit access to the management account, and/or to delegate to Identity Centro to another member account. But since that's not an option given these answers, limiting the permission set is the next best thing.","poster":"Impromptu"},{"comment_id":"1312400","timestamp":"1731643920.0","upvote_count":"2","poster":"tinyshare","content":"Selected Answer: D\nD is correct. Identity Center uses permission sets."},{"timestamp":"1730991420.0","comment_id":"1308414","upvote_count":"1","poster":"VerRi","content":"Selected Answer: B\nD might work, but SCPs are used to limit permissions and permission sets are used to grant permissions."},{"upvote_count":"2","timestamp":"1724937600.0","comment_id":"1274503","content":"Selected Answer: B\nIt's B according to chatGPT","poster":"ApacheKafkaAWS"},{"content":"Selected Answer: D\nOption D \n \nIn IAM Identity Center, update the DevOps permission set. Ensure that the assigned policy has full access but explicitly denies permission for the sso:* action and the sso-directory:* action. In the Deny statement, add a StringEquals condition that compares the aws:SourceAccount global condition context key with the organization’s management account. Delete the SCP.\n\nThis approach ensures that the DevOps team retains necessary permissions while explicitly denying access to IAM Identity Center actions in the management account. Adding the StringEquals condition ensures that the policy is applied specifically to the management account, effectively preventing access.","poster":"limelight04","timestamp":"1724800800.0","comment_id":"1273707","upvote_count":"2"},{"content":"Selected Answer: D\nvote D","upvote_count":"2","comment_id":"1272407","timestamp":"1724647260.0","poster":"siheom"},{"content":"Selected Answer: A\nThe right answer is A","timestamp":"1724246400.0","upvote_count":"1","poster":"hzaki","comments":[{"upvote_count":"1","content":"Sorry, It's D","comment_id":"1276495","poster":"hzaki","timestamp":"1725259260.0"}],"comment_id":"1270141"}],"timestamp":"2024-08-21 15:20:00","isMC":true,"topic":"1","question_text":"A company uses an organization in AWS Organizations that a security team and a DevOps team manage. Both teams access the accounts by using AWS IAM Identity Center.\n\nA dedicated group has been created for each team. The DevOps team's group has been assigned a permission set named DevOps. The permission set has the AdministratorAccess managed IAM policy attached. The permission set has been applied to all accounts in the organization.\n\nThe security team wants to ensure that the DevOps team does not have access to IAM Identity Center in the organization's management account. The security team has attached the following SCP to the organization root:\n\n//IMG//\n\n\nAfter implementing the policy, the security team discovers that the DevOps team can still access IAM Identity Center.\n\nWhich solution will fix the problem?","answers_community":["D (69%)","B (23%)","8%"],"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/146254-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_description":"","exam_id":23,"answer_images":[],"choices":{"D":"In IAM Identity Center, update the DevOps permission set. Ensure that the assigned policy has full access but explicitly denies permission for the sso:* action and the sso-directory:* action. In the Deny statement, add a StringEquals condition that compares the aws:SourceAccount global condition context key with the organization's management account IDelete the SCP.","B":"In the organization's management account, update the SCP condition reference to the ARN of the DevOps team's group role to include the AWS account ID of the organization's management account.","C":"In IAM Identity Center, create a new permission set. Ensure that the assigned policy has full access but explicitly denies permission for the sso:* action and the sso-directory:* action. Update the assigned permission set for the DevOps team's group role in the organization's management account. Delete the SCP.","A":"In the organization's management account, create a new OU. Move the organization's management account to the new OU. Detach the SCP from the organization root. Attach the SCP to the new OU."}},{"id":"qhSaB38cX6UBAm6gU8mU","unix_timestamp":1724509140,"discussion":[{"timestamp":"1724801160.0","poster":"limelight04","comment_id":"1273710","content":"Selected Answer: B\nOption B: Create a Systems Manager State Manager association that links to the Systems Manager command document. Create a tag query that runs immediately.\n\nHere’s why:\n\nState Manager allows you to define and maintain consistent configuration of your instances. By creating an association that links to the command document, you can ensure that the desired configuration is applied as soon as the instances are launched.\nUsing a tag query ensures that the configuration is applied to the correct instances based on their tags, which are applied by the Auto Scaling group.","upvote_count":"2"},{"timestamp":"1724650980.0","upvote_count":"2","poster":"chinchin97","content":"Selected Answer: B\nState Manager ensures that all instances launched by the Auto Scaling group automatically receive the desired configuration which immediately applies when instances are launched.\n\nWhile the primary focus of Option D is on patch management (applying updates and patches) rather than configuring the overall state of the operating system. Using Run Command is very AD-hoc which means you need to time the launching of the EC2 instance with the command and might not provide the continuous assurance that the configuration is maintained.","comment_id":"1272452"},{"comment_id":"1271694","poster":"Kushab94","upvote_count":"2","timestamp":"1724509140.0","content":"Selected Answer: B\nB. Create a Systems Manager State Manager association that links to the Systems Manager command document. Create a tag query that runs immediately."}],"question_text":"An Amazon EC2 Auto Scaling group manages EC2 instances that were created from an AMI. The AMI has the AWS Systems Manager Agent installed. When an EC2 instance is launched into the Auto Scaling group, tags are applied to the EC2 instance.\n\nEC2 instances that are launched by the Auto Scaling group must have the correct operating system configuration.\n\nWhich solution will meet these requirements?","answer_description":"","timestamp":"2024-08-24 16:19:00","choices":{"D":"Create a Systems Manager Patch Manager patch baseline and a patch group that use the same tags that the Auto Scaling group applies. Register the patch group with the patch baseline. Define a Systems Manager command document to patch the instances Invoke the document by using Systems Manager Run Command.","B":"Create a Systems Manager State Manager association that links to the Systems Manager command document. Create a tag query that runs immediately.","A":"Create a Systems Manager Run Command document that configures the desired instance configuration. Set up Systems Manager Compliance to invoke the Run Command document when the EC2 instances are not in compliance with the most recent patches.","C":"Create a Systems Manager Run Command task that specifies the desired instance configuration. Create a maintenance window in Systems Manager Maintenance Windows that runs daily. Register the Run Command task against the maintenance window. Designate the targets."},"question_images":[],"answer_images":[],"answer_ET":"B","answers_community":["B (100%)"],"topic":"1","answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/146391-exam-aws-certified-devops-engineer-professional-dop-c02/","isMC":true,"exam_id":23,"question_id":200}],"exam":{"isBeta":false,"isImplemented":true,"isMCOnly":true,"name":"AWS Certified DevOps Engineer - Professional DOP-C02","id":23,"provider":"Amazon","numberOfQuestions":355,"lastUpdated":"11 Apr 2025"},"currentPage":40},"__N_SSP":true}