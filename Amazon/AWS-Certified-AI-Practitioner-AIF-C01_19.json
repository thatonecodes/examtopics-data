{"pageProps":{"questions":[{"id":"UOYJtXLLjafnHkpTHHVx","topic":"1","discussion":[{"content":"Selected Answer: B\nExplicação: Durante o treinamento de um modelo de fundação (FM), aumentar o número de épocas significa que o modelo passará mais vezes pelos dados de treinamento, \no que pode ajudar a melhorar a precisão, especialmente se ele ainda estiver aprendendo padrões importantes. Mais épocas,mais aprendizado, até certo ponto. Porém, é importante monitorar para evitar overfitting . A. Diminua o tamanho do lote: Isso pode afetar a estabilidade do treinamento, mas não garante aumento de precisão. C. Diminua as épocas: Isso reduz o tempo de aprendizado, o que pode diminuir a precisão. D. Aumente o parâmetro de temperatura: Isso afeta o comportamento do modelo na inferência, tornando as respostas mais criativas/aleatórias, mas não melhora a precisão no treinamento.","timestamp":"1744226460.0","upvote_count":"1","poster":"Rcosmos","comment_id":"1559358"},{"poster":"Jessiii","timestamp":"1739327340.0","upvote_count":"2","comment_id":"1355367","content":"Selected Answer: B\nB. Increase the epochs: In deep learning, training a model for more epochs means that the model will go through the dataset more times, which generally leads to better learning and improved accuracy. Increasing the number of epochs allows the model to learn patterns more effectively, helping it reach the desired accuracy level. However, there’s a trade-off, as increasing epochs too much could lead to overfitting."},{"timestamp":"1735671480.0","upvote_count":"1","comment_id":"1335012","content":"Selected Answer: B\nB: Increase the epochs.\n\nExplanation:\nIncreasing the epochs allows the model to go through the entire training dataset multiple times, improving its learning and optimizing its weights. This can help the model achieve a higher accuracy level, provided it does not lead to overfitting. For a foundation model (FM), increasing epochs is a common approach to refining accuracy to meet specific acceptance levels.","poster":"Moon"},{"timestamp":"1733790060.0","comment_id":"1324279","content":"Selected Answer: B\nB. Increase the epochs.\n\nIncreasing the number of epochs, or training cycles, can help improve the accuracy of a foundation model. By exposing the model to the training data multiple times, it can learn more intricate patterns and relationships, leading to better performance.","upvote_count":"2","poster":"eesa"},{"content":"Selected Answer: B\nB. Increase the epochs: Increasing the number of epochs allows the model to continue learning from the data, potentially improving its accuracy as it trains on more examples. However, there is a risk of overfitting if epochs are increased too much.","comment_id":"1309181","poster":"jove","timestamp":"1731180360.0","upvote_count":"3"}],"question_id":91,"unix_timestamp":1731180360,"timestamp":"2024-11-09 20:26:00","url":"https://www.examtopics.com/discussions/amazon/view/151042-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answer_ET":"B","question_text":"A company is training a foundation model (FM). The company wants to increase the accuracy of the model up to a specific acceptance level.\nWhich solution will meet these requirements?","answers_community":["B (100%)"],"exam_id":14,"answer":"B","answer_images":[],"isMC":true,"choices":{"C":"Decrease the epochs.","D":"Increase the temperature parameter.","B":"Increase the epochs.","A":"Decrease the batch size."},"question_images":[],"answer_description":""},{"id":"fLzxta8g5xLh9tS7N2eZ","isMC":true,"exam_id":14,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/151043-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","topic":"1","unix_timestamp":1731180540,"answer_images":[],"answer_ET":"B","timestamp":"2024-11-09 20:29:00","question_text":"A company is building a large language model (LLM) question answering chatbot. The company wants to decrease the number of actions call center employees need to take to respond to customer questions.\nWhich business objective should the company use to evaluate the effect of the LLM chatbot?","choices":{"C":"Corporate social responsibility","A":"Website engagement rate","D":"Regulatory compliance","B":"Average call duration"},"answer":"B","question_id":92,"discussion":[{"timestamp":"1744226640.0","content":"Selected Answer: B\nExplicação:\nSe o objetivo é reduzir o número de ações dos funcionários do call center, o impacto mais direto e mensurável será na duração média da chamada. Um chatbot LLM bem implementado pode:\n\nAjudar os atendentes com respostas rápidas e precisas.\n\nReduzir o tempo necessário para buscar informações.\n\nAumentar a eficiência no atendimento ao cliente.\n\nTudo isso contribui para chamadas mais curtas e eficazes, o que é um indicativo claro de ganho de produtividade.","comment_id":"1559359","upvote_count":"1","poster":"Rcosmos"},{"poster":"Jessiii","comment_id":"1355368","upvote_count":"1","timestamp":"1739327400.0","content":"Selected Answer: B\nB. Average call duration: This metric is a direct measure of how much time call center employees spend responding to customer questions. By implementing an LLM chatbot, the company aims to reduce the number of actions that call center employees need to take, which should lead to a decrease in average call duration. If the chatbot can effectively answer customer questions, employees can resolve issues more quickly or be less involved in the conversation, leading to shorter calls."},{"content":"Selected Answer: B\nB: Average call duration\n\nExplanation:\nAverage call duration is a key metric for evaluating the efficiency of a question-answering chatbot in a call center environment. By reducing the number of actions employees need to take, the chatbot can help streamline customer interactions, resulting in shorter call durations. Monitoring this metric helps the company assess whether the chatbot is achieving its goal of improving call center efficiency.","poster":"Moon","comment_id":"1335015","upvote_count":"1","timestamp":"1735671660.0"},{"comment_id":"1309182","timestamp":"1731180540.0","content":"Selected Answer: B\nObviously it is B","poster":"jove","upvote_count":"2"}],"answers_community":["B (100%)"],"question_images":[]},{"id":"U5pH9ZTsWbmhyl5qwjwK","timestamp":"2024-11-05 23:47:00","answer":"D","answer_images":[],"exam_id":14,"url":"https://www.examtopics.com/discussions/amazon/view/150822-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answers_community":["D (100%)"],"discussion":[{"upvote_count":"6","content":"Selected Answer: D\nAmazon SageMaker Clarify provides functionality to detect and identify potential bias in data both before and after training, helping teams uncover imbalances in datasets that might lead to biased model predictions. This is essential for ensuring fairness and compliance, especially in sensitive applications.\n\nWhy Not the Other Options?\nA. Integrates a Retrieval Augmented Generation (RAG) workflow: RAG workflows are used for combining retrieved documents with model outputs, typically in language models, but this is not a function of SageMaker Clarify.\nB. Monitors the quality of ML models in production: Monitoring model quality in production is handled by SageMaker Model Monitor, not SageMaker Clarify.\nC. Documents critical details about ML models: This functionality is part of Amazon SageMaker Model Cards, which documents model details for transparency and compliance.","comment_id":"1307602","poster":"jove","timestamp":"1730846820.0"},{"comment_id":"1559360","poster":"Rcosmos","upvote_count":"1","content":"Selected Answer: D\nExplicação:\nO Amazon SageMaker Clarify é uma ferramenta que auxilia na detecção de vieses e na explicabilidade de modelos de machine learning (ML). Ele oferece funcionalidades como:\n\nDetecção de vieses: Ajuda a identificar possíveis vieses nos dados durante a preparação e também nos modelos após o treinamento. \n\nExplicabilidade de modelos: Fornece insights sobre como os modelos de ML fazem previsões, aumentando a transparência","timestamp":"1744226820.0"},{"timestamp":"1739327520.0","poster":"Jessiii","comment_id":"1355370","upvote_count":"1","content":"Selected Answer: D\nIdentifies potential bias during data preparation: This is the core functionality of Amazon SageMaker Clarify. It helps data scientists and AI practitioners detect bias in training data, providing insights into how the data might introduce bi"},{"upvote_count":"2","comment_id":"1349065","poster":"85b5b55","content":"Selected Answer: D\nAmazon Sagemake Clarify helps to Identify bias, how much models makes prediction, datasets or models reflections and more.","timestamp":"1738242540.0"},{"timestamp":"1733790120.0","upvote_count":"2","comment_id":"1324280","poster":"eesa","content":"Selected Answer: D\nD. Identifies potential bias during data preparation   \n\nAmazon SageMaker Clarify is a tool designed to help understand, debug, and improve machine learning models. One of its key functionalities is to identify potential bias in datasets and models. It can analyze datasets for imbalances, fairness issues, and other biases that could impact the model's performance and fairness"}],"question_id":93,"isMC":true,"answer_description":"","choices":{"C":"Documents critical details about ML models","D":"Identifies potential bias during data preparation","A":"Integrates a Retrieval Augmented Generation (RAG) workflow","B":"Monitors the quality of ML models in production"},"unix_timestamp":1730846820,"question_text":"Which functionality does Amazon SageMaker Clarify provide?","question_images":[],"topic":"1","answer_ET":"D"},{"id":"DefZw4Mt0zqlfS61xDVX","answer_description":"","question_id":94,"answer_images":[],"isMC":true,"answer":"C","timestamp":"2024-11-09 20:32:00","choices":{"D":"Increase the model training time.","C":"Increase the volume of data that is used in training.","B":"Add hyperparameters to the model.","A":"Reduce the volume of data that is used in training."},"discussion":[{"upvote_count":"1","timestamp":"1739327520.0","content":"Selected Answer: C\nIncrease the volume of data that is used in training: If the model performs well on the training dataset but poorly on production data, it could be due to overfitting or the model not generalizing well. Increasing the volume of data can help the model generalize better to unseen data and improve its robustness, thus improving performance in production.","poster":"Jessiii","comment_id":"1355371"},{"poster":"scs50","content":"Selected Answer: B\nThe company should use hyperparameters for model tuning, which involves adjusting parameters such as regularization, learning rates, and dropout rates to enhance the model's ability to generalize well to new data\n\nExplanation: \nHyperparameter tuning is the most effective solution in this scenario because it allows the company to adjust the settings that control the learning process of the model. By fine-tuning hyperparameters, such as increasing regularization or early stopping or adjusting dropout rates, the model can avoid overfitting to the training data and better generalize to new, unseen data in production. This approach helps improve the model's performance across various data distributions.","timestamp":"1736127540.0","upvote_count":"1","comment_id":"1336926"},{"poster":"Moon","upvote_count":"3","content":"Selected Answer: C\nC: Increase the volume of data that is used in training.\n\nExplanation:\nThe issue described is likely caused by overfitting, where the model performs well on the training dataset but fails to generalize to unseen data. Increasing the volume of training data can help mitigate overfitting by providing the model with more diverse examples, improving its ability to generalize to new data in production.","timestamp":"1735672140.0","comment_id":"1335017"},{"timestamp":"1735519980.0","upvote_count":"1","content":"Selected Answer: C\nThe correct answer is C. Increasing the volume of data used in training can help improve the model's performance in production by providing it with more diverse examples to learn from.","comment_id":"1333824","poster":"may2021_r"},{"upvote_count":"3","content":"Selected Answer: C\nHow can you prevent overfitting?\n• Increase the training data size\n• Early stopping the training of the model\n• Data augmentation (to increase diversity in the dataset)\n• Adjust hyperparameters (but you can’t “add” them)","comment_id":"1326009","timestamp":"1734063420.0","poster":"MH1980"},{"comment_id":"1322424","timestamp":"1733414040.0","upvote_count":"1","content":"Selected Answer: C\nTo prevent overfitting, increase training data, use early stopping, apply data augmentation, and fine-tune hyperparameters without adding new ones.","poster":"Dandelion2025"},{"timestamp":"1731459360.0","upvote_count":"1","content":"Selected Answer: C\nReducing the training data make the model prone to overfitting, and will likely further degrade the model's performance.","poster":"taka5094","comment_id":"1311011"},{"comment_id":"1310994","poster":"Blair77","content":"Selected Answer: C\nMore diverse training data helps the model learn broader patterns and generalize better to unseen data in production. This reduces the risk of overfitting to the training set.\nReduced Overfitting: The significant performance drop in production suggests overfitting to the training data. Increasing the data volume can help the model learn more robust features that are truly predictive rather than memorizing specifics of a limited dataset.. For A - Reducing the training data volume would likely exacerbate the problem rather than solve it. The model's poor performance in production suggests it's not generalizing well, which is often a result of insufficient or non-representative training data.","upvote_count":"1","timestamp":"1731454800.0"},{"comment_id":"1310455","timestamp":"1731392160.0","comments":[{"comment_id":"1310457","poster":"fed6485","upvote_count":"1","timestamp":"1731392220.0","content":"i mean A. reduce the portion for training and increase the portion for testing.. \nif it was 80-10-10, than do 75 -15-15"}],"upvote_count":"1","content":"Selected Answer: A\nyes Overfitting.. but if the \"Volume Data\" is FIXED, meaning if they are going to reuse the same data.. this time the need to REDUCE it.. so \"A\"\n\nif they have MORE/EXTRA data to augment the one already available.. than C","poster":"fed6485"},{"poster":"fed6485","upvote_count":"1","timestamp":"1731392100.0","content":"yes Overfitting.. but if the \"Volume Data\" is FIXED, meaning if they are going to reuse the same data.. this time the need to REDUCE it.. so \"A\"\n\nif they have MORE/EXTRA data to augment the one already available.. than C","comment_id":"1310454"},{"timestamp":"1731180720.0","poster":"jove","content":"Selected Answer: C\nModel is overfitting. Needs more training data","comment_id":"1309184","upvote_count":"1"}],"url":"https://www.examtopics.com/discussions/amazon/view/151044-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","question_text":"A company is developing a new model to predict the prices of specific items. The model performed well on the training dataset. When the company deployed the model to production, the model's performance decreased significantly.\nWhat should the company do to mitigate this problem?","question_images":[],"unix_timestamp":1731180720,"exam_id":14,"topic":"1","answer_ET":"C","answers_community":["C (86%)","7%"]},{"id":"b5kF0dPb87K7l3jQOKxS","answer_description":"","question_id":95,"question_text":"An ecommerce company wants to build a solution to determine customer sentiments based on written customer reviews of products.\nWhich AWS services meet these requirements? (Choose two.)","answer_images":[],"answers_community":["BD (100%)"],"discussion":[{"poster":"Jessiii","timestamp":"1739327700.0","upvote_count":"2","comment_id":"1355375","content":"Selected Answer: BD\nB. Amazon Comprehend: Amazon Comprehend is a fully managed natural language processing (NLP) service that can analyze text and extract insights, including sentiment analysis. This makes it ideal for determining customer sentiment based on written reviews.\nD. Amazon Bedrock: Amazon Bedrock provides access to foundation models (FMs) for various tasks, including sentiment analysis, through generative AI. It can be used to analyze customer reviews and understand sentiment."},{"content":"Selected Answer: BD\nAmazon Comprehend (insight of the customer reviews) and Amazon Bedrock helps for sentiment analysis.","poster":"85b5b55","timestamp":"1738243140.0","comment_id":"1349070","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: BD\nB. Amazon Comprehend:\n\n Amazon Comprehend is a fully managed natural language processing (NLP) service that can analyze text and determine sentiment, entities, key phrases, and language. For customer sentiment analysis based on written reviews, Amazon Comprehend provides built-in sentiment analysis that can classify text as positive, negative, or neutral.\n\nD. Amazon Bedrock:\n\n Amazon Bedrock is a service that provides access to various foundation models (FMs), which can be used to build and deploy AI-driven applications. For advanced natural language processing tasks like sentiment analysis, foundation models can be fine-tuned and applied to specific use cases, such as understanding customer sentiment in reviews. This is a more customizable and advanced option compared to pre-built solutions like Amazon Comprehend.","comment_id":"1318566","timestamp":"1732702020.0","poster":"eesa"},{"comment_id":"1308251","content":"Selected Answer: BD\nAmazon Comprehend is a natural language processing (NLP) service that uses machine learning to uncover insights and relationships in text. It offers sentiment analysis capabilities out-of-the-box, which can directly determine the sentiment (positive, negative, neutral, or mixed) expressed in customer reviews.\n\nAmazon Bedrock is a fully managed service that makes foundation models accessible with simple API calls. It allows you to build generative AI applications for various use cases, including sentiment analysis. By providing customer reviews as input prompts, you can use Bedrock to generate sentiment labels or scores.","timestamp":"1730958960.0","poster":"taka5094","upvote_count":"2"},{"poster":"PHD_CHENG","comment_id":"1308230","content":"Why not B,E?","comments":[{"content":"I also thought about B and E.\nFor B it is easy, you can analyze text with comprehend\nFor E you using Rekognition you can check how customer reacts to your product while unboxing and so on\n\nWhen AWS Bedrock can also be the case, it simply can do the same but trained on specific data, that actually is the same, analyze text and produce output,","poster":"JustEugen","comment_id":"1349232","upvote_count":"1","timestamp":"1738270860.0"}],"upvote_count":"2","timestamp":"1730953560.0"}],"isMC":true,"exam_id":14,"timestamp":"2024-11-07 05:26:00","topic":"1","unix_timestamp":1730953560,"question_images":[],"answer":"BD","url":"https://www.examtopics.com/discussions/amazon/view/150924-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answer_ET":"BD","choices":{"A":"Amazon Lex","C":"Amazon Polly","E":"Amazon Rekognition","D":"Amazon Bedrock","B":"Amazon Comprehend"}}],"exam":{"isBeta":false,"provider":"Amazon","name":"AWS Certified AI Practitioner AIF-C01","lastUpdated":"11 Apr 2025","isImplemented":true,"isMCOnly":false,"numberOfQuestions":154,"id":14},"currentPage":19},"__N_SSP":true}