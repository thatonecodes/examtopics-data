{"pageProps":{"questions":[{"id":"rhe4yKZDVlx98qfY6Qqo","topic":"1","answer_ET":"C","question_text":"A company hosts its staging website using an Amazon EC2 instance backed with Amazon EBS storage. The company wants to recover quickly with minimal data losses in the event of network connectivity issues or power failures on the EC2 instance.\nWhich solution will meet these requirements?","unix_timestamp":1680954180,"choices":{"B":"Add the instance to an EC2 Auto Scaling group with a lifecycle hook to detach the EBS volume when the EC2 instance shuts down or terminates.","D":"Create an Amazon CloudWatch alarm for the StatusCheckFailed Instance metric and select the EC2 action to reboot the instance.","C":"Create an Amazon CloudWatch alarm for the StatusCheckFailed System metric and select the EC2 action to recover the instance.","A":"Add the instance to an EC2 Auto Scaling group with the minimum, maximum, and desired capacity set to 1."},"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/105584-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_description":"","answer_images":[],"discussion":[{"upvote_count":"11","timestamp":"1687251480.0","comment_id":"928291","poster":"madperro","content":"Selected Answer: C\nC is the right answer.\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html"},{"timestamp":"1687208580.0","comment_id":"927945","poster":"tartarus23","content":"Selected Answer: C\nExplanation:\n\nAmazon CloudWatch provides system-wide visibility into resource utilization, application performance, and operational health. If a system status check fails, this implies there's a problem with the underlying EC2 system that may require AWS involvement to repair. The \"Recover this instance\" action for the system status check automatically recovers the instance if it becomes impaired due to an underlying issue.","upvote_count":"10"},{"timestamp":"1721962800.0","upvote_count":"1","poster":"jamesf","content":"Selected Answer: C\nC\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html\n\nIn the event that AWS determines an instance is unavailable due to an underlying hardware issue, there are two mechanisms that you can configure for instance resiliency which can restore availability—simplified automatic recovery and Amazon CloudWatch action based recovery. This process is called instance recovery.\n\nThe following are examples of underlying hardware issues that might require instance recovery:\n- Loss of network connectivity\n- Loss of system power\n- Software issues on the physical host\n- Hardware issues on the physical host that impact network reachability","comment_id":"1255352"},{"upvote_count":"1","poster":"c3518fc","timestamp":"1712935980.0","content":"Selected Answer: C\nC. This is the correct solution. By creating a CloudWatch alarm for the StatusCheckFailed System metric and configuring the alarm to trigger the \"Recover this instance\" action, the EC2 instance will be automatically recovered in the event of a system failure or power outage. This ensures the instance can be quickly recovered with minimal data loss, as the EBS volume remains attached during the recovery process.\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html","comment_id":"1194404"},{"upvote_count":"1","poster":"4555894","timestamp":"1709905620.0","comment_id":"1168839","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html"},{"upvote_count":"1","content":"C is correct: recover is the right way\nA and B are irrelevant\nD: should not reboot in case of power failures","poster":"thanhnv142","comment_id":"1135652","timestamp":"1706607720.0"},{"upvote_count":"3","content":"Selected Answer: C\nMy Reason:\nStatusCheckFailed_System: This check monitors the AWS systems on which your instance runs1. For Example loss of network connectivity, loss of system power, software issues on the physical host, and hardware issues on the physical host that impact network reachability\n\nStatusCheckFailed_Instance: This check monitors the software and network configuration of your individual instance. These checks detect problems that require your involvement to repair. If an instance status check fails, it typically means that there’s an issue with the instance, such as a misconfigured network or a problem with the instance’s file system.","timestamp":"1700821380.0","poster":"yorkicurke","comment_id":"1079178"},{"upvote_count":"2","timestamp":"1686923220.0","poster":"bakamon","content":"Selected Answer: C\nCorrect Answer is C","comment_id":"925227"},{"poster":"qan1257","upvote_count":"4","content":"Selected Answer: C\nA is incorrect. \nSimplified automatic recovery is not initiated for instances in an Auto Scaling group. If your instance is part of an Auto Scaling group with health checks enabled, then the instance is replaced when it becomes impaired.\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html","comment_id":"908954","timestamp":"1685323380.0"},{"upvote_count":"1","comment_id":"896571","content":"Selected Answer: C\nC with recover action creates identical instance","timestamp":"1683972120.0","poster":"ele"},{"poster":"Zoe_zoe","timestamp":"1683154020.0","content":"C\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html\n\nThere are only 2 ways to recover EC2 instances. Since this instance has EBS volumes, only the CloudWatch action based recovery is applicable.","upvote_count":"3","comment_id":"889016"},{"timestamp":"1683078180.0","poster":"haazybanj","content":"Selected Answer: D\nOption D is the correct solution\nOption C is incorrect because modifying the AWS CloudFormation template requires manual intervention and cannot be automated. Additionally, creating an Amazon CloudWatch alarm to invoke the Lambda function after the failure event occurs doesn't provide an automated way to promote the replica instance.\n\nTherefore, Option D is the correct solution.","upvote_count":"1","comment_id":"888061"},{"upvote_count":"1","timestamp":"1681575900.0","comment_id":"871089","poster":"alce2020","content":"C is correct"},{"upvote_count":"1","timestamp":"1681502580.0","comments":[{"comments":[{"comments":[{"poster":"Ffida2214","upvote_count":"1","comment_id":"1094165","content":"If there is power outage than it is considered as instance failure and cloudwatch alarm can recover from system failure but can't recover from instance failure.\nhttps://repost.aws/knowledge-center/automatic-recovery-ec2-cloudwatch\n\nI believe option A is quickest recovery, and if Data needed to be backup then option B","timestamp":"1702360740.0"}],"upvote_count":"1","comment_id":"955479","content":"How would you launch a new instance if they is a power outage? So, C is correct as you will have to recover and hopefully quickly.","timestamp":"1689686880.0","poster":"ogwu2000"}],"timestamp":"1685511000.0","poster":"bcx","comment_id":"910840","upvote_count":"1","content":"You would lose the contents on the EBS volume."}],"poster":"jqso234","content":"Selected Answer: A\noption A is a better choice for this scenario because it ensures that there is always an EC2 instance running to serve the staging website, and the new instance will have the same configuration as the original instance, including the EBS volume, so there will be minimal data loss. Option C may result in some data loss since a new EBS volume will be created, and it may take longer to recover the instance since the EC2 action to recover the instance will need to be triggered by the Amazon CloudWatch alarm.","comment_id":"870446"},{"timestamp":"1680954180.0","comment_id":"864655","upvote_count":"3","content":"Selected Answer: C\nC for me","poster":"Dimidrol"}],"question_id":296,"timestamp":"2023-04-08 13:43:00","answer":"C","exam_id":23,"answers_community":["C (95%)","3%"],"question_images":[]},{"id":"AoQVGjcXahv1aGHqdpG0","exam_id":23,"unix_timestamp":1681575720,"url":"https://www.examtopics.com/discussions/amazon/view/106272-exam-aws-certified-devops-engineer-professional-dop-c02/","question_text":"A company wants to use AWS development tools to replace its current bash deployment scripts. The company currently deploys a LAMP application to a group of Amazon EC2 instances behind an Application Load Balancer (ALB). During the deployments, the company unit tests the committed application, stops and starts services, unregisters and re-registers instances with the load balancer, and updates file permissions. The company wants to maintain the same deployment functionality through the shift to using AWS services.\nWhich solution will meet these requirements?","choices":{"C":"Use AWS CodePipeline to move the application source code from the AWS CodeCommit repository to AWS CodeDeploy. Use CodeDeploy to test the application. Use CodeDeploy's appspec.yml file to restart services and update permissions without a custom script. Use AWS CodeBuild to unregister and re-register instances with the ALB.","B":"Use AWS CodePipeline to move the application from the AWS CodeCommit repository to AWS CodeDeploy. Use CodeDeploy's deployment group to test the application, unregister and re-register instances with the ALand restart services. Use the appspec.yml file to update file permissions without a custom script.","A":"Use AWS CodeBuild to test the application. Use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services, and deregister and register instances with the ALB. Use the appspec.yml file to update file permissions without a custom script.","D":"Use AWS CodePipeline to trigger AWS CodeBuild to test the application. Use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services. Unregister and re-register the instances in the AWS CodeDeploy deployment group with the ALB. Update the appspec.yml file to update file permissions without a custom script."},"answer_description":"","timestamp":"2023-04-15 18:22:00","answer_images":[],"isMC":true,"answer_ET":"D","answers_community":["D (88%)","8%"],"question_images":[],"discussion":[{"timestamp":"1687251840.0","upvote_count":"9","content":"Selected Answer: D\nD is better than A. You need to include CodePipeline to move execution from CodeBuild to CodeDeploy.","comment_id":"928297","poster":"madperro"},{"comment_id":"888072","upvote_count":"5","content":"Selected Answer: D\nOption D is also a viable solution. It suggests using AWS CodePipeline to trigger AWS CodeBuild to test the application, and then use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services, unregister and re-register instances with the ALB, and update file permissions. This approach also covers all the deployment functionality required by the company","poster":"haazybanj","timestamp":"1683078900.0"},{"timestamp":"1723693800.0","upvote_count":"1","content":"Selected Answer: B\nAnswer is B. company want to replace its bash deployment scripts so option D is not suitable","comments":[{"timestamp":"1734216180.0","content":"Options D is suitable since it includes \"Update the appspec.yml file to update file permissions without a custom script\".","poster":"SabeloM","upvote_count":"1","comment_id":"1326625"}],"poster":"rk0509","comment_id":"1266179"},{"timestamp":"1721963340.0","comment_id":"1255356","content":"Selected Answer: D\nShould be D\n\nCodePipeline - execute from CodeBuild to CodeDeploy\nCodeBuild - test the application\nCodeDeploy - deploy app, restart services, Unregister and re-register instance\n\nNot Option A: not using CodePipeline\nNot Option BC: using CodeCommit repo, not relevant with question.","poster":"jamesf","upvote_count":"3"},{"poster":"zijo","timestamp":"1711036080.0","content":"codebuild to test not codedeploy D is correct","upvote_count":"1","comment_id":"1179372"},{"content":"D: is correct: need codepipeline for a seamless deployment. Need codebuild to test and codedeploy to deploy the app on EC2\nA: no mention of codepipeline\nB and C both mention AWS CodeCommit repository, which is irrelevant","upvote_count":"4","timestamp":"1706608680.0","poster":"thanhnv142","comment_id":"1135659","comments":[{"poster":"thanhnv142","upvote_count":"1","content":"A: <deregister and register instances with the ALB>: we need to unregister, not deregister it","comment_id":"1148888","timestamp":"1707797100.0"},{"comment_id":"1139745","poster":"thanhnv142","timestamp":"1707017220.0","content":"B and C: The question doesnt mention the need for a source code repository. \nB: move the application from the AWS CodeCommit repository to AWS CodeDeploy -> Cannot do this, codecommit does not store apps, only code\nC: move the application source code from the AWS CodeCommit repository to AWS CodeDeploy -> cannot do this, code deploy does not store code","upvote_count":"1"}]},{"comment_id":"927949","content":"Selected Answer: A\nExplanation:\n\nAWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy, which is perfect for unit testing the application.\n\nAWS CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances. You can specify scripts to be run at set points during a deployment lifecycle, such as deregistering and registering instances with a load balancer, stopping and starting services, or changing file permissions, by defining them in the appspec.yml file.","timestamp":"1687209120.0","comments":[{"timestamp":"1712938200.0","content":"but it says to deregister","upvote_count":"1","poster":"c3518fc","comment_id":"1194419"}],"upvote_count":"2","poster":"tartarus23"},{"timestamp":"1686923460.0","upvote_count":"2","comment_id":"925232","poster":"bakamon","content":"Selected Answer: D\nD is the correct bubamon"},{"poster":"Akaza","content":"D for sure","timestamp":"1684912920.0","upvote_count":"1","comment_id":"905595"},{"poster":"alce2020","timestamp":"1681575720.0","upvote_count":"2","content":"Selected Answer: D\nD it is","comment_id":"871082"}],"answer":"D","question_id":297,"topic":"1"},{"id":"FI99ERSfd5MmrYIvacWA","isMC":true,"question_id":298,"discussion":[{"timestamp":"1706609040.0","content":"ABF are the right answers:\nA: enable hybrid on AWS system manager\nB: create IAM role for System manager to manage EC2 instances\nF: use maintenance windows to schedule patching on non-business hours\n\nC: incorrect because there is no IAM access keys for on-prem \nD: should not run patching every hour\nE: should not use Eventbridge because AWS has its own service to schedule patching","comment_id":"1135662","poster":"thanhnv142","upvote_count":"9"},{"timestamp":"1690270800.0","poster":"DavidPham","content":"Selected Answer: ABF\nABF is correct","upvote_count":"5","comment_id":"962463"},{"upvote_count":"1","timestamp":"1740291300.0","comment_id":"1360416","poster":"79f3aa3","content":"Selected Answer: ABF\nABF is correct. But option 'B' should also include on-prem servers. Both EC2 and on-prem servers will use the hybrid activation role."},{"timestamp":"1735053180.0","poster":"spring21","comment_id":"1331163","upvote_count":"2","content":"Selected Answer: ACF\nTo create IAM access keys for on-premises machines to interact with AWS Systems Manager, you need to: create a dedicated IAM user with the necessary permissions for Systems Manager actions, then generate access keys for that user and securely store them on the on-premises machine; ensure you follow best practices like rotating access keys regularly and using a secure method to distribute them."},{"upvote_count":"2","content":"Selected Answer: ABF\nABF are correct\n\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/activations.html\n\nTo configure non-EC2 machines for use with AWS Systems Manager in a hybrid and multicloud environment, you create a hybrid activation. Non-EC2 machine types supported as managed nodes include the following:\n- Servers on your own premises (on-premises servers)\n- AWS IoT Greengrass core devices\n- AWS IoT and non-AWS edge devices\n- Virtual machines (VMs), including VMs in other cloud environments","poster":"jamesf","comment_id":"1255357","timestamp":"1721963520.0"},{"comment_id":"1226012","content":"ABF is correct","upvote_count":"1","poster":"HarryLy","timestamp":"1717752660.0"},{"upvote_count":"2","content":"Selected Answer: AF\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-managedinstances.html\n\nAF are right but the letter B is wrong the role is for non EC2 instances","comment_id":"953594","poster":"Kiroo","timestamp":"1689536640.0"},{"upvote_count":"4","timestamp":"1687252020.0","comment_id":"928298","content":"Selected Answer: ABF\nABF is correct.\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/activations.html","poster":"madperro"},{"timestamp":"1683078960.0","upvote_count":"3","comment_id":"888074","content":"Selected Answer: ABF\nABF is right","poster":"haazybanj"},{"upvote_count":"3","poster":"alce2020","comment_id":"871076","timestamp":"1681575420.0","content":"Selected Answer: ABF\nABF it is"}],"url":"https://www.examtopics.com/discussions/amazon/view/106271-exam-aws-certified-devops-engineer-professional-dop-c02/","exam_id":23,"question_text":"A company runs an application with an Amazon EC2 and on-premises configuration. A DevOps engineer needs to standardize patching across both environments. Company policy dictates that patching only happens during non-business hours.\nWhich combination of actions will meet these requirements? (Choose three.)","choices":{"B":"Attach an IAM role to the EC2 instances, allowing them to be managed by AWS Systems Manager.","D":"Run an AWS Systems Manager Automation document to patch the systems every hour","A":"Add the physical machines into AWS Systems Manager using Systems Manager Hybrid Activations.","C":"Create IAM access keys for the on-premises machines to interact with AWS Systems Manager.","E":"Use Amazon EventBridge scheduled events to schedule a patch window.","F":"Use AWS Systems Manager Maintenance Windows to schedule a patch window."},"answer_ET":"ABF","answer_images":[],"question_images":[],"timestamp":"2023-04-15 18:17:00","answers_community":["ABF (82%)","Other"],"answer":"ABF","topic":"1","unix_timestamp":1681575420,"answer_description":""},{"id":"2jHLwNkUdWzENSCme6iR","exam_id":23,"timestamp":"2023-04-15 18:11:00","unix_timestamp":1681575060,"question_text":"A company has chosen AWS to host a new application. The company needs to implement a multi-account strategy. A DevOps engineer creates a new AWS account and an organization in AWS Organizations. The DevOps engineer also creates the OU structure for the organization and sets up a landing zone by using AWS Control Tower.\nThe DevOps engineer must implement a solution that automatically deploys resources for new accounts that users create through AWS Control Tower Account Factory. When a user creates a new account, the solution must apply AWS CloudFormation templates and SCPs that are customized for the OU or the account to automatically deploy all the resources that are attached to the account. All the OUs are enrolled in AWS Control Tower.\nWhich solution will meet these requirements in the MOST automated way?","topic":"1","choices":{"A":"Use AWS Service Catalog with AWS Control Tower. Create portfolios and products in AWS Service Catalog. Grant granular permissions to provision these resources. Deploy SCPs by using the AWS CLI and JSON documents.","D":"Deploy the Customizations for AWS Control Tower (CfCT) solution. Use an AWS CodeCommit repository as the source. In the repository, create a custom package that includes the CloudFormation templates and the SCP JSON documents.","B":"Deploy CloudFormation stack sets by using the required templates. Enable automatic deployment. Deploy stack instances to the required accounts. Deploy a CloudFormation stack set to the organization’s management account to deploy SCPs.","C":"Create an Amazon EventBridge rule to detect the CreateManagedAccount event. Configure AWS Service Catalog as the target to deploy resources to any new accounts. Deploy SCPs by using the AWS CLI and JSON documents."},"question_id":299,"discussion":[{"timestamp":"1687209240.0","upvote_count":"7","poster":"tartarus23","comment_id":"927951","content":"Selected Answer: D\nThe CfCT solution is designed for the exact purpose stated in the question. It extends the capabilities of AWS Control Tower by providing you with a way to automate resource provisioning and apply custom configurations across all AWS accounts created in the Control Tower environment. This enables the company to implement additional account customizations when new accounts are provisioned via the Control Tower Account Factory.\n\nThe CloudFormation templates and SCPs can be added to a CodeCommit repository and will be automatically deployed to new accounts when they are created. This provides a highly automated solution that does not require manual intervention to deploy resources and SCPs to new accounts."},{"timestamp":"1687252380.0","poster":"madperro","comment_id":"928304","upvote_count":"6","content":"Selected Answer: D\nCfCT is designed for the purpose stated in the question. So D.\nhttps://docs.aws.amazon.com/controltower/latest/userguide/cfct-overview.html"},{"comments":[{"poster":"jamesf","upvote_count":"1","comment_id":"1255360","content":"keywords: \"sets up a landing zone by using AWS Control Tower\"","timestamp":"1721963820.0"}],"comment_id":"1255358","timestamp":"1721963700.0","content":"Selected Answer: D\nD\nhttps://docs.aws.amazon.com/controltower/latest/userguide/cfct-overview.html\nCustomizations for AWS Control Tower (CfCT) helps you customize your AWS Control Tower landing zone and stay aligned with AWS best practices. Customizations are implemented with AWS CloudFormation templates and service control policies (SCPs).","poster":"jamesf","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\n\"This CfCT capability is integrated with AWS Control Tower lifecycle events, so that your resource deployments remain synchronized with your landing zone.\"\n\"For example, when a new account is created through account factory, all resources attached to the account are deployed automatically.\"\n\"You can deploy the custom templates and policies to individual accounts and organizational units (OUs) within your organization.\"\nhttps://docs.aws.amazon.com/controltower/latest/userguide/cfct-overview.html","timestamp":"1717462800.0","poster":"Gomer","comment_id":"1223847"},{"timestamp":"1706628720.0","content":"D is correct: Use CfCT is the correct solution: it utilizes both CloudFormation template and SCP\nA and C: no mention of AWS CloudFormation\nB: No mention of AWS control tower","poster":"thanhnv142","upvote_count":"3","comment_id":"1135923"},{"poster":"khchan123","upvote_count":"3","timestamp":"1705332900.0","comment_id":"1123490","content":"Selected Answer: D\nD. B is wrong because StackSets doesn't deploy stack instances to the organization management account."},{"content":"Selected Answer: B\nB. Deploying CloudFormation stack sets is the most automated way to deploy resources for new accounts created through AWS Control Tower Account Factory. With stack sets, you can define a CloudFormation template and deploy it to multiple accounts automatically. By enabling automatic deployment and deploying stack instances to the required accounts, you can ensure that the resources specified in the CloudFormation templates are automatically provisioned for each account. Additionally, by deploying a CloudFormation stack set to the organization's management account, you can deploy Service Control Policies (SCPs) across all accounts in the organization.","poster":"Bassel","timestamp":"1685711460.0","upvote_count":"2","comment_id":"912837"},{"content":"Customizations for AWS Control Tower combines AWS Control Tower and other highly-available, trusted AWS services to help customers more quickly set up a secure, multi-account AWS environment using AWS best practices. You can easily add customizations to your AWS Control Tower landing zone using an AWS CloudFormation template and service control policies (SCPs). You can deploy the custom template and policies to individual accounts and organizational units (OUs) within your organization. It also integrates with AWS Control Tower lifecycle events to ensure that resource deployments stay in sync with your landing zone. For example, when a new account is created using the AWS Control Tower account factory, Customizations for AWS Control Tower ensures that all resources attached to the account's OUs will be automatically deployed.","upvote_count":"2","timestamp":"1685359140.0","comment_id":"909323","poster":"youonebe"},{"upvote_count":"2","timestamp":"1682913540.0","content":"Selected Answer: D\nD is it","comment_id":"885843","poster":"haazybanj"},{"upvote_count":"2","comment_id":"871071","content":"Selected Answer: D\nD it is","poster":"alce2020","timestamp":"1681575060.0"}],"answers_community":["D (92%)","8%"],"answer_ET":"D","question_images":[],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/106270-exam-aws-certified-devops-engineer-professional-dop-c02/","answer":"D","answer_description":"","answer_images":[]},{"id":"xJtbpVqkrlQz3Yn6oewr","question_id":300,"answer_images":[],"discussion":[{"timestamp":"1685711700.0","comment_id":"912843","content":"Selected Answer: C\nC. Using Aurora with read replicas for the product catalog allows for a single product catalog across all regions. Aurora read replicas can be set up in different regions to provide low-latency access to the product catalog from each region. Additionally, by deploying additional local Aurora instances in each region for customer information and purchases, the company can comply with the requirement of keeping customer data and purchases in each region.","poster":"Bassel","upvote_count":"9"},{"timestamp":"1740698040.0","upvote_count":"1","comment_id":"1362770","content":"Selected Answer: C\nC. Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases. \nIt's very bad to use word \"local\" in answer about AWS","poster":"dark4igi"},{"content":"Selected Answer: C\nC\nkeywords: ''the LEAST amount of application changes\"","timestamp":"1721964000.0","comment_id":"1255362","poster":"jamesf","upvote_count":"2"},{"timestamp":"1708570800.0","comment_id":"1156051","upvote_count":"3","content":"Selected Answer: C\nHow should the company meet these requirements with the LEAST amount of application changes? Anything option with DynamoDB is out since the all the data is stored Aurora(relational database).","poster":"Sisanda_giiven"},{"content":"C is correct: data is kept in each region and one product catalog for all regions \nA: Redshift is for data analysis, not for the need in the question\nB: DynamoDB is primarily used for session data in a web app\nD: Amazon DynamoDB global tables for the customer information is against the policy","upvote_count":"3","timestamp":"1706630160.0","comment_id":"1135937","poster":"thanhnv142"},{"content":"C is correct","poster":"amrit1227","upvote_count":"1","timestamp":"1703462400.0","comment_id":"1104929"},{"poster":"madperro","timestamp":"1687252560.0","comment_id":"928307","upvote_count":"2","content":"Selected Answer: C\nC makes most sense and minimizes application changes."},{"timestamp":"1682913720.0","comment_id":"885847","poster":"haazybanj","upvote_count":"3","content":"Selected Answer: C\nThe best solution to meet the company's requirements with the LEAST amount of application changes is to use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases. This will allow for a single product catalog across all regions, while still keeping customer information and purchases in each region for compliance purposes. Amazon Redshift is a data warehousing solution and is not appropriate for this use case. Amazon DynamoDB global tables may be used, but they require application changes to support them. Using local Aurora instances in each region for customer information and purchases could also work, but this would require more configuration and management than using Aurora with read replicas. Therefore, option C is the best solution."},{"upvote_count":"3","content":"Selected Answer: C\nC is correct","timestamp":"1681574760.0","comment_id":"871064","poster":"alce2020"}],"unix_timestamp":1681574760,"answer_description":"","topic":"1","question_text":"An online retail company based in the United States plans to expand its operations to Europe and Asia in the next six months. Its product currently runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. All data is stored in an Amazon Aurora database instance.\nWhen the product is deployed in multiple regions, the company wants a single product catalog across all regions, but for compliance purposes, its customer information and purchases must be kept in each region.\nHow should the company meet these requirements with the LEAST amount of application changes?","choices":{"C":"Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases.","B":"Use Amazon DynamoDB global tables for the product catalog and regional tables for the customer information and purchases.","D":"Use Aurora for the product catalog and Amazon DynamoDB global tables for the customer information and purchases.","A":"Use Amazon Redshift for the product catalog and Amazon DynamoDB tables for the customer information and purchases."},"answer":"C","timestamp":"2023-04-15 18:06:00","answer_ET":"C","isMC":true,"question_images":[],"answers_community":["C (100%)"],"exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/106269-exam-aws-certified-devops-engineer-professional-dop-c02/"}],"exam":{"provider":"Amazon","numberOfQuestions":355,"isMCOnly":true,"id":23,"name":"AWS Certified DevOps Engineer - Professional DOP-C02","isBeta":false,"isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":60},"__N_SSP":true}