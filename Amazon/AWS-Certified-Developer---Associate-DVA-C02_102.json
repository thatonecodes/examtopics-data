{"pageProps":{"questions":[{"id":"WB4Eg12kNvqnIZVwPpAt","answer_images":[],"timestamp":"2023-03-27 01:24:00","exam_id":24,"answers_community":["A (100%)"],"choices":{"B":"Add a second cache behavior to the distribution with the same origin as the default cache behavior. Set the path pattern for the second cache behavior to *, and make viewer access restricted. Change the default cache behavior's path pattern to the path of the login page, and make viewer access unrestricted.","C":"Add a second origin as a failover origin to the default cache behavior. Point the failover origin to the S3 bucket. Set the path pattern for the primary origin to *, and make viewer access restricted. Set the path pattern for the failover origin to the path of the login page, and make viewer access unrestricted.","A":"Add a second cache behavior to the distribution with the same origin as the default cache behavior. Set the path pattern for the second cache behavior to the path of the login page, and make viewer access unrestricted. Keep the default cache behavior's settings unchanged.","D":"Add a bucket policy to the S3 bucket to allow read access. Set the resource on the policy to the Amazon Resource Name (ARN) of the login page object in the S3 bucket. Add a CloudFront function to the default cache behavior to redirect unauthorized requests to the login page's S3 URL."},"discussion":[{"upvote_count":"12","timestamp":"1695770640.0","poster":"Untamables","comment_id":"851562","content":"Selected Answer: A\nA\nIf you create additional cache behaviors, the default cache behavior is always the last to be processed.\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesCacheBehavior"},{"poster":"sumanshu","comment_id":"1331066","upvote_count":"2","timestamp":"1735032360.0","content":"Selected Answer: A\nA) Adding a second cache behavior allows you to define specific rules for the login page while keeping the default settings for private content unchanged.\n\nB) Eliminated - Changing the default cache behavior to allow unrestricted access to the login page affects other private content, potentially compromising security.\n\nD) Eliminated - Adding a bucket policy to allow public access to the login page directly contradicts the requirement to use CloudFront for secure content delivery."},{"comment_id":"1215179","timestamp":"1732222320.0","content":"Selected Answer: A\nA is the correct answer.","poster":"65703c1","upvote_count":"1"},{"timestamp":"1718804280.0","content":"Answer is A. --The original way the developer had designed this application was too restrictive and didn't allow someone to even authenticate to get a signed cookie. By caching the second behavior, it allows the person authenticating to retrieve a cookie to access their personal data.","comment_id":"1100762","poster":"ShinobiGrappler","upvote_count":"1"},{"timestamp":"1717363620.0","content":"D cloud front function acts as lamda function","poster":"LR2023","upvote_count":"1","comment_id":"1086467"},{"comment_id":"985148","poster":"ninomfr64","content":"Selected Answer: A\nB) you cannot override the path pattern of the default Cache behavior\nC) the origin failover is used when the primary origin is not available, this is not our case\nD) with this configuration I think users wil get 403 Forbidden error and then redirected to the login page's S3 URL\n\nA is a workable approach in my opinion","timestamp":"1708349220.0","upvote_count":"2"},{"poster":"Harddiver","upvote_count":"3","timestamp":"1702278960.0","content":"Should it be D? In case s3 bucket restricts permissions, those should be open for login.","comment_id":"920427"},{"content":"Selected Answer: A\nBy adding a second cache behavior with unrestricted viewer access to the login page's path pattern, unauthenticated users will be allowed to access the login page. At the same time, the default cache behavior's settings remain unchanged, and private content remains secure because it still requires signed cookies for access.","comment_id":"879841","timestamp":"1698202680.0","upvote_count":"3","poster":"MrTee"}],"answer_description":"","question_text":"A developer is testing a new file storage application that uses an Amazon CloudFront distribution to serve content from an Amazon S3 bucket. The distribution accesses the S3 bucket by using an origin access identity (OAI). The S3 bucket's permissions explicitly deny access to all other users.\nThe application prompts users to authenticate on a login page and then uses signed cookies to allow users to access their personal storage directories. The developer has configured the distribution to use its default cache behavior with restricted viewer access and has set the origin to point to the S3 bucket. However, when the developer tries to navigate to the login page, the developer receives a 403 Forbidden error.\nThe developer needs to implement a solution to allow unauthenticated access to the login page. The solution also must keep all private content secure.\nWhich solution will meet these requirements?","question_id":506,"url":"https://www.examtopics.com/discussions/amazon/view/104014-exam-aws-certified-developer-associate-dva-c02-topic-1/","topic":"1","answer_ET":"A","answer":"A","question_images":[],"isMC":true,"unix_timestamp":1679873040},{"id":"TonBoLYKM1vaz8zurRuG","exam_id":24,"discussion":[{"upvote_count":"17","poster":"gpt_test","timestamp":"1680565740.0","comment_id":"860469","content":"Selected Answer: C\nExplanation: Adding a test phase to the amplify.yml build settings allows the developer to define and execute end-to-end tests as part of the build and deployment process in AWS Amplify Hosting. This will help ensure that bugs are caught and fixed before the application reaches production, improving the overall quality of the application."},{"content":"Selected Answer: C\nC\nhttps://docs.aws.amazon.com/amplify/latest/userguide/running-tests.html","comment_id":"851565","comments":[{"comment_id":"967017","timestamp":"1690710840.0","poster":"jipark","content":"ton of thanks !!\ndocument commented 'End to End Test'","upvote_count":"2"}],"timestamp":"1679873520.0","poster":"Untamables","upvote_count":"10"},{"upvote_count":"1","comment_id":"1364040","poster":"Dadasar","timestamp":"1740933780.0","content":"Selected Answer: C\nA. Eliminado: Esse comando não existe na Amplify CLI. O Amplify não tem um comando direto para adicionar testes, então essa alternativa está errada.\nB. Eliminado: Testes unitários são importantes, mas eles não são testes de ponta a ponta (E2E). Além disso, amplify push serve para implantar mudanças na infraestrutura, não para rodar testes.\nD. Eliminado: O arquivo aws-exports.js contém configurações do Amplify para conectar o front-end aos serviços da AWS. Ele não é usado para definir fases de teste.\nPortanto, a melhor solução é a alternativa C, pois ela permite adicionar testes ao processo de build e evitar que bugs cheguem à produção."},{"poster":"Dadasar","content":"Selected Answer: C\nA. Eliminado: Esse comando não existe na Amplify CLI. O Amplify não tem um comando direto para adicionar testes, então essa alternativa está errada.\nB. Eliminado: Testes unitários são importantes, mas eles não são testes de ponta a ponta (E2E). Além disso, amplify push serve para implantar mudanças na infraestrutura, não para rodar testes.\nD. Eliminado: O arquivo aws-exports.js contém configurações do Amplify para conectar o front-end aos serviços da AWS. Ele não é usado para definir fases de teste.\nPortanto, a melhor solução é a alternativa C, pois ela permite adicionar testes ao processo de build e evitar que bugs cheguem à produção.","upvote_count":"1","timestamp":"1740933720.0","comment_id":"1364039"},{"comment_id":"1331068","poster":"sumanshu","content":"Selected Answer: C\nTo implement end-to-end (E2E) testing before deployment, you can add a test phase to the amplify.yml file. \n\nA) Eliminated - Amplify CLI does not have a command named amplify add test.","upvote_count":"2","timestamp":"1735032960.0"},{"comment_id":"1231694","content":"This appear at 17 Jun exam","timestamp":"1718595600.0","upvote_count":"1","poster":"tsangckl"},{"content":"Selected Answer: C\nC is the correct answer.","poster":"65703c1","comment_id":"1215180","upvote_count":"1","timestamp":"1716317640.0"},{"content":"Selected Answer: B\nB as per https://docs.aws.amazon.com/amplify/latest/userguide/running-tests.html\nYou can run end-to-end (E2E) tests in the test phase of your Amplify app to catch regressions before pushing code to production. The test phase can be configured in the build specification YAML. Currently, you can run only the Cypress testing framework during a build.\n\nbuild specification is provided in the amplify.yml file","comment_id":"985138","upvote_count":"1","poster":"ninomfr64","timestamp":"1692443460.0"},{"timestamp":"1689959640.0","upvote_count":"1","poster":"SachinR28","content":"Selected Answer: B\nI'LL GO WITH B","comment_id":"958741"},{"timestamp":"1684795080.0","upvote_count":"1","comment_id":"904402","content":"Selected Answer: B\nWe can use amplify.yml file to run any test commands at build time. Since the test must run while the program is being deployed (E2E) I'll go with B.","poster":"rlnd2000"}],"unix_timestamp":1679873520,"question_id":507,"answer":"C","timestamp":"2023-03-27 01:32:00","isMC":true,"answer_description":"","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/104015-exam-aws-certified-developer-associate-dva-c02-topic-1/","choices":{"A":"Run the amplify add test command in the Amplify CLI.","C":"Add a test phase to the amplify.yml build settings for the application.","B":"Create unit tests in the application. Deploy the unit tests by using the amplify push command in the Amplify CLI.","D":"Add a test phase to the aws-exports.js file for the application."},"question_text":"A developer is using AWS Amplify Hosting to build and deploy an application. The developer is receiving an increased number of bug reports from users. The developer wants to add end-to-end testing to the application to eliminate as many bugs as possible before the bugs reach production.\nWhich solution should the developer implement to meet these requirements?","topic":"1","answers_community":["C (91%)","9%"],"answer_ET":"C"},{"id":"C49NCaKGy9T9azfMzEqO","choices":{"B":"In the Resources section of the CloudFormation template, create resources for each EC2 instance type in the list.","C":"In the CloudFormation template, create a separate parameter for each EC2 instance type in the list.","A":"Create a separate CloudFormation template for each EC2 instance type in the list.","D":"In the CloudFormation template, create a parameter with the list of EC2 instance types as AllowedValues."},"answer_ET":"D","exam_id":24,"answers_community":["D (100%)"],"question_images":[],"answer":"D","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/102784-exam-aws-certified-developer-associate-dva-c02-topic-1/","discussion":[{"timestamp":"1683371760.0","comment_id":"890697","upvote_count":"25","content":"Selected Answer: D\nOption D is the correct answer. In the CloudFormation template, the developer should create a parameter with the list of approved EC2 instance types as AllowedValues. This way, users can select the instance type they want to use when launching the CloudFormation stack, but only from the approved list.\n\nOption A is not a scalable solution as it requires creating a separate CloudFormation template for each EC2 instance type, which can become cumbersome and difficult to manage as the number of approved instance types grows.\n\nOption B is not necessary as creating resources for each EC2 instance type in the list would not enforce the requirement to choose only from the approved list. It would also increase the complexity of the template and make it difficult to manage.\n\nOption C is not ideal as it would require creating a separate parameter for each EC2 instance type, which can become difficult to manage as the number of approved instance types grows. Also, it does not enforce the requirement to choose only from the approved list.","comments":[{"timestamp":"1691113740.0","content":"quite much clear explanation !!!","upvote_count":"2","poster":"jipark","comment_id":"971608"}],"poster":"Bibay"},{"comment_id":"890865","timestamp":"1683390180.0","content":"Got this question in exam.Correct answer is D.","poster":"geekdamsel","upvote_count":"8"},{"upvote_count":"1","poster":"sumanshu","timestamp":"1734706920.0","comment_id":"1329520","content":"Selected Answer: D\nA) Eliminated - higher maintenance overhead for maintaining multiple templates\nB) Eliminated - This would create multiple EC2 instances unnecessarily, which does not align with the requirement to choose a single instance type from a list."},{"poster":"trieudo","comment_id":"1324997","upvote_count":"1","timestamp":"1733916120.0","content":"Selected Answer: D\n==> Discard A: duplicate code, hard to maintain\n==> Discard B: all resource wil be created instead of it is neccessary or not\n==> Discard C: multiple param ==> when have larger param count, hard to maintain\n\nD for dynamic for fixed parameter ==> most generic"},{"comment_id":"1110346","content":"Selected Answer: D\nParameters:\n InstanceType:\n Type: String\n Default: 't2.micro'\n AllowedValues:\n - 't2.micro'\n - 't2.small'\n - 't2.medium'\n - 't3.micro'\n - 't3.small'\n - 't3.medium'\n Description: 'Select the EC2 instance type for deployment.'\n\nResources:\n MyEC2Instance:\n Type: 'AWS::EC2::Instance'\n Properties:\n ImageId: ami-12345678\n InstanceType: !Ref InstanceType","upvote_count":"4","timestamp":"1727238060.0","poster":"LocNV"},{"poster":"MessiVN","content":"Selected Answer: D\nD is correct","timestamp":"1718690940.0","comment_id":"1232273","upvote_count":"1"},{"content":"Selected Answer: D\nD is the correct answer.","timestamp":"1716296100.0","upvote_count":"1","poster":"65703c1","comment_id":"1214954"},{"content":"Selected Answer: D\nCorrecta D. Con este parámetro se permite dar permisos de elegir el tipo de instancia.","upvote_count":"1","poster":"vinfo","comment_id":"1190634","timestamp":"1712440620.0"},{"content":"Selected Answer: D\noption D is correct","comment_id":"1183979","timestamp":"1711533300.0","upvote_count":"1","poster":"apa_1"},{"timestamp":"1701568380.0","upvote_count":"1","content":"Selected Answer: D\nD is correct","comment_id":"1086520","poster":"payireb682"},{"timestamp":"1700092080.0","poster":"leonardoliveros","comment_id":"1072016","content":"Selected Answer: D\nD is the correct, because you are restricting the possible options to that parameter","upvote_count":"1"},{"content":"Why B instead of C? Each AWS SDK implements retry logic automatically. Most AWS SDKs now support exponential backoff and jitter as part of their retry behavior\nThen D to increase capacity https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TroubleshootingThrottling.html\nC&D","upvote_count":"1","timestamp":"1688070000.0","comment_id":"938549","comments":[{"upvote_count":"1","timestamp":"1688070120.0","comment_id":"938552","poster":"Pupina","content":"This answer is for question 7 not 6"}],"poster":"Pupina"},{"content":"Selected Answer: D\nD looks about right","timestamp":"1680814080.0","poster":"NanaDanso","upvote_count":"4","comment_id":"863314"},{"poster":"prabhay786","upvote_count":"4","timestamp":"1679308440.0","comment_id":"844757","content":"It should be D"},{"timestamp":"1678957140.0","poster":"aragon_saa","comment_id":"840719","upvote_count":"3","content":"D\nhttps://www.examtopics.com/discussions/amazon/view/88788-exam-aws-certified-developer-associate-topic-1-question-343/"}],"topic":"1","isMC":true,"answer_description":"","question_text":"A developer is creating an AWS CloudFormation template to deploy Amazon EC2 instances across multiple AWS accounts. The developer must choose the EC2 instances from a list of approved instance types.\nHow can the developer incorporate the list of approved instance types in the CloudFormation template?","timestamp":"2023-03-16 09:59:00","unix_timestamp":1678957140,"question_id":508},{"id":"t9Sp1kG6d30JWQ35kPc9","unix_timestamp":1679698740,"exam_id":24,"discussion":[{"upvote_count":"23","comment_id":"1215372","timestamp":"1716347340.0","content":"B. Create and inspect the Lambda dead-letter queue. Troubleshoot the failed functions. Reprocess the events.\n\nWhen Lambda functions are invoked asynchronously, there is a possibility that the function fails without logging errors if there is no proper error handling. Configuring a dead-letter queue (DLQ) allows you to capture and review events that were not processed successfully. By creating and inspecting the DLQ, you can identify and troubleshoot the issues with the failed Lambda invocations and reprocess those events if needed. This will help ensure that no orders are missed without leaving any errors in the Lambda logs.","poster":"[Removed]"},{"content":"Selected Answer: B\nExplanation: By configuring a dead-letter queue (DLQ) for the Lambda function, you can capture asynchronous invocation events that were not successfully processed. This allows you to troubleshoot the failed functions and reprocess the events, ensuring that orders are not missed. The DLQ will hold information about the failed events, allowing you to analyze and resolve the issue.","poster":"gpt_test","comment_id":"860466","upvote_count":"13","comments":[{"timestamp":"1683636000.0","comment_id":"893090","upvote_count":"5","content":"as you said \"... events that were not successfully processed.\" but there is not failure in Lambda log, so the lambda was not invoked by the POST API event. B is id not the answer.","poster":"rlnd2000","comments":[{"upvote_count":"2","comments":[{"upvote_count":"5","content":"Asynchronous invocation means that the caller of the lambda does not wait for a response. The type of invocation has no effect on the lambda having logs or not. I picked A, because the lambda not having logs suggests something’s gone wrong upstream of the lambda.","comment_id":"964212","timestamp":"1690412520.0","poster":"TeeTheMan"}],"content":"Its an asynchronous invocation events, that's y there is no log.\nBecause in asynchronous its not mandatory to get the result after invocation events.","timestamp":"1686808200.0","poster":"kavi00203","comment_id":"923751"}]}],"timestamp":"1680565560.0"},{"content":"Selected Answer: B\nA.Eliminada: O problema ocorre no backend (Lambda), e não no frontend. Como a invocação é assíncrona, o frontend não tem controle sobre falhas no processamento.\nC. Eliminada: Já foi mencionado que os logs do Lambda não mostram erros ou falhas, então apenas inspecionar os logs do CloudWatch não ajudaria a encontrar a causa do problema.\nD. Eliminada: O cache no API Gateway não afeta requisições POST, pois o cache só é aplicado para métodos GET. Então essa alternativa não faz sentido.","comment_id":"1364042","poster":"Dadasar","timestamp":"1740934200.0","upvote_count":"1"},{"timestamp":"1735033320.0","poster":"sumanshu","comment_id":"1331069","content":"Selected Answer: B\nsince there are no logs of errors or failures, the issue is likely due to dropped asynchronous events. Configuring a DLQ will capture these dropped events for further analysis and reprocessing.\n\nA) Eliminated - While inspecting frontend logs can help diagnose client-side issues, the problem here involves unprocessed events in Lambda.\n\nC) Eliminated - The question states that there are no errors or failures in the Lambda logs\n\nD) Eliminated - API Gateway caching is not related to this issue. Even with caching enabled, events would still invoke the Lambda function.","upvote_count":"3"},{"timestamp":"1731660720.0","poster":"mallikarjun_angadi","upvote_count":"1","comment_id":"1312495","content":"Answer : B\nLambda has a concurrency limit and in some cases, if the limit is reached, Lambda could throttle incoming requests without throwing an error, which means some invocations may be lost or delayed. Those will be moved to DLQ"},{"timestamp":"1730251560.0","upvote_count":"1","comment_id":"1304798","poster":"nbxyzd","content":"Selected Answer: B\nOption A is obviously wrong. Remember, it's an asynchronous labmda, so replaying the POST API returns no info instrumental to issue diagnosis. If you know how AWS usually designs a quiz, you'll know B is definitely the answer."},{"poster":"65703c1","content":"Selected Answer: B\nB is the correct answer.","comment_id":"1215183","timestamp":"1716317880.0","upvote_count":"1"},{"upvote_count":"1","poster":"KarBiswa","comment_id":"1098910","content":"Selected Answer: B\nhttps://aws.amazon.com/about-aws/whats-new/2016/12/aws-lambda-supports-dead-letter-queues/","timestamp":"1702817760.0"},{"comment_id":"1055004","content":"Selected Answer: B\nB. Crie e inspecione a fila de mensagens mortas do Lambda. Solucione os problemas das funções com falha. Reprocesse os eventos. Mais Votados","timestamp":"1698366780.0","upvote_count":"1","poster":"Jonalb"},{"timestamp":"1697105640.0","content":"Selected Answer: A\nThe Lambda application logs show no errors or failures. - So Lambda function was not invoked at all","upvote_count":"1","poster":"mr_swal","comments":[{"timestamp":"1697406480.0","comment_id":"1044452","content":"if the application code doesn't log errors and doesn't throw exceptions, no error or failure will be logged","upvote_count":"1","poster":"daicoso"}],"comment_id":"1041653"},{"poster":"nmc12","content":"Selected Answer: B\nThe Lambda Dead Letter Queue is a feature that helps in troubleshooting events that failed processing by a Lambda function. When an asynchronous invocation of a Lambda function fails, AWS Lambda can direct the failed event to an Amazon SNS topic or an Amazon SQS queue (the dead-letter queue), where the event is stored and can be analyzed or reprocessed.","upvote_count":"1","timestamp":"1696245540.0","comment_id":"1023039"},{"comment_id":"1013789","poster":"norris81","timestamp":"1695369480.0","upvote_count":"3","content":"Selected Answer: C\nI don't like B which has reprocess the errors, which will make a whole load of errors be process creating orders which could be months old"},{"poster":"misa27","comment_id":"1003851","timestamp":"1694336640.0","content":"Selected Answer: B\nB\nhttps://aws.amazon.com/what-is/dead-letter-queue/","upvote_count":"1"},{"poster":"ninomfr64","upvote_count":"1","timestamp":"1692445200.0","content":"Selected Answer: B\nA) asynchronous invocations doe not return result to the caller, thus I do not expect errors in frontend log\nC) the scenario question rules out the option to have error messages in the Lambda log\nD) I do not see how caching can have impact in this scenario\n\nB) having a dead-letter queue is a viable option to troubleshoot asynchronous lambda invocation error, another option would be using Destination","comment_id":"985156"},{"content":"Selected Answer: C\nOption C is the appropriate choice because it involves inspecting the Lambda logs in Amazon CloudWatch to identify any potential issues or errors that might be causing the orders not to be processed\n\nOption B is not the most appropriate choice because the dead-letter queue is generally used to capture events that cannot be processed by a Lambda function. In this scenario, it seems that the Lambda function is executing without apparent errors. Thus, the issue might not be related to dead-letter queue failures.","upvote_count":"2","comment_id":"964283","timestamp":"1690424820.0","poster":"backfringe"},{"timestamp":"1690354860.0","poster":"redfivedog","comments":[{"comment_id":"1267407","upvote_count":"2","poster":"Saurabh04","timestamp":"1723860360.0","content":"Caching is only for GET Requests not for POST Requests. Correct answer is B"},{"poster":"xdkonorek2","timestamp":"1703419980.0","content":"Absolutely agree, D is the answer","comment_id":"1104572","upvote_count":"1"}],"upvote_count":"3","comment_id":"963472","content":"Selected Answer: D\nI think D should be the correct answer to this question. The logs have no indications of errors or failed events, so if some transactions are not being processed, that probably means that the lambda function wasn't invoked for those calls. One reason could be that caching is enabled in API gateway for the POST request, so the lambda function isn't triggered for any cache hits.\n\n- A is not correct as the frontend would be getting 202s for all asynchronous post requests.\n- B is not correct because lambda logs have no errors => no lambda execution errors => DLQ won't get any requests of interest if we enable it. A comment below mentioned that asynchronous lambda invocations don't generate logs, but that is not true.\n- C is obviously incorrect. The premise explicitly mentions that there aren't any errors in the logs."},{"poster":"gomurali","upvote_count":"1","comment_id":"935108","content":"https://aws.amazon.com/about-aws/whats-new/2016/12/aws-lambda-supports-dead-letter-queues/","timestamp":"1687851300.0"},{"poster":"csG13","upvote_count":"3","content":"Selected Answer: B\nIt's B. Apparently C & D are wrong. \n\nAlso it's not A because the call is async. Meaning that the response code from the lambda service is 202. Since generally frontend can make POST requests, the problem should be visible somewhere in the backed. Dead-letter queues are for debugging and further analysis. Hence should be B.","timestamp":"1685965740.0","comment_id":"915403","comments":[{"content":"How can you tell from this context that the POST API call was successful?","poster":"rn5357","timestamp":"1694669160.0","comment_id":"1007220","upvote_count":"1"}]},{"timestamp":"1683903840.0","comment_id":"896012","poster":"Nagendhar","upvote_count":"3","content":"Ans: B\n\nB. Create and inspect the Lambda dead-letter queue. Troubleshoot the failed functions. Reprocess the events.\n\nSince the Lambda application logs show no errors or failures, it is possible that the asynchronous invocation is not being processed successfully. In this case, the best solution would be to inspect the Lambda dead-letter queue, which stores failed asynchronous invocations. By doing this, the developer can troubleshoot any failed functions and reprocess the events."},{"timestamp":"1679875140.0","comment_id":"851579","comments":[{"content":"Read it carefully: \"The Lambda application logs show no errors or failures\"\nThere are logs, so the lambda was called\n\nanswer B","poster":"konieczny69","comment_id":"1136943","upvote_count":"1","timestamp":"1706716800.0"}],"poster":"Untamables","upvote_count":"12","content":"Selected Answer: A\nA\nThe Lambda function might have not been called since the Lambda logs show no errors or failures. The cause might be that the frontend application does not call the API or an error occurs in the API Gateway processing."},{"comment_id":"849825","content":"Selected Answer: A\nB is wrong, if send to DLQ, there should be failed and try logs for lambda before sending to DLQ","timestamp":"1679724180.0","upvote_count":"2","poster":"clarksu"},{"comment_id":"849662","upvote_count":"4","content":"Selected Answer: B\nUse DLQ","timestamp":"1679698740.0","poster":"Dun6"}],"topic":"1","question_text":"An ecommerce company is using an AWS Lambda function behind Amazon API Gateway as its application tier. To process orders during checkout, the application calls a POST API from the frontend. The POST API invokes the Lambda function asynchronously. In rare situations, the application has not processed orders. The Lambda application logs show no errors or failures.\nWhat should a developer do to solve this problem?","answer":"B","question_id":509,"answer_description":"","isMC":true,"choices":{"B":"Create and inspect the Lambda dead-letter queue. Troubleshoot the failed functions. Reprocess the events.","D":"Make sure that caching is disabled for the POST API in API Gateway.","A":"Inspect the frontend logs for API failures. Call the POST API manually by using the requests from the log file.","C":"Inspect the Lambda logs in Amazon CloudWatch for possible errors. Fix the errors."},"answer_images":[],"timestamp":"2023-03-24 23:59:00","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/103807-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_images":[],"answers_community":["B (57%)","A (28%)","Other"]},{"id":"6px9YUygpcNTzIMwFNPY","question_text":"A company is building a web application on AWS. When a customer sends a request, the application will generate reports and then make the reports available to the customer within one hour. Reports should be accessible to the customer for 8 hours. Some reports are larger than 1 MB. Each report is unique to the customer. The application should delete all reports that are older than 2 days.\nWhich solution will meet these requirements with the LEAST operational overhead?","answer":"C","answer_ET":"C","discussion":[{"poster":"gpt_test","upvote_count":"15","timestamp":"1696376640.0","content":"Selected Answer: C\nExplanation: Storing the reports in an Amazon S3 bucket provides a cost-effective and scalable solution for handling files larger than 1 MB. Server-side encryption ensures data security. Generating a presigned URL with an expiration date allows the customer to access the report for 8 hours, and S3 Lifecycle configuration rules automatically delete the reports older than 2 days, reducing operational overhead.","comment_id":"860463"},{"upvote_count":"8","poster":"March2023","timestamp":"1695675120.0","content":"Selected Answer: C\nPresigned URL","comment_id":"850532"},{"timestamp":"1735034160.0","content":"Selected Answer: C\nS3 Lifecycle rules can automatically delete objects after 2 days, reducing operational overhead by eliminating the need for custom cleanup logic\n\nA) Eliminated - DynamoDB is not designed to store large objects (e.g., reports larger than 1 MB).\n\nD) Eliminated - Storing large reports in a relational database like RDS is inefficient and costly compared to S3.","comments":[{"upvote_count":"1","poster":"sumanshu","timestamp":"1735034220.0","comment_id":"1331075","content":"B) Eliminated - Attaching reports to SNS messages is impractical because SNS is not designed for large file attachments."}],"comment_id":"1331074","poster":"sumanshu","upvote_count":"1"},{"upvote_count":"1","poster":"65703c1","timestamp":"1732244040.0","content":"Selected Answer: C\nC is the correct answer.","comment_id":"1215313"},{"comment_id":"1098916","content":"Selected Answer: C\nThe 1MB condition denies the TTL option so C is best","upvote_count":"2","poster":"KarBiswa","timestamp":"1718622180.0"},{"timestamp":"1717364820.0","comment_id":"1086477","content":"C\npresigned and lifecycle rules to move","upvote_count":"1","poster":"LR2023"},{"timestamp":"1708351380.0","upvote_count":"6","content":"A) DynamoDB cannot store object larger than 400K\nB) SNS cannot send email with attachment - https://repost.aws/questions/QUOvaKJVb3QzOqVENONBZUag/sns-send-file-attachment\nD) the nature or format of the report is not specified, however RDS doent look like a great place to store large document file. Also generating a url to the reports from the RDS database requires some work while it is a native capabilities in S3\n\nC) is a workable solution as S3 is designed to store file objects, it allows to easily generate pre-signed url, and provide lifecycle management rule that allows to expire objects","poster":"ninomfr64","comment_id":"985168"},{"content":"Selected Answer: C\nDynamo DB cannot store object > 400KB -> option A is out immediately. \nLimited access to S3 calls for presigned URL which is option C. C also has lifecycle config to delete old object while B does not have that. \nD is possible but too much effort compared to design pattern in C.","poster":"imvb88","upvote_count":"5","timestamp":"1700854980.0","comment_id":"906073"},{"timestamp":"1695773400.0","upvote_count":"5","content":"Selected Answer: C\nC\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html","poster":"Untamables","comment_id":"851582"}],"exam_id":24,"choices":{"D":"Generate the reports and then store the reports in an Amazon RDS database with a date stamp. Generate an URL that retrieves the reports from the RDS database. Provide the URL to customers through the web application. Schedule an hourly AWS Lambda function to delete database records that have expired date stamps.","B":"Generate the reports and then store the reports in an Amazon S3 bucket that uses server-side encryption. Attach the reports to an Amazon Simple Notification Service (Amazon SNS) message. Subscribe the customer to email notifications from Amazon SNS.","C":"Generate the reports and then store the reports in an Amazon S3 bucket that uses server-side encryption. Generate a presigned URL that contains an expiration date Provide the URL to customers through the web application. Add S3 Lifecycle configuration rules to the S3 bucket to delete old reports.","A":"Generate the reports and then store the reports as Amazon DynamoDB items that have a specified TTL. Generate a URL that retrieves the reports from DynamoDB. Provide the URL to customers through the web application."},"question_id":510,"timestamp":"2023-03-25 23:52:00","answer_description":"","isMC":true,"topic":"1","unix_timestamp":1679784720,"url":"https://www.examtopics.com/discussions/amazon/view/103904-exam-aws-certified-developer-associate-dva-c02-topic-1/","answers_community":["C (100%)"],"question_images":[],"answer_images":[]}],"exam":{"numberOfQuestions":551,"name":"AWS Certified Developer - Associate DVA-C02","isImplemented":true,"provider":"Amazon","isMCOnly":true,"id":24,"lastUpdated":"11 Apr 2025","isBeta":false},"currentPage":102},"__N_SSP":true}