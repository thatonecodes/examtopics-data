{"pageProps":{"questions":[{"id":"ffzke5Rp6iJlrJXeouiM","question_images":[],"question_text":"A financial company wants to store sensitive user data in an Amazon Aurora PostgreSQL DB cluster. The database will be accessed by multiple applications across the company. The company has mandated that all communications to the database be encrypted and the server identity must be validated. Any non-SSL- based connections should be disallowed access to the database.\nWhich solution addresses these requirements?","exam_id":22,"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/26777-exam-aws-certified-database-specialty-topic-1-question-64/","topic":"1","timestamp":"2020-07-27 14:27:00","discussion":[{"comment_id":"144953","timestamp":"1632199080.0","upvote_count":"10","poster":"BillyC","content":"ANS D is Correct!"},{"comment_id":"595622","poster":"novice_expert","comments":[{"upvote_count":"1","poster":"khchan123","comment_id":"604267","timestamp":"1653030540.0","content":"Yes answer D."}],"timestamp":"1651414500.0","upvote_count":"6","content":"Selected Answer: D\n- in DB parameter groups: rds.force_ssl=1 (o=>false, 1=>true)\n-Download and use the Amazon RDS certificate bundle \n- configure the PostgreSQL connection string with\n sslmode=verify-full.\n\nhttps://jdbc.postgresql.org/documentation/head/ssl-client.html\nIf sslmode=verify-ca, the server is verified by checking the certificate chain up to the root certificate stored on the client.\n\nIf sslmode=verify-full, the server host name will be verified to make sure it matches the name stored in the server certificate."},{"content":"Selected Answer: D\nAnswer is D\n\nrds.force_ssl=1 to force ssl in RDS and sslmode=verify-full to encrypt the connection and validate server identity.","comment_id":"1007309","upvote_count":"2","poster":"Pranava_GCP","timestamp":"1694675040.0"},{"timestamp":"1671785100.0","comment_id":"754045","poster":"tucobbad","upvote_count":"3","content":"Selected Answer: D\nAns is D\n\nrds.force_ssl=1 to force ssl in RDS and sslmode=verify-full to encrypt the connection and validate server identity."},{"timestamp":"1636047960.0","upvote_count":"1","content":"Correct Answer ==>> D","comment_id":"430291","poster":"guru_ji"},{"upvote_count":"2","timestamp":"1635871680.0","content":"Ans: D","comment_id":"298819","poster":"myutran"},{"comment_id":"253404","upvote_count":"1","content":"D indeed is the right choice","poster":"JobinAkaJoe","timestamp":"1634902080.0"},{"poster":"Ashoks","upvote_count":"2","content":"yes. it is D","timestamp":"1633852680.0","comment_id":"212733"},{"upvote_count":"3","timestamp":"1632593940.0","comment_id":"152567","content":"ANS: D\nPostgreSQL: sslrootcert=rds-cert.pem sslmode=[verify-ca | verify-full]","poster":"firbhat"}],"question_id":321,"answer":"D","unix_timestamp":1595852820,"choices":{"A":"Set the rds.force_ssl=0 parameter in DB parameter groups. Download and use the Amazon RDS certificate bundle and configure the PostgreSQL connection string with sslmode=allow.","B":"Set the rds.force_ssl=1 parameter in DB parameter groups. Download and use the Amazon RDS certificate bundle and configure the PostgreSQL connection string with sslmode=disable.","D":"Set the rds.force_ssl=1 parameter in DB parameter groups. Download and use the Amazon RDS certificate bundle and configure the PostgreSQL connection string with sslmode=verify-full.","C":"Set the rds.force_ssl=0 parameter in DB parameter groups. Download and use the Amazon RDS certificate bundle and configure the PostgreSQL connection string with sslmode=verify-ca."},"answer_images":[],"isMC":true,"answer_description":"","answers_community":["D (100%)"]},{"id":"4XwVWYuO8SoE0p9FPXzm","timestamp":"2020-07-25 03:19:00","topic":"1","question_images":[],"answer_ET":"A","choices":{"B":"Create an AWS Lambda function to run on the first day of every month to take a manual RDS snapshot.","D":"Create an AWS Lambda function to run on the first day of every month to create an automated RDS snapshot.","A":"Create an AWS Lambda function to run on the first day of every month to take a manual RDS snapshot. Move the snapshot to the company's Amazon S3 bucket.","C":"Create an RDS snapshot schedule from the AWS Management Console to take a snapshot every 30 days."},"unix_timestamp":1595639940,"url":"https://www.examtopics.com/discussions/amazon/view/26594-exam-aws-certified-database-specialty-topic-1-question-65/","discussion":[{"poster":"Exia","content":"A.\nUnlike automated backups, manual snapshots aren't subject to the backup retention period. Snapshots don't expire.\n\nFor very long-term backups of MariaDB, MySQL, and PostgreSQL data, we recommend exporting snapshot data to Amazon S3. If the major version of your DB engine is no longer supported, you can't restore to that version from a snapshot.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html","comments":[{"content":"So the keyword here is \"move to S3\". Move means copy to S3 and then delete on RDS. The question asks for \"operational efficiency\" and \"24 hours\" to report to auditor. Just leave it in RDS, it doesn't expire and can be easily share right away. B is the answer.","comment_id":"645601","poster":"helpaws","upvote_count":"3","timestamp":"1660248240.0"}],"upvote_count":"14","comment_id":"293976","timestamp":"1633954200.0"},{"poster":"db2luwdba","timestamp":"1658116560.0","upvote_count":"10","content":"There is difference between copy / share a snapshot and Export. Export to S3 option will \n\n When you export a DB snapshot, Amazon RDS extracts data from the snapshot and stores it in an Amazon S3 bucket. The data is stored in an Apache Parquet format that is compressed and consistent.\nWhere you have option to copy manual snapshot as is to different region or different AWS account. So we can not basically move the manual snapshot to S3 directly. \nB is correct.","comment_id":"632810","comments":[{"poster":"db2luwdba","timestamp":"1658116800.0","comment_id":"632812","content":"Plus \nUnlike automated backups, manual snapshots aren't subject to the backup retention period. Snapshots don't expire.\n\nFor very long-term backups of MariaDB, MySQL, and PostgreSQL data, we recommend exporting snapshot data to Amazon S3. If the major version of your DB engine is no longer supported, you can't restore to that version from a snapshot.\n\nHere the backup movement is only for compliance. there is no requirement to query that backup .( using parquet format query through athena or rds redshift spectrum )","upvote_count":"3"}]},{"comment_id":"1300509","content":"Selected Answer: B\nB no need to move snapshots as a suggests","upvote_count":"1","timestamp":"1729434660.0","poster":"michalf84"},{"comment_id":"1277740","content":"Selected Answer: B\nNo need to move the file it stays in aws","upvote_count":"1","poster":"michalf84","timestamp":"1725381660.0"},{"timestamp":"1714012500.0","upvote_count":"1","poster":"rahul2406","content":"B is correct","comment_id":"1201715"},{"content":"Selected Answer: B\nB is the most operationally efficient.","upvote_count":"1","comment_id":"1121696","timestamp":"1705153800.0","poster":"MultiAZ"},{"poster":"jitesh_k","upvote_count":"1","timestamp":"1701477600.0","comment_id":"1085575","content":"https://aws.amazon.com/blogs/database/amazon-rds-snapshot-restore-and-recovery-demystified/#:~:text=Amazon%20RDS%20snapshots%20are%20stored,for%20copy%20and%20restore%20operations.\n\nManual RDS snapshots are stored in S3 anyways. So moving to S3 does not make sense."},{"poster":"Sathish_dbs","content":"Selected Answer: B\nKeep the snapshot the in the RDS itself, no need to waste the operational efficiency by moving to and restoring from S3 unnecessarily","comment_id":"1040697","timestamp":"1697031540.0","upvote_count":"1"},{"poster":"milan9527","timestamp":"1686208440.0","comment_id":"917939","upvote_count":"1","content":"Selected Answer: B\nMove to S3 is additional work without efficiency"},{"upvote_count":"1","timestamp":"1685625600.0","comment_id":"912141","poster":"aviathor","content":"Selected Answer: A\nActually you do not even need to take a manual snapshot. Even automated snapshots can be exported to S3. \n\nYou can export all types of DB snapshotsâ€”including manual snapshots, automated system snapshots, and snapshots created by the AWS Backup service.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ExportSnapshot.html"},{"comments":[{"upvote_count":"2","poster":"Nice_Guy","timestamp":"1678081380.0","comment_id":"830567","content":"I think the maximum retention period of automated backups is 35 days."}],"comment_id":"829653","upvote_count":"1","content":"Selected Answer: C\nOption C, creating an RDS snapshot schedule from the AWS Management Console to take a snapshot every 30 days, would be the most operationally efficient solution for this scenario.","poster":"ninjalight25","timestamp":"1677994920.0"},{"upvote_count":"1","poster":"lollyj","content":"Selected Answer: B\nThis is confusing because don't allow manual snapshots end up in s3 anyway?","comment_id":"750304","timestamp":"1671490620.0"},{"comment_id":"724021","upvote_count":"1","comments":[{"content":"my mistacke... B is the more correct.\nbecause, only need to backups for a month..\nso only need to snapshot 12*5 = 60.\nit does not reach the rds snapshot's limitation.","comment_id":"738524","upvote_count":"2","poster":"Maze","timestamp":"1670464800.0"},{"poster":"MrAliMohsan","timestamp":"1684837800.0","upvote_count":"1","content":"Also since they asked for \"Operationally Efficient\" Option so I also think B is a better answer.","comment_id":"904815"},{"timestamp":"1689186360.0","poster":"leotoras","content":"this limit is adjustable, you can really have more than 100 snaps per region","upvote_count":"1","comment_id":"950087"}],"poster":"Maze","content":"A.\nmanual snapshot has a limitation. (Each supported Region: 100)\nthis case, customer want to keep backup 5 years..\nso i think, it can't possible to keep snapshots during 5 yeers(365*5)\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html#RDS_Limits.Limits","timestamp":"1669081680.0"},{"comment_id":"698627","content":"Selected Answer: A\nA is the answer. aws recommends long term backups to be exported to s3","timestamp":"1666147320.0","poster":"awsjjj","upvote_count":"2"},{"poster":"awsjjj","comment_id":"696612","content":"Selected Answer: A\nFor very long-term backups of MariaDB, MySQL, and PostgreSQL data, we recommend exporting snapshot data to Amazon S3. If the major version of your DB engine is no longer supported, you can't restore to that version from a snapshot.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html","timestamp":"1665958620.0","upvote_count":"2"},{"timestamp":"1664324280.0","upvote_count":"1","comment_id":"681314","content":"Option B is correct. manual snapshot won't expire.","poster":"yxyj"},{"poster":"ryuhei","timestamp":"1656077220.0","comment_id":"621672","upvote_count":"4","content":"Selected Answer: B\nI don't think you can move snapshots to individual S3, so the answer is probably B."},{"upvote_count":"3","poster":"awsguys","content":"A and B seems right . but i choose A . Move the snapshot to the company's Amazon S3 bucket. sound likes more right .","comment_id":"605525","timestamp":"1653224760.0"},{"upvote_count":"2","timestamp":"1651366740.0","comment_id":"595374","poster":"novice_expert","content":"Selected Answer: A\nA. Create an AWS Lambda function to run on the first day of every month to take a manual RDS snapshot. Move the snapshot to the company's Amazon S3 bucket.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html"},{"comment_id":"562126","timestamp":"1646583960.0","content":"This is also a Tutorials DOJO question (a very respectable site) and their choice is also (A). If they say its (A) -> its pretty much as close as being stamped by official RDS","poster":"RotterDam","upvote_count":"3"},{"poster":"RotterDam","upvote_count":"6","timestamp":"1646583720.0","content":"Selected Answer: A\nA seems right. You can set lifecycle rules to move the snapshots to cold storage and delete them after 5 years in S3","comment_id":"562122"},{"upvote_count":"3","content":"A: \nThere is a requirements to keep the snapshots for 5 years. RDS only allows up to 100 snapshots. \n\nAs per the link from Exia, https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html. There is a recommendation:\n\nFor very long-term backups of MariaDB, MySQL, and PostgreSQL data, we recommend exporting snapshot data to Amazon S3.","poster":"awsmonster","timestamp":"1641707640.0","comment_id":"519946"},{"timestamp":"1640619540.0","upvote_count":"3","poster":"jove","comment_id":"510431","content":"Selected Answer: B\nYou need a monthly manual snapshot, for sure but you cannot MOVE a snapshot to an S3 bucket, you can EXPORT it in a parquet format but cannot MOVE or COPY it."},{"poster":"SMAZ","timestamp":"1640471100.0","upvote_count":"1","comment_id":"509305","content":"A - as it says company owned s3 bucket."},{"content":"Also wording \"move snapshot\" is used instead of \"export snapshot\" so will go with B but in real case use option A and export snapshot","upvote_count":"1","poster":"dkay16","comment_id":"445506","timestamp":"1635959040.0"},{"timestamp":"1635875460.0","upvote_count":"2","comment_id":"445502","comments":[{"timestamp":"1636084560.0","content":"planning for exam ?","poster":"guru_ji","comment_id":"446009","upvote_count":"1"},{"comment_id":"508561","poster":"jove","content":"You can't use Athena for viewing RDS snapshots","comments":[{"upvote_count":"1","comment_id":"508564","poster":"jove","content":"I was wrong. The snapshot \"export\", exports the data in parquet format which can be queried using Athena.. \n\nFor long term backups, you should export the snapshots to S3","timestamp":"1640361540.0"}],"upvote_count":"1","timestamp":"1640360940.0"}],"poster":"dkay16","content":"I think A because once you move/export RDS snapshot to S3 it can be viewed using Athena or other methods by auditors. In case of B , yes snapshot will be on S3 but to give data to Auditor in 24 hours we have to restore the DB and extract data or give permission to access DB which may or may not possible in 24 hours for multiple instances. https://aws.amazon.com/blogs/database/building-data-lakes-and-implementing-data-retention-policies-with-amazon-rds-snapshot-export-to-amazon-s3/. Really not a valid question without detail requirements but again this is test ."},{"content":"A. \nThe bucket used to store the manual snapshot is in the AWS ownership and we cannot control the life cycle policy. Moving to a company-owned bucket will help with configuring the life cycle.","timestamp":"1635852000.0","poster":"LB","comment_id":"435596","upvote_count":"1"},{"comments":[{"timestamp":"1639150080.0","comment_id":"498799","poster":"2025flakyt","content":"How about storage for 5 years to meet compliance?","upvote_count":"1"}],"comment_id":"378599","timestamp":"1635173940.0","upvote_count":"2","content":"BBBBBBBBBBBBBBBBBBBB\n\nA - looks a trap answer - you don't have to move to S3 as manual snapshots are retained until removed.\n\nC, D - ruled out of equation","poster":"Suresh108"},{"timestamp":"1635047700.0","upvote_count":"1","poster":"AM","comment_id":"377813","content":"B seems right. Manual backups never expire.No need to move to S3."},{"timestamp":"1634850780.0","comment_id":"365420","poster":"Dip11","content":"C and D are ruled out as not possible. From A and B, the snapshots are already stored on S3 so no need to separately move. And question does not mention about export to S3. So Answer should be B.","upvote_count":"3"},{"comment_id":"306719","content":"B,C and D do not address the retention part. To keep the data you need to move it to S3","poster":"jyrajan","upvote_count":"1","timestamp":"1634509920.0","comments":[{"comment_id":"358795","poster":"Aesthet","upvote_count":"1","content":"manual snapshots are retained until you delete them - no need to move to s3. Also you can't \"move\" data to s3, only export it and only for mariadb, mysql, postgre and also with some additional limitations descibed here https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ExportSnapshot.html#USER_ExportSnapshot.Limits\nFor me answer B is correct","timestamp":"1634817780.0"}]},{"poster":"myutran","comment_id":"298829","content":"Ans: B","upvote_count":"1","timestamp":"1634469960.0"},{"content":"A. Only one of the answers moves data to S3. The data is 5TB and S3 can hold that, Lambda can work on a event trigger. Once in S3 the data can be moved to Glacier on LifeCycle Object, and retained for as long as you need and has retrieval option of 3-5 hours","upvote_count":"1","timestamp":"1634271300.0","poster":"jyrajan","comment_id":"297898"},{"upvote_count":"1","content":"B - Not every RDS DB can be exported to S3 and here are undefined multiple RDS instances.","poster":"koniec","timestamp":"1633879920.0","comment_id":"279746"},{"content":"Must be A","poster":"Pavs1","timestamp":"1633771860.0","upvote_count":"1","comment_id":"278781"},{"timestamp":"1632717960.0","comment_id":"212737","poster":"Ashoks","comments":[{"timestamp":"1646583840.0","poster":"RotterDam","comment_id":"562124","upvote_count":"1","content":"you cant share the manual snapshots in the s3 buckets owned by Amazon"}],"content":"B. Manual snapshots are stored in S3 and they are available to share till manually delete them.","upvote_count":"3"},{"upvote_count":"3","timestamp":"1632691500.0","poster":"vicks316","comments":[{"comments":[{"comment_id":"356009","poster":"Zhongkai","upvote_count":"1","content":"we can restore db from s3","timestamp":"1634557200.0"}],"comment_id":"253414","poster":"JobinAkaJoe","upvote_count":"2","content":"Thats just an assumption. What if auditor(could be internal) wants the db restored from backup. B is the best answer","timestamp":"1633058580.0"},{"timestamp":"1632876060.0","upvote_count":"1","content":"The answer is B","comment_id":"220857","poster":"[Removed]"}],"content":"The answer is A, you have to move the manual snapshot to an s3 bucket to be able to provide it to an auditor.","comment_id":"201795"},{"comment_id":"145866","content":"B is correct for me","upvote_count":"3","timestamp":"1632411900.0","poster":"BillyC"},{"upvote_count":"2","content":"B.\nfor automated backup feature, RDS retains backups of a DB Instance for a limited, user-specified period of time called the retention period, which by default is 7 days but can be set to up to 35 days.","comment_id":"143057","timestamp":"1632376440.0","poster":"lui"}],"isMC":true,"answers_community":["B (48%)","A (48%)","4%"],"answer_description":"","answer_images":[],"answer":"B","question_id":322,"exam_id":22,"question_text":"A company is using 5 TB Amazon RDS DB instances and needs to maintain 5 years of monthly database backups for compliance purposes. A Database\nAdministrator must provide Auditors with data within 24 hours.\nWhich solution will meet these requirements and is the MOST operationally efficient?"},{"id":"n7UJLx8XEh2igk7nOpaK","timestamp":"2020-07-27 14:32:00","exam_id":22,"topic":"1","answer_images":[],"discussion":[{"timestamp":"1632513060.0","comment_id":"144956","comments":[{"comments":[{"timestamp":"1635918480.0","upvote_count":"1","content":"New requirement, only visible if you have contributor access","comment_id":"306723","poster":"jyrajan"}],"poster":"BillyMadison","comment_id":"146872","timestamp":"1633016400.0","content":"BillyC, any idea why the AWS Database specialty exam is so hard to find on this site / why there are 404 errors?","upvote_count":"1"}],"content":"Ans C is correct","upvote_count":"11","poster":"BillyC"},{"poster":"IhorK","comment_id":"972400","upvote_count":"1","content":"Selected Answer: C\n\"Add a resource of type AWS::SecretsManager::RotationSchedule\" missing in answer C.","timestamp":"1691175000.0"},{"timestamp":"1691174640.0","poster":"IhorK","upvote_count":"1","content":"Selected Answer: C\nhttps://malsouli.medium.com/aws-secrets-manager-create-and-rotate-secrets-automatically-36719faa7e4f","comment_id":"972395"},{"upvote_count":"3","poster":"novice_expert","comment_id":"595665","content":"Selected Answer: C\nincomplete or wrong info but answer needs SecretsManager which is in C only\n\nAdd a resource of type AWS::SecretsManager::Secret \n-> specify the GenerateSecretString property\n-> define the database user name in the SecureStringTemplate template. \n-> Create a resource for the database \n-> reference the secret string for the MasterUserName and MasterUserPassword properties. \n-> add a resource of type AWS::SecretsManagerSecretTargetAttachment with the SecretId and TargetId properties set to the Amazon Resource Names (ARNs) of the secret and the database.","timestamp":"1651422540.0"},{"poster":"RotterDam","comment_id":"561734","timestamp":"1646531340.0","upvote_count":"1","content":"(C) is correct"},{"content":"yes, it is C","timestamp":"1635669900.0","poster":"Ashoks","upvote_count":"4","comment_id":"212741"},{"timestamp":"1633072740.0","poster":"Ebi","content":"Answer is C","comment_id":"159030","upvote_count":"3"}],"question_images":[],"choices":{"B":"Add a Mapping property from the database Amazon Resource Name (ARN) to the secret ARN. Then, create the secret with a chosen user name and a randomly generated password set by the GenerateSecretString property. Add the database with the MasterUserName and MasterUserPassword properties set to the user name of the secret.","C":"Add a resource of type AWS::SecretsManager::Secret and specify the GenerateSecretString property. Then, define the database user name in the SecureStringTemplate template. Create a resource for the database and reference the secret string for the MasterUserName and MasterUserPassword properties. Then, add a resource of type AWS::SecretsManagerSecretTargetAttachment with the SecretId and TargetId properties set to the Amazon Resource Names (ARNs) of the secret and the database.","D":"Create the secret with a chosen user name and a randomly generated password set by the GenerateSecretString property. Add an SecretTargetAttachment resource with the SecretId property set to the Amazon Resource Name (ARN) of the secret and the TargetId property set to a parameter value matching the desired database ARN. Then, create a database with the MasterUserName and MasterUserPassword properties set to the previously created values in the secret.","A":"Create the database with the MasterUserName and MasterUserPassword properties set to the default values. Then, create the secret with the user name and password set to the same default values. Add a Secret Target Attachment resource with the SecretId and TargetId properties set to the Amazon Resource Names (ARNs) of the secret and the database. Finally, update the secret's password value with a randomly generated string set by the GenerateSecretString property."},"answer_ET":"C","isMC":true,"question_id":323,"answer":"C","unix_timestamp":1595853120,"question_text":"A company wants to automate the creation of secure test databases with random credentials to be stored safely for later use. The credentials should have sufficient information about each test database to initiate a connection and perform automated credential rotations. The credentials should not be logged or stored anywhere in an unencrypted form.\nWhich steps should a Database Specialist take to meet these requirements using an AWS CloudFormation template?","url":"https://www.examtopics.com/discussions/amazon/view/26778-exam-aws-certified-database-specialty-topic-1-question-66/","answers_community":["C (100%)"],"answer_description":""},{"id":"j4ggAsDr13ZIvCzCeAE5","discussion":[{"content":"Selected Answer: C\nC. Execute GRANT and REVOKE commands that restrict access to the tables containing sensitive data.\n\nhttps://aws.amazon.com/blogs/database/managing-postgresql-users-and-roles/#:~:text=GRANT%20SELECT%20ON%20TABLE%20mytable1%2C%20mytable2%20TO%20readonly%3B","upvote_count":"2","comment_id":"992071","timestamp":"1693220400.0","poster":"Pranava_GCP"},{"comment_id":"972405","upvote_count":"2","poster":"IhorK","timestamp":"1691175480.0","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/database/managing-postgresql-users-and-roles/"},{"timestamp":"1678402140.0","content":"I am leaning towards A since you do not need to issue a GRANT to revoke a permission. U use grant to grant access to a table . C is kind of confusing","poster":"sk1974","comment_id":"834496","upvote_count":"2"},{"upvote_count":"4","poster":"novice_expert","timestamp":"1651369740.0","comment_id":"595394","content":"Selected Answer: C\nx A. Use AWS IAM database authentication and restrict access to the tables using an IAM policy. (this is for db access)\nx B. Configure the rules in a NACL to restrict outbound traffic from the Aurora DB cluster. (This is for Network Access Control)\nC. Execute GRANT and REVOKE commands that restrict access to the tables containing sensitive data.\nx D. Define access privileges to the tables containing sensitive data in the pg_hba.conf file. (not allowed)","comments":[{"comment_id":"911597","content":"revoke dies not restrict access\nit revokes some existing grant","poster":"Zdujgfr567783ff","upvote_count":"1","timestamp":"1685575500.0"}]},{"upvote_count":"3","timestamp":"1635778680.0","content":"C.\nTable level means DCL","poster":"TonyGe","comment_id":"415807"},{"comment_id":"377815","timestamp":"1635439380.0","content":"This is easy. I am a DBA.Table level access is GRANT,REVOKE for many database flavors including Oracle an Postgres. Answer is C.","poster":"AM","upvote_count":"2"},{"content":"Ans: C","poster":"myutran","comment_id":"298843","upvote_count":"2","timestamp":"1635334560.0"},{"poster":"GeeBeeEl","content":"I see answers like A or C, but I am looking for collateral support and cannot find any in the options selected so far. I choose A, see https://aws.amazon.com/blogs/database/managing-postgresql-users-and-roles/ You create roles and then attach policies to the roles. May you support your response with a link so that we can check to confirm your reasoning? Thanks","upvote_count":"1","comment_id":"294800","timestamp":"1635204420.0","comments":[{"comment_id":"403020","timestamp":"1635581460.0","upvote_count":"2","content":"in your provided link roles are db roles not IAM roles :) so C is correct","poster":"ExtHo"}]},{"content":"It is C","comment_id":"212755","poster":"Ashoks","timestamp":"1634512920.0","upvote_count":"3"},{"poster":"Ebi","content":"Answer is C","upvote_count":"1","comment_id":"159032","timestamp":"1634325180.0"},{"comment_id":"153913","timestamp":"1633942140.0","poster":"Billhardy","upvote_count":"2","content":"This should be C"},{"comment_id":"146467","timestamp":"1632426840.0","upvote_count":"1","poster":"BillyC","content":"A or C.. please comments","comments":[{"comment_id":"147002","poster":"Kitty0403","content":"Answer is C. Table level access is managed by DCL.","timestamp":"1632473520.0","upvote_count":"7"}]}],"answer_ET":"C","answer":"C","question_id":324,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/26925-exam-aws-certified-database-specialty-topic-1-question-67/","choices":{"C":"Execute GRANT and REVOKE commands that restrict access to the tables containing sensitive data.","D":"Define access privileges to the tables containing sensitive data in the pg_hba.conf file.","A":"Use AWS IAM database authentication and restrict access to the tables using an IAM policy.","B":"Configure the rules in a NACL to restrict outbound traffic from the Aurora DB cluster."},"exam_id":22,"topic":"1","answer_description":"","answers_community":["C (100%)"],"isMC":true,"unix_timestamp":1596024600,"timestamp":"2020-07-29 14:10:00","question_images":[],"question_text":"A company is going to use an Amazon Aurora PostgreSQL DB cluster for an application backend. The DB cluster contains some tables with sensitive data. A\nDatabase Specialist needs to control the access privileges at the table level.\nHow can the Database Specialist meet these requirements?"},{"id":"6v4PyYS9Lkc5pXUz4T6n","answer_images":[],"choices":{"C":"Remove the DB cluster endpoint to simulate a master DB instance failure","D":"Use Aurora Backtrack to crash the DB cluster","B":"Use Aurora fault injection to crash the master DB instance","A":"Stop the DB cluster and analyze how the website responds"},"exam_id":22,"question_id":325,"question_text":"A Database Specialist is working with a company to launch a new website built on Amazon Aurora with several Aurora Replicas. This new website will replace an on-premises website connected to a legacy relational database. Due to stability issues in the legacy database, the company would like to test the resiliency of\nAurora.\nWhich action can the Database Specialist take to test the resiliency of the Aurora DB cluster?","topic":"1","timestamp":"2020-07-28 16:52:00","question_images":[],"unix_timestamp":1595947920,"isMC":true,"answers_community":["B (100%)"],"answer_description":"","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/26856-exam-aws-certified-database-specialty-topic-1-question-68/","discussion":[{"upvote_count":"7","poster":"TonyGe","comment_id":"415808","timestamp":"1636232100.0","content":"B.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Managing.FaultInjectionQueries.html"},{"poster":"jitesh_k","upvote_count":"1","content":"Cannot be A because stopping the DB cluster means application does not have a Database at all.\nCannot be C because removing DB cluster endpoint will also mean the same thing as above.\nD is just a distractor - backtrack cannot crash a cluster.\nB makes sense - it crashes one instance and allows Aurora to recover.","comment_id":"1085646","timestamp":"1701484620.0"},{"upvote_count":"2","timestamp":"1693221060.0","comment_id":"992084","poster":"Pranava_GCP","content":"Selected Answer: B\nB. Use Aurora fault injection to crash the master DB instance"},{"comment_id":"595356","timestamp":"1651362780.0","content":"Selected Answer: B\nB. Use Aurora fault injection to crash the master DB instance","upvote_count":"4","poster":"novice_expert"},{"content":"Ans;: B","poster":"myutran","upvote_count":"3","comment_id":"298844","timestamp":"1635940440.0"},{"timestamp":"1634840520.0","poster":"Ashoks","comment_id":"212757","upvote_count":"3","content":"It is B"},{"poster":"BillyMadison","content":"B with the link that is provided in the suggested answer\n\"You can test the fault tolerance of your Amazon Aurora DB cluster by using fault injection queries. Fault injection queries are issued as SQL commands to an Amazon Aurora instance and they enable you to schedule a simulated occurrence of one of the following events:\nA crash of a writer or reader DB instance\nA failure of an Aurora Replica\nA disk failure\nDisk congestion\nWhen a fault injection query specifies a crash, it forces a crash of the Aurora DB instance. The other fault injection queries result in simulations of failure events, but don't cause the event to occur. When you submit a fault injection query, you also specify an amount of time for the failure event simulation to occur for.\"","comment_id":"157643","upvote_count":"4","timestamp":"1633853700.0"},{"timestamp":"1633105860.0","poster":"firbhat","comment_id":"153964","upvote_count":"3","content":"Ans B:\n Two ways to test/simulate fault tolerance â€¢ Manual failover\nâ€¢ Fault injection queries"},{"content":"will go with B","timestamp":"1632428520.0","comment_id":"153915","upvote_count":"1","poster":"Billhardy"},{"upvote_count":"4","timestamp":"1632259320.0","comment_id":"145883","poster":"BillyC","content":"B is correct"}],"answer":"B"}],"exam":{"name":"AWS Certified Database - Specialty","isMCOnly":false,"numberOfQuestions":359,"lastUpdated":"11 Apr 2025","provider":"Amazon","isBeta":false,"isImplemented":true,"id":22},"currentPage":65},"__N_SSP":true}