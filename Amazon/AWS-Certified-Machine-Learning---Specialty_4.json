{"pageProps":{"questions":[{"id":"aMUVWhEonOoBjFH5FNo4","timestamp":"2021-02-05 18:10:00","question_images":[],"unix_timestamp":1612545000,"answers_community":["B (100%)"],"topic":"1","question_id":16,"choices":{"C":"Deploy the model to an Amazon SageMaker batch transformation job. Generate inferences in a daily batch report to identify machines that need maintenance.","B":"Deploy the model on AWS IoT Greengrass in each factory. Run sensor data through this model to infer which machines need maintenance.","A":"Deploy the model in Amazon SageMaker. Run sensor data through this model to predict which machines need maintenance.","D":"Deploy the model in Amazon SageMaker and use an IoT rule to write data to an Amazon DynamoDB table. Consume a DynamoDB stream from the table with an AWS Lambda function to invoke the endpoint."},"discussion":[{"content":"I would select B, based on the following AWS examples:\n https://aws.amazon.com/blogs/iot/industrial-iot-from-condition-based-monitoring-to-predictive-quality-to-digitize-your-factory-with-aws-iot-services/\nhttps://aws.amazon.com/blogs/iot/using-aws-iot-for-predictive-maintenance/","poster":"[Removed]","upvote_count":"26","comment_id":"284292","timestamp":"1663695300.0"},{"content":"B is my answer.\n\nFor latency-sensitive use cases and for use-cases that require analyzing large amounts of streaming data, it may not be possible to run ML inference in the cloud. Besides, cloud-connectivity may not be available all the time.\n\nFor these use cases, you need to deploy the ML model close to the data source.\n\nSageMaker Neo + IoT GreenGrass\n\nTo design and push something to edge:\n1. design something to do the job, say TF model\n2. compile it for the edge device using SageMaker Neo, say Nvidia Jetson\n3. run it on the edge using IoT GreenGrass","timestamp":"1664754780.0","comment_id":"299291","poster":"SophieSu","upvote_count":"17"},{"comment_id":"990811","poster":"Mickey321","upvote_count":"2","timestamp":"1724679660.0","content":"Selected Answer: B\nwithout relying on internet connectivity."},{"content":"Selected Answer: B\nThe described solution will be solved by an edge solution as internet relability is low. IoT Greengrass is the best solution for the edge inference.","upvote_count":"3","comment_id":"740506","poster":"Peeking","timestamp":"1702162560.0"},{"timestamp":"1687808760.0","poster":"ovokpus","content":"Selected Answer: B\nThis is an edge solution, having as little traffic with AWS resources in regions. For this, start thinking IoT Greengrass and Sagemaker Neo, and you'll be halfway there.\n\nAnswer is B, no doubt","comment_id":"622784","upvote_count":"3"},{"content":"B is the answer, obviously","upvote_count":"1","timestamp":"1675540260.0","comment_id":"540616","poster":"apprehensive_scar"},{"upvote_count":"4","content":"Selected Answer: B\nThis solution requires edge capabilities and to be able to run the inference models in near real-time. SageMaker Neo is a deployable unit on the edge architecture (IoT Greengrass) which can host the runtime inference model.","timestamp":"1668779460.0","comment_id":"480752","poster":"[Removed]"},{"timestamp":"1665251280.0","poster":"mahmoudai","comment_id":"434853","upvote_count":"1","content":"A: not a complete solution a lot of details is missed\nC: daily batch training is huge defect in this solution\nD: writing to dynamoDB and invoking endpoint make this solution slower than using an IoT Green Grass\n\nAnswer: B"},{"content":"I would choose B because IoT reduce latency because they work on local machine","upvote_count":"1","comment_id":"325047","timestamp":"1665154860.0","poster":"Vita_Rasta84444"},{"timestamp":"1664312820.0","comment_id":"291796","poster":"astonm13","content":"I would choose B","upvote_count":"1"}],"exam_id":26,"answer_ET":"B","answer_description":"","answer_images":[],"question_text":"A manufacturer is operating a large number of factories with a complex supply chain relationship where unexpected downtime of a machine can cause production to stop at several factories. A data scientist wants to analyze sensor data from the factories to identify equipment in need of preemptive maintenance and then dispatch a service team to prevent unplanned downtime. The sensor readings from a single machine can include up to 200 data points including temperatures, voltages, vibrations, RPMs, and pressure readings.\nTo collect this sensor data, the manufacturer deployed Wi-Fi and LANs across the factories. Even though many factory locations do not have reliable or high- speed internet connectivity, the manufacturer would like to maintain near-real-time inference capabilities.\nWhich deployment architecture for the model will address these business requirements?","answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/44064-exam-aws-certified-machine-learning-specialty-topic-1/","isMC":true},{"id":"p5V78kqKjaKO16SgrHNy","unix_timestamp":1612545420,"question_text":"A Machine Learning Specialist is designing a scalable data storage solution for Amazon SageMaker. There is an existing TensorFlow-based model implemented as a train.py script that relies on static training data that is currently stored as TFRecords.\nWhich method of providing training data to Amazon SageMaker would meet the business requirements with the LEAST development overhead?","discussion":[{"poster":"[Removed]","timestamp":"1633999920.0","comment_id":"284295","upvote_count":"21","content":"I would select B. Based on the following AWS documentation it appears this is the right approach: \nhttps://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html\nhttps://github.com/aws-samples/amazon-sagemaker-script-mode/blob/master/tf-horovod-inference-pipeline/train.py"},{"timestamp":"1635495120.0","upvote_count":"12","comment_id":"299311","poster":"SophieSu","content":"B is my answer.\nReading Data\nfilenames = [\"s3://bucketname/path/to/file1.tfrecord\",\n \"s3://bucketname/path/to/file2.tfrecord\"]\ndataset = tf.data.TFRecordDataset(filenames)"},{"timestamp":"1727176320.0","content":"Selected Answer: B\nThis approach leverages the existing TFRecord format and minimizes changes to the current setup, ensuring a smooth transition to using Amazon SageMaker with minimal development effort.","comment_id":"1288558","upvote_count":"1","poster":"MultiCloudIronMan"},{"poster":"Mickey321","content":"Selected Answer: B\noption B","comment_id":"990813","upvote_count":"1","timestamp":"1693057380.0"},{"poster":"kaike_reis","timestamp":"1691062200.0","upvote_count":"2","content":"Selected Answer: B\nLetters C and D need code development and are therefore discarded. As we want a scalable data storage, it is recommended to use the Letter B, since S3 is scalable. Letter A is wrong as your personal computer is not scalable.","comment_id":"971057"},{"content":"Where had the Capslock Donald gone? I kinda miss his answers","comment_id":"935100","upvote_count":"8","timestamp":"1687850820.0","poster":"ashton777"},{"timestamp":"1682235480.0","upvote_count":"2","comment_id":"878005","content":"Internet connectivity issue: then how IOT can be a solution? (Correct answer should be A)","poster":"himanshu10k"},{"content":"Selected Answer: B\nAmazon SageMaker script mode enables training a machine learning model using a script that you provide. By using the unchanged train.py script and putting the TFRecord data into an Amazon S3 bucket, you can easily point the Amazon SageMaker training invocation to the S3 bucket without reformatting the training data. \n\nThis option avoids the need to rewrite the train.py script or to prepare the data in a different format. It also leverages the scalability and cost-effectiveness of Amazon S3 for storing large amounts of data, which is important for training machine learning models.","comment_id":"847543","poster":"AjoseO","upvote_count":"3","comments":[{"comment_id":"967894","poster":"ccpmad","upvote_count":"1","content":"thank you chatgpt","timestamp":"1690792320.0"}],"timestamp":"1679521140.0"},{"timestamp":"1643930460.0","poster":"apprehensive_scar","comment_id":"540095","upvote_count":"1","content":"B, obviously"},{"upvote_count":"2","comment_id":"515996","content":"Selected Answer: B\nI like answer B","timestamp":"1641238920.0","poster":"KM226"},{"content":"Why not A? Why can't we train it from local?","poster":"Zhubajie","comment_id":"484282","comments":[{"upvote_count":"5","poster":"AddiWei","comment_id":"551955","timestamp":"1645371480.0","content":"Sagemaker to my understanding requires the data to be in S3."}],"timestamp":"1637590680.0","upvote_count":"1"},{"poster":"Huy","comment_id":"401551","content":"B. https://aws.amazon.com/about-aws/whats-new/2019/01/amazon-sagemaker-batch-transform-now-supports-tfrecord-format/","timestamp":"1635988320.0","upvote_count":"2"},{"timestamp":"1634419260.0","comment_id":"286443","comments":[{"comment_id":"297107","timestamp":"1635235080.0","content":"according your explaination, the correct answer should be B","poster":"SophieSu","upvote_count":"2"},{"poster":"akgarg00","timestamp":"1700390340.0","comment_id":"1074583","upvote_count":"1","content":"It mentions using sagemaker in \"script mode\" Which is different from working on Sagemaker using python SDK."}],"content":"Unfortunilty you can't use the script unchanged, there are some things that need to be added:\n1. Make sure your script can handle --model_dir as an additional command line argument. If you did not specify a location when you created the TensorFlow estimator, an S3 location under the default training job bucket is used. Distributed training with parameter servers requires you to use the tf.estimator.train_and_evaluate API and to provide an S3 location as the model directory during training. \n2. Load input data from the input channels. The input channels are defined when fit is called. \n\n## https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html\n\nBeause of the pre-rec Ans A and B are an easy disqualifcation.\nThere is no need to change the training format so option C is a red herring \n\nAns is D \n\nNot the most obvious answer","upvote_count":"4","poster":"cnethers"}],"answer_ET":"B","choices":{"B":"Use Amazon SageMaker script mode and use train.py unchanged. Put the TFRecord data into an Amazon S3 bucket. Point the Amazon SageMaker training invocation to the S3 bucket without reformatting the training data.","D":"Prepare the data in the format accepted by Amazon SageMaker. Use AWS Glue or AWS Lambda to reformat and store the data in an Amazon S3 bucket.","C":"Rewrite the train.py script to add a section that converts TFRecords to protobuf and ingests the protobuf data instead of TFRecords.","A":"Use Amazon SageMaker script mode and use train.py unchanged. Point the Amazon SageMaker training invocation to the local path of the data without reformatting the training data."},"answer_images":[],"answers_community":["B (100%)"],"topic":"1","timestamp":"2021-02-05 18:17:00","question_images":[],"isMC":true,"question_id":17,"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/44065-exam-aws-certified-machine-learning-specialty-topic-1/","answer_description":"","exam_id":26},{"id":"plyPu3bNYv6Lw722CVER","answer_images":[],"answer_description":"","question_images":[],"answers_community":["D (100%)"],"isMC":true,"unix_timestamp":1614048060,"answer":"D","choices":{"C":"K-means","A":"Latent Dirichlet Allocation (LDA)","D":"Convolutional neural network (CNN)","B":"Recurrent neural network (RNN)"},"timestamp":"2021-02-23 03:41:00","question_id":18,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/45463-exam-aws-certified-machine-learning-specialty-topic-1/","answer_ET":"D","discussion":[{"content":"D. CNN - image","upvote_count":"36","timestamp":"1634281320.0","poster":"SophieSu","comment_id":"297109"},{"content":"yeah, nothing creepy about a company wanting to do this :)","upvote_count":"2","comment_id":"1235563","poster":"Chiquitabandita","timestamp":"1719083040.0"},{"timestamp":"1693057680.0","comment_id":"990818","content":"Selected Answer: D\nD - image","poster":"Mickey321","upvote_count":"2"},{"timestamp":"1691062320.0","content":"Selected Answer: D\nD is the correct\nWell, I did those exams topics questions for 2 weeks and still easier compared to Maarek exams that simulate AWS MLS. Is that correct? Can I expect the exam to be easier as it's in exams topics?","upvote_count":"3","poster":"kaike_reis","comment_id":"971063"},{"content":"Selected Answer: D\nConvolutional neural networks (CNNs) are specifically designed for image recognition tasks and have been highly successful in detecting patterns and features within images. \n\nCNNs are particularly effective in capturing spatial patterns and visual features from images","upvote_count":"2","comment_id":"967896","timestamp":"1690792500.0","poster":"ccpmad"},{"poster":"ryuhei","upvote_count":"1","timestamp":"1664279700.0","comment_id":"680717","content":"Selected Answer: D\nAnswer is \"D\""}],"exam_id":26,"question_text":"The chief editor for a product catalog wants the research and development team to build a machine learning system that can be used to detect whether or not individuals in a collection of images are wearing the company's retail brand. The team has a set of training data.\nWhich machine learning algorithm should the researchers use that BEST meets their requirements?"},{"id":"MD9snjb9PKMCzPLf7ENm","question_id":19,"choices":{"D":"Add event type and event value fields to the interactions dataset in Amazon Personalize.","B":"Add user metadata and use the HRNN-Metadata recipe in Amazon Personalize.","C":"Implement a new solution using the built-in factorization machines (FM) algorithm in Amazon SageMaker.","A":"Use the event tracker in Amazon Personalize to include real-time user interactions."},"question_text":"A retail company is using Amazon Personalize to provide personalized product recommendations for its customers during a marketing campaign. The company sees a significant increase in sales of recommended items to existing customers immediately after deploying a new solution version, but these sales decrease a short time after deployment. Only historical data from before the marketing campaign is available for training.\nHow should a data scientist adjust the solution?","answer":"A","unix_timestamp":1614048540,"answer_images":[],"isMC":true,"question_images":[],"answer_ET":"A","answer_description":"","discussion":[{"comment_id":"297112","upvote_count":"38","poster":"SophieSu","content":"A is the correct answer. Because in this case, it is not the problem with the existing historical data (event value, event type(click or not)), the sales do not keep growing and now you need to obtain more recent interactive data. An event tracker specifies a destination dataset group for new event data.","timestamp":"1666011000.0","comments":[{"poster":"AjithkumarSL","upvote_count":"3","comment_id":"375345","content":"I agree.. A is the right choice.. The model need the real time data to adjust to create recommendations..","timestamp":"1666763640.0"}]},{"poster":"ovokpus","content":"Selected Answer: A\nhere is the receipt:\n\nhttps://docs.aws.amazon.com/personalize/latest/dg/maintaining-relevance.html","timestamp":"1687808160.0","upvote_count":"6","comment_id":"622774"},{"poster":"Mickey321","upvote_count":"1","comment_id":"990827","timestamp":"1724680380.0","content":"Selected Answer: A\nA real time data"},{"timestamp":"1711421040.0","content":"A is the right choice.","poster":"vingidost","upvote_count":"1","comment_id":"850613"},{"comment_id":"807780","upvote_count":"2","content":"Selected Answer: A\nA. Use the event tracker in Amazon Personalize to include real-time user interactions.\n\nBy using the event tracker in Amazon Personalize, the data scientist can collect real-time user interactions, including clicks, views, and purchases, and use these interactions to update the model and generate more accurate recommendations. This could help address the decrease in sales after deploying a new solution version, as the model can be updated to reflect the latest customer behavior. Additionally, including real-time user interactions can help the model better respond to changes in customer behavior and provide more relevant and personalized recommendations, which can help increase sales.","timestamp":"1707855300.0","poster":"AjoseO"},{"poster":"apprehensive_scar","timestamp":"1675535400.0","content":"Selected Answer: A\neasy one. A","comment_id":"540573","upvote_count":"2"},{"poster":"Huy","timestamp":"1667775840.0","comment_id":"401561","upvote_count":"3","content":"A. https://docs.aws.amazon.com/personalize/latest/dg/recording-events.html"}],"exam_id":26,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/45464-exam-aws-certified-machine-learning-specialty-topic-1/","answers_community":["A (100%)"],"timestamp":"2021-02-23 03:49:00"},{"id":"5muXUf6T37BGqWilLoBm","answer_description":"","question_text":"A machine learning (ML) specialist wants to secure calls to the Amazon SageMaker Service API. The specialist has configured Amazon VPC with a VPC interface endpoint for the Amazon SageMaker Service API and is attempting to secure traffic from specific sets of instances and IAM users. The VPC is configured with a single public subnet.\nWhich combination of steps should the ML specialist take to secure the traffic? (Choose two.)","choices":{"D":"Modify the ACL on the endpoint network interface to restrict access to the instances.","C":"Modify the security group on the endpoint network interface to restrict access to the instances.","E":"Add a SageMaker Runtime VPC endpoint interface to the VPC.","A":"Add a VPC endpoint policy to allow access to the IAM users.","B":"Modify the users' IAM policy to allow access to Amazon SageMaker Service API calls only."},"answer":"AC","topic":"1","timestamp":"2021-02-08 21:54:00","isMC":true,"answer_ET":"AC","answer_images":[],"question_images":[],"discussion":[{"poster":"mona_mansour","timestamp":"1665591840.0","upvote_count":"15","comment_id":"353808","content":"A&C...>https://aws.amazon.com/blogs/machine-learning/securing-all-amazon-sagemaker-api-calls-with-aws-privatelink/"},{"poster":"wisoxe8356","timestamp":"1701862500.0","comment_id":"736760","upvote_count":"7","content":"Selected Answer: AC\nA - VPC endpoint policy can limit the access to specific group of user/roles\nNot B - setting iam user policy can limit user access other aws service but not secure the traffic\nC - “specific” sets of instances - means security rules in instance level\nNot D - ACL (access control list) allows or denies specific inbound or outbound traffic at the subnet level.\nNot E - VPC is configured with public subnet, adding interface without limit the traffic means not secure"},{"timestamp":"1726474440.0","upvote_count":"1","poster":"loict","content":"Selected Answer: AC\nA. YES - for users\nB. NO - the users should access more than just SageMaker\nC. YES - for instances\nD. NO - ACL are not supported for SageMaker endpoint (only S3, RDS, EKS, etc.)\nE. NO - endpoint is already there","comment_id":"1009010"},{"comment_id":"967898","poster":"ccpmad","timestamp":"1722415200.0","content":"Selected Answer: AC\nA. Add a VPC endpoint policy to allow access to the IAM users: This will specify the permissions for the IAM users to access the Amazon SageMaker Service API through the VPC endpoint.\n\nC. Modify the security group on the endpoint network interface to restrict access to the instances: By configuring the security group, the specialist can control which instances are allowed to communicate with the SageMaker Service API through the VPC endpoint.","upvote_count":"1"},{"content":"Should be A & D n0?\nWe want to configure the endpoint - first to allow IAM users, second to control access to instances. \nSince Security Groups are attached to instances (not VPCs) and only allow allow rules - it should be D.","timestamp":"1701271560.0","comment_id":"730553","poster":"venimus_vidimus_vicimus","upvote_count":"3"},{"poster":"exam_prep","comment_id":"604642","upvote_count":"1","content":"Yes, A & D are correct.\nA> This will limit access to only names IAM users. It is like defining all for given principals as below:\n{\n \"Statement\": [\n {\n \"Effect\": \"Allow\",\n \"Principal\": \"*\",\n \"Action\": \"*\",\n \"Resource\": \"*\"\n }\n ]\n}\nD-> To restrict access to certain instances or IP address you define deny rule at NACL level. Here VPC Interface endpoint is in subnet (the only subnet in VPC). So modify NACL configurations at this subnet level.\nSecurity group are only for allowing the traffic not for deny so so C is incorrect.","timestamp":"1684620720.0"},{"timestamp":"1677188340.0","comment_id":"554901","poster":"yj123","upvote_count":"1","comments":[{"poster":"yj123","timestamp":"1677188340.0","upvote_count":"1","content":"i mean A, D","comment_id":"554902"}],"content":"security group cannot restrict access explicitly, C?"},{"upvote_count":"2","poster":"[Removed]","comment_id":"481906","content":"Selected Answer: AC\nSecurity Group controls instance level access. The question requires instance level access. \nThe VPC endpoint is already set up. It needs a policy attachment for particular IAM Users. I would have preferred this to be IAM Roles instead of Users, as a more appropriate question. Nevertheless, answer is A & C.","timestamp":"1668873540.0"},{"timestamp":"1667151960.0","comment_id":"427084","poster":"Madwyn","upvote_count":"1","content":"A say allow access TO the IAM users? That's wired, why to the IAM users? How do you access them?"},{"comment_id":"414284","poster":"msamory","content":"The VPC endpoint is already available waiting to be configured. No need to add one. A and E are out. \nFurthermore if an IAM endpoint is not set, a default one will be provided and you can't have more than 1 IAM policy but can modify the one that's available.\n-Restric access to only calls coming from the VPC, then modify the security group to give access to user group or roles that need access to that notebook.\nI think the answer is B and C","comments":[{"content":"A says add a VPC endpoint policy, not add an endpoint.","timestamp":"1666802340.0","upvote_count":"2","comment_id":"427083","poster":"Madwyn"}],"timestamp":"1666595940.0","upvote_count":"4"},{"timestamp":"1665291540.0","upvote_count":"2","content":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-access.html\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/notebook-interface-endpoint.html#nbi-private-link-policy\nhttps://docs.aws.amazon.com/vpc/latest/userguide/integrated-services-vpce-list.html","comment_id":"286452","poster":"cnethers"}],"exam_id":26,"question_id":20,"unix_timestamp":1612817640,"answers_community":["AC (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/44301-exam-aws-certified-machine-learning-specialty-topic-1/"}],"exam":{"name":"AWS Certified Machine Learning - Specialty","isImplemented":true,"id":26,"isMCOnly":false,"numberOfQuestions":369,"lastUpdated":"11 Apr 2025","provider":"Amazon","isBeta":false},"currentPage":4},"__N_SSP":true}