{"pageProps":{"questions":[{"id":"TF7JyythSLEjHruv8Cda","topic":"1","answer_images":[],"exam_id":29,"timestamp":"2019-08-25 17:45:00","question_id":346,"answer_ET":"AD","answer":"AD","choices":{"E":"The CMK specified in the application is using an alias.","C":"The CMK specified in the application is using the CMK KeyID instead of CMK Amazon Resource Name.","B":"The CMK specified in the application is currently in use.","A":"The CMK specified in the application does not exist.","D":"The CMK specified in the application is not enabled."},"answer_description":"","discussion":[{"upvote_count":"34","poster":"mojoa","comment_id":"9470","content":"Most of the Parameter Store failures related to CMKs are caused by the following problems:\n\n The credentials that an application is using do not have permission to perform the specified action on the CMK.\n\n To fix this error, run the application with different credentials or revise the IAM or key policy that is preventing the operation. For help with AWS KMS IAM and key policies, see Authentication and Access Control for AWS KMS.\n\n The CMK is not found.\n\n This typically happens when you use an incorrect identifier for the CMK. Find the correct identifiers for the CMK and try the command again.\n\n The CMK is not enabled. When this occurs, Parameter Store returns an InvalidKeyId exception with a detailed error message from AWS KMS. If the CMK state is Disabled, enable it. If it is Pending Import, complete the import procedure. If the key state is Pending Deletion, cancel the key deletion or use a different CMK.\n\n To find the key state of a CMK in the AWS KMS console, on the Customer managed keys or AWS managed keys page, see the Status column. To use the AWS KMS API to find the status of a CMK, use the DescribeKey operation.","timestamp":"1632783720.0","comments":[{"poster":"BillyC","comments":[{"poster":"duduga40","content":"A and D, right?","upvote_count":"4","timestamp":"1633276680.0","comment_id":"10069"}],"upvote_count":"15","content":"SO, A and D","comment_id":"9642","timestamp":"1633263300.0"}]},{"comments":[{"timestamp":"1668693780.0","upvote_count":"3","comment_id":"720506","poster":"TerrenceC","content":"More accurately, we could refer to the bottom section - Troubleshooting KMS key issues in Parameter Store."}],"content":"Answer A, D\nhttps://docs.amazonaws.cn/en_us/kms/latest/developerguide/services-parameter-store.html","timestamp":"1634053500.0","comment_id":"35226","poster":"AnNguyen","upvote_count":"13"},{"comment_id":"1155192","timestamp":"1708484280.0","upvote_count":"1","poster":"Raphaello","content":"Selected Answer: AD\nKMS key is either disabled, or does not exist.\n\nAD."},{"timestamp":"1659244260.0","upvote_count":"1","comment_id":"639910","content":"Selected Answer: AD\nA and D","poster":"ritears41"},{"poster":"MoreOps","content":"Selected Answer: AD\nA and D , similar to other questions asked","comment_id":"574966","timestamp":"1648207260.0","upvote_count":"1"},{"comment_id":"533375","poster":"Radhaghosh","timestamp":"1643244300.0","upvote_count":"1","content":"A & D is the Answer"},{"upvote_count":"1","timestamp":"1636246260.0","poster":"ShakthiVinu","content":"A and D for sure","comment_id":"397362"},{"upvote_count":"1","comment_id":"356575","poster":"Mikeclue","content":"AD it is","timestamp":"1636010520.0"},{"timestamp":"1635995340.0","comment_id":"353856","upvote_count":"1","content":"Ans: AD 100%","poster":"sanjaym"},{"upvote_count":"3","content":"A & D are correct","poster":"NANDY666","comment_id":"276188","timestamp":"1635578040.0"},{"poster":"devjava","upvote_count":"1","timestamp":"1635345780.0","comment_id":"221885","content":"Ans > A,D"},{"content":"Ans (A & D)","timestamp":"1635239940.0","poster":"AfricanCloudGuru","comment_id":"207452","upvote_count":"1"},{"comment_id":"207451","poster":"AfricanCloudGuru","upvote_count":"1","content":"Ans (A & D)","timestamp":"1635144420.0"},{"upvote_count":"4","timestamp":"1634955780.0","poster":"RB80","content":"C cant be right as you can use either KeyID or Key ARN to get Parameter, example from AWS documentation\n\n aws ssm put-parameter --name param1 --value \"secret\" --type SecureString --key-id 1234abcd-12ab-34cd-56ef-1234567890ab\n\naws ssm put-parameter --name MyParameter --value \"secret_value\" --type SecureString --tier Advanced --key-id arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab","comment_id":"109819"},{"content":"I also will choose A+D","timestamp":"1634845560.0","comment_id":"78693","poster":"ADVIT","upvote_count":"4"},{"upvote_count":"2","poster":"RaySmith","comment_id":"76021","timestamp":"1634753880.0","content":"AD correct"},{"comment_id":"70750","content":"I would like to say A & D","upvote_count":"2","timestamp":"1634287440.0","poster":"tomtom2020"},{"timestamp":"1634250660.0","comment_id":"45672","upvote_count":"2","poster":"RakeshTaninki","content":"A and D"},{"upvote_count":"2","content":"A and D","timestamp":"1634117220.0","poster":"henry76","comment_id":"37602"},{"timestamp":"1633763580.0","content":"A & D are sure correct answers.","poster":"INASR","upvote_count":"4","comment_id":"10829"},{"content":"A and D. The link is so precise as to these answers: CMK not found, CMK not enabled, and the application does not have the permission to use CMK.","upvote_count":"5","poster":"Osemk","comment_id":"10353","timestamp":"1633733220.0"},{"upvote_count":"7","timestamp":"1632760980.0","poster":"BillyC","comment_id":"8217","content":"May be A and and D"}],"question_text":"The Development team receives an error message each time the team members attempt to encrypt or decrypt a Secure String parameter from the SSM\nParameter Store by using an AWS KMS customer managed key (CMK).\nWhich CMK-related issues could be responsible? (Choose two.)","unix_timestamp":1566747900,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/4049-exam-aws-certified-security-specialty-topic-1-question-41/","answers_community":["AD (100%)"],"question_images":[]},{"id":"nicHQA45CloeVaODB7cc","answer_description":"","question_id":347,"isMC":true,"unix_timestamp":1669165260,"choices":{"D":"Configure Route 53 to export log data to Amazon CloudWatch Logs. Use CloudWatch Logs Insights to identify and delete log entries that are older than 1 year.","A":"Configure Route 53 to export log data to Amazon S3. Configure an S3 Lifecycle policy that deletes objects in the target S3 bucket that are older than 1 year.","B":"Configure Route 53 to export log data to Amazon S3. Configure an AWS Lambda function to run every hour to delete log files that are older than 1 year.","C":"Configure Route 53 to export log data to Amazon CloudWatch Logs. For the target CloudWatch Logs log group, set the retention period to 1 year."},"topic":"1","exam_id":29,"url":"https://www.examtopics.com/discussions/amazon/view/88363-exam-aws-certified-security-specialty-topic-1-question-410/","answers_community":["A (72%)","C (28%)"],"answer_ET":"A","answer":"A","question_images":[],"discussion":[{"content":"Selected Answer: A\nA is correct\nS3 most cost-effectively\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html\nChanging the retention period for logs and exporting logs to Amazon S3\n\nBy default, CloudWatch Logs stores query logs indefinitely. You can optionally specify a retention period so that CloudWatch Logs deletes logs that are older than the retention period. For more information, see Change log data retention in CloudWatch Logs in the Amazon CloudWatch User Guide.\n\nIf you want to retain log data but you don't need CloudWatch Logs tools to view and analyze the data, you can export logs to Amazon S3, which can reduce your storage costs.","poster":"tainh","comments":[{"upvote_count":"1","poster":"AzureDP900","timestamp":"1677957780.0","comment_id":"829308","content":"Agree with you. A is right"}],"comment_id":"734298","upvote_count":"11","timestamp":"1670057220.0"},{"comment_id":"897859","upvote_count":"1","content":"Answer A is the most cost effective solution for storing the DNS logs.","poster":"ITGURU51","timestamp":"1684091700.0"},{"timestamp":"1676056500.0","upvote_count":"3","poster":"swrp4595","content":"Selected Answer: A\nOption C is incorrect because it is not the most cost-effective solution. Configuring Route 53 to export log data to Amazon CloudWatch Logs and setting the retention period to 1 year will result in charges for storing the logs for the full year, even if the logs are no longer needed. Additionally, there is a charge for the number of ingested log events, and this can add up over time, leading to higher costs. In comparison, options A and B provide a more cost-effective solution by automatically deleting logs that are older than 1 year, reducing the amount of data stored and the associated charges.","comment_id":"804668"},{"poster":"milofficial","timestamp":"1676006040.0","content":"Selected Answer: A\ngeneral wise words: key word durable is almost always S3\nS3 is more cost-effectively than CloudWatch. S3 Lifecycle policies for automatic deletion\n\nA 100%","comment_id":"803985","upvote_count":"2"},{"comment_id":"799440","content":"Selected Answer: A\nTo all those saying C, Every AWS exam question I have ever encountered that mentions cost Expects you to know what the cheapest option is, no other answer will be accepted.\nThis makes me say A.","timestamp":"1675660920.0","poster":"roguecloud","upvote_count":"2"},{"comment_id":"796011","poster":"Anshnow","timestamp":"1675339020.0","content":"Selected Answer: A\nA,\n\nIf you want to retain log data but you don't need CloudWatch Logs tools to view and analyze the data, you can export logs to Amazon S3, which can reduce your storage costs\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html","upvote_count":"2"},{"upvote_count":"4","content":"Selected Answer: A\nIt is A.\n\nCloudWatch does cost 10+ times more than s3\nYou can export dns query logs to either s3 or cloudwatch\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html#query-logs-changing-retention-period","timestamp":"1673881620.0","poster":"selim507","comment_id":"777836"},{"comment_id":"765054","upvote_count":"3","poster":"awsec2","timestamp":"1672779960.0","content":"i think A"},{"upvote_count":"2","comment_id":"764840","poster":"Smartphone","timestamp":"1672761180.0","content":"Answer: A\nIf you want to retain log data but you don't need CloudWatch Logs tools to view and analyze the data, you can export logs to Amazon S3, which can reduce your storage costs. For more information, see Exporting log data to Amazon S3."},{"upvote_count":"3","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html","timestamp":"1672715880.0","poster":"Wilson_S","comment_id":"764203"},{"comments":[{"comment_id":"766552","poster":"secdaddy","content":"Not sure. It looks like that feature only logs internal queries, not public queries.\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver-query-logs.html\n\nIn the article you post, it says \"if it lives in your Amazon VPC and makes a DNS query, then this feature will log it\"","upvote_count":"1","timestamp":"1672917300.0"}],"upvote_count":"1","timestamp":"1672205640.0","content":"DNS query logs can be send directly to S3:\nhttps://aws.amazon.com/blogs/aws/log-your-vpc-dns-queries-with-route-53-resolver-query-logs/","poster":"f9048f93rf","comment_id":"759387"},{"comment_id":"758972","upvote_count":"3","timestamp":"1672170120.0","comments":[{"content":"CloudWatch does cost 10+ times more than s3, so I go with A","upvote_count":"1","timestamp":"1673881440.0","poster":"selim507","comment_id":"777830"}],"content":"Selected Answer: C\nRetention period for cloudwatch logs can be till 10 years.. this seems to be the right option","poster":"must_be_rohit"},{"comment_id":"754927","timestamp":"1671891240.0","content":"Selected Answer: C\nsend dns query logs to cloudwatchlog and set retention period to 1year.","poster":"Fyssy","upvote_count":"3"},{"comments":[{"timestamp":"1672937640.0","content":"Answer is C, Its a tricky question. I agree with U","poster":"Leonardocp33","upvote_count":"1","comment_id":"766848"},{"upvote_count":"1","content":"I know C is a possibility, but this link has me feeling A. https://docs.amazonaws.cn/en_us/Route53/latest/DeveloperGuide/resolver-query-logs-choosing-target-resource.html","comments":[{"timestamp":"1672014120.0","poster":"Wilson_S","upvote_count":"1","content":"Sorry, that link is for resolver query logs, but the question does specify “public DNS query logging.” Its a tricky question as the it wants a cost effective solution but i don’t see how you can get to S3 without it going to Cloudwatch Logs first.","comment_id":"756101"}],"comment_id":"756098","poster":"Wilson_S","timestamp":"1672013700.0"}],"poster":"NOZOMI","upvote_count":"3","timestamp":"1671287940.0","comment_id":"748126","content":"Selected Answer: C\nQuery logs cannot be exported directly to s3.\nI think A is correct for cost efficiency because it can be exported to s3 with the logs function.\nBut if the answer is A, anything is possible"},{"content":"Selected Answer: A\nIf you want to retain log data but you don't need CloudWatch Logs tools to view and analyze the data, you can export logs to Amazon S3, which can reduce your storage costs. \n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html","timestamp":"1669786200.0","comment_id":"731132","upvote_count":"3","poster":"kerar"},{"upvote_count":"3","poster":"tryks","content":"Selected Answer: A\nA > S3 cheaper than cloud watch","timestamp":"1669292100.0","comment_id":"725817"},{"comment_id":"725314","upvote_count":"3","poster":"Isaias","content":"Selected Answer: A\nI go with A, s3 provides a highly durable storage and MOST cost-effectively \nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/S3Export.html","timestamp":"1669226460.0"},{"comments":[{"comment_id":"748314","upvote_count":"3","poster":"Blueocean","timestamp":"1671304200.0","content":"This is not cost effective. Question specifically talks about the solution being cost effective. S3 is the most cost effective of the options. Answer is A."}],"poster":"AdamWest","upvote_count":"1","content":"Selected Answer: C\nC - Route 53 dns is written to route 53. Using the log group set retention to 1 year. (two links)\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Working-with-log-groups-and-streams.html#SettingLogRetention","timestamp":"1669165260.0","comment_id":"724788"}],"question_text":"A company recently began using Amazon Route 53 as its DNS provider. The company must log public DNS queries that Route 53 receives. The company has activated Route 53 public DNS query logging. The queries must be stored in a highly durable storage solution that deletes logs that are older than 1 year.\n\nWhich solution will meet these requirements MOST cost-effectively?","answer_images":[],"timestamp":"2022-11-23 02:01:00"},{"id":"3XT2GpLV72ESxNyk1JPS","unix_timestamp":1669165860,"answers_community":["D (100%)"],"answer_images":[],"question_text":"A company has configured a gateway VPC endpoint in a VPC. Only Amazon EC2 instances that reside in a single subnet in the VPC can use the endpoint. The company has modified the route table for this single subnet to route traffic to Amazon S3 through the gateway VPC endpoint. The VPC provides internet access through an internet gateway.\n\nA security engineer attempts to use instance profile credentials from an EC2 instance to retrieve an object from the S3 bucket, but the attempt fails. The security engineer verifies that the EC2 instance has an IAM instance profile with the correct permissions to access the S3 bucket and to retrieve objects. The security engineer also verifies that the S3 bucket policy is allowing access properly. Additionally, the security engineer verifies that the EC2 instance’s security group and the subnet’s network ACLs allow the communication.\n\nWhat else should the security engineer check to determine why the request from the EC2 instance is failing?","choices":{"B":"Verify that the VPC endpoint’s security group does not have an explicit inbound deny rule for the EC2 instance.","D":"Verify that the VPC endpoint policy is allowing access to Amazon S3.","C":"Verify that the internet gateway is allowing traffic to Amazon S3.","A":"Verify that the EC2 instance’s security group does not have an implicit inbound deny rule for Amazon S3."},"discussion":[{"upvote_count":"1","poster":"Toptip","timestamp":"1685892240.0","content":"Selected Answer: D\nD for me","comment_id":"914771"},{"timestamp":"1677958020.0","content":"D is right","comment_id":"829313","poster":"AzureDP900","upvote_count":"1"},{"poster":"Leonardocp33","timestamp":"1672937940.0","content":"Selected Answer: D\nD is correct","upvote_count":"1","comment_id":"766855"},{"timestamp":"1670117580.0","upvote_count":"2","content":"Selected Answer: D\nD is correct","comment_id":"734783","poster":"tainh"},{"content":"Selected Answer: D\nReview the endpoint policy. Check if the policy blocks access to the S3 bucket or to the AWS Identity and Access Management (IAM) user affected by the connectivity issues. If necessary, edit the policy to enable access for the S3 bucket or IAM user\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/connect-s3-vpc-endpoint/","poster":"kerar","timestamp":"1669786800.0","comment_id":"731137","upvote_count":"3"},{"comment_id":"724795","timestamp":"1669165860.0","poster":"AdamWest","upvote_count":"4","content":"Selected Answer: D\nD- Its possible the instance profile creds are not permitted in the VPC endpoint policy. All endpoints come standard with a permit any any. But they can be changed\nDefault Enpoint policy:\n\"Effect\": \"Allow\",\n \"Principal\": \"*\",\n \"Action\": \"*\",\n \"Resource\": \"*\"\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-access.html"}],"topic":"1","question_images":[],"question_id":348,"answer_ET":"D","isMC":true,"timestamp":"2022-11-23 02:11:00","answer":"D","exam_id":29,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/88364-exam-aws-certified-security-specialty-topic-1-question-411/"},{"id":"PXozk62tElOXwENVnxzH","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/88365-exam-aws-certified-security-specialty-topic-1-question-412/","answer_images":[],"question_id":349,"topic":"1","choices":{"F":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule for Security Hub findings of high severity. Configure the rule to publish a message to the queue.","A":"Enable AWS Security Hub in the AWS account.","D":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Subscribe the security team’s email distribution list to the queue.","E":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule for GuardDuty findings of high severity. Configure the rule to publish a message to the topic.","C":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team’s email distribution list to the topic.","B":"Enable Amazon GuardDuty in the AWS account."},"answer_description":"","question_text":"A company has a single AWS account and uses an Amazon EC2 instance to test application code. The company recently discovered that the instance was compromised. The instance was serving up malware. The analysis of the instance showed that the instance was compromised 35 days ago.\n\nA security engineer must implement a continuous monitoring solution that automatically notifies the company’s security team about compromised instances through an email distribution list for high severity findings. The security engineer must implement the solution as soon as possible.\n\nWhich combination of steps should the security engineer take to meet these requirements? (Choose three.)","isMC":true,"timestamp":"2022-11-23 02:14:00","exam_id":29,"answers_community":["BCE (100%)"],"unix_timestamp":1669166040,"answer_ET":"BCE","answer":"BCE","discussion":[{"poster":"kerar","content":"Selected Answer: BCE\nYou can use CloudWatch Events with GuardDuty to set up automated finding alerts by sending GuardDuty finding events to a messaging hub to help increase the visibility of GuardDuty findings. This topic shows you how to send findings alerts to email, Slack, or Amazon Chime by setting up an SNS topic and then connecting that topic to an CloudWatch Events event rule.\n\nhttps://docs.aws.amazon.com/guardduty/latest/ug/guardduty_findings_cloudwatch.html","upvote_count":"9","timestamp":"1669787460.0","comment_id":"731148"},{"timestamp":"1709146260.0","upvote_count":"1","comment_id":"1161921","content":"Selected Answer: BCE\nBCE are the correct answers.\nGuardDuty >> EventBridge >> SNS","poster":"Raphaello"},{"upvote_count":"1","content":"Selected Answer: BCE\nhttps://docs.aws.amazon.com/guardduty/latest/ug/guardduty_settingup.html#setup-sns","poster":"kejam","timestamp":"1699939800.0","comment_id":"1070015"},{"upvote_count":"1","comment_id":"914776","timestamp":"1685892420.0","content":"Selected Answer: BCE\nBCE for me too","poster":"Toptip"},{"comment_id":"829314","content":"BCE is right","timestamp":"1677958140.0","poster":"AzureDP900","upvote_count":"1"},{"content":"Selected Answer: BCE\neasy one","poster":"milofficial","timestamp":"1676035020.0","comment_id":"804338","upvote_count":"3"},{"timestamp":"1672938960.0","poster":"Leonardocp33","content":"Selected Answer: BCE\nBCE, I try and it works.","comment_id":"766872","upvote_count":"3"},{"content":"BCE - all connected","poster":"D2","timestamp":"1669433040.0","comment_id":"727235","upvote_count":"1"},{"poster":"AdamWest","comment_id":"724797","timestamp":"1669166040.0","content":"Selected Answer: BCE\nBCE - Is correct.","upvote_count":"3"}]},{"id":"dtSqqxTDMwFT2VNGifBd","answers_community":["D (84%)","Other"],"topic":"1","answer_description":"","exam_id":29,"isMC":true,"question_text":"An IAM user receives an Access Denied message when the user attempts to access objects in an Amazon S3 bucket. The user and the S3 bucket are in the same AWS account. The S3 bucket is configured to use server-side encryption with AWS KMS keys (SSE-KMS) to encrypt all of its objects at rest by using a customer managed key from the same AWS account. The S3 bucket has no bucket policy defined. The IAM user has been granted permissions through an IAM policy that allows the kms:Decrypt permission to the customer managed key. The IAM policy also allows the s3:List* and s3:Get* permissions for the S3 bucket and its objects.\n\nWhich of the following is a possible reason that the IAM user cannot access the objects in the S3 bucket?","choices":{"B":"The S3 bucket has been changed to use the AWS managed key to encrypt objects at rest.","D":"The KMS key policy has been edited to remove the ability for the AWS account to have full access to the key.","A":"The IAM policy needs to allow the kms:DescribeKey permission.","C":"An S3 bucket policy needs to be added to allow the IAM user to access the objects."},"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/88366-exam-aws-certified-security-specialty-topic-1-question-413/","discussion":[{"content":"Selected Answer: D\nAgree with D https://aws.amazon.com/premiumsupport/knowledge-center/s3-bucket-access-default-encryption/","timestamp":"1670794740.0","upvote_count":"7","poster":"Balki","comments":[{"content":"yes, It is D","comment_id":"829319","upvote_count":"2","timestamp":"1677958260.0","poster":"AzureDP900"}],"comment_id":"742118"},{"poster":"kejam","upvote_count":"1","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/kms/latest/developerguide/key-policy-default.html#key-policy-default-allow-root-enable-iam","comment_id":"1070018","timestamp":"1699940040.0"},{"comment_id":"862630","poster":"task_7","timestamp":"1680744600.0","upvote_count":"1","content":"Selected Answer: A\nThe minimum permissions required to download a file from an S3 bucket encrypted with SSE-KMS CMK are:\n\ns3:GetObject - This permission allows you to download the object from the S3 bucket.\n\nkms:Decrypt - This permission allows you to decrypt the data key that is used to encrypt the object.\n\nkms:DescribeKey - This permission allows you to retrieve metadata about the CMK, such as the key policy and key state","comments":[{"upvote_count":"2","content":"My bad look like Decrypt is good enough","comment_id":"862667","timestamp":"1680750900.0","poster":"task_7"}]},{"comment_id":"739219","upvote_count":"2","poster":"piter8111","content":"Selected Answer: D\nD. The possible reason for access denied is not having correct permission in KMS resource policy.","timestamp":"1670513340.0"},{"upvote_count":"3","content":"Selected Answer: D\nit has a iam policy to grant the s3 so it does not need the bucket policy because it says \"The user and the S3 bucket are in the same AWS account.\" , I think the problem is with the key policy so a select D, \nhttps://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html\nNo AWS principal, including the account root user or key creator, has any permissions to a KMS key unless they are explicitly allowed, and never denied, in a key policy, IAM policy, or grant.","timestamp":"1670175540.0","comment_id":"735304","poster":"Isaias"},{"timestamp":"1670119500.0","poster":"tainh","comment_id":"734795","content":"Selected Answer: D\ni think D is correct\nS3 use default policy, so resouce owner can access bucket (same AWS Account)\nhttps://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-policy.html\nMay be KMS key policy don't grant IAM user permission to access KMS\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-bucket-access-default-encryption/","upvote_count":"3"},{"timestamp":"1669972800.0","poster":"Sreeprasad","content":"D. The possible reason for access denied is not having correct permission in KMS resource policy. C is not the answer. Bucket and IAM user is in the same account and iam policy already granted permissions","comment_id":"733600","upvote_count":"1"},{"poster":"kerar","comment_id":"731150","upvote_count":"1","comments":[{"comment_id":"733386","timestamp":"1669950900.0","poster":"speedster","content":"both are in same account in this question","upvote_count":"1"},{"poster":"Isaias","comment_id":"733100","upvote_count":"1","timestamp":"1669928760.0","content":"It says \"The user and the S3 bucket are in the same AWS account.\" I think the problem is with the key policy so a select D, \nhttps://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html\nNo AWS principal, including the account root user or key creator, has any permissions to a KMS key unless they are explicitly allowed, and never denied, in a key policy, IAM policy, or grant."}],"content":"Selected Answer: C\nThe bucket policy in Account A must grant access to Account B.\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cross-account-access-denied-error-s3/","timestamp":"1669787700.0"},{"timestamp":"1669166220.0","comment_id":"724799","poster":"AdamWest","content":"Selected Answer: C\nC - By default, all Amazon S3 buckets and objects are private. Only the resource owner which is the AWS account that created the bucket can access that bucket. The resource owner can, however, choose to grant access permissions to other resources and users. One way to do this is to write an access policy.","upvote_count":"1"}],"answer":"D","question_id":350,"unix_timestamp":1669166220,"answer_ET":"D","question_images":[],"timestamp":"2022-11-23 02:17:00"}],"exam":{"isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":509,"name":"AWS Certified Security - Specialty","isBeta":false,"isMCOnly":false,"provider":"Amazon","id":29},"currentPage":70},"__N_SSP":true}