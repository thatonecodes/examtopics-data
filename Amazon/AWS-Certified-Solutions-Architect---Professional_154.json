{"pageProps":{"questions":[{"id":"a32VoSPfmViP0Q863jfh","answer_images":[],"exam_id":32,"question_id":766,"topic":"1","timestamp":"2021-08-20 19:37:00","isMC":true,"unix_timestamp":1629481020,"choices":{"C":"Set up AWS Single Sign-On and attach AWS accounts. Create permission sets with policies to restrict access to non-European Regions. Create IAM users and IAM groups in each account.","B":"Enable AWS Organizations, attach the AWS accounts, and create OUs for European Regions and non-European Regions. Create SCPs to limit access to non-European Regions and attach the policies to the OUs.","D":"Enable AWS Organizations, attach the AWS accounts, and create OUs for European Regions and non-European Regions. Create permission sets with policies to restrict access to non-European Regions. Create IAM users and IAM groups in the primary account.","A":"Create IAM users and IAM groups in each account. Create IAM policies to limit access to non-European Regions. Attach the IAM policies to the IAM groups."},"question_images":[],"answer_ET":"B","answer_description":"","question_text":"A large company in Europe plans to migrate its applications to the AWS Cloud. The company uses multiple AWS accounts for various business groups. A data privacy law requires the company to restrict developers' access to AWS European Regions only.\nWhat should the solutions architect do to meet this requirement with the LEAST amount of management overhead?","answers_community":["B (80%)","C (20%)"],"answer":"B","discussion":[{"timestamp":"1633270800.0","content":"B - \"This policy uses the Deny effect to deny access to all requests for operations that don't target one of the two approved regions (eu-central-1 and eu-west-1).\" https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_general.html#example-scp-deny-region","comment_id":"429040","poster":"mericov","upvote_count":"19"},{"poster":"SureNot","upvote_count":"2","comment_id":"708738","timestamp":"1667253120.0","content":"Selected Answer: B\nB answer B is little bit weird. It's enough to have only one OU and attact SCP to it.\nBut having two two OUs with the same SCP is still ok."},{"poster":"tomosabc1","content":"Selected Answer: C\nC is correct.\n\nB is wrong, because each account(meaning each business unit) has developers, meaning there are some IAM users in each account who has access to AWS European Regions only. There is no point to create OUs for European Regions and non-European Regions. We can simply create only one OU and attach SCP to that OU or root OU.","comments":[{"upvote_count":"1","poster":"tomosabc1","timestamp":"1666353960.0","content":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_general.html#example-scp-deny-region","comment_id":"700835"}],"comment_id":"700828","timestamp":"1666353120.0","upvote_count":"1"},{"content":"Selected Answer: B\n+1 for BBB","upvote_count":"2","timestamp":"1666010340.0","comment_id":"697402","poster":"Blair77"},{"comment_id":"515809","poster":"Ni_yot","upvote_count":"2","content":"B defo. Use service control policies to restrict access to certain accounts","timestamp":"1641218220.0"},{"upvote_count":"1","timestamp":"1640943780.0","content":"B is correct.","poster":"cldy","comment_id":"514002"},{"upvote_count":"1","content":"hope i can have this question in my exam","poster":"acloudguru","timestamp":"1638271320.0","comment_id":"490631"},{"content":"B is correct","comment_id":"470172","poster":"andypham","timestamp":"1636095780.0","upvote_count":"1"},{"content":"BBBBBBBBBBBB","timestamp":"1635250140.0","poster":"Liongeek","upvote_count":"1","comment_id":"455597"},{"upvote_count":"1","content":"It's B","comment_id":"449356","timestamp":"1635139680.0","poster":"andylogan"},{"upvote_count":"1","timestamp":"1634718780.0","content":"How about non-developers if B is correct? SCP will restrict them as well. It has to be A.","comment_id":"446658","comments":[{"upvote_count":"1","timestamp":"1643304420.0","poster":"AMKazi","content":"you can restrict which groups you want to deny access in the policy.\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html","comment_id":"533972"}],"poster":"johnnsmith"},{"upvote_count":"4","poster":"tgv","content":"BBB\n---","comment_id":"437302","timestamp":"1634264100.0"},{"timestamp":"1634214900.0","comment_id":"429176","content":"would go for B","poster":"denccc","upvote_count":"4"},{"comment_id":"428306","upvote_count":"2","content":"I think it is B","timestamp":"1633132560.0","poster":"pkboy78"}],"url":"https://www.examtopics.com/discussions/amazon/view/60089-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"92pUDa125sUVlT3LG20n","discussion":[{"comment_id":"431867","content":"Ans: C\nReason: AWS Application Discovery Service collects and presents configuration, usage, and behavior data from your servers to help you better understand your workloads.\nLink: https://aws.amazon.com/application-discovery/","timestamp":"1633973580.0","comments":[{"comment_id":"433816","content":"answer C: it is the correct because AWS Application Discovery Service is used to collect data using Discovery Connector for VMWare or Discovery Agent for VMware, Hyper-V or Physical Server","timestamp":"1634323260.0","poster":"sergioandreslq","upvote_count":"4"}],"poster":"Shanmahi","upvote_count":"15"},{"timestamp":"1665509280.0","poster":"AwsBRFan","upvote_count":"1","comment_id":"692296","content":"Selected Answer: C\nI would to say C correct, but this seems a old question. D is wrong cuz you dont need register the servers, the discover connector brings this data to migration Hub.\n\nReference:\nhttps://www.youtube.com/watch?v=aq6ohCf6PBo\nhttps://docs.aws.amazon.com/application-discovery/latest/userguide/discovery-connector.html\n\n\"We recommended that all customers currently using Discovery Connector transition to the new Agentless Collector. Customer's currently using Discovery Connector can continue to do so until Aug 31, 2023. After this date, data sent to AWS Application Discovery Service by Discovery Connector will not be processed. Going forward, Application Discovery Service Agentless Collector is the supported discovery tool for agentless data collection by AWS Application Discovery Service. \""},{"content":"The Discovery connector VM is connected to vCenter not on all VMs but for the lack of better options it would be C","timestamp":"1664642580.0","comment_id":"684352","poster":"dcdcdc3","upvote_count":"2"},{"upvote_count":"1","poster":"cannottellname","timestamp":"1645737420.0","comment_id":"555569","content":"Q: What data does the AWS Application Discovery Agentless Connector capture?\n\nThe AWS Application Discovery Agentless Connector is delivered as an Open Virtual Appliance (OVA) package that can be deployed to a VMware host. Once configured with credentials to connect to vCenter, the Discovery Connector collects VM inventory, configuration, and performance history such as CPU, memory, and disk usage and uploads it to Application Discovery Service data store."},{"upvote_count":"1","content":"C: Application Discovery Service.","timestamp":"1640940660.0","comment_id":"513962","poster":"cldy"},{"timestamp":"1639007760.0","comment_id":"497248","upvote_count":"1","content":"C is right!","poster":"AzureDP900"},{"timestamp":"1638258780.0","content":"C, EASY ONE ,HOPE i can have it in my exam","upvote_count":"1","poster":"acloudguru","comment_id":"490503"},{"content":"C of cause.","upvote_count":"1","poster":"Ni_yot","timestamp":"1638183960.0","comment_id":"489816"},{"poster":"Liongeek","content":"CCCCCCCCCCCCC","timestamp":"1636046220.0","comment_id":"455598","upvote_count":"1"},{"content":"It's C","timestamp":"1635003900.0","upvote_count":"1","comment_id":"451168","poster":"andylogan"},{"timestamp":"1634952120.0","comment_id":"449381","upvote_count":"1","poster":"andylogan","content":"It's C"},{"upvote_count":"1","comment_id":"437305","content":"CCC\n---","poster":"tgv","timestamp":"1634684160.0"},{"upvote_count":"1","timestamp":"1632550200.0","comment_id":"430302","comments":[{"upvote_count":"5","timestamp":"1633161900.0","content":"Sorry, Answer is C, Migration hub uses Application Discovery to collect the data","comment_id":"430306","poster":"zolthar_z"}],"poster":"zolthar_z","content":"Answer is D, Application discovery is oriented to map resources from on-premise to AWS Cloud, Migration hub helps to create migration plans"},{"content":"A - Deploy SMS connector, then with Server Migration Service, you have automated, incremental and scheduled migrations towards AMI images which can be used to deploy EC2 instances. AWS SMS migrates VMware vSphere, Hyper-V and Azure VMs.","comment_id":"430090","poster":"mericov","timestamp":"1632283500.0","comments":[{"poster":"vjawscert","upvote_count":"1","timestamp":"1634326080.0","content":"They are just in the planning phase so no SMS needed here. My vote would be - C (that is the close one even not accurate as we can collect information with agentless connectors)","comment_id":"434242"},{"poster":"sergioandreslq","upvote_count":"1","comment_id":"433815","content":"A: it is incorrect because SMS is used to migrate servers not to collect data to plan the migration, in this case, the issue is: \"What should the solutions architect do to GATHER!!! the required information. \nSo, answer C is the correct because AWS Application Discovery Service is used to collect data using Discovery Connector for VMWare or Discovery Agent for VMware, Hyper-V or Physical Server","timestamp":"1634178840.0"}],"upvote_count":"3"},{"upvote_count":"2","poster":"Rmukh","content":"No it is C","comment_id":"429359","timestamp":"1632246720.0"},{"timestamp":"1632246420.0","poster":"pkboy78","content":"I think it is D","upvote_count":"1","comments":[{"content":"Yes I think C is correct","upvote_count":"2","comment_id":"431065","timestamp":"1633890240.0","poster":"pkboy78"}],"comment_id":"428305"}],"answer":"C","answers_community":["C (100%)"],"answer_description":"","unix_timestamp":1629480960,"question_id":767,"exam_id":32,"question_text":"A company has several applications running in an on-premises data center. The data center runs a mix of Windows and Linux VMs managed by VMware vCenter.\nA solutions architect needs to create a plan to migrate the applications to AWS. However, the solutions architect discovers that the document for the applications is not up to date and that there are no complete infrastructure diagrams. The company's developers lack time to discuss their applications and current usage with the solutions architect.\nWhat should the solutions architect do to gather the required information?","topic":"1","choices":{"C":"Install the AWS Application Discovery Service on each of the VMs to collect the configuration and utilization data.","D":"Register the on-premises VMs with the AWS Migration Hub to collect configuration and utilization data.","A":"Deploy the AWS Server Migration Service (AWS SMS) connector using the OVA image on the VMware cluster to collect configuration and utilization data from the VMs.","B":"Use the AWS Migration Portfolio Assessment (MPA) tool to connect to each of the VMs to collect the configuration and utilization data."},"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/60088-exam-aws-certified-solutions-architect-professional-topic-1/","isMC":true,"question_images":[],"timestamp":"2021-08-20 19:36:00","answer_images":[]},{"id":"77ABitFGB0uakCegKhZN","answer_description":"","choices":{"B":"From the management account, share the transit gateway with member accounts by using an AWS Organizations SCP.","D":"Launch an AWS CloudFormation stack set from the management account that automatically creates a new VPC and a peering transit gateway attachment in a member account. Share the attachment with the transit gateway in the management account by using a transit gateway service-linked role.","A":"From the management account, share the transit gateway with member accounts by using AWS Resource Access Manager.","C":"Launch an AWS CloudFormation stack set from the management account that automatically creates a new VPC and a VPC transit gateway attachment in a member account. Associate the attachment with the transit gateway in the management account by using the transit gateway ID.","E":"From the management account, share the transit gateway with member accounts by using AWS Service Catalog."},"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/69467-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"2022-01-04 18:48:00","topic":"1","question_images":[],"answer":"AC","unix_timestamp":1641318480,"question_text":"A company has 50 AWS accounts that are members of an organization in AWS Organizations. Each account contains multiple VPCs. The company wants to use\nAWS Transit Gateway to establish connectivity between the VPCs in each member account. Each time a new member account is created, the company wants to automate the process of creating a new VPC and a transit gateway attachment.\nWhich combination of steps will meet these requirements? (Choose two.)","answers_community":["AC (100%)"],"question_id":768,"isMC":true,"exam_id":32,"discussion":[{"poster":"AndySH","timestamp":"1641318480.0","comment_id":"516872","content":"A and C","upvote_count":"12"},{"timestamp":"1668070260.0","content":"Selected Answer: AC\nProcess of elimination.\n\nB - no - SCP's are not really for sharing resources.\n\nD - No - \"peering transit gateway attachment\" - Meant to really be peering transit gateway to transit gateway.\n\nE - No - Sure, you can configure service catalog via account factory, however that leaves the part out of automating the gateway attachment process (potentially)\n\n\n\nhttps://controltower.aws-management.tools/networking/tgw/tgw-simple/","poster":"janvandermerwer","comment_id":"715060","upvote_count":"2"},{"timestamp":"1664904240.0","upvote_count":"3","poster":"Ell89","comment_id":"686350","content":"Selected Answer: AC\nA & C\nyou need to share the TGW via the RAM.\nthe VPC TGW attachment needs to be associated with the TGW."}],"answer_ET":"AC"},{"id":"fbDDYXsThqmlLsJYHvPP","timestamp":"2021-08-20 20:02:00","question_text":"A scientific company needs to process text and image data from an Amazon S3 bucket. The data is collected from several radar stations during a live, time-critical phase of a deep space mission. The radar stations upload the data to the source S3 bucket. The data is prefixed by radar station identification number.\nThe company created a destination S3 bucket in a second account. Data must be copied from the source S3 bucket to the destination S3 bucket to meet a compliance objective. The replication occurs through the use of an S3 replication rule to cover all objects in the source S3 bucket.\nOne specific radar station is identified as having the most accurate data. Data replication at this radar station must be monitored for completion within 30 minutes after the radar station uploads the objects to the source S3 bucket.\nWhat should a solutions architect do to meet these requirements?","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/60091-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1629482520,"topic":"1","question_images":[],"answer":"D","question_id":769,"answer_images":[],"exam_id":32,"isMC":true,"answers_community":["D (100%)"],"discussion":[{"upvote_count":"11","poster":"nl11121","content":"Answer is D - https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-time-control.html","comment_id":"429324","timestamp":"1633023720.0"},{"upvote_count":"5","content":"D - S3 Replication Time Control is designed to replicate 99.99% of objects within 15 minutes after upload, with the majority of those new objects replicated in seconds.","timestamp":"1633388460.0","comment_id":"433105","poster":"Jupi"},{"upvote_count":"1","comment_id":"939145","content":"Selected Answer: D\nKey: \"S3 Replication Time Control\"\n\"S3 Replication Time Control is designed to replicate 99.99% of objects within 15 minutes after upload, with the majority of those new objects replicated in seconds\"\n\nhttps://aws.amazon.com/about-aws/whats-new/2019/11/amazon-s3-replication-time-control-for-predictable-replication-time-backed-by-sla","poster":"SkyZeroZx","timestamp":"1688134860.0"},{"poster":"[Removed]","upvote_count":"1","timestamp":"1656408900.0","comment_id":"623878","content":"Selected Answer: D\nKey: \"S3 Replication Time Control\"\n\"S3 Replication Time Control is designed to replicate 99.99% of objects within 15 minutes after upload, with the majority of those new objects replicated in seconds\"\n\nhttps://aws.amazon.com/about-aws/whats-new/2019/11/amazon-s3-replication-time-control-for-predictable-replication-time-backed-by-sla"},{"poster":"kangtamo","timestamp":"1656294300.0","upvote_count":"1","content":"Selected Answer: D\nAgree with D.","comment_id":"622878"},{"comment_id":"538183","content":"D seems to work. https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-time-control.html. not sure how A can help here. Once you setup data sync there is now to ensure it completes on time.","upvote_count":"1","timestamp":"1643747280.0","poster":"Ni_yot"},{"upvote_count":"1","content":"Answer is A\nDataSync is designed for this kind of job.\n\nhttps://cloudcompiled.com/tutorials/aws-datasync-transfer-data/\nhttps://aws.amazon.com/blogs/storage/how-to-use-aws-datasync-to-migrate-data-between-amazon-s3-buckets/","comment_id":"530442","poster":"HellGate","timestamp":"1642933380.0"},{"timestamp":"1640614920.0","upvote_count":"1","content":"D only talks about precise data expedite transfer. How about rest of the data? No options talk about it. So i am little confused.","poster":"Gaurav_GGG","comment_id":"510371"},{"comment_id":"497251","content":"It is D","timestamp":"1639008120.0","upvote_count":"1","poster":"AzureDP900"},{"comment_id":"449398","upvote_count":"1","timestamp":"1634724060.0","content":"It's D","poster":"andylogan"},{"upvote_count":"1","poster":"tgv","comment_id":"435560","timestamp":"1634509920.0","content":"DDD\n---"},{"timestamp":"1633618740.0","upvote_count":"1","poster":"blackgamer","content":"Yes, it is D.","comment_id":"434705"},{"upvote_count":"2","comment_id":"428323","poster":"pkboy78","timestamp":"1632949620.0","content":"I think it is D"}],"answer_description":"","choices":{"C":"Enable Amazon S3 Transfer Acceleration on the source S3 bucket, and configure the radar station with the most accurate data to use the new endpoint. Monitor the S3 destination bucket's TotalRequestLatency metric. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an alert if this status changes.","D":"Create a new S3 replication rule on the source S3 bucket that filters for the keys that use the prefix of the radar station with the most accurate data. Enable S3 Replication Time Control (S3 RTC). Monitor the maximum replication time to the destination. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an alert when the time exceeds the desired threshold.","B":"In the second account, create another S3 bucket to receive data from the radar station with the most accurate data. Set up a new replication rule for this new S3 bucket to separate the replication from the other radar stations. Monitor the maximum replication time to the destination. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an alert when the time exceeds the desired threshold.","A":"Set up an AWS DataSync agent to replicate the prefixed data from the source S3 bucket to the destination S3 bucket. Select to use all available bandwidth on the task, and monitor the task to ensure that it is in the TRANSFERRING status. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an alert if this status changes."}},{"id":"idJrQldA1qVKBcydqgUV","exam_id":32,"question_id":770,"answer_images":[],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/60092-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["B (100%)"],"question_text":"A company is serving files to its customer through an SFTP server that is accessible over the Internet. The SFTP server is running on a single Amazon EC2 instance with an Elastic IP address attached. Customers connect to the SFTP server through its Elastic IP address and use SSH for authentication. The EC2 instance also has an attached security group that allows access from all customer IP addresses.\nA solutions architect must implement a solution to improve availability, minimize the complexity of infrastructure management, and minimize the disruption to customers who access files. The solution must not change the way customers connect.\nWhich solution will meet these requirements?","answer_ET":"B","topic":"1","isMC":true,"answer_description":"","unix_timestamp":1629483420,"choices":{"B":"Disassociate the Elastic IP address from the EC2 instance. Create an Amazon S3 bucket to be used for SFTP file hosting. Create an AWS Transfer Family server. Configure the Transfer Family server with a VPC-hosted, Internet-facing endpoint. Associate the SFTP Elastic IP address with the new endpoint. Attach the security group with customer IP addresses to the new endpoint. Point the Transfer Family server to the S3 bucket. Sync all files from the SFTP server to the S3 bucket.","D":"Disassociate the Elastic IP address from the EC2 instance. Create a multi-attach Amazon Elastic Block Store (Amazon EBS) volume to be used for SFTP file hosting. Create a Network Load Balancer (NLB) with the Elastic IP address attached. Create an Auto Scaling group with EC2 instances that run an SFTP server. Define in the Auto Scaling group that instances that are launched should attach the new multi-attach EBS volume. Configure the Auto Scaling group to automatically add instances behind the NLB. Configure the Auto Scaling group to use the security group that allows customer IP addresses for the EC2 instances that the Auto Scaling group launches. Sync all files from the SFTP server to the new multi-attach EBS volume.","A":"Disassociate the Elastic IP address from the EC2 instance. Create an Amazon S3 bucket to be used for SFTP file hosting. Create an AWS Transfer Family server. Configure the Transfer Family server with a publicly accessible endpoint. Associate the SFTP Elastic IP address with the new endpoint. Point the Transfer Family server to the S3 bucket. Sync all files from the SFTP server to the S3 bucket.","C":"Disassociate the Elastic IP address from the EC2 instance. Create a new Amazon Elastic File System (Amazon EFS) file system to be used for SFTP file hosting. Create an AWS Fargate task definition to run an SFTP server. Specify the EFS file system as a mount in the task definition. Create a Fargate service by using the task definition, and place a Network Load Balancer (NLB) in front of the service. When configuring the service, attach the security group with customer IP addresses to the tasks that run the SFTP server. Associate the Elastic IP address with the NLB. Sync all files from the SFTP server to the S3 bucket."},"timestamp":"2021-08-20 20:17:00","discussion":[{"poster":"mericov","upvote_count":"12","timestamp":"1633021200.0","comment_id":"429025","content":"I would say B. Reasons: \"The EC2 instance also has an attached security group that allows access from all customer IP addresses\" - There is no option to put a security group in the publicly accessible endpoint (A)."},{"comment_id":"763871","content":"Selected Answer: B\nI'll go with B","upvote_count":"1","timestamp":"1672679700.0","poster":"evargasbrz"},{"comment_id":"577756","poster":"jj22222","timestamp":"1648574220.0","upvote_count":"2","content":"Selected Answer: B\nBBBBBBBBBB"},{"timestamp":"1642766340.0","upvote_count":"2","content":"Why B ? What does \"Attach the security group with customer IP addresses to the new endpoint.\" mean ? How do we attach so many IP addresses of customers ? And how will such solution minimize infra complexity ?\nA looks reasonable. Some additional reading link https://aws.amazon.com/premiumsupport/knowledge-center/aws-sftp-endpoint-type/","poster":"tkanmani76","comment_id":"529109","comments":[{"timestamp":"1642766760.0","comment_id":"529112","content":"Realize their is SG with client IP already which can be attached to endpoint - Option B will give access through Elastic IP.","poster":"tkanmani76","upvote_count":"2"}]},{"timestamp":"1639008240.0","upvote_count":"1","comment_id":"497252","poster":"AzureDP900","content":"I will go with B"},{"content":"It's B","timestamp":"1635198900.0","poster":"andylogan","comment_id":"449807","upvote_count":"1"},{"timestamp":"1634864460.0","upvote_count":"1","comment_id":"439816","comments":[{"poster":"andylogan","comment_id":"449808","content":"It's hosted with managed AWS Transfer Family server and S3 now, no need for EC2 - then B","timestamp":"1636076640.0","upvote_count":"1"}],"poster":"mgurkan","content":"How about availability? one EC2 does not provide high availability."},{"content":"BBB\n---","upvote_count":"1","timestamp":"1634618640.0","poster":"tgv","comment_id":"437326"},{"content":"B is correct. \nhttps://docs.aws.amazon.com/transfer/latest/userguide/create-server-in-vpc.html","poster":"blackgamer","timestamp":"1634089500.0","comment_id":"434709","upvote_count":"1"},{"comment_id":"432278","upvote_count":"2","content":"B.https://aws.amazon.com/premiumsupport/knowledge-center/aws-sftp-endpoint-type/","timestamp":"1633374180.0","poster":"tvs"},{"poster":"vjawscert","upvote_count":"2","comment_id":"431856","timestamp":"1633262580.0","content":"Correct Answer: B\nCD - Maintenance overhead with EC2\nA - You can't use a static elastic ip with public hosted one (ref: https://aws.amazon.com/premiumsupport/knowledge-center/aws-sftp-endpoint-type/)"},{"timestamp":"1633142580.0","upvote_count":"2","poster":"denccc","comment_id":"431714","content":"Would go for B: https://aws.amazon.com/premiumsupport/knowledge-center/aws-sftp-endpoint-type/. Only this way you can use security groups to restrict sources."},{"comments":[{"content":"B. Not able to attaché EIP to public facing SFTP endpoint of AWS Transfer Family server.","poster":"tvs","comment_id":"432281","timestamp":"1633475640.0","upvote_count":"2"}],"content":"It is A","upvote_count":"1","poster":"pkboy78","comment_id":"428329","timestamp":"1632785880.0"}],"answer":"B"}],"exam":{"id":32,"lastUpdated":"11 Apr 2025","isMCOnly":false,"name":"AWS Certified Solutions Architect - Professional","numberOfQuestions":1019,"provider":"Amazon","isBeta":false,"isImplemented":true},"currentPage":154},"__N_SSP":true}