{"pageProps":{"questions":[{"id":"le1AONqdIz3sWQ3wihwX","question_text":"A company has an ecommerce website with a product recommendation engine built in TensorFlow. The recommendation engine endpoint is hosted by Amazon\nSageMaker. Three compute-optimized instances support the expected peak load of the website.\nResponse times on the product recommendation page are increasing at the beginning of each month. Some users are encountering errors. The website receives the majority of its traffic between 8 AM and 6 PM on weekdays in a single time zone.\nWhich of the following options are the MOST effective in solving the issue while keeping costs to a minimum? (Choose two.)","timestamp":"2022-05-01 20:08:00","answer_description":"","question_images":[],"exam_id":26,"answer":"AC","url":"https://www.examtopics.com/discussions/amazon/view/75022-exam-aws-certified-machine-learning-specialty-topic-1/","isMC":true,"choices":{"E":"Reconfigure the endpoint to use burstable instances.","B":"Create a new endpoint configuration with two production variants.","D":"Deploy a second instance pool to support a blue/green deployment of models.","C":"Configure the endpoint to automatically scale with the InvocationsPerInstance metric.","A":"Configure the endpoint to use Amazon Elastic Inference (EI) accelerators."},"unix_timestamp":1651428480,"topic":"1","question_id":91,"answer_ET":"AC","discussion":[{"comments":[{"content":"Agree. \n\nThe problem with E is that it mentioned \"majority of its traffic between 8 AM and 6 PM on weekdays\", therefore it is not cost effective during period from 6PM to 8AM weekdays and weekends. Whereas the auto-scaling(C) could save money during all the time.","timestamp":"1675343100.0","comment_id":"796032","upvote_count":"1","poster":"Jerry84"}],"comment_id":"601418","content":"Selected Answer: AC\nAC - for me\nhttps://aws.amazon.com/machine-learning/elastic-inference/\nhttps://aws.amazon.com/blogs/machine-learning/configuring-autoscaling-inference-endpoints-in-amazon-sagemaker/","poster":"Sivadharan","upvote_count":"16","timestamp":"1652499360.0"},{"upvote_count":"9","poster":"rohit07cf","comment_id":"596083","timestamp":"1651501860.0","content":"AC looks correct"},{"comment_id":"1229650","content":"Selected Answer: CE\ntraffic between 8 AM and 6 PM on weekdays in a single time zone\n.--- Reconfigure the endpoint to use burstable instances.\n Configure the endpoint to automatically scale with the InvocationsPerInstance metric.","upvote_count":"2","timestamp":"1718258760.0","poster":"sheetalconect"},{"upvote_count":"2","comment_id":"1002171","content":"Selected Answer: AC\nA. YES - EI provides GPU access (Sept 2023: now deprecated)\nB. NO - not best practice to scale (altough it might help ?)\nC. YES - you want to scale with traffic\nD. NO - not best practice to scale (altough it might help ?)\nE. NO - burstable instances is for inpredictable traffic, bursting for long period of time is not cost effective","poster":"loict","timestamp":"1694153040.0"},{"content":"Selected Answer: CE\nEither AC or CE very confusing but C is confirmed and will go with E","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1693144560.0","content":"Or since the question is really old so maybe AC is what needs the answer to be","comment_id":"991487","poster":"Mickey321"}],"comment_id":"991484","timestamp":"1693144140.0","poster":"Mickey321"},{"comment_id":"988914","timestamp":"1692859440.0","upvote_count":"1","content":"Selected Answer: AC\nA C for me","poster":"Mickey321"},{"poster":"kaike_reis","upvote_count":"1","comment_id":"977853","content":"Selected Answer: AC\nA - C for me\nE is costy","timestamp":"1691682000.0"},{"comment_id":"887965","content":"E is not correct.\nA C E are both effective method to optimize inference, but A is used for GPU, and E is used for CPU. since this question is about Tensorflow, it should be A and E is not effective.","poster":"ZSun","timestamp":"1683064920.0","upvote_count":"1"},{"timestamp":"1679241240.0","comment_id":"843904","upvote_count":"3","poster":"blanco750","content":"Selected Answer: AC\nA and C are the right answers"},{"timestamp":"1676978940.0","upvote_count":"3","content":"Interesting if option A will be relevant anymore, as AWS is discontinuing Elastic Inference starting Apr 15. https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html. Wonder if they change the option to include Inf instane type","poster":"luckybme","comment_id":"816488"},{"comment_id":"744394","content":"Selected Answer: CE\nWhy elastic inference given that GPU is not necessary? I guess C and E (IMO)","poster":"wjohnny","upvote_count":"2","timestamp":"1670958960.0"},{"poster":"Ob1KN0B","upvote_count":"3","comment_id":"649475","timestamp":"1661007900.0","content":"Selected Answer: AE\nA - This is using Tensorflow which means Elastic inference can be used to save costs for GPU, thereby reducing the compute time.\nE - Since the load is not uniform, it will help to use burstable instances to operate above the threshold when the situation demands.\nC is not at all cost effective."},{"timestamp":"1658916060.0","upvote_count":"8","poster":"matteocal","content":"Selected Answer: AC\nAC is the most correct","comment_id":"637983"},{"comment_id":"618629","upvote_count":"2","poster":"KlaudYu","timestamp":"1655633940.0","content":"Selected Answer: AE\nI'd go AE if it requests for cost minimum"},{"poster":"tgaos","timestamp":"1653793020.0","upvote_count":"4","comment_id":"608611","content":"AC is correct"},{"poster":"bluer1","timestamp":"1651428480.0","upvote_count":"6","content":"AC - for me","comment_id":"595692"}],"answers_community":["AC (74%)","14%","12%"],"answer_images":[]},{"id":"OSb4GAMP75uCGGH3Uopy","discussion":[{"comment_id":"595013","poster":"spaceexplorer","upvote_count":"10","content":"Selected Answer: D\nD; A involves too much effort and management overhead.","comments":[{"upvote_count":"2","timestamp":"1683503040.0","comment_id":"598380","content":"Agree. but A has feature engineering which is the problem of the current model... confusing","poster":"LydiaGom","comments":[{"comment_id":"636382","content":"we don't use Logistic Regression to predict price.","upvote_count":"4","poster":"Raja3sa","timestamp":"1690260360.0"},{"comment_id":"887976","poster":"ZSun","upvote_count":"1","content":"AutoML also contains feature engineering/preprocessing tools.","timestamp":"1714687800.0"}]}],"timestamp":"1682859480.0"},{"upvote_count":"1","comment_id":"1002174","timestamp":"1725775680.0","poster":"loict","content":"Selected Answer: D\nA. NO - Logistic regression model is for classification, not to predict numerical values\nB. NO - approach is the highest quality, but takes time \nC. NO - XGBoost is for classification\nD. YES - simplest option"},{"comment_id":"988915","content":"Selected Answer: D\nD for me also","upvote_count":"1","poster":"Mickey321","timestamp":"1724481960.0"},{"poster":"ADVIT","comment_id":"944948","timestamp":"1720292700.0","content":"It's D as rest require more operation activities.","upvote_count":"1"},{"poster":"Shailendraa","comment_id":"649314","content":"D is Correct: trick to eliminate is A can not as Logistic is classification algo which gives binary outcome.B &C seems a lot of work .","timestamp":"1692513120.0","upvote_count":"3"},{"timestamp":"1689398340.0","poster":"Morsa","content":"Selected Answer: D\nThe problem is not a classification problem so A is incorrect as logistic regression is used for binary problems. D is the correct solution","comment_id":"631620","upvote_count":"3"},{"upvote_count":"2","content":"The problem is not which model you chose but primitive level feature engineering therefore correct answer should be \"B\"","timestamp":"1685755620.0","comment_id":"610863","poster":"mk5183"},{"timestamp":"1683710460.0","comment_id":"599485","poster":"edvardo","upvote_count":"3","content":"Selected Answer: D\nD. \nhttps://aws.amazon.com/sagemaker/autopilot/\n\nSupports missing values, categorical features, etc.\n\nThe simplest solution for this case"},{"timestamp":"1683333180.0","poster":"ckkobe24","comment_id":"597492","content":"why not Bï¼Ÿ","upvote_count":"2"}],"answer":"D","answer_ET":"D","timestamp":"2022-04-30 14:58:00","answer_images":[],"unix_timestamp":1651323480,"answers_community":["D (100%)"],"answer_description":"","question_id":92,"topic":"1","question_text":"A real-estate company is launching a new product that predicts the prices of new houses. The historical data for the properties and prices is stored in .csv format in an Amazon S3 bucket. The data has a header, some categorical fields, and some missing values. The company's data scientists have used Python with a common open-source library to fill the missing values with zeros. The data scientists have dropped all of the categorical fields and have trained a model by using the open-source linear regression algorithm with the default parameters.\nThe accuracy of the predictions with the current model is below 50%. The company wants to improve the model performance and launch the new product as soon as possible.\nWhich solution will meet these requirements with the LEAST operational overhead?","url":"https://www.examtopics.com/discussions/amazon/view/74970-exam-aws-certified-machine-learning-specialty-topic-1/","question_images":[],"choices":{"B":"Create an Amazon SageMaker notebook with a new IAM role that is associated with the notebook. Pull the dataset from the S3 bucket. Explore different combinations of feature engineering transformations, regression algorithms, and hyperparameters. Compare all the results in the notebook, and deploy the most accurate configuration in an endpoint for predictions.","C":"Create an IAM role with access to Amazon S3, Amazon SageMaker, and AWS Lambda. Create a training job with the SageMaker built-in XGBoost model pointing to the bucket with the dataset. Specify the price as the target feature. Wait for the job to complete. Load the model artifact to a Lambda function for inference on prices of new houses.","A":"Create a service-linked role for Amazon Elastic Container Service (Amazon ECS) with access to the S3 bucket. Create an ECS cluster that is based on an AWS Deep Learning Containers image. Write the code to perform the feature engineering. Train a logistic regression model for predicting the price, pointing to the bucket with the dataset. Wait for the training job to complete. Perform the inferences.","D":"Create an IAM role for Amazon SageMaker with access to the S3 bucket. Create a SageMaker AutoML job with SageMaker Autopilot pointing to the bucket with the dataset. Specify the price as the target attribute. Wait for the job to complete. Deploy the best model for predictions."},"exam_id":26,"isMC":true},{"id":"Z8vmiqYxJ9rCRiG9RIix","question_text":"A data scientist is reviewing customer comments about a company's products. The data scientist needs to present an initial exploratory analysis by using charts and a word cloud. The data scientist must use feature engineering techniques to prepare this analysis before starting a natural language processing (NLP) model.\nWhich combination of feature engineering techniques should the data scientist use to meet these requirements? (Choose two.)","discussion":[{"upvote_count":"12","comment_id":"597085","poster":"DJiang","content":"Selected Answer: CD\nSentiment analysis is the result of analysis, not feature engineering. I think this answer should be C & D.","timestamp":"1651717620.0"},{"poster":"hk0308","content":"Selected Answer: C\nD is also wrong. For creating a word cloud, the frequency of words (not their inverse frequency, as used in TF-IDF) is typically the most appropriate metric. Word clouds are designed to visually represent how often a word appears in the text, with more frequent words appearing larger and more prominent.","upvote_count":"1","comment_id":"1322297","timestamp":"1733390880.0"},{"content":"Selected Answer: CD\nA. NO - it is categorization of words and thus inferencing, not pre-processing\nB. NO - Coreferencing (eg. linking \"He\" to \"Mark\" seen in a previous sentence) is a complex task, not pre-processing\nC. YES - it consists of reducing words to their base form to reduce dimensionality\nD. YES - fast pre-processing task \nE. NO - it is not feature engineering, it is training","timestamp":"1694154960.0","upvote_count":"3","comment_id":"1002205","poster":"loict"},{"timestamp":"1692860220.0","comment_id":"988924","upvote_count":"1","content":"Selected Answer: CD\nC and D for me","poster":"Mickey321"},{"poster":"ADVIT","content":"Selected Answer: CD\nC for merge similar words\nD for remove not important words like \"the, is, a\"","upvote_count":"1","timestamp":"1688670420.0","comment_id":"944949"},{"timestamp":"1663009080.0","comment_id":"667380","upvote_count":"2","content":"12-sep exam","poster":"Shailendraa"},{"timestamp":"1660930980.0","upvote_count":"2","comment_id":"649063","content":"Selected Answer: DE\nhttps://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d\n\nSentiment analysis IS a part of feature engg in NLP.","poster":"Ob1KN0B"},{"timestamp":"1658906700.0","content":"Selected Answer: CD\nsentiment analysis is not part of feature engineering","upvote_count":"2","poster":"matteocal","comment_id":"637893"},{"poster":"Morsa","upvote_count":"3","comment_id":"631355","content":"Selected Answer: CD\nI agree ABE are not feature engineering","timestamp":"1657801560.0"},{"timestamp":"1651692660.0","content":"Selected Answer: CD\nA, B, E are not feature engineering","comment_id":"597003","poster":"edvardo","upvote_count":"4"},{"timestamp":"1651455900.0","content":"Selected Answer: CD\nwhy not C & D","comment_id":"595811","poster":"ckkobe24","upvote_count":"4"}],"timestamp":"2022-05-02 03:45:00","topic":"1","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/75045-exam-aws-certified-machine-learning-specialty-topic-1/","question_id":93,"exam_id":26,"question_images":[],"unix_timestamp":1651455900,"answers_community":["CD (91%)","6%"],"answer_description":"","isMC":true,"answer":"CD","answer_ET":"CD","choices":{"B":"Coreference","D":"Term frequency-inverse document frequency (TF-IDF)","C":"Stemming","E":"Sentiment analysis","A":"Named entity recognition"}},{"id":"YBWrSqIfG3Q8Zc5OEhPL","question_text":"A data scientist is evaluating a GluonTS on Amazon SageMaker DeepAR model. The evaluation metrics on the test set indicate that the coverage score is 0.489 and 0.889 at the 0.5 and 0.9 quantiles, respectively.\nWhat can the data scientist reasonably conclude about the distributional forecast related to the test set?","discussion":[{"poster":"cognito_22","comments":[{"comment_id":"670175","timestamp":"1694800800.0","poster":"example_","upvote_count":"4","content":"https://ts.gluon.ai/stable/tutorials/forecasting/quick_start_tutorial.html"}],"comment_id":"598247","timestamp":"1683483360.0","content":"Selected Answer: D\nhttps://ts.gluon.ai/tutorials/forecasting/quick_start_tutorial.html","upvote_count":"10"},{"upvote_count":"1","poster":"backbencher2022","timestamp":"1729194120.0","comment_id":"1046324","content":"Selected Answer: C\nC is correct based on this blog - https://aws.amazon.com/blogs/machine-learning/training-debugging-and-running-time-series-forecasting-models-with-the-gluonts-toolkit-on-amazon-sagemaker/"},{"comment_id":"989050","poster":"Mickey321","content":"Selected Answer: D\nD for me","upvote_count":"1","timestamp":"1724493180.0"},{"content":"D: A well-calibrated model should have quantile coverage close to the desired coverage level (e.g., 90% quantile coverage should be close to 90%). If the quantile coverage is consistently off from the desired level, it may indicate the need to recalibrate the model or investigate the sources of uncertainty estimation errors.","poster":"vbal","comment_id":"959629","timestamp":"1721659080.0","upvote_count":"1"},{"upvote_count":"1","poster":"CKS1210","comment_id":"936091","content":"Selected Answer: C\nhttps://apps.microsoft.com/store/detail/move-mouse/9NQ4QL59XLBF?hl=en-us&gl=us","timestamp":"1719551100.0"},{"upvote_count":"1","content":"Selected Answer: D\nI think it is D","poster":"WilianCB","timestamp":"1714581300.0","comment_id":"886499"},{"comment_id":"844178","comments":[{"comment_id":"1046895","poster":"wendaz","content":"My chatgpt is latest: \nThe coverage of a distributional forecast at a given quantile is the fraction of observations that fall below the predicted quantile. In a well-calibrated forecast, the coverage score should be approximately equal to the quantile itself.\n\nGiven the information:\n\nCoverage score is 0.489 at the 0.5 quantile.\nCoverage score is 0.889 at the 0.9 quantile.\nFor a well-calibrated forecast:\n\nAt the 0.5 quantile (or median), the coverage should be approximately 0.5.\nAt the 0.9 quantile, the coverage should be approximately 0.9.\nThe provided coverage scores closely match the quantiles, with slight deviations.\n\nTherefore, the correct conclusion is:\n\nOption D: The coverage scores indicate that the distributional forecast is correctly calibrated. These scores should be approximately equal to the quantile itself.","timestamp":"1729253820.0","upvote_count":"1"}],"content":"Selected Answer: C\nThanks to ChatGPT\nGiven the coverage score results, the data scientist can conclude that the distributional forecast related the test set is well calibrated. Specifically, when the model predicts quantiles, around % of the true values should fall within the 0.5 quantile range, and around90% of the true values should fall within the 0.9 quantile range., the GluonTS on Amazon SageMaker DeepAR model performance on the test set was concerning the coverage of the predicted quantiles.","poster":"blanco750","upvote_count":"1","timestamp":"1710878520.0"},{"content":"Selected Answer: C\nScores should always fall below the quantile itself. Ref: https://d1.awsstatic.com/asset-repository/Amazon%20Forecast%20Technical%20Guide%20to%20Time-Series%20Forecasting%20Principles.pdf -- Pg 18","timestamp":"1710074160.0","poster":"SANDEEP_AWS","comment_id":"834967","comments":[{"timestamp":"1710328020.0","poster":"SANDEEP_AWS","content":"PDF Pg 23","comment_id":"837874","upvote_count":"2"},{"timestamp":"1714377960.0","upvote_count":"1","comment_id":"884149","poster":"Tony_1406","content":"https://docs.aws.amazon.com/forecast/latest/dg/metrics.html#metrics-wQL\nA more concise doc."}],"upvote_count":"2"},{"upvote_count":"2","comment_id":"641449","poster":"[Removed]","timestamp":"1691008560.0","content":"C is correct"}],"topic":"1","timestamp":"2022-05-07 20:16:00","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/75279-exam-aws-certified-machine-learning-specialty-topic-1/","exam_id":26,"question_id":94,"question_images":[],"unix_timestamp":1651947360,"answers_community":["D (71%)","C (29%)"],"answer_description":"","isMC":true,"answer":"D","answer_ET":"D","choices":{"A":"The coverage scores indicate that the distributional forecast is poorly calibrated. These scores should be approximately equal to each other at all quantiles.","C":"The coverage scores indicate that the distributional forecast is correctly calibrated. These scores should always fall below the quantile itself.","D":"The coverage scores indicate that the distributional forecast is correctly calibrated. These scores should be approximately equal to the quantile itself.","B":"The coverage scores indicate that the distributional forecast is poorly calibrated. These scores should peak at the median and be lower at the tails."}},{"id":"vt1vyqXiwIPeUhNtTR8r","question_text":"An energy company has wind turbines, weather stations, and solar panels that generate telemetry data. The company wants to perform predictive maintenance on these devices. The devices are in various locations and have unstable internet connectivity.\nA team of data scientists is using the telemetry data to perform machine learning (ML) to conduct anomaly detection and predict maintenance before the devices start to deteriorate. The team needs a scalable, secure, high-velocity data ingestion mechanism. The team has decided to use Amazon S3 as the data storage location.\nWhich approach meets these requirements?","discussion":[{"comment_id":"597932","upvote_count":"13","poster":"siju13","content":"Selected Answer: C\nAnswer is C.\n\nB, D wrong because Kinesis data stream cannot write to S3 directly.","timestamp":"1683422220.0"},{"comment_id":"596771","content":"A. Not enough.\nC. Correct. Check https://docs.aws.amazon.com/firehose/latest/dev/writing-with-iot.html\nB, D: Wrong. KDS doesn't write directly to S3","upvote_count":"7","timestamp":"1683201600.0","poster":"edvardo"},{"poster":"loict","content":"Selected Answer: C\nA. NO - HTTP is not best protocol for IoT \nB. NO - No need to buffer write from Firehose to S3 with Kinesis/Kafka in the middle\nC. YES - Firehose is a good connector MQTT to S3\nD. NO - Kinesis/Kafka cannot intake MQTT out-of-the-box, Firehose is the right connector","timestamp":"1725778020.0","upvote_count":"1","comment_id":"1002209"},{"poster":"Mickey321","upvote_count":"1","comment_id":"989053","content":"Selected Answer: C\nAnswer is C","timestamp":"1724493360.0"},{"content":"Selected Answer: C\nC is sorrect","poster":"blanco750","comment_id":"844188","upvote_count":"2","timestamp":"1710878820.0"}],"topic":"1","timestamp":"2022-05-04 14:00:00","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/75149-exam-aws-certified-machine-learning-specialty-topic-1/","exam_id":26,"question_id":95,"question_images":[],"unix_timestamp":1651665600,"answers_community":["C (100%)"],"answer_description":"","isMC":true,"answer":"C","answer_ET":"C","choices":{"B":"Ingest the data over Message Queuing Telemetry Transport (MQTT) to AWS IoT Core. Set up a rule in AWS IoT Core to use Amazon Kinesis Data Firehose to send data to an Amazon Kinesis data stream that is configured to write to an S3 bucket.","C":"Ingest the data over Message Queuing Telemetry Transport (MQTT) to AWS IoT Core. Set up a rule in AWS IoT Core to direct all MQTT data to an Amazon Kinesis Data Firehose delivery stream that is configured to write to an S3 bucket.","D":"Ingest the data over Message Queuing Telemetry Transport (MQTT) to Amazon Kinesis data stream that is configured to write to an S3 bucket.","A":"Ingest the data by using an HTTP API call to a web server that is hosted on Amazon EC2. Set up EC2 instances in an Auto Scaling configuration behind an Elastic Load Balancer to load the data into Amazon S3."}}],"exam":{"isBeta":false,"name":"AWS Certified Machine Learning - Specialty","lastUpdated":"11 Apr 2025","numberOfQuestions":369,"id":26,"isMCOnly":false,"isImplemented":true,"provider":"Amazon"},"currentPage":19},"__N_SSP":true}