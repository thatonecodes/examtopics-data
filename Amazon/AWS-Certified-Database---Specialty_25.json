{"pageProps":{"questions":[{"id":"16o6iokLOfTdbaMeypbK","timestamp":"2022-09-05 06:13:00","question_images":[],"answers_community":["B (93%)","7%"],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/80196-exam-aws-certified-database-specialty-topic-1-question-207/","question_text":"A finance company migrated its 3 ׀¢׀’ on-premises PostgreSQL database to an Amazon Aurora PostgreSQL DB cluster. During a review after the migration, a database specialist discovers that the database is not encrypted at rest. The database must be encrypted at rest as soon as possible to meet security requirements. The database specialist must enable encryption for the DB cluster with minimal downtime.\nWhich solution will meet these requirements?","answer_ET":"B","unix_timestamp":1662351180,"exam_id":22,"topic":"1","choices":{"C":"Create an encrypted Aurora Replica of the unencrypted DB cluster. Promote the Aurora Replica as the new master.","B":"Take a snapshot of the unencrypted DB cluster and restore it to a new DB cluster with encryption enabled. Update any database connection strings to reference the new DB cluster endpoint, and then delete the unencrypted DB cluster.","A":"Modify the unencrypted DB cluster using the AWS Management Console. Enable encryption and choose to apply the change immediately.","D":"Create a new DB cluster with encryption enabled and use the pg_dump and pg_restore utilities to load data to the new DB cluster. Update any database connection strings to reference the new DB cluster endpoint, and then delete the unencrypted DB cluster."},"answer":"B","answer_images":[],"question_id":121,"discussion":[{"timestamp":"1704218220.0","content":"Selected Answer: B\nit's B","comment_id":"1112119","poster":"missipssamarsh","upvote_count":"2"},{"content":"Selected Answer: B\nI'll go with B \n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Overview.Encryption.html#:~:text=You%20can%27t%20convert%20an%20unencrypted%20DB%20cluster%20to%20an%20encrypted%20one.%20However%2C%20you%20can%20restore%20an%20unencrypted%20snapshot%20to%20an%20encrypted%20Aurora%20DB%20cluster.%20To%20do%20this%2C%20specify%20a%20KMS%20key%20when%20you%20restore%20from%20the%20unencrypted%20snapshot.","poster":"dougporto1988","upvote_count":"4","comment_id":"850739","timestamp":"1679807400.0"},{"upvote_count":"1","comment_id":"811741","timestamp":"1676629260.0","content":"Selected Answer: B\nIt's B \nhttps://catalog.us-east-1.prod.workshops.aws/workshops/aad9ff1e-b607-45bc-893f-121ea5224f24/en-US/rds/aurora/2-encryptexistingcluster","poster":"teo2157"},{"upvote_count":"1","content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/database/best-practices-for-migrating-postgresql-databases-to-amazon-rds-and-amazon-aurora/","timestamp":"1672171020.0","comment_id":"758982","poster":"lollyj"},{"upvote_count":"2","poster":"Kanwar_89","content":"Selected Answer: B\nPoint number 4 in limitations - https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Overview.Encryption.html#Overview.Encryption.Limitations","comment_id":"758696","timestamp":"1672154400.0"},{"poster":"cloudsunriser","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Overview.Encryption.html","upvote_count":"1","timestamp":"1664209980.0","comment_id":"679958"},{"timestamp":"1662805140.0","upvote_count":"1","comment_id":"665309","poster":"SonamDhingra","content":"Selected Answer: B\nB is correct"},{"comment_id":"659718","timestamp":"1662351180.0","upvote_count":"3","poster":"mbar94","content":"Selected Answer: B\nIt's B. A and C for sure incorrect - https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Overview.Encryption.html"}],"answer_description":""},{"id":"pUBHu0x3QpPEbS6lvKor","isMC":true,"answers_community":["A (100%)"],"answer":"A","question_text":"A company has a 4 ׀¢׀’ on-premises Oracle Real Application Clusters (RAC) database. The company wants to migrate the database to AWS and reduce licensing costs. The company's application team wants to store JSON payloads that expire after 28 hours. The company has development capacity if code changes are required.\nWhich solution meets these requirements?","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/80197-exam-aws-certified-database-specialty-topic-1-question-208/","timestamp":"2022-09-05 06:14:00","answer_ET":"A","question_images":[],"answer_images":[],"question_id":122,"discussion":[{"timestamp":"1664210400.0","upvote_count":"4","comment_id":"679964","poster":"cloudsunriser","content":"Selected Answer: A\nExpiration + Json + Capacity to have code change = Option A"},{"timestamp":"1662805380.0","upvote_count":"2","comment_id":"665311","poster":"SonamDhingra","content":"Selected Answer: A\nA is correct"},{"content":"Selected Answer: A\nJSON + expiration = Dynamo DB. It's A.","poster":"mbar94","upvote_count":"3","comment_id":"659719","timestamp":"1662351240.0"}],"exam_id":22,"unix_timestamp":1662351240,"topic":"1","choices":{"C":"Use Amazon DocumentDB with a read replica in a different Availability Zone. Use DocumentDB change streams to expire the data.","D":"Use Amazon Aurora PostgreSQL with Multi-AZ and leverage the Time to Live (TTL) feature to automatically expire the data.","A":"Use Amazon DynamoDB and leverage the Time to Live (TTL) feature to automatically expire the data.","B":"Use Amazon RDS for Oracle with Multi-AZ. Create an AWS Lambda function to purge the expired data. Schedule the Lambda function to run daily using Amazon EventBridge."}},{"id":"39wSjOnUewyeXmLtdQ7Y","timestamp":"2022-09-05 06:26:00","choices":{"A":"Increase the Provisioned IOPS rate on the storage.","D":"Create a read replica to offload Read IOPS from the DB instance.","C":"Use General Purpose SSD (gp2) storage with burst credits.","B":"Increase the available storage space."},"answers_community":["A (86%)","14%"],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/80198-exam-aws-certified-database-specialty-topic-1-question-209/","answer_ET":"A","answer_description":"","question_id":123,"exam_id":22,"discussion":[{"content":"What is ׀¢׀’ in the question guys?","poster":"PVM159","comments":[{"timestamp":"1691931180.0","content":"TB. Google the answer text should reveal the original question somewhere.","upvote_count":"2","comment_id":"980027","poster":"zanhsieh"}],"upvote_count":"5","comment_id":"848889","timestamp":"1679626440.0"},{"timestamp":"1705306500.0","content":"Selected Answer: A\nA \nAlthough it may still take some time to \"rebalance\" the storage","poster":"MultiAZ","upvote_count":"2","comment_id":"1123174"},{"upvote_count":"3","timestamp":"1672233000.0","content":"Selected Answer: A\nIncreasing the provisioned IO capacity will immediately alleviate the latency.","comment_id":"759861","poster":"lollyj"},{"comment_id":"758785","content":"Ans - A\nGetting the best performance from Amazon RDS Provisioned IOPS SSD storage:\nIf your workload is I/O constrained, using Provisioned IOPS SSD storage can increase the number of I/O requests that the system can process concurrently. Increased concurrency allows for decreased latency because I/O requests spend less time in a queue. Decreased latency allows for faster database commits, which improves response time and allows for higher database throughput.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","upvote_count":"2","timestamp":"1672158600.0","poster":"parle101"},{"upvote_count":"2","comment_id":"711278","poster":"hogtrough","timestamp":"1667582760.0","content":"Selected Answer: A\nKey word is \"immediate.\" Replica will take time to create."},{"timestamp":"1665851400.0","comment_id":"695533","poster":"awsjjj","upvote_count":"1","content":"Selected Answer: A\nanswer A due to \"immediate improvement\""},{"upvote_count":"2","timestamp":"1664211060.0","poster":"cloudsunriser","comment_id":"679969","content":"Selected Answer: A\nI think both A and D are correct but as last line of question says we want immediate improvement then A should be answer as read replica creation will take some time."},{"poster":"SonamDhingra","content":"Selected Answer: A\nA is correct","timestamp":"1662805860.0","comment_id":"665316","upvote_count":"2"},{"content":"Selected Answer: D\nIt seems that D - https://aws.amazon.com/blogs/database/best-storage-practices-for-running-production-workloads-on-hosted-databases-with-amazon-rds-or-amazon-ec2/","timestamp":"1662351960.0","comment_id":"659722","upvote_count":"2","poster":"mbar94"}],"answer":"A","topic":"1","unix_timestamp":1662351960,"answer_images":[],"question_text":"A database specialist is working on an Amazon RDS for PostgreSQL DB instance that is experiencing application performance issues due to the addition of new workloads. The database has 5 ׀¢׀’ of storage space with Provisioned IOPS. Amazon CloudWatch metrics show that the average disk queue depth is greater than\n200 and that the disk I/O response time is significantly higher than usual.\nWhat should the database specialist do to improve the performance of the application immediately?","question_images":[]},{"id":"7XEyS3sQpJ1pXxoNyuQR","isMC":true,"answer_description":"","unix_timestamp":1595041200,"answers_community":["B (92%)","8%"],"url":"https://www.examtopics.com/discussions/amazon/view/26014-exam-aws-certified-database-specialty-topic-1-question-21/","answer":"B","answer_images":[],"question_text":"A company maintains several databases using Amazon RDS for MySQL and PostgreSQL. Each RDS database generates log files with retention periods set to their default values. The company has now mandated that database logs be maintained for up to 90 days in a centralized repository to facilitate real-time and after-the-fact analyses.\nWhat should a Database Specialist do to meet these requirements with minimal effort?","exam_id":22,"answer_ET":"B","choices":{"A":"Create an AWS Lambda function to pull logs from the RDS databases and consolidate the log files in an Amazon S3 bucket. Set a lifecycle policy to expire the objects after 90 days.","D":"Create an AWS Lambda function to download the logs from the RDS databases and publish the logs to Amazon CloudWatch Logs. Change the log retention policy for the log group to expire the events after 90 days.","B":"Modify the RDS databases to publish log to Amazon CloudWatch Logs. Change the log retention policy for each log group to expire the events after 90 days.","C":"Write a stored procedure in each RDS database to download the logs and consolidate the log files in an Amazon S3 bucket. Set a lifecycle policy to expire the objects after 90 days."},"question_images":[],"question_id":124,"timestamp":"2020-07-18 05:00:00","discussion":[{"timestamp":"1632322740.0","content":"I'll go with B because it facilitate real-time","poster":"learnaws","comment_id":"137580","upvote_count":"12","comments":[{"content":"I think it's due to the question need minimal effort. A need write a lambda is not minimal effort","comment_id":"150695","upvote_count":"4","timestamp":"1632805980.0","comments":[{"timestamp":"1645975380.0","poster":"user0001","content":"regardless of the effort, why do you want to write code? (option A).\nyou should always try to go with built-in fuctionality","upvote_count":"1","comment_id":"557403"},{"poster":"cloud4gr8","comment_id":"164727","timestamp":"1634040600.0","upvote_count":"3","content":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html"}],"poster":"szmulder"}]},{"timestamp":"1694762400.0","content":"Selected Answer: B\nB. Modify the RDS databases to publish log to Amazon CloudWatch Logs. Change the log retention policy for each log group to expire the events after 90 days. \n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Procedural.UploadtoCloudWatch.html\n\n\"In an on-premises database, the database logs reside on the file system. Amazon RDS doesn't provide host access to the database logs on the file system of your DB instance. For this reason, Amazon RDS lets you export database logs to Amazon CloudWatch Logs. With CloudWatch Logs, you can perform real-time analysis of the log data. You can also store the data in highly durable storage and manage the data with the CloudWatch Logs Agent. \"","comment_id":"1008223","poster":"Pranava_GCP","upvote_count":"2"},{"comment_id":"942674","upvote_count":"3","timestamp":"1688469420.0","content":"Selected Answer: B\nThe answer is B.\n\n\"In an on-premises database, the database logs reside on the file system. Amazon RDS doesn't provide host access to the database logs on the file system of your DB instance. For this reason, Amazon RDS lets you export database logs to Amazon CloudWatch Logs. With CloudWatch Logs, you can perform real-time analysis of the log data. You can also store the data in highly durable storage and manage the data with the CloudWatch Logs Agent.\"\nReference: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Procedural.UploadtoCloudWatch.html","poster":"mraronsimon"},{"poster":"ken_test1234","upvote_count":"1","content":"Selected Answer: B\nBecause you need a centralized place for analysis and real time data , using s3 will require to search and view the logs 1 by 1 which is not a real time analyses","comment_id":"853065","timestamp":"1679996460.0"},{"upvote_count":"1","comment_id":"836465","content":"B.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Procedural.UploadtoCloudWatch.html\nPublish logs to CloudWatch","poster":"Mintwater","timestamp":"1678565280.0"},{"timestamp":"1665932580.0","poster":"awsjjj","comment_id":"696315","content":"Selected Answer: B\nB it is","upvote_count":"1"},{"poster":"sachin","comment_id":"620219","content":"with the least amount of work possible ; _the ans seems to be B but \nwith have central repository to store logs for post-mortem analysis .. the Ans A seems to be correct.. \nThis is confusing question :)","upvote_count":"1","timestamp":"1655880660.0"},{"timestamp":"1651258440.0","poster":"novice_expert","content":"Selected Answer: A\nno for B because: Logfiles are already created, and we do not want to mix that info with other log entries on CloudWatch \n\nso A:\nLambda function to pull logs from the RDS databases -> consolidate the log files in an Amazon S3 bucket. Set a lifecycle policy to expire the objects after 90 days.","comments":[{"timestamp":"1655730000.0","content":"Why not mix logs on CloudWatch? We can use different Log groups and we can filter logs....","comment_id":"619290","upvote_count":"2","poster":"DevoteamAnalytix"}],"comment_id":"594652","upvote_count":"1"},{"poster":"RotterDam","upvote_count":"1","content":"Selected Answer: B\nB is the correction Option","comment_id":"561216","timestamp":"1646456880.0"},{"timestamp":"1645738320.0","comment_id":"555580","content":"Selected Answer: B\nB can be scripted too","poster":"tugboat","upvote_count":"1"},{"comment_id":"536107","content":"Selected Answer: B\nB, best option with minimal effort and real time.","poster":"soyyodario","timestamp":"1643543880.0","upvote_count":"2"},{"comment_id":"521062","content":"Going with B","upvote_count":"1","timestamp":"1641841380.0","poster":"awsmonster"},{"timestamp":"1639709580.0","poster":"mnzsql365","upvote_count":"3","comment_id":"503319","content":"B is the right ans. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.Procedural.UploadtoCloudWatch.html"},{"comment_id":"479447","content":"Answer: B","upvote_count":"1","timestamp":"1637074380.0","poster":"andy909"},{"content":"Its a tricky question, the correct option goes down to which of the options uses minimal effort, creating a lambda function or modifying all the databases. The question doesn´t tell us how many RDS, so I would choose B","upvote_count":"1","comment_id":"445294","timestamp":"1635989160.0","poster":"GMartinelli"},{"poster":"guru_ji","timestamp":"1635978540.0","content":"B is Correct","upvote_count":"1","comment_id":"437711"},{"poster":"ChauPhan","content":"Vote B for minimal effort.","upvote_count":"1","comment_id":"423669","timestamp":"1635951840.0"},{"timestamp":"1635412920.0","content":"I believe it is B.","poster":"LMax","comment_id":"317363","upvote_count":"2"},{"comment_id":"299608","timestamp":"1634898840.0","poster":"myutran","content":"Ans: B","upvote_count":"1"},{"timestamp":"1634542440.0","comment_id":"212004","upvote_count":"1","content":"B should be","poster":"Ashoks"},{"comment_id":"168940","upvote_count":"1","timestamp":"1634232120.0","content":"Going with B","poster":"Rahu"},{"poster":"BillyC","upvote_count":"1","timestamp":"1632587640.0","comment_id":"140239","content":"B is Correct"},{"comment_id":"137942","poster":"helpaws","upvote_count":"2","content":"B here","timestamp":"1632533760.0","comments":[{"timestamp":"1632583800.0","upvote_count":"1","poster":"BillyMadison","comment_id":"139751","content":"Going with b as well\nhttps://aws.amazon.com/premiumsupport/knowledge-center/rds-aurora-mysql-logs-cloudwatch/\nhttps://docs.aws.amazon.com/AmazonCloudWatchLogs/latest/APIReference/API_PutRetentionPolicy.html"}]}],"topic":"1"},{"id":"dwe9kc7oJV6Lhl67lWDp","unix_timestamp":1662352080,"choices":{"A":"Modify the DB instance and set a new master user password.","C":"Create a new master user for the DB instance.","B":"Use AWS Secrets Manager to modify the master user password and restart the DB instance.","D":"Review the IAM user that owns the DB instance, and add missing permissions."},"isMC":true,"answer_ET":"A","question_text":"A software company uses an Amazon RDS for MySQL Multi-AZ DB instance as a data store for its critical applications. During an application upgrade process, a database specialist runs a custom SQL script that accidentally removes some of the default permissions of the master user.\nWhat is the MOST operationally efficient way to restore the default permissions of the master user?","url":"https://www.examtopics.com/discussions/amazon/view/80200-exam-aws-certified-database-specialty-topic-1-question-210/","answer":"A","answer_description":"","discussion":[{"upvote_count":"2","poster":"khun","timestamp":"1671418920.0","comment_id":"749402","content":"Selected Answer: A\nA. \nIf you accidentally delete the permissions for the master user, you can restore them by modifying the DB instance and setting a new master user password."},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.MasterAccounts.html","poster":"Gosha109876","comment_id":"734608","timestamp":"1670089440.0","upvote_count":"4"},{"poster":"SonamDhingra","upvote_count":"1","comment_id":"665319","timestamp":"1662805920.0","content":"A is correct."},{"content":"Selected Answer: A\nA is correct.","poster":"mbar94","timestamp":"1662352080.0","upvote_count":"2","comment_id":"659724"}],"topic":"1","question_id":125,"question_images":[],"timestamp":"2022-09-05 06:28:00","exam_id":22,"answer_images":[],"answers_community":["A (100%)"]}],"exam":{"provider":"Amazon","name":"AWS Certified Database - Specialty","isMCOnly":false,"isBeta":false,"isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":359,"id":22},"currentPage":25},"__N_SSP":true}