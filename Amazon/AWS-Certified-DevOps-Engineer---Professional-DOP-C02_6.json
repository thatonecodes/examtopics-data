{"pageProps":{"questions":[{"id":"p4qC6yfRsxFx3GRboMoh","answer_ET":"BE","discussion":[{"comment_id":"908158","poster":"lunt","comments":[{"comments":[{"poster":"robertohyena","content":"From your link: https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying.html\n\nWhen changing a key policy, keep in mind the following rules:\n- You can view the key policy for an AWS managed key or a customer managed key, but you can only change the key policy for a customer managed key. \n- The policies of AWS managed keys are created and managed by the AWS service that created the KMS key in your account. \n- You cannot view or change the key policy for an AWS owned key.","upvote_count":"2","timestamp":"1702204020.0","comments":[{"timestamp":"1727072460.0","upvote_count":"1","poster":"heff_bezos","comment_id":"1288009","content":"From your link:\n\"You can add or remove IAM users, IAM roles, and AWS accounts in the key policy, and change the actions that are allowed or denied for those principals.\"\nThe answer is BE because you don't want to grant permissions to the KMS key for an ENTIRE account, you'd want to allow access for a particular role."}],"comment_id":"1092417"}],"poster":"svjl","content":"You van modify the key policies, it is a managed key. What is wrong is change it to use for different account.\nhttps://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying.html","upvote_count":"2","timestamp":"1701959280.0","comment_id":"1090369"}],"content":"Selected Answer: BE\nC = AWS KMS fundamentals. Cannot modify AWS managed KMS key policies. No Cross account access = will not work. Not sure why there is even a discussion on this. Associate level basics.","timestamp":"1685212140.0","upvote_count":"14"},{"content":"Selected Answer: BD\nthere is no need to modify the artifacts S3 bucket policy to allow the roles access","upvote_count":"1","comment_id":"1330101","timestamp":"1734794040.0","poster":"youonebe"},{"poster":"jamesf","content":"Selected Answer: BE\nB - Cannot modify AWS managed KMS key policies.\nE - Cross account access and we need bucket policies also to be updated, if its same account then we do not need bucket policies permissions","timestamp":"1722232740.0","comment_id":"1257285","upvote_count":"2"},{"upvote_count":"3","poster":"xdkonorek2","timestamp":"1718815800.0","content":"Selected Answer: BD\nBD,\ntry it yourself, create account with a bucket, create role with access to s3 operations, and trust policy for another account. \nrole assumed by another account has full access to s3 resources thereby it's not needed to set up resource policy on s3 bucket","comment_id":"1232977"},{"upvote_count":"1","content":"Selected Answer: BD\nAnswer is BD , \nI have recently implemented similar solution, and my S3 bucket do not have any policy configured , my IAM role has required KMS key permission and it worked. \n\nmodifying the S3 bucket policy, but this is not necessary if the IAM roles are correctly configured and used by the CodePipeline CloudFormation action","comments":[{"poster":"Venki_dev","comment_id":"1232675","upvote_count":"3","content":"I switch to BE , \n\nbecause its cross account access and we need bucket policies also to be updated, if its same account then we do not need bucket policies permissions","timestamp":"1718760180.0"}],"poster":"Venki_dev","timestamp":"1717909440.0","comment_id":"1227073"},{"timestamp":"1713743280.0","comment_id":"1199865","content":"Selected Answer: BD\nNobody is saying why we are modifying the artifacts in S3 in Option E in the Codecommit account. Doesn't seem to make sense to me.","upvote_count":"1","poster":"c3518fc"},{"content":"Selected Answer: BE\nBE. are correct","timestamp":"1713082680.0","upvote_count":"2","poster":"dkp","comment_id":"1195386"},{"upvote_count":"4","comment_id":"1140897","timestamp":"1707126480.0","content":"B and E are correct: <fail with an access denied error.> this means there are issues with policies and permissions. \nA: no mention of policies\nC: This is what the dev team has tried but failed. Can not modify managed key policy, can only view it\nD: no mention of configuring S3 bucket policy","poster":"thanhnv142"},{"upvote_count":"3","poster":"robertohyena","comment_id":"1092426","timestamp":"1702204560.0","content":"Selected Answer: BE\nexact steps are in this doc\nhttps://docs.aws.amazon.com/codepipeline/latest/userguide/pipelines-create-cross-account.html"},{"comment_id":"1060924","timestamp":"1698960360.0","upvote_count":"4","poster":"YR4591","content":"Selected Answer: BE\nIt's BE,\nAccording to this, aws managed kms key can't be used cross account:\nhttps://repost.aws/knowledge-center/cross-account-access-denied-error-s3\n\n\"Warning: AWS managed AWS KMS key policies can't be modified because they're read-only. However, you can always view both the AWS managed KMS key policies and customer managed KMS key policies. Because AWS managed KMS key policies can't be updated, cross-account permissions also can't be granted for those key policies. Additionally, objects that are encrypted using an AWS managed KMS key can't be accessed by other AWS accounts. For customer managed KMS key policies, you can change the key policy only from the AWS account that created the policy.\""},{"timestamp":"1689233760.0","upvote_count":"3","poster":"Certified101","content":"Selected Answer: BE\nBE, bucket policy needs to be amended also as it will assume roles in the prod and dev account","comment_id":"950449"},{"poster":"habros","timestamp":"1688911200.0","comment_id":"947309","upvote_count":"2","content":"Selected Answer: BE\nBE. CMEK = you determine access (key policy) and rotation period (you define instead of 365 days for AWS managed keys). Perfect for cross account resources."},{"upvote_count":"4","poster":"Mail1964","timestamp":"1684832280.0","comment_id":"904759","content":"Selected Answer: BE\nYou can view the key policy for an AWS managed key or a customer managed key, but you can only change the key policy for a customer managed key."},{"timestamp":"1684197540.0","comment_id":"898794","content":"CE for me","poster":"devnv","upvote_count":"1"},{"comment_id":"897087","poster":"2pk","timestamp":"1684018020.0","upvote_count":"2","comments":[{"poster":"2pk","timestamp":"1684879920.0","upvote_count":"1","content":"I thought again, it should be A & E correct. \nB is worng becasue The access denied error typically occurs when the IAM roles used by the CloudFormation action lack the necessary permissions to access the required resources. Therefore, option B does not directly address the access denied error in the given scenario.","comment_id":"905273"}],"content":"B & E , i guess too"},{"upvote_count":"2","content":"Selected Answer: BE\nI think it is B and E","comment_id":"896397","timestamp":"1683951960.0","poster":"PhuocT"},{"content":"Selected Answer: CE\nQuestions says: \"A DevOps engineer creates the CodePipeline pipeline and configures the pipeline to encrypt build artifacts by using the AWS Key Management Service (AWS KMS) AWS managed key for Amazon S3 (the aws/s3 key).\" not CMK ...","comment_id":"892908","upvote_count":"3","comments":[{"timestamp":"1691029500.0","content":"Answer C is incorrect because you cannot \"create\" an AWS-managed key or modify its key policy. In order to modify a key policy, you need an customer-managed key (Answer B). The question states they used an AWS-managed key, but got an error. So you have to re-evaluate how to make this work, which requires a customer-managed key.\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#key-mgmt","upvote_count":"4","poster":"sb333","comment_id":"970690"}],"poster":"Jeanphi72","timestamp":"1683618720.0"}],"unix_timestamp":1683618720,"question_id":26,"question_text":"A company is building a new pipeline by using AWS CodePipeline and AWS CodeBuild in a build account. The pipeline consists of two stages. The first stage is a CodeBuild job to build and package an AWS Lambda function. The second stage consists of deployment actions that operate on two different AWS accounts: a development environment account and a production environment account. The deployment stages use the AWS CloudFormation action that CodePipeline invokes to deploy the infrastructure that the Lambda function requires.\n\nA DevOps engineer creates the CodePipeline pipeline and configures the pipeline to encrypt build artifacts by using the AWS Key Management Service (AWS KMS) AWS managed key for Amazon S3 (the aws/s3 key). The artifacts are stored in an S3 bucket. When the pipeline runs, the CloudFormation actions fail with an access denied error.\n\nWhich combination of actions must the DevOps engineer perform to resolve this error? (Choose two.)","question_images":[],"exam_id":23,"answer_description":"","timestamp":"2023-05-09 09:52:00","answer_images":[],"isMC":true,"topic":"1","answer":"BE","answers_community":["BE (80%)","13%","7%"],"choices":{"A":"Create an S3 bucket in each AWS account for the artifacts. Allow the pipeline to write to the S3 buckets. Create a CodePipeline S3 action to copy the artifacts to the S3 bucket in each AWS account. Update the CloudFormation actions to reference the artifacts S3 bucket in the production account.","C":"Create an AWS managed KMS key. Configure the KMS key policy to allow the development account and the production account to perform decrypt operations. Modify the pipeline to use the KMS key to encrypt artifacts.","B":"Create a customer managed KMS key. Configure the KMS key policy to allow the IAM roles used by the CloudFormation action to perform decrypt operations. Modify the pipeline to use the customer managed KMS key to encrypt artifacts.","D":"In the development account and in the production account, create an IAM role for CodePipeline. Configure the roles with permissions to perform CloudFormation operations and with permissions to retrieve and decrypt objects from the artifacts S3 bucket. In the CodePipeline account, configure the CodePipeline CloudFormation action to use the roles.","E":"In the development account and in the production account, create an IAM role for CodePipeline. Configure the roles with permissions to perform CloudFormation operations and with permissions to retrieve and decrypt objects from the artifacts S3 bucket. In the CodePipeline account, modify the artifacts S3 bucket policy to allow the roles access. Configure the CodePipeline CloudFormation action to use the roles."},"url":"https://www.examtopics.com/discussions/amazon/view/108791-exam-aws-certified-devops-engineer-professional-dop-c02/"},{"id":"XwhmMVJ3no5o8zkW62f2","answer_ET":"ADE","topic":"1","unix_timestamp":1683618060,"answer_images":[],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/108790-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_description":"","isMC":true,"question_id":27,"timestamp":"2023-05-09 09:41:00","question_text":"A company is using an organization in AWS Organizations to manage multiple AWS accounts. The company’s development team wants to use AWS Lambda functions to meet resiliency requirements and is rewriting all applications to work with Lambda functions that are deployed in a VPC. The development team is using Amazon Elastic File System (Amazon EFS) as shared storage in Account A in the organization.\n\nThe company wants to continue to use Amazon EFS with Lambda. Company policy requires all serverless projects to be deployed in Account B.\n\nA DevOps engineer needs to reconfigure an existing EFS file system to allow Lambda functions to access the data through an existing EFS access point.\n\nWhich combination of steps should the DevOps engineer take to meet these requirements? (Choose three.)","answer":"ADE","exam_id":23,"answers_community":["ADE (75%)","AEF (19%)","6%"],"choices":{"D":"Update the Lambda execution roles with permission to access the VPC and the EFS file system.","A":"Update the EFS file system policy to provide Account B with access to mount and write to the EFS file system in Account A.","B":"Create SCPs to set permission guardrails with fine-grained control for Amazon EFS.","F":"Configure the Lambda functions in Account B to assume an existing IAM role in Account A.","E":"Create a VPC peering connection to connect Account A to Account B.","C":"Create a new EFS file system in Account B. Use AWS Database Migration Service (AWS DMS) to keep data from Account A and Account B synchronized."},"discussion":[{"timestamp":"1684327920.0","content":"Selected Answer: ADE\nI got ADE","comment_id":"900150","upvote_count":"12","poster":"OrganizedChaos25"},{"timestamp":"1700182440.0","comment_id":"1072934","upvote_count":"7","content":"Selected Answer: ADE\nInitially, I thought of A,E,F. But after reading the docs I came to conclusion A,D,E is correct answer.\nE: https://docs.aws.amazon.com/lambda/latest/dg/configuration-filesystem.html#configuration-filesystem-cross-account\nA,D: https://docs.aws.amazon.com/lambda/latest/dg/configuration-filesystem.html#configuration-filesystem-permissions","poster":"learnwithaniket"},{"poster":"jamesf","comment_id":"1257287","upvote_count":"2","content":"Selected Answer: ADE\nShould be ADE\nVPC peering required.","timestamp":"1722233100.0"},{"poster":"dkp","content":"Selected Answer: ADE\nA,D,E is correct","upvote_count":"3","comment_id":"1195389","timestamp":"1713083160.0"},{"poster":"DanShone","content":"A,D,E is correct","timestamp":"1710606180.0","upvote_count":"3","comment_id":"1175092"},{"content":"Selected Answer: AEF\n1.need to update the file system plocy on efs to allow mounting the file system into account b\n2.need vpc peering between account account a and account b as the pre-requisite\n3.need to assume cross-account iam role to descibe the mounts so that a specific mount can be chosen","upvote_count":"1","timestamp":"1708478460.0","comment_id":"1155127","poster":"kyuhuck"},{"poster":"thanhnv142","comment_id":"1140911","content":"Selected Answer: ADE\nADE are correct: <The company wants to continue to use Amazon EFS with Lambda. Company policy requires all serverless projects to be deployed in Account B.> means we need assign relevant IAM policies to lambda in account b\nB: no mention of policy \nC: no mention of policy\nF: <assume an existing IAM role in Account A>: What role?","upvote_count":"5","timestamp":"1707127140.0"},{"poster":"a54b16f","comment_id":"1123571","timestamp":"1705344720.0","upvote_count":"5","content":"Selected Answer: ADE\nNOT F: account B will mount EFS and would read/write as a local folder. There is no way/no need to assume role. Option D would assign permission that allow account B to read/write the EFS."},{"comment_id":"1071865","content":"Selected Answer: ADE\nIt's ADE.","timestamp":"1700080440.0","upvote_count":"3","poster":"zain1258"},{"timestamp":"1699618920.0","poster":"hzhang","content":"Selected Answer: AEF\nD only works if both lamda function and EFS are in the same account.","upvote_count":"2","comment_id":"1067224","comments":[{"comment_id":"1071867","upvote_count":"1","timestamp":"1700080500.0","content":"When peering enabled between two VPCs, this is possible even if the function and EFS are in different account.","poster":"zain1258"}]},{"upvote_count":"3","timestamp":"1698485520.0","content":"Selected Answer: ADE\n1) Lambda in account a can get access directly to EFS using cross account policy on the efs.\n2) Access to the efs is via network, thats why vpc peering is needed.\n\nhttps://aws.amazon.com/blogs/storage/mount-amazon-efs-file-systems-cross-account-from-amazon-eks/","poster":"YR4591","comment_id":"1056088"},{"comment_id":"998868","timestamp":"1693866060.0","poster":"RVivek","content":"Selected Answer: AEF\nA & E are obvious answers.\nD is wrong Lamda execuation role is in account B. You cannot directly assign permission to that role . Instead you add AWS STS AssumeRole API call to your Lambda function's code in account B","upvote_count":"4"},{"poster":"sb333","comment_id":"956130","upvote_count":"4","timestamp":"1689734340.0","content":"Selected Answer: ADE\nhttps://docs.aws.amazon.com/efs/latest/ug/create-file-system-policy.html (Answer A)\nhttps://aws.amazon.com/blogs/compute/using-amazon-efs-for-aws-lambda-in-your-serverless-applications/ (Answer D)\nhttps://docs.aws.amazon.com/lambda/latest/dg/services-efs.html (Answer E)"},{"poster":"unknownuser123","comment_id":"954635","content":"Selected Answer: AEF\nAEF Makes more sense","upvote_count":"3","timestamp":"1689629460.0"},{"comment_id":"954069","comments":[{"upvote_count":"3","comment_id":"963178","timestamp":"1690326180.0","poster":"CirusD","content":"I am sure you didn't get 1000 if you got this answer wrong"},{"content":"Please provide supporting links, since the documentation points to ADE.\nhttps://docs.aws.amazon.com/efs/latest/ug/create-file-system-policy.html (Answer A)\nhttps://aws.amazon.com/blogs/compute/using-amazon-efs-for-aws-lambda-in-your-serverless-applications/ (Answer D)\nhttps://docs.aws.amazon.com/lambda/latest/dg/services-efs.html (Answer E)","upvote_count":"3","comment_id":"956129","poster":"sb333","comments":[{"comment_id":"956145","timestamp":"1689735600.0","upvote_count":"2","content":"Another support for D and not F.\nhttps://repost.aws/knowledge-center/access-efs-across-accounts\n\nThis talks about assigning IAM permissions on the account B side, with EFS located in account A. For Lambda, those IAM permissions are part of the execution role. There is nothing indicating the need for using roles from account A. Only an EFS file system policy in account A. And of course peering is needed between the two accounts.\n\nIf you did get 1000 points, and you selected AEF, this could have been one of those questions that did not count against your raw score. AWS will have some questions that are not included in your score, but are questions that may be new and are being evaluated.","poster":"sb333"}],"timestamp":"1689734280.0"},{"timestamp":"1700080620.0","comment_id":"1071869","poster":"zain1258","upvote_count":"1","content":"In exam there are a few questions that does not have any impact on your score. No matter you mark them right or wrong."}],"poster":"emupsx1","content":"The answer is AEF because:\nA few hours ago, I just finished the DOP-C02 exam.\nMy score is 1000 points.\nThis question has come up, I choose AEF.","timestamp":"1689588480.0","upvote_count":"4"},{"timestamp":"1689523440.0","content":"ADF for me","comment_id":"953456","upvote_count":"1","comments":[{"comment_id":"953458","timestamp":"1689523620.0","content":"E is wrong . All accounts in same VPC so, you cant do VPC peering.","poster":"ogwu2000","upvote_count":"1"}],"poster":"ogwu2000"},{"timestamp":"1684198020.0","content":"AEF are correct","upvote_count":"2","comment_id":"898798","poster":"devnv"},{"timestamp":"1684018620.0","upvote_count":"1","poster":"2pk","comments":[{"comments":[{"comment_id":"956124","content":"Explanation for answer D. https://aws.amazon.com/blogs/compute/using-amazon-efs-for-aws-lambda-in-your-serverless-applications/\n\"The execution role for Lambda function must provide access to the VPC and EFS.\"","upvote_count":"1","poster":"sb333","timestamp":"1689733800.0"}],"poster":"punj","upvote_count":"1","content":"what does access to VPC means in the context of Lamnda's IAM role? I think it should be AEF.","timestamp":"1689487320.0","comment_id":"953062"}],"comment_id":"897090","content":"A,D & E in my point of view\nOption A is required to allow Account B to mount and write to the EFS file system in Account A. This can be done by updating the EFS file system policy to allow access from the security group associated with the VPC in Account B.\n\nOption D is required to allow the Lambda function to access the VPC and the EFS file system. This can be done by updating the Lambda execution role with the required permissions. The Lambda execution role should be updated to include permissions to access the VPC in Account B and the EFS file system in Account A.\n\nOption E is required to allow traffic to flow between Account A and Account B. This can be done by creating a VPC peering connection between the VPC in Account B and the VPC in Account A that is associated with the EFS file system."},{"timestamp":"1683880680.0","content":"Selected Answer: AEF\nAEF makes more sense","comment_id":"895765","poster":"ParagSanyashiv","upvote_count":"2"},{"comment_id":"894287","poster":"Sazeka","timestamp":"1683744600.0","upvote_count":"4","content":"Selected Answer: ADF\n1. Need to update the file system policy on EFS to allow mounting the file system into Account B.\n## File System Policy\n$ cat file-system-policy.json\n{\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"elasticfilesystem:ClientMount\",\n\"elasticfilesystem:ClientWrite\"\n],\n\"Principal\": {\n\"AWS\": \"arn:aws:iam::<aws-account-id-A>:root\" # Replace with AWS account ID of EKS cluster\n}\n}\n]\n}\n2. Need VPC peering between Account A and Account B as the pre-requisite\n3. Need to assume cross-account IAM role to describe the mounts so that a specific mount can be chosen."},{"timestamp":"1683618060.0","upvote_count":"3","comment_id":"892901","poster":"Jeanphi72","content":"Selected Answer: ADE\nTo my knowledge: You can connect to Amazon EFS file systems from \nEC2 instances in other AWS regions using an inter-region VPC peering connection, and \nfrom on-premises servers using an AWS VPN connection."}]},{"id":"UKxc8jPOP3Yn68bNB3Su","unix_timestamp":1684198260,"url":"https://www.examtopics.com/discussions/amazon/view/109364-exam-aws-certified-devops-engineer-professional-dop-c02/","timestamp":"2023-05-16 02:51:00","answers_community":["B (100%)"],"exam_id":23,"question_text":"A media company has several thousand Amazon EC2 instances in an AWS account. The company is using Slack and a shared email inbox for team communications and important updates. A DevOps engineer needs to send all AWS-scheduled EC2 maintenance notifications to the Slack channel and the shared inbox. The solution must include the instances’ Name and Owner tags.\n\nWhich solution will meet these requirements?","answer":"B","isMC":true,"question_images":[],"answer_description":"","answer_images":[],"topic":"1","choices":{"A":"Integrate AWS Trusted Advisor with AWS Config. Configure a custom AWS Config rule to invoke an AWS Lambda function to publish notifications to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe a Slack channel endpoint and the shared inbox to the topic.","C":"Create an AWS Lambda function that sends EC2 maintenance notifications to the Slack channel and the shared inbox. Monitor EC2 health events by using Amazon CloudWatch metrics. Configure a CloudWatch alarm that invokes the Lambda function when a maintenance notification is received.","D":"Configure AWS Support integration with AWS CloudTrail. Create a CloudTrail lookup event to invoke an AWS Lambda function to pass EC2 maintenance notifications to Amazon Simple Notification Service (Amazon SNS). Configure Amazon SNS to target the Slack channel and the shared inbox.","B":"Use Amazon EventBridge to monitor for AWS Health events. Configure the maintenance events to target an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe an AWS Lambda function to the SNS topic to send notifications to the Slack channel and the shared inbox."},"discussion":[{"timestamp":"1728894540.0","poster":"dkp","content":"Selected Answer: B\nB is the answer","upvote_count":"2","comment_id":"1195391"},{"comment_id":"1140922","timestamp":"1722845400.0","upvote_count":"2","content":"Selected Answer: B\nB is correct: <eeds to send all AWS-scheduled EC2 maintenance notifications to the Slack channel and the shared inbox> means SNS\nC: no mention of SNS\nA: AWS trusted advisor has nothing to do here\nD: AWS Support is support plan. It has nothing to do here. so as AWS cloud trail","poster":"thanhnv142"},{"poster":"yuliaqwerty","content":"Answer is B","comment_id":"1118971","upvote_count":"1","timestamp":"1720631940.0"},{"content":"Yes it's B","timestamp":"1720049400.0","comment_id":"1113285","upvote_count":"1","poster":"sarlos"},{"upvote_count":"4","poster":"n_d1","timestamp":"1705841280.0","comment_id":"958347","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/health/latest/ug/cloudwatch-events-health.html"},{"poster":"Certified101","content":"Selected Answer: B\nB is correct","timestamp":"1705755600.0","comment_id":"957423","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: B\nB is the answer I got","timestamp":"1700232780.0","comment_id":"900152","poster":"OrganizedChaos25"},{"poster":"devnv","upvote_count":"1","timestamp":"1700103060.0","comment_id":"898802","content":"B is correct"}],"answer_ET":"B","question_id":28},{"id":"4KxA9NYitppty5JKWZpq","exam_id":23,"question_images":[],"topic":"1","answer_images":[],"timestamp":"2023-05-16 02:58:00","isMC":true,"answer_ET":"B","answer":"B","question_text":"An AWS CodePipeline pipeline has implemented a code release process. The pipeline is integrated with AWS CodeDeploy to deploy versions of an application to multiple Amazon EC2 instances for each CodePipeline stage.\n\nDuring a recent deployment, the pipeline failed due to a CodeDeploy issue. The DevOps team wants to improve monitoring and notifications during deployment to decrease resolution times.\n\nWhat should the DevOps engineer do to create notifications when issues are discovered?","discussion":[{"comment_id":"1140938","timestamp":"1722845820.0","content":"Selected Answer: B\nB is correct: <monitoring and notifications during deployment> means eventbridge and SNS\nA: cloudwatchlog has nothing to do here. This is use for continuous monitoring of AWS services\nC: cloudtrail is for account activities monitoring\nD: Inspector is for threat detection","upvote_count":"5","poster":"thanhnv142"},{"poster":"dkp","timestamp":"1728894720.0","comment_id":"1195395","upvote_count":"2","content":"Selected Answer: B\nB is correc"},{"timestamp":"1714297560.0","upvote_count":"2","poster":"YR4591","content":"Selected Answer: B\nIts B, They want to monitor issued DURING deployment, means near real time, so cloudwatch event will do the work.\n\nC is wrong for to reasons, first, cloudtrail alone can't trigger lambda without an event. Second, cloud trail logs are update in 5 minutes intervals, which means monitoring for the code deploy will not be during deployment.","comment_id":"1056098"},{"content":"Selected Answer: B\nB. Implement Amazon EventBridge for CodePipeline and CodeDeploy, create an AWS Lambda function to evaluate code deployment issues, and create an Amazon Simple Notification Service (Amazon SNS) topic to notify stakeholders of deployment issues.\n\nExplanation:\nAmazon EventBridge provides a serverless event bus that integrates with various AWS services. By implementing EventBridge for CodePipeline and CodeDeploy, the engineer can capture deployment events and trigger actions based on those events. Creating an AWS Lambda function allows for evaluating code deployment issues and performing custom actions. Additionally, creating an Amazon SNS topic provides a means to notify stakeholders of any deployment issues detected.","timestamp":"1703902920.0","comment_id":"938658","upvote_count":"3","poster":"haazybanj"},{"poster":"OrganizedChaos25","comment_id":"900157","upvote_count":"3","timestamp":"1700232900.0","content":"Selected Answer: B\nB is correct"},{"upvote_count":"1","content":"Yes it's B","timestamp":"1700103480.0","poster":"devnv","comment_id":"898805"}],"choices":{"C":"Implement AWS CloudTrail to record CodePipeline and CodeDeploy API call information, create an AWS Lambda function to evaluate code deployment issues, and create an Amazon Simple Notification Service (Amazon SNS) topic to notify stakeholders of deployment issues.","B":"Implement Amazon EventBridge for CodePipeline and CodeDeploy, create an AWS Lambda function to evaluate code deployment issues, and create an Amazon Simple Notification Service (Amazon SNS) topic to notify stakeholders of deployment issues.","A":"Implement Amazon CloudWatch Logs for CodePipeline and CodeDeploy, create an AWS Config rule to evaluate code deployment issues, and create an Amazon Simple Notification Service (Amazon SNS) topic to notify stakeholders of deployment issues.","D":"Implement Amazon EventBridge for CodePipeline and CodeDeploy, create an Amazon Inspector assessment target to evaluate code deployment issues, and create an Amazon Simple Notification Service (Amazon SNS) topic to notify stakeholders of deployment issues."},"unix_timestamp":1684198680,"question_id":29,"answer_description":"","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/109365-exam-aws-certified-devops-engineer-professional-dop-c02/"},{"id":"mnLgb9lMzVm34dRUXsc0","discussion":[{"comment_id":"950458","content":"Selected Answer: A\nA. Configure the application account’s deployment IAM role to have a trust relationship with the centralized DevOps account. Configure the trust relationship to allow the sts:AssumeRole action. Configure the application account’s deployment IAM role to have the required access to the EKS cluster. Configure the EKS cluster aws-auth ConfigMap to map the role to the appropriate system permissions.\n\nOptions B, C, and D are not correct because the centralized DevOps account’s deployment IAM role doesn't need to trust the application account, it's the other way around. The sts:AssumeRoleWithSAML action in option C is used for federation from a SAML 2.0 compliant identity provider and is not necessary in this scenario. Lastly, there's no need to have a trust relationship with the AWS Control Tower management account as in option D, as the interaction is directly between the DevOps account and the application account.","poster":"Certified101","timestamp":"1689234840.0","upvote_count":"10"},{"timestamp":"1707136500.0","upvote_count":"6","poster":"thanhnv142","content":"Selected Answer: A\nA is correct: <Unauthorized error during attempts to connect> means we need to setup relevant permissions and policies\n- A is correct because < AWS CodeBuild project that is set up in the centralized DevOps account>, so we should setup trust relationship on the account that has resources, which is the application account and allow codebuild from centralized account assume it\nB and C are wrong: we need to setup trust from the app account, not the centralized account.\nD: this option mentions control Tower, which is irrelevant","comment_id":"1141080"},{"poster":"jamesf","comment_id":"1259737","timestamp":"1722582060.0","upvote_count":"2","content":"Selected Answer: A\nA. Configure the application account’s deployment IAM role to have a trust relationship with the centralized DevOps account. \n- setup trust relationship on the account that has resources, which is the application account\n\nConfigure the trust relationship to allow the sts:AssumeRole action. \n- allow CodeBuild from centralized account assume it\n- CodeBuild is configured in Centralized DevOps account but not in application account.\n\nConfigure the application account’s deployment IAM role to have the required access to the EKS cluster. Configure the EKS cluster aws-auth ConfigMap to map the role to the appropriate system permissions.\n- the application account has access to the resources"},{"comment_id":"928755","poster":"tartarus23","timestamp":"1687290300.0","upvote_count":"3","content":"Selected Answer: A\n(A) This solution addresses the Unauthorized error by allowing the DevOps account to assume the IAM role in the application account that has the necessary permissions to access the EKS cluster. The other options don't provide the necessary cross-account permissions or correctly configure the roles for accessing EKS."},{"comments":[{"timestamp":"1700079240.0","content":"CodeBuild is configured in Centralized DevOps account not in application account.","upvote_count":"2","comment_id":"1071848","poster":"zain1258"}],"poster":"walkwolf3","upvote_count":"2","content":"B is correct.\nUnauthorized error happened from CodeBuild in Dev account to EKS cluster in application account, instead of reverse direction.","comment_id":"918253","timestamp":"1686227820.0"},{"content":"I'd like to add more, don't get the source and destination mixed up. Because the Application team must deploy resources in the Dev account. So, the source should be the Application team and the destination should be the Dev team.","timestamp":"1684876560.0","upvote_count":"2","poster":"2pk","comment_id":"905240"},{"timestamp":"1684847100.0","comment_id":"904930","poster":"PhuocT","content":"Selected Answer: A\nA is correct","upvote_count":"1"},{"content":"A is correct Answer","comment_id":"897413","timestamp":"1684054620.0","poster":"ParagSanyashiv","upvote_count":"1"},{"poster":"2pk","timestamp":"1684013580.0","comment_id":"897065","upvote_count":"3","content":"Answer is A.\nIn the source AWS account, the IAM role used by the CI/CD pipeline should have permissions to access the source code repository, build artifacts, and any other resources required for the build process.\nIn the destination AWS accounts, the IAM role used for deployment should have permissions to access the AWS resources required for deploying the application, such as EC2 instances, RDS databases, S3 buckets, etc. The exact permissions required will depend on the specific resources being used by the application.\nthe IAM role used for deployment in the destination accounts should also have permissions to assume the IAM role for deployment in the centralized DevOps account. This is typically done using an IAM role trust policy that allows the destination account to assume the DevOps account role."}],"answer_images":[],"answer_description":"","question_images":[],"answers_community":["A (100%)"],"question_id":30,"question_text":"A global company manages multiple AWS accounts by using AWS Control Tower. The company hosts internal applications and public applications.\n\nEach application team in the company has its own AWS account for application hosting. The accounts are consolidated in an organization in AWS Organizations. One of the AWS Control Tower member accounts serves as a centralized DevOps account with CI/CD pipelines that application teams use to deploy applications to their respective target AWS accounts. An IAM role for deployment exists in the centralized DevOps account.\n\nAn application team is attempting to deploy its application to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster in an application AWS account. An IAM role for deployment exists in the application AWS account. The deployment is through an AWS CodeBuild project that is set up in the centralized DevOps account. The CodeBuild project uses an IAM service role for CodeBuild. The deployment is failing with an Unauthorized error during attempts to connect to the cross-account EKS cluster from CodeBuild.\n\nWhich solution will resolve this error?","exam_id":23,"unix_timestamp":1684013580,"answer_ET":"A","timestamp":"2023-05-13 23:33:00","topic":"1","choices":{"A":"Configure the application account’s deployment IAM role to have a trust relationship with the centralized DevOps account. Configure the trust relationship to allow the sts:AssumeRole action. Configure the application account’s deployment IAM role to have the required access to the EKS cluster. Configure the EKS cluster aws-auth ConfigMap to map the role to the appropriate system permissions.","B":"Configure the centralized DevOps account’s deployment IAM role to have a trust relationship with the application account. Configure the trust relationship to allow the sts:AssumeRole action. Configure the centralized DevOps account’s deployment IAM role to allow the required access to CodeBuild.","D":"Configure the application account’s deployment IAM role to have a trust relationship with the AWS Control Tower management account. Configure the trust relationship to allow the sts:AssumeRole action. Configure the application account’s deployment IAM role to have the required access to the EKS cluster. Configure the EKS cluster aws-auth ConfigMap to map the role to the appropriate system permissions.","C":"Configure the centralized DevOps account’s deployment IAM role to have a trust relationship with the application account. Configure the trust relationship to allow the sts:AssumeRoleWithSAML action. Configure the centralized DevOps account’s deployment IAM role to allow the required access to CodeBuild."},"url":"https://www.examtopics.com/discussions/amazon/view/109182-exam-aws-certified-devops-engineer-professional-dop-c02/","isMC":true,"answer":"A"}],"exam":{"isMCOnly":true,"numberOfQuestions":355,"isImplemented":true,"id":23,"isBeta":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified DevOps Engineer - Professional DOP-C02","provider":"Amazon"},"currentPage":6},"__N_SSP":true}