{"pageProps":{"questions":[{"id":"p2ammYNQ0gwJgiz6vrKl","choices":{"D":"Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to all S3 buckets in the account.","C":"Embed an access key and a secret key in the Lambda function’s code to grant the required IAM permissions for read access to the S3 bucket.","A":"Apply an S3 bucket policy that grants read access to the S3 bucket.","B":"Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to the S3 bucket."},"question_text":"A company has an AWS Lambda function that needs read access to an Amazon S3 bucket that is located in the same AWS account.\n\nWhich solution will meet these requirements in the MOST secure manner?","answers_community":["B (100%)"],"question_id":231,"discussion":[{"upvote_count":"9","poster":"kruasan","comments":[{"content":"The other options are less secure:\nA. A bucket policy grants open access to a resource. It is a less granular way to provide access and grants more privilege than needed.\nC. Embedding access keys in code is extremely insecure and against best practices. The keys provide full access and are at major risk of compromise if the code leaks.\nD. Granting access to all S3 buckets provides far too much privilege if only one bucket needs access. It greatly expands the impact if compromised.","poster":"kruasan","upvote_count":"4","timestamp":"1698603600.0","comment_id":"884504"}],"content":"Selected Answer: B\nThis solution satisfies the needs in the most secure manner:\n• An IAM role provides temporary credentials to the Lambda function to access AWS resources. The function does not have persistent credentials. \n• The IAM policy grants least privilege access by specifying read access only to the specific S3 bucket needed. Access is not granted to all S3 buckets.\n• If the Lambda function is compromised, the attacker would only gain access to the one specified S3 bucket. They would not receive broad access to resources.","comment_id":"884503","timestamp":"1698603600.0"},{"upvote_count":"1","comment_id":"1126399","timestamp":"1721353320.0","poster":"Rido4good","content":"Has anyone passed this exam, choosing the wrong answers from ExamTopics? or what's the reason for the confusion???"},{"upvote_count":"3","content":"Selected Answer: B\nB is correct.","timestamp":"1720156320.0","poster":"bbgun891404021","comment_id":"1114326"},{"comment_id":"1028804","content":"Answer=B","poster":"TMabs","upvote_count":"2","timestamp":"1712661360.0"},{"poster":"antropaws","comment_id":"907086","content":"Selected Answer: B\nB is correct.","upvote_count":"2","timestamp":"1700984400.0"},{"poster":"Dr_Chomp","content":"Selected Answer: B\nyou dont want to grant access to all S3 buckets (which is answer D) - only the one identified (so answer A)","upvote_count":"2","comment_id":"867851","timestamp":"1697079000.0"},{"comment_id":"827396","content":"Selected Answer: B\nB is only for one bucket and you want to use Role based security here.","timestamp":"1693678800.0","poster":"Steve_4542636","upvote_count":"2"},{"comment_id":"818606","timestamp":"1692744900.0","upvote_count":"1","poster":"Ja13","content":"Selected Answer: B\nC, it says MOST secure manner, so only to one bucket"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-permissions.html","upvote_count":"2","timestamp":"1692637380.0","comment_id":"817033","poster":"Joxtat"},{"timestamp":"1692356880.0","poster":"kpato87","comment_id":"812983","upvote_count":"4","content":"Selected Answer: B\nThis is the most secure and recommended way to provide an AWS Lambda function with access to an S3 bucket. It involves creating an IAM role that the Lambda function assumes, and attaching an IAM policy to the role that grants the necessary permissions to read from the S3 bucket."},{"timestamp":"1692334260.0","comment_id":"812737","upvote_count":"3","content":"Selected Answer: B\nB. Least of privilege","poster":"Joan111edu"}],"isMC":true,"exam_id":31,"answer_images":[],"answer_description":"","answer":"B","answer_ET":"B","unix_timestamp":1676703060,"topic":"1","question_images":[],"timestamp":"2023-02-18 07:51:00","url":"https://www.examtopics.com/discussions/amazon/view/99756-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"TvHFbR1Mtj5eaIo5pW7E","question_images":[],"discussion":[{"timestamp":"1666624920.0","content":"Selected Answer: A\nagree with A,\nGlobal Accelerator has automatic failover and is perfect for this scenario with VoIP\nhttps://aws.amazon.com/global-accelerator/faqs/","upvote_count":"59","comment_id":"703159","poster":"Six_Fingered_Jose","comments":[{"comment_id":"1023411","upvote_count":"4","poster":"awashenko","timestamp":"1696275060.0","content":"I also agree A after reading this link."},{"comment_id":"1052999","comments":[{"content":"This is the best case for A to be an answer. Cloudfront is great but for HTTP use cases.","comment_id":"1174028","poster":"TilTil","upvote_count":"2","timestamp":"1710475260.0"}],"upvote_count":"10","poster":"bnagaraja9099","timestamp":"1698160740.0","content":"A - Global Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP, as well as for HTTP use cases that specifically require static IP addresses or deterministic, fast regional failover. Both services integrate with AWS Shield for DDoS protection."},{"timestamp":"1666935000.0","upvote_count":"7","comment_id":"706158","comments":[{"upvote_count":"2","comment_id":"780515","content":"This option does not meet the requirements because AWS Global Accelerator is only used to route traffic to the optimal AWS Region, it does not provide automatic failover between regions.","timestamp":"1674083280.0","poster":"bullrem","comments":[{"content":"Instant regional failover: AWS Global Accelerator automatically checks the health of your applications and routes user traffic only to healthy application endpoints. If the health status changes or you make configuration updates, AWS Global Accelerator reacts instantaneously to route your users to the next available endpoint.","upvote_count":"10","timestamp":"1677655500.0","poster":"sachin","comment_id":"825603"}]}],"poster":"BoboChow","content":"Thank you for your link, it make me consolidate A."},{"comment_id":"968126","poster":"ElaineRan","upvote_count":"3","content":"Thank you, the link also helps me to know the differences between Global Acc and CloudFront.","timestamp":"1690808220.0"}]},{"timestamp":"1667583240.0","upvote_count":"39","poster":"mouhannadhaj","content":"Selected Answer: A\nCloudFront uses Edge Locations to cache content while Global Accelerator uses Edge Locations to find an optimal pathway to the nearest regional endpoint. CloudFront is designed to handle HTTP protocol meanwhile Global Accelerator is best used for both HTTP and non-HTTP protocols such as TCP and UDP. so i think A is a better answer","comment_id":"711284"},{"timestamp":"1738744860.0","upvote_count":"1","content":"Selected Answer: A\nC is not correct, because Network Loadbalancer is already integrated with Route 53.","comment_id":"1351770","poster":"lubomir.tomecek"},{"content":"Selected Answer: A\ni full understand this is a use case for global accelerator but can anyone tell me why you need a NLB over an ALB here?","poster":"adamatic","timestamp":"1738594380.0","upvote_count":"1","comments":[{"content":"oh i see, ALB is for HTTP/HTTPS","upvote_count":"1","comment_id":"1350950","poster":"adamatic","timestamp":"1738595160.0"}],"comment_id":"1350938"},{"comment_id":"1347239","timestamp":"1737953460.0","content":"Selected Answer: A\nThe Nature of the application VoIP needs NLB and Global Accelerator + an auto scalling","poster":"AfricanCloudGuru","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\ncloudfront doenst provide autoatic failover","timestamp":"1735913640.0","comment_id":"1336044","poster":"ylanzzz"},{"upvote_count":"1","poster":"satyaammm","timestamp":"1735577220.0","content":"Selected Answer: A\nNLB is suitable for UDP and global accelerator is also suitable for UDP.","comment_id":"1334261"},{"timestamp":"1735132860.0","content":"Selected Answer: A\nThe correct answer is A: Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Use the NLB as an AWS Global Accelerator endpoint in each Region.\nKey reasons:\n\nNLB supports UDP protocol (required for VoIP), while ALB only handles HTTP/HTTPS\nGlobal Accelerator provides:\n\nAutomatic routing to lowest latency region\nBuilt-in cross-region failover\nOptimized network performance via AWS global network","comment_id":"1331548","upvote_count":"1","poster":"AbhishekCloudEngg"},{"poster":"minhhieu_tech_1","timestamp":"1733824860.0","upvote_count":"1","comment_id":"1324477","content":"Selected Answer: A\nCloudfront is not support UDP Protocol. So maybe C answer isnt correct."},{"comment_id":"1314509","content":"Selected Answer: C\nI think this is not a very well written one. What we need:\n1, Network Service that handles latency based policy and cross region failover -> Route53\n2, A component that route traffic to ASG that are compatible with UDP -> Network Load Balancer.","poster":"EzKkk","timestamp":"1732003380.0","upvote_count":"1"},{"comment_id":"1261914","poster":"Bobby3","upvote_count":"1","timestamp":"1722998220.0","content":"Selected Answer: C\nAws GA is most suitable for https."},{"upvote_count":"2","poster":"bishtr3","timestamp":"1720887360.0","content":"A : UDP so NLB and Global Accelerator reduces the number of hops by providing packets to travel over congestion free AWS global network.\nGlobal Accelerator supported end point : ALB,NLB,EC2 & Elastic IP address","comment_id":"1247376"},{"content":"Selected Answer: A\nyou can configure a Network Load Balancer (NLB) in each AWS Region to address your on-premises endpoints. Then you can register the NLBs as endpoints in your AWS Global Accelerator configuration.\n\nhttps://aws.amazon.com/global-accelerator/faqs/","poster":"jatric","timestamp":"1719553440.0","upvote_count":"2","comment_id":"1238557"},{"poster":"ManikRoy","upvote_count":"2","comment_id":"1183405","content":"Selected Answer: A\nUDP Connection :- So NLB \nRouting to region having lowest latency and also with Automated failover, Also non-HTTP use cases, such as gaming (UDP), or Voice over IP - Global Accelerator","timestamp":"1711464960.0"},{"comment_id":"1182916","upvote_count":"3","timestamp":"1711418340.0","poster":"TruthWS","content":"A is correct because Accelerator endpoint usefull more than route53"},{"comment_id":"1182599","upvote_count":"2","timestamp":"1711380600.0","poster":"biggybear","content":"Selected Answer: A\nCorrect as Global accelerator is most preferred for TCP and UDP"},{"content":"A ia correct","poster":"biggybear","timestamp":"1711380540.0","upvote_count":"1","comment_id":"1182597"}],"isMC":true,"topic":"1","answer_description":"","choices":{"B":"Deploy an Application Load Balancer (ALB) and an associated target group. Associate the target group with the Auto Scaling group. Use the ALB as an AWS Global Accelerator endpoint in each Region.","C":"Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Create an Amazon Route 53 latency record that points to aliases for each NLB. Create an Amazon CloudFront distribution that uses the latency record as an origin.","A":"Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Use the NLB as an AWS Global Accelerator endpoint in each Region.","D":"Deploy an Application Load Balancer (ALB) and an associated target group. Associate the target group with the Auto Scaling group. Create an Amazon Route 53 weighted record that points to aliases for each ALB. Deploy an Amazon CloudFront distribution that uses the weighted record as an origin."},"answer_ET":"A","answers_community":["A (80%)","C (20%)","0%"],"unix_timestamp":1665411540,"answer_images":[],"exam_id":31,"answer":"A","question_text":"A company provides a Voice over Internet Protocol (VoIP) service that uses UDP connections. The service consists of Amazon EC2 instances that run in an Auto Scaling group. The company has deployments across multiple AWS Regions.\nThe company needs to route users to the Region with the lowest latency. The company also needs automated failover between Regions.\nWhich solution will meet these requirements?","question_id":232,"timestamp":"2022-10-10 16:19:00","url":"https://www.examtopics.com/discussions/amazon/view/85029-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"eHGuCLj22gwqr2AYIYNE","question_text":"A company hosts a web application on multiple Amazon EC2 instances. The EC2 instances are in an Auto Scaling group that scales in response to user demand. The company wants to optimize cost savings without making a long-term commitment.\n\nWhich EC2 instance purchasing option should a solutions architect recommend to meet these requirements?","discussion":[{"comment_id":"1091034","timestamp":"1702036680.0","upvote_count":"13","content":"Selected Answer: C\nThere is a little trap here, because in the way this question is asked, both B and C are true since we don't know if it's production or not.\n\nIn a production environment C is absolutely forbidden and B is the good solution, we even have questions in this dump about this case.\n\nIn a dev environment spot instances are good if you don't care about stability so C can be a good answer.\n\nSince this question is all about cost, let's go for the stingy rat solution, spot instances are cheaper, so C is correct.","poster":"Mikado211"},{"timestamp":"1711630560.0","content":"Selected Answer: C\nBy using a mix of On-Demand Instances and Spot Instances, the company can leverage the cost-effectiveness of Spot Instances for parts of their workload while ensuring the availability and reliability of On-Demand Instances for critical components. This approach allows for cost optimization without sacrificing performance or reliability.","poster":"Uzbekistan","upvote_count":"8","comment_id":"1184771"},{"timestamp":"1711214580.0","poster":"ExamGuru727","upvote_count":"3","comment_id":"1181054","content":"Selected Answer: C\nOn-demand + spot for additional capacity will save costs."},{"comment_id":"1137725","poster":"thewalker","timestamp":"1706800500.0","content":"Selected Answer: B\nOn-Demand.","upvote_count":"1"},{"comment_id":"1093137","content":"Any one have dumps","poster":"Krishhhh","upvote_count":"1","timestamp":"1702275180.0"},{"content":"Selected Answer: C\nIt's about COST, not operational efficiency for this question :) C is correct","comment_id":"1056138","upvote_count":"5","poster":"beginnercloud","timestamp":"1698491460.0"},{"content":"Selected Answer: C\nA mix of On-Demand Instances to handle baseline workload and Spot Instances to handle excess workload.","timestamp":"1696314360.0","upvote_count":"5","comment_id":"1023664","poster":"TariqKipkemei"},{"content":"Exam topic is not free anymore. Anyone has free access ?","comments":[{"timestamp":"1711888980.0","poster":"Kaula","comments":[{"comment_id":"1273736","timestamp":"1724808840.0","poster":"AWSSURI","content":"Now its upto question 250 and im pretty sure one day they will ask 100 dollars for all of 900 questions","upvote_count":"2"}],"content":"Free up to question 400, from 401 you have to pay","comment_id":"1186784","upvote_count":"1"},{"upvote_count":"3","poster":"soewailin","comment_id":"1026045","timestamp":"1696550220.0","content":"for now though, I have still access."}],"comment_id":"1012270","upvote_count":"1","poster":"Kt","timestamp":"1695211440.0"},{"content":"Selected Answer: C\nBy combining On-Demand Instances for steady-state workloads or critical components and Spot Instances for less critical or burstable workloads, you can achieve a balance between cost savings and performance. This strategy allows you to optimize costs without making a long-term commitment, as Spot Instances provide cost savings without the need for upfront payments or long-term contracts.","upvote_count":"4","comment_id":"981998","poster":"Damdom","timestamp":"1692135120.0"},{"content":"Selected Answer: C\nIt's about COST, not operational efficiency for this question.","comment_id":"912570","upvote_count":"4","timestamp":"1685685960.0","poster":"Abrar2022"},{"content":"Selected Answer: C\nAutoscaling with ALB / scale up on demand using on demand and spot instance combination makes sense. Reserved will not fit the no-long term commitment clause.","comment_id":"857442","poster":"kraken21","upvote_count":"2","timestamp":"1680298800.0"},{"poster":"WherecanIstart","content":"Selected Answer: C\nWithout commitment....Spot instances","timestamp":"1679635620.0","comment_id":"848989","upvote_count":"2"},{"poster":"cegama543","content":"Selected Answer: B\nIf the company wants to optimize cost savings without making a long-term commitment, then using only On-Demand Instances may not be the most cost-effective option. Spot Instances can be significantly cheaper than On-Demand Instances, but they come with the risk of being interrupted if the Spot price increases above your bid price. If the company is willing to accept this risk, a mix of On-Demand Instances and Spot Instances may be the best option to optimize cost savings while maintaining the desired level of scalability.\n\nHowever, if the company wants the most predictable pricing and does not want to risk instance interruption, then using only On-Demand Instances is a good choice. It ultimately depends on the company's priorities and risk tolerance.","comment_id":"838345","upvote_count":"3","comments":[{"upvote_count":"3","content":"First, the question is about cost, cost, cost. Second, answer C is \"a mix of on-demand and spot instances\"; they could still use on-demand if spot is not available.","timestamp":"1703849820.0","poster":"pentium75","comment_id":"1108639"}],"timestamp":"1678743960.0"},{"poster":"Steve_4542636","comment_id":"827398","content":"Selected Answer: C\nIt's about COST, not operational efficiency for this question.","upvote_count":"2","timestamp":"1677788700.0"},{"comment_id":"818521","timestamp":"1677106920.0","content":"Selected Answer: C\nShould be C","poster":"Samuel03","upvote_count":"2"},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html","upvote_count":"2","timestamp":"1676999340.0","comment_id":"816900","poster":"bdp123"},{"comment_id":"816725","timestamp":"1676992860.0","upvote_count":"2","content":"Selected Answer: C\nC - WEB apps , mostly Stateless , and ASG support OnDemand and Spot mix , in fact , you can prioritize to have Ondemand , before it uses Spot > https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-template-spot-instances.html","poster":"AlmeroSenior"},{"upvote_count":"2","poster":"designmood22","content":"Selected Answer: C\nAnswer : C. A mix of On-Demand Instances and Spot Instances","timestamp":"1676991180.0","comment_id":"816693"},{"upvote_count":"2","content":"Selected Answer: C\nTo optimize cost savings without making a long-term commitment, a mix of On-Demand Instances and Spot Instances would be the best EC2 instance purchasing option to recommend.\nBy combining On-Demand and Spot Instances, the company can take advantage of the cost savings offered by Spot Instances during periods of low demand while maintaining the reliability and stability of On-Demand Instances during periods of high demand. This provides a cost-effective solution that can scale with user demand without making a long-term commitment.","poster":"LuckyAro","timestamp":"1676958840.0","comment_id":"816264"},{"poster":"NolaHOla","content":"In this scenario, a mix of On-Demand Instances and Spot Instances is the most cost-effective option, as it can provide significant cost savings while maintaining application availability. The Auto Scaling group can be configured to launch Spot Instances when the demand is high and On-Demand Instances when demand is low or when Spot Instances are not available. This approach provides a balance between cost savings and reliability.","comment_id":"815451","timestamp":"1676906700.0","upvote_count":"5"},{"comment_id":"814745","poster":"minglu","timestamp":"1676859720.0","upvote_count":"4","content":"In my opinion, it is C, on demand instances and spot instances can be in a single auto scaling group."}],"url":"https://www.examtopics.com/discussions/amazon/view/100006-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2023-02-20 03:22:00","question_id":233,"exam_id":31,"answer_images":[],"answer":"C","isMC":true,"answers_community":["C (94%)","6%"],"question_images":[],"unix_timestamp":1676859720,"answer_description":"","answer_ET":"C","topic":"1","choices":{"D":"A mix of On-Demand Instances and Reserved Instances","A":"Dedicated Instances only","C":"A mix of On-Demand Instances and Spot Instances","B":"On-Demand Instances only"}},{"id":"G5CKRsYqZc1h53J3oss5","exam_id":31,"isMC":true,"answer_images":[],"answer_description":"","choices":{"B":"Signed URLs","E":"AWS Secrets Manager","A":"Signed cookies","C":"AWS AppSync","D":"JSON Web Token (JWT)"},"url":"https://www.examtopics.com/discussions/amazon/view/99831-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","timestamp":"2023-02-18 15:51:00","discussion":[{"comment_id":"818276","timestamp":"1692724440.0","content":"Selected Answer: AB\nI thought that option A was totally wrong, because the question mentions \"HTTP client does not support cookies\". However it is right, along with option B. Check the link bellow, first paragraph. \nhttps://aws.amazon.com/blogs/media/secure-content-using-cloudfront-functions/","comments":[{"content":"Thanks for this! What a tricky question. If the client doesn't support cookies, THEN they use the signed S3 Urls.","comment_id":"827406","upvote_count":"11","timestamp":"1693679400.0","comments":[{"poster":"AAAWrekng","content":"LOL, like the old question, in my hand I have 2 coins, and they equal 15 cents, one of them is not a nickel. What are the coins","comment_id":"1049195","timestamp":"1713660180.0","upvote_count":"6"}],"poster":"Steve_4542636"},{"comment_id":"1166639","poster":"bujuman","content":"Plus, Customers can choose to use either one or both, depending on the use case.\nThanks for this share !","upvote_count":"3","timestamp":"1725549300.0"}],"poster":"leoattf","upvote_count":"29"},{"poster":"johnmcclane78","comments":[{"poster":"pentium75","content":"So you want to 'distribute the signed URL to the users who are unable to change the hardcoded URL'?","comment_id":"1108641","upvote_count":"2","timestamp":"1719654060.0"},{"upvote_count":"5","poster":"ONS_KH","content":"This is the response of chatgpt isnt it ? Pay attention ! it doesn't always give the right answer","comment_id":"1048213","timestamp":"1713554460.0"}],"content":"B. Signed URLs - This method allows the media company to control who can access the video content by creating a time-limited URL with a cryptographic signature. This URL can be distributed to the users who are unable to change the hardcoded URLs they are using for access, and they can access the content without needing to support cookies.\n\nD. JSON Web Token (JWT) - This method allows the media company to control who can access the video content by creating a secure token that contains user authentication and authorization information. This token can be distributed to the users who are using a custom HTTP client that does not support cookies. The users can include this token in their requests to access the content without needing to support cookies.\n\nTherefore, options B and D are the correct answers.\n\nOption A (Signed cookies) would not work for users who are using a custom HTTP client that does not support cookies. Option C (AWS AppSync) is not relevant to the requirement of securing video content. Option E (AWS Secrets Manager) is a service used for storing and retrieving secrets, which is not relevant to the requirement of securing video content.","timestamp":"1693915920.0","comment_id":"829961","upvote_count":"21"},{"poster":"Dantecito","timestamp":"1738714440.0","content":"Selected Answer: AB\nSigned cookies, signed URLs, and JSON web token (JWT) are Amazon Cloudfront authentication methods. But as the question says with the least possible impact for users, I would go with AB since D requires using Lambda@Edge and I suppose it has more impact to the users than the first two.","comment_id":"1351617","upvote_count":"1"},{"content":"Selected Answer: BD\nB. Signed URLs: Signed URLs allow you to control access to your content in CloudFront by providing URLs that are valid only for a specified duration. This means users can access the content using the same URLs they have hardcoded, without the need for cookies or special client support.\n\nD. JSON Web Token (JWT): JSON Web Tokens (JWTs) can be used to control access to resources by embedding authentication and authorization information in the token itself. Users can include the JWT in the request headers, allowing access to be controlled without relying on cookies. This approach doesn't require changes to hardcoded URLs and can be integrated into custom HTTP clients.","poster":"Uzbekistan","comment_id":"1184780","timestamp":"1727522220.0","upvote_count":"1"},{"content":"Selected Answer: AB\na little tricky but you have to \"control\" access, ok dont support cookies, so put signed cookies.","comment_id":"1142555","upvote_count":"2","timestamp":"1722967680.0","poster":"lostmagnet001"},{"content":"so how many marks do you get if you get 1 wrong","upvote_count":"5","comment_id":"1139890","poster":"ray320x","timestamp":"1722751320.0"},{"content":"Selected Answer: AB\nIf you have gotten this far and got THIS trick question right then you are going to make it! Good Luck!","timestamp":"1721251380.0","upvote_count":"6","poster":"awsgeek75","comment_id":"1125415"},{"upvote_count":"16","poster":"pentium75","comment_id":"1108643","timestamp":"1719654180.0","content":"Selected Answer: AB\n'SOME are using a client that does not support cookies' -> use signed URLs\n'SOME are unable to change the hardcoded URLs' -> used signed cookies"},{"timestamp":"1719409860.0","comment_id":"1106159","upvote_count":"2","content":"Selected Answer: AB\nSigned URLs and signed cookies are the most suitable options. They can effectively address the requirements of both users with custom HTTP clients and those with hardcoded URLs.","poster":"ale_brd_111"},{"upvote_count":"1","content":"B & E - B. Signed URLs: This allows you to generate time-limited URLs with a signature that grants temporary access to specific resources in your S3 bucket. It doesn't rely on cookies and can be generated for users without requiring any changes to their HTTP client or hardcoded URLs. This method provides fine-grained control over access to your content.\n\nE. AWS Secrets Manager: While AWS Secrets Manager can be useful for managing and rotating secrets, it is not directly related to securing S3 content in the context of the question. It's not one of the primary methods for securing access to S3 objects.","timestamp":"1712300400.0","poster":"prabhjot","comment_id":"1025343"},{"comment_id":"1023675","timestamp":"1712126220.0","upvote_count":"4","poster":"TariqKipkemei","content":"Selected Answer: AB\nTo secure streaming video content from Amazon CloudFront, two methods are available: signed cookies or signed URLs. Customers can choose to use either one or both, depending on the use case."},{"timestamp":"1710702060.0","upvote_count":"2","content":"AB - https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html","comment_id":"1009967","poster":"tabbyDolly"},{"poster":"Guru4Cloud","comments":[{"comment_id":"999772","upvote_count":"2","timestamp":"1709668440.0","content":"No good\nSigned cookies require client support and may impact users.\n\nAWS AppSync and Secrets Manager do not help address the specific access requirements.\n\nGood\n\n\nSo Signed URLs and JWTs allow securing access to S3 content with minimal impact to users, meeting the requirements.","poster":"Guru4Cloud"}],"upvote_count":"3","timestamp":"1709668380.0","comment_id":"999771","content":"Selected Answer: BD\nB and D are the correct options for meeting the requirements with the least impact to users.\n\nSigned URLs allow access to individual objects in Amazon S3 for a specified time period without requiring cookies. This allows the custom HTTP client users to access content.\n\nJSON Web Tokens (JWT) allow users to get temporary access tokens that can be passed in requests. This allows users with hardcoded URLs to access content without updating URLs."},{"poster":"riccardoto","upvote_count":"2","content":"Selected Answer: BD\nI understand why many users here are voting AB, but in my opinion BD is more correct.\nUsing JWT or signed urls will work both for users that cannot use cookies or cannot change the url.","comment_id":"974735","timestamp":"1707319620.0"},{"timestamp":"1705591800.0","poster":"katetel","upvote_count":"2","content":"Selected Answer: AB\nit's correct","comment_id":"955483"},{"timestamp":"1703149560.0","upvote_count":"2","poster":"MrAWSAssociate","content":"Selected Answer: CE\nThese are the right answers!","comment_id":"929144"},{"timestamp":"1701552120.0","comment_id":"913016","poster":"DrWatson","content":"Selected Answer: AB\n\"Some of the company’s users\" does not support cookies, then they'll use Signed URLs.\n\"Some of the company’s users\" are unable to change the hardcoded URLs, then they'll use Signed cookies.","upvote_count":"5"},{"comments":[{"poster":"ale_brd_111","upvote_count":"1","timestamp":"1719409800.0","comment_id":"1106156","content":"Nicely put"},{"upvote_count":"3","poster":"kruasan","content":"C. AWS AppSync - This is for building data-driven apps with real-time and offline capabilities. It does not directly help with securing streaming content.\nD. JSON Web Token (JWT) - Although JWTs can be used for authorization, they would require the client to get a token and validate/check access on the server for each request. This does not work for hardcoded URLs and minimizes impact.\nE. AWS Secrets Manager - This service is for managing secrets, not for controlling access to resources. It would not meet the requirements.","comment_id":"884509","timestamp":"1698604620.0"}],"timestamp":"1698604560.0","upvote_count":"5","content":"Selected Answer: AB\nSigned cookies would allow the media company to authorize access to related content (like HLS video segments) with a single signature, minimizing implementation overhead. This works for users that can support cookies.\nSigned URLs would allow the media company to sign each URL individually to control access, supporting users that cannot use cookies. By embedding the signature in the URL, existing hardcoded URLs would not need to change.","poster":"kruasan","comment_id":"884508"},{"comment_id":"874181","poster":"Shrestwt","timestamp":"1697671380.0","content":"A. Signed cookies: CloudFront signed cookies allow you to control who can access your content when you don't want to change your current URLs.\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-cookies.html\n\nB. Signed URLs: This method allows the media company to control who can access the video content by creating a time-limited URL with a cryptographic signature.","upvote_count":"2"},{"content":"Selected Answer: AB\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-choosing-signed-urls-cookies.html","timestamp":"1696833300.0","poster":"ahilan26","upvote_count":"3","comment_id":"865322"},{"content":"Some of the company’s users are using a custom HTTP client that does not support cookies.\n**Singned URLS\n\n Some of the company’s users are unable to change the hardcoded URLs that they are using for access. **Signed cookies","poster":"CapJackSparrow","upvote_count":"6","timestamp":"1694718240.0","comment_id":"839288"},{"timestamp":"1693649160.0","upvote_count":"5","comment_id":"826814","content":"Selected Answer: AB\nhttps://aws.amazon.com/vi/blogs/media/awse-protecting-your-media-assets-with-token-authentication/\nJSON Web Token (JWT) need using with Lambda@Edge","poster":"TungPham"},{"comment_id":"826032","upvote_count":"1","content":"Selected Answer: BD\nb d seems good","timestamp":"1693575240.0","poster":"HaineHess"},{"upvote_count":"2","comments":[{"comment_id":"868521","timestamp":"1697126280.0","poster":"FFO","content":"AB is wrong, your point that cookies are disabled eliminates the use of signed cookies. The hard coding eliminates the use of signed URLs. so AB totally eliminated. read the article further not just the first few lines, the read up signed URLs","upvote_count":"1"}],"timestamp":"1692718740.0","content":"Selected Answer: AB\nIt says some use a custom HTTP client that does not support cookies - those will use signed URLs which has precedence over cookies\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-choosing-signed-urls-cookies.html","comment_id":"818121","poster":"bdp123"},{"content":"Selected Answer: BD\nB, D\nPresigned URL uses the GET Parameter. That is, authentication is performed using Query String. The string containing Query String is a URI, not a URL. Therefore, B can be the answer.\nThe authentication method using JWT Token may use HTTP Header. This is not using cookies. Therefore, D can be the answer.\nPlease understand even if the sentence is awkward. I am not an English speaker.","poster":"pagom","comment_id":"817751","upvote_count":"1","timestamp":"1692695400.0"},{"upvote_count":"1","poster":"ChrisG1454","timestamp":"1692612060.0","comment_id":"816516","content":"Using Appsync is possible\nhttps://stackoverflow.com/questions/48495338/how-to-upload-file-to-aws-s3-using-aws-appsync"},{"comment_id":"816272","poster":"LuckyAro","comments":[{"timestamp":"1693649460.0","content":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-choosing-signed-urls-cookies.html","poster":"TungPham","upvote_count":"1","comment_id":"826826"}],"upvote_count":"1","timestamp":"1692590580.0","content":"Selected Answer: BD\nB. Signed URLs: Signed URLs provide access to specific objects in Amazon S3 and can be generated with an expiration time, which means that the URL will only be valid for a specific period. This method does not require the use of cookies or changes to the hardcoded URLs used by some of the users.\n\nD. JSON Web Token (JWT): JWT is a method for securely transmitting information between parties as a JSON object. It can be used to authenticate users and control access to resources, including streaming video content hosted in Amazon S3. This method does not require the use of cookies, and it can be used with custom HTTP clients that support header-based authentication.\n\nTherefore, the media company can use Signed URLs and JWT to control access to their streaming video content hosted in Amazon S3, without impacting the users who are unable to change the hardcoded URLs they are using or those using a custom HTTP client that does not support cookies."},{"comment_id":"815453","upvote_count":"2","timestamp":"1692538020.0","content":"I would go A and B based on the question's description","poster":"NolaHOla"},{"poster":"everfly","comment_id":"815365","timestamp":"1692534300.0","content":"Selected Answer: AB\nSigned URLs are URLs that grant temporary access to an S3 object. They include a signature that verifies the authenticity of the request, as well as an expiration date that limits the time during which the URL is valid. This solution will work for users who are using custom HTTP clients that do not support cookies.\n\nSigned cookies are similar to signed URLs, but they use cookies to grant temporary access to S3 objects. This solution will work for users who are unable to change the hardcoded URLs that they are using for access.","upvote_count":"4"},{"content":"The question says \"custom HTTP client that does not support cookies\". Then how can A be the answer ??","upvote_count":"2","poster":"Neha999","comment_id":"814068","timestamp":"1692441540.0"},{"comment_id":"813197","content":"A and B","upvote_count":"2","poster":"cloudbusting","timestamp":"1692365280.0"},{"poster":"cloudbusting","upvote_count":"1","comment_id":"813195","content":"Syned URL and cookies","timestamp":"1692365160.0"},{"timestamp":"1692363060.0","poster":"NolaHOla","comment_id":"813126","upvote_count":"2","content":"I would go for A,B given the question's description"}],"question_id":234,"answers_community":["AB (89%)","9%"],"answer_ET":"AB","unix_timestamp":1676731860,"question_text":"A media company uses Amazon CloudFront for its publicly available streaming video content. The company wants to secure the video content that is hosted in Amazon S3 by controlling who has access. Some of the company’s users are using a custom HTTP client that does not support cookies. Some of the company’s users are unable to change the hardcoded URLs that they are using for access.\n\nWhich services or methods will meet these requirements with the LEAST impact to the users? (Choose two.)","question_images":[],"answer":"AB"},{"id":"SRL6YAcdjYHqZCVFnEVN","topic":"1","answer_description":"","question_id":235,"choices":{"C":"Use AWS Database Migration Service (AWS DMS) to ingest the data. Use Amazon EMR to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.","B":"Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use AWS Glue to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.","A":"Use Amazon Kinesis Data Streams to stream the data. Use Amazon Kinesis Data Analytics to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.","E":"Use Amazon Kinesis Data Streams to stream the data. Use AWS Glue to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use the Amazon RDS query editor to query the transformed data from Amazon S3.","D":"Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use Amazon Kinesis Data Analytics to transform the data and to write the data to Amazon S3. Use the Amazon RDS query editor to query the transformed data from Amazon S3."},"discussion":[{"poster":"Steve_4542636","comment_id":"827413","upvote_count":"16","timestamp":"1693679880.0","content":"Selected Answer: AB\nOK, for B I did some research, https://docs.aws.amazon.com/glue/latest/dg/add-job-streaming.html\n\n\"You can create streaming extract, transform, and load (ETL) jobs that run continuously, consume data from streaming sources like Amazon Kinesis Data Streams, Apache Kafka, and Amazon Managed Streaming for Apache Kafka (Amazon MSK). The jobs cleanse and transform the data, and then load the results into Amazon S3 data lakes or JDBC data stores.\""},{"timestamp":"1696838040.0","poster":"Paras043","content":"But how can you transform data using kinesis data analytics ??","comments":[{"content":"See https://aws.amazon.com/kinesis/data-analytics/faqs/?nc=sn&loc=6","timestamp":"1699373700.0","comment_id":"891451","upvote_count":"3","poster":"luisgu"}],"upvote_count":"8","comment_id":"865352"},{"content":"Selected Answer: AB\nJust because C is not going to work a DE use RDS so totally illogical\n\nA & B seem to have redundant streaming, transformation and query steps so not sure if these are the right choices but CDE are completely wrong anyway!","comment_id":"1125420","upvote_count":"4","poster":"awsgeek75","timestamp":"1721251680.0"},{"timestamp":"1719708120.0","upvote_count":"4","content":"For A didn't know that Kinesis Analytics can transform the data as well:\nAmazon Kinesis Data Analytics provides built-in functions to filter, aggregate, and transform streaming data for advanced analytics. It processes streaming data with sub-second latencies, enabling you to analyze and respond to incoming data and streaming events in real time.","comment_id":"1109347","poster":"farnamjam"},{"comment_id":"1108646","poster":"pentium75","content":"Selected Answer: AB\n\"Use SQL to query the transformed data\" [which is in S3] requires Athena, thus D and E are out. DMS is nonsense here thus C is out.","timestamp":"1719654780.0","upvote_count":"3"},{"content":"why E is not right choise?","comment_id":"1087491","timestamp":"1717486020.0","comments":[{"content":"Because you can't \"use the Amazon RDS query editor to query .. data from S3\"","timestamp":"1719654660.0","upvote_count":"2","comment_id":"1108645","poster":"pentium75"}],"upvote_count":"2","poster":"MiniYang"},{"poster":"TariqKipkemei","upvote_count":"2","timestamp":"1712126520.0","comment_id":"1023683","content":"Selected Answer: AB\noptions A and B will meet these requirements."},{"timestamp":"1709668140.0","poster":"Guru4Cloud","comment_id":"999767","upvote_count":"3","content":"Selected Answer: AB\nA and B are correct.\n\nA uses Kinesis Data Streams for streaming, Kinesis Data Analytics for transformation, Kinesis Data Firehose for writing to S3, and Athena for SQL queries on S3 data.\n\nB uses Amazon MSK for streaming, AWS Glue for transformation and writing to S3, and Athena for SQL queries on S3 data."},{"comments":[{"poster":"awsgeek75","upvote_count":"3","comment_id":"1125421","content":"\"Use the Amazon RDS query editor to query the transformed data from Amazon S3.\" is not possible as RDS query editor is for RDS and not for S3","timestamp":"1721251740.0"}],"content":"Why E is incorrect?","comment_id":"986184","upvote_count":"3","poster":"Diqian","timestamp":"1708492980.0"},{"content":"Selected Answer: AE\nTo transform real-time streaming data from multiple sources, write it to Amazon S3, and query the transformed data using SQL, the company can use the following solutions: Amazon Kinesis Data Streams, Amazon Kinesis Data Analytics, and Amazon Kinesis Data Firehose. The transformed data can be queried using Amazon Athena. Therefore, options A and E are the correct answers.\n\nOption A is correct because it uses Amazon Kinesis Data Streams to stream data from multiple sources, Amazon Kinesis Data Analytics to transform the data, and Amazon Kinesis Data Firehose to write the data to Amazon S3. Amazon Athena can be used to query the transformed data in Amazon S3.\n\nOption E is also correct because it uses Amazon Kinesis Data Streams to stream data from multiple sources, AWS Glue to transform the data, and Amazon Kinesis Data Firehose to write the data to Amazon S3. Amazon Athena can be used to query the transformed data in Amazon S3.","comment_id":"874835","timestamp":"1697728200.0","poster":"MrCloudy","comments":[{"content":"Amazon Athena is not in option E","timestamp":"1711214400.0","upvote_count":"8","comment_id":"1015055","poster":"sand444"}],"upvote_count":"3"},{"comment_id":"857455","content":"Selected Answer: AB\nDMS can move data from DBs to streaming services and cannot natively handle streaming data. Hence A.B makes sense. Also AWS Glue/ETL can handle MSK streaming https://docs.aws.amazon.com/glue/latest/dg/add-job-streaming.html.","upvote_count":"3","poster":"kraken21","timestamp":"1696112820.0"},{"upvote_count":"6","timestamp":"1696059840.0","content":"Selected Answer: AB\nThe solutions that meet the requirements of streaming real-time data, transforming the data before writing to S3, and querying the transformed data using SQL are A and B.\n\nOption C: This option is not ideal for streaming real-time data as AWS DMS is not optimized for real-time data ingestion.\nOption D & E: These option are not recommended as the Amazon RDS query editor is not designed for querying data in S3, and it is not efficient for running complex queries.","poster":"elearningtakai","comment_id":"855401"},{"content":"Selected Answer: AB\nThe correct answers are options A & B","timestamp":"1695952080.0","poster":"gold4otas","comment_id":"853896","upvote_count":"2"},{"upvote_count":"1","content":"may Amazon RDS query editor to query the transformed data from Amazon S3 ?\ni don't think so, plz get link docs to that","comment_id":"825942","timestamp":"1693570140.0","poster":"TungPham"},{"comment_id":"817307","timestamp":"1692657180.0","poster":"ManOnTheMoon","comments":[],"upvote_count":"1","content":"Why not A & D?"},{"timestamp":"1692632220.0","comment_id":"816938","content":"Selected Answer: AB\nA and B","poster":"LuckyAro","upvote_count":"2"},{"poster":"designmood22","comment_id":"816695","content":"Answer is : A & B","timestamp":"1692622440.0","upvote_count":"2"},{"timestamp":"1692374040.0","content":"Answer is A and B","upvote_count":"3","poster":"rrharris","comment_id":"813354"},{"poster":"NolaHOla","comment_id":"813135","content":"A and B","timestamp":"1692363180.0","upvote_count":"3"}],"unix_timestamp":1676731980,"url":"https://www.examtopics.com/discussions/amazon/view/99834-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"answer_ET":"AB","answer":"AB","question_images":[],"exam_id":31,"isMC":true,"timestamp":"2023-02-18 15:53:00","answers_community":["AB (93%)","7%"],"question_text":"A company is preparing a new data platform that will ingest real-time streaming data from multiple sources. The company needs to transform the data before writing the data to Amazon S3. The company needs the ability to use SQL to query the transformed data.\n\nWhich solutions will meet these requirements? (Choose two.)"}],"exam":{"isImplemented":true,"lastUpdated":"11 Apr 2025","provider":"Amazon","numberOfQuestions":1019,"id":31,"isMCOnly":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","isBeta":false},"currentPage":47},"__N_SSP":true}