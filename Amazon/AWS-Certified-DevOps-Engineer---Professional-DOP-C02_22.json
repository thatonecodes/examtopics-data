{"pageProps":{"questions":[{"id":"aYD5tWc2tXv8R7GCuCb8","answer":"B","choices":{"D":"Add the following conditional expression:","B":"Change \"Resource\": \"*\"to \"Resource\": \"arn:aws:ec2:*:*:instance/*\"","E":"Change \"Action\": \"ec2:*\"to \"Action\": \"ec2:StopInstances\"","C":"Add the following conditional expression:","A":"Add the following conditional expression:","F":"Add the following conditional expression:"},"timestamp":"2023-12-29 16:06:00","answer_description":"","question_id":106,"unix_timestamp":1703862360,"question_images":["https://img.examtopics.com/aws-certified-devops-engineer-professional-dop-c02/image16.png"],"exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/129705-exam-aws-certified-devops-engineer-professional-dop-c02/","answers_community":["B (59%)","A (21%)","D (21%)"],"answer_images":[],"topic":"1","question_text":"A company is reviewing its IAM policies. One policy written by the DevOps engineer has been flagged as too permissive. The policy is used by an AWS Lambda function that issues a stop command to Amazon EC2 instances tagged with Environment: NonProduction over the weekend. The current policy is:\n\n//IMG//\n\n\nWhat changes should the engineer make to achieve a policy of least permission? (Choose three.)","isMC":true,"answer_ET":"B","discussion":[{"comment_id":"1146584","timestamp":"1707592320.0","upvote_count":"8","content":"Selected Answer: A\nA,D,E\nprincipalType could be a condition key \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html","poster":"vortegon"},{"timestamp":"1707745800.0","content":"Selected Answer: B\nB, D and E are correct:\nA: This allow all any lambda func to do the task, wont make any change\nB: This allow action only on EC2, so it is correct\nC: We need to allow action on Ec2 instances tagged with NonProdction only. Using this would grant permissions to other tags as well\nD: perfectly correct\nE: Only permit stop action, so it is correct\nF: irrelevant","upvote_count":"6","comment_id":"1148157","poster":"thanhnv142"},{"upvote_count":"1","content":"BDE seems correct to me.","comment_id":"1358620","timestamp":"1739950200.0","poster":"rinip86277"},{"upvote_count":"1","content":"Selected Answer: D\nDEF - clearly","timestamp":"1735046880.0","comment_id":"1331127","poster":"youonebe"},{"poster":"3f78595","timestamp":"1725671220.0","comment_id":"1279861","upvote_count":"1","content":"A, B, D\nThe engineer should make the following changes to achieve a policy of least permission:\n\nA:Add a condition to ensure that the principal making the request is an AWS Lambda function. This ensures that only Lambda functions can execute this policy.\n\nB:Narrow down the resources by specifying the ARN of EC2 instances instead of allowing all resources. This ensures that the policy only affects EC2 instances.\n\nD:Add a condition to ensure that this policy only applies to EC2 instances tagged with ''Environment: NonProduction''. This ensures that production environments are not affected by this policy."},{"upvote_count":"1","content":"I'll go with BDE\n\nB - restrict resource from wildcard to only \"arn:aws:ec2:*:*:instance/*\"\nD - this condition limits to non Prod only\nE - limit actions to \"ec2:StopInstances\" and not all ec2 actions\n\nas for F, although YOU CAN allow access based on date/time. The typical format is:\n\n \"Condition\": {\n \"DateGreaterThan\": {\"aws:CurrentTime\": \"2020-04-01T00:00:00Z\"},\n \"DateLessThan\": {\"aws:CurrentTime\": \"2020-06-30T23:59:59Z\"}\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws-dates.html","comment_id":"1266566","poster":"GripZA","timestamp":"1723740420.0"},{"upvote_count":"4","poster":"kiko_zhang","comment_id":"1258352","timestamp":"1722364740.0","content":"DEF.\nwhen using E, there is no need for B.\nF: https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws-dates.html"},{"upvote_count":"1","timestamp":"1722324780.0","comment_id":"1257969","comments":[{"content":"And in question, there is keywords: least permission\nSo B is needed","timestamp":"1722324900.0","poster":"jamesf","upvote_count":"2","comment_id":"1257970"}],"poster":"jamesf","content":"Selected Answer: B\nBDE are correct.\n\nOption F is irrelevant and can use Amazon EventBridge Rule to execute the Lambda"},{"timestamp":"1721986140.0","content":"Selected Answer: D\nDEF\nE is more prefect answer rather than B. \nD. restricted the ec2 using env tag as \"nonproduction\"\nF. support scope of running time which mention in the question.","poster":"ericphl","upvote_count":"4","comment_id":"1255621"},{"upvote_count":"3","timestamp":"1715260380.0","comment_id":"1208866","poster":"MalonJay","content":"DEF\nPrincipal condition is usually for resource policies."},{"comment_id":"1205511","content":"Selected Answer: B\nBDE for me","upvote_count":"4","timestamp":"1714652400.0","poster":"seetpt"},{"poster":"didek1986","content":"Selected Answer: D\nD we need non prod,E we need specific action,F we need dates restriction","upvote_count":"3","timestamp":"1713629340.0","comment_id":"1199240"},{"content":"Selected Answer: B\nBDE seems correct","upvote_count":"2","poster":"dkp","timestamp":"1713060120.0","comment_id":"1195218"},{"poster":"soojung","timestamp":"1707823740.0","content":"Why is B the correct answer?","upvote_count":"2","comment_id":"1149120"},{"upvote_count":"5","comment_id":"1139573","timestamp":"1706991600.0","poster":"pokemonas","content":"there is no point to restrict \"Resource\": into instances, when you restricting action to \"ec2:StopInstances\". Only EC2 instance have such action. So whats the point to restrict Resource."},{"poster":"promo286","upvote_count":"2","timestamp":"1706373480.0","comment_id":"1133493","content":"Selected Answer: B\nB, D, and E."},{"timestamp":"1705431480.0","content":"Selected Answer: B\nVote for BDE","upvote_count":"3","poster":"yuliaqwerty","comment_id":"1124445"},{"upvote_count":"1","comment_id":"1121420","poster":"Ola2234","timestamp":"1705134900.0","content":"BDE is the correct answer."},{"timestamp":"1704233280.0","upvote_count":"2","comment_id":"1112313","poster":"d262e67","content":"Selected Answer: B\nB, D, and E. Principal is not for an IAM policy. And it's not possible to include weekdays in the policy."},{"poster":"ozansenturk","comment_id":"1111922","content":"Selected Answer: B\nBDE seems correct","upvote_count":"1","timestamp":"1704201480.0"},{"upvote_count":"2","comment_id":"1109123","poster":"csG13","content":"Selected Answer: B\nB, D & E seem correct.","timestamp":"1703885100.0"},{"comment_id":"1108824","poster":"PrasannaBalaji","content":"BDE is correct","timestamp":"1703862360.0","upvote_count":"2"}]},{"id":"ukbUB8drJq8il05PS65y","choices":{"B":"Write each log event as a single write operation.","A":"Use batch writes to write multiple log events in a single write operation.","E":"Configure the memory store retention period to be longer than the magnetic store retention period.","F":"Configure the memory store retention period to be shorter than the magnetic store retention period.","C":"Treat each log as a single-measure record.","D":"Treat each log as a multi-measure record."},"question_images":[],"answer":"ADF","answer_images":[],"discussion":[{"comment_id":"1146587","timestamp":"1707592620.0","content":"Selected Answer: ADF\nWhile E suggests configuring the memory store retention period to be longer than the magnetic store retention period, this is typically not aimed at optimizing query performance but rather at keeping data in the faster-access memory store for longer periods, which could be beneficial for workloads requiring frequent access to recent data. However, for the scenario described, focusing on efficient data ingestion methods (A and D) and understanding the role of retention periods (F) provides a balanced approach to achieving the fastest query performance for daily queries.","upvote_count":"6","poster":"vortegon"},{"timestamp":"1721996280.0","content":"Selected Answer: ADE\nE fast performance\nA writer more throughput\n D multi measure means less records to store each data point. Faster query","upvote_count":"2","comment_id":"1255708","poster":"auxwww"},{"timestamp":"1720153800.0","content":"Selected Answer: ADE\nMy only hesitation is in regards to how batch writes might improve query performance, other than if the stored data is in a contiguous chunk, that could hep a query later. As far as for multi-measure and more memory, I defer to references:\nA: (YES) \"When writing data to InfluxDB, write data in batches to minimize the network overhead related to every write request.\" \nD: (YES) \"Multi-measure records results in lower query latency for most query types when compared to single-measure records.\" \nE: (YES) \"The memory store is optimized for high throughput data writes and fast point-in-time queries.\" \nF: (NO) \"The magnetic store is optimized for lower throughput late-arriving data writes, long term data storage, and fast analytical queries.\"","comment_id":"1242468","comments":[{"timestamp":"1720154760.0","content":"Memory based storage is always going to provide \"FASTEST query performance\" compared to magnetic storage. You want faster query, provide higher ratio of memory storage compared to magnetic.","comment_id":"1242481","poster":"Gomer","upvote_count":"1"}],"poster":"Gomer","upvote_count":"2"},{"upvote_count":"3","poster":"didek1986","content":"Selected Answer: ADF\nADF\nA - improve write performance and efficiency\nD - query for a specific measure in a multi-measure record, Timestream only scans the relevant measure, not the entire record. This means that even though the record contains multiple measures, the query performance for a specific measure is not negatively impacted. Multi-measure record reduces the number of records that need to be written and subsequently queried, which improve query performance.\nF - memory store, which is optimised for write and query performance, is not filled with older data that is not frequently accessed","comment_id":"1197773","timestamp":"1713425400.0"},{"comment_id":"1195222","upvote_count":"3","timestamp":"1713060540.0","content":"Selected Answer: ADF\nADF seems more relevant","poster":"dkp"},{"timestamp":"1708893360.0","content":"Selected Answer: ADF\nADF – batch writes, Treat log as multi-measure record, Memory story should be shorter,.\nhttps://aws.amazon.com/blogs/database/improve-query-performance-and-reduce-cost-using-scheduled-queries-in-amazon-timestream/#:~:text=Improve%20query%20performance%20and%20reduce%20cost%20using%20scheduled,6%20Query%20performance%20metrics%20...%207%20Conclusion%20","poster":"Diego1414","upvote_count":"4","comment_id":"1159160"},{"poster":"Ramdi1","upvote_count":"3","content":"Selected Answer: ACD\nA. Batch writes: This significantly reduces overhead associated with individual write operations and improves overall write throughput.\nC. Single-measure record: For daily queries summarizing multiple metrics, treating each log as a single record helps Timestream leverage its optimized storage and query processing for single measures.\nD. Multi-measure record: While it seems counterintuitive, Timestream performs better with multiple measures within a single record compared to separate records for each metric. This allows for efficient data retrieval and aggregation during queries.","comment_id":"1149377","timestamp":"1707843420.0","comments":[{"timestamp":"1707843420.0","upvote_count":"1","poster":"Ramdi1","content":"Options B, E, and F are not recommended for optimal performance:\n \nB. Single write operations: This increases overhead and reduces write throughput, negating Timestream's scalability benefits.\nE. Longer memory store: While faster for recent data, it increases cost and doesn't impact daily queries focused on older, magnetic store data.\nF. Shorter memory store: Reduces cost but sacrifices potential performance gains for frequently accessed recent data, which might not be relevant for daily queries.\n \nBy combining batch writes, single-measure records, and multi-measure records, the company can achieve the fastest query performance for their daily Timestream use case.","comment_id":"1149378"}]},{"content":"Selected Answer: ADF\nA,D and F are correct:\nA: do job in batch optimize costs and performance\nB: should not do single write\nC: The app emits multiple records the same time. So it should be multi-measure record, not single one\nD: correct\nE: Should not do this\nF: correct","poster":"thanhnv142","comment_id":"1148173","timestamp":"1707747240.0","upvote_count":"3"},{"comment_id":"1143488","timestamp":"1707321480.0","poster":"Chelseajcole","content":"ACE. Batch the write, write as whole and stay in memory longer","upvote_count":"1"}],"topic":"1","isMC":true,"answer_description":"","answers_community":["ADF (73%)","ADE (15%)","12%"],"timestamp":"2024-02-07 16:58:00","url":"https://www.examtopics.com/discussions/amazon/view/133291-exam-aws-certified-devops-engineer-professional-dop-c02/","question_text":"A company is developing an application that will generate log events. The log events consist of five distinct metrics every one tenth of a second and produce a large amount of data.\n\nThe company needs to configure the application to write the logs to Amazon Timestream. The company will configure a daily query against the Timestream table.\n\nWhich combination of steps will meet these requirements with the FASTEST query performance? (Choose three.)","unix_timestamp":1707321480,"question_id":107,"exam_id":23,"answer_ET":"ADF"},{"id":"I9XKScn2Rf6W7SkiHbZJ","answer":"BE","question_id":108,"choices":{"E":"Refactor the user data command to use an AWS Systems Manager document (SSM document). Use Systems Manager State Manager to create an association between the SSM document and the EC2 instances.","A":"Configure the user data content to use the Multipurpose Internet Mail Extensions (MIME) multipart format. Set the scripts-user parameter to always in the text/cloud-config section.","B":"Refactor the user data commands to use the cfn-init helper script. Update the user data to install and configure the cfn-hup and cfn-init helper scripts to monitor and apply the metadata changes.","C":"Configure an EC2 launch template for the EC2 instances. Create a new EC2 Auto Scaling group. Associate the Auto Scaling group with the EC2 launch template. Use the AutoScalingScheduledAction update policy for the Auto Scaling group.","D":"Refactor the user data commands to use an AWS Systems Manager document (SSM document). Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 instances."},"question_images":[],"isMC":true,"unix_timestamp":1707151500,"answer_ET":"BE","answers_community":["BE (70%)","BD (26%)","4%"],"exam_id":23,"answer_description":"","discussion":[{"upvote_count":"8","comment_id":"1146591","timestamp":"1723310580.0","poster":"vortegon","content":"Selected Answer: BE\nB and E are the most effective in ensuring that updates to the application are installed on the running EC2 instances by leveraging CloudFormation's and AWS Systems Manager's capabilities for managing and applying updates."},{"timestamp":"1743334320.0","upvote_count":"1","poster":"Srikantha","content":"Selected Answer: BE\nThe best combination of steps to ensure the application is updated on the running EC2 instances during a CloudFormation stack update is:\n\nB. Refactor the user data commands to use the cfn-init helper script. Update the user data to install and configure the cfn-hup and cfn-init helper scripts to monitor and apply the metadata changes.\nD. Refactor the user data commands to use an AWS Systems Manager document (SSM document). Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 instances.","comment_id":"1412065"},{"upvote_count":"3","poster":"dkp","comment_id":"1195229","timestamp":"1728872400.0","content":"Selected Answer: BE\nB&E\nD. Systems Manager Run Command (with user data): Using Run Command within user data to apply an SSM document introduces an unnecessary step. Option E with State Manager automates the process."},{"timestamp":"1727651820.0","poster":"WhyIronMan","content":"Selected Answer: BE\nB, E.\n\"Association\" is the key. Details are everything during an Investigation...","upvote_count":"2","comment_id":"1186474"},{"timestamp":"1727238120.0","content":"Selected Answer: E\nUser data is executed when the system starts, not executed in runing EC2.","upvote_count":"1","comment_id":"1182248","poster":"Seoyong"},{"content":"Selected Answer: BE\nEC2 instance profile with AmazonSSMManagedinstanceCore policy doesn't have permissions to SSM Run Command, so D is incorrect. \nSo for me it's BE.","poster":"vmahilevskyi","timestamp":"1727167500.0","comment_id":"1181453","upvote_count":"3"},{"poster":"ogerber","content":"Selected Answer: BE\n\"Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 instances.\" \n**Add an AWS CLI command in the ****user data*****\nit will not help to update running instances, tricky question.\nOnly Systems Manager State Manager will update the running instances in this question","timestamp":"1726592100.0","comment_id":"1176028","upvote_count":"2"},{"upvote_count":"1","content":"B and D\nA. This option is not applicable for updating applications on EC2 instances.\n\nB. Refactoring the user data commands to use the cfn-init helper script helps in handling metadata changes and applying them to the EC2 instances. This is especially useful in CloudFormation stack updates.\n\nC. Creating a new EC2 Auto Scaling group with an update policy doesn't necessarily address the application update requirement in this scenario.\n\nD. Refactoring the user data commands to use an AWS Systems Manager document and using Run Command to apply the SSM document is a valid approach for updating applications on EC2 instances.\n\nE. While using Systems Manager documents and State Manager is a valid approach, it might be more complex than needed for a straightforward update of an application on EC2 instances.\n\nTherefore, options B and D together provide a good solution for updating the application on the running EC2 instances.","comment_id":"1162961","timestamp":"1724953260.0","poster":"fdoxxx"},{"timestamp":"1723561140.0","upvote_count":"1","comment_id":"1149380","poster":"Ramdi1","content":"Selected Answer: BD\nption B: cfn-init is a powerful tool for managing configuration on EC2 instances. By using cfn-init, the DevOps engineer can ensure that the new application version is installed regardless of the current state of the instances Option D: SSM documents provide a centralized and reusable way to manage configurations. By using Run Command, the engineer can trigger the application update on all instances directly from the template.","comments":[{"content":"Options A, C, and E are not suitable for this scenario:\n \nOption A: MIME multipart format isn't necessary for this scenario.\nOption C: While Auto Scaling offers flexibility, creating a new launch template and Auto Scaling group is unnecessary for a simple application update.\nOption E: State Manager is generally used for ongoing configuration management, not one-time deployments like this.\n \nBy using both cfn-init and SSM documents, the DevOps engineer can achieve a reliable and manageable way to update the application on the running EC2 instances.","comment_id":"1149381","timestamp":"1723561200.0","upvote_count":"1","poster":"Ramdi1"}]},{"comment_id":"1148186","poster":"thanhnv142","content":"Selected Answer: BD\nB and D:\nA: irrelevant\nB: cfn-init is perfectly correct for this purpose\nC: irrelevant. The question does not mention autoscaling group\nD: <Systems Manager Run Command > can help install packages, so it is correct\nE: < Systems Manager State Manager> is used to maintain, not to update","timestamp":"1723465320.0","upvote_count":"2"},{"content":"Selected Answer: BD\nHere's why these options are correct:\nOption B: cfn-init is a powerful tool for managing configuration on EC2 instances. By using cfn-init, the DevOps engineer can ensure that the new application version is installed regardless of the current state of the instances. cfn-hup helps keep cfn-init updated with the latest configuration changes.\n \nOption D: SSM documents provide a centralized and reusable way to manage configurations. By using Run Command, the engineer can trigger the application update on all instances directly from the template. This approach allows for easier management and updates in the future.","comment_id":"1148054","upvote_count":"2","poster":"Ramdi1","timestamp":"1723456080.0"},{"content":"Selected Answer: BD\ncfn-hup to chek for updates in cloudformation and ssm run command to run commands if required for application","timestamp":"1722869100.0","comment_id":"1141284","upvote_count":"2","poster":"hotblooded"}],"question_text":"A DevOps engineer has created an AWS CloudFormation template that deploys an application on Amazon EC2 instances. The EC2 instances run Amazon Linux. The application is deployed to the EC2 instances by using shell scripts that contain user data. The EC2 instances have an IAM instance profile that has an IAM role with the AmazonSSMManagedinstanceCore managed policy attached.\n\nThe DevOps engineer has modified the user data in the CloudFormation template to install a new version of the application. The engineer has also applied the stack update. However, the application was not updated on the running EC2 instances. The engineer needs to ensure that the changes to the application are installed on the running EC2 instances.\n\nWhich combination of steps will meet these requirements? (Choose two.)","answer_images":[],"timestamp":"2024-02-05 17:45:00","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/132880-exam-aws-certified-devops-engineer-professional-dop-c02/"},{"id":"4IeWrvUrkZypXcXeZkrd","topic":"1","timestamp":"2024-02-07 12:52:00","unix_timestamp":1707306720,"question_id":109,"question_text":"A company is refactoring applications to use AWS. The company identifies an internal web application that needs to make Amazon S3 API calls in a specific AWS account.\n\nThe company wants to use its existing identity provider (IdP) auth.company.com for authentication. The IdP supports only OpenID Connect (OIDC). A DevOps engineer needs to secure the web application's access to the AWS account.\n\nWhich combination of steps will meet these requirements? (Choose three.)","discussion":[{"comment_id":"1146597","upvote_count":"5","content":"Selected Answer: BDE\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-idp_oidc.html","poster":"vortegon","timestamp":"1707593580.0"},{"upvote_count":"1","timestamp":"1735078560.0","content":"Selected Answer: BCE\nBCE\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-idp_oidc.html","poster":"sn61613","comment_id":"1331245"},{"timestamp":"1720206720.0","upvote_count":"2","comment_id":"1242978","poster":"Gomer","content":"Selected Answer: BDE\n\"Use OpenID Connect (OIDC) federated identity providers instead of creating\" IAM users.\" \"With an\" IdP \"you can manage\" \"user identities outside of AWS and give these external user identities permissions to access AWS resources in your account.\"\nB: (YES) \"IAM OIDC identity Providers\" \"This is useful when creating a mobile app or web application that requires access to AWS resources, but you don't want to create custom sign-in code or manage your own user identities.\"\nD: (YES) \"For OIDC providers, use the fully qualified URL of the OIDC IdP with the aud context key\" e.g.: \"Condition\": {\"StringEquals\": {\"server.example.com:aud\": \"appid_from_oidc_idp\"}}\"\nE: (YES) \"AssumeRoleWithWebIdentity\" \"Federation through a web-based\" IDP \"returns a set of temporary security credentials for federated users\" \"authenticated\" \"with a public identity provider.\" \"This operation is useful for\" \"client-based web applications that require access to AWS.\""},{"content":"Selected Answer: BDE\nBDE for me","comment_id":"1205513","upvote_count":"1","poster":"seetpt","timestamp":"1714652460.0"},{"comment_id":"1195241","timestamp":"1713062400.0","content":"Selected Answer: ADE\nDE is correct not sure between A & B\nA. Configure AWS IAM Identity Center (AWS Single Sign-On). Configure an IdP. Upload the IdP metadata from the existing IdP.\nPros: Integrates with AWS SSO and allows for IdP metadata upload.\nCons: AWS SSO is generally used for managing multiple AWS accounts and SSO for multiple AWS services, might be overkill for a single account and application.\nB. Create an IAM IdP by using the provider URL, audience, and signature from the existing IP.\nPros: Creates a custom IAM IdP using the existing IdP's details.\nCons: Manual configuration of IAM IdP might be error-prone and not the best practice for OIDC integration.","upvote_count":"1","poster":"dkp"},{"poster":"thanhnv142","comment_id":"1148217","content":"Selected Answer: BDE\nBDE: \nA: we need to create an IDP. We dont need a AWS Single Sign-On\nB: correct\nC: we need to authen. sts.amazon.com:aud does not for authen\nD: auth.company.com:aud is for authen\nE: This used for authen AssumeRoleWithWebIdentity\nF: This is not used for authen","timestamp":"1707749280.0","upvote_count":"3"},{"upvote_count":"1","timestamp":"1707739860.0","comments":[{"poster":"Ramdi1","content":"Options A, B, and F are not suitable for this scenario:\nA: AWS SSO is currently not available for public AWS accounts and wouldn't address the specific OIDC integration requirement.\nB: While creating an IAM IdP is possible, it's generally less secure than leveraging the existing, trusted IdP with OIDC support.\nF: GetFederationToken is often used with SAML-based federation and wouldn't work directly with OIDC.","timestamp":"1707739860.0","upvote_count":"1","comment_id":"1148079"}],"comment_id":"1148078","poster":"Ramdi1","content":"Selected Answer: CDE\nC & D: Creating an IAM role with specific S3 permissions and configuring the trust policy based on the appropriate audience (sts.amazon.com:aud or auth.company.com:aud) allows secure role assumption by the OIDC IdP on behalf of authenticated users.\nE: Using AssumeRoleWithWebIdentity fetches temporary credentials with restricted privileges, enhancing security compared to long-lived credentials."},{"content":"BDE is my answer","poster":"Chelseajcole","timestamp":"1707321780.0","upvote_count":"3","comment_id":"1143493"},{"poster":"Arnaud92","comment_id":"1143290","upvote_count":"1","timestamp":"1707306720.0","content":"Selected Answer: ADE\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-idp_oidc.html"}],"isMC":true,"answers_community":["BDE (73%)","13%","7%"],"question_images":[],"exam_id":23,"choices":{"A":"Configure AWS IAM Identity Center (AWS Single Sign-On). Configure an IdP. Upload the IdP metadata from the existing IdP.","D":"Create an IAM role that has a policy that allows the necessary S3 actions. Configure the role's trust policy to allow the OIDC IP to assume the role if the auth.company.com:aud context key is appid_from_idp.","C":"Create an IAM role that has a policy that allows the necessary S3 actions. Configure the role's trust policy to allow the OIDC IP to assume the role if the sts.amazon.com:aud context key is appid_from_idp.","B":"Create an IAM IdP by using the provider URL, audience, and signature from the existing IP.","E":"Configure the web application to use the AssumeRoleWithWebIdentity API operation to retrieve temporary credentials. Use the temporary credentials to make the S3 API calls.","F":"Configure the web application to use the GetFederationToken API operation to retrieve temporary credentials. Use the temporary credentials to make the S3 API calls."},"url":"https://www.examtopics.com/discussions/amazon/view/133261-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_description":"","answer_ET":"BDE","answer":"BDE","answer_images":[]},{"id":"SYUli4Z8Get5R24A54qi","exam_id":23,"answer_description":"","answers_community":["A (78%)","C (22%)"],"question_images":[],"answer_images":[],"question_id":110,"discussion":[{"timestamp":"1722327720.0","content":"Selected Answer: A\nKeywords: Control Tower\nA company uses Amazon RDS for all databases in its AWS accounts. The company uses AWS Control Tower","comment_id":"1258026","upvote_count":"2","poster":"jamesf"},{"comment_id":"1199251","upvote_count":"3","timestamp":"1713630120.0","content":"Selected Answer: A\nA\nhttps://docs.aws.amazon.com/controltower/latest/userguide/strongly-recommended-controls.html#disallow-rds-storage-unencrypted","poster":"didek1986"},{"poster":"dkp","upvote_count":"3","content":"Selected Answer: A\nmost efficient way is A","timestamp":"1713062820.0","comment_id":"1195243"},{"timestamp":"1710582360.0","comment_id":"1174884","upvote_count":"3","content":"Selected Answer: A\nA - least operational overhead","poster":"DanShone"},{"upvote_count":"3","timestamp":"1709984760.0","poster":"sejar","comment_id":"1169435","content":"Selected Answer: C\nGuardrail uses AWS Config for compliance detection"},{"timestamp":"1708895640.0","poster":"Diego1414","upvote_count":"2","comment_id":"1159199","content":"Selected Answer: C\nAnswer: C - https://docs.aws.amazon.com/controltower/latest/userguide/strongly-recommended-controls.html#disallow-rds-storage-unencrypted"},{"comment_id":"1148227","poster":"thanhnv142","content":"Selected Answer: A\nA is correct: we need guardraild to detect non-compliances\nB and D: no mention of guardrail.\nC: Though this option mentions guardrail, it uses AWS Config to detect non-compliances","comments":[{"timestamp":"1707836400.0","poster":"thanhnv142","comment_id":"1149261","content":"correction: C","upvote_count":"1"}],"upvote_count":"4","timestamp":"1707749520.0"},{"comment_id":"1148075","poster":"Ramdi1","timestamp":"1707739800.0","upvote_count":"3","content":"Selected Answer: A\nLeverages existing infrastructure: It utilizes native AWS Control Tower functionality for compliance checks and integrates seamlessly with SNS for notifications.\nCentralized management: Configuration and monitoring are done in the audit account, eliminating the need for individual resources in each account.\nScalability: Handles future account growth without manual intervention."},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/controltower/latest/userguide/strongly-recommended-controls.html#disallow-rds-storage-unencrypted","timestamp":"1707594060.0","poster":"vortegon","upvote_count":"4","comment_id":"1146601"},{"poster":"Arnaud92","upvote_count":"3","comment_id":"1143288","timestamp":"1707306660.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/controltower/latest/userguide/strongly-recommended-controls.html#disallow-rds-storage-unencrypted"},{"poster":"hotblooded","comments":[{"timestamp":"1735287660.0","content":"The key here is most operational efficiency. Option C says create a rule in every account. Control tower is more efficient in this regard.","poster":"Slays","upvote_count":"1","comment_id":"1332310"},{"comment_id":"1143616","upvote_count":"2","poster":"Chelseajcole","timestamp":"1707328620.0","content":"thanks for the summary"}],"content":"Selected Answer: C\nCompliance == Aws config","upvote_count":"2","timestamp":"1707151680.0","comment_id":"1141286"}],"answer_ET":"A","unix_timestamp":1707151680,"question_text":"A company uses Amazon RDS for all databases in its AWS accounts. The company uses AWS Control Tower to build a landing zone that has an audit and logging account. All databases must be encrypted at rest for compliance reasons. The company's security engineer needs to receive notification about any noncompliant databases that are in the company’s accounts.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","isMC":true,"timestamp":"2024-02-05 17:48:00","url":"https://www.examtopics.com/discussions/amazon/view/132881-exam-aws-certified-devops-engineer-professional-dop-c02/","topic":"1","answer":"A","choices":{"A":"Use AWS Control Tower to activate the optional detective control (guardrail) to determine whether the RDS storage is encrypted. Create an Amazon Simple Notification Service (Amazon SNS) topic in the company's audit account. Create an Amazon EventBridge rule to filter noncompliant events from the AWS Control Tower control (guardrail) to notify the SNS topic. Subscribe the security engineer's email address to the SNS topic.","C":"Create a custom AWS Config rule in every account to determine whether the RDS storage is encrypted. Create an Amazon Simple Notification Service (Amazon SNS) topic in the audit account. Create an Amazon EventBidge rule to filter noncompliant events from the AWS Control Tower control (guardrail) to notify the SNS topic. Subscribe the security engineer's email address to the SNS topic.","B":"Use AWS CloudFormation StackSets to deploy AWS Lambda functions to every account. Write the Lambda function code to determine whether the RDS storage is encrypted in the account the function is deployed to. Send the findings as an Amazon CloudWatch metric to the management account. Create an Amazon Simple Notification Service (Amazon SNS) topic. Create a CloudWatch alarm that notifies the SNS topic when metric thresholds are met. Subscribe the security engineer's email address to the SNS topic.","D":"Launch an Amazon C2 instance. Run an hourly cron job by using the AWS CLI to determine whether the RDS storage is encrypted in each AWS account. Store the results in an RDS database. Notify the security engineer by sending email messages from the EC2 instance when noncompliance is detected"}}],"exam":{"isImplemented":true,"provider":"Amazon","isBeta":false,"isMCOnly":true,"numberOfQuestions":355,"lastUpdated":"11 Apr 2025","name":"AWS Certified DevOps Engineer - Professional DOP-C02","id":23},"currentPage":22},"__N_SSP":true}