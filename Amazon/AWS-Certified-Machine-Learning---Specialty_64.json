{"pageProps":{"questions":[{"id":"MYt6sPx2AGtwJyjkKpwR","isMC":true,"exam_id":26,"url":"https://www.examtopics.com/discussions/amazon/view/8376-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","answer":"B","answer_images":[],"unix_timestamp":1573954800,"question_id":316,"answer_ET":"B","answer_description":"","question_images":[],"discussion":[{"comments":[{"comment_id":"28387","upvote_count":"10","content":"Yes, Clustering seems to be more appropriate in this scenario than recommender system","poster":"rsimham","timestamp":"1632180300.0","comments":[{"comment_id":"919091","poster":"mirik","upvote_count":"1","timestamp":"1686299820.0","content":"Collaborative filtering recommendation system is also unsupervised"}]},{"timestamp":"1633598220.0","upvote_count":"3","poster":"haison8x","comment_id":"148509","content":"https://towardsdatascience.com/customer-segmentation-with-machine-learning-a0ac8c3d4d84\n\nB"}],"content":"All of the questions in the preceding examples rely on having example data that includes answers. There are times that you don't need, or can't get, example data with answers. This is true for problems whose answers identify groups. For example:\n\n\"I want to group current and prospective customers into 10 groups based on their attributes. How should I group them? \" You might choose to send the mailing to customers in the group that has the highest percentage of current customers. That is, prospective customers that most resemble current customers based on the same set of attributes. For this type of question, Amazon SageMaker provides the K-Means Algorithm.\n\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/algos.html\n\nClustering algorithms are unsupervised. In unsupervised learning, labels that might be associated with the objects in the training dataset aren't used.\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/algo-kmeans-tech-notes.html\n\nTHE ANSWER COULD BE B.clustering on customer profile data to understand key characteristic","comment_id":"22087","poster":"DonaldCMLIN","upvote_count":"37","timestamp":"1632160620.0"},{"content":"Option C. This is not purely unsupervised, as clustering would be, because we have current and past customer profiles to go on. We want to find new customers by finding similar profiles on social media. So it is supervised to some extent. It's not a cluster problem; it is user-user collaborative filtering. The key is to recognize that this is not clustering. You're not blindly trying to group people. You have existing profiles that you are comparing them to.","timestamp":"1635721260.0","comment_id":"278563","poster":"cloud_trail","upvote_count":"10"},{"timestamp":"1730547480.0","upvote_count":"1","comment_id":"1306158","poster":"MultiCloudIronMan","content":"Selected Answer: B\n'B' is correct"},{"poster":"VR10","upvote_count":"2","timestamp":"1708416660.0","comment_id":"1154565","content":"It is B. Recommendation Engines: Traditionally focus on suggesting products/services to existing customers based on past behavior."},{"content":"Selected Answer: B\nClustering is right","upvote_count":"2","comment_id":"1067022","timestamp":"1699601520.0","poster":"elvin_ml_qayiran25091992razor"},{"timestamp":"1698298020.0","comment_id":"1054298","poster":"DimLam","upvote_count":"3","content":"Selected Answer: B\nC would be an answer if wanted to send the promo to the existing customers. But we want to find potential customers. And we can do it only by comparing existing customers with potential customers. It can be done by creating clusters of existing customers and measuring the distance to those clusters for the new potential users.\n\nSo my answer is B"},{"poster":"loict","comment_id":"1007285","timestamp":"1694672640.0","upvote_count":"3","content":"Selected Answer: C\nA. NO - Linear Regression not best to understand relationships between data\nB. NO - it is supervised (we know premiums received vs. claims paid, so can assign users to GOOD or BAD), so no clustering\nC. YES - A recommendation engine in AWS lingua is Amazing Recommender (https://docs.aws.amazon.com/personalize/latest/dg/what-is-personalize.html - \"Creating a targeted marketing campaign\") and can create user segments\nD. NO - not as good as C"},{"comment_id":"992235","content":"Selected Answer: B\nB for me","timestamp":"1693229520.0","upvote_count":"1","poster":"Mickey321"},{"upvote_count":"2","poster":"teka112233","comment_id":"986993","timestamp":"1692666780.0","content":"Selected Answer: B\nRecommendation engines is perfect for customers we have, but for implementing a machine learning model to identify potential (new customers on social media) this requires clustering and segmentation.\nhttps://neptune.ai/blog/customer-segmentation-using-machine-learning"},{"poster":"jyrajan69","comment_id":"968959","timestamp":"1690886640.0","content":"Based on the link below, it must be C\nhttps://medium.com/voice-tech-podcast/a-simple-way-to-explain-the-recommendation-engine-in-ai-d1a609f59d97","upvote_count":"1"},{"timestamp":"1690827900.0","upvote_count":"1","content":"Selected Answer: B\nWe are divided, but I stick with B.","comment_id":"968395","poster":"kaike_reis"},{"comment_id":"961682","poster":"Venkatesh_Babu","upvote_count":"1","timestamp":"1690207740.0","content":"Selected Answer: C\nI think it should be c"},{"upvote_count":"1","content":"Selected Answer: C\nrecommender system would help here, as we already have details of all customers","poster":"nilmans","comment_id":"929391","timestamp":"1687345920.0"},{"timestamp":"1687345800.0","comment_id":"929387","upvote_count":"2","content":"it should be C - recommender system would be better fit here.","poster":"nilmans"},{"poster":"mirik","upvote_count":"1","timestamp":"1686301560.0","content":"Selected Answer: C\nWe should use recommendation system to find key characteristics only among company users (past and present). At this step we don't take any users from the web. After we finish processing this CF model we identify key characteristics (important features?) and only after that, we will start looking for similar users on the web.","comment_id":"919119"},{"timestamp":"1684963020.0","content":"Selected Answer: B\nI would use clustering technique to identify which customers in my database are the target audience and get similar customer profiles from the social media dataset. Its a lot simpler","upvote_count":"2","comment_id":"906158","poster":"earthMover"},{"upvote_count":"2","comment_id":"905445","timestamp":"1684898760.0","poster":"vbal","content":"recommendation engines can use either supervised or unsupervised learning. I can't find any reason to NOT use recommendation engine???"},{"content":"I am still not sure between B & C, reading this post https://medium.com/@daniilkorbut/recommendation-system-algorithms-ba67f39ac9a3\nseems clustering is possible but there are a few things to consider: clustering is done on large dataset while here is not mentioned. also it's an unsupervised algorithm, here we have existing customer's data.","comments":[{"content":"we have customer data but not target. these are all positive customers (the one who bought sth.) not negative ones (the one who didnt) if we had the one who didnt we could use C.","timestamp":"1683288540.0","upvote_count":"2","poster":"Dota_addict","comment_id":"890019"}],"upvote_count":"1","comment_id":"832347","timestamp":"1678229820.0","poster":"Nadia0012"},{"content":"C should not be answer --- they didn't say any recommendation AWS AI/ML service. If answers shown with any of the below two services then answer should have been select multiple choices!\n1) https://docs.aws.amazon.com/personalize/latest/dg/what-is-personalize.html\nCreating a targeted marketing campaign â€“ You can use Amazon Personalize to generate segments of users who will most likely interact with items in your catalog. Then you can use an AWS service or third party service to create a targeted marketing campaign that promotes different items to different user segments.\n\n2) Amazon pinpoint segment\nhttps://docs.aws.amazon.com/pinpoint/latest/userguide/segments.html","poster":"expertguru","timestamp":"1673120880.0","upvote_count":"1","comment_id":"768881"},{"poster":"chrisdavidi","comment_id":"634215","upvote_count":"3","content":"we need to figure out when to use the recommendation engine vs regression vs clustering this is helpful: https://dzone.com/articles/decision-trees-vs-clustering-algorithms-vs-linear\nhowever, a recommendation engine uses clustering to make the suggestion so it sounds more comprehensive I would say C","timestamp":"1658344800.0"},{"upvote_count":"6","content":"Selected Answer: B\nClustering is basically the modelling method for customer segmentation.","comment_id":"624021","poster":"ovokpus","timestamp":"1656426720.0"},{"upvote_count":"2","content":"I agree, the Answer is B. We do not have a new uncategorised customers, on the system, but we should find similar customers on the web, which we can do by clustering, making profila of customer with insured pet.","poster":"Vita_Rasta84444","comment_id":"334399","timestamp":"1636221780.0"},{"upvote_count":"1","comments":[{"comment_id":"919125","timestamp":"1686302100.0","upvote_count":"1","poster":"mirik","content":"This issue is actually a supervised - we have company customers who bought insurance for their dogs and company customers who didn't buy."}],"poster":"astonm13","comment_id":"291027","content":"Considering the quote \"to understand characteristics of customer segments\", I would say recommender engine does not fit to it. I would go for the clustering (answer B). It is not supervised, cause we don't have info on those people who where targeted but refused to become our customers.","timestamp":"1636069380.0"},{"upvote_count":"2","content":"Answer is B. recomendation enginbe is correct if we want to make decisions on current customers, here we want to make decision on new customers as well. So we need clustring.","comment_id":"286030","timestamp":"1636010100.0","poster":"ss001maryam","comments":[{"comment_id":"919128","upvote_count":"1","timestamp":"1686302220.0","poster":"mirik","content":"We make decision on current/past customers and find the new ones from the web that look similar to existing ones that insured their dogs."}]},{"poster":"harmanbirstudy","comment_id":"263433","timestamp":"1635672120.0","content":"Recommendation Engine would make sense it we are recommending someone coming on our website and we recommend something them.\nHere we need to go to social media, where we cannot apply our own machine learning model,which means we need understand the data before targetting new customers on the social media adds.\nHence among the list only option that make sense it Clustering , so Anwser is B","upvote_count":"3"},{"upvote_count":"3","poster":"R_cool","timestamp":"1634908020.0","content":"what is real answer","comment_id":"256206"},{"comment_id":"169094","timestamp":"1633957980.0","upvote_count":"2","content":"Answer is B; recommendation engine does not identify new customers as it suggests products to be given based on profiles","poster":"syu31svc"},{"content":"C is not correct at all. A recommendation engine would probably be factorization machine. This is a grouping problem, a clustering problem......it is not a recommendation engine! B is the correct answer!!!","comment_id":"148132","timestamp":"1633125360.0","upvote_count":"3","poster":"GeeBeeEl"},{"comment_id":"89715","content":"Go for C, find new user on social media that similar with our current user, it's called user-user collaborative filtering","comments":[{"upvote_count":"10","poster":"DScode","timestamp":"1633048080.0","content":"sorry, but any kind of collaborative filtering needs an interaction data, which is not present, and for new user, collaborative filtering suffers from cold start problems since they don't have data beforehand. This is pure case of unsupervised market segmentation problem, since we do not have any labels. Thus, by far and wide, the answer should be Clustering, i.e. option B.","comments":[{"poster":"lightblue","content":"we have labels - past customers and present customers","upvote_count":"1","timestamp":"1634472660.0","comments":[{"timestamp":"1634545440.0","upvote_count":"1","poster":"lightblue","comment_id":"251878","content":"D can be answer imo"}],"comment_id":"251877"}],"comment_id":"107081"}],"poster":"roytruong","timestamp":"1632840480.0","upvote_count":"2"},{"comment_id":"79074","content":"why bit D? marketing campaign mainly use classifiers","poster":"hughhughhugh","timestamp":"1632671580.0","upvote_count":"5"},{"upvote_count":"1","content":"what is the difference between old and new customer? The premiums receive. So, here we can assume premiums as labels and have supervised learning. Please correct me if I'm mistaking.","comment_id":"76575","poster":"mirik","timestamp":"1632619620.0"},{"content":"I would pick C but honest speaking, the question content is not entirely clear. \n\nVery often when we launch a marketing campaign, there is specific target(s) in mind, e.g. selling specific type of insurance in this case, and usually we then analyze the profile of existing customers whose have that product and then try to target those with similar profile. This what most recommendation engine does.","comment_id":"69228","upvote_count":"4","poster":"rickywck","timestamp":"1632420120.0"}],"question_text":"A Marketing Manager at a pet insurance company plans to launch a targeted marketing campaign on social media to acquire new customers. Currently, the company has the following data in Amazon Aurora:\nâœ‘ Profiles for all past and existing customers\nâœ‘ Profiles for all past and existing insured pets\nâœ‘ Policy-level information\nâœ‘ Premiums received\nâœ‘ Claims paid\nWhat steps should be taken to implement a machine learning model to identify potential new customers on social media?","choices":{"C":"Use a recommendation engine on customer profile data to understand key characteristics of consumer segments. Find similar profiles on social media.","A":"Use regression on customer profile data to understand key characteristics of consumer segments. Find similar profiles on social media","B":"Use clustering on customer profile data to understand key characteristics of consumer segments. Find similar profiles on social media","D":"Use a decision tree classifier engine on customer profile data to understand key characteristics of consumer segments. Find similar profiles on social media."},"timestamp":"2019-11-17 02:40:00","answers_community":["B (75%)","C (25%)"]},{"id":"cc8RcnHZAWVG7wrrNqtN","url":"https://www.examtopics.com/discussions/amazon/view/8379-exam-aws-certified-machine-learning-specialty-topic-1/","choices":{"C":"Principal component analysis (PCA)","D":"Linear regression","A":"Logistic regression","B":"Random Cut Forest (RCF)"},"exam_id":26,"answer_images":[],"question_id":317,"answer_ET":"D","answer":"D","timestamp":"2019-11-17 03:06:00","answers_community":["D (90%)","10%"],"unix_timestamp":1573956360,"answer_description":"","question_text":"A manufacturing company has a large set of labeled historical sales data. The manufacturer would like to predict how many units of a particular part should be produced each quarter.\nWhich machine learning approach should be used to solve this problem?","question_images":[],"isMC":true,"discussion":[{"comment_id":"22092","comments":[{"poster":"rsimham","upvote_count":"10","content":"agree. RCF is mostly used for anomaly detection or separate outliers","comment_id":"28394","timestamp":"1648157280.0"}],"content":"HOW MANY/MUCH, THOSE ARE REGRESSION TOPIC,\nLOGISTIC FOR 0/1,YES/NO\n\nhttps://docs.aws.amazon.com/zh_tw/machine-learning/latest/dg/regression-model-insights.html\n\nTHE ANSWER SHOULD BE D.","timestamp":"1647806700.0","upvote_count":"62","poster":"DonaldCMLIN"},{"timestamp":"1649720400.0","comment_id":"169098","poster":"syu31svc","content":"Amazon SageMaker Random Cut Forest (RCF) is an unsupervised algorithm for detecting anomalous data points within a data set\nAnswer is D 100%","upvote_count":"10"},{"content":"Selected Answer: D\nThe problem involves predicting the number of units to be produced each quarter based on historical sales data. This is a continuous numerical prediction, making it a regression problem.\n\n\nLinear regression is ideal for forecasting when there is a linear relationship between input variables (e.g., past sales, seasonal trends) and the target variable (units to be produced).\nIt helps model the relationship between past sales and future demand.\nIf there are seasonal effects, a time-series model (like ARIMA or Prophet) could be considered as well.","poster":"JonSno","timestamp":"1739840340.0","comment_id":"1358062","upvote_count":"1"},{"content":"The Answer is D. Random Cut Forest is for Anomaly Detection","poster":"[Removed]","timestamp":"1730945280.0","comment_id":"1207629","upvote_count":"1"},{"content":"D should be the answer","poster":"t47","comment_id":"1192420","upvote_count":"1","timestamp":"1728492540.0"},{"poster":"endeesa","content":"Selected Answer: D\nHow many units should give this away as Linear regression","upvote_count":"1","comment_id":"1081536","timestamp":"1716807120.0"},{"poster":"AmeeraM","comment_id":"1041649","upvote_count":"1","content":"Selected Answer: D\nI do not see any hint of anomalies here, we are looking for a number to be predicted, this seems to be the reason of the correct answer\nhttps://docs.aws.amazon.com/quicksight/latest/user/how-does-rcf-generate-forecasts.html","timestamp":"1712916480.0"},{"timestamp":"1710247920.0","upvote_count":"3","content":"Selected Answer: D\nHow can the right answer be B? That Random Cut Forest is an algorithm written for anomaly detection.","poster":"DavidRou","comment_id":"1005654"},{"upvote_count":"1","timestamp":"1709134380.0","poster":"Mickey321","comment_id":"992236","content":"Selected Answer: D\noption D"},{"timestamp":"1706732820.0","poster":"kaike_reis","content":"Selected Answer: D\nD is the correct. B is for outlier detection only.","comment_id":"968400","upvote_count":"1"},{"timestamp":"1700868180.0","poster":"earthMover","upvote_count":"1","comment_id":"906159","content":"Selected Answer: D\nIt sounds like Linear regression problem and Random Cut is more known for anomaly detection while it can do other types of ML. The answer seems to be strange with no explanation."},{"timestamp":"1694753280.0","upvote_count":"1","content":"D is correct!","comment_id":"839599","poster":"jackzhao"},{"timestamp":"1694270400.0","upvote_count":"2","comment_id":"834186","poster":"oso0348","content":"Selected Answer: D\nD. Linear regression would be the appropriate machine learning approach to solve this problem of predicting the number of units of a particular part to be produced each quarter. Linear regression is a supervised learning algorithm used for predicting continuous variables based on input features. In this case, the historical sales data can be used as input features, and the number of units produced each quarter can be used as the continuous target variable."},{"comment_id":"832717","content":"Selected Answer: D\ndefinitely D.","timestamp":"1694155800.0","upvote_count":"1","poster":"Nadia0012"},{"timestamp":"1691666760.0","comment_id":"804349","poster":"AjoseO","content":"Selected Answer: D\nThis is a regression problem where the goal is to predict a continuous outcome, which in this case is the number of units of a particular part that should be produced each quarter. Linear regression is a simple and commonly used approach to solve such problems, where a linear relationship is established between the independent variables (e.g., historical sales data) and the dependent variable (e.g., number of units of a part to be produced).","upvote_count":"2"},{"comment_id":"777104","timestamp":"1689451440.0","upvote_count":"1","content":"Selected Answer: D\nD, RCF answers here just link one article where RCF is implemented to find outliers in time series, or are able to deduce trends, but here they mention already labelled data, RCF is unsupervised, so that data would go to waste.","poster":"Tomatoteacher"},{"timestamp":"1687558260.0","content":"Honestly, i think these are all bad answers. It should be time series modeling methods.","poster":"hamimelon","comment_id":"754611","upvote_count":"2"},{"comment_id":"739667","poster":"Peeking","content":"Selected Answer: D\nThe answer is D. B is out of it as RCF is used for anomaly detection. Logistic Regression is for Classification mainly. Only linear regression can be used if Time series algorithms are not part of the options.","upvote_count":"1","timestamp":"1686268380.0"},{"poster":"Jeremy1","comment_id":"720286","content":"Selected Answer: B\nLooks like regression, but here is is... Random Cut Forest https://docs.aws.amazon.com/quicksight/latest/user/how-does-rcf-generate-forecasts.html","upvote_count":"2","timestamp":"1684300500.0"},{"upvote_count":"2","timestamp":"1677916200.0","poster":"Moulichintakunta","comment_id":"658988","content":"Selected Answer: D\nhere talks about measuring count which is a supervised regression task"},{"comment_id":"621897","content":"Selected Answer: D\nThis should be obvious.","poster":"ovokpus","timestamp":"1671928920.0","upvote_count":"1"},{"poster":"jvpigozzo","comment_id":"439940","content":"RCF goes with anomaly detection. Answer is D","timestamp":"1651239360.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1651084260.0","comment_id":"412459","poster":"boston12311","content":"Someone is having fun, highlighting silly options like RCF here. It's lin regression"},{"content":"Where does the answer come from? RCF is for anomaly detection. How can it be the right answer?","comment_id":"372857","poster":"AWS__Newbie","upvote_count":"2","timestamp":"1650598860.0"},{"timestamp":"1650459120.0","content":"D!!!!!!","comment_id":"313157","upvote_count":"2","poster":"littlewat"},{"content":"Its a regression problem - for sure D!","timestamp":"1650242220.0","upvote_count":"2","comment_id":"291031","poster":"astonm13"},{"poster":"cloud_trail","upvote_count":"1","comment_id":"278566","content":"If you see this question on the exam, give thanks because it doesn't get any easier than this. Your basic linear regression -- D.","timestamp":"1649932260.0"},{"upvote_count":"3","timestamp":"1649822520.0","content":"It is a regression problem which only linear regression can solve it in the options. D is the correct answer.","poster":"fhuadeen","comment_id":"173430"},{"timestamp":"1649298120.0","upvote_count":"1","content":"linear regression","poster":"k115","comment_id":"115587"},{"timestamp":"1649070480.0","content":"random cut is mainly for anomly detection this is related to regression so linear regression should be correct ans","comment_id":"85570","poster":"Sadhna","upvote_count":"4"},{"poster":"rt1512","upvote_count":"6","content":"It is B. Overall, this approach provides significantly more robust forecasts in comparison to other widely available algorithms such as ETS.\nhttps://docs.aws.amazon.com/quicksight/latest/user/how-does-rcf-generate-forecasts.html","comment_id":"83369","timestamp":"1648963980.0"},{"comment_id":"51111","content":"No way to use RCF. It should be a regression problem, so D is the answer","timestamp":"1648415820.0","upvote_count":"5","poster":"Phong"}],"topic":"1"},{"id":"4ODWR0HmSdq0DeG62WbV","question_text":"A financial services company is building a robust serverless data lake on Amazon S3. The data lake should be flexible and meet the following requirements:\nâœ‘ Support querying old and new data on Amazon S3 through Amazon Athena and Amazon Redshift Spectrum.\nâœ‘ Support event-driven ETL pipelines\nâœ‘ Provide a quick and easy way to understand metadata\nWhich approach meets these requirements?","topic":"1","timestamp":"2019-11-17 03:26:00","question_images":[],"unix_timestamp":1573957560,"exam_id":26,"choices":{"C":"Use an AWS Glue crawler to crawl S3 data, an Amazon CloudWatch alarm to trigger an AWS Batch job, and an AWS Glue Data Catalog to search and discover metadata.","D":"Use an AWS Glue crawler to crawl S3 data, an Amazon CloudWatch alarm to trigger an AWS Glue ETL job, and an external Apache Hive metastore to search and discover metadata.","A":"Use an AWS Glue crawler to crawl S3 data, an AWS Lambda function to trigger an AWS Glue ETL job, and an AWS Glue Data catalog to search and discover metadata.","B":"Use an AWS Glue crawler to crawl S3 data, an AWS Lambda function to trigger an AWS Batch job, and an external Apache Hive metastore to search and discover metadata."},"question_id":318,"answer":"A","isMC":true,"discussion":[{"upvote_count":"45","comment_id":"22096","comments":[{"comments":[{"upvote_count":"4","poster":"qwerty456","comments":[{"content":"We can schedule batch with cloud watch events.","timestamp":"1667539740.0","upvote_count":"1","comment_id":"252338","poster":"kalyanvarma"},{"upvote_count":"2","poster":"qwerty456","comment_id":"131139","content":"srr, looks like you can apart from Cron, the argument should be AWS Batch aren't SERVERLESS","timestamp":"1667178840.0"}],"timestamp":"1667131440.0","content":"you can't schedule AWS Batch with CloudWatch","comment_id":"131137"},{"comment_id":"34969","timestamp":"1664628900.0","poster":"ComPah","upvote_count":"4","content":"if we use Flexible as key word ..Using Lambda might be a constraint"}],"upvote_count":"1","timestamp":"1663820460.0","comment_id":"28397","poster":"rsimham","content":"I am thinking about Answer C, because events can be triggered by cloudwatch w/Glue metastore"}],"timestamp":"1663754820.0","content":"BOTH A AND B ARE ANSWERS.\n\nBUT external Apache Hive MIGHT BE NOT SERVERLESS SOLUTION.\n\nThe AWS Glue Data Catalog is your persistent metadata store. It is a managed service that lets you store, annotate, and share metadata in the AWS Cloud in the same way you would in an Apache Hive metastore.\nThe Data Catalog is a drop-in replacement for the Apache Hive Metastore\n\nhttps://docs.aws.amazon.com/zh_tw/glue/latest/dg/components-overview.html\n\nBEAUTIFUL ANSWER IS A.","poster":"DonaldCMLIN"},{"poster":"cybe001","upvote_count":"18","comments":[{"content":"agree, event-driven means Lambda, CloudWatch alarms are just to trigger alarms based on log analysis.","comment_id":"671118","poster":"rb39","upvote_count":"3","timestamp":"1694898120.0"}],"timestamp":"1664891460.0","content":"Answer is A. Lamda is the preferred way of implementing event-driven ETL job with S3, when new data arrives in S3, it notifies lamda which can start the ETL job.","comment_id":"39908"},{"poster":"loict","upvote_count":"2","comment_id":"1007287","content":"Selected Answer: A\nA. YES - all integrated components\nB. NO - missing a component to invoke the Lambda\nC. NO - CloudWatch will not trigger when there is a new file to process\nD. NO - CloudWatch will not trigger when there is a new file to process","timestamp":"1726295220.0"},{"upvote_count":"1","content":"Selected Answer: A\nA for me","comment_id":"992238","timestamp":"1724852100.0","poster":"Mickey321"},{"timestamp":"1722451020.0","poster":"kaike_reis","content":"Selected Answer: A\nNote that the question asks for a serverless system. In this case, the letters B, C and D are wrong, as they bring options that are managed: AWS Batch (managed) and external Apache Hive (even more managed). For event-driven AWS ETL solutions that are serverless, activation through the Lambda function is recommended, so the correct alternative is Letter A. Note that CloudWatch Alarms only activates from log evaluation, which is not mentioned in the question.","upvote_count":"1","comment_id":"968410"},{"comment_id":"832997","poster":"jackzhao","upvote_count":"1","content":"I will chose A, I think C & D is wrong, you can use Amazon CloudWatch Event to trigger lambda but not CloudWatch alarm.","timestamp":"1709904540.0"},{"timestamp":"1709890500.0","content":"Selected Answer: A\nBatch is more for configurations and other kinds of things by scheduling than event driven and batch data processing with ETL, the answer is A.","poster":"Valcilio","comment_id":"832776","upvote_count":"1"},{"content":"Selected Answer: A\nFound this supporting A - Lambda used to trigger ETL job after crawler completes. The crawler starts on schedules or events (files arriving).","upvote_count":"1","comment_id":"720289","poster":"Jeremy1","timestamp":"1700205540.0"},{"upvote_count":"2","timestamp":"1689212520.0","content":"Selected Answer: A\nBased on Majority discussion","comment_id":"630742","poster":"Skychaser"},{"comments":[{"timestamp":"1713883500.0","comment_id":"878490","content":"cloudwatch and lambda function can work together to trigger event. But AWS batch cannot independently conduct ETL and require other service. when it comes to ETL, glue is much easier choice than Batch","upvote_count":"1","poster":"ZSun"},{"comment_id":"723230","content":"Agreed. CloudWatch could trigger event to launch Lambda. Refer to: https://docs.aws.amazon.com/lambda/latest/dg/services-cloudwatchevents.html","upvote_count":"1","poster":"VinceCar","timestamp":"1700552100.0"}],"timestamp":"1685266980.0","content":"Selected Answer: C\nQuite confused between A&C since they all workable solution. In below AWS Blog, even mix the CloudWatch + Lambda to use the Glue. For key word event trigger, prefer CloudWatch\nhttps://aws.amazon.com/blogs/big-data/build-and-automate-a-serverless-data-lake-using-an-aws-glue-trigger-for-the-data-catalog-and-etl-jobs/\nhttps://docs.aws.amazon.com/glue/latest/dg/automating-awsglue-with-cloudwatch-events.html","comment_id":"608341","poster":"exam887","upvote_count":"2"},{"poster":"syu31svc","comment_id":"169104","content":"Answer is A 100%","timestamp":"1667314980.0","upvote_count":"2"},{"content":"A is preferred. Lambda can trigger ETL pipelines: https://aws.amazon.com/glue/","poster":"halfway","comment_id":"109856","upvote_count":"3","timestamp":"1666659360.0"},{"poster":"PRC","content":"A is correct...Lambda is event driven and Glue is serverless as opposed to Hive","timestamp":"1665152580.0","comment_id":"65644","upvote_count":"4"}],"answer_ET":"A","answers_community":["A (80%)","C (20%)"],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/8382-exam-aws-certified-machine-learning-specialty-topic-1/","answer_description":""},{"id":"mFJTQautEnF3N3m6EKW3","answer_images":[],"answer_description":"","question_text":"A company's Machine Learning Specialist needs to improve the training speed of a time-series forecasting model using TensorFlow. The training is currently implemented on a single-GPU machine and takes approximately 23 hours to complete. The training needs to be run daily.\nThe model accuracy is acceptable, but the company anticipates a continuous increase in the size of the training data and a need to update the model on an hourly, rather than a daily, basis. The company also wants to minimize coding effort and infrastructure changes.\nWhat should the Machine Learning Specialist do to the training solution to allow it to scale for future demand?","question_id":319,"exam_id":26,"answers_community":["B (75%)","C (20%)","5%"],"discussion":[{"timestamp":"1632645720.0","upvote_count":"38","comment_id":"35298","content":"the answer is B. using Hovord distribution results in less coding effort","poster":"JayK"},{"upvote_count":"15","comment_id":"39910","timestamp":"1633219140.0","content":"Answer is B. \"minimize coding effort and infrastructure changes\" If we use DeepAR then the code and infra has to be changed to work with DeepAR.","poster":"cybe001"},{"comment_id":"1234385","content":"Selected Answer: C\nA. NO, this will not address training dataset continuous increase\nB. NO, this will require code effort and infrastructure change\nC. YES, a built-in model ensure low code effort, so only infrastructure change needed*\nD. This will not work\n\n* they say current model accuracy is acceptable, we doo expect good results with DeepAR as it allows to automatically pick among 5 different models what works best for the customer","timestamp":"1718970780.0","comments":[{"timestamp":"1719063720.0","comment_id":"1235419","poster":"ninomfr64","upvote_count":"2","content":"DeepAR doesn't pick among 5 models. However, I still think that switching to DeepAR can assure accuracy and minimize coding effort as the model is built-in"}],"upvote_count":"4","poster":"ninomfr64"},{"poster":"VR10","content":"A comes with minimum changes, but it wont scale.\nB code changes are minimum but infrastructure still needs to be changed to achieve a distributed solution.\nC. Is even more significant infra and code change.\nD. wont work.\nIt is really subjective and tricky.\nCould be A or B, depending on what change is considered \"SMALL\".\nFor scalability, B seems better. for quick win A could work.\nI keep going back and forth.","upvote_count":"1","comment_id":"1154582","timestamp":"1708419780.0"},{"content":"Selected Answer: B\nA. NO - one time shot and not scalable\nB. YES - best practice\nC. NO - DeepAR is for forecasting\nD. NO - code will not benefit from parallelization without change","comment_id":"1007293","timestamp":"1694673180.0","poster":"loict","upvote_count":"4"},{"content":"Selected Answer: B\noption B","comment_id":"992240","poster":"Mickey321","upvote_count":"2","timestamp":"1693229820.0"},{"comment_id":"968415","content":"Selected Answer: B\nNote that we want to increase training speed, minimize code and infrastructure modification effort on AWS. Letter A would only delay the problem and increase costs too much. The solution that best translates the problem would be Letter B: we would keep the code in tensorflow and use Horovod to make our training faster through parallelization. Letter D is too complex and would change the execution infrastructure a lot and Letter C would be too abrupt a turn as we would throw our model away.","upvote_count":"2","poster":"kaike_reis","timestamp":"1690829040.0"},{"poster":"ZSun","content":"A is better option even though B helps. Firstly, you only have One GPU, in this case distributed training Horovod doesn't help much;\nSecondly, the question is about minimize \"coding effort\" not minimize budget. adding distributed framework require much more coding, but increase gpu instance only require single click.","upvote_count":"1","comment_id":"876745","timestamp":"1682100000.0"},{"content":"Selected Answer: B\nHorovod distribution is accepted by sagemaker, making easy to implement!","poster":"Valcilio","upvote_count":"1","timestamp":"1678268160.0","comment_id":"832779"},{"upvote_count":"4","comment_id":"804353","poster":"AjoseO","content":"Selected Answer: B\nHovord distribution will allow the Machine Learning Specialist to take advantage of Amazon SageMaker's built-in support for Horovod, which is a popular, open-source distributed deep learning framework. \n\nImplementing Horovod in TensorFlow will allow the Specialist to parallelize the training across multiple GPUs or instances, which can significantly reduce the time it takes to train the model. \n\nThis will allow the company to meet its requirement to update the model on an hourly basis, and minimize coding effort and infrastructure changes as it leverages the existing TensorFlow code and infrastructure, along with the scalability and ease of use of Amazon SageMaker.","timestamp":"1676035740.0"},{"comment_id":"792208","timestamp":"1675039080.0","upvote_count":"1","poster":"joe3232","content":"Are is there a 23X differential between the weakest and strongest GPU in AWS? (and allow for future growth). I don' tthink so."},{"content":"Answer:C- built-in sagemaker DeepAR model. minimize coding & infra changes.","poster":"vbal","upvote_count":"1","comment_id":"773102","comments":[{"content":"But they are happy with it - just want it to go faster. Not throw the whole thing out.","timestamp":"1678135200.0","poster":"cpal012","comment_id":"831244","upvote_count":"1"}],"timestamp":"1673495100.0"},{"timestamp":"1657101120.0","upvote_count":"2","comment_id":"627811","content":"Selected Answer: B\nthe answer is B. using Hovord distribution results in less coding effort","poster":"KingGuo"},{"comment_id":"551624","upvote_count":"1","timestamp":"1645342440.0","poster":"John_Pongthorn","content":"Selected Answer: A\nMost likely , it is A because it is based on AWS teachnoloy, why we have to use open source\n\nwe exam AWS ML , the answer should be relevant to AWS technology inevitably\nhttps://aws.amazon.com/sagemaker/distributed-training/"},{"content":"This one reminds me of an old saying by Yogi Berra: \"When you come to a fork in the road, take it.\" If you see Horovod as an option in a question about scaling TF, take it. Answer is B.","upvote_count":"9","poster":"cloud_trail","comment_id":"280326","timestamp":"1636289280.0"},{"comment_id":"279219","content":"I Think it's B \nhttps://aws.amazon.com/blogs/machine-learning/launching-tensorflow-distributed-training-easily-with-horovod-or-parameter-servers-in-amazon-sagemaker/\n &\nhttps://aws.amazon.com/blogs/machine-learning/multi-gpu-and-distributed-training-using-horovod-in-amazon-sagemaker-pipe-mode/","upvote_count":"5","poster":"RaniaSayed","timestamp":"1635869880.0"},{"content":"Seen similar question on udemy/whizlab , its always Horvord when Tensorflow needs scaling. ANWSER is B","comment_id":"263458","upvote_count":"5","poster":"harmanbirstudy","timestamp":"1635477000.0"},{"content":"\"Minimize code and infrastructure changes\" and \"training set size increasing continuously\" are in conflict.\n\nThe latter is necessary, while the former is more optional. This rules out A, because it will not scale to continuously-increasing dataset size for daily training.\n\nC requires a total rewrite, which does not minimize coding effort.\n\nThis leaves B and D, and the question will be which is easier to implement. EMR is not, especially, known for being easy to implement, whereas Horovod + SageMaker specifically are. Also SageMaker is a named AWS service and is extremely expensive, so of course that's what Amazon recommends. :)","poster":"yeetusdeleetus","timestamp":"1635156960.0","upvote_count":"1","comment_id":"212462"},{"poster":"sebtac","upvote_count":"2","timestamp":"1634980440.0","content":"correct answer is B; the expected probably is C as AWS wants us to use their own solutions :)","comment_id":"174098"},{"poster":"syu31svc","upvote_count":"1","timestamp":"1634971500.0","content":"I would say that the answer is A and this is just my reasoning:\n\nMinimize infrastructure changes would mean saving costs. Having to increase the number of machines to \"as many as possible\" would increase costs. Also, from https://d1.awsstatic.com/whitepapers/aws-power-ml-at-scale.pdf:\nIf the training times on a GPU card are insufficient for your business needs, we recommend that you try a more powerful GPU before moving to multiple GPUs","comment_id":"171934"},{"upvote_count":"3","content":"Possible B or C because of scaling and future needs. But Switching TensorFlow to DeepAT for time-series forecasting would be more effort imho than re-coding to horovod. I would choose B.","timestamp":"1633954740.0","comment_id":"93620","poster":"mawsman"},{"comment_id":"89557","poster":"deep_n","timestamp":"1633864620.0","content":"Correct answer is B","upvote_count":"2"},{"timestamp":"1633426320.0","poster":"VB","comment_id":"60788","upvote_count":"2","comments":[{"comment_id":"81573","timestamp":"1633784760.0","upvote_count":"1","content":"Correct point of view! With B you have to change the code and implement infrastructure change and the question says \"The company also wants to minimize coding effort and infrastructure changes\"...I'll go with A","poster":"Erso","comments":[{"content":"True but does it \"allow it to scale for future demand\" ?","poster":"BigPlums","upvote_count":"1","timestamp":"1633827120.0","comment_id":"81811"}]}],"content":"The question does not talk about running that application in AWS.. the question is very general MI related..and \"...The company also wants to minimize coding effort and infrastructure changes...\". So, can answer be A ?"},{"upvote_count":"2","timestamp":"1633391820.0","comment_id":"47637","comments":[{"content":"I opt A. \nhttps://aws.amazon.com/blogs/machine-learning/launching-tensorflow-distributed-training-easily-with-horovod-or-parameter-servers-in-amazon-sagemaker/\n\n\"Before moving to distributed training in a cluster, make sure that you have first tried scaling up on a single machine with multiple GPUs. Communication between multiple GPUs on a single machine is faster than communicating across a network between multiple machines. For more details, see the AWS whitepaper Power Machine Learning at Scale.\"","upvote_count":"4","poster":"Littlefishfish","comments":[{"poster":"lightblue","comment_id":"251889","timestamp":"1635278940.0","content":"not sure if they mean multiple GPU by this -> 'Change the machine to one with a more powerful GPU'","upvote_count":"2"}],"comment_id":"101410","timestamp":"1634645160.0"}],"content":"Why not A?","poster":"tap123"},{"comment_id":"28401","poster":"rsimham","comments":[{"upvote_count":"1","poster":"ComPah","comment_id":"34973","content":"Looks like C if you take minimize coding as key word","comments":[{"upvote_count":"7","content":"Its B from Horovod github page\nThe primary motivation for this project is to make it easy to take a single-GPU TensorFlow program and successfully train it on many GPUs faster.","poster":"ComPah","comment_id":"39806","timestamp":"1633022520.0"}],"timestamp":"1632524640.0"}],"timestamp":"1632400320.0","content":"I think Answer is C.\nhttps://aws.amazon.com/blogs/machine-learning/now-available-in-amazon-sagemaker-deepar-algorithm-for-more-accurate-time-series-forecasting/","upvote_count":"1"}],"topic":"1","unix_timestamp":1575944640,"choices":{"D":"Move the training to Amazon EMR and distribute the workload to as many machines as needed to achieve the business goals.","A":"Do not change the TensorFlow code. Change the machine to one with a more powerful GPU to speed up the training.","C":"Switch to using a built-in AWS SageMaker DeepAR model. Parallelize the training to as many machines as needed to achieve the business goals.","B":"Change the TensorFlow code to implement a Horovod distributed framework supported by Amazon SageMaker. Parallelize the training to as many machines as needed to achieve the business goals."},"answer_ET":"B","question_images":[],"timestamp":"2019-12-10 03:24:00","url":"https://www.examtopics.com/discussions/amazon/view/10082-exam-aws-certified-machine-learning-specialty-topic-1/","answer":"B","isMC":true},{"id":"7HMPphOfE15tyPL2PINv","exam_id":26,"answer_description":"","question_id":320,"question_text":"Which of the following metrics should a Machine Learning Specialist generally use to compare/evaluate machine learning classification models against each other?","answer_images":[],"timestamp":"2019-11-17 04:07:00","unix_timestamp":1573960020,"question_images":[],"discussion":[{"poster":"DonaldCMLIN","content":"RECALL IS ONE OF FACTOR IN CLASSIFY,\n\nAUC IS MORE FACTORS TO COMPREHENSIVE JUDGEMENT\nhttps://docs.aws.amazon.com/zh_tw/machine-learning/latest/dg/cross-validation.html\n\nANSWER MIGHT BE D.","comment_id":"22098","timestamp":"1647765960.0","comments":[{"comment_id":"50254","upvote_count":"6","poster":"devsean","content":"AUC is to determine hyperparams in a single model, not compare different models.","timestamp":"1647783420.0"},{"comment_id":"107086","content":"Not might be, but should be D","poster":"DScode","timestamp":"1650490200.0","upvote_count":"5"}],"upvote_count":"38"},{"content":"Selected Answer: D\nArea Under the ROC Curve (AUC) is a commonly used metric to compare and evaluate machine learning classification models against each other. The AUC measures the model's ability to distinguish between positive and negative classes, and its performance across different classification thresholds. The AUC ranges from 0 to 1, with a score of 1 representing a perfect classifier and a score of 0.5 representing a classifier that is no better than random.\n\nWhile recall is an important evaluation metric for classification models, it alone is not sufficient to compare and evaluate different models against each other. Recall measures the proportion of actual positive cases that are correctly identified as positive, but does not take into account the false positive rate.","timestamp":"1691667060.0","poster":"AjoseO","comment_id":"804355","comments":[{"content":"chatgpt answers, all your answers are from chatgpt","timestamp":"1706556660.0","upvote_count":"2","poster":"ccpmad","comment_id":"966545"}],"upvote_count":"5"},{"poster":"AsusTuf","comments":[{"timestamp":"1731681360.0","content":"it's a classification problem, mape is for regression","poster":"Scrook","comment_id":"1211929","upvote_count":"2"}],"content":"why not C?","upvote_count":"1","comment_id":"1040295","timestamp":"1712820120.0"},{"comment_id":"992241","timestamp":"1709134680.0","poster":"Mickey321","content":"Selected Answer: D\noption D","upvote_count":"1"},{"timestamp":"1694158620.0","upvote_count":"1","content":"Selected Answer: D\nAUC is the best metric.","comment_id":"832780","poster":"Valcilio"},{"timestamp":"1651498500.0","comment_id":"278575","poster":"cloud_trail","content":"D. AUC is always used to compare ML classification models. The others can all be misleading. Consider the cases where classes are highly imbalanced. In those cases accuracy, misclassification rate and the like are useless. Recall is only useful if used in combination with precision or specificity, which what AUC does.","upvote_count":"4"},{"upvote_count":"5","comment_id":"263469","content":"AUC/ROC work well with special case of Binary Classification not in general","timestamp":"1651333560.0","comments":[{"upvote_count":"4","timestamp":"1651437480.0","content":"AUC is to compare different models in terms of their separation power. 0.5 is useless as it's the diagonal line. 1 is perfect. I would go with F1 Score if it was an option. However, taking Recall only as a metric for comparing between models, would be misleading.","comment_id":"274389","poster":"MohamedSharaf"}],"poster":"harmanbirstudy"},{"comment_id":"263466","upvote_count":"1","comments":[{"poster":"DavidRou","comment_id":"1005662","timestamp":"1710249060.0","upvote_count":"1","content":"When you draw the ROC graph, you're considering True and False Positive Rate. The first one is also called Recall ;)"}],"poster":"harmanbirstudy","content":"Its Accuracy,Precision,Recall and F1 score , there is no metion of AUC/ROC for comparing models in many articles , so ANSWER is A","timestamp":"1651215000.0"},{"upvote_count":"1","poster":"Thai_Xuan","content":"D. AUC is scale- and threshold-invariant, enabling it compare models.\nhttps://towardsdatascience.com/how-to-evaluate-a-classification-machine-learning-model-d81901d491b1","timestamp":"1650939180.0","comment_id":"193330"},{"comment_id":"127776","content":"Actually A, B and D seem to be correct","poster":"johnny_chick","timestamp":"1650552360.0","upvote_count":"1"},{"content":"Probably D\nhttps://towardsdatascience.com/metrics-for-evaluating-machine-learning-classification-models-python-example-59b905e079a5","poster":"deep_n","comment_id":"89560","upvote_count":"2","timestamp":"1650117000.0"},{"content":"why not B?","timestamp":"1649718000.0","poster":"hughhughhugh","upvote_count":"1","comment_id":"79265"},{"content":"Answer should be D..ROC is used to determine the diagnostic capability of classification model varying on threshold","poster":"PRC","comment_id":"65483","upvote_count":"3","timestamp":"1649566980.0"},{"comment_id":"58895","comments":[{"upvote_count":"1","poster":"oMARKOo","timestamp":"1650730800.0","comment_id":"190875","content":"Actually AUC could be generalized for multi-class problem.\nhttps://www.datascienceblog.net/post/machine-learning/performance-measures-multi-class-problems/"},{"upvote_count":"2","comments":[{"upvote_count":"1","content":"Also in multi-class classification, if you follow an One-vs_Rest strategy you can still use AUC.\nhttps://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py","poster":"mrsimoes","timestamp":"1650569340.0","comment_id":"171418"}],"timestamp":"1650397800.0","content":"Could be, you mean in a multiclass clasification problem. But in that con context recall directly can't be compare because first you have to decide recall of what of the classes, in a 3 classes problem we have 3 recalls or you suppose a weighted recall or average recall ?. Do you think in that ?","poster":"sebas10","comment_id":"106925"}],"timestamp":"1649148540.0","poster":"Hypermasterd","upvote_count":"4","content":"Should be A. A is the only one that generally works for classifcation.\nAUC only works with binary classification."},{"comment_id":"57058","content":"Correct Answer is D. Another benefit of using AUC is that it is classification-threshold-invariant like log loss. \nhttps://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226","timestamp":"1648211760.0","upvote_count":"3","poster":"stamarpadar"}],"choices":{"A":"Recall","B":"Misclassification rate","D":"Area Under the ROC Curve (AUC)","C":"Mean absolute percentage error (MAPE)"},"url":"https://www.examtopics.com/discussions/amazon/view/8384-exam-aws-certified-machine-learning-specialty-topic-1/","isMC":true,"answer_ET":"D","answers_community":["D (100%)"],"topic":"1","answer":"D"}],"exam":{"provider":"Amazon","isBeta":false,"isImplemented":true,"name":"AWS Certified Machine Learning - Specialty","numberOfQuestions":369,"id":26,"lastUpdated":"11 Apr 2025","isMCOnly":false},"currentPage":64},"__N_SSP":true}