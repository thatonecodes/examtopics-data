{"pageProps":{"questions":[{"id":"o3hmWeMiiPuoQt6xSzJh","topic":"1","exam_id":31,"timestamp":"2022-10-10 10:55:00","answer_description":"","question_images":[],"answer_ET":"A","choices":{"A":"Turn on S3 Transfer Acceleration on the destination S3 bucket. Use multipart uploads to directly upload site data to the destination S3 bucket.","B":"Upload the data from each site to an S3 bucket in the closest Region. Use S3 Cross-Region Replication to copy objects to the destination S3 bucket. Then remove the data from the origin S3 bucket.","D":"Upload the data from each site to an Amazon EC2 instance in the closest Region. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. At regular intervals, take an EBS snapshot and copy it to the Region that contains the destination S3 bucket. Restore the EBS volume in that Region.","C":"Schedule AWS Snowball Edge Storage Optimized device jobs daily to transfer data from each site to the closest Region. Use S3 Cross-Region Replication to copy objects to the destination S3 bucket."},"isMC":true,"question_id":1,"url":"https://www.examtopics.com/discussions/amazon/view/84973-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"poster":"PhucVuu","timestamp":"1727009340.0","content":"Selected Answer: A\nKeyword: \nFrom GLOBAL sites as quickly as possible in a SINGLE S3 bucket.\nMinimize operational complexity\n\nA. is correct because S3 Transfer Acceleration is support for high speed transfer in Edge location and you can upload it immediately. Also with multipart uploads your big file can be uploaded in parallel.\nB, C, D. is not minimize operational and fast when compare to answer A","comment_id":"859494","upvote_count":"17"},{"upvote_count":"11","content":"General line: Collect huge amount of the files across multiple continents\nConditions: High speed Internet connectivity\nTask: aggregate the data from all in a single S3 bucket\nRequirements: as quick as possible, minimize operational complexity\n\nCorrect answer A: S3 Transfer Acceleration because:\n- ideally works with objects for long-distance transfer (uses Edge Locations)\n- can speed up content transfers to and from S3 as much as 50-500%\n- use cases: mobile & web application uploads and downloads, distributed office transfers, data exchange with trusted partners. Generally for sharing of large data sets between companies, customers can set up special access to their S3 buckets with accelerated uploads to speed data exchanges and the pace of innovation.\n\nB - about disaster recovery\nC - about transferring data between your local environment and the AWS Cloud\nD - about disaster recovery","comments":[{"content":"C, we DO have a \"local environment\" (a \"site\") that collect data, and THAT data must go to \"the AWS cloud\". Why not C? The stem says nothing about large objects, which would be a requirement for the \"multipart upload\" that is mentioned.","comment_id":"1104566","upvote_count":"3","timestamp":"1703419320.0","poster":"pentium75"}],"poster":"Ruffyit","timestamp":"1726902780.0","comment_id":"1073122"},{"comment_id":"1458796","content":"Selected Answer: A\nI think that should be option A Thanks to P A S S C E R T H U B","poster":"AndrewPau","upvote_count":"4","timestamp":"1743758880.0"},{"poster":"Wylla","upvote_count":"1","comment_id":"1413829","content":"Selected Answer: A\nthe simplest way","timestamp":"1743370680.0"},{"timestamp":"1742827980.0","poster":"Sreejaggu","comment_id":"1409693","upvote_count":"1","content":"Selected Answer: A\nEliminating other options, Option A is feasible and cost efficient."},{"content":"Selected Answer: A\nA for sure","comment_id":"1400400","poster":"ted21","timestamp":"1742365080.0","upvote_count":"1"},{"content":"Selected Answer: A\nchon A","poster":"namnv080808","comment_id":"1374837","upvote_count":"1","timestamp":"1741569600.0"},{"poster":"mc0226","comment_id":"1365794","content":"Selected Answer: A\nS3 Acceleration is more proper with less operation in this case","timestamp":"1741247100.0","upvote_count":"1"},{"comment_id":"1364991","upvote_count":"2","timestamp":"1741104840.0","poster":"Dantecito","content":"Selected Answer: A\nOptions B and D are technically possible solutions, but.\nB. The cost is high, the process is slower, and it is more complex.\nC. This option is not feasible. You would need to purchase Snowball devices, wait for them to arrive, upload the 500GB of data, and then ship them back. This process is not practical for daily use. Snowball devices are designed for one-time uploads of terabytes of data, not for routine or smaller-scale transfers.\nD. Using EC2 instances, EBS volumes, and cross-Region snapshots is also not ideal. The cost is significantly higher, and the process is overly complex for this scenario."},{"timestamp":"1740692940.0","poster":"ConnorNoah44","upvote_count":"1","content":"Selected Answer: A\nI think that should be option A","comment_id":"1362739"},{"content":"Selected Answer: A\nI think that should be option A","upvote_count":"1","poster":"teeee123","timestamp":"1740111000.0","comment_id":"1359619"},{"comment_id":"1359292","poster":"Bl_12","upvote_count":"1","timestamp":"1740062160.0","content":"Selected Answer: B\nS3 bucket"},{"timestamp":"1736748060.0","upvote_count":"3","poster":"piya161","content":"Selected Answer: A\nHi All,\nI have gone through the exam today and it was bit tough, none of the questions in the exam came from examtopics, i have gone mostly around 150 questions. The questions we go through here are quite easy compared to actual ones. i just suggest everyone to go through some youtube (\nsthithapragna) videos as well apart from examtopics. YT videos were found quite accurate to the exams which i have attempted today.(1/13/2025).Hope this review helps everyone.","comment_id":"1339802"},{"timestamp":"1735808100.0","poster":"liamezr","comment_id":"1335413","upvote_count":"1","content":"Selected Answer: A\nExplanation:\nOption B suggests uploading the data from each site to an S3 bucket in the closest Region. This ensures that the data is transferred quickly over high-speed Internet connections. By using S3 Cross-Region Replication, the objects can be automatically copied to the destination S3 bucket, allowing for easy aggregation"},{"content":"Selected Answer: A\nAmazon S3 Transfer Acceleration meets the requirements by ensuring fast, secure, and simple global data uploads with minimal operational overhead.","timestamp":"1735694400.0","comment_id":"1335092","upvote_count":"1","poster":"ANDREWKIM1"},{"timestamp":"1735236480.0","comment_id":"1332051","poster":"samuelbrandao","content":"Selected Answer: A\nTransfer Aceleration com multpart upload é a opção menos complexa","upvote_count":"1"},{"timestamp":"1735136460.0","comment_id":"1331578","upvote_count":"1","content":"Selected Answer: A\nAWS Global Accelerator is a networking service that improves the performance and availability of your applications by leveraging the global infrastructure of AWS. It provides two key benefits:\n\nImproved Performance:\n\nGlobal Accelerator uses the AWS global network to direct user traffic to the nearest AWS Region or endpoint, reducing latency.\nIt supports TCP and UDP traffic and can significantly enhance the performance of latency-sensitive applications, such as gaming, IoT, or streaming.\nIncreased Availability:\n\nGlobal Accelerator provides automatic failover between endpoints in multiple AWS Regions or Availability Zones. If one endpoint becomes unavailable, the traffic is rerouted to the next best endpoint.","poster":"MGKYAING"}],"unix_timestamp":1665392100,"answer_images":[],"question_text":"A company collects data for temperature, humidity, and atmospheric pressure in cities across multiple continents. The average volume of data that the company collects from each site daily is 500 GB. Each site has a high-speed Internet connection.\nThe company wants to aggregate the data from all these global sites as quickly as possible in a single Amazon S3 bucket. The solution must minimize operational complexity.\nWhich solution meets these requirements?","answers_community":["A (94%)","6%"],"answer":"A"},{"id":"Uzhe6w78XW0WFF48aH5f","unix_timestamp":1665216660,"question_id":2,"topic":"1","answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/84681-exam-aws-certified-solutions-architect-associate-saa-c03/","answers_community":["B (98%)","2%"],"timestamp":"2022-10-08 10:11:00","question_images":[],"discussion":[{"content":"Selected Answer: B\nB because FIFO is made for that specific purpose","upvote_count":"68","comment_id":"689128","timestamp":"1726990440.0","poster":"Sinaneos"},{"poster":"rein_chau","content":"Selected Answer: B\nShould be B because SQS FIFO queue guarantees message order.","upvote_count":"28","timestamp":"1665234660.0","comment_id":"689332"},{"timestamp":"1740386640.0","upvote_count":"1","content":"Selected Answer: B\nFIFO make sure to send the data exactly in the same order","comment_id":"1360919","poster":"offek"},{"poster":"ak240519","timestamp":"1739460960.0","content":"Selected Answer: B\nB is the only solution that guarantees message order.","upvote_count":"1","comment_id":"1356186"},{"poster":"adamatic","comment_id":"1350827","content":"Selected Answer: B\nHas to be FIFO queue for this requirement","timestamp":"1738579020.0","upvote_count":"1"},{"content":"Selected Answer: B\nSQS FIFO as if want to maintain order of messages recieved to order of messages sent. It is like QUEUE data structutre in DSA","timestamp":"1737698760.0","poster":"Mrigraj12","comment_id":"1345914","upvote_count":"1"},{"timestamp":"1736997960.0","comment_id":"1341358","content":"Selected Answer: B\nSQS FIFO gurantees message order.","upvote_count":"1","poster":"surez"},{"content":"Selected Answer: B\nExplanation:\nFIFO Queues: Amazon SQS FIFO queues are specifically designed to maintain the order of messages. This ensures that messages are processed in the exact sequence they were sent, which is crucial for order processing in an e-commerce application.\n\nWhy other options are less suitable:\nA. Amazon SNS: SNS is a publish-subscribe service. It doesn't guarantee message order.\nC. API Gateway Authorizer: Authorizers are used for authentication and authorization, not for managing message order.\nD. Amazon SQS Standard Queue: Standard SQS queues do not guarantee message order.","upvote_count":"3","timestamp":"1735140780.0","poster":"MGKYAING","comment_id":"1331621"},{"upvote_count":"3","content":"Standard queues ensure at-least-once message delivery, but due to the highly distributed architecture, more than one copy of a message might be delivered, and messages may occasionally arrive out of order.","timestamp":"1728509580.0","comment_id":"1295294","poster":"ondan"},{"poster":"Abishek016","upvote_count":"2","comment_id":"1290476","timestamp":"1727491980.0","content":"AnswerB - SQS FIFO queues ensure that messages are processed in the order they are received, which perfectly matches the requirement of maintaining order."},{"content":"A lot of answers seem to not match the most voted. i'm confused which to follow.","poster":"paobalinas","comment_id":"1288836","timestamp":"1727225760.0","upvote_count":"2"},{"poster":"gx2222","timestamp":"1726904340.0","upvote_count":"5","content":"Selected Answer: B\nExplanation:\n\nTo ensure that orders are processed in the order that they are received, the best solution is to use an Amazon SQS FIFO (First-In-First-Out) queue. This type of queue maintains the exact order in which messages are sent and received.\n\nIn this case, the application can send information about new orders to an Amazon API Gateway REST API, which can then use an API Gateway integration to send a message to an Amazon SQS FIFO queue for processing. The queue can then be configured to invoke an AWS Lambda function to perform the necessary processing on each order. This ensures that orders are processed in the exact order in which they are received.","comment_id":"859087"},{"content":"Selected Answer: B\nKeywords:\n- Orders are processed in the order that they are received.\n\nA: Incorrect - SNS just for notification like send email, SMS. It don't retain the data in the queue and it's used pub-sub pattern.\nB: Correct - SQS FIFO will help message process in order. FIFO -> first in first out.\nC: Incorrect - with this solution we will create blocker app not good app =))\nD: Incorrect - SQS standard don't guarantee the order.","poster":"PhucVuu","timestamp":"1726904340.0","comment_id":"860761","upvote_count":"12"},{"comment_id":"957541","content":"Selected Answer: B\nExplanation:\n- Amazon API Gateway will be used to receive the orders from the web application.\n- Instead of directly processing the orders, the API Gateway will integrate with an Amazon SQS FIFO queue.\n- FIFO (First-In-First-Out) queues in Amazon SQS ensure that messages are processed in the order they are received.\n- By using a FIFO queue, the order processing is guaranteed to be sequential, ensuring that the first order received is processed before the next one.\n- An AWS Lambda function can be configured to be triggered by the SQS FIFO queue, processing the orders as they arrive","timestamp":"1726904340.0","upvote_count":"6","poster":"Guru4Cloud"},{"comment_id":"1117350","content":"Selected Answer: B\nA. This option could be correct if we use SNS FIFO option, but this is not the case stated in the question. Additionally, this task is more efficient done by a queue than a subscription service. So, this option is not correct.\nB. We use a queue, which is efficient processing messages. Additionally, it preserves the order since it is a FIFO queue. Meanwhile we don’t have any kind of messages throughput limitation, this option is correct.\nC. This option discards any messages that are still processing, which is not a good solution.\nD. Same option as B but using a normal queue, which does not preserve the order. Incorrect.","poster":"Andreshere","timestamp":"1726904340.0","upvote_count":"6"},{"upvote_count":"1","poster":"PaulGa","content":"Selected Answer: B\nFIFO is crucial to ensuring the solution works. \nTwo answers use SQS and the author has differentiated between these option by specifically stating in option B “FIFO”\nOn the other hand, SNS also has a FIFO option but the author has chosen to not state that in answer A. If the author had said in option A: “…with FIFO” then A could have been a viable answer. \nTherefore it has to be Ans B (not A as the author recommends).","timestamp":"1726904280.0","comment_id":"1264067"}],"exam_id":31,"isMC":true,"answer_ET":"B","choices":{"C":"Use an API Gateway authorizer to block any requests while the application processes an order.","A":"Use an API Gateway integration to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic when the application receives an order. Subscribe an AWS Lambda function to the topic to perform processing.","B":"Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) FIFO queue when the application receives an order. Configure the SQS FIFO queue to invoke an AWS Lambda function for processing.","D":"Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) standard queue when the application receives an order. Configure the SQS standard queue to invoke an AWS Lambda function for processing."},"question_text":"A company is building an ecommerce web application on AWS. The application sends information about new orders to an Amazon API Gateway REST API to process. The company wants to ensure that orders are processed in the order that they are received.\nWhich solution will meet these requirements?","answer":"B"},{"id":"9x08282kjYaKzskF8a75","question_id":3,"topic":"1","exam_id":31,"choices":{"A":"Create AWS Secrets Manager secrets for encrypted certificates. Manually update the certificates as needed. Control access to the data by using fine-grained IAM access.","C":"Create an AWS Key Management Service (AWS KMS) customer managed key. Allow the EC2 role to use the KMS key for encryption operations. Store the encrypted data on Amazon S3.","B":"Create an AWS Lambda function that uses the Python cryptography library to receive and perform encryption operations. Store the function in an Amazon S3 bucket.","D":"Create an AWS Key Management Service (AWS KMS) customer managed key. Allow the EC2 role to use the KMS key for encryption operations. Store the encrypted data on Amazon Elastic Block Store (Amazon EBS) volumes."},"question_images":[],"discussion":[{"comment_id":"696559","poster":"Chunsli","upvote_count":"49","timestamp":"1665953220.0","comments":[{"content":"Agree, also the data in EBS will be accessible only to the EC2 instance and that is not as available as S3 would be.","comment_id":"949751","comments":[{"poster":"jerryl","upvote_count":"1","comment_id":"1401955","timestamp":"1742659860.0","content":"agree on this, although the question did not mention where the EBS is attached to, but i assume should be the EC2, then your statement make sense"}],"upvote_count":"8","poster":"MutiverseAgent","timestamp":"1689164160.0"}],"content":"C makes a better sense. Between C (S3) and D (EBS), S3 is highly available with LEAST operational overhead."},{"comments":[{"content":"EBS volumes are not Multi-AZ. EBS io2 types are multi-attach within the same AZ. EFS is multi-AZ","poster":"TS1991","timestamp":"1727365680.0","upvote_count":"2","comment_id":"1289573"},{"content":"Per AWS: \"Amazon EBS volumes are designed to be highly available, reliable, and durable\"\n\nhttps://aws.amazon.com/ebs/features/","poster":"FNJ1111","timestamp":"1672258680.0","comment_id":"760295","upvote_count":"2"},{"poster":"Ello2023","content":"EBS is Highly Available as it stores in multi AZ and S3 is regional.","upvote_count":"2","timestamp":"1673813640.0","comments":[{"timestamp":"1674554820.0","comment_id":"786394","content":"EBS also has Multi-AZ capability, but it does not replicate the data across multiple availability zones by default. When Multi-AZ is enabled, it creates a replica of the EBS volume in a different availability zone and automatically failover to the replica in case of a failure. However, this requires additional configuration and management. In comparison, Amazon S3 automatically replicates data across multiple availability zones without any additional configuration. Therefore, storing the data on Amazon S3 provides a simpler and more efficient solution for high availability.","comments":[{"timestamp":"1709196240.0","poster":"dkw2342","content":"This is false. There is no AWS-provided functionality that will replicate EBS volumes across AZs. There are 3rd-party solutions to this, but that's not what's being asked here.\n\nEBS is only replicated WITHIN an AZ by default.","upvote_count":"3","comment_id":"1162350"}],"poster":"oguz11","upvote_count":"11"},{"comment_id":"1204692","timestamp":"1714499460.0","poster":"Bayebrymo","upvote_count":"3","content":"This is false... S3 is Multi AZ and EBS is only replicated WITHIN an AZ by default."},{"timestamp":"1703510700.0","poster":"pentium75","upvote_count":"3","comment_id":"1105296","content":"S3 is also highly available. Within the region, but still. Multi-AZ = HA."}],"comment_id":"777027"},{"comment_id":"749967","poster":"JayBee65","timestamp":"1671462780.0","upvote_count":"1","content":"Yes it is!"}],"upvote_count":"23","content":"Selected Answer: C\nCorrect Answer is C: EBS is not highly available","comment_id":"692346","timestamp":"1665514380.0","poster":"MXB05"},{"content":"Selected Answer: C\nC. Correct, AWS KMS handles encryption with minimal effort and Amazon S3 offers durable and available storage vs D Incorrect. EBS is storage attached to an EC2 instance, which reduces availability compared to S3.","poster":"pabloveintimilla","comment_id":"1359929","upvote_count":"1","timestamp":"1740175980.0"},{"upvote_count":"1","comment_id":"1357093","content":"Selected Answer: C\nThe answer is in LEAST operational overhead","timestamp":"1739664420.0","poster":"sk1974"},{"poster":"Dharmarajan","upvote_count":"1","comment_id":"1348761","content":"Selected Answer: C\nOf the given options, C makes most sense. Reason being the rest of the options do notmake as much sense due to A. Being not specific enough, B. being insufficient to achieve the objective, D, being on EBS, which needs to be attached to a EC2 instance. \n\nOne thing with the questions is that there is many times, some data that is unclear or there is some ambiguity. I feel these scenarios makes one to assume things and perhaps even train the mind to evaluate ambiguous situations. This is valuable in my opinion.","timestamp":"1738181460.0"},{"upvote_count":"1","comment_id":"1336785","content":"Selected Answer: C\nS3 is highly available compared to EBS and using AWS KMS is more suitable for managing certificates here","poster":"satyaammm","timestamp":"1736086140.0"},{"content":"Selected Answer: C\nBoth C and D are correct. C is suitable for this requirement. we've to use S3 because they want to save the data with H.A","timestamp":"1733225340.0","comment_id":"1321346","upvote_count":"1","poster":"thiahthura"},{"timestamp":"1721578860.0","poster":"jaradat02","content":"Selected Answer: C\nC is the most efficient.","upvote_count":"1","comment_id":"1252575"},{"poster":"Shub80","timestamp":"1719327360.0","upvote_count":"4","comment_id":"1236954","content":"AWS KMS: Provides a managed service for secure key storage and encryption/decryption operations. This eliminates the need to manage encryption/decryption logic within the application itself.\nCustomer Managed Key: The company maintains control over the key, ensuring security.\nEC2 Role Permissions: Granting permissions to the EC2 role allows the application to use KMS for encryption/decryption without managing individual credentials.\nAmazon S3: Offers highly available and scalable storage for the encrypted certificates. S3 is generally cheaper than EBS for data that is not frequently accessed."},{"upvote_count":"1","comment_id":"1232157","content":"Selected Answer: C\nC for sure","timestamp":"1718666400.0","poster":"ChymKuBoy"},{"upvote_count":"1","timestamp":"1713312540.0","comment_id":"1196893","content":"Selected Answer: C\nS3: highly available\nEBS: lower latency","poster":"huangyou2003"},{"comment_id":"1196573","poster":"f761d0e","timestamp":"1713270480.0","content":"\"Amazon S3 is an object storage service that can store large volumes of unstructured data, whereas Amazon EBS is a block storage service that is ideally suited for durable, low-latency data storage associated with EC2 instances.\"\nhttps://www.tutorialspoint.com/difference-between-amazon-s3-and-amazon-ebs#:~:text=In%20conclusion%2C%20Amazon%20S3%20is,storage%20associated%20with%20EC2%20instances.\nSeems like D to me. S3 is for large data, EBS is ec2 specific.","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: C\nThe language is confusing over here so I'm going by process of elimination\nA: Wrong because manual operation and fine grained IAM is overhead\nB: What?\nD: Between C and D S3 is more HA than EFS so C wins","comments":[{"upvote_count":"2","content":"Sorry meant EBS, not EFS for D\nD: Between C and D, S3 is more HA than EBS. So C wins","comment_id":"1122933","poster":"awsgeek75","timestamp":"1705271880.0"}],"timestamp":"1705271700.0","comment_id":"1122932","poster":"awsgeek75"},{"content":"Selected Answer: D\nI would select D.\nyou can mount a single Amazon Elastic Block Store (EBS) volume to multiple Docker containers running on the same Amazon Elastic Compute Cloud (EC2) instance.\n.\nyou can store data from a container running on Amazon Elastic Compute Cloud (EC2) to an Amazon Simple Storage Service (S3) bucket. One way to do this is to use the aws s3 cp command in the command line of the EC2 instance.","timestamp":"1703778420.0","poster":"ignajtpolandstrong","upvote_count":"1","comment_id":"1107930"},{"timestamp":"1703510940.0","upvote_count":"3","poster":"pentium75","content":"Selected Answer: C\nA - does not mention storing the encrypted data at all (though that is a requirement), also involves manual action which is surely NOT \"least operational effort\"\nB - Doesn't make any sense\nC - Yes, S3 meets the requirements and is easy to access from containerized app\nD - EBS volumes are mounted to the container host, but data is created on containers","comment_id":"1105298"},{"poster":"xdkonorek2","content":"Selected Answer: A\nA is OK\nsecrets manager:\n - is highly available\n - you can store custom secrets in it like certificate\n - automatically encrypts secrets at rest, and can be configured for encryption in transit\n - downloading certificate from it is less operational overhead than decrypting it manually with KMS key\n\narguments againts it that this is more manual than C and D? this manual step is necessary measure and can't be omitted in other options\nC and D have this \"store the encrypted data in...\" to store encrypted certificate you have to: log in to instance, get kms key, get certificate, encrypt it, and load that data this is more operational overhead","comments":[{"timestamp":"1703510760.0","poster":"pentium75","content":"\"Least operational overhead\" and \"manually\" (as in A) usually don't go together. Also, A does not say anything about storing the data (which is a requirement).\n\n\"C and D have this 'store the encrypted data in'\" yes, exactly, the encrypted data, NOT the certificate. You encrypt data with the certificate, and you want to store THAT encrypted data.","upvote_count":"3","comment_id":"1105297"}],"upvote_count":"2","comment_id":"1061661","timestamp":"1699036200.0"},{"upvote_count":"2","content":"Selected Answer: C\n\"C\" is more correct because S3 is more efficient and cheaper to store data like certificates, like this case. Also Option D involves using Amazon Elastic Block Store (Amazon EBS) volumes, which is not typically used for storing certificates and may introduce unnecessary complexity and operational overhead.","poster":"David_Ang","timestamp":"1696613520.0","comment_id":"1026862"},{"content":"confused between EBS and S3, both are HA, but location?","timestamp":"1696516140.0","upvote_count":"1","comment_id":"1025760","poster":"Abitek007"},{"content":"C. when it comes to availability, Amazon S3 is generally more highly available than Amazon EBS because S3 replicates data across multiple AZs by default, providing greater resilience to failures. However, the choice between S3 and EBS depends on your specific use case and whether you need block storage for EC2 instances (EBS) or object storage for storing and retrieving data (S3).","comment_id":"1018224","upvote_count":"2","timestamp":"1695767040.0","poster":"joshik"},{"timestamp":"1694607600.0","comment_id":"1006598","poster":"Ramdi1","upvote_count":"2","content":"Selected Answer: D\nI selected D, even though S3 has high availability to 11 9’s. The question started with EC2 Instance. EBS provides block level storage that is attached to EC2 Instances. They are also designed for High Availability."},{"content":"Selected Answer: C\nOption C is the best solution that meets all the requirements with the least operational overhead:\n\nUse AWS KMS customer managed key for encryption\nAllow EC2 instance role access to use the KMS key\nStore encrypted data in Amazon S3","comment_id":"978764","poster":"Guru4Cloud","timestamp":"1691767800.0","upvote_count":"2"},{"poster":"mr_D3v1n3","timestamp":"1690402980.0","upvote_count":"2","content":"All data within EBS is stored in equally sized blocks. This system offers some performance advantages over traditional storage, and generally boasts lower latency, too. This would meet the near real time requirement over the S3 option","comment_id":"964156"},{"content":"Selected Answer: C\nA: Missing encrypt/decrypt process. B: \"Store the function in an Amazon S3 bucket\" made meaningless. D: Amazon Elastic Block Store (Amazon EBS) for clone all of hard disk, CD/DVD. The context of question requires near real-time, it need save small parts, not a big part. --> Choose C (with S3, AWS Key Management Service - AWS KMS).\n\nSee https://docs.aws.amazon.com/kms/index.html . Decrypt process https://docs.aws.amazon.com/kms/latest/APIReference/API_Decrypt.html .","poster":"james2033","timestamp":"1689334440.0","comment_id":"951479","upvote_count":"2"},{"comment_id":"930292","timestamp":"1687422600.0","content":"Selected Answer: C\nA. Manual - no no no!\nB. External (python) library - no no no!\nC. yeap.\nD. S3 over EBS (see answer C)","poster":"cookieMr","upvote_count":"3"},{"comment_id":"898492","comments":[{"upvote_count":"1","timestamp":"1707091740.0","comment_id":"1140604","content":"near real time is the key that goes with EBS if we compare with S3 in this situation.","poster":"jaswantn"}],"upvote_count":"3","timestamp":"1684167240.0","poster":"Futurebones","content":"I will go for D, as mentioned in the question ' an EC2 instance' , ' near real-time', 'LEAST operational overhead' all refer to EBS rather than S3."},{"timestamp":"1683991860.0","upvote_count":"1","comment_id":"896835","poster":"bgsanata","content":"The correct answer is D...\nUsing a containerized applications in EC2 mean it's easier to use EBS. S3 require extra work to be done and the question is about Least operational overhead."},{"comment_id":"890886","poster":"studynoplay","content":"Selected Answer: C\nThe moment you see storage, think S3. It is default unless there is a very specific requirement where S3 does not fit which will be explicitly described in the question","upvote_count":"3","timestamp":"1683391860.0"},{"upvote_count":"2","poster":"Rahulbit34","comment_id":"887719","content":"C make sense. as its asking for least operational overhead","timestamp":"1683047160.0"},{"timestamp":"1681034580.0","poster":"channn","comment_id":"865404","content":"Selected Answer: C\nA. manual put <> near real time\nC. chooses as S3 is highly available\nD: only for that EC2","upvote_count":"2"},{"content":"Selected Answer: C\nTo meet the requirements of securely downloading, encrypting, decrypting, and storing certificates with minimal operational overhead, you can use AWS Key Management Service (KMS) and Amazon S3.\n\nHere's how this solution would work:\n\nStore the security certificates in an S3 bucket with Server-Side Encryption enabled.\nCreate a KMS Customer Master Key (CMK) for encrypting and decrypting the certificates.\nGrant permission to the EC2 instance to access the CMK.\nHave the application running on the EC2 instance retrieve the security certificates from the S3 bucket.\nUse the KMS API to encrypt and decrypt the certificates as needed.\nStore the encrypted certificates in another S3 bucket with Server-Side Encryption enabled.\nThis solution provides a highly secure way to encrypt and decrypt certificates and store them in highly available storage with minimal operational overhead. AWS KMS handles the encryption and decryption of data, while S3 provides highly available storage for the encrypted data. The only operational overhead involved is setting up the KMS CMK and S3 buckets, which is a one-time setup task.","upvote_count":"3","comment_id":"860465","timestamp":"1680565560.0","poster":"gx2222"},{"poster":"alexiscloud","timestamp":"1680075660.0","comment_id":"854144","content":"C: S3 is hight available","upvote_count":"1"},{"timestamp":"1673818980.0","upvote_count":"1","comment_id":"777090","content":"Ans is C: \nSecurity certificates are just normal files. it is not SSL certificate etc… confusing !!!!!!!","poster":"AHUI"},{"content":"Selected Answer: C\nIs this the real question from Exam? It is typically vague. Usually S3 would be chosen when the situation mentioned \"high availability\". But AWS official website states that EBS volume has 99.999% availability.","comment_id":"774677","timestamp":"1673628300.0","upvote_count":"4","poster":"goodmail"},{"content":"Selected Answer: D\nEBS volumes are in one AZ and S3 buckets are a global resource.\n\nAmazon EBS volumes are designed to be highly available, reliable, and durable. At no additional charge to you, Amazon EBS volume data is replicated across multiple servers in an Availability Zone to prevent the loss of data from the failure of any single component.","timestamp":"1673578680.0","comment_id":"774051","poster":"LuckyAro","upvote_count":"2","comments":[{"poster":"LuckyAro","upvote_count":"4","timestamp":"1673578920.0","comments":[{"timestamp":"1675360800.0","comment_id":"796304","poster":"Ak1009","upvote_count":"3","content":"That was a hilarious change"}],"comment_id":"774055","content":"On 2nd thought, I'll change my answer to C"}]},{"upvote_count":"1","poster":"DavidNamy","comment_id":"765456","timestamp":"1672825980.0","content":"Selected Answer: D\nUsers cannot terminate an EC2 instance in the us-east-1 Region"},{"comment_id":"765208","timestamp":"1672803360.0","upvote_count":"1","poster":"thensanity","content":"LEAST operational - S3"},{"poster":"Mindvision","comment_id":"762225","upvote_count":"4","timestamp":"1672425120.0","content":"Correct answer is C, \n\nLeast operational overhead is S3\n\nAmazon S3 provides durability by redundantly storing the data across multiple Availability Zones whereas EBS provides durability by redundantly storing the data in a single Availability Zone.\n\nBoth S3 and EBS gives the availability of 99.99%, but the only difference that occurs is that S3 is accessed via the internet using API’s and EBS is accessed by the single instance attached to EBS."},{"poster":"Nandan747","content":"Selected Answer: C\nWell, they said Highly available. S3 is HA by default, EBS you need to ensure it's HA.","timestamp":"1672232700.0","comment_id":"759855","upvote_count":"3"},{"timestamp":"1672187940.0","content":"C is correct","upvote_count":"1","comment_id":"759207","poster":"techhb"},{"upvote_count":"4","content":"Selected Answer: C\nOption C is the best solution that meets the requirements with the least operational overhead.\n\nOption C is the best solution because it involves using AWS KMS to perform encryption operations and storing the encrypted data on Amazon S3. KMS provides a managed service for creating and controlling the encryption keys used to encrypt and decrypt data, which reduces the operational overhead of managing the encryption process. Amazon S3 is a highly available storage service, which meets the requirement of storing data in highly available storage. Additionally, allowing the EC2 role to use the KMS key for encryption operations means that the EC2 instance can access the key without requiring additional authentication, which further simplifies the process.","timestamp":"1671653700.0","comment_id":"752724","poster":"Buruguduystunstugudunstuy"},{"content":"Since the solution is deployed in an EC2 instance, it's less operational overhead to have the data stored in EBS than S3.","upvote_count":"3","comment_id":"750133","timestamp":"1671473640.0","poster":"yoben84"},{"comment_id":"749971","timestamp":"1671463080.0","upvote_count":"2","poster":"JayBee65","content":"Which solution will meet these requirements with the LEAST operational overhead? rules out both A and B as these involve manual steps. If the EC2 instance is performing encryption then D allows you to write the encrypted data locally rather than to S3, so quicker, and the EBS volume can be a Solid State Drives (SSD) e.g. EBS Provisioned IOPS SSD (io2 Block Express) which provides \"Highest performance SSD volume designed for business-critical latency-sensitive transactional workloads\". This link explains why EBS should be used over EFS and S3: https://www.justaftermidnight247.com/insights/ebs-efs-and-s3-when-to-use-awss-three-storage-solutions/"},{"comment_id":"749211","upvote_count":"4","content":"There is some problem with way in which question is phrased. \nIn 1st part it talks about certificate to communicate other business services. This means it is talking about TLS certificate but later it talks about encrypting data stored in S3 buckets. \nFor S3 encryption KMS (option C) is right solution but keeping TLS (HTTPS) communication encryption keys Secrets managers may be the right option.","poster":"career360guru","timestamp":"1671399960.0"},{"comment_id":"743192","upvote_count":"1","poster":"bearcandy","content":"D = near real time (EBS is faster than S3), not about cost savings","timestamp":"1670870580.0"},{"upvote_count":"2","comment_id":"739668","timestamp":"1670550900.0","poster":"lapaki","content":"Selected Answer: D\nShould be D. EBS is HA up to 5 9s. It's also replicated across multiple servers in an AZ. S3 is max of 4 9s. https://aws.amazon.com/ebs/faqs/"},{"content":"Why do some people say that EBS is HA? how can an EBS volume be highly available??? S3 is the only option, and of course we need to use KMS, then the answer is clearly C.","comments":[{"content":"Amazon says this too \"Amazon EBS volumes are designed to be highly available, reliable, and durable. At no additional charge to you, Amazon EBS volume data is replicated across multiple servers in an Availability Zone to prevent the loss of data from the failure of any single component.\" https://aws.amazon.com/ebs/features/","timestamp":"1671462720.0","poster":"JayBee65","upvote_count":"1","comment_id":"749965"}],"poster":"fabio3wz","upvote_count":"3","timestamp":"1669815540.0","comment_id":"731534"},{"upvote_count":"1","comment_id":"723772","poster":"Wpcorgan","timestamp":"1669050180.0","content":"C is correct"},{"upvote_count":"4","comment_id":"719400","content":"Selected Answer: D\nD is correct answer. Least overhead, just open EBS while launching EC2. It's not about which one is the most highly available, it's about which one fits the scenario best.\nhttps://aws.amazon.com/blogs/compute/must-know-best-practices-for-amazon-ebs-encryption/","timestamp":"1668581580.0","poster":"Cizzla7049"},{"comment_id":"707577","poster":"SimonPark","content":"Selected Answer: C\nS3 = highly available storage than EBS\nhttps://www.justaftermidnight247.com/insights/ebs-efs-and-s3-when-to-use-awss-three-storage-solutions/","upvote_count":"2","timestamp":"1667097420.0"},{"timestamp":"1666646520.0","poster":"Six_Fingered_Jose","content":"Selected Answer: C\nC should be the answer,\nHighly available storage = S3","upvote_count":"4","comment_id":"703370"},{"upvote_count":"3","comment_id":"702041","poster":"nikerlas","content":"Selected Answer: D\n\"store data in highly available storage after the data is encrypted.\" ==> EBS","timestamp":"1666517880.0"}],"unix_timestamp":1665514380,"question_text":"A company's containerized application runs on an Amazon EC2 instance. The application needs to download security certificates before it can communicate with other business applications. The company wants a highly secure solution to encrypt and decrypt the certificates in near real time. The solution also needs to store data in highly available storage after the data is encrypted.\nWhich solution will meet these requirements with the LEAST operational overhead?","answer":"C","isMC":true,"answer_images":[],"answer_ET":"C","answers_community":["C (80%)","D (17%)","2%"],"url":"https://www.examtopics.com/discussions/amazon/view/85186-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2022-10-11 20:53:00","answer_description":""},{"id":"aqTjkhjqmGKqCs4RH81f","answer_ET":"B","answer":"B","timestamp":"2024-09-30 21:54:00","isMC":true,"unix_timestamp":1727726040,"answers_community":["B (80%)","C (20%)"],"question_images":[],"answer_description":"","exam_id":31,"discussion":[{"content":"Selected Answer: B\nQuestion says, \"Apps must be able to retrieve frequently accessed data with low latency\" so we go with cached volumes.\nWe'd have chosen the stored volumes if question was about low-latency access to the entire dataset.","comment_id":"1299941","timestamp":"1729325940.0","poster":"sOI852POL","upvote_count":"10"},{"upvote_count":"2","poster":"FlyingHawk","content":"Selected Answer: B\nB- Cached volumes store only the most frequently accessed data on-premises, while the full dataset is stored in Amazon S3. This ensures low-latency access to frequently accessed data while leveraging the scalability and durability of S3 for the full dataset.\nC - Stored volumes store the entire dataset on-premises and asynchronously back it up to AWS. This option does not address the company’s requirement for limited on-premises storage capacity.","timestamp":"1737255180.0","comments":[{"comment_id":"1342840","timestamp":"1737255240.0","content":"A - S3 File Gateway provides file-based storage (SMB or NFS) and is not suitable for block storage requirements.\nD - Tape Gateway is designed for backup and archival use cases, not for low-latency access to frequently accessed data. It uses virtual tapes stored in S3 and is not suitable for block storage or real-time application access.","upvote_count":"1","poster":"FlyingHawk"}],"comment_id":"1342839"},{"upvote_count":"1","timestamp":"1735202520.0","comments":[{"poster":"FlyingHawk","upvote_count":"1","content":"Stored volumes store the entire dataset on-premises and asynchronously back it up to AWS. This option does not address the company’s requirement for limited on-premises storage capacity, as it requires storing the full dataset locally.","timestamp":"1737255060.0","comment_id":"1342838"}],"poster":"EllenLiu","comment_id":"1331841","content":"Selected Answer: C\nchoose store volume mode"},{"comment_id":"1298941","poster":"8621a7c","content":"Selected Answer: C\nBlock storage use volume gateway, low latency use store volumes.","timestamp":"1729110780.0","upvote_count":"2"},{"comment_id":"1291668","content":"Respuesta correcta B . Baja latencia = Elastic Cache . A , C y D no cumplen un acceso con baja latencia ( descartados ) .","timestamp":"1727726040.0","upvote_count":"3","poster":"viejito"}],"choices":{"A":"Use Amazon S3 File Gateway. Integrate S3 File Gateway with the on-premises applications to store and directly retrieve files by using the SMB file system.","C":"Use an AWS Storage Gateway Volume Gateway with stored volumes as iSCSI targets.","D":"Use an AWS Storage Gateway Tape Gateway. Integrate Tape Gateway with the on-premises applications to store virtual tapes in Amazon S3.","B":"Use an AWS Storage Gateway Volume Gateway with cached volumes as iSCSI targets."},"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/148471-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","question_id":4,"question_text":"A company currently stores 5 TB of data in on-premises block storage systems. The company's current storage solution provides limited space for additional data. The company runs applications on premises that must be able to retrieve frequently accessed data with low latency. The company requires a cloud-based storage solution.\n\nWhich solution will meet these requirements with the MOST operational efficiency?"},{"id":"esEwOxE4wayAJXXpmr8M","answers_community":["D (100%)"],"choices":{"C":"Provision two Amazon Simple Queue Service (Amazon SQS) queues. Use one SQS queue for order collection. Use the second SQS queue for order fulfillment. Configure the EC2 instances to poll their respective queues. Scale the Auto Scaling groups based on notifications that the queues send.","A":"Use Amazon CloudWatch to monitor the CPUUtilization metric for each instance in both Auto Scaling groups. Configure each Auto Scaling group's minimum capacity to meet its peak workload value.","D":"Provision two Amazon Simple Queue Service (Amazon SQS) queues. Use one SQS queue for order collection. Use the second SQS queue for order fulfillment. Configure the EC2 instances to poll their respective queues. Scale the Auto Scaling groups based on the number of messages in each queue.","B":"Use Amazon CloudWatch to monitor the CPUUtilization metric for each instance in both Auto Scaling groups. Configure a CloudWatch alarm to invoke an Amazon Simple Notification Service (Amazon SNS) topic to create additional Auto Scaling groups on demand."},"question_text":"A company operates a food delivery service. Because of recent growth, the company's order processing system is experiencing scaling problems during peak traffic hours. The current architecture includes Amazon EC2 instances in an Auto Scaling group that collect orders from an application. A second group of EC2 instances in an Auto Scaling group fulfills the orders.\n\nThe order collection process occurs quickly, but the order fulfillment process can take longer. Data must not be lost because of a scaling event.\n\nA solutions architect must ensure that the order collection process and the order fulfillment process can both scale adequately during peak traffic hours.\n\nWhich solution will meet these requirements?","unix_timestamp":1728298740,"timestamp":"2024-10-07 12:59:00","answer_description":"","discussion":[{"poster":"sOI852POL","upvote_count":"4","comment_id":"1299931","content":"Selected Answer: D\nSQS to ensure data is not lost because of a scaling event, scale based on number of messages on the queue.","timestamp":"1729325160.0"},{"upvote_count":"2","poster":"8621a7c","content":"Selected Answer: D\nGo with D","comment_id":"1298946","timestamp":"1729111140.0"},{"content":"Selected Answer: D\nAnswer is D","timestamp":"1728300900.0","comment_id":"1294228","upvote_count":"2","poster":"aragon_saa"}],"question_images":[],"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/148807-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","answer_images":[],"question_id":5,"exam_id":31,"isMC":true,"answer_ET":"D"}],"exam":{"isBeta":false,"provider":"Amazon","id":31,"isImplemented":true,"isMCOnly":true,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Associate SAA-C03","numberOfQuestions":1019},"currentPage":1},"__N_SSP":true}