{"pageProps":{"questions":[{"id":"rZBnQhKaMMv9bbrbr5XU","topic":"1","answer_description":"","exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/113019-exam-aws-certified-solutions-architect-professional-sap-c02/","question_text":"An education company is running a web application used by college students around the world. The application runs in an Amazon Elastic Container Service (Amazon ECS) cluster in an Auto Scaling group behind an Application Load Balancer (ALB). A system administrator detects a weekly spike in the number of failed login attempts, which overwhelm the application's authentication service. All the failed login attempts originate from about 500 different IP addresses that change each week. A solutions architect must prevent the failed login attempts from overwhelming the authentication service.\n\nWhich solution meets these requirements with the MOST operational efficiency?","question_id":166,"choices":{"B":"Create an AWS WAF web ACL with a rate-based rule, and set the rule action to Block. Connect the web ACL to the ALB.","D":"Create an AWS WAF web ACL with an IP set match rule, and set the rule action to Block. Connect the web ACL to the ALB.","C":"Use AWS Firewall Manager to create a security group and security group policy to allow access only to specific CIDR ranges.","A":"Use AWS Firewall Manager to create a security group and security group policy to deny access from the IP addresses."},"unix_timestamp":1687465800,"answer_ET":"B","isMC":true,"answer":"B","answers_community":["B (100%)"],"timestamp":"2023-06-22 22:30:00","discussion":[{"poster":"totten","timestamp":"1728753180.0","comment_id":"1041952","content":"Selected Answer: B\nOption B provides the most operational efficiency to prevent the weekly spike in failed login attempts. Here's why:\n\nAWS WAF (Web Application Firewall) with a rate-based rule allows you to monitor and block traffic based on the rate of requests from different IP addresses.\nThe rate-based rule can help identify and block the excessive login attempts originating from a large number of IP addresses that change weekly.\nBy blocking traffic at the ALB level using AWS WAF, the traffic doesn't reach the application, reducing the load on your authentication service.\nThe rate-based rule can automatically adjust to changing patterns of attack without manual updates, providing an efficient solution.\nAWS WAF is designed for web application protection and allows you to create flexible rules to mitigate various types of attacks, making it a suitable choice for handling this scenario.","upvote_count":"7"},{"upvote_count":"3","poster":"career360guru","timestamp":"1732326480.0","content":"Selected Answer: B\nUsing WAF with ALB is most operationally efficient. This narrows the choices down to B and D. As IP address keeps changing B is most efficient.","comment_id":"1077973"},{"comment_id":"1058471","content":"Selected Answer: B\nThe application should be used by users \"around the world\" so policies that IP based are not suitable, as you have to update set of new IPs each week. \nOption B has valid actions, as WAP webACL has rate-basted rule and Block Action.","timestamp":"1730354280.0","upvote_count":"2","poster":"joleneinthebackyard"},{"content":"Correct B.","poster":"ggrodskiy","comment_id":"959787","timestamp":"1721675100.0","upvote_count":"1"},{"poster":"NikkyDicky","comment_id":"945187","content":"Selected Answer: B\neasyu B","upvote_count":"1","timestamp":"1720320180.0"},{"timestamp":"1720212840.0","content":"Selected Answer: B\nB, if login hit at a certain ratio, block this IP","poster":"Christina666","comment_id":"944114","upvote_count":"1"},{"poster":"SkyZeroZx","timestamp":"1719966780.0","comment_id":"941331","upvote_count":"2","content":"Selected Answer: B\nB and not D because of \"500 different IP addresses that change each week\""},{"comment_id":"934801","upvote_count":"3","content":"Selected Answer: B\nB and not D because of \"500 different IP addresses that change each week\"","timestamp":"1719438000.0","poster":"SmileyCloud"},{"comment_id":"934489","timestamp":"1719407520.0","poster":"easytoo","upvote_count":"1","content":"b-b-b-b-b-b"},{"content":"yep, it's B","poster":"PhuocT","upvote_count":"1","timestamp":"1719213960.0","comment_id":"932307"},{"content":"Selected Answer: B\nB Is Correct.\nSince IP address keeps changing, WAF can't block on IP/CIDR.","poster":"elanelans","upvote_count":"2","timestamp":"1719129720.0","comment_id":"931344"},{"comment_id":"931011","upvote_count":"3","timestamp":"1719088200.0","poster":"bhanus","content":"Selected Answer: B\nB is the answer"}],"question_images":[],"answer_images":[]},{"id":"TuRA1JfeUFJXHDFq5Lr5","exam_id":33,"unix_timestamp":1687502100,"question_id":167,"topic":"1","answer_images":[],"answer_ET":"A","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/113047-exam-aws-certified-solutions-architect-professional-sap-c02/","isMC":true,"timestamp":"2023-06-23 08:35:00","answer":"A","question_images":[],"answer_description":"","discussion":[{"timestamp":"1732130520.0","content":"Selected Answer: A\nRegister the customer-owned block of IP addresses in the company's AWS account: This allows the company to use their existing IP addresses within AWS, ensuring customers don't need to update firewall allow lists.\n\nCreate Elastic IP addresses from the address pool: Elastic IP addresses are static IPv4 addresses for dynamic cloud computing. Creating them from the customer-owned pool allows assigning these IP addresses to AWS resources.\n\nAssign the Elastic IP addresses to an AWS Transfer for SFTP endpoint: AWS Transfer for SFTP enables secure SFTP file transfers. Assigning customer-owned Elastic IP addresses to the endpoint maintains existing IP addresses for customers.\n\nUse AWS Transfer to store files in Amazon S3: AWS Transfer for SFTP integrates with Amazon S3, allowing ingested files to be stored directly in S3 buckets, eliminating the need to manage file storage infrastructure and reducing operational overhead.","comment_id":"1315473","upvote_count":"1","poster":"0b43291"},{"content":"Selected Answer: A\nOption A is the only possible option.","upvote_count":"2","comment_id":"1077979","poster":"career360guru","timestamp":"1700704320.0"},{"content":"Selected Answer: A\nOption A is valid\nOption D: S3 doen't have support for SFTP option -> out\nB, C: using EC2 to host FTP (not SFTP) while there is a native soltion in option A -> out","comment_id":"1058468","poster":"joleneinthebackyard","timestamp":"1698731520.0","upvote_count":"2"},{"poster":"Simon523","timestamp":"1693206240.0","upvote_count":"4","content":"Selected Answer: A\nshould use AWS Transfer for SFTP","comment_id":"991874"},{"timestamp":"1690754220.0","comment_id":"967544","upvote_count":"2","poster":"breadops","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/storage/use-ip-whitelisting-to-secure-your-aws-transfer-for-sftp-servers/"},{"upvote_count":"1","timestamp":"1690052640.0","comment_id":"959785","poster":"ggrodskiy","content":"Correct A."},{"poster":"nicecurls","comment_id":"947087","timestamp":"1688897160.0","upvote_count":"1","content":"Selected Answer: A\nit's A"},{"poster":"Piccaso","comment_id":"945529","upvote_count":"1","timestamp":"1688721660.0","content":"Selected Answer: A\nD is too manual"},{"upvote_count":"1","content":"Selected Answer: A\nits an A","timestamp":"1688698500.0","comment_id":"945195","poster":"NikkyDicky"},{"poster":"SmileyCloud","timestamp":"1687815780.0","upvote_count":"2","content":"Selected Answer: A\nA - AWS Managed SFTP","comment_id":"934804"},{"poster":"nexus2020","timestamp":"1687612140.0","content":"Selected Answer: A\nAWS Transfer for SFTP, fully managed service, no operational overhead","upvote_count":"2","comment_id":"932556"},{"poster":"Alabi","content":"Selected Answer: A\nOption A suggests using AWS Transfer for SFTP, which is a fully managed service that enables the transfer of files over the Secure File Transfer Protocol (SFTP) directly into and out of Amazon S3. By registering the customer-owned block of IP addresses in the company's AWS account and creating Elastic IP addresses from that address pool, the company can assign those IP addresses to an AWS Transfer for SFTP endpoint. This allows the customers to continue using their existing firewall allow lists without requiring any changes. The files transferred through the SFTP endpoints are stored directly in Amazon S3, reducing operational overhead.","timestamp":"1687571820.0","comment_id":"932095","upvote_count":"3"},{"poster":"gd1","content":"Selected Answer: A\nAWS Transfer Family provides fully managed support for Secure File Transfer Protocol (SFTP), File Transfer Protocol over SSL (FTPS), and File Transfer Protocol (FTP). AWS Transfer Family provides a seamless migration experience while preserving authentications and security policies, and it can handle the scale of demanding file transfer workloads. The file transfer can be stored directly into Amazon S3 or Amazon EFS.","upvote_count":"2","timestamp":"1687570140.0","comment_id":"932080"},{"upvote_count":"1","poster":"MoussaNoussa","content":"A is the right answer","comment_id":"931281","timestamp":"1687502100.0"}],"choices":{"C":"Register the customer-owned block of IP addresses with Amazon Route 53. Create alias records in Route 53 that point to a Network Load Balancer (NLB). Launch EC2 instances hosting FTP services in an Auto Scaling group behind the NLB. Store the files in Amazon S3.","A":"Register the customer-owned block of IP addresses in the company's AWS account. Create Elastic IP addresses from the address pool and assign them to an AWS Transfer for SFTP endpoint. Use AWS Transfer to store the files in Amazon S3.","D":"Register the customer-owned block of IP addresses in the company’s AWS account. Create Elastic IP addresses from the address pool and assign them to an Amazon S3 VPC endpoint. Enable SFTP support on the S3 bucket.","B":"Add a subnet containing the customer-owned block of IP addresses to a VPC. Create Elastic IP addresses from the address pool and assign them to an Application Load Balancer (ALB). Launch EC2 instances hosting FTP services in an Auto Scaling group behind the ALStore the files in attached Amazon Elastic Block Store (Amazon EBS) volumes."},"question_text":"A company operates an on-premises software-as-a-service (SaaS) solution that ingests several files daily. The company provides multiple public SFTP endpoints to its customers to facilitate the file transfers. The customers add the SFTP endpoint IP addresses to their firewall allow list for outbound traffic. Changes to the SFTP endpoint IP addresses are not permitted.\n\nThe company wants to migrate the SaaS solution to AWS and decrease the operational overhead of the file transfer service.\n\nWhich solution meets these requirements?"},{"id":"RcZ8Gi3L9s1kb5STs1hs","question_images":[],"question_id":168,"isMC":true,"topic":"1","unix_timestamp":1670854500,"answers_community":["D (89%)","11%"],"answer_ET":"D","discussion":[{"timestamp":"1677506940.0","content":"Selected Answer: D\nVoted D because of the 65% / 35% proportion. C seems to be good but with only 50% instances available we break the SLA","poster":"_lasco_","upvote_count":"25","comment_id":"823791"},{"timestamp":"1693175460.0","content":"Can not be C because Savings Plans requirement long term commitment.","comment_id":"991671","poster":"joefromnc","upvote_count":"7"},{"upvote_count":"1","content":"Selected Answer: C\nSavings Plans provide cost savings compared to On-Demand while ensuring predictable compute resources for scheduled jobs with tight SLAs. Balanced distribution of On-Demand and Spot Instances across AZs ensures redundancy and cost-effectiveness.","comment_id":"1367887","poster":"BennyMao","timestamp":"1741500480.0"},{"poster":"TariqKipkemei","timestamp":"1732252020.0","upvote_count":"1","content":"Selected Answer: D\nkeywords:\n'65%, more than half of the instances must continue to meet SLAs' = On-demand instances with capacity reservations.\n'cost-effectively' = spot instances.","comment_id":"1316167"},{"content":"D. Split the 12 instances across three Availability Zones in the chosen AWS Region. Run three instances in each Availability Zone as On-Demand Instances with Capacity Reservations. Run one instance in each Availability Zone as a Spot Instance.","poster":"amministrazione","comment_id":"1275465","timestamp":"1725092700.0","upvote_count":"1"},{"comment_id":"1231534","poster":"Helpnosense","upvote_count":"2","timestamp":"1718570280.0","content":"Selected Answer: C\nI vote C.\nThe 65% of scheduled jobs is the portion of the total work load. I don't believe it's SLA since SLA will be 99.99% or more. The jobs is hourly from 0.3 to 2 hours. There are 12 servers on prem. If the number of jobs per server can handle is N. Then to cover the worst situation that all the jobs run 2 hours, by given 12 servers and tight SLA, the number of hourly jobs is 12 / 2 = 6N. Answer C has 6 servers and since the number of job per server is N then 6 server can handle 6N jobs match the hourly job number 6N. \n2 ec2 with saving plan + 2 spot instances is more cost effective than 3 ec2 with capacity plan(not saving a penny by capacity reservation plan) + 1 spot instance."},{"poster":"gofavad926","timestamp":"1710612120.0","upvote_count":"2","content":"Selected Answer: D\nD is more cost-effective than C","comment_id":"1175174"},{"comment_id":"1101422","poster":"atirado","timestamp":"1703066640.0","upvote_count":"2","content":"Selected Answer: D\nOption A - This option might not work: it might not provide sufficient processing capacity for the batch jobs to meet the SLAs during outages. Moreover, 4 servers will not provide sufficient capacity to meet the SLAs of batch jobs\n\nOption B - This option might not work: In case of an outage affecting the On-Demand instances there might not be enough processing capacity to meet batch job SLAs\nOption C - This option will not meet the requirement not to make any long-term commitments\n\nOption D - This option will work: There is enough sufficient processing capacity to meet the SLAs of batch jobs and keep processing One-off jobs"},{"comment_id":"1088399","upvote_count":"1","content":"D would be perfect, because it requires more cpu usage, we should have more capacity CPU .","poster":"subbupro","timestamp":"1701773760.0"},{"comment_id":"1079665","poster":"edder","content":"Selected Answer: D\nThe answer is D.\nSince it originally had a completely redundant configuration, it is thought that scheduled tasks are executed on 4 machines and user tasks are executed on 2 machines.\nA,B: Requirements cannot be met when a specific region falls.\nC: No Savings Plan required.\nD: Even if a specific region goes down, 6 machines will be maintained, so service can be maintained.","upvote_count":"1","timestamp":"1700875800.0"},{"timestamp":"1691337060.0","content":"Selected Answer: D\nAbout 65% or about 8 instances have to run at the same time to meet the SLA.","upvote_count":"3","poster":"Russs99","comment_id":"973990"},{"timestamp":"1691064420.0","comments":[{"upvote_count":"4","poster":"joefromnc","comment_id":"991672","content":"Can’t be C it says it can’t require long term commitment. Savings plans like reserved instance require long term commitments with a contract.","timestamp":"1693175520.0"}],"comment_id":"971093","upvote_count":"4","content":"Correct C.\nOption D is incorrect because running three instances in each Availability Zone as On-Demand Instances with Capacity Reservations will increase the cost of the solution without providing any additional benefit. Capacity Reservations are not necessary when using a Savings Plan, as they both offer guaranteed capacity at a discounted pricehttps://docs.aws.amazon.com/whitepapers/latest/how-aws-pricing-works/amazon-ec2.html. Also, running only one instance in each Availability Zone as a Spot Instance will not provide enough capacity for the user jobs that account for 35% of system usage.","poster":"ggrodskiy"},{"timestamp":"1688564640.0","content":"Selected Answer: D\nD. 3 AZ (Redundancy), 3 EC2 in each AZ as on demand and 1 spot (addresses SLA in 65/35 ratio)\nRuling out Factors:\nA. Only 2 AZ (low redundancy), all EC2 in capacity reservation (Not Cost effective as SLA requirement is in 65/35 ratio).\nB. All 4 on-demand in 1 AZ (low redundancy), rest spot (Will efect tight SLA - is actually 35/65 instead of 65/35).\nC. Savings Plan (Against no long term commitments requirement).","upvote_count":"3","comment_id":"943795","poster":"awsrd2023"},{"timestamp":"1687983840.0","comment_id":"937119","content":"Selected Answer: D\nD\n1 - need capacity reservation\n2 - need to cover 65% with HA","upvote_count":"1","poster":"NikkyDicky"},{"poster":"aca1","upvote_count":"3","timestamp":"1684863420.0","comment_id":"905115","content":"Selected Answer: D\nJust D is the right one. We need to garantee 65% (about 8 instances of 12) of capacity for the SLA, so 9 can do it and then let the others as spot. \nAnother point Saving Plans need commitment \"Savings Plans are a flexible pricing model that offer low prices on Amazon EC2, AWS Lambda, and AWS Fargate usage, in exchange for a commitment to a consistent amount of usage (measured in $/hour) for a 1 or 3 year term\" - https://aws.amazon.com/savingsplans/compute-pricing/"},{"poster":"gameoflove","upvote_count":"1","timestamp":"1683611220.0","content":"Selected Answer: C\nVoted C, the reason for this option is Spot Instance which is truely cost saving when we are performing Batch jobs and if you plan the cost properly this is best solution","comment_id":"892810"},{"poster":"Maria2023","upvote_count":"1","content":"Selected Answer: D\n65% SLA can be reached only on answer D. Yeah - 9 instances are a bit too much but that's the only answer that meets the SLA","comment_id":"875893","timestamp":"1682015400.0"},{"poster":"rxhan","timestamp":"1681832820.0","content":"Selected Answer: D\nOption D splits the 12 instances across three AZs and runs three instances in each AZ as On-Demand Instances with Capacity Reservations, and one instance in each AZ as a Spot Instance. This option can provide better redundancy and capacity for scheduled jobs while still providing some cost savings through Spot Instances. Additionally, the user jobs can be easily absorbed by the available Spot Instances during On-Demand Instance failures.","upvote_count":"4","comment_id":"873816"},{"timestamp":"1681072020.0","poster":"asifjanjua88","comment_id":"865805","comments":[{"timestamp":"1698827400.0","upvote_count":"2","content":"This is proof that ChatGPT does make mistakes! Savings plans are 1 year or 3 year commitments. So C is incorrect.","comment_id":"1059466","poster":"fig"}],"content":"Option C as per ChatGPT","upvote_count":"2"},{"upvote_count":"3","comment_id":"854528","timestamp":"1680100860.0","content":"Selected Answer: D\n12 nodes in redundant configuration ..Means 6 nodes can handle load at any given time. \nOut of 6 nodes, 65 % is SLA driven (~4nodes) and 35% load can be paused. \nThis lead to 4 nodes with single point of failure. D- If one -az down you still have 4 nodes available.","poster":"Amac1979"},{"content":"Selected Answer: D\n...Run one instance in each Availability Zone as a Spot Instance.","poster":"mfsec","comment_id":"852813","timestamp":"1679980920.0","upvote_count":"2"},{"content":"The solution that meets the requirements most cost-effectively is Split the 12 instances across three Availability Zones in the chosen AWS Region. Run two instances in each Availability Zone as On-Demand Instances with a Savings Plan. Run two instances in each Availability Zone as Spot Instances.","upvote_count":"1","comment_id":"852642","poster":"higashikumi","timestamp":"1679966880.0"},{"content":"Selected Answer: D\nD -> No long term commitment. Please hourly jobs require 65% capacity","poster":"kiran15789","timestamp":"1678219260.0","comment_id":"832250","upvote_count":"1"},{"upvote_count":"1","comments":[{"comment_id":"832536","upvote_count":"7","timestamp":"1678251120.0","poster":"NPN","content":"Option-C uses savings plan and needs commitment; The question says no long-term commitment; Hence option-D is the best."}],"poster":"dev112233xx","content":"Selected Answer: C\nI can’t understand people who voted D.. Capacity Reserved instances are very expensive and have the same price of on-demand so it’s not a “cost-effectively“ solution .\nC is the most cost effectively solution that also makes sense.","comment_id":"830288","timestamp":"1678047720.0"},{"upvote_count":"2","timestamp":"1677490620.0","comment_id":"823489","poster":"sambb","content":"Selected Answer: D\nD has no long term commitment (e.g. saving plans) and has 75% on demand instances / 25% spot instances which is near the requirements"},{"timestamp":"1677354540.0","upvote_count":"1","poster":"cudbyanc","content":"Option D is also a good solution because it splits the 12 instances across three Availability Zones and uses a mix of On-Demand Instances with Capacity Reservations and Spot Instances. However, it allocates fewer On-Demand Instances than Option C, which could result in lower availability.","comment_id":"821781"},{"upvote_count":"2","comment_id":"821780","timestamp":"1677354480.0","comments":[{"timestamp":"1681048740.0","comment_id":"865555","content":"'Reserved Instances' model does not any commitment or upfront payments:\n\n\"You can create Capacity Reservations at any time, without entering into a one-year or three-year term commitment.\"\n\n\"When you no longer need the capacity assurance, cancel the Capacity Reservation to release the capacity and to stop incurring charges\"\n\n\"When you run an instance that matches the attributes of a reservation, you just pay for the instance and nothing for the reservation. There are no upfront or additional charges. \"\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html","poster":"frfavoreto","upvote_count":"1"}],"content":"Selected Answer: C\nC is a good solution because it splits the 12 instances across three Availability Zones and uses a mix of On-Demand Instances with a Savings Plan and Spot Instances.\n\nOn-Demand instances provide a consumption-based model with no long-term commitments, which is one of the requirements mentioned in the scenario. Although other purchasing options such as Reserved Instances or Savings Plans could offer significant discounts over On-Demand pricing, they require longer commitments and upfront payments, which may not align with the requirement of a consumption-based model with no long-term commitments. Additionally, using On-Demand instances can help to maintain high availability and meet the tight SLAs required for the scheduled jobs, as they provide the fastest and most reliable way to provision EC2 instances.","poster":"cudbyanc"},{"poster":"hobokabobo","timestamp":"1677235980.0","content":"Selected Answer: D\nWe have an SLA to meet, that cannot be guaranteed with spot instances. We need to ensure that 65% of capacity is always available.\nThe only option that has at least 65% capacity always available is D.\nOther options may be cheaper but do not provide the required Service Level.","comment_id":"820376","upvote_count":"1"},{"timestamp":"1677157740.0","content":"Selected Answer: D\n\" with no long-term commitments.\" -> option c require atleast 1=3 years of commitments, so we can ignore it. So D is the best option","upvote_count":"1","comment_id":"819224","poster":"kiran15789"},{"comment_id":"818788","poster":"God_Is_Love","content":"Selected Answer: C\nLogical answer : A and B gets eliminated because one says two AZs and other is wierd proportion of 4 OnDemand, rest Spot instances.\nthat leaves C and D. Most might go for D thinking 65-35 proportion but question asks for MOST cost effective which is option with Savings plans and its just 1 year commitment [its not really long term] (https://aws.amazon.com/savingsplans/compute-pricing/)\nIn fact one standing out in this aspect is only C. Two OnDemand with savings plan saves and Two Spot instances save costs too. Win win situation\nand we have this same proportion in other two AZs as well, good for High Availability. So, I choose C.","upvote_count":"1","timestamp":"1677126360.0","comments":[{"poster":"zejou1","timestamp":"1678578240.0","upvote_count":"1","content":"without knowing what the company considers \"long-term\" we cannot make that assumption. Yes, I leaned to it at first but reviewing the statement \"which solution will meet these requirements most cost-effectively?\" they don't want a commitment at all.","comment_id":"836606"}]},{"timestamp":"1677122280.0","upvote_count":"1","content":"Logical answer : A and B gets eliminated because one says two AZs and other is wierd proportion of 4 OnDemand, rest Spot instances.\nthat leaves C and D. Most might go for D thinking 65-35 proportion but question asks for MOST cost effective which is option with Savings plans and its just 1 year commitment [its not really long term] (https://aws.amazon.com/savingsplans/compute-pricing/)\nIn fact one standing out in this aspect is only C. Two OnDemand with savings plan saves and Two Spot instances save costs too. Win win situation\nand we have this same proportion in other two AZs as well, good for High Availability. So, I choose C.","comment_id":"818731","poster":"God_Is_Love"},{"timestamp":"1675388760.0","content":"C\nSavings plans are 60-75% savings, capacity reservations guarantee the capacity (no savings).","poster":"Amac1979","comment_id":"796612","upvote_count":"1"},{"content":"Selected Answer: D\nSLA looks like 65%","comment_id":"792858","timestamp":"1675085520.0","upvote_count":"1","poster":"zozza2023"},{"timestamp":"1674306240.0","upvote_count":"1","poster":"Pugsley","comment_id":"783299","content":"Selected Answer: D\nThe math is more logical for D - look at the 65% vs 35%."},{"comment_id":"774804","timestamp":"1673638560.0","content":"Selected Answer: D\nOption D is correct because it meets the requirements of maintaining high availability, meeting SLAs for scheduled jobs, and reducing costs with a consumption-based model. By splitting the 12 instances across three Availability Zones, the system can maintain high availability and availability of resources in case of a failure. Option D also uses a combination of On-Demand Instances with Capacity Reservations and Spot Instances, which allows for scheduled jobs to be run on the On-Demand instances with guaranteed capacity, while also taking advantage of the cost savings from Spot Instances for the user jobs which have lower SLA requirements.","upvote_count":"2","poster":"masetromain"},{"content":"I think is D since it says most cost effective","poster":"Vicious000","timestamp":"1673038920.0","upvote_count":"1","comment_id":"768079"},{"poster":"masetromain","content":"Selected Answer: D\nhttps://www.examtopics.com/discussions/amazon/view/89276-exam-aws-certified-solutions-architect-professional-topic-1/","upvote_count":"3","timestamp":"1670944740.0","comment_id":"744194"},{"poster":"zhangyu20000","upvote_count":"3","content":"D is correct, other options has no more than 50% compute, less than required 65.","comment_id":"742885","timestamp":"1670854500.0"}],"answer_description":"","answer_images":[],"timestamp":"2022-12-12 15:15:00","exam_id":33,"choices":{"A":"Split the 12 instances across two Availability Zones in the chosen AWS Region. Run two instances in each Availability Zone as On-Demand Instances with Capacity Reservations. Run four instances in each Availability Zone as Spot Instances.","C":"Split the 12 instances across three Availability Zones in the chosen AWS Region. Run two instances in each Availability Zone as On-Demand Instances with a Savings Plan. Run two instances in each Availability Zone as Spot Instances.","B":"Split the 12 instances across three Availability Zones in the chosen AWS Region. In one of the Availability Zones, run all four instances as On-Demand Instances with Capacity Reservations. Run the remaining instances as Spot Instances.","D":"Split the 12 instances across three Availability Zones in the chosen AWS Region. Run three instances in each Availability Zone as On-Demand Instances with Capacity Reservations. Run one instance in each Availability Zone as a Spot Instance."},"url":"https://www.examtopics.com/discussions/amazon/view/91214-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"D","question_text":"A company uses an on-premises data analytics platform. The system is highly available in a fully redundant configuration across 12 servers in the company’s data center.\nThe system runs scheduled jobs, both hourly and daily, in addition to one-time requests from users. Scheduled jobs can take between 20 minutes and 2 hours to finish running and have tight SLAs. The scheduled jobs account for 65% of the system usage. User jobs typically finish running in less than 5 minutes and have no SLA. The user jobs account for 35% of system usage. During system failures, scheduled jobs must continue to meet SLAs. However, user jobs can be delayed.\nA solutions architect needs to move the system to Amazon EC2 instances and adopt a consumption-based model to reduce costs with no long-term commitments. The solution must maintain high availability and must not affect the SLAs.\nWhich solution will meet these requirements MOST cost-effectively?"},{"id":"WoFuqzIfXsOLomMBNf9z","discussion":[{"timestamp":"1734199260.0","upvote_count":"1","content":"Selected Answer: A\nCluster that would place them in same Az.","poster":"bhanus","comment_id":"1326575"},{"timestamp":"1730299800.0","content":"typical cluster placement group use case","comment_id":"1204571","upvote_count":"1","poster":"43c89f4"},{"poster":"career360guru","comment_id":"1077980","upvote_count":"4","timestamp":"1716422220.0","content":"Selected Answer: A\nA is the only option."},{"upvote_count":"1","content":"Selected Answer: A\neasy A","comment_id":"945197","timestamp":"1704603360.0","poster":"NikkyDicky"},{"poster":"SmileyCloud","content":"Selected Answer: A\nA - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","comment_id":"934807","timestamp":"1703634420.0","upvote_count":"4"},{"comment_id":"932096","timestamp":"1703390280.0","content":"Selected Answer: A\nA for sure","poster":"Alabi","upvote_count":"1"},{"comment_id":"932083","upvote_count":"2","timestamp":"1703388780.0","content":"Selected Answer: A\nA cluster placement group is a type of placement group that packs instances close together inside an Availability Zone. This strategy enables workloads to achieve the low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of high performance computing (HPC) applications.","poster":"gd1"},{"upvote_count":"1","timestamp":"1703325480.0","content":"Selected Answer: A\nA- Provides Low latency and high throughput.\nAuto scaling with additional ENI, spread placement and partition placement won't achieve the requirement.","poster":"elanelans","comment_id":"931340"},{"content":"Selected Answer: A\nA - Cluster placement group\nC is incorrect because Partition placement groups are used for large distributed workloads, like Hadoop, Cassandra, and Kafka. They do not offer the same low-latency, high-throughput benefits as cluster placement groups.","comment_id":"931013","timestamp":"1703284500.0","poster":"bhanus","upvote_count":"4"}],"question_images":[],"question_id":169,"answer_images":[],"answers_community":["A (100%)"],"choices":{"D":"Launch five new EC2 instances into a spread placement group. Attach an extra elastic network interface to each EC2 instance.","A":"Launch five new EC2 instances into a cluster placement group. Ensure that the EC2 instance type supports enhanced networking.","C":"Launch five new EC2 instances into a partition placement group. Ensure that the EC2 instance type supports enhanced networking.","B":"Launch five new EC2 instances into an Auto Scaling group in the same Availability Zone. Attach an extra elastic network interface to each EC2 instance."},"answer":"A","timestamp":"2023-06-22 22:35:00","isMC":true,"exam_id":33,"unix_timestamp":1687466100,"answer_description":"","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/113020-exam-aws-certified-solutions-architect-professional-sap-c02/","question_text":"A company has a new application that needs to run on five Amazon EC2 instances in a single AWS Region. The application requires high-throughput, low-latency network connections between all of the EC2 instances where the application will run. There is no requirement for the application to be fault tolerant.\n\nWhich solution will meet these requirements?","answer_ET":"A"},{"id":"PqTfqAntr6Zp3iRYRNsM","topic":"1","unix_timestamp":1687571100,"exam_id":33,"question_text":"A company is creating a REST API to share information with six of its partners based in the United States. The company has created an Amazon API Gateway Regional endpoint. Each of the six partners will access the API once per day to post daily sales figures.\n\nAfter initial deployment, the company observes 1,000 requests per second originating from 500 different IP addresses around the world. The company believes this traffic is originating from a botnet and wants to secure its API while minimizing cost.\n\nWhich approach should the company take to secure its API?","answer_images":[],"answer":"D","question_id":170,"answers_community":["D (97%)","3%"],"discussion":[{"content":"Selected Answer: D\nAns is Opt D, A usage plan provides select customers with specific access permissions and request quotas, which helps manage and restrict usage to prevent overuse of resources.\nAPI keys are used for tracking and controlling how the API is used. This additional layer of security ensures that only those with the key can access the API.\nWhy not Opt C, Amazon API Gateway doesn't support request limiting through resource policies. You can set permissions on who can access your API using a resource policy, but rate limiting isn't handled by resource policies.\nAPI keys alone do not provide throttling or rate limiting. For throttling, you typically would need to use them along with usage plans","upvote_count":"15","timestamp":"1703396340.0","comment_id":"932135","poster":"shree2023"},{"comment_id":"1127409","timestamp":"1721488320.0","upvote_count":"1","poster":"kejam","content":"Selected Answer: D\nAnswer D\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-control-access-aws-waf.html\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html"},{"poster":"duriselvan","timestamp":"1718197920.0","upvote_count":"1","comment_id":"1094651","content":"c ANS\nC. WAF with IP Filtering and Resource Policy:\n\nPros:\nSimple and cost-effective solution.\nWAF rules and resource policy restrict access.\nCons:\nIP filtering might not be effective if partners use dynamic IP addresses.\nResource policy request limit applies to all methods, not just POST."},{"upvote_count":"1","content":"Selected Answer: D\nOption D","comment_id":"1077982","timestamp":"1716422580.0","poster":"career360guru"},{"upvote_count":"1","poster":"xav1er","timestamp":"1708635120.0","comment_id":"987697","content":"Selected Answer: D\ndef answ D as described here \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-control-access-aws-waf.html"},{"comment_id":"959782","content":"Correct D.","upvote_count":"1","timestamp":"1705957200.0","poster":"ggrodskiy"},{"comment_id":"945200","timestamp":"1704603540.0","content":"Selected Answer: D\nD fits","poster":"NikkyDicky","upvote_count":"1"},{"poster":"Christina666","upvote_count":"1","content":"Selected Answer: D\nAmazon API Gateway resource policies are JSON policy documents that you attach to an API to control whether a specified principal (typically an IAM role or group) can invoke the API. You can use API Gateway resource policies to allow your API to be securely invoked by:\n\nUsers from a specified AWS account.\n\nSpecified source IP address ranges or CIDR blocks.\n\nSpecified virtual private clouds (VPCs) or VPC endpoints (in any account).","timestamp":"1704495720.0","comment_id":"944118"},{"poster":"SmileyCloud","upvote_count":"3","content":"Selected Answer: D\nIt's D. The IP filtering is done with the WAF ACL so there is no need to do another IP filtering by using resource policies which can do exactly that. https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-resource-policies.html","timestamp":"1703635020.0","comment_id":"934813"},{"upvote_count":"1","poster":"easytoo","comment_id":"934521","content":"d-d-d-d-d-d","timestamp":"1703605920.0"},{"comment_id":"933832","poster":"SkyZeroZx","upvote_count":"2","timestamp":"1703538000.0","content":"Selected Answer: D\nD is classic use of \"usage plan\" in API Gateway addicionally more apropiate practice is API Key for autentication or other methos"},{"content":"Selected Answer: D\nI vote for D since I couldn't find a way to set up a request limit in resource policy\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-resource-policies.html","comment_id":"933223","poster":"Maria2023","upvote_count":"2","timestamp":"1703487900.0"},{"upvote_count":"1","comment_id":"932101","content":"Selected Answer: C\nOption C provides a cost-effective approach to securing the API while allowing access only to the IP addresses used by the six partners. By creating an AWS WAF web ACL and configuring it to allow access only to the IP addresses of the trusted partners, the company can effectively block requests originating from unauthorized sources. Associating the web ACL with the API ensures that the filtering rules are applied to the API traffic.\n\nAdditionally, creating a resource policy with a request limit allows the company to set a maximum limit on the number of requests that can be made to the API within a given time frame. This helps mitigate the impact of potential botnet traffic, ensuring that the API is not overwhelmed with excessive requests.\n\nRequiring an API key on the POST method adds an extra layer of security by enforcing authentication for accessing the API. This ensures that only authorized partners with valid API keys can successfully make requests to the API.","poster":"Alabi","timestamp":"1703390520.0"},{"timestamp":"1703389500.0","poster":"gd1","comment_id":"932088","content":"Selected Answer: D\nGPT 4.0: AWS WAF is a web application firewall that lets you monitor HTTP and HTTPS requests that are forwarded to Amazon API Gateway. The solution architect can create a WAF rule that allows access only from the IP addresses of the six partners.\nA usage plan in API Gateway provides throttling and quota limits to manage the rate of requests from your customers and prevent attacks. Setting a request limit that matches the expected usage of the partners would help to protect the API.","upvote_count":"2"}],"question_images":[],"answer_ET":"D","isMC":true,"choices":{"B":"Create an Amazon CloudFront distribution with the API as the origin. Create an AWS WAF web ACL with a rule to block clients that submit more than five requests per day. Associate the web ACL with the CloudFront distribution. Add a custom header to the CloudFront distribution populated with an API key. Configure the API to require an API key on the POST method.","D":"Create an AWS WAF web ACL with a rule to allow access to the IP addresses used by the six partners. Associate the web ACL with the API. Create a usage plan with a request limit and associate it with the API. Create an API key and add it to the usage plan.","A":"Create an Amazon CloudFront distribution with the API as the origin. Create an AWS WAF web ACL with a rule to block clients that submit more than five requests per day. Associate the web ACL with the CloudFront distribution. Configure CloudFront with an origin access identity (OAI) and associate it with the distribution. Configure API Gateway to ensure only the OAI can run the POST method.","C":"Create an AWS WAF web ACL with a rule to allow access to the IP addresses used by the six partners. Associate the web ACL with the API. Create a resource policy with a request limit and associate it with the API. Configure the API to require an API key on the POST method."},"url":"https://www.examtopics.com/discussions/amazon/view/113147-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_description":"","timestamp":"2023-06-24 03:45:00"}],"exam":{"name":"AWS Certified Solutions Architect - Professional SAP-C02","provider":"Amazon","isBeta":false,"isImplemented":true,"id":33,"isMCOnly":true,"numberOfQuestions":529,"lastUpdated":"11 Apr 2025"},"currentPage":34},"__N_SSP":true}