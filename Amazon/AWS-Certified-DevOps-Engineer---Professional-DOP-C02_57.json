{"pageProps":{"questions":[{"id":"imoWZXAAAu4DHhM5r0kX","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/151629-exam-aws-certified-devops-engineer-professional-dop-c02/","discussion":[{"content":"Selected Answer: CE\n1. IAM user creation:\n • Both the DevOps team and developers should be able to create IAM users.\n 2. Permissions control:\n • Developers should be restricted from granting excessive permissions to the IAM users they create.\n 3. Prevention of unauthorized IAM user creation:\n • Only the designated roles (DevOps and developers) should create IAM users.\n\nTo achieve this, AWS Permissions Boundaries provide an effective way to enforce limits on the permissions that developers can assign","poster":"Ky_24","comment_id":"1327507","upvote_count":"4","timestamp":"1734366840.0"},{"timestamp":"1732781160.0","upvote_count":"3","comment_id":"1319089","poster":"ArunRav","content":"Selected Answer: CE\nSCP in A denies the access to everyone but it doesnt explain the details about PermissionBoundaries policy used in C option. When you combine the C option with E option ie Creation of PermissionBoundaries policy to create the boundary and Creation of Developer boundary policy which allow developers to have access with boundaries mentioned in PermissionBoundaries make sense.\nHence CE"},{"timestamp":"1732456200.0","upvote_count":"4","poster":"Impromptu","content":"Selected Answer: CE\nA would prevent anyone to create IAM users, so both DevOps teams and Developers cannot create IAM users.\nB would prevent DevOps team to create IAM users \"with any level of permissions\".\nC would create the permission boundary that defines the maximum permissions of a user created by the Developers.\nD does not work like that. The permission boundary would be used for preventing too many permissions on a user created by the Developers, and not for giving them user creation rights as well.\nE would give the Developers the permissions to create users, but would force them to also attach the permission boundary (created in C) to the new user, limiting their permissions correctly (even if the Developer would give that user too many permissions)","comment_id":"1317064"},{"content":"Selected Answer: AE\nOption A provides the control at the organizational level to deny IAM user creation by non-DevOps users.\n • Option E ensures that developers can create users with limited permissions by enforcing Permission Boundaries, ensuring they cannot assign excessive permissions.\n\nThis combination effectively meets the requirements with the least operational overhead.","comment_id":"1314571","timestamp":"1732012740.0","upvote_count":"1","poster":"uncledana"}],"topic":"1","exam_id":23,"answer_images":[],"answer_ET":"CE","answer":"CE","question_images":[],"timestamp":"2024-11-19 11:39:00","question_text":"A company uses an organization in AWS Organizations to manage multiple AWS accounts in a hierarchical structure. An SCP that is associated with the organization root allows IAM users to be created.\n\nA DevOps team must be able to create IAM users with any level of permissions. Developers must also be able to create IAM users. However, developers must not be able to grant new IAM users excessive permissions. The developers have the CreateAndManageUsers role in each account. The DevOps team must be able to prevent other users from creating IAM users.\n\nWhich combination of steps will meet these requirements? (Choose two.)","question_id":281,"isMC":true,"unix_timestamp":1732012740,"choices":{"C":"Create an IAM permissions policy named PermissionBoundaries within each account. Configure the PermissionBoundaries policy to specify the maximum permissions that a developer can grant to a new IAM user.","E":"Create an IAM permissions policy named DeveloperBoundary within each account. Configure the DeveloperBoundary policy to allow developers to create IAM users and to assign policies to IAM users of only if the developer includes the PermissionBoundaries policy as the permissions boundary. Attach the DeveloperBoundary policy to the CreateAndManageUsers role within each account.","A":"Create an SCP in the organization to deny users the ability to create and modify IAM users. Attach the SCP to the root of the organization. Attach the CreateAndManageUsers role to developers.","B":"Create an SCP in the organization to grant users that have the DeveloperBoundary policy attached the ability to create new IAM users and to modify IAM users. Configure the SCP to require users to attach the PermissionBoundaries policy to any new IAM user. Attach the SCP to the root of the organization.","D":"Create an IAM permissions policy named PermissionBoundaries within each account. Configure PermissionsBoundaries to allow users who have the PermissionBoundaries policy to create new IAM users."},"answers_community":["CE (92%)","8%"]},{"id":"6aMtJKA1xaYsyEuXWMys","topic":"1","question_id":282,"isMC":true,"discussion":[{"upvote_count":"6","comment_id":"1323485","content":"Selected Answer: C\nC: \nEnforce tagging across all accounts via StackSets. \nUse CDK Stacks to deploy same configuration SQS.","timestamp":"1733653620.0","poster":"sn61613"},{"timestamp":"1744246740.0","poster":"Srikantha","content":"Selected Answer: D\nTagging enforcement via CDK stack-level tagging.\nReusable constructs for consistent SQS configuration.\nCDK feature flags to help with best practices and configuration enforcement.\nAll with the least operational overhead and maximum developer productivity.","upvote_count":"1","comment_id":"1559436"},{"timestamp":"1738523340.0","comment_id":"1350623","upvote_count":"1","poster":"jojewi8143","content":"Selected Answer: C\nGoing with C"},{"timestamp":"1737391140.0","comment_id":"1343743","content":"Selected Answer: B\nGoing with B which enforce tagging using SCPs and promote the reuse of code using CF modules for the SQS.","poster":"teo2157","upvote_count":"1"},{"comment_id":"1319095","timestamp":"1732782300.0","content":"Selected Answer: B\nThough it is a straightforward solution...It doesn't give the level of enforcing with SCP has. Hence for restricting SCP and CFT to deploy.\nHence B","poster":"ArunRav","upvote_count":"1"},{"content":"Selected Answer: D\nOption D provides a straightforward, flexible, and scalable solution by using AWS CDK for both tagging enforcement and reusing code, while also ensuring that developers can maintain standardization in their deployments with feature flags. This solution promotes best practices in terms of both infrastructure consistency and operational efficiency.","timestamp":"1732012800.0","poster":"uncledana","comment_id":"1314573","upvote_count":"1"}],"answer":"C","answers_community":["C (64%)","D (18%)","B (18%)"],"timestamp":"2024-11-19 11:40:00","question_text":"A company has deployed a landing zone that has a well-defined AWS Organizations structure and an SCP. The company's development team can create their AWS resources only by using AWS CloudFormation and the AWS Cloud Development Kit (AWS CDK).\n\nA DevOps engineer notices that Amazon Simple Queue Service (Amazon SQS) queues that are deployed in different CloudFormation stacks have different configurations. The DevOps engineer also notices that the application cost allocation tag is not always set.\n\nThe DevOps engineer needs a solution that will enforce tagging and promote the reuse of code. The DevOps engineer needs to avoid different configurations for the deployed SQS queues.\n\nWhat should the DevOps engineer do to meet these requirements?","exam_id":23,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/151630-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_description":"","answer_images":[],"unix_timestamp":1732012800,"choices":{"A":"Create an Organizations tag policy to enforce the cost allocation tag in CloudFormation stacks. Instruct the development team to use CloudFormation to define SQS queues. Instruct the development team to deploy the SQS queues by using CloudFormation StackSets.","C":"Use AWS CDK tagging to enforce the cost allocation tag in CloudFormation StackSets. Instruct the development team to use the AWS CDK to define SQS queues. Instruct the development team to deploy the SQS queues by using CDK stacks.","D":"Use AWS CDK tagging to enforce the cost allocation tag in CloudFormation stacks. Instruct the development team to use the AWS CDK to define SQS queues. Instruct the development team to deploy the SQS queues by using CDK feature flags.","B":"Update the SCP to enforce the cost allocation tag in CloudFormation stacks. Instruct the development team to use CloudFormation modules to define SQS queues. Instruct the development team to deploy the SQS queues by using CloudFormation stacks."},"question_images":[]},{"id":"D1isfQz2g6kA57WMOSGi","exam_id":23,"unix_timestamp":1732012920,"answers_community":["A (100%)"],"answer":"A","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/151631-exam-aws-certified-devops-engineer-professional-dop-c02/","choices":{"D":"Use AWS Trusted Advisor to check for noncompliant configurations. Manually apply necessary changes based on Trusted Advisor recommendations.","A":"Use AWS Config rules to detect changes in resource configurations. Configure remediation action that uses AWS Systems Manager Automation documents to revert the configuration changes.","B":"Use Amazon CloudWatch alarms to monitor resource metrics. When an alarm is activated, use an Amazon Simple Notification Service (Amazon SNS) topic to notify an administrator to manually reverts the configuration changes.","C":"Use AWS CloudFormation to create a stack that deploys the necessary configuration changes. Update the stack when configuration changes need to be reverted."},"answer_images":[],"isMC":true,"answer_ET":"A","question_id":283,"timestamp":"2024-11-19 11:42:00","question_text":"A DevOps team manages a company's AWS account. The company wants to ensure that specific AWS resource configuration changes are automatically reverted.\n\nWhich solution will meet this requirement?","discussion":[{"upvote_count":"5","timestamp":"1732012920.0","poster":"uncledana","comment_id":"1314575","content":"Selected Answer: A\nThe best solution is A, where AWS Config rules are used to monitor resource configuration changes, and remediation actions using AWS Systems Manager Automation documents are configured to automatically revert any non-compliant configuration changes. This provides an automated, scalable solution that meets the requirement to ensure that specific AWS resource configuration changes are automatically reverted."}],"question_images":[],"topic":"1"},{"id":"AgsI045sR261QZmb2Gep","answer_images":[],"timestamp":"2023-04-15 16:39:00","answer":"ADE","discussion":[{"content":"Selected Answer: ADE\nS3 cross-Region replication (CRR) automatically replicates data between buckets across different AWS Regions. To enable CRR, you need to add a replication configuration to your source bucket that specifies the destination bucket, the IAM role, and the encryption type (optional). You also need to grant permissions to the IAM role to perform replication actions on both the source and destination buckets. Additionally, you can choose the destination storage class and enable additional replication options such as S3 Replication Time Control (S3 RTC) or S3 Batch Replication.","poster":"tschenhau","timestamp":"1699680600.0","comment_id":"894541","upvote_count":"7"},{"comments":[{"comment_id":"1222359","timestamp":"1733011740.0","content":"Source Account: (Source Bucket)(Versioning)(Role/Policy to \"Enable\" Replicaton)\nTarget Account: (Target Bucket)(Versioning)(Role/Policy to \"Allow\" Replicaton)","upvote_count":"2","poster":"Gomer"}],"upvote_count":"3","timestamp":"1733010900.0","comment_id":"1222353","poster":"Gomer","content":"Selected Answer: ADE\nTricky question because they are trying to get one to confuse the \"enable\" replicaton \"role\"/policy (\"rule\") in source account with the \"allow\" replicaton role/\"policy\" in target account. These references helped me work up some summary steps:\nSteps to configure S3 replication between different accounts\n1. Create source and destination buckets in different accounts and regions (acctA, acctB)\n2. Enable versioning on the buckets (acctA, acctB)\n3. Create IAM role and attach a policy granting S3 permission to replicate objects (acctA)\n4. Add the replication configuration to source bucket (acctA)\n5. Add bucket \"policy on the destination bucket to allow\" objects replication (acctB)(req. 2nd role)\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-walkthrough1.html#enable-replication\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-walkthrough-2.html"},{"poster":"thanhnv142","timestamp":"1722301140.0","upvote_count":"2","comment_id":"1135457","content":"ADF is correct: this task is done by S3 itself\nA: Create role in the source to allow S3 access permission\nD: add policy to allow repication in the target\nE: enable replication in the source"},{"timestamp":"1710952020.0","comment_id":"1012408","poster":"bugincloud","content":"Selected Answer: ADE\nADE make sense.","upvote_count":"2"},{"comment_id":"924220","timestamp":"1702653360.0","poster":"madperro","upvote_count":"2","content":"Selected Answer: ADE\nADE make sense."},{"upvote_count":"2","comment_id":"886964","poster":"haazybanj","content":"Selected Answer: ADE\nConfirmed","timestamp":"1698898200.0"},{"content":"ADE confirmed!","poster":"alce2020","comment_id":"871403","upvote_count":"1","timestamp":"1697421000.0"},{"content":"Selected Answer: ADE\nADE\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-walkthrough-2.html","upvote_count":"3","comment_id":"870996","poster":"ele","timestamp":"1697380740.0"}],"question_text":"A DevOps engineer needs to back up sensitive Amazon S3 objects that are stored within an S3 bucket with a private bucket policy using S3 cross-Region replication functionality. The objects need to be copied to a target bucket in a different AWS Region and account.\nWhich combination of actions should be performed to enable this replication? (Choose three.)","choices":{"E":"Create a replication rule in the source bucket to enable the replication.","A":"Create a replication IAM role in the source account","D":"Add statements to the target bucket policy allowing the replication IAM role to replicate objects.","B":"Create a replication I AM role in the target account.","F":"Create a replication rule in the target bucket to enable the replication.","C":"Add statements to the source bucket policy allowing the replication IAM role to replicate objects."},"question_id":284,"answer_ET":"ADE","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/106261-exam-aws-certified-devops-engineer-professional-dop-c02/","isMC":true,"topic":"1","answers_community":["ADE (100%)"],"question_images":[],"unix_timestamp":1681569540,"exam_id":23},{"id":"XktKoN16mK35hFTZX7o0","timestamp":"2025-02-25 18:30:00","question_images":[],"isMC":true,"question_text":"A company's DevOps team uses Node Package Manager (NPM) open source libraries to build applications. The DevOps team runs its application build process in an AWS CodeBuild project that downloads the NPM libraries from public NPM repositories.\n\nThe company wants to host the NPM libraries in private NPM repositories. The company also needs to be able to run checks on new versions of the libraries before the DevOps team uses the libraries.\n\nWhich solution will meet these requirements with the LEAST operational effort?","answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/157101-exam-aws-certified-devops-engineer-professional-dop-c02/","topic":"1","answers_community":["A (100%)"],"question_id":285,"answer_images":[],"choices":{"C":"Create an AWS CodeCommit repository for each library. Clone the required NPM libraries to the appropriate CodeCommit repository. Modify the CodeBuild appspec.yaml config file to use the private CodeCommit repositories. Add a step to perform the required checks on the package versions.","D":"Create an AWS CodeCommit repository for each library. Clone the required NPM libraries to the appropriate CodeCommit repository. Modify the CodeBuild buildspec.yaml config file so that NPM uses the private CodeCommit repositories. Add an AWS CodePipeline pipeline that performs the required checks on the package versions for each new commit to the repositories. Configure the pipeline to revert to the most recent commit in the event of a failure.","B":"Enable Amazon S3 caching in the CodeBuild project configuration. Add a step in the buildspec.yaml config file to perform the required checks on the package versions in the cache.","A":"Create an AWS CodeArtifact repository with an upstream repository named npm-store. Configure the application build process to use the CodeArtifact repository as the default source for NPM. Create an AWS CodePipeline pipeline to perform the required checks on package versions in the CodeArtifact repository. Set the package status to unlisted if a failure occurs."},"exam_id":23,"answer_description":"","unix_timestamp":1740504600,"discussion":[{"timestamp":"1740504600.0","comment_id":"1361515","upvote_count":"1","content":"Selected Answer: A\nCodeArtifact with Upstream Repository\n\nProxy Public Packages: The npm-store upstream repository acts as a proxy for npm.org, automatically caching public packages in CodeArtifact13.\n\nCentralized Control: The build process uses CodeArtifact as the default NPM source, ensuring all dependencies are managed privately.\n\nCodePipeline for Version Checks\n\nAutomated Validation: The pipeline runs tests or checks on new package versions before they’re approved for use.\n\nUnlisted Status: Failed packages are marked as unlisted, preventing their inclusion in builds until resolved16.\n\nWhy Other Options Fail:\n\nB/C/D: Cloning libraries into CodeCommit (C/D) or using S3 caching (B) adds manual effort and complexity compared to CodeArtifact’s native proxying.\n\nNo Need for Manual Cloning: CodeArtifact’s upstream eliminates the need to clone public packages into private repositories","poster":"Bwhizzy"}],"answer_ET":"A"}],"exam":{"numberOfQuestions":355,"isBeta":false,"lastUpdated":"11 Apr 2025","provider":"Amazon","isImplemented":true,"id":23,"isMCOnly":true,"name":"AWS Certified DevOps Engineer - Professional DOP-C02"},"currentPage":57},"__N_SSP":true}