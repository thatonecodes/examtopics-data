{"pageProps":{"questions":[{"id":"zsCGGirsqZZNe4PHFjnn","choices":{"D":"Apply undersampling to the training dataset before training.","A":"Apply anomaly detection to remove outliers from the training dataset before training.","C":"Apply normalization to the features of the training dataset before training.","B":"Apply Synthetic Minority Oversampling Technique (SMOTE) to the training dataset before training."},"question_text":"A global bank requires a solution to predict whether customers will leave the bank and choose another bank. The bank is using a dataset to train a model to predict customer loss. The training dataset has 1,000 rows. The training dataset includes 100 instances of customers who left the bank.\n\nA machine learning (ML) specialist is using Amazon SageMaker Data Wrangler to train a churn prediction model by using a SageMaker training job. After training, the ML specialist notices that the model returns only false results. The ML specialist must correct the model so that it returns more accurate predictions.\n\nWhich solution will meet these requirements?","answer":"B","question_images":[],"question_id":266,"answer_images":[],"unix_timestamp":1725707220,"answer_description":"","isMC":true,"exam_id":26,"url":"https://www.examtopics.com/discussions/amazon/view/147147-exam-aws-certified-machine-learning-specialty-topic-1/","answer_ET":"B","answers_community":["B (100%)"],"discussion":[{"comment_id":"1286138","content":"Selected Answer: B\nB is the right choice . D is not an option .While undersampling would discard valuable data from the majority class. Since the dataset is already small (only 1,000 rows), undersampling could lead to a loss of important information","timestamp":"1726721040.0","poster":"Tkhan1","upvote_count":"1"},{"comment_id":"1279973","upvote_count":"1","poster":"GS_77","timestamp":"1725707220.0","content":"Selected Answer: B\nSMOTE is most effective."}],"timestamp":"2024-09-07 13:07:00","topic":"1"},{"id":"YrlfeiSUZ7hgViomqdrp","answers_community":["B (86%)","14%"],"topic":"1","answer_description":"","question_images":[],"unix_timestamp":1725039720,"choices":{"A":"Difference in proportions of labels (DPL)","B":"Class imbalance (CI)","C":"Conditional demographic disparity (CDD)","D":"Kolmogorov-Smirnov (KS)"},"timestamp":"2024-08-30 19:42:00","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/146688-exam-aws-certified-machine-learning-specialty-topic-1/","exam_id":26,"answer":"B","discussion":[{"upvote_count":"1","timestamp":"1729417500.0","content":"Selected Answer: B\nClass Imbalance (CI): This occurs when certain classes (in this case, age groups) are underrepresented in the dataset. This can lead to biased model predictions because the model may not learn enough about the underrepresented class to make accurate predictions1.","comment_id":"1300385","poster":"MultiCloudIronMan"},{"upvote_count":"1","poster":"MultiCloudIronMan","comment_id":"1288137","timestamp":"1727097600.0","content":"Selected Answer: B\nB is correct because."},{"poster":"Tkhan1","comment_id":"1286140","timestamp":"1726721220.0","content":"Selected Answer: B\nB is the correct option","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: B\nThe type of pretraining bias observed in the training dataset, where there are fewer examples of customers in the 40 to 55 year-old age group compared to the other age groups, is:\n\nB. Class imbalance (CI)\n\nExplanation:\nClass imbalance (CI) refers to a situation where certain classes or groups are underrepresented in the dataset. In this case, the age group 40 to 55 is underrepresented compared to other age groups.\nDifference in proportions of labels (DPL) generally refers to differences in the proportions of different labels (outcomes) rather than input features like age.\nConditional demographic disparity (CDD) refers to differences in outcomes for different demographic groups conditional on certain factors, not the raw distribution of demographic features.\nKolmogorov-Smirnov (KS) is a statistical test used to compare distributions, but it is not specifically a type of bias.\nTherefore, the correct answer is B. Class imbalance (CI).","timestamp":"1725105840.0","poster":"Shivanshub","comment_id":"1275568"},{"content":"Selected Answer: C\nAnswer is C","upvote_count":"1","comment_id":"1275303","timestamp":"1725060240.0","poster":"aragon_saa"},{"comment_id":"1275202","timestamp":"1725039720.0","content":"Selected Answer: B\nClass imbalance can lead to biased models that perform poorly on the underrepresented class or group, as the model may not have enough examples to learn the patterns and characteristics of that class effectively.","upvote_count":"1","poster":"GS_77"}],"question_text":"A banking company provides financial products to customers around the world. A machine learning (ML) specialist collected transaction data from internal customers. The ML specialist split the dataset into training, testing, and validation datasets. The ML specialist analyzed the training dataset by using Amazon SageMaker Clarify. The analysis found that the training dataset contained fewer examples of customers in the 40 to 55 year-old age group compared to the other age groups.\n\nWhich type of pretraining bias did the ML specialist observe in the training dataset?","answer_ET":"B","question_id":267,"answer_images":[]},{"id":"kf3ARyycbcrPbayAg2oy","unix_timestamp":1575921480,"timestamp":"2019-12-09 20:58:00","choices":{"B":"Replace the age field value for records with a value of 0 with the mean or median value from the dataset","A":"Drop all records from the dataset where age has been set to 0.","C":"Drop the age feature from the dataset and train the model using the rest of the features.","D":"Use k-means clustering to handle missing features"},"exam_id":26,"answer":"B","answers_community":["B (60%)","D (40%)"],"question_images":[],"answer_images":[],"topic":"1","answer_ET":"B","isMC":true,"question_id":268,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/10054-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"poster":"rajs","upvote_count":"39","comments":[{"content":"https://www.displayr.com/5-ways-deal-missing-data-cluster-analysis/\nB is correct","upvote_count":"7","timestamp":"1633214340.0","comment_id":"57665","comments":[{"poster":"Shakespeare","upvote_count":"1","timestamp":"1734203040.0","content":"If it was KNN it would be more accurate, but we don't have that option.","comment_id":"1326594"}],"poster":"L2007"}],"content":"Dropping the Age feature is a NOT ATOLL a good idea - as age plays a critical role in this disease as per the question\n\nDropping 10% of data is NOT a good idea considering the fact that the number of observations is already low.\n\nThe Mean or Median are a potential solutions \n\nBut the question says that \"Disease worsens after age 65 so there is a correlation between age and other symptoms related feature\" So that means that using Unsupervised Learning we can make pretty good prediction of \"Age\" \n\nSo the answer is D Use K-Means clustering","timestamp":"1633211100.0","comment_id":"57342"},{"poster":"vetal","timestamp":"1632104400.0","comment_id":"28509","upvote_count":"20","content":"Replacing the age with mean or median might bring a bias to the dataset. Use k-means clustering to estimate the missing age based on other features might get better results. Removing 10% available data looks odd. Why not D?"},{"poster":"JonSno","comment_id":"1358043","content":"Selected Answer: B\nThe issue arises from incorrect age values (age = 0) in a dataset where all patients are supposed to be over 65 years old. Since age is an important predictor for the disease's progression, removing or ignoring this feature may negatively impact model performance.\n\nThe best approach is imputing missing or incorrect values with a reasonable estimate (e.g., mean or median age of the dataset), ensuring that:\n\nThe dataset remains intact without losing valuable patient records.\nThe model still benefits from age as a feature.\nThe imputed values are realistic and do not introduce bias.","timestamp":"1739837760.0","upvote_count":"2"},{"content":"Selected Answer: B\nPreserves data, maintains model integrity, and corrects anomalies effectively.","timestamp":"1735588920.0","poster":"growe","upvote_count":"1","comment_id":"1334374"},{"poster":"imymoco","timestamp":"1720167660.0","content":"B. Replace the age field value for records with a value of 0 with the mean or median value from the dataset: This method allows for retaining all patient records while addressing the anomaly. It is a standard approach for dealing with missing or incorrect values in a way that preserves the integrity of the dataset.\n\nB. GPT answer","upvote_count":"1","comment_id":"1242610"},{"upvote_count":"1","content":"B-chatgpt","poster":"pn12345","timestamp":"1714956540.0","comment_id":"1207109"},{"comment_id":"1204228","content":"The question tries to mislead by adding information around the feature correlation. K-means clustering is not meant for imputing data. Hence answer should be B, that would be the right way of handling the missing value.","timestamp":"1714429980.0","upvote_count":"1","poster":"rookiee1111"},{"poster":"3eb0542","timestamp":"1713032220.0","upvote_count":"4","content":"Selected Answer: B\nUsing k-means clustering to handle missing features is not directly applicable to this scenario. K-means clustering is a method for grouping data points into clusters based on similarity, and it's not typically used for imputing missing values.","comment_id":"1195089"},{"upvote_count":"3","poster":"kyuhuck","comment_id":"1148754","timestamp":"1707779160.0","content":"Selected Answer: B\nadd/ comment why? b ? - >replacing the age field value for records with a value of 0 with the mean or median value from the dataset, is generally the best approach among the given options. It allows the preservation of the dataset size and leverages the remaining correct data points, assuming age is a crucial predictor in this context. However, it's vital to perform this imputation carefully to avoid introducing bias. Median is often preferred in this scenario to mitigate the impact of outliers."},{"comment_id":"1147316","timestamp":"1707664440.0","upvote_count":"2","content":"Selected Answer: B\nThe best way to handle the missing values in the patient age feature is to replace them with the\nmean or median value from the dataset. This is a common technique for imputing missing values that\npreserves the overall distribution of the data and avoids introducing bias or reducing the sample size.\nDropping the records or the feature would result in losing valuable information and reducing the\naccuracy of the model. Using k-means clustering would not be appropriate for handling missing\nvalues in a single feature, as it is a method for grouping similar data points based on multiple","poster":"kyuhuck"},{"comment_id":"1138951","timestamp":"1706925660.0","content":"mean or median is for outliers so D","poster":"Topg4u","upvote_count":"1"},{"content":"Selected Answer: B\nObviously B, why would you use a clustering algorithm to predict a value? D just doesn't make sense","upvote_count":"4","comment_id":"1081323","poster":"endeesa","timestamp":"1701075120.0"},{"upvote_count":"4","content":"B is correct.K-means is unsupervised and used mainly for clustering. KNN would have been more accurate. It can be used to predict a value. since knn is not present i think it is mean median value","timestamp":"1699837440.0","poster":"geoan13","comment_id":"1068960"},{"comment_id":"1067006","timestamp":"1699600680.0","content":"Selected Answer: B\nB is correct or KNN, but dont K means","upvote_count":"4","poster":"elvin_ml_qayiran25091992razor"},{"upvote_count":"2","content":"Selected Answer: D\nA. NO - unless we want to loose 10% of the data\nB. NO - age is predictive, so using the means we would introduce a bias\nC. NO - age is predictive \nD. YES - better quality than B, it is likely that other physiological values can help predict the age","timestamp":"1694607060.0","poster":"loict","comment_id":"1006586"},{"upvote_count":"1","timestamp":"1690771440.0","comment_id":"967698","content":"Selected Answer: D\nk-means should give the best estimation of the age. Using mean would reduce the correlation between outcome and age for the model.","poster":"FloKo"},{"content":"How can it be when there is a labelled outcome, which means this is Supervised and K-Means is for UnSupervised. So only possible answer should be B","upvote_count":"3","timestamp":"1690702620.0","comment_id":"966944","poster":"jyrajan69"},{"content":"Selected Answer: B\nBoth A and B are correct. But, I noted that at the end of the question is mentioned that all other features are OKAY, so is reasonable to do this simple imputation.","comment_id":"965691","upvote_count":"1","timestamp":"1690562760.0","poster":"kaike_reis"},{"comment_id":"929328","timestamp":"1687342800.0","upvote_count":"3","content":"B is correct, K-NN could have helped instead of k-means","poster":"nilmans"},{"poster":"rags1482","timestamp":"1686790380.0","upvote_count":"3","comment_id":"923628","content":"B\n\n\nIn the case where the data is labeled, it is best to use mean or median imputation. K-means clustering is an unsupervised learning algorithm, which means that it does not use labels. This means that k-means clustering will not be able to take advantage of the information in the labels when imputing missing values."},{"timestamp":"1683143400.0","comment_id":"888881","upvote_count":"2","content":"k-means is used for clustering, what you guys wanted is k-nearest neighbours. By Clustering alone, you cannot get the age, you can say that this group has similar features, but k-means doesnt give you the age as a result, it is unsupervised, you need a supervised learning to guess the age, so as a result D is not correct and B is correct.","poster":"Dota_addict"},{"content":"Selected Answer: D\nA lot of people in the comments insist that you cannot use k-means for computing missing values. If you see using this link you can do it. There are Deep learning techniques which would be better, but K-means is better than the resulting mean. So D is correct and B would be second best. https://link.springer.com/chapter/10.1007/978-3-642-14834-7_56#:~:text=We%20divide%20the%20data%20set,is%20used%20as%20impute%20value.","upvote_count":"3","timestamp":"1673809980.0","poster":"Tomatoteacher","comment_id":"776976"},{"poster":"dhyuk","upvote_count":"2","timestamp":"1671786360.0","comment_id":"754070","content":"i Think its A"},{"comment_id":"483235","content":"Selected Answer: D\nThe following is an excerpt from a Springer Verlag book called Contemporary Computing. \n\n\"...We propose an efficient missing value imputation method based on clustering with weighted distance. We divide the data set into clusters based on user specified value K. Then find a complete valued neighbor which is nearest to the missing valued instance. Then we compute the missing value by taking the average of the centroid value and the centroidal distance of the neighbor. This value is used as impute value. In our proposed approach we use K-means technique with weighted distance and show that our approach results in better performance...\"","timestamp":"1637497860.0","upvote_count":"8","poster":"[Removed]"},{"timestamp":"1636170420.0","upvote_count":"2","content":"KNN is good to get the values from nearest neighbours, but K-means also works - get the values from the clusters","poster":"richardxyz","comment_id":"440471"},{"content":"B will introduce strong bias to the data ignoring the relativity of the age feature with other features since the disease worsens with age. \nD should be the correct answer since we can impute missing data using unsupervised learning \nhttps://medium.com/jungle-book/missing-data-filling-with-unsupervised-learning-b448964030d","timestamp":"1636133340.0","comment_id":"430994","upvote_count":"1","poster":"G1807"},{"content":"B.\n\nD. K-means cannot handle missing data since it is unsupervised learning. You cannot know the predicted values. Use KNN instead.","poster":"Exia","comment_id":"408633","upvote_count":"6","timestamp":"1636092900.0"},{"timestamp":"1635905220.0","content":"Since the missing values are considerable fraction from the whole data set, yet they are crucial to the model (disease is highly correlated to those ager than 65) then there is a need for imputation. It seems odd to use clustering technique to do such a job. Hence, the only correct answer is impute using mean or median values. On the other hand, imputing using K-nearest neighbors or KNNs would be a viable solution but not K-means clustering.","poster":"hero67","comment_id":"387082","upvote_count":"4"},{"poster":"abdohanfi","upvote_count":"3","comment_id":"367780","content":"i think k means clustring is unsupervised and he said that the data is labeled so doesnt need unsupervised algorithm so i think the mean or median for the 0s are good option","timestamp":"1635450660.0"},{"upvote_count":"2","comment_id":"324203","poster":"Vita_Rasta84444","content":"I think it is D. If we just impute the median we will lose the important information, and age is one of the predictors. With K-means, we can make clusters and then impute the cluster age mean for the cluster.","timestamp":"1635360540.0"},{"content":"searching the net, I have notice that even K-Means Clustering can be also used for imputing missing data so D is still a good candidate","timestamp":"1635349860.0","upvote_count":"5","comment_id":"295899","poster":"omar_bahrain"},{"upvote_count":"3","content":"Wow there are a lot of bad comments for this one. Age is a critically important column so you cannot just dump the whole column. Eliminate C. k-means is not used for imputation. KNN is. D is a deception option and incorrect. KNN imputation would have been the best option but it;s not listed here. Because age is a critical predictor as stated in the question, you just cannot assign the mean or median to it. That will ruin your model. Eliminate B. A is the best option listed. Dropping 11% of your training examples is not optimal but it is acceptable when you still have thousands of samples.","poster":"cloud_trail","comment_id":"278243","timestamp":"1635201540.0","comments":[{"timestamp":"1636032840.0","poster":"Huy","comment_id":"399247","upvote_count":"1","comments":[{"content":"May be D is better than B.","timestamp":"1636060860.0","upvote_count":"1","poster":"Huy","comment_id":"402516"}],"content":"Should not give missing data > 10%. So not A. Impute mean/median make sense in this case. \nB is correct. In fact, this doesn't ruin your model. You still need to validate and test."}]},{"timestamp":"1635019680.0","comment_id":"263478","content":"It will be my first time to handle missing values with K-Means, so I will go with B, choosing between the mean and the median looking at the distribution of the data.","poster":"DzR","upvote_count":"4"},{"upvote_count":"3","timestamp":"1634983020.0","content":"Should be B. Using K-mean is OK, but D said \"handle missing feature\". those 450 samples have incorrect input feature instead of \"missing\" feature, so D is a misleading option.","comment_id":"254332","poster":"dd1024"},{"upvote_count":"5","poster":"yeetusdeleetus","comment_id":"212260","content":"Correct answer is B.\n\nThe fact that they mentioned the data with missing values appears normal compared to the rest of the population (ie, normally distributed) means that the mean will not introduce very significant bias. If anything it will introduce noise, not bias.\n\nUsing k-means is clever but would not solve the problem unless you also imputed values, which the answer does not state.\n\nI personally would prefer to drop rows with missing values and I think it gives better results, and if the resulting dataset is too small you should gather more data. But, in the context of the question where they mention the data with missing values is 'normal' compared to the remainder of data, the mean is what we are pointed to.","timestamp":"1634742240.0"},{"poster":"Omar_Cascudo","timestamp":"1634701920.0","content":"B and D are correct paths to follow. Clustering the patients, as disease gets worst with age, and assign the mean or median age of the cluster should not introduce bias. I go with D.","upvote_count":"1","comment_id":"211271"},{"content":"Drop rows is better than filling the wrong values. Since age is the most important feature, using missing data techniques here can be dangerous. It is better to avoid input noise in your most important variable.","timestamp":"1634657580.0","upvote_count":"4","comment_id":"201695","poster":"weslleylc"},{"poster":"Tunermania","comments":[{"poster":"lightblue","comment_id":"247700","upvote_count":"1","content":"what abt the\"w\" added to 'right' - in your comment","timestamp":"1634757240.0"}],"timestamp":"1634604840.0","content":"Since there have been a huge suggestion of the answer being B or C, i will like to analyse the solution from different angle:\nFrom the question it's stated that \"The other features for these observations appear normal compared to the rest of the sample population\" which logically mean, only the age feature is having missing values, if i am right. \n\nOption D state that \" Use k-means clustering to handle missing <features>\". I want us to notice the \"s\" added to to feature in option D. Thus, contradicting the statement in the question about age feature being the only one that has missing values.\n\nHence, option B should be the wright answer.","upvote_count":"2","comment_id":"182823"},{"timestamp":"1634525760.0","poster":"Th3Dud3","content":"D. Use k-means clustering to handle missing features ---> Nothing specific about AGE","comment_id":"179935","upvote_count":"3"},{"upvote_count":"2","comment_id":"175547","content":"B is best choice. Because with A,B is definitely not suitable for this problem. D if we only use K-Mean we only cluster the age and then what next? we need a step after clustering. So D is not enough for this problem","poster":"Willnguyen22","timestamp":"1634354460.0"},{"poster":"syu31svc","content":"C and D are wrong; k-means clustering does not handle missing value in any way\n\nBetween A and B, B is the better choice since not most of the values are missing for it to be dropped.","timestamp":"1634238960.0","upvote_count":"2","comment_id":"171776"},{"timestamp":"1634055960.0","content":"\"a particular disease that is known to worsen with age.\" It suggested that there is colinearity between the age and the severity of the disease. \n\nIf we want to impute the data, we need to minimize the bias.\n\nA. dropping 10% of the data may not be good.\nB. Age is highly related to the severity of the disease. Using the mean or median will induce a large bias. \nC. drop age column. Actually, it makes some sense because age is highly related to the severity, but the severity of the disease looks OK in these samples. \nD. Do clustering and impute the sample's age by the mean/median value of its cluster. Looks reasonable to me. Also, there are some papers talking about K mean clustering and data imputation, and some of them imputed clinical data. Also, in the sample question from Amazon mentioned using samples with similar features to impute missing data. \n\nA, C is dropping, C looks better than A. B, D is imputation, D looks better. \n\nFor 90% of data have correct Age information so that the drop Age column might be not good. So, D might the best answer.","poster":"yddmj","comment_id":"164141","upvote_count":"3"},{"comment_id":"150917","timestamp":"1633956540.0","content":"The correct Answer should be D. \nBuild clusters and then impute values based on other ages in the same cluster.","upvote_count":"3","poster":"hans1234"},{"timestamp":"1633634520.0","poster":"bab2020","comment_id":"117098","content":"D is correct","upvote_count":"4"},{"comment_id":"108449","comments":[{"timestamp":"1635302640.0","content":"Nope. Terrible idea when the target variable is strongly correlated with age and the range of age can be from 66 to over 100.","poster":"cloud_trail","upvote_count":"1","comment_id":"278248"}],"timestamp":"1633496340.0","upvote_count":"10","content":"The correct answer would be 'B'. There have been lot of discussion around K means clustering. The reason why clustering algorithm would not work in this case is because the feature 'Age' is a continuous feature. Since Age is a non categorical feature we really have no prior knowledge on how many clusters needs to be formed. \nK means clustering is right technique if we want to impute missing values for categorical features, since in that case we would be sure of number of clusters to work with.\nIn my opinion the correct answer would be replacing continuous missing values with mean or median.","poster":"Antriksh"},{"poster":"BigEv","upvote_count":"2","content":"Both B and D make sense. But I will go with D, because as one of the most important features \n of this model, to replace 10% of age could bring a bias to the model.","timestamp":"1633009500.0","comment_id":"42844"},{"upvote_count":"5","content":"should be B","timestamp":"1632866280.0","comment_id":"40992","poster":"ozan11"},{"poster":"cybe001","upvote_count":"5","comment_id":"38277","content":"Looks like D is the correct answer, you can use K-means to find missing values\nhttps://medium.com/jungle-book/missing-data-filling-with-unsupervised-learning-b448964030d","timestamp":"1632759900.0"},{"timestamp":"1632617760.0","comment_id":"35284","poster":"JayK","comments":[{"content":"How is this even possible ? the disease worsens with age , age is the most imp factor in predicting outcome , how can you remove age","poster":"PANDU","timestamp":"1632636540.0","comment_id":"36185","upvote_count":"8"}],"content":"I think the answer is C. The reason being. The data set contains patients above 65, even if we bin the data, the range above 65 can be one bin. So removing that feature would not have a big impact","upvote_count":"1"},{"poster":"ComPah","timestamp":"1632319440.0","comment_id":"34753","comments":[{"poster":"vetal","upvote_count":"3","timestamp":"1632651420.0","comments":[{"upvote_count":"2","poster":"OhCobblers","comment_id":"160834","timestamp":"1633975800.0","content":"The question states all the patients are over 65"},{"comment_id":"36990","timestamp":"1632753240.0","upvote_count":"8","comments":[{"timestamp":"1633113420.0","content":"Also my understanding is you need supervised learning for imputation.K-means doesn't fit the bill by itself","comments":[{"timestamp":"1633139220.0","content":"I agree (after I chose wrongly D myself). For k-means you should do additional derivation of feasible number of clusters which is not a trivial task. So, B is correct.","upvote_count":"6","poster":"tap123","comment_id":"46776"}],"upvote_count":"4","comment_id":"44257","poster":"ComPah"}],"content":"D would have been correct if the option would be like, imputation based on K means. K means alone can't handle missing values. So it's really very vague. Considering the other options and the feature age, B seems to be a correct option.","poster":"am7"}],"content":"I think k-means clustering still possible: assume that the k = sum of different ages in the dataset (possibly around 35), then do clustering and then replace 0 for that 450 records with the cluster number.","comment_id":"36440"}],"upvote_count":"9","content":"KNN K-nearest Neighbor would have been right answer.Option D is misleading"},{"upvote_count":"6","timestamp":"1632106440.0","content":"how can you use k-means to handle missing data? that's a problem","comment_id":"32893","poster":"heihei"},{"upvote_count":"7","comments":[{"content":"second best answer is D (k-means clustering) - filling the most probable value","comments":[{"poster":"hughhughhugh","content":"not knn","timestamp":"1633484520.0","comment_id":"79041","upvote_count":"2"}],"comment_id":"28257","upvote_count":"5","timestamp":"1632086340.0","poster":"rsimham"}],"comment_id":"28256","content":"I think dropping 10% of data set is not a smart idea.\nI will go with B. Replace the age field value for records with a value of 0 with the mean or median value from the dataset","poster":"rsimham","timestamp":"1632082920.0"}],"question_text":"A Data Scientist is developing a machine learning model to predict future patient outcomes based on information collected about each patient and their treatment plans. The model should output a continuous value as its prediction. The data available includes labeled outcomes for a set of 4,000 patients. The study was conducted on a group of individuals over the age of 65 who have a particular disease that is known to worsen with age.\nInitial models have performed poorly. While reviewing the underlying data, the Data Scientist notices that, out of 4,000 patient observations, there are 450 where the patient age has been input as 0. The other features for these observations appear normal compared to the rest of the sample population\nHow should the Data Scientist correct this issue?"},{"id":"EIjDom7kyyMfty9Plvpp","choices":{"D":"MaxNumberOfTrainingJobsNotImproving","A":"MaxRuntimeInSeconds","C":"CompleteOnConvergence","B":"TargetObjectiveMetricValue"},"answer_description":"","isMC":true,"answer_ET":"C","answer_images":[],"question_id":269,"timestamp":"2024-08-31 07:17:00","question_images":[],"answers_community":["C (100%)"],"question_text":"A tourism company uses a machine learning (ML) model to make recommendations to customers. The company uses an Amazon SageMaker environment and set hyperparameter tuning completion criteria to MaxNumberOfTrainingJobs.\n\nAn ML specialist wants to change the hyperparameter tuning completion criteria. The ML specialist wants to stop tuning immediately after an internal algorithm determines that tuning job is unlikely to improve more than 1% over the objective metric from the best training job.\n\nWhich completion criteria will meet this requirement?","topic":"1","discussion":[{"upvote_count":"1","comment_id":"1400471","poster":"ef12052","timestamp":"1742380440.0","content":"Selected Answer: C\nCompleteOnConvergence – A flag to stop tuning after an internal algorithm determines that the tuning job is unlikely to improve more than 1% over the objective metric from the best training job."},{"content":"Selected Answer: C\nThe completion criteria that will meet this requirement is CompleteOnConvergence. This criterion stops the tuning job immediately after an internal algorithm determines that the tuning job is unlikely to improve more than 1% over the objective metric from the best training job","timestamp":"1727097780.0","upvote_count":"1","poster":"MultiCloudIronMan","comment_id":"1288141"},{"timestamp":"1726721880.0","upvote_count":"2","poster":"Tkhan1","content":"Selected Answer: C\nC is the correct answer .CompleteOnConvergence – A flag to stop tuning after an internal algorithm determines that the tuning job is unlikely to improve more than 1% over the objective metric from the best training job.\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-progress.html","comment_id":"1286146"},{"timestamp":"1725081420.0","comment_id":"1275382","poster":"georgejinh","content":"Selected Answer: C\nonvergence detection is a completion criteria that lets automatic model tuning decide when to stop tuning. Generally, automatic model tuning will stop tuning when it estimates that no significant improvement can be achieved.","upvote_count":"2"}],"exam_id":26,"url":"https://www.examtopics.com/discussions/amazon/view/146705-exam-aws-certified-machine-learning-specialty-topic-1/","answer":"C","unix_timestamp":1725081420},{"id":"E59ao7Lk0PGWdENrGEv7","question_images":[],"topic":"1","answers_community":["D (100%)"],"answer_description":"","unix_timestamp":1726097760,"timestamp":"2024-09-12 01:36:00","discussion":[{"upvote_count":"1","poster":"Tkhan1","timestamp":"1726722300.0","comment_id":"1286149","content":"Selected Answer: D\nD is the correct option"},{"comment_id":"1282366","timestamp":"1726097760.0","upvote_count":"1","poster":"GS_77","content":"Selected Answer: D\nse the SageMaker Data Wrangler histogram visualization to inspect the range of values for the specific feature"}],"answer":"D","exam_id":26,"url":"https://www.examtopics.com/discussions/amazon/view/147369-exam-aws-certified-machine-learning-specialty-topic-1/","question_text":"A car company has dealership locations in multiple cities. The company uses a machine learning (ML) recommendation system to market cars to its customers.\n\nAn ML engineer trained the ML recommendation model on a dataset that includes multiple attributes about each car. The dataset includes attributes such as car brand, car type, fuel efficiency, and price.\n\nThe ML engineer uses Amazon SageMaker Data Wrangler to analyze and visualize data. The ML engineer needs to identify the distribution of car prices for a specific type of car.\n\nWhich type of visualization should the ML engineer use to meet these requirements?","answer_images":[],"question_id":270,"isMC":true,"choices":{"D":"Use the SageMaker Data Wrangler histogram visualization to inspect the range of values for the specific feature.","B":"Use the SageMaker Data Wrangler quick model visualization to quickly evaluate the data and produce importance scores for the car price and type of car.","C":"Use the SageMaker Data Wrangler anomaly detection visualization to Identify outliers for the specific features.","A":"Use the SageMaker Data Wrangler scatter plot visualization to inspect the relationship between the car price and type of car."},"answer_ET":"D"}],"exam":{"name":"AWS Certified Machine Learning - Specialty","isBeta":false,"id":26,"numberOfQuestions":369,"provider":"Amazon","isImplemented":true,"isMCOnly":false,"lastUpdated":"11 Apr 2025"},"currentPage":54},"__N_SSP":true}