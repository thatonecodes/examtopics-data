{"pageProps":{"questions":[{"id":"SpN4Cg6bHgFCT9PKl37r","question_images":[],"answer_description":"","answer":"B","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/16949-exam-aws-certified-security-specialty-topic-1-question-130/","topic":"1","answer_images":[],"choices":{"D":"Block user access of the EC2 instance's metadata service using IAM policies. Remove all scripts and clear the logs after execution.","C":"Externalize the bootstrap scripts in Amazon S3 and encrypt them using AWS KMS. Remove the scripts from the instance and clear the logs after the instance is configured.","A":"Store the scripts in the AMI and encrypt the sensitive data using AWS KMS Use the instance role profile to control access to the KMS keys needed to decrypt the data.","B":"Store the sensitive data in AWS Systems Manager Parameter Store using the encrypted string parameter and assign the GetParameters permission to the EC2 instance role."},"answers_community":["B (70%)","C (30%)"],"question_id":36,"question_text":"A company uses user data scripts that contain sensitive information to bootstrap Amazon EC2 instances. A Security Engineer discovers that this sensitive information is viewable by people who should not have access to it.\nWhat is the MOST secure way to protect the sensitive information used to bootstrap the instances?","timestamp":"2020-03-18 22:25:00","exam_id":29,"answer_ET":"B","discussion":[{"upvote_count":"24","comments":[{"timestamp":"1662040020.0","upvote_count":"1","content":"Excellent answer, Removed. You will be missed.\nTo decrypt the parameter value before returning it, set the WithDecryption parameter of GetParameter to true. When you use WithDecryption, Parameter Store calls the AWS KMS Decrypt operation on your behalf to decrypt the parameter value. As a result, the GetParameter request returns the parameter with a plaintext parameter value, as shown in the following example.\n\n$ aws ssm get-parameter --name MyParameter --with-decryption\n\n{\n \"Parameter\": {\n \"Type\": \"SecureString\", \n \"Name\": \"MyParameter\", \n \"Value\": \"secret_value\"\n }\n}\nhttps://docs.aws.amazon.com/kms/latest/developerguide/services-parameter-store.html","poster":"sapien45","comment_id":"656316"}],"comment_id":"322240","content":"The answer is B , you can use: \n\naws ssm get-parameter --name MyParameter --with-decryption\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/services-parameter-store.html","timestamp":"1635284940.0","poster":"[Removed]"},{"content":"Selected Answer: B\nB is the answer.\nSSM parameter store.","upvote_count":"1","comment_id":"1149785","poster":"Raphaello","timestamp":"1707878220.0"},{"timestamp":"1681153920.0","content":"AWS Systems Manager Parameter Store can be used to encrypt sensitive data. The answer is B.","upvote_count":"1","comment_id":"866566","poster":"ITGURU51"},{"poster":"Bosch123","upvote_count":"1","content":"In Practical scenario Option 'C' is used. \nA user data script is a set of executable text provided with all necessary secret within it. Imagine a password is needed in the script and would you store that value in secret manager, retrieve it runtime, replace the value in the script.. is it not over engineering?\nJust because AWS Secret manager and KMS is available, does not mean it needs to be used anywhere.","comment_id":"680079","timestamp":"1664218740.0"},{"comment_id":"665906","poster":"bobsmith2000","timestamp":"1662881040.0","content":"For me it's C.\n\nA - never bake secrets into an Ami\nB - the encrypting key i isn't specified. If it's aws managed default key, them anyone can see the plain text from aws console of from the instance itself (did to instance role). Moreover no mentions of lot deletion.\nC - KMS adds another layer of security of who can access the data from s3 console. I'm addition all logs are deleted.\nD - red herring","upvote_count":"3"},{"upvote_count":"3","timestamp":"1662108360.0","comment_id":"657197","poster":"bobsmith2000","content":"Selected Answer: C\nWhy not C?\nWith B anyone on an EC2 instance may use aws cli to get ssm parameter.\nWith C it's not stored or accessible by anyone."},{"poster":"dcasabona","comment_id":"638290","content":"Selected Answer: B\nOption B.","upvote_count":"1","timestamp":"1658948400.0"},{"poster":"TigerInTheCloud","upvote_count":"2","timestamp":"1649872680.0","content":"Selected Answer: B\nB is a better answer than A\n\nSomeone prefers B for the reason of kms:decrypt permission. Howevefr, the default aws/ssm key policy Sid mentions \"Allow access through SSM for all principals in the account that are authorized to use SSM\" (through kms:ViaService condition).\n\nI test and confirm the ssm:GetParameters or ssm:GetParameter is enough. Be careful the difference of the two permissions :-)","comment_id":"585365"},{"timestamp":"1647368820.0","content":"Selected Answer: B\nB is the only possible answer","upvote_count":"1","poster":"ceros399","comment_id":"568583"},{"poster":"Radhaghosh","content":"B is the most close option (although kms:Decrypt is missing)","upvote_count":"1","comment_id":"531776","timestamp":"1643075640.0"},{"timestamp":"1637439660.0","upvote_count":"2","content":"Selected Answer: B\nRef: https://docs.aws.amazon.com/kms/latest/developerguide/services-parameter-store.html#parameter-store-encrypt\n\"To decrypt the parameter value before returning it, set the WithDecryption parameter of GetParameter to true. When you use WithDecryption, Parameter Store calls the AWS KMS Decrypt operation on your behalf to decrypt the parameter value. As a result, the GetParameter request returns the parameter with a plaintext parameter value\"\nExample: aws ssm get-parameter --name MyParameter --with-decryption","poster":"NivNZ","comment_id":"482816"},{"comment_id":"381245","upvote_count":"2","content":"B - this is what we do when autoscaling starts new instance","poster":"DerekKey","timestamp":"1636049880.0"},{"timestamp":"1636032780.0","content":"B for sure.","poster":"sanjaym","comment_id":"351404","upvote_count":"3"},{"content":"B is answer","comment_id":"338187","poster":"Hungdv","upvote_count":"4","timestamp":"1635811980.0"},{"timestamp":"1635503640.0","comment_id":"333544","upvote_count":"2","comments":[{"timestamp":"1636103940.0","comments":[{"timestamp":"1643075580.0","upvote_count":"1","comment_id":"531775","poster":"Radhaghosh","content":"without KMS how are you doing encrypt/decrypt?"}],"upvote_count":"4","comment_id":"390524","poster":"rhinozD","content":"No, If you don't use CMK, you don't need to have kms:decrypt in instance role.\nJust: aws ssm get-parameter --name MyParameter --with-decryption\nB is the answer."}],"poster":"gobble","content":"so we try to choose between A and B. \nfor B, 2 issues. it is called SecureString. there is no such thing called encrypted string parameter. . 2nd issue is that GetParameters permission is not enough, instance role need kms:decrypt as well. \nfor A, not good idea to store script inside AMI, hard to update. However, it is workable solution. \nI will go with A."},{"comment_id":"324008","content":"None of the options are good. If you leave encrypted data on a volume it could become possible to decrypt it with new technology in a few years. And if you let the machine use the data and then delete it, it could still be in the RAM available for any program in the machine's RAM memory.","poster":"Larsson","timestamp":"1635317820.0","upvote_count":"1"},{"comment_id":"316812","poster":"cldy","upvote_count":"1","timestamp":"1635168780.0","content":"A. \nFor B you also need kms decrypt permission."},{"content":"b for me","upvote_count":"2","timestamp":"1634987520.0","poster":"PatrykMilewski","comment_id":"253593"},{"poster":"Evgenii_Ignatev","timestamp":"1634858820.0","upvote_count":"1","comment_id":"190497","content":"Here is how you can do it - https://stackoverflow.com/a/53638555 - similar to option B but with Secrets Manager. As you can see proper solution would combine user data script accessing encrypted parameters, not echoing them on console and optionally shredding logs or masking sensitive data in logs."},{"timestamp":"1634276700.0","upvote_count":"1","comment_id":"140783","poster":"DK_M","content":"Ans : A\n\nBy default, all AWS Windows AMIs have user data execution enabled for the initial launch. You can specify that user data scripts are executed the next time the instance reboots or restarts. Alternatively, you can specify that user data scripts are executed every time the instance reboots or restarts."},{"upvote_count":"2","timestamp":"1633734540.0","comment_id":"111963","content":"B\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-securestring.html","poster":"TheEnemy"},{"content":"Answer: A\nSame as earlier question. None of the other answers explain how the instance would decrypt the sensitive data. B requires kms:decrypt, not just ssm:getparameters","comment_id":"94263","upvote_count":"2","poster":"inf","comments":[{"upvote_count":"3","comment_id":"143213","timestamp":"1634536860.0","poster":"AloraCloud","content":"You only need a kms:decrypt if it is not the default KMS key.\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-securestring.html","comments":[{"upvote_count":"1","content":"please read the article you reference above carefully. It is required encrypt and decrypt permission for both default or customer-managed key.","poster":"MichaelHoang","timestamp":"1634839680.0","comment_id":"176303"}]}],"timestamp":"1632928020.0"},{"upvote_count":"3","comments":[{"timestamp":"1633574220.0","upvote_count":"1","comment_id":"107885","content":"maybe that is also valid point","poster":"awssecuritynewbie"},{"comment_id":"328313","poster":"halfway","upvote_count":"2","timestamp":"1635375900.0","content":"AWS cli can be used without the ssm agent"}],"comment_id":"93079","content":"during bootstrap the ssm agent might not be up-and-running, which would invalidate option B? then option A makes sense","timestamp":"1632755160.0","poster":"kung07"},{"content":"B, for sure","timestamp":"1632559920.0","upvote_count":"1","poster":"gfhbox0083","comment_id":"90502"},{"poster":"Raj9","timestamp":"1632559260.0","comment_id":"66570","content":"b for me","upvote_count":"2"},{"comment_id":"66373","poster":"RaySmith","content":"B for me","upvote_count":"2","timestamp":"1632480840.0"},{"content":"I would say B makes more sense","poster":"awssecuritynewbie","timestamp":"1632298740.0","comment_id":"65783","upvote_count":"4"}],"unix_timestamp":1584566700},{"id":"d5TaiXsT6E1m2BPuarEy","timestamp":"2020-03-21 01:48:00","exam_id":29,"answer_description":"","answer_ET":"BC","answers_community":["BC (67%)","CE (17%)","AC (17%)"],"answer_images":[],"isMC":true,"question_text":"A company is building a data lake on Amazon S3. The data consists of millions of small files containing sensitive information. The Security team has the following requirements for the architecture:\n* Data must be encrypted in transit.\n* Data must be encrypted at rest.\n* The bucket must be private, but if the bucket is accidentally made public, the data must remain confidential.\nWhich combination of steps would meet the requirements? (Choose two.)","unix_timestamp":1584751680,"choices":{"A":"Enable AES-256 encryption using server-side encryption with Amazon S3-managed encryption keys (SSE-S3) on the S3 bucket.","B":"Enable default encryption with server-side encryption with AWS KMS-managed keys (SSE-KMS) on the S3 bucket.","E":"Add a bucket policy that includes a deny if a PutObject request does not include s3:x-amz-server-side-encryption: \"aws:kms\".","C":"Add a bucket policy that includes a deny if a PutObject request does not include aws:SecureTransport.","D":"Add a bucket policy with aws:SourceIp to Allow uploads and downloads from the corporate intranet only.","F":"Enable Amazon Macie to monitor and act on changes to the data lake's S3 bucket."},"url":"https://www.examtopics.com/discussions/amazon/view/17068-exam-aws-certified-security-specialty-topic-1-question-131/","answer":"BC","topic":"1","question_images":[],"discussion":[{"timestamp":"1634279040.0","comments":[{"comment_id":"369175","timestamp":"1636046340.0","poster":"Gustava6272","comments":[{"timestamp":"1642538340.0","upvote_count":"1","content":"with KMS you have more control meaning it's going to give you better protection in case of accidental exposure.","poster":"YouYouYou","comment_id":"527003"},{"upvote_count":"6","timestamp":"1670372460.0","content":"The reason why SSE-S3 is not a correct answer here is due to one of the conditions: if the bucket is accidently made public, the data should still remain protected. With SSE-S3, if bucket is made public, then the data is unencrypted for anyone trying to access it.","comment_id":"737316","poster":"Mimikabs"}],"content":"Why is SSE-S3 less better than SSE-KMS ? ie why not AC . Both will encrypt as required by the question.","upvote_count":"3"}],"poster":"JackLee1","content":"This question is in the sample question bank on AWS site. There the answer is marked as BC\nhttps://d1.awsstatic.com/training-and-certification/docs-security-spec/AWS-Certified-Security-Speciality_Sample-Questions.pdf\n\nReason from the sample question bank\n\nB, C –Bucket encryption using KMS will protect both in case disks are stolen as well as if the bucket is public. This is because the AWS KMS key would need to have privileges granted to it for users outside of AWS. HTTPS will protect data in transit.\n\nI think it should also mention for GetObject to have the aws:SecureTransport condition specified for download.\n\nhttps://aws.amazon.com/blogs/security/how-to-use-bucket-policies-and-apply-defense-in-depth-to-help-secure-your-amazon-s3-data/","comment_id":"166767","upvote_count":"33"},{"upvote_count":"6","comment_id":"79224","content":"CE, B does not force KMS encrypted objects. E does.","timestamp":"1633621680.0","comments":[{"poster":"[Removed]","comment_id":"99551","timestamp":"1633791540.0","content":"If you set default encryption on the bucket, no items can be PUT without being encrypted. If they are being PUT without any encryption headers, S3 uses the bucket's default encryption setting to encrypt the object, which satisfies the encrypt-at-rest request. Read here: https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-encryption.html","upvote_count":"4"}],"poster":"[Removed]"},{"comments":[{"content":"As a side note, usually questions with 6 options asks to choose 3 best answer out of 6.\nThis one it asks for only 2; which made me wonder what could be 3rd best answer, specially that there are 3 requirements:\n1. encryption at rest, 2. encryption in transit, 3. retain confidentiality even if the bucket was made public.\n\nThat lead me to think \"D\" could be a good 3rd best answer beside B & C.\nAllow access only from requests coming from certain IP's, even if bucket was made public, that will restrict access and conform with required confidentiality.\n--\n \"Condition\": {\n \"IpAddress\": {\n \"aws:SourceIp\": [\n \"192.0.2.0/24\"\n ]\n },\n--","poster":"Raphaello","timestamp":"1708975620.0","upvote_count":"1","comment_id":"1160021"}],"comment_id":"1150282","timestamp":"1707922260.0","content":"Selected Answer: BC\nBC are correct providing privacy, encryption at rest, and encryption in transit respectively.\n\nHowever, E is not out-right wrong. It is another technique to enforce encryption at rest with custom key.","poster":"Raphaello","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: BC\nBC are correct. Example of a guy that encrypted objects and after making public the bucket, everybody can access to the objects:\nhttps://stackoverflow.com/questions/59507962/aws-s3-object-encryption-public-accessible\nHow to enforce HTTS in transit:\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html","comment_id":"893168","poster":"matrpro","timestamp":"1683642240.0"},{"comment_id":"870496","upvote_count":"1","timestamp":"1681509060.0","content":"Answer B keeps the data at rest encrypted and confidential.\nAnswer C keeps the data in transit encrypted and confidential.","poster":"ITGURU51"},{"upvote_count":"1","poster":"Meta512","comment_id":"777271","timestamp":"1673837700.0","content":"Selected Answer: BC\nBC is correct according to JackLee1 and Mimikabs explains why SSE-S3 is invalid as well"},{"content":"Selected Answer: BC\nI think bc","upvote_count":"1","poster":"skiwili","comment_id":"769484","timestamp":"1673186220.0"},{"comment_id":"764318","poster":"boooliyooo","upvote_count":"1","content":"Selected Answer: AC\nTo meet the requirements for the data lake on Amazon S3, the security team should take the following steps:\n\n A. Enable AES-256 encryption using server-side encryption with Amazon S3-managed encryption keys (SSE-S3) on the S3 bucket. This will ensure that the data is encrypted at rest, using a strong encryption algorithm.\n\n C. Add a bucket policy that includes a deny if a PutObject request does not include aws:SecureTransport. This will ensure that the data is encrypted in transit, as aws:SecureTransport is a condition key that checks whether the request is being made using a secure transport (HTTPS). By including a deny statement in the bucket policy, any PutObject requests that are not made using a secure transport will be denied.\n\nOption E, adding a bucket policy that includes a deny if a PutObject request does not include s3:x-amz-server-side-encryption: \"aws:kms\", would not meet the requirement to encrypt the data in transit. This condition only checks for the use of server-side encryption with AWS KMS-managed keys (SSE-KMS) for the PutObject request, and does not ensure that the data is encrypted in transit.","timestamp":"1672734000.0"},{"timestamp":"1672164060.0","upvote_count":"1","poster":"Fyssy","comment_id":"758888","content":"Selected Answer: CE\nEC. The datalake upload will must likely be done via CLI so add a bucket policy that includes a deny if a PutObject request does not include s3:x-amz-server-side-encryption: \"aws:kms\"."},{"comment_id":"719695","timestamp":"1668605940.0","upvote_count":"1","poster":"Laziiie","content":"Why A,C cant be answer?"},{"poster":"sanjaym","content":"BC for sure.","upvote_count":"1","comment_id":"352115","timestamp":"1635398700.0"},{"content":"B C sorry for the last post in Q24, BC it is. The right answer can be also seen in https://d1.awsstatic.com/training-and-certification/docs-security-spec/AWS-Certified-Security-Speciality_Sample-Questions.pdf","upvote_count":"1","poster":"Mike_1","comment_id":"212119","timestamp":"1634862420.0"},{"upvote_count":"3","poster":"rdy4u","content":"B - Protect if the bucket is made public\nC - Encryption at transit.\nE - Encryption at rest\n\nDuplicated questions with New Q24","timestamp":"1633902240.0","comment_id":"130152"},{"content":"B, C for sure","poster":"gfhbox0083","comment_id":"90505","upvote_count":"1","timestamp":"1633765920.0"},{"content":"B + C for sure","comment_id":"79961","timestamp":"1633707660.0","poster":"ADVIT","upvote_count":"1"},{"upvote_count":"1","poster":"Buggie","timestamp":"1633170000.0","comments":[{"content":"question is \"combination of steps\" A does not make sense if you select b\ncorrect answer is bc","comment_id":"76477","timestamp":"1633235040.0","upvote_count":"1","poster":"xaccan"}],"comment_id":"76030","content":"AB for me. see no issues with s3 encryption."},{"content":"bc for sure","comment_id":"66573","timestamp":"1632460080.0","poster":"Raj9","upvote_count":"1"},{"content":"BC to me","comment_id":"66375","poster":"RaySmith","timestamp":"1632209880.0","upvote_count":"1"}],"question_id":37},{"id":"BoKdfENBvnsqQyvb1l8U","isMC":true,"answer_images":[],"exam_id":29,"question_text":"A Security Engineer discovered a vulnerability in an application running on Amazon ECS. The vulnerability allowed attackers to install malicious code. Analysis of the code shows it exfiltrates data on port 5353 in batches at random time intervals.\nWhile the code of the containers is being patched, how can Engineers quickly identify all compromised hosts and stop the egress of data on port 5353?","unix_timestamp":1584567960,"question_id":38,"answer_description":"","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/16951-exam-aws-certified-security-specialty-topic-1-question-132/","answer_ET":"C","topic":"1","discussion":[{"content":"Correct VPC flowlogs will help you to detect the network traffic in VPC and NACL outbound to block traffic","poster":"awssecuritynewbie","upvote_count":"18","comment_id":"65792","timestamp":"1632221640.0"},{"content":"C for me","comment_id":"253594","upvote_count":"10","timestamp":"1633586460.0","poster":"PatrykMilewski"},{"poster":"Raphaello","content":"Selected Answer: C\nC is the right answer.","timestamp":"1707922380.0","upvote_count":"1","comment_id":"1150283"},{"comment_id":"866586","upvote_count":"1","content":"The VPC flow logs can be used to identify the C2 traffic which is using port 5353.","timestamp":"1681155180.0","poster":"ITGURU51"},{"timestamp":"1670609880.0","poster":"[Removed]","upvote_count":"1","content":"To quickly identify all compromised hosts and stop the egress of data on port 5353, the following steps can be taken:\n\nCreate an Amazon CloudWatch custom metric on the VPC Flow Logs identifying egress traffic on port 5353. This will allow you to monitor and identify any hosts that are exfiltrating data on port 5353.\nUpdate the NACLs to block port 5353 outbound. This will prevent any further exfiltration of data on port 5353.\nOption C is the best solution because it allows you to quickly identify the compromised hosts and stop the egress of data on port 5353 using VPC Flow Logs and NACLs.","comment_id":"740342"},{"content":"Selected Answer: C\nIt it VPCFlow Logs and not CloudTrail that contains port information. and Inspector is not supported on ECS","comment_id":"656348","timestamp":"1662041940.0","poster":"sapien45","upvote_count":"1"},{"timestamp":"1659606360.0","content":"Selected Answer: C\nC and Not B , because in network reachability package of inspector does not support ECR https://docs.aws.amazon.com/inspector/latest/user/findings-types.html. Thanks Hariru for the nudge in the right direction","upvote_count":"4","comment_id":"642296","poster":"Rja148393"},{"upvote_count":"4","timestamp":"1645890240.0","content":"why not B ? inspector is good service to dectect vulnerability ?","poster":"lotfi50","comment_id":"556747"},{"comment_id":"534268","poster":"Radhaghosh","upvote_count":"1","content":"C is the correct answer","timestamp":"1643335380.0"},{"upvote_count":"2","content":"Selected Answer: C\nIts C because:\nD is saying Cloudtrail, which doesnt have any port information. Additionally SG cant block.\nB says inspector which is for EC2\nA says total nonsense.","timestamp":"1637431920.0","comment_id":"482763","poster":"Hariru"},{"upvote_count":"2","poster":"kiev","content":"C for me as well.","timestamp":"1635827940.0","comment_id":"437628"},{"timestamp":"1633557600.0","comments":[{"poster":"Ghostbusters","content":"The reason why D is incorrect is: CloudTrail will not have any such logs. CloudTrail houses logs on API calls, not traffic to a certain port (when you think of traffic, think access logs or flow logs).\nThe reason why C is correct is: (a) VPC Flow Logs is the right log to use here and (b) VPC Flow Logs can be sent to CloudWatch (it can also be sent to S3, but this question tests the knowledge of its integration with CW)","upvote_count":"21","comments":[{"content":"your replies are very well formed. thank you.","comment_id":"285340","timestamp":"1635651420.0","poster":"cross","upvote_count":"2"}],"timestamp":"1635140820.0","comment_id":"254754"}],"poster":"Melymel","comment_id":"250158","content":"it's D. The question is talking about ECS not a VPC","upvote_count":"1"},{"poster":"gfhbox0083","timestamp":"1632999360.0","comment_id":"90507","content":"C, for sure.","upvote_count":"1"},{"comment_id":"77576","timestamp":"1632755220.0","poster":"xaccan","upvote_count":"1","content":"c is correct"},{"comment_id":"66376","poster":"RaySmith","timestamp":"1632614340.0","content":"C to me","upvote_count":"1"}],"choices":{"B":"Enable Amazon Inspector on Amazon ECS and configure a custom assessment to evaluate containers that have port 5353 open. Update the NACLs to block port 5353 outbound.","D":"Use Amazon Athena to query AWS CloudTrail logs in Amazon S3 and look for any traffic on port 5353. Update the security groups to block port 5353 outbound.","A":"Enable AWS Shield Advanced and AWS WAF. Configure an AWS WAF custom filter for egress traffic on port 5353","C":"Create an Amazon CloudWatch custom metric on the VPC Flow Logs identifying egress traffic on port 5353. Update the NACLs to block port 5353 outbound."},"timestamp":"2020-03-18 22:46:00","question_images":[],"answer":"C"},{"id":"HBTWmhTGmnBLHM4jQRkp","choices":{"C":"The kms:Encrypt permission is missing from the EC2 IAM role","A":"The kms:GenerateDataKey permission is missing from the EC2 instance's IAM role","D":"The KMS CMK key policy that enables IAM user permissions is missing","B":"The ARN tag on the CMK contains the EC2 instance's ID instead of the instance's ARN"},"answers_community":["D (67%)","A (33%)"],"timestamp":"2020-03-21 02:00:00","unix_timestamp":1584752400,"url":"https://www.examtopics.com/discussions/amazon/view/17070-exam-aws-certified-security-specialty-topic-1-question-133/","question_text":"An Amazon EC2 instance is denied access to a newly created AWS KMS CMK used for decrypt actions. The environment has the following configuration:\n✑ The instance is allowed the kms:Decrypt action in its IAM role for all resources\n✑ The AWS KMS CMK status is set to enabled\n✑ The instance can communicate with the KMS API using a configured VPC endpoint\nWhat is causing the issue?","answer_description":"","question_id":39,"question_images":[],"exam_id":29,"answer_images":[],"answer":"D","topic":"1","answer_ET":"D","isMC":true,"discussion":[{"poster":"RaySmith","upvote_count":"11","content":"D seems corr","timestamp":"1632887460.0","comment_id":"66378"},{"content":"I believe D is wrong.\nBut guys, I would go for D, the problem is the question. It's stating \"EC2 Instance\" and this should be IAM Role and option D is wrong IMHO because of this, this is NOT IAM user.","comment_id":"191543","timestamp":"1633891800.0","comments":[{"timestamp":"1633966200.0","poster":"Ayusef","upvote_count":"2","content":"I agree with you. The wording was correct until it said user.","comment_id":"217421"}],"poster":"DanMuniz","upvote_count":"6"},{"comment_id":"1150286","poster":"Raphaello","upvote_count":"1","timestamp":"1707922560.0","content":"Selected Answer: D\nD\nThe KMS default key policy (uppermost part of the policy) that delegates permissions to IAM identity policies, is missing."},{"timestamp":"1687639380.0","upvote_count":"1","poster":"rajkanch","comment_id":"932916","content":"A - > https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-key-management.html#sqs-what-permissions-for-sse"},{"timestamp":"1685395980.0","poster":"ITGURU51","content":"The best answer is D because the EC2 instance needs permissions to use the newly created key.","upvote_count":"1","comment_id":"909731"},{"poster":"Dmosh","content":"Selected Answer: D\nNot A, we are not speaking of encryption.","comment_id":"879491","timestamp":"1682349840.0","upvote_count":"1"},{"timestamp":"1672734420.0","upvote_count":"2","poster":"boooliyooo","comment_id":"764322","content":"Selected Answer: D\nOption A, the kms:GenerateDataKey permission being missing from the EC2 instance's IAM role, would not cause the issue, as the kms:Decrypt action is allowed for all resources in the role."},{"timestamp":"1670610300.0","upvote_count":"1","content":"The issue is caused by the fact that the KMS CMK key policy that enables IAM user permissions is missing. In order for the Amazon EC2 instance to have access to the AWS KMS CMK and be able to perform decrypt actions, the KMS CMK key policy must be configured to grant the necessary permissions to the EC2 instance's IAM role.\n\nIn order to fix the issue, the Security team can update the KMS CMK key policy to grant the EC2 instance's IAM role the necessary permissions for decrypt actions. This will allow the EC2 instance to access the KMS CMK and perform decrypt actions as needed.","poster":"[Removed]","comment_id":"740345"},{"comment_id":"732080","upvote_count":"2","poster":"AshishFL","content":"The key is 'Newly Created'. The key policy by default has the IAM user permissions. So D is wrong. GenerateDataKey permission is required to decrypt using the key. A is the right answer. If the key was not 'new' and someone changed the default key policy to remove the account root permission required to manage IAM permissions, then D may have been viable option.","comments":[{"timestamp":"1683643080.0","content":"Hello, I see what you mean but if the ec2 can access other older CMK keys it is because it has already allowed the GenerateDataKey. It is another tricky AWS' question with 2 feasible valid options. I am going to think that this ec2 instance es the 1st time that is using KMS and that the new CMK does not have root as a principal to allow IAM to manage the permissions. C would be my choice.","upvote_count":"1","comment_id":"893177","poster":"matrpro"}],"timestamp":"1669849980.0"},{"content":"Selected Answer: D\nkey policy should allow root user in order for IAM policies to work","poster":"jAWStest","comment_id":"719151","upvote_count":"1","timestamp":"1668548400.0"},{"content":"Selected Answer: A\nhttps://stackoverflow.com/questions/66543870/aws-kms-why-do-i-need-the-kmsdecrypt-permission-when-i-try-to-encrypt-data","timestamp":"1668354780.0","upvote_count":"3","poster":"Fyssy","comment_id":"717408"},{"poster":"VijiTu","comment_id":"663338","upvote_count":"1","content":"Answer D - Unless the key policy explicitly allows it, you cannot use IAM policies to allow access to a KMS key. Without permission from the key policy, IAM policies that allow permissions have no effect.","timestamp":"1662623760.0"},{"upvote_count":"1","comment_id":"659349","poster":"sapien45","comments":[{"comment_id":"909732","upvote_count":"1","content":"Key policies are the primary way to control access to KMS keys. Every KMS key must have exactly one key policy. The statements in the key policy determine who has permission to use the KMS key and how they can use it.","poster":"ITGURU51","timestamp":"1685396220.0"}],"content":"Selected Answer: D\nThat is right. you could use IAM policies (EC2 instances roles for example) only if KMS policies allow you to do so.","timestamp":"1662303480.0"},{"upvote_count":"1","content":"After some researchs go for D https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html","poster":"teo2157","timestamp":"1650380220.0","comment_id":"588245"},{"timestamp":"1636293780.0","upvote_count":"5","content":"D is correct\n\nAlthough I want to see \"IAM role\" instead of \"IAM user\", but ok with it since \"IAM user\" is a legit principle\n\nA is not correct because GenerateDataKey is needed for envelope encryption. In this question, it is about using CMK, so data key is irrelevant","poster":"chengxu32","comment_id":"331402"},{"timestamp":"1636115280.0","upvote_count":"3","poster":"Huy","content":"Every CMK must have exactly one key policy. The statements in the key policy document determine who has permission to use the CMK and how they can use it.\nKey users = IAM users + IAM Roles\nSo D is correct.","comment_id":"323960"},{"upvote_count":"1","content":"D. Correct","comment_id":"316815","timestamp":"1635525540.0","poster":"cldy"},{"timestamp":"1633777260.0","upvote_count":"1","content":"D, for sure","poster":"gfhbox0083","comment_id":"90509"},{"poster":"xaccan","comment_id":"77577","content":"D is mostly correct","timestamp":"1633417560.0","upvote_count":"2"},{"upvote_count":"1","content":"I agree with Ray, it is D, \n\nYou need to have the CMK key policy granting you access to use that key!","timestamp":"1632931140.0","comment_id":"74619","poster":"awssecuritynewbie"}]},{"id":"KYzvvJEtgK269VoXz5pT","answer_description":"","answer":"C","answer_images":[],"choices":{"D":"Create an AWS Lambda function that closes the finding whenever a new occurrence is reported","A":"Disable the FTP rule in GuardDuty in the Region where the FTP server is deployed","C":"Use GuardDuty filters with auto archiving enabled to close the findings","B":"Add the FTP server to a trusted IP list and deploy it to GuardDuty to stop receiving the notifications"},"timestamp":"2020-03-21 02:01:00","question_images":[],"answers_community":["C (100%)"],"topic":"1","discussion":[{"comment_id":"254764","comments":[{"timestamp":"1641475020.0","comment_id":"518241","upvote_count":"1","content":"really good approach to tackle this question","poster":"f4bi4n"},{"timestamp":"1658590260.0","content":"correct. Have my upvote, good sir.","upvote_count":"2","comment_id":"635673","poster":"z0mb133"},{"timestamp":"1637227800.0","content":"I agree to this and one more point to add FTP is insecure protocol and attackers definitely try to exploit vulnerable protocols. So we cant whitelist FTP . It must be C","comment_id":"480558","upvote_count":"3","poster":"munish3420"},{"content":"Made my switch my answer from B to C","comment_id":"656371","upvote_count":"3","poster":"sapien45","timestamp":"1662043500.0"}],"content":"For those who pointed out B as the answer: Do not think in terms of \"can Guard Duty do it this way?\" Instead, think: \"should this be done?\" Because if you ask the 1st q, answer is \"yes, GD supports IP whitelisting\" and you will be tempted to think B is the answer. If you ask the 2nd q, you will see that doing this will make it impossible to actually identify a real attack on this FTP server. The question warns you against this by saying \"changes should not impact visibility of malicious attacks\". This question is very typical type where the question designer first thinks of a feature (in this case auto-archiving from filters) and then tries to come up with a question to test that. It reeks of that (well intended but intrinsically flawed) approach","poster":"Ghostbusters","timestamp":"1635541200.0","upvote_count":"45"},{"timestamp":"1635618480.0","content":"C.\n\"When you create an Amazon GuardDuty filter, you choose specific filter criteria, name the filter and can enable the auto-archiving of findings that the filter matches. This allows you to further tune GuardDuty to your unique environment, without degrading the ability to identify threats. With auto-archive set, all findings are still generated by GuardDuty, so you have a complete and immutable history of all suspicious activity.\"","upvote_count":"17","comments":[{"content":"suppression rules - threats you dont intend on acting on\nhttps://docs.aws.amazon.com/guardduty/latest/ug/findings_suppression-rule.html","upvote_count":"2","poster":"AnonymousJhb","timestamp":"1645445400.0","comment_id":"552830"}],"poster":"mvsnogueira","comment_id":"256055"},{"comment_id":"1150289","timestamp":"1707922680.0","poster":"Raphaello","upvote_count":"2","content":"Selected Answer: C\nC\nUse suppression rule (auto archive) will prevent the finding to show up among the active findings, or populated to SH."},{"upvote_count":"2","content":"If you are receiving findings for expected behavior in your environment, you can automatically archive findings based on criteria you define with suppression rules. Suppression rules are rules which automatically send matched findings to archive. Answer C","comment_id":"871664","timestamp":"1681641840.0","poster":"ITGURU51"},{"poster":"[Removed]","upvote_count":"1","content":"To address the issue of the false positive findings being raised by Amazon GuardDuty, the Security Engineer can use GuardDuty filters with auto archiving enabled to close the findings. This will stop GuardDuty from raising the issue and improve the signal-to-noise ratio.\n\nTo implement this solution, the Engineer will need to create a filter in GuardDuty that targets the FTP server and any related findings. The filter should be configured to automatically archive the findings when they are reported, so that they are no longer raised as an issue. This will prevent the false positive findings from being raised and improve the overall visibility of potential anomalous behavior.","comment_id":"740377","timestamp":"1670613300.0"},{"comment_id":"547884","upvote_count":"3","content":"Selected Answer: C\nI Believe C is the answer, many people here mentioned good reasons for it.\nyou don't want to NOT get the alert at all, you just want to be able to view it later since you know its on by \"default\",\nyou can put it in an archive and maybe create a rule to specify that if the connections per hour is lets say 150% of the last 48 hours, raise an alert","timestamp":"1644943740.0","poster":"MoreOps"},{"poster":"Radhaghosh","timestamp":"1643161140.0","content":"\"The Engineer must verify that modifications do not impair the visibility of potentially unusual activity\" --> This line changes the entire approach. Solution mentioned in B will hide any potential positive attack, That is why Answer should be C","upvote_count":"1","comment_id":"532538"},{"comment_id":"486432","timestamp":"1637813880.0","content":"C\nhttps://aws.amazon.com/about-aws/whats-new/2018/05/amazon-guardduty-adds-capability-to-automatically-archive-findings1/","upvote_count":"2","poster":"Cloudvin"},{"timestamp":"1636165740.0","upvote_count":"5","poster":"khos77","comments":[{"comment_id":"730826","upvote_count":"1","content":"Great solution, I don't know what's worse, to not to be notified or to not act on the alert. One way or another it's bad pattern.","poster":"hubekpeter","timestamp":"1669753500.0"}],"comment_id":"273934","content":"I completely agree with ghostbusters comments. You don't want to eliminate the alerts only suppress them. This automatically sends the matched items to archive yet still generates the findings. Just doesn't generate a cloudwatch event... So C hands down is the answer."},{"poster":"deegadaze1","content":"B is the correct Answer:-Trusted IP lists consist of IP addresses that you have trusted for secure communication with your AWS infrastructure and applications. GuardDuty does not generate VPC Flow Log or CloudTrail findings for IP addresses on trusted IP lists. At any given time, you can have only one uploaded trusted IP list per AWS account per Region.\n\nThreat lists consist of known malicious IP addresses. GuardDuty generates findings based on threat lists. At any given time, you can have up to six uploaded threat lists per AWS account per Region.","comment_id":"186440","upvote_count":"2","timestamp":"1635447540.0"},{"comment_id":"133370","poster":"Michael679","content":"C - Archiving findings could improve the signal-to-noise ratio, but still monitor anomalous behavior.","upvote_count":"3","timestamp":"1635159900.0"},{"upvote_count":"5","poster":"Tron09","comment_id":"122355","content":"It can't be \"B\". Trusted IP list is a list of source IPs. We cannot add the FTP server's IP to that list, doesn't make sense. \n\"C\" is the answer.","timestamp":"1634947800.0"},{"content":"answer is C.","poster":"RajeshNayyar","timestamp":"1634731200.0","upvote_count":"1","comment_id":"102630"},{"timestamp":"1634503980.0","poster":"inf","comment_id":"94265","content":"Answer: C\n\nCan't be B \nIf you add the server to a whitelist, then it invalidates this statement: \"The Engineer needs to ensure that changes do not compromise the visibility of potential anomalous behavior\"\nNeed to make sure the FTP server is still being monitored for other malicious activity","upvote_count":"3"},{"comments":[{"comment_id":"99553","upvote_count":"3","timestamp":"1634718360.0","poster":"[Removed]","content":"I disagree, please read the statement in the question \"The Engineer needs to ensure that changes do not compromise the visibility of potential anomalous behavior.\" ... If you set the IP as trusted, GuardDuty will stop notifying you for any potential anomalous behavior, not just for the use case specified in the question. Answer is C."}],"timestamp":"1634342220.0","poster":"richasskikr","upvote_count":"1","content":"I agree with B.\n\nWith auto-archive rules, GuardDuty still generates all findings. Suppression rules provide\nsuppression of findings while maintaining a complete and immutable history of all activity.\nGuardDuty does not generate findings based on trusted IP lists.\n\nhttps://docs.aws.amazon.com/guardduty/latest/ug/guardduty-ug.pdf","comment_id":"93940"},{"content":"Answer: C\nUse a filter, filter on the specific event for that FTP server, then auto-archive\nAbsolutely not B - if added as a trusted IP, what happens when an actual attack happens? No notifications.","comment_id":"92840","timestamp":"1634265060.0","upvote_count":"2","poster":"inf"},{"poster":"mychiv","comment_id":"90760","comments":[{"timestamp":"1635525600.0","comment_id":"237791","upvote_count":"1","content":"Per the reference provided by @mychiv\n\"Amazon GuardDuty now allows you to setup automatic archiving when creating a findings filter. This is useful when you have a unique use case in your environment that generates many similar findings, or in situations where you have reviewed a certain class of findings and don’t want to be alerted again.\"","poster":"ucsdmiami2020"}],"timestamp":"1634159220.0","upvote_count":"2","content":"C\nhttps://aws.amazon.com/about-aws/whats-new/2018/05/amazon-guardduty-adds-capability-to-automatically-archive-findings1/"},{"content":"Same question 27, Page 34.\nAnswer is C, in my opinion, \nAmazon GuardDuty now allows you to setup automatic archiving when creating a findings filter. This is useful when you have a unique use case in your environment","upvote_count":"2","comment_id":"89513","timestamp":"1633894260.0","poster":"gfhbox0083"},{"timestamp":"1633680120.0","content":"isn't it A ?","upvote_count":"1","comments":[{"timestamp":"1635210300.0","content":"No. You can't control rules in Guard Duty, your choices are it's turned on or it's turned off.","upvote_count":"1","poster":"freddyman","comment_id":"174208"}],"poster":"patand","comment_id":"80185"},{"timestamp":"1632807180.0","upvote_count":"1","poster":"xaccan","comment_id":"77578","content":"B is the right choice"},{"comment_id":"66575","upvote_count":"2","poster":"Raj9","comments":[{"content":"Nope, it's C. Adding the FTP server's IP is meaningless. You'd need to add all of the calling IPs which makes no sense.","comments":[{"upvote_count":"1","content":"ans is C 100%","comment_id":"79681","poster":"Henrydred","timestamp":"1633442520.0"}],"poster":"lolcats","timestamp":"1633188780.0","comment_id":"77882","upvote_count":"7"}],"content":"b - trusted ip","timestamp":"1632591480.0"},{"comment_id":"66379","content":"B for me","timestamp":"1632404520.0","poster":"RaySmith","upvote_count":"4"}],"question_text":"A company has enabled Amazon GuardDuty in all Regions as part of its security monitoring strategy. In one of the VPCs, the company hosts an Amazon EC2 instance working as an FTP server that is contacted by a high number of clients from multiple locations. This is identified by GuardDuty as a brute force attack due to the high number of connections that happen every hour.\nThe finding has been flagged as a false positive. However, GuardDuty keeps raising the issue. A Security Engineer has been asked to improve the signal-to-noise ratio. The Engineer needs to ensure that changes do not compromise the visibility of potential anomalous behavior.\nHow can the Security Engineer address the issue?","question_id":40,"unix_timestamp":1584752460,"isMC":true,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/17071-exam-aws-certified-security-specialty-topic-1-question-134/","exam_id":29}],"exam":{"isMCOnly":false,"id":29,"numberOfQuestions":509,"name":"AWS Certified Security - Specialty","isBeta":false,"provider":"Amazon","lastUpdated":"11 Apr 2025","isImplemented":true},"currentPage":8},"__N_SSP":true}