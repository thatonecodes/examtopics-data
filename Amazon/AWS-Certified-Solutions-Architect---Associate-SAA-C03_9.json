{"pageProps":{"questions":[{"id":"vppuEcUp1tyuUa2tEPFD","answer_images":[],"isMC":true,"question_text":"A company stores its application logs in an Amazon CloudWatch Logs log group. A new policy requires the company to store all application logs in Amazon OpenSearch Service (Amazon Elasticsearch Service) in near-real time.\nWhich solution will meet this requirement with the LEAST operational overhead?","topic":"1","answer":"A","question_images":[],"answers_community":["A (67%)","C (31%)","2%"],"question_id":41,"url":"https://www.examtopics.com/discussions/amazon/view/85802-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"comments":[{"upvote_count":"1","comment_id":"1358774","content":"Thank you for the link - clear answer","timestamp":"1739972640.0","poster":"Vandaman"},{"timestamp":"1716822360.0","poster":"lofzee","upvote_count":"2","content":"good enough for me","comment_id":"1219636"},{"timestamp":"1672666320.0","poster":"HayLLlHuK","upvote_count":"1","comment_id":"763744","content":"Zerotn3 is right! There should be a Lambda for writing into ES"},{"comment_id":"705585","upvote_count":"5","poster":"UWSFish","content":"Great link. Convinced me","timestamp":"1666876860.0"},{"comment_id":"762590","poster":"Zerotn3","content":"Option A (Configure a CloudWatch Logs subscription to stream the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service)) is not a suitable option, as a CloudWatch Logs subscription is designed to send log events to a destination such as an Amazon Simple Notification Service (Amazon SNS) topic or an AWS Lambda function. It is not designed to write logs directly to Amazon Elasticsearch Service (Amazon ES).","comments":[{"content":"that is not true, you can stream logs from CloudWatch Logs directly to OpenSearch","poster":"kucyk","upvote_count":"7","comment_id":"808522","timestamp":"1676388660.0"}],"upvote_count":"4","timestamp":"1672480380.0"}],"comment_id":"704843","content":"Selected Answer: A\nanswer is A\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html\n\n> You can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in NEAR REAL-TIME through a CloudWatch Logs subscription\n\nleast overhead compared to kinesis","upvote_count":"99","poster":"Six_Fingered_Jose","timestamp":"1666799760.0"},{"comment_id":"752876","poster":"Buruguduystunstugudunstuy","timestamp":"1671666420.0","content":"Selected Answer: C\nThe correct answer is C: Create an Amazon Kinesis Data Firehose delivery stream. Configure the log group as the delivery stream source. Configure Amazon OpenSearch Service (Amazon Elasticsearch Service) as the delivery stream's destination.\n\nThis solution uses Amazon Kinesis Data Firehose, which is a fully managed service for streaming data to Amazon OpenSearch Service (Amazon Elasticsearch Service) and other destinations. You can configure the log group as the source of the delivery stream and Amazon OpenSearch Service as the destination. This solution requires minimal operational overhead, as Kinesis Data Firehose automatically scales and handles data delivery, transformation, and indexing.","comments":[{"poster":"Buruguduystunstugudunstuy","comments":[{"timestamp":"1674989520.0","content":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","poster":"ocbn3wby","comment_id":"791561","upvote_count":"2"}],"comment_id":"752878","content":"Option A: Configure a CloudWatch Logs subscription to stream the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service) would also work, but it may require more operational overhead as you would need to set up and manage the subscription and ensure that the logs are delivered in near-real time.\n\nOption B: Create an AWS Lambda function. Use the log group to invoke the function to write the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service) would also work, but it may require more operational overhead as you would need to set up and manage the Lambda function and ensure that it scales to handle the incoming logs.\n\nOption D: Install and configure Amazon Kinesis Agent on each application server to deliver the logs to Amazon Kinesis Data Streams. Configure Kinesis Data Streams to deliver the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service) would also work, but it may require more operational overhead as you would need to install and configure the Kinesis Agent on each application server and set up and manage the Kinesis Data Streams.","upvote_count":"3","timestamp":"1671666420.0"},{"content":"ANSWER A\nhttps://docs.aws.amazon.com/opensearch-service/latest/developerguide/integrations.html\nYou can use CloudWatch or Kinesis, but in the Kinesis description it never says real time, however in the Cloudwatch description it does say Real time \"\"You can load streaming data from CloudWatch Logs to your OpenSearch Service domain by using a CloudWatch Logs subscription . For information about Amazon CloudWatch subscriptions, see Real-time processing of log data with subscriptions.\"\"","poster":"Lalo","upvote_count":"4","comment_id":"919673","timestamp":"1686353460.0"}],"upvote_count":"19"},{"comment_id":"1330610","upvote_count":"1","timestamp":"1734907620.0","content":"Selected Answer: D\nIn summary, the CloudWatch Logs → Kinesis Data Firehose → Amazon OpenSearch Service (option C) integration is the path recommended by AWS for this type of case. It allows for near real-time transmission, automatic scaling and relatively simple configuration, with the lowest operational overhead .","poster":"Mischi"},{"upvote_count":"2","comment_id":"1315971","content":"Selected Answer: A\nCloudWatch Logs subscription filter: This is the most straightforward way to stream logs from a CloudWatch Logs group to Amazon OpenSearch Service (Amazon Elasticsearch Service) in near real-time. It eliminates the need for additional components or complex configurations, reducing operational overhead.\nDirect integration: CloudWatch Logs can directly stream logs to OpenSearch Service without requiring intermediate services, making it a simple and efficient solution.\nLow operational overhead: Once set up, the subscription filter automatically forwards logs to OpenSearch Service with minimal maintenance.","timestamp":"1732216560.0","poster":"0de7d1b"},{"poster":"ChymKuBoy","upvote_count":"2","comment_id":"1299525","timestamp":"1729221720.0","content":"Selected Answer: C\nC for sure\nSimplicity: Kinesis Data Firehose is a managed service that handles the task of capturing, transforming, and loading data into destinations like Amazon OpenSearch Service. This eliminates the need for complex configuration and management.\nScalability: Kinesis Data Firehose can automatically scale to handle varying data volumes, ensuring that logs are ingested in near-real time.\nCost-effectiveness: Kinesis Data Firehose is a pay-as-you-go service, making it a cost-effective option for log ingestion and analysis."},{"upvote_count":"3","comment_id":"1288321","content":"Selected Answer: C\nI think C is correct because the cloud watch subscription can't stream directly to OpenSearch, it is via Lambda, SNS, FireHouse,....","timestamp":"1727128020.0","poster":"tonybuivannghia"},{"comment_id":"1287675","poster":"Tieri","timestamp":"1727004600.0","upvote_count":"1","content":"You can configure a log group in Amazon CloudWatch Logs, so you can stream data to your Amazon OpenSearch Service cluster in near real-time."},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","upvote_count":"2","comment_id":"1276105","timestamp":"1725199500.0","poster":"Johnoppong101"},{"upvote_count":"1","timestamp":"1722306660.0","comment_id":"1257783","poster":"KTEgghead","content":"Selected Answer: A\nConfigure a CloudWatch Logs log group to stream data directly to the Amazon OpenSearch Service cluster. This can be done through a CloudWatch Logs subscription, which allows for real-time processing of log data."},{"poster":"jaradat02","upvote_count":"1","timestamp":"1721683200.0","comment_id":"1253292","content":"Selected Answer: A\nA is the correct answer, CloudWatch offers a subscription where you can stream data to other AWS services"},{"content":"Selected Answer: C\nCorrect Answer:\nC. Create an Amazon Kinesis Data Firehose delivery stream. Configure the log group as the delivery stream's source. Configure Amazon OpenSearch Service (Amazon Elasticsearch Service) as the delivery stream's destination.\n\nExplanation:\nAmazon Kinesis Data Firehose is a fully managed service for delivering real-time streaming data to destinations such as Amazon OpenSearch Service. It requires minimal setup and management, making it a low-overhead solution.\nBy configuring the log group as the source for the Kinesis Data Firehose delivery stream and Amazon OpenSearch Service as the destination, logs can be delivered in near-real time with built-in reliability and scalability.","timestamp":"1720867020.0","poster":"Seb888","comment_id":"1247259","upvote_count":"2"},{"timestamp":"1720066020.0","upvote_count":"1","poster":"jatric","comment_id":"1241802","content":"Selected Answer: A\neasy enough to figure out. Option A"},{"upvote_count":"1","comment_id":"1233578","content":"Selected Answer: A\nA for sure","poster":"ChymKuBoy","timestamp":"1718880420.0"},{"comment_id":"1205101","poster":"824c449","upvote_count":"1","content":"Selected Answer: C\nIt can natively connect to CloudWatch Logs as a source and OpenSearch Service as a destination, handling the delivery of logs efficiently and with minimal setup. This approach offers the least operational overhead by simplifying the data transfer pipeline with automatic scaling and error handling.","timestamp":"1714569060.0"},{"comment_id":"1199076","poster":"zinabu","content":"Selected Answer: A\nYou can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in near real-time through a CloudWatch Logs subscription.\n\nhere is the link/; https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","upvote_count":"1","timestamp":"1713607740.0"},{"upvote_count":"1","timestamp":"1712060460.0","content":"Selected Answer: A\nAnswer A.\nThis doc clarifies the subject: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","comment_id":"1188029","poster":"OctavioBatera"},{"comment_id":"1164108","poster":"CloudLearner01","content":"A is correct \nYou can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in near real-time through a CloudWatch Logs subscription.\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","timestamp":"1709382360.0","upvote_count":"1"},{"timestamp":"1708072200.0","upvote_count":"1","comment_id":"1151828","content":"Selected Answer: A\nYou can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in near real-time through a CloudWatch Logs subscription. This is the solution that requires the least operational overhead.\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","poster":"vip2"},{"timestamp":"1707312900.0","upvote_count":"1","poster":"eyob911","content":"A,\nYou can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in near real-time through a CloudWatch Logs subscription","comment_id":"1143345"},{"timestamp":"1706199180.0","upvote_count":"2","content":"Selected Answer: C\nAmazon Kinesis Data Firehose can automatically deliver logs from CloudWatch Logs to Amazon OpenSearch Service without requiring you to manage and configure additional components or write custom code. It simplifies the process and reduces operational overhead","poster":"Varun_SP","comment_id":"1131840"},{"comments":[{"content":"Arratum: Obviously option A according to my wording","timestamp":"1717129680.0","comment_id":"1221937","upvote_count":"1","poster":"bujuman"}],"upvote_count":"2","comment_id":"1117556","content":"Selected Answer: C\nFollowing these key words:\n- near-real time.\n- LEAST operational overhead and the fact that CloudWatch loggroup support OpenSearch Service subscription filter","timestamp":"1704810000.0","poster":"bujuman"},{"content":"Selected Answer: A\nSince the scenario perfectly fits this description: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","comment_id":"1105749","upvote_count":"3","timestamp":"1703571300.0","poster":"pentium75"},{"upvote_count":"1","content":"Selected Answer: A\nThe solution that will meet the requirement with the least operational overhead is:\n\n**Option A**: Configure a CloudWatch Logs subscription to stream the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service).\n\nThis option allows you to directly stream logs from CloudWatch to OpenSearch Service (Elasticsearch Service) in near-real time without the need for additional services or resources, thus minimizing operational overhead. The other options involve additional services (Lambda, Kinesis Data Firehose, Kinesis Data Streams) and would therefore require more operational management.","timestamp":"1702993020.0","poster":"SaurabhTiwari1","comment_id":"1100661"},{"poster":"Marco_St","upvote_count":"1","timestamp":"1700629500.0","content":"Selected Answer: A\nA, C can both support near-real-time logs transfer to OpenSearch. But it depends on the current needs. Based on the context of question, Option A is the best one. \nFor Option C: This Kinesis Data Firehose offers additional benefits like easy scaling, built-in failure handling, and potential for data transformation if needed. But these are not required by the question. It only requires LEAST overhead-operation and near-real-time transfer then A is straightforward.","comment_id":"1076922"},{"comments":[{"content":"Pretty sure A supports near-real-time transfer","comments":[{"timestamp":"1709719500.0","comment_id":"1167068","upvote_count":"1","poster":"cheroh_tots","content":"They both do, but C has the least operational overhead."}],"comment_id":"1105039","poster":"SohamSLP","timestamp":"1703483400.0","upvote_count":"1"}],"timestamp":"1698679620.0","comment_id":"1057968","upvote_count":"1","content":"Selected Answer: C\nYou need real time buffer like Kinesis, otherwise you are going to lose data.","poster":"tom_cruise"},{"comment_id":"1045551","content":"Selected Answer: A\nIt is possible to configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in near realtime through a CloudWatch Logs subscription which implies les ops overhead.","poster":"mhka1988","timestamp":"1697519700.0","upvote_count":"1"},{"poster":"OlehKom","comment_id":"1042759","content":"Selected Answer: C\n\"A new policy requires the company to store all application logs in Amazon OpenSearch Service (Amazon Elasticsearch Service) in !!!near-real time!!!!.\" \n\nAmazon Kinesis Data Firehose captures and loads data in near real time. It loads new data into Amazon S3, Amazon Redshift, and Amazon OpenSearch Service within 60 seconds after the data is sent to the service. As a result, you can access new data sooner and react to business and operational events faster.","timestamp":"1697209140.0","upvote_count":"2"},{"content":"Selected Answer: C\nYou need kinesis as a buffer in between, otherwise, the logs will be lost if anything goes wrong.","poster":"tom_cruise","upvote_count":"1","timestamp":"1697032260.0","comment_id":"1040707"},{"timestamp":"1696854960.0","poster":"mohamoha","content":"Selected Answer: A\nYou can configure a CloudWatch Logs log group to stream data it receives to Amazon OpenSearch Service cluster in near real-time through a CloudWatch Logs subscription.\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","upvote_count":"2","comment_id":"1028924"},{"comments":[{"timestamp":"1712124840.0","content":"Create an AWS Lambda function. Use the log group to invoke the function to write the logs to Amazon Open Search Service (Amazon Elasticsearch Service) would also work, but it may require more operational overhead as you would need to set up and manage the Lambda function and ensure that it scales to handle the incoming logs. Option D: Install and configure Amazon Kinesis Agent on each application server to deliver the logs to Amazon Kinesis Data Streams. Configure Kinesis Data Streams to deliver the logs to Amazon Open Search Service (Amazon Elasticsearch Service) would also work, but it may require more operational overhead as you would need to install and configure the \n\nhttps://2048-cupcakes.org/","upvote_count":"1","poster":"Sofiachloe","comment_id":"1188497"}],"upvote_count":"1","comment_id":"1015469","poster":"JKevin778","timestamp":"1695527040.0","content":"Selected Answer: C\n100% C.\nCloudWatch logs cannot be send to OpenSearch directly, need KDS or KDF works in the middle. \nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters.html"},{"comment_id":"1004584","timestamp":"1694424480.0","poster":"hootani","upvote_count":"1","content":"Selected Answer: C\nThe answer is C"},{"upvote_count":"1","comment_id":"981939","content":"Selected Answer: C\nC is the correct answer.\n\nUsing Kinesis Data Firehose will allow near real-time delivery of the CloudWatch logs to Amazon Elasticsearch Service with the least operational overhead compared to the other options.\n\nFirehose can be configured to automatically ingest data from CloudWatch Logs into Elasticsearch without needing to run Lambda functions or install agents on the application servers. This makes it the most operationally simple way to meet the stated requirements.","timestamp":"1692127560.0","poster":"Guru4Cloud"},{"poster":"npraveen","upvote_count":"3","content":"Selected Answer: C\nNear Real Time: Cloud watch logs --> Subscription Filter --> Kinesis data fire house --> S3\nReal Time: Cloud watch logs --> Subscription Filter -->Lmabda --> S3","comment_id":"956248","timestamp":"1689744720.0"},{"content":"We need to consider the “least operation overhead” and with that said Cloudwatch log Group and opersearch is already existing in the system and needs integration. Kinesics is preferable for near real time streaming but it will be additional overhead..Hence answer should be A","poster":"Cloudnative9990","upvote_count":"2","timestamp":"1689532740.0","comment_id":"953563"},{"comment_id":"946928","upvote_count":"1","poster":"bala_s","timestamp":"1688885760.0","content":"Answer is A . The question says near real time and not real time\nYou can also use a CloudWatch Logs subscription to stream log data in near real time to an Amazon OpenSearch Service cluster. For more information, see Streaming CloudWatch Logs data to Amazon OpenSearch Service."},{"poster":"bigboi23","content":"Selected Answer: C\nOPTION C \n\nYou can use subscriptions to get access to a real-time feed of log events from CloudWatch Logs and have it delivered to other services such as an Amazon Kinesis stream, an Amazon Kinesis Data Firehose stream, or AWS Lambda for custom processing, analysis, or loading to other systems. \n\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html","upvote_count":"1","comment_id":"946503","timestamp":"1688821740.0"},{"timestamp":"1687438320.0","content":"By configuring a CloudWatch Logs subscription, you can stream the logs from CloudWatch Logs to Amazon OpenSearch Service in near-real-time. This solution requires minimal operational overhead as it leverages the built-in functionality of CloudWatch Logs and Amazon OpenSearch Service for log streaming and indexing.\n\nOption B (Creating an AWS Lambda function) would involve additional development effort and maintenance of a custom Lambda function to write the logs to Amazon OpenSearch Service.\n\nOption C (Creating an Amazon Kinesis Data Firehose delivery stream) introduces an additional service (Kinesis Data Firehose) that may not be necessary for this specific requirement, adding unnecessary complexity.\n\nOption D (Installing and configuring Amazon Kinesis Agent) also introduces additional overhead in terms of manual installation and configuration on each application server, which may not be needed if the logs are already stored in CloudWatch Logs.\n\nIn summary, option A is the correct choice as it provides a straightforward and efficient way to stream logs from CloudWatch Logs to Amazon OpenSearch Service with minimal operational overhead.","upvote_count":"3","poster":"cookieMr","comments":[{"upvote_count":"1","timestamp":"1687481820.0","comment_id":"931146","content":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html","poster":"srijrao"}],"comment_id":"930524"},{"upvote_count":"1","content":"Selected Answer: C\nI vote for C.\nSolution A add unnecessary hop","timestamp":"1686645120.0","poster":"konieczny69","comment_id":"922080"},{"comment_id":"915401","timestamp":"1685965500.0","content":"Selected Answer: C\nA is wrong because subscriptions cannot be sent directly to Opensearch, see 'destination arn' in https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html\n\nCorrect answer is C","upvote_count":"2","poster":"ruqui"},{"upvote_count":"1","timestamp":"1684911900.0","content":"@six _fingers is right!!!! You can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in near real-time through a CloudWatch Logs subscription. \n\nanswer is A\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","poster":"Abrar2022","comment_id":"905583"},{"upvote_count":"1","comment_id":"902534","content":"Selected Answer: C\nThis should be C. OpenSearch is one of the main destinations for Kinesis Data Firehose.","poster":"Rud90","timestamp":"1684581300.0"},{"content":"Selected Answer: C\nC for me and ChatGPT","upvote_count":"2","timestamp":"1681443960.0","poster":"ErfanKh","comment_id":"869948"},{"upvote_count":"2","poster":"channn","timestamp":"1681038960.0","comment_id":"865451","content":"Selected Answer: C\nchoose C after seeing all comments from community"},{"poster":"jayce5","comments":[{"comment_id":"917789","timestamp":"1686198660.0","upvote_count":"1","content":"The link above supports answer A not C, there is no mention of Kinesis","poster":"fishy_resolver"}],"content":"Selected Answer: C\nMust be C, https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html\n\"You can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in near real-time through a CloudWatch Logs subscription. For more information, see Real-time processing of log data with subscriptions.\".\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html\n\"You can use subscriptions to get access to a real-time feed of log events from CloudWatch Logs and have it delivered to other services such as an Amazon Kinesis stream, an Amazon Kinesis Data Firehose stream, or AWS Lambda for custom processing, analysis, or loading to other systems.\"\n\nCloudWatch cannot stream directly to Amazon OpenSearch Service.","upvote_count":"3","comment_id":"853835","timestamp":"1680049500.0"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","timestamp":"1676644740.0","comment_id":"811989","poster":"Alhaz","upvote_count":"1"},{"content":"Selected Answer: A\nThe correct answer remains A. Kindly check the link for a confirmation. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","timestamp":"1675379160.0","comment_id":"796509","upvote_count":"3","poster":"imisioluwa"},{"timestamp":"1674414600.0","poster":"bullrem","comment_id":"784617","content":"Selected Answer: C\nOption C (Create an Amazon Kinesis Data Firehose delivery stream. Configure the log group as the delivery stream's sources. Configure Amazon OpenSearch Service (Amazon Elasticsearch Service) as the delivery stream's destination) would be the best option as it allows to easily and securely stream logs from CloudWatch Logs to Amazon Elasticsearch Service in near-real time with minimal operational overhead. Data Firehose is designed specifically for data stream processing and can automatically handle tasks such as data transformation, data validation, and data loading, simplifying the process of sending logs to Amazon Elasticsearch Service.","upvote_count":"1"},{"upvote_count":"3","content":"Selected Answer: A\nA. Configure a CloudWatch Logs subscription to stream the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service).\n\nThis solution meets the requirement of storing all application logs in Amazon OpenSearch Service (Amazon Elasticsearch Service) with the least operational overhead. A CloudWatch Logs subscription allows you to automatically stream logs from CloudWatch Logs to a destination such as Elasticsearch Service, Kinesis Data Streams, or Lambda without the need for additional configurations and management.\nIt eliminates the need for additional infrastructure, Lambda functions and configurations, or separate agents to handle the logs transfer to Elasticsearch Service.","poster":"remand","timestamp":"1673974680.0","comment_id":"779092"},{"content":"Answer : A \nBased on Keywords and Documentation : A is the Answer \nYou can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in \"near real-time through a CloudWatch Logs subscription\"","timestamp":"1673938620.0","poster":"Chan1509","comments":[{"timestamp":"1675867680.0","content":"But CloudWatch Logs log group does NOT support store(write) performance. It just stream data to Amazon OpenSearch Service.","comment_id":"802135","poster":"JiyuKim","upvote_count":"1"}],"upvote_count":"1","comment_id":"778635"},{"upvote_count":"3","content":"The answer is C. The \" in near-real time\" makes it more accurate and least operational overhead.","poster":"imisioluwa","timestamp":"1673650320.0","comment_id":"774909"},{"timestamp":"1672665060.0","content":"Selected Answer: A\nNo doubt C will work, but seems A is cheaper","poster":"gustavtd","upvote_count":"1","comment_id":"763733"},{"comment_id":"762591","content":"Selected Answer: C\nOption A (Configure a CloudWatch Logs subscription to stream the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service)) is not a suitable option, as a CloudWatch Logs subscription is designed to send log events to a destination such as an Amazon Simple Notification Service (Amazon SNS) topic or an AWS Lambda function. It is not designed to write logs directly to Amazon Elasticsearch Service (Amazon ES).","comments":[{"comment_id":"763745","timestamp":"1672666380.0","poster":"HayLLlHuK","upvote_count":"1","content":"You're totally right"}],"poster":"Zerotn3","timestamp":"1672480560.0","upvote_count":"4"},{"timestamp":"1672099440.0","content":"LEAST Operational Overhead \"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html\"\n\nAnswer: A","upvote_count":"1","comment_id":"757961","poster":"SoluAWS"},{"timestamp":"1671795060.0","upvote_count":"2","poster":"duriselvan","comment_id":"754150","content":"Ans c is correct note :- Kinesis Data Firehose (Near real-time (buffer time min. 60 sec))"},{"poster":"career360guru","upvote_count":"2","content":"Option A has least amount of changes needed to achieve this. \nBut D is also possible would be better long term solution as it will avoid the duplication of the logs going into Cloudwatch and then moving to opensearch.","timestamp":"1671397080.0","comment_id":"749186"},{"poster":"study_aws1","content":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html\n\nYou'll need to have destination arn (not mentioned under option A) - either Lambda or Kinesis Firehose.\n\n The Amazon Resource Name (ARN) of the Kinesis stream, Kinesis Data Firehose stream, or Lambda function you want to use as the destination of the subscription feed.\n\nOption B) does not mention the Subscription Filter. Looks more towards Option C)","timestamp":"1668134460.0","comment_id":"715712","upvote_count":"4"},{"timestamp":"1667104740.0","upvote_count":"2","comment_id":"707600","content":"Selected Answer: A\nYou can configure a CloudWatch Logs log group to stream data it receives to your Amazon OpenSearch Service cluster in near real-time through a CloudWatch Logs subscription.","poster":"SimonPark"},{"poster":"ManoAni","upvote_count":"2","content":"Selected Answer: C\nThey mentioned near real time","comments":[{"content":"A is also near real time. plus A is least operational overhead","timestamp":"1669835340.0","upvote_count":"2","comment_id":"731894","poster":"mj98"}],"timestamp":"1666717140.0","comment_id":"704042"},{"comments":[{"comment_id":"731893","poster":"mj98","timestamp":"1669835280.0","content":"LEAST operational overhead","upvote_count":"1"}],"poster":"capepenguin","upvote_count":"3","timestamp":"1666572600.0","content":"Please tell me why not C?\nhttps://docs.aws.amazon.com/opensearch-service/latest/developerguide/integrations.html#integrations-fh","comment_id":"702564"},{"content":"Answer is A\n\nCloudWatch has a native feature to stream logs to OpenSearch, when you enable this setting it creates a Lambda Function automatically with pre-populated code which streams the logs to OpenSearch Cluster. The question here needs a solution with LEAST operational overhead, therefore the answer should be A\nREF: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_OpenSearch_Stream.html","upvote_count":"4","timestamp":"1666300200.0","poster":"ericcloud20","comment_id":"700304"},{"upvote_count":"2","poster":"palermo777","content":"B looks good:\nhttps://d1.awsstatic.com/whitepapers/whitepaper-use-amazon-elasticsearch-to-log-and-monitor-almost-everything.pdf\nChapter: Pushing Amazon CloudWatch Logs into Amazon ES: \"... integration makes it easy to send data to Elasticsearch if source data exists in CloudWatch Logs\"\n\nApproach with Amazon Kinesis Data Firehose requires installation of Amazon Kinesis agent on the EC2 instances, hence it's not considered as LEAST operational complex","comment_id":"700276","timestamp":"1666297260.0","comments":[{"timestamp":"1669851780.0","poster":"EKA_CloudGod","content":"Did you mean A?","comment_id":"732093","upvote_count":"1"}]},{"content":"Selected Answer: A\nShould be A","timestamp":"1666247760.0","comment_id":"699607","poster":"KJa","upvote_count":"2"},{"timestamp":"1666097220.0","content":"Selected Answer: B\nB seems to be the right answer\nhttps://computingforgeeks.com/stream-logs-in-aws-from-cloudwatch-to-elasticsearch/","comment_id":"698246","poster":"LeGloupier","upvote_count":"3"}],"answer_description":"","unix_timestamp":1666097220,"exam_id":31,"timestamp":"2022-10-18 14:47:00","choices":{"C":"Create an Amazon Kinesis Data Firehose delivery stream. Configure the log group as the delivery streams sources. Configure Amazon OpenSearch Service (Amazon Elasticsearch Service) as the delivery stream's destination.","A":"Configure a CloudWatch Logs subscription to stream the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service).","B":"Create an AWS Lambda function. Use the log group to invoke the function to write the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service).","D":"Install and configure Amazon Kinesis Agent on each application server to deliver the logs to Amazon Kinesis Data Streams. Configure Kinesis Data Streams to deliver the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service)."},"answer_ET":"A"},{"id":"uo0G5mL1wr2YYR7wGnCm","answer_ET":"D","answer_images":[],"answer_description":"","unix_timestamp":1666877100,"question_text":"A company is building a web-based application running on Amazon EC2 instances in multiple Availability Zones. The web application will provide access to a repository of text documents totaling about 900 TB in size. The company anticipates that the web application will experience periods of high demand. A solutions architect must ensure that the storage component for the text documents can scale to meet the demand of the application at all times. The company is concerned about the overall cost of the solution.\nWhich storage solution meets these requirements MOST cost-effectively?","answers_community":["D (98%)","2%"],"discussion":[{"comment_id":"1059167","upvote_count":"16","content":"Selected Answer: D\nthe cost of S3<EFS<EBS","poster":"Azure55","timestamp":"1698781440.0"},{"comment_id":"930607","timestamp":"1687441200.0","content":"Selected Answer: D\nAmazon S3 (Simple Storage Service) is a highly scalable and cost-effective storage service. It is well-suited for storing large amounts of data, such as the 900 TB of text documents mentioned in the scenario. S3 provides high durability, availability, and performance.\n\nOption A (Amazon EBS) is block storage designed for individual EC2 instances and may not scale as seamlessly and cost-effectively as S3 for large amounts of data.\n\nOption B (Amazon EFS) is a scalable file storage service, but it may not be the most cost-effective option compared to S3, especially for the anticipated storage size of 900 TB.\n\nOption C (Amazon OpenSearch Service) is a search and analytics service and may not be suitable as the primary storage solution for the text documents.\n\nIn summary, Amazon S3 is the recommended choice as it offers high scalability, cost-effectiveness, and durability for storing the large repository of text documents required by the web application.","poster":"cookieMr","upvote_count":"11"},{"poster":"PaulGa","content":"Selected Answer: D\nAns D - Amazon S3 is highly scalable, cost-effective storage service, well-suited for large amounts of data. It is highly durable, highly available, and offers good performance.\nBy comparison, EFS (option B) could do it but is more expensive...","timestamp":"1726494960.0","upvote_count":"3","comment_id":"1284768"},{"upvote_count":"2","content":"S3 can be a good option for storing text documents. It allows users to store any file type as objects. (documents, videos, images)","comment_id":"1268929","timestamp":"1724099640.0","poster":"Americanman"},{"comment_id":"1253295","content":"Selected Answer: D\nUsing EFS would obviously be the optimal case, we have to use s3 to fulfill the cost efficiency requirement.","upvote_count":"3","poster":"jaradat02","timestamp":"1721683380.0"},{"upvote_count":"4","content":"Option A : EBS can't be multi-AZ\nOption B: EFS is expensive\nOption C: ElasticSearch is not for storing","timestamp":"1705220160.0","comment_id":"1122377","poster":"theochan"},{"comment_id":"1039819","poster":"awashenko","timestamp":"1696966500.0","content":"Selected Answer: D\nD is the only real solution here. S3 is the cheapest option for storage and it can scale indefinitely.","upvote_count":"5"},{"upvote_count":"4","poster":"Guru4Cloud","comment_id":"981941","content":"Selected Answer: D\nMOST cost-effective = S3 (unless explicitly stated in the requirements)","timestamp":"1692127620.0"},{"comment_id":"907149","upvote_count":"3","poster":"Jeeva28","content":"Selected Answer: D\n900 in the question to divert our Thinking.When you have keyword least in question S3 will be only thing we should look","timestamp":"1685085300.0"},{"poster":"Abrar2022","comment_id":"905586","content":"EFS and S3 meet the requirements but S3 is a better option because it is cheaper.","timestamp":"1684912200.0","upvote_count":"2"},{"comment_id":"891421","timestamp":"1683466500.0","content":"Selected Answer: D\nMOST cost-effective = S3 (unless explicitly stated in the requirements)","upvote_count":"3","poster":"studynoplay"},{"content":"Selected Answer: D\nS3 is the cheapest and most scalable.","timestamp":"1681745700.0","comment_id":"872862","poster":"Robrobtutu","upvote_count":"2"},{"upvote_count":"2","comment_id":"862771","content":"Selected Answer: C\nNow in OpenSearch you can reach at 3 PB so option C is better.\nWith S3 in an intensive scenario the costs of retriving the buckets could be high.\nYes OpenSearch is NOT cheap but this has to be analysed carefully.\nSo, I opt \"C\" to increase the discussion.\n\nWith UltraWarm, you can retain up to 3 PB of data on a single Amazon OpenSearch Service cluster, while reducing your cost per GB by nearly 90% compared to the warm storage tier. You can also easily query and visualize the data in your Kibana interface (version 7.10 and earlier) or OpenSearch Dashboards. Analyze both your recent (weeks) and historical (months or years) log data without spending hours or days restoring archived logs.\n\nhttps://aws.amazon.com/es/opensearch-service/features/","timestamp":"1680770520.0","poster":"jdr75"},{"comment_id":"861757","upvote_count":"3","poster":"Dr_Chomp","timestamp":"1680669180.0","content":"EFS is a good option but expensive alongside S3 and customer concerned about cost - thus: S3 (D)"},{"upvote_count":"3","comment_id":"849130","poster":"frenzoid","timestamp":"1679648160.0","content":"I wonder why people choose S3, yet S3 max capacity is 5TB 🤔.","comments":[{"poster":"frenzoid","comment_id":"849133","content":"My bad, the 5TB limit is for individual files. S3 has virtually unlimited storage capacity.","timestamp":"1679648280.0","upvote_count":"8"}]},{"timestamp":"1676825100.0","comment_id":"814276","poster":"Help2023","upvote_count":"5","content":"Selected Answer: D\nA. It is Not a block storage \nB. It is Not a file storage \nC. Opensearch is useful but can only accommodate up to 600TiB and is mainly for search and anaytics. \nD. S3 is more cost effective than all and can handle all objects like Block, File or Text."},{"timestamp":"1673974860.0","upvote_count":"2","poster":"remand","comment_id":"779095","content":"Selected Answer: D\nD. Amazon S3\n\nAmazon S3 is an object storage service that can store and retrieve large amounts of data at any time, from anywhere on the web. It is designed for high durability, scalability, and cost-effectiveness, making it a suitable choice for storing a large repository of text documents. With S3, you can store and retrieve any amount of data, at any time, from anywhere on the web, and you can scale your storage up or down as needed, which will help to meet the demand of the web application. Additionally, S3 allows you to choose between different storage classes, such as standard, infrequent access, and archive, which will enable you to optimize costs based on your specific use case."},{"timestamp":"1673231880.0","upvote_count":"3","poster":"SilentMilli","comment_id":"769994","content":"Selected Answer: D\nThe most cost-effective storage solution for a web application that needs to scale to meet high demand and store a large repository of text documents would be Amazon S3. Amazon S3 is an object storage service that is designed for durability, availability, and scalability. It can store and retrieve any amount of data from anywhere on the internet, making it a suitable choice for storing a large repository of text documents. Additionally, Amazon S3 is designed to be highly scalable and can easily handle periods of high demand without requiring any additional infrastructure or maintenance."},{"content":"Selected Answer: D\nIs there anything cheaper than S3?","comment_id":"763734","timestamp":"1672665120.0","upvote_count":"4","poster":"gustavtd"},{"upvote_count":"2","timestamp":"1671666660.0","content":"Selected Answer: D\nD. Amazon S3 is the most cost-effective storage solution that meets the requirements described.\n\nAmazon S3 is an object storage service that is designed to store and retrieve large amounts of data from anywhere on the web. It is highly scalable, highly available, and cost-effective, making it an ideal choice for storing a large repository of text documents that will experience periods of high demand. S3 is a standalone storage service that can be accessed from anywhere, and it is designed to handle large numbers of objects, making it well-suited for storing the 900 TB repository of text documents described in the scenario. It is also designed to handle high levels of demand, making it suitable for handling periods of high demand.","poster":"Buruguduystunstugudunstuy","comment_id":"752879"},{"upvote_count":"1","content":"Selected Answer: D\nOption D","timestamp":"1671397380.0","poster":"career360guru","comment_id":"749189"},{"timestamp":"1671274020.0","poster":"NikaCZ","comment_id":"747995","content":"Selected Answer: D\nOnly EFS and S3 meeting the requirements but S3 is better option because it is cheaper.","upvote_count":"5"},{"content":"D is correct","comment_id":"723865","upvote_count":"1","poster":"Wpcorgan","timestamp":"1669060320.0"},{"upvote_count":"5","content":"Selected Answer: D\nOnly EFS and S3, Since EFS is make it much costly, S3 is the viable option","poster":"PS_R","comment_id":"713889","timestamp":"1667916660.0"},{"comments":[{"timestamp":"1680770640.0","poster":"jdr75","comment_id":"862774","upvote_count":"1","content":"sic: \nA solutions architect must ensure that the storage component for the text documents can scale to meet the demand of the application at all times.\n\nYes, ensure the storage, BUT to meet the demand. You cannot definitely forget the demand."}],"timestamp":"1666877100.0","poster":"UWSFish","upvote_count":"3","content":"Selected Answer: D\nI originally thought C but the question is specific about wanting the storage to scale not the search capacity.","comment_id":"705591"}],"timestamp":"2022-10-27 15:25:00","choices":{"D":"Amazon S3","C":"Amazon OpenSearch Service (Amazon Elasticsearch Service)","A":"Amazon Elastic Block Store (Amazon EBS)","B":"Amazon Elastic File System (Amazon EFS)"},"question_id":42,"exam_id":31,"isMC":true,"topic":"1","answer":"D","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/86512-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"n9OQiB1WEk4DGzBO9H6c","unix_timestamp":1666752420,"exam_id":31,"topic":"1","answer_description":"","question_id":43,"question_images":[],"answer_images":[],"answer_ET":"B","answers_community":["B (69%)","A (30%)","1%"],"url":"https://www.examtopics.com/discussions/amazon/view/86450-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2022-10-26 04:47:00","discussion":[{"content":"Selected Answer: B\nIf you want to use AWS WAF across accounts, accelerate WAF configuration, automate the protection of new resources, use Firewall Manager with AWS WAF","comment_id":"713898","comments":[{"content":"they didn't mention multiple accounts! only 2 regoins","upvote_count":"3","timestamp":"1698991320.0","comments":[{"comment_id":"1219640","upvote_count":"9","poster":"lofzee","timestamp":"1716822720.0","content":"wtf? the question says \n\"to protect these API Gateway managed REST APIs across multiple accounts from SQL injection and cross-site scripting attack\""}],"poster":"slimen","comment_id":"1061110"},{"content":"B is wrong: AWS Firewall Manager cannot create security policies across regions. \nQ: Can I create security policies across regions? No, AWS Firewall Manager security policies are region specific. Each Firewall Manager policy can only include resources available in that specified AWS Region. You can create a new policy for each region where you operate.\nhttps://aws.amazon.com/firewall-manager/faqs/#:~:text=No%2C%20AWS%20Firewall%20Manager%20security,in%20that%20specified%20AWS%20Region.","poster":"baku98","upvote_count":"8","timestamp":"1702121580.0","comments":[{"poster":"mauroicardi","timestamp":"1710457740.0","content":"AWS Firewall Manager is integrated with AWS Organizations so you can enable AWS WAF rules, AWS Shield Advanced protections, VPC security groups, AWS Network Firewalls, and Amazon Route 53 Resolver DNS Firewall rules across multiple AWS accounts and resources from a single place.","upvote_count":"4","comment_id":"1173808"},{"comment_id":"1105753","timestamp":"1703571600.0","poster":"pentium75","content":"That's why B says that you \"set up AWS Firewall Manager IN BOTH REGIONS\". Still you can \"centrally configure\" WAF per region, so that you don't have to attach WAF to every individual API.","upvote_count":"5"}],"comment_id":"1091772"}],"timestamp":"1667917680.0","poster":"Gil80","upvote_count":"42"},{"poster":"Nigma","content":"B\n\nUsing AWS WAF has several benefits. Additional protection against web attacks using criteria that you specify. You can define criteria using characteristics of web requests such as the following:\nPresence of SQL code that is likely to be malicious (known as SQL injection).\nPresence of a script that is likely to be malicious (known as cross-site scripting).\n\nAWS Firewall Manager simplifies your administration and maintenance tasks across multiple accounts and resources for a variety of protections.\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html","upvote_count":"18","timestamp":"1667878140.0","comment_id":"713459","comments":[{"content":"Q: Can I create security policies across regions?\n\nNo, AWS Firewall Manager security policies are region specific. Each Firewall Manager policy can only include resources available in that specified AWS Region. You can create a new policy for each region where you operate.\n\nSo you could not centrally (i.e. in one place) configure policies, you would need to do this is each region","timestamp":"1671545640.0","poster":"JayBee65","comment_id":"750983","upvote_count":"4","comments":[]}]},{"timestamp":"1739997240.0","content":"Selected Answer: A\nAWF has Web ACL which has a rule regarding HTTP header, HHTP body or URL string protects from common attack - SQL Injection and cross site scripting.","comment_id":"1358960","poster":"AwsAbhiKumar","upvote_count":"1"},{"comment_id":"1348797","comments":[{"comments":[{"comment_id":"1348800","poster":"Dharmarajan","timestamp":"1738189440.0","upvote_count":"1","content":"This is a tricky one. Again. AWS WAF is a product specifically for preventing SQL Injection attacks. So maybe A is indeed the right choice. I believe A is indeed the right answer now, after referring to the doc.\nhttps://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-type-sqli-match.html"}],"timestamp":"1738189260.0","upvote_count":"1","content":"OK I stand corrected: the choice does say \"Centrally manager rules\" and not \"use a sigle policy\". In that view B is indeed the most appropriate.","poster":"Dharmarajan","comment_id":"1348799"}],"upvote_count":"1","poster":"Dharmarajan","timestamp":"1738189140.0","content":"Selected Answer: A\nC&D are out of question as AWS Shield is only for DDoS attack prevention.\nB is not supported - one single policy cannot be used for multiple regions.\nThat leaves out A."},{"comment_id":"1343344","upvote_count":"1","poster":"FlyingHawk","content":"Selected Answer: B\nCentralized control with Firewall Manager means you can create and manage WAF rules once and apply them across multiple accounts and Regions, ensuring consistency and compliance.\nFirewall Manager automatically applies policies to new and existing resources across accounts, reducing the effort of manually associating web ACLs in each Region and account.","timestamp":"1737350040.0"},{"comment_id":"1343342","upvote_count":"1","poster":"FlyingHawk","content":"Selected Answer: B\nIf only a few accounts, A is more straight. but the question mentions \"multiple accounts\", may be B is better choice.","timestamp":"1737349980.0"},{"upvote_count":"1","timestamp":"1732722840.0","content":"Selected Answer: C\nThe keywords here is \"across multiple accounts\", not \"across multiple regions\".","comment_id":"1318767","poster":"tom_cruise"},{"content":"Selected Answer: B\nAWS Firewall Manager:\n\nCentralized Management: Allows you to centrally manage security policies across multiple accounts and regions.\nWAF Rule Configuration: Enables you to create and manage WAF rules in a single location, simplifying the configuration process.\nAutomatic Deployment: Automatically deploys WAF rules to protected resources, reducing manual effort.\nPolicy-Based Control: Provides granular control over security policies, allowing you to tailor them to specific needs.","upvote_count":"2","comment_id":"1315979","timestamp":"1732217580.0","poster":"0de7d1b"},{"comment_id":"1299548","upvote_count":"2","content":"I recently purchased the Multiwood Ergonomic Office Chair, and it's a game changer! The comfort and support it provides have transformed my work-from-home experience. Plus, the value for the quality is unbeatable highly recommended for anyone looking to enhance their workspace.","poster":"leoo55","timestamp":"1729229880.0"},{"poster":"ChymKuBoy","upvote_count":"3","content":"Selected Answer: B\nB for sure\nCentralized management: AWS Firewall Manager allows you to centrally manage AWS WAF rules across multiple accounts and regions. This simplifies the configuration and management process.\n\nConsistent security policies: You can enforce consistent security policies across all your API Gateway APIs, ensuring that they are protected from the same threats.\n\nScalability: AWS Firewall Manager can handle a large number of accounts and resources, making it suitable for global companies with many API Gateway APIs.","comment_id":"1299526","timestamp":"1729222080.0"},{"comment_id":"1284776","upvote_count":"1","content":"Selected Answer: A\nAns A - \"With AWS WAF, you can create security rules that control bot traffic and block common attack patterns such as SQL injection or cross-site scripting (XSS). Use cases. Filter web traffic.\"\nhttps://aws.amazon.com › waf \n\nNone of the other options can do it.","timestamp":"1726495260.0","poster":"PaulGa"},{"content":"AWS WAF helps you to protect your application against common web exploits and bots that can affect availability, compromise security or consume excessive resources.\nYou can create security rules that will control bot traffic and common attacks like SQL injection or Cross-site scripting (XSS)","poster":"Americanman","comment_id":"1268935","upvote_count":"1","timestamp":"1724101980.0"},{"upvote_count":"1","comment_id":"1253297","content":"Selected Answer: B\nA is valid, but B achieves the least operational overhead.","poster":"jaradat02","timestamp":"1721683620.0"},{"comment_id":"1177302","poster":"TilTil","upvote_count":"2","timestamp":"1710851340.0","content":"Selected Answer: A\nWAF deals well with the types of attacks mentioned. XSS and SQL Injection are both app level attacks hence needs a WAF."},{"upvote_count":"2","poster":"sirasdf","timestamp":"1708561800.0","comment_id":"1155955","content":"B\n\nOption A involves setting up AWS WAF in both regions and associating regional web ACLs with an API stage. While this can provide the necessary protection, it requires more manual configuration in each region, potentially leading to more administrative effort, especially if there are updates or changes needed to be made across multiple regions.\n\nTherefore, Option B is likely to require the least amount of administrative effort."},{"comment_id":"1136224","content":"Selected Answer: A\nOriginal architecture does not have WAFs. B assumes there are WAFs already in place and why would you want to deploy a Firewall Manager to manage 1 Firewall? it adds unnecessary administrative tasks and costs for a tool that is not needed. You would want that if you were managing 10+ Firewalls not just one. A makes the most sense.","timestamp":"1706653140.0","poster":"killbots","upvote_count":"4"},{"comment_id":"1134807","upvote_count":"1","poster":"thewalker","content":"Selected Answer: B\nB is the answer","timestamp":"1706522220.0"},{"timestamp":"1705425180.0","content":"Selected Answer: B\nB is basically A but with least admin overhead.","comment_id":"1124377","upvote_count":"2","poster":"awsgeek75"},{"poster":"1Alpha1","timestamp":"1703374560.0","content":"Selected Answer: A\nAre AWS firewall Manager security policies region specific?\nQ: Can I create protection policies across regions? No, Amazon Firewall Manager protection policies are region specific. Each Firewall Manager policy can only include resources available in that specified Amazon Web Services Region. You can create a new policy for each region where you operate.","comment_id":"1104359","upvote_count":"2"},{"comment_id":"1101108","timestamp":"1703035320.0","content":"AW FW manager demo:\n https://youtu.be/fwFHTxtSN2M","poster":"djgodzilla","upvote_count":"1"},{"comment_id":"1083672","upvote_count":"2","content":"Selected Answer: A\nFor \"SQL injection and cross-site scripting attacks\" use AWS WAF:\nhttps://aws.amazon.com/waf/features/","comments":[{"content":"Y, but WAF is also involved in B, just centrally configured by Firewall Manager","poster":"pentium75","upvote_count":"2","timestamp":"1703571660.0","comment_id":"1105755"}],"timestamp":"1701278280.0","poster":"Murtadhaceit"},{"poster":"slimen","content":"Selected Answer: A\nthe question mentioned 2 regions not 2 accounts\nWAF is more suitable here with less effort than Firewall Manager!","timestamp":"1698991380.0","upvote_count":"3","comment_id":"1061111"},{"upvote_count":"1","poster":"cosmiccliff","comment_id":"1061046","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/waf/latest/developerguide/fms-chapter.html#:~:text=AWS%20Firewall%20Manager%20simplifies,new%20accounts%20and%20resources.","timestamp":"1698981360.0"},{"content":"One question for those who voted for B, how WAF manager protect APIGW from SQL injection and etc w/o WAF. WAF manager is not FW!!!","comments":[{"upvote_count":"1","poster":"pentium75","content":"B specifically says that you use Firewall Manager to configure WAF, and protecting from SQL injection is exactly what WAF does.","comment_id":"1105758","timestamp":"1703571720.0"}],"comment_id":"1057350","timestamp":"1698641580.0","upvote_count":"1","poster":"ronin201"},{"poster":"Abitek007","comments":[],"content":"Selected Answer: A\nyou can as well use Firewall Manager, but the question says least operational overhead","comment_id":"1039370","upvote_count":"2","timestamp":"1696933740.0"},{"poster":"Valder21","content":"Selected Answer: A\nSQL injection, cross-site scripting = WAF","comment_id":"996129","timestamp":"1693577940.0","upvote_count":"2","comments":[]},{"poster":"Hassaoo","upvote_count":"1","timestamp":"1693456860.0","comment_id":"994747","content":"A is Right Option\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-control-access-aws-waf.html"},{"comment_id":"981943","timestamp":"1692127740.0","poster":"Guru4Cloud","content":"Selected Answer: B\nB is the correct answer.\n\nUsing AWS Firewall Manager to centrally configure AWS WAF rules provides the least administrative effort compared to the other options.\n\nFirewall Manager allows centralized administration of AWS WAF rules across multiple accounts and Regions. WAF rules can be defined once in Firewall Manager and automatically applied to APIs in all the required Regions and accounts.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1691846580.0","content":"Selected Answer: A\nawf setting is region specific","poster":"ukivanlamlpi","comment_id":"979380"},{"upvote_count":"1","comment_id":"952234","poster":"RajkumarTatipaka","timestamp":"1689414420.0","content":"Selected Answer: B\nif you want to manage protection accross accounts and resources then use AWS firewall manager. AWS WAF protect against web attacks like sql-injection and cross-site scrpting"},{"poster":"cookieMr","comment_id":"930635","content":"Selected Answer: B\nB. By setting up AWS Firewall Manager, you can centrally configure AWS WAF rules, which can be applied to multiple AWS accounts and Regions. This allows for efficient management and enforcement of security rules across accounts without the need for separate configuration in each individual Region.\n\nOption A (Setting up AWS WAF with Regional web ACLs) requires setting up and managing AWS WAF in each Region separately, which increases administrative effort.\n\nOption C (Setting up AWS Shield with Regional web ACLs) primarily focuses on DDoS protection and may not provide the same level of protection against SQL injection and cross-site scripting attacks as AWS WAF.\n\nOption D (Setting up AWS Shield in one Region) provides DDoS protection but does not directly address protection against SQL injection and cross-site scripting attacks.\n\nIn summary, option B offers the most efficient and centralized approach by leveraging AWS Firewall Manager to configure AWS WAF rules across multiple Regions, minimizing administrative effort while ensuring protection against SQL injection and cross-site scripting attacks.","upvote_count":"2","timestamp":"1687442220.0"},{"comment_id":"905421","timestamp":"1684893720.0","upvote_count":"2","poster":"omoakin","content":"AAAAAAAAAAA"},{"content":"Crazy community voting !\nCorrect answer is => A : AWS Firewall Manager security policies are region specific. Each Firewall Manager policy can only include resources available in that specified AWS Region.","upvote_count":"3","comment_id":"879262","comments":[{"poster":"JummyFash","comment_id":"978146","timestamp":"1691712120.0","content":"You can say that again. I will go with A as well","comments":[{"poster":"JummyFash","upvote_count":"1","timestamp":"1691713020.0","comment_id":"978150","content":"B is the correct answer..\nAmong the options provided, option B offers the least amount of administrative effort to protect the API Gateway managed REST APIs from SQL injection and cross-site scripting attacks across multiple accounts.\n\nAWS Firewall Manager allows you to centrally configure and manage AWS WAF rules across multiple accounts and resources. By setting up AWS Firewall Manager in both the us-east-1 and ap-southeast-2 Regions, you can apply consistent WAF rules to the API Gateway instances in those regions without the need to individually configure WAF rules for each API Gateway."}],"upvote_count":"1"}],"poster":"HelloTomorrow","timestamp":"1682335860.0"},{"comment_id":"858968","upvote_count":"4","poster":"TheAbsoluteTruth","content":"Selected Answer: B\nLa opción A proporciona protección contra inyecciones SQL y secuencias de comandos entre sitios utilizando AWS WAF, que es una solución de firewall de aplicaciones web. Sin embargo, esta opción requiere que se configure AWS WAF en cada región individualmente y se asocie una lista de control de acceso web (ACL) con una etapa de API. Esto puede resultar en un esfuerzo administrativo significativo si hay varias regiones y etapas de API que se deben proteger.\n\nLa opción B es una solución centralizada que utiliza AWS Firewall Manager para administrar las reglas de AWS WAF en múltiples regiones. Con esta opción, es posible configurar las reglas de AWS WAF en una sola ubicación y aplicarlas a todas las regiones relevantes de manera uniforme. Esta solución puede reducir significativamente el esfuerzo administrativo en comparación con la opción A.","timestamp":"1680449160.0"},{"content":"Prerequisites for using AWS Firewall Manager\nYour account must be a member of AWS Organizations\nYour account must be the AWS Firewall Manager administrator\nYou must have AWS Config enabled for your accounts and Regions\nTo manage AWS Network Firewall or Route 53 resolver DNS Firewall, the AWS Organizations management account must enable AWS Resource Access Manager (AWS RAM).\n\ncan anybody explain me least Administration efficiency\ni will go with A\nif ı am wrong anybody correct me","comments":[{"comment_id":"862788","timestamp":"1680771900.0","upvote_count":"1","content":"When they said \"LEAST amount of administrative effort\" they ignore the \"transition costs\" associated to get the final scenario. Only takes account the administration effort supposing all the migration task & prerrequisites were done.\nSo B is probably, BEST.","poster":"jdr75"}],"upvote_count":"1","timestamp":"1679986320.0","comment_id":"852888","poster":"sezer"},{"poster":"bdp123","upvote_count":"1","timestamp":"1677115740.0","comment_id":"818630","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/security/centrally-manage-aws-waf-api-v2-and-aws-managed-rules-at-scale-with-firewall-manager/"},{"comment_id":"817768","content":"B.\nSet up AWS Firewall Manager\nhttps://docs.aws.amazon.com/waf/latest/developerguide/enable-disabled-region.html\nCreate WAF policies separate for each Region:\nhttps://docs.aws.amazon.com/waf/latest/developerguide/get-started-fms-create-security-policy.html\nTo protect resources in multiple Regions (other than CloudFront distributions), you must create separate Firewall Manager policies for each Region.","timestamp":"1677065640.0","upvote_count":"2","poster":"andyto"},{"comment_id":"801854","content":"Selected Answer: A\nI' ll go with A.\nB is wrong because\nTo protect resources in multiple Regions (other than CloudFront distributions), you must create separate Firewall Manager policies for each Region.\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/get-started-fms-create-security-policy.html","poster":"JiyuKim","timestamp":"1675849980.0","upvote_count":"5"},{"content":"Though Option A and B are valid, the question is on Administration efficiency. Since only 2 regions are in consideration, it is much easier to provision WAF than a central Firewall Manager (plus WAF).\n\nRegarding \"to protect API Gateways across multiple accounts\". may be it is an extra information. Web ACLs are at regional level, essentially filters out HTTP messages irrespective of the account i.e., it is applicable to all accounts.","timestamp":"1672946520.0","upvote_count":"1","poster":"Mahadeva","comments":[{"content":"Option A: WAF","timestamp":"1672946580.0","comment_id":"766993","poster":"Mahadeva","upvote_count":"1"},{"timestamp":"1676825640.0","poster":"Help2023","comment_id":"814281","content":"A & B are viable options, however because it is two regions instead of creating WAF twice (one for each region) simply create it all at once in the Central Firewall Manager. Imagine you need to make some changes later and again rather than changing it on each, 1 by 1 simply change it on the Central Firewall Manager once and you can deploy more in the future by just adding regions.","upvote_count":"2"}],"comment_id":"766991"},{"timestamp":"1672661460.0","content":"Selected Answer: B\nUse AWS WAF and set up a managed rule to block request patterns associated with the exploitation of SQL databases, like SQL injection attacks. Associate it with the Application Load Balancer. Integrate AWS WAF with AWS Firewall Manager to reuse the rules across all the AWS accounts.","poster":"aba2s","upvote_count":"1","comment_id":"763695"},{"content":"Selected Answer: B\nB. Set up AWS Firewall Manager in both Regions. Centrally configure AWS WAF rules.\n\nTo protect Amazon API Gateway managed REST APIs from SQL injection and cross-site scripting attacks across multiple accounts with the least amount of administrative effort, you can set up AWS Firewall Manager in both Regions and centrally configure AWS WAF rules.","timestamp":"1672491840.0","poster":"Zerotn3","upvote_count":"1","comment_id":"762653"},{"poster":"techhb","comment_id":"760149","timestamp":"1672248600.0","content":"Selected Answer: B\nClarified here https://medium.com/@tshemku/aws-waf-vs-firewall-manager-vs-shield-vs-shield-advanced-4c86911e94c6","upvote_count":"2"},{"poster":"Buruguduystunstugudunstuy","upvote_count":"4","comment_id":"759156","timestamp":"1672184040.0","content":"Selected Answer: B\nOption B, setting up AWS Firewall Manager in both Regions and centrally configuring AWS WAF rules, would require the least amount of administrative effort.\n\nAWS Firewall Manager is a centralized service that enables you to set security policies across your accounts and applications, including API Gateway-managed REST APIs. By setting up AWS Firewall Manager in both Regions and centrally configuring AWS WAF rules, you can protect your APIs from SQL injection and cross-site scripting attacks with minimal effort, as the rules will be centrally managed and automatically enforced across all of your accounts and applications."},{"timestamp":"1671785160.0","comment_id":"754046","poster":"DavidNamy","upvote_count":"1","content":"Selected Answer: B\nOption B involves setting up AWS Firewall Manager in both regions and centrally configuring AWS WAF rules. This allows you to manage the protection of your APIs across multiple accounts and regions from a central location, reducing the administrative effort required."},{"timestamp":"1671630240.0","content":"Selected Answer: A\nCorrect answer - A\nWAF - HTTP headers, HTTP body, or URI strings Protects from common attack - SQL\ninjection and Cross-Site Scripting (XSS)","comment_id":"752375","upvote_count":"2","poster":"Silvestr"},{"comment_id":"751710","timestamp":"1671582780.0","content":"\"Least administrative effort\" would be answer: B","upvote_count":"1","poster":"Cyoung82"},{"comments":[{"timestamp":"1671545400.0","poster":"JayBee65","comments":[{"upvote_count":"1","comment_id":"750977","content":"https://aws.amazon.com/firewall-manager/","timestamp":"1671545400.0","poster":"JayBee65"}],"comment_id":"750975","upvote_count":"1","content":"AWS Firewall Manager\nCentrally configure and manage firewall rules across your accounts \nDeploy managed rules, such as pre-configured WAF rules on your applications, across accounts."}],"timestamp":"1671397620.0","upvote_count":"3","poster":"career360guru","content":"Selected Answer: A\nOption A is right option. \nOption B does not mention configuring WAF rules it just says Firewall Manager. Firewall Manager is just a management layer that manages all firewall configurations.","comment_id":"749190"},{"content":"Selected Answer: A\n\"To protect resources in multiple Regions (other than CloudFront distributions), you must create separate Firewall Manager policies for each Region.\"\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/get-started-fms-create-security-policy.html\n\nI thınk i ll go for A","poster":"ileri_sec","upvote_count":"1","comment_id":"744458","timestamp":"1670964960.0"},{"timestamp":"1670429880.0","comment_id":"738124","poster":"Jit","upvote_count":"1","content":"A .\nWAF for API is a regional. https://docs.aws.amazon.com/waf/latest/developerguide/how-aws-waf-works.html"},{"upvote_count":"1","content":"B is correct","poster":"Wpcorgan","comment_id":"723866","timestamp":"1669060440.0"},{"content":"Selected Answer: B\nThe Answer is AWS Firewall Manager, as it says multiple accounts - My bad.","upvote_count":"3","comment_id":"714440","timestamp":"1667987640.0","poster":"PS_R"},{"comment_id":"713897","timestamp":"1667917560.0","upvote_count":"2","content":"Selected Answer: B\nOption B.\n\nhttps://aws.amazon.com/es/blogs/security/centrally-manage-aws-waf-api-v2-and-aws-managed-rules-at-scale-with-firewall-manager/","poster":"ArielSchivo"},{"content":"Selected Answer: A\nSQL Injections _ think WAF","timestamp":"1667916780.0","poster":"PS_R","comment_id":"713890","upvote_count":"2"},{"comment_id":"713426","content":"The keyword is \"protect API Gateway managed REST APIs across multiple accounts\". Firewall Manager is used when it comes to managing multiple accounts. Option B)","poster":"study_aws1","timestamp":"1667873880.0","upvote_count":"1"},{"comment_id":"707551","upvote_count":"1","poster":"dokaedu","timestamp":"1667086500.0","content":"Correct Answer: A\nAWS Firewall Manager manage multiple AWS WAFs in many regions, Each Firewall Manager policy can only include resources available in that specified AWS Region, You can create a new policy for each region where you operate. The AWS WAF policies are reginal."},{"timestamp":"1666752420.0","upvote_count":"1","comment_id":"704341","content":"IMO: WAF & FW Mgr are regional.\nhttps://aws.amazon.com/firewall-manager/faqs/#:~:text=No%2C%20AWS%20Firewall%20Manager%20security%20policies%20are%20region%20specific.","poster":"envest"}],"isMC":true,"question_text":"A global company is using Amazon API Gateway to design REST APIs for its loyalty club users in the us-east-1 Region and the ap-southeast-2 Region. A solutions architect must design a solution to protect these API Gateway managed REST APIs across multiple accounts from SQL injection and cross-site scripting attacks.\nWhich solution will meet these requirements with the LEAST amount of administrative effort?","choices":{"A":"Set up AWS WAF in both Regions. Associate Regional web ACLs with an API stage.","C":"Set up AWS Shield in bath Regions. Associate Regional web ACLs with an API stage.","B":"Set up AWS Firewall Manager in both Regions. Centrally configure AWS WAF rules.","D":"Set up AWS Shield in one of the Regions. Associate Regional web ACLs with an API stage."},"answer":"B"},{"id":"2ncJjTupIZ2lP5Uf3t5W","exam_id":31,"question_id":44,"choices":{"A":"Create an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins. Configure Route 53 to route traffic to the CloudFront distribution.","B":"Create an Amazon CloudFront distribution that has the ALB as an origin. Create an AWS Global Accelerator standard accelerator that has the S3 bucket as an endpoint Configure Route 53 to route traffic to the CloudFront distribution.","C":"Create an Amazon CloudFront distribution that has the S3 bucket as an origin. Create an AWS Global Accelerator standard accelerator that has the ALB and the CloudFront distribution as endpoints. Create a custom domain name that points to the accelerator DNS name. Use the custom domain name as an endpoint for the web application.","D":"Create an Amazon CloudFront distribution that has the ALB as an origin. Create an AWS Global Accelerator standard accelerator that has the S3 bucket as an endpoint. Create two domain names. Point one domain name to the CloudFront DNS name for dynamic content. Point the other domain name to the accelerator DNS name for static content. Use the domain names as endpoints for the web application."},"answer_description":"","isMC":true,"answer_ET":"A","answer_images":[],"timestamp":"2022-10-10 15:12:00","answer":"A","question_text":"A global company hosts its web application on Amazon EC2 instances behind an Application Load Balancer (ALB). The web application has static data and dynamic data. The company stores its static data in an Amazon S3 bucket. The company wants to improve performance and reduce latency for the static data and dynamic data. The company is using its own domain name registered with Amazon Route 53.\nWhat should a solutions architect do to meet these requirements?","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/85010-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1665407520,"discussion":[{"comments":[{"upvote_count":"7","timestamp":"1718748480.0","content":"A, adding to the excellent explanation by Kartikey140, the solution under C uses a custom DNS name, the question specifies: \"The company is using its own domain name registered with Amazon Route 53\"","poster":"Mihailo34","comment_id":"1232618"},{"content":"By creating a CloudFront distribution that has both the S3 bucket and the ALB as origins, the company can reduce latency for both the static and dynamic data. The CloudFront distribution acts as a content delivery network (CDN), caching the data closer to the users and reducing the latency. The company can then configure Route 53 to route traffic to the CloudFront distribution, providing improved performance for the web application.","poster":"daizy","timestamp":"1675216680.0","upvote_count":"19","comment_id":"794804"}],"content":"Answer is A\nExplanation - AWS Global Accelerator vs CloudFront\n• They both use the AWS global network and its edge locations around the world\n• Both services integrate with AWS Shield for DDoS protection.\n• CloudFront \n• Improves performance for both cacheable content (such as images and videos) \n• Dynamic content (such as API acceleration and dynamic site delivery)\n• Content is served at the edge\n• Global Accelerator \n• Improves performance for a wide range of applications over TCP or UDP \n• Proxying packets at the edge to applications running in one or more AWS Regions.\n• Good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP\n• Good for HTTP use cases that require static IP addresses \n• Good for HTTP use cases that required deterministic, fast regional failover","poster":"Kartikey140","timestamp":"1726904580.0","upvote_count":"125","comment_id":"718554"},{"comment_id":"717912","poster":"kanweng","timestamp":"1726904580.0","content":"Selected Answer: A\nQ: How is AWS Global Accelerator different from Amazon CloudFront?\n\nA: AWS Global Accelerator and Amazon CloudFront are separate services that use the AWS global network and its edge locations around the world. CloudFront improves performance for both cacheable content (such as images and videos) and dynamic content (such as API acceleration and dynamic site delivery). Global Accelerator improves performance for a wide range of applications over TCP or UDP by proxying packets at the edge to applications running in one or more AWS Regions. Global Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP, as well as for HTTP use cases that specifically require static IP addresses or deterministic, fast regional failover. Both services integrate with AWS Shield for DDoS protection.","upvote_count":"42"},{"comment_id":"1329269","upvote_count":"1","timestamp":"1734665820.0","poster":"SamKuo","content":"Selected Answer: C\nAWS Global Accelerator:Dynamic content \nCloudFront:static content"},{"upvote_count":"15","content":"Keywords:\n- The web application has static data and dynamic data. Static data in an Amazon S3 bucket.\n- Improve performance and reduce latency for the static data and dynamic data.\n- The company is using its own domain name registered with Amazon Route 53.\nA: Correct - CloudFront has the Edge location and the cache for dynamic and static\nB: Incorrect - AWS Global Accelerator don't have cache function, so static file need to be load directly from S3 every time.\n- Beside that we configure CloudFront -> ALB, Accelerator -> S3, Route 53 -> CloudFront. It means that all the traffic go to CloudFront only, Acclerator don't have any traffic.\nC: Incorrect - Global Accelerator can configure CloudFront as the endpoint.\nD: Incorrect - We already have domain name. Why will we use new domain name? Will we change to new domain name? How everyone know you new domain name?","comment_id":"862836","poster":"PhucVuu","timestamp":"1726904700.0","comments":[{"content":"For C, it seems like Global Accelerator does not support CloudFront as an endpoint","comment_id":"1323776","timestamp":"1733694300.0","poster":"zoe9z","upvote_count":"2"}]},{"upvote_count":"3","content":"Selected Answer: A\nA. Create an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins. Configure Route 53 to route traffic to the CloudFront distribution.\n\nHere's the reasoning:\n\nCloudFront with Multiple Origins: CloudFront allows you to set up multiple origins for your distribution, so you can use both the ALB (for dynamic content) and the S3 bucket (for static content) as origins. This means that both your dynamic and static content can be served through CloudFront, which will cache content at edge locations to reduce latency.\nRoute 53 Integration with CloudFront: Amazon Route 53 can be easily configured to route traffic for your domain to a CloudFront distribution. Users will access your domain, and Route 53 will direct them to the nearest CloudFront edge location.","timestamp":"1726904640.0","poster":"M0SHE","comment_id":"1018155"},{"comment_id":"1018822","poster":"aropl","timestamp":"1726904640.0","content":"A is correct, other answers have wrong origin or endpoint types.\nCloudfront supports multiple origins on the same distribution (ALB and S3) in our case.\nB incorrect - Global Accelerator Standard accelerator doesn;t support s3 endpoints\nc incorrect - Global Accelerator Standard accelerator doesn't support CloudFront distribution as endpoint\nD incorrect - Global Accelerator Standard accelerator doesn't support s3 endpoints","upvote_count":"10"},{"upvote_count":"2","poster":"rainiverse","timestamp":"1726904640.0","comment_id":"1019312","content":"Selected Answer: A\nI'm wavering between A and C.\nWith dynamic content, CloudFront is cacheable and that's not good.\nBut with answer C, AWS Global doesn't support Cloudfront endpoint\n\"Endpoints for standard accelerators in AWS Global Accelerator can be Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses. \"\nSo I choose A"},{"upvote_count":"1","poster":"PaulGa","comment_id":"1264089","content":"Selected Answer: C\nAns C - for the good reasons given by Diddy99. Altho' Ans A could do it, it is not the best optimised answer; Ans C is, but at cost of a custom domain name (which I don't like)","timestamp":"1723377180.0"},{"content":"Selected Answer: A\nCloudfront caches content at edge locations, reduces latency, and can serve static content from S3 buckets. It can also accelerate dynamic content from EC2. CloudFront maintains a persistent pool of connections to the origin, which minimises the overhead of establishing new connections. Any of these questions with \"latency\" and \"improve performance\" smell like CloudFront.","timestamp":"1721702160.0","comment_id":"1253371","poster":"KTEgghead","upvote_count":"1"},{"poster":"creamymangosauce","comment_id":"1247150","content":"Selected Answer: A\nA - CloudFront for caching static content. No need for Global Accelerator since no static IP is required","upvote_count":"2","timestamp":"1720852860.0"},{"poster":"bishtr3","content":"A","upvote_count":"1","timestamp":"1720796580.0","comment_id":"1246837"},{"timestamp":"1718476140.0","upvote_count":"6","comment_id":"1231100","poster":"diddy99","content":"Selected Answer: C\nAnswer is C\nExplanation:\nA: Using Cloudfront to cache static content is perfect for low latency and performance. However, caching dynamic content from ALB through cloudfront might not be efficient as dynamic contents is often personalized and are not good for caching.\nB: Using cloudfront to cache dynamic contents from ALB is not the most efficient approach\nC: Using amazon cloudfront to cache the static data from S3 ensures efficient distribution of static contents globally. AWS Global accelerator routes traffic to the nearest AWS EDGE location. Hence, routing is optimized to both the ALB (Dynamic contents) and Cloud front distribution."},{"timestamp":"1718057280.0","poster":"ChymKuBoy","upvote_count":"1","comment_id":"1228143","content":"Selected Answer: A\nA for sure"},{"poster":"OBIOHAnze","content":"Selected Answer: A\nBy using CloudFront with separate origins for static and dynamic content, the company can achieve improved performance and reduced latency for both types of data. Route 53 then intelligently routes traffic based on the requested object, ensuring a smooth user experience.","comment_id":"1216179","upvote_count":"1","timestamp":"1716435480.0"},{"comment_id":"1198539","timestamp":"1713523740.0","upvote_count":"1","content":"Selected Answer: A\nIt would have made sense to use S3 bucket as the origin for cloud front and ALB as the end point for global accelerator. However the option C messes it up when it mentions also the cloud front distribution as the end point for global accelerator standard (which is not supported). As this is not possible the only option left is A to use Cloud front for both S3 & ALB.","poster":"ManikRoy"},{"poster":"Prosen2522","content":"Selected Answer: A\nCloudFront can be used for both static and dynamic content distribution.","upvote_count":"4","comment_id":"1151613","timestamp":"1708038840.0"},{"content":"Selected Answer: A\nAnswer is A","poster":"hi2vaisakh","timestamp":"1705411440.0","comment_id":"1124234","upvote_count":"1"},{"upvote_count":"1","poster":"awsgeek75","content":"Selected Answer: A\nGlobaAccelerator helps routing users to closest region. The question doesn't say anything about latency due to region so BCD don't really solve much problems.","timestamp":"1705173000.0","comment_id":"1121978"},{"comment_id":"1121620","upvote_count":"2","poster":"A_jaa","timestamp":"1705149180.0","content":"Selected Answer: A\nAnswer: A"},{"poster":"Mutahir1","timestamp":"1703897820.0","comment_id":"1109318","content":"Ans is C:, This solution involves using Amazon CloudFront for caching the static content, which will improve performance and reduce latency for the static data. Additionally, by creating an AWS Global Accelerator standard accelerator with the ALB and the CloudFront distribution as endpoints, the company can further improve the availability and performance of the web application. Finally, creating a custom domain name that points to the accelerator DNS name will allow the company to use the custom domain name as an endpoint for the web application, providing a seamless experience for the users.\nThe search results provide information about the benefits of using a standard accelerator in AWS Global Accelerator to improve the availability and performance of applications, as well as the steps for creating a standard accelerator and working with standard accelerators in AWS Global Accelerator","upvote_count":"1"},{"comment_id":"1106097","upvote_count":"1","timestamp":"1703601360.0","content":"Selected Answer: A\nAnswer is A","poster":"Wang87"},{"upvote_count":"4","content":"Selected Answer: A\nA is correct;\n\nOption B and option C are incorrect because they include invalid endpoint configurations for Global Accelerator. Global Accelerator Standard does not support S3 endpoints or CloudFront distribution endpoints.","poster":"ale_brd_111","comment_id":"1084353","timestamp":"1701348180.0"},{"poster":"theonlyhero","upvote_count":"9","comment_id":"1066746","content":"I just tested, there is no option in Global Accelerator to make CloudFront distribution as endpoints. so anwer is A","timestamp":"1699565100.0"},{"upvote_count":"2","comment_id":"1054243","poster":"Ruffyit","timestamp":"1698287280.0","content":"I'm wavering between A and C.\nWith dynamic content, CloudFront is cacheable and that's not good.\nBut with answer C, AWS Global doesn't support Cloudfront endpoint\n\"Endpoints for standard accelerators in AWS Global Accelerator can be Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses. \"\nSo I choose A"},{"comments":[{"timestamp":"1704173520.0","upvote_count":"2","content":"As mentioned before by others, Global Accelerator Standard can't use S3 or CloudFront distribution as Endpoints.","poster":"eladbeV2","comment_id":"1111614"}],"content":"Selected Answer: C\nC seems reasonable due to the fact that CloudFront is tedious when it comes to Dynamic content, you need to expire the content everytime it changes, which adds extra work and might lead to inconsistent results.","timestamp":"1697197440.0","comment_id":"1042624","poster":"gldiazcardenas","upvote_count":"1"},{"comment_id":"1028721","poster":"danielpark99","upvote_count":"1","content":"Answer is A\nCloudFront vs Global Accelerator has some diffrences \n1. CloudFront : Improves performance for both cachealbe contents\n2. Global Accelerator : proxying packets at the edge to applications runnnig in one or more AWS regions as workingi like anycast with closer to the pop and no-cache\nGood use case for required fast regional failover","timestamp":"1696845600.0"},{"content":"I did some research and \"a\" is correct but \"c\" is also correct. the thing is that \"a\" is more simple than c and the fact that does not use global accelerator makes it cheaper so is more correct","timestamp":"1695644640.0","poster":"David_Ang","upvote_count":"1","comment_id":"1016791"},{"timestamp":"1694194980.0","comment_id":"1002643","poster":"gsax","upvote_count":"1","content":"Selected Answer: A\nA - Simple solution, CloudFront itself is enough to reduce latency and improve performance. And it can use both as origins S3 and ALB.\n\nA - Simple solution, CloudFront itself is enough to reduce latency and network \nhttps://repost.aws/knowledge-center/cloudfront-distribution-serve-content\n\nnetwork \nhttps://repost.aws/knowledge-center/cloudfront-distribution-serve-content"},{"upvote_count":"1","comment_id":"969030","timestamp":"1690890720.0","content":"Selected Answer: A\nThe answer A fulfills the requirements, so I would choose A.\nThe answer C may also seem to make sense though.","poster":"Lorenzo1"},{"content":"A.","timestamp":"1690768260.0","upvote_count":"1","comment_id":"967658","poster":"gurmit"},{"upvote_count":"1","comment_id":"965275","poster":"TariqKipkemei","timestamp":"1690518240.0","content":"Selected Answer: A\nImprove performance and reduce latency for the static data and dynamic data = Amazon CloudFront","comments":[{"upvote_count":"1","comment_id":"979604","poster":"Lx016","timestamp":"1691877000.0","content":"And? All four answers are about CloudFront, to find the correct answer need to find correct origin(s) to distribute which are S3 and ALB"}]},{"poster":"hakim1977","timestamp":"1690270140.0","comment_id":"962448","content":"Selected Answer: A\nAnswer is A.\n\nGlobal Accelerator is a good fit for non-HTTP use cases.","upvote_count":"1"},{"timestamp":"1689259020.0","poster":"frkael","comment_id":"950752","upvote_count":"3","content":"Keywords: Static and Dynamic data/ S3 and ALB.\nSo Cloudfront is for S3 and Global Acelarator is for ALB"},{"poster":"miki111","timestamp":"1689178620.0","comment_id":"949993","upvote_count":"1","content":"Option A MET THE REQUIREMENT"},{"upvote_count":"5","comment_id":"949798","poster":"Jayendra0609","content":"Selected Answer: C\nSince the data in S3 is static while other data is dynamic. And caching dynamic data doesn't make sense since it will be changing every time. So rather than caching we can use edge locations of Global Accelerator to reduce latency.","comments":[{"content":"I will support option C because the combination of CloudFront and Global Accelerator as described in answer C is better. • Note: CloudFront uses Edge Locations to cache content (improve performance) while Global Accelerator uses Edge Locations to find an optimal pathway to the nearest regional endpoint (reduce latency for the static data and dynamic data).","comment_id":"974463","upvote_count":"1","poster":"Clouddon","comments":[{"timestamp":"1691394360.0","upvote_count":"1","comment_id":"974496","content":"The above explanation is correct however, the answer cannot be option C (my bad) The correct answer is A. AWS says that Global Accelerator is an acceleration at network level\nAWS Global Accelerator is a networking service that improves the performance, reliability and security of your online applications using AWS Global Infrastructure. AWS Global Accelerator can be deployed in front of your Network Load Balancers, Application Load Balancers, AWS EC2 instances, and Elastic IPs, any of which could serve as Regional endpoints for your application. (This implies that Cloudfront is not part of the endpoints that can be used by Global accelerator which only provide security of your online applications ) except someone can proof otherwise.","poster":"Clouddon"}],"timestamp":"1691392080.0"}],"timestamp":"1689166260.0"},{"comment_id":"948151","timestamp":"1688995920.0","upvote_count":"1","content":"Cloudfront: Speeds up distribution of static and dynamic content through its worldwide network of edge locations providing low latency to deliver the best performance through cached data.","poster":"ibu007"},{"poster":"jaydesai8","content":"Selected Answer: A\nmakes sense","timestamp":"1688737860.0","comment_id":"945742","upvote_count":"1"},{"comment_id":"933930","comments":[{"upvote_count":"1","poster":"Mary_Matic","comment_id":"977301","content":"Exactly, the key is \"both static and dyanamic data\" the right answer is C - otherwise it could have been A for statis content s3 with cloudfront","timestamp":"1691644800.0"}],"upvote_count":"4","content":"Answer is C\nAs the company wants to improve both static and dynamic delivery.\nCheck the screen shot in the following article. It shows the structure of this scenario.","poster":"Mia2009687","timestamp":"1687738680.0"},{"comment_id":"926523","timestamp":"1687074840.0","poster":"cookieMr","upvote_count":"5","content":"Selected Answer: A\nOption A: Creating an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins is a valid approach. CloudFront is a content delivery network (CDN) that caches and delivers content from edge locations, improving performance and reducing latency. By configuring CloudFront to have the S3 bucket as an origin for static data and the ALB as an origin for dynamic data, the company can benefit from CloudFront's caching and distribution capabilities. Routing traffic to the CloudFront distribution through Route 53 ensures that requests are directed to the nearest edge location, further enhancing performance and reducing latency."},{"upvote_count":"1","content":"Selected Answer: A\nMakes sense","comment_id":"922369","poster":"Mehkay","timestamp":"1686673140.0"},{"poster":"thaotnt","comment_id":"921833","content":"Selected Answer: A\nUsing CloudFront","timestamp":"1686614580.0","upvote_count":"1"},{"poster":"saryu","comment_id":"920478","upvote_count":"1","timestamp":"1686467160.0","content":"Selected Answer: A\nA is right"},{"comment_id":"920272","timestamp":"1686428760.0","upvote_count":"4","content":"Selected Answer: A\nI was not believing the correct answer was A until I found this:\n\n\nCreate one origin for your S3 bucket, and another origin for your load balancer.\n-Create a behavior that specifies a path pattern to route all static content requests to the S3 bucket.\n-Edit the Default (*) path pattern behavior and set its Origin as your load balancer.","poster":"pedroso"},{"poster":"teja54","comment_id":"910173","upvote_count":"2","timestamp":"1685444340.0","content":"Selected Answer: A\nI will not explain"},{"content":"Selected Answer: C\nI think its C bcoz the question states both static and dynamic will be accessed with low latency. CF for static page in s3 and GA for alb, GA reduce hops on network so the latency will be minimal.","timestamp":"1685437680.0","comments":[{"poster":"RupeC","timestamp":"1689015840.0","content":"CF can also handle dynamic content. It just cannot come from an S3 bucket.","upvote_count":"1","comment_id":"948341"},{"comment_id":"932775","poster":"vipyodha","content":"bot we can not use global accelerator with cloudfront as endpoints","upvote_count":"1","timestamp":"1687625040.0"}],"comment_id":"910094","upvote_count":"1","poster":"DEFALT47"},{"poster":"sbnpj","content":"Selected Answer: C\nchatgpt says C","timestamp":"1684372200.0","upvote_count":"3","comment_id":"900644"},{"upvote_count":"1","content":"Selected Answer: A\nCorrect is A in my opinion","poster":"beginnercloud","comment_id":"899809","timestamp":"1684308660.0"},{"comment_id":"897328","timestamp":"1684047360.0","upvote_count":"1","poster":"cheese929","content":"Selected Answer: A\nA is correct"},{"comment_id":"878665","timestamp":"1682270040.0","upvote_count":"4","content":"C. Create an Amazon CloudFront distribution that has the S3 bucket as an origin. Create an AWS Global Accelerator standard accelerator that has the ALB and the CloudFront distribution as endpoints - you can't use Cloudfront as Accelerator endpoint","poster":"eugene_stalker"},{"timestamp":"1682050740.0","poster":"dhiraj1999","comment_id":"876185","content":"I think Answer is C\nCloudfront will point to a S3 but static content is in S3, need to use Accelerator for Dynamic content","upvote_count":"2"},{"timestamp":"1681669980.0","comment_id":"872046","poster":"CLOUDUMASTER","content":"cloudfront allows you to povide lower latency & Accelerator improves performance for a variety of scenarios hence answer is C","upvote_count":"1"},{"poster":"channn","content":"Selected Answer: A\nKey words: The company is using its own domain name registered with Amazon Route 53.\nC and D created new domain name so out","comment_id":"858577","upvote_count":"3","timestamp":"1680417480.0"},{"upvote_count":"6","timestamp":"1680211740.0","comments":[{"poster":"linux_admin","comment_id":"856305","content":"In option A, the company creates an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins, and configures Route 53 to route traffic to the CloudFront distribution. While this would improve performance for static data served from the S3 bucket, it would not improve performance for dynamic data served by the ALB.\n\nThis is because CloudFront is primarily designed to cache and serve static content, such as images, videos, and web pages. When a request for static content is made, CloudFront will serve the content from its edge locations, which are closer to the user and offer lower latency.\n\nHowever, when a request is made for dynamic content, such as an application form or user input, CloudFront will pass the request to the origin server, which in this case is the ALB. The ALB will still receive all the requests for dynamic data and would still need to process them, resulting in the same latency and performance issues as before.","upvote_count":"3","timestamp":"1726904700.0"}],"content":"Selected Answer: C\nOption A suggests creating an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins, and configuring Route 53 to route traffic to the CloudFront distribution. While this would improve performance for static data served from the S3 bucket, it would not improve performance for dynamic data served by the ALB.\n\nThe ALB would still receive all the requests for dynamic data and would still need to process them, resulting in the same latency and performance issues as before. Therefore, option A would not be the best solution for improving the performance of both static and dynamic data.","poster":"linux_admin","comment_id":"856291"},{"content":"Selected Answer: A\nC is not viable because Global Accelerator doesn't support CloudFront as an endpoint.","upvote_count":"7","comment_id":"854300","timestamp":"1680087480.0","poster":"Abhineet9148232"},{"timestamp":"1679979960.0","content":"Answer C:\nTo improve performance and reduce latency for static and dynamic data hosted on EC2 instances behind an ALB, a solutions architect should use Amazon CloudFront to cache static content stored in an S3 bucket, which reduces latency and improves performance. They should also configure the ALB to route dynamic requests to the appropriate EC2 instances, distributing the workload and reducing latency. Additionally, using AWS Global Accelerator with an ALB and a CloudFront distribution as endpoints can help improve performance and reduce latency. Route 53 can be configured to route traffic to the custom domain name that points to the accelerator DNS name, which is used as an endpoint for the web application.","poster":"alexiscloud","upvote_count":"1","comment_id":"852799"},{"upvote_count":"1","timestamp":"1679588520.0","poster":"PaoloRoma","content":"Selected Answer: C\nA) reduce latency only for static content\nB) improve a bit performance only for static content, but it is bad use of CloudFront and Global Accelerator\nC) imporve performance for both static and dynamic content, putting everything behind Global Acceleratos also enblae to change architecture transparently for user\nD) improve a bit performance only for static content, but it is bad use of CloudFront and Global Accelerator","comment_id":"848434"},{"poster":"TaiTran1994","timestamp":"1679298000.0","upvote_count":"1","comment_id":"844624","content":"Selected Answer: C\nin option A : route 53 does not route any traffic, it only responds to the DNS queries"},{"timestamp":"1679226120.0","poster":"Krishna8686868246","content":"C cannot be the answer since end points for global accelerator can be nlb, alb, ec2 or static IP. We cannot have cloudfront as endpoint","comment_id":"843701","upvote_count":"4"},{"comment_id":"840248","content":"Can someone please explain why this step is needed in C.\nCreate a custom domain name that points to the accelerator DNS name. Use the custom domain name as an endpoint for the web application.","timestamp":"1678909020.0","poster":"BillyBlunts","upvote_count":"1"},{"upvote_count":"3","poster":"sanking","comment_id":"836736","content":"Selected Answer: C\nChatGPT's answer is also C.","timestamp":"1678599840.0"},{"poster":"cegama543","content":"Selected Answer: C\nOption C is the correct solution to improve performance and reduce latency for the static and dynamic data of the web application.\nOption A is incorrect because it only includes the S3 bucket and ALB as origins for the CloudFront distribution, missing the opportunity to cache the static data in edge locations closer to the users.\n\nOption B is incorrect because it includes the S3 bucket as an endpoint for the AWS Global Accelerator, which is not necessary for the static data since it will already be cached in the CloudFront distribution.\n\nOption D is incorrect because it creates two domain names for the web application, which can add complexity to the configuration and increase the risk of errors. Using a single domain name and routing traffic to the closest endpoint using the AWS Global Accelerator is a simpler and more effective solution.","comment_id":"831493","upvote_count":"3","timestamp":"1678156380.0"},{"comment_id":"824343","timestamp":"1677553980.0","upvote_count":"3","poster":"KZM","content":"Selected Answer: C\nHow about C, to improve performance and reduce latency for both static data and dynamic data?"},{"content":"I think dynamic data should not be cached. Therefore cloudfront is not for dynamic cached. A cannot be the answer.","upvote_count":"1","timestamp":"1676879100.0","comment_id":"814965","poster":"habibi03336"},{"comment_id":"797870","timestamp":"1675509840.0","upvote_count":"3","poster":"Ello2023","content":"Selected Answer: A\nQuoted from Amazon \"Fortunately, Amazon CloudFront can serve both types of content, to reduce latency, protect your architecture, and optimize costs. In this post, we demonstrate how to use CloudFront to deliver both static and dynamic content using a single distribution, for dynamic and static websites and web applications.\""},{"poster":"CaoMengde09","content":"So for a while i was tempted by C Answer and i would ready to defy the whole community who vouched for A. Then i understood that using AWS Global Accelerator on two many endpoints doesn't make sense at all because the AWS Global improve Geo Routing coming from users for only one endpoint which should be the ALB in that case.\n\nSo C is totally false. Using CloudFront in front of the ALB with 2 origins : S3 and ALB makes totally sense and is a good practice to improve Content Delivery for STATIC/DYNAMIC \n\nOnce i digested the fact that AWS Cloud Front can afford having multiple origins (S3 and ALB i was sure A is a hell yeah","timestamp":"1675347300.0","comment_id":"796105","upvote_count":"6"},{"upvote_count":"3","poster":"techhb","content":"Selected Answer: A\nOut of A vs C i choose A,CloudFront uses multiple sets of dynamically changing IP addresses while Global Accelerator will provide you a set of static IP addresses as a fixed entry point to your applications.\nCloudFront pricing is mainly based on data transfer out and HTTP requests while Global Accelerator charges a fixed hourly fee and an incremental charge over your standard Data Transfer rates, also called a Data Transfer-Premium fee (DT-Premium).\nCloudFront uses Edge Locations to cache content while Global Accelerator uses Edge Locations to find an optimal pathway to the nearest regional endpoint.\nCloudFront is designed to handle HTTP protocol meanwhile Global Accelerator is best used for both HTTP and non-HTTP protocols such as TCP and UDP.","timestamp":"1673725200.0","comment_id":"775870"},{"poster":"SilentMilli","timestamp":"1673025840.0","comment_id":"767921","content":"Selected Answer: A\nTo improve performance and reduce latency for static data and dynamic data, you can use Amazon CloudFront, a content delivery network (CDN) service. CloudFront delivers content from origins, such as an S3 bucket or an Application Load Balancer (ALB), to users over the internet with low latency and high data transfer speeds. To set up CloudFront for your web application, you can create a distribution and specify the S3 bucket and the ALB as origins. CloudFront will cache static data from the S3 bucket and dynamic data from the ALB. You can then configure Amazon Route 53, the DNS service, to route traffic to the CloudFront distribution. This will allow users to access the web application through CloudFront, which can improve performance and reduce latency.","upvote_count":"2"},{"upvote_count":"1","timestamp":"1672628460.0","poster":"techhb","content":"Selected Answer: A\nits A","comment_id":"763475"},{"timestamp":"1672171260.0","poster":"Buruguduystunstugudunstuy","content":"Selected Answer: A\nOption A, creating an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins and configuring Route 53 to route traffic to the CloudFront distribution, would be the best solution to improve performance and reduce latency for the static data and dynamic data.\n\nCloudFront is a content delivery network (CDN) that speeds up the delivery of static and dynamic web content by caching it at edge locations around the world. By creating a CloudFront distribution with the S3 bucket and the ALB as origins, you can improve performance and reduce latency for both static data (stored in the S3 bucket) and dynamic data (generated by the web application running on the EC2 instances behind the ALB). You can then configure Route 53 to route traffic to the CloudFront distribution, which will automatically route traffic to the nearest edge location to minimize latency.","comment_id":"758989","upvote_count":"3","comments":[{"content":"Option B, creating a CloudFront distribution with the ALB as an origin and an AWS Global Accelerator standard accelerator with the S3 bucket as an endpoint, would not improve performance and reduce latency for static data stored in the S3 bucket. \n\nOption C, creating a CloudFront distribution with the S3 bucket as an origin and an AWS Global Accelerator standard accelerator with the ALB and the CloudFront distribution as endpoints, would not allow the web application to access dynamic data generated by the EC2 instances. \n\nOption D, creating two domain names and pointing one domain name to the CloudFront DNS name for dynamic content and the other domain name to the accelerator DNS name for static content, would not improve performance and reduce latency for both static and dynamic data.","comment_id":"758991","upvote_count":"1","poster":"Buruguduystunstugudunstuy","timestamp":"1672171320.0"}]},{"poster":"MaxMa","content":"C is incorrect maybe because CloudFront can not be endpoint to Accelerator.","comment_id":"744755","upvote_count":"2","timestamp":"1670996340.0"},{"comment_id":"742451","timestamp":"1670825760.0","poster":"rezba1987","content":"Selected Answer: A\nWhen you want to use CloudFront to distribute your content, you create a distribution and choose the configuration settings you want. Also you can use distributions to serve the static and dynamic content, for example, .html, .css, .js, and image files, using HTTP or HTTPS","upvote_count":"1"},{"poster":"Shailendradhaniya","content":"Selected Answer: A\nA","timestamp":"1670583240.0","upvote_count":"2","comment_id":"740009"},{"timestamp":"1669573680.0","content":"Answer A","poster":"hakant","upvote_count":"2","comment_id":"728509"},{"comment_id":"727351","poster":"ogwu2000","comments":[{"poster":"JayBee65","comment_id":"730170","upvote_count":"1","comments":[{"content":"CloudFront improves performance for both cacheable content (such as images and videos), and Dynamic content, whereas AWS Global Accelerator does not support Dynamic content.","comment_id":"730171","upvote_count":"3","poster":"JayBee65","timestamp":"1669714800.0"}],"content":"CloudFront improves performance for both cacheable content (such as images and videos), whereas AWS Global Accelerator does not.","timestamp":"1669714740.0"}],"content":"C. Not A. Why should CloudFront distribution have two origins - S3 bucket and the ALB ?","timestamp":"1669446720.0","upvote_count":"2"},{"content":"A is correct","timestamp":"1669034340.0","poster":"Wpcorgan","upvote_count":"1","comment_id":"723476"},{"timestamp":"1668561240.0","upvote_count":"2","poster":"mikey2000","content":"Selected Answer: A\ncf support s3, alb or lambda function url as origin","comment_id":"719251"},{"comment_id":"717479","poster":"yd_h","timestamp":"1668368160.0","content":"A\nEndpoints for standard accelerators in AWS Global Accelerator can be Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses.","upvote_count":"2"},{"timestamp":"1668216060.0","comment_id":"716424","upvote_count":"1","content":"Selected Answer: A\nanswer is A","poster":"goatbernard"},{"content":"When you set up your accelerator with Global Accelerator, you associate the static IP addresses to regional endpoints in one or more AWS Regions. For standard accelerators, the endpoints are Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses. For custom routing accelerators, endpoints are virtual private cloud (VPC) subnets with one or more EC2 instances.","poster":"yuantongxue","comment_id":"716317","upvote_count":"1","timestamp":"1668200340.0"},{"poster":"17Master","content":"Selected Answer: A\nA","comment_id":"706854","timestamp":"1667005080.0","upvote_count":"1"},{"timestamp":"1666621620.0","comment_id":"703113","poster":"Six_Fingered_Jose","upvote_count":"2","content":"Selected Answer: A\nThis is a tough question, initially thought answer was C but after some research found A to be the most viable answer here.\n\nCloudFront can be used to reduce latency for dynamic content (the ALB in this case) by using edge locations to connect via AWS network instead of the internet, thus reducing latency.\nSo it might not necessary cache the content but it still reduces latency and improve performance with the lowest amount of work."},{"poster":"kogs","content":"A makes more sense and its possible.","upvote_count":"2","timestamp":"1666318620.0","comment_id":"700472"},{"timestamp":"1665669720.0","poster":"KVK16","comment_id":"693956","content":"Selected Answer: C\nStatic content can be cached at Cloud front Edge locations from S3 and dynamic content \n EC2 behind the ALB whose performance can be improved by Global Accelerator whose one endpoint is ALB and other Cloud front. So with regards to custom domain name endpoint is web application is R53 alias records for the custom domain point to web application\n\n\nS3 cannot be endpoint for Global Accelerator - (interesting to think how S3 Global transfer acceleration functions)","upvote_count":"3"},{"poster":"BoboChow","comments":[{"timestamp":"1665544440.0","poster":"BoboChow","content":"Neither CloudFront nor S3 can be as endpoint for AWS Accelerator, so B is out, too.","comment_id":"692595","upvote_count":"1"}],"upvote_count":"2","content":"Selected Answer: A\nB,D is out because I don't think S3 can be an endpoint to AWS Accelerator.\nAs for C, I'm wondring if it works that dynamic and static resource use different domain name.\nSo I am going with A","comment_id":"692592","timestamp":"1665544260.0"},{"content":"Selected Answer: A\nA","comment_id":"691972","upvote_count":"3","timestamp":"1665482100.0","poster":"sba21"},{"content":"can't have CloudFront nor S3 as endpoints for AWS Accelerator... that eliminate B,C,D.. \nalso CloudFront can improve performance and latency for both static and dynamic contents.. so I am going with A","comment_id":"691395","comments":[{"poster":"ArielSchivo","upvote_count":"1","content":"Option A includes an S3 bucket, how can that work with dynamic content? I'm confused here.","comments":[{"poster":"17Master","comment_id":"706851","content":"CloudFront --> BackEnd(S3+ALB) its possible.","upvote_count":"1","timestamp":"1667004960.0"},{"timestamp":"1667005020.0","upvote_count":"1","comment_id":"706853","poster":"17Master","content":"For more information about using an Application Load Balancer as your origin for CloudFront, https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCustomOrigins.html#concept_elb_origin"}],"comment_id":"697338","timestamp":"1666004520.0"}],"upvote_count":"3","timestamp":"1665424740.0","poster":"Ekie"},{"timestamp":"1665411180.0","comment_id":"691236","comments":[],"content":"Selected Answer: C\ncan an ALB be an origin to CF? dont think so, only data sources.","poster":"ogerber","upvote_count":"1"},{"timestamp":"1665407520.0","content":"Selected Answer: A\nAA is much easier though","comment_id":"691165","upvote_count":"2","poster":"D2w"}],"question_images":[],"answers_community":["A (76%)","C (24%)"]},{"id":"NCIfVnYZuAxapgT7t2rv","question_text":"A company has implemented a self-managed DNS solution on three Amazon EC2 instances behind a Network Load Balancer (NLB) in the us-west-2 Region. Most of the company's users are located in the United States and Europe. The company wants to improve the performance and availability of the solution. The company launches and configures three EC2 instances in the eu-west-1 Region and adds the EC2 instances as targets for a new NLB.\nWhich solution can the company use to route traffic to all the EC2 instances?","answer":"B","answers_community":["B (79%)","A (18%)","3%"],"topic":"1","discussion":[{"timestamp":"1667087760.0","poster":"dokaedu","upvote_count":"21","comments":[{"poster":"EllenLiu","comment_id":"1326740","upvote_count":"1","timestamp":"1734247740.0","content":"A is not correct as should use NLB or ALB as the distribution origin?"},{"timestamp":"1689331680.0","comments":[{"content":"Just to complete my previous comment. If the scenario were that the company uses HTTP/HTTPS service, then the correct answer (as the original dokaedu message mentions) would be option D)","upvote_count":"3","comment_id":"951472","poster":"MutiverseAgent","timestamp":"1689333660.0"}],"comment_id":"951449","content":"After reading the discussion I think the right answer is B, as the service they use is DNS it does not make sense using a cloudfront distribution for this. The scenario would be different if the service were HTTP/HTTPS.","poster":"MutiverseAgent","upvote_count":"5"},{"comments":[{"poster":"pentium75","timestamp":"1703571900.0","comment_id":"1105763","content":"Who said that?","upvote_count":"3"}],"comment_id":"1046706","upvote_count":"2","timestamp":"1697614740.0","content":"Why I need replace NLB to ALB?","poster":"RNess"}],"comment_id":"707556","content":"B is the correct one for seld manage DNS\nIf need to use Route53, ALB (layar 7 ) needs to be used as end points for 2 reginal x 3 EC2s, if it the case answer would be the option 4"},{"content":"Selected Answer: B\nfor me it is B","upvote_count":"13","timestamp":"1666098300.0","comment_id":"698257","poster":"LeGloupier"},{"comment_id":"1337696","timestamp":"1736280780.0","upvote_count":"1","poster":"satyaammm","content":"Selected Answer: B\nAWS Global Accelerator is the most suitable here as it provides low latency and makes the AWS Network closer."},{"upvote_count":"2","poster":"PaulGa","content":"Selected Answer: B\nAns B - \"AWS Global Accelerator improves the availability and performance of your applications for global users by routing traffic to the optimal endpoint based on performance and policies.\"\n\nhttps://aws.amazon.com › global-accelerator › faqs","comment_id":"1284779","timestamp":"1726495680.0"},{"upvote_count":"3","timestamp":"1709254380.0","content":"Selected Answer: B\ni choose a previous until i checked google that tells me \"DNS is an Application-layer protocol\"","poster":"rityoui","comment_id":"1163136"},{"upvote_count":"1","comment_id":"1134815","poster":"thewalker","content":"Selected Answer: A\nA seems the right answer.","timestamp":"1706522760.0"},{"upvote_count":"5","comment_id":"1105765","timestamp":"1703572020.0","poster":"pentium75","content":"Selected Answer: B\nNot A: CloudFront is not for DNS\nNot C: Involves CloudFront which is not needed, otherwise would work but ignore the NLBs\nNot D: ALB can't handle DNS\nLeaves B"},{"comments":[{"content":"Route 53 geolocation has nothing to do with traffic in the sense that it does not affect the amount or speed of traffic that reaches your resources. It only affects how Route 53 responds to DNS queries based on the location of your users.","upvote_count":"2","comment_id":"1100678","poster":"SaurabhTiwari1","timestamp":"1702994580.0"}],"upvote_count":"3","content":"Selected Answer: B\nKeyword- \nAWS global accelerator = Super cop (who direct the traffic and give you the best way to reach your destination)\n\nGeolocation is use for showing web content as you want to show your web content to particular country or continent.\nGeolocation has nothing to do with traffic.","poster":"SaurabhTiwari1","comment_id":"1100674","timestamp":"1702994220.0"},{"content":"Option B. Create a standard accelerator in AWS Global Accelerator. Establish endpoint groups in us-west-2 and eu-west-1. Add two NLBs as endpoints of the endpoint group.\n\nAWS Global Accelerator is a network service that can provide a global traffic management solution. By creating a standard accelerator in AWS Global Accelerator, you can guide user traffic to the endpoint closest to them, thereby improving the performance and availability of the application. In this case, you can establish endpoint groups in the us-west-2 and eu-west-1 regions, and add two NLBs as endpoints. In this way, no matter where the user is located, their requests will be routed to the EC2 instance closest to them, thereby improving the performance and availability of DNS resolution. In addition, this design can also provide flexibility and scalability to handle a large amount of traffic. Therefore, this solution can meet your needs.","comment_id":"1078563","poster":"Masakichen","upvote_count":"8","timestamp":"1700756160.0"},{"content":"Global Accelerator: AWS Global Accelerator is designed to improve the availability and performance of applications by using static IP addresses (Anycast IPs) and routing traffic over the AWS global network infrastructure.\n\nEndpoint Groups: By creating endpoint groups in both the us-west-2 and eu-west-1 Regions, the company can effectively distribute traffic to the NLBs in both Regions. This improves availability and allows traffic to be directed to the closest Region based on latency.","poster":"Ruffyit","upvote_count":"2","comment_id":"1057060","timestamp":"1698603120.0"},{"poster":"tom_cruise","upvote_count":"2","comment_id":"1040765","timestamp":"1697035260.0","content":"Selected Answer: B\nKey: route traffic to all the EC2 instances"},{"poster":"Hassaoo","upvote_count":"4","comment_id":"994752","content":"B. Create a standard accelerator in AWS Global Accelerator. Create endpoint groups in us-west-2 and eu-west-1. Add the two NLBs as endpoints for the endpoint groups.\n\nHere's why this option is the most suitable:\n\nGlobal Accelerator: AWS Global Accelerator is designed to improve the availability and performance of applications by using static IP addresses (Anycast IPs) and routing traffic over the AWS global network infrastructure.\n\nEndpoint Groups: By creating endpoint groups in both the us-west-2 and eu-west-1 Regions, the company can effectively distribute traffic to the NLBs in both Regions. This improves availability and allows traffic to be directed to the closest Region based on latency.","timestamp":"1693457280.0"},{"poster":"Guru4Cloud","content":"Selected Answer: B\nB is the best solution to route traffic to all the EC2 instances across regions.\n\nThe key reasons are:\n\nAWS Global Accelerator allows routing traffic to endpoints in multiple AWS Regions. It uses the AWS global network to optimize availability and performance.\nCreating an accelerator with endpoint groups in us-west-2 and eu-west-1 allows traffic to be distributed across both regions.\nAdding the NLBs in each region as endpoints allows the traffic to be routed to the EC2 instances behind them.\nThis provides improved performance and availability compared to just using Route 53 geolocation routing.","upvote_count":"6","comment_id":"982511","timestamp":"1692187020.0"},{"timestamp":"1689249660.0","comment_id":"950639","content":"B\nroute requests to one of the two NLBs --> hence AD out / Attach Elastic IP addresses --> who will pay for it?","upvote_count":"2","poster":"MNotABot"},{"comment_id":"930642","upvote_count":"4","poster":"cookieMr","content":"Selected Answer: B\nOption B offers a global solution by utilizing Global Accelerator. By creating a standard accelerator and configuring endpoint groups in both Regions, the company can route traffic to all the EC2 across multiple regions. Adding the two NLBs as endpoints ensures that traffic is distributed effectively.\n\nOption A does not directly address the requirement of routing traffic to all EC2 instances. It focuses on routing based on geolocation and using CloudFront as a distribution, which may not achieve the desired outcome.\n\nOption C involves managing Elastic IP addresses and routing based on geolocation. However, it may not provide the same level of performance and availability as AWS Global Accelerator.\n\nOption D focuses on ALBs and latency-based routing. While it can be a valid solution, it does not utilize AWS Global Accelerator and may require more configuration and management compared to option B.","timestamp":"1687442520.0"},{"comment_id":"919196","upvote_count":"5","poster":"beginnercloud","timestamp":"1686307260.0","content":"Selected Answer: B\nCorrectly is B.\n\nif it is self-managed DNS, you cannot use Route 53. There can be only 1 DNS service for the domain."},{"upvote_count":"3","content":"Selected Answer: B\nFor self-managed DNS solution:\nhttps://aws.amazon.com/blogs/security/how-to-protect-a-self-managed-dns-service-against-ddos-attacks-using-aws-global-accelerator-and-aws-shield-advanced/","timestamp":"1683469620.0","poster":"studynoplay","comment_id":"891459"},{"content":"Selected Answer: B\nRe-wording the correct explanations here:\nif it is self-managed DNS, you cannot use Route 53. There can be only 1 DNS service for the domain. If the question didn't mentioned self-managed DNS and asked for optimal solution, then D is correct.","comment_id":"891457","timestamp":"1683469440.0","poster":"studynoplay","upvote_count":"6"},{"timestamp":"1683006120.0","upvote_count":"1","comment_id":"887049","content":"Using self managed DNS - other three options talking about Route 53 so B can only B answer","poster":"Yadav_Sanjay"},{"upvote_count":"1","poster":"tonyexim","content":"I think both answer A and B is solutions","timestamp":"1682560680.0","comment_id":"882154"},{"timestamp":"1681873800.0","content":"Selected Answer: B\nThe first half of Option A seems right. \"Create an Amazon Route 53 geolocation routing policy to route requests to one of the two NLBs.\", however, for the second part \"Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin.\" , it's totally useless. Route 53 can use geolocation routing directly route rquest to the NLBs","comment_id":"874251","upvote_count":"2","poster":"EricYu2023"},{"poster":"Musti35","upvote_count":"1","timestamp":"1681550940.0","comment_id":"870806","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/global-accelerator/?icmpid=docs_homepage_networking\nexplanation:\nAWS Global Accelerator Documentation\nAWS Global Accelerator is a network layer service in which you create accelerators to improve the security, availability, and performance of your applications for local and global users. Depending on the type of accelerator that you choose, you can gain additional benefits, such as improving availability or mapping users to specific destination endpoints."},{"upvote_count":"1","poster":"saransh_001","timestamp":"1680499260.0","comment_id":"859553","content":"Selected Answer: B\noption A although mentions geolocation routing and would allow the company to route traffic based on the location of the user. However, the company has already implemented a self-managed DNS solution and wants to use NLBs for load balancing, so it may not be feasible for them to switch to Route 53 and CloudFront."},{"content":"Selected Answer: A\noption A although mentions geolocation routing and would allow the company to route traffic based on the location of the user. However, the company has already implemented a self-managed DNS solution and wants to use NLBs for load balancing, so it may not be feasible for them to switch to Route 53 and CloudFront.","timestamp":"1680499200.0","poster":"saransh_001","comment_id":"859551","upvote_count":"1"},{"comment_id":"858973","comments":[{"content":"Gracias","poster":"jcramos","upvote_count":"2","comment_id":"861300","timestamp":"1680626220.0"}],"content":"Selected Answer: B\nLa opción A no es la solución óptima porque aunque puede enrutar el tráfico a uno de los dos NLB en función de la geolocalización, aún no proporciona una solución global para enrutar el tráfico a todas las instancias EC2.\n\nLa opción B es la solución adecuada porque permite que la empresa utilice AWS Global Accelerator para enrutar el tráfico a los NLB en ambas regiones, lo que permite que el tráfico se enrute automáticamente a las instancias EC2 en ambas regiones. AWS Global Accelerator se encarga de enrutar el tráfico de manera óptima a través de la red global de AWS para minimizar la latencia y mejorar el rendimiento y la disponibilidad de la solución.","poster":"TheAbsoluteTruth","upvote_count":"3","timestamp":"1680449340.0"},{"upvote_count":"2","content":"Selected Answer: B\n?\"The company wants to improve the performance and availability of the solution\": Geo location might be a good option if the question stressed on limiting access based on location. Since performance and availability are needed B is the right choice.","comment_id":"854510","timestamp":"1680099300.0","poster":"kraken21"},{"upvote_count":"3","timestamp":"1679602440.0","content":"Selected Answer: B\nBoth A and B will do the job... B provides access to the AWS backbone and therefore better performance","comment_id":"848633","poster":"Bang3R"},{"comment_id":"847120","poster":"MssP","content":"Selected Answer: B\n\"self-managed DNS solution\". You cannot make anything in Route53 if you don´t use :-) Answer is B","upvote_count":"1","timestamp":"1679492880.0"},{"content":"Selected Answer: B\nI vote B. \"A\" doesn't sound right. When NLB is used, it means it is redicting TCP/IP packets. CloudFont is used for Http request, not for TCP/IP","poster":"fkie4","comment_id":"835508","upvote_count":"1","timestamp":"1678488600.0"},{"upvote_count":"2","comment_id":"802309","poster":"Ouk","comments":[{"timestamp":"1677493440.0","comment_id":"823523","poster":"ahalamri","upvote_count":"2","content":"What do you mean ? we will fail ?"},{"upvote_count":"2","content":"Can you explain what you say?","comment_id":"822015","timestamp":"1677379020.0","poster":"Ja13"}],"content":"Selected Answer: A\nNot only this question, but in many replies for C03 questions seem intentionally wrong","timestamp":"1675877400.0"},{"timestamp":"1675752000.0","poster":"ProfXsamson","comments":[{"poster":"ProfXsamson","comment_id":"800622","timestamp":"1675752120.0","content":"For standard accelerators, Global Accelerator uses the AWS global network to route traffic to the optimal regional endpoint based on health, client location, and policies that you configure, which increases the availability of your applications. Endpoints for standard accelerators can be Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses that are located in one AWS Region or multiple Regions.","upvote_count":"1"}],"comment_id":"800619","upvote_count":"1","content":"Selected Answer: B\nWith a standard accelerator, Global Accelerator directs traffic over the AWS global network to endpoints in the nearest Region to the client."},{"comment_id":"792299","content":"Had a little chat with ChatGTP.\n(in this case) B is not the best option because it is meant for optimizing performance for users globally by directing traffic to the AWS Region that provides the lowest latency. However, in this case the company wants to improve performance and availability for its users located in the US and Europe, so using a geolocation routing policy in Amazon Route 53 would be more suitable.\n\nIf the question involved users globally, then option B would likely be the best solution. The standard accelerator in AWS Global Accelerator is specifically designed for optimizing performance for users globally by directing traffic to the AWS Region that provides the lowest latency. This would help improve the performance and availability of the company's self-managed DNS solution for users worldwide.","poster":"gogod2","comments":[{"upvote_count":"1","poster":"Rocky2023","comment_id":"798292","content":"I did same and getting both A & B when regenerated the response :)","timestamp":"1675538640.0"}],"timestamp":"1675044600.0","upvote_count":"2"},{"comment_id":"779104","poster":"remand","content":"Selected Answer: B\nB. Create a standard accelerator in AWS Global Accelerator. Create endpoint groups in us-west-2 and eu-west-1. Add the two NLBs as endpoints for the endpoint groups.\n\nAWS Global Accelerator is a service that improves the availability and performance of internet applications by routing traffic to the optimal AWS region for a given user. The company can create a standard accelerator and create endpoint groups in us-west-2 and eu-west-1. Then add the two NLBs as endpoints for the endpoint groups. This will allow the company to route traffic to all the EC2 instances based on the optimal region for the user.","upvote_count":"4","timestamp":"1673975280.0"},{"timestamp":"1673609280.0","upvote_count":"1","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/global-accelerator/latest/dg/what-is-global-accelerator.html","comment_id":"774380","poster":"Vickysss"},{"timestamp":"1672945440.0","upvote_count":"2","content":"Selected Answer: A\nThough Option A and B are valid, the question is on Administration efficiency. Since only 2 regions are in consideration, it is much easier to provision WAF than a central Firewall Manager (plus WAF). \n\nRegarding \"to protect API Gateways across multiple accounts\". may be it is an extra information. Web ACLs are at regional level, essentially filters out HTTP messages irrespective of the account i.e., it is applicable to all accounts.","poster":"Mahadeva","comment_id":"766965"},{"poster":"dan80","timestamp":"1672875480.0","comment_id":"766148","upvote_count":"2","content":"Selected Answer: B\nhttps://aws.amazon.com/global-accelerator/"},{"content":"B is correct answer. \nUse case - Use traffic dials to route traffic to the nearest Region or achieve fast failover across Regions in the case to the users in there appropriate regions. https://aws.amazon.com/global-accelerator/\n\nA - incorrect as DNS is self managed just in the us not eu","poster":"Mindvision","timestamp":"1672512780.0","upvote_count":"2","comment_id":"762860"},{"timestamp":"1672492560.0","content":"Selected Answer: A\nB solution is not correct because it does not fully address the requirements of the question.\n\nAWS Global Accelerator is a service that routes traffic over the Amazon global network to the optimal AWS Region for the user, based on network performance. It does not allow routing based on the geographic location of the user.","comments":[{"upvote_count":"1","content":"But the question is for \"improving performance and availability.\" Network performance is offered by Global Accelerator. Why should a European user be stuck on Euro region if the US-West offers better network performance? Geolocation binds a user to Location. \n\nIn addition to Performance, Global Accelerator offers Failover to other region (satisfies another part of the question -- solution to make use of all EC2 instances across regions).","comment_id":"767000","timestamp":"1672947120.0","poster":"Mahadeva"}],"comment_id":"762658","upvote_count":"3","poster":"Zerotn3"},{"comment_id":"759162","comments":[{"poster":"Buruguduystunstugudunstuy","upvote_count":"1","comment_id":"759163","content":"To implement this solution, the company can create a geolocation routing policy in Amazon Route 53 and specify the two NLBs as the target resources. The company can then create an Amazon CloudFront distribution and use the Route 53 record as the origin for the distribution. This will allow the company to distribute traffic to the NLBs through the CloudFront distribution, improving the performance and availability of the DNS solution.","timestamp":"1672184580.0"}],"timestamp":"1672184520.0","poster":"Buruguduystunstugudunstuy","upvote_count":"3","content":"Selected Answer: A\nThe correct solution is Option A. Create an Amazon Route 53 geolocation routing policy to route requests to one of the two NLBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin.\n\nTo improve the performance and availability of the self-managed DNS solution, the company can use Amazon Route 53 geolocation routing to route traffic to the NLBs that are closest to the users. Geolocation routing allows the company to route traffic to a specific resource based on the geographic location of the user making the request. By using geolocation routing, the company can ensure that users are directed to the NLBs that are closest to them, improving the performance of the DNS solution."},{"poster":"duriselvan","comment_id":"754161","content":"company wants to improve the performance\n\nAWS Global Accelerator\nImprove application availability, performance, and security using the AWS global network\n\nhttps://aws.amazon.com/global-accelerator/","timestamp":"1671795780.0","upvote_count":"1"},{"comment_id":"754160","timestamp":"1671795720.0","content":"B is correct ans","poster":"duriselvan","upvote_count":"2"},{"comment_id":"750793","upvote_count":"2","timestamp":"1671536220.0","poster":"Manoj26","content":"I would pick B\nhttps://aws.amazon.com/global-accelerator/"},{"comment_id":"740720","poster":"lapaki","content":"Selected Answer: B\nB. We don’t need services from the other answers.","timestamp":"1670653200.0","upvote_count":"1"},{"poster":"Newptone","content":"Selected Answer: B\nFor option A: Create an Amazon CloudFront distribution.\nDNS is tcp/udp only, you can not use CF to cache the traffic.","comment_id":"727358","upvote_count":"2","timestamp":"1669447080.0"},{"upvote_count":"1","timestamp":"1669062180.0","poster":"jhxetc","content":"Selected Answer: B\nB makes the most sense since is not for a web app, but rather a DNS solution. We probably don't need to involve Route 53 (itself a DNS solution).","comment_id":"723883"},{"poster":"grzeev","upvote_count":"3","timestamp":"1669025820.0","content":"Selected Answer: D\nfor me it is D","comment_id":"723381"},{"timestamp":"1668368820.0","comment_id":"717488","content":"Selected Answer: B\nWS Global Accelerator is a networking service that helps you improve the availability and performance of the applications that you offer to your global users. AWS Global Accelerator is easy to set up, configure, and manage. It provides static IP addresses that provide a fixed entry point to your applications and eliminate the complexity of managing specific IP addresses for different AWS Regions and Availability Zones. AWS Global Accelerator always routes user traffic to the optimal endpoint based on performance, reacting instantly to changes in application health, your user’s location, and policies that you configure\n\nhttps://aws.amazon.com/global-accelerator/faqs/","poster":"Jtic","upvote_count":"2"},{"timestamp":"1668068580.0","poster":"KADSM","comment_id":"715042","upvote_count":"2","content":"It should be A. As in B - The solution is about using Standard accelerator. It may need custom routing accelerator to route the traffic to specific EC2 instance. \n\nCustom routing accelerator\nCustom routing accelerators are a new type of accelerator in AWS Global Accelerator. This new accelerator lets you use your own application logic to route user traffic to a specific Amazon EC2 instance destination in a single or multiple AWS Regions. . A custom routing accelerator is an alternative to the standard accelerator, which automatically routes traffic to a healthy endpoint that is nearest to your users. Because standard accelerators are designed to load balance traffic, you can't use them to route users to a specific EC2 instance destination behind your accelerator."},{"poster":"SimonPark","comment_id":"707607","timestamp":"1667105700.0","comments":[{"comment_id":"754633","upvote_count":"1","poster":"career360guru","comments":[{"comment_id":"951447","content":"Iteresting point career360guru","upvote_count":"1","poster":"MutiverseAgent","timestamp":"1689331380.0"}],"timestamp":"1671844680.0","content":"A is not correct as Cloudfront does not support TCP/UDP. We are talking about DNS which uses UDP or TCP connections"}],"upvote_count":"1","content":"Selected Answer: A\nimho, it's A"},{"poster":"Six_Fingered_Jose","timestamp":"1666800540.0","upvote_count":"5","comment_id":"704850","content":"Selected Answer: A\nI think it is A,\nif you carefully read the document below, with GA routing is managed manually in multi-region applications\n> Your traffic routing is managed manually\nhttps://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/view/30/\n\nthus, Route53 geolocation seems to be the only solution to this problem (routing to different resources on different regions based on user's geolocation)"},{"comment_id":"699905","upvote_count":"4","poster":"Evangelia","timestamp":"1666268820.0","content":"B for self managed DNS solution"}],"isMC":true,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/85807-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"answer_description":"","choices":{"B":"Create a standard accelerator in AWS Global Accelerator. Create endpoint groups in us-west-2 and eu-west-1. Add the two NLBs as endpoints for the endpoint groups.","C":"Attach Elastic IP addresses to the six EC2 instances. Create an Amazon Route 53 geolocation routing policy to route requests to one of the six EC2 instances. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution's origin.","A":"Create an Amazon Route 53 geolocation routing policy to route requests to one of the two NLBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin.","D":"Replace the two NLBs with two Application Load Balancers (ALBs). Create an Amazon Route 53 latency routing policy to route requests to one of the two ALBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin."},"unix_timestamp":1666098300,"answer_images":[],"answer_ET":"B","timestamp":"2022-10-18 15:05:00","question_id":45}],"exam":{"lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"id":31,"isMCOnly":true,"provider":"Amazon","name":"AWS Certified Solutions Architect - Associate SAA-C03","isBeta":false,"isImplemented":true},"currentPage":9},"__N_SSP":true}