{"pageProps":{"questions":[{"id":"ESdkCxpiZvWurH3o5TgG","question_text":"A company has multiple lines of business (LOBs) that roll up to the parent company. The company has asked its solutions architect to develop a solution with the following requirements:\n• Produce a single AWS invoice for all of the AWS accounts used by its LOBs.\n• The costs for each LOB account should be broken out on the invoice.\n• Provide the ability to restrict services and features in the LOB accounts, as defined by the company's governance policy.\n• Each LOB account should be delegated full administrator permissions, regardless of the governance policy.\n\nWhich combination of steps should the solutions architect take to meet these requirements? (Choose two.)","answers_community":["BD (57%)","BE (38%)","5%"],"exam_id":33,"answer_images":[],"answer_description":"","isMC":true,"discussion":[{"upvote_count":"14","timestamp":"1714963440.0","comment_id":"1207135","content":"Selected Answer: BD\nE: Is wrong --> Consolidated billing is already enabled by default when you create an organization\n\nB: obvious\nD: since there are no OUs, I assume that the SCP applies to each LOB account","poster":"7f6aef3"},{"comment_id":"1161404","poster":"chelbsik","upvote_count":"8","timestamp":"1709109420.0","comments":[{"poster":"juanife","content":"I agree with you on that point","timestamp":"1717158300.0","upvote_count":"1","comment_id":"1222141"},{"content":"D does not conflict, they can be full administrators in their accounts but not have access to all services, one does not conflict with the other","upvote_count":"3","comment_id":"1209022","timestamp":"1715277000.0","poster":"e4bc18e"}],"content":"Selected Answer: BE\nI choose BE\nD conficts with the last requirement"},{"upvote_count":"1","timestamp":"1735567920.0","content":"Selected Answer: BD\nThis is a very interesting question. While the answer appears to be B + D, the solution could be further enhanced by including option E.\n\nHowever, given the question's emphasis on restricting services within each Line of Business (LOB), B + D likely represents the most suitable choice.","comment_id":"1334185","poster":"PSPaul"},{"content":"Selected Answer: BD\nIt should be B and D\nBut it's not really true. To have B + D +E together is perfect\n\nTo response this question BD is would be ok","timestamp":"1735567500.0","upvote_count":"1","comment_id":"1334183","poster":"PSPaul"},{"upvote_count":"1","timestamp":"1735241700.0","content":"Selected Answer: AD\nIf we choose E are we saying that we only enable Consolidated billing feature of Organization and not all features. Because then we cannot even use SCP ? \n\nD is not entirely correct as well - SCP are there to Deny and set perimeter, instead of allowing","poster":"pk0619","comment_id":"1332096"},{"poster":"0b43291","upvote_count":"1","comment_id":"1312407","content":"Selected Answer: BD\nB. Use AWS Organizations to create a single organization in the parent account and invite each LOB's AWS account to join. This allows: - Producing a single invoice for all accounts (consolidated billing). - Breaking out costs for each LOB account. - Delegating full administrator permissions to LOB accounts (through SCPs).\n\nD. Create an SCP that allows only approved services and features based on the governance policy, and apply it to the LOB accounts. SCPs in AWS Organizations define rules for what services and resources can be used in member accounts. This restricts available services and features for LOB accounts while allowing full administrator permissions within defined boundaries.","timestamp":"1731647100.0"},{"upvote_count":"1","poster":"tgv","comment_id":"1268432","timestamp":"1724048520.0","content":"Selected Answer: BD\nB D\nD is required for governance"},{"content":"For SAP 01 version D and E were in the same option, so the answer is B - D+E","upvote_count":"2","timestamp":"1722763920.0","comment_id":"1260586","poster":"zolthar_z"},{"comment_id":"1229173","timestamp":"1718198340.0","content":"Selected Answer: BD\nB D because Consolidated billing is already enabled by default when you create an organization","upvote_count":"1","poster":"trungtd"},{"comment_id":"1218994","poster":"naylinu","upvote_count":"1","timestamp":"1716731040.0","content":"It should chose 3 ......... A + E . And D is require for governance","comments":[{"timestamp":"1716731100.0","comment_id":"1218995","content":"Sorry B + E . And D is require for governance","upvote_count":"2","poster":"naylinu"}]},{"comment_id":"1214887","poster":"teo2157","content":"Selected Answer: BE\nWe have to read carefully the question, it says \"Provide the ability to restrict services and features in the LOB accounts, as defined by the company's governance policy.\", Organizations itself provide that ability but the question is not saying anything about to apply SCPs immediatelly to the OUs but just to have that ability. So for me D is discarded due to that.","upvote_count":"4","timestamp":"1716290280.0"},{"comment_id":"1206051","poster":"seetpt","upvote_count":"2","content":"Selected Answer: BE\nBE for me","timestamp":"1714733580.0"},{"timestamp":"1713121680.0","comment_id":"1195664","content":"The number of answers can not satisfy the question objectives.\n“Produce a single AWS invoice for all of the AWS accounts used by its LOBs.” B\n“The costs for each LOB account should be broken out on the invoice.” E is trying to address this requirement, but has flaw. \n“Provide the ability to restrict services and features in the LOB accounts, as defined by the company's governance policy.” D, but the policy should be applied to OU instead of Account.\n“Each LOB account should be delegated full administrator permissions, regardless of the governance policy.” NO answer is addressing this requirement.","upvote_count":"2","poster":"bjexamprep"},{"poster":"Keval12345","content":"Selected Answer: BD\nI think there should bbe choose 3 options here. BDE","comment_id":"1192237","timestamp":"1712661480.0","upvote_count":"3"},{"content":"Selected Answer: BE\nIt should be BE. D just clearly broke the requirement of \"each LOB account should be delegated full administrator permissions, regardless of the governance policy.\".","upvote_count":"4","comment_id":"1186545","timestamp":"1711852680.0","poster":"VerRi"},{"timestamp":"1710922020.0","content":"Could it be A, C? Service quotas is a terrible way of restricting features but it's the only one that satisfies the last 2 requirements.","poster":"djangoUnchained","comment_id":"1178022","upvote_count":"1","comments":[{"upvote_count":"2","poster":"djangoUnchained","content":"Forget it, answer is BD. In the SCP you can grant an exception to not limit the admin accounts.","comment_id":"1180034","timestamp":"1711108440.0"}]},{"upvote_count":"2","content":"Selected Answer: BD\nB and D","timestamp":"1710021960.0","poster":"career360guru","comment_id":"1169881"},{"timestamp":"1709521140.0","upvote_count":"1","comment_id":"1165258","poster":"thotwielder","content":"Selected Answer: AD\nThe question asks for billing at LOB level not at a company level. So A, not B."},{"upvote_count":"2","poster":"a54b16f","comment_id":"1160862","content":"Selected Answer: BD\nCan't be A, unless it changes to OU","timestamp":"1709054400.0"},{"content":"I think something is missing in this question related to tags.","poster":"igor12ghsj577","comment_id":"1147179","timestamp":"1707650280.0","upvote_count":"1"},{"poster":"TheCloudGuruu","comment_id":"1145511","timestamp":"1707486060.0","upvote_count":"3","content":"Selected Answer: BE\nB and E"},{"content":"Why not B and E? SCP will restrict the other accounts which contradicts the last requirement. We would have to go B and E for that reason","comments":[{"comments":[{"content":"The second step is sending the invite. So B breaks down the actual steps required.","comment_id":"1145712","timestamp":"1707505020.0","upvote_count":"1","poster":"kejam"}],"upvote_count":"1","poster":"kejam","timestamp":"1707504900.0","comment_id":"1145710","content":"The first step in enabling consolidated billing is creating the Organization."}],"poster":"981809e","comment_id":"1143823","timestamp":"1707340080.0","upvote_count":"2"},{"comment_id":"1142957","poster":"kejam","content":"Selected Answer: BD\nAnswer BD:\nChanged my answer because of this text in A: \"Then invite each LOB account to the appropriate organization.\"","timestamp":"1707282180.0","upvote_count":"2"},{"comment_id":"1142954","content":"Selected Answer: AD\nAnswer AD:\n\nA: Creates a separate organization (unit) for each LOB, useful for LOB billing.\nD: SCPs to limit only approved services as defined by the governance policy.","poster":"kejam","timestamp":"1707281820.0","upvote_count":"1","comments":[]},{"comment_id":"1141717","poster":"alexis123456","timestamp":"1707187560.0","upvote_count":"4","content":"Selected Answer: BD\ncorrect answer is B and D"},{"poster":"duriselvan","content":"D,E ANS","comment_id":"1141262","upvote_count":"1","timestamp":"1707149220.0"}],"answer":"BD","timestamp":"2024-02-05 17:07:00","unix_timestamp":1707149220,"question_id":381,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/132869-exam-aws-certified-solutions-architect-professional-sap-c02/","topic":"1","choices":{"D":"Create an SCP that allows only approved services and features, then apply the policy to the LOB accounts.","C":"Implement service quotas to define the services and features that are permitted and apply the quotas to each LOB. as appropriate.","B":"Use AWS Organizations to create a single organization in the parent account. Then, invite each LOB's AWS account to join the organization.","A":"Use AWS Organizations to create an organization in the parent account for each LOB. Then invite each LOB account to the appropriate organization.","E":"Enable consolidated billing in the parent account's billing console and link the LOB accounts."},"answer_ET":"BD"},{"id":"2vXD5StO3MjgBxyElqjI","answer_ET":"DE","discussion":[{"comment_id":"1312409","poster":"0b43291","content":"D. The \"Evaluate Target Health\" setting is not enabled for the latency alias record set associated with the stopped Region. When using latency routing, this setting must be enabled so Route 53 considers the health status of associated resources and stops routing traffic to unavailable servers.\n\nE. HTTP health checks are not set up for one or more weighted record sets associated with the stopped web servers. Without health checks, Route 53 cannot detect unhealthy or unavailable servers and will continue routing traffic to them.","upvote_count":"3","timestamp":"1731647940.0"},{"upvote_count":"4","comment_id":"1223890","poster":"trungtd","timestamp":"1717473180.0","content":"Selected Answer: DE\nRoute 53 latency-based routing does not inherently perform health checks. If a web server in one region goes down, Route 53 won't automatically redirect traffic to the other region unless health checks are properly configured and associated with your DNS records."},{"poster":"career360guru","content":"Selected Answer: DE\nOption D and E","timestamp":"1710022860.0","upvote_count":"1","comment_id":"1169889"},{"timestamp":"1707588660.0","content":"Selected Answer: DE\nDE are the correct answers for the given scenario","comment_id":"1146561","upvote_count":"1","poster":"Russs99"},{"comment_id":"1142966","upvote_count":"4","content":"Selected Answer: DE\nAnswer DE:\n\nAn antique/classic question, answers are in a different order and wording slightly changed.\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html","poster":"kejam","timestamp":"1707283020.0"},{"timestamp":"1707193020.0","poster":"alexis123456","upvote_count":"2","content":"Selected Answer: DE\ncorrect answer is D an E","comment_id":"1141720"}],"exam_id":33,"answer_images":[],"timestamp":"2024-02-06 03:49:00","choices":{"D":"The setting to evaluate target health is not turned on for the latency alias resource record set that is associated with the domain in the Region where the web servers were stopped.","E":"An HTTP health check has not been set up for one or more of the weighted resource record sets associated with the stopped web servers.","B":"One of the web servers in the secondary Region did not pass its HTTP health check.","C":"Latency resource record sets cannot be used in combination with weighted resource record sets.","A":"The weight for the Region where the web servers were stopped is higher than the weight for the other Region."},"question_images":[],"question_id":382,"url":"https://www.examtopics.com/discussions/amazon/view/132993-exam-aws-certified-solutions-architect-professional-sap-c02/","question_text":"A solutions architect has deployed a web application that serves users across two AWS Regions under a custom domain. The application uses Amazon Route 53 latency-based routing. The solutions architect has associated weighted record sets with a pair of web servers in separate Availability Zones for each Region.\n\nThe solutions architect runs a disaster recovery scenario. When all the web servers in one Region are stopped, Route 53 does not automatically redirect users to the other Region.\n\nWhich of the following are possible root causes of this issue? (Choose two.)","isMC":true,"unix_timestamp":1707187740,"answer_description":"","topic":"1","answers_community":["DE (100%)"],"answer":"DE"},{"id":"G5bMcE65SkD4Db5ERLZC","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/136546-exam-aws-certified-solutions-architect-professional-sap-c02/","question_id":383,"answer_description":"","discussion":[{"content":"Selected Answer: B\nKinesis Data Firehose is well-suited for ingesting and processing streaming data at scale, such as the continuous updates from the water-level monitoring sensors. It can reliably capture and deliver data to various destinations, including S3, without requiring additional application code.\n\nStoring the data in Apache Parquet format in S3 offers several benefits. Parquet is a columnar storage format optimized for analytics workloads, providing efficient compression and query performance. This format is suitable for data analysis and querying using tools like Athena.\n\nUsing AWS Lambda to transform the data from Kinesis Data Firehose into Parquet format reduces the maintenance effort associated with managing traditional servers. Lambda automatically scales with the incoming workload, ensuring continuous data processing without downtime.","upvote_count":"7","timestamp":"1710818220.0","poster":"CMMC","comment_id":"1176961"},{"poster":"mifune","comment_id":"1209704","timestamp":"1715425680.0","upvote_count":"5","content":"Selected Answer: B\nLamda functions integrates with Data Firehouse better than sending the data to Apache Flink and then implement a solution to transform the data into the Parquet Format to be sent to S3. From AWS Documentation: \"With Amazon Managed Service for Apache Flink, you can use Java, Scala, Python, or SQL to process and analyze streaming data\". So, Flink does not make any authomatic data transformation. The correct option is B."},{"timestamp":"1733125080.0","poster":"dv1","upvote_count":"1","comment_id":"1320826","content":"Selected Answer: B\nManaged service for apache flink cannot ingest streaming data directly. This means that anything flink is out. Best remaining answer is B."},{"comment_id":"1296252","upvote_count":"1","content":"Selected Answer: B\nOption B is the most suitable solution as it leverages serverless and scalable services (Kinesis Data Firehose, Lambda, S3, and Athena) to handle data ingestion, transformation, and analysis with minimal operational overhead and optimized costs.","poster":"JoeTromundo","timestamp":"1728681120.0"},{"poster":"sammyhaj","comments":[{"comments":[{"comment_id":"1358582","content":"KDF cannot directly write to Aurora DB, and the lambda function that KDF invoked is for transformation only.","timestamp":"1739942040.0","poster":"altonh","upvote_count":"1"}],"comment_id":"1358581","timestamp":"1739941980.0","upvote_count":"1","poster":"altonh","content":"KDF Aurora DB directly, and the lambda function that KDF invoked is for transformation only."},{"content":"The statement does not say that it is necessary to continue storing the data in human readable form.\nThe statement says that the agency wants to increase overall application availability and reduce the effort that is required to perform maintenance tasks. These are the requirements.","upvote_count":"1","poster":"JoeTromundo","timestamp":"1728681060.0","comment_id":"1296251"}],"timestamp":"1723733520.0","upvote_count":"3","content":"Selected Answer: A\nIt says convert to human readable, that isn't Parquet, its CSV","comment_id":"1266505"},{"timestamp":"1715230200.0","upvote_count":"2","poster":"nileshlg","comment_id":"1208695","content":"D seems to be the correct option as its a managed service"},{"comment_id":"1206052","upvote_count":"2","content":"Selected Answer: B\nB for me","poster":"seetpt","timestamp":"1714733640.0"},{"poster":"titi_r","upvote_count":"3","content":"Selected Answer: B\n“B” seems to be the correct ans. Amazon Data Firehose can ingest data streams from IoT and convert them to into Parquet format using Lambda function. The destination of the stream can be S3.\nhttps://aws.amazon.com/firehose/\nhttps://d1.awsstatic.com/pdp-how-it-works-assets/Product-Pate-Diagram-Amazon-Kinesis-Data-Firehose%402x.39ea068e48494676c0f4386535f85a966e9ac252.png","timestamp":"1713877980.0","comment_id":"1200747"},{"timestamp":"1713336900.0","poster":"tushar321","upvote_count":"1","content":"D seems a better fit as Apache flink is a managed services for steaming as well as transformation. makes things simpler","comment_id":"1197044"},{"upvote_count":"4","timestamp":"1712059260.0","content":"Selected Answer: B\nBoth B and D are work.\nB - KDF&Lambda for data transformation\nD - KDA for real-time analysis","comment_id":"1188011","poster":"VerRi"},{"upvote_count":"1","comment_id":"1186136","content":"Selected Answer: D\nUsing a managed service for data transformation optimizes operational overhead.","poster":"Wilson_S","timestamp":"1711808040.0"},{"poster":"oayoade","content":"Selected Answer: A\n\"human readable format\", I go with CSV","timestamp":"1710972720.0","upvote_count":"3","comment_id":"1178784"},{"upvote_count":"3","poster":"Russs99","comment_id":"1178711","timestamp":"1710969000.0","content":"Selected Answer: B\nAlthough option D call work, it introduces unnecessary complexity for the given scenario."},{"upvote_count":"2","timestamp":"1710954420.0","poster":"Dgix","content":"Selected Answer: D\nAnswer is D.","comment_id":"1178527"},{"poster":"Sathya","timestamp":"1710816300.0","upvote_count":"1","content":"Answer is D","comment_id":"1176949"}],"answers_community":["B (74%)","A (17%)","9%"],"answer":"B","unix_timestamp":1710816300,"exam_id":33,"answer_images":[],"timestamp":"2024-03-19 03:45:00","isMC":true,"question_text":"A flood monitoring agency has deployed more than 10,000 water-level monitoring sensors. Sensors send continuous data updates, and each update is less than 1 MB in size. The agency has a fleet of on-premises application servers. These servers receive updates from the sensors, convert the raw data into a human readable format, and write the results to an on-premises relational database server. Data analysts then use simple SQL queries to monitor the data.\n\nThe agency wants to increase overall application availability and reduce the effort that is required to perform maintenance tasks. These maintenance tasks, which include updates and patches to the application servers, cause downtime. While an application server is down, data is lost from sensors because the remaining servers cannot handle the entire workload.\n\nThe agency wants a solution that optimizes operational overhead and costs. A solutions architect recommends the use of AWS IoT Core to collect the sensor data.\n\nWhat else should the solutions architect recommend to meet these requirements?","answer_ET":"B","topic":"1","choices":{"A":"Send the sensor data to Amazon Kinesis Data Firehose. Use an AWS Lambda function to read the Kinesis Data Firehose data, convert it to .csv format, and insert it into an Amazon Aurora MySQL DB instance. Instruct the data analysts to query the data directly from the DB instance.","B":"Send the sensor data to Amazon Kinesis Data Firehose. Use an AWS Lambda function to read the Kinesis Data Firehose data, convert it to Apache Parquet format, and save it to an Amazon S3 bucket. Instruct the data analysts to query the data by using Amazon Athena.","C":"Send the sensor data to an Amazon Managed Service for Apache Flink (previously known as Amazon Kinesis Data Analytics) application to convert the data to .csv format and store it in an Amazon S3 bucket. Import the data into an Amazon Aurora MySQL DB instance. Instruct the data analysts to query the data directly from the DB instance.","D":"Send the sensor data to an Amazon Managed Service for Apache Flink (previously known as Amazon Kinesis Data Analytics) application to convert the data to Apache Parquet format and store it in an Amazon S3 bucket. Instruct the data analysts to query the data by using Amazon Athena."}},{"id":"0k9irbO38Cv4PinZS2Jm","answer_ET":"BE","question_images":[],"answer":"BE","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/136548-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_description":"","question_id":384,"exam_id":33,"timestamp":"2024-03-19 04:29:00","isMC":true,"choices":{"B":"Configure the target group health check to point at a simple HTML page instead of a product catalog page and the Amazon Route 53 health check against the product page to evaluate full application functionality. Configure Amazon CloudWatch alarms to notify administrators when the site fails.","D":"Configure an Amazon CloudWatch alarm for Amazon RDS with an action to recover a high-load, impaired RDS instance in the database tier.","C":"Configure the target group health check to use a TCP check of the Amazon EC2 web server and the Amazon Route 53 health check against the product page to evaluate full application functionality. Configure Amazon CloudWatch alarms to notify administrators when the site fails.","E":"Configure an Amazon ElastiCache cluster and place it between the web application and RDS MySQL instances to reduce the load on the backend database tier.","A":"Configure read replicas for Amazon RDS MySQL and use the single reader endpoint in the web application to reduce the load on the backend database tier."},"answer_images":[],"unix_timestamp":1710818940,"discussion":[{"comment_id":"1190666","timestamp":"1712447940.0","content":"Selected Answer: BE\nMy answer is a bit difference.\nIt doesn't mentioned read-only scnerio so read replica in A may not able to help\ncompare B and C, both pro and con. I lean to B from both the real world and in this particual question to bypass the database","poster":"pangchn","upvote_count":"9"},{"comment_id":"1192252","upvote_count":"8","poster":"Capt_Leonidas","content":"Selected Answer: BE\nhttps://www.examtopics.com/discussions/amazon/view/46826-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"1712663040.0"},{"content":"Selected Answer: BE\nB and E works as expection.\nDue to web app is normal, A and C can not help\nCloudWatch alarm can not support so complicated action","upvote_count":"1","poster":"vip2","timestamp":"1720411980.0","comment_id":"1244074"},{"upvote_count":"2","content":"Selected Answer: BE\nWhen you talking about a product catalog page, you need to cache information (text, images) to leverage the load on the data tier. ElastiCache is the solution (or a CDN).","timestamp":"1717681260.0","poster":"michele_scar","comment_id":"1225552"},{"content":"A & E is correct answer as the monitoring aspect is not part of the problem statement","timestamp":"1716857820.0","comment_id":"1219921","poster":"9f02c8d","upvote_count":"1"},{"comment_id":"1212442","timestamp":"1715868120.0","upvote_count":"3","content":"Selected Answer: AB\nA and B are my answers.\nA instead of E only because we have no tips that indicate the necessity to have a caching systems. For example, it say \"high load on database\", but nothing about same record read more more time.\nSo for me A and B","poster":"red_panda"},{"upvote_count":"3","timestamp":"1714733760.0","comment_id":"1206055","poster":"seetpt","content":"Selected Answer: BE\nBE for me"},{"timestamp":"1713878580.0","content":"Selected Answer: BE\nB and E.","comment_id":"1200760","poster":"titi_r","upvote_count":"4"},{"timestamp":"1712595180.0","poster":"w3ap0nx","content":"Selected Answer: BE\n\"for future growth\" -> E (cache in front of the DB)","upvote_count":"5","comment_id":"1191692"},{"content":"Selected Answer: BE\nB: Will improve web app\nD: Will improve database high load issue and query response times.","upvote_count":"4","timestamp":"1712494980.0","poster":"ovladan","comment_id":"1190955"},{"poster":"VerRi","timestamp":"1712059980.0","upvote_count":"2","content":"Selected Answer: AB\nTCP check is like a heartbeat check, too rough.","comment_id":"1188024"},{"upvote_count":"2","comment_id":"1183816","poster":"failexamonly","timestamp":"1711507920.0","content":"Selected Answer: AC\nread replica to reduce load.\ntcp check to see if ec2 is reachable"},{"upvote_count":"2","timestamp":"1711137540.0","content":"I agree with A and B .","poster":"AWSPro1234","comment_id":"1180289"},{"upvote_count":"3","timestamp":"1710970140.0","comment_id":"1178732","poster":"Russs99","content":"Selected Answer: A\nA and B are my picks"},{"poster":"Dgix","content":"By the way, ExamTopics, we get a 503 when submitting voting comments. Please change my previous submission to that type, specifying A and C.","timestamp":"1710956340.0","comment_id":"1178558","upvote_count":"1"},{"poster":"Dgix","content":"First of all: the instances are terminated because the load on the DB is too high.\n\nA: Best way to reduce the load on the DB. It doesn't notify admins, though, which means we then need either B or C (D and E do not notify admins).\nB: Health checks do not burden the site as they are done relatively seldom, so trying to reduce load by using a page that's lighter on the DB is not very relevant. Notifies admins.\nC: TCP checks are lighter on the load than HTTP checks, which means the already slight overhead for health checks is reduced further than in B. Notifies admins. This is preferable to B, but both feel inconsequential.\nD: Recovery actions in this situation are out of scope. This alternative is there to confuse.\nE: An alternative to A, but it has operational overhead in that the application must be changed to use the cache. A is more straightforward.\n\nThus A and C.","timestamp":"1710956220.0","upvote_count":"2","comment_id":"1178557"},{"upvote_count":"3","content":"Selected Answer: AB\nB. Health check is failing because the application cannot read from the DB, event though the EC2 instance is fine. As a result the ALB is terminating the EC2 instance unnecessarily.","timestamp":"1710923040.0","comment_id":"1178035","poster":"djangoUnchained"},{"content":"Selected Answer: AD\nConfiguring read replicas for Amazon RDS MySQL and using the single reader endpoint in the web application would help distribute the DB workload across multiple instances, and that can alleviate performance issues during high load. Prevent DB-related outages and improve overall application availability.\n\nConfiguring a CloudWatch alarm for Amazon RDS with an action to recover a high-load, impaired RDS instance in the DB tier enables proactive monitoring and automated recovery in case of DB performance issues. Can trigger automated actions during high load to recover the instance, such as initiating a failover in the Multi-AZ deployment. Ensure that the DB tier remains stable and responsive, reducing the likelihood of application outages.","poster":"CMMC","upvote_count":"1","timestamp":"1710818940.0","comment_id":"1176963"}],"question_text":"A public retail web application uses an Application Load Balancer (ALB) in front of Amazon EC2 instances running across multiple Availability Zones (AZs) in a Region backed by an Amazon RDS MySQL Multi-AZ deployment. Target group health checks are configured to use HTTP and pointed at the product catalog page. Auto Scaling is configured to maintain the web fleet size based on the ALB health check.\n\nRecently, the application experienced an outage. Auto Scaling continuously replaced the instances during the outage. A subsequent investigation determined that the web server metrics were within the normal range, but the database tier was experiencing high load, resulting in severely elevated query response times.\n\nWhich of the following changes together would remediate these issues while improving monitoring capabilities for the availability and functionality of the entire application stack for future growth? (Choose two.)","answers_community":["BE (70%)","AB (17%)","7%"]},{"id":"Qvo4zZxIJsvKCYn8zuDi","answer_images":[],"question_images":[],"timestamp":"2024-03-19 04:38:00","topic":"1","exam_id":33,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/136549-exam-aws-certified-solutions-architect-professional-sap-c02/","unix_timestamp":1710819480,"answer_ET":"A","answer":"A","question_id":385,"question_text":"A company has an on-premises data center and is using Kubernetes to develop a new solution on AWS. The company uses Amazon Elastic Kubernetes Service (Amazon EKS) clusters for its development and test environments.\n\nThe EKS control plane and data plane for production workloads must reside on premises. The company needs an AWS managed solution for Kubernetes management.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","choices":{"C":"Install an AWS Outposts server in the on-premises data center. Deploy Amazon EKS by using an extended cluster configuration on the Outposts server for the production workloads.","A":"Install an AWS Outposts server in the on-premises data center. Deploy Amazon EKS by using a local cluster configuration on the Outposts server for the production workloads.","B":"Install Amazon EKS Anywhere on the company's hardware in the on-premises data center. Deploy the production workloads on an EKS Anywhere cluster.","D":"Install an AWS Outposts server in the on-premises data center. Install Amazon EKS Anywhere on the Outposts server. Deploy the production workloads on an EKS Anywhere cluster."},"answers_community":["A (80%)","14%","6%"],"isMC":true,"discussion":[{"content":"Selected Answer: A\nA\n3 things to consider fromr question requirement\ncontrol plane location - onprem\ndata plane location - onprem\nmanagement - AWS\nEKS anywhere it managed by customer so BD out\nhttps://anywhere.eks.amazonaws.com/docs/concepts/eksafeatures/#comparing-amazon-eks-anywhere-to-amazon-eks\n\nExtended clusters – Run the Kubernetes control plane in an AWS Region and nodes on your Outpost.\nLocal clusters – Run the Kubernetes control plane and nodes on your Outpost\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/eks-deployment-options.html\nhttps://docs.aws.amazon.com/eks/latest/userguide/eks-outposts.html","upvote_count":"14","poster":"pangchn","comment_id":"1181124","timestamp":"1711224660.0"},{"timestamp":"1731718560.0","poster":"0b43291","upvote_count":"1","comment_id":"1312864","content":"Selected Answer: A\nThe correct answer is A. Install an AWS Outposts server in the on-premises data center. Deploy Amazon EKS by using a local cluster configuration on the Outposts server for the production workloads.\n\nThe key requirement is that the company needs an AWS managed solution for Kubernetes management. While EKS Anywhere provides a consistent Kubernetes experience with Amazon EKS, it is a self-managed solution where the customer is responsible for managing the underlying infrastructure and control plane.\n\nOn the other hand, AWS Outposts allows running AWS services, including Amazon EKS, on-premises. When deploying Amazon EKS on an Outposts server using a local cluster configuration, the EKS control plane and data plane reside on the Outposts server in your data center, meeting the requirement of having the production workloads on-premises.\n\nAdditionally, Amazon EKS on Outposts is fully managed by AWS, handling provisioning, upgrading, and lifecycle management of the Kubernetes control plane, providing the least operational overhead."},{"content":"Selected Answer: A\nWith EKS LOCAL clusters on Outposts, you can run the Amazon EKS control plane and data plane entirely on the Outposts hardware on-premises.Also, it's an AWS managed solution.","poster":"JoeTromundo","comment_id":"1296254","timestamp":"1728682440.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1724052300.0","content":"Selected Answer: A\nIt's A, EKS Everywhere = Operational Overhead, and it said it needs to be managed by AWS","comment_id":"1268459","poster":"asquared16"},{"content":"B\nOption A (AWS Outposts with local EKS cluster): While this can run EKS on premises, managing an AWS Outposts server and the associated EKS infrastructure might involve more overhead compared to EKS Anywhere.\nOption C (AWS Outposts with extended EKS cluster): Similar to option A, this involves managing the Outposts server and integrating it with your on-premises environment, which could increase the complexity and operational overhead.\nOption D (AWS Outposts with EKS Anywhere): This combines managing an Outposts server with deploying EKS Anywhere, which adds unnecessary complexity and overhead compared to deploying EKS Anywhere directly on the company's hardware.","upvote_count":"1","timestamp":"1722995220.0","poster":"luuthang2011","comment_id":"1261904"},{"comments":[{"timestamp":"1728682320.0","poster":"JoeTromundo","comment_id":"1296253","content":"Can't be B. The company needs an AWS managed solution for Kubernetes management. EKS Anywhere is not an AWS managed solution. It's a self-managed solution.","upvote_count":"2"}],"upvote_count":"1","timestamp":"1722108180.0","poster":"salekali01","content":"Selected Answer: B\nEKS anywhere!!!","comment_id":"1256435"},{"content":"Selected Answer: A\nVote A because by using outpostM EKS is AWS managed service but running on local. Question require AWS managed solution for Kubernetes management. If EKS Anywhere with control plane on prem not AWS cloud, then it's self managed cluster.","comment_id":"1239349","upvote_count":"2","poster":"Helpnosense","timestamp":"1719677100.0"},{"poster":"4bc91ae","comment_id":"1235758","upvote_count":"1","timestamp":"1719134160.0","content":"Selected Answer: A\nA - Control Plane has to be on-prem (not case for Outpost)"},{"poster":"9f02c8d","comment_id":"1219925","upvote_count":"2","content":"B - Correct. The requirement is to use on-premise hardware with AWS managed EKS that means EKS Anywhere which leverages on-premise hardware with full control over both the control plane and data plane","timestamp":"1716858480.0"},{"upvote_count":"1","timestamp":"1713879540.0","content":"Selected Answer: A\nA - correct.","comment_id":"1200767","poster":"titi_r"},{"poster":"TonytheTiger","upvote_count":"2","timestamp":"1711552620.0","content":"Option A: requirement is ask for AWS Managed Solution and \n AWS Outpost give you that option https://docs.aws.amazon.com/managedservices/latest/userguide/outposts.html\n\nNot Option B : Unlike Amazon EKS in AWS Cloud, EKS Anywhere is a user-managed product that runs on user-managed infrastructure. You are responsible for cluster lifecycle \noperations and maintenance of your EKS Anywhere clusters.\nhttps://anywhere.eks.amazonaws.com/docs/overview/","comment_id":"1184198"},{"upvote_count":"1","timestamp":"1711507320.0","content":"Selected Answer: A\nhttps://anywhere.eks.amazonaws.com/docs/concepts/eksafeatures/#:~:text=With%20Amazon%20EKS%20on%20Outposts,with%20EKS%20Anywhere%20automation%20tooling.","poster":"failexamonly","comment_id":"1183811"},{"content":"Correct answer is A.\nIt is not C because EKS Anywhere cluster is a customer-managed product that runs on customer-managed infrastructure. \nRef: https://aws.amazon.com/eks/eks-anywhere/faqs/","timestamp":"1711184400.0","poster":"yog927","comment_id":"1180723","upvote_count":"1"},{"upvote_count":"2","content":"Correct answer is A\nYou can use Amazon EKS to run on-premises Kubernetes applications on AWS Outposts. You can deploy Amazon EKS on Outposts in the following ways:\n\n Extended clusters – Run the Kubernetes control plane in an AWS Region and nodes on your Outpost.\n\n Local clusters – Run the Kubernetes control plane and nodes on your Outpost.\nhttps://docs.aws.amazon.com/eks/latest/userguide/eks-outposts.html","timestamp":"1711168260.0","poster":"ahmadraufsyahputra","comment_id":"1180547"},{"comment_id":"1179147","content":"Selected Answer: A\nThe correct answer is A: when deploying EKS on an Outpost server in a local cluster configuration, the control plane and data plane reside on-premises, but the control plane is AWS-managed.\n\nB is incorrect. Although for EKS-A, the control plane and data plane reside on-premises, it is not AWS-managed but completely customer-managed (both control plane and data plane).\n\nC is incorrect because in an extended cluster configuration on AWS Outpost, the control plane runs inside the AWS cloud, not on the outpost server on-premises.\n\nD is incorrect because you do not combine EKS-A and Outpost.","poster":"gustori99","timestamp":"1711019640.0","upvote_count":"3"},{"comment_id":"1178926","timestamp":"1710986940.0","content":"Selected Answer: B\nAnswer is B. The requirement is that both control plane and data plane will reside on premise. If you deploy EKS using extended cluster the control plane lies within AWS region. You need a local cluster for the control plane to reside on outpost. \nPlease refer to url below. \nhttps://docs.aws.amazon.com/eks/latest/userguide/eks-outposts.html","poster":"k23319","upvote_count":"2"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/eks/latest/userguide/eks-deployment-options.html","timestamp":"1710973440.0","poster":"oayoade","comment_id":"1178805","upvote_count":"2"},{"comments":[{"content":"Does AWS manage Amazon EKS Anywhere clusters or cluster infrastructure capacity?\n\nNo. Unlike Amazon EKS in AWS Cloud, Amazon EKS Anywhere is a customer-managed product that runs on customer-managed infrastructure. You are responsible for cluster lifecycle operations and maintenance of your Amazon EKS Anywhere clusters and the cluster infrastructure capacity.\nhttps://aws.amazon.com/eks/eks-anywhere/faqs/","comment_id":"1194376","timestamp":"1712930460.0","upvote_count":"1","poster":"Zas1"}],"comment_id":"1178750","upvote_count":"2","timestamp":"1710971100.0","content":"Selected Answer: B\nThis option provides an AWS-managed solution for Kubernetes management on-premises without the additional complexity of managing an Outposts server.","poster":"Russs99"},{"timestamp":"1710956460.0","content":"Selected Answer: C\nC is the answer.","poster":"Dgix","comment_id":"1178560","upvote_count":"1"},{"timestamp":"1710819480.0","upvote_count":"1","comment_id":"1176965","content":"Selected Answer: C\nC provides an AWS-managed solution for Kubernetes management with minimal operational overhead, as it leverages the capabilities of AWS Outposts and Amazon EKS for on-premises deployment. Avoid additional complexity introduced by deploying EKS Anywhere or managing hardware independently in the on-premises DC.\n\nDeploying Amazon EKS using an extended cluster configuration on the Outposts server enables the company to have an EKS cluster with the control plane and data plane residing on-premises.","poster":"CMMC"}]}],"exam":{"id":33,"lastUpdated":"11 Apr 2025","numberOfQuestions":529,"isImplemented":true,"isMCOnly":true,"isBeta":false,"provider":"Amazon","name":"AWS Certified Solutions Architect - Professional SAP-C02"},"currentPage":77},"__N_SSP":true}