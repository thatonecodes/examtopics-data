{"pageProps":{"questions":[{"id":"0rLe5TaQs7u6aqreWuQO","question_images":[],"answer_ET":"C","exam_id":31,"timestamp":"2024-02-05 18:27:00","isMC":true,"answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/132893-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1707154020,"answer_images":[],"answer_description":"","question_id":711,"choices":{"A":"Run the application on AWS Lambda as a single function with maximum provisioned concurrency.","C":"Run the application on Amazon Elastic Container Service (Amazon ECS) as microservices with service auto scaling.","D":"Run the application on AWS Elastic Beanstalk as a single application environment with an all-at-once deployment strategy.","B":"Run the application on Amazon EC2 Spot Instances as microservices with a Spot Fleet default allocation strategy."},"question_text":"A manufacturing company runs its report generation application on AWS. The application generates each report in about 20 minutes. The application is built as a monolith that runs on a single Amazon EC2 instance. The application requires frequent updates to its tightly coupled modules. The application becomes complex to maintain as the company adds new features.\n\nEach time the company patches a software module, the application experiences downtime. Report generation must restart from the beginning after any interruptions. The company wants to redesign the application so that the application can be flexible, scalable, and gradually improved. The company wants to minimize application downtime.\n\nWhich solution will meet these requirements?","answer":"C","discussion":[{"comment_id":"1141307","timestamp":"1707154020.0","upvote_count":"10","content":"Microservices using ECS","poster":"Andy_09"},{"timestamp":"1726621200.0","comment_id":"1285528","content":"Selected Answer: C\nMonolith -> Microservices = ECS.","poster":"MatAlves","upvote_count":"1"},{"timestamp":"1711957560.0","content":"Selected Answer: C\nSure 100%","upvote_count":"3","poster":"Hung23","comment_id":"1187279"},{"upvote_count":"1","poster":"asdfcdsxdfc","content":"Selected Answer: C\nMicroservices using Elastic Container Service is correct","comment_id":"1165168","timestamp":"1709510700.0"},{"content":"Selected Answer: C\nC is correct","poster":"Indrasis","comment_id":"1155286","timestamp":"1708495320.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nB will not help\nspot instances provide cost savings but using it for a stateful task isn't right cause spot instances can be interrupted","comments":[{"upvote_count":"1","poster":"sandordini","timestamp":"1714063140.0","comment_id":"1202156","content":"Correct answer but incorrect reasoning. Spot fleet includes on-demand AND spot instances to provide the desired capacity."}],"poster":"Typewriter101","comment_id":"1150981","timestamp":"1708000020.0"}],"topic":"1"},{"id":"KZPMgXguDltAj7JeCoGv","discussion":[{"comment_id":"1141310","poster":"Andy_09","upvote_count":"11","timestamp":"1707154260.0","content":"Lambda looks like a better option"},{"comment_id":"1150983","timestamp":"1708000260.0","poster":"Typewriter101","upvote_count":"8","content":"Selected Answer: D\nLambda\nserverless, scalable, minimal infrastructure, handling hundreds of requests per second"},{"comment_id":"1202408","content":"Selected Answer: D\nA: auto-scaling of EC2 instances - Lot of overhead + Infra\nB: The company selected one component of the web application to test as a microservice. The component supports hundreds of requests each second. > lastic Beanstalk is a bad choice if you need worker processes. The whole point of a worker process is to perform a task in the background without slowing down your main web app. But Elastic Beanstalk doesn't support this option in a scalable way.\nAlso, they want to test just 1 selected microservice and I think it's a bit of overkill to do it using Elastic Beanstalk. Happy to be challenged though!\nC: self-managed EC2 instances > infra + operational overhead\nD: Lambda supports Python, microservice should be quicker than 15 mins, worst case scenario the test will fail.. (that's the purpose tests are conducted for anyway..)\nI'd go for D","upvote_count":"5","poster":"sandordini","timestamp":"1714112700.0"},{"poster":"gsgdga","content":"Selected Answer: C\nmicroservice => EKS, ECS","comment_id":"1182229","upvote_count":"1","timestamp":"1711344780.0","comments":[{"poster":"LuongTo","timestamp":"1730080680.0","content":"containerized application then go with EKS, ECS is absolutely yes, but there would be more solution for microservices e.g. lambda","upvote_count":"2","comment_id":"1303791"}]},{"timestamp":"1711127040.0","upvote_count":"1","comment_id":"1180207","content":"Selected Answer: C\nC is the correct answer. The best way to deploy microservice is to use container-based service","poster":"alawada","comments":[{"upvote_count":"1","content":"\"Maintain nodes yourself with self-managed nodes\"\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/worker.html","poster":"MatAlves","comment_id":"1285551","timestamp":"1726630260.0"},{"poster":"dkw2342","timestamp":"1711366020.0","upvote_count":"2","content":"Microservices doesn't automatically mean ECS or EKS. Read the question again: \"Serverless\" clearly contradicts \"self-managed EC2 instances\".\n\nD is the only option that fits the criteria.","comment_id":"1182427"}]},{"content":"Best answer is C.\nThe application is a large-scale we app as mentioned in the question.","poster":"rubiteb","timestamp":"1708641840.0","comments":[{"content":"You cannot have 'minimal infrastructure and minimal operational support' with 'Auto Scaling groups of self-managed EC2 instances.'","upvote_count":"2","comment_id":"1285552","poster":"MatAlves","timestamp":"1726630380.0"},{"content":"I mean B for Elastic Beans Stalk not C. EBS is the best solution for running large-scale application.","upvote_count":"1","poster":"rubiteb","timestamp":"1708641960.0","comment_id":"1156781"}],"upvote_count":"1","comment_id":"1156779"},{"content":"C is the correct answer. The best way to deploy microservice is to use container-based service such as EKS or ECS. So C is great","timestamp":"1707357180.0","comment_id":"1143955","comments":[{"content":"Using ECS or EKS involves managing cluster and ec2 which will increase the infrastructure and operational overhead compared to lambda which is serverless.","poster":"Typewriter101","comment_id":"1150985","upvote_count":"2","timestamp":"1708000380.0"}],"poster":"Umuntu","upvote_count":"3"},{"poster":"Andy_09","content":"EBS for minimal infra maintenance","upvote_count":"1","comment_id":"1141308","timestamp":"1707154140.0"}],"answer":"D","answer_description":"","unix_timestamp":1707154140,"exam_id":31,"answer_ET":"D","question_id":712,"topic":"1","choices":{"C":"Use Amazon Elastic Kubernetes Service (Amazon EKS). Launch Auto Scaling groups of self-managed EC2 instances.","D":"Use an AWS Lambda function that runs custom developed code.","A":"Use a Spot Fleet with auto scaling of EC2 instances that run the most recent Amazon Linux operating system.","B":"Use an AWS Elastic Beanstalk web server environment that has high availability configured."},"question_text":"A company wants to rearchitect a large-scale web application to a serverless microservices architecture. The application uses Amazon EC2 instances and is written in Python.\n\nThe company selected one component of the web application to test as a microservice. The component supports hundreds of requests each second. The company wants to create and test the microservice on an AWS solution that supports Python. The solution must also scale automatically and require minimal infrastructure and minimal operational support.\n\nWhich solution will meet these requirements?","question_images":[],"answer_images":[],"answers_community":["D (87%)","13%"],"url":"https://www.examtopics.com/discussions/amazon/view/132894-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"timestamp":"2024-02-05 18:29:00"},{"id":"MQqId6EKg3efHMGYTsSD","answer":"A","answer_ET":"A","answer_images":[],"choices":{"B":"Create a Direct Connect gateway. Recreate the private VIFs to use the new gateway. Associate each VPC by creating new virtual private gateways.","C":"Create a transit VPConnect the Direct Connect connection to the transit VPCreate a peering connection between all other VPCs in the Region. Update the route tables.","D":"Create AWS Site-to-Site VPN connections from on premises to each VPC. Ensure that both VPN tunnels are UP for each connection. Turn on the route propagation feature.","A":"Create a transit gateway, and associate the Direct Connect connection with a new transit VIF. Turn on the transit gateway's route propagation feature."},"question_id":713,"unix_timestamp":1707154320,"discussion":[{"comment_id":"1141311","timestamp":"1707154320.0","poster":"Andy_09","content":"Option A","upvote_count":"7"},{"poster":"Umuntu","timestamp":"1707357480.0","comment_id":"1143960","upvote_count":"6","content":"A is the best solution"},{"content":"Selected Answer: A\nA, but... why there is not mentioned transit gateway attachments?\nif no attachments, how VPCs are going to communicate onprem through the transit gateway?","poster":"Besisco","timestamp":"1739103000.0","comment_id":"1353887","upvote_count":"1"},{"timestamp":"1726630620.0","upvote_count":"3","poster":"MatAlves","content":"Selected Answer: A\n\"You can use AWS Direct Connect gateway to connect your Direct Connect connection over a transit virtual interface to the VPCs or VPNs that are attached to your transit gateway. You associate a Direct Connect gateway with the transit gateway. Then, create a transit virtual interface for your AWS Direct Connect connection to the Direct Connect gateway.\"\nhttps://docs.aws.amazon.com/directconnect/latest/UserGuide/direct-connect-transit-gateways.html","comment_id":"1285553"},{"comment_id":"1180209","upvote_count":"2","timestamp":"1711127220.0","content":"Selected Answer: A\nTurn on the transit gateway's route propagation feature.","poster":"alawada"},{"upvote_count":"2","timestamp":"1709938620.0","content":"https://docs.aws.amazon.com/directconnect/latest/UserGuide/direct-connect-gateways-intro.html","poster":"cedser8","comment_id":"1169144"},{"timestamp":"1708000860.0","comment_id":"1150986","content":"Selected Answer: A\ntransit gateway -> hub and spoke","poster":"Typewriter101","upvote_count":"6"}],"isMC":true,"answer_description":"","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/132895-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"timestamp":"2024-02-05 18:32:00","question_text":"A company has an AWS Direct Connect connection from its on-premises location to an AWS account. The AWS account has 30 different VPCs in the same AWS Region. The VPCs use private virtual interfaces (VIFs). Each VPC has a CIDR block that does not overlap with other networks under the company's control.\n\nThe company wants to centrally manage the networking architecture while still allowing each VPC to communicate with all other VPCs and on-premises networks.\n\nWhich solution will meet these requirements with the LEAST amount of operational overhead?","question_images":[],"topic":"1"},{"id":"C4mNvVyrT1l3yZCH6KAU","exam_id":31,"question_id":714,"isMC":true,"unix_timestamp":1707157680,"answer":"C","discussion":[{"timestamp":"1707615780.0","upvote_count":"12","comment_id":"1146918","poster":"jaswantn","content":"option C....Default Host Management Configuration creates and applies a default IAM role to ensure that Systems Manager has permissions to manage all instances in the Region and perform automated patch scans using Patch Manager."},{"timestamp":"1709192880.0","poster":"Pics00094","comment_id":"1162306","content":"Selected Answer: C\nC is the answer","upvote_count":"6"},{"poster":"FlyingHawk","upvote_count":"1","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/setup-instance-permissions.html, DHMC eliminates the need to manually create and attach a new IAM role for Systems Manager, reducing operational overhead.","timestamp":"1735787400.0","comment_id":"1335344"},{"comments":[{"poster":"FlyingHawk","content":"A is the way before having C, details see this blog: \nhttps://aws.amazon.com/blogs/mt/enable-management-of-your-amazon-ec2-instances-in-aws-systems-manager-using-default-host-management-configuration/","timestamp":"1735786200.0","upvote_count":"1","comment_id":"1335341"}],"content":"Selected Answer: C\nWell.. Actually I don't know what to choose. A or C ??\n\nA - EC2 instances can have only one IAM role attached at a time. Whether attaching multiple roles is possible or not depends on whether AWS allows such configuration in your environment.\nB - Systems Manager manages EC2 instances through the instance's attached IAM role, not an IAM user.\nC - It doesn't address the core requirement of maintaining the existing RDS connectivity. It still requires the EC2 instances to have the necessary IAM permissions to be managed by SSM. The IAM role associated with the EC2 instance must still have the AmazonSSMManagedInstanceCore policy attached to enable Systems Manager capabilities.\nD - Removing the existing policies would break the application's ability to connect to the RDS database. This directly contradicts the requirement of not disrupting running applications.","comment_id":"1329250","upvote_count":"1","poster":"LeonSauveterre","timestamp":"1734661620.0"},{"upvote_count":"1","timestamp":"1734542160.0","content":"Selected Answer: A\nI'd vote for A because the request here is not to disrupt the existing workload, meaning the existing IAM role must be intact with the addition to the new permission set that gives SSM patch manager patching capabilities.","poster":"rosanna","comment_id":"1328633"},{"upvote_count":"3","comments":[{"upvote_count":"2","timestamp":"1726631040.0","poster":"MatAlves","content":"https://docs.aws.amazon.com/systems-manager/latest/userguide/fleet-manager-default-host-management-configuration.html","comment_id":"1285556"}],"content":"Selected Answer: C\n\"The Default Host Management Configuration setting allows AWS Systems Manager to manage your Amazon EC2 instances automatically as managed instances.\n\nDefault Host Management Configuration makes it possible to manage EC2 instances without your having to manually create an AWS Identity and Access Management (IAM) instance profile. Instead, Default Host Management Configuration creates and applies a default IAM role to ensure that Systems Manager has permissions to manage all instances in the AWS account and AWS Region where it's activated.\"","timestamp":"1726631040.0","poster":"MatAlves","comment_id":"1285555"},{"timestamp":"1714731840.0","content":"Selected Answer: A\ni think A","poster":"88f8032","comment_id":"1206038","upvote_count":"2"},{"content":"So is C same as A, but automated?","comments":[{"comment_id":"1329241","upvote_count":"1","content":"No, A is impossible because EC2 instances can have only one IAM role attached at a time.","poster":"LeonSauveterre","timestamp":"1734660960.0"}],"comment_id":"1153897","timestamp":"1708344360.0","upvote_count":"2","poster":"NayeraB"},{"comment_id":"1152845","poster":"osmk","upvote_count":"2","content":"C is fine","timestamp":"1708206360.0"},{"content":"C is a better option","comment_id":"1142292","timestamp":"1707232080.0","poster":"Andy_09","upvote_count":"3"},{"upvote_count":"3","timestamp":"1707157680.0","comment_id":"1141340","comments":[{"timestamp":"1708879620.0","content":"\"Attach the new IAM role to the EC2 instances and the existing IAM role\" - You can't attach multiple policies to an EC2 instance. So A is wrong.","poster":"arunkpskpm","upvote_count":"6","comment_id":"1158965"}],"content":"Correct answer A","poster":"Andy_09"}],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/132900-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"answer_images":[],"question_text":"A company has applications that run on Amazon EC2 instances. The EC2 instances connect to Amazon RDS databases by using an IAM role that has associated policies. The company wants to use AWS Systems Manager to patch the EC2 instances without disrupting the running applications.\n\nWhich solution will meet these requirements?","timestamp":"2024-02-05 19:28:00","answers_community":["C (79%)","A (21%)"],"choices":{"A":"Create a new IAM role. Attach the AmazonSSMManagedInstanceCore policy to the new IAM role. Attach the new IAM role to the EC2 instances and the existing IAM role.","B":"Create an IAM user. Attach the AmazonSSMManagedInstanceCore policy to the IAM user. Configure Systems Manager to use the IAM user to manage the EC2 instances.","C":"Enable Default Host Configuration Management in Systems Manager to manage the EC2 instances.","D":"Remove the existing policies from the existing IAM role. Add the AmazonSSMManagedInstanceCore policy to the existing IAM role."},"answer_ET":"C","topic":"1"},{"id":"HkT24E4ZThU790SoXBE4","unix_timestamp":1707157800,"discussion":[{"content":"I think the better solution now is using Karpenter or turn on EKS Auto mode \nhttps://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html","upvote_count":"1","timestamp":"1735787820.0","comment_id":"1335346","poster":"FlyingHawk"},{"poster":"MatAlves","comment_id":"1285558","timestamp":"1726631280.0","upvote_count":"2","content":"Selected Answer: B\nRefer to \n\nhttps://www.examtopics.com/discussions/amazon/view/109702-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"content":"Selected Answer: B\nAnswerB\n\nUsing of Kubernetes Cluster Autoscaler seems to be the best solution here","comment_id":"1237455","timestamp":"1719405900.0","poster":"Scheldon","upvote_count":"2"},{"content":"Selected Answer: B\nWhen the workload increases and existing nodes reach maximum capacity, the Cluster Autoscaler detects the need for additional nodes and requests them from the underlying AWS infrastructure.","poster":"alawada","comment_id":"1180212","timestamp":"1711127700.0","upvote_count":"2"},{"timestamp":"1708775700.0","comment_id":"1157850","upvote_count":"2","content":"Selected Answer: B\nBcorrect","poster":"osmk"},{"comment_id":"1155957","timestamp":"1708561980.0","poster":"Naveena_Devanga","content":"B is the correct answer. The Kubernetes Cluster Autoscaler automatically adjusts the number of nodes in your cluster when pods fail or are rescheduled onto other nodes. The Cluster Autoscaler uses Auto Scaling groups","upvote_count":"4"},{"upvote_count":"2","poster":"jaswantn","content":"option B.","comment_id":"1146921","timestamp":"1707615900.0"},{"poster":"Andy_09","timestamp":"1707157800.0","comment_id":"1141343","content":"Kubernetes Cluster Autoscaler looks correct","upvote_count":"4"}],"answer_ET":"B","question_text":"A company runs container applications by using Amazon Elastic Kubernetes Service (Amazon EKS) and the Kubernetes Horizontal Pod Autoscaler. The workload is not consistent throughout the day. A solutions architect notices that the number of nodes does not automatically scale out when the existing nodes have reached maximum capacity in the cluster, which causes performance issues.\n\nWhich solution will resolve this issue with the LEAST administrative overhead?","url":"https://www.examtopics.com/discussions/amazon/view/132902-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2024-02-05 19:30:00","topic":"1","answer_images":[],"choices":{"C":"Use an AWS Lambda function to resize the EKS cluster automatically.","B":"Use the Kubernetes Cluster Autoscaler to manage the number of nodes in the cluster.","D":"Use an Amazon EC2 Auto Scaling group to distribute the workload.","A":"Scale out the nodes by tracking the memory usage."},"answer":"B","answers_community":["B (100%)"],"isMC":true,"question_images":[],"question_id":715,"exam_id":31,"answer_description":""}],"exam":{"name":"AWS Certified Solutions Architect - Associate SAA-C03","isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":true,"isBeta":false,"id":31,"provider":"Amazon","numberOfQuestions":1019},"currentPage":143},"__N_SSP":true}