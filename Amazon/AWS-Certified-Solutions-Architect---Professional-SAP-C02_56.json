{"pageProps":{"questions":[{"id":"8cpCl6QtVDnKPcMmeGhq","question_id":276,"question_text":"A solutions architect has launched multiple Amazon EC2 instances in a placement group within a single Availability Zone. Because of additional load on the system, the solutions architect attempts to add new instances to the placement group. However, the solutions architect receives an insufficient capacity error.\n\nWhat should the solutions architect do to troubleshoot this issue?","answer_ET":"B","timestamp":"2023-11-22 07:23:00","answer_description":"","answer_images":[],"answer":"B","choices":{"B":"Stop and start all the instances in the placement group. Try the launch again.","A":"Use a spread placement group. Set a minimum of eight instances for each Availability Zone.","D":"Launch the additional instances as Dedicated Hosts in the placement groups.","C":"Create a new placement group. Merge the new placement group with the original placement group."},"isMC":true,"answers_community":["B (88%)","13%"],"url":"https://www.examtopics.com/discussions/amazon/view/126815-exam-aws-certified-solutions-architect-professional-sap-c02/","topic":"1","unix_timestamp":1700634180,"exam_id":33,"discussion":[{"content":"Should be B\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\nIf you try to add more instances to the placement group later, or if you try to launch more than one instance type in the placement group, you increase your chances of getting an insufficient capacity error.\n\nIf you stop an instance in a placement group and then start it again, it still runs in the placement group. However, the start fails if there isn't enough capacity for the instance.\n\nIf you receive a capacity error when launching an instance in a placement group that already has running instances, stop and start all of the instances in the placement group, and try the launch again. Starting the instances may migrate them to hardware that has capacity for all of the requested instances.","comment_id":"1079000","comments":[{"poster":"heatblur","upvote_count":"2","content":"I don't know about this -- you would stop all the instances handling a production load? That would immediately induce downtime","comment_id":"1080299","timestamp":"1700942520.0"},{"poster":"Jay_2pt0_1","content":"You're right. Straight from the documentation. Thank you for researching this one.","comment_id":"1086238","upvote_count":"2","timestamp":"1701525480.0"}],"timestamp":"1700795520.0","upvote_count":"17","poster":"George88"},{"upvote_count":"1","timestamp":"1731812220.0","content":"B is correct, when you try to add more instances to a placement group with insufficient capacity, it might result in an \"Insufficient capacity\" error. One way to troubleshoot this issue is by recycling (stopping and starting) all existing instances in the placement group. This helps AWS reschedule your instances to accommodate the new ones. Other options do not solve the root cause of the problem.","comment_id":"1313361","poster":"AzureDP900"},{"comment_id":"1182561","upvote_count":"1","timestamp":"1711376760.0","poster":"TonytheTiger","content":"Selected Answer: B\nOption B - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity \nOR \nhttps://repost.aws/knowledge-center/ec2-insufficient-capacity-errors"},{"comment_id":"1117809","poster":"career360guru","content":"Selected Answer: B\nOption B","timestamp":"1704830460.0","upvote_count":"2"},{"poster":"yuliaqwerty","content":"B https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html#concepts-placement-groups:~:text=stop%20and%20start%20all%20of%20the%20instances%20in%20the%20placement%20group%2C%20and%20try%20the%20launch%20again","upvote_count":"1","comment_id":"1102755","timestamp":"1703177220.0"},{"timestamp":"1701698820.0","upvote_count":"1","content":"Selected Answer: B\nAnswer is B\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html#concepts-placement-groups","poster":"J0n102","comment_id":"1087690"},{"upvote_count":"3","content":"I agree with answer B despite the fact that you will have to incur downtime and (obviously) will discuss that before executing the stop and start. This question does not particular state that there must be no downtime. So my advice would be taking appropriate actions and stop/start placement group instead of add Dedicated Host.","poster":"dutchy1988","timestamp":"1701262620.0","comment_id":"1083454"},{"comment_id":"1083017","upvote_count":"2","content":"Selected Answer: B\nhttps://www.examtopics.com/discussions/amazon/view/89258-exam-aws-certified-solutions-architect-professional-topic-1/","poster":"shaaam80","timestamp":"1701214080.0"},{"poster":"enk","content":"Selected Answer: B\nGeorge88's article specifically states B as the answer. However, I agree with Heatblur's reply that in a prod load in real life this is unacceptable unless your app is resilent and can afford a handful of servers being rebooted.","upvote_count":"3","timestamp":"1701079800.0","comment_id":"1081391"},{"upvote_count":"2","content":"Selected Answer: D\nUsing Dedicated Hosts (D) can be a solution if the capacity issue is persistent and critical, and if the cost and complexity of managing Dedicated Hosts are justifiable.\n\nA: Spread Placement might help but doesn't directly address the capacity issue.\n\nB: All the instances are handling traffic -- stopping them surely won't help.\n\nC: You can't merge placement groups.","poster":"heatblur","comment_id":"1080306","timestamp":"1700942880.0"},{"poster":"salazar35","timestamp":"1700922060.0","comment_id":"1080054","content":"Selected Answer: B\nVote B","upvote_count":"2"},{"comments":[{"poster":"devalenzuela86","comment_id":"1079865","timestamp":"1700903340.0","content":"Go with B","upvote_count":"1"}],"timestamp":"1700649360.0","poster":"devalenzuela86","content":"A forsure","comment_id":"1077239","upvote_count":"1"},{"poster":"cypkir","content":"Selected Answer: B\nAnswer: B","comment_id":"1076982","upvote_count":"3","timestamp":"1700634180.0"}],"question_images":[]},{"id":"0GWRnpK9wKXIs4lVFXi1","isMC":true,"answer":"AD","answer_ET":"AD","answers_community":["AD (43%)","CD (39%)","Other"],"exam_id":33,"url":"https://www.examtopics.com/discussions/amazon/view/126817-exam-aws-certified-solutions-architect-professional-sap-c02/","timestamp":"2023-11-22 07:24:00","question_text":"A company has used infrastructure as code (IaC) to provision a set of two Amazon EC2 instances. The instances have remained the same for several years.\n\nThe company's business has grown rapidly in the past few months. In response, the company’s operations team has implemented an Auto Scaling group to manage the sudden increases in traffic. Company policy requires a monthly installation of security updates on all operating systems that are running.\n\nThe most recent security update required a reboot. As a result, the Auto Scaling group terminated the instances and replaced them with new, unpatched instances.\n\nWhich combination of steps should a solutions architect recommend to avoid a recurrence of this issue? (Choose two.)","topic":"1","unix_timestamp":1700634240,"question_images":[],"answer_images":[],"question_id":277,"discussion":[{"upvote_count":"14","comment_id":"1135972","poster":"LazyAutonomy","comments":[{"content":"But why is ASG terminates those instances?\n\nWhat's happening is that ansible/puppet/chef/whatever IaC processes are causing OS updates to be applied long after the default 300s health check grace period ends, which means new kernel, new glibc, etc packages are installed, requiring a reboot for the change to take effect. During these reboots, EC2 ASG thinks the instances are unhealthy (EC2 ping health checks will fail) and replaces them with new instances instantiated from an old unpatched AMI.\n\nIf you still have lingering doubts about eliminating C and E, then consider the fact that deploying an ELB and turning on ELB health checks in the ASG wont make a difference. A rebooting instance will still get terminated by ASG because EC2 + ELB health checks will fail during the reboot. The instances will probably die faster.\n\nSo the problem isn't the reboot. The problem is ASG killing rebooting servers and replacing them with unpatched servers.","poster":"LazyAutonomy","upvote_count":"2","timestamp":"1706634840.0","comments":[{"upvote_count":"3","poster":"LazyAutonomy","comments":[{"upvote_count":"3","comments":[{"comments":[{"comment_id":"1135982","content":"Answer: A + D.\n\nTerrible, terrible, terrible question.","upvote_count":"3","timestamp":"1706635020.0","poster":"LazyAutonomy"}],"upvote_count":"4","poster":"LazyAutonomy","content":"So where does that leave us?\n\nA - does nothing meaningful at all, but at least it's harmless.\nB - working instances will all die on reboot during the \"maintenance window\" (all at the same time? lol) \nC - working instances will die faster when rebooted\nD - perfect, except it technically isn't possible to \"update\" launch configs or \"patch\" AMIs in place. Bummer.\nE - broken instances will never get replaced, defeating the purpose of ASGs.\n\nI think it's safe to conclude the author of this question was just really sloppy with how they worded option D.\n\nTo avoid a re-occurrence of this issue, I am compelled by common sense to adopt a more relaxed interpretation of D. If I infer that the intent of D is New AMI + New launch config + Invoke ASG refresh, then I don't actually need to do anything else. D will be enough to prevent re-occurrence. But I have to pair it with a second option. So I'll pair it with A, which sounds good but actually does nothing and is harmless.","comment_id":"1135977","timestamp":"1706634960.0"}],"content":"Can we eliminate B? Yes. I can safely assume the intention of B is to create a new ASG with the same old launch config + existing AMI. The behaviour of new ASG will match the old ASG. Any instance rebooted after the health check grace period ends will get terminated, even during a \"maintenance window\" (which is not a thing).\n\nOption A wants to modify the termination policy of the existing ASG to \"Oldest launch configuration\". That's unnecessary but harmless. The default termination policy will do this anyway, and AZ re-balancing always takes precedence even when using a non-default termination policy.\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-termination-policies.html\n\n\"Amazon EC2 Auto Scaling always balances instances across Availability Zones first, regardless of which termination policy is used\"","timestamp":"1706634900.0","poster":"LazyAutonomy","comment_id":"1135976"}],"comment_id":"1135974","content":"The simplest solution would be to just increase the health check grace period to something large, like 1 hour, and make sure IaC patches & reboots new instances within the grace period. That will buy you a month before the next senseless EC2 massacre. But nothing resembling that option is being offered here.\n\nThe next simplest option is to protect individual EC2 instances from scale-in while they're being rebooted. But nothing resembling that option is being offered here either.\n\nSo we're left with somehow updating the kernel/glibc/etc that's baked into the AMI itself, thus altogether avoiding the need for new instances to reboot in the first place (let's just ignore livepatch methods for the moment).\n\nYes, we all know that launch configs can't technically be updated in place (and AMIs can't be \"patched\" either), but if we eliminate D for that reason then we're left A & B, neither of which mention new AMIs or launch configs at all.","timestamp":"1706634900.0"}],"comment_id":"1135973"}],"timestamp":"1706634840.0","content":"Selected Answer: AD\nTerrible, terrible question. All answers are technically wrong. But the answer they want is A & D.\n\nC & E - There is nothing in the question to suggest any requirement that warrants the introduction of a load balancer of any kind. Is there any inbound traffic? Maybe, maybe not. Even if the traffic is inbound, what if they've implemented DNS-round-robin \"load balancing\" directly to the EC2 public/private IPs (ie no need for ELB)?\n\nThere's also nothing to suggest that the \"traffic\" is consistently the same 24x7, which means they may want the ASG to periodically scale-in and scale-out instances dynamically e.g. in response to EC2 CPU usage. Enabling termination protection will also prevent the ASG from replacing genuinely unhealthy instances, defeating the purpose of having an ASG in the first place.\n\nSo that leaves us with A, B & D."},{"content":"A and C. D is wrong launch config can't be updated https://docs.aws.amazon.com/autoscaling/ec2/userguide/change-launch-config.html","upvote_count":"6","timestamp":"1703177580.0","poster":"yuliaqwerty","comment_id":"1102758"},{"poster":"d401c0d","content":"Selected Answer: AD\nHow to implement:\nAccess your Auto Scaling group: Navigate to your Auto Scaling group in the AWS console. \nEdit the update policy: Go to the \"Update policy\" section within your Auto Scaling group settings. \nSelect \"oldest\" option: Choose the option that specifies to target the oldest launch configuration for replacement when scaling activities occur.","comment_id":"1353137","timestamp":"1738962420.0","upvote_count":"1"},{"content":"Selected Answer: AD\nA and D","poster":"deepakR20","upvote_count":"1","timestamp":"1736075640.0","comment_id":"1336725"},{"upvote_count":"1","comment_id":"1313359","poster":"AzureDP900","content":"A D for me.\nHere's why:\nA: Modifying the Auto Scaling group to target the oldest launch configuration for replacement ensures that the most recent instance replacements do not reuse unpatched images. This approach helps maintain the security of the newly patched instances.\nD: Creating automation scripts to patch an AMI, update the launch configuration, and invoke an Auto Scaling instance refresh enables a more streamlined process for updating instances with the latest security patches. Automation can help ensure consistency in the patching process, reducing the risk of human error.","timestamp":"1731812040.0"},{"content":"Selected Answer: CD\nThe recommended steps to avoid the issue are:\n\nD. Create automation scripts to patch AMI, update launch configuration, and invoke Auto Scaling instance refresh. C. Create ELB in front of Auto Scaling group. Configure monitoring for target group health checks after instance replacement.\n\nExplanation:\n\nD. Automation scripts ensure new instances launched by Auto Scaling group are patched and secure.\n\nC. ELB distributes traffic to healthy instances. Monitoring ensures new instances are ready before terminating old ones, maintaining availability during refresh.","poster":"0b43291","upvote_count":"1","comment_id":"1310429","timestamp":"1731385080.0"},{"content":"Selected Answer: CD\nD should get the job done.\nThe rest are redundant. But C seems to be not hurting to do anyway","comment_id":"1264462","timestamp":"1723437120.0","upvote_count":"1","poster":"kgpoj"},{"timestamp":"1720269120.0","upvote_count":"1","poster":"053081f","content":"Selected Answer: AD\nWhile options A and D are considered the most suitable (and safest) answers to the question's requirements, they may not completely solve the problem. For example, if there are 10 instances in an Auto Scaling group (No.1, No.2, No.3 ... No.10), and two of them are unpatched, the Oldest Launch setting would prioritize replacing the older unpatched instances. However, there's a possibility that only No.10 might be scaled in, leaving No.9 still unpatched and active in the group.","comment_id":"1243357"},{"content":"Selected Answer: CD\nCD i think","timestamp":"1714728480.0","poster":"seetpt","upvote_count":"1","comment_id":"1206017"},{"poster":"titi_r","upvote_count":"1","timestamp":"1713213420.0","comment_id":"1196209","content":"Selected Answer: AC\nA and C."},{"upvote_count":"2","timestamp":"1710013080.0","content":"Selected Answer: AD\nSometimes I really hate the AWS exam writers. This questions is on a level to which even they shouldn't plumb. \n\nAll of the alternatives are wrong in some way. So you have to guess. Whoever wrote this should be fired.\n\nD, since it addresses the AMI (though \"update\" is not what you do with an AMI). And then A, for the reasons LazyAutonomy gives.\n\nBut wow do I sometimes hate the exam writers. It's one thing to force us to focus on minute details; it's quite another to subject us to their own sloppiness.","comment_id":"1169754","poster":"Dgix"},{"content":"Answer: A, C\n\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/automation-tutorial-update-patch-windows-ami-autoscaling.html","comment_id":"1152934","timestamp":"1708213680.0","poster":"adelynllllllllll","upvote_count":"1"},{"upvote_count":"2","timestamp":"1704834660.0","poster":"career360guru","content":"Selected Answer: CD\nOption C and D","comment_id":"1117851"},{"content":"Selected Answer: DE\nA and C does not prevent EC2 to be terminated by security patch. B is very burdened(create new group each time?).\nD is poorly worded as it says 'update configuration'.\nBut I will go with D E.","upvote_count":"1","comments":[{"poster":"JMAN1","upvote_count":"1","comment_id":"1114796","content":"Sorry. E does not prevent terminating from patch.Let me go with C D.","timestamp":"1704489120.0"}],"comment_id":"1114793","poster":"JMAN1","timestamp":"1704488460.0"},{"content":"Selected Answer: CD\nCD \nAnswer is worded a bit poorly but this is correct.","timestamp":"1703902740.0","comment_id":"1109340","upvote_count":"3","poster":"Atown"},{"upvote_count":"2","timestamp":"1702533660.0","poster":"awsamar","comment_id":"1096086","content":"Selected Answer: AC\nD is out\nAC then"},{"comment_id":"1096077","upvote_count":"2","timestamp":"1702533360.0","poster":"awsamar","content":"Option D is out because it says to \"update launch configuration\"\nAWS Auto Scaling launch configurations cannot be updated directly. Once a launch configuration is created, it cannot be modified; instead, a new one must be created to reflect any changes"},{"timestamp":"1702532940.0","upvote_count":"4","content":"Selected Answer: AC\nThe answer is A and D.","poster":"blackgamer","comment_id":"1096072"},{"poster":"J0n102","content":"Selected Answer: CD\nAnswer: CD","upvote_count":"2","comment_id":"1087637","timestamp":"1701693840.0"},{"comment_id":"1086875","poster":"ishpal","content":"Selected Answer: CD\nhttps://www.examtopics.com/discussions/amazon/view/68855-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"1701615060.0","upvote_count":"4"},{"comment_id":"1076985","upvote_count":"3","timestamp":"1700634240.0","poster":"cypkir","content":"Selected Answer: CD\nAnswer: C D"}],"choices":{"D":"Create automation scripts to patch an AMI, update the launch configuration, and invoke an Auto Scaling instance refresh.","C":"Create an Elastic Load Balancer in front of the Auto Scaling group. Configure monitoring to ensure that target group health checks return healthy after the Auto Scaling group replaces the terminated instances.","B":"Create a new Auto Scaling group before the next patch maintenance. During the maintenance window, patch both groups and reboot the instances.","A":"Modify the Auto Scaling group by setting the Update policy to target the oldest launch configuration for replacement.","E":"Create an Elastic Load Balancer in front of the Auto Scaling group. Configure termination protection on the instances."},"answer_description":""},{"id":"7x3B7m2r2ZBT3eAsZyNq","unix_timestamp":1700634480,"timestamp":"2023-11-22 07:28:00","isMC":true,"exam_id":33,"question_id":278,"answers_community":["D (100%)"],"answer_images":[],"question_images":[],"choices":{"D":"Create an AWS CodeArtifact domain and repository. Add an external connection for public:pypi to the CodeArtifact repository. Configure the Python client to use the CodeArtifact repository. Create a VPC endpoint for CodeArtifact.","B":"Create a NAT gateway in the VPC. Configure VPC routes to allow access to the internet with a network ACL that allows access to only the PyPI repository endpoint.","C":"Create a NAT instance in the VPConfigure VPC routes to allow access to the internet. Configure SageMaker notebook instance firewall rules that allow access to only the PyPI repository endpoint.","A":"Create an AWS CodeCommit repository for each package that the data scientists need to access. Configure code synchronization between the PyPI repository and the CodeCommit repository. Create a VPC endpoint for CodeCommit."},"answer":"D","answer_description":"","discussion":[{"poster":"salazar35","timestamp":"1700922900.0","comment_id":"1080062","content":"Selected Answer: D\nCodeArtifact allows you to store artifacts using popular package managers and build tools like Maven, Gradle, npm, Yarn, Twine, pip, NuGet, and SwiftPM","upvote_count":"8"},{"upvote_count":"1","timestamp":"1714266960.0","comment_id":"1203336","poster":"svenkata18","comments":[{"comment_id":"1267961","poster":"Daniel76","content":"Requirement is to isolate Sagemaker instances from the Internet","upvote_count":"1","timestamp":"1723965120.0"}],"content":"Why not C , can use NAT gateway and Sagemaker instance notebook rules as there were not asking for cost-effective"},{"poster":"career360guru","timestamp":"1704834900.0","comment_id":"1117853","upvote_count":"1","content":"Selected Answer: D\nOption D"},{"comment_id":"1116748","poster":"vibzr2023","timestamp":"1704730440.0","content":"Answer : D\nNot option C\nBy using CodeArtifact, you can effectively meet the requirements of providing access to PyPI while maintaining isolation, security, and cost-efficiency for the SageMaker instances. NAT are additional costs... which you can avoid","upvote_count":"2"},{"comment_id":"1110425","poster":"carpa_jo","content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/machine-learning/private-package-installation-in-amazon-sagemaker-running-in-internet-free-mode/","upvote_count":"3","timestamp":"1704016680.0"},{"upvote_count":"2","poster":"heatblur","timestamp":"1701358020.0","content":"Selected Answer: D\nD is the answer.\n\nIt can't be A -- CodeCommit is primarily a source control service and does not directly synchronize with external repositories like PyPI. This option requires significant overhead in maintaining the sync.","comment_id":"1084495"},{"content":"Selected Answer: D\nD for sure","upvote_count":"2","poster":"devalenzuela86","timestamp":"1700650500.0","comment_id":"1077276"},{"poster":"cypkir","upvote_count":"1","content":"Selected Answer: D\nAnswer: D","comment_id":"1076991","timestamp":"1700634480.0"}],"answer_ET":"D","question_text":"A team of data scientists is using Amazon SageMaker instances and SageMaker APIs to train machine learning (ML) models. The SageMaker instances are deployed in a VPC that does not have access to or from the internet. Datasets for ML model training are stored in an Amazon S3 bucket. Interface VPC endpoints provide access to Amazon S3 and the SageMaker APIs.\n\nOccasionally, the data scientists require access to the Python Package Index (PyPI) repository to update Python packages that they use as part of their workflow. A solutions architect must provide access to the PyPI repository while ensuring that the SageMaker instances remain isolated from the internet.\n\nWhich solution will meet these requirements?","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/126819-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"b1KbMp3HWWWjpq8iOc8Z","answer_ET":"B","question_id":279,"answers_community":["B (60%)","A (40%)"],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/91464-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"A":"Use the file gateway option in AWS Storage Gateway to replace the existing Windows file server, and point the existing file share to the new file gateway.","B":"Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx.","C":"Use AWS Data Pipeline to schedule a daily task to replicate data between the on-premises Windows file server and Amazon Elastic File System (Amazon EFS).","D":"Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon Elastic File System (Amazon EFS)."},"answer_description":"","isMC":true,"question_images":[],"question_text":"A company is storing data on premises on a Windows file server. The company produces 5 GB of new data daily.\nThe company migrated part of its Windows-based workload to AWS and needs the data to be available on a file system in the cloud. The company already has established an AWS Direct Connect connection between the on-premises network and AWS.\nWhich data migration strategy should the company use?","timestamp":"2022-12-13 17:03:00","answer":"B","unix_timestamp":1670947380,"exam_id":33,"discussion":[{"content":"Selected Answer: B\nB. Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx.\nD. Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon Elastic File System (Amazon EFS) are also valid options. They both use DataSync to schedule a daily task to replicate the data between on-premises and cloud, the main difference is the type of file system in the cloud, Amazon FSx or Amazon Elastic File System (Amazon EFS).","comments":[{"content":"EFS only support Linux FS. this is why we need to go for FSx . option B","timestamp":"1683057720.0","comments":[{"content":"thanks for this explaination.\n> EFS only support Linux FS. this is why we need to go for FSx . option B","comment_id":"981617","poster":"Karamen","upvote_count":"1","timestamp":"1692101040.0"}],"comment_id":"887856","upvote_count":"25","poster":"rbm2023"}],"poster":"masetromain","timestamp":"1673642160.0","upvote_count":"14","comment_id":"774833"},{"content":"Selected Answer: A\nFor an and b we need FSx. Data Sync is useful for a batch and is able to process large data volumes. in (a) the data is also accessible from on prem. The data volume is quite small (5 GB) per day therefore (a) is feasible. In my opinion, the key requirement is \"data to be available on a file system in the cloud\" and \",, migrating workloads\" and I think this includes that it can be accessed from servers on prem. In addition (a) replaces only a Windows File server and not the overall windows landscape in AWS. There I vote for (a), AWS Data Sync.\n\nSee https://tutorialsdojo.com/aws-datasync-vs-storage-gateway/ for a comparison","timestamp":"1693506600.0","comments":[{"upvote_count":"3","poster":"swadeey","timestamp":"1701110220.0","comment_id":"1081876","content":"Correct point here is migration not daily sync and replication."},{"poster":"vn_thanhtung","upvote_count":"3","comment_id":"998343","timestamp":"1693814400.0","content":"needs the data to be available on a file system in the cloud"}],"comment_id":"995400","upvote_count":"12","poster":"victorHugo"},{"poster":"happpieee","upvote_count":"1","comment_id":"1402072","content":"Selected Answer: B\nDayaSync allows migration and continue access to both on-prem file server and FSx in a synchronised manner.","timestamp":"1742681160.0"},{"comment_id":"1399052","upvote_count":"1","content":"Selected Answer: A\nA seem to be a more efficient solution as it eliminates duplicate storage. Storage gateway has to be FSx, which is implicit in this option.","timestamp":"1742073660.0","poster":"ParamD"},{"poster":"fbukevin","timestamp":"1735715160.0","upvote_count":"1","content":"Selected Answer: B\nComparing A and B, finally I choosed B due to the \"scheduling\". In A, despite file gateway could provide or combine a scheduling function, B explicitly says that operation.","comment_id":"1335133"},{"poster":"Biden","comment_id":"1334807","content":"Selected Answer: A\nWorkloads are only partially migrated which means data need to be accessed simultaneously by on-prem VMs and the already migrated VMs in cloud\nAnd we should assume that the data should be up to date all the time not just updated periodically\nFinally, File Gateway could be Amazon FSX File GW\nHence clearly A.","timestamp":"1735649760.0","upvote_count":"2"},{"poster":"Tiger4Code","content":"Selected Answer: B\nD is wrong cos EFS support only Linux File System","timestamp":"1732912860.0","upvote_count":"2","comment_id":"1319912"},{"content":"Selected Answer: A\nUsing Amazon FSx File Gateway, you can access data with low latency from on-premise and also in-cloud always. Why do you neet to batch datasync as like B?","timestamp":"1728530460.0","poster":"toyaji","comment_id":"1295376","upvote_count":"1"},{"poster":"amministrazione","comment_id":"1275478","upvote_count":"1","timestamp":"1725093540.0","content":"B. Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx."},{"comment_id":"1257703","upvote_count":"2","timestamp":"1722288060.0","content":"Selected Answer: A\nBecause part of the workloads have already been migrated we need a solution that keeps the data consistent between on prem and the cloud. With DataSync files stored by systems on-prem would be visible in the cloud only the following day. This could cause data inconsistencies and business disruption. The best solution is to use a file gateway to maintain files synchronised at all times. 5GBs/day is easily transferable over DX","poster":"8693a49"},{"content":"B, for sure.\nNeeds the data to be available on a file system in the cloud.","upvote_count":"1","comment_id":"1246226","timestamp":"1720716540.0","poster":"gfhbox0083"},{"poster":"mifune","content":"Selected Answer: B\nWindows file server -> FSx (cristal clear)","timestamp":"1713700020.0","upvote_count":"1","comment_id":"1199629"},{"comment_id":"1187699","poster":"Vongolatt","timestamp":"1712011440.0","upvote_count":"2","content":"Selected Answer: B\nA is not the data migration"},{"content":"Selected Answer: B\noption B is the most suitable data migration strategy for the company. It leverages AWS DataSync to automate the replication of daily data increments from the on-premises Windows file server to Amazon FSx for Windows File Server. This approach provides a seamless integration for Windows-based workloads with minimal disruption and supports the company's needs for a cloud-native file system that is fully managed and integrates well with AWS services.","comment_id":"1180324","upvote_count":"1","poster":"mav3r1ck","comments":[{"comment_id":"1257701","timestamp":"1722287580.0","content":"Batch sync is not seamles and might not be with minimal disruption depending on how it's used. Is this generated with ChatGPT?","upvote_count":"1","poster":"8693a49"}],"timestamp":"1711141140.0"},{"timestamp":"1711140600.0","upvote_count":"2","content":"Selected Answer: B\nThis option is particularly suitable for the company's requirements because it allows for scheduled daily tasks to efficiently replicate the 5 GB of new data to Amazon FSx, providing a cloud-native file system that integrates well with Windows-based workloads.","comment_id":"1180313","poster":"mav3r1ck"},{"content":"Selected Answer: B\nB is the answer","upvote_count":"1","poster":"gofavad926","comment_id":"1175371","timestamp":"1710628860.0"},{"timestamp":"1709473320.0","comment_id":"1164814","upvote_count":"1","content":"Selected Answer: B\nB is right, but, I wish they change \"FSx\" to \"FSx for windows file server\"","poster":"a54b16f"},{"timestamp":"1709457960.0","upvote_count":"2","comments":[{"timestamp":"1742428560.0","content":"you are right, storage gw is not purposed for migration.","poster":"GabrielShiao","comment_id":"1400841","upvote_count":"1"},{"comment_id":"1257702","poster":"8693a49","timestamp":"1722287640.0","content":"My thinking is that a file gateway would be better in a migration where applications are moved in batches because it provides a drop-in replacement. Batch sync could break some of the apps that have not yet migrated.","upvote_count":"1"}],"poster":"Dgix","comment_id":"1164647","content":"The key here is the word \"migration\". This suggests DataSync. If the objective was to set up a permanent hybrid solution, then AWS Storage Gateway would be the solution. Again an example where the entire question hinges on one single word."},{"poster":"djeong95","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-files-fsx.html","timestamp":"1708714560.0","upvote_count":"1","comment_id":"1157395"},{"comment_id":"1145128","upvote_count":"1","content":"Selected Answer: B\nThe most appropriate data migration strategy for the company, considering the need for the data to be available on a file system in the cloud and the existing AWS Direct Connect connection, is:\n\n * B. Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx.\nOption B is the best choice because AWS DataSync is a data transfer service designed to make it easy to move large amounts of data online between on-premises storage systems and AWS storage services. Amazon FSx provides fully managed Windows file servers in the cloud, offering native Windows file system capabilities, making it an ideal target for Windows-based workloads that the company has migrated to AWS. Using DataSync to automate the daily replication of data ensures the new data produced is consistently available in the cloud with minimal manual effort.","timestamp":"1707440400.0","poster":"8608f25"},{"comment_id":"1135446","timestamp":"1706582280.0","poster":"Vaibs099","upvote_count":"1","content":"company migrated part of its Windows-based workload to AWS and needs the data to be available on a file system in the cloud. -> This line is key here, they have already moved part of Windows workload and require data to be available on another file system in the cloud. This is possible by Data Sync migrating data to FSx for Windows Server (SMB supporting file server). \n\nFile Gateway - would for connection to S3 and hardware compliance locally will give illusion of File Server. This is good for DR, Backup and migration to cheaper storage. But doesn't solve the purpose of moving data and creating another file share in Cloud."},{"poster":"tmlong18","upvote_count":"1","content":"Selected Answer: A\nB incorrect. Since you created a DX between AWS and on-premises, you can mount FSx in your local server directly. It doesn’t make sense to schedule a daily task.","timestamp":"1704970200.0","comment_id":"1119624","comments":[{"content":"This is wrong look at what the question actually asks, it says what is a proper MIGRATION strategy, File Gateway only lets you access data but does not migrate data from on premises.","timestamp":"1709757480.0","poster":"e4bc18e","comment_id":"1167484","upvote_count":"1"}]},{"content":"Selected Answer: B\nAnyone saying A has never used file gateway before. You can't \"point the existing file share to the new file gateway\". That's not how file gateways work.","upvote_count":"2","poster":"0c118eb","comment_id":"1101781","timestamp":"1703092680.0"},{"poster":"ninomfr64","content":"Selected Answer: A\nWindows workload thus C and D are ruled out (EFS is for NFS only). \n\nB is precisely stated pointing to FSx for Windows, while A to work we need to imply we are using FSx for Windows File Gateway which is not (clearly stated). Assuming it is FSx for Windows File Gateway, A is more versatile as is quicker in synching data (B once a day)","upvote_count":"3","timestamp":"1703007000.0","comment_id":"1100856"},{"poster":"shaaam80","content":"Selected Answer: B\nAnswer B. Company is looking for a migration strategy. With AWS Direct Connect in place, Datasync replication is the way to go. 5GB of new data is would be replicated in no time.","comment_id":"1087781","upvote_count":"2","timestamp":"1701708480.0"},{"timestamp":"1701110100.0","upvote_count":"2","content":"Aren't we talking about migration not sync. Migration means move data and use on solution. So if we use option B it says schedule daily task to replicate. That means we have on premise working and then replication to cloud. Shouldn't migration means migrate to one file system that is either cloud gateway or keep on server","poster":"swadeey","comment_id":"1081874"},{"comments":[{"comment_id":"1080296","content":"https://docs.aws.amazon.com/filegateway/latest/filefsxw/what-is-file-fsxw.html\nhttps://docs.aws.amazon.com/filegateway/latest/filefsxw/file-gateway-fsx-concepts.html","timestamp":"1700942400.0","upvote_count":"2","poster":"trap"}],"content":"Correct: A\nhttps://aws.amazon.com/storagegateway/file/fsx/","poster":"trap","comment_id":"1080286","upvote_count":"2","timestamp":"1700941920.0"},{"upvote_count":"1","content":"Selected Answer: B\nB is the answer","timestamp":"1700416440.0","poster":"BECAUSE","comment_id":"1074802"},{"timestamp":"1699847400.0","comment_id":"1069005","poster":"severlight","content":"Selected Answer: B\nobvious","upvote_count":"1"},{"poster":"covabix879","content":"Selected Answer: A\nFile Gateway is a better option considering company already have direct connect. It will synchronize file with cloud continuously rather than daily.","timestamp":"1696087920.0","comments":[{"poster":"grire974","timestamp":"1704996180.0","upvote_count":"2","comment_id":"1120044","content":"agreed; but the answer doesn't mention moving the data to the cloud. so it would just be an empty gateway."}],"comment_id":"1021621","upvote_count":"2"},{"timestamp":"1695744000.0","comment_id":"1017961","content":"Selected Answer: A\nHas to be A since daily sync job wont make the data available immediately","upvote_count":"2","poster":"KungLjao"},{"comment_id":"998547","comments":[{"timestamp":"1696205340.0","comment_id":"1022703","upvote_count":"2","content":"It doesn't say access by both on-prem and on-cloud is required.","poster":"daz2023"}],"poster":"Simon523","content":"Selected Answer: B\nthe question is required the data can be access by both on-premises and on-cloud windows server (migrated part of its Windows-based workload), so A is wrong.","upvote_count":"2","timestamp":"1693831860.0"},{"comments":[{"poster":"vn_thanhtung","comment_id":"998344","upvote_count":"2","timestamp":"1693814460.0","content":"needs the data to be available on a file system in the cloud. So A?"}],"upvote_count":"2","poster":"aviathor","content":"Selected Answer: A\n1) Any answer mentioning EFS is out since EFS is for Linux only.\n2) We are now left with DataSync vs File Gateway. The difference is that DataSync is batch-oriented, meaning that data will be out of sync between on-premise and cloud in between 2 synchronisation jobs. File Gateway for FSx on the other hand will synchronise continuously.\n\nI would chose A because that is the most \"versatile\" option, allowing access to the data from AWS as well as from on-premise.","comment_id":"994106","timestamp":"1693399680.0"},{"timestamp":"1692346980.0","content":"Selected Answer: B\nB. To decide between B and A for me was in the last sentence of the question \"Which migration strategy..\". Best migration strategy is AWS DataSync for this use case.","poster":"CloudHandsOn","comment_id":"984290","upvote_count":"1"},{"timestamp":"1691213940.0","upvote_count":"4","comment_id":"972711","poster":"chico2023","content":"Selected Answer: B\nAnswer: B\nThe company is migrating part of their Windows-based workload that taps into a Windows file server. This eliminates C and D right away.\n\nA seems incorrect. It mentions the File Gateway option in AWS Storage Gateway, BUT, this File Gateway has to connect to something, like a FSx share or an S3 bucket. It doesn't specify it. Not to mention that it seems they are not looking for a way for the whole company to tap from the cloud (even with it being cached on-prem), they seem to only want \"the data to be available on a file system in the cloud\" for \" part of their Windows-based workload\" in AWS.\n\nDue to that, B is the most correct option in my opinion."},{"content":"Selected Answer: A\nAmazon FSx File Gateway optimizes on-premises access to fully managed, highly reliable file shares in Amazon FSx for Windows File Server. Customers with unstructured or file data, whether from SMB-based group shares, or business applications, may require on-premises access to meet low-latency requirements. Amazon FSx File Gateway helps accelerate your file-based storage migration to the cloud to enable faster performance, improved data protection, and reduced cost.","timestamp":"1688710080.0","poster":"aviathor","upvote_count":"2","comment_id":"945384"},{"timestamp":"1688004180.0","upvote_count":"2","comment_id":"937370","content":"Selected Answer: B\nB\n1 - windows -> FSx\n2 - a would've be an option if mentioned 1st migration to s3","poster":"NikkyDicky"},{"content":"Selected Answer: A\nA works towards full migration and allows migrated workloads to use fully up to date data at any point and not just a daily sync which might not be enough","timestamp":"1687871580.0","poster":"hglopes","upvote_count":"2","comment_id":"935392"},{"comment_id":"926401","poster":"SkyZeroZx","content":"Selected Answer: B\nkeyword = migration strategy\nthen B","upvote_count":"1","timestamp":"1687058220.0"},{"upvote_count":"2","timestamp":"1683625800.0","poster":"gameoflove","content":"Selected Answer: B\nB as AWS FSx support Windows Files system can also be mounted as External Drive","comment_id":"892961"},{"content":"\"The company migrated part of its Windows-based workload to AWS\" so those Ec2 windows now need access to that data; I believe FSx is the best way. Option A, using storage gateway the data ends on S3 or... FSx. DataSync is also a great utility when teaming up with DX.","poster":"Sarutobi","upvote_count":"1","comment_id":"873191","timestamp":"1681776840.0"},{"content":"Since the company needs the data to be available on a file system in the cloud, the best option is to use Amazon FSx for Windows File Server to store and access the data. Therefore, option B is the correct choice, and the company should use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx.","upvote_count":"1","poster":"Sin_ha","comment_id":"869822","timestamp":"1681428840.0","comments":[{"upvote_count":"1","content":"The problem I have with B is that it talks about a DAILY task. So the workload running on prem and in the cloud may be up to 24 hours out of sync.","comment_id":"945371","poster":"aviathor","timestamp":"1688709660.0"}]},{"poster":"takecoffe","upvote_count":"2","timestamp":"1680394560.0","comments":[{"poster":"OnePunchExam","timestamp":"1680839460.0","upvote_count":"1","content":"Data migration is simply moving data from A to B, it doesn't mean it is a one-off thing like as part of cloud migration workload strategy.\nAnswer is B.","comment_id":"863464"}],"comment_id":"858381","content":"I will go with A ..\n they are talking about migration to cloud. not a hybrid solution.\nWhich data migration strategy should the company use?"},{"upvote_count":"2","poster":"mfsec","content":"Selected Answer: B\nB is the right answer.","comment_id":"852959","timestamp":"1679988660.0"},{"upvote_count":"4","poster":"testingaws123","comment_id":"840108","content":"Selected Answer: A\nThe company migrated part of its Windows-based workload to AWS and needs the data to be available on a file system in the cloud. \nHere It is open to discussion. Do they want to migrate the entire data to the cloud or do they just want data to be available in the cloud.\nIt sound like data will sync to the cloud and remain active on prem. Which leads to option A.","timestamp":"1678901220.0"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/efs/latest/ug/trnsfr-data-using-datasync.html","upvote_count":"1","poster":"zejou1","timestamp":"1678677540.0","comment_id":"837587"},{"upvote_count":"2","poster":"_lasco_","comment_id":"823860","timestamp":"1677510480.0","content":"Selected Answer: B\nB\nI was in doubt between B and D, but EFS does not support windows for mounting:\nhttps://docs.aws.amazon.com/efs/latest/ug/mounting-fs.html"},{"timestamp":"1676049780.0","upvote_count":"2","content":"Selected Answer: A\nI am curious if Amazon FSx File Gateway from Azure Storage Gateway (https://aws.amazon.com/storagegateway/file/) can address this.","poster":"moota","comment_id":"804602"},{"content":"Selected Answer: B\nMy initial thought was A, but the solution requires data to be available in the cloud, not to replace a Windows File server with a Cloud-based sol'n-like storage gateway. So B is correct.","poster":"oatif","comments":[{"comment_id":"847153","timestamp":"1679495460.0","content":"Correct, it says \"The company migrated part of its Windows-based workload to AWS\" so there is still some workload onpremise, this is not about data also workloads, so A is incorrect as smiply replacing the existing windows file server is not an option. Also DataSync work with Direct Connect which the company already uses further giving a hint to B","upvote_count":"1","poster":"vvahe"},{"poster":"aviathor","content":"What bothers me about B is the DAILY synchronisation with a part of the workload remaining on-prem, and the rest on AWS.","timestamp":"1688709840.0","upvote_count":"1","comment_id":"945377"}],"timestamp":"1675581600.0","upvote_count":"3","comment_id":"798665"},{"content":"Selected Answer: B\nhttps://www.examtopics.com/discussions/amazon/view/47620-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"1670947380.0","poster":"masetromain","upvote_count":"4","comment_id":"744255"}],"answer_images":[]},{"id":"Rtx0nUw9lXCQSyDwXZjt","answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/127000-exam-aws-certified-solutions-architect-professional-sap-c02/","timestamp":"2023-11-23 12:18:00","unix_timestamp":1700738280,"question_id":280,"answer_description":"","topic":"1","discussion":[{"content":"Selected Answer: A\nThe best answer is A: configuring Amazon Data Lifecycle Manager to automate the copying of EBS snapshots to additional regions, is the most suitable solution. It meets the requirement of minimal operational overhead while ensuring that snapshots are stored in multiple regions for disaster recovery. This approach is straightforward and leverages AWS's native capabilities for snapshot management.\n\nCan't be C...EBS snapshots are not stored in S3 in a direct manner that would allow the use of S3 Cross-Region Replication. This option seems to misunderstand the nature of EBS snapshots and S3 integration.","poster":"heatblur","comments":[{"poster":"titi_r","comment_id":"1196220","content":"Indeed, you can do a cross-Region snapshot copy with AWS Backup, but ans “C” states to do a local-Region copy, then from the S3 console to run a S3 cross-Region replication, which is NOT possible. See the text and link below.\n“EBS snapshots are stored in Amazon S3, in S3 buckets that you CAN’T access directly. You can create and manage your snapshots using the Amazon EC2 console or the Amazon EC2 API. You can't access your snapshots using the Amazon S3 console or the Amazon S3 API.”\nhttps://docs.aws.amazon.com/ebs/latest/userguide/ebs-snapshots.html\n\nSo, correct ans is “A”.","upvote_count":"2","timestamp":"1713215700.0"},{"upvote_count":"1","poster":"ftaws","timestamp":"1706613840.0","comment_id":"1135721","content":"EBS snapshot are stored in S3."}],"timestamp":"1701358200.0","comment_id":"1084500","upvote_count":"8"},{"comment_id":"1249003","upvote_count":"1","content":"Selected Answer: A\nCRR is a feature in AWS S3 that automatically replicates data from one S3 bucket in one AWS region to another S3 bucket in a different region.\nthe requirements here to send backup to two regions","poster":"mark_232323","timestamp":"1721141760.0"},{"comment_id":"1246695","poster":"mark_232323","upvote_count":"1","timestamp":"1720784100.0","content":"Selected Answer: A\nAWS Backup does not store snapshots in Amazon S3: AWS Backup stores the EBS snapshots in the same AWS Region where the EBS volumes reside. It does not store the snapshots in Amazon S3 buckets."},{"poster":"titi_r","comment_id":"1196222","timestamp":"1713215820.0","upvote_count":"1","content":"Selected Answer: A\n\"A\" - correct."},{"upvote_count":"3","timestamp":"1709328000.0","comment_id":"1163763","poster":"SAExamTaker","content":"\"You can now copy snapshots across regions using Data Lifecycle Manager (DLM). You can enable policies which, along with create, can now also copy snapshots to one or more AWS region(s). Copies can be scheduled for up to three regions from a single policy and retention periods are set for each region separately.\" \nhttps://aws.amazon.com/about-aws/whats-new/2019/12/amazon-data-lifecycle-manager-enables-automation-snapshot-copy-via-policies/"},{"timestamp":"1708883160.0","upvote_count":"1","comment_id":"1158995","content":"Selected Answer: C\nA (Amazon Data Lifecycle Manager) could work, but it's more suitable for lifecycle management tasks such as creating, retaining, and deleting EBS snapshots based on defined policies. It doesn't inherently handle cross-region replication.","poster":"Russs99"},{"poster":"career360guru","timestamp":"1704836160.0","content":"Selected Answer: A\nOption A. EBS Data Lifecycle manager supports automated cross region snapshot.\nhttps://aws.amazon.com/about-aws/whats-new/2019/12/amazon-data-lifecycle-manager-enables-automation-snapshot-copy-via-policies/","comment_id":"1117862","upvote_count":"2"},{"timestamp":"1704304320.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html\nIt help's - Create disaster recovery backup policies that back up data to isolated Regions or accounts.","upvote_count":"2","poster":"Maygam","comment_id":"1112992"},{"comment_id":"1107984","upvote_count":"1","timestamp":"1703782860.0","poster":"duriselvan","content":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-ami-policy.html"},{"content":"C ans \na IS not correct \nSnapshots must be archived in the same Region in which they were created. If you enabled cross-Region copy and snapshot archiving, Amazon Data Lifecycle Manager does not archive the snapshot copy.","upvote_count":"1","poster":"duriselvan","timestamp":"1703782680.0","comment_id":"1107981"},{"upvote_count":"1","timestamp":"1703178060.0","content":"C Amazon data lifecycle manager can't copy snapshots. AWS backup has cross-Region copy feature https://aws.amazon.com/getting-started/hands-on/amazon-ebs-backup-and-restore-using-aws-backup/#:~:text=same%20AWS%20Region%20(-,however%2C%20see%20step%203.2%20for%20information%20on%20cross%2DRegion%20copy,-).%20This%20tutorial%20uses","comments":[{"upvote_count":"1","poster":"Jay_2pt0_1","timestamp":"1703771280.0","content":"Since 2019, DLM can copy to other regions. See https://aws.amazon.com/about-aws/whats-new/2019/12/amazon-data-lifecycle-manager-enables-automation-snapshot-copy-via-policies/ I'm pretty sure the answer is A","comment_id":"1107818"}],"poster":"yuliaqwerty","comment_id":"1102768"},{"timestamp":"1701341340.0","comment_id":"1084256","poster":"knark446","upvote_count":"1","content":"Selected Answer: A\nFor me A would be the solution. \nC will imply copying the ebs snapshots to s3, why not using directly the AWS Backup cross-region backup copy feature?"},{"poster":"dutchy1988","comment_id":"1083476","timestamp":"1701263400.0","content":"https://aws.amazon.com/about-aws/whats-new/2020/12/amazon-data-lifecycle-manager-now-automates-copying-ebs-snapshots-across-accounts/\n\nfully automated and no overhead. Answer A","upvote_count":"2"},{"timestamp":"1701027900.0","upvote_count":"1","poster":"jpes","content":"Selected Answer: C\nAnswer is C","comment_id":"1080997"},{"timestamp":"1700895120.0","upvote_count":"1","poster":"Leo0802","content":"should be C","comment_id":"1079788"},{"upvote_count":"2","timestamp":"1700738280.0","comments":[{"comment_id":"1080065","content":"How AWS Backup create Snaphot?","comments":[{"timestamp":"1701224880.0","content":"yes. i'm researching and saw that: https://docs.aws.amazon.com/prescriptive-guidance/latest/backup-recovery/new-ebs-volume-backups.html#amazon-dlm","poster":"Totoroha","upvote_count":"1","comment_id":"1083059"}],"poster":"salazar35","upvote_count":"1","timestamp":"1700923020.0"}],"poster":"Totoroha","content":"Answer is C. Therefore, option C is the most efficient and cost-effective solution that aligns with the agency's strict disaster recovery requirements while minimizing operational complexity.","comment_id":"1078368"}],"exam_id":33,"question_text":"A solutions architect works for a government agency that has strict disaster recovery requirements. All Amazon Elastic Block Store (Amazon EBS) snapshots are required to be saved in at least two additional AWS Regions. The agency also is required to maintain the lowest possible operational overhead.\n\nWhich solution meets these requirements?","question_images":[],"answer_images":[],"answer":"A","isMC":true,"answers_community":["A (89%)","11%"],"choices":{"B":"Use Amazon EventBridge to schedule an AWS Lambda function to copy the EBS snapshots to the additional Regions.","C":"Setup AWS Backup to create the EBS snapshots. Configure Amazon S3 Cross-Region Replication to copy the EBS snapshots to the additional Regions.","A":"Configure a policy in Amazon Data Lifecycle Manager (Amazon DLM) to run once daily to copy the EBS snapshots to the additional Regions.","D":"Schedule Amazon EC2 Image Builder to run once daily to create an AMI and copy the AMI to the additional Regions."}}],"exam":{"name":"AWS Certified Solutions Architect - Professional SAP-C02","numberOfQuestions":529,"lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":true,"isBeta":false,"isImplemented":true,"id":33},"currentPage":56},"__N_SSP":true}