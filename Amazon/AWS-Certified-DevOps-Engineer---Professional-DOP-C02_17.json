{"pageProps":{"questions":[{"id":"9JPi3L5bOfwwKidhdM93","url":"https://www.examtopics.com/discussions/amazon/view/129734-exam-aws-certified-devops-engineer-professional-dop-c02/","exam_id":23,"question_images":[],"answers_community":["B (68%)","D (32%)"],"isMC":true,"answer_description":"","unix_timestamp":1703872440,"discussion":[{"comment_id":"1152637","poster":"kyuhuck","upvote_count":"9","timestamp":"1708182960.0","content":"Selected Answer: D\nBest Option: Option D appears to be the most straightforward and effective solution that meets the requirements. It simplifies the process by utilizing CodeBuild's feature to directly send reports to an S3 bucket configured as the artifact destination. By setting the object expiration to 90 days in the S3 bucket settings, it fulfills the requirement to keep the test reports for 90 days. This option does not require additional services for moving the reports to S3, assuming the CodeBuild report group configuration allows for direct report storage in S3 with specified retention policies."},{"comments":[{"upvote_count":"2","content":"I think this is the most valid point.","poster":"b0gdan433","comment_id":"1210243","timestamp":"1715522280.0"}],"timestamp":"1710297300.0","comment_id":"1172198","poster":"Seoyong","upvote_count":"7","content":"Selected Answer: B\nquestion key word : \nhow to expire objects in S3.\n\nonly S3 Lifecycle rule can expire objects."},{"upvote_count":"1","poster":"spring21","content":"Selected Answer: D\nphases:\n build:\n commands:\n - echo \"Running tests...\"\n - run_tests_command\nartifacts:\n files:\n - path/to/test_report/*\n discard-paths: no\n base-directory: path/to/test_report","timestamp":"1733707320.0","comment_id":"1323820"},{"timestamp":"1724152200.0","comment_id":"1269390","content":"Selected Answer: B\nB for me","poster":"[Removed]","upvote_count":"1"},{"timestamp":"1714936500.0","comment_id":"1207042","poster":"xdkonorek2","content":"Selected Answer: D\nI think D even though this sentence sounds ridiculous: \"Configure the report group as an artifact in the CodeBuild project buildspec file\" they probably meant that report should be sent as an artifact and that's correct.","comments":[{"timestamp":"1724251980.0","content":"D is incorrect because it talks about storing report groups as artifacts but since report groups are not CodeBuild artifacts, this cannot be done.","comment_id":"1270196","poster":"flaacko","upvote_count":"2"}],"upvote_count":"2"},{"upvote_count":"2","poster":"seetpt","comment_id":"1205496","timestamp":"1714651800.0","content":"Selected Answer: B\nI think B"},{"timestamp":"1713975540.0","content":"Selected Answer: B\nNot sure why we are configuring the report group as an artifact in the CodeBuild project buildspec file. Doesn't make sense and we use S3 lifecycle to expire objects automatically.","comment_id":"1201507","upvote_count":"5","poster":"c3518fc"},{"content":"Selected Answer: B\nBoth B & D seem to work, but object expiration settings still need to set the lifecycle rule manually for option D","poster":"dkp","comment_id":"1195153","upvote_count":"5","timestamp":"1713047880.0"},{"content":"Selected Answer: D\nanswer D","poster":"stoy123","comment_id":"1183511","upvote_count":"1","timestamp":"1711477020.0"},{"content":"Selected Answer: D\nOptions B and D both provide viable solutions to meet the requirements. However, D offers a more direct and simplified approach by leveraging the capabilities of AWS CodeBuild and Amazon S3, including the use of S3 Lifecycle policies for managing the expiration of the test reports. Option B is also a valid solution but involves additional components like EventBridge and Lambda, which might not be necessary for this specific requirement. Therefore, D is the recommended solution for its simplicity and direct alignment with the requirements.","poster":"CloudHandsOn","comment_id":"1180727","timestamp":"1711184700.0","upvote_count":"1"},{"content":"Selected Answer: D\nrtifacts:\n files:\n - '**/*'\n name: '<artifact-name>'\n artifactPrefix: '<path-prefix>'\n discardPaths: yes\n baseDirectory: 'test-reports'\n reports:\n reportGroupName:\n files:\n - '**/*'\n baseDirectory: 'test-reports'\n\nReplace <path-prefix> with the desired path prefix within the S3 bucket.","timestamp":"1710209220.0","poster":"master9","comment_id":"1171394","upvote_count":"2"},{"timestamp":"1709619840.0","upvote_count":"2","poster":"dzn","comment_id":"1166253","content":"Selected Answer: D\nAWS Lambda is not necessary. Test report files specified in the `base-directory` and `files` in the buildspec.yml reports section are uploaded to S3 by specifying them in the artifacts section as well. This is mean of `Configure the report group as an artifact in the CodeBuild project buildspec file.`"},{"poster":"thanhnv142","comment_id":"1147948","content":"Selected Answer: B\nB is correct: <build process and outputs a test report.> means we need report group in codebuild and store report in S3\nA: No mention of report group in codebuild \nC: No mention of s3 and report group\nD: report group is not the same as an artifact","upvote_count":"4","timestamp":"1707731160.0"},{"timestamp":"1705599300.0","upvote_count":"4","content":"Selected Answer: B\nB is correct","poster":"twogyt","comment_id":"1126083"},{"comment_id":"1121061","poster":"a54b16f","content":"Selected Answer: B\nPattern: run lambda inside PostBuild to zip up unit test result folder and copy to S3","upvote_count":"3","comments":[{"comment_id":"1121062","upvote_count":"1","poster":"a54b16f","timestamp":"1705088280.0","content":"B is not exactly use this pattern, but using eventBridge also works"}],"timestamp":"1705088100.0"},{"content":"Selected Answer: B\nhttps://malsouli.medium.com/10-smart-ways-to-use-aws-codebuild-22a8ee0d9302 \n\nThe test reports have to be handled separately , either via postbuild, or via eventbridge as suggested in B","upvote_count":"4","poster":"a54b16f","timestamp":"1704993900.0","comment_id":"1120007"},{"content":"Selected Answer: B\ndefinitely B","upvote_count":"4","poster":"JayF88","timestamp":"1704810060.0","comment_id":"1117558"},{"timestamp":"1704184140.0","content":"Selected Answer: B\n\"B. Add a report group in the CodeBuild project buildspec file with the appropriate path and format for the reports. Create an Amazon S3 bucket to store the reports. Configure an Amazon EventBridge rule that invokes an AWS Lambda function to copy the reports to the S3 bucket when a build is completed. Create an S3 Lifecycle rule to expire the objects after 90 days.\": A test report expires 30 days after it is created. You cannot view an expired test report, but you can export the test results to raw test result files in an S3 bucket. Exported raw test files do not expire. https://docs.aws.amazon.com/codebuild/latest/userguide/test-report.html when you export a test group to s3, it is zipped https://docs.aws.amazon.com/codebuild/latest/userguide/test-report-group-create-cli.html","comment_id":"1111716","poster":"ozansenturk","upvote_count":"5"},{"upvote_count":"4","timestamp":"1704064920.0","content":"Selected Answer: B\nD might sound a better option but the problem is that \"report groups\" cannot be a part of artifacts. If you check the Buildspec syntax in the link below, you'll see that artifacts are separated from report groups. Under artifacts you cannot specify the arn of the report group.\n\nhttps://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#reports-buildspec-file","poster":"d262e67","comment_id":"1110878"},{"comment_id":"1109424","timestamp":"1703914140.0","poster":"PrasannaBalaji","content":"Selected Answer: D\nD is correct.","upvote_count":"2"},{"content":"Selected Answer: D\nit's D","comment_id":"1108965","poster":"csG13","upvote_count":"3","timestamp":"1703872440.0"}],"answer_ET":"B","choices":{"D":"Add a report group in the CodeBuild project buildspec file with the appropriate path and format for the reports. Create an Amazon S3 bucket to store the reports. Configure the report group as an artifact in the CodeBuild project buildspec file. Configure the S3 bucket as the artifact destination. Set the object expiration to 90 days.","A":"Add a new stage in the CodePipeline pipeline after the stage that contains the CodeBuild project. Create an Amazon S3 bucket to store the reports. Configure an S3 deploy action type in the new CodePipeline stage with the appropriate path and format for the reports.","C":"Add a new stage in the CodePipeline pipeline. Configure a test action type with the appropriate path and format for the reports. Configure the report expiration time to be 90 days in the CodeBuild project buildspec file.","B":"Add a report group in the CodeBuild project buildspec file with the appropriate path and format for the reports. Create an Amazon S3 bucket to store the reports. Configure an Amazon EventBridge rule that invokes an AWS Lambda function to copy the reports to the S3 bucket when a build is completed. Create an S3 Lifecycle rule to expire the objects after 90 days."},"answer":"B","question_text":"A company has an application and a CI/CD pipeline. The CI/CD pipeline consists of an AWS CodePipeline pipeline and an AWS CodeBuild project. The CodeBuild project runs tests against the application as part of the build process and outputs a test report. The company must keep the test reports for 90 days.\n\nWhich solution will meet these requirements?","answer_images":[],"timestamp":"2023-12-29 18:54:00","question_id":81,"topic":"1"},{"id":"Y4DVL0hdU0xoTuq6s6OY","answer":"AE","answer_images":[],"answers_community":["AE (78%)","AC (16%)","6%"],"answer_ET":"AE","question_images":[],"discussion":[{"timestamp":"1719783480.0","upvote_count":"6","comments":[{"timestamp":"1719783480.0","content":"https://docs.aws.amazon.com/apigateway/latest/developerguide/rest-api-mutual-tls.html","upvote_count":"1","comment_id":"1110883","poster":"d262e67"}],"poster":"d262e67","comment_id":"1110882","content":"Selected Answer: AE\nA. Because it's only for internal teams.\nE. Because the truststore dictates which CAs to trust. If you have intermediate CAs those also need to be present in the S3 bucket."},{"comment_id":"1208772","poster":"Jay_2pt0_1","content":"Selected Answer: AE\nA. use ACM to generate cert\nE. See https://aws.amazon.com/blogs/compute/introducing-mutual-tls-authentication-for-amazon-api-gateway/","timestamp":"1731149280.0","upvote_count":"2"},{"timestamp":"1729168560.0","content":"Selected Answer: AE\nC is incorrect because the trust store should contain the root CA certificate, not the client certificate.\nRoot CA certificate is used to validate the client certificates (can be many) presented by the clients. If the client certificate itself is in the trust store, it would mean that only that specific client is trusted, which is not practical in a scenario where there are multiple clients (read it as company's internal teams).","comment_id":"1197235","poster":"didek1986","upvote_count":"4"},{"timestamp":"1727644860.0","upvote_count":"1","content":"Selected Answer: AC\nA and C. Details are everything in an Investigation...\nWhat API Gateway needs is the Client Certificate generated by option A and not the CA","comment_id":"1186452","poster":"WhyIronMan"},{"timestamp":"1726484520.0","content":"Selected Answer: AE\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/rest-api-mutual-tls.html\nAfter reading the above documentation I would determine A & E","comment_id":"1174962","poster":"DanShone","upvote_count":"4"},{"comment_id":"1173565","timestamp":"1726323840.0","content":"Selected Answer: AC\nCheck this article, https://docs.aws.amazon.com/apigateway/latest/developerguide/rest-api-mutual-tls.html. You need to upload the truststore to an Amazon S3 bucket in a single file","upvote_count":"1","poster":"Nano803"},{"upvote_count":"3","comment_id":"1149212","timestamp":"1723551780.0","content":"Selected Answer: AE\nAfter reading this I would suggest A & E","poster":"Ramdi1"},{"comment_id":"1147954","upvote_count":"1","timestamp":"1723449240.0","content":"Selected Answer: AC\nA and C is correct: \nA: we prefer AWS service more than a public one, which is B\nB: The reason is explained in option a\nC: Upload the provisioned to S3 bucket. \nD: should not upload private key to anywhere. \nE: This option has no connection to option A.","poster":"thanhnv142"},{"timestamp":"1722963660.0","content":"Selected Answer: BE\nDetails can be found here: https://aws.amazon.com/blogs/compute/introducing-mutual-tls-authentication-for-amazon-api-gateway/","poster":"Spavanko","upvote_count":"2","comment_id":"1142499"},{"upvote_count":"3","comment_id":"1120016","timestamp":"1720712040.0","poster":"a54b16f","content":"Selected Answer: AE\nyou need to use ROOT CA , or whatever the certificated being used to sign other certificate in truststore,"},{"poster":"kabary","comment_id":"1110897","upvote_count":"2","timestamp":"1719785580.0","content":"Selected Answer: AC\nYou shall NEVER upload private cert or key to an S3 bucket. This is a bad practise and hence C.\n\nI also choose A because you need private cert between the internal teams and the API.","comments":[{"poster":"matanasov","upvote_count":"2","content":"Option C and Option D involve uploading the client certificate or its private key to an S3 bucket and configuring the API Gateway to use them as the trust store. This is not a recommended practice as it exposes sensitive information to potential security risks. The trust store for mutual TLS should typically involve the CA certificate or a certificate chain that verifies the client certificates, not the client certificates or private keys themselves.","timestamp":"1720245600.0","comment_id":"1115033"}]},{"comment_id":"1108714","upvote_count":"3","poster":"PrasannaBalaji","content":"Selected Answer: AE\nA and E","timestamp":"1719660540.0"}],"isMC":true,"question_text":"A company uses an Amazon API Gateway regional REST API to host its application API. The REST API has a custom domain. The REST API's default endpoint is deactivated.\n\nThe company's internal teams consume the API. The company wants to use mutual TLS between the API and the internal teams as an additional layer of authentication.\n\nWhich combination of steps will meet these requirements? (Choose two.)","url":"https://www.examtopics.com/discussions/amazon/view/129685-exam-aws-certified-devops-engineer-professional-dop-c02/","timestamp":"2023-12-29 14:29:00","topic":"1","answer_description":"","question_id":82,"choices":{"A":"Use AWS Certificate Manager (ACM) to create a private certificate authority (CA). Provision a client certificate that is signed by the private CA.","D":"Upload the provisioned client certificate private key to an Amazon S3 bucket. Configure the API Gateway mutual TLS to use the private key that is stored in the S3 bucket as the trust store.","B":"Provision a client certificate that is signed by a public certificate authority (CA). Import the certificate into AWS Certificate Manager (ACM).","E":"Upload the root private certificate authority (CA) certificate to an Amazon S3 bucket. Configure the API Gateway mutual TLS to use the private CA certificate that is stored in the S3 bucket as the trust store.","C":"Upload the provisioned client certificate to an Amazon S3 bucket. Configure the API Gateway mutual TLS to use the client certificate that is stored in the S3 bucket as the trust store."},"unix_timestamp":1703856540,"exam_id":23},{"id":"t21LV23pfYv5IzG3x2LP","question_text":"A company uses AWS Directory Service for Microsoft Active Directory as its identity provider (IdP). The company requires all infrastructure to be defined and deployed by AWS CloudFormation.\n\nA DevOps engineer needs to create a fleet of Windows-based Amazon EC2 instances to host an application. The DevOps engineer has created a CloudFormation template that contains an EC2 launch template, IAM role, EC2 security group, and EC2 Auto Scaling group. The DevOps engineer must implement a solution that joins all EC2 instances to the domain of the AWS Managed Microsoft AD directory.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","timestamp":"2023-12-30 06:32:00","answer":"B","unix_timestamp":1703914320,"topic":"1","isMC":true,"question_id":83,"choices":{"A":"In the CloudFormation template, create an AWS::SSM::Document resource that joins the EC2 instance to the AWS Managed Microsoft AD domain by using the parameters for the existing directory. Update the launch template to include the SSMAssociation property to use the new SSM document. Attach the AmazonSSMManagedInstanceCore and AmazonSSMDirectoryServiceAccess AWS managed policies to the IAM role that the EC2 instances use.","D":"Store the existing AWS Managed Microsoft AD domain administrator credentials in AWS Secrets Manager. In the CloudFormation template, update the EC2 launch template to include user data. Configure the user data to pull the administrator credentials from Secrets Manager and to join the AWS Managed Microsoft AD domain. Attach the AmazonSSMManagedInstanceCore and SecretsManagerReadWrite AWS managed policies to the IAM role that the EC2 instances use.","C":"Store the existing AWS Managed Microsoft AD domain connection details in AWS Secrets Manager. In the CloudFormation template, create an AWS::SSM::Association resource to associate the AWS-CreateManagedWindowsInstanceWithApproval Automation runbook with the EC2 Auto Scaling group. Pass the ARNs for the parameters from Secrets Manager to join the domain. Attach the AmazonSSMDirectoryServiceAccess and SecretsManagerReadWrite AWS managed policies to the IAM role that the EC2 instances use.","B":"In the CloudFormation template, update the launch template to include specific tags that propagate on launch. Create an AWS::SSM::Association resource to associate the AWS-JoinDirectoryServiceDomain Automation runbook with the EC2 instances that have the specified tags. Define the required parameters to join the AWS Managed Microsoft AD directory. Attach the AmazonSSMManagedInstanceCore and AmazonSSMDirectoryServiceAccess AWS managed policies to the IAM role that the EC2 instances use."},"answer_description":"","answers_community":["B (100%)"],"answer_ET":"B","exam_id":23,"answer_images":[],"discussion":[{"comment_id":"1281388","poster":"aws_god","upvote_count":"1","timestamp":"1725949260.0","content":"Selected Answer: B\nB is correct - https://docs.aws.amazon.com/directoryservice/latest/admin-guide/step4_test_ec2_access.html"},{"content":"Selected Answer: B\nans is B","upvote_count":"2","timestamp":"1713050340.0","poster":"dkp","comment_id":"1195161"},{"comment_id":"1147959","upvote_count":"3","timestamp":"1707732360.0","poster":"thanhnv142","content":"Selected Answer: B\nB is correct: we need to use AWS:SSM::Document with the AWS-JoinDirectoryServiceDomain automation runbook for this task\nA: no mention of the name of runbook to join domain \nC: AWS-CreateManagedWindowsInstanceWithApproval Automation runbook is used for creating a windows instance, not to join domain\nD: no mention of AWS::SSM::Document"},{"content":"Selected Answer: B\nB is correct","poster":"twogyt","timestamp":"1705599840.0","comment_id":"1126087","upvote_count":"2"},{"content":"Selected Answer: B\nkeyword: JoinDirectoryServiceDomain","poster":"a54b16f","comment_id":"1121071","upvote_count":"2","timestamp":"1705088880.0"},{"content":"Selected Answer: B\nMust be B:\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/walkthrough-powershell.html#walkthrough-powershell-domain-join","upvote_count":"2","poster":"d262e67","comment_id":"1110887","timestamp":"1704066720.0"},{"content":"Selected Answer: B\nIt’s B","upvote_count":"2","comment_id":"1109509","timestamp":"1703923500.0","poster":"csG13"},{"comment_id":"1109426","timestamp":"1703914320.0","upvote_count":"2","content":"Selected Answer: B\nB is correct","poster":"PrasannaBalaji"}],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/129833-exam-aws-certified-devops-engineer-professional-dop-c02/"},{"id":"BinhFzwAibFLpUBIPTfi","timestamp":"2023-12-29 19:07:00","answers_community":["C (72%)","B (28%)"],"exam_id":23,"answer_images":[],"choices":{"C":"Update the SCP in the child OU to allow all actions for Amazon EC2.","B":"Create a new SCP that allows all actions for Amazon EC2. Attach the SCP to the vendor-data account.","A":"Attach the AmazonEC2FullAccess IAM policy to the IAM user.","D":"Create a new SCP that allows all actions for Amazon EC2. Attach the SCP to the root OU."},"answer":"C","question_text":"A company uses AWS Organizations to manage its AWS accounts. The company has a root OU that has a child OU. The root OU has an SCP that allows all actions on all resources. The child OU has an SCP that allows all actions for Amazon DynamoDB and AWS Lambda, and denies all other actions.\n\nThe company has an AWS account that is named vendor-data in the child OU. A DevOps engineer has an IAM user that is attached to the Administrator Access IAM policy in the vendor-data account. The DevOps engineer attempts to launch an Amazon EC2 instance in the vendor-data account but receives an access denied error.\n\nWhich change should the DevOps engineer make to launch the EC2 instance in the vendor-data account?","answer_ET":"C","topic":"1","question_images":[],"answer_description":"","question_id":84,"url":"https://www.examtopics.com/discussions/amazon/view/129736-exam-aws-certified-devops-engineer-professional-dop-c02/","unix_timestamp":1703873220,"discussion":[{"timestamp":"1721905620.0","upvote_count":"7","content":"Selected Answer: B\nI vote B. can't understand why B is not correct answer. SCP can be attached to account.\n\nFor the C, it is possible. but the potential risk is it's not only allow all EC2 action on \"vendor-data\" account, but also allow all EC2 actions in other account under the child OU. which is not a best practice.","comment_id":"1254943","comments":[{"upvote_count":"1","timestamp":"1743332100.0","content":"Deny takes precedence","comment_id":"1411997","poster":"Srikantha"}],"poster":"ericphl"},{"content":"Selected Answer: C\nIt's C - Allow must be explicit from root all the way down to the account level. Since it's not specified in the OU the only way to make it available to vendor-account is to change the OU policy.","timestamp":"1703873220.0","comment_id":"1108979","poster":"csG13","upvote_count":"5"},{"timestamp":"1743332160.0","upvote_count":"1","poster":"Srikantha","comment_id":"1411998","content":"Selected Answer: C\nThis ensures that IAM policies in the vendor-data account can grant EC2 permissions, resolving the issue."},{"comment_id":"1266841","content":"Answer is C. You can attach SCP to vendor-data account. however there is deny rule at OU level and that will apply and without updating that your SCP at vendor data account is not useful. As the account will inherit SCP applied at OU.","poster":"Abilash2605","timestamp":"1723786860.0","upvote_count":"2"},{"upvote_count":"1","content":"Selected Answer: C\nB - Incorrect IMO - The question doesn't ask about taking away anything currently allowed in the existing SCP","poster":"auxwww","comment_id":"1264763","timestamp":"1723487760.0"},{"timestamp":"1713976620.0","upvote_count":"3","poster":"c3518fc","comment_id":"1201516","content":"Selected Answer: C\nBy updating the SCP in the child OU to allow all actions for Amazon EC2, the DevOps engineer can grant the necessary permissions to launch EC2 instances in the vendor-data account while maintaining the desired restrictions for other services and accounts within the child OU."},{"comment_id":"1195162","timestamp":"1713050520.0","upvote_count":"3","content":"Selected Answer: C\nanswer is C","poster":"dkp"},{"comment_id":"1186455","timestamp":"1711841280.0","upvote_count":"2","content":"Selected Answer: C\nC, details are everything during an investigation","poster":"WhyIronMan"},{"comments":[{"poster":"stoy123","upvote_count":"2","timestamp":"1711616820.0","comment_id":"1184653","content":"Edit: C is correct"}],"timestamp":"1711478640.0","poster":"stoy123","content":"Selected Answer: B\nB is the correct answer!!!!","upvote_count":"2","comment_id":"1183529"},{"poster":"DanShone","content":"Selected Answer: C\nC is correct","upvote_count":"2","comment_id":"1174960","timestamp":"1710593640.0"},{"content":"Selected Answer: C\nC is correct: \nA: We need to modify SCP not IAM policy\nB: SCP is attached to OUs, not account\nD: This option changes nothing, as the roout OU has already allowed all actions","poster":"thanhnv142","comment_id":"1147960","upvote_count":"3","timestamp":"1707732600.0","comments":[]},{"content":"Selected Answer: C\nupdate policy to include EC2","poster":"a54b16f","comment_id":"1121072","upvote_count":"1","timestamp":"1705089000.0"},{"upvote_count":"1","comment_id":"1110891","poster":"d262e67","content":"Selected Answer: C\nThe only correct option","timestamp":"1704066960.0"},{"timestamp":"1703914380.0","poster":"PrasannaBalaji","comment_id":"1109429","upvote_count":"1","content":"Selected Answer: C\nC is correct"}],"isMC":true},{"id":"YGyy3wcmR3wFduzazqKY","timestamp":"2023-12-29 19:17:00","exam_id":23,"choices":{"B":"Configure an Amazon EventBridge rule to receive new AMI events from Image Builder. Target an AWS Lambda function that updates the launch templates of the Auto Scaling groups with the newest AMI ID.","A":"Configure an Amazon EventBridge rule to receive new AMI events from Image Builder. Target an AWS Systems Manager Run Command document that updates the launch templates of the Auto Scaling groups with the newest AMI ID.","D":"Configure the Image Builder distribution settings to update the launch templates with the newest AMI IConfigure the Auto Scaling groups to use the newest version of the launch template.","C":"Configure the launch template to use a value from AWS Systems Manager Parameter Store for the AMI ID. Configure the Image Builder pipeline to update the Parameter Store value with the newest AMI ID."},"answer":"D","answer_images":[],"discussion":[{"timestamp":"1707733020.0","comment_id":"1147969","upvote_count":"7","content":"Selected Answer: D\nD is correct: Image builder has a built-in that allow updating EC2 launch template\nA: AWS Systems Manager Run Command document is used for running scripts on EC2, not to update\nB: Lambda is used for other tasks, not this one\nC: This seems to be a feasible option, but we can update the launch template directly without using parameter store","poster":"thanhnv142"},{"comment_id":"1110893","timestamp":"1704067200.0","poster":"d262e67","upvote_count":"5","content":"Selected Answer: D\nDefinitely D according to this:\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/dist-using-launch-template.html"},{"comment_id":"1412001","poster":"Srikantha","timestamp":"1743332220.0","upvote_count":"2","content":"Selected Answer: C\nUsing Parameter Store as a centralized AMI reference ensures that new instances always use the latest AMI with minimal operational overhead."},{"poster":"f4bi4n","upvote_count":"2","comment_id":"1272645","content":"Selected Answer: C\nI would go with C even when D seems to be the primary choice.\nIn D, you would need to maintain all of the launchTemplateConfigurations in a list, which means there is a lot of overhead. \nWith C this is not the case","timestamp":"1724670960.0"},{"content":"Answers B, C, and D can work. I'm leaning towards \"D\", but I'm witholding a formal vote for now. It appears the \"correct\" answer may depend on how you interpret requirements.\nNOT B: EventBridge/Lamba can work, but not as simple as D or C. It DOES \"update the launch templates of the company's Auto Scaling groups.\"\nNOT C: Answer C can work and is fairly simple, but it DOES NOT \"update the launch templates of the company's Auto Scaling groups\", because it does not need to, which could be argued is \"operationally efficient\".\nYES D: Seems like simple solution. ASG does need to be updated, but I don't know if that means defining someting like an $LATEST AMI alias (pointer) in ASG, or if ASG actually needs to be updated for each new version of Launch template. This solution could be more complex than C:.","poster":"Gomer","upvote_count":"1","timestamp":"1719869940.0","comment_id":"1240399"},{"content":"Selected Answer: C\nC: This involves configuring the launch template to reference the AMI ID stored in the AWS Systems Manager Parameter Store. The EC2 Image Builder pipeline is then set up to update this Parameter Store value each time a new AMI is built. By doing so, the launch template always points to the latest AMI without requiring manual updates each time a new AMI is built. This approach automates the update process and ensures that Auto Scaling groups always use the most recent and secure AMIs, with minimal manual intervention and operational overhead.","upvote_count":"2","comment_id":"1210995","timestamp":"1715621460.0","poster":"TEC1"},{"poster":"dkp","comment_id":"1195163","timestamp":"1713050700.0","upvote_count":"2","content":"Selected Answer: D\nans is D"},{"timestamp":"1711841520.0","poster":"WhyIronMan","upvote_count":"4","comment_id":"1186458","content":"Selected Answer: D\nD is the correct and best practice suggested by aws\nhttps://docs.aws.amazon.com/imagebuilder/latest/userguide/dist-using-launch-template.html"},{"content":"Selected Answer: B\nanswer B","timestamp":"1711478940.0","upvote_count":"2","comment_id":"1183533","poster":"stoy123"},{"timestamp":"1711275120.0","upvote_count":"1","comment_id":"1181435","poster":"Seoyong","content":"Selected Answer: B\nC is not efficiency .\nhttps://aws.amazon.com/blogs/compute/tracking-the-latest-server-images-in-amazon-ec2-image-builder-pipelines/"},{"timestamp":"1710604620.0","upvote_count":"2","poster":"ogerber","comment_id":"1175074","content":"Selected Answer: D\nits D, 100%\nConfigure the Image Builder distribution settings to update the launch templates with the newest AMI IConfigure the Auto Scaling groups to use the newest version of the launch template."},{"comment_id":"1153805","content":"Selected Answer: C\nadd Explanation 'c' cause = chat gpt4.0 = c and i think\nThe most operationally efficient solution is to use AWS systems manager parameter store1 to store the ami di and reference it in the launch template2. this way, the launch template does not nned to be updated event titme a new ami is created by image buider, instead the image builder prpeline, can update the parameter store value with the newest ami id3,j and the auto scaling gorup can launch instances using the lastest value from parameter store","poster":"kyuhuck","upvote_count":"2","timestamp":"1708335300.0","comments":[{"poster":"WhyIronMan","upvote_count":"2","timestamp":"1711841760.0","comment_id":"1186459","content":"don't trust chat gpt to help you pass exam, studying is the right way. \nQuestion says \"Which solution will meet these requirements with the MOST operational efficiency?\" you are adding more steps than it needs in D.\n\nOption C involves using Systems Manager Parameter Store to manage the AMI ID, but it requires manual updates to the Parameter Store value, which may not be as efficient or automated as directly configuring Image Builder to update the launch templates \n\nremember that Parameter store is not supported in distribution settings of image builder"}]},{"upvote_count":"2","poster":"kyuhuck","timestamp":"1708321620.0","comment_id":"1153730","content":"Selected Answer: C\nGiven these options, C represents the most operationally efficient solution that meets the requirements. It automates the process of using the newest AMIs for EC2 instance launches within Auto Scaling groups by leveraging the AWS Systems Manager Parameter Store and EC2 Image Builder. This method ensures that the Auto Scaling groups always use the latest security-hardened AMIs without needing to manually update launch templates for each new AMI release, thereby streamlining operations and maintaining compliance with the company's security policies."},{"poster":"a54b16f","comment_id":"1121084","timestamp":"1705089780.0","content":"Selected Answer: D\nD is correct. Actually C is also a valid option to pass AMI ID into launch template, but it has lots of limitations and not used in enterprise environment","upvote_count":"3"},{"comment_id":"1110902","upvote_count":"2","content":"Selected Answer: D\nAnswer is D.","timestamp":"1704069060.0","poster":"kabary"},{"comment_id":"1109431","upvote_count":"1","content":"D is correct","timestamp":"1703914500.0","poster":"PrasannaBalaji"},{"content":"Selected Answer: B\nB seems like an option","poster":"csG13","timestamp":"1703873820.0","comments":[{"comment_id":"1108988","timestamp":"1703874120.0","upvote_count":"1","content":"now that I think twice about it, D seems to be the most operationally efficient. I change my answer to D.","poster":"csG13"}],"comment_id":"1108986","upvote_count":"2"}],"unix_timestamp":1703873820,"url":"https://www.examtopics.com/discussions/amazon/view/129737-exam-aws-certified-devops-engineer-professional-dop-c02/","question_id":85,"question_text":"A company's security policies require the use of security hardened AMIs in production environments. A DevOps engineer has used EC2 Image Builder to create a pipeline that builds the AMIs on a recurring schedule.\n\nThe DevOps engineer needs to update the launch templates of the company's Auto Scaling groups. The Auto Scaling groups must use the newest AMIs during the launch of Amazon EC2 instances.\n\nWhich solution will meet these requirements with the MOST operational efficiency?","answers_community":["D (63%)","C (25%)","13%"],"question_images":[],"answer_description":"","isMC":true,"topic":"1","answer_ET":"D"}],"exam":{"isBeta":false,"id":23,"name":"AWS Certified DevOps Engineer - Professional DOP-C02","lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":true,"isImplemented":true,"numberOfQuestions":355},"currentPage":17},"__N_SSP":true}