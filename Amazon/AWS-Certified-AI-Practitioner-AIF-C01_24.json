{"pageProps":{"questions":[{"id":"CaZqK9qgerThZp0Xb4e9","timestamp":"2024-11-09 22:56:00","url":"https://www.examtopics.com/discussions/amazon/view/151048-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answers_community":["B (91%)","9%"],"question_images":[],"unix_timestamp":1731189360,"question_id":116,"answer_ET":"B","answer":"B","question_text":"A research company implemented a chatbot by using a foundation model (FM) from Amazon Bedrock. The chatbot searches for answers to questions from a large database of research papers.\nAfter multiple prompt engineering attempts, the company notices that the FM is performing poorly because of the complex scientific terms in the research papers.\nHow can the company improve the performance of the chatbot?","choices":{"D":"Clean the research paper data to remove complex scientific terms.","B":"Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.","C":"Change the FM inference parameters.","A":"Use few-shot prompting to define how the FM can answer the questions."},"discussion":[{"timestamp":"1739503680.0","poster":"Willdoit","upvote_count":"2","comment_id":"1356355","content":"Selected Answer: B\nDomain adaptation fine-tuning is a method where the foundation model (FM) is fine-tuned on a specific domain's dataset, allowing the model to better understand and handle specialized language or complex terms relevant to that domain. In this case, since the chatbot is struggling with complex scientific terms in the research papers, fine-tuning the model on a corpus of research papers with similar scientific terminology will help it perform better in answering questions related to these terms."},{"poster":"Jessiii","content":"Selected Answer: B\nB. Use domain adaptation fine-tuning: Domain adaptation fine-tuning involves customizing the foundation model (FM) to perform better in a specific domain (in this case, research papers with complex scientific terms). By fine-tuning the FM on a corpus that includes more examples of the complex terminology and context of the research papers, the model will become better at understanding and generating appropriate responses. This improves its performance with domain-specific language","upvote_count":"1","timestamp":"1739329560.0","comment_id":"1355399"},{"poster":"85b5b55","content":"Selected Answer: B\nDomain Adaptation fine-tuning helps for industry-specific terminology based solutions.","upvote_count":"1","timestamp":"1738323180.0","comment_id":"1349496"},{"timestamp":"1735486320.0","poster":"may2021_r","content":"Selected Answer: B\nAnswer:\nB. Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.\n\nExplanation:\nDomain Adaptation Fine-Tuning involves training the foundation model (FM) further on domain-specific data—in this case, complex scientific terms and research papers. This process helps the model better understand and accurately respond to specialized language and concepts, thereby improving the chatbot's performance in handling intricate scientific queries.","upvote_count":"1","comment_id":"1333569"},{"upvote_count":"2","content":"Selected Answer: B\nB. “After multiple prompt engineering attempts” means few-shot prompt has tried or? So A is not the correct one.","comment_id":"1320147","timestamp":"1732961400.0","poster":"CTao"},{"content":"Selected Answer: A\nA is correct","comment_id":"1318338","timestamp":"1732663200.0","poster":"PHD_CHENG","upvote_count":"1"},{"upvote_count":"3","poster":"jove","timestamp":"1731189360.0","content":"Selected Answer: B\nDomain adaptation fine-tuning allows you to fine-tune the foundation model (FM) on a dataset that includes examples of the specific domain, in this case, scientific papers with complex terms. This way, the model can better understand and handle the specialized terminology, improving its accuracy when answering domain-specific questions.","comment_id":"1309210"}],"answer_images":[],"exam_id":14,"isMC":true,"answer_description":"","topic":"1"},{"id":"07auZAKKSKecOGcuJZSf","answer_ET":"A","answer":"A","discussion":[{"poster":"Jessiii","timestamp":"1739329560.0","comment_id":"1355400","content":"Selected Answer: A\nA. Decrease the temperature value: The temperature parameter controls the randomness of the model’s output. Lower temperatures make the model more deterministic and lead to more consistent and focused responses, while higher temperatures introduce more randomness and variety. For sentiment analysis, where you want consistent outputs for the same input, decreasing the temperature will help achieve more predictable and reliable results.","upvote_count":"1"},{"comment_id":"1310612","upvote_count":"2","poster":"Blair77","content":"Selected Answer: A\nLowering the temperature value in an LLM controls the randomness of the model's output. A lower temperature (close to 0) makes the model's predictions more deterministic and consistent, leading to similar outputs for identical prompts. This is particularly beneficial in tasks like sentiment analysis, where consistency and reliability in responses are crucial.","timestamp":"1731418620.0"},{"poster":"dehkon","content":"A. Decrease the temperature value.\n\nLowering the temperature value reduces the randomness of predictions from a large language model (LLM) and makes the output more deterministic and consistent. This is ideal for producing consistent responses to the same input prompt during sentiment analysis.","upvote_count":"3","comment_id":"1308650","timestamp":"1731045180.0"}],"topic":"1","answers_community":["A (100%)"],"question_images":[],"question_id":117,"answer_images":[],"unix_timestamp":1731045180,"url":"https://www.examtopics.com/discussions/amazon/view/150997-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","choices":{"C":"Decrease the length of output tokens.","A":"Decrease the temperature value.","D":"Increase the maximum generation length.","B":"Increase the temperature value."},"question_text":"A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company needs the LLM to produce more consistent responses to the same input prompt.\nWhich adjustment to an inference parameter should the company make to meet these requirements?","answer_description":"","timestamp":"2024-11-08 06:53:00","exam_id":14,"isMC":true},{"id":"zhaHDHVKeQNPpuSqMNQO","question_text":"A company wants to develop a large language model (LLM) application by using Amazon Bedrock and customer data that is uploaded to Amazon S3. The company's security policy states that each team can access data for only the team's own customers.\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/151076-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answer_description":"","answer":"A","discussion":[{"timestamp":"1741181040.0","poster":"HarshulSinghThakur","comment_id":"1365402","upvote_count":"1","content":"This option ensures that each team has a dedicated service role with permissions specifically tailored to access only their own customer data. This approach aligns with the company's security policy by enforcing strict access controls at the role level, ensuring that teams cannot access data belonging to other teams. By creating separate roles for each team, the solution adheres to the principle of least privilege, which is a fundamental security best practice. This method also simplifies auditing and management of access permissions, as each role's permissions can be reviewed and adjusted independently."},{"poster":"Jessiii","upvote_count":"2","content":"Selected Answer: A\nA. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.: This would require multiple service roles for Amazon Bedrock itself, which could lead to unnecessary complexity and overhead in role management. It's better to use IAM roles to control team-specific data access.","timestamp":"1739329680.0","comment_id":"1355401"},{"comment_id":"1354278","poster":"pavankvv","content":"Selected Answer: D\nBy creating a single Bedrock role with full S3 access and then using IAM roles to control access to the customer data folders, the company can meet its requirements for developing the LLM application while also adhering to its security policy.","timestamp":"1739166300.0","upvote_count":"1"},{"poster":"Moon","timestamp":"1735684980.0","comment_id":"1335059","content":"Selected Answer: A\nA: Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.\n\nExplanation:\nTo comply with the company's security policy requiring each team to access only their own customer data, the best approach is to create custom service roles in Amazon Bedrock for each team. These roles should have fine-grained permissions, granting access only to the specific Amazon S3 data (e.g., folders or buckets) associated with each team's customers. This ensures compliance with the principle of least privilege.\n\nWrong: D. Create one Amazon Bedrock role that has full Amazon S3 access. Create IAM roles for each team that have access to only each team's customer folders: Giving Bedrock full S3 access is a major security risk. Even with team-specific IAM roles, the Bedrock role could be exploited to access any data in S3.","upvote_count":"2"},{"upvote_count":"1","comment_id":"1333567","timestamp":"1735485960.0","content":"Selected Answer: A\nThe correct answer is A. Custom service roles for each team provide granular control over customer data access.","poster":"may2021_r"},{"upvote_count":"1","timestamp":"1735485900.0","content":"Selected Answer: A\nA. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.","comment_id":"1333565","poster":"may2021_r"},{"poster":"Contactfornitish","timestamp":"1733026980.0","content":"Selected Answer: D\nA. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data\nWhile this restricts data access, managing multiple service roles for Amazon Bedrock per team is unnecessarily complex and does not align with Bedrock’s design of using a single service role.\n\nB. Create a custom service role that has Amazon S3 access. Ask teams to specify the customer name on each Amazon Bedrock request\nRelying on teams to specify the customer name without enforcing access control policies does not guarantee compliance with the security policy.\n\nC. Redact personal data in Amazon S3. Update the S3 bucket policy to allow team access to customer data\nRedacting personal data is helpful for privacy but does not solve the issue of restricting access based on team-specific customer data.","comment_id":"1320448","upvote_count":"3"},{"comment_id":"1310977","upvote_count":"1","poster":"fed6485","timestamp":"1731451860.0","content":"Selected Answer: A\nit has to be A.\nB, absurd\nC, would let all teams access all data, even if scrubbed/redacted ..\nD, it would not solve the problem as Bedrock would have access, know and reply with the full knowledge of all customers, IAM roles for each team won't stop Bedrock from knowing and replying with that data.. \n\nA. \nYou can also create a custom service role and customize the attached permissions to your specific use-case. If you use the console, you can select this role instead of letting Amazon Bedrock create one for you.\n\n\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam-sr.html"},{"comment_id":"1310616","content":"Selected Answer: A\nAdherence to Principle of Least Privilege: By creating a custom service role for each team that grants access only to their specific customer data in S3, you ensure compliance with the principle of least privilege. Each team will have the minimum necessary permissions to access only their relevant data. D is wrong.","poster":"Blair77","upvote_count":"1","timestamp":"1731419040.0"},{"upvote_count":"2","poster":"taka5094","comment_id":"1310447","content":"Selected Answer: A\nCreating a Bedrock role with access to all S3 data violates the principle of least privilege.","timestamp":"1731391080.0"},{"upvote_count":"3","comments":[{"poster":"urbanmonk","comment_id":"1323159","upvote_count":"1","timestamp":"1733585760.0","content":"D makes sense on the surface but it talks about distinct customer's folders 📂 , which was not mentioned in the question. And granting Bedrock Full S3 access is certainly a huge red flag. So the answer cannot be D. That leaves \"A\" as the only plausible solution and answer."}],"comment_id":"1309495","poster":"jove","content":"I think it should be D, one IAM role for the service, and multiple IAM roles for the teams","timestamp":"1731249060.0"}],"timestamp":"2024-11-10 15:31:00","unix_timestamp":1731249060,"question_images":[],"answers_community":["A (71%)","D (29%)"],"exam_id":14,"isMC":true,"topic":"1","answer_images":[],"question_id":118,"answer_ET":"A","choices":{"B":"Create a custom service role that has Amazon S3 access. Ask teams to specify the customer name on each Amazon Bedrock request.","C":"Redact personal data in Amazon S3. Update the S3 bucket policy to allow team access to customer data.","D":"Create one Amazon Bedrock role that has full Amazon S3 access. Create IAM roles for each team that have access to only each team's customer folders.","A":"Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data."}},{"id":"SNQyGJSzhM0fhD1cSeiL","isMC":true,"choices":{"C":"Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.","B":"Configure AWS CloudTrail to monitor the model's responses and create alerts for any detected personal information.","D":"Implement Amazon SageMaker Model Monitor to detect data drift and receive alerts when model quality degrades.","A":"Use Amazon Macie to scan the model's output for sensitive data and set up alerts for potential violations."},"unix_timestamp":1731249660,"question_images":[],"answer_description":"","timestamp":"2024-11-10 15:41:00","answer_ET":"C","topic":"1","answers_community":["C (100%)"],"discussion":[{"upvote_count":"1","timestamp":"1743432900.0","poster":"Rcosmos","content":"Selected Answer: C\nExplicação:Guardrails for Amazon Bedrock permite configurar diretrizes que ajudam a impedir que os modelos fundacionais (FMs) incluam informações pessoais ou violem políticas de uso. Isso é feito por meio de filtros e regras de moderação de conteúdo.Amazon CloudWatch pode ser usado para configurar alarmes e notificações quando essas políticas forem violadas, fornecendo a visibilidade necessária em tempo real.","comment_id":"1415156"},{"comment_id":"1355402","upvote_count":"1","timestamp":"1739329740.0","content":"Selected Answer: C\nC. Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.: Guardrails for Amazon Bedrock are designed to enforce compliance and mitigate the risk of inappropriate or sensitive data being generated by foundation models. Guardrails can filter content to prevent sensitive information from being included in model outputs. Amazon CloudWatch alarms can then be configured to notify the company of potential policy violations, making it a comprehensive solution for ensuring privacy and compliance.","poster":"Jessiii"},{"poster":"Moon","comment_id":"1335081","content":"Selected Answer: C\nC: Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.\n\nExplanation:\nGuardrails for Amazon Bedrock allow you to enforce policies that filter out sensitive or inappropriate content, such as personal patient information, from the model's responses. By configuring these guardrails, you ensure that the model adheres to privacy policies. Additionally, you can set up Amazon CloudWatch alarms to receive notifications when policy violations occur, providing real-time monitoring and alerting.","upvote_count":"1","timestamp":"1735692060.0"},{"upvote_count":"1","poster":"Gianiluca","content":"Selected Answer: C\nC. Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.\n\nReasoning:\nRequirement:\n\nThe company wants to ensure that the disease detection model does not include personal patient information in its responses. This requires a mechanism to filter sensitive information from the model's outputs.\nThey also need a notification system for policy violations.\nSolution:\n\nGuardrails for Amazon Bedrock provide built-in content moderation and filtering mechanisms to enforce compliance with policies, such as removing personal information from model outputs.\nAmazon CloudWatch Alarms can be used to monitor events or logs (such as detected policy violations) and send notifications when violations occur.","comment_id":"1332503","timestamp":"1735315020.0"},{"upvote_count":"1","content":"if the answer A was slightly different.. \n\nA. Use Amazon Macie to scan the model's DATA for sensitive data and set up alerts for potential violations.\ninstead of\nA. Use Amazon Macie to scan the model's OUTPUT for sensitive data and set up alerts for potential violations.\n\n\nas Macie cannot scan the output.. but the data in S3, so A is incorrect.. so C, even if, personal information should always be removed, no point of train on it.","poster":"fed6485","timestamp":"1731464340.0","comment_id":"1311038"},{"poster":"jove","comment_id":"1309498","upvote_count":"3","timestamp":"1731249660.0","content":"Selected Answer: C\nGuardrails to prevent, CloudWatch to notify"}],"question_id":119,"exam_id":14,"answer":"C","question_text":"A medical company deployed a disease detection model on Amazon Bedrock. To comply with privacy policies, the company wants to prevent the model from including personal patient information in its responses. The company also wants to receive notification when policy violations occur.\nWhich solution meets these requirements?","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/151077-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/"},{"id":"5dlY2ECRHYJbqWYTowi2","timestamp":"2024-11-15 13:07:00","url":"https://www.examtopics.com/discussions/amazon/view/151354-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answers_community":["A (67%)","U (33%)"],"question_images":[],"unix_timestamp":1731672420,"question_id":120,"answer":"A","answer_ET":"A","question_text":"A company manually reviews all submitted resumes in PDF format. As the company grows, the company expects the volume of resumes to exceed the company's review capacity. The company needs an automated system to convert the PDF resumes into plain text format for additional processing.\nWhich AWS service meets this requirement?","choices":{"B":"Amazon Personalize","C":"Amazon Lex","A":"Amazon Textract","D":"Amazon Transcribe"},"discussion":[{"poster":"Rcosmos","content":"Selected Answer: U\nExplicação:\nAmazon Textract é um serviço da AWS que extrai automaticamente texto, dados e informações estruturadas de documentos digitalizados, como arquivos PDF ou imagens. Ele é ideal para converter currículos em texto simples para análise e processamento adicional.\nPor que as outras opções estão incorretas:\nB. Amazon Personalize: É usado para criar sistemas de recomendação personalizados, não para extrair texto de documentos.\nC. Amazon Lex: É um serviço de criação de chatbots com linguagem natural, não converte PDFs em texto.\nD. Amazon Transcribe: É usado para converter fala em texto (por exemplo, de arquivos de áudio), não para processar documentos PDF.","timestamp":"1743433440.0","comment_id":"1415163","upvote_count":"1"},{"upvote_count":"1","comment_id":"1355403","timestamp":"1739329740.0","poster":"Jessiii","content":"Selected Answer: A\nA. Amazon Textract: Amazon Textract is a fully managed service that automatically extracts text and data from scanned documents, including PDFs. It uses machine learning to identify the text in the document and converts it into a plain-text format, making it ideal for converting resumes from PDF to text for further processing."},{"comment_id":"1315752","poster":"eesa","timestamp":"1732183140.0","content":"Amazon Textract is designed to extract text, handwriting, and structured data (like tables and forms) from documents such as PDFs. It is ideal for automating the conversion of resumes into plain text format for further processing.","upvote_count":"1"},{"timestamp":"1731672420.0","content":"Selected Answer: A\nAmazon Textract is specifically designed to extract text and structured data from various types of documents, including PDFs. It can efficiently convert resumes from PDF format into plain text for further processing, even if the text is embedded in tables or forms.","poster":"tgv","upvote_count":"1","comment_id":"1312603"}],"answer_images":[],"exam_id":14,"answer_description":"","isMC":true,"topic":"1"}],"exam":{"isBeta":false,"provider":"Amazon","numberOfQuestions":154,"isImplemented":true,"name":"AWS Certified AI Practitioner AIF-C01","isMCOnly":false,"lastUpdated":"11 Apr 2025","id":14},"currentPage":24},"__N_SSP":true}