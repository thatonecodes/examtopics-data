{"pageProps":{"questions":[{"id":"2nOmgwlpzFCEgyKO0R2t","question_text":"A company that is new to AWS reports it has exhausted its service limits across several accounts that are on the Basic Support plan. The company would like to prevent this from happening in the future.\nWhat is the MOST efficient way of monitoring and managing all service limits in the company's accounts?","choices":{"C":"Use Amazon CloudWatch and AWS Lambda to periodically calculate the limits across all linked accounts using AWS Trusted Advisor, programmatically increase the limits that are close to exceeding the threshold.","A":"Use Amazon CloudWatch and AWS Lambda to periodically calculate the limits across all linked accounts using AWS Trusted Advisor, provide notifications using Amazon SNS if the limits are close to exceeding the threshold.","B":"Reach out to AWS Support to proactively increase the limits across all accounts. That way, the customer avoids creating and managing infrastructure just to raise the service limits.","D":"Use Amazon CloudWatch and AWS Lambda to periodically calculate the limits across all linked accounts using AWS Trusted Advisor, and use Amazon SNS for notifications if a limit is close to exceeding the threshold. Ensure that the accounts are using the AWS Business Support plan at a minimum."},"answer_images":[],"topic":"1","question_images":[],"answer_description":"","isMC":true,"question_id":486,"discussion":[{"timestamp":"1672229940.0","upvote_count":"1","poster":"evargasbrz","comment_id":"759796","content":"Selected Answer: D\nD-> It requires at least Business plan."},{"content":"Selected Answer: D\nD - https://aws.amazon.com/ru/blogs/mt/monitoring-service-limits-with-trusted-advisor-and-amazon-cloudwatch/","timestamp":"1670339340.0","upvote_count":"1","comment_id":"736933","poster":"SureNot"},{"poster":"et22s","comment_id":"716758","timestamp":"1668264480.0","content":"Selected Answer: D\nThis solution requires a paid plan (Business at the minimum).\n\"The stack uses AWS Support APIs which are not available under the free developer plan. For more information, refer to https://aws.amazon.com/premiumsupport/plans\"\n\nSource: https://docs.aws.amazon.com/solutions/latest/quota-monitor-for-aws/plan-your-deployment.html","upvote_count":"2"},{"timestamp":"1668061440.0","content":"Selected Answer: D\nD - You'll need business support plan for most functionality.\n- In fact, with \"basic\" support, you may have trouble even getting a ticket logged!\nRan into this scenario recently.\nSure - basic checks are available in the trusted advisor console - However, you can't report on them using cloudwatch etc","comment_id":"714965","poster":"janvandermerwer","upvote_count":"2"},{"content":"D\nhttps://docs.aws.amazon.com/solutions/latest/quota-monitor-on-aws/welcome.html\n\"To use this solution, each account must have a Business- or Enterprise-level AWS Support plan in order to gain access to the Trusted Advisor service quota checks.\"","upvote_count":"1","comment_id":"670156","timestamp":"1663262880.0","poster":"dcdcdc3"},{"comment_id":"660503","content":"Selected Answer: D\nIt's D. Here is the proof you need:\n\nhttps://aws.amazon.com/solutions/implementations/quota-monitor/","poster":"epomatti","upvote_count":"2","timestamp":"1662406560.0"},{"comment_id":"626409","poster":"nm4u","timestamp":"1656823740.0","upvote_count":"1","content":"AWS Documentation says below. \nIf you have a Basic or Developer Support plan, you can use the Trusted Advisor console to access all checks in the Service Limits category and six checks in the Security category.\n\nIf you have a Business, Enterprise On-Ramp, or Enterprise Support plan, you can use the Trusted Advisor console and the AWS Support API to access all Trusted Advisor checks.\n\nBased on this, the Correct answer should be A.","comments":[{"poster":"nm4u","comment_id":"626414","content":"Changing to D. \nReason explained below. It's very tricky question. \nYes, we basic support, you can use trusted advisor console to access all checks in service limit. However, for the given usecase, we need to have the service/quota monitoring automatically using lambda which will use aws trusted advisor via api calls. So correct answer should be D. \nReference: https://docs.aws.amazon.com/solutions/latest/quota-monitor-on-aws/welcome.html","upvote_count":"4","timestamp":"1656824520.0"}]},{"comments":[{"content":"A is right https://aws.amazon.com/premiumsupport/plans/\nD is wrong","comment_id":"602082","upvote_count":"1","timestamp":"1652618040.0","poster":"user0001"},{"comment_id":"611332","timestamp":"1654319580.0","poster":"bobsmith2000","content":"https://docs.aws.amazon.com/awssupport/latest/user/trustedadvisor.html\nThere are no mentions of any restrictions","upvote_count":"1"}],"content":"D as trust advisor API is not available for basic plan.\nhttps://docs.aws.amazon.com/awssupport/latest/user/Welcome.html","comment_id":"570309","timestamp":"1647589080.0","upvote_count":"3","poster":"KengL"},{"timestamp":"1646935140.0","poster":"Sonujunko","comment_id":"564928","comments":[{"timestamp":"1665399660.0","content":"Trusted Advisor CONSOLE","comment_id":"691034","poster":"wassb","upvote_count":"1"}],"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/awssupport/latest/user/trusted-advisor.html\n\n\" If you have a Basic or Developer Support plan, you can use the Trusted Advisor console to access all checks in the Service Limits category and six checks in the Security category.\"","upvote_count":"1"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/solutions/latest/limit-monitor/deployment.html\nPrerequisites\nTo use this solution, each account must have a Business- or Enterprise-level AWS Support plan in order to gain access to the Trusted Advisor Service Limits checks.","timestamp":"1645972380.0","upvote_count":"2","comment_id":"557374","poster":"Alexey79"},{"poster":"padel","upvote_count":"1","comment_id":"538046","timestamp":"1643733300.0","content":"Why not A instead of D ?"},{"content":"Selected Answer: D\nIt's D","upvote_count":"2","poster":"Bigbearcn","timestamp":"1643589240.0","comment_id":"536572"},{"poster":"tkanmani76","content":"Should be D","comment_id":"522623","upvote_count":"2","timestamp":"1642047240.0"},{"comment_id":"518425","upvote_count":"1","poster":"wahlbergusa","timestamp":"1641489960.0","content":"From \"Trusted Advisor\" page : \"AWS Basic Support and AWS Developer Support customers can access core security checks and all checks for service quotas.\"\n\nI think it should be A. (sample solution : https://aws.amazon.com/solutions/implementations/limit-monitor/)"},{"poster":"AndySH","content":"Answer is D","comment_id":"516939","upvote_count":"1","timestamp":"1641324480.0"}],"answers_community":["D (92%)","8%"],"answer":"D","unix_timestamp":1641324480,"exam_id":32,"answer_ET":"D","timestamp":"2022-01-04 20:28:00","url":"https://www.examtopics.com/discussions/amazon/view/69474-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"v4yAl4R2j5YyChldwqj4","unix_timestamp":1568131980,"topic":"1","answers_community":["BC (57%)","CE (43%)"],"answer":"BC","answer_ET":"CE","question_text":"A company runs an IoT platform on AWS. IoT sensors in various locations send data to the company's Node.js API servers on Amazon EC2 instances running behind an Application Load Balancer. The data is stored in an Amazon RDS MySQL DB instance that uses a 4 TB General Purpose SSD volume.\nThe number of sensors the company has deployed in the field has increased over time, and is expected to grow significantly. The API servers are consistently overloaded and RDS metrics show high write latency.\nWhich of the following steps together will resolve the issues permanently and enable growth as new sensors are provisioned, while keeping this platform cost- efficient? (Choose two.)","discussion":[{"comment_id":"13296","content":"I will go with \"C & E\".\nA: 6TB will not resolve the issue permanently.\nB: the issue in the question is writing issue. So why we need read replica!\nC: Kinesis is always best for IoT and load.\nD: does not make sense.\nE: the question does not say anything about keeping the same DB architect! Dynamo is so scalable, for indefinitely solution.","poster":"Moon","timestamp":"1632752820.0","upvote_count":"37","comments":[{"upvote_count":"4","poster":"Ibranthovic","content":"I was thinking about B, but i read your command, and i agree with you.\nIt's C and E","comment_id":"14566","timestamp":"1632964560.0","comments":[{"poster":"MultiAZ","timestamp":"1634302200.0","comments":[{"poster":"DerekKey","upvote_count":"5","comment_id":"425116","content":"You are wrong. The problem is related to writing information to DB. This Aurora implementation will have one WRITER. The problem will persist.","timestamp":"1636140720.0"}],"comment_id":"143321","content":"Actually B is better than E. Dynamo will add quite some cost, which is not according to the requirement.\nGenerally Aurora will perform better on writes than MySQL. Offloading the read queries (which are nto problematic, but still add load on the IO subsystem) to read replica will leave more room for your writes.\nAMD Aurora is very scalable, just like Dynamo, though lacking the single-millisecond response times","upvote_count":"2"}]},{"poster":"AWSum1","content":"Thanks for pointing out why E is valid. I didn't think of it in that way","comment_id":"449667","upvote_count":"1","timestamp":"1636242660.0"}]},{"timestamp":"1632074580.0","poster":"dpvnme","comment_id":"10469","upvote_count":"21","content":"C&E would be my choice"},{"poster":"khatingarun","content":"Selected Answer: CE\nc and e is correct because this issue is with the writing and aurora has only one writer instance","upvote_count":"1","comment_id":"1346378","timestamp":"1737791760.0"},{"content":"Selected Answer: BC\nAmazon Aurora is 5X faster than RDS for MySQL. Also, it's automatically scalable which is one of the requirement. DynamoDB can't be used because it's a non-sql DB. Thus, then only option which provides scalability is option B and makes it one of the right options. For the API performance, option C takes care of that. Just adding more API servers won't help. The bottleneck is on database writes and not at the API level.","comment_id":"1299490","timestamp":"1729209780.0","poster":"Sin_Dan","upvote_count":"2"},{"upvote_count":"1","comment_id":"930835","poster":"SkyZeroZx","timestamp":"1687454640.0","content":"Selected Answer: CE\nI will go with \"C & E\".\nA: 6TB will not resolve the issue permanently.\nB: the issue in the question is writing issue. So why we need read replica!\nC: Kinesis is always best for IoT and load.\nD: does not make sense.\nE: the question does not say anything about keeping the same DB architect! Dynamo is so scalable, for indefinitely solution."},{"poster":"milofficial","comment_id":"837058","upvote_count":"1","timestamp":"1678628400.0","content":"Selected Answer: CE\nC & E is correct"},{"poster":"andras","content":"Selected Answer: BC\nAurora gives two times throughput performance provided by PostgreSQL or five times the throughput provided by standard MySQL running on similar hardware.","upvote_count":"2","comment_id":"816489","timestamp":"1676979000.0"},{"content":"Aurora gives two times throughput performance provided by PostgreSQL or five times the throughput provided by standard MySQL running on similar hardware.","timestamp":"1676978880.0","upvote_count":"1","comment_id":"816485","poster":"andras"},{"timestamp":"1665588000.0","poster":"joanneli77","content":"I'm not sure how you can assume DynamoDB is appropriate for the data if it has already been deployed to RDS. Are we assuming intelligence, or assuming stupidity of prior engineers?","comment_id":"693196","upvote_count":"2"},{"poster":"KiraguJohn","content":"If you change RDS to Dynamo DB will you also not be required to make some changes on Nodejs code as well?","comment_id":"627165","timestamp":"1656982080.0","upvote_count":"1"},{"content":"C. Leverage Amazon Kinesis Data Streams and AWS Lambda to ingest and process the raw data\nE. Re-architect the database tier to use Amazon DynamoDB instead of an RDS MySQL DB instance","comment_id":"497588","poster":"cldy","timestamp":"1639044960.0","upvote_count":"1"},{"content":"C & E is the right answer","upvote_count":"1","poster":"AzureDP900","timestamp":"1638735240.0","comment_id":"494628"},{"timestamp":"1635935880.0","upvote_count":"1","comment_id":"411125","content":"I'll go with C,E","poster":"WhyIronMan"},{"content":"It's C&E","timestamp":"1635910020.0","comment_id":"346943","poster":"Waiweng","upvote_count":"3"},{"content":"Going with C&E","upvote_count":"1","timestamp":"1635846540.0","comment_id":"316495","poster":"awsexamprep47"},{"comment_id":"291695","poster":"Kian1","timestamp":"1635827760.0","content":"going with CE","upvote_count":"1"},{"poster":"Trap_D0_r","upvote_count":"1","comment_id":"282810","timestamp":"1635461160.0","comments":[{"content":"Dude you need to change the way you think. If you want to add more instances how many you will add to fix the load issue permanently? Also is it cost efficient to add more servers???!","timestamp":"1635637740.0","poster":"Ebi","comment_id":"286744","upvote_count":"3"}],"content":"CD\n\"The API Servers are constantly overloaded\" only one answer addresses the API limit issue, and that's D. D must be one of the answers. As someone else stated, Kinesis makes the most sense here. Kinesis will address the high write latency with Lambda to do processing/transforms and more API servers will address the API bottleneck."},{"content":"I go with CE","poster":"Ebi","comment_id":"280237","upvote_count":"3","timestamp":"1635321600.0"},{"poster":"Firststack","upvote_count":"1","content":"C & E for me","timestamp":"1635227520.0","comment_id":"279692"},{"comment_id":"251888","timestamp":"1635206580.0","upvote_count":"2","content":"C & E is the right answer","poster":"Bulti"},{"poster":"petebear55","timestamp":"1635111120.0","content":"YES B WILL NOT BE 'cost efficient' c and E","upvote_count":"1","comment_id":"247539"},{"upvote_count":"2","content":"Correct is CE. Kinesis + DynamoDB","poster":"T14102020","timestamp":"1635065100.0","comment_id":"243478"},{"content":"I'll go with C,E","upvote_count":"4","comment_id":"230837","timestamp":"1634820960.0","poster":"jackdryan"},{"timestamp":"1634737140.0","poster":"gookseang","content":"CE seems","comment_id":"230103","upvote_count":"2"},{"upvote_count":"1","poster":"kj07","timestamp":"1634625600.0","content":"First I thought BC, but I think CE has more sense in a serverless approach.","comment_id":"226056"},{"poster":"Paitan","upvote_count":"2","comment_id":"197440","content":"C and E","timestamp":"1634625540.0"},{"comment_id":"151820","content":"C & E is correct","upvote_count":"2","poster":"fullaws","timestamp":"1634588880.0"},{"upvote_count":"3","poster":"IAmNotLambda","timestamp":"1634070540.0","comment_id":"141094","content":"By choosing C are we suggesting to get rid of ALB and API Servers on EC2 Instance?\n\nI would go for D and E. X-Ray to analyze and debug API issues!"},{"content":"CE for sure","comment_id":"133170","poster":"NikkyDicky","upvote_count":"1","timestamp":"1633973100.0"},{"poster":"sami777","timestamp":"1633732380.0","comment_id":"131695","content":"C,E are correct.","upvote_count":"1"},{"content":"C&E is my choice too","timestamp":"1633656660.0","poster":"NKnab","upvote_count":"1","comment_id":"102124"},{"upvote_count":"1","content":"C,E are the best answers","poster":"AShahine21","comment_id":"94734","timestamp":"1633617300.0"},{"poster":"zdd","timestamp":"1633569000.0","upvote_count":"1","comment_id":"74305","content":"D,E \nD : resolve the issues : The API servers are consistently overloaded\nE : resolve the issues : RDS metrics show high write latency."},{"upvote_count":"7","timestamp":"1633413900.0","comment_id":"61946","content":"C & E\nA: RDS is not good for scale, especially with high writes\nB: Although Aurora is better than RDS MySQL. Read replica is to improve read heavy performance. \nC: Whenever IoT, Kinesis is good. here Kinesis+Lambda, good pair to ingest and process IoT data\nD: NOT related\nE: DynamoDB, very good for databases, when scalability","poster":"paulwang"},{"comment_id":"51672","upvote_count":"4","timestamp":"1633298520.0","content":"Should be C, E","poster":"amog"},{"comment_id":"44446","poster":"dumma","content":"C and E are correct","upvote_count":"4","timestamp":"1633254180.0"},{"poster":"Scunningham99","content":"c and e","timestamp":"1633138800.0","comment_id":"27872","upvote_count":"3"},{"poster":"donathon","content":"CE\nA: This will not improve the IOPS and is not sustainable.\nB: The issue is with write not read.\nD: X-Ray is use to analyze and debug applications not a DB.","comment_id":"13650","comments":[{"upvote_count":"2","timestamp":"1634431980.0","content":"A : Definitely this increase the iops from 12,000 to 16,000 but no one can not sure 16,000 is enough","comment_id":"149035","poster":"AICOO"}],"timestamp":"1632923100.0","upvote_count":"11"},{"timestamp":"1632724200.0","upvote_count":"5","poster":"awsami","content":"is it B&C ? Option E doesn't seems right , conversion from sql database and nosql dynamodb","comment_id":"13090"},{"upvote_count":"1","timestamp":"1632425340.0","comments":[{"comment_id":"11880","upvote_count":"3","content":"yeah but it needs to resolve the issues permanently. 6TB can't scale","poster":"dpvnme","timestamp":"1632666780.0"}],"comment_id":"11622","content":"AC. cost-efficient","poster":"Lee"}],"answer_description":"","exam_id":32,"choices":{"E":"Re-architect the database tier to use Amazon DynamoDB instead of an RDS MySQL DB instance","D":"Use AWS X-Ray to analyze and debug application issues and add more API servers to match the load","C":"Leverage Amazon Kinesis Data Streams and AWS Lambda to ingest and process the raw data","A":"Resize the MySQL General Purpose SSD storage to 6 TB to improve the volume's IOPS","B":"Re-architect the database tier to use Amazon Aurora instead of an RDS MySQL DB instance and add read replicas"},"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/5011-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"2019-09-10 18:13:00","answer_images":[],"question_id":487,"isMC":true},{"id":"8l7gp0AFa86D4UTq1uti","isMC":true,"topic":"1","choices":{"B":"Use Import/Export to import the VM as an ESS snapshot and attach to EC2.","D":"Use me ec2-bundle-instance API to Import an Image of the VM into EC2","A":"Use the EC2 VM Import Connector for vCenter to import the VM into EC2.","C":"Use S3 to create a backup of the VM and restore the data into EC2."},"answer_images":[],"question_text":"You are responsible for a legacy web application whose server environment is approaching end of life You would like to migrate this application to AWS as quickly as possible, since the application environment currently has the following limitations:\n✑ The VM's single 10GB VMDK is almost full;\n✑ Me virtual network interface still uses the 10Mbps driver, which leaves your 100Mbps WAN connection completely underutilized;\n✑ It is currently running on a highly customized. Windows VM within a VMware environment;\n✑ You do not have me installation media;\nThis is a mission critical application with an RTO (Recovery Time Objective) of 8 hours. RPO (Recovery Point Objective) of 1 hour.\nHow could you best migrate this application to AWS while meeting your business continuity requirements?","unix_timestamp":1578801960,"discussion":[{"timestamp":"1632074820.0","poster":"amog","comment_id":"37908","content":"Answer is A\nEC2 VM Import/Export enables importing virtual machine (VM) images from existing virtualization environment to EC2, and then export them back\nEC2 VM Import/Export enables\nmigration of applications and workloads to EC2,\ncoping VM image catalog to EC2, or\ncreate a repository of VM images for backup and disaster recovery\nto leverage previous investments in building VMs by migrating your VMs to EC2.\nThe supported file formats are: VMware ESX VMDK images, Citrix Xen VHD images, Microsoft Hyper-V VHD images, and RAW images\nFor VMware vSphere, AWS Connector for vCenter can be used to export a VM from VMware and import it into Amazon EC2\nFor Microsoft Systems Center, AWS Systems Manager for Microsoft SCVMM can be used to import Windows VMs from SCVMM to EC2","upvote_count":"12"},{"poster":"amministrazione","timestamp":"1723751100.0","content":"A. Use the EC2 VM Import Connector for vCenter to import the VM into EC2.","upvote_count":"1","comment_id":"1266646"},{"content":"Selected Answer: A\nkeyword = EC2 VM Import Connector","poster":"SkyZeroZx","upvote_count":"1","timestamp":"1687192740.0","comment_id":"927696"},{"timestamp":"1649094600.0","comment_id":"580870","content":"Selected Answer: A\nVote A","upvote_count":"1","poster":"roka_ua"},{"comment_id":"406237","upvote_count":"1","timestamp":"1636180200.0","content":"A Correct","poster":"Akhil254"},{"timestamp":"1636074720.0","upvote_count":"1","poster":"01037","comment_id":"347764","content":"A is the better solution"},{"comment_id":"325494","content":"A.\nhttps://aws.amazon.com/about-aws/whats-new/2011/03/04/Announcing-VMImport-Connector/\nhttps://aws.amazon.com/blogs/aws/ec2-vm-import-connector/","poster":"cldy","upvote_count":"1","timestamp":"1635922860.0"},{"poster":"fullaws","timestamp":"1635668400.0","content":"A is correct","upvote_count":"1","comment_id":"143878"},{"comment_id":"136173","upvote_count":"1","comments":[{"upvote_count":"4","content":"https://aws.amazon.com/de/blogs/aws/ec2-vm-import-connector/","poster":"fcbflo","comment_id":"139116","timestamp":"1635483900.0"}],"poster":"DuyPhan","content":"initially, i go with A, but there is no \"EC2 VM Import Connector for vCenter\"\nThere is only have Server Migration Connector which used to migrate on-premise VM to AWS.\nSo, i go with B","timestamp":"1635249720.0"},{"comment_id":"131112","timestamp":"1634522940.0","content":"go with A","upvote_count":"1","poster":"noisonnoiton"},{"upvote_count":"1","comment_id":"113030","timestamp":"1634511780.0","content":"My answer is A. Import/Export which is called Snowball, is used to transfer large amount of data","poster":"ricoyao","comments":[{"timestamp":"1634890680.0","upvote_count":"3","content":"This is VM Import/Export and not AWS import export, A is still the right answer","poster":"khksoma","comment_id":"132262"}]},{"content":"B is the answer.","upvote_count":"2","timestamp":"1633887060.0","poster":"JAWS1600","comment_id":"107013"},{"comments":[{"timestamp":"1633966860.0","comment_id":"107333","content":"Someone needs to ban this guy","comments":[{"comment_id":"108177","content":"Big time","upvote_count":"7","poster":"meenu2225","timestamp":"1634179800.0"}],"poster":"wlc90210","upvote_count":"17"}],"timestamp":"1633877280.0","comment_id":"107006","upvote_count":"1","poster":"JAWS1600","content":"B\nis the right answer"},{"upvote_count":"3","timestamp":"1632595920.0","poster":"BillyC","content":"A is Correct!","comment_id":"49907"},{"timestamp":"1632351780.0","comments":[{"upvote_count":"2","timestamp":"1632885540.0","comment_id":"69588","content":"That is what I think too, it should be S3 first.","poster":"kakashi"}],"content":"I understand A definitely is better but wonder why B is incorrect? Is it simply because an EBS snapshot cannot be directly attach to EC2?","upvote_count":"2","poster":"EricZhang","comment_id":"40592"}],"answers_community":["A (100%)"],"answer_ET":"A","question_id":488,"exam_id":32,"answer":"A","question_images":[],"timestamp":"2020-01-12 05:06:00","answer_description":"Reference:\nhttps://aws.amazon.com/developertools/2759763385083070","url":"https://www.examtopics.com/discussions/amazon/view/11792-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"g2zdbS6g2C0tHQfD9WWU","question_text":"A Solutions Architect is designing a system that will collect and store data from 2,000 internet-connected sensors. Each sensor produces 1 KB of data every second. The data must be available for analysis within a few seconds of it being sent to the system and stored for analysis indefinitely.\nWhich is the MOST cost-effective solution for collecting and storing the data?","choices":{"A":"Put each record in Amazon Kinesis Data Streams. Use an AWS Lambda function to write each record to an object in Amazon S3 with a prefix that organizes the records by hour and hashes the record's key. Analyze recent data from Kinesis Data Streams and historical data from Amazon S3.","D":"Put each record into an object in Amazon S3 with a prefix what organizes the records by hour and hashes the record's key. Use S3 lifecycle management to transition objects to S3 infrequent access storage to reduce storage costs. Analyze recent and historical data by accessing the data in Amazon S3","B":"Put each record in Amazon Kinesis Data Streams. Set up Amazon Kinesis Data Firehouse to read records from the stream and group them into objects in Amazon S3. Analyze recent data from Kinesis Data Streams and historical data from Amazon S3.","C":"Put each record into an Amazon DynamoDB table. Analyze the recent data by querying the table. Use an AWS Lambda function connected to a DynamoDB stream to group records together, write them into objects in Amazon S3, and then delete the record from the DynamoDB table. Analyze recent data from the DynamoDB table and historical data from Amazon S3"},"answer_images":[],"topic":"1","answer_description":"","question_images":[],"question_id":489,"isMC":true,"discussion":[{"timestamp":"1632470880.0","upvote_count":"26","poster":"Moon","content":"I prefer \"B\" for scalability and cost-effectiveness..\nEven I like A, for grouping by prefixes. But that is not a requirement in the question. Plus answer B is saying \"group them into objects in amazon S3\". So it has some sort of classification for the streams in groups...maybe per second!!\nSo, my preference is B.","comment_id":"13294","comments":[{"comment_id":"341601","timestamp":"1636105380.0","upvote_count":"8","poster":"dijesim222","content":"cost for s3 puts : 24 hr/day * 60 min/hr * 60 sec/min * 2000 req/sec * 0.005e-3 usd/req = 864 $/day\ncost for kinesis data streams: \n required shards (2) : 24 hr/day * 0.015 $/hr/shard * 2 shards = 0.72 $/day\n puts (1kb is 1 payload unit): 24 hr/day * 60 min/hr * 60 sec/min * 2000 req/sec * 0.014e-6 $/req = 2.42 $/day\n\nhuge cost difference.."},{"poster":"Byrney","timestamp":"1667796000.0","comment_id":"712807","upvote_count":"1","content":"Custom prefixes are possible with Firehose (option B):\nhttps://aws.amazon.com/blogs/big-data/amazon-kinesis-data-firehose-custom-prefixes-for-amazon-s3-objects/"}]},{"timestamp":"1632360360.0","poster":"huhupai","comment_id":"11146","comments":[{"poster":"dpvnme","timestamp":"1632385320.0","comment_id":"11881","content":"on second read, i'll go with B too","comments":[{"timestamp":"1634901060.0","comment_id":"212604","content":"B is better than A , since its about cost-effective solution.\nChoosing A involves lambda - that only adds cost to the equation.","poster":"jar0d","upvote_count":"1"}],"upvote_count":"3"}],"content":"I prefer B.","upvote_count":"12"},{"poster":"SkyZeroZx","comment_id":"930840","timestamp":"1687454820.0","upvote_count":"1","content":"Selected Answer: B\nI prefer \"B\" for scalability and cost-effectiveness..\nEven I like A, for grouping by prefixes. But that is not a requirement in the question. Plus answer B is saying \"group them into objects in amazon S3\". So it has some sort of classification for the streams in groups...maybe per second!!\nSo, my preference is B."},{"content":"Selected Answer: B\nB - Firehose is cheaper than lambda. There is no requirement stated for manipulating the data, hence no requirement for Lambda making A incorrect.","comment_id":"660507","timestamp":"1662406920.0","poster":"epomatti","upvote_count":"1"},{"comment_id":"654381","poster":"Rocketeer","content":"B is more practical. I can buffer, group and write data to S3 every 60 secs. I do not want to write a file to S3 every seconds using the lambda.","upvote_count":"1","timestamp":"1661888700.0"},{"upvote_count":"1","poster":"bobsmith2000","timestamp":"1652856780.0","content":"Selected Answer: B\nB no-brainer.\nData Streams for injecting data and realtime processing, Fire Hose for buffering and storing in S3.\nClassic.","comment_id":"603185"},{"upvote_count":"1","poster":"Alexey79","comment_id":"557878","content":"Selected Answer: A\n“Within a few seconds of being submitted to the system, the data must be accessible for processing”\nKinesis Firehouse buffer time minimum 60 sec.\nReal-time solution is required, which replaces Firehouse by Lamda.\nhttps://aws.amazon.com/kinesis/","comments":[{"content":"B is right answer as you can use Amazon Kinesis Data Streams for recent data and s3 for historical ,","upvote_count":"1","poster":"user0001","comment_id":"602093","timestamp":"1652619840.0"}],"timestamp":"1646025960.0"},{"comment_id":"497375","upvote_count":"1","poster":"cldy","timestamp":"1639030320.0","content":"B. Put each record in Amazon Kinesis Data Streams. Set up Amazon Kinesis Data Firehouse to read records from the stream and group them into objects in Amazon S3. Analyze recent data from Kinesis Data Streams and historical data from Amazon S3."},{"content":"B is my choice","poster":"AzureDP900","comment_id":"494630","upvote_count":"1","timestamp":"1638735480.0"},{"content":"Selected Answer: B\nB is the right answer. Kinesis Data stream with Kinesis Forehouse reading and buffering from it to write to S3 is a standard ingestion pattern for ingesting IoT data.","comment_id":"484674","upvote_count":"1","poster":"acloudguru","timestamp":"1637629860.0"},{"timestamp":"1636277760.0","content":"I'll go with B","comment_id":"411128","poster":"WhyIronMan","upvote_count":"1"},{"upvote_count":"2","comment_id":"346944","poster":"Waiweng","content":"it's B","timestamp":"1636233720.0"},{"content":"B is the answer","timestamp":"1636108800.0","upvote_count":"1","comment_id":"346708","poster":"blackgamer"},{"comment_id":"316497","content":"B is the answer\nPerfect use case for Kinesis Data Stream,Kinesis Firehose & S-3 combination","upvote_count":"1","timestamp":"1636026660.0","poster":"awsexamprep47"},{"content":"it is B","timestamp":"1635654780.0","poster":"Kian1","comment_id":"291704","upvote_count":"1"},{"comments":[{"content":"Nevermind, It's B","timestamp":"1635632280.0","upvote_count":"2","poster":"lechuk","comment_id":"288698"}],"comment_id":"288695","poster":"lechuk","upvote_count":"1","content":"A. \nFirehose has ~60 seconds latency","timestamp":"1635388860.0"},{"poster":"Ebi","comment_id":"280239","timestamp":"1635334080.0","upvote_count":"5","content":"Definitely B"},{"content":"B is the right answer. Kinesis Data stream with Kinesis Forehouse reading and buffering from it to write to S3 is a standard ingestion pattern for ingesting IoT data.","upvote_count":"2","comment_id":"251890","timestamp":"1635283680.0","poster":"Bulti"},{"comment_id":"243484","timestamp":"1635076080.0","content":"Correct is B. Kinesis Streams + Kinesis Firehose","upvote_count":"1","poster":"T14102020"},{"poster":"howardxie","comment_id":"234727","timestamp":"1635021240.0","content":"not b,there is no need to group record,don't mention it.\nand firehorse charged by minium size of 5KB which the sensor data is 1KB per record,too expensive","upvote_count":"1"},{"comment_id":"230838","timestamp":"1634928000.0","upvote_count":"2","content":"I'll go with B","poster":"jackdryan"},{"upvote_count":"1","content":"BBBBBBBBBBB","timestamp":"1634920560.0","poster":"gookseang","comment_id":"230104"},{"content":"B is the Answer; data is less than 1024KB; kinesis data stream with kinesis fire hose works well","comment_id":"220606","timestamp":"1634911920.0","poster":"jaykris123","upvote_count":"1"},{"timestamp":"1634888400.0","comment_id":"197609","content":"Definitely B. Another common topic from the Data Analytics Specialty exam.","upvote_count":"1","poster":"Paitan"},{"timestamp":"1634786640.0","poster":"fullaws","comment_id":"151830","upvote_count":"1","content":"B is correct, lambda max concurrent execution is 1000. few second available as the application is read from kinesis stream instead of firehose"},{"content":"by the way Streams can push data to S3 directly. In \"A\" we are using Lambda to do that, which I believe is not required. B it is.","comment_id":"141099","upvote_count":"1","poster":"IAmNotLambda","timestamp":"1634667420.0"},{"comment_id":"133172","upvote_count":"1","content":"B for sure","timestamp":"1634663280.0","poster":"NikkyDicky"},{"poster":"chicagomassageseeker","timestamp":"1634649120.0","content":"Take 2: Revised Answer B.\n\nThis example was discussed in udemy course. Here are the numbers.\n\nRemember the two key factors for a final decision. \n1.Data availability in few seconds. \n2.MOST cost-effective solution for collecting and storing the data\n\nLet’s see which is the most Cost-effective solution Kinesis vs DynamoDB Streams.\n\n2000 internet sensor producing 1kb every second = 2000Kb per second of data.\nSo you need 2 Shards in kinesis = 2MB/sec\n2Shards * $0.015/hr (cost per shard) for a month = $21.6 per month\n\nDynamo DB Streams:\nYou will need 2000 WCU for 2000 KB as 1 WCU = 1KB\n1 WCU = $0.00065 \nSo 2000 WCU = 2MB/s will cost you $936 per Month.\n\nSo Dynamo DB is COSTLIEST. Rule out C.\n\nNow between A and B. Kinesis Data streams are real time compared to Firehose( 60 seconds latency). However, The only way you can write to S3 (durable location) is by using Firehose.","comment_id":"120824","upvote_count":"7"},{"timestamp":"1634517120.0","upvote_count":"3","content":"Answer A\nFirehose in not real time. question says that the data needs to be available in few seconds. firehose has minimum 60 second delay.","comment_id":"120789","poster":"chicagomassageseeker","comments":[{"timestamp":"1634608260.0","upvote_count":"3","comment_id":"120822","content":"Take 2: Revised Answer B. This example was discussed in udemy course. Here are the numbers. Remember the two key factors for a final decision. 1.Data availability in few seconds. 2.MOST cost-effective solution for collecting and storing the data Let’s see which is the most Cost-effective solution Kinesis vs DynamoDB Streams. 2000 internet sensor producing 1kb every second = 2000Kb per second of data. So you need 2 Shards in kinesis = 2MB/sec 2Shards * $0.015/hr (cost per shard) for a month = $21.6 per month Dynamo DB Streams: You will need 2000 WCU for 2000 KB as 1 WCU = 1KB 1 WCU = $0.00065 So 2000 WCU = 2MB/s will cost you $936 per Month. So Dynamo DB is COSTLIEST. Rule out C. Now between A and B. Kinesis Data streams are real time compared to Firehose( 60 seconds latency). However, The only way you can write to S3 (durable location) is by using Firehose.","poster":"chicagomassageseeker"}]},{"timestamp":"1634428440.0","comment_id":"100551","content":"B is correct -https://docs.aws.amazon.com/firehose/latest/dev/writing-with-kinesis-streams.html","upvote_count":"2","poster":"NKnab"},{"timestamp":"1634387820.0","comment_id":"94356","upvote_count":"2","poster":"Merlin1","content":"The real time data is analyzed from streams not firehose, so I think the firehose buffer here may be a good thing as it keeps the data in streams longer and thus available for RT analytics. Plus it groups data as objects and time stamps them prior to s3 which cuts down on put costs and indexes objects by time. Assuming seconds. Im thinking B"},{"content":"Basically the q is unanswerable given the info none of the As are complete : I will say D on basis of cost over B \nA. No lambda can only do 1000 concurrent connections otherwise this is a documented way of using Kinesis Data Streams.\nB No-Yes : Works IF you have a front end to consume the data as a Consumer (Amazon Kinesis Data Streams application) Link ; is a documented way of sending data to S3. \nC. No Works IF you e.g. use AWS IOT to consume the data .. BUT possible are going to hit Lambda current connections limit.. \nD Yes-No Works IF you have a front end to consume the data .. supports the ingestion rate, and I would say is the cheapest ongoing.","poster":"bertman","upvote_count":"3","comment_id":"83943","timestamp":"1634136180.0"},{"poster":"fw","timestamp":"1634097720.0","content":"B.\nIt analyzes recent data from Kinesis Data Streams in real time, not from Firehose which has 1 minute delay.","comment_id":"83128","upvote_count":"2"},{"comment_id":"77770","content":"B is my answer","poster":"Joeylee","upvote_count":"2","timestamp":"1634063280.0"},{"content":"B (Invalid): \"Kinesis Data Firehose buffers incoming data before delivering it to Amazon S3. You can choose a buffer size (1–128 MBs) or buffer interval (60–900 seconds).\" Doesn't meet the requirement of having data available within few seconds. This is the typical solution for IoT architecture. \nC (Invalid): Using a longer route, DynamoDB to Lambda to S3. Using DynamoDB by itself should work. \nA (Valid): Kinesis helps maintain data for 24 hours. In Lambda's Trigger Config, you can specify Batch Size & Window (example: 500 records/sec from stream). Don't need to trigger 2K functions concurrently. \nD (Valid): S3 can handle 3500 PUT request/second per prefix so I dont' see the problem here. \n\nIoT architecture would use Lambda for transformation, Firehose for buffering or format conversion. None of it is happening here. We just need to dump data in S3. Each options will have same Put/Gets requests. Let me know if I am missing something here.","comment_id":"77068","upvote_count":"3","timestamp":"1634025300.0","poster":"Smart","comments":[{"content":"2000 sensors each producing 1KB per second! thats approximately 2MB per second. Kinesis Firehouse can delivery Buffer size from 1 MB ! we can certainly use it in current scenario. I think B is the right answer.","upvote_count":"1","comment_id":"91714","comments":[{"comment_id":"91717","upvote_count":"1","content":"Actually. Though I have used it.. I am bit confused, if firehouse will wait minimum no of seconds given in bufferInterval if minimumBufferSize is reaches quickly. But in general Firehose is only for near real time. If we need real time, we must use Streams + Lambda, which will be A.","timestamp":"1634277240.0","poster":"BVV"}],"timestamp":"1634199120.0","poster":"BVV"},{"content":"IGNORE - I misread option B; I thought S3 was used for both immediate analysis and late analysis.\n\nB is correct. Stream itself have 1-sec latency; Firehose has batch and compression capabilities that will bring down the cost.","timestamp":"1634167380.0","poster":"Smart","upvote_count":"1","comment_id":"84780"}]},{"upvote_count":"1","content":"A doesn't feel right, because Lambda wouldn't be able to handle the influx of records, D doesn't say anything about how we're analyzing the data, but then the question wasn't about how we could analyze the costs, so at first glance it sounds feasible - until you look at the costs of multi-millions of PUT/GET operations you'd need to analyze this data every single day, so D is also a No-GO. S3 is the recommended solution for storage here, so in order to reduce our costs we need to condense the data first. Both B and C could achieve this technically. But C wouldn't allow us to analyze any recent data since all data is wiped every second, so B gets my favours.","poster":"MrP","comment_id":"57357","timestamp":"1633757160.0"},{"upvote_count":"3","comment_id":"55046","timestamp":"1633540740.0","poster":"Mobidic","content":"B is not cost effective since it's using both firehose and kinesis stream to do the same thing than a."},{"upvote_count":"1","poster":"amog","timestamp":"1633262040.0","content":"Agree B","comment_id":"51674"},{"poster":"KatiePerry","content":"you need the data back within 2 seconds, kinesis will not give data back in 3 seconds. hence C is the answer","comment_id":"40509","timestamp":"1633195500.0","upvote_count":"3"},{"comment_id":"30738","content":"C is correct answer.\nS3 becomes costlier due to the frequency of PUTs per second. we need to aggregate it before sending to S3 as a permanent store.","poster":"dojo","timestamp":"1633117380.0","upvote_count":"2"},{"upvote_count":"4","timestamp":"1633082880.0","content":"B outwits A:\nAt first glance we have more component of FireHose which adds the cost. However, eventually it will save the cost as follows:\n1) For A, each record will execute Lambda, and with FireHose it can buffer from 5 min to 15 min, and thereaafter Lambda will be executed. \nHence, number of Lambda execution would be less compared to A\n\n2) Number of S3 put operations shall be less, as aggregated put operation shall be performed. Ofcourse, size of data will be high as it's aggregated. But the beauty is that, FireHose can COMPRESS data as well","poster":"cinopi","comment_id":"30692"},{"upvote_count":"2","poster":"Scunningham99","comment_id":"27873","content":"prefer b","timestamp":"1633068300.0"},{"upvote_count":"6","poster":"chaudh","timestamp":"1632831960.0","comment_id":"16237","content":"key point is that the data must be available for analysis within a few seconds of it being sent to the system\nA is good but limited with Lambda function (2000)\nB is an answer, offload the write to S3 by stream group, able to anaylyze directly from strem. \nC is too slow\nD is too cost (for lots of puts request to S3)"},{"timestamp":"1632829320.0","upvote_count":"4","content":"Prefer B.\n\nhttps://aws.amazon.com/kinesis/data-firehose/faqs/\nHow is data organized in my Amazon S3 bucket?","comments":[{"upvote_count":"1","timestamp":"1633237740.0","comment_id":"44002","poster":"sarah1","content":"That's actually a really good link.\nFor others: kinesis firehose adds a UTC folder structure to files it puts in s3"}],"poster":"cmm103","comment_id":"13769"},{"upvote_count":"1","poster":"donathon","content":"A\nB: Firehose is a managed service of Kinesis and hence it does not read from Kinesis.\nC\\D: Too slow.","comments":[{"poster":"Ibranthovic","timestamp":"1632829740.0","content":"2000 lambda function each seconds and we know that the max Concurrent executions for lambda is 1000.\n\nSo it can't be A.\nI prefer B","upvote_count":"9","comment_id":"14567","comments":[{"comment_id":"77047","content":"This limit can be increased. As AWS2020 mentioned, Kinesis Data Streams can be source of Firehose. Using Lambda, just to put objects in S3 doesn't make sense.","poster":"Smart","upvote_count":"3","timestamp":"1633902120.0"}]},{"comment_id":"18172","timestamp":"1632890280.0","poster":"AWS2020","upvote_count":"12","content":"that's not right. Firehose can read from Kinesis.. \n\nhttps://aws.amazon.com/about-aws/whats-new/2017/08/amazon-kinesis-firehose-can-now-read-data-directly-from-amazon-kinesis-streams/"},{"comment_id":"197296","poster":"AlwaysLearning2020","upvote_count":"1","timestamp":"1634843700.0","content":"https://aws.amazon.com/kinesis/data-firehose/faqs/\nQ: What is a source?\nA source is where your streaming data is continuously generated and captured. For example, a source can be a logging server running on Amazon EC2 instances, an application running on mobile devices, a sensor on an IoT device, **or a Kinesis stream**."}],"comment_id":"13654","timestamp":"1632626820.0"},{"content":"I would go with A","upvote_count":"1","timestamp":"1632310920.0","comment_id":"10470","poster":"dpvnme"}],"answer":"B","answers_community":["B (80%)","A (20%)"],"unix_timestamp":1568132340,"exam_id":32,"answer_ET":"B","timestamp":"2019-09-10 18:19:00","url":"https://www.examtopics.com/discussions/amazon/view/5012-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"KMB0eupBb8NqJSOjSODV","question_images":[],"timestamp":"2019-09-15 04:22:00","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/5193-exam-aws-certified-solutions-architect-professional-topic-1/","answers_community":["C (75%)","D (17%)","8%"],"answer_ET":"C","topic":"1","question_id":490,"exam_id":32,"choices":{"C":"Refactor the web application to post each incoming bid to an Amazon SQS FIFO queue in place of Kinesis Data Streams. Refactor the bid processor to continuously the SQS queue. Place the bid processing EC2 instance in an Auto Scaling group with a minimum and a maximum size of 1.","D":"Switch the EC2 instance type from t2.large to a larger general compute instance type. Put the bid processor EC2 instances in an Auto Scaling group that scales out the number of EC2 instances running the bid processor, based on the IncomingRecords metric in Kinesis Data Streams.","B":"Refactor the web application to post each incoming bid to an Amazon SNS topic in place of Kinesis Data Streams. Configure the SNS topic to trigger an AWS Lambda function that processes each bid as soon as a user submits it.","A":"Refactor the web application to use the Amazon Kinesis Producer Library (KPL) when posting bids to Kinesis Data Streams. Refactor the bid processor to flag each record in Kinesis Data Streams as being unread, processing, and processed. At the start of each bid processing run, scan Kinesis Data Streams for unprocessed records."},"question_text":"An auction website enables users to bid on collectible items. The auction rules require that each bid is processed only once and in the order it was received. The current implementation is based on a fleet of Amazon EC2 web servers that write bid records into Amazon Kinesis Data Streams. A single t2.large instance has a cron job that runs the bid processor, which reads incoming bids from Kinesis Data Streams and processes each bid. The auction site is growing in popularity, but users are complaining that some bids are not registering.\nTroubleshooting indicates that the bid processor is too slow during peak demand hours, sometimes crashes while processing, and occasionally loses track of which records is being processed.\nWhat changes should make the bid processing more reliable?","discussion":[{"content":"I prefer \"C\".\nFIFO is better in this case compared to Kinesis, as it guarantee the order of the bid.\nMin Max 1, is okay as the SQS will hold the queue in case of failure of the instance, till it come back again.","comments":[{"poster":"AShahine21","comments":[{"timestamp":"1634610060.0","comment_id":"259181","poster":"01037","upvote_count":"5","content":"Yes.\nBut the question is \"What changes should make the bid processing more reliable?\", only about reliability, not speed."}],"comment_id":"105180","content":"\"Troubleshooting indicates that the bid processor is too slow during peak demand hours\".. C will not solve this problem.","upvote_count":"1","timestamp":"1633326720.0"},{"content":"Yes, C. Only SQS works. More than one EC2 instances in an auto scaling DOESN'T WORK as they are to serve one queue in FIFO.","poster":"Kelvin","comment_id":"336763","comments":[{"comment_id":"341391","poster":"dijesim222","content":"exactly. bids cannot processed in parallel, which rules out D completely, C is the only sensible answer left","timestamp":"1635509940.0","upvote_count":"4"}],"upvote_count":"2","timestamp":"1635376140.0"},{"poster":"chicagomassageseeker","content":"SQS is not suitable for Real time bidding. Also SQL FIFO has can scale only to a max 300 messages and 3000 messages (in batch). C for sure doesn't fit the solution","comment_id":"124518","timestamp":"1633776780.0","upvote_count":"2","comments":[{"content":"question mentions cron job hence no real time or near real time (cron job's max resolution 1 second)","poster":"dijesim222","timestamp":"1635612420.0","comment_id":"341392","upvote_count":"2"}]},{"poster":"Alvindo","timestamp":"1646476080.0","content":"kinesis data streams consumes data in the order they are stored which is basically going to be fifo https://aws.amazon.com/kinesis/data-streams/faqs/","comment_id":"561363","upvote_count":"1"}],"upvote_count":"27","poster":"Moon","timestamp":"1632194400.0","comment_id":"13292"},{"comments":[{"comments":[{"upvote_count":"4","content":"This one refers to Real-Time Bidding which I don't think is the scenario here. \n\nCheck this out: https://aws.amazon.com/blogs/compute/solving-complex-ordering-challenges-with-amazon-sqs-fifo-queues/","poster":"Smart","comment_id":"84783","timestamp":"1632852000.0"}],"upvote_count":"8","comment_id":"46807","timestamp":"1632547620.0","content":"agree with D.\nhttps://d0.awsstatic.com/whitepapers/Building_a_Real_Time_Bidding_Platform_on_AWS_v1_Final.pdf","poster":"freelyfly84"}],"upvote_count":"21","comment_id":"44449","poster":"dumma","timestamp":"1632465540.0","content":"Correct answer is D as a single consumer is not able to keep up the bids, multiple\nconsumers can be used with Auto Scaling based on the incoming records metric"},{"upvote_count":"1","content":"Selected Answer: C\nerror in voting comment is letter C","poster":"SkyZeroZx","comment_id":"930845","timestamp":"1687455000.0"},{"comment_id":"773946","content":"I prefer C between C and D\nWhile D is viable, it doesn't say anything about failed transactions in EC2. The message will be lost and that's not acceptable as in the question.","poster":"NishKar","upvote_count":"1","timestamp":"1673566140.0"},{"timestamp":"1672230720.0","content":"Selected Answer: D\nThe problem is with crashes while processing, and SQS FIFO is more limited than Kinesis and not better (300 per second, 3,000 max batch processing), so I prefer D.","upvote_count":"1","comment_id":"759806","comments":[{"poster":"evargasbrz","upvote_count":"1","content":"... and this part is also important: \"...Auto Scaling group that scales out the number of EC2 instances running the bid processor, based on the IncomingRecords metric in Kinesis Data Streams.\"","timestamp":"1672230840.0","comment_id":"759809"}],"poster":"evargasbrz"},{"poster":"SureNot","upvote_count":"1","comment_id":"736944","timestamp":"1670340360.0","content":"Selected Answer: C\nC is the best option, but why do we have \"Auto Scaling group with a minimum and a maximum size of 1\"..."},{"upvote_count":"1","poster":"AjayPrajapati","timestamp":"1667843040.0","content":"Selected Answer: C\nC is correct\nkinesis and SNS can have duplicate. App need to handle the duplicate.","comment_id":"713214"},{"timestamp":"1665045120.0","upvote_count":"2","comment_id":"687615","content":"Ordering is guaranteed on a shard level of kinesis data streams, but not across all stream. hard to choose","poster":"JohnPi"},{"poster":"tomosabc1","comment_id":"684156","content":"Selected Answer: D\nThe answer is C.\n\nBecause the auction website already used Kinesis Data Stream, but still its bid processor \"sometimes crashes while processing, and occasionally loses track of which records is being processed\", the question is asking us to make the bid processing more reliable, rather than faster.\nAs for option D, neither \"switch to a larger instance type\" nor \"adding more EC2 instances within an Auto Scaling group\" are able to solve aforementioned reliability issue.","timestamp":"1664622420.0","upvote_count":"1","comments":[{"timestamp":"1664622540.0","comment_id":"684157","content":"The answer is C. I voted for a wrong answer remissly.","upvote_count":"1","poster":"tomosabc1"}]},{"poster":"Rocketeer","comment_id":"654450","upvote_count":"1","timestamp":"1661896560.0","content":"I prefer D. There can be multiple items being auctioned. With kinesis data streams I can get the bids for different items in different shards in order. With FIFO, they will all be going through a single queue."},{"upvote_count":"1","comment_id":"650854","content":"Ans = C. SQS FIFO was made for this.","timestamp":"1661264520.0","poster":"Ni_yot"},{"comment_id":"638625","content":"This is between C and D.\nFor D - We need to make sure ordering is in in-place and process it once - Kinesis can do ordering but cant avoid duplicates especially with an ASG, see below link:\nhttps://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-duplicates.html\nFor C - with FIFO we have dedup already set and ordering - ASG is making sure 1 instance is alive - although its better to scale it according to queue size since max batch processing is 3000 messages.\nSince the question asks about reliability and not throughput or speed - C will make sure all bids are processed in-order and only once. D Will process in order and quickly but with duplicates.\nSo C is the only valid answer","timestamp":"1659003180.0","upvote_count":"1","poster":"Enigmaaaaaa"},{"content":"Selected Answer: C\nAnswer: C\nExplanation:\nA\\B: Not feasible\nC: FIFO is better in this case compared to Kinesis, as it guarantee the order of the bid. Min Max 1, is okay as the SQS will hold the queue in case of failure of the instance, till it come back again. \nD: Still it does not solve the ordering issue.","poster":"TechX","comment_id":"625604","timestamp":"1656657180.0","upvote_count":"3"},{"upvote_count":"1","content":"Selected Answer: C\nC. SQS then Kinesis decouples the architecture and business flow to ensure that all bids are getting sent almost real time.","poster":"tartarus23","comment_id":"597758","timestamp":"1651846680.0"},{"timestamp":"1651504560.0","content":"Selected Answer: C\nMy problem with D is that it didn't state how the processing of bids is coordinated among the EC2s.","upvote_count":"1","poster":"aloha123","comment_id":"596096"},{"timestamp":"1648626900.0","content":"Selected Answer: C\nC looks right","poster":"jj22222","upvote_count":"1","comment_id":"578129"},{"timestamp":"1639383840.0","comment_id":"500462","content":"Kinesis just like SQS FIFO provides ordering of records. The only difference is that Kinesis is near real time.","upvote_count":"4","poster":"KiraguJohn"},{"comment_id":"457137","poster":"StelSen","timestamp":"1636300860.0","content":"People tends to choose Option-C, because of this \"The auction rules require that each bid is processed only once and in the order it was received.\". But the real problem statement is different. i.e. Slow, Missing etc., All because of consumer side. Option-C stick to 1 instance. No use. Option-D resolves problem. AWS Kinesis Data Stream also taking care of ORDER. Refer https://aws.amazon.com/kinesis/data-streams/faqs/ (Look for word ORDER)","upvote_count":"4"},{"content":"\"Troubleshooting indicates that the bid processor is too slow during peak demand hours, sometimes crashes while processing, and occasionally loses track of which records is being processed.\nWhat changes should make the bid processing more reliable?\"\n\nCrashes while processing = Needs to be replaced asap to continue processing the bids \n\nOccasionally loses track = Only happens sometimes not ALL the time\n\nFrom troubleshooting , the problem is the BID PROCESSOR \n\nThen, what changes to make it more RELIABLE = continued service due to crashes and slow processing\n\nAnswer is D.","upvote_count":"2","poster":"AWSum1","comment_id":"450654","timestamp":"1636287540.0"},{"comment_id":"425202","timestamp":"1636181340.0","upvote_count":"1","content":"A is wrong - how the bid processor can flag a record in Kinesis Data Stream? It can only read data\nB is wrong - would be OK if the answer would mention SNS FIFO\nD is wrong - we don't know a number of shards - we can't have two consumers for the same shard","poster":"DerekKey"},{"content":"I'll go with D\nTroubleshooting indicates that the bid processor is too slow during peak demand hours\nWeb Servers and Kinesis are doing their job in the right way.\nThe bid processor is the bottleneck .","upvote_count":"2","poster":"WhyIronMan","comments":[{"poster":"JohnPi","upvote_count":"1","content":"order is per shard. with autoscaling multiple consumers (scaled ec2) will consume the same shard","timestamp":"1665045480.0","comment_id":"687617"}],"comment_id":"411133","timestamp":"1635930360.0"},{"poster":"rodolfo2020","timestamp":"1635911160.0","upvote_count":"1","content":"The answer is A\nhttps://docs.aws.amazon.com/es_es/streams/latest/dev/developing-producers-with-kpl.html\n\nYou need must read","comment_id":"411003"},{"poster":"vkbajoria","upvote_count":"2","timestamp":"1635907980.0","comment_id":"366735","content":"I would have selected D if auto scaling based on shard. If that's the case then processing of order as bid arrived will be preserved with right sized EC2. Even then \"occasionally loses track\" needs to be handled by saving last processed record some where.\nC sounds more like it takes care of all the issues. The only concerned here is the FIFO can only supports 300 per second but the question did not mention the seed of arrival so I am assuming it is still ok here.\nFinal answer C"},{"timestamp":"1635854340.0","content":"C. With FIFO it address the problem of \"occasionally loses track of which records is being processed.\"","comment_id":"348227","poster":"Waiweng","upvote_count":"4"},{"timestamp":"1635819240.0","comment_id":"348226","upvote_count":"1","content":"definitely C","poster":"Waiweng"},{"upvote_count":"1","timestamp":"1635614520.0","comment_id":"346711","content":"Definitely C","poster":"blackgamer"},{"timestamp":"1635382440.0","content":"Answer is D. The problem only arises during peak demand times. So I think the problem is caused by insufficient processing power of the instance.","comment_id":"338559","upvote_count":"2","poster":"BloodCube"},{"poster":"awsexamprep47","content":"C is the answer , SQS FIFO along-with Min & Max of 1 will maintain the processing order","comment_id":"316502","timestamp":"1635342900.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1635267900.0","poster":"Kian1","comment_id":"291705","content":"going with C"},{"comments":[{"timestamp":"1635173880.0","comments":[{"comment_id":"425183","poster":"DerekKey","upvote_count":"1","content":"In reality, you can do that but in the case of this question, this solution is not mentioned. You enable enhanced metrics in Kinesis (Write: IncomingRecords) then use CW alarm to scale ALB.","timestamp":"1635936960.0"}],"comment_id":"286753","content":"ASG can not be created based on Kinesis metrics, D is ruled out","upvote_count":"1","poster":"Ebi"}],"timestamp":"1634932380.0","comment_id":"280247","poster":"Ebi","content":"The most reasonable answer is C","upvote_count":"2"},{"comments":[{"content":"Change To A","poster":"gookseang","comment_id":"278595","timestamp":"1634751480.0","upvote_count":"2"}],"comment_id":"278594","poster":"gookseang","timestamp":"1634705700.0","upvote_count":"1","content":"I will go D"},{"upvote_count":"1","comment_id":"259184","content":"C.\nBid order is mandated, so it has to be C.\n\nAnd \"FIFO has can scale only to a max 300 messages and 3000 messages (in batch)\" is only talking about throughput, which is not the question is asking for.\nActually, FIFO can hold up to 20,000 messages.\nhttps://aws.amazon.com/sqs/faqs/#:~:text=A%20single%20Amazon%20SQS%20message,20%2C000%20for%20a%20FIFO%20queue.","timestamp":"1634651280.0","poster":"01037"},{"poster":"Bulti","comment_id":"252232","timestamp":"1634483520.0","content":"The choice is difficult between C and D. But based on my experience of the aWD data analytics specialty exam where such questions are asked I would go with C rather than D. Although both C and D will preserve ordering only c as stated will be able to meet the tracking of the messages requirements . In the data analytics they would describe the use of Dynamo Db to track messages which are being processed by the KCL EC2 instances so that each instance dedicated to a specific Kinesis shard would know where to resume processing from. Option d doesn't address how to solve the tracking issue. Also the question doesnt stress a lot on volume which makes me think that option C even with a smaller throughput of 3000 messages per sec if batched would go the job. Hence I will. Go with option C.","upvote_count":"3"},{"upvote_count":"1","poster":"T14102020","content":"Correct answer is C. Key - \"the order it was received\". Kinesis not support order. So only SQS FIFO.","timestamp":"1634481120.0","comment_id":"243522"},{"poster":"Singarakannan","comment_id":"233082","upvote_count":"1","timestamp":"1634272560.0","content":"Typically, when you use the KCL, you should ensure that the number of instances does not exceed the number of shards (except for failure standby purposes). Each shard is processed by exactly one KCL worker and has exactly one corresponding record processor, so you never need multiple instances to process one shard."},{"upvote_count":"4","comment_id":"230839","timestamp":"1634264580.0","content":"I'll go with C","poster":"jackdryan"},{"poster":"MultiAZ","content":"I vote for C\nWhat bothers me in D is the scaling of the processor into multiple instances. If you start processing in parallel, the output can be out of sync (although the input is ordered)","comment_id":"143308","upvote_count":"1","timestamp":"1634074200.0"},{"content":"C. t2.large has 2 vCPU and is burstable. It can cater for around 500Mb/s of traffic so I don't think having a bigger instance would do much good. Until and unless someone can explain?\n\nAlso, with Kinesis what number of shards are we talking about?","timestamp":"1634033460.0","upvote_count":"2","comment_id":"141125","poster":"IAmNotLambda"},{"poster":"inf","comments":[{"poster":"cox1960","content":"kinesis data stream orders record per shard, not per stream.","timestamp":"1634701560.0","comment_id":"263792","upvote_count":"1"}],"comment_id":"136814","upvote_count":"2","content":"Answer: C (reluctantly)\nA - incorrect - Kinesis data records are immutable - can't use flaggs. \"After you write a record to a stream, you cannot modify that record or its order within the stream.\". Also, it does not cater for performance issues - the same number of records need processing, so the system may still crash.\nB - incorrect - possible that the bid processor cannot run on Lambda, also SNS can't guarantee that the subscriber (Lambda) function will process bids in the order received.\nC - correct - FIFO is definitely the preferred option, although Kinesis Data Streams maintains ordeed records. Without updating the EC2 instance, it will still have processing issues during peak times, however when it recovers after a crash, it will process unprocessed records. Thus more reliable than the original solution and technically viable.\nD - incorrect - AS caters with higher performing (sustainable) EC2 covers processing throughput/performance. However, how does it cater for losing track of records being processed? - if the application crashes on any of the instances, how will it know to replay that record without recoding\n(assuming A assumption is correct)","timestamp":"1634022240.0"},{"poster":"NikkyDicky","upvote_count":"1","content":"A. the issue is not with Kinesis ordering but with the bid processor losing track of what's processed. Nothing in the question prevents refactor","comment_id":"133178","timestamp":"1633839120.0"},{"comment_id":"120842","timestamp":"1633561860.0","content":"Answer A:\n\nGuys - Please read 6Rs about AWS. Refactor/Re-architect is one them. \n\n“Refactor” the bid processor = “Reimagine what other cloud native feature can be used instead of bid processor” = Rearchitect bid processor with Kinesis Data Analytics, which can transform and mark your records “unread, processing, and processed”. \nRefactor the web application to use the Amazon Kinesis Producer Library (KPL) = Rearchitect fleet of Amazon EC2 web servers and use KPL instead. KPL provides ordering and replay features. You can also replay the records for unprocessed records.\nEliminate C. SQL FIFO has can scale only to a max 300 messages and 3000 messages (in batch)","upvote_count":"2","comments":[{"content":"Hu? You would change the frontend and leave backend unchanged when the backend is overloaded? Consumer is the problem not the producer.\nAnswer: D","comments":[{"timestamp":"1633640040.0","poster":"chicagomassageseeker","comment_id":"124481","content":"Option A suggeests to change both producer and consumer. It says to refactor the bid processor (single EC2 instance) which means you are changing the backend bid processor.","comments":[{"poster":"chicagomassageseeker","comments":[{"comment_id":"124495","upvote_count":"1","content":"KPL maintains ordering per shard and provides replay capability for unprocessed records","poster":"chicagomassageseeker","timestamp":"1633736580.0"}],"content":"Option A:\nCurrent : Amazon EC2 web servers -> write bid records into -> Amazon Kinesis Data Stream -> processed by Single T2 instance process Bids\n\nProposed: KPL-> write bid records into-> Amazon Kinesis Data Stream->Kinesis Data Analytics ( even though the question didn’t mention kinesis data Analytics, we can infer from “Refactor the bid processor” meaning- “use some other cloud native feature to process bids”)","comment_id":"124492","timestamp":"1633642380.0","upvote_count":"1"}],"upvote_count":"1"}],"upvote_count":"4","poster":"hobokabobo","timestamp":"1633613220.0","comment_id":"121637"}],"poster":"chicagomassageseeker"},{"upvote_count":"2","comment_id":"114312","content":"C. Key thing to keep in mind is the requirement needs to be reliable. You can be slow but reliable. An SQS FIFO queue ensures the ordering and since the application is decoupled, it can process the messages in turn. The ASG ensures its reliability by spinning up a new instance if the current one fails.","timestamp":"1633492740.0","poster":"tones"},{"upvote_count":"1","content":"I am weighing on option D, the bottleneck is the performance of EC2 instance. ASG can take care of this issue.","timestamp":"1633484820.0","poster":"meenu2225","comment_id":"110425"},{"poster":"JAWS1600","upvote_count":"1","timestamp":"1633381500.0","comment_id":"107958","comments":[{"comment_id":"110424","upvote_count":"1","content":"I think u mean D, as option C is the one with 1 instance.","poster":"meenu2225","timestamp":"1633437720.0"}],"content":"D is not reliable with 1 instance. I would go with C"},{"upvote_count":"1","timestamp":"1633338780.0","poster":"VrushaliD","comment_id":"107915","content":"Answer is D. Kinesis maintains order and Autoscaling of bid processor is needed."},{"content":"D is correct","comment_id":"102147","timestamp":"1633276200.0","upvote_count":"1","poster":"NKnab"},{"timestamp":"1633274220.0","content":"d is wrong -there is no such thing as incomingreocrds metrics","comment_id":"102132","upvote_count":"1","comments":[{"upvote_count":"2","timestamp":"1633331880.0","content":"2s google research proves otherwise: https://aws.amazon.com/premiumsupport/knowledge-center/kinesis-data-streams-iteratorage-metric/","comment_id":"107510","poster":"Wira"},{"comment_id":"425187","timestamp":"1636124880.0","poster":"DerekKey","upvote_count":"1","content":"IncomingRecords \nThe number of records successfully put to the Kinesis stream over the specified time period. This metric includes record counts from PutRecord and PutRecords operations. Minimum, Maximum, and Average statistics represent the records in a single put operation for the stream in the specified time period."}],"poster":"NKnab"},{"content":"For me, the problem is not related to the Order to Bids, but to the T2 instance.\nIn order to solve the instance, we should change the bid processor.\nOn the other Hand, SQS FIFO Has a limit of 300 msg/seconds, so using answer C, we are moving the problem from the T2 instance which doesn't handle the peak demand, to the SQS which could not handle the huge demand.","comments":[{"comments":[{"comment_id":"96510","timestamp":"1633232220.0","content":"The auction rules require that each bid is processed only once and in the order it was received. Answer is C.","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1633256640.0","comment_id":"98189","poster":"AShahine21","content":"yes, but it doesn't handle a huge number of msg/s."}],"poster":"easytoo"}],"upvote_count":"1","comment_id":"94741","timestamp":"1633091820.0","poster":"AShahine21","content":"Hence, the answer is D"}],"upvote_count":"1","comment_id":"94740","poster":"AShahine21","timestamp":"1633083300.0"},{"comment_id":"94375","upvote_count":"2","content":"The other point is \"too Slow\" A FIFO Q will not address the speed...Autoscaling will.","poster":"Merlin1","timestamp":"1633052700.0"},{"timestamp":"1632943800.0","upvote_count":"2","comment_id":"94369","content":"While I like C the question is a bit ambiguous as to haw many transaction we are talking about. FIFO q's are limited to 300/second....Is that going to be enough? Maybe. The other thing is that Streams CAN order data. BUt the real issue is the Bid processor being overloaded and I don't think autoscaling of 1 addresses that. Although the FIFO queue will hold the message long enough for the new instance to receive it....But what happens to the records the Bid processor consumed but didn't finish processing when it failed. Option D is the only one to actually address the overloaded Bid Processor. The question requires the data to be in order but doesn't mention that being a problem....Just that the Processor cant keep up. While A FIFO Q would help that and perhaps be enough at 300 records per second, is that's what's causing the bod processor to fail? Probably but we don't know for sure. Again the question doesn't seem to present the problem as ordered so we can perhaps assume that streams is accomplishing that? So the only thing left is to handle the bid processor which would be D.","poster":"Merlin1"},{"timestamp":"1632839040.0","upvote_count":"4","comment_id":"81252","poster":"fw","content":"D. The problem here is with the bid processor's EC2 instance's processing power and crash at times during peak hours."},{"comment_id":"71190","poster":"Smart","upvote_count":"1","timestamp":"1632803760.0","content":"Kinesis doesn't guarantee ordering at stream level. Leaves option C as an answer."},{"comment_id":"63167","timestamp":"1632668040.0","comments":[{"comment_id":"63170","timestamp":"1632802380.0","upvote_count":"3","comments":[{"poster":"Smart","content":"How do you keep track of records processed and failed across multiple EC2 instances.","comment_id":"77078","timestamp":"1632826140.0","upvote_count":"2"}],"poster":"virtual","content":"\"Troubleshooting indicates that the bid processor is too slow during peak demand hours\", so the problem is regarding this particular process ..."}],"content":"I also vote for D. I think the question highlights auto-scaling.","poster":"virtual","upvote_count":"4"},{"content":"D is correct, there is no issue with data ingestion. Kinesis support ordering for inputs. The main issue is with the bid processor.","timestamp":"1632667440.0","poster":"Gorha","comment_id":"53419","upvote_count":"8","comments":[{"upvote_count":"2","timestamp":"1632893340.0","comment_id":"90868","poster":"ewredtrfygi","content":"Agree that D is correct. One issue with SQS FIFO being glossed over is that, without batching, it can only support 300 messages per second. No way is that going to be scalable for a business that is growing rapidly as stated in the question. Kinesis streams don't order data, but data is ordered within shards, so if you make sure bids for the same product use the same partitionID then those bids will go to the same shard, ensuring they are processed in order."}]},{"content":"Should be D","poster":"amog","timestamp":"1632630840.0","comment_id":"51677","upvote_count":"3"},{"upvote_count":"4","poster":"KatiePerry","content":"WHY NOT D?","timestamp":"1632379500.0","comment_id":"40508"},{"timestamp":"1632354240.0","poster":"cinopi","upvote_count":"1","content":"SQS justifies --> bid is processed only once and in the order + reliable (14 days it can hold data at max)","comment_id":"32585"},{"content":"agree with c too","upvote_count":"2","timestamp":"1632302160.0","poster":"Scunningham99","comment_id":"27874"},{"upvote_count":"4","content":"C\nA\\B: Not feasible\nC: FIFO is better in this case compared to Kinesis, as it guarantee the order of the bid. Min Max 1, is okay as the SQS will hold the queue in case of failure of the instance, till it come back again.\nD: Still it does not solve the ordering issue.","poster":"donathon","comments":[{"timestamp":"1632386760.0","upvote_count":"4","content":"kinesis data stream provide ordering guarantee. \nhttps://amazonaws-china.com/kinesis/data-streams/getting-started/ , key word \"order\"","comment_id":"43502","poster":"PacoDerek","comments":[{"upvote_count":"2","timestamp":"1633385820.0","poster":"fi3fjwoifej","comment_id":"109027","content":"ordered per shard which is not scalable. you can only preserve order in one shard"}]}],"timestamp":"1632237720.0","comment_id":"13656"},{"content":"I would go with C.","comments":[{"timestamp":"1632163800.0","upvote_count":"1","poster":"dpvnme","comments":[{"content":"to maintain the processing order of the bids...multiple in parallel will cause problems","comment_id":"183025","timestamp":"1634156280.0","poster":"ipindado2020","upvote_count":"1"}],"content":"Auto Scaling group with a minimum and a maximum size of 1?","comment_id":"11895"},{"upvote_count":"1","content":"SQS FIFO can only support 300 unbatched message events per second (individual site users would not batch send messages), and this limit includes reads, writes and deletes to the SQS queue. The \"auction site is growing in popularity\"; SQS FIFO will for sure fail at scale during peak bidding hours. The answer must be D.","poster":"ewredtrfygi","comments":[{"timestamp":"1633853400.0","poster":"ricoyao","upvote_count":"3","content":"300 is soft limit, you can request to a limit increase.","comment_id":"135531","comments":[{"comment_id":"183027","timestamp":"1634261700.0","upvote_count":"2","content":"Very good point...\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/quotas-messages.html\n\"The 3000 transactions represent 300 API calls, each with a batch of 10 messages. To request a quota increase, submit a support request.\"\n\nThat makes sqs fifo perfect for this case.","poster":"ipindado2020"}]}],"comment_id":"90876","timestamp":"1632942900.0"}],"poster":"huhupai","upvote_count":"3","comment_id":"11147","timestamp":"1632087240.0"}],"answer_images":[],"answer":"C","unix_timestamp":1568514120,"isMC":true}],"exam":{"provider":"Amazon","id":32,"lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"isMCOnly":false,"isBeta":false,"isImplemented":true,"name":"AWS Certified Solutions Architect - Professional"},"currentPage":98},"__N_SSP":true}