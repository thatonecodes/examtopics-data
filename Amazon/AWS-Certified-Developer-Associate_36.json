{"pageProps":{"questions":[{"id":"eX7EvEiwkSGM60pIzaeI","timestamp":"2022-11-25 13:27:00","question_text":"A developer is writing an application in AWS Lambda. To simplify testing and deployments, the developer needs the database connection string to be easily changed without modifying the Lambda code.\n\nHow can this requirement be met?","answer_ET":"A","question_images":[],"isMC":true,"topic":"1","answer":"A","discussion":[{"comment_id":"938462","poster":"rcaliandro","content":"Selected Answer: A\nA is correct. We can store the string as a secret in AWS Secrets Manager and we can also have the possibility to rotate the credentials. Is a secure way so no problem with this approach.","upvote_count":"1","timestamp":"1688064240.0"},{"timestamp":"1669445520.0","poster":"michaldavid","upvote_count":"1","content":"Selected Answer: A\nYou can use secret manager to store the variable","comment_id":"727341"},{"poster":"k1kavi1","timestamp":"1669436640.0","upvote_count":"1","content":"Selected Answer: A\nA. Store the connection string as a secret in AWS Secrets Manager.","comment_id":"727254"},{"poster":"kapil206001","comment_id":"726735","upvote_count":"2","content":"A\nhttps://www.examtopics.com/discussions/amazon/view/28268-exam-aws-certified-developer-associate-topic-1-question-248/","timestamp":"1669379220.0"}],"answer_images":[],"answers_community":["A (100%)"],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/88689-exam-aws-certified-developer-associate-topic-1-question-257/","exam_id":25,"question_id":176,"choices":{"D":"Store the connection string as a Lambda layer.","C":"Store the connection string in AWS KMS.","A":"Store the connection string as a secret in AWS Secrets Manager.","B":"Store the connection string in an IAM user account."},"unix_timestamp":1669379220},{"id":"YoGwBKuF1S5zK9TopWzG","exam_id":25,"topic":"1","choices":{"B":"Update the code in the Lambda function to remove calls to the SQS SDK ReceiveMessage function. Configure the Lambda function to use the SQS queue as an event source. Set the maxReceiveCount value on the SQS queue's redrive policy to at least 5.","C":"Create a second SQS queue to use as a dead-letter queue. Configure a redrive policy on the original SQS queue to send failed messages to the dead-letter queue. Modify the Lambda function to read messages from both queues.","D":"Create a second SQS queue to use as a dead-letter queue. Move the call to the third-party dependency into an exception handling block. Write the message to the dead-letter queue if a failure in the third-party dependency is caught in the exception handler.","A":"Move the call to the third-party dependency into an exception handling block. Write the message back to the SQS queue if a failure in the third-party dependency is caught in the exception handler."},"question_text":"A company has an AWS Lambda function that reads messages from an Amazon Simple Queue Service (Amazon SQS) queue by using the Amazon SQS API. The Lambda function is not processing all the messages successfully because of random failures of a third-party dependency. A developer needs to improve the reliability of the Lambda function so that the Lambda function will process each message successfully despite the failures of the third-party dependency.\n\nWhich solution will meet this requirement with the LEAST effort?","discussion":[{"comment_id":"1101585","content":"Selected Answer: A\nA. It is infinite retry until the message is processed successfully.\nD is absolutely incorrect. you can't call it successfully processed when you leave messages in the DLQ.","poster":"c9ebec2","timestamp":"1703080800.0","upvote_count":"1"},{"comment_id":"938467","poster":"rcaliandro","content":"Selected Answer: D\nSo it's a good idea to create an SQS dead letter queue for this reason A and B are for sure not correct. We have to exclude also the C because create a DLQ Q and modify the lambda function to read messages from both queues doesn't make sense. Instead, it is a good idea to create an SQS Dead letter Queue, catch the application exceptions in the function and write on the DLQ if there is a failure caused by the third-party library. So the answer D is the correct one","upvote_count":"1","timestamp":"1688064660.0"},{"upvote_count":"3","poster":"m4r0ck","content":"Selected Answer: D\nTo me, the key here is 'so that the Lambda function will process each message successfully \"despite the failures\" of the third-party dependency', which means that we don't necessarily need to reprocess the message, meaning that any answers talking about returning the message back to the SQS queue are wrong.\nLeft are C or D, in C the answer is talking about consuming the messages from the normal queue and from the dead letter queue. again from the first statement, we're not looking to reprocess the failed messages therefore no need to reconsume the messages in the DLQ. so D is the right one in my opinion","timestamp":"1677180120.0","comment_id":"819623"},{"comment_id":"817870","poster":"ezeik","comments":[{"content":"No read the question \"despite the failures of the third-party dependency\"","comment_id":"994850","poster":"ja1092m","upvote_count":"1","timestamp":"1693464000.0"}],"upvote_count":"3","timestamp":"1677073020.0","content":"Selected Answer: A\nI think it's A.\n1) least effort - no additional queues\n2) unlimited number of retries in this scenario which garanties processing of the message."},{"timestamp":"1676849400.0","content":"They need to reword \"exception handling block\". As a developer, to me this means the \"catch\" or \"Except\" portion of the code. I disqualified the correct answer based off of that.","comment_id":"814662","poster":"AmberTheTamber","upvote_count":"1"},{"timestamp":"1676591940.0","poster":"pancman","upvote_count":"1","comment_id":"811219","content":"Selected Answer: D\nD is correct. Dead-letter queues are the way to catch and handle errors in SQS."},{"upvote_count":"1","poster":"Phinx","timestamp":"1674269340.0","comment_id":"782959","content":"Selected Answer: D\nD for me."},{"comment_id":"770540","upvote_count":"2","comments":[{"upvote_count":"1","content":"\"Set the maxReceiveCount on the source queue's redrive policy to at least five. \"\nhttps://aws.amazon.com/premiumsupport/knowledge-center/lambda-retrying-valid-sqs-messages/","comment_id":"817890","poster":"ezeik","timestamp":"1677074280.0"}],"timestamp":"1673276100.0","content":"Selected Answer: D\nD makes the most sense to me.\nC: Redrive policy should be working on DLQ, not the original queue","poster":"KT_Yu"},{"timestamp":"1672674780.0","comment_id":"763822","poster":"by116549","content":"Does C not look to be correct based on this resource:\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html","upvote_count":"2"},{"upvote_count":"2","poster":"almadeedo","content":"Selected Answer: B\nChoosing B (even if it tolerates just a maximum number of failures equal to the selected maxReceiveCount value).\nAs regarding A, it seems strage the wording \"write back to the SQS queue\", even if this appears to be the only solution guarantiing the succesfull processing of \"each\" message (by the way, with this solution we can incurr in infinite loops for structural errors).\nAs regarding D, I was wondering how an immediate move to the DLQ after a single failure will encrease resiliency without using it as a source of the process (following this approach we will have just traces of all the failures in the DLQ but no increased resiliency).\nAs regarding C we're increasing resiliency to just two tries if we don't modify maxReceiveCount.\n\nCan anybody argument on my above reasonings?","comment_id":"757297","timestamp":"1672046340.0"},{"comment_id":"734165","content":"Changing to D, as we need to create a second SQS queue and link it to the original SQS queue to configure DLQ.","poster":"ubuntu1234","timestamp":"1670034240.0","upvote_count":"1"},{"content":"B.\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html\nIf your function returns an error, or can't be invoked because it's at maximum concurrency, processing might succeed with additional attempts. To give messages a better chance to be processed before sending them to the dead-letter queue, set the maxReceiveCount on the source queue's redrive policy to at least 5.(C and D needs to create the DLQ in the same source queue, instead of creating a second queue, which makes them wrong choice)","upvote_count":"2","timestamp":"1669781880.0","poster":"ubuntu1234","comment_id":"731080"},{"timestamp":"1669445700.0","poster":"michaldavid","upvote_count":"2","comment_id":"727343","content":"Selected Answer: D\nDefo not A and B. D makes more sense than C"},{"timestamp":"1669436820.0","content":"Selected Answer: D\nUse dead letter queue with exception handling","comment_id":"727255","upvote_count":"2","poster":"k1kavi1"}],"unix_timestamp":1669436820,"question_id":177,"url":"https://www.examtopics.com/discussions/amazon/view/88804-exam-aws-certified-developer-associate-topic-1-question-258/","answer":"D","answers_community":["D (67%)","A (22%)","11%"],"question_images":[],"answer_description":"","timestamp":"2022-11-26 05:27:00","isMC":true,"answer_images":[],"answer_ET":"D"},{"id":"iJJIvbfRSPQU3rQmJ9rh","question_id":178,"question_text":"A developer is building a new application that uses an Amazon DynamoDB table. The specification states that all items that are older than 48 hours must be removed.\n\nWhich solution will meet this requirement?","unix_timestamp":1669379700,"topic":"1","discussion":[{"timestamp":"1688064840.0","comment_id":"938470","upvote_count":"1","content":"Selected Answer: C\nC is the correct answer, I totally agree with you. The TTL attribute must to be numeric and must represent the current timestamp + 48 hours when we insert the item for the first time. In this way, once the data in inserted, it will be deleted after 2 days in 48 hours.","poster":"rcaliandro"},{"timestamp":"1680079620.0","comment_id":"854186","upvote_count":"1","content":"Selected Answer: C\nTTL attributes must use the Number data type","poster":"capesignalfreer"},{"poster":"pancman","upvote_count":"2","comment_id":"811220","content":"Selected Answer: C\nC is the answer. The TTL attribute’s value must be a top-level Number data type and its value must be a timestamp in Unix epoch time format in seconds.","timestamp":"1676592180.0"},{"upvote_count":"1","poster":"michaldavid","comment_id":"727346","timestamp":"1669445940.0","content":"Selected Answer: C\nGoing with C on this one"},{"poster":"k1kavi1","timestamp":"1669436880.0","content":"Selected Answer: C\nAgreed","upvote_count":"1","comment_id":"727256"},{"poster":"kapil206001","content":"C\nhttps://www.examtopics.com/discussions/amazon/view/69346-exam-aws-certified-developer-associate-topic-1-question-395/","timestamp":"1669379700.0","upvote_count":"1","comment_id":"726745"}],"choices":{"A":"Create a new attribute that has the Number data type. Add a local secondary index (LSI) for this attribute, and enable TTL with an expiration of 48 hours. In the application code, set the value of this attribute to the current timestamp for each new item that is being inserted.","D":"Create a new attribute that has the String data type. Enable TTL on the DynamoDB table for this attribute. In the application code, set the value of this attribute to the current timestamp plus 48 hours for each new item that is being inserted.","B":"Create a new attribute that has the String data type. Add a local secondary index (LSI) for this attribute, and enable TTL with an expiration of 48 hours. In the application code, set the value of this attribute to the current timestamp for each new item that is being inserted.","C":"Create a new attribute that has the Number data type. Enable TTL on the DynamoDB table for this attribute. In the application code, set the value of this attribute to the current timestamp plus 48 hours for each new item that is being inserted."},"answer_ET":"C","question_images":[],"exam_id":25,"answer":"C","answer_description":"","timestamp":"2022-11-25 13:35:00","url":"https://www.examtopics.com/discussions/amazon/view/88691-exam-aws-certified-developer-associate-topic-1-question-259/","isMC":true,"answer_images":[],"answers_community":["C (100%)"]},{"id":"ZBp6hzl1DhNtO5ydq4Oz","question_id":179,"question_text":"A developer is writing an AWS Lambda function. The developer wants to log key events that occur during the Lambda function and include a unique identifier to associate the events with a specific function invocation.\nWhich of the following will help the developer accomplish this objective?","unix_timestamp":1597770660,"topic":"1","discussion":[{"timestamp":"1633541340.0","poster":"rasiram","comment_id":"167156","content":"Answer A\nWhen Lambda runs your function, it passes a context object to the handler. This object provides methods and properties that provide information about the invocation, function, and execution environment.\n\nContext methods\n\ngetRemainingTimeInMillis() – Returns the number of milliseconds left before the execution times out.\n\nContext properties\n\nfunctionName – The name of the Lambda function.\n\nfunctionVersion – The version of the function.\n\ninvokedFunctionArn – The Amazon Resource Name (ARN) that's used to invoke the function. Indicates if the invoker specified a version number or alias.\n\nmemoryLimitInMB – The amount of memory that's allocated for the function.\n\nawsRequestId – The identifier of the invocation request.","upvote_count":"35"},{"timestamp":"1634330580.0","content":"A is the answer\n\nEach service that integrates with Lambda sends data to your function in JSON as an event. The structure of the event document is different for each event type, and contains data about the resource or request that triggered the function. Lambda runtimes convert the event into an object and pass it to your function.","comment_id":"245387","comments":[{"upvote_count":"4","comments":[{"poster":"ai_neuro","comment_id":"368802","upvote_count":"3","comments":[{"timestamp":"1643397300.0","upvote_count":"2","content":"Your claim is not correct. Lambda request id is automatically included in the log message. This is exactly what is stated in the link you urself posted. \n\nC is correct\n\nhttps://aws.amazon.com/blogs/compute/techniques-and-tools-for-better-serverless-api-logging-with-amazon-api-gateway-and-aws-lambda/","poster":"CHRIS12722222","comment_id":"534906"}],"timestamp":"1635935460.0","content":"It's A: The this identifier is not automatically included in the log message.\n\nI think you are referring to this post here: https://aws.amazon.com/blogs/compute/techniques-and-tools-for-better-serverless-api-logging-with-amazon-api-gateway-and-aws-lambda/\n\nHowever, in this case the request-id is only found in the event structure because the blogger re-sends the API-gateway context information ($context.requestId) to the downstream lambda using a mapping template."}],"poster":"br00net","comment_id":"334665","content":"An identifier that can be obtained from the Lambda context object is automatically included in the log message.\nAs in the question developer wants - \" to associate the events with a specific function invocation.\" We need to obtain another id: var apiRequestId = event.context['request-id'];","timestamp":"1634404140.0"}],"upvote_count":"13","poster":"RicardoD"},{"upvote_count":"1","poster":"avinashk99","content":"Selected Answer: A\nEach invocation of a Lambda function may run on a new container instance. The local file system (/tmp) is the only writable directory, but it:\nIs cleared out when the Lambda container is terminated or reused for another invocation.","comment_id":"1347924","timestamp":"1738071900.0"},{"upvote_count":"1","timestamp":"1734342480.0","poster":"sumanshu","comment_id":"1327251","content":"Selected Answer: A\nA) Correct - Each AWS Lambda invocation has a unique request identifier (aws_request_id) that can be obtained from the Lambda context object (context.aws_request_id).\n\nLogs written to the console are automatically captured and sent to Amazon CloudWatch Logs by the Lambda service. No additional file handling is required, ensuring simplicity.","comments":[{"upvote_count":"1","poster":"sumanshu","comment_id":"1327252","comments":[{"timestamp":"1734342600.0","poster":"sumanshu","content":"D) Eliminated - writing logs to a file is inefficient and unnecessary in a Lambda environment.","comment_id":"1327253","upvote_count":"1"}],"content":"B & C - Eliminated The event object contains the input payload for the Lambda function, not the unique request identifier.","timestamp":"1734342540.0"}]},{"content":"Selected Answer: A\nLambda event object doesn't provide unique identifier\n\nWriting logs to a file is not practical in a Lambda environment, as Lambda functions are stateless and ephemeral, meaning any files written to the local filesystem are not persistent.","timestamp":"1731396480.0","upvote_count":"1","comment_id":"1310471","poster":"JonasKahnwald"},{"poster":"dostonbekabdullaev","timestamp":"1705389420.0","comment_id":"1123939","upvote_count":"1","content":"Selected Answer: A\nAAAAAAAA"},{"comment_id":"1123042","content":"Selected Answer: A\ni will go with A","upvote_count":"1","timestamp":"1705291740.0","poster":"AsmaZoheb"},{"upvote_count":"2","poster":"Quang_Nguyen","timestamp":"1704538920.0","comment_id":"1115126","content":"Selected Answer: A\nAnswer A because:\nWhile Lambda supports writing logs to files, logging to the console offers distinct advantages:\n- Integration with CloudWatch Logs: Lambda automatically forwards console logs to CloudWatch Logs, providing centralized logging and monitoring.\n- Efficiency and Scalability: Lambda manages console logging, avoiding overhead and ensuring scalability.\n- Querying and Filtering: CloudWatch Logs allows you to query and filter logs based on the request identifier, making it easy to track events for specific invocations."},{"comment_id":"1105155","upvote_count":"1","content":"Selected Answer: D\nconsidering the best practices for logging and persisting logs associated with Lambda function","poster":"a_win","timestamp":"1703498220.0"},{"comment_id":"1067968","timestamp":"1699721340.0","poster":"kyoharo","upvote_count":"3","content":"Selected Answer: D\nD. Obtain the request identifier from the Lambda context object. Architect the application to write logs to a file.\n\nExplanation:\n\n Lambda Context Object: The Lambda context object contains information about the invocation, including a unique identifier for the request. This identifier can be used to associate events with a specific function invocation.\n\n Write Logs to a File: Writing logs to a file is a common practice in Lambda functions, as it allows for persistent storage of logs that can be later analyzed. This is more suitable for production scenarios compared to writing logs to the console, which might not persist after the function execution."},{"comment_id":"1026249","upvote_count":"2","poster":"cdm2009","content":"Selected Answer: A\nThe default file options available to Lambda are temporary, and there's no mention of configuring any advanced storage system. Nor is it necessary - CloudWatch will just automatically collect output from Lambda STDOUT, providing optimal management and processing options inherently.","timestamp":"1696567680.0"},{"poster":"sara_exam_topics","upvote_count":"2","comment_id":"1020563","content":"Selected Answer: A\nObtaining Request Identifier from Lambda Context Object: The Lambda context object includes a unique request ID, which can be used to associate events with a specific function invocation.\n\nWriting Logs to the Console: Writing logs to the console (stdout) within a Lambda function is a common practice. These console logs can be captured and persisted using AWS CloudWatch Logs, making them accessible for later analysis and troubleshooting.","timestamp":"1695971640.0"},{"upvote_count":"3","comment_id":"954749","timestamp":"1689640680.0","content":"It's A, not D. writing logs to a file is not recommended for Lambda functions because the file system of a Lambda execution environment is ephemeral and not persisted across invocations.","poster":"CarlosC"},{"comment_id":"954296","content":"Selected Answer: A\nIt is context that will add data to console or standard output, cause saving to file just adds overhead but output can anyways be seen or saved from cloudwatch if needed","timestamp":"1689605460.0","poster":"ancomedian","upvote_count":"1"},{"poster":"MalayShah","upvote_count":"1","content":"Selected Answer: A\nBoth A & D seems correct. Actually D seems more relevant as it will contain only function logs which app is stroring instead of CloudWatch logs which contains Lambda default start execution logs as well. \nBut still I want to go with A as storing to file in S3 will require additional IAM Role attached to Lambda execution role and question has just mention what will just work so.","comment_id":"946336","timestamp":"1688806560.0"},{"content":"Selected Answer: D\nThe correct answer is D. Obtain the request identifier from the Lambda context object. Architect the application to write logs to a file.\n\nAWS Lambda provides a context object that contains information about the runtime environment and the current function invocation. The context object includes a unique identifier called the \"request identifier\" or \"request ID.\" This identifier can be obtained from the context object and used to associate the events with a specific function invocation.\n\nTo accomplish the objective of logging key events with a unique identifier, the developer should obtain the request identifier from the Lambda context object. Additionally, the developer should architect the application to write logs to a file, rather than just writing them to the console. Writing logs to a file allows for better log management and enables additional analysis and processing of the logs.\n\nTherefore, option D is the correct choice: Obtain the request identifier from the Lambda context object and architect the application to write logs to a file.","comments":[{"upvote_count":"1","poster":"cdm2009","comment_id":"1026244","content":"The default file options available to Lambda are temporary, and there's no mention of configuring any advanced storage system. Nor is it necessary - CloudWatch will just automatically collect output from Lambda STDOUT, providing optimal management and processing options inherently.","timestamp":"1696567380.0"}],"timestamp":"1688465820.0","upvote_count":"2","comment_id":"942605","poster":"Yasser001"},{"poster":"konatus","comment_id":"937428","upvote_count":"2","timestamp":"1688008200.0","content":"Selected Answer: A\nCloudWatch will collect the output from console."},{"comment_id":"935663","poster":"rcaliandro","timestamp":"1687888080.0","upvote_count":"1","content":"Also here I am really confused. One thing is for sure, we do need the context instead of the event to retrieve the unique identifier. \nSo, between A and D I don't know what to choose and for this reason I'm not voting here. \nIs it better put the logs in a file (maybe an s3 folder) or in the console (in order that the logs will be avaialable on CloudWatch)?"},{"comments":[{"comment_id":"932427","upvote_count":"1","poster":"kagu","timestamp":"1687601400.0","content":"its a tricky question, but lambda functions runs your script in a wrapper that also records the stdout of the script, it can be A, but in actual practice, you usually want to go with D"}],"content":"Selected Answer: D\nit's D. Option A (Obtain the request identifier from the Lambda context object. Architect the application to write logs to the console) may not be the ideal choice as writing logs to the console does not provide persistent storage, and the logs may be lost after the function execution ends.","poster":"ezredame","comment_id":"908857","upvote_count":"1","timestamp":"1685305560.0"},{"poster":"MrTee","timestamp":"1682250660.0","content":"Selected Answer: A\nThe request identifier is available in the context object passed to the Lambda function. The developer can use this identifier to associate log events with a specific function invocation. By writing logs to the console, they will be automatically captured by AWS CloudWatch Logs.","upvote_count":"1","comment_id":"878277"},{"timestamp":"1680739560.0","content":"Selected Answer: D\nThe unique identifier is in the context, so the available options are A or D.\nThe developer wants to log KEY events, so the KEY events must be defined and saved by the developer, CloudWatch logs saves a lot of information, to which would be added the one written by the developer in the console, so A is not a good option, regardless of the fact that the problem does not mention that it has permissions to write to Cloudwatch, in which case the main point of the problem, which is logging, would not be met. For all of the above, the correct option is D.","poster":"nearavenac","upvote_count":"1","comment_id":"862600"},{"content":"Answer D\nContext object provides the necessary information about the Lambda. Also, writing logs to a file is better and more professional as it allows for long time archiving and compliance needs.","timestamp":"1680464640.0","upvote_count":"1","comment_id":"859300","poster":"AgboolaKun"},{"content":"Selected Answer: D\nThe AWS Lambda context object provides information about the Lambda function invocation, including a unique identifier for the request. This identifier can be used to associate log events with a specific function invocation. Writing logs to a file is a better practice as it allows developers to store, archive, or analyze log data later. Writing logs to the console is generally not recommended for production-ready applications as it can cause issues like scrolling latency when there is a high volume of log events.","upvote_count":"1","comment_id":"854080","timestamp":"1680071280.0","poster":"Cock"},{"comment_id":"823293","content":"Selected Answer: D\nThe correct answer is D. Obtain the request identifier from the Lambda context object. Architect the application to write logs to a file.\n\nLambda functions in AWS provide two objects to pass contextual information to the function: the event object and the context object. The event object contains the input data for the function, while the context object contains information about the function and its execution environment, such as function name, memory limit, and request ID.","timestamp":"1677480120.0","poster":"sebasbonilla","upvote_count":"1"},{"comment_id":"819947","timestamp":"1677199500.0","content":"Selected Answer: D\nThe answer is D. Everybody seems to agree that function identifier is in the context object. The thing people are divided on is whether to write the logs to the console or to a file. I think the logs should be written to a file as printing them in the console wouldn't be of much value.","upvote_count":"1","poster":"pancman"},{"upvote_count":"2","poster":"isshin","comment_id":"816172","content":"Selecting D as writing event logs to a file is more productive than seeing it in cloudwatch logs","timestamp":"1676951340.0"},{"comment_id":"813437","timestamp":"1676748300.0","upvote_count":"3","poster":"jra777","content":"Selected Answer: D\nshould save to file because console already provide context through cloud watch"},{"timestamp":"1676298660.0","content":"A. Obtain the request identifier from the Lambda context object. Architect the application to write logs to the console.\nTo log key events and associate them with a specific function invocation, the developer should obtain the request identifier from the Lambda context object. The context object provides information about the current invocation, including the request ID, which is a unique identifier for the current invocation. The developer can log key events by writing them to the console, as this information will be available in the CloudWatch Logs for the function.","comment_id":"807485","poster":"may2021_r","upvote_count":"1"},{"upvote_count":"1","timestamp":"1676114760.0","content":"Selected Answer: D\nFrom context and write to a file to check on logs at a later date.","poster":"Smartiup","comment_id":"805163"},{"upvote_count":"1","content":"Selected Answer: A\nshould be A","timestamp":"1676061120.0","poster":"Krt5894","comment_id":"804771"},{"comment_id":"781793","content":"Selected Answer: D\nwrite to a file","upvote_count":"1","poster":"unbornfroyo","timestamp":"1674181200.0"},{"poster":"ayoubmk","content":"Selected Answer: A\nThe simplest way to see logs from your AWS lambda function is in the console so I vote for A.","comment_id":"763443","upvote_count":"2","timestamp":"1672623180.0"},{"poster":"fabriciollf","timestamp":"1671996900.0","content":"Selected Answer: A\nThe correct answer is A","upvote_count":"2","comment_id":"755953"},{"comment_id":"729232","content":"Selected Answer: D\nOnly Context object will give the request identifier, so the question is whether writing to log or console. From development perspective, it must be writing to file for logging, as writing to console is not persistent. Hence, answer is D.","timestamp":"1669646160.0","poster":"humble_developer","upvote_count":"3"},{"timestamp":"1669602000.0","content":"Selected Answer: A\ncontext.awsRequestId is the unique ID for Lambda that can be associated with the events\n\nOther option that says event context id (var apiRequestId = event.context['request-id']) is the API Gateway event context request ID , that is passed to lambda using mapping template (https://aws.amazon.com/blogs/compute/techniques-and-tools-for-better-serverless-api-logging-with-amazon-api-gateway-and-aws-lambda/). It is not mentioned anywhere Lambda is invoked by API gateway.","poster":"SBoksh","upvote_count":"3","comment_id":"728744"},{"upvote_count":"1","content":"A. Per the question 1. There must be a list of key events that interest the developer; 2. each of the event invokes a different function. So the functionName fron lambda context is a good candidate for the ID to the event.","comment_id":"727896","timestamp":"1669516440.0","poster":"gpit"},{"timestamp":"1669174020.0","upvote_count":"1","poster":"IvanPetrovichPavlov","comment_id":"724859","content":"Selected Answer: D\nneeds to log key events into file, since CloudWatch logs will contains too much noise."},{"poster":"dark_cherrymon","content":"C?\n\nevent and context has request id\n\nthe question says it wants to associate lambda with the event, so i would think that event is the api gateway and not lambda itself\n\nexports.handler = function(event, context) {\n var apiRequestId = event.context['request-id'];\n var lambdaRequestId = context.awsRequestId;\n console.log(\"API Gateway Request ID: \" + apiRequestId + \" Lambda Request ID: \" + context.awsRequestId);\n var logprefix = \"APIG: \" + apiRequestId + \" - \";\n console.log(logprefix + \"hello world!\");\n ...\n}","timestamp":"1668653100.0","upvote_count":"2","comment_id":"720148"},{"timestamp":"1665415560.0","comment_id":"691303","upvote_count":"9","content":"Selected Answer: D\nAccording to Tutorial Dojo the correct answer is D:\n\nThe option that says: Get the awsRequestId from the context object and log it to the console is incorrect. This won’t be an effective logging solution as the logs with specific events would be difficult to find through the stream of CloudWatch Logs. Also, if the objective is to log to the console, getting the request ID from the context object will no longer be necessary since CloudWatch Logs already does this for you.\n\nSo...the correct one is to log to a file because it is already logger to the console, so there is no need to do that...","poster":"SuperPiski"},{"comment_id":"678795","poster":"GenePoole","upvote_count":"6","timestamp":"1664110980.0","content":"Selected Answer: A\nThe request identifier is found in the context, logging to console will appear in the log.\n\nhttps://aws.amazon.com/blogs/compute/techniques-and-tools-for-better-serverless-api-logging-with-amazon-api-gateway-and-aws-lambda/"},{"content":"Selected Answer: A\nANS: A","timestamp":"1643926140.0","poster":"JP_PA","upvote_count":"4","comment_id":"540038"},{"content":"A\n\nhttps://docs.aws.amazon.com/whitepapers/latest/serverless-architectures-lambda/the-context-object.html","timestamp":"1636161300.0","comment_id":"452990","upvote_count":"1","poster":"jc966"},{"timestamp":"1635616440.0","comment_id":"352610","upvote_count":"2","poster":"VAG1595","content":"Answer: A"},{"comments":[{"upvote_count":"3","timestamp":"1635480600.0","poster":"br00net","comment_id":"348868","content":"I will strengthen my argumentation: couple of weeks ago I took the exam and my score was 994/1000","comments":[{"content":"congrats to your results, though","poster":"ai_neuro","upvote_count":"4","comment_id":"368804","timestamp":"1636093020.0"},{"timestamp":"1664265660.0","poster":"Veit","upvote_count":"2","comment_id":"680505","content":"the reality is that \"The exam includes 15 unscored questions that do not affect your score.\" (https://d1.awsstatic.com/training-and-certification/docs-dev-associate/AWS-Certified-Developer-Associate_Exam-Guide.pdf) \nSo, it possible that you failed 15 of 65 questions and still have 1000/1000"},{"timestamp":"1668651720.0","poster":"dark_cherrymon","content":"ok it's C then, i was thinking C too, suprised it was just the other two","upvote_count":"1","comment_id":"720143"}]},{"timestamp":"1635993360.0","upvote_count":"3","comment_id":"368803","content":"It's A: The this identifier is not automatically included in the log message.\n\nI think you are referring to this post here: https://aws.amazon.com/blogs/compute/techniques-and-tools-for-better-serverless-api-logging-with-amazon-api-gateway-and-aws-lambda/\n\nHowever, in this case the request-id is only found in the event structure because the blogger re-sends the API-gateway context information ($context.requestId) to the downstream lambda using a mapping template.","poster":"ai_neuro"}],"comment_id":"314846","timestamp":"1634400180.0","poster":"br00net","upvote_count":"5","content":"C is the correct answer\nAn identifier that can be obtained from the Lambda context object is automatically included in the log message. \nAs in the question developer wants - \" to associate the events with a specific function invocation.\" We need to obtain another id: var apiRequestId = event.context['request-id'];"},{"comment_id":"189649","poster":"Chinta","content":"Answer is A","timestamp":"1634232420.0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1634006100.0","poster":"saeidp","comment_id":"174951","content":"A is correct"},{"content":"answer : A","comment_id":"164688","upvote_count":"1","timestamp":"1633520760.0","poster":"hellohi"},{"content":"Agree with A","upvote_count":"1","poster":"ipindado2020","timestamp":"1633124700.0","comment_id":"164578"},{"timestamp":"1632709380.0","content":"I think its D ref https://docs.aws.amazon.com/lambda/latest/dg/java-context.html","upvote_count":"1","poster":"Polu","comment_id":"163308","comments":[{"content":"Now I think its A not D beacause Lambda log are writter to console https://docs.aws.amazon.com/lambda/latest/dg/java-logging.html","poster":"Polu","comment_id":"163313","timestamp":"1632853140.0","upvote_count":"3"}]}],"choices":{"D":"Obtain the request identifier from the Lambda context object. Architect the application to write logs to a file.","A":"Obtain the request identifier from the Lambda context object. Architect the application to write logs to the console.","B":"Obtain the request identifier from the Lambda event object. Architect the application to write logs to a file.","C":"Obtain the request identifier from the Lambda event object. Architect the application to write logs to the console."},"answer_ET":"A","exam_id":25,"question_images":[],"answer":"A","answer_description":"","timestamp":"2020-08-18 19:11:00","url":"https://www.examtopics.com/discussions/amazon/view/29007-exam-aws-certified-developer-associate-topic-1-question-26/","isMC":true,"answer_images":[],"answers_community":["A (54%)","D (46%)"]},{"id":"dqGDXrBtariAjhEDAaGZ","url":"https://www.examtopics.com/discussions/amazon/view/88692-exam-aws-certified-developer-associate-topic-1-question-260/","exam_id":25,"discussion":[{"comment_id":"938473","upvote_count":"1","poster":"rcaliandro","content":"Selected Answer: A\nAmazon Cognito user pools of course. Cognito user pools provide authentication, Cognito Identity pool (not even present among the options) provide authorization. A is the correct answer.","timestamp":"1688064900.0"},{"comment_id":"900142","timestamp":"1684327380.0","poster":"pranay_2406","upvote_count":"1","content":"Selected Answer: A\nTo meet the requirements of storing user attributes and allowing new users to sign up using their email addresses, the developer should implement Amazon Cognito user pools.\n\nOption A, Amazon Cognito user pools, is the correct choice. Amazon Cognito user pools provide a fully managed user directory service that allows developers to add sign-up and sign-in functionality to their web or mobile applications. User pools support millions of users and can handle high-scale user registration and authentication.\n\nWith Amazon Cognito user pools, developers can configure the user pool to allow users to sign up using their email addresses. User attributes, such as name, email, and custom attributes, can be defined and stored for each user. Additionally, user pools offer features like multi-factor authentication, password recovery, and customizable email templates."},{"timestamp":"1676592300.0","comment_id":"811223","poster":"pancman","upvote_count":"4","content":"Selected Answer: A\nWhen you see a question with anything related to users signing up on the app --> Cognito"},{"comment_id":"798582","poster":"tony554556","content":"Whoever makes the default correct answer must be drunk or know nothing about AWS.","upvote_count":"4","timestamp":"1675566420.0"},{"upvote_count":"2","content":"Selected Answer: A\nCognito 100%","timestamp":"1669446000.0","poster":"michaldavid","comment_id":"727348"},{"timestamp":"1669437000.0","comment_id":"727257","upvote_count":"2","content":"Selected Answer: A\nChoosing A","poster":"k1kavi1"},{"poster":"kapil206001","comment_id":"726750","timestamp":"1669379760.0","content":"A\nhttps://www.examtopics.com/discussions/amazon/view/10491-exam-aws-certified-developer-associate-topic-1-question-102/","upvote_count":"1"}],"question_text":"A developer is designing a web application in which new users will use their email addresses to create accounts. Millions of users are expected to sign up. The application will store attributes for each user.\n\nWhich AWS service or feature should the developer implement to meet these requirements?","timestamp":"2022-11-25 13:36:00","answer_description":"","isMC":true,"question_id":180,"unix_timestamp":1669379760,"choices":{"D":"AWS Mobile Hub Cloud Logic","C":"AWS AppSync","B":"AWS Mobile Hub User File Storage","A":"Amazon Cognito user pools"},"answers_community":["A (100%)"],"question_images":[],"topic":"1","answer":"A","answer_ET":"A","answer_images":[]}],"exam":{"name":"AWS Certified Developer Associate","isBeta":false,"numberOfQuestions":443,"isMCOnly":true,"id":25,"lastUpdated":"11 Apr 2025","isImplemented":true,"provider":"Amazon"},"currentPage":36},"__N_SSP":true}