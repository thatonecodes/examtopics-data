{"pageProps":{"questions":[{"id":"3zZztCtqnF0Z9giTVzL4","url":"https://www.examtopics.com/discussions/amazon/view/68949-exam-aws-certified-security-specialty-topic-1-question-289/","answers_community":["D (100%)"],"choices":{"D":"Create a security group with a single inbound rule that allows connections from 0.0.0.0/0 on port 443. Ensure this security group is the only one associated with the ALB.","C":"Create a network ACL that allows outbound connections to the VPC IP range on port 443 only. Associate the network ACL with the VPC's internet gateway.","A":"Create a security group with a rule that denies inbound connections from 0.0.0.0/0 on port 80. Attach this security group to the ALB to overwrite more permissive rules from the ALB's default security group.","B":"Create a network ACL that denies inbound connections from 0.0.0.0/0 on port 80. Associate the network ACL with the VPC's internet gateway."},"answer_ET":"D","topic":"1","unix_timestamp":1640792400,"discussion":[{"poster":"Radhaghosh","content":"Answer D, Very Simple and Classical Use case","comment_id":"533419","timestamp":"1643249400.0","upvote_count":"7"},{"content":"Selected Answer: D\nOnly allow HTTPS (443) in ALB's SG.","poster":"Raphaello","comment_id":"1155711","timestamp":"1708533960.0","upvote_count":"1"},{"timestamp":"1685789220.0","content":"Selected Answer: D\nD only makes sense","poster":"Toptip","upvote_count":"1","comment_id":"913463"},{"content":"A - SG - can't have deny rules\nB - Not correct - NACL would deny for every instance with subnet, NACL is associated to subset not sure what is meant by associate NACL with VPC's IGW\nC - Not correct - Need inbound rule restrictions, NACL is associated to subset not sure what is meant by associate NACL with VPC's IGW\nD - SG allows all traffic on 443, this does the job\nAnswer is D","timestamp":"1662096480.0","poster":"MungKey","comment_id":"657006","upvote_count":"1"},{"content":"NACL operates at the subnet level while SG at the instance ot NI level","upvote_count":"2","poster":"sapien45","timestamp":"1658168280.0","comment_id":"633122"},{"upvote_count":"1","timestamp":"1642474380.0","comment_id":"526270","content":"Selected Answer: D\nSimple, only allow 443 in SG and it'll implicitly block all traffic over any other ports.","poster":"sam_live"},{"content":"D.....","timestamp":"1640993340.0","comment_id":"514262","poster":"roger8978","upvote_count":"2"},{"content":"Answer is D,,,,,","poster":"babaseun","upvote_count":"1","timestamp":"1640792400.0","comment_id":"512333"}],"timestamp":"2021-12-29 16:40:00","question_id":211,"question_images":[],"exam_id":29,"question_text":"A company needs to use HTTPS when connecting to its web applications to meet compliance requirements. These web applications run in Amazon VPC on\nAmazon EC2 instances behind an Application Load Balancer (ALB). A security engineer wants to ensure that the load balancer will only accept connections over port 443, even if the ALB is mistakenly configured with an HTTP listener.\nWhich configuration steps should the security engineer take to accomplish this task?","answer_description":"","answer_images":[],"answer":"D","isMC":true},{"id":"qRGHQUDFUbp2F4wbBRfm","exam_id":29,"answer_images":[],"answer_description":"","isMC":true,"question_text":"A security team is responsible for reviewing AWS API call activity in the cloud environment for security violations. These events must be recorded and retained in a centralized location for both current and future AWS regions.\nWhat is the SIMPLEST way to meet these requirements?","answer":"C","choices":{"D":"Enable Amazon CloudWatch logging for all AWS services across all regions, and aggregate them to a single Amazon S3 bucket for later analysis.","C":"Enable AWS CloudTrail by creating a new trail and applying the trail to all regions. Specify a single Amazon S3 bucket as the storage location.","A":"Enable AWS Trusted Advisor security checks in the AWS Console, and report all security incidents for all regions.","B":"Enable AWS CloudTrail by creating individual trails for each region, and specify a single Amazon S3 bucket to receive log files for later analysis."},"answers_community":["C (89%)","11%"],"discussion":[{"poster":"sensor","comment_id":"3309","upvote_count":"36","content":"The referenced link does not prove req that futre regions must be taken into account. With C future regions req is satisfied.","timestamp":"1632069120.0"},{"timestamp":"1632724980.0","content":"The reference link actually supports C.","poster":"Osemk","comment_id":"9379","upvote_count":"17"},{"content":"Selected Answer: C\nC is the correct answer.","upvote_count":"1","timestamp":"1709691240.0","poster":"Raphaello","comment_id":"1166877"},{"poster":"tonimrz","upvote_count":"1","timestamp":"1691664780.0","content":"Selected Answer: C\nYo can apply this trail in several regions in a easy way.","comment_id":"977540"},{"comment_id":"971803","content":"Selected Answer: B\nJust look at CT 'Create Trail' options","poster":"addy_prepare","timestamp":"1691135100.0","upvote_count":"1"},{"timestamp":"1688303400.0","content":"C - an org trail with central logging created from the management account","comment_id":"940897","poster":"CE1212","upvote_count":"1"},{"content":"Selected Answer: C\nAnswer should be C. It's easier than B","timestamp":"1685882460.0","upvote_count":"1","poster":"Robert0","comment_id":"914592"},{"upvote_count":"2","poster":"bbddmm","comment_id":"890682","content":"Selected Answer: C\nthe answer is C","timestamp":"1683369660.0"},{"comment_id":"801284","timestamp":"1675795020.0","upvote_count":"1","content":"Selected Answer: C\nSimplest would be C. Creating seperate trails wills just be unnecessary in this case","poster":"AWS_Noob"},{"timestamp":"1674896580.0","upvote_count":"3","comment_id":"790434","poster":"Suhasj02","content":"C - You can configure CloudTrail to deliver log files from multiple regions to a single S3 bucket for a single account. For example, you have a trail in the US West (Oregon) Region that is configured to deliver log files to a S3 bucket, and a CloudWatch Logs log group. When you change an existing single-region trail to log all regions, CloudTrail logs events from all regions that are in a single AWS partition in your account. CloudTrail delivers log files to the same S3 bucket and CloudWatch Logs log group.\n\nTo log events across all regions in all AWS partitions in your account, create a multi-region trail in each partition.\n\nLink - https://docs.aws.amazon.com/awscloudtrail/latest/userguide/receive-cloudtrail-log-files-from-multiple-regions.html","comments":[{"content":"Yes this explanation seems to be good with partitions and mutli-region trail.\nSo I vote C as well.","upvote_count":"1","timestamp":"1708268820.0","comment_id":"1153361","poster":"virtual"}]},{"comment_id":"777225","upvote_count":"2","timestamp":"1673830560.0","poster":"pearl15","content":"Selected Answer: C\nC It should be C and no brainer. Questions is asking about all the trails and future trails not asking about selective trails. B could have been the answer if the selective trails were the question. Since one trail across multiple regions is supported, we should create Multiple Region."},{"poster":"janvandermerwer","comments":[{"timestamp":"1673296860.0","comment_id":"770843","poster":"xplusfb","content":"Absolutely agreed. C is the right one.","upvote_count":"1"}],"content":"Selected Answer: C\nC for ease of current (and future) management.\n\nCloudwatch doesn't really work that way.","comment_id":"716393","upvote_count":"2","timestamp":"1668212760.0"},{"upvote_count":"4","timestamp":"1666955580.0","comment_id":"706382","content":"Selected Answer: C\nBy default trail is a multi-region. You neeed to use cli to create a single-region trail:\n\"In the console, you create a trail that logs events in all AWS Regions that you have enabled. This is a recommended best practice. To log events in a single region (not recommended), use the AWS CLI.\"","poster":"[Removed]"},{"upvote_count":"1","content":"C is the answer","poster":"arae","comment_id":"691343","timestamp":"1665418560.0"},{"timestamp":"1664485620.0","comment_id":"683061","upvote_count":"1","content":"C question talks about a region and subsequent regions in future","poster":"Desteeny"},{"upvote_count":"1","comment_id":"681896","timestamp":"1664380740.0","poster":"ceeee","content":"Selected Answer: C\nC is definitely the answe"},{"content":"Selected Answer: C\nC is correct","timestamp":"1663579320.0","comment_id":"673124","poster":"Mr__","upvote_count":"1"},{"content":"Selected Answer: C\nou can now turn on a trail across all regions for your AWS account. CloudTrail will deliver log files from all regions to the Amazon S3 bucket and an optional CloudWatch Logs log group you specified. Additionally, when AWS launches a new region, CloudTrail will create the same trail in the new region. As a result, you will receive log files containing API activity for the new region without taking any action.","upvote_count":"3","comment_id":"658649","timestamp":"1662222540.0","poster":"sapien45"},{"comment_id":"655247","upvote_count":"1","poster":"123Raj333","timestamp":"1661962200.0","content":"Selected Answer: C\nfuture regions"},{"content":"Selected Answer: C\noption C","comment_id":"639367","poster":"dcasabona","timestamp":"1659119880.0","upvote_count":"1"},{"content":"Selected Answer: B\nC is also Organisation Trail","poster":"sapien45","upvote_count":"2","timestamp":"1658166840.0","comment_id":"633114"},{"comment_id":"587885","upvote_count":"1","content":"Selected Answer: C\nMulti-Region Capable","poster":"w_a_r","timestamp":"1650319080.0"},{"content":"Selected Answer: C\nand future AWS regions.","timestamp":"1649955420.0","upvote_count":"1","poster":"TigerInTheCloud","comment_id":"585914"},{"upvote_count":"1","content":"Selected Answer: C\nWho is the guy who replied to these questions ? he shouldn't be certified ;P","poster":"mx677","comment_id":"552400","timestamp":"1645402440.0"},{"comment_id":"468714","upvote_count":"1","content":"C > https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","timestamp":"1635953220.0","poster":"1awssec"},{"upvote_count":"1","content":"C is my answer.","comment_id":"437277","poster":"hk436","timestamp":"1635930780.0"},{"content":"C is correct. Default, create a trail in Console, it is applied to all regions already. We can use this command to check \"aws cloudtrail describe-trails\" and see the parameter \"IsMultiRegionTrail\": true would be appeared.","poster":"Kdosec","comment_id":"397375","upvote_count":"3","timestamp":"1635844920.0"},{"poster":"Mikeclue","content":"C is the correct answer","comment_id":"356537","timestamp":"1635706560.0","upvote_count":"2"},{"content":"Ans: C 100%","upvote_count":"1","poster":"sanjaym","timestamp":"1635659220.0","comment_id":"353795"},{"content":"Why in the world is this not C! you can enable Cloudtrail for all regions. Why would I do this each individually?","upvote_count":"3","comment_id":"229714","timestamp":"1635482820.0","poster":"shooricg"},{"poster":"devjava","timestamp":"1635360060.0","upvote_count":"3","content":"Ans > C\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/receive-cloudtrail-log-files-from-multiple-regions.html","comment_id":"221860"},{"comment_id":"207426","content":"Ans(c)\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/receive-cloudtrail-log-files-from-multiple-regions.html","poster":"AfricanCloudGuru","upvote_count":"2","timestamp":"1635231300.0"},{"poster":"Ayusef","timestamp":"1635226860.0","content":"Clearly C... I often wonder if the people selecting the answers on the front side just randomly click buttons.","upvote_count":"1","comment_id":"198402"},{"content":"The key is \"current regions and future regions\", option C correctly satisfies the ask.","poster":"satbim","timestamp":"1635223500.0","upvote_count":"1","comment_id":"188071"},{"timestamp":"1634992200.0","comment_id":"155121","upvote_count":"1","poster":"enthuguys","content":"Correct is C\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/receive-cloudtrail-log-files-from-multiple-regions.html"},{"comment_id":"119319","poster":"shikyo","upvote_count":"2","content":"no the correct answer is C ! if you create a trail by region, you will don't support the future region, like it writen in the question.","timestamp":"1634976180.0"},{"comment_id":"87122","content":"C. - For Apply trail to all regions, choose Yes to receive log files from all Regions. This is the default and recommended setting. If you choose No, the trail logs files only from the Region in which you create the trail.","timestamp":"1634925900.0","upvote_count":"2","poster":"AnilL"},{"content":"C is the correct answer. Here is why - \"You can now turn on a trail across all regions for your AWS account. CloudTrail will deliver log files from all regions to the Amazon S3 bucket [...]. Additionally, when AWS launches a new region, CloudTrail will create the same trail in the new region. As a result, you will receive log files containing API activity for the new region without taking any action.\"","comment_id":"82249","poster":"Ahmaad","upvote_count":"5","timestamp":"1634659080.0"},{"comment_id":"81340","content":"C is correct.","upvote_count":"1","poster":"raju7258","timestamp":"1634485500.0"},{"upvote_count":"1","poster":"RaySmith","timestamp":"1634158620.0","comment_id":"75242","content":"C is correct"},{"upvote_count":"2","comment_id":"59845","timestamp":"1633844160.0","content":"C is the right answer as if you create an individual trail in each region then the future region will not be added automatically, you have to go to cloudtrail to enable trail for every new region.\n\nSo C is the correct answer.","poster":"ankurpatel18"},{"content":"C is the answer.","poster":"RakeshTaninki","timestamp":"1633369260.0","upvote_count":"1","comment_id":"45657"},{"timestamp":"1633218060.0","content":"C is correct for sure . When you open Cloudtrail console, click trails and create new trail and then you can specify the option if \"Apply trail to all regions\n\"Yes No\" .","comment_id":"10808","poster":"INASR","upvote_count":"6"},{"timestamp":"1633195740.0","upvote_count":"3","content":"C is correct ans","comment_id":"10190","poster":"ugreenhost"},{"timestamp":"1632629760.0","comment_id":"8505","content":"C is Correct","upvote_count":"5","poster":"BillyC"},{"poster":"Wpcorgan","comment_id":"8187","timestamp":"1632417960.0","content":"C ! Correct","upvote_count":"2"},{"poster":"jchen","comment_id":"7824","content":"Correct answer is C","timestamp":"1632179400.0","upvote_count":"4"}],"topic":"1","question_images":[],"unix_timestamp":1561791300,"question_id":212,"url":"https://www.examtopics.com/discussions/amazon/view/2060-exam-aws-certified-security-specialty-topic-1-question-29/","answer_ET":"C","timestamp":"2019-06-29 08:55:00"},{"id":"jOgyHIGovqw4zVSPUgit","exam_id":29,"unix_timestamp":1641412800,"timestamp":"2022-01-05 21:00:00","answer_ET":"D","answers_community":["D (60%)","B (40%)"],"discussion":[{"content":"Selected Answer: D\nleast amount of management overhead --> Answer D","comment_id":"532467","timestamp":"1643150280.0","poster":"Radhaghosh","upvote_count":"8"},{"content":"Selected Answer: B\nBest answer is B.\n\nThe ask is to \" assess the impact of the exposed access key\", which mean how the exposed access key has been used.\nCredential report does not include such information, it includes information about the credential itself..when it was created, last used, last changed. Not useful to assess the impact.","poster":"Raphaello","comment_id":"1161777","upvote_count":"1","timestamp":"1709136060.0"},{"upvote_count":"1","content":"D, according to ChatGPT. \n\n\"Here's why Option D is the best choice:\n - AWS IAM provides a credential report that contains details about the AWS access keys associated with your IAM users.\n - The credential report includes information such as when each access key was last used.\n - Analyzing this report is a straightforward and efficient way to determine the last usage of the exposed access key.\n- It does not involve setting up additional logs or searching through logs, which can be more time-consuming and complex.\"","timestamp":"1696939980.0","poster":"AWSvad","comment_id":"1039477"},{"content":"Selected Answer: B\nto assess the impact of the exposed access key. -> search for the access key in CloudWatch Logs","poster":"Nuha_23","comment_id":"990233","timestamp":"1692981720.0","upvote_count":"1"},{"poster":"captainpike","comment_id":"963642","content":"Selected Answer: B\nQuestion says \"The company needs to assess the impact of the exposed access key.\" How can you analyze the impact with IAM Report \"last used\" info ? It has to be B","timestamp":"1690370220.0","upvote_count":"2"},{"comments":[{"timestamp":"1685789760.0","poster":"Toptip","comment_id":"913468","content":"Good article:\nhttps://aws.amazon.com/blogs/security/new-in-iam-quickly-identify-when-an-access-key-was-last-used/","upvote_count":"1"}],"timestamp":"1685789520.0","poster":"Toptip","comment_id":"913467","upvote_count":"2","content":"Selected Answer: D\nB can be true only if CloudTrail was enabled. since it was not mentioned in the question i pick D."},{"timestamp":"1676704320.0","poster":"gtmnagalla","upvote_count":"1","comment_id":"812752","content":"Selected Answer: D\nboth B&D seems correct options but 'D' has less managerial overhead"},{"poster":"dcasabona","upvote_count":"4","comment_id":"644625","content":"Selected Answer: B\nI agree that option D would be faster to check if the Access Key was used, but there is a gap of 4 hours to be generated. So, we could be looking at a past information. As CloudWatch is near real time, I would go for it - option B.","timestamp":"1660069140.0"},{"content":"Selected Answer: B\nQuestion is to examine the ramifications of the revealed access key.\ncan only be done via option B i.e. Analyze Amazon CloudWatch Logs for activity by searching for the access key.\nYou can configure CloudTrail with CloudWatch Logs to monitor your trail logs and be notified when specific activity occurs.\n\n The credential report in AWS Identity and Access Management (IAM) can only see when the access key was last used\n\nhence the answer is B (Analyze Amazon CloudWatch Logs for activity by searching for the access key)","upvote_count":"4","poster":"Tesla_0011","comment_id":"604716","comments":[{"upvote_count":"1","timestamp":"1669774980.0","poster":"landsamboni","comment_id":"731021","comments":[{"comment_id":"731026","poster":"landsamboni","timestamp":"1669775940.0","content":"Correction: it is D. If the developer informed his supervisor immediately, the credential report would be enough to determine if the access key was used after the manager disabled it and the service used. However, I'm still not comfortable considering the impact measurement of this option. Still, I think D is the quickest and easy step to follow. Not necessarily the best.","upvote_count":"1"}],"content":"Exactly, suppose the credential report tells you \"the key was used 1 hour ago\", how could you check the impact with only that information? you need to check when and also what was done using that key. That is why I think the answer is B"}],"timestamp":"1653108960.0"},{"content":"Selected Answer: D\nD is a fast and simple way to see if leaked credentials were accessed.","timestamp":"1650981540.0","comment_id":"592489","upvote_count":"3","poster":"mongiam"},{"comment_id":"568599","upvote_count":"2","timestamp":"1647370260.0","poster":"ceros399","content":"Selected Answer: D\nD - is the ans"},{"content":"Selected Answer: D\nD is the fastest and simplest way to see when it was last used , \nsince it was deactivated as soon as it was reported, all you need is to see if the use time is later then the commit time.","comment_id":"547880","timestamp":"1644943080.0","upvote_count":"2","poster":"MoreOps"},{"timestamp":"1643377200.0","comment_id":"534732","upvote_count":"3","poster":"AliS2020","content":"D is correct \n\naccess_key_1_last_used_region\nThe AWS Region in which the access key was most recently used. When an access key is used more than once in a 15-minute span, only the first use is recorded in this field.\n\nThe value in this field is N/A (not applicable) in these cases:\n\nThe user does not have an access key.\n\nThe access key has never been used.\n\nThe access key was last used before IAM started tracking this information on April 22, 2015.\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html\nThe last used service is not Region-specific, such as Amazon S3."},{"poster":"argol","upvote_count":"3","comment_id":"518997","timestamp":"1641563940.0","content":"\"D\" is right\nGetCredentialReport"},{"comment_id":"517776","timestamp":"1641412800.0","upvote_count":"1","poster":"ddm123","content":"Answer is D\nFor those thinking about A - Bear in mind that TrustAdvisor can just notify you if your key is exposed and also check for existence of IAM user to discourage root access \nhttps://docs.aws.amazon.com/awssupport/latest/user/trusted-advisor-check-reference.html#exposed-access-keys"}],"answer_description":"","isMC":true,"answer_images":[],"answer":"D","question_text":"A company maintains an open-source application that is hosted on a public GitHub repository. While creating a new commit to the repository, an engineer uploaded their AWS access key and secret access keys. The engineer reported the mistake to a manager, and the manager immediately disabled the access key.\nThe company needs to assess the impact of the exposed access key. A security engineer must recommend a solution that requires the least possible managerial overhead.\nWhich solution meets these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/69547-exam-aws-certified-security-specialty-topic-1-question-290/","question_id":213,"topic":"1","question_images":[],"choices":{"D":"Analyze a credential report in AWS Identity and Access Management (IAM) to see when the access key was last used.","C":"Analyze VPC flow logs for activity by searching for the access key.","B":"Analyze Amazon CloudWatch Logs for activity by searching for the access key.","A":"Analyze an AWS Identity and Access Management (IAM) use report from AWS Trusted Advisor to see when the access key was last used."}},{"id":"ZZ9JYLYInxxtccGbxyNO","choices":{"A":"A customer managed CMK that uses customer provided key material","C":"An AWS managed CMK","D":"Operation system-native encryption that uses GnuPG","B":"A customer managed CMK that uses AWS provided key material"},"question_text":"A security engineer must use AWS Key Management Service (AWS KMS) to design a key management solution for a set of Amazon Elastic Block Store (Amazon\nEBS) volumes that contain sensitive data. The solution needs to ensure that the key material automatically expires in 90 days.\nWhich solution meets these criteria?","exam_id":29,"answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/69148-exam-aws-certified-security-specialty-topic-1-question-291/","timestamp":"2021-12-31 18:45:00","unix_timestamp":1640972700,"topic":"1","discussion":[{"poster":"TigerInTheCloud","content":"Selected Answer: A\nhttps://awscli.amazonaws.com/v2/documentation/api/latest/reference/kms/import-key-material.html\n\naws kms import-key-material \\\n --key-id 1234abcd-12ab-34cd-56ef-1234567890ab \\\n --encrypted-key-material fileb://EncryptedKeyMaterial.bin \\\n --import-token fileb://ImportToken.bin \\\n --expiration-model KEY_MATERIAL_EXPIRES \\\n --valid-to 2021-09-21T19:00:00Z","upvote_count":"5","timestamp":"1649946900.0","comment_id":"585836"},{"upvote_count":"1","content":"Selected Answer: A\nCorrect answer is A.\nYou can select your KMS key with imported key material expiration date.\nhttps://docs.aws.amazon.com/kms/latest/developerguide/importing-keys-managing.html","poster":"Raphaello","timestamp":"1708550100.0","comment_id":"1155857"},{"comment_id":"764507","poster":"jishrajesh","upvote_count":"4","timestamp":"1672744320.0","content":"Selected A"},{"content":"B, A requires manual rotation","upvote_count":"1","timestamp":"1671504960.0","poster":"[Removed]","comment_id":"750429"},{"poster":"vikaswalajay","timestamp":"1664408940.0","content":"Not A\nManual rotation is a good choice when you want to control the key rotation schedule. It also provides a way to rotate KMS keys that are not eligible for automatic key rotation, including asymmetric KMS keys, HMAC KMS keys, KMS keys in custom key stores, and KMS keys with imported key material.","upvote_count":"1","comment_id":"682209"},{"content":"Selected Answer: A\nI agree on option A - KMS CMK","poster":"dcasabona","upvote_count":"1","timestamp":"1659116280.0","comment_id":"639343"},{"poster":"sapien45","content":"Selected Answer: A\nJust did it with external key material. Expiration option available on the last screen","timestamp":"1658162280.0","comment_id":"633091","upvote_count":"3"},{"upvote_count":"1","comment_id":"533377","poster":"Radhaghosh","timestamp":"1643244480.0","content":"Key Rotation 90 days --> It has to be Customer Managed Key with Imported Key Material. \nOption A"},{"timestamp":"1642389300.0","content":"answer A. \ngo to AWS KMS console and try to configure AWS CMK with external key. The option to set expiration date is available at the end of last step where the key is uploaded to CMK.","comment_id":"525429","poster":"sam_live","upvote_count":"4"},{"upvote_count":"2","comment_id":"521051","poster":"LearnMeSomeAWS","timestamp":"1641840780.0","content":"\"A\"- adjusting expire dates can only be oone with imported key material, not AWS provided. From the link below \"When you import key material, you can optionally specify a time at which the key material expires. When the key material expires, AWS KMS deletes the key material and the KMS key becomes unusable. To use the KMS key again, you must reimport key material.\""},{"timestamp":"1641268140.0","content":"A......... https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys-import-key-material.html","upvote_count":"2","poster":"babaseun","comment_id":"516218"},{"comment_id":"514180","upvote_count":"2","content":"A..........","timestamp":"1640972700.0","poster":"roger8978"}],"question_id":214,"answer":"A","isMC":true,"question_images":[],"answer_images":[],"answer_description":"","answer_ET":"A"},{"id":"b2gP0o2CZBeaishZnjoe","question_text":"A company uses a third-party identity provider and SAML-based SSO for its AWS accounts. After the third-party identity provider renewed an expired signing certificate, users saw the following message when trying to log in:\n//IMG//\n\nA security engineer needs to provide a solution that corrects the error and minimizes operational overhead.\nWhich solution meets these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/69166-exam-aws-certified-security-specialty-topic-1-question-292/","answer_ET":"C","answer_images":[],"unix_timestamp":1640996940,"discussion":[{"timestamp":"1640996940.0","upvote_count":"17","comment_id":"514283","content":"Error: Response signature invalid (service: AWSSecurityTokenService; status code: 400; error code: InvalidIdentityToken)\n========================================================\n\nThis error can occur when federation metadata of the identity provider does not match the metadata of the IAM identity provider. For example, the metadata file for the identity service provider might have changed to update an expired certificate. Download the updated SAML metadata file from your identity service provider. Then update it in the AWS identity provider entity that you define in IAM with the aws iam update-saml-provider cross-platform CLI command or the Update-IAMSAMLProvider PowerShell cmdlet.\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_saml.html#troubleshoot_saml_invalid-metadata\n\nAnswer: C","poster":"khamrumunnu"},{"content":"Selected Answer: C\nDownload the updated SAML metadata file from your identity service provider, then update it in AWS.","comment_id":"1155862","timestamp":"1708550460.0","poster":"Raphaello","upvote_count":"1"},{"comment_id":"731075","upvote_count":"2","content":"Selected Answer: C\nAnswer C\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_saml.html#troubleshoot_saml_invalid-metadata","timestamp":"1669781460.0","poster":"D2"},{"timestamp":"1652712780.0","poster":"ShortRound","comment_id":"602628","content":"Selected Answer: C\nmost def C","upvote_count":"1"},{"upvote_count":"1","poster":"Radhaghosh","comment_id":"533467","content":"This error can occur when federation metadata of the identity provider does not match the metadata of the IAM identity provider. \nOption C is correct","timestamp":"1643253480.0"},{"poster":"babaseun","comment_id":"516225","timestamp":"1641269220.0","upvote_count":"2","content":"C ..... https://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_saml.html#:~:text=browser%20for%20troubleshooting.-,Error%3A%20Response%20signature%20invalid%20(service%3A%20AWSSecurityTokenService%3B%20status%20code%3A%20400%3B%20error%20code%3A%20InvalidIdentityToken),-This%20error%20can"}],"timestamp":"2022-01-01 01:29:00","answers_community":["C (100%)"],"question_id":215,"exam_id":29,"choices":{"C":"Download the updated SAML metadata file from the identity service provider. Update the file in the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS CLI.","B":"Sign the identity provider's metadata file with the new public key. Upload the signature to the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS CLI.","D":"Configure the AWS identity provider entity defined in AWS Identity and Access Management (IAM) to synchronously fetch the new public key by using the AWS Management Console.","A":"Upload the third-party signing certificate's new private key to the AWS identity provider entity defined in AWS Identity and Access Management (IAM) by using the AWS Management Console."},"topic":"1","answer":"C","answer_description":"","isMC":true,"question_images":["https://www.examtopics.com/assets/media/exam-media/04239/0019300001.png"]}],"exam":{"isBeta":false,"isImplemented":true,"provider":"Amazon","isMCOnly":false,"id":29,"lastUpdated":"11 Apr 2025","name":"AWS Certified Security - Specialty","numberOfQuestions":509},"currentPage":43},"__N_SSP":true}