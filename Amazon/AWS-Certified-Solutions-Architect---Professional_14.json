{"pageProps":{"questions":[{"id":"sqKS9RpdkLrsbk0q6xT7","choices":{"C":"Take hourly DB backups to EC2 Instance store volumes with transaction logs stored In S3 every 5 minutes.","A":"Take hourly DB backups to S3, with transaction logs stored in S3 every 5 minutes.","D":"Take 15 minute DB backups stored In Glacier with transaction logs stored in S3 every 5 minutes.","B":"Use synchronous database master-slave replication between two availability zones."},"answer_ET":"A","exam_id":32,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/5789-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"comment_id":"175414","timestamp":"1634438640.0","content":"The only answer we can be assured of working is A. \nB doesn't help for data corruption (question doesn't specify physical or logical so have to address both) as logical corruption will be replicated.\nC. We don't put backups on ephemeral storage.\nD. Glacier Standard retrieval is 3-5 hours, and whilst expedited can be used to retrieve within 5 minutes, this is only for archives up to 250MB - the question doesn't give the size of the database, so I think we should not choose this option.","comments":[{"upvote_count":"2","timestamp":"1635830280.0","content":"Nicely explained.","comment_id":"329051","poster":"01037"},{"comment_id":"1126446","content":"@soksy \nFor the RPO being 15min how will answer A the hourly backups meet the requirement","poster":"Emmanuel23","upvote_count":"1","timestamp":"1705642200.0"}],"poster":"soksy","upvote_count":"19"},{"content":"A.. coz RDS backup or snapshot is written to S3.. If automatically backup, transaction logs are also being backup in 5 mins interval to S3.","poster":"skywalker","timestamp":"1632373620.0","upvote_count":"11","comment_id":"18752"},{"poster":"NeuralN","timestamp":"1733118660.0","content":"Selected Answer: D\nD is clearly the most correct choice, but none of these solutions are optimal given the information. \n\nA does not backup often enough to meet the RPO of 15 minutes. It is otherwise a reasonable answer. \nB does not provide point-in-time restoration of data corruption. Will not work. \nC is hourly backups again, which does not meet RPO. Also, backups on ephemeral storage? \nD meets RPO, but is possibly slow because Glacier. We don't know if it will meet RTO, but we do know it will meet RPO and nothing else will, so we have to choose it even though it'd make more sense to store in S3 standard and setup a retention policy to move to glacier or discard.","upvote_count":"1","comment_id":"1320798"},{"comment_id":"1289027","poster":"Chinta","upvote_count":"2","timestamp":"1727271720.0","content":"B is the correct one"},{"timestamp":"1723722120.0","poster":"amministrazione","comment_id":"1266404","content":"A. Take hourly DB backups to S3, with transaction logs stored in S3 every 5 minutes.","upvote_count":"1"},{"poster":"QasimAWS","comment_id":"1206406","upvote_count":"2","timestamp":"1714813140.0","content":"I would go with the Option B. \nthe Option A & C states \"Take Hourly Backup\" which will exceed the RPO requirement. they just wanna lose the data for 15 minutes not more than that. \nThe option D is also a good solution according to the scenario but saving the backup in glacier would also exceed the RTO requirements."},{"upvote_count":"1","comment_id":"1197206","timestamp":"1713354840.0","poster":"vip2","content":"Selected Answer: D\nRPO for backup and RTO for restore\nSo D is correct"},{"comment_id":"1128845","content":"Selected Answer: A\nD is using Glacier.. 15 min RPO VS 3-5 hours retrieval from Glacier.. ? Should be A","poster":"AimarLeo","upvote_count":"1","timestamp":"1705938360.0"},{"content":"Selected Answer: D\na) hourly back up does not meet RPO 0f 15 minutes\nd) glacier takes longer time to retreive, this satisfies RPO","poster":"nideesh","upvote_count":"1","timestamp":"1701323400.0","comment_id":"1084021"},{"comment_id":"927065","poster":"SkyZeroZx","content":"Selected Answer: A\nA - Best Answer: Meets the requirement and is more cost effective than B\nB - If corrupted data is replicated is wrong this answer\nC - We cannot backup to an instance store volume. Instance store volumes are ephemeral (temporary)\nD - Won't meet the RTO, because Glacier's standard retrieval time is typically within 3 to 5 hours","timestamp":"1687143060.0","upvote_count":"1"},{"content":"A - Best Answer: Meets the requirement and is more cost effective than B\nB - If corrupted data is replicated is wrong this answer\nC - We cannot backup to an instance store volume. Instance store volumes are ephemeral (temporary)\nD - Won't meet the RTO, because Glacier's standard retrieval time is typically within 3 to 5 hours","timestamp":"1686336660.0","comment_id":"919571","poster":"SkyZeroZx","upvote_count":"1"},{"content":"A - doesn't fit RTO (hourly backups) whereas we need 15 minute backups.\nB - replication will not help in case of data errors, plus, it's expensive, considering RPO, RTO\nC - could work, but Instance store volume aren't scalable, - bad solution\nD - could work, however RTO must be less than 3 hours, only with Glacier Expedite retrieval. Glacier Standard would fail as it's typically 3-5 hours, which doesn't fit the requirements.","timestamp":"1686123240.0","poster":"kondratyevmn","upvote_count":"1","comment_id":"916979"},{"poster":"sjpd10","timestamp":"1666864980.0","content":"A works","comment_id":"705418","upvote_count":"1"},{"upvote_count":"2","timestamp":"1645070520.0","content":"If we are at 10:30am, that would mean that incident occured at 8am. Based on the backup schedule, we will be restoring from the 7am backup and have transaction logs upto 9:55am. Therefore total amount of data loss, will be 5 minutes, satisfying the RPO of 15 min and the RTO. So my answer would be A.","poster":"jyrajan69","comment_id":"549145"},{"content":"A. Take hourly DB backups to S3, with transaction logs stored in S3 every 5 minutes.","timestamp":"1638938040.0","upvote_count":"1","poster":"cldy","comment_id":"496527"},{"content":"A Correct","comment_id":"405792","upvote_count":"1","poster":"Akhil254","timestamp":"1636278060.0"},{"upvote_count":"1","content":"With A , I will not be able to meet the RPO requirement. if we use the S3 backup 2 hours back to restore the DB, the RPO will be 30 minutes from the moment it was corrupted. Transaction logs cannot be used to restore a database . So the answer is D .","poster":"santhoshmp","comment_id":"380396","timestamp":"1636195980.0"},{"timestamp":"1636150440.0","content":"Just want to ask how can RDS backup at hourly interval? I can only find daily, weekly and monthly.","upvote_count":"1","poster":"kuroro","comment_id":"363353"},{"content":"A.\nwhile D can also work but backup every 15 mins doesn't seem like real ... so A satisfies the requirement.","upvote_count":"1","comment_id":"323079","timestamp":"1635667500.0","poster":"cldy"},{"timestamp":"1635624540.0","poster":"eji","content":"D is correct because now you can retrieve from glacier much faster but it cost additional charge. so you can still meet the RTO","upvote_count":"2","comment_id":"319675"},{"timestamp":"1635270120.0","comment_id":"312602","content":"Only one option is correct and that is A :)","poster":"ExtHo","upvote_count":"1"},{"poster":"Madwyn","comment_id":"293713","timestamp":"1635196860.0","upvote_count":"2","content":"D is incorrect. When recover the DB, you won't need old backups from 90 days ago, it doesn't make sense to commit such a long retention period. Glacier Expedited can reduce the retrieval time to 1-5 minutes, but the retention made it no longer economical, imagine the total amount of data stored on Glacier for 90 days compared to most recent 24 hours data on S3, big cost difference."},{"comment_id":"267771","upvote_count":"3","poster":"rusll","timestamp":"1635077940.0","content":"D. this is the only option that will satisfy both the rpo and the rto constraints, sure it will cost a lot of money, and sure its not ideal (standard-ia is better adapted for backups), but its the only feasible solution proposed."},{"comments":[{"comment_id":"198886","timestamp":"1634944260.0","poster":"iamgk","upvote_count":"3","content":"because transaction logs are stored every 5 mins , means RPO will be less than 15 mins."}],"upvote_count":"1","content":"Still can't understand why option A can meet the 15 min RPO requirement. Anyone can explain?","comment_id":"193393","timestamp":"1634932860.0","poster":"hkwong"},{"upvote_count":"2","comment_id":"193347","timestamp":"1634664660.0","content":"I vote for D","poster":"deejiw"},{"content":"I Think A","poster":"srknbngl","comment_id":"190100","upvote_count":"1","timestamp":"1634538000.0"},{"upvote_count":"1","timestamp":"1634236380.0","poster":"7thGuest","content":"A - Best Answer: Meets the requirement and is more cost effective than B\nB - Second Best: Meets the requirement but is more expensive\nC - We cannot backup to an instance store volume. Instance store volumes are ephemeral (temporary)\nD - Won't meet the RTO, because Glacier's standard retrieval time is typically within 3 to 5 hours","comments":[{"comment_id":"163034","timestamp":"1634383680.0","upvote_count":"1","content":"I disagree with B. What happen on master happen on slave. If you take 1h and half to see that data is corrupted, it is corrupted on slave too. No backup on S3, no transaction logs, B is not really helping.","poster":"CDV_fr"},{"timestamp":"1634401860.0","comment_id":"170678","upvote_count":"2","poster":"JoshEversman","content":"with A option, if there is already 50 mins since last backup and now disaster occurs, how will you go to 15 min RPO, D appears to be option, as with expedited request in glacier, you can retrieve data in 1-5 mins."}],"comment_id":"150013"},{"content":"A is correct","upvote_count":"2","comment_id":"143246","poster":"fullaws","timestamp":"1634002860.0"},{"comments":[{"comments":[{"poster":"JAWS1600","upvote_count":"1","timestamp":"1633879140.0","content":"Sorry I meant A is the right answer - Hourly backup","comment_id":"104955"}],"timestamp":"1633793580.0","comment_id":"104954","content":"D is the right answer.","poster":"JAWS1600","upvote_count":"1"}],"timestamp":"1633708680.0","poster":"JAWS1600","comment_id":"100451","upvote_count":"2","content":"Db backup every 15 minutes? Is it in real? Even if backup takes 5 minutes to finish. We are going to degrade the performance of DB , 20 minutes every hour. More over Backup may not finish in 15 minutes. We need 1 hour for back. This is my logic. However question has a clue \"1.5 hours\". It has to mean something which can let us decide between A and D more clearly"},{"content":"Answer is A.","poster":"SadioMane","timestamp":"1633544820.0","upvote_count":"5","comment_id":"56473"},{"content":"sorry, I take that back the application is already is multi AZ. D is correct","upvote_count":"1","poster":"Gorha","comment_id":"53905","timestamp":"1633375500.0"},{"comments":[{"content":"Data corruption that could occurs on Master will occurs on Slave for sure","upvote_count":"3","poster":"CDV_fr","timestamp":"1634271780.0","comment_id":"163033"}],"poster":"Gorha","timestamp":"1633265820.0","comment_id":"53895","content":"B also is visible, why not enabling multi AZ data replication?","upvote_count":"3"},{"timestamp":"1633242480.0","poster":"Gorha","comment_id":"51337","upvote_count":"1","content":"A is wrong as we don't know if the database is RDS or not. It will work if its RDS.\nD is correct, as mentioned Glacier supports retrieval in minutes now.","comments":[{"content":"No, I think S3 would be more appropriate than Glacier for a D.R. even with new Glacier features ...\nSo, I also vote for A as being an async. replication.","comment_id":"54084","timestamp":"1633461240.0","upvote_count":"1","poster":"virtual"}]},{"content":"I Think A","poster":"BillyC","comment_id":"49633","upvote_count":"5","timestamp":"1633185900.0"},{"comments":[{"timestamp":"1633613400.0","comment_id":"65724","upvote_count":"5","comments":[{"content":"90 days isn't necessary.","poster":"01037","upvote_count":"1","timestamp":"1635849480.0","comment_id":"329053"}],"poster":"Smart","content":"There is a 90-day minimum storage requirement. Not quite cost-effective in my opinion."},{"poster":"CDV_fr","timestamp":"1634252400.0","upvote_count":"1","comment_id":"163032","content":"Could be but the problem is that this time, even if it is minutes, is 100% lost. You only have 3h to build back your data and some DB restore can take hours."}],"timestamp":"1632722100.0","content":"I think, Answer is D. Now Glacier can be configured to retrive data from minutes to hours. More over RPO required is 15 minutes, which decides the back up strategy.","upvote_count":"2","comment_id":"48772","poster":"venkatt"},{"comment_id":"36351","upvote_count":"3","timestamp":"1632473160.0","poster":"amog","content":"Answer is A\nReplication is asynchronous"},{"content":"D is wrong because it would take 3 to 5 hour to retrieve file from Glacier, which does not meet RTO","timestamp":"1632407400.0","poster":"Danao","upvote_count":"5","comment_id":"26731"},{"comments":[{"poster":"xueyue2","content":"I don't think A will work, take hourly backup means \"Recovery Point Objective (RPO) of 15 minutes\" will be break in a disaster situation.","upvote_count":"2","timestamp":"1633707720.0","comment_id":"70532"}],"comment_id":"12975","poster":"Ming","content":"Why the answer is A?","timestamp":"1632318000.0","upvote_count":"1"},{"comments":[{"comment_id":"314384","poster":"nitinz","upvote_count":"1","timestamp":"1635460200.0","comments":[{"upvote_count":"1","poster":"nitinz","content":"WELL C IS NO GOOD, WE ARE SCREWED IF EC2 IS GONE. D IS NOT THE BEST BUT WILL DO THE TRICK.","timestamp":"1635502080.0","comment_id":"314387"}],"content":"Answer is C\n\nA. Take hourly DB backups to S3, with transaction logs stored in S3 every 5 minutes. CAN NOT MAKE SLA FOR RTO AND RPO\nB. Use synchronous database master-slave replication between two availability zones. WELL DAMAGE IS DONE ON BOTH SIDES... BOTH NODES HAVE CORRUPTED DATA.\nC. Take hourly DB backups to EC2 Instance store volumes with transaction logs stored In S3 every 5 minutes. POSSIBLE.\nD. Take 15 minute DB backups stored In Glacier with transaction logs stored in S3 every 5 minutes. VERY NICE ONLY PROBLEM IS GLACIER WILL TAKE AGES TO RECOVER."}],"content":"Why the anser is C?","timestamp":"1632181440.0","upvote_count":"1","poster":"Ming","comment_id":"12974"}],"isMC":true,"answer_description":"","answer":"D","question_text":"An ERP application is deployed across multiple AZs in a single region. In the event of failure, the Recovery Time Objective (RTO) must be less than 3 hours, and the Recovery Point Objective (RPO) must be 15 minutes. The customer realizes that data corruption occurred roughly 1.5 hours ago.\nWhat DR strategy could be used to achieve this RTO and RPO in the event of this kind of failure?","unix_timestamp":1569630480,"answers_community":["D (60%)","A (40%)"],"timestamp":"2019-09-28 02:28:00","question_id":66,"answer_images":[],"question_images":[]},{"id":"grx2M5aDAmVmJYy90M6O","answer_ET":"B","topic":"1","isMC":true,"choices":{"B":"Setup a public and two private subnets in different AZs within a VPC and create a subnet group. Launch RDS with that subnet group.","D":"Create two separate VPCs and launch a Web app in one VPC and RDS in a separate VPC and connect them with VPC peering.","A":"Create a VPC with one public and one private subnet. Launch an application instance in the public subnet while RDS is launched in the private subnet.","C":"Create a network interface and attach two subnets to it. Attach that network interface with RDS while launching a DB instance."},"timestamp":"2021-05-20 02:30:00","question_text":"MapMySite is setting up a web application in the AWS VPC. The organization has decided to use an AWS RDS instead of using its own DB instance for HA and\nDR requirements.\nThe organization also wants to secure RDS access.\nHow should the web application be setup with RDS?","answers_community":["B (100%)"],"exam_id":32,"question_id":67,"unix_timestamp":1621470600,"answer_images":[],"question_images":[],"answer_description":"A Virtual Private Cloud (VPC) is a virtual network dedicated to the user's AWS account. It enables the user to launch AWS resources, such as RDS into a virtual network that the user has defined. Subnets are segments of a VPC's IP address range that the user can designate to a group of VPC resources based on the security and operational needs.\nA DB subnet group is a collection of subnets (generally private) that a user can create in a VPC and assign to the RDS DB instances. A DB subnet group allows the user to specify a particular VPC when creating the DB instances. Each DB subnet group should have subnets in at least two Availability Zones in a given region.\nReference:\nhttp://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.html","url":"https://www.examtopics.com/discussions/amazon/view/53151-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"upvote_count":"1","timestamp":"1723812060.0","comment_id":"1267071","content":"B. Setup a public and two private subnets in different AZs within a VPC and create a subnet group. Launch RDS with that subnet group.","poster":"amministrazione"},{"content":"Selected Answer: B\nDB instance for HA and DR requirements.\nB - is correct.","poster":"SkyZeroZx","upvote_count":"2","timestamp":"1686621780.0","comment_id":"921872"},{"content":"DB instance for HA and DR requirements.\nB - is correct.","comment_id":"658968","timestamp":"1662269340.0","poster":"ggrodskiy","upvote_count":"1"},{"comment_id":"643298","content":"answering that qstn from a security angle i wld go for A","upvote_count":"1","poster":"gondohwe","timestamp":"1659780480.0"},{"comment_id":"531759","timestamp":"1643073540.0","upvote_count":"3","poster":"RVivek","content":"B. Each DB subnet group should have subnets in at least two Availability Zones in a given AWS Region. When creating a DB instance in a VPC, you must choose a DB subnet group \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html\n\nA- is in correct . After you create a subnet group how do you choose private subnet to deploy RDS"},{"comment_id":"494920","content":"B. Setup a public and two private subnets in different AZs within a VPC and create a subnet group. Launch RDS with that subnet group.","poster":"cldy","timestamp":"1638768540.0","upvote_count":"4"},{"comment_id":"434700","content":"B: reason: DB subnet group is a collection of subnets (generally private) that a user can create in a VPC and assign to the RDS DB instances. A DB subnet group allows the user to specify a particular VPC when creating the DB instances. Each DB subnet group should have subnets in at least two AZs in a given region.","poster":"sergioandreslq","upvote_count":"1","timestamp":"1635832260.0"},{"comment_id":"424987","upvote_count":"1","poster":"FERIN_01","timestamp":"1635650160.0","content":"A subnet group is a collection of subnets (typically private) that you can designate for your clusters running in an Amazon Virtual Private Cloud (VPC) environment. ... ElastiCache uses that subnet group to choose a subnet and IP addresses within that subnet to associate with your nodes."},{"comment_id":"408097","content":"those old questions are impossible, the formulation is very poor and you are always wondering if it's a voluntary mistake or not: it's not testing knowlege but how yo interpret a sh***y question.In real life you'd ask your client to rephrase to clear things out. I agree A or B depending on how you want to read the question concerning the presence of the public subnet in the subnet group.","poster":"robertomartinez","timestamp":"1635494160.0","upvote_count":"3"},{"poster":"01037","upvote_count":"4","timestamp":"1632462660.0","content":"B? is the public subnet is also in RDS subnet group?\nThen RDS instance may exist in the public subnet?","comment_id":"373571","comments":[{"upvote_count":"1","poster":"bamjive06","content":"I see where you're going with this. So whats your answer then? If they didnt mention HA, I'd have picked A. So B sounds OK - RDS part of private ofcoz...\nSarcasm maybe ;)","comments":[{"content":"A\nThe subnets in a DB subnet group are either public or private. They can't be a mix of both public and private subnets.\nSo B is ruled out","timestamp":"1633324260.0","poster":"DashL","upvote_count":"1","comment_id":"388241"}],"comment_id":"382207","timestamp":"1632970860.0"}]},{"timestamp":"1632441540.0","upvote_count":"2","comment_id":"361743","poster":"viet1991","content":"B. Setup a public and two private subnets in different AZs within a VPC and create a subnet group. Launch RDS with that subnet group."}],"answer":"B"},{"id":"HphNHHqt1V1ExXwxHRzC","answers_community":["D (100%)"],"answer_description":"Compute resources will be provisioned by AWS Data Pipeline when the first activity for a scheduled time that uses those resources is ready to run, and those instances will be terminated when the final activity that uses the resources has completed successfully or failed.\nReference:\nhttps://aws.amazon.com/datapipeline/faqs/","discussion":[{"content":"D. When the final activity that uses the resources has completed successfully or failed","poster":"amministrazione","timestamp":"1723812120.0","upvote_count":"1","comment_id":"1267072"},{"comment_id":"922272","content":"Selected Answer: D\nD.\nWhen the final activity that uses the resources has completed successfully or failed\n\nExplanation:\nCompute resources will be provisioned by AWS Data Pipeline when the first activity for a\nscheduled time that uses those resources is ready to run, and those instances will be terminated\nwhen the final activity that uses the resources has completed successfully or failed.\nhttps://aws.amazon.com/datapipeline/faqs/","upvote_count":"1","poster":"SkyZeroZx","timestamp":"1686663960.0"},{"comment_id":"631116","upvote_count":"1","content":"go for D","timestamp":"1657763100.0","poster":"BrianPing"},{"upvote_count":"3","content":"D. When the final activity that uses the resources has completed successfully or failed","timestamp":"1638791820.0","comment_id":"495099","poster":"cldy"},{"poster":"backfringe","content":"I'd go with D","upvote_count":"1","comment_id":"488847","timestamp":"1638076260.0"},{"poster":"01037","content":"I don't really know\nBut D seems reasonable.","timestamp":"1635552360.0","upvote_count":"2","comment_id":"373587"},{"content":"D.\nWhen the final activity that uses the resources has completed successfully or failed\n\nExplanation:\nCompute resources will be provisioned by AWS Data Pipeline when the first activity for a\nscheduled time that uses those resources is ready to run, and those instances will be terminated\nwhen the final activity that uses the resources has completed successfully or failed.\nhttps://aws.amazon.com/datapipeline/faqs/","upvote_count":"1","timestamp":"1634935980.0","comment_id":"361757","poster":"viet1991"},{"comment_id":"55346","poster":"miracle","content":"Answer is D.","timestamp":"1634802540.0","upvote_count":"1"},{"comment_id":"34456","content":"100 GB... Reference: \"Effective immediately, you can provision new RDS database instances with 1,000 to 10,000 IOPS, and with 100GB to 1 TB of storage for MySQL and Oracle databases\"","timestamp":"1633502340.0","upvote_count":"1","poster":"shan75"}],"unix_timestamp":1577948280,"question_id":68,"url":"https://www.examtopics.com/discussions/amazon/view/11245-exam-aws-certified-solutions-architect-professional-topic-1/","question_text":"When does an AWS Data Pipeline terminate the AWS Data Pipeline-managed compute resources?","answer_images":[],"question_images":[],"choices":{"B":"When the final activity that uses the resources is running","A":"AWS Data Pipeline terminates AWS Data Pipeline-managed compute resources every 2 hours.","C":"AWS Data Pipeline terminates AWS Data Pipeline-managed compute resources every 12 hours.","D":"When the final activity that uses the resources has completed successfully or failed"},"topic":"1","timestamp":"2020-01-02 07:58:00","answer":"D","answer_ET":"D","isMC":true,"exam_id":32},{"id":"HWDXVhLd4foBJXtX2KCT","topic":"1","answer_ET":"B","question_text":"What bandwidths do AWS Direct Connect currently support?","answer":"B","discussion":[{"content":"Selected Answer: D\n1Gbps and 10 Gbps","timestamp":"1742184540.0","comment_id":"1399522","poster":"codeScalable","upvote_count":"1"},{"comment_id":"1267073","content":"B. 10Gbps and 100Gbps","upvote_count":"1","timestamp":"1723812180.0","poster":"amministrazione"},{"poster":"magnonobre","content":"Selected Answer: B\nAWS Direct Connect Announces Native 100 Gbps Dedicated Connections at Select Locations\nhttps://aws.amazon.com/pt/about-aws/whats-new/2021/02/aws-direct-connect-announces-native-100-gbps-connections-select-locations/","upvote_count":"4","comment_id":"885701","timestamp":"1682897160.0"},{"poster":"AnonymousJhb","content":"Selected Answer: D\nI think this question should be around port size and not speed. If so, then the answer is D. \n1Gbps and 10Gbps ports are available. \nSpeeds of 50Mbps, 100Mbps, 200Mbps, 300Mbps, 400Mbps, and 500Mbps can be ordered from any APN partners.","comment_id":"521704","timestamp":"1641926940.0","upvote_count":"1"},{"poster":"cldy","content":"D. 1Gbps and 10 Gbps","comment_id":"494215","upvote_count":"2","timestamp":"1638699240.0"},{"comment_id":"382211","timestamp":"1635427500.0","poster":"bamjive06","content":"Not getting too detailed with this, a Direct Connect (site2site) offers 1G/10/G/100G...but given this may be an old question, answer is D.","upvote_count":"2"},{"upvote_count":"2","poster":"viet1991","content":"D.\n---\nQ. What connection speeds are available?\n\nFor Dedicated Connections, 1Gbps, 10Gbps, and 100Gbps ports are available. For Hosted Connections, capacities of 50Mbps, 100Mbps, 200Mbps, 300Mbps, 400Mbps, 500Mbps, 1Gbps, 2Gbps, 5Gbps and 10Gbps may be ordered from approved AWS Direct Connect Partners. See AWS Direct Connect Partners for more information. \n\nhttps://aws.amazon.com/directconnect/faqs/#:~:text=What%20connection%20speeds%20are%20available,approved%20AWS%20Direct%20Connect%20Partners.","timestamp":"1634331240.0","comment_id":"361758","comments":[{"content":"According to this, BCE are all correct?","timestamp":"1634480760.0","comment_id":"373594","upvote_count":"1","poster":"01037","comments":[{"timestamp":"1635170280.0","poster":"01037","comment_id":"373595","upvote_count":"1","content":"It's BCD"}]}]},{"upvote_count":"2","content":"More accurately, both 1/10 Gbps are Dedicated Connections. However, as of today, Direct Connect has offered Hosted Connections that provide more granular bandwidth capacities for every client using.","timestamp":"1632738360.0","poster":"TerrenceC","comment_id":"212010"},{"timestamp":"1632335100.0","upvote_count":"1","comment_id":"55347","poster":"miracle","content":"Answer is D."}],"question_id":69,"timestamp":"2020-02-26 06:30:00","answer_images":[],"exam_id":32,"choices":{"C":"100Mbps and 1Gbps","B":"10Gbps and 100Gbps","A":"10Mbps and 100Mbps","D":"1Gbps and 10 Gbps"},"answers_community":["B (67%)","D (33%)"],"answer_description":"","unix_timestamp":1582695000,"isMC":true,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/14882-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"vImzwKQ5NP8tKRz9jnL6","answer_ET":"A","timestamp":"2020-02-26 06:46:00","isMC":true,"question_images":[],"topic":"1","answer_images":[],"question_id":70,"unix_timestamp":1582695960,"answer":"A","answer_description":"The element NotPrincipal that is included within your IAM policy statements allows you to specify an exception to a list of principals to whom the access to a specific resource is either allowed or denied. Use the NotPrincipal element to specify an exception to a list of principals. For example, you can deny access to all principals except the one named in the NotPrincipal element.\nReference:\nhttp://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements.html#Principal","discussion":[{"poster":"amministrazione","comment_id":"1267074","content":"A. NotPrincipal","timestamp":"1723812300.0","upvote_count":"1"},{"timestamp":"1683404100.0","poster":"CProgrammer","upvote_count":"1","comment_id":"890987","content":"again thats not english. thats not even a question"},{"timestamp":"1653740280.0","poster":"ravisar","upvote_count":"1","content":"I don't understand this question. \"while the denotes everyone except the specified entity\" - what does it mean? There is nothing in IAM policy about \"Vendor\"! I understand the purpose of principal in resource-based IAM policies.","comment_id":"608386"},{"upvote_count":"1","comment_id":"424992","content":"Use the NotPrincipal element to specify the IAM user, federated user, IAM role, AWS account, AWS service, or other principal that is not allowed or denied access to a resource. The NotPrincipal element enables you to specify an exception to a list of principals. Use this element to deny access to all principals except the one named in the NotPrincipal element. The syntax for specifying NotPrincipal is the same as for specifying AWS JSON policy elements: Principal.\n\nYou cannot use the NotPrincipal element in an IAM identity-based policy. You can use it in the trust policies for IAM roles and in resource-based policies. Resource-based policies are policies that you embed directly in an IAM resource.","poster":"FERIN_01","timestamp":"1635987240.0"},{"content":"Ok\nIt's A","poster":"01037","upvote_count":"1","comment_id":"374368","timestamp":"1635901980.0"},{"content":"Answer is A.","poster":"miracle","timestamp":"1634030340.0","comment_id":"55351","upvote_count":"3"}],"answers_community":[],"question_text":"The Principal element of an IAM policy refers to the specific entity that should be allowed or denied permission, whereas the translates to everyone except the specified entity.","exam_id":32,"url":"https://www.examtopics.com/discussions/amazon/view/14883-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"A":"NotPrincipal","D":"Action","B":"Vendor","C":"Principal"}}],"exam":{"isImplemented":true,"numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Professional","id":32,"isMCOnly":false,"isBeta":false,"provider":"Amazon","lastUpdated":"11 Apr 2025"},"currentPage":14},"__N_SSP":true}