{"pageProps":{"questions":[{"id":"IduDoNC9F5cfaShNEWAm","answer_images":[],"unix_timestamp":1650628980,"question_id":96,"exam_id":20,"discussion":[{"comment_id":"589962","content":"Selected Answer: A\nnear real-time dashboards -> operational => OpenSearch","upvote_count":"15","timestamp":"1650628980.0","poster":"rb39"},{"timestamp":"1667659920.0","content":"Selected Answer: A\nCorrect answer is A as Kinesis Data Firehose can ingest data to ElasticSearch and with Kibana it can provide near-real-time visualization.\n\nOption B is wrong as SageMaker Jupyter notebook does not provide near-realt0tie visualization, but it is more for data exploration.\n\nOption C is wrong as data with SPICE is cached and needs to be refreshed, so it does not provide near-real-time data.\n\nOption D is wrong as using SPICE and Glue does not provide near-real-time data.","comments":[{"timestamp":"1673799240.0","poster":"nadavw","comment_id":"776783","content":"The minimum refresh frequency of QucikSight is hourly (E. edition)\nhttps://docs.aws.amazon.com/quicksight/latest/user/refreshing-imported-data.html","upvote_count":"2"}],"poster":"cloudlearnerhere","upvote_count":"9","comment_id":"711828"},{"poster":"pk349","timestamp":"1682948640.0","upvote_count":"1","content":"A: I passed the test","comment_id":"886320"},{"timestamp":"1675354500.0","poster":"Gabba","content":"Selected Answer: A\nReal time dashboard is Kibana, so option A.","upvote_count":"1","comment_id":"796205"},{"comment_id":"691947","upvote_count":"1","poster":"rav009","timestamp":"1665479880.0","content":"Selected Answer: A\nA \ntextbox question"},{"poster":"Arka_01","timestamp":"1664083140.0","content":"Selected Answer: A\n\"The dashboard must support near-real-time data\" and \"time-sensitive\" are the keys here. OpenSearch and Kibana can only meet these requirements.","upvote_count":"1","comment_id":"678459"}],"answers_community":["A (100%)"],"answer_ET":"A","isMC":true,"question_images":[],"answer":"A","choices":{"B":"Select Amazon S3 as the endpoint for Kinesis Data Firehose. Read data into an Amazon SageMaker Jupyter notebook and carry out the desired analyses and visualizations.","C":"Select Amazon Redshift as the endpoint for Kinesis Data Firehose. Connect Amazon QuickSight with SPICE to Amazon Redshift to create the desired analyses and visualizations.","A":"Select Amazon OpenSearch Service (Amazon Elasticsearch Service) as the endpoint for Kinesis Data Firehose. Set up an OpenSearch Dashboards (Kibana) using the data in Amazon OpenSearch Service (Amazon ES) with the desired analyses and visualizations.","D":"Select Amazon S3 as the endpoint for Kinesis Data Firehose. Use AWS Glue to catalog the data and Amazon Athena to query it. Connect Amazon QuickSight with SPICE to Athena to create the desired analyses and visualizations."},"timestamp":"2022-04-22 14:03:00","url":"https://www.examtopics.com/discussions/amazon/view/74126-exam-aws-certified-data-analytics-specialty-topic-1-question/","question_text":"A technology company is creating a dashboard that will visualize and analyze time-sensitive data. The data will come in through Amazon Kinesis Data Firehose with the butter interval set to 60 seconds. The dashboard must support near-real-time data.\nWhich visualization solution will meet these requirements?","topic":"1","answer_description":""},{"id":"3bg2QH7IrAIcdTpM0rHq","question_id":97,"discussion":[{"comment_id":"384057","timestamp":"1635967920.0","comments":[{"poster":"lakediver","comment_id":"505837","content":"The following are two commonly used metrics for automatic scaling: \nYarnMemoryAvailablePercentage: This is the percentage of remaining memory that's available for YARN. \nContainerPendingRatio: This is the ratio of pending containers to allocated containers. You can use this metric to scale a cluster based on container-allocation behavior for varied loads. This is useful for performance tuning.","upvote_count":"3","timestamp":"1640065620.0"},{"upvote_count":"2","comment_id":"505836","poster":"lakediver","content":"Agree\nFor further reference see \nhttps://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-in-amazon-emr/","timestamp":"1640065560.0"}],"content":"Ans D\nA and B = wrong, instance fleet does not support auto scaling. C = wrong, HDFS utilization never exceeds 10% no scaling will never happen.","upvote_count":"23","poster":"Shraddha"},{"upvote_count":"7","timestamp":"1635700860.0","content":"D should be the right answer. Considering the following links: the first link is possible to see that the right metric to this requirement is YARNMemoryAvailablePercentage, because the HDFS never is over 10%. The second link explain that if you will use auto scaling so you should use instance group.\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/UsingEMR_ViewingMetrics.html\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html","comment_id":"360762","poster":"ariane_tateishi"},{"poster":"monkeydba","comment_id":"1067150","timestamp":"1699611060.0","content":"\"Managed scaling is available for clusters composed of either instance groups or instance fleets.\"\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-managed-scaling.html#:~:text=Managed%20scaling%20is%20available%20for%20clusters%20composed%20of%20either%20instance%20groups%20or%20instance%20fleets.","upvote_count":"1"},{"timestamp":"1682948700.0","comment_id":"886322","content":"D: I passed the test","upvote_count":"1","poster":"pk349"},{"timestamp":"1677084360.0","upvote_count":"1","poster":"srirnag","comment_id":"818065","content":"YARNMemoryAvailablePercentage-> is for CPU intensive workload, \nCapacityRemainingGB-> for Capacity intensive workload, \nInstance fleet is ruled out. Hence, D"},{"poster":"cloudlearnerhere","upvote_count":"4","comments":[{"timestamp":"1667660340.0","comment_id":"711839","upvote_count":"2","content":"CloudWatch metrics that you can use for automatic scaling in Amazon EMR, The following are two commonly used metrics for automatic scaling:\n\nYarnMemoryAvailablePercentage: This is the percentage of remaining memory that's available for YARN.\n\nContainerPendingRatio: This is the ratio of pending containers to allocated containers. You can use this metric to scale a cluster based on container-allocation behavior for varied loads. This is useful for performance tuning.\n\n\nFor the given use case, the correct solution should support automatic scaling. You can set up automatic scaling in Amazon EMR for an instance group, adding and removing instances automatically based on the value of an Amazon CloudWatch metric that you specify. The metric YARNMemoryAvailablePercentage represents the percentage of remaining memory available to YARN (YARNMemoryAvailablePercentage = MemoryAvailableMB / MemoryTotalMB). This value is useful for scaling cluster resources based on YARN memory usage.","poster":"cloudlearnerhere"}],"comment_id":"711837","timestamp":"1667660340.0","content":"Selected Answer: D\nCorrect answer is D as instance group configurations for core and task nodes can be used to scale as per the YARNMemoryAvailablePercentage metric.\n\noptions A & B are incorrect because an Instance Fleet doesn’t have an automatic scaling policy. Only an Instance Group has this feature.\n\nOption C is incorrect as the CapacityRemainingGB metric is just the amount of remaining HDFS disk capacity and this does not exceed 10% for each run. The cluster will not scale-in or scale-out if you choose this metric."},{"poster":"Arka_01","content":"Selected Answer: D\nInstance Fleet cannot take part in Auto-Scaling. CapacityRemainingGB is not the parameter to refer as \"(HDFS) utilization never exceeds 10%\". So the answer is D.","upvote_count":"1","timestamp":"1664083200.0","comment_id":"678460"},{"upvote_count":"1","comment_id":"637078","timestamp":"1658804280.0","content":"Selected Answer: D\nSelected Answer: D","poster":"rocky48"},{"poster":"Ramshizzle","content":"Answer should be D like others have said. However, I think it would be even better to use Instance fleets and EMR Managed auto scaling, but this is not an option here.","timestamp":"1656402960.0","upvote_count":"1","comment_id":"623830"},{"poster":"Bik000","comment_id":"604813","content":"Selected Answer: D\nAnswer is D","timestamp":"1653129900.0","upvote_count":"1"},{"poster":"jrheen","comment_id":"595320","upvote_count":"1","timestamp":"1651356660.0","content":"Answer-D"},{"timestamp":"1647776280.0","content":"D is the right answer.","poster":"ShilaP","upvote_count":"1","comment_id":"571570"},{"timestamp":"1637419440.0","poster":"aws2019","content":"Option D is the right choice.","upvote_count":"1","comment_id":"482626"},{"comment_id":"442334","content":"Ans D","timestamp":"1636098420.0","upvote_count":"1","poster":"Billhardy"},{"poster":"Naresh_Dulam","comment_id":"281610","content":"Answer is D over B. Because Spot instance fleet support \"managed\" auto scaling and managed auto scaling can't use Cloud watch metric like YARNMemoryAvailablePercentage. \nManaged auto scaling scaled depends load on the cluster.","timestamp":"1634914200.0","upvote_count":"4"},{"timestamp":"1634851620.0","comment_id":"274319","upvote_count":"1","poster":"lostsoul07","content":"D is the right answer"},{"comment_id":"216746","content":"D IS Correct for my","poster":"BillyC","timestamp":"1634775060.0","upvote_count":"3"},{"timestamp":"1634763600.0","upvote_count":"1","poster":"jack42","comment_id":"195016","content":"Its D, while we look for performance, we need more memory to run the container in parallel, if we go with option C, the cluster is not using disk HDFS more than 10% that means if you have two running nodes with more than 10% disk space then it will trigger the autoscale and resulting to run your cluster in single node. So for performance always we need more memory and CPU."},{"comment_id":"191594","upvote_count":"1","content":"If there is Apache Hive and EMR means it's about Hadoop so YARNMemoryAvailablePercentage metric would eliminate A and C\nFrom link: https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html\n\"Set up automatic scaling in Amazon EMR for an instance group, adding and removing instances automatically based on the value of an Amazon CloudWatch metric that you specify\"","timestamp":"1634715000.0","poster":"syu31svc"},{"poster":"KoMo","comment_id":"179180","timestamp":"1633592220.0","upvote_count":"3","content":"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html\nInstance Groups vs Instance Fleets"},{"upvote_count":"2","comment_id":"175548","timestamp":"1633571880.0","poster":"Paitan","content":"Option D is the right choice."},{"poster":"carol1522","comments":[{"upvote_count":"4","timestamp":"1633324980.0","content":"Also, you are right! The answer is D :)","poster":"awssp12345","comment_id":"165557"},{"content":"That is not entirely true, Instance fleets support EMR managed scaling where the customer cannot specify metrics like YARNMemoryAvailablePercentage to scale the cluster. So basically Instance fleets does not support custom Auto scaling! https://aws.amazon.com/blogs/big-data/introducing-amazon-emr-managed-scaling-automatically-resize-clusters-to-lower-cost/","timestamp":"1633296360.0","comment_id":"165556","poster":"awssp12345","upvote_count":"3"}],"content":"D because instance fleet dont have automatic scaling: https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-instance-group-configuration.html","comment_id":"161740","timestamp":"1633024920.0","upvote_count":"3"},{"poster":"Prodip","upvote_count":"1","content":"Will go with Option D. YARNMemoryAvailablePercentage value is useful for scaling cluster resources","comment_id":"154783","timestamp":"1632966540.0"},{"content":"It should be between B and D. The CapacityRemaining metric is for disk space which is not the problem as stated in the question (10% utilzation). You cannot mix instance and group, so to me would be option D. What do you think?","upvote_count":"3","poster":"testtaker3434","comment_id":"153579","timestamp":"1632626700.0"}],"unix_timestamp":1596974880,"exam_id":20,"isMC":true,"answer":"D","question_images":["https://www.examtopics.com/assets/media/exam-media/04144/0002200002.png"],"url":"https://www.examtopics.com/discussions/amazon/view/27702-exam-aws-certified-data-analytics-specialty-topic-1-question/","answer_images":[],"answer_ET":"D","question_text":"A financial company uses Apache Hive on Amazon EMR for ad-hoc queries. Users are complaining of sluggish performance.\nA data analyst notes the following:\n✑ Approximately 90% of queries are submitted 1 hour after the market opens.\nHadoop Distributed File System (HDFS) utilization never exceeds 10%.\n//IMG//\n\nWhich solution would help address the performance issues?","choices":{"A":"Create instance fleet configurations for core and task nodes. Create an automatic scaling policy to scale out the instance groups based on the Amazon CloudWatch CapacityRemainingGB metric. Create an automatic scaling policy to scale in the instance fleet based on the CloudWatch CapacityRemainingGB metric.","D":"Create instance group configurations for core and task nodes. Create an automatic scaling policy to scale out the instance groups based on the Amazon CloudWatch YARNMemoryAvailablePercentage metric. Create an automatic scaling policy to scale in the instance groups based on the CloudWatch YARNMemoryAvailablePercentage metric.","B":"Create instance fleet configurations for core and task nodes. Create an automatic scaling policy to scale out the instance groups based on the Amazon CloudWatch YARNMemoryAvailablePercentage metric. Create an automatic scaling policy to scale in the instance fleet based on the CloudWatch YARNMemoryAvailablePercentage metric.","C":"Create instance group configurations for core and task nodes. Create an automatic scaling policy to scale out the instance groups based on the Amazon CloudWatch CapacityRemainingGB metric. Create an automatic scaling policy to scale in the instance groups based on the CloudWatch CapacityRemainingGB metric."},"answer_description":"","topic":"1","answers_community":["D (100%)"],"timestamp":"2020-08-09 14:08:00"},{"id":"yTTZ5MQzAtM8W80BNipX","answers_community":["C (100%)"],"answer_description":"","answer_images":[],"timestamp":"2020-08-16 00:26:00","question_images":[],"exam_id":20,"topic":"1","discussion":[{"upvote_count":"28","content":"Option C.\nEMRFS consistent view tracks consistency using a DynamoDB table to track objects in Amazon S3 that have been synced with or created by EMRF. So increasing RCU for the shared DynamoDB table will help here.","comment_id":"175554","poster":"Paitan","timestamp":"1632689700.0"},{"comment_id":"158882","poster":"Priyanka_01","comments":[{"upvote_count":"1","comments":[{"comment_id":"392611","upvote_count":"3","content":"Your link is about DynamoDB as a data source and therefore unrelated to the question. The correct page is\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emrfs-metadata.html","timestamp":"1635854340.0","poster":"jueueuergen"}],"comment_id":"165575","poster":"awssp12345","timestamp":"1632298020.0","content":"Agreed https://docs.aws.amazon.com/emr/latest/ReleaseGuide/EMR_Hive_Optimizing.html"},{"timestamp":"1632452820.0","upvote_count":"2","content":"Since the question specifically says \"Amazon EMR clusters using the EMR File System\n(EMRFS) with consistent view enabled\" C makes most sense.","comment_id":"165576","poster":"awssp12345"}],"upvote_count":"13","content":"C any thoughts??\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emrfs-metadata.html","timestamp":"1632097740.0"},{"upvote_count":"2","comment_id":"939643","poster":"Debi_mishra","content":"Popular option C is actually wrong. Increasing RCU of dynamodb wont increase S3 list performance. Looks like there are too many tiny objects and its hitting S3 API limitations. A sounds more logical.","timestamp":"1688191980.0"},{"poster":"pk349","upvote_count":"1","timestamp":"1682948820.0","comment_id":"886324","content":"C: I passed the test"},{"content":"Answer is C.\nWhen consistent view is enabled, a dynamo db table is created and s3 object metadata is stored in this table. Whenever s3 listing is done, it reads data from dynamodb table.","poster":"anjuvinayan","upvote_count":"2","comment_id":"877036","timestamp":"1682140920.0"},{"upvote_count":"1","timestamp":"1677085200.0","content":"A is right. C is not right since DDB is not in picture.","comment_id":"818080","poster":"srirnag"},{"timestamp":"1676652240.0","poster":"Arjun777","content":"How is DynamoDB related to this question pls ? EMR Task node not able to lsit S3 directories and if a hash function to create a random string and add that to the beginning of the object prefixes when storing the log data in Amazon S3. This approach is known as \"sharding\" and can be an effective way to reduce the number of S3 requests required to retrieve log data. Therefore, option A is the most likely action to increase the performance of accessing log data in Amazon S3.","comment_id":"812130","upvote_count":"1"},{"comment_id":"729880","poster":"henom","timestamp":"1669692060.0","upvote_count":"6","content":"The answer is A. There is no limit to create prefix inside a bucket. To scale the read/write capacity from/to S3 bucket, the recommended approach is to have additional prefixes inside the bucket to enhance the read/write capacity. For example, your application can achieve at least 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket. There are no limits to the number of prefixes in a bucket.\n\nFor example, your application can achieve at least 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket. There are no limits to the number of prefixes in a bucket.\n\nYou can increase your read or write performance by parallelizing reads. For example, if you create 10 prefixes in an Amazon S3 bucket to parallelize reads, you could scale your read performance to 55,000 read requests per second."},{"upvote_count":"4","poster":"cloudlearnerhere","timestamp":"1667669400.0","comments":[{"upvote_count":"1","timestamp":"1667669400.0","comment_id":"711904","content":"Option A is wrong as for S3 list operation it's recommended to store metadata externally. S3 performance has been significantly improved and optimized as well.\n\nOption C is wrong as the S3 standard would not help increase the performance issue. It only increases availability and durability.\n\nOption D is wrong as it would not increase the S3 querying performance issue.","comments":[{"timestamp":"1670065080.0","content":"Is there a typo in your comment?","poster":"shubhary25","comment_id":"734360","upvote_count":"1"}],"poster":"cloudlearnerhere"}],"content":"Selected Answer: C\nCorrect answer is C as the current setup uses EMR and EMRFS with Consistent View enabled which is supported by DynamoDB for metadata. Increasing the DynamoDB RCUs should help increase performance.\n\nEMRFS consistent view tracks consistency using a DynamoDB table to track objects in Amazon S3 that have been synced with or created by EMRFS. The metadata is used to track all operations (read, write, update, and copy), and no actual content is stored in it. This metadata is used to validate whether the objects or metadata received from Amazon S3 matches what is expected. This confirmation gives EMRFS the ability to check list consistency and read-after-write consistency for new objects EMRFS writes to Amazon S3 or objects synced with EMRFS. Multiple clusters can share the same metadata.","comment_id":"711903"},{"timestamp":"1664490660.0","content":"------------------------------------------\nAnswer : A\nConfirmed by paid dumps","comments":[{"poster":"JoellaLi","upvote_count":"1","content":"but what is the reason of not C?","comment_id":"698268","timestamp":"1666100460.0"}],"comment_id":"683097","poster":"JHJHJHJHJ","upvote_count":"3"},{"comment_id":"682019","content":"my answer is A. https://aws.amazon.com/premiumsupport/knowledge-center/emr-s3-503-slow-down/","poster":"karanbhasin","upvote_count":"3","timestamp":"1664388840.0"},{"content":"The answer is A. There is no limit to create prefix inside a bucket. To scale the read/write capacity from/to S3 bucket, the recommended approach is to have additional prefixes inside the bucket to enhance the read/write capacity. For example, your application can achieve at least 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket. There are no limits to the number of prefixes in a bucket.\n\nFor example, your application can achieve at least 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket. There are no limits to the number of prefixes in a bucket.\n\nYou can increase your read or write performance by parallelizing reads. For example, if you create 10 prefixes in an Amazon S3 bucket to parallelize reads, you could scale your read performance to 55,000 read requests per second.","upvote_count":"1","comment_id":"671539","timestamp":"1663420380.0","poster":"somenath"},{"comment_id":"663710","upvote_count":"1","content":"Selected Answer: C\nThis looks like the correct answer","poster":"Arka_01","timestamp":"1662648600.0"},{"content":"Selected Answer: C\nAnswer is C.","timestamp":"1659818100.0","poster":"rocky48","upvote_count":"1","comment_id":"643523"},{"timestamp":"1653133200.0","comment_id":"604869","poster":"Bik000","content":"Selected Answer: C\nMy Answer is C","upvote_count":"1"},{"content":"Contrary to most suggestions here. The correct answer is D. As the S3 is in one availability zone, it is likely that the entire cluster is deployed in a different zone. So redeploying the cluster to a different AZ can solve the problem. And Question clearly mentions \"most likely\". IMO definitely D","upvote_count":"2","poster":"Balendu","comments":[{"content":"I dont think this is the case here. The problem is that listing the s3 bucket items is taking longer because of the increase in new jobs. If emr was in different AZ, you may not be able to list bucket items","upvote_count":"1","timestamp":"1648537080.0","comment_id":"577312","poster":"CHRIS12722222"}],"timestamp":"1636243140.0","comment_id":"450568"},{"upvote_count":"2","content":"I Think A. Applications running on Amazon S3 today will enjoy this performance improvement with no changes, and customers building new applications on S3 do not have to make any application customizations to achieve this performance. Amazon S3’s support for parallel requests means you can scale your S3 performance by the factor of your compute cluster, without making any customizations to your application. Performance scales per prefix, so you can use as many prefixes as you need in parallel to achieve the required throughput. There are no limits to the number of prefixes.","comment_id":"440859","poster":"Marcinha","timestamp":"1636111560.0"},{"content":"Ans C\n\nThe problem is about “to list objects in Amazon S3”. A is about S3 performance, B and D are irrelevant. The key is that consistent view uses a DynamoDB to track S3 files. There are many hidden uses of DynamoDB, e.g. Kinesis Client Library also uses a DynamoDB table to store the cursor and other metadata.\n\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emrfs-metadata.html","comment_id":"392179","timestamp":"1635806040.0","poster":"Shraddha","upvote_count":"4"},{"poster":"Donell","content":"Answer is C.\nTook a lot of time to confirm if its A or C, asked few AWS experts too.\nEMRFS consistent view tracks consistency using a DynamoDB table to track objects in Amazon S3 that have been synced with or created by EMRFS. The metadata is used to track all operations (read, write, update, and copy), and no actual content is stored in it. This metadata is used to validate whether the objects or metadata received from Amazon S3 matches what is expected. This confirmation gives EMRFS the ability to check list consistency and read-after-write consistency for new objects EMRFS writes to Amazon S3 or objects synced with EMRFS. Multiple clusters can share the same metadata.\n\nIt is possible to change the RCU as part of configurations using the CLI with parameter fs.s3.consistent.metadata.read.capacity (https://docs.aws.amazon.com/emr/latest/ManagementGuide/emrfs-configure-consistent-view.html). It appears that Option C is the right one. Also, Option A is suggesting using only one prefix (create a random string and add that to the beginning of the object prefixes) for all objects; so it is not correct.","timestamp":"1635343620.0","comment_id":"387040","upvote_count":"9"},{"comment_id":"373080","content":"AAAAAAAAAAAAAA","timestamp":"1635269160.0","upvote_count":"4","poster":"Dantehilary"},{"timestamp":"1635265020.0","content":"Correct answer C\nWith a consistent view EMRFS checks the metadata (DynamoDB) for information about the set of objects in consistent view ! for every Amazon S3 operation !. The problem has appeared after increasing number of jobs that means number of requests to DynamoDB. S3 performance was not impacted. The question is about performance change after running more queries. It is not a general question about ways to speed up EMR working with EMRFS.\nHow to know if metadata operations are being throttled?\nEMRFS sets default throughput capacity limits on the metadata for its read and write operations at 500 and 100 units, respectively. You can configure your own throughput capacity limits. However, DynamoDB has strict partition limits of 3000 read capacity units (RCUs) and 1000 write capacity units (WCUs) per second for read and write operations. To avoid sync failures caused by throttling, we recommend you limit throughput for read operations to fewer than 3000 RCUs and write operations to fewer than 1000 WCUs. For instructions on setting custom throughput capacity limits, see Configure Consistent View.","comment_id":"350698","upvote_count":"1","poster":"DerekKey"},{"poster":"KingD","content":"the problem here is reading data from S3 so how does increasing read capacity units for DynamoDB help here? The Final answer is A. for clarification, refer to the link below! \nhttps://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","timestamp":"1635145380.0","upvote_count":"1","comment_id":"323051"},{"poster":"Brijeshs","upvote_count":"1","comment_id":"290847","comments":[{"content":"It says \"taking longer to list items\". As my understanding, during listing items, it will read DynamoDB metadata to check the consistency.","comment_id":"599427","upvote_count":"1","poster":"MWL","timestamp":"1652163240.0"}],"content":"I think it should be A as Option C only talks about increasing RCU, NOT WCU. For DynamoDB throttling by EMRFS, we may need to increase WCU as well, thoughts?","timestamp":"1634983860.0"},{"poster":"imatowel","content":"`A data analyst has determined that it is taking longer for the EMR task nodes to list objects in Amazon S3` It's A for sure","comment_id":"284775","timestamp":"1634938680.0","upvote_count":"3"},{"poster":"lostsoul07","timestamp":"1634758200.0","upvote_count":"1","content":"C is the right answer","comment_id":"274320"},{"content":"Answer : C\n\nPlease refer : https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","poster":"Roontha","comment_id":"263540","upvote_count":"1","timestamp":"1634594460.0"},{"comment_id":"262849","upvote_count":"1","content":"After Reading this I prefer C as the Answer:\n\n\"EMRFS consistent view tracks consistency using a DynamoDB table to track objects in Amazon S3 that have been synced with or created by EMRFS. The metadata is used to track all operations (read, write, update, and copy), and no actual content is stored in it.\"","timestamp":"1633971420.0","poster":"kratos0551"},{"timestamp":"1633728360.0","upvote_count":"1","poster":"passtest100","content":"should be A:\nC does not works since the question asks to increas the retrieval direct from s3 rather than dynamodb, which RCU works for. \nFOR b: the s3-ia has the same latency as s3 standard. \nthe following links indicate the logic of option A:\nhttps://www.rapyder.com/blogs/amazon-s3-performance-optimisation/\n4. Structure data well for faster S3 operations\nLatency on S3 operations also depends on key names. If your workload against S3 is going to exceed 100 requests per second, prefix similarities will become a bottleneck. For high volume operations, naming schemes become relevant. As an example, more variability in initial characters of the key names allows even distribution across multiple index partitions.","comments":[{"upvote_count":"1","timestamp":"1633877580.0","comment_id":"247009","content":"The number of job increases, not files. And \"list objects\" takes longer time, not \"get file\". So C is correct","poster":"ricksun"},{"content":"As of a 7/17/2018 AWS announcement, hashing and random prefixing the S3 key is no longer required to see improved performance: https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","comment_id":"338523","timestamp":"1635187500.0","poster":"SuperSundra","upvote_count":"2"}],"comment_id":"217035"},{"content":"A is the only possible answer here. Changing AZ doesn't address performance issues, Dynamo is not mentioned in the question, IA S3 is only a billing issue not a performance one.","poster":"[Removed]","comments":[{"upvote_count":"1","comment_id":"224028","poster":"dduenas","timestamp":"1633867080.0","content":"EMRFS uses dynamo as background mechanism"}],"upvote_count":"1","comment_id":"216939","timestamp":"1633630980.0"},{"poster":"[Removed]","comment_id":"216931","upvote_count":"2","timestamp":"1633599720.0","content":"I don't see DynamoDB mentioned in the question...."},{"poster":"BillyC","timestamp":"1633476360.0","upvote_count":"1","comment_id":"216744","content":"C is my answer"},{"timestamp":"1633068780.0","comment_id":"191599","upvote_count":"1","comments":[{"poster":"syu31svc","content":"After reviewing the links given in this discussion, changing my answer to C","timestamp":"1633428060.0","comment_id":"194801","upvote_count":"1"}],"content":"B and D make no sense\nBetween A and C, I don't see how DynamoDB comes into the picture so I would go for A","poster":"syu31svc"},{"timestamp":"1632198720.0","upvote_count":"1","poster":"zeronine","comments":[{"upvote_count":"1","timestamp":"1632272700.0","comment_id":"161440","content":"Changing my answer to C","poster":"zeronine"}],"comment_id":"160740","content":"I think A."}],"question_id":98,"url":"https://www.examtopics.com/discussions/amazon/view/28681-exam-aws-certified-data-analytics-specialty-topic-1-question/","choices":{"D":"Redeploy the EMR clusters that are running slowly to a different Availability Zone.","B":"Use a lifecycle policy to change the S3 storage class to S3 Standard for the log data.","A":"Use a hash function to create a random string and add that to the beginning of the object prefixes when storing the log data in Amazon S3.","C":"Increase the read capacity units (RCUs) for the shared Amazon DynamoDB table."},"unix_timestamp":1597530360,"question_text":"A media company has been performing analytics on log data generated by its applications. There has been a recent increase in the number of concurrent analytics jobs running, and the overall performance of existing jobs is decreasing as the number of new jobs is increasing. The partitioned data is stored in\nAmazon S3 One Zone-Infrequent Access (S3 One Zone-IA) and the analytic processing is performed on Amazon EMR clusters using the EMR File System\n(EMRFS) with consistent view enabled. A data analyst has determined that it is taking longer for the EMR task nodes to list objects in Amazon S3.\nWhich action would MOST likely increase the performance of accessing log data in Amazon S3?","answer":"C","answer_ET":"C","isMC":true},{"id":"XHWzSQyx4Xzq6eiwsPlf","question_id":99,"topic":"1","timestamp":"2022-04-20 14:36:00","url":"https://www.examtopics.com/discussions/amazon/view/73892-exam-aws-certified-data-analytics-specialty-topic-1-question/","choices":{"B":"Use the Amazon Kinesis Producer Library (KPL) agent on Amazon EC2 to collect and send data to Kinesis Data Streams to further push the data to Amazon OpenSearch Service (Amazon Elasticsearch Service) and visualize using Amazon QuickSight.","D":"Use Amazon CloudWatch subscriptions to get access to a real-time feed of logs and have the logs delivered to Amazon Kinesis Data Streams to further push the data to Amazon OpenSearch Service (Amazon Elasticsearch Service) and OpenSearch Dashboards (Kibana).","A":"Enable detailed monitoring on Amazon EC2, use Amazon CloudWatch agent to store logs in Amazon S3, and use Amazon Athena for fast, interactive log analytics.","C":"Use the Amazon Kinesis Producer Library (KPL) agent on Amazon EC2 to collect and send data to Kinesis Data Firehose to further push the data to Amazon OpenSearch Service (Amazon Elasticsearch Service) and OpenSearch Dashboards (Kibana)."},"unix_timestamp":1650458160,"answer_description":"","question_text":"A software company hosts an application on AWS, and new features are released weekly. As part of the application testing process, a solution must be developed that analyzes logs from each Amazon EC2 instance to ensure that the application is working as expected after each deployment. The collection and analysis solution should be highly available with the ability to display new information with minimal delays.\nWhich method should the company use to collect and analyze the logs?","answer_images":[],"answers_community":["C (52%)","D (41%)","7%"],"exam_id":20,"answer":"C","question_images":[],"discussion":[{"timestamp":"1662626820.0","content":"I don't understand why everyone is choosing C. First of all, KPL does not send data to Kinesis Firehose, it sends data to Kinesis Data Streams, so C is very much incorrect. Second, the term KPL agent, there is no such thing. We would install Kinesis Agent on EC2 and not KPL Agent, so B and C are incorrect. In Option D, you see that it is using Cloudwatch logs which already offers what the customer wants... and implementing an Opensearch with Kibana for it would be overengineering and duplicating the same solution in another tool, duplicating data and cost. In option A it is using CloudWatch logs and Athena, which is easy to configure and works well. The answer does not say it, but the customer could use Cloudwatch Dashboards and Cloudwatch Metrics generated from the log stream. Activating EC2 detailed monitoring is not necessary though. Another thing: you guys are saying that Data Streams cannot deliver data to ES, but actually by using a Lambda you can pretty much do this... This question is very strange... But, by elimination, I would stay with option A.","comment_id":"663390","comments":[{"comment_id":"743649","comments":[{"upvote_count":"9","comment_id":"772672","content":"Direct KPL to Firehose is not possible. The above doc says \nKPL --> Data streams --> Firehose. \nCorrect if I am wrong here.","timestamp":"1673450940.0","poster":"gopi_data_guy"}],"poster":"bp339","upvote_count":"6","content":"KPL to Firehose is possible.\nhttps://docs.aws.amazon.com/streams/latest/dev/kpl-with-firehose.html","timestamp":"1670912100.0"},{"content":"Ability to display is missing in Athena","poster":"sattty","upvote_count":"1","timestamp":"1689329220.0","comment_id":"951426"},{"comments":[{"comment_id":"700500","content":"why not D?","comments":[{"comments":[{"timestamp":"1688025840.0","poster":"ogerber","upvote_count":"2","content":"The problem with D is that kinesis data stream cannot write directly to opensearch. Only via lambda. Thats why it seams there is not correct answer... unless C is to be interpreted as kinesis agent.\nhttps://opensearch.org/docs/1.1/opensearch/data-streams/","comment_id":"937788"}],"comment_id":"717787","content":"You are right, changed to D!","timestamp":"1668413400.0","upvote_count":"3","poster":"rav009"}],"upvote_count":"2","timestamp":"1666325460.0","poster":"JoellaLi"}],"timestamp":"1664522700.0","comment_id":"683313","poster":"rav009","upvote_count":"3","content":"Agree, kinesis agent can write to firehose, KPL can't. So A"},{"poster":"JoellaLi","comment_id":"696774","timestamp":"1665977400.0","upvote_count":"5","content":"But it 'should be highly available with the ability to display new information with minimal delays.' D is real time solution, while A is not."},{"content":"First of all, KPL does send to Kinesis Firehose","upvote_count":"6","poster":"ccpmad","timestamp":"1688803440.0","comment_id":"946307"},{"timestamp":"1680248400.0","content":"KPL does send to Firehose; check out Udemy's course by Stephane Maarek and Frank Kane. They have several diagrams there to show KPL talks directly to Firehose (without going through Streams).","comment_id":"856730","upvote_count":"3","poster":"Aina"}],"upvote_count":"21","poster":"FHU"},{"upvote_count":"9","content":"D is correct. CloudWatch subscription is realtime. Push logs to Kinesis Firehose or Streams which can push into ElasticSearch for aggregation and dashboard.\nCloudWatch-Subs -> Amazon Streams - > Firehose -> ElasticSearch -> Dashbaord","timestamp":"1725606420.0","comment_id":"1279443","poster":"[Removed]"},{"poster":"michele_scar","content":"Selected Answer: C\nThis is the only valid option. KDS doesn't have integration with Opensearch","timestamp":"1731938940.0","upvote_count":"1","comment_id":"1314023"},{"timestamp":"1709138340.0","content":"C is correct, KDS cannot send data to OpenSearch as stated in answer D. Also answer D does not mention how the logs will get ingested from the EC2 instances to CloudWatch. logs.","upvote_count":"2","poster":"LeoSantos121212121212121","comment_id":"1161803"},{"poster":"DigitalDanny","upvote_count":"1","timestamp":"1702312860.0","content":"Selected Answer: A\nreal-time capabilities are not a strict requirement and minimal delay is the primary consideration, then using Kinesis might indeed be considered overkill for your specific use case. In such scenarios, a simpler and cost-effective solution, such as Option A (CloudWatch + S3 + Athena), could be more suitable. This architecture allows for periodic log analysis without the need for real-time streaming.\n\nOption A provides a straightforward setup with CloudWatch for log collection, S3 for storage, and Athena for fast and interactive log analytics. It is a serverless solution that can meet your requirements while minimizing complexity.\n\nConsider your specific needs, the frequency of log analysis, and the trade-offs between simplicity, cost, and real-time capabilities when making your decision. If real-time insights are unnecessary, a less complex solution like Option A might be more appropriate.","comment_id":"1093685"},{"poster":"pn12345","comment_id":"1092670","content":"Selected Answer: C\ncorrect answer","upvote_count":"2","timestamp":"1702227480.0"},{"upvote_count":"2","comment_id":"1079140","poster":"roymunson","timestamp":"1700815800.0","content":"Very weird one:\nI'm also inbetween C & D but bot are making no sense because of:\nC: KPL can't write into Firehose. The normal process flow would be KPL -> KDS -> KDF.\nD: Is weird because they KDS can't write directly to OpenSearch. The normal process flow would be CloudWatch -> KDS -> Lambda -> OpenSearch. In addition to that, the question is talking about logs of the application itself and not metrics/logs of the EC2 - Instance (I'm not a native english speaker but this is how I've understood the question). I don't think that CloudWatch is the right tool for that. \n\nIn the end I go with C (hoping KPL agent is somewhat of a typo and they mean just Agent)."},{"timestamp":"1698778260.0","content":"KPL cannot send data directly to KDF.\n \n\"You can send data to your Kinesis Data Firehose Delivery stream using different types of sources: You can use a Kinesis data stream, the Kinesis Agent, or the Kinesis Data Firehose API using the AWS SDK. You can also use Amazon CloudWatch Logs, CloudWatch Events, or AWS IoT as your data source.\"\n\nSource: https://docs.aws.amazon.com/firehose/latest/dev/basic-write.html#\n\nSo, C is incorrect. D would be 100% correct IF it had KDF instead of KDS. I am guessing it's a typo or who knows what !! I am gonna pretend this question won't show up in the exam :)","comment_id":"1059142","poster":"TeamsDude","upvote_count":"1"},{"poster":"gofavad926","content":"Selected Answer: D\nD. I thought in a different option but:\nA. \"detailed monitoring on Amazon EC2\" is for metrics, and report 1 minute period, so is NOT real time\nBC. Do not exist KPL agent\nD. Is the real time option","upvote_count":"1","comment_id":"1043504","timestamp":"1697291880.0"},{"upvote_count":"1","content":"So what is the answer here?","comment_id":"1039159","poster":"Lala2020","timestamp":"1696913580.0"},{"poster":"Hamza98","comment_id":"1027979","content":"Selected Answer: D\nThe correct answer is D, although in reality none is correct. I had this same question but instead of KDS it was Kinesis Data Firehose. Answer A B C were also among the answers and were all incorrect. Answer C will cause some delays while CloudWatch subscriptions are near-real time","upvote_count":"3","timestamp":"1696770300.0"},{"upvote_count":"3","comment_id":"1021056","timestamp":"1696022400.0","content":"Selected Answer: C\nC - i guess correct\nD - says KDS --> OpenSearch does not work.","poster":"debasishg"},{"upvote_count":"1","comment_id":"1003105","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/opensearch-service/latest/developerguide/integrations.html#integrations-kinesis","poster":"[Removed]","timestamp":"1694257440.0"},{"upvote_count":"3","comments":[{"content":"Apparently CloudWatch logs can send data to KDS, who knew https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html","comment_id":"970395","timestamp":"1690995240.0","comments":[{"content":"So answer is D","comment_id":"970396","upvote_count":"1","comments":[{"timestamp":"1690995300.0","upvote_count":"1","content":"Actually no, its C, since Kinesis Data Stream cannot send logs to OpenSearch haha","comment_id":"970397","poster":"MLCL"}],"timestamp":"1690995240.0","poster":"MLCL"}],"upvote_count":"1","poster":"MLCL"}],"poster":"MLCL","timestamp":"1690995060.0","content":"Selected Answer: C\nClearly C, \nD can't be correct, Kinesis Data Streams cant send data directly to OpenSearch","comment_id":"970394"},{"comment_id":"969205","upvote_count":"1","poster":"NikkyDicky","content":"Selected Answer: D\ngoing w D","timestamp":"1690906980.0"},{"upvote_count":"1","comment_id":"953591","content":"Selected Answer: D\nD is the answer","poster":"developeranfc","timestamp":"1689536220.0"},{"upvote_count":"4","poster":"ccpmad","comment_id":"946317","content":"Selected Answer: C\nI think D is not correct, as Kinesis Data Streams can't push directly to OpenSearch Service: \"You can still use other sources to load streaming data, such as Amazon Kinesis Data Firehose and Amazon CloudWatch Logs, which have built-in support for OpenSearch Service. Others, like Amazon S3, Amazon Kinesis Data Streams, and Amazon DynamoDB, use AWS Lambda functions as event handlers.\" You need Lambda to do that. \nhttps://docs.aws.amazon.com/opensearch-service/latest/developerguide/integrations.html\nSo C is the correct for me. \nYes, Amazon Kinesis Producer Library (KPL) agent does not exist, but i think they are refering just to the agent https://docs.aws.amazon.com/streams/latest/dev/writing-with-agents.html","timestamp":"1688803920.0"},{"poster":"pk349","content":"D:: I passed the test","comments":[{"poster":"ccpmad","upvote_count":"3","timestamp":"1688803620.0","comment_id":"946312","content":"Kinesis Data Streams can't push directly to OpenSearch Service"}],"comment_id":"886253","timestamp":"1682946000.0","upvote_count":"2"},{"timestamp":"1682075880.0","upvote_count":"2","comment_id":"876451","content":"D is the answer. but here in answer there is a mistake . its CW log -->KDF-->ES-->kibana. Same question in cloud guru","poster":"anjuvinayan"},{"poster":"rags1482","comment_id":"870585","timestamp":"1681527240.0","upvote_count":"2","comments":[{"timestamp":"1682040120.0","upvote_count":"2","poster":"aftu","comment_id":"876108","content":"If you note in the link there is an option to stream the logs directly to OpenSearch so KDS wouldn't be necessary, though D is still the best option from my perspective."}],"content":"The answer is D Based on below link \nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html"},{"poster":"Aina","upvote_count":"3","comments":[{"content":"https://docs.aws.amazon.com/streams/latest/dev/writing-with-agents.html\nI think they are refering just to the agent...\nD can't be as KDS can't push data to opensearch, you need lambda for that","upvote_count":"2","timestamp":"1688803860.0","poster":"ccpmad","comment_id":"946316"}],"content":"B and C are incorrect because because there is no such thing as KPL agent - there is KPL - Kinesis Producer Library and then there is Kinesis Agent, which you need to install on your EC2.","comment_id":"856736","timestamp":"1680248520.0"},{"comment_id":"839851","upvote_count":"3","content":"looks like its D. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html","poster":"imjustgoodataws","timestamp":"1678881660.0"},{"content":"C is correct, KPL can send data to KDF.","upvote_count":"1","comment_id":"839792","poster":"TonyGe","timestamp":"1678877520.0"},{"upvote_count":"1","content":"C. Use the Amazon Kinesis Producer Library (KPL) agent on Amazon EC2 to collect and send data to Kinesis Data Firehose to further push the data to Amazon OpenSearch Service (Amazon Elasticsearch Service) and OpenSearch Dashboards (Kibana).\n\nThis solution is designed for highly available log collection and analysis, with the ability to display new information quickly. The Kinesis Producer Library agent can collect logs from each EC2 instance and send them to Kinesis Data Firehose, which can then further push the data to Amazon OpenSearch Service (Amazon Elasticsearch Service) and OpenSearch Dashboards (Kibana) for visualization and analysis. This architecture provides real-time monitoring, and the OpenSearch Dashboards provide highly interactive log analytics.","timestamp":"1678535220.0","poster":"AwsNewPeople","comment_id":"835921"},{"poster":"itsme1","timestamp":"1677944160.0","content":"Selected Answer: D\nThere is a Kinesis Agent for collecting and sending logs, which is no where in any of the answers. KPL Agent is made up. Cloudwatch subscription captures the logs and firehose can deliver to OpenSearch, for displaying new information with minimal delays. \n\nAnalysis with Athena is possible, but requires someone to write queries and execute, so its not as fast as the Kibana dashboard (option D)","upvote_count":"3","comment_id":"829078"},{"timestamp":"1677687420.0","upvote_count":"1","content":"Selected Answer: A\nIt is the easiest and native way to get the logs of EC2 instances","poster":"Vicious000","comment_id":"826061"},{"timestamp":"1677511620.0","poster":"VijayAmit","comment_id":"823888","upvote_count":"3","content":"Ans is D. KPL can't write directly to Firehose.\nAn Amazon Kinesis Data Streams producer is an application that puts user data records into a Kinesis data stream (also called data ingestion).\nhttps://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-kpl.html"},{"upvote_count":"1","timestamp":"1676738940.0","comment_id":"813305","content":"Option C eliminated based on fKPL cant source to firehose and it requirements kinesis agent . Option KDS writing to open search via Lamdba is possible but its not mentioned in the option. Hence answer is A","poster":"Arjun777"},{"comment_id":"766798","upvote_count":"4","timestamp":"1672933980.0","content":"A is not meet minimal delays\nB and C, no such KPL Agent..(if it intends to say Kinesis Agent than C is the answer)\nD, Stream cannot ingest data into ES, it needs firehose (If it intends to say stream to firehose, than D is the answer)","poster":"Chelseajcole"},{"poster":"silvaa360","upvote_count":"4","timestamp":"1670689080.0","content":"Answer must be C).\n\nD is close to be a solution, but the logs need to be already in cloudwatch to be used by cloudwatch subsc filters and the KDS cannot send directly to ES.","comment_id":"741094"},{"poster":"Kapello10","comment_id":"734261","content":"Selected Answer: A\nAAAAAAAAAAAAAA","timestamp":"1670052300.0","upvote_count":"1"},{"poster":"henom","timestamp":"1669601280.0","comment_id":"728736","content":"Ans-C\n\nAns D is wrong - Use Amazon CloudWatch subscriptions to get access to a real-time feed of logs and have the logs delivered to Amazon Kinesis Data Streams to further push the data to Amazon OpenSearch Service (Amazon Elasticsearch Service) and OpenSearch Dashboards (Kibana). is wrong.\n\nbecause the subscription filter is only available for the data that are already sent to CloudWatch Logs. You can't directly integrate Amazon Elasticsearch with Amazon QuickSight. This option also didn't describe how it collected the data from the EC2 instance in the first place or mentioned anything about installing a CloudWatch Logs Agent to the instances. Also, just like the other incorrect answer, you can't directly deliver data from Kinesis Data Streams to Amazon ES.\nhttps://docs.aws.amazon.com/quicksight/latest/user/supported-data-sources.html\n\nhttps://docs.aws.amazon.com/firehose/latest/dev/writing-with-agents.html","upvote_count":"2"},{"timestamp":"1668413460.0","comment_id":"717788","content":"Selected Answer: D\nNot such thing \"KPL agent\", only Kinesis agent for KDF.\nD is right.\nCloudWatch-Subs -> Amazon Streams - > Firehose -> ElasticSearch -> Dashbaord","upvote_count":"4","poster":"rav009"},{"poster":"cloudlearnerhere","comment_id":"711095","comments":[{"content":"D is also incorrect because the subscription filter is only available for the data that are already sent to CloudWatch Logs. You can't directly integrate Amazon Elasticsearch with Amazon QuickSight. This option also didn't describe how it collected the data from the EC2 instance in the first place or mentioned anything about installing a CloudWatch Logs Agent to the instances.","poster":"cloudlearnerhere","comment_id":"719203","timestamp":"1668558300.0","upvote_count":"2"}],"upvote_count":"5","timestamp":"1667562660.0","content":"Selected Answer: C\nCorrect answer is C as Kinesis Agent can be used to send data or logs to Kinesis Data Firehose and then to ElasticSearch. Kibana can be used for analysis.\n\nOption A is wrong as detailed monitoring is not required. CloudWatch agent pushes logs to CloudWatch.\n\nOption B is wrong as Kibana is an ideal solution for visualization with ElasticSearch and not QuickSight.\n\nOption D is wrong as Kinesis Data Streams do not directly integrate with ElasticSearch."},{"timestamp":"1665977220.0","content":"Selected Answer: D\nIt should be D based on Link: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html.\n \"You can use subscriptions to get access to a real-time feed of log events from CloudWatch Logs and have it delivered to other services such as an Amazon Kinesis stream, an Amazon Kinesis Data Firehose stream, or AWS Lambda for custom processing, analysis, or loading to other systems. When log events are sent to the receiving service, they are base64 encoded and compressed with the gzip format.\"","comment_id":"696772","poster":"JoellaLi","comments":[{"upvote_count":"3","content":"And to support that Stream can be used as well not only Firehose:\n\"You can load streaming data into your Amazon OpenSearch Service domain from many different sources. Some sources, like Amazon Kinesis Data Firehose and Amazon CloudWatch Logs, have built-in support for OpenSearch Service. \nOthers, like Amazon S3, Amazon Kinesis Data Streams, and Amazon DynamoDB, use AWS Lambda functions as event handlers. The Lambda functions respond to new data by processing it and streaming it to your domain.\n\"","timestamp":"1666325760.0","poster":"JoellaLi","comment_id":"700502"}],"upvote_count":"4"},{"comments":[],"comment_id":"693398","upvote_count":"6","content":"D is correct. CloudWatch subscription is realtime. Push logs to Kinesis Firehose or Streams which can push into ElasticSearch for aggregation and dashboard.\nCloudWatch-Subs -> Amazon Streams - > Firehose -> ElasticSearch -> Dashbaord","poster":"sipsap","timestamp":"1665611220.0"},{"content":"Selected Answer: C\nSelected Answer: C","upvote_count":"1","poster":"rocky48","timestamp":"1659816480.0","comment_id":"643503"},{"comment_id":"620898","upvote_count":"3","timestamp":"1655979240.0","content":"I aggree that the answer is C. However, it must be noted that using CloudWatch subscriptions is the best method to get access to real-time log data. So if answer D was worded different, using FireHose to send logs to ES, it would have my preference.","poster":"Ramshizzle"},{"upvote_count":"4","comment_id":"604178","content":"Selected Answer: C\nKinesis Data Streams cannot connect with ES directly so it has to be option C","timestamp":"1653004800.0","poster":"Shammy45"},{"upvote_count":"3","poster":"CHRIS12722222","content":"Answer = C","timestamp":"1650482100.0","comment_id":"588915"},{"upvote_count":"3","poster":"AWSRanger","comment_id":"588663","content":"Answer is \"C\". Since you cannot delivery data to Amazon ES from Kinesis Data Streams.","timestamp":"1650458160.0"}],"isMC":true,"answer_ET":"C"},{"id":"edixvUFujmFuFppioY3d","topic":"1","answer_ET":"B","answer_description":"","question_id":100,"timestamp":"2020-08-16 12:05:00","discussion":[{"timestamp":"1632067800.0","comment_id":"159139","upvote_count":"21","poster":"paul0099","content":"It is B"},{"upvote_count":"8","content":"Ans B\nThis is a textbook question.\n\nhttps://docs.aws.amazon.com/glue/latest/dg/monitor-continuations.html","timestamp":"1634759400.0","comment_id":"392222","poster":"Shraddha"},{"timestamp":"1682948880.0","upvote_count":"2","comment_id":"886326","content":"B: I passed the test","poster":"pk349"},{"timestamp":"1678673700.0","poster":"AwsNewPeople","comment_id":"837548","upvote_count":"5","content":"Selected Answer: B\nThe correct approach to solve the issue with minimal coding effort would be to enable job bookmarks on the AWS Glue jobs.\n\nEnabling job bookmarks on the AWS Glue jobs would allow the ETL job to keep track of the last processed record in the data source. This way, on the next run, the job will only process the new or updated data that was added to the source since the last successful run, thus processing only the incremental data.\n\nUsing DataFrame instead of DynamicFrame or custom logic to track processed S3 objects could require significant coding effort and may not be the most efficient approach. Deleting processed objects or data from Amazon S3 after each run may not be ideal since it may result in loss of valuable historical data.\n\nTherefore, enabling job bookmarks is the most appropriate approach to solve the issue with minimal coding effort."},{"upvote_count":"2","content":"Selected Answer: B\nCorrect answer is B as AWS Glue can be used to export the data incrementally using job bookmarks with coding required.\n\nAWS Glue tracks data that has already been processed during a previous run of an ETL job by persisting state information from the job run. This persisted state information is called a job bookmark. Job bookmarks help AWS Glue maintain state information and prevent the reprocessing of old data. With job bookmarks, you can process new data when rerunning on a scheduled interval. A job bookmark is composed of the states for various elements of jobs, such as sources, transformations, and targets. For example, your ETL job might read new partitions in an Amazon S3 file. AWS Glue tracks which partitions the job has processed successfully to prevent duplicate processing and duplicate data in the job's target data store.\n\n\nJob bookmarks are implemented for JDBC data sources, the Relationalize transform, and some Amazon Simple Storage Service (Amazon S3) sources.","timestamp":"1667669280.0","comment_id":"711902","poster":"cloudlearnerhere"},{"upvote_count":"1","timestamp":"1664083500.0","content":"Selected Answer: B\nFor incremental data, Job bookmark is the built-in feature for Glue.","poster":"Arka_01","comment_id":"678463"},{"timestamp":"1664083440.0","comment_id":"678462","content":"For incremental data, Job bookmark is the built-in option to choose for Glue.","poster":"Arka_01","upvote_count":"1"},{"upvote_count":"1","timestamp":"1658807220.0","poster":"rocky48","content":"Selected Answer: B\nB is correct","comment_id":"637124"},{"comment_id":"604829","timestamp":"1653130680.0","upvote_count":"2","poster":"Bik000","content":"Selected Answer: B\nAnswer is B"},{"poster":"Mobeen_Mehdi","upvote_count":"4","content":"its strongly B as book mark only take new data it stops processing preprocessed data","comment_id":"480597","timestamp":"1637230980.0"},{"upvote_count":"1","timestamp":"1635315600.0","content":"The answer is B, the hint is in the wording 'only in incremental data'.","poster":"rosnl","comment_id":"448406"},{"poster":"Billhardy","upvote_count":"2","comment_id":"442337","timestamp":"1634888640.0","content":"Ans B"},{"content":"although B is the obvious answer the part of the question that says minimal coding effort suggests it might be D.","timestamp":"1634264280.0","poster":"brfc","upvote_count":"1","comments":[{"timestamp":"1674131640.0","upvote_count":"1","content":"There is no code change effort you just need to enabled job bookmark. \nRemoving processed data from S3 is the worst option as you are simply loosing the data from your datalake","poster":"gopi_data_guy","comment_id":"781126"}],"comment_id":"288232"},{"timestamp":"1633655700.0","poster":"lostsoul07","upvote_count":"1","content":"B is the right answer","comment_id":"274321"},{"content":"My answer is B","timestamp":"1633381320.0","comment_id":"216742","upvote_count":"1","poster":"BillyC"},{"poster":"syu31svc","timestamp":"1632942660.0","comment_id":"191606","content":"Job bookmarks help AWS Glue maintain state information and prevent the reprocessing of old data so answer is B 100%","upvote_count":"2"},{"content":"Job Bookmarks should do the trick. So option B.","timestamp":"1632852060.0","poster":"Paitan","comment_id":"175555","upvote_count":"1"},{"upvote_count":"3","content":"B is correct","poster":"Nicki1013","timestamp":"1632568500.0","comment_id":"169342"},{"comment_id":"160766","upvote_count":"4","timestamp":"1632207720.0","poster":"zeronine","content":"My answer is B"}],"url":"https://www.examtopics.com/discussions/amazon/view/28711-exam-aws-certified-data-analytics-specialty-topic-1-question/","unix_timestamp":1597572300,"question_text":"A company has developed several AWS Glue jobs to validate and transform its data from Amazon S3 and load it into Amazon RDS for MySQL in batches once every day. The ETL jobs read the S3 data using a DynamicFrame. Currently, the ETL developers are experiencing challenges in processing only the incremental data on every run, as the AWS Glue job processes all the S3 input data on each run.\nWhich approach would allow the developers to solve the issue with minimal coding effort?","choices":{"A":"Have the ETL jobs read the data from Amazon S3 using a DataFrame.","D":"Have the ETL jobs delete the processed objects or data from Amazon S3 after each run.","B":"Enable job bookmarks on the AWS Glue jobs.","C":"Create custom logic on the ETL jobs to track the processed S3 objects."},"question_images":[],"answer":"B","exam_id":20,"isMC":true,"answers_community":["B (100%)"],"answer_images":[]}],"exam":{"id":20,"name":"AWS Certified Data Analytics - Specialty","numberOfQuestions":164,"lastUpdated":"11 Apr 2025","isImplemented":true,"isBeta":false,"provider":"Amazon","isMCOnly":true},"currentPage":20},"__N_SSP":true}