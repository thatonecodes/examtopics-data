{"pageProps":{"questions":[{"id":"CzUM50r7ySsKj7gLan3N","question_id":16,"timestamp":"2023-11-23 22:31:00","discussion":[{"timestamp":"1701325980.0","upvote_count":"9","comment_id":"1084033","poster":"ahrentom","comments":[{"timestamp":"1701405900.0","upvote_count":"2","comment_id":"1084947","poster":"kejam","content":"Agreed. CloudTrail for Org requires the destination S3 bucket to allow writes from each member account. Object Lock is enabled to prevent the data from being overwritten/deleted."}],"content":"Selected Answer: BD\nI go with BD, because each Member Account has to write into the security Account S3 bucket, not only the Organization Management Account.\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-set-bucket-policy-for-multiple-accounts.html"},{"timestamp":"1742463180.0","content":"Selected Answer: AD\nThe management account's CloudTrail service will automatically write logs from all member accounts to the centralized bucket. Member accounts should not have direct write access to the logging bucket to maintain security and integrity of the logs.\n\n\"By default, organization log files are accessible only to the management account. For information about how to allow read access to the Amazon S3 bucket for IAM users in member accounts, see Sharing CloudTrail log files between AWS accounts.\"\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/create-s3-bucket-policy-for-cloudtrail.html#org-trail-bucket-policy","poster":"jsopra","comment_id":"1400208","upvote_count":"2"},{"upvote_count":"1","timestamp":"1729662180.0","comment_id":"1301897","content":"Selected Answer: AD\nA and D","poster":"Pmktechno"},{"timestamp":"1728715260.0","comment_id":"1296374","upvote_count":"1","content":"Selected Answer: AD\nTo all who are choosing B, the answer is A. \n\nHere's the reasoning:\n In an AWS Organizations setup, the management account can be configured to collect CloudTrail logs from all member accounts and forward them to a centralized Amazon S3 bucket in a dedicated security account. This centralized logging approach ensures that all account activity across the organization is captured and securely stored.","poster":"lovekiller"},{"upvote_count":"1","timestamp":"1721765280.0","comment_id":"1253938","poster":"navid1365","content":"Selected Answer: BD\nB and D"},{"comment_id":"1235513","content":"Selected Answer: AD\nB increases the surface area for potential security issues since multiple member accounts have write access to the bucket.","poster":"cumzle_com","timestamp":"1719074820.0","upvote_count":"1"},{"timestamp":"1709521080.0","content":"AD.\nA and not B because, member account number tracking does not make sense, when it's easy to use single Org as reference for Bucket policy.","poster":"Ritarocks","comment_id":"1165257","upvote_count":"1"},{"upvote_count":"1","content":"The organization includes a dedicated security account= Member account while ALL OTHER =Management account. this means to me that granting the permission from the Management account reduces operational overhead than doing it at individual member accounts. Therefore I go with option AD.","comment_id":"1133354","poster":"Ernestokoro","timestamp":"1706360760.0"},{"content":"A, D\nOption B covers the storage aspect by configuring a dedicated S3 bucket in the security account, allowing member accounts to write logs. S3 Object Lock in compliance mode ensures the retention requirements.\n\nOption D complements this by configuring CloudTrail to capture the logs and deliver them to the dedicated S3 bucket directly.\n\nTogether, these options cover the log storage, retention, and collection requirements with the least operational overhead.","timestamp":"1705286760.0","upvote_count":"1","poster":"vikasj1in","comment_id":"1123022"},{"upvote_count":"1","content":"Selected Answer: AD\nEnable Organization Trail: In the Management Console or CLI, activate an organization trail that logs all events from all member accounts.\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","comment_id":"1106742","timestamp":"1703676240.0","poster":"WeepingMaplte"},{"content":"Selected Answer: BD\nMember account needs to write to S3.","comment_id":"1099821","timestamp":"1702913460.0","poster":"jeff001","upvote_count":"2"},{"timestamp":"1701558360.0","upvote_count":"4","poster":"marco25","content":"Selected Answer: BD\ntrails across member accounts, needs permissions to the sender bucket","comment_id":"1086458"},{"poster":"Aamee","comments":[{"upvote_count":"1","poster":"ykhan321","content":"A has only one account and option B has all the aws accounts.","comment_id":"1102039","timestamp":"1703115360.0"},{"comment_id":"1089471","upvote_count":"2","poster":"confusedyeti69","timestamp":"1701875040.0","content":"If following your logic, the management account can delete and change the logs too. \nAnd the options also says to only give write access to S3 only.\nIt is not A because members need to write S3, not only management.\n\nIn compliance mode, a protected object version can't be overwritten or deleted by any user, including the root user in your AWS account.\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html"}],"comment_id":"1082161","timestamp":"1701148080.0","content":"Selected Answer: AD\nIf I understand correctly, the reason why the option B can't be a correct one cuz the use case has asked about the logs which must not be deleted or changed which can't be met in option B if we opt for each member's accounts to be given with the full S3 logs access under an organization.","upvote_count":"1"},{"content":"Selected Answer: AD\nA and D are correct","poster":"[Removed]","upvote_count":"1","timestamp":"1700911380.0","comment_id":"1079963"},{"comment_id":"1078837","timestamp":"1700775060.0","content":"Selected Answer: AD\ncorrect","upvote_count":"1","poster":"oioi"}],"choices":{"A":"In the dedicated security account, create an Amazon S3 bucket. Configure S3 Object Lock in compliance mode and a retention period of 2 years on the S3 bucket. Set the bucket policy to allow the organization's management account to write to the S3 bucket.","D":"Create an AWS CloudTrail trail for the organization. Configure logs to be delivered to the logging Amazon S3 bucket in the dedicated security account.","E":"Turn on AWS CloudTrail in each account. Configure logs to be delivered to an Amazon S3 bucket that is created in the organization's management account. Forward the logs to the S3 bucket in the dedicated security account by using AWS Lambda and Amazon Kinesis Data Firehose.","B":"In the dedicated security account, create an Amazon S3 bucket. Configure S3 Object Lock in compliance mode and a retention period of 2 years on the S3 bucket. Set the bucket policy to allow the organization's member accounts to write to the S3 bucket.","C":"In the dedicated security account, create an Amazon S3 bucket that has an S3 Lifecycle configuration that expires objects after 2 years. Set the bucket policy to allow the organization's member accounts to write to the S3 bucket."},"answer":"BD","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/127087-exam-aws-certified-security-specialty-scs-c02-topic-1/","question_images":[],"isMC":true,"unix_timestamp":1700775060,"answer_ET":"BD","answer_description":"","exam_id":30,"question_text":"A company has AWS accounts in an organization in AWS Organizations. The organization includes a dedicated security account.\n\nAll AWS account activity across all member accounts must be logged and reported to the dedicated security account. The company must retain all the activity logs in a secure storage location within the dedicated security account for 2 years. No changes or deletions of the logs are allowed.\n\nWhich combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)","answers_community":["BD (64%)","AD (36%)"],"answer_images":[]},{"id":"d0cdeac0wgda3pBrI7DV","answer_images":[],"question_images":[],"discussion":[{"upvote_count":"6","poster":"yorkicurke","timestamp":"1719221340.0","content":"Selected Answer: B\nHate questions like these which rather then testing your knoweledge of technologies trick you into these weired worded questions.\n\nthe statement 'Ensure that the security group that is attached to the Lambda function allows outbound' threw me off as Lambda does not have SGs.\n\nBut then through some internet digging came accross the fact that when a Lambda function needs to access resources inside a Virtual Private Cloud (VPC), it does so using ENI which resides in a subnet of the VPC and can have a security group associated with it. The security group acts as a virtual firewall for the ENI.","comment_id":"1104559"},{"upvote_count":"1","comment_id":"1105284","content":"Selected Answer: B\na) when you use the console to store a database secret, Secrets Manager automatically creates it in the correct JSON structure.\nc) secret manager already configured as auto-rotation. also, secret id should have been known instead of listing secrets .\nd) accessing secret manager via public is not recommended.","timestamp":"1719313140.0","poster":"Daniel76"},{"upvote_count":"2","comment_id":"1089480","content":"Why would the lambda need access to the EC2? The question is unclear about the exact job of the lambda. It is worded as if the lambda job is to change the creds in secrets manager only.","timestamp":"1717679580.0","comments":[{"poster":"JPSWS","upvote_count":"2","timestamp":"1718889780.0","content":"The DB runs on the EC2 that's why the Lambda needs access to it to set the new credentials","comment_id":"1101676"}],"poster":"confusedyeti69"},{"poster":"Aamee","timestamp":"1716867120.0","upvote_count":"4","content":"Selected Answer: B\nB is the only one that logically seems right. All others are distracters except option C. But option C describes the solution of this problem as a one time thing whereas, it's been asked to provide a permanent solution for this use case. That's why B looks much more secured and valid option among all others.","comment_id":"1082184"},{"comment_id":"1079965","upvote_count":"2","content":"Selected Answer: B\nI'll vote B. The rest are distractors but feel free to correct me if I'm wrong.","poster":"[Removed]","timestamp":"1716629220.0"},{"content":"Selected Answer: B\ncorrect","comment_id":"1078840","poster":"oioi","timestamp":"1716492900.0","upvote_count":"2"}],"question_id":17,"answer":"B","timestamp":"2023-11-23 22:35:00","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/127088-exam-aws-certified-security-specialty-scs-c02-topic-1/","topic":"1","answer_ET":"B","unix_timestamp":1700775300,"choices":{"B":"Ensure that the security group that is attached to the Lambda function allows outbound connections to the EC2 instance. Ensure that the security group that is attached to the EC2 instance allows inbound connections from the security group that is attached to the Lambda function.","D":"Add an internet gateway to the VPC. Create a NAT gateway in a public subnet. Update the VPC route tables so that traffic from the Lambda function and traffic from the EC2 instance can reach the Secrets Manager public endpoint.","A":"Use the AWS Management Console to edit the JSON structure of the secret in Secrets Manager so that the secret automatically conforms with the structure that the database requires.","C":"Use the Secrets Manager list-secrets command in the AWS CLI to list the secret. Identify the database credentials. Use the Secrets Manager rotate-secret command in the AWS CLI to force the immediate rotation of the secret."},"answer_description":"","answers_community":["B (100%)"],"exam_id":30,"question_text":"A company is testing its incident response plan for compromised credentials. The company runs a database on an Amazon EC2 instance and stores the sensitive database credentials as a secret in AWS Secrets Manager. The secret has rotation configured with an AWS Lambda function that uses the generic rotation function template. The EC2 instance and the Lambda function are deployed in the same private subnet. The VPC has a Secrets Manager VPC endpoint.\n\nA security engineer discovers that the secret cannot rotate. The security engineer determines that the VPC endpoint is working as intended. The Amazon CloudWatch logs contain the following error: \"setSecret: Unable to log into database\".\n\nWhich solution will resolve this error?"},{"id":"NSSXzL9O5BvOQRyBBfzm","answer_images":[],"timestamp":"2023-11-25 12:39:00","answer":"A","unix_timestamp":1700912340,"answer_ET":"A","question_id":18,"exam_id":30,"topic":"1","discussion":[{"content":"Selected Answer: A\ngotta be A","timestamp":"1727709780.0","upvote_count":"2","comment_id":"1186221","poster":"ale_brd_111"},{"comment_id":"1084043","content":"Selected Answer: A\nA is correct, key word in SCP is to Deny, because it overwrites the FullAccessSCP Alow statement.","timestamp":"1717044840.0","upvote_count":"4","poster":"ahrentom"},{"upvote_count":"3","comment_id":"1083028","poster":"AgboolaKun","content":"Selected Answer: A\nA is correct. The NotAction element cannot be used in this case.\n\nYou only need an explicit DENY here since all accounts and OUs already have a default FullAWSAccess SCP but you don't want them to be able to disable Amazon GuardDuty and AWS Security Hub.","comments":[{"content":"Kindly correct me if I am wrong. When we attach a new SCP the default FullAWSAccess SCP is detached from the OU. isn't that right?","timestamp":"1720209900.0","upvote_count":"1","comment_id":"1114819","poster":"Sab31"}],"timestamp":"1716934680.0"},{"timestamp":"1716908100.0","upvote_count":"2","content":"Selected Answer: D\nProbably going with D but still not 100% sure how is it going to work that way... would appreciate if someone could help in understanding this question..","comments":[{"comments":[{"poster":"Aamee","timestamp":"1717439280.0","upvote_count":"2","comment_id":"1087094","content":"Ah ok, got it...thnx so much... in this way, probably looks like all other options are invalid except option A since on all others they've used 'NotAction' attribute with Allow directly and indirectly which won't work.."},{"poster":"Zek","comment_id":"1212082","content":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_syntax.html#scp-elements-table","upvote_count":"1","timestamp":"1731701520.0"}],"poster":"LeoD","timestamp":"1717233600.0","upvote_count":"2","comment_id":"1085168","content":"SCPs do not support NotAction with effect Allow."}],"poster":"Aamee","comment_id":"1082755"},{"comment_id":"1079971","poster":"[Removed]","upvote_count":"1","timestamp":"1716629940.0","content":"A. OU level will still have access to other services outside of Guardduty and Security Hub due to the OU level policy. D could work but is not necessary"}],"question_text":"A company deploys a set of standard IAM roles in AWS accounts. The IAM roles are based on job functions within the company. To balance operational efficiency and security, a security engineer implemented AWS Organizations SCPs to restrict access to critical security services in all company accounts.\n\nAll of the company's accounts and OUs within AWS Organizations have a default FullAWSAccess SCP that is attached. The security engineer needs to ensure that no one can disable Amazon GuardDuty and AWS Security Hub. The security engineer also must not override other permissions that are granted by IAM policies that are defined in the accounts.\n\nWhich SCP should the security engineer attach to the root of the organization to meet these requirements?","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/127154-exam-aws-certified-security-specialty-scs-c02-topic-1/","question_images":[],"answers_community":["A (82%)","D (18%)"],"answer_description":"","choices":{"D":"","C":"","A":"","B":""}},{"id":"ONaN2BR5gSwvIOS7Jgyn","question_images":[],"exam_id":30,"discussion":[{"poster":"Aamee","comment_id":"1095797","timestamp":"1718303340.0","upvote_count":"19","content":"Since this is the last question here so maybe I can post it here. I've passed this exam with a score of 926. Only few of the questions were not from this exam material but else, everything came from here. Would like to thanks to all of you who helped in answering my queries and got my concept clarified!... Man_Kind, Agboola and others, you guys simply rock, thanks once again so much! :)","comments":[{"poster":"giancesarini2023","upvote_count":"2","comment_id":"1106429","content":"@Aamee, do you think there is a question from 1 to 50? I'm only studying from 50 to 115.","timestamp":"1719435120.0"}]},{"poster":"saptati","timestamp":"1726247580.0","upvote_count":"6","comment_id":"1172849","comments":[{"poster":"saptati","timestamp":"1726332420.0","upvote_count":"2","comment_id":"1173639","content":"Correction, I took the exam on 13 March 2024."}],"content":"I took the exam on 13 Feb 2024. Around 25 questions came from here. The rest I answered by myself. If you are an experienced AWS Professional, you won't find it difficult to pass the exam. If you are a novice, then wait for the exam topics to update the question bank. The 121 questions aren't enough. All the best, and thanks everyone for contributing to the discussion."},{"upvote_count":"1","content":"Selected Answer: A\nall the invalid options are to store sensitive information (the RDS database password in this case) in PLAINTEXT format.","timestamp":"1743856500.0","poster":"phmeeeee","comment_id":"1534778"},{"comment_id":"1141773","upvote_count":"2","timestamp":"1722913560.0","poster":"nn67","content":"A\nkeyword dynamic reference"},{"comment_id":"1138449","content":"Yesterday I took this exam (Feb 1st) single question also wasn't came from this set of questions. Please wait examtopics team should be update soon new set of questions.","upvote_count":"3","poster":"Pmktechno","timestamp":"1722588840.0"},{"content":"Hello, I passed exam with 956 score. Thank you all for contributing and correcting the answers.","upvote_count":"1","comment_id":"1125336","poster":"brpjp","timestamp":"1721244000.0","comments":[{"comment_id":"1134177","content":"when did you take the exam?","upvote_count":"1","poster":"alexleely","timestamp":"1722170640.0"}]},{"comment_id":"1082166","timestamp":"1716866040.0","poster":"Aamee","upvote_count":"1","content":"Selected Answer: A\nYup, for sure it should be A. Here's the summary:\n\n\"Updating a secret in Secrets Manager doesn't automatically update the secret in CloudFormation. In order for CloudFormation to update a secretsmanager dynamic reference, you must perform a stack update that updates the resource containing the dynamic reference, either by updating the resource property that contains the secretsmanager dynamic reference, or updating another of the resource's properties.\""},{"timestamp":"1716630420.0","poster":"[Removed]","upvote_count":"4","comment_id":"1079975","content":"Selected Answer: A\nA. See below\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html#dynamic-references-secretsmanager"},{"poster":"oioi","timestamp":"1716493440.0","comment_id":"1078847","upvote_count":"1","content":"Selected Answer: A\ncorrect"}],"question_id":19,"answer_ET":"A","answer_images":[],"answer":"A","answers_community":["A (100%)"],"choices":{"A":"Use a dynamic reference in the CloudFormation template to reference the database credentials in Secrets Manager.","C":"Use a SecureString parameter in the CloudFormation template to reference the database credentials in Secrets Manager.","D":"Use a SecureString parameter in the CloudFormation template to reference an encrypted value in AWS KMS.","B":"Use a parameter in the CloudFormation template to reference the database credentials. Encrypt the CloudFormation template by using AWS KMS."},"question_text":"A company needs to follow security best practices to deploy resources from an AWS CloudFormation template. The CloudFormation template must be able to configure sensitive database credentials.\n\nThe company already uses AWS Key Management Service (AWS KMS) and AWS Secrets Manager.\n\nWhich solution will meet the requirements?","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/127089-exam-aws-certified-security-specialty-scs-c02-topic-1/","unix_timestamp":1700775840,"timestamp":"2023-11-23 22:44:00","topic":"1","answer_description":""},{"id":"Vez7zeUB8aHAIPGiY2hT","discussion":[{"upvote_count":"2","comment_id":"1190729","poster":"ion_gee","content":"Selected Answer: BDF\nNot A, do not need cloud watch. \nNot C, Kinesis Data firehose(Now Amazon Data Firehose) is what we need here, not Kinesis Data Streams.\nNot E . Rather use Athena to query S3 \n\nSee Ref https://aws.amazon.com/blogs/architecture/visualize-aws-security-hub-findings-using-analytics-and-business-intelligence-tools/","timestamp":"1728269220.0"},{"content":"Selected Answer: BDF\nBDF probably","timestamp":"1727709480.0","upvote_count":"1","comment_id":"1186219","poster":"ale_brd_111"},{"content":"Selected Answer: BDF\nBDF are the best options","timestamp":"1724408940.0","comment_id":"1157106","upvote_count":"1","poster":"nublit"},{"timestamp":"1723928520.0","upvote_count":"1","poster":"awssecuritynewbie","content":"Selected Answer: BDF\nBDF for sure,","comment_id":"1152907"},{"timestamp":"1723808100.0","comment_id":"1152017","upvote_count":"1","content":"Selected Answer: BDF\nBDF\nAlso agree with previous comment.","poster":"sarcactus"},{"content":"BDF\nThe steps are literally provided in this Doc https://aws.amazon.com/blogs/architecture/visualize-aws-security-hub-findings-using-analytics-and-business-intelligence-tools/","comment_id":"1149865","timestamp":"1723608780.0","poster":"MikeRach","upvote_count":"1"}],"unix_timestamp":1707828600,"answers_community":["BDF (100%)"],"topic":"1","answer":"BDF","timestamp":"2024-02-13 13:50:00","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/133740-exam-aws-certified-security-specialty-scs-c02-topic-1/","exam_id":30,"question_text":"An international company wants to combine AWS Security Hub findings across all the company's AWS Regions and from multiple accounts. In addition, the company wants to create a centralized custom dashboard to correlate these findings with operational data for deeper analysis and insights. The company needs an analytics tool to search and visualize Security Hub findings.\n\nWhich combination of steps will meet these requirements? (Chose three.)","answer_ET":"BDF","question_id":20,"choices":{"A":"Designate an AWS account as a delegated administrator for Security Hub. Publish events to Amazon CloudWatch from the delegated administrator account, all member accounts, and required Regions that are enabled for Security Hub findings.","D":"In each Region, create an Amazon EventBridge rule to deliver findings to an Amazon Kinesis Data Firehose delivery stream. Configure the Kinesis Data Firehose delivery streams to deliver the logs to a single Amazon S3 bucket.","B":"Designate an AWS account in an organization in AWS Organizations as a delegated administrator for Security Hub. Publish events to Amazon EventBridge from the delegated administrator account, all member accounts, and required Regions that are enabled for Security Hub findings.","C":"In each Region, create an Amazon EventBridge rule to deliver findings to an Amazon Kinesis data stream. Configure the Kinesis data streams to output the logs to a single Amazon S3 bucket.","E":"Use AWS Glue DataBrew to crawl the Amazon S3 bucket and build the schema. Use AWS Glue Data Catalog to query the data and create views to flatten nested attributes. Build Amazon QuickSight dashboards by using Amazon Athena.","F":"Partition the Amazon S3 data. Use AWS Glue to crawl the S3 bucket and build the schema. Use Amazon Athena to query the data and create views to flatten nested attributes. Build Amazon QuickSight dashboards that use the Athena views."},"answer_images":[],"answer_description":"","question_images":[]}],"exam":{"name":"AWS Certified Security - Specialty SCS-C02","isBeta":false,"isImplemented":true,"numberOfQuestions":288,"isMCOnly":true,"provider":"Amazon","id":30,"lastUpdated":"11 Apr 2025"},"currentPage":4},"__N_SSP":true}