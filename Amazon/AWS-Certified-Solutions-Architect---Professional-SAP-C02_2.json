{"pageProps":{"questions":[{"id":"qh2v4yw32p83UQ3Ajbz3","exam_id":33,"unix_timestamp":1673789520,"timestamp":"2023-01-15 14:32:00","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/95421-exam-aws-certified-solutions-architect-professional-sap-c02/","isMC":true,"answer":"ACE","discussion":[{"poster":"masetromain","comments":[{"content":"E: In the development account, creating a group that contains all the IAM users of the design team and attaching a different IAM policy to the group to allow the sts:AssumeRole action on the role in the production account is correct because it allows the users in the group to assume the role created in the production account, which gives them access to the S3 bucket in the production account.\n\nThe other choices are not correct because:\n\nB: In the development account, creating a new IAM policy that allows read and write access to the S3 bucket is not correct because the design team needs to access the S3 bucket in the production account, not the development account.","upvote_count":"4","comment_id":"779105","poster":"masetromain","comments":[{"content":"D: In the development account, creating a role, attaching the new policy to the role and defining the production account as a trusted entity is not correct because the design team needs to assume a role in the production account to access the S3 bucket, not create a role in the development account.\n\nF: In the development account, creating a group that contains all the IAM users of the design team and attaching a different IAM policy to the group to allow the sts:AssumeRole action on the role in the development account is not correct because the design team needs to assume a role in the production account to access the S3 bucket, not the development account.","comment_id":"779106","upvote_count":"2","poster":"masetromain","timestamp":"1673975280.0"}],"timestamp":"1673975280.0"}],"content":"Selected Answer: ACE\nThe correct answer is A, C, and E.\n\nA: In the production account, creating a new IAM policy that allows read and write access to the S3 bucket is correct because it allows the design team to upload and update the static assets in the S3 bucket in the production account.\n\nC: In the production account, creating a role and attaching the new policy to the role, and defining the development account as a trusted entity is correct because it allows the design team from the development account to assume the role and access the S3 bucket in the production account, while limiting their access to only the specific resources and actions defined in the policy.","upvote_count":"14","timestamp":"1673975280.0","comment_id":"779103"},{"comments":[{"upvote_count":"1","timestamp":"1732927200.0","comment_id":"1319982","content":"C: \"creating a role and attaching the new policy to the role\" => it is very clear to use the policy to control read write. A question about the role created with C, where to use?","poster":"LuongTo"}],"content":"Selected Answer: ACE\nStep 1: Create a role in the Production Account; create the role in the Production account and specify the Development account as a trusted entity. You also limit the role permissions to only read and write access to the productionapp bucket. Anyone granted permission to use the role can read and write to the productionapp bucket.\nStep 2: Grant access to the role Sign in as an administrator in the Development account and allow the AssumeRole action on the UpdateApp role in the Production account.\n\nSo, recap, production account you create the policy for S3, and you set development account as a trusted entity. Then on the development account you allow the sts:assumeRole action on the role in production account. \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html","timestamp":"1679188920.0","poster":"zejou1","upvote_count":"10","comment_id":"843330"},{"content":"A. In the production account, create a new IAM policy that allows read and write access to the S3 bucket.\nD. In the development account, create a role. Attach the new policy to the role Define the production account as a trusted entity.\nE. In the development account, create a group that contains all the IAM users of the design team Attach a different IAM policy to the group to allow the sts:AssumeRole action on the role In the production account.","timestamp":"1725255600.0","poster":"amministrazione","upvote_count":"1","comment_id":"1276419"},{"content":"Selected Answer: ACE\nACE. F is a trap.","comment_id":"1179460","poster":"Dgix","upvote_count":"1","timestamp":"1711041600.0"},{"timestamp":"1703286360.0","poster":"career360guru","comment_id":"1103770","content":"Selected Answer: ACE\nA, C and E","upvote_count":"1"},{"comment_id":"1067623","poster":"AMohanty","timestamp":"1699666980.0","content":"BCE\nNeed to provide Account in Dev S3 Read Write Access\nWe define the permissions of the user in the Account it was created in","upvote_count":"1"},{"upvote_count":"1","timestamp":"1688347080.0","poster":"NikkyDicky","comment_id":"941344","content":"Selected Answer: ACE\nACE in this case"},{"poster":"MoussaNoussa","upvote_count":"1","comment_id":"924258","timestamp":"1686837840.0","content":"ACE is the correct choice of course"},{"upvote_count":"2","content":"Selected Answer: ACE\nVote for ACE","timestamp":"1684288620.0","comment_id":"899649","poster":"leehjworking"},{"comment_id":"851686","timestamp":"1679891700.0","upvote_count":"3","poster":"mfsec","content":"Selected Answer: ACE\nACE is the best choice"},{"comment_id":"830542","content":"Selected Answer: ACE\nMake Dev account as trusted entity. create a role in prod account. attache IAM policy of prod account and let development account assume this role to access prod s3 bucket.","upvote_count":"2","poster":"God_Is_Love","timestamp":"1678076340.0"},{"poster":"Musk","content":"Selected Answer: ACE\nI think it's clear","comment_id":"797740","timestamp":"1675499460.0","upvote_count":"1"},{"poster":"tatdatpham","timestamp":"1675272960.0","upvote_count":"2","content":"Selected Answer: ACE\nACE is correct answer","comment_id":"795363"},{"poster":"zozza2023","content":"Selected Answer: ACE\nACE should works","upvote_count":"2","comment_id":"793429","timestamp":"1675119300.0"},{"upvote_count":"2","comment_id":"777171","content":"ACE is my answer","poster":"zhangyu20000","timestamp":"1673825040.0"},{"poster":"masetromain","upvote_count":"2","timestamp":"1673789520.0","content":"Selected Answer: ADE\nA, D, and E are the correct steps that would meet the requirements.\n\nA. In the production account, create a new IAM policy that allows read and write access to the S3 bucket. This will allow the design team to read and write to the S3 bucket that holds the assets in the production account.\n\nD. In the development account, create a role. Attach the new policy to the role. Define the production account as a trusted entity. This will allow the design team to assume a role in the development account that has permissions to access the S3 bucket in the production account.\n\nE. In the development account, create a group that contains all the IAM users of the design team. Attach a different IAM policy to the group to allow the sts:AssumeRole action on the role in the production account. This will allow the users in the design team group to assume the role created in step D and access the S3 bucket in the production account.","comment_id":"776600","comments":[{"timestamp":"1673789520.0","upvote_count":"1","content":"Option B is not required because the design team needs to access the S3 bucket in the production account, not in the development account.\n\nOption C is not required because the design team needs to access the S3 bucket in the production account and this can be done by assuming a role in the development account.\n\nOption F is not required because the design team needs to access the S3 bucket in the production account and this can be done by assuming a role in the development account that is trusted by the production account.","comment_id":"776601","poster":"masetromain"}]}],"answer_ET":"ACE","question_text":"A publishing company's design team updates the icons and other static assets that an ecommerce web application uses. The company serves the icons and assets from an Amazon S3 bucket that is hosted in the company's production account. The company also uses a development account that members of the design team can access.\n\nAfter the design team tests the static assets in the development account, the design team needs to load the assets into the S3 bucket in the production account. A solutions architect must provide the design team with access to the production account without exposing other parts of the web application to the risk of unwanted changes.\n\nWhich combination of steps will meet these requirements? (Choose three.)","choices":{"D":"In the development account, create a role. Attach the new policy to the role Define the production account as a trusted entity.","C":"In the production account, create a role Attach the new policy to the role. Define the development account as a trusted entity.","E":"In the development account, create a group that contains all the IAM users of the design team Attach a different IAM policy to the group to allow the sts:AssumeRole action on the role In the production account.","F":"In the development account, create a group that contains all the IAM users of the design team Attach a different IAM policy to the group to allow the sts:AssumeRole action on the role in the development account.","A":"In the production account, create a new IAM policy that allows read and write access to the S3 bucket.","B":"In the development account, create a new IAM policy that allows read and write access to the S3 bucket."},"question_id":6,"answers_community":["ACE (95%)","5%"],"question_images":[],"answer_description":"","topic":"1"},{"id":"4jpLwpphbeGeAreHwGNl","question_id":7,"question_images":[],"unix_timestamp":1673789820,"url":"https://www.examtopics.com/discussions/amazon/view/95425-exam-aws-certified-solutions-architect-professional-sap-c02/","topic":"1","answer_ET":"C","answer":"C","answer_description":"","choices":{"A":"Create a new Elastic Beanstalk application. Select a load-balanced environment type. Select all Availability Zones. Add a scale-out rule that will run if the maximum CPU utilization is over 85% for 5 minutes.","D":"Select the Rebuild environment action with the load balancing option. Select an Availability Zones. Add a scale-out rule that will run if the sum CPU utilization is over 85% for 5 minutes.","B":"Create a second Elastic Beanstalk environment. Apply the traffic-splitting deployment policy. Specify a percentage of incoming traffic to direct to the new environment in the average CPU utilization is over 85% for 5 minutes.","C":"Modify the existing environment’s capacity configuration to use a load-balanced environment type. Select all Availability Zones. Add a scale-out rule that will run if the average CPU utilization is over 85% for 5 minutes."},"isMC":true,"question_text":"A company developed a pilot application by using AWS Elastic Beanstalk and Java. To save costs during development, the company's development team deployed the application into a single-instance environment. Recent tests indicate that the application consumes more CPU than expected. CPU utilization is regularly greater than 85%, which causes some performance bottlenecks.\n\nA solutions architect must mitigate the performance issues before the company launches the application to production.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","discussion":[{"upvote_count":"27","timestamp":"1674546840.0","content":"Selected Answer: C\nI think AWS wants you to know is the below.\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html","comment_id":"786286","poster":"Untamables"},{"upvote_count":"5","poster":"ninomfr64","content":"A = you don't need to create a new application (instead you could create a new environment in the existing application)\nB = traffic-split is used to deploy a new version of the app, not to scale out\nC = correct\nD = rebuild does not allow to change environment configuration https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-management-rebuild.html","timestamp":"1705668960.0","comment_id":"1126681"},{"timestamp":"1728470820.0","upvote_count":"2","content":"Selected Answer: C\nYou can change your environment type to a single-instance or load-balanced, scalable environment by editing your environment's configuration.","comment_id":"1295110","poster":"nimbus_00"},{"poster":"amministrazione","content":"C. Modify the existing environment’s capacity configuration to use a load-balanced environment type. Select all Availability Zones. Add a scale-out rule that will run if the average CPU utilization is over 85% for 5 minutes.","upvote_count":"1","timestamp":"1725255660.0","comment_id":"1276422"},{"comment_id":"1106521","upvote_count":"3","poster":"Maygam","timestamp":"1703645400.0","content":"Selected Answer: C\nYou can change the existing environment from single instance to load balanced.\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html"},{"timestamp":"1703286660.0","comment_id":"1103772","poster":"career360guru","upvote_count":"1","content":"Selected Answer: C\nOption C"},{"timestamp":"1702803960.0","comment_id":"1098761","upvote_count":"1","poster":"yuliaqwerty","content":"C here https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/GettingStarted.EditConfig.html"},{"content":"Selected Answer: C\nyou can change existing Beanstalk environment type from a single instance to load-balanced","upvote_count":"2","timestamp":"1700030460.0","poster":"severlight","comment_id":"1071142"},{"poster":"CuteRunRun","timestamp":"1691820540.0","upvote_count":"1","comment_id":"979166","content":"Selected Answer: C\nI prefer C"},{"poster":"Spaco","content":"Selected Answer: C\nOption C is very correct. See https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html for confirmation","comment_id":"964296","timestamp":"1690427700.0","upvote_count":"1"},{"content":"Selected Answer: C\nits a C","comment_id":"941346","upvote_count":"1","poster":"NikkyDicky","timestamp":"1688347320.0"},{"comment_id":"899686","upvote_count":"4","poster":"leehjworking","content":"Anybody know why we should select all AZs?","timestamp":"1684291680.0"},{"upvote_count":"1","poster":"mfsec","content":"Selected Answer: C\nModify the existing environment’s capacity configuration to use a load-balanced environment type.","timestamp":"1679891760.0","comment_id":"851687"},{"timestamp":"1679189220.0","upvote_count":"4","poster":"zejou1","content":"Selected Answer: C\nYou can change your environment type to a single-instance or load-balanced, scalable environment by editing your environment's configuration. In some cases, you might want to change your environment type from one type to another. For example, let's say that you developed and tested an application in a single-instance environment to save costs. When your application is ready for production, you can change the environment type to a load-balanced, scalable environment so that it can scale to meet the demands of your customers.\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html","comment_id":"843332"},{"poster":"God_Is_Love","upvote_count":"2","content":"Selected Answer: C\nA is wrong. no need to re create new EB env when the question is asking to mitigate probable performance issues based on current compute consumption of >=85%","comment_id":"830550","timestamp":"1678077360.0"},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html","upvote_count":"2","comment_id":"808660","poster":"spd","timestamp":"1676397660.0"},{"timestamp":"1675500060.0","comment_id":"797747","upvote_count":"1","poster":"Musk","content":"Selected Answer: C\nIt's C. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html#using-features.managing.changetype"},{"poster":"vsk12","comments":[{"comment_id":"793861","timestamp":"1675154640.0","upvote_count":"2","poster":"mikeshop","content":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html\nYes they can."}],"timestamp":"1674580980.0","comment_id":"786727","upvote_count":"2","content":"A: Elastic Beanstalk environment can not be changed."},{"comment_id":"784271","poster":"romidan","content":"I think C does make sense as per the link below - \nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/GettingStarted.EditConfig.html\n\nAs per this link, a change would automatically initiate the new instance as per the ASG min attribute.","upvote_count":"1","timestamp":"1674389760.0"},{"comments":[{"comments":[{"content":"\"you can't change the existing environment.\": since when?\n2 years ago it was possible and I firmly believe AWS didn't change that without updating the documentation https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/GettingStarted.EditConfig.html","timestamp":"1678671600.0","comment_id":"837532","upvote_count":"4","comments":[{"content":"lol... it is chatgpt typing","poster":"BabaP","upvote_count":"2","comment_id":"912975","timestamp":"1685727960.0"}],"poster":"hobokabobo"}],"comment_id":"779111","content":"C. Modify the existing environment’s capacity configuration to use a load-balanced environment type. Select all Availability Zones. Add a scale-out rule that will run if the average CPU utilization is over 85% for 5 minutes.\nThis option is not correct because you can't change the existing environment.\n\nD. Select the Rebuild environment action with the load balancing option. Select an Availability Zones. Add a scale-out rule that will run if the sum CPU utilization is over 85% for 5 minutes.\nThis option is not correct because it rebuilds the environment but it does not scale out the instances.\n\nIn summary, option A is the correct answer because it creates a new load-balanced environment, which increases scalability and availability, and it also includes a scale-out rule that triggers when CPU utilization is high, which automatically scales the instances to handle increased traffic, thus alleviating performance bottlenecks.","upvote_count":"1","timestamp":"1673975460.0","poster":"masetromain"}],"poster":"masetromain","timestamp":"1673975460.0","upvote_count":"2","comment_id":"779110","content":"Selected Answer: A\nThe correct answer is A. Create a new Elastic Beanstalk application. Select a load-balanced environment type. Select all Availability Zones. Add a scale-out rule that will run if the maximum CPU utilization is over 85% for 5 minutes.\nThis solution will create a new load-balanced environment which will increase the scalability and availability of the application, which will help mitigate the performance issues. Additionally, by adding a scale-out rule that triggers when the CPU utilization is high, the application will automatically scale to handle increased traffic, which will help alleviate the performance bottlenecks.\n\nB. Create a second Elastic Beanstalk environment. Apply the traffic-splitting deployment policy. Specify a percentage of incoming traffic to direct to the new environment in the average CPU utilization is over 85% for 5 minutes.\nThis option is not correct because it only directs some traffic to the new environment but it does not scale out the instances."},{"upvote_count":"2","comment_id":"777177","comments":[{"upvote_count":"5","timestamp":"1674399540.0","content":"Yes, you can. Try on your AWS account. The correct answer is C.","poster":"keenian","comment_id":"784410"}],"content":"A: You cannot change envrionment","timestamp":"1673826000.0","poster":"zhangyu20000"},{"timestamp":"1673789820.0","content":"Selected Answer: C\nThe correct answer is C. This solution will meet the requirements with the least operational overhead because it modifies the existing environment's capacity configuration to use a load-balanced environment type and selects all availability zones. This will allow the application to scale out automatically if the average CPU utilization is over 85% for 5 minutes. This will help alleviate the performance issues without the need to create a new environment or rebuild the existing one.","upvote_count":"4","comment_id":"776607","poster":"masetromain","comments":[{"content":"Option A, creating a new Elastic Beanstalk application, would require more operational overhead as it would involve creating a new environment and configuring it with a load-balanced environment type and selecting all availability zones.\n\nOption B, creating a second Elastic Beanstalk environment and applying a traffic-splitting deployment policy, would also require more operational overhead as it would involve creating a new environment and configuring it to handle some of the incoming traffic.\n\nOption D, selecting the Rebuild environment action with the load balancing option, would also require more operational overhead as it would involve rebuilding the existing environment and configuring it with a load-balanced environment type.","comments":[{"timestamp":"1673789880.0","upvote_count":"2","comment_id":"776611","poster":"masetromain","content":"To modify the existing environment's capacity in Elastic Beanstalk, you can use the Elastic Beanstalk management console or the AWS Elastic Beanstalk API.\n\nTo do this using the management console:\n\n1 - Open the Elastic Beanstalk management console.\n2 - Select the application and environment that you want to modify.\n3 - In the navigation pane, choose Configuration.\n4 - In the Capacity configuration section, you can modify the number of instances in your environment and configure automatic scaling settings.\n\nTo do this using the AWS Elastic Beanstalk API, you can use the UpdateEnvironment API action. The UpdateEnvironment action allows you to change the number of instances in your environment, as well as other settings like the environment name and description."}],"poster":"masetromain","upvote_count":"1","comment_id":"776608","timestamp":"1673789820.0"}]}],"answers_community":["C (96%)","4%"],"timestamp":"2023-01-15 14:37:00","answer_images":[],"exam_id":33},{"id":"GLLNzisGdc2mjje6cXhW","answer_description":"","topic":"1","isMC":true,"timestamp":"2023-01-15 14:42:00","exam_id":33,"answer_ET":"B","discussion":[{"poster":"masetromain","content":"Selected Answer: B\nB. Performing a one-time migration of the database cluster to Amazon RDS, and creating several additional read replicas to handle the load during end of month.\n\nThis is the optimal solution as migrating the database to Amazon RDS will provide the ability to easily scale read replicas for handling increased read traffic during the end of the month. Additionally, RDS will manage the underlying infrastructure and provide automatic backups, software patching, and monitoring, which will reduce the operational overhead for the company. \n\nOption A may help but it will not be sufficient to handle the heavy load, option C and D are not efficient solutions to han","upvote_count":"16","timestamp":"1673790120.0","comment_id":"776617"},{"content":"B. Performing a one-time migration of the database cluster to Amazon RDS, and creating several additional read replicas to handle the load during end of month.","upvote_count":"1","comment_id":"1276424","timestamp":"1725255720.0","poster":"amministrazione"},{"upvote_count":"1","comment_id":"1175888","content":"Selected Answer: B\nB, include read replicas","timestamp":"1710686280.0","poster":"gofavad926"},{"upvote_count":"1","timestamp":"1703287020.0","poster":"career360guru","content":"Selected Answer: B\nOption B -> Reporting workload = higher read operation ==> Solution RDS read replica.","comment_id":"1103774"},{"comment_id":"1048928","poster":"hansean","timestamp":"1697816280.0","upvote_count":"1","content":"Selected Answer: D\nI go with D"},{"upvote_count":"1","poster":"uC6rW1aB","comment_id":"1001231","timestamp":"1694067900.0","content":"Selected Answer: D\nI vote D\nTo solve heavy IO issue, I think both option B and D both works.But the question demands for to \"handle the month-end load with the LEAST impact on performance\" , Option B create the new read replicas during end of month seems too complicated, you'll need to seperate read/write traffic from application at the end of the month."},{"comment_id":"995563","content":"Selected Answer: B\nReporting is also an important hint. Only read operations are needed here; so read replicas would server the purpose","upvote_count":"2","poster":"venvig","timestamp":"1693528560.0"},{"poster":"xplusfb","content":"Selected Answer: B\nall other sections not applicable i guess specially D its so funny. Each month none of technical person doesnt want to do like this task.","upvote_count":"1","timestamp":"1691696640.0","comment_id":"978039"},{"upvote_count":"1","content":"Selected Answer: B\nB of cpourse","timestamp":"1688347380.0","comment_id":"941349","poster":"NikkyDicky"},{"poster":"SkyZeroZx","comments":[{"poster":"nexus2020","timestamp":"1688584680.0","comment_id":"944070","content":"month end reporting is to submit the financial data, aka write the new data to DB","upvote_count":"2"}],"comment_id":"926968","timestamp":"1687133340.0","content":"Selected Answer: B\nit slows down during the final three days of each month due to month-end reporting\nthen \nhight read in database == solution add read replicas \nB","upvote_count":"2"},{"upvote_count":"1","content":"Selected Answer: B\nPerforming a one-time migration","comment_id":"851688","timestamp":"1679891880.0","poster":"mfsec"},{"timestamp":"1675119600.0","content":"Selected Answer: B\nB is the best solution","comment_id":"793433","poster":"zozza2023","upvote_count":"2"}],"answer_images":[],"question_text":"A finance company is running its business-critical application on current-generation Linux EC2 instances. The application includes a self-managed MySQL database performing heavy I/O operations. The application is working fine to handle a moderate amount of traffic during the month. However, it slows down during the final three days of each month due to month-end reporting, even though the company is using Elastic Load Balancers and Auto Scaling within its infrastructure to meet the increased demand.\n\nWhich of the following actions would allow the database to handle the month-end load with the LEAST impact on performance?","question_id":8,"question_images":[],"answer":"B","answers_community":["B (93%)","7%"],"url":"https://www.examtopics.com/discussions/amazon/view/95427-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"D":"Replacing all existing Amazon EBS volumes with new PIOPS volumes that have the maximum available storage size and I/O per second by taking snapshots before the end of the month and reverting back afterwards.","A":"Pre-warming Elastic Load Balancers, using a bigger instance type, changing all Amazon EBS volumes to GP2 volumes.","B":"Performing a one-time migration of the database cluster to Amazon RDS, and creating several additional read replicas to handle the load during end of month.","C":"Using Amazon CloudWatch with AWS Lambda to change the type, size, or IOPS of Amazon EBS volumes in the cluster based on a specific CloudWatch metric."},"unix_timestamp":1673790120},{"id":"I30bBMRC2ZxaPZPovOoF","url":"https://www.examtopics.com/discussions/amazon/view/95428-exam-aws-certified-solutions-architect-professional-sap-c02/","topic":"1","question_id":9,"answer_ET":"A","isMC":true,"question_text":"A company runs a Java application that has complex dependencies on VMs that are in the company's data center. The application is stable. but the company wants to modernize the technology stack. The company wants to migrate the application to AWS and minimize the administrative overhead to maintain the servers.\n\nWhich solution will meet these requirements with the LEAST code changes?","timestamp":"2023-01-15 14:46:00","answer_description":"","exam_id":33,"answer_images":[],"answer":"A","answers_community":["A (94%)","6%"],"choices":{"D":"Migrate the application code to a container that runs in AWS Lambda. Configure Lambda to use an Application Load Balancer (ALB). Use the ALB to interact with the application.","B":"Migrate the application code to a container that runs in AWS Lambda. Build an Amazon API Gateway REST API with Lambda integration. Use API Gateway to interact with the application.","C":"Migrate the application to Amazon Elastic Kubernetes Service (Amazon EKS) on EKS managed node groups by using AWS App2Container. Store container images in Amazon Elastic Container Registry (Amazon ECR). Give the EKS nodes permission to access the ECR image repository. Use Amazon API Gateway to interact with the application.","A":"Migrate the application to Amazon Elastic Container Service (Amazon ECS) on AWS Fargate by using AWS App2Container. Store container images in Amazon Elastic Container Registry (Amazon ECR). Grant the ECS task execution role permission 10 access the ECR image repository. Configure Amazon ECS to use an Application Load Balancer (ALB). Use the ALB to interact with the application."},"unix_timestamp":1673790360,"question_images":[],"discussion":[{"comment_id":"776623","content":"Selected Answer: A\nThe correct answer would be A, as migrating the application to Amazon Elastic Container Service (Amazon ECS) on AWS Fargate by using AWS App2Container and storing container images in Amazon Elastic Container Registry (Amazon ECR) would minimize the code changes and administrative overhead required to maintain the servers. This option would allow the company to use the Application Load Balancer (ALB) to interact with the application and the ECS task execution role permission to access the ECR image repository.\n\nOption B would require the application code to be migrated to a container that runs in AWS Lambda, which would require more code changes. \n\nOption C would require migrating the application to Amazon Elastic Kubernetes Service (Amazon EKS) which would require more administrative overhead. \n\nOption D would require configuring Lambda to use an Application Load Balancer (ALB), which is not a native feature of Lambda.","timestamp":"1673790360.0","upvote_count":"20","poster":"masetromain","comments":[{"comments":[{"content":"You are right, I mixed A with B","timestamp":"1675500780.0","poster":"Musk","comment_id":"797756","upvote_count":"1"}],"comment_id":"797752","poster":"Musk","content":"B does not say anything about Lambda. Where have you red that?","upvote_count":"1","timestamp":"1675500720.0"},{"poster":"rbm2023","comment_id":"897074","content":"There is another problem with Option B, it suggest using EKS with managed node groups and not Fargate, which breaks the requirement for reducing administrative overhead","upvote_count":"1","timestamp":"1684015200.0"},{"content":"This solution allows for the existing application code to be packaged into a container, which can then be deployed to ECS on Fargate. The use of AWS App2Container will help automate the containerization process, minimizing the need for code changes. Additionally, by using ECR to store container images, the application can continue to use the same images and dependencies that it currently relies on. The use of an Application Load Balancer (ALB) to interact with the application further simplifies the migration process by allowing the use of the existing application's endpoint.","comment_id":"776625","timestamp":"1673790480.0","poster":"masetromain","upvote_count":"4"}]},{"content":"Selected Answer: A\nAWS App2Container (A2C) is a command line tool to help you lift and shift applications that run in your on-premises data centers or on virtual machines, so that they run in containers that are managed by Amazon ECS, Amazon EKS, or AWS App Runner.\n\nMoving legacy applications to containers is often the starting point toward application modernization. There are many benefits to containerization:\n• Reduces operational overhead and infrastructure costs\n• Increases development and deployment agility\n• Standardizes build and deployment processes across an organization\nhttps://docs.aws.amazon.com/app2container/latest/UserGuide/what-is-a2c.html\nAWS Fargate is a serverless, pay-as-you-go compute engine that lets you focus on building applications without managing servers. AWS Fargate is compatible with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS).\nhttps://aws.amazon.com/fargate/","comment_id":"843345","timestamp":"1679190900.0","upvote_count":"9","poster":"zejou1"},{"timestamp":"1725255780.0","content":"A. Migrate the application to Amazon Elastic Container Service (Amazon ECS) on AWS Fargate by using AWS App2Container. Store container images in Amazon Elastic Container Registry (Amazon ECR). Grant the ECS task execution role permission 10 access the ECR image repository. Configure Amazon ECS to use an Application Load Balancer (ALB). Use the ALB to interact with the application.","poster":"amministrazione","upvote_count":"1","comment_id":"1276426"},{"timestamp":"1710686460.0","poster":"gofavad926","comment_id":"1175891","content":"Selected Answer: A\nA, ECS Fargate","upvote_count":"1"},{"content":"Selected Answer: A\nIf the keyword 'Java' has not been mentioned, Answer A would have been considered as A2C (App2Container) is valid only for Java and .Net web applications","timestamp":"1706702160.0","comment_id":"1136729","upvote_count":"2","poster":"AimarLeo"},{"timestamp":"1705669140.0","content":"Selected Answer: A\nA = correct\nB = migrating app to container to be executed in a Lambda requires more code changes\nC = EKS with managed node group requires more operations than ECS with Fargate\nD = see B","poster":"ninomfr64","comment_id":"1126684","upvote_count":"1"},{"poster":"career360guru","timestamp":"1703287380.0","upvote_count":"2","comment_id":"1103778","content":"Selected Answer: A\nOption A. Option C EKS not not valid because as using API Gateway is not needed and may require more code changes."},{"comment_id":"1071154","upvote_count":"1","poster":"severlight","content":"Selected Answer: A\nin the case of fargate capacity provider you should grant permissions to access ecr to task execution role, otherwise to ec2 instance roles which you run containers on","timestamp":"1700031420.0"},{"upvote_count":"1","comment_id":"1045455","timestamp":"1697508360.0","content":"Sorry is A","poster":"CVDON"},{"comment_id":"1045454","upvote_count":"1","timestamp":"1697508240.0","poster":"CVDON","content":"C on eks because of complex VM dependecies"},{"content":"Selected Answer: A\nit's an A","upvote_count":"1","poster":"NikkyDicky","comment_id":"941351","timestamp":"1688347560.0"},{"poster":"Maria2023","content":"Did anyone notice that part \"has complex dependencies on VMs that are in the company's data center.\"? If the application has complex dependencies on VMs then how do we migrate it to containers or lambda? Another awkward question.","upvote_count":"1","comment_id":"929801","timestamp":"1687370280.0"},{"poster":"Sarutobi","upvote_count":"1","timestamp":"1682621460.0","comment_id":"882943","content":"Selected Answer: A\nI still select A, but as someone that has migrated Java applications to AWS using AWS App2Container and RedHat S2i, this is a lot of pain."},{"comment_id":"851695","upvote_count":"1","content":"Selected Answer: A\nMigrate the application to Amazon Elastic Container Service (Amazon ECS) on AWS Fargate by using AWS App2Container.","poster":"mfsec","timestamp":"1679892000.0"},{"poster":"kiran15789","content":"Selected Answer: A\nleast code chansges","timestamp":"1678353480.0","upvote_count":"2","comment_id":"833759"},{"poster":"keonlee","content":"Selected Answer: A\nFargate, Modernize stack","comment_id":"809366","upvote_count":"2","timestamp":"1676457000.0"},{"upvote_count":"2","content":"Selected Answer: A\nLeast code changes","timestamp":"1676398800.0","comment_id":"808671","poster":"spd"},{"timestamp":"1676148420.0","upvote_count":"1","comment_id":"805666","content":"Selected Answer: A\nA is much simpler with AWS Copilot. I also don't have to deal with Lambda's cold start time. You also need to do a little bit of coding to interact with Lambda's Runtime API that are part of Lambda's base images - https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/","poster":"moota"},{"timestamp":"1675317600.0","comment_id":"795791","comments":[{"comment_id":"837502","comments":[{"poster":"hobokabobo","timestamp":"1678669200.0","comment_id":"837506","upvote_count":"1","content":"Also its an app not rest, thats more a job for a loadbalancer."}],"content":"can't agree more, however A mentions how to migrate an app on an instance to container images. That seems to be an important step. B does not.","timestamp":"1678669080.0","upvote_count":"1","poster":"hobokabobo"}],"poster":"jojom19980","upvote_count":"2","content":"Selected Answer: B\nB should be correct, why to use EKS, the question does not mention any details or complex design to use it so I will go with an easy and cost Solution"}]},{"id":"a0a9ObWhYJ4qWxABOUv8","exam_id":33,"question_id":10,"topic":"1","unix_timestamp":1673791260,"answer":"D","discussion":[{"comment_id":"779113","poster":"masetromain","upvote_count":"23","comments":[{"comments":[{"content":"If the answer explanation of why it's one option and why the other ones are not ok truly represents the correct answer then I would not say anything. I think chat gpt is very useful if you (with knowledge on mind) are able to judge what this ai machine says and validate that.","poster":"juanife","comment_id":"1355710","timestamp":"1739383260.0","upvote_count":"1"}],"content":"You always use ChatGPT to paste answers. Most of the time ChatGPT gives wrong answers do you know this?","comment_id":"840773","upvote_count":"12","poster":"testingaws123","timestamp":"1678979820.0"},{"content":"Option B is not correct because it uses a SQS queue as a buffer between the API Gateway and the Lambda function, but this does not provide failover to another region. In addition, it would also increase the latency of the system as the SQS will act as an additional layer.\n\nOption C is not correct because it deploys the Lambda function to the us-west-2 Region and creates an API Gateway endpoint in the same region. But it uses AWS Global Accelerator and an Application Load Balancer to manage traffic across the two API Gateway endpoints. However, this is not a failover solution as both regions will be active and serving traffic at the same time.","upvote_count":"3","timestamp":"1673975580.0","comment_id":"779115","poster":"masetromain"}],"content":"Selected Answer: D\nThe correct answer is D. Deploy the Lambda function and an API Gateway endpoint to the us-west-2 Region. Configure Amazon Route 53 to use a failover routing policy to route traffic for the two API Gateway endpoints. This solution meets the requirement of having a failover to another region by having a copy of the Lambda function and API Gateway endpoint in a different region, and using Route 53's failover routing policy to route traffic between the two regions.\n\nOption A is not correct because it only creates an additional API Gateway endpoint in us-west-2 and relies on Route 53's failover routing policy to direct traffic to the correct endpoint. But it does not deploy the Lambda function to the new region and this makes the failover incomplete.","timestamp":"1673975580.0"},{"comment_id":"1276433","content":"D. Deploy the Lambda function and an API Gateway endpoint to the us-west-2 Region. Configure Amazon Route 53 to use a failover routing policy to route traffic for the two API Gateway endpoints.","poster":"amministrazione","upvote_count":"1","timestamp":"1725256260.0"},{"timestamp":"1710686640.0","poster":"gofavad926","comment_id":"1175893","upvote_count":"1","content":"Selected Answer: D\nD, deploy everything in the second region and configure the failover routing policy"},{"content":"Selected Answer: D\nOption D","timestamp":"1703287560.0","poster":"career360guru","comment_id":"1103779","upvote_count":"1"},{"comment_id":"995573","upvote_count":"1","content":"Selected Answer: D\nRefer https://aws.amazon.com/blogs/architecture/implementing-multi-region-disaster-recovery-using-event-driven-architecture/","timestamp":"1693530420.0","poster":"venvig"},{"upvote_count":"1","timestamp":"1688347680.0","comment_id":"941352","content":"Selected Answer: D\nclearly D","poster":"NikkyDicky"},{"poster":"mfsec","comment_id":"851698","upvote_count":"1","timestamp":"1679892060.0","content":"Selected Answer: D\nDeploy the Lambda function and an API Gateway endpoint to the us-west-2 Region"},{"content":"Selected Answer: D\nCurrently, the default API endpoint type in API Gateway is the edge-optimized API endpoint, which enables clients to access an API through an Amazon CloudFront distribution. This typically improves connection time for geographically diverse clients. By default, a custom domain name is globally unique and the edge-optimized API endpoint would invoke a Lambda function in a single region in the case of Lambda integration. You can’t use this type of endpoint with a Route 53 active-active setup and fail-over.\n\nThe new regional API endpoint in API Gateway moves the API endpoint into the region and the custom domain name is unique per region. This makes it possible to run a full copy of an API in each region and then use Route 53 to use an active-active setup and failover.\nhttps://aws.amazon.com/blogs/compute/building-a-multi-region-serverless-application-with-amazon-api-gateway-and-aws-lambda/","timestamp":"1679191980.0","comment_id":"843354","upvote_count":"2","poster":"zejou1"},{"upvote_count":"1","poster":"God_Is_Love","comment_id":"830560","timestamp":"1678080060.0","content":"Selected Answer: D\nB is wrong, cannot direct traffic to SQS Queue ? it does not even mention posting messages to queue."},{"comment_id":"793436","upvote_count":"2","content":"Selected Answer: D\nThe correct answer is D","timestamp":"1675120140.0","poster":"zozza2023"},{"poster":"zhangyu20000","content":"D is correct\nA is not because the Lambda is in us-ease-1 but api gateway is in us-west-2. cannot cross regions","timestamp":"1673827380.0","upvote_count":"4","comment_id":"777194"},{"upvote_count":"2","comments":[{"timestamp":"1695588300.0","poster":"CProgrammer","content":"D CLEARLY States: Configure Amazon Route 53 to use a failover routing policy to route traffic for the two API Gateway endpoints. You claimed it did not , and the moderator ALLOWED IT ?!? !?","upvote_count":"1","comment_id":"1016171"},{"comment_id":"1016166","poster":"CProgrammer","upvote_count":"1","timestamp":"1695587940.0","content":"Gateway VPC endpoints provide reliable connectivity to Amazon S3 and DynamoDB without requiring an internet gateway or a NAT device for your VPC. \n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html \n\n==> IN CONTRAST \nThese are the ENDPOINTS for API Gateway:\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html\nGateway endpoint DOES NOT DIRECT TRAFFIC PERIOD"}],"comment_id":"776639","poster":"masetromain","content":"Selected Answer: A\nThe correct answer is A.\n\nIn this solution, an API Gateway endpoint is created in the us-west-2 Region. This new endpoint is configured to direct traffic to the Lambda function in us-east-1. If a failure occurs in the us-east-1 Region, Amazon Route 53's failover routing policy automatically routes traffic to the us-west-2 Region. This ensures that traffic is directed to a healthy endpoint, providing failover support for the application.\n\nB, C and D does not meet the requirement of having failover routing policy.\n\nIn B, SQS is not a failover mechanism, it is a messaging service and it does not provide failover routing.\n\nIn C, Global Accelerator and Application Load Balancer does not provide failover routing.\n\nIn D, While creating a second endpoint in the us-west-2 Region and using Amazon Route 53 to route traffic to it, it still does not provide failover routing.","timestamp":"1673791260.0"}],"question_images":[],"timestamp":"2023-01-15 15:01:00","answer_images":[],"isMC":true,"choices":{"D":"Deploy the Lambda function and an API Gateway endpoint to the us-west-2 Region. Configure Amazon Route 53 to use a failover routing policy to route traffic for the two API Gateway endpoints.","A":"Create an API Gateway endpoint in the us-west-2 Region to direct traffic to the Lambda function in us-east-1. Configure Amazon Route 53 to use a failover routing policy to route traffic for the two API Gateway endpoints.","C":"Deploy the Lambda function to the us-west-2 Region. Create an API Gateway endpoint in us-west-2 10 direct traffic to the Lambda function in us-west-2. Configure AWS Global Accelerator and an Application Load Balancer to manage traffic across the two API Gateway endpoints.","B":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Configure API Gateway to direct traffic to the SQS queue instead of to the Lambda function. Configure the Lambda function to pull messages from the queue for processing."},"answer_ET":"D","answers_community":["D (94%)","6%"],"question_text":"A company has an asynchronous HTTP application that is hosted as an AWS Lambda function. A public Amazon API Gateway endpoint invokes the Lambda function. The Lambda function and the API Gateway endpoint reside in the us-east-1 Region. A solutions architect needs to redesign the application to support failover to another AWS Region.\n\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/95432-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_description":""}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Solutions Architect - Professional SAP-C02","isMCOnly":true,"numberOfQuestions":529,"isImplemented":true,"id":33,"provider":"Amazon"},"currentPage":2},"__N_SSP":true}