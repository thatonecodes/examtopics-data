{"pageProps":{"questions":[{"id":"B1eJG4lceFfcx8Iw4H1C","exam_id":36,"discussion":[{"timestamp":"1718684340.0","comment_id":"926419","poster":"albert_kuo","upvote_count":"1","content":"Selected Answer: B\nIn the given scenario, when an object is restored from Glacier using a restore request, the restored object's storage class will not be Reduced Redundancy Storage (RRS). The storage class of the restored object will be the same as the original object, which in this case would be Glacier."},{"timestamp":"1665042240.0","poster":"gretch","upvote_count":"1","comment_id":"96211","content":"C\nYou can restore an object copy for any number of days. However you should restore objects only for the duration that you need because of the storage costs associated with the object copy. When you restore an archive, you pay for both the archive (at the S3 Glacier or S3 Glacier Deep Archive rate) and a copy that you restored temporarily (Reduced Redundancy Storage (RRS) or Standard, whichever is the lower cost storage in the region).","comments":[{"poster":"jaribu","content":"The question is asking for what is NOT true. C is true because when you request a retrieval, you specify how long your object will be retained in either RRR or Standard storage.","comment_id":"112737","timestamp":"1665576240.0","upvote_count":"2"}]},{"poster":"ThoseWereTheDays","upvote_count":"1","timestamp":"1664156640.0","comment_id":"73319","content":"B is correct.\n\nAfter you receive a temporary copy of the restored object, the object's storage class remains S3 Glacier or S3 Glacier Deep Archive. (A HEAD Object or the GET Object API operations request returns S3 Glacier or S3 Glacier Deep Archive as the storage class.)\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/restoring-objects.html"},{"content":"I think the answer is A, the archive itself will not change attribute to object, the archive will be copied to another storage tier as object.","upvote_count":"1","timestamp":"1664042220.0","poster":"kteng","comment_id":"49051"},{"content":"Comparing B & D, Does anyone can confirm , after retrieving the data from Glacier, where it will restore ?","upvote_count":"1","comment_id":"32781","poster":"karmaah","timestamp":"1663865580.0","comments":[{"poster":"jaribu","upvote_count":"1","content":"Depending on which is cheaper in your region, your retrieved objects are restored in RRR or Standard.","timestamp":"1666743540.0","comment_id":"112738"},{"upvote_count":"2","timestamp":"1664151060.0","poster":"nasa86","comment_id":"54077","content":"B & D are both wrong. The storage class does not change. Think question is wrong. I feel like all four is true."}]}],"question_images":[],"timestamp":"2019-12-26 14:43:00","answers_community":["B (100%)"],"answer_description":"AWS Glacier is an archival service offered by AWS. AWS S3 provides lifecycle rules to archive and restore objects from S3 to Glacier. Once the object is archived their storage class will change to Glacier. If the user sends a request for restore, the storage class will still be Glacier for the restored object. The user will be paying for both the archived copy as well as for the restored object. The object is available only for the duration specified in the restore request and if the user wants to modify that period, he has to raise another restore request with the updated duration.","isMC":true,"question_id":211,"question_text":"A user has moved an object to Glacier using the life cycle rules. The user requests to restore the archive after 6 months. When the restore request is completed the user accesses that archive. Which of the below mentioned statements is not true in this condition?","url":"https://www.examtopics.com/discussions/amazon/view/10935-exam-aws-sysops-topic-1-question-289-discussion/","topic":"1","choices":{"C":"The user can modify the restoration period only by issuing a new restore request with the updated period","A":"The archive will be available as an object for the duration specified by the user during the restoration request","D":"The user needs to pay storage for both RRS (restored) and Glacier (Archive. Rates)","B":"The restored object's storage class will be RRS"},"answer_ET":"B","answer":"B","answer_images":[],"unix_timestamp":1577367780},{"id":"wt8pHRLzYYzgu6IhYcer","exam_id":36,"choices":{"A":"6 Reserved instances (heavy utilization). 6 Reserved instances {medium utilization), rest covered by On-Demand instances","B":"6 Reserved instances (heavy utilization). 6 On-Demand instances, rest covered by Spot Instances","C":"6 Reserved instances (heavy utilization) 6 Spot instances, rest covered by On-Demand instances","D":"6 Reserved instances (heavy utilization) 6 Reserved instances (medium utilization) rest covered by Spot instances"},"question_text":"You run a web application where web servers on EC2 Instances are in an Auto Scaling group. Monitoring over the last 6 months shows that 6 web servers are necessary to handle the minimum load During the day up to 12 servers are needed five to six days per year, the number of web servers required might go up to\n15.\nWhat would you recommend to minimize costs while being able to provide hill availability?","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/52938-exam-aws-sysops-topic-1-question-29-discussion/","topic":"1","isMC":true,"answer_images":[],"answers_community":["B (100%)"],"question_id":212,"answer":"B","answer_description":"","discussion":[{"timestamp":"1691029200.0","content":"In this scenario, if maintaining high availability is the primary concern, it may be more advisable to rely on Reserved Instances and On-Demand instances rather than depending heavily on Spot Instances, which might have the risk of interruptions. Therefore, Option A (using Reserved Instances for both heavy and medium utilization) could be considered a safer approach to provide high availability while still minimizing costs.\n\nUltimately, both Option A and Option B could be valid choices, and the decision depends on the specific requirements and risk tolerance of the web application's workload.","upvote_count":"1","comment_id":"970687","poster":"albert_kuo"},{"upvote_count":"1","content":"Selected Answer: B\nI don't agree with A, it will imply buying some instances for a year when they are only need for some specific period of time (https://aws.amazon.com/ec2/pricing/reserved-instances/)","poster":"ablazleon","comment_id":"568822","timestamp":"1647414000.0"},{"upvote_count":"1","poster":"ceeee","comment_id":"412007","content":"Correct answer is B acually. Going with A means u are reserving 6 instances for 6 days throughout the entire year ? and for what lol. it's very expensive to do so","timestamp":"1636113240.0"},{"poster":"xxxdolorxxx","upvote_count":"1","content":"My vote goes to A.","timestamp":"1635668520.0","comment_id":"400083"},{"timestamp":"1633891560.0","comment_id":"364955","poster":"TroyMcLure","comments":[{"content":"Incorrect, Answer is B.\n\nSure, spot instances availability is not guaranteed, but so is the server traffic of 15 instances. \n\nSince your objective is to minimize costs, you will assure the 12 and provide somewhat reliable for 15. \n\n3 on-demand strikes out the “minimize costs” objective.","upvote_count":"1","timestamp":"1730830860.0","comment_id":"1307501","poster":"Sekir"},{"upvote_count":"1","poster":"Kognitiv","content":"I agree, however another major factor was cost and spot instances are more flexible in cost.","comment_id":"386402","timestamp":"1633951860.0","comments":[{"upvote_count":"2","comment_id":"386404","timestamp":"1634614320.0","poster":"Kognitiv","content":"You have 6 dedicated reserved instances for heavy utilization, 6 on demand instances for those 5/6 days out of the year. Then leave the rest up to spot instances, since it is trying to have the best of both worlds w/ Cost & HA..."}]}],"content":"Correct Answer: A\nSpot Instances shouldn't be used with this purpose because availability is not guaranteed.","upvote_count":"1"},{"upvote_count":"1","poster":"FHU","content":"Letter A.","comment_id":"359394","timestamp":"1633477920.0"}],"timestamp":"2021-05-17 10:49:00","answer_ET":"B","unix_timestamp":1621241340},{"id":"g8UouqLEK1FnUb3AUsVr","answers_community":[],"answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/16337-exam-aws-sysops-topic-1-question-290-discussion/","exam_id":36,"discussion":[{"comment_id":"368963","upvote_count":"1","content":"Correct Answer: A","poster":"TroyMcLure","timestamp":"1729960260.0"},{"poster":"awscertified","timestamp":"1727849280.0","comment_id":"62743","upvote_count":"2","content":"A. Setup the CloudWatch action to terminate the instance when the CPU utilization is less than 5%"}],"choices":{"A":"Setup the CloudWatch action to terminate the instance when the CPU utilization is less than 5%","C":"Setup a job which terminates all instances after 600 minutes","D":"It is not possible to terminate instances automatically","B":"Setup the CloudWatch with Auto Scaling to terminate all the instances"},"answer_images":[],"isMC":true,"answer_description":"Amazon CloudWatch alarm watches a single metric over a time period that the user specifies and performs one or more actions based on the value of the metric relative to a given threshold over a number of time periods. The user can setup an action which terminates the instances when their CPU utilization is below a certain threshold for a certain period of time. The EC2 action can either terminate or stop the instance as part of the EC2 action.","unix_timestamp":1583972820,"question_text":"A user is running a batch process on EBS backed EC2 instances. The batch process starts a few instances to process hadoop Map reduce jobs which can run between 50 `\" 600 minutes or sometimes for more time. The user wants to configure that the instance gets terminated only when the process is completed. How can the user configure this with CloudWatch?","question_images":[],"answer_ET":"A","timestamp":"2020-03-12 01:27:00","topic":"1","question_id":213},{"id":"Qd6gMcp2xcjg5BSe76Ld","question_text":"A user has enabled versioning on an S3 bucket. The user is using server side encryption for data at rest. If the user is supplying his own keys for encryption (SSE-\nC), what is recommended to the user for the purpose of security?","url":"https://www.examtopics.com/discussions/amazon/view/16338-exam-aws-sysops-topic-1-question-291-discussion/","answer":"D","timestamp":"2020-03-12 01:31:00","discussion":[{"content":"D. Keep rotating the encryption key manually at the client side","timestamp":"1727337000.0","poster":"awscertified","upvote_count":"3","comment_id":"62747"}],"topic":"1","answer_ET":"D","answer_images":[],"question_images":[],"answer_description":"AWS S3 supports client side or server side encryption to encrypt all data at Rest. The server side encryption can either have the S3 supplied AES-256 encryption key or the user can send the key along with each API call to supply his own encryption key (SSE-C). Since S3 does not store the encryption keys in SSE-C, it is recommended that the user should manage keys securely and keep rotating them regularly at the client side version.","question_id":214,"unix_timestamp":1583973060,"answers_community":[],"isMC":true,"choices":{"D":"Keep rotating the encryption key manually at the client side","C":"Configure S3 to store the user's keys securely with SSL","A":"The user should not use his own security key as it is not secure","B":"Configure S3 to rotate the user's encryption key at regular intervals"},"exam_id":36},{"id":"GpzssQm4SdUwWQY9jBzd","answers_community":["B (75%)","A (25%)"],"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/10895-exam-aws-sysops-topic-1-question-292-discussion/","exam_id":36,"discussion":[{"content":"Selected Answer: B\nB is correct answer\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html","timestamp":"1733104260.0","poster":"dexdinh91","upvote_count":"1","comment_id":"1085617"},{"timestamp":"1723438140.0","upvote_count":"1","poster":"albert_kuo","comment_id":"979117","content":"Selected Answer: A\nThe command dd if=/dev/xvdf of=/dev/null bs=1M is being used to read data from the EBS volume (specified as /dev/xvdf) and write it to the null device (/dev/null). This effectively reads data from the EBS volume, which is a way to access the data and pre-warm the volume.\n\nPre-warming an EBS volume involves reading all the data from the volume to ensure that it's loaded into the underlying storage blocks. This can improve the performance of the EBS volume, as it reduces the likelihood of experiencing initial latency when accessing the data for the first time."},{"timestamp":"1686015660.0","poster":"Finger41","content":"Selected Answer: B\nB - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html\n\nsudo dd if=/dev/xvdf of=/dev/null bs=1M is used to initialise your ebs volumes.","upvote_count":"2","comment_id":"612100"},{"upvote_count":"1","content":"Correct Answer: A","timestamp":"1667011620.0","comment_id":"368966","poster":"TroyMcLure"},{"poster":"Drey","timestamp":"1666295040.0","upvote_count":"3","content":"It's B. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html\n[dd] The if (input file) parameter should be set to the drive you wish to initialize. The of (output file) parameter should be set to the Linux null virtual device, /dev/null. The bs parameter sets the block size of the read operation; for optimal performance, this should be set to 1 MB.","comment_id":"360962"},{"timestamp":"1665713880.0","poster":"4007","content":"A. Pre warming the EBS volume. \nInitializing and Pre-warming mean the same thing. However, answer B says initiating (not the same meaning as initializing) and the definition is off, too. \"Empty EBS volumes receive their maximum performance the moment that they are created and do not require initialization (formerly known as pre-warming).\" https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html","comment_id":"129275","upvote_count":"1"},{"poster":"Phil31","content":"Answer is B\nThe command \"dd if=/dev/xvdf of=/dev/null bs=1M\" is used for initializing Amazon EBS Volumes.\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html\n\nThe command used for pre warming the EBS volume is \"dd if=/dev/zero of=/dev/xvdf bs=1M\" as seen previously in the question 249.","upvote_count":"2","comment_id":"87790","timestamp":"1664909460.0"},{"comment_id":"62750","timestamp":"1664543940.0","upvote_count":"1","poster":"awscertified","content":"A. Pre warming the EBS volume"},{"poster":"karmaah","comment_id":"32496","upvote_count":"1","content":"Pl review the question 245 for dd if and of values. little bit of confusion.","timestamp":"1663874520.0"}],"choices":{"B":"Initiating the device to mount on the EBS volume","A":"Pre warming the EBS volume","C":"Formatting the volume","D":"Copying the data from a snapshot to the device"},"answer_images":[],"isMC":true,"unix_timestamp":1577228760,"answer_description":"","question_images":[],"question_text":"A user runs the command `dd if=/dev/xvdf of=/dev/null bs=1M` on an EBS volume created from a snapshot and attached to a Linux instance. Which of the below mentioned activities is the user performing with the step given above?","answer_ET":"B","timestamp":"2019-12-25 00:06:00","topic":"1","question_id":215}],"exam":{"provider":"Amazon","isBeta":false,"isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":false,"numberOfQuestions":928,"name":"AWS-SysOps","id":36},"currentPage":43},"__N_SSP":true}