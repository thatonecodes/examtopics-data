{"pageProps":{"questions":[{"id":"gFPBkTCdHOcjuTHbYu0z","discussion":[{"upvote_count":"6","comment_id":"1047387","content":"Selected Answer: B\nB\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/how-to-set-lifecycle-configuration-intro.html","poster":"100fold","timestamp":"1713486360.0"},{"comment_id":"1211659","upvote_count":"1","timestamp":"1731627540.0","poster":"navid1365","content":"Selected Answer: B\nFor sure it's B."},{"poster":"Raphaello","content":"Selected Answer: B\nCorrect answer is B.\nThe question tries to trick to select Macie, since data contains sensitive data, but Macie discover and classify data, and send findings to SecurityHub or EventBridge for any action that might be needed. It does NOT delete objects.\n\nAnother thing is that S3 object lifecycle is used for 2 roles, both transition and EXPIRATION of objects.\n\nB is the correct answer.","upvote_count":"1","comment_id":"1154789","timestamp":"1724158020.0"},{"content":"Selected Answer: B\nB is self-explanatory and sufficient.","comment_id":"1087120","upvote_count":"1","poster":"Aamee","timestamp":"1717441560.0"}],"answer":"B","answer_description":"","exam_id":30,"isMC":true,"unix_timestamp":1697675160,"url":"https://www.examtopics.com/discussions/amazon/view/124009-exam-aws-certified-security-specialty-scs-c02-topic-1/","choices":{"A":"Use Amazon Macie to scan the S3 bucket for sensitive data every 72 hours. Configure Macie to delete the objects that contain sensitive data when they are discovered.","B":"Configure an S3 Lifecycle rule on the S3 bucket to expire objects that have been in the S3 bucket for 72 hours.","D":"Use the S3 Intelligent-Tiering storage class for all objects that are uploaded to the S3 bucket. Use S3 Intelligent-Tiering to expire objects that have been in the $3 bucket for 72 hours.","C":"Create an Amazon EventBridge scheduled rule that invokes an AWS Lambda function every day. Program the Lambda function to remove any objects that have been in the S3 bucket for 72 hours."},"answers_community":["B (100%)"],"topic":"1","question_text":"A company has a new partnership with a vendor. The vendor will process data from the company's customers. The company will upload data files as objects into an Amazon S3 bucket. The vendor will download the objects to perform data processing. The objects will contain sensitive data.\nA security engineer must implement a solution that prevents objects from residing in the S3 bucket for longer than 72 hours.\nWhich solution will meet these requirements?","question_id":246,"answer_images":[],"question_images":[],"timestamp":"2023-10-19 02:26:00","answer_ET":"B"},{"id":"r94uGPX8zGKM2tn15ET3","question_text":"A company accidentally deleted the private key for an Amazon Elastic Block Store (Amazon EBS)-backed Amazon EC2 instance. A security engineer needs to regain access to the instance.\nWhich combination of steps will meet this requirement? (Choose two.)","answer_description":"","answer_images":[],"isMC":true,"choices":{"A":"Stop the instance. Detach the root volume. Generate a new key pair.","E":"When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new public key. Move the volume back to the original instance that is running.","B":"Keep the instance running. Detach the root volume. Generate a new key pair.","D":"When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new private key. Move the volume back to the original instance. Start the instance.","C":"When the volume is detached from the original instance, attach the volume to another instance as a data volume. Modify the authorized_keys file with a new public key. Move the volume back to the original instance. Start the instance."},"answers_community":["AC (100%)"],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/124010-exam-aws-certified-security-specialty-scs-c02-topic-1/","answer":"AC","exam_id":30,"answer_ET":"AC","unix_timestamp":1697675280,"discussion":[{"upvote_count":"10","poster":"100fold","timestamp":"1713486480.0","content":"Selected Answer: AC\nAnswer AC\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#replacing-lost-key-pair","comment_id":"1047390"},{"timestamp":"1724158380.0","poster":"Raphaello","comment_id":"1154792","upvote_count":"3","content":"Selected Answer: AC\nAC are the correct answers.\nThere are other ways to add/replace pub key into \"authorized_keys\" file without stopping the instance, but within the context of this scenario, AC are good.\n\nRemember, \"authorized_keys\" file resides on the root volume. You cannot keep the instance running without the root volume."},{"timestamp":"1717628340.0","poster":"jeff001","comment_id":"1088913","content":"Selected Answer: AC\nA & C. Stop the instance, detach its root volume and attach it to another instance as a data volume, modify the authorized_keys file with a new public key, move the volume back to the original instance, and restart the instance","upvote_count":"2"},{"comment_id":"1083042","poster":"352ae9a","timestamp":"1716939120.0","upvote_count":"2","content":"Answer AC"}],"timestamp":"2023-10-19 02:28:00","topic":"1","question_id":247},{"id":"BBErap1INwX5mp6UXOwy","question_text":"A company purchased a subscription to a third-party cloud security scanning solution that integrates with AWS Security Hub. A security engineer needs to implement a solution that will remediate the findings from the third-party scanning solution automatically.\nWhich solution will meet this requirement?","timestamp":"2023-10-19 02:44:00","answer":"A","answer_images":[],"answers_community":["A (67%)","B (33%)"],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/124011-exam-aws-certified-security-specialty-scs-c02-topic-1/","question_id":248,"isMC":true,"unix_timestamp":1697676240,"exam_id":30,"discussion":[{"poster":"100fold","content":"Selected Answer: A\nAnswer A\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automate-remediation-for-aws-security-hub-standard-findings.html","timestamp":"1697676240.0","comment_id":"1047404","upvote_count":"8"},{"timestamp":"1708441620.0","comment_id":"1154801","poster":"Raphaello","content":"Selected Answer: A\nAnother tricking question.\nEventBridge integrates with SecurityHub in 3 different ways..\n1. All findings (SH Imported)\n2. Findings for custom actions (SH Custom Actions)\n3. Insights for custom actions (SH Insights)\n(https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-cwe-integration-types.html)\n\nYou do not always need custom actions for EB integration, and to automatically remediate findings as in this scenario, 1st type of integration is required.\n\nAnswer is A.","upvote_count":"5"},{"poster":"IPLogic","upvote_count":"1","content":"Selected Answer: A\nOption B involves setting up a custom action in Security Hub and configuring the custom action to call AWS Systems Manager Automation runbooks to remediate the findings. While this approach can be effective, it requires manual intervention to trigger the custom action. This means that someone would need to manually select the custom action for each finding, which does not fully automate the remediation process.\n\nOn the other hand, option A leverages Amazon EventBridge to automatically react to new Security Hub findings and triggers an AWS Lambda function to remediate the findings. This approach ensures that the remediation process is fully automated and immediate, without requiring any manual intervention. It provides a more seamless and efficient solution for automatically addressing security findings.","timestamp":"1733235360.0","comment_id":"1321404"},{"upvote_count":"1","content":"Selected Answer: A\nThe requirement is automate response. EventBridge rules automatically actions when triggered, while Security Hub actions are manually triggered.","timestamp":"1725843300.0","poster":"Davidng88","comment_id":"1280659"},{"content":"Selected Answer: B\nWhile Option A can work, it lacks the direct integration with custom actions in Security Hub that Option B provides. Custom actions allow you to define specific remediation steps based on findings, which is more efficient and streamlined. Therefore, I recommend considering Option B for automated remediation.\nhttps://amer.resources.awscloud.com/security-assets/aws-security-hub-automated-response-and-remediation-implementation-guide","poster":"cumzle_com","timestamp":"1718903940.0","comment_id":"1233824","comments":[{"comment_id":"1286622","upvote_count":"1","timestamp":"1726789800.0","content":"just A","poster":"helloworldabc"}],"upvote_count":"1"},{"timestamp":"1714133160.0","poster":"SamHan","content":"Selected Answer: B\nB is correct","comment_id":"1202576","upvote_count":"1"},{"comment_id":"1133087","upvote_count":"2","poster":"Derets","timestamp":"1706334900.0","content":"Selected Answer: B\nAnswer B\nCustom action is a native feature for Security Hub when using a 3rd-party library. Then you need to use Systems Manager Automation runbooks.\nAnswer A (EventBridge+Lambda) can be used for standard findings."},{"comment_id":"1104499","content":"Selected Answer: B\nVerty tricky one. A,B and C can all be implemented. and we havent asked for easy,quickly or something like that a solution. so reason for not picking others\n\nA:- could also be used but would require additional steps to configure rules to route findings from this specific third-party source to the appropriate target. Custom actions provide a native option within Security Hub.\n\nC:- identical to B. same reasoning that Custom actions provide a native option within Security Hub.\n\nto be honest i could go for any out of these three. even though i chose B. Arghhhh","timestamp":"1703406060.0","poster":"yorkicurke","comments":[{"timestamp":"1708441980.0","comment_id":"1154811","content":"I beg to disagree. \nEventBridge integration type \"SH Imported\" with automatically send all findings to EB.\nEB does not care how the findings ended up in SH. SH integration with the third party handle this, and as long as the third party tool actually integrates with SH, that means it can send findings to it. \nOnce done, findings in SH automatically sent over to EB\n(https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-cwe-integration-types.html#securityhub-cwe-integration-types-all-findings)\n\nThere you can build the action that you want.\n\nAnswer is A.","upvote_count":"2","poster":"Raphaello"}],"upvote_count":"4"},{"upvote_count":"1","poster":"Aamee","timestamp":"1701806040.0","comment_id":"1088777","content":"Selected Answer: A\nTo remediate the findings automatically, option A describes about the best practices.."}],"answer_ET":"A","answer_description":"","choices":{"A":"Set up an Amazon EventBridge rule that reacts to new Security Hub findings. Configure an AWS Lambda function as the target for the rule to remediate the findings.","B":"Set up a custom action in Security Hub. Configure the custom action to call AWS Systems Manager Automation runbooks to remediate the findings.","D":"Set up AWS Config rules to use AWS Systems Manager Automation runbooks to remediate the findings.","C":"Set up a custom action in Security Hub. Configure an AWS Lambda function as the target for the custom action to remediate the findings."},"topic":"1"},{"id":"w1XC307rywFasJx8e8i8","url":"https://www.examtopics.com/discussions/amazon/view/124012-exam-aws-certified-security-specialty-scs-c02-topic-1/","topic":"1","discussion":[{"comment_id":"1358740","poster":"AWSLoverLoverLoverLoverLover","content":"Selected Answer: C\nThe goal is to quickly prevent the compromised EC2 instance from accessing the sensitive data in S3. The fastest way to do this is:\n\nRevoke the IAM role's active session permissions\n\nThis immediately removes temporary credentials from the EC2 instance.\nUse AWS STS to revoke active session tokens:\n\nUpdate the S3 bucket policy to deny access to the IAM role\n\nEven if the instance has temporary credentials, a bucket policy denial rule will override all permissions.\nRemove the IAM role from the EC2 instance profile\n\nThis prevents the EC2 instance from obtaining new credentials.","upvote_count":"1","timestamp":"1739969340.0"},{"upvote_count":"1","poster":"sophire","content":"Selected Answer: D\nWhile Option C attempts to mitigate access by removing permissions, it does not directly address the potential misuse of the KMS key during an active session. Option D ensures an immediate and definitive block to sensitive data access, making it the more secure and fastest response to prevent exposure.\n\nIf the volume of objects is significant, re-encryption can be deferred without compromising data security because disabling the original key renders the data inaccessible.","timestamp":"1735529400.0","comment_id":"1333892"},{"poster":"Sodev","upvote_count":"1","content":"C, However, This is not a good question. what happen if \"Critical operation\" need to continue access to data on S3 ?\nIf i am a writer for this question. I will add more Answer \"Deny outbount from EC2 and routing to S3 via s3 gateway endpoint only\"","comment_id":"1190389","timestamp":"1728218340.0"},{"content":"Selected Answer: C\nD takes longer than it looks. \nIf you disable the KMS key, the data key is still usable until you try to encrypt it again. If the data key has been unencrypted within the instance, it will remain usable even after you disable the KMS and the rogue instance can keep reading info from S3.\nhttps://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#unusable-kms-keys.","timestamp":"1726949040.0","upvote_count":"2","poster":"xflare","comment_id":"1179691"},{"timestamp":"1724161260.0","poster":"Raphaello","upvote_count":"1","content":"Selected Answer: C\nD is a valid solution, but not the fastest as requested. Creating a batch operation to re-encrypt 2TB to data on S3 might take time. \nPlus, old or new KMS key are both equally same for an attacker who has access to the EC2/role that's allowed to use the key.\n\nThe solution needs to be with the role itself to eliminate further access to sensitive data.\n\nRevoke current active session permissions, set S3 bucket policy to deny the role, and remove the role altogether from EC2 instance profile.\n\nC.","comment_id":"1154825"},{"timestamp":"1718012760.0","content":"C. Revoke the IAM role's active session permissions.","poster":"Oralinux","comment_id":"1092467","upvote_count":"3"},{"comment_id":"1091422","timestamp":"1717895460.0","poster":"Daniel76","upvote_count":"2","content":"Selected Answer: C\nThis contains more detail response. Refer to part 2 for containment step. The first step is always to deal with the role access first.\nhttps://www.bicarait.com/2021/04/27/aws-incident-response-unintended-access-to-s3-bucket/\nIt only takes a few minutes for policy updates to effectively revoke the role’s temporary security credentials to force all users assuming the role to reauthenticate and request new credentials. (as compare to re-encrypt entire s3 bucket data to a single new key)\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_control-access_disable-perms.html#deny-access-to-all-sessions\nFurthermore, though unrelated to the requirement:\nThe s3 bucket may be encrypted by multiple data keys which is intended. by re-encrypting the entire bucket, you may affect data that are encrypted by other legitimate keys unaffected by this vulnerable ec2."},{"upvote_count":"1","content":"Still v confusing btw C and D.... but I'd probably go with C.","timestamp":"1716562560.0","poster":"Aamee","comment_id":"1079432"},{"comments":[{"poster":"confusedyeti69","content":"If your bucket has millions of objects, re-encryption is slower. Ans is C","comments":[{"comment_id":"1088786","content":"No, that's not the point here. The req. is to implement it 'FASTER' to get it secured on the first attempt which I also feel Option D provides it. Disabling the key right away can atleast help ensure that no sensitive data would get exposed further IMO... and then the rest of the steps to re-encrypting the data can be done as a 2nd step to follow...","poster":"Aamee","timestamp":"1717611240.0","upvote_count":"1"}],"timestamp":"1717556460.0","upvote_count":"1","comment_id":"1088192"}],"poster":"kejam","content":"Selected Answer: D\nAnswer D. The fastest way to prevent sensitive data from being exposed is to disable the current key.\n\nA. Not fast\nB. Not fast\nC. AWSRevokeOlderSessions is fast, however bad actors can immediately reconnect with new sessions before you remove the IAM role from the EC2 instance profile. If these steps were reversed to prevent that its no longer the fastest solution because its 2 steps.\nD. Disable the current key... 1st step prevents sensitive data exposure and the rest of the steps to re-encrypt the data with a new key can follow.","upvote_count":"3","comment_id":"1067550","timestamp":"1715371800.0"},{"comment_id":"1047407","timestamp":"1713487680.0","content":"Selected Answer: C\nAnswer C\nhttps://www.examtopics.com/discussions/amazon/view/60659-exam-aws-certified-security-specialty-topic-1-question-287/","poster":"100fold","upvote_count":"3"}],"exam_id":30,"choices":{"C":"Revoke the IAM role's active session permissions. Update the S3 bucket policy to deny access to the IAM role. Remove the IAM role from the EC2 instance profile.","D":"Disable the current key. Create a new KMS key that the IAM role does not have access to, and re-encrypt all the data with the new key. Schedule the compromised key for deletion.","A":"Download the data from the existing S3 bucket to a new EC2 instance. Then delete the data from the S3 bucket. Re-encrypt the data with a client-based key. Upload the data to a new S3 bucket.","B":"Block access to the public range of S3 endpoint IP addresses by using a host-based firewall. Ensure that internet-bound traffic from the affected EC2 instance is routed through the host-based firewall."},"answer":"C","answers_community":["C (69%)","D (31%)"],"question_images":[],"question_id":249,"isMC":true,"answer_description":"","question_text":"An application is running on an Amazon EC2 instance that has an IAM role attached. The IAM role provides access to an AWS Key Management Service (AWS KMS) customer managed key and an Amazon S3 bucket. The key is used to access 2 TB of sensitive data that is stored in the S3 bucket.\nA security engineer discovers a potential vulnerability on the EC2 instance that could result in the compromise of the sensitive data. Due to other critical operations, the security engineer cannot immediately shut down the EC2 instance for vulnerability patching.\nWhat is the FASTEST way to prevent the sensitive data from being exposed?","answer_images":[],"answer_ET":"C","timestamp":"2023-10-19 02:48:00","unix_timestamp":1697676480},{"id":"i2PjKe01Tf0d5dJz5mNw","discussion":[{"content":"Selected Answer: C\nCorrect answer is C.\nIt covers the required areas to protect sensitive data, without least overhead.","poster":"Raphaello","timestamp":"1724194500.0","comment_id":"1155112","upvote_count":"1"},{"poster":"kejam","comment_id":"1067553","upvote_count":"4","timestamp":"1715372280.0","content":"Selected Answer: C\nAnswer C\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_turn-on-for-db.html"},{"upvote_count":"4","poster":"100fold","comment_id":"1047409","timestamp":"1713487800.0","content":"Selected Answer: C\nAnswer C\nhttps://www.examtopics.com/discussions/amazon/view/60739-exam-aws-certified-security-specialty-topic-1-question-268/"}],"answer":"C","answer_description":"","exam_id":30,"isMC":true,"unix_timestamp":1697676600,"url":"https://www.examtopics.com/discussions/amazon/view/124013-exam-aws-certified-security-specialty-scs-c02-topic-1/","answers_community":["C (100%)"],"choices":{"D":"Set up an AWS CloudHSM cluster with AWS Key Management Service (AWS KMS) to store KMS keys. Set up Amazon RDS encryption using AWS KMS to encrypt the database. Store database credentials in the AWS Systems Manager Parameter Store with automatic rotation. Set up TLS for the connection to the RDS hosted database.","A":"Enable Amazon RDS encryption to encrypt the database and snapshots. Enable Amazon Elastic Block Store (Amazon EBS) encryption on Amazon EC2 instances. Include the database credential in the EC2 user data field. Use an AWS Lambda function to rotate database credentials. Set up TLS for the connection to the database.","B":"Install a database on an Amazon EC2 instance. Enable third-party disk encryption to encrypt the Amazon Elastic Block Store (Amazon EBS) volume. Store the database credentials in AWS CloudHSM with automatic rotation. Set up TLS for the connection to the database.","C":"Enable Amazon RDS encryption to encrypt the database and snapshots. Enable Amazon Elastic Black Store (Amazon EBS) encryption on Amazon EC2 instances. Store the database credentials in AWS Secrets Manager with automatic rotation. Set up TLS for the connection to the RDS hosted database."},"question_id":250,"topic":"1","question_text":"A company is building an application on AWS that will store sensitive information. The company has a support team with access to the IT infrastructure, including databases. The company’s security engineer must introduce measures to protect the sensitive data against any data breach while minimizing management overhead. The credentials must be regularly rotated.\nWhat should the security engineer recommend?","answer_images":[],"question_images":[],"timestamp":"2023-10-19 02:50:00","answer_ET":"C"}],"exam":{"isBeta":false,"numberOfQuestions":288,"name":"AWS Certified Security - Specialty SCS-C02","isImplemented":true,"isMCOnly":true,"lastUpdated":"11 Apr 2025","provider":"Amazon","id":30},"currentPage":50},"__N_SSP":true}