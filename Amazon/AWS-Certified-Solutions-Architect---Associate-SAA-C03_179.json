{"pageProps":{"questions":[{"id":"2rcCnImhxskH3lHjLAK5","question_text":"A company has deployed a multi-account strategy on AWS by using AWS Control Tower. The company has provided individual AWS accounts to each of its developers. The company wants to implement controls to limit AWS resource costs that the developers incur.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","answers_community":["B (73%)","C (27%)"],"topic":"1","exam_id":31,"question_images":[],"choices":{"C":"Use AWS Cost Explorer to monitor and report on costs for each developer account. Configure Cost Explorer to send a daily report to each developer to monitor their spending. Use AWS Cost Anomaly Detection to detect anomalous spending and provide alerts.","D":"Use AWS Service Catalog to allow developers to launch resources within a limited cost range. Create AWS Lambda functions in each AWS account to stop running resources at the end of each work day. Configure the Lambda functions to resume the resources at the start of each work day.","A":"Instruct each developer to tag all their resources with a tag that has a key of CostCenter and a value of the developer's name. Use the required-tags AWS Config managed rule to check for the tag. Create an AWS Lambda function to terminate resources that do not have the tag. Configure AWS Cost Explorer to send a daily report to each developer to monitor their spending.","B":"Use AWS Budgets to establish budgets for each developer account. Set up budget alerts for actual and forecast values to notify developers when they exceed or expect to exceed their assigned budget. Use AWS Budgets actions to apply a DenyAll policy to the developer's IAM role to prevent additional resources from being launched when the assigned budget is reached."},"unix_timestamp":1714487400,"timestamp":"2024-04-30 16:30:00","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/139799-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":891,"discussion":[{"timestamp":"1714487400.0","content":"Selected Answer: B\nMy first instinct says B, but Im concerned about the central management abilities of AWS Budgets. It seems that even though it is not planned to be used primarily to control other accounts its still possible:\n\"You can use actions to define an explicit response that you want to take when a budget exceeds its action threshold. You can trigger these alerts on actual or forecasted cost and usage budgets.\n1. The management account sets the budget and threshold for the member account using budget filters.\n2. When the budget threshold is breached, a budget action applies a restrictive SCP on the OU.\n\nSo hopefully B :D","comment_id":"1204613","upvote_count":"5","poster":"sandordini"},{"timestamp":"1716893700.0","poster":"Scheldon","content":"Selected Answer: B\nAnswerB\n\nhttps://docs.aws.amazon.com/cost-management/latest/userguide/budgets-controls.html\nTaking into consideration that AWS Budgets is allowing to will inform you that you exceeded budged and execute actions like for example IAM actions to prevent running new resources in cloud, I think this option is a good and resonable move. In case of need budged can be always increased and \"chains\" disabled.","comment_id":"1220158","upvote_count":"5"},{"poster":"LeonSauveterre","upvote_count":"1","comment_id":"1335374","comments":[{"poster":"LeonSauveterre","content":"The gist is, when you reach the limit, you must be stopped. It's the only way to prevent unexpected expenses. Reports, monitors, analyses, logs, charts, they DON'T work.","timestamp":"1735798200.0","upvote_count":"1","comment_id":"1335375"}],"content":"Selected Answer: B\nA - Tags help monitor costs, and AWS Config can enforce tagging rules, but manually tagging is TOO MUCH WORK.\nB - Preventive (aka not reactive) cost control, good. Too provocative? Yeah, maybe. Developers might experience disruption if they hit their budget limits unexpectedly, and then the cost a little over the budget might not seem like a problem anymore... BUT this is actually a preventive approach with \"the LEAST operational overhead\".\nC - \"Daily reports\" might be too late.\nD - It can limit resource usage during non-working hours, but overall, you gotta deal with high operational overhead.","timestamp":"1735798020.0"},{"poster":"MatAlves","timestamp":"1726903440.0","upvote_count":"2","comment_id":"1287196","content":"Selected Answer: B\nAs beautifully explained in this article:\n\nhttps://docs.aws.amazon.com/cost-management/latest/userguide/budgets-controls.html"},{"comment_id":"1232665","upvote_count":"3","content":"Selected Answer: B\n(A) is eliminated. 'send a daily report to each developer' can be ignored.\n(C) is eliminated. 'detect anomalous spending' won't stop the spending.\n(D) is eliminated. 'stop running resources at the end of each work day' won't stop developers from mining bitcoin ($$$) the next day.\n(B) is correct. 'actions to apply a DenyAll policy..' is the only solution that will 'implement controls to limit AWS resource costs that the developers incur.'","comments":[{"comment_id":"1287193","timestamp":"1726903380.0","poster":"MatAlves","content":"I'd definitely be mining bitcoin the next day...","upvote_count":"3"}],"timestamp":"1718757120.0","poster":"NSA_Poker"},{"content":"Selected Answer: C\nSeem AWS Budgets does not have DenyAll function but only \n\nApply a custom Deny IAM policy that restricts the ability for a user, group, or role to provision additional Amazon EC2 resources","poster":"f07ed8f","timestamp":"1716369900.0","comment_id":"1215606","upvote_count":"2"},{"comment_id":"1205572","poster":"BBR01","upvote_count":"4","timestamp":"1714656540.0","content":"Selected Answer: C\nB and D are too aggressive. \nA - \"Instruct each developer\", nope, too much operational work."}],"isMC":true,"answer_ET":"B","answer_description":"","answer":"B"},{"id":"g3ECemwYPiE1wdb24kgF","choices":{"C":"Configure the security group for the database tier to allow inbound Microsoft SQL Server traffic from the security group for the application tier.","D":"Configure the security group for the database tier to allow outbound HTTPS traffic and Microsoft SQL Server traffic to the security group for the web tier.","A":"Configure the security group for the web tier to allow inbound HTTPS traffic from the security group for the ALB.","B":"Configure the security group for the web tier to allow outbound HTTPS traffic to 0.0.0.0/0.","F":"Configure the security group for the application tier to allow outbound HTTPS traffic and Microsoft SQL Server traffic to the security group for the web tier.","E":"Configure the security group for the application tier to allow inbound HTTPS traffic from the security group for the web tier."},"answers_community":["ACE (100%)"],"unix_timestamp":1714487940,"answer_ET":"ACE","answer_images":[],"answer":"ACE","topic":"1","timestamp":"2024-04-30 16:39:00","answer_description":"","question_id":892,"exam_id":31,"isMC":true,"discussion":[{"comments":[{"timestamp":"1718539740.0","content":"Agree since security group is stateful so allow inbound is enough","upvote_count":"2","poster":"KennethNg923","comment_id":"1231357"}],"comment_id":"1231167","upvote_count":"6","poster":"EdricHoang","content":"Selected Answer: ACE\nSecurity group is stateful, just need allow Inbound.","timestamp":"1718497440.0"},{"upvote_count":"1","comment_id":"1363583","content":"Selected Answer: ACE\nSince SG's are stateful , allow inbound only. Ignore all outbound roles","timestamp":"1740840660.0","poster":"sk1974"},{"poster":"Scheldon","comment_id":"1220186","upvote_count":"3","content":"Selected Answer: ACE\nAnswerACE:\n\nSecurity Group is protecting instances, it's statefull. by defoult is allowing for outgoing traffic but not incomming.\nhence we need to allow for inboud traffic. path looks like below\nALB >>HTTPS>> WEB tier >>HTTPS>> Application >>SQL traffic>> SQL DB\nhence we need allow for \nincoming https traffic on web tier \nthen \nincomming http on app tier \nand on the end for\nincomming sql traffic on DB tier","timestamp":"1716895920.0"},{"poster":"sandordini","comment_id":"1204622","upvote_count":"4","content":"Selected Answer: ACE\nALB >>HTTPS>> WEB tier >>HTTPS>> Application >>SQL traffic>> SQL DB","timestamp":"1714487940.0"}],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/139800-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A solutions architect is designing a three-tier web application. The architecture consists of an internet-facing Application Load Balancer (ALB) and a web tier that is hosted on Amazon EC2 instances in private subnets. The application tier with the business logic runs on EC2 instances in private subnets. The database tier consists of Microsoft SQL Server that runs on EC2 instances in private subnets. Security is a high priority for the company.\n\nWhich combination of security group configurations should the solutions architect use? (Choose three.)"},{"id":"lXMxSCFy8POjSfVauDDA","unix_timestamp":1714488180,"question_text":"A company has released a new version of its production application. The company's workload uses Amazon EC2, AWS Lambda, AWS Fargate, and Amazon SageMaker.\n\nThe company wants to cost optimize the workload now that usage is at a steady state. The company wants to cover the most services with the fewest savings plans.\n\nWhich combination of savings plans will meet these requirements? (Choose two.)","question_id":893,"answer_images":[],"discussion":[{"content":"Selected Answer: CD\nIt's pretty obvious, although it's called: Machine Learning Savings Plans for Amazon SageMaker (C)\nFor the compute workloads we need a compute savings plan, that covers all the 3 compute options we use here (EC2, Lambda and Fargate) (D)","upvote_count":"8","poster":"sandordini","comment_id":"1204624","timestamp":"1714488180.0"},{"upvote_count":"4","timestamp":"1729657200.0","poster":"mk168898","comment_id":"1301866","content":"just pick the 2 options that doesn't overlap"},{"timestamp":"1718123040.0","content":"Selected Answer: CD\nno doubt","upvote_count":"3","poster":"mattyu","comment_id":"1228528"},{"upvote_count":"3","comment_id":"1220189","timestamp":"1716896160.0","content":"Answer CD\n\nhttps://aws.amazon.com/savingsplans/ml-pricing/\nhttps://aws.amazon.com/savingsplans/compute-pricing/","poster":"Scheldon"}],"question_images":[],"answer":"CD","isMC":true,"choices":{"E":"Purchase an EC2 Instance Savings Plan for Amazon EC2 and Fargate.","A":"Purchase an EC2 Instance Savings Plan for Amazon EC2 and SageMaker.","C":"Purchase a SageMaker Savings Plan.","D":"Purchase a Compute Savings Plan for Lambda, Fargate, and Amazon EC2.","B":"Purchase a Compute Savings Plan for Amazon EC2, Lambda, and SageMaker."},"topic":"1","answer_ET":"CD","exam_id":31,"answer_description":"","timestamp":"2024-04-30 16:43:00","answers_community":["CD (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/139801-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"TAxcSuGW3Y8RjZ1dANMd","exam_id":31,"answer_images":[],"choices":{"D":"Use Amazon RDS Proxy to connect the applications to Aurora PostgreSQL.","A":"Use the AWS Schema Conversion Tool (AWS SCT) to rewrite the SQL queries in the applications.","E":"Use AWS Database Migration Service (AWS DMS) to rewrite the SQL queries in the applications.","B":"Enable Babelfish on Aurora PostgreSQL to run the SQL queries from the applications.","C":"Migrate the database schema and data by using the AWS Schema Conversion Tool (AWS SCT) and AWS Database Migration Service (AWS DMS)."},"question_id":894,"answer_ET":"BC","url":"https://www.examtopics.com/discussions/amazon/view/139802-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1714488480,"question_images":[],"topic":"1","isMC":true,"question_text":"A company uses a Microsoft SQL Server database. The company's applications are connected to the database. The company wants to migrate to an Amazon Aurora PostgreSQL database with minimal changes to the application code.\n\nWhich combination of steps will meet these requirements? (Choose two.)","timestamp":"2024-04-30 16:48:00","answer_description":"","answer":"BC","answers_community":["BC (100%)"],"discussion":[{"content":"Selected Answer: BC\nB: Babelfish for Aurora PostgreSQL is a new capability for Amazon Aurora PostgreSQL-Compatible Edition that enables Aurora to understand commands from applications written for Microsoft SQL Server.\nC: Is just obvious: Use Data Migration Tool for the migration, Schema Conversion tool for the Schema conversion.","poster":"sandordini","upvote_count":"5","comment_id":"1204629","timestamp":"1714488480.0","comments":[{"upvote_count":"3","comment_id":"1212035","poster":"pranavsharma1604","timestamp":"1715790660.0","content":"https://aws.amazon.com/rds/aurora/babelfish/"}]},{"timestamp":"1735800540.0","upvote_count":"1","content":"Selected Answer: BC\nA - AWS SCT does not directly rewrite SQL queries in the application code. This would require manual updates.\nB - Babelfish allows Aurora PostgreSQL to understand SQL Server’s native T-SQL language and protocol.\nC - Convert the schema & migrate the data effectively, good.\nD - Amazon RDS Proxy improves database scalability and availability (if the question mentions something like having trouble conneting during peek hours or whatnot then RDS Proxy is likely the answer) but does not address the compatibility issues between SQL Server and Aurora PostgreSQL.\nE - This is not enough. Refer to option C.","comment_id":"1335382","poster":"LeonSauveterre"},{"content":"Selected Answer: BC\nDMS + SCT is correct, but \" rewrite the SQL queries in the applications.\" is wrong so A + E are out.\nThen only left B + C -> DMS + SCT + Babekfish (for SQL Server)","poster":"KennethNg923","upvote_count":"2","comment_id":"1231359","timestamp":"1718539980.0"},{"timestamp":"1716971520.0","content":"Selected Answer: BC\nAnswerBC\nDMS will allow for DATABASE migration and use AWS Schema Conversion Tool (AWS SCT) to create some or all of the target tables, indexes, views, triggers, and so on.\nhttps://docs.aws.amazon.com/dms/latest/userguide/Welcome.html\nTo minimalize amount of code which need to me changes we need to use babelfish\nhttps://aws.amazon.com/rds/aurora/babelfish/","comment_id":"1220764","poster":"Scheldon","upvote_count":"2"},{"upvote_count":"4","comment_id":"1212036","content":"Selected Answer: BC\nhttps://aws.amazon.com/rds/aurora/babelfish/","timestamp":"1715790720.0","poster":"pranavsharma1604"}]},{"id":"yyZgTj9UIshBMuILamAZ","discussion":[{"timestamp":"1716972300.0","upvote_count":"9","content":"Selected Answer: A\nAnswerA\nThe task is to force automatic encryption for every new EBS volume and prevent possibility of creation any unencrypted volume hence:\n\nhttps://docs.aws.amazon.com/ebs/latest/userguide/work-with-ebs-encr.html#ebs-encryption_key_mgmt\nTo enable encryption by default for a Region\nOpen the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n\nFrom the navigation bar, select the Region.\n\nFrom the navigation pane, select EC2 Dashboard.\n\nIn the upper-right corner of the page, choose Account Attributes, Data protection and security.\n\nChoose Manage.\n\nSelect Enable. You keep the AWS managed key with the alias alias/aws/ebs created on your behalf as the default encryption key, or choose a symmetric customer managed encryption key.\n\nChoose Update EBS encryption.","poster":"Scheldon","comment_id":"1220769"},{"upvote_count":"1","timestamp":"1736910240.0","poster":"FlyingHawk","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/ebs/latest/userguide/encryption-by-default.html\nYou can configure your AWS account to enforce the encryption of the new EBS volumes and snapshot copies that you create. For example, Amazon EBS encrypts the EBS volumes created when you launch an instance and the snapshots that you copy from an unencrypted snapshot. For examples of transitioning from unencrypted to encrypted EBS resources, see https://docs.aws.amazon.com/ebs/latest/userguide/ebs-encryption.html#encrypt-unencrypted: To enable encryption by default for a Region\n%aws ec2 enable-ebs-encryption-by-default --region region\n\n\n\nIn the upper-right corner of the page, choose Account Attributes, Data protection and security.","comment_id":"1340641"},{"comment_id":"1335383","timestamp":"1735801380.0","upvote_count":"1","poster":"LeonSauveterre","content":"Selected Answer: B\nA - This automatically encrypts all newly created volumes, but can't prevent unencrypted volumes.\nB - AWS Config can enforce and automate compliance by using a rule to check whether all EBS volumes are encrypted.\nC - Creating encrypted copies of volumes after they are created? Why bother to do this\nD - What does Migration Hub have to do with this... I don't understand."},{"timestamp":"1733490660.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/ebs/latest/userguide/encryption-by-default.html","comment_id":"1322755","poster":"Xandero","upvote_count":"1"},{"poster":"EdricHoang","comment_id":"1243727","upvote_count":"3","timestamp":"1720335240.0","content":"Selected Answer: B\n\"The solution must also prevent the creation of unencrypted EBS volumes.\" \nFor prevention future actions, I go for AWS config. You can setup Encryption in EC2, but Its manual process, what happen if you add one or more EC2?"},{"upvote_count":"1","content":"AnswerA\n\nhttps://docs.aws.amazon.com/ebs/latest/userguide/work-with-ebs-encr.html#ebs-encryption_key_mgmt\nTo enable encryption by default for a Region\nOpen the Amazon EC2 console at https://console.aws.amazon.com/ec2/.\n\nFrom the navigation bar, select the Region.\n\nFrom the navigation pane, select EC2 Dashboard.\n\nIn the upper-right corner of the page, choose Account Attributes, Data protection and security.\n\nChoose Manage.\n\nSelect Enable. You keep the AWS managed key with the alias alias/aws/ebs created on your behalf as the default encryption key, or choose a symmetric customer managed encryption key.\n\nChoose Update EBS encryption.","poster":"Scheldon","comment_id":"1220768","timestamp":"1716972120.0"},{"timestamp":"1716125640.0","comment_id":"1213810","poster":"0bdf3af","upvote_count":"2","content":"A. https://repost.aws/knowledge-center/ebs-automatic-encryption"},{"upvote_count":"3","timestamp":"1715577900.0","poster":"lsomas","content":"Selected Answer: B\nAs it needs to prevent creation of Unencrypted EBS volume","comment_id":"1210715"},{"timestamp":"1715350620.0","comments":[{"comment_id":"1320471","timestamp":"1733034180.0","poster":"JA2018","content":"From Google Translate\n\nB is OK, AWS Config to automatically identify unencrypted EBS volumes and apply corrective action. A,C,D: Incorrect, do not comply with","upvote_count":"1"}],"upvote_count":"3","content":"B es correcto , AWS Config para identificar automáticamente los volúmenes de EBS no cifrados y aplicar una acción correctiva.A,C,D : incorrectas , no cumplen con el cifrado automático","comment_id":"1209412","poster":"viejito"}],"answer_ET":"A","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/140296-exam-aws-certified-solutions-architect-associate-saa-c03/","unix_timestamp":1715350620,"timestamp":"2024-05-10 16:17:00","topic":"1","choices":{"D":"Create a customer managed key in AWS Key Management Service (AWS KMS). Configure AWS Migration Hub to use the key when the company migrates workloads.","B":"Use AWS Config. Configure the encrypted-volumes identifier. Apply the default AWS Key Management Service (AWS KMS) key.","C":"Configure AWS Systems Manager to create encrypted copies of the EBS volumes. Reconfigure the EC2 instances to use the encrypted volumes.","A":"Configure the EC2 account attributes to always encrypt new EBS volumes."},"answer_description":"","exam_id":31,"question_id":895,"question_images":[],"question_text":"A company plans to rehost an application to Amazon EC2 instances that use Amazon Elastic Block Store (Amazon EBS) as the attached storage.\n\nA solutions architect must design a solution to ensure that all newly created Amazon EBS volumes are encrypted by default. The solution must also prevent the creation of unencrypted EBS volumes.\n\nWhich solution will meet these requirements?","answers_community":["A (61%)","B (39%)"],"answer":"A","isMC":true}],"exam":{"isImplemented":true,"id":31,"provider":"Amazon","name":"AWS Certified Solutions Architect - Associate SAA-C03","lastUpdated":"11 Apr 2025","isBeta":false,"isMCOnly":true,"numberOfQuestions":1019},"currentPage":179},"__N_SSP":true}