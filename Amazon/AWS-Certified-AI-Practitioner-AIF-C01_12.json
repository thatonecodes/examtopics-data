{"pageProps":{"questions":[{"id":"yOwQGOpDapCQN1SbDfDW","answer_ET":"C","timestamp":"2024-11-04 19:14:00","answers_community":["C (100%)"],"question_id":56,"answer_description":"","answer":"C","question_images":[],"answer_images":[],"isMC":true,"unix_timestamp":1730744040,"topic":"1","exam_id":14,"url":"https://www.examtopics.com/discussions/amazon/view/150732-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","choices":{"B":"Training time for each epoch","C":"Average response time","A":"Customer satisfaction score (CSAT)","D":"Number of training instances"},"discussion":[{"poster":"jove","timestamp":"1730828940.0","content":"Selected Answer: C\nAverage response time refers to the time taken by an AI model to produce a result after receiving an input. It is a critical metric for assessing the runtime efficiency of an AI model during inference, particularly in applications where quick responses are essential, such as in real-time applications or interactive systems.","comment_id":"1307492","upvote_count":"7"},{"upvote_count":"1","content":"Selected Answer: C\nO tempo médio de resposta mede a eficiência do tempo de execução de um modelo operacional de IA — ou seja, quanto tempo ele leva para processar uma solicitação e Retornar uma resposta. Isso é crucial em ambientes de produção onde a latência pode impactar a experiência do usuário e a performance do sistema. As outras opções não medem diretamente a eficiência operacional em tempo de execução: A. CSAT (Customer Satisfaction Score) avalia a satisfação do cliente, não o desempenho técnico do modelo.\n\nB. Tempo de treinamento por época mede a eficiência durante o treinamento, e não durante a execução operacional. D. Número de instâncias de treinamento refere-se à infraestrutura usada, mas não mede eficiência diretamente.","poster":"Rcosmos","timestamp":"1744219860.0","comment_id":"1559328"},{"upvote_count":"1","timestamp":"1739326020.0","content":"Selected Answer: C\nAverage response time measures how quickly the AI model can generate a result after receiving input. This is a key metric for runtime efficiency, as it directly reflects how fast the model operates during inference or real-time usage. Lower response times indicate higher runtime efficiency.","comment_id":"1355338","poster":"Jessiii"},{"upvote_count":"2","content":"Selected Answer: C\nC: Average response time\n\nExplanation:\nAverage response time is a key metric for measuring the runtime efficiency of operating AI models. It indicates how quickly the AI model processes a request and returns a response, which is critical for assessing the performance and efficiency of deployed models, especially in real-time applications.","poster":"Moon","timestamp":"1735612440.0","comment_id":"1334567"},{"content":"Selected Answer: C\nAverage response time measures how quickly an AI model produces predictions or outputs during runtime, making it a key metric for evaluating the runtime efficiency of AI models.\nIt reflects the latency users experience when interacting with the model, which is especially critical for applications like chatbots, recommendation systems, or fraud detection.","comment_id":"1332687","upvote_count":"1","poster":"ap6491","timestamp":"1735344120.0"},{"timestamp":"1730744040.0","poster":"LR2023","comment_id":"1307051","upvote_count":"4","content":"Selected Answer: C\nYes, \"average response time\" is the primary metric used to measure the runtime efficiency of operating AI models, as it directly reflects how quickly a model can produce a prediction or response to a given input"}],"question_text":"Which metric measures the runtime efficiency of operating AI models?"},{"id":"Nw9bSq4kY9vf3NPqmwG6","choices":{"D":"Use prompt engineering.","C":"Train a new FM.","B":"Retrain the FM.","A":"Fine-tune the FM."},"answer_description":"","exam_id":14,"question_images":[],"topic":"1","answer_images":[],"question_text":"A company wants to improve the accuracy of the responses from a generative AI application. The application uses a foundation model (FM) on Amazon Bedrock.\n\nWhich solution meets these requirements MOST cost-effectively?","answer":"D","unix_timestamp":1744046100,"answer_ET":"D","isMC":true,"question_id":57,"url":"https://www.examtopics.com/discussions/amazon/view/302411-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answers_community":["D (100%)"],"discussion":[{"timestamp":"1744046100.0","poster":"Rcosmos","content":"Selected Answer: D\nA solução mais econômica é D. Use engenharia rápida.\n\nA técnica de engenharia rápida permite melhorar a precisão das respostas sem a necessidade de ajustar ou treinar novamente o modelo, o que pode ser bastante custoso em termos de tempo e recursos computacionais. A engenharia rápida envolve a criação de prompts mais eficazes e direcionados, otimizando os resultados gerados pelo modelo com investimentos mínimos.","upvote_count":"1","comment_id":"1558678"}],"timestamp":"2025-04-07 19:15:00"},{"id":"py2XCPTrIglJnlnQPpVG","discussion":[{"upvote_count":"1","poster":"Rcosmos","content":"Selected Answer: B\nA estratégia correta é B. Use a detecção de toxicidade do Amazon Comprehend.\n\nO Amazon Comprehend é um serviço que utiliza processamento de linguagem natural (NLP) para analisar texto e identificar linguagem prejudicial, como comentários tóxicos. Ele permite detectar automaticamente padrões de toxicidade sem depender de dados rotulados para treinamento, tornando-se uma solução eficaz para esse caso de uso.","comment_id":"1558679","timestamp":"1744046160.0"}],"answer":"B","isMC":true,"timestamp":"2025-04-07 19:16:00","exam_id":14,"answer_description":"","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/302412-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","choices":{"B":"Use Amazon Comprehend toxicity detection.","A":"Use Amazon Rekognition moderation.","D":"Use Amazon Polly to monitor comments.","C":"Use Amazon SageMaker built-in algorithms to train the model."},"question_images":[],"answer_ET":"B","question_text":"A company wants to identify harmful language in the comments section of social media posts by using an ML model. The company will not use labeled data to train the model.\n\nWhich strategy should the company use to identify harmful language?","answer_images":[],"question_id":58,"unix_timestamp":1744046160,"topic":"1"},{"id":"1OWu3TPS1N32FuO0NU91","timestamp":"2025-04-07 19:17:00","answer":"D","discussion":[{"timestamp":"1744046220.0","content":"Selected Answer: D\nA opção correta é D. Monitor de modelos do Amazon SageMaker.\n\nO Amazon SageMaker Model Monitor é ideal para monitorar continuamente o desempenho de modelos de aprendizado de máquina implantados em produção. Ele ajuda a identificar possíveis desvios de qualidade ou mudanças nos padrões dos dados ao longo do tempo, garantindo que o modelo continue funcionando conforme esperado. Esse recurso é essencial para acompanhar mudanças no comportamento e na demografia dos espectadores enquanto recomenda conteúdo personalizado.","poster":"Rcosmos","comment_id":"1558680","upvote_count":"1"}],"unix_timestamp":1744046220,"answer_images":[],"question_text":"A media company wants to analyze viewer behavior and demographics to recommend personalized content. The company wants to deploy a customized ML model in its production environment. The company also wants to observe if the model quality drifts over time.\n\nWhich AWS service or feature meets these requirements?","answer_ET":"D","answer_description":"","choices":{"C":"Amazon Comprehend","A":"Amazon Rekognition","B":"Amazon SageMaker Clarify","D":"Amazon SageMaker Model Monitor"},"topic":"1","exam_id":14,"isMC":true,"answers_community":["D (100%)"],"question_id":59,"url":"https://www.examtopics.com/discussions/amazon/view/302413-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","question_images":[]},{"id":"2nfbnhRonOYvxGsLPXFL","answer_description":"","answer":"U","unix_timestamp":1744046280,"answer_ET":"A","topic":"1","answers_community":["U (100%)"],"answer_images":[],"question_text":"A company is deploying AI/ML models by using AWS services. The company wants to offer transparency into the models’ decision-making processes and provide explanations for the model outputs.\n\nWhich AWS service or feature meets these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/302414-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","discussion":[{"poster":"Rcosmos","upvote_count":"1","content":"Selected Answer: U\nA resposta correta é A. Cartões de modelo do Amazon SageMaker.\n\nOs cartões de modelo do Amazon SageMaker são projetados para promover a transparência e explicabilidade, documentando informações detalhadas sobre a finalidade do modelo, seu desempenho, limitações e processos de tomada de decisão. Eles ajudam a fornecer explicações claras e padronizadas dos resultados do modelo, sendo uma ferramenta ideal para atender a esses requisitos.","comment_id":"1558681","timestamp":"1744046280.0"}],"question_id":60,"exam_id":14,"choices":{"C":"Amazon Comprehend","B":"Amazon Rekognition","D":"Amazon Lex","A":"Amazon SageMaker Model Cards"},"timestamp":"2025-04-07 19:18:00","question_images":[],"isMC":true}],"exam":{"numberOfQuestions":154,"isImplemented":true,"provider":"Amazon","isBeta":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified AI Practitioner AIF-C01","id":14,"isMCOnly":false},"currentPage":12},"__N_SSP":true}