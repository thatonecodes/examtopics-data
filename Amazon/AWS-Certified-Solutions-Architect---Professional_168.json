{"pageProps":{"questions":[{"id":"1P3CAF00eAb06Vee40EE","answer_images":[],"discussion":[{"comment_id":"653583","content":"D seems to be the answer. No need to separately create the train in the member accounts. https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","timestamp":"1661795520.0","upvote_count":"5","poster":"Rocketeer"},{"content":"Selected Answer: C\nC - one management trail for all accounts no need to deliver logs for external system (not required in the question)","comment_id":"632250","poster":"asfsdfsdf","timestamp":"1657987380.0","upvote_count":"5"},{"upvote_count":"1","poster":"Jesuisleon","timestamp":"1685193240.0","comment_id":"908006","content":"C is the answer.\nAmazon will NOT recommendate 3rd party softwares/ external management systems to the clients. that doesnt make sense. IT's AMAZON exam. so D is out."},{"comment_id":"791302","timestamp":"1674956700.0","content":"Option C,\nIdeally It is best practice to configure CloudTrail in each member account, rather than in a single management account. This way, you can ensure that all API calls made within each account are being logged and tracked.\nBut the ask in the question specifically says \"Tracked Changes \" which means versioning needs to be enabled .","upvote_count":"1","poster":"Heer"},{"comment_id":"715782","upvote_count":"2","timestamp":"1668145980.0","content":"Selected Answer: C\nS3 version for durable","poster":"due"},{"timestamp":"1666383840.0","comment_id":"701148","poster":"vijay1319","upvote_count":"3","content":"Selected Answer: C\ntracked for changes == versioning"},{"timestamp":"1666383780.0","poster":"vijay1319","content":"tracked for changes == versioning","upvote_count":"1","comment_id":"701147"},{"comment_id":"700231","content":"Selected Answer: C\nVersioning is required for MFA delete. Answer has to be C","upvote_count":"3","timestamp":"1666293300.0","poster":"redipa"},{"upvote_count":"3","content":"Selected Answer: C\nexternal management system means management overhead","poster":"aandc","comment_id":"627728","timestamp":"1657085460.0"},{"timestamp":"1653022080.0","upvote_count":"4","comment_id":"604240","content":"C is correct","poster":"solo18"},{"timestamp":"1650652920.0","poster":"shailurtm2001","comment_id":"590203","upvote_count":"2","content":"D correct."}],"topic":"1","answer":"C","unix_timestamp":1650652920,"url":"https://www.examtopics.com/discussions/amazon/view/74165-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"answers_community":["C (100%)"],"answer_description":"","question_id":836,"timestamp":"2022-04-22 20:42:00","question_text":"A financial services company sells its software-as-a-service (SaaS) platform for application compliance to large global banks. The SaaS platform runs on AWS and uses multiple AWS accounts that are managed in an organization in AWS Organizations. The SaaS platform uses many AWS resources globally.\nFor regulatory compliance, all API calls to AWS resources must be audited, tracked for changes, and stored in a durable and secure data store.\nWhich solution will meet these requirements with the LEAST operational overhead?","exam_id":32,"isMC":true,"answer_ET":"C","choices":{"D":"Create a new AWS CloudTrail trail in the organization's management account. Create a new Amazon S3 bucket to store the logs. Configure Amazon Simple Notification Service (Amazon SNS) to send log-file delivery notifications to an external management system that will track the logs. Enable MFA delete and encryption on the S3 bucket.","C":"Create a new AWS CloudTrail trail in the organization's management account. Create a new Amazon S3 bucket with versioning turned on to store the logs. Deploy the trail for all accounts in the organization. Enable MFA delete and encryption on the S3 bucket.","A":"Create a new AWS CloudTrail trail. Use an existing Amazon S3 bucket in the organization's management account to store the logs. Deploy the trail to all AWS Regions. Enable MFA delete and encryption on the S3 bucket.","B":"Create a new AWS CloudTrail trail in each member account of the organization. Create new Amazon S3 buckets to store the logs. Deploy the trail to all AWS Regions. Enable MFA delete and encryption on the S3 buckets."}},{"id":"sc82w9a9cmmfGx59Ftak","timestamp":"2022-04-22 18:43:00","answers_community":["ACF (41%)","ABC (29%)","CDF (21%)","6%"],"url":"https://www.examtopics.com/discussions/amazon/view/74154-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"ACF","topic":"1","exam_id":32,"question_id":837,"choices":{"F":"Migrate the MySQL database to run on an Amazon RDS for MySQL Multi-AZ DB instance that uses General Purpose SSD (gp3) storage.","D":"Run the web service on an ECS cluster that has a Fargate launch type. Use AWS CodePipeline and AWS CodeDeploy to perform a canary deployment to update the ECS service.","C":"Configure an Amazon Simple Queue Service (Amazon SQS) queue as an event source to receive the POST requests from the web service. Configure an AWS Lambda function to poll the queue. Write the data to the database.","E":"Configure an Amazon Simple Queue Service (Amazon SQS) queue. Install the SQS agent on the containers that run in the ECS cluster to poll the queue. Write the data to the database.","B":"Migrate the MySQL database to run on an Amazon RDS for MySQL Multi-AZ DB instance that uses Provisioned IOPS SSD (io2) storage.","A":"Run the web service on an ECS cluster that has a Fargate launch type. Use AWS CodePipeline and AWS CodeDeploy to perform a blue/green deployment with validation testing to update the ECS service."},"answer":"ACF","discussion":[{"content":"Selected Answer: ABC\nSince it is a business critical app need Blue-Green with validation, therefore A, canary might cause error for some users.\nRDS doesnt support GP3 but moving to RDS is essential, therefore B must be right.\nC to save costs - SQS and Lambda","poster":"pinhead900","upvote_count":"7","timestamp":"1663525260.0","comment_id":"672667","comments":[{"content":"This makes the new gp3 volumes ideal for a wide variety of applications that require high performance at low cost, including MySQL, Cassandra, virtual desktops, and Hadoop analytics clusters","upvote_count":"1","comment_id":"673953","poster":"Cloudxie","timestamp":"1663663680.0"}]},{"upvote_count":"1","timestamp":"1693489860.0","poster":"rsn","comment_id":"995164","content":"Selected Answer: AEF\nIt has to be either a Lambda based solution or ECS based solution. Not both.. If you chose C, then there must be an option to say how it is being deployed. So I go with AEF"},{"timestamp":"1685302020.0","content":"Selected Answer: ACF\nDepends on the date for this question.\nA - Blue Green, because you want to test first and then green light the new version. Canary is not a good option in this case because it might maintain the failed requests.\nC - using SQS with a lambda will decouple the functionalities and as far as I know there is no SQS agent mentioned on option E.\nF - Amazon RDS now supports new General Purpose gp3 storage volumes. General purpose would be more cost effective as B suggests provisioned IOPS i would go with F.\nPosted On: Nov 9, 2022 \nhttps://aws.amazon.com/about-aws/whats-new/2022/11/amazon-rds-general-purpose-gp3-storage-volumes/","poster":"rbm2023","comment_id":"908838","upvote_count":"2"},{"poster":"Jesuisleon","timestamp":"1685195160.0","comment_id":"908024","content":"Selected Answer: ACF\nA seems better than D. Both blue/green deployment and canary deployment can fullfil this task, but from this link https://aws.amazon.com/blogs/containers/create-a-pipeline-with-canary-deployments-for-amazon-ecs-using-aws-app-mesh/ , canary seems to need AWS App Mesh while for blue/green just CodePipeline. To be honest, I am not sure.\n\nC is right, everyone agrees with it.\n\nF is right than B. see this :\"General Purpose SSD gp3 storage is supported on Single-AZ and Multi-AZ DB instances, but isn't supported on Multi-AZ DB clusters. For more information, see Configuring and managing a Multi-AZ deployment and Multi-AZ DB cluster deployments.\" from \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html\n\nGP3 support RDS Multi-AZ instances not support RDS Multi-AZ clusters, so F is cost-effectiveness","upvote_count":"2"},{"timestamp":"1668144780.0","comment_id":"715777","content":"RDS do support gp3 volumes but not on MultiAZ configuration,\nBlue/Green Deployment over canary so the answer is ABC","poster":"breathingcloud","upvote_count":"2"},{"comments":[{"content":"gp3 storage\nBy using General Purpose SSD gp3 storage volumes, you can customize storage performance independently of storage capacity. Storage performance is the combination of I/O operations per second (IOPS) and how fast the storage volume can perform reads and writes (storage throughput). On gp3 storage volumes, Amazon RDS provides a baseline storage performance of 3000 IOPS and 125 MiBps.\n\nFor every RDS DB engine except RDS for SQL Server, when the storage size for gp3 volumes reaches a certain threshold, the baseline storage performance increases to 12,000 IOPS and 500 MiBps. This is because of volume striping, where the storage uses four logical volumes instead of one. RDS for SQL Server doesn't support volume striping, and therefore doesn't have a threshold value.","comment_id":"712535","poster":"Jonfernz","timestamp":"1667757420.0","upvote_count":"1"}],"content":"Selected Answer: ACF\nIt's ACF. RDS has gp3 now.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","timestamp":"1667757360.0","comment_id":"712533","upvote_count":"2","poster":"Jonfernz"},{"timestamp":"1667382540.0","poster":"alxjandroleiva","comment_id":"709734","content":"Selected Answer: CDF\ncost-effectiveness","upvote_count":"1"},{"poster":"fais1985","content":"Correct Answer :- ABC\nA - prevent 502 errors , but expensive\nB - Supports GP2, PIOPS & Magnetic Only \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html\nC - SQS+ Lambda Cost saving","upvote_count":"1","timestamp":"1666972500.0","comment_id":"706596"},{"content":"My Choice is ACF","poster":"Ni_yot","timestamp":"1666376940.0","upvote_count":"1","comment_id":"701102"},{"comments":[{"upvote_count":"2","content":"it does support gp3. - https://aws.amazon.com/blogs/aws/new-amazon-ebs-gp3-volume-lets-you-provision-performance-separate-from-capacity-and-offers-20-lower-price/","comment_id":"701101","timestamp":"1666376880.0","poster":"Ni_yot"}],"content":"Selected Answer: AC\nA- Make more sens than Canary to prevent 502 bad gateway - OK\nB- io2 - not available for RDS MySQL - not OK\nC- SQS + Lambda > installing SQS agent - OK\nD- A is a better option for not facing 502 Bad gtw - not OK\nE- wrong option - not OK\nF- gp3 - not available for RDS MySQL - not OK\n\nRDS MySQL actually support only gp2 & io1 storage.\n\nI can only have two good answer: A & C \nThis is a very difficult one!","timestamp":"1664994420.0","upvote_count":"2","poster":"Blair77","comment_id":"687131"},{"timestamp":"1661439240.0","poster":"kadev","upvote_count":"4","comment_id":"651839","content":"ACF\nB is wrong: iOPS not cost-effectiveness\nD is wrong: canary will replace all tasks => could cause 502 err again\nE: SQS agent is not exist, you need use sdk to build procuder and consumer\nAbout F : i think that is a typing errer (General Purpose SSD is clearly but he typo gp3 instead of gp2)"},{"content":"Selected Answer: ABC\nABC because RDS does not support GP3 right now","timestamp":"1661387340.0","comment_id":"651548","poster":"foureye2004","upvote_count":"3","comments":[{"timestamp":"1664994660.0","comment_id":"687135","content":"B - io2 is not available for RDS MySQL...","poster":"Blair77","upvote_count":"1"}]},{"comment_id":"650283","upvote_count":"2","poster":"gnic","content":"Selected Answer: CDF\nCDF -> canary deployment, cost-effective","timestamp":"1661172420.0"},{"comment_id":"632257","upvote_count":"3","poster":"asfsdfsdf","content":"Selected Answer: ACF\nACF -\nThe only concern is about D which is more cost effective - however it may cause some users to report errors if.\nSo if its a dependable solution it must be blue/green even its expensive no other choice as the question is not allowing failures.\nGP3 is + MultAZ will provide good cost effective solution For DB part\nAnd SQS will make sure no drop of data - you dont need to install an agent for this if using lambda","timestamp":"1657988280.0"},{"comments":[{"content":"I would go ABC too.\ngp2 isn't for DBs.","comment_id":"637645","poster":"hilft","timestamp":"1658873220.0","upvote_count":"2","comments":[{"poster":"Blair77","upvote_count":"1","timestamp":"1664994840.0","comment_id":"687139","content":"Cone on guys, gp2 is exactly for RDS DB!\nhttps://aws.amazon.com/fr/blogs/database/best-storage-practices-for-running-production-workloads-on-hosted-databases-with-amazon-rds-or-amazon-ec2/"}]}],"comment_id":"628549","content":"A. You need Blue/Green over Canary for HA. \nB. AWS doesn't recommend GP2/3 for database\nC. SQS + Lambda > installing SQS agent\n\nIt's ABC","timestamp":"1657240620.0","poster":"hilft","upvote_count":"2"},{"content":"CDF. Canary -> cost effective","timestamp":"1656595200.0","comment_id":"625278","poster":"aandc","upvote_count":"3"},{"content":"Selected Answer: ACF\nACF.\nThere is a consensus for C.\nWhy A? app is mission critical and question asks for HA. Blue/Green is gives your much better HA than canary.\nWhy F? - there isnâ€™t anything in question premise that hints towards provisioned IOPS or any issue with IO per se. On the contrary, question asks for cost effectiveness. So, live with GP instead of provisioned IOPS.","timestamp":"1655070300.0","comment_id":"615505","comments":[{"comment_id":"617962","comments":[{"content":"The question states that users should not receive errors. With Canary, that is entirely possible. With answer A, it includes testing before switching over to the new deployment.","upvote_count":"1","poster":"sb333","timestamp":"1664929320.0","comment_id":"686498"}],"content":"Consideration is HA + Costs. Canary is also safe for deployment, though as not HA as b/g, while cost wise, it's cheaper. \nhttps://aws.amazon.com/about-aws/whats-new/2020/02/amazon-elastic-container-service-support-canary-deployments/\nhttps://harness.io/blog/continuous-verification/blue-green-canary-deployment-strategies/","upvote_count":"1","timestamp":"1655504100.0","poster":"wannaaws"}],"poster":"makpk","upvote_count":"1"},{"poster":"Jonfernz","timestamp":"1654504860.0","content":"Selected Answer: CDF\nCanary over blue/green simply because they want a cost effective solution. With canary, you would use nodes on a smaller scale. So D over A. Info: https://circleci.com/blog/canary-vs-blue-green-downtime/\n\nYou're gonna need something to pull the data from SQS - Lambda required. And there is no such thing as an SQS agent anyway. So the answer is C.\n\nAs for GP3 vs io2 ...let's think about this. GP3 offers 99.98% durability vs IO2's 99.9999%. But this question wants us to take cost into consideration. So let's calculate the difference in operating costs.\n\nFor a 100GB volume with 16,000 IOPS and 256 MiB/s, gp3 would cost $78 per month (i.e. 0.08*100 + 0.005 * (16000-3000) + 0.04 * (256-125)), and io2 would cost $1052 per month (i.e. 0.125*100 + 0.065*16000.\n\nFor me it's CDF based on the answers given. Although in the real world, you would rarely see Fargate being used because running on EC2 is 1.3 times cheaper.","comment_id":"612265","upvote_count":"4"},{"content":"BCD\n\nB. AWS recommends faster storage over the general-purpose SSD for DBs. IOPS > GP\nC. SQS + Lambda to decouple\nD. There seems debate between blue/green vs. Canary. The question is asking for highly accesible and cost-effective solution. Canary > blue/green.","comment_id":"611611","poster":"hilft","upvote_count":"1","timestamp":"1654385100.0"},{"timestamp":"1653748740.0","poster":"bogdan_alex","upvote_count":"2","content":"Selected Answer: ACF\nI'll go with ACF","comment_id":"608428"},{"content":"I think the answer BCD is correct, as A (Bluegreen deployment is not cost effective).","comment_id":"593139","poster":"JYZ","timestamp":"1651061100.0","upvote_count":"1"},{"upvote_count":"1","content":"A , because there is validation testing and blue/green deployment. C because answer E says SQS agent which does not exist and F because its cost effective. So answer ACF","comment_id":"592043","timestamp":"1650938700.0","poster":"jyrajan69"},{"poster":"Bigbearcn","upvote_count":"1","content":"ACF. use ECS cluster to put the post data to SQS and Lambda poll the SQS then wirte to DB.\nE option is wrong.","timestamp":"1650810540.0","comment_id":"591111"},{"poster":"shailurtm2001","upvote_count":"1","content":"Seems like ACF is correct.","comment_id":"590205","timestamp":"1650653520.0"},{"content":"Selected Answer: ACF\nACF\nA - blue/green deployment to ensure there are no bad requests\nC - SQS + Lambda to make sure all data is written to the DB\nF - multi-az DB with SSD to save costs (there is no need for IOPS)","timestamp":"1650645780.0","comment_id":"590125","poster":"snakecharmer2","upvote_count":"2"}],"unix_timestamp":1650645780,"answer_description":"","answer_images":[],"question_text":"A retail company runs a business-critical web service on an Amazon Elastic Container Service (Amazon ECS) cluster that runs on Amazon EC2 instances. The web service receives POST requests from end users and writes data to a MySQL database that runs on a separate EC2 instance. The company needs to ensure that data loss does not occur.\nThe current code deployment process includes manual updates of the ECS service. During a recent deployment, end users encountered intermittent 502 Bad\nGateway errors in response to valid web requests.\nThe company wants to implement a reliable solution to prevent this issue from recurring. The company also wants to automate code deployments. The solution must be highly available and must optimize cost-effectiveness.\nWhich combination of steps will meet these requirements? (Choose three.)","question_images":[],"isMC":true},{"id":"l1g7CPvY7wJlNwaXtI18","topic":"1","answer":"C","question_id":838,"timestamp":"2022-04-22 21:15:00","answers_community":["C (100%)"],"unix_timestamp":1650654900,"question_text":"A company has multiple AWS accounts as part of an organization created with AWS Organizations. Each account has a VPC in the us-east-2 Region and is used for either production or development workloads. Amazon EC2 instances across production accounts need to communicate with each other, and EC2 instances across development accounts need to communicate with each other, but production and development instances should not be able to communicate with each other.\nTo facilitate connectivity, the company created a common network account. The company used AWS Transit Gateway to create a transit gateway in the us-east-2\nRegion in the network account and shared the transit gateway with the entire organization by using AWS Resource Access Manager. Network administrators then attached VPCs in each account to the transit gateway, after which the EC2 instances were able to communicate across accounts. However, production and development accounts were also able to communicate with one another.\nWhich set of steps should a solutions architect take to ensure production traffic and development traffic are completely isolated?","question_images":[],"isMC":true,"answer_description":"","choices":{"B":"Create a tag on each VPC attachment with a value of either production or development, according to the type of account being attached. Using the Network Manager feature of AWS Transit Gateway, create policies that restrict traffic between VPCs based on the value of this tag.","C":"Create separate route tables for production and development traffic. Delete each account's association and route propagation to the default AWS Transit Gateway route table. Attach development VPCs to the development AWS Transit Gateway route table and production VPCs to the production route table, and enable automatic route propagation on each attachment.","D":"Create a tag on each VPC attachment with a value of either production or development, according to the type of account being attached. Modify the AWS Transit Gateway routing table to route production tagged attachments to one another and development tagged attachments to one another.","A":"Modify the security groups assigned to development EC2 instances to block traffic from production EC2 instances. Modify the security groups assigned to production EC2 instances to block traffic from development EC2 instances."},"answer_images":[],"answer_ET":"C","exam_id":32,"discussion":[{"content":"C is correct. attach different route table.\nhttps://aws.amazon.com/cn/blogs/architecture/field-notes-working-with-route-tables-in-aws-transit-gateway/","poster":"Bigbearcn","timestamp":"1650813060.0","comment_id":"591130","upvote_count":"6"},{"timestamp":"1672764900.0","content":"Selected Answer: C\nC is the correct answer \nhttps://docs.aws.amazon.com/vpc/latest/tgw/tgw-transit-gateways.html","upvote_count":"1","comment_id":"764888","poster":"evargasbrz"},{"content":"Selected Answer: C\nIt's C\nhttps://docs.aws.amazon.com/vpc/latest/tgw/how-transit-gateways-work.html","poster":"gnic","timestamp":"1661946240.0","upvote_count":"1","comment_id":"655039"},{"comment_id":"632325","poster":"asfsdfsdf","content":"Selected Answer: C\nC is the only correct way to fully segregate between VPCs (different route tables)","timestamp":"1657996800.0","upvote_count":"3"},{"timestamp":"1652027040.0","poster":"tartarus23","upvote_count":"2","comment_id":"598615","content":"Selected Answer: C\nC. The production and development route tables and VPC should be disassociated and configured separately using AWS transit gateway then route propagation enabled for the respective VPC attachments."},{"content":"Should be C.","comment_id":"590214","upvote_count":"1","poster":"shailurtm2001","timestamp":"1650654900.0"}],"url":"https://www.examtopics.com/discussions/amazon/view/74166-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"PnY9OAzK04AvdCo3hDQY","timestamp":"2022-04-24 19:12:00","isMC":true,"question_text":"A company is using an Amazon EMR cluster to run its big data jobs. The cluster's jobs are invoked by AWS Step Functions Express Workflows that consume various Amazon Simple Queue Service (Amazon SQS) queues. The workload of this solution is variable and unpredictable. Amazon CloudWatch metrics show that the cluster's peak utilization is only 25% at times and that the cluster sits idle the rest of the time.\nA solutions architect must optimize the costs of the cluster without negatively impacting the time it takes to run the various jobs.\nWhat is the MOST cost-effective solution that meets these requirements?","exam_id":32,"question_id":839,"url":"https://www.examtopics.com/discussions/amazon/view/74352-exam-aws-certified-solutions-architect-professional-topic-1/","answer":"D","choices":{"B":"Modify the EMR cluster to use an instance fleet of Dedicated On-Demand Instances for the master node and core nodes, and to use Spot Instances for the task nodes. Define target capacity for each node type to cover the load.","C":"Purchase Reserved Instances for the master node and core nodes. Terminate all existing task nodes in the EMR cluster.","A":"Modify the EMR cluster by turning on automatic scaling of the core nodes and task nodes with a custom policy that is based on cluster utilization. Purchase Reserved Instance capacity to cover the master node.","D":"Modify the EMR cluster to use capacity-optimized Spot Instances and a diversified task fleet. Define target capacity for each node type with a mix of On- Demand Instances and Spot Instances."},"topic":"1","discussion":[{"comment_id":"651203","content":"Selected Answer: A\nA. \nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-automatic-scaling.html","poster":"nyshaa","timestamp":"1661339700.0","upvote_count":"10"},{"content":"Selected Answer: A\nI'll go with A. \nB -> is more expensive than A.\nD-> can negatively impacting the time it takes to run the various jobs.","upvote_count":"1","poster":"evargasbrz","timestamp":"1672765260.0","comment_id":"764892"},{"comment_id":"715804","timestamp":"1668149340.0","content":"Selected Answer: D\ncluster's peak utilization is only 25% at times and that the cluster sits idle the rest of the time\n\nneed to optimized","upvote_count":"2","poster":"due"},{"comment_id":"700232","poster":"fdoxxx","comments":[{"timestamp":"1666293900.0","upvote_count":"2","comment_id":"700244","content":"changing to A - RI for master node is better than On-Demand","poster":"fdoxxx"}],"timestamp":"1666293300.0","content":"The key part of the question is \"without negatively impacting the time it takes to run the various jobs.\" So Spot Instance for master node seems not to be perfect choice. I am going for B. \nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html#emr-dev-master-instance-group-spot:~:text=label%2Dexpression%3A%20%27CORE%27-,Master%20node%20on%20a%20Spot%20Instance,are%20running%20the%20entire%20cluster%20(all%20instance%20groups)%20as%20Spot%20Instances.,-Core%20nodes%20on","upvote_count":"1"},{"timestamp":"1665841140.0","poster":"AwsBRFan","comment_id":"695429","content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/big-data/optimizing-amazon-emr-for-resilience-and-cost-with-capacity-optimized-spot-instances/","upvote_count":"4"},{"poster":"skywalker","content":"A\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-scale-on-demand.html","timestamp":"1665208560.0","upvote_count":"1","comment_id":"689057"},{"timestamp":"1662310320.0","comment_id":"659409","poster":"Ni_yot","content":"I also thinks its A. Automatic scaling with a custom policy in Amazon EMR release versions 4.0 and later allows you to programmatically scale out and scale in core nodes and task nodes based on a CloudWatch metric and other parameters that you specify in a scaling policy. Automatic scaling with a custom policy is available with the instance groups configuration and is not available when you use instance fleets. For more information about instance groups and instance fleets, see Create a cluster with instance fleets or uniform instance groups.","upvote_count":"3"},{"content":"Selected Answer: B\nB for me","timestamp":"1661103060.0","upvote_count":"3","comment_id":"649846","poster":"asfsdfsdf"},{"upvote_count":"1","content":"Selected Answer: B\nBetween B and D, You cannot use spot for master hence B","comment_id":"646791","timestamp":"1660490220.0","poster":"Harithareddynn"},{"timestamp":"1659159180.0","upvote_count":"1","poster":"cen007","content":"Selected Answer: B\nReserved Or Dedicated for master node, spot for task nodes","comment_id":"639483"},{"upvote_count":"3","timestamp":"1658062620.0","poster":"Enigmaaaaaa","content":"Selected Answer: D\nWill go with D due to the below:\nhttps://aws.amazon.com/blogs/big-data/strategies-for-reducing-your-amazon-emr-costs/\nhttps://aws.amazon.com/blogs/big-data/optimizing-amazon-emr-for-resilience-and-cost-with-capacity-optimized-spot-instances/\nThe correct is answer is a combining both A and D since the question asks for \"minimizing the time required to perform numerous workloads\" it has to be D.\nhttps://aws.amazon.com/blogs/big-data/best-practices-for-resizing-and-automatic-scaling-in-amazon-emr/","comments":[{"upvote_count":"3","timestamp":"1658135160.0","content":"Changing to A.\nYou cant define mix of on-demand and spot to master node type","comment_id":"632946","poster":"Enigmaaaaaa"}],"comment_id":"632557"},{"upvote_count":"2","poster":"wannaaws","timestamp":"1655516340.0","comment_id":"618037","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-instance-fleet.html"},{"comment_id":"591173","upvote_count":"3","poster":"Bigbearcn","content":"Selected Answer: D\nD is ok. \nhttps://aws.amazon.com/blogs/big-data/optimizing-amazon-emr-for-resilience-and-cost-with-capacity-optimized-spot-instances/","comments":[{"poster":"Bigbearcn","comment_id":"591179","upvote_count":"3","content":"A auto scaling is also workable. but auto scaling need instance group that each node type (master, core, or task) consists of the same instance type and the same purchasing option for instances:On-Demand or Spot. To optimizing cost, D is better.","timestamp":"1650820560.0"},{"comments":[{"upvote_count":"1","poster":"pixepe","timestamp":"1663064100.0","content":"Correction:\nB makes more sense; as task nodes are Spot instances (and remember that task nodes are stateless)\n\n\nD is incorrect, because master node can either be OnDemand or Spot instance, But NOT a MIX of it - Requirement (Define target capacity for each node type with a mix of On- Demand Instances and Spot Instances. Most Voted)","comment_id":"667855","comments":[{"content":"Correcting it to A\nThe workload of this solution is variable and unpredictable => We need auto-scaling.\nIf they have mentioned EMR managed scaling for B, than only B would have been better. In B there is no mention of scaling, \n\nSo answer is A","poster":"pixepe","upvote_count":"1","comment_id":"695335","timestamp":"1665829260.0"}]}],"upvote_count":"1","comment_id":"659672","poster":"pixepe","content":"Seems D is correct based on link https://aws.amazon.com/blogs/big-data/optimizing-amazon-emr-for-resilience-and-cost-with-capacity-optimized-spot-instances/","timestamp":"1662343980.0"}],"timestamp":"1650820320.0"}],"unix_timestamp":1650820320,"answer_ET":"D","answer_images":[],"question_images":[],"answers_community":["D (47%)","A (37%)","B (17%)"],"answer_description":""},{"id":"kOAED2oaWtAH0CPXpU9N","unix_timestamp":1650821880,"answer_description":"","choices":{"D":"Create an AWS Direct Connect connection between the on-premises data center and AWS. Establish an AWS Site-to-Site VPN connection between all VPCs in each Region. Create VPC peering connections that initiate from the central VPC to all other VPCs.","A":"Create an AWS Site-to-Site VPN connection between the on-premises data center and a new central VPC. Create VPC peering connections that initiate from the central VPC to all other VPCs.","C":"Create an AWS Site-to-Site VPN connection between the on-premises data center and a new central VPC. Use a transit gateway with dynamic routing. Connect the transit gateway to all other VPCs.","B":"Create an AWS Direct Connect connection between the on-premises data center and AWS. Provision a transit VIF, and connect it to a Direct Connect gateway. Connect the Direct Connect gateway to all the other VPCs by using a transit gateway in each Region."},"answer":"B","answer_ET":"B","question_text":"A company needs to establish a connection from its on-premises data center to AWS. The company needs to connect all of its VPCs that are located in different\nAWS Regions with transitive routing capabilities between VPC networks. The company also must reduce network outbound traffic costs, increase bandwidth throughput, and provide a consistent network experience for end users.\nWhich solution will meet these requirements?","topic":"1","answer_images":[],"discussion":[{"upvote_count":"7","comment_id":"591186","poster":"Bigbearcn","content":"Selected Answer: B\nI'll go for B. VPCs in multiple region needs TGW in each region to connect.","comments":[{"upvote_count":"1","comment_id":"597906","content":"true , you need transit gateway to connect between regions","poster":"user0001","timestamp":"1651877160.0"}],"timestamp":"1650821880.0"},{"upvote_count":"1","timestamp":"1658063100.0","comment_id":"632558","content":"Selected Answer: B\nTransit GW + Direct Connect GW + Transit VIF + enabled SiteLink if two different DX locations\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/introducing-aws-direct-connect-sitelink/","poster":"Enigmaaaaaa"},{"comments":[{"comment_id":"631711","timestamp":"1657883820.0","poster":"CloudHandsOn","upvote_count":"1","content":"Eliminated 2* of the answers."}],"content":"First answer I came to was B. One requirement of 'boost bandwidth throughput' sort of eliminated 3 of them for me, when comparing VPN to Direct Connect.","timestamp":"1657883700.0","upvote_count":"1","poster":"CloudHandsOn","comment_id":"631710"},{"content":"Selected Answer: B\nThere are three stipulations we must meet:\n- transitive routing\n- cut network outbound traffic expenditures\n- boost bandwidth throughput.\nSo first a transit gateway would cover, two other - correct correct\nSo it's B.","comment_id":"593249","timestamp":"1651071300.0","poster":"bobsmith2000","comments":[{"comment_id":"593250","timestamp":"1651071360.0","upvote_count":"1","poster":"bobsmith2000","content":"So first a transit gateway would cover, two other - direct connect"}],"upvote_count":"2"}],"answers_community":["B (100%)"],"isMC":true,"timestamp":"2022-04-24 19:38:00","question_id":840,"url":"https://www.examtopics.com/discussions/amazon/view/74358-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"exam_id":32}],"exam":{"lastUpdated":"11 Apr 2025","isMCOnly":false,"numberOfQuestions":1019,"provider":"Amazon","isImplemented":true,"name":"AWS Certified Solutions Architect - Professional","id":32,"isBeta":false},"currentPage":168},"__N_SSP":true}