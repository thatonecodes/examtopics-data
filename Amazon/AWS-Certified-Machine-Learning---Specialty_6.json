{"pageProps":{"questions":[{"id":"8njH3ttlHXxg9asCqbB8","url":"https://www.examtopics.com/discussions/amazon/view/44080-exam-aws-certified-machine-learning-specialty-topic-1/","answer_ET":"D","answer":"D","answers_community":["D (93%)","7%"],"answer_description":"","timestamp":"2021-02-05 19:56:00","answer_images":[],"question_text":"A data scientist uses an Amazon SageMaker notebook instance to conduct data exploration and analysis. This requires certain Python packages that are not natively available on Amazon SageMaker to be installed on the notebook instance.\nHow can a machine learning specialist ensure that required packages are automatically available on the notebook instance for the data scientist to use?","question_id":26,"choices":{"C":"Use the conda package manager from within the Jupyter notebook console to apply the necessary conda packages to the default kernel of the notebook.","B":"Create a Jupyter notebook file (.ipynb) with cells containing the package installation commands to execute and place the file under the /etc/init directory of each Amazon SageMaker notebook instance.","D":"Create an Amazon SageMaker lifecycle configuration with package installation commands and assign the lifecycle configuration to the notebook instance.","A":"Install AWS Systems Manager Agent on the underlying Amazon EC2 instance and use Systems Manager Automation to execute the package installation commands."},"discussion":[{"comment_id":"284343","poster":"[Removed]","upvote_count":"20","content":"I would select D. See AWS documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-add-external.html","timestamp":"1664040060.0"},{"timestamp":"1731834960.0","poster":"u_b","comment_id":"1073135","upvote_count":"2","content":"by excluding wrong options:\nA you might not have access to the EC2 instance => out\nB no automation => out\nC only the default kernel, which limits the DS => out\n\n=> D"},{"comment_id":"990869","poster":"Mickey321","timestamp":"1724683500.0","content":"Selected Answer: D\noption D","upvote_count":"1"},{"comment_id":"943173","poster":"ADVIT","timestamp":"1720129440.0","upvote_count":"1","content":"D.\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/nbi-add-external.html"},{"poster":"CKS1210","upvote_count":"1","timestamp":"1719319500.0","content":"Selected Answer: D\nInstall custom environments and kernels on the notebook instance's Amazon EBS volume. This ensures that they persist when you stop and restart the notebook instance, and that any external libraries you install are not updated by SageMaker. To do that, use a lifecycle configuration that includes both a script that runs when you create the notebook instance (on-create) and a script that runs each time you restart the notebook instance (on-start).","comment_id":"933593"},{"comment_id":"679235","poster":"31Rishab","timestamp":"1695676740.0","content":"Selected Answer: D\nEven the link given suggest Option D","upvote_count":"3"},{"upvote_count":"2","poster":"ovokpus","comment_id":"621182","timestamp":"1687542780.0","content":"Selected Answer: D\nPlease ignore my previous comment, the answer is D"},{"timestamp":"1687542600.0","comments":[],"upvote_count":"1","comment_id":"621178","content":"Selected Answer: B\nKey word here is how can the developer \"guarantee\"??\nHe guarantees that by including the install commands as part of the notebook.\n\nSo, against the grain, I stand with B","poster":"ovokpus"},{"timestamp":"1683271080.0","poster":"ayatkhrisat","content":"Selected Answer: D\nD should be the answer","comment_id":"597176","upvote_count":"3"},{"comment_id":"519137","timestamp":"1673115660.0","upvote_count":"2","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/nbi-add-external.html\n upvoted 1 times","poster":"vetaal"},{"upvote_count":"2","comment_id":"518650","poster":"geekgirl007","timestamp":"1673042400.0","content":"Selected Answer: D\nD \"automatically\" is the key here and using lifecycle configuration https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-add-external.html"},{"timestamp":"1670072400.0","content":"It is D, although is not even the best answer in my opinion. Although by default conda packages are installed in ephemeral storage, you can change that default behaviour. I did that in my last project and we created our own conda environment that persisted between shutdowns.","poster":"rafaelo","comment_id":"493150","upvote_count":"1"},{"upvote_count":"1","content":"based on the refernce given under the answer its D not B","poster":"abdohanfi","timestamp":"1667242740.0","comment_id":"369320"},{"upvote_count":"2","comment_id":"353730","timestamp":"1667071620.0","poster":"mona_mansour","content":"You can install packages using the following methods:\n\n1-Lifecycle configuration scripts\n2-Notebooks – The following commands are supported.\n\n%conda install\n\n%pip install\n\n3-The Jupyter terminal – You can install packages using pip and conda directly."},{"upvote_count":"1","content":"NOT B ...>/etc/init contains configuration files used by Upstart.\nANS...>D","timestamp":"1666915920.0","comment_id":"353714","poster":"mona_mansour"},{"upvote_count":"1","comment_id":"291825","poster":"astonm13","timestamp":"1666198980.0","content":"Its for sure D"},{"content":"D https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-add-external.html","poster":"ksrivastavaSumit","comment_id":"284649","upvote_count":"3","timestamp":"1665891420.0"}],"question_images":[],"isMC":true,"topic":"1","exam_id":26,"unix_timestamp":1612551360},{"id":"JUAeTQqcUDDPK26h2bLT","question_text":"A data scientist needs to identify fraudulent user accounts for a company's ecommerce platform. The company wants the ability to determine if a newly created account is associated with a previously known fraudulent user. The data scientist is using AWS Glue to cleanse the company's application logs during ingestion.\nWhich strategy will allow the data scientist to identify fraudulent accounts?","choices":{"B":"Create a FindMatches machine learning transform in AWS Glue.","C":"Create an AWS Glue crawler to infer duplicate accounts in the source data.","D":"Search for duplicate accounts in the AWS Glue Data Catalog.","A":"Execute the built-in FindDuplicates Amazon Athena query."},"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/44079-exam-aws-certified-machine-learning-specialty-topic-1/","exam_id":26,"answer_description":"","isMC":true,"unix_timestamp":1612551060,"timestamp":"2021-02-05 19:51:00","answers_community":["B (100%)"],"question_id":27,"answer_ET":"B","answer":"B","answer_images":[],"discussion":[{"timestamp":"1665730200.0","comment_id":"353701","content":"B ,You can use the FindMatches transform to find duplicate records in the source data. A labeling file is generated or provided to help teach the transform.","upvote_count":"13","poster":"mona_mansour"},{"content":"B it is. Reasonable explanation.","timestamp":"1664066880.0","comment_id":"284342","upvote_count":"6","poster":"[Removed]"},{"poster":"Mickey321","upvote_count":"1","timestamp":"1724683980.0","comment_id":"990874","content":"Selected Answer: B\noption B Find matches"},{"poster":"Valcilio","comment_id":"830346","upvote_count":"1","timestamp":"1709674740.0","content":"Selected Answer: B\nIt's B, how it's using Glue to clean the data the easiest way will be use Glue's ML FindMatches extension to do this too."},{"poster":"Tomatoteacher","upvote_count":"1","timestamp":"1705441920.0","comment_id":"778319","content":"Selected Answer: B\nIt is B."},{"upvote_count":"2","poster":"omar_bahrain","comment_id":"291900","content":"Agree. Please refer to:\nhttps://aws.amazon.com/blogs/big-data/integrate-and-deduplicate-datasets-using-aws-lake-formation-findmatches/","timestamp":"1664080200.0"}],"topic":"1"},{"id":"tEVFI5NKdFZLb0ignCQ4","answer_ET":"BD","exam_id":26,"choices":{"C":"Increase the XGBoost max_depth parameter because the model is currently underfitting the data.","B":"Increase the XGBoost scale_pos_weight parameter to adjust the balance of positive and negative weights.","D":"Change the XGBoost eval_metric parameter to optimize based on Area Under the ROC Curve (AUC).","E":"Decrease the XGBoost max_depth parameter because the model is currently overfitting the data.","A":"Change the XGBoost eval_metric parameter to optimize based on Root Mean Square Error (RMSE)."},"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/75336-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"comment_id":"598961","timestamp":"1652089080.0","upvote_count":"12","content":"B and D","poster":"LydiaGom"},{"comment_id":"622300","upvote_count":"8","content":"Selected Answer: BD\nCompensate for imbalance and optimize on AUC. This is a class imbalance problem, not an overfitting problem.","timestamp":"1656204780.0","poster":"ovokpus","comments":[{"poster":"rb39","comment_id":"671820","upvote_count":"1","timestamp":"1663450800.0","content":"totally right, overfitting has nothing to do so there is no need to reduce tree depth"}]},{"comment_id":"1292568","timestamp":"1727915700.0","upvote_count":"1","poster":"MJSY","content":"Selected Answer: BD\nthe question didnt show the model performance on training data, so the overfitting issues is not correct."},{"comment_id":"1010421","timestamp":"1695028740.0","poster":"loict","content":"Selected Answer: BD\nA. NO - that will not address FN specifically but also FP\nB. YES - changing weight is best practice for class imbalance\nC. NO - there is no underfitting at 99.1% accuracy\nD. YES - AUC will address recall, which takes into account FN rate\nE. NO - there is no overfitting at 99.1% accuracy","upvote_count":"3"},{"poster":"Mickey321","comment_id":"990951","timestamp":"1693068300.0","content":"Selected Answer: BD\nStep B: Increasing the XGBoost scale_pos_weight parameter to adjust the balance of positive and negative weights can help the model deal with the imbalanced dataset. According to the XGBoost documentation, this parameter controls the balance of positive and negative weights, and is useful for unbalanced classes. A typical value to consider is sum(negative instances) / sum(positive instances). In this case, since there are 100 times more non-fraudulent transactions than fraudulent ones, setting scale_pos_weight to 100 can make the model more sensitive to the minority class and reduce false negatives.\nStep D: Changing the XGBoost eval_metric parameter to optimize based on Area Under the ROC Curve (AUC) can help the model focus on improving the true positive rate and the true negative rate, which are both important for fraud detection. According to the XGBoost","upvote_count":"2"},{"upvote_count":"1","poster":"Mickey321","comment_id":"990942","timestamp":"1693067460.0","content":"Selected Answer: BD\nStep B: Increasing the XGBoost scale_pos_weight parameter to adjust the balance of positive and negative weights can help the model deal with the imbalanced dataset. According to the XGBoost documentation, this parameter controls the balance of positive and negative weights, and is useful for unbalanced classes. A typical value to consider is sum(negative instances) / sum(positive instances). In this case, since there are 100 times more non-fraudulent transactions than fraudulent ones, setting scale_pos_weight to 100 can make the model more sensitive to the minority class and reduce false negatives.\nStep D: Changing the XGBoost eval_metric parameter to optimize based on Area Under the ROC Curve (AUC) can help the model focus on improving the true positive rate and the true negative rate, which are both important for fraud detection."},{"content":"Selected Answer: BE\nI have some doubts about D and E.\nPrecision-Recall AUC is better than AUC curve in imbalanced classes. Then, I choose E","poster":"Mllb","comment_id":"860095","upvote_count":"2","timestamp":"1680537060.0"},{"poster":"AjoseO","upvote_count":"1","content":"Selected Answer: BD\nOption A and Option E are unlikely to help reduce false negatives.\n\nOption C, increasing max_depth, may lead to overfitting, which could make the model worse.\n\nOption D, changing the eval_metric to optimize based on AUC, could help improve the model's ability to discriminate between the two classes.\n\nOption B, increasing the scale_pos_weight parameter to adjust the balance of positive and negative weights, can help the model better handle imbalanced datasets, which is the case here. By increasing the weight of positive examples, the model will learn to prioritize correctly classifying them, which should reduce the number of false negatives.","timestamp":"1679522100.0","comment_id":"847553"},{"content":"Selected Answer: BD\nBD, I have done this before, but it would be better to use Average Precision(AP) instead of AUC, but it is better than other answers.","comment_id":"778325","poster":"Tomatoteacher","timestamp":"1673906100.0","upvote_count":"1"},{"comment_id":"667343","upvote_count":"1","timestamp":"1663007340.0","content":"12-sep exam","poster":"Shailendraa"},{"content":"Selected Answer: BE\nCompensate for imbalance and overwriting.","timestamp":"1656023040.0","poster":"ovokpus","comment_id":"621353","upvote_count":"1"},{"upvote_count":"1","poster":"NeverMinda","comment_id":"612477","timestamp":"1654542420.0","content":"Selected Answer: BE\nB and E"},{"comment_id":"599204","content":"B. Increase the XGBoost scale_pos_weight parameter to adjust the balance of positive and negative weights is the correct answer.\nAccording to https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html, scale_pos_weight controls the balance of positive and negative weights. It's useful for unbalanced classes.","timestamp":"1652117580.0","poster":"MLGuru","upvote_count":"3"}],"question_text":"A Data Scientist is developing a machine learning model to classify whether a financial transaction is fraudulent. The labeled data available for training consists of\n100,000 non-fraudulent observations and 1,000 fraudulent observations.\nThe Data Scientist applies the XGBoost algorithm to the data, resulting in the following confusion matrix when the trained model is applied to a previously unseen validation dataset. The accuracy of the model is 99.1%, but the Data Scientist needs to reduce the number of false negatives.\n//IMG//\n\nWhich combination of steps should the Data Scientist take to reduce the number of false negative predictions by the model? (Choose two.)","unix_timestamp":1652089080,"topic":"1","answers_community":["BD (81%)","BE (19%)"],"isMC":true,"answer_description":"","answer":"BD","question_images":["https://www.examtopics.com/assets/media/exam-media/04145/0007400001.png"],"question_id":28,"timestamp":"2022-05-09 11:38:00"},{"id":"sYeGPs1vvR7VTJk33IPD","unix_timestamp":1612712400,"exam_id":26,"answer_description":"","discussion":[{"timestamp":"1648494300.0","upvote_count":"27","poster":"cnethers","comment_id":"287086","content":"I agree with an answer of C \nAttention mechanism. The disadvantage of an encoder-decoder framework is that model performance decreases as and when the length of the source sequence increases because of the limit of how much information the fixed-length encoded feature vector can contain. To tackle this problem, in 2015, Bahdanau et al. proposed the attention mechanism. In an attention mechanism, the decoder tries to find the location in the encoder sequence where the most important information could be located and uses that information and previously decoded words to predict the next token in the sequence."},{"content":"Selected Answer: C\nC. By tuning attention-related hyperparameters (such as attention type, attention layer size, and dropout), the model can focus on relevant parts of the input sequence during translation.","comment_id":"1154392","upvote_count":"1","timestamp":"1724108640.0","poster":"AIWave"},{"content":"Selected Answer: C\nA. NO - n-grams are more the opposite, it is to capture local information\nB. NO - it could help, but not best\nC. YES - best practice (https://docs.aws.amazon.com/sagemaker/latest/dg/seq-2-seq-hyperparameters.html)\nD. NO - weight are for vectorized words, they do not relate to sequences","poster":"loict","upvote_count":"1","timestamp":"1710768840.0","comment_id":"1010513"},{"content":"Selected Answer: C\nAction C: Adjusting hyperparameters related to the attention mechanism can help improve the translation quality for long sentences, because the attention mechanism allows the decoder to focus on the most relevant parts of the source sentence at each time step. According to the Amazon SageMaker documentation, the seq2seq algorithm supports several types of attention mechanisms, such as dot, general, concat, and location. The data scientist can experiment with different values of the hyperparameters attention_type, attention_coverage_type, and attention_num_hidden to find the optimal configuration for the translation task.","upvote_count":"1","poster":"Mickey321","comment_id":"990954","timestamp":"1708973220.0"},{"timestamp":"1691952780.0","comment_id":"807800","content":"Selected Answer: C\nC. Adjust hyperparameters related to the attention mechanism.\n\nThe seq2seq algorithm uses an attention mechanism to dynamically focus on relevant parts of the input sequence for each output sequence element. Increasing the attention mechanism's ability to learn dependencies between long input and output sequences might help improve the translation quality for long sentences. \n\nThe data scientist could try adjusting relevant hyperparameters such as attention depth or attention scale, or try a different attention mechanism such as scaled dot-product attention, to see if that improves the translation quality for long sentences.","upvote_count":"4","poster":"AjoseO"},{"content":"Selected Answer: C\ni go with C","poster":"peterfish","comment_id":"633326","timestamp":"1674108600.0","upvote_count":"4"},{"content":"Ans: C\nExplanation: https://docs.aws.amazon.com/sagemaker/latest/dg/seq-2-seq- howitworks.html","comment_id":"561302","upvote_count":"2","poster":"SriAkula","timestamp":"1662358920.0"},{"upvote_count":"3","timestamp":"1661001600.0","poster":"AddiWei","content":"This is such a niche question for a niche market. Geared towards someone who specializes in NLP.","comment_id":"551932"},{"timestamp":"1651377240.0","comment_id":"342983","poster":"Juka3lj","upvote_count":"3","content":"c is correct\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/seq-2-seq-howitworks.html"},{"timestamp":"1647777060.0","content":"I believe the answer is C\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/seq-2-seq-howitworks.html","upvote_count":"3","poster":"rajesriv","comment_id":"285600"}],"question_text":"A data scientist has developed a machine learning translation model for English to Japanese by using Amazon SageMaker's built-in seq2seq algorithm with\n500,000 aligned sentence pairs. While testing with sample sentences, the data scientist finds that the translation quality is reasonable for an example as short as five words. However, the quality becomes unacceptable if the sentence is 100 words long.\nWhich action will resolve the problem?","answers_community":["C (100%)"],"question_images":[],"answer_images":[],"choices":{"C":"Adjust hyperparameters related to the attention mechanism.","A":"Change preprocessing to use n-grams.","B":"Add more nodes to the recurrent neural network (RNN) than the largest sentence's word count.","D":"Choose a different weight initialization type."},"isMC":true,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/44186-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","timestamp":"2021-02-07 16:40:00","question_id":29,"answer":"C"},{"id":"f9oUdsKBPmZaZUX2q11J","url":"https://www.examtopics.com/discussions/amazon/view/44081-exam-aws-certified-machine-learning-specialty-topic-1/","answer_ET":"DE","unix_timestamp":1612552200,"answer":"DE","topic":"1","timestamp":"2021-02-05 20:10:00","answers_community":["DE (83%)","BD (17%)"],"isMC":true,"exam_id":26,"question_id":30,"question_images":[],"question_text":"A financial company is trying to detect credit card fraud. The company observed that, on average, 2% of credit card transactions were fraudulent. A data scientist trained a classifier on a year's worth of credit card transactions data. The model needs to identify the fraudulent transactions (positives) from the regular ones\n(negatives). The company's goal is to accurately capture as many positives as possible.\nWhich metrics should the data scientist use to optimize the model? (Choose two.)","answer_images":[],"answer_description":"","choices":{"B":"False positive rate","A":"Specificity","C":"Accuracy","E":"True positive rate","D":"Area under the precision-recall curve"},"discussion":[{"upvote_count":"37","comment_id":"315427","timestamp":"1665920640.0","poster":"littlewat","content":"D, E is the answer. we need to make the recall rate(not precision) high."},{"content":"To maximize detection of fraud in real-world, imbalanced datasets, D and E should always be applied.\n\nhttps://en.wikipedia.org/wiki/Sensitivity_and_specificity\nhttps://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/","comment_id":"284352","comments":[{"comments":[{"comment_id":"287105","upvote_count":"5","content":"that is not correct unfortunately \nRecall is = Sensitivity = False Negative which is a Type II error \nPrecision = specificity = False Positive which is a Type I error\nI do agree that in the real world you would focus on Recall/sensitivity ie. reducing type II errors. \nHowever, in the question, they want to reduce the False Positives so you would need to focus on precision and specificity minimizing type I errors","poster":"cnethers","timestamp":"1664236920.0","comments":[{"comment_id":"362033","content":"recall = sensitivity = TRUE POSITIVE RATE\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjhyduhndjwAhXtzDgGHVsSBacQFjABegQIBRAD&url=https%3A%2F%2Fwww.split.io%2Fglossary%2Ffalse-positive-rate%2F&usg=AOvVaw10zzmY-IDlhbboUTwEMnqw","upvote_count":"2","timestamp":"1667254980.0","poster":"yummytaco"},{"poster":"seanLu","comment_id":"302372","upvote_count":"6","content":"This is incorrect. The goal is to capture as many positive as possible, so false positive is not a concern. suppose we have 100 samples, 2 are positive, the rest 98 negative. We have two models: A has TP = 2, TN = 48, FP = 50, FN = 0. B has TP = 1, TN = 88, FP = 10, FN = 1. Model A has higher false positive rate (50/98 vs 10/98). However we will choose A, since it captures all TP. I will go with D, E.","timestamp":"1665113220.0"},{"poster":"omar_bahrain","comment_id":"307336","content":"specifity is different\n\n than precision","upvote_count":"1","timestamp":"1665488280.0"},{"comments":[{"poster":"omar_bahrain","comment_id":"291970","content":"I came a cross this article and I would say it might support choosing A&B as answers:\nhttps://medium.com/datadriveninvestor/rethinking-the-right-metrics-for-fraud-detection-4edfb629c423","upvote_count":"1","timestamp":"1664955120.0"}],"upvote_count":"6","content":"My ANS would be AB","comment_id":"287106","poster":"cnethers","timestamp":"1664659620.0"}]}],"content":"Note, True positive rate = Sensitivity = Recall","poster":"[Removed]","comment_id":"284353","timestamp":"1663911720.0","upvote_count":"5"}],"upvote_count":"13","poster":"[Removed]","timestamp":"1663758660.0"},{"upvote_count":"3","content":"Selected Answer: DE\n\"accurately capture positives\" means maximize TPR.\n\nA. NO - Specificity = TN / ( TN + FP ) is a measure of negative cases\nB. NO - FPR = FP / Total\nC. NO - given the class imbalance, overall accuracy would not help\nD. YES - not sure if we need that on top of E, but other options are eliminated anyway\nE. YES - TPR = TP / Total, what we want","timestamp":"1726660440.0","comment_id":"1010541","poster":"loict"},{"upvote_count":"1","content":"Selected Answer: DE\nThe data scientist should use True positive rate and Area under the precision-recall curve to optimize the model.\n\nThe true positive rate (TPR) is the proportion of actual positives that are correctly identified as such. It is also known as sensitivity or recall. In this case, it is important to capture as many fraudulent transactions as possible, so the TPR should be maximized.\n\nThe area under the precision-recall curve (AUPRC) is a measure of how well the model is able to distinguish between positive and negative classes. It is a good metric to use when the classes are imbalanced, as in this case where only 2% of transactions are fraudulent. The AUPRC summarizes the trade-off between precision and recall across all possible thresholds.\n\nAccuracy and specificity are not good metrics to use when the classes are imbalanced because they can be misleading. The false positive rate (FPR) is also not a good metric to use because it does not take into account the number of true negatives.","timestamp":"1724803740.0","poster":"teka112233","comment_id":"991702"},{"content":"Selected Answer: DE\nMetric D: Area under the precision-recall curve (AUPRC) is a good metric to use for imbalanced classification problems, where the positive class is much less frequent than the negative class. Precision is the proportion of positive predictions that are correct, and recall (or true positive rate) is the proportion of positive cases that are detected. AUPRC summarizes the trade-off between precision and recall for different decision thresholds, and a higher AUPRC means that the model can achieve both high precision and high recall. Since the company’s goal is to accurately capture as many positives as possible, AUPRC can help them evaluate how well the model performs on the minority class.\nMetric E: True positive rate (TPR) is another good metric to use for imbalanced classification problems, as it measures the sensitivity of the model to the positive class. TPR is the same as recall, and it is the proportion of positive cases that are detected by the model. A higher TPR means that the model can identify more fraudulent transactions, which is the company’s goal.","comment_id":"990958","poster":"Mickey321","timestamp":"1724691060.0","upvote_count":"1"},{"comment_id":"807811","comments":[{"upvote_count":"1","comment_id":"807812","timestamp":"1707858900.0","content":"Precision is the fraction of correctly identified positive instances among all instances the model has classified as positive. Recall, also known as the true positive rate, is the fraction of positive instances that are correctly identified as positive by the model. A higher area under the precision-recall curve indicates that the model is making fewer false positive predictions and more true positive predictions, which aligns with the goal of the financial company to accurately capture as many fraudulent transactions as possible.","poster":"AjoseO"}],"poster":"AjoseO","content":"Selected Answer: DE\nThe goal is to accurately capture as many fraudulent transactions (positives) as possible. To optimize the model towards this goal, the data scientist should focus on metrics that emphasize the true positive rate and the area under the precision-recall curve.\n\nTrue positive rate (TPR or sensitivity) is the proportion of actual positive cases that are correctly identified as positive by the model. A higher TPR means that more fraudulent transactions are being captured.\n\nThe precision-recall curve is a graph that shows the trade-off between precision and recall for different thresholds.","upvote_count":"1","timestamp":"1707858900.0"},{"upvote_count":"4","content":"Selected Answer: DE\nagreed with DE","comment_id":"727894","poster":"ystotest","timestamp":"1701051660.0"},{"comment_id":"618633","timestamp":"1687170840.0","upvote_count":"2","poster":"f4bi4n","content":"Why not A and D?\n- Specificity shows us how the FNR is\n- AUC PR includes Precision and Recall which shows us the ratio of TP to TP/FP and TP to TP / FN"},{"content":"Answer: D&E","comment_id":"561321","timestamp":"1678007100.0","poster":"SriAkula","upvote_count":"1"},{"timestamp":"1671149280.0","comment_id":"502535","upvote_count":"1","poster":"KM226","content":"I meant say D&E not BD"},{"upvote_count":"2","timestamp":"1671149100.0","comment_id":"502534","content":"Selected Answer: BD\nI believe the answer is B&D, which equals F1. F1 combines precision and Sensitivity.","poster":"KM226"},{"upvote_count":"1","timestamp":"1667621760.0","content":"D&E is the only choices that takes False Negatives into considration","comment_id":"426453","comments":[{"upvote_count":"1","poster":"f4bi4n","content":"TPR is already included in the AUC PR\nTNR is not included in all others besides A","timestamp":"1687171260.0","comment_id":"618638"}],"poster":"mahmoudai"},{"timestamp":"1667438340.0","poster":"AShahine21","upvote_count":"2","comment_id":"370618","content":"Recall and TPR\nD and E"},{"upvote_count":"1","content":"AB is the answer","comment_id":"307573","timestamp":"1665624840.0","poster":"kawow"}]}],"exam":{"id":26,"isBeta":false,"isMCOnly":false,"numberOfQuestions":369,"isImplemented":true,"name":"AWS Certified Machine Learning - Specialty","lastUpdated":"11 Apr 2025","provider":"Amazon"},"currentPage":6},"__N_SSP":true}