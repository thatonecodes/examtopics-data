{"pageProps":{"questions":[{"id":"tAistWrRXgFyQsE2T38k","isMC":true,"choices":{"B":"Store the PGP private key in Secrets Manager. Add an exception-handling step in the Transfer Family managed workflow to decrypt files. Configure PGP encryption parameters in the exception handler. Associate the workflow with the SFTP user.","C":"Store the PGP private key in Secrets Manager. Add a nominal step in the Transfer Family managed workflow to decrypt files. Configure PGP decryption parameters in the nominal step. Associate the workflow with the Transfer Family server.","A":"Store the PGP public key in Secrets Manager. Add a nominal step in the Transfer Family managed workflow to decrypt files. Configure PGP encryption parameters in the nominal step. Associate the workflow with the Transfer Family server.","D":"Store the PGP public key in Secrets Manager. Add an exception-handling step in the Transfer Family managed workflow to decrypt files. Configure PGP decryption parameters in the exception handler. Associate the workflow with the SFTP user."},"url":"https://www.examtopics.com/discussions/amazon/view/142919-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"C","question_images":[],"topic":"1","answers_community":["C (100%)"],"answer_description":"","discussion":[{"content":"The answer should be \"C\" because you store the \"private\" key in Secrets Manager","upvote_count":"7","poster":"zapper1234","comment_id":"1237009","timestamp":"1719336480.0"},{"comment_id":"1309279","upvote_count":"1","timestamp":"1731204840.0","comments":[{"upvote_count":"1","timestamp":"1731204900.0","content":"store the PGP private key in Secrets Manager. Add a nominal step in the Transfer Family managed workflow to decrypt files.","poster":"AzureDP900","comment_id":"1309280"}],"poster":"AzureDP900","content":"C and D are pretty similar however D talks about exception handling. C is right answer"},{"content":"Selected Answer: C\nC correct","poster":"mark_232323","upvote_count":"1","comment_id":"1248267","timestamp":"1721039460.0"},{"poster":"dzhang344","content":"Selected Answer: C\nC, for sure.","timestamp":"1720632060.0","comment_id":"1245625","upvote_count":"1"},{"comment_id":"1242718","upvote_count":"3","content":"C, for sure.\nIn the context of AWS Transfer Family managed workflows, a \"\"nominal step\"\" refers to one of the predefined steps that you can include in a managed workflow to automate file transfer and processing tasks.\nAn \"\"exception-handling step\"\" is a specific type of step designed to handle errors or exceptions that occur during the execution of a workflow.","timestamp":"1720177740.0","poster":"gfhbox0083"},{"poster":"grandcanyon","content":"Selected Answer: C\nC is correct b/c private key is what is required for decryption","timestamp":"1719961200.0","comment_id":"1241068","upvote_count":"2"},{"content":"Selected Answer: C\nAgree with Zapper1234 plus the permission is granted to transfer family server.","timestamp":"1719758340.0","upvote_count":"2","comment_id":"1239690","poster":"Helpnosense"}],"question_id":426,"timestamp":"2024-06-25 19:28:00","exam_id":33,"answer":"C","unix_timestamp":1719336480,"answer_images":[],"question_text":"A company needs to use an AWS Transfer Family SFTP-enabled server with an Amazon S3 bucket to receive updates from a third-party data supplier. The data is encrypted with Pretty Good Privacy (PGP) encryption. The company needs a solution that will automatically decrypt the data after the company receives the data.\nA solutions architect will use a Transfer Family managed workflow. The company has created an IAM service role by using an IAM policy that allows access to AWS Secrets Manager and the S3 bucket. The role’s trust relationship allows the transfer amazonaws.com service to assume the role.\n\nWhat should the solutions architect do next to complete the solution for automatic decryption?"},{"id":"1Fa2XmeVELM2iMNWRts3","url":"https://www.examtopics.com/discussions/amazon/view/142914-exam-aws-certified-solutions-architect-professional-sap-c02/","unix_timestamp":1719321600,"answers_community":["C (80%)","B (20%)"],"question_id":427,"question_images":[],"timestamp":"2024-06-25 15:20:00","answer_ET":"C","answer":"C","answer_description":"","topic":"1","answer_images":[],"discussion":[{"content":"memobrydb for ultra-fast Redis performance, so C","comment_id":"1236922","poster":"zapper1234","timestamp":"1719321600.0","upvote_count":"7"},{"content":"where is A?","poster":"chris_spencer","comment_id":"1298185","upvote_count":"5","timestamp":"1728989100.0"},{"poster":"eesa","comment_id":"1422187","content":"Selected Answer: C\nwhere is A?","timestamp":"1743586200.0","upvote_count":"1"},{"poster":"AzureDP900","content":"C is right. Amazon MemoryDB for Redis is a fully managed, Redis-compatible, in-memory database service that delivers ultra-fast performance with microsecond read and single-digit millisecond write latencies. It supports Multi-AZ replication for high availability and durability. If the primary node fails, MemoryDB automatically fails over to a replica node in less than a minute.","upvote_count":"2","comment_id":"1318995","timestamp":"1732764120.0"},{"poster":"TomTom","upvote_count":"1","comments":[{"timestamp":"1732245660.0","comment_id":"1316135","content":"Wrongly tick, should be C","poster":"TomTom","upvote_count":"1"}],"comment_id":"1316134","timestamp":"1732245600.0","content":"Selected Answer: B\nTo meet the requirements of low latency and high availability for a gaming leaderboard, Amazon MemoryDB for Redis is the best solution. It provides microsecond read latencies and single-digit millisecond write latencies, ensuring fast data access and updates, which is critical for real-time applications like leaderboards.\nThis setup minimizes operational overhead compared to managing multiple EC2 instances or configuring a traditional RDS database"},{"content":"Selected Answer: C\nMEM DB for gaming leaderboard with related latency requirement","timestamp":"1720294380.0","comment_id":"1243523","poster":"vip2","upvote_count":"3"},{"content":"It is C for sure","comment_id":"1241236","timestamp":"1719991620.0","upvote_count":"2","poster":"rohan0411"}],"isMC":true,"exam_id":33,"choices":{"C":"Create multiple Redis nodes on Amazon EC2 instances that are spread across multiple Availability Zones. Configure backups to Amazon S3.","A":"Create an Amazon ROS database with a read replica. Configure the application to point writes to the writer endpoint. Configure the application to point reads to the reader endpoint.","B":"Create an Amazon MemoryDB for Redis cluster in Muit-AZ mode Configure the application to interact with the primary node."},"question_text":"A company is migrating infrastructure for its massive multiplayer game to AWS. The game’s application features a leaderboard where players can see rankings in real time. The leaderboard requires microsecond reads and single-digit-millisecond write latencies. The datasets are single-digit terabytes in size and must be available to accept writes in less than a minute if a primary node failure occurs.\n\nThe company needs a solution in which data can persist for further analytical processing through a data pipeline.\n\nWhich solution will meet these requirements with the LEAST operational overhead?"},{"id":"ScoyCsSSPzALns1Kn2Dq","answer_images":[],"topic":"1","choices":{"A":"In the organization's management account, create a cost allocation tag that is named BusinessUnit. Also in the management account, create an Amazon S3 bucket and an AWS Cost and Usage Report (AWS CUR). Configure the S3 bucket as the destination for the AWS CUR. From the management account, query the AWS CUR data by using Amazon Athena. Use Amazon QuickSight for visualization.","C":"In the organization's management account, create a cost allocation tag that is named BusinessUnit. In each member account, create an Amazon S3 bucket and an AWS Cost and Usage Report (AWS CUR). Configure each S3 bucket as the destination for its respective AWS CUR. In the management account, create an Amazon CloudWatch dashboard for visualization.","D":"In each member account, create a cost allocation tag that is named BusinessUnit. Also in each member account, create an Amazon S3 bucket and an AWS Cost and Usage Report (AWS CUR). Configure each S3 bucket as the destination for its respective AWS CUR. From the management account, query the AWS CUR data by using Amazon Athena. Use Amazon QuickSight for visualization.","B":"In each member account, create a cost allocation tag that is named BusinessUnit. In the organization’s management account, create an Amazon S3 bucket and an AWS Cost and Usage Report (AWS CUR). Configure the S3 bucket as the destination for the AWS CUR. Create an Amazon CloudWatch dashboard for visualization."},"answer":"A","timestamp":"2024-06-25 15:21:00","question_images":[],"question_text":"A company is running several applications in the AWS Cloud. The applications are specific to separate business units in the company. The company is running the components of the applications in several AWS accounts that are in an organization in AWS Organizations.\n\nEvery cloud resource in the company’s organization has a tag that is named BusinessUnit. Every tag already has the appropriate value of the business unit name.\n\nThe company needs to allocate its cloud costs to different business units. The company also needs to visualize the cloud costs for each business unit.\n\nWhich solution will meet these requirements?","answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/142915-exam-aws-certified-solutions-architect-professional-sap-c02/","unix_timestamp":1719321660,"exam_id":33,"isMC":true,"answer_description":"","discussion":[{"content":"You need Athena and Quicksight so I say A","timestamp":"1719321660.0","poster":"zapper1234","upvote_count":"6","comment_id":"1236924"},{"poster":"altonh","upvote_count":"1","comment_id":"1359648","timestamp":"1740119700.0","content":"Selected Answer: A\nAlthough I believe the correct answer is A, the statement \"create a cost allocation tag\" seemed to be incorrect. You need to Activate the tag, not create it."},{"comment_id":"1313327","poster":"AzureDP900","upvote_count":"1","content":"A right\nThe cost allocation tag is attached to all resources in the organization's management account, which allows for easy identification of costs associated with each business unit.\nThe S3 bucket and AWS CUR are created in the management account, which simplifies the process of storing and querying cost data.\nAmazon Athena can be used from the management account to query the AWS CUR data, allowing for easy visualization and analysis of costs across different business units.\nAmazon QuickSight is also available in the management account, providing a user-friendly interface for visualizing the cost data.","timestamp":"1731807120.0"},{"upvote_count":"1","comment_id":"1313215","poster":"0b43291","timestamp":"1731787260.0","content":"Selected Answer: A\nBy centralizing the cost allocation tag, AWS CUR, and data analysis in the management account, this solution ensures consistent tagging and cost allocation across the organization. It also provides a single source of truth for cost and usage data, enabling efficient querying and visualization using Athena and QuickSight."},{"comment_id":"1266771","poster":"kgpoj","timestamp":"1723771560.0","content":"Selected Answer: A\nCreate tag in management account\nUse Athena + QuickSight","upvote_count":"2"},{"timestamp":"1720177920.0","poster":"gfhbox0083","upvote_count":"1","content":"A, for sure","comment_id":"1242725"},{"timestamp":"1720105380.0","comment_id":"1242161","poster":"NoinNothing","upvote_count":"1","content":"Selected Answer: A\nAnswer is \"A\""},{"content":"Selected Answer: A\nA is the best answer","comment_id":"1241072","poster":"grandcanyon","upvote_count":"1","timestamp":"1719962340.0"},{"timestamp":"1719661260.0","comment_id":"1239241","poster":"d7ccbf6","content":"Selected Answer: A\nYou need Athena and Quicksight to visualize CUR","upvote_count":"1"}],"question_id":428,"answer_ET":"A"},{"id":"d6brKgvou1EEe5mhhE13","question_id":429,"answer_ET":"AD","answers_community":["AD (100%)"],"topic":"1","unix_timestamp":1719336780,"answer":"AD","choices":{"C":"Increase the payload size from the smart meters to send more data.","A":"Increase the write capacity units to the DynamoDB table.","B":"Increase the memory available to the Lambda functions.","D":"Stream the data into an Amazon Kinesis data stream from API Gateway and process the data in batches.","E":"Collect data in an Amazon SQS FIFO queue, which triggers a Lambda function to process each message"},"exam_id":33,"question_images":[],"isMC":true,"answer_images":[],"answer_description":"","discussion":[{"upvote_count":"6","poster":"mifune","comment_id":"1238347","timestamp":"1719513060.0","content":"Selected Answer: AD\nI would go with Increasing the write capacity units to the DynamoDB table and Stream the data into an Amazon Kinesis data stream from API Gateway and process the data in batches. I think that processing the data in batches is much better than increasing the lambda functions memory."},{"poster":"zapper1234","upvote_count":"5","comment_id":"1237011","content":"AB because the more memory a Lambda funtion has the faster it reacts","timestamp":"1719336780.0"},{"timestamp":"1731787560.0","poster":"0b43291","upvote_count":"1","comment_id":"1313216","content":"Selected Answer: AD\nBy increasing the DynamoDB write capacity units and streaming the data into a Kinesis data stream for batch processing, you can address the throughput limitations, reduce Lambda invocation overhead, and improve the overall performance and scalability of the smart meter data processing pipeline.\n\nThe other options are either not applicable or may not resolve the issues effectively:\nB. Increasing the memory available to the Lambda functions may not resolve the issues caused by the high volume of concurrent requests and the need for batching.\n\nC. Increasing the payload size from the smart meters is not necessary and may even exacerbate the issues by increasing the processing overhead for each data point.\n\nE. Collecting data in an Amazon SQS FIFO queue and triggering a Lambda function for each message would still result in a high number of Lambda invocations and may not provide significant performance improvements compared to processing data in batches from a Kinesis data stream."},{"upvote_count":"4","poster":"vip2","content":"Selected Answer: AD\nKinesis allows to process data in batches, which can help reduce the number of requests and the load on your Lambda functions and DynamoDB.","comment_id":"1243521","timestamp":"1720294140.0"},{"comment_id":"1239649","content":"Selected Answer: AD\nA and D","poster":"wbedair","timestamp":"1719752760.0","upvote_count":"3"},{"comment_id":"1239165","timestamp":"1719651840.0","poster":"ujizane","upvote_count":"2","content":"need batch execution so i think AD is correct"}],"question_text":"A utility company wants to collect usage data every 5 minutes from its smart meters to facilitate time-of-use metering. When a meter sends data to AWS, the data is sent to Amazon API Gateway, processed by an AWS Lambda function. and stored in an Amazon DynamoDB table. During the pilot phase, the Lambda functions took from 3 to 5 seconds to complete.\n\nAs more smart meters are deployed, the engineers notice the Lambda functions are taking from 1 to 2 minutes to complete. The functions are also increasing in duration as new types of metrics are collected from the devices. There are many ProvisionedThroughputExceededException errors while performing PUT operations on DynamoDB, and there are also many TooManyRequestsException errors from Lambda.\n\nWhich combination of changes will resolve these issues? (Choose two.)","timestamp":"2024-06-25 19:33:00","url":"https://www.examtopics.com/discussions/amazon/view/142920-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"rqKNFPvGBes1G1HG84aK","choices":{"D":"Create a connection alias in the primary Region Associate the connection alias with a directory in the failover Region. Create a Route 53 failover routing policy. Set Evaluate Target Health to Yes.","A":"Create a connection alias in the primary Region and in the failover Region. Associate the connection aliases with a directory in each Region. Create a Route 53 failover routing policy. Set Evaluate Target Health to Yes.","C":"Create a connection alias in the primary Region. Associate the connection alias with a directory in the primary Region. Create a Route 53 weighted routing policy.","B":"Create a connection alias in the primary Region and in the failover Region. Associate the connection aliases with a directory in the primary Region. Create a Route 53 multivalue answer routing policy."},"answer_description":"","answers_community":["A (74%)","D (26%)"],"unix_timestamp":1719337500,"topic":"1","discussion":[{"comments":[{"timestamp":"1720293480.0","content":"I think you mean A with link that you provided","comment_id":"1243516","poster":"vip2","upvote_count":"2"},{"poster":"toma","upvote_count":"3","content":"you are right.","timestamp":"1719747480.0","comment_id":"1239621"}],"comment_id":"1239239","poster":"d7ccbf6","upvote_count":"6","timestamp":"1719661080.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/workspaces/latest/adminguide/cross-region-redirection.html#cross-region-redirection-associate-connection-aliases"},{"poster":"ujizane","timestamp":"1719654900.0","comment_id":"1239199","content":"Selected Answer: A\nA\nhttps://docs.aws.amazon.com/ja_jp/workspaces/latest/adminguide/cross-region-redirection.html","upvote_count":"6"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/workspaces/latest/adminguide/cross-region-redirection.html#cross-region-redirection-create-connection-aliases\n\nUsing the same AWS account, create connection aliases in each primary and failover Region where you want to set up cross-Region redirection.","poster":"bhanus","timestamp":"1733592900.0","upvote_count":"1","comment_id":"1323219"},{"poster":"AzureDP900","comment_id":"1313328","content":"A is right\nCreating connection aliases in both Regions ensures that users can access the WorkSpaces instance from either region.\n\nAssociating the connection aliases with directories in each Region allows for load balancing and redirection of traffic between the two Regions.\n\nCreating a Route 53 failover routing policy enables Amazon Route 53 to direct users from the primary Region to the failover Region if there's an issue with the primary Region.\n\nSetting Evaluate Target Health to Yes ensures that Route 53 continuously monitors the health of the WorkSpaces instance in both Regions and directs traffic accordingly.","timestamp":"1731807240.0","upvote_count":"1"},{"comment_id":"1313221","poster":"0b43291","content":"Selected Answer: A\nBy following Option A, you can achieve high availability for your Amazon WorkSpaces solution across two AWS Regions, with automatic failover and health monitoring provided by the Route 53 failover routing policy and connection aliases associated with WorkSpaces directories in each Region.\n\nThe other options are either incomplete or incorrect:\nOption B (multivalue answer routing policy) is not suitable for failover scenarios, as it distributes traffic across multiple resources simultaneously, rather than failing over to a secondary resource when the primary becomes unavailable.\n\nOption C (weighted routing policy) is used for distributing traffic based on predefined weights, but it does not provide automatic failover capabilities based on health checks.\n\nOption D is incorrect because it associates the connection alias with the failover Region's directory, which would make the failover Region the primary deployment, defeating the purpose of having a failover configuration.","upvote_count":"1","timestamp":"1731788340.0"},{"poster":"JoeTromundo","timestamp":"1728770160.0","comment_id":"1296646","upvote_count":"1","content":"Selected Answer: A\n\"You can associate a connection alias with ONLY ONE directory per AWS Region.\"\nSo, it can't be D."},{"upvote_count":"1","comment_id":"1265169","poster":"PSPaul","timestamp":"1723553640.0","content":"For A: Potential latency increase due to cross-region access\nFor B:Potential data consistency issues if failover occurs\n\nI choose A"},{"content":"Selected Answer: A\nA is correct","timestamp":"1721582580.0","poster":"vip2","comment_id":"1252624","upvote_count":"2"},{"poster":"Moghite","timestamp":"1721551980.0","content":"Selected Answer: A\nI will go with option A","upvote_count":"2","comment_id":"1252330"},{"poster":"mark_232323","comment_id":"1247835","timestamp":"1720971480.0","content":"Selected Answer: A\nA for sure","upvote_count":"4"},{"timestamp":"1720105980.0","comment_id":"1242163","poster":"NoinNothing","upvote_count":"3","content":"Answer is A - \nA. Create a connection alias in the primary Region and in the failover Region. Associate the connection aliases with a directory in each Region. Create a Route 53 failover routing policy. Set Evaluate Target Health to Yes."},{"timestamp":"1719652140.0","poster":"ujizane","comment_id":"1239166","content":"A\nhttps://docs.aws.amazon.com/ja_jp/workspaces/latest/adminguide/cross-region-redirection.html","upvote_count":"3"},{"poster":"zapper1234","timestamp":"1719337500.0","comment_id":"1237017","content":"Believe the answer is A becuase the two distinct Workspaces directories would give you two IP's for truc failover","upvote_count":"4"}],"isMC":true,"exam_id":33,"question_text":"A company recently completed a successful proof of concept of Amazon WorkSpaces. A solutions architect needs to make the solution highly available across two AWS Regions. Amazon WorkSpaces is deployed in a failover Region, and a hosted zone is deployed in Amazon Route 53.\n\nWhat should the solutions architect do to configure high availability for the solution?","question_id":430,"answer_images":[],"answer_ET":"A","timestamp":"2024-06-25 19:45:00","url":"https://www.examtopics.com/discussions/amazon/view/142921-exam-aws-certified-solutions-architect-professional-sap-c02/","question_images":[],"answer":"A"}],"exam":{"id":33,"provider":"Amazon","name":"AWS Certified Solutions Architect - Professional SAP-C02","isBeta":false,"numberOfQuestions":529,"isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":true},"currentPage":86},"__N_SSP":true}