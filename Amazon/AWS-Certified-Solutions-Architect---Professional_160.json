{"pageProps":{"questions":[{"id":"JZ7Lxf69pNmH3moPun0r","isMC":true,"answer":"B","question_text":"A company is running an application on several Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer. The load on the application varies throughout the day, and EC2 instances are scaled in and out on a regular basis. Log files from the EC2 instances are copied to a central\nAmazon S3 bucket every 15 minutes. The security team discovers that log files are missing from some of the terminated EC2 instances.\nWhich set of actions will ensure that log files are copied to the central S3 bucket from the terminated EC2 instances?","unix_timestamp":1641391380,"timestamp":"2022-01-05 15:03:00","url":"https://www.examtopics.com/discussions/amazon/view/69532-exam-aws-certified-solutions-architect-professional-topic-1/","question_images":[],"exam_id":32,"discussion":[{"comment_id":"528899","timestamp":"1642731720.0","poster":"DLML","content":"B is correct. Check out this aws blog. https://aws.amazon.com/blogs/infrastructure-and-automation/run-code-before-terminating-an-ec2-auto-scaling-instance/","upvote_count":"6"},{"content":"B is the correct answer. Options A and D are sending ABANDON signal, which would leave the instance in non-terminated state. And I don't have to speak for option C!","upvote_count":"1","comment_id":"1298653","timestamp":"1729075080.0","poster":"Sin_Dan"},{"content":"Selected Answer: B\nOnly A or B are valid I will choose B\nC - will drop logs if the instance is terminated \nD - not mention which transition to use\nA - is incorrect abandon will not stop the instance from terminating, so the script will not be executed","comment_id":"632054","poster":"asfsdfsdf","upvote_count":"2","timestamp":"1657958460.0"},{"timestamp":"1648060620.0","content":"B is correct. The difference between B and D are 1) SNS vs Event bridge 2) Life Cycle Abandon vs Continue. \n\nThe SNS and Event bridge will work. For abandon vs Continue - (Action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occur). You want to continue even if there is a time out, instead of abandoning the log file copying.","upvote_count":"4","comment_id":"573845","poster":"ravisar"},{"upvote_count":"2","content":"B is correct. System Manager, EC2_INSTANCE_TERMINATING plus CONTINUE are the keywords","timestamp":"1643932320.0","poster":"saeidp","comment_id":"540110"},{"poster":"tkanmani76","content":"D is right - https://docs.aws.amazon.com/autoscaling/ec2/userguide/adding-lifecycle-hooks.html - Refer to Default Result section - If the instance is terminating, both abandon and continue allow the instance to terminate. However, abandon stops any remaining actions, such as other lifecycle hooks, and continue allows any other lifecycle hooks to complete.","timestamp":"1643003220.0","upvote_count":"2","comment_id":"531072"},{"comment_id":"522057","timestamp":"1641984540.0","upvote_count":"3","poster":"m0h3n","content":"Ans: B SSM document is reliable way to copy the data from EC2 instance."},{"timestamp":"1641391380.0","poster":"Smartphone","comments":[{"comment_id":"518160","timestamp":"1641466380.0","poster":"Smartphone","upvote_count":"2","content":"Changing my answer here. B looks more close. The System Manager Document (script) to copy and run it through the lambda function, is the correct solution. \nhttps://github.com/aws-samples/aws-lambda-lifecycle-hooks-function\nhttps://github.com/aws-samples/aws-lambda-lifecycle-hooks-function/blob/master/cloudformation/template.yaml"}],"upvote_count":"1","comment_id":"517493","content":"Looks like the Answer is A"}],"answer_images":[],"question_id":796,"answer_description":"Reference:\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/configuring-lifecycle-hook-notifications.html","choices":{"B":"Create an AWS Systems Manager document with a script to copy log files to Amazon S3. Create an Auto Scaling lifecycle hook and an Amazon EventBridge (Amazon CloudWatch Events) rule to detect lifecycle events from the Auto Scaling group. Invoke an AWS Lambda function on the autoscaling:EC2_INSTANCE_TERMINATING transition to call the AWS Systems Manager API SendCommand operation to run the document to copy the log files and send CONTINUE to the Auto Scaling group to terminate the instance.","A":"Create a script to copy log files to Amazon S3, and store the script in a file on the EC2 instance. Create an Auto Scaling lifecycle hook and an Amazon EventBridge (Amazon CloudWatch Events) rule to detect lifecycle events from the Auto Scaling group. Invoke an AWS Lambda function on the autoscaling:EC2_INSTANCE_TERMINATING transition to send ABANDON to the Auto Scaling group to prevent termination, run the script to copy the log files, and terminate the instance using the AWS SDK.","C":"Change the log delivery rate to every 5 minutes. Create a script to copy log files to Amazon S3, and add the script to EC2 instance user data. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to detect EC2 instance termination. Invoke an AWS Lambda function from the EventBridge (CloudWatch Events) rule that uses the AWS CLI to run the user-data script to copy the log files and terminate the instance.","D":"Create an AWS Systems Manager document with a script to copy log files to Amazon S3. Create an Auto Scaling lifecycle hook that publishes a message to an Amazon Simple Notification Service (Amazon SNS) topic. From the SNS notification, call the AWS Systems Manager API SendCommand operation to run the document to copy the log files and send ABANDON to the Auto Scaling group to terminate the instance."},"answers_community":["B (100%)"],"topic":"1","answer_ET":"D"},{"id":"V7z35kAHku8nmLlma9gW","unix_timestamp":1641624660,"question_images":[],"answer":"AD","answers_community":["AD (100%)"],"answer_images":[],"answer_description":"","topic":"1","discussion":[{"upvote_count":"5","timestamp":"1645990740.0","content":"i like A and D for this one. With A you can easily get the replica promoted with the RTO timescale and with D. If R53 detects a failure of one DB i will route traffic to the other DB. Both solutions meet the 15 RTO requirement","poster":"Ni_yot","comment_id":"557567"},{"upvote_count":"3","timestamp":"1658621760.0","poster":"hilft","comment_id":"635811","content":"A and D."},{"upvote_count":"4","content":"Selected Answer: AD\nAnswer is AD\nexample for this is here:\nhttps://cloudbasic.net/aws/rds/alwayson/dr/","poster":"asfsdfsdf","timestamp":"1657959240.0","comment_id":"632057"},{"upvote_count":"3","comment_id":"545693","content":"question from DevOps Prof exam","poster":"peddyua","timestamp":"1644649320.0"},{"upvote_count":"3","poster":"m0h3n","timestamp":"1641624660.0","content":"A - Automated failover using Lambda\nD - Failover route policy","comment_id":"519353"}],"question_text":"A solutions architect must implement a multi-Region architecture for an Amazon RDS for PostgreSQL database that supports a web application. The database launches from an AWS CloudFormation template that includes AWS services and features that are present in both the primary and secondary Regions.\nThe database is configured for automated backups, and it has an RTO of 15 minutes and an RPO of 2 hours. The web application is configured to use an Amazon\nRoute 53 record to route traffic to the database.\nWhich combination of steps will result in a highly available architecture that meets all the requirements? (Choose two.)","question_id":797,"timestamp":"2022-01-08 07:51:00","choices":{"A":"Create a cross-Region read replica of the database in the secondary Region. Configure an AWS Lambda function in the secondary Region to promote the read replica during failover event.","E":"Create a hot standby database in the secondary Region. Use an AWS Lambda function to restore the secondary database to the latest RDS automatic backup in the event that the primary database fails.","B":"In the primary Region, create a health check on the database that will invoke an AWS Lambda function when a failure is detected. Program the Lambda function to recreate the database from the latest database snapshot in the secondary Region and update the Route 53 host records for the database.","C":"Create an AWS Lambda function to copy the latest automated backup to the secondary Region every 2 hours.","D":"Create a failover routing policy in Route 53 for the database DNS record. Set the primary and secondary endpoints to the endpoints in each Region."},"exam_id":32,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/69659-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"AD"},{"id":"PRwRcibFO3n9mAT7z7Hz","url":"https://www.examtopics.com/discussions/amazon/view/8640-exam-aws-certified-solutions-architect-professional-topic-1/","timestamp":"2019-11-20 08:46:00","exam_id":32,"isMC":true,"question_images":[],"answer_ET":"B","answers_community":["B (100%)"],"topic":"1","answer_description":"","discussion":[{"content":"B looks correct one. with kinesis parallel processing using shards","timestamp":"1632513540.0","poster":"examacc","upvote_count":"22","comment_id":"22905","comments":[{"content":"B is correct answer, Keinesis can do online analytics.","poster":"nitinz","timestamp":"1635462180.0","upvote_count":"1","comment_id":"314349"}]},{"upvote_count":"18","timestamp":"1632692340.0","comment_id":"114159","content":"Pretty much anytime AWS exams use \"real-time,\" it's a pretty safe bet the answer has Kinesis in it.","poster":"roguecloud"},{"content":"B. Utilize Amazon Kinesis to collect the inbound sensor data, analyze the data with Kinesis clients and save the results to a Redshift cluster using EMR.","comment_id":"1266373","timestamp":"1723718160.0","poster":"amministrazione","upvote_count":"1"},{"content":"Selected Answer: B\nAnswer is B.","upvote_count":"1","poster":"iamRohanKaushik","timestamp":"1679377440.0","comment_id":"845557"},{"content":"Selected Answer: B\nB is only correct approach to go ahead this solution","timestamp":"1678458540.0","comment_id":"835105","poster":"gameoflove","upvote_count":"1"},{"timestamp":"1662161220.0","poster":"skywalker","upvote_count":"1","comment_id":"657905","content":"my vote is B"},{"content":"B correct.","poster":"cldy","comment_id":"514394","timestamp":"1641017760.0","upvote_count":"1"},{"timestamp":"1638323520.0","poster":"acloudguru","upvote_count":"3","comment_id":"491137","content":"B, i really like this collar, I will buy one for my dog, i also like this easy question, hope i can find it in my exam"},{"timestamp":"1636219440.0","upvote_count":"1","content":"B Correct","comment_id":"405778","poster":"Akhil254"},{"comment_id":"322488","upvote_count":"1","content":"B. - fulfills all three requirements.","poster":"cldy","timestamp":"1635494820.0"},{"comment_id":"264362","upvote_count":"2","poster":"Ajeeshpv","content":"yes B is correct. For analytic processing and Data mining Kinesis is the right tool","timestamp":"1635346020.0"},{"upvote_count":"3","comment_id":"253900","timestamp":"1635042300.0","poster":"Shan_lion","content":"I prefer B... \nWhen the question says \"Real Time\", then straight away the first option to come in our mind is Kinesis."},{"upvote_count":"1","poster":"Candid_Developer","timestamp":"1634815800.0","comment_id":"210216","content":"my vote is B"},{"timestamp":"1634433480.0","comment_id":"193318","upvote_count":"6","comments":[{"poster":"deejiw","upvote_count":"2","timestamp":"1634531400.0","content":"*Elastic and parallel -> Kinesis Shard","comment_id":"193319"},{"upvote_count":"1","timestamp":"1635741540.0","poster":"01037","comment_id":"323475","content":"Agree.\nI'll go for B too"}],"content":"B\nReal-time -> Kinesis\nScalable -> Kinesis Shard\nData mining -> Redshift","poster":"deejiw"},{"comment_id":"190456","poster":"un","timestamp":"1634407800.0","content":"B seems to be correct to me","upvote_count":"1"},{"poster":"srknbngl","timestamp":"1634390100.0","upvote_count":"1","content":"B is correct","comment_id":"190074"},{"content":"B is correct","timestamp":"1633503600.0","upvote_count":"2","comment_id":"143158","poster":"fullaws"},{"upvote_count":"1","comment_id":"138622","content":"I do not find a right answer, \nB seems to make most sense but the EMS does not fit\nC may work too, but I doubt AWS will push you towards MS SQL Server","poster":"MultiAZ","timestamp":"1633371720.0"},{"comment_id":"122461","upvote_count":"3","content":"go with B","timestamp":"1633165380.0","poster":"noisonnoiton"},{"timestamp":"1632682380.0","comment_id":"94620","poster":"JAWS1600","upvote_count":"1","comments":[{"comment_id":"119681","poster":"Lucifer8740","timestamp":"1633150140.0","upvote_count":"1","content":"You don't make any sense either."},{"comment_id":"163418","poster":"Jasperian","timestamp":"1634158020.0","content":">> Analyze data with Kinesis Clients - Does not make sense\"\n\"You can develop a consumer application for Amazon Kinesis Data Streams using the Kinesis Client Library (KCL)\"","upvote_count":"1"},{"upvote_count":"4","content":"D doesn't make any sense at all. B is valid as you can collects large amounts of data streaming constantly. EMR is not for collecting data but for analyzing it in real time.","comment_id":"115162","poster":"oatif","timestamp":"1633084320.0"}],"content":"D .\nB is invalid - \"analyze the data with Kinesis clients and save the results to a Redshift cluster using EMR\" \nSave results to Redshift with EMR ?? Does not make sense\nAnalyze data with Kinesis Clients - Does not make sense\nOption A - not correct dure to \"daily scheduled\"\nOption C - SQL server is not DWH - not food for data mining"},{"content":"Answer B","comment_id":"49621","upvote_count":"5","poster":"BillyC","timestamp":"1632566520.0"}],"question_text":"Your company is in the process of developing a next generation pet collar that collects biometric information to assist families with promoting healthy lifestyles for their pets. Each collar will push 30kb of biometric data in JSON format every 2 seconds to a collection platform that will process and analyze the data providing health trending information back to the pet owners and veterinarians via a web portal. Management has tasked you to architect the collection platform ensuring the following requirements are met.\n✑ Provide the ability for real-time analytics of the inbound biometric data\n✑ Ensure processing of the biometric data is highly durable. Elastic and parallel\n✑ The results of the analytic processing should be persisted for data mining\nWhich architecture outlined below win meet the initial requirements for the collection platform?","answer":"B","choices":{"C":"Utilize SQS to collect the inbound sensor data analyze the data from SQS with Amazon Kinesis and save the results to a Microsoft SQL Server RDS instance.","A":"Utilize S3 to collect the inbound sensor data analyze the data from S3 with a daily scheduled Data Pipeline and save the results to a Redshift Cluster.","D":"Utilize EMR to collect the inbound sensor data, analyze the data from EUR with Amazon Kinesis and save me results to DynamoDB.","B":"Utilize Amazon Kinesis to collect the inbound sensor data, analyze the data with Kinesis clients and save the results to a Redshift cluster using EMR."},"question_id":798,"unix_timestamp":1574235960,"answer_images":[]},{"id":"cjPEo9H1V9b7RCoE1DA3","discussion":[{"comment_id":"99708","timestamp":"1633909500.0","content":"\"Effect\": \"Deny\",\n\"Action\": \"iam:*\",\n\"Resource\": [\n\"arn:aws:iam::123456789012:group/marketing/*\",\n\nat the very top there is deny","poster":"oatif","upvote_count":"7"},{"comment_id":"1266701","upvote_count":"1","content":"B. False","poster":"amministrazione","timestamp":"1723756260.0"},{"timestamp":"1658765340.0","comment_id":"636814","upvote_count":"1","content":"deny IAM activity.\nFalse","poster":"hilft"},{"timestamp":"1646546340.0","comment_id":"561791","upvote_count":"1","poster":"Alvindo","content":"questions dissapeard :0"},{"upvote_count":"4","content":"Wait, what? Where's the question? :0","comment_id":"504992","timestamp":"1639932840.0","poster":"AkaAka4"},{"upvote_count":"1","comment_id":"328519","timestamp":"1635238440.0","poster":"cldy","content":"B. FALSE.\nDeny ALL actions on IAM (iam:*)"},{"poster":"eji","comment_id":"277497","upvote_count":"2","timestamp":"1634551740.0","content":"we can't specific bucket in s3:listbucket. CMIIW"}],"answer_ET":"B","question_id":799,"question_text":"Dave is the main administrator in Example Corp., and he decides to use paths to help delineate the users in the company and set up a separate administrator group for each path-based division. Following is a subset of the full list of paths he plans to use:\n* /marketing\n* /sales\n* /legal\nDave creates an administrator group for the marketing part of the company and calls it Marketing_Admin.\nHe assigns it the /marketing path. The group's ARN is arn:aws:iam::123456789012:group/marketing/Marketing_Admin.\nDave assigns the following policy to the Marketing_Admin group that gives the group permission to use all IAM actions with all groups and users in the /marketing path. The policy also gives the Marketing_Admin group permission to perform any AWS S3 actions on the objects in the portion of the corporate bucket.\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Deny\",\n\"Action\": \"iam:*\",\n\"Resource\": [\n\"arn:aws:iam::123456789012:group/marketing/*\",\n\"arn:aws:iam::123456789012:user/marketing/*\"\n]\n},\n{\n\"Effect\": \"Allow\",\n\"Action\": \"s3:*\",\n\"Resource\": \"arn:aws:s3:::example_bucket/marketing/*\"\n},\n{\n\"Effect\": \"Allow\",\n\"Action\": \"s3:ListBucket*\",\n\"Resource\": \"arn:aws:s3:::example_bucket\",\n\"Condition\":{\"StringLike\":{\"s3:prefix\": \"marketing/*\"}}\n}\n]\n}","answers_community":[],"unix_timestamp":1590983340,"answer":"B","question_images":[],"timestamp":"2020-06-01 05:49:00","exam_id":32,"url":"https://www.examtopics.com/discussions/amazon/view/21692-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"topic":"1","answer_description":"Effect Deny","isMC":true,"choices":{"B":"False","A":"True"}},{"id":"99GwVVwbi8skrXKPg8H5","answer_images":[],"exam_id":32,"answers_community":["CD (61%)","AD (39%)"],"answer":"CD","answer_description":"","discussion":[{"comment_id":"644864","timestamp":"1660120380.0","content":"Selected Answer: CD\nA incorrrect: default oldest launchconfiguration will be terminated first\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-termination-policies.html\n\nB. Incorrect: No need to create a new ASG\nC. Correct: Need a loadbalancer to make sure the request route to the healthy instance.\nD. Correct: Script to update OS patch, Lambda to update a launch configuration and trigger Autoscaling Instance refresh\nE. Incorrect: Termination protection is not help.","poster":"foureye2004","upvote_count":"10"},{"comment_id":"1008957","poster":"rodrod","content":"Selected Answer: CD\nA does not make sense. D will replace all instances anyways.\nA makes sense for other scenarios like scale in. Az rebalancing etc","timestamp":"1694846520.0","upvote_count":"1"},{"timestamp":"1689685140.0","content":"Correct CD.","upvote_count":"1","poster":"ggrodskiy","comment_id":"955432"},{"content":"D cannot be correct, as only launch templates can be modified and not legacy launch configuration","upvote_count":"2","timestamp":"1674333060.0","poster":"AjayD123","comment_id":"783720"},{"upvote_count":"4","content":"C and D. \nThe following example updates an Auto Scaling group with a newly patched AMI. This approach ensures that new images are automatically made available to different computing environments that use Auto Scaling groups.\n\nThe final step of the automation in this example uses a Python function to create a new launch template that uses the newly patched AMI. Then the Auto Scaling group is updated to use the new launch template. In this type of Auto Scaling scenario, users could terminate existing instances in the Auto Scaling group to force a new instance to launch that uses the new image. Or, users could wait and allow scale-in or scale-out events to naturally launch newer instances.","comment_id":"658736","timestamp":"1662229560.0","poster":"Ni_yot"},{"timestamp":"1657961640.0","content":"Selected Answer: AD\nE and B are eliminated they don't make any sense\nD is a must since need to patch the AMI and create a new launch configuration update it in the AS and execute refresh. \nBoth A and C are correct for this use case, C - will make sure servers are running correctly after patching and A will make sure the unpatched EC2s will be terminated first. \nSince the requirement is to make sure ASG is to have only latest configuration I have to choose AD - if A was with \"SkipMatching\" it was making more sense","comment_id":"632068","poster":"asfsdfsdf","upvote_count":"3"},{"upvote_count":"3","content":"Selected Answer: AD\nEven through you cannot update launch config, I suppose it's AD\nRight by the book:\n- latest ami in ASG\n- instances refresh","poster":"bobsmith2000","timestamp":"1654150740.0","comment_id":"610467"},{"comment_id":"598756","upvote_count":"1","timestamp":"1652050320.0","content":"A/D, you need to update AMI otherwise you wont get the latest or resolve the security issue","poster":"user0001"},{"timestamp":"1649934660.0","poster":"SaiKrish123","comment_id":"585719","upvote_count":"1","content":"C&D in autoscaling group launch configuration need to be updated with AMI"},{"timestamp":"1645366740.0","upvote_count":"1","poster":"Alexey79","content":"Selected Answer: AD\nA\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html\n“The termination policy for the Auto Scaling group controls which instances are replaced first.”\n“If you did not assign a specific termination policy to the group, Amazon EC2 Auto Scaling uses the default termination policy. It selects the Availability Zone with two instances, and terminates the instance that was launched from the oldest launch template or launch configuration.”\n\nBoth C and D correct and describe need for refresh EC2 Instances with newest template. But, C doesn’t mention Patching phase, only D does. In question, ELB requirement is not mentioned.","comment_id":"551852"},{"upvote_count":"2","content":"C And D:\nhttps://aws.amazon.com/blogs/compute/introducing-instance-refresh-for-ec2-auto-scaling/#:~:text=You%20can%20trigger%20an%20Instance,ASG%20terminates%20and%20launches%20instances.","comment_id":"544120","timestamp":"1644445320.0","poster":"usmanbaigmughal"},{"poster":"saeidp","content":"C and D\nWalkthrough: Simplify AMI patching using Automation, AWS Lambda, and Parameter Store\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/automation-walk-patch-windows-ami-simplify.html\n\nWalkthrough: Patch an AMI and update an Auto Scaling group\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/automation-walk-patch-windows-ami-autoscaling.html","timestamp":"1642980000.0","comment_id":"530900","upvote_count":"2"},{"timestamp":"1641316080.0","content":"Answer is A & C\nTo change the launch configuration for an Auto Scaling group, use an existing launch configuration as the basis for a new launch configuration. Then, update the Auto Scaling group to use the new launch configuration. After you change the launch configuration for an Auto Scaling group, any new instances are launched using the new configuration options, but existing instances are not affected. To update the existing instances, terminate them so that they are replaced by your Auto Scaling group, or allow auto scaling to gradually replace older instances with newer instances based on your termination policies.\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/change-launch-config.html","poster":"Smartphone","upvote_count":"1","comment_id":"516853"},{"timestamp":"1640868300.0","comment_id":"513360","upvote_count":"1","content":"I believe it should be A & C","poster":"AwsSuperTrooper"},{"comments":[{"content":"C And D\nFor E : Termination protection have no sense.\n\nhttps://aws.amazon.com/blogs/compute/introducing-instance-refresh-for-ec2-auto-scaling/#:~:text=You%20can%20trigger%20an%20Instance,ASG%20terminates%20and%20launches%20instances.","upvote_count":"1","timestamp":"1644445380.0","poster":"usmanbaigmughal","comment_id":"544121","comments":[{"timestamp":"1649999520.0","poster":"sashsz","comment_id":"586162","upvote_count":"1","content":"D & E - make sure that the new instances are patched after they are created and keep the old running to serve the traffic. NO much to think about ."}]}],"content":"Think its D & E","upvote_count":"3","timestamp":"1640747940.0","poster":"techn00b","comment_id":"511744"}],"question_images":[],"question_id":800,"topic":"1","question_text":"A company has used infrastructure as code (IaC) to provision a set of two Amazon EC2 instances. The instances have remained the same for several years.\nThe company's business has grown rapidly in the past few months. In response the company's operations team has implemented an Auto Scaling group to manage the sudden increases in traffic. Company policy requires a monthly installation of security updates on all operating systems that are running.\nThe most recent security update required a reboot. As a result, the Auto Scaling group terminated the instances and replaced them with new, unpatched instances.\nWhich combination of steps should a solutions architect recommend to avoid a recurrence of this issue? (Choose two.)","timestamp":"2021-12-29 04:19:00","unix_timestamp":1640747940,"isMC":true,"answer_ET":"CD","url":"https://www.examtopics.com/discussions/amazon/view/68855-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"D":"Create automation scripts to patch an AMI, update the launch configuration, and invoke an Auto Scaling instance refresh.","C":"Create an Elastic Load Balancer in front of the Auto Scaling group. Configure monitoring to ensure that target group health checks return healthy after the Auto Scaling group replaces the terminated instances.","A":"Modify the Auto Scaling group by setting the Update policy to target the oldest launch configuration for replacement.","B":"Create a new Auto Scaling group before the next patch maintenance. During the maintenance window, patch both groups and reboot the instances.","E":"Create an Elastic Load Balancer in front of the Auto Scaling group. Configure termination protection on the instances."}}],"exam":{"provider":"Amazon","id":32,"numberOfQuestions":1019,"isImplemented":true,"isBeta":false,"name":"AWS Certified Solutions Architect - Professional","isMCOnly":false,"lastUpdated":"11 Apr 2025"},"currentPage":160},"__N_SSP":true}