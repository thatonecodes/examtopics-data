{"pageProps":{"questions":[{"id":"0oycM2szvlfelAY3GtGQ","answer":"B","answer_description":"","answer_images":[],"answer_ET":"B","question_id":716,"question_images":[],"answers_community":["B (100%)"],"unix_timestamp":1707157980,"timestamp":"2024-02-05 19:33:00","topic":"1","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/132904-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company maintains about 300 TB in Amazon S3 Standard storage month after month. The S3 objects are each typically around 50 GB in size and are frequently replaced with multipart uploads by their global application. The number and size of S3 objects remain constant, but the company's S3 storage costs are increasing each month.\n\nHow should a solutions architect reduce costs in this situation?","exam_id":31,"discussion":[{"upvote_count":"1","timestamp":"1726631400.0","comment_id":"1285559","poster":"MatAlves","comments":[{"timestamp":"1726631400.0","poster":"MatAlves","comment_id":"1285560","content":"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpu-abort-incomplete-mpu-lifecycle-config.html","upvote_count":"1"}],"content":"Selected Answer: B\nB - No brainer."},{"poster":"alawada","content":"Selected Answer: B\nOptimize multipart uploads to reduce costs associated with storing incomplete multipart upload parts. Ensure that multipart uploads are completed and the parts are assembled into complete objects in a timely manner to avoid unnecessary storage costs.","timestamp":"1711128300.0","comment_id":"1180217","upvote_count":"4"},{"upvote_count":"4","poster":"Typewriter101","content":"Selected Answer: B\nwhen primary concern is cost and the data transfer multipart upload may be the more cost-effective than S3 transfer acceleration. So switching to s3 TA is won't be reasonable.","timestamp":"1708003680.0","comment_id":"1151025"},{"content":"Option B is correct","timestamp":"1707358260.0","comment_id":"1143973","upvote_count":"2","poster":"Umuntu"},{"poster":"Andy_09","content":"Option B","comment_id":"1141345","upvote_count":"3","timestamp":"1707157980.0"}],"choices":{"C":"Configure S3 inventory to prevent objects from being archived too quickly.","A":"Switch from multipart uploads to Amazon S3 Transfer Acceleration.","B":"Enable an S3 Lifecycle policy that deletes incomplete multipart uploads.","D":"Configure Amazon CloudFront to reduce the number of objects stored in Amazon S3."}},{"id":"BRGYtWM1VMyY2y2pV9jp","question_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/132906-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"comments":[{"content":"its bezos with his alt accounts.","poster":"1e22522","upvote_count":"4","comment_id":"1262127","timestamp":"1723041240.0"}],"poster":"Rhydian25","content":"Selected Answer: D\nWhy are people voting for C? PostgreSQL is a relational DB. DynamoDB is NoSQL.\n\nIt makes no sense","comment_id":"1239416","upvote_count":"7","timestamp":"1719693840.0"},{"content":"Selected Answer: D\nTo add more to all the answer Redis has built-in support for geospatial data, making it ideal for updates and retrieval of locations.","poster":"Dantecito","timestamp":"1739835360.0","upvote_count":"1","comment_id":"1358033"},{"timestamp":"1726631820.0","upvote_count":"1","comment_id":"1285562","comments":[{"poster":"MatAlves","comment_id":"1285564","content":"Specific to Redis, ElastiCache lets you “scale in” or “scale out” both reads and writes. Cluster mode offers added shard support, enabling write scaling. \n\nhttps://aws.amazon.com/blogs/database/building-a-real-time-gaming-leaderboard-with-amazon-elasticache-for-redis/","timestamp":"1726631940.0","upvote_count":"2"}],"poster":"MatAlves","content":"Selected Answer: D\nRefer to https://www.examtopics.com/discussions/amazon/view/53854-exam-aws-certified-solutions-architect-associate-saa-c02/"},{"content":"Selected Answer: D\nI confuse, Is DAX working with RDS?","poster":"Lin878","timestamp":"1719621240.0","comment_id":"1238970","upvote_count":"1"},{"content":"Selected Answer: D\nThe answer C is not making any sense with \"Deploy Amazon DynamoDB Accelerator (DAX) in front of the existing DB instance.\", because AWS DynamoDB is a DBaaS.","comment_id":"1237550","timestamp":"1719415020.0","upvote_count":"2","poster":"Jacky_S"},{"upvote_count":"2","comment_id":"1237519","content":"Selected Answer: D\nAnswerD\n\nElastiCache is a fully managed, in-memory caching service that provides microsecond read and write latencies that support flexible, real-time use cases.\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/creating-elasticache-cluster-with-RDS-settings.html","timestamp":"1719412080.0","poster":"Scheldon","comments":[{"poster":"Scheldon","upvote_count":"1","comment_id":"1237520","content":"Beside DAX is for DynamoDB and I think it will not work with RDS","timestamp":"1719412140.0"}]},{"poster":"ug56c","content":"Selected Answer: D\nAmazon ElastiCache for Redis for RDS","comment_id":"1232530","timestamp":"1718728980.0","upvote_count":"1"},{"comment_id":"1224645","content":"Selected Answer: C\n\" writing updates\" so it shoud be DAX.","upvote_count":"2","timestamp":"1717581300.0","poster":"sheilawu"},{"timestamp":"1716474420.0","comments":[{"upvote_count":"1","content":"Vote for C (DAX) as ElastiCache for Redis cluster only helps on read operation but not write operation.","comment_id":"1216647","poster":"f07ed8f","timestamp":"1716474420.0"}],"content":"Selected Answer: C\nVote for C (DAX) as ElastiCache for Redis cluster only helps on read operation but not white.","comment_id":"1216646","poster":"f07ed8f","upvote_count":"4"},{"content":"Performance >> Amazon ElastiCache for Redis cluster","poster":"sirajtr47","timestamp":"1715048820.0","comments":[{"upvote_count":"1","comments":[{"comment_id":"1237547","timestamp":"1719414720.0","upvote_count":"1","poster":"Jacky_S","content":"i agree with DAX, but how it can be deploying in front of DB instance? Since that is a DBaaS."}],"poster":"Rylz","content":"Yeah, but this is an online game that need to update everything instantly so i don't think that caching is the right method here\nthink about it, you are making movments in the online game its like loading new data all the time, so each time you move you load the cache for next time usage. what if you dont need to use it again? \ni dont think elasticache is the right method here so it leave us with DAX\nwhat do you think?","timestamp":"1717407060.0","comment_id":"1223508"}],"upvote_count":"4","comment_id":"1207683"},{"comment_id":"1155811","timestamp":"1708543500.0","content":"Selected Answer: D\nD looks correct","upvote_count":"2","poster":"FZA24"},{"upvote_count":"4","comment_id":"1143974","content":"D looks correct","timestamp":"1707358500.0","poster":"Umuntu"},{"timestamp":"1707158160.0","comment_id":"1141347","poster":"Andy_09","content":"Looks correct","upvote_count":"2"}],"answers_community":["D (74%)","C (26%)"],"topic":"1","isMC":true,"answer":"D","question_id":717,"choices":{"C":"Deploy Amazon DynamoDB Accelerator (DAX) in front of the existing DB instance. Modify the game to use DAX.","B":"Migrate from Amazon RDS to Amazon OpenSearch Service with OpenSearch Dashboards.","D":"Deploy an Amazon ElastiCache for Redis cluster in front of the existing DB instance. Modify the game to use Redis.","A":"Take a snapshot of the existing DB instance. Restore the snapshot with Multi-AZ enabled."},"question_text":"A company has deployed a multiplayer game for mobile devices. The game requires live location tracking of players based on latitude and longitude. The data store for the game must support rapid updates and retrieval of locations.\n\nThe game uses an Amazon RDS for PostgreSQL DB instance with read replicas to store the location data. During peak usage periods, the database is unable to maintain the performance that is needed for reading and writing updates. The game's user base is increasing rapidly.\n\nWhat should a solutions architect do to improve the performance of the data tier?","answer_images":[],"exam_id":31,"unix_timestamp":1707158160,"answer_ET":"D","timestamp":"2024-02-05 19:36:00"},{"id":"2crPxUAJL3DxJY4ctNKU","isMC":true,"choices":{"D":"Enable point-in-time recovery on the DynamoDB tables.","C":"Configure deletion protection on the DynamoDB tables.","B":"Create a backup and restore plan for the DynamoDB tables. Recover the DynamoDB tables manually.","A":"Configure a trail in AWS CloudTrail. Create an Amazon EventBridge rule for delete actions. Create an AWS Lambda function to automatically restore deleted DynamoDB tables."},"answers_community":["C (100%)"],"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/132907-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company stores critical data in Amazon DynamoDB tables in the company's AWS account. An IT administrator accidentally deleted a DynamoDB table. The deletion caused a significant loss of data and disrupted the company's operations. The company wants to prevent this type of disruption in the future.\n\nWhich solution will meet this requirement with the LEAST operational overhead?","answer_images":[],"topic":"1","question_id":718,"answer_ET":"C","answer_description":"","unix_timestamp":1707158340,"exam_id":31,"answer":"C","timestamp":"2024-02-05 19:39:00","discussion":[{"poster":"BillaRanga","comment_id":"1152051","upvote_count":"15","comments":[{"poster":"BillaRanga","timestamp":"1723810260.0","upvote_count":"3","comment_id":"1152053","content":"Option B and D talks about recovering but not preventing. A is tooooo much work"}],"content":"Selected Answer: C\nhttps://aws.amazon.com/about-aws/whats-new/2023/03/amazon-dynamodb-table-deletion-protection/\n\nDeletion protection is now available for Amazon DynamoDB tables in all AWS Regions. DynamoDB now makes it possible for you to protect your tables from accidental deletion when performing regular table management operations. When creating new tables or managing existing tables, authorized administrators can set the deletion protection property for each table, which will govern whether a table can be deleted.","timestamp":"1723810200.0"},{"poster":"Andy_09","upvote_count":"5","comment_id":"1141349","timestamp":"1722875940.0","content":"Option C"},{"comment_id":"1151028","poster":"Typewriter101","content":"Selected Answer: C\nB involves more operations.","timestamp":"1723721580.0","upvote_count":"3"}]},{"id":"ybsDkqEv8oj2hDmZwSXJ","question_images":[],"answers_community":["B (58%)","C (42%)"],"timestamp":"2024-02-05 19:53:00","unix_timestamp":1707159180,"answer_description":"","answer":"B","answer_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/132910-exam-aws-certified-solutions-architect-associate-saa-c03/","exam_id":31,"answer_ET":"B","question_id":719,"question_text":"A company has an on-premises data center that is running out of storage capacity. The company wants to migrate its storage infrastructure to AWS while minimizing bandwidth costs. The solution must allow for immediate retrieval of data at no additional cost.\n\nHow can these requirements be met?","choices":{"D":"Deploy AWS Direct Connect to connect with the on-premises data center. Configure AWS Storage Gateway to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.","A":"Deploy Amazon S3 Glacier Vault and enable expedited retrieval. Enable provisioned retrieval capacity for the workload.","C":"Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.","B":"Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally."},"discussion":[{"timestamp":"1708446000.0","content":"B is the correct one because:\n\"A company has an on-premises data center that is running out of storage capacity\".\nSo when they keep data on-premis and do the backup to S3 they'll run out of data and this is not their purpose.","upvote_count":"10","comment_id":"1154840","comments":[{"poster":"Sergantus","comment_id":"1309242","upvote_count":"1","content":"Storage Gateway in Stored mode DOS does NOT improve capacity – the main copy of data is stored on the gateway. It's B for that same reason","timestamp":"1731197820.0"}],"poster":"67a3f49"},{"timestamp":"1710519120.0","poster":"JCVDB23","comment_id":"1174371","content":"Selected Answer: B\nB. Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally.\n\nAWS Storage Gateway’s cached volumes let you use Amazon S3 as your primary data storage while retaining frequently accessed data locally in your storage gateway. Cached volumes minimize the need to scale your on-premises storage infrastructure, while still providing your applications with low-latency access to their frequently accessed data. All data transferred between your gateway and AWS storage is encrypted for security. You can also save on data transfer costs as AWS Storage Gateway compresses all data transferred between the gateway and AWS, allowing you to store more data in AWS while reducing your data transfer costs.","upvote_count":"7"},{"poster":"tch","comment_id":"1344983","timestamp":"1737586140.0","content":"Selected Answer: B\nIn the cached Volume Gateway mode, your primary data is stored in Amazon S3, while retaining your frequently accessed data locally in the cache for low latency access. In the stored Volume Gateway mode, your primary data is stored locally and your entire dataset is available for low latency access on premises while also asynchronously getting backed up to Amazon S3","upvote_count":"2"},{"content":"Selected Answer: B\nAnother headache one. Well, I'll go for B for now.\nA - Really cost-effective, but immediate retrievals incurs additional costs.\nB - Less optimal for datasets where most data is accessed frequently and must be immediately available locally.\nC - The on-prem data center \"is running out of storage capacity\". Then why store everything locally? Why even migrate storage infrastructure to AWS...\nD - Like C, and also, bandwidth costs are not acceptable.","poster":"LeonSauveterre","timestamp":"1734663120.0","comment_id":"1329259","upvote_count":"1"},{"poster":"Lin878","comments":[{"content":"you don't fool me bezos boy","upvote_count":"3","comment_id":"1262130","poster":"1e22522","timestamp":"1723041480.0"}],"comment_id":"1238972","timestamp":"1719621780.0","upvote_count":"1","content":"Selected Answer: C\nI vote \"C\" because Question doesn't mention to access frequent data. If they want access frequent data, I will vote \"B\" with cached volume."},{"upvote_count":"1","timestamp":"1719412980.0","content":"Selected Answer: B\nAnswerB\n\nI think B answer is the best option here. We will store only data which are frequently accessed and all other we will sent to the cloud. So we will have access to all data but hence most frequently accessed data will be stored in On-Premises Cache we will not pay a lot of additionally $$ for data transfer if any.","poster":"Scheldon","comment_id":"1237531"},{"timestamp":"1718461560.0","comment_id":"1231026","poster":"ike001","upvote_count":"1","content":"C is the correct. answer"},{"poster":"mohammadthainat","comment_id":"1188430","timestamp":"1712111760.0","upvote_count":"3","content":"Selected Answer: B\n1- \"The company wants to migrate its storage infrastructure to AWS\" ->> B as data will be migrated to AWS.\n\n2- \"The solution must allow for immediate retrieval of data at no additional cost.\" ->> B as data will be stored in S3 Standard storage class which provide immediate data retrieval"},{"timestamp":"1711346580.0","content":"Selected Answer: C\nimmediate retrieval of data → shoud have full data set on-premises => stored volumes AWS Storage Gateway","poster":"gsgdga","upvote_count":"4","comment_id":"1182237"},{"content":"B - as the company is migrating their data to AWS so data has to be stored in the cloud.","timestamp":"1708631760.0","upvote_count":"2","poster":"rubiteb","comment_id":"1156666"},{"content":"C>>>\nCached Mode: In this mode, your primary data resides in Amazon S3, while frequently accessed data is cached locally for low-latency access.\nStored Mode: Here, your entire dataset is stored locally, allowing low-latency access on premises. Simultaneously, the data is asynchronously backed up to Amazon S3.","comments":[{"upvote_count":"1","poster":"MatAlves","content":"How does that address the fact the company is \"running out of storage capacity\"?","timestamp":"1726632600.0","comment_id":"1285567"}],"poster":"osmk","timestamp":"1708183620.0","upvote_count":"4","comment_id":"1152648"},{"comments":[{"poster":"sandordini","timestamp":"1714114200.0","comment_id":"1202421","upvote_count":"1","content":"D: It never said one month would be a problem.. Question doesn't state a matter of urgency, but it still stores the data on-prem, and synchronizes to AWS. \nC: The same issue as D. Stores data locally, but our on-prem storage is full. Thats why the company wants cloud.\nA: Has retrieval costs."},{"poster":"xBUGx","upvote_count":"1","content":"i was voting for C, but C doesnt solve on prem out of capacity issue.","comment_id":"1189374","timestamp":"1712239140.0"}],"timestamp":"1708092960.0","content":"Selected Answer: C\nD -> It takes One month to set up AWS Direct Connect setup\nA -> No sense as it talks nothing about On-Prem\nB -> Cached volume only stores frequently access data On-Prem, But requirement tells \"Data\" so we assume it tells All data\n\nC -> Correct, as Stored volumes stores everything in Storage Gateway On-Prem while asynchronously backing up to the cloud","poster":"BillaRanga","upvote_count":"5","comment_id":"1152058"},{"upvote_count":"2","poster":"jaswantn","content":"option C... data being accessible through stored volume reduces bandwidth cost and provides immediate retrieval of data.","comment_id":"1146930","timestamp":"1707616680.0"},{"poster":"Andy_09","content":"Option C, as it makes all the data available for low-latency access.","timestamp":"1707159180.0","upvote_count":"2","comment_id":"1141356"}],"isMC":true},{"id":"Ob6uIQzecSa9pIAvO0Lr","url":"https://www.examtopics.com/discussions/amazon/view/132911-exam-aws-certified-solutions-architect-associate-saa-c03/","timestamp":"2024-02-05 19:56:00","answer_images":[],"discussion":[{"poster":"sandordini","comment_id":"1202422","content":"Selected Answer: B\nNot A: Only handles Dynamic scaling, not pattern-based/predictive scaling.\nB: Both Predictive and dynamic\nNot C: Manual version of predictive, lacks live circumstances..\nNot D: The question doesn't talk about cool down period...","upvote_count":"3","timestamp":"1729925820.0"},{"timestamp":"1727020380.0","content":"https://aws.amazon.com/blogs/aws/new-predictive-scaling-for-ec2-powered-by-machine-learning/","comment_id":"1180223","poster":"alawada","upvote_count":"2"},{"upvote_count":"4","content":"Selected Answer: B\nBy configuring dynamic scaling with target tracking, the company can automatically adjust resources based on the forecasted demand while also responding to live changes in utilization","poster":"BillaRanga","comment_id":"1152064","timestamp":"1723810740.0"},{"comment_id":"1141360","upvote_count":"4","timestamp":"1722876960.0","poster":"Andy_09","content":"Option B"}],"isMC":true,"answers_community":["B (100%)"],"unix_timestamp":1707159360,"topic":"1","exam_id":31,"answer":"B","answer_ET":"B","question_id":720,"question_text":"A company runs a three-tier web application in a VPC across multiple Availability Zones. Amazon EC2 instances run in an Auto Scaling group for the application tier.\n\nThe company needs to make an automated scaling plan that will analyze each resource's daily and weekly historical workload trends. The configuration must scale resources appropriately according to both the forecast and live changes in utilization.\n\nWhich scaling strategy should a solutions architect recommend to meet these requirements?","question_images":[],"answer_description":"","choices":{"D":"Set up a simple scaling policy. Increase the cooldown period based on the EC2 instance startup time.","A":"Implement dynamic scaling with step scaling based on average CPU utilization from the EC2 instances.","B":"Enable predictive scaling to forecast and scale. Configure dynamic scaling with target tracking","C":"Create an automated scheduled scaling action based on the traffic patterns of the web application."}}],"exam":{"isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":true,"id":31,"numberOfQuestions":1019,"isBeta":false,"name":"AWS Certified Solutions Architect - Associate SAA-C03","provider":"Amazon"},"currentPage":144},"__N_SSP":true}