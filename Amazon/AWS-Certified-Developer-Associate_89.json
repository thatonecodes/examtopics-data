{"pageProps":{"questions":[{"id":"4LI84Uv3VX2mHi6xoMvT","question_images":["https://www.examtopics.com/assets/media/exam-media/04238/0005000001.png"],"exam_id":25,"question_id":441,"answer_ET":"B","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/5283-exam-aws-certified-developer-associate-topic-1-question-97/","unix_timestamp":1568699100,"answer_images":[],"isMC":true,"choices":{"B":"Use aws cloudformation package to upload the source code to an Amazon S3 bucket and produce a modified CloudFormation template.","D":"Use aws serverless create-package to embed the source file directly into the existing CloudFormation template.","C":"Use aws lambda zip to package the source file together with the CloudFormation template and deploy the resulting zip archive.","A":"Use aws cloudformation compile to base64 encode and embed the source file into a modified CloudFormation template."},"question_text":"Given the source code for an AWS Lambda function in the local file store.py containing a handler function called get_store and the following AWS\nCloudFormation template:\n//IMG//\n\nWhat should be done to prepare the template so that it can be deployed using the AWS CLI command aws cloudformation deploy?","topic":"1","answers_community":["B (100%)"],"answer":"B","discussion":[{"timestamp":"1632249720.0","upvote_count":"28","content":"B. Use aws cloudformation package to upload the source code to an Amazon S3 bucket and produce a modified CloudFormation template.\nhttps://docs.aws.amazon.com/cli/latest/reference/cloudformation/package.html\n(...) Examples\nFollowing command exports a template named template.json by uploading local artifacts to S3 bucket bucket-name and writes the exported template to packaged-template.json:\naws cloudformation package --template-file /path_to_template/template.json --s3-bucket bucket-name --output-template-file packaged-template.json","comment_id":"11623","poster":"awscertified"},{"poster":"Kane","content":"Answer is 'B'. First of all packaging the source code and uploading to s3 then deploy the code with s3 url.","upvote_count":"12","comment_id":"11369","timestamp":"1632130980.0"},{"poster":"sumanshu","content":"Selected Answer: B\nWhen deploying an AWS Lambda function using a CloudFormation template, the Lambda function's source code must be made accessible for deployment.","timestamp":"1734612360.0","comment_id":"1328968","upvote_count":"1"},{"content":"Selected Answer: B\nB is the correct answer. We need to launch sam package first, in order to upload the code on S3 and create a cloudformation template and sam deploy after, in order to run the CF template and create the resources. \nP.S. instead of \"sam\" we can also run \"aws cloudformation\" command.","timestamp":"1687963860.0","poster":"rcaliandro","upvote_count":"1","comment_id":"936789"},{"poster":"sichilam","content":"B is the answer","timestamp":"1673392740.0","comment_id":"771888","upvote_count":"1"},{"poster":"tasbasi","content":"Selected Answer: B\nas stated by 'awscertified',\naws cloudformation package ->> (which will upload to s3)\naws cloudformation deploy ->> (deploy from s3 via AWS Cli)","comment_id":"589491","timestamp":"1650555840.0","upvote_count":"4"},{"poster":"KingGuo","upvote_count":"1","comment_id":"544961","content":"Selected Answer: B\nANS: B","timestamp":"1644544860.0"},{"content":"ANS: B","poster":"JP_PA","upvote_count":"1","comment_id":"542734","timestamp":"1644273540.0"},{"comment_id":"444081","upvote_count":"1","timestamp":"1636302360.0","poster":"Mal_8","content":"Ans: B"},{"poster":"praveenas400","comment_id":"391195","timestamp":"1636166760.0","upvote_count":"2","content":"Answer is B"},{"upvote_count":"1","comments":[{"comment_id":"510512","content":"B: Command “aws serverless create-package” does not exist.\naws cloudformation package – is the same as \"sam package\" and can be used with SAM","timestamp":"1640625960.0","upvote_count":"3","poster":"t33me"}],"comment_id":"361484","poster":"capoitas","timestamp":"1635402120.0","content":"The answer is D because in the first line of the template the transform is set to the SAM transform, also the resource type is Serverless::Function. So i guess we can assume this is a SAM template. Now i'm not sure that command exists, but it makes sense to do."},{"timestamp":"1635262680.0","content":"Ans : B","comment_id":"308989","upvote_count":"2","poster":"wils3"},{"upvote_count":"1","poster":"kkdd","timestamp":"1635092460.0","content":"B is correct. \n\nhttps://aws.nz/best-practice/cloudformation-package-deploy/\n~ $ aws cloudformation package \\\n --template-file template.yml \\\n --output-template-file template.packaged.yml \\\n --s3-bucket {some-bucket}\n\n ~ $ aws cloudformation deploy \\\n --template-file template.packaged.yml \\\n --stack-name {some-name}","comment_id":"248326"},{"comment_id":"247422","timestamp":"1635024900.0","content":"B is the answer\n\nD is for SAM CLI","poster":"RicardoD","upvote_count":"1"},{"poster":"cafeaulait","timestamp":"1634940240.0","upvote_count":"1","content":"Answer: B","comment_id":"245966"},{"poster":"codeScalable","timestamp":"1634916000.0","upvote_count":"2","comment_id":"191191","content":"I strongly believe the answer is D, using SAM"},{"upvote_count":"5","content":"What's going on with the revealed solution? Isn't that something set by those who make those questions? I'm getting a little confused here. I think that the answer is 'B' like everyone else here. But the revealed solution says its 'D'. Very confused","comment_id":"183051","poster":"hulala","comments":[{"content":"I am also Very confused. Who is revealing the answer here. Please explain why it was 'D'","comment_id":"324193","timestamp":"1635312900.0","poster":"loyfra","upvote_count":"1"}],"timestamp":"1634881560.0"},{"upvote_count":"2","timestamp":"1634682540.0","content":"B is correct","poster":"saeidp","comment_id":"171568"},{"timestamp":"1634530020.0","upvote_count":"3","comment_id":"138503","poster":"KhatriRocks","content":"Yes, I'll go with B"},{"timestamp":"1634126820.0","upvote_count":"2","comment_id":"124961","poster":"Scarback","content":"Resp: B"},{"timestamp":"1634114880.0","upvote_count":"10","content":"B\n\nSTEP 1: Run the CloudFormation package command\n\nThe following command creates a .zip file containing the function's source code folder, and then uploads the .zip file to the root folder of the my-bucket bucket.\n\naws cloudformation package --template /path_to_template/template.json --s3-bucket mybucket --output json > packaged-template.json\n\nIn addition to uploading the .zip file to the S3 bucket, the above command also saves the template that it generates to the path specified by the --output option as below\n\nOutput:\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: 'AWS::Serverless-2016-10-31'\nResources:\n MyFunction:\n Type: 'AWS::Serverless::Function'\n Properties:\n Handler: index.handler\n Runtime: nodejs8.10\n CodeUri: s3://mybucket/lambdafunction.zip\n\nSTEP 2: Run the CloudFormation deploy command by passing the above template as parameter\n\naws cloudformation deploy --template /path_to_template/my-template.json --stack-name my-new-stack --parameter-overrides Key1=Value1 Key2=Value2","comment_id":"124344","poster":"onlinebaba"},{"timestamp":"1633808520.0","comment_id":"116733","content":"B is correct, D can also be used if aws cli is not specified in the question (SAM uses serverless cli)","poster":"Inv","upvote_count":"6"},{"poster":"vickey","timestamp":"1633496280.0","comment_id":"110480","content":"Why Not \"D\"? Use SAM with cloud formation?","upvote_count":"2"},{"content":"Does cli command \"aws serverless create-package\" even exist?","comment_id":"96100","upvote_count":"1","timestamp":"1633441800.0","poster":"newme"},{"timestamp":"1632978000.0","upvote_count":"4","comment_id":"57489","content":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-cli-package.html\n\nUploading Local Artifacts to an S3 Bucket\n...\nInstead of manually uploading the files to an S3 bucket and then adding the location to your template, you can specify local references, called local artifacts, in your template and then use the package command to quickly upload them. A local artifact is a path to a file or folder that the package command uploads to Amazon S3.\n...\nIf you specify a file, the command directly uploads it to the S3 bucket. After uploading the artifacts, the command returns a copy of your template, replacing references to local artifacts with the S3 location where the command uploaded the artifacts. Then, you can use the returned template to create or update a stack.","comments":[{"upvote_count":"1","comment_id":"57490","content":"So the answer goes to B.","timestamp":"1633186320.0","poster":"Bach999"},{"upvote_count":"1","timestamp":"1633247580.0","poster":"Bach999","comment_id":"57491","content":"Package Command\n\naws cloudformation package --template /path_to_template/template.json --s3-bucket mybucket --output json > packaged-template.json\nThe command saves the template that it generates to the path specified by the --output option. The command replaces the artifact with the S3 location, as shown in the following example:"}],"poster":"Bach999"},{"upvote_count":"1","comment_id":"50948","timestamp":"1632898680.0","poster":"jonnalagadda","content":"Ans: B"},{"timestamp":"1632817920.0","content":"Ans: B","poster":"Dev1","comment_id":"49906","upvote_count":"1"},{"poster":"Pepper","timestamp":"1632711720.0","content":"Answer is B. aws cloudformation package --- s3 (Zip) --- aws cloudformation deploy","comment_id":"42749","upvote_count":"1"},{"poster":"Amacus","comment_id":"36321","content":"I think is D Use aws serverless create-package to embed the source file directly into the existing CloudFormation template. Use SAM with cloud formation","timestamp":"1632638340.0","upvote_count":"1"},{"upvote_count":"2","content":"B is Correct!","comment_id":"12172","poster":"BillyC","timestamp":"1632628620.0"}],"timestamp":"2019-09-17 07:45:00"},{"id":"0HvhZeWxvdYslaXQBjoI","answer_images":[],"question_images":[],"discussion":[{"timestamp":"1632795000.0","upvote_count":"21","poster":"Polu","comment_id":"163299","content":"A - \"In some cases, you might want to preserve the original input with the error. Use ResultPath in a Catch to include the error with the original input, instead of replacing it.\""},{"content":"A is the answer\n\nThe output of a state can be a copy of its input, the result it produces (for example, output from a Task state’s Lambda function), or a combination of its input and result. Use ResultPath to control which combination of these is passed to the state output.","comment_id":"245482","poster":"RicardoD","timestamp":"1636166760.0","upvote_count":"13"},{"upvote_count":"1","poster":"sumanshu","content":"Selected Answer: A\nwhen an error occurs, you can use the Catch field to handle errors and preserve both the original input and the error details. The ResultPath field in a Catch block allows you to specify where in the state output the error information should be stored, alongside the original input.","comment_id":"1328974","timestamp":"1734612900.0"},{"upvote_count":"1","poster":"RachitNandi1997","timestamp":"1693164480.0","comment_id":"991630","content":"Selected Answer: A\nA is the correct answer."},{"comment_id":"936793","timestamp":"1687964100.0","upvote_count":"2","poster":"rcaliandro","content":"Selected Answer: A\nWe can provide a catch block in your template in order to capture an eventual error during the execution. Once in the catch statement, we can use the result in \"ResultPath\" to include both the original input and the error. So, I vote for A!"},{"comments":[{"comment_id":"921184","content":"So is it Option A?","poster":"shasankperiwal","upvote_count":"1","timestamp":"1686552120.0"}],"content":"Saw this question in the exam today.","timestamp":"1677469860.0","upvote_count":"2","comment_id":"823149","poster":"pancman"},{"poster":"ShriniW","upvote_count":"1","timestamp":"1676056320.0","content":"WHy B is highlighted its not correct . The correct is option A , why null value have to be set .","comment_id":"804664"},{"upvote_count":"2","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/step-functions/latest/dg/input-output-resultpath.html#input-output-resultpath-catch","comment_id":"787449","poster":"michele_scar","timestamp":"1674639000.0"},{"content":"https://docs.aws.amazon.com/step-functions/latest/dg/input-output-resultpath.html","upvote_count":"2","poster":"Dirisme","timestamp":"1673277300.0","comment_id":"770561"},{"upvote_count":"3","poster":"cloud_collector","timestamp":"1665904440.0","comment_id":"696052","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/step-functions/latest/dg/input-output-resultpath.html#input-output-resultpath-catch"},{"poster":"szhang2004","content":"A is correct","timestamp":"1662510300.0","comment_id":"661786","upvote_count":"2"},{"upvote_count":"2","comment_id":"653267","timestamp":"1661745060.0","content":"Selected Answer: A\nA is correct","poster":"Hari008"},{"upvote_count":"2","content":"A is correct","poster":"Chinta","timestamp":"1634357040.0","comment_id":"195198"},{"upvote_count":"3","poster":"saeidp","content":"A is correct","comment_id":"174981","timestamp":"1633073520.0"}],"answer_ET":"A","topic":"1","answer_description":"","question_id":442,"exam_id":25,"url":"https://www.examtopics.com/discussions/amazon/view/28954-exam-aws-certified-developer-associate-topic-1-question-98/","timestamp":"2020-08-18 09:28:00","answer":"A","answers_community":["A (100%)"],"choices":{"C":"Use ErrorEquals in a Retry statement to include the error with the original input.","B":"Use InputPath in a Catch statement and set the value to null.","A":"Use ResultPath in a Catch statement to include the error with the original input.","D":"Use OutputPath in a Retry statement and set the value to $."},"isMC":true,"unix_timestamp":1597735680,"question_text":"A company is developing a report implemented using AWS Step Functions. Amazon CloudWatch shows errors in the Step Functions task state machine. To troubleshoot each task, the state input needs to be included along with the error message in the state output.\nWhich coding practice can preserve both the original input and the error for the state?"},{"id":"ydpeXZgZLkQ1aRRLTvBU","answer_images":[],"unix_timestamp":1568700780,"url":"https://www.examtopics.com/discussions/amazon/view/5287-exam-aws-certified-developer-associate-topic-1-question-99/","exam_id":25,"answer_description":"","choices":{"B":"Use the AWS CLI to get the metrics.","A":"Contact AWS Support for a limit increase.","D":"Retry the call with exponential backoff.","C":"Analyze the applications and remove the API call."},"answers_community":["D (80%)","B (20%)"],"question_images":[],"timestamp":"2019-09-17 08:13:00","isMC":true,"question_text":"A developer is receiving HTTP 400: ThrottlingException errors intermittently when calling the Amazon CloudWatch API. When a call fails, no data is retrieved.\nWhat best practice should first be applied to address this issue?","answer":"D","discussion":[{"poster":"awscertified","upvote_count":"32","content":"I would say try D first and if does not fi the problem completely, request limit increase (A)\nD. Retry the call with exponential backoff","timestamp":"1632469020.0","comment_id":"11652","comments":[{"upvote_count":"22","poster":"jnara","comment_id":"111325","content":"D is the right answer.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling/\nIt's a best practice to use the following methods to reduce your call rate and avoid API throttling:\n\nDistribute your API calls evenly over time rather than making several API calls in a short time span. If you require data to be available with a one-minute resolution, you have an entire minute to emit that metric. Use jitter (randomized delay) to send data points at various times.\nCombine as many metrics as possible into a single API call. For example, a single PutMetricData call can include 20 metrics and 150 data points. You can also use pre-aggregated data sets, such as StatisticSet, to publish aggregated data points, thus reducing the number of PutMetricData calls per second.\nRetry your call with exponential backoff and jitter.","timestamp":"1633396320.0"},{"poster":"Goozian","upvote_count":"4","comment_id":"432960","content":"defiantly it's not D, as 4xx is a client errors. Must only implement the retries on 5xx server errors","timestamp":"1636221180.0"}]},{"poster":"newbie2019","upvote_count":"21","content":"Answer is D. After that, then engaging support.\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling/","timestamp":"1632647220.0","comment_id":"23085"},{"comment_id":"1329037","content":"Selected Answer: D\nThis is a retry mechanism where the client waits for an increasing amount of time between retries after each failure. This approach helps to prevent overwhelming the API further and allows time for the system to recover.","poster":"sumanshu","timestamp":"1734623520.0","upvote_count":"1"},{"poster":"Melisa202401","comment_id":"1174699","content":"https://repost.aws/knowledge-center/cloudwatch-400-error-throttling\nCHOOSE D","timestamp":"1710558240.0","upvote_count":"1"},{"timestamp":"1695909540.0","content":"Selected Answer: D\nhttps://repost.aws/knowledge-center/cloudwatch-400-error-throttling > D","comment_id":"1019937","upvote_count":"1","poster":"NaghamAbdellatif"},{"comment_id":"991948","upvote_count":"1","timestamp":"1693213740.0","content":"Selected Answer: B\nAWS CLI metrics should be used first.","poster":"RachitNandi1997"},{"content":"Selected Answer: B\nAWS CLI implement exponential backoff \nhttps://docs.aws.amazon.com/cli/latest/userguide/cli-configure-retries.html","timestamp":"1692945240.0","comment_id":"989726","poster":"ninomfr64","upvote_count":"1"},{"comment_id":"936796","upvote_count":"1","poster":"rcaliandro","content":"Selected Answer: D\nUsually, when a function or a service return an error, we can implement a retry mechanism with exponential backoff in order to try to call the function several times. So D is the correct answer","timestamp":"1687964400.0"},{"timestamp":"1673393400.0","comment_id":"771892","poster":"sichilam","content":"D is the answer\n\nResolution\nIt's a best practice to use the following methods to reduce your call rate and avoid API throttling:\n\nDistribute your API calls evenly over time rather than making several API calls in a short time span. If you require data to be available with a one-minute resolution, you have an entire minute to emit that metric. Use jitter (randomized delay) to send data points at various times.\nCombine as many metrics as possible into a single API call. For example, a single PutMetricData call can include 20 metrics and 150 data points. You can also use pre-aggregated data sets, such as StatisticSet, to publish aggregated data points, thus reducing the number of PutMetricData calls per second.\nRetry your call with exponential backoff and jitter.","upvote_count":"1"},{"content":"Selected Answer: D\nD is correct based on feedbacks and link in chat.","comment_id":"753435","timestamp":"1671723540.0","poster":"speer","upvote_count":"1"},{"content":"Selected Answer: D\nAns is D. C is avoiding the problem rather than solving it.","upvote_count":"1","comment_id":"729838","poster":"humble_developer","timestamp":"1669686780.0"},{"poster":"mohamedba","timestamp":"1653687420.0","comment_id":"608203","content":"The answer is D.\nKey Word is \"sporadically\", this means the error does not occur very often, exponential backoff is the way to go. If it was a persistent issue, you should go with A","upvote_count":"2"},{"content":"Selected Answer: D\nD\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling/","timestamp":"1638876480.0","comment_id":"495919","upvote_count":"2","poster":"joesome"},{"upvote_count":"1","poster":"leliodesouza","content":"Selected Answer: D\nD is correct.","timestamp":"1637969220.0","comment_id":"487708"},{"comments":[{"upvote_count":"1","comment_id":"539762","timestamp":"1643899320.0","poster":"Vlasto","content":"You have it in your comment and yet you select wrong aswer. The question is about the throttling error which as you mentioned should be handled by exponential backoff. So D is the answer."}],"poster":"jc966","comment_id":"443761","upvote_count":"4","timestamp":"1636246140.0","content":"Answer is B.\nIf you're not using an AWS SDK, you should retry original requests that receive server (5xx) or throttling errors. However, client errors (4xx) indicate that you need to revise the request to correct the problem before trying again. \nhttps://docs.aws.amazon.com/general/latest/gr/api-retries.html"},{"comment_id":"426717","upvote_count":"2","timestamp":"1636134780.0","content":"D is the correct answer","poster":"santhoshmj"},{"content":"D is WRONG!!!! the developer is getting a 400 error which is from the client side not server side !!! Exponential backoff is NOT an option !! B is the correct answer.","upvote_count":"3","timestamp":"1635868500.0","comment_id":"388784","comments":[{"upvote_count":"3","timestamp":"1636038180.0","poster":"EV123","content":"The error is 400: ThrottlingException, which means it exceeds the limit, even if you use CLI, you will get the same error. So D is correct","comment_id":"399925"}],"poster":"ceeee"},{"poster":"DOUG65535","upvote_count":"3","content":"should be B. theres not only one solution to cause 400, the first thing is to address the situation by CLI","comments":[{"comment_id":"399514","content":"Can you explain why using CLI would help in this situation? CLI also makes the same API calls which comes back as 400. You dont' want to overwhelm the server by having everyone calling it again and again. So expoential backoff should help avoid that and at the same time we try to resolve the 400 error.","timestamp":"1635902880.0","upvote_count":"1","poster":"Mamba4Ever"},{"poster":"EV123","timestamp":"1636024680.0","comment_id":"399919","content":"The error is 400: ThrottlingException, which means it exceeds the limit, even if you use CLI, you will get the same error. So D is correct","upvote_count":"1"}],"timestamp":"1635716100.0","comment_id":"370502"},{"timestamp":"1635508560.0","comment_id":"354777","poster":"mvsnogueira","upvote_count":"1","content":"D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling/"},{"poster":"VAG1595","content":"Answer: D","comment_id":"341076","timestamp":"1635336180.0","upvote_count":"1"},{"content":"Option D: \nurl: https://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling/","poster":"ashfaq5603","comment_id":"333964","upvote_count":"1","timestamp":"1635161760.0"},{"content":"its B, not D. D is wrong because via the SDK expontentialbackoff is automatically on","poster":"knownothing","timestamp":"1635116580.0","upvote_count":"2","comment_id":"319623"},{"upvote_count":"1","comment_id":"311123","poster":"wils3","content":"Ans : D","timestamp":"1634912400.0"},{"upvote_count":"1","content":"Why incorrect answer is always given as a default, D is definitely the right answer.","comment_id":"268792","timestamp":"1634537040.0","poster":"Mamba4Ever"},{"upvote_count":"4","content":"D is Correct.\nIt's a best practice to use the following methods to reduce your call rate and avoid API throttling:\n\n1. Distribute your API calls evenly over time rather than making several API calls in a short time span. If you require data to be available with a one-minute resolution, you have an entire minute to emit that metric. Use jitter (randomized delay) to send data points at various times.\n2. Combine as many metrics as possible into a single API call. For example, a single PutMetricData call can include 20 metrics and 150 data points. You can also use pre-aggregated data sets, such as StatisticSet, to publish aggregated data points, thus reducing the number of PutMetricData calls per second.\n3. Retry your call with exponential backoff and jitter.","comment_id":"240753","poster":"Dacudo","timestamp":"1634303160.0"},{"poster":"Vishaka1995","content":"Right answer: D","upvote_count":"1","timestamp":"1634237640.0","comment_id":"197402"},{"timestamp":"1634196840.0","upvote_count":"1","content":"D is correct","comment_id":"191204","poster":"codeScalable"},{"content":"D is the right answer.","upvote_count":"1","timestamp":"1634166240.0","poster":"maryamf","comment_id":"181538"},{"comment_id":"171583","poster":"saeidp","upvote_count":"1","timestamp":"1634061180.0","content":"D is correct"},{"content":"D Exponential Back-offs way to go","poster":"Nalex9ja","comment_id":"164564","upvote_count":"1","timestamp":"1633986600.0"},{"content":"\"D\" is correct","timestamp":"1633970460.0","upvote_count":"1","poster":"WilsonNF","comment_id":"153231"},{"content":"Ans D. : After trying exponential backoff you can engage support. \nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling","comment_id":"142338","upvote_count":"1","poster":"MFDOOM","timestamp":"1633942860.0"},{"timestamp":"1633942020.0","upvote_count":"1","comment_id":"139444","poster":"wackyGuru","content":"D. Retry the call with exponential backoff"},{"upvote_count":"4","comment_id":"125148","timestamp":"1633884540.0","content":"D\n\nCloudWatch requests are throttled for each AWS account on a per-Region basis to help service performance and \"ALL\" calls do add data metrics count towards max allowed request rate. When the rate is reached we may see the following throttling exception\n\n\n<ErrorResponse xmlns=\"http://monitoring.amazonaws.com/doc/2010-08-01/\">\n <Error>\n <Type>Sender</Type>\n <Code>Throttling</Code>\n <Message>Rate exceeded</Message>\n </Error>\n <RequestId>2f85f68d-980b-11e7-a296-21716fd2d2e3</RequestId>\n</ErrorResponse>\n\n\nHere is the order in which this issue can be addressed\n1. Distribute calls evenly over time\n2. Combine as many metrics as possible into a single PutMetricData API\n3. Retry with exponential backoff\n4. Contact AWS to increase rate limit","poster":"onlinebaba"},{"comments":[{"timestamp":"1633829760.0","comments":[{"comment_id":"989729","poster":"ninomfr64","content":"Becasue AWS CLI is based on AWS SDK that implements retry/exponential backoof for you https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-retries.html","upvote_count":"1","timestamp":"1692945300.0"}],"poster":"AWSforWork","comment_id":"121978","upvote_count":"1","content":"How B. Use the AWS CLI to get the metrics can help \"throttling\"? are you saying for troubleshooting?"}],"comment_id":"119663","content":"The Answer should be 'B'. As the error occurs intermittently with no data.","upvote_count":"1","poster":"Anushree_","timestamp":"1633749600.0"},{"timestamp":"1633545540.0","content":"Ans : D","upvote_count":"1","poster":"MannyC","comment_id":"118786"},{"comment_id":"112978","upvote_count":"1","content":"Yes I also think answer should be 'D'","poster":"Donell","timestamp":"1633495920.0"},{"poster":"newme","timestamp":"1633272000.0","upvote_count":"1","content":"If the question is to ask how to locate the problem, for example debugging, I think B is correct.","comment_id":"96569"},{"timestamp":"1633190700.0","poster":"mirik","comment_id":"73344","upvote_count":"3","content":"The problem in this question is the \"When a call fails, no data is retrieved\", not the failing call itself, so the answer B is correct."},{"poster":"kinetic1g","comment_id":"67475","content":"D. Retry the call with exponential backoff","timestamp":"1633146360.0","upvote_count":"1"},{"upvote_count":"1","content":"D)\nagree with @arnero it is intermittent so the app is most likely not the issue, so try again or code programmatic method to try again with backoff","comment_id":"59659","poster":"simplimarvelous","timestamp":"1633051080.0"},{"content":"It is said that the problem happens \"intermittently\", not always. So, I guess D may be helpful to try first. If D won't help, then A.","upvote_count":"2","timestamp":"1632881580.0","poster":"hhuo","comment_id":"42005"},{"upvote_count":"1","comments":[{"content":"this may be correct, but does not sound like a \"best practice\"","poster":"arnero","timestamp":"1632836460.0","upvote_count":"3","comment_id":"40125"}],"poster":"dumma","comment_id":"33255","timestamp":"1632680760.0","content":"Correct answer is A as CloudWatch allows you to GetMetricData at 50 transactions per second (TPS). The maximum number of operation requests you can make per second without being throttled. If you need more you need to increase the limit. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_limits.html"},{"upvote_count":"3","comment_id":"11375","timestamp":"1632265080.0","content":"probably is 'D'.","poster":"Kane"}],"topic":"1","question_id":443,"answer_ET":"D"}],"exam":{"numberOfQuestions":443,"id":25,"isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":true,"name":"AWS Certified Developer Associate","provider":"Amazon","isBeta":false},"currentPage":89},"__N_SSP":true}