{"pageProps":{"questions":[{"id":"FpHrtwIJ2sBIBZUA5hLr","exam_id":25,"answer_ET":"A","question_images":[],"question_id":296,"discussion":[{"upvote_count":"5","timestamp":"1671868920.0","poster":"almadeedo","comment_id":"754765","content":"Selected Answer: A\nChoosing A.\nAs stated in https://docs.aws.amazon.com/it_it/codeguru/latest/profiler-api/API_AgentConfiguration.html:\nSamplingIntervalInMilliseconds is The sampling interval in milliseconds that is used to profile samples ... and so:\n- Reducing (lower value) the sampling interval expressed in millisecond will increase the number of sampling, hence reduce the number of miss"},{"content":"A\n\nTo reduce the number of missed events in the profile, the developer should set a lower value for the SamplingIntervalInMilliseconds property. This property determines the frequency at which the profiler agent samples data from the application. By default, the SamplingIntervalInMilliseconds property is set to 10 milliseconds. However, if the application is generating a significant number of events that are being missed by the profiler, the developer can reduce the SamplingIntervalInMilliseconds property to a lower value, such as 1 millisecond, to increase the frequency of data sampling and capture more events in the profile.","upvote_count":"3","timestamp":"1677013800.0","poster":"Ankit1010","comment_id":"817171"},{"comment_id":"744921","upvote_count":"1","poster":"mrbig00","timestamp":"1671009420.0","comments":[{"poster":"LittleSoap","upvote_count":"1","content":"Option A is the correct answer because by reducing the interval at which you sample, you have less chances of missing events","comment_id":"864686","timestamp":"1680958080.0"}],"content":"Selected Answer: C\nThe correct answer is C. To reduce the number of missed events in the profile, the developer should set a higher value for the SamplingIntervalInMilliseconds property. This property controls the sampling rate of the agent, and setting a higher value will result in the agent collecting more data.\n\nOption A is incorrect because setting a lower value for the SamplingIntervalInMilliseconds property would result in the agent collecting less data, leading to more missed events in the profile.\n\nOption B is incorrect because the ReportingIntervalInMilliseconds property does not affect the number of missed events in the profile. This property controls how often the agent sends data to CodeGuru Profiler.\n\nOption D is incorrect because setting a higher value for the ReportingIntervalInMilliseconds property would not affect the number of missed events in the profile. This property only controls how often the agent sends data to CodeGuru Profiler."},{"comment_id":"728656","timestamp":"1669588560.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/it_it/codeguru/latest/profiler-api/API_AgentConfiguration.html","upvote_count":"1","poster":"DrCloud"}],"topic":"1","choices":{"D":"Set a higher value for the ReportingIntervalInMilliseconds property.","B":"Set a lower value for the ReportingIntervalInMilliseconds property.","C":"Set a higher value for the SamplingIntervalInMilliseconds property.","A":"Set a lower value for the SamplingIntervalInMilliseconds property."},"answer":"A","isMC":true,"timestamp":"2022-11-27 23:36:00","answer_description":"","unix_timestamp":1669588560,"url":"https://www.examtopics.com/discussions/amazon/view/89005-exam-aws-certified-developer-associate-topic-1-question-365/","answer_images":[],"question_text":"A developer is using Amazon CodeGuru Profiler. The developer has configured the application with the CodeGuru Profiler agent. However, when the application runs, the developer notices that a significant number of events are missing from the generated profile.\n\nHow can the developer reduce the number of missed events in the profile?","answers_community":["A (86%)","14%"]},{"id":"J0LFrUdlpNk3tTSDUUSY","exam_id":25,"url":"https://www.examtopics.com/discussions/amazon/view/88892-exam-aws-certified-developer-associate-topic-1-question-366/","unix_timestamp":1669484580,"answer_images":[],"timestamp":"2022-11-26 18:43:00","answer_description":"","answer":"A","answers_community":["A (60%)","D (40%)"],"question_text":"A development team set up a pipeline to launch a test environment. The developers want to automate tests for their application. The team created an AWS CodePipeline stage to deploy the application to a test environment in batches using AWS Elastic Beanstalk. A later CodePipeline stage contains a single action that uses AWS CodeBuild to run numerous automated Selenium-based tests on the deployed application. The team must speed up the pipeline without removing any of the individual tests.\n\nWhich set of actions will MOST effectively speed up application deployment and testing?","topic":"1","answer_ET":"A","question_images":[],"isMC":true,"discussion":[{"comment_id":"744610","content":"Selected Answer: A\nThe correct answer is A. \nFor test enviroment all-at-once is a good fit, see the aws documentation:\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.deploy-existing-version.html\n\nAll at once – The quickest deployment method. Suitable if you can accept a short loss of service, and if quick deployments are important to you. With this method, Elastic Beanstalk deploys the new application version to each instance. Then, the web proxy or application server might need to restart. As a result, your application might be unavailable to users (or have low availability) for a short time.","upvote_count":"3","timestamp":"1670980980.0","poster":"fabriciollf"},{"comment_id":"734372","upvote_count":"2","poster":"ubuntu1234","content":"A\nWhy use All At Once? I recommend considering it only for development and test environments. Downtimes due to failed deployments may affect your business badly in production.\nhttps://blog.shikisoft.com/which_elastic_beanstalk_deployment_should_you_use/","timestamp":"1670065800.0"},{"upvote_count":"3","content":"Selected Answer: A\nVote for A because of launching a test environment, should use all at once","timestamp":"1670008320.0","poster":"fswklotto1","comment_id":"734013"},{"content":"Selected Answer: D\nDDDDDD","poster":"michaldavid","comment_id":"729513","timestamp":"1669659720.0","upvote_count":"2"},{"upvote_count":"2","timestamp":"1669543740.0","content":"Selected Answer: D\nGoing with D","poster":"k1kavi1","comment_id":"728122"},{"poster":"alfredk92","timestamp":"1669484580.0","comment_id":"727723","content":"Should be D","upvote_count":"2"}],"choices":{"B":"Set up a rolling update in Elastic Beanstalk. Run tests in serial with a single CodeBuild action.","D":"Set up a traffic-splitting deployment in Elastic Beanstalk. Run tests in parallel with multiple CodeBuild actions.","A":"Set up an all-at-once deployment in Elastic Beanstalk. Run tests in parallel with multiple CodeBuild actions.","C":"Set up an immutable update in Elastic Beanstalk. Run tests in serial with a single CodeBuild action."},"question_id":297},{"id":"D4Lxf4mg1d0tQK5hYCeC","question_images":[],"exam_id":25,"question_text":"A developer migrated a legacy application to an AWS Lambda function. The function uses a third-party service to pull data with a series of API calls at the end of each month. The function then processes the data to generate the monthly reports. The function has been working with no issues so far.\n\nThe third-party service recently issued a restriction to allow a fixed number of API calls each minute and each day. If the API calls exceed the limit for each minute or each day, then the service will produce errors. The API also provides the minute limit and daily limit in the response header. This restriction might extend the overall process to multiple days because the process is consuming more API calls than the available limit.\n\nWhat is the MOST operationally efficient way to refactor the serverless application to accommodate this change?","answer_description":"","isMC":true,"answer":"B","topic":"1","question_id":298,"discussion":[{"poster":"JulietHsu","comment_id":"782544","comments":[{"timestamp":"1675999080.0","upvote_count":"2","comment_id":"803928","poster":"pancman","content":"The maximum delay allowed in an SQS queue is 15 minutes. The question states that the job will take multiple days. So that wouldn't work."}],"timestamp":"1674234180.0","upvote_count":"6","content":"Selected Answer: B\nI don't see how Step Functions will help this case. I would go with SQS and lambda"},{"timestamp":"1675999440.0","comments":[{"upvote_count":"2","poster":"joanneli77","content":"SQS Queue can just keep re-trying. Items can stay in a SQS Queue for 14 days. Delay timers are not relevant... Your lambda just fires off and tries again until the entire workload is complete. Answer is B. Queue until finished.","timestamp":"1676846040.0","comment_id":"814628"}],"comment_id":"803930","upvote_count":"5","poster":"pancman","content":"Selected Answer: A\nA makes the most sense in this question: Use an AWS Step Functions state machine to monitor API failures. Use the Wait state to delay calling the Lambda function.\n\nSQS queue wouldn't work because the maximum delay allowed in an SQS queue is 15 minutes.\nKinesis is more suitable for data streams, which is not the case here.\nC (CloudWatch) would work but it is not as efficient as A."},{"comments":[{"timestamp":"1710934800.0","poster":"a15ce96","upvote_count":"1","comment_id":"1178205","content":"Moreover, SQS is a cliche, the most common solution in such tests."}],"timestamp":"1710934680.0","comment_id":"1178203","content":"Selected Answer: B\nA says: \" Use the Wait state to delay calling the Lambda function\". I don't like the fact we need to wait with no specific time boundaries. Option B with the statement of \"to poll the queue within the API threshold limits\" looks better.","upvote_count":"1","poster":"a15ce96"},{"upvote_count":"1","comment_id":"1092095","content":"why not C seems operationally efficient over setting up Step function and SQS","timestamp":"1702159080.0","poster":"LR2023"},{"comment_id":"904923","comments":[{"comment_id":"904924","upvote_count":"1","timestamp":"1684846860.0","content":"4. After processing each API call, delete the message from the Amazon SQS queue to indicate that it has been processed successfully.\n\nBy implementing this solution, the Lambda function will only make API calls within the allowed limits, preventing errors and ensuring smooth operation. The use of Amazon SQS provides a scalable and reliable queueing system, allowing you to handle varying API call rates and accommodate the restrictions imposed by the third-party service.\n\nTherefore, the most operationally efficient approach is to refactor the application using an Amazon SQS queue to control the rate of API calls made by the Lambda function.","poster":"pranay_2406"}],"upvote_count":"2","timestamp":"1684846860.0","poster":"pranay_2406","content":"Selected Answer: B\nIt's B\nBy using an Amazon SQS queue, you can decouple the API calls from the Lambda function's execution and ensure that you stay within the API limits. Here's how the solution would work:\n\n1. Set up an Amazon SQS queue to hold the API calls. This queue will act as a buffer, allowing you to control the rate at which the API calls are made.\n\n2. Configure the Lambda function to periodically poll the Amazon SQS queue for messages. You can use the AWS SDK or AWS Lambda triggers to trigger the function when there are messages in the queue.\n\n3. Within the Lambda function, retrieve the API calls from the queue and make the necessary API requests to the third-party service. Ensure that the Lambda function respects the API threshold limits for each minute and each day."},{"content":"Selected Answer: B\nuse plze SQS","upvote_count":"1","comment_id":"854030","timestamp":"1680067440.0","poster":"sdafadsfa"},{"content":"B\n\nUsing an Amazon SQS queue to hold the API calls is the most operationally efficient way to refactor the serverless application to accommodate this change.\n\nThe Lambda function can poll the queue for messages within the API threshold limits. This allows the function to process the data and generate reports without exceeding the API limits. If the number of messages in the queue is higher than the limit, then the function can be configured to stop processing new messages until the number of messages in the queue decreases.","comments":[{"content":"Option A is not the most efficient way because AWS Step Functions incur additional costs and add complexity to the overall architecture. The Wait state might cause the function to execute beyond the necessary time window, leading to higher costs.\n\nOption C is not a suitable solution because it involves stopping the function during execution, which is not an efficient way to handle the situation.\n\nOption D is not a suitable solution because it adds an extra layer of complexity by introducing Amazon Kinesis Data Firehose. This option may also require additional resources, which might increase the cost.","upvote_count":"1","timestamp":"1677013500.0","poster":"Ankit1010","comment_id":"817167"}],"poster":"Ankit1010","comment_id":"817165","timestamp":"1677013500.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\nWill go with step function. It will cover the scenario where the minute and day limit change during the execution of the job.","poster":"Smartiup","comment_id":"810995","timestamp":"1676571360.0"},{"poster":"Phinx","comment_id":"786210","timestamp":"1674541920.0","content":"Selected Answer: C\nI'll go with C. SQS is not efficient in this scenario.","upvote_count":"2"}],"url":"https://www.examtopics.com/discussions/amazon/view/96195-exam-aws-certified-developer-associate-topic-1-question-367/","timestamp":"2023-01-20 18:03:00","answer_ET":"B","answer_images":[],"answers_community":["B (58%)","A (32%)","11%"],"choices":{"D":"Use Amazon Kinesis Data Firehose to batch the API calls and deliver them to an Amazon S3 bucket with an event notification to invoke the Lambda function.","A":"Use an AWS Step Functions state machine to monitor API failures. Use the Wait state to delay calling the Lambda function.","C":"Use an Amazon CloudWatch Logs metric to count the number of API calls. Configure an Amazon CloudWatch alarm that stops the currently running instance of the Lambda function when the metric exceeds the API threshold limits.","B":"Use an Amazon Simple Queue Service (Amazon SQS) queue to hold the API calls. Configure the Lambda function to poll the queue within the API threshold limits."},"unix_timestamp":1674234180},{"id":"SrRCBj56UxKOYYTM9x1M","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/96159-exam-aws-certified-developer-associate-topic-1-question-368/","unix_timestamp":1674225000,"question_id":299,"question_images":[],"answer_ET":"D","answer_images":[],"timestamp":"2023-01-20 15:30:00","exam_id":25,"isMC":true,"answers_community":["D (86%)","14%"],"choices":{"B":"Create an AWS Key Management Service (AWS KMS) AWS managed key. Provide the key’s Amazon Resource Name (ARN) in the KMSMasterKeyId parameter during creation of the DynamoDB table.","C":"Create an AWS owned key. Provide the key’s Amazon Resource Name (ARN) in the KMSMasterKeyId parameter during creation of the DynamoDB table.","A":"Create an AWS Key Management Service (AWS KMS) customer managed key. Provide the key’s Amazon Resource Name (ARN) in the KMSMasterKeyId parameter during creation of the DynamoDB table.","D":"Create the DynamoDB table with the default encryption options."},"answer":"D","discussion":[{"content":"Selected Answer: D\nIf the question asked for \"the access to DynamoDB should be monitored via CloudTrail\" or \"need a centralized place to store the key\", we'd need to go with KMS. Since there are no such details, D option is acceptable.","timestamp":"1710934920.0","poster":"a15ce96","comment_id":"1178211","upvote_count":"1","comments":[{"content":"I'm sorry, not \"\"the access to DynamoDB\", but \"\"the access to key\". Meaning we can audit actions made on KMS","poster":"a15ce96","upvote_count":"1","timestamp":"1710934980.0","comment_id":"1178212"}]},{"upvote_count":"4","content":"D\n\nThe correct answer is D.\n\nWhen creating an Amazon DynamoDB table using the AWS CLI, server-side encryption with an AWS owned encryption key is enabled by default. Therefore, the developer does not need to create an AWS KMS key or specify the KMSMasterKeyId parameter. Option A and B are incorrect because they suggest creating customer-managed and AWS-managed KMS keys, which are not needed in this scenario. Option C is also incorrect because AWS owned keys are automatically used for server-side encryption by default.","comments":[{"upvote_count":"1","content":"Thank you for your thorough explanation. You are actually the only one who correctly explained why D is the correct answer. Creating DynamoDB with CLI gives you access to AWS owned key by default. This is explained in the link here - https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/encryption.tutorial.html","timestamp":"1686965940.0","poster":"AgboolaKun","comment_id":"925689"}],"timestamp":"1677013200.0","comment_id":"817158","poster":"Ankit1010"},{"upvote_count":"1","comments":[{"poster":"Drey","upvote_count":"1","timestamp":"1675781160.0","comment_id":"801013","content":"changed my mind, it's D."}],"comment_id":"801012","content":"Selected Answer: B\nIt's B.","poster":"Drey","timestamp":"1675781040.0"},{"poster":"JulietHsu","content":"Selected Answer: D\nDynamoDB default encryption","timestamp":"1674234120.0","comment_id":"782542","upvote_count":"4"},{"upvote_count":"1","poster":"KT_Yu","timestamp":"1674225000.0","comment_id":"782352","content":"Selected Answer: D\nAnswer should be D"}],"question_text":"A developer is creating an Amazon DynamoDB table by using the AWS CLI. The DynamoDB table must use server-side encryption with an AWS owned encryption key.\n\nHow should the developer create the DynamoDB table to meet these requirements?","topic":"1"},{"id":"yBQmDkqkwh6mvTnUsoTd","topic":"1","choices":{"B":"Scale the ECS cluster to contain more ECS instances.","A":"Use Amazon ElastiCache to cache query results.","C":"Add read capacity units (RCUs) to the DB instance.","D":"Modify the ECS task definition to increase the task memory."},"answer_ET":"A","answers_community":["A (89%)","11%"],"question_id":300,"unix_timestamp":1674225180,"question_images":[],"question_text":"A company has a three-tier application that is deployed in Amazon Elastic Container Service (Amazon ECS). The application is using an Amazon RDS for MySQL DB instance. The application performs more database reads than writes.\n\nDuring times of peak usage, the application’s performance degrades. When this performance degradation occurs, the DB instance’s ReadLatency metric in Amazon CloudWatch increases suddenly.\n\nHow should a developer modify the application to improve performance?","exam_id":25,"discussion":[{"content":"Selected Answer: A\nElasticCache for read writes, adding additional read units is not possible with RDS","poster":"breathingcloud","comments":[{"content":"\" adding additional read units is not possible with RDS\", thanks for that","upvote_count":"2","poster":"tony554556","timestamp":"1675646940.0","comment_id":"799313"}],"comment_id":"787293","timestamp":"1674624180.0","upvote_count":"5"},{"poster":"Drey","content":"Selected Answer: A\nVoting for A.","timestamp":"1675782300.0","comment_id":"801031","upvote_count":"1"},{"comment_id":"783919","upvote_count":"1","timestamp":"1674363540.0","content":"A. More reads then Write","poster":"JagpreetLM10"},{"poster":"Phinx","timestamp":"1674355200.0","comment_id":"783893","upvote_count":"1","content":"Selected Answer: A\nBy implementing Caching, it will greatly help in reading performance."},{"timestamp":"1674234660.0","poster":"JulietHsu","upvote_count":"1","comment_id":"782554","content":"Selected Answer: A\nI would go with A - to cache the query results.\nKeyword: \"The application performs more database reads than writes.\" \nRead capacity units is for DynamoDB."},{"poster":"KT_Yu","content":"Selected Answer: C\nAnswer should be C","upvote_count":"1","comments":[{"timestamp":"1674355140.0","comment_id":"783892","poster":"Phinx","content":"RCU is for DynamoDB. RDS is using instance type.","upvote_count":"3"},{"content":"How should a developer >>>modify the application<<<","poster":"captainpike","upvote_count":"1","timestamp":"1680111900.0","comment_id":"854772"}],"timestamp":"1674225180.0","comment_id":"782354"}],"url":"https://www.examtopics.com/discussions/amazon/view/96160-exam-aws-certified-developer-associate-topic-1-question-369/","timestamp":"2023-01-20 15:33:00","answer_description":"","isMC":true,"answer_images":[],"answer":"A"}],"exam":{"name":"AWS Certified Developer Associate","isMCOnly":true,"isImplemented":true,"isBeta":false,"id":25,"numberOfQuestions":443,"provider":"Amazon","lastUpdated":"11 Apr 2025"},"currentPage":60},"__N_SSP":true}