{"pageProps":{"questions":[{"id":"u7g5j7t5PFvjLca0ZHeM","answer_ET":"D","topic":"1","unix_timestamp":1661972580,"url":"https://www.examtopics.com/discussions/amazon/view/78759-exam-aws-certified-solutions-architect-professional-topic-1/","exam_id":32,"answers_community":["D (76%)","C (24%)"],"answer":"D","question_text":"A company's compliance audit reveals that some Amazon Elastic Block Store (Amazon EBS) volumes that were created in an AWS account were not encrypted.\nA solutions architect must implement a solution to encrypt all new EBS volumes at rest.\nWhich solution will meet this requirement with the LEAST effort?","question_id":886,"answer_images":[],"question_images":[],"answer_description":"","timestamp":"2022-08-31 21:03:00","isMC":true,"discussion":[{"content":"Selected Answer: D\nThe question asks how to encrypt \"new\" volumes. I guess we are not worrying about the older stuff for now.","upvote_count":"1","poster":"devilman222","comment_id":"1269417","timestamp":"1724153940.0"},{"comment_id":"765047","upvote_count":"2","content":"Selected Answer: D\nD is correct.","timestamp":"1672779600.0","poster":"evargasbrz"},{"content":"Selected Answer: D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/ebs-automatic-encryption/","upvote_count":"3","poster":"AwsBRFan","timestamp":"1666027080.0","comment_id":"697588"},{"content":"Selected Answer: D\nAgree with D for all New volumes","timestamp":"1665079620.0","poster":"dcdcdc3","comment_id":"688021","upvote_count":"2"},{"upvote_count":"2","poster":"sb333","content":"Selected Answer: D\nD is correct. The question is looking for the LEAST effort for encrypting \"new\" volumes. This is accomplished by turning on encryption by default, which will only allow encryption to be used unless it is turned off again. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default\n\nIf you want to correct current volumes, which the questions is not asking you to do, then you could follow-up with answer C as a solution (which requires a bit of configuration). Remember to only answer what the question is asking for and not try to solve things that it doesn't ask for.","timestamp":"1664748840.0","comment_id":"685094"},{"timestamp":"1664726760.0","upvote_count":"1","poster":"JohnPi","content":"Selected Answer: D\nNew Amazon EBS volumes aren't encrypted by default. However, there is a setting in the EC2 console that turns on encryption by default for all new Amazon EBS volumes and snapshot copies created within a specified Region.","comment_id":"684929"},{"comment_id":"674374","poster":"Malluchan","timestamp":"1663694400.0","content":"D is correct , Since the ask is to encrypt all new EBS volumes. Existing unencrypted Volumes will be handled separately..","upvote_count":"1"},{"timestamp":"1663177560.0","upvote_count":"2","content":"Selected Answer: D\nD as per link","poster":"Ni_yot","comment_id":"669230"},{"comment_id":"666352","content":"I will go with D as per the link already added","timestamp":"1662919380.0","poster":"Ni_yot","upvote_count":"1"},{"content":"Selected Answer: C\nI think its C","comment_id":"659818","poster":"cale","comments":[{"poster":"[Removed]","content":"Can encrypt un-encrypted EBS volumes.","timestamp":"1665349560.0","comment_id":"690545","upvote_count":"1"}],"timestamp":"1662360540.0","upvote_count":"2"},{"timestamp":"1662216060.0","content":"D is right. https://aws.amazon.com/premiumsupport/knowledge-center/ebs-automatic-encryption/","upvote_count":"4","poster":"FF","comment_id":"658583"},{"comment_id":"655393","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"716656","timestamp":"1668250920.0","poster":"Steven111","content":"encrypt all new EBS volumes, NEW!"}],"timestamp":"1661972580.0","content":"Selected Answer: C\nIt's C. Enabling encryption doesn't guarantee that ESB will be encrypted. You have to create a snapshot, create a new volume encrypted...","poster":"gnic"}],"choices":{"C":"Create an AWS Config rule to detect the creation of a new EBS volume. Encrypt the volume by using AWS Systems Manager Automation.","D":"Turn on EBS encryption by default in all AWS Regions.","A":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule to detect the creation of unencrypted EBS volumes. Invoke an AWS Lambda function to delete noncompliant volumes.","B":"Use AWS Audit Manager with data encryption."}},{"id":"azA6pRztLmmRZZfIYsSC","unix_timestamp":1581791220,"timestamp":"2020-02-15 19:27:00","answers_community":["B (100%)"],"question_text":"Your company plans to host a large donation website on Amazon Web Services (AWS). You anticipate a large and undetermined amount of traffic that will create many database writes. To be certain that you do not drop any writes to a database hosted on AWS.\nWhich service should you use?","answer_images":[],"topic":"1","exam_id":32,"discussion":[{"comment_id":"1266978","upvote_count":"1","poster":"amministrazione","timestamp":"1723804920.0","content":"B. Amazon Simple Queue Service (SQS) for capturing the writes and draining the queue to write to the database."},{"content":"Selected Answer: B\nB. Amazon Simple Queue Service (SQS) for capturing the writes and draining the queue to write to the database.\nThis a classic usage for write in database without provisioned more resource and more spend money","poster":"SkyZeroZx","comment_id":"927928","timestamp":"1687207920.0","upvote_count":"1"},{"content":"B. Amazon Simple Queue Service (SQS) for capturing the writes and draining the queue to write to the database.","timestamp":"1638880440.0","comment_id":"495979","upvote_count":"1","poster":"cldy"},{"poster":"01037","upvote_count":"2","timestamp":"1636221840.0","comment_id":"367748","content":"No doubt, B"},{"content":"B.\nalways use SQS to consume undetermined write traffic.","upvote_count":"1","timestamp":"1635763440.0","poster":"cldy","comment_id":"329236"},{"timestamp":"1633532940.0","upvote_count":"2","content":"Answer is B","comment_id":"54398","poster":"miracle"},{"content":"B is correct!","poster":"Gorha","upvote_count":"4","comment_id":"50982","timestamp":"1633317180.0"}],"question_id":887,"question_images":[],"answer":"B","answer_description":"Amazon Simple Queue Service (Amazon SQS) offers a reliable, highly scalable hosted queue for storing messages as they travel between computers. By using\nAmazon SQS, developers can simply move data between distributed application components performing different tasks, without losing messages or requiring each component to be always available. Amazon SQS makes it easy to build a distributed, decoupled application, working in close conjunction with the Amazon\nElastic Compute Cloud (Amazon EC2) and the other AWS infrastructure web services.\nWhat can I do with Amazon SQS?\nAmazon SQS is a web service that gives you access to a message queue that can be used to store messages while waiting for a computer to process them. This allows you to quickly build message queuing applications that can be run on any computer on the internet. Since Amazon SQS is highly scalable and you only pay for what you use, you can start small and grow your application as you wish, with no compromise on performance or reliability. This lets you focus on building sophisticated message-based applications, without worrying about how the messages are stored and managed. You can use Amazon SQS with software applications in various ways. For example, you can:\nIntegrate Amazon SQS with other AWS infrastructure web services to make applications more reliable and flexible.\nUse Amazon SQS to create a queue of work where each message is a task that needs to be completed by a process. One or many computers can read tasks from the queue and perform them.\nBuild a microservices architecture, using queues to connect your microservices.\nKeep notifications of significant events in a business process in an Amazon SQS queue. Each event can have a corresponding message in a queue, and applications that need to be aware of the event can read and process the messages.","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/14218-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"B","choices":{"A":"Amazon RDS with provisioned IOPS up to the anticipated peak write throughput.","C":"Amazon ElastiCache to store the writes until the writes are committed to the database.","D":"Amazon DynamoDB with provisioned write throughput up to the anticipated peak write throughput.","B":"Amazon Simple Queue Service (SQS) for capturing the writes and draining the queue to write to the database."}},{"id":"lyX22zCKZUV2wGdf73RX","unix_timestamp":1662947100,"timestamp":"2022-09-12 03:45:00","answers_community":["D (57%)","A (43%)"],"answer_images":[],"question_text":"A company is planning to migrate an application from on premises to the AWS Cloud. The company will begin the migration by moving the application's underlying data storage to AWS. The application data is stored on a shared file system on premises, and the application servers connect to the shared file system through\nSMB.\nA solutions architect must implement a solution that uses an Amazon S3 bucket for shared storage. Until the application is fully migrated and code is rewritten to use native Amazon S3 APIs, the application must continue to have access to the data through SMB. The solutions architect must migrate the application data to\nAWS to its new location while still allowing the on-premises application to access the data.\nWhich solution will meet these requirements?","topic":"1","exam_id":32,"discussion":[{"comment_id":"685089","timestamp":"1664747700.0","upvote_count":"6","content":"Selected Answer: A\nThe answer is A. You cannot migrate data to S3 at this time per the question. You must copy the data to AWS to a solution that allows SMB. Later, once they modify the application to use S3, will they then migrate the data to S3. AWS DataSync was built for a solution like this. It can migrate from an on-premises SMB server to FSx for Windows File Server. DataSync will replicate on a schedule and keep the target in sync with the Source based on that replication schedule.\nhttps://docs.aws.amazon.com/datasync/latest/userguide/how-datasync-works.html","poster":"sb333"},{"upvote_count":"1","poster":"WhyIronMan","comment_id":"1249189","timestamp":"1721158920.0","content":"Selected Answer: D\nD)\nmust MIGRATE the application data to AWS to its new location WHILE still allowing the on-premises application to access the data"},{"upvote_count":"1","comment_id":"1111246","content":"Selected Answer: D\nThe scenario didn't indicate the need of windows integration!","timestamp":"1704118380.0","poster":"aewis"},{"comment_id":"1008851","upvote_count":"2","timestamp":"1694839440.0","content":"Selected Answer: D\nThey want to use S3 now but through SMB. Later they will switch to pure S3.\nCan't be A add it does not support S3...","poster":"rodrod"},{"timestamp":"1691270640.0","upvote_count":"2","comment_id":"973385","comments":[{"comment_id":"997407","timestamp":"1693725300.0","upvote_count":"1","content":"The solutions architect must migrate the application data to\nAWS to its new location while still allowing the on-premises application to access the data. => D match","poster":"vn_thanhtung"}],"poster":"rsn","content":"Selected Answer: A\nAssuming that underlying data on prem will continue to be updated during the migration proccess, \"A\" works better than \"D\". Option \"D\" does not talk about keeping the data in synch"},{"poster":"Jesuisleon","content":"Selected Answer: D\nThe question emphasize \" the application must continue to have access to the data through SMB\", A failed to fulfill this .","upvote_count":"1","comment_id":"907382","timestamp":"1685106960.0"},{"content":"Selected Answer: A\nD would work if it weren't windows. It will not really work well.\nA on the other hand works. Yes we have costs for FX and we need the datasync but it works even with windows.","comment_id":"858416","timestamp":"1680398280.0","poster":"hobokabobo","upvote_count":"2"},{"timestamp":"1674821460.0","comment_id":"789566","content":"One solution that can meet these requirements is to use Amazon S3 with the AWS Storage Gateway service.\n\nAWS Storage Gateway is a hybrid storage service that allows you to store data both on-premises and in the AWS cloud. It provides file-based storage, using the SMB protocol, which is compatible with the on-premises application's existing file access method. The Storage Gateway service can be configured as a File Gateway, which provides a SMB file share that is backed by an Amazon S3 bucket.","poster":"Heer","upvote_count":"1"},{"comment_id":"714975","timestamp":"1668062520.0","poster":"breathingcloud","upvote_count":"1","content":"Question clearly states \"must implement a solution that uses an Amazon S3 bucket for shared storage \" so the answer is D"},{"comments":[{"timestamp":"1666528800.0","comment_id":"702170","poster":"joancarles","content":"Answer D. SMB it's supported for Storage Gateway to store and retrieve files from S3 bucket:\nhttps://aws.amazon.com/about-aws/whats-new/2018/06/aws-storage-gateway-adds-smb-support-to-store-objects-in-amazon-s3/?nc1=h_ls","upvote_count":"1"}],"timestamp":"1665080640.0","poster":"dcdcdc3","upvote_count":"4","content":"Selected Answer: D\nSince question states that app will be rewritten to use native S3 APIs, I would not pick FSX, rather, use Storage GW/File Gateway and the data will reside in S3. \n\nhttps://stackoverflow.com/questions/71413007/aws-fsx-vs-s3-file-gateway\n\nSMB over SGW/FGW is reported way slower than FSX but this is not an issue within the question.","comment_id":"688033"},{"content":"Selected Answer: D\nD\nbecause if you use Datasync, then you are maintaining two locations and have not actually migrated anything, just replicating.\nD will allow a migration and permanent switch from on prem to AWS storage.","upvote_count":"1","timestamp":"1664981760.0","poster":"Ell89","comment_id":"686977"},{"timestamp":"1664727060.0","comment_id":"684932","upvote_count":"3","content":"Selected Answer: D\nFile Gateway appliance is a virtual machine to bridge between your NFS and S3","poster":"JohnPi"},{"timestamp":"1663177860.0","upvote_count":"1","poster":"Ni_yot","content":"Will go with D. B and C ruled out as you need to continue accessing the data during copy. A does migrate date to S3.","comment_id":"669235"},{"content":"Answer D","comment_id":"666533","upvote_count":"1","timestamp":"1662947100.0","poster":"asg76"}],"question_id":888,"question_images":[],"answer":"D","answer_description":"","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/81735-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"D","choices":{"C":"Deploy an AWS Server Migration Service (AWS SMS) VM to the on-premises environment. Use AWS SMS to migrate the file storage server from on premises to an Amazon EC2 instance.","B":"Create an S3 bucket for the application. Copy the data from the on-premises storage to the S3 bucket.","D":"Create an S3 bucket for the application. Deploy a new AWS Storage Gateway file gateway on an on-premises VM. Create a new file share that stores data in the S3 bucket and is associated with the file gateway. Copy the data from the on-premises storage to the new file gateway endpoint.","A":"Create a new Amazon FSx for Windows File Server file system. Configure AWS DataSync with one location for the on-premises file share and one location for the new Amazon FSx file system. Create a new DataSync task to copy the data from the on-premises file share location to the Amazon FSx file system."}},{"id":"pRuIRqeq4yAMOa1JUr4A","answers_community":["B (93%)","7%"],"url":"https://www.examtopics.com/discussions/amazon/view/79258-exam-aws-certified-solutions-architect-professional-topic-1/","question_id":889,"answer_images":[],"answer":"B","choices":{"D":"Place the EC2 instance behind a Network Load Balancer (NLB). Update the DNS record sftp.example.com in Route 53 to point to the NLB.","B":"Migrate the SFTP server to AWS Transfer for SFTP. Update the DNS record sftp.example.com in Route 53 to point to the server endpoint hostname.","C":"Migrate the SFTP server to a file gateway in AWS Storage Gateway. Update the DNS record sftp.example.com in Route 53 to point to the file gateway endpoint.","A":"Move the EC2 instance into an Auto Scaling group. Place the EC2 instance behind an Application Load Balancer (ALB). Update the DNS record sftp.example.com in Route 53 to point to the ALB."},"timestamp":"2022-09-02 05:40:00","question_images":[],"topic":"1","isMC":true,"exam_id":32,"answer_description":"","discussion":[{"timestamp":"1662436680.0","comment_id":"660778","poster":"cale","content":"Selected Answer: B\nAWS Transfer Family is managed service -- https://aws.amazon.com/aws-transfer-family/faqs/","upvote_count":"8"},{"timestamp":"1664981940.0","upvote_count":"1","poster":"Ell89","comment_id":"686981","content":"Selected Answer: B\n100% B\n\nfor A, what happens if an AZ goes down? you think EC2 instances are more reliable than a managed service?"},{"timestamp":"1664747220.0","poster":"sb333","comment_id":"685087","upvote_count":"2","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/transfer/latest/userguide/what-is-aws-transfer-family.html"},{"timestamp":"1662392520.0","comment_id":"660320","upvote_count":"3","content":"Selected Answer: B\nhttps://aws.amazon.com/about-aws/whats-new/2018/11/aws-transfer-for-sftp-fully-managed-sftp-for-s3/?nc1=h_ls","poster":"AwsBRFan"},{"upvote_count":"1","comment_id":"656926","timestamp":"1662090000.0","poster":"cloudude","content":"Selected Answer: A\nA makes more sense"}],"question_text":"A finance company hosts a data lake in Amazon S3. The company receives financial data records over SFTP each night from several third parties. The company runs its own SFTP server on an Amazon EC2 instance in a public subnet of a VPC. After the files are uploaded, they are moved to the data lake by a cron job that runs on the same instance. The SFTP server is reachable on DNS sftp.example.com through the use of Amazon Route 53.\nWhat should a solutions architect do to improve the reliability and scalability of the SFTP solution?","unix_timestamp":1662090000,"answer_ET":"B"},{"id":"UbsJf0hnGHsNVqLBCZGC","unix_timestamp":1662090180,"answers_community":["D (100%)"],"exam_id":32,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/79259-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"timestamp":"1662436980.0","content":"Selected Answer: D\nIt is D","comment_id":"660782","upvote_count":"3","poster":"cale"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/snowball/latest/snowcone-guide/snowcone-what-is-snowcone.html (snowcone will max 14 TB) \nhttps://docs.aws.amazon.com/SchemaConversionTool/latest/userguide/agents.oltp.html (SCT agents can extract data)","upvote_count":"3","poster":"AwsBRFan","comment_id":"660326","timestamp":"1662392940.0"},{"content":"Selected Answer: D\nNo brainer D","timestamp":"1662090180.0","comment_id":"656927","upvote_count":"4","poster":"cloudude"}],"question_images":[],"answer_description":"","answer_images":[],"topic":"1","answer":"D","choices":{"A":"Take the application offline. Create a local backup of the database. Transmit the database backup file over the existing connection to an Amazon S3 bucket. Use native database tools to restore the backup onto the new database and to set up replication to capture any changes since the backup. Modify the database connection string, and bring the application online.","D":"Use AWS Database Migration Service (AWS DMS) to launch a replication instance in a connected VPC. Use the AWS Schema Conversion Tool to extract the data locally and to move the data to an AWS Snowball Edge Storage Optimized device. Ship the device to AWS, and use an AWS DMS task to complete the transfer to the target database. For the migration type, choose the option to migrate existing data and replicate ongoing changes. Modify DNS records to point to the new database.","B":"Install the Server Migration Connector VM in the local data center. Use the AWS Server Migration Service (AWS SMS) console to replicate the on-premises database to the new database. Modify DNS records to point to the new database.","C":"Create a local backup of the database, and copy the backup onto an AWS Snowcone device. Activate the AWS DataSync agent on the device, and configure the agent to copy the backup and ongoing changes to an Amazon S3 bucket. Use AWS Backup to restore the backup onto the new database and to apply the changes. Modify DNS records to point to the new database."},"question_id":890,"answer_ET":"D","question_text":"A weather forecasting company is migrating an application that stores data on premises in a PostgreSQL database. The Company wants to migrate the database to Amazon Aurora PostgreSQL. The database size grows at an average rate of 5 GB daily and is currently 50 TB. The data center has an internet connection with\n50 Mbps of available bandwidth. The migration to AWS must be completed as soon as possible within the next 21 days.\nWhich data transfer strategy meets these requirements with the LEAST amount of application downtime?","timestamp":"2022-09-02 05:43:00"}],"exam":{"isImplemented":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Professional","id":32,"isMCOnly":false,"provider":"Amazon","isBeta":false},"currentPage":178},"__N_SSP":true}