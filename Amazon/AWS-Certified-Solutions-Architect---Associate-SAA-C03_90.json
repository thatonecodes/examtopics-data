{"pageProps":{"questions":[{"id":"uIGKnWPfx1ZGwbSpYiGR","answers_community":["B (60%)","A (40%)"],"discussion":[{"timestamp":"1684430040.0","upvote_count":"13","comment_id":"901403","poster":"cloudenthusiast","content":"Selected Answer: B\nAWS DataSync is a fully managed data transfer service that simplifies and automates the process of moving data between on-premises storage and Amazon S3. It provides secure and efficient data transfer with built-in encryption, ensuring that the data is encrypted in transit.\n\nBy using AWS DataSync, the company can easily migrate the 100 GB of historical data from their on-premises location to an S3 bucket. DataSync will handle the encryption of data in transit and ensure secure transfer."},{"comment_id":"901217","content":"Selected Answer: B\nUsing DataSync, the company can easily migrate the 100 GB of historical data to an S3 bucket. DataSync will handle the encryption of data in transit, so the company does not need to set up a VPN or worry about managing encryption keys.\n\nOption A, using the s3 sync command in the AWS CLI to move the data directly to an S3 bucket, would require more operational overhead as the company would need to manage the encryption of data in transit themselves. Option D, setting up an IPsec VPN from the on-premises location to AWS, would also require more operational overhead and would be overkill for this scenario. Option C, using AWS Snowball, could work but would require more time and resources to order and set up the physical device.","poster":"luiscc","upvote_count":"7","timestamp":"1684414500.0"},{"poster":"dollykidurian","timestamp":"1742017800.0","comment_id":"1397364","content":"My counter to all those, picking choice A, you will have to manually re-run the command if on-premise internet goes down however with datasync the service auto resume. (less operational overhead and less monitoring)","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: B\nYou can also copy or synchronize data from on-premises to AWS manually with the AWS CLI, but doing so requires a fair bit of system tuning see https://aws.amazon.com/blogs/storage/migrating-and-managing-large-datasets-on-amazon-s3/","timestamp":"1738773540.0","comment_id":"1351979","poster":"zdi561"},{"comment_id":"1324258","upvote_count":"1","content":"Selected Answer: A\nFor A, it is more straightforward approach, with 100Mbps = 12.5MBs, 100 GB = 100 * 1024 MB = 102,400 MB, 102400 / 12.5 = 8192s = 2.3 hours, so if the network is stable, it should be less operational overhead than B which requires the installation of agent and network configuration, so compared to S3 sync, DataSync requires more upfront configuration but provides more robust, automated transfer capabilities.In an AWS certification exam, they typically expect you to choose the solution that provides the most straightforward, efficient approach with the least operational overhead while meeting all specified requirements.\nFor this scenario, they would likely expect you to choose A.","poster":"FlyingHawk","timestamp":"1733786460.0","comments":[{"comment_id":"1324261","content":"In the context of AWS exam, AWS may expect we choose B as AWS DataSync is a managed service designed specifically for data migration tasks, A is more ad-hoc approach suit for small data-set. 100 GB will take 2.22 hours, although it is acceptable.","upvote_count":"1","poster":"FlyingHawk","timestamp":"1733787720.0"}]},{"poster":"LeonSauveterre","upvote_count":"2","content":"Selected Answer: A\nOption A meets all the requirements with the LEAST operational overhead (while option B will introduce unnecessary complexity for a one-time transfer). The data will be encrypted in transit (via HTTPS), and a 100 Mbps connection is sufficient to transfer data of 100 GB.\n\nIf the task involves periodic transfers or error recovery, DataSync (option B) could be considered as an alternative.","comment_id":"1322285","timestamp":"1733389140.0"},{"timestamp":"1722875160.0","poster":"1e22522","content":"Selected Answer: B\nWhy would u u se the CLI","comment_id":"1261114","upvote_count":"2"},{"comments":[{"upvote_count":"1","comment_id":"1189085","poster":"bujuman","timestamp":"1712206380.0","content":"Erratum:\nAssertions:\n- needs to encrypt the data in transit to the S3 bucket.\n- The company will store new data directly in Amazon S3.\nRequirements:\n- with the LEAST operational overhead\nEven Though options A and B could do the job, option B requires VM maintenance because it is not a once-off migration (The company will store new data directly in Amazon S3)\nNB: According to me, we must stuck to the question and avoid to interpret"}],"upvote_count":"3","comment_id":"1188480","content":"Selected Answer: A\nAssertions:\n- needs to encrypt the data in transit to the S3 bucket.\n- The company will store new data directly in Amazon S3.\nRequirements:\n- with the LEAST operational overhead\nEven Though options A and B could do the job, option A requires VM maintenance because it is not a once-off migration (The company will store new data directly in Amazon S3)\nNB: According to me, we must stuck to the question and avoid to interpret","timestamp":"1712122560.0","poster":"bujuman"},{"comments":[{"poster":"awsgeek75","timestamp":"1705674420.0","comment_id":"1126744","upvote_count":"3","content":"I agree, A is a million times simpler than B in terms of operational setup. AWS CLI is just one install on a server on client side and one command (literally) to sync the data."}],"upvote_count":"5","comment_id":"1110768","poster":"pentium75","timestamp":"1704045960.0","content":"Selected Answer: A\nA - one single command, uses encryption automatically\nB - Must install, configure and eventually decommission DataSync\nC - Overkill\nD - No need for VPN"},{"comment_id":"1101843","upvote_count":"2","timestamp":"1703097960.0","content":"Selected Answer: A\nBy default, all data transmitted from the client computer running the AWS CLI and AWS service endpoints is encrypted by sending everything through a HTTPS/TLS connection. You don't need to do anything to enable the use of HTTPS/TLS. It is always enabled unless you explicitly disable it for an individual command by using the --no-verify-ssl command line option.\nThis is simpler compared to datasync, which will cost operational overhead to configure.","poster":"1rob"},{"timestamp":"1699215240.0","comment_id":"1063239","poster":"potomac","upvote_count":"2","content":"Selected Answer: B\nstorage data (including metadata) is encrypted in transit, but how it's encrypted throughout the transfer depends on your source and destination locations."},{"comments":[{"upvote_count":"2","comment_id":"1126747","poster":"awsgeek75","timestamp":"1705674540.0","content":"There is no limitation on AWS CLI s3 sync command transfer size. Not that I can find in the docs. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/sync.html\n\nHappy to be corrected!"}],"poster":"thanhnv142","content":"B is correct to migrate\nA is incorrect because is it only used to upload minor files (about a few GB) to AWS. 100 GB is not appropriate.","comment_id":"1049218","timestamp":"1697853540.0","upvote_count":"2"},{"comment_id":"988458","poster":"Guru4Cloud","upvote_count":"4","content":"Selected Answer: B\nUse AWS DataSync to migrate the data from the on-premises location to an S3 bucket","timestamp":"1692806700.0"},{"upvote_count":"5","content":"Selected Answer: A\nB is a good option but as the volume is not large and the speed is not bad, A requires less operational overhead","timestamp":"1689468960.0","comment_id":"952830","poster":"HectorLeon2099"},{"timestamp":"1688699820.0","poster":"VellaDevil","upvote_count":"1","content":"Selected Answer: B\nAnswer A and B both are correct and with least operational overhead. But since the question says from an \"On-premise Location\" hence I would go with DataSync.","comment_id":"945214"},{"poster":"TariqKipkemei","comment_id":"931190","upvote_count":"2","timestamp":"1687491780.0","content":"Selected Answer: B\nAWS DataSync is a secure, online service that automates and accelerates moving data between on premises and AWS Storage services."},{"content":"Why not A?\ns3 is already encrypted in transit by TLS.\nWe need to have the LEAST operational overhead and DataSync implies the installation of Agent whereas AWS CLI is easier to use.","comments":[{"content":"I can think of two reasons.\n- S3 does have HTTP and HTTPS endpoints available. \n- DataSync offers data compression - considering the question mentions of internet bandwidth is mentioned.","poster":"Smart","timestamp":"1692904260.0","upvote_count":"2","comment_id":"989430"}],"poster":"vrevkov","comment_id":"927475","timestamp":"1687178100.0","upvote_count":"3"},{"poster":"Axeashes","comment_id":"923625","timestamp":"1686789720.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/cli/latest/userguide/cli-services-s3-commands.html","upvote_count":"3"},{"timestamp":"1684302300.0","content":"Answer - A\nUse the s3 sync command in the AWS CLI to move the data directly to an S3 bucket.","comment_id":"899768","poster":"EA100","upvote_count":"4"}],"choices":{"B":"Use AWS DataSync to migrate the data from the on-premises location to an S3 bucket","C":"Use AWS Snowball to move the data to an S3 bucket","D":"Set up an IPsec VPN from the on-premises location to AWS. Use the s3 cp command in the AWS CLI to move the data directly to an S3 bucket","A":"Use the s3 sync command in the AWS CLI to move the data directly to an S3 bucket"},"answer_ET":"B","question_id":446,"question_text":"A company wants to migrate 100 GB of historical data from an on-premises location to an Amazon S3 bucket. The company has a 100 megabits per second (Mbps) internet connection on premises. The company needs to encrypt the data in transit to the S3 bucket. The company will store new data directly in Amazon S3.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","question_images":[],"exam_id":31,"timestamp":"2023-05-17 07:45:00","url":"https://www.examtopics.com/discussions/amazon/view/109490-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"topic":"1","answer":"B","unix_timestamp":1684302300,"answer_description":"","answer_images":[]},{"id":"xOCkaWy5EOmzKZrG6RIt","question_text":"A company containerized a Windows job that runs on .NET 6 Framework under a Windows container. The company wants to run this job in the AWS Cloud. The job runs every 10 minutes. The job’s runtime varies between 1 minute and 3 minutes.\n\nWhich solution will meet these requirements MOST cost-effectively?","question_images":[],"answer":"C","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/109463-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"answer_ET":"C","discussion":[{"poster":"baba365","comment_id":"1018204","content":"Lambda supports only Linux-based container images.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/images-create.html","timestamp":"1695765060.0","upvote_count":"16","comments":[{"timestamp":"1704746640.0","content":"Not really. Lambda supports .Net 6 directly: https://aws.amazon.com/blogs/compute/introducing-the-net-6-runtime-for-aws-lambda/","poster":"awsgeek75","upvote_count":"7","comment_id":"1117001"}]},{"timestamp":"1684698480.0","poster":"AmrFawzy93","comment_id":"903515","content":"Selected Answer: C\nBy using Amazon ECS on AWS Fargate, you can run the job in a containerized environment while benefiting from the serverless nature of Fargate, where you only pay for the resources used during the job's execution. Creating a scheduled task based on the container image of the job ensures that it runs every 10 minutes, meeting the required schedule. This solution provides flexibility, scalability, and cost-effectiveness.","upvote_count":"8"},{"upvote_count":"1","poster":"zdi561","comment_id":"1351998","content":"Selected Answer: A\nLambda is the best for cost , the job is kicked off every 10min and it only takes several min.Set 10min timeout , there is no cost for idling . Batch and ECS cost more for sure.","timestamp":"1738776540.0"},{"upvote_count":"1","poster":"zdi561","content":"Selected Answer: A\nLambda can be in .net container, and it is the cheaper than any other options.","timestamp":"1737345000.0","comment_id":"1343314"},{"poster":"LeonSauveterre","content":"Selected Answer: C\nFor B: Even though AWS Batch is free, I think it's more suitable for large-scale or relatively complex workloads, not lightweight periodic jobs. So B is not cost-effective (The cost depends on the compute resources you provision to execute the jobs, and maybe \"cost-effective\" somewhat involves less operational overhead because you have spent your money)\n\nIf you require queueing for task prioritization or processing a backlog of tasks, or work on data processing over datasets where Batch excels, AWS Batch would be better!","comment_id":"1322290","timestamp":"1733389800.0","upvote_count":"1"},{"upvote_count":"2","content":"A A A A A A","comment_id":"1259517","poster":"muhammadahmer36","timestamp":"1722536640.0"},{"content":"selected answer : A\nAWS Lambda now supports .NET 6 as both a managed runtime and a container base image","timestamp":"1712555460.0","comment_id":"1191409","poster":"zinabu","upvote_count":"5"},{"timestamp":"1712265060.0","content":"Selected Answer: A\nhttps://aws.amazon.com/about-aws/whats-new/2022/02/aws-lambda-adds-support-net6/","upvote_count":"3","poster":"xBUGx","comment_id":"1189547"},{"comment_id":"1117002","content":"The question is weirdly phrased for .Net based containers. \"A company containerized a Windows job that runs on .NET 6 Framework under a Windows container.\" This could mean that the job requires .Net 6 Framework OR it could mean the job requires Windows and .Net Framework 6. If the job is just based on .Net 6 then Lambda can run it. I am just a bit cautious about language because other parameters fall under Lambda. Question may have been wrongly quoted here.","poster":"awsgeek75","upvote_count":"4","timestamp":"1704746760.0"},{"content":"Selected Answer: C\nI guess this is an old question from before August 2023, when AWS Batch did not support Windows containers, while ECS already did since September 2021. Thus it would be C, though now B does also work. Since both Batch and ECS are free, we'd pay only for the Fargate resources (which are identical in both cases), now B and C would be correct.\n\nA doesn't work because Lambda still does not support Windows containeres.\nD doesn't make sense because the container would have to run 24/7","timestamp":"1704091140.0","upvote_count":"7","poster":"pentium75","comment_id":"1110983"},{"comments":[{"poster":"pentium75","upvote_count":"2","timestamp":"1704090960.0","comment_id":"1110982","content":"Both Batch and ECS are free.\nhttps://aws.amazon.com/de/ecs/pricing/\nhttps://aws.amazon.com/de/batch/pricing/"}],"timestamp":"1702996020.0","content":"I think that Batch with Fargate is more cheaper than ECS.","comment_id":"1100701","poster":"ftaws","upvote_count":"1"},{"poster":"kt7","comment_id":"1070905","upvote_count":"6","content":"Selected Answer: B\nBatch supports fargate now","timestamp":"1700001780.0"},{"comment_id":"1060583","poster":"ccmc","timestamp":"1698931620.0","upvote_count":"3","content":"Selected Answer: B\naws batch supports fargate"},{"upvote_count":"1","poster":"deechean","comment_id":"996007","content":"Selected Answer: C\nC works. For A, the lambda support container image, but the container image much implement the Lambda Runtime API.","timestamp":"1693568340.0","comments":[{"upvote_count":"3","poster":"markoniz","timestamp":"1694712240.0","content":"Absolutely agree with this one ... Lambda do not support Windows container, on the other hand ECS is adequate solution","comment_id":"1007830"}]},{"timestamp":"1693428900.0","upvote_count":"3","poster":"Hades2231","comments":[{"poster":"RDM10","content":"that's exactly my question too.\nIn one of the discussions, they same lambda is for jobs for 15 min. But for other question, they same batch is the best. I do not understand why we cant use batch?","upvote_count":"1","timestamp":"1695358980.0","comment_id":"1013604"}],"comment_id":"994457","content":"Selected Answer: B\nAs they support Batch on Fargate now (Aug 2023), the correct answer should be B?"},{"comments":[{"upvote_count":"2","poster":"pentium75","timestamp":"1704090540.0","comment_id":"1110979","content":"But it's clearly \"a Windows job\". Lambda does not support Windows containers. (.NET 6 could also run under Linux, but they'd need to modify the container in any case.)"}],"upvote_count":"1","poster":"Smart","timestamp":"1692904560.0","comment_id":"989435","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/lambda/latest/dg/csharp-image.html#csharp-image-clients"},{"content":"Selected Answer: C\nC is the most cost-effective solution for running a short-lived Windows container job on a schedule.\n\nUsing Amazon ECS scheduled tasks on Fargate eliminates the need to provision EC2 resources. You pay only for the duration the task runs.\n\nScheduled tasks handle scheduling the jobs and scaling resources automatically. This is lower cost than managing your own scaling via Lambda or Batch.\n\nECS also supports Windows containers natively unlike Lambda (option A).\n\nOption D still requires provisioning and paying for full time EC2 resources to run a task scheduler even when tasks are not running.","poster":"Guru4Cloud","comment_id":"988457","upvote_count":"2","timestamp":"1692806400.0"},{"comment_id":"987929","timestamp":"1692765900.0","content":"August 2023, AWS Batch now support Windows container\n\nhttps://docs.aws.amazon.com/batch/latest/userguide/fargate.html#when-to-use-fargate","poster":"cd93","upvote_count":"2","comments":[{"content":"https://aws.amazon.com/blogs/containers/running-windows-containers-with-amazon-ecs-on-aws-fargate/","comment_id":"992185","timestamp":"1693227120.0","poster":"cd93","upvote_count":"2"}]},{"timestamp":"1687692120.0","comment_id":"933513","poster":"wRhlH","upvote_count":"2","content":"For those wonder why not B \nAWS Batch doesn't support Windows containers on either Fargate or EC2 resources.\nhttps://docs.aws.amazon.com/batch/latest/userguide/fargate.html#when-to-use-fargate:~:text=AWS%20Batch%20doesn%27t%20support%20Windows%20containers%20on%20either%20Fargate%20or%20EC2%20resources.","comments":[{"timestamp":"1693001940.0","content":"They have now added support, which now makes B true? \nhttps://aws.amazon.com/about-aws/whats-new/2023/07/aws-batch-fargate-linux-arm64-windows-x86-containers-cli-sdk/","comment_id":"990422","comments":[{"poster":"cyber_bedouin","comment_id":"1046969","content":"the actual exam is not up-to-date, it came out in August 30, 2022","timestamp":"1697637300.0","upvote_count":"2"}],"upvote_count":"1","poster":"lemur88"}]},{"poster":"mattcl","timestamp":"1687557480.0","upvote_count":"2","content":"A: Lambda supports containerized applications","comment_id":"931973"},{"comment_id":"931196","poster":"TariqKipkemei","content":"Selected Answer: C\nAWS Fargate will bill you based on the amount of vCPU, RAM, OS, CPU architecture, and storage that your containerized apps consume while running on EKS or ECS. From the time you start downloading a container image until the ECS task or EKS pod ends. \nLambda is also an option but will involve some re-architecting, so why take the long route?","timestamp":"1687492620.0","comments":[{"content":"Also, Lambda does not support windows-based container images.\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/images-create.html#:~:text=Lambda%20supports%20only-,Linux%2Dbased,-container%20images.","comment_id":"1064518","poster":"TariqKipkemei","upvote_count":"2","timestamp":"1699335900.0"}],"upvote_count":"2"},{"timestamp":"1687173240.0","upvote_count":"2","comments":[{"timestamp":"1691660280.0","poster":"Ale1973","comment_id":"977474","content":"But, scenary says \"Create an AWS Lambda function based on the container image of the job\", then, I must assume that it is exactly the same image, not a new image based on it...","upvote_count":"1"},{"timestamp":"1687173420.0","upvote_count":"1","comment_id":"927408","content":"Furthermore, Lambda can create \"Container Image\" appropriate for the company containerized app.","poster":"MrAWSAssociate"}],"comment_id":"927405","content":"Selected Answer: A\nThe previous status for the company app is within containerization techonoly using .Net. Now the company wants to use one of AWS solution (should not be ECS), so one easy possibility is using Lambda with EventBridge as option \"A\" declared !","poster":"MrAWSAssociate"},{"comment_id":"923657","upvote_count":"2","content":"Selected Answer: C\nBy leveraging AWS Fargate and ECS, you can achieve cost-effective scaling and resource allocation for your containerized Windows job running on .NET 6 Framework in the AWS Cloud. The serverless nature of Fargate ensures that you only pay for the actual resources consumed by your containers, allowing for efficient cost management.","timestamp":"1686796980.0","poster":"AnishGS"},{"content":"Selected Answer: C\ncame across this study: https://blogs.perficient.com/2021/06/17/aws-cost-analysis-comparing-lambda-ec2-fargate/\nIndicating Fargate as a lower cost than Lamda for little or no idle time - I believe that is the case. .NET6 seems supported on both Lamda and Fargate.","comment_id":"923652","upvote_count":"3","timestamp":"1686795900.0","poster":"Axeashes"},{"comment_id":"915246","content":"By utilizing AWS Fargate to run the containerized Windows job on .NET 6 Framework, and scheduling it using CloudWatch Events, you can achieve cost-effective execution while meeting the job's requirements. C is the answer","upvote_count":"1","poster":"AshishRocks","timestamp":"1685955360.0"},{"upvote_count":"3","comment_id":"910701","poster":"omoakin","content":"CCCCCCCCCC","timestamp":"1685496300.0"},{"content":"100% C crt","comment_id":"909000","poster":"PRASAD180","upvote_count":"3","timestamp":"1685329080.0"},{"content":"C for sure","timestamp":"1684793820.0","poster":"Anmol_1010","comment_id":"904399","upvote_count":"2"},{"upvote_count":"2","poster":"Rob1L","content":"Selected Answer: A\nIt's A : lambda support .NET 6","comment_id":"902573","timestamp":"1684585140.0"},{"upvote_count":"2","content":"Selected Answer: B\nAWS Batch is a cost-effective service designed to handle batch computing workloads, making it suitable for running periodic jobs like the one described. By utilizing AWS Fargate as the underlying compute environment, you can efficiently run your Windows job without managing the infrastructure. You can configure the job scheduling in AWS Batch to execute the job every 10 minutes.\n\nWhile option C (using Amazon ECS on AWS Fargate with a scheduled task) is also a valid approach, it may introduce additional complexity as you would need to manage the scheduling of the task separately from AWS Batch.\n\nTherefore, for the given requirements, option B using AWS Batch is the recommended and most cost-effective solution.","comment_id":"901404","timestamp":"1684430220.0","poster":"cloudenthusiast"},{"poster":"norris81","comment_id":"900442","upvote_count":"3","timestamp":"1684348080.0","content":"https://aws.amazon.com/about-aws/whats-new/2021/10/aws-fargate-amazon-ecs-windows-containers/\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/images-create.html\n\nLambda supports only Linux-based container images"},{"poster":"exam9391","timestamp":"1684335240.0","upvote_count":"1","content":"A -> https://docs.aws.amazon.com/lambda/latest/dg/lambda-csharp.html","comment_id":"900263"},{"timestamp":"1684265220.0","poster":"nosense","content":"Selected Answer: B\nb most cost effective","comment_id":"899531","upvote_count":"1"}],"choices":{"D":"Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate to run the job. Create a standalone task based on the container image of the job. Use Windows task scheduler to run the job every\n10 minutes.","B":"Use AWS Batch to create a job that uses AWS Fargate resources. Configure the job scheduling to run every 10 minutes.","A":"Create an AWS Lambda function based on the container image of the job. Configure Amazon EventBridge to invoke the function every 10 minutes.","C":"Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate to run the job. Create a scheduled task based on the container image of the job to run every 10 minutes."},"unix_timestamp":1684265220,"answer_description":"","timestamp":"2023-05-16 21:27:00","answers_community":["C (51%)","B (29%)","A (20%)"],"answer_images":[],"question_id":447,"exam_id":31},{"id":"pzCNlx3HS6H5BZmheJ3x","answer_ET":"AE","isMC":true,"answer":"AE","question_id":448,"question_text":"A company wants to move from many standalone AWS accounts to a consolidated, multi-account architecture. The company plans to create many new AWS accounts for different business units. The company needs to authenticate access to these AWS accounts by using a centralized corporate directory service.\n\nWhich combination of actions should a solutions architect recommend to meet these requirements? (Choose two.)","answers_community":["AE (100%)"],"timestamp":"2023-05-16 21:29:00","choices":{"A":"Create a new organization in AWS Organizations with all features turned on. Create the new AWS accounts in the organization.","C":"Configure a service control policy (SCP) to manage the AWS accounts. Add AWS IAM Identity Center (AWS Single Sign-On) to AWS Directory Service.","D":"Create a new organization in AWS Organizations. Configure the organization's authentication mechanism to use AWS Directory Service directly.","B":"Set up an Amazon Cognito identity pool. Configure AWS IAM Identity Center (AWS Single Sign-On) to accept Amazon Cognito authentication.","E":"Set up AWS IAM Identity Center (AWS Single Sign-On) in the organization. Configure IAM Identity Center, and integrate it with the company's corporate directory service."},"exam_id":31,"answer_images":[],"discussion":[{"poster":"cloudenthusiast","timestamp":"1716054540.0","upvote_count":"11","content":"Selected Answer: AE\nA. By creating a new organization in AWS Organizations, you can establish a consolidated multi-account architecture. This allows you to create and manage multiple AWS accounts for different business units under a single organization.\n\nE. Setting up AWS IAM Identity Center (AWS Single Sign-On) within the organization enables you to integrate it with the company's corporate directory service. This integration allows for centralized authentication, where users can sign in using their corporate credentials and access the AWS accounts within the organization.\n\nTogether, these actions create a centralized, multi-account architecture that leverages AWS Organizations for account management and AWS IAM Identity Center (AWS Single Sign-On) for authentication and access control.","comment_id":"901425"},{"poster":"Guru4Cloud","upvote_count":"3","timestamp":"1724428320.0","comment_id":"988455","content":"Selected Answer: AE\nA) Using AWS Organizations allows centralized management of multiple AWS accounts in a single organization. New accounts can easily be created within the organization.\n\nE) Integrating AWS IAM Identity Center (AWS SSO) with the company's corporate directory enables federated single sign-on. Users can log in once to access accounts and resources across AWS.\n\nTogether, Organizations and IAM Identity Center provide consolidated management and authentication for multiple accounts using existing corporate credentials."},{"comments":[{"comment_id":"947405","poster":"baba365","content":"Ans: CD\n\n‘centralized corporate directory service’ with new accounts in AWS Organizations","timestamp":"1720541160.0","upvote_count":"2"}],"content":"Selected Answer: AE\nA:AWS Organization\nE:Authentication because option C (SCP) for Authorization","comment_id":"931746","timestamp":"1719157440.0","poster":"samehpalass","upvote_count":"4"},{"poster":"TariqKipkemei","timestamp":"1719115560.0","upvote_count":"2","content":"Selected Answer: AE\nCreate a new organization in AWS Organizations with all features turned on. Create the new AWS accounts in the organization.\nSet up AWS IAM Identity Center (AWS Single Sign-On) in the organization. Configure IAM Identity Center, and integrate it with the company's corporate directory service.\n\nAWS IAM Identity Center (successor to AWS Single Sign-On) helps you securely create or connect your workforce identities and manage their access centrally across AWS accounts and applications.\n\nhttps://aws.amazon.com/iam/identity-center/#:~:text=AWS%20IAM%20Identity%20Center%20(successor%20to%20AWS%20Single%20Sign%2DOn)%20helps%20you%20securely%20create%20or%20connect%20your%20workforce%20identities%20and%20manage%20their%20access%20centrally%20across%20AWS%20accounts%20and%20applications.","comment_id":"931200"},{"poster":"nosense","upvote_count":"2","comment_id":"899538","timestamp":"1715887740.0","content":"ae is right"}],"question_images":[],"unix_timestamp":1684265340,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/109467-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1"},{"id":"mJJshHfugvAedqjDOGfz","timestamp":"2023-05-16 21:32:00","answers_community":["A (97%)","3%"],"question_text":"A company is looking for a solution that can store video archives in AWS from old news footage. The company needs to minimize costs and will rarely need to restore these files. When the files are needed, they must be available in a maximum of five minutes.\n\nWhat is the MOST cost-effective solution?","unix_timestamp":1684265520,"exam_id":31,"answer_description":"","answer":"A","answer_ET":"A","isMC":true,"answer_images":[],"topic":"1","question_images":[],"discussion":[{"timestamp":"1700337240.0","upvote_count":"12","poster":"cloudenthusiast","content":"Selected Answer: A\nBy choosing Expedited retrievals in Amazon S3 Glacier, you can reduce the retrieval time to minutes, making it suitable for scenarios where quick access is required. Expedited retrievals come with a higher cost per retrieval compared to standard retrievals but provide faster access to your archived data.","comment_id":"901428"},{"comments":[{"poster":"wsdasdasdqwdaw","comment_id":"1056696","timestamp":"1714373820.0","upvote_count":"2","content":"Fully agree. Check here for evidences: https://aws.amazon.com/s3/storage-classes/glacier/#:~:text=S3%20Glacier%20Flexible%20Retrieval%20provides,amounts%20of%20data%20typically%20in"}],"comment_id":"899544","poster":"nosense","upvote_count":"5","timestamp":"1700170320.0","content":"glacier expedited retrieval times of typically 1-5 minutes."},{"upvote_count":"2","poster":"Ravan","comment_id":"1159997","timestamp":"1724690700.0","content":"Selected Answer: A\nThe most cost-effective solution that also meets the requirement of having the files available within a maximum of five minutes when needed is:\n\nA. Store the video archives in Amazon S3 Glacier and use Expedited retrievals.\n\nAmazon S3 Glacier is designed for long-term storage of data archives, providing a highly durable and secure solution at a low cost. With Expedited retrievals, data can be retrieved within a few minutes, which meets the requirement of having the files available within five minutes when needed. This option provides the balance between cost-effectiveness and retrieval speed, making it the best choice for the company's needs."},{"content":"Selected Answer: A\nOccasional cost for retrieval from Glacier is nothing compared to the huge storage cost savings compared to C. Still meets the five minute requirement.","poster":"pentium75","upvote_count":"2","comment_id":"1110988","timestamp":"1719809220.0"},{"content":"Selected Answer: C\nThe retrieval price will play an important role here. I selected the \"C\" option because in \"Glacier and use Expedited retrievals\" its around $0.004 per GB/month and for STD-IA $0.0125 per GB/month\nhttps://www.cloudforecast.io/blog/aws-s3-pricing-and-optimization-guide/","comment_id":"1105922","upvote_count":"1","timestamp":"1719393060.0","comments":[{"timestamp":"1719808980.0","upvote_count":"2","comment_id":"1110985","content":"But they \"will rarely need to restore their files\", thus the low cost for occasional expedited retrievals will be nothing compared to the huge storage cost savings.","poster":"pentium75"}],"poster":"master9"},{"comments":[{"upvote_count":"2","comment_id":"1110987","content":"A mentions \"G3 Glacier\" which has been renamed to \"S3 Glacier Flexible Retrieval\" and meets the requirements.","timestamp":"1719809160.0","poster":"pentium75"}],"timestamp":"1712920680.0","poster":"ngo01214","content":"s3 expedited can only be applied on glacier flexible retrieval storage class and s3 intelligent tiering archive access tier. so the answer should be C","comment_id":"1041687","upvote_count":"3"},{"comment_id":"989436","content":"Selected Answer: A\nI am going with option A, but it is a poorly written question. \"For all but the largest archives (more than 250 MB), data accessed by using Expedited retrievals is typically made available within 1–5 minutes. \"","poster":"Smart","upvote_count":"2","timestamp":"1708809600.0"},{"content":"Selected Answer: A\nAnswer - A\nFast availability: Although retrieval times for objects stored in Amazon S3 Glacier typically range from minutes to hours, you can use the Expedited retrievals option to expedite access to your archives. By using Expedited retrievals, the files can be made available in a maximum of five minutes when needed. However, Expedited retrievals do incur higher costs compared to standard retrievals.","upvote_count":"2","poster":"Guru4Cloud","comment_id":"988453","timestamp":"1708710240.0"},{"content":"Selected Answer: A\nExpedited retrievals are designed for urgent requests and can provide access to data in as little as 1-5 minutes for most archive objects. Standard retrievals typically finish within 3-5 hours for objects stored in the S3 Glacier Flexible Retrieval storage class or S3 Intelligent-Tiering Archive Access tier. These retrievals typically finish within 12 hours for objects stored in the S3 Glacier Deep Archive storage class or S3 Intelligent-Tiering Deep Archive Access tier. So A.","upvote_count":"3","poster":"hsinchang","timestamp":"1706242320.0","comment_id":"963243"},{"poster":"TariqKipkemei","comment_id":"931201","timestamp":"1703311980.0","upvote_count":"2","content":"Selected Answer: A\nExpedited retrievals allow you to quickly access your data that's stored in the S3 Glacier Flexible Retrieval storage class or the S3 Intelligent-Tiering Archive Access tier when occasional urgent requests for restoring archives are required. Data accessed by using Expedited retrievals is typically made available within 1–5 minutes."},{"content":"Selected Answer: A\nA for sure!","timestamp":"1702992720.0","upvote_count":"2","comment_id":"927416","poster":"MrAWSAssociate"},{"upvote_count":"1","timestamp":"1701328980.0","poster":"Doyin8807","comment_id":"909907","content":"C because A is not the most cost effective"},{"timestamp":"1700319660.0","upvote_count":"5","poster":"luiscc","comment_id":"901223","content":"Selected Answer: A\nExpedited retrieval typically takes 1-5 minutes to retrieve data, making it suitable for the company's requirement of having the files available in a maximum of five minutes."},{"content":"Selected Answer: A\nGlacier expedite","poster":"Efren","comment_id":"900904","upvote_count":"3","timestamp":"1700302440.0"},{"timestamp":"1700207520.0","poster":"EA100","comment_id":"899770","upvote_count":"2","content":"Answer - A\nFast availability: Although retrieval times for objects stored in Amazon S3 Glacier typically range from minutes to hours, you can use the Expedited retrievals option to expedite access to your archives. By using Expedited retrievals, the files can be made available in a maximum of five minutes when needed. However, Expedited retrievals do incur higher costs compared to standard retrievals."}],"choices":{"C":"Store the video archives in Amazon S3 Standard-Infrequent Access (S3 Standard-IA).","B":"Store the video archives in Amazon S3 Glacier and use Standard retrievals.","D":"Store the video archives in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA).","A":"Store the video archives in Amazon S3 Glacier and use Expedited retrievals."},"question_id":449,"url":"https://www.examtopics.com/discussions/amazon/view/109470-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"uuQDiTZp9Jp6vnwQSZ57","isMC":true,"unix_timestamp":1684432620,"discussion":[{"comment_id":"903902","timestamp":"1700652540.0","poster":"Yadav_Sanjay","upvote_count":"12","content":"Selected Answer: A\nECS is slightly cheaper than EKS"},{"content":"Selected Answer: A\nAmazon S3 is a highly scalable and cost-effective storage service that can be used to host static website content. It provides durability, high availability, and low latency access to the static files.\n\nAmazon ECS with AWS Fargate eliminates the need to manage the underlying infrastructure. It allows you to run containerized applications without provisioning or managing EC2 instances. This reduces operational overhead and provides scalability.\n\nBy using a managed Amazon RDS cluster for the database, you can offload the management tasks such as backups, patching, and monitoring to AWS. This reduces the operational burden and ensures high availability and durability of the database.","upvote_count":"5","comment_id":"901431","poster":"cloudenthusiast","timestamp":"1700337420.0"},{"timestamp":"1720465260.0","upvote_count":"5","comment_id":"1117009","poster":"awsgeek75","content":"Selected Answer: A\nB: CloudFront = Extra cost for something they don't want (CDN)\nC: Kubernetes is more operationally complex than ECS containers on Fargate.\nD: EC2 expensive\nA: S3 is cheap for static content. ECS with Fargate is easiest implantation. Managed RDS is very low op overhead"},{"upvote_count":"1","comments":[{"timestamp":"1713936900.0","poster":"wsdasdasdqwdaw","content":"Aaa I got it. With CF we are adding additional cost => A.","upvote_count":"2","comment_id":"1052555","comments":[{"upvote_count":"2","poster":"cyber_bedouin","timestamp":"1717754160.0","comment_id":"1090255","content":"A is better because ECS Fargate = \"containerized application\""}]}],"timestamp":"1713936600.0","poster":"wsdasdasdqwdaw","comment_id":"1052552","content":"Why not B ?"},{"comment_id":"988449","timestamp":"1708710120.0","content":"Selected Answer: A\nUse Amazon S3 to host static content. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database.","poster":"Guru4Cloud","upvote_count":"3"},{"timestamp":"1704989700.0","comment_id":"949019","poster":"jaydesai8","content":"Selected Answer: A\nS3= hosting static contents\nEcs = Little cheaper than EKS\nRDS = Database","upvote_count":"4"},{"comment_id":"934012","poster":"TariqKipkemei","timestamp":"1703569500.0","upvote_count":"3","content":"Selected Answer: A\nUse Amazon S3 to host static content. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database"}],"exam_id":31,"answer_images":[],"answer_ET":"A","timestamp":"2023-05-18 19:57:00","answer_description":"","answers_community":["A (100%)"],"topic":"1","choices":{"D":"Use Amazon EC2 Reserved Instances to host static content. Use Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 for compute power. Use a managed Amazon RDS cluster for the database.","B":"Use Amazon CloudFront to host static content. Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 for compute power. Use a managed Amazon RDS cluster for the database.","A":"Use Amazon S3 to host static content. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database.","C":"Use Amazon S3 to host static content. Use Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database."},"question_id":450,"question_text":"A company is building a three-tier application on AWS. The presentation tier will serve a static website The logic tier is a containerized application. This application will store data in a relational database. The company wants to simplify deployment and to reduce operational costs.\n\nWhich solution will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/109664-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"answer":"A"}],"exam":{"provider":"Amazon","id":31,"numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Associate SAA-C03","lastUpdated":"11 Apr 2025","isImplemented":true,"isBeta":false,"isMCOnly":true},"currentPage":90},"__N_SSP":true}