{"pageProps":{"questions":[{"id":"JcRW9LoaDCwxDb3cW4vS","isMC":true,"exam_id":23,"question_text":"A company wants to decrease the time it takes to develop new features. The company uses AWS CodeBuild and AWS CodeDeploy to build and deploy its applications. The company uses AWS CodePipeline to deploy each microservice with its own CI/CD pipeline.\n\nThe company needs more visibility into the average time between the release of new features and the average time to recover after a failed deployment.\n\nWhich solution will provide this visibility with the LEAST configuration effort?","unix_timestamp":1720911180,"answer":"B","choices":{"C":"Program an AWS Lambda function that writes information about successful runs and failed runs to Amazon DynamoDB. Create an Amazon EventBridge rule to invoke the Lambda function after every successful run and after every failed run. Build an Amazon QuickSight dashboard to show the information from DynamoDB.","B":"Program an AWS Lambda function that creates Amazon CloudWatch custom metrics with information about successful runs and failed runs for each pipeline. Create an Amazon EventBridge rule to invoke the Lambda function after every successful run and after every failed run. Use the metrics to build a CloudWatch dashboard.","A":"Program an AWS Lambda function that creates Amazon CloudWatch custom metrics with information about successful runs and failed runs for each pipeline. Create an Amazon EventBridge rule to invoke the Lambda function every 5 minutes. Use the metrics to build a CloudWatch dashboard.","D":"Program an AWS Lambda function that writes information about successful runs and failed runs to Amazon DynamoDB. Create an Amazon EventBridge rule to invoke the Lambda function every 5 minutes. Build an Amazon QuickSight dashboard to show the information from DynamoDB."},"question_images":[],"answer_ET":"B","question_id":151,"answers_community":["B (100%)"],"timestamp":"2024-07-14 00:53:00","url":"https://www.examtopics.com/discussions/amazon/view/143877-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_images":[],"discussion":[{"poster":"limelight04","content":"Selected Answer: B\nB is the correct answer","upvote_count":"2","comment_id":"1272370","timestamp":"1724636940.0"},{"content":"Selected Answer: B\nB is most simple and direct with LEAST configuration effort.","comment_id":"1258518","timestamp":"1722393660.0","upvote_count":"3","poster":"jamesf"},{"upvote_count":"2","timestamp":"1721036460.0","comment_id":"1248228","content":"---> B","poster":"tgv"},{"content":"Selected Answer: B\nA. Invoking the Lambda function every 5 minutes is less efficient compared to event-driven invocation\nB. provides the needed visibility with minimal configuration effort\nC & D. Using DynamoDB and QuickSight involves more configuration","timestamp":"1720911180.0","poster":"trungtd","upvote_count":"4","comment_id":"1247536"}],"topic":"1","answer_description":""},{"id":"vqJaN980JvEE8nTrtcuV","answer_images":[],"exam_id":23,"choices":{"A":"Deletion has failed because the S3 bucket has an active website configuration. Modify the CloudFormation template to remove the WebsiteConfiguration property from the S3 bucket resource.","C":"Deletion has failed because the custom resource does not define a deletion policy. Add a DeletionPolicy property to the custom resource definition with a value of RemoveOnDeletion.","B":"Deletion has failed because the S3 bucket is not empty. Modify the custom resource's AWS Lambda function code to recursively empty the bucket when RequestType is Delete.","D":"Deletion has failed because the S3 bucket is not empty. Modify the S3 bucket resource in the CloudFormation template to add a DeletionPolicy property with a value of Empty."},"isMC":true,"answer_description":"","question_text":"A company has developed a static website hosted on an Amazon S3 bucket. The website is deployed using AWS CloudFormation. The CloudFormation template defines an S3 bucket and a custom resource that copies content into the bucket from a source location.\n\nThe company has decided that it needs to move the website to a new location, so the existing CloudFormation stack must be deleted and re-created. However, CloudFormation reports that the stack could not be deleted cleanly.\n\nWhat is the MOST likely cause and how can the DevOps engineer mitigate this problem for this and future versions of the website?","answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/143364-exam-aws-certified-devops-engineer-professional-dop-c02/","question_id":152,"unix_timestamp":1720188540,"discussion":[{"upvote_count":"2","content":"Selected Answer: B\nYou can only delete empty buckets. Deletion fails for buckets that have contents.\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html","comment_id":"1332005","timestamp":"1735231500.0","poster":"youonebe"},{"comment_id":"1270821","content":"Selected Answer: B\nvote for B","upvote_count":"2","poster":"[Removed]","timestamp":"1724342040.0"},{"content":"Selected Answer: B\nBy default cloudformation can't delete an S3 bucket that's not empty. If the bucket still contains objects when the stack deletion is attempted, the stack deletion will fail. \n\nAlthough the Q doesn't specify that the custom resource uses Lambda. I think it's safe to assume here that since a custom resource is responsible for copying content into the bucket, it can also be used to handle the cleanup process.","timestamp":"1724073060.0","poster":"GripZA","comment_id":"1268692","upvote_count":"3"},{"content":"---> B","upvote_count":"2","comment_id":"1248230","poster":"tgv","timestamp":"1721036580.0"},{"content":"Selected Answer: B\nof course B","comment_id":"1247537","timestamp":"1720911300.0","poster":"trungtd","upvote_count":"3"},{"poster":"inturist","comment_id":"1246631","timestamp":"1720778340.0","upvote_count":"3","content":"Selected Answer: B\nAgree B"},{"poster":"siheom","comment_id":"1246408","upvote_count":"3","timestamp":"1720747020.0","content":"Selected Answer: B\nDefinitely B"}],"answers_community":["B (100%)"],"answer_ET":"B","question_images":[],"timestamp":"2024-07-05 16:09:00","topic":"1"},{"id":"N5krdFq5lyVRFrKHOPny","answer":"B","answer_images":[],"timestamp":"2024-07-06 22:32:00","answers_community":["B (100%)"],"discussion":[{"poster":"limelight04","content":"Selected Answer: B\nOption B: Configure AWS Systems Manager on each instance. Use Systems Manager Inventory and create AWS Config rules that monitor changes from Systems Manager Inventory to identify prohibited applications.\nThis approach leverages Systems Manager Inventory and AWS Config to efficiently track and identify prohibited applications while minimizing operational overhead.","comment_id":"1272371","upvote_count":"2","timestamp":"1724637300.0"},{"comment_id":"1269472","upvote_count":"3","content":"Selected Answer: B\nB fir nme","timestamp":"1724158320.0","poster":"[Removed]"},{"comment_id":"1260898","timestamp":"1722824100.0","poster":"jamesf","content":"Selected Answer: B\nkeywords: AWS Systems Manage, Systems Manager Inventory, AWS Config rule","upvote_count":"4"},{"poster":"tgv","content":"---> B","comment_id":"1248232","upvote_count":"2","timestamp":"1721036820.0"},{"content":"B\nhttps://aws.amazon.com/blogs/mt/preventing-blacklisted-applications-with-aws-systems-manager-and-aws-config/","comment_id":"1243548","upvote_count":"4","timestamp":"1720297920.0","poster":"getadroit"}],"unix_timestamp":1720297920,"url":"https://www.examtopics.com/discussions/amazon/view/143475-exam-aws-certified-devops-engineer-professional-dop-c02/","question_images":[],"isMC":true,"exam_id":23,"answer_description":"","topic":"1","question_id":153,"choices":{"A":"Configure AWS Systems Manager on each instance. Use AWS Systems Manager Inventory. Use Systems Manager resource data sync to synchronize and store findings in an Amazon S3 bucket. Create an AWS Lambda function that runs when new objects are added to the S3 bucket. Configure the Lambda function to identify prohibited applications.","D":"Designate Amazon CloudWatch Logs as the log destination for all application instances. Run an automated script across all instances to create an inventory of installed applications. Configure the script to forward the results to CloudWatch Logs. Create a CloudWatch alarm that uses filter patterns to search log data to identify prohibited applications.","B":"Configure AWS Systems Manager on each instance. Use Systems Manager Inventory Create AWS Config rules that monitor changes from Systems Manager Inventory to identify prohibited applications.","C":"Configure AWS Systems Manager on each instance. Use Systems Manager Inventory. Filter a trail in AWS CloudTrail for Systems Manager Inventory events to identify prohibited applications."},"answer_ET":"B","question_text":"A company uses Amazon EC2 as its primary compute platform. A DevOps team wants to audit the company's EC2 instances to check whether any prohibited applications have been installed on the EC2 instances.\n\nWhich solution will meet these requirements with the MOST operational efficiency?"},{"id":"VbAAB0WFKF7BItuUugho","question_images":[],"isMC":true,"question_text":"A company has an event-driven JavaScript application. The application uses decoupled AWS managed services that publish, consume, and route events. During application testing, events are not delivered to the target that is specified by an Amazon EventBridge rule.\n\nA DevOps team must provide application testers with additional functionality to view, troubleshoot, and prevent the loss of events without redeployment of the application.\n\nWhich combination of steps should the DevOps team take to meet these requirements? (Choose three.)","topic":"1","question_id":154,"timestamp":"2024-07-05 16:06:00","answers_community":["BCE (74%)","CEF (21%)","5%"],"discussion":[{"content":"Selected Answer: BCE\nF is incorrect because it invites an app redeployment with SDK being used to change code base! So BCE are the correct options","upvote_count":"2","timestamp":"1734342060.0","poster":"RajAWSDevOps007","comment_id":"1327249"},{"poster":"[Removed]","timestamp":"1724158740.0","upvote_count":"2","comment_id":"1269476","content":"Selected Answer: BCE\nBCE, without redeployment."},{"content":"Selected Answer: BCE\nKeywords: without redeployment of the application.\nOption B: Enabling CloudTrail will allow testers to track event activities and interactions with AWS services, aiding in troubleshooting.\nOption C: Using a standard SQS queue as a DLQ ensures that failed events are captured and can be analyzed or retried.\nOption E: Adding CloudWatch Logs as a target provides immediate logging of event processing, aiding in real-time monitoring and troubleshooting.","poster":"jamesf","upvote_count":"3","timestamp":"1722401100.0","comment_id":"1258565"},{"comment_id":"1253231","timestamp":"1721674020.0","poster":"TEC1","content":"Selected Answer: CEF\nI will go with CEF","upvote_count":"2"},{"timestamp":"1721338800.0","upvote_count":"1","poster":"dalieba","comment_id":"1250696","content":"CEF, X-ray enables you to debug distributed applications to troubleshoot the root cause of performance issues and errors"},{"comments":[{"comment_id":"1308228","poster":"VerRi","content":"GJ bro","upvote_count":"1","timestamp":"1730953320.0"}],"poster":"noisonnoiton","content":"Selected Answer: BCE\nwithout redeployment of the application.\n\nB,C,E","timestamp":"1721196240.0","comment_id":"1249414","upvote_count":"4"},{"upvote_count":"1","content":"---> CEF\nI thought E its not possible, but --> https://repost.aws/knowledge-center/cloudwatch-log-group-eventbridge","comment_id":"1248250","poster":"tgv","timestamp":"1721038560.0","comments":[{"timestamp":"1721298720.0","poster":"tgv","comment_id":"1250305","upvote_count":"2","content":"good catch with \"without redeployment of the application.\"\nB, C, E"}]},{"content":"Selected Answer: CEF\nC allows you to capture events that could not be delivered to the specified target\nE capture detailed logs of the events that are processed\nF end-to-end tracing capabilities\n\nB is wrong because while CloudTrail provides logging for AWS API calls, it is not specifically designed for capturing and troubleshooting event flows in EventBridge","upvote_count":"1","comment_id":"1247616","poster":"trungtd","timestamp":"1720933020.0"},{"comment_id":"1246407","content":"Selected Answer: BCE\nBCE...","timestamp":"1720746960.0","upvote_count":"3","poster":"siheom"},{"comment_id":"1242822","content":"Selected Answer: CEF\nCEF\nC > D - because SQS FIFO is not supported by Dead Letter Queues in event bridge","timestamp":"1720188420.0","poster":"xdkonorek2","upvote_count":"1"},{"poster":"xdkonorek2","comment_id":"1242820","upvote_count":"1","timestamp":"1720188360.0","content":"Selected Answer: CDF\nCDF\nC > D - because SQS FIFO is not supported by Dead Letter Queues in event bridge"}],"answer_ET":"BCE","choices":{"F":"Update the application code base to use the AWS X-Ray SDK tracing feature to instrument the code with support for the X-Amzn-Trace-Id header.","D":"Configure the EventBridge rule to use an Amazon Simple Queue Service (Amazon SQS) FIFO queue as a dead-letter queue.","B":"Create an Amazon S3 bucket. Enable AWS CloudTrail. Create a CloudTrail trail that specifies the S3 bucket as the storage location.","E":"Create a log group in Amazon CloudWatch Logs Specify the log group as an additional target of the EventBridge rule.","A":"Launch AWS Device Farm with a standard test environment and project to run a specific build of the application.","C":"Configure the EventBridge rule to use an Amazon Simple Queue Service (Amazon SQS) standard queue as a dead-letter queue."},"answer":"BCE","answer_images":[],"answer_description":"","unix_timestamp":1720188360,"exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/143363-exam-aws-certified-devops-engineer-professional-dop-c02/"},{"id":"HJ8ROOoiX2RFjP3YmiPW","topic":"1","answer":"AE","discussion":[{"comment_id":"1247658","timestamp":"1720940820.0","upvote_count":"5","poster":"trungtd","content":"Selected Answer: AE\nLEAST administrative overhead:\n=> Should create ECR repositories in the shared services account => A\nAnd should create only 1 Lambda function => E\n\nD wrong because it involves creating and managing multiple pipelines, which increases administrative overhead significantly"},{"content":"Selected Answer: AE\nAE because lambda","comment_id":"1349848","upvote_count":"1","poster":"jojewi8143","timestamp":"1738410780.0"},{"timestamp":"1726205160.0","upvote_count":"4","poster":"aws_god","comment_id":"1283024","content":"Selected Answer: AD\nLambda is not meant to work with Docker"},{"upvote_count":"3","content":"Selected Answer: AD\nAD gives the least administrative overhead","poster":"limelight04","comment_id":"1272375","timestamp":"1724638320.0"},{"poster":"auxwww","timestamp":"1723031700.0","upvote_count":"2","comment_id":"1262082","content":"Why E is not optimal - https://stackoverflow.com/questions/51158595/build-and-push-docker-image-to-aws-ecr-using-lambda"},{"content":"Selected Answer: AD\nWhy not E - To push images to the post-scan repo, you need a custom lambda container to run docker pull and push commands which is more complicated than Option D","timestamp":"1723031520.0","comment_id":"1262079","poster":"auxwww","upvote_count":"3"},{"poster":"jamesf","comment_id":"1258567","timestamp":"1722401580.0","content":"Selected Answer: AE\nkeywords: LEAST Administrative overhead\n\nOption A centralizes the repository management in the shared services account, simplifying access control and configuration management. Pre-scan and post-scan repositories are clearly separated, ensuring that only post-scan images are deployed.\n\nOption E uses event-driven automation to handle the scanning results and image promotion, reducing manual intervention and ensuring that only images that pass the security scan are moved to the post-scan repositories. This approach is efficient and minimizes administrative overhead compared to manually setting up pipelines or replication mechanisms.","upvote_count":"4"},{"upvote_count":"2","comment_id":"1248261","timestamp":"1721039040.0","content":"---> AE","poster":"tgv"},{"comment_id":"1242812","timestamp":"1720187220.0","upvote_count":"4","content":"Selected Answer: AE\nE > D for LEAST administrative overhead","poster":"xdkonorek2"}],"url":"https://www.examtopics.com/discussions/amazon/view/143361-exam-aws-certified-devops-engineer-professional-dop-c02/","question_id":155,"question_images":[],"answer_ET":"AE","unix_timestamp":1720187220,"timestamp":"2024-07-05 15:47:00","choices":{"D":"Create a pipeline in AWS CodePipeline for each pre-scan repository. Create a source stage that runs when new images are pushed to the pre-scan repositories. Create a stage that uses AWS CodeBuild as the action provider. Write a buildspec.yaml definition that determines the image scanning status and pushes images without critical vulnerabilities to the post-scan repositories.","A":"Create Amazon Elastic Container Registry (Amazon ECR) repositories in the shared services account: one repository for each pre-scan image and one repository for each post-scan image. Configure Amazon ECR image scanning to run on new image pushes to the pre-scan repositories. Use resource-based policies to grant the organization write access to the pre-scan repositories and read access to the post-scan repositories.","B":"Create pre-scan Amazon Elastic Container Registry (Amazon ECR) repositories in each account that publishes container images. Create repositories for post-scan images in the shared services account. Configure Amazon ECR image scanning to run on new image pushes to the pre-scan repositories. Use resource-based policies to grant the organization read access to the post-scan repositories.","E":"Create an AWS Lambda function. Create an Amazon EventBridge rule that reacts to image scanning completed events and invokes the Lambda function. Write function code that determines the image scanning status and pushes images without critical vulnerabilities to the post-scan repositories.","C":"Configure image replication for each image from the image's pre-scan repository to the image's post-scan repository."},"question_text":"A company is migrating its container-based workloads to an AWS Organizations multi-account environment. The environment consists of application workload accounts that the company uses to deploy and run the containerized workloads. The company has also provisioned a shared services account for shared workloads in the organization.\n\nThe company must follow strict compliance regulations. All container images must receive security scanning before they are deployed to any environment. Images can be consumed by downstream deployment mechanisms after the images pass a scan with no critical vulnerabilities. Pre-scan and post-scan images must be isolated from one another so that a deployment can never use pre-scan images.\n\nA DevOps engineer needs to create a strategy to centralize this process.\n\nWhich combination of steps will meet these requirements with the LEAST administrative overhead? (Choose two.)","isMC":true,"answer_description":"","answers_community":["AE (58%)","AD (42%)"],"answer_images":[],"exam_id":23}],"exam":{"isImplemented":true,"isMCOnly":true,"name":"AWS Certified DevOps Engineer - Professional DOP-C02","id":23,"lastUpdated":"11 Apr 2025","numberOfQuestions":355,"provider":"Amazon","isBeta":false},"currentPage":31},"__N_SSP":true}