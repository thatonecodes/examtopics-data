{"pageProps":{"questions":[{"id":"m4MfUkN8z8pMrNM99jGI","unix_timestamp":1669038840,"isMC":true,"answer":"B","answer_images":[],"timestamp":"2022-11-21 14:54:00","discussion":[{"upvote_count":"2","content":"what's DynamoDAdd?","timestamp":"1682695200.0","poster":"suru003","comment_id":"883597"},{"comment_id":"777259","timestamp":"1673835120.0","poster":"sichilam","content":"Why not C?","comments":[{"comment_id":"788301","upvote_count":"3","timestamp":"1674699540.0","poster":"tieyua","content":"Policy attached to a Role for EC2 instance profile. Policy gives Role access to Dynamo and allows developer to passrole into EC2 during launch."},{"upvote_count":"2","comment_id":"1043918","timestamp":"1697353080.0","content":"True answer is B.\nNot C because: \nThis permission allows one AWS service to \"pass\" a role to another AWS service.\nA common use case is with Amazon EC2. When you launch an EC2 instance and you want it to assume an IAM role (e.g., to give it permissions to access DynamoDB), you're essentially \"passing\" that role to the EC2 service. For this, the entity (user or service) trying to create the EC2 instance needs the iam:PassRole permission for the role it's trying to assign to the EC2 instance.\nIf you don't have the iam:PassRole permission for a specific role, you can't assign that role to resources.","poster":"nmc12"}],"upvote_count":"1"},{"comment_id":"729922","content":"Selected Answer: B\nBBBBBBB","timestamp":"1669698120.0","poster":"michaldavid","upvote_count":"1"},{"comments":[{"comment_id":"723567","timestamp":"1669038900.0","upvote_count":"2","content":"it's pass role and not get role \n\n\"An IAM permissions policy attached to the IAM user that allows the user to pass only those approved roles. You usually add iam:GetRole to iam:PassRole so the user can get the details of the role to be passed\"\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_passrole.html\n\nthe rest of the question was a bit of a grammer issue and i'm not too certain","poster":"dark_cherrymon"}],"upvote_count":"1","poster":"dark_cherrymon","timestamp":"1669038840.0","comment_id":"723565","content":"Selected Answer: B\ni picked b"}],"question_text":"A development team is building a new application that will run on Amazon EC2 and use Amazon DynamoDB as a storage layer. The developers all have assigned IAM user accounts in the same IAM group. The developers currently can launch EC2 instances, and they need to be able to launch EC2 instances with an instance role allowing access to Amazon DynamoDB.\n\nWhich AWS IAM changes are needed when creating an instance role to provide this functionality?","choices":{"A":"Create an IAM permission policy attached to the role that allows access to DynamoDB. Add a trust policy to the role that allows DynamoDB to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:GetRole and iam:PassRole permissions for the role.","D":"Create an IAM permissions policy attached to the role that allows access to DynamoDB. Add a trust policy to the role that allows Amazon EC2 to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:GetRole permission for the role.","B":"Create an IAM permissions policy attached to the role that allows access to DynamoDAdd a trust policy to the role that allows Amazon EC2 to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:PassRole permission for the role.","C":"Create an IAM permission policy attached to the role that allows access to Amazon EC2. Add a trust policy to the role that allows DynamoDB to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:PassRole permission for the role."},"question_images":[],"topic":"1","answer_ET":"B","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/88203-exam-aws-certified-developer-associate-topic-1-question-149/","question_id":56,"exam_id":25,"answer_description":""},{"id":"TBriMMzpsVZce9AuICjI","question_id":57,"url":"https://www.examtopics.com/discussions/amazon/view/79050-exam-aws-certified-developer-associate-topic-1-question-15/","exam_id":25,"timestamp":"2022-09-01 14:34:00","question_text":"A company has point-of-sale devices across thousands of retail shops that synchronize sales transactions with a centralized system. The system includes an\nAmazon API Gateway API that exposes an AWS Lambda function. The Lambda function processes the transactions and stores the transactions in Amazon RDS for MySQL. The number of transactions increases rapidly during the day and is near zero at night.\nHow can a developer increase the elasticity of the system MOST cost-effectively?","choices":{"A":"Migrate from Amazon RDS to Amazon Aurora MySQL. Use an Aurora Auto Scaling policy to scale road replicas based on CPU consumption.","C":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Publish transactions to the queue. Set the queue to invoke the Lambda function. Turn on enhanced fanout for the Lambda function.","B":"Migrate from Amazon RDS to Amazon Aurora MySQL. Use an Aurora Auto Scaling policy to scale read replicas based on the number of database connections.","D":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Publish transactions to the queue. Set the queue to invoke the Lambda function. Set the reserved concurrency of the Lambda function to be less than the number of database connections."},"isMC":true,"unix_timestamp":1662035640,"discussion":[{"timestamp":"1662073140.0","upvote_count":"25","poster":"JAMG54","content":"A and B are for read problem, nor for write.\nC its not possible because enhanced fanout its for kinesis\nD is the most probably","comment_id":"656713"},{"poster":"SuperPiski","comments":[{"comment_id":"867378","poster":"Syre","content":"D is very incorrect, D would limit the number of concurrent executions of the Lambda function, potentially creating a bottleneck and reducing the throughput of the system. A and B are wrong as they are for reads. C is the answer","timestamp":"1681222200.0","upvote_count":"2","comments":[{"content":"option D is better fit than C:\nin option c the reserved concurrency of lambda is set lower than database connection, that means database write operation will not throttle , while at lambda there is sqs behind lambda so for huge number of request sqs will hundle and will not throttle.","poster":"vipyodha","upvote_count":"2","timestamp":"1706697660.0","comment_id":"1136672"}]}],"upvote_count":"7","timestamp":"1662652140.0","comment_id":"663752","content":"Selected Answer: D\nRead replicas are for read... transactions means that something have to be written.\nThere is no such thing of fanout for lambda.\nThis lead to D. Because we've limited the number of concurrent lambdas to be lower than the number of connections, the system will run with no problems"},{"upvote_count":"1","content":"Selected Answer: D\n\"enhanced fanout\" is only for Kinesis-Lambda integration, not for SQS. Therefore answer D is best","timestamp":"1738070880.0","comment_id":"1347919","poster":"avinashk99"},{"poster":"sumanshu","comment_id":"1326852","timestamp":"1734266760.0","comments":[{"comments":[{"poster":"sumanshu","comment_id":"1326854","content":"Scaling based on read replicas only improves the performance of read-heavy workloads. This is irrelevant for the application's write-heavy workload, where sales transactions need to be written to the database.","comments":[{"poster":"sumanshu","content":"C) Eliminated - Enhanced fanout is specific to Amazon Kinesis Data Streams, not SQS. Even if enhanced fanout were relevant, it would not address database connection limits, which are the critical bottleneck here.","timestamp":"1734266940.0","comment_id":"1326855","upvote_count":"1"}],"upvote_count":"1","timestamp":"1734266880.0"}],"poster":"sumanshu","upvote_count":"1","comment_id":"1326853","timestamp":"1734266820.0","content":"A & B - Eliminated - because they focus on scaling read replicas, which is not suitable for a workload dominated by write operations"}],"upvote_count":"1","content":"Selected Answer: D\nD) Correct - By adding an SQS queue between the point-of-sale devices and the Lambda function, you can handle spikes in transaction volume without overwhelming the Lambda function or the RDS database.\n\nLimiting the concurrency of the Lambda function ensures that the number of simultaneous connections to the database does not exceed what the RDS instance can handle."},{"timestamp":"1730099220.0","upvote_count":"1","comment_id":"1303853","content":"Selected Answer: B\nB is seamly correct","poster":"thucta96dn"},{"content":"Selected Answer: D\nA&B are out because the aplpication writes to the DB, therefore read replicas do not help.\nC ist out because enahced fan out is a kinesis feature\nD solves the issue. Setting the concurrency limit to the number of database connections ensures that all running lambdas can successfuly write to the database.","comment_id":"1288026","poster":"trainee46","timestamp":"1727077260.0","upvote_count":"1"},{"comment_id":"1217682","content":"B. auto scalling is cost effective.","poster":"itsonlyjit1990","upvote_count":"1","timestamp":"1716571800.0"},{"comment_id":"1125155","upvote_count":"1","content":"option c Using an Amazon SQS queue to buffer transactions and then invoking the Lambda function can help in managing the varying transaction load. Turning on enhanced fanout for the Lambda function allows it to scale more effectively by processing records in parallel.","timestamp":"1705510860.0","poster":"gilleep_17"},{"upvote_count":"1","poster":"AsmaZoheb","timestamp":"1705272600.0","content":"Selected Answer: C\nOption C leverages the scalability of SQS and enhanced fanout for Lambda, making it the most cost-effective and suitable choice for handling varying transaction loads efficiently.","comment_id":"1122937"},{"timestamp":"1697010840.0","upvote_count":"1","comment_id":"1040336","poster":"kashtelyan","content":"Selected Answer: C\nC is correct because you are turning Kinesis enhanced fan out FORFORFOR Lambda not Lambda fanout itself. The scenario is exactly stating this.\nhttps://aws.amazon.com/about-aws/whats-new/2018/11/aws-lambda-supports-kinesis-data-streams-enhanced-fan-out-and-http2/"},{"upvote_count":"1","content":"Selected Answer: B\nreserved concurrency is not cost effectively, D is not correct","timestamp":"1696463520.0","comment_id":"1025213","poster":"dexdinh91"},{"upvote_count":"2","content":"It can't be C. Enhanced fan-out is a feature of Amazon Kinesis Data Streams, not SQS. Enhanced fan-out allows multiple consumers to receive data from a Kinesis data stream concurrently. D is the most probable","timestamp":"1690065480.0","poster":"CarlosC","comment_id":"959879"},{"content":"Selected Answer: D\nAgain, tricky question! I was for B but if we think about that, it is written \"stores the transactions in Amazon RDS\" and the B option is only about read replicas. So I changed my mind and now I will go for D as well.\nIt makes sense to create a Queue before process the transactions and publish messages to the SQS Queue and attach a lambda function to perform the transaction.\nAlso, set the reserved concurrency (max number of parallel invocations for a function) less than to the number of DB connections is a brilliant idea to avoid concurrency issues with the function.","timestamp":"1687880700.0","poster":"rcaliandro","comment_id":"935560","upvote_count":"6"},{"upvote_count":"1","content":"Selected Answer: B\nkeyword is \"increase the elasticity of the system MOST cost-effectively\"\nwe can find relative keyword auth-scaling","comment_id":"914241","poster":"siner","timestamp":"1685864940.0"},{"content":"Selected Answer: D\nShould be d","upvote_count":"1","comment_id":"907758","timestamp":"1685162940.0","poster":"rudyyang2001"},{"comment_id":"892457","timestamp":"1683572940.0","poster":"imvb88","content":"Selected Answer: D\ntransactions -> need write function. A, B only for read function -> out \nC: enhanced fan-out is feature of Kinesis. Lambda does support it but only with Kinesis, not with SQS -> out \nD make sense since SQS + Lambda is a pattern, plus setting reserved concurrency limit makes sense","upvote_count":"2"},{"upvote_count":"1","comment_id":"877839","content":"Selected Answer: C\nThis approach uses an Amazon SQS queue to decouple the point-of-sale devices from the centralized system, allowing for better scalability and reliability. The queue can handle large volumes of transactions during peak periods and ensure that the transactions are processed in a timely manner by invoking the Lambda function. Using enhanced fanout for the Lambda function can further increase its elasticity by allowing multiple instances to process messages concurrently. This is the most cost-effective approach as it doesn't require any changes to the existing RDS database or the use of expensive Aurora Auto Scaling.","poster":"MrTee","timestamp":"1682221800.0"},{"timestamp":"1681342800.0","upvote_count":"1","poster":"moonhope","comment_id":"868909","content":"B.\nhttps://aws.amazon.com/getting-started/hands-on/aurora-autoscaling-with-readreplicas/"},{"upvote_count":"3","comments":[{"poster":"cdm2009","comment_id":"1026184","content":"Enhanced Fan-Out applies to SNS and KDS - but we are using neither here. The reason such an option does not exist for SQS, is because that is how SQS operates natively.\n\nBecause of this, we must limit the concurrency of the Lambda function to be less than the maximum connection limit of the database. If we do not create this \"bottleneck\" (which the SQS queue exists to level out over time) then we will instead encounter connection errors.","upvote_count":"1","timestamp":"1696560840.0"}],"comment_id":"867384","timestamp":"1681222500.0","poster":"Syre","content":"Selected Answer: C\nD is very incorrect, D would limit the number of concurrent executions of the Lambda function, potentially creating a bottleneck and reducing the throughput of the system. A and B are wrong as they are for reads. C is the answer\n\nThe AWS Lambda feature called \"Enhanced Fan-Out\" exist, that enables multiple Lambda functions to receive and process events from an Amazon Simple Notification Service (SNS) or Amazon Kinesis Data Streams (KDS) stream in parallel. This feature is designed to increase the parallelism and throughput of the event processing pipeline, and it can be used to support high-throughput, real-time data processing use cases."},{"content":"The most cost-effective way to increase the elasticity of the system would be to create an Amazon Simple Queue Service (Amazon SQS) queue and publish transactions to the queue, then set the queue to invoke the Lambda function. Option C is the correct answer. This approach would decouple the transactions from the Lambda function and the RDS database, allowing for better scalability and fault tolerance. Turning on enhanced fanout for the Lambda function would also allow for faster processing of the transactions. Migrating to Amazon Aurora MySQL with read replicas (options A and B) would provide better performance, but it may not be the most cost-effective solution. Option D is incorrect because setting the reserved concurrency of the Lambda function to be less than the number of database connections would limit the processing capacity of the function and may cause a bottleneck","timestamp":"1677475500.0","comment_id":"823228","poster":"sebasbonilla","upvote_count":"3"},{"comment_id":"818557","upvote_count":"4","content":"Selected Answer: D\nCorrect answer is D. Neither A nor B will be of any use at all, because they say to scale out *read* replicas, but this application needs to WRITE to the database. So we want to decouple writes, and the easiest way to do that is with a queue. So we want SQS. But \"enhanced fanout\" is only for Kinesis-Lambda integration, not for SQS. Therefore answer D is best, and it also ensures we don't saturate database connections by configuring reserved concurrency - this protects against data loss by preventing an overload of the database during peak POS system usage.","timestamp":"1677110220.0","poster":"Kirkster"},{"comment_id":"806970","upvote_count":"1","timestamp":"1676251020.0","poster":"may2021_r","content":"Option D is the correct answer because creating an Amazon SQS queue and publishing transactions to the queue before storing them in Amazon RDS for MySQL can help to buffer the traffic and prevent sudden traffic spikes. Setting the queue to invoke the Lambda function can help to decouple the Lambda function from the point-of-sale devices, allowing for better scaling. Setting the reserved concurrency of the Lambda function to be less than the number of database connections can also help to prevent overloading the database tier."},{"timestamp":"1676060880.0","poster":"Krt5894","upvote_count":"1","comment_id":"804758","content":"Selected Answer: D\nD it is"},{"timestamp":"1674548280.0","comment_id":"786308","upvote_count":"2","content":"A and B are for read to eliminate\nC: there is fan-out option for lambda but is not posible here because lambda parallel workers may excute tasks more then databse connections (without replicas and autoscaling). D : lambda conccurrency less then database connection so fo each executes messag from SQS wil get database connetion available to handle transaction","poster":"gaddour_med"},{"poster":"michele_scar","content":"Selected Answer: D\nA and B are for read and are not cost-affectly because you increase the ACU base on connection so in real-life you will pay more than the use case.\nFanout lambda doesn't exists\nSo D is the answer.","timestamp":"1674221340.0","comment_id":"782283","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\nI think it's D as well. The problem states \"stores the transaction\" that means writing to a database.","poster":"Phinx","comment_id":"780588","timestamp":"1674088380.0"},{"timestamp":"1671513900.0","upvote_count":"1","comment_id":"750533","content":"Selected Answer: D\nAnswer D","poster":"mithunkundu1983"},{"poster":"tieyua","timestamp":"1671462780.0","upvote_count":"2","content":"scale from zero at night to thousands of busy shops during the day, is the exactly selling point of Aurora. I vote by the marketing sales pitch.","comment_id":"749966"},{"upvote_count":"2","content":"Selected Answer: D\nlambda reserved concurrency less than DB conn so when the db connection increases, lamda can scale up to reserved concurrency to provide a consistent rate WCU to RDS\nhttps://docs.aws.amazon.com/lambda/latest/operatorguide/reserved-concurrency.html","comment_id":"728566","poster":"SBoksh","timestamp":"1669580280.0"},{"comment_id":"727818","upvote_count":"1","content":"Selected Answer: A\nIf fix the typo \"road replica\" to \"read replica\", \"A\" definitely is the answer as exemplified by https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html#Aurora.Integrating.AutoScaling.BYB \n\nMore connectivity doesn't mean the DB is busy.","poster":"gpit","timestamp":"1669497360.0"},{"content":"Selected Answer: D\ni don't get what's with the whole reserved concurrency. i got to D because abc got eliminated. also AB are not cost effective","timestamp":"1668644040.0","comments":[{"content":"Reserved concurrency means that you don't allow more Lambda function executions at the same time than your database can handle (max concurrent connections). This way, you decouple the database writes from the load (from the POS system's call to the API). So yes, it's D, and the reserved concurrency ensures you don't get database connection timeouts that would result in data loss.","poster":"Kirkster","comment_id":"818558","timestamp":"1677110280.0","upvote_count":"1"}],"upvote_count":"1","comment_id":"720092","poster":"dark_cherrymon"},{"timestamp":"1665033780.0","poster":"adsdadasdad","content":"How can a developer increase the elasticity of the system MOST cost-effectively?\nsqs is a good choice but it states that the transactions are minimal at night and high through the day. This i believe points to aurora because it scales and uses the word elasticity. in this case sqs is defined not to scale in any matter and only solves the problem of parralel connections.Now the question is would you scale based on cpu or the amount of concurrent lambda requests. Like we saw it states that the number of transactions and not anything to do with CPU or READS but does impact the cpu but is not mentioned. i think this part confuses people and leads people to think to use sqs because it will solve the parralel problem of many requests. I do think its B. Here is a full explenation of SuperPiski question around writing to scaled instances.https://aws.amazon.com/blogs/database/planning-i-o-in-amazon-aurora/","comments":[{"upvote_count":"1","timestamp":"1677110460.0","poster":"Kirkster","comment_id":"818559","content":"It can't be B, because B (as well as A) only increase the number of read replicas, but the lambda function needs to *write* records to the database. So neither A nor B will help at all, because we need to write, not read. Therefore, the answer is D, because it uses SQS to decouple, and because reserved concurrency protects against data loss due to too many simultaneous database connections. (source: I'm a principal Solutions Architect at AWS)"}],"comment_id":"687484","upvote_count":"4"},{"poster":"venimus_vidimus_vicimus","upvote_count":"4","comment_id":"675999","content":"Selected Answer: D\nnever heard about fanout lambda","timestamp":"1663843980.0"},{"timestamp":"1662370620.0","upvote_count":"3","comment_id":"659999","comments":[{"poster":"SuperPiski","timestamp":"1662652020.0","content":"Transactions cannot be done with read replicas, should be done in the write instance.","upvote_count":"2","comment_id":"663751"},{"content":"\"Aurora Auto Scaling enables your Aurora DB cluster to handle sudden increases in connectivity or workload. When the connectivity or workload decreases, Aurora Auto Scaling removes unnecessary Aurora Replicas so that you don't pay for unused provisioned DB instances.\"","timestamp":"1663914720.0","upvote_count":"1","poster":"Merrick","comment_id":"676827"}],"poster":"PVR","content":"The answer is B. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html"},{"timestamp":"1662076740.0","poster":"sindra","content":"there is some ambiguity.. if we think that auora can scale to 0, i think the best answer is B.. but to optimize the design i believe its D since SQS cannot do the enhancedfanout by them self","upvote_count":"1","comment_id":"656739"},{"content":"I think its D","timestamp":"1662070920.0","upvote_count":"1","comment_id":"656708","comments":[{"content":"https://docs.aws.amazon.com/lambda/latest/dg/services-rds.html","comment_id":"656715","timestamp":"1662073260.0","upvote_count":"2","poster":"JAMG54"}],"poster":"JAMG54"},{"timestamp":"1662035640.0","comment_id":"656238","content":"Selected Answer: C\nI think its C","poster":"Chhotu_DBA","upvote_count":"2"}],"topic":"1","answer_images":[],"question_images":[],"answers_community":["D (74%)","C (17%)","7%"],"answer_description":"","answer":"D","answer_ET":"D"},{"id":"1HKNxD734HN9Ve8RoRa4","discussion":[{"timestamp":"1703571060.0","content":"Selected Answer: CE\nOption A is not generic solution for application written in different language with different versions: \"Data key caching is not supported by the AWS Encryption SDK for .NET. Version 3.x of the AWS Encryption SDK for Java deprecates the caching CMM. However, version 4.x of the AWS Encryption SDK for .NET and version 3.x of the AWS Encryption SDK for Java support the AWS KMS Hierarchical keyring, an alternative cryptographic materials caching solution.\" (Ref : https://docs.aws.amazon.com/encryption-sdk/latest/developer-guide/data-key-caching.html)","poster":"a_win","upvote_count":"1","comment_id":"1105746"},{"poster":"rcaliandro","comment_id":"936982","content":"Selected Answer: AC\nIf ThrottlingException is received then the quota for the account has been reached and it's possible to request to support to increase the quota for the account (answer C). Furthemore, \"Data key caching stores data keys and related cryptographic material in a cache. When you encrypt or decrypt data, the AWS Encryption SDK looks for a matching data key in the cache. If it finds a match, it uses the cached data key rather than generating a new one. Data key caching can improve performance, reduce cost, and help you stay within service limits as your application scales.\" by AWS documentation: https://docs.aws.amazon.com/encryption-sdk/latest/developer-guide/data-key-caching.html.\nAlso A is a correct option","upvote_count":"2","timestamp":"1687975320.0"},{"upvote_count":"2","comment_id":"777266","poster":"sichilam","content":"Use the data key caching feature with the AWS Encryption SDK encryption library. Data key caching reduces the rate of API requests by caching and reusing the data keys for encryption to meet cost and performance requirements.","timestamp":"1673837100.0"},{"poster":"ayoubmk","comment_id":"770608","content":"Selected Answer: AC\nhttps://aws.amazon.com/premiumsupport/knowledge-center/kms-throttlingexception-error/","upvote_count":"3","timestamp":"1673279340.0"},{"comment_id":"734203","poster":"SBoksh","upvote_count":"2","content":"Selected Answer: AC\nhttps://aws.amazon.com/premiumsupport/knowledge-center/kms-throttlingexception-error/","timestamp":"1670042280.0"},{"timestamp":"1669039380.0","poster":"dark_cherrymon","comment_id":"723577","content":"and A\n\n\"Use the data key caching feature with the AWS Encryption SDK encryption library. Data key caching reduces the rate of API requests by caching and reusing the data keys for encryption to meet cost and performance requirements.\"\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/kms-throttlingexception-error/#:~:text=The%20ThrottlingException%20error%20code%20indicates,KMS%20service%20throttles%20the%20request.\n\nwhich leads me to \n\nhttps://docs.aws.amazon.com/encryption-sdk/latest/developer-guide/data-caching-details.html#simplecache\n\n\" To create an instance of the local cache, use the LocalCryptoMaterialsCache constructor in Java and Python, the\"","upvote_count":"2"},{"timestamp":"1669039260.0","comment_id":"723573","poster":"dark_cherrymon","upvote_count":"2","content":"Selected Answer: C\nit's definately C\n\n\"Request an AWS KMS quota increase to exceed the request quota.\"\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/kms-throttlingexception-error/#:~:text=The%20ThrottlingException%20error%20code%20indicates,KMS%20service%20throttles%20the%20request."}],"answer_ET":"AC","unix_timestamp":1669039260,"isMC":true,"answer":"AC","answers_community":["AC (70%)","C (20%)","10%"],"timestamp":"2022-11-21 15:01:00","answer_images":[],"question_id":58,"question_text":"A banking application processes thousands of transactions each second. Each transaction payload must have end-to-end encryption. The application encrypts each transaction locally by using the AWS Key Management Service (AWS KMS) GenerateDataKey operation. A developer is testing the application and receives a ThrottlingException error.\n\nWhich actions are best practices to resolve this error? (Choose two.)","url":"https://www.examtopics.com/discussions/amazon/view/88204-exam-aws-certified-developer-associate-topic-1-question-150/","choices":{"C":"Create a case in the AWS Support Center to increase the quota for the account.","D":"Use Amazon Simple Queue Service (Amazon SQS) to queue the requests to AWS KMS.","A":"Use the LocalCryptoMatenalsCache feature of the AWS Encryption SDK encryption library.","B":"Call the AWS KMS Encrypt operation directly to allow AWS KMS to encrypt the data.","E":"Switch to an AWS KMS custom key store."},"exam_id":25,"question_images":[],"answer_description":"","topic":"1"},{"id":"SRKg6rO6U5DiD3A5Bu55","url":"https://www.examtopics.com/discussions/amazon/view/88205-exam-aws-certified-developer-associate-topic-1-question-151/","timestamp":"2022-11-21 15:06:00","choices":{"A":"Grant the CloudFormation service role the S3 ListBucket and GetObject permissions. Add a bucket policy to Amazon S3 with the pnncipal of \"AWS\": [account numbers].","D":"Use a service-based link to grant the Lambda function the S3 GetObject permission. Add a resource of \"*\" to allow access to the S3 bucket.","B":"Grant the CloudFormation service role the S3 GetObject permission. Add a bucket policy to Amazon S3 with the principal of \"*\".","C":"Use a service-based link to grant the Lambda function the S3 ListBucket and GetObject permissions by explicitly adding the S3 bucket’s account number in the resource."},"exam_id":25,"question_text":"A developer has code that is stored in an Amazon S3 bucket. The code must be deployed as an AWS Lambda function across multiple accounts in the same AWS Region as the S3 bucket. An AWS CloudFormation template that runs for each account will deploy the Lambda function.\nWhat is the MOST secure way to allow CloudFormation to access the Lambda code in the S3 bucket?","answer_images":[],"isMC":true,"question_images":[],"question_id":59,"unix_timestamp":1669039560,"answer":"A","answers_community":["A (100%)"],"topic":"1","discussion":[{"content":"Selected Answer: A\nThe CloudFormation has a role that must be grant with access to the S3 bucket","timestamp":"1687978860.0","upvote_count":"1","comment_id":"937039","poster":"rcaliandro"},{"content":"Selected Answer: A\nA is correct","poster":"michele_scar","upvote_count":"2","timestamp":"1674740760.0","comment_id":"788771"},{"content":"A it is","comment_id":"777660","upvote_count":"1","timestamp":"1673874000.0","poster":"sichilam"},{"comment_id":"773840","upvote_count":"3","timestamp":"1673552460.0","content":"Selected Answer: A\nA * in a permission is a red flag","poster":"Dirisme"},{"poster":"michaldavid","upvote_count":"1","comment_id":"729925","timestamp":"1669698420.0","content":"Selected Answer: A\nAAAAAAAAAA"},{"upvote_count":"2","timestamp":"1669039560.0","comment_id":"723580","poster":"dark_cherrymon","content":"Selected Answer: A\nprevious answer was A equalivent \n\nhttps://www.examtopics.com/discussions/amazon/view/51575-exam-aws-certified-developer-associate-topic-1-question-360/"}],"answer_ET":"A","answer_description":""},{"id":"fJGeig6wSmAR1sIX9JVg","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/88208-exam-aws-certified-developer-associate-topic-1-question-152/","answer_ET":"B","question_images":[],"answer":"B","answer_images":[],"answers_community":["B (93%)","7%"],"question_id":60,"unix_timestamp":1669039980,"timestamp":"2022-11-21 15:13:00","choices":{"A":"Create a beta stage for the new version of the API. Send the updated endpoint to the users.","D":"Create a deployment stage. Enable mutual TLS for the new version of the API.","B":"Create a development stage for the new version of the API. Use a canary deployment.","C":"Create a development stage for the new version of the API. Promote a canary release."},"topic":"1","question_text":"A company is migrating a legacy application to a serverless application on AWS. The legacy application consists of a set of web services that are exposed by an Amazon API Gateway API. A developer needs to replace the existing implementation of web services with AWS Lambda functions. The developer needs to test a new version of the API that uses the functions in production. The developer must minimize the impact of the testing on the application's users.\n\nWhich solution will meet these requirements?","exam_id":25,"discussion":[{"timestamp":"1670005860.0","upvote_count":"5","poster":"gpit","comment_id":"733984","content":"Selected Answer: B\nB is the sure safer way, because it is under your control, not your clients'."},{"comment_id":"1001229","content":"whats the difference with canary release and deplyment? C cant be the answer?","timestamp":"1694067720.0","comments":[{"content":"Promoting canary release means testing has ended, new version is available to 100% of the users","comment_id":"1095784","timestamp":"1702498200.0","upvote_count":"3","poster":"xdkonorek2"}],"poster":"bearminwoo","upvote_count":"3"},{"content":"Selected Answer: B\nB is correct \"Create a development stage for the new version of the API. Use a canary deployment\"","poster":"rcaliandro","comment_id":"937042","timestamp":"1687979040.0","upvote_count":"1"},{"upvote_count":"2","comment_id":"815621","content":"Selected Answer: B\nIt is B for sure - Canary deployment. The question is asking for a solution that will have the minimum impact on users. For those who think A is correct, why would you send your beta version to the users? And if you do, what sort of an impact would it have on the users if something is wrong with the beta version?","poster":"pancman","timestamp":"1676915520.0"},{"content":"I vote for A because we need to test first before talking to deployment!","timestamp":"1673874720.0","poster":"sichilam","upvote_count":"1","comment_id":"777669"},{"timestamp":"1672531380.0","content":"I guess it wasn't clear what \"testing\" mean here. Testing post production go live? Or testing your newly minted code in prod env.","upvote_count":"3","comment_id":"762985","poster":"tieyua"},{"comment_id":"742387","upvote_count":"2","poster":"xicomynor","timestamp":"1670817900.0","content":"I choose A. I understand this as the developer being the one that is testing, not involing production users yet. By using B a production user could find any error or similar, but with A only the ones testing with specific endpoint would be prone to errors and once it's tested by developer B can be used."},{"upvote_count":"4","timestamp":"1670043540.0","comment_id":"734213","poster":"SBoksh","content":"Selected Answer: B\nno need to involve user or depend on them for testing"},{"poster":"gpit","comment_id":"733987","upvote_count":"2","timestamp":"1670006100.0","content":"BTW, D, mTLS, is for two way certification, an authentication way, not for deployment."},{"comment_id":"728048","timestamp":"1669538280.0","upvote_count":"2","content":"Selected Answer: B\nbbbbbbb","poster":"saysamsuf"},{"content":"l choose B. \nI dont think it it’s A, because it mentions least impact for the application user, and providing an updated endpoint to your users in production will be a huge disruption. Creating a development stage, and using canary approach sounds more feasible, according to the doc.\n\nReference: https://docs.aws.amazon.com/apigateway/latest/developerguide/canary-release.html","poster":"CloudHandsOn","upvote_count":"4","timestamp":"1669287060.0","comment_id":"725752"},{"poster":"kapil206001","comment_id":"725146","content":"I choose B \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/canary-release.html#api-gateway-canary-release-deployment-overview","timestamp":"1669209420.0","upvote_count":"2"},{"poster":"dark_cherrymon","upvote_count":"1","timestamp":"1669039980.0","comments":[{"timestamp":"1674740940.0","content":"You have reason about the minimal impact but if the User application is on Mobile, you can't distribute a new test endpoint to these user to test. Should be boring for common users.\nSo it's B","upvote_count":"1","comment_id":"788774","poster":"michele_scar"}],"content":"Selected Answer: A\nA because\n\ni don't think it's b or c because your not doing an upgrade, and also elimanted D because i see no mention of security","comment_id":"723584"}],"isMC":true}],"exam":{"lastUpdated":"11 Apr 2025","isMCOnly":true,"provider":"Amazon","numberOfQuestions":443,"isBeta":false,"isImplemented":true,"id":25,"name":"AWS Certified Developer Associate"},"currentPage":12},"__N_SSP":true}