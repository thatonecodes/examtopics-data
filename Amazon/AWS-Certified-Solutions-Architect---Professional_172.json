{"pageProps":{"questions":[{"id":"FrE7sfundgpYReiDynxH","isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/74189-exam-aws-certified-solutions-architect-professional-topic-1/","answer":"C","discussion":[{"content":"Selected Answer: C\nC - NLB does not support MQTT protocol \nKinese streams support it. \nhttps://docs.aws.amazon.com/iot/latest/developerguide/kinesis-rule-action.html","upvote_count":"8","comment_id":"593316","poster":"snakecharmer2","comments":[{"upvote_count":"4","poster":"pinhead900","content":"how can this be highly voted? MQTT is application layer and can work over TCP and UDP\nhttps://en.wikipedia.org/wiki/MQTT\nDon't take highly voted answers for granted, must be B","comment_id":"676876","timestamp":"1663918140.0"},{"upvote_count":"5","comment_id":"602179","content":"NLB works on 4th level of OSI. \nMQTT work over TCP.\nHence NLB are not aware of what a TCP package contains.","timestamp":"1652630700.0","poster":"bobsmith2000"}],"timestamp":"1651079880.0"},{"upvote_count":"6","poster":"dcdcdc3","content":"Selected Answer: C\nBecause MSK has Maximum number of client connections 1000 per second and the company has 10,000 sensors, the MSK likely will not be able to handle all connections, so have to select C as the answer\n\nhttps://docs.aws.amazon.com/msk/latest/developerguide/limits.html","timestamp":"1665019740.0","comment_id":"687371"},{"comment_id":"791189","upvote_count":"1","timestamp":"1674947820.0","poster":"Heer","content":"Those who have selected option B ,Please note that \"While Amazon MSK itself does not have built-in ETL (Extract, Transform, Load) capabilities, it can be used in conjunction with other AWS services to build an ETL pipeline.\"\n\nThere are 3 ask in the question :\n1)Pull the sensor data using MQTT->IOT Core has the capabilities to connect to MQTT\n2)ETL the data ->We can direct send data from IOT Core to Lambda too but for large scale data Kinesis Data Firehouse is being used .And Firehouse use Lambda for ETL .\n3)Send the data to destination which is S3 . Lambda can do that easily .\nOPTION C is the right answer"},{"upvote_count":"1","poster":"mrgreatness","comment_id":"715570","timestamp":"1668115200.0","content":"C for me"},{"content":"C for me: \nhttps://docs.aws.amazon.com/iot/latest/developerguide/mqtt.html","upvote_count":"2","timestamp":"1666357080.0","comment_id":"700906","poster":"Blair77"},{"timestamp":"1665019320.0","upvote_count":"3","comment_id":"687370","poster":"dcdcdc3","content":"B is possible (4th diagram, PrivateLink, using one or more NLB for MSK) :\nhttps://aws.amazon.com/blogs/big-data/secure-connectivity-patterns-to-access-amazon-msk-across-aws-regions/\n\nSimplest design - IoT Core can send to MSK but there is no such option in the answers:\nhttps://aws.amazon.com/blogs/iot/how-to-integrate-aws-iot-core-with-amazon-msk/\n\nC is well described here:\nhttps://medium.com/swlh/create-kinesis-firehose-data-stream-from-iot-core-to-s3-using-serverless-framework-2af1d0b35500\n\nboth B and C are correct. Both are highly available, both not optimal..\n\nMaybe if the on-prem Kafka cluster is only storing transformed data in S3, then really Kafka is not needed and firehose is sufficient? \nThen C would be the answer"},{"timestamp":"1664853540.0","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/iot/latest/developerguide/mqtt.html","upvote_count":"2","comments":[{"upvote_count":"2","content":"Relooking at all the details, it makes more sense for this to be B.","timestamp":"1664854680.0","poster":"sb333","comment_id":"685902"}],"poster":"sb333","comment_id":"685894"},{"poster":"JohnPi","timestamp":"1664694840.0","content":"Selected Answer: C\nhttps://aws.amazon.com/iot-core/","upvote_count":"1","comment_id":"684658"},{"poster":"tarisai","content":"Selected Answer: B\nhttps://www.aklivity.io/products/private-msk-proxy","upvote_count":"3","comment_id":"653498","timestamp":"1661778120.0"},{"content":"I think its B because NLB support MQTT protocol\nhttps://www.emqx.com/en/blog/mqtt-broker-clustering-part-1-load-balancing\nhttp://kth.diva-portal.org/smash/get/diva2:1466268/FULLTEXT01.pdf","poster":"user89","timestamp":"1653664620.0","comment_id":"608132","upvote_count":"5"},{"poster":"shailurtm2001","comments":[{"poster":"user0001","comment_id":"599793","comments":[{"comment_id":"610953","content":"Because of \"a solutions architect must establish a new architecture on AWS that is highly available and scalable\"\nFollowing best practices and well-architected framework, when you migrate to cloud, you'd better rearchitect the app to benefit from the cloud managed services and optimise costs","upvote_count":"3","poster":"bobsmith2000","timestamp":"1654236360.0"}],"content":"true, why do we want to change the code?","timestamp":"1652225460.0","upvote_count":"2"}],"comment_id":"590320","upvote_count":"4","timestamp":"1650677940.0","content":"B seems right."}],"choices":{"D":"Deploy AWS IoT Core, and launch an Amazon EC2 instance to host the Kafka server. Configure AWS IoT Core to send the data to the EC2 instance. Route the sensors to send the data to AWS IoT Core.","C":"Deploy AWS IoT Core, and connect it to an Amazon Kinesis Data Firehose delivery stream. Use an AWS Lambda function to handle data transformation. Route the sensors to send the data to AWS IoT Core.","A":"Launch two Amazon EC2 instances to host the Kafka server in an active/standby configuration across two Availability Zones. Create a domain name in Amazon Route 53. Create a Route 53 failover policy. Route the sensors to send the data to the domain name.","B":"Migrate the on-premises Kafka server to Amazon Managed Streaming for Apache Kafka (Amazon MSK). Create a Network Load Balancer (NLB) that points to the Amazon MSK broker. Enable NLB health checks. Route the sensors to send the data to the NLB."},"timestamp":"2022-04-23 03:39:00","question_text":"A company has more than 10,000 sensors that send data to an on-premises Apache Kafka server by using the Message Queuing Telemetry Transport (MQTT) protocol. The on-premises Kafka server transforms the data and then stores the results as objects in an Amazon S3 bucket.\nRecently, the Kafka server crashed. The company lost sensor data while the server was being restored. A solutions architect must create a new design on AWS that is highly available and scalable to prevent a similar occurrence.\nWhich solution will meet these requirements?","answers_community":["C (85%)","B (15%)"],"answer_description":"","exam_id":32,"question_id":856,"question_images":[],"answer_ET":"C","answer_images":[],"unix_timestamp":1650677940},{"id":"GZjpDV1hn6KxuVMdMAql","answer_ET":"A","unix_timestamp":1650630360,"question_images":["https://www.examtopics.com/assets/media/exam-media/04241/0056200001.png"],"answers_community":["A (100%)"],"discussion":[{"comment_id":"1264713","poster":"devilman222","content":"Selected Answer: A\nObviously A. Since the correct answer is usually wrong, can they just get rid of that and use most voted.","upvote_count":"1","timestamp":"1723478460.0"},{"content":"Selected Answer: A\nSSE-KMS (with a customer managed key) â€“ To upload objects, the kms:GenerateDataKey permission on the AWS KMS key is required.","comment_id":"990115","upvote_count":"1","timestamp":"1692970020.0","poster":"Simon523"},{"poster":"AwsBRFan","content":"Selected Answer: A\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-access-denied-error-kms/\n \"An error occurred (AccessDenied) when calling the PutObject operation: Access Denied\"\n\nThis error message indicates that your IAM user or role needs permission for the kms:GenerateDataKey action.","timestamp":"1665925860.0","comment_id":"696251","upvote_count":"1"},{"upvote_count":"2","timestamp":"1658623080.0","comment_id":"635820","poster":"hilft","content":"A.\nkms:GenerateDataKey"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingClientSideEncryption.html","timestamp":"1657633620.0","poster":"Millari","upvote_count":"1","comment_id":"630563"},{"upvote_count":"2","timestamp":"1656823380.0","content":"Selected Answer: A\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-access-denied-error-kms/","comment_id":"626408","poster":"aandc"},{"comment_id":"590816","poster":"Bigbearcn","upvote_count":"1","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/kms/latest/cryptographic-details/client-side-encryption.html","timestamp":"1650751680.0"},{"content":"Selected Answer: A\nCorrect answer should be A\nkms:GenerateDataKey","upvote_count":"2","poster":"mirnuj_atom","comment_id":"589980","timestamp":"1650630360.0"}],"topic":"1","question_id":857,"answer":"A","isMC":true,"exam_id":32,"choices":{"A":"kms:GenerateDataKey","B":"kms:GetKeyPolicy","D":"kms:Sign","C":"kms:GetPublicKey"},"answer_images":[],"answer_description":"","question_text":"A solutions architect needs to implement a client-side encryption mechanism for objects that will be stored in a new Amazon S3 bucket. The solutions architect created a CMK that is stored in AWS Key Management Service (AWS KMS) for this purpose.\nThe solutions architect created the following IAM policy and attached it to an IAM role:\n//IMG//\n\nDuring tests, the solutions architect was able to successfully get existing test objects in the S3 bucket. However, attempts to upload a new object resulted in an error message. The error message stated that the action was forbidden.\nWhich action must the solutions architect add to the IAM policy to meet all the requirements?","timestamp":"2022-04-22 14:26:00","url":"https://www.examtopics.com/discussions/amazon/view/74131-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"RKg5qL4HVmR3ZyrUX180","question_images":[],"unix_timestamp":1661915100,"answers_community":["CD (100%)"],"answer":"CD","question_text":"A retail company needs to provide a series of data files to another company, which is its business partner. These files are saved in an Amazon S3 bucket under\nAccount A, which belongs to the retail company. The business partner company wants one of its IAM users, User_DataProcessor, to access the files from its own\nAWS account (Account B).\nWhich combination of steps must the companies take so that User_DataProcessor can access the S3 bucket successfully? (Choose two.)","answer_images":[],"answer_description":"","discussion":[{"comment_id":"656732","timestamp":"1662075840.0","poster":"RVD","upvote_count":"6","content":"Selected Answer: CD\nCD-AccountA allow access via s3 bucket policy and in Account B allow s3 processor to access S3"},{"comment_id":"716108","poster":"due","content":"Selected Answer: CD\nAcc A (S3 owner) S3 bucket policy allow with Principal \"User_DataProcessor\" + Acc B (user) IAM policy allow all","upvote_count":"1","timestamp":"1668175680.0"},{"poster":"bloless1s","content":"Selected Answer: CD\nMust be C,D. Detail explained here: https://aws.amazon.com/premiumsupport/knowledge-center/cross-account-access-s3/","timestamp":"1666081500.0","upvote_count":"4","comment_id":"698038"},{"poster":"Rocketeer","timestamp":"1662031920.0","content":"I am thinking CD","comment_id":"656189","upvote_count":"1"}],"answer_ET":"CD","timestamp":"2022-08-31 05:05:00","question_id":858,"isMC":true,"topic":"1","choices":{"E":"InAccount B, set the permissions of User_DataProcessor to the following:","B":"InAccountA, set the S3 bucket policy to the following:","D":"InAccount B, set the permissions of User_DataProcessor to the following:","C":"InAccount A, set the S3 bucket policy to the following:","A":"Turn on the cross-origin resource sharing (CORS) feature for the S3 bucket in Account A."},"exam_id":32,"url":"https://www.examtopics.com/discussions/amazon/view/78586-exam-aws-certified-solutions-architect-professional-topic-1/"},{"id":"RgTvQz3LzeRXMWNi5e8E","discussion":[{"upvote_count":"10","poster":"Bigbearcn","comment_id":"590806","timestamp":"1650749160.0","content":"Selected Answer: BD\nIt's B and D."},{"content":"Selected Answer: BD\nB & D\nYou want to share the subnets using RAM (D) and you need to enable it first (B)","poster":"snakecharmer2","upvote_count":"7","timestamp":"1650463200.0","comment_id":"588783"},{"comment_id":"1210388","timestamp":"1715546760.0","poster":"onepunchfinish","upvote_count":"1","content":"Choose BD\n\nSharing at the subnet level will allow the operations account to share specific subnets with other AWS accounts in the organization. By using AWS Resource Access Manager, the operations team can maintain centralised control over network resources while enabling individual accounts to deploy AWS resources within the shared subnets"},{"comment_id":"1043912","upvote_count":"1","timestamp":"1697352120.0","content":"Selected Answer: BE\nkey word: Individual accounts cannot have the ability to manage their own networks. that means the individual accounts do not have their own subnet and rely on the resource sharing to provide subnet. prefix list is the way to go","poster":"DavidC"},{"comment_id":"590362","timestamp":"1650682200.0","upvote_count":"2","content":"BE https://docs.aws.amazon.com/vpc/latest/userguide/sharing-managed-prefix-lists.html","poster":"shailurtm2001"},{"timestamp":"1650628560.0","upvote_count":"3","poster":"mirnuj_atom","comment_id":"589958","content":"B/D, the prefix-list has nothing to do with the subnet sharing."}],"url":"https://www.examtopics.com/discussions/amazon/view/73910-exam-aws-certified-solutions-architect-professional-topic-1/","question_id":859,"unix_timestamp":1650463200,"answer_ET":"BD","answer_images":[],"topic":"1","choices":{"C":"Create VPCs in each AWS account within the organization in AWS Organizations. Configure the VPCs to share the same CIDR range and subnets as the VPC in the infrastructure account. Peer the VPCs in each individual account with the VPC in the infrastructure account.","E":"Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each prefix list to associate with the resource share.","D":"Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each subnet to associate with the resource share.","B":"Enable resource sharing from the AWS Organizations management account.","A":"Create a transit gateway in the infrastructure account."},"answer_description":"","question_text":"A company has many AWS accounts and uses AWS Organizations to manage all of them. A solutions architect must implement a solution that the company can use to share a common network across multiple accounts.\nThe company's infrastructure team has a dedicated infrastructure account that has a VPC. The infrastructure team must use this account to manage the network.\nIndividual accounts cannot have the ability to manage their own networks. However, individual accounts must be able to create AWS resources within subnets.\nWhich combination of actions should the solutions architect perform to meet these requirements? (Choose two.)","isMC":true,"timestamp":"2022-04-20 16:00:00","answer":"BD","exam_id":32,"question_images":[],"answers_community":["BD (94%)","6%"]},{"id":"FNxyxNUrFdfkTHDP26pQ","choices":{"D":"Use only custom rule groups in the web ACLs, and set the action to Allow. Enable AWS WAF logging. Analyze the requests for false positives. Modify the rules to avoid any false positive. Over time, change the action of the web ACL rules from Allow to Block.","B":"Use only rate-based rules in the web ACLs, and set the throttle limit as high as possible. Temporarily block all requests that exceed the limit. Define nested rules to narrow the scope of the rate tracking.","A":"Set the action of the web ACL rules to Count. Enable AWS WAF logging. Analyze the requests for false positives. Modify the rules to avoid any false positive. Over time, change the action of the web ACL rules from Count to Block.","C":"Set the action of the web ACL rules to Block. Use only AWS managed rule groups in the web ACLs. Evaluate the rule groups by using Amazon CloudWatch metrics with AWS WAF sampled requests or AWS WAF logs."},"answer":"A","answer_ET":"A","exam_id":32,"unix_timestamp":1650748440,"discussion":[{"poster":"Bigbearcn","upvote_count":"12","content":"Selected Answer: A\nIt's A. in case of affect legimate traffic, set the action to count first.","comment_id":"590805","timestamp":"1650748440.0"},{"content":"Selected Answer: A\nhttps://aws.amazon.com/premiumsupport/knowledge-center/waf-analyze-count-action-rules/","upvote_count":"2","poster":"sb333","comment_id":"685854","timestamp":"1664845620.0"},{"comment_id":"638206","content":"Agree with Bigbearcn.\nA","timestamp":"1658938740.0","poster":"hilft","upvote_count":"1"}],"url":"https://www.examtopics.com/discussions/amazon/view/74273-exam-aws-certified-solutions-architect-professional-topic-1/","question_id":860,"question_images":[],"answer_images":[],"answer_description":"","isMC":true,"answers_community":["A (100%)"],"topic":"1","question_text":"A company has developed a web application. The company is hosting the application on a group of Amazon EC2 instances behind an Application Load Balancer.\nThe company wants to improve the security posture of the application and plans to use AWS WAF web ACLs. The solution must not adversely affect legitimate traffic to the application.\nHow should a solutions architect configure the web ACLs to meet these requirements?","timestamp":"2022-04-23 23:14:00"}],"exam":{"numberOfQuestions":1019,"name":"AWS Certified Solutions Architect - Professional","provider":"Amazon","isImplemented":true,"lastUpdated":"11 Apr 2025","isBeta":false,"isMCOnly":false,"id":32},"currentPage":172},"__N_SSP":true}