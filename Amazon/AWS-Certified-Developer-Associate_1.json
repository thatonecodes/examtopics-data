{"pageProps":{"questions":[{"id":"VzscqY2AmUG8y1HbcLeK","timestamp":"2022-08-31 02:09:00","isMC":true,"discussion":[{"content":"I think is C\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html","timestamp":"1661904540.0","poster":"nsasomsub","comments":[{"poster":"Spamuel","content":"agreed","timestamp":"1661952660.0","upvote_count":"4","comment_id":"655117"}],"comment_id":"654550","upvote_count":"21"},{"content":"Selected Answer: D\nAnswer seems to be D. Earlier I too thought of C as dynamoDB has transactions api but they take more WCU and RCU. I searched and found a article which suggests that for gamers Aurora MySQL is the preference. Please refer below link: https://aws.amazon.com/blogs/database/level-up-your-games-with-amazon-aurora/","upvote_count":"11","timestamp":"1669703460.0","poster":"AWS_Shubham","comments":[{"timestamp":"1674083640.0","comment_id":"780518","upvote_count":"5","content":"But transaction databases are not recommended for complex items such as game items. In this case, it might store objects.","poster":"Phinx"}],"comment_id":"730018"},{"timestamp":"1736160840.0","poster":"Hasitha99","comment_id":"1337081","upvote_count":"1","content":"Selected Answer: C\nOnly possible answers are C or D. But looking at answers and latest updates, answer \"C\" seems most suitable bacause dynamodb support single all-or-nothing TransactWriteItems or TransactGetItems operations and its key valaue nature support high performance."},{"poster":"sumanshu","comments":[{"upvote_count":"2","timestamp":"1733825280.0","poster":"sumanshu","comments":[{"comment_id":"1324483","poster":"sumanshu","timestamp":"1733825280.0","content":"D) Aurora also supports ACID transactions, which means you can perform multiple updates in a transaction block, and if one fails, it will roll back. However, the gaming use case here focuses on trading game items—a relatively straightforward workload that doesn’t necessarily need relational database capabilities. Gaming platforms generally prefer NO-SQL database for flexibility. - (So, C can given more preference than option D)","upvote_count":"1"}],"content":"C) Though DynamoDB is No-SQL Database, but it has transactional capabilities i.e. ACID properties (Atomicity, Consistency, Isolation, Durability). Atomicity means - All operations succeed or fail together. Also, DynamoDB provides two powerful API for transactions \n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html\n\nTransactWriteItems or TransactGetItems. - (i.e. we can group multiple actions together and submit them as single all or nothing) - So, C can be the answer","comment_id":"1324482"}],"upvote_count":"2","content":"Selected Answer: C\nA) DynamoDB Consistent Read: ensures strong consistent reads. But question is asking for Updates (i.e. Writes Operation) - Eliminated\nB) ElastiCache for Memcached: Is in memory key-value store, So not suitable for storing or transactions operations. - Eliminated\nE) Amazon Athena: is query service for analyzing data in S3 using SQL.- Eliminated","timestamp":"1733825280.0","comment_id":"1324481"},{"upvote_count":"2","content":"Selected Answer: C\nDynamoDB has the capability to perform Transactional queries ( all succeed or rollback everything )","timestamp":"1707895740.0","comment_id":"1149912","poster":"Baalhammun"},{"timestamp":"1705267380.0","upvote_count":"1","comment_id":"1122866","content":"I think so C DynamoDB provide to perform multiple write operations (e.g., updates, inserts, deletes) and read operations within a single transaction.","poster":"AsmaZoheb"},{"timestamp":"1701859860.0","comment_id":"1089211","content":"Which answer should we consider as correct? Option with most voted or one mentioned in revel answer? Please help me as I am preparing for exam","upvote_count":"2","poster":"Vpss4"},{"upvote_count":"1","poster":"xdkonorek2","timestamp":"1701714360.0","comment_id":"1087846","content":"Selected Answer: C\nboth C and D are valid"},{"timestamp":"1700196060.0","upvote_count":"1","content":"Please tell me are the answers suggested here correct answer otherwise why do we have all this variations with an answer and what is voted as the anser","comment_id":"1073028","poster":"Orit"},{"poster":"bojila","timestamp":"1698688980.0","content":"What is the difference between current dump and this one? https://www.examtopics.com/exams/amazon/aws-certified-developer-associate-dva-c02/","comment_id":"1058143","upvote_count":"2"},{"content":"Selected Answer: C\nAmazon DynamoDB provides support for ACID (Atomicity, Consistency, Isolation, Durability) transactions through its TransactWriteItems and TransactGetItems operations. With these operations, you can group multiple write operations and/or read operations into a single transaction. If any part of the transaction fails, all changes are rolled back, ensuring data consistency.","timestamp":"1693197240.0","poster":"Chinnu_37","upvote_count":"3","comment_id":"991793"},{"poster":"qich1989","content":"Selected Answer: D\nI think the answer is D. Because the question is to build a trade system for gaming, not build a game system.","timestamp":"1693131480.0","comment_id":"991383","upvote_count":"3"},{"comment_id":"973814","comments":[{"poster":"xdkonorek2","comment_id":"1087838","upvote_count":"1","timestamp":"1701714060.0","content":"Every relational database is transactional..."}],"content":"Selected Answer: C\nAmazon DynamoDB supports transactional operations using the TransactWriteItems and TransactGetItems operations. These operations allow you to group multiple write and read operations into a single, all-or-nothing transaction. If any of the operations in the transaction fail, the entire transaction will be rolled back, ensuring data consistency.\n\nOption D is wrong(Amazon Aurora MySQL with operations made within a transaction block) is a relational database and does support transactions, but it might be overkill for a gaming website's item trading feature, and the cost and complexity might be higher compared to DynamoDB.","poster":"lamokay","timestamp":"1691324760.0","upvote_count":"2"},{"timestamp":"1689175500.0","upvote_count":"2","poster":"Ssakshi0709","comment_id":"949937","content":"Selected Answer: C\nDynamo db is more flexible in this"},{"poster":"rcaliandro","content":"Selected Answer: C\nI vote for C, DynamoDB is more flexible and it supports transactions by using Transact*","comment_id":"935352","upvote_count":"1","timestamp":"1687869480.0"},{"content":"My first choice would have been DynamoDB, however, the question is asking about gamers that require rollback. Aurora can commit or \"roll back the current transaction\"; https://docs.aws.amazon.com/whitepapers/latest/amazon-aurora-mysql-db-admin-handbook/transaction-management-and-autocommit.html","upvote_count":"1","poster":"CarlosC","comment_id":"919322","timestamp":"1686314880.0"},{"timestamp":"1685300760.0","comment_id":"908833","content":"Selected Answer: C\nDefinitely C: https://aws.amazon.com/blogs/aws/new-amazon-dynamodb-transactions/","poster":"ezredame","upvote_count":"2"},{"timestamp":"1683713400.0","comment_id":"893808","upvote_count":"5","content":"I think that the answer is CD. First, there are 5 options, meaning the question probably has more than 1 correct answer. And 2nd both of the services support transactions","poster":"abalanag"},{"content":"Selected Answer: D\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html","timestamp":"1682569620.0","poster":"suru003","comment_id":"882221","comments":[{"timestamp":"1682569620.0","upvote_count":"1","poster":"suru003","content":"I wanted to add different link, please delete it.","comment_id":"882222"}],"upvote_count":"2"},{"comments":[{"upvote_count":"1","comment_id":"995796","poster":"ninomfr64","content":"\"If any update fails, the transaction must roll back\" -> ACID\nI think, the type of rollback mentioned in the blog post is the ability to rollback a transaction even if it completed. My 2 cents","timestamp":"1693553580.0"}],"timestamp":"1680252300.0","upvote_count":"3","poster":"shahs10","comment_id":"856818","content":"Selected Answer: D\nDynamoDB transact do not have rollback capability \nhttps://repost.aws/questions/QUb_YHhSanQjiWBsmRvj0mHQ/does-dynamodb-have-commit-and-rollback-transaction-http-ap-is"},{"upvote_count":"1","timestamp":"1678085580.0","poster":"santosh__1234","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html","comment_id":"830602"},{"poster":"ShriniW","content":"Selected Answer: C\nC is right","comment_id":"812832","timestamp":"1676713740.0","upvote_count":"1"},{"poster":"QueTeddyJR","comment_id":"811162","upvote_count":"2","content":"Selected Answer: C\nI think the answer is C because of the Context, most people know gaming industry deals with very high reads and write that require a db that should scale easily hence DynamoDB.","timestamp":"1676586180.0"},{"upvote_count":"3","content":"Answer is C, this blog explains same scenario. https://aws.amazon.com/blogs/aws/new-amazon-dynamodb-transactions/","poster":"tunjiaramide","comments":[{"timestamp":"1678733460.0","upvote_count":"1","content":"I was very convinced D was the answer but that link shows the answer is clearly C.","poster":"captainpike","comment_id":"838185"}],"comment_id":"806142","timestamp":"1676193660.0"},{"content":"Selected Answer: C\nIt should be C","upvote_count":"1","comment_id":"804740","poster":"Krt5894","timestamp":"1676060640.0"},{"poster":"michele_scar","timestamp":"1674206460.0","comment_id":"782047","upvote_count":"1","content":"Selected Answer: D\nFor me is D because \"gaming website\" is a distractor. Ok that is talking about game but is a simply website with commercial transaction, so is recommended SQL usage with the simply rollback() function in case of failure."},{"content":"Ans is C","poster":"rajeshperla","timestamp":"1674110460.0","upvote_count":"1","comment_id":"780803"},{"poster":"rathee15","timestamp":"1673765640.0","comment_id":"776217","upvote_count":"1","content":"Selected Answer: C\nTransact API from Dynamodb"},{"upvote_count":"2","timestamp":"1671869280.0","content":"D because Aurora has Automatic fail-over","comment_id":"754766","poster":"TheAloneShadow"},{"content":"Selected Answer: C\nAnswer is C","upvote_count":"1","timestamp":"1671333600.0","comment_id":"748581","poster":"mithunkundu1983"},{"poster":"nitinitare51","upvote_count":"4","timestamp":"1670130660.0","content":"Seems to be option C\nhttps://aws.amazon.com/blogs/database/amazon-dynamodb-gaming-use-cases-and-design-patterns/","comment_id":"734853"},{"upvote_count":"1","timestamp":"1665766560.0","poster":"sahil_chachere","content":"The answer is C for sure.","comment_id":"694916"},{"content":"I choise D\nbecause DynamoDB Transactions are not supported across regions in global tables","timestamp":"1665616920.0","comments":[{"comments":[{"upvote_count":"1","timestamp":"1680252360.0","comment_id":"856819","poster":"shahs10","comments":[{"content":"TransactWriteItems provides all-or-nothing operation which means it has built-in roll back","timestamp":"1695246480.0","poster":"alihaider907","upvote_count":"1","comment_id":"1012624"}],"content":"But dynamodb transact do not rollback"}],"content":"It's not a requirement to be supported across regions. Global Tables aren't required here. As long as they can get to the one region, DynamoDB Transactions work.","timestamp":"1665947580.0","poster":"Freddie26","comment_id":"696456","upvote_count":"1"}],"poster":"zzr2","upvote_count":"1","comment_id":"693443"},{"content":"Answer is C","comment_id":"691220","timestamp":"1665409920.0","upvote_count":"1","poster":"scomperleur"},{"poster":"technicalworm","content":"Selected Answer: C\nit must be C","comment_id":"690152","upvote_count":"1","timestamp":"1665317580.0"},{"content":"Selected Answer: C\nAnswer is C","timestamp":"1664919000.0","poster":"bilel500","comment_id":"686441","upvote_count":"1"},{"poster":"JeffreyQ","upvote_count":"1","content":"Selected Answer: C\nC looks more correct","timestamp":"1662996840.0","comment_id":"667167"},{"comment_id":"664929","upvote_count":"1","content":"Selected Answer: C\nC and D are both correct","poster":"zads","timestamp":"1662755460.0"},{"poster":"sindra","timestamp":"1661979960.0","upvote_count":"5","comment_id":"655489","content":"Selected Answer: C\nI think the answer is C,\nit still like C and D is fit with the answer, but from game perspective usually it recommended to use DynamoDB"}],"question_text":"A gaming website gives users the ability to trade game items with each other on the platform. The platform requires both users' records to be updated and persisted in one transaction. If any update fails, the transaction must roll back.\nWhich AWS solution can provide the transactional capability that is required for this feature?","exam_id":25,"topic":"1","answer_images":[],"unix_timestamp":1661904540,"answer_ET":"C","question_images":[],"answers_community":["C (62%)","D (38%)"],"choices":{"B":"Amazon ElastiCache for Memcached with operations made within a transaction block","C":"Amazon DynamoDB with reads and writes made by using Transact* operations","D":"Amazon Aurora MySQL with operations made within a transaction block","E":"Amazon Athena with operations made within a transaction block","A":"Amazon DynamoDB with operations made with the Consistent Read parameter set to true"},"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/78546-exam-aws-certified-developer-associate-topic-1-question-1/","question_id":1,"answer":"C"},{"id":"YXXZseVeFMi8yQ8FI2HM","question_id":2,"answer":"AC","choices":{"D":"Create Amazon CloudWatch alarms based on expected values of selected CloudWatch metrics to detect anomalies and errors.","E":"Design an Amazon CloudWatch dashboard of the selected CloudFront distribution metrics.","B":"Export the CloudFront logs to an Amazon S3 bucket. Detect anomalies and error rates with Amazon QuickSight.","A":"Activate real-time logs on the CloudFront distribution. Create a stream in Amazon Kinesis Data Streams.","C":"Configure Amazon Kinesis Data Streams to deliver logs to Amazon OpenSearch Service (Amazon Elasticsearch Service). Create a dashboard in OpenSearch Dashboards (Kibana)."},"answer_description":"","discussion":[{"comments":[{"upvote_count":"1","timestamp":"1663676040.0","comment_id":"674123","comments":[{"timestamp":"1666135680.0","upvote_count":"2","comments":[{"poster":"ninomfr64","upvote_count":"1","timestamp":"1692684660.0","content":"I would also go for A and C, however wording in C is misleading as it let me think KDS is delivering log directly OpenSearch while as you suggest KDS messages are picked by a Lambda that actually delivers them to OpenSearch","comment_id":"987132"}],"poster":"nothankyouspankyou","content":"Its possible:\nhttps://docs.aws.amazon.com/opensearch-service/latest/developerguide/integrations.html#integrations-kinesis","comment_id":"698553"}],"content":"IS Kinesis Data Streams to deliver logs to Amazon OpenSearch Service? NO ofc it is Firehose","poster":"Musafaynou"}],"comment_id":"658559","timestamp":"1662214500.0","upvote_count":"11","content":"A and C is correct to me: https://aws.amazon.com/blogs/networking-and-content-delivery/cloudfront-realtime-logs/\n\nIt mentions shortest possible refresh interval so best to use the real-time logs","poster":"JOL86"},{"comment_id":"659287","content":"A and C","upvote_count":"5","poster":"datamech001","timestamp":"1662295920.0"},{"timestamp":"1734197400.0","content":"Selected Answer: AC\nB) Eliminated - While exporting CloudFront logs to S3 and analyzing them with Amazon QuickSight is possible, this approach has a much longer delay because CloudFront access logs (standard logs) are delivered to S3 in batches, typically delayed by minutes or more. This is not suitable for real-time monitoring or detecting anomalies quickly","comment_id":"1326555","upvote_count":"1","poster":"sumanshu","comments":[{"content":"D) Eliminated: CloudWatch Alarms are used for triggering notifications (e.g., SMS, email) when metrics exceed thresholds, not for creating a real-time monitoring dashboard.","poster":"sumanshu","comment_id":"1326556","timestamp":"1734197520.0","comments":[{"comment_id":"1326557","upvote_count":"1","comments":[{"content":"A & C - Correct\n\nA (Real-time logs with Kinesis) and C (Kinesis + OpenSearch)","upvote_count":"1","poster":"sumanshu","timestamp":"1734197700.0","comment_id":"1326558"}],"content":"E) - Option E is valid but doesn't fully meet the requirement. Metrics alone cannot give detailed insights into every request/response for debugging errors.","timestamp":"1734197640.0","poster":"sumanshu"}],"upvote_count":"1"}]},{"content":"DE i think so for dashboard we create in CloudWatch","upvote_count":"1","timestamp":"1705270020.0","poster":"AsmaZoheb","comment_id":"1122903"},{"poster":"rjdio1981","content":"what's the difference between this and the dva-c02 listing on this page?","comment_id":"994618","timestamp":"1693443120.0","upvote_count":"1"},{"timestamp":"1687876020.0","upvote_count":"1","content":"Selected Answer: AC\nI agree with you guys, I'll go for AC.\nFirst of all we need to send the cloud formation logs to a new Kinesis data stream by choosing the right partition key and shards number. Then, I think that this part is missing, we should use Kinesis Firehose before delivering to Elasticsearch. Once the data is managed by Elasticsearch, we can create the final dashboard with Kibana near realtime","poster":"rcaliandro","comment_id":"935475"},{"content":"Selected Answer: AC\ni think is AC","poster":"LeoUrlian","comment_id":"866546","timestamp":"1681152300.0","upvote_count":"1"},{"poster":"Krt5894","content":"Selected Answer: AC\nA and C","comment_id":"804751","timestamp":"1676060820.0","upvote_count":"1"},{"timestamp":"1674208920.0","poster":"michele_scar","upvote_count":"1","content":"Selected Answer: CE\nWith C and E you should aggregate and SHOW the metrics.","comment_id":"782082"},{"poster":"Dirisme","upvote_count":"3","content":"Selected Answer: AC\nreal time and dashboard keywords requires kinesis data stream","timestamp":"1672977480.0","comment_id":"767250"},{"poster":"Agil09","timestamp":"1671553860.0","content":"Selected Answer: AC\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/cloudfront-realtime-logs/\nWith real-time logs, you can customize the information collected and where it gets delivered. The real-time logs are integrated with Amazon Kinesis Data Streams to enable delivery of these logs to a generic HTTP endpoint using Amazon Kinesis Data Firehose. Amazon Kinesis Data Firehose can deliver logs to Amazon S3, Amazon Redshift, Amazon Elasticsearch Service (Amazon ES), and service providers like Datadog, Datazoom, New Relic, and Splunk. Using these logs, you can create real-time dashboards, set up alerts, and investigate anomalies or respond to operational events quickly.","upvote_count":"4","comment_id":"751196"},{"content":"Selected Answer: AC\nA and C","timestamp":"1664138040.0","comment_id":"679212","upvote_count":"1","poster":"tfer"},{"content":"Selected Answer: AC\nAC seems right","timestamp":"1662282780.0","upvote_count":"4","comment_id":"659136","poster":"Danbraga"},{"content":"Selected Answer: DE\nDE for me. https://aws.amazon.com/it/blogs/mt/sending-cloudfront-standard-logs-to-cloudwatch-logs-for-analysis/","poster":"sidvic","comment_id":"658132","comments":[{"comments":[{"timestamp":"1662616080.0","content":"you're right","upvote_count":"4","poster":"sidvic","comment_id":"663175"}],"content":"key phrase on this question is \"shortest possible refresh interval\". That would be AC","upvote_count":"3","poster":"Danbraga","comment_id":"662376","timestamp":"1662548460.0"}],"upvote_count":"3","timestamp":"1662187140.0"}],"answer_ET":"AC","exam_id":25,"topic":"1","isMC":true,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/79694-exam-aws-certified-developer-associate-topic-1-question-10/","timestamp":"2022-09-03 08:39:00","unix_timestamp":1662187140,"answers_community":["AC (80%)","DE (15%)","5%"],"question_images":[],"question_text":"A company hosts a three-tier web application on AWS behind an Amazon CloudFront distribution. A developer wants a dashboard to monitor error rates and anomalies of the CloudFront distribution with the shortest possible refresh interval.\nWhich combination of slops should the developer take to meet these requirements? (Choose two.)"},{"id":"cgKLlGd9neEjA6yZb7uh","answer_ET":"B","answer_description":"","isMC":true,"answers_community":["B (100%)"],"topic":"1","unix_timestamp":1662196920,"url":"https://www.examtopics.com/discussions/amazon/view/79731-exam-aws-certified-developer-associate-topic-1-question-100/","exam_id":25,"answer_images":[],"question_id":3,"answer":"B","choices":{"A":"Perform a DynamoDB Query operation with the Id. If the price is >= 600, perform an UpdateItem operation to update the price.","B":"Perform a DynamoDB UpdateItem operation with a condition expression of \"Price >= 600\".","C":"Perform a DynamoDB UpdateItem operation with a condition expression of \"ProductCategory IN ({\"S\": \"Sporting Goods\"}) and Price 600\".","D":"Perform a DynamoDB UpdateItem operation with a condition expression of \"MIN Price = 500\"."},"timestamp":"2022-09-03 11:22:00","discussion":[{"poster":"JonasKahnwald","timestamp":"1734870900.0","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html#Expressions.ConditionExpressions.SimpleComparisons","comment_id":"1330379","upvote_count":"1"},{"content":"Selected Answer: B\nDynamoDB will only execute the update when the price is at least 600.\nIt reduces the price by 100 in a single call.","comment_id":"1329041","upvote_count":"1","timestamp":"1734624000.0","poster":"sumanshu"},{"timestamp":"1687964580.0","content":"Selected Answer: B\nOf course B,we have to update the Price with the value (Price - 100) whenever price >= 600","upvote_count":"1","poster":"rcaliandro","comment_id":"936800"},{"upvote_count":"2","comment_id":"794935","timestamp":"1675239840.0","poster":"gaddour_med","content":"WHY consition is not Price >500 it can be 550","comments":[{"content":"Because you are checking the price BEFORE performing the update.","comment_id":"1311833","timestamp":"1731580200.0","upvote_count":"1","poster":"JonasKahnwald"}]},{"poster":"sichilam","upvote_count":"1","comment_id":"772454","content":"B is correct\naws dynamodb update-item \\\n --table-name ProductCatalog \\\n --key '{\"Id\": {\"N\": \"456\"}}' \\\n --update-expression \"SET Price = Price - :discount\" \\\n --condition-expression \"Price > :limit\" \\\n --expression-attribute-values file://values.json","timestamp":"1673438580.0"},{"upvote_count":"2","poster":"thensanity","content":"all - keyword, you do not need to specify which id needs to be updated","comment_id":"761595","timestamp":"1672363620.0"},{"comment_id":"731029","timestamp":"1669776060.0","upvote_count":"1","content":"Selected Answer: B\nIt'd be even better if B is in an index.","poster":"gpit"},{"content":"Selected Answer: B\nit's not A because you don't need to query by ID","timestamp":"1668746940.0","comment_id":"721066","upvote_count":"1","poster":"dark_cherrymon"},{"content":"Selected Answer: B\nB is answer","comment_id":"689408","timestamp":"1665238500.0","poster":"habros","upvote_count":"1"},{"comment_id":"686803","content":"Selected Answer: B\nB is the answer","timestamp":"1664968020.0","poster":"haazybanj","upvote_count":"1"},{"timestamp":"1662510420.0","poster":"szhang2004","comment_id":"661790","upvote_count":"1","content":"should be B"},{"comment_id":"659432","poster":"Vinafec","content":"Selected Answer: B\nEasy B","timestamp":"1662313560.0","upvote_count":"1"},{"upvote_count":"4","content":"Selected Answer: B\nI vote for B, acording to this doc:\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html","comment_id":"658277","poster":"Danbraga","timestamp":"1662196920.0"}],"question_text":"A company has an online order website that uses Amazon DynamoDB to store item inventory. A sample of the inventory object is as follows:\n//IMG//\n\nA developer needs to reduce all inventory prices by 100 as long as the resulting price would not be less than 500.\nWhat should the developer do to make this change with the LEAST number of calls to DynamoDB?","question_images":["https://www.examtopics.com/assets/media/exam-media/04238/0005200001.png"]},{"id":"NfeQzEnRm70rUmF5Ddq5","exam_id":25,"url":"https://www.examtopics.com/discussions/amazon/view/69125-exam-aws-certified-developer-associate-topic-1-question-101/","discussion":[{"comments":[{"timestamp":"1696092660.0","comment_id":"1021724","content":"Increase your stream's shard count\nA low number of shards in a stream increases a function's iterator age. Increasing the number of shards in a stream increases the number of concurrent Lambda functions consuming from your stream, which decreases a function's iterator age.","poster":"dimon_millioner","upvote_count":"1"},{"timestamp":"1665730740.0","poster":"Arnaud92","comment_id":"694561","upvote_count":"3","content":"true : « To increase the speed at which your function processes records, add shards to your data stream. Lambda processes records in each shard in order. It stops processing additional records in a shard if your function returns an error. With more shards, there are more batches being processed at once, which lowers the impact of errors on concurrency. »"}],"upvote_count":"16","timestamp":"1641074760.0","comment_id":"514712","content":"AC is correct. Visit the link in the solution\nhttps://aws.amazon.com/premiumsupport/knowledge-center/lambda-iterator-age/","poster":"CHRIS12722222"},{"timestamp":"1734624180.0","poster":"sumanshu","upvote_count":"1","content":"Selected Answer: AC\nIterator age metric is increasing: This means the Lambda function is not processing records as quickly as they arrive in the Kinesis data stream.\nRun duration is above normal: This suggests the Lambda function is taking longer to process each batch of records.\n\n\nEach Lambda function invocation processes records from a single shard. By increasing the number of shards, you can achieve more parallelism in record processing, which increases the overall throughput.\n\nIncreasing the memory also increases the allocated CPU power.","comment_id":"1329042"},{"upvote_count":"1","poster":"rcaliandro","timestamp":"1687964760.0","content":"Selected Answer: AC\nTo increase the performances of our lambda function we can add shards to the Kinesis data stream and also increase the memory (so the CPU as well) of the function. I will go for A and C","comment_id":"936805"},{"comments":[{"upvote_count":"1","comment_id":"921556","poster":"shasankperiwal","timestamp":"1686584220.0","content":"You are not even listening to what you're saying\nIf Lambda isn't coping then a decrease in number of shards will result in more data\nSo we would need to increase the number of shards"}],"timestamp":"1685298060.0","upvote_count":"1","poster":"mamila","content":"Selected Answer: CD\nSeriously nobody sees that the answer is C and D?\nLambda is not coping with the current amount of shards so they need to be reduced, not increased!","comment_id":"908803"},{"upvote_count":"1","poster":"peterpain","comment_id":"904717","content":"Selected Answer: AC\nA: Increase the number of shards for the better performance for Kinesis\nC: Increasing memory allocation of lambda also increases the vCPU of it","timestamp":"1684829460.0"},{"comment_id":"868699","upvote_count":"1","content":"Selected Answer: CE\nIncreasing the number of shards of the Kinesis data stream may not improve processing speed, and decreasing the number of shards can potentially reduce the parallel processing capability of the Lambda function, resulting in slower processing. Decreasing the timeout of the Lambda function is not recommended, as it may cause the function to terminate before completing the processing of all records.","timestamp":"1681324260.0","poster":"Syre"},{"timestamp":"1673440140.0","upvote_count":"1","content":"A and C","poster":"sichilam","comment_id":"772473"},{"upvote_count":"1","comment_id":"768731","content":"The Answer is A and C\nhttps://aws.amazon.com/premiumsupport/knowledge-center/lambda-iterator-age/","timestamp":"1673109540.0","poster":"KT_Yu"},{"upvote_count":"1","poster":"haazybanj","content":"Selected Answer: AC\nA and C is the right answer","timestamp":"1664968080.0","comment_id":"686804"},{"comment_id":"683330","poster":"arun00028","timestamp":"1664523600.0","upvote_count":"1","content":"Selected Answer: AC\nA an C"},{"timestamp":"1657637940.0","content":"Selected Answer: AC\nI vote for AC","upvote_count":"1","poster":"Prem21","comment_id":"630595"},{"content":"Selected Answer: AC\nI vote for AC","timestamp":"1656171240.0","upvote_count":"1","poster":"AulaitQM","comment_id":"622176"},{"comment_id":"545997","timestamp":"1644683220.0","poster":"IsraLev","upvote_count":"1","content":"Selected Answer: AC\nAnswer: AC"},{"poster":"JohnPi","upvote_count":"1","content":"Selected Answer: AC\nA&C is correct","timestamp":"1644437640.0","comment_id":"544071"},{"poster":"JP_PA","content":"Selected Answer: AC\nANS: A&C","comment_id":"541838","timestamp":"1644164520.0","upvote_count":"1"},{"upvote_count":"2","content":"It is AC.\n\nResolution from the below url.\nhttps://aws.amazon.com/premiumsupport/knowledge-center/lambda-iterator-age/\n\n1.Decrease your function's runtime duration\nAchievable by:\nIncrease the amount of memory allocated to the function.\nOptimize your function code .\n2.Increase your stream's shard count","poster":"Janakiram_Madurai","comment_id":"541608","timestamp":"1644139500.0"},{"comment_id":"515022","poster":"denccc","content":"It's AC","timestamp":"1641134220.0","upvote_count":"4"},{"comment_id":"513944","comments":[{"comment_id":"567729","content":"E is not correct because that way only gets a workarround with the same bad performance...","timestamp":"1647270300.0","upvote_count":"1","poster":"eledu1985"},{"content":"that doesn't make it run faster, so not E","comment_id":"721067","timestamp":"1668747000.0","poster":"dark_cherrymon","upvote_count":"1"}],"content":"Selected Answer: AE\nINcrease shards and increase timeout","poster":"ayush_1995","timestamp":"1640938560.0","upvote_count":"1"}],"timestamp":"2021-12-31 09:16:00","answer_ET":"AC","answer":"AC","question_id":4,"isMC":true,"unix_timestamp":1640938560,"topic":"1","question_images":[],"answer_images":[],"answer_description":"","question_text":"A company is using an AWS Lambda function to process records from an Amazon Kinesis data stream. The company recently observed slow processing of the records. A developer notices that the iterator age metric for the function is increasing and that the Lambda run duration is constantly above normal.\nWhich actions should the developer take to increase the processing speed? (Choose two.)","answers_community":["AC (77%)","8%","Other"],"choices":{"C":"Increase the memory that is allocated to the Lambda function.","A":"Increase the number of shards of the Kinesis data stream.","E":"Increase the timeout of the Lambda function.","B":"Decrease the timeout of the Lambda function.","D":"Decrease the number of shards of the Kinesis data stream."}},{"id":"1RvAhqhwsK5VxWG2xSG0","answers_community":["AD (91%)","9%"],"exam_id":25,"answer_ET":"AD","isMC":true,"discussion":[{"content":"Selected Answer: AD\nI never saw anything in AWS that uses *.tar files, which rules out B and C.","timestamp":"1734871140.0","comment_id":"1330385","poster":"JonasKahnwald","upvote_count":"1"},{"comment_id":"1329044","timestamp":"1734624360.0","content":"Selected Answer: AD\nElastic Beanstalk supports updating an environment with a new application version in multiple ways, primarily through the AWS Management Console or the AWS CLI.\n\n\nElastic Beanstalk does not support .tar files;","comments":[{"timestamp":"1734624360.0","comment_id":"1329045","content":"E) Eliminated - Rebuilding the environment is unnecessary for deploying a new application version. This approach would recreate resources (e.g., instances, load balancers), leading to increased downtime and resource usage, which is not required to update the environment","upvote_count":"1","poster":"sumanshu"}],"upvote_count":"1","poster":"sumanshu"},{"timestamp":"1702140120.0","poster":"xdkonorek2","content":"Selected Answer: AD\nelasticbeanstalk is allergic to .tar files:\n2023/12/09 17:38:45.327466 [INFO] Executing instruction: StageApplication\n2023/12/09 17:38:45.327795 [ERROR] An error occurred during execution of command [app-deploy] - [StageApplication]. Stop running the command. Error: staging application failed due to invalid zip file","upvote_count":"1","comment_id":"1091914"},{"poster":"RachitNandi1997","timestamp":"1693302120.0","content":"Selected Answer: CD\nMy opinion will be C and D","upvote_count":"1","comment_id":"992957"},{"upvote_count":"1","poster":"rcaliandro","content":"Selected Answer: AD\nIn my opinion is A and D. We need a .zip to be uploaded in Elastic Beanstalk and we can do that by using the AWS Management Console or AWS CLI","comment_id":"936809","timestamp":"1687964940.0"},{"comment_id":"772578","poster":"sichilam","content":"A and D","timestamp":"1673444160.0","upvote_count":"1"},{"upvote_count":"1","content":"The CLI command for Elastic Beanstalk deployment is eb deploy","comment_id":"768736","timestamp":"1673109840.0","poster":"KT_Yu"},{"comment_id":"686807","upvote_count":"2","content":"Selected Answer: AD\nA and D more realistic","poster":"haazybanj","timestamp":"1664968260.0"},{"timestamp":"1662131640.0","content":"This should be A and D I think? Elastic beanstalk won't take .tar files and E seems strange to use AWS Management console and then CLI to rebuild.","upvote_count":"4","poster":"JOL86","comment_id":"657542"},{"upvote_count":"4","timestamp":"1662117540.0","poster":"LEHUY","content":"Selected Answer: AD\nA,D looking more realistic.\nWhen you go to your EB console and any application ; rightaway on the console you can see a BIG option to upload and deploy ;thats where I lean to A. (Upload zip and Deploy).\nAnd to D obviously you can do the same with AWS EB CLI , by creating application new version and updating environment fot the target app.\nhttps://docs.aws.amazon.com/cli/latest/reference/elasticbeanstalk/update-environment.html","comment_id":"657342"}],"timestamp":"2022-09-02 13:19:00","topic":"1","question_text":"A developer is making changes to a custom application that uses AWS Elastic Beanstalk.\nWhich solutions will update the Elastic Beanstalk environment with the new application version after the developer completes the changes? (Choose two.)","answer":"AD","unix_timestamp":1662117540,"url":"https://www.examtopics.com/discussions/amazon/view/79379-exam-aws-certified-developer-associate-topic-1-question-102/","question_id":5,"question_images":[],"choices":{"D":"Package the application code into a .zip file. Use the AWS CLI to create a new application version from the .zip file and to update the environment.","E":"Package the application code into a .zip file. Use the AWS Management Console to create a new application version from the .zip file. Rebuild the environment by using the AWS CLI.","A":"Package the application code into a .zip file. Use the AWS Management Console to upload the zip file and deploy the packaged application.","B":"Package the application code into a .tar file. Use the AWS Management Console to create a new application version from the .tar file. Update the environment by using the AWS CLI.","C":"Package the application code into a .tar file. Use the AWS Management Console to upload the .tar file and deploy the packaged application."},"answer_description":"","answer_images":[]}],"exam":{"provider":"Amazon","numberOfQuestions":443,"isImplemented":true,"isBeta":false,"lastUpdated":"11 Apr 2025","name":"AWS Certified Developer Associate","id":25,"isMCOnly":true},"currentPage":1},"__N_SSP":true}