{"pageProps":{"questions":[{"id":"WZIDIdeeMIwHkNKAzxfS","discussion":[{"timestamp":"1732442640.0","poster":"65703c1","upvote_count":"2","comment_id":"1217297","content":"Selected Answer: A\nA is the correct answer."},{"poster":"SerialiDr","content":"Selected Answer: A\nA. Enable TTL (Time to Live) on the expirationDate attribute in the table. Create a DynamoDB stream. Create an AWS Lambda function to process the deleted items. Create a DynamoDB trigger for the Lambda function.\n\nThis approach leverages DynamoDB's TTL feature to automatically delete items past their expiration date, minimizing the need for custom code to manage this process. The use of a DynamoDB stream and a Lambda function triggered by this stream allows for processing or archiving the items just before they are deleted, without the need to manually scan and delete expired items, thereby significantly reducing operational complexity and code maintenance.","timestamp":"1725696840.0","upvote_count":"3","comment_id":"1167885"},{"content":"Selected Answer: A\ngoing with A","timestamp":"1725628680.0","upvote_count":"1","poster":"Abdullah22","comment_id":"1167276"},{"poster":"KarBiswa","timestamp":"1725358980.0","upvote_count":"1","comment_id":"1164762","content":"Selected Answer: A\nIt is TTL and stream combination. It will be utilized by the Lambda"},{"comment_id":"1155239","poster":"CrescentShared","upvote_count":"3","content":"Selected Answer: A\nNot sure why C. A can totally handle this.","timestamp":"1724207460.0"}],"question_text":"A developer supports an application that accesses data in an Amazon DynamoDB table. One of the item attributes is expirationDate in the timestamp format. The application uses this attribute to find items, archive them, and remove them from the table based on the timestamp value.\n\nThe application will be decommissioned soon, and the developer must find another way to implement this functionality. The developer needs a solution that will require the least amount of code to write.\n\nWhich solution will meet these requirements?","exam_id":24,"question_id":196,"question_images":[],"isMC":true,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/134275-exam-aws-certified-developer-associate-dva-c02-topic-1/","timestamp":"2024-02-21 05:31:00","answers_community":["A (100%)"],"unix_timestamp":1708489860,"choices":{"A":"Enable TTL on the expirationDate attribute in the table. Create a DynamoDB stream. Create an AWS Lambda function to process the deleted items. Create a DynamoDB trigger for the Lambda function.","B":"Create two AWS Lambda functions: one to delete the items and one to process the items. Create a DynamoDB stream. Use the DeleteItem API operation to delete the items based on the expirationDate attribute. Use the GetRecords API operation to get the items from the DynamoDB stream and process them.","D":"Enable TTL on the expirationDate attribute in the table. Specify an Amazon Simple Queue Service (Amazon SQS) dead-letter queue as the target to delete the items. Create an AWS Lambda function to process the items.","C":"Create two AWS Lambda functions: one to delete the items and one to process the items. Create an Amazon EventBridge scheduled rule to invoke the Lambda functions. Use the DeleteItem API operation to delete the items based on the expirationDate attribute. Use the GetRecords API operation to get the items from the DynamoDB table and process them."},"answer":"A","answer_images":[],"topic":"1","answer_ET":"A"},{"id":"QMj6qFO8eNev6NfaP3we","discussion":[{"upvote_count":"12","poster":"nder","comment_id":"1169334","timestamp":"1709971620.0","content":"Selected Answer: D\nQuick google will tell you the max size of a lambda layer is 250mb."},{"upvote_count":"1","content":"Selected Answer: D\nhttps://aws.amazon.com/blogs/compute/using-amazon-efs-for-aws-lambda-in-your-serverless-applications/\n\nSharing large code packages with Lambda\nEFS is useful for sharing software packages or binaries that are otherwise too large for Lambda layers. You can copy these to EFS and have Lambda use these packages as if there are installed in the Lambda deployment package.","comment_id":"1288988","poster":"preachr","timestamp":"1727268000.0"},{"timestamp":"1716537960.0","upvote_count":"1","content":"Selected Answer: D\nD is the correct answer.","poster":"65703c1","comment_id":"1217298"},{"content":"Selected Answer: D\nI've been going back and forward on this one for a few days. I have settled for EFS primarily based off a blog I read from an AWS community builder who specializes in lambda.\nhttps://betterdev.blog/serverless-ml-on-aws-lambda/#overcoming_lambda_size_limitations:~:text=the%20DynamoDB%20table.-,Overcoming%20Lambda%20size%20limitations,-If%20we%20package\n\n250mb limit per lambda, although the layers capacity is 75gb this covers your whole environment and breaches the single lambda limit.\nThe blog uses a container solution, the limit here is 10GB which is still to small for our use case.\nEFS fits this use case even though it is a tad more troublesome to implement.\n\nGranted the blog is 2 years old, I'm hoping not much has changed since.","timestamp":"1711710840.0","upvote_count":"3","comment_id":"1185377","poster":"DeaconStJohn"},{"timestamp":"1709806560.0","poster":"SerialiDr","comment_id":"1167887","content":"Selected Answer: D\nD. Save the library in an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all the Lambda functions.\n\nThis approach allows Lambda functions to access large libraries or datasets that exceed the size limits of Lambda's deployment package. By using Amazon EFS, a fully managed elastic file storage, the library can be stored once and mounted onto multiple Lambda functions simultaneously. This eliminates the need to package the library with each Lambda function, which would not be feasible given the size constraints of Lambda layers and deployment packages. Additionally, this method requires minimal code changes, focusing only on configuring the Lambda functions to mount the EFS file system, providing a scalable and efficient solution for making large libraries available to serverless applications.","upvote_count":"3"},{"content":"Selected Answer: D\njust the layer limitation 250 mb .","timestamp":"1709740260.0","upvote_count":"2","poster":"Abdullah22","comment_id":"1167315"},{"poster":"KarBiswa","upvote_count":"4","comment_id":"1164766","content":"Selected Answer: A\nUpto 75 GB can be accommodated. \nhttps://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html","timestamp":"1709468820.0"},{"poster":"ANDRES715","timestamp":"1709168040.0","content":"Selected Answer: A\nLa solución recomendada para este caso es guardar la biblioteca en capas Lambda y adjuntar esas capas a todas las funciones Lambda. Esto permitirá que todas las funciones Lambda tengan acceso a la biblioteca sin necesidad de duplicarla en cada función.\n\n\nLas capas Lambda son una forma de compartir código y bibliotecas comunes entre varias funciones Lambda. Puedes crear una capa Lambda que contenga la biblioteca de aprendizaje automático y luego adjuntar esa capa a todas las funciones Lambda que necesiten acceder a ella.\n\n\nAl utilizar capas Lambda, puedes reducir el tamaño de las funciones Lambda y simplificar su mantenimiento. Además, si el tamaño de la biblioteca está aumentando, puedes actualizar la capa Lambda sin tener que modificar y volver a implementar todas las funciones Lambda.","comment_id":"1162104","upvote_count":"4"},{"content":"Selected Answer: D\nS3 takes too long.","timestamp":"1708489920.0","poster":"CrescentShared","comment_id":"1155240","upvote_count":"2"}],"choices":{"C":"Save the library as a Lambda container image. Redeploy the Lambda functions with the new image.","A":"Save the library in Lambda layers. Attach the layers to all Lambda functions.","D":"Save the library in an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all the Lambda functions.","B":"Save the library in Amazon S3. Download the library from Amazon S3 inside the Lambda function."},"isMC":true,"answer_ET":"D","unix_timestamp":1708489920,"topic":"1","answers_community":["D (75%)","A (25%)"],"timestamp":"2024-02-21 05:32:00","exam_id":24,"question_id":197,"question_text":"A developer needs to implement a custom machine learning (ML) library in an application. The size of the library is 15 GB. The size of the library is increasing. The application uses AWS Lambda functions. All the Lambda functions must have access to the library.\n\nWhich solution will meet these requirements?","answer_description":"","answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/134276-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer_images":[],"question_images":[]},{"id":"Aux1oUzwjB3gYahyVS2G","unix_timestamp":1708490280,"question_images":[],"answer":"A","answer_images":[],"question_id":198,"choices":{"A":"Create Amazon Cognito user pools for external social identity providers. Configure IAM roles for the identity pools.","C":"Create an Amazon RDS for SQL Server DB instance to store the users and manage the permissions to the backend resources in AWS.","D":"Configure the sign-in page to register and store the users and their passwords in an Amazon DynamoDB table with an attached IAM policy.","B":"Program the sign-in page to create users' IAM groups with the IAM roles attached to the groups."},"timestamp":"2024-02-21 05:38:00","answer_ET":"A","question_text":"A developer is designing a serverless application for a game in which users register and log in through a web browser. The application makes requests on behalf of users to a set of AWS Lambda functions that run behind an Amazon API Gateway HTTP API.\n\nThe developer needs to implement a solution to register and log in users on the application's sign-in page. The solution must minimize operational overhead and must minimize ongoing management of user identities.\n\nWhich solution will meet these requirements?","answer_description":"","exam_id":24,"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/134277-exam-aws-certified-developer-associate-dva-c02-topic-1/","answers_community":["A (100%)"],"isMC":true,"discussion":[{"upvote_count":"2","content":"Selected Answer: A\nA is the correct answer.","comment_id":"1217300","poster":"65703c1","timestamp":"1732443000.0"},{"timestamp":"1725359400.0","comment_id":"1164769","poster":"KarBiswa","upvote_count":"3","content":"Selected Answer: A\nCognito is the option"},{"content":"Selected Answer: A\nAmazon Cognito es un servicio de AWS que permite agregar fácilmente la funcionalidad de registro e inicio de sesión a las aplicaciones. Puedes utilizar proveedores de identidades sociales externos, como Google, Facebook o Amazon, para permitir que los usuarios se registren e inicien sesión en tu aplicación.\n\n\nAl crear grupos de usuarios en Amazon Cognito y asignar roles de IAM a esos grupos, puedes gestionar de manera eficiente los permisos y accesos de los usuarios a los recursos backend en AWS. Esto te permite minimizar los gastos operativos y la gestión continua de las identidades de los usuarios.","poster":"ANDRES715","upvote_count":"3","timestamp":"1724885760.0","comment_id":"1162105"},{"comment_id":"1162051","upvote_count":"3","poster":"monishvster","content":"Selected Answer: A\nCognito is the answer","timestamp":"1724881200.0"},{"upvote_count":"3","comment_id":"1155241","content":"Selected Answer: A\nAnybody has an idea why it is C?","timestamp":"1724207880.0","poster":"CrescentShared"}]},{"id":"GksTScBP9OWD4eTVaATV","unix_timestamp":1707437520,"choices":{"B":"Configure a subscription filter on the CloudWatch Logs log group. Configure the filter to send an SNS notification when the number of errors exceeds the defined threshold within a 5-minute period.","A":"Rewrite the application code to stream application logs to Amazon SNS. Configure an SNS topic to send a notification when the number of errors exceeds the defined threshold within a 5-minute period.","C":"Install and configure the Amazon Inspector agent on the EC2 instances to monitor for errors. Configure Amazon Inspector to send an SNS notification when the number of errors exceeds the defined threshold within a 5-minute period.","D":"Create a CloudWatch metric filter to match the application error pattern in the log data. Set up a CloudWatch alarm based on the new custom metric. Configure the alarm to send an SNS notification when the number of errors exceeds the defined threshold within a 5-minute period."},"timestamp":"2024-02-09 01:12:00","exam_id":24,"discussion":[{"poster":"Moumita","comment_id":"1145116","content":"Correct Answer is D","timestamp":"1707437520.0","upvote_count":"7"},{"upvote_count":"5","timestamp":"1708490340.0","content":"Selected Answer: D\nShould be D","poster":"CrescentShared","comment_id":"1155242"},{"comment_id":"1231722","timestamp":"1718598600.0","upvote_count":"1","content":"This appear at 17 Jun exam","poster":"tsangckl"},{"timestamp":"1716538740.0","poster":"65703c1","content":"Selected Answer: D\nD is the correct answer.","upvote_count":"1","comment_id":"1217308"},{"poster":"KarBiswa","content":"Selected Answer: D\nD is the option","timestamp":"1709469180.0","upvote_count":"3","comment_id":"1164771"},{"comment_id":"1162053","content":"Selected Answer: D\nShould be D","timestamp":"1709163660.0","upvote_count":"3","poster":"monishvster"}],"question_id":199,"question_text":"A company has a web application that is hosted on Amazon EC2 instances. The EC2 instances are configured to stream logs to Amazon CloudWatch Logs. The company needs to receive an Amazon Simple Notification Service (Amazon SNS) notification when the number of application error messages exceeds a defined threshold within a 5-minute period.\n\nWhich solution will meet these requirements?","question_images":[],"answer":"D","answer_description":"","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/133406-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer_ET":"D","answer_images":[],"topic":"1","answers_community":["D (100%)"]},{"id":"CBucJ2xnKqV0rqc88ayr","timestamp":"2024-02-21 05:40:00","url":"https://www.examtopics.com/discussions/amazon/view/134278-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer":"B","unix_timestamp":1708490400,"answer_images":[],"question_images":[],"answers_community":["B (55%)","C (42%)","3%"],"discussion":[{"poster":"AssessmentKing","content":"Selected Answer: B\nImages are first uploaded to S3 bucket.\nThen, manual audit is performed that lasts 1-24 hours.\nOnly after the audit of the image is finished we can run our Lambda function.\nIf we run event at regular intervals (what does it mean?) should we run it every hour and then we would have bunch of untagged objects that haven't been audited and we would add a tag to them which doesn't make sense.\n\n- In option B they explicitly mention that the Wait period will be 24 hours thus insuring that the audit of those objects has been completed. Only then we run the Lambda function.","upvote_count":"7","comment_id":"1177324","timestamp":"1710852900.0"},{"poster":"mooncake1","timestamp":"1737860580.0","upvote_count":"1","content":"Selected Answer: B\nC will take too long... Each img will takd 24 hrs, and it will wait for all imgs. I do not understand why people are confused.. It needs to be triggered when the img is uploaded.","comments":[{"content":"Also SQS max VT is 12 hr. 24 hr is impossible, A not right","poster":"mooncake1","upvote_count":"1","timestamp":"1737860700.0","comment_id":"1346779"}],"comment_id":"1346777"},{"poster":"Arad","comment_id":"1338104","timestamp":"1736373600.0","content":"Selected Answer: C\nC is the right answer.\nLambda+EvenBridge is operationally more efficient than Step Function.","upvote_count":"1"},{"poster":"ShakthiGCP","comment_id":"1324257","upvote_count":"1","timestamp":"1733784480.0","content":"Selected Answer: B\nAns: B . We have to wait for 1- 24 hrs .we cant just run the lambda functions to get untagged objects ."},{"timestamp":"1730564400.0","poster":"Saudis","content":"Selected Answer: C\nI am confuse because the chatGPT Says C","upvote_count":"1","comment_id":"1306236"},{"upvote_count":"1","comments":[{"timestamp":"1730326980.0","poster":"devmo","upvote_count":"1","content":"Changing my mind to B as a lambda might time out if number of untagged items are a lot. Good use case for dynamodb streams.","comment_id":"1305213"}],"poster":"devmo","content":"Selected Answer: C\nWith option B, what if the external company doesn't complete the audit in 24 hours Least operational over head and long term solution would be going with 1 lambda and event bridge is what I feel.","timestamp":"1730326440.0","comment_id":"1305208"},{"poster":"MasoudK","timestamp":"1729107000.0","comment_id":"1298921","content":"C coz of operationally efficient words","upvote_count":"3"},{"upvote_count":"2","timestamp":"1718080320.0","comment_id":"1228238","content":"Selected Answer: C\nThis solution leverages AWS Lambda, which is a serverless compute service that runs your code in response to events and automatically manages the underlying compute resources for you1. By using Lambda in conjunction with Amazon EventBridge, which can trigger events at regular intervals, you can create a system that periodically checks for new audit results and applies tags to S3 objects without the need for managing server instances or handling queue visibility timeouts. This approach is not only operationally efficient but also cost-effective, as you pay only for the compute time you consume with Lambda21.","poster":"tsangckl"},{"comment_id":"1217310","timestamp":"1716539040.0","poster":"65703c1","content":"Selected Answer: B\nB is the correct answer.","upvote_count":"2"},{"content":"Selected Answer: B\nI'm still not sure if B is correct. \nHowever, I think this use case is very similar to a feature that exists in step functions. Although the wording doesn't answer the question directly and I think waiting 24 hours is the opposite of operationally efficient. The GetTaskToken feature that is part of service integration in step functions would be a perfect match for this scenario, removing the 24 hour wait while maintaining operational efficiency using AWS Step functions.\nI can only hope this is what they are getting at when I answer this on the exam.\n\nhttps://docs.aws.amazon.com/step-functions/latest/dg/connect-to-resource.html","upvote_count":"4","comment_id":"1182475","timestamp":"1711371420.0","poster":"DeaconStJohn"},{"upvote_count":"2","comment_id":"1170914","poster":"KarBiswa","content":"Selected Answer: C\nBest option considering the question conditions. Reading from Rest API","timestamp":"1710148980.0"},{"comment_id":"1167895","upvote_count":"4","poster":"SerialiDr","timestamp":"1709807220.0","content":"Selected Answer: C\nC. Create an AWS Lambda function to load all untagged S3 objects. Retrieve the results for each item from the REST API and tag each S3 object accordingly. Create and configure an Amazon EventBridge rule to run at regular intervals. Set the Lambda function as a target for the EventBridge rule.\n\nThis solution leverages AWS Lambda for processing and tagging S3 objects based on the audit results available through the REST API. By using Amazon EventBridge to trigger the Lambda function at regular intervals, the developer ensures that the process runs automatically without manual intervention, efficiently handling the tagging of S3 objects once the audit results are available. This approach minimizes operational effort and does not require the continuous monitoring of S3 object creation or the management of complex workflows."},{"content":"Selected Answer: A\nShould be A","comment_id":"1162054","upvote_count":"1","poster":"monishvster","timestamp":"1709163840.0"},{"comment_id":"1161611","upvote_count":"3","content":"Selected Answer: B\nI may choose B.","poster":"Jisking","timestamp":"1709122860.0"},{"upvote_count":"3","comment_id":"1155244","timestamp":"1708490400.0","poster":"CrescentShared","content":"Selected Answer: C\nA does not make any sense."}],"topic":"1","exam_id":24,"answer_description":"","question_id":200,"choices":{"D":"Launch an Amazon EC2 instance. Deploy a script to the EC2 instance to use the external database results to tag the S3 objects accordingly. Configure a crontab file to run the script at regular intervals.","A":"Create an AWS Lambda function to run in response to the s3:ObjectCreated event type. Write the S3 key to an Amazon Simple Queue Service (Amazon SQS) queue with a visibility timeout of 24 hours. Create and configure a second Lambda function to read items from the queue. Retrieve the results for each item from the DynamoDB table. Tag each S3 object accordingly.","B":"Create an AWS Lambda function to run in response to the s3:ObjectCreated event type. Integrate the function into an AWS Step Functions standard workflow. Define an AWS Step Functions Wait state and set the value to 24 hours. Create and configure a second Lambda function to retrieve the audit results and tag the S3 objects accordingly after the Wait state is over.","C":"Create an AWS Lambda function to load all untagged S3 objects. Retrieve the results for each item from the REST API and tag each S3 object accordingly. Create and configure an Amazon EventBridge rule to run at regular intervals. Set the Lambda function as a target for the EventBridge rule."},"isMC":true,"answer_ET":"B","question_text":"A photo sharing application uses Amazon S3 to store image files. All user images are manually audited for inappropriate content by a third-party company. The audits are completed 1-24 hours after user upload and the results are written to an Amazon DynamoDB table, which uses the S3 object key as a primary key. The database items can be queried by using a REST API created by the third-party company.\n\nAn application developer needs to implement an automated process to tag all S3 objects with the results of the content audit.\n\nWhat should the developer do to meet these requirements in the MOST operationally efficient way?"}],"exam":{"name":"AWS Certified Developer - Associate DVA-C02","isImplemented":true,"id":24,"isBeta":false,"provider":"Amazon","numberOfQuestions":551,"lastUpdated":"11 Apr 2025","isMCOnly":true},"currentPage":40},"__N_SSP":true}