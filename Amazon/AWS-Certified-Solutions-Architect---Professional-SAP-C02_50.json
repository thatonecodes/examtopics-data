{"pageProps":{"questions":[{"id":"S0te0n5wz5ZvX0C62n2B","question_text":"A company is in the process of implementing AWS Organizations to constrain its developers to use only Amazon EC2, Amazon S3, and Amazon DynamoDB. The developers account resides in a dedicated organizational unit (OU). The solutions architect has implemented the following SCP on the developers account:\n//IMG//\n\nWhen this policy is deployed, IAM users in the developers account are still able to use AWS services that are not listed in the policy.\nWhat should the solutions architect do to eliminate the developers’ ability to use services outside the scope of this policy?","isMC":true,"topic":"1","answers_community":["B (65%)","D (28%)","7%"],"discussion":[{"timestamp":"1670809860.0","comment_id":"742312","poster":"zhangyu20000","upvote_count":"18","content":"B is correct because default FullAWSAccess SCP is applied"},{"poster":"Six_Fingered_Jose","comment_id":"1008687","comments":[{"upvote_count":"3","content":"That's correct. You can disable AWSFullAccess SCP from member accounts as long as you are replacing it with another policy with specific permissions required.","poster":"jainparag1","comment_id":"1079046","timestamp":"1700803200.0"}],"upvote_count":"11","timestamp":"1694810340.0","content":"Selected Answer: B\nIf you go to AWS management console and look up how SCP works, you will find that by default FullAWSAccess policy is attached to all OUs by default if you have SCP enabled."},{"timestamp":"1742806320.0","poster":"GabrielShiao","content":"Selected Answer: A\nI have to choose A although A is impractical. While most vote B, it is actually impossible since removing FullAWSAcess SCP from OU will deny all the services on the ous and accounts under the OU. The correct action is to remove FullAWSAccess SCP from the developer account.","upvote_count":"1","comment_id":"1409606"},{"poster":"GabrielShiao","comment_id":"1400893","upvote_count":"1","timestamp":"1742436900.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html\nIf you removed the default SCP from the OU, you will be denied for these permission even you allowed in SCP on the account in OU."},{"content":"Selected Answer: A\nIf you removed FullAWSAccess from developer accounts, I vote B, however, B is removing it from OU. Keep in mind every level of organization hierarchy must reside at least one SCP.","poster":"GabrielShiao","comment_id":"1400877","upvote_count":"1","timestamp":"1742433480.0"},{"content":"It can be as well handled with a or d, like\n{\n \"Effect\": \"Deny\",\n \"NotAction\": [\n \"ec2:*\",\n \"s3:*\",\n \"dynamodb:*\"\n ],\n \"Resource\": \"*\"\n }","poster":"konieczny69","timestamp":"1729616640.0","comment_id":"1301654","upvote_count":"2"},{"upvote_count":"1","comment_id":"1275474","poster":"amministrazione","content":"B. Remove the FullAWSAccess SCP from the developers account’s OU.","timestamp":"1725093300.0"},{"comment_id":"1264052","content":"Selected Answer: B\nB. Remove the FullAWSAccess SCP from the developers account’s OU.\n\nExplanation:\nFullAWSAccess SCP: By default, AWS Organizations attaches a FullAWSAccess SCP to all OUs and accounts, allowing access to all AWS services unless restricted by another SCP. If this SCP is still attached to the developers' OU, it will allow access to all services, regardless of the more restrictive SCP you have applied.\n\nSCP Behavior: SCPs are evaluated in an \"implicit deny\" model. If an action is not explicitly allowed by the SCPs, it is implicitly denied. However, if multiple SCPs are attached and one allows an action (like FullAWSAccess), that action is permitted unless explicitly denied in another SCP.","upvote_count":"2","poster":"MAZIADI","timestamp":"1723374960.0"},{"upvote_count":"1","timestamp":"1723023480.0","poster":"felon124","content":"Selected Answer: B\nAWS Organizations attaches an AWS managed SCP named FullAWSAccess to every root, OU and account when it's created. This policy allows all services and actions. You can replace FullAWSAccess with a policy allowing only a set of services so that new AWS services are not allowed unless they are explicitly allowed by updating SCPs.\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html","comment_id":"1262021"},{"upvote_count":"1","timestamp":"1722285840.0","content":"Selected Answer: D\nBest practice would be to create an explicit deny statement. The reason is that other SCPs could be in effect, aside from AWSFullAccess, that could grant access to other services. If the goal is to deny access to any other service, then this must be made explicit.","poster":"8693a49","comment_id":"1257687"},{"comment_id":"1257592","content":"Selected Answer: B\nB is correct\nRemove from develop account OU --> implicitly deny all service -->add explicity 'allow' to restirct only allow related services in SCP.","poster":"vip2","upvote_count":"1","timestamp":"1722271800.0"},{"content":"Selected Answer: D\n{\n \"Sid\": \"ExplicitDeny\",\n \"Effect\": \"Deny\",\n \"NotAction\": [\n \"ec2:*\",\n \"dynamodb:*\",\n \"s3:*\"\n ],\n \"Resource\": \"*\"\n }","poster":"Moghite","upvote_count":"2","timestamp":"1721760600.0","comment_id":"1253909"},{"comments":[{"comment_id":"1264659","timestamp":"1723467720.0","content":"It can be, read \"How SCPs work with Allow\" in here it shows example:\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html","poster":"sam2ng","upvote_count":"1"}],"timestamp":"1718584140.0","upvote_count":"2","comment_id":"1231589","content":"Selected Answer: D\nFullAWSAccess SCP is inherited from root. Can't be removed from OU.\nD is correct answer.","poster":"Helpnosense"},{"upvote_count":"4","content":"Selected Answer: D\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n {\n \"Sid\": \"AllowEC2\",\n \"Effect\": \"Allow\",\n \"Action\": \"ec2:*\",\n \"Resource\": \"*\"\n },\n {\n \"Sid\": \"AllowDynamoDB\",\n \"Effect\": \"Allow\",\n \"Action\": \"dynamodb:*\",\n \"Resource\": \"*\"\n },\n {\n \"Sid\": \"AllowS3\",\n \"Effect\": \"Allow\",\n \"Action\": \"s3:*\",\n \"Resource\": \"*\"\n },\n {\n \"Sid\": \"ExplicitDeny\",\n \"Effect\": \"Deny\",\n \"NotAction\": [\n \"ec2:*\",\n \"dynamodb:*\",\n \"s3:*\"\n ],\n \"Resource\": \"*\"\n }\n ]\n}","poster":"qaz12wsx","timestamp":"1713174060.0","comment_id":"1195945"},{"upvote_count":"2","timestamp":"1710171120.0","content":"Selected Answer: D\nD - the alternative doesn't mention an ASG which must be taken as implied.\nThe other solutions are simply absurd:\nA: The operational overhead is ENORMOUS. To those who think that \"operational overhead\" is only day-to-day maintenance: it is not. It encompasses ALL CHANGES to the infrastructure.\nB: Kubernetes is the very definition of operational overhead. Always avoid unless there is an absolutely compelling reason to use it.\nC: And what do you people think the function of the Lambda is? None. \nD: This works and is the most straightforward as soon as you realise that the ASG is implied.\n\nIn the final analysis, this is another example of how AWS exam questions leave out information in order to trip you up.","comment_id":"1171098","poster":"Dgix"},{"poster":"Dafukubai","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html\n\nFullAWSAccess NOT inherited. It must be set at every OU layer.\nB is the most inadvisable choice because target account will get a explicitly DENY for all AWS services including EC2 etc if delete FullAWSAccess at it OU.","comment_id":"1152316","timestamp":"1708133040.0","upvote_count":"2"},{"upvote_count":"4","comments":[{"timestamp":"1707406140.0","content":"Full SCP:\n{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n {\n \"Sid\": \"AllowEC2\",\n \"Effect\": \"Allow\",\n \"Action\": \"ec2:\",\n \"Resource\": \"*\"\n },\n {\n \"Sid\": \"AllowDynamoDB\",\n \"Effect\": \"Allow\",\n \"Action\": \"dynamodb:\",\n \"Resource\": \"*\"\n },\n {\n \"Sid\": \"AllowS3\",\n \"Effect\": \"Allow\",\n \"Action\": \"s3:\",\n \"Resource\": \"*\"\n },\n {\n \"Sid\": \"ExplicitDenyAllOtherServices\",\n \"Effect\": \"Deny\",\n \"NotAction\": [\n \"ec2:\",\n \"dynamodb:\",\n \"s3:\"\n ],\n \"Resource\": \"*\"\n }\n ]\n}","poster":"8608f25","comment_id":"1144630","comments":[{"upvote_count":"3","timestamp":"1707406260.0","poster":"8608f25","comment_id":"1144635","content":"Explanation:\n * Option A is less efficient because creating an explicit deny statement for each AWS service except EC2, S3, and DynamoDB would be impractical given the large number of services AWS offers.\n * Option B suggests removing the FullAWSAccess SCP from the developers account’s OU. While removing FullAWSAccess could potentially restrict access, it’s not as direct or effective as implementing an explicit deny. The FullAWSAccess SCP allows all actions on all resources within the account or OU it’s applied to, and simply removing it doesn’t automatically restrict access to only the specified services.\n * Option C suggests modifying the FullAWSAccess SCP to explicitly deny all services. However, the FullAWSAccess SCP is a default SCP applied by AWS Organizations and should generally be left as is. Custom SCPs should be created to enforce specific policies.\n * Option D is the most direct and effective approach."}],"upvote_count":"2"}],"poster":"8608f25","timestamp":"1707406080.0","comment_id":"1144629","content":"Selected Answer: D\nTo eliminate the developers’ ability to use AWS services outside the scope of Amazon EC2, Amazon S3, and Amazon DynamoDB, the solutions architect should:\n * D. Add an explicit deny statement using a wildcard to the end of the SCP.\nThis action effectively restricts access to only the specified services by explicitly denying access to all other AWS services. The corrected Service Control Policy (SCP) would look something like this:\n{\n \"Sid\": \"ExplicitDenyAllOtherServices\",\n \"Effect\": \"Deny\",\n \"NotAction\": [\n \"ec2:\",\n \"dynamodb:\",\n \"s3:\"\n ],\n \"Resource\": \"*\"\n }"},{"upvote_count":"2","comment_id":"1137484","content":"Selected Answer: B\nignore my previous comment","timestamp":"1706781840.0","poster":"LazyAutonomy"},{"timestamp":"1706780880.0","content":"Selected Answer: A\nBy default, FullAWSAccess is applied at the root, so all member accounts in all OUs will inherit this policy. Removing FullAWSAccess SCP from a specific OU isn't enough. Answer is A.","upvote_count":"1","comments":[{"poster":"LazyAutonomy","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1706781780.0","comment_id":"1137482","content":"The answer is B.","poster":"LazyAutonomy"}],"comment_id":"1137476","timestamp":"1706781180.0","content":"Ahh, thanks to @gustori99 for pointing out my incorrect understanding. SCPs are not inherited. See https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html"}],"poster":"LazyAutonomy","comment_id":"1137470"},{"content":"A is correct - Removing FullAWSAccess SCP from the developer account only is not going to help. As FullAWSAccess allowing all is also being inherited from the root and Parent OUs. When SCP is enable FullAWSAccess is enabled by default. \n\nOne option is replacing FullAWSAccess on root and all Parent OUs and developer account to the SCP mentioned in question allowing only three service. \n\nIf we are only removing FullAWSAccess SCP from developer's account then we will have to explicitly deny all other services not required.","upvote_count":"1","timestamp":"1706553420.0","poster":"Vaibs099","comment_id":"1135219"},{"upvote_count":"1","comments":[{"content":"The question states \"the solutions architect has implemented the following SCP on the developers account\". In my understanding the SCP is attached on the developers account not on the OU level. \n\nIf SCP is attached on OU level then B is correct. If it is attached on the account B cannot be correct.","upvote_count":"1","comment_id":"1157012","poster":"gustori99","timestamp":"1708676880.0"}],"comment_id":"1135081","poster":"gustori99","timestamp":"1706542740.0","content":"Selected Answer: A\nIt seams that almost no one understands how SCPs are evaluated:\n\nFrom the documentation: For a permission to be allowed for a specific account, there must be an explicit Allow statement at every level from the root through each OU in the direct path to the account (including the target account itself).\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html\n\nSo FullAWSAccess at the root level is NOT inherited. It must be present at ALL levels. \n\nB is wrong because when you remove FullAWSAccess at the OU level and do not replace it with an allow list of the permitted services, ALL services will be denied even if you have an allow list on account level.\n\nC and D does't make sense."},{"timestamp":"1706296740.0","poster":"TheHowesHold","comment_id":"1132814","content":"Selected Answer: B\nB -AWS Organizations attaches an AWS managed SCP policy named FullAWSAccess which allows all services and actions. If this policy is removed and not replaced at any level of the organization, all OUs and accounts under that level would be blocked from taking any actions.","upvote_count":"2"},{"upvote_count":"2","comment_id":"1110390","poster":"ele","timestamp":"1704011100.0","content":"Selected Answer: D\nRight answer is D.\nD: explicit deny will override any allow inherited from root. AWS doc: https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html#how_scps_deny\nnot A as it is not efficient.\nnot B as it will not help if root still has FullAccess\nnot C as it is not possible to modify"},{"comment_id":"1100842","timestamp":"1703005560.0","poster":"ninomfr64","content":"Selected Answer: B\nServices are implicitly denied and you allow services with SCP (ore explicitly deny). In this scenario an SCP applied to higher level is allowing more services thus B","upvote_count":"2"},{"comment_id":"1088470","timestamp":"1701778800.0","poster":"subbupro","upvote_count":"1","content":"Best approach - apply the deny in the root level - it is a must one best practices. When you create the organization we need to first create the below statement, \n Create an explicit default deny statement for each AWS service that should be constrained."},{"poster":"eurriola10","content":"Selected Answer: B\nB is correct. Review this link under Sandbox OU Scenario 2 https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_evaluation.html#strategy_using_scps","comment_id":"1082728","timestamp":"1701188880.0","upvote_count":"3"},{"content":"Selected Answer: B\nThe answer is B.\nWhen I actually tried it, except for A, the behavior was as follows.\nB: Services outside the scope of the policy cannot be used.\nC: All services are unavailable.\nD: All services are unavailable.","comment_id":"1079764","upvote_count":"5","timestamp":"1700891760.0","poster":"edder"},{"poster":"severlight","content":"Selected Answer: B\nB, they are able to access, hence all current SCPs including parent ones have explicit allow. Removing explicit allow from the current OU will be enough to deny access.","upvote_count":"2","comment_id":"1068369","timestamp":"1699776660.0"},{"timestamp":"1694407200.0","poster":"AMohanty","content":"A\nSCP is a DENY statement, its NOT designed to PERMIT/ALLOW service access.","upvote_count":"1","comment_id":"1004454"},{"upvote_count":"1","comments":[{"upvote_count":"2","poster":"chico2023","content":"As bad as it sounds, I still think it's the less wrong answer and I can explain my understanding below:","timestamp":"1691179680.0","comment_id":"972477"},{"timestamp":"1703946420.0","upvote_count":"1","comment_id":"1109782","content":"This explanation makes much more sense than the others, say I would go to A too.","poster":"jpa8300"}],"timestamp":"1691179680.0","poster":"chico2023","comment_id":"972476","content":"Selected Answer: A\nAnswer: A"},{"content":"Selected Answer: B\nIf you reenable SCPs on the organization root, all entities are reset to being attached to only the default FullAWSAccess SCP.","timestamp":"1688676180.0","poster":"Christina666","upvote_count":"2","comment_id":"945010"},{"content":"Selected Answer: D\nIt's D actually. If you remove the FullAWSAccess you are still inheriting the same policy from the root account. See this: https://imgur.com/a/2EMUm0S\nThis means you have to remove the same SCP from root. On top of that, AWS has the same use case here -> https://aws.amazon.com/blogs/industries/best-practices-for-aws-organizations-service-control-policies-in-a-multi-account-environment/","comment_id":"938183","upvote_count":"4","timestamp":"1688046060.0","poster":"SmileyCloud","comments":[{"comment_id":"948915","timestamp":"1689074100.0","upvote_count":"1","content":"Is it a recommended practice to have a FullAWSAccess + a Deny in another SCP?","poster":"Arnaud92"}]},{"poster":"NikkyDicky","content":"Selected Answer: B\nReplace default allow SCP","timestamp":"1688003220.0","upvote_count":"2","comment_id":"937351"},{"poster":"Parimal1983","content":"Selected Answer: B\nInstead of creating explicit deny for each and every service, it is efficient way to remove root level allow SCP for all services and add explicit SCP with EC2, S3 and DynamoDB to developer OU","comment_id":"933395","timestamp":"1687682400.0","upvote_count":"4"},{"upvote_count":"4","comment_id":"924110","poster":"ailves","timestamp":"1686826980.0","content":"Selected Answer: B\nAccording to https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_strategies.html we have to replace (not remove) SCP.\n\"To use SCPs as an allow list, you must replace the AWS managed FullAWSAccess SCP with an SCP that explicitly permits only those services and actions that you want to allow\"."},{"timestamp":"1683621360.0","comment_id":"892926","poster":"gameoflove","content":"Selected Answer: B\nFullAWSAccess must be resolved","upvote_count":"2"},{"upvote_count":"2","comment_id":"876728","timestamp":"1682097960.0","content":"Selected Answer: B\nInitially I voted for A but then I saw the following statement : \"AWS services that aren't explicitly allowed by the SCPs associated with an AWS account or its parent OUs are denied access to the AWS accounts or OUs associated with the SCP. SCPs associated to an OU are inherited by all AWS accounts in that OU\"","poster":"Maria2023"},{"comment_id":"873174","timestamp":"1681775220.0","upvote_count":"3","content":"Selected Answer: D\nB says: \"Remove the FullAWSAccess SCP from the developers account’s OU\", with the information we have here there is no way to guarantee the SCP is applied to the developers account's OU. It can be any place from the root all the way down to the developer's OU.","poster":"Sarutobi"},{"timestamp":"1681205640.0","poster":"frfavoreto","comment_id":"867132","content":"Selected Answer: B\n'B' is the BEST answer, but not the only correct one. \n\n'D' is also technically correct, because adding a wildcard DENY statement would override the FullAWSAccess SCP attached by default to the OU and it would have the same final result. \n\nHowever 'B' is more appropriate here, the so called best practice. This is what 'Professional' exam certs are all about.","upvote_count":"3"},{"timestamp":"1679987580.0","comment_id":"852929","content":"Remove the FullAWSAccess SCP from the developers account’s OU","poster":"mfsec","upvote_count":"1"},{"comment_id":"828663","content":"An allow list strategy has you remove the FullAWSAccess SCP that is attached by default to every OU and account. This means that no APIs are permitted anywhere unless you explicitly allow them. To allow a service API to operate in an AWS account, you must create your own SCPs and attach them to the account and every OU above it, up to and including the root. Every SCP in the hierarchy, starting at the root, must explicitly allow the APIs that you want to be usable in the OUs and accounts below it\n\nA deny list strategy makes use of the FullAWSAccess SCP that is attached by default to every OU and account. This SCP overrides the default implicit deny, and explicitly allows all permissions to flow down from the root to every account, unless you explicitly deny a permission with an additional SCP that you create and attach to the appropriate OU or account\nIf the developers can access other services it implies the \"Deny List Strategy\" hence FullAWSAccess is in place and should be removed","upvote_count":"3","timestamp":"1677903120.0","poster":"Ajani"},{"poster":"Gabehcoud","timestamp":"1677225300.0","comment_id":"820230","comments":[{"poster":"atlasga","content":"It's applied by default.","comment_id":"866690","timestamp":"1681169340.0","upvote_count":"2"}],"content":"the question doesn't state that there is another SCP applied to developers account. By choosing B, are we just assuming ? Why can't it be D?","upvote_count":"2"},{"comment_id":"804546","timestamp":"1676045340.0","upvote_count":"3","content":"I was confused at first but the intersection of sets here allowed me to understand the flow of SCPs from root to child OUs https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_inheritance_auth.html","poster":"moota"},{"upvote_count":"4","timestamp":"1675088640.0","content":"Selected Answer: B\nB is correct.\nBy removing FullAWSAccess SCP, default deny will be applied.","poster":"jooncco","comment_id":"792917"},{"content":"Selected Answer: B\nB is correct\nhttps://docs.aws.amazon.com/organizations/latest/APIReference/API_DetachPolicy.html","poster":"AjayD123","comment_id":"780727","upvote_count":"2","timestamp":"1674102900.0"},{"timestamp":"1670946900.0","poster":"masetromain","comment_id":"744248","content":"Selected Answer: B\nhttps://www.examtopics.com/discussions/amazon/view/46899-exam-aws-certified-solutions-architect-professional-topic-1/","upvote_count":"4"}],"question_images":["https://img.examtopics.com/aws-certified-solutions-architect-professional-sap-c02/image5.png"],"choices":{"A":"Create an explicit deny statement for each AWS service that should be constrained.","C":"Modify the FullAWSAccess SCP to explicitly deny all services.","D":"Add an explicit deny statement using a wildcard to the end of the SCP.","B":"Remove the FullAWSAccess SCP from the developers account’s OU."},"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/91103-exam-aws-certified-solutions-architect-professional-sap-c02/","timestamp":"2022-12-12 02:51:00","exam_id":33,"answer":"B","answer_description":"","unix_timestamp":1670809860,"answer_ET":"B","question_id":246},{"id":"9G4ufzNqQrlxsqDiCpqe","unix_timestamp":1698603660,"discussion":[{"upvote_count":"7","timestamp":"1698881760.0","comment_id":"1060123","poster":"joleneinthebackyard","content":"Selected Answer: D\n\"must implement a solution to encrypt all NEWWW EBS volumes at rest.\""},{"content":"Selected Answer: D\nC only address existing unencrypted EBS, not preventing future unencrypted \n\nD is so clear \"Proactively prevents the creation of unencrypted EBS volumes\"\nThe key word is all new EBS volume","timestamp":"1735050540.0","upvote_count":"2","comment_id":"1331149","poster":"PSPaul"},{"poster":"AzureDP900","comment_id":"1313816","content":"D \nThe company requires that all new EBS volumes be encrypted at rest.\nTurning on EBS encryption by default for all regions will automatically encrypt any new EBS volume created, meeting the compliance requirement with minimal effort.\nThis approach ensures that encryption is enabled for all new volumes without requiring additional configuration or automation.","upvote_count":"1","timestamp":"1731901020.0"},{"comments":[{"timestamp":"1730365560.0","content":"The question ask to encrypt new EBS, not the existing.","comment_id":"1305345","poster":"Daniel76","upvote_count":"1"}],"timestamp":"1720772820.0","upvote_count":"1","content":"Selected Answer: C\nthere is no direct way to encrypt existing unencrypted EBS volumes or snapshots.\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automatically-encrypt-existing-and-new-amazon-ebs-volumes.html","comment_id":"1246594","poster":"mark_232323"},{"content":"Selected Answer: D\nI am not picking an answer, I just wanted to point out that EBS encryption is regions specific. option D says : Turn on EBS encryption by default in all AWS Regions. there is no such feature. Option D still appears to be the best answer","comment_id":"1239326","comments":[{"timestamp":"1730366040.0","upvote_count":"1","content":"We may consider it meant to be doing this configuration region by region. It's still require the least effort doing that. :)","poster":"Daniel76","comment_id":"1305350"}],"upvote_count":"1","poster":"Russs99","timestamp":"1719671160.0"},{"poster":"vibzr2023","comment_id":"1121123","timestamp":"1705094160.0","upvote_count":"4","content":"Answer: D\nEncryption of Amazon Elastic Block Store (Amazon EBS) volumes is important to an organization's data protection strategy. It is an important step in establishing a well-architected environment. Although there is no direct way to encrypt existing unencrypted EBS volumes or snapshots, you can encrypt them by creating a new volume or snapshot. \nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automatically-encrypt-existing-and-new-amazon-ebs-volumes.html"},{"timestamp":"1704818160.0","comment_id":"1117683","content":"Selected Answer: D\nOption D","upvote_count":"1","poster":"career360guru"},{"content":"Selected Answer: D\nThe keyword is all NEW EBS volumes.\nSo by make EBS Encryption default, it means all new EBS will be encrypted without additional configuration.","timestamp":"1698834540.0","upvote_count":"2","comment_id":"1059579","poster":"airgead"},{"content":"Selected Answer: D\nLeast effort option","comment_id":"1058536","poster":"s61","upvote_count":"3","timestamp":"1698737340.0"},{"content":"Selected Answer: D\nThe question states: ' A solutions architect must implement a solution to encrypt all new EBS volumes at rest'\nreference: https://repost.aws/knowledge-center/ebs-automatic-encryption","upvote_count":"3","poster":"gonzales","timestamp":"1698649620.0","comment_id":"1057419"},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automatically-encrypt-existing-and-new-amazon-ebs-volumes.html","comment_id":"1057067","poster":"KungLjao","upvote_count":"3","timestamp":"1698603660.0"}],"timestamp":"2023-10-29 19:21:00","question_text":"A company's compliance audit reveals that some Amazon Elastic Block Store (Amazon EBS) volumes that were created in an AWS account were not encrypted. A solutions architect must implement a solution to encrypt all new EBS volumes at rest.\n\nWhich solution will meet this requirement with the LEAST effort?","isMC":true,"exam_id":33,"topic":"1","answer_images":[],"choices":{"A":"Create an Amazon EventBridge rule to detect the creation of unencrypted EBS volumes. Invoke an AWS Lambda function to delete noncompliant volumes.","B":"Use AWS Audit Manager with data encryption.","D":"Turn on EBS encryption by default in all AWS Regions.","C":"Create an AWS Config rule to detect the creation of a new EBS volume. Encrypt the volume by using AWS Systems Manager Automation."},"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/124903-exam-aws-certified-solutions-architect-professional-sap-c02/","answers_community":["D (83%)","C (17%)"],"question_images":[],"answer":"D","question_id":247,"answer_ET":"D"},{"id":"mvVCplsrQAkj7DtCwX0i","unix_timestamp":1698604080,"discussion":[{"timestamp":"1698836160.0","poster":"airgead","content":"Selected Answer: C\nAnswer C is correct with the following reasons:\nThe keywords: \"no EC2 instance can use the same SSH key\" AND \" all connections must be logged in AWS CloudTrail.\"\n1. EC2 Instance connect using temporary ssh key, one-time SSH keys each time the user connects\n2. User connections via EC2 Instance Connect are logged to AWS CloudTrail","comment_id":"1059616","upvote_count":"8"},{"content":"Selected Answer: C\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/connect-linux-inst-eic.html","timestamp":"1698604080.0","comment_id":"1057073","poster":"KungLjao","upvote_count":"7"},{"timestamp":"1714905360.0","poster":"svenkata18","content":"D\nWhy not D. In C with instance connect, there are 100s of instances and key would be created for each instance manually would take lot of time","comment_id":"1206841","upvote_count":"2"},{"timestamp":"1713955440.0","content":"Option C - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-connect-configure-IAM-role.html","poster":"TonytheTiger","upvote_count":"1","comment_id":"1201265"},{"comment_id":"1200802","poster":"TonytheTiger","upvote_count":"1","content":"Selected Answer: C\nOption C - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-connect-configure-IAM-role.html","timestamp":"1713887100.0"},{"comments":[{"comment_id":"1235640","poster":"marchelok","upvote_count":"1","content":"No CloudTrail logging for AWS system manager documents.","timestamp":"1719095880.0"}],"comment_id":"1192276","poster":"SKS","content":"can some one justify why cant use AWS system manager (Session manager) option B ??","timestamp":"1712665080.0","upvote_count":"1"},{"comment_id":"1117693","timestamp":"1704819120.0","upvote_count":"2","content":"Selected Answer: C\nOption C","poster":"career360guru"}],"url":"https://www.examtopics.com/discussions/amazon/view/124904-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"B":"Create an AWS Systems Manager document to run commands on EC2 instances to set a new unique SSH key. Create a new IAM policy, and attach it to the engineers’ IAM role with an Allow statement to run Systems Manager documents. Instruct the engineers to run the document to set an SSH key and to connect through any SSH client.","C":"Launch new EC2 instances without setting up any SSH key for the instances. Set up EC2 Instance Connect on each instance. Create a new IAM policy, and attach it to the engineers’ IAM role with an Allow statement for the SendSSHPublicKey action. Instruct the engineers to connect to the instance by using a browser-based SSH client from the EC2 console.","D":"Set up AWS Secrets Manager to store the EC2 SSH key. Create a new AWS Lambda function to create a new SSH key and to call AWS Systems Manager Session Manager to set the SSH key on the EC2 instance. Configure Secrets Manager to use the Lambda function for automatic rotation once daily. Instruct the engineers to fetch the SSH key from Secrets Manager when they connect through any SSH client.","A":"Launch new EC2 instances, and generate an individual SSH key for each instance. Store the SSH key in AWS Secrets Manager. Create a new IAM policy, and attach it to the engineers’ IAM role with an Allow statement for the GetSecretValue action. Instruct the engineers to fetch the SSH key from Secrets Manager when they connect through any SSH client."},"answer_description":"","exam_id":33,"answer_ET":"C","question_id":248,"question_text":"A research company is running daily simulations in the AWS Cloud to meet high demand. The simulations run on several hundred Amazon EC2 instances that are based on Amazon Linux 2. Occasionally, a simulation gets stuck and requires a cloud operations engineer to solve the problem by connecting to an EC2 instance through SSH.\n\nCompany policy states that no EC2 instance can use the same SSH key and that all connections must be logged in AWS CloudTrail.\n\nHow can a solutions architect meet these requirements?","answers_community":["C (100%)"],"timestamp":"2023-10-29 19:28:00","isMC":true,"answer":"C","topic":"1","answer_images":[],"question_images":[]},{"id":"kktTR4VGUB3yOKU7G3OB","unix_timestamp":1698548220,"discussion":[{"comment_id":"1228744","timestamp":"1718152680.0","poster":"trungtd","content":"Option C: Amazon Route 53 Resolver with Conditional Forwarding Rules\n\nLeast Administrative Overhead: This option leverages AWS-managed services to handle DNS resolution without the need to manage additional infrastructure or complicated configurations.\nRoute 53 Resolver Endpoints: Create inbound and outbound endpoints to handle DNS queries between AWS and the on-premises environment.\n Inbound Endpoints: Allow on-premises systems to resolve DNS names hosted in AWS.\n Outbound Endpoints: Forward DNS queries from AWS to on-premises DNS servers.\nConditional Forwarding Rules: Set up rules to forward specific domain queries (like your Active Directory domain) to the on-premises DNS servers. This ensures seamless DNS resolution for the applications in the VPC.\n\nB: Private hosted zones are intended for DNS records within AWS. \nA & D: too much overhead","upvote_count":"5"},{"upvote_count":"1","content":"C is right\nThe company needs to resolve DNS requests from EC2 instances in a VPC to an on-premises Active Directory domain that runs in a data center with an AWS Direct Connect connection.\nAmazon Route 53 Resolver is specifically designed for this use case, providing a secure way to enable name resolution between your on-premises and cloud-based resources.\nBy using Route 53 Resolver, you can create DNS endpoints within the VPC that resolve DNS queries to the on-premises Active Directory domain without requiring any additional infrastructure or overhead in the data center.","comment_id":"1313812","poster":"AzureDP900","timestamp":"1731900480.0"},{"poster":"sarlos","content":"Why not B?","timestamp":"1715646180.0","comment_id":"1211146","upvote_count":"2"},{"timestamp":"1704819420.0","upvote_count":"1","comment_id":"1117698","content":"Selected Answer: C\nOption C","poster":"career360guru"},{"comment_id":"1082638","content":"Selected Answer: C\nAnswer is C, least admin overhead using Route 53 resolver with conditional forwarding","timestamp":"1701181260.0","poster":"shaaam80","upvote_count":"2"},{"upvote_count":"1","poster":"devalenzuela86","content":"Selected Answer: C\nAnswer C","timestamp":"1700934000.0","comment_id":"1080211"},{"upvote_count":"4","timestamp":"1698837720.0","poster":"airgead","content":"Selected Answer: C\nOption C: Amazon Route 53 Resolver > Conditional Forwarding\nLower Maintenance than Option A which using EC2.","comment_id":"1059637"},{"timestamp":"1698650580.0","poster":"gonzales","upvote_count":"3","comment_id":"1057425","content":"Selected Answer: C\nTo forward DNS queries from your VPCs to your network, you create an outbound endpoint. \nreference: https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver-forwarding-outbound-queries.html"},{"poster":"Bad_Mat","comment_id":"1057281","timestamp":"1698631500.0","upvote_count":"1","content":"I vote for C"},{"timestamp":"1698548220.0","upvote_count":"3","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/security/how-to-set-up-dns-resolution-between-on-premises-networks-and-aws-using-aws-directory-service-and-amazon-route-53/","comment_id":"1056544","poster":"AM_aws"}],"url":"https://www.examtopics.com/discussions/amazon/view/124867-exam-aws-certified-solutions-architect-professional-sap-c02/","choices":{"D":"Provision a new Active Directory domain controller in the VPC with a bidirectional trust between this new domain and the on-premises Active Directory domain.","A":"Provision a set of EC2 instances across two Availability Zones in the VPC as caching DNS servers to resolve DNS queries from the application servers within the VPC.","B":"Provision an Amazon Route 53 private hosted zone. Configure NS records that point to on-premises DNS servers.","C":"Create DNS endpoints by using Amazon Route 53 Resolver. Add conditional forwarding rules to resolve DNS namespaces between the on-premises data center and the VPC."},"answer_description":"","exam_id":33,"answer_ET":"C","question_id":249,"question_text":"A company is migrating mobile banking applications to run on Amazon EC2 instances in a VPC. Backend service applications run in an on-premises data center. The data center has an AWS Direct Connect connection into AWS. The applications that run in the VPC need to resolve DNS requests to an on-premises Active Directory domain that runs in the data center.\n\nWhich solution will meet these requirements with the LEAST administrative overhead?","answers_community":["C (100%)"],"timestamp":"2023-10-29 03:57:00","isMC":true,"answer":"C","topic":"1","answer_images":[],"question_images":[]},{"id":"6sdcMt5rInMljH7nPUWc","answer_ET":"B","answer_description":"","answers_community":["B (94%)","6%"],"unix_timestamp":1700594700,"timestamp":"2023-11-21 20:25:00","isMC":true,"answer_images":[],"question_text":"A company processes environmental data. The company has set up sensors to provide a continuous stream of data from different areas in a city. The data is available in JSON format.\n\nThe company wants to use an AWS solution to send the data to a database that does not require fixed schemas for storage. The data must be sent in real time.\n\nWhich solution will meet these requirements?","choices":{"C":"Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to send the data to Amazon Aurora.","A":"Use Amazon Kinesis Data Firehose to send the data to Amazon Redshift.","B":"Use Amazon Kinesis Data Streams to send the data to Amazon DynamoDB.","D":"Use Amazon Kinesis Data Firehose to send the data to Amazon Keyspaces (for Apache Cassandra)."},"answer":"B","question_images":[],"exam_id":33,"topic":"1","question_id":250,"url":"https://www.examtopics.com/discussions/amazon/view/126753-exam-aws-certified-solutions-architect-professional-sap-c02/","discussion":[{"timestamp":"1701181440.0","comment_id":"1082641","upvote_count":"9","content":"Selected Answer: B\nKinesis Data streams is real-time. Firehose is near real-time. DynamDB is not a relational DB and does not enforce fixed schemas on its tables. Answer is B","poster":"shaaam80"},{"poster":"FZA24","timestamp":"1737100200.0","comments":[{"poster":"GabrielShiao","upvote_count":"1","timestamp":"1737420120.0","comment_id":"1343943","content":"There is no exact correct answer. B is the only the incomplete approach"}],"comment_id":"1342039","content":"Selected Answer: B\nOk B but there is not built-in directly connector between KDS and DynamoDB. All designs show a Lambda between them. Any link to illustrate this design?","upvote_count":"2"},{"timestamp":"1731900300.0","poster":"AzureDP900","upvote_count":"1","comment_id":"1313810","content":"B is correct\nAmazon DynamoDB is designed to handle high-traffic, real-time data streams and can store JSON-formatted data without requiring fixed schemas.\nKinesis Data Streams can capture and transform the data in real-time, and by sending it directly to DynamoDB, you can leverage DynamoDB's NoSQL key-value store with flexible schema support.\nIn fact, using Kinesis Data Streams to feed DynamoDB is a common pattern for building scalable, high-traffic applications that require real-time data processing."},{"content":"Selected Answer: D\nBy using Amazon Kinesis Data Firehose to send the data to Amazon Keyspaces, the company can efficiently stream real-time data and store it in a schema-less database, meeting the requirement for flexibility and real-time processing.\n\nOption B is not correct:\nWhile Amazon Kinesis Data Streams can handle real-time data, it does not directly integrate with Amazon DynamoDB. Additional steps are needed to process and insert the data into DynamoDB. Additionally, DynamoDB, though flexible, typically benefits from having a defined schema for efficient access patterns.","comments":[{"comment_id":"1267389","content":"just B","timestamp":"1723855500.0","poster":"helloworldabc","upvote_count":"2"}],"comment_id":"1242425","poster":"053081f","timestamp":"1720146120.0","upvote_count":"1"},{"poster":"anubha.agrahari","content":"B, Firehose+ DynamoDB \nhttps://aws.amazon.com/blogs/database/working-with-json-data-in-amazon-dynamodb/","timestamp":"1717337160.0","upvote_count":"2","comment_id":"1223174"},{"comment_id":"1222913","timestamp":"1717277160.0","content":"Option D - By using Amazon Kinesis Data Firehose to send the environmental data to Amazon Keyspaces (for Apache Cassandra), you can leverage a fully managed streaming data ingestion service and a schema-flexible NoSQL database, meeting the requirements for real-time processing and storage of data without a fixed schema.","upvote_count":"1","poster":"9f02c8d"},{"upvote_count":"2","timestamp":"1705091280.0","poster":"vibzr2023","comment_id":"1121097","content":"Answer: B\nOption B leverages the strengths of both Kinesis Data Streams and DynamoDB to provide a scalable and real-time solution for ingesting and storing JSON-format data without fixed schemas.\nOption A: Kinesis Data Firehose: While suitable for real-time data delivery, it has a limited set of destinations, not including DynamoDB."},{"content":"Selected Answer: B\nOption B","comment_id":"1117700","timestamp":"1704819480.0","poster":"career360guru","upvote_count":"1"},{"comment_id":"1080205","upvote_count":"2","content":"Selected Answer: B\nCorrect B","timestamp":"1700933820.0","poster":"devalenzuela86"},{"upvote_count":"2","timestamp":"1700908680.0","comment_id":"1079926","poster":"salazar35","content":"Selected Answer: B\nLoad json format to DynamoDB"},{"timestamp":"1700661480.0","poster":"Totoroha","comment_id":"1077418","content":"Correct is B\nAmazon DynamoDB: DynamoDB is a NoSQL database service provided by AWS that does not require fixed schemas","upvote_count":"3"},{"timestamp":"1700633580.0","comment_id":"1076972","poster":"career360guru","content":"Selected Answer: B\nB is right option. D is not correct because Firehose can not write to Keyspaces.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1700594700.0","comment_id":"1076581","content":"Correct is B","poster":"cypkir"}]}],"exam":{"isBeta":false,"isMCOnly":true,"provider":"Amazon","numberOfQuestions":529,"id":33,"isImplemented":true,"name":"AWS Certified Solutions Architect - Professional SAP-C02","lastUpdated":"11 Apr 2025"},"currentPage":50},"__N_SSP":true}