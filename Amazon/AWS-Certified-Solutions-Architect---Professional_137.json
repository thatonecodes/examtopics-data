{"pageProps":{"questions":[{"id":"WgcFPyBbe7hjGfG2YtM2","topic":"1","choices":{"D":"Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Configure CloudTrail in each member account to deliver log events to the central S3 bucket.","B":"Configure CloudTrail in each member account to deliver log events to a central S3 bucket. Ensure the central S3 bucket policy allows PutObject access from the member accounts. Migrate existing logs to the central S3 bucket. Set up an Amazon CloudWatch alarm to alert if CloudTrail is not configured properly.","C":"Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Migrate the existing CloudTrail logs from each member account to the central S3 bucket. Delete the existing CloudTrail and logs in the member accounts.","A":"Create an AWS Lambda function in each member account with a cross-account role. Trigger the Lambda functions when new CloudTrail logs are created and copy the CloudTrail logs to a centralized S3 bucket. Set up an Amazon CloudWatch alarm to alert if CloudTrail is not configured properly."},"answer":"C","unix_timestamp":1616039700,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/47622-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"discussion":[{"poster":"kalyan_krishna742020","content":"I think answer is C. \nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","timestamp":"1632566340.0","upvote_count":"15","comment_id":"316711"},{"content":"C is correct \nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html\nsee section Best practices for moving from member account trails to organization trails why delete the existing CloudTrail and logs in the member accounts \nThanks to kalyan_krishna742020 providing official AWS link","poster":"ExtHo","timestamp":"1633925220.0","comment_id":"329993","upvote_count":"9"},{"upvote_count":"1","timestamp":"1702712520.0","poster":"sumaju","content":"Selected Answer: C\nOrg Trail is the option. Now between C and D, when Org Trail is created, it automatically configured for all member accounts. \"Configure CloudTrail in each member account to deliver log events to the central S3 bucket\" line in the option \"D\" is incorrect.\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-an-organizational-trail-best-practice.html","comment_id":"1097990"},{"poster":"dev112233xx","content":"Selected Answer: C\n\"Best practices for moving from member account trails to organization trails\"\nwait one day then DELETE the account trail\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-an-organizational-trail-best-practice.html","timestamp":"1681759440.0","upvote_count":"1","comment_id":"873029"},{"timestamp":"1661049360.0","upvote_count":"2","comment_id":"649581","content":"Selected Answer: C\nI think that consolidate Cloudtrail Log will stream logs all member accounts to parent accounts. If choose D, existing logs in member account still retain in S3 bucket member account. If choose C, existing logs in member account are migrated to S3 bucket central account.\nSo C will adhere to consolidate logging approach! --> Answer is C","poster":"Kyperos"},{"timestamp":"1660143300.0","poster":"Andykris","comment_id":"645041","content":"B & C is deleting existing logs which defeats the requirements. D is the answer","upvote_count":"2"},{"upvote_count":"1","content":"Selected Answer: C\nHave to choose C.\nThe \"most operationally efficient solution\" is to create 1 org trail which capture and send events to a central bucket- deploy it on all member accounts - move old member accounts logs to the central buckets and delete them. see below link:\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","comment_id":"628803","timestamp":"1657289580.0","poster":"asfsdfsdf"},{"poster":"ksaru","content":"People those answered C - note that the question states that logs must be retained in the member account S3 buckets and this option deletes them.\nHence, D is correct.","comments":[{"content":"The logs should not be lost, so you copy them to the centralized bucket. Then there is no more need for them in the member accounts. The question does not state that they must remain in the member accounts. The answer is C.","poster":"sb333","timestamp":"1665501540.0","comment_id":"692216","upvote_count":"3"}],"timestamp":"1657102560.0","upvote_count":"2","comment_id":"627820"},{"upvote_count":"1","timestamp":"1656243720.0","content":"Selected Answer: C\nAgree with C.","poster":"kangtamo","comment_id":"622520"},{"upvote_count":"2","poster":"TechIsi","timestamp":"1651309980.0","content":"Correct answer is C, when you create an organizational trail and specify a bucket, all account trails are automatically configured to send to that bucket. You also have to configure the bucket policy to allow put action for all the accounts.","comment_id":"594931"},{"timestamp":"1649821320.0","poster":"westcon","content":"DDD\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","comment_id":"584977","upvote_count":"1"},{"content":"Selected Answer: D\nD. Configure an organization-level CloudTrail in the parent account to deliver log events to a central S3 bucket. Configure CloudTrail in each member account to deliver log events to the central S3 bucket.","poster":"jj22222","upvote_count":"1","comment_id":"578123","timestamp":"1648626180.0"},{"poster":"lifebegins","comment_id":"553641","content":"Sorry Dear Friends, Answer is C.\nWe can created the CloudTrail in Parent Account and the set the level to Entire Orgranization, Automatically Cloud Trail applied to all member accounts.\n\nWhen i practically done, I understand the Truth. \nAnswer is C:","timestamp":"1645531020.0","upvote_count":"1"},{"upvote_count":"2","timestamp":"1645530300.0","poster":"lifebegins","content":"Answer B: \nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-receive-logs-from-multiple-accounts.html\n\nCloud Trail cannot manage the logs for others. Only Destination bucket can be shared centrally","comment_id":"553632"},{"content":"Answer is B:\n\nhttps://d0.awsstatic.com/aws-answers/AWS_Multi_Account_Security_Strategy.pdf\n\nRefer Logging Account Structure","timestamp":"1645529940.0","comment_id":"553626","upvote_count":"1","poster":"lifebegins"},{"poster":"Yardenfayer","timestamp":"1645457400.0","content":"its D\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-receive-logs-from-multiple-accounts.html","upvote_count":"1","comment_id":"552957"},{"poster":"futen0326","comment_id":"550773","timestamp":"1645259940.0","content":"Selected Answer: D\nIt's D. Question explicitly states that the logs in the member accounts should not be lost. Deleting them does exactly that.","comments":[{"comment_id":"561360","content":"thought that as well BUT answer c says to migrate the existing logs to central s3 bucket so it wouldn't be lost and i believe enabling cloud trail(whole organization) in the central account is enough and you don't need to do it in each account","timestamp":"1646475780.0","upvote_count":"1","poster":"Alvindo"}],"upvote_count":"1"},{"comment_id":"536842","content":"My answer is C. \nWe don't need to use Lambda function to move logs...\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-receive-logs-from-multiple-accounts.html","upvote_count":"1","timestamp":"1643625960.0","poster":"HellGate"},{"poster":"AzureDP900","comment_id":"496972","content":"I will go with C","timestamp":"1638982860.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"446941","content":"It's C - trail organization","poster":"andylogan","timestamp":"1636254480.0"},{"timestamp":"1636214460.0","content":"C\n---\nWhen you have two trails, you incur higher costs because of the additional copy of events delivered to the organization trail.\n\nTo help manage costs, but avoid losing events before log delivery starts on the organization trail, consider keeping both your individual member account trails and your organization trail for up to one day. This ensures that the organization trail logs all events, but you incur duplicate event costs only for one day. After the first day, you can stop logging on (or delete) any individual member account trails.\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","upvote_count":"2","poster":"student22","comment_id":"442689"},{"comments":[{"timestamp":"1636087560.0","comment_id":"439647","poster":"student22","upvote_count":"2","content":"I think the correct answer is C\nWhen it mentions 'Delete the existing CloudTrail .... in the member accounts' it's referring to the original CloudTrail in the member account."}],"content":"A wrong - this is not way we manage cross-account CT\nC wrong - when you create organization-level CloudTrail it will create TRAILS in CloudTrail for each monitored account - therefore you must not delete CloudTrail in those accounts. The answer states: Delete the existing CloudTrail .... in the member accounts\nD wrong - there is no reason to mix organization-level CT with account-level CT. They will do the same thing. Answer doesn't mention required permissions.\n\nI would go with B - we are using this configuration for every customer that has more accounts but doesn't user Organization. Trails in CT should point to central S3 bucket with proper permissions check: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-receive-logs-from-multiple-accounts.html","upvote_count":"3","timestamp":"1635762300.0","poster":"DerekKey","comment_id":"439284"},{"timestamp":"1635054000.0","poster":"tgv","comment_id":"436566","upvote_count":"1","content":"CCC\n---"},{"timestamp":"1634961300.0","content":"I'll go with C","comment_id":"414004","poster":"WhyIronMan","upvote_count":"2"},{"poster":"DashL","content":"D\nThe statement \"Existing logs currently stored in Amazon S3 buckets in each individual member account should not be lost\" looks like it is required to leave the existing logs as is. Option D is the only answer which leaves the existing logs as is.","comment_id":"398606","timestamp":"1634949120.0","upvote_count":"3"},{"poster":"hk436","content":"c is my answer!","timestamp":"1634445120.0","upvote_count":"1","comment_id":"385626"},{"upvote_count":"1","poster":"Waiweng","timestamp":"1634277360.0","content":"it's C","comment_id":"357765"},{"comment_id":"346306","content":"C for sure.","upvote_count":"2","poster":"Amitv2706","timestamp":"1634221200.0"},{"content":"C is the correct answer","poster":"blackgamer","timestamp":"1634090100.0","upvote_count":"1","comment_id":"343344"},{"content":"C is the correct answer for me","comment_id":"334465","upvote_count":"2","poster":"Ziegler","timestamp":"1634052960.0"},{"upvote_count":"2","timestamp":"1633622460.0","comment_id":"329405","poster":"Pupu86","content":"Option C is the closest despite the statement - delete cloudtrail logs"},{"comment_id":"318608","upvote_count":"2","timestamp":"1632773520.0","content":"I think the answer is B. Because C cannot meet the requirement \" Existing logs currently stored in Amazon S3 buckets in each individual member account should not be lost.\" it will delete the existing log in the member account for C. so the answer is B","comments":[{"content":"However, users in member accounts will not have sufficient permissions to delete the organization trail, turn logging on or off, change what types of events are logged, or otherwise alter the organization trail in any way.","poster":"tiffanny","comment_id":"323510","timestamp":"1633327980.0","upvote_count":"1"},{"poster":"ExtHo","timestamp":"1633647360.0","comment_id":"329984","content":"First Migrate the existing CloudTrail logs from each member account to the central S3\nbucket so all member account logs are in central bucket and Delete the existing CloudTrail and logs in the member accounts this will fulfill condition \"should not lost\"","upvote_count":"5"}],"poster":"eji"},{"poster":"ItsmeP","comment_id":"317307","upvote_count":"2","content":"C is not correct as Migrate existing logs to the central S3 bucket also a requirement.","timestamp":"1632675960.0"},{"content":"should it be C?\n------ https://docs.aws.amazon.com/organizations/latest/userguide/services-that-can-integrate-cloudtrail.html -------\nUsing AWS CloudTrail, a user in a management account can create an organization trail that logs all events for all AWS accounts in that organization. Organization trails are automatically applied to all member accounts in the organization. Member accounts can see the organization trail, but can't modify or delete it. By default, member accounts don't have access to the log files for the organization trail in the Amazon S3 bucket. This helps you uniformly apply and enforce your event logging strategy across the accounts in your organization.","timestamp":"1632579240.0","poster":"KevinZhong","comment_id":"317017","upvote_count":"3"},{"poster":"SD13","content":"Correct Answer : C\nConfiguring the organization trail is a better option since it will start logging for new accounts automatically. A & B is missing this condition. D is not correct since the configuration of organizational trail needs to be done at the master account, not on all member accounts, member account has only read-only permission to see the settings not changing it.","upvote_count":"6","timestamp":"1632314040.0","comment_id":"316516","comments":[{"timestamp":"1647027540.0","upvote_count":"2","poster":"razerlg","content":"You are definetly right. From AWS docs:\n\nIf an AWS account is added to an organization, the organization trail and service-linked role will be added to that AWS account, and logging will begin for that account automatically in the organization trail.\n\nC , and not B, is allowing for this solution to scale automatically with new accounts added to the Organization. In B you would have to manually create new trail + update the central bucket policy","comment_id":"565765"}]},{"upvote_count":"3","content":"B is correct","timestamp":"1632254280.0","comment_id":"315752","poster":"ItsmeP"},{"content":"A is okay","comment_id":"315492","timestamp":"1632205380.0","poster":"awsnoob","upvote_count":"1"},{"comments":[{"content":"C is better answer, sums it up https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html","poster":"nitinz","comment_id":"319556","comments":[{"comment_id":"439279","content":"You are completely wrong. Read the content of that page again and than read answer C.","poster":"DerekKey","timestamp":"1635091260.0","upvote_count":"1"}],"timestamp":"1633186320.0","upvote_count":"3"}],"comment_id":"313787","upvote_count":"2","poster":"nitinz","content":"I think B is better option.","timestamp":"1632181260.0"}],"timestamp":"2021-03-18 04:55:00","question_id":681,"question_text":"A company uses AWS Organizations to manage one parent account and nine member accounts. The number of member accounts is expected to grow as the business grows. A security engineer has requested consolidation of AWS CloudTrail logs into the parent account for compliance purposes. Existing logs currently stored in Amazon S3 buckets in each individual member account should not be lost. Future member accounts should comply with the logging strategy.\nWhich operationally efficient solution meets these requirements?","answers_community":["C (75%)","D (25%)"],"question_images":[],"isMC":true,"answer_ET":"C","exam_id":32},{"id":"yC7Il6cgOUaEjvC2wWLu","answer":"BD","isMC":true,"question_text":"A weather service provides high-resolution weather maps from a web application hosted on AWS in the eu-west-1 Region. The weather maps are updated frequently and stored in Amazon S3 along with static HTML content. The web application is fronted by Amazon CloudFront.\nThe company recently expanded to serve users in the us-east-1 Region, and these new users report that viewing their respective weather maps is slow from time to time.\nWhich combination of steps will resolve the us-east-1 performance issues? (Choose two.)","answers_community":["BD (100%)"],"answer_ET":"BD","topic":"1","question_id":682,"choices":{"A":"Configure the AWS Global Accelerator endpoint for the S3 bucket in eu-west-1. Configure endpoint groups for TCP ports 80 and 443 in us-east-1.","D":"Use Lambda@Edge to modify requests from North America to use the S3 bucket in us-east-1.","C":"Use Lambda@Edge to modify requests from North America to use the S3 Transfer Acceleration endpoint in us-east-1.","B":"Create a new S3 bucket in us-east-1. Configure S3 cross-Region replication to synchronize from the S3 bucket in eu-west-1.","E":"Configure the AWS Global Accelerator endpoint for us-east-1 as an origin on the CloudFront distribution. Use Lambda@Edge to modify requests from North America to use the new origin."},"timestamp":"2021-03-17 15:02:00","discussion":[{"upvote_count":"25","timestamp":"1632252540.0","poster":"wasabidev","comment_id":"313333","comments":[{"poster":"nitinz","comment_id":"313790","timestamp":"1632611640.0","content":"i agree","upvote_count":"1"}],"content":"BD. with replication there is not more need to use S3 Transfer Acceleration"},{"upvote_count":"6","comments":[{"timestamp":"1633521120.0","upvote_count":"4","comments":[{"timestamp":"1633711440.0","content":"my bad, it's also can be used for download from s3. \nhttps://aws.amazon.com/blogs/aws/aws-storage-update-amazon-s3-transfer-acceleration-larger-snowballs-in-more-regions\nhowever, i still think it is not needed as the maps are updated frequently so caching should not help much.","upvote_count":"2","comment_id":"317660","poster":"certainly"}],"content":"sorry, upvoted by mistake. BD are correct. \nS3 Transfer Acceleration is for upload not download. https://aws.amazon.com/about-aws/whats-new/2016/04/transfer-files-into-amazon-s3-up-to-300-percent-faster/","poster":"certainly","comment_id":"317647"},{"timestamp":"1634017320.0","poster":"KevinZhong","content":"changed my mind to BD, seems it's not the case to use Transfer Acceleration\n------------------\nWhy use Transfer Acceleration?\nYou might want to use Transfer Acceleration on a bucket for various reasons:\n 1. Your customers upload to a centralized bucket from all over the world.\n 2. You transfer gigabytes to terabytes of data on a regular basis across continents.\n 3. You can't use all of your available bandwidth over the internet when uploading to Amazon S3.","comment_id":"320921","upvote_count":"9"}],"comment_id":"317028","poster":"KevinZhong","content":"BC\nSeems S3 Transfer Acceleration it better to work with Edge.\n-------------\nAmazon S3 Transfer Acceleration is a bucket-level feature that enables fast, easy, and secure transfers of files over long distances between your client and an S3 bucket. Transfer Acceleration takes advantage of the globally distributed edge locations in Amazon CloudFront.","timestamp":"1633119840.0"},{"upvote_count":"2","poster":"syaldram","content":"You can't use GA as the origin for CloudFront.","comment_id":"773445","timestamp":"1673527380.0"},{"poster":"tomosabc1","timestamp":"1665426840.0","comments":[{"poster":"tomosabc1","content":"Of course, BD surely resolves the issue in question, that is, these new users report that viewing their respective weather maps is slow from time to time. But it will create a new issue, which is the users in us-east-1 is always 15 minutes(or even 2 hours) slower than the users in eu-west-1 in seeing the updated weather data. That's not good.","timestamp":"1665427140.0","upvote_count":"1","comment_id":"691425"}],"upvote_count":"1","comment_id":"691422","content":"Similar to StanM's response, I don't think S3 cross region replication is a good fit for this scenario, as weather map are updated frequently. The CRR replication lag means that the users in us-east-1 is always 15 minutes(or even 2 hours) slower than the users in eu-west-1 in seeing the updated weather data, which doesn't sound right in a real world scenario.\n\nS3 CRR Replication Lag\nCross-Region Replication is an asynchronous process, and the objects are eventually replicated. Most objects replicate within 15 minutes, but sometimes replication can take a couple hours or more. \nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-crr-replication-time/\n\nCan anyone explain why AC is wrong?"},{"poster":"p2010","comments":[{"comment_id":"903386","content":"NO, you are wrong ,S3 transfer acceleration can speed up both for upload and download, \nhttps://aws.amazon.com/s3/transfer-acceleration/","upvote_count":"2","poster":"Jesuisleon","timestamp":"1684685820.0"}],"upvote_count":"3","comment_id":"605444","content":"Selected Answer: BD\nS3 Transfer Acceleration is for upload not download","timestamp":"1653220920.0"},{"timestamp":"1651873800.0","poster":"user0001","upvote_count":"1","content":"C is wrong, you can't configure o use the S3 Transfer Acceleration endpoint in us-east-1","comment_id":"597898"},{"poster":"kenchou73","comment_id":"569703","timestamp":"1647519240.0","upvote_count":"1","content":"Selected Answer: BD\nhttps://aws.amazon.com/blogs/apn/using-amazon-cloudfront-with-multi-region-amazon-s3-origins/"},{"upvote_count":"1","content":"Selected Answer: BD\nANS: BD are correct, C is use for data upload to local region or nearest region and from there it will transfer to destination bucket using aws backbone","comment_id":"568805","timestamp":"1647411840.0","poster":"RVD"},{"poster":"AzureDP900","comment_id":"496977","upvote_count":"1","content":"I'll go with B, D","timestamp":"1638983280.0"},{"content":"B. Create a new S3 bucket in us-east-1. Configure S3 cross-Region replication to synchronize from the S3 bucket in eu-west-1.\nD. Use Lambda@Edge to modify requests from North America to use the S3 bucket in us-east-1.","timestamp":"1638705360.0","poster":"cldy","comment_id":"494290","upvote_count":"1"},{"timestamp":"1637388960.0","poster":"backfringe","content":"B and D","comment_id":"482286","upvote_count":"2"},{"content":"It's B D - since S3 Transfer Acceleration for transferring of files over long distances\nthis case we need replica and Lambda@Edge","comment_id":"446948","upvote_count":"1","timestamp":"1635941280.0","poster":"andylogan"},{"upvote_count":"4","content":"B&D correct. see also\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/dynamically-route-viewer-requests-to-any-origin-using-lambdaedge/","timestamp":"1635899580.0","comment_id":"439699","poster":"DerekKey"},{"comment_id":"438366","content":"B,D Company that has implemented the same scenarios says:\n\nTo serve content from these other regions, we need to route requests to the different Amazon S3 buckets we’re using. In this post, we explore how to accomplished this by using Amazon CloudFront as a content delivery network and Lambda@Edge as a router. We will also take a quick look at how this impacts latency and cost.\n\nReference : https://aws.amazon.com/blogs/apn/using-amazon-cloudfront-with-multi-region-amazon-s3-origins/","timestamp":"1635587280.0","upvote_count":"1","poster":"Kopa"},{"comment_id":"436570","timestamp":"1635493200.0","upvote_count":"1","poster":"tgv","content":"BBB DDD\n---"},{"content":"B and D for sure.","timestamp":"1635361200.0","upvote_count":"1","comment_id":"434012","poster":"blackgamer"},{"timestamp":"1635220440.0","upvote_count":"1","comment_id":"414008","content":"I'll go with B, D","poster":"WhyIronMan"},{"poster":"Waiweng","timestamp":"1634791080.0","comment_id":"383993","content":"it's B,D","upvote_count":"2"},{"upvote_count":"2","comment_id":"366361","timestamp":"1634480820.0","poster":"pradhyumna","content":"B and C, Transfer acceleration can help with downloads too, https://aws.amazon.com/blogs/aws/aws-storage-update-amazon-s3-transfer-acceleration-larger-snowballs-in-more-regions"},{"comments":[{"poster":"DashL","upvote_count":"2","comment_id":"398609","content":"The question says viewing is slow - not that the users are seeing outdated weather maps. So, the answer will be D.","timestamp":"1635011340.0"}],"timestamp":"1634460660.0","comment_id":"353481","upvote_count":"1","poster":"StanM","content":"The question says that 'The weather maps are updated frequently'.\nS3 replication takes up to 15 mins or even more:\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-object-replication-time/\nAs such the 'BD' is not the way to go."},{"comments":[{"comment_id":"463661","upvote_count":"3","timestamp":"1636137300.0","content":"Global Accelerator is to get your app performing as if it were CloudFront, but for apps that aren't using CloudFront, and without the caching layer. The users' TCP connections will terminate on endpoints at the closest AWS Edge location closest to them and they experience slightly better performance when talking to the Origin.\n\nIt's like TCP Optimization / WAN Optimization (e.g. Riverbed, Cisco WAAS, FatPipe) to get increased performance from a remote site over a WAN circuit to an on-prem data center. (But in this analogy the remote site is the AWS Edge location, and the on-prem DC is your VPC.) It won't be as good as caching with CloudFront, but it'll be an improvement over backhauling all the way to a distant origin without Global Accelerator.\n\nIn this case you don't need that because you ARE using CloudFront and can get the full benefits of the caching layer AND local TCP termination at the AWS Edge locations that it provides. B&D will get you there.","poster":"kirrim"}],"content":"Not sure anymore. Why not BE?","upvote_count":"2","timestamp":"1634390280.0","poster":"CarisB","comment_id":"338949"},{"upvote_count":"4","comment_id":"338595","poster":"CarisB","timestamp":"1634038140.0","content":"BD\nMy first thought was AC, but after reading comments and https://aws.amazon.com/blogs/apn/using-amazon-cloudfront-with-multi-region-amazon-s3-origins/, I think BD is correct."},{"comment_id":"317404","timestamp":"1633167300.0","content":"Agree with BC","upvote_count":"2","poster":"aws_master"}],"question_images":[],"exam_id":32,"answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/47536-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1615989720},{"id":"LsbtYhJNpq9N082wuQIb","choices":{"D":"Provision Amazon EBS encrypted volumes using AWS KMS.","C":"Provision Amazon EBS encrypted volumes using AWS KMS and ensure explicit encryption of data when writing to Amazon EBS.","B":"Acquire a public certificate from a third-party vendor and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.","E":"Use SSL or encrypt data while communicating with the external system using a VPN.","F":"Communicate with the external system using plaintext and use the VPN to encrypt the data in transit.","A":"Create a public certificate for the required domain in AWS Certificate Manager and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances."},"answers_community":["BDE (100%)"],"question_images":[],"question_text":"A company is deploying a public-facing global application on AWS using Amazon CloudFront. The application communicates with an external system. A solutions architect needs to ensure the data is secured during end-to-end transit and at rest.\nWhich combination of steps will satisfy these requirements? (Choose three.)","unix_timestamp":1616041980,"question_id":683,"exam_id":32,"timestamp":"2021-03-18 05:33:00","answer_description":"","answer":"BDE","discussion":[{"timestamp":"1632728400.0","comments":[{"timestamp":"1633222440.0","upvote_count":"1","comment_id":"317666","poster":"certainly","content":"I Agree. explicit encryption on top of EBS encryption with KMS just sounds weird"},{"comments":[{"content":"A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-services.html","upvote_count":"18","poster":"WhyIronMan","comment_id":"414010","timestamp":"1634781360.0"}],"comment_id":"403032","poster":"tuananhngo","content":"A IS BETTER THAN B","timestamp":"1634461980.0","upvote_count":"3"}],"comment_id":"316534","upvote_count":"17","poster":"SD13","content":"Correct Options: BDE\nC is asking for explicit encryption on top of EBS encryption with KMS, I believe it's not needed."},{"comment_id":"318612","poster":"eji","timestamp":"1633336980.0","content":"BDE for me, we cannot use \"public\" certificate for ec2 from amazon certificate manager, so A cannot be the answer. and for C i agree with SD13 i think explicit encryption it's not needed","upvote_count":"9"},{"timestamp":"1667956740.0","content":"vote BDE","poster":"due","upvote_count":"1","comment_id":"714201"},{"poster":"dcdcdc3","comment_id":"679926","upvote_count":"1","content":"IRL we use self-signed cert between LB and the ec2 (or private from ACM). The way the answer is written A cannot be true.","timestamp":"1664208180.0"},{"poster":"cldy","comment_id":"496796","content":"B. Acquire a public certificate from a third-party vendor and deploy it to CloudFront, an Application Load Balancer, and Amazon EC2 instances.\nD. Provision Amazon EBS encrypted volumes using AWS KMS.\nE. Use SSL or encrypt data while communicating with the external system using a VPN.","timestamp":"1638965280.0","upvote_count":"1"},{"comment_id":"484030","timestamp":"1637572740.0","content":"Selected Answer: BDE\nA is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-services.html\nC is asking for explicit encryption on top of EBS encryption with KMS, I believe it's not needed.","upvote_count":"2","poster":"acloudguru"},{"comment_id":"459431","content":"B,D,E\n---\nQ: With which AWS services can I use ACM certificates?\n\nYou can use public and private ACM certificates with the following AWS services:\n• Elastic Load Balancing – Refer to the Elastic Load Balancing documentation\n• Amazon CloudFront – Refer to the CloudFront documentation\n• Amazon API Gateway – Refer to the API Gateway documentation\n• AWS Elastic Beanstalk – Refer to the AWS Elastic Beanstalk documentation\n• AWS CloudFormation – Support is currently limited to public certificates that use email validation. Refer to the AWS CloudFormation documentation \n\nIn addition, you can use private certificates issued with ACM Private CA with EC2 instances, containers, IoT devices, and on your own servers.\n\nhttps://aws.amazon.com/certificate-manager/faqs/?nc1=h_ls","poster":"student22","upvote_count":"3","timestamp":"1636287780.0"},{"comment_id":"446958","poster":"andylogan","timestamp":"1636049640.0","upvote_count":"1","content":"It's B D E"},{"comment_id":"435312","poster":"tgv","upvote_count":"1","timestamp":"1635937380.0","content":"BBB DDD EEE\n---\nhttps://aws.amazon.com/certificate-manager/faqs/"},{"content":"BDE is correct.","comment_id":"434016","poster":"blackgamer","upvote_count":"1","timestamp":"1635844500.0"},{"upvote_count":"3","poster":"WhyIronMan","comment_id":"414009","content":"I'll go with B,D,E\n\nQ: Can I use certificates on Amazon EC2 instances or on my own servers?\n\nYou can use private certificates issued with ACM Private CA with EC2 instances, containers, and on your own servers. At this time, public ACM certificates can be used only with specific AWS services. See With which AWS services can I use ACM certificates?\n\nhttps://aws.amazon.com/certificate-manager/faqs/?nc1=h_ls","timestamp":"1634633820.0"},{"poster":"DashL","upvote_count":"4","content":"BDE\nFor those answering ADE:\nHTTPS between viewers and CloudFront – You can use a certificate that was issued by a trusted certificate authority (CA) such as Comodo, DigiCert, or Symantec, or you can use a certificate provided by AWS Certificate Manager (ACM).\nHTTPS between CloudFront and a custom origin – If the origin is not an Elastic Load Balancing (ELB) load balancer, such as Amazon EC2, the certificate must be issued by a trusted CA such as Comodo, DigiCert, or Symantec. If your origin is an ELB load balancer, you can also use a certificate provided by ACM.\nFor SSL Between ELB and EC2: Amazon-issued certificates can’t be installed on an EC2 instance. To enable end-to-end encryption, you must use a third-party SSL certificate. Install the third-party certificate on an EC2 instance. Then, associate the third-party certificate with a load balancer by importing it into AWS Certificate Manager (ACM) (https://aws.amazon.com/premiumsupport/knowledge-center/acm-ssl-certificate-ec2-elb/)\nThe requirement of 3rd party cert between ELB and EC2 makes Option A is invalid.","timestamp":"1634438220.0","comment_id":"398613"},{"upvote_count":"2","comment_id":"385628","poster":"hk436","timestamp":"1634408220.0","content":"BDE are my answers!!"},{"comments":[{"comment_id":"405274","content":"What about get-certificate . Doesn't it export cert with whole chain. For me it is still AC\nhttps://docs.aws.amazon.com/cli/latest/reference/acm/get-certificate.html","timestamp":"1634535960.0","poster":"ogryzek","upvote_count":"1"}],"poster":"chkmtess","content":"BDE\nExplanation for B - \"You can't export an Amazon Issued ACM public certificate for use on an EC2 instance because ACM manages the private key.\"\nhttps://aws.amazon.com/premiumsupport/knowledge-center/configure-acm-certificates-ec2/","upvote_count":"3","comment_id":"382900","timestamp":"1634367000.0"},{"poster":"TonyGe","content":"BED for sure.\nA is incorrect, public cert cannot be used in EC2.","timestamp":"1634323980.0","upvote_count":"2","comment_id":"381354"},{"comment_id":"380359","content":"You generate the certificate for CF. Answer is ADE.","poster":"ElreySham","timestamp":"1634116560.0","upvote_count":"1"},{"timestamp":"1634019660.0","content":"it's A,D,E","comment_id":"357778","comments":[{"content":"A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-services.html","upvote_count":"3","comment_id":"414011","timestamp":"1634844600.0","poster":"WhyIronMan"},{"poster":"Kopa","comment_id":"414480","upvote_count":"1","timestamp":"1635740640.0","content":"Can you please argument why its A? Thanks"}],"upvote_count":"3","poster":"Waiweng"},{"upvote_count":"1","poster":"tvs","content":"ACE - https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html , public certificates not available for EC2 instance.","comments":[{"comments":[{"upvote_count":"3","timestamp":"1633964700.0","comment_id":"355391","content":"Sorry typo BDE","poster":"tvs"}],"upvote_count":"1","timestamp":"1633854300.0","content":"I mean ADE","poster":"tvs","comment_id":"355390"}],"timestamp":"1633745880.0","comment_id":"355388"},{"poster":"cnethers","content":"I would vote ADE\nA - unless you want to use your own certificates the best is to use an AWS service \nD - explicit encryption is not required with KMS https://aws.amazon.com/blogs/compute/must-know-best-practices-for-amazon-ebs-encryption/\nE - This is the option you would use to communicate to the external system to meet the in transit requirement.\nB - is not wrong but there is no requirement to asking for that so certificate manager will do just fine. \nC - Read the link above to understand when explicit encryption is required.\nF - this does not meet the requirement to encrypt the data even though the VPN is a secure tunnel.","timestamp":"1633420080.0","comments":[{"timestamp":"1634896080.0","comment_id":"414012","poster":"WhyIronMan","upvote_count":"3","content":"A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-services.html"}],"comment_id":"324097","upvote_count":"5"},{"comment_id":"317415","content":"ADE for me.\nBetween A and B i choose A (certificate from AWS more prefer that from 3-rd party vendor)\nD - KMS for EBS is fine. For transit encryption - check E.\nE- ssl is fine for communication between the systems (internal or external)","comments":[{"poster":"WhyIronMan","upvote_count":"1","timestamp":"1634970240.0","comment_id":"414013","content":"A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-services.html"}],"timestamp":"1633187940.0","poster":"aws_master","upvote_count":"4"},{"comment_id":"317296","timestamp":"1633129860.0","upvote_count":"1","comments":[{"content":"A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-services.html","timestamp":"1635025440.0","upvote_count":"1","comment_id":"414014","poster":"WhyIronMan"}],"poster":"ItsmeP","content":"ACE is correct., In A ACM is creating certificate, further we are applying certificate to CloudFront, an Application Load Balancer, and Amazon EC2 only without ACM."},{"comments":[{"upvote_count":"1","comment_id":"315508","comments":[{"comment_id":"316574","upvote_count":"1","poster":"trap","content":"Can AWS Certificate Manager deploy its certificates on EC2 instances?","timestamp":"1632870180.0","comments":[{"upvote_count":"1","comment_id":"414015","poster":"WhyIronMan","content":"A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-services.html","timestamp":"1635180060.0"},{"timestamp":"1633462140.0","comment_id":"334761","poster":"sarah_t","upvote_count":"1","content":"Turns out: no \n(well, almost: it works on Nitro enclaves but that's not the case here)"}]},{"upvote_count":"3","timestamp":"1633024740.0","poster":"awsnoob","comment_id":"316772","content":"BCE, as trap mention: AWS CM cannot deploy on EC2"}],"content":"nvm it should be ACE","timestamp":"1632637800.0","poster":"awsnoob"}],"content":"The application communicates with an external system... It should be BCE?","comment_id":"315502","timestamp":"1632543360.0","poster":"awsnoob","upvote_count":"1"},{"upvote_count":"1","content":"ACE makes sense","timestamp":"1632149880.0","comments":[{"upvote_count":"2","comments":[{"comments":[{"content":"your link says: no, you need to use a supported service like a ALB or cloudfront","comment_id":"334762","timestamp":"1633669980.0","poster":"sarah_t","upvote_count":"3"}],"upvote_count":"1","content":"Ya, https://aws.amazon.com/premiumsupport/knowledge-center/configure-acm-certificates-ec2/","comment_id":"316771","poster":"awsnoob","timestamp":"1632952140.0"},{"upvote_count":"1","poster":"KevinZhong","comment_id":"317033","timestamp":"1633116300.0","content":"https://aws.amazon.com/certificate-manager/faqs/?nc1=h_ls\nIn addition to using private certificates with ACM-integrated services, you can also use private certificates on EC2 instances, on ECS containers, or anywhere. See Private Certificates for more details.","comments":[{"content":"A is wrong because public ACM certificates can be used only with specific AWS services. EC2 is not included\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-services.html","timestamp":"1635650940.0","upvote_count":"1","comment_id":"414017","poster":"WhyIronMan"}]}],"content":"A is wrong. AWS Certificate Manager cannot deploy certificate on EC2 instances","timestamp":"1632514980.0","comment_id":"315070","poster":"trap"}],"comment_id":"313806","poster":"nitinz"}],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/47624-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"answer_ET":"ACE","topic":"1"},{"id":"FSg3jKv9dauxYzCLeF3c","choices":{"C":"Create a VPC peering connection from each business unit VPC to the shared VPC. Accept the VPC peering connections from the shared VPC console. Configure VPC routing tables to send traffic to the VPC peering connection.","B":"Create a VPC endpoint service using the centralized application NLB and enable the option to require endpoint acceptance. Create a VPC endpoint in each of the business unit VPCs using the service name of the endpoint service. Accept authorized endpoint requests from the endpoint service console.","A":"Create an AWS Transit Gateway. Attach the shared VPC and the authorized business unit VPCs to the transit gateway. Create a single transit gateway route table and associate it with all of the attached VPCs. Allow automatic propagation of routes from the attachments into the route table. Configure VPC routing tables to send traffic to the transit gateway.","D":"Configure a virtual private gateway for the shared VPC and create customer gateways for each of the authorized business unit VPCs. Establish a Site-to-Site VPN connection from the business unit VPCs to the shared VPC. Configure VPC routing tables to send traffic to the VPN connection."},"answers_community":["B (100%)"],"question_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/46708-exam-aws-certified-solutions-architect-professional-topic-1/","answer_ET":"B","exam_id":32,"timestamp":"2021-03-12 14:24:00","isMC":true,"answer":"B","unix_timestamp":1615555440,"discussion":[{"comment_id":"313141","poster":"wasabidev","content":"B. Transit Gateway doesn't support routing between VPC with identical CIDRs","upvote_count":"19","timestamp":"1633043100.0","comments":[{"upvote_count":"3","poster":"DashL","content":"Amazon Transit Gateway doesn’t support routing between Amazon VPCs with overlapping CIDRs. If you attach a new Amazon VPC that has a CIDR which overlaps with an already attached Amazon VPC, Amazon Transit Gateway will not propagate the new Amazon VPC route into the Amazon Transit Gateway route table.","timestamp":"1633811940.0","comment_id":"398620"}]},{"poster":"tvs","content":"B. Use NLB VPC endpoint service name overcome CIDR overlap issues.","timestamp":"1634173020.0","comments":[{"timestamp":"1635070080.0","comment_id":"463666","content":"Agree!\n\nNLBs always SNAT the client source IP address to their own IP within your VPC when the incoming request to the NLB via a gateway load balancer endpoint or vpc endpoint (private link):\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#client-ip-preservation\n\n(This can be annoying if you want the NLB's client IP preservation feature!)","poster":"kirrim","upvote_count":"3"}],"comment_id":"430603","upvote_count":"8"},{"comment_id":"628807","upvote_count":"2","content":"Selected Answer: B\nB - classic use cased for PrivateLink (NLB +EP) all other options are out due to overlapping CIDRs not possible to route it","timestamp":"1657290000.0","poster":"asfsdfsdf"},{"timestamp":"1641012540.0","poster":"cldy","content":"B correct.","upvote_count":"1","comment_id":"514362"},{"content":"I'll go with B","upvote_count":"1","timestamp":"1638983460.0","comment_id":"496979","poster":"AzureDP900"},{"comment_id":"491033","content":"Selected Answer: B\nA is not useful for overlap CIDR. B, use NLB's vpc endpoint","upvote_count":"1","poster":"acloudguru","timestamp":"1638311400.0"},{"content":"BBB\n---","comment_id":"436574","timestamp":"1635028620.0","upvote_count":"2","poster":"tgv"},{"poster":"blackgamer","comment_id":"434034","upvote_count":"1","timestamp":"1634691180.0","content":"It is B"},{"content":"I'll go with B","poster":"WhyIronMan","timestamp":"1634155200.0","upvote_count":"2","comment_id":"414019"},{"timestamp":"1633611660.0","comment_id":"357786","content":"it's B","poster":"Waiweng","upvote_count":"3"},{"comment_id":"317419","poster":"aws_master","timestamp":"1633386000.0","content":"B for sure","upvote_count":"3"},{"upvote_count":"2","comment_id":"316542","timestamp":"1633112400.0","content":"Correct option : B","poster":"SD13"},{"timestamp":"1632546360.0","upvote_count":"5","comment_id":"313130","content":"Yes, B","poster":"gm"},{"poster":"kalyan_krishna742020","comment_id":"308871","timestamp":"1632117960.0","content":"Ans: C\nhttps://docs.aws.amazon.com/vpc/latest/peering/peering-configurations-partial-access.html","comments":[{"upvote_count":"8","timestamp":"1632266700.0","poster":"kalyan_krishna742020","content":"My bad.. it is B. \nhttps://aws.amazon.com/blogs/networking-and-content-delivery/how-to-securely-publish-internet-applications-at-scale-using-application-load-balancer-and-aws-privatelink/","comment_id":"308874"}],"upvote_count":"3"}],"question_text":"A company provides a centralized Amazon EC2 application hosted in a single shared VPC. The centralized application must be accessible from client applications running in the VPCs of other business units. The centralized application front end is configured with a Network Load Balancer (NLB) for scalability.\nUp to 10 business unit VPCs will need to be connected to the shared VPC. Some of the business unit VPC CIDR blocks overlap with the shared VPC, and some overlap with each other. Network connectivity to the centralized application in the shared VPC should be allowed from authorized business unit VPCs only.\nWhich network configuration should a solutions architect use to provide connectivity from the client applications in the business unit VPCs to the centralized application in the shared VPC?","answer_images":[],"question_id":684,"topic":"1"},{"id":"bs4hQl413NnX1UFHzz09","answer_images":[],"isMC":true,"question_id":685,"discussion":[{"timestamp":"1634865540.0","content":"A is correct instead B and Final answer AD.\nhttps://aws.amazon.com/kinesis/data-firehose/faqs/\nQ: What is Amazon Kinesis Data Firehose?\nIt is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration.","poster":"ExtHo","comments":[{"poster":"DashL","content":"Unlike some other AWS services, Kinesis does not provide a native auto-scaling solution like DynamoDB On-Demand or EC2 Auto Scaling. Therefore, there is a need for the right number of shards to be calculated for every stream based on the expected number of records and/or the size of the records. This can lead to over/under-provisioning of shards within a stream resulting in higher costs and/or data ingestion being throttled.","comment_id":"398622","timestamp":"1635401280.0","upvote_count":"3"}],"comment_id":"343653","upvote_count":"17"},{"poster":"Waiweng","content":"It's A&D","upvote_count":"9","timestamp":"1635078600.0","comment_id":"357790"},{"upvote_count":"1","comment_id":"1328365","content":"Selected Answer: BD\nA is wrong: You can't connect on-premise events with kinesis data firehose directly.\nB is fully managed and can be auto-scaling with on-demand mode. It buffers the events with retention period up to 365 days.","poster":"Zinnia_Wang","timestamp":"1734512640.0"},{"content":"Its A & D simply because Firehose & Streams BOTH require on going Administration but Firehose less. There is no indication that processing via Streams ( complex transforms etc) is required, and that would easily make it Streams but it implies that Lambda is doing the work so for simplicity Firehose is the easier to configure and not worry about long term - ish. I had a nice long chat with Google Gemini over it ( ha ha) -- Kinesis Firehose: Offers a simpler setup with automatic buffer scaling and basic data delivery capabilities. While it can integrate with Lambda for pre-processing, the overall administration burden is less compared to Kinesis Data Streams. However, some configuration and monitoring of delivery destinations, access controls, and Lambda functions (if used) are still required.","upvote_count":"1","comment_id":"1236643","timestamp":"1719274020.0","poster":"CProgrammer"},{"poster":"robertohyena","upvote_count":"3","content":"Selected Answer: BD\nA - With Amazon Kinesis Data Streams, there are no servers to manage. The on-demand mode eliminates the need to provision or manage capacity required for running applications.\nD - Elasticsearch Service, now OpenSearch support semi-structured JSON data and dynamic schemas","comment_id":"744910","timestamp":"1671008820.0"},{"comment_id":"645645","content":"D because data is semi structure.","timestamp":"1660262640.0","upvote_count":"1","comments":[{"timestamp":"1660262760.0","poster":"Andykris","content":"A becase Kenisis data firehose can scale and handle data traffic","comment_id":"645646","upvote_count":"1"}],"poster":"Andykris"},{"upvote_count":"3","content":"I still dont understand why choose D over C. Amazon QuickSight do the same thing as Kibana isn't it?","timestamp":"1654668540.0","comment_id":"613094","comments":[{"upvote_count":"1","content":"no ongoing administration","comment_id":"1066912","poster":"korn666","timestamp":"1699585200.0"}],"poster":"Anhdd"},{"upvote_count":"1","timestamp":"1652840040.0","comment_id":"603118","poster":"Niaj","content":"Selected Answer: AD\nAD for sure is the right answer here"},{"timestamp":"1644252240.0","comment_id":"542545","poster":"jj22222","content":"a and D look right","upvote_count":"1"},{"poster":"shaiker","upvote_count":"1","content":"Selected Answer: AD\nes is the only one doing the json unstructured data in the list. Aurora is relational and requires structured schema. firehose stream near realtime into es","timestamp":"1641324120.0","comment_id":"516936"},{"poster":"tkanmani76","upvote_count":"2","timestamp":"1641196260.0","comments":[{"comment_id":"613097","content":"seem that Aurora is relational and requires structured schema, while the question require the json unstructured data. In my opinion","upvote_count":"1","poster":"Anhdd","timestamp":"1654668660.0"},{"comment_id":"515465","poster":"tkanmani76","content":"Supporting Links - Confirming Quicksight support for handling JSON Semi structured data as well ..https://docs.aws.amazon.com/quicksight/latest/user/supported-data-sources.html","upvote_count":"1","timestamp":"1641196800.0"},{"comment_id":"698803","comments":[{"timestamp":"1666166940.0","poster":"fanq10","content":"Sorry, a typo - Correction -> Why NOT C? Here is the answer:\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html\nTherefore, the Answer is D: Amazon ES + kibana","upvote_count":"1","comment_id":"698805"}],"poster":"fanq10","content":"Why C? Here is the answer:\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html\nTherefore, Amazon ES + kibana","timestamp":"1666166820.0","upvote_count":"1"}],"content":"A is fine. \nC - Why not QuickSight ? As this specifically handles embeddable dashboards with visualizations on real time basis. Kibana can as well do this along with ES - but why not QuickSight - AWS solution for dashboards ?.","comment_id":"515457"},{"timestamp":"1639217400.0","upvote_count":"1","comment_id":"499310","content":"A. Use Amazon Kinesis Data Firehose to buffer events. Create an AWS Lambda function to process and transform events.\nD. Configure Amazon Elasticsearch Service (Amazon ES) to receive events. Use the Kibana endpoint deployed with Amazon ES to create near-real-time visualizations and dashboards.","poster":"cldy"},{"upvote_count":"1","comment_id":"495101","content":"A & D is right","timestamp":"1638792120.0","poster":"AzureDP900"},{"poster":"acloudguru","timestamp":"1638243000.0","upvote_count":"1","content":"Selected Answer: AD\nAD, this is a pattern of AWS, simple question, hope I can have it in my exam","comment_id":"490387"},{"timestamp":"1636261140.0","content":"It's A D","upvote_count":"1","poster":"andylogan","comment_id":"446968"},{"upvote_count":"2","timestamp":"1636134300.0","content":"how about B&E ? \nhttps://aws-samples.github.io/aws-dbs-refarch-graph/src/writing-from-amazon-kinesis-data-streams/","poster":"icttss","comment_id":"444965"},{"upvote_count":"3","timestamp":"1636047300.0","poster":"DerekKey","content":"A&D correct\nB wrong - Kinesis Datastream will not scale automatically. You must do it manually\nC wrong - \"dynamic schemas\"","comment_id":"439713"},{"poster":"tgv","content":"AAA DDD\n---","upvote_count":"1","comment_id":"435315","timestamp":"1635840660.0"},{"comment_id":"434043","timestamp":"1635692280.0","poster":"blackgamer","upvote_count":"1","content":"Answer is AD"},{"content":"I'll go with with B,D","poster":"WhyIronMan","comment_id":"414025","comments":[{"comment_id":"414026","content":"Changing to A,D after read","timestamp":"1635650400.0","poster":"WhyIronMan","upvote_count":"1"}],"timestamp":"1635590700.0","upvote_count":"1"},{"poster":"mustpassla","upvote_count":"3","content":"BD for sure, simple use case","timestamp":"1635138120.0","comment_id":"367535"},{"poster":"anandbabu","comment_id":"334279","upvote_count":"3","content":"go with BD","comments":[{"poster":"ppshein","content":"Kinesis stream cannot send data directly to ES, we need firehose to make it.","upvote_count":"4","timestamp":"1635019260.0","comment_id":"347689"}],"timestamp":"1634787720.0"},{"content":"Going with AD","timestamp":"1633911660.0","comment_id":"321526","poster":"champcloud","upvote_count":"2"},{"comment_id":"317424","content":"AD for me","upvote_count":"2","timestamp":"1633300200.0","poster":"aws_master"},{"content":"AD correct. \nB can't support : buffer that automatically scales to match the throughput of data and requires no ongoing administration.","upvote_count":"3","timestamp":"1633010100.0","poster":"ItsmeP","comment_id":"317341"},{"upvote_count":"1","content":"Correct Option : B D","timestamp":"1633001280.0","comment_id":"316546","comments":[{"comment_id":"331939","content":"B is not AWS managed. Going with AD after re-reading & giving it some thought..","timestamp":"1634347620.0","upvote_count":"1","poster":"SD13"}],"poster":"SD13"},{"timestamp":"1632545580.0","upvote_count":"1","comments":[{"content":"just out of curiosity did you pass your SA pro exam?","comment_id":"396213","poster":"MrCarter","timestamp":"1635145920.0","upvote_count":"1"}],"content":"Support for semi-structured JSON data and dynamic schemas... BD?","poster":"awsnoob","comment_id":"315521"},{"content":"B&C are correct","upvote_count":"1","comment_id":"313812","comments":[{"timestamp":"1632808800.0","comment_id":"315540","poster":"trap","upvote_count":"15","content":"A and D seems more correct\nFirehose is fully managed (i.e. scales automatically) whereas Streams is manually managed\n\nhttps://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-aws-integrations.html#es-aws-integrations-fh\nES (with embeded kibana) supports semi-structured JSON data and dynamic schemas + create dashboards to observe events in near-real time.","comments":[{"poster":"coma74","upvote_count":"3","timestamp":"1632950220.0","content":"I think A and D,too.\n\nhttps://aws.amazon.com/blogs/big-data/ingest-streaming-data-into-amazon-elasticsearch-service-within-the-privacy-of-your-vpc-with-amazon-kinesis-data-firehose/","comment_id":"316404"},{"upvote_count":"1","timestamp":"1633543200.0","comment_id":"319642","content":"firehose only goes to S3 or redshift. stream can go anywhere.","poster":"nitinz","comments":[{"comment_id":"323550","upvote_count":"2","content":"no. https://docs.aws.amazon.com/firehose/latest/dev/create-destination.html\nfirehose can go to anywhere too","poster":"tiffanny","timestamp":"1634040540.0"}]},{"timestamp":"1633830060.0","comment_id":"319645","content":"after re-reading it and checking your link I agree A & D","upvote_count":"1","poster":"nitinz"}]}],"poster":"nitinz","timestamp":"1632535800.0"}],"exam_id":32,"answer":"BD","url":"https://www.examtopics.com/discussions/amazon/view/47625-exam-aws-certified-solutions-architect-professional-topic-1/","choices":{"B":"Create an Amazon Kinesis data stream to buffer events. Create an AWS Lambda function to process and transform events.","D":"Configure Amazon Elasticsearch Service (Amazon ES) to receive events. Use the Kibana endpoint deployed with Amazon ES to create near-real-time visualizations and dashboards.","A":"Use Amazon Kinesis Data Firehose to buffer events. Create an AWS Lambda function to process and transform events.","C":"Configure an Amazon Aurora PostgreSQL DB cluster to receive events. Use Amazon QuickSight to read from the database and create near-real-time visualizations and dashboards.","E":"Configure an Amazon Neptune DB instance to receive events. Use Amazon QuickSight to read from the database and create near-real-time visualizations and dashboards."},"question_text":"A company has an on-premises monitoring solution using a PostgreSQL database for persistence of events. The database is unable to scale due to heavy ingestion and it frequently runs out of storage.\nThe company wants to create a hybrid solution and has already set up a VPN connection between its network and AWS. The solution should include the following attributes:\n✑ Managed AWS services to minimize operational complexity.\n✑ A buffer that automatically scales to match the throughput of data and requires no ongoing administration.\n✑ A visualization tool to create dashboards to observe events in near-real time.\n✑ Support for semi-structured JSON data and dynamic schemas.\nWhich combination of components will enable the company to create a monitoring solution that will satisfy these requirements? (Choose two.)","topic":"1","answer_description":"","answer_ET":"BD","timestamp":"2021-03-18 05:44:00","question_images":[],"answers_community":["BD (57%)","AD (43%)"],"unix_timestamp":1616042640}],"exam":{"name":"AWS Certified Solutions Architect - Professional","isBeta":false,"id":32,"isMCOnly":false,"provider":"Amazon","numberOfQuestions":1019,"isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":137},"__N_SSP":true}