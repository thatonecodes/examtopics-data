{"pageProps":{"questions":[{"id":"uuZpBDHnZeRwoMRxgTUl","answer":"A","choices":{"B":"Create a Lambda function URL for the function. Specify AWS_IAM as the authentication type.","C":"Create an Amazon CloudFront distribution. Deploy the function to Lambda@Edge. Integrate IAM authentication logic into the Lambda@Edge function.","A":"Create an Amazon API Gateway REST API. Configure the method to use the Lambda function. Enable IAM authentication on the API.","D":"Create an Amazon CloudFront distribution. Deploy the function to CloudFront Functions. Specify AWS_IAM as the authentication type."},"answers_community":["A (55%)","B (45%)"],"answer_ET":"A","timestamp":"2023-01-15 04:25:00","answer_description":"","answer_images":[],"question_text":"A solutions architect needs to design a new microservice for a company’s application. Clients must be able to call an HTTPS endpoint to reach the microservice. The microservice also must use AWS Identity and Access Management (IAM) to authenticate calls. The solutions architect will write the logic for this microservice by using a single AWS Lambda function that is written in Go 1.x.\n\nWhich solution will deploy the function in the MOST operationally efficient way?","question_id":176,"isMC":true,"question_images":[],"unix_timestamp":1673753100,"topic":"1","discussion":[{"timestamp":"1673784720.0","content":"Selected Answer: A\nA. Create an Amazon API Gateway REST API. Configure the method to use the Lambda function. Enable IAM authentication on the API.\nThis option is the most operationally efficient as it allows you to use API Gateway to handle the HTTPS endpoint and also allows you to use IAM to authenticate the calls to the microservice. API Gateway also provides many additional features such as caching, throttling, and monitoring, which can be useful for a microservice.","upvote_count":"22","poster":"mhmt4438","comment_id":"776512","comments":[{"poster":"FlyingHawk","upvote_count":"1","timestamp":"1737435060.0","comment_id":"1344010","content":"Simplicity:\n\nLambda Function URLs provide a direct HTTPS endpoint with minimal configuration. You don’t need to set up API Gateway, which reduces complexity.\n\nIAM Authentication:\n\nLambda Function URLs natively support IAM authentication, eliminating the need for custom logic or additional services."}]},{"timestamp":"1724939880.0","content":"The question specifically asks for the solution that is most operationally efficient, not necessarily the one with the most features (which is A). \n\nOption B—using a Lambda function URL with AWS_IAM authentication—is indeed the most operationally efficient because:\n1) Minimal Configuration: Lambda function URLs are designed to quickly create HTTPS endpoints without the need for additional AWS services like API Gateway.\n2) Built-in IAM Authentication: You can easily specify AWS_IAM as the authentication type directly, fulfilling the requirement without extra setup.\n3) No Extra Overhead: Unlike API Gateway, there’s no need to manage complex API configurations, throttling settings, or additional API management features unless specifically required.","comment_id":"1274541","poster":"OlehKom","upvote_count":"6"},{"timestamp":"1732674000.0","poster":"FlyingHawk","upvote_count":"3","comment_id":"1318390","content":"Selected Answer: B\nUse Lambda Function URLs for simplicity, low cost, and direct integration with IAM for authentication. If your microservice evolves to require more complex features, you can later integrate with API Gateway as needed.\nAPI Gateway can integrate with Lambda and enable IAM authentication, but it introduces more operational overhead and cost compared to a Lambda Function URL. It's unnecessary unless the application requires additional features like request validation, throttling, or custom authorizers."},{"timestamp":"1732340640.0","comment_id":"1316575","poster":"LeonSauveterre","content":"Selected Answer: B\nWhy is B better than A: Both options meet the requirements, but Lambda function URLs are simpler and involve less operational overhead compared to setting up and managing an API Gateway, so B for sure.","upvote_count":"3"},{"poster":"maryam_sh","timestamp":"1723043100.0","comment_id":"1262139","content":"Selected Answer: B\nB is the most operationally efficient solution. It provides the necessary functionality with minimal setup and cost, directly supports IAM authentication, and avoids the additional complexity and overhead associated with other options. This approach is particularly suitable for scenarios where the API requirements are straightforward and do not need the advanced features provided by API Gateway or CloudFront.","upvote_count":"4"},{"upvote_count":"2","poster":"hro","timestamp":"1710545280.0","comment_id":"1174568","content":"I think from a decoupllng and separation of concerns A is the answer. You dont want to have a heavy reliance on the Lambda function with you have specific services for what is being required.\nthere is operationally efficient incorrect and operationally efficient correct.\nSo A is the best answer."},{"comment_id":"1155624","content":"Selected Answer: B\nAccording to this statement \"MOST operationally efficient way\" and the following link related to Lambda Function URL security: \nhttps://docs.aws.amazon.com/lambda/latest/dg/urls-auth.html","timestamp":"1708528140.0","upvote_count":"3","poster":"bujuman"},{"comment_id":"1125224","poster":"awsgeek75","timestamp":"1705517040.0","upvote_count":"3","content":"I originally voted B but after reading this article, I am not sure if A is wrong or is just badly worded. \nIf A actually said \"Configure the [authorization] method to use the Lambda function\" then it would be way more logical than B but this could be intentional. Although I think this is AWS test not IELTS so picking right answers based on small word mistakes is not the intention!\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-lambda-authorizer.html"},{"poster":"upliftinghut","upvote_count":"2","content":"Selected Answer: B\nA& B are all good. The requirement is most operationally efficient so B is faster. In real life, I won't risk B for production, dev & test makes sense but no production please","comments":[{"upvote_count":"4","comment_id":"1114694","timestamp":"1704475380.0","poster":"upliftinghut","content":"Reference link why B is here: https://aws.amazon.com/blogs/aws/announcing-aws-lambda-function-urls-built-in-https-endpoints-for-single-function-microservices/"}],"timestamp":"1704475320.0","comment_id":"1114692"},{"content":"Selected Answer: B\nI think this question has 2 answers as both A and B will work. However, B is more operationally efficient due to Lambda function URL and direct support for AWS_IAM as the auth type for this setup.\nhttps://docs.aws.amazon.com/lambda/latest/dg/urls-auth.html#urls-auth-iam\n\nC, D are not operationally efficient and GO is not supported on Lambda@Edge or CloudFront functions. Even if AWS start supporting it, the operational efficiency with increase because of CloudFront","timestamp":"1704126180.0","poster":"awsgeek75","comment_id":"1111343","upvote_count":"2","comments":[{"poster":"awsgeek75","comment_id":"1111344","upvote_count":"2","content":"* meant to say \"operational efficiency will decrease\" because of CloudFront","timestamp":"1704126240.0"}]},{"poster":"pentium75","timestamp":"1703744100.0","comment_id":"1107484","content":"Selected Answer: B\nWe know that the application provides \"an HTTPS endpoint\" but we don't even know whether it is a REST API. The question is not mentioning any other requirements besides IAM authentication, which can be handled by Lambda alone.\n\nA would work, but would be an additional processing step (lowering operational efficiency). It would also provide benefits but none of those is asked for in the question.\n\nC and D is wrong because Lambda@Edge does not support Go.","upvote_count":"3"},{"upvote_count":"3","content":"Selected Answer: A\nOptions B, C, and D involve using Lambda function URLs or CloudFront, but they lack the full set of features provided by API Gateway, such as built-in IAM authentication, throttling, and other API management capabilities.","poster":"meowruki","comment_id":"1083905","timestamp":"1701308100.0"},{"upvote_count":"2","content":"Selected Answer: B\nI think it is B - most operationally efficient. A is a better answer, but more complicated.","poster":"google_platform_team","comment_id":"1079201","timestamp":"1700823900.0"},{"comment_id":"1043561","poster":"swap001","timestamp":"1697297460.0","upvote_count":"3","content":"Selected Answer: B\nThere is no need of an additional API gateway when Lambda itself can support the need. This is more operationally efficient."},{"content":"Why not B? I agree that A is a nice choice, but it clearly says \"MOST operationally efficient way\", there is nothing said about API. B in this case suits absolutely fine, it's simpler and cheaper.","poster":"OlehKom","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1732340520.0","poster":"LeonSauveterre","comment_id":"1316574","content":"I totally agree. The answer should be B instead of A. I'm sure of it."}],"timestamp":"1696263120.0","comment_id":"1023266"},{"upvote_count":"2","content":"Selected Answer: A\nCreate an Amazon API Gateway REST API. Configure the method to use the Lambda function. Enable IAM authentication on the API","timestamp":"1695624660.0","poster":"TariqKipkemei","comment_id":"1016542"},{"timestamp":"1694437980.0","poster":"Guru4Cloud","comment_id":"1004837","upvote_count":"4","content":"Selected Answer: A\nA. Create an Amazon API Gateway REST API. Configure the method to use the Lambda function. Enable IAM authentication on the API.\nThis option is the most operationally efficient as it allows you to use API Gateway to handle the HTTPS endpoint and also allows you to use IAM to authenticate the calls to the microservice. API Gateway also provides many additional features such as caching, throttling, and monitoring, which can be useful for a microservice."},{"timestamp":"1690997100.0","comment_id":"970417","content":"Selected Answer: B\nC & D (incorrect) - what will be the origin for CDN? Plus Go is not supported. Plus for option D, IAM is not supported.\n\nA, why develop and manage API in API GW?\n\nJust enable Lambda function URL...","poster":"Smart","upvote_count":"2"},{"upvote_count":"2","comment_id":"966628","timestamp":"1690661880.0","poster":"Zeezie","content":"B -- MOST operationally efficient. Just look at the Lambda Create function console...\n\nEnable function URL > \nUse function URLs to assign HTTP(S) endpoints to your Lambda function.\n\nAuth type\nChoose the auth type for your function URL. > \nAWS_IAM\nOnly authenticated IAM users and roles can make requests to your function URL."},{"poster":"testopesto","content":"Selected Answer: B\nThe MOST operationally efficient way\nhttps://docs.aws.amazon.com/lambda/latest/dg/urls-auth.html\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-urls.html","timestamp":"1690633740.0","upvote_count":"3","comment_id":"966402"},{"comment_id":"965658","timestamp":"1690559160.0","content":"Selected Answer: A\nCreate an Amazon API Gateway REST API. Configure the method to use the Lambda function. Enable IAM authentication on the API.","upvote_count":"2","poster":"Undisputed"},{"comment_id":"936663","upvote_count":"3","timestamp":"1687956120.0","poster":"cookieMr","comments":[{"timestamp":"1690996680.0","comment_id":"970415","poster":"Smart","content":"The question is not asking for API Gateway benefits.","upvote_count":"3"},{"upvote_count":"2","poster":"foha2012","timestamp":"1705879920.0","comment_id":"1128247","content":"Also, Lambda URL is not available in all regions.\nNote:\nFunction URLs are not supported in the following regions: Asia Pacific (Hyderabad) (ap-south-2), Asia Pacific (Melbourne) (ap-southeast-4), Europe (Spain) (eu-south-2), Europe (Zurich) (eu-central-2), Israel (Tel Aviv) (il-central-1), and Middle East (UAE) (me-central-1)."}],"content":"Selected Answer: A\nBy creating an API Gateway REST API, you can define the HTTPS endpoint that clients can call to reach the microservice. Enable IAM authentication on the API to enforce authentication for the API calls. This ensures that only authenticated requests are allowed to reach the microservice. This solution is operationally efficient as it leverages the built-in capabilities of API Gateway to handle the HTTP endpoint, request routing, and IAM authentication. It provides a scalable and managed solution without the need for additional infrastructure components.\n\nB suggests creating a Lambda URL and specifying AWS IAM as the authentication type. While this can provide IAM authentication, it lacks the benefits of API Gateway, such as request validation, rate limiting, and easy management of API configurations.\n\nC and D involve using CloudFront, Lambda@Edge, and CloudFront Functions. While these services offer flexibility and the ability to run logic at the edge locations, they introduce additional complexity and may not be necessary for the given requirement."},{"comment_id":"911724","poster":"vassdlevi","timestamp":"1685594640.0","upvote_count":"1","content":"Selected Answer: B\nhttps://docs.aws.amazon.com/lambda/latest/dg/urls-configuration.html"},{"content":"A is crt 100%","poster":"PRASAD180","upvote_count":"2","timestamp":"1677144240.0","comment_id":"819017"},{"upvote_count":"3","timestamp":"1676879580.0","comment_id":"814974","comments":[{"content":"Lambda@Edge only support NodeJS or Python","upvote_count":"3","comment_id":"906536","timestamp":"1685005140.0","comments":[{"upvote_count":"2","poster":"vassdlevi","comment_id":"940542","content":"AWS Lambda natively supports Java, Go, PowerShell, Node.js, C#, Python, and Ruby code, and provides a Runtime API which allows you to use any additional programming languages to author your functions.","timestamp":"1688273040.0"}],"poster":"moiraqi"}],"content":"Why c is not correct? ?","poster":"tellmenowwwww"},{"poster":"bdp123","comment_id":"808720","content":"Selected Answer: A\nhttps://asanchez.dev/blog/deploy-api-go-aws-lambda-gateway/","timestamp":"1676401560.0","upvote_count":"2"},{"comment_id":"776135","comments":[{"content":"With CloudFront Functions in Amazon CloudFront, you can write lightweight functions in JavaScript for high-scale, latency-sensitive CDN customizations. But you are using Go 1.x. Lambda supports go. So A makes a lot more sense than D","upvote_count":"2","comment_id":"786215","timestamp":"1674542400.0","poster":"JayBee65"}],"timestamp":"1673753100.0","upvote_count":"1","content":"D\nhttps://aws.amazon.com/premiumsupport/knowledge-center/iam-authentication-api-gateway/","poster":"SanLi"}],"exam_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/95365-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"vOYC8nwhhqMFxirWMstf","answer":"B","timestamp":"2022-10-10 17:02:00","unix_timestamp":1665414120,"question_id":177,"topic":"1","answer_images":[],"question_images":[],"answer_description":"","answers_community":["B (66%)","C (24%)","11%"],"url":"https://www.examtopics.com/discussions/amazon/view/85038-exam-aws-certified-solutions-architect-associate-saa-c03/","discussion":[{"poster":"sba21","timestamp":"1665491340.0","comment_id":"692095","content":"Selected Answer: B\nhttps://www.examtopics.com/discussions/amazon/view/68306-exam-aws-certified-solutions-architect-associate-saa-c02/","upvote_count":"38"},{"poster":"123jhl0","comments":[{"content":"Hey brother, I think you might be wrong. The AWS Cost Explorer retains for 12 months and the 14 days visibility is actually for the free trial. So it has nothing related to how much the cost explorer can retain. I hope I made myself clear.","poster":"satyaammm","timestamp":"1735575780.0","comment_id":"1334252","upvote_count":"3"},{"poster":"kidomaruto","upvote_count":"2","comment_id":"1059436","content":"\"The Cost Explorer Hourly and Resource level granularity allows you to access cost and usage data at hourly granularity for the past 14 days and resource level granularity.\"\n\nhttps://aws.amazon.com/fr/aws-cost-management/aws-cost-explorer/pricing/#:~:text=The%20Cost%20Explorer%20Hourly%20and,available%20for%20EC2%20instances%20only.","timestamp":"1698824700.0"},{"content":"Cost Explorer, AWS prepares the data about your costs for the current month and the last 12 months: https://aws.amazon.com/aws-cost-management/aws-cost-explorer/","upvote_count":"17","comment_id":"731271","timestamp":"1669800600.0","comments":[{"poster":"JA2018","timestamp":"1731074040.0","content":"https://docs.aws.amazon.com/cost-management/latest/userguide/differences-billing-data-cost-explorer-data.html\n\nCost Explorer supports deep-dive analysis so that you can identify savings opportunities. Cost Explorer data provides more granular dimensions (such as Availability Zone or operating system) and includes features that might show differences when compared to billing data. On the Cost Management preferences page, you can manage your preferences for Cost Explorer data, including linked account access and historical and granular data settings. For more information, see Controlling access to Cost Explorer.","comment_id":"1308809","upvote_count":"1"}],"poster":"Udoyen"},{"content":"12 months data visible on Cost Explorer.","comment_id":"700643","upvote_count":"17","timestamp":"1666339320.0","poster":"goku58"}],"timestamp":"1665930600.0","content":"Selected Answer: C\nThe requested result is a graph, so...\nA - can't be as the result is a report\nB - can't be as it is limited to 14 days visibility and the graph has to cover 2 months\nC - seems to provide graphs and the best option available, as...\nD - could provide graphs, BUT involves operational overhead, which has been requested to be minimised.","comment_id":"696285","upvote_count":"29"},{"comment_id":"1357974","upvote_count":"1","timestamp":"1739824380.0","poster":"Vandaman","content":"Selected Answer: B\nI see lately that you can look back as far as 3 years."},{"content":"Selected Answer: B\nCost Explorer, AWS prepares the data about your costs for the current month and the last 12 months, and then calculates the forecast for the next 12 months. The current month's data is available for viewing in about 24 hours. The rest of your data takes a few days longer. Cost Explorer updates your cost data at least once every 24 hours.","poster":"AshishDhole","timestamp":"1738853580.0","upvote_count":"1","comment_id":"1352457"},{"upvote_count":"1","timestamp":"1737276780.0","content":"Selected Answer: B\nCost explorer has option to filter by service and we can modify the timeline also to compare the costs across 3 months","poster":"V2910","comment_id":"1342929"},{"content":"Selected Answer: B\nAWS Cost Explorer allows you to view cost and usage data with granular filtering. However, the historical data retention depends on the level of granularity:\n\nDaily granularity: You can access up to the past 12 months of daily cost and usage data.\n\nHourly granularity: If you have detailed billing enabled, you can view up to the past 14 days of hourly usage data.\n\nMonthly granularity: You can access up to the past 12 months of cost and usage data, and also forecast costs for the next 12 months.","timestamp":"1734007380.0","upvote_count":"3","poster":"aatikah","comment_id":"1325601"},{"poster":"mzeynalli","comment_id":"1302293","content":"Selected Answer: B\nB. Use Cost Explorer's granular filtering feature to perform an in-depth analysis of EC2 costs based on instance types.\n\nExplanation:\nCost Explorer provides an easy way to analyze AWS costs and usage visually. It allows you to filter data by multiple parameters, such as instance types, regions, and time periods. It also enables you to drill down and identify specific cost drivers, such as unwanted vertical scaling.\nThis option is suitable because it provides granular insights with minimal operational overhead, as it is a built-in AWS tool specifically designed for cost analysis.","timestamp":"1729743060.0","upvote_count":"4"},{"poster":"mzeynalli","timestamp":"1729742940.0","upvote_count":"2","comment_id":"1302292","content":"The correct answer is:\n\nB. Use Cost Explorer's granular filtering feature to perform an in-depth analysis of EC2 costs based on instance types.\n\nExplanation:\n\nCost Explorer provides an easy way to analyze AWS costs and usage visually. It allows you to filter data by multiple parameters, such as instance types, regions, and time periods. It also enables you to drill down and identify specific cost drivers, such as unwanted vertical scaling.\nThis option is suitable because it provides granular insights with minimal operational overhead, as it is a built-in AWS tool specifically designed for cost analysis.\nWhy Other Options Are Less Suitable:\n\nC. AWS Billing and Cost Management Dashboard: It provides a high-level view of costs, but it lacks the specific filtering capabilities needed for a granular, instance-type-level analysis over time."},{"comment_id":"1296712","upvote_count":"3","content":"Option B:\nUse AWS Cost Explorer, a tool that makes it easy to view your costs and break them down into categories like EC2 instance types, time periods, and more.\nWith Cost Explorer, you can easily filter the information to see which EC2 instance types caused the increase in costs over the last two months. This lets you do an in-depth analysis without much effort.","timestamp":"1728787380.0","poster":"PaulEkwem"},{"poster":"PaulGa","timestamp":"1723580160.0","content":"Selected Answer: B\nI would have gone for Ans B but apparently the right one is Ans C. \nI’m not convinced because neither B or C actually determine the root cause – they just point you in the right direction and then you’ll need to do some further analysis around resource demand (CPU, storage, network, etc), data/network traffic, what function/ instructions are actually being processed, along with taking a view of the scaling algorithms. On that basis I’d have said Ans B because it requires the LEAST overhead to get to the next step which is the one that matters: the root analysis for vertical scaling.","comment_id":"1265343","upvote_count":"3"},{"poster":"DavidNgTan","upvote_count":"2","content":"Selected Answer: B\nAWS Cost explorer will provide your usage and cost by main graph.\nhttps://docs.aws.amazon.com/cost-management/latest/userguide/ce-what-is.html","comment_id":"1253073","timestamp":"1721651280.0"},{"content":"Selected Answer: C\nI think the highest priority is \"with the LEAST operational overhead?\". B is very good for \"perform an in-depth analysis\" but C overwhelming win on cost.","timestamp":"1716424560.0","upvote_count":"2","poster":"stlwell","comment_id":"1216116"},{"comment_id":"1194063","content":"Selected Answer: D\nBoth B and D has their merits and achieve the ask of a question. Infact Option D would give more streamlined and automated approach and will be very less overhead once setup.","timestamp":"1712883360.0","poster":"firsttimetesttaker","upvote_count":"1"},{"comment_id":"1187780","poster":"JohnZh","timestamp":"1712020740.0","upvote_count":"1","comments":[{"timestamp":"1712020920.0","poster":"JohnZh","content":"Oh I see why: they want to identify \"unwanted vertical scaling of instance types for a couple of EC2 instances\", which could be RDS, ES, ElasticCache, and etc:\nhttps://aws.amazon.com/aws-cost-management/aws-cost-explorer/features/#:~:text=Cost%20Explorer%20allows%20customers%20to,or%20understand%20peak%20hour%20usage","upvote_count":"2","comment_id":"1187781"}],"content":"Not sure why it's B -- how can cost explorer identify the root cause of the vertical scaling?"},{"comment_id":"1183305","poster":"ManikRoy","timestamp":"1711455900.0","content":"Selected Answer: B\nNote that If Hourly granularity is required then the correct option might not be B as cost explorer hourly granular details are provided only for past 14 days. \nreference link -\nhttps://aws.amazon.com/aws-cost-management/aws-cost-explorer/features/#:~:text=Cost%20Explorer%20allows%20customers%20to,or%20understand%20peak%20hour%20usage.","upvote_count":"2"},{"poster":"vi24","timestamp":"1709836800.0","upvote_count":"1","comment_id":"1168273","content":"Cost and usage report is the right tool for analyzing and understanding your bill. Cost explorer is mostly used for monitoring usage/expenditure over time to forecast and decide on more suitable plan/ package."},{"upvote_count":"1","comment_id":"1147994","timestamp":"1707735000.0","content":"The answer is B.\nYou can enable Cost Explorer for your account using this procedure on the Billing and Cost Management console. You can't enable Cost Explorer using the API. After you enable Cost Explorer, AWS prepares the data about your costs for the current month and the last 12 months, and then calculates the forecast for the next 12 months. The current month's data is available for viewing in about 24 hours. The rest of your data takes a few days longer. Cost Explorer updates your cost data at least once every 24 hours.","poster":"cheroh_tots"}],"choices":{"B":"Use Cost Explorer's granular filtering feature to perform an in-depth analysis of EC2 costs based on instance types.","C":"Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the last 2 months.","A":"Use AWS Budgets to create a budget report and compare EC2 costs based on instance types.","D":"Use AWS Cost and Usage Reports to create a report and send it to an Amazon S3 bucket. Use Amazon QuickSight with Amazon S3 as a source to generate an interactive graph based on instance types."},"question_text":"A company observes an increase in Amazon EC2 costs in its most recent bill. The billing team notices unwanted vertical scaling of instance types for a couple of EC2 instances. A solutions architect needs to create a graph comparing the last 2 months of EC2 costs and perform an in-depth analysis to identify the root cause of the vertical scaling.\nHow should the solutions architect generate the information with the LEAST operational overhead?","exam_id":31,"answer_ET":"B","isMC":true},{"id":"YkU5Qeryurr47p3hhDgu","unix_timestamp":1673603700,"question_id":178,"choices":{"B":"Host the visualization tool in the same AWS Region as the data warehouse. Access it over the internet.","D":"Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region.","C":"Host the visualization tool on premises and query the data warehouse directly over a Direct Connect connection at a location in the same AWS Region.","A":"Host the visualization tool on premises and query the data warehouse directly over the internet."},"answer_images":[],"exam_id":31,"discussion":[{"content":"Selected Answer: D\nA. --> No since if you access via internet you are creating egress traffic.\nB. -->It's a good choice to have both DWH and visualization in the same region to lower the egress transfer (i.e. data going egress/out of the region) but if you access over internet you might still have egress transfer.\nC. -> Valid but in this case you send out of AWS 50MB if you query the DWH instead of the visualization tool, D removes this need since puts the visualization tools in AWS with the DWH so reduces data returned out of AWS from 50MB to 500KB\nD. --> Correct, see explanation on answer C\n-------------------------------------------------------------------------------------------------------------------------------------------\nUseful links:\nAWS Direct Connect connection create a connection in an AWS Direct Connect location to establish a network connection from your premises to an AWS Region.\nhttps://docs.aws.amazon.com/directconnect/latest/UserGuide/Welcome.html","comments":[{"content":"It is not quite making sense that the answer D to mention on AWS Direct Connect if the tool is staying with AWS already. That is the main reason i vote on C rather than D.","poster":"Jacky_S","comment_id":"1235492","upvote_count":"3","timestamp":"1719071880.0"},{"content":"I thought Direct Connect is exclusively for on-prem to VPC. Why would you use DirectConnect to connect to a service in your own Region in the AWS Cloud? \nI believe C is correct.","timestamp":"1710537780.0","upvote_count":"3","comments":[{"comment_id":"1176015","poster":"chickenmf","timestamp":"1710700140.0","upvote_count":"1","content":"Agree with you 100%"}],"comment_id":"1174513","poster":"hro"}],"timestamp":"1677754440.0","poster":"AlessandraSAA","upvote_count":"15","comment_id":"826759"},{"content":"Selected Answer: D\nHosting the visualization tool in the same AWS Region as the data warehouse and accessing it over a Direct Connect connection within the same Region eliminates data transfer fees and ensures low-latency, high-bandwidth connectivity.\n\nA. Hosting the visualization tool on premises and querying the data warehouse over the internet incurs data transfer costs for every query result, as well as potential latency and bandwidth limitations.\n\nB. Hosting the visualization tool in the same AWS Region as the data warehouse but accessing it over the internet still incurs data transfer costs for each query result.\n\nC. Hosting the visualization tool on premises and querying the data warehouse over a Direct Connect connection within the same AWS Region incurs data transfer costs for every query result and adds complexity by requiring on-premises infrastructure.","poster":"cookieMr","comment_id":"936666","timestamp":"1687956300.0","upvote_count":"5"},{"timestamp":"1732341000.0","comment_id":"1316578","poster":"LeonSauveterre","content":"Selected Answer: D\nWhy C is Less Cost-Effective Than D: While Direct Connect minimizes costs in both cases, hosting the visualization tool on premises (C) still incurs some egress costs when pulling large query results to the corporate office. Hosting the visualization tool in the same AWS Region as the data warehouse (D) eliminates most egress costs **entirely** due to AWS's intra-region free data transfer policy.","upvote_count":"2"},{"content":"This is question that need a careful reading of the question. Please note: in the question that the company has a DX connection but it doesn't mention the company is utilizing the DX to query the data warehouse (this indicates that the query was using internet). So my verdict would be to place the visualization tool on-prem (which it already is) and use the DX to query the data warehouse to reduce cost of (DTO) so I vote for C","timestamp":"1716538320.0","comment_id":"1217304","poster":"Jazz888","upvote_count":"2"},{"timestamp":"1710469680.0","comment_id":"1173988","poster":"hro","content":"The answer is C. At no point does the question suggest that the DWH source is out of Region.","upvote_count":"2"},{"poster":"reviewmine","timestamp":"1708328640.0","comment_id":"1153759","content":"Selected Answer: D\nIt's D. Host the visualization on the same region to avoid egress cost and access the tool via AWS Direct connection.","upvote_count":"3"},{"poster":"upliftinghut","content":"Selected Answer: D\nLeverage the existing DirectConnect so not incur data transfer charge","timestamp":"1704475980.0","comment_id":"1114702","upvote_count":"2"},{"poster":"Ruffyit","timestamp":"1700740800.0","upvote_count":"2","comment_id":"1078395","content":"D. Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region."},{"timestamp":"1695624840.0","comment_id":"1016544","poster":"TariqKipkemei","content":"Selected Answer: D\nHost the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region","upvote_count":"2"},{"comment_id":"1004830","content":"Selected Answer: D\nD. Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region.","upvote_count":"2","poster":"Guru4Cloud","timestamp":"1694437740.0"},{"poster":"jtexam","content":"Selected Answer: B\nby hosting in same region, you have 500kb transfer charged on internet transfer teir, 50MB charged in inter-region tier.\n\nusing direct link, both are charged in direct link tier. direct link tier is not cheap. \n\nso i go for B","comments":[{"timestamp":"1703744460.0","upvote_count":"2","poster":"pentium75","content":"We don't want \"lowest cost\", we want \"lowest data transfer egress cost\". And \"data transfer egress\" cost for Direct Connect is WAY lower than for Internet. (Therefor the circuit itself is expensive, but that does exist anyway.)","comment_id":"1107489"}],"comment_id":"949512","upvote_count":"1","timestamp":"1689142140.0"},{"timestamp":"1688335740.0","comment_id":"941269","content":"Aaaaaaaa","upvote_count":"1","poster":"Mmmmmmkkkk"},{"comment_id":"790450","poster":"dexpos","upvote_count":"2","timestamp":"1674897480.0","content":"Selected Answer: D\nD let you reduce at minimum the data transfer costs"},{"poster":"alexleely","comments":[{"poster":"markw92","comment_id":"926868","timestamp":"1687114860.0","upvote_count":"1","content":"C option doesnt travel through internet because we have a direct connect. If you are hosting your visualization tool in same region why you need a direct connection which D has? Doesn't make sense. So, C is the right answer."}],"upvote_count":"5","content":"Selected Answer: D\nD: Direct Connect connection at a location in the same Region will provide the lowest data transfer egress cost, improved performance, and lower complexity\n\nWhy it is not C is because the visualization tool is hosted on-premises, as it's not hosted in the same region as the data warehouse the data transfer between them would occur over the internet, thus, would incur in egress data transfer costs.","timestamp":"1674364860.0","comment_id":"783927"},{"upvote_count":"2","comments":[{"comment_id":"786220","timestamp":"1674542700.0","upvote_count":"3","content":"Whilst \"Direct Connect can help lower egress costs even after taking the installation costs into account. This is because AWS charges lower transfer rates.\" D removes the need to send the query results out of AWS and instead returns the web page, so reduces data returned from 50MB to 500KB, so D","poster":"JayBee65"}],"poster":"Vickysss","comment_id":"780056","content":"Selected Answer: C\nhttps://www.nops.io/reduce-aws-data-transfer-costs-dont-get-stung-by-hefty-egress-fees/","timestamp":"1674050160.0"},{"comment_id":"776515","timestamp":"1673784960.0","poster":"mhmt4438","upvote_count":"5","content":"Selected Answer: D\nCorrect answer is D"},{"comment_id":"775856","content":"Selected Answer: D\nShould be D\nhttps://aws.amazon.com/directconnect/pricing/\nhttps://aws.amazon.com/blogs/aws/aws-data-transfer-prices-reduced/","poster":"Aninina","timestamp":"1673723580.0","upvote_count":"3"},{"poster":"Morinator","timestamp":"1673603700.0","upvote_count":"3","comment_id":"774308","content":"Selected Answer: D\nhttps://www.examtopics.com/discussions/amazon/view/47140-exam-aws-certified-solutions-architect-associate-saa-c02/"}],"answers_community":["D (94%)","4%"],"isMC":true,"answer_description":"","question_text":"A company previously migrated its data warehouse solution to AWS. The company also has an AWS Direct Connect connection. Corporate office users query the data warehouse using a visualization tool. The average size of a query returned by the data warehouse is 50 MB and each webpage sent by the visualization tool is approximately 500 KB. Result sets returned by the data warehouse are not cached.\n\nWhich solution provides the LOWEST data transfer egress cost for the company?","timestamp":"2023-01-13 10:55:00","answer":"D","question_images":[],"topic":"1","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/94998-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"3KAAslyBzo2Mtqku8fUN","exam_id":31,"question_images":[],"discussion":[{"comment_id":"826112","timestamp":"1677690960.0","poster":"Steve_4542636","content":"Selected Answer: C\nMulti az is not the same as multi regional","upvote_count":"48"},{"comment_id":"783922","upvote_count":"16","poster":"alexleely","timestamp":"1674364140.0","content":"Selected Answer: B\nB: Amazon RDS Multi-AZ feature automatically creates a synchronous replica in another availability zone and failover to the replica in the event of an outage. This will provide high availability and data durability across multiple AWS regions which fit the requirements. \n\nThough C may sound good, it in fact requires manual management and monitoring of the replication process due to the fact that Amazon RDS read replicas are asynchronous, meaning there is a delay between the primary and read replica. Therefore, there will be a need to ensure that the read replica is constantly up-to-date and someone still has to fix any read replica errors during the replication process which may cause data inconsistency. Lastly, you still have to configure additional steps to make it fail over to the read replica.","comments":[{"timestamp":"1676887140.0","comment_id":"815069","poster":"Rehan33","content":"I go with option B because:\nMulti-AZ is for high availiblity\nRead replicas are for low-latency\nin question they talk about available online","comments":[{"content":"They also ask for multiple regions which is not covered by Multi AZ","upvote_count":"3","poster":"awsgeek75","timestamp":"1705517580.0","comment_id":"1125230"}],"upvote_count":"4"},{"comments":[{"comments":[{"poster":"smartegnine","timestamp":"1686611640.0","upvote_count":"1","comment_id":"921803","content":"https://aws.amazon.com/rds/features/multi-az/\n\n\nsmartegnine 0 minutes ago Awaiting moderator approval\nSelected Answer: B\nIn an Amazon RDS Multi-AZ deployment, Amazon RDS automatically creates a primary database (DB) instance and synchronously replicates the data to an instance in a different AZ."}],"upvote_count":"15","content":"You are right, Multi-AZ is only within one Region. C would be the right answer.","timestamp":"1674614400.0","comment_id":"787214","poster":"alexleely"}],"upvote_count":"22","timestamp":"1674566940.0","comment_id":"786561","poster":"Mahadeva","content":"But the question is clearly asking for Multiple Regions. Multi-AZ is not across Regions."}]},{"poster":"hasiet","upvote_count":"2","content":"Selected Answer: C\nC. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region.\n\nThis option provides cross-region availability with minimal operational overhead, as RDS manages the replication process for you.","comment_id":"1318811","timestamp":"1732726740.0"},{"upvote_count":"2","poster":"akshay243007","timestamp":"1721967840.0","content":"Selected Answer: C\nMulti AZ is not supported in to diffrent region\nread Raplica is supported in to diffrent region \n\nSo I am go with the option C","comment_id":"1255404"},{"poster":"Uzbekistan","comment_id":"1183675","timestamp":"1711492920.0","upvote_count":"1","content":"Selected Answer: B\nOption C involves setting up read replicas in another region, which provides cross-region availability but may introduce additional complexity in managing replication and monitoring.\n\nB. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance with Multi-AZ:\n\nHigh Availability: Amazon RDS Multi-AZ deployments provide high availability and failover support for DB instances. With Multi-AZ, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone (AZ). In the event of a failure, Amazon RDS automatically fails over to the standby replica, ensuring data availability and minimal downtime. + Cross-Region Replication."},{"content":"Selected Answer: C\nA - Just no\nB - Multi-AZ is multiple AZs in same region, does not meet \"Multiple AWS Regions\" requirement\nC - Meets requirements\nD - Does not meet the \"online ... at all times\" requirement","upvote_count":"10","comment_id":"1107505","timestamp":"1703745240.0","poster":"pentium75"},{"upvote_count":"2","timestamp":"1701860640.0","content":"Multi az is not the same as multi regional","comment_id":"1089229","poster":"Ruffyit"},{"comment_id":"1020734","poster":"vijaykamal","upvote_count":"1","content":"Selected Answer: B\nOption C, while providing a read replica in another Region, adds complexity to the architecture and may introduce some additional operational overhead compared to Multi-AZ. Cross-Region replication involves setting up and managing replication between two separate RDS instances.","timestamp":"1695988260.0","comments":[{"poster":"pentium75","content":"But data must be online \"across multiple AWS regions\"!","timestamp":"1703745060.0","comment_id":"1107499","upvote_count":"2"}]},{"timestamp":"1695625020.0","poster":"TariqKipkemei","comment_id":"1016546","upvote_count":"3","content":"Selected Answer: C\nMigrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region"},{"content":"Selected Answer: C\nMulti-AZ is not the same as Multi-Regional","poster":"Guru4Cloud","comment_id":"1004828","upvote_count":"4","timestamp":"1694437500.0"},{"upvote_count":"3","timestamp":"1693895160.0","content":"can someone explain why not D","poster":"Valder21","comments":[{"comment_id":"1107500","content":"\"Data must be online (!) across multiple AWS regions at all times (!)\". Snapshots are not online.","poster":"pentium75","timestamp":"1703745120.0","upvote_count":"3"}],"comment_id":"999166"},{"timestamp":"1693207920.0","comment_id":"991883","upvote_count":"2","poster":"beginnercloud","content":"Selected Answer: C\nkey words \"AWS Regions at all times\" so C is correct"},{"content":"Selected Answer: C\nkey words \"AWS Regions at all times\"","comment_id":"951857","timestamp":"1689371400.0","poster":"fuzzycr","upvote_count":"2"},{"comment_id":"936673","upvote_count":"6","content":"Selected Answer: C\nBy migrating the PostgreSQL database to an RDS for PostgreSQL DB instance and creating a read replica in another AWS Region, you can achieve data availability and online access across multiple Regions. This solution requires less operational overhead compared to managing a PostgreSQL cluster on EC2 instances (Option A) or setting up manual replication using snapshots (Option D). Additionally, Amazon RDS handles the underlying infrastructure and replication setup, reducing the operational complexity for the company.\n\nOption B, is a valid solution for achieving high availability within a single AWS Region. However, it does not meet the requirement of having the data available and online across multiple AWS Regions at all times, which is specified in the question. The Multi-AZ feature in RDS provides automatic failover within the same Region, but it does not replicate the data to multiple Regions.","poster":"cookieMr","timestamp":"1687956780.0"},{"content":"Selected Answer: B\nC and D just specifiy another single region. This does not translate to multiple regions.\n\nB (Multi-AZ) means the solution will be highly available. \n\nThe data will be available in multiple regions for both B and C but B is a better solution!","poster":"mal1903","comment_id":"925190","comments":[{"poster":"Guru4Cloud","upvote_count":"1","timestamp":"1695213120.0","comment_id":"1012309","content":"its data is available and online across multiple AWS Regions at all times"},{"upvote_count":"2","poster":"pentium75","content":"\"Another single region\" plus the original region ARE of course \"multiple regions\", what else? While B \"Multi-AZ\" is two AZs in the same region.","timestamp":"1703745180.0","comment_id":"1107501"}],"timestamp":"1686920940.0","upvote_count":"1"},{"timestamp":"1686858780.0","comments":[{"content":"I would like to change my answer to \"B\". The question has some distractor words: \"its data is available and online across multiple AWS Regions at all times\". We agree that AWS is a could service available online around the world in 99 regions. So the option \"B\" is the most appropriate answer, since multi-AZ focuses on the avialability factor and it has the LEAST amount of operational overhead.","poster":"MrAWSAssociate","timestamp":"1686898800.0","upvote_count":"1","comment_id":"924933"}],"upvote_count":"3","comment_id":"924552","content":"Selected Answer: C\nAnswer B is not right, because \"RDS Multi-AZ\" always span at least two Availability Zones within a single region and the question requirment RDS DB should be available in multiple regions. Therefore, C is the most suitable answer for this question.","poster":"MrAWSAssociate"},{"comments":[{"upvote_count":"1","comment_id":"1012311","timestamp":"1695213180.0","content":"Multi-AZ is not the same as Multi-Regional","poster":"Guru4Cloud"}],"upvote_count":"1","poster":"abhishek2021","timestamp":"1686742260.0","content":"Selected Answer: B\nB & C both makes data available. However, B is less overhead. \nWhat I think, the question is asking for data availability across multiple regions not for a DR solution. So, RDS being accessible over public IP will do the trick for data being available across regions.","comment_id":"923072"},{"upvote_count":"2","comment_id":"922191","timestamp":"1686657660.0","poster":"Bmarodi","content":"Selected Answer: C\nOption meets the requirements, ref. link: https://aws.amazon.com/blogs/database/best-practices-for-amazon-rds-for-postgresql-cross-region-read-replicas/"},{"upvote_count":"1","timestamp":"1686611580.0","content":"Selected Answer: B\nIn an Amazon RDS Multi-AZ deployment, Amazon RDS automatically creates a primary database (DB) instance and synchronously replicates the data to an instance in a different AZ.\n\nhttps://aws.amazon.com/rds/features/multi-az/","comment_id":"921801","poster":"smartegnine"},{"poster":"ruqui","comment_id":"905960","timestamp":"1684937700.0","upvote_count":"2","content":"Selected Answer: C\nB is wrong because Multi AZ feature don't allow to have replicas in another region!!!! (the requirement is that \"data should be available and online across multiple AWS Regions at all times\") ... only feasible option is C"},{"content":"Multi-AZ provides redundancy within a single Region, it does not replicate data across multiple Regions. If the requirement specifically states the need for data availability across multiple Regions, creating a read replica in another Region (option C) would be the more appropriate choice.","poster":"kaustubhBarhate","comment_id":"902429","timestamp":"1684570020.0","upvote_count":"1"},{"upvote_count":"3","content":"Selected Answer: C\nMulti region","poster":"fakrap","comment_id":"894642","timestamp":"1683786360.0"},{"comment_id":"891865","content":"Selected Answer: B\noption C could make the data available across multiple AWS Regions, but it may not provide the same level of availability and minimal operational overhead as option B.","timestamp":"1683528960.0","upvote_count":"1","poster":"mandragon"},{"upvote_count":"5","poster":"channn","content":"Selected Answer: C\nReplica can do across multiple AWS Regions","comment_id":"854073","timestamp":"1680070980.0"},{"comment_id":"852366","timestamp":"1679940540.0","poster":"gold4otas","content":"Selected Answer: B\nB: Use Multi-AZ deployments for High Availability/Failover and Read Replicas for read scalability.","upvote_count":"2"},{"timestamp":"1676860440.0","content":"Option \"C\" would be a better solution.\nOption \"B\" not specifically mention about cross multiple Regions.","poster":"KZM","upvote_count":"3","comment_id":"814753"},{"comment_id":"802900","upvote_count":"5","timestamp":"1675925580.0","poster":"nickolaj","content":"Selected Answer: C\n\"online across multiple AWS Regions\"\nin B we did not have any words about Regions, Multi-AZ only for one region!"},{"content":"Selected Answer: C\nC is the correct answer, read replicas can be created cross region and can be promoted to be main database","timestamp":"1675516500.0","comment_id":"797974","upvote_count":"5","poster":"aakashkumar1999"},{"poster":"remand","timestamp":"1675480560.0","upvote_count":"2","comment_id":"797561","content":"Selected Answer: B\nrequires manual intervention to promote the read replica"},{"comment_id":"791073","poster":"dark_firzen","upvote_count":"7","timestamp":"1674938160.0","content":"Selected Answer: C\nQuestion asks for \"available and online across multiple AWS Regions at all times\". Multi-AZ is only within one region. Database can be replicated cross-region."},{"content":"Selected Answer: C\nMulti AZ can be cross region but the nodes in the other regions would be read replicas","upvote_count":"2","timestamp":"1674897720.0","comment_id":"790456","poster":"dexpos"},{"content":"Selected Answer: C\nQuestion says \" online across multiple AWS Regions at all times\". Currently only Read Replica supports cross-regions , Multi-AZ does not support cross-region (it works only in same region)\nhttps://aws.amazon.com/about-aws/whats-new/2018/01/amazon-rds-read-replicas-now-support-multi-az-deployments/","upvote_count":"4","timestamp":"1674800760.0","poster":"Mahakali","comment_id":"789361"},{"timestamp":"1674721620.0","upvote_count":"3","content":"Selected Answer: C\nBecause data must be available all the time. With multi-AZ, you can not read stand-by database.","poster":"aws4myself","comment_id":"788527"},{"comment_id":"787121","comments":[{"timestamp":"1674607320.0","upvote_count":"1","content":"Option B (using Multi-AZ feature on RDS) provides automatic failover and high availability across multiple regions with less operational overhead, that is why it is the best solution.","poster":"bullrem","comment_id":"787122","comments":[{"upvote_count":"1","comment_id":"809399","content":"Availability is not High Availability","poster":"Parsons","timestamp":"1676459040.0"}]}],"content":"Selected Answer: B\nOption C would meet the requirement of data being available across multiple regions, but it would require additional operational overhead in terms of managing and maintaining the read replica in the other region. This would also require additional infrastructure to handle replication and failover. Option B (RDS Multi-AZ) provides automatic failover across regions with minimal operational overhead, making it the best option in terms of minimizing operational overhead.","upvote_count":"1","timestamp":"1674607200.0","poster":"bullrem"},{"poster":"JayBee65","timestamp":"1674542820.0","comment_id":"786222","upvote_count":"1","content":"Selected Answer: B\nEAST amount of operational overhead = PostgreSQL DB instance with the Multi-AZ feature turned on. No read replicas to manage."},{"comment_id":"784319","poster":"John_Zhuang","timestamp":"1674392460.0","content":"Selected Answer: C\nC for sure","upvote_count":"3"},{"comment_id":"781823","poster":"LuckyAro","timestamp":"1674184620.0","content":"Selected Answer: B\nAmazon RDS for PostgreSQL DB instance with the Multi-AZ feature turned on","upvote_count":"1"},{"comment_id":"776522","timestamp":"1673785200.0","upvote_count":"5","content":"Selected Answer: C\nhttps://www.examtopics.com/discussions/amazon/view/61056-exam-aws-certified-solutions-architect-associate-saa-c02/","poster":"mhmt4438"},{"timestamp":"1673724240.0","upvote_count":"3","comment_id":"775862","poster":"Aninina","content":"Selected Answer: C\nshould be C: multiple AWS regions"},{"poster":"Morinator","timestamp":"1673603820.0","upvote_count":"3","comment_id":"774311","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/aws/cross-region-read-replicas-for-amazon-rds-for-mysql/"}],"url":"https://www.examtopics.com/discussions/amazon/view/95000-exam-aws-certified-solutions-architect-associate-saa-c03/","question_id":179,"answer_description":"","answers_community":["C (82%)","B (18%)"],"timestamp":"2023-01-13 10:57:00","topic":"1","answer":"C","answer_images":[],"unix_timestamp":1673603820,"choices":{"A":"Migrate the PostgreSQL database to a PostgreSQL cluster on Amazon EC2 instances.","D":"Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Set up DB snapshots to be copied to another Region.","B":"Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance with the Multi-AZ feature turned on.","C":"Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region."},"isMC":true,"answer_ET":"C","question_text":"An online learning company is migrating to the AWS Cloud. The company maintains its student records in a PostgreSQL database. The company needs a solution in which its data is available and online across multiple AWS Regions at all times.\n\nWhich solution will meet these requirements with the LEAST amount of operational overhead?"},{"id":"6ysko0OYzcmjz321Zd5W","answer":"C","unix_timestamp":1673603880,"answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/95001-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"discussion":[{"timestamp":"1703775300.0","upvote_count":"16","poster":"cookieMr","content":"The Multivalue routing policy allows Route 53 to respond to DNS queries with multiple healthy IP addresses for the same resource. This is particularly useful in scenarios where multiple instances are serving the same purpose and need to be load balanced or failover capable. With the Multivalue routing policy, Route 53 returns multiple IP addresses in a random order to distribute the traffic across all healthy instances.\n\nOption A (Simple routing policy) would only return a single IP address in response to DNS queries and does not support returning multiple addresses.\n\nOption B (Latency routing policy) is used to route traffic based on the lowest latency to the resource and does not fulfill the requirement of returning all healthy IP addresses.\n\nOption D (Geolocation routing policy) is used to route traffic based on the geographic location of the user and does not fulfill the requirement of returning all healthy IP addresses.\n\nTherefore, the Multivalue routing policy is the most suitable option for returning the IP addresses of all healthy EC2 instances in response to DNS queries.","comment_id":"936675"},{"content":"Selected Answer: C\nUse a multivalue answer routing policy to help distribute DNS responses across multiple resources. For example, use multivalue answer routing when you want to associate your routing records with a Route 53 health check. For example, use multivalue answer routing when you need to return multiple values for a DNS query and route traffic to multiple IP addresses.\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/multivalue-versus-simple-policies/","timestamp":"1689818880.0","poster":"LuckyAro","upvote_count":"14","comment_id":"781863"},{"comment_id":"1111353","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-multivalue\n\n\"Multivalue answer routing policy – Use when you want Route 53 to respond to DNS queries with up to eight healthy records selected at random. You can use multivalue answer routing to create records in a private hosted zone.\"\n\nCompany requires that the IP addresses of \"ALL\" healthy EC2 instances be returned so C is the only option.","timestamp":"1719845220.0","poster":"awsgeek75","upvote_count":"5"},{"content":"Use a multivalue answer routing policy to help distribute DNS responses across multiple resources. For example, use multivalue answer routing when you want to associate your routing records with a Route 53 health check. For example, use multivalue answer routing when you need to return multiple values for a DNS query and route traffic to multiple IP addresses.","poster":"Ruffyit","comment_id":"1089234","upvote_count":"2","timestamp":"1717664940.0"},{"content":"Selected Answer: C\nUse Multivalue answer routing policy when you want Route 53 to respond to DNS queries with up to eight healthy records selected at random.","poster":"TariqKipkemei","upvote_count":"2","timestamp":"1711436820.0","comment_id":"1017390"},{"comment_id":"1004823","poster":"Guru4Cloud","timestamp":"1710169320.0","content":"Selected Answer: C\nC. Multivalue routing policy","upvote_count":"2"},{"content":"Selected Answer: A\nA. Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic","comments":[{"upvote_count":"2","timestamp":"1719549360.0","poster":"pentium75","content":"This is for a different question I guess","comment_id":"1107508"}],"upvote_count":"1","comment_id":"1004822","timestamp":"1710169260.0","poster":"Guru4Cloud"},{"poster":"animefan1","timestamp":"1704282900.0","comment_id":"941681","content":"multivalue supports health checks","upvote_count":"2"},{"upvote_count":"4","timestamp":"1695124200.0","poster":"MLCL","comment_id":"843788","content":"IP are returned RANDOMLY for multi-value Routing, is this what we want ?"},{"comment_id":"837669","timestamp":"1694577360.0","content":"Selected Answer: C\nMultivalue answer routing policy ...answer is C","poster":"WherecanIstart","upvote_count":"2"},{"comment_id":"776545","timestamp":"1689417600.0","upvote_count":"3","poster":"mhmt4438","content":"Selected Answer: C\nAnswer is C"},{"timestamp":"1689355500.0","poster":"Aninina","content":"Selected Answer: C\nShould be C","comment_id":"775863","upvote_count":"2"},{"content":"Selected Answer: C\nhttps://www.examtopics.com/discussions/amazon/view/46491-exam-aws-certified-solutions-architect-associate-saa-c02/","timestamp":"1689240600.0","comment_id":"774384","upvote_count":"2","poster":"bamishr"},{"poster":"Morinator","comment_id":"774312","upvote_count":"2","timestamp":"1689235080.0","content":"Selected Answer: C\nhttps://www.examtopics.com/discussions/amazon/view/46491-exam-aws-certified-solutions-architect-associate-saa-c02/"}],"question_text":"A company hosts its web application on AWS using seven Amazon EC2 instances. The company requires that the IP addresses of all healthy EC2 instances be returned in response to DNS queries.\n\nWhich policy should be used to meet this requirement?","answer_description":"","answer_images":[],"exam_id":31,"question_id":180,"answers_community":["C (97%)","3%"],"timestamp":"2023-01-13 10:58:00","question_images":[],"choices":{"B":"Latency routing policy","C":"Multivalue routing policy","D":"Geolocation routing policy","A":"Simple routing policy"},"topic":"1"}],"exam":{"provider":"Amazon","id":31,"name":"AWS Certified Solutions Architect - Associate SAA-C03","numberOfQuestions":1019,"isImplemented":true,"lastUpdated":"11 Apr 2025","isBeta":false,"isMCOnly":true},"currentPage":36},"__N_SSP":true}