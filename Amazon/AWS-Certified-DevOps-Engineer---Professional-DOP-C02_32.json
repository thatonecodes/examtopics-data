{"pageProps":{"questions":[{"id":"twWcxUrisrWv1nJCoXra","question_images":[],"unix_timestamp":1720187100,"answer_images":[],"question_text":"A company uses an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to deploy its web applications on containers. The web applications contain confidential data that cannot be decrypted without specific credentials.\n\nA DevOps engineer has stored the credentials in AWS Secrets Manager. The secrets are encrypted by an AWS Key Management Service (AWS KMS) customer managed key. A Kubernetes service account for a third-party tool makes the secrets available to the applications. The service account assumes an IAM role that the company created to access the secrets.\n\nThe service account receives an Access Denied (403 Forbidden) error while trying to retrieve the secrets from Secrets Manager.\n\nWhat is the root cause of this issue?","question_id":156,"answer_ET":"B","answer_description":"","choices":{"D":"The IAM role that is assumed by the Kubernetes service account does not have permission to access the EKS cluster.","C":"The key policy for the customer managed key does not allow the EKS cluster IAM role to use the key.","B":"The key policy for the customer managed key does not allow the Kubernetes service account IAM role to use the key.","A":"The IAM role that is attached to the EKS cluster does not have access to retrieve the secrets from Secrets Manager."},"isMC":true,"discussion":[{"timestamp":"1738410840.0","comment_id":"1349849","poster":"jojewi8143","content":"Selected Answer: B\nB seems correct to me","upvote_count":"2"},{"comments":[{"poster":"jamesf","upvote_count":"2","content":"If the IAM role has the correct permissions to access Secrets Manager but still receives an \"Access Denied\" error, the issue is likely related to the KMS key policy. Specifically, the key policy needs to explicitly allow the IAM role to use the key for decrypting the secrets.\n\nSo, the error message indicates that the key policy for the customer-managed KMS key does not include the necessary permissions for the IAM role assumed by the Kubernetes service account. Adjusting the key policy to grant the required permissions should resolve the issue.","comment_id":"1258571","timestamp":"1722401940.0"}],"comment_id":"1258570","upvote_count":"2","content":"Selected Answer: B\nWhen a service account in Amazon EKS tries to access secrets in AWS Secrets Manager, it does so by assuming an IAM role. The permissions required to access these secrets include:\n- Secrets Manager permissions: The IAM role must have the necessary permissions to retrieve the secrets from AWS Secrets Manager.\n- KMS key permissions: The IAM role must also have permissions to use the AWS KMS key that encrypts the secrets.","poster":"jamesf","timestamp":"1722401940.0"},{"timestamp":"1721040120.0","content":"---> B","upvote_count":"3","poster":"tgv","comment_id":"1248272"},{"timestamp":"1720941180.0","upvote_count":"3","poster":"trungtd","content":"Selected Answer: B\nThe IAM role assumed by the Kubernetes service account, not the EKS cluster IAM role => C is wrong","comment_id":"1247660"}],"answers_community":["B (100%)"],"answer":"B","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/143360-exam-aws-certified-devops-engineer-professional-dop-c02/","exam_id":23,"timestamp":"2024-07-05 15:45:00"},{"id":"oReqDiA3S5y52mjF6Om8","topic":"1","timestamp":"2023-04-08 09:14:00","answer_description":"","discussion":[{"comments":[{"upvote_count":"2","content":"May I add that AWS Opswork offers lifecycle events which you can leverage to execute custom actions on the EC2 instance for example retrieving metadata from S3 as the question requested.","poster":"flaacko","timestamp":"1723815480.0","comment_id":"1267169"}],"comment_id":"1004281","timestamp":"1694377680.0","content":"Selected Answer: B\nBoth Amazon CloudWatch's recover action and EC2 Auto Recovery are designed to respond to system status check failures, not instance status check failures. System status check failures indicate issues with the underlying hardware, while instance status check failures are often related to issues within your instance (like an OS-level issue).\n\nIf the requirement is to handle unresponsiveness due to both system-level and instance-level issues, neither option A nor C would fully meet the requirement. In that case, AWS OpsWorks with auto healing (Option B) could be a better fit since OpsWorks allows you to configure more complex health checks and could recover from both system-level and instance-level issues.\n\nSo, if you want to handle both types of unresponsiveness, Option B would be the most comprehensive solution.","poster":"Jonfernz","upvote_count":"12"},{"poster":"endian675","comment_id":"1323794","upvote_count":"2","timestamp":"1733699700.0","content":"Selected Answer: B\nOpsWorks has now been retired, so don't expect to see this question. However, the answer appears to be B. \n\nA: doesn't make sense because S3 notifications only happen if the S3 objects are modified.\nC: same argument as A\nD: impossible."},{"comment_id":"1315230","content":"Every options are wrong at this moment. Opsworks reached EOL. Other options do not make any sense.","upvote_count":"1","poster":"BrusingWayne","timestamp":"1732105200.0"},{"timestamp":"1731859560.0","content":"The best approach is C, using EC2 Auto Recovery to monitor and recover the instance if it becomes unresponsive, combined with S3 event notifications to ensure the application metadata is properly retrieved after the instance is back online.","comment_id":"1313649","upvote_count":"1","poster":"Ravi_Bulusu"},{"timestamp":"1717743120.0","poster":"HarryLy","content":"Selected Answer: B\nB seem correct","comment_id":"1225941","upvote_count":"1"},{"comment_id":"1221269","content":"Identical with Question #: 102","upvote_count":"1","timestamp":"1717018320.0","poster":"Gomer"},{"upvote_count":"1","poster":"hoazgazh","timestamp":"1712798100.0","content":"Selected Answer: B\nTo automatic restart, must pull artifact for proactive","comment_id":"1193368"},{"poster":"thanhnv142","comment_id":"1134718","timestamp":"1706514000.0","content":"B: is correct: AWS opsworks auto healing will monitor the healthiness of EC2. If there is failure, restart EC2 and pull data from S3 to EC2\nA: incorrect because no mention of method to trigger S3 and S3 will not trigger by itself\nC: incorrect because no mention of method to trigger S3 and S3 will not trigger by itself\nD: Cloud formation only for deploy, this task is about opswork","upvote_count":"3"},{"timestamp":"1703127180.0","upvote_count":"3","content":"Selected Answer: B\nOpWorks is deprecated now , So will it be part of exam ? What is the point of learning of service that are not , going to use.","comment_id":"1102129","poster":"z_inderjot"},{"comments":[{"comment_id":"1092336","upvote_count":"1","poster":"harithzainudin","content":"yes indeed. its EOL","timestamp":"1702195860.0"}],"comment_id":"1064159","upvote_count":"3","content":"Selected Answer: B\nOpWorks is EOL now, however, I think this is the correct answer currenty.","timestamp":"1699296000.0","poster":"TheAWSRhino"},{"content":"Selected Answer: B\nA and C are wrong because S3 event notification destination is lambda, sqs and sns topic, you can't directly push metadata to EC2;\nD is wrong because although user data can retrieve s3 metadata, it can't restart automatically.","timestamp":"1693819800.0","poster":"beanxyz","comment_id":"998424","upvote_count":"4"},{"poster":"n_d1","content":"Selected Answer: B\nB. It doesn't make sense for an S3 event notification to be triggered by an EC2 instance being restarted. The OpsWorks autohealing capability can detect failed instances and replace them. \nAfter the auto-healed instance is back online, OpsWorks triggers a Configure lifecycle event on the instance. The metadata from S3 could be retrieved by the lifecycle event with a recipe.\n\nhttps://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-autohealing.html\nhttps://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook-events.html\nhttps://github.com/awsdocs/aws-opsworks-user-guide/blob/master/doc_source/create-custom-configure.md","timestamp":"1686859920.0","comment_id":"924560","upvote_count":"2"},{"content":"Selected Answer: B\nB, not simplest one but the only that meets requirements.\nFor A - how can you push data from S3 to EC2? Data needs to be pulled from EC2.","timestamp":"1686382260.0","upvote_count":"2","comment_id":"919866","poster":"madperro"},{"content":"Selected Answer: A\nA for me\n By creating a CloudWatch alarm for the StatusCheckFailed metric, the system can detect if the instance becomes unresponsive. The recover action can then be triggered to automatically stop and start the instance, ensuring it restarts or relaunches when necessary.\n\nAdditionally, an S3 event notification can be set up to push the metadata to the instance once it is back up and running. This ensures that the application metadata is retrieved and available after the restart","timestamp":"1684826220.0","comment_id":"904673","poster":"Akaza","comments":[{"upvote_count":"3","comment_id":"910367","poster":"bcx","content":"The second part would not work. An S3 notification event occurs only when actions occur on the object. When you restart the instance, nobody is overwriting the object to trigger the notification. IMHO.","timestamp":"1685459640.0"}],"upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: B\nB seems to be more feasible in this case.","comment_id":"884066","timestamp":"1682747940.0","poster":"ParagSanyashiv"},{"poster":"Mail1964","timestamp":"1682601780.0","upvote_count":"1","comment_id":"882671","content":"https://aws.amazon.com/about-aws/whats-new/2022/03/amazon-ec2-default-automatic-recovery/"},{"upvote_count":"1","comments":[{"content":"\"Use an S3 event notification to push the metadata to the instance when the instance is back up and running.\" makes no sense","poster":"aussiehoa","upvote_count":"1","comment_id":"966898","timestamp":"1690696680.0"}],"comment_id":"871157","content":"I'd say the answer is A ..you can configure Amazon CloudWatch to monitor the EC2 instance and trigger an automatic restart or relaunch if it becomes unresponsive. You can set up a CloudWatch alarm to monitor the instance's CPU utilization, network traffic, or other metrics, and define an action to take if the alarm is triggered, such as rebooting the instance or terminating and relaunching it.","timestamp":"1681579500.0","poster":"alce2020"},{"upvote_count":"1","timestamp":"1680938040.0","content":"Selected Answer: B\nA and C both is wrong cause recover is only for system status check failure. So if it's instance status check fails, it will not respond.","poster":"ele","comment_id":"864482"}],"url":"https://www.examtopics.com/discussions/amazon/view/105569-exam-aws-certified-devops-engineer-professional-dop-c02/","isMC":true,"answer":"B","question_text":"A company runs an application on one Amazon EC2 instance. Application metadata is stored in Amazon S3 and must be retrieved if the instance is restarted. The instance must restart or relaunch automatically if the instance becomes unresponsive.\nWhich solution will meet these requirements?","choices":{"B":"Configure AWS OpsWorks, and use the auto healing feature to stop and start the instance. Use a lifecycle event in OpsWorks to pull the metadata from Amazon S3 and update it on the instance.","C":"Use EC2 Auto Recovery to automatically stop and start the instance in case of a failure. Use an S3 event notification to push the metadata to the instance when the instance is back up and running.","D":"Use AWS CloudFormation to create an EC2 instance that includes the UserData property for the EC2 resource. Add a command in UserData to retrieve the application metadata from Amazon S3.","A":"Create an Amazon CloudWatch alarm for the StatusCheckFailed metric. Use the recover action to stop and start the instance. Use an S3 event notification to push the metadata to the instance when the instance is back up and running."},"question_id":157,"unix_timestamp":1680938040,"question_images":[],"exam_id":23,"answer_images":[],"answer_ET":"B","answers_community":["B (97%)","3%"]},{"id":"AbSXpOV1xQCElvFTwscO","exam_id":23,"url":"https://www.examtopics.com/discussions/amazon/view/143359-exam-aws-certified-devops-engineer-professional-dop-c02/","isMC":true,"question_images":[],"unix_timestamp":1720186020,"answer_description":"","question_text":"A company is migrating its product development teams from an on-premises data center to a hybrid environment. The new environment will add four AWS Regions and will give the developers the ability to use the Region that is geographically closest to them.\n\nAll the development teams use a shared set of Linux applications. The on-premises data center stores the applications on a NetApp ONTAP storage device. The storage volume is mounted read-only on the development on-premises VMs. The company updates the applications on the shared volume once a week.\n\nA DevOps engineer needs to replicate the data to all the new Regions. The DevOps engineer must ensure that the data is always up to date with deduplication. The data also must not be dependent on the availability of the on-premises storage device.\n\nWhich solution will meet these requirements?","question_id":158,"discussion":[{"content":"Selected Answer: D\nOption C does involve using Amazon FSx for NetApp ONTAP, it doesn’t address the deduplication requirement or the independence from the availability of the on-premises storage device. Additionally, SnapMirror relationships are typically used for data replication within the same storage system rather than across multiple Regions.\n\nFor the specific requirements of deduplication, independence, and multi-Region replication, Option D (using Amazon EFS with AWS DataSync) is a more suitable solution.","timestamp":"1724638860.0","upvote_count":"1","poster":"limelight04","comment_id":"1272378"},{"content":"Selected Answer: C\nAmazon FSx for NetApp ONTAP provides a managed NetApp ONTAP experience in the cloud. By creating Multi-AZ FSx for ONTAP instances in each Region, you can replicate data with high availability and redundancy.\n\nCheckout cheaper contributor access here: https://exammatter.net/\n\nSnapMirror is a replication technology provided by NetApp that allows for efficient and reliable data replication. Configuring SnapMirror relationships between your on-premises NetApp storage device and the FSx for ONTAP instances will ensure that your data is consistently replicated across all AWS Regions.","timestamp":"1723099920.0","poster":"Duke315","upvote_count":"3","comment_id":"1262355"},{"comment_id":"1258576","content":"Selected Answer: C\nAmazon FSx for NetApp ONTAP provides a managed NetApp ONTAP experience in the cloud. By creating Multi-AZ FSx for ONTAP instances in each Region, you can replicate data with high availability and redundancy.\n\nSnapMirror is a replication technology provided by NetApp that allows for efficient and reliable data replication. Configuring SnapMirror relationships between your on-premises NetApp storage device and the FSx for ONTAP instances will ensure that your data is consistently replicated across all AWS Regions.","timestamp":"1722402480.0","upvote_count":"3","poster":"jamesf"},{"content":"---> C","timestamp":"1721040300.0","poster":"tgv","upvote_count":"2","comment_id":"1248275"},{"timestamp":"1720942140.0","upvote_count":"3","poster":"trungtd","content":"Selected Answer: C\nC\nhttps://docs.aws.amazon.com/fsx/latest/ONTAPGuide/migrating-fsx-ontap-snapmirror.html","comment_id":"1247665"},{"timestamp":"1720298460.0","content":"C\nhttps://aws.amazon.com/blogs/storage/cross-region-disaster-recovery-with-amazon-fsx-for-netapp-ontap/","poster":"getadroit","upvote_count":"2","comment_id":"1243551"}],"answers_community":["C (90%)","10%"],"answer_ET":"C","topic":"1","answer":"C","timestamp":"2024-07-05 15:27:00","answer_images":[],"choices":{"A":"Create an Amazon S3 File Gateway in the on-premises data center. Create S3 buckets in each Region. Set up a cron job to copy the data from the storage device to the S3 File Gateway. Set up S3 Cross-Region Replication (CRR) to the S3 buckets in each Region.","B":"Create an Amazon FSx File Gateway in one Region. Create file servers in Amazon FSx for Windows File Server in each Region. Set up a cron job to copy the data from the storage device to the FSx File Gateway.","C":"Create Multi-AZ Amazon FSx for NetApp ONTAP instances and volumes in each Region. Configure a scheduled SnapMirror relationship between the on-premises storage device and the FSx for ONTAP instances.","D":"Create an Amazon Elastic File System (Amazon EFS) file system in each Region. Deploy an AWS DataSync agent in the on-premises data center. Configure a schedule for DataSync to copy the data to Amazon EFS daily."}},{"id":"rBqumfTVG8L1tigNPzZS","answer_ET":"AD","question_images":[],"topic":"1","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/143375-exam-aws-certified-devops-engineer-professional-dop-c02/","discussion":[{"content":"Selected Answer: AD\nOption A addresses the need to anonymize PII before moving data to the development environment. By using Amazon Macie, you can identify PII in the production S3 bucket. AWS Step Functions can orchestrate a workflow to redact this PII before transferring the data. This ensures compliance with data protection requirements. You need to provide the necessary KMS key permissions for decrypting and encrypting data as it moves between accounts.\n\nOption D ensures that the data update process is automated and scheduled. Using Amazon EventBridge to trigger the AWS Step Functions state machine on a weekly basis automates the data transfer and anonymization process.","poster":"jamesf","upvote_count":"4","timestamp":"1722403140.0","comment_id":"1258582"},{"upvote_count":"3","comment_id":"1250881","timestamp":"1721368680.0","content":"Selected Answer: AD\n---> A D","poster":"tgv"},{"upvote_count":"3","poster":"trungtd","comment_id":"1247667","timestamp":"1720942560.0","content":"Selected Answer: AD\nA. Anonymizing PII in the Production Account\nD. Automating the Weekly Data Transfer \n\nB suggests replicating the data before redacting PII, which violates the requirement \nC does not ensure that the PII is redacted before the data is stored in the development environment\nE introduces additional infrastructure management and costs"},{"poster":"getadroit","upvote_count":"1","comment_id":"1243556","timestamp":"1720298940.0","content":"redact should be done before"},{"content":"A & D\nhttps://aws.amazon.com/blogs/security/how-to-use-amazon-macie-to-preview-sensitive-data-in-s3-buckets/","timestamp":"1720298880.0","comment_id":"1243555","poster":"getadroit","upvote_count":"2"}],"isMC":true,"unix_timestamp":1720197780,"answers_community":["AD (100%)"],"answer":"AD","choices":{"E":"Create a development environment from the CloudFormation template in the development account. Schedule a cron job on an Amazon EC2 instance to run once a week to start the S3 Batch Operations job.","C":"Set up an S3 Batch Operations job to copy files from the production S3 bucket to the development S3 bucket. In the development account, configure an AWS Lambda function to redact ail PII. Configure S3 Object Lambda to use the Lambda function for S3 GET requests. Give the Lambda function's IAM role encrypt and decrypt permissions on the KMS key in the development account.","B":"Set up S3 replication between the production S3 bucket and the development S3 bucket. Activate Amazon Macie on the development S3 bucket. Create an AWS Step Functions state machine to initiate a discovery job and redact all PII as the files are copied to the development S3 bucket. Give the state machine tasks encrypt and decrypt permissions on the KMS key in the development account.","D":"Create a development environment from the CloudFormation template in the development account. Schedule an Amazon EventBridge rule to start the AWS Step Functions state machine once a week.","A":"Activate Amazon Macie on the S3 bucket in the production account. Create an AWS Step Functions state machine to initiate a discovery job and redact all PII before copying files to the S3 bucket in the development account. Give the state machine tasks decrypt permissions on the KMS key in the production account. Give the state machine tasks encrypt permissions on the KMS key in the development account."},"timestamp":"2024-07-05 18:43:00","question_text":"A company has an application that stores data that includes personally identifiable information (PII) in an Amazon S3 bucket. All data is encrypted with AWS Key Management Service (AWS KMS) customer managed keys. All AWS resources are deployed from an AWS CloudFormation template.\n\nA DevOps engineer needs to set up a development environment for the application in a different AWS account. The data in the development environment's S3 bucket needs to be updated once a week from the production environment's S3 bucket.\n\nThe company must not move PII from the production environment without anonymizing the PII first. The data in each environment must be encrypted with different KMS customer managed keys.\n\nWhich combination of steps should the DevOps engineer take to meet these requirements? (Choose two.)","answer_description":"","question_id":159,"exam_id":23},{"id":"mS0J1wGbNP557TviPIM3","choices":{"B":"Create an IAM role that has a policy that allows EventBridge to use Systems Manager to run commands in the EKS cluster's nodes. Create a Systems Manager State Manager association that uses the nodes' machine size to prefetch corresponding container images.","D":"Create an IAM role that has a policy that allows EventBridge to use Systems Manager to run commands in the EKS cluster's control plane nodes. Create a Systems Manager State Manager association that uses the nodes' tags to prefetch corresponding container images.","A":"Create an IAM role that has a policy that allows EventBridge to use Systems Manager to run commands in the EKS cluster's control plane nodes. Create a Systems Manager State Manager association that uses the control plane nodes' tags to prefetch corresponding container images.","C":"Create an IAM role that has a policy that allows EventBridge to use Systems Manager to run commands in the EKS cluster's nodes. Create a Systems Manager State Manager association that uses the nodes' tags to prefetch corresponding container images."},"isMC":true,"question_text":"A company uses an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to host its machine learning (ML) application. As the ML model and the container image size grow, the time that new pods take to start up has increased to several minutes.\n\nA DevOps engineer needs to reduce the startup time to seconds. The solution must also reduce the startup time to seconds when the pod runs on nodes that were recently added to the cluster.\n\nThe DevOps engineer creates an Amazon EventBridge rule that invokes an automation in AWS Systems Manager. The automation prefetches the container images from an Amazon Elastic Container Registry (Amazon ECR) repository when new images are pushed to the repository. The DevOps engineer also configures tags to be applied to the cluster and the node groups.\n\nWhat should the DevOps engineer do next to meet the requirements?","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/143374-exam-aws-certified-devops-engineer-professional-dop-c02/","answer_ET":"C","topic":"1","exam_id":23,"answer_images":[],"question_id":160,"unix_timestamp":1720197360,"discussion":[{"comment_id":"1247669","upvote_count":"6","poster":"trungtd","content":"Selected Answer: C\nThe control plane manages the Kubernetes cluster but does not run the application containers => A & D wrong\nMachine size is not a practical or flexible approach to determining where images should be prefetched. Should be Tag =>B Wrong","timestamp":"1720943040.0"},{"comment_id":"1332054","upvote_count":"2","poster":"youonebe","content":"Selected Answer: C\ncontrol plane is fully managed by aws.","timestamp":"1735236540.0"},{"upvote_count":"3","content":"Selected Answer: C\n---> C","comment_id":"1250885","poster":"tgv","timestamp":"1721368740.0"},{"comment_id":"1243557","content":"C\nhttps://aws.amazon.com/blogs/containers/start-pods-faster-by-prefetching-images/","timestamp":"1720299360.0","upvote_count":"2","poster":"getadroit"}],"timestamp":"2024-07-05 18:36:00","question_images":[],"answer":"C","answers_community":["C (100%)"]}],"exam":{"lastUpdated":"11 Apr 2025","isBeta":false,"provider":"Amazon","isImplemented":true,"numberOfQuestions":355,"isMCOnly":true,"name":"AWS Certified DevOps Engineer - Professional DOP-C02","id":23},"currentPage":32},"__N_SSP":true}