{"pageProps":{"questions":[{"id":"Ce3kivQD7oztlxodmye4","answer_images":[],"discussion":[{"comment_id":"1353832","upvote_count":"1","poster":"GOTJ","content":"Selected Answer: B\nSeveral links below prove that option \"B\" is correct, regardless of the \"NLB recreation\" drawback. \n\nIt's time to kick option C out (it was my first guess, I must confess)\n\nDDoS prevention, even though useful, is not required by the company. The company is interested SOLELY in prevent \"unauthorized access\" to the application. In the absence of more specific information, I came to the conclusion that the company detected some \"weird ips\" trying to access the application. After some investigation, I came to the conclusion that AWS Shield Advanced doesn't provide this feature for ips if they weren't previously involved in a DDoS attack. \n\nIn an on-premises environment, I would setup a firewall rule with an allow list to accomplish this requirement, which is precisely what option \"B\" offers.","timestamp":"1739095560.0"},{"comment_id":"1341365","timestamp":"1736999700.0","poster":"FlyingHawk","upvote_count":"2","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/containers/network-load-balancers-now-support-security-groups/"},{"timestamp":"1735972800.0","comment_id":"1336289","upvote_count":"3","poster":"LeonSauveterre","comments":[{"upvote_count":"2","content":"https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-security-groups.html","poster":"Salilgen","comment_id":"1337910","timestamp":"1736335800.0"}],"content":"Selected Answer: D\nA - AWS WAF works at Layer 7 (application layer) and is designed for HTTP/HTTPS traffic, so WAF works only with Application Load Balancers (ALB), API Gateway, and CloudFront.\nC - Works but comes with unnecessary complexity and introduces architectural changes.\nSo A & C are out. I'm actually torn between B and D.\n\nIf the primary issue is unauthorized IP access and not large-scale DDoS attacks, then B might be the answer, but NLBs do not directly associate with security groups. Security groups are applied to the targets of the NLB (EC2 instances, IP addrs, or ALBs). Also, this is an architectural change.\n\nOn the other hand, if the primary concern includes DDoS attacks, option D (AWS Shield Advanced) becomes more relevant but this is so much more expensive and may still be overkill for simple IP-based access control. I'm gonna go with D if it shows up in my exam."},{"content":"Selected Answer: B\nTricky one. About option A > AWS WAF does not support Network Load Balancers (NLBs) directly. NLBs operate at the transport layer (Layer 4), while AWS WAF is designed to work with Application Load Balancers (ALBs) at the application layer (Layer 7).....Given that the requirement is to improve application security for a Network Load Balancer with minimal architectural changes, the most appropriate solution would be Option B","timestamp":"1735557840.0","poster":"Denise123","upvote_count":"2","comment_id":"1334065"},{"comment_id":"1331351","content":"Selected Answer: B\nshield is only for DDos attacks protection","timestamp":"1735103460.0","upvote_count":"1","poster":"EllenLiu"},{"content":"Selected Answer: D\nThe correct answer is D. Use AWS Shield Advanced to provide enhanced DDoS protection and prevent unauthorized access attempts.\n\nExplanation:\n\nOption D: Correct. AWS Shield Advanced is designed to protect against DDoS attacks, which can be a source of unauthorized access attempts. It provides enhanced protection features for applications behind a Network Load Balancer, offering additional security measures without requiring significant architectural changes. By leveraging AWS Shield Advanced, the company can gain comprehensive DDoS protection tailored for use with their existing NLB setup.\n\nOption B: Incorrect. NLBs do not support security groups which are applicable to instances, not to the NLB itself. In addition, recreating the NLB to deal with unauthorized access attempts does not align with the requirement for minimal architectural change.","poster":"Anyio","upvote_count":"3","timestamp":"1735099380.0","comment_id":"1331340"},{"upvote_count":"4","timestamp":"1734279060.0","comment_id":"1326954","content":"Selected Answer: D\nUse AWS Shield Advanced to provide enhanced DDoS protection and prevent unauthorized access attempts.","poster":"dragossky"},{"upvote_count":"1","comment_id":"1319729","timestamp":"1732886280.0","content":"Selected Answer: B\nReal-time data processing normally use RTP Protocol which uses a range of ports to deliver audio and video streams. It doesn't specifically says HTTPS so i assume, it can't use WAF to control the traffic since it operates in HTTP/HTTPS Level only.\n\nNot designed for real-time:\nHTTP is primarily designed for request-response communication, which involves sending a request and then waiting for a full response, making it less efficient for continuous data streams needed in real-time applications","poster":"ckhemani"},{"poster":"ttttttttttttttttttttttt","timestamp":"1732581060.0","comments":[{"comment_id":"1319991","poster":"ARV14","content":"Waf supports ALB layer7, not nlb","upvote_count":"2","timestamp":"1732930320.0"}],"upvote_count":"1","content":"Selected Answer: A\nWhy is it not A?","comment_id":"1317840"},{"content":"Selected Answer: D\nThe answer should be D. It makes no sense to pick B for a public app in cases of DDoS, SGs wouldn't help with that. It's like, the closer the questions end, the more trolls left.","upvote_count":"3","timestamp":"1731601200.0","comment_id":"1312154","poster":"Sergantus"},{"poster":"mk168898","content":"I don't think B is correct. if you only allow selected IPs to access then this company cannot host their video streaming service to the public.\n\nD should be the correct answer. AWS shield advanced if I rmb correctly prevent unauthorised attempts","timestamp":"1731400920.0","upvote_count":"1","comment_id":"1310494"},{"timestamp":"1725648360.0","upvote_count":"3","poster":"Jeyaluxshan","comment_id":"1279757","content":"Network Load Balancers (NLB) now supports security groups, enabling you to filter the traffic that your NLB accepts and forwards to your application. Using security groups, you can configure rules to help ensure that your NLB only accepts traffic from trusted IP addresses, and centrally enforce access control policies. This improves your application's security posture and simplifies operations"},{"upvote_count":"3","poster":"AbhiBK","comment_id":"1277189","content":"Answer is D","timestamp":"1725337200.0"},{"comment_id":"1269088","timestamp":"1724132040.0","content":"Selected Answer: B\nB is correct","poster":"[Removed]","upvote_count":"1"},{"timestamp":"1722806400.0","upvote_count":"1","comment_id":"1260816","poster":"komorebi","content":"Selected Answer: B\nAnswer is B"},{"comment_id":"1260577","poster":"example_","timestamp":"1722762420.0","content":"Selected Answer: B\nhttps://aws.amazon.com/about-aws/whats-new/2023/08/network-load-balancer-supports-security-groups/","upvote_count":"4"}],"timestamp":"2024-08-04 11:07:00","topic":"1","choices":{"A":"Implement a series of AWS WAF rules directly on the NLB to filter out unauthorized traffic.","B":"Recreate the NLB with a security group to allow only trusted IP addresses.","D":"Use AWS Shield Advanced to provide enhanced DDoS protection and prevent unauthorized access attempts.","C":"Deploy a second NLB in parallel with the existing NLB configured with a strict IP address allow list."},"answers_community":["B (48%)","D (48%)","4%"],"question_id":941,"answer_description":"","answer":"B","unix_timestamp":1722762420,"url":"https://www.examtopics.com/discussions/amazon/view/144979-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"question_text":"A company hosts a video streaming web application in a VPC. The company uses a Network Load Balancer (NLB) to handle TCP traffic for real-time data processing. There have been unauthorized attempts to access the application.\n\nThe company wants to improve application security with minimal architectural change to prevent unauthorized attempts to access the application.\n\nWhich solution will meet these requirements?","exam_id":31,"answer_ET":"B","isMC":true},{"id":"B8l2X28QL1erjdgDOaos","choices":{"B":"Use server-side encryption with AWS KMS keys (SSE-KMS) for the SNS topic instead of customer managed keys.","C":"Create a resource policy for the encryption key that the SNS topic uses that has the necessary AWS KMS permissions.","F":"Configure a Lambda execution role that has the necessary IAM permissions to use a customer managed key in AWS KMS.","D":"Specify the Lambda function's Amazon Resource Name (ARN) in the SNS topic's resource policy.","A":"Create a resource policy for the SNS topic that allows the Lambda function to publish messages to the topic.","E":"Associate an Amazon API Gateway HTTP API with the SNS topic to control access to the topic by using API Gateway resource policies."},"url":"https://www.examtopics.com/discussions/amazon/view/144981-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"question_id":942,"answer":"ACF","answer_description":"","topic":"1","answer_ET":"ACF","answers_community":["ACF (71%)","ADF (29%)"],"question_images":[],"unix_timestamp":1722763140,"timestamp":"2024-08-04 11:19:00","question_text":"A healthcare company is developing an AWS Lambda function that publishes notifications to an encrypted Amazon Simple Notification Service (Amazon SNS) topic. The notifications contain protected health information (PHI).\n\nThe SNS topic uses AWS Key Management Service (AWS KMS) customer managed keys for encryption. The company must ensure that the application has the necessary permissions to publish messages securely to the SNS topic.\n\nWhich combination of steps will meet these requirements? (Choose three.)","exam_id":31,"discussion":[{"comment_id":"1264205","poster":"Abbas_Abi_AWS","upvote_count":"8","content":"Selected Answer: ACF\nA C F is corrcet","timestamp":"1723389900.0"},{"timestamp":"1739092200.0","upvote_count":"1","content":"Selected Answer: ADF\nDoes a SNS topic need to decrypt an encrypted message in order to deliver it to its subscribers? If so, option \"C\" should be in. If not, it should be out. And I think is out, unless SNS topic needs to apply certain logic to the message prior to subscription deliver (filters). \n\nThis question requires a CSE-KMS approach, which force the Lambda function to encrypt the message before publishing, so option \"F\" is a must (I think everybody here is on the same page with this one). \n\nAlso, option \"A\" should be obvious by now. And even though option \"D\" is redundant, it's technically correct, so it's a better choice.","comment_id":"1353813","poster":"GOTJ"},{"comments":[{"comment_id":"1341404","timestamp":"1737003780.0","content":"For A: https://repost.aws/knowledge-center/sns-topic-lambda and https://repost.aws/knowledge-center/sns-topics-iam-errors-subscriber \nFor F: https://repost.aws/knowledge-center/lambda-kmsaccessdeniedexception-errors","upvote_count":"1","poster":"FlyingHawk"}],"timestamp":"1737003180.0","poster":"FlyingHawk","comment_id":"1341378","upvote_count":"1","content":"Selected Answer: ACF\nFor C - https://docs.aws.amazon.com/sns/latest/dg/sns-enable-encryption-for-topic.html \nPermissions for custom KMS keys – If using a custom KMS key, include the following in the key policy to allow Amazon SNS to encrypt and decrypt messages:"},{"comment_id":"1336294","upvote_count":"2","timestamp":"1735974180.0","content":"Selected Answer: ACF\nA - This is a must-do.\nB - As question stated, we have no reason to replace the keys.\nC - This ensures the function can encrypt messages when publishing.\nD - While specifying the Lambda function's ARN in the SNS topic's resource policy is part of the solution (it's how you grant the \"sns:Publish\" permission), it's not sufficient on its own. You also need the KMS key policy and the Lambda execution role permissions. This option is a part of option A, not a standalone answer.\nE - The Lambda function interacts directly with the SNS topic, and API Gateway is not relevant.\nF - Yes, so that this role will have policies that allow the \"kms:Encrypt\", \"kms:GenerateDataKey,\" and \"kms:Decrypt\" actions on the specific KMS key used to encrypt the topic.","poster":"LeonSauveterre"},{"poster":"EllenLiu","content":"Selected Answer: ACF\nI don't understand why lambda needs KMS to encrypt message.\nIn this scenario, the Lambda function does not need direct permissions to use the KMS key because the encryption and decryption are fully managed by Amazon SNS as part of the SSE-KMS feature.\nSNS is the only service lambda will talk to, The Lambda interacts with SNS using HTTPS and does not directly deal with the encrypted data or the KMS key. so Lambda only needs the permission to publish messages to the SNS topic. \nI would like to choose F only if #F answer can be updated as below: \nF. Configure a Lambda execution role that has the necessary IAM permissions to publish to the SNS topic.\nA: Create a resource policy for the SNS topic => grants lambda the ability to publish messages to the topic\nC: The KMS key resource policy must allow SNS to use the key for encryption and decryption.\nF: Configure the Lambda Execution Role => SNS permissions to publish to the topic","timestamp":"1735108200.0","upvote_count":"2","comment_id":"1331392"},{"upvote_count":"2","comment_id":"1320799","content":"Selected Answer: ADF\n#A: This is essential because the resource policy on the SNS topic will define which entities (like the Lambda function) are allowed to publish messages to it.\n\n#D: By specifying the Lambda function's ARN in the SNS topic policy, you clearly grant access only to that specific Lambda function.\n\n#F: Since the SNS topic uses a customer-managed KMS key, the Lambda execution role must have the necessary permissions to use that key for encryption/decryption when publishing messages.","comments":[{"comment_id":"1341374","upvote_count":"1","poster":"FlyingHawk","content":"D is redundant because Option A already covers the need to allow the Lambda function to publish to the SNS topic. The ARN of the Lambda function would be included in the resource policy created in Option A.","timestamp":"1737002520.0"},{"upvote_count":"1","poster":"JA2018","timestamp":"1733118780.0","comment_id":"1320800","comments":[{"timestamp":"1737002640.0","comment_id":"1341375","upvote_count":"1","content":"C is correct since the SNS topic uses a customer managed key for encryption. The key's resource policy must allow the SNS service to use the key for encryption and decryption.","poster":"FlyingHawk"},{"content":"Key takeaway: \n\n- To ensure the Lambda function can securely publish messages to an encrypted SNS topic, you need to properly configure the SNS topic resource policy to allow the Lambda function access and make sure the Lambda execution role has the necessary KMS permissions to use the customer-managed encryption key.","comment_id":"1320801","timestamp":"1733118780.0","upvote_count":"1","poster":"JA2018"}],"content":"Why the other options are not correct:\n\n#B: The question already states that the SNS topic is using customer-managed KMS keys, so there's no need to switch to server-side encryption with AWS managed keys.\n\n#C: While technically you could create a resource policy on the encryption key itself, it's not the most secure approach as it would grant access to the key itself, not just the ability to use it for SNS encryption.\n\n#E: Introducing an API Gateway layer is unnecessary complexity for this scenario, as you can directly control access to the SNS topic using the Lambda execution role and its permissions."}],"poster":"JA2018","timestamp":"1733118720.0"},{"content":"Selected Answer: ACF\nD is correct too and С is not clear, but seems like it is about KMS policy and adding permissions for sns service which has to be added in case of CMK","timestamp":"1730296920.0","poster":"elmyth","comment_id":"1305022","upvote_count":"4"},{"upvote_count":"1","comment_id":"1290880","content":"Selected Answer: ADF\nmy answer","comments":[{"poster":"Sergantus","timestamp":"1731602340.0","upvote_count":"1","comment_id":"1312166","content":"D is like a part of A, so it makes no sense to pick both, it should be A C F."}],"poster":"agbor_tambe","timestamp":"1727569860.0"},{"comment_id":"1274420","timestamp":"1724920860.0","poster":"progounick","upvote_count":"3","content":"Selected Answer: ACF\nChatGPT agrees with me"},{"timestamp":"1722806460.0","upvote_count":"4","comment_id":"1260817","content":"Selected Answer: ADF\nAnswer is ADF","poster":"komorebi"}],"answer_images":[]},{"id":"OkLerD2MTJA6wb9xW4i7","timestamp":"2022-10-17 16:39:00","answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/85729-exam-aws-certified-solutions-architect-associate-saa-c03/","question_images":[],"isMC":true,"answer_ET":"B","question_text":"A company runs an on-premises application that is powered by a MySQL database. The company is migrating the application to AWS to increase the application's elasticity and availability.\nThe current architecture shows heavy read activity on the database during times of normal operation. Every 4 hours, the company's development team pulls a full export of the production database to populate a database in the staging environment. During this period, users experience unacceptable application latency. The development team is unable to use the staging environment until the procedure completes.\nA solutions architect must recommend replacement architecture that alleviates the application latency issue. The replacement architecture also must give the development team the ability to continue using the staging environment without delay.\nWhich solution meets these requirements?","answer_description":"","discussion":[{"comment_id":"752672","upvote_count":"24","poster":"Buruguduystunstugudunstuy","content":"Selected Answer: B\nThe recommended solution is Option B: Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on-demand.\n\nTo alleviate the application latency issue, the recommended solution is to use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production, and use database cloning to create the staging database on-demand. This allows the development team to continue using the staging environment without delay, while also providing elasticity and availability for the production application.\n\nTherefore, Options A, C, and D are not recommended","timestamp":"1687367700.0","comments":[{"comments":[{"comment_id":"752675","poster":"Buruguduystunstugudunstuy","upvote_count":"8","timestamp":"1687367820.0","content":"Option D: Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Populating the staging database by implementing a backup and restore process that uses the mysqqldump utility is not the recommended solution because it involves taking a full export of the production database, which can cause unacceptable application latency."}],"content":"Option A: Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Populating the staging database by implementing a backup and restore process that uses the mysqldump utility is not the recommended solution because it involves taking a full export of the production database, which can cause unacceptable application latency.\n\nOption C: Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Using the standby instance for the staging database is not the recommended solution because it does not give the development team the ability to continue using the staging environment without delay. The standby instance is used for failover in case of a production instance failure, and it is not intended for use as a staging environment.","poster":"Buruguduystunstugudunstuy","timestamp":"1687367760.0","upvote_count":"18","comment_id":"752674"},{"poster":"MutiverseAgent","timestamp":"1704996840.0","content":"Agree, solution it seems to be the B)\n1) Because the company wants \"elasticity and availability\" as the question mentioned, so I think this leaves us in the two questions related to Aurora discarding the RDS Mysql solution.\n2) Accoding AWS documentation (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Clone.html)\n\"Aurora cloning is especially useful for quickly setting up test environments using your production data, without risking data corruption\"","comment_id":"949134","upvote_count":"8"}]},{"comment_id":"1060640","upvote_count":"11","poster":"arashjs1993","timestamp":"1714655760.0","content":"Selected Answer: B\nAura MySQL is very fast in comparison to RDS for creating a clone of DB, you can create a even clone of a clone while you still work on your own clone, this will allow the dev team continue working during cloning step.\nhttps://aws.amazon.com/blogs/aws/amazon-aurora-fast-database-cloning/"},{"content":"Selected Answer: B\nConclusão:\nA configuração B com o Amazon Aurora MySQL oferece uma solução eficiente, escalável e de alto desempenho, eliminando o problema de latência do aplicativo e permitindo que a equipe de desenvolvimento use o ambiente de preparo sem atrasos. A clonagem de banco de dados Aurora é a chave para atender a esses requisitos com o mínimo impacto operacional.","upvote_count":"1","comment_id":"1339591","poster":"Rcosmos","timestamp":"1736696880.0"},{"comment_id":"1191830","upvote_count":"2","timestamp":"1728420780.0","content":"Selected Answer: B\nAnswer B:\nFew Points about Aurora Database Cloning:\n• Create a new Aurora DB Cluster from an existing one\n• Faster than snapshot & restore\n• Uses copy-on-write protocol\n• Very fast & cost-effective\n• Useful to create a “staging” database from a “production” database without impacting the production database","poster":"MehulKapadia"},{"poster":"ronntsai127","upvote_count":"3","timestamp":"1727435040.0","comment_id":"1184110","content":"When the question did not say about \"cost efficient\", always choose Aurora MySQL > RDS MySQL, because AWS can earn more money in Aurora"},{"timestamp":"1720987080.0","content":"Selected Answer: B\nI'll go for B\nAD: looks time consuming as mysqldump is like a table dump\nC: You cannot use a standby for anything apart from read-only database. This would be an option if dev team was specifically using it for read-only mode.\nhttps://aws.amazon.com/blogs/database/readable-standby-instances-in-amazon-rds-multi-az-deployments-a-new-high-availability-option/","upvote_count":"2","comment_id":"1122897","poster":"awsgeek75"},{"timestamp":"1714367040.0","comment_id":"1056631","upvote_count":"2","content":"B. With Aurora, you can create a clone of the production database quickly and efficiently, without the need for time-consuming backup and restore processes. The development team can spin up the staging database on-demand, eliminating delays and allowing them to continue using the staging environment without interruption.","poster":"Ruffyit"},{"content":"Selected Answer: B\nB is the correct","comment_id":"1020083","poster":"Modulopi","timestamp":"1711648980.0","upvote_count":"1"},{"content":"Selected Answer: C\nNo mention of cost, so technically both options B & C would work.\n \nC. https://aws.amazon.com/blogs/database/readable-standby-instances-in-amazon-rds-multi-az-deployments-a-new-high-availability-option/#:~:text=read%20replicas.-,Amazon%20RDS,-now%20offers%20Multi\n \nB.https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Clone.html#:~:text=cloning%20works.-,Aurora%20cloning,-is%20especially%20useful","timestamp":"1708755060.0","comment_id":"988818","upvote_count":"2","poster":"TariqKipkemei"},{"comment_id":"978725","poster":"Guru4Cloud","upvote_count":"2","content":"Selected Answer: B\nOption B is the best solution that meets all the requirements:\n\nUse Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on-demand.\n\nThe key requirements are to:\n\nAlleviate application latency caused by database exports\nGive development immediate access to a staging environment\nAurora Multi-AZ replicas improves availability and provides fast failover.\n\nDatabase cloning creates an instantly available copy of the production database that can be used for staging. This avoids any export or restoration del","timestamp":"1707669540.0"},{"poster":"cookieMr","timestamp":"1703235180.0","upvote_count":"3","comment_id":"930226","content":"Selected Answer: B\nA. Populating the staging database through a backup and restore process using the mysqldump utility would still result in delays and impact application latency.\n\nB. With Aurora, you can create a clone of the production database quickly and efficiently, without the need for time-consuming backup and restore processes. The development team can spin up the staging database on-demand, eliminating delays and allowing them to continue using the staging environment without interruption.\n\nC. Using the standby instance for the staging database would not provide the development team with the ability to use the staging environment without delay. The standby instance is designed for failover purposes and may not be readily available for immediate use.\n\nD. Relying on a backup and restore process using the mysqldump utility would still introduce delays and impact application latency during the data population phase."},{"timestamp":"1696101300.0","upvote_count":"5","content":"Selected Answer: B\nWith Amazon Aurora MySQL, creating a staging database using database cloning is an easy process. Using database cloning will eliminate the performance issues that occur when a full export is done, and the new database is created. In addition, Amazon Aurora's high availability is provided through Multi-AZ deployment, and read replicas can be used to serve the heavy read traffic without affecting the production database. This solution provides better scalability, elasticity, and availability than the current architecture.","comment_id":"857382","poster":"linux_admin"},{"content":"Answer B:","timestamp":"1695970560.0","poster":"alexiscloud","comment_id":"854097","upvote_count":"1"},{"poster":"bdp123","timestamp":"1692298140.0","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/aws/amazon-aurora-fast-database-cloning/","comment_id":"812361","upvote_count":"3"},{"upvote_count":"1","poster":"john2323","comment_id":"806122","content":"Selected Answer: B\nDatabase cloning is the best answer","timestamp":"1691822940.0"},{"upvote_count":"1","comment_id":"757881","timestamp":"1687809780.0","poster":"techhb","content":"Selected Answer: B\nDatabase cloning is right answer here."},{"comments":[{"content":"This is correct, stand by instances cannot be used for read/write and is for failover targets. Read Replicas can be used for that so B is correct.","upvote_count":"3","timestamp":"1687281000.0","poster":"aadi7","comment_id":"751374"},{"content":"In a RDS Multi-AZ deployment, you can use the standby instance for read-only purposes, such as running queries and reporting. This is known as a \"read replica.\" You can create one or more read replicas of a DB instance and use them to offload read traffic from the primary instance.\nhttps://aws.amazon.com/about-aws/whats-new/2018/01/amazon-rds-read-replicas-now-support-multi-az-deployments/","upvote_count":"4","comment_id":"751369","poster":"aadi7","timestamp":"1687280820.0"}],"upvote_count":"4","comment_id":"747499","timestamp":"1686933180.0","poster":"career360guru","content":"Option B is right.\nYou can not access Standby instance for Read in RDS Multi-AZ Deployments."},{"poster":"333666999","comments":[{"poster":"MutiverseAgent","timestamp":"1704996480.0","upvote_count":"1","comment_id":"949126","content":"Because standby instances are not writable, and at least from my side I occasionally have used the staging database for bug replication. So being able to write might be a thing to consider.","comments":[{"poster":"TTaws","upvote_count":"1","timestamp":"1705081140.0","content":"You don't need to write anything as they are only pulling the reports. (READ requests) \nThe Best answer here is C","comment_id":"949950"}]},{"content":"Also the company wants \"elasticity and availability\" as the question mentioned, so I think this leaves us in the two questions related to Aurora discarding the RDS Mysql solution.","comment_id":"949130","poster":"MutiverseAgent","timestamp":"1704996660.0","upvote_count":"1"}],"comment_id":"743419","timestamp":"1686606000.0","content":"Selected Answer: C\nwhy not C","upvote_count":"4"},{"content":"Selected Answer: B\nOption B","poster":"DivaLight","upvote_count":"1","comment_id":"727730","timestamp":"1685116560.0"},{"comment_id":"717757","upvote_count":"1","timestamp":"1684041540.0","poster":"pspinelli19","content":"Selected Answer: B\nAmazon Aurora Fast Database Cloning is what is required here.\nhttps://aws.amazon.com/blogs/aws/amazon-aurora-fast-database-cloning/"},{"upvote_count":"2","content":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Clone.html","poster":"KLLIM","timestamp":"1682832120.0","comment_id":"707665"},{"poster":"LeGloupier","comment_id":"697473","content":"Selected Answer: B\nB\nDatabase cloning","timestamp":"1681742340.0","upvote_count":"4"}],"choices":{"A":"Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility.","C":"Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Use the standby instance for the staging database.","D":"Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility.","B":"Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on-demand."},"answer":"B","question_id":943,"answers_community":["B (91%)","9%"],"exam_id":31,"unix_timestamp":1666017540,"topic":"1"},{"id":"f8t0TMQWLsha34SXsxIw","choices":{"C":"Purchase a Savings Plan to run the web portal and the document extract program. Run the web portal and the document extract program in an Auto Scaling group.","D":"Create an Amazon S3 bucket to host the web portal. Use Amazon API Gateway and an AWS Lambda function for the existing functionalities. Use the Lambda function to run the document extract program. Invoke the Lambda function when the API that is associated with a new document upload is called.","B":"Run Amazon EC2 Spot Instances in an Auto Scaling group for the web portal. Run the document extract program on EC2 Spot Instances. Start document extract program instances when an employee uploads a new reimbursement document.","A":"Run Amazon EC2 On-Demand Instances in an Auto Scaling group for the web portal. Use an AWS Lambda function to run the document extract program. Invoke the Lambda function when an employee uploads a new reimbursement document."},"timestamp":"2024-08-07 22:10:00","unix_timestamp":1723061400,"topic":"1","answer":"A","question_id":944,"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/145215-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_description":"","answer_images":[],"exam_id":31,"question_text":"A company has an employee web portal. Employees log in to the portal to view payroll details. The company is developing a new system to give employees the ability to upload scanned documents for reimbursement. The company runs a program to extract text-based data from the documents and attach the extracted information to each employee’s reimbursement IDs for processing.\n\nThe employee web portal requires 100% uptime. The document extract program runs infrequently throughout the day on an on-demand basis. The company wants to build a scalable and cost-effective new system that will require minimal changes to the existing web portal. The company does not want to make any code changes.\n\nWhich solution will meet these requirements with the LEAST implementation effort?","isMC":true,"question_images":[],"discussion":[{"timestamp":"1736380440.0","content":"Selected Answer: C\ni hate these types of questions . there is no perfect answer \nA:on demand \"not cost-effective \" , also , how do you want to invoke Lambda . there is no API call\nB: spot instance (\"web portal requires 100% uptime\")\nD:s3 is for static website . it can work but payroll needs to update every 2 weeks and require extensive code change \nC in my opinion is the only correct answer. it is scalable \"ASG\", no code change and cost effective \"saving plan\"","poster":"hpirnaj","upvote_count":"3","comment_id":"1338130"},{"content":"Selected Answer: C\nSpot Instances are not suitable for workloads requiring 100% uptime then B is out.\nD is the best solution but it requires some implementation effort.\nSavings plan (that include Lambda too...) is cheaper than on-demand (option A). \nMoreover, C doesn't require any code change or other AWS services.","poster":"Salilgen","comments":[{"content":"which saving plan to purchase ? Compute Savings Plans, EC2 Instance Savings Plans, and Amazon SageMaker Savings Plans???","comment_id":"1387732","poster":"tch","upvote_count":"1","timestamp":"1741753680.0"}],"timestamp":"1736341320.0","comment_id":"1337949","upvote_count":"1"},{"content":"Selected Answer: A\nAnswer: A\nThis solution offers the most scalable and cost-effective approach with minimal changes to the existing web portal and no code modifications.\n\nWhy Not Other Options?:\n\nOption B (Spot Instances): Spot Instances are not suitable for workloads requiring 100% uptime, as they can be terminated by AWS with short notice.\n\nOption C (Savings Plan): A Savings Plan could reduce costs but does not address the requirement for running the document extraction program efficiently or without code changes.\n\nOption D (S3 with API Gateway and Lambda): This would require significant changes to the existing web portal setup, including moving the portal to S3 and reconfiguring its architecture, which contradicts the requirement of minimal implementation effort and no code change.","poster":"ckhemani","comment_id":"1319739","upvote_count":"3","timestamp":"1732888140.0"},{"timestamp":"1728850380.0","upvote_count":"3","comment_id":"1297103","content":"D makes more sense if the company asks to redesign the whole thing to achieve better operational management, performance, cost effective, etc. However, it requires us to provide solution with MINIMUM change... thus A it is I guess.","poster":"XXXXXlNN"},{"comment_id":"1289719","upvote_count":"4","content":"Selected Answer: A\n\"The company does not want to make any code changes.\" \nOption D requires a complete re-architecture of the web portal to be hosted on Amazon S3 and API Gateway, which involves significant changes to the existing system. This does not align with the requirement of minimal changes to the current setup.","timestamp":"1727384160.0","poster":"JoeTromundo"},{"timestamp":"1726453920.0","poster":"rpmaws","content":"Selected Answer: A\nbecause they don't want any change in code so A is correct.","comment_id":"1284429","upvote_count":"3"},{"content":"Selected Answer: A\nA ChatGPT agrees with me","comment_id":"1274424","timestamp":"1724921100.0","poster":"progounick","upvote_count":"2"},{"poster":"progounick","comment_id":"1273425","content":"Selected Answer: D\nI think D is better choice. Even though A makes sense too, D seems the correct one","timestamp":"1724762460.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\nLeast effort, webportal is simply an interface: D","timestamp":"1724700000.0","comment_id":"1273008","poster":"RealPro111"},{"comment_id":"1267751","upvote_count":"2","timestamp":"1723906800.0","poster":"[Removed]","content":"Selected Answer: A\nA sounds right"},{"upvote_count":"2","poster":"744fdad","comment_id":"1265261","timestamp":"1723569780.0","content":"i think D"},{"poster":"komorebi","comment_id":"1262231","content":"Answer is A","upvote_count":"1","timestamp":"1723064640.0"},{"comment_id":"1262216","upvote_count":"3","poster":"swati1508","timestamp":"1723061400.0","content":"I thinks it’s D"}],"answers_community":["A (70%)","C (20%)","10%"]},{"id":"qYayMyzAtKI1cLuXzz5R","question_images":[],"question_text":"A media company has a multi-account AWS environment in the us-east-1 Region. The company has an Amazon Simple Notification Service (Amazon SNS) topic in a production account that publishes performance metrics. The company has an AWS Lambda function in an administrator account to process and analyze log data.\n\nThe Lambda function that is in the administrator account must be invoked by messages from the SNS topic that is in the production account when significant metrics are reported.\n\nWhich combination of steps will meet these requirements? (Choose two.)","answer":"AC","topic":"1","answer_ET":"AC","url":"https://www.examtopics.com/discussions/amazon/view/145416-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"answer_images":[],"discussion":[{"timestamp":"1723410840.0","comment_id":"1264301","content":"Selected Answer: AB\nVOTE A,B","upvote_count":"5","poster":"siheom"},{"upvote_count":"1","content":"Selected Answer: AC\nThe Correct answer is A,C.\n\nUsing the Amazon SNS console, add a cross-account AWS Lambda subscription to an Amazon SNS topic.\n\nthe Lambda function resource policy allows SNS to invoke the function.\nthe SNS topic access policy allows Lambda to subscribe to the topic.\nNote: The SNS topic resides in account A and the Lambda function resides in account B.","timestamp":"1735135140.0","comment_id":"1331563","poster":"Anyio"},{"poster":"Anyio","timestamp":"1735134360.0","upvote_count":"2","content":"Selected Answer: AB\nThe correct answers are A,B.\n\nExplanation:\n\nOption A: Correct. Creating an IAM resource policy for the Lambda function that allows Amazon SNS to invoke the function is necessary for SNS to have permission to trigger Lambda. This policy ensures that the Lambda function can be invoked by a service principal from the SNS service.\n\nOption B: Correct. Using an Amazon Simple Queue Service (Amazon SQS) queue as an intermediary buffer allows for decoupling the SNS topic from the Lambda function, providing more reliability and handling burst traffic effectively. In this setup, the SNS topic can publish to the SQS queue, and the queue can then trigger the Lambda function to process the messages.","comment_id":"1331558","comments":[{"comment_id":"1331561","upvote_count":"2","timestamp":"1735135080.0","content":"Sorry this is the wrong answer (or second best answer) :). The Correct answer is A,C.\nUsing the Amazon SNS console, add a cross-account AWS Lambda subscription to an Amazon SNS topic.\n\nthe Lambda function resource policy allows SNS to invoke the function.\nthe SNS topic access policy allows Lambda to subscribe to the topic.\nNote: The SNS topic resides in account A and the Lambda function resides in account B.","poster":"Anyio"}]},{"poster":"EllenLiu","content":"Selected Answer: AC\nA: resource-policy for Lambda: should grant SNS to access lambda permission\nC: resource-policy for SNS: should specify who can subscribe SNS topic","upvote_count":"2","timestamp":"1735111080.0","comment_id":"1331411"},{"content":"Selected Answer: AD\n#A: This is the most direct way to allow the SNS topic in the production account to trigger the Lambda function in the administrator account. By creating an IAM policy on the Lambda function that grants SNS permission to invoke it, you establish the necessary access control.\n\n#D: Using an EventBridge rule in the production account allows you to filter and route the SNS notifications specifically to the Lambda function in the administrator account, providing greater control and flexibility over the event delivery .","upvote_count":"1","comment_id":"1320802","timestamp":"1733119140.0","poster":"JA2018"},{"timestamp":"1727570100.0","comment_id":"1290882","poster":"agbor_tambe","upvote_count":"1","content":"Selected Answer: AC\nmost reasonable"},{"timestamp":"1727103480.0","comment_id":"1288170","content":"Selected Answer: AC\nProbably A and C\n\nhttps://repost.aws/knowledge-center/sns-with-crossaccount-lambda-subscription","upvote_count":"3","poster":"mooondooo"},{"upvote_count":"1","comment_id":"1273466","poster":"progounick","timestamp":"1724766420.0","content":"Selected Answer: AC\nA and C seem to be the best answer"},{"poster":"dhewa","upvote_count":"2","timestamp":"1724271000.0","content":"Selected Answer: AC\nNo need to complicate stuff, AWS services already exist only permissions are missing. A&C will set up the necessary permissions and subscriptions for cross-account invocation of the Lambda function by the SNS topic.","comment_id":"1270375"},{"timestamp":"1724171640.0","upvote_count":"1","comment_id":"1269598","content":"A,C correct - While using SQS could be a solution for buffering messages, it introduces additional complexity","poster":"523db89"},{"poster":"jamesukae","comment_id":"1269152","upvote_count":"2","timestamp":"1724134560.0","content":"Selected Answer: BE\nFor me AB is contradict , why we invoke lambda function by both SNS and SQS?\n\nI think BE is correct answer because question also need solution to analyze data."},{"comments":[{"poster":"GOTJ","timestamp":"1739038980.0","content":"I like your reasoning for option \"D\". However, with this setup, EventBridge should be the service that invoke the Lambda function:\n\nPerf Metrics --> SNS --> EventBridge (for filtering and routing \"the significant metrics\") --> Lambda\n\nSince you've detached Lambda from SNS adding a service in between, SNS should no longer invoke the Lambda Function and option \"A\" would be wrong, isn't it?","upvote_count":"1","comment_id":"1353572"}],"comment_id":"1263585","content":"correct answer is AD","timestamp":"1723308720.0","upvote_count":"4","poster":"nebajp"}],"unix_timestamp":1723308720,"timestamp":"2024-08-10 18:52:00","choices":{"D":"Use an Amazon EventBridge rule in the production account to capture the SNS topic notifications. Configure the EventBridge rule to forward notifications to the Lambda function that is in the administrator account.","B":"Implement an Amazon Simple Queue Service (Amazon SQS) queue in the administrator account to buffer messages from the SNS topic that is in the production account. Configure the SQS queue to invoke the Lambda function.","E":"Store performance metrics in an Amazon S3 bucket in the production account. Use Amazon Athena to analyze the metrics from the administrator account.","C":"Create an IAM policy for the SNS topic that allows the Lambda function to subscribe to the topic.","A":"Create an IAM resource policy for the Lambda function that allows Amazon SNS to invoke the function."},"question_id":945,"exam_id":31,"answers_community":["AC (50%)","AB (35%)","Other"],"answer_description":""}],"exam":{"isBeta":false,"numberOfQuestions":1019,"isMCOnly":true,"lastUpdated":"11 Apr 2025","isImplemented":true,"provider":"Amazon","id":31,"name":"AWS Certified Solutions Architect - Associate SAA-C03"},"currentPage":189},"__N_SSP":true}