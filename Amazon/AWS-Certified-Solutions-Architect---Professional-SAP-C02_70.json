{"pageProps":{"questions":[{"id":"sADkS5ulYlQLOZAqN1Ur","discussion":[{"comments":[{"timestamp":"1706964360.0","content":"But the pattern here is known.. 4 hours peak time etc.. not sure if that would be the write answer","poster":"AimarLeo","comment_id":"1139235","upvote_count":"1"},{"comments":[{"timestamp":"1694176680.0","upvote_count":"1","comment_id":"1002466","content":"You can scale DynamoDB tables and global secondary indexes using target tracking scaling policies and scheduled scaling.\nhttps://docs.aws.amazon.com/autoscaling/application/userguide/services-that-can-integrate-dynamodb.html","poster":"tannh"}],"poster":"dqwsmwwvtgxwkvgcvc","comment_id":"987817","content":"How AWS Application Auto Scaling scale the read/write performance of DynamoDB?","timestamp":"1692745500.0","upvote_count":"1"}],"content":"A is correct. On demand mode is for unknown load pattern, auto scaling is for know burst pattern","timestamp":"1673790660.0","poster":"zhangyu20000","comment_id":"776630","upvote_count":"25"},{"content":"Selected Answer: A\nA\non-demand prices can be 7 times higher, given the options it is better to have reserved WCU and RCU and auto scale in the given schedule","poster":"ccort","timestamp":"1674465060.0","comment_id":"785162","upvote_count":"16"},{"timestamp":"1736894280.0","upvote_count":"1","content":"Selected Answer: A\nReserved capacity applies to the baseline level of provisioned throughput. During peak workloads, Auto Scaling dynamically adjusts the provisioned capacity of a DynamoDB table (RCUs and WCUs) based on the actual workload. you are charged on-demand rates for the excess capacity.","poster":"zhen234","comment_id":"1340552"},{"upvote_count":"1","content":"Selected Answer: B\nB. Configure on-demand capacity mode for the table.\n\nExplanation:\nOn-Demand Capacity Mode:\n\nDynamoDB's on-demand capacity mode automatically adjusts to accommodate variable workloads.\nIt eliminates the need to provision RCUs and WCUs, allowing the table to scale up during the 4-hour peak period and scale down during off-peak times, which is cost-effective when usage is highly variable.\nCost Optimization:\n\nWith on-demand capacity, you pay only for the read and write requests that are made. This is ideal for workloads with sporadic or unpredictable traffic patterns, such as this scenario with a weekly 4-hour peak.\nMinimized Operational Overhead:\n\nOn-demand mode requires no manual adjustments or additional services (like Application Auto Scaling), simplifying management and reducing costs related to provisioning errors or overprovisioning.\nAccess Pattern with More Writes:\n\nOn-demand capacity mode is well-suited for write-heavy workloads as it scales automatically to handle higher write throughput during peak times.","poster":"wem","comment_id":"1323242","timestamp":"1733599860.0"},{"timestamp":"1729162140.0","content":"Selected Answer: B\nB is the right answer. Reserved RCU/WCU locks you into fixed cost. Even though on demand is more expensive, the additional cost is paid only for 4 hrs a week.","comment_id":"1299159","comments":[{"poster":"DhirajBansal","upvote_count":"1","content":"but Yes, here in option A it is saying for purchasing average load RCUs and WCUs which will cost less and also auto scaling can be used for scheduled scaling WCU and RCUs which will be cost efficient.","comment_id":"1319015","timestamp":"1732769340.0"}],"upvote_count":"2","poster":"Sin_Dan"},{"upvote_count":"1","content":"A. Use AWS Application Auto Scaling to increase capacity during the peak period. Purchase reserved RCUs and WCUs to match the average load.","timestamp":"1725093840.0","comment_id":"1275484","poster":"amministrazione"},{"content":"I think B is correct. because reserved is not required, ondemand would be better because it requireds only 4 hours per week. so B would be better. Autoscaling of the application can not impact dynamo db tables.","upvote_count":"1","comment_id":"1271514","poster":"subbupro","timestamp":"1724471760.0"},{"upvote_count":"1","poster":"vn_hunglv","timestamp":"1721519580.0","comment_id":"1252032","content":"Selected Answer: A\nTôi chọn A"},{"timestamp":"1721221200.0","content":"Selected Answer: A\nAuto-scaling is for known traffic pattern, On-demand is for unknown traffic patter and also could be more expensive","comment_id":"1249607","poster":"zolthar_z","upvote_count":"2"},{"comments":[{"content":"Nice. Thanks for the link. It explains clearly.\n\nSee this: \"Scheduled scaling – Scale a resource one time only or on a recurring schedule.\"","upvote_count":"1","timestamp":"1732118640.0","comment_id":"1315362","poster":"mnsait"}],"poster":"Malcnorth59","content":"Selected Answer: A\nAWS documentation suggests A is correct:\nhttps://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html","upvote_count":"3","timestamp":"1716295560.0","comment_id":"1214945"},{"content":"A is correct. The focus is minimizing the cost of tables.","timestamp":"1714303140.0","poster":"Kubernetes","upvote_count":"2","comment_id":"1203534"},{"poster":"mav3r1ck","content":"Selected Answer: B\nConsidering the application's need to handle a peak load that is double the average and the fact that the workload is write-heavy, option B (Configure on-demand capacity mode for the table) is the most suitable solution. It directly addresses the variability in workload without requiring upfront capacity planning or additional management overhead, thus likely providing the best cost optimization for this scenario. On-demand capacity mode eliminates the need to scale resources manually or through Auto Scaling and ensures that you only pay for the write and read throughput you consume.","comments":[{"poster":"mav3r1ck","content":"A. AWS Application Auto Scaling with Reserved Capacity\nPros: Auto Scaling allows you to automatically adjust the provisioned throughput to meet demand, and purchasing reserved RCUs and WCUs can reduce costs for the capacity you know you'll consistently use.\nCons: This option might not be as cost-effective for workloads with significant variability and a high write-to-read ratio, especially if the peak load is much higher than the average load. Reserved capacity benefits consistent usage patterns, but the peak load being double the average may not be fully optimized here.","upvote_count":"1","timestamp":"1711146600.0","comment_id":"1180372"},{"content":"B. On-demand Capacity Mode\nPros: On-demand capacity mode is ideal for unpredictable workloads because it automatically scales to accommodate the load without provisioning. You pay for what you use without managing capacity planning. This mode is particularly suitable for the described scenario where the load spikes significantly and unpredictably.\nCons: While potentially more expensive per unit than provisioned capacity with auto-scaling, it eliminates the risk of over-provisioning or under-provisioning.","timestamp":"1711146660.0","comment_id":"1180373","upvote_count":"1","poster":"mav3r1ck"}],"timestamp":"1711146600.0","comment_id":"1180371","upvote_count":"2"},{"timestamp":"1710640140.0","poster":"kz407","comments":[{"upvote_count":"1","content":"I initially thought the same but the AWS definition of Application autoscaling listed here includes DynamoDB: https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html","poster":"Malcnorth59","timestamp":"1716295440.0","comment_id":"1214941"}],"comment_id":"1175523","upvote_count":"2","content":"Selected Answer: A\nA is badly worded however, because it says \"application\" autoscaling. We are not talking about that here. Either it should be reworded as \"DynamoDB autoscaling\" for the answer to be correct.\nOn-demand capacity mode is for unknown read/write patterns. Since the load change patterns are known, anything that involves on-demand capacity modes can be eliminated (hence not B).\nDAX is a caching service deployed in front of DynamoDB. It is geared towards \"performance at scale\". Problem in the use case, is to optimize table costs. Using DAX will incur additional costs. Hence anything that involves DAX (C and D) can also be eliminated."},{"upvote_count":"2","poster":"anubha.agrahari","timestamp":"1709766540.0","comment_id":"1167545","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/database/amazon-dynamodb-auto-scaling-performance-and-cost-optimization-at-any-scale/#:~:text=You%20can%20approximate%20a%20blend,save%20money%20as%20reserved%20capacity"},{"upvote_count":"1","poster":"8608f25","content":"Selected Answer: B\nOption B is the most cost-effective solution for workloads with significant fluctuations and unpredictable access patterns. The on-demand capacity mode automatically adjusts the table’s throughput capacity as needed in response to actual traffic, eliminating the need to manually configure or manage capacity. This mode is ideal for applications with irregular traffic patterns, such as a significant peak once a week, because you only pay for the read and write requests your application performs, without having to provision throughput in advance. Option B directly addresses the requirement to minimize costs associated with fluctuating loads, especially when the load significantly exceeds the average only during a brief period, by leveraging DynamoDB’s on-demand capacity mode to automatically scale and pay only for what is used.","timestamp":"1707443820.0","comment_id":"1145198"},{"comments":[{"poster":"igor12ghsj577","content":"Amazon DynamoDB auto scaling uses the AWS Application Auto Scaling service to dynamically adjust provisioned throughput capacity on your behalf, in response to actual traffic patterns. This enables a table or a global secondary index to increase its provisioned read and write capacity to handle sudden increases in traffic, without throttling. When the workload decreases, Application Auto Scaling decreases the throughput so that you don't pay for unused provisioned capacity.","timestamp":"1706871420.0","comment_id":"1138455","upvote_count":"2"}],"timestamp":"1706869320.0","comment_id":"1138416","content":"Selected Answer: A\nI think there is mistake in answer A, and it should be DynamoDb auto scaling instead of application autos calling. Or application and dynamoDB auto scaling.","upvote_count":"1","poster":"igor12ghsj577"},{"upvote_count":"1","poster":"jpa8300","comment_id":"1109863","timestamp":"1703957820.0","comments":[{"comment_id":"1355532","timestamp":"1739350020.0","content":"The access pattern includes many more writes to the table than read. so I think D incorrect","upvote_count":"1","poster":"longlehoang"}],"content":"Selected Answer: D\nI choose option D, because DAX is not only an accelerator for the Reads, it also cache releasing a lot of load from the DB."},{"poster":"ninomfr64","content":"Selected Answer: A\nA -> You can scale DynamoDB tables and global secondary indexes using target tracking scaling policies and scheduled scaling. In this I would go for scheduled scaling.\nhttps://docs.aws.amazon.com/autoscaling/application/userguide/services-that-can-integrate-dynamodb.html\nB -> on-demand capacity mode is for unknown workload, this is not the case\nC -> DAX come with costs and it helps with reads, while here we have a more write-bound workload\nD -> See B and C comments","comment_id":"1101558","upvote_count":"2","timestamp":"1703079360.0"},{"upvote_count":"1","timestamp":"1699855320.0","poster":"severlight","content":"Selected Answer: A\nwe use scheduled scaling here","comment_id":"1069058"},{"content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/database/amazon-dynamodb-auto-scaling-performance-and-cost-optimization-at-any-scale/#:~:text=You%20can%20approximate%20a%20blend,save%20money%20as%20reserved%20capacity.","timestamp":"1697649480.0","upvote_count":"1","comment_id":"1047098","poster":"whenthan"},{"timestamp":"1694321400.0","content":"Selected Answer: A\nReserved capacity is available for single-Region, provisioned read and write capacity units (RCU and WCU) on DynamoDB tables including global and local secondary indexes. You cannot purchase reserved capacity for replicated WCUs (rWCUs).","poster":"Simon523","comment_id":"1003696","upvote_count":"2"},{"timestamp":"1693963380.0","upvote_count":"1","poster":"awsent","comment_id":"1000061","content":"Correct Answer: A\nApplication auto scaling can be used for scheduled scaling for DynamoDB tables and GSIs\nhttps://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html"},{"upvote_count":"1","poster":"sontls","comment_id":"991733","content":"aababasdasdasdasd","timestamp":"1693185960.0"},{"comment_id":"985715","content":"Selected Answer: A\nRefer https://aws.amazon.com/dynamodb/reserved-capacity/\nReserved capacity is a great option to reduce DynamoDB costs for workloads with steady usage and predictable growth over time\n Reserved capacity mode might be best if you:\n\n Have predictable application traffic.\n Run applications whose traffic is consistent or ramps gradually.\n Can forecast capacity requirements to control costs.","timestamp":"1692527220.0","upvote_count":"2","poster":"venvig"},{"content":"Selected Answer: B\nA. This approach takes into account peak and average loads, but it might lead to unnecessary costs since you have to pay for reserved RCUs and WCUs, even during off-peak times.\n\nB. The on-demand capacity mode can adjust dynamically based on actual demand, making it a suitable option, especially considering the peak lasts only for 4 hours.\n\nC. DAX is designed to accelerate read operations, but the problem description indicates the access pattern is primarily write-focused. Therefore, this option might not be the best choice.\n\nD. This option combines DAX with the on-demand capacity mode, but as mentioned, DAX might not be necessary.\n\nConclusion: Option B (configuring the table for on-demand capacity mode) seems to be the most appropriate choice, as it allows for dynamic capacity scaling during peaks and only pays for the required capacity costs during off-peak times.","poster":"uC6rW1aB","upvote_count":"3","comment_id":"982279","comments":[{"timestamp":"1692745620.0","comment_id":"987819","content":"Yes I am also not sure about option B & D","poster":"dqwsmwwvtgxwkvgcvc","upvote_count":"1"},{"comment_id":"1088621","poster":"subbupro","timestamp":"1701792780.0","upvote_count":"2","content":"A is correct, reserved is only for average load which is less than ondemand . So A is corrclect"},{"content":"Yeh B is listed as correct in Neal's udemy exam set says for this question. However if performance isn't mentioned (Dynamo throttling can occur with reserved capacity); I think A is best if there's a known average & the reserved amount is for the average. Man it would be great if there was some consensus among mock exam providers. FML.","timestamp":"1705006140.0","comment_id":"1120173","poster":"grire974","upvote_count":"1"}],"timestamp":"1692169320.0"},{"comments":[{"upvote_count":"1","content":"If you already know the usage patterns, you save $$ by purchasing reserved RCUs and WCUs. It is what you want to do to save $$ because you will definitely use the reserved units, and what goes beyond that is what autoscaling is for.","comment_id":"976072","poster":"b3llman","timestamp":"1691534820.0"}],"upvote_count":"2","timestamp":"1690993440.0","comment_id":"970369","content":"Correct B.\nOption A uses AWS Application Auto Scaling, which is a service that helps you adjust provisioned capacity automatically in response to actual traffic patterns. However, this option requires you to purchase reserved RCUs and WCUs, which are commitments to pay for a minimum amount of capacity for a specific term. This option can be more expensive and less flexible than on-demand capacity modehttps://aws.amazon.com/blogs/database/amazon-dynamodb-auto-scaling-performance-and-cost-optimization-at-any-scale/","poster":"ggrodskiy"},{"comment_id":"948319","timestamp":"1689013620.0","upvote_count":"2","poster":"Jonalb","content":"Selected Answer: A\nA is correct, very correct!"},{"poster":"NikkyDicky","upvote_count":"1","content":"Selected Answer: D\nA won't work cause you reserve for average load, so peak demand will result in errors\nbetween B and D, D provides an addition, even if small benefit for reads","timestamp":"1688143200.0","comment_id":"939254","comments":[{"poster":"NikkyDicky","comment_id":"939265","upvote_count":"1","timestamp":"1688143980.0","content":"Changing to A after re-reading DDB autoscaling - it actually changes provisioned capacity, so should work"},{"comment_id":"1120184","timestamp":"1705006740.0","upvote_count":"1","poster":"grire974","content":"How does DAX reduce cost? It requires adding ec2 instances into the solution to power your DAX cluster; and the workload is write intensive. I think DAX is for performance; less so cost; perhaps cost if it was extremely read intensive."}]},{"timestamp":"1687777800.0","content":"Selected Answer: B\nThe question states the application is WCU heavy, so DAX will have minimal impact on reducing load/cost, and comes with its own costs, which excludes C and D.\nIt doesn't matter whether the performance needs are unpredictable or not, what matters is they are variable, and that under-performing has been ruled out by the question. So the choice is between provisioning at a constant level high enough to cope with the 4h peak, or provisioning at a level that varies. DDB provides no native mechanism other than on-demand to alter the provisioning levels over time, so B is the answer here.\nOn-demand R/WCU usage isn't any more expensive than explicitly provisioned usage, per unit. The difference is that on-demand usage removes the upper limit on provisioning, so if the application wants to use more, it can, and you pay for it. So for the 4h a week the app needs double the WCU level, DDB will provide it, and the cost per hour will be twice as high, but for the rest of the week the cost will be the same as if you had explicitly provisioned the lower level.","poster":"[Removed]","upvote_count":"2","comment_id":"934329"},{"timestamp":"1686925980.0","content":"Selected Answer: A\nbecause on-demand is cheeper for unpredictable patterns, we can't choose B, C, D","upvote_count":"3","poster":"ailves","comment_id":"925273"},{"timestamp":"1686181800.0","upvote_count":"1","content":"Selected Answer: D\nThis solution meets the requirements by using Application Auto Scaling to automatically increase capacity during the peak period, which will handle the double the average load. And by purchasing reserved RCUs and WCUs to match the average load, it will minimize the cost of the table for the rest of the week when the load is close to the average.","poster":"0r3m","comment_id":"917672"},{"content":"Selected Answer: B\nSince the application load is close to the average load for most of the week and the peak load only occurs once a week for a limited 4-hour period, it is not necessary to provision and pay for provisioned capacity (RCUs and WCUs) to match the peak load. On-demand capacity mode provides the flexibility to automatically scale based on the actual load, allowing you to optimize costs by paying only for the resources consumed during those peak periods.","timestamp":"1685442120.0","comment_id":"910147","upvote_count":"2","poster":"andreitugui"},{"timestamp":"1685351700.0","poster":"EricZhang","upvote_count":"1","comment_id":"909238","content":"A - incorrect. as when peak hour comes, the dynamodb table will throw throttling error\nC & D - incorrect. DAX is for app which is read-intensive\nB - have to choose this"},{"comment_id":"893566","poster":"gameoflove","upvote_count":"1","timestamp":"1683687120.0","content":"Selected Answer: A\nOn Demand Mode is cost optimize"},{"poster":"rajalek","timestamp":"1682243280.0","comment_id":"878155","upvote_count":"1","content":"Utilize on-demand capacity mode for the DynamoDB table - this mode allows the table to automatically scale up and down its capacity based on the actual usage. This means that during the peak load, the table will scale up to handle the increased traffic and scale down during periods of lower traffic. Since the peak load occurs once a week for a 4-hour period, the table will only pay for the resources it actually uses during that time and will not be over-provisioned for the rest of the week.\nAnswer B"},{"content":"A is the answer , using DynamoDB Accelerator (DAX) will be good for Applications that are read-intensive, not write-intensive.https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html#DAX.use-cases","comment_id":"860854","upvote_count":"1","timestamp":"1680601560.0","poster":"mikad"},{"poster":"takecoffe","comment_id":"858387","upvote_count":"2","content":"Selected Answer: D\nDAX is better choice","timestamp":"1680395640.0"},{"timestamp":"1680145260.0","upvote_count":"1","poster":"hgc2023","content":"read and write units are more expensive in on demand mode so I don't think D is the answer","comment_id":"855230"},{"timestamp":"1679991000.0","comment_id":"852997","comments":[{"poster":"igor12ghsj577","timestamp":"1706869080.0","comment_id":"1138414","upvote_count":"1","content":"how application auto scaling which only uses DB can help you to decrease cost of Database itself ?"}],"upvote_count":"2","content":"Selected Answer: A\nUse AWS Application Auto Scaling makes the most sense","poster":"mfsec"},{"timestamp":"1679312880.0","poster":"Dimidrol","comment_id":"844830","upvote_count":"3","content":"Selected Answer: A\nA for me, not B. On-demand is ideal for bursty, new, or unpredictable workloads whose traffic can spike in seconds or minutes, and when underprovisioned capacity would impact the user experience."},{"poster":"dev112233xx","comment_id":"840387","timestamp":"1678920300.0","upvote_count":"2","content":"Selected Answer: D\nD - no doubts..\nIn addition to on-demand, DAX can reduce the Dynamodb cost up to 60%✅"},{"poster":"kiran15789","timestamp":"1678477380.0","upvote_count":"3","comment_id":"835355","content":"Selected Answer: A\nWill go with A in exam as peak load is known"},{"timestamp":"1678270380.0","poster":"kiran15789","content":"Selected Answer: A\ntuning dynamo db is not sufficient, you also need to scale the applicaiton to meet peak loads","comment_id":"832805","upvote_count":"2"},{"poster":"dev112233xx","timestamp":"1678054380.0","content":"Selected Answer: D\nAnswer D makes sense. On-demand is the good option for infrequent access to dynamoDB.\nA option requires a code refactoring","comment_id":"830372","upvote_count":"2"},{"poster":"Sarutobi","comment_id":"823827","content":"Selected Answer: B\nIn this link https://aws.amazon.com/blogs/aws/amazon-dynamodb-on-demand-no-capacity-planning-and-pay-per-request-pricing/ I found this: \"DynamoDB on-demand is useful if your application traffic is difficult to predict and control, your workload has large spikes of short duration, or if your average table utilization is well below the peak.\" I think this is very close to what we are looking for so maybe B.","upvote_count":"1","timestamp":"1677509220.0","comments":[{"timestamp":"1677588360.0","poster":"sambb","upvote_count":"2","comment_id":"824798","content":"Here, the traffic is predicted \"The peak load occurs once a week for a 4-hour period and is double the average load\". Hence, with AWS Autoscaling we can schedule the WCU scaling, which would be way cheaper than on-demand capacity."}]},{"upvote_count":"3","comment_id":"821062","content":"OnDemand when needed is good, but here, we know that only 4 hours is peak.\nSo better purchase the reserved RCUs/WCUs and on top of it enable auto scaling which\nmeets 4 hour high demand. DAX is a extreme performant cache cluster. \nDAX is not ideal for write intensitive, that does not mean use DAX for reads. Look at where DAX does not fit -https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html\nHere for reducing costs,A is correct. See here how provisoned reduce costs-\nhttps://aws.amazon.com/dynamodb/pricing/?refid=ce6876ca-ceb9-46a2-adaa-d36fce8fbba7","timestamp":"1677285840.0","poster":"God_Is_Love"},{"content":"Selected Answer: A\nA. Use AWS Application Auto Scaling to increase capacity during the peak period. Purchase reserved RCUs and WCUs to match the average load.\n\nSince the peak period is only 4 hours a week and the application load is close to the average load for the rest of the week, it is not cost-effective to configure on-demand capacity mode for the table. Instead, AWS Application Auto Scaling can be used to increase the RCUs and WCUs during the peak period to meet the increased demand, and then decrease them to match the average load for the rest of the week. Additionally, reserved capacity can be purchased to match the average load, further reducing costs. Using DynamoDB Accelerator (DAX) in front of the table does not directly address the issue of cost optimization.","upvote_count":"2","comment_id":"810227","timestamp":"1676518980.0","poster":"c73bf38"},{"poster":"zozza2023","timestamp":"1675094700.0","upvote_count":"3","comments":[{"poster":"moota","comments":[{"poster":"moota","comment_id":"804775","content":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html#DAX.use-cases","upvote_count":"2","timestamp":"1676061360.0"},{"poster":"vvahe","upvote_count":"1","timestamp":"1679496840.0","content":"This, DAX is not an option, on demand isn't either, leaves A","comment_id":"847166"}],"upvote_count":"2","comment_id":"804774","content":"DAX is useful for read-intensive loads.","timestamp":"1676061300.0"}],"content":"Selected Answer: A\nhas nothing with DAX here.\nbetween A and B==> A is the answer","comment_id":"793015"},{"comment_id":"791391","poster":"pravi1","upvote_count":"2","content":"A makes sense here. On-demand more costly compared to reserved ones.","timestamp":"1674967320.0"},{"upvote_count":"1","timestamp":"1674523140.0","content":"A SAPC01 #1005","comment_id":"786028","poster":"DDONG"},{"timestamp":"1673644140.0","content":"Selected Answer: B\nB. Configure on-demand capacity mode for the table. This solution will allow the table to automatically scale its capacity based on the actual usage, and will minimize the cost of the table as it will only pay for the capacity used during the peak load period, and not the entire week. Additionally, since the access pattern includes more writes than reads, on-demand capacity mode is a good fit as it is more cost-effective for write-heavy workloads.","comment_id":"774855","upvote_count":"3","poster":"masetromain","comments":[{"timestamp":"1673644140.0","content":"Option D is a possible solution that could meet the requirements, as it leverages DynamoDB Accelerator (DAX) to improve the performance of read operations on the table and also configures on-demand capacity mode for the table which will minimize the cost as it only charges for the requests made to the table.\n\nHowever, it's important to consider that DAX will add some costs to the solution, and it's not guaranteed that the on-demand capacity mode will be enough to handle the peak load, so it's important to monitor the table and make sure that the performance is meeting the expectations.","upvote_count":"1","poster":"masetromain","comment_id":"774856"}]}],"answer_ET":"A","question_text":"A company recently deployed an application on AWS. The application uses Amazon DynamoDB. The company measured the application load and configured the RCUs and WCUs on the DynamoDB table to match the expected peak load. The peak load occurs once a week for a 4-hour period and is double the average load. The application load is close to the average load for the rest of the week. The access pattern includes many more writes to the table than reads of the table.\n\nA solutions architect needs to implement a solution to minimize the cost of the table.\n\nWhich solution will meet these requirements?","topic":"1","unix_timestamp":1673644140,"timestamp":"2023-01-13 22:09:00","choices":{"B":"Configure on-demand capacity mode for the table.","C":"Configure DynamoDB Accelerator (DAX) in front of the table. Reduce the provisioned read capacity to match the new peak load on the table.","A":"Use AWS Application Auto Scaling to increase capacity during the peak period. Purchase reserved RCUs and WCUs to match the average load.","D":"Configure DynamoDB Accelerator (DAX) in front of the table. Configure on-demand capacity mode for the table."},"answers_community":["A (69%)","B (20%)","11%"],"question_images":[],"exam_id":33,"question_id":346,"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/95089-exam-aws-certified-solutions-architect-professional-sap-c02/","answer":"A","answer_images":[],"answer_description":""},{"id":"UBNHzKsXkZYFwn8uYLWP","discussion":[{"timestamp":"1711477860.0","comment_id":"1183517","upvote_count":"12","content":"Selected Answer: C\nOption C - From AWS doc page \"Don't use AWS Organizations to update service control policies (SCPs) attached to an OU that is registered with AWS Control Tower. Doing so could result in the controls entering an unknown state, which will require you to repair your landing zone or re-register your OU in AWS Control Tower. Instead, you can create new SCPs and attach those to the OUs rather than editing the SCPs that AWS Control Tower has created.\" \n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/orgs-guidance.html","poster":"TonytheTiger"},{"content":"Selected Answer: B\nVoting for B: SCP will cause a state drift, since company already use Control Tower","poster":"chelbsik","timestamp":"1707759960.0","comment_id":"1148443","comments":[{"upvote_count":"3","comment_id":"1259451","content":"Adding a new SCP will not cause drift. Modifying an existing SCP that was created by CT would, which is not the case here.","poster":"8693a49","timestamp":"1722524340.0"}],"upvote_count":"6"},{"poster":"sergza888","comment_id":"1475069","timestamp":"1743782160.0","content":"Selected Answer: C\nUnfortunately it is C even though i liked B better \"Proactive controls check resources whenever those resources are created or updated by means of AWS CloudFormation stack operations. Specifically, these proactive controls are implemented as preCreate and preUpdate hook handlers. As a consequence, these controls may not affect requests that are made directly to services through the AWS console, through AWS APIs, or through other means such as AWS SDKs, or other Infrastructure-as-Code (IaC) tools.\"","upvote_count":"1"},{"comment_id":"1311713","upvote_count":"2","poster":"0b43291","timestamp":"1731556080.0","content":"Selected Answer: C\nOption C (SCP): Service Control Policies (SCPs) provide a proactive mechanism to prevent non-compliant actions from occurring in the first place. The SCP will block the launch of instances with public IP addresses or the attachment of public IP addresses to existing instances, ensuring that the requirement is met from the outset.\n Option B (Control Tower proactive control): Proactive controls in AWS Control Tower are designed to detect and remediate non-compliant resources after they have been created. While they can remediate instances with public IP addresses, they do not prevent the initial assignment of public IP addresses."},{"comment_id":"1310365","poster":"AzureDP900","content":"Option C is actually a good solution for this scenario.\n\nC is right.\nBy creating an SCP (Security Policy) that:\nPrevents the launch of instances with public IP addresses.\nPrevents the attachment of a public IP address to existing instances, you can effectively prevent new or existing Amazon EC2 instances in the OU's accounts from gaining a public IP address.\nThis solution is suitable because it:\nIs proactive and automated, reducing the risk of human error Can detect existing instances with public IP addresses and prevent future assignments Is directly attached to the OU, ensuring that all accounts within it are subject to this policy.","upvote_count":"2","timestamp":"1731366600.0"},{"timestamp":"1730314260.0","poster":"sashenka","comment_id":"1305115","content":"Selected Answer: C\nThe company must prevent any new or existing Amazon EC2 instances in the OU's accounts from gaining a public IP address.\"\nThe key phrase is \"from gaining\" a public IP address - this means:\n\nIt's about preventing future actions of getting public IPs\nIt's NOT about removing already attached public IPs\nIt applies to both new and existing instances\n\nIn this case, an SCP (Option C) is indeed the correct solution","upvote_count":"1"},{"content":"Selected Answer: C\n\"The company MUST PREVENT...\"\nProactive controls do not directly prevent the action of attaching a public IP. They are applicable to resources that are specifically PROVISIONED THROUGH AWS SERVICE CATALOG. They do not have the ability to broadly prevent all EC2 instances in an organization from obtaining a public IP, especially those created outside of Service Catalog.\nAlso, as user VerRi says here in the comments, how will AWS Control Tower proactive control \"check whether instances IN the OU's accounts have a public IP address.\"?\nOption C is the best solution because it uses an SCP, which is a preventive control that directly stops the creation or modification of EC2 instances with public IP addresses in all accounts under the specified OU. This ensures compliance with the requirement of preventing public IP addresses on EC2 instances.","upvote_count":"3","poster":"JoeTromundo","timestamp":"1728666540.0","comment_id":"1296193"},{"upvote_count":"2","timestamp":"1726195680.0","poster":"liuliangzhou","comment_id":"1282942","content":"Selected Answer: C\nB. AWS Control Tower's Active Controls primarily focus on security related best practices such as IAM policies, security group rules, etc., rather than directly controlling the public IP addresses of EC2 instances. Although custom proactive control can be created, setting the associatePublicIpAddress property to False is usually done through API calls or CLI/SDK when starting an EC2 instance, rather than through proactive control in AWS Control Tower.\nC. AWS Service Control Policies (SCPs) are a mechanism provided by AWS Organizations for implementing access control to AWS services at the OU level. SCP can restrict the ability to request public IP addresses when launching EC2 instances within OU accounts, as well as limit the permission to modify existing instances to attach public IP addresses. This fully meets the company's needs as it ensures the implementation of a unified strategy at the OU level without the need to manage each account or instance separately."},{"comment_id":"1231048","timestamp":"1718467620.0","upvote_count":"1","content":"Selected Answer: B\nSCP prevent but not remediate existing. So correct is B with CT","poster":"michele_scar"},{"poster":"teo2157","comment_id":"1214261","timestamp":"1716198240.0","content":"Selected Answer: B\nGoing for B as Control Tower permissions have to be managed using Controls but not SCPs which causes drifts.","upvote_count":"2"},{"content":"Selected Answer: C\nB is a bit weird because proactive control is used to check NEW resources. \nIt is weird to say \"Check whether instances IN the OU's accounts have a public IP address.\".","upvote_count":"4","poster":"VerRi","comment_id":"1186133","timestamp":"1711806960.0"},{"content":"Selected Answer: C\nC.\nB is not correct since Control Tower doesn't have this capability.","poster":"Dgix","comment_id":"1179117","timestamp":"1711016940.0","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: B\nOption B is the right option.","comment_id":"1169031","poster":"career360guru","timestamp":"1709922540.0"},{"comment_id":"1164128","timestamp":"1709386080.0","poster":"sat2008","upvote_count":"3","content":"Selected Answer: C\nNOT B -- These controls are referred to as proactive because they check your resources –**BEFORE** the resources are deployed – to determine whether the new resources will comply with the controls that are activated in your environment.\n\nThis control applies only to a new network interface created by means of the NetworkInterfaces property, where a NetworkInterfaceId has not been specified.\nBest answer is C"},{"poster":"arberod","timestamp":"1708017960.0","upvote_count":"2","comment_id":"1151155","content":"Selected Answer: B\nIt is B"},{"poster":"duriselvan","comment_id":"1147478","content":"C ans https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/connect-with-ec2-instance-connect-endpoint.html","timestamp":"1707666300.0","upvote_count":"1"},{"timestamp":"1707484080.0","poster":"saggy4","content":"Selected Answer: B\nC incorrect: Because SCP will surely block creation of instances with Public IP but will not resolve the existing ones. ALso will create a drift in Control Tower\nB is correct","upvote_count":"5","comment_id":"1145482"},{"poster":"kejam","upvote_count":"4","comment_id":"1141638","timestamp":"1707179040.0","content":"Selected Answer: B\nMaking changes to SCPs outside if Control Tower causes state drift.\nhttps://docs.aws.amazon.com/controltower/latest/userguide/external-resources.html\n\nControl Tower has Proactive Controls to cover the requirements\nhttps://docs.aws.amazon.com/controltower/latest/userguide/ec2-rules.html#ct-ec2-pr-9-description\nhttps://docs.aws.amazon.com/controltower/latest/userguide/ec2-rules.html#ct-ec2-pr-8-description"},{"upvote_count":"1","timestamp":"1705375560.0","comment_id":"1123831","content":"Selected Answer: C\nOption C. Not sure why Option D mentioned as correct.","poster":"ma23"},{"upvote_count":"1","comment_id":"1123103","content":"c will only prevent new instances from gaining a public IP. What if the instances already have public ips?","poster":"thotwielder","timestamp":"1705299420.0"},{"content":"Selected Answer: C\nOption C","timestamp":"1705004160.0","poster":"career360guru","upvote_count":"1","comment_id":"1120152"},{"timestamp":"1703326500.0","content":"B is correct https://docs.aws.amazon.com/controltower/latest/userguide/ec2-rules.html#ct-ec2-pr-8-description","comment_id":"1103965","upvote_count":"2","poster":"yuliaqwerty","comments":[{"poster":"carpa_jo","upvote_count":"4","content":"Control Tower proactive controls only work in combination with CloudFormation: https://docs.aws.amazon.com/controltower/latest/userguide/proactive-controls.html\nWe have no information if the developers are using CloudFormation. And even if they did, they could still perform this activity for example from the AWS management console without CloudFormation, so this doesn't really help. \nC should be correct.","timestamp":"1703890920.0","comment_id":"1109230"}]},{"content":"Selected Answer: C\nAnswer C. While using AWS Organizations, SCP is the best bet for any preventive action.","upvote_count":"4","poster":"shaaam80","timestamp":"1701344400.0","comment_id":"1084303"},{"upvote_count":"5","content":"Selected Answer: C\n\"apply policy/rule/allow/deny something to a entire OU\" -> SCP","poster":"GabrielDeBiasi","timestamp":"1701170220.0","comment_id":"1082480"},{"content":"Selected Answer: C\nC. Crie um SCP (Service Control Policy) que impeça o lançamento de instâncias que possuam um endereço IP público. Além disso, configure o SCP para evitar a anexação de um endereço IP público a instâncias existentes. Anexe o SCP à UO.\n\nA razão para escolher esta opção é que as Políticas de Controle de Serviço (SCPs) são projetadas para oferecer controle centralizado no nível da organização, permitindo que você gerencie permissões em todas as contas dentro da UO. Ao criar um SCP que proíbe explicitamente a atribuição de endereços IP públicos a instâncias EC2, você pode efetivamente impedir tanto a criação de novas instâncias com IPs públicos quanto a modificação de instâncias existentes para adicionar IPs públicos.","timestamp":"1700702580.0","poster":"Jonalb","comment_id":"1077959","upvote_count":"1"},{"content":"Selected Answer: C\nAnswer C","timestamp":"1700689260.0","poster":"devalenzuela86","comment_id":"1077881","upvote_count":"1"},{"timestamp":"1700657700.0","comment_id":"1077383","content":"Selected Answer: C\nOption C - Prevents launching new EC2 instances with Public IP, and attaching Public IP to an existing instance. Option D - Though it helps identify EC2 instances Public IP, it doesn't seem to deny launching EC2 instances with Public IP.","poster":"Maygam","upvote_count":"1"},{"poster":"cypkir","content":"Selected Answer: C\nAnswer: C","comment_id":"1077080","timestamp":"1700638380.0","upvote_count":"1"}],"exam_id":33,"question_text":"A company is using AWS Control Tower to manage AWS accounts in an organization in AWS Organizations. The company has an OU that contains accounts. The company must prevent any new or existing Amazon EC2 instances in the OU's accounts from gaining a public IP address.\n\nWhich solution will meet these requirements?","topic":"1","answer":"C","answer_images":[],"question_id":347,"unix_timestamp":1700638380,"timestamp":"2023-11-22 08:33:00","answer_ET":"C","answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/126862-exam-aws-certified-solutions-architect-professional-sap-c02/","isMC":true,"choices":{"D":"Create an AWS Config custom rule that detects instances that have a public IP address. Configure a remediation action that uses an AWS Lambda function to detach the public IP addresses from the instances.","B":"Implement the AWS Control Tower proactive control to check whether instances in the OU's accounts have a public IP address. Set the AssociatePublicIpAddress property to False. Attach the proactive control to the OU.","A":"Configure all instances in each account in the OU to use AWS Systems Manager. Use a Systems Manager Automation runbook to prevent public IP addresses from being attached to the instances.","C":"Create an SCP that prevents the launch of instances that have a public IP address. Additionally, configure the SCP to prevent the attachment of a public IP address to existing instances. Attach the SCP to the OU."},"question_images":[],"answers_community":["C (67%)","B (33%)"]},{"id":"BMOKA2ST4FdSAKMb5D84","question_images":[],"answer_images":[],"question_id":348,"question_text":"A company is deploying a third-party web application on AWS. The application is packaged as a Docker image. The company has deployed the Docker image as an AWS Fargate service in Amazon Elastic Container Service (Amazon ECS). An Application Load Balancer (ALB) directs traffic to the application.\n\nThe company needs to give only a specific list of users the ability to access the application from the internet. The company cannot change the application and cannot integrate the application with an identity provider. All users must be authenticated through multi-factor authentication (MFA).\n\nWhich solution will meet these requirements?","timestamp":"2024-01-01 03:24:00","answer_description":"","discussion":[{"comment_id":"1115528","content":"Selected Answer: A\nA?\nAs GPT says,\n\nIn this scenario, setting up a user pool in Amazon Cognito allows you to define the specific list of users who can access the application.\nYou can configure the user pool to require multi-factor authentication (MFA), ensuring an additional layer of security for user authentication.\nConfiguring the ALB listener rule to require authentication through the Amazon Cognito hosted UI means that users attempting to access the application through the ALB will be redirected to the Cognito hosted UI for authentication, where they'll need to provide their credentials and MFA code.\nThis setup ensures that only authenticated users from the specific user pool with MFA will have access to the application, meeting the requirements without modifying the application itself.","upvote_count":"9","poster":"JMAN1","timestamp":"1720306380.0"},{"timestamp":"1721017800.0","comment_id":"1123107","upvote_count":"6","content":"web application = Cognito","poster":"thotwielder"},{"timestamp":"1725859080.0","content":"Selected Answer: A\nAs application can not be changed to integrate with Identity provider and users needs to be authenticated from internet using Cognito is the only possible solution among the options.","upvote_count":"4","comment_id":"1169317","poster":"career360guru"},{"comment_id":"1147482","upvote_count":"3","poster":"duriselvan","content":"A ans https://repost.aws/knowledge-center/cognito-user-pool-alb-authentication","timestamp":"1723384440.0"},{"content":"A sounds OK","upvote_count":"1","comment_id":"1129730","poster":"igor12ghsj577","timestamp":"1721741280.0"},{"upvote_count":"1","comments":[{"content":"No, I am wrong.\nBut answer is still A.\n\nAPI GW authentication only integration with:\nCognito\nAWS_IAM\nLambda authorizer\n\nALB authentication only integration with:\nCognito\nOIDC","comment_id":"1124787","timestamp":"1721196840.0","poster":"tmlong18","upvote_count":"4"}],"timestamp":"1721192100.0","poster":"tmlong18","comment_id":"1124756","content":"Selected Answer: A\nAnswer is A\n\nALB authentication only integration with:\nCognito\nAWS_IAM\nLambda authorizer"},{"upvote_count":"1","content":"Selected Answer: A\nAnswer is A","comment_id":"1120156","poster":"career360guru","timestamp":"1720722300.0"},{"timestamp":"1720111380.0","upvote_count":"1","comment_id":"1113977","content":"Answer is A","poster":"Laercio96"},{"comment_id":"1110943","timestamp":"1719793500.0","content":"B&C is for accessing aws resources","upvote_count":"1","poster":"clevvve"},{"upvote_count":"1","content":"Selected Answer: A\nAnswer is A","timestamp":"1719793440.0","comment_id":"1110942","poster":"clevvve"}],"answer":"A","exam_id":33,"answers_community":["A (100%)"],"choices":{"D":"Create a user pool in AWS Amplify. Configure the pool for the application. Populate the pool with the required users. Configure the pool to require MFA. Configure a listener rule on the ALB to require authentication through the Amplify hosted UI.","C":"Configure the users in AWS Identity and Access Management (IAM). Enable AWS IAM Identity Center (AWS Single Sign-On). Configure resource protection for the ALB. Create a resource protection rule to require users to use MFA.","A":"Create a user pool in Amazon Cognito. Configure the pool for the application. Populate the pool with the required users. Configure the pool to require MFConfigure a listener rule on the ALB to require authentication through the Amazon Cognito hosted UI.","B":"Configure the users in AWS Identity and Access Management (IAM). Attach a resource policy to the Fargate service to require users to use MFA. Configure a listener rule on the ALB to require authentication through IAM."},"isMC":true,"topic":"1","answer_ET":"A","unix_timestamp":1704075840,"url":"https://www.examtopics.com/discussions/amazon/view/130043-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"3RpnWh8vnVGd57XJFeWW","isMC":true,"answer_ET":"A","topic":"1","choices":{"D":"Specify an administration role ARN and the CAPABILITY_IAM capability during the creation of the stack set.","A":"Enable the new Regions in all relevant accounts. Specify the CAPABILITY_NAMED_IAM capability during the creation of the stack set.","B":"Use the Service Quotas console to request a quota increase for the number of CloudFormation stacks in each new Region in all relevant accounts. Specify the CAPABILITY_IAM capability during the creation of the stack set.","C":"Specify the CAPABILITY_NAMED_IAM capability and the SELF_MANAGED permissions model during the creation of the stack set."},"question_id":349,"answer_images":[],"discussion":[{"content":"Selected Answer: A\nSome stack templates might include resources that can affect permissions in your AWS account; for example, by creating new AWS Identity and Access Management (IAM) users. For those stacks, you must explicitly acknowledge this by specifying one of these capabilities.\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/API_CreateStack.html","comment_id":"1141722","upvote_count":"6","timestamp":"1707188580.0","poster":"kejam"},{"content":"Selected Answer: A\nQuestion says \"several previously unused AWS Regions\" so you have to enable them under the Account first ? \nAnd the CAPABILITY_NAMED_IAM for the custom name","timestamp":"1708243860.0","comment_id":"1153109","upvote_count":"5","poster":"sat2008"},{"timestamp":"1731366120.0","upvote_count":"2","poster":"AzureDP900","content":"The correct answer is A.\nWhen deploying a CloudFormation stack set to multiple Regions, you need to ensure that the IAM role has sufficient permissions to create stacks in those Regions. The issue here is likely due to a limitation on the number of CloudFormation stacks that can be created in a Region.\nTo resolve this issue, you should:\nEnable the new Regions in all relevant accounts.\nSpecify the CAPABILITY_NAMED_IAM capability during the creation of the stack set. This allows AWS to create stacks without having to manage IAM roles for each stack instance.","comment_id":"1310364"},{"poster":"career360guru","timestamp":"1709968980.0","comment_id":"1169320","content":"Selected Answer: A\nA seems to be the right choice","upvote_count":"1"},{"content":"Selected Answer: C\nC is the answer.\nThe following resources require you to specify CAPABILITY_IAM or CAPABILITY_NAMED_IAM: AWS::IAM::Group, AWS::IAM::InstanceProfile, AWS::IAM::Policy, and AWS::IAM::Role. If the application contains IAM resources with custom names, you must specify CAPABILITY_NAMED_IAM.\nWith self-managed permissions, you create the AWS Identity and Access Management (IAM) roles required by StackSets to deploy across accounts and AWS Regions.\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-prereqs-self-managed.html\nhttps://docs.aws.amazon.com/serverlessrepo/latest/devguide/acknowledging-application-capabilities.html","timestamp":"1707838680.0","poster":"ele","comment_id":"1149307","upvote_count":"1","comments":[{"poster":"ele","upvote_count":"2","content":"nop, it's A. \nB y \"Enable the new Regions in all relevant accounts. \" they mean: \nCreate the necessary IAM service roles in your administrator and target accounts to define the permissions you want. \nThe A IS CORRECT.","timestamp":"1707838980.0","comment_id":"1149314"}]},{"poster":"HunkyBunky","upvote_count":"1","timestamp":"1707369600.0","content":"Selected Answer: A\nProper answer is - A\n\nWe want to create Cloudformation stack that contains IAM role with custom name - so we need to set CAPABILITY_NAMED_IAM","comment_id":"1144106"},{"upvote_count":"3","content":"Correct A","poster":"alexis123456","timestamp":"1707149940.0","comment_id":"1141274"}],"answer":"A","question_images":[],"exam_id":33,"question_text":"A solutions architect is preparing to deploy a new security tool into several previously unused AWS Regions. The solutions architect will deploy the tool by using an AWS CloudFormation stack set. The stack set's template contains an IAM role that has a custom name. Upon creation of the stack set, no stack instances are created successfully.\n\nWhat should the solutions architect do to deploy the stacks successfully?","unix_timestamp":1707149940,"answers_community":["A (93%)","7%"],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/132873-exam-aws-certified-solutions-architect-professional-sap-c02/","timestamp":"2024-02-05 17:19:00"},{"id":"BEDeqBF7FEH0aBSumXa1","exam_id":33,"answer_description":"","topic":"1","answer_images":[],"isMC":true,"answers_community":["A (100%)"],"question_text":"A company has an application that uses an Amazon Aurora PostgreSQL DB cluster for the application's database. The DB cluster contains one small primary instance and three larger replica instances. The application runs on an AWS Lambda function. The application makes many short-lived connections to the database's replica instances to perform read-only operations.\n\nDuring periods of high traffic, the application becomes unreliable and the database reports that too many connections are being established. The frequency of high-traffic periods is unpredictable.\n\nWhich solution will improve the reliability of the application?","answer_ET":"A","answer":"A","discussion":[{"upvote_count":"16","comment_id":"1141726","content":"Selected Answer: A\nlambda -> rds-proxy -> aurora replica(s) read-only endpoint\n\nhttps://aws.amazon.com/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/\nhttps://aws.amazon.com/about-aws/whats-new/2021/03/amazon-rds-proxy-adds-read-only-endpoints-for-amazon-aurora-replicas/\n\nRDS Data API is used with Aurora Serverless\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html#data-api.limitations","timestamp":"1707189900.0","poster":"kejam"},{"comment_id":"1311742","timestamp":"1731560640.0","poster":"0b43291","content":"Selected Answer: A\nThe other options have limitations or do not address the root cause of the issue:\n\n Option B (Increasing max_connections): While increasing the maximum number of connections allowed on the DB cluster may provide a temporary solution, it does not address the underlying issue of inefficient connection management, and it may lead to increased resource consumption and potential performance degradation.\n\n Option C (Instance scaling): While instance scaling can help increase the overall capacity of the DB cluster, it does not directly address the issue of too many connections being established. Additionally, it may not be effective if the high-traffic periods are unpredictable and short-lived.\n\n Option D (RDS Proxy with Aurora Data API): The Aurora Data API is designed for serverless applications to interact with Aurora Serverless databases using a web services model, not for traditional database connections. It does not address the issue of connection management for the existing application architecture.","upvote_count":"2"},{"content":"Option A allows the application to connect to the replica instances without directly accessing them. This approach helps to:\n1) Reduce the number of connections to the primary instance\n2) Increase performance by offloading read operations to the replica instances\n3) Improve reliability by reducing the load on the primary instance during periods of high traffic","upvote_count":"1","timestamp":"1731366000.0","poster":"AzureDP900","comment_id":"1310362"},{"timestamp":"1709969220.0","content":"Selected Answer: A\nOption A","poster":"career360guru","upvote_count":"1","comment_id":"1169321"},{"upvote_count":"2","timestamp":"1707667980.0","poster":"duriselvan","content":"A is ans lambda -> rds-proxy -> aurora replica(s) read-only endpoint","comment_id":"1147492"},{"content":"Selected Answer: A\nrds-proxy","timestamp":"1707234120.0","upvote_count":"1","poster":"master9","comment_id":"1142330"},{"content":"correct Answer is A","comment_id":"1141280","timestamp":"1707150600.0","poster":"alexis123456","upvote_count":"4"}],"url":"https://www.examtopics.com/discussions/amazon/view/132877-exam-aws-certified-solutions-architect-professional-sap-c02/","unix_timestamp":1707150600,"question_id":350,"question_images":[],"choices":{"A":"Use Amazon RDS Proxy to create a proxy for the DB cluster. Configure a read-only endpoint for the proxy. Update the Lambda function to connect to the proxy endpoint.","D":"Use Amazon RDS Proxy to create a proxy for the DB cluster. Configure a read-only endpoint for the Aurora Data API on the proxy. Update the Lambda function to connect to the proxy endpoint.","C":"Configure instance scaling for the DB cluster to occur when the DatabaseConnections metric is close to the max connections setting. Update the Lambda function to connect to the Aurora reader endpoint.","B":"Increase the max_connections setting on the DB cluster's parameter group. Reboot all the instances in the DB cluster. Update the Lambda function to connect to the DB cluster endpoint."},"timestamp":"2024-02-05 17:30:00"}],"exam":{"isImplemented":true,"isBeta":false,"provider":"Amazon","isMCOnly":true,"lastUpdated":"11 Apr 2025","id":33,"name":"AWS Certified Solutions Architect - Professional SAP-C02","numberOfQuestions":529},"currentPage":70},"__N_SSP":true}