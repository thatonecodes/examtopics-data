{"pageProps":{"questions":[{"id":"mTVpWgqyNwmSxAX43FsO","answer_images":[],"discussion":[{"timestamp":"1656241740.0","comments":[{"upvote_count":"1","timestamp":"1673858220.0","content":"“One of the well-known embedding techniques is Word2Vec, which provides embeddings for words.” “In addition to word embeddings, there are also use cases where we want to learn the embeddings of more general-purpose objects such as sentences, customers, and products. This is so we can build practical applications for information retrieval, product search, item matching, customer profiling based on similarity or as inputs for other supervised tasks. This is where Amazon SageMaker Object2Vec comes in.”\n\nhttps://aws.amazon.com/blogs/machine-learning/introduction-to-amazon-sagemaker-object2vec/","poster":"Jerry84","comment_id":"777462"},{"timestamp":"1694497680.0","comment_id":"1005429","poster":"robotgeek","content":"This is wrong, maybe the response (and the question) is outdated because BlazingText now supports three diferent techniques","upvote_count":"2"}],"comment_id":"622502","poster":"ovokpus","upvote_count":"16","content":"Selected Answer: AC\nseq2seq and object2vec take care of more than just the words. Any response with blazingText is wrong because blazingText just uses a cbow (continuous bag of words), working only on individual words"},{"comments":[{"timestamp":"1697781420.0","upvote_count":"1","content":"yeah, my initial thought was the same. But both B and D embed words, not sentences.","poster":"DimLam","comment_id":"1048433"}],"upvote_count":"7","poster":"peterfish","comment_id":"633428","content":"Selected Answer: BD\nIt should be B an D. The objective is to create a latent space/word embedding that puts similar words closer to each other for other purposes. Thus, we should use Sagemaker Blazing Text in unsupervised mode (Word2Vec mode). cbow, skip-grams, and batch skip-grams are the 3 algorithms for this. However, since we do not need to do the later part of E, E is not correct. The ans should be B and D.","timestamp":"1658217060.0"},{"poster":"CloudGyan","timestamp":"1736947500.0","upvote_count":"1","comment_id":"1340999","content":"Selected Answer: CE\nUsing Amazon SageMaker Object2Vec (C) provides an end-to-end solution for learning embeddings with contextual and sequential relationships, while BlazingText in Skip-gram mode combined with a custom RNN (E) allows for greater flexibility in capturing sequence-level dependencies. Both approaches can produce high-quality embedding vectors that meet the requirements.\n\nWhy not A : The seq2seq algorithm is designed for sequence-to-sequence tasks like translation or summarization. While it generates embeddings internally, it is not designed to provide a general-purpose feature space for downstream predictive models."},{"upvote_count":"1","comment_id":"1281709","timestamp":"1725992280.0","poster":"GS_77","content":"Selected Answer: CE\nBest choices"},{"comment_id":"1159200","upvote_count":"2","poster":"AIWave","content":"Selected Answer: BC\nTo extract embedding vectors: Blazingtext Word2vec and Object2vec (B, C).\nSeq to seq: generate one sequence from another (A is out)\nAmazon SageMaker BlazingText algorithm in continuous bag-of-words (CBOW) mode does not capture word embeddings (D is out)","timestamp":"1708895700.0"},{"content":"Selected Answer: BE\nTo capture word context and sequential QA information, the embedding vectors need to consider\nboth the order and the meaning of the words in the text.\nOption B, Amazon SageMaker BlazingText algorithm in Skip-gram mode, is a valid option because it\ncan learn word embeddings that capture the semantic similarity and syntactic relations between\nwords based on their co-occurrence in a window of words. Skip-gram mode can also handle rare\nwords better than continuous bag-of-words (CBOW) mode1.\nOption E, combination of the Amazon SageMaker BlazingText algorithm in Batch Skip-gram mode\nwith a custom recurrent neural network (RNN), is another valid option because it can leverage the\nadvantages of Skip-gram mode and also use an RNN to model the sequential nature of the text. An\nRNN can capture the temporal dependencies and long-term dependencies between words, which are\nimportant for QA tasks2","comment_id":"1147576","poster":"kyuhuck","upvote_count":"2","timestamp":"1707676380.0"},{"comment_id":"1144318","timestamp":"1707384000.0","upvote_count":"3","poster":"kyuhuck","content":"Selected Answer: CE\nConsidering the requirements, the two options that can produce the required embedding vectors that capture word context and sequential QA information are:\n\nC. Amazon SageMaker Object2Vec algorithm: Because it can learn to capture relationships in pairs of text, which could include the sequential nature of questions and answers.\n\nE. Combination of the Amazon SageMaker BlazingText algorithm in Batch Skip-gram mode with a custom recurrent neural network (RNN): This combination provides both context-aware word embeddings and the ability to capture sequential dependencies in text data."},{"comment_id":"1133417","poster":"aakash_0086","content":"Selected Answer: CE\nC because Object2Vec is a neural network-based algorithm that can learn embeddings for a wide range of data types and tasks.\n\nE because If you want to capture word context and sequential information, especially in the context of natural language processing (NLP), it is advisable to use models that are specifically designed for sequence modeling, such as recurrent neural networks (RNNs) or more advanced models like long short-term memory networks (LSTMs) or transformers.","upvote_count":"3","timestamp":"1706366820.0"},{"timestamp":"1705161540.0","comment_id":"1121825","upvote_count":"1","content":"Selected Answer: AE\nA. Amazon SageMaker seq2seq algorithm: Sequence-to-sequence (seq2seq) models are designed to convert sequences from one domain to sequences in another domain, often used in tasks like machine translation. They are capable of understanding the context and the sequence in which words appear, making them suitable for differentiating between questions and answers in a text.\n\nE. Combination of the Amazon SageMaker BlazingText algorithm in Batch Skip-gram mode with a custom recurrent neural network (RNN): This combination is promising. BlazingText in Skip-gram mode captures word context, and the recurrent neural network (RNN) is excellent for capturing sequential data, such as the flow in conversations or text. This combination should be effective at understanding both the context of individual words and the sequence of questions and answers.","poster":"CloudHandsOn"},{"timestamp":"1697782440.0","upvote_count":"1","comment_id":"1048453","content":"One problem of Object2Vec is it takes two objects as input during training and loss minimizes the difference between embeddings of these two objects. I don't think we have some labels to pass to Object2Vec\nWe might think that we have a QA which we can pass as two objects. But in the question we want embeddings to distinguish between Q & A, but this Object2Vec minimizes the difference. \nSo I wouldn't tell it is for sure C\nhttps://aws.amazon.com/blogs/machine-learning/introduction-to-amazon-sagemaker-object2vec/","poster":"DimLam"},{"upvote_count":"3","content":"Selected Answer: AE\nA . Seq2seq (sequence-to-sequence) models are designed to handle sequences. They are particularly well-suited for tasks like translating sentences from one language to another, but they can also be used for other tasks that involve sequences, such as converting questions to answers. Given that the embedding space must differentiate between questions and answers, a seq2seq model would be a good choice.\n\nE . BlazingText in Skip-gram mode can capture word context effectively. However, on its own, it might not capture the sequential information between questions and answers. By combining it with a custom RNN, the sequential nature of the sentences, especially in a QA setting, can be captured. RNNs are designed to work with sequences and can remember past information, making them suitable for this task.","comment_id":"1045646","poster":"seifskl","timestamp":"1697527500.0"},{"timestamp":"1695130980.0","poster":"loict","upvote_count":"1","content":"Selected Answer: BD\nA. NO - seq2seq not for word embeddings\nB. YES - BlazingText in Skip-gram works and can capture Q&A\nC. NO - object2vec not for word embeddings\nD. YES - BlazingText in CBOW works and can capture Q&A\nE. NO - no need for RNN","comment_id":"1011385"},{"upvote_count":"2","content":"Selected Answer: BC\nAnswers should be B and C\nSee the following for BlazingText with Skip-gram:\nhttps://arxiv.org/pdf/1604.04661.pdf (search skip-gram) Linked from this page https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html\n\nFor Object2Vec see this page\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/object2vec.html","timestamp":"1693747380.0","poster":"Shenannigan","comment_id":"997652"},{"upvote_count":"2","content":"Selected Answer: CE\nC is confirmed but confused between A or E then lean to E","poster":"Mickey321","timestamp":"1693143600.0","comment_id":"991479"},{"upvote_count":"1","content":"Selected Answer: CE\nconfusing","comment_id":"988867","timestamp":"1692856080.0","poster":"Mickey321"},{"upvote_count":"3","content":"Selected Answer: BC\nSeq2Seq will not generate an embedding vector, so A it's wrong from my POV.\nI go with B - C","poster":"kaike_reis","timestamp":"1691680980.0","comment_id":"977819"},{"timestamp":"1690903620.0","upvote_count":"2","poster":"Mickey321","content":"Selected Answer: BE\nIMO E for sure then either B or C \nCombination of the Amazon SageMaker BlazingText algorithm in Batch Skip-gram mode with a custom recurrent neural network (RNN) is a more sophisticated approach that can be used to capture sequential QA information. This is because RNNs are able to learn long-term dependencies between words.","comment_id":"969165"},{"timestamp":"1682895240.0","content":"Selected Answer: BC\nI've never heard about using seq2seq to generate embedding vectors.\n\nB = In skip gram, the order of the words does matter\nC = It's made for these type of things, generate embeddings of \"objects\" (sentences or what have you).","poster":"WilianCB","upvote_count":"2","comment_id":"885678"},{"comment_id":"859251","timestamp":"1680460260.0","poster":"Mllb","upvote_count":"2","content":"Selected Answer: BC\nWord2Vec in n-gram (context sensitive)\nObject2Vec: two tokens closer as positive class and two tokens away as negative class"},{"upvote_count":"2","timestamp":"1679239500.0","comment_id":"843884","poster":"blanco750","content":"Selected Answer: BE\nQuestion is looking for 2 things \n1. Words embedding\n2. sequential QA information(questions and answers among the sentences,)\nFor 1, we have Blazing text skip-gram , batch skip-gram and Object2vec. very difficult to choose \n2. However there is part 2 which mentions sequential QA information. @Chelseajcole posted response from chatgpt :) which highlights RNN for this. Interesting.\nso it seems either B/C and E ?\nVery difficult. i have already spent 1.5 hrs researching on this question alone :(","comments":[{"comment_id":"844299","timestamp":"1679264880.0","poster":"blanco750","content":"Actually I would change it to B and C. Please ignore the above comment.","upvote_count":"2"}]},{"poster":"Chelseajcole","timestamp":"1677685680.0","comments":[{"upvote_count":"1","poster":"blanco750","timestamp":"1679239080.0","comment_id":"843874","content":"Oh. this looks really compelling. The question mentions sequential QA information and RNN can be used to capture sequential information !"}],"content":"ChatGPT answer:\n\nBased on the requirements mentioned in the question, the two options that can produce the required embedding vectors that capture word context and sequential QA information are:\n\nB. Amazon SageMaker BlazingText algorithm in Skip-gram mode - This algorithm is specifically designed for generating high-quality word embeddings and can capture the context of words within a sentence. The skip-gram mode is suitable for capturing the relationship between words that appear within a certain distance from each other in the text.\n\nE. Combination of the Amazon SageMaker BlazingText algorithm in Batch Skip-gram mode with a custom recurrent neural network (RNN) - This option allows for the incorporation of additional information from the sequence of sentences by using an RNN. The batch skip-gram mode can be used to capture the relationships between words in a larger context, while the RNN can capture the sequential information and dependencies between the sentences.\n\nTherefore, options B and E can produce the required embedding vectors that capture word context and sequential QA information.","upvote_count":"2","comment_id":"826040"},{"comment_id":"805341","poster":"drcok87","upvote_count":"2","timestamp":"1676128860.0","content":"C is obvious \nB or d\n Could be d because CBOW->given context, predict work embeddings: \"Which options can produce the required embedding vectors that capture word context”"},{"upvote_count":"1","content":"Answer BD. Even option E could be, but custom RNN is not necessary.\nhttps://aws.amazon.com/blogs/machine-learning/enhanced-text-classification-and-word-vectors-using-amazon-sagemaker-blazingtext/","comment_id":"800240","poster":"damaldon","timestamp":"1675714980.0"},{"comment_id":"761106","timestamp":"1672323480.0","upvote_count":"4","content":"Selected Answer: BC\nSeq2Seq is for translations or sequences of some kind. They don't return word embedding.\n\nBlazingText and Object2Vec provide word embedding. \n\nChoosing the blazingtext mode: https://www.mlexam.com/blazingtext-algorithm/\nRead: In skip-gram mode you supply a word and the model returns the context of the word. With CBOW you provide the context and a predicted word is returned.","poster":"rrshah83"},{"comment_id":"628140","content":"Should be A and B \nA Seq2seq can generate embedding vectors\nB Sagemaker Blazing Text in Skip-gram mode can return the context of word.","timestamp":"1657148160.0","poster":"rjekstein","upvote_count":"2"},{"upvote_count":"3","comment_id":"626610","content":"Selected Answer: CD\nmy best guess -> CD\nBoth generate Vectors as response and cbow is used for context usecases","timestamp":"1656860760.0","poster":"f4bi4n"},{"upvote_count":"4","timestamp":"1656609120.0","poster":"phani1989","content":"I believe it should be C and E","comment_id":"625375"},{"poster":"DJiang","comments":[{"content":"Why is seq2seq relevant here? Isnt it for machine translation?","poster":"thafa","timestamp":"1655889180.0","upvote_count":"1","comment_id":"620273"}],"upvote_count":"1","comment_id":"599644","content":"Selected Answer: AE\nI think answer is A,E: \"identical terms but in distinct situations\" refers to the typical question of mapping contexts to embedding, and therefore models that are able to handle contexts should be considered.","timestamp":"1652193900.0"}],"question_images":[],"unix_timestamp":1652193900,"answer_description":"","isMC":true,"choices":{"E":"Combination of the Amazon SageMaker BlazingText algorithm in Batch Skip-gram mode with a custom recurrent neural network (RNN)","D":"Amazon SageMaker BlazingText algorithm in continuous bag-of-words (CBOW) mode","B":"Amazon SageMaker BlazingText algorithm in Skip-gram mode","A":"Amazon SageMaker seq2seq algorithm","C":"Amazon SageMaker Object2Vec algorithm"},"answer":"AC","topic":"1","exam_id":26,"question_text":"A machine learning (ML) specialist needs to extract embedding vectors from a text series. The goal is to provide a ready-to-ingest feature space for a data scientist to develop downstream ML predictive models. The text consists of curated sentences in English. Many sentences use similar words but in different contexts. There are questions and answers among the sentences, and the embedding space must differentiate between them.\nWhich options can produce the required embedding vectors that capture word context and sequential QA information? (Choose two.)","question_id":86,"url":"https://www.examtopics.com/discussions/amazon/view/75431-exam-aws-certified-machine-learning-specialty-topic-1/","answer_ET":"AC","timestamp":"2022-05-10 16:45:00","answers_community":["AC (25%)","BC (23%)","CE (17%)","Other"]},{"id":"XiYJ2w9CnjxZmn3N7XoK","isMC":true,"answer_ET":"D","answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/74871-exam-aws-certified-machine-learning-specialty-topic-1/","question_id":87,"question_images":[],"timestamp":"2022-04-29 10:13:00","question_text":"A retail company wants to update its customer support system. The company wants to implement automatic routing of customer claims to different queues to prioritize the claims by category.\nCurrently, an operator manually performs the category assignment and routing. After the operator classifies and routes the claim, the company stores the claim's record in a central database. The claim's record includes the claim's category.\nThe company has no data science team or experience in the field of machine learning (ML). The company's small development team needs a solution that requires no ML expertise.\nWhich solution meets these requirements?","topic":"1","unix_timestamp":1651219980,"answer_description":"","exam_id":26,"discussion":[{"comment_id":"594312","upvote_count":"16","comments":[{"timestamp":"1684841940.0","upvote_count":"6","poster":"Omijh","comment_id":"606037","content":"I think D because Textract doesn't support CSV but only PNG, JPEG, TIFF, and PDF formats"}],"timestamp":"1682755980.0","poster":"cron0001","content":"Selected Answer: D\nI would say D. We shouldn't need Textract to extract columns from a database"},{"poster":"ovokpus","timestamp":"1687739820.0","upvote_count":"5","content":"Selected Answer: D\nD because it does not require heavy machine learning expertise","comment_id":"622298"},{"comment_id":"1002156","poster":"loict","upvote_count":"4","timestamp":"1725774420.0","content":"Selected Answer: D\nA. NO - Object2Vec is unsupervised, it will create vector representations but not assign to a category the claims\nB. NO - we want a supervised method, LDA will create topics in an unsupervised way\nC. NO - again we want a supervised method\nD. YES - That is supervised; no need for ML skills, only basic API programming"},{"comment_id":"977830","timestamp":"1723303560.0","content":"C is wrong because the columns doesn't exist.","upvote_count":"1","poster":"kaike_reis"},{"poster":"Mickey321","content":"Selected Answer: D\nD. Export the database to a .csv file with two columns: claim_label and claim_text. Use Amazon Comprehend custom classification and the .csv file to train the custom classifier. Develop a service in the application to use the Amazon Comprehend API to process incoming claims, predict the labels, and route the claims to the appropriate queue.","comment_id":"969167","upvote_count":"1","timestamp":"1722526200.0"},{"poster":"AjoseO","timestamp":"1708382580.0","upvote_count":"1","comment_id":"814631","content":"Selected Answer: D\nOption D meets the requirements. The solution requires no ML expertise, and the small development team can use the Amazon Comprehend custom classification API to train a model to automatically detect claim categories. \n\nThe company can export the database to a .csv file with two columns: claim_label and claim_text. Then, the development team can use the .csv file to train the custom classifier. Finally, the team can develop a service in the application to use the Amazon Comprehend API to process incoming claims, predict the labels, and route the claims to the appropriate queue. \nThis solution is straightforward, does not require extensive expertise, and can be implemented quickly."},{"timestamp":"1693418040.0","content":"Selected Answer: A\nIt should A because Object2Vec is meant for text classification. The problem is to categorize the text based on the content.","upvote_count":"1","comment_id":"654291","poster":"DD4"},{"content":"B. LDA is for topic modelling based on categories. Comprehend is for extracting the entities related to sentiments etc.","timestamp":"1693312500.0","poster":"s12201812","upvote_count":"1","comment_id":"653483","comments":[{"poster":"GiyeonShin","comment_id":"818613","content":"Comprehend can be used for custom classification of NLP too(https://aws.amazon.com/ko/comprehend/features/). \nLDA can find document topics and word distribution for topics, but it is necessary to manually link the topics with predefined customer category.","timestamp":"1708650300.0","upvote_count":"1"},{"upvote_count":"1","content":"But it says the solution should not require ML expertise. LDA requires ML expertise.","poster":"hamimelon","comment_id":"752928","timestamp":"1703212140.0"}]},{"upvote_count":"2","content":"The firm needs a solution for their manual process and this means among others the routing of their client orders. To do that you will need textract","comment_id":"632178","timestamp":"1689513720.0","poster":"Morsa"}],"answers_community":["D (96%)","4%"],"choices":{"B":"Export the database to a .csv file with one column: claim_text. Use the Amazon SageMaker Latent Dirichlet Allocation (LDA) algorithm and the .csv file to train a model. Use the LDA algorithm to detect labels automatically. Use SageMaker to deploy the model to an inference endpoint. Develop a service in the application to use the inference endpoint to process incoming claims, predict the labels, and route the claims to the appropriate queue.","C":"Use Amazon Textract to process the database and automatically detect two columns: claim_label and claim_text. Use Amazon Comprehend custom classification and the extracted information to train the custom classifier. Develop a service in the application to use the Amazon Comprehend API to process incoming claims, predict the labels, and route the claims to the appropriate queue.","A":"Export the database to a .csv file with two columns: claim_label and claim_text. Use the Amazon SageMaker Object2Vec algorithm and the .csv file to train a model. Use SageMaker to deploy the model to an inference endpoint. Develop a service in the application to use the inference endpoint to process incoming claims, predict the labels, and route the claims to the appropriate queue.","D":"Export the database to a .csv file with two columns: claim_label and claim_text. Use Amazon Comprehend custom classification and the .csv file to train the custom classifier. Develop a service in the application to use the Amazon Comprehend API to process incoming claims, predict the labels, and route the claims to the appropriate queue."},"answer_images":[]},{"id":"sucZI8iWB0aHe4x9RmYF","answer":"C","discussion":[{"timestamp":"1687807680.0","upvote_count":"10","comment_id":"622768","content":"Selected Answer: C\n\"Choose logarithmic scaling when you are searching a range that spans several orders of magnitude. For example, if you are tuning a Tune a linear learner model model, and you specify a range of values between .0001 and 1.0 for the learning_rate hyperparameter, searching uniformly on a logarithmic scale gives you a better sample of the entire range than searching on a linear scale would, because searching on a linear scale would, on average, devote 90 percent of your training budget to only the values between .1 and 1.0, leaving only 10 percent of your training budget for the values between .0001 and .1.\"\n\nbased on the above from this link\n\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html\n\nC is clearly the answer","poster":"ovokpus"},{"timestamp":"1683283860.0","comments":[{"content":"But according to the doc you gave, \"Logarithmic scaling works only for ranges that have only values greater than 0.\"\nI think choosing ScalingType=Linear is the best fit, but there's no such option.","comments":[{"timestamp":"1735164960.0","poster":"587df71","content":"Yes and 0.0001 is greater than 0","comment_id":"1331718","upvote_count":"1"}],"poster":"DJiang","timestamp":"1683816420.0","upvote_count":"2","comment_id":"600172"}],"comment_id":"597262","upvote_count":"5","poster":"edvardo","content":"Selected Answer: C\nI would choose C: https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html"},{"content":"Selected Answer: C\nC is the way.","poster":"kaike_reis","timestamp":"1723303980.0","comment_id":"977842","upvote_count":"1"},{"poster":"cox1960","timestamp":"1714415340.0","content":"Selected Answer: C\nnot A since you choose reverse logarithmic scaling when you are searching a range that is highly sensitive to small changes that are very close to 1.","upvote_count":"4","comment_id":"884603"},{"upvote_count":"4","timestamp":"1712083920.0","comment_id":"859264","poster":"Mllb","content":"Selected Answer: B\nIt should be B.\nIn logarithmic parameters the min value is the maximum value. This is the reason that C is not correct"},{"content":"\"Choose logarithmic scaling when you are searching a range that spans several orders of magnitude. For example, if you are tuning a Tune a linear learner model model, and you specify a range of values between .0001 and 1.0 for the learning_rate hyperparameter, searching uniformly on a logarithmic scale gives you a better sample of the entire range than searching on a linear scale would, because searching on a linear scale would, on average, devote 90 percent of your training budget to only the values between .1 and 1.0, leaving only 10 percent of your training budget for the values between .0001 and .1.\"","upvote_count":"3","timestamp":"1687807620.0","poster":"ovokpus","comment_id":"622766"},{"poster":"rhuanca","content":"B looks better , because learning rates were splited up base on a previous experience (0.1 - 0,01) in this case we are changing the structure . On the other hand A and B only change scaletype and this means no real changes","timestamp":"1684151640.0","upvote_count":"2","comment_id":"602062"}],"timestamp":"2022-05-05 12:51:00","unix_timestamp":1651747860,"answer_ET":"C","exam_id":26,"topic":"1","isMC":true,"choices":{"B":"Run three different HPO jobs that use different learning rates form the following intervals for MinValue and MaxValue while using the same number of training jobs for each HPO job: ✑ [0.01, 0.1] ✑ [0.001, 0.01] ✑ [0.0001, 0.001] Select the most accurate hyperparameter configuration form these three HPO jobs.","D":"Run three different HPO jobs that use different learning rates form the following intervals for MinValue and MaxValue. Divide the number of training jobs for each HPO job by three: ✑ [0.01, 0.1] ✑ [0.001, 0.01] [0.0001, 0.001] Select the most accurate hyperparameter configuration form these three HPO jobs.","A":"Modify the HPO configuration as follows: Select the most accurate hyperparameter configuration form this HPO job.","C":"Modify the HPO configuration as follows: Select the most accurate hyperparameter configuration form this training job."},"answers_community":["C (83%)","B (17%)"],"question_images":["https://www.examtopics.com/assets/media/exam-media/04145/0010800001.png"],"answer_description":"","question_text":"A machine learning (ML) specialist is using Amazon SageMaker hyperparameter optimization (HPO) to improve a model's accuracy. The learning rate parameter is specified in the following HPO configuration:\n//IMG//\n\nDuring the results analysis, the ML specialist determines that most of the training jobs had a learning rate between 0.01 and 0.1. The best result had a learning rate of less than 0.01. Training jobs need to run regularly over a changing dataset. The ML specialist needs to find a tuning mechanism that uses different learning rates more evenly from the provided range between MinValue and MaxValue.\nWhich solution provides the MOST accurate result?","answer_images":[],"question_id":88,"url":"https://www.examtopics.com/discussions/amazon/view/75200-exam-aws-certified-machine-learning-specialty-topic-1/"},{"id":"QDeQdnEjuYEXVgjuOlVF","answer_description":"","topic":"1","question_text":"A manufacturing company wants to use machine learning (ML) to automate quality control in its facilities. The facilities are in remote locations and have limited internet connectivity. The company has 20 ׀¢׀’ of training data that consists of labeled images of defective product parts. The training data is in the corporate on- premises data center.\nThe company will use this data to train a model for real-time defect detection in new parts as the parts move on a conveyor belt in the facilities. The company needs a solution that minimizes costs for compute infrastructure and that maximizes the scalability of resources for training. The solution also must facilitate the company's use of an ML model in the low-connectivity environments.\nWhich solution will meet these requirements?","question_id":89,"url":"https://www.examtopics.com/discussions/amazon/view/74972-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"comment_id":"595033","upvote_count":"15","content":"Selected Answer: C\nC; Using S3 for scalable training and SageMaker Neo for compiling model for edge devices","timestamp":"1682860980.0","poster":"spaceexplorer"},{"comment_id":"1011948","poster":"loict","timestamp":"1726810740.0","content":"Selected Answer: C\nA. NO - SageMaker endpoint does not address low-connectivity for inference\nB. NO - Train on premises does not address scalability for training\nC. YES - maximize training scalability and works with low-connectivity\nD. NO - Train on premises does not address scalability for training","upvote_count":"2"},{"upvote_count":"1","timestamp":"1726161000.0","comment_id":"1005943","poster":"teka112233","content":"Selected Answer: C\nThe company needs a solution that minimizes costs for compute infrastructure and that maximizes the scalability of resources for training --> S3\nThe solution also must facilitate the company's use of an ML model in the low-connectivity environments.---> Edge devices and AWS IOT Greengrass"},{"upvote_count":"1","comment_id":"988908","poster":"Mickey321","content":"Selected Answer: C\nAnswer is c","timestamp":"1724481660.0"},{"upvote_count":"2","timestamp":"1708383060.0","content":"Selected Answer: C\nMoving the training data to an Amazon S3 bucket and training and evaluating the model by using Amazon SageMaker will reduce the company's compute infrastructure costs and maximize the scalability of resources for training. \n\nOptimizing the model by using SageMaker Neo will further reduce costs by allowing the model to run on inexpensive edge devices. \n\nSetting up an edge device in the manufacturing facilities with AWS IoT Greengrass and deploying the model on the edge device will enable the company to use the ML model in the low-connectivity environments. \n\nThis solution provides a complete end-to-end solution for the company's needs, from data storage to model deployment, while minimizing costs and providing scalability and offline capabilities.","poster":"AjoseO","comment_id":"814636"},{"content":"Selected Answer: C\nC best satisfies the options of minimising cost, and taking care of lack of connectivity through edge deployment.","comment_id":"741317","poster":"Peeking","upvote_count":"1","timestamp":"1702253820.0"},{"poster":"Morsa","timestamp":"1689441780.0","upvote_count":"2","content":"Selected Answer: C\nSame arguments as belie","comment_id":"631883"},{"poster":"exam_prep","content":"C: is the correct answer. Upload 20 years of massive data to S3 for model training. Sagemaker for creating and training a model. Once ready, deploy at edge using IOT Greengrass (this takes care of poor internet connectivity issue which is not addressed by option A)","comment_id":"602681","timestamp":"1684268220.0","upvote_count":"3"}],"exam_id":26,"isMC":true,"timestamp":"2022-04-30 15:23:00","answer_images":[],"answer_ET":"C","answer":"C","unix_timestamp":1651324980,"question_images":[],"choices":{"C":"Move the training data to an Amazon S3 bucket. Train and evaluate the model by using Amazon SageMaker. Optimize the model by using SageMaker Neo. Set up an edge device in the manufacturing facilities with AWS IoT Greengrass. Deploy the model on the edge device.","A":"Move the training data to an Amazon S3 bucket. Train and evaluate the model by using Amazon SageMaker. Optimize the model by using SageMaker Neo. Deploy the model on a SageMaker hosting services endpoint.","B":"Train and evaluate the model on premises. Upload the model to an Amazon S3 bucket. Deploy the model on an Amazon SageMaker hosting services endpoint.","D":"Train the model on premises. Upload the model to an Amazon S3 bucket. Set up an edge device in the manufacturing facilities with AWS IoT Greengrass. Deploy the model on the edge device."},"answers_community":["C (100%)"]},{"id":"TqftevkvKMCLfHeQ8d9l","question_id":90,"url":"https://www.examtopics.com/discussions/amazon/view/9805-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","unix_timestamp":1575598320,"answer":"B","discussion":[{"comment_id":"27169","timestamp":"1632581280.0","poster":"vetal","comments":[{"content":"Yeah, it's B. But the page in the developer guide is page number 201 (209 in pdf). Second bullet point at the top.","poster":"devsean","upvote_count":"6","comment_id":"50138","timestamp":"1632681600.0"}],"upvote_count":"51","content":"https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-dg.pdf\npage 55:\nIf you plan to use GPU devices, make sure that your containers are nvidia-docker compatible. Only the\nCUDA toolkit should be included on containers. Don't bundle NVIDIA drivers with the image. For more\ninformation about nvidia-docker, see NVIDIA/nvidia-docker.\n\nSo the answer is B"},{"comment_id":"58356","content":"Answer is B. below is from AWS documentation,\nIf you plan to use GPU devices for model training, make sure that your containers are nvidia-docker compatible. Only the CUDA toolkit should be included on containers; don't bundle NVIDIA drivers with the image. \nhttps://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html","upvote_count":"14","poster":"AKT","timestamp":"1632753660.0"},{"comment_id":"1357513","poster":"JonSno","content":"Selected Answer: B\nWhen using Amazon SageMaker with GPU-based EC2 instances (e.g., P3 instances), you must ensure that your custom Docker container can leverage NVIDIA GPUs. NVIDIA-Docker (now part of Docker with nvidia-container-runtime) allows containers to access GPU resources without needing to bundle NVIDIA drivers inside the container.\n\nTo make a custom Docker container GPU-compatible, the Machine Learning Specialist should:\n\nUse NVIDIA CUDA and cuDNN in the Dockerfile.\nEnsure the container is built using the NVIDIA Container Toolkit (nvidia-docker).\nUse nvidia-container-runtime as the runtime.","upvote_count":"1","timestamp":"1739752980.0"},{"timestamp":"1727164740.0","upvote_count":"1","comment_id":"803146","content":"Selected Answer: B\nTo leverage the NVIDIA GPUs on Amazon EC2 P3 instances for training with Amazon SageMaker, the Docker container must be built to be compatible with NVIDIA-Docker. \n\nNVIDIA-Docker is a wrapper around Docker that makes it easier to use GPUs in containers by providing GPU-aware functionality. \n\nTo build a Docker container that is compatible with NVIDIA-Docker, the Specialist should install the NVIDIA GPU drivers in the Docker container and install the NVIDIA-Docker runtime on the EC2 instances.","poster":"AjoseO"},{"upvote_count":"1","poster":"bakarys","content":"Selected Answer: B\nNVIDIA-Docker is a Docker container runtime plugin that allows the Docker container to access the GPU resources on the host machine. By building the Docker container to be NVIDIA-Docker compatible, the Docker container will have access to the NVIDIA GPU resources on the Amazon EC2 P3 instances, allowing for accelerated training of the ResNet model.","timestamp":"1727164740.0","comment_id":"814328"},{"content":"Selected Answer: B\nThe reason for this choice is that NVIDIA-Docker is a tool that enables GPU-accelerated containers by automatically configuring the container runtime to use NVIDIA GPUs1. NVIDIA-Docker allows you to build and run Docker containers that can fully access the GPUs on your host system. This way, you can run GPU-intensive applications, such as deep learning frameworks, inside containers without any performance loss or compatibility issues.","upvote_count":"1","poster":"Mickey321","timestamp":"1727164740.0","comment_id":"973129"},{"content":"Selected Answer: B\nA. NO - the drivers are not necessary (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html)\nB. YES - it is about using the CUDA library, need to use proper base image (https://medium.com/@jgleeee/building-docker-images-that-require-nvidia-runtime-environment-1a23035a3a58) \nC. NO - file structure irrelavant to GPU\nD. NO - SageMaker config, irrelevant to Docker","upvote_count":"2","poster":"loict","timestamp":"1727164740.0","comment_id":"1006378"},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-dg.pdf\npage 55","comments":[{"content":"page 570\nOn a GPU instance, the image is run with the --gpus option. Only the CUDA toolkit should be\nincluded in the image not the NVIDIA drivers. For more information, see NVIDIA User Guide.","comment_id":"1197036","upvote_count":"1","poster":"iambasspaul","timestamp":"1713335700.0"}],"comment_id":"1156784","poster":"6ff83cb","upvote_count":"1","timestamp":"1708642860.0"},{"content":"Answer B\nLoad the CUDA toolkit only, not the drivers. Ref GPU section : https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi-specs.html","poster":"Crypt0zknight","timestamp":"1696245660.0","upvote_count":"1","comment_id":"1023040"},{"comment_id":"961678","upvote_count":"1","timestamp":"1690207560.0","poster":"Venkatesh_Babu","content":"Selected Answer: B\nI think it should be b"},{"upvote_count":"1","poster":"jackzhao","comment_id":"837550","content":"B is correct!","timestamp":"1678674120.0"},{"comment_id":"830038","timestamp":"1678030680.0","poster":"Sylzys","content":"Selected Answer: B\nAs per aws documentation, answer is B, and A is even explicitly not recommended","upvote_count":"1"},{"comment_id":"517354","content":"Selected Answer: B\nAs referred in other comments ans is B","upvote_count":"1","timestamp":"1641377340.0","poster":"Sorrybutnotsorry"},{"timestamp":"1639898820.0","comment_id":"504691","poster":"hussamS","content":"Selected Answer: B\nANS B\nAs mentioned byi other users","upvote_count":"1"},{"comment_id":"450145","upvote_count":"1","timestamp":"1635255120.0","poster":"sachin80","content":"As per me answer is B"},{"content":"The answer is for sure B - as mentioned by others. And this is clearly stated in the docs","upvote_count":"1","timestamp":"1634318400.0","poster":"konradL","comment_id":"338230"},{"timestamp":"1634177160.0","poster":"takahirokoyama","comment_id":"283305","content":"Ans. is B.","upvote_count":"1"},{"comment_id":"149901","content":"https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-dg.pdf is clear \"DO NOT BUNDLE NVIDIA DRIVERS WITH THE IMAGE\" Details are found in https://github.com/NVIDIA/nvidia-docker A is wrong, C and D are out. Looks more like a B than anything","upvote_count":"4","timestamp":"1633724040.0","poster":"GeeBeeEl"},{"poster":"Antriksh","upvote_count":"4","timestamp":"1633455360.0","comment_id":"108351","content":"If you plan to use GPU devices for model training, make sure that your containers are nvidia-docker compatible. Only the CUDA toolkit should be included on containers; don't bundle NVIDIA drivers with the image. -- source: (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-dockerfile.html)\nCorrect answer is 'B'"},{"upvote_count":"1","poster":"roytruong","comment_id":"98686","content":"this is B","timestamp":"1632825420.0"},{"upvote_count":"5","comment_id":"27007","timestamp":"1632177240.0","poster":"heihei","content":"i think it's b"}],"answer_ET":"B","question_text":"A Machine Learning Specialist is packaging a custom ResNet model into a Docker container so the company can leverage Amazon SageMaker for training. The\nSpecialist is using Amazon EC2 P3 instances to train the model and needs to properly configure the Docker container to leverage the NVIDIA GPUs.\nWhat does the Specialist need to do?","answer_description":"","question_images":[],"answer_images":[],"choices":{"A":"Bundle the NVIDIA drivers with the Docker image.","B":"Build the Docker container to be NVIDIA-Docker compatible.","C":"Organize the Docker container's file structure to execute on GPU instances.","D":"Set the GPU flag in the Amazon SageMaker CreateTrainingJob request body."},"exam_id":26,"answers_community":["B (100%)"],"timestamp":"2019-12-06 03:12:00","isMC":true}],"exam":{"isBeta":false,"numberOfQuestions":369,"isMCOnly":false,"id":26,"lastUpdated":"11 Apr 2025","provider":"Amazon","isImplemented":true,"name":"AWS Certified Machine Learning - Specialty"},"currentPage":18},"__N_SSP":true}