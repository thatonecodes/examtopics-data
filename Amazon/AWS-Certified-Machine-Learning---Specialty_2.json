{"pageProps":{"questions":[{"id":"WeTmJrA9wVAElJpkVC1u","question_id":6,"answer_images":[],"unix_timestamp":1612593180,"discussion":[{"comments":[{"poster":"AShahine21","upvote_count":"2","comment_id":"371790","timestamp":"1633297440.0","content":"Amazon Mechanical Turk is an Amazon service"}],"timestamp":"1632933540.0","poster":"SophieSu","upvote_count":"27","comment_id":"297077","content":"A. Fastest route must Amazon Services."},{"timestamp":"1694790840.0","content":"Selected Answer: A\nA. YES - Rekognition with built-in labels for images & video, Transcribe to convert sound to text and Comprehend for Topic Modeling\nB. NO - complicated\nC. NO - complicated\nD. NO - complicated","comment_id":"1008546","upvote_count":"1","poster":"loict"},{"timestamp":"1692895800.0","content":"Selected Answer: A\nAWS services for fastest route","poster":"Mickey321","comment_id":"989341","upvote_count":"1"},{"comments":[{"comment_id":"1237175","content":"this takes time and u need to have atleast some technical ML expertise","timestamp":"1719373800.0","upvote_count":"1","poster":"winstonmcgee69"}],"timestamp":"1684476180.0","comment_id":"901676","upvote_count":"1","poster":"angus","content":"why not C?\nC. Use Amazon Transcribe to convert speech to text. Use the Amazon SageMaker Neural Topic Model (NTM) and Object Detection algorithms to tag data into distinct categories/classes."},{"poster":"Flysun","comment_id":"852776","content":"I will choose B，https://aws.amazon.com/cn/getting-started/hands-on/machine-learning-tutorial-label-training-data/","timestamp":"1679978460.0","upvote_count":"1"},{"content":"Selected Answer: A\nMechanical Turk is the most accurate, but the three services in letter A is the fastest!","timestamp":"1678288200.0","poster":"Valcilio","comment_id":"833086","upvote_count":"1"},{"upvote_count":"2","comment_id":"804816","content":"Selected Answer: A\nA. Use Amazon Rekognition, Amazon Comprehend, and Amazon Transcribe to tag data into distinct categories/classes is the fastest route to index the assets. These AWS services provide pre-built machine learning models that can be used to tag the content in the archive without the need for building custom models from scratch. \n\nThis option would be faster than using custom models with the AWS Deep Learning AMI and Amazon EC2 GPU instances, or using Amazon Mechanical Turk for human labeling. \n\nAdditionally, the use of pre-built models reduces the need for machine learning expertise, aligning with the company's goal of accelerating efforts by its in-house researchers.","poster":"AjoseO","timestamp":"1676066520.0"},{"timestamp":"1668302220.0","content":"A. Option B is for those without ML experience. But \"researchers who have limited machine learning expertise“, so A is better.","upvote_count":"2","poster":"VinceCar","comment_id":"717038"},{"upvote_count":"2","comment_id":"519145","content":"A. The most straight forward use of services.","poster":"hess","timestamp":"1641580260.0"},{"poster":"YJ4219","comment_id":"391347","timestamp":"1634756460.0","upvote_count":"1","content":"I would have said B, but in B it says \"label footage\" which means it ignored the rest of the data, so i'd go with A","comments":[{"comment_id":"427061","poster":"Madwyn","upvote_count":"2","content":"The question said \"a very large archive\" meaning a lot of money to pay for labour. B won't be as fast as machine, plus you only label the footage, ignored other stuff.","timestamp":"1635181980.0"}]},{"comment_id":"375261","upvote_count":"1","poster":"AjithkumarSL","content":"Would go for A","timestamp":"1633684860.0"},{"timestamp":"1633254180.0","poster":"AShahine21","upvote_count":"1","comment_id":"371789","content":"I will go with B"},{"content":"Correct answer is A","comment_id":"310784","poster":"Juka3lj","upvote_count":"3","timestamp":"1633065060.0"},{"comments":[{"poster":"AhmedAbuMusa","timestamp":"1634882640.0","comment_id":"400984","upvote_count":"1","content":"Take into consideration that it is \"a very large archive\""}],"comment_id":"284603","content":"B. as no one in-house is an expert and It probably is the fastest way to get there","timestamp":"1632520680.0","poster":"ksrivastavaSumit","upvote_count":"2"}],"exam_id":26,"timestamp":"2021-02-06 07:33:00","answers_community":["A (100%)"],"isMC":true,"answer_description":"","question_text":"A media company with a very large archive of unlabeled images, text, audio, and video footage wishes to index its assets to allow rapid identification of relevant content by the Research team. The company wants to use machine learning to accelerate the efforts of its in-house researchers who have limited machine learning expertise.\nWhich is the FASTEST route to index the assets?","url":"https://www.examtopics.com/discussions/amazon/view/44106-exam-aws-certified-machine-learning-specialty-topic-1/","answer":"A","question_images":[],"answer_ET":"A","topic":"1","choices":{"A":"Use Amazon Rekognition, Amazon Comprehend, and Amazon Transcribe to tag data into distinct categories/classes.","C":"Use Amazon Transcribe to convert speech to text. Use the Amazon SageMaker Neural Topic Model (NTM) and Object Detection algorithms to tag data into distinct categories/classes.","D":"Use the AWS Deep Learning AMI and Amazon EC2 GPU instances to create custom models for audio transcription and topic modeling, and use object detection to tag data into distinct categories/classes.","B":"Create a set of Amazon Mechanical Turk Human Intelligence Tasks to label all footage."}},{"id":"WtUcuEuKOCy0fBTFVhuN","discussion":[{"content":"Agreed, B it is. See https://medium.com/slalom-data-analytics/amazon-kinesis-data-streams-auto-scaling-the-number-of-shards-105dc967bed5\n\nOne shard can Ingest 1 MB/second or 1,000 records/second. So 100 KB * 100 = 10 MB (10 shards required)","comment_id":"283196","timestamp":"1649414340.0","poster":"[Removed]","upvote_count":"26"},{"timestamp":"1725689520.0","upvote_count":"1","content":"Selected Answer: B\n100 KB * 100 = 10 MB\n1 MB/second\n10 / 1 = 10 shards.","comment_id":"1167776","poster":"james2033"},{"upvote_count":"1","timestamp":"1708800780.0","poster":"Mickey321","comment_id":"989343","content":"Selected Answer: B\nEach shard in Amazon Kinesis Data Streams can support up to 1,000 transactions per second.\nThe data needs to be ingested at up to 100 transactions per second, so we need at least 1 shard.\nHowever, we also need to consider the size of the JSON data blob. Each JSON data blob is 100 KB in size, and each shard can only store up to 1 MB of data.\nThis means that we need to have at least 10 shards, so that each shard can store 100 KB of data."},{"comment_id":"769452","content":"B - Max. ingestion per shard = 1000 KB/s\n\n--> 100 Records * 100 KB = 10.000 KB\n--> 10.000 KB / 1000 KB/per Shard = 10 Shards","poster":"PHTR","timestamp":"1688815500.0","upvote_count":"3"},{"comment_id":"658172","poster":"Shailendraa","upvote_count":"1","timestamp":"1677835500.0","content":"10 should be correct."},{"comment_id":"612231","upvote_count":"2","timestamp":"1670317080.0","content":"Selected Answer: B\nB is correct","poster":"tgaos"},{"comment_id":"434722","content":"100 kb * 100 t/second = 10000 kb = 10 mb\n10mb / max_threshold_per_shard (1 mb) = 10 shards","poster":"mahmoudai","timestamp":"1651917240.0","upvote_count":"1"},{"poster":"benson2021","timestamp":"1649901300.0","upvote_count":"2","content":"Reference: https://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html","comment_id":"332994"}],"question_images":[],"answers_community":["B (100%)"],"choices":{"C":"100 shards","D":"1,000 shards","A":"1 shards","B":"10 shards"},"question_id":7,"unix_timestamp":1612417620,"answer":"B","question_text":"A Machine Learning Specialist is working for an online retailer that wants to run analytics on every customer visit, processed through a machine learning pipeline.\nThe data needs to be ingested by Amazon Kinesis Data Streams at up to 100 transactions per second, and the JSON data blob is 100 KB in size.\nWhat is the MINIMUM number of shards in Kinesis Data Streams the Specialist should use to successfully ingest this data?","isMC":true,"timestamp":"2021-02-04 06:47:00","answer_ET":"B","url":"https://www.examtopics.com/discussions/amazon/view/43964-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","answer_images":[],"exam_id":26,"answer_description":""},{"id":"AwzZtoQ2coNOPXUuxXMu","question_text":"A Machine Learning Specialist is deciding between building a naive Bayesian model or a full Bayesian network for a classification problem. The Specialist computes the Pearson correlation coefficients between each feature and finds that their absolute values range between 0.1 to 0.95.\nWhich model describes the underlying data in this situation?","topic":"1","answer_description":"","choices":{"A":"A naive Bayesian model, since the features are all conditionally independent.","D":"A full Bayesian network, since some of the features are statistically dependent.","C":"A naive Bayesian model, since some of the features are statistically dependent.","B":"A full Bayesian network, since the features are all conditionally independent."},"discussion":[{"poster":"[Removed]","comments":[{"comment_id":"310788","timestamp":"1666299120.0","upvote_count":"1","content":"I agree, makes moste sense","poster":"Juka3lj"}],"upvote_count":"24","comment_id":"283201","content":"I would say D, because of correlations and dependencies between features. See https://towardsdatascience.com/basics-of-bayesian-network-79435e11ae7b and https://www.quora.com/Whats-the-difference-between-a-naive-Bayes-classifier-and-a-Bayesian-network?share=1","timestamp":"1663661220.0"},{"comment_id":"325001","upvote_count":"9","content":"It should be D. Naive Bayes is called naive because it assumes that each input variable is independent. This is a strong assumption and unrealistic for real data; however, the technique is very effective on a large range of complex problems.","timestamp":"1666848720.0","poster":"Vita_Rasta84444"},{"timestamp":"1724518980.0","comment_id":"989348","content":"Selected Answer: D\nIn this case, the absolute values of the Pearson correlation coefficients range between 0.1 to 0.95. This means that some of the features are statistically dependent. Therefore, a full Bayesian network is a better model for the underlying data than a naive Bayesian model.","poster":"Mickey321","upvote_count":"1"},{"content":"Selected Answer: D\nIn a full Bayesian network, features are connected to each other by edges that represent their conditional dependence relationships. A full Bayesian network is useful when the relationships between the features are complex, non-linear or when they are not conditionally independent. \n\nIn this situation, where the Pearson correlation coefficients range between 0.1 and 0.95, it suggests that there are dependencies between the features, indicating that a full Bayesian network would be appropriate to capture the relationships between the features and model the data.","poster":"AjoseO","comment_id":"804811","timestamp":"1707601920.0","upvote_count":"5"},{"upvote_count":"3","poster":"ystotest","content":"Selected Answer: D\ndistinction between Bayes theorem and Naive Bayes is that Naive Bayes assumes conditional independence where Bayes theorem does not. This means the relationship between all input features are independent . The Pearson correlation coefficient (r) is the most common way of measuring a linear correlation. It is a number between –1 and 1 that measures the strength and direction of the relationship between two variables.","timestamp":"1701037380.0","comment_id":"727833"},{"content":"A naive Bayesian model, since some of the features, are statistically dependent.","poster":"Shailendraa","upvote_count":"2","comment_id":"658174","timestamp":"1693725900.0"},{"poster":"SophieSu","upvote_count":"6","timestamp":"1666028220.0","comment_id":"297083","content":"D. Naive bayes - features are independent given the class."},{"upvote_count":"2","content":"I would say, B. Naive Bayes assumes conditional independence and not statistical","comment_id":"291745","poster":"astonm13","comments":[{"content":"you mean (a) naive bayes not (b)","timestamp":"1667607780.0","upvote_count":"1","comment_id":"369251","poster":"abdohanfi"}],"timestamp":"1665765900.0"},{"comment_id":"285623","timestamp":"1664997060.0","content":"This is also a good source of information to help build your understanding https://www.simplypsychology.org/correlation.html","poster":"cnethers","upvote_count":"1"}],"timestamp":"2021-02-04 06:56:00","unix_timestamp":1612418160,"answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/43965-exam-aws-certified-machine-learning-specialty-topic-1/","answer_images":[],"question_images":[],"answer":"D","exam_id":26,"isMC":true,"question_id":8,"answer_ET":"D"},{"id":"SUbCyKxOMDLMihiZ3D9R","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/44249-exam-aws-certified-machine-learning-specialty-topic-1/","exam_id":26,"question_images":["https://www.examtopics.com/assets/media/exam-media/04145/0006400001.jpg"],"choices":{"A":"Exponential transformation","B":"Logarithmic transformation","D":"Sinusoidal transformation","C":"Polynomial transformation"},"isMC":true,"answer_ET":"B","topic":"1","unix_timestamp":1612761120,"question_text":"A Data Scientist is building a linear regression model and will use resulting p-values to evaluate the statistical significance of each coefficient. Upon inspection of the dataset, the Data Scientist discovers that most of the features are normally distributed. The plot of one feature in the dataset is shown in the graphic.\n//IMG//\n\nWhat transformation should the Data Scientist apply to satisfy the statistical assumptions of the linear regression model?","discussion":[{"timestamp":"1647897600.0","comment_id":"291746","content":"I would say B. Logarithmic transformation converts skewed distributions towards normal","poster":"astonm13","upvote_count":"20"},{"content":"I would go with B. For right skewed distributions -> Logrithmic transformation\nFor left skewed distributions -> exponential transformations=","upvote_count":"1","comment_id":"1152815","timestamp":"1723920540.0","poster":"AIWave"},{"poster":"Mickey321","upvote_count":"1","content":"Selected Answer: B\nThe linear regression model assumes that the errors are normally distributed. The plot of the feature shows that the errors are not normally distributed.\nThe logarithmic transformation can be used to transform the errors to be normally distributed.\nThe exponential transformation, polynomial transformation, and sinusoidal transformation cannot be used to transform the errors to be normally distributed.","timestamp":"1708802040.0","comment_id":"989357"},{"upvote_count":"1","timestamp":"1706691780.0","poster":"ccpmad","comment_id":"967840","content":"Selected Answer: B\nB\nwhen the feature data is not normally distributed, applying a logarithmic transformation can help to normalize the data and satisfy the assumptions of the linear regression model."},{"timestamp":"1696404540.0","poster":"cpal012","comment_id":"860754","upvote_count":"1","content":"'A' would make it considerably worse.","comments":[{"upvote_count":"3","comment_id":"939771","content":"Exponential transformation would make it exponentially worse. :D","timestamp":"1704107460.0","poster":"goku58"}]},{"upvote_count":"2","comment_id":"855612","poster":"Zhechen0912","content":"Selected Answer: B\nLog Normal Distribution => Log() => Normal Distribution","timestamp":"1696069560.0"},{"comment_id":"805277","content":"Selected Answer: B\nB is correct answer","upvote_count":"1","timestamp":"1691755680.0","poster":"sqavi"},{"content":"Selected Answer: B\nThis is B, as this feature seems skewed while others have a regular distribution according to the question. The log transformation will reduce this features skewness.","timestamp":"1657941720.0","poster":"vetaal","comment_id":"524640","upvote_count":"2"},{"poster":"YJ4219","upvote_count":"2","comment_id":"391356","timestamp":"1649336340.0","content":"I think it's B.\nreference: https://corporatefinanceinstitute.com/resources/knowledge/other/positively-skewed-distribution/#:~:text=For%20positively%20skewed%20distributions%2C%20the,each%20value%20in%20the%20dataset.\n\"For positively skewed distributions, the most popular transformation is the log transformation. The log transformation implies the calculations of the natural logarithm for each value in the dataset. The method reduces the skew of a distribution. Statistical tests are usually run only when the transformation of the data is complete.\""},{"content":"I would also go for B, as Log transformation is often mentioned, when we are talking about right (positive) skewness.","comment_id":"338828","poster":"konradL","timestamp":"1648796760.0","upvote_count":"3"}],"answer_description":"","timestamp":"2021-02-08 06:12:00","answer_images":[],"question_id":9,"answer":"B"},{"id":"sX81DpH1CzjzOLRRTb3R","answer_ET":"B","question_text":"A Machine Learning Specialist is assigned to a Fraud Detection team and must tune an XGBoost model, which is working appropriately for test data. However, with unknown data, it is not working as expected. The existing parameters are provided as follows.\n//IMG//\n\nWhich parameter tuning guidelines should the Specialist follow to avoid overfitting?","unix_timestamp":1612809060,"question_id":10,"url":"https://www.examtopics.com/discussions/amazon/view/44289-exam-aws-certified-machine-learning-specialty-topic-1/","answer_images":[],"answer":"B","isMC":true,"answers_community":["B (100%)"],"discussion":[{"timestamp":"1666855740.0","poster":"SophieSu","upvote_count":"17","comment_id":"299226","content":"B lower max_depth is the correct answer.\nD min_child_weight means something like \"stop trying to split once your sample size in a node goes below a given threshold\"\nLower min_child_weight, the tree becomes more deep and complex.\nIncrease min_child_weight, the tree will have less branches and less complexity."},{"upvote_count":"1","poster":"Mickey321","timestamp":"1724519820.0","content":"Selected Answer: B\nThe max_depth parameter controls the maximum depth of the decision trees in the XGBoost model. A higher max_depth value will result in more complex decision trees, which can lead to overfitting.","comment_id":"989362"},{"upvote_count":"1","comment_id":"967853","content":"Selected Answer: B\nOverfitting occurs when a model performs well on the training data but poorly on unseen or test data. In the context of XGBoost, reducing the max_depth parameter helps prevent overfitting. The max_depth parameter controls the maximum depth of the trees in the ensemble. A smaller max_depth value limits the complexity of the trees, making them less likely to memorize the noise in the training data and improve generalization to unseen data.","poster":"ccpmad","timestamp":"1722410280.0"},{"poster":"gcaria","timestamp":"1717516860.0","upvote_count":"1","content":"Selected Answer: B\nIt is B","comment_id":"914796"},{"content":"B: overfitting problem.","timestamp":"1717466040.0","upvote_count":"1","comment_id":"914047","poster":"vbal"},{"timestamp":"1694542560.0","poster":"Shailendraa","comment_id":"667325","content":"12-Sep Exam.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1668873720.0","poster":"[Removed]","comment_id":"481909","content":"Selected Answer: B\nWhen a model overfits, the solutions are:\n1. Reduce model flexibility and complexity\n2. Reduce the number of feature combinations\n3. Decrease n-grams size\n4. Decrease the number of numeric attribute bins\n5. Increase the amount of regularization\n6. Add dropout"},{"content":"B. 30-deep tree is crazy; normally it's 6-7 no more","poster":"Dr_Kiko","upvote_count":"2","comment_id":"434111","timestamp":"1667058000.0"},{"comment_id":"286381","timestamp":"1665216840.0","poster":"cnethers","upvote_count":"2","comments":[{"poster":"arulrajjayaraj","content":"Ans : B , Lower values avoid over-fitting.\nNo for D - Larger values avoid over-fitting.","timestamp":"1666021260.0","upvote_count":"8","comment_id":"287744"}],"content":"A. Increase the max_depth parameter value. (This would increase the complexity resulting in overfitting)\n B. Lower the max_depth parameter value. (This would reduce the complexity and minimize overfitting)\n C. Update the objective to binary:logistic. it depends on what the target(s) generally you would have a binary classification for fraud detection but there is nothing to say you can't have a multi class so there is not enough information given.\n D. Lower the min_child_weight parameter value. (This would reduce the complexity and minimize overfitting)\n\nI find that there are 2 correct answers to this question which does not help B & D"},{"comment_id":"286376","content":"Thus, those parameters can be used to control the complexity of the trees. It is important to tune them together in order to find a good trade-off between model bias and variance","upvote_count":"2","timestamp":"1664416920.0","poster":"cnethers"},{"timestamp":"1664285400.0","content":"min_child_weight is the minimum weight (or number of samples if all samples have a weight of 1) required in order to create a new node in the tree. A smaller min_child_weight allows the algorithm to create children that correspond to fewer samples, thus allowing for more complex trees, but again, more likely to overfit.","comment_id":"286374","poster":"cnethers","upvote_count":"1"},{"upvote_count":"2","content":"max_depth is the maximum number of nodes allowed from the root to the farthest leaf of a tree. Deeper trees can model more complex relationships by adding more nodes, but as we go deeper, splits become less relevant and are sometimes only due to noise, causing the model to overfit.","poster":"cnethers","timestamp":"1663999200.0","comment_id":"286372"}],"topic":"1","timestamp":"2021-02-08 19:31:00","exam_id":26,"choices":{"D":"Lower the min_child_weight parameter value.","C":"Update the objective to binary:logistic.","A":"Increase the max_depth parameter value.","B":"Lower the max_depth parameter value."},"answer_description":"","question_images":["https://www.examtopics.com/assets/media/exam-media/04145/0006500001.png"]}],"exam":{"lastUpdated":"11 Apr 2025","id":26,"isImplemented":true,"name":"AWS Certified Machine Learning - Specialty","provider":"Amazon","isMCOnly":false,"isBeta":false,"numberOfQuestions":369},"currentPage":2},"__N_SSP":true}