{"pageProps":{"questions":[{"id":"2UcUAPapL64m0ej43jLd","answer_ET":"B","answers_community":["B (100%)"],"unix_timestamp":1604273280,"timestamp":"2020-11-02 00:28:00","discussion":[{"poster":"Newguru2020","timestamp":"1664545980.0","comments":[{"content":"Ans B. https://s3browser.com/bucket-lifecycle-configuration.aspx\nAbort incomplete multipart uploads allows you to delete multipart uploads that are not successfully completed within the predefined time period.","upvote_count":"3","poster":"ming98","comment_id":"222492","timestamp":"1664626800.0"}],"comment_id":"210845","upvote_count":"14","content":"Ans: B\nAs a best practice, we recommend you configure a lifecycle rule (using the AbortIncompleteMultipartUpload action) to minimize your storage costs.\n\nAmazon S3 supports a bucket lifecycle rule that you can use to direct Amazon S3 to stop multipart uploads that don't complete within a specified number of days after being initiated. When a multipart upload is not completed within the time frame, it becomes eligible for stoppage and Amazon S3 stops the multipart upload (and deletes the parts associated with the multipart upload)."},{"comment_id":"960097","upvote_count":"1","poster":"albert_kuo","content":"Selected Answer: B\nBy creating a lifecycle rule to abort incomplete multipart uploads, you can ensure that any incomplete uploads are automatically deleted after a specified period. This way, if a network outage or any other event causes incomplete multipart uploads in the future, the lifecycle rule will take care of deleting them automatically, preventing any accumulation of incomplete uploads.","timestamp":"1721712180.0"},{"content":"B is the answer","upvote_count":"1","comment_id":"369461","poster":"RicardoD","timestamp":"1667514240.0"},{"comment_id":"271596","poster":"abhishek_m_86","content":"B. Create an Amazon S3 lifecycle rule to abort incomplete multipart uploads so that they are deleted this time and in the future.\nSeem correct","upvote_count":"2","timestamp":"1665590880.0"},{"timestamp":"1665192360.0","upvote_count":"1","comment_id":"256897","poster":"arpana_03","content":"B is correct answer"},{"poster":"Jordanro","upvote_count":"1","timestamp":"1665177000.0","content":"B. https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html#mpu-stop-incomplete-mpu-lifecycle-config","comment_id":"254075"},{"comment_id":"244135","upvote_count":"1","poster":"jackdryan","timestamp":"1665144900.0","content":"I'll go with B"}],"question_text":"An organization recently faced a network outage while uploading data into one of their S3 buckets. This outage generated many incomplete multipart uploads in that S3 bucket. A sysops administrator wants to delete the incomplete multipart uploads and ensure that the incomplete multipart uploads are deleted automatically the next time such an event occurs.\nHow should this be done?","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/35690-exam-aws-sysops-topic-1-question-855-discussion/","answer":"B","topic":"1","isMC":true,"exam_id":36,"answer_description":"Reference:\nhttps://aws.amazon.com/blogs/aws/s3-lifecycle-management-update-support-for-multipart-uploads-and-delete-markers/","choices":{"B":"Create an Amazon S3 lifecycle rule to abort incomplete multipart uploads so that they are deleted this time and in the future.","D":"Use the AWS Management Console to abort all the incomplete uploads from the day of the event so that they are deleted.","C":"Use the AWS CLI to list all the multipart uploads, and abort all the incomplete uploads from the day of the event so that they are deleted.","A":"Create an Amazon S3 Event Notification to trigger an AWS Lambda function that deletes incomplete multipart uploads."},"question_id":836},{"id":"V69rgegGZ0CWRK56Va56","answer_description":"Reference:\nhttps://docs.aws.amazon.com/cur/latest/userguide/monthly-report.html","exam_id":36,"discussion":[{"poster":"kiev","comment_id":"267631","upvote_count":"8","timestamp":"1665637320.0","content":"Anyone here going for the exam anytime soon? Going for mine in 3 hours time and will give you guys insight into what came. Please pray for me.","comments":[{"poster":"Drey","content":"so how did it go for both of you?","upvote_count":"1","timestamp":"1667021460.0","comment_id":"343027"},{"upvote_count":"2","comment_id":"268508","timestamp":"1666128660.0","content":"i am going tomorrow, good luck! and let us know how did it go","poster":"liliia"}]},{"timestamp":"1663723080.0","comments":[{"upvote_count":"1","content":"A is good. \nBesides resource tag, it seems that we can use accounts, servers... as dimension for custom categories and create Cost and Usage reports. \n\nhttps://aws.amazon.com/aws-cost-management/aws-cost-categories/\nYou can create custom categories and map your cost and usage information into these categories based on the rules defined by you using various dimensions such as account, tag, service, charge type, and even other cost categories. Once cost categories are set up and enabled, you will be able to view your cost and usage information by these categories starting at the beginning of the month in AWS Cost Explorer, AWS Budgets, and AWS Cost and Usage Report (CUR).","comment_id":"273924","timestamp":"1666347120.0","poster":"ANS0908431"}],"content":"D is correct...It is not possible without resource tagging...","comment_id":"212820","poster":"ImranR","upvote_count":"7"},{"timestamp":"1725275040.0","content":"Selected Answer: D\ntagging resources and generating a monthly cost allocation report, is the most efficient and practical way to meet the requirement of providing AWS resource usage reports by department.","comment_id":"996831","poster":"albert_kuo","upvote_count":"1"},{"content":"A is the answer","comment_id":"369462","upvote_count":"1","poster":"RicardoD","timestamp":"1667811480.0"},{"comments":[{"timestamp":"1667809740.0","content":"You can definitely tag existing resources.","upvote_count":"1","comment_id":"367435","poster":"chewingice"}],"upvote_count":"2","comment_id":"361310","timestamp":"1667043420.0","poster":"Desteeny","content":"A is good. \nBest practice to use tagging when resources are created. D is not the best because you cannot start tagging all the resources when you need to generate the report."},{"upvote_count":"1","timestamp":"1666159860.0","comment_id":"271599","content":"D. Tag all resources with department codes. Generate a monthly cost allocation report.\nSeems correct","poster":"abhishek_m_86"},{"comments":[{"poster":"wannaaws","upvote_count":"1","content":"Had another look, seemingly \"Tag all resources with department codes\" is the key to be able to achieve it.","comment_id":"260882","timestamp":"1665467340.0"}],"comment_id":"260864","poster":"wannaaws","content":"Important: The Monthly Cost Allocation Report feature will be unavailable at a later date. We strongly recommend that you use the AWS Cost and Usage Reports instead.\nhttps://docs.aws.amazon.com/cur/latest/userguide/monthly-cost-allocation.html\nShall it be A, by using AWS Cost and Usage reports?","timestamp":"1665360120.0","upvote_count":"1"},{"comment_id":"254812","timestamp":"1665166080.0","poster":"kiev","content":"I am going for D as well. To know departmental spending you need to tag all the departments first before running a cost and usage report monthly to know who is spending what.","upvote_count":"1"},{"upvote_count":"1","comment_id":"244137","content":"I'll go with D","timestamp":"1664995560.0","poster":"jackdryan"},{"comments":[{"comment_id":"213081","poster":"Newguru2020","upvote_count":"1","timestamp":"1664256900.0","content":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/configurecostallocreport.html"}],"comment_id":"213080","upvote_count":"5","timestamp":"1664114640.0","content":"Ans: D\nTag resources with appropriate department code and run cost allocation report later","poster":"Newguru2020"}],"choices":{"C":"Run a monthly AWS CloudTrail report of resource usage by tag using department codes.","A":"Configure AWS Cost and Usage reports for each department. Run the reports monthly.","D":"Tag all resources with department codes. Generate a monthly cost allocation report.","B":"Schedule a monthly report for each department using AWS Budgets."},"answer":"D","url":"https://www.examtopics.com/discussions/amazon/view/36056-exam-aws-sysops-topic-1-question-856-discussion/","question_images":[],"unix_timestamp":1604502840,"question_text":"A company's finance department wants to receive a monthly report showing AWS resource usage by department.\nWhich solution should be used to meet the requirements?","topic":"1","question_id":837,"answer_images":[],"isMC":true,"answers_community":["D (100%)"],"timestamp":"2020-11-04 16:14:00","answer_ET":"A"},{"id":"Xzvu02sSRSKMXCM1flsB","url":"https://www.examtopics.com/discussions/amazon/view/35676-exam-aws-sysops-topic-1-question-857-discussion/","unix_timestamp":1604269020,"answer_ET":"A","discussion":[{"upvote_count":"8","poster":"Newguru2020","comments":[{"content":"Right. If this is a NAT instance, you must stop source / destination checking. A NAT instance must be able to send and receive traffic when the source or destination is not itself.\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_NAT_Instance.html#EIP_Disable_SrcDestCheck","comment_id":"218575","poster":"mrphuongbn","upvote_count":"6","timestamp":"1666096860.0"}],"content":"Easy. Disable Source/Destination check on Instance to make it a NAT instance\nAns: C","comment_id":"210809","timestamp":"1664730000.0"},{"upvote_count":"1","comment_id":"960101","poster":"albert_kuo","timestamp":"1721712300.0","content":"Selected Answer: C\nBy disabling source/destination checks on the NAT instance, the instance can effectively serve as a gateway for instances in the private subnet to access the internet, and the internet traffic will flow through the NAT instance without being blocked."},{"content":"Selected Answer: C\nC is the answer","comment_id":"801245","poster":"gulu73","timestamp":"1707329340.0","upvote_count":"1"},{"upvote_count":"1","poster":"RicardoD","comment_id":"369463","content":"c is the answer","timestamp":"1667526540.0"},{"upvote_count":"2","comment_id":"323191","content":"I can't believe that the suggested answer is A. This is absolutely funny. Answer is C.","poster":"Hypercuber","timestamp":"1667341020.0"},{"upvote_count":"2","timestamp":"1666704540.0","content":"C. Disable source/destination checks on the NAT instance\nSeem correct","comment_id":"271602","poster":"abhishek_m_86"},{"comment_id":"244140","content":"I'll go with C","upvote_count":"1","poster":"jackdryan","timestamp":"1666468200.0"},{"upvote_count":"1","comment_id":"224574","timestamp":"1666240740.0","poster":"MFDOOM","content":"C. Disable source/destination checks on the NAT instance"},{"content":"C is correct","poster":"ImranR","comment_id":"212825","timestamp":"1665037980.0","upvote_count":"1"}],"topic":"1","isMC":true,"answers_community":["C (100%)"],"question_id":838,"answer_description":"Reference:\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html","question_images":[],"timestamp":"2020-11-01 23:17:00","question_text":"A SysOps Administrator maintains several Amazon EC2 instances that do not have access to the public internet. To patch operating systems, the instances require outbound internet connectivity. For security reasons, the instances should not be reachable from the public Internet.\nThe Administrator deploys a NAT instance, updates the security groups, and configures the appropriate routes within the route table. However, the instances are still unable to reach the Internet.\nWhat should be done to resolve the issue?","choices":{"A":"Assign Elastic IP addresses to the instances and create a route from the private subnets to the internet gateway","C":"Disable source/destination checks on the NAT instance","B":"Delete the NAT instance and replace it with AWS WAF","D":"Start/stop the NAT instance so it is launched on a different host"},"answer_images":[],"answer":"C","exam_id":36},{"id":"wsOTHdCSI6rlknTrlJop","topic":"1","answer":"A","timestamp":"2020-11-01 23:07:00","answer_description":"Reference:\nhttps://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html","answers_community":["A (100%)"],"discussion":[{"upvote_count":"13","comments":[{"content":"Agree.","comment_id":"211744","poster":"r_man","upvote_count":"1","timestamp":"1695421680.0"}],"timestamp":"1695327780.0","poster":"Newguru2020","content":"Ans: A\nSince the default automatic rotation period for KMS is 365 days and there is no option to customize it.","comment_id":"210804"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html#rotate-aws-managed-keys\n\nCustomer managed keys\nAutomatic key rotation is disabled by default on customer managed keys but authorized users can enable and disable it. When you enable (or re-enable) automatic key rotation, AWS KMS automatically rotates the KMS key one year (approximately 365 days) after the enable date and every year thereafter.\n\nAWS managed keys\nAWS KMS automatically rotates AWS managed keys every year (approximately 365 days). You cannot enable or disable key rotation for AWS managed keys.","poster":"Finger41","comment_id":"620724","timestamp":"1719110340.0","upvote_count":"1"},{"comment_id":"271603","content":"A. Create a new CMK every 7 days to manually rotate the encryption keys.\nSeem correct","timestamp":"1698521520.0","upvote_count":"2","poster":"abhishek_m_86"},{"timestamp":"1697566560.0","comment_id":"244141","upvote_count":"1","content":"I'll go with A","poster":"jackdryan"},{"poster":"MFDOOM","content":"A. Create a new CMK every 7 days to manually rotate the encryption keys","timestamp":"1697173440.0","upvote_count":"1","comment_id":"224579"},{"poster":"ImranR","content":"A is correct as stated by Newguru2020....","comment_id":"212114","timestamp":"1697160780.0","upvote_count":"1"}],"answer_images":[],"question_text":"A SysOps Administrator using AWS KMS needs to rotate all customer master keys (CMKs) every week to meet Information Security guidelines.\nWhich option would meet the requirement?","choices":{"D":"Use data keys for each encryption task to avoid the need to rotate keys.","A":"Create a new CMK every 7 days to manually rotate the encryption keys.","C":"Switch to using AWS CloudHSM as AWS KMS does not support key rotation.","B":"Enable key rotation on the CMKs and set the rotation period to 7 days."},"unix_timestamp":1604268420,"answer_ET":"A","url":"https://www.examtopics.com/discussions/amazon/view/35673-exam-aws-sysops-topic-1-question-858-discussion/","exam_id":36,"isMC":true,"question_images":[],"question_id":839},{"id":"oppaKp6Howt8HcK9xCz5","answer_description":"Reference:\nhttps://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html","answer_images":[],"topic":"1","isMC":true,"answer":"C","choices":{"C":"Configure the unified CloudWatch agent to stream the logs to Amazon CloudWatch Logs.","D":"Configure VPC Flow Logs for the subnet hosting the EC2 instance.","B":"Configure an Amazon CloudWatch Events rule to transfer the logs to Amazon S3 upon an EC2 state change to terminated.","A":"Change the storage type from EBS to instance store."},"discussion":[{"comment_id":"210797","upvote_count":"9","timestamp":"1663921080.0","content":"Ans: C \nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/UseCloudWatchUnifiedAgent.html","poster":"Newguru2020"},{"content":"Selected Answer: B\nOption B involves using Amazon CloudWatch Events to capture EC2 instance state change events. When an EC2 instance is terminated, a state change event is triggered, and you can configure a CloudWatch Events rule to respond to this event.\n\nBy setting up a CloudWatch Events rule with a target to transfer the logs to Amazon S3 when an EC2 instance state changes to \"terminated,\" you can automatically copy the application logs to Amazon S3 for future analysis. This ensures that even when the instances are terminated, you have a reliable and durable storage location for the logs.","upvote_count":"1","comment_id":"960103","timestamp":"1721712480.0","poster":"albert_kuo"},{"content":"Selected Answer: C\nC is the answer","poster":"gulu73","timestamp":"1707329400.0","comment_id":"801247","upvote_count":"1"},{"comment_id":"404603","poster":"wahlbergusa","timestamp":"1667247300.0","upvote_count":"1","content":"\"... upon an EC2 state change to terminated\" , once the EC2 instance is terminated Lambda function will not be able to pull any logs cause logs will be long gone alongside the EC2 instance. Only way is pulling/pushing the logs as soon as events occur. Hence the answer is C."},{"comments":[{"poster":"wahlbergusa","content":"\"... upon an EC2 state change to terminated\" , once the EC2 instance is terminated Lambda function will not be able to pull any logs cause logs will be long gone alongside the EC2 instance. Only way is pulling/pushing the logs as soon as events occur. Hence the answer is C.","comment_id":"404929","upvote_count":"1","timestamp":"1667309340.0"}],"comment_id":"404284","timestamp":"1667171700.0","content":"Why not b? Create a rule that trigger a lambda function that transfer the logs to a S3 bucket. https://docs.aws.amazon.com/autoscaling/ec2/userguide/cloud-watch-events.html","upvote_count":"2","poster":"Pupina"},{"content":"C. Configure the unified CloudWatch agent to stream the logs to Amazon CloudWatch Logs.","comment_id":"271608","upvote_count":"2","timestamp":"1667052000.0","poster":"abhishek_m_86"},{"upvote_count":"1","content":"I'll go with C","comment_id":"244144","timestamp":"1666691400.0","poster":"jackdryan"},{"upvote_count":"1","content":"Ans C: CloudWatch agent to write logs to the Cloudwatch","poster":"weril","comment_id":"236780","timestamp":"1666272540.0"},{"poster":"ImranR","content":"C is looking efficient...","comment_id":"212837","timestamp":"1664143860.0","upvote_count":"1"}],"unix_timestamp":1604267880,"answer_ET":"D","question_id":840,"answers_community":["C (50%)","B (50%)"],"question_images":[],"timestamp":"2020-11-01 22:58:00","url":"https://www.examtopics.com/discussions/amazon/view/35668-exam-aws-sysops-topic-1-question-859-discussion/","question_text":"A SysOps Administrator is maintaining an application running on Amazon EBS-backed Amazon EC2 instances in an Amazon EC2 Auto Scaling group. The application is set to automatically terminate unhealthy instances. The Administrator wants to preserve application logs from these instances for future analysis.\nWhich action will accomplish this?","exam_id":36}],"exam":{"numberOfQuestions":928,"lastUpdated":"11 Apr 2025","provider":"Amazon","isMCOnly":false,"isImplemented":true,"name":"AWS-SysOps","id":36,"isBeta":false},"currentPage":168},"__N_SSP":true}