{"pageProps":{"questions":[{"id":"6i0CpP1jU1KI58CPVBQA","discussion":[{"timestamp":"1664492940.0","upvote_count":"6","comment_id":"350742","comments":[{"poster":"random_007","upvote_count":"1","comment_id":"412664","timestamp":"1664723340.0","content":"@binhdt2611 as per shared link it support Windows Server 2012 or later. May it get updated. Thanks"}],"content":"Answer is B\nConfiguring the CloudWatch Agent for procstat plugin can collect metrics from individual processes. It is supported on Linux servers and on servers running Windows Server 2008 R2 or later.\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-procstat-process-metrics.html","poster":"binhdt2611"},{"content":"Selected Answer: B\nThe procstat plugin is part of the Amazon CloudWatch agent, which can be installed on the EC2 Linux instance. This plugin is specifically designed to monitor individual processes and collect CPU and memory metrics for those processes. By configuring the procstat plugin, you can easily monitor CPU utilization for running processes on the instance.","timestamp":"1722228060.0","comment_id":"966093","poster":"albert_kuo","upvote_count":"1"},{"timestamp":"1665757140.0","comment_id":"412665","poster":"random_007","content":"Answer B","upvote_count":"1"}],"exam_id":36,"answer_ET":"B","question_id":856,"answer":"B","question_text":"A company has a web application that is experiencing performance problems many times each night. A root cause analysis reveals spikes in CPU utilization that last 5 minutes on an Amazon EC2 Linux instance. A SysOps administrator is tasked with finding the process ID (PID) of the service or process that is consuming more CPU.\nHow can the administrator accomplish this with the LEAST amount of effort?","choices":{"A":"Configure an AWS Lambda function in Python 3.7 to run every minute to capture the PID and send a notification.","D":"Use the default Amazon CloudWatch CPU utilization metric to capture the PID in the CloudWatch dashboard.","B":"Configure the procstat plugin to collect and send CPU metrics for the running processes.","C":"Log in to the EC2 Linux instance using a .pem key each night and then run the top command."},"question_images":[],"answer_description":"Reference:\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-procstat-process-metrics.html","timestamp":"2021-05-06 07:50:00","answers_community":["B (100%)"],"topic":"1","isMC":true,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/51948-exam-aws-sysops-topic-1-question-873-discussion/","unix_timestamp":1620280200},{"id":"s0JVyX22gKhvaZSyiWnS","topic":"1","question_text":"A company is using an Amazon ElastiCache for Redis cluster in a production environment. To align with the company's technical requirements, a SysOps administrator needs to select a deployment to provide increased availability and fault tolerance.\nWhich action should the SysOps administrator take to accomplish this goal?","answer_images":[],"answer_description":"Reference:\nhttps://aws.amazon.com/elasticache/redis/faqs/","answer":"D","unix_timestamp":1620280080,"question_images":[],"discussion":[{"comments":[{"content":"• Multi AZ with Auto-Failover\n• Read Replicas to scale reads and have high availability\n• Data Durability using AOF persistence\n• Backup and restore features\n• Supports Sets and Sorted Sets","timestamp":"1725322740.0","poster":"albert_kuo","upvote_count":"1","comment_id":"997206"}],"timestamp":"1722228360.0","comment_id":"966096","poster":"albert_kuo","content":"Selected Answer: D\nMulti-AZ (Availability Zone) with automatic failover is a feature in Amazon ElastiCache for Redis that provides enhanced fault tolerance. When Multi-AZ is enabled, ElastiCache automatically creates replicas of the primary node in different Availability Zones. In case the primary node becomes unavailable due to a hardware failure, network issue, or other reasons, ElastiCache will automatically promote one of the replicas to be the new primary, ensuring minimal downtime.","upvote_count":"1"},{"timestamp":"1667787600.0","comment_id":"369509","content":"D is the answer","upvote_count":"2","poster":"RicardoD"},{"content":"Answer D:\nCheck FAQ in this link\n\nQ: Can I have replicas in the same Availability Zone as the primary?\nYes. Note that placing both the primary and the replica(s) in the same Availability Zone will not make your Amazon ElastiCache for Redis replication group resilient to an Availability Zone disruption. Additionally this well not be allowed if Multi-AZ is turned on.\n\nhttps://aws.amazon.com/elasticache/faqs/#Redis\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html","upvote_count":"3","comment_id":"350740","poster":"binhdt2611","timestamp":"1664209860.0"}],"answer_ET":"D","timestamp":"2021-05-06 07:48:00","url":"https://www.examtopics.com/discussions/amazon/view/51947-exam-aws-sysops-topic-1-question-874-discussion/","answers_community":["D (100%)"],"choices":{"D":"Verify that Multi-AZ with automatic failover is enabled. Place replicas in multiple Availability Zones.","A":"Deploy the ElastiCache cluster with Memcached as the engine.","C":"Verify that cluster mode is disabled. Increase the number of shards.","B":"Deploy the Redis cluster within an Auto Scaling group to launch replicas across multiple Availability Zones."},"exam_id":36,"isMC":true,"question_id":857},{"id":"xSEWn0TCt3YRykiRTcRC","timestamp":"2021-05-06 07:54:00","question_id":858,"isMC":true,"answer":"A","answer_images":[],"question_text":"The chief financial officer (CFO) of an organization has seen a spike in Amazon S3 storage costs over the last few months. A SysOps administrator suspects that these costs are related to storage for older versions of S3 objects from one of its S3 buckets.\nWhat can the administrator do to confirm this suspicion?","answers_community":["A (100%)"],"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/51949-exam-aws-sysops-topic-1-question-875-discussion/","topic":"1","question_images":[],"unix_timestamp":1620280440,"exam_id":36,"answer_description":"","discussion":[{"timestamp":"1722228540.0","upvote_count":"1","comment_id":"966097","poster":"albert_kuo","content":"Selected Answer: A\nAmazon S3 inventory provides a scheduled report of the objects and their corresponding metadata for a bucket. By enabling Amazon S3 inventory for the specific S3 bucket in question, the administrator can collect comprehensive information about the objects stored in the bucket, including information about older versions of objects.\n\nOnce the inventory is generated, the administrator can query the inventory data to identify the total storage consumed by previous versions of objects. This will help identify if storage costs are indeed being driven by older versions of objects that are consuming space."},{"content":"Selected Answer: A\nA is the answer","timestamp":"1707330180.0","comment_id":"801260","poster":"gulu73","upvote_count":"1"},{"comment_id":"388548","upvote_count":"2","timestamp":"1667122080.0","poster":"gingerbytes","content":"A\nS3 Inventory also provides you with more information about your objects than you would get by LIST operation—things like delete markers, replication status, and multipart upload flags are shown. These reports can be sent to another bucket, or even to another AWS account if defined by a specific workflow. On top of everything, using S3 Inventory provides you with some cost savings, by being 50% cheaper to use compared to using multiple LIST operations."},{"content":"A is the answer","poster":"RicardoD","comment_id":"369510","upvote_count":"1","timestamp":"1665749760.0"},{"poster":"binhdt2611","content":"I think A\n\nAmazon S3 inventory helps you manage your storage by creating lists of the objects in an S3 bucket on a defined schedule. You can configure multiple inventory lists for a bucket. The inventory lists are published to CSV, ORC, or Parquet files in a destination bucket.\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/configure-inventory.html","comment_id":"350751","timestamp":"1664875560.0","upvote_count":"2"}],"choices":{"B":"Use object-level cost allocation tags to identify the total storage of previous object versions.","C":"Enable the Amazon S3 analytics feature for the bucket to identify the total storage of previous object versions.","A":"Enable Amazon S3 inventory and then query the inventory to identify the total storage of previous object versions.","D":"Use Amazon CloudWatch storage metrics for the S3 bucket to identify the total storage of previous object versions."}},{"id":"jfX1n2qTHrxiTHgyVaAW","choices":{"D":"Use the AWS Systems Manager Run Command to update the corporate DNS IP address on all the EC2 instances.","A":"Develop an AWS Lambda function to update the corporate DNS IP address on all the EC2 instances.","B":"Run a shell script to update the corporate DNS IP address on each EC2 instance.","C":"Update the Amazon Machine Images (AMIs) of the EC2 instances to configure the updated corporate DNS IP address."},"topic":"1","timestamp":"2021-05-06 07:55:00","question_text":"A company manages more than 1,000 Amazon EC2 instances running Amazon Linux 2 in multiple VPCs. A SysOps administrator must change the statically configured DNS server IP address on all the EC2 instances.\nWhich solution will require the LEAST amount of effort?","discussion":[{"upvote_count":"3","content":"D is the answer","poster":"RicardoD","timestamp":"1730595420.0","comment_id":"369513"},{"poster":"binhdt2611","upvote_count":"3","content":"Answer is D","timestamp":"1728961200.0","comment_id":"350753"}],"unix_timestamp":1620280500,"exam_id":36,"isMC":true,"answer_description":"","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/51950-exam-aws-sysops-topic-1-question-876-discussion/","answers_community":[],"answer_images":[],"answer":"D","answer_ET":"D","question_id":859},{"id":"i76XZCsO4uvl0BcnmHM2","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/51951-exam-aws-sysops-topic-1-question-877-discussion/","timestamp":"2021-05-06 07:58:00","answers_community":[],"answer_images":[],"question_id":860,"question_text":"A company wants to reduce costs on jobs that can be completed at any time. The jobs are currently run using multiple On-Demand Instances, and the jobs take just under 2 hours to complete. If a job fails for any reason, it can be restarted from the beginning.\nWhich method is the MOST cost-effective based on these requirements?","choices":{"D":"Use a mixture of On-Demand and Spot Instances for job execution.","A":"Purchase Reserved Instances to be used for job execution.","B":"Submit a request for a one-time Spot Instance for job execution.","C":"Submit a request for a Spot block to be used for job execution."},"discussion":[{"content":"it'is outdated. Spot Instances with a defined duration (also known as Spot blocks) are no longer available to new customers as of July 1, 2021.\nhttps://aws.amazon.com/fr/blogs/aws/new-ec2-spot-blocks-for-defined-duration-workloads/","poster":"Gorille69","comment_id":"647633","timestamp":"1723809540.0","upvote_count":"1"},{"upvote_count":"1","content":"You simply submit a Spot instance request and use the new BlockDuration parameter to specify the number of hours your want your instance(s) to run, along with the maximum price that you are willing to pay. When Spot instance capacity is available for the the requested duration, your instances will launch and run continuously for a flat hourly price. They will be terminated automatically at the end of the time block (you can also terminate them manually). This model is a good for situations where you have jobs that need to run continuously for up to 6 hours.\n\n\nhttps://aws.amazon.com/blogs/aws/new-ec2-spot-blocks-for-defined-duration-workloads/","timestamp":"1718514480.0","comment_id":"617093","poster":"waterzhong"},{"upvote_count":"3","content":"Spot Instance is the MOST cost-effective since it doesn't matter if the job is stopped, it can be started again from the beginning and Spot Instances are much cheaper than specifying a defined spot block duration.","comment_id":"396949","poster":"lin","timestamp":"1699291740.0"},{"content":"C is the answer","timestamp":"1696818840.0","comment_id":"369514","poster":"RicardoD","upvote_count":"1"},{"poster":"binhdt2611","content":"Answer is C - use Spot block is cost-effective\n\nIn order to make EC2 an even better fit for this type of defined-duration workload, you can now launch Spot instances that will run continuously for a finite duration (1 to 6 hours). Pricing is based on the requested duration and the available capacity, and is typically 30% to 45% less than On-Demand, with an additional 5% off during non-peak hours for the region. Spot blocks and Spot instances are priced separately; you can view the current Spot pricing to learn more.\n\nhttps://aws.amazon.com/blogs/aws/new-ec2-spot-blocks-for-defined-duration-workloads/","comment_id":"350755","upvote_count":"3","timestamp":"1695226620.0"}],"answer_description":"","topic":"1","answer":"C","exam_id":36,"unix_timestamp":1620280680,"answer_ET":"C","question_images":[]}],"exam":{"isImplemented":true,"numberOfQuestions":928,"name":"AWS-SysOps","provider":"Amazon","isMCOnly":false,"lastUpdated":"11 Apr 2025","id":36,"isBeta":false},"currentPage":172},"__N_SSP":true}