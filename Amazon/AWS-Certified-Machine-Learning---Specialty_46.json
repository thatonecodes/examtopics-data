{"pageProps":{"questions":[{"id":"y60hQUNqIY9Gt74th5AN","topic":"1","exam_id":26,"answer":"CD","answer_description":"","question_id":226,"answer_images":[],"question_text":"A machine learning (ML) specialist is using the Amazon SageMaker DeepAR forecasting algorithm to train a model on CPU-based Amazon EC2 On-Demand instances. The model currently takes multiple hours to train. The ML specialist wants to decrease the training time of the model.\n\nWhich approaches will meet this requirement? (Choose two.)","discussion":[{"upvote_count":"2","poster":"Peter_Hsieh","content":"Selected Answer: CD\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html","timestamp":"1730454180.0","comment_id":"1204930"},{"poster":"ggrodskiy","upvote_count":"1","comment_id":"1203186","content":"CD\nGiven the specific context of training a DeepAR forecasting model and the potential cost implications, the options B and D are generally more applicable and cost-effective approaches to decreasing training time. However, if cost is not a concern and the DeepAR algorithm can benefit significantly from GPU acceleration, then option C could be a valid approach as well.","timestamp":"1730050560.0"},{"upvote_count":"2","comment_id":"1160606","timestamp":"1724756400.0","poster":"Adzz","content":"Selected Answer: CD\nC and D"},{"content":"Selected Answer: CD\nCD is correct answer","comment_id":"1158194","poster":"akdavsan","upvote_count":"2","timestamp":"1724532240.0"},{"content":"Selected Answer: CD\nThe best approaches to decrease the training time of the model are C and D, because they can\nimprove the computational efficiency and parallelization of the training process. These approaches\nhave the following benefits:\nC: Replacing CPU-based EC2 instances with GPU-based EC2 instances can speed up the training of the\nDeepAR algorithm, as it can leverage the parallel processing power of GPUs to perform matrix\noperations and gradient computations faster than CPUs12. The DeepAR algorithm supports GPU\u0002based EC2 instances such as ml.p2 and ml.p33.\nD: Using multiple training instances can also reduce the training time of the DeepAR algorithm, as it\ncan distribute the workload across multiple nodes and perform data parallelism4. The DeepAR\nalgorithm supports distributed training with multiple CPU-based or GPU-based EC2 instances3.\nThe other options are not effective or relevant, because they have the following drawbacks:","timestamp":"1723025760.0","poster":"kyuhuck","comment_id":"1143309","upvote_count":"3"}],"question_images":[],"isMC":true,"timestamp":"2024-02-07 13:16:00","url":"https://www.examtopics.com/discussions/amazon/view/133266-exam-aws-certified-machine-learning-specialty-topic-1/","unix_timestamp":1707308160,"choices":{"D":"Use multiple training instances.","E":"Use a pre-trained version of the model. Run incremental training.","B":"Configure model auto scaling dynamically to adjust the number of instances automatically.","A":"Replace On-Demand Instances with Spot Instances.","C":"Replace CPU-based EC2 instances with GPU-based EC2 instances."},"answer_ET":"CD","answers_community":["CD (100%)"]},{"id":"ewfC0iOhyAzGlOlZLxgE","answer":"B","isMC":true,"topic":"1","answer_images":[],"discussion":[{"upvote_count":"1","poster":"Babaaaaa","comment_id":"1228247","timestamp":"1733899980.0","content":"Selected Answer: B\nIt is B"},{"poster":"Alice1234","comment_id":"1145879","upvote_count":"4","content":"To maximize the probability of detecting an abnormality, the focus should be on high recall (the ability of the model to find all actual positives), especially in scenarios where missing an abnormality could have significant negative effects. Between the given options:\n\nB. Precision = 0.61 - Recall = 0.98\n\nThis option has the highest recall, meaning it is best at identifying actual abnormalities (label 1), which is crucial for minimizing the risk of undetected process abnormalities. Although precision is lower (indicating more false positives), in this context, ensuring abnormalities are detected (even at the cost of investigating more false alarms) is more critical.","timestamp":"1723244580.0"},{"upvote_count":"2","poster":"delfoxete","content":"Selected Answer: B\nif abnormality is not detected then higher cost. Therefore FN (false negatives) should be minimized. Which means recall should have the highest value","timestamp":"1722963660.0","comment_id":"1142498"}],"url":"https://www.examtopics.com/discussions/amazon/view/133089-exam-aws-certified-machine-learning-specialty-topic-1/","choices":{"B":"Precision = 0.61 -\nRecall = 0.98","D":"Precision = 0.98 -\nRecall = 0.8","A":"Precision = 0.91 -\nRecall = 0.6","C":"Precision = 0.7 -\nRecall = 0.9"},"answers_community":["B (100%)"],"answer_ET":"B","timestamp":"2024-02-06 20:01:00","unix_timestamp":1707246060,"question_id":227,"exam_id":26,"answer_description":"","question_images":[],"question_text":"A chemical company has developed several machine learning (ML) solutions to identify chemical process abnormalities. The time series values of independent variables and the labels are available for the past 2 years and are sufficient to accurately model the problem.\n\nThe regular operation label is marked as 0 The abnormal operation label is marked as 1. Process abnormalities have a significant negative effect on the companyâ€™s profits. The company must avoid these abnormalities.\n\nWhich metrics will indicate an ML solution that will provide the GREATEST probability of detecting an abnormality?"},{"id":"PDv9zGmVv9WBKWwe2QlH","question_images":[],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/134338-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"content":"Selected Answer: B\nMulti-model endpoints provide a scalable and cost-effective solution to deploying large numbers of models. \nhttps://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html","poster":"Peter_Hsieh","timestamp":"1730451180.0","upvote_count":"2","comment_id":"1204899"},{"comment_id":"1169122","content":"Selected Answer: B\nBy preparing a SageMaker Docker container based on the open-source multi-model server, the company can host all models in a single endpoint and dynamically select the appropriate model based on the city of each request. This approach optimizes resource utilization and avoids managing unnecessary resources, as opposed to having separate instances for each city","poster":"AIWave","timestamp":"1725825720.0","upvote_count":"1"},{"content":"Selected Answer: B\nA multi-model endpoint in Amazon SageMaker is an endpoint that can host multiple machine learning models simultaneously. This allows you to deploy and manage multiple models on a single endpoint, reducing operational costs and simplifying deployment and management tasks. Each model is associated with a specific container image and can be invoked using a unique model name or endpoint name. This feature is useful when you have multiple models that need to be deployed together or when you want to reduce the number of endpoints that need to be managed.","timestamp":"1724298780.0","comment_id":"1156154","poster":"rav009","upvote_count":"2"}],"question_id":228,"unix_timestamp":1708581180,"answer_ET":"B","exam_id":26,"answer_images":[],"topic":"1","answer":"B","answer_description":"","timestamp":"2024-02-22 06:53:00","question_text":"An online delivery company wants to choose the fastest courier for each delivery at the moment an order is placed. The company wants to implement this feature for existing users and new users of its application. Data scientists have trained separate models with XGBoost for this purpose, and the models are stored in Amazon S3. There is one model for each city where the company operates.\n\nOperation engineers are hosting these models in Amazon EC2 for responding to the web client requests, with one instance for each model, but the instances have only a 5% utilization in CPU and memory. The operation engineers want to avoid managing unnecessary resources.\n\nWhich solution will enable the company to achieve its goal with the LEAST operational overhead?","choices":{"A":"Create an Amazon SageMaker notebook instance for pulling all the models from Amazon S3 using the boto3 library. Remove the existing instances and use the notebook to perform a SageMaker batch transform for performing inferences offline for all the possible users in all the cities. Store the results in different files in Amazon S3. Point the web client to the files.","D":"Prepare a Docker container based on the prebuilt images in Amazon SageMaker. Replace the existing instances with separate SageMaker endpoints, one for each city where the company operates. Invoke the endpoints from the web client, specifying the URL and EndpointName parameter according to the city of each request.","B":"Prepare an Amazon SageMaker Docker container based on the open-source multi-model server. Remove the existing instances and create a multi-model endpoint in SageMaker instead, pointing to the S3 bucket containing all the models. Invoke the endpoint from the web client at runtime, specifying the TargetModel parameter according to the city of each request.","C":"Keep only a single EC2 instance for hosting all the models. Install a model server in the instance and load each model by pulling it from Amazon S3. Integrate the instance with the web client using Amazon API Gateway for responding to the requests in real time, specifying the target resource according to the city of each request."},"answers_community":["B (100%)"]},{"id":"nAAXU62N8b3Fqoe8u5sd","answer_images":[],"question_text":"A company builds computer-vision models that use deep learning for the autonomous vehicle industry. A machine learning (ML) specialist uses an Amazon EC2 instance that has a CPU:GPU ratio of 12:1 to train the models.\n\nThe ML specialist examines the instance metric logs and notices that the GPU is idle half of the time. The ML specialist must reduce training costs without increasing the duration of the training jobs.\n\nWhich solution will meet these requirements?","topic":"1","answer_description":"","answers_community":["D (67%)","B (33%)"],"isMC":true,"answer_ET":"C","exam_id":26,"unix_timestamp":1707308280,"choices":{"C":"Use memory-optimized EC2 Spot Instances for the training jobs.","A":"Switch to an instance type that has only CPUs.","B":"Use a heterogeneous cluster that has two different instances groups.","D":"Switch to an instance type that has a CPU:GPU ratio of 6:1."},"url":"https://www.examtopics.com/discussions/amazon/view/133268-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"content":"Selected Answer: B\nhttps://aws.amazon.com/it/blogs/machine-learning/improve-price-performance-of-your-model-training-using-amazon-sagemaker-heterogeneous-clusters/","comment_id":"1411293","timestamp":"1743165660.0","upvote_count":"1","poster":"ef12052"},{"timestamp":"1716779100.0","comment_id":"1219289","poster":"rav009","content":"The topic is wierd.\nGPU is idle, which means CPU is not able to feed data to GPU in time, which means more CPU is needed.\nThe current ratio is 12:1, and you need to increase the ratio. D is wrong because 6:1 is smaller than 12:1","upvote_count":"2"},{"comment_id":"1169133","poster":"AIWave","upvote_count":"1","timestamp":"1709936400.0","content":"Selected Answer: D\nA: No - removing GPU could significantly increase training time\nB: No - doesn't solve the issue of GPU under utilization\nC: No - doesn't solve the issue of GPU under utilization and may take longer\nD: Yes - Reducing CPU's should solve the issue of GPU underutilization withour causing training delays"},{"timestamp":"1707527340.0","comment_id":"1145880","content":"ChatGPT\nD. Switch to an instance type that has a CPU:GPU ratio of 6:1. This solution aligns with reducing training costs without extending the duration of training jobs. By selecting an instance with a lower CPU:GPU ratio, the specialist can ensure more consistent utilization of the GPU, thereby reducing idle time and optimizing resource use without compromising training efficiency.","upvote_count":"1","poster":"Alice1234","comments":[{"comments":[{"upvote_count":"1","content":"yes, GPT4o says the option D is the right answer","comment_id":"1262235","poster":"Jordarlu","timestamp":"1723065480.0"}],"content":"Is it from GPT 4? Because I got option B from it.","comment_id":"1160610","upvote_count":"1","poster":"Adzz","timestamp":"1709039160.0"}]},{"content":"Selected Answer: D\nSwitching to an instance type that has a CPU: GPU ratio of 6:1 will reduce the training costs by using\nfewer CPUs and GPUs, while maintaining the same level of performance. The GPU idle time indicates\nthat the CPU is not able to feed the GPU with enough data, so reducing the CPU: GPU ratio will\nIT Certification Guaranteed, The Easy Way!\n167\nbalance the workload and improve the GPU utilization. A lower CPU: GPU ratio also means less\noverhead for inter-process communication and synchronization between the CPU and GPU\nprocesses. References:\nOptimizing GPU utilization for AI/ML workloads on Amazon EC2\nAnalyze CPU vs. GPU Performance for AWS Machine Learning","timestamp":"1707308280.0","upvote_count":"1","poster":"kyuhuck","comment_id":"1143313"}],"answer":"D","question_id":229,"timestamp":"2024-02-07 13:18:00","question_images":[]},{"id":"rpqyulFgBsPpIB6tpigN","answer_ET":"C","answers_community":["C (63%)","B (38%)"],"choices":{"D":"Use Amazon SageMaker Studio Notebook with Pandas.","C":"Use Amazon SageMaker Studio Data Wrangler.","B":"Use AWS Glue DataBrew.","A":"Use Amazon EMR Serverless with PySpark."},"topic":"1","answer_images":[],"question_id":230,"question_text":"A company wants to forecast the daily price of newly launched products based on 3 years of data for older product prices, sales, and rebates. The time-series data has irregular timestamps and is missing some values.\n\nData scientist must build a dataset to replace the missing values. The data scientist needs a solution that resamples the data daily and exports the data for further modeling.\n\nWhich solution will meet these requirements with the LEAST implementation effort?","url":"https://www.examtopics.com/discussions/amazon/view/133269-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"content":"Selected Answer: B\nThere is a need for scheduling daily resampling. This can be automated in Databrew more easily than in Data Wrangler.","comment_id":"1401637","poster":"Togy","upvote_count":"1","timestamp":"1742575680.0"},{"comments":[{"upvote_count":"1","timestamp":"1730579880.0","poster":"spinatram","comment_id":"1306320","content":"C is the right one I think. For B, you should to feed this data to sagemaker which brings more operational effort than Data Wrangler"}],"comment_id":"1271316","timestamp":"1724419980.0","content":"Selected Answer: B\nWhile SageMaker Data Wrangler (option C) is also a strong contender, DataBrew is slightly easier to use and requires even less implementation effort, especially for users who may not be as familiar with the SageMaker ecosystem.","upvote_count":"2","poster":"GS_77"},{"upvote_count":"1","poster":"vkbajoria","timestamp":"1711140600.0","content":"Selected Answer: C\nData Wrangler is better for ML work. Brew can be used as well","comment_id":"1180315"},{"timestamp":"1709938140.0","comment_id":"1169140","poster":"AIWave","content":"Selected Answer: C\nData wrangler supports tight integration with Sagemaker and is better suited for this scenario since resampled data is used in further modelling.\nAWS Glue DataBrew is a data preparation service more for general purpose use.","upvote_count":"1"},{"comment_id":"1160615","upvote_count":"1","timestamp":"1709039220.0","poster":"Adzz","content":"Selected Answer: C\nBest for Data Wrangler"},{"comment_id":"1158226","poster":"akdavsan","content":"Selected Answer: C\nThis is exactly what Data Wrangler is for","upvote_count":"1","timestamp":"1708819200.0"},{"poster":"kyuhuck","comment_id":"1143315","timestamp":"1707308460.0","content":"Selected Answer: C\nAnswer: C\nExplanation:\nAmazon SageMaker Studio Data Wrangler is a visual data preparation tool that enables users to clean\nand normalize data without writing any code. Using Data Wrangler, the data scientist can easily\nimport the time-series data from various sources, such as Amazon S3, Amazon Athena, or Amazon\nRedshift. Data Wrangler can automatically generate data insights and quality reports, which can help\nidentify and fix missing values, outliers, and anomalies in the data. Data Wrangler also provides over\n250 built-in transformations, such as resampling, interpolation, aggregation, and filtering, which can\nbe applied to the data with a point-and-click interface. Data Wrangler can also export the prepared\ndata to different destinations, such as Amazon S3, Amazon SageMaker Feature Store, or Amazon\nSageMaker Pipelines, for further modeling and analysis. D","upvote_count":"1"}],"timestamp":"2024-02-07 13:21:00","answer_description":"","exam_id":26,"question_images":[],"unix_timestamp":1707308460,"answer":"C","isMC":true}],"exam":{"lastUpdated":"11 Apr 2025","isImplemented":true,"numberOfQuestions":369,"provider":"Amazon","name":"AWS Certified Machine Learning - Specialty","id":26,"isBeta":false,"isMCOnly":false},"currentPage":46},"__N_SSP":true}