{"pageProps":{"questions":[{"id":"clICmCIR2wAzhg1JpKoX","choices":{"C":"Enable AWS CloudTrail and configure it to stream to an Amazon CloudWatch Logs group. Create a metric filter in CloudWatch to match when the ec2:RunInstances action occurs, and trigger the Lambda function when the metric is greater than 0.","D":"Create an Amazon CloudWatch Events rule that matches each time an EC2 instance is launched, and associate it with the Lambda function as the target.","A":"Create an Amazon CloudWatch Events rule that matches each time an EC2 instance is launched using one of the allowed AMIs, and associate it with the Lambda function as the target.","B":"For the Amazon S3 bucket receiving the AWS CloudTrail logs, create an S3 event notification configuration with a filter to match when logs contain the ec2:RunInstances action, and associate it with the Lambda function as the target."},"answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/5428-exam-aws-certified-solutions-architect-professional-topic-1/","answer_description":"","answer":"D","topic":"1","discussion":[{"comments":[{"poster":"PacoDerek","upvote_count":"2","content":"S3 event notification do have filter function\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html\nYou can configure notifications to be filtered by the prefix and suffix of the key name of objects","timestamp":"1632621540.0","comments":[{"timestamp":"1633143060.0","content":"However, that's not the kind of filter required. You would need to be able to filter based on the content of an object, not on the name of the object. S3 event notification can only filter on name of object.","comment_id":"51890","poster":"sb333","upvote_count":"6"}],"comment_id":"43144"}],"content":"D\nA: This covers the harden AMI but not non-compliant ones. We want to execute the termination when the non-compliant ones launches.\nB: S3 event notification has no filter.\nC: Too tedious","comment_id":"11754","upvote_count":"36","timestamp":"1632159180.0","poster":"donathon"},{"content":"a: cloudwatch cannot validate \"allowed AMIs\"\nb: cloudtrail logs do not have a unique identifier for s3 event filters to trigger off of - https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-examples.html\nc: cloudwatch logs group - metric filter can only trigger SNS (an additional step not mentioned, before triggering lambda)\nd: cloudwatch events rule can trigger off of \"pending\" (as mentioned by others) and can target a lambda function directly","poster":"sarah1","upvote_count":"11","comment_id":"43979","timestamp":"1632744300.0"},{"upvote_count":"1","poster":"SkyZeroZx","comment_id":"930726","content":"Selected Answer: D\nD\nA: This covers the harden AMI but not non-compliant ones. We want to execute the termination when the non-compliant ones launches.\nB: S3 event notification has no filter.\nC: Too tedious","timestamp":"1687446660.0"},{"content":"D for sure","poster":"AzureDP900","comment_id":"508078","upvote_count":"2","timestamp":"1640282100.0"},{"upvote_count":"3","timestamp":"1636056000.0","content":"I'll go with D","comment_id":"410501","poster":"WhyIronMan"},{"comment_id":"346164","timestamp":"1636039200.0","upvote_count":"3","content":"it's D","poster":"Waiweng"},{"poster":"Amitv2706","upvote_count":"1","comment_id":"335633","timestamp":"1635965880.0","content":"For those who are voting for C : \nCan CW metric filter directly trigger lambda ?\n\nAnswer is D."},{"comment_id":"291454","content":"going with D","poster":"Kian1","timestamp":"1635810540.0","upvote_count":"2"},{"poster":"Ebi","upvote_count":"5","timestamp":"1635598200.0","comment_id":"280353","content":"D is the answer"},{"comment_id":"251791","timestamp":"1635543720.0","content":"correct answer is D.","poster":"Bulti","upvote_count":"2"},{"comment_id":"243423","timestamp":"1635528900.0","upvote_count":"1","content":"Correct answer is D. CloudWatch and Lambda for all instances","poster":"T14102020"},{"upvote_count":"3","poster":"jackdryan","content":"I'll go with D","timestamp":"1635447240.0","comment_id":"230812"},{"content":"seems D","upvote_count":"1","poster":"gookseang","comment_id":"230070","timestamp":"1635439920.0"},{"comment_id":"230067","poster":"gookseang","content":"seems D","upvote_count":"1","timestamp":"1635364260.0"},{"poster":"sam422","comment_id":"188035","content":"I go with D after reading this document https://d1.awsstatic.com/whitepapers/aws-building-ami-factory-process-using-ec2-ssm-marketplace-and-service-catalog.pdf","timestamp":"1635312660.0","upvote_count":"1"},{"content":"I go with D after reading this document https://d1.awsstatic.com/whitepapers/aws-building-ami-factory-process-using-ec2-ssm-marketplace-and-service-catalog.pdf","upvote_count":"1","timestamp":"1635283380.0","poster":"sam422","comment_id":"188032"},{"comment_id":"151670","timestamp":"1635032880.0","poster":"fullaws","upvote_count":"2","content":"D is correct"},{"upvote_count":"6","content":"Answer: C\nA - incorrect - need to trigger when any EC2 instance is launched\nB - incorrect - does not inspect the logs, thus can't filter on appropriate events such as starting of an instance. Instead send S3 to CloudWatch and use an Event Rule\nC - incorrect - should work but akin to using a sledgehammer to crack a nut. Also it should have mentioned CloudWatch Alarm to trigger SNS then Lambda, however what details of the instance are being passed to Lambda from CloudWatch? the notification includes the \"metric\", its value, time, etc - not the AMI, EC2 Instance ID, subnet, etc. Or should have said use Cloudwatch Event Rules, like the next answer does.\nD - correct - takes 2 minutes to configure via the console - Event Rule <- [ [ EC2 Events <- \"AWS API Call via CloudTrail\" <- RunInstances] -> Lambda]. Nothing stopping us using RunInstances as the trigger. Remember CloudTrail is enabled by default and \"AWS API Call via CloudTrail\" is an AWS managed event source - simple","poster":"inf","comment_id":"136071","comments":[{"poster":"Phat","upvote_count":"3","timestamp":"1635129600.0","content":"I think you mean D","comment_id":"173469"},{"content":"good good","timestamp":"1658623320.0","poster":"hilft","comment_id":"635821","upvote_count":"1"}],"timestamp":"1634963580.0"},{"upvote_count":"1","content":"D for sure","poster":"NikkyDicky","comment_id":"133107","timestamp":"1634799180.0"},{"content":"It has to be D, cloud watch is much faster and we want instantaneous notifications. CloudTrail events would send notification in 15 mins or so vs Cloud watch which should be in 1-2 mins.","poster":"oatif","timestamp":"1634427060.0","upvote_count":"1","comment_id":"130184"},{"comments":[{"comment_id":"124426","poster":"chicagomassageseeker","upvote_count":"1","content":"I meant D. Not C.","timestamp":"1634400600.0"}],"timestamp":"1634327280.0","comment_id":"124425","content":"Answer C \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/automating_with_cloudwatch_events.html","upvote_count":"2","poster":"chicagomassageseeker"},{"comment_id":"121483","upvote_count":"1","content":"Correct Answer is D","poster":"cloud4gr8","timestamp":"1634211540.0"},{"comment_id":"107679","poster":"Wira","upvote_count":"2","timestamp":"1634065260.0","content":"C\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudwatch-alarms-for-cloudtrail.html#cloudwatch-alarms-for-cloudtrail-ec2-large-instance-changes"},{"timestamp":"1633991400.0","poster":"meenu2225","comment_id":"103589","upvote_count":"3","content":"Guys according to me its C,\nThere is no such event that tracks and captures a launch of EC2 instance. You can track State chnage events but that would not be accurate as it will launch Lambda everytime state of EC2 chnages. You can send CloudTrail events to CloudWatch and trigger a lambda.\nThus, Option C."},{"comment_id":"94871","poster":"FreeSwan","upvote_count":"1","content":"D is correct","timestamp":"1633891500.0"},{"content":"Mapping is stored in dynamoDB. Only program can access the mapping. So D","comment_id":"76599","upvote_count":"2","timestamp":"1633560060.0","poster":"Joeylee"},{"comments":[{"timestamp":"1633653480.0","upvote_count":"2","comment_id":"77013","content":"Correction to previous comment. CloudTrail is real-time but its delivery to S3 is not. Actually, CW Events is based on CT.","poster":"Smart"},{"content":"agree: \nhttps://aws.amazon.com/cloudtrail/faqs/","comment_id":"77596","poster":"juanC1917","upvote_count":"2","timestamp":"1633710240.0"}],"comment_id":"70880","timestamp":"1633301100.0","poster":"Smart","upvote_count":"4","content":"Anything related to CloudTrail Logs is not valid as CloudTrail is not real-time. Additionally, CloudTrail typically delivers log files within 15 minutes of account activity. In addition, CloudTrail publishes log files multiple times an hour, about every five minutes."},{"upvote_count":"3","timestamp":"1632973260.0","content":"Should be D\n\"quickly mitigate the risk\"","comment_id":"51275","poster":"amog"},{"comments":[{"comment_id":"32591","comments":[{"comments":[{"poster":"n1ch0las","content":"but it has to get launched and into Pending before it can ever go to stopped and then restarted. so if the lambda is fired off it will never allow the unapproved AMI to ever get to the point to where it can be stopped and restarted.","upvote_count":"1","comments":[{"timestamp":"1633452360.0","content":"Agreed. When a stopped instance is started again, it will trigger lambda function again. Additional cost - big deal?","poster":"Smart","comment_id":"70881","upvote_count":"1"}],"comment_id":"61299","timestamp":"1633281420.0"}],"upvote_count":"1","comment_id":"32592","timestamp":"1632571560.0","poster":"cinopi","content":"REF: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html (have a close look on PENDING state)"}],"timestamp":"1632427080.0","content":"Pending => EITHER instance is newly launched OR existing instance is started which was previously stopped.\n\nHence, we can't determine by looking over PENDING state that instance is newly launched.","poster":"cinopi","upvote_count":"1"}],"timestamp":"1632282900.0","comment_id":"31074","upvote_count":"1","poster":"JayK","content":"D\nThere is an event \n\"EC2 Instance state-change Notification\" and you can specify the state as \"Pending\" , as this is the state am instance enters in to while launching."},{"poster":"cinopi","content":"Should be C\n\nReason for not opting D: \nThere is no specific event that can identify EC2 LAUNCH.\nThere is event named as 'pending' which is called after LAUNCH operation, however, it is also the state when instance is stopped and started.\n\nDetails: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html","timestamp":"1632192000.0","comment_id":"30678","upvote_count":"5","comments":[{"timestamp":"1632633720.0","upvote_count":"4","poster":"PacoDerek","content":"there is no EC2:RunInstance metric in cloudwatch. \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html#ec2-cloudwatch-dimensions","comment_id":"43157"},{"poster":"jar0d","comment_id":"211112","content":"C is OK,\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/monitor-cloudtrail-log-files-with-cloudwatch-logs.html\n\njust replace ConsoleLogin with event you want","upvote_count":"1","timestamp":"1635328200.0"}]},{"timestamp":"1632172620.0","content":"As explained by \"donathon\", answer is \"D\".","upvote_count":"3","poster":"Moon","comment_id":"13442"}],"question_id":476,"answer_images":[],"isMC":true,"timestamp":"2019-09-19 08:40:00","answers_community":["D (100%)"],"unix_timestamp":1568875200,"question_text":"A company has a requirement that only allows specially hardened AMIs to be launched into public subnets in a VPC, and for the AMIs to be associated with a specific security group. Allowing non-compliant instances to launch into the public subnet could present a significant security risk if they are allowed to operate.\nA mapping of approved AMIs to subnets to security groups exists in an Amazon DynamoDB table in the same AWS account. The company created an AWS\nLambda function that, when invoked, will terminate a given Amazon EC2 instance if the combination of AMI, subnet, and security group are not approved in the\nDynamoDB table.\nWhat should the Solutions Architect do to MOST quickly mitigate the risk of compliance deviations?","exam_id":32,"question_images":[]},{"id":"rKD2Qp2hqmMAfDubJ09P","topic":"1","question_images":[],"isMC":true,"answers_community":["B (100%)"],"exam_id":32,"answer_description":"","question_text":"A customer has a 10 GB AWS Direct Connect connection to an AWS region where they have a web application hosted on Amazon Elastic Computer Cloud (EC2).\nThe application has dependencies on an on-premises mainframe database that uses a BASE (Basic Available, Soft state, Eventual consistency) rather than an\nACID (Atomicity, Consistency, Isolation, Durability) consistency model. The application is exhibiting undesirable behavior because the database is not able to handle the volume of writes.\nHow can you reduce the load on your on-premises database resources in the most cost-effective way?","unix_timestamp":1568562480,"choices":{"D":"Provision an RDS read-replica database on AWS to handle the writes and synchronize the two databases using Data Pipeline.","C":"Modify the application to use DynamoDB to feed an EMR cluster which uses a map function to write to the on-premises database.","B":"Modify the application to write to an Amazon SQS queue and develop a worker process to flush the queue to the on-premises database.","A":"Use an Amazon Elastic Map Reduce (EMR) S3DistCp as a synchronization mechanism between the on-premises database and a Hadoop cluster on AWS."},"answer":"B","url":"https://www.examtopics.com/discussions/amazon/view/5207-exam-aws-certified-solutions-architect-professional-topic-1/","question_id":477,"answer_ET":"B","discussion":[{"content":"A is wrong - S3DistCp is used between HDFS and S3, not a database. I would go with B (SQS to flaten write request rate to DB).","comment_id":"11199","upvote_count":"20","timestamp":"1632081660.0","poster":"piotr"},{"content":"I agree...answer is B:\nhttp://jayendrapatil.com/aws-sqs-simple-queue-service/#targetText=A%20customer%20has%20a%2010,Elastic%20Computer%20Cloud%20(EC2).&targetText=The%20application%20is%20exhibiting%20undesirable,handle%20the%20volume%20of%20writes.","comments":[{"content":"Cost effective solution is another reason to go with B","poster":"manoj101","timestamp":"1633346160.0","upvote_count":"4","comment_id":"117922"}],"poster":"Moon","upvote_count":"18","comment_id":"12650","timestamp":"1632220740.0"},{"upvote_count":"1","comment_id":"1285541","timestamp":"1726625340.0","poster":"thanhpolimi","content":"Answer is B. A is totally wrong"},{"poster":"amministrazione","comment_id":"1266643","timestamp":"1723751040.0","content":"B. Modify the application to write to an Amazon SQS queue and develop a worker process to flush the queue to the on-premises database.","upvote_count":"1"},{"content":"Selected Answer: B\nB because database is some legacy and when handle intesive write operations fail then i need reduce writes SQS is a classic option .","timestamp":"1687192320.0","poster":"SkyZeroZx","upvote_count":"1","comment_id":"927685"},{"comment_id":"901974","poster":"rtguru","timestamp":"1684503540.0","upvote_count":"1","content":"because eventual consistency is required , B is best fit for the scenario"},{"timestamp":"1673014620.0","comment_id":"767786","poster":"CertNerd1234","content":"As it is explicitly stated that the on-prem database is BASE and not ACID using an SQS queue to buffer writes seems like the obvious thing to do.","upvote_count":"1"},{"comment_id":"750291","upvote_count":"1","poster":"TigerInTheCloud","content":"Selected Answer: B\nThere is no right answer. If there are peaks of high-volume writing then B makes sense. Others do not make any sense at all.","timestamp":"1671489060.0"},{"timestamp":"1660663980.0","content":"B for me. Eventual consistency = SQS","comment_id":"647731","upvote_count":"2","poster":"Ni_yot"},{"content":"Selected Answer: B\nGo with B","timestamp":"1654649220.0","poster":"kangtamo","comment_id":"612990","upvote_count":"1"},{"comment_id":"552209","timestamp":"1645385340.0","content":"C is correct. Eventual consistency implys multiple nodes. Map function writes to all nodes in parallel.","poster":"johnnsmith","upvote_count":"1"},{"content":"B Correct","comment_id":"406235","timestamp":"1636160880.0","poster":"Akhil254","upvote_count":"1"},{"poster":"01037","content":"Has to be B","comment_id":"347758","timestamp":"1635750060.0","upvote_count":"1"},{"timestamp":"1635503100.0","poster":"cldy","comment_id":"324997","content":"B.\nSQS good to absorb writes + also cost effective","upvote_count":"1"},{"poster":"MHKyaw","upvote_count":"1","content":"I go with B","comment_id":"269221","timestamp":"1634347560.0"},{"timestamp":"1634236200.0","poster":"newme","content":"Answer is B","upvote_count":"1","comment_id":"211053"},{"upvote_count":"3","poster":"fullaws","comment_id":"143876","content":"B is correct","timestamp":"1633842240.0"},{"comment_id":"131110","poster":"noisonnoiton","upvote_count":"2","content":"go with B","timestamp":"1633463700.0"},{"upvote_count":"5","content":"Yes Agree B should the answer, As we are looking for \"Cost-effective\" way for BASE DB that can bare few latencies.","comment_id":"51630","timestamp":"1632835500.0","poster":"cloudinvader"},{"content":"Answer is B","poster":"amog","upvote_count":"5","comment_id":"37906","timestamp":"1632828780.0"},{"comment_id":"17402","poster":"Warrenn","timestamp":"1632767340.0","content":"Answer is B","upvote_count":"6"},{"content":"Answer is B","comment_id":"13020","poster":"SivaG","timestamp":"1632511380.0","upvote_count":"8"}],"answer_images":[],"timestamp":"2019-09-15 17:48:00"},{"id":"09Jed9CvseMpAAWxe5Hw","answer_images":[],"timestamp":"2019-09-16 13:02:00","answer_description":"","discussion":[{"timestamp":"1632544560.0","comments":[{"timestamp":"1635583500.0","poster":"DashL","comment_id":"401353","content":"Agree with Ans C.\nBut all the reasons provided here doesn't sound right.\nThe key part of the question is: \"Which is the FASTEST and MOST cost-effective way to perform the migration?\"\nA: First of all, you cannot convert a physical server to a virtual server. You have to create a new VM and migrate the applications and data. Because the question did not state what is the bandwidth, it is difficult to calculate how long it will take to transfer data.\nB: Reasons same as A plus it will take significant amount of time to provision DX\nC: Seems to be the most reasonable solution.\nD: SMS cannot migrate a physical server. On top of that Because the question did not state what is the bandwidth, it is difficult to calculate how long it will take to transfer data.","upvote_count":"4"}],"poster":"donathon","content":"C\nA: This will be too slow.\nB: Direct connect takes too long to provision.\nC: Because the question did not state what is the bandwidth of the company, using Snowball to transfer 70TB make sense.\nD: While this is possible, we do not know If the server is physical or virtual and SMS just migrate it does not upgrade. Wherelse in C you can immediately select the best AMI to start and rely on Snowball to transfer the data.","upvote_count":"36","comment_id":"11756"},{"timestamp":"1632792600.0","poster":"Moon","content":"I do support answer \"C\".\nThe snowball is the FASTEST option for transfer (next business day for delivery).","upvote_count":"8","comments":[{"comment_id":"333526","timestamp":"1635263280.0","content":"Migration via Snowball takes about a week.","poster":"sarah_t","upvote_count":"1"}],"comment_id":"13440"},{"upvote_count":"1","content":"Selected Answer: C\nC\nA: This will be too slow.\nB: Direct connect takes too long to provision.\nC: Because the question did not state what is the bandwidth of the company, using Snowball to transfer 70TB make sense.\nD: While this is possible, we do not know If the server is physical or virtual and SMS just migrate it does not upgrade. Wherelse in C you can immediately select the best AMI to start and rely on Snowball to transfer the data.","timestamp":"1687447200.0","poster":"SkyZeroZx","comment_id":"930733"},{"timestamp":"1665586500.0","poster":"joanneli77","upvote_count":"2","content":"Without knowing local bandwidth, you can't determine whether snowball is faster or not. The problem is with the question. 70TB may take a long time to transfer, but it may not.","comment_id":"693183"},{"timestamp":"1663389300.0","content":"Selected Answer: C\nc is the most feasible answer here","comment_id":"671248","upvote_count":"1","poster":"Dionenonly"},{"poster":"jj22222","content":"C looks right","comment_id":"534244","upvote_count":"1","timestamp":"1643332500.0"},{"poster":"cldy","upvote_count":"1","timestamp":"1639211940.0","comment_id":"499207","content":"C. Re-platform the server to Amazon EC2, and use AWS Snowball to transfer the static data to Amazon S3."},{"comment_id":"491510","upvote_count":"1","poster":"AzureDP900","content":"Internet speed is not provided, direct connect is expensive. So my answer is C.","timestamp":"1638352920.0"},{"content":"C it is a easy one hope I can have it in my exam","timestamp":"1638231420.0","upvote_count":"1","comment_id":"490284","poster":"acloudguru"},{"upvote_count":"1","poster":"kirrim","comment_id":"459665","content":"Don't see this one mentioned, so just calling it out... another reason D is invalid is because it's storing the static file data in EBS, not in S3.","timestamp":"1635993900.0"},{"timestamp":"1635622020.0","poster":"WhyIronMan","comment_id":"410502","content":"I'll go with C","upvote_count":"1"},{"content":"it's C","comment_id":"346166","poster":"Waiweng","timestamp":"1635574140.0","upvote_count":"3"},{"timestamp":"1635139920.0","poster":"Ebi","content":"I go with C","comment_id":"280356","upvote_count":"5"},{"timestamp":"1635038640.0","upvote_count":"2","content":"C.\nB is not only expensive, but also provision of DX takes time.","comment_id":"255504","poster":"01037"},{"content":"Answer is C. Using Snowball is going to be faster than Direct Connect. Other options are either not feasible or too slow.","comment_id":"251792","upvote_count":"1","timestamp":"1635033420.0","poster":"Bulti"},{"content":"Correct is C. Snowball and Re-platform","upvote_count":"2","poster":"T14102020","comment_id":"243427","timestamp":"1634970960.0"},{"content":"I'll go with C","upvote_count":"5","comment_id":"230813","poster":"jackdryan","timestamp":"1634821200.0"},{"comment_id":"230074","upvote_count":"1","content":"seems C","poster":"gookseang","timestamp":"1634812800.0"},{"timestamp":"1634793900.0","content":"Answer C is correct.","poster":"BigMomma4752","upvote_count":"1","comment_id":"208655"},{"upvote_count":"1","comment_id":"197437","timestamp":"1634701380.0","poster":"Paitan","content":"Definitely option C"},{"content":"C is correct","upvote_count":"1","poster":"fullaws","comment_id":"151680","timestamp":"1634323200.0"},{"content":"Answer: C\nA - incorrect - P2V keeps same OS, also who's to say the files aren't on that server which means the image contains the 70TB - double transfer: on-prem->ec2->s3 - EBS costs will be high, and if you can't split the files out, we hit the 16TB limit for a volume.\nB - incorrect - as above, plus not cost-effective. May take months to get Direct Connect running\nC - correct - Snowball has a relatively fast turn round (week or so), and replatform is the only way to change the host O/S\nD - incorrect - no mention of whether system is physical or virtual, and AWS SMS does V2V migrations (from Hyper/V, VMware, Azure)","timestamp":"1634307600.0","poster":"inf","comment_id":"136077","upvote_count":"4"},{"poster":"NikkyDicky","upvote_count":"2","content":"C most likely","comment_id":"133116","timestamp":"1634151060.0"},{"poster":"meenu2225","comment_id":"106328","timestamp":"1633880100.0","content":"C is the answer","upvote_count":"2"},{"poster":"JAWS1600","content":"The requirement is that they want to upgrade their OS. for P2V is out of question. Because P2V will not upgrade OS. only replatform do - Options C and D. C makes more sense.","comment_id":"95054","timestamp":"1633478880.0","upvote_count":"2"},{"content":"B is correct. 10Gbps direct connect provision 3days + transfer within 1day. where snowball end-to-end time will be 1 week.","upvote_count":"1","poster":"FreeSwan","comment_id":"94880","timestamp":"1633256760.0","comments":[{"content":"Where did you read the 10Gbps ?","poster":"AShahine21","upvote_count":"2","timestamp":"1633677120.0","comment_id":"98620"},{"timestamp":"1633815720.0","upvote_count":"1","comment_id":"103594","content":"Yeah, but do u know how much it costs for Dx connection?","poster":"meenu2225"},{"comment_id":"95053","upvote_count":"1","content":"Snowball is way to go. \nB is not stating spinning up EC2. P2V conversion and transfer image using DC.. then what ?\nAbout the timings of DC. It is 72 hours that AWS takes. There are other time lines required by your MPLS partner - ATT or Verizon. Which is usually 2/3 days or longer. \nPlus efforts of configuration , setting up VIFs , Public interface , testing. It has lot of efforts and time involved. \nIt can take up to 72 hours for AWS to review your request and provision a port for your connection. During this time, you might receive an email with a request for more information about your use case or the specified location. The email is sent to the email address that you used when you signed up for AWS. You must respond within 7 days or the connection is deleted.","timestamp":"1633279800.0","poster":"JAWS1600"},{"content":"70 TB data, order snowball and migrate, easy","upvote_count":"1","poster":"sam422","timestamp":"1634663220.0","comment_id":"187970"},{"timestamp":"1635198660.0","poster":"QCO","upvote_count":"1","comment_id":"284434","content":"Bear in mind that there's no Dx connection in place, it needs to be set up. It would take nothing less than a month. Not ideal as well as not being cost effective. Snowball will do the job faster, easier and cheaper"}]},{"timestamp":"1633092000.0","poster":"Joeylee","upvote_count":"2","content":"C but should use snowmobile","comments":[{"content":"Snowball is cost-effective between 10TB - 10PB. Using a snowmobile in this case would be overkill.","upvote_count":"1","poster":"chrisk0208","timestamp":"1634997180.0","comment_id":"244191"}],"comment_id":"76600"},{"upvote_count":"2","poster":"amog","content":"Should be C","comment_id":"51279","timestamp":"1633060860.0"},{"content":"upgrade to the latest version PtoV does not upgrade to the latest","poster":"VMHarry","upvote_count":"2","timestamp":"1632962100.0","comment_id":"29562"},{"timestamp":"1632596220.0","content":"70TB would be cost effective to use snowball","poster":"dpvnme","upvote_count":"2","comment_id":"11858"},{"timestamp":"1632511260.0","upvote_count":"3","poster":"huhupai","content":"Is Direct Connect the FASTEST and MOST cost-effective way?","comments":[{"poster":"SadioMane","content":"LOL. It's a good one","comment_id":"177705","upvote_count":"1","timestamp":"1634371620.0"}],"comment_id":"11261"}],"choices":{"D":"Re-platform the server by using the AWS Server Migration Service to move the code and data to a new Amazon EC2 instance.","C":"Re-platform the server to Amazon EC2, and use AWS Snowball to transfer the static data to Amazon S3.","B":"Run a physical-to-virtual conversion on the application server. Transfer the server image over AWS Direct Connect, and transfer the static data to Amazon S3.","A":"Run a physical-to-virtual conversion on the application server. Transfer the server image over the internet, and transfer the static data to Amazon S3."},"exam_id":32,"answer_ET":"C","question_images":[],"question_text":"A Solutions Architect must migrate an existing on-premises web application with 70 TB of static files supporting a public open-data initiative. The Architect wants to upgrade to the latest version of the host operating system as part of the migration effort.\nWhich is the FASTEST and MOST cost-effective way to perform the migration?","url":"https://www.examtopics.com/discussions/amazon/view/5231-exam-aws-certified-solutions-architect-professional-topic-1/","unix_timestamp":1568631720,"answer":"C","answers_community":["C (100%)"],"topic":"1","question_id":478,"isMC":true},{"id":"P5DdXyUzLcSKrux0z39t","question_text":"A company has an application that generates a weather forecast that is updated every 15 minutes with an output resolution of 1 billion unique positions, each approximately 20 bytes in size (20 Gigabytes per forecast). Every hour, the forecast data is globally accessed approximately 5 million times (1,400 requests per second), and up to 10 times more during weather events. The forecast data is overwritten every update. Users of the current weather forecast application expect responses to queries to be returned in less than two seconds for each request.\nWhich design meets the required request rate and response time?","topic":"1","answer_description":"","unix_timestamp":1569197820,"question_id":479,"answers_community":["D (67%)","B (33%)"],"answer_ET":"D","exam_id":32,"answer":"D","answer_images":[],"timestamp":"2019-09-23 02:17:00","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/5581-exam-aws-certified-solutions-architect-professional-topic-1/","discussion":[{"content":"I have new insight after doing this question for 2nd time.\nB\nA: Cache control should be done at the Cloudfront not API Stage.\nB: EFS has better performance than S3. The data size is only 20GB so this seems suitable.\nC: Lambda@Edge does not cache data. Lambda@Edge is a feature of Amazon CloudFront that lets you run code closer to users of your application, which improves performance and reduces latency. With Lambda@Edge, you don't have to provision or manage infrastructure in multiple locations around the world.\nD: Why have the EC2 in the middle when CloudFront can set S3 as the origin?","poster":"donathon","comment_id":"13678","upvote_count":"18","timestamp":"1632239520.0","comments":[{"timestamp":"1632338400.0","comment_id":"23973","poster":"Frank1","upvote_count":"3","content":"Cache control should be done at API gateway level. https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html"},{"timestamp":"1633020300.0","poster":"JAWS1600","content":"A is good option. API Caching helps reduce calls made to origin. \nhttps://medium.com/@bhargavshah2011/api-gateway-caching-3f86034ca491. \nI just dont support B because it has EC2\nFurther more with number of location we have ( 1 billion) we need ES .Straight S3 wont do a good job for 15 minutes TTL.","comment_id":"94062","upvote_count":"7"},{"poster":"SD13","comment_id":"330352","content":"Correct option is B. A is wring since Lambda can scale up to 3000 per sec based on region. and C is wrong since Lambda@edge can scale up to 10,000/sec, both are less than 15000 request/sec expected spike.","timestamp":"1635957120.0","upvote_count":"3"},{"poster":"aws_arn_name","upvote_count":"1","comment_id":"350343","timestamp":"1636064040.0","content":"I don't understand B. If EFS mounted on EC2 so what is origin of CloudFront"},{"comment_id":"29807","content":"LambdaEdge helps to improve cache hit ration. So, I think, C is correct\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/lambdaedge-design-best-practices/","timestamp":"1632548280.0","upvote_count":"8","poster":"9Ow30"},{"upvote_count":"3","content":"20GB is per forecast and forecast is updated every 15 minutes, use EFS is more expensive.","poster":"huhupai","comments":[{"upvote_count":"1","content":"I agree with this, it not possible to hold so huge data In EFS","poster":"Jesuisleon","comment_id":"919541","timestamp":"1686334860.0"}],"comment_id":"22173","timestamp":"1632252060.0"},{"timestamp":"1632242520.0","upvote_count":"3","comment_id":"14559","poster":"Ibranthovic","content":"I'm still not sure to be honest, I still prefer D over B."},{"poster":"Haykhay","timestamp":"1668110640.0","comment_id":"715531","content":"it is absolutely not true that API caching isnt possible https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html","upvote_count":"1"}]},{"poster":"donathon","timestamp":"1632096960.0","content":"D\nAmazon EC2, Elastic Load Balancing, Amazon S3 buckets configured as website endpoints, or your own web server (HTTP). These are the only origin that you can define for CloudFront.\nEFS also has lower limits then S3 which make it less suitable for this case which may have 14k request per second.\nYou can control how long your files stay in a CloudFront cache before CloudFront forwards another request to your origin. Reducing the duration allows you to serve dynamic content. Increasing the duration means your users get better performance because your files are more likely to be served directly from the edge cache. A longer duration also reduces the load on your origin.\nTo change the cache duration for an individual file, you can configure your origin to add a Cache-Control max-age or Cache-Control s-maxage directive, or an Expires header field to the file.","comments":[{"content":"cloudfront can target APIgateway (and most other dns origins):\nhttps://aws.amazon.com/premiumsupport/knowledge-center/api-gateway-cloudfront-distribution/","timestamp":"1632610380.0","poster":"sarah1","comment_id":"43983","upvote_count":"1"},{"poster":"tiana528","content":"Not D. D says `Store forecast locations in Amazon S3 as individual objects`, the question says `15-minute weather prediction with a resolution of 1 billion distinct locations`. Uploading so many small objects to s3 every 15 minutes seems very ineffective. EFS is much more efficient.","upvote_count":"1","timestamp":"1638441360.0","comment_id":"492371"}],"comment_id":"12205","upvote_count":"14"},{"timestamp":"1693143240.0","upvote_count":"1","comment_id":"991475","poster":"TravelKo","content":"you need to provide search capability. It should be C."},{"comment_id":"980189","timestamp":"1691950860.0","poster":"Veres","upvote_count":"1","content":"Selected Answer: D\nAnswer should D according to the AWS case study.\n\nThe platform ingests information from more than 100 different sources and generates close to one-half terabyte (TB) of data each time it updates. The information is mapped and processed into forecast points that can be retrieved in real time, based on queries coming into the system. All data is stored in Amazon Simple Storage Service (Amazon S3), leveraging the efficiency of cloud storage as opposed to an on-premises storage solution and eliminating the hassle of managing a storage platform.\n\nhttps://aws.amazon.com/solutions/case-studies/the-weather-company/"},{"poster":"SkyZeroZx","content":"Selected Answer: B\nB: EFS has better performance than S3. The data size is only 20GB so this seems suitable.","comment_id":"930748","timestamp":"1687448340.0","upvote_count":"1"},{"poster":"Heer","timestamp":"1676015340.0","content":"ChatGPT Output:OPTION B:\n\nAmazon EFS (Elastic File System) is a scalable, distributed file system that provides high-performance access to data over the network. By storing the forecast data in an Amazon EFS volume, you can provide access to the same data from multiple EC2 instances in a fleet. This makes it easier to scale the infrastructure horizontally and provide better performance as the load increases.\n\nAdditionally, Amazon EFS provides better data persistence compared to Amazon S3, which means that the data will be stored on disk and will persist even if the EC2 instances are terminated. This is important as the forecast data is updated every 15 minutes and needs to be accessible to the users at all times.\n\nOverall, the combination of Amazon EFS and Amazon CloudFront provides better scalability and performance compared to storing the forecast data in Amazon S3 and using CloudFront for distribution.","comment_id":"804099","upvote_count":"1"},{"upvote_count":"1","poster":"RRRichard","content":"It should be A.\nAPI Gateway has Endpoint cache enablement.\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html","timestamp":"1671518220.0","comment_id":"750568"},{"timestamp":"1666071540.0","poster":"Vizz5585","content":"Selected Answer: B\nThe answer is B.\nLambdas have concurrency limits \nS3 has minimum storage limits","comment_id":"697940","upvote_count":"1"},{"comment_id":"684059","comments":[{"upvote_count":"2","content":"B(wrong): EFS limits :\n1 read = 1 Operation\n1 Write = 5 Operations.\nEFS suports 35000 read operations limit only if you are just READING and not WRITING anything.\nEFS has 7000 Write Operations limit limiting only if you are just WRITING and not READING anything\nSo EFS cannot handle 1 billlion files ( each 20 bytes) write requests in 15mins.\n\nC(wrong): Maximum RPS for API Gateway is 10,000requests/s, for lambda it is 1,000requests/s. They can't meet with the requirements of maximum 14,000+ requests/s during whether events. In addition, Lambda@Edge is not used to cache data at edge locations for the specific time. \nhttps://aws.amazon.com/blogs/networking-and-content-delivery/lambdaedge-design-best-practices/","poster":"tomosabc1","timestamp":"1664609040.0","comment_id":"684060"}],"upvote_count":"3","content":"Selected Answer: D\nI think the answer should be D. The following is what I consolidated after reading the analysis from all other comments.\nThe question seems to be inspired from the actual case study of the weather company. All their data are stored in S3. https://aws.amazon.com/solutions/case-studies/the-weather-company/\n\nA(wrong): Cache-control is not available for API Gateway, for which it is TTL.","poster":"tomosabc1","timestamp":"1664608980.0"},{"timestamp":"1663543320.0","comment_id":"672792","content":"Answer is B. Lambda can only handle 10,000 request. Also B is the answer per dojo tutorials.","poster":"linuxmaster007","upvote_count":"2"},{"comment_id":"645523","content":"Amazon S3 automatically scales to high request rates. For example, your application can achieve at least 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per partitioned prefix.","timestamp":"1660228620.0","poster":"Sumit_Kumar","upvote_count":"1"},{"upvote_count":"1","content":"B. Store forecast locations in an Amazon EFS volume. Create an Amazon CloudFront distribution that targets an Elastic Load Balancing group of an Auto Scaling fleet of Amazon EC2 instances that have mounted the Amazon EFS volume. Set the cache-control timeout for 15 minutes in the CloudFront distribution.","timestamp":"1638953040.0","poster":"cldy","comment_id":"496667"},{"poster":"AzureDP900","upvote_count":"3","content":"D is right","timestamp":"1638353400.0","comment_id":"491519"},{"upvote_count":"1","poster":"Kopa","comment_id":"469259","content":"Im going for B","timestamp":"1636261680.0"},{"comment_id":"457113","upvote_count":"2","content":"The \"cache-control timeout is possible in CloudFront only. API Gateway is time to live. Lambda@Edge don't have cache-control timeout option. This left with only either B or D is right. Now, both B&D uses EC2/ASG. But From EC2, accessing EFS is faster than accessing S3. https://dzone.com/articles/confused-by-aws-storage-options-s3-ebs-amp-efs-explained. So I chose \"B\".","poster":"StelSen","timestamp":"1636256100.0"},{"comment_id":"456262","poster":"student22","timestamp":"1636236240.0","content":"B \n---\nB vs D - EFS better than S3 to query many small files frequently. \nA & D - API gateway will throttle at 10k rpm by default.","upvote_count":"2"},{"comment_id":"435383","upvote_count":"3","timestamp":"1636206360.0","content":"Yes, this is B. Lambda is out because of concurrent limit and response time, s3 is out because of update frequency.","poster":"blackgamer"},{"poster":"WhyIronMan","comment_id":"411112","upvote_count":"3","timestamp":"1636182420.0","content":"I'll go with D"},{"timestamp":"1636095120.0","upvote_count":"1","content":"I have a question - home someone can provide some insight. I did a lot of search, but couldn't find an answer.\nAs per the document: https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html, the Default quota for Lambda concurrent executions is 1000, but can be increased to \"Tens of thousands\". So, why everybody is stuck on the figure of \"1000\" for lambda?","comment_id":"401415","poster":"DashL","comments":[{"timestamp":"1636136040.0","comment_id":"401417","poster":"DashL","upvote_count":"1","content":"Also, nowhere in the question it says that the solution has to be implemented immediately. So, there will be enough time to create a quota increase request before implementing the solution."}]},{"content":"I have a question - home someone can provide some insight. I did a lot of search, but couldn't find an answer.\nAs per the document: https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html, the Default quota for Lambda concurrent executions is 1000, but can be increased to \"Tens of thousands\". So, why everybody is stuck on the figure of \"1000\" for lambda??","comment_id":"401413","timestamp":"1636084560.0","upvote_count":"1","poster":"DashL"},{"upvote_count":"3","timestamp":"1636070760.0","content":"According to this https://aws.amazon.com/solutions/case-studies/the-weather-company/.. they built it with S3 and they state The platform is robust enough to handle between 10 and 15 billion transactions each day at 100,000 to 150,000 per second, depending on the weather.”","comment_id":"383969","poster":"SheldonHofstadter"},{"comment_id":"346950","content":"it's B","timestamp":"1636061640.0","upvote_count":"3","poster":"Waiweng"},{"poster":"CloudWiz","comment_id":"330378","content":"A company has been running a web application with an Oracle relational database in an on-premises data center for the past 15 years. The company must migrate the database to AWS. The company needs to reduce operational overhead without having to modify the application's code.\nWhich solution meets these requirements?\nA. Use AWS Database Migration Service (AWS DMS) to migrate the database servers to Amazon RDS.\nB. Use Amazon EC2 instances to migrate and operate the database servers.\nC. Use AWS Database Migration Service (AWS DMS) to migrate the database servers to Amazon DynamoDB.\nD. Use an AWS Snowball Edge Storage Optimized device to migrate the data from Oracle to Amazon Aurora.","timestamp":"1636059900.0","upvote_count":"1"},{"content":"Correct Answer is B EFS \nAs billions of objects are being overwritten on the S3 bucket every 15 minutes, the eventual consistency model could result in older data being served to users. Access from the EC2 instances to the S3 bucket via HTTP calls will also increase the total response time of the application. Access to EFS is faster compared to calling objects on S3 buckets.","upvote_count":"1","timestamp":"1635948000.0","comment_id":"324292","poster":"ExtHo"},{"upvote_count":"1","poster":"Pupu86","comment_id":"317758","timestamp":"1635899340.0","content":"This is a purpose-built question\nAWS ES is built for search basis so A/C is out\nAWS EFS is built of shared access file systems so B is out\nAnswer is D.\n\nCheck out the comparison between EFS/S3/EBS\nhttps://aws.amazon.com/efs/when-to-choose-efs/"},{"comment_id":"282461","poster":"kopper2019","timestamp":"1635843060.0","upvote_count":"3","content":"still confused about this one maybe this goes for D\nhttps://aws.amazon.com/solutions/case-studies/the-weather-company/"},{"poster":"Ebi","content":"S3 is not a good choice for storing many small files that updated frequently,\nI will go with B","comment_id":"280365","upvote_count":"4","timestamp":"1635811740.0"},{"upvote_count":"1","comment_id":"263744","poster":"cox1960","content":"B\nGlobally means CloudFront so B and D. Then, with caching we do not have the 14000rps requirement for the backend/storage anymore. What will give the fastest answer when cache is missed? EFS over S3.","timestamp":"1635621960.0"},{"timestamp":"1635617040.0","comment_id":"251861","poster":"Bulti","content":"Between B and D, I think D is a better choice- The article here-> https://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance.html throws some light on how the 20B location objects can be organized using prefixes to improve the read performance. I think it can easily handle 14000 requests/sec. On the other hand EFS is not an object store and therefore querying the location data stored in a file would be inconvenient and may be a bit more expensive in terms of processing as well. Also it does have restriction of 35000 file operations/ sec which includes both read and write operations. Its clearly mentioned in the question that weather locations are to be updated every 15 min which means that while these files are being updated while they are being read as well. Therefore I will go with D.","upvote_count":"2"},{"comments":[{"poster":"Bulti","timestamp":"1635679320.0","upvote_count":"3","comment_id":"268967","content":"I have overthought the answer. The correct answer is B. A is out because even though we cache the query results for 15 min, the initial load on API Gateway/Lambda will cause the requests to throttle which will result in not meeting the 2 sec SLA. S3 is not meant for this heavy duty load especially with small files of 20 bytes per location data."}],"content":"I think the answer is D. Caching is just a distraction. There are 20 billions locations that can be queried, one per request. Given that the no of max request per second is 14000, the cache hit ratio is going to be pretty low and initially most requests are going to hit the infrastructure to retrieve the location data. So caching is a distractor. Also the other important data point is the SLA which is 2 sec per request. Given the above requirements, I think A is out since API Gateway has a max concurrency of 10000 RPS and it needs to support 14,000 at peak times. C is also out because it uses API Gateway as well.","timestamp":"1635616980.0","upvote_count":"1","comment_id":"251860","poster":"Bulti"},{"timestamp":"1635555960.0","poster":"Bulti","content":"Answer is D.","upvote_count":"1","comment_id":"251859"},{"content":"it looks like between D and C .. but its one of those questions we could al be going around in circles on. It may have been easier if the answer said elastisearch instead of ES which is easily missed. So i'm going for my origional thought of C after reading this https://aws.amazon.com/elasticsearch-service/the-elk-stack/what-is-elasticsearch/ but as mentioned it could just as easily be D having read this https://aws.amazon.com/solutions/case-studies/the-weather-company/ ... However i feel given best practice and the way AWS is trying to go that C is the answer ... Good luck brethren","timestamp":"1635527940.0","poster":"petebear55","upvote_count":"1","comment_id":"247469"},{"poster":"GopiSivanathan","upvote_count":"1","comment_id":"246172","timestamp":"1635444360.0","content":"lambda@edge quota: Requests per second 10,000 (in each Region). its a soft limit and more can be requested. Shouldnt the answer be C?"},{"comment_id":"245217","content":"The answer is A.\nB. Have you ever tried to move a folder over the network with 10K small files? Try it!! it takes forever to write. small files kill filesystems!! And that is true even for D, as partitioning is not mentioned. A last word for D, EC2 without load balancing?? How do you handle increasing EC2 origins (when autoscaling) with Cloudfront?\nElasticsearch is made for real time analytics so it is perfect for this case (being like a nosql in nature), API gateway can have up to 234GB of cache so it could cache the entire dataset (20GB) and there's the other level of cache made from cloudfront on the edge, so the number of requests to backend will drop quickly as soon as the second person in e.g. New York asks for the same weather data.","timestamp":"1635427440.0","poster":"PAUGURU","upvote_count":"3"},{"poster":"T14102020","comment_id":"243440","timestamp":"1635395520.0","upvote_count":"1","content":"Correct is D. S3"},{"upvote_count":"2","content":"D is wrong,cache control header is in origin,not distribution","poster":"howardxie","timestamp":"1635217620.0","comment_id":"234648"},{"timestamp":"1635061320.0","comment_id":"230819","upvote_count":"1","content":"I'll go with D","poster":"jackdryan"},{"timestamp":"1635012840.0","comments":[{"comments":[{"timestamp":"1635735780.0","upvote_count":"1","poster":"gookseang","comment_id":"278289","content":"https://aws.amazon.com/blogs/networking-and-content-delivery/lambdaedge-design-best-practices/"}],"upvote_count":"1","comment_id":"278288","content":"I will change to C","timestamp":"1635703140.0","poster":"gookseang"}],"comment_id":"230077","upvote_count":"1","poster":"gookseang","content":"seems D"},{"upvote_count":"1","timestamp":"1634994300.0","comment_id":"230076","poster":"gookseang","content":"B, my friend said D...................."},{"poster":"kj07","timestamp":"1634975520.0","upvote_count":"1","comment_id":"225678","content":"Answer: D\nA/C out because exceed the limits\nFrom B and D I choose D, because S3 in more optimized for high volumes and you can increase the request rate using prefixes."},{"content":"C is optimal, due to this question is focus the request rate and response time.\n\nThe Lambda@Edge functions that run on \"viewer\" requests and responses will execute at a very high frequency—potentially every time a user requests a file from any edge location.\n\nThe 1000/s limit only effects when send request to \"origin\".","comment_id":"200813","upvote_count":"3","timestamp":"1634971020.0","poster":"aayao"},{"upvote_count":"3","content":"B.\nFor D: https://www.quora.com/Why-is-Amazon-S3-expensive-for-creating-small-files-compared-to-DynamoDB\nS3 is meant to store big files.","comment_id":"187053","timestamp":"1634828220.0","poster":"exergeng"},{"content":"I go for B","poster":"ipindado2020","timestamp":"1634727660.0","comment_id":"183003","upvote_count":"2"},{"content":"All numbers are distractors, the question is about request rate and response time lambda@edge will fit the purpose, Answer is C","poster":"sam422","timestamp":"1634720820.0","comment_id":"182564","comments":[{"content":"changed my answer to D after reading this https://aws.amazon.com/solutions/case-studies/weatherrisk/","poster":"sam422","upvote_count":"1","comment_id":"188974","timestamp":"1634835960.0"}],"upvote_count":"1"},{"comment_id":"151757","upvote_count":"3","content":"B is correct, S3 not for online analytics processing.","poster":"fullaws","timestamp":"1634623380.0"},{"upvote_count":"3","comment_id":"143378","poster":"MultiAZ","content":"I would go for B\nA and C are a no-go, ElasticSearch is for caching and not storing data.\nWhat bothers me with D is \"Amazon S3 as *individual objects*\". Storing 1 billion individual objects every 15 minutes is 1.1 Mil writes per second. If it was not referring \"individual objects\" then this may work\nAlso have in mind we have up to 14 000 request per second at the front, but most of them are cached by CloudFront. So EFS has not issues (although it can deliver 14K IOPS anyway)","timestamp":"1634620440.0"},{"upvote_count":"10","poster":"inf","comment_id":"136372","content":"Answer: D\nEliminate Answers:\nRequires 14,000 RPS\n- eliminates A, C - API Gateway can push 10,000 RPS + burst up to another 5,000 RPS - however burst rate isn't guaranteed, set by AWS, thus may not meet 14,000 RPS\n- eliminates A, C - Lambda RPS (instances of function) can burst up to 3,000 initially, then scales up 500 every minute. It will take too long to scale for 14,000 RPS\nRequire 20GB/2s\n- eliminates B - EFS throughput is based on file system size - we're dealing with ~20GB of data which is max 100MB/s. EFS scales to 10GB/s, but requires > 100TB file system.\n- eliminates A,C - (tentative) - with Lambda as origin we'd be lucky to get .5 GB/s throughput, thus Lambda cannot be the origin as we need 10GB/s over 2s\n\nPromote Answers:\n- promote B, D - CloudFront can cache newer files once TTL has expired \n- promote D - S3 can easily scale to meet 14,000 RPS and billions of files\n\nThus D, as its the only answer to meet requirements.","timestamp":"1634204760.0","comments":[{"comment_id":"706083","poster":"vijay1319","content":"That's Awesome explanation dude..","timestamp":"1666928700.0","upvote_count":"1"}]},{"poster":"NikkyDicky","comment_id":"133122","timestamp":"1633865460.0","upvote_count":"1","content":"D, most likely"},{"timestamp":"1633829880.0","content":"Answer is D.\n EFS has 7,000 write operations/sec limit in general purpose mode. That limit further goes down if you are also reading from the EFS as thtesame time. Clearly EFS volume cannot scale to 1 billion 20byte size write throughput in 15mins.\nhttps://docs.aws.amazon.com/efs/latest/ug/limits.html\n\nWhere S3 has 3,500 PUT/COPY/POST/DELETE per second PER PREFIX. There are no limits to the number of prefixes in a bucket. \nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance.html","poster":"chicagomassageseeker","upvote_count":"2","comment_id":"124444"},{"content":"D\nhttps://aws.amazon.com/solutions/case-studies/the-weather-company/","comment_id":"114266","timestamp":"1633606380.0","poster":"roger8978","upvote_count":"4"},{"comment_id":"109972","poster":"hobokabobo","content":"B\nA&C: As other stated this hits the limit of lamba\nD: well what is this ec2 in between cloudfrond and s3? what is it supposed to do(besides adding another point of failue and slowing down things)? Speed is another consideration plus read after write consitency: 2 seconds response is not realistic. \n D: there is a reason to use ec2. EFS need to be mounted. It will lock while updating the data and is fast enough. Sounds like a solution.","upvote_count":"1","timestamp":"1633570440.0","comments":[{"upvote_count":"1","poster":"hobokabobo","content":"last line should be B (obviously)","timestamp":"1633575060.0","comment_id":"109974"}]},{"comment_id":"109228","timestamp":"1633536960.0","content":"If you read the question line \"Every hour, the forecast data is globally accessed approximately 5 million times (1,400 requests per second), and up to 10 times more during weather events\" , it clearly eliminate the S3 use ( 1400*10) . Answer is B - EFS","upvote_count":"1","poster":"CloudYogi"},{"timestamp":"1633464840.0","upvote_count":"1","comment_id":"107878","content":"ok this question confused me massively. \nat first I liked A but with the API gateway limits and Lambda cold starts the may not meet the requirements.\nthen I liked B but EFS is a file storage by definition - are we dealing with files or actually objects?\nSince the data appears to be an object S3 comes as a winner... nevertheless I'm still not quite certain... and I don't like that.","poster":"Wira"},{"comment_id":"106768","content":"https://aws.amazon.com/solutions/case-studies/the-weather-company/","poster":"JohnyGaddar","timestamp":"1633341120.0","upvote_count":"2"},{"comment_id":"105720","timestamp":"1633270320.0","poster":"Ibranthovic","content":"After re-visiting the Question. the answer is B.\nFor sure A and C are not valid answers.\nD is not valid as well, as S3 is made for static files, S3 is not made for 1 billions files that change every 15 minutes.","upvote_count":"2"},{"poster":"NKnab","upvote_count":"4","content":"D is correct -https://aws.amazon.com/solutions/case-studies/weatherrisk/","comments":[{"comment_id":"123016","upvote_count":"1","poster":"LunchTime","content":"This client has different requirements then in the question - \"The company wanted to retain weather data for at least 10 years, but it could retain data for 12 months because of storage limitations.\" As such, I would not use this as support for answer D.","timestamp":"1633774320.0"}],"timestamp":"1633142820.0","comment_id":"101863"},{"upvote_count":"1","poster":"AShahine21","comment_id":"94677","content":"For EFS, \"file system can support 35,000 read operations per second, or 7,000 write operations\"\nhttps://docs.aws.amazon.com/efs/latest/ug/limits.html\n\nI think D is the right answer","comments":[{"comment_id":"95186","content":"Most Probably, it is B\nD was a good solution in case they decided to use prefixes","upvote_count":"1","timestamp":"1633128360.0","poster":"AShahine21"}],"timestamp":"1633106040.0"},{"timestamp":"1633024560.0","content":"After giving it a second thought. I am sure B is the best answer.\nHere is why : EFS can handle 35 K requests/ sec.\n2. LAMBDA in options A and C is not going to work as origin. No way lambda can act that fast. It need a pre-warm time. 1400 lambdas /sec . No way.\n3. Option D is asking for 1 billion objects in S3. Which is ridiculous for S3 . Specially if they will be overwritten every 15 mts. That means with versioning, it will create a mess and make it sluggish. S3 will not be able to handle the peak load ( 10 times of 5 millions /day)","comment_id":"94067","upvote_count":"2","poster":"JAWS1600"},{"comments":[{"upvote_count":"1","timestamp":"1632820320.0","content":"1400 requests per sec","poster":"VrushaliD","comment_id":"93506"},{"comment_id":"93637","timestamp":"1632906780.0","upvote_count":"1","comments":[{"content":"it says \"and up to 10 time more during weather events\" so 1,400 initially then 14000","poster":"sdee1013","comments":[{"upvote_count":"1","comment_id":"107893","timestamp":"1633508700.0","content":"still S3 + CloudFront will serve the purpose. Its D","poster":"VrushaliD"}],"timestamp":"1633218840.0","upvote_count":"2","comment_id":"104008"}],"content":"Its 1400 requests / sec as listed in the question \"1,400 requests per second\" - NOT 14000","poster":"JAWS1600"},{"timestamp":"1633831620.0","upvote_count":"1","comment_id":"124445","content":"EFS limits :\n1 read = 1 Operation\n1 Write = 5 Operations.\nEFS suports 35000 read operations limit only if you are just READING and not WRITING anything. \nEFS has 7000 Write Operations limit limiting only if you are just WRITING and not READING anything\nSo EFS cannot handle 1 billlion files ( each 20 bytes) write requests in 15mins.","poster":"chicagomassageseeker"},{"comment_id":"182561","content":"14,000 requests /sec is a distractor","poster":"sam422","timestamp":"1634631720.0","upvote_count":"1"},{"upvote_count":"2","comment_id":"88690","content":"you can use partitions on S3 to increase the performance. every partition will get 3500 PUTs and 5500 GETs \nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance.html","timestamp":"1632792240.0","poster":"[Removed]"}],"comment_id":"87896","poster":"fw","upvote_count":"1","content":"Let's do a comparison on requests per second.\nCloudfront: 100,000\nAPI Gateway: 10,000\nS3: 3500 Puts & 5500 GETs\nEFS: 35,000\nIt needs to handle 14,000 requests/sec.\nThe only solution is B. Use EFS.","timestamp":"1632776460.0"},{"timestamp":"1632725880.0","upvote_count":"1","poster":"Joeylee","content":"I will choose A. S3 use eventually consistent read, and the data size is too small.","comment_id":"76608"},{"upvote_count":"1","comment_id":"64034","poster":"paulwang","comments":[{"upvote_count":"1","timestamp":"1633010760.0","comment_id":"94060","content":"Not a practical option .\"Store Forecast locations as Individual objects\". That means 1 billion objects. If objects get updated- every 15 minutes. With versioning turned on - that is lot of objects for 1 day.","poster":"JAWS1600"}],"content":"D if I have to choose one.\n\"accessed approximately 5 million times (1,400 requests per second), and up to 10 times more during weather events\" makes me only consider S3.\nELB with a group of auto scaling fleet of EC2 is used to do search. maybe consider using dynamo DB to store the mapping between S3 link and location information, used for search will be faster and cheaper.","timestamp":"1632670500.0"},{"timestamp":"1632661740.0","content":"EFS is not good at small write/read operations, I assume \"each approximately 20 bytes in size\" means an object/file is 20 bytes each, so B is out. S3 has significant delays (hundreds of milliseconds) , but still within acceptable limits. Since Cloudfront only accepts EC2, ELB and S3 as endpoints and since it's offered it each possible solution, this leaves only B & D. Therefore only D is the correct answer.","upvote_count":"2","comment_id":"56255","poster":"MrP"},{"poster":"Vyasc","upvote_count":"2","comment_id":"54346","content":"I think C is right, while I am not sure about how the lambda rate limits apply to edge functions, it is possible to cache data using Lambda@Edge based upon this URL\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/leveraging-external-data-in-lambdaedge/","timestamp":"1632657840.0"},{"comments":[{"comments":[{"timestamp":"1633824840.0","upvote_count":"3","content":"Sorry, mean to say \"B\" is correct.\nA&C: Lambda can't handle the volume of requests as pr the link I provided above. That excludes A&C. Also, which also excludes A&C.\nB: EFS can handle 1 - 3 Gbs depending on the region. That means EFS itself will take between 6.67 to 20 seconds to upload the data every 15 minutes. (https://docs.aws.amazon.com/efs/latest/ug/limits.html) seems reasonable. \nD: S3 is not performant when querying small files as we are in this question per the following link: https://www.upsolver.com/blog/small-file-problem-hdfs-s3 \"Writing small files to an object storage (Amazon S3, Azure Blob, HDFS, etc.) is easy enough; however, trying to query the data in this state using an SQL engine such as Athena or Presto will absolutely kill both your performance and your budget.\"\nRemember, there are 1BB records of 20 bytes that makeup the 20 GB forecast created every 15 minutes. As such, querying S3 will be to slow and therefore D is incorrect.","poster":"LunchTime","comment_id":"123581"}],"comment_id":"123012","content":"Great point. The concurrency limit for Lambda is a maximum of 3,000 depending on the region. https://docs.aws.amazon.com/lambda/latest/dg/invocation-scaling.html. D is the best answer.","upvote_count":"1","timestamp":"1633761480.0","poster":"LunchTime"}],"upvote_count":"7","content":"Should be D\n14000 request per second is over Lambda limit","poster":"amog","comment_id":"51280","timestamp":"1632655320.0"},{"content":"B ? \nEFS while using \"20 bytes in size\".","upvote_count":"1","timestamp":"1632647460.0","poster":"ashp","comment_id":"45447"},{"comments":[{"comment_id":"31725","upvote_count":"6","poster":"abrahamrohithroy","content":"D is likely to be the answer.The question seems to be inspired from the actual case study of the weather company. All their data are stored in S3. https://aws.amazon.com/solutions/case-studies/the-weather-company/","timestamp":"1632592080.0"}],"timestamp":"1632553920.0","upvote_count":"2","comment_id":"29874","content":"maybe it's about this https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","poster":"aperally"},{"poster":"Scunningham99","timestamp":"1632526140.0","comment_id":"27864","content":"agree with d","upvote_count":"1"},{"poster":"johannes756","comment_id":"27263","upvote_count":"5","content":"B\nalthough cost is not mentioned, D is expensive at 1 billion puts every 15 mins \"Store forecast locations in an Amazon S3 as individual objects\". S3 charges $0.005/1k puts","timestamp":"1632501600.0"},{"poster":"huhupai","content":"I would go for C, https://aws.amazon.com/blogs/networking-and-content-delivery/lambdaedge-design-best-practices/","timestamp":"1632328140.0","upvote_count":"4","comment_id":"22182"},{"comment_id":"13438","upvote_count":"2","content":"I do support answer \"D\".\n\nC, wrong because Lambda@Edge is used to edit the flow, not for caching!","poster":"Moon","timestamp":"1632192780.0"},{"poster":"SivaG","upvote_count":"2","comment_id":"12891","timestamp":"1632179220.0","content":"queries to be returned in less than two seconds for each request .. Hence I think \"C\""},{"timestamp":"1632106860.0","upvote_count":"3","content":"c is my view","poster":"awsec2","comment_id":"12281"}],"question_images":[],"choices":{"B":"Store forecast locations in an Amazon EFS volume. Create an Amazon CloudFront distribution that targets an Elastic Load Balancing group of an Auto Scaling fleet of Amazon EC2 instances that have mounted the Amazon EFS volume. Set the cache-control timeout for 15 minutes in the CloudFront distribution.","C":"Store forecast locations in an Amazon ES cluster. Use an Amazon CloudFront distribution targeting an API Gateway endpoint with AWS Lambda functions responding to queries as the origin. Create an Amazon Lambda@Edge function that caches the data locally at edge locations for 15 minutes.","D":"Store forecast locations in Amazon S3 as individual objects. Create an Amazon CloudFront distribution targeting an Elastic Load Balancing group of an Auto Scaling fleet of EC2 instances, querying the origin of the S3 object. Set the cache-control timeout for 15 minutes in the CloudFront distribution.","A":"Store forecast locations in an Amazon ES cluster. Use an Amazon CloudFront distribution targeting an Amazon API Gateway endpoint with AWS Lambda functions responding to queries as the origin. Enable API caching on the API Gateway stage with a cache-control timeout set for 15 minutes."}},{"id":"7qnxrBfedpLEcLkEwV92","discussion":[{"upvote_count":"25","poster":"donathon","comment_id":"12206","content":"A\nWith the DeletionPolicy attribute you can preserve or (in some cases) backup a resource when its stack is deleted. You specify a DeletionPolicy attribute for each resource that you want to control. If a resource has no DeletionPolicy attribute, AWS CloudFormation deletes the resource by default. To keep a resource when its stack is deleted, specify Retain for that resource. You can use retain for any resource. For example, you can retain a nested stack, Amazon S3 bucket, or EC2 instance so that you can continue to use or modify those resources after you delete their stacks.\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html","timestamp":"1632429300.0"},{"comment_id":"11264","upvote_count":"11","timestamp":"1632069360.0","content":"I would go for A.","poster":"huhupai"},{"comment_id":"930753","poster":"SkyZeroZx","timestamp":"1687448940.0","content":"Selected Answer: A\nA classic usage of DeletionPolicy in CloudFormation","upvote_count":"1"},{"poster":"Aum","comment_id":"715595","timestamp":"1668119520.0","upvote_count":"2","content":"why not B? Stack policy can also disallows deletion of resources within the stack. \"A\" just said to configure \"DeletionPolicy\" it didn't actually say to prevent deletion. You can actually set it to snapshot before delete, etc."},{"timestamp":"1638868920.0","poster":"cldy","upvote_count":"1","content":"A. Modify the CloudFormation templates to add a DeletionPolicy attribute to RDS and EBS resources.","comment_id":"495819"},{"poster":"AzureDP900","comment_id":"494613","timestamp":"1638734220.0","content":"A is right","upvote_count":"1"},{"timestamp":"1636216380.0","poster":"moon2351","comment_id":"448094","content":"The answer is definitely A.","upvote_count":"1"},{"content":"I'll go with A","comment_id":"411113","upvote_count":"1","timestamp":"1636095480.0","poster":"WhyIronMan"},{"comment_id":"346912","timestamp":"1635952380.0","upvote_count":"2","poster":"Waiweng","content":"it's A"},{"comment_id":"280366","upvote_count":"3","content":"A is the answer","timestamp":"1635345000.0","poster":"Ebi"},{"timestamp":"1635066300.0","poster":"Bulti","content":"Answer is A","comment_id":"251862","upvote_count":"2"},{"timestamp":"1634892360.0","poster":"T14102020","comment_id":"243019","content":"Correct is A. CloudFormation","upvote_count":"1"},{"content":"I'll go with A","timestamp":"1634354760.0","upvote_count":"2","poster":"jackdryan","comment_id":"230821"},{"content":"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA","timestamp":"1634308440.0","poster":"gookseang","upvote_count":"1","comment_id":"230079"},{"upvote_count":"1","content":"A for sure","poster":"ipindado2020","timestamp":"1634193480.0","comment_id":"183004"},{"poster":"fullaws","comment_id":"151781","content":"A is correct","upvote_count":"1","timestamp":"1633779300.0"},{"upvote_count":"1","poster":"NikkyDicky","timestamp":"1633739940.0","content":"A for sure","comment_id":"133124"},{"poster":"paulwang","timestamp":"1633713300.0","content":"A.\nNo doubt.\nJust FYI, \nYou can prevent a stack from being accidentally deleted by enabling termination protection on the stack. That protect the whole stack from delete.\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-protect-stacks.html","upvote_count":"4","comment_id":"64042"},{"content":"Answer is A","upvote_count":"1","comment_id":"51281","poster":"amog","timestamp":"1632945900.0"},{"timestamp":"1632841980.0","upvote_count":"7","content":"A:\nAlso, \nFor RDS, DeletionPolicy should be SNAPSHOT\nFor S3, DeletionPolicy should be RETAIN","comment_id":"32595","poster":"cinopi"},{"poster":"Moon","upvote_count":"4","timestamp":"1632772920.0","content":"\"A\" is the right answer","comment_id":"13434"},{"content":"a is right","poster":"awsec2","comment_id":"12282","timestamp":"1632720120.0","upvote_count":"3"},{"comment_id":"11877","poster":"dpvnme","timestamp":"1632156240.0","content":"AAAAAAAAAA","upvote_count":"4"}],"url":"https://www.examtopics.com/discussions/amazon/view/5233-exam-aws-certified-solutions-architect-professional-topic-1/","answer_images":[],"question_id":480,"question_images":[],"isMC":true,"answers_community":["A (100%)"],"question_text":"A company is using AWS CloudFormation to deploy its infrastructure. The company is concerned that, if a production CloudFormation stack is deleted, important data stored in Amazon RDS databases or Amazon EBS volumes might also be deleted.\nHow can the company prevent users from accidentally deleting data in this way?","answer_ET":"A","answer":"A","exam_id":32,"topic":"1","answer_description":"With the DeletionPolicy attribute you can preserve or (in some cases) backup a resource when its stack is deleted. You specify a DeletionPolicy attribute for each resource that you want to control. If a resource has no DeletionPolicy attribute, AWS CloudFormation deletes the resource by default. To keep a resource when its stack is deleted, specify Retain for that resource. You can use retain for any resource. For example, you can retain a nested stack, Amazon S3 bucket, or EC2 instance so that you can continue to use or modify those resources after you delete their stacks.\nReference:\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html","timestamp":"2019-09-16 13:11:00","unix_timestamp":1568632260,"choices":{"C":"Modify IAM policies to deny deleting RDS and EBS resources that are tagged with an ג€aws:cloudformation:stack-nameג€ tag.","B":"Configure a stack policy that disallows the deletion of RDS and EBS resources.","D":"Use AWS Config rules to prevent deleting RDS and EBS resources.","A":"Modify the CloudFormation templates to add a DeletionPolicy attribute to RDS and EBS resources."}}],"exam":{"lastUpdated":"11 Apr 2025","provider":"Amazon","id":32,"numberOfQuestions":1019,"isMCOnly":false,"name":"AWS Certified Solutions Architect - Professional","isBeta":false,"isImplemented":true},"currentPage":96},"__N_SSP":true}