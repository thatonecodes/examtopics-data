{"pageProps":{"questions":[{"id":"JbzeXXtt7oQNmsk6GDoh","unix_timestamp":1730832540,"question_id":81,"question_text":"A company wants to create an application by using Amazon Bedrock. The company has a limited budget and prefers flexibility without long-term commitment.\nWhich Amazon Bedrock pricing model meets these requirements?","answer_description":"","isMC":true,"answer":"A","answers_community":["A (86%)","14%"],"url":"https://www.examtopics.com/discussions/amazon/view/150811-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","topic":"1","timestamp":"2024-11-05 19:49:00","discussion":[{"upvote_count":"1","comment_id":"1558602","poster":"Rcosmos","timestamp":"1744037040.0","content":"Selected Answer: U\nExplicação:\nO modelo de preço sob demanda do Amazon Bedrock permite que a empresa pague apenas pelo que usar, sem necessidade de compromissos de longo prazo ou reservas antecipadas.\nIsso oferece: Flexibilidade: Ideal para projetos em fase inicial ou com uso variável.\nCusto controlado: Perfeito para orçamentos limitados, pois evita gastos fixos ou comprometimento com capacidade provisionada.\nSem contratos: A empresa pode interromper ou ajustar o uso a qualquer momento."},{"poster":"Jessiii","comment_id":"1355358","upvote_count":"2","content":"Selected Answer: A\nOn-Demand: The On-Demand pricing model allows the company to pay for the compute resources or services they use without requiring a long-term commitment. This model is ideal for companies that need flexibility and have variable usage patterns, as they can scale up or down based on their needs while only paying for what they use. This model provides the most flexibility and is cost-effective for companies with limited budgets.","timestamp":"1739326920.0"},{"timestamp":"1738238340.0","poster":"85b5b55","upvote_count":"1","content":"Selected Answer: A\nOn-Demand pricing plan helps to run the application in the temporary mode.","comment_id":"1349035"},{"timestamp":"1735669320.0","comment_id":"1334985","content":"Selected Answer: A\nA: On-Demand\n\nExplanation:\nThe On-Demand pricing model for Amazon Bedrock provides flexibility and allows the company to pay only for what they use, without requiring long-term commitments or upfront payments. This is ideal for a company with a limited budget that needs to control costs while maintaining flexibility.\n\nD: Spot Instance:\nSpot Instances are an AWS EC2 pricing model for obtaining unused compute capacity at discounted rates. They are not applicable to Amazon Bedrock, which does not rely on Spot Instances.","upvote_count":"1","poster":"Moon"},{"comment_id":"1307521","timestamp":"1730832540.0","upvote_count":"2","content":"Selected Answer: A\nOn-Demand is the best pricing model for a company that has a limited budget and wants flexibility without long-term commitment when creating an application using Amazon Bedrock.","poster":"jove"}],"exam_id":14,"question_images":[],"answer_ET":"A","choices":{"B":"Model customization","A":"On-Demand","D":"Spot Instance","C":"Provisioned Throughput"},"answer_images":[]},{"id":"xFHF0RHNhkTwvgFZAg8M","question_text":"Which AWS service or feature can help an AI development team quickly deploy and consume a foundation model (FM) within the team's VPC?","answers_community":["B (61%)","D (39%)"],"isMC":true,"unix_timestamp":1730832600,"discussion":[{"comment_id":"1365652","timestamp":"1741222500.0","content":"Selected Answer: B\nB. Amazon SageMaker JumpStart\n\nExplanation:\n • Amazon SageMaker JumpStart enables AI teams to quickly deploy and consume foundation models (FMs) within their own VPC.\n • It provides pre-trained foundation models from AWS and third-party providers, making it easy to fine-tune and integrate them into applications.\n • VPC Integration: Ensures that models are deployed securely within the team’s AWS environment.","poster":"SP888","upvote_count":"2"},{"comment_id":"1357348","upvote_count":"1","poster":"JJwin","timestamp":"1739733720.0","content":"Selected Answer: D\nAmazon SageMaker endpoints are a managed service feature that allows you to deploy models (including foundation models) for real-time inference. By hosting your model on an endpoint, you can make it accessible within your Virtual Private Cloud (VPC) and integrate it into your applications quickly. This approach provides a secure, scalable, and managed way to deploy and consume models across different teams.\nB. Amazon SageMaker JumpStart: Provides quick access to pre-trained models and sample solutions, but you ultimately deploy those models via SageMaker endpoints to consume them in your VPC."},{"timestamp":"1739497140.0","content":"Selected Answer: D\nAmazon SageMaker endpoints allow AI development teams to deploy and consume foundation models (FMs) within their Amazon VPC for secure, low-latency inference.","comment_id":"1356334","upvote_count":"2","poster":"Willdoit"},{"content":"Selected Answer: B\nAmazon SageMaker JumpStart: Amazon SageMaker JumpStart helps developers quickly deploy and consume pre-trained models, including foundation models (FMs), within their environment. It provides a collection of ready-to-use models, workflows, and deployment solutions, allowing teams to get started quickly without having to build everything from scratch. It supports various ML use cases, making it an ideal choice for quickly deploying an FM in a VPC.","comment_id":"1355359","timestamp":"1739326980.0","poster":"Jessiii","upvote_count":"1"},{"comment_id":"1349036","upvote_count":"1","content":"Selected Answer: B\nAmazon SageMaker JumpStart helps to deploy pre-trained Open-sourced models quickly.","timestamp":"1738238520.0","poster":"85b5b55"},{"timestamp":"1738099380.0","poster":"dspd","upvote_count":"1","content":"Selected Answer: B\nThe correct answer is B: Amazon SageMaker JumpStart.\n\nHere's why:\n\nAmazon SageMaker JumpStart is specifically designed to help teams quickly deploy and use foundation models (FMs) with the following benefits:\nProvides pre-trained models that can be deployed with just a few clicks\nAllows deployment within your VPC for secure access\nIncludes popular foundation models from various providers\nOffers fine-tuning capabilities for customization\nHandles the infrastructure management automatically\n\nAmazon SageMaker endpoints - While these are used to deploy models, SageMaker JumpStart provides a more complete solution specifically for foundation models with built-in deployment capabilities","comment_id":"1348198"},{"timestamp":"1736971920.0","content":"Selected Answer: D\nI lean towards Sagemaker Endpoints . to my knowledge Jumpstart will help you select/deploy the model, but to actually use it/consume it in your Prod/dev environment/VPC you need the Endpoint","poster":"waldonuts","upvote_count":"2","comment_id":"1341244"},{"poster":"scs50","upvote_count":"1","timestamp":"1736562360.0","comment_id":"1339040","content":"Selected Answer: B\nAmazon SageMaker JumpStart provides security features, including the ability to integrate with a Virtual Private Cloud (VPC), ensuring secure communication and data transfer during machine learning tasks. SageMaker Jumpstart simplifies the process of building, training, and deploying ML models by offering ready-to-use resources and templates."},{"content":"Selected Answer: B\nfor quick access we can use jumpstart","comment_id":"1336105","poster":"Aswiz","timestamp":"1735926720.0","upvote_count":"1"},{"timestamp":"1735669740.0","poster":"Moon","content":"Selected Answer: D\nhe question asks about quickly deploying and consuming an FM within the team's VPC.\n\nA. Amazon Personalize: This is for building recommendation systems, not general FM deployment or consumption. It's irrelevant to the question.\n\nB. Amazon SageMaker JumpStart: JumpStart provides a quick way to find and deploy pre-trained models. However, the initial deployment is not automatically within your VPC. You need to configure the endpoint settings during deployment to specify your VPC. Therefore, while it speeds up the process of getting a model ready, it doesn't directly fulfill the \"within the team's VPC\" requirement without extra steps.\n\n\nD. Amazon SageMaker endpoints: This is the most accurate answer. While JumpStart can help you get a model ready, it's the SageMaker endpoint itself that is configured to reside within your VPC. You create the endpoint and specify the VPC configuration during that endpoint creation.","comment_id":"1334995","upvote_count":"1"},{"timestamp":"1735355640.0","comment_id":"1332734","content":"Selected Answer: B\nLet me explain why Amazon SageMaker JumpStart (Option B) is the correct answer:\n\n1. VPC Integration: SageMaker JumpStart allows deployment of foundation models within your team's VPC, ensuring secure access and network isolation.\n\n2. Quick Deployment: It provides a streamlined process for deploying pre-trained foundation models with minimal setup required. The service includes:\n - One-click deployment options\n - Pre-configured model endpoints\n - Built-in model optimization\n\n3. Foundation Model Support: SageMaker JumpStart specifically offers a wide range of foundation models that are ready to use.","upvote_count":"1","poster":"may2021_r"},{"upvote_count":"2","timestamp":"1733504460.0","content":"Selected Answer: B\nAmazon SageMaker JumpStart","comment_id":"1322852","poster":"Chika22"},{"content":"Selected Answer: D\nAmazon SageMaker endpoints allow you to deploy machine learning models, including foundation models, for real-time inference within a Virtual Private Cloud (VPC). This feature is particularly suitable for AI teams looking to host and consume their models securely and quickly.\n\nAmazon SageMaker JumpStart: While JumpStart provides prebuilt solutions and model deployment templates, it is not specifically focused on VPC integration for foundation models.","poster":"Contactfornitish","upvote_count":"1","timestamp":"1733186940.0","comment_id":"1321151"},{"upvote_count":"2","timestamp":"1732794360.0","comment_id":"1319200","content":"Selected Answer: B\nIt could be B or D as question says Service or Feature.\nWhy D got eliminated? - Even though it says Service or Feature, I think that is just because SageMaker itself is an umbrella for many services and features. Like SageMaker studio itself has many features. SageMaker endpoint is not a feature per say, but the deployment environment for models.","poster":"0c2d840"},{"upvote_count":"2","content":"Selected Answer: B\nB. Amazon SageMaker JumpStart\n\nAmazon SageMaker JumpStart provides a collection of pre-trained models, including foundation models, that can be easily deployed and customized within a team's VPC. This allows for secure and efficient access to these powerful models without exposing them to the public internet","poster":"eesa","timestamp":"1732701240.0","comment_id":"1318558"},{"upvote_count":"1","poster":"RY66","content":"The correct answer to this question is B. Amazon SageMaker JumpStart.\nAmazon SageMaker JumpStart is a service that provides pre-trained models, solutions, and examples to help quickly start machine learning tasks.\nJumpStart includes a variety of foundation models (FMs) and offers features to easily deploy and fine-tune these models.\nImportantly, models deployed through JumpStart can be run securely within a team's VPC, which aligns with the question's requirement of deploying and consuming a foundation model within the team's VPC.\nJumpStart enables quick deployment and consumption of models, satisfying the \"quickly deploy and consume\" part of the question.","comment_id":"1315035","timestamp":"1732075920.0"},{"content":"Selected Answer: D\n.. AWS FEATURE can help .. and CONSUME a foundation model (FM) within the team's VPC?","comment_id":"1311001","comments":[{"upvote_count":"1","content":"sorry i didn't notice i have already commented/answer on this.","timestamp":"1731457200.0","poster":"fed6485","comment_id":"1311002"}],"upvote_count":"2","timestamp":"1731457140.0","poster":"fed6485"},{"timestamp":"1731390900.0","comment_id":"1310446","upvote_count":"2","comments":[{"content":"Answer is A. Even though it says Service or Feature, I think that is just because SageMaker itself is an umbrella for many services and features. Like SageMaker studio itself has many features. SageMaker endpoint is not a feature per say, but the deployment environment for models.","timestamp":"1732794240.0","poster":"0c2d840","upvote_count":"1","comment_id":"1319199"}],"content":"Selected Answer: D\n... mmm.. interesting one as.. \n\nWhich AWS service or feature can help an AI development team quickly deploy and consume a foundation model (FM) within the team's VPC?\n\nthe fact that \"AWS service or FEATURE\" .. deploy within the team's VPC..\n\ndefinitely or B or D\nB if the question refers to the SERVICE\nD if the question refers to the FEATURE\n\n:)","poster":"fed6485"},{"poster":"raat","upvote_count":"2","content":"Amazon SageMaker JumpStart (option B) is indeed a valuable service for quickly getting started with pre-built models and solutions. However, it is more focused on providing a range of pre-trained models and example solutions to help you get started with machine learning projects.\n\nFor the specific requirement of deploying and consuming a foundation model within your VPC, Amazon SageMaker endpoints (option D) are more directly suited. They allow you to deploy models for real-time inference securely within your VPC, ensuring that your data and model interactions remain within your private network.\n\nIf you have any more questions or need further clarification, feel free to ask!","comment_id":"1309994","timestamp":"1731325920.0"},{"timestamp":"1730832600.0","content":"Selected Answer: B\nB. Amazon SageMaker JumpStart is the best option for quickly deploying and consuming a foundation model within a team's VPC, as it streamlines the process and provides ready-to-use resources.","upvote_count":"3","poster":"jove","comment_id":"1307522"}],"answer":"B","answer_ET":"B","exam_id":14,"question_id":82,"timestamp":"2024-11-05 19:50:00","url":"https://www.examtopics.com/discussions/amazon/view/150812-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","question_images":[],"answer_description":"","choices":{"C":"PartyRock, an Amazon Bedrock Playground","A":"Amazon Personalize","B":"Amazon SageMaker JumpStart","D":"Amazon SageMaker endpoints"},"topic":"1","answer_images":[]},{"id":"9LhirZoM7WXFgZ9ScPvx","question_text":"How can companies use large language models (LLMs) securely on Amazon Bedrock?","answers_community":["A (100%)"],"choices":{"C":"Enable Amazon Bedrock automatic model evaluation jobs.","D":"Use Amazon CloudWatch Logs to make models explainable and to monitor for bias.","A":"Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.","B":"Enable AWS Audit Manager for automatic model evaluation jobs."},"answer":"A","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/150813-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answer_ET":"A","question_id":83,"answer_description":"","discussion":[{"poster":"Jessiii","comment_id":"1355360","upvote_count":"1","timestamp":"1739327040.0","content":"Selected Answer: A\nDesign clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.:\nDesigning clear and specific prompts helps prevent unintended or manipulative outputs from the large language models (LLMs), ensuring secure and controlled use.\nConfiguring IAM roles and policies using least privilege access ensures that only authorized users and services can access and invoke the models, limiting potential security risks."},{"upvote_count":"1","comment_id":"1349040","content":"Selected Answer: A\nUsing IAM with least privilege will secure the LLM on the Amazon Bedrock.","poster":"85b5b55","timestamp":"1738238940.0"},{"upvote_count":"1","comment_id":"1324273","poster":"eesa","content":"Selected Answer: A\nA. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.\n\nThis option addresses two key aspects of secure LLM usage on Amazon Bedrock:\n\nPrompt Engineering: Clear and specific prompts reduce the risk of unintended or harmful outputs. Well-defined prompts help guide the model's responses and minimize the potential for bias or misinformation.\nIAM Access Control: Implementing strong access controls is crucial to protect sensitive data and prevent unauthorized access to the LLM. By using IAM roles and policies with least privilege access, you can limit permissions to only the necessary actions, reducing the risk of security breaches.","timestamp":"1733789100.0"},{"poster":"jove","upvote_count":"2","timestamp":"1730832720.0","comment_id":"1307524","content":"Selected Answer: A\nA. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access is the best approach for companies to securely use large language models on Amazon Bedrock, as it emphasizes both prompt clarity and access control."}],"topic":"1","question_images":[],"timestamp":"2024-11-05 19:52:00","answer_images":[],"unix_timestamp":1730832720,"exam_id":14},{"id":"5IjHhHhZLDfjVBjjPPuo","question_text":"A company has terabytes of data in a database that the company can use for business analysis. The company wants to build an AI-based application that can build a SQL query from input text that employees provide. The employees have minimal experience with technology.\nWhich solution meets these requirements?","topic":"1","answers_community":["A (100%)"],"question_id":84,"discussion":[{"poster":"Jessiii","content":"Selected Answer: A\nGenerative pre-trained transformers (GPT): GPT models are well-suited for natural language processing tasks, such as generating SQL queries from input text. These models are designed to understand and generate human-like text, which makes them ideal for translating text input into structured outputs like SQL queries. With minimal training, GPT models can be fine-tuned for specific tasks, such as query generation, and can help employees with minimal technical experience by understanding natural language inputs and converting them into SQL queries.","comment_id":"1355361","timestamp":"1739327040.0","upvote_count":"1"},{"timestamp":"1738239780.0","poster":"85b5b55","content":"Selected Answer: A\nGPT helps to produces the NL based responsed based on the input text.","upvote_count":"1","comment_id":"1349048"},{"poster":"Moon","timestamp":"1735817160.0","upvote_count":"1","comment_id":"1335526","content":"Selected Answer: A\nThe best solution for building an AI-based application that translates natural language (employee input text) into SQL queries is A. Generative pre-trained transformers (GPT).\n\nHere's why:\n\nGPT's strength in natural language processing: GPT models are specifically designed for understanding and generating human language. They excel at tasks like text translation, question answering, and, crucially, code generation from natural language descriptions. This makes them ideal for converting employee input into SQL queries."},{"upvote_count":"2","content":"Selected Answer: A\nGenerative pre-trained transformers (GPT) are powerful natural language processing models that excel in understanding and generating human-like text. In this scenario, a GPT model can be trained or fine-tuned to take natural language input from employees and convert it into structured SQL queries. This makes it accessible for users who may not have technical expertise, allowing them to retrieve the data they need from the database using simple, conversational prompts.","timestamp":"1730832900.0","comment_id":"1307525","poster":"jove"}],"exam_id":14,"unix_timestamp":1730832900,"answer_images":[],"timestamp":"2024-11-05 19:55:00","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/150814-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answer_description":"","answer_ET":"A","answer":"A","question_images":[],"choices":{"D":"WaveNet","A":"Generative pre-trained transformers (GPT)","C":"Support vector machine","B":"Residual neural network"}},{"id":"2xGPb99rni6Of2rpQsUA","question_text":"A company built a deep learning model for object detection and deployed the model to production.\nWhich AI process occurs when the model analyzes a new image to identify objects?","answers_community":["B (100%)"],"topic":"1","question_id":85,"discussion":[{"poster":"Rcosmos","comment_id":"1559346","timestamp":"1744224480.0","upvote_count":"1","content":"Selected Answer: B\nExplicação:\nA inferência é o processo que ocorre após o modelo estar treinado e implantado, quando ele é usado para analisar novos dados (neste caso, uma nova imagem) e gerar previsões ou classificações — como identificar objetos na imagem.\n\nAs outras opções se referem a fases diferentes do ciclo de vida da IA:\n\nA. Formação (Treinamento): é o processo de ensinar o modelo usando dados rotulados.\n\nC. Implantação de modelo: é quando o modelo é colocado em produção, mas ainda não está processando dados.\n\nD. Correção de viés: refere-se a técnicas usadas para identificar e mitigar preconceitos nos dados ou no modelo."},{"content":"Selected Answer: B\nInference: Inference is the process in which a trained model analyzes new data (in this case, a new image) to make predictions or classifications. After the model is trained, it is deployed to production, and inference occurs when the model processes new, unseen data to identify objects or make decisions.","poster":"Jessiii","comment_id":"1355362","timestamp":"1739327100.0","upvote_count":"1"},{"content":"Selected Answer: B\nDuring the inference phase, model analyses a new image to identify objects.","timestamp":"1738239900.0","poster":"85b5b55","upvote_count":"1","comment_id":"1349049"},{"poster":"eesa","upvote_count":"1","timestamp":"1733789220.0","content":"Selected Answer: B\nB. Inference\n\nInference is the process of using a trained model to make predictions or decisions on new, unseen data. In the case of an object detection model, inference involves feeding a new image into the model, which then analyzes the image and outputs the detected objects and their locations.","comment_id":"1324274"},{"content":"Selected Answer: B\nAI inference is the process that a trained machine learning model uses to draw conclusions from brand-new data. An AI model capable of making inferences can do so without examples of the desired result.","timestamp":"1733577360.0","poster":"urbanmonk","upvote_count":"1","comment_id":"1323110"},{"timestamp":"1731180000.0","content":"Selected Answer: B\nIt's the inference","upvote_count":"4","comment_id":"1309177","poster":"jove"}],"exam_id":14,"unix_timestamp":1731180000,"answer_images":[],"timestamp":"2024-11-09 20:20:00","isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/151041-exam-aws-certified-ai-practitioner-aif-c01-topic-1-question/","answer_description":"","answer_ET":"B","answer":"B","question_images":[],"choices":{"D":"Bias correction","C":"Model deployment","B":"Inference","A":"Training"}}],"exam":{"isBeta":false,"id":14,"name":"AWS Certified AI Practitioner AIF-C01","provider":"Amazon","isMCOnly":false,"numberOfQuestions":154,"isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":17},"__N_SSP":true}