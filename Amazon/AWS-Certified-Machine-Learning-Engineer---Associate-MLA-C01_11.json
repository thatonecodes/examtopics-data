{"pageProps":{"questions":[{"id":"IqV4LlUflvM5hKZbbpi7","topic":"1","unix_timestamp":1732674720,"question_text":"A company has trained and deployed an ML model by using Amazon SageMaker. The company needs to implement a solution to record and monitor all the API call events for the SageMaker endpoint. The solution also must provide a notification when the number of API call events breaches a threshold.\nWhich solution will meet these requirements?","answer":"C","answers_community":["C (82%)","D (18%)"],"question_images":[],"choices":{"D":"Add the Invocations metric to an Amazon CloudWatch dashboard for monitoring. Set up a CloudWatch alarm to provide notification when the threshold is breached.","B":"Use SageMaker Debugger to track the inferences and to report metrics. Use the tensor_variance built-in rule to provide a notification when the threshold is breached.","A":"Use SageMaker Debugger to track the inferences and to report metrics. Create a custom rule to provide a notification when the threshold is breached.","C":"Log all the endpoint invocation API events by using AWS CloudTrail. Use an Amazon CloudWatch dashboard for monitoring. Set up a CloudWatch alarm to provide notification when the threshold is breached."},"answer_description":"","discussion":[{"content":"Selected Answer: C\nI pick C. The company needs to implement a solution to record and monitor all the API call events for the SageMaker endpoint. Its needs to RECORD all events.","timestamp":"1732674720.0","poster":"a4002bd","comment_id":"1318394","upvote_count":"6"},{"content":"Selected Answer: C\nC. CloudTrail + CloudWatch dashboard + CloudWatch alarm\n\n ✅ Correcto.\n\n AWS CloudTrail captura todos los eventos de API, incluidas las invocaciones a endpoints de SageMaker (InvokeEndpoint).\n\n CloudWatch puede procesar estos logs para generar métricas personalizadas.\n\n Puedes usar un alarm de CloudWatch para notificar cuando el número de eventos supera un umbral.\n\n Esto cubre tanto registro como notificación","comment_id":"1414060","poster":"eesa","upvote_count":"1","timestamp":"1743403380.0"},{"poster":"eesa","timestamp":"1742567580.0","upvote_count":"1","content":"Selected Answer: C\n✅ Breakdown of the correct answer:\nCloudTrail:\n\n Logs all SageMaker API calls, including InvokeEndpoint.\n Provides auditing and visibility into who called the endpoint, when, and with what parameters.\n Essential for tracking all invocation events (as required).\n\nCloudWatch Dashboard + Alarm:\n\n Use a CloudWatch dashboard to monitor invocation patterns and metrics.\n Set up an alarm based on metrics like the number of invocations (from CloudTrail logs or the Invocations metric) to trigger notifications when thresholds are breached.","comment_id":"1401590"},{"timestamp":"1737952560.0","comment_id":"1347228","upvote_count":"1","poster":"abrarjahin","content":"Selected Answer: D\nCloud trail is not an option for real time solution","comments":[{"poster":"Certified101","upvote_count":"1","content":"Neither is cloudwatch, its not real time.","comment_id":"1352315","timestamp":"1738837740.0"}]},{"comment_id":"1329419","poster":"lyndonZhao","upvote_count":"1","content":"Selected Answer: D\nCloudWatch Invocations metric: This metric tracks the number of API calls made to a SageMaker endpoint.\nBy adding this metric to a CloudWatch dashboard and setting up an alarm, you can monitor the number of API calls and receive notifications when the threshold is breached.","timestamp":"1734694320.0"},{"content":"Selected Answer: C\nSageMaker endpoint API calls → Record with CloudTrail → Monitor metrics in CloudWatch → CloudWatch alarm for notifications","poster":"Saransundar","timestamp":"1733394060.0","upvote_count":"1","comment_id":"1322310"}],"isMC":true,"url":"https://www.examtopics.com/discussions/amazon/view/152091-exam-aws-certified-machine-learning-engineer-associate-mla/","question_id":51,"answer_images":[],"timestamp":"2024-11-27 03:32:00","exam_id":27,"answer_ET":"C"},{"id":"A7phqdhZEJcLy1F6zK4R","question_text":"A company has AWS Glue data processing jobs that are orchestrated by an AWS Glue workflow. The AWS Glue jobs can run on a schedule or can be launched manually.\nThe company is developing pipelines in Amazon SageMaker Pipelines for ML model development. The pipelines will use the output of the AWS Glue jobs during the data processing phase of model development. An ML engineer needs to implement a solution that integrates the AWS Glue jobs with the pipelines.\nWhich solution will meet these requirements with the LEAST operational overhead?","unix_timestamp":1732684980,"topic":"1","exam_id":27,"question_id":52,"isMC":true,"timestamp":"2024-11-27 06:23:00","answer_ET":"C","choices":{"C":"Use Callback steps in SageMaker Pipelines to start the AWS Glue workflow and to stop the pipelines until the AWS Glue jobs finish running.","D":"Use Amazon EventBridge to invoke the pipelines and the AWS Glue jobs in the desired order.","B":"Use processing steps in SageMaker Pipelines. Configure inputs that point to the Amazon Resource Names (ARNs) of the AWS Glue jobs.","A":"Use AWS Step Functions for orchestration of the pipelines and the AWS Glue jobs."},"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/152099-exam-aws-certified-machine-learning-engineer-associate-mla/","discussion":[{"content":"Selected Answer: C\n✅ Explanation:\nSageMaker Pipelines + AWS Glue Integration Goal:\n\nYou want SageMaker Pipelines to wait for AWS Glue jobs to finish, since their outputs are needed during the model development phase. You also want to keep operational overhead low.\nWhy Callback steps are the best option:\n\n Callback steps in SageMaker Pipelines allow you to pause the pipeline execution until an external process completes.\n You can:\n Use the callback step to trigger an AWS Glue workflow (or job).\n Use a Lambda function or a service like EventBridge or Step Functions to report back to SageMaker when the Glue job completes.\n This approach provides tight integration while maintaining low operational overhead—you don’t need to build a whole orchestration layer.","comment_id":"1401592","poster":"eesa","upvote_count":"1","timestamp":"1742567820.0"},{"poster":"Saransundar","content":"Selected Answer: C\nhttps://sagemaker-examples.readthedocs.io/en/latest/sagemaker-pipelines/tabular/custom_callback_pipelines_step/sagemaker-pipelines-callback-step.html This shows how to use the Callback Step and how to include a Glue ETL job as part of a SageMaker ML pipeline.","comment_id":"1322307","timestamp":"1733393340.0","upvote_count":"1"},{"poster":"Wonjin7","comment_id":"1320893","timestamp":"1733135760.0","upvote_count":"1","content":"Selected Answer: B\nI think it's B when I consider 'LEAST operational overhead'."},{"comment_id":"1319548","poster":"Linux_master","content":"Selected Answer: C\nhttps://aws.amazon.com/blogs/machine-learning/extend-amazon-sagemaker-pipelines-to-include-custom-steps-using-callback-steps/","timestamp":"1732857180.0","upvote_count":"2"},{"poster":"GiorgioGss","comment_id":"1318921","timestamp":"1732743900.0","content":"Selected Answer: C\nLEAST effort:\nhttps://aws.amazon.com/blogs/machine-learning/extend-amazon-sagemaker-pipelines-to-include-custom-steps-using-callback-steps/\nThe example is exactly for the same use-case as the question.","upvote_count":"2"},{"timestamp":"1732684980.0","upvote_count":"1","content":"Selected Answer: B\nThis approach allows you to directly integrate the outputs of AWS Glue jobs into SageMaker Pipelines, leveraging the processing steps to handle the data. It minimizes additional orchestration overhead and keeps the workflow streamlined within SageMaker Pipelines","comment_id":"1318433","poster":"a4002bd"}],"answer_images":[],"answer_description":"","answer":"C","answers_community":["C (75%)","B (25%)"]},{"id":"dFX4DiLbGGRBNARFO126","answer_ET":"A","discussion":[{"upvote_count":"1","poster":"Saransundar","timestamp":"1733392140.0","content":"Selected Answer: A\nAmazon Redshift database → Sensitive data → Dynamic Data Masking → Query-time masking for data scientist → No transformation or additional storage → Least effort","comment_id":"1322303"},{"upvote_count":"2","comment_id":"1318922","poster":"GiorgioGss","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/redshift/latest/dg/t_ddm.html\nLEAST effort leads to A.","timestamp":"1732744260.0"}],"question_text":"A company is using an Amazon Redshift database as its single data source. Some of the data is sensitive.\nA data scientist needs to use some of the sensitive data from the database. An ML engineer must give the data scientist access to the data without transforming the source data and without storing anonymized data in the database.\nWhich solution will meet these requirements with the LEAST implementation effort?","answer_description":"","topic":"1","answer":"A","question_id":53,"isMC":true,"answers_community":["A (100%)"],"choices":{"D":"Unload the Amazon Redshift data to Amazon S3. Create an AWS Glue job to anonymize the data. Share the dataset with the data scientist.","A":"Configure dynamic data masking policies to control how sensitive data is shared with the data scientist at query time.","B":"Create a materialized view with masking logic on top of the database. Grant the necessary read permissions to the data scientist.","C":"Unload the Amazon Redshift data to Amazon S3. Use Amazon Athena to create schema-on-read with masking logic. Share the view with the data scientist."},"question_images":[],"unix_timestamp":1732744260,"exam_id":27,"url":"https://www.examtopics.com/discussions/amazon/view/152196-exam-aws-certified-machine-learning-engineer-associate-mla/","answer_images":[],"timestamp":"2024-11-27 22:51:00"},{"id":"hb5xaLGtEE5u42IRvdHa","choices":{"D":"Use SageMaker Debugger built-in rules to monitor the training job. Configure the rules to initiate the predefined actions.","C":"Expand the metrics in Amazon CloudWatch to include the gradients in each training step. Use the metrics to invoke an AWS Lambda function to initiate the predefined actions.","B":"Use Amazon CloudWatch default metrics to gain insights about the training job. Use the metrics to invoke an AWS Lambda function to initiate the predefined actions.","A":"Use TensorBoard to monitor the training job. Publish the findings to an Amazon Simple Notification Service (Amazon SNS) topic. Create an AWS Lambda function to consume the findings and to initiate the predefined actions."},"isMC":true,"question_id":54,"exam_id":27,"question_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/152197-exam-aws-certified-machine-learning-engineer-associate-mla/","answer_description":"","unix_timestamp":1732744560,"answer_images":[],"answer":"D","discussion":[{"poster":"Saransundar","comment_id":"1322302","upvote_count":"2","content":"Selected Answer: D\nSageMaker Debugger → Built-in rules → Monitor training (vanishing gradients, GPU use, overfitting) → Predefined actions → Low overhead","timestamp":"1733391900.0"},{"comment_id":"1318923","upvote_count":"2","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html","timestamp":"1732744560.0","poster":"GiorgioGss"}],"question_text":"An ML engineer is using a training job to fine-tune a deep learning model in Amazon SageMaker Studio. The ML engineer previously used the same pre-trained model with a similar dataset. The ML engineer expects vanishing gradient, underutilized GPU, and overfitting problems.\nThe ML engineer needs to implement a solution to detect these issues and to react in predefined ways when the issues occur. The solution also must provide comprehensive real-time metrics during the training.\nWhich solution will meet these requirements with the LEAST operational overhead?","answers_community":["D (100%)"],"timestamp":"2024-11-27 22:56:00","answer_ET":"D"},{"id":"inCQtx2tzWOtDX0gKn0G","answers_community":["D (100%)"],"topic":"1","choices":{"A":"Set up SageMaker Debugger and create a custom rule.","D":"Set up shadow testing with a shadow variant of the new model.","C":"Set up blue/green deployments with canary traffic shifting.","B":"Set up blue/green deployments with all-at-once traffic shifting."},"exam_id":27,"answer_ET":"D","question_id":55,"unix_timestamp":1732744620,"discussion":[{"timestamp":"1733391720.0","comment_id":"1322300","poster":"Saransundar","content":"Selected Answer: D\nShadow testing is a technique used to evaluate a new model's performance by running it alongside the current production model, processing the same live data but without affecting production outcomes.","upvote_count":"2"},{"poster":"GiorgioGss","comment_id":"1318924","upvote_count":"1","timestamp":"1732744620.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/shadow-tests-create.html"}],"answer":"D","timestamp":"2024-11-27 22:57:00","answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/152198-exam-aws-certified-machine-learning-engineer-associate-mla/","isMC":true,"question_text":"A credit card company has a fraud detection model in production on an Amazon SageMaker endpoint. The company develops a new version of the model. The company needs to assess the new model's performance by using live data and without affecting production end users.\nWhich solution will meet these requirements?","question_images":[]}],"exam":{"numberOfQuestions":106,"isMCOnly":false,"lastUpdated":"11 Apr 2025","isImplemented":true,"isBeta":false,"id":27,"provider":"Amazon","name":"AWS Certified Machine Learning Engineer - Associate MLA-C01"},"currentPage":11},"__N_SSP":true}