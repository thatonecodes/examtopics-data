{"pageProps":{"questions":[{"id":"HV3WGfvvBhZ1Ics3mNAi","unix_timestamp":1682202300,"exam_id":24,"discussion":[{"comment_id":"877667","timestamp":"1682202300.0","content":"Selected Answer: D\nThe best caching strategy for populating real-time dashboards using Amazon ElastiCache would be a write-through caching strategy. In this strategy, when new data is written to the database, it is also written to the cache. This ensures that the most current data is always available in the cache for the real-time dashboards to access, reducing the latency of the data retrieval. Additionally, using a write-through cache ensures that data consistency is maintained between the database and the cache, as any changes to the data are written to both locations simultaneously.","poster":"MrTee","upvote_count":"16"},{"comment_id":"1332971","upvote_count":"2","content":"Selected Answer: D\nA) Eliminated\n\nIn a read-through cache, when an application tries to retrieve data:\nIf the data is not available in the cache, the cache retrieves it from the database, stores it in the cache, and returns it to the application.\nIf the data is available in the cache, it is returned directly.\nThe cache is updated only when data is requested, which could result in outdated data being served to real-time dashboards if no recent read request has occurred.","comments":[{"content":"B) Eliminated\n\nIn a write-behind cache, data is written to the cache first, and the database is updated asynchronously (in the background).\nThis caching strategy prioritizes write performance but risks data loss in the event of a failure because the cache may not yet have updated the database.\nFor real-time dashboards, there is no guarantee that the cache is always up-to-date because the data is updated asynchronously.","poster":"sumanshu","comment_id":"1332972","comments":[{"comment_id":"1332973","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"1332974","poster":"sumanshu","timestamp":"1735392600.0","content":"D) Correct\nIn a write-through cache, every write operation to the database is immediately mirrored in the cache.\nThis ensures that the cache always contains the most up-to-date data and is ideal for scenarios where real-time consistency is required, such as updating dashboards."}],"content":"C) Eliminated\n\nIn a lazy-loading cache, the data is loaded into the cache only when requested.\nIf the data is not in the cache (a \"cache miss\"), it is fetched from the database, loaded into the cache, and returned to the application.\nWhile this reduces unnecessary caching, it does not proactively update the cache. Therefore, data in the cache may become stale, which is unsuitable for real-time dashboards.","timestamp":"1735392600.0","poster":"sumanshu"}],"timestamp":"1735392540.0","upvote_count":"1"}],"poster":"sumanshu","timestamp":"1735392540.0"},{"upvote_count":"1","comment_id":"1305489","content":"Selected Answer: D\nthe keyword => real-time","poster":"Saudis","timestamp":"1730386080.0"},{"comment_id":"1263499","poster":"tirthyakamaldasgupta","content":"When using a write-through cache strategy, the cache is updated in real-time alongside the database. This ensures that the cached data remains consistent with the underlying database. According to AWS best practices, this approach pushes data into the cache at the time it is written to the database, reducing the risk of serving stale data.\nIn contrast, option A (a read-through cache strategy) may result in stale data, particularly if the cache has a time-to-live (TTL) setting that allows data to remain in the cache longer than it remains accurate in the database. This can be problematic for real-time dashboards that require up-to-date information. For these reasons, I opted for option D.\n\nhttps://aws.amazon.com/caching/best-practices/#:~:text=Write%2Dthrough,also%20pushed%20into%20the%20cache.\n\nPlease correct me if my understanding is incorrect, as I am still learning.","upvote_count":"1","timestamp":"1723294860.0"},{"content":"Selected Answer: D\nD is the correct answer.","poster":"65703c1","upvote_count":"1","comment_id":"1216096","timestamp":"1716422880.0"},{"upvote_count":"1","poster":"Walker17","timestamp":"1707216120.0","content":"B. Write Behind Cache.","comment_id":"1142034"},{"comment_id":"1124455","poster":"SerialiDr","content":"Selected Answer: D\nD. A write-through cache: A write-through caching strategy immediately writes data to both the cache and the database at the same time. This approach ensures that the cache always contains the most recent data, making it highly suitable for applications that require up-to-date information, such as real-time dashboards.","upvote_count":"2","timestamp":"1705432620.0"},{"timestamp":"1701558180.0","content":"Selected Answer: C\nChatGPT:C","poster":"tqiu654","upvote_count":"1","comment_id":"1086456"},{"comment_id":"916174","comments":[{"content":"I agree. I think it's A because D is better option when you need data to be consistent and highly available since data is always up to date but as Prem28 says it lags behind on latency when compared to read-through. What I get from the question is they need strategy for \"real-time\" dashboards --> reduction of latency not accuracy or consistent data","upvote_count":"1","poster":"[Removed]","timestamp":"1702354320.0","comment_id":"1094106"}],"content":"ans- A\n\nOption D, a write-through cache, is incorrect because it would not meet the requirement of populating real-time dashboards. A write-through cache writes data to the cache and the database at the same time. This means that the data in the cache would always be up-to-date, but it would also mean that the cache would always be lagging behind the database. This would cause a delay in populating real-time dashboards.","timestamp":"1686050280.0","poster":"Prem28","upvote_count":"1"},{"poster":"loctong","timestamp":"1684311960.0","comment_id":"899864","content":"Selected Answer: D\nA write-through cache strategy involves writing data to both the cache and the underlying database simultaneously. When data is updated or inserted into the database, it is also stored or updated in the cache to ensure that the cache remains up-to-date with the latest data.","upvote_count":"2"}],"timestamp":"2023-04-23 00:25:00","answer_description":"","question_id":31,"choices":{"A":"A read-through cache","D":"A write-through cache","B":"A write-behind cache","C":"A lazy-loading cache"},"question_text":"A developer is integrating Amazon ElastiCache in an application. The cache will store data from a database. The cached data must populate real-time dashboards.\n\nWhich caching strategy will meet these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/107063-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer_ET":"D","question_images":[],"answer_images":[],"answers_community":["D (96%)","4%"],"isMC":true,"answer":"D","topic":"1"},{"id":"4BEkrVp1Gv43dPIytbuS","url":"https://www.examtopics.com/discussions/amazon/view/107064-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer_ET":"A","unix_timestamp":1682202660,"discussion":[{"timestamp":"1682202660.0","content":"Selected Answer: A\nCreate a Lambda layer to store the external library. Configure the Lambda function to use the layer. This will allow the developer to make the external library available to the Lambda execution environment without having to include it in the Lambda package, which will reduce the Lambda package space. Using a Lambda layer is a simple and straightforward solution that requires minimal operational overhead.","upvote_count":"13","comment_id":"877670","poster":"MrTee"},{"poster":"sumanshu","upvote_count":"1","comment_id":"1332978","content":"Selected Answer: A\nLayers are managed separately from the Lambda function.\nThey reduce the size of the deployment package.\nLayers are easy to use, and there is no need for complex infrastructure or manual management.","timestamp":"1735393200.0"},{"content":"Option B is correct because it is straightforward with lesser operation overhead than managing layers. Option A and C are incorrect. While Option A approach allows you to separate library from your function code, it introduces some operational overhead in managing layers.\nOption C is simple but doesn't separate library from your function code.","timestamp":"1722991080.0","poster":"Saurabh04","comment_id":"1261878","upvote_count":"1"},{"comments":[{"poster":"frangesk","comment_id":"1270699","timestamp":"1724333040.0","content":"Do you remember the answer?","upvote_count":"1"}],"comment_id":"1231698","timestamp":"1718596140.0","poster":"tsangckl","upvote_count":"1","content":"This appear at 17 Jun exam"},{"upvote_count":"1","poster":"65703c1","comment_id":"1216100","content":"Selected Answer: A\nA is the correct answer.","timestamp":"1716423180.0"},{"comment_id":"1154904","content":"Selected Answer: A\nYou can add up to five layers to a Lambda function. The total unzipped size of the function and all layers cannot exceed the unzipped deployment package size quota of 250 MB. For more information, see Lambda quotas.","poster":"KillThemWithKindness","timestamp":"1708452840.0","upvote_count":"4"},{"comment_id":"1124478","poster":"SerialiDr","upvote_count":"2","content":"Selected Answer: A\nA. Create a Lambda layer to store the external library. Configure the Lambda function to use the layer: This is the most suitable solution. Lambda layers allow you to include libraries and other dependencies without including them in the deployment package of your Lambda function. By creating a layer with the external library and configuring the Lambda function to use this layer, the developer can easily manage and update the library independently of the Lambda function code, reducing the package size and operational overhead.","timestamp":"1705434960.0"},{"poster":"CalvinL4","comment_id":"1114236","timestamp":"1704426600.0","content":"One lambda layer only allows 50 mb for storage. The file is 100 MB. So I will vote for D unless the library can break down into less than 5 layers.","upvote_count":"1"},{"poster":"loctong","timestamp":"1684312140.0","upvote_count":"2","comment_id":"899868","content":"Selected Answer: A\nBy creating a Lambda layer, you can separate the external library from the Lambda function code itself and make it available to multiple functions. This approach offers the following benefits:"},{"poster":"dan80","comment_id":"884386","timestamp":"1682777820.0","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html","upvote_count":"3"}],"question_images":[],"timestamp":"2023-04-23 00:31:00","answer_description":"","question_id":32,"answer":"A","choices":{"B":"Create an Amazon S3 bucket. Upload the external library into the S3 bucket. Mount the S3 bucket folder in the Lambda function. Import the library by using the proper folder in the mount point.","C":"Load the external library to the Lambda function's /tmp directory during deployment of the Lambda package. Import the library from the /tmp directory.","D":"Create an Amazon Elastic File System (Amazon EFS) volume. Upload the external library to the EFS volume. Mount the EFS volume in the Lambda function. Import the library by using the proper folder in the mount point.","A":"Create a Lambda layer to store the external library. Configure the Lambda function to use the layer."},"topic":"1","question_text":"A developer is creating an AWS Lambda function. The Lambda function needs an external library to connect to a third-party solution. The external library is a collection of files with a total size of 100 MB. The developer needs to make the external library available to the Lambda execution environment and reduce the Lambda package space.\n\nWhich solution will meet these requirements with the LEAST operational overhead?","exam_id":24,"answer_images":[],"answers_community":["A (100%)"],"isMC":true},{"id":"xlUaYzDUu7VbMPwv6GB6","answer":"C","isMC":true,"unix_timestamp":1682203500,"timestamp":"2023-04-23 00:45:00","answers_community":["C (49%)","A (38%)","14%"],"exam_id":24,"answer_description":"","discussion":[{"comments":[{"poster":"awsdummie","comment_id":"889629","upvote_count":"5","content":"C is incorrect, after passing health checks the elastic Beanstalk transfers them to the original Auto Scaling group. No testing or platform update is done.","timestamp":"1683230880.0"},{"upvote_count":"3","timestamp":"1684450260.0","content":"I would agree that option A can affect the cost, but cost is not the issue. The question is asking for zero downtime. I believe the answer is option A","poster":"yeacuz","comment_id":"901542"}],"comment_id":"877673","content":"Selected Answer: C\nOption C is the correct solution that meets the requirements. Performing an immutable update to deploy the new application code to new EC2 instances and serving traffic to the new instances after they pass health checks will ensure zero downtime for the application.\n\nOption A would work but cloning the production environment to a different platform version will result in a longer deployment time and can impact the cost of the environment.","timestamp":"1682203500.0","upvote_count":"23","poster":"MrTee"},{"timestamp":"1687235580.0","poster":"gagol14","content":"Selected Answer: A\nNot C: While an immutable update can ensure zero downtime during the deployment process, it doesn't account for updating the Elastic Beanstalk platform version.","comment_id":"928145","upvote_count":"9"},{"timestamp":"1741940160.0","comment_id":"1395548","upvote_count":"1","content":"Selected Answer: A\nOption A creates a completely separate environment with the newer Node.js version, deploys the new code there, and allows for testing without affecting the production environment. Once verified, you simply swap the URLs","poster":"Artemiy"},{"comment_id":"1332980","upvote_count":"1","poster":"sumanshu","timestamp":"1735393740.0","content":"Selected Answer: C\nA) Eliminated - This solution meets the requirement of zero downtime but may have additional resource and cost overhead.\n\nB) Eliminated - All-at-once deployment means that all instances are updated at the same time, which would result in downtime during the deployment.\n\nC) Correct - Immutable updates ensure that new EC2 instances are created, and only healthy instances will serve traffic. The old EC2 instances are not affected until the new instances are confirmed to be healthy and live.\n\nD) Eliminated - Rolling deployments help ensure that some EC2 instances are always running the old code and serving traffic while others are being updated."},{"poster":"MasoudK","timestamp":"1727814780.0","upvote_count":"1","comment_id":"1292109","content":"Option A is Correct not C: By cloning the production environment to a different platform version, you create a separate environment where you can safely deploy and test the new application code and platform version without affecting the live production environment.• Option C (Immutable update): While immutable updates ensure zero downtime by deploying to new instances, they do not address the need to update the Elastic Beanstalk platform version. Additionally, this approach can be more resource-intensive and costly."},{"timestamp":"1726222560.0","upvote_count":"1","content":"Selected Answer: C\nAns is c","comment_id":"1283101","poster":"Saudis"},{"poster":"65703c1","content":"Selected Answer: C\nC is the correct answer.","upvote_count":"1","comment_id":"1216105","timestamp":"1716423300.0"},{"poster":"ibratoev","timestamp":"1711548960.0","content":"It is A: https://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config","comment_id":"1184160","upvote_count":"3"},{"content":"This question must be true for 2 options because C & D are both correct","timestamp":"1710652860.0","comment_id":"1175595","upvote_count":"1","poster":"KarBiswa"},{"content":"Selected Answer: D\nhttps://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","comment_id":"1170366","poster":"KarBiswa","timestamp":"1710079620.0","upvote_count":"1"},{"upvote_count":"3","content":"Selected Answer: C\nThe solutions that best meet the requirements for zero downtime are:\n\nA. Clone the production environment to a different platform version. Deploy the new application code, and test it. Swap the environment URLs upon verification.\nC. Perform an immutable update to deploy the new application code to new EC2 instances. Serve traffic to the new instances after they pass health checks.\nBoth options A and C provide robust strategies for deploying updates with zero downtime, allowing for thorough testing in an isolated environment before directing production traffic to the new setup.","poster":"SerialiDr","timestamp":"1705482660.0","comment_id":"1124816"},{"poster":"Certified101","content":"Selected Answer: A\nNot C: tt doesn't account for updating the Elastic Beanstalk platform version. This would affect both the live and test environments.\n\nIts also best practise to have 2 seperate environments for production and test and there is no mention of cost optimisation here.","timestamp":"1702411440.0","upvote_count":"3","comment_id":"1094916"},{"timestamp":"1701559440.0","comment_id":"1086466","upvote_count":"2","poster":"tqiu654","content":"Selected Answer: A\nChatGPT:A"},{"comment_id":"1043623","content":"Selected Answer: C\nA & C both works for given scenario but C does it more feasibly for Elastic Beanstalk with zero downtime.","upvote_count":"1","timestamp":"1697302380.0","poster":"Rameez1"},{"upvote_count":"2","comments":[{"poster":"[Removed]","comment_id":"1094115","content":"Option A offers quick rollback too... did some research and cloning is same as blue/green deployments. with that said, I think the answer is A","upvote_count":"1","timestamp":"1702356660.0"},{"comment_id":"1123913","upvote_count":"1","poster":"CrescentShared","content":"It's a downtime if test fails and rollback.","timestamp":"1705386240.0"}],"content":"Selected Answer: C\nKey terminology in question is \"Test\". So it should be immutable for quick rollback in case of test not working.","comment_id":"990144","poster":"stilloneway","timestamp":"1692972780.0"},{"comment_id":"988597","content":"Selected Answer: C\nExplanation:\n\nImmutable Update with Elastic Beanstalk:\nWith an immutable update, Elastic Beanstalk provisions new instances with the updated code while keeping the existing instances running. The traffic is shifted gradually to the new instances after they pass health checks, ensuring that there is no downtime during the deployment. If any issue arises during the deployment, traffic is still being served by the existing instances.","upvote_count":"4","poster":"love777","timestamp":"1692816000.0"},{"comments":[{"comment_id":"985812","timestamp":"1692538140.0","content":"I take this back. I'm going with A\n\n\"However, you can avoid this downtime by deploying the new version to a separate environment. The existing environment’s configuration is copied and used to launch the green environment with the new version of the application. The new green environment will have its own URL. When it’s time to promote the green environment to serve production traffic, you can use Elastic Beanstalk's Swap Environment URLs feature.\"\n\nhttps://docs.aws.amazon.com/whitepapers/latest/blue-green-deployments/swap-the-environment-of-an-elastic-beanstalk-application.html","upvote_count":"1","poster":"Naj_64"}],"comment_id":"985802","timestamp":"1692537720.0","poster":"Naj_64","content":"Selected Answer: D\nScreenshot of Step 4 of Method 1 in the link:\nhttps://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config\n\n\"...your application is unavailable during the update. To keep at least one instance in service during the update, enable rolling updates\"","upvote_count":"2"},{"comment_id":"983902","content":"Selected Answer: A\nA is the answer. Sorry about the double post ...\nhttps://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config","poster":"MG1407","timestamp":"1692295920.0","upvote_count":"4"},{"comment_id":"983901","upvote_count":"2","poster":"MG1407","content":"Selected Answer: D\nCan't be clearer than this ... https://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config","timestamp":"1692295800.0"},{"content":"Selected Answer: A\nA is the correct solution here. From https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html, \"A blue/green deployment is also required if you want to update an environment to an incompatible platform version.\". An immutable deployment would ensure zero downtime, but the new instances launched would have the same platform version as before.","poster":"redfivedog","upvote_count":"2","comment_id":"964359","timestamp":"1690434600.0"},{"upvote_count":"3","timestamp":"1690308060.0","comment_id":"962983","poster":"bobo777","content":"Selected Answer: A\nA developer also needs to update to a new platform version and it's more likely a new major version of node.js. To update to the new major version there is only one method and it is a blue/green deployment by creating (cloning) a new environment with the latest platform version. Then deploy a new app version to it. Test it, then swap the env URL without downtime."},{"timestamp":"1688039580.0","upvote_count":"3","content":"Selected Answer: D\nOn the step 4 of Method 1 in the link. you will see it clearly that rolling update is perfect fit with this question. Of course with zero downtime.\n\nhttps://docs.amazonaws.cn/en_us/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.config","poster":"Phongsanth","comment_id":"938021","comments":[{"comment_id":"985798","content":"+1\n\n\"...your application is unavailable during the update. To keep at least one instance in service during the update, enable rolling updates\"","poster":"Naj_64","upvote_count":"1","timestamp":"1692537600.0"}]},{"comment_id":"901543","content":"Selected Answer: A\nOption A is referring to Blue/Green deployments and will fulfill the requirements of the question (https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html)","poster":"yeacuz","upvote_count":"4","timestamp":"1684450320.0"},{"poster":"loctong","comment_id":"899867","upvote_count":"2","content":"Selected Answer: D\nPerforming an immutable update involves creating new EC2 instances with the updated code and the newer version of Node.js, and then swapping the traffic to the new instances once they pass health checks. This approach ensures zero downtime as the existing instances continue to serve traffic until the new instances are ready.","timestamp":"1684312080.0"},{"poster":"awsdummie","timestamp":"1683230940.0","content":"Option A","upvote_count":"5","comment_id":"889631"},{"comments":[{"comment_id":"943168","upvote_count":"1","timestamp":"1688506440.0","poster":"qwan","content":"Option D states \" Apply the code to a subset of EC2 instances until the tests pass\". Subset, not all EC2 instances. So, if deployment fails, you still have some EC2 instances running the old application code. So, no downtime."}],"upvote_count":"2","poster":"MrTee","comment_id":"877675","content":"Option B and D both involve deploying the new application code to the existing EC2 instances, which can result in downtime if the deployment fails. Redeploying the previous code after a failed deployment can also result in downtime.","timestamp":"1682203680.0"}],"question_id":33,"answer_images":[],"answer_ET":"C","choices":{"B":"Deploy the new application code in an all-at-once deployment to the existing EC2 instances. Test the code. Redeploy the previous code if verification fails.","A":"Clone the production environment to a different platform version. Deploy the new application code, and test it. Swap the environment URLs upon verification.","D":"Use a rolling deployment for the new application code. Apply the code to a subset of EC2 instances until the tests pass. Redeploy the previous code if the tests fail.","C":"Perform an immutable update to deploy the new application code to new EC2 instances. Serve traffic to the new instances after they pass health checks."},"question_images":[],"question_text":"A company has a front-end application that runs on four Amazon EC2 instances behind an Elastic Load Balancer (ELB) in a production environment that is provisioned by AWS Elastic Beanstalk. A developer needs to deploy and test new application code while updating the Elastic Beanstalk platform from the current version to a newer version of Node.js. The solution must result in zero downtime for the application.\n\nWhich solution meets these requirements?","url":"https://www.examtopics.com/discussions/amazon/view/107066-exam-aws-certified-developer-associate-dva-c02-topic-1/","topic":"1"},{"id":"aeDWjw5mEZ3m1hz92d3E","answer_images":[],"choices":{"D":"Use the aws lambda invoke command with a test event during the CIICD process.","A":"Create an AWS CloudFormation template that creates an SQS queue and deploys the Lambda function. Create a stack from the template during the CI/CD process. Invoke the deployed function. Verify the output.","B":"Create an SQS event for tests. Use a test that consumes messages from the SQS queue during the function's Cl/CD process.","C":"Create an SQS queue for tests. Use this SQS queue in the application's unit test. Run the unit tests during the CI/CD process."},"question_text":"A developer is creating an AWS Lambda function. The Lambda function will consume messages from an Amazon Simple Queue Service (Amazon SQS) queue. The developer wants to integrate unit testing as part of the function's continuous integration and continuous delivery (CI/CD) process.\n\nHow can the developer unit test the function?","isMC":true,"answers_community":["D (45%)","C (38%)","B (17%)"],"exam_id":24,"unix_timestamp":1686976320,"question_images":[],"answer_description":"","topic":"1","timestamp":"2023-06-17 06:32:00","url":"https://www.examtopics.com/discussions/amazon/view/112424-exam-aws-certified-developer-associate-dva-c02-topic-1/","answer_ET":"D","answer":"D","discussion":[{"timestamp":"1687235700.0","upvote_count":"16","comment_id":"928148","poster":"gagol14","content":"Selected Answer: C\nUnit testing is a type of testing that verifies the correctness of individual units of source code, typically functions or methods. When unit testing a Lambda function that interacts with Amazon SQS, you can create a separate test SQS queue that the Lambda function interacts with during testing. You would then validate the behavior of the function based on its interactions with the test queue. This approach isolates the function's behavior from the rest of the system, which is a key principle of unit testing.\n\nOption A is incorrect because AWS CloudFormation is typically used for infrastructure deployment, not for unit testing.\n\nOption B is incorrect because it does not actually test the function; it only creates an event.\n\nOption D is incorrect because the 'aws lambda invoke' command is used to manually trigger a Lambda function, but doesn't necessarily facilitate testing the function's behavior when consuming messages from an SQS queue."},{"poster":"redfivedog","content":"Selected Answer: D\nD is correct here. Both B and C are integration tests as they are using an actual SQS queue in the tests and not mocking it out.","comment_id":"964367","upvote_count":"13","timestamp":"1690435320.0"},{"upvote_count":"1","comment_id":"1346315","poster":"mooncake1","timestamp":"1737776280.0","content":"Selected Answer: D\nThose who select C and still think they are right - Should study more about unit test & integrate testing before AWS"},{"poster":"sumanshu","content":"Selected Answer: D\nA) Eliminated - This approach involves creating and destroying AWS resources (SQS, Lambda) for each test, which increases the time, complexity, and potential costs associated with running tests.\n\n\nB) Eliminated - t involves real AWS resources (SQS)\n\nC) Eliminated - Even though it's meant for testing, you're still using an actual AWS service (SQS) to conduct the test, making it less of a unit test and more of an integration test.\n\nD) Correct - You use the aws lambda invoke command to invoke the Lambda function directly during the test process, without needing to rely on actual resources like an SQS queue.","comment_id":"1332982","upvote_count":"1","timestamp":"1735394040.0"},{"timestamp":"1733955300.0","content":"Selected Answer: C\nUnit testing is a type of testing that verifies the correctness of individual units of source code, typically functions or methods","poster":"ShakthiGCP","comment_id":"1325287","upvote_count":"1"},{"comment_id":"1324003","timestamp":"1733742360.0","content":"Selected Answer: C\noption C seems more appropriate. As there is a clear isolation of test stage environment and it is staged prior to the deployment. \nOption D triggered manually and consuming from the same queue that was meant for the Production environment","upvote_count":"1","poster":"f271c23"},{"content":"Selected Answer: D\nIt's testing so option D seems more logic. The other options would put a message in SQS.","timestamp":"1731339900.0","upvote_count":"1","poster":"CloudChingon","comment_id":"1310177"},{"comment_id":"1252784","poster":"Anandesh","timestamp":"1721615760.0","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/lambda/latest/dg/testing-guide.html","upvote_count":"1"},{"comment_id":"1216114","content":"Selected Answer: D\nD is the correct answer.","upvote_count":"1","poster":"65703c1","timestamp":"1716424440.0"},{"comment_id":"1193526","timestamp":"1712820480.0","content":"Selected Answer: D\nIn the case of unit tests, whose objective is to isolate the tested unit, option D is the one that most isolates the unit.","poster":"Moralles","upvote_count":"1"},{"comment_id":"1175977","poster":"41eb566","timestamp":"1710696480.0","content":"Selected Answer: C\nTo unit test the AWS Lambda function that consumes messages from an Amazon SQS queue as part of the CI/CD process, the developer can follow option C:\n\nC. Create an SQS queue for tests. Use this SQS queue in the application's unit test. Run the unit tests during the CI/CD process.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1708454160.0","comment_id":"1154919","poster":"KillThemWithKindness","content":"Selected Answer: D\nIn production, our Lambda function code will directly access the AWS resources we defined in our function handler; however, in our unit tests we want to isolate our code and replace the AWS resources with simulations. This isolation facilitates running unit tests in an isolated environment to prevent accidental access to actual cloud resources.\n\nhttps://aws.amazon.com/blogs/devops/unit-testing-aws-lambda-with-python-and-mock-aws-services/"},{"poster":"SerialiDr","comment_id":"1124828","upvote_count":"3","content":"Selected Answer: D\nD. Use the aws lambda invoke command with a test event during the CI/CD process: This option is closer to what unit testing entails. The aws lambda invoke command can be used to invoke the Lambda function with a simulated event payload that mimics an SQS message. This allows the developer to test the function's logic and handling of SQS messages without needing an actual SQS queue. The test can focus on how the function processes the input and generates output, which is the essence of unit testing.","timestamp":"1705483260.0"},{"poster":"CrescentShared","comment_id":"1123915","timestamp":"1705386780.0","content":"Anybody find this question in the exam, please? The question itself looks so wrong to me, the action of testing the lambda function does not seem like a 'unit test' already... Isn't the unit test testing all the Classes inside the lambda function?","upvote_count":"2"},{"content":"Selected Answer: C\nC there should be a seperate isolated test enviroment \nD will only invoke the lambda and not test SQS polling.","poster":"Certified101","comment_id":"1094922","upvote_count":"2","timestamp":"1702411620.0"},{"timestamp":"1701559380.0","content":"Selected Answer: D\nChatGPT:D","comment_id":"1086465","upvote_count":"1","poster":"tqiu654"},{"content":"B.\nOption A (CloudFormation template for SQS queue and Lambda function) involves more of an integration test rather than a unit test. It's typically preferable to keep unit tests isolated and focused on the specific functionality of the function.\n\nOption C (Create an SQS queue for tests) might involve additional setup and cleanup steps, and it could introduce dependencies that impact the isolation of unit tests.\n\nOption D (aws lambda invoke command with a test event) is similar to Option B, but creating a test event is generally more flexible and allows for a clearer representation of the expected input to the Lambda function.","upvote_count":"3","poster":"ShawnWon","timestamp":"1700387640.0","comment_id":"1074557"},{"poster":"dilleman","content":"Selected Answer: D\nOption D is the only true unit test.","comment_id":"1042354","timestamp":"1697177940.0","upvote_count":"3"},{"comment_id":"988602","upvote_count":"7","poster":"love777","timestamp":"1692816240.0","content":"Selected Answer: B\nExplanation:\n\nOption B involves simulating the SQS event trigger for testing purposes. This is a common practice in AWS Lambda unit testing. Here's how it works:\n\nSQS Event for Tests: In your unit test code, you can create an SQS event object that simulates the event structure that Lambda receives when an SQS message is consumed. This event object will contain the necessary information, such as the message content, message attributes, etc.\n\nTesting Logic: You can then pass this event object to your Lambda function's handler function as if it were an actual SQS event. This allows you to test your Lambda function's logic as it would work in response to an SQS message.\n\nMocking Dependencies: During unit testing, you might want to mock any AWS service calls, such as SQS, to isolate your Lambda function's logic from external services."},{"poster":"r3mo","timestamp":"1690314600.0","upvote_count":"2","content":"Option B!\nOffers a practical and efficient way to unit test an AWS Lambda function consuming messages from an SQS queue. It provides an accurate representation of the actual event source, simplifies the testing process, integrates well with CI/CD pipelines, isolates production resources, and is cost-effective.","comment_id":"963080"},{"upvote_count":"2","timestamp":"1689686280.0","comment_id":"955457","content":"Selected Answer: D\nD, from Google Bard","poster":"nguyenta"},{"comment_id":"944482","timestamp":"1688634360.0","poster":"vicvega","content":"The idea of creating permanent, persistent AWS resources for a test that might take 3 seconds is an anti-pattern. During a CI/CD pipeline, resources should be spun up, used, and then torn down. Nothing should hang around after a CI/CD pipeline runs.\n\nDoes that not negate B and C?","upvote_count":"3"},{"comment_id":"938198","timestamp":"1688046600.0","poster":"Phongsanth","content":"Selected Answer: C\nI vote C.\nUnit test should be isolated. Check out in this link.\nhttps://aws.amazon.com/blogs/devops/unit-testing-aws-lambda-with-python-and-mock-aws-services/","upvote_count":"3"},{"upvote_count":"4","timestamp":"1687869480.0","comment_id":"935355","poster":"hexie","content":"Selected Answer: B\nB. And before explaining it I would like to ask you guys to use ChatGPT if you want, but don't take it as a source of truth and either use it's answers here, where people usually come to read USEFUL stuff and understand correctly what it's all about. Moderators should review those votes before approving it lol\n\nB option is ONE approach for unit testing AWS Lambda functions, since it involves creating a mock SQS event and passing it to the function to be tested. This will allow the function behavior to be tested in isolation, which is the aim of unit testing. :)\n\nC option is more like a integration test, not a unit test. That's all. :)"},{"poster":"patrick889","content":"chatGPT said C is correct","upvote_count":"3","comment_id":"925766","timestamp":"1686976320.0"}],"question_id":34},{"id":"GFBHuGUQjP34Gs4CX76Y","unix_timestamp":1679377500,"answer":"C","answers_community":["C (80%)","A (20%)"],"exam_id":24,"answer_description":"","timestamp":"2023-03-21 06:45:00","answer_ET":"C","url":"https://www.examtopics.com/discussions/amazon/view/103442-exam-aws-certified-developer-associate-dva-c02-topic-1/","question_text":"A company receives food orders from multiple partners. The company has a microservices application that uses Amazon API Gateway APIs with AWS Lambda integration. Each partner sends orders by calling a customized API that is exposed through API Gateway. The API call invokes a shared Lambda function to process the orders.\nPartners need to be notified after the Lambda function processes the orders. Each partner must receive updates for only the partner's own orders. The company wants to add new partners in the future with the fewest code changes possible.\nWhich solution will meet these requirements in the MOST scalable way?","choices":{"B":"Create a different Lambda function for each partner. Configure the Lambda function to notify each partner's service endpoint directly.","D":"Create one Amazon Simple Notification Service (Amazon SNS) topic. Subscribe all partners to the SNS topic.","C":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure the Lambda function to publish messages with specific attributes to the SNS topic. Subscribe each partner to the SNS topic. Apply the appropriate filter policy to the topic subscriptions.","A":"Create a different Amazon Simple Notification Service (Amazon SNS) topic for each partner. Configure the Lambda function to publish messages for each partner to the partner's SNS topic."},"discussion":[{"upvote_count":"12","comment_id":"845559","content":"Selected Answer: C\nC\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-message-filtering.html","timestamp":"1679377500.0","poster":"Untamables"},{"poster":"Bibay","content":"Selected Answer: C\nOption C is the most scalable way to meet the requirements. This solution allows for a single SNS topic to be used for all partners, which minimizes the need for code changes when adding new partners. By publishing messages with specific attributes to the SNS topic and applying the appropriate filter policy to the topic subscriptions, partners will only receive notifications for their own orders. This approach allows for a more flexible and scalable solution, where new partners can be added to the system with minimal changes to the existing codebase. Option A and D may not be scalable when there are a large number of partners, as creating a separate SNS topic for each partner or subscribing all partners to a single topic may not be feasible. Option B may result in a large number of Lambda functions that need to be managed separately.","upvote_count":"7","comment_id":"890718","timestamp":"1727238300.0"},{"content":"Selected Answer: C\nA) Eliminated - Every time a new partner is added, a new SNS topic needs to be created. This requires manual configuration and updates to the infrastructure.","timestamp":"1734749460.0","upvote_count":"1","poster":"sumanshu","comment_id":"1329784","comments":[{"comments":[{"poster":"sumanshu","content":"C) Correct - A single SNS topic is used. The Lambda function publishes messages with attributes (e.g., partner ID). Each partner subscribes to the SNS topic and uses a filter policy to only receive messages relevant to their partner ID","upvote_count":"1","timestamp":"1734749520.0","comments":[{"upvote_count":"1","comment_id":"1329787","timestamp":"1734749580.0","content":"D) Eliminated - All partners would receive updates for all orders because there is no filtering mechanism to ensure partner-specific messages.","poster":"sumanshu"}],"comment_id":"1329786"}],"comment_id":"1329785","poster":"sumanshu","content":"B) Eliminated - Adding a new partner means creating a new Lambda function, increasing operational overhead.","upvote_count":"1","timestamp":"1734749460.0"}]},{"upvote_count":"1","content":"Selected Answer: C\nkeyword: MOST scalable way, only the partner's own orders\n\n==> Discard A: you must update lambda for new topic added, but it simple for case having few partners, and little change\n==> Discard B: You must create duplicate lambda function and maintain it. But best case for customized comlexity requirements\n==> Discard D: it is easy to scalable, but violate rule 'only the partner's own orders', when a partner can see msg of all anothers\n\nC: best choice, match with 2 keywords above","timestamp":"1734007020.0","poster":"trieudo","comment_id":"1325598"},{"comments":[{"content":"With C, if it's more that 200 partners, we could create another SNS for the next 200 partners. so it couls support up to 2000000 partners.","comment_id":"1282072","timestamp":"1726056000.0","poster":"AnthonyTL","upvote_count":"2"}],"upvote_count":"1","content":"Selected Answer: A\nbecause of the fact that By default, you can have up to 200 filter policies per topic, the C option can't be the wright answer, but it's the A choice. since we can go up to 100 00 topics per SNS","comment_id":"1270652","timestamp":"1724326560.0","poster":"wail1997"},{"comment_id":"1257729","timestamp":"1722292200.0","poster":"ACurryDeveloper","upvote_count":"1","content":"A works, but C is better, benchods. More efficient. Have to remember good curry cannot be had in a hurry"},{"comment_id":"1248793","timestamp":"1721122080.0","upvote_count":"1","poster":"Anandesh","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/sns/latest/dg/example-filter-policies.html"},{"timestamp":"1716298500.0","comment_id":"1214981","content":"Selected Answer: C\nC is the correct answer.","poster":"65703c1","upvote_count":"1"},{"timestamp":"1715033100.0","comment_id":"1207594","content":"Selected Answer: C\nFunny understand why some people want to create separate SNS for each partner. You have got the option to filter and send notifications to the appropriate partner.","upvote_count":"1","poster":"Prosen2522"},{"content":"Selected Answer: C\nAnswer is C ... No Question","timestamp":"1712597880.0","poster":"badsati","comment_id":"1191723","upvote_count":"1"},{"content":"Selected Answer: A\nyou can create up to \n 10.000 filter policies per AWS account\n 200 filter policies per topic (not subscription!) limits option C to 200 partners\n 100 000 topics per AWS account, limits option A to 100 000 partners\n\nA and C works but A has better scalability with ability to add 100 000 partners","comment_id":"1102285","timestamp":"1703148900.0","poster":"xdkonorek2","comments":[{"poster":"drycleansing","timestamp":"1712791980.0","comment_id":"1193344","upvote_count":"1","content":"the best answer"}],"upvote_count":"5"},{"poster":"leonardoliveros","timestamp":"1700093100.0","comment_id":"1072030","upvote_count":"1","content":"Selected Answer: C\nYou can using a filter policy to just sent the info by partner"},{"timestamp":"1692277020.0","comment_id":"983637","content":"Selected Answer: C\nC. adding a new partner would only require to create a new subscription with the right filter","upvote_count":"1","poster":"ninomfr64"},{"poster":"tttamtttam","upvote_count":"1","timestamp":"1689319800.0","comment_id":"951328","content":"Selected Answer: C\nC seems the most efficient way. when you add more partners, you can just assign new codes for each partner. with the codes, you can send notifications to specific paters"},{"upvote_count":"1","timestamp":"1689072480.0","content":"Selected Answer: A\nThe answer is A since this question has two crucial requirements: \na) ... with the fewest code changes possible. \n\nb) ...in the MOST scalable way\n\nChatGPT initially gives an incorrect answer and then adjusts its response when requirements are asked.","comment_id":"948896","poster":"rlnd2000","comments":[{"comment_id":"948898","timestamp":"1689072660.0","poster":"rlnd2000","content":"OOH another important requirement: Each partner must receive updates for only the partner's own orders, that is not achievable with option C","upvote_count":"1","comments":[{"timestamp":"1690762320.0","upvote_count":"5","comment_id":"967607","poster":"Jeremy11","content":"This part of C seems to meet that requirement: Apply the appropriate filter policy to the topic subscriptions."}]},{"upvote_count":"2","content":"Cannot be A. It requires change of lambda function code to send notifications to new SNS topics for new partners. Not a scalable solution.","timestamp":"1695548760.0","comment_id":"1015646","poster":"Skywalker23"}]},{"timestamp":"1683390420.0","upvote_count":"4","content":"Got this question in exam. Correct answer is C.","comment_id":"890871","poster":"geekdamsel"},{"content":"Selected Answer: C\nC is the answer","timestamp":"1681988460.0","poster":"Rpod","comment_id":"875496","upvote_count":"2"},{"timestamp":"1681144260.0","poster":"robotgeek","upvote_count":"2","comments":[{"content":"You apply message filtering on the SNS so they recieve only their messages, think C is the correct answer","comment_id":"1144719","timestamp":"1707410340.0","upvote_count":"1","poster":"Baalhammun"}],"comment_id":"866440","content":"Selected Answer: A\nThe subscription depends on how the subscriber subcribes to the topic. It would be unsecure to allow customers to notify to whatever they want, they would get messages from other partners. This is more like a traditional queue scenario."},{"content":"Selected Answer: C\nC is the best answer. A would work but is less scalable as you have to create new topics for each new partner.","upvote_count":"2","timestamp":"1680614340.0","poster":"grimsdev","comment_id":"861072"},{"content":"Selected Answer: C\nC is the answer\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-message-filtering.html","comment_id":"859549","comments":[{"poster":"robotgeek","upvote_count":"1","timestamp":"1681391700.0","content":"So you are allowing Customer A to subscribe to orders from Customer B? sounds like a security fiasco IMHO. Is there any way you as a publisher can limit what Customers can subscribe to which messages with only 1 topic?","comment_id":"869432"}],"upvote_count":"3","timestamp":"1680498900.0","poster":"TungNNS"},{"comment_id":"858002","content":"Selected Answer: C\nC is the answer.\nTo receive only a subset of the messages, a subscriber must assign a filter policy to the topic subscription.","poster":"ihta_2031","timestamp":"1680358380.0","upvote_count":"4"},{"content":"Selected Answer: A\nI think Option A should be the answer where for each partner we should have an SNS topic","comment_id":"853248","upvote_count":"1","poster":"shahs10","timestamp":"1680007920.0"}],"question_images":[],"answer_images":[],"question_id":35,"isMC":true,"topic":"1"}],"exam":{"isBeta":false,"id":24,"numberOfQuestions":551,"name":"AWS Certified Developer - Associate DVA-C02","isMCOnly":true,"lastUpdated":"11 Apr 2025","isImplemented":true,"provider":"Amazon"},"currentPage":7},"__N_SSP":true}