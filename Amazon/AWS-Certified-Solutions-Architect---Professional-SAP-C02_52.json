{"pageProps":{"questions":[{"id":"zeqBsnaQvvzfU0SZ7pMa","discussion":[{"comment_id":"1078107","poster":"HunkyBunky","upvote_count":"18","timestamp":"1700719320.0","content":"Selected Answer: A\nIt should be A, becase with DeletionPolicy you can only keep or delete bucket, but bucket can't be deleted if it is not empty. So better way in that case - to create a lambda function as a custom resource, that will clean bucket before deletion.\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html\nhttps://awstut.com/en/2022/05/08/create-and-delete-s3-object-by-cfn-custom-resource-en/"},{"content":"Selected Answer: A\nA because anyone who goes by the name of HunkyBunky must know what they are talking about","upvote_count":"6","timestamp":"1708208940.0","comment_id":"1152887","poster":"dankositzke"},{"upvote_count":"1","content":"A is correct, This solution meets the requirements because it allows you to delete the S3 bucket when deleting the CloudFormation stack, which was failing due to the bucket not being deleted. By implementing a Lambda function as a custom resource, you can trigger it to delete the S3 bucket when the CloudFormation stack is deleted, ensuring that all resources are properly cleaned up.","timestamp":"1731898380.0","poster":"AzureDP900","comment_id":"1313802"},{"comment_id":"1172444","timestamp":"1710326400.0","upvote_count":"2","poster":"federikinho","content":"100% HunkyBunky explanation. You cannot just delete a non-empty bucket"},{"content":"Selected Answer: A\nOption A. Option C can be a good option but application itself deletes the objects after 24 hours so it will affect and will requires changes to application that is clearly stated in question as No.","comment_id":"1117733","poster":"career360guru","upvote_count":"3","timestamp":"1704822780.0"},{"upvote_count":"1","timestamp":"1701752880.0","content":"Selected Answer: A\nAnswer: A, I agree with @HunkyBunky's reasoning","comment_id":"1088195","poster":"J0n102"},{"timestamp":"1701183780.0","comment_id":"1082672","content":"Selected Answer: A\nAnswer is A. S3 buckets can't be deleted if they are not empty. Create a Lambda function to empty the bucket so bucket can be deleted.","poster":"shaaam80","upvote_count":"4"},{"upvote_count":"2","content":"Selected Answer: A\nSame as HunkyBunky comment","poster":"salazar35","comment_id":"1079988","timestamp":"1700914440.0"},{"content":"Selected Answer: D\nFor sure D","timestamp":"1700597340.0","poster":"devalenzuela86","upvote_count":"2","comments":[{"poster":"devalenzuela86","timestamp":"1700932020.0","comments":[{"timestamp":"1708427460.0","content":"D is not an option at all it will keep the S3 regardless empty or not and only delete the stack","upvote_count":"3","poster":"sat2008","comment_id":"1154650"}],"comment_id":"1080185","content":"Change to A. Its better option than D","upvote_count":"1"}],"comment_id":"1076624"}],"answer":"A","topic":"1","choices":{"C":"Modify the CloudF ormation stack to create an S3 Lifecycle rule that expires all objects 45 minutes after creation. Add a DependsOn attribute that points to the S3 bucket’s resource.","A":"Implement a Lambda function that deletes all files from a given S3 bucket. Integrate this Lambda function as a custom resource into the CloudFormation stack. Ensure that the custom resource has a DependsOn attribute that points to the S3 bucket's resource.","D":"Modify the CloudFormation stack to attach a DeletionPolicy attribute with a value of Delete to the S3 bucket.","B":"Modify the CloudFormation template to provision an Amazon Elastic File System (Amazon EFS) file system to store the temporary files there instead of in Amazon S3. Configure the Lambda functions to run in the same VPC as the file system. Mount the file system to the EC2 instances and Lambda functions."},"unix_timestamp":1700597340,"question_text":"A financial services company runs a complex, multi-tier application on Amazon EC2 instances and AWS Lambda functions. The application stores temporary data in Amazon S3. The S3 objects are valid for only 45 minutes and are deleted after 24 hours.\n\nThe company deploys each version of the application by launching an AWS CloudFormation stack. The stack creates all resources that are required to run the application. When the company deploys and validates a new application version, the company deletes the CloudFormation stack of the old version.\n\nThe company recently tried to delete the CloudFormation stack of an old application version, but the operation failed. An analysis shows that CloudFormation failed to delete an existing S3 bucket. A solutions architect needs to resolve this issue without making major changes to the application's architecture.\n\nWhich solution meets these requirements?","answer_ET":"A","answer_images":[],"question_images":[],"answer_description":"","answers_community":["A (94%)","6%"],"url":"https://www.examtopics.com/discussions/amazon/view/126757-exam-aws-certified-solutions-architect-professional-sap-c02/","timestamp":"2023-11-21 21:09:00","question_id":256,"isMC":true,"exam_id":33},{"id":"e9PFA0zq8dWFhDgnFNpt","answer_images":[],"question_text":"A company is hosting a monolithic REST-based API for a mobile app on five Amazon EC2 instances in public subnets of a VPC. Mobile clients connect to the API by using a domain name that is hosted on Amazon Route 53. The company has created a Route 53 multivalue answer routing policy with the IP addresses of all the EC2 instances. Recently, the app has been overwhelmed by large and sudden increases to traffic. The app has not been able to keep up with the traffic.\nA solutions architect needs to implement a solution so that the app can handle the new and varying load.\nWhich solution will meet these requirements with the LEAST operational overhead?","unix_timestamp":1670947140,"answer_description":"","topic":"1","question_images":[],"exam_id":33,"isMC":true,"discussion":[{"upvote_count":"36","poster":"EricZhang","comments":[{"upvote_count":"4","poster":"dqwsmwwvtgxwkvgcvc","timestamp":"1692403860.0","comment_id":"984845","content":"I guess multivalue answer routing in Route53 is not proper load balancing so replacing multivalue answer routing with ALB would proper balance the load (with minimal effort)"},{"comments":[{"timestamp":"1681516680.0","upvote_count":"13","poster":"scuzzy2010","comment_id":"870533","comments":[{"timestamp":"1710462540.0","poster":"24Gel","content":"disagree, ASG in Option D, after set up, operational is not overheat as well","comments":[{"content":"i mean Option C not D","comment_id":"1173870","timestamp":"1710462600.0","comments":[{"comment_id":"1173871","upvote_count":"2","content":"never mind, A is simpler than C","poster":"24Gel","timestamp":"1710462660.0"}],"upvote_count":"1","poster":"24Gel"}],"upvote_count":"1","comment_id":"1173868"}],"content":"Separating would be development overhead, but once done, the operational overheard (operational = ongoing day-to-day) will be the least."}],"content":"How can this be the answer ?? It says: Separate the API into individual AWS Lambda functions. Can you calculate the operational overhead to do that?","timestamp":"1677434400.0","upvote_count":"21","comment_id":"822775","poster":"lkyixoayffasdrlaqd"},{"timestamp":"1684486200.0","comment_id":"901778","poster":"Jay_2pt0_1","content":"From any type of real-world perspective, this just can't be the answer IMHO. Surely AWS takes \"real world\" into account.","upvote_count":"1"}],"timestamp":"1671188520.0","content":"Selected Answer: A\nServerless requires least operational effort.","comment_id":"747081"},{"poster":"jooncco","comments":[{"poster":"altonh","content":"Option C means your R53 is playing catch-up with your ASG. What happens if you scale down? Your clients will still have the terminated EC2 in their cache until the next TTL.","comment_id":"1337837","upvote_count":"1","timestamp":"1736314980.0"},{"timestamp":"1685423580.0","upvote_count":"1","comments":[{"comments":[{"timestamp":"1709460120.0","content":"Too contrived in my opinion, and what about DNS caches in the clients?. You coul get stuck for a while with the previous list of servers. I think it's has to be A (but it would involve a considerable development effort) or D which is extremely easy to implement but and the same time it sounds a little bit fishy because they don't mention anything about ASG or scaling\n\nI hate this kind of questions and I don't understand what kind of useful insight they provide unless they want us to become masters of the art of dealing with ambiguity","comment_id":"1164688","upvote_count":"3","poster":"liquen14","comments":[{"upvote_count":"1","comment_id":"1233432","poster":"cnethers","timestamp":"1718852700.0","content":"Agree that D does not scale to meet demand, it's just a better way to load balance which was being done at R53 before so the scaling issue has not been resolved.\nAlso agree A requires more dev effort and less ops effort, so I would have to lean to A...\nAnswer selection is poor IMO"}]}],"timestamp":"1691671260.0","upvote_count":"4","content":"Because if you have 4 ec2 in your ASG you need to have 4 records in domain name if ASG scale up to 6 for example you need 2 add 2 records more in domain name","comment_id":"977659","poster":"Vesla"}],"content":"\"Create an AWS Lambda function that reacts to Auto Scaling group changes and updates the Route 53 record. \"\nThis does not make any sense, why do you need to change R53 records using a Lambda?","comment_id":"909903","poster":"chathur"},{"upvote_count":"8","poster":"scuzzy2010","timestamp":"1677190440.0","content":"It says \"a monolithic REST-based API \" - hence only 1 API. Initially I thought C, but I'll go with A as it says least operation overhead (not least implementation effort). Lambda has virtually no operation overhead compared to EC2.","comment_id":"819817","comments":[{"poster":"aviathor","comment_id":"944679","upvote_count":"1","content":"Answer A says \"Separate the API into individual AWS Lambda functions.\" Makes me think there may be many APIs.\n\nHowever, we are looking to minimize operational effort, not development effort...","timestamp":"1688648880.0"},{"upvote_count":"5","content":"A monolithic REST api likely has a gazillion individual APIs. This refactor would not be a small one.","poster":"Jay_2pt0_1","timestamp":"1682929920.0","comment_id":"885999"}]},{"timestamp":"1700803740.0","comment_id":"1079048","poster":"jainparag1","upvote_count":"1","content":"Dealing with business logic change is applicable to existing solution or any solution based on the complexity. Rather it's easier to deal when these are microservices. You shouldn't hesitate to refactor your application by putting one time effort (dev overhead) to save significant operational overhead on daily basis. AWS is pushing for serverless only for this."}],"comment_id":"793547","content":"Selected Answer: C\nSuppose there are a 100 REST APIs (Since this application is monolithic, it's quite common).\nAre you still going to copy and paste all those API codes into lambda?\nWhat if business logic changes?\nThis is not MINIMAL. I would go with C.","upvote_count":"32","timestamp":"1675131000.0"},{"timestamp":"1742931240.0","content":"Selected Answer: D\nOption A is not the answer because if the application is migrated to lambda then code refactoring is required which will require operational overhead, while option D the architecture remains the same but we evenly distribute the traffic by adding ALB then assigning the EC2s to a target group therefore the load will be evenly balanced. Route 53 gets updated pointing to the ALB","poster":"abdullahelwalid","upvote_count":"1","comment_id":"1410146"},{"timestamp":"1742076240.0","upvote_count":"1","content":"Selected Answer: C\nD. doesn’t have auto scaling.\nB. EKS will add operational overhead \nA. Adds lots of lambda functions whose maintenance and management will add to operational overhead compared to current monolithic setup.\nC. Is the best fit of the available options, it will enable autoscaling and will allow upto 8 nodes from current 5, one lambda function to update route53 will add minimal operational overhead. Though D with Autoscaling would have allowed minimal operational overhead and more flexibility to scale.","comment_id":"1399058","poster":"ParamD"},{"upvote_count":"1","timestamp":"1740627720.0","content":"Selected Answer: C\nLess operational overhead. Much less development effort.","poster":"soulation","comment_id":"1362404"},{"content":"Selected Answer: A\nwell... i have to say... none of the options here comply to least operational overhead... each and every option involves changing the application logic.. but foe the sake of it... A is the best answer.. It cannot be B as containerizing would not be suitable to use with IP addresses of the instances... ASG and ELB would not fit here as Route 53 records point to the static IP addresses of the instances.. so the best answer is A... But again... a lot of overhead invovled if someone goes on for implementation...","timestamp":"1739036460.0","comment_id":"1353557","poster":"SaqibTaqi","upvote_count":"1"},{"timestamp":"1737571500.0","upvote_count":"2","comment_id":"1344917","poster":"sintesi_suffisso0","content":"Selected Answer: D\nIt can’t be A since we don’t know how much time the API needs to complete"},{"comment_id":"1339314","upvote_count":"3","timestamp":"1736642040.0","poster":"Shanmahi","content":"Selected Answer: D\nWhile all 4 options work well and general inclination is to go for \"serverless\", the least operational effort is certainly add an ALB to distribute the incoming traffic on the EC2 instances. In a \"real-world\" scenario, I would ideally place Route53 -> ALB -> EC2 instances in an ASG. However, in the given option choices, D with ALB meets the requirement well from operational complexity point of view."},{"poster":"jerry00218","content":"Selected Answer: A\nServerless is the least operational effort","comment_id":"1334484","upvote_count":"1","timestamp":"1735602480.0"},{"content":"Selected Answer: D\nD provides a balanced solution to handle increased and varying traffic loads while minimizing the complexity and maintenance overhead.","comment_id":"1333997","poster":"thanhpolimi","timestamp":"1735548480.0","upvote_count":"2"},{"comment_id":"1326985","poster":"grumpysloth","timestamp":"1734283500.0","content":"Selected Answer: C\nOperational overhead to fix the scalabiltiy issue is minimal if we keep the EC2 instances as they are and use ASG. We know nothing about the code complexity or response time, it might be hours, so Lambda is nto an option IMHO. D is not an option because it doesn't include autoscaling, so it won't solve the issue.","upvote_count":"3"},{"timestamp":"1733834460.0","poster":"JOJO9","upvote_count":"2","content":"Selected Answer: D\nThis approach leverages AWS managed services like the Application Load Balancer (ALB) and Auto Scaling groups, minimizing the operational overhead required to handle varying traffic loads. The ALB automatically distributes incoming traffic across the EC2 instances, while the instances can be placed in private subnets for better security. Additionally, the Auto Scaling group can be configured to automatically scale the EC2 instances based on metrics like CPU utilization, eliminating the need for manual scaling.\nBy using these managed services, you can offload tasks like load balancing, health checks, and auto-scaling to AWS, reducing the operational burden on your team. Updating the Route 53 record to point to the ALB's DNS name ensures that traffic is seamlessly routed to the backend instances without the need for manual DNS updates or additional components like Lambda functions.","comment_id":"1324522"},{"timestamp":"1733712180.0","poster":"Heman31in","upvote_count":"2","comment_id":"1323839","content":"Selected Answer: D\nOption Initial Effort Ongoing Overhead Scalability Cost Suitability for \"Least Operational Overhead\"\nA High Minimal Excellent (serverless) Cost-effective for low-to-medium traffic Poor (high re-architecture effort)\nB Very High High Excellent (with effort) Expensive Poor (requires Kubernetes expertise)\nC Moderate High Good (DNS-based scaling) Cheaper than ALB Moderate (Route 53 overhead)\nD Low Minimal Excellent (real-time ALB) Predictable Best"},{"poster":"wem","content":"Selected Answer: D\nD\nExplanation:\nBenefits of an Application Load Balancer (ALB):\n\nLoad Balancing: An ALB automatically distributes incoming traffic across multiple EC2 instances, ensuring high availability and efficient use of resources.\nScalability: The ALB works seamlessly with an Auto Scaling group to scale the number of instances based on traffic load.\nImproved Security: Moving EC2 instances to private subnets ensures they are not directly exposed to the internet, reducing security risks.\nOperational Overhead:\n\nMinimal setup compared to other options.\nNo need to manage DNS changes dynamically as the ALB provides a single, stable endpoint.\nIntegration with Route 53:\n\nRoute 53 can easily point to the ALB's DNS name, providing seamless updates to the clients.\nHandling Sudden Traffic Spikes:\n\nThe ALB efficiently distributes traffic among available instances and works with Auto Scaling to dynamically adjust capacity to meet varying load demands.","upvote_count":"2","timestamp":"1733596380.0","comment_id":"1323230"},{"comment_id":"1319907","upvote_count":"2","timestamp":"1732911900.0","poster":"Tiger4Code","content":"Selected Answer: D\nD: ALB --> EC2\nNot A cos This would require re-architecting the application from a monolithic design to a microservices or serverless architecture, which introduces additional complexity. Managing AWS Lambda functions and API Gateway would involve more operational overhead and may not be the most straightforward solution for handling increased load."},{"content":"I don't think this question is correct! all the answers are illogical given that the solution is very straight forward! Nothing in the question suggest that anything out of the ordinary is needed or justified! I am guessing that the answer should have been option D with auto scaling... \n They can't seriously expect an architect to simply suggest to refactor the whole app as a solution!","upvote_count":"1","poster":"ahhatem","comment_id":"1310495","timestamp":"1731401520.0"},{"timestamp":"1731246060.0","poster":"sashenka","comment_id":"1309458","upvote_count":"1","content":"For those of you considering D... If the \"new and varying load\" goes 100x of current, how without Auto Scaling Group can the \"five Amazon EC2 instances\" handle it?"},{"poster":"konieczny69","upvote_count":"1","comment_id":"1304113","timestamp":"1730140860.0","content":"its monolithic - cant be lambda"},{"timestamp":"1728436440.0","comment_id":"1294910","upvote_count":"1","poster":"Karelito00","content":"Option C is correct.\nOption A: You have to migrate all the business logic to lambda functions. I don't know how the option A is marked as correct when the question says with the Least Operation Overhead.\nOption D is good because we have an ALB in front of the instances and we don't have to handle the load balancing in Route 53, however this option doesn't scale, so if we got a traffic increase the application will fail.\nOption C: we have an ASG, so our application instances scales horizontally on demand, the downside is that we have to keep managing the load balancing at Route 53."},{"upvote_count":"1","timestamp":"1727809620.0","poster":"sashenka","comment_id":"1292081","content":"Selected Answer: A\nOperational overhead is the cost of the day-to-day operation of the service in question. The questions usually differentiated themselves by having answers that demonstrated knowing a service could potentially be expensive and you might be able to minimize the cost using an a different AWS service or sometimes not an AWS service at all. Whenever you see these in a question think \"serverless\" and \"easiest to implement and operate day 2\" it basically eliminates any answers that deploy infra (EC2 instances) that you will have to patch and manage."},{"upvote_count":"1","content":"Selected Answer: A\nAfter reading this discussions I am also with A.. because D has no AutoScaling","timestamp":"1727367900.0","poster":"chris_spencer","comment_id":"1289601"},{"timestamp":"1726744560.0","comment_id":"1286290","poster":"fabriciollf","content":"Selected Answer: A\nIn my opinion the key is this part of the question \"LEAST operational overhead\". Serverless is the best fit here.","upvote_count":"1"},{"comment_id":"1285159","timestamp":"1726571160.0","poster":"Fastercut","content":"A: It requires huge code restructuring normally re-writting the code would be the last option of any architectural changes.\nB: Kubernetes kind of increases the operational overhead in terms of knowledge to handle them and complexity in configurations\nC: Supports scalling and meets all the requirements with minimal effort.\nD. ALB load balances effectively, would not exactly be able to “handle the new and varying load” I guess. \n\nA & C: Kind of satisfy the requirement and has the Least Overhead. But considering the other factors Personally I would go with option C","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\nOption A will have the LEAST operational effort.","timestamp":"1725991380.0","poster":"AWSum1","comment_id":"1281703"},{"poster":"amministrazione","comment_id":"1275475","upvote_count":"1","content":"D. Create an Application Load Balancer (ALB) in front of the API. Move the EC2 instances to private subnets in the VPC. Add the EC2 instances as targets for the ALB. Update the Route 53 record to point to the ALB.","timestamp":"1725093360.0"},{"timestamp":"1722741060.0","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1722741120.0","poster":"Jason666888","comment_id":"1260510","content":"So for option C, if you upscale to 8 instances and the API still get overwhelmed, then there's nothing more you can do about it"}],"poster":"Jason666888","content":"Selected Answer: A\nIt has to be A, period.\n\nProblem with C: muti-value has an upper limit: 8. Route 53 responds to DNS queries with up to eight healthy records and gives different answers to different DNS resolvers. Also you need to manage the elastic IP's attachment everytime when new instances scale up for route53 multi-value routing\n\nProblem with D: multi-value cannot work with load balancers. please check doc here: https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-multivalue.html","comment_id":"1260508"},{"comments":[{"upvote_count":"1","timestamp":"1722329280.0","content":"Creating an Auto Scaling group and managing updates to Route 53 records via a Lambda function involves more complexity and management. The use of an ALB (as in Option D) is more efficient, as it inherently provides load balancing and scaling features without the need to update DNS records constantly.","poster":"Reval","comment_id":"1258040"}],"timestamp":"1722268260.0","upvote_count":"2","content":"Selected Answer: C\nA requires more work and it's not practical\nD cannot be the answer, why are we even moving instances to the private subnet in the first place? No security issues or other issues mentioned here.","poster":"Syre","comment_id":"1257570"},{"comments":[{"upvote_count":"1","comment_id":"1257693","poster":"8693a49","content":"True, some apps won't work well on Lambda. On the other hand option D is missing auto-scaling, which means it won't cope with increasing traffic. Assuming the app can be ported to Lambda, A satisfies all requirements: scalability and very low operational effort.","timestamp":"1722286200.0"}],"poster":"zolthar_z","upvote_count":"3","comment_id":"1248898","content":"Selected Answer: D\nKeep it simple, we can't assume if the API is a large/small application, the idea is make the least operational overhead and that is only add a ALB, We don't know the effort to move the application to a lambda, Answer is D","timestamp":"1721133840.0"},{"upvote_count":"4","poster":"Moghite","comments":[{"comment_id":"1257695","upvote_count":"1","content":"Refactoring is not operational effort. Operational effort is the routine work done once the application is in production (patching OS, monitoring logs, restarting servers, increasing capacity, etc). Serverless always has the lowest operational effort for the customer because AWS do it behind the scenes.","poster":"8693a49","timestamp":"1722286380.0"},{"upvote_count":"1","timestamp":"1722090060.0","content":"ALB won't help you with scaling. Obviously clear case for C","poster":"mns0173","comment_id":"1256332"}],"content":"Selected Answer: D\nResponse is D\nA- Requires significant refactoring of the application\nB- solution complex and requires containerizing application.\nC- The multi-value answer routings less flexible compared to using an ALB for load balancing.","comment_id":"1246944","timestamp":"1720806780.0"},{"poster":"subbupro","upvote_count":"1","content":"D is a perfect, least operation effort. C needs to write lamda func which is over head.","comment_id":"1227677","timestamp":"1717996980.0"},{"poster":"[Removed]","upvote_count":"17","comments":[{"content":"D does not scale to meet demand, it's just a better way to load balance which was being done at R53 before so the scaling issue has not been resolved.\nA requires more dev effort (not a consideration in the question) and less ops effort, so I would have to lean to A...\nAnswer selection is poor IMO for this question ..","timestamp":"1718852940.0","poster":"cnethers","upvote_count":"3","comment_id":"1233434"}],"content":"Selected Answer: D\nThe least operational overhead solution is:\n\nD. Create an Application Load Balancer (ALB) in front of the API. Move the EC2 instances to private subnets. Add the instances as targets for the ALB. Update the Route 53 record to point to the ALB.","timestamp":"1717565940.0","comment_id":"1224540"},{"comments":[{"poster":"ahhatem","upvote_count":"1","timestamp":"1717532700.0","content":"In addition, a monolithic REST-API does not necessarily require huge work to work effectively on lambda.... It depends on how it is written, might be very easy or very complicated!","comment_id":"1224346"}],"poster":"ahhatem","comment_id":"1224345","timestamp":"1717532520.0","content":"Selected Answer: A\nThe questions requires least operational effort... Nothing mentions the dev work to refactor!","upvote_count":"1"},{"comment_id":"1216044","content":"Selected Answer: C\nC should be the answer\nA - IMO, it's not feasible given the entire application is a monolithic, so we can't just refactor to separate into Lambda functions.\nD - Since there is no mention of ASG, this is ruled out. This does nothing to address the high volume requests.","poster":"nkv_3762","upvote_count":"3","timestamp":"1716412860.0"},{"upvote_count":"3","content":"Selected Answer: D\nTo handle the monolithic REST-based API being overwhelmed by traffic with minimal operational overhead, the best solution involves placing an Application Load Balancer (ALB) in front of the EC2 instances and moving these instances to private subnets within the VPC. The ALB effectively distributes incoming traffic across multiple instances, preventing any single instance from being overloaded. Additionally, integrating Auto Scaling with the ALB ensures that the number of EC2 instances dynamically adjusts based on traffic load, maintaining performance and availability. This approach avoids the extensive development and refactoring efforts required by other solutions, providing a scalable and reliable setup with minimal changes to the existing infrastructure.","timestamp":"1716315540.0","poster":"higashikumi","comment_id":"1215160"},{"comment_id":"1214895","timestamp":"1716291180.0","poster":"Malcnorth59","upvote_count":"1","content":"I am going to select D. If you look at what has been implemented, it effectively tries to do what an ALB + ASG does. Option A is attractive but I believe it is not the one with LEAST operational overhead. It requires a complete re-architecting and redevelopment of the solution whereas D can be done with minimal change by an operations team"},{"comment_id":"1195978","comments":[{"timestamp":"1713699540.0","comment_id":"1199625","poster":"mifune","content":"That solution would be ideal, except that the question asks for how to resolve the increasement of requests. An ALB does not scales, so C is the correct anwser.","upvote_count":"1"}],"timestamp":"1713176220.0","content":"Selected Answer: D\nI go with D","poster":"qaz12wsx","upvote_count":"2"},{"content":"Selected Answer: C\nI choose C.\nA,B may need significant development effort to refactor \nD doesn’t address the major issue which is scaling","timestamp":"1712269020.0","poster":"lasithasilva709","comment_id":"1189561","upvote_count":"2"},{"upvote_count":"1","content":"Selected Answer: A\nThere is a difference between development burden of refactoring and operational burden.","poster":"Smart","timestamp":"1711923900.0","comment_id":"1187051"},{"content":"A. partial correct - because monolithic application, if EC2 are not handle i dont think Lamda can handle the traffic.\n\ni can go for D.\n- because of Multi-value, ALB, TG,ASG","timestamp":"1711860300.0","comment_id":"1186582","upvote_count":"1","poster":"43c89f4"},{"timestamp":"1711422900.0","upvote_count":"1","poster":"VerRi","content":"Selected Answer: D\nA will work, but not the least operational overhead.","comment_id":"1182966"},{"comments":[{"comments":[{"timestamp":"1711140960.0","content":"Testing and Debugging Challenges: Serverless applications, due to their distributed nature, can present unique challenges for testing and debugging. Ensuring that the application behaves correctly as a collection of independently deployed functions requires comprehensive integration testing. Debugging issues can also be more complex compared to a monolithic architecture, where the application components are more tightly coupled.","comment_id":"1180322","upvote_count":"1","poster":"mav3r1ck"}],"comment_id":"1180319","timestamp":"1711140840.0","content":"There are several reasons why it might not be considered the best option with the \"least\" operational overhead in this specific scenario:\nRefactoring Effort: Transforming a monolithic application into a set of microservices or serverless functions can be a significant undertaking. It requires a thorough analysis of the existing application architecture, identifying logical separations between different parts of the application, and then implementing those separations. This process can be time-consuming and requires careful planning to ensure that the application continues to function correctly as a set of more granular services.","poster":"mav3r1ck","upvote_count":"1"},{"poster":"mav3r1ck","timestamp":"1711141020.0","content":"In contrast, option D — creating an Application Load Balancer (ALB) in front of the API and updating the infrastructure to better manage traffic through scaling and health checks — offers a balance between reducing operational overhead and implementing the solution with minimal changes to the existing application architecture. It provides an immediate solution to the problem of handling varying loads without the significant upfront investment in refactoring the application or the learning curve associated with adopting serverless technologies.","upvote_count":"1","comment_id":"1180323"}],"poster":"mav3r1ck","timestamp":"1711140720.0","content":"Selected Answer: D\nChoosing option A — separating the API into individual AWS Lambda functions and configuring an Amazon API Gateway REST API with Lambda integration — does present a modern, highly scalable solution that could theoretically handle new and varying loads with potentially lower operational overhead once implemented.","upvote_count":"1","comment_id":"1180317"},{"content":"Selected Answer: C\nFor me it's C.\nAnswer A it's impossible. Can you imagine how much time do we need to refactor the application into n API/functions?\nAnswer B and C make no sense.\nThe only one is C, for me.","timestamp":"1711036800.0","comments":[{"timestamp":"1720975620.0","content":"Agree. Answer A is to turn monolithic application to micro service. The time spend on this work vs the time to creating ASG + Lambda code retrieving ec2 ip and update R53. Obviously answer C is least effort.\nD is wrong because just ALB without asg will not make any change to the load processing.","upvote_count":"1","comment_id":"1247861","poster":"Helpnosense"}],"poster":"red_panda","upvote_count":"4","comment_id":"1179381"},{"content":"Selected Answer: D\nProblem I have with A, is the overhead of rearchitecting the application code. Monolithic REST API into Lambda means time and money spent on redesigning, development, testing and deployment. That's also \"operational overhead\" IMHO.\nOption D on the other hand is quite straightforward. Only thing missing for that to be the obvious go-to is that it doesn't mention EC2 autoscaling.\nAs far as the current set up is concerned, given that the only form of load balancing available is the multivalue DNS responses, it's quite possible that always the top most IP in the list gets the most hits. When quite a high traffic hits the target, it goes down (no replacement is spun up either) resulting in the IP of that EC2 is not included in the subsequent DNS responses. Eventually, you are gonna exhaust the entire set of EC2 instance.\nWith this behaviour being more likely than not, trying to revamp the monolith into AWS Lambda would be overkill, and it brings way too much operational overhead as well.","comment_id":"1174973","timestamp":"1710595680.0","upvote_count":"3","poster":"kz407"},{"timestamp":"1709457000.0","comments":[{"upvote_count":"1","timestamp":"1709816040.0","content":"but have you answered this request : implement a solution so that the app can handle the new and varying load. !!","comment_id":"1167993","poster":"JOKERO"}],"upvote_count":"1","poster":"Dgix","content":"The correct answer is D, believe it or not. \"LEAST OPERATIONAL OVERHEAD\", remember? Refactoring the monolith constitutes substantial overhead. The reason D isn't immediately apparent as the correct solution is that D doesn't mention that autoscaling _can_ be used, but the operational overhead is practically zero. This is just another \"fine\" example of AWS wording their questions and replies in an incomplete, ambiguous manner (which we all hate) :).","comment_id":"1164622"},{"upvote_count":"1","timestamp":"1707359040.0","poster":"_Jassybanga_","comment_id":"1143983","comments":[{"timestamp":"1707359220.0","poster":"_Jassybanga_","comments":[{"comment_id":"1143989","poster":"_Jassybanga_","content":"Actually the answer should be D as the main problem is load balancing which is achived by using ALB. in A the load balancing is still not happening","upvote_count":"2","timestamp":"1707359400.0"}],"content":"Sorry I read it wrong - answer can be D as well, Route53 - ALB - Ec2 - Least changes needs to be done and is a fine working solution","upvote_count":"1","comment_id":"1143985"}],"content":"I will go with A - may be complex development with simple operations overhead as we are going full serverless here. The option D does not make sense , we are putting the API as target group for ALB but at the same time we want to point the EC2 Ip to the ALB.. not clear to be honest ."},{"timestamp":"1705177080.0","poster":"AWSPro1234","upvote_count":"3","comment_id":"1122021","content":"Selected Answer: D\nD is correct."},{"timestamp":"1704631800.0","poster":"GabrielShiao","comments":[{"content":"Yeh but D doesn't mention autoscaling; I almost wrote D; but I think it's A. Just because the load is balanced doesn't mean it can handle excess demand. Ordinarily and ALB would be attached to an ASG; but an ASG isn't mentioned. And and ALB can connect to ec2 without an ASG.","upvote_count":"2","comment_id":"1120027","poster":"grire974","timestamp":"1704995280.0"}],"content":"Selected Answer: D\nD is least effort, no code change, auto scaling, HA. Changing code is not easy. Even if c is workable but it is not so load balancing since multivalue answer can return 8 records at maximum which is not a good choice","comment_id":"1115832","upvote_count":"3"},{"upvote_count":"2","comment_id":"1111107","poster":"learnwithaniket","timestamp":"1704107280.0","content":"Selected Answer: D\nLeast operational overhead is D. Since they already have EC2 instances running.\nCreating API Gateway and Lambda requires efforts."},{"upvote_count":"2","content":"this is the kind of questions where the answers are divided. Reading the explanations in this discussion I would also choose option A, because it is the one that will cause least overhead in the day by day work, but I also agree with people that say that converting a monolithic app into a Lambda function is not easy. Options C and D are also correct and they are both a dood choice and one complements the other. If you have several EC2 and you need to sale out and in, you must have a ASG. On the other hand the ALB is needed to spread the load between the EC2.\nSo in summary it is not easy to choose the correct answer here, but I still go to A, because of the requirement 'LEAST' overhead.","timestamp":"1703947380.0","poster":"jpa8300","comment_id":"1109790"},{"timestamp":"1703006040.0","content":"Selected Answer: A\nNot B as EKS and EC2 requires a lot of work\nNot C as EC2 requires work and the lambda to update R53 upon scale out requires more work (and it is cumbersome)\nNot D as EC2 requires more work than Lambda \n\nA because R53, API GW and Lambda are all serverless and managed services","comment_id":"1100845","poster":"ninomfr64","upvote_count":"1"},{"comment_id":"1088478","comments":[{"upvote_count":"1","timestamp":"1704995520.0","content":"Route53 can only return a max of 8 healthy values; so there's an upper limit on how this could scale: https://aws.amazon.com/route53/faqs/#:~:text=If%20you%20want%20to%20route,response%20to%20each%20DNS%20query. ignoring the fact that its also quite unorthodox.","comment_id":"1120032","poster":"grire974"}],"poster":"subbupro","timestamp":"1701779460.0","upvote_count":"1","content":"A and B are operation over head , we need to do the rearchitecture, and D is not having any scope for auto scaling just using an ALB and Route 53 . So C would be best"},{"poster":"KevinYao","comment_id":"1080494","content":"Selected Answer: C\nA. it needs more development job, and it's hard to do rollup upgrade.\nB. EKS cost is high\nD. It's hard to auto scalling without ASG.","comments":[],"timestamp":"1700976060.0","upvote_count":"2"},{"comment_id":"1079998","timestamp":"1700915340.0","content":"Selected Answer: D\nLeast operational overhead is D. The API is already on EC2 instances. Transitioning to serverless just screams operational overhead IMO.","poster":"enk","comments":[],"upvote_count":"4"},{"upvote_count":"1","content":"Selected Answer: A\ncheck EricZhang's answer","timestamp":"1699777620.0","poster":"severlight","comment_id":"1068372"},{"poster":"rlf","timestamp":"1697705520.0","comment_id":"1047725","content":"Answer is A.\nC is wrong. R53. Multivalue answer routing is not a substitute for Elastic Load Balancing (ELB). Route 53 randomly selects any 8 records and it does not mention about launch template (placing all existing instances to ASG ?)\nD is wrong. ALB does not support REST without API gateway http integration.\nhttps://repost.aws/knowledge-center/api-gateway-application-load-balancers","upvote_count":"2"},{"poster":"whenthan","content":"Selected Answer: D\nA - X [code refactoring and rearch]\nB-X [containerizing - more overhead on EC2s]\nC-X [ lambda function to frequently update -- more overhead]\n\nD-- is correct","upvote_count":"3","timestamp":"1697633760.0","comment_id":"1046927"},{"content":"Selected Answer: D\nThe question is just to test your knowledge about issue detection. The issue here is Route 53 with multi records. The system currently doesn't have load balancing.","poster":"longns","timestamp":"1696111260.0","comment_id":"1021878","upvote_count":"3"},{"timestamp":"1695863460.0","upvote_count":"1","comment_id":"1019314","comments":[{"poster":"covabix879","comment_id":"1021589","upvote_count":"2","timestamp":"1696085880.0","content":"No mention of ASG. Even with ASG, it can't handle sudden increase"},{"poster":"swadeey","timestamp":"1701109380.0","comment_id":"1081864","upvote_count":"1","content":"But moving ec2 from public to private will need to change ips and also login on how users will access application from public IPs to private and will need a lot of overhead to configure. And we need least overhead right?"}],"content":"Selected Answer: D\nD. Create an Application Load Balancer (ALB) in front of the API: This solution involves setting up an ALB, which can distribute incoming traffic across multiple targets, such as EC2 instances. By moving the EC2 instances to private subnets, you enhance security. The ALB can handle varying loads, and you can also set up an Auto Scaling group for the EC2 instances without needing to update Route 53 records since the ALB's DNS remains constant. This solution provides load balancing, scalability, and simplicity.","poster":"bbastia2"},{"content":"A.\nD doesn't talk of scaling in or scaling out based on Load. That eliminates D\nC why do you require a lambda to update R53.EC2 <- ASG <- APIGW <- ALB R53 should do the job\nB doesnt again talk about ScalingIn and Scaling out\n\nOption A, is viable.","timestamp":"1694408880.0","poster":"AMohanty","upvote_count":"3","comment_id":"1004462"},{"comment_id":"998516","poster":"Simon523","content":"Selected Answer: A\nThe problem here is \"The app has not been able to keep up with the traffic.\" so it doesn't cause the EC2 not enough resource, so I guess C is not correct.","upvote_count":"1","timestamp":"1693829400.0"},{"upvote_count":"2","timestamp":"1693211160.0","content":"Selected Answer: C\nThe core problem is `Recently, the app has been overwhelmed by large and sudden increases to traffic. The app has not been able to keep up with the traffic.`. \n\nA never solve the problem as the bottleneck is still on the EC2 instances. \nB would take tons of efforts.\nD uses ALB only which do not have any autoscaling feature.\n\nC must be the only correct answer","poster":"[Removed]","comment_id":"991932"},{"upvote_count":"2","poster":"Soweetadad","content":"Does ALB even support Rest API (unless you use it with APIGW)? I would go with either A (less right) or C","timestamp":"1692928440.0","comment_id":"989617"},{"poster":"dqwsmwwvtgxwkvgcvc","comment_id":"984259","timestamp":"1692344760.0","content":"Selected Answer: D\nAnswer D uses ALB to balance to replace Route 53 multivalue answer routing policy for proper load balancing.","upvote_count":"3"},{"timestamp":"1691183580.0","upvote_count":"3","comment_id":"972512","content":"Selected Answer: D\nAnswer: D\n\nI can't believe that SAP-C02 has this type of questions. Least operational overhead should be A, however the question says exactly this: \"A solutions architect needs to implement a solution so that the app can handle the new and varying load.\"\nIn any moment it says \"...implement a solution so that the NEW app can handle...\"\n\nC is a possibility, but to \"Create an AWS Lambda function that reacts to Auto Scaling group changes and updates the Route 53 record\"? I wouldn't even think suggesting this, unless customer really wants it.\n\nAnswer D has the \"where is the ASG to handle spikes in traffic\" thing, but it's the less worse in my opinion as the issue seems to be related to poor distribution of requests as seen here: \"The company has created a Route 53 multivalue answer routing policy with the IP addresses of all the EC2 instances\"","poster":"chico2023"},{"upvote_count":"1","timestamp":"1689010320.0","comment_id":"948297","poster":"Asds","content":"Selected Answer: A\nCan’t be C as they don’t mention elb at all\n\nWhich leads to…..A"},{"upvote_count":"1","content":"Selected Answer: D\nshould be D, from a developer point of view.\nA - move implemention from EC2 to lambda? not possible to be least overhead\nB - EKS also lot overhead\nC - why use lambda to update route53 records?\nD - correct answer","timestamp":"1688816100.0","poster":"softarts","comment_id":"946435"},{"upvote_count":"2","timestamp":"1688736420.0","content":"Selected Answer: A\nA: Serverless - Least OPS overhead.\nRule Out Factors:\nB: K8s - OPS overhead + Dev overhead.\nC: ASG + Lambda seems impractical for sudden and large traffic surges. \nD: ALB + EC2 is good, but ASG is missing so not addressing traffic surges.","comment_id":"945725","poster":"awsrd2023"},{"timestamp":"1688676540.0","comment_id":"945013","poster":"Christina666","content":"I thought it was C, but the question is \"least operational\", serverless beats option C I guess, I choose A. Please delete my last comment @Examtopics","upvote_count":"1"},{"content":"Selected Answer: A\nI thought it was C, but the question is \"least operational\", serverless beats option C I guess, and this question only has 5 instances, so I choose A","upvote_count":"1","comment_id":"945011","timestamp":"1688676420.0","poster":"Christina666"},{"comment_id":"938189","content":"Selected Answer: A\nIt's A, keyword here is \"least operational\" not \"least development\". So, yes the development effort with A is higher than C, but operational is lower because i don't have to worry about EC2, patching, upgrades, monitoring etc.. \"least operational\" <<<---","upvote_count":"2","timestamp":"1688046300.0","poster":"SmileyCloud"},{"upvote_count":"1","timestamp":"1688003640.0","content":"Selected Answer: A\nLambda - least ops overhead","poster":"NikkyDicky","comment_id":"937361"},{"upvote_count":"1","content":"Selected Answer: C\nI would discard A because the development overhead. D does not have ASG, so only valid options would be C","poster":"javitech83","timestamp":"1687688580.0","comment_id":"933460"},{"comment_id":"933018","poster":"gd1","timestamp":"1687650300.0","content":"Selected Answer: D\nGPT 4.0 Application Load Balancer (ALB) helps distribute incoming traffic across multiple targets, such as Amazon EC2 instances. This distribution helps to increase the availability of your application. ALB can scale automatically to the volume of incoming traffic. Moving the EC2 instances to private subnets in the VPC would also enhance the security posture by reducing the surface area of attack.","upvote_count":"3"},{"upvote_count":"4","poster":"bcx","timestamp":"1687094700.0","content":"Selected Answer: C\nA is definitely wrong, the questions says that it is a monolithic application running on EC2. It also requires a solution with minimal operational effort. Implementing A would take a lot of time and effort to rewrite the monolithic application to be able to be hosted by Lambda.\nB is kind of the same, Kubernetes! Containers! OMG, that's a lot of operational effort.\n\nSo it is C or D, both seem valid. But D does not have autoscaling capability, which means that it could not handle the issue (handle the spikes in traffic).","comment_id":"926718"},{"comment_id":"924141","timestamp":"1686828840.0","content":"Selected Answer: A\nThe question is about \"LEAST operational overhead\" and does it include refactoring mobile app? According to https://docs.aws.amazon.com/whitepapers/latest/microservices-on-aws/serverless-microservices.html AWS supposes that refactoring app is not included in operational overhead, so the answer is A.","upvote_count":"1","poster":"ailves"},{"comment_id":"913329","upvote_count":"1","poster":"ZK000001qws","timestamp":"1685772600.0","content":"There are limitation associated with Lambda function and a monolithic app hosted on VMs would not be best suited to be placed on lambda functions (its a change of archicture). Thus loadbalance replacing domain pointing to each VM is plausible. I would go with D"},{"timestamp":"1685101380.0","content":"Selected Answer: D\nqn mentioned 5 EC2 in a VPC, however Route 53 multivalue is mainly benefit for EC2 across region. and the key clue is \"The app has not been able to keep up with the traffic\" >> seemed to suggest could be due to traffic all route to the 1st EC2 Ip address, but not yet failed and there is no mention of all 5 EC2 has been performing near to high CPU in the R53 multivalue mode\n\nHence having a ALB will distribute the load for processing","comment_id":"907314","poster":"Limlimwdwd","upvote_count":"2"},{"timestamp":"1684943400.0","comment_id":"906015","content":"Selected Answer: A\nI will go with A, as this is a Serverless solution and for me the best one the fit to scale and less day to day tasks (operational overhead)\n\nI was look really deep to the option C \"C. Create an Auto Scaling group. Place all the EC2 instances in the Auto Scaling group. Configure the Auto Scaling group to perform scaling actions that are based on CPU utilization. Create an AWS Lambda function that reacts to Auto Scaling group changes and updates the Route 53 record\" - but this one is missing one really important point, how will the ASG scale if you are just adding the current instance to the ASG, the ASG will need a Launch Template with a standard AMI to launch new EC2s and we do not have it here, we are just addind the current instances inside de ASG.","upvote_count":"1","poster":"aca1"},{"timestamp":"1684664400.0","upvote_count":"1","comment_id":"903106","poster":"ShinLi","content":"I think the answer is C. as they already have 5 EC2 in a public subnet. so, setup an Auto Scaling group is the easiest setup and does not have much operations overhead."},{"content":"C is right. It handles the new and varying load by Autoscaling of EC2 \n\nA is wrong\nIt does not handle the new and varying load\nIt is not scalable and brings huge operational overhead","upvote_count":"2","poster":"iamunstopable","timestamp":"1682680080.0","comment_id":"883446"},{"upvote_count":"2","poster":"Sarutobi","comment_id":"873184","content":"Selected Answer: A\nI will pick A because this is an EXAM but I maybe not the best idea for real-life implementation. I think D is a great first step, with the added benefit that the EC2 are moved to a private subnet, increasing security. Maybe then I will go for A. C is also possible, but I don't like multi-value to replace a load balancer function, and that solution with Lambda updating route-53, ummm...not sure I like it too much; maybe a life-cycle hook.","timestamp":"1681776300.0"},{"timestamp":"1681206600.0","upvote_count":"5","poster":"frfavoreto","content":"Selected Answer: A\nPeople get confused between LEAST OPERATIONAL OVERHEAD and IMPLEMENTATION EFFORT. \n\nThese are 2 different and completely independent concepts.","comment_id":"867141"},{"upvote_count":"4","poster":"OnePunchExam","content":"Selected Answer: A\n1. Always when I see this type of question with key requirement 'LEAST operational overhead', many people confusing initial cloud infrastructure setup for new solution as part of overhead which is not. Operation overhead is about maintenance, patching, backups etc.\n2. Also the monolithic part is meant to confused, though it is possible (see https://aws.amazon.com/blogs/compute/migrating-a-monolithic-net-rest-api-to-aws-lambda/)\n3. Lastly, don't make assumptions about the application. I see comments about 100 REST APIs, refactoring effort etc.","comment_id":"863459","timestamp":"1680838080.0"},{"content":"since the request is LEAST *operational* overhead, i will go with A","upvote_count":"1","poster":"mikad","timestamp":"1680590340.0","comment_id":"860720"},{"timestamp":"1680394080.0","poster":"takecoffe","comment_id":"858378","upvote_count":"1","content":"I will choose D."},{"timestamp":"1679987940.0","content":"Selected Answer: A\nI vote A - sep lambda functions","upvote_count":"2","poster":"mfsec","comment_id":"852937"},{"timestamp":"1678677000.0","upvote_count":"3","comment_id":"837581","content":"Selected Answer: A\nhttps://aws.amazon.com/getting-started/hands-on/break-monolith-app-microservices-ecs-docker-ec2/module-one/ and https://docs.aws.amazon.com/whitepapers/latest/microservices-on-aws/serverless-microservices.html\n\nJust saying, moving it to a microservice architecture not only makes sense but will remove a lot of operational overhead.","poster":"zejou1"},{"comment_id":"830343","poster":"dev112233xx","timestamp":"1678051740.0","upvote_count":"6","comments":[{"content":"Sudden bursts of traffic can not be contained using ASGs.","poster":"chathur","upvote_count":"1","comment_id":"907767","timestamp":"1685163840.0"},{"comment_id":"831999","upvote_count":"3","content":"Agree, with u\nMakes no sense refactor the APP not knowing details ( A & B)\nI dont see why to create a lambda to add and remove records to route 53 that could be cached as long as the duration of the TTL. ( C )","poster":"rtgfdv3","timestamp":"1678199280.0"}],"content":"Selected Answer: D\nThis question is the mother of all tricky questions lol\nThe main issue of the current design is that R53 is used to distribute the load to the app. Which is a bad practice. This why i think ALB is the best solution here. Answer A is incorrect because a big refactor and this is the last think you want to think about !\nAnswer D solve only the Autoscaling, but miss the ALB and still use the R53 as a load balancer!"},{"timestamp":"1677725520.0","comment_id":"826432","upvote_count":"2","poster":"doto","content":"Selected Answer: C\nccccccccccccc"},{"timestamp":"1677509940.0","content":"Selected Answer: C\nC is correct\n\nA: may require a lot of effort in refactoring to lambda and different architecture\nB: may require a lot of effort in refactoring to containers/kubernetes and different architecture \nC: correct\nD: would be great to have a load balancer but the solution does not involve autoscaling so by itself does not satisfy the increase in demand. Also moving instances to private subnet may be not viable, depending on the app behaviour.","comment_id":"823847","upvote_count":"1","poster":"_lasco_"},{"comment_id":"821887","comments":[{"upvote_count":"1","content":"That's correct, but unfortunately D is not scaleable as it's missing the ASG","comment_id":"828455","timestamp":"1677883320.0","poster":"anita_student"}],"timestamp":"1677366000.0","content":"Selected Answer: D\nOption A and B suggest re-architecting the application, which may require significant development work and operational overhead. Option C adds complexity by requiring an additional Lambda function to update the Route 53 record.","upvote_count":"3","poster":"cudbyanc"},{"poster":"hobokabobo","timestamp":"1677329880.0","content":"Selected Answer: A\nWhy do they give a question with a set of answers that are all bad given the scenario. \nD: misses Autoscaler. It just does not do what the architect was asked to find a solution for.\nC: it simply does not work: changing DNS need to take TTL into account... \nB: adds overhead for Kubernetes. \nA: works but is ridiculous expensive and comes with operational effort to maintain lambda.\n\nSo I guess the only possible option is A. \n\nDisclaimer: No one reasonable would use Lambda if it comes to high load. If the load justifies an EC2 let alone 5 EC instances. EC2 is way to go. Autoscaler, Loadbalancer. This is simple and simple means less operational overhead while complexity means operational overhead: Lambda adds complexity and is expensive when it comes to load (one invocation: cheap but not massive number of invocations).","upvote_count":"3","comment_id":"821486"},{"comment_id":"820059","timestamp":"1677207600.0","upvote_count":"3","content":"Selected Answer: A\nMy Logical answer : After reading some discussion comments, my take - Least operation effort does not mean quick fix, its least work to maintain it. C is wrong , it seemed good reading first part but at the end it mentions wierd statement \"lambda updating Route53 all the time when it reacts ? why updating DNS service every time? \" D is not apt because, why would we put internet facing EC2 instances in private subnet? that adds additional overhead of maintaining NAT gateways /route tables etc. So serverless solution for least operational effort leaves A or B. I feel B is over provisioning with ECS/EKS clustering because it looks like a low/medium scale app with just 5 ec2 instances. I'd go with A as best answer.","poster":"God_Is_Love"},{"upvote_count":"1","content":"My Logical answer : After reading some discussion comments, my take - Least operation effort does not mean quick fix, its least work to maintain it. C is wrong , it seemed good reading first part but at the end it mentions wierd statement \"lambda updating Route53 all the time when it reacts ? why updating DNS service every time? \" D is not apt because, why would we put internet facing EC2 instances in private subnet? that adds additional overhead of maintaining NAT gateways /route tables etc. So serverless solution for least operational effort leaves A or B. I feel B is over provisioning with ECS/EKS clustering because it looks like a low/medium scale app with just 5 ec2 instances. I'd go with A as best answer.","comment_id":"820056","poster":"God_Is_Love","timestamp":"1677207300.0"},{"poster":"kiran15789","timestamp":"1677169320.0","comments":[{"timestamp":"1678476840.0","upvote_count":"1","content":"Decided to update my answer to D","comment_id":"835351","poster":"kiran15789"}],"upvote_count":"1","content":"Selected Answer: C\nC based on minimal operational overhead","comment_id":"819391"},{"content":"Selected Answer: A\nAPI Gateway is the option","upvote_count":"1","comment_id":"812355","timestamp":"1676666820.0","poster":"spd"},{"upvote_count":"3","comment_id":"801587","timestamp":"1675821060.0","content":"Selected Answer: A\nNo C\nBecause max 8 EC2s on Route53 multivalue answers","poster":"tinyflame"},{"comment_id":"799872","content":"Selected Answer: A\nI know this question is gonna be a controversial one. The real issue is what the mean of LEAST OPERATIONAL OVERHEAD means. It could mean the least amount of work to set up initially, in which case the answer is definitely C. Converting a monolithic application to lambda is not a simple task.\nBut in operation overhead means how much work it would take to maintain, the answer is definitely A because serverless has a lot less effort once its operational. \nPersonally, I would go with A on this question. I've been taking these cert exams for a while now and I get a sense that AWS wants you to use serverless.\nAdditionally, not quite sure what it means in C to have the lambda update Route 53...","upvote_count":"5","poster":"DWsk","timestamp":"1675695540.0"},{"timestamp":"1675580220.0","comments":[{"comment_id":"806905","poster":"oatif","timestamp":"1676244660.0","upvote_count":"1","content":"operational overhead means less effort in the long run, so i would change my answer to A."}],"poster":"oatif","upvote_count":"1","comment_id":"798657","content":"Selected Answer: C\nThe answer is C, no idea, why ppl are voting for A. C requires the minimum amount of effort."},{"timestamp":"1675091460.0","upvote_count":"2","comment_id":"792961","content":"why not C?","poster":"zozza2023"},{"poster":"viddkr","upvote_count":"2","comment_id":"786164","timestamp":"1674537060.0","content":"Selected Answer: A\nQuestion on 23-Jan-2023, selected A"},{"content":"Selected Answer: A\nOption A is good because it separates the API into individual AWS Lambda functions, which allows for automatic scaling of the backend based on the traffic it receives. Additionally, it also allows for more fine-grained scaling of specific parts of the API that may be receiving more traffic than others. By configuring an Amazon API Gateway REST API with Lambda integration, you can also benefit from features such as caching, monitoring, and security. Finally, by updating the Route 53 record to point to the API Gateway API, you can ensure that mobile clients are directed to the correct endpoint. This solution will have the least operational overhead, as it allows for automatic scaling and offloads many of the operational responsibilities to the managed services provided by AWS.","poster":"masetromain","upvote_count":"1","timestamp":"1673641860.0","comment_id":"774829","comments":[{"upvote_count":"3","comment_id":"793757","poster":"tatdatpham","timestamp":"1675149240.0","content":"I think the answer is C, you forgot that the application is monolithic. You need a lot of effort to migrate app to lambda function."}]},{"content":"Selected Answer: C\nC - least operational effort from existing setup.\n\nA - Operational effort is high\nB - Containerize - Operational effort is high\nD - ALB and private subnet - Operational effort is high","timestamp":"1672998540.0","comment_id":"767485","poster":"adit","upvote_count":"5"},{"upvote_count":"2","content":"Selected Answer: D\nI go with D","poster":"masetromain","comment_id":"744250","comments":[{"upvote_count":"3","content":"D does not have ASG, it cannot scale out","comments":[],"comment_id":"749868","timestamp":"1671457500.0","poster":"zhangyu20000"}],"timestamp":"1670947140.0"}],"choices":{"C":"Create an Auto Scaling group. Place all the EC2 instances in the Auto Scaling group. Configure the Auto Scaling group to perform scaling actions that are based on CPU utilization. Create an AWS Lambda function that reacts to Auto Scaling group changes and updates the Route 53 record.","B":"Containerize the API logic. Create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. Run the containers in the cluster by using Amazon EC2. Create a Kubernetes ingress. Update the Route 53 record to point to the Kubernetes ingress.","D":"Create an Application Load Balancer (ALB) in front of the API. Move the EC2 instances to private subnets in the VPC. Add the EC2 instances as targets for the ALB. Update the Route 53 record to point to the ALB.","A":"Separate the API into individual AWS Lambda functions. Configure an Amazon API Gateway REST API with Lambda integration for the backend. Update the Route 53 record to point to the API Gateway API."},"timestamp":"2022-12-13 16:59:00","answer":"D","question_id":257,"url":"https://www.examtopics.com/discussions/amazon/view/91462-exam-aws-certified-solutions-architect-professional-sap-c02/","answer_ET":"D","answers_community":["D (37%)","A (37%)","C (27%)"]},{"id":"UGuP1D686GBs2Pd5bUsh","discussion":[{"upvote_count":"8","poster":"nublit","content":"Selected Answer: C\nC is correct. For Elastic Architecture the best option is API GW + Lambda + DynamoDB","timestamp":"1701698880.0","comment_id":"1087691"},{"poster":"Pinina","comment_id":"1266919","upvote_count":"1","content":"Selected Answer: C\nRespuesta c","timestamp":"1723797180.0"},{"poster":"career360guru","timestamp":"1704824640.0","upvote_count":"2","comment_id":"1117747","content":"Selected Answer: C\noption C"},{"timestamp":"1701184260.0","content":"C is correct. API Gateway, Lambda & DynamoDB for session data","comment_id":"1082677","upvote_count":"2","poster":"shaaam80"},{"content":"Selected Answer: C\nC is the right Answer: APIGW is the ideal choice for exposing the REST API because it can handle varying loads efficiently and scale automatically. API Gateway also integrates seamlessly with AWS Lambda, which is used for the business logic in this solution. This setup allows for easy management and can handle peaks in traffic without manual intervention.","timestamp":"1700930520.0","comment_id":"1080172","poster":"heatblur","upvote_count":"3"},{"comment_id":"1077460","content":"C is answer","timestamp":"1700664720.0","poster":"Totoroha","upvote_count":"2"},{"poster":"devalenzuela86","timestamp":"1700597640.0","content":"Selected Answer: C\nC for sure","comment_id":"1076629","upvote_count":"2"}],"question_images":[],"answer_images":[],"question_id":258,"exam_id":33,"timestamp":"2023-11-21 21:14:00","answers_community":["C (100%)"],"answer":"C","topic":"1","isMC":true,"question_text":"A company has developed a mobile game. The backend for the game runs on several virtual machines located in an on-premises data center. The business logic is exposed using a REST API with multiple functions. Player session data is stored in central file storage. Backend services use different API keys for throttling and to distinguish between live and test traffic.\n\nThe load on the game backend varies throughout the day. During peak hours, the server capacity is not sufficient. There are also latency issues when fetching player session data. Management has asked a solutions architect to present a cloud architecture that can handle the game’s varying load and provide low-latency data access. The API model should not be changed.\n\nWhich solution meets these requirements?","choices":{"D":"Implement the REST API using AWS AppSync. Run the business logic in AWS Lambda. Store player session data in Amazon Aurora Serverless.","C":"Implement the REST API using Amazon API Gateway. Run the business logic in AWS Lambda. Store player session data in Amazon DynamoDB with on-demand capacity.","A":"Implement the REST API using a Network Load Balancer (NLB). Run the business logic on an Amazon EC2 instance behind the NLB. Store player session data in Amazon Aurora Serverless.","B":"Implement the REST API using an Application Load Balancer (ALB). Run the business logic in AWS Lambda. Store player session data in Amazon DynamoDB with on-demand capacity."},"answer_ET":"C","unix_timestamp":1700597640,"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/126758-exam-aws-certified-solutions-architect-professional-sap-c02/"},{"id":"JBhBGiprLI2BovtdJZac","discussion":[{"comment_id":"1245324","content":"Selected Answer: D\nsee on-premises as source and AWS EFS as target","upvote_count":"2","timestamp":"1720591920.0","poster":"vip2"},{"content":"B: no efs connection","upvote_count":"1","timestamp":"1711004760.0","poster":"Pics00094","comment_id":"1179026","comments":[{"comment_id":"1267394","content":"just D","upvote_count":"1","timestamp":"1723856460.0","poster":"helloworldabc"}]},{"comment_id":"1120110","content":"Answer: D\nOption C is also correct but why you need s3 when DataSync moves data directly from the on-premises NFS to EFS, eliminating intermediate storage and transfer steps, reducing latency and potential bottlenecks.","timestamp":"1705000800.0","poster":"vibzr2023","upvote_count":"4"},{"comment_id":"1117752","poster":"career360guru","content":"Selected Answer: D\nOption D","upvote_count":"1","timestamp":"1704825420.0"},{"comment_id":"1095487","content":"Selected Answer: D\nhttps://docs.aws.amazon.com/datasync/latest/userguide/datasync-in-vpc.html","upvote_count":"3","timestamp":"1702473240.0","poster":"zhdetn"},{"comments":[{"comment_id":"1083412","comments":[{"timestamp":"1703218320.0","comment_id":"1103126","content":"but that is not for EFS APIs, not for data flow.","poster":"GoKhe","comments":[{"timestamp":"1703218440.0","poster":"GoKhe","comment_id":"1103128","content":"Also, EFS is accessed over a mount point which can be either an IP or DNS name. Both in private network. so, DX connection is good enough for it. PrivateLink in the answer is meaningless in this case","upvote_count":"2"}],"upvote_count":"1"}],"content":"why not ? See https://docs.aws.amazon.com/efs/latest/ug/efs-vpc-endpoints.html\nSeems to be supported","poster":"dutchy1988","timestamp":"1701260040.0","upvote_count":"1"}],"content":"Everybody sure Answer is D?? So: \nAmazon Elastic File System (Amazon EFS) does not offer AWS PrivateLink support directly.","poster":"Totoroha","comment_id":"1083039","timestamp":"1701220200.0","upvote_count":"1"},{"poster":"shaaam80","timestamp":"1701185580.0","content":"Selected Answer: D\nAnswer - D. Leveraging AWS PrivateLink with a private VIF ensures a private and secure connection between the on-premises environment and the Amazon EFS file system. This eliminates the need for public internet access.","upvote_count":"1","comment_id":"1082698"},{"poster":"salazar35","content":"Selected Answer: D\nD is most likely","timestamp":"1700915940.0","upvote_count":"2","comment_id":"1080003"},{"comment_id":"1076637","content":"Selected Answer: D\nD for sure","upvote_count":"3","poster":"devalenzuela86","timestamp":"1700598300.0"}],"answer":"D","topic":"1","choices":{"C":"Deploy an AWS DataSync agent to an on-premises server that has access to the NFS file system. Send data over the Direct Connect connection to an S3 bucket by using a public VIF. Configure an AWS Lambda function to process event notifications from Amazon S3 and copy the images from Amazon S3 to the EFS file system.","D":"Deploy an AWS DataSync agent to an on-premises server that has access to the NFS file system. Send data over the Direct Connect connection to an AWS PrivateLink interface VPC endpoint for Amazon EFS by using a private VIF. Configure a DataSync scheduled task to send the images to the EFS file system every 24 hours.","A":"Configure a periodic process to run the aws s3 sync command from the on-premises file system to Amazon S3. Configure an AWS Lambda function to process event notifications from Amazon S3 and copy the images from Amazon S3 to the EFS file system.","B":"Deploy an AWS Storage Gateway file gateway with an NFS mount point. Mount the file gateway file system on the on-premises server. Configure a process to periodically copy the images to the mount point."},"question_text":"A company is migrating an application to the AWS Cloud. The application runs in an on-premises data center and writes thousands of images into a mounted NFS file system each night. After the company migrates the application, the company will host the application on an Amazon EC2 instance with a mounted Amazon Elastic File System (Amazon EFS) file system.\n\nThe company has established an AWS Direct Connect connection to AWS. Before the migration cutover, a solutions architect must build a process that will replicate the newly created on-premises images to the EFS file system.\n\nWhat is the MOST operationally efficient way to replicate the images?","unix_timestamp":1700598300,"answer_ET":"D","question_images":[],"answer_images":[],"answer_description":"","answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/126759-exam-aws-certified-solutions-architect-professional-sap-c02/","timestamp":"2023-11-21 21:25:00","question_id":259,"isMC":true,"exam_id":33},{"id":"xJNavRLBD5WGXWcydLgO","exam_id":33,"answer_images":[],"unix_timestamp":1700598600,"timestamp":"2023-11-21 21:30:00","topic":"1","answer_ET":"B","answer_description":"","discussion":[{"timestamp":"1700721420.0","poster":"HunkyBunky","content":"Selected Answer: B\nDefinitely - B, becase you can't assign securityGroup on Cloudfront. Also, security group can have only 60 rules, so you can't add ALL CloudFront IPs into it, so prefix list","comment_id":"1078142","upvote_count":"6"},{"comment_id":"1264604","poster":"tgv","content":"Selected Answer: B\nB for sure","timestamp":"1723459620.0","upvote_count":"1"},{"poster":"pangchn","comment_id":"1171246","timestamp":"1710183120.0","upvote_count":"1","content":"Selected Answer: B\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/limit-access-to-your-origins-using-the-aws-managed-prefix-list-for-amazon-cloudfront/"},{"poster":"LazyAutonomy","timestamp":"1706614740.0","content":"Selected Answer: B\nB, but this is why security architects > solution architects. Any cloudfront distribution, belonging to any account in any org will still have direct access the origin.","upvote_count":"1","comment_id":"1135731"},{"upvote_count":"1","timestamp":"1704826020.0","content":"Selected Answer: B\nOption B","poster":"career360guru","comment_id":"1117756"},{"timestamp":"1702473840.0","poster":"zhdetn","comment_id":"1095491","upvote_count":"4","content":"Selected Answer: B\nhttps://aws.amazon.com/about-aws/whats-new/2022/02/amazon-cloudfront-managed-prefix-list/?nc1=h_ls"},{"upvote_count":"4","content":"Selected Answer: B\nAllow ingress access to ALB SG only from CloudFront prefix list. Answer - B","timestamp":"1701185880.0","comment_id":"1082700","poster":"shaaam80"},{"content":"Selected Answer: B\nB is right","upvote_count":"1","comment_id":"1080005","poster":"salazar35","timestamp":"1700916900.0"},{"upvote_count":"3","timestamp":"1700598600.0","content":"Selected Answer: B\nB for sure","poster":"devalenzuela86","comment_id":"1076639"}],"choices":{"B":"Update ALB security group ingress to allow access only from the com.amazonaws.global.cloudfront.origin-facing CloudFront managed prefix list.","C":"Create a com.amazonaws.region.elasticloadbalancing VPC interface endpoint for Elastic Load Balancing. Update the ALB scheme from internet-facing to internal.","D":"Extract CloudFront IPs from the AWS provided ip-ranges.json document. Update ALB security group ingress to allow access only from CloudFront IPs.","A":"Create a new security group and attach it to the CloudFront distribution. Update the ALB security group ingress to allow access only from the CloudFront security group."},"url":"https://www.examtopics.com/discussions/amazon/view/126760-exam-aws-certified-solutions-architect-professional-sap-c02/","question_images":[],"question_text":"A company recently migrated a web application from an on-premises data center to the AWS Cloud. The web application infrastructure consists of an Amazon CloudFront distribution that routes to an Application Load Balancer (ALB), with Amazon Elastic Container Service (Amazon ECS) to process requests. A recent security audit revealed that the web application is accessible by using both CloudFront and ALB endpoints. However, the company requires that the web application must be accessible only by using the CloudFront endpoint.\n\nWhich solution will meet this requirement with the LEAST amount of effort?","answer":"B","isMC":true,"answers_community":["B (100%)"],"question_id":260}],"exam":{"numberOfQuestions":529,"isMCOnly":true,"isImplemented":true,"name":"AWS Certified Solutions Architect - Professional SAP-C02","lastUpdated":"11 Apr 2025","provider":"Amazon","isBeta":false,"id":33},"currentPage":52},"__N_SSP":true}