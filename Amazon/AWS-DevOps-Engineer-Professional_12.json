{"pageProps":{"questions":[{"id":"88NH7q1ACqmVxVv0UwEQ","question_id":56,"answer_images":[],"topic":"1","answer_description":"","question_text":"A DevOps engineer is working on a data archival project that requires the migration of on-premises data to an Amazon S3 bucket. The DevOps engineer develops a script that incrementally archives on-premises data that is older than 1 month to Amazon S3. Data that is transferred to Amazon S3 is deleted from the on-premises location. The script uses the S3 PutObject operation.\n\nDuring a code review, the DevOps engineer notices that the script does not verify whether the data was successfully copied to Amazon S3. The DevOps engineer must update the script to ensure that data is not corrupted during transmission. The script must use MD5 checksums to verify data integrity before the on-premises data is deleted.\n\nWhich solutions for the script will meet these requirements? (Choose two.)","timestamp":"2023-01-13 22:25:00","isMC":true,"answers_community":["BD (100%)"],"choices":{"C":"Include the checksum digest within the tagging parameter as a URL query parameter.","D":"Check the returned response for the ETag. Compare the returned ETag against the MD5 checksum.","A":"Check the returned response for the Versionld. Compare the returned VersionId against the MD5 checksum.","B":"Include the MD5 checksum within the Content-MD5 parameter. Check the operation call's return status to find out if an error was returned.","E":"Include the checksum digest within the Metadata parameter as a name-value pair. After upload, use the S3 HeadObject operation to retrieve metadata from the object."},"answer":"BD","exam_id":35,"unix_timestamp":1673645100,"answer_ET":"BD","question_images":[],"discussion":[{"upvote_count":"3","comment_id":"825126","content":"Selected Answer: BD\nB for checking that it was sent without any data loss.\nD for checking that the data stored was the expected one without any issues.","poster":"SHoKMaSTeR","timestamp":"1677608100.0"},{"comment_id":"804864","timestamp":"1676072220.0","poster":"ospherenet","content":"Option B is to include the MD5 checksum within the Content-MD5 parameter and check the operation call's return status to find out if an error was returned. Option D is to check the returned response for the ETag and compare the returned ETag against the MD5 checksum. This way, the script can ensure the data was successfully transferred to Amazon S3 and is not corrupted during transmission.","upvote_count":"3"},{"upvote_count":"1","timestamp":"1674876240.0","poster":"Bulti","content":"B,D is correct. MD5 checksum and ETag to verify the checksum passed.","comment_id":"790226"},{"timestamp":"1673645100.0","content":"Selected Answer: BD\nB D for me.https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html","poster":"Dimidrol","upvote_count":"3","comment_id":"774870"}],"url":"https://www.examtopics.com/discussions/amazon/view/95094-exam-aws-devops-engineer-professional-topic-1-question-149/"},{"id":"lbYkUyYYCHxIRgE1qDct","isMC":true,"choices":{"C":"Upload the licenses to a private Amazon S3 bucket. Populate an Amazon SQS queue with the list of licenses stored in S3. Create an AWS CloudFormation template that uses an Auto Scaling group to launch the servers. In the user data script acquire an available license from SQS. Create an Auto Scaling lifecycle hook, then use it to put the license back in SQS after the instance is terminated.","A":"Upload the licenses to a private Amazon S3 bucket. Create an AWS CloudFormation template with a Mappings section for the licenses. In the template, create an Auto Scaling group to launch the servers. In the user data script, acquire an available license from the Mappings section. Create an Auto Scaling lifecycle hook, then use it to update the mapping after the instance is terminated.","D":"Upload the licenses to an Amazon DynamoDB table. Create an AWS CLI script to launch the servers by using the parameter --count, with min:max instances to launch. In the user data script, acquire an available license from the DynamoDB table. Monitor each instance and, in case of failure, replace the instance, then manually update the DynamoDB table.","B":"Upload the licenses to an Amazon DynamoDB table. Create an AWS CloudFormation template that uses an Auto Scaling group to launch the servers. In the user data script, acquire an available license from the DynamoDB table. Create an Auto Scaling lifecycle hook, then use it to update the mapping after the instance is terminated."},"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/8044-exam-aws-devops-engineer-professional-topic-1-question-15/","question_id":57,"answer":"B","answer_ET":"B","topic":"1","answer_description":"","discussion":[{"content":"I believe B is the right solution","poster":"marwan","timestamp":"1632244020.0","upvote_count":"24","comment_id":"21104"},{"comment_id":"99279","content":"A - license list is dynamic (based on scaling) and mapping are good for values that are static in nature\nB - looks good\nC - sqs - unnecessary overhead\nD - too many manual tasks","poster":"Raj9","timestamp":"1634673360.0","upvote_count":"17"},{"poster":"Tika01","timestamp":"1679030820.0","upvote_count":"1","comment_id":"841623","content":"Selected Answer: B\nThis approach allows the licenses to be stored and managed in a central location in an Amazon DynamoDB table. The AWS CloudFormation template can then use an Auto Scaling group to launch the server nodes, which will dynamically acquire a license from the DynamoDB table when the instance starts up using the user data script. An Auto Scaling lifecycle hook can be created to update the license mapping after the instance is terminated. This mechanism allows the software solution to scale and manage licenses automatically. Additionally, the DynamoDB table can be used to create a dashboard that displays which licenses are available at any moment, giving the company greater visibility into license usage."},{"content":"Selected Answer: B\nB is correct because as one condition states that we need to create a dashboard that can be done using dynamodb, Cloudformation instead of CLI scripts to launch instance nodes using ASG. We can use acquire license using TransactGetItems which would in User Data script. ASG lifecycle hook consists terminating:wait where we can run scripts to complete dynamodb transaction on the instance using SSM run command with SSM agent installed on the instance from user data script","upvote_count":"2","timestamp":"1677935580.0","poster":"okm1997_2","comment_id":"828962"},{"poster":"hoomaan","upvote_count":"1","comment_id":"821873","content":"B- Correct","timestamp":"1677364380.0"},{"content":"How is B the correct answer?\nWhat does it even mean update the mapping? What mapping?","comment_id":"809777","upvote_count":"1","poster":"BelloMio","timestamp":"1676480820.0"},{"upvote_count":"1","poster":"Piccaso","comment_id":"797204","content":"Selected Answer: B\nDynamoDB is a must. S3 bucket is not efficient as DynamoDB\nCloudFormation is more effective than self-prepared CLI script","timestamp":"1675441860.0"},{"upvote_count":"2","poster":"Hackmajoris","comment_id":"769695","timestamp":"1673201760.0","comments":[{"comment_id":"797206","content":"Same confusion.","upvote_count":"1","timestamp":"1675441920.0","poster":"Piccaso"}],"content":"Why D is set as the correct answer?"},{"comment_id":"763072","upvote_count":"1","poster":"Bulti","content":"B is the right answer.","timestamp":"1672551240.0"},{"timestamp":"1672265400.0","content":"Selected Answer: B\nB is the right answer","upvote_count":"1","poster":"Teonardo","comment_id":"760380"},{"content":"Selected Answer: B\nB is the good for me","upvote_count":"2","poster":"ceros399","timestamp":"1672147680.0","comment_id":"758551"},{"timestamp":"1670067960.0","comment_id":"734406","upvote_count":"4","content":"The Dev Ops Pro is a measure of how well you know automation. D requires manual intervention. B looks to be the right solution.","poster":"ericzaj"},{"upvote_count":"4","content":"Selected Answer: B\nA - S3 contains static data and there is no information on the available licenses to create dashboard. \nB- DynamoDb contains mapping on the availability of licenses and can create dashboard on the data. \nC - Overhead to maintain S3 and SQS. Hard to create Dashboard out of SQS. \nD - Manual update , no no","timestamp":"1667876160.0","poster":"developer_404","comment_id":"713444"},{"comment_id":"695187","content":"Selected Answer: B\nB is right answer","poster":"nzin4x","upvote_count":"2","timestamp":"1665809100.0"},{"poster":"RogerMarsh","timestamp":"1665137280.0","content":"B is correct.","comment_id":"688501","upvote_count":"1"},{"timestamp":"1661995440.0","upvote_count":"2","poster":"colinquek","comment_id":"655658","content":"B - becos:\n1. dynamodb's transactgetitem api- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html#transaction-apis-txgetitems\n2. CF to generate ASG to manage the EC2s."},{"poster":"blueorca","comment_id":"544068","content":"Selected Answer: B\nShould be B","timestamp":"1644437520.0","upvote_count":"2"},{"timestamp":"1636228140.0","comment_id":"385414","content":"Answer B","poster":"D2","upvote_count":"2"},{"upvote_count":"5","timestamp":"1636001880.0","content":"\"B\" is the right answer. \"A dashboard to verify which licenses are available.\" is a key requirement. S3 and SQS won't provide you such a feature. \"D\" includes CLI scripts. CLI works in most cases, but it is never a right answer if an AWS native solution is available.","comment_id":"381593","poster":"30th"},{"timestamp":"1635886320.0","comment_id":"338637","content":"b it is","poster":"mo_awsdevops","upvote_count":"1"},{"poster":"WhyIronMan","timestamp":"1635589560.0","upvote_count":"2","comment_id":"323459","content":"I'll go with B"},{"timestamp":"1635476160.0","content":"Correct Answer: B","poster":"aws_Tamilan","upvote_count":"1","comment_id":"321926"},{"content":"I believe to C: because lifecycle hook can work with SQS directly https://docs.aws.amazon.com/autoscaling/ec2/userguide/configuring-lifecycle-hook-notifications.html","poster":"yyy","timestamp":"1635305880.0","comment_id":"280743","upvote_count":"1"},{"upvote_count":"2","content":"If you go for A, how do you create dashboard on information stored in the mapping section. There is a need to create dashboard of available license. That is easy with B. So having eliminated D, because of the manual process. You should go for B","comment_id":"253295","timestamp":"1634978580.0","poster":"fogunfunminiyi"},{"timestamp":"1634962560.0","comment_id":"222448","upvote_count":"2","poster":"jackdryan","content":"I'll go with B"},{"upvote_count":"1","timestamp":"1634834640.0","content":"I'll go with B","poster":"ChauPhan","comment_id":"206349"},{"timestamp":"1634796780.0","poster":"SPRao","content":"option B is correct, because once the instance terminate ASG uses lifecycle hooks to update mapping","upvote_count":"1","comment_id":"109609"},{"poster":"zkchen","comment_id":"87576","comments":[{"poster":"lokey","comment_id":"97406","timestamp":"1634596680.0","upvote_count":"1","content":"i believe DynamoDB transactions can cover this"}],"upvote_count":"1","timestamp":"1634456040.0","content":"I prefer to C because of the keyword “parallel” and “MOST effective”.\nhow to guarantee two instances don't get the same copy using dynamoDB?"},{"poster":"Kayode","upvote_count":"2","comment_id":"84085","timestamp":"1634273520.0","content":"The answer is B"},{"content":"B is correct","upvote_count":"1","comment_id":"62173","timestamp":"1634201220.0","poster":"yassu"},{"upvote_count":"1","comment_id":"55493","content":"It is B","poster":"xaocho","timestamp":"1633929660.0"},{"content":"I go with B","timestamp":"1633917600.0","upvote_count":"2","poster":"dinhvu","comment_id":"36374"},{"upvote_count":"2","poster":"un","timestamp":"1633863060.0","comment_id":"33946","content":"I will go with B"},{"comment_id":"31430","content":"I will go with B. Using cli is not efficient way to do it.","upvote_count":"3","poster":"ppshein","timestamp":"1633602360.0"},{"timestamp":"1633559760.0","poster":"amzngenius","content":"B is MOST effective way","upvote_count":"2","comment_id":"30626"},{"comment_id":"28390","content":"I go with b","timestamp":"1633480500.0","poster":"jiedee","upvote_count":"2"},{"poster":"BeastX","content":"Why not A","comments":[{"comments":[{"content":"It's not about Mappings in CloudFormation, rather A doesn't provide complete answer. I believe it's B because DynamoDB looks good place to store such info.","poster":"toshko85","upvote_count":"1","comment_id":"57165","timestamp":"1634111760.0"}],"comment_id":"22516","timestamp":"1632598800.0","upvote_count":"4","content":"Because the mappings section in a CloudFromation template can't be used to store variables. \nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/mappings-section-structure.html","poster":"Arragon"}],"comment_id":"21698","timestamp":"1632456960.0","upvote_count":"2"}],"exam_id":35,"question_images":[],"answer_images":[],"unix_timestamp":1573598640,"question_text":"A company is creating a software solution that executes a specific parallel-processing mechanism. The software can scale to tens of servers in some special scenarios. This solution uses a proprietary library that is license-based, requiring that each individual server have a single, dedicated license installed. The company has 200 licenses and is planning to run 200 server nodes concurrently at most.\nThe company has requested the following features:\n✑ A mechanism to automate the use of the licenses at scale.\n✑ Creation of a dashboard to use in the future to verify which licenses are available at any moment.\nWhat is the MOST effective way to accomplish these requirements?","timestamp":"2019-11-12 23:44:00"},{"id":"Wck1l6OY60AkwuN1awP0","answer_description":"","timestamp":"2023-01-13 22:32:00","discussion":[{"comment_id":"812572","upvote_count":"6","timestamp":"1676687400.0","content":"Selected Answer: A\nBy default, the AWSCodeCommitPowerUser managed policy allows users to push changes to any branch in any repository in the AWS account. To restrict the developers' ability to push changes to the main branch directly, an additional policy is needed that explicitly denies these actions for the main branch.\n\nThe Deny rule should be included in a policy statement that targets the specific repositories and includes a condition that references the main branch. The policy statement should look something like this: \n{\n \"Effect\": \"Deny\",\n \"Action\": [\n \"codecommit:GitPush\",\n \"codecommit:PutFile\"\n ],\n \"Resource\": \"arn:aws:codecommit:<region>:<account-id>:<repository-name>\",\n \"Condition\": {\n \"StringEqualsIfExists\": {\n \"codecommit:References\": [\n \"refs/heads/main\"\n ]\n }\n }","poster":"joseribas89"},{"poster":"Mark1000","upvote_count":"5","timestamp":"1676738460.0","comment_id":"813294","content":"The correct answer is A\n\nOption C is ruled out at the outset, as it is a Managed Policy (managed by AWS) that cannot be changed."},{"comment_id":"812985","timestamp":"1676725800.0","poster":"Piccaso","content":"Selected Answer: A\nhttps://docs.aws.amazon.com/codecommit/latest/userguide/how-to-conditional-branch.html\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-edit.html","upvote_count":"3"},{"poster":"fiesty_questy","comment_id":"807984","timestamp":"1676338500.0","upvote_count":"2","content":"Selected Answer: A\nC is incorrect. You can't modify managed policy"},{"content":"Selected Answer: A\nAdd an additional policy","comment_id":"807897","upvote_count":"2","timestamp":"1676329200.0","poster":"MHK2022"},{"comment_id":"806359","upvote_count":"1","poster":"Piccaso","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/codecommit/latest/userguide/how-to-conditional-branch.html","timestamp":"1676208180.0"},{"timestamp":"1676153580.0","content":"answer is A","comment_id":"805715","poster":"Sabreen_Salama","upvote_count":"2"},{"upvote_count":"2","timestamp":"1676072460.0","comment_id":"804866","content":"A for me. It describes the correct approach to restrict the developers' ability to push changes directly to the main branch in AWS CodeCommit. The company can create an additional policy that includes a Deny rule for the GitPush and PutFile actions for the specific repositories and with a condition that references the main branch. This will restrict the developers from pushing changes directly to the main branch.","poster":"ospherenet"},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/codecommit/latest/userguide/how-to-conditional-branch.html - Other developers can still pull from the branch, make their own branches, and create pull requests, but they cannot push or merge changes to that branch. You can configure this access by creating a conditional policy that uses a context key for one or more branches in IAM.\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-edit.html - AWS managed policies cannot be edited","upvote_count":"2","poster":"kowalkowal","comment_id":"790590","timestamp":"1674909060.0"},{"upvote_count":"2","comment_id":"790231","content":"A is the right answer. We need to add a new policy that denies action to push to the repository 's main branch. C is incorrect because you cannot modify a managed IAM policy.","poster":"Bulti","timestamp":"1674876660.0"},{"comments":[{"comment_id":"781222","upvote_count":"2","timestamp":"1674138420.0","content":"You are right. A is answer.","poster":"Dimidrol"}],"content":"Selected Answer: A\nA for me. Managed policy can not be modified","upvote_count":"3","poster":"saeidp","timestamp":"1674087900.0","comment_id":"780582"},{"upvote_count":"2","poster":"Dimidrol","timestamp":"1673645640.0","comment_id":"774879","content":"https://docs.aws.amazon.com/codecommit/latest/userguide/how-to-conditional-branch.html"},{"content":"Selected Answer: C\nC for me","timestamp":"1673645520.0","comments":[{"content":"You cannot modify MANAGED aws policy. You can only add additional one that forbids. So \"A\" is correct.","upvote_count":"3","comment_id":"784712","poster":"USalo","timestamp":"1674423180.0"}],"upvote_count":"3","poster":"Dimidrol","comment_id":"774878"}],"answer":"A","answer_images":[],"topic":"1","isMC":true,"question_text":"A company uses AWS CodeCommit for source code control. Developers apply their changes to various feature branches and create pull requests to move those changes to the main branch when the changes are ready for production.\n\nThe developers should not be able to push changes directly to the main branch. The company applied the AWSCodeCommitPowerUser managed policy to the developers' IAM role, and now these developers can push changes to the main branch directly on every repository in the AWS account.\n\nWhat should the company do to restrict the developers' ability to push changes to the main branch directly?","exam_id":35,"choices":{"D":"Create an additional policy to include an Allow rule for the GitPush and PutFile actions. Include a restriction for the specific repositories in the policy statement with a condition that references the feature branches.","C":"Modify the IAM policy. Include a Deny rule for the GitPush and PutFile actions for the specific repositories in the policy statement with a condition that references the main branch.","A":"Create an additional policy to include a Deny rule for the GitPush and PutFile actions. Include a restriction for the specific repositories in the policy statement with a condition that references the main branch.","B":"Remove the IAM policy, and add an AWSCodeCommitReadOnly managed policy. Add an Allow rule for the GitPush and PutFile actions for the specific repositories in the policy statement with a condition that references the main branch."},"question_id":58,"unix_timestamp":1673645520,"url":"https://www.examtopics.com/discussions/amazon/view/95101-exam-aws-devops-engineer-professional-topic-1-question-150/","answers_community":["A (82%)","C (18%)"],"answer_ET":"A","question_images":[]},{"id":"wiJpFpMX17q3XsNWG9Qu","unix_timestamp":1673646420,"exam_id":35,"question_id":59,"choices":{"D":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule that matches all AWS Config evaluation results of NON_COMPLIANT. Configure an input transformer for the restricted-ssh rule. Configure the EventBridge (CloudWatch Events) rule to publish a notification to the SNS topic.","C":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule that matches an AWS Config evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure the EventBridge (CloudWatch Events) rule to invoke AWS Systems Manager Run Command on the SNS topic to customize a notification and to publish the notification to the SNS topic.","B":"Configure AWS Config to send all evaluation results for the restricted-ssh rule to the SNS topic. Configure a filter policy on the SNS topic to send only notifications that contain the text of NON_COMPLIANT in the notification to subscribers.","A":"Create an Amazon EventBridge (Amazon CloudWatch Events) rule that matches an AWS Config evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure an input transformer for the EventBridge (CloudWatch Events) rule. Configure the EventBridge (CloudWatch Events) rule to publish a notification to the SNS topic."},"question_images":[],"timestamp":"2023-01-13 22:47:00","url":"https://www.examtopics.com/discussions/amazon/view/95102-exam-aws-devops-engineer-professional-topic-1-question-151/","answer_description":"","topic":"1","question_text":"A company uses a single AWS account to test applications on Amazon EC2 instances. The company has turned on AWS Config in the AWS account and has activated the restricted-ssh AWS Config managed rule.\n\nThe company needs an automated monitoring solution that will provide a customized notification in real time if any security group in the account is not compliant with the restricted-ssh rule. The customized notification must contain the name and ID of the noncompliant security group.\n\nA DevOps engineer creates an Amazon Simple Notification Service (Amazon SNS) topic in the account and subscribes the appropriate personnel to the topic.\n\nWhat should the DevOps engineer do next to meet these requirements?","answer_images":[],"isMC":true,"discussion":[{"poster":"Dimidrol","timestamp":"1673646420.0","comment_id":"774889","content":"Selected Answer: A\nA for me.https://aws.amazon.com/ru/premiumsupport/knowledge-center/config-resource-non-compliant/","upvote_count":"7"},{"timestamp":"1676243640.0","comment_id":"806893","content":"The correct answer is A. Create an Amazon EventBridge (Amazon CloudWatch Events) rule that matches an AWS Config evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure an input transformer for the EventBridge (CloudWatch Events) rule. Configure the EventBridge (CloudWatch Events) rule to publish a notification to the SNS topic.\n\nThis approach uses Amazon EventBridge (previously known as Amazon CloudWatch Events) to filter AWS Config evaluation results based on the restricted-ssh rule and its compliance status (NON_COMPLIANT). An input transformer can be used to customize the information contained in the notification, such as the name and ID of the noncompliant security group. The EventBridge (CloudWatch Events) rule can then be configured to publish a notification to the SNS topic, which will notify the appropriate personnel in real-time.","upvote_count":"4","poster":"ospherenet"},{"poster":"Piccaso","content":"Selected Answer: D\nThe difference between A and D is:\nA: matches an AWS Config evaluation result of NON_COMPLIANT for the restricted-ssh rule. \nD: matches all AWS Config evaluation results of NON_COMPLIANT --> Configure an input transformer for the restricted-ssh rule\n\nWe do need to match all results first, then configure a specific input transformer.","timestamp":"1676210100.0","comment_id":"806391","upvote_count":"3"},{"content":"Selected Answer: B\nA is correct as this is the most efficient way to deliver customized NON_COMPLIANT evaluation results to the subscriber. B is another roundabout way of doing the same but the way it describes is not enough. It will require more complex filtering logic on not just NON_COMPLIANT text but also other attributes of the message since all config change events occurring across all resources are sent to the SNS Topic and filtering only the ones for a specific config rule involves much more than just searching for NON_COMPLIANT text. https://stackoverflow.com/questions/64146609/how-to-configure-aws-config-to-send-compliance-change-notification-to-sns-topic","poster":"Bulti","upvote_count":"1","timestamp":"1674914460.0","comment_id":"790641"},{"comment_id":"783754","upvote_count":"1","poster":"Christina666","content":"Selected Answer: A\nShort description\nUse an EventBridge rule with a custom event pattern and an input transformer to match an AWS Config evaluation rule output as NON_COMPLIANT. Then, route the response to an Amazon Simple Notification Service (Amazon SNS) topic.","timestamp":"1674337740.0"},{"content":"I go with A","upvote_count":"1","poster":"a866325272","timestamp":"1673822280.0","comment_id":"777135"},{"content":"Selected Answer: A\ni agree","poster":"Oleg_gol","comment_id":"776989","timestamp":"1673811060.0","upvote_count":"2"}],"answers_community":["A (71%)","D (21%)","7%"],"answer_ET":"A","answer":"A"},{"id":"xV6SzwT4kPnN4vC9uses","question_text":"A company has an organization in AWS Organizations. The company has configured AWS Single Sign-On (AWS SSO) to centrally manage access to the AWS accounts in the organization. A DevOps engineer needs to ensure that all users sign in by using multi-factor authentication (MFA). Users must be allowed to manage their own MFA devices. Users also must be prompted for MFA every time they sign in.\n\nWhat should the DevOps engineer do to meet these requirements?","answer_images":[],"choices":{"A":"In AWS SSO, configure always-on MFBlock user sign-in when a user does not yet have a registered MFA device.","B":"In AWS SSO, configure always-on MFA. Require a user to register an MFA device at sign-in when the user does not yet have a registered MFA device.","D":"In AWS SSO, configure context-aware MFA. Block user sign-in when a user does not yet have a registered MFA device.","C":"In AWS SSO, configure context-aware MFA. Update the trust policy of all permission sets to include the aws:MultiFactorAuthPresent condition on the sts:AssumeRole action."},"unix_timestamp":1673646600,"answer_ET":"B","topic":"1","question_images":[],"answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/95103-exam-aws-devops-engineer-professional-topic-1-question-152/","question_id":60,"exam_id":35,"isMC":true,"answer":"B","timestamp":"2023-01-13 22:50:00","discussion":[{"poster":"Dimidrol","comment_id":"774891","upvote_count":"5","content":"Selected Answer: B\nB for me. https://docs.aws.amazon.com/singlesignon/latest/userguide/mfa-enable-how-to.html","timestamp":"1673646600.0"},{"timestamp":"1676218200.0","poster":"Piccaso","upvote_count":"2","comment_id":"806525","content":"Selected Answer: B\nBetween \"always-on\" and \"context-aware\", we need to use \"always-on\" because of \"must be prompted for MFA every time they sign in\". C and D are eliminated \nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/mfa-enable-how-to.html\nBetween A and B, B is better https://docs.aws.amazon.com/singlesignon/latest/userguide/how-to-configure-mfa-device-enforcement.html"},{"content":"Selected Answer: B\nB is the right answer","poster":"Bulti","upvote_count":"1","timestamp":"1674916500.0","comment_id":"790664"},{"timestamp":"1674642660.0","upvote_count":"2","poster":"DerekKey","comment_id":"787505","content":"Selected Answer: B\nB: On the Configure multi-factor authentication page, under If a user does not yet have a registered MFA device choose one of the following choices:\nRequire them to register an MFA device at sign in"}],"answer_description":""}],"exam":{"provider":"Amazon","isMCOnly":false,"numberOfQuestions":208,"lastUpdated":"11 Apr 2025","id":35,"isImplemented":true,"name":"AWS DevOps Engineer Professional","isBeta":false},"currentPage":12},"__N_SSP":true}