{"pageProps":{"questions":[{"id":"P4Z6afozN3Js67d2gzz1","answer":"A","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/66483-exam-aws-certified-database-specialty-topic-1-question-167/","discussion":[{"poster":"novice_expert","timestamp":"1651369920.0","content":"Selected Answer: A\nA. Create a custom DB parameter group and set the wait_timeout parameter value to 900. Associate the DB instance with the custom parameter group.\n\nwait_timeout: The number of seconds the server waits for activity on a non-interactive TCP/IP or UNIX File connection before closing it.","comment_id":"595396","upvote_count":"3"},{"timestamp":"1643910480.0","upvote_count":"4","comment_id":"539868","poster":"AriraAWS","content":"Selected Answer: A\nA is the right answer, done that many times...."},{"comment_id":"510995","upvote_count":"3","timestamp":"1640686860.0","content":"Selected Answer: A\nManaged RDS needs parameter grou.\nwait_timeout: The number of seconds the server waits for activity on a non-interactive TCP/IP or UNIX File connection before closing it.","poster":"Shunpin"},{"content":"A is answer","comment_id":"509130","timestamp":"1640438760.0","poster":"odba2014","upvote_count":"1"},{"poster":"MBO80","upvote_count":"3","comments":[{"comment_id":"502422","content":"Yes, the correct answer is A\nFrom part one of that blog series:\n\"You can set parameters globally using a parameter group. Alternatively, you can set them for a particular session using the SET command.\"\nhttps://aws.amazon.com/blogs/database/best-practices-for-configuring-parameters-for-amazon-rds-for-mysql-part-1-parameters-related-to-performance/\nYou can't edit files directly on the RDS servers, must use SET command or Parameter Group","timestamp":"1639594200.0","upvote_count":"1","poster":"grekh001"}],"timestamp":"1639257960.0","content":"For me, answer is A\nhttps://aws.amazon.com/fr/blogs/database/best-practices-for-configuring-parameters-for-amazon-rds-for-mysql-part-3-parameters-related-to-security-operational-manageability-and-connectivity-timeout/","comment_id":"499673"},{"poster":"cynthiacy","content":"C. the answer is wrong, but the link is right!","comments":[{"comment_id":"508721","content":"This is an Amazon managed service, you cannot edit my.cnf file yourself. The correct answer is A","timestamp":"1640370300.0","poster":"jove","upvote_count":"2"}],"timestamp":"1638440640.0","upvote_count":"2","comment_id":"492368"},{"upvote_count":"1","poster":"Sp230","content":"Answer should be B","timestamp":"1638035520.0","comment_id":"488364"},{"comment_id":"483535","upvote_count":"1","poster":"johnconnor","timestamp":"1637517480.0","content":"Actually, I think all the answers could be wrong because you are not supposed to edit the .cnf file in RDS, but you could set the parameter globally with SET GLOBAL wait_timeout = xxxx; there should be an option for that"},{"comment_id":"483529","content":"It should be C!","upvote_count":"1","poster":"johnconnor","timestamp":"1637517120.0"},{"timestamp":"1637517060.0","comment_id":"483528","upvote_count":"1","content":"Answer is wrong, we should open the my.cnf file in /etc/mysql and then restart the server with service mysql restart","poster":"johnconnor"}],"isMC":true,"answers_community":["A (100%)"],"answer_ET":"A","exam_id":22,"choices":{"A":"Create a custom DB parameter group and set the wait_timeout parameter value to 900. Associate the DB instance with the custom parameter group.","C":"Edit the my.cnf file and set the wait_timeout parameter value to 900. Restart the DB instance.","D":"Modify the default DB parameter group and set the wait_timeout parameter value to 900.","B":"Connect to the MySQL database and run the SET SESSION wait_timeout=900 command."},"question_id":76,"answer_description":"","answer_images":[],"topic":"1","unix_timestamp":1637517060,"question_text":"A database specialist needs to configure an Amazon RDS for MySQL DB instance to close non-interactive connections that are inactive after 900 seconds.\nWhat should the database specialist do to accomplish this task?","timestamp":"2021-11-21 18:51:00"},{"id":"NM40XfPzB84tT9Bf5v4G","answer":"B","question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/68542-exam-aws-certified-database-specialty-topic-1-question-168/","discussion":[{"poster":"Pranava_GCP","comment_id":"1018551","upvote_count":"2","content":"Selected Answer: B\nB. Add a cross-Region read replica in the DR Region\n\nthis is MOST operationally efficient solution","timestamp":"1695796620.0"},{"comment_id":"893807","upvote_count":"1","timestamp":"1683713340.0","poster":"tsk9921","content":"B is right"},{"poster":"Sathish_dbs","comment_id":"768809","upvote_count":"2","content":"why not the option A ? replica consumes instance and data cost while snapshots costs less and restore of 3 TB can happen in less than 2 hours to achieve an RTO of 2 hours","timestamp":"1673115540.0","comments":[{"content":"Because copy a 3TB snapshot to another region using lamdba, it will cost far beyond 15 mins.","upvote_count":"1","timestamp":"1690001580.0","comment_id":"959171","poster":"Bota5ky"},{"comment_id":"1018554","timestamp":"1695796800.0","upvote_count":"1","poster":"Pranava_GCP","content":"cost-saving is not a requirement here, but operationally efficient is required in this case."}]},{"content":"Selected Answer: B\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Replication.CrossRegion.html\n\nRTO is 2 hours. With 3 TB database, cross-region replica \n\nGlobal Database was good but DMS ?","timestamp":"1651404240.0","poster":"novice_expert","comment_id":"595566","upvote_count":"2"},{"upvote_count":"3","content":"Would have chosen Global Database, but DMS is not needed there. So D is wrong.","comment_id":"522313","poster":"deepcloud","timestamp":"1642005840.0"},{"upvote_count":"2","poster":"Shunpin","timestamp":"1640690340.0","content":"Selected Answer: B\nRTO is 2 hours. With 3 TB database, cross-region replica is a better option","comment_id":"511029"},{"timestamp":"1640375220.0","poster":"jove","upvote_count":"3","content":"Selected Answer: B\nAnswer is B","comment_id":"508802"}],"isMC":true,"answers_community":["B (100%)"],"answer_ET":"B","question_id":77,"exam_id":22,"choices":{"D":"Create an Aurora global database that spans two Regions. Use AWS Database Migration Service (AWS DMS) to migrate the existing database to the new global database.","B":"Add a cross-Region read replica in the DR Region with the same instance type as the current primary instance. If the read replica in the DR Region needs to be used for production, promote the read replica to become a standalone DB cluster.","C":"Create a smaller DB cluster in the DR Region. Configure an AWS Database Migration Service (AWS DMS) task with change data capture (CDC) enabled to replicate data from the current production DB cluster to the DB cluster in the DR Region.","A":"Implement an AWS Lambda function to take a snapshot of the production DB cluster every 2 hours, and copy that snapshot to an Amazon S3 bucket in the DR Region. Restore the snapshot to an appropriately sized DB cluster in the DR Region."},"answer_description":"","answer_images":[],"topic":"1","unix_timestamp":1640375220,"question_text":"A company is running its production databases in a 3 TB Amazon Aurora MySQL DB cluster. The DB cluster is deployed to the us-east-1 Region. For disaster recovery (DR) purposes, the company's database specialist needs to make the DB cluster rapidly available in another AWS Region to cover the production load with an RTO of less than 2 hours.\nWhat is the MOST operationally efficient solution to meet these requirements?","timestamp":"2021-12-24 20:47:00"},{"id":"Q4eESfsvdQWyczXQUQPf","answer":"D","answer_images":[],"answer_description":"","answers_community":["D (77%)","B (23%)"],"topic":"1","answer_ET":"D","question_text":"A company has an on-premises SQL Server database. The users access the database using Active Directory authentication. The company successfully migrated its database to Amazon RDS for SQL Server. However, the company is concerned about user authentication in the AWS Cloud environment.\nWhich solution should a database specialist provide for the user to authenticate?","unix_timestamp":1636498560,"question_id":78,"choices":{"B":"Establish a forest trust between the on-premises Active Directory and AWS Directory Service for Microsoft Active Directory. Use AWS SSO to configure an Active Directory user delegated to access the databases in RDS for SQL Server.","A":"Deploy Active Directory Federation Services (AD FS) on premises and configure it with an on-premises Active Directory. Set up delegation between the on- premises AD FS and AWS Security Token Service (AWS STS) to map user identities to a role using theAmazonRDSDirectoryServiceAccess managed IAM policy.","C":"Use Active Directory Connector to redirect directory requests to the company's on-premises Active Directory without caching any information in the cloud. Use the RDS master user credentials to connect to the DB instance and configure SQL Server logins and users from the Active Directory users and groups.","D":"Establish a forest trust between the on-premises Active Directory and AWS Directory Service for Microsoft Active Directory. Ensure RDS for SQL Server is using mixed mode authentication. Use the RDS master user credentials to connect to the DB instance and configure SQL Server logins and users from the Active Directory users and groups."},"isMC":true,"exam_id":22,"question_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/65739-exam-aws-certified-database-specialty-topic-1-question-169/","timestamp":"2021-11-09 23:56:00","discussion":[{"poster":"rlnd2000","upvote_count":"6","content":"Selected Answer: D\nD => You need to use sql authentication with master user credential for configuring SQL Server logins and users from the Active Directory users and groups, so for me mixed mode authentication is a MUST, I go with D.\n\nfrom: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_SQLServerWinAuth.html\n...\n6. Use the Amazon RDS master user credentials to connect to the SQL Server DB instance as you do any other DB instance. Because the DB instance is joined to the AWS Managed Microsoft AD domain, you can provision SQL Server logins and users from the Active Directory users and groups in their domain. (These are known as SQL Server \"Windows\" logins.) Database permissions are managed through standard SQL Server permissions granted and revoked to these Windows logins.\n...","comment_id":"602056","timestamp":"1652615160.0"},{"comments":[{"timestamp":"1636767720.0","poster":"palanikumar_n","upvote_count":"1","comment_id":"477239","content":"did you take the exam recently . how many question came from the dump"},{"poster":"johnconnor","comments":[{"content":"\"Amazon RDS uses mixed mode for Windows Authentication\"\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_SQLServerWinAuth.html\nThe correct answer is D","upvote_count":"4","timestamp":"1639052640.0","comment_id":"497710","poster":"grekh001"}],"timestamp":"1637559060.0","content":"I think you are right, I vote for B","upvote_count":"2","comment_id":"483877"}],"poster":"toppic26","content":"Answer is not D. Mixed mode is for both AD and Sql users. Question doesnt require that. Answer is B","comment_id":"476892","timestamp":"1636716540.0","upvote_count":"5"},{"poster":"Pranava_GCP","content":"Selected Answer: B\nB. Establish a forest trust between the on-premises Active Directory and AWS Directory Service for Microsoft Active Directory. Use AWS SSO to configure an Active Directory user delegated to access the databases in RDS for SQL Server. \n\nhttps://aws.amazon.com/what-is/sso/#:~:text=Single%20sign%2Don%20(SSO),with%20one%2Dtime%20user%20authentication.","upvote_count":"1","timestamp":"1693510380.0","comment_id":"995444"},{"content":"Selected Answer: B\nB is my answer. I don't understand why others select D. I will continue reading reasons why","upvote_count":"1","poster":"lollyj","comment_id":"755292","timestamp":"1671925200.0"},{"poster":"awsjjj","comment_id":"694997","content":"Selected Answer: D\nAnswer is D. you have to login to the instance to map the aws directory with sql server logins","comments":[{"upvote_count":"5","content":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_SQLServerWinAuth.html\nUse the Amazon RDS master user credentials to connect to the SQL Server DB instance as you do any other DB instance. Because the DB instance is joined to the AWS Managed Microsoft AD domain, you can provision SQL Server logins and users from the Active Directory users and groups in their domain. (These are known as SQL Server \"Windows\" logins.) Database permissions are managed through standard SQL Server permissions granted and revoked to these Windows logins.","poster":"awsjjj","timestamp":"1665777900.0","comment_id":"694998","comments":[{"timestamp":"1680703440.0","comment_id":"862170","upvote_count":"1","content":"Amazon RDS uses mixed mode for Windows Authentication. This approach means that the master user (the name and password used to create your SQL Server DB instance) uses SQL Authentication. Because the master user account is a privileged credential, you should restrict access to this account.\n\nTo get Windows Authentication using an on-premises or self-hosted Microsoft Active Directory, create a forest trust. The trust can be one-way or two-way. For more information on setting up forest trusts using AWS Directory Service, see When to create a trust relationship in the AWS Directory Service Administration Guide.","poster":"Mintwater"}]}],"timestamp":"1665777780.0","upvote_count":"5"},{"comment_id":"623543","timestamp":"1656373260.0","upvote_count":"2","poster":"Omijh","content":"Selected Answer: B\nThe link reference clearly shows after the forest trust you can either connect with sso or access link. The option D has multiple problem 1. connect using master creds [not required & unwanted] 2. Mixed mode will allow both the AD and the regular connection which the client didn't want in the first place."},{"timestamp":"1655827440.0","comment_id":"619930","upvote_count":"1","poster":"sachin","content":"D is correct"},{"comment_id":"594558","content":"Selected Answer: B\nD uses master user access","timestamp":"1651246680.0","poster":"novice_expert","upvote_count":"1"},{"upvote_count":"1","timestamp":"1649455440.0","poster":"Rama_aws","comment_id":"583064","content":"Selected Answer: D\nThe correct answer is D"},{"content":"Selected Answer: D\nD is correct","comment_id":"561011","poster":"RotterDam","timestamp":"1646423820.0","upvote_count":"2"},{"poster":"tugboat","content":"Selected Answer: D\nPer - https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_SQLServerWinAuth.html\nAmazon RDS uses mixed mode for Windows Authentication. This approach means that the master user (the name and password used to create your SQL Server DB instance) uses SQL Authentication. Because the master user account is a privileged credential, you should restrict access to this account.\n\nTo get Windows Authentication using an on-premises or self-hosted Microsoft Active Directory, create a forest trust.","comment_id":"554979","timestamp":"1645662420.0","upvote_count":"3"},{"comment_id":"497806","upvote_count":"2","poster":"nood","timestamp":"1639061160.0","content":"D for me\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_SQLServerWinAuth.html"},{"comment_id":"492703","poster":"Justu","content":"Nope, Right answer is D:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_SQLServerWinAuth.html\nRead it and understand.","timestamp":"1638465600.0","upvote_count":"2"},{"timestamp":"1636498560.0","comment_id":"475112","poster":"leunamE","content":"Answer is D. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_SQLServerWinAuth.html","upvote_count":"3"}]},{"id":"B9M6ibLFyy2CvSjvb8lP","topic":"1","discussion":[{"upvote_count":"14","timestamp":"1632754260.0","comment_id":"139697","content":"C. \nhttps://docs.aws.amazon.com/redshift/latest/dg/concurrency-scaling.html\n\"ith the Concurrency Scaling feature, you can support virtually unlimited concurrent users and concurrent queries, with consistently fast query performance. When concurrency scaling is enabled, Amazon Redshift automatically adds additional cluster capacity when you need it to process an increase in concurrent read queries. Write operations continue as normal on your main cluster. Users always see the most current data, whether the queries run on the main cluster or on a concurrency scaling cluster. You're charged for concurrency scaling clusters only for the time they're in use. For more information about pricing, see Amazon Redshift pricing. You manage which queries are sent to the concurrency scaling cluster by configuring WLM queues. When you enable concurrency scaling for a queue, eligible queries are sent to the concurrency scaling cluster instead of waiting in line.\"","poster":"BillyMadison"},{"comment_id":"911059","timestamp":"1685526840.0","content":"These days, wouldn't you rather use RA3 nodes that automatically unload unused data to 23","upvote_count":"2","poster":"aviathor"},{"poster":"novice_expert","content":"Selected Answer: C\nhttps://docs.aws.amazon.com/redshift/latest/dg/concurrency-scaling.html","timestamp":"1651174560.0","upvote_count":"1","comment_id":"594015"},{"content":"D.\nMain cluster can't be a single-node cluster.","timestamp":"1647916680.0","comment_id":"572655","upvote_count":"1","poster":"JustPassIt"},{"poster":"GMartinelli","timestamp":"1638891720.0","upvote_count":"2","content":"Selected Answer: C\nOption C","comment_id":"496149"},{"timestamp":"1634828340.0","poster":"GaryY","comments":[{"timestamp":"1635309540.0","comment_id":"463419","comments":[{"timestamp":"1664850360.0","upvote_count":"3","poster":"Jiang_aws1","comment_id":"685878","content":"# https://aws.amazon.com/redshift/faqs/\nQ: What is Elastic Resize and how is it different from Concurrency Scaling?\n\nElastic Resize adds or removes nodes from a single Redshift cluster within minutes to manage its query throughput. For example, an ETL workload for certain hours in a day or\nmonth-end reporting may need additional Amazon Redshift resources to complete on time. Concurrency Scaling adds additional cluster resources to increase the overall \nquery concurrency."}],"poster":"surisitcs","upvote_count":"1","content":"Elastic resize is only available for Amazon Redshift clusters that use the EC2-VPC platform. Option of \"Dense Storage\" and \"Elastic resize\" is mutually exclusive I think"}],"upvote_count":"1","content":"Why not D? I think D (Redshift elastic resize) is also correct.","comment_id":"461730"},{"upvote_count":"1","poster":"GMartinelli","timestamp":"1634625180.0","comments":[{"content":"redshift spectrum doesn't have fast response so C is incorrect.","comment_id":"799952","poster":"im_not_robot","upvote_count":"1","timestamp":"1675700640.0"}],"comment_id":"445280","content":"C. But I would argue that you could use redshift spectrum for everything, I just don´t know if you can use it on S3 IA for the historical data, but it might work."},{"comment_id":"437454","timestamp":"1634336640.0","content":"C ==>> Correct","upvote_count":"2","poster":"guru_ji"},{"upvote_count":"1","content":"C => S3 + local storage + concurrency scaling","timestamp":"1634198400.0","comment_id":"434508","poster":"aws4myself"},{"comment_id":"314763","upvote_count":"1","poster":"LMax","timestamp":"1634013180.0","content":"Agree with C"},{"poster":"myutran","comment_id":"297846","content":"Ans: C","upvote_count":"1","timestamp":"1633582380.0"},{"upvote_count":"2","timestamp":"1633101360.0","content":"C is the answer","poster":"Ebi","comment_id":"153374"},{"comment_id":"145727","content":"C Here","upvote_count":"2","timestamp":"1632932580.0","poster":"BillyC"}],"question_id":79,"unix_timestamp":1595262600,"question_images":[],"timestamp":"2020-07-20 18:30:00","question_text":"A company needs a data warehouse solution that keeps data in a consistent, highly structured format. The company requires fast responses for end-user queries when looking at data from the current year, and users must have access to the full 15-year dataset, when needed. This solution also needs to handle a fluctuating number incoming queries. Storage costs for the 100 TB of data must be kept low.\nWhich solution meets these requirements?","answer":"C","answer_description":"","choices":{"D":"Leverage an Amazon Redshift data warehouse solution using a dense storage instance to store the most recent data. Keep historical data on Amazon S3 and access it using the Amazon Redshift Spectrum layer. Leverage Amazon Redshift elastic resize.","B":"Leverage an Amazon Redshift data warehouse solution using a dense storage instance to store the most recent data. Keep historical data on Amazon S3 and access it using the Amazon Redshift Spectrum layer. Provision enough instances to support high demand.","C":"Leverage an Amazon Redshift data warehouse solution using a dense storage instance to store the most recent data. Keep historical data on Amazon S3 and access it using the Amazon Redshift Spectrum layer. Enable Amazon Redshift Concurrency Scaling.","A":"Leverage an Amazon Redshift data warehouse solution using a dense storage instance type while keeping all the data on local Amazon Redshift storage. Provision enough instances to support high demand."},"answers_community":["C (100%)"],"isMC":true,"answer_ET":"C","answer_images":[],"exam_id":22,"url":"https://www.examtopics.com/discussions/amazon/view/26261-exam-aws-certified-database-specialty-topic-1-question-17/"},{"id":"v6WxzRyO2ryTluBIUNgF","question_images":[],"timestamp":"2021-11-12 13:55:00","exam_id":22,"answer_images":[],"answer_ET":"B","isMC":true,"discussion":[{"comment_id":"478767","timestamp":"1636989480.0","poster":"toppic26","upvote_count":"11","content":"Answer is B: https://docs.aws.amazon.com/redshift/latest/mgmt/managing-snapshots-console.html#xregioncopy-kms-encrypted-snapshot"},{"timestamp":"1679780520.0","poster":"backbencher2022","comment_id":"850482","upvote_count":"1","content":"Selected Answer: B\nAnswer is B - https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-db-encryption.html#configure-snapshot-copy-grant"},{"comment_id":"594761","content":"Selected Answer: B\nnew KMS CMK in the destination Region\n-> snapshot copy grant in the destination Region specifying the new key\n->In the source Region, configure cross-Region snapshots for the Amazon Redshift cluster specifying \n- the destination Region, \n- the snapshot copy grant, \n- and retention periods for the snapshot.","poster":"novice_expert","upvote_count":"2","timestamp":"1651280460.0"},{"comment_id":"585203","content":"Selected Answer: B\nB is the right answer","timestamp":"1649855640.0","upvote_count":"2","poster":"amitkhurana"},{"content":"Option B.","comment_id":"528401","poster":"awsmonster","upvote_count":"1","timestamp":"1642682880.0"},{"content":"Option B.","comment_id":"476933","poster":"leunamE","upvote_count":"3","timestamp":"1636721700.0"}],"unix_timestamp":1636721700,"question_id":80,"topic":"1","choices":{"B":"Create a new AWS Key Management Service (AWS KMS) customer managed key in the destination Region. Create a snapshot copy grant in the destination Region specifying the new key. In the source Region, configure cross-Region snapshots for the Amazon Redshift cluster specifying the destination Region, the snapshot copy grant, and retention periods for the snapshot.","D":"Use the same customer-supplied key materials to create a CMK with the same private key in the destination Region. Configure cross-Region snapshots in the source Region targeting the destination Region. Specify the corresponding CMK in the destination Region to encrypt the snapshot.","A":"Copy the AWS Key Management Service (AWS KMS) customer managed key from the source Region to the destination Region. Set up an AWS Glue job in the source Region to copy the latest snapshot of the Amazon Redshift cluster from the source Region to the destination Region. Use a time-based schedule in AWS Glue to run the job on a daily basis.","C":"Copy the AWS Key Management Service (AWS KMS) customer-managed key from the source Region to the destination Region. Create Amazon S3 buckets in each Region using the keys from their respective Regions. Use Amazon EventBridge (Amazon CloudWatch Events) to schedule an AWS Lambda function in the source Region to copy the latest snapshot to the S3 bucket in that Region. Configure S3 Cross-Region Replication to copy the snapshots to the destination Region, specifying the source and destination KMS key IDs in the replication configuration."},"question_text":"A company uses an Amazon Redshift cluster to run its analytical workloads. Corporate policy requires that the company's data be encrypted at rest with customer managed keys. The company's disaster recovery plan requires that backups of the cluster be copied into another AWS Region on a regular basis.\nHow should a database specialist automate the process of backing up the cluster data in compliance with these policies?","answer":"B","answer_description":"","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/amazon/view/65890-exam-aws-certified-database-specialty-topic-1-question-170/"}],"exam":{"name":"AWS Certified Database - Specialty","numberOfQuestions":359,"isBeta":false,"lastUpdated":"11 Apr 2025","provider":"Amazon","isImplemented":true,"isMCOnly":false,"id":22},"currentPage":16},"__N_SSP":true}