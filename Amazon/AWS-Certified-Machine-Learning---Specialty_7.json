{"pageProps":{"questions":[{"id":"T18Wfz3DW9c0oe9xnTIn","unix_timestamp":1615433100,"answer_images":[],"answer":"D","answers_community":["D (100%)"],"discussion":[{"comment_id":"359490","poster":"AShahine21","upvote_count":"18","timestamp":"1650569040.0","content":"I will go with D, \"cannot be accessed and transferred to a remote host by malicious code accidentally installed on the training container\"\n\nBased on the following link: https://aws.amazon.com/blogs/security/secure-deployment-of-amazon-sagemaker-resources/\n\"EnableNetworkIsolation â€“ Set this to true when creating training, hyperparameter tuning, and inference jobs to prevent situations like malicious code being accidentally installed and transferring data to a remote host.\""},{"comments":[{"poster":"Dr_Kiko","timestamp":"1651805940.0","comment_id":"434076","upvote_count":"1","content":"ahaha this link literally contains the answer\nFor example, a malicious user or code that you accidentally install on the container (in the form of a publicly available source code library) could access your data and transfer it to a remote host."}],"content":"If you enable network isolation, the containers can't make any outbound network calls, even to other AWS services such as Amazon S3. Additionally, no AWS credentials are made available to the container runtime environment. In the case of a training job with multiple instances, network inbound and outbound traffic is limited to the peers of each training container. SageMaker still performs download and upload operations against Amazon S3 using your SageMaker execution role in isolation from the training or inference container.","comment_id":"318407","timestamp":"1648428960.0","upvote_count":"8","poster":"achiko"},{"timestamp":"1725690180.0","poster":"james2033","upvote_count":"1","comment_id":"1167785","content":"Selected Answer: D\n'network isolation' make sense"},{"comment_id":"1010548","content":"Selected Answer: D\nA. NO - Remove Amazon S3 access permissions from the SageMaker execution role.\nB. NO - Encrypting the weights has nothing to do with protecting the training data\nC. NO - If the dataset is encrypted, one may still hack SageMaker instance and get access to uncrypted data\nD. YES - Enable network isolation for training jobs, data is protected end-to-end","timestamp":"1710770340.0","upvote_count":"2","poster":"loict"},{"comment_id":"991215","timestamp":"1709017680.0","poster":"Mickey321","content":"Selected Answer: D\nNetwork isolation","upvote_count":"2"},{"upvote_count":"3","poster":"Valcilio","timestamp":"1693943400.0","comment_id":"830354","content":"Selected Answer: D\nIt's D, not C because encrypted can be stole."},{"poster":"halfway","content":"I choose D. More document about it: https://docs.aws.amazon.com/sagemaker/latest/dg/mkt-algo-model-internet-free.html","upvote_count":"2","timestamp":"1651822560.0","comment_id":"451393"},{"poster":"benson2021","upvote_count":"4","timestamp":"1650196320.0","comment_id":"334012","content":"Answer is D.\nhttps://aws.amazon.com/blogs/security/secure-deployment-of-amazon-sagemaker-resources/\nsearch for 'isolation' and there is a security parameter : EnableNetworkIsolation talking about this."},{"content":"I would choose C","timestamp":"1649406600.0","poster":"Vita_Rasta84444","comment_id":"325613","upvote_count":"1"},{"comments":[{"comment_id":"434075","content":"incorrect; you CAN transfer encrypted files even w/o a key\nD is a better option","upvote_count":"1","timestamp":"1651800480.0","poster":"Dr_Kiko"}],"comment_id":"307575","content":"most likely it is C. \nhttps://docs.aws.amazon.com/sagemaker/latest/dg/data-protection.html","poster":"omar_bahrain","upvote_count":"5","timestamp":"1648237380.0"}],"answer_ET":"D","isMC":true,"topic":"1","choices":{"C":"Encrypt the training and validation dataset.","B":"Encrypt the weights of the CNN model.","D":"Enable network isolation for training jobs.","A":"Remove Amazon S3 access permissions from the SageMaker execution role."},"timestamp":"2021-03-11 04:25:00","answer_description":"","exam_id":26,"question_images":[],"question_id":31,"url":"https://www.examtopics.com/discussions/amazon/view/46341-exam-aws-certified-machine-learning-specialty-topic-1/","question_text":"A machine learning specialist is developing a proof of concept for government users whose primary concern is security. The specialist is using Amazon\nSageMaker to train a convolutional neural network (CNN) model for a photo classifier application. The specialist wants to protect the data so that it cannot be accessed and transferred to a remote host by malicious code accidentally installed on the training container.\nWhich action will provide the MOST secure protection?"},{"id":"wMGPUSXLshZtkUBakybW","exam_id":26,"question_images":[],"answer_images":[],"answer":"C","choices":{"C":"Create a private workforce and manifest file. Create a labeling job by using the built-in bounding box task type in Amazon SageMaker Ground Truth. Write the labeling instructions.","A":"Create a workforce with AWS Identity and Access Management (IAM). Build a labeling tool on Amazon EC2 Queue images for labeling by using Amazon Simple Queue Service (Amazon SQS). Write the labeling instructions.","D":"Create a workforce with Amazon Cognito. Build a labeling web application with AWS Amplify. Build a labeling workflow backend using AWS Lambda. Write the labeling instructions.","B":"Create an Amazon Mechanical Turk workforce and manifest file. Create a labeling job by using the built-in image classification task type in Amazon SageMaker Ground Truth. Write the labeling instructions."},"unix_timestamp":1612569300,"question_id":32,"question_text":"A medical imaging company wants to train a computer vision model to detect areas of concern on patients' CT scans. The company has a large collection of unlabeled CT scans that are linked to each patient and stored in an Amazon S3 bucket. The scans must be accessible to authorized users only. A machine learning engineer needs to build a labeling pipeline.\nWhich set of steps should the engineer take to build the labeling pipeline with the LEAST effort?","discussion":[{"content":"I would answer C, because of the requirement that authorized users should only have access. These users will comprise the private workforce of AWS Ground Truth. See documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-private.html","poster":"[Removed]","timestamp":"1663617180.0","comment_id":"284449","comments":[{"upvote_count":"3","timestamp":"1667007720.0","comment_id":"317716","content":"Agree C","poster":"CharlesChiang"},{"content":"Yes it is C","timestamp":"1666071180.0","poster":"astonm13","comment_id":"291835","upvote_count":"1"},{"content":"agree C","poster":"cnethers","timestamp":"1664017260.0","comment_id":"287110","upvote_count":"2"}],"upvote_count":"17"},{"timestamp":"1667713260.0","comment_id":"334031","upvote_count":"8","content":"Answer is C. The question mentions that \"to detect *areas* of concern on patients' CT scans\", that can be achieved by bounding box instead of image classification.\nbounding box: https://docs.aws.amazon.com/sagemaker/latest/dg/sms-bounding-box.html\nimage classification: https://docs.aws.amazon.com/sagemaker/latest/dg/sms-image-classification.html","comments":[{"comment_id":"878871","upvote_count":"1","timestamp":"1713916800.0","content":"The concern here is not about \"object detection\" or \"image classification\". it is about using \"ground truth\" and \"private workforce\"","poster":"ZSun"}],"poster":"benson2021"},{"poster":"jopaca1216","timestamp":"1726445460.0","upvote_count":"2","content":"The principal key is that Mechanical Turk workforce does not ensure privacy of the CT Scans, and Ground Truth does.","comment_id":"1008766"},{"timestamp":"1707860100.0","upvote_count":"3","comment_id":"807819","poster":"AjoseO","content":"Selected Answer: C\nThis option would allow the medical imaging company to create a private workforce, which can ensure that only authorized users have access to the scans, and to use Amazon SageMaker Ground Truth to create a labeling job, which would simplify the labeling pipeline process."},{"upvote_count":"1","comment_id":"667346","poster":"Shailendraa","content":"12-sep exam","timestamp":"1694543460.0"},{"upvote_count":"2","content":"Selected Answer: C\nC - GroundTruth and privacy concerns","comment_id":"624007","timestamp":"1687961220.0","poster":"ovokpus"}],"timestamp":"2021-02-06 00:55:00","url":"https://www.examtopics.com/discussions/amazon/view/44091-exam-aws-certified-machine-learning-specialty-topic-1/","topic":"1","answer_ET":"C","answers_community":["C (100%)"],"isMC":true,"answer_description":""},{"id":"uj2wUcZAsbRgxMwQF5wR","topic":"1","choices":{"A":"Configure Amazon Textract to route low-confidence predictions to Amazon SageMaker Ground Truth. Perform a manual review on those words before performing a business validation.","C":"Configure Amazon Textract to route low-confidence predictions to Amazon Augmented AI (Amazon A2I). Perform a manual review on those words before performing a business validation.","D":"Use Amazon Rekognition's feature to detect text in an image to extract the data from scanned images. Use this information to process the loan applications.","B":"Use an Amazon Textract synchronous operation instead of an asynchronous operation."},"answer":"C","isMC":true,"exam_id":26,"url":"https://www.examtopics.com/discussions/amazon/view/44092-exam-aws-certified-machine-learning-specialty-topic-1/","question_images":[],"discussion":[{"comment_id":"284451","timestamp":"1682458680.0","comments":[{"content":"yeap, it literally says it there \nLoan or mortgage applications, tax forms, and many other financial documents contain millions of data points which need to be processed and extracted quickly and effectively. Using Amazon Textract and Amazon A2I you can extract critical data from these forms","upvote_count":"5","comment_id":"434069","poster":"Dr_Kiko","timestamp":"1682961720.0"}],"content":"I agree with C, given we are evaluating model inferences (predictions). See https://aws.amazon.com/augmented-ai/ and https://aws.amazon.com/blogs/machine-learning/automated-monitoring-of-your-machine-learning-models-with-amazon-sagemaker-model-monitor-and-sending-predictions-to-human-review-workflows-using-amazon-a2i/","poster":"[Removed]","upvote_count":"21"},{"poster":"alp_ileri","upvote_count":"1","timestamp":"1725753840.0","content":"why not a?","comment_id":"832452","comments":[{"timestamp":"1729728540.0","comment_id":"878879","content":"the differences rely on the function of these two service. Ground Truth is used for \"labeling\" typically, text or image label: if the service cannot automatically label the data, it send to ground truth and wait for human to label it.\nbut A2I is for validate prediction. The model already predict the results and human then add views to it.","upvote_count":"5","poster":"ZSun","comments":[{"upvote_count":"2","content":"https://docs.aws.amazon.com/textract/latest/dg/a2i-textract.html\nhttps://aws.amazon.com/blogs/machine-learning/using-amazon-textract-with-amazon-augmented-ai-for-processing-critical-documents/","comment_id":"889001","poster":"ZSun","timestamp":"1730679420.0"}]},{"upvote_count":"2","comment_id":"832453","poster":"alp_ileri","content":"i think ground truth can do same task instead of Augmented AI","timestamp":"1725753900.0"}]},{"poster":"Valcilio","comment_id":"830357","timestamp":"1725566040.0","upvote_count":"2","content":"Selected Answer: C\nThe answer is C, Augmented AI is made for review ML predictions!"},{"poster":"AjoseO","upvote_count":"1","content":"Selected Answer: C\nBy routing the low-confidence predictions to Amazon Augmented AI, the company can reduce the time to process the loan applications by leveraging human intelligence to review and validate the predictions. This way, the company can quickly address any errors or mistakes that Amazon Textract might make, reducing the time to process loan applications.","timestamp":"1723577820.0","comment_id":"807822"},{"poster":"Juka3lj","timestamp":"1682771280.0","content":"correct is C","comment_id":"342989","upvote_count":"2"}],"answer_ET":"C","timestamp":"2021-02-06 00:58:00","answers_community":["C (100%)"],"question_id":33,"answer_images":[],"question_text":"A company is using Amazon Textract to extract textual data from thousands of scanned text-heavy legal documents daily. The company uses this information to process loan applications automatically. Some of the documents fail business validation and are returned to human reviewers, who investigate the errors. This activity increases the time to process the loan applications.\nWhat should the company do to reduce the processing time of loan applications?","unix_timestamp":1612569480,"answer_description":""},{"id":"XO5QdPmszIiAExyRap43","question_id":34,"answer_ET":"C","unix_timestamp":1614282000,"answer_images":[],"url":"https://www.examtopics.com/discussions/amazon/view/45615-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"content":"C is the correct answer. # of shard is determined by:\n1. # of transactions per second\ntimes\n2. data blob eg. 100 KB in size\n3. One shard can Ingest 1 MB/second","upvote_count":"38","timestamp":"1648306560.0","comment_id":"299347","poster":"SophieSu"},{"upvote_count":"13","poster":"dolorez","comment_id":"605004","timestamp":"1669066080.0","content":"the answer should be A - the reason why shards are not the right answer is the lack of ProvisionedThroughputExceeded exceptions that occur when a KDS has too few shards. The scenario talks about a consistent pace of delivery into S3 and a rising backlog of data (which indicates KDS stream is still able to ingest data) in the stream, hence the S3 write limit per prefix is at fault:\n\nhttps://www.amazonaws.cn/en/kinesis/data-streams/faqs/#:~:text=Q%3A%20What%20happens%20if%20the%20capacity%20limits%20of%20a%20Kinesis%20stream%20are%20exceeded%20while%20the%20data%20producer%20adds%20data%20to%20the%20stream%3F\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html","comments":[{"content":"from https://aws.amazon.com/kinesis/data-firehose/faqs/?nc1=h_ls\n\nQ: How often does Kinesis Data Firehose read data from my Kinesis stream?\nA: Kinesis Data Firehose calls Kinesis Data Streams GetRecords() once every second for each Kinesis shard.\n\n// and the number of records per GetRecords() is at most 10.000\n\n=> having n shards you will get at most 10.000n records to firehose per sec. => hence firehose instead of s3 could be the limiting factor.\n\n=> i'd also go with inc shards as the first choice (to not having to change the S3 consumers)","timestamp":"1715866500.0","upvote_count":"1","comment_id":"1072545","poster":"u_b"}]},{"content":"Selected Answer: A\nshards is a concept in kinesis data stream.\nBut here the topic mention \"There also is an increasing backlog of data for Kinesis Data Streams and Kinesis Data Firehose to ingest\"\nSo even firehose has large backlogs, which means the limit comes from the S3.\n\nSo A.","upvote_count":"1","timestamp":"1731897000.0","poster":"rav009","comment_id":"1213081"},{"comment_id":"1155753","upvote_count":"2","content":"Selected Answer: A\nThe bottle neck is not at data ingestion (i.e. Kinesis shards), but in write to S3, which throughput is bound by prefixes used.","timestamp":"1724255160.0","poster":"pupsik"},{"timestamp":"1713544800.0","content":"A is not solving the issue, the bottleneck locate not in S3 but in the KDS, so we should solve the problem at the KDS, the Shards","comment_id":"1048115","upvote_count":"1","poster":"wendaz"},{"upvote_count":"4","timestamp":"1710772380.0","comment_id":"1010589","content":"I think the question is very ambiguous. \"There also is an increasing backlog of data for Kinesis Data Streams and Kinesis Data Firehose to ingest.\", that suggest the backlog is on the client-side (even before reaching KDS). Any component down the chain can be a bottlneck (KDS shrad, Firehose, S3). There is just no way to know in my opinion, but increasing shard is certainly the easiest to try without impact the storage structure in S3 and possibly breaking the app.","poster":"loict"},{"timestamp":"1709087340.0","upvote_count":"1","comment_id":"991716","content":"Selected Answer: C\nthis is my key word to solve this problem :\nThere also is an increasing backlog of data for Kinesis Data Streams and Kinesis Data Firehose to ingest.\nso increasing the shards to ingest is the solution","poster":"teka112233"},{"timestamp":"1709020320.0","upvote_count":"1","poster":"Mickey321","comment_id":"991234","content":"Selected Answer: C\nno of shards"},{"content":"Selected Answer: C\nA is not correct, because \"There also is an increasing backlog of data for Kinesis Data Streams and Kinesis Data Firehose to ingest\", the backlog is totally not caused by S3 performance, but the shard issue.","upvote_count":"2","poster":"daidaidai","comment_id":"891294","timestamp":"1699358880.0"},{"upvote_count":"3","timestamp":"1696407840.0","poster":"Mllb","content":"Selected Answer: C\nTo increase ingest","comment_id":"860802"},{"content":"Selected Answer: C\nThe increasing backlog of data for Kinesis Data Streams and Kinesis Data Firehose indicates that the ingestion rate is slower than the data production rate. Therefore, the next step to improve the data ingestion rate into Amazon S3 is to increase the capacity of Kinesis Data Streams by increasing the number of shards. This will increase the parallelism of data processing, allowing for a higher throughput rate. Option C is the correct answer.\n\nOption A is incorrect because increasing the number of S3 prefixes for the delivery stream will not directly affect the ingestion rate into S3.","timestamp":"1695414120.0","poster":"AjoseO","upvote_count":"4","comment_id":"847569"},{"upvote_count":"3","poster":"Aninina","timestamp":"1688553660.0","comment_id":"766618","content":"Selected Answer: C\nTo improve the data ingestion rate into Amazon S3, the ML specialist should consider increasing the number of shards for the Kinesis data stream. A Kinesis data stream is made up of one or more shards, and each shard provides a fixed amount of capacity for ingesting and storing data. By increasing the number of shards, the specialist can increase the overall capacity of the data stream and improve the rate at which data is ingested."},{"upvote_count":"3","poster":"GauravLahotiML","content":"Selected Answer: C\nC is the correct answer","comment_id":"723790","timestamp":"1684682820.0"},{"upvote_count":"3","poster":"aScientist","content":"Selected Answer: C\nClearly S3 is a bottleneck. S3 has parallel perfromance acrtoss prefixes, thus increasing throughput","comment_id":"711209","timestamp":"1683202980.0"},{"comment_id":"673387","poster":"niopio","content":"Selected Answer: A\nIt seems S3 is the bottlneck. Adding more prefixes will help:\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html","timestamp":"1679244600.0","upvote_count":"6"},{"comment_id":"667348","poster":"Shailendraa","content":"12-sep exam","timestamp":"1678653060.0","upvote_count":"1"},{"comment_id":"644422","content":"The question seems to indicate the problem in the ability of S3 to load the data. Therefore, I think the answer is A.\nhttps://docs.aws.amazon.com/firehose/latest/dev/dynamic-partitioning.html","upvote_count":"2","timestamp":"1675941900.0","poster":"V_B_"},{"timestamp":"1674215280.0","upvote_count":"3","comment_id":"633966","poster":"KlaudYu","content":"Selected Answer: A\n\"As the amount of data rises, a machine learning professional sees that the pace at which data is fed into Amazon S3 remains rather consistent\". It means there is a bottleneck in S3"},{"content":"This question is a piece of shard. I shardded trying to answer this question.","timestamp":"1659994380.0","comment_id":"543401","poster":"AddiWei","upvote_count":"6"}],"answer":"C","isMC":true,"answers_community":["C (63%)","A (38%)"],"exam_id":26,"topic":"1","choices":{"C":"Increase the number of shards for the data stream.","D":"Add more consumers using the Kinesis Client Library (KCL).","A":"Increase the number of S3 prefixes for the delivery stream to write to.","B":"Decrease the retention period for the data stream."},"question_images":[],"question_text":"A company ingests machine learning (ML) data from web advertising clicks into an Amazon S3 data lake. Click data is added to an Amazon Kinesis data stream by using the Kinesis Producer Library (KPL). The data is loaded into the S3 data lake from the data stream by using an Amazon Kinesis Data Firehose delivery stream. As the data volume increases, an ML specialist notices that the rate of data ingested into Amazon S3 is relatively constant. There also is an increasing backlog of data for Kinesis Data Streams and Kinesis Data Firehose to ingest.\nWhich next step is MOST likely to improve the data ingestion rate into Amazon S3?","timestamp":"2021-02-25 20:40:00","answer_description":""},{"id":"Ce7UhROP0QYDaZV23Ghn","timestamp":"2021-02-22 09:04:00","topic":"1","unix_timestamp":1613981040,"question_text":"The displayed graph is from a forecasting model for testing a time series.\n//IMG//\n\nConsidering the graph only, which conclusion should a Machine Learning Specialist make about the behavior of the model?","isMC":true,"question_id":35,"answer_description":"","choices":{"C":"The model predicts the seasonality well, but not the trend.","A":"The model predicts both the trend and the seasonality well","B":"The model predicts the trend well, but not the seasonality.","D":"The model does not predict the trend or the seasonality well."},"answers_community":["A (75%)","B (25%)"],"answer":"A","url":"https://www.examtopics.com/discussions/amazon/view/45385-exam-aws-certified-machine-learning-specialty-topic-1/","discussion":[{"timestamp":"1649542740.0","content":"A is correct answer.\nPlease Refer: https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/","poster":"jeetss1","comment_id":"355526","upvote_count":"16"},{"content":"A; the problem is bias, not trends","comment_id":"433749","timestamp":"1651711200.0","poster":"Dr_Kiko","upvote_count":"8"},{"comment_id":"1411937","timestamp":"1743314100.0","upvote_count":"1","poster":"apache007","content":"Selected Answer: B\nB. The model predicts the trend well, but not the seasonality.\n\nHere's what we can observe:\nThe predicted mean line closely follows the general upward trend of the observed line.\nThe predicted mean line does not capture the high frequency up and down changes of the observed line."},{"upvote_count":"2","poster":"VR10","content":"agreed, this seems to be A. there is similarity between the blue and green lines as far as capturing trend and seasonality is concerned. It just seems that if assumption is that the model is a linear regression model then just the intercept is off by a few units.","comment_id":"1153712","timestamp":"1724035740.0"},{"comment_id":"973055","timestamp":"1707146160.0","content":"Selected Answer: A\nA. The model predicts both the trend and the seasonality well","poster":"Mickey321","upvote_count":"1"},{"timestamp":"1694153700.0","upvote_count":"2","poster":"Valcilio","comment_id":"832672","content":"Selected Answer: A\nThe problem is Bias not trends or sesonality!"},{"comment_id":"402560","poster":"spamicho","content":"A is right, both trend (rising) and seasonality is there","timestamp":"1651295820.0","upvote_count":"3"},{"content":"C is correct answer","comment_id":"373995","upvote_count":"1","comments":[{"poster":"btsql","content":"A is correct answer. Not C","comment_id":"374008","upvote_count":"2","timestamp":"1650660000.0"}],"poster":"btsql","timestamp":"1650319920.0"},{"comment_id":"370254","upvote_count":"3","content":"The trend is up, so isnâ€™t it correctly predicted? And the seasonality is also in sync, the amplitude is wrong.","poster":"Kuntazulu","timestamp":"1649670420.0"},{"upvote_count":"4","timestamp":"1649490420.0","comment_id":"338820","content":"A is right. trend and seasonality are fine, level is the one the model gets wrong","poster":"georschi"},{"upvote_count":"1","timestamp":"1648523040.0","poster":"NotAnMLProfessional","comment_id":"312347","content":"Should be C"},{"poster":"ashlash","timestamp":"1647789000.0","upvote_count":"2","comment_id":"296447","content":"Should be A"}],"question_images":["https://www.examtopics.com/assets/media/exam-media/04145/0000900001.jpg"],"answer_images":[],"answer_ET":"A","exam_id":26}],"exam":{"isImplemented":true,"isMCOnly":false,"name":"AWS Certified Machine Learning - Specialty","isBeta":false,"id":26,"numberOfQuestions":369,"provider":"Amazon","lastUpdated":"11 Apr 2025"},"currentPage":7},"__N_SSP":true}