{"pageProps":{"questions":[{"id":"AijQSRraRz0AZ6dHNnvz","answers_community":["BC (93%)","2%"],"choices":{"A":"Use AWS WAF to protect the NLB.","E":"Use AWS Shield Standard with Amazon API Gateway.","C":"Use AWS WAF to protect Amazon API Gateway.","B":"Use AWS Shield Advanced with the NLB.","D":"Use Amazon GuardDuty with AWS Shield Standard"},"unix_timestamp":1668599100,"question_id":111,"timestamp":"2022-11-16 12:45:00","isMC":true,"question_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/amazon/view/87640-exam-aws-certified-solutions-architect-associate-saa-c03/","answer_images":[],"answer_ET":"BC","discussion":[{"poster":"babaxoxo","content":"Selected Answer: BC\nShield - Load Balancer, CF, Route53\nAWF - CF, ALB, API Gateway","comment_id":"719631","upvote_count":"49","comments":[{"comment_id":"905211","poster":"YogK","content":"Shield - Amazon Elastic Compute Cloud (EC2), Elastic Load Balancing (ELB), Amazon CloudFront, AWS Global Accelerator, and Route 53.\n\nWAF - Amazon CloudFront, the Application Load Balancer (ALB), Amazon API Gateway, and AWS AppSync","upvote_count":"14","timestamp":"1700777880.0"},{"timestamp":"1687834560.0","comment_id":"758139","upvote_count":"5","poster":"Ouk","content":"Thank u U meant WAF* - CloudFormation, right? haha"}],"timestamp":"1684233960.0"},{"content":"Selected Answer: BC\nAWS Shield Advanced - DDos attacks\nAWS WAF to protect Amazon API Gateway, because WAF sits before the API Gateway and then comes NLB.","comments":[{"upvote_count":"3","comments":[{"timestamp":"1704522420.0","comment_id":"944319","content":"yes.. coming from outside to inside... first of all DDos protection is required so the outer most NLB with Shield Advanced and then filter particular request doing SQL injection and all i.e API Gateway with WAF","poster":"aadityaravi8","upvote_count":"2"}],"content":"don't agree that NLB sits before API gateway. it should be other way around","comment_id":"896683","poster":"studynoplay","timestamp":"1699888020.0"}],"timestamp":"1684230300.0","poster":"rjam","upvote_count":"8","comment_id":"719582"},{"content":"Selected Answer: BC\nAWS Shield protects against Layer 3 and 4 attacks through NLB and AWS WAF protects against Layer 7 attacks through API Gateway.","poster":"satyaammm","timestamp":"1739036160.0","upvote_count":"1","comment_id":"1353550"},{"upvote_count":"1","comment_id":"1353129","poster":"Dharmarajan","timestamp":"1738960440.0","comments":[{"timestamp":"1738960440.0","upvote_count":"2","poster":"Dharmarajan","comment_id":"1353130","content":"Definitely a very good question, to be noted for the exam."}],"content":"Selected Answer: BC\nI did not get this right initially, but when I looked it up, it became clear.\nBasically any device that acts at network level - Shield (Layer 4 devices, maybe capable of layer 7 as well). For example, NLB, ELB, CF, Route 53.\nAny device that works on HTTP/HTTPS/SFTP level(Layer 7 services) ==> WAF , which is ALB, API Gateway.\n\na Layer 7 device are not capable of layer 4 sevices, and they rely on underlying hardware/firmware(OR in this case of Software defined networking, Software) to do that."},{"comment_id":"1198358","comments":[{"timestamp":"1732799280.0","poster":"lofzee","content":"Shield advanced does not protect against SQL injection. That is what WAF is for.\nGuardDuty is not the right tool here.\nAnswers are B and C bro.","comment_id":"1220172","upvote_count":"3"}],"content":"Selected Answer: BD\nB- (Shield Advance) PROTECT the platform against web exploits like SQL injection\nD- (GuardDuty) also wants to DETECT mitigate large, sophisticated DDoS attacks\nWAF use for filter traffic, not make sense here.","poster":"EMPERBACH","timestamp":"1729318320.0","upvote_count":"1"},{"poster":"Guru4Cloud","timestamp":"1708195680.0","content":"Selected Answer: BC\nB) Use AWS Shield Advanced with the NLB\n\nC) Use AWS WAF to protect Amazon API Gateway\n\nThe key reasons are:\n\nAWS Shield Advanced provides expanded DDoS protection against larger and more sophisticated attacks\nUsing it with the NLB helps protect against network floods\nWAF still provides critical protection against exploits at the API lay","comment_id":"983835","upvote_count":"6"},{"upvote_count":"2","comment_id":"980634","content":"Selected Answer: BC\nWAF - can't support NLB and its supports API Gateway\nAWS Shield Advanced - NLB - DDOS","poster":"Sat897","timestamp":"1707909000.0"},{"timestamp":"1703590500.0","upvote_count":"7","poster":"cookieMr","content":"B. AWS Shield Advanced provides advanced DDoS protection for the NLB, making it the appropriate choice for protecting against large and sophisticated DDoS attacks at the network layer.\n\nC. AWS WAF is designed to provide protection at the application layer, making it suitable for securing the API Gateway against web exploits like SQL injection.\n\nA. AWS WAF is not compatible with NLB as it operates at the application layer, whereas NLB operates at the transport layer.\n\nD. While GuardDuty helps detect threats, it does not directly protect against web exploits or DDoS attacks. Shield Standard focuses on edge resources, not specifically NLBs.\n\nE. Shield Standard provides basic DDoS protection for edge resources, but it does not directly protect the NLB or address web exploits at the application layer.","comment_id":"934251"},{"comment_id":"895747","content":"Selected Answer: BC\nB and C is correct","upvote_count":"2","poster":"cheese929","timestamp":"1699783200.0"},{"poster":"kruasan","timestamp":"1698436680.0","content":"Selected Answer: BC\nNLB is a Lyer 3/4 component while WAF is a Layer 7 protection component.\n\nThat is why WAF is only available for Application Load Balancer in the ELB portfolio. NLB does not terminate the TLS session therefore WAF is not capable of acting on the content. I would consider using AWS Shield at Layer 3/4.\nhttps://repost.aws/questions/QU2fYXwSWUS0q9vZiWDoaEzA/nlb-need-to-attach-aws-waf","upvote_count":"5","comment_id":"883011"},{"content":"Selected Answer: C\n• A. Use AWS WAF to protect the NLB. \nINCORRECT, cos' WAF not integrate with network LB\n • B. Use AWS Shield Advanced with the NLB.\n\nYES. AWS Shield Advanced provides additional protections against more sophisticated and larger attacks for your applications running in AWS.\nThe doubt is : why apply the protection in the NLB when the facing of the app. is the API Gateway?, because Shield shoud be in front of the communications, not behind.\nNevertheless, this is the best option. \n\n • C. Use AWS WAF to protect Amazon API Gateway. \nYES, https://aws.amazon.com/es/waf/faqs/\n • D. Use Amazon GuardDuty with AWS Shield Standard \nINCORRECT, GuardDuty not prevent attacks.\n •E. Use AWS Shield Standard with Amazon API Gateway. \nINCORRECT. It could be, in principle, a good option, cos' it's in front of the gateway, but the questions said explicity:\n\"wants to detect and mitigate large, sophisticated DDoS attacks\",\nand Standard not provide this feature.","comment_id":"865320","upvote_count":"2","poster":"jdr75","timestamp":"1696832820.0"},{"upvote_count":"4","content":"for those who select A, it is wrong, WAF is Layer 7, it only support ABL, APIGateway, CloudFront,COgnito User Pool and AppSync graphQL API (https://docs.aws.amazon.com/waf/latest/developerguide/waf-chapter.html). NLB is NOT supported. Answer is BC","comment_id":"791624","poster":"kerl","timestamp":"1690626240.0"},{"upvote_count":"2","comments":[{"upvote_count":"1","comments":[{"upvote_count":"2","comment_id":"949810","poster":"Arifzefen","content":"A is not correct as WAF doesn't support Network Load Balancer","timestamp":"1705071720.0"}],"comment_id":"784429","poster":"bullrem","content":"A and C are the best options for protecting the platform against web vulnerabilities and detecting and mitigating large and sophisticated DDoS attacks.\nA: AWS WAF can be used to protect the NLB from web vulnerabilities such as SQL injection.\nC: AWS WAF can be used to protect Amazon API Gateway and also provide protection against DDoS attacks.\nB: AWS Shield Advanced is used to protect resources from DDoS attacks, but it is not specific to the NLB and may not provide the same level of protection as using WAF specifically on the NLB.\nD and E: Amazon GuardDuty and AWS Shield Standard are primarily used for threat detection and may not provide the same level of protection as using WAF and Shield Advanced.","timestamp":"1690031760.0"},{"poster":"omoakin","content":"correct","timestamp":"1700890380.0","upvote_count":"1","comment_id":"906300"},{"content":"The best protection for the platform would be to use A and C together because it will protect both the NLB and the API Gateway from web vulnerabilities and DDoS attacks.","poster":"bullrem","timestamp":"1690031580.0","upvote_count":"1","comment_id":"784426"}],"poster":"bullrem","content":"Selected Answer: AB\nA and B are the best options to provide the greatest protection for the platform against web vulnerabilities and large, sophisticated DDoS attacks.\nOption A: Use AWS WAF to protect the NLB. This will provide protection against common web vulnerabilities such as SQL injection.\nOption B: Use AWS Shield Advanced with the NLB. This will provide additional protection against large and sophisticated DDoS attacks.","timestamp":"1690031280.0","comment_id":"784420"},{"upvote_count":"2","timestamp":"1687799700.0","comment_id":"757775","content":"Selected Answer: BC\nWS Shield Advanced can help protect your Amazon EC2 instances and Network Load Balancers against infrastructure-layer Distributed Denial of Service (DDoS) attacks. Enable AWS Shield Advanced on an AWS Elastic IP address and attach the address to an internet-facing EC2 instance or Network Load Balancer.https://aws.amazon.com/blogs/security/tag/network-load-balancers/","poster":"drabi"},{"comment_id":"754298","timestamp":"1687523880.0","content":"Regional resources\n\nYou can protect regional resources in all Regions where AWS WAF is available. You can see the list at AWS WAF endpoints and quotas in the Amazon Web Services General Reference.\n\nYou can use AWS WAF to protect the following regional resource types:\n\nAmazon API Gateway REST API\n\nApplication Load Balancer\n\nAWS AppSync GraphQL API\n\nAmazon Cognito user pool\n\nYou can only associate a web ACL to an Application Load Balancer that's within AWS Regions. For example, you cannot associate a web ACL to an Application Load Balancer that's on AWS Outposts.","upvote_count":"1","comments":[{"poster":"duriselvan","timestamp":"1687523940.0","upvote_count":"1","comment_id":"754299","content":"Ans:-a and C"}],"poster":"duriselvan"},{"timestamp":"1687464360.0","content":"Selected Answer: AC\n***CORRECT***\n\nA. Use AWS WAF to protect the NLB.\nC. Use AWS WAF to protect Amazon API Gateway.\n\nAWS WAF is a web application firewall that helps protect web applications from common web exploits such as SQL injection and cross-site scripting attacks. By using AWS WAF to protect the NLB and Amazon API Gateway, the company can provide an additional layer of protection for its cloud communications platform against these types of web exploits.","comments":[{"poster":"Buruguduystunstugudunstuy","content":"About AWS Shield Advanced and Amazon GuardDuty\n\nAWS Shield Advanced is a managed DDoS protection service that provides additional protection for Amazon EC2 instances, Amazon RDS DB instances, Amazon Elastic Load Balancers, and Amazon CloudFront distributions. It can help detect and mitigate large, sophisticated DDoS attacks, \"but it does not provide protection against web exploits like SQL injection.\"\n\nAmazon GuardDuty is a threat detection service that uses machine learning and other techniques to identify potentially malicious activity in your AWS accounts. It can be used in conjunction with AWS Shield Standard, which provides basic DDoS protection for Amazon EC2 instances, Amazon RDS DB instances, and Amazon Elastic Load Balancers. However, neither Amazon GuardDuty nor AWS Shield Standard provides protection against web exploits like SQL injection.\n\nOverall, the combination of using AWS WAF to protect the NLB and Amazon API Gateway provides the most protection against web exploits and large, sophisticated DDoS attacks.","timestamp":"1687464600.0","upvote_count":"1","comment_id":"753684"},{"timestamp":"1687805040.0","upvote_count":"5","poster":"PassNow1234","comment_id":"757835","comments":[{"comment_id":"789728","upvote_count":"5","content":"This guy just copies and pastes from ChatGPT.","poster":"jwu413","timestamp":"1690463880.0"}],"content":"Your answer is wrong. \n\nSophisticated DDOS = Shield Advanced (DD0S attacks the front!) What happens if your load balances goes down? \n\nYour API gateway is on the BACK further behind the NLB. SQL Protect that with the WAF\n\nB and C are right."}],"comment_id":"753681","poster":"Buruguduystunstugudunstuy","upvote_count":"1"},{"poster":"BENICE","timestamp":"1687226700.0","content":"Option B and C","comment_id":"750476","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: BC\nB and C","poster":"career360guru","timestamp":"1687024020.0","comment_id":"748352"},{"upvote_count":"1","poster":"tz1","timestamp":"1686510540.0","content":"B & C is the answer","comment_id":"742100"},{"upvote_count":"1","content":"B and C","poster":"Wpcorgan","comment_id":"724494","timestamp":"1684767000.0"},{"timestamp":"1684324080.0","poster":"BENICE","content":"B and C\n\"AWS Shield Advanced\" for \"sophisticated DDoS attacks\"\n\"AWS WAF\" for \"NLB","comment_id":"720494","upvote_count":"4"},{"timestamp":"1684232820.0","poster":"Nigma","content":"B and C","comment_id":"719611","upvote_count":"1"}],"exam_id":31,"topic":"1","answer":"BC","question_text":"A company is designing a cloud communications platform that is driven by APIs. The application is hosted on Amazon EC2 instances behind a Network Load Balancer (NLB). The company uses Amazon API Gateway to provide external users with access to the application through APIs. The company wants to protect the platform against web exploits like SQL injection and also wants to detect and mitigate large, sophisticated DDoS attacks.\n\nWhich combination of solutions provides the MOST protection? (Choose two.)"},{"id":"RpK099iNJTFYvq7LbB13","question_text":"A company has a legacy data processing application that runs on Amazon EC2 instances. Data is processed sequentially, but the order of results does not matter. The application uses a monolithic architecture. The only way that the company can scale the application to meet increased demand is to increase the size of the instances.\n\nThe company’s developers have decided to rewrite the application to use a microservices architecture on Amazon Elastic Container Service (Amazon ECS).\n\nWhat should a solutions architect recommend for communication between the microservices?","answer_ET":"A","choices":{"B":"Create an Amazon Simple Notification Service (Amazon SNS) topic. Add code to the data producers, and publish notifications to the topic. Add code to the data consumers to subscribe to the topic.","D":"Create an Amazon DynamoDB table. Enable DynamoDB Streams. Add code to the data producers to insert data into the table. Add code to the data consumers to use the DynamoDB Streams API to detect new table entries and retrieve the data.","A":"Create an Amazon Simple Queue Service (Amazon SQS) queue. Add code to the data producers, and send data to the queue. Add code to the data consumers to process data from the queue.","C":"Create an AWS Lambda function to pass messages. Add code to the data producers to call the Lambda function with a data object. Add code to the data consumers to receive a data object that is passed from the Lambda function."},"unix_timestamp":1668603240,"question_id":112,"answer_description":"","answer_images":[],"answer":"A","answers_community":["A (95%)","5%"],"discussion":[{"upvote_count":"21","comment_id":"753696","content":"Selected Answer: A\nOption B, using Amazon Simple Notification Service (SNS), would not be suitable for this use case, as SNS is a pub/sub messaging service that is designed for one-to-many communication, rather than point-to-point communication between specific microservices.\n\nOption C, using an AWS Lambda function to pass messages, would not be suitable for this use case, as it would require the data producers and data consumers to have a direct connection and invoke the Lambda function, rather than being decoupled through a message queue.\n\nOption D, using an Amazon DynamoDB table with DynamoDB Streams, would not be suitable for this use case, as it would require the data consumers to continuously poll the DynamoDB Streams API to detect new table entries, rather than being notified of new data through a message queue.","timestamp":"1687465020.0","poster":"Buruguduystunstugudunstuy","comments":[{"content":"I think A is obvious the most suitable, but i dont understand how is this related to ECS mentioned in the question","comment_id":"1409572","timestamp":"1742801220.0","upvote_count":"1","poster":"jerryl"},{"timestamp":"1687465080.0","content":"Hence, Option A is the correct answer.\n\nCreate an Amazon Simple Queue Service (Amazon SQS) queue. Add code to the data producers, and send data to the queue. Add code to the data consumers to process data from the queue.","comment_id":"753697","poster":"Buruguduystunstugudunstuy","upvote_count":"10"}]},{"poster":"cookieMr","comment_id":"934263","content":"Selected Answer: A\nA. Creating an Amazon SQS queue allows for asynchronous communication between microservices, decoupling the data producers and consumers. It provides scalability, flexibility, and ensures that data processing can happen independently and at a desired pace.\n\nB. Amazon SNS is more suitable for pub/sub messaging, where multiple subscribers receive the same message. It may not be the best fit for sequential data processing.\n\nC. Using AWS Lambda functions for communication introduces unnecessary complexity and may not be the optimal solution for sequential data processing.\n\nD. Amazon DynamoDB with DynamoDB Streams is primarily designed for real-time data streaming and change capture scenarios. It may not be the most efficient choice for sequential data processing in a microservices architecture.","upvote_count":"7","timestamp":"1703591400.0"},{"content":"Selected Answer: A\nSQS Queues are most suitable as they provide decoupling between microservices.","timestamp":"1739036340.0","upvote_count":"1","poster":"satyaammm","comment_id":"1353554"},{"upvote_count":"2","timestamp":"1725843660.0","poster":"scar0909","comment_id":"1169235","content":"Selected Answer: A\nA for sure"},{"poster":"reviewmine","timestamp":"1723986840.0","upvote_count":"5","comment_id":"1153371","content":"Selected Answer: A\nTo Decouple a monolithic application - SQS\n- SQS standard - not in order\n- SQS FIFO - in order"},{"comment_id":"1132179","content":"Selected Answer: A\nData is processed sequentially, but the order of results does not matter => SQS; if order matters => SQL FIFO","timestamp":"1721947500.0","upvote_count":"3","poster":"upliftinghut"},{"timestamp":"1720686780.0","poster":"Cloud_A","upvote_count":"2","comment_id":"1119608","content":"Selected Answer: A\nA is the answer."},{"timestamp":"1710226500.0","upvote_count":"2","poster":"TariqKipkemei","content":"Selected Answer: A\nData is processed sequentially, but the order of results does not matter = Amazon Simple Queue Service","comment_id":"1005378"},{"content":"Selected Answer: A\nA) Create an Amazon Simple Queue Service (Amazon SQS) queue. Add code to the data producers, and send data to the queue. Add code to the data consumers to process data from the queue.\n\nFor asynchronous communication between decoupled microservices, an SQS queue is the most appropriate service to use.\n\nSQS provides a scalable, highly available queue to buffer messages between producers and consumers.\nThe order of processing does not matter, so a queue model fits well.\nThe consumers can scale independently to process messages from the queue.","comment_id":"983851","poster":"Guru4Cloud","upvote_count":"4","timestamp":"1708197300.0"},{"poster":"omoakin","timestamp":"1700890740.0","comment_id":"906309","content":"BBBBBBBBB","upvote_count":"1"},{"content":"Selected Answer: A\nSQS for decoupling a monolithic architecture, hence option A is the right answer.","poster":"Bmarodi","comment_id":"906022","timestamp":"1700848620.0","upvote_count":"2"},{"upvote_count":"1","comment_id":"861457","content":"it also says 'the order of results does not matter'. Option B is correct.","poster":"Madhuaws","timestamp":"1696448400.0"},{"timestamp":"1695059880.0","comment_id":"843125","upvote_count":"2","poster":"asoli","content":"Selected Answer: A\nThe answer is A.\nB is wrong because SNS cannot send events \"directly\" to ECS.\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-event-destinations.html"},{"comment_id":"821539","timestamp":"1692964920.0","upvote_count":"3","content":"Selected Answer: B\nit deosn;t say it is one-one relationships , SNS is better","comments":[{"timestamp":"1702835940.0","poster":"markw92","content":"watch out for this sentence in the question...\"Data needs to process sequentially....\"","upvote_count":"3","comment_id":"926103"}],"poster":"user_deleted"},{"content":"Selected Answer: A\nBest answer is A. \nThough C or D is possible it requires additional components and integration and so they are not efficient. Assuming that rate of incoming requests is within limits that SQS can handle A is best option.","upvote_count":"2","comment_id":"748246","poster":"career360guru","timestamp":"1687016700.0"},{"upvote_count":"2","timestamp":"1686827160.0","content":"Selected Answer: A\nA is correct","poster":"k1kavi1","comment_id":"746096"},{"timestamp":"1686495960.0","content":"answer is B. \nAn Amazon Simple Notification Service (Amazon SNS) topic can be used for communication between the microservices in this scenario. The data producers can be configured to publish notifications to the topic, and the data consumers can be configured to subscribe to the topic and receive notifications as they are published. This allows for asynchronous communication between the microservices, Question here focus on communication between microservices","poster":"Shasha1","comment_id":"741917","upvote_count":"2"},{"content":"We need decoupling so ok to use SQS","poster":"xua81376","comment_id":"721986","upvote_count":"3","timestamp":"1684491900.0"},{"poster":"BENICE","content":"Can someone explain it bit more? Not able to understand it.","comment_id":"720502","comments":[{"timestamp":"1684717680.0","upvote_count":"16","content":"As monolithic systems become too large to deal with, many enterprises are drawn to breaking them down into the microservices architectural style by means of decoupling. Amazon Simple Queue Service (Amazon SQS) is a fully managed message queuing service that makes it easy to decouple and scale microservices, distributed systems, and serverless applications","comment_id":"724066","poster":"EKA_CloudGod"}],"upvote_count":"2","timestamp":"1684324620.0"},{"upvote_count":"3","poster":"taer","timestamp":"1684294440.0","content":"Selected Answer: A\nAnswer is A","comment_id":"720235"},{"comment_id":"719645","poster":"Nigma","timestamp":"1684234440.0","upvote_count":"3","content":"SQS to decouple."}],"url":"https://www.examtopics.com/discussions/amazon/view/87647-exam-aws-certified-solutions-architect-associate-saa-c03/","topic":"1","question_images":[],"exam_id":31,"timestamp":"2022-11-16 13:54:00","isMC":true},{"id":"fe3oxVCIJAeEg41zjv5N","choices":{"D":"Create an Amazon EC2 instance with a MySQL engine installed that triggers an AWS Lambda function to synchronously replicate the data to an Amazon RDS MySQL DB instance.","A":"Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones.","B":"Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data.","C":"Create an Amazon RDS MySQL DB instance and then create a read replica in a separate AWS Region that synchronously replicates the data."},"answer_ET":"B","answer_description":"","question_id":113,"timestamp":"2022-11-16 12:57:00","exam_id":31,"question_text":"A company wants to migrate its MySQL database from on premises to AWS. The company recently experienced a database outage that significantly impacted the business. To ensure this does not happen again, the company wants a reliable database solution on AWS that minimizes data loss and stores every transaction on at least two nodes.\n\nWhich solution meets these requirements?","topic":"1","answers_community":["B (98%)","2%"],"unix_timestamp":1668599820,"answer":"B","question_images":[],"isMC":true,"answer_images":[],"discussion":[{"poster":"rjam","timestamp":"1668599820.0","content":"Selected Answer: B\nAmazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data\n Standby DB in Multi-AZ- synchronous replication\n\nRead Replica always asynchronous. so option C is ignored.","upvote_count":"20","comment_id":"719590"},{"timestamp":"1684009200.0","comments":[{"poster":"pentium75","upvote_count":"7","timestamp":"1703656440.0","content":"B is correct but the explanation is flawed ;)\n\nRDS Multi-AZ = Synchronous = High Availability\nRead Replica = Asynchronous = Disaster Recovery (DR)","comment_id":"1106597"}],"content":"Selected Answer: B\nRDS Multi-AZ = Synchronous = Disaster Recovery (DR)\nRead Replica = Asynchronous = High Availability","comment_id":"897050","poster":"studynoplay","upvote_count":"15"},{"timestamp":"1739036580.0","comment_id":"1353559","content":"Selected Answer: B\nRDS Multi AZ is the most suitable here.","poster":"satyaammm","upvote_count":"1"},{"upvote_count":"2","poster":"PoolDead","timestamp":"1722872700.0","content":"\"Minimizes Data Loss\" Therefore answer is B.\n\nAmazon RDS read replicas use asynchronous replication, not synchronous. Therefore, this option does not meet the requirement for minimizing data loss as asynchronous replication can result in data lag.","comment_id":"1261104"},{"poster":"Nawaff","timestamp":"1720170960.0","content":"Selected Answer: B\nAnswer is B\nFind the below URL for the perfect explanation for the differences between:\n- Multi-AZ DB\n- Multi-Region DB\n- Read replicas DB\n\nhttps://aws.amazon.com/rds/features/read-replicas/","comment_id":"1242652","upvote_count":"2"},{"upvote_count":"2","comment_id":"1169236","content":"Selected Answer: B\nMulti AZ for availability","poster":"scar0909","timestamp":"1709953320.0"},{"content":"Option A is incorrect because Amazon RDS does not support synchronous replication to three nodes in three Availability Zones.\nOption C is incorrect because while you can create a read replica in a separate AWS Region1, the replication from the primary DB instance to the read replica is asynchronous, not synchronous.","comment_id":"1050767","timestamp":"1697986200.0","poster":"riyasara","upvote_count":"4"},{"upvote_count":"3","timestamp":"1687778640.0","poster":"cookieMr","content":"Selected Answer: B\nB. Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data.\n\nEnabling Multi-AZ functionality in Amazon RDS ensures synchronous replication of data to a standby replica in a different Availability Zone. This provides high availability and minimizes data loss in the event of a database outage.\n\nA. Creating an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones would provide even higher availability but is not necessary for the stated requirements.\n\nC. Creating a read replica in a separate AWS Region would provide disaster recovery capabilities but does not ensure synchronous replication or meet the requirement of storing every transaction on at least two nodes.\n\nD. Using an EC2 instance with a MySQL engine and triggering an AWS Lambda function for replication introduces unnecessary complexity and is not the most suitable solution for ensuring reliable and synchronous replication.","comment_id":"934336"},{"comment_id":"865940","poster":"channn","upvote_count":"3","content":"Selected Answer: B\nB\nsince all other answers r wrong","timestamp":"1681092960.0"},{"poster":"jayce5","timestamp":"1680209040.0","upvote_count":"2","content":"Selected Answer: B\nB\nSince read replica is async.","comment_id":"856246"},{"poster":"LuckyAro","timestamp":"1673920560.0","comments":[{"comment_id":"1106599","timestamp":"1703656560.0","poster":"pentium75","content":"But is IS protected. Read replica is asynchronous, fails to meet the \"store EVERY transaction on at least two nodes\" requirement.","upvote_count":"1"}],"upvote_count":"1","comment_id":"778453","content":"Selected Answer: C\nMulti AZ is not as protected as Multi-Region Read Replica."},{"comment_id":"769296","comments":[{"upvote_count":"1","comment_id":"1106596","poster":"pentium75","timestamp":"1703656380.0","content":"How would you implement A?"}],"upvote_count":"3","content":"I curios to know why A isn't right. Is it just that it would take more effort?","poster":"JayBee65","timestamp":"1673175000.0"},{"content":"B is correct C requires more wokr.","timestamp":"1671912420.0","poster":"techhb","comment_id":"755119","upvote_count":"2"},{"comment_id":"750475","upvote_count":"2","content":"Option B","poster":"BENICE","timestamp":"1671509040.0"},{"comment_id":"748820","content":"Multi-AZ will give at least two nodes as required by the question. The answer is B.\n\nAmazon RDS provides high availability and failover support for DB instances using Multi-AZ deployments with a single standby DB instance.\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html","timestamp":"1671365700.0","poster":"bammy","upvote_count":"5"},{"comment_id":"748255","timestamp":"1671299820.0","poster":"career360guru","content":"Selected Answer: B\nOption B","upvote_count":"2"},{"upvote_count":"2","comments":[{"upvote_count":"2","poster":"JayBee65","comment_id":"769293","content":"Option B is not incorrect: \"The primary DB instance is synchronously replicated across Availability Zones to a standby replica to provide data redundancy and minimize latency spikes during system backups\" from https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html","timestamp":"1673174700.0"},{"upvote_count":"2","content":"I would go with Option B since it meets the company's requirements and is the most suitable solution.\n\nBy creating an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled, the solutions architect will ensure that data is automatically synchronously replicated across multiple AZs within the same Region. This provides high availability and data durability, minimizing the risk of data loss and ensuring that every transaction is stored on at least two nodes.","comment_id":"753706","poster":"Buruguduystunstugudunstuy","timestamp":"1671748380.0"}],"poster":"Shasha1","comment_id":"741929","content":"Option A is the correct answer in this scenario because it meets the requirements specified in the question. It creates an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones, which will provide high availability and durability for the database, ensuring that the data is stored on multiple nodes and automatically replicated across Availability Zones.\n\nOption B is not a correct answer because it creates an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled, which only provides failover capabilities. It does not enable synchronous replication to multiple nodes, which is required in this scenario.","timestamp":"1670779440.0"},{"timestamp":"1670638200.0","comment_id":"740632","poster":"stepman","upvote_count":"1","content":"Maybe C since Amazon RDC now supports cross region read replica https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-rds-sql-server-cross-region-read-replica/"},{"upvote_count":"1","poster":"Wpcorgan","timestamp":"1669135980.0","content":"B is correct","comment_id":"724498"},{"poster":"EKA_CloudGod","upvote_count":"2","timestamp":"1669086780.0","content":"Selected Answer: B\nOption B is the correct answer:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStandby.html","comment_id":"724069"},{"timestamp":"1668603420.0","content":"B is the answer","poster":"Nigma","comment_id":"719650","upvote_count":"3"}],"url":"https://www.examtopics.com/discussions/amazon/view/87641-exam-aws-certified-solutions-architect-associate-saa-c03/"},{"id":"L3upx0LM2PxUmLuafjCj","answer_ET":"A","discussion":[{"poster":"romko","content":"Selected Answer: A\nA - is correct, because Dynamodb on-demand scales write and read capacity\nB - Aurora auto scaling scales only read replicas","comments":[{"upvote_count":"7","comment_id":"853604","comments":[{"upvote_count":"2","timestamp":"1718478720.0","poster":"Duckydoo","comment_id":"1231106","content":"Could you point us to a source where it says that Aurora Auto Scaling can scale write replicas? The AWS documentation specifically mentions that it supports only read replicas (e.g. https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html):\n\nTo meet your connectivity and workload requirements, Aurora Auto Scaling dynamically adjusts the number of Aurora Replicas (reader DB instances) provisioned for an Aurora DB cluster. Aurora Auto Scaling is available for both Aurora MySQL and Aurora PostgreSQL."},{"timestamp":"1687350240.0","comments":[{"timestamp":"1733811240.0","upvote_count":"1","comment_id":"1324403","content":"Dynamo is serverless, so you don't need to worry about maintenance and patching.","poster":"SteveNguyen"}],"content":"That's why Dynamo DB is best suited option","comment_id":"929479","upvote_count":"3","poster":"Yadav_Sanjay"},{"timestamp":"1687350180.0","content":"Correct...Both can serve purpose but note the keyword \"must scale read and write capacity as quickly as possible to meet changes in user demand\". DynamoDB can scale quickly than Aurora. Remember \"PUSH BUTTON SCALING FEATURE\" of Dynamo DB.","comment_id":"929478","upvote_count":"7","poster":"Yadav_Sanjay"}],"content":"That’s not correct. Amazon Aurora with Aurora Auto Scaling can scale both read and write replicas. Is there anything else you would like me to help you with?","timestamp":"1680030900.0","poster":"klayytech"}],"upvote_count":"49","comment_id":"725099","timestamp":"1669206000.0"},{"comments":[{"timestamp":"1669105560.0","content":"I HOPE SO","upvote_count":"9","comment_id":"724173","poster":"Bobbybash"},{"comments":[{"upvote_count":"2","timestamp":"1712569440.0","poster":"soufiyane","content":"did you pass ?","comment_id":"1191488"}],"content":"You can tell us now ? Going by the date of your post I guess you would have challenged the exam by now ? so how did it go ?","comment_id":"798614","poster":"LuckyAro","upvote_count":"9","timestamp":"1675572300.0"}],"timestamp":"1668936180.0","content":"please is this dump enough to pass the exam?","comment_id":"722500","poster":"Manlikeleke","upvote_count":"15"},{"timestamp":"1741613940.0","comment_id":"1381830","content":"Selected Answer: A\nAurora is more complex to set up and manage....\nDynamoDB is simpler to use, less configuration needed, the most important is highly scalable, auto-scaling\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html","poster":"tch","upvote_count":"1"},{"poster":"satyaammm","content":"Selected Answer: A\nDynamoDB provides the best read and write capacity here.","comment_id":"1353561","upvote_count":"1","timestamp":"1739036700.0"},{"upvote_count":"3","poster":"Dharmarajan","comment_id":"1352646","content":"Selected Answer: A\nI also initially thought Aurora is better suited since it gives auto scaling as well as auto scaling. However, it doesn't auto scale for writer instances.\nthere is a note in Aurora doc:\n\"Aurora Auto Scaling doesn't apply to the workload on the writer DB instance. Aurora Auto Scaling helps with the workload only on the reader instances.\"\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html\n\nHence the right answer is A. But man, how devious! a small detail can derail you from making the right choice!","timestamp":"1738873260.0"},{"comment_id":"1339586","upvote_count":"1","timestamp":"1736696280.0","content":"Selected Answer: A\nDynamodb - No need to provision, patch, or manage servers.","poster":"devarajchidambaram"},{"content":"Selected Answer: A\nDynamo DB Push Scaling","timestamp":"1714852020.0","upvote_count":"2","comment_id":"1206645","poster":"ManikRoy"},{"upvote_count":"3","comment_id":"1119642","timestamp":"1704971700.0","content":"Selected Answer: A\nhttps://aws.amazon.com/blogs/database/how-to-determine-if-amazon-dynamodb-is-appropriate-for-your-needs-and-then-plan-your-migration/#:~:text=Are%20working%20with%20an%20online%20transaction%20processing%20(OLTP)%20workload.%20High%2Dperformance%20reads%20and%20writes%20are%20easy%20to%20manage%20with%20DynamoDB%2C%20and%20you%20can%20expect%20performance%20that%20is%20effectively%20constant%20across%20widely%20varying%20loads.","poster":"Cloud_A"},{"comments":[{"timestamp":"1725221100.0","comment_id":"1276225","content":"Where do you see \"static content scaling\"?\nIn the question, I can read \"dynamic ordering website\", I fail to see how dynamic website can be hosted on S#.","poster":"ChaBum","upvote_count":"2"}],"upvote_count":"3","timestamp":"1704063240.0","poster":"awsgeek75","comment_id":"1110860","content":"Selected Answer: A\nC,D are out due to EC2 scaling which is not ideal for static content scaling.\nA and B are logical choices. B uses Aurora which is more for relational database and comes with the baggage and limitations of RDBMS scaling. DynamDB (no SQL) is easier to scale for both read and write. A is simply better than be for an ordering website so that is the better option. Note that B would have been good if A wasn't a choice."},{"timestamp":"1697189340.0","content":"Selected Answer: A\ndynamodb is serverless","poster":"tom_cruise","comment_id":"1042511","upvote_count":"5"},{"content":"Selected Answer: A\nHi all! The answer is A and NOT B on this one as the company is building an ordering website (OLTP). DynamoDB's high performance read and writes are perfect for an OLTP use case. \n\nhttps://aws.amazon.com/blogs/database/how-to-determine-if-amazon-dynamodb-is-appropriate-for-your-needs-and-then-plan-your-migration/","timestamp":"1694843820.0","comment_id":"1008939","upvote_count":"4","poster":"Angryasianxd"},{"comment_id":"1007052","poster":"n0pz","upvote_count":"2","content":"S3 is discarded since the question says: A company is building a new dynamic ordering website,","timestamp":"1694653260.0"},{"content":"Selected Answer: A\nminimize server maintenance and patching, highly available, scale read and write = serverless = Amazon S3, Amazon API Gateway, AWS Lambda, Amazon DynamoDB","comment_id":"1006178","poster":"TariqKipkemei","upvote_count":"3","timestamp":"1694578320.0"},{"timestamp":"1694281020.0","content":"Selected Answer: A\nKey phrase in the Question is must scale read and write capacity. Aurora is only for Read.\nAmazon DynamoDB has two read/write capacity modes for processing reads and writes on your tables:\nOn-demand\nProvisioned (default, free-tier eligible)\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html","comment_id":"1003385","upvote_count":"4","poster":"DebAwsAccount"},{"upvote_count":"2","poster":"Guru4Cloud","content":"Selected Answer: A\nMinimize maintenance & Patching = Serverless\nS3, DynamoDB are serverless","comment_id":"983858","timestamp":"1692292980.0"},{"timestamp":"1691897280.0","comment_id":"979718","poster":"ravindrabagale","content":"Minimize maintenance & Patching = Serverless services\nServerless services with no sql database is perfect combination","upvote_count":"2"},{"timestamp":"1687778940.0","poster":"cookieMr","content":"Selected Answer: A\nB. This solution leverages serverless technologies like API Gateway and Lambda for hosting dynamic content, reducing server maintenance and patching. Aurora with Aurora Auto Scaling provides a highly available and scalable database solution. Hosting static content in S3 and configuring CloudFront for content delivery ensures high availability and efficient scaling.\n\nA. Using DynamoDB with on-demand capacity may provide scalability, but it does not offer the same level of flexibility and performance as Aurora. Additionally, it does not address the hosting of dynamic content using serverless technologies.\n\nC. Hosting all the website content on EC2 instances requires server maintenance and patching. While using ASG and an ALB helps with availability and scalability, it does not minimize server maintenance as requested.\n\nD. Hosting all the website content on EC2 instances introduces server maintenance and patching. Using Aurora with Aurora Auto Scaling is a good choice for the database, but it does not address the need to minimize server maintenance and patching for the overall infrastructure.","upvote_count":"1","comment_id":"934338"},{"poster":"dydzah","upvote_count":"2","content":"B isn't correct because of cooldown\nYou can tune the responsiveness of a target-tracking scaling policy by adding cooldown periods that affect scaling your Aurora DB cluster in and out. A cooldown period blocks subsequent scale-in or scale-out requests until the period expires. These blocks slow the deletions of Aurora Replicas in your Aurora DB cluster for scale-in requests, and the creation of Aurora Replicas for scale-out requests.","timestamp":"1685543700.0","comment_id":"911365"},{"comment_id":"910927","timestamp":"1685515560.0","content":"Key word in question \"storing ordering data\" \nDynamoDB is perfect for storing ordering data (key-values)","upvote_count":"3","poster":"Abrar2022"},{"content":"Selected Answer: A\nMinimize maintenance & Patching = Serverless \nS3, DynamoDB are serverless","comment_id":"897053","timestamp":"1684010280.0","poster":"studynoplay","upvote_count":"3"},{"comments":[{"comment_id":"1004827","upvote_count":"5","timestamp":"1694437440.0","content":"For anyone who is confused about Option B, there's a serverless Aurora service called \"Aurora Serverless v2\". This will bring us an equivalent solution to option A. But the Option B in the question only states the Aurora, therefore by default we need to manage the servers underneath.\nRef: https://www.projectpro.io/article/aws-aurora-vs-rds/737#:~:text=RDS%20is%20a%20fully%2Dmanaged,manual%20management%20of%20database%20servers.","poster":"yyuussaaa"}],"upvote_count":"1","content":"The company wants to minimize server maintenance and patching -> Serverless (minimize)\nC,D are wrong because these are not serverless\nB is wrong because RDS is not serverless\n-> A full serverless","timestamp":"1683698760.0","comment_id":"893658","poster":"lucdt4"},{"upvote_count":"3","timestamp":"1673344020.0","poster":"DavidNamy","comments":[{"content":"The answer is A.\nKey phrase in the Question is must scale read and write capacity. Aurora is only for Read.\nAmazon DynamoDB has two read/write capacity modes for processing reads and writes on your tables:\nOn-demand\nProvisioned (default, free-tier eligible)\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html","comment_id":"788782","timestamp":"1674741660.0","poster":"Joxtat","upvote_count":"4"}],"content":"Selected Answer: B\nThe correct answer is B.\n\nThe option A would also meet the company's requirements of minimizing server maintenance and patching, and providing high availability and quick scaling for read and write capacity. However, there are a few reasons why option B is a more optimal solution:\n\nIn option A, it uses Amazon DynamoDB with on-demand capacity for the database, which may not provide the same level of scalability and performance as using Amazon Aurora with Aurora Auto Scaling.\nAmazon Aurora offers additional features such as automatic failover, read replicas, and backups that makes it a more robust and resilient option than DynamoDB. Additionally, the auto scaling feature is better suited to handle the changes in user demand.\nAdditionally, option B provides a more cost-effective solution, as Amazon Aurora can be more cost-effective for high read and write workloads than Amazon DynamoDB, and also it's providing more features.","comment_id":"771261"},{"timestamp":"1672650060.0","content":"Selected Answer: A\nA for sure ~","comment_id":"763607","upvote_count":"2","poster":"Zerotn3"},{"timestamp":"1671300000.0","comment_id":"748259","content":"Selected Answer: A\nOption A","upvote_count":"2","poster":"career360guru"},{"poster":"lapaki","comment_id":"742500","timestamp":"1670829540.0","content":"Selected Answer: A\nA. Looking for serverless to reduce maintenance requirements","upvote_count":"3"},{"comment_id":"741937","content":"A\nAmazon DynamoDB with on-demand capacity for the database. This solution allows the website to automatically scale to meet changes in user demand and minimize the need for server maintenance and patching. B is not a correct answer because it uses Amazon Aurora with Aurora Auto Scaling for the database(While Amazon Aurora is a highly available and scalable database solution); however, it is not a suitable choice for this scenario because it requires server maintenance and patching.","upvote_count":"2","comments":[{"poster":"JayBee65","comment_id":"769313","timestamp":"1673176020.0","content":"Right answer but wrong reason. B is not suitable because the requirements are \"must scale read and write\" but Aurora replication is using single-master replication, i.e. Read Replication.","upvote_count":"3"}],"poster":"Shasha1","timestamp":"1670780280.0"},{"content":"Selected Answer: A\nOn-demand mode is a good option if any of the following are true:\n\nYou create new tables with unknown workloads.\n\nYou have unpredictable application traffic.\n\nYou prefer the ease of paying for only what you use.\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html","timestamp":"1669198500.0","poster":"mabotega","comment_id":"725048","upvote_count":"3"},{"comment_id":"724499","timestamp":"1669136100.0","content":"A is correct","upvote_count":"2","poster":"Wpcorgan"},{"poster":"Az900500","content":"Selected Answer A\n\n\"Read write capacity = DynamoDb\" Read Replica mostly Aurora .. @nhlegend yes DynampDB has 400KB maximum but in the answer neither Dynamo or Aurora was used as primary storage","upvote_count":"5","timestamp":"1668725640.0","comment_id":"720943"},{"poster":"sdasdawa","comment_id":"719877","timestamp":"1668620880.0","content":"Selected Answer: A\nAgree with A, DynamoDB is perfect for storing ordering data (key-values)","upvote_count":"6"},{"content":"A is the answer","upvote_count":"3","poster":"Nigma","timestamp":"1668603600.0","comment_id":"719651"},{"comments":[{"upvote_count":"3","poster":"rjam","comment_id":"719596","comments":[{"content":"Question states \"must scale Read and Write Capacity\" which refers to Dynamo, whereas, Aurora is good for scaling read replicas.","timestamp":"1670013360.0","comment_id":"734052","poster":"Aamee","upvote_count":"4"},{"timestamp":"1673176080.0","poster":"JayBee65","comment_id":"769314","content":"B is not suitable because the requirements are \"must scale read and write\" but Aurora replication is using single-master replication, i.e. Read Replication.","upvote_count":"1"}],"content":"amazon aurora - highly available, self-healing, auto-scaling","timestamp":"1668600180.0"}],"timestamp":"1668600060.0","comment_id":"719594","poster":"rjam","upvote_count":"2","content":"Selected Answer: B\noption B . Aurora is better than DynamoDB"},{"content":"B is correct, DynampDB has 400KB maximum","poster":"nhlegend","comments":[{"timestamp":"1668553380.0","content":"typo, I mean A is correct","upvote_count":"4","poster":"nhlegend","comment_id":"719178"}],"upvote_count":"1","timestamp":"1668553260.0","comment_id":"719177"}],"answer_images":[],"answer":"A","answer_description":"","choices":{"D":"Host all the website content on Amazon EC2 instances. Create an Auto Scaling group to scale the EC2 instances. Use an Application Load Balancer to distribute traffic. Use Amazon Aurora with Aurora Auto Scaling for the database.","C":"Host all the website content on Amazon EC2 instances. Create an Auto Scaling group to scale the EC2 instances. Use an Application Load Balancer to distribute traffic. Use Amazon DynamoDB with provisioned write capacity for the database.","A":"Host static content in Amazon S3. Host dynamic content by using Amazon API Gateway and AWS Lambda. Use Amazon DynamoDB with on-demand capacity for the database. Configure Amazon CloudFront to deliver the website content.","B":"Host static content in Amazon S3. Host dynamic content by using Amazon API Gateway and AWS Lambda. Use Amazon Aurora with Aurora Auto Scaling for the database. Configure Amazon CloudFront to deliver the website content."},"topic":"1","timestamp":"2022-11-16 00:01:00","question_images":[],"question_id":114,"url":"https://www.examtopics.com/discussions/amazon/view/87570-exam-aws-certified-solutions-architect-associate-saa-c03/","isMC":true,"exam_id":31,"question_text":"A company is building a new dynamic ordering website. The company wants to minimize server maintenance and patching. The website must be highly available and must scale read and write capacity as quickly as possible to meet changes in user demand.\n\nWhich solution will meet these requirements?","unix_timestamp":1668553260,"answers_community":["A (95%)","5%"]},{"id":"lZHJZ2l7apFBk1EVA63B","topic":"1","isMC":true,"answers_community":["A (76%)","C (24%)"],"question_id":115,"url":"https://www.examtopics.com/discussions/amazon/view/87534-exam-aws-certified-solutions-architect-associate-saa-c03/","question_text":"A company has an AWS account used for software engineering. The AWS account has access to the company’s on-premises data center through a pair of AWS Direct Connect connections. All non-VPC traffic routes to the virtual private gateway.\n\nA development team recently created an AWS Lambda function through the console. The development team needs to allow the function to access a database that runs in a private subnet in the company’s data center.\n\nWhich solution will meet these requirements?","answer":"A","unix_timestamp":1668526860,"timestamp":"2022-11-15 16:41:00","discussion":[{"upvote_count":"24","comments":[{"poster":"markw92","content":"The question says on-prem database...how do we create a SG for that instance in AWS? C make sense. my 2 cents..","comments":[{"poster":"SSadiq","timestamp":"1718287320.0","comment_id":"1229870","upvote_count":"2","content":"SG is for Lambda and not for the on-prem database. A is the correct option"},{"poster":"AZ_Master","comment_id":"1075045","timestamp":"1700442720.0","content":"A is correct. To configure SG for Lambda , go to Lambda function -> Configure -> Edit VPC and scroll down to see \"security groups\" where you can configure Lambda for VPC. \nAlso see here\nhttps://repost.aws/questions/QUSaj1a6jBQ92Kp56klbZFNw/aws-lambda-to-on-premise-via-direct-connect-and-aws-privatelink","upvote_count":"2"}],"upvote_count":"7","comment_id":"926111","timestamp":"1687018800.0"}],"timestamp":"1669919700.0","poster":"Gil80","content":"Selected Answer: A\nTo configure a VPC for an existing function:\n\n1. Open the Functions page of the Lambda console.\n2. Choose a function.\n3. Choose Configuration and then choose VPC.\n4. Under VPC, choose Edit.\n5. Choose a VPC, subnets, and security groups. <-- **That's why I believe the answer is A**.\n\nNote:\nIf your function needs internet access, use network address translation (NAT). Connecting a function to a public subnet doesn't give it internet access or a public IP address.","comment_id":"732947"},{"upvote_count":"11","poster":"javitech83","comments":[{"poster":"LuckyAro","content":"C says to \"update the route table\" not create a new connection. C is correct.","comment_id":"778458","upvote_count":"5","timestamp":"1673921220.0","comments":[{"timestamp":"1685957100.0","content":"C is wrong. Lambda can't connect by default to resources in a private VPC, so you have to do some specific setup steps to run in a private VPC, Answer A is correct","poster":"ruqui","upvote_count":"3","comment_id":"915268"},{"comment_id":"875516","comments":[{"upvote_count":"1","comment_id":"1409603","poster":"jerryl","content":"the question didnt mention where the direct connect is set up but mention that all non vpc traffic are private\nso i think it makes sense you need to config route table\nand i think in C, update the vpc already imply that the lambda is going to be run in that vpc","timestamp":"1742805540.0"}],"poster":"Adios_Amigo","upvote_count":"4","timestamp":"1681989480.0","content":"No need to do route updates. This is because the route to the destination on-premises is already set."}]}],"timestamp":"1670411220.0","content":"Selected Answer: A\nit is A. C is not correct at all as in the question it metions that the VPC already has connectivity with on-premises","comment_id":"737760"},{"comment_id":"1409866","content":"Selected Answer: C\nSame queston in exam topic #524 and highly voted answer is C there \n\nSince database on company's data center can not have security group. my vote goes to C","upvote_count":"1","poster":"ChhatwaniB","timestamp":"1742868000.0"},{"upvote_count":"1","timestamp":"1738873740.0","poster":"Dharmarajan","content":"Selected Answer: A\nThe language is confusing, but the option A essentially says that \"Configure the Lambda to execute in your own VPC (instead of AWS's own Lambda VPC) and since your VPC already is configured with the route to On prem data center, it will be able to access the on prem data center resources.","comment_id":"1352653"},{"upvote_count":"2","content":"Selected Answer: A\nBy default, Lambda functions operate outside the customer’s VPC. To access on-premises resources via Direct Connect, the Lambda function must be deployed inside the VPC.\n\nOnce attached to the VPC, Lambda can use the VPC’s networking setup (route tables, security groups, and the virtual private gateway) to communicate with the on-premises database over Direct Connect.","timestamp":"1738529220.0","poster":"FlyingHawk","comment_id":"1350648"},{"upvote_count":"1","poster":"ensbrvsnss","comment_id":"1270998","content":"Selected Answer: C\neither A or C","timestamp":"1724373420.0"},{"upvote_count":"2","content":"Selected Answer: C\nC is correect as lambda already in VPC and AWS account already has connection setup with on-premise database in private subnet","comment_id":"1243935","poster":"jatric","timestamp":"1720370940.0"},{"comment_id":"1220176","content":"Selected Answer: A\nB,C,D dont have any logic behind them.\nA is the most logical answer as you need to connect a function to a VPC. The VPC will be connected to the on-prem database.","upvote_count":"2","poster":"lofzee","timestamp":"1716895140.0"},{"content":"Selected Answer: A\nAnswer A: During Lambda function creation select \"Advanced Settings\" select \"Enable VPC\", this will allow you to select VPC, Subnets and SecurityGroup for your Lambda function. This is the way Lambda can get controlled access to resouces in your VPC.\n\nDefault Lambda Settings:\nWhen you create a Lambda function without specifying a VPC, the Lambda function does not get associated with any particular VPC. By default, Lambda functions are not deployed within a VPC and do not have access to resources within a VPC, such as EC2 instances, RDS databases, or Elasticache clusters, unless you explicitly configure the Lambda function to connect to a VPC.","comment_id":"1195046","timestamp":"1713023640.0","upvote_count":"5","poster":"MehulKapadia"},{"content":"Selected Answer: C\nUpdate the route tables in the VPC to allow the Lambda function to access the on-premises data center through Direct Connect.\n\nBy updating the route tables in the VPC to allow the Lambda function to access the on-premises data center through Direct Connect, is the most appropriate solution. By updating the route tables, you can specify the route for traffic from the Lambda function to the IP address range of the on-premises data center via the Direct Connect connection. This ensures that the Lambda function can securely communicate with the database in the private subnet of the data center.","timestamp":"1712235660.0","poster":"Uzbekistan","upvote_count":"2","comment_id":"1189339"},{"comment_id":"1124547","poster":"awsgeek75","timestamp":"1705444680.0","upvote_count":"9","content":"Every time I read this question the badly phrased options make no sense at all. I now want to vote for A but it makes no sense.\nQuestion says: All non-VPC traffic routes to the virtual private gateway\nSo Lambda is technically a non VPC traffic too. This means it already goes through the VPGW but we don't know what it connects. Assuming it connect the data-centre to AWS then A makes sense. BUT all this is based on different interpretation now for me."},{"comment_id":"1115282","timestamp":"1704556080.0","comments":[{"poster":"Kanagarajd","timestamp":"1709992980.0","comment_id":"1169527","content":"I agree with explanation!","upvote_count":"3"}],"content":"Selected Answer: A\nThe wording is strange because technically, the Lambda function does not \"run in the VPC\", rather it is connected to the VPC, but otherwise A is what relevant documentation says - connect the Lambda function to the VPN and allow traffic in the security group. \n\nNot B, we have Direct Connect, no need for VPN.\n\nNot C, route is already in place. And route alone does not help - the \"route tables in the VPC\" are completely irrelevant as long as we don't connect the Lambda function to the VPC.\n\nNot D, an \"Elastic IP address\" is always connected to an \"elastic network interface\", such is created automatically with A.","poster":"pentium75","upvote_count":"7"},{"poster":"awsgeek75","upvote_count":"1","timestamp":"1704064680.0","comment_id":"1110874","content":"Selected Answer: C\nThe question and options are very badly worded so it makes C a possible candidate (unconvincingly though!).\nB: VPN is not needed as Direct Connect is already there\nD: Irrelevant \nA is too generic (appropriate security group for what?) Lambda has fixed VPC or ENI\nC is logically relevant"},{"content":"A says \"configure the Lambda function to RUN IN the VPC\", but \"a Lambda function ALWAYS runs inside a VPC owned by the Lambda service\" (https://docs.aws.amazon.com/lambda/latest/dg/foundation-networking.html). \"You can configure a Lambda function to CONNECT TO private subnets in a virtual private cloud (VPC) in your AWS account\", but \"connect to\" is not the same as \"run in\" (https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html). Otherwise A would make sense (you CAN assign a security group to the Elastic Network Interface that Lambda uses to connect to your VPC).","upvote_count":"2","poster":"pentium75","comments":[{"upvote_count":"2","comment_id":"1106607","content":"B We already have Direct Connect, so why set up VPN\n\nC doesn't make sense because \"all non-VPC traffic [already] routes to the virtual private gateway\" (which is obviously connected to the Direct Connect gateway), so why should you \"update the route tables\"?\n\nD sounds plausible; however, an Elastic IP address is associated with an Elastic Network Interface (though that is automatically provided by AWS). So the \"without an elastic network interface\" makes D wrong.\n\nMy best guess is that there's a typo or misunderstanding in the answers. It's either A but it should read \"connect to the VPC\" instead of \"run in the VPC\", or it's D but it should read \"without CREATING an elastic network interface\" or \"WITH an elastic network interface\".","poster":"pentium75","timestamp":"1703658600.0"}],"timestamp":"1703658600.0","comment_id":"1106606"},{"comment_id":"1067367","poster":"xdkonorek2","timestamp":"1699632480.0","upvote_count":"2","content":"Selected Answer: C\nit's not A:\nA Lambda function always runs inside a VPC owned by the Lambda service.\nhttps://docs.aws.amazon.com/lambda/latest/dg/foundation-networking.html"},{"comment_id":"1063942","upvote_count":"2","poster":"liux99","content":"The answer is C. The question is to allow lambda to access the database running in private subnet in the corporate data center. The only connectivity with the data center is Direct connect.","timestamp":"1699281840.0"},{"poster":"Igogor","timestamp":"1697432220.0","comment_id":"1044670","upvote_count":"2","content":"Answer C is correct: \n\nhttps://repost.aws/questions/QUSaj1a6jBQ92Kp56klbZFNw/aws-lambda-to-on-premise-via-direct-connect-and-aws-privatelink"},{"content":"Selected Answer: A\nGo to the Lambda console.\nClick the Functions tab.\nSelect the Lambda function that you want to configure.\nClick the Configuration tab.\nIn the Network section, select the VPC that you want the function to run in.\nIn the Security groups section, select the security group that you want to allow the function to access the database subnet.\nClick the Save button.","poster":"Guru4Cloud","upvote_count":"4","timestamp":"1692293340.0","comment_id":"983868"},{"comment_id":"962772","timestamp":"1690292460.0","content":"Correct answer is A\nLambda is available in the Region by default.. if you want to connect it to your private subnet or to on prem data center you must configure your Lambda with vpc..\n\nC is wrong because there is no help adding routes to VPC without configuring your lambda to vpc.","poster":"zjcorpuz","upvote_count":"3"},{"timestamp":"1687779120.0","upvote_count":"5","comment_id":"934341","content":"Selected Answer: A\nOption A: Configure the Lambda function to run in the VPC with the appropriate security group. This allows the Lambda function to access the database in the private subnet of the company's data center. By running the Lambda function in the VPC, it can communicate with resources in the private subnet securely.\n\nOption B is incorrect because setting up a VPN connection and routing the traffic from the Lambda function through the VPN would add unnecessary complexity and overhead.\n\nOption C is incorrect because updating the route tables in the VPC to allow access to the on-premises data center through Direct Connect would affect the entire VPC's routing, potentially exposing other resources to the on-premises network.\n\nOption D is incorrect because creating an Elastic IP address and sending traffic through it without an elastic network interface is not a valid configuration for accessing resources in a private subnet.","poster":"cookieMr"},{"timestamp":"1683337380.0","content":"Selected Answer: C\nMy answer is C. Refer to the steps in the link. need to configure the routing table to route traffic to the destination. \nhttps://aws.amazon.com/blogs/compute/running-aws-lambda-functions-on-aws-outposts-using-aws-iot-greengrass/\n\nA is wrong as it says configure the lambda function in the VPC. the requirement to run in the database that is on-premise.","upvote_count":"7","comment_id":"890403","poster":"cheese929"},{"poster":"kruasan","timestamp":"1682693460.0","upvote_count":"4","comment_id":"883561","content":"Selected Answer: A\nonce you have configured your Lambda to be deployed (or connected) to your VPC [1], as long as your VPC has connectivity to your data center, it will be allowed to route the traffic towards it - whether it uses Direct Connect or other connections, like VPN.\nhttps://repost.aws/questions/QUSaj1a6jBQ92Kp56klbZFNw/questions/QUSaj1a6jBQ92Kp56klbZFNw/aws-lambda-to-on-premise-via-direct-connect-and-aws-privatelink?"},{"comments":[{"upvote_count":"1","content":"from Google Translate\n\n\"Because it is traffic going to the company data center.\"","comment_id":"1313880","poster":"JA2018","timestamp":"1731910680.0"},{"poster":"darn","upvote_count":"4","comment_id":"877575","content":"english please","timestamp":"1682190960.0"},{"poster":"youdelin","comment_id":"1038963","content":"dude, english","upvote_count":"1","timestamp":"1696880280.0"},{"comment_id":"1118462","content":"zzzzzzz","poster":"4fad2f8","upvote_count":"1","timestamp":"1704883560.0"}],"poster":"Jinius83","upvote_count":"4","content":"C\nAWS -> 회사 데이터 센터로 나가는 트래픽이기 때문에","timestamp":"1681703460.0","comment_id":"872310"},{"upvote_count":"5","content":"Selected Answer: A\nCORRECT ANSWER = A, \nC = WRONG because in question, it is telling non VPN traffic is being sent through virtual private gateway(Direct Connect), meaning all routes are looking towards on prem where out destination service is located. So no routing change will be needed. \n\nWhen you create Lambda(Function) - > you need to choose VPN and than Security group inside VPC. \n\nLink for better understanding :\n\nhttps://www.youtube.com/watch?v=beV1AYyhgYA&ab_channel=DigitalCloudTraining","comments":[{"upvote_count":"1","comment_id":"864432","timestamp":"1680931980.0","poster":"datz","content":"it is telling non \"VPC\" traffic, really wish there was edit function lol"}],"timestamp":"1680931920.0","poster":"datz","comment_id":"864431"},{"upvote_count":"2","comment_id":"841752","poster":"Devsin2000","timestamp":"1679039400.0","content":"In my opinion this question is flawed. Non of the answers makes any sense to me. However, if I have to choose one I will choose C. There is no option of associating Security Group with Lambda function."},{"content":"Selected Answer: A\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-managing-eni","poster":"bdp123","comment_id":"816780","upvote_count":"3","timestamp":"1676995020.0"},{"timestamp":"1676448240.0","comments":[{"poster":"nickolaj","upvote_count":"3","content":"Option B is not ideal as it would require additional configuration and management of a VPN connection between the company's data center and AWS, which may not be necessary for the specific use case.\n\nOption C is not recommended as updating the route tables to allow the Lambda function to access the on-premises data center through Direct Connect would allow all VPC traffic to route through the data center, which may not be desirable and could potentially create security risks.\n\nOption D is not a viable solution for accessing resources in the on-premises data center as Elastic IP addresses are only used for outbound internet traffic from an Amazon VPC, and cannot be used to communicate with resources in an on-premises data center.","comment_id":"809271","timestamp":"1676448240.0"}],"upvote_count":"3","content":"Selected Answer: A\nThe best solution to meet the requirements would be option A - Configure the Lambda function to run in the VPC with the appropriate security group.\n\nBy configuring the Lambda function to run in the VPC, the function will have access to the private subnets in the company's data center through the Direct Connect connections. Additionally, security groups can be used to control inbound and outbound traffic to and from the Lambda function, ensuring that only the necessary traffic is allowed.","comment_id":"809270","poster":"nickolaj"},{"content":"Selected Answer: A\n\"All non-VPC traffic routes to the virtual private gateway.\" means -> there are already the appropriate routes, so no need for update the route tables.\nKey phrase: \"database that runs in a private subnet in the company's data center.\", means: You need the appropriate security group to access the DB.","comment_id":"807170","upvote_count":"4","timestamp":"1676275680.0","poster":"Yelizaveta"},{"timestamp":"1673921340.0","poster":"LuckyAro","content":"Selected Answer: A\nA makes more sense to me.","comment_id":"778459","upvote_count":"2"},{"comments":[{"poster":"Deepak_k","timestamp":"1675985640.0","content":"Yes Lambda is not connected to an Amazon VPC. so Answer A","comment_id":"803785","upvote_count":"2"}],"poster":"Mindvision","timestamp":"1672674300.0","content":"A = Answer. \n\nNote that \" All non-VPC traffic routes to the virtual gateway\" meaning if traffic not meant for the VPC, it routes to on-prem (C answer invalid). For the Lambda function to access the on-prem database you have to configure the Lambda function in the VPC and use appropriate SG outbound. \n \nPhew! did some research on this, was a bit confused with C.","comment_id":"763817","upvote_count":"6"},{"content":"Selected Answer: C\nit is C only","upvote_count":"4","comment_id":"755601","timestamp":"1671968640.0","poster":"NV305"},{"comments":[{"upvote_count":"7","comments":[{"timestamp":"1675060740.0","content":"Have noticed the Buru----tuy guy/girl likes giving incorrect answers.","comments":[{"content":"Most likely Buru----tuy is getting responses from ChatGPT, which is not always right.","upvote_count":"5","comment_id":"803834","poster":"superman917","timestamp":"1675989240.0"}],"comment_id":"792486","poster":"ProfXsamson","upvote_count":"2"}],"poster":"JayBee65","timestamp":"1673176380.0","content":"Sorry, but like a lot of your responses in this group, your answers are incorrect. I really think you need to study more, unless you are deliberately trying to confuse people. \"All non-VPC traffic routes to the virtual private gateway\" means that C is not necessary.","comment_id":"769319"},{"timestamp":"1671748980.0","comments":[{"upvote_count":"1","comment_id":"938044","content":"wrong again, my cute, tiny, untrained AI :) \nIt seems you lack the concept of on-prem, which is frankly awkward...","timestamp":"1688040120.0","poster":"Ezekiel2517"}],"upvote_count":"4","content":"Option A, configuring the Lambda function to run in the VPC with the appropriate security group, is not the correct solution because it does not allow the Lambda function to access the database in the private subnet in the data center.\n\nOption B, setting up a VPN connection from AWS to the data center and routing the traffic from the Lambda function through the VPN, is not the correct solution because it would not be the most efficient solution, as the traffic would need to be routed over the public internet, potentially increasing latency.\n\nOption D, creating an Elastic IP address and configuring the Lambda function to send traffic through the Elastic IP address without an elastic network interface, is not a valid solution because Elastic IP addresses are used to assign a static public IP address to an instance or network interface, and do not provide a direct connection to an on-premises data center.","poster":"Buruguduystunstugudunstuy","comment_id":"753709"}],"comment_id":"753708","upvote_count":"3","poster":"Buruguduystunstugudunstuy","content":"Selected Answer: C\nTo allow an AWS Lambda function to access a database in a private subnet in the company's data center, the correct solution is to update the route tables in the Virtual Private Cloud (VPC) to allow the Lambda function to access the on-premises data center through the AWS Direct Connect connections.\n\nOption C, updating the route tables in the VPC to allow the Lambda function to access the on-premises data center through Direct Connect, is the correct solution to meet the requirements.","timestamp":"1671748980.0"},{"upvote_count":"2","content":"Selected Answer: A\nOption A","comment_id":"748265","poster":"career360guru","timestamp":"1671300420.0"},{"timestamp":"1669326660.0","content":"Selected Answer: A\nWhen you connect a function to a VPC, Lambda assigns your function to a Hyperplane ENI (elastic network interface) for each subnet in your function's VPC configuration. Lambda creates a Hyperplane ENI the first time a unique subnet and security group combination is defined for a VPC-enabled function in an account.","comment_id":"726231","upvote_count":"3","poster":"Newptone"},{"poster":"romko","content":"Selected Answer: A\nlambda by default runs out of vpc, so without A lambda is out of vpc.\n\nC is incorrect, because don't matter how you change route tables in VPC it doesn't make sense while lambda is out of vpc.\n\nSo the correct answer is A","timestamp":"1669207080.0","comment_id":"725111","upvote_count":"4"},{"timestamp":"1669136160.0","poster":"Wpcorgan","comment_id":"724500","content":"C is correct","upvote_count":"1"},{"poster":"taer","upvote_count":"3","content":"Selected Answer: C\nAnswer is C","timestamp":"1668663300.0","comment_id":"720236"},{"comment_id":"720136","upvote_count":"3","timestamp":"1668650700.0","content":"Selected Answer: C\nC\nhttps://www.examtopics.com/discussions/amazon/view/68069-exam-aws-certified-solutions-architect-associate-saa-c02/","poster":"mricee9"},{"content":"Its A.Deploy the Lambda Function in the VPC with a security group.\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-managing-eni","comment_id":"719075","upvote_count":"3","poster":"Ohnet","timestamp":"1668541560.0"},{"timestamp":"1668526860.0","poster":"sdasdawa","upvote_count":"2","comment_id":"718922","content":"Selected Answer: A\n1st section in\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-managing-eni"}],"question_images":[],"answer_images":[],"exam_id":31,"choices":{"B":"Set up a VPN connection from AWS to the data center. Route the traffic from the Lambda function through the VPN.","A":"Configure the Lambda function to run in the VPC with the appropriate security group.","C":"Update the route tables in the VPC to allow the Lambda function to access the on-premises data center through Direct Connect.","D":"Create an Elastic IP address. Configure the Lambda function to send traffic through the Elastic IP address without an elastic network interface."},"answer_description":"","answer_ET":"A"}],"exam":{"isBeta":false,"isImplemented":true,"name":"AWS Certified Solutions Architect - Associate SAA-C03","id":31,"numberOfQuestions":1019,"provider":"Amazon","lastUpdated":"11 Apr 2025","isMCOnly":true},"currentPage":23},"__N_SSP":true}