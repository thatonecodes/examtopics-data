{"pageProps":{"questions":[{"id":"zDtHu7du1HTzxqYyMDeg","discussion":[{"comment_id":"1362356","content":"Selected Answer: AC\nusing parqueet or ORC is efficient and so will be partitioning by order date so the range of data is lower","poster":"Ell89","timestamp":"1740614400.0","upvote_count":"1"},{"timestamp":"1739917320.0","poster":"italiancloud2025","upvote_count":"1","content":"Selected Answer: BC\nNo, porque la opción A implica modificar la aplicación de terceros para que genere archivos en formato columnar, lo cual puede ser más complejo o inviable, mientras que la opción B utiliza un job de Glue para consolidar los CSV sin tocar la fuente. La opción C sigue siendo esencial para particionar por fecha y optimizar las consultas.","comment_id":"1358484"},{"content":"Selected Answer: AC\nhttps://docs.aws.amazon.com/redshift/latest/dg/r_SUPER_type.html","upvote_count":"1","comment_id":"1317242","timestamp":"1732491000.0","poster":"emupsx1"}],"question_images":[],"answer":"AC","answer_description":"","choices":{"A":"Configure the third-party application to create the files in a columnar format.","D":"Configure the third-party application to create the files in JSON format.","B":"Develop an AWS Glue ETL job to convert the multiple daily CSV files to one file for each day.","C":"Partition the order data in the S3 bucket based on order date.","E":"Load the JSON data into the Amazon Redshift table in a SUPER type column."},"unix_timestamp":1732491000,"answers_community":["AC (67%)","BC (33%)"],"answer_ET":"AC","question_id":61,"isMC":true,"answer_images":[],"question_text":"A retail company uses an Amazon Redshift data warehouse and an Amazon S3 bucket. The company ingests retail order data into the S3 bucket every day.\n\nThe company stores all order data at a single path within the S3 bucket. The data has more than 100 columns. The company ingests the order data from a third-party application that generates more than 30 files in CSV format every day. Each CSV file is between 50 and 70 MB in size.\n\nThe company uses Amazon Redshift Spectrum to run queries that select sets of columns. Users aggregate metrics based on daily orders. Recently, users have reported that the performance of the queries has degraded. A data engineer must resolve the performance issues for the queries.\n\nWhich combination of steps will meet this requirement with LEAST developmental effort? (Choose two.)","topic":"1","url":"https://www.examtopics.com/discussions/amazon/view/151918-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","timestamp":"2024-11-25 00:30:00","exam_id":21},{"id":"H6apOuWdnjeGjcKzklBG","url":"https://www.examtopics.com/discussions/amazon/view/151919-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","answer_description":"","answer_images":[],"unix_timestamp":1732491300,"isMC":true,"question_text":"A company stores customer records in Amazon S3. The company must not delete or modify the customer record data for 7 years after each record is created. The root user also must not have the ability to delete or modify the data.\n\nA data engineer wants to use S3 Object Lock to secure the data.\n\nWhich solution will meet these requirements?","question_id":62,"answer":"B","question_images":[],"answer_ET":"B","timestamp":"2024-11-25 00:35:00","choices":{"C":"Place a legal hold on individual objects in the S3 bucket. Set the retention period to 7 years.","D":"Set the retention period for individual objects in the S3 bucket to 7 years.","B":"Enable compliance mode on the S3 bucket. Use a default retention period of 7 years.","A":"Enable governance mode on the S3 bucket. Use a default retention period of 7 years."},"discussion":[{"content":"Selected Answer: B\n\"In compliance mode, a protected object version can't be overwritten or deleted by any user, including the root user in your AWS account. When an object is locked in compliance mode, its retention mode can't be changed, and its retention period can't be shortened. Compliance mode helps ensure that an object version can't be overwritten or deleted for the duration of the retention period.\"","upvote_count":"2","timestamp":"1736962740.0","poster":"MerryLew","comment_id":"1341158"},{"upvote_count":"3","poster":"emupsx1","timestamp":"1732491300.0","content":"Selected Answer: B\nhttps://aws.amazon.com/s3/features/object-lock/","comment_id":"1317246"}],"topic":"1","exam_id":21,"answers_community":["B (100%)"]},{"id":"0I5mbuFfIuSm1i2vG5Zh","question_id":63,"question_text":"A data engineer needs to create a new empty table in Amazon Athena that has the same schema as an existing table named old_table.\n\nWhich SQL statement should the data engineer use to meet this requirement?","isMC":true,"choices":{"A":"CREATE TABLE new_table AS SELECT * FROM old_tables;","C":"CREATE TABLE new_table (LIKE old_table);","B":"INSERT INTO new_table SELECT * FROM old_table;","D":"CREATE TABLE new_table AS (SELECT * FROM old_table) WITH NO DATA;"},"unix_timestamp":1730002260,"answers_community":["D (100%)"],"answer":"D","exam_id":21,"question_images":[],"discussion":[{"content":"Selected Answer: D\nD is the correct answer.\n\nHere is why:\n\nThe AS clause allows you to define the new table's schema based on a SELECT statement.\n \nThe WITH NO DATA clause at the end explicitly tells Athena to create the table structure without copying any data.\n\nFor more information, see the \"Creating an empty copy of an existing table\" section in this documentation - https://docs.aws.amazon.com/athena/latest/ug/ctas-examples.html","comment_id":"1309172","upvote_count":"2","poster":"AgboolaKun","timestamp":"1731177540.0"},{"content":"Selected Answer: D\nwith no data, creates a new table with the same schema as the old one.\nhttps://docs.aws.amazon.com/athena/latest/ug/create-table-as.html","upvote_count":"1","timestamp":"1730461740.0","comment_id":"1305777","poster":"Eleftheriia"},{"poster":"pikuantne","comment_id":"1305419","timestamp":"1730378640.0","content":"Selected Answer: D\nD is correct","upvote_count":"1"},{"timestamp":"1730002260.0","upvote_count":"1","content":"Answer: D","comment_id":"1303477","poster":"Parandhaman_Margan"}],"answer_images":[],"topic":"1","answer_description":"","answer_ET":"D","url":"https://www.examtopics.com/discussions/amazon/view/150339-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","timestamp":"2024-10-27 05:11:00"},{"id":"cRVgnAk0leTLEkJ44Ri6","timestamp":"2024-10-27 05:11:00","answer_ET":"A","isMC":true,"question_id":64,"url":"https://www.examtopics.com/discussions/amazon/view/150340-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","exam_id":21,"unix_timestamp":1730002260,"answer_description":"","discussion":[{"timestamp":"1742289300.0","upvote_count":"1","poster":"saqib839","content":"Selected Answer: A\nbut he said create table so neither of them is true.","comment_id":"1400036"},{"poster":"MerryLew","content":"Selected Answer: A\nThe INSERT INTO SELECT statement copies data from one table and inserts it into another table.","comment_id":"1341160","timestamp":"1736962860.0","upvote_count":"1"},{"comment_id":"1305892","timestamp":"1730475060.0","comments":[{"upvote_count":"1","content":"https://docs.aws.amazon.com/athena/latest/ug/insert-into.html","timestamp":"1730475060.0","poster":"Eleftheriia","comment_id":"1305894"}],"content":"Selected Answer: A\nINSERT INTO cities_usa (city,state)\nSELECT city,state\nFROM cities_world\n WHERE country='usa'","upvote_count":"4","poster":"Eleftheriia"},{"timestamp":"1730363460.0","content":"Selected Answer: A\nshould be A or C but C will failed if cities_usa contains more than 2 columns so specify the list of column want to insert is the good one.","poster":"truongnguyen86","upvote_count":"1","comment_id":"1305334"},{"upvote_count":"1","poster":"Parandhaman_Margan","timestamp":"1730002260.0","comment_id":"1303478","content":"Answer:D"}],"question_text":"A data engineer needs to create an Amazon Athena table based on a subset of data from an existing Athena table named cities_world. The cities_world table contains cities that are located around the world. The data engineer must create a new table named cities_us to contain only the cities from cities_world that are located in the US.\n\nWhich SQL statement should the data engineer use to meet this requirement?","topic":"1","answer_images":[],"question_images":[],"answers_community":["A (100%)"],"choices":{"D":"UPDATE cities_usa SET (city, state) = (SELECT city, state FROM cities_world WHERE country=’usa’);","C":"INSERT INTO cities_usa SELECT city, state FROM cities_world WHERE country=’usa’;","B":"MOVE city, state FROM cities_world TO cities_usa WHERE country=’usa’;","A":"INSERT INTO cities_usa (city,state) SELECT city, state FROM cities_world WHERE country=’usa’;"},"answer":"A"},{"id":"PvaK00CG9s2z5cr8ApIg","question_images":[],"question_id":65,"isMC":true,"discussion":[{"content":"Selected Answer: D\nI think that D is one of the correct answers as described\n\nhttps://aws.amazon.com/blogs/big-data/centrally-manage-access-and-permissions-for-amazon-redshift-data-sharing-with-aws-lake-formation/","comment_id":"1307023","poster":"Eleftheriia","upvote_count":"3","timestamp":"1730739120.0"},{"timestamp":"1730190480.0","content":"i think not A because they say access and permissions are centrally managed in Lake Formation ... therefore : BD","poster":"ae35a02","upvote_count":"2","comment_id":"1304346"},{"content":"Selected Answer: BD\nworkgroups don't manage permission to tables and views, they manage resource allocation for queries execution.","timestamp":"1730121480.0","comment_id":"1303971","poster":"ae35a02","upvote_count":"4"},{"upvote_count":"2","content":"Answer:AD","poster":"Parandhaman_Margan","comment_id":"1303480","timestamp":"1730002620.0"}],"answer_images":[],"answer":"BD","question_text":"A company implements a data mesh that has a central governance account. The company needs to catalog all data in the governance account. The governance account uses AWS Lake Formation to centrally share data and grant access permissions.\n\nThe company has created a new data product that includes a group of Amazon Redshift Serverless tables. A data engineer needs to share the data product with a marketing team. The marketing team must have access to only a subset of columns. The data engineer needs to share the same data product with a compliance team. The compliance team must have access to a different subset of columns than the marketing team needs access to.\n\nWhich combination of steps should the data engineer take to meet these requirements? (Choose two.)","exam_id":21,"answer_ET":"BD","url":"https://www.examtopics.com/discussions/amazon/view/150341-exam-aws-certified-data-engineer-associate-dea-c01-topic-1/","timestamp":"2024-10-27 05:17:00","answer_description":"","topic":"1","choices":{"C":"Create an Amazon Redshift managed VPC endpoint in the marketing team’s account. Grant the marketing team access to the views.","B":"Create an Amazon Redshift data share that includes the tables that need to be shared.","A":"Create views of the tables that need to be shared. Include only the required columns.","E":"Share the Amazon Redshift data share to the Amazon Redshift Serverless workgroup in the marketing team's account.","D":"Share the Amazon Redshift data share to the Lake Formation catalog in the governance account."},"unix_timestamp":1730002620,"answers_community":["BD (57%)","D (43%)"]}],"exam":{"name":"AWS Certified Data Engineer - Associate DEA-C01","provider":"Amazon","id":21,"numberOfQuestions":207,"isMCOnly":true,"lastUpdated":"11 Apr 2025","isBeta":false,"isImplemented":true},"currentPage":13},"__N_SSP":true}