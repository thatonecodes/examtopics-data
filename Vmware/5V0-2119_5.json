{"pageProps":{"questions":[{"id":"5Rf724viS5FKbJN4W4O4","topic":"1","unix_timestamp":1587561000,"exam_id":260,"answer_images":[],"timestamp":"2020-04-22 15:10:00","url":"https://www.examtopics.com/discussions/vmware/view/18922-exam-5v0-2119-topic-1-question-27-discussion/","question_text":"You are designing a vSAN stretched cluster solution.\nWhat is the maximum number of nodes possible for this solution?","question_id":21,"answer":"A","isMC":true,"question_images":[],"answer_ET":"A","choices":{"C":"32 per data site + 1 witness host","D":"64 per data site + 1 witness host","A":"15 per data site + 1 witness host","B":"30 per data site + 1 witness host"},"answer_description":"","discussion":[{"content":"Correct answer is A, in a streched cluster: https://storagehub.vmware.com/t/vmware-vsan-6-7-technical-overview/stretched-clusters-30/","poster":"scotland81","comment_id":"77918","upvote_count":"16","timestamp":"1587561000.0"},{"poster":"Lazylinux","comment_id":"510163","timestamp":"1640595240.0","upvote_count":"2","content":"A for sure and as of vSAN 7 it is 20+20+1 = 41"},{"timestamp":"1609435800.0","upvote_count":"3","poster":"diegof1","content":"A is correct.\n\nStretched clusters consist of two active data sites and one witness site. Each site is its own fault domain supporting a fault tolerance of 1 across the active data sites.\nA stretched cluster can have up to 15 hosts at each site and must be in communication with a witness host, which brings the host maximum to 15 + 15 + 1 witness.\nEach site should contain the same number of hosts.\n\nTaken from vSAN 6.7 Deploy and Manage Lecture Manual","comment_id":"256368"},{"poster":"Lance_D","upvote_count":"2","timestamp":"1605100320.0","content":"Additional link supporting A: 15+15+1 as the correct option/answer","comment_id":"217264"},{"content":"Answer is A is correct. Please see the link & note below:\nhttps://download3.vmware.com/vcat/vmw-vcloud-architecture-toolkit-spv1-webworks/index.html#page/Storage%20and%20Availability/Architecting%20VMware%20vSAN%206.2/Architecting%20Virtual%20SAN%206.2.2.101.html\n\nNote:\nWith vSAN 6.2, stretched clusters have been enhanced to simplify the creation of the configuration. A new graphical configuration wizard assists with the configuration as appropriate. vSAN stretched clustering is a specific configuration implemented in environments where disaster/downtime avoidance is a key requirement. However, the maximum number of hosts in a stretch cluster configuration remains at 31, where Site 1 contains 15 hosts, Site 2 contains 15 hosts, and site 3 contains the witness host or virtual appliances","timestamp":"1605099960.0","upvote_count":"1","poster":"Lance_D","comment_id":"217261"},{"content":"i belive 30 hosts\nhttps://storagehub.vmware.com/t/vmware-vsan-6-7-technical-overview/stretched-clusters-30/","comments":[{"timestamp":"1598609040.0","upvote_count":"1","content":"mistake\nA maximum of thirty (30) hosts may be used in a single vSAN Stretched Cluster across the data sites. In vSAN versions up to 6.5, this was fifteen (15) per site. With the introduction of Site Affinity rules that places data on only one data site or the other, it is possible to have a vSAN Stretched Cluster deployment that does not have an equal number of hosts per site.","poster":"sugisho","comment_id":"168310"}],"timestamp":"1598608920.0","upvote_count":"1","comment_id":"168309","poster":"sugisho"},{"poster":"alsmk2","upvote_count":"1","timestamp":"1597917960.0","comments":[{"timestamp":"1599162420.0","comment_id":"172900","poster":"alsmk2","content":"A is the correct answer actually - misread the question 15 nodes per data site + 1. Two data sites = 30+1","upvote_count":"1"}],"content":"B\n\nHave done a couple of 30+1 stretched deployments - 15 hosts per site as others have already stated.\n\nQuestion doesn't state specifically the maximum nodes for 1 site, so for the entire solution, B is correct.","comment_id":"162144"},{"upvote_count":"1","timestamp":"1596614280.0","poster":"MIP","content":"A\nIn vSAN Stretched Cluster maximum number of data hosts on each site is 15. \nLimit: 30 (15 on each site x 2)\nhttps://configmax.vmware.com/guest?vmwareproduct=vSphere&release=vSphere%206.7&categories=7-0","comment_id":"150988"},{"content":"A, 15 per site + 1 witness","comment_id":"145749","poster":"oklanmayor","timestamp":"1595939220.0","upvote_count":"2"},{"poster":"avilis","comment_id":"123554","upvote_count":"1","timestamp":"1593526260.0","content":"B. 30 it is."},{"comments":[{"timestamp":"1592462940.0","poster":"Kywik","content":"Oups ! It's 30 hosts across all data sites. So correct answer is A (15 nodes per data site).","comment_id":"112974","upvote_count":"2"}],"upvote_count":"1","comment_id":"112971","poster":"Kywik","content":"Correct answer is B.\nA maximum of thirty (30) hosts may be used in a single vSAN Stretched Cluster across the data sites.","timestamp":"1592462400.0"}],"answers_community":[]},{"id":"9KsFWLwymnH3cVfGnL72","answer_ET":"CD","answers_community":["CD (100%)"],"answer_description":"Reference:\nhttps://blogs.vmware.com/virtualblocks/2018/05/24/vsan-deployment-considerations/","answer_images":[],"discussion":[{"comment_id":"568834","content":"C is fine but certainly not D, as all the objects are fully protected with the policy either accessibility or data migrate, the only reason is to rebuild the objects after failure.","upvote_count":"1","timestamp":"1647415380.0","poster":"xurooj"},{"poster":"Jonesythegreat","upvote_count":"1","comment_id":"521788","timestamp":"1641938340.0","content":"This should be A and D. You are not increasing your storage policy options by doing N+1, but you are increasing your availability to recover with failures."},{"upvote_count":"2","poster":"Lundu1995","comment_id":"521596","timestamp":"1641913200.0","content":"mhn i'm not really 100% sure if its c&d . it could be a & d as well cause more nodes = more votes on the object and if you have more votes on an object the object is accessible if there is a failure"},{"comment_id":"513809","poster":"Lazylinux","content":"Selected Answer: CD\nis correct","timestamp":"1640914620.0","upvote_count":"1"},{"timestamp":"1640595600.0","content":"C and D for sure","comment_id":"510166","poster":"Lazylinux","upvote_count":"1"},{"upvote_count":"1","poster":"AllenHuang","comment_id":"332977","timestamp":"1618116960.0","content":"Agree,C&D"},{"upvote_count":"2","content":"C & D are the correct answers","comment_id":"256369","timestamp":"1609435920.0","poster":"diegof1"},{"content":"I agree with the answers","upvote_count":"1","comment_id":"204604","poster":"atechnicznik","timestamp":"1603449240.0"}],"topic":"1","question_id":22,"isMC":true,"exam_id":260,"choices":{"A":"To ensure object accessibility","E":"To support data at rest encryption on vSAN hybrid clusters","B":"To support the use of RAID-6","D":"To provide full protection during maintenance mode operations","C":"To provide more flexible storage policy options"},"timestamp":"2020-10-23 12:34:00","question_images":[],"url":"https://www.examtopics.com/discussions/vmware/view/35052-exam-5v0-2119-topic-1-question-28-discussion/","answer":"CD","unix_timestamp":1603449240,"question_text":"What are two recommended reasons for configuring a cluster with at least one node in addition to the minimum required number? (Choose two.)"},{"id":"9iSF3hM6ZqbPYRmuHPRx","topic":"1","question_text":"vCenter reports a number of vSAN network alarms on a 2-node vSAN Direct Connect cluster. The test pings show irregularities in the ping results.\nUsing vSAN Health service, which two checks should be used to identify the network root cause? (Choose two.)","answer":"BE","isMC":true,"question_images":[],"answers_community":["BE (100%)"],"exam_id":260,"answer_ET":"AB","discussion":[{"upvote_count":"7","content":"i think B & E is the correct answer","poster":"Mzoear","comment_id":"91340","timestamp":"1589808420.0"},{"poster":"Lazylinux","comment_id":"510169","content":"Selected Answer: BE\nAre correct","timestamp":"1640595660.0","upvote_count":"1"},{"timestamp":"1609436460.0","content":"B & E are the correct answer.","upvote_count":"2","poster":"diegof1","comment_id":"256374"},{"timestamp":"1598440440.0","poster":"wtkc","content":"E is only pinging. So we can not detect root cause.\nProbably A and B are correct.\nif physical disk is dying, maybe ping is irregular. So I choose A.\n\n The other network health check results should be examined to narrow down the root cause of the misconfiguration.\nhttps://storagehub.vmware.com/t/vmware-r-vsan-tm-network-design/vmotion-basic-unicast-connectivity-check/","comment_id":"166658","upvote_count":"1","comments":[{"content":"A physical disk dying would be storage, not network. B & E are correct.","comment_id":"172902","poster":"alsmk2","upvote_count":"1","timestamp":"1599162660.0"}]},{"comment_id":"108516","poster":"LCOJ","content":"I agree with B & E are correct.","timestamp":"1591951320.0","upvote_count":"4"},{"content":"B & E are correct.","upvote_count":"3","comment_id":"104727","timestamp":"1591551180.0","poster":"Ady_14"}],"timestamp":"2020-05-18 15:27:00","answer_description":"Reference:\nhttps://vsan-essentials.gitbooks.io/vsan-6-2/content/chapter10.html","url":"https://www.examtopics.com/discussions/vmware/view/20864-exam-5v0-2119-topic-1-question-29-discussion/","unix_timestamp":1589808420,"question_id":23,"choices":{"B":"Network latency","C":"vSAN extended configuration","D":"vSAN disk balance","A":"Physical disk operation health","E":"vSAN basic unicast connectivity"},"answer_images":[]},{"id":"qk2Xkb6rFFZPMV8YbSWt","answer_description":"","question_images":[],"question_text":"A single disk in a vSAN disk group suffers from an unrecoverable hardware failure. This causes vSAN to set the health status for all disks in the group to\nPermanent disk loss, indicating disk failure.\nAssuming all other disks have not suffered from a hardware failure, why would vSAN mark all disks in the group as failed?","answers_community":["D (100%)"],"topic":"1","exam_id":260,"url":"https://www.examtopics.com/discussions/vmware/view/19100-exam-5v0-2119-topic-1-question-3-discussion/","choices":{"D":"Deduplication and compression are enabled on the vSAN cluster.","C":"The key management server is offline.","A":"The vSAN disk management service has failed.","B":"The affected vSphere host is offline."},"question_id":24,"answer":"D","discussion":[{"content":"D is the right answer\nhttps://kb.vmware.com/s/article/2149067","poster":"adelbelkis2","comment_id":"79751","upvote_count":"8","timestamp":"1587883560.0"},{"timestamp":"1591162620.0","poster":"DenZn","upvote_count":"6","comment_id":"101433","content":"Agree D is correct - Information from vSAN Deploy and Manage eBook: If an unhealthy disk belongs to a deduplication-enabled diskgroup, the whole diskgroup is marked as unhealthy."},{"poster":"YoussefELL","comment_id":"942510","content":"Selected Answer: D\nWhen deduplication and compression is enabled, if a capacity disk fails, the entire disk group becomes unavailable.","timestamp":"1688459040.0","upvote_count":"1"},{"poster":"Lazylinux","timestamp":"1640590500.0","content":"Selected Answer: D\nD is correct","upvote_count":"1","comment_id":"510096"},{"content":"Selected Answer: D\nVMware Documentation","comment_id":"489853","timestamp":"1638187740.0","poster":"ZakirK","upvote_count":"1"},{"content":"D is the correct answer.\n\nUnhealthy disks or diskgroups are marked as such, and at this point, the disks or diskgroups are no longer used for new data placement. If an unhealthy disk belongs to a deduplication-enabled diskgroup, the whole diskgroup is marked as unhealthy.\n\nTaken from vSAN 6.7 Deploy and Manage Lecture Manual - Unhealthy Devices and Data Evacuation section","poster":"diegof1","timestamp":"1609637700.0","upvote_count":"3","comment_id":"258089"},{"comment_id":"141743","timestamp":"1595486460.0","poster":"jasonv","content":"D is correct, it's one of the cavehats of dedup & compression, only on disk can fail wht whole diskgroup","upvote_count":"3"},{"poster":"apiedra","content":"D is right, when you have dedup enabled and any disk failed, the entire diskgroup will go down","timestamp":"1590088920.0","upvote_count":"5","comment_id":"93571"},{"comment_id":"91323","content":"D is right","timestamp":"1589807640.0","poster":"Mzoear","upvote_count":"2"}],"unix_timestamp":1587883560,"isMC":true,"answer_images":[],"answer_ET":"D","timestamp":"2020-04-26 08:46:00"},{"id":"qPep6svZw4WNfXBj0BgD","answer":"A","isMC":true,"answer_description":"Reference:\nhttps://vsan-essentials.gitbooks.io/vsan-6-2/content/chapter4.html","url":"https://www.examtopics.com/discussions/vmware/view/18867-exam-5v0-2119-topic-1-question-30-discussion/","answers_community":["A (100%)"],"answer_images":[],"question_images":[],"unix_timestamp":1587475620,"discussion":[{"content":"I think the correct answer is A: \"multiple disk groups\". https://blogs.vmware.com/virtualblocks/2019/04/18/vsan-disk-groups/","poster":"Darius_Th3D0G","timestamp":"1587475620.0","upvote_count":"7","comment_id":"77473"},{"comment_id":"512067","content":"Selected Answer: A\nis correct","timestamp":"1640774820.0","upvote_count":"1","poster":"Lazylinux"},{"content":"A for sure","comment_id":"510170","poster":"Lazylinux","timestamp":"1640595720.0","upvote_count":"1"},{"poster":"diegof1","timestamp":"1609436760.0","comment_id":"256377","upvote_count":"2","content":"A is the correct answer.\nBreaking up the disk groups has the following advantages:\n• Redundancy: In example one, a single disk groups can result in a host failure.\n• Flexibility: Scale up or scale out are both viable options.\n• Performance: More cache devices means more I/O paths.\n\nTaken from vSAN 6.7 Deploy and Manage Lecture Manual - Design: One or Multiple Disk Groups Per Host Section"},{"upvote_count":"2","poster":"wtkc","comments":[{"poster":"alsmk2","timestamp":"1599162720.0","content":"Adding multiple disk groups = more IO paths = more performance. A is correct.","upvote_count":"3","comment_id":"172903"}],"comment_id":"166671","content":"In all flash mode, there is no read cache and directly read to capacity disks.\nSo, Adding or Spliting cache don't improve read performance.\nI choose B.","timestamp":"1598441400.0"},{"poster":"LCOJ","comment_id":"108518","content":"A agree thay A is the correct answer","timestamp":"1591951500.0","upvote_count":"4"},{"timestamp":"1591551300.0","comment_id":"104728","upvote_count":"3","poster":"Ady_14","content":"A is correct."}],"topic":"1","question_id":25,"choices":{"A":"Multiple disk groups","C":"Large cache disks","D":"Large controller cache","B":"Large capacity disks"},"exam_id":260,"timestamp":"2020-04-21 15:27:00","answer_ET":"B","question_text":"A vSAN administrator is designing a new all-flash vSAN cluster. The cluster will host read intensive applications.\nWhich factor should be included in the design to improve read performance?"}],"exam":{"numberOfQuestions":100,"id":260,"isMCOnly":true,"lastUpdated":"12 Apr 2025","isBeta":false,"name":"5V0-21.19","isImplemented":true,"provider":"Vmware"},"currentPage":5},"__N_SSP":true}