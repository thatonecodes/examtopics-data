{"pageProps":{"questions":[{"id":"1ZjFRTSdRxHzb0JdGPDv","isMC":true,"question_text":"You converted an auto mode VPC network to custom mode. Since the conversion, some of your Cloud Deployment Manager templates are no longer working.\nYou want to resolve the problem.\nWhat should you do?","choices":{"A":"Apply an additional IAM role to the Google API's service account to allow custom mode networks.","D":"Explicitly reference the custom mode networks in the Deployment Manager templates.","C":"Explicitly reference the custom mode networks in the Cloud Armor whitelist.","B":"Update the VPC firewall to allow the Cloud Deployment Manager to access the custom mode networks."},"unix_timestamp":1604286540,"url":"https://www.examtopics.com/discussions/google/view/35718-exam-professional-cloud-network-engineer-topic-1-question-29/","topic":"1","answer_images":[],"discussion":[{"poster":"[Removed]","content":"Ans - D","upvote_count":"13","timestamp":"1653042120.0","comment_id":"223569"},{"poster":"ThisisJohn","timestamp":"1682775120.0","upvote_count":"8","content":"My vote goes to D as well.\n\n\"After you convert an auto mode network to custom mode, you must review all API calls and gcloud commands that implicitly reference any subnet that was automatically created while the network was in auto mode. API calls and commands will need to be modified so that they reference the subnet explicitly.\" https://cloud.google.com/vpc/docs/using-vpc#switch-network-mode","comments":[{"upvote_count":"1","poster":"AzureDP900","content":"agreed","timestamp":"1716938700.0","comment_id":"729821"}],"comment_id":"469784"},{"content":"Selected Answer: D\nThe correct option is D. Because when you convert a VPC network from auto mode to custom mode, the subnets are no longer automatically created for each region. Cloud Deployment Manager templates may still reference the auto-mode network and expect those subnets to exist.\n\nTo resolve this, you need to explicitly reference the custom mode networks and the specific subnets in your Deployment Manager templates, as custom mode requires manually defined subnets for each region. This will ensure that the templates are targeting the correct networks and subnets after the conversion.","comment_id":"1355105","poster":"saraali","timestamp":"1739301420.0","upvote_count":"1"},{"content":"D: \"After you convert an auto mode network to custom mode, you must review all API calls and gcloud commands that implicitly ***** reference any subnet that was automatically created while the network was in auto mode. API calls and commands will need to be modified so that they reference the subnet explicitly. For gcloud CLI commands that have a subnet specification flag (--subnet), that flag is required to reference subnets in a custom mode VPC network.\"","upvote_count":"2","timestamp":"1720959480.0","poster":"pk349","comment_id":"775493"},{"timestamp":"1708429260.0","content":"Selected Answer: D\nCorrect Answer is D","comment_id":"649362","upvote_count":"3","poster":"GCP72"},{"content":"Answer is : D","upvote_count":"5","timestamp":"1688464320.0","comment_id":"516544","poster":"kumarp6"},{"content":"Correct Answer is (D): \n\nAll yaml files used by Deployment Manager as template used to resources provisioning, must be updated manually.","poster":"ESP_SAP","upvote_count":"5","comment_id":"210941","timestamp":"1651453740.0"}],"answer":"D","question_images":[],"answer_ET":"D","exam_id":8,"answers_community":["D (100%)"],"question_id":151,"timestamp":"2020-11-02 04:09:00","answer_description":""},{"id":"vwTLhc1e0AB8RUgSQsVm","answer":"C","choices":{"A":"Create a Shared VPC Host Project and the respective Service Projects for each of the 3 separate departments.","C":"Create 3 separate VPCs, and use VPC peering to establish connectivity between the two appropriate VPCs.","D":"Create a single project, and deploy specific firewall rules. Use network tags to isolate access between the departments.","B":"Create 3 separate VPCs, and use Cloud VPN to establish connectivity between the two appropriate VPCs."},"exam_id":8,"answers_community":["C (100%)"],"question_id":152,"question_images":[],"answer_description":"","answer_images":[],"discussion":[{"timestamp":"1590932820.0","content":"Definitely C.","poster":"Shaun_Wang","comment_id":"99329","upvote_count":"19"},{"content":"Best answer is C C. \nA. Not correct. Shared VPC work to connect resources from different project. Since requirements. state \"single project for 3 separate departments\", shared VPC would not work here. \nB. Not correct since Cloud VPN is used to connect peer networks traffic over Internet.\nC. Correct. \nD. Possible but it would incur in operational overhead if we compare with C.","comments":[{"content":"C is right answer","upvote_count":"1","poster":"AzureDP900","timestamp":"1669681980.0","comment_id":"729743"}],"poster":"B3nd3cida","upvote_count":"16","timestamp":"1638134700.0","comment_id":"489427"},{"content":"C: Shared VPC allows an organization to connect resources from multiple projects to a common VPC network to communicate with each other securely and efficiently using internal IPs from that network. It requires designating a project as a host project and attach one or more other service projects to it.\nVPC Network Peering is useful in these environments:\n• SaaS (Software-as-a-Service) ecosystems in Google Cloud. You can make services available privately across different VPC networks within and across organizations.\n• Organizations that have several network administrative domains that need to communicate using internal IP addresses.\nIf you have multiple network administrative domains within your organization, VPC Network Peering allows you to make services available across VPC networks by using internal IP addresses.","upvote_count":"1","timestamp":"1727407560.0","poster":"pk349","comment_id":"773566"},{"upvote_count":"1","comment_id":"1093437","poster":"xhilmi","timestamp":"1727407560.0","content":"Selected Answer: C\nChoose C\n\nC. Create 3 separate VPCs, and use VPC peering to establish connectivity between the two appropriate VPCs.\n\nVPC peering allows you to establish direct connectivity between separate VPCs, and it seems suitable for creating separate network administrative domains while enabling connectivity between the two departments that require it. Each department would have its own VPC, and VPC peering would be used selectively to allow communication between the relevant VPCs."},{"upvote_count":"1","timestamp":"1712551740.0","content":"Answer is 'C'","poster":"dishum","comment_id":"1191372"},{"poster":"vyomkeshbakshi","timestamp":"1711456620.0","content":"Selected Answer: C\nOption C as in question it is clearly asked about single project.","comment_id":"1183310","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nC definitely makes most sense given the requirements. Peering the 2 networks that need to talk is the most suitable solution. A pluralsight course gave a similar example to this scenario so I'd definitely stick with C","timestamp":"1690664100.0","comment_id":"966642","poster":"oalsa"},{"upvote_count":"1","timestamp":"1678209840.0","poster":"Ben756","content":"Selected Answer: C\nC is correct","comment_id":"832147"},{"timestamp":"1660711200.0","poster":"GCP72","content":"Selected Answer: C\n\"C\" is the correct answer","upvote_count":"2","comment_id":"647899"},{"poster":"binglu","upvote_count":"2","content":"Selected Answer: C\nAnswer is C","comment_id":"627645","timestamp":"1657067640.0"},{"upvote_count":"3","timestamp":"1641290160.0","comment_id":"516428","poster":"kumarp6","content":"Answer is C"},{"upvote_count":"3","poster":"yas_cloud","comment_id":"494411","timestamp":"1638714000.0","content":"It would be C. D is also correct in terms of what mainly you want to achieve, but i believe it also incurs additional operational overhead."},{"timestamp":"1638275220.0","upvote_count":"4","poster":"lorca","content":"Selected Answer: C\nDefinitely C.","comment_id":"490662"},{"content":"C is correct.","comment_id":"481284","timestamp":"1637287980.0","poster":"Arad","upvote_count":"3"},{"poster":"ThisisJohn","comment_id":"464176","content":"I would say A, as it is written, does not guarantee isolation between for the third department, just simplifies operation through shared VPC. For me, the one which guarantees isolation is C","upvote_count":"2","timestamp":"1634568000.0"},{"upvote_count":"1","timestamp":"1622504400.0","content":"Answer Should be A. \nBecause its single Project with 3 Department. When you create 3 VPC it will be consider as 3 Projects. So C is the Wrong answer. With Shared VPC and IAM controls, you can separate network administration from project administration.","comments":[{"poster":"clooudy","content":"wrong, creating 3 VPCs won't be considered as creating 3 projects","comment_id":"483722","timestamp":"1637536080.0","upvote_count":"5"}],"poster":"Vishaan","comment_id":"371432"},{"poster":"un","comment_id":"366566","content":"C is correct","timestamp":"1621960020.0","upvote_count":"1"},{"comment_id":"338613","poster":"EJJ","content":"Keyphrase/s:\n1. separate network administrative domains (can be achieved with seperate VPCs)\n2. reduce operational overhead (can be achieved using shared VPC)\nIn order to fulfill the requirements: 2 VPCs connected to each other, 1 isolated VPC, and keyphrase no.1, the ANSWER is C. Keyphrase no.2 is just diversion.","timestamp":"1618807980.0","upvote_count":"3"},{"upvote_count":"1","comment_id":"318341","content":"C is the one","poster":"Vidyasagar","timestamp":"1616522400.0"},{"content":"The correct ans is \"C\". Shared VPC doesn't work with single project","comment_id":"289644","poster":"voyager","timestamp":"1613235360.0","upvote_count":"2"},{"poster":"voyager","comment_id":"289641","upvote_count":"1","content":"YES C.","timestamp":"1613235060.0"},{"comment_id":"270881","upvote_count":"1","content":"C reason being seperate n/w domains.\nhttps://cloud.google.com/vpc/docs/vpc-peering","timestamp":"1611024360.0","poster":"narangikhatmal"},{"timestamp":"1609772760.0","content":"\"A\" is correct.\nThe organization IS deployING a single project. The organization HAS NOT deploy a single project so we can change the project structure.\nPeered VPC networks remain administratively separate. They take a lot of operational overhead.\nWe can implement a security best practice of least privilege for network administration and can operate less overhead using a Shared VPC network.","upvote_count":"1","comments":[{"comment_id":"272477","poster":"chetz12","timestamp":"1611197400.0","content":"The problem with option A is that it won't let you administer separate VPC/subnet as they are part of centralized VPC. \nC sounds the most reasonable if networks have to be managed in isolation","upvote_count":"1"}],"comment_id":"259464","poster":"ydanno"},{"timestamp":"1605552060.0","upvote_count":"2","poster":"norwayping","comment_id":"220538","content":"C is the right one"},{"timestamp":"1602396360.0","comment_id":"197463","upvote_count":"2","poster":"EM0","content":"yes It would be\nC"},{"content":"i think the keyword is single project with 3 departments, because in vpc shared project we have to assign one project as host and others as service project, so with such statement here i would also go with C, before i was also thinking about A option but here it says about only 1 project with 3 dept","timestamp":"1598431020.0","poster":"Capo","comment_id":"166556","upvote_count":"3"},{"timestamp":"1598070660.0","upvote_count":"2","content":"Answer should be C: Keyword is separate network administrative domains. Reduce operational overhead causes this question to be tricky!","comment_id":"163340","poster":"runtheworld"},{"upvote_count":"2","timestamp":"1593569820.0","comment_id":"123865","content":"I think C is correct","poster":"dxloader"}],"unix_timestamp":1590932820,"question_text":"Your organization is deploying a single project for 3 separate departments. Two of these departments require network connectivity between each other, but the third department should remain in isolation. Your design should create separate network administrative domains between these departments. You want to minimize operational overhead.\nHow should you design the topology?","url":"https://www.examtopics.com/discussions/google/view/21662-exam-professional-cloud-network-engineer-topic-1-question-3/","isMC":true,"topic":"1","timestamp":"2020-05-31 15:47:00","answer_ET":"C"},{"id":"y3d8nPLHsZd9jAkP6IoC","question_text":"You have recently been put in charge of managing identity and access management for your organization. You have several projects and want to use scripting and automation wherever possible. You want to grant the editor role to a project member.\nWhich two methods can you use to accomplish this? (Choose two.)","timestamp":"2020-11-02 04:18:00","answer_ET":"BD","choices":{"A":"GetIamPolicy() via REST API","E":"Enter an email address in the Add members field, and select the desired role from the drop-down menu in the GCP Console.","D":"gcloud projects add-iam-policy-binding Sprojectname --member user:Susername --role roles/editor","C":"gcloud pubsub add-iam-policy-binding Sprojectname --member user:Susername --role roles/editor","B":"setIamPolicy() via REST API"},"isMC":true,"unix_timestamp":1604287080,"url":"https://www.examtopics.com/discussions/google/view/35719-exam-professional-cloud-network-engineer-topic-1-question-30/","question_id":153,"discussion":[{"comment_id":"210943","comments":[{"timestamp":"1703252820.0","comment_id":"930453","content":"@dzhu is correct , question says should use scripting and automation, so obvious answer is BD","upvote_count":"3","poster":"Jason_Cloud_at"},{"timestamp":"1647624780.0","comment_id":"447173","poster":"dzhu","content":"E is not scripting and automation. So E is obviously wrong. The answer should be B and D","upvote_count":"12"},{"comment_id":"729822","upvote_count":"1","timestamp":"1685316360.0","poster":"AzureDP900","content":"Yes, D and E are correct"}],"upvote_count":"18","content":"Correct Answer are (D) & (E)\n\nGetIamPolicy and SetIamPolicy is only for service accounts. But question asks for a project members.\nHence, D and E are correct ans.\nD - https://cloud.google.com/iam/docs/granting-changing-revoking-access#granting-gcloud-manual\nE - https://cloud.google.com/iam/docs/granting-changing-revoking-access#access-control-via-console","timestamp":"1619918280.0","poster":"ESP_SAP"},{"comments":[{"comment_id":"1106052","timestamp":"1719402000.0","poster":"BenMS","content":"In answer D, \"project_name\" is the name of a parameter inserted by the programmer. The fact it's a confusing name does not affect its accuracy.\n\nI agree B is a correct answer.\n\nTherefore I think the correct answers are B & D.","upvote_count":"1"},{"comment_id":"989727","timestamp":"1708850040.0","content":"Agree with you. A, B will be correct hence D provide wrong parameter regarding Project Name","poster":"nqthien041292","upvote_count":"1"}],"upvote_count":"9","comment_id":"465759","content":"A) GetIamPolicy() would not do anything by itself but see (B)\nB) would require use of GetIamPolicy() as otherwise SetIamPolicy() override existing binding\nC) obviously wrong, question is not about pubsub\nD) the documentation indicate that project_id need to be used not project_name, would therefore return an error\nE) would work, despite being very vague, but is not automation.\n\nNow, the question ask for \"which 2 _methods_ can be used to achieve that\".\n\nBoth GetIamPolicy() and SetIamPolicy() are programatic _methods_ that if used together could achieve that.\n\nTherefore one could roll with A&B in the spirits of that very tricky question.","timestamp":"1650555600.0","poster":"EranSolstice"},{"content":"Selected Answer: BD\nThe correct options are BD.\nReason:\nB. setIamPolicy() via REST API:\nYou can use the setIamPolicy() method via the REST API to update the IAM policy of a project, granting roles programmatically. This allows automation and scripting, aligning with your goal of minimizing manual management.\n\nD. gcloud projects add-iam-policy-binding Sprojectname --member user:Susername --role roles/editor:\nThe gcloud command-line tool is a common method to manage IAM roles for projects. This command allows you to grant the roles/editor role to a user, making it suitable for automation and scripting within a project.","timestamp":"1739301900.0","comment_id":"1355107","poster":"saraali","upvote_count":"2"},{"timestamp":"1729989900.0","comment_id":"1202869","upvote_count":"2","content":"Selected Answer: BD\nBoth methods can be used to grant the editor role to a project member using scripting and automation.\nThe setIamPolicy() method via REST API can be used to set the IAM policy for a project. The IAM policy is a JSON document that specifies the roles and members that have access to the project. To grant the editor role to a project member, you can use the following JSON document:\n{\n \"bindings\": [\n {\n \"role\": \"roles/editor\",\n \"members\": [\n \"user:Susername\"\n ]\n }\n ]\n}\nThe gcloud projects add-iam-policy-binding command can be used to add a binding to the IAM policy for a project. A binding is a pair of a role and a member. To grant the editor role to a project member, you can use the following command:\ngcloud projects add-iam-policy-binding Sprojectname --member user:Susername --role roles/editor","poster":"thewalker","comments":[{"comment_id":"1202870","timestamp":"1729989900.0","content":"The other options are incorrect because:\nA. GetIamPolicy() via REST API This method can be used to get the IAM policy for a project, but it cannot be used to set the IAM policy.\nC. gcloud pubsub add-iam-policy-binding Sprojectname --member user:Susername --role roles/editor This command is used to add a binding to the IAM policy for a Pub/Sub topic or subscription, not a project.\nE. Enter an email address in the Add members field and select the desired role from the drop-down menu in the GCP Console. This method can be used to grant the editor role to a project member, but it is not a scripting or automation method.\nTherefore, the best options are to use the setIamPolicy() method via REST API or the gcloud projects add-iam-policy-binding command.","upvote_count":"1","poster":"thewalker"}]},{"poster":"vyomkeshbakshi","comment_id":"1174107","timestamp":"1726378440.0","content":"D and B.","upvote_count":"1"},{"upvote_count":"3","content":"Selected Answer: BD\nB) https://cloud.google.com/resource-manager/reference/rest/v1/projects/setIamPolicy\nD) https://cloud.google.com/sdk/gcloud/reference/projects/add-iam-policy-binding","poster":"rick2","timestamp":"1716314640.0","comment_id":"1076620"},{"timestamp":"1713737460.0","content":"Selected Answer: BD\nBD are correct. Scripting and Automation!","upvote_count":"2","poster":"PotatoGCP","comment_id":"1049921"},{"content":"Selected Answer: AB\nKeywords: scripting and automation + the word \"methods\"\nsearch for the word \"method\" in the below documentation and see where it's mentioned :)\n\nhttps://cloud.google.com/iam/docs/granting-changing-revoking-access#multiple-roles-programmatic","timestamp":"1702940940.0","comment_id":"926906","poster":"Mo7y","upvote_count":"2"},{"comment_id":"855514","content":"Selected Answer: DE\nOption D is correct because it uses the gcloud command-line tool to add an IAM policy binding to a project. This command adds a new IAM policy binding to a project, granting the specified user the editor role.\n\nOption E is correct because it describes the process of using the GCP Console to grant the editor role to a project member. This can be done by entering the member's email address in the Add members field and selecting the editor role from the drop-down menu.","poster":"Komal697","upvote_count":"2","comments":[{"content":"You should read the question well , It says use scripting and automation , E is a manual process so answer is BD","upvote_count":"1","timestamp":"1703252880.0","comment_id":"930456","poster":"Jason_Cloud_at"}],"timestamp":"1696064280.0"},{"content":"Selected Answer: BD\nB & D are correct.\nB. setIamPolicy() via REST API - This method updates the IAM policy for a resource, such as a project, and allows you to add or modify members and their roles.\nD. gcloud projects add-iam-policy-binding Sprojectname --member user:Susername --role roles/editor - This method uses the gcloud command-line tool to add an IAM policy binding for a specific project and member.\nOption A is not sufficient because getIamPolicy() only retrieves the current IAM policy for a resource, but does not allow for modifying it.\nOption C is not sufficient because it is a command for Pub/Sub, not for managing IAM policies for projects.\nOption E is not sufficient because it requires manual interaction with the GCP Console, and cannot be easily scripted or automated.","poster":"Ben756","upvote_count":"3","comment_id":"834202","timestamp":"1694271660.0"},{"poster":"Blitzer","comment_id":"820217","timestamp":"1692855540.0","upvote_count":"5","content":"Selected Answer: BD\nI think BD are the correct ones by elimination:\n\nA. GetIamPolicy() - read only method and BTW with a typo (should be getIAmPolicy but I guess that's not the intenional mistake)\nB. setIamPolicy() via REST API - does the job!\nC. gcloud pubsub add-iam-policy-binding Sprojectname --member user:Susername --role roles/editor - nothing to do because points to pubsub\nD. gcloud projects add-iam-policy-binding Sprojectname --member user:Susername --role roles/editor - does the job!\nE. Enter an email address in the Add members field, and select the desired role from the drop-down menu in the GCP Console. - no automation option"},{"poster":"Melampos","comment_id":"790039","content":"Selected Answer: BD\ntwo methods for set permissions","timestamp":"1690489380.0","upvote_count":"3"},{"content":"A. GetIamPolicy() via REST API\nB. setIamPolicy() via REST API","comment_id":"775496","upvote_count":"1","timestamp":"1689337140.0","poster":"pk349"},{"poster":"chelbsik","upvote_count":"1","timestamp":"1686383160.0","comment_id":"740816","content":"Selected Answer: AB\nI go for AB because of EranSolstice explanaition seems correct to me, see https://cloud.google.com/iam/docs/granting-changing-revoking-access#multiple-roles\nNo idea why people vote for E - this is not automation at all."},{"content":"Selected Answer: DE\nI think D&E is correct answer","poster":"GCP72","timestamp":"1676921040.0","comment_id":"649508","upvote_count":"3"},{"timestamp":"1651240140.0","content":"I'd vote A and B as @EranSolstice says, because of the following exceprt from here https://cloud.google.com/iam/docs/granting-changing-revoking-access#multiple-roles\n\nTo make large-scale access changes that involve granting and revoking MULTIPLE roles, use the read-modify-write pattern to update the resource's IAM policy:\n\n Reading the current policy by calling getIamPolicy().\n Editing the returned policy, either by using a text editor or programmatically, to add or remove any principals or role bindings.\n Writing the updated policy by calling setIamPolicy().","upvote_count":"4","comment_id":"469790","poster":"ThisisJohn"},{"upvote_count":"1","poster":"ThisisJohn","timestamp":"1651240080.0","content":"I'd vote A and B as @EranSolstice says, because of the following exceprt from here https://cloud.google.com/iam/docs/granting-changing-revoking-access#multiple-roles\n\nTo make large-scale access changes that involve granting and revoking MULTIPLE roles, use the read-modify-write pattern to update the resource's IAM policy:\n\n Reading the current policy by calling getIamPolicy().\n Editing the returned policy, either by using a text editor or programmatically, to add or remove any principals or role bindings.\n Writing the updated policy by calling setIamPolicy().","comment_id":"469788"},{"comment_id":"440862","upvote_count":"5","poster":"PeppaPig","timestamp":"1646657100.0","content":"B&D are correct."},{"poster":"JohnnyBG","content":"Tricky question, I would say B and D since automation is the prefered choice. But for B, see bellow .. probably better than manually as in E but it implies that you have all other IAM Setting and apply them all together ..\n\nCAUTION: This method will replace the existing policy, and cannot be used to append additional IAM settings.\n\nhttps://cloud.google.com/resource-manager/reference/rest/v1/projects/setIamPolicy","timestamp":"1641896400.0","upvote_count":"2","comment_id":"403777"},{"comments":[{"timestamp":"1640206680.0","content":"AB will be the answer","upvote_count":"1","comment_id":"388223","poster":"Fliu"},{"poster":"ExamTopicsFan","timestamp":"1648567380.0","comment_id":"454263","content":"gcloud projects add-iam-policy-binding example-project-id-1 --member='user:test-user@gmail.com' --role='roles/editor'","upvote_count":"1"}],"content":"D is incorrect:\nmembers[] \nstring\nuser:{emailid}: An email address that represents a specific Google account. For example, alice@example.com .\nhttps://cloud.google.com/iam/docs/reference/rest/v1/Policy#Binding","poster":"Fliu","timestamp":"1640206440.0","upvote_count":"1","comment_id":"388220"},{"timestamp":"1634980140.0","upvote_count":"4","content":"Ans is BD.. take note that the preferred way is thru automation using scripting","poster":"EJJ","comment_id":"341473"},{"content":"D and E","timestamp":"1632446580.0","upvote_count":"7","poster":"Vidyasagar","comment_id":"318727"},{"timestamp":"1621506360.0","content":"Ans - DE","comment_id":"223572","poster":"[Removed]","upvote_count":"7"}],"answers_community":["BD (71%)","DE (18%)","11%"],"question_images":[],"topic":"1","answer":"BD","exam_id":8,"answer_description":"","answer_images":[]},{"id":"M1FEv55EoXZGzWfcTB5j","choices":{"A":"Tune TCP parameters on the on-premises servers.","B":"Compress files using utilities like tar to reduce the size of data being sent.","C":"Remove the -m flag from the gsutil command to enable single-threaded transfers.","D":"Use the perfdiag parameter in your gsutil command to enable faster performance: gsutil perfdiag gs://[BUCKET NAME]."},"exam_id":8,"discussion":[{"timestamp":"1619918520.0","upvote_count":"11","comments":[{"comment_id":"729689","timestamp":"1685307360.0","upvote_count":"1","content":"yes, It is right\nA. Tune TCP parameters on the on-premises servers.","poster":"AzureDP900"}],"content":"Correct Answer is (A)\n\nAs the question states that the RTT is 100ms thus low transfer rate is due to the TCP window size that is too small. And the solution is to increase the window size .","comment_id":"210944","poster":"ESP_SAP"},{"comment_id":"1355109","content":"Selected Answer: A\nThe correct option is A. The issue of underutilizing the available 10-Gbps bandwidth is often related to TCP configuration. By tuning TCP parameters, such as TCP window size and congestion control algorithms, you can optimize the connection for high-bandwidth, high-latency environments like your 100-ms round-trip time (RTT) peering connection. This adjustment allows gsutil to take better advantage of the available bandwidth.","timestamp":"1739302380.0","poster":"saraali","upvote_count":"1"},{"timestamp":"1726378860.0","upvote_count":"1","poster":"vyomkeshbakshi","comment_id":"1174127","content":"Even if you are not aware of all the options, question is asked about what to do on the on prem servers. All other option includes cloud except A"},{"timestamp":"1689337320.0","upvote_count":"2","content":"A: The TCP window is the maximum number of bytes that can be sent before the ACK must be received. If either the sender or receiver are frequently forced to stop and wait for ACKs for previously sent packets, gaps in the data flow are created, which limits the maximum throughput of the connection.","comment_id":"775500","poster":"pk349"},{"comment_id":"649512","poster":"GCP72","upvote_count":"1","timestamp":"1676922480.0","content":"Selected Answer: A\nCorrect Answer is A"},{"poster":"Taliesyn","comment_id":"601493","timestamp":"1668421800.0","content":"I would roll with D, since gsutil kindly provides a tool to analyze performance issues.","comments":[{"upvote_count":"2","comment_id":"601494","poster":"Taliesyn","timestamp":"1668421860.0","content":"Ooopsie, read too fast, the answer states that gsutil perfdiag improves performance, which is wrong."}],"upvote_count":"1"},{"timestamp":"1659316380.0","content":"A \n\nLike most modern operating systems, Linux now does a good job of auto-tuning the TCP buffers. In some cases, the default maximum Linux TCP buffer sizes are still too small. When this is the case, you can observe an effect called the Bandwidth Delay Product.\nThe TCP window is the maximum number of bytes that can be sent before the ACK must be received. If either the sender or receiver are frequently forced to stop and wait for ACKs for previously sent packets, gaps in the data flow are created, which limits the maximum throughput of the connection.","comment_id":"537613","upvote_count":"4","poster":"Luvero"},{"upvote_count":"2","comment_id":"516549","content":"Answer is : A","timestamp":"1656928740.0","poster":"kumarp6"},{"comment_id":"318365","content":"A is correct","poster":"Vidyasagar","timestamp":"1632414300.0","upvote_count":"2"},{"content":"Correct Answer is (A) its the only logical solution as its truly the limiting factor here.","comment_id":"244647","poster":"Gharet","timestamp":"1623760440.0","upvote_count":"2"},{"content":"Ans - A","comment_id":"223575","poster":"[Removed]","upvote_count":"2","timestamp":"1621506540.0"}],"answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/google/view/35720-exam-professional-cloud-network-engineer-topic-1-question-31/","timestamp":"2020-11-02 04:22:00","answer_ET":"A","question_text":"You are using a 10-Gbps direct peering connection to Google together with the gsutil tool to upload files to Cloud Storage buckets from on-premises servers. The on-premises servers are 100 milliseconds away from the Google peering point. You notice that your uploads are not using the full 10-Gbps bandwidth available to you. You want to optimize the bandwidth utilization of the connection.\nWhat should you do on your on-premises servers?","question_id":154,"answer":"A","answer_images":[],"unix_timestamp":1604287320,"topic":"1","question_images":[],"answer_description":"","isMC":true},{"id":"kDh8ffb0neJJFDb08kX0","unix_timestamp":1604287680,"question_text":"You work for a multinational enterprise that is moving to GCP.\nThese are the cloud requirements:\n\"¢ An on-premises data center located in the United States in Oregon and New York with Dedicated Interconnects connected to Cloud regions us-west1 (primary\nHQ) and us-east4 (backup)\n\"¢ Multiple regional offices in Europe and APAC\n\"¢ Regional data processing is required in europe-west1 and australia-southeast1\n\"¢ Centralized Network Administration Team\nYour security and compliance team requires a virtual inline security appliance to perform L7 inspection for URL filtering. You want to deploy the appliance in us- west1.\nWhat should you do?","answer":"A","question_id":155,"url":"https://www.examtopics.com/discussions/google/view/35721-exam-professional-cloud-network-engineer-topic-1-question-32/","answers_community":["A (100%)"],"answer_images":[],"topic":"1","choices":{"A":"\"¢ Create 2 VPCs in a Shared VPC Host Project. \"¢ Configure a 2-NIC instance in zone us-west1-a in the Host Project. \"¢ Attach NIC0 in VPC #1 us-west1 subnet of the Host Project. \"¢ Attach NIC1 in VPC #2 us-west1 subnet of the Host Project. \"¢ Deploy the instance. \"¢ Configure the necessary routes and firewall rules to pass traffic through the instance.","D":"\"¢ Create 1 VPC in a Shared VPC Service Project. \"¢ Configure a 2-NIC instance in zone us-west1-a in the Service Project. \"¢ Attach NIC0 in us-west1 subnet of the Service Project. \"¢ Attach NIC1 in us-west1 subnet of the Service Project \"¢ Deploy the instance. \"¢ Configure the necessary routes and firewall rules to pass traffic through the instance.","C":"\"¢ Create 1 VPC in a Shared VPC Host Project. \"¢ Configure a 2-NIC instance in zone us-west1-a in the Host Project. \"¢ Attach NIC0 in us-west1 subnet of the Host Project. \"¢ Attach NIC1 in us-west1 subnet of the Host Project \"¢ Deploy the instance. \"¢ Configure the necessary routes and firewall rules to pass traffic through the instance.","B":"\"¢ Create 2 VPCs in a Shared VPC Host Project. \"¢ Configure a 2-NIC instance in zone us-west1-a in the Service Project. \"¢ Attach NIC0 in VPC #1 us-west1 subnet of the Host Project. \"¢ Attach NIC1 in VPC #2 us-west1 subnet of the Host Project. \"¢ Deploy the instance. \"¢ Configure the necessary routes and firewall rules to pass traffic through the instance."},"answer_ET":"A","exam_id":8,"timestamp":"2020-11-02 04:28:00","isMC":true,"answer_description":"","question_images":[],"discussion":[{"upvote_count":"33","comments":[{"comment_id":"729688","timestamp":"1685307300.0","upvote_count":"1","content":"Agreed","poster":"AzureDP900"},{"content":"Shared networks should be created in the host project, while shared instances should be created in the service project and connected to shared networks to communicated with other parties. Answer B is correct.","comment_id":"503308","upvote_count":"1","poster":"walkwolf3","timestamp":"1655426100.0"},{"comments":[{"content":"It's my understanding that network equipment should always be implemented in the Host project of a Shared VPC. The fact this scenario is installing a compute instance is not relevant, as the purpose of that instance is to manage the network.\n\nTherefore A is the right answer.","comment_id":"1106062","poster":"BenMS","upvote_count":"1","timestamp":"1719403320.0"}],"upvote_count":"6","poster":"seddy","timestamp":"1636658460.0","comment_id":"354905","content":"Yeah, but I believe the Centralized network Administration refers to 'Shared VPC' in general, not to creating the workload in the Host project. By creating a shared VPC, we are centralizing the networking aspect in the first place. Then, it's a best practice to separate the workload by creating the instance in the service project. \n\nSo, I believe the answer should be B!"},{"comments":[{"comment_id":"512457","upvote_count":"1","content":"Unless they refer to VPC as a subnet - which is dumb ;)","timestamp":"1656514500.0","poster":"desertlotus1211"}],"upvote_count":"1","content":"You're mistaken VPC and VPC Networks. \n'A project that participates in Shared VPC is either a host project or a service project:\nA host project contains one or more Shared VPC networks'...\n\nEach VPC Network has subnets.... The appliance NIC can attach to each subnet...\n\nThe answers are misleading as it says 'VPC' do they mean VPC Network OR literally another VPC - which in any event is another set of network subnets... \n\nThere is no need for TWO VPC Networks... therefore Answer is C.\n\nThoughts?","comment_id":"512455","poster":"desertlotus1211","timestamp":"1656514380.0"}],"poster":"ESP_SAP","comment_id":"210945","timestamp":"1619918880.0","content":"Correct Answer is (A):\n\n\n You cannot attach 2 NICs of same appliance to same VPC. The two NICs must be attached to different VPCs.\n\nIt cant be C or D because you need 2 VPCs.\n\nhttps://cloud.google.com/vpc/docs/create-use-multiple-interfaces\nEach interface is attached to a different VPC network, giving that instance access to different VPC networks in Google Cloud Platform (GCP). You cannot attach multiple network interfaces to the same VPC network.\n\nIt can't be B because you need to deploy the appliances in HOST Project to achieve CENTRALIZED NETWORK ADMINISTRATION"},{"comment_id":"1355113","poster":"saraali","upvote_count":"1","content":"Selected Answer: A\nThe correct option is A. Because Shared VPC Host Project is the best approach for centralized network management and security policies. Here, the security appliance requires two network interfaces (NICs) for inspecting and filtering traffic between different VPCs or subnets. In this setup, you can create a 2-NIC instance in us-west1 (your primary region) in the Host Project. Each NIC is attached to a different VPC subnet within the Host Project, allowing traffic to be inspected as it flows between different subnets or VPCs. Now you will configure routes and firewall rules to ensure traffic flows through the appliance for L7 inspection before proceeding to the destination.","timestamp":"1739303220.0"},{"comment_id":"905611","timestamp":"1700819220.0","content":"https://medium.com/google-cloud/google-cloud-shared-vpc-b33e0c9dd320 ....based on this answer is B , the VM to be configured in service project. The host project is used for routes and FW rules.","poster":"Hetavi","upvote_count":"1"},{"comment_id":"775502","upvote_count":"1","timestamp":"1689337380.0","poster":"pk349","content":"A. \"¢ Create 2 VPCs in a Shared VPC Host Project. \"¢ Configure a 2-NIC instance in zone us-west1-a in the Host Project. \"¢ Attach NIC0 in VPC #1 us-west1 subnet of the Host Project. \"¢ Attach NIC1 in VPC #2 us-west1 subnet of the Host Project. \"¢ Deploy the instance. \"¢ Configure the necessary routes and firewall rules to pass traffic through the instance."},{"comment_id":"681012","upvote_count":"2","poster":"desertlotus1211","content":"Answer is A:\nhttps://cloud.google.com/vpc/docs/multiple-interfaces-concepts#third-party","timestamp":"1679938740.0"},{"content":"Selected Answer: A\nCorrect Answer is A","comment_id":"649513","poster":"GCP72","timestamp":"1676922660.0","upvote_count":"1"},{"poster":"kapara","comment_id":"622457","timestamp":"1672054860.0","upvote_count":"1","content":"Selected Answer: A\nThis explains why A is the correct answer : https://cloud.google.com/architecture/best-practices-vpc-design#multi-nic"},{"comment_id":"561839","comments":[{"comment_id":"561843","timestamp":"1662443460.0","content":"And based on \" Centralized Network Administration\" , I support A.\nhttps://cloud.google.com/architecture/best-practices-vpc-design#single-host-project-multiple-service-projects-single-shared-vpc","poster":"[Removed]","upvote_count":"1"}],"poster":"[Removed]","content":"C & D is not right due to multi-nic into same VPC.","timestamp":"1662443340.0","upvote_count":"1"},{"timestamp":"1659318000.0","upvote_count":"1","comment_id":"537624","content":"A\n\nthe appliance will be deployed in Host project\nand to have 2 NICs you need 2 VPCs\n\nhere is an error if you deploy the appliance with both NICs on same VPC \n\n{\"ResourceType\":\"compute.v1.instance\",\"ResourceErrorCode\":\"INVALID_USAGE\",\"ResourceErrorMessage\":\"Networks must be distinct for NICs attached to a VM.\"}","poster":"Luvero"},{"content":"Answer is : A","comment_id":"516557","timestamp":"1656929580.0","poster":"kumarp6","upvote_count":"1"},{"poster":"matmuh","upvote_count":"2","content":"Answer is B. \n\nWhy not option A? Because installing all projects on the shared vpc host project does not comply with google's best practices.","timestamp":"1655085660.0","comment_id":"500366","comments":[{"timestamp":"1707319440.0","upvote_count":"1","comment_id":"974734","poster":"gcpengineer","content":"how the traffic will traverse with service proj?"}]},{"comment_id":"360452","poster":"densnoigaskogen","timestamp":"1637244300.0","comments":[{"content":"Reviewed the question again, my answer is wrong.\n A should be the answer. The reasons to create 2 VPCs in the shared VPC Host project can be:\n - meet the requirements of primary and backup redundancy for interconnect towards the Data centers in Oregon and New york. Each VPC should represent a On-prem Data Center.\n - each VM NIC needs to be attached to a VPC, as we can not attach multiple network interfaces of a VM to the same VPC network. \nB is not correct, because the L7 virutal application needs to be deployed in Host project to bridge between those 2 VPCs, so that it can inspects both traffic coming from interconnects (us-west1 and us-east4) and internet-based connections (Europe and APAC)\nAdditonal ref: https://cloud.google.com/architecture/best-practices-vpc-design#single-host-project-multiple-service-projects-single-shared-vpc","upvote_count":"3","poster":"densnoigaskogen","comment_id":"361230","timestamp":"1637322120.0"}],"content":"C should be the answer.\nIt's about using 3rd party appliances in a Shared VPC network scenario.\n\"Centralized Anetwork Administration Team\" indicates that we need to have contralised control for network resources( such as, subnets, routes, firewall rules), a single VPC in shared VPC Host project is the best choice of architecure.\nIn a shared VPC network, we can create a VM with mulitple network interfaces attaching to different subnets, which represent different networks.\nReference: https://cloud.google.com/vpc/docs/multiple-interfaces-concepts#third-party","upvote_count":"2"},{"timestamp":"1634839860.0","upvote_count":"1","comment_id":"340544","content":"So! will be A or B?","poster":"WakandaF"},{"comment_id":"318377","content":"B is correct","upvote_count":"4","poster":"Vidyasagar","timestamp":"1632414900.0"},{"content":"Ans - B","upvote_count":"1","poster":"[Removed]","comment_id":"223641","timestamp":"1621511940.0"},{"timestamp":"1620704460.0","content":"The correct answer should be B. \nIn the shared VPC scenario, Host Project is the deployment of the VPC network, and Service Project is the deployment of the instance.\n\nhttps://cloud.google.com/vpc/docs/shared-vpc","poster":"majun","comments":[{"poster":"ThisisJohn","content":"Definitely, as Hybrid_Cloud_boy says, you can deploy instances into a host project, as per the example below:\n\nStateful L7 firewall between VPC networks https://cloud.google.com/architecture/best-practices-vpc-design#l7","timestamp":"1652699880.0","upvote_count":"1","comment_id":"479388"},{"poster":"Hybrid_Cloud_boy","content":"You can absolutely deploy instances into a host project - This is incorrect. A is the right answer.","comment_id":"236641","upvote_count":"2","timestamp":"1622991060.0"}],"comment_id":"217097","upvote_count":"3"}]}],"exam":{"lastUpdated":"11 Apr 2025","isMCOnly":true,"isBeta":false,"numberOfQuestions":228,"provider":"Google","isImplemented":true,"name":"Professional Cloud Network Engineer","id":8},"currentPage":31},"__N_SSP":true}