{"pageProps":{"questions":[{"id":"aXEwaNalEZmyQK39rkLx","question_text":"Your organization deployed a new version of a critical application that uses Cloud SQL for MySQL with high availability (HA) and binary logging enabled to store transactional information. The latest release of the application had an error that caused massive data corruption in your Cloud SQL for MySQL database. You need to minimize data loss. What should you do?","answers_community":["C (89%)","11%"],"isMC":true,"answer_ET":"C","exam_id":5,"unix_timestamp":1671554760,"url":"https://www.examtopics.com/discussions/google/view/92205-exam-professional-cloud-database-engineer-topic-1-question/","answer":"C","discussion":[{"comment_id":"836516","timestamp":"1694459220.0","upvote_count":"7","poster":"dynamic_dba","content":"C.\nThe question specifically mentions binary logging and the binary logs are used by point-in-time recovery. D doesnâ€™t buy you anything since the corrupt data would also be on the HA replica you fail over to. B looks like a lot of work and if the Cloud SQL instance were instantiated a while ago, option B could take a long time. A would work but the backup could have been taken a while before the corruption began. In which case restoring using that backup would wipe all the good data up to the point of corruption. The question asks for minimal data loss and the only way to ensure that is to restore to a point-in-time just before the corruption began."},{"upvote_count":"1","timestamp":"1741827360.0","comment_id":"1388128","content":"Selected Answer: C\nPoint in time recovery helps us to go back exactly a minute before corruption. This will leave us with most of the data before the corruption","poster":"fff2e69"},{"poster":"PKookNN","upvote_count":"1","comment_id":"1126644","timestamp":"1721383740.0","content":"Selected Answer: C\nunrelated but this was also a question from PCA. and the same answer C"},{"content":"C. Perform a point-in-time recovery of your Cloud SQL for MySQL database, selecting a date and time before the data was corrupted.\n\nPerforming a point-in-time recovery is the best option to minimize data loss in case of data corruption. Point-in-time recovery restores the database to a specific point in time before the data was corrupted, by replaying the binary logs that were generated since the selected time. This option is available when binary logging is enabled on Cloud SQL for MySQL with high availability.\n\nOption A, restoring from an automated backup, can lead to data loss because it might not contain all the changes made to the database after the backup was taken. Option B, reloading the database from CSV files, can be time-consuming and may lead to data loss if the files used for initialization are not up to date. Option D, failing over to the Cloud SQL for MySQL HA instance, may not help in this scenario as the data corruption is replicated to the HA instance, and it is intended to be used for high availability and not for disaster recovery.","comment_id":"834545","poster":"Hilab","timestamp":"1694301660.0","upvote_count":"2"},{"comment_id":"812779","poster":"zanhsieh","timestamp":"1692339720.0","upvote_count":"1","content":"Selected Answer: A\nA. Originally I thought it was C, but after reading mysql best practices as well as Kloudgeek link carefully I changed my answer. In Cloud SQL best-practice:\nhttps://cloud.google.com/sql/docs/mysql/best-practices\n\"A point-in-time recovery always creates a new instance; you cannot perform a point-in-time recovery to an existing instance.\"\nKloudgeek's link (why gcloud command use clone?):\nhttps://cloud.google.com/sql/docs/mysql/backup-recovery/pitr#perform-pitr-binlog\n\"gcloud sql instances clone instance1 \\\ninstance1-clone \\\n--bin-log-file-name=mysql-bin.0000031 \\\n--bin-log-position=107\"\nIt seems to me that the question does not expect Cloud SQL instance switched just because of data corruption."},{"upvote_count":"1","poster":"pk349","timestamp":"1687698660.0","content":"C: Perform a point-in-time recovery of your Cloud SQL for MySQL database, selecting a date and time ***** before the data was corrupted.","comment_id":"755759"},{"timestamp":"1687588860.0","upvote_count":"1","poster":"GCP72","comment_id":"754772","content":"Selected Answer: C\nC is correct answer"},{"content":"Selected Answer: C\nBinary logging --> Point in Recovery","comment_id":"752448","timestamp":"1687352040.0","upvote_count":"3","poster":"range9005"},{"content":"Selected Answer: C\nSince it is retaining transaction log, point in time recovery is enabled and that would be the best option","comment_id":"751455","upvote_count":"2","timestamp":"1687286700.0","poster":"fredcaram"},{"poster":"Kloudgeek","timestamp":"1687272360.0","content":"Correct Answer C: Binary Logging enabled, with that you can identify the point of time the data was good and recover from that point time.\nhttps://cloud.google.com/sql/docs/mysql/backup-recovery/pitr#perform_the_point-in-time_recovery_using_binary_log_positions","comment_id":"751227","upvote_count":"3"}],"timestamp":"2022-12-20 17:46:00","answer_images":[],"question_images":[],"answer_description":"","choices":{"D":"Fail over to the Cloud SQL for MySQL HA instance. Use that instance to recover the transactions that occurred before the corruption.","B":"Reload the Cloud SQL for MySQL database using the LOAD DATA command to load data from CSV files that were used to initialize the instance.","C":"Perform a point-in-time recovery of your Cloud SQL for MySQL database, selecting a date and time before the data was corrupted.","A":"Open the Google Cloud Console, navigate to SQL > Backups, and select the last version of the automated backup before the corruption."},"question_id":51,"topic":"1"},{"id":"yo4mSUiUomAdamRwdMCq","question_id":52,"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/92356-exam-professional-cloud-database-engineer-topic-1-question/","answer":"CE","choices":{"C":"Ensure that all PostgreSQL tables have a primary key.","D":"Shut down the database before the Data Migration Service task is started.","E":"Ensure that pglogical is installed on the source PostgreSQL database.","B":"Disable all foreign key constraints on the source PostgreSQL database.","A":"Drop or disable all users except database administration users."},"question_images":[],"exam_id":5,"answer_images":[],"discussion":[{"poster":"dynamic_dba","timestamp":"1694460300.0","comment_id":"836534","upvote_count":"5","content":"C, E.\nA is wrong because you want user accounts migrated as well as the data. B is nonsense. D is also nonsense since the DMS is an online migration. That leave C and E, both of which are mentioned in the Google doc:\nhttps://cloud.google.com/database-migration/docs/postgres/configure-source-database"},{"comment_id":"1014105","comments":[{"timestamp":"1721327280.0","content":"so true!! I remember doing the challenge on my own for like 2 days to make certain I've got it all right; so the number of times I actually had to install pglogical and create primary keys on tables were ridiculous! :D","upvote_count":"3","poster":"RaphaelG","comment_id":"1126169"}],"timestamp":"1711119060.0","content":"You are sure to know the answer is CE if you did the labsðŸ˜‚","poster":"DeeData","upvote_count":"4"},{"comment_id":"861173","upvote_count":"3","poster":"Pilot50","timestamp":"1696429860.0","content":"Selected Answer: CE\nhttps://cloud.google.com/database-migration/docs/postgres/faq"},{"poster":"Hilab","comment_id":"834546","timestamp":"1694302380.0","content":"C. Ensure that all PostgreSQL tables have a primary key.\nE. Ensure that pglogical is installed on the source PostgreSQL database.\n\nWhen using Database Migration Service to migrate data from a PostgreSQL on-premises instance to Cloud SQL, it is important to ensure that all PostgreSQL tables have a primary key. This is because Cloud SQL requires tables to have a primary key to enable replication and ensure data consistency.\n\nIt is also important to ensure that pglogical is installed on the source PostgreSQL database. This is because pglogical is used by Database Migration Service to replicate data changes from the source database to the target Cloud SQL instance.\n\nOptions A and D are not prerequisites for creating and automating the task. Option B is not recommended as it can cause data inconsistencies during the migration. Disabling foreign key constraints may result in data being migrated with foreign key constraint violations.","upvote_count":"3"},{"timestamp":"1693900860.0","content":"Selected Answer: CE\nRun the CREATE EXTENSION IF NOT EXISTS pglogical command on every database on your source instance. This installs the pglogical extension into the database.\nFor tables that don't have primary keys, Database Migration Service supports migration of the initial snapshot and INSERT statements during the change data capture (CDC) phase. You should migrate UPDATE and DELETE statements manually.","poster":"Nirca","upvote_count":"1","comment_id":"829814"},{"upvote_count":"2","timestamp":"1688333940.0","comment_id":"764125","poster":"TFMV","content":"CE are correct."},{"upvote_count":"1","comments":[{"content":"Found this confirming C - was not option prior to 6/2022 - Tables without primary keys on the source PostgreSQL database are not migrated. For those tables, DMS migrated only the schema. This is no longer a limitation after the June 2022 product update.\n\nAdditional good content beyond scope of question in source link...https://cloud.google.com/blog/products/databases/reduce-downtime-for-postgresql-migration-to-google-cloud-sql","upvote_count":"2","comment_id":"762146","timestamp":"1688135700.0","poster":"sp57"}],"timestamp":"1688135280.0","content":"E for sure; presume C is required for \"automation\" of task, because intervention required for tables without primary key. \nFor tables that don't have primary keys, Database Migration Service supports migration of the initial snapshot and INSERT statements during the change data capture (CDC) phase. You should migrate UPDATE and DELETE statements manually.\n\nhttps://cloud.google.com/database-migration/docs/postgres/configure-source-database","comment_id":"762138","poster":"sp57"},{"timestamp":"1687794420.0","content":"Selected Answer: CE\nVote for CE","comment_id":"757705","poster":"chelbsik","upvote_count":"2"},{"content":"C: Ensure that all PostgreSQL ***** tables have a primary key.\n E: Ensure that pglogical ***** is installed on the source PostgreSQL database.","upvote_count":"1","timestamp":"1687698600.0","comment_id":"755758","poster":"pk349"},{"timestamp":"1687591380.0","upvote_count":"1","content":"Selected Answer: CE\nCE\nhttps://cloud.google.com/database-migration/docs/postgres/faq","comment_id":"754786","poster":"GCP72"},{"content":"Selected Answer: CE\nhttps://cloud.google.com/database-migration/docs/postgres/configure-source-database","poster":"h3clht","timestamp":"1687400100.0","upvote_count":"1","comment_id":"752957"},{"upvote_count":"1","timestamp":"1687400040.0","content":"CE\nhttps://cloud.google.com/database-migration/docs/postgres/configure-source-database","comment_id":"752956","poster":"h3clht"},{"content":"Selected Answer: BE\nRemove all the foreign key constraints\nCome up with necessary pglogical","poster":"range9005","timestamp":"1687352160.0","comment_id":"752452","upvote_count":"2"}],"answer_ET":"CE","unix_timestamp":1671634560,"question_text":"You plan to use Database Migration Service to migrate data from a PostgreSQL on-premises instance to Cloud SQL. You need to identify the prerequisites for creating and automating the task. What should you do? (Choose two.)","topic":"1","timestamp":"2022-12-21 15:56:00","answer_description":"","answers_community":["CE (80%)","BE (20%)"]},{"id":"xpDPy9XD0lIwd8BUBGau","exam_id":5,"answer_description":"","timestamp":"2022-12-20 17:54:00","question_images":[],"question_text":"You are using Compute Engine on Google Cloud and your data center to manage a set of MySQL databases in a hybrid configuration. You need to create replicas to scale reads and to offload part of the management operation. What should you do?","isMC":true,"answer_images":[],"unix_timestamp":1671555240,"topic":"1","answer":"A","question_id":53,"choices":{"B":"Use Data Migration Service.","A":"Use external server replication.","D":"Use the mysqldump utility and binary logs.","C":"Use Cloud SQL for MySQL external replica."},"url":"https://www.examtopics.com/discussions/google/view/92206-exam-professional-cloud-database-engineer-topic-1-question/","answer_ET":"A","discussion":[{"content":"C.\nD is nonsense, so can be eliminated. The question tells us weâ€™re already managing BOTH sets of MySQL instances, one on prem and the other in GCE. The question also says an objective is to offload part of the management. That can only mean leverage a managed service. The Data(base) Migration Service is a managed service used to instantiate a new migrated DB in Cloud SQL (or AlloyDB for PostgreSQL but thatâ€™s not in scope here). The question isnâ€™t asking about database migration, so we can eliminate B. A could be used to create replicas, but doesnâ€™t help with offloading management operations. That leaves C which does use a managed service which could be leveraged to create replicas.","poster":"dynamic_dba","comment_id":"836569","timestamp":"1678572360.0","upvote_count":"17"},{"content":"Selected Answer: A\nA\nA: CORRECT. External server replication meant to serve the case as the question describe: DC -> GSQL.\nB: WRONG. DMS intends for one time migration + CDC but does not mean to serve as primary + replica fashion. The replica is not ready to serve the traffic.\nC: WRONG. Cloud SQL for MySQL external replica meant to serve the replica is outside of Google cloud, which means GSQL -> GSQL or GSQL -> DC.\nD: WRONG. This option is for one time only.\nReference:\nhttps://cloud.google.com/sql/docs/mysql/replication/external-server\nhttps://cloud.google.com/sql/docs/mysql/replication\nhttps://cloud.google.com/database-migration/docs/overview#use_cases","comments":[{"upvote_count":"1","content":"Correct the reference links:\nhttps://cloud.google.com/sql/docs/mysql/replication/configure-replication-from-external#curl\nhttps://cloud.google.com/sql/docs/mysql/replication/configure-external-replica\nhttps://cloud.google.com/database-migration/docs/overview#use_cases","poster":"zanhsieh","comment_id":"806038","timestamp":"1676184600.0"}],"timestamp":"1676184180.0","upvote_count":"5","comment_id":"806031","poster":"zanhsieh"},{"upvote_count":"1","comment_id":"1410725","poster":"Devops2022","content":"Selected Answer: C\nCloud SQL for MySQL external replica allows you to configure MySQL replicas on Google Cloud that can replicate from your on-premises MySQL databases. This is part of the hybrid configuration, where you can scale read operations and offload some management tasks by using Cloud SQL to manage the replicas. With this approach, Cloud SQL can serve as the replication target, allowing you to scale reads effectively without completely migrating to the cloud.","timestamp":"1743045480.0"},{"content":"Selected Answer: C\nC to offload part of the management operation.","poster":"887ad17","timestamp":"1737662760.0","comment_id":"1345655","upvote_count":"1"},{"upvote_count":"1","content":"https://cloud.google.com/sql/docs/mysql/replication#external-read-replicas\n\nhttps://cloud.google.com/sql/docs/mysql/replication#replication_use_cases","poster":"TNT87","comment_id":"1300320","timestamp":"1729408440.0"},{"comment_id":"1255826","content":"Selected Answer: C\nExternal replica is for scaling read","timestamp":"1722016020.0","poster":"dunhill","upvote_count":"1"},{"content":"Selected Answer: A\nhttps://cloud.google.com/sql/docs/mysql/replication/external-","poster":"Pime13","timestamp":"1714651440.0","upvote_count":"1","comment_id":"1205492"},{"timestamp":"1708509300.0","upvote_count":"1","comment_id":"1155405","content":"C. MySQL external replica are best for create replicas to sclae reads and offload","poster":"Jason_Cloud_at"},{"content":"Selected Answer: C\nC is the answer as Question mentions offload part of the management operation","poster":"BIGQUERY_ALT_ALT","comment_id":"1080091","upvote_count":"3","timestamp":"1700924340.0"},{"content":"Selected Answer: C\nit's c","poster":"ewelaz","upvote_count":"1","timestamp":"1695820080.0","comment_id":"1018816"},{"timestamp":"1695069900.0","comment_id":"1010857","poster":"Kapello10","content":"Selected Answer: C\nThe ans is C","upvote_count":"2"},{"poster":"learnazureportal","comment_id":"999923","content":"A is correct - se external server replication -==> This option allows you to set up replication between your on-premises MySQL server (in your data center) and a MySQL server running on GOOGLE CLOUD COMPUTE ENGINE.","timestamp":"1693948380.0","upvote_count":"2"},{"content":"Selected Answer: A\nBy using external server replication, you can set up and manage replication between your on-premises MySQL database and a replica instance in Google Cloud. This enables you to scale reads, offload management operations, and distribute the workload between your data center and Google Cloud, providing the desired benefits in a hybrid configuration.","timestamp":"1685109900.0","comment_id":"907423","upvote_count":"4","poster":"KennyHuang"},{"upvote_count":"2","content":"Selected Answer: B\nAgree with B. \n- Multi-cloud continuous replication\n\nMuch like the read replicas across regions, if data exists in another cloud provider, a migration job can be set up which continuously replicates the database <<into Google Cloud for multi-cloud read-availability>>. Database Migration Service doesn't support a dual-write scenario, that is writing to and reading from both the source and destination.\n\nhttps://cloud.google.com/database-migration/docs/overview#use_cases","poster":"leroygordo","timestamp":"1678319760.0","comment_id":"833455"},{"timestamp":"1678045740.0","comments":[{"comment_id":"830268","content":"https://cloud.google.com/sql/docs/mysql/replication/external-server","upvote_count":"2","poster":"H_S","timestamp":"1678045920.0"}],"upvote_count":"1","poster":"H_S","content":"Selected Answer: C\noffload part of the management operation => cloud sql => C","comment_id":"830263"},{"timestamp":"1678011060.0","poster":"Nirca","upvote_count":"1","comment_id":"829822","content":"Selected Answer: A\nA. Use external server replication. \nhttps://cloud.google.com/sql/docs/mysql/replication/external-server#config-description"},{"timestamp":"1674364740.0","upvote_count":"4","comment_id":"783925","content":"Selected Answer: A\nI strongly believe it is A. Since the database is already in your datacenter. So you need to replicate your datacenter database to cloud to offload management. External Server Replication will replicate your database on to cloud sql. \nhttps://cloud.google.com/sql/docs/mysql/replication/external-server","poster":"Tharun1125438"},{"upvote_count":"1","poster":"ssaporylo","comment_id":"765361","content":"C: https://cloud.google.com/sql/docs/mysql/replication","timestamp":"1672819320.0"},{"poster":"pk349","content":"C: Use Cloud SQL for MySQL external replica.","timestamp":"1671980940.0","upvote_count":"2","comment_id":"755757"},{"content":"Selected Answer: C\nC is the Correct Answer","timestamp":"1671881100.0","upvote_count":"2","poster":"GCP72","comment_id":"754828"},{"timestamp":"1671825120.0","comment_id":"754478","content":"Selected Answer: B\nhttps://cloud.google.com/database-migration/docs/overview#use_cases","poster":"lapeyus","upvote_count":"2"},{"comment_id":"752457","upvote_count":"2","poster":"range9005","content":"Selected Answer: C\nCloud SQL for MySQL external replica helps to migrate data to ClouSql and to increase read write latency","timestamp":"1671634800.0"},{"poster":"miguelp","timestamp":"1671620940.0","upvote_count":"1","comment_id":"752197","content":"B \nhttps://cloud.google.com/database-migration/docs/overview#use_cases"},{"poster":"Kloudgeek","comment_id":"751242","timestamp":"1671555240.0","content":"Correct answer is C: https://cloud.google.com/sql/docs/mysql/replication/create-replica , Use Read Replica, in this case we can use Cloud SQL as read replica to offload the read requests and scaling","upvote_count":"3"}],"answers_community":["A (45%)","C (42%)","12%"]},{"id":"GhpAGLRgMhknuFzQhYc9","isMC":true,"answer_ET":"AC","answer_description":"","timestamp":"2022-12-20 22:04:00","url":"https://www.examtopics.com/discussions/google/view/92227-exam-professional-cloud-database-engineer-topic-1-question/","topic":"1","answer":"AC","question_id":54,"answer_images":[],"exam_id":5,"question_text":"Your company is shutting down their data center and migrating several MySQL and PostgreSQL databases to Google Cloud. Your database operations team is severely constrained by ongoing production releases and the lack of capacity for additional on-premises backups. You want to ensure that the scheduled migrations happen with minimal downtime and that the Google Cloud databases stay in sync with the on-premises data changes until the applications can cut over. What should you do? (Choose two.)","unix_timestamp":1671570240,"answers_community":["AC (88%)","13%"],"choices":{"C":"Use replication from an external server to migrate the databases to Cloud SQL.","A":"Use Database Migration Service to migrate the databases to Cloud SQL.","D":"Use an external read replica to migrate the databases to Cloud SQL.","E":"Use a read replica to migrate the databases to Cloud SQL.","B":"Use a cross-region read replica to migrate the databases to Cloud SQL."},"discussion":[{"content":"Selected Answer: AD\nCan anyone explain why D is not the right answer?","poster":"Devops2022","upvote_count":"1","timestamp":"1743046020.0","comment_id":"1410728"},{"comment_id":"1255827","upvote_count":"1","content":"Selected Answer: AC\nreplication from an external server is for db migration.","poster":"dunhill","timestamp":"1722016080.0"},{"timestamp":"1696280880.0","poster":"juliorevk","upvote_count":"1","content":"Selected Answer: AC\nA because Database migration service is the managed offering\nC because the external server is used for migration.\nThe others aren't approaches aren't actual methods for migration.","comment_id":"1023452"},{"poster":"Pilot50","comment_id":"861179","content":"Selected Answer: AC\nno other choices are correct","timestamp":"1680618900.0","upvote_count":"1"},{"upvote_count":"1","comments":[{"poster":"Ral17","timestamp":"1732636380.0","content":"Why can't you use a read replica as a source for migration if it is being synced with the primary instance?","comment_id":"1318152","upvote_count":"1"}],"comment_id":"836574","timestamp":"1678572960.0","content":"A, C.\nB doesnâ€™t make sense since the DBs arenâ€™t in Cloud SQL yet. D and E donâ€™t makes sense because no method is attached to either answer and you wouldnâ€™t use a read replica as a source anyway. That leaves A and C. A makes sense since it can be scheduled and is online hence little/no downtime. Native DB replication of an external (on prem) server is basically what the Database Migration Service is doing. Which makes C correct as well.","poster":"dynamic_dba"},{"content":"Selected Answer: AC\nA & C is the correct Answer","poster":"Nirca","timestamp":"1678011660.0","comment_id":"829828","upvote_count":"1"},{"poster":"pk349","timestamp":"1671980820.0","upvote_count":"2","comment_id":"755755","content":"A: Use Database Migration Service ***** to migrate the databases to Cloud SQL.\n C: Use replication ***** from an external server to migrate the databases to Cloud SQL."},{"timestamp":"1671881400.0","poster":"GCP72","comment_id":"754829","upvote_count":"2","content":"A & C is the correct Answer"},{"content":"Selected Answer: AC\nhttps://cloud.google.com/sql/docs/mysql/replication/manage-replicas#basic-steps-to-change-parallel-replication-flags","timestamp":"1671825420.0","comment_id":"754485","poster":"lapeyus","upvote_count":"1"},{"upvote_count":"1","timestamp":"1671635520.0","content":"Selected Answer: AC\nA is Database Migration Service to migrate the databases with CDC\nC is Replication from an external server is used to Migration Database to Cloud SQL","comment_id":"752479","poster":"range9005"},{"content":"Selected Answer: AC\nUsing A for CDC makes sense to me and C is an option as well","timestamp":"1671570240.0","poster":"fredcaram","upvote_count":"1","comment_id":"751472"}],"question_images":[]},{"id":"WmB3icXTEJ3sx1Jefl1I","timestamp":"2022-12-20 21:37:00","choices":{"B":"1. Create migration job using Database Migration Service.\n2. Set the migration job type to Continuous, and allow the databases to complete the full dump phase and start sending data in change data capture (CDC) mode.\n3. Wait for the replication delay to minimize, initiate a promotion of the new Cloud SQL instance, and wait for the migration job to complete.\n4. Update your application connections to the new instance.","A":"1. Create a Cloud SQL for MySQL instance for your databases, and configure Datastream to stream your database changes to Cloud SQL.\n2. Select the Backfill historical data check box on your stream configuration to initiate Datastream to backfill any data that is out of sync between the source and destination.\n3. Delete your stream when all changes are moved to Cloud SQL for MySQL, and update your application to use the new instance.","C":"1. Create migration job using Database Migration Service.\n2. Set the migration job type to One-time, and perform this migration during a maintenance window.\n3. Stop all write workloads to the source database and initiate the dump. Wait for the dump to be loaded into the Cloud SQL destination database and the destination database to be promoted to the primary database.\n4. Update your application connections to the new instance.","D":"1. Use the mysqldump utility to manually initiate a backup of MySQL during the application maintenance window.\n2. Move the files to Cloud Storage, and import each database into your Cloud SQL instance.\n3. Continue to dump each database until all the databases are migrated.\n4. Update your application connections to the new instance."},"url":"https://www.examtopics.com/discussions/google/view/92222-exam-professional-cloud-database-engineer-topic-1-question/","answer":"B","discussion":[{"content":"B.\nA is wrong because Datastream is a CDC and replication service for data synchronization across heterogeneous databases. Itâ€™s reasonable to assume youâ€™ll be using Cloud SQL for MySQL, so youâ€™ll be performing a homogeneous migration. Plus, while the a Datastream source can be MySQL, a Datastream target is either BigQuery or Cloud Storage and not Cloud SQL. See https://cloud.google.com/datastream/docs/overview.\nC is wrong because a one time migration wouldnâ€™t capture all the data changes once the maintenance window ended and the apps were fired back up. Furthermore, stopping all writes during the dump would constitute downtime which the question wants minimized. D would take forever in a rapidly changing source system. B is the cleanest and simplest solution especially since the question puts no time constraint on making the migration happen.","timestamp":"1694464080.0","poster":"dynamic_dba","comment_id":"836581","upvote_count":"8"},{"poster":"887ad17","upvote_count":"1","content":"Selected Answer: B\nonly B have initiate a promotion of the new Cloud SQL instance","timestamp":"1737663120.0","comment_id":"1345659"},{"upvote_count":"1","comment_id":"1213862","timestamp":"1732037760.0","poster":"dija123","content":"Selected Answer: B\nAgree with B"},{"upvote_count":"2","poster":"Pilot50","timestamp":"1696430280.0","comment_id":"861183","content":"Selected Answer: B\nC isn't correct since it will not minimize the downtime"},{"upvote_count":"1","comment_id":"829831","poster":"Nirca","content":"Selected Answer: B\nB is the correct answer","timestamp":"1693902240.0"},{"content":"B: Create migration job using Database ***** Migration Service.\nSet the migration job type to Continuous, and allow the databases to complete the full dump phase and start sending data in change data capture (CDC) mode.\nWait ***** for the replication delay to minimize, initiate a promotion of the new Cloud SQL instance, and wait for the migration job to complete.\nUpdate your application connections to the new instance.","poster":"pk349","timestamp":"1687698360.0","comment_id":"755752","upvote_count":"1"},{"poster":"GCP72","timestamp":"1687599300.0","upvote_count":"2","comment_id":"754832","content":"Selected Answer: B\nB is the correct answer"},{"content":"Selected Answer: B\nContinuous Migration with CDC","poster":"range9005","upvote_count":"2","timestamp":"1687353240.0","comment_id":"752484"},{"upvote_count":"2","poster":"fredcaram","content":"Selected Answer: B\nC is not minimizing the downtime","comment_id":"751475","timestamp":"1687287960.0"},{"content":"Correct option is B. You need to minimize the downtime of the application but option C refers to stop the app while migration to complete.","upvote_count":"4","poster":"Kloudgeek","comment_id":"751445","timestamp":"1687286220.0"}],"question_images":[],"answer_ET":"B","answers_community":["B (100%)"],"exam_id":5,"answer_images":[],"answer_description":"","isMC":true,"unix_timestamp":1671568620,"question_text":"Your company is migrating the existing infrastructure for a highly transactional application to Google Cloud. You have several databases in a MySQL database instance and need to decide how to transfer the data to Cloud SQL. You need to minimize the downtime for the migration of your 500 GB instance. What should you do?","question_id":55,"topic":"1"}],"exam":{"isImplemented":true,"id":5,"lastUpdated":"11 Apr 2025","name":"Professional Cloud Database Engineer","numberOfQuestions":132,"provider":"Google","isBeta":false,"isMCOnly":true},"currentPage":11},"__N_SSP":true}