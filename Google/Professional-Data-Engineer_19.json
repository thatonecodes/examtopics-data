{"pageProps":{"questions":[{"id":"9SXK5Ki5zAg3sbxptfnR","discussion":[{"content":"C\nif data is time based or sequential, find partition and cluster option\nif data is not time based, \nalways look for denomalize / nesting option.","timestamp":"1724005620.0","poster":"musumusu","comment_id":"813480","upvote_count":"10"},{"upvote_count":"5","content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/bigquery/docs/best-practices-performance-nested\nBest practice: Use nested and repeated fields to denormalize data storage and increase query performance.\n\nDenormalization is a common strategy for increasing read performance for relational datasets that were previously normalized. The recommended way to denormalize data in BigQuery is to use nested and repeated fields. It's best to use this strategy when the relationships are hierarchical and frequently queried together, such as in parent-child relationships.","comment_id":"730460","timestamp":"1716982740.0","poster":"zellck"},{"upvote_count":"1","comment_id":"763274","content":"C. Create a table that includes information about the books and authors, but nest the author fields inside the author column.","poster":"AzureDP900","timestamp":"1719846900.0"},{"timestamp":"1716482640.0","poster":"Atnafu","upvote_count":"2","content":"C\nBest practice: Use nested and repeated fields to denormalize data storage and increase query performance.","comment_id":"725344"},{"timestamp":"1715934960.0","content":"Selected Answer: C\nUse nested and repeated fields to denormalize data storage which will increase query performance.BigQuery doesn't require a completely flat denormalization. You can use nested and repeated fields to maintain relationships","upvote_count":"2","comment_id":"720395","poster":"dish11dish"},{"poster":"Thobm","timestamp":"1710269460.0","comment_id":"667249","upvote_count":"1","content":"Selected Answer: C\nhttps://cloud.google.com/bigquery/docs/best-practices-performance-nested"},{"upvote_count":"2","poster":"ducc","timestamp":"1709435160.0","content":"Selected Answer: C\nC is correct","comment_id":"657943"},{"upvote_count":"2","timestamp":"1709414520.0","comment_id":"657759","content":"Selected Answer: C\nC. Create a table that includes information about the books and authors, but nest the author fields inside the author column.","poster":"AWSandeep"}],"answers_community":["C (100%)"],"topic":"1","isMC":true,"choices":{"B":"Create a table that is wide and includes a column for each attribute, including the author's first name, last name, date of birth, etc.","D":"Keep the schema the same, create a view that joins all of the tables, and always query the view.","A":"Keep the schema the same, maintain the different tables for the book and each of the attributes, and query as you are doing today.","C":"Create a table that includes information about the books and authors, but nest the author fields inside the author column."},"answer_ET":"C","question_id":91,"answer_description":"","question_images":[],"timestamp":"2022-09-02 21:22:00","exam_id":11,"url":"https://www.examtopics.com/discussions/google/view/79552-exam-professional-data-engineer-topic-1-question-180/","answer_images":[],"unix_timestamp":1662146520,"answer":"C","question_text":"You are migrating an application that tracks library books and information about each book, such as author or year published, from an on-premises data warehouse to BigQuery. In your current relational database, the author information is kept in a separate table and joined to the book information on a common key. Based on Google's recommended practice for schema design, how would you structure the data to ensure optimal speed of queries about the author of each book that has been borrowed?"},{"id":"UVh4hryBfw5tE2zBfLdv","choices":{"B":"Create the pipeline statically in the class definition.","D":"Batch the job into ten-second increments.","A":"Call out to the service via HTTP.","C":"Create a new object in the startBundle method of DoFn."},"answer":"D","timestamp":"2022-09-04 03:19:00","question_id":92,"answer_description":"","unix_timestamp":1662254340,"topic":"1","question_images":[],"question_text":"You need to give new website users a globally unique identifier (GUID) using a service that takes in data points and returns a GUID. This data is sourced from both internal and external systems via HTTP calls that you will make via microservices within your pipeline. There will be tens of thousands of messages per second and that can be multi-threaded. and you worry about the backpressure on the system. How should you design your pipeline to minimize that backpressure?","answers_community":["D (93%)","7%"],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/79924-exam-professional-data-engineer-topic-1-question-181/","answer_ET":"D","exam_id":11,"discussion":[{"upvote_count":"20","content":"Selected Answer: D\nD: I have insisted on this choice all aling.\n please read find the keyword massive backpressure\nhttps://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1\n\nif the call takes on average 1 sec, that would cause massive backpressure on the pipeline. In these circumstances you should consider batching these requests, instead.","comment_id":"683247","timestamp":"1680155040.0","comments":[{"comments":[{"content":"By the way if you see the shared Pseudocode, it's talking about start bundle and finish bundle of DoFn. The question is which one to choose to avoid back pressure? \nyou can see why you need to choose bundle instead of batching in below link\n Batching introduces some processing overhead as well as the need for a magic number to determine the key space.\nInstead, use the StartBundle and FinishBundle lifecycle elements to batch your data. With these options, no shuffling is needed.\nhttps://cloud.google.com/dataflow/docs/tutorials/ecommerce-java#micro-batch-calls","comments":[{"content":"Valid points. but I don't change my mind, regarding the requirements of this particular question:\n- multi-threaded ability\n- no mention of heavy initialization steps or a lot of disk I/O (where shuffling might be a problem).\nAnd especially the excerpt:\n\"if the call takes on average 1 sec, that would cause massive backpressure on the pipeline. In these circumstances you should consider batching these requests, instead\"\nIt's like the guys that authored the question had this sentence in front of their eyes.","comment_id":"726510","upvote_count":"2","timestamp":"1684996140.0","poster":"NicolasN"}],"poster":"Atnafu","timestamp":"1684888200.0","comment_id":"725513","upvote_count":"2"}],"timestamp":"1683533340.0","content":"Thanks for sharing, you found exactly the same problem!\nThe document defitely proposes batching for this scenario.\n\nI'm quoting another part from the same example that would be useful for a similar question with different conditions:\n- If you're using a client in the DoFn that has heavy instantiation steps, rather than create that object in each DoFn call:\n * If the client is thread-safe and serializable, create it statically in the class definition of the DoFn.\n * If it's not thread-safe, create a new object in the startBundle method of DoFn. By doing so, the client will be reused across all elements of a bundle, saving initialization time.","upvote_count":"6","poster":"NicolasN","comment_id":"713664"}],"poster":"John_Pongthorn"},{"poster":"John_Pongthorn","content":"Selected Answer: D\nD\nAll guys ,pls read carefully on Pattern: Calling external services for data enrichment\nhttps://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1 \nA , B , C all of them are solution for norma case but if you need to stand for backpressure,\nin last sector in Note : Note: When using this pattern, be sure to plan for the load that's placed on the external service and any associated backpressure. For example, imagine a pipeline that's processing tens of thousands of messages per second in steady state. If you made a callout per element, you would need the system to deal with the same number of API calls per second. Also, if the call takes on average 1 sec, that would cause massive backpressure on the pipeline. In these circumstances, you should consider batching these requests, instead.\n\nAnyone can share ideas to debate with me.","timestamp":"1679820660.0","comment_id":"679554","upvote_count":"8"},{"timestamp":"1718953680.0","content":"Selected Answer: D\nOption D is the best approach to minimize backpressure in this scenario. By batching the jobs into 10-second increments, you can throttle the rate at which requests are made to the external GUID service. This prevents too many simultaneous requests from overloading the service.\n\nOption A would not help with backpressure since it just makes synchronous HTTP requests as messages arrive. Similarly, options B and C don't provide any inherent batching or throttling mechanism.\n\nBatching into time windows is a common strategy in stream processing to deal with high velocity data. The 10-second windows allow some buffering to happen, rather than making a call immediately for each message. This provides a natural throttling that can be tuned based on the external service's capacity.","comment_id":"1102293","comments":[{"content":"To design a pipeline that minimizes backpressure, especially when dealing with tens of thousands of messages per second in a multi-threaded environment, it's important to consider how each option affects system performance and scalability. Let's examine each of your options:","comments":[{"timestamp":"1718953740.0","comment_id":"1102295","content":"A. Call out to the service via HTTP: Making HTTP calls to an external service for each message can introduce significant latency and backpressure, especially at high throughput. This is due to the overhead of establishing a connection, waiting for the response, and handling potential network delays or failures.","comments":[{"content":"Given these considerations, option D (Batch the job into ten-second increments) seems to be the most effective strategy for minimizing backpressure in your scenario. By batching messages, you can reduce the strain on your pipeline and external services, making the system more resilient and scalable under high load. However, the exact batch size and interval should be fine-tuned based on the specific characteristics of your workload and the capabilities of the external systems you are interacting with.\n\nAdditionally, it's important to consider other strategies in conjunction with batching, such as implementing efficient error handling, load balancing, and potentially using asynchronous I/O for external HTTP calls to further optimize performance and minimize backpressure.","upvote_count":"1","timestamp":"1718953860.0","poster":"MaxNRG","comment_id":"1102299"},{"content":"B. Create the pipeline statically in the class definition: While this approach can improve initialization time and reduce overhead during execution, it doesn't directly address the issue of backpressure caused by high message throughput.","poster":"MaxNRG","upvote_count":"1","timestamp":"1718953740.0","comment_id":"1102296","comments":[{"timestamp":"1718953800.0","content":"C. Create a new object in the startBundle method of DoFn: This approach is typically used in Apache Beam to initialize resources before processing a bundle of elements. While it can optimize resource usage and performance within each bundle, it doesn't inherently solve the backpressure issue caused by high message rates.","comments":[],"comment_id":"1102297","poster":"MaxNRG","upvote_count":"1"}]}],"upvote_count":"1","poster":"MaxNRG"}],"comment_id":"1102294","upvote_count":"1","poster":"MaxNRG","timestamp":"1718953740.0"}],"poster":"MaxNRG","upvote_count":"2"},{"upvote_count":"1","poster":"izekc","comment_id":"886089","timestamp":"1698841260.0","content":"Selected Answer: D\nOption C is not correct because it does not address the issue of backpressure. Creating a new object in the startBundle method of DoFn will not help to reduce the number of calls that are made to the service, which can lead to backpressure.\n\nHere are some reasons why C is not correct:\n\nCreating a new object in the startBundle method of DoFn is not a scalable solution. As the number of messages increases, the number of objects that need to be created will also increase. This can lead to performance problems and memory usage issues.\nCreating a new object in the startBundle method of DoFn does not address the issue of backpressure. The service may still experience backpressure if the number of messages exceeds the service's capacity.\nA better solution would be to use batching to reduce the number of calls that are made to the service. This can help to improve performance and reduce backpressure."},{"timestamp":"1698680580.0","content":"gpt: Option C is a better approach as it allows for object creation to occur in a more controlled manner within the DoFn, potentially reducing the pressure on the system. However, it could still create a large number of objects depending on the rate of incoming messages.\n\nOption D of batching the job into ten-second increments can also be a good solution to reduce backpressure on the system. This way, you can limit the number of messages being processed at any given time, which can help prevent bottlenecks and reduce the likelihood of backpressure.\n\nTherefore, the best approach would be to combine options C and D, creating a new object in the startBundle method of a DoFn, and batching the job into smaller time increments, such as 10 seconds. This way, you can control the rate of object creation and processing, which can help minimize backpressure on the system.","poster":"Oleksandr0501","upvote_count":"1","comments":[{"timestamp":"1698680760.0","poster":"Oleksandr0501","content":"another vague question, as we see... \nso, i`ll choose D... if i get this test\n\"However, depending on the specifics of your use case, one option may be better suited than the other. For example, if you have a high volume of incoming messages with occasional spikes, option D of batching the job into smaller time increments may be more effective in managing the load. On the other hand, if the incoming messages are more evenly distributed over time, option C of creating a new object in the startBundle method of DoFn may be a better option.\nUltimately, it may be necessary to experiment with both approaches and determine which one works best for your specific use case.\"","upvote_count":"1","comment_id":"885279"}],"comment_id":"885274"},{"timestamp":"1696004040.0","comment_id":"854664","poster":"juliobs","upvote_count":"1","content":"Selected Answer: D\nD works.\nCould be C, but who said that the pipeline is in Dataflow/Beam?"},{"comment_id":"813489","poster":"musumusu","timestamp":"1692383880.0","upvote_count":"1","content":"Answer C\nbatch increment in 10 sec, can improve load balancing, but overall back pressure (messages are generating more than consuming or publishing) in this case startBundle in DoFn or find other options in future like\n caching, \nload shedding (prioritising message flow), \nmessege queuing \nThese options handle backpressure..\nIf your cpu is performing bad then go with change in batch increment timing"},{"content":"Selected Answer: D\nI was hesitating between C and D, but then I realised this: https://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1 \nHere is says \"If it's not thread-safe, create a new object in the startBundle method of DoFn.\" The task explicitly says \"There will be tens of thousands of messages per second and that can be multi-threaded.\" \nCorrect me if I'm wrong, but multi-threaded == thread-safe. Therefore, no need to go for the C approach.","poster":"maci_f","upvote_count":"3","comment_id":"786742","timestamp":"1690213320.0"},{"content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1\nFor example, imagine a pipeline that's processing tens of thousands of messages per second in steady state. If you made a callout per element, you would need the system to deal with the same number of API calls per second. Also, if the call takes on average 1 sec, that would cause massive backpressure on the pipeline. In these circumstances you should consider batching these requests, instead.","comment_id":"730455","poster":"zellck","comments":[{"poster":"AzureDP900","comment_id":"763276","timestamp":"1688224620.0","upvote_count":"1","content":"D. Batch the job into ten-second increments."}],"upvote_count":"3","timestamp":"1685360160.0"},{"comment_id":"725512","poster":"Atnafu","upvote_count":"1","timestamp":"1684888020.0","content":"C\nC is an answer because\nFirst of all, no doubt that we should avoid single call of element that's why we use multi-threading else it overwhelm an external service endpoint.To avoid this issue, batch calls to external systems.\nBatch calls has also issue:GroupByKey transform or Apache Beam Timer API.\nthese approaches both require shuffling, which introduces some processing overhead as well as the need for a magic number to determine the key space.\nInstead, use the StartBundle and FinishBundle lifecycle elements to batch your data. With these options, no shuffling is needed.\nSource:\nhttps://cloud.google.com/dataflow/docs/tutorials/ecommerce-java#micro-batch-calls\nhttps://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1\nSummary:\nStartBundle and FinishBundle do batch with no shuffling"},{"content":"Ans C: reference https://cloud.google.com/architecture/e-commerce/patterns/batching-external-calls","poster":"AHUI","upvote_count":"1","comment_id":"681308","timestamp":"1679961480.0"},{"poster":"SMASL","upvote_count":"2","comment_id":"672194","timestamp":"1679140500.0","content":"Selected Answer: C\nBased on the answers in this discussion thread, I would go for C. The most important link to support this choice is as following: https://cloud.google.com/architecture/e-commerce/patterns/batching-external-calls"},{"poster":"Thobm","timestamp":"1678646760.0","comment_id":"667243","content":"Selected Answer: D\nBeam docs recommend batching \nhttps://beam.apache.org/documentation/patterns/grouping-elements-for-efficient-external-service-calls/","upvote_count":"1"},{"timestamp":"1678444740.0","poster":"John_Pongthorn","upvote_count":"1","comment_id":"665247","content":"C , It is straight foward , You can take a look at https://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1 \nPattern : Calling external services for data enrichmen"},{"comments":[{"timestamp":"1678179420.0","content":"https://cloud.google.com/architecture/e-commerce/patterns/batching-external-calls\nTo support choice C","upvote_count":"1","comment_id":"662125","poster":"TNT87"}],"content":"Answer C\nhttps://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1","poster":"TNT87","comment_id":"662123","timestamp":"1678179360.0","upvote_count":"1"},{"upvote_count":"1","poster":"YorelNation","content":"Selected Answer: C\ni think you are right gg","timestamp":"1678104960.0","comment_id":"661076"},{"timestamp":"1678013940.0","comment_id":"659959","poster":"nwk","content":"How about C?\nhttps://cloud.google.com/architecture/e-commerce/patterns/batching-external-calls","upvote_count":"2"},{"comment_id":"659531","upvote_count":"2","poster":"AWSandeep","timestamp":"1677970080.0","content":"Selected Answer: D\nD. Batch the job into ten-second increments."},{"comment_id":"658885","upvote_count":"1","timestamp":"1677899940.0","poster":"ducc","content":"Selected Answer: D\nD is correct IMO"}],"answer_images":[]},{"id":"bafyniHDWDqudfCJjJJE","answer_description":"","question_text":"You are migrating your data warehouse to Google Cloud and decommissioning your on-premises data center. Because this is a priority for your company, you know that bandwidth will be made available for the initial data load to the cloud. The files being transferred are not large in number, but each file is 90 GB.\nAdditionally, you want your transactional systems to continually update the warehouse on Google Cloud in real time. What tools should you use to migrate the data and ensure that it continues to write to your warehouse?","answers_community":["C (93%)","7%"],"choices":{"A":"Storage Transfer Service for the migration; Pub/Sub and Cloud Data Fusion for the real-time updates","D":"gsutil for both the migration and the real-time updates","C":"gsutil for the migration; Pub/Sub and Dataflow for the real-time updates","B":"BigQuery Data Transfer Service for the migration; Pub/Sub and Dataproc for the real-time updates"},"discussion":[{"timestamp":"1685359920.0","poster":"zellck","upvote_count":"11","content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets#gsutil_for_smaller_transfers_of_on-premises_data\nThe gsutil tool is the standard tool for small- to medium-sized transfers (less than 1 TB) over a typical enterprise-scale network, from a private data center to Google Cloud.","comments":[{"comment_id":"763278","poster":"AzureDP900","content":"Agreed\n\nthx for sharing link","upvote_count":"1","timestamp":"1688224800.0"},{"content":"what is wrong with A, there is no cost constraint","timestamp":"1692384420.0","poster":"musumusu","upvote_count":"1","comment_id":"813496"}],"comment_id":"730447"},{"upvote_count":"8","comment_id":"657775","poster":"AWSandeep","timestamp":"1677794100.0","content":"Selected Answer: C\nC. gsutil for the migration; Pub/Sub and Dataflow for the real-time updates\n\nUse Gsutil when there is enough bandwidth to meet your project deadline for less than 1 TB of data. Storage Transfer Service is for much larger volumes for migration. Moreover, Cloud Data Fusion and Dataproc are not ideal for real-time updates. BigQuery Data Transfer Service does not support all on-prem sources."},{"content":"Selected Answer: A\nAccording to the latest documentation, \"Generally, you should use gcloud storage commands instead of gsutil commands. The gsutil tool is a legacy Cloud Storage CLI and minimally maintained.\"\nWe should remove the presence of gsutil in the questions.","poster":"shangning007","timestamp":"1734595620.0","upvote_count":"2","comment_id":"1328897"},{"comment_id":"1104545","upvote_count":"1","timestamp":"1719217860.0","poster":"TVH_Data_Engineer","content":"Selected Answer: C\nConsidering the requirement for handling large files and the need for real-time data integration, Option C (gsutil for the migration; Pub/Sub and Dataflow for the real-time updates) seems to be the most appropriate. gsutil will effectively handle the large file transfers, while Pub/Sub and Dataflow provide a robust solution for real-time data capture and processing, ensuring continuous updates to your warehouse on Google Cloud."},{"timestamp":"1718954040.0","poster":"MaxNRG","comments":[{"upvote_count":"2","content":"Option A is incorrect because Storage Transfer Service is better for scheduled batch transfers, not ad hoc large migrations.\n\nOption B is incorrect because BigQuery Data Transfer Service is more focused on scheduled replication jobs, not ad hoc migrations.\n\nOption D would not work well for real-time updates after migration is complete.\n\nSo option C leverages the right Google cloud services for the one-time migration and ongoing real-time processing.","poster":"MaxNRG","timestamp":"1718954040.0","comment_id":"1102305"}],"upvote_count":"1","content":"Selected Answer: C\nOption C is the best choice given the large file sizes for the initial migration and the need for real-time updates after migration.\n\nSpecifically:\n\ngsutil can transfer large files in parallel over multiple TCP connections to maximize bandwidth. This works well for the 90GB files during initial migration.\nPub/Sub allows real-time messaging of updates that can then be streamed into Cloud Dataflow. Dataflow provides scalable stream processing to handle transforming and writing those updates into BigQuery or other sinks.","comment_id":"1102304"},{"poster":"xiangbobopopo","content":"Selected Answer: C\nagree with C","comment_id":"1055166","timestamp":"1714201020.0","upvote_count":"1"},{"upvote_count":"4","timestamp":"1678179720.0","poster":"TNT87","comment_id":"662134","content":"https://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets#gsutil_for_smaller_transfers_of_on-premises_data\nAnswer C"},{"timestamp":"1678105200.0","comment_id":"661080","upvote_count":"3","content":"Selected Answer: C\nC seems legit","poster":"YorelNation"}],"isMC":true,"question_id":93,"answer_images":[],"answer_ET":"C","exam_id":11,"question_images":[],"timestamp":"2022-09-02 21:55:00","url":"https://www.examtopics.com/discussions/google/view/79560-exam-professional-data-engineer-topic-1-question-182/","topic":"1","answer":"C","unix_timestamp":1662148500},{"id":"tdrHkVTkFRA0LwgWIctc","answer_description":"","choices":{"C":"For each index, have a separate table and use a timestamp as the row key design.","B":"Create one unique table for all of the indices, and then use a reverse timestamp as the row key design.","A":"Create one unique table for all of the indices, and then use the index and timestamp as the row key design.","D":"For each index, have a separate table and use a reverse timestamp as the row key design."},"unix_timestamp":1662150300,"url":"https://www.examtopics.com/discussions/google/view/79580-exam-professional-data-engineer-topic-1-question-183/","question_id":94,"discussion":[{"upvote_count":"17","poster":"John_Pongthorn","content":"This is special case , plese Take a look carefully the below link and read at last paragraph at the bottom of this comment, let everyone share idea, We will go with B, C\nhttps://cloud.google.com/bigtable/docs/schema-design#time-based\n\nDon't use a timestamp by itself or at the beginning of a row key, because this will cause sequential writes to be pushed onto a single node, creating a hotspot.\n\nIf you usually retrieve the most recent records first, you can use a reversed timestamp in the row key by subtracting the timestamp from your programming language's maximum value for long integers (in Java, java.lang.Long.MAX_VALUE). With a reversed timestamp, the records will be ordered from most recent to least recent.","comments":[{"content":"According to the link you provided:\nIf you usually retrieve the most recent records first in your queries, a pattern to consider is using reversed timestamps in the row key. This pattern causes rows to be ordered from most recent to least recent, so more recent data is earlier in the table. \n--------------------- READ CAREFULY --------------------------------------------------------------------------------\nAs with any timestamp, avoid starting a row key with a reversed timestamp so that you don't cause hotspots.\n-----------------------------------------------------------------------------------------------------------------------------------\nYou can get a reversed timestamp by subtracting the timestamp from your programming language's maximum value for long integers (in Java, java.lang.Long.MAX_VALUE).\n\nHence, starting row key with timestamp should be avoided (normal or reversed).\n\nThat leads to answer A, which is a best practice.","timestamp":"1738575540.0","upvote_count":"1","poster":"Ryannn23","comment_id":"1350814"},{"poster":"Mcloudgirl","comment_id":"714755","content":"I agree, based on the docs, B. Leading with a non-reversed timestamp will lead to hotspotting, reversed is the way to go.","timestamp":"1668013800.0","upvote_count":"2"}],"timestamp":"1664187180.0","comment_id":"679610"},{"content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/bigtable/docs/schema-design#time-based\nIf you usually retrieve the most recent records first, you can use a reversed timestamp in the row key by subtracting the timestamp from your programming language's maximum value for long integers (in Java, java.lang.Long.MAX_VALUE). With a reversed timestamp, the records will be ordered from most recent to least recent.","poster":"zellck","timestamp":"1669728480.0","comment_id":"730443","upvote_count":"13"},{"poster":"Ryannn23","comment_id":"1350815","upvote_count":"2","content":"Selected Answer: A\nVote A, as explained by Augustax:\n\nAgree A is the best option because:\n1. Multi-tenancy solution\n2. As with any timestamp, avoid starting a row key with a reversed timestamp so that you don't cause hotspots.","timestamp":"1738575600.0"},{"upvote_count":"4","content":"Selected Answer: A\nAgree A is the best option because:\n1. Multi-tenancy solution\n2. As with any timestamp, avoid starting a row key with a reversed timestamp so that you don't cause hotspots.","timestamp":"1737424620.0","comment_id":"1343962","poster":"Augustax"},{"upvote_count":"4","poster":"shangning007","comment_id":"1328892","content":"Selected Answer: D\nI don't think any answer is correct.\nA lot people upvote for B, but based on https://cloud.google.com/bigtable/docs/schema-design#time-based, \"As with any timestamp, avoid starting a row key with a reversed timestamp so that you don't cause hotspots.\"","timestamp":"1734594540.0"},{"content":"Selected Answer: D\nWhy other options are not as suitable:\n\nA and B (One table for all indices): Storing all indices in a single table can lead to performance issues as the table grows larger. It also makes it harder to scale individual indices independently.\nC (Timestamp as row key): Using a regular timestamp would place the most recent data at the end of the table, making it less efficient to retrieve the latest prices.","timestamp":"1730464200.0","comment_id":"1305798","poster":"ToiToi","upvote_count":"2"},{"upvote_count":"2","comment_id":"1303917","content":"Selected Answer: D\nOption B and Option D are both from my point of view correct. It depens on the situation. If there is need to get the information from each stock index, then D is more suitable. Otherwise B.","poster":"SamuelTsch","timestamp":"1730110620.0"},{"content":"Selected Answer: D\n1. Reverse Timestamp for most recent stock prices\n2. Having different table for each stock is more efficient, improves the query performance and option B doesn't specify stock in row key.","timestamp":"1725522720.0","poster":"mayankazyour","comment_id":"1278776","upvote_count":"2"},{"comment_id":"1260426","upvote_count":"6","poster":"iooj","timestamp":"1722712920.0","content":"Selected Answer: A\nRow keys that start with a timestamp (irrespective reversed or not) causes sequential writes to be pushed onto a single node, creating a hotspot. If you put a timestamp in a row key, precede it with a high-cardinality value (index in our case) to avoid hotspots.\n\nThe ideal option would be: \"use the index and reversed timestamp as the row key design\"."},{"comment_id":"1122671","content":"Selected Answer: B\nB is a correct answer because \"you need to access only the most recent stock prices\"\n\n\"If you usually retrieve the most recent records first, you can use a reversed timestamp in the row key by subtracting the timestamp from your programming language's maximum value for long integers (in Java, java.lang.Long.MAX_VALUE). With a reversed timestamp, the records will be ordered from most recent to least recent.\"\nhttps://cloud.google.com/bigtable/docs/schema-design#time-based","poster":"datapassionate","upvote_count":"5","timestamp":"1705249620.0"},{"comment_id":"1104546","content":"Selected Answer: B\nB. One unique table for all indices, reverse timestamp as row key:\n\nA single table for all indices keeps the structure simple.\nUsing a reverse timestamp as part of the row key ensures that the most recent data comes first in the sorted order. This design is beneficial for quickly accessing the latest data.\nFor example: you can convert the timestamp to a string and format it in reverse order, like \"yyyyMMddHHmmss\", ensuring newer dates and times are sorted lexicographically before older ones.","poster":"TVH_Data_Engineer","upvote_count":"2","timestamp":"1703414100.0"},{"timestamp":"1694771640.0","content":"Correct Is B","upvote_count":"1","poster":"kshehadyx","comment_id":"1008346"},{"poster":"arien_chen","content":"Selected Answer: D\nOption B using reverse timestamp only, this is not the answer. \nthe right answer should be using the index and revers timestamp as the row key. \n\nSo, Option D is the only answer, because not A,B,C .","comment_id":"986534","upvote_count":"6","timestamp":"1692624000.0"},{"content":"Selected Answer: B\nhttps://cloud.google.com/bigtable/docs/schema-design#row-keys - If you usually retrieve the most recent records first, you can use a reversed timestamp\nB it is.","upvote_count":"2","comment_id":"968055","poster":"Lanro","timestamp":"1690804680.0"},{"poster":"Chom","upvote_count":"2","content":"Selected Answer: A\nA is the answer","timestamp":"1688745300.0","comment_id":"945802"},{"timestamp":"1687349520.0","comment_id":"929460","upvote_count":"2","poster":"vaga1","content":"Selected Answer: B\nthe answer relieves on whether the application need to access the whole indexes at the same time or not. If yes then is B, if no is A.\n\nin mind the answer is yes, so B makes more sense: I retrieve all the list at the same time."},{"content":"Selected Answer: B\nhttps://cloud.google.com/bigtable/docs/schema-design#time-based If you usually retrieve the most recent records first, you can use a reversed timestamp in the row key by subtracting the timestamp from your programming language's maximum value for long integers (in Java, java.lang.Long.MAX_VALUE). With a reversed timestamp, the records will be ordered from most recent to least recent.","timestamp":"1686299640.0","upvote_count":"2","poster":"ajdf","comment_id":"919089"},{"comment_id":"918084","poster":"WillemHendr","content":"Selected Answer: B\n\"access the data with the simplest query\"","timestamp":"1686217560.0","upvote_count":"1"},{"content":"Selected Answer: A\nyes reverse time stamp is recommended to prevent hot spot. But our query pattern is we need most recent record the is easy when you use Timestamp and Also option a stating that our row key not starting with time stamp which is index#timestamp and which is the most efficient way for this scenario.","comment_id":"877313","timestamp":"1682170860.0","upvote_count":"4","poster":"Prudvi3266"},{"upvote_count":"1","content":"Selected Answer: B\nReversed timestamp will definitely help here.","comment_id":"844672","timestamp":"1679302980.0","poster":"midgoo"},{"comment_id":"821015","content":"Answer A:\nI checked on other website and chatgpt also suggested A, to use index per stock and timestamp.","timestamp":"1677280440.0","upvote_count":"1","poster":"musumusu"},{"poster":"niketd","comment_id":"818771","timestamp":"1677124680.0","upvote_count":"3","content":"Selected Answer: B\nThe key here is \"only the most recent stock prices\". Doesn't talk about accessing a specific index - so answer should be B"},{"timestamp":"1676777820.0","upvote_count":"1","poster":"kostol","content":"Selected Answer: A\nhttps://cloud.google.com/bigtable/docs/schema-design#row-keys-avoid","comment_id":"813702"},{"timestamp":"1675008060.0","upvote_count":"1","content":"Answer is B: https://stackoverflow.com/questions/65487550/bigtable-reverse-timestamp-advantage-over-regular-timestamp\n\nYou want to access the MOST recent stock price First. Reverse Timestamp","comment_id":"791800","poster":"desertlotus1211"},{"upvote_count":"2","timestamp":"1672235400.0","poster":"nkit","content":"Selected Answer: A\nReversing TS won't help","comment_id":"759900"},{"upvote_count":"2","timestamp":"1672155720.0","poster":"PrashantGupta1616","content":"Selected Answer: A\nI go for A.","comment_id":"758726"},{"upvote_count":"2","timestamp":"1671755280.0","content":"How does reversing timestamp help in query speed? its still gonna scan through the whole table to output the result. \n\nAccording to Google, \n\"It's important to create a row key that makes it possible to retrieve a well-defined range of rows. Otherwise, your query requires a table scan, which is much slower than retrieving specific rows.\"\n\nTherefore I go for A.","poster":"kelvintoys93","comment_id":"753769"},{"poster":"Atnafu","content":"A\nRow keys to avoid\nRow keys that start with a timestamp. This pattern causes sequential writes to be pushed onto a single node, creating a hotspot. If you put a timestamp in a row key, precede it with a high-cardinality value like a user ID to avoid hotspots.\nhttps://cloud.google.com/bigtable/docs/schema-design#row-keys-avoid","upvote_count":"1","comments":[{"timestamp":"1669263420.0","content":"plus \nIf you usually retrieve the most recent records first, you can use a reversed timestamp that is not row key design \nReverse is with domain on schema design\nIf you're storing data about entities that can be represented as domain names, consider using a reverse domain name (for example, com.company.product) as the row key.","upvote_count":"2","comment_id":"725547","poster":"Atnafu"}],"comment_id":"725536","timestamp":"1669261500.0"},{"comments":[{"poster":"arien_chen","timestamp":"1692624720.0","comment_id":"986547","upvote_count":"1","content":"the question mention 'the major indices', not all stock symbols.\nI think 1000 tables limits is not a problem."}],"poster":"jkhong","timestamp":"1668437760.0","upvote_count":"5","content":"C, D -> Bigtable has a limitation of 1000 tables per instances. Since we are concerned of stock data, there has bound to be thousands... It is also an anti pattern to store similar schemas in separate tables.\nhttps://cloud.google.com/bigtable/docs/schema-design#tables\n\nDon't know why is everybody harping on the fact that timestamp or reverse timestamp is the only row key, or that they are the primary key. Im interpreting it as having timestamp as part of the design. We'll need reverse timestamp since we are only concerned with recent data so B, with only 1 unique table for all stock indexes","comment_id":"718047"},{"poster":"Teraflow","upvote_count":"5","content":"Selected Answer: A\nIndexes need to be unique, reverse timestamp is not necessarily unique","comment_id":"712172","timestamp":"1667717520.0"},{"comment_id":"701447","poster":"kastuarr","timestamp":"1666431840.0","upvote_count":"3","content":"Selected Answer: D\nD will avoid hot spotting , allow a very fast query and the reverse time stamp will allow recent records to be retrieved easily"},{"content":"B. reverse timestamp rowkey = most newer registry","comments":[{"comment_id":"696736","timestamp":"1665971640.0","poster":"devaid","upvote_count":"2","comments":[{"upvote_count":"1","content":"There's no mention of Spanner here...","comment_id":"718042","timestamp":"1668437340.0","poster":"jkhong"}],"content":"2nd tought: I'm agree with B, but the stock symbol as part of the row key is needed, like: \"stock#reverseTimeStamp\". So, in that case makes more sense D because it create one table for every index, but that is not efficient on Spanner so i keep with B ..."}],"poster":"devaid","comment_id":"687027","upvote_count":"1","timestamp":"1664986620.0"},{"content":"B is correct. By reversing the timestamp, you can design a row key where the most recent event appears at the start of the table instead of the end. As a result, you can get the N most recent events simply by retrieving the first N rows of the table.","poster":"Amey_Yeole","timestamp":"1664431140.0","comment_id":"682384","upvote_count":"4"},{"content":"Selected Answer: B\nreversing the timestamp","comment_id":"668256","timestamp":"1663088100.0","upvote_count":"3","poster":"Remi2021"},{"upvote_count":"2","timestamp":"1663064820.0","comment_id":"667868","content":"Selected Answer: B\nI think its B because it ask that we need to ensure that you can access the data with the simplest query, not to create the rowkey as the best practices (which should include the index first and then the timestamp)","poster":"DiegoGonL"},{"upvote_count":"2","content":"I think its B because it ask that we need to ensure that you can access the data with the simplest query, not to create the rowkey as the best practices (which should include the index first and then the timestamp)","poster":"DiegoGonL","timestamp":"1663057800.0","comment_id":"667785"},{"comment_id":"667762","content":"Selected Answer: A\nAns A\n\nhttps://cloud.google.com/bigtable/docs/schema-design","comments":[{"content":"By reversing the timestamp, you can design a row key where the most recent event appears at the start of the table instead of the end. As a result, you can get the N most recent events simply by retrieving the first N rows of the table\nChnging my answer to B","comment_id":"667767","upvote_count":"1","timestamp":"1663055880.0","comments":[{"comment_id":"770769","content":"https://cloud.google.com/bigtable/docs/schema-design#row-keys-avoid \nBest practices says b isn't a good idea","comments":[{"comment_id":"786767","poster":"maci_f","upvote_count":"2","timestamp":"1674583380.0","content":"But that only applies to using only the plain timestamp. With the reversed timestamp, the situation is different -- reversing the timestamp prevents creating hotspots. \n\nFor the very same reason, the article also recommends to avoid sequential IDs as row-keys, but recommends using reversed IDs: \"A safer approach is to use a reversed version of the user's numeric ID, which spreads traffic more evenly across all of the nodes for your Bigtable table.\""}],"upvote_count":"1","timestamp":"1673289720.0","poster":"dconesoko"}],"poster":"TNT87"}],"timestamp":"1663055760.0","upvote_count":"1","poster":"TNT87"},{"poster":"Wasss123","content":"Selected Answer: B\nI choose B \nReversed timestamp is better than using timestamp in schema design","timestamp":"1663012500.0","upvote_count":"1","comment_id":"667415"},{"poster":"Thobm","timestamp":"1663000680.0","content":"Selected Answer: B\nB avoids hotspots (\"major indices\" is a small number, so we'd have a couple of hotspots otherwise), and follows BigTable best practices for one single table: https://cloud.google.com/bigtable/docs/schema-design","comment_id":"667229","upvote_count":"2"},{"timestamp":"1662343620.0","poster":"nwk","comment_id":"659666","content":"Vote D for the most recent stock price\nhttps://fullstackchronicles.io/cloud-bigtable-primer-part-ii-row-key-selection-and-schema-design","comments":[{"poster":"nwk","comment_id":"659669","upvote_count":"1","content":"2nd thought, D is missing Stock Symbol as part of the row key, #stock#reverst TS","timestamp":"1662343860.0"}],"upvote_count":"2"},{"comment_id":"658111","timestamp":"1662184380.0","upvote_count":"2","content":"Selected Answer: A\nA according to the documentation\n\nhttps://cloud.google.com/bigtable/docs/schema-design#tables","poster":"ducc"},{"upvote_count":"4","comment_id":"657808","content":"Selected Answer: A\nA. Create one unique table for all of the indices, and then use the index and timestamp as the row key design.\n\nIf you put a timestamp in a row key, precede it with a high-cardinality value like a stock ID to avoid hotspots. Also, store datasets with similar schemas in the same table, rather than in separate tables. Sending requests to many different tables can increase backend connection overhead, resulting in increased tail latency. Having multiple tables of different sizes can disrupt the behind-the-scenes load balancing that makes Bigtable function well. You can simulate a reverse scan in BigTable to get the most recent additions to the table.\n\nReferences:\nhttps://cloud.google.com/bigtable/docs/reads\nhttps://cloud.google.com/bigtable/docs/schema-design","comments":[{"timestamp":"1663013040.0","poster":"Wasss123","comment_id":"667423","content":"Answer B : \nYou can read in the same resource you provided :\n\nIf you usually retrieve the most recent records first, you can use a reversed timestamp in the row key by subtracting the timestamp from your programming language's maximum value for long integers (in Java, java.lang.Long.MAX_VALUE). With a reversed timestamp, the records will be ordered from most recent to least recent.\nSo B is correct","upvote_count":"7"}],"timestamp":"1662150300.0","poster":"AWSandeep"}],"isMC":true,"answer_ET":"B","timestamp":"2022-09-02 22:25:00","answer_images":[],"topic":"1","answers_community":["B (42%)","A (38%)","D (20%)"],"question_images":[],"exam_id":11,"question_text":"You are using Bigtable to persist and serve stock market data for each of the major indices. To serve the trading application, you need to access only the most recent stock prices that are streaming in. How should you design your row key and tables to ensure that you can access the data with the simplest query?","answer":"B"},{"id":"9yp88zRdGaaJdW7Dj6Ng","choices":{"B":"Have a staging table that is an append-only model, and then update the production table every ninety minutes with the changes written to staging.","C":"Have a staging table that moves the staged data over to the production table and deletes the contents of the staging table every three hours.","D":"Have a staging table that moves the staged data over to the production table and deletes the contents of the staging table every thirty minutes.","A":"Have a staging table that is an append-only model, and then update the production table every three hours with the changes written to staging."},"answer_description":"","question_text":"You are building a report-only data warehouse where the data is streamed into BigQuery via the streaming API. Following Google's best practices, you have both a staging and a production table for the data. How should you design your data loading to ensure that there is only one master dataset without affecting performance on either the ingestion or reporting pieces?","question_images":[],"exam_id":11,"timestamp":"2022-09-02 22:36:00","isMC":true,"answer":"C","discussion":[{"content":"Selected Answer: C\n[C]\nI found the correct answer based on a real case, where Google's Solutions Architect team decided to move an internal process to use BigQuery.\nThe related doc is here: https://cloud.google.com/blog/products/data-analytics/moving-a-publishing-workflow-to-bigquery-for-new-data-insights","upvote_count":"20","timestamp":"1667742000.0","comment_id":"712330","poster":"NicolasN","comments":[{"comment_id":"712331","upvote_count":"18","timestamp":"1667742000.0","comments":[{"poster":"squishy_fishy","timestamp":"1698018960.0","comment_id":"1051247","upvote_count":"2","content":"I second this. At my work, I run into this exact steaming buffer thing, it will not let me delete the data until after 60 minutes."},{"comment_id":"763281","upvote_count":"1","timestamp":"1672594080.0","poster":"AzureDP900","content":"Agreed C is right"}],"poster":"NicolasN","content":"The interesting excerpts:\n\"Following common extract, transform, load (ETL) best practices, we used a staging table and a separate production table so that we could load data into the staging table without impacting users of the data. The design we created based on ETL best practices called for first deleting all the records from the staging table, loading the staging table, and then replacing the production table with the contents.\"\n\"When using the streaming API, the BigQuery streaming buffer remains active for about 30 to 60 minutes or more after use, which means that you can’t delete or change data during that time. Since we used the streaming API, we scheduled the load every three hours to balance getting data into BigQuery quickly and being able to subsequently delete the data from the staging table during the load process.\""}]},{"comments":[{"timestamp":"1671187680.0","content":"Aren't there other aspects of data pipelining that we should be aware of? other than merely referring to the number of 'recommended' minutes stated in docs. B doesn't address how the appended data is subsequently deleted, since the table is append-only, the size will constantly grow, and so the user may unnecessarily incur more storage costs.","poster":"jkhong","upvote_count":"1","comment_id":"747068"},{"timestamp":"1662460140.0","upvote_count":"1","poster":"YorelNation","content":"They don't seems concerned too much by data accuracy in the question","comment_id":"661089"},{"comment_id":"687018","content":"A and B are discarded because the UPDATE statement, is not performance efficient. Neither appending more and more values to the stagging table. It's better cleaning the stagging table, and merging with the master dataset.","comments":[{"content":"You can use BigQuery's features like MERGE to efficiently update the production table with only the new or changed data from the staging table, reducing processing time and costs.","timestamp":"1703152200.0","comment_id":"1102326","upvote_count":"1","poster":"MaxNRG"}],"poster":"devaid","upvote_count":"4","timestamp":"1664985900.0"}],"poster":"nwk","upvote_count":"11","content":"Vote B - \"Some recently streamed rows might not be available for table copy typically for a few minutes. In rare cases, this can take up to 90 minutes\"\nhttps://cloud.google.com/bigquery/docs/streaming-data-into-bigquery#dataavailability","comment_id":"659676","timestamp":"1662344400.0"},{"poster":"SamuelTsch","content":"Selected Answer: A\ndeleting data from my point of view is not a good practice to build datawarehouse solutions. So, C and D are excluded. \naccording to the official documentation, the updating/merging process could last till 90 minutes. 3 hours could be enough.","timestamp":"1730112120.0","upvote_count":"5","comment_id":"1303927"},{"poster":"TVH_Data_Engineer","upvote_count":"5","comment_id":"1217320","timestamp":"1716540360.0","content":"Selected Answer: A\nAn append-only staging table ensures that all incoming data is captured without risk of data loss or overwrites, which is crucial for maintaining data integrity in a streaming ingestion scenario.\nThree-Hour Update Interval:\n\nUpdating the production table every three hours strikes a good balance between minimizing the latency of data availability for reporting and reducing the frequency of potentially resource-intensive update operations.\nThis interval is frequent enough to keep the production table relatively up-to-date for reporting purposes while ensuring that the performance of both ingestion and reporting processes is not significantly impacted.\nFrequent updates (like every ninety minutes or every thirty minutes) could introduce unnecessary overhead and contention, especially if the dataset is large or if there are complex transformations involved."},{"comment_id":"1102328","timestamp":"1703152380.0","poster":"MaxNRG","content":"Selected Answer: A\nNot C nor D. Moving and deleting: \nDeleting data from the staging table every 3 or 30 minutes could lead to data loss if the production table update fails, and it also requires more frequent and potentially resource-intensive operations.\n\nOptions C and D cause rebuilding of the staging table, which slows down ingestion, and may lose data if errors occur during recreation.\n\nA or B","upvote_count":"3","comments":[{"poster":"MaxNRG","content":"When designing a report-only data warehouse in BigQuery, where data is streamed in and you have both staging and production tables, the key is to balance the frequency of updates with the performance needs of both the ingestion and reporting processes. Let's evaluate each option:","comments":[{"comments":[{"upvote_count":"1","poster":"MaxNRG","timestamp":"1703152440.0","comments":[{"timestamp":"1703152500.0","comment_id":"1102333","poster":"MaxNRG","upvote_count":"2","content":"Considering these options, A (Staging table as append-only, updating production every three hours) seems to be the most balanced approach. It provides a good compromise between having up-to-date data in the production environment and maintaining system performance. However, the exact frequency should be fine-tuned based on the specific performance characteristics of your system and the timeliness requirements of your reports.\n\nIt's also important to implement efficient mechanisms for transferring data from staging to production to minimize the impact on system performance. Techniques like partitioning and clustering in BigQuery can be used to optimize query performance and manage large datasets more effectively."}],"comment_id":"1102332","content":"C. Staging table moves data to production and clears staging every three hours: Moving data from staging to production and then clearing the staging table ensures that there is only one master dataset. However, this method might lead to more significant interruptions in data availability, both during the move and the clearing process. This might not be ideal if continuous access to the latest data is required.\n\nD. Staging table moves data to production and clears staging every thirty minutes: This option provides the most up-to-date data in the production table but could significantly impact performance. Such frequent data transfers and deletions might lead to more overhead and could interrupt both the ingestion and reporting processes."}],"comment_id":"1102331","content":"A. Staging table as append-only, updating production every three hours: This approach allows for a consistent flow of data into the staging table without interruptions. Updating the production table every three hours strikes a balance between having reasonably fresh data and not overloading the system with too frequent updates. However, this may not be suitable if your reporting requirements demand more up-to-date data.\n\nB. Staging table as append-only, updating production every ninety minutes: This is similar to option A but with a more frequent update cycle. This could be more appropriate if your reporting needs require more current data. However, more frequent updates can impact performance, especially during the update windows.","timestamp":"1703152440.0","upvote_count":"1","poster":"MaxNRG"}],"upvote_count":"1","timestamp":"1703152380.0","comment_id":"1102330"}]},{"poster":"Aman47","timestamp":"1702567200.0","comment_id":"1096588","upvote_count":"1","content":"Neither. In the current scenario, DataStream (a new google resource) captures the CDC data and uses Dataflow to Replicate the changes to big query."},{"comments":[{"comments":[],"comment_id":"734936","timestamp":"1670141760.0","upvote_count":"2","poster":"hauhau","content":"B just say \"update\", not specificlly mention DML. update can be merge"}],"content":"Selected Answer: B\nVote B\n C : the doc says streaming data can be used up to 90 minutes not 3 hours\n B : correct , insert staging table first with append\nand use merge from staging into production table","comment_id":"734934","timestamp":"1670141580.0","upvote_count":"2","poster":"hauhau"},{"poster":"zellck","comment_id":"730432","upvote_count":"7","timestamp":"1669728000.0","content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/blog/products/data-analytics/moving-a-publishing-workflow-to-bigquery-for-new-data-insights\nFollowing common extract, transform, load (ETL) best practices, we used a staging table and a separate production table so that we could load data into the staging table without impacting users of the data. The design we created based on ETL best practices called for first deleting all the records from the staging table, loading the staging table, and then replacing the production table with the contents. \n\nWhen using the streaming API, the BigQuery streaming buffer remains active for about 30 to 60 minutes or more after use, which means that you can’t delete or change data during that time. Since we used the streaming API, we scheduled the load every three hours to balance getting data into BigQuery quickly and being able to subsequently delete the data from the staging table during the load process."},{"poster":"Atnafu","comment_id":"725554","upvote_count":"3","content":"C\nFollowing common extract, transform, load (ETL) best practices, we used a staging table and a separate production table so that we could load data into the staging table without impacting users of the data. The design we created based on ETL best practices called for first deleting all the records from the staging table, loading the staging table, and then replacing the production table with the contents. \n\nWhen using the streaming API, the BigQuery streaming buffer remains active for about 30 to 60 minutes or more after use, which means that you can’t delete or change data during that time. Since we used the streaming API, we scheduled the load every three hours to balance getting data into BigQuery quickly and being able to subsequently delete the data from the staging table during the load process.\nBuilding a script with BigQuery on the back end\nhttps://cloud.google.com/blog/products/data-analytics/moving-a-publishing-workflow-to-bigquery-for-new-data-insights","timestamp":"1669264260.0"},{"timestamp":"1664869380.0","comment_id":"685996","comments":[{"comment_id":"686004","upvote_count":"1","poster":"John_Pongthorn","timestamp":"1664869860.0","content":"https://cloud.google.com/architecture/database-replication-to-bigquery-using-change-data-capture#prune_merged_data\n\nhttps://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language#limitations"}],"content":"Selected Answer: C\nD : read more on Streaming inserts and timestamp-aware queries as the following link\nit is the same as this question exactly, but it is quite similar.\nhttps://cloud.google.com/blog/products/bigquery/performing-large-scale-mutations-in-bigquery\n\nread carefully in the content below.\nWhen using timestamps to keep track of updated and deleted records, it’s a good idea to periodically delete stale entries. To illustrate, the following pair of DML statements can be used to remove older versions as well as deleted records.\n\nYou’ll notice that the above DELETE statements don’t attempt to remove records that are newer than 3 hours. This is because data in BigQuery’s streaming buffer is not immediately available for UPDATE, DELETE, or MERGE operations, as described in DML Limitations. These queries assume that the actual values for RecordTime roughly match the actual ingestion time.","upvote_count":"4","poster":"John_Pongthorn"},{"content":"Either C or D But When will we delete stale data on staging table ? Every xxx???? \nhttps://cloud.google.com/architecture/database-replication-to-bigquery-using-change-data-capture#prune_merged_data","comment_id":"679649","comments":[{"poster":"Oleksandr0501","content":"gpt: \"Overall, deleting the staging table every 30 minutes is a better choice than every 3 hours because it reduces the risk of data inconsistencies and performance issues.\"","timestamp":"1683727260.0","upvote_count":"1","comment_id":"894053"}],"upvote_count":"1","timestamp":"1664190300.0","poster":"John_Pongthorn"},{"poster":"TNT87","comment_id":"662157","content":"Selected Answer: D\nD. Have a staging table that moves the staged data over to the production table and deletes the contents of the staging table every thirty minutes.","upvote_count":"2","timestamp":"1662535320.0"},{"timestamp":"1662535260.0","poster":"TNT87","comment_id":"662155","content":"Ans D\nD. Have a staging table that moves the staged data over to the production table and deletes the contents of the staging table every thirty minutes.","upvote_count":"1"},{"comment_id":"657824","timestamp":"1662150960.0","upvote_count":"2","content":"Selected Answer: D\nD. Have a staging table that moves the staged data over to the production table and deletes the contents of the staging table every thirty minutes.","poster":"AWSandeep"}],"topic":"1","unix_timestamp":1662150960,"url":"https://www.examtopics.com/discussions/google/view/79593-exam-professional-data-engineer-topic-1-question-184/","answer_images":[],"answers_community":["C (62%)","A (26%)","8%"],"answer_ET":"C","question_id":95}],"exam":{"name":"Professional Data Engineer","lastUpdated":"11 Apr 2025","numberOfQuestions":319,"id":11,"isBeta":false,"isMCOnly":true,"isImplemented":true,"provider":"Google"},"currentPage":19},"__N_SSP":true}