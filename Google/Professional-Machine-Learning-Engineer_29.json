{"pageProps":{"questions":[{"id":"wlInzyc2rtDaYUilxT14","topic":"1","answer_images":[],"answer":"D","question_id":141,"choices":{"A":"Determine whether there is a meaningful correlation between the sensitive features and the other features. Train a BigQuery ML boosted trees classification model and exclude the sensitive features and any meaningfully correlated features.","D":"Define a fairness metric that is represented by accuracy across the sensitive features. Train a BigQuery ML boosted trees classification model with all features. Use the trained model to make predictions on a test set. Join the data back with the sensitive features, and calculate a fairness metric to investigate whether it meets your requirements.","C":"Train a BigQuery ML boosted trees classification model with all features. Use the ML.EXPLAIN_PREDICT method to calculate the attribution values for each feature for each customer in a test set. If for any individual customer, the importance value for any feature exceeds a predefined threshold, discard the model and train the model again without this feature.","B":"Train a BigQuery ML boosted trees classification model with all features. Use the ML.GLOBAL_EXPLAIN method to calculate the global attribution values for each feature of the model. If the feature importance value for any of the sensitive features exceeds a threshold, discard the model and tram without this feature."},"isMC":true,"question_text":"You work for a telecommunications company. You’re building a model to predict which customers may fail to pay their next phone bill. The purpose of this model is to proactively offer at-risk customers assistance such as service discounts and bill deadline extensions. The data is stored in BigQuery and the predictive features that are available for model training include:\n\n- Customer_id\n- Age\n- Salary (measured in local currency)\n- Sex\n- Average bill value (measured in local currency)\n- Number of phone calls in the last month (integer)\n- Average duration of phone calls (measured in minutes)\n\nYou need to investigate and mitigate potential bias against disadvantaged groups, while preserving model accuracy.\n\nWhat should you do?","answers_community":["D (100%)"],"question_images":[],"timestamp":"2024-01-13 07:27:00","discussion":[{"content":"Selected Answer: D\nFairness Metric: Defining a metric like parity (equal accuracy) or calibration (similar predicted probabilities) across sensitive features like age, sex, or salary allows you to quantify potential bias.\nModel Training with All Features (Initially): Training the model with all features provides a baseline performance and allows you to identify potentially biased features later.\nTest Set Predictions: Making predictions on a held-out test set ensures the evaluation is based on unseen data and avoids overfitting.\nJoining Back Sensitive Features: Reintroducing sensitive features after prediction allows you to calculate fairness metrics for different customer groups.\nIterative Refinement: Based on the fairness metric results, you can determine if further mitigation strategies are needed.","timestamp":"1729234620.0","poster":"fitri001","comment_id":"1197758","comments":[{"upvote_count":"1","timestamp":"1729234680.0","poster":"fitri001","content":"A. Excluding Features Based on Correlation: While correlated features might indicate bias, simply excluding them can discard valuable information and potentially reduce model accuracy.\nB. Global Attribution for Feature Removal: Using global feature importance might not reveal bias impacting specific customer groups. Additionally, discarding a feature solely based on importance could affect model performance.\nC. Individual Attribution for Model Discarding: While individual attribution can identify per-customer bias, discarding the model entirely based on a single instance might be overly cautious and lead to starting from scratch frequently.","comment_id":"1197759"}],"upvote_count":"3"},{"poster":"pinimichele01","upvote_count":"1","content":"Selected Answer: D\nhttps://cloud.google.com/vertex-ai/docs/evaluation/intro-evaluation-fairness","timestamp":"1728382440.0","comment_id":"1191501"},{"comment_id":"1170806","content":"Answer is A","timestamp":"1726024980.0","poster":"prtikare","upvote_count":"1"},{"upvote_count":"1","timestamp":"1721246580.0","comment_id":"1125376","poster":"shadz10","content":"Selected Answer: D\nhttps://cloud.google.com/vertex-ai/docs/evaluation/intro-evaluation-fairness"},{"content":"Selected Answer: D\nDirect Bias Assessment: It directly measures model fairness using a relevant metric, providing clear insights into potential issues.\nPreserving Information: It avoids prematurely removing features, potentially capturing valuable predictive signals while mitigating bias.\nAligning with Goals: It allows tailoring the fairness metric to specific ethical and business objectives.","comment_id":"1121343","poster":"pikachu007","upvote_count":"2","timestamp":"1720844820.0"}],"exam_id":13,"url":"https://www.examtopics.com/discussions/google/view/131049-exam-professional-machine-learning-engineer-topic-1-question/","answer_ET":"D","answer_description":"","unix_timestamp":1705127220},{"id":"g39FmftI5N05lTlU5keh","question_images":[],"answer_ET":"D","unix_timestamp":1705127700,"answer_description":"","answers_community":["D (71%)","B (29%)"],"question_id":142,"timestamp":"2024-01-13 07:35:00","answer":"D","topic":"1","choices":{"B":"Build a Flask-based app, package the app and a pickled model in a custom container image, and deploy the model to Vertex AI Endpoints.","D":"Build a custom predictor class based on XGBoost Predictor from the Vertex AI SDK, and package the handler in a custom container image based on a Vertex built-in container image. Store a pickled model in Cloud Storage, and deploy the model to Vertex AI Endpoints.","A":"Store a pickled model in Cloud Storage. Build a Flask-based app, package the app in a custom container image, and deploy the model to Vertex AI Endpoints.","C":"Build a custom predictor class based on XGBoost Predictor from the Vertex AI SDK, package it and a pickled model in a custom container image based on a Vertex built-in image, and deploy the model to Vertex AI Endpoints."},"question_text":"You recently trained a XGBoost model that you plan to deploy to production for online inference. Before sending a predict request to your model’s binary, you need to perform a simple data preprocessing step. This step exposes a REST API that accepts requests in your internal VPC Service Controls and returns predictions. You want to configure this preprocessing step while minimizing cost and effort. What should you do?","answer_images":[],"isMC":true,"discussion":[{"timestamp":"1733090340.0","content":"Selected Answer: B\nOption B is simpler (Flask app handles preproc directly) and less costly (Storage within the container)\n*** Storing the pickled model in Cloud Storage adds network calls during prediction, increasing latency and cost.\n***The XGBoost Predictor (C & D) task adds unneeded complexity to a simple preprocessing task","upvote_count":"2","comment_id":"1320721","poster":"lunalongo"},{"timestamp":"1713397500.0","comment_id":"1197577","comments":[{"upvote_count":"3","comment_id":"1197578","timestamp":"1713397500.0","poster":"fitri001","content":"why D?\nReduced Code Footprint: You only need to write the custom predictor logic, not a full Flask application. This minimizes development effort and container size.\nLeverages Vertex AI Features: By using the XGBoost Predictor from the Vertex AI SDK, you benefit from pre-built functionality for handling XGBoost models.\nCost-Effective Deployment: Utilizing Vertex built-in container images reduces the need for custom image maintenance and potentially lowers container runtime costs.\nSeparate Model Storage: Storing the pickled model in Cloud Storage keeps the model separate from the prediction logic, allowing for easier model updates without redeploying the entire container."}],"poster":"fitri001","content":"Selected Answer: D\nwhy not c?\nWhile it utilizes the XGBoost Predictor, packaging the pickled model in the container increases image size and requires redeploying the container for model updates.","upvote_count":"3"},{"poster":"guilhermebutzke","timestamp":"1708299300.0","upvote_count":"1","content":"Selected Answer: D\nMy Answer: D\n\nThis option involves using the Vertex AI SDK to build a custom predictor class, which allows for easy integration with the XGBoost model. Packaging the handler in a custom container image based on a Vertex built-in container image ensures compatibility and smooth deployment. Storing the pickled model in Cloud Storage provides a scalable and reliable way to access the model. Deploying the model to Vertex AI Endpoints allows for easy management and scaling of inference requests, while minimizing cost and effort.\n\nThe main difference between C and D is where the model is saved. So, is a good practice to save models in GCS because Separation of Concerns, Flexibility, and Reduced Image Size","comment_id":"1153624"},{"poster":"pikachu007","comment_id":"1121344","timestamp":"1705127700.0","upvote_count":"1","content":"Selected Answer: D\nMinimal Custom Code: Leverages the pre-built XGBoost Predictor class for core model prediction, reducing development effort and potential errors.\nOptimized Container Image: Utilizes a Vertex built-in container image, pre-configured for efficient model serving and compatibility with Vertex AI Endpoints.\nSeparated Model Storage: Stores the model in Cloud Storage, reducing container image size and simplifying model updates independently of the container.\nVPC Service Controls: Vertex AI Endpoints support VPC Service Controls, ensuring adherence to internal traffic restrictions."}],"url":"https://www.examtopics.com/discussions/google/view/131050-exam-professional-machine-learning-engineer-topic-1-question/","exam_id":13},{"id":"ibV33k4fa20NUe7vwBDg","isMC":true,"question_id":143,"question_images":[],"answer_description":"","exam_id":13,"answer":"A","choices":{"C":"Use Vertex Explainable AI with the XRAI method, and enable Vertex AI Model Monitoring to check for feature distribution drift.","B":"Use Vertex Explainable AI with the sampled Shapley method, and enable Vertex AI Model Monitoring to check for feature distribution skew.","D":"Use Vertex Explainable AI with the XRAI method, and enable Vertex AI Model Monitoring to check for feature distribution skew.","A":"Use Vertex Explainable AI with the sampled Shapley method, and enable Vertex AI Model Monitoring to check for feature distribution drift."},"answers_community":["A (100%)"],"question_text":"You work at a bank. You need to develop a credit risk model to support loan application decisions. You decide to implement the model by using a neural network in TensorFlow. Due to regulatory requirements, you need to be able to explain the model’s predictions based on its features. When the model is deployed, you also want to monitor the model’s performance over time. You decided to use Vertex AI for both model development and deployment. What should you do?","answer_ET":"A","answer_images":[],"unix_timestamp":1704876060,"discussion":[{"upvote_count":"9","content":"Selected Answer: A\nNot image -> not XRAI\nPerformance over time -> drift, not skew","timestamp":"1721133540.0","comment_id":"1124284","poster":"b1a8fae"},{"content":"Selected Answer: A\nwhy not the others?\nB. Feature Distribution Skew: While skew can be relevant, drift is generally a more significant concern for credit risk models. Drift indicates a change in the underlying data distribution, potentially impacting model performance.\nC & D. XRAI Method: XRAI (Explainable AI for Images) is specifically designed for interpreting image classification models. It wouldn't be the most effective choice for a neural network-based credit risk model working with tabular data.","timestamp":"1729209120.0","poster":"fitri001","comment_id":"1197580","comments":[{"comment_id":"1197581","upvote_count":"1","poster":"fitri001","content":"Vertex Explainable AI: This is a built-in Vertex AI feature that helps understand how features contribute to model predictions.\nSampled Shapley Method: This is a well-suited method for explaining complex models like neural networks. It provides insights into feature importance without requiring retraining the entire model.","timestamp":"1729209240.0"}],"upvote_count":"2"},{"upvote_count":"2","comment_id":"1118378","poster":"winston9","timestamp":"1720593660.0","content":"Selected Answer: A\nExplainable AI with the XRAI method is for unstructured, image region analysis, in this case we use structured data for loan approval analysis."}],"topic":"1","timestamp":"2024-01-10 09:41:00","url":"https://www.examtopics.com/discussions/google/view/130773-exam-professional-machine-learning-engineer-topic-1-question/"},{"id":"TrKCy3QWz2xGCvFBFpB3","unix_timestamp":1705128120,"topic":"1","answer_images":[],"isMC":true,"discussion":[{"timestamp":"1729209420.0","content":"Selected Answer: B\nVertex AI Metadata Lineage: This feature tracks the relationships between pipeline components and the artifacts they produce. By identifying the model version's lineage, you can pinpoint the specific pipeline run that generated it.\nData Copy Step: Within the pipeline run, locate the step responsible for creating the data copy in TFRecord format for training.\nMetadata Search: Vertex AI Metadata likely stores information about the data copy's location in Cloud Storage, allowing you to access it.","poster":"fitri001","comments":[{"poster":"fitri001","timestamp":"1729209480.0","content":"A. Feature Store: Feature Store is designed for managing feature engineering and serving preprocessed features, not necessarily raw training data. While it could be a good practice for future pipelines, it wouldn't help recover historical data.\nC. Endpoint Logs: Endpoint logs primarily focus on model deployment details and might not provide information about the specific training data used for a particular version.\nD. Training Job Logs: Training job logs might contain references to the data used, but they might not be as detailed or structured as Vertex AI Metadata lineage, making it harder to pinpoint the exact data copy location.","upvote_count":"1","comment_id":"1197585"}],"upvote_count":"4","comment_id":"1197583"},{"timestamp":"1728382800.0","upvote_count":"1","content":"Selected Answer: B\nagree with shadz10 and pikachu007","poster":"pinimichele01","comment_id":"1191505"},{"upvote_count":"2","content":"Selected Answer: B\nhttps://cloud.google.com/vertex-ai/docs/ml-metadata/introduction","poster":"shadz10","timestamp":"1721248140.0","comment_id":"1125391"},{"timestamp":"1720845720.0","poster":"pikachu007","upvote_count":"3","comment_id":"1121345","content":"Selected Answer: B\nA. Feature Store: While useful for managing features, it might not store complete training datasets, and modifying the pipeline would not help recover historical data.\nC. Endpoint Logs and Pipeline Run: This approach involves more manual searching and might be less precise for identifying the exact data copy.\nD. Training Job Logs: Training job logs might not reliably contain complete data paths or might be purged after a certain period."}],"question_id":144,"choices":{"C":"Use the logging features in the Vertex AI endpoint to determine the timestamp of the model’s deployment. Find the pipeline run at that timestamp. Identify the step that creates the data copy, and search in the logs for its location.","A":"Use Vertex AI Feature Store. Modify the pipeline to use the feature store, and ensure that all training data is stored in it. Search the feature store for the data used for the training.","D":"Find the job ID in Vertex AI Training corresponding to the training for the model. Search in the logs of that job for the data used for the training.","B":"Use the lineage feature of Vertex AI Metadata to find the model artifact. Determine the version of the model and identify the step that creates the data copy and search in the metadata for its location."},"answer_ET":"B","answer":"B","answer_description":"","question_images":[],"exam_id":13,"question_text":"You are investigating the root cause of a misclassification error made by one of your models. You used Vertex AI Pipelines to train and deploy the model. The pipeline reads data from BigQuery. creates a copy of the data in Cloud Storage in TFRecord format, trains the model in Vertex AI Training on that copy, and deploys the model to a Vertex AI endpoint. You have identified the specific version of that model that misclassified, and you need to recover the data this model was trained on. How should you find that copy of the data?","answers_community":["B (100%)"],"timestamp":"2024-01-13 07:42:00","url":"https://www.examtopics.com/discussions/google/view/131051-exam-professional-machine-learning-engineer-topic-1-question/"},{"id":"NAkTjxHKfJn6Vm5a9OdY","unix_timestamp":1705404660,"isMC":true,"answer_images":[],"topic":"1","discussion":[{"poster":"rajshiv","timestamp":"1733173800.0","upvote_count":"2","content":"Selected Answer: A\nA is the best answer among the choices. Integrated gradient and pixel visualization is the best alternative among the choices given.","comment_id":"1321101"},{"timestamp":"1728798240.0","comment_id":"1296734","poster":"YangG","content":"Selected Answer: D\nIt is to understand why model is making specific mistakes, so example-based explanation makes sense to me.","upvote_count":"2"},{"content":"Selected Answer: D\nhttps://cloud.google.com/vertex-ai/docs/explainable-ai/overview#example-based\n\n\"Improve your data or model: One of the core use cases for example-based explanations is helping you understand why your model made certain mistakes in its predictions, and using those insights to improve your data or model. [...]\n\nFor example, suppose we have a model that classifies images as either a bird or a plane, and that it is misclassifying the following bird as a plane with high confidence. You can use Example-based explanations to retrieve similar images from the training set to figure out what is happening.\"\n\nNot A: Integrated Gradients is recommended for low-contrast images, such as X-rays\nhttps://cloud.google.com/vertex-ai/docs/explainable-ai/overview#compare-methods\n\nNot C: Cannot set Outlines for XRAI\nhttps://cloud.google.com/ai-platform/prediction/docs/ai-explanations/visualizing-explanations","timestamp":"1725206400.0","comment_id":"1276153","poster":"eico","upvote_count":"3"},{"content":"Selected Answer: D\nImprove your data or model: One of the core use cases for example-based explanations is helping you understand why your model made certain mistakes in its predictions, and using those insights to improve your data or model.\n\nhttps://cloud.google.com/vertex-ai/docs/explainable-ai/overview","comment_id":"1174105","upvote_count":"4","timestamp":"1710487440.0","poster":"VipinSingla"},{"comment_id":"1151239","upvote_count":"4","poster":"guilhermebutzke","content":"My Answer: A\n\nAccording to this documentation:\n\nhttps://cloud.google.com/vertex-ai/docs/explainable-ai/visualization-settings\n\nThis option A aligns with using Integrated Gradients, which is suitable for feature-based explanations. Setting the visualization type to PIXELS allows for per-pixel attribution, which can help in understanding the specific regions of the image influencing the model's decision. Additionally, setting the clip_percent_upperbound parameter to 95 helps in filtering out noise and focusing on areas of strong attribution, which is crucial for understanding mislabeled images with high confidence.\n\nOption C suggests using XRAI for feature-based explanations and setting the visualization type to OUTLINES, along with setting the polarity to positive. However, based on the provided documentation, XRAI is recommended to have its visualization type set to PIXELS, not OUTLINES.","timestamp":"1708022760.0"},{"content":"Selected Answer: A\nAlthough Xrai could be an option, it doesn't not allow you to set those options, so only other answer is A\nhttps://cloud.google.com/vertex-ai/docs/explainable-ai/visualization-settings#visualization_options","timestamp":"1706691360.0","poster":"sonicclasps","upvote_count":"2","comments":[{"upvote_count":"1","content":"Why not it's D? \nhttps://cloud.google.com/vertex-ai/docs/explainable-ai/overview","comments":[{"upvote_count":"2","timestamp":"1707009720.0","content":"For example, suppose we have a model that classifies images as either a bird or a plane, and that it is misclassifying the following bird as a plane with high confidence. You can use Example-based explanations to retrieve similar images from the training set to figure out what is happening.","comments":[{"comment_id":"1141053","timestamp":"1707134760.0","poster":"sonicclasps","content":"yes you are correct, but having to specify the output layer to be used is definitely no guarantee that you'll get examples that are easily interpretable (imo)","upvote_count":"1"}],"poster":"vaibavi","comment_id":"1139708"}],"comment_id":"1139707","poster":"vaibavi","timestamp":"1707009600.0"}],"comment_id":"1136551"},{"content":"Selected Answer: A\nGoing with A\nNot c - For XRAI, Pixels is the default setting and shows areas of attribution. Outlines is not recommended for XRAI.\nhttps://cloud.google.com/ai-platform/prediction/docs/ai-explanations/visualizing-explanations","poster":"shadz10","timestamp":"1705404660.0","upvote_count":"2","comment_id":"1124142"}],"question_id":145,"choices":{"C":"Configure feature-based explanations by using XRAI. Set visualization type to OUTLINES, and set polarity to positive.","B":"Create an index by using Vertex AI Matching Engine. Query the index with your mislabeled images.","D":"Configure example-based explanations. Specify the embedding output layer to be used for the latent space representation.","A":"Configure feature-based explanations by using Integrated Gradients. Set visualization type to PIXELS, and set clip_percent_upperbound to 95."},"answer_ET":"D","answer":"D","answer_description":"","question_images":[],"exam_id":13,"question_text":"You work for a manufacturing company. You need to train a custom image classification model to detect product defects at the end of an assembly line. Although your model is performing well, some images in your holdout set are consistently mislabeled with high confidence. You want to use Vertex AI to understand your model’s results. What should you do?","answers_community":["D (60%)","A (40%)"],"timestamp":"2024-01-16 12:31:00","url":"https://www.examtopics.com/discussions/google/view/131297-exam-professional-machine-learning-engineer-topic-1-question/"}],"exam":{"numberOfQuestions":304,"provider":"Google","isImplemented":true,"id":13,"lastUpdated":"11 Apr 2025","name":"Professional Machine Learning Engineer","isMCOnly":true,"isBeta":false},"currentPage":29},"__N_SSP":true}