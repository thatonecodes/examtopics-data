{"pageProps":{"questions":[{"id":"148BGYTx5iDuZ1rFq9Ak","url":"https://www.examtopics.com/discussions/google/view/69756-exam-professional-cloud-developer-topic-1-question-135/","question_id":41,"topic":"1","unix_timestamp":1641740220,"exam_id":7,"question_text":"You manage an ecommerce application that processes purchases from customers who can subsequently cancel or change those purchases. You discover that order volumes are highly variable and the backend order-processing system can only process one request at a time. You want to ensure seamless performance for customers regardless of usage volume. It is crucial that customers' order update requests are performed in the sequence in which they were generated. What should you do?","answer":"C","answer_images":[],"question_images":[],"discussion":[{"comments":[{"content":"Agreed considering only one request can be processed at a time","poster":"Blueocean","comments":[{"comment_id":"530677","poster":"Blueocean","upvote_count":"3","timestamp":"1642955460.0","content":"And there are a large number of incoming requests Pub Sub is needed"}],"upvote_count":"2","timestamp":"1642955400.0","comment_id":"530674"}],"timestamp":"1641740220.0","upvote_count":"9","content":"I vote C\nhttps://cloud.google.com/pubsub/docs/pull","comment_id":"520262","poster":"scaenruy"},{"upvote_count":"1","poster":"mrgarfield","content":"Selected Answer: D\nWhy the other options are not as suitable:\n\nOption A: WebSockets provide real-time communication, but they might not be suitable for all scenarios, especially if the backend needs to process requests asynchronously.\nOption B: Using REST requests directly can lead to performance bottlenecks under high load, as the backend might become overwhelmed with requests.\nOption C: A Pub/Sub subscriber in pull mode requires the frontend to actively poll for messages, which can introduce latency and overhead.","timestamp":"1725549060.0","comment_id":"1279016"},{"poster":"__rajan__","timestamp":"1695351540.0","content":"Selected Answer: C\nC is correct.","comment_id":"1013534","upvote_count":"1"},{"timestamp":"1691255280.0","content":"Selected Answer: C\nPull model so that application handle the requests by pulling requests one by one. This is called event driven architecture where the response to client from the app will happen asynchronously.","comment_id":"973218","poster":"purushi","upvote_count":"1"},{"timestamp":"1673442300.0","content":"Selected Answer: C\nC. Use a Pub/Sub subscriber in pull mode and use a data store to manage ordering.\n\nTo ensure that customer order update requests are performed in the sequence in which they were generated, the recommended approach is to use a Pub/Sub subscriber in pull mode, together with a data store to manage ordering.\nThis approach allows the backend system to process requests one at a time, while maintaining the order of requests. By using a pull-based subscription, the backend system can control the rate at which messages are consumed from the Pub/Sub topic, and can ensure that requests are processed in the correct order. The data store can be used to maintain a queue of requests, where each request is added to the queue in the order that it was generated, and then processed by the backend system.","poster":"omermahgoub","comment_id":"772532","upvote_count":"1","comments":[{"content":"A. Send the purchase and change requests over WebSockets to the backend.\nWebSockets are a protocol for bidirectional communication between a client and server, it may not ensure that requests are processed in the order they were generated.\n\nB. Send the purchase and change requests as REST requests to the backend.\nSending the request as REST does not ensure that requests are processed in the order they were generated, it also would not allow controlling the rate at which requests are consumed.\n\nD. Use a Pub/Sub subscriber in push mode and use a data store to manage ordering.\nPush-based subscription don't allow controlling the rate at which requests are consumed, it also may not ensure that requests are processed in the order they were generated.","poster":"omermahgoub","upvote_count":"1","comment_id":"772533","timestamp":"1673442300.0"}]},{"upvote_count":"1","content":"Selected Answer: C\nC is the answer.","timestamp":"1671332220.0","poster":"zellck","comment_id":"748570"},{"comment_id":"649309","upvote_count":"2","content":"Selected Answer: C\nC is correct","poster":"tomato123","timestamp":"1660976400.0"},{"poster":"jdx000","timestamp":"1657631700.0","upvote_count":"1","comment_id":"630543","content":"Selected Answer: C\nCorrect answer C"}],"timestamp":"2022-01-09 15:57:00","answer_ET":"C","isMC":true,"choices":{"C":"Use a Pub/Sub subscriber in pull mode and use a data store to manage ordering.","A":"Send the purchase and change requests over WebSockets to the backend.","D":"Use a Pub/Sub subscriber in push mode and use a data store to manage ordering.","B":"Send the purchase and change requests as REST requests to the backend."},"answer_description":"","answers_community":["C (88%)","13%"]},{"id":"T3lSBbVxL88AP0pJ5IyD","topic":"1","question_id":42,"url":"https://www.examtopics.com/discussions/google/view/70393-exam-professional-cloud-developer-topic-1-question-136/","answer_images":[],"discussion":[{"upvote_count":"6","comment_id":"529593","content":"Agree with Option A \nhttps://cloud.google.com/datastore/docs/firestore-or-datastore","poster":"Blueocean","timestamp":"1674361740.0"},{"content":"Selected Answer: A\nThe answer is A. Firestore in Native mode.\n\nFirestore in Native mode is a NoSQL document database that is designed for scalability, performance, and ease of use. It is a good choice for storing customer purchase history because it meets all of the requirements","upvote_count":"1","timestamp":"1726974120.0","poster":"__rajan__","comment_id":"1013536"},{"content":"Selected Answer: A\nFirestore is for storing semi structured data. It is optimized for high reads and low writes. Since each document can store different collection types, ( MONGO DB ), fire store is suitable for the above requirements.","upvote_count":"2","timestamp":"1722938460.0","comment_id":"973702","poster":"purushi"},{"upvote_count":"1","timestamp":"1704978360.0","poster":"omermahgoub","comment_id":"772534","comments":[{"content":"B. Cloud Storage using an object read\nCloud Storage is an object storage service and it is not optimized for real-time queries as it does not support secondary indexes or SQL-like queries.\n\nC. Cloud SQL using a SQL SELECT statement\nCloud SQL is a relational database service that supports SQL statements and it would be possible to use SQL SELECT statements to sort purchase by different fields but it not optimized for real-time queries and the distinct record formats may be challenging to implement.\n\nD. Firestore in Datastore mode using a global query\nFirestore in Datastore mode is a previous generation of Firestore and it does not support the same level of query support and performance as Firestore in Native mode, it may also face challenges to support real-time query and distinct record formats.","timestamp":"1704978360.0","upvote_count":"1","poster":"omermahgoub","comment_id":"772535"}],"content":"Selected Answer: A\nA. Firestore in Native mode\n\nFirestore in Native mode satisfies these requirements. It is a NoSQL document database, which means that it stores semi-structured data, and each document can have its own fields and structure. This allows for storing distinct record formats at the same time, which is a requirement. Firestore also has strong query performance and support, customers can query their purchase immediately after submission, and purchases can be sorted on a variety of fields, it is highly optimized to support real-time queries, you can retrieve data with low latency."},{"comment_id":"748567","content":"Selected Answer: A\nA is the answer.","timestamp":"1702868100.0","poster":"zellck","upvote_count":"2"},{"upvote_count":"1","timestamp":"1693908900.0","content":"@megn they mean that each record can have a different shape, the data is not consistent.","poster":"[Removed]","comment_id":"660035"},{"content":"Selected Answer: A\nA is correct","comment_id":"649310","upvote_count":"2","poster":"tomato123","timestamp":"1692512400.0"},{"comment_id":"626862","poster":"nehaxlpb","timestamp":"1688449920.0","content":"Selected Answer: A\nFirestore is the next major version of Datastore and a re-branding of the product. Taking the best of Datastore and the Firebase Realtime Database, Firestore is a NoSQL document database built for automatic scaling, high performance, and ease of application development.\n\nFirestore introduces new features such as:\n\nA new, strongly consistent storage layer\nA collection and document data model\nReal-time updates\nMobile and Web client libraries\nFirestore is backwards compatible with Datastore, but the new data model, real-time updates, and mobile and web client library features are not. To access all of the new Firestore features, you must use Firestore in Native mode.","upvote_count":"3"},{"timestamp":"1685207340.0","upvote_count":"1","content":"What do they mean by \"Distinct record formats\"?","comment_id":"608154","poster":"[Removed]"},{"content":"firestore native mode:\nA new, strongly consistent storage layer\nA collection and document data model\nReal-time updates\nMobile and Web client libraries","comment_id":"603119","upvote_count":"3","timestamp":"1684376220.0","poster":"szl0144"}],"exam_id":7,"timestamp":"2022-01-22 05:29:00","answer_description":"","question_text":"Your company needs a database solution that stores customer purchase history and meets the following requirements:\n✑ Customers can query their purchase immediately after submission.\n✑ Purchases can be sorted on a variety of fields.\n✑ Distinct record formats can be stored at the same time.\nWhich storage option satisfies these requirements?","answer_ET":"A","unix_timestamp":1642825740,"answer":"A","isMC":true,"question_images":[],"answers_community":["A (100%)"],"choices":{"C":"Cloud SQL using a SQL SELECT statement","D":"Firestore in Datastore mode using a global query","B":"Cloud Storage using an object read","A":"Firestore in Native mode"}},{"id":"0VApz0UhaOVwc7wilsyn","answer_description":"","isMC":true,"url":"https://www.examtopics.com/discussions/google/view/69749-exam-professional-cloud-developer-topic-1-question-137/","unix_timestamp":1641738240,"choices":{"C":"Create a Cloud Task to generate a test load. Use Cloud Scheduler to run 60,000 Cloud Task transactions per minute for 10 minutes. Analyze the results using Cloud Monitoring.","A":"Build a test harness to generate requests and deploy it to Cloud Run. Analyze the VPC Flow Logs using Cloud Logging.","D":"Create a Compute Engine instance that uses a LAMP stack image from the Marketplace, and use Apache Bench to generate load tests against the service. Analyze the results using Cloud Trace.","B":"Create a Google Kubernetes Engine cluster running the Locust or JMeter images to dynamically generate load tests. Analyze the results using Cloud Trace."},"answer":"B","topic":"1","timestamp":"2022-01-09 15:24:00","discussion":[{"comment_id":"520249","poster":"scaenruy","content":"I vote B\nhttps://cloud.google.com/architecture/distributed-load-testing-using-gke","upvote_count":"7","timestamp":"1673274240.0"},{"comment_id":"1013538","content":"Selected Answer: B\nB is correct.","poster":"__rajan__","timestamp":"1726974420.0","upvote_count":"1"},{"timestamp":"1722938700.0","comment_id":"973705","poster":"purushi","upvote_count":"1","content":"Selected Answer: B\nThe key here is \"Your test infrastructure must be able to autoscale\" and load testing."},{"timestamp":"1704978480.0","content":"Selected Answer: B\nB. Create a Google Kubernetes Engine cluster running the Locust or JMeter images to dynamically generate load tests. Analyze the results using Cloud Trace.\n\nTo verify that your application can support up to 5,000 read and 1,000 write transactions per second and to identify any bottlenecks that occur, you can use a load testing tool such as Locust or JMeter to generate load tests on your Cloud Run service. These tools allow you to simulate a high number of concurrent requests and help you determine the maximum number of requests your service can handle.\n\nYou can run the load testing tool on a Google Kubernetes Engine (GKE) cluster which will support autoscale feature, this way you can handle the high number of requests, and use Cloud Trace to analyze the results, which will give you insights into the performance and any bottlenecks.","poster":"omermahgoub","upvote_count":"1","comment_id":"772536","comments":[{"comment_id":"772537","poster":"omermahgoub","upvote_count":"1","content":"A. Build a test harness to generate requests and deploy it to Cloud Run. Analyze the VPC Flow Logs using Cloud Logging.\nVPC flow logs would not provide the transaction details, it's more useful to troubleshoot issues at the network level.\n\nC. Create a Cloud Task to generate a test load. Use Cloud Scheduler to run 60,000 Cloud Task transactions per minute for 10 minutes. Analyze the results using Cloud Monitoring.\nAlthough cloud task is a good solution for scheduling the test loads, it's not the best solution for load testing since it doesn't support dynamic loading and it would be hard to get the fine-grained details about the performance.\n\nD. Create a Compute Engine instance that uses a LAMP stack image from the Marketplace, and use Apache Bench to","timestamp":"1704978480.0"}]},{"upvote_count":"1","poster":"zellck","comment_id":"748563","content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/architecture/distributed-load-testing-using-gke","timestamp":"1702867860.0"},{"timestamp":"1692512400.0","poster":"tomato123","content":"Selected Answer: B\nB is correct","upvote_count":"2","comment_id":"649311"},{"upvote_count":"1","poster":"nehaxlpb","comment_id":"626897","content":"Selected Answer: B\nThis tutorial explains how to use Google Kubernetes Engine (GKE) to deploy a distributed load testing framework that uses multiple containers to create traffic for a simple REST-based API. This tutorial load-tests a web application deployed to App Engine that exposes REST-style endpoints to respond to incoming HTTP POST requests.\n\nYou can use this same pattern to create load testing frameworks for a variety of scenarios and applications, such as messaging systems, data stream management systems, and database systems.","timestamp":"1688455800.0"},{"timestamp":"1680523080.0","content":"Correct answer is B","comment_id":"580250","poster":"dishum","upvote_count":"1"}],"question_images":[],"question_text":"You recently developed a new service on Cloud Run. The new service authenticates using a custom service and then writes transactional information to a Cloud\nSpanner database. You need to verify that your application can support up to 5,000 read and 1,000 write transactions per second while identifying any bottlenecks that occur. Your test infrastructure must be able to autoscale. What should you do?","answer_ET":"B","answer_images":[],"answers_community":["B (100%)"],"question_id":43,"exam_id":7},{"id":"G6w9eJwWePLc91hGV80Y","url":"https://www.examtopics.com/discussions/google/view/69747-exam-professional-cloud-developer-topic-1-question-138/","question_id":44,"discussion":[{"timestamp":"1641736980.0","content":"I vote B\nhttps://cloud.google.com/build/docs/build-config-file-schema","poster":"scaenruy","comment_id":"520239","upvote_count":"10"},{"content":"Selected Answer: C\nCloud Storage is designed for this: Cloud Storage is a robust, scalable, and reliable object storage service. It's perfect for storing files that need to be accessed by multiple parts of your CI/CD pipeline.\nShared access: Cloud Storage objects can be accessed by any builder in your pipeline, as long as they have the necessary permissions.\nSimplicity: Using gsutil to interact with Cloud Storage is straightforward and well-documented.","poster":"thewalker","timestamp":"1725948120.0","comment_id":"1281380","upvote_count":"1","comments":[{"comment_id":"1281381","upvote_count":"1","poster":"thewalker","content":"A. Store and retrieve the file contents using Compute Engine instance metadata: Instance metadata is primarily for managing the instance itself, not for sharing data between builders in a pipeline.\nB. Output the file contents to a file in /workspace. Read from the same /workspace file in the subsequent build step: This approach is limited to the current build step. If the build step is restarted, the file in /workspace will be lost.\nD. Add a build argument that runs an HTTP POST via curl to a separate web server to persist the value in one builder. Use an HTTP GET via curl from the subsequent build step to read the value: This is overly complex and introduces unnecessary dependencies on external services.","timestamp":"1725948120.0"}]},{"timestamp":"1691316540.0","content":"Selected Answer: B\nCorrect answer is B. Save your flat file under /workspace folder and hence the same file can be used for other build steps. Very simple and straight forward approach though. :)","upvote_count":"1","poster":"purushi","comment_id":"973708"},{"upvote_count":"1","timestamp":"1677503580.0","content":"Selected Answer: B\nI vote B\nhttps://cloud.google.com/build/docs/build-config-file-schema","poster":"Pime13","comment_id":"823710"},{"poster":"omermahgoub","upvote_count":"1","content":"Selected Answer: B\nThe best approach is to output the file contents to a file in /workspace directory in one build step and read from the same /workspace file in the subsequent build step . This way, the file is easily accessible by all builders in the pipeline as they all run in the same environment and share the same file system. And it's the easiest and simplest way of sharing the file between the builds in the pipeline.","timestamp":"1673442540.0","comment_id":"772539"},{"upvote_count":"2","timestamp":"1671331680.0","comment_id":"748562","content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/build/docs/configuring-builds/pass-data-between-steps#passing_data_using_workspaces\nTo pass data between build steps, store the assets produced by the build step in /workspace and these assets will be available to any subsequent build steps.","poster":"zellck"},{"comment_id":"728830","upvote_count":"2","timestamp":"1669616580.0","content":"https://cloud.google.com/build/docs/configuring-builds/pass-data-between-steps#passing_data_using_workspaces\nhttps://cloud.google.com/build/docs/configuring-builds/pass-data-between-steps","comments":[{"poster":"TNT87","content":"Answer B","timestamp":"1669616580.0","comment_id":"728831","upvote_count":"1"}],"poster":"TNT87"},{"upvote_count":"1","content":"B is wrong \n\nhttps://cloud.google.com/build/docs/build-config-file-schema\n\n\nUse the dir field in a build step to set a working directory to use when running the step's container. If you set the dir field in the build step, the working directory is set to /workspace/<dir>. If this value is a relative path, it is relative to the build's working directory. If this value is absolute, it may be outside the build's working directory, in which case the contents of the path may NOT be persisted across build step executions","comment_id":"718071","timestamp":"1668440520.0","comments":[{"upvote_count":"1","content":"Ans B is correct \nhttps://cloud.google.com/build/docs/configuring-builds/pass-data-between-steps#passing_data_using_workspaces","comment_id":"720261","poster":"TNT87","timestamp":"1668665760.0"},{"content":"whatsa your answer then","poster":"TNT87","comment_id":"728829","upvote_count":"1","timestamp":"1669616280.0"},{"comment_id":"720157","timestamp":"1668654180.0","upvote_count":"1","poster":"[Removed]","content":"did you take the exam recently?"}],"poster":"cstempo"},{"timestamp":"1660976460.0","comment_id":"649312","poster":"tomato123","upvote_count":"2","content":"Selected Answer: B\nB is correct"},{"poster":"nehaxlpb","upvote_count":"1","comment_id":"626899","timestamp":"1656920880.0","content":"Selected Answer: B\nTo pass data between build steps, store the assets produced by the build step in /workspace and these assets will be available to any subsequent build steps."},{"poster":"americoleonardo","upvote_count":"1","timestamp":"1653007740.0","comment_id":"604195","content":"Selected Answer: B\nagree with b"},{"poster":"mbenhassine1986","timestamp":"1652095260.0","upvote_count":"1","comment_id":"599019","content":"I Vote B\nhttps://cloud.google.com/build/docs/configuring-builds/pass-data-between-steps#passing_data_using_workspaces"}],"answers_community":["B (90%)","10%"],"answer_description":"","answer":"B","question_text":"You are using Cloud Build for your CI/CD pipeline to complete several tasks, including copying certain files to Compute Engine virtual machines. Your pipeline requires a flat file that is generated in one builder in the pipeline to be accessible by subsequent builders in the same pipeline. How should you store the file so that all the builders in the pipeline can access it?","answer_ET":"B","answer_images":[],"question_images":[],"timestamp":"2022-01-09 15:03:00","exam_id":7,"topic":"1","choices":{"C":"Use gsutil to output the file contents to a Cloud Storage object. Read from the same object in the subsequent build step.","A":"Store and retrieve the file contents using Compute Engine instance metadata.","B":"Output the file contents to a file in /workspace. Read from the same /workspace file in the subsequent build step.","D":"Add a build argument that runs an HTTP POST via curl to a separate web server to persist the value in one builder. Use an HTTP GET via curl from the subsequent build step to read the value."},"isMC":true,"unix_timestamp":1641736980},{"id":"6nDnEyIBl7h3lMmh83mc","url":"https://www.examtopics.com/discussions/google/view/91966-exam-professional-cloud-developer-topic-1-question-139/","topic":"1","discussion":[{"content":"Selected Answer: A\nA is the obvious choice","timestamp":"1740741480.0","comment_id":"1362948","poster":"09bd94b","upvote_count":"1"},{"timestamp":"1726974840.0","upvote_count":"1","content":"Selected Answer: A\nA is correct.","poster":"__rajan__","comment_id":"1013545"},{"content":"Selected Answer: A\nA is a very straight forward option. One more choice would be using vulnerability scanning tools like Grype ( open source ) in the build step itself with cloud build.","comment_id":"973710","upvote_count":"1","poster":"purushi","timestamp":"1722939060.0"},{"comments":[{"upvote_count":"2","timestamp":"1704978720.0","content":"Option B, Create a Cloud Function that is triggered on a code check-in and scan the code for CVEs, would impact development agility as it would add an additional step to the development process which can slow down the development teams and impact the development process.\n\nOption C, Disallow the use of non-commercially supported base images in the development environment, would limit the flexibility of the development teams, and they may not be able to use the best tools for the job which can negatively impact the quality of the end-product.\n\nOption D, Use Cloud Monitoring to review the output of Cloud Build to determine whether a vulnerable version has been used, is a good practice to detect and alert on potential issues as soon as possible, but it is an additional step that needs to be set up and maintained. Additionally, it does not handle the vulnerability scanning on its own but rather acts as an additional layer of security.","comment_id":"772541","poster":"omermahgoub"}],"poster":"omermahgoub","comment_id":"772540","timestamp":"1704978660.0","upvote_count":"2","content":"Selected Answer: A\nA. Enable the Vulnerability scanning setting in the Container Registry would be the best solution in this case.\n\nIt would allow you to automatically scan images for known vulnerabilities and detect any issues as soon as they're pushed to the registry. This will help to identify vulnerabilities early in the development cycle, allowing the development teams to take action before images are deployed to production. This approach is automated, does not impact development agility and since it is a built-in feature of the Container Registry, it is a managed service and therefore, it does not require additional maintenance and management."},{"comment_id":"755575","upvote_count":"1","poster":"TNT87","content":"https://docs.docker.com/engine/scan/\nAnswer A","timestamp":"1703498520.0"},{"poster":"zellck","timestamp":"1702867560.0","upvote_count":"1","comment_id":"748561","content":"Selected Answer: A\nA is the answer.\n\nhttps://cloud.google.com/container-analysis/docs/os-overview"}],"answers_community":["A (100%)"],"choices":{"A":"Enable the Vulnerability scanning setting in the Container Registry.","D":"Use Cloud Monitoring to review the output of Cloud Build to determine whether a vulnerable version has been used.","C":"Disallow the use of non-commercially supported base images in your development environment.","B":"Create a Cloud Function that is triggered on a code check-in and scan the code for CVEs."},"question_images":[],"answer":"A","unix_timestamp":1671331560,"answer_ET":"A","answer_images":[],"isMC":true,"question_text":"Your company’s development teams want to use various open source operating systems in their Docker builds. When images are created in published containers in your company’s environment, you need to scan them for Common Vulnerabilities and Exposures (CVEs). The scanning process must not impact software development agility. You want to use managed services where possible. What should you do?","exam_id":7,"timestamp":"2022-12-18 03:46:00","answer_description":"","question_id":45}],"exam":{"id":7,"isBeta":false,"name":"Professional Cloud Developer","numberOfQuestions":338,"lastUpdated":"11 Apr 2025","isMCOnly":false,"provider":"Google","isImplemented":true},"currentPage":9},"__N_SSP":true}