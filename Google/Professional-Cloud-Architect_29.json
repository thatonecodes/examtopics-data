{"pageProps":{"questions":[{"id":"ltO0pKc5GbERYEi5xwaR","question_text":"You are building a continuous deployment pipeline for a project stored in a Git source repository and want to ensure that code changes can be verified before deploying to production. What should you do?","answer_images":[],"question_images":[],"isMC":true,"answer_description":"","answers_community":["D (100%)"],"timestamp":"2019-11-14 20:14:00","answer_ET":"D","discussion":[{"poster":"Googler2","comment_id":"73254","upvote_count":"60","timestamp":"1586599200.0","comments":[{"content":"Agreed with D as the right answer. The url provided explains it better","upvote_count":"10","timestamp":"1591187280.0","poster":"Ziegler","comment_id":"101594"},{"content":"yes, D is correct","poster":"AzureDP900","timestamp":"1665954360.0","comment_id":"696575","upvote_count":"1"},{"poster":"zr79","comment_id":"696917","content":"How can I join Google","upvote_count":"6","timestamp":"1665983040.0"}],"content":"I believe the best answer is D, because the tagging is a best practice that is recommended on Jenkins/Spinnaker to deploy the right code and prevent accidentally (or intentionally) push of wrong code to production environments. See https://stackify.com/continuous-delivery-git-jenkins/"},{"upvote_count":"53","poster":"Anish17","comment_id":"164142","content":"I got this question in real exam. This question states \"before deploying to production\" environment. So i picked D . I passed the exam.","timestamp":"1598160300.0","comments":[{"timestamp":"1611634020.0","poster":"bnlcnd","content":"that resolved the puzzle :)","comment_id":"276579","upvote_count":"6"},{"comment_id":"467204","comments":[{"poster":"zr79","comment_id":"696919","content":"He won't answer, he already passed the exam","upvote_count":"10","timestamp":"1665983100.0"}],"timestamp":"1635128520.0","upvote_count":"2","content":"congrats for passing the exam. practising all 255 questions is sufficient for passing the exam? how much percentage of questions you got from here roughly?","poster":"GunaGCP123"},{"content":"Agree, its the only answer that meets the requirement of \"before deploying to production\"","poster":"Rzla","upvote_count":"2","timestamp":"1630090260.0","comment_id":"433298"},{"poster":"winset","content":"not only 1 Q passed! C is beeter","upvote_count":"2","timestamp":"1613210820.0","comment_id":"289426"}]},{"poster":"Ekramy_Elnaggar","upvote_count":"3","timestamp":"1731958500.0","comment_id":"1314186","content":"Selected Answer: D\n1. Clear separation of environments: Using separate staging and production environments ensures that code changes are thoroughly tested before they reach your users. This minimizes the risk of introducing bugs or regressions into production.\n\n2. Controlled deployments: Tagging the repository for different stages (staging, production) provides a clear and auditable way to track which code versions are deployed in each environment. This makes it easier to roll back to a previous version if necessary.\n\n3. Jenkins for automation: Jenkins is a powerful automation server that can monitor your Git repository for new tags, automatically build and deploy the code to the appropriate environment, and even trigger automated tests.\n\n4. Comprehensive testing: A staging environment allows you to perform comprehensive testing, including integration testing, user acceptance testing (UAT), and performance testing, before deploying to production."},{"upvote_count":"1","content":"Selected Answer: D\nD is the best choice.","comment_id":"1309316","timestamp":"1731220800.0","poster":"sim7243"},{"comment_id":"1155351","poster":"bkovari","content":"ABC is about to deploy to production without prior testing. Hence D is the only reasonable choice.","upvote_count":"1","timestamp":"1708502160.0"},{"upvote_count":"1","comment_id":"1129566","poster":"ashishdwi007","timestamp":"1706016840.0","content":"A B and C are very risky options and irrelevant as involving production. Whereas question is to test before rolling out to production.\nHence D"},{"upvote_count":"1","poster":"blackhawk86","timestamp":"1694609880.0","comment_id":"1006642","content":"Selected Answer: D\nNo discussion here."},{"comment_id":"712401","timestamp":"1667747880.0","content":"Selected Answer: D\nok for D","poster":"megumin","upvote_count":"1"},{"timestamp":"1664386320.0","comment_id":"681983","content":"Given the question D is the only answer. Everything else pushes to production immediately.","poster":"BiddlyBdoyng","upvote_count":"1"},{"content":"I don't think it was a good idea when new edtion be created and directly deploy to the production ENV without any testing stage even using Canary deployment.","upvote_count":"1","timestamp":"1648445940.0","comments":[{"content":"D is better.","upvote_count":"1","timestamp":"1648446000.0","comment_id":"576641","poster":"[Removed]"}],"comment_id":"576639","poster":"[Removed]"},{"timestamp":"1647869760.0","poster":"Davidik79","comment_id":"572266","content":"Selected Answer: D\nThe question states: \"... code changes can be verified BEFORE deploying to production\", it eliminates option C.\nThe approach of tagging is the correct practise that DevOps use","upvote_count":"2"},{"content":"Selected Answer: D\nCorrect answer is D. Question talks about 'before deploying to production'. C talks about after deploying to production.","upvote_count":"4","timestamp":"1642801440.0","poster":"[Removed]","comment_id":"529438"},{"upvote_count":"1","timestamp":"1642060020.0","content":"C is the closest answer\nIf question is asking 'what's Jenkin best practise' then D is the answer","comments":[{"upvote_count":"2","timestamp":"1647869820.0","poster":"Davidik79","comment_id":"572268","content":"C involves deploying into production. the question specifies: \"BEFORE deploying to production\""},{"upvote_count":"1","timestamp":"1694609820.0","poster":"blackhawk86","comment_id":"1006641","content":"Incorrect. D is the correct answer. 1. It should test BEFORE deploy to production. 2. It's a DevOps practice"}],"poster":"hantanbl","comment_id":"522700"},{"upvote_count":"1","comment_id":"519020","timestamp":"1641566160.0","poster":"lxgywil","content":"I choose D as we want to ensure that code changes can be verified BEFORE deploying to production. Option C suggests that we build and deploy changes to production for 10% of users."},{"poster":"OrangeTiger","content":"Selected Answer: D\nVote D.\nC is canary deploy.\nBut the sentence in question has no word to mean \"tested by a small number of users\"","upvote_count":"3","timestamp":"1641034680.0","comment_id":"514478","comments":[{"timestamp":"1641034980.0","comment_id":"514481","upvote_count":"1","poster":"OrangeTiger","content":"The revelal solution on this site is wrong, isn't it? I'm getting anxious."}]},{"content":"D is the correct answer","upvote_count":"1","timestamp":"1640434020.0","comment_id":"509095","poster":"vincy2202"},{"upvote_count":"2","content":"Selected Answer: D\nclearly","timestamp":"1639739340.0","poster":"ABO_Doma","comment_id":"503618"},{"upvote_count":"3","comment_id":"502607","timestamp":"1639626960.0","poster":"phantomsg","content":"Selected Answer: D\nQuestion asks to verify before Production. So tagging and deploying appropriately is the right approach."},{"timestamp":"1638703500.0","upvote_count":"1","comment_id":"494267","poster":"haroldbenites","content":"Go for D.\n“BEFORE DEPLOYING TO PRODUCTION”"},{"comment_id":"494217","upvote_count":"3","timestamp":"1638699480.0","poster":"pakilodi","content":"Selected Answer: D\nC & D are valid answers here. I choose D because they want to test before deploy to production. If the question was : \"test to a subset users in production (Canary) before full deployment\", it would have been C"},{"content":"Selected Answer: D\nvote D","comment_id":"489498","poster":"joe2211","timestamp":"1638143280.0","upvote_count":"2"},{"poster":"jimcsng","upvote_count":"2","content":"Selected Answer: D\nD is correct while C is not. The question is about ensuring the traceability of the code changes, not necessarily ensure a successful release.","timestamp":"1637308740.0","comment_id":"481473"},{"timestamp":"1635447180.0","poster":"[Removed]","content":"D is right. Ask is before deploying... \nC is wrong choice.","comment_id":"469432","upvote_count":"2"},{"poster":"MaxNRG","content":"D – Use Jenkins to monitor tags in repository. Deploy staging tags to staging env for testing. After testing tag repository for production and deploy it to production env.\nC – omits testing before canary release (10% of users), also references staging and master branches, instead of just master to build from.\n\nJenkins is automation server to build test and deploy. While both tools (Spinnaker, Jenkins) are used for SW updates, there are key differences. Spinnaker is not a build tool, but a deployment tool, with focus on the cloud.\nBecause Spinnaker was not intended to be a build tool, there are things that Jenkins will do better: managing SCM, running tests and building packages.","comment_id":"467409","upvote_count":"1","timestamp":"1635158940.0"},{"upvote_count":"1","comment_id":"459948","timestamp":"1633852200.0","poster":"3RED","comments":[{"comment_id":"459951","upvote_count":"2","poster":"3RED","content":"Moreover D is wrong as it takes a full deployment instead of a canary","timestamp":"1633852260.0"}],"content":"C- As there is a staging branch in the workflow , testing/QA is being done in the staging . After that it follows canary deployment in prod."},{"timestamp":"1633125180.0","upvote_count":"1","poster":"SuperCloud","content":"D ensures the code is ready for production, via tagging.","comment_id":"455707"},{"timestamp":"1630244160.0","content":"Spinnaker is an alternative CIC/CD for Jenkins\nred/black or blue/green - is a quick switch deployment reducing the deployment time on the distributed environment [[URL 1]]\nThere is a difference between validation and verification - Validation is the process of checking whether the specification captures the customer’s requirements, while verification is the process of checking that the software meets specifications.\n[[URL2]]. That means we are talking about UAT/customer validation and not SIT/testing.\n\n\nLet's go with option elimination\n\nA. Use Spinnaker to deploy builds to production using the red/black deployment strategy so that changes can easily be rolled back.\n>> Does not cover validation hence eliminating.","upvote_count":"3","comment_id":"434626","poster":"amxexam","comments":[{"content":"**Parts of my post did not get approved lost part of and.\n\nWe must select a solution that does proper testing in test environment and not in prod hence D","comment_id":"440962","poster":"amxexam","comments":[{"upvote_count":"1","comment_id":"440963","poster":"amxexam","timestamp":"1631024700.0","content":"**Parts of my post did not get approved lost part of answer"}],"timestamp":"1631024700.0","upvote_count":"1"}]},{"poster":"avi0986","content":"D is ok, question mentioned that before production rollout","comment_id":"409013","timestamp":"1626619740.0","upvote_count":"2"},{"comment_id":"401860","content":"Answer is D","timestamp":"1625744280.0","upvote_count":"2","poster":"MamthaSJ"},{"upvote_count":"2","poster":"aviratna","content":"D: As requirement is before deploying to production while option C is after deployment","comment_id":"391810","timestamp":"1624776360.0"},{"poster":"sanzpaul","upvote_count":"1","timestamp":"1624259220.0","comment_id":"386862","content":"I go for D as it states verify before deploying to production. using a test environment is an industry best practice."},{"upvote_count":"2","content":"D. Use Jenkins to monitor tags in the repository. Deploy staging tags to a staging environment for testing. After testing, tag the repository for production and deploy that to the production environment.","timestamp":"1621407180.0","poster":"victory108","comment_id":"361105"},{"timestamp":"1620805860.0","upvote_count":"1","comment_id":"355371","content":"D if \"before deploying to production\"\nA if \"after deploying to production\"","poster":"un"},{"timestamp":"1618584300.0","comment_id":"337074","content":"D better but in the question, it says \"code changes can be verified deploying to production.\" what if they don't have a staging or testing environment, in that case, I have to go with C","upvote_count":"1","poster":"ccmcwolf"},{"timestamp":"1618584180.0","upvote_count":"1","comment_id":"337069","poster":"ccmcwolf","content":"D better"},{"content":"Answer is D","poster":"Ausias18","timestamp":"1617166320.0","upvote_count":"1","comment_id":"324736"},{"comment_id":"324317","comments":[{"comment_id":"335605","timestamp":"1618414680.0","upvote_count":"1","content":"Excellent idea, table above with comments feed below.","poster":"Blobby"}],"timestamp":"1617113040.0","upvote_count":"3","content":"Maybe it would be a good idea to add to this site functionality: a dense table with two columns: \"Option\" and \"Votes count\" - relevant to each particular question. \nAs rows in the table there would be all posible options for which anyone voted on the question: A/B/AC/DEF and so on.\nThere should be also functionality to click on particular cell to \"drill down\" - showing explanations made by each person who vouted for this option :)","poster":"lynx256"},{"upvote_count":"1","content":"IMO - D\nBut I'n not so sure about it (maybe C) ...?","poster":"lynx256","comment_id":"324310","timestamp":"1617111900.0"},{"content":"C is better than D as you're verifying the deployment to production with a canary release.","upvote_count":"1","timestamp":"1616949060.0","comment_id":"322774","poster":"realkrt"},{"content":"This question is older and Jenkins was more prominent, Spinakker is great and it would be my choice now, but the answer for this question is still C at this time.","timestamp":"1613912100.0","comment_id":"295768","poster":"rice","upvote_count":"1"},{"poster":"ahmedemad3","comment_id":"281706","timestamp":"1612251660.0","content":"Ans: D\n\"after\" deploying to production -> C\n\"before\" deploying to production -> D","upvote_count":"3"},{"upvote_count":"1","timestamp":"1610901180.0","poster":"HKim","content":"The key here is \"to ensure that code changes can be verified deploying to production\". This means the answer would have to include Blue/Green, Red/Black or Canary deployments thus leaving only A and C. If choices are between Red/Black and Canary, then Canary is a better way therefore C is better than A.","comment_id":"269640"},{"timestamp":"1610675040.0","comment_id":"267548","content":"Those, who are advocating \"C\", where is it written to have it deployed on prod for 10% users? which Canary deployment best practice says this? The answer should be D IMO. This is what we do in real life. \"C\" could have been right if was better phrased.","upvote_count":"1","comments":[{"content":"D is correct for me. It indicates \"want to be sure\". You don't deploy to prod anything that you don't fell confident.","poster":"jcamilodo","comment_id":"271354","timestamp":"1611073020.0","upvote_count":"2"}],"poster":"alii"},{"timestamp":"1609290300.0","upvote_count":"1","content":"B- incorrect as it deploys fully to production.\nC - incorrect as Jenkins does not have inherent capability to deploy for partial users.\nD - incorrect as it requires staging env. Question only mentions testing in production \nA - correct, tests in production, for partial users with ability to rollback hence mitigating risk.","poster":"NeoFer","comment_id":"255266"},{"content":"\"after\" deploying to production -> C\n\"before\" deploying to production -> D","upvote_count":"1","poster":"sdsdfasdf4","comment_id":"249417","timestamp":"1608562560.0"},{"poster":"Bijesh","timestamp":"1607757540.0","upvote_count":"1","content":"Spinnaker can work with google cloud repository. THe coursera lab/qwiklabs has sessions on it. THis means we can avoid Jenkins right ?\nAnd a blue green/red black deployment helps to check things in production","comment_id":"241412"},{"poster":"Chulbul_Pandey","timestamp":"1606891500.0","comment_id":"232672","upvote_count":"4","content":"Common sense :) its D"},{"poster":"OSNG","upvote_count":"4","comment_id":"229817","timestamp":"1606590120.0","content":"Correct answer is D:\n* Continuous Deployment - Means code will change/update frequently (often after every week). for this kind of environment D is the automated options, as Jenkins will automatically perform the required testing.\n\nWHY NOT C: you need to monitor and rollback manually (in my opinion) if portion of it is not good, doing for long term where code is changing/being updated so frequently is not a long term solution."},{"comment_id":"202096","upvote_count":"1","poster":"MaRa_85","timestamp":"1603028940.0","content":"I'm quite confused which one is correct because option C states that code has to be deployed into production and test with 10% of users whereas option D states that thorough testing will be performed in staging environment before deploying into production. To me, D makes more sense but most of them said C."},{"content":"Answer is A - https://spinnaker.io/guides/user/kubernetes-v2/rollout-strategies/ , spinnaker is a tool that Google and netflix develop , prefer way","upvote_count":"2","timestamp":"1602505500.0","poster":"dan80","comment_id":"198405"},{"upvote_count":"2","poster":"VedaSW","content":"The key is \"code changes can be verified\". So, one way is you build the staging branch and master branch, and perform the comparison. If the result matches master, you have verified the codes and good for deployment.","timestamp":"1601113260.0","comment_id":"187572"},{"poster":"AshokC","upvote_count":"2","comment_id":"179609","content":"Going with D","timestamp":"1600134840.0"},{"content":"For me its D. testing needs to be done before Prod i.e. is only D.","comment_id":"176188","poster":"imranrq","upvote_count":"2","timestamp":"1599614580.0"},{"content":"All of the websites with this question have C as the answer.","upvote_count":"3","timestamp":"1598215740.0","comment_id":"164693","poster":"peterbrv","comments":[{"content":"all the websites have the same source. so do not take it seriously. just check the comments here. that is the only way.","comment_id":"218994","poster":"certificatores","upvote_count":"2","comments":[{"timestamp":"1616762760.0","comment_id":"321120","content":"Agree :)\nAlthough I don't know, which is the source , there is nonsense to know answers (A/B/C/D and so on) without explanation. So discussion is the only way to UNDERSTAND the answers.","poster":"lynx256","upvote_count":"1"}],"timestamp":"1605342780.0"}]},{"upvote_count":"1","poster":"haidertanveer0808","content":"IMO C is a better option as canary deployment is a standard way to do checkout in Prod.If successfull complete rollout else rollback.","comment_id":"160336","timestamp":"1597695480.0"},{"content":"I selected D in my exam","comment_id":"135662","upvote_count":"4","poster":"daurib","timestamp":"1594812240.0"},{"content":"C is not correct since what is gurantee that you master and staging branch will be in sync. As you all would have experienced we keep on making branch alignment mistake. So tagging is best option and recommended approach for CICD.\nSo for me correct answer is D","comment_id":"130905","upvote_count":"1","poster":"saurabh1805","timestamp":"1594320180.0"},{"content":"C is the correct answer","timestamp":"1592638080.0","upvote_count":"1","comment_id":"114563","poster":"Tushant"},{"content":"The question is about verifying the deployment in production. I guess it should be D, tags/version is used to deploy to production deployment then we can verify if it's correctly deployed.","comment_id":"110691","timestamp":"1592211960.0","upvote_count":"2","poster":"ronald89"},{"upvote_count":"1","comment_id":"109328","timestamp":"1592041680.0","content":"A\nSpinnaker is more powerful tool than Jenkins when it come to Deployment Pipelines and the Quest has asked for Deployment Pipelines\nhttps://www.spinnakersummit.com/blog/spinnaker-vs-jenkins-for-continuous-delivery","poster":"bubai01"},{"timestamp":"1591110840.0","comment_id":"100956","content":"C is the correct answer","poster":"Nirms","upvote_count":"1"},{"upvote_count":"1","comments":[{"comments":[{"timestamp":"1596889800.0","upvote_count":"1","comment_id":"153027","poster":"Gobblegobble","content":"Final decision updated to Option C"}],"poster":"AD2AD4","comment_id":"98100","content":"Final Decision to go with Option D","upvote_count":"4","timestamp":"1590738900.0"}],"poster":"AD2AD4","timestamp":"1590652140.0","comment_id":"97347","content":"Final Decision to go with Option A as Spinnaker is suggested CD approach and red/black is used by industry also known as Blue/Green."},{"comment_id":"93621","content":"I will go with D","upvote_count":"5","timestamp":"1590096420.0","poster":"gcp_aws"},{"timestamp":"1589888820.0","comments":[{"comment_id":"276576","timestamp":"1611633840.0","poster":"bnlcnd","upvote_count":"1","content":"C is definitely not the choice. The statement is either missing some words due to typo or just trying to mislead."}],"upvote_count":"5","content":"I choose D.\nC is not even a cohesive description of anything. You build staging and master branches, good. Now you end up with 2 packages. Then you deploy which to where? The second sentence only mentions one environment - production. So...you deploy both to your production? This can't be right.","comment_id":"92051","poster":"huangmeiguai"},{"timestamp":"1589817060.0","poster":"amp87","content":"Answer A uses a red/black deployment model which means to switch the traffic on new machines while keeping old machines active, ready to rollback if an issue occurs.\nThe question is not clear in this point but I would prefer a canary release and do the validation of the new release with a small portion of users, means I would go with answer C.","upvote_count":"1","comment_id":"91452"},{"content":"C is the answer.","comment_id":"89260","timestamp":"1589508180.0","upvote_count":"2","poster":"Jack_in_Large"},{"comment_id":"83309","poster":"Zarmi","comments":[{"comment_id":"141986","poster":"cetanx","upvote_count":"4","timestamp":"1595505360.0","content":"I agree, if question is \"... before deploying to production?\" -> D is the answer as it's the only option offers testing in a staging (non-prod) environment."},{"upvote_count":"1","poster":"bnlcnd","timestamp":"1611633720.0","comment_id":"276575","content":"That's exactly the confusion in this question. either A or D will be the answer depends on what does this statement mean.\nRed/Black == Blue/Green. If we wan to verify in PROD, this is the answer.\nIf we want to verify before PROD, D is the answer. I guess the question just had a typo and missed the critical word."}],"upvote_count":"8","timestamp":"1588551360.0","content":"What does it mean \"code changes can be verified deploying to production\"?\nTesting before deploying to production? If yes, we have only 1 choice - D.\nOthers are testing on production."},{"comment_id":"77309","comments":[{"comment_id":"103482","upvote_count":"2","poster":"Rafaa","timestamp":"1591402800.0","comments":[{"upvote_count":"2","comment_id":"215596","content":"https://spinnaker.io/\n\nDeploy across multiple cloud providers including AWS EC2, Kubernetes, Google Compute Engine, Google Kubernetes Engine, Google App Engine, Microsoft Azure, Openstack, Cloud Foundry, and Oracle Cloud Infrastructure, with DC/OS coming soon.","timestamp":"1604880420.0","poster":"pepYash"}],"content":"spinnaker is only used with Kubernetes/containers. Question does not talk about Kubernetes. Jenkins is more universal"}],"upvote_count":"3","poster":"PRC","timestamp":"1587448500.0","content":"Refer this..https://cloud.google.com/solutions/continuous-delivery-spinnaker-kubernetes-engine...Could it be A?"},{"upvote_count":"3","comment_id":"60259","poster":"Javed","timestamp":"1583577240.0","content":"C is correct"},{"comment_id":"56378","upvote_count":"3","poster":"[Removed]","content":"Unsure about the ans. But selected D in the exam","timestamp":"1582873080.0"},{"poster":"2g","timestamp":"1580392500.0","upvote_count":"3","comment_id":"44766","content":"answer: C"},{"upvote_count":"9","timestamp":"1576813620.0","poster":"ef2344","content":"i guess answer is D","comment_id":"31219"},{"comments":[{"poster":"AWS56","content":"Agree C is the answer","timestamp":"1578831660.0","comment_id":"38009","upvote_count":"2"},{"poster":"tartar","comment_id":"151771","content":"C is ok","upvote_count":"5","comments":[{"content":"I dont know.. C/D","upvote_count":"4","comment_id":"157963","timestamp":"1597395480.0","poster":"tartar"}],"timestamp":"1596699180.0"},{"upvote_count":"4","timestamp":"1614897720.0","poster":"nitinz","comments":[{"comment_id":"303652","timestamp":"1614897900.0","content":"Here is quick link to CI/CD build pipleline. How Jenkins uses tags for build automation https://www.jenkins.io/blog/2018/05/16/pipelines-with-git-tags/","upvote_count":"1","poster":"nitinz"}],"comment_id":"303651","content":"Answer is D, those who are saying C\na) not reading question properly.\nb) have no clue about CI/CD pipe line.\nIf you think C, then re-read the question."}],"poster":"keneda95","timestamp":"1573758840.0","content":"Guillaume you see the right answer is C!!","comment_id":"21608","upvote_count":"7"}],"url":"https://www.examtopics.com/discussions/google/view/8197-exam-professional-cloud-architect-topic-1-question-45/","choices":{"C":"Use Jenkins to build the staging branches and the master branch. Build and deploy changes to production for 10% of users before doing a complete rollout.","A":"Use Spinnaker to deploy builds to production using the red/black deployment strategy so that changes can easily be rolled back.","D":"Use Jenkins to monitor tags in the repository. Deploy staging tags to a staging environment for testing. After testing, tag the repository for production and deploy that to the production environment.","B":"Use Spinnaker to deploy builds to production and run tests on production deployments."},"unix_timestamp":1573758840,"question_id":141,"exam_id":4,"answer":"D","topic":"1"},{"id":"m8IeqUDNteADDt4CMPcD","question_images":[],"timestamp":"2019-10-22 08:36:00","answers_community":["C (87%)","13%"],"choices":{"A":"Grant your colleague the IAM role of project Viewer","D":"Disable autoscaling for the instance group. Add his SSH key to the project-wide SSH Keys","C":"Disable the health check for the instance group. Add his SSH key to the project-wide SSH Keys","B":"Perform a rolling restart on the instance group"},"answer":"C","topic":"1","discussion":[{"comment_id":"528447","poster":"Narinder","comments":[{"upvote_count":"2","content":"great answer","timestamp":"1645823940.0","poster":"twistyfries","comment_id":"556265"},{"comment_id":"602454","content":"This looks best justification between A and C.. So, C should be correct answer.","timestamp":"1652682780.0","poster":"AmitAr","upvote_count":"2"},{"poster":"devjuliusoh","comment_id":"649561","upvote_count":"2","timestamp":"1661044020.0","content":"Good explanation"},{"upvote_count":"1","content":"The key element in C is \"Disable the Health check.\", so that server wont restart automatically.\nBut before that the actual troubleshooting step is to check Cloud console -> Instance template -> Metadata-> and see if any startup script is there, if yes review it and possibly remove it. [Consider the case, a script is causing restarting the VM, (possibly in Metadata). ]","comment_id":"1129601","poster":"ashishdwi007","timestamp":"1706017620.0"}],"timestamp":"1642686600.0","upvote_count":"98","content":"C, is the correct answer. As per the requirement linux expert would need access to VM to troubleshoot the issue. With health check enabled, old VM will be terminated as soon as health-check fails for the VM and new VM will be auto-created. So, this situation will prevent linux expert to troubleshoot the issue. Had it been the case that stack-drover logging is enabled and the expert just want to view the logs from the Cloud-logs than role to project-viewer could help. But it is specifically mentioned that expert will login into VM to troubleshoot the issue and not looking at the cloud Logs. So, Option-C is the correct answer."},{"upvote_count":"39","comment_id":"16929","poster":"KouShikyou","timestamp":"1571828220.0","content":"C should be correct answer."},{"timestamp":"1731959160.0","content":"Selected Answer: C\n1. Access for troubleshooting: Disabling the health check prevents the VMs from constantly restarting, allowing the expert to log in and investigate the root cause.\n\n2. SSH access: Adding the expert's SSH key grants them the necessary access to the VMs.\n\n3. Temporary measure: This is a temporary measure for troubleshooting. Once the issue is resolved, the health check should be re-enabled.","comment_id":"1314189","poster":"Ekramy_Elnaggar","upvote_count":"3"},{"timestamp":"1710671760.0","upvote_count":"1","content":"Selected Answer: C\nC is correct!","comment_id":"1175729","poster":"wilson1005"},{"poster":"heretolearnazure","upvote_count":"1","comment_id":"987706","content":"I like C","timestamp":"1692731520.0"},{"comment_id":"839961","timestamp":"1678890000.0","content":"Selected Answer: C\nTo allow your colleague, who is a Linux expert, to access the VMs and troubleshoot the issue, you should disable the health check for the instance group. This will prevent the instance group from automatically removing and replacing unhealthy instances.\n\nYou should also add your colleague's SSH key to the project-wide SSH Keys to allow him to SSH into the instances and perform troubleshooting. This can be done through the Google Cloud Console or the gcloud command-line tool.","upvote_count":"4","poster":"JC0926"},{"upvote_count":"6","comment_id":"830961","content":"Selected Answer: C\nC. Disable the health check for the instance group. Add his SSH key to the project-wide SSH Keys.\n\nGranting the IAM role of project Viewer (Option A) would allow your colleague to view the project resources but not necessarily give them access to the specific VM instances. Performing a rolling restart on the instance group (Option B) would not resolve the issue, as the instances keep restarting after 5 seconds. Disabling autoscaling for the instance group (Option D) is not relevant since autoscaling is already disabled.\n\nDisabling the health check for the instance group will prevent the managed instance group from automatically recreating the instances. Adding your colleague's SSH key to the project-wide SSH Keys will allow them to access the VMs and troubleshoot the issue. Once the issue is resolved, you can re-enable the health check for the instance group.","timestamp":"1678117260.0","poster":"MestreCholas"},{"comment_id":"800449","content":"Selected Answer: C\nC is the answer","upvote_count":"1","poster":"urssiva","timestamp":"1675736460.0"},{"poster":"roaming_panda","timestamp":"1672741860.0","comment_id":"764431","content":"C as the machines will keep restarting if hc is not disabled , and then our expert can look around for RCA","upvote_count":"1"},{"comment_id":"752076","content":"To allow your colleague access the instances in MIG you should do option D: Disable autoscaling for the instance group. Add his SSH key to the project-wide SSH Keys.\n\nDisabling autoscaling for the instance group will prevent new instances from being created or terminated while your colleague is trying to troubleshoot the issue. This will give him a stable environment to work in and will ensure that he can access the instances that are currently in the instance group.\n\nAdding his SSH key to the project-wide SSH Keys will allow him to connect to the instances using Secure Shell (SSH) without requiring a password. This is a convenient way to give him access to the instances and can help him troubleshoot the issue more efficiently.","timestamp":"1671615240.0","comments":[{"poster":"n_nana","timestamp":"1673508600.0","comment_id":"773224","upvote_count":"1","content":"autoscaling is already disabled. Answer D is not make sense here. i voted it wrongly instead of reply."},{"upvote_count":"2","comment_id":"752077","content":"Option A: Granting your colleague the IAM role of project Viewer will not allow him to access the instances in the managed instance group. The project Viewer role does not include any permissions to access Compute Engine resources.\n\nOption B: Performing a rolling restart on the instance group will not solve the issue and may even make it worse if the instances are not able to start up properly.\n\nOption C: Disabling the health check for the instance group will not solve the issue and may even make it worse if the instances are not able to start up properly. Adding his SSH key to the project-wide SSH Keys will allow him to access the instances, but it is not a sufficient solution on its own.","poster":"omermahgoub","timestamp":"1671615240.0"}],"upvote_count":"2","poster":"omermahgoub"},{"content":"Selected Answer: C\nC is the correct answer","poster":"surajkrishnamurthy","timestamp":"1671501180.0","upvote_count":"1","comment_id":"750388"},{"comment_id":"712404","poster":"megumin","timestamp":"1667748060.0","content":"Selected Answer: C\nok for C","upvote_count":"1"},{"timestamp":"1665669060.0","comment_id":"693943","content":"C. Disable the health check for the instance group. Add his SSH key to the project-wide SSH Keys. This will allow the engineer to logon to the VM's and check the logs. Disabling health checks will prevent rebooting of the VM's.","poster":"minmin2020","upvote_count":"2"},{"timestamp":"1663841340.0","content":"C should be the correct answer","upvote_count":"1","comment_id":"675967","poster":"holerina"},{"comment_id":"654306","timestamp":"1661883660.0","content":"Selected Answer: C\nDisable the health check for the instance group. Add his SSH key to the project-wide SSH Keys","poster":"abirroy","upvote_count":"1"},{"timestamp":"1659954660.0","content":"vote C\nwhat can project viewer do without access vm by linux expert?","poster":"backhand","comment_id":"644070","upvote_count":"1"},{"comment_id":"629585","poster":"tricky_learner","timestamp":"1657461600.0","content":"Selected Answer: C\nI believe that answer C is correct.","upvote_count":"1"},{"upvote_count":"1","content":"About create SSH Keys to VM https://cloud.google.com/compute/docs/connect/create-ssh-keys","comment_id":"609974","poster":"elaineshi","timestamp":"1654051500.0"},{"comments":[{"timestamp":"1674351960.0","comment_id":"783864","poster":"oxfordcommaa","content":"Answer A wouldn't be the resolution.\nThe instances are being restarted, as long as they are being restarted, the linux expert will not be able to log in and do what he needs to do.\nDisabling the health check is how to make the instances available for access...then you add the keys and you are kosher.","upvote_count":"1"},{"poster":"Nidhal1920","comment_id":"869283","content":"The Linux expert don't need to see all the resources under my project (least privilege principle) ! So A is not correct. It's C .","timestamp":"1681381500.0","upvote_count":"1"}],"timestamp":"1652193540.0","content":"Selected Answer: A\nFor others answering please concentrate on the requirement. The ask is to allow access to the Linux expert and not to go and solve the problem\n\nHence A.","poster":"amxexam","comment_id":"599639","upvote_count":"2"},{"timestamp":"1643925060.0","upvote_count":"3","poster":"juancambb","comment_id":"540019","content":"Selected Answer: C\nis C the correct"},{"timestamp":"1642645800.0","upvote_count":"2","comment_id":"528083","poster":"Q_Review","content":"Selected Answer: C\nNeed to grant access, not resolve the issue."},{"content":"stop health check - this will prevent autohealing behaviour, i.e. instance restart\nSSH key added project-wide - enable the linux admin to log on to the box and troubleshoot the application.","comment_id":"519781","upvote_count":"3","poster":"pddddd","timestamp":"1641677160.0"},{"poster":"PhuocT","content":"Selected Answer: C\nC is the correct answer. with A: project Viewer, how Linux expert could access to VM and check the issue?","comment_id":"511320","timestamp":"1640708400.0","upvote_count":"3"},{"comments":[{"comments":[{"comments":[{"timestamp":"1661884500.0","content":"A looks safer .. its view only.","poster":"abirroy","comment_id":"654320","upvote_count":"1"}],"timestamp":"1661884380.0","comment_id":"654317","content":"Project-wide SSH keys are stored in Compute/Project-meta-data. Project wide ssh keys can be used to login into all the instances within project. Using project-wide ssh keys eases the SSH key management but if compromised, poses the security risk which can impact all the instances within project.","poster":"abirroy","upvote_count":"1"}],"comment_id":"519058","upvote_count":"3","poster":"lxgywil","timestamp":"1641570180.0","content":"The thing is, A will give your colleague MORE than enough access, which is against the principle of least privilege. Keep in mind that this will be project-wide, thus option C is more viable in this situation."}],"comment_id":"502303","upvote_count":"2","poster":"ochanz","content":"Selected Answer: A\nYou have an outage in your Compute Engine managed instance group: all instances keep restarting after 5 seconds. You have a health check configured, but autoscaling is disabled. Your colleague, who is a Linux expert, offered to look into the issue. You need to make sure that he can access the VMs. What should you do?\nA. Grant your colleague the IAM role of project Viewer # this will give the colleague enough access to view and troubleshoot.\nB. Perform a rolling restart on the instance group X\nC. Disable the health check for the instance group. Add his SSH key to the project-wide SSH Keys X this will give the Linux expert more access compared to option A\nD. Disable autoscaling for the instance group. Add his SSH key to the project-wide SSH Keys X autoscaling has been disabled.","timestamp":"1639583520.0"},{"upvote_count":"1","content":"Go for C.","comment_id":"494270","timestamp":"1638703680.0","poster":"haroldbenites"},{"timestamp":"1635174120.0","upvote_count":"1","content":"C – disable health checks, add his SSH keys to project-wide SSH keys. Though A was also a candidate, though it violates principle of least privilege (no need for Linux expert review GCP project) and also he likely doesn’t have GCP account.\nAlso, Linux VMs with external IPs can be accessed via 3rd party tools like Putty, etc.\nIn theory healtchecks can be configured to reset every 5 sec (1 sec probe interval and 5 sec fail probes). That’s stupid configuration but seems like a root cause of reset.\nC – disables healthchecks, so Linux VMs can start, then Linux expert can log in. Though, not clear why we need his help if VMs start normally?\nA – is correct if it’s not a healthcheck issue (some system error in VM causes reset), so no SSH access is possible.","poster":"MaxNRG","comment_id":"467511"},{"timestamp":"1631942220.0","poster":"AnilKr","upvote_count":"1","content":"Question is asking to make sure that linux expert can access only, how come option C is correct here?","comment_id":"446926"},{"comments":[{"upvote_count":"6","poster":"Rzla","content":"Great, you gave the expert read access to the project.... then what? A doesn't give you the permissions or access required to troubleshoot an issue with GCE instance. Its C, stop the instances bouncing and allow interactive access to troubleshoot.","timestamp":"1632399420.0","comment_id":"450238"}],"comment_id":"434636","upvote_count":"1","content":"For others answering please concentrate on the requirement. The ask is to allow access to the Linux expert and not to go and solve the problem \n\nHence A.","poster":"amxexam","timestamp":"1630244460.0"},{"comment_id":"401862","poster":"MamthaSJ","timestamp":"1625744460.0","content":"Answer is C","upvote_count":"1"},{"poster":"aviratna","timestamp":"1624776540.0","upvote_count":"2","content":"C is correct","comment_id":"391812"},{"comment_id":"361104","poster":"victory108","upvote_count":"2","timestamp":"1621407120.0","content":"C. Disable the health check for the instance group. Add his SSH key to the project-wide SSH keys"},{"poster":"un","timestamp":"1620806280.0","upvote_count":"1","content":"C is correct","comment_id":"355374"},{"content":"C is correct","upvote_count":"1","poster":"un","timestamp":"1620806040.0","comment_id":"355372"},{"content":"C. This is because \"disabling health check\" will ensure, the servers dont restart after you give linux expert keys to login otherwise he will get frustated and wont really help you !","comment_id":"342169","upvote_count":"6","timestamp":"1619287320.0","poster":"gosi"},{"comment_id":"334437","timestamp":"1618293780.0","upvote_count":"1","poster":"pentium2000","content":"I would go C. \nIf you can't to fix the keep restarting issue of instances, how your export colleagues is able to login to fix it?"},{"upvote_count":"1","poster":"Ausias18","content":"Answer is C","timestamp":"1617166380.0","comment_id":"324738"},{"upvote_count":"2","content":"IMO C is ok.\nA is too broad. \nThe question is \"You need to make sure that he can access the VMs\" - IMO - while VM are running (longer than 5 sec). So disabling Healt Check seems to be necessary...","poster":"lynx256","timestamp":"1616756400.0","comment_id":"321046"},{"content":"This is vague, Question is \"what sould you do?\" but for what\n1. Colleague should be given any access\n\n2. Fix the issue at hand.","comment_id":"305510","upvote_count":"1","timestamp":"1615179240.0","poster":"Jane111"},{"comment_id":"279126","timestamp":"1611904140.0","poster":"GS14","content":"C should be the answer, \nB is not doing anything on ensuring the expert can access the machines, rolling restart has nothing to do with access.\nD is wrong as autoscaling is already disabled","upvote_count":"1"},{"upvote_count":"1","comment_id":"276582","content":"C is right. You want the VM not keep restarting and let the expert to login the VM via SSH.","poster":"bnlcnd","timestamp":"1611634440.0"},{"timestamp":"1610160840.0","upvote_count":"2","comment_id":"262957","content":"It is definitely C, as failing health checks will keep causing the instances to restart, rendering one unable to \"go in and inspect\" the root cause.","poster":"joshuaquek"},{"comment_id":"261312","timestamp":"1609970400.0","content":"C should be the answer to me. Rolling restart for VM doesn't give access to an user so B doesn't make sense. Auto-scaling is already disabled so D doesn't make sense. Project viewer is more broader access which means it violates least privilege access.","upvote_count":"1","poster":"Arimaverick"},{"upvote_count":"1","content":"It should be C","timestamp":"1608899940.0","poster":"Prakzz","comment_id":"252042"},{"comment_id":"249434","timestamp":"1608563940.0","content":"Ok OS-Login and Option A is out of the question because Viewer role doesn't give roles/compute.osLogin permission. Option B is nonsense. Option C looks good. Option D is out cause autoscaling is already disabled.","upvote_count":"1","poster":"sdsdfasdf4"},{"upvote_count":"2","timestamp":"1606891560.0","comment_id":"232675","poster":"Chulbul_Pandey","content":"C is right.."},{"comment_id":"205050","timestamp":"1603536900.0","upvote_count":"2","poster":"AdityaGupta","content":"Question says \"You have a health check configured, but autoscaling is disabled.\" to identify the issue you should disable the healthcheck for the instance group. Add his SSH key to the project-wide SSH keys... Correct Answer is C"},{"poster":"MaRa_85","comment_id":"202093","comments":[{"timestamp":"1618120020.0","content":"Very good question, MaRa_85!","upvote_count":"2","poster":"cmfchong","comment_id":"332999"}],"upvote_count":"2","timestamp":"1603028760.0","content":"If the SSH key for the Linux expert is added to the project wide SSH keys, then the linux expert will have access to all the resources defined in that project. In that case, whats the difference between A and C? Please clarify."},{"poster":"kimberjdaw","upvote_count":"1","comment_id":"187819","content":"You only do C if you're messing with the guy. The health check is obviously the problem, so turning them off would make the problem go away and really confuse the guy. It's also the only answer that makes sense. The question is broken.","timestamp":"1601141040.0"},{"poster":"VedaSW","timestamp":"1601113800.0","upvote_count":"1","comments":[{"timestamp":"1618120260.0","content":"Yes, me too. No explanation to say why B is right. Not helpful to others.","poster":"cmfchong","comment_id":"333003","upvote_count":"1"}],"comment_id":"187577","content":"Wow. Answer B is very wrong. How does doing a rolling restart will result in the Linux expert able to go in to the instance to investigate further? My mind is blown with this \"answer\"."},{"upvote_count":"1","content":"C is the answer","poster":"asheesh0574","timestamp":"1600944720.0","comment_id":"186079"},{"timestamp":"1600135380.0","poster":"AshokC","content":"Answer: C","comment_id":"179613","upvote_count":"1"},{"poster":"passtest100","comment_id":"178702","content":"A is better. Access VM does not mean you should login the VM OS. Through the console, you can get the information of the OS booting up, which also means access the VM. So the VM retarting every 5 seconds does not mean you can not access the VM.","timestamp":"1599999180.0","upvote_count":"1"},{"comment_id":"168477","upvote_count":"1","poster":"Kabiliravi","timestamp":"1598621340.0","content":"C is correct"},{"poster":"peterbrv","upvote_count":"1","content":"I strongly suggest to check out https://www.itexams.com/exam/Professional%20Cloud%20Architect?","comment_id":"164699","timestamp":"1598216160.0"},{"content":"C --- 100%","upvote_count":"1","poster":"peterbrv","timestamp":"1598215980.0","comment_id":"164696"},{"upvote_count":"1","comment_id":"162470","timestamp":"1597952580.0","poster":"wiqi","content":"C makes sense."},{"timestamp":"1595048580.0","comment_id":"137652","content":"C should be the correct answer.. health-check might be causing auto-restarts and to debug he should login into VM instances.","poster":"TusharPinjan","upvote_count":"2"},{"poster":"saurabh1805","upvote_count":"3","timestamp":"1594320360.0","comment_id":"130910","content":"Question is to provide ssh access. So A and B is out of equation.\nautoScaling is already disabled so you dont have to disable that agin. And since instance is gettign auto restarted you will prefer to disable alerts till you are doing investigation.\n\nSO for me C is correct answer"},{"upvote_count":"2","content":"C is the correct answer here. \nRead the question, Linux admin needs access to VM","comment_id":"128522","poster":"cyrus86","timestamp":"1594088580.0"},{"poster":"mlantonis","upvote_count":"1","timestamp":"1592902800.0","comment_id":"117255","content":"Only C makes sense"},{"poster":"Tushant","content":"C is the correct answer","comment_id":"114564","upvote_count":"1","timestamp":"1592638140.0"},{"comment_id":"110452","timestamp":"1592184720.0","upvote_count":"1","poster":"shashu07","content":"Correct Answer is C\n• C. Disable the health check for the instance group. Add his SSH key to the project-wide SSH keys \n\nhttps://cloud.google.com/compute/docs/instance-groups/autohealing-instances-in-migs\n\nHealth checks used for autohealing should be conservative so they don't preemptively delete and recreate your instances. When an autohealer health check is too aggressive, the autohealer might mistake busy instances for failed instances and unnecessarily restart them, reducing availability"},{"upvote_count":"1","timestamp":"1592152380.0","poster":"HD1803","comment_id":"110253","content":"C is the right"},{"poster":"syu31svc","comment_id":"109225","timestamp":"1592030880.0","upvote_count":"1","content":"Cause of the restart is the health check so you have to disable it in order to investigate. Answer is C no doubt"},{"upvote_count":"1","timestamp":"1591819560.0","poster":"Sundeepk","content":"looks like C is correct because health checks can delete and recreate VMS","comment_id":"107150"},{"upvote_count":"1","content":"C, for sure.\nAutoscaling is already disabled..","timestamp":"1591772880.0","comment_id":"106550","poster":"gfhbox0083"},{"content":"totally agree with C","poster":"rbrto","timestamp":"1591478220.0","comment_id":"104139","upvote_count":"2"},{"content":"C is the correct answer","poster":"Nirms","timestamp":"1591111140.0","comment_id":"100959","upvote_count":"3"},{"timestamp":"1590652260.0","poster":"AD2AD4","upvote_count":"1","comments":[{"comment_id":"98101","comments":[{"poster":"Ziegler","timestamp":"1591190040.0","comment_id":"101632","comments":[{"content":"autoscaling is disabled instead of health check, He also cannot access to vm if VM are restarted so initially you need to disable health check from managed instance group in order to connect by ssh","timestamp":"1591478100.0","comment_id":"104136","poster":"rbrto","upvote_count":"5"}],"content":"But health check is already disabled according to the question, why disabling health check again? Please help with the reason for C as the right answer. Thanks","upvote_count":"1"},{"comment_id":"254067","content":"is this final final ;)","upvote_count":"1","timestamp":"1609161780.0","poster":"GM007"}],"upvote_count":"1","poster":"AD2AD4","content":"Final Decision to go with Option C","timestamp":"1590738960.0"}],"content":"Final Decision to go with Option A as its IAM question","comment_id":"97353"},{"comment_id":"94079","poster":"gcp_aws","timestamp":"1590180300.0","content":"C is the answer... Project viewer is too broader a role for this purpose.","upvote_count":"1"},{"poster":"darwinmak","upvote_count":"2","comment_id":"91095","content":"I will choose C.\nNote: To give a user SSH to VM instances and prevent access to all APIs, add the user's SSH keys to the project or instance instead of adding the user to the project and granting them wide ranging permissions.\nhttps://cloud.google.com/compute/docs/access","timestamp":"1589788140.0"},{"comment_id":"89261","content":"C or SB","timestamp":"1589508300.0","poster":"Jack_in_Large","upvote_count":"1"},{"upvote_count":"4","poster":"Erso","timestamp":"1588855260.0","comments":[{"content":"You have my vote for \"A\" as the colleague may not be part of the same project team and thus shouldn't grant anything more than Viewer permission.","timestamp":"1589272080.0","comment_id":"87501","upvote_count":"3","poster":"skywalker","comments":[{"comment_id":"88789","upvote_count":"3","timestamp":"1589438820.0","poster":"xionis","content":"Check the note on the link\nhttps://cloud.google.com/compute/docs/access#accesscontrolusers\nCorrect answer c"}]}],"comment_id":"85174","content":"Probably the correct answer is A. Always least privilege and in this case we have not so much details about this \"collegue\"..."},{"comment_id":"73264","content":"A - The question is about \"access control\", not resolving the bottom line issue. Now, Google recommended practice is the 'least privilege', which encourages you to only give the required accesses. Now, who is your colleague? is your colleague responsible for the instances or it happen to know Linux stuff? I really should not care if she is Linux expert. Why does she needs full access (sudo) to the instance? Can she work with a viewer access? YES I believe she could use a primitive IAM Viewer, which grants her Read-only permissions to all resources. https://cloud.google.com/compute/docs/access","upvote_count":"4","timestamp":"1586600220.0","poster":"Googler2","comments":[{"upvote_count":"3","poster":"yeeba","comment_id":"86076","content":"But he still can't logon with just the viewer access, as the machine keeps rebooting","timestamp":"1589032080.0"},{"comment_id":"94943","content":"A is the right answer. The question is more about access to your Linux expert colleague and not really about you resolving the problem with the vm, else B could have been the best answer.","timestamp":"1590327120.0","poster":"Ziegler","upvote_count":"2"}]},{"poster":"anton_royce","timestamp":"1585900620.0","content":"B, because the expert can only access after the Linux after restarting stop.","comment_id":"70669","upvote_count":"2"},{"comment_id":"60261","poster":"Javed","content":"C is correct","timestamp":"1583577420.0","upvote_count":"1"},{"poster":"[Removed]","timestamp":"1582873200.0","comment_id":"56379","upvote_count":"2","content":"I Choose B in the exam"},{"timestamp":"1582070820.0","content":"Your instances are restarting and you would want to solve that with a restart? The problem is highly likely the MIG health check failing and the service restarting the instances. Only C would stop them restarting.","comments":[{"poster":"SMS","timestamp":"1584224820.0","upvote_count":"1","content":"C is the right answer. Take out the health check, add ssh key temporarily until debugging is done","comment_id":"64059"}],"upvote_count":"4","comment_id":"52297","poster":"mawsman"},{"poster":"Smart","upvote_count":"5","content":"B & D are wrong. The question is asking for access into VMs that requires SSH. Project viewer role won't enable that. Additionally, this role is very broad. Besides, in order to get into VMs, VMs need to exist longer than 5 seconds i.e. disable the health check. Correct answer is C","timestamp":"1581725160.0","comment_id":"50709"},{"poster":"ADVIT","comment_id":"49840","timestamp":"1581571680.0","upvote_count":"4","content":"Only C"},{"content":"answer: C","comment_id":"44770","poster":"2g","upvote_count":"4","timestamp":"1580392560.0"},{"content":"C i scorrect","poster":"natpilot","comment_id":"42820","upvote_count":"4","timestamp":"1580029800.0"},{"content":"Question is for Access (You need to make sure that he can access the VMs). \nSo If I Disable the health check for the instance group and Add his SSH key to the project-wide SSH keys ====> I am actually giving sudo access to the Linux Expert ? An d so I would go with C.\n\nhttps://medium.com/@0d6e/options-for-managing-ssh-access-on-google-compute-engine-e629b3203664","poster":"AWS56","upvote_count":"5","comment_id":"37371","timestamp":"1578645300.0"},{"comments":[{"upvote_count":"2","timestamp":"1614261360.0","content":"Nothing says so in the question. \nIf you're code is not starting on the instance, it won't start better on the new one.\nIf your health check malfunctions instance will continue to be shutdown after the restart hence the answer is \"disable healthcheck\" and grant ssh access to your colleague for help","comment_id":"299089","poster":"Alekshar"}],"upvote_count":"1","timestamp":"1576620060.0","content":"a rolling update or restart automatically fixes the problem","comment_id":"30474","poster":"passnow"},{"timestamp":"1576516440.0","upvote_count":"4","content":"question is for access so A is right","poster":"liam123","comment_id":"30137"},{"timestamp":"1576341240.0","upvote_count":"8","poster":"aviv","content":"Answer should be C, instances are being restarted due to a failed health check.","comment_id":"29595"},{"poster":"Jayant","timestamp":"1574465760.0","comment_id":"23762","content":"question is asking to grant access not to resolve issues \"You need to make sure that he can access the VMs. What should you do?\" ------ why it should not be \"A\"","comments":[{"content":"project viewer in the whole project ? that role make no sense","comment_id":"104143","timestamp":"1591478340.0","poster":"rbrto","upvote_count":"4"},{"content":"Google's best security pratice is the principle of least privilege, only grant to someone what he needs to do its job nothing more.","comment_id":"299085","timestamp":"1614261300.0","poster":"Alekshar","upvote_count":"6"}],"upvote_count":"15"},{"upvote_count":"4","timestamp":"1572026580.0","content":"The answer should be C, B is assuming that there is no problem with your code and it is just Google malfunctioning.","poster":"Eroc","comment_id":"17425"},{"content":"Can anyone explain why B and not C?","poster":"crypt0","upvote_count":"2","timestamp":"1571726160.0","comment_id":"16608","comments":[{"upvote_count":"6","comment_id":"151774","poster":"tartar","content":"C is ok","timestamp":"1596699480.0"},{"timestamp":"1598216100.0","content":"A rolling restart is shutting down and updating nodes one at a time (while the other nodes are running) until they're all updated. This keeps your site running while you update your cluster, whether it's physical, container, or image based. \nWe don't need to keep restarting nodes. We need to \"calm vm down\", so disable healthcheck","upvote_count":"1","poster":"peterbrv","comment_id":"164698"},{"timestamp":"1602763680.0","comments":[{"comment_id":"215597","timestamp":"1604880900.0","upvote_count":"1","poster":"pepYash","content":"precisely:\nhttps://cloud.google.com/compute/docs/access#granting_users_ssh_access_to_vm_instances"}],"upvote_count":"7","content":"it's C\n\"Note: To give a user SSH to VM instances and prevent access to all APIs, add the user's SSH keys to the project or instance instead of adding the user to the project and granting them wide ranging permissions.\"\nhttps://cloud.google.com/compute/docs/access","comment_id":"200464","poster":"Mihai_"},{"upvote_count":"2","poster":"nitinz","comment_id":"303658","content":"C, disable health check in MIG.","timestamp":"1614898260.0"}]}],"isMC":true,"exam_id":4,"url":"https://www.examtopics.com/discussions/google/view/6953-exam-professional-cloud-architect-topic-1-question-46/","answer_description":"","unix_timestamp":1571726160,"answer_images":[],"question_id":142,"answer_ET":"C","question_text":"You have an outage in your Compute Engine managed instance group: all instances keep restarting after 5 seconds. You have a health check configured, but autoscaling is disabled. Your colleague, who is a Linux expert, offered to look into the issue. You need to make sure that he can access the VMs. What should you do?"},{"id":"fhXGqy0fhxFOHl871K7K","unix_timestamp":1622993760,"url":"https://www.examtopics.com/discussions/google/view/54735-exam-professional-cloud-architect-topic-1-question-47/","discussion":[{"poster":"rishab86","comment_id":"376166","content":"Link : https://cloud.google.com/security/compliance/pci-dss \nClearly mention GKE as PCI DSS-Compliant but not all GCP service are PCI DSS-Compliant so answer is definitely C.","upvote_count":"47","timestamp":"1622993760.0","comments":[{"timestamp":"1659688620.0","comment_id":"642846","upvote_count":"8","content":"In 2022, GCP is now fully PCI-DSS compliant, so technically D is perfectly true.\nBut you still have to check that your application is PCI-DSS compliant.\n\nso C is still the best answer.","poster":"Mikado211"},{"upvote_count":"1","timestamp":"1635174720.0","comment_id":"467514","poster":"MaxNRG","content":"C – Kubernetes Engine provides tools you need to build to PCI-DSS compliant environment."},{"content":"But, The paragraph 3 says that all products of google are certified by PCI.","timestamp":"1638704100.0","comment_id":"494272","upvote_count":"2","poster":"haroldbenites"}]},{"content":"C: GKE & Compute Engine is PCI DSS compliant while Cloud Function, App Engine are not PC compliant","upvote_count":"5","poster":"aviratna","timestamp":"1624776660.0","comment_id":"391813"},{"upvote_count":"3","poster":"Ekramy_Elnaggar","timestamp":"1731959700.0","content":"Selected Answer: C\n1. GKE and PCI DSS: While GKE itself isn't inherently PCI DSS compliant, it provides the infrastructure and tools you need to build a compliant environment. You'll need to configure it correctly, implement security measures, and follow best practices.\n\n2. Shared Responsibility Model: Google Cloud Platform operates under a shared responsibility model. Google is responsible for securing the underlying infrastructure, while you are responsible for securing your applications and data within that environment.   \n\n3. Flexibility for Compliance: GKE offers features like private clusters, network policies, and integration with security tools that help you meet PCI DSS requirements.","comment_id":"1314194"},{"timestamp":"1690443180.0","upvote_count":"1","poster":"eka_nostra","content":"Selected Answer: C\nWe still have to configure our env to comply with PCI/DSS. https://cloud.google.com/architecture/pci-dss-compliance-in-gcp#kubernetes_engine","comment_id":"964478"},{"content":"The most accurate statement is option C: GKE and GCP provide the tools you need to build a PCI DSS-compliant environment.\n\nGoogle Kubernetes Engine (GKE) is a fully managed service that allows you to deploy and manage containerized applications on Google Cloud. It is not specifically certified for PCI DSS hosting, but it can be used as part of a PCI DSS-compliant environment if the necessary controls and safeguards are in place.\n\nGoogle Cloud Platform (GCP) provides a range of tools and services that can be used to build a PCI DSS-compliant environment, including Cloud Identity and Access Management (IAM) for controlling access to resources, Cloud Key Management Service (KMS) for managing encryption keys, and Cloud Security Command Center for monitoring and detecting security threats.","upvote_count":"4","timestamp":"1671615420.0","poster":"omermahgoub","comment_id":"752079","comments":[{"content":"Option A: App Engine is a fully managed platform for building and deploying web and mobile applications, but it is not the only compute platform on GCP that is certified for PCI DSS hosting. Other compute platforms such as Compute Engine and Google Kubernetes Engine can also be used as part of a PCI DSS-compliant environment.\n\nOption B: GKE is not considered shared hosting and can be used as part of a PCI DSS-compliant environment if the necessary controls and safeguards are in place.\n\nOption D: While Google Cloud Platform is certified PCI-compliant, not all of its services are automatically usable in a PCI DSS-compliant environment. It is up to the user to ensure that they are using the appropriate controls and safeguards to meet the requirements of the PCI DSS.","comment_id":"752083","timestamp":"1671615480.0","upvote_count":"3","poster":"omermahgoub"}]},{"poster":"abirroy","comment_id":"654331","upvote_count":"1","content":"Selected Answer: C\nC is the right answer","timestamp":"1661884980.0"},{"poster":"[Removed]","comment_id":"545479","upvote_count":"3","timestamp":"1644611160.0","content":"Selected Answer: C\nI got similar question on my exam."},{"timestamp":"1640434440.0","poster":"vincy2202","content":"Selected Answer: C\nC is the correct answer","comment_id":"509098","upvote_count":"1"},{"content":"Go for C.","timestamp":"1638704160.0","poster":"haroldbenites","comment_id":"494274","upvote_count":"1"},{"poster":"SHOURYA_SOOD","comment_id":"486445","upvote_count":"1","timestamp":"1637815860.0","content":"Selected Answer: C\nC- All of them: GKE, GCE, and GAE ate PCI-DSS-Compliant but A & B says it's only GAE and GCE respectively so cancel them out.\nD says all of GCP is PCI DSS-Compliant but it's not true.\nSo, C seems to be the right answer."},{"timestamp":"1633545060.0","upvote_count":"1","content":"C is the right answer","poster":"imranmani","comment_id":"458402"},{"comment_id":"401867","timestamp":"1625744760.0","upvote_count":"3","content":"Answer is C","poster":"MamthaSJ"},{"upvote_count":"1","comment_id":"399760","content":"C. GKE and GCP provide the tools you need to build a PCI DSS-compliant environment.","poster":"victory108","timestamp":"1625559900.0"}],"topic":"1","answer_description":"","exam_id":4,"isMC":true,"question_text":"Your company is migrating its on-premises data center into the cloud. As part of the migration, you want to integrate Google Kubernetes Engine (GKE) for workload orchestration. Parts of your architecture must also be PCI DSS-compliant. Which of the following is most accurate?","answer_images":[],"answer_ET":"C","question_images":[],"timestamp":"2021-06-06 17:36:00","question_id":143,"answer":"C","answers_community":["C (100%)"],"choices":{"C":"GKE and GCP provide the tools you need to build a PCI DSS-compliant environment.","A":"App Engine is the only compute platform on GCP that is certified for PCI DSS hosting.","D":"All Google Cloud services are usable because Google Cloud Platform is certified PCI-compliant.","B":"GKE cannot be used under PCI DSS because it is considered shared hosting."}},{"id":"5WoqYlEfks0YGGbvNykR","answer_description":"","discussion":[{"content":"Answer is B:\n\nKeynotes from question:\n1- On-premise data sources\n2- Unfit data; not well maintained and degraded\n3- Google-recommended best practice to \"detect anomalies\" <<-Very important.\n\nExplanation:\nA & C - incorrect; Datalab does not provide anomaly detection OOTB. It is used more for data science scenarios like interactive data analysis and build ML models. \nB - CORRECT; DataPrep OOTB provides for fast exploration and anomaly detection and lists cloud storage as an ingestion medium. Refer to ELT pipeline architecture here = https://cloud.google.com/dataprep\nD - incorrect; At this time DataPrep cannot connect to SaaS or on-premise source. Not to be confused for DataFlow which can!","upvote_count":"63","comment_id":"334598","timestamp":"1618311720.0","poster":"JohnWick2020"},{"upvote_count":"12","poster":"Eroc","content":"Both B and D work, because the question says \"Google's Best Practices\" uploading the files first would keep the original copies Google encrypted and stored.","comments":[{"comment_id":"89267","upvote_count":"1","comments":[{"timestamp":"1596281100.0","comment_id":"148530","upvote_count":"9","content":"You can't connect DataPrep to your on-prem systems. You simply upload a file, but that is not connecting it to your systems. Because of that, I'd discard D and stay with B.","poster":"Musk"}],"poster":"skywalker","timestamp":"1589509140.0","content":"Both of them works...."},{"timestamp":"1596699960.0","poster":"tartar","content":"B is ok","comment_id":"151777","upvote_count":"9"},{"content":"B, dataprep = visually explore, clean, and prepare data for analysis","comment_id":"303661","timestamp":"1614898500.0","poster":"nitinz","upvote_count":"7"},{"content":"B is better choice","comment_id":"696582","upvote_count":"1","poster":"AzureDP900","timestamp":"1665954660.0"}],"timestamp":"1572093060.0","comment_id":"17594"},{"upvote_count":"1","poster":"Sib09","content":"Selected Answer: B\nyou have to bring data to Cloud storage before running data prep.","timestamp":"1740131040.0","comment_id":"1359706"},{"timestamp":"1731960120.0","upvote_count":"3","comment_id":"1314195","content":"Selected Answer: B\nWhy Cloud Storage is important ?\n1. Centralized repository: Cloud Storage provides a secure and scalable place to store your data. This makes it accessible to various GCP services.\n2. Data lake concept: This aligns with the idea of a data lake, where you bring raw data into a central location before processing and refining it.\n\nWhy Cloud Dataprep is a good fit ?\n1. Visual data exploration: Dataprep excels at helping you quickly understand your data through visualizations and profiling. This is crucial for identifying anomalies.\n2. Data cleaning and transformation: Dataprep makes it easy to clean and standardize your data, which is essential before anomaly detection. Inconsistent formats, missing values, and errors can skew your analysis.\n3. Built-in anomaly detection: Dataprep has features specifically designed to help you find anomalies. It can highlight unusual values, outliers, and patterns.","poster":"Ekramy_Elnaggar"},{"timestamp":"1723541580.0","poster":"snehaso","upvote_count":"1","content":"Datalab was shutdown. Its replacement is vertex AI. Read question accordingly","comment_id":"1265074"},{"upvote_count":"4","content":"Cloud Datalab is a powerful interactive tool created to explore, analyze, transform, and visualize data and build machine learning models on Google Cloud Platform.\nDataprep by Trifacta is an intelligent data service for visually exploring, cleaning, and preparing structured and unstructured data for analysis, reporting, and machine learning.\nDataprep do not have an integration for on-prem: https://console.cloud.google.com/marketplace/product/endpoints/cloud-dataprep-editions-v2?project=fast-art-401415\n\nSo, clearly, the only option left is B.","comment_id":"1067853","timestamp":"1699708740.0","poster":"thewalker"},{"timestamp":"1692731760.0","upvote_count":"1","content":"B is correct.","poster":"heretolearnazure","comment_id":"987707"},{"content":"Today, data ingestion to DataPrep can be Application, file upload, database.\nso B is also now valid","upvote_count":"1","poster":"n_nana","comment_id":"824037","timestamp":"1677523560.0"},{"comments":[{"poster":"omermahgoub","timestamp":"1671615660.0","comment_id":"752086","upvote_count":"1","content":"Option A: Using Cloud Datalab to explore and clean your data is not a recommended approach, as Cloud Datalab is a collaborative data exploration and visualization platform that is not specifically designed for data preparation tasks such as cleansing and transformation.\n\nOption C: Connecting Cloud Datalab to your on-premises systems is not a recommended approach, as Cloud Datalab is a collaborative data exploration and visualization platform and is not designed for data preparation tasks such as cleansing and transformation.\n\nOption D: Connecting Cloud Dataprep to your on-premises systems is not necessary, as you can use Cloud Dataprep to explore and clean data stored in Cloud Storage."}],"comment_id":"752085","timestamp":"1671615660.0","content":"The recommended approach for detecting anomalies in your company data using Google-recommended practices is option B: Upload your files into Cloud Storage. Use Cloud Dataprep to explore and clean your data.\n\nCloud Storage is a highly scalable, durable, and secure object storage service that can be used to store and retrieve data from anywhere on the web. You can use Cloud Storage to store your company data files and make them available for analysis.\n\nCloud Dataprep is a fully managed data preparation service that allows you to quickly and easily explore, clean, and transform your data for analysis. It can help you detect anomalies in your data by providing features such as data profiling, data cleansing, and data transformation.","upvote_count":"2","poster":"omermahgoub"},{"content":"ok for B & D, but B is suitable to gcp","timestamp":"1670736480.0","comment_id":"741432","upvote_count":"1","poster":"allen_y_q_huang"},{"comment_id":"733521","upvote_count":"1","poster":"Smaks","timestamp":"1669964340.0","content":"Selected Answer: B\nDatalab is deprecated : https://cloud.google.com/datalab/docs\nNew Cloud Dataprep options will give connectivity to relational databases, business applications and extend our integrations across Google Cloud with Google Sheets: https://www.trifacta.com/blog/cloud-dataprep-trifacta/"},{"poster":"megumin","comment_id":"712410","timestamp":"1667748240.0","content":"Selected Answer: B\nok for B","upvote_count":"1"},{"upvote_count":"3","poster":"Cloudexplorer","timestamp":"1658680740.0","comment_id":"636143","content":"Could anyone provide a link where it explicitly says that Datprep does not connect to on-premises data sources. \n\nIn the ingestion layer on the diagram at https://cloud.google.com/dataprep it shows databases as a source. \nI can't see anywhere that there is a limitation connecting to on-premises. Would be great if someone could share that."},{"upvote_count":"1","comment_id":"624848","content":"Selected Answer: B\nIt's gotta be B.","timestamp":"1656528600.0","poster":"BigSteveO"},{"content":"Keyword : Anamolies Data prep is the only product ... So options A and C is eliminated ... Cost effective is storing the data in GCS Cloud storage ... So option is B","comment_id":"618129","timestamp":"1655538780.0","upvote_count":"1","poster":"Dhiraj03"},{"comment_id":"590391","poster":"nkit","upvote_count":"1","timestamp":"1650688200.0","content":"Selected Answer: B\nDataprep to detect anomalies in Data is the right choice."},{"upvote_count":"1","content":"B...It supports only CloudStorage and Bigquery...\"So you can start transforming datasets, you hereby instruct Google to allow Trifacta, who provides the service Dataprep in collaboration with Google, to view and modify project data in Cloud Storage and BigQuery, run Dataflow jobs, and use all project service accounts.\"","comment_id":"521242","poster":"GMats","timestamp":"1641869940.0"},{"content":"Go for B.","poster":"haroldbenites","comment_id":"494276","comments":[{"poster":"haroldbenites","comment_id":"494280","content":"The question says “best practice”. In GCP , a best practice for many use cases is load to cloud storage and then processing data.","timestamp":"1638704580.0","upvote_count":"1"}],"timestamp":"1638704340.0","upvote_count":"1"},{"poster":"joe2211","upvote_count":"1","comment_id":"489499","content":"Selected Answer: B\nvote B","timestamp":"1638143520.0"},{"timestamp":"1637299440.0","comment_id":"481353","content":"B is the right answer","upvote_count":"1","poster":"vincy2202"},{"content":"B is correct.\ndatalab: not used for clean,for virtualize and analysis purpose, so A is not correct","comment_id":"472657","poster":"exam_war","upvote_count":"1","timestamp":"1636040460.0"},{"timestamp":"1635913260.0","comment_id":"471911","poster":"FERIN_02","upvote_count":"2","content":"Input sources for GCP Dataprep are \n1) Local computer\n2) Cloud storage\n3) BigQuery\n\nHence option B"},{"timestamp":"1635447660.0","poster":"[Removed]","content":"B is correct.","upvote_count":"1","comment_id":"469435"},{"timestamp":"1635175020.0","upvote_count":"1","content":"B – Upload your files to Cloud Storage. Use Cloud Dateprep to analyze and clean up your data.\nThis is direct function of Cloud Dataprep – fast exploration and anomaly detection.\nD – doesn’t work since Dataprep cannot connect to on-prem systems. You need specify one of next sources for Dataprep: BigQuery, Cloud Storage, upload file directly.\nhttps://cloud.google.com/dataprep/","comment_id":"467516","poster":"MaxNRG"},{"timestamp":"1625744880.0","upvote_count":"1","content":"Answer is B","comment_id":"401869","poster":"MamthaSJ"},{"timestamp":"1621407720.0","comment_id":"361116","content":"B. Upload your files into Cloud Storage. Use Cloud Dataprep to explore and clean your data.","upvote_count":"2","poster":"victory108"},{"poster":"un","comment_id":"355592","upvote_count":"1","content":"B is correct","timestamp":"1620832860.0"},{"poster":"Ausias18","comment_id":"324740","content":"Answer is B","upvote_count":"1","timestamp":"1617166560.0"},{"timestamp":"1616765760.0","poster":"lynx256","comments":[{"upvote_count":"1","poster":"lynx256","timestamp":"1616766300.0","content":"Ref: https://docs.trifacta.com/display/DP/Connection+Types\nAs you can see, for some DB (especially RDBMS) we have to buy Dataprep \"Premium\" edition.\nBut there doesn't matter if source is in GCP or on prem.","comment_id":"321171"}],"comment_id":"321159","content":"IMO - D.\nIn question we read \"Your company has multiple on-premises systems that serve as sources for reporting.\". So - I guess - we have connection to them from CGP. So Cloud Dataprep by TRIFACTA® INC can be connected to these on-prem data services. If so, there is no sense B. Moreover - in B we have to repeat our this procedure (upload + clean) whereas in D we work on the source directly. \nOf course, we cannot use Dataprep to REWRITE cleaned data in place (Dataprep is not for this purpose). We can use Dataprep to REPORT cleaned data to a new sink.","upvote_count":"2"},{"content":"„Your company has multiple on-premises systems that serve as sources for reporting.”\nIn option B we must export the data from many sources to many files on GCS and then start the Dataprep process.\nIn option D we connect Dataprep to multiple sources and start the process. \nI choose D.","upvote_count":"1","poster":"pawel_ski","timestamp":"1616222100.0","comment_id":"315425"},{"timestamp":"1614319260.0","upvote_count":"2","comments":[{"timestamp":"1616766480.0","comment_id":"321174","upvote_count":"1","content":"I think Premium is edition of Dataprep. CMIIW but in the question there is no information, what edition of Dataprep we want to use.","poster":"lynx256"}],"comment_id":"299564","content":"I think B is the correct answer as Cloud Data Prep can connect to GCS. Reason for not going with D is Relational database connection is limited feature with Cloud Data Prep Premium \nhttps://docs.trifacta.com/display/DP/Connection+Types","poster":"Vika"},{"content":"Question doesn't call out any data regulatory requirements, so I would assume to connect DataPrep to on-prem as mentioned in D, I would rather go with practice to upload the data to cloud storage and use DataPrep which is B","upvote_count":"1","comment_id":"279134","poster":"GS14","timestamp":"1611904680.0"},{"content":"Dataprep can get data from on-prem sources. No need to upload to GCS. If you want to store it in GCS, Dataprep can help.\nSo I prefer D to B.","timestamp":"1605856080.0","upvote_count":"1","comment_id":"223372","poster":"fankan","comments":[{"comment_id":"223377","poster":"fankan","content":"Sorry, my mistake, B is the answer.","timestamp":"1605856500.0","upvote_count":"1"}]},{"timestamp":"1601538420.0","upvote_count":"1","comment_id":"190825","poster":"occupatissimo","content":"question ask for \"detect anomalies\" only and not also to \"maintain data against degradation\", so data can still reside on-premises. Then using storage is necessary to continuously update the data. Why not D?"},{"content":"B - The file has to be uploaded to Cloud storage since Dataprep cannot connect to an on-premise source.","comment_id":"179919","timestamp":"1600182960.0","poster":"AshokC","upvote_count":"1"},{"timestamp":"1597643280.0","comment_id":"159652","poster":"jespinosar","upvote_count":"4","content":"B) is Ok. \nTrying to justify why D) is not a good choice...\nNotice D) says \"Connect Cloud Dataprep to your on-premises systems...\", but you cannot connect DataPrep to your on-premise...your on-premise might *upload* data to DataPrep, so it's push data, not pull data.\nBesides, D) would supose managing all the retries (not as simple and resumable as gsutil) and I think DataPrep can manage several files at once (only possible it the data is on GCS)"},{"comment_id":"147683","poster":"balajee14","timestamp":"1596141060.0","content":"Both B and D Seems to be correct. I agree it says \"Google Recommended Practice\". \nBut in Question they say \"Detect Anomaly\", If that's case, yes just take a copy in Storage, Detect the Anomaly. But in answers they say \"Explore and Clean the Data too\". So if i go with B, Post Cleaning the file in Storage, What would i do? How would i sent it back to the Systems back for Reports to be generated? It does not says Report is generated from Cloud right, if its from Cloud then yeah use these Cleaned up files as Source. So to Detect Anomaly and Clean it , You need Prep to Connect from On-premise to the Core system that is yielding the data so that Good reports can be generated. So why not go with D?","upvote_count":"2"},{"upvote_count":"3","content":"B is the correct answer. \nremember Cloud Datalab is a tool for data exploration, analysis, visualization, and machine learning","poster":"cyrus86","timestamp":"1594088700.0","comment_id":"128525"},{"comment_id":"117259","upvote_count":"2","timestamp":"1592903040.0","content":"I agree with B","poster":"mlantonis"},{"upvote_count":"2","timestamp":"1592644320.0","comment_id":"114626","content":"B is the correct answer","poster":"Tushant"},{"comment_id":"106554","upvote_count":"2","timestamp":"1591773360.0","content":"B, for sure.\nCloud Dataprep is an intelligent data service for visually exploring, cleaning, and preparing structured and unstructured data for analysis, reporting, and machine learning.","poster":"gfhbox0083"},{"poster":"Ziegler","content":"B is the correct answer","upvote_count":"1","timestamp":"1591261620.0","comment_id":"102259"},{"poster":"Nirms","upvote_count":"2","content":"B is the correct answer","timestamp":"1591111440.0","comment_id":"100964"},{"comment_id":"98104","poster":"AD2AD4","content":"Final Decision to go with Option B","upvote_count":"2","timestamp":"1590739020.0"},{"poster":"gcp_aws","content":"B is the correct answer","upvote_count":"2","timestamp":"1590180540.0","comment_id":"94081"},{"content":"B is correct..DataPrep for data cleaning while GCS for storage","comment_id":"74782","upvote_count":"2","timestamp":"1586939880.0","poster":"PRC"},{"comment_id":"56369","comments":[{"comments":[{"timestamp":"1599697500.0","comment_id":"176795","poster":"h18","upvote_count":"5","content":"oh there is a moderator approval also... thats why this site has only positive comments. no negative comments."}],"comment_id":"176794","upvote_count":"4","content":"How did you get all the questions in exam? From last 7-8 questions, you are just commenting this? You got all the questions in sequence :) or you are paid to put such comments?","timestamp":"1599697440.0","poster":"h18"}],"upvote_count":"2","content":"Agree B. Looks correct. Selected B in exam","timestamp":"1582872840.0","poster":"[Removed]"},{"content":"Answer: B","timestamp":"1580392740.0","poster":"2g","upvote_count":"2","comment_id":"44775"},{"content":"Agree B","comment_id":"38022","poster":"AWS56","upvote_count":"2","timestamp":"1578831960.0"},{"timestamp":"1576341540.0","comment_id":"29598","upvote_count":"4","poster":"aviv","content":"Agreed with B. Dataprep provides data cleaning and automatically identifies anomalies in the data. It can integrated with Cloud Storage and BigQuery"}],"answers_community":["B (100%)"],"question_id":144,"timestamp":"2019-10-26 14:31:00","topic":"1","exam_id":4,"url":"https://www.examtopics.com/discussions/google/view/7267-exam-professional-cloud-architect-topic-1-question-48/","answer_images":[],"isMC":true,"question_text":"Your company has multiple on-premises systems that serve as sources for reporting. The data has not been maintained well and has become degraded over time.\nYou want to use Google-recommended practices to detect anomalies in your company data. What should you do?","answer":"B","question_images":[],"choices":{"C":"Connect Cloud Datalab to your on-premises systems. Use Cloud Datalab to explore and clean your data.","A":"Upload your files into Cloud Storage. Use Cloud Datalab to explore and clean your data.","B":"Upload your files into Cloud Storage. Use Cloud Dataprep to explore and clean your data.","D":"Connect Cloud Dataprep to your on-premises systems. Use Cloud Dataprep to explore and clean your data."},"answer_ET":"B","unix_timestamp":1572093060},{"id":"6rCzOAbSmnxSeoJqTQA2","topic":"1","answer":"C","question_text":"Google Cloud Platform resources are managed hierarchically using organization, folders, and projects. When Cloud Identity and Access Management (IAM) policies exist at these different levels, what is the effective policy at a particular node of the hierarchy?","answer_ET":"C","answers_community":["C (100%)"],"url":"https://www.examtopics.com/discussions/google/view/6846-exam-professional-cloud-architect-topic-1-question-49/","answer_images":[],"exam_id":4,"timestamp":"2019-10-20 15:45:00","choices":{"A":"The effective policy is determined only by the policy set at the node","D":"The effective policy is the intersection of the policy set at the node and policies inherited from its ancestors","B":"The effective policy is the policy set at the node and restricted by the policies of its ancestors","C":"The effective policy is the union of the policy set at the node and policies inherited from its ancestors"},"isMC":true,"question_images":[],"answer_description":"","question_id":145,"discussion":[{"timestamp":"1576622700.0","content":"The effective policy for a resource is the union of the policy set at that resource and the policy inherited from its parent.https://cloud.google.com/iam/docs/resource-hierarchy-access-control","upvote_count":"33","poster":"passnow","comment_id":"30476"},{"content":"You can set IAM policies at the level of the node, in addition to policies inherited from its parent. Hence, it is a union.","comment_id":"536803","poster":"ghadxx","upvote_count":"14","timestamp":"1643622780.0"},{"upvote_count":"3","poster":"Ekramy_Elnaggar","content":"Selected Answer: C\nHere's how IAM policies work in GCP's hierarchical structure:\n1. Hierarchy: GCP resources are organized in a hierarchy:\n - Organization: The root node representing your company.\n - Folders: Used to organize projects within the organization.\n - Projects: Containers for your resources (VMs, databases, etc.).\n2. Inheritance: IAM policies are inherited down the hierarchy. This means a policy set at the Organization level applies to all folders and projects within it.\n3. Union of Policies: When you have policies at different levels, the effective policy at a particular node (e.g., a project) is the combination (union) of:\n - The policy set directly at that node.\n - All the policies inherited from its parent folder and the organization.\n\nExample: If a user has \"Viewer\" access at the Organization level and \"Editor\" access at the Project level, their effective permission on that project is \"Editor\" (the higher permission).","timestamp":"1731960300.0","comment_id":"1314196"},{"comment_id":"974809","poster":"Di4sa","timestamp":"1691422260.0","content":"Selected Answer: C\nFrom google doc: Google Cloud resources are organized hierarchically, where the organization node is the root node in the hierarchy, the projects are the children of the organization, and the other resources are descendants of projects. You can set allow policies at different levels of the resource hierarchy. Resources inherit the allow policies of the parent resource. The effective allow policy for a resource is the union of the allow policy set at that resource and the allow policy inherited from its parent.","upvote_count":"3"},{"comment_id":"752097","poster":"omermahgoub","comments":[{"poster":"omermahgoub","comment_id":"752098","timestamp":"1671616020.0","content":"Option A: The effective policy is not determined only by the policy set at the node, as policies set at higher levels in the hierarchy can also have an impact on the effective policy.\n\nOption B: The effective policy is not restricted by the policies of its ancestors, as the policies of its ancestors can also be included in the effective policy if they allow access.\n\nOption C: The effective policy is not the union of the policy set at the node and policies inherited from its ancestors, as the intersection of the policies is used to determine the effective policy.","upvote_count":"1"}],"timestamp":"1671616020.0","content":"The effective policy at a particular node in the resource hierarchy in GCP is determined by the intersection of the policy set at the node and policies inherited from its ancestors, as described in option D\n\nCloud IAM policies in GCP are hierarchical, meaning that policies set at higher levels of the resource hierarchy can be inherited by lower levels. When a user or service account attempts to access a resource, the effective policy at that resource is determined by evaluating the policies set at the resource itself and all of its ancestors in the hierarchy. If any of the policies deny access, the user or service account will be denied access.\n\nFor example, consider the following resource hierarchy:\nOrganization => Folder => Project => Compute Engine instance\nIf an IAM policy is set at the organization level that allows read access to all Compute Engine instances, and a policy is set at the project level that denies read access to a specific Compute Engine instance, the effective policy for that instance will be the intersection of the two policies, which will be to deny read access to the instance.","upvote_count":"1"},{"upvote_count":"2","poster":"habros","comment_id":"728167","content":"Selected Answer: C\nC. Is a skewed wording question. Cannot be comprehended right away.","timestamp":"1669550100.0"},{"poster":"megumin","upvote_count":"1","comment_id":"712412","content":"Selected Answer: C\nok for C","timestamp":"1667748360.0"},{"comment_id":"701764","content":"Selected Answer: C\nC is correct answer","timestamp":"1666469700.0","upvote_count":"1","poster":"Mahmoud_E"},{"content":"English as a second language will struggle here. Good luck to us","comment_id":"696925","upvote_count":"5","poster":"zr79","timestamp":"1665984060.0"},{"poster":"BiddlyBdoyng","comment_id":"683733","timestamp":"1664554500.0","upvote_count":"3","content":"A: Would mean polcies set at the project or higher meant nothing, this is obviously wrong\nB: would mean you could not grant a permissions to a single VM, it would need to be at project or above (you restrict by not giving the permission)\nC : The permission is the sum of all the permissions you are given through the hierarchy, this is correct, you cannot restrict once it is given at a higher level.\nD: Would mean you would need the permission set at ancestor and the node, this would mean to get access to a single VM you would need to be given access to all VMs at the project level."},{"upvote_count":"2","content":"C is correct answer as it inheritance is the basic model of IAM","comment_id":"675972","timestamp":"1663842120.0","poster":"holerina"},{"upvote_count":"1","content":"Selected Answer: C\nC is correct","comment_id":"601471","timestamp":"1652513520.0","poster":"avinashvidyarthi"},{"upvote_count":"3","timestamp":"1640679900.0","content":"C\nGoogle Cloud resources are organized hierarchically, where the organization node is the root node in the hierarchy, the projects are the children of the organization, and the other resources are descendants of projects. You can set Identity and Access Management (IAM) policies at different levels of the resource hierarchy. Resources inherit the policies of the parent resource. The effective policy for a resource is the union of the policy set at that resource and the policy inherited from its parent.","comment_id":"510911","poster":"Atnafu"},{"content":"C is the correct answer","poster":"vincy2202","comment_id":"509100","upvote_count":"2","timestamp":"1640434800.0"},{"content":"Go for C.","timestamp":"1638704640.0","comment_id":"494281","poster":"haroldbenites","upvote_count":"1"},{"poster":"MamthaSJ","upvote_count":"3","content":"Answer is C","timestamp":"1625744940.0","comment_id":"401872"},{"comment_id":"361113","upvote_count":"2","content":"C. The effective policy is the union of the policy set at the node and policies inherited from its ancestors","poster":"victory108","timestamp":"1621407600.0"},{"poster":"DuncanK53","content":"Def answer C. Key word is 'union'.","timestamp":"1621257240.0","comment_id":"359564","upvote_count":"1"},{"comment_id":"324743","timestamp":"1617166680.0","upvote_count":"3","content":"Answer is C","poster":"Ausias18"},{"content":"C is ok","comment_id":"321027","upvote_count":"1","poster":"lynx256","timestamp":"1616754840.0"},{"upvote_count":"3","poster":"Darzan","content":"C is the answer. Effective policy is the union of policy set at the resource and the policy inherited from the parents (Organization, folder, and project)","timestamp":"1614041820.0","comment_id":"297052"},{"upvote_count":"1","comment_id":"277407","timestamp":"1611707220.0","content":"You can set an IAM policy at the organization level, the folder level, the project level, or (in some cases) the resource level. Resources inherit the policies of the parent node. If you set a policy at the Organization level, it is inherited by all its child folders and projects, and if you set a policy at the project level, it is inherited by all its child resources.","poster":"bnlcnd"},{"upvote_count":"1","content":"C - https://cloud.google.com/iam/docs/resource-hierarchy-access-control","timestamp":"1600185660.0","poster":"AshokC","comment_id":"179942"},{"upvote_count":"1","timestamp":"1599703920.0","poster":"h18","content":"c is the answer","comment_id":"176842"},{"upvote_count":"1","poster":"RM07","timestamp":"1594352520.0","content":"Ans: C is the correct ans no doubt in that.","comment_id":"131111"},{"poster":"mlantonis","upvote_count":"1","timestamp":"1592902980.0","comment_id":"117258","content":"C the union."},{"upvote_count":"1","comment_id":"114629","timestamp":"1592644560.0","content":"C is the correct answer","poster":"Tushant"},{"content":"C, for sure.\nthe union","poster":"gfhbox0083","upvote_count":"1","timestamp":"1591773480.0","comment_id":"106557"},{"content":"C is the correct answer","poster":"Nirms","timestamp":"1591111620.0","upvote_count":"1","comment_id":"100969"},{"timestamp":"1590739080.0","comment_id":"98105","content":"Final Decision to go with Option C","poster":"AD2AD4","upvote_count":"1"},{"comment_id":"94082","upvote_count":"2","content":"C is the correct answer","timestamp":"1590180600.0","poster":"gcp_aws"},{"content":"Answer C. Selected C in exam","poster":"[Removed]","upvote_count":"2","comment_id":"56371","timestamp":"1582872900.0"},{"content":"Answer: C","upvote_count":"2","poster":"2g","timestamp":"1580392800.0","comment_id":"44776"},{"upvote_count":"2","comment_id":"40424","timestamp":"1579374420.0","poster":"sri007","content":"c is ans"},{"content":"https://cloud.google.com/iam/docs/policies","comments":[{"comment_id":"157968","content":"C is ok","poster":"tartar","timestamp":"1597396200.0","upvote_count":"5"},{"comment_id":"210426","timestamp":"1604234280.0","upvote_count":"2","content":"C it is","poster":"kumarp6"},{"timestamp":"1614898560.0","poster":"nitinz","upvote_count":"1","content":"C policy = Union","comment_id":"303663"}],"upvote_count":"3","timestamp":"1571579100.0","comment_id":"16236","poster":"MeasService"}],"unix_timestamp":1571579100}],"exam":{"provider":"Google","isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":false,"name":"Professional Cloud Architect","id":4,"numberOfQuestions":279,"isBeta":false},"currentPage":29},"__N_SSP":true}