{"pageProps":{"questions":[{"id":"ZIxJI8HJpxSoff59q92K","unix_timestamp":1698317820,"answers_community":["BE (52%)","AE (40%)","8%"],"exam_id":6,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/124660-exam-professional-cloud-devops-engineer-topic-1-question-126/","discussion":[{"poster":"koo_kai","content":"Selected Answer: AE\nChose A, E","timestamp":"1730143620.0","comment_id":"1056351","upvote_count":"5"},{"content":"Selected Answer: AE\nTo reduce toil and minimize deployment time, the key is to reduce manual steps and optimize automation.\n\nA. Create a trigger to notify the required team:\n- If manual intervention is required, a trigger-based notification ensures that teams act quickly, reducing wait times and bottlenecks.\n- This improves efficiency by minimizing delays caused by human response times.\n\nE. Automate promotion approvals:\n- Manual approvals for every environment slow down deployments.\n- Automating promotions from development to test ensures a smoother and faster pipeline while still allowing manual approvals for later, more critical stages (e.g., production).","poster":"cachopo","timestamp":"1740751620.0","upvote_count":"1","comment_id":"1363062","comments":[{"content":"Why Not the Others?\n\nB. Dividing automation into smaller tasks does not necessarily speed up the pipeline. It might even introduce additional complexity.\n\nC. Using a script to automate pipeline creation helps initial setup, but it does not reduce deployment time in an existing pipeline.\n\nD. Adding more engineers to manual steps increases human dependency, which contradicts the goal of reducing toil.","timestamp":"1740751680.0","upvote_count":"1","poster":"cachopo","comment_id":"1363064"}]},{"content":"Selected Answer: CE\nmain purpose of toil is to reduce the CICD build, deploy time. Not to break the work in pieces. B is not toil, it is good to troubleshoot the code or cicd configuration","timestamp":"1740149220.0","comment_id":"1359795","upvote_count":"2","poster":"manishk39"},{"poster":"nqthien041292","comment_id":"1091888","upvote_count":"3","content":"Selected Answer: BE\nVote BE","timestamp":"1733759400.0"},{"comment_id":"1089956","poster":"xhilmi","upvote_count":"3","content":"Selected Answer: BE\nThe recommended approaches to reduce toil and minimize deployment time in Google Cloud Deploy are (options B and E).\n\n- Option B, dividing automation steps into smaller tasks, allows for better manageability and flexibility in the deployment process. This enables parallel execution of smaller tasks, speeding up the overall deployment.\n\n- Option E, automating promotion approvals, eliminates manual intervention and streamlines the progression from development to test environments, further reducing delays and potential errors associated with manual approval processes.\n\nBoth options contribute to a more efficient and automated deployment pipeline in Google Cloud Deploy.","timestamp":"1733547660.0"},{"comment_id":"1079179","upvote_count":"2","content":"Selected Answer: BE\nIt is BE","poster":"Andrei_Z","timestamp":"1732443840.0"},{"upvote_count":"4","timestamp":"1731694200.0","poster":"pharao89","comment_id":"1071759","content":"Selected Answer: AE\nimho:\n\nA. Create a trigger to notify the required team to complete the next step when manual intervention is required.\nWe want to reduce the time for end-to-end deployment. Notification of required manual intervention can reduce this time.\n\nB. Divide the automation steps into smaller tasks.\nThis doesn't reduce toil or time, but maybe I miss something here?\n\nC. Use a script to automate the creation of the deployment pipeline in Google Cloud Deploy.\nWe would rather use a webhook to create a deployment or pub/sub message. Doesn't sound like an answer to this question.\n\nD. Add more engineers to finish the manual steps.\nThis simply doesn't work here.\n\nE. Automate promotion approvals from the development environment to the test environment.\nThis reduces toil if covered by appropriate tests."},{"poster":"mshafa","upvote_count":"2","content":"Selected Answer: BE\nShould be BE\nhttps://sre.google/workbook/eliminating-toil/","comment_id":"1061799","timestamp":"1730672160.0"},{"timestamp":"1729940220.0","comment_id":"1054478","content":"Selected Answer: BE\nChose based on eliminating other options","poster":"Jason_Cloud_at","upvote_count":"3"}],"answer_images":[],"choices":{"D":"Add more engineers to finish the manual steps.","E":"Automate promotion approvals from the development environment to the test environment.","C":"Use a script to automate the creation of the deployment pipeline in Google Cloud Deploy.","B":"Divide the automation steps into smaller tasks.","A":"Create a trigger to notify the required team to complete the next step when manual intervention is required."},"topic":"1","question_images":[],"question_id":31,"answer":"BE","isMC":true,"question_text":"You are reviewing your deployment pipeline in Google Cloud Deploy. You must reduce toil in the pipeline, and you want to minimize the amount of time it takes to complete an end-to-end deployment. What should you do? (Choose two.)","timestamp":"2023-10-26 12:57:00","answer_ET":"BE"},{"id":"jFysW2DSIMQChW1Kfdgz","question_images":[],"unix_timestamp":1697955960,"discussion":[{"upvote_count":"3","poster":"xhilmi","timestamp":"1733548260.0","content":"Selected Answer: A\nThe recommended approach for optimizing CPU utilization based on historical system metrics in a global organization running a monolithic application on Compute Engine is (option A).\n\nUtilizing the Recommender API allows you to leverage Google Cloud's machine learning algorithms to analyze historical data and provide specific recommendations for resource optimization.\n\nThis method is proactive and can automatically suggest appropriate changes to improve efficiency, aligning with Google-recommended practices. By incorporating the insights provided by the Recommender API, you can make informed decisions to select the most suitable machine type for the application, ensuring optimal CPU utilization with minimal manual intervention.","comment_id":"1089958"},{"upvote_count":"2","content":"A is the answer.","poster":"mshafa","comment_id":"1061233","timestamp":"1730626440.0"},{"poster":"Jason_Cloud_at","comment_id":"1054481","timestamp":"1729940280.0","content":"Selected Answer: A\nIt should be A","upvote_count":"3"},{"comment_id":"1050258","upvote_count":"2","content":"Selected Answer: A\nAnswer should be A\nhttps://cloud.google.com/recommender/docs/overview","poster":"nhiguchi","timestamp":"1729578360.0"}],"answer_description":"","choices":{"A":"Use the Recommender API and apply the suggested recommendations.","D":"Review the Cloud Monitoring dashboard for the VM and choose the machine type with the lowest CPU utilization.","B":"Create an Agent Policy to automatically install Ops Agent in all VMs.","C":"Install the Ops Agent in a fleet of VMs by using the gcloud CLI."},"isMC":true,"answers_community":["A (100%)"],"answer":"A","url":"https://www.examtopics.com/discussions/google/view/124316-exam-professional-cloud-devops-engineer-topic-1-question-127/","question_text":"You work for a global organization and are running a monolithic application on Compute Engine. You need to select the machine type for the application to use that optimizes CPU utilization by using the fewest number of steps. You want to use historical system metrics to identify the machine type for the application to use. You want to follow Google-recommended practices. What should you do?","topic":"1","exam_id":6,"question_id":32,"answer_ET":"A","timestamp":"2023-10-22 08:26:00","answer_images":[]},{"id":"6g1NTK9YPW6idGdBdeNQ","question_id":33,"topic":"1","answer":"B","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/google/view/124699-exam-professional-cloud-devops-engineer-topic-1-question-128/","timestamp":"2023-10-27 09:19:00","answer_images":[],"question_text":"You deployed an application into a large Standard Google Kubernetes Engine (GKE) cluster. The application is stateless and multiple pods run at the same time. Your application receives inconsistent traffic. You need to ensure that the user experience remains consistent regardless of changes in traffic and that the resource usage of the cluster is optimized.\n\nWhat should you do?","choices":{"A":"Configure a cron job to scale the deployment on a schedule","B":"Configure a Horizontal Pod Autoscaler.","C":"Configure a Vertical Pod Autoscaler","D":"Configure cluster autoscaling on the node pool."},"exam_id":6,"unix_timestamp":1698391140,"isMC":true,"answer_description":"","question_images":[],"answer_ET":"B","discussion":[{"upvote_count":"6","comment_id":"1055180","poster":"Jason_Cloud_at","content":"Selected Answer: B\nInconsistent traffic .. HPA","timestamp":"1714202340.0"},{"timestamp":"1719563460.0","upvote_count":"1","comment_id":"1107671","content":"HPA will take care of the traffic flow, will scale the pods which will maintain consistent performance","poster":"kish18"},{"comment_id":"1089959","content":"Selected Answer: B\nThe recommended approach to ensure a consistent user experience and optimize resource usage for a stateless application with inconsistent traffic in a large Standard Google Kubernetes Engine (GKE) cluster is (option B)\n\nConfigure a Horizontal Pod Autoscaler (HPA). HPA automatically adjusts the number of replica pods based on observed CPU utilization or other custom metrics. In the context of varying traffic patterns, HPA dynamically scales the number of pods to meet demand, ensuring that there are enough instances to handle increased traffic and scaling down during periods of lower demand.\n\nThis helps maintain consistent performance while optimizing resource utilization in response to changing workloads.","poster":"xhilmi","upvote_count":"2","timestamp":"1717730220.0"},{"content":"B is the answer.","comment_id":"1061234","timestamp":"1714721760.0","poster":"mshafa","upvote_count":"2"}]},{"id":"BvkZpZs1cVg8vEGFPmgU","question_id":34,"topic":"1","answer":"D","answers_community":["D (86%)","14%"],"url":"https://www.examtopics.com/discussions/google/view/124662-exam-professional-cloud-devops-engineer-topic-1-question-129/","timestamp":"2023-10-26 13:09:00","choices":{"C":"Deploy the service in multiple regions and use an internal load balancer to route traffic.","B":"Use the n2-highcpu-96 machine type in the configuration of the managed instance group.","D":"Validate that the resource requirements are within the available project quota limits of each region.","A":"Monitor results of Cloud Trace to determine the optimal sizing."},"answer_images":[],"question_text":"You need to deploy a new service to production. The service needs to automatically scale using a managed instance group and should be deployed across multiple regions. The service needs a large number of resources for each instance and you need to plan for capacity. What should you do?","unix_timestamp":1698318540,"exam_id":6,"isMC":true,"answer_description":"","question_images":[],"answer_ET":"D","discussion":[{"timestamp":"1727302380.0","content":"Same Q as #37","comment_id":"1289179","upvote_count":"2","poster":"mouthwash"},{"timestamp":"1708003380.0","poster":"alpha_canary","comment_id":"1151023","upvote_count":"1","content":"Selected Answer: D\nD, then C"},{"content":"Selected Answer: D\nThe recommended approach for deploying a new service to production that requires automatic scaling across multiple regions with a managed instance group and has high resource requirements is (option D).\n\nValidating that the resource requirements are within the available project quota limits for each region is crucial to avoid issues during deployment. Each Google Cloud region has specific quota limits for various resources, such as CPU, memory, and instances.\n\nEnsuring that the planned capacity aligns with the allocated quotas prevents unexpected scaling limitations and helps in effective capacity planning for the service across multiple regions.\n\nThis approach ensures a smooth deployment and operation of the service without encountering resource constraints.","comment_id":"1089961","timestamp":"1701926520.0","upvote_count":"1","poster":"xhilmi"},{"timestamp":"1700572620.0","comment_id":"1076305","content":"Weird question, you need both C and D in order to have a proper solution...","poster":"Andrei_Z","upvote_count":"1"},{"comment_id":"1061236","timestamp":"1699004220.0","poster":"mshafa","upvote_count":"1","content":"D is the answer."},{"content":"Selected Answer: D\nQuestion #37","timestamp":"1698514260.0","upvote_count":"4","poster":"koo_kai","comment_id":"1056355"},{"upvote_count":"1","comments":[{"poster":"lelele2023","comment_id":"1061086","timestamp":"1698987540.0","content":"I don't agree with C, since it only mentions multi-region but doesn't do anything to cope with scalability. D although doesn't directly mention multi-region but it is the prereq to achieve large scale resource provisioning","upvote_count":"2"}],"poster":"Jason_Cloud_at","content":"Selected Answer: C\nValid answer","comment_id":"1054488","timestamp":"1698318540.0"}]},{"id":"WgIPmuUUQPYYe3uN5A0s","question_images":[],"answer_description":"","unix_timestamp":1622646360,"discussion":[{"comments":[{"poster":"AzureDP900","content":"Agreed","comment_id":"702660","upvote_count":"1","timestamp":"1666581540.0"}],"upvote_count":"25","poster":"francisco_guerra","comment_id":"386472","content":"A: Correct. The Horizontal Pod Autoscaler changes the shape of your Kubernetes workload by automatically increasing or decreasing the number of Pods in response to the workload's CPU or memory consumption\nB: Incorrect. It is not based on the CPU its based on the workload\nC: No, Hope is not an strategy\nD: No, have more resource than needed","timestamp":"1624210260.0"},{"timestamp":"1624915980.0","upvote_count":"25","comment_id":"393260","poster":"Charun","content":"answer A"},{"poster":"Kedar1234","timestamp":"1720848720.0","upvote_count":"1","content":"Selected Answer: B\nExamtopics suggest Ans B","comment_id":"1247123"},{"timestamp":"1701497340.0","upvote_count":"1","comment_id":"1085739","poster":"jomonkp","content":"option A"},{"poster":"Hiren_Meghnathi","comment_id":"1072197","timestamp":"1700115420.0","upvote_count":"1","content":"Selected Answer: A\nAnswer A"},{"content":"Selected Answer: A\ni think A","upvote_count":"2","timestamp":"1677883800.0","comment_id":"828456","poster":"umesh0u"},{"upvote_count":"2","content":"Selected Answer: A\nAnswer is A","poster":"JonathanSJ","comment_id":"772043","timestamp":"1673413800.0"},{"upvote_count":"1","poster":"akarayol","timestamp":"1672317240.0","content":"A and B confusing","comment_id":"760997"},{"timestamp":"1668090060.0","poster":"mohan999","content":"B is incorrect, because the cluster autoscaler doesn't work based on CPU/Memory usage on the node. The cluster will be scaled on the basis of resources requested by the workloads. So A is more relevant since HPA will automatically scales up/down based on the workload usage.","comment_id":"715291","upvote_count":"1"},{"poster":"GCP72","comment_id":"646690","timestamp":"1660471740.0","content":"Selected Answer: A\nThe correct answer is \"A\"","upvote_count":"1"},{"comment_id":"599118","upvote_count":"1","content":"Selected Answer: A\nSubmit the option provide in A","poster":"Ananda","timestamp":"1652110980.0"},{"content":"Selected Answer: A\nA is correct","poster":"gomezzang","timestamp":"1650514920.0","upvote_count":"1","comment_id":"589081"},{"poster":"skm4690","timestamp":"1649609700.0","upvote_count":"1","content":"A seems to be correct.","comment_id":"583822"},{"comment_id":"567757","poster":"Goatee_McGee","content":"Answer is A","timestamp":"1647274200.0","upvote_count":"1"},{"timestamp":"1645633440.0","content":"Selected Answer: A\nEven with autoscaling maximul limit effect scaling","upvote_count":"1","comment_id":"554644","poster":"asdqweasd"},{"comment_id":"495150","content":"C for me: 30% of total deployed CPU consumption mean 10% of CUP on each zone; 10% of increment month-over-month mean at the beginning of the second mont you will have 11% of CPU, at the tird 12,1% and so on; you can easly accomodate a fault of a zone; you don't have additional cost","poster":"burndayl","upvote_count":"2","comments":[{"content":"10% growth is only predicted value, but you should also be prepared for scenarios if the growth at real time is higher. In any case, using HPA and scaling based on it would be an optimal choice in my opinion.","timestamp":"1668090480.0","comment_id":"715295","upvote_count":"2","poster":"mohan999"}],"timestamp":"1638796860.0"},{"upvote_count":"1","timestamp":"1638706020.0","comment_id":"494306","content":"Selected Answer: A\nAns: A","poster":"alaahakim"},{"comment_id":"483748","poster":"Bala999","upvote_count":"1","timestamp":"1637540340.0","content":"Selected Answer: A\nCorrect answer A."},{"timestamp":"1636470000.0","upvote_count":"1","comment_id":"474869","poster":"Manh","content":"answer A"},{"comment_id":"380370","upvote_count":"3","comments":[{"timestamp":"1635337380.0","poster":"Trony","content":"Agreed: Cluster autoscaler will add additional nodes if some pods can't be scheduled, but you need something to add new pods when load increases, and that is HPA.","upvote_count":"1","comment_id":"468578"}],"timestamp":"1623492180.0","poster":"akg001","content":"The correct answer - A\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/horizontalpodautoscaler"},{"poster":"[Removed]","content":"I think A","upvote_count":"1","comment_id":"374003","timestamp":"1622770500.0"},{"poster":"devopsbatch","content":"B autoscaler will take care of user growth","timestamp":"1622646360.0","comment_id":"372815","comments":[{"comments":[{"poster":"rinkeshgala1","comment_id":"376425","comments":[{"content":"A is still the option, as you already enable Node Autoscaler in the question, but you need to verify the max node in the node pool based on your load, if not, if the load increase and you reach the max node in the node pool, it still has down time","timestamp":"1623112320.0","poster":"DucLee3110","upvote_count":"1","comment_id":"377119"}],"upvote_count":"3","timestamp":"1623030840.0","content":"what if there is a shortage of nodes then how cluster will auto scale. also, cluster auto scaler will take of under utilized nodes as well. so eventually you will save cost.\nso option B should be the choice right ?"}],"poster":"DucLee3110","content":"I think A, as it mentioned \"while avoiding unnecessary costs\", if you set cluster autoscaler but have max node, it can also impact user. A can verify what is max size based on your load.","timestamp":"1622785740.0","comment_id":"374106","upvote_count":"2"}],"upvote_count":"1"}],"url":"https://www.examtopics.com/discussions/google/view/54240-exam-professional-cloud-devops-engineer-topic-1-question-13/","choices":{"B":"Because you are deployed on GKE and are using a cluster autoscaler, your GKE cluster will scale automatically, regardless of growth rate.","A":"Verify the maximum node pool size, enable a horizontal pod autoscaler, and then perform a load test to verify your expected resource needs.","C":"Because you are at only 30% utilization, you have significant headroom and you won't need to add any additional capacity for this rate of growth.","D":"Proactively add 60% more node capacity to account for six months of 10% growth rate, and then perform a load test to make sure you have enough capacity."},"timestamp":"2021-06-02 17:06:00","topic":"1","exam_id":6,"answer":"A","answer_ET":"A","isMC":true,"answer_images":[],"question_text":"You are performing a semi-annual capacity planning exercise for your flagship service. You expect a service user growth rate of 10% month-over-month over the next six months. Your service is fully containerized and runs on Google Cloud Platform (GCP), using a Google Kubernetes Engine (GKE) Standard regional cluster on three zones with cluster autoscaler enabled. You currently consume about 30% of your total deployed CPU capacity, and you require resilience against the failure of a zone. You want to ensure that your users experience minimal negative impact as a result of this growth or as a result of zone failure, while avoiding unnecessary costs. How should you prepare to handle the predicted growth?","question_id":35,"answers_community":["A (92%)","8%"]}],"exam":{"isMCOnly":true,"lastUpdated":"11 Apr 2025","numberOfQuestions":196,"provider":"Google","name":"Professional Cloud DevOps Engineer","isImplemented":true,"id":6,"isBeta":false},"currentPage":7},"__N_SSP":true}