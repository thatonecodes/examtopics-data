{"pageProps":{"questions":[{"id":"ZPxEgbpSiOBMA5DwYvbc","question_text":"You have a storage bucket that contains two objects. Cloud CDN is enabled on the bucket, and both objects have been successfully cached. Now you want to make sure that one of the two objects will not be cached anymore, and will always be served to the internet directly from the origin.\nWhat should you do?","answer_description":"","choices":{"D":"Add a Cache-Control entry with value private to the metadata of the object you don't want to be cached anymore. Invalidate all the previously cached copies.","A":"Ensure that the object you don't want to be cached anymore is not shared publicly.","B":"Create a new storage bucket, and move the object you don't want to be checked anymore inside it. Then edit the bucket setting and enable the private attribute.","C":"Add an appropriate lifecycle rule on the storage bucket containing the two objects."},"exam_id":8,"topic":"1","discussion":[{"comment_id":"217321","content":"D is correct https://cloud.google.com/cdn/docs/caching","upvote_count":"16","poster":"spidrfong","timestamp":"1620735780.0"},{"comments":[{"upvote_count":"1","poster":"xhilmi","comment_id":"1103413","timestamp":"1719059040.0","content":"Option A (Ensure that the object you don't want to be cached anymore is not shared publicly) is not the best choice because CDN behavior is typically determined by Cache-Control headers rather than object permissions.\n\nOption B (Create a new storage bucket, move the object you don't want to be cached anymore inside it, and enable the private attribute) is not necessary and could be an unnecessary workaround. You can control caching behavior through Cache-Control headers without needing to create a new bucket.\n\nOption C (Add an appropriate lifecycle rule on the storage bucket containing the two objects) is not the most direct way to control caching behavior. Lifecycle rules are typically used for managing the lifecycle of objects (e.g., deleting old objects), not for controlling cache behavior."}],"upvote_count":"2","content":"Selected Answer: D\nChoose D.\n\nOption D is the correct choice because setting the Cache-Control header to \"private\" for the specific object will instruct the CDN to bypass caching for that object. Additionally, invalidating previously cached copies ensures that the new caching instructions take effect for existing cached content.","timestamp":"1719058980.0","poster":"xhilmi","comment_id":"1103412"},{"comments":[{"timestamp":"1696068120.0","comment_id":"855582","content":"Option A, \"Ensure that the object you don't want to be cached anymore is not shared publicly,\" is not the correct answer because public sharing is not related to caching. Public sharing only controls whether the object is accessible by users who have the link or if it's accessible to everyone on the internet.\nOption B, \"Create a new storage bucket, and move the object you don't want to be checked anymore inside it. Then edit the bucket setting and enable the private attribute,\" is not the correct answer because creating a new bucket would cause unnecessary complexity and may not be an ideal solution for a large number of objects or frequent changes to objects.\n\nOption C, \"Add an appropriate lifecycle rule on the storage bucket containing the two objects,\" is not the correct answer because lifecycle rules control the lifecycle of objects, such as deletion or archiving, but not caching.","upvote_count":"1","poster":"Komal697"}],"content":"Selected Answer: D\noption D, \"Add a Cache-Control entry with value private to the metadata of the object you don't want to be cached anymore. Invalidate all the previously cached copies,\" is the correct answer because it adds a header to the object's metadata that tells the CDN not to cache the object and to always fetch it from the origin server. Invalidating previously cached copies is also important to ensure that users are not served stale or outdated content.","comment_id":"855581","poster":"Komal697","timestamp":"1696068120.0","upvote_count":"3"},{"timestamp":"1694289960.0","upvote_count":"1","poster":"Ben756","comment_id":"834468","content":"Selected Answer: D\nthe best option for making sure that one of the two objects will not be cached anymore is D. Add a Cache-Control entry with value private to the metadata of the object you don’t want to be cached anymore. Invalidate all the previously cached copies."},{"content":"Selected Answer: D\nD if correct","upvote_count":"2","comment_id":"778149","timestamp":"1689528240.0","poster":"spoxman"},{"comment_id":"775545","content":"• D. Add a Cache-Control entry with value private to the metadata of the object you don't want to be cached anymore. Invalidate *** all the previously cached copies.","timestamp":"1689339360.0","poster":"pk349","upvote_count":"1"},{"comment_id":"729714","poster":"AzureDP900","upvote_count":"2","content":"D is right","timestamp":"1685309460.0"},{"upvote_count":"4","content":"Selected Answer: D\nAnswer is D, stated here \nhttps://cloud.google.com/cdn/docs/caching#preventing-caching","poster":"small1_small2","timestamp":"1677105180.0","comment_id":"650421"},{"timestamp":"1656932100.0","comment_id":"516621","content":"Answer is : D","poster":"kumarp6","upvote_count":"3"},{"timestamp":"1656931860.0","upvote_count":"1","poster":"kumarp6","content":"Answer is : D","comment_id":"516618"},{"upvote_count":"3","timestamp":"1632414720.0","comment_id":"318375","content":"D is correct","poster":"Vidyasagar"},{"comment_id":"242805","content":"Ans is D, Preventing caching Include a Cache-Control: private header in responses that should not be stored in Cloud CDN caches, or a Cache-Control: no-store header in responses that should not be stored in any cache, even a web browser's cache.","timestamp":"1623597840.0","upvote_count":"3","poster":"cesar7816"},{"comment_id":"223803","content":"Ans - D","poster":"[Removed]","upvote_count":"1","timestamp":"1621521060.0"},{"content":"Should be D","comment_id":"216800","poster":"lukedj87","upvote_count":"3","timestamp":"1620659760.0"}],"answers_community":["D (100%)"],"answer_ET":"D","unix_timestamp":1605028560,"url":"https://www.examtopics.com/discussions/google/view/36697-exam-professional-cloud-network-engineer-topic-1-question-51/","question_id":176,"answer_images":[],"isMC":true,"question_images":[],"timestamp":"2020-11-10 18:16:00","answer":"D"},{"id":"lys2Jy40XmG4kIYMwV4M","question_text":"Your company offers a popular gaming service. Your instances are deployed with private IP addresses, and external access is granted through a global load balancer. You have recently engaged a traffic-scrubbing service and want to restrict your origin to allow connections only from the traffic-scrubbing service.\nWhat should you do?","answer_description":"","choices":{"A":"Create a Cloud Armor Security Policy that blocks all traffic except for the traffic-scrubbing service.","D":"Create IPTables firewall rules that block all traffic except for the traffic-scrubbing service.","B":"Create a VPC Firewall rule that blocks all traffic except for the traffic-scrubbing service.","C":"Create a VPC Service Control Perimeter that blocks all traffic except for the traffic-scrubbing service."},"topic":"1","exam_id":8,"discussion":[{"poster":"Vidyasagar","comment_id":"318373","content":"A is correct","timestamp":"1632414660.0","upvote_count":"15"},{"poster":"cesar7816","timestamp":"1623597960.0","comment_id":"242808","upvote_count":"9","content":"Ans is A, Cloud Armor is used for LB, there is no way we can use FW rules at LB level"},{"comment_id":"1356676","timestamp":"1739583960.0","upvote_count":"1","content":"Selected Answer: A\nThe best option is A: Create a Cloud Armor Security Policy that blocks all traffic except for the traffic-scrubbing service.\n\nExplanation:\nCloud Armor is specifically designed to protect your Google Cloud resources, including those behind a load balancer, by filtering traffic based on IP, region, or other criteria. In this case, you can define a Cloud Armor security policy that allows traffic only from the traffic-scrubbing service and blocks everything else.","poster":"saraali"},{"comment_id":"1154833","timestamp":"1724162760.0","content":"Answer is B:\n\nCloud Armor is used for DDOS attacks and HTTPs requests, etc. VPC FW rules are more appropriate.","poster":"desertlotus1211","upvote_count":"1"},{"poster":"xhilmi","upvote_count":"2","comment_id":"1103416","content":"Selected Answer: A\nBy creating a Cloud Armor Security Policy, you can define rules that explicitly allow traffic only from the IP addresses associated with the traffic-scrubbing service. This way, you can effectively block all other traffic at the edge, preventing it from reaching your backend instances.\n\nIn summary, Option A leverages Cloud Armor's capabilities to enforce security policies at the edge, making it a suitable choice for restricting access to your gaming service's origin only to the traffic-scrubbing service while blocking all other traffic.","timestamp":"1719059340.0"},{"content":"Answer should be A.\nRefer to this link, https://cloud.google.com/armor/docs/integrating-cloud-armor#https-vpc-firewall-rules\n1, GCP Armor security policies act on the edge and block the unpermitted traffic from entering cloud;\n2, VPC firewall sits between external load balancer and provides further protection. Note from VPC firewall's point of view, the source ip ranges from LB are not the client's original ip ranges, they're external LB's ip ranges as external LBs are proxies.","timestamp":"1707533160.0","upvote_count":"2","comment_id":"977130","poster":"i_0_i"},{"upvote_count":"2","content":"Selected Answer: A\ncause this is fail fast so earlier block access","comment_id":"975524","timestamp":"1707397560.0","poster":"didek1986"},{"comment_id":"905662","timestamp":"1700822880.0","upvote_count":"1","content":"question says that it wants to restrict origin. So origin is external IP in this case. The external origin will hit load balancer . So security to be applied on load balancer with Armor. Hence answer should be A","poster":"Hetavi"},{"comment_id":"855585","content":"Selected Answer: B\nTo restrict your origin to allow connections only from the traffic-scrubbing service, you can create a VPC firewall rule that blocks all traffic except for the traffic-scrubbing service's IP range. This will prevent any external traffic from reaching your instances, except for the traffic coming from the traffic-scrubbing service.","poster":"Komal697","upvote_count":"1","timestamp":"1696068300.0","comments":[{"upvote_count":"1","comment_id":"855586","comments":[{"poster":"desertlotus1211","content":"There's no mention in the question about any limiting factors. What is Best Practice?","timestamp":"1700101200.0","upvote_count":"1","comment_id":"898785"}],"timestamp":"1696068300.0","poster":"Komal697","content":"Option A is also a valid solution, as you can create a Cloud Armor security policy that allows traffic only from the traffic-scrubbing service's IP range. However, Cloud Armor is an additional layer of protection that can be used to augment the firewall rules, but it may not be necessary to use it exclusively in this case.\nOption C is not suitable for this scenario, as VPC Service Controls are used to restrict access to Google APIs and services, not to limit incoming traffic to a specific IP range.\nOption D is also not suitable, as IPTables firewall rules are typically used in Linux-based systems, and GCP provides a more comprehensive and integrated firewall service through VPC firewall rules."}]},{"poster":"subhala","comments":[{"timestamp":"1707404820.0","upvote_count":"1","poster":"gcpengineer","content":"global LB is external","comment_id":"975703"}],"timestamp":"1693935780.0","content":"If traffic scrubbing svc is internal, B is the right answer. If it is external and LB is HTTP, then A, that is Cloud Armor is right answer..","upvote_count":"2","comment_id":"830258"},{"comment_id":"790054","poster":"Melampos","content":"Selected Answer: C\nRestrict resource access to allowed IP addresses, identities, and trusted client deviceshttps://cloud.google.com/vpc-service-controls","upvote_count":"1","timestamp":"1690491600.0"},{"poster":"AzureDP900","upvote_count":"1","timestamp":"1685214900.0","comment_id":"728604","content":"A. Create a Cloud Armor Security Policy that blocks all traffic except for the traffic-scrubbing service."},{"upvote_count":"2","content":"Selected Answer: A\nA is correct, Cloud Armor whitelisting ensure only certain IP address can access the LB. deny all connection by default","poster":"small1_small2","comment_id":"650423","timestamp":"1677105360.0"},{"poster":"vladani","content":"why not A? Can someone elaborate?","timestamp":"1658727240.0","comments":[{"poster":"clooudy","content":"answer is A","upvote_count":"1","timestamp":"1659388500.0","comment_id":"538250"}],"upvote_count":"1","comment_id":"531943"},{"timestamp":"1656932160.0","comment_id":"516622","upvote_count":"2","poster":"kumarp6","content":"Answer is : A"},{"upvote_count":"1","timestamp":"1656457140.0","poster":"desertlotus1211","comment_id":"511680","content":"If it's a gaming application - more than likely they're using a HTTPS LB"},{"content":"Really bad formed question, really ambiguous\nIs the traffic-scrubbing an external service, or one inside of your VPC?\nIs the global LB a HTTP LB or TCP/SSL on L4?\nAs already pointed out by others, Cloud Armor only works togherther with global HTTP LB.","comment_id":"446404","comments":[{"content":"https://cloud.google.com/armor/docs/security-policy-overview\n\nGoogle Cloud Armor security policies are available only for backend services behind an external HTTP(S) load balancer, TCP proxy load balancer, or an SSL proxy load balancer. The load balancer can be in Premium Tier or Standard Tier.","timestamp":"1668426240.0","poster":"Taliesyn","upvote_count":"1","comment_id":"601511"}],"poster":"PeppaPig","upvote_count":"1","timestamp":"1647507000.0"},{"upvote_count":"1","comment_id":"400680","poster":"densnoigaskogen","timestamp":"1641552180.0","content":"I would go with B.\nCloud Armor can only be applied when using external HTTP(S) LB, not other global LBs. Additionally, Cloud Armor is placed between outside and your LB, which is inside GCP network, but outside your private VPC perimeter. \nThe question says, it wants to restrict access to the origin, so, VPC Firewall rules are more applicable."},{"upvote_count":"4","poster":"Hybrid_Cloud_boy","content":"Reading this leads me to believe A\n\nThe below links outlines NAT behavior of GCP global load balancer. Since this is a full proxy, the source IP of the scrubbing source would be translated to GFE IP, so allowing the scrubbing source via FW rule would not work.\n\nSo, by elimination this tells me that cloudarmor is the answer! So A\n\nhttps://cloud.google.com/load-balancing/docs/https","timestamp":"1623001800.0","comment_id":"236764"},{"timestamp":"1621521300.0","upvote_count":"1","content":"Ans - A","comment_id":"223806","poster":"[Removed]"},{"timestamp":"1620659940.0","upvote_count":"3","comment_id":"216801","content":"I would go with A.\nBeing able to use cloud armor really depends if the global LB is an HTTP LB (otherwise, cloud armor can't be used...)","poster":"lukedj87"}],"answers_community":["A (78%)","11%","11%"],"answer_ET":"A","unix_timestamp":1605028740,"url":"https://www.examtopics.com/discussions/google/view/36698-exam-professional-cloud-network-engineer-topic-1-question-52/","answer_images":[],"question_id":177,"isMC":true,"question_images":[],"answer":"A","timestamp":"2020-11-10 18:19:00"},{"id":"ApIkeV8SXcKV8niuvje8","unix_timestamp":1605232440,"exam_id":8,"answer_images":[],"question_id":178,"discussion":[{"comments":[{"timestamp":"1669583820.0","poster":"AzureDP900","content":"A is right","comment_id":"728605","upvote_count":"2"}],"timestamp":"1610901600.0","upvote_count":"26","poster":"garbad","comment_id":"269644","content":"Answer is A, \n\ncost and complexity of multiple tunnel vpn is very high, also , dedicated interconnect is not required as required max speed is 1.5gbps\nAlso , direct connectivity is bogus verb, all the solution provide direct connectivity to your vpc instance , once connected through router"},{"timestamp":"1627115520.0","comment_id":"413053","upvote_count":"14","content":"Everybody that says C please do not take this exam and never be consulted for network related question ...","poster":"JohnnyBG","comments":[{"comment_id":"976089","timestamp":"1691537520.0","upvote_count":"1","poster":"desertlotus1211","content":"what makes you think PI is not complex? Relying on the partner to do their job is challenging. BTW - do you know the cost of PI vs VPN? do the math first","comments":[{"comment_id":"976921","upvote_count":"1","content":"vpn operation of having multiple tunnel at max 3-4 tunnels...rather hav a partner connect. if cost is factor, its better to stay in on prem","timestamp":"1691604060.0","poster":"gcpengineer"}]}]},{"comment_id":"1356677","poster":"saraali","upvote_count":"1","content":"Selected Answer: A\nThe best solution for your scenario is A. Provision a Partner Interconnect through your ISP.\n\nExplanation:\nPartner Interconnect is a connectivity solution provided by Google Cloud that allows you to establish a dedicated connection from your on-premises network to Google Cloud via a Google Partner Interconnect provider. This solution is well-suited to scenarios where you want a reliable, high-speed connection but don’t need the full capacity of a Dedicated Interconnect.","timestamp":"1739584080.0"},{"comment_id":"1242260","upvote_count":"2","poster":"nkastanas","timestamp":"1720122120.0","content":"Selected Answer: A\nDedicated Interconnect is for organizations that need high bandwidth, low latency, and have the capability to manage a direct physical connection in a colocation facility.\nPartner Interconnect is for organizations that prefer a simpler, more flexible setup and do not have the infrastructure to support a Dedicated Interconnect."},{"poster":"desertlotus1211","upvote_count":"1","timestamp":"1708456980.0","comment_id":"1154950","content":"Do the math people: https://cloud.google.com/network-connectivity/pricing#partner-pricing\n\nA 2 tunnel VPN is $297.80 per month.... A PI is $2.36 per hour per VLAN attachment (@10Gigs) plus data transfer.... ARE YOU SURE IT'S CHEAPER THAN VPN PER MONTH?"},{"comment_id":"1103427","upvote_count":"2","poster":"xhilmi","content":"Selected Answer: A\nPartner Interconnect (Option A): This solution involves using your ISP as a Google Partner Interconnect provider. It establishes a connection between your on-premises network and Google's network through the service provider. Partner Interconnect can offer a dedicated and reliable connection with specified bandwidth.\n\nGiven the requirement for direct connectivity, the fact that your ISP is a Google Partner Interconnect provider, and considering factors like minimal cost and complexity, this could indeed be a suitable choice.","timestamp":"1703255700.0"},{"comments":[{"upvote_count":"1","timestamp":"1680170940.0","comment_id":"855590","comments":[{"upvote_count":"1","content":"Partner Interconnect provided up to 10GB pipes... DI requires you to be in an area where DI are available. You already have your partner provider... no need to search and go through DI requirements. Minimal cost and complexity","poster":"desertlotus1211","comment_id":"898788","timestamp":"1684196760.0"}],"poster":"Komal697","content":"Option A, provisioning a Partner Interconnect, could be a valid solution but may not provide the same guaranteed bandwidth as a Dedicated Interconnect, and may be subject to the same packet loss issues as a VPN.\nOption C, creating multiple VPN tunnels and using ECMP, could improve reliability and increase bandwidth, but may not provide the necessary speeds and guaranteed bandwidth for the application requirements.\nOption D, using network compression, could increase the amount of data transferred over the VPN, but would not address the issue of packet losses and may not provide the necessary speeds and reliability for the application requirements."}],"poster":"Komal697","content":"Selected Answer: B\nOption B, provisioning a Dedicated Interconnect, is the most appropriate solution because it can provide a dedicated, private, high-speed connection between the on-premises environment and GCP. Dedicated Interconnects offer a guaranteed bandwidth of up to 10 Gbps, and can be upgraded for burstable traffic as needed. Additionally, they offer SLAs for reliability and support.","upvote_count":"2","timestamp":"1680170940.0","comment_id":"855589"},{"upvote_count":"1","content":"Selected Answer: A\nIt is A, partner interconnect. It supports RFC 1918 as well as required max speed. https://cloud.google.com/hybrid-connectivity/","comment_id":"822118","timestamp":"1677394680.0","poster":"Popa"},{"comment_id":"775547","poster":"pk349","timestamp":"1673708280.0","content":"• C. Create multiple VPN ***** tunnels to account for the packet losses, and increase bandwidth using ECMP.\nIt’s very common to use parallel links to increase bandwidth. This mechanism is often called equal-cost multipath (ECMP). ECMP often works well, but there are a few caveats. Before we get to the issue of running BGP over parallel links, it’s important to look at how traffic is split over multiple parallel links.\nDedicated Interconnect provides a direct physical connection between your on-premises network and Google's network. Partner Interconnect provides connectivity between your on-premises and VPC networks through a supported service provider.","upvote_count":"1"},{"poster":"Moran12","content":"Selected Answer: A\nPartner would be cost effective as egress traffic would be lower than vpn","timestamp":"1665591780.0","upvote_count":"2","comment_id":"693250"},{"comment_id":"686002","upvote_count":"3","content":"Selected Answer: A\nAAAAAAAAAA","timestamp":"1664869740.0","poster":"Mr_MIXER007"},{"poster":"vladani","upvote_count":"2","content":"Selected Answer: A\nAns - A","timestamp":"1643096280.0","comment_id":"531947"},{"comment_id":"516624","poster":"kumarp6","content":"Answer is : A","upvote_count":"2","timestamp":"1641301260.0"},{"content":"https://cloud.google.com/blog/products/networking/google-cloud-network-connectivity-options-explained\n\nAnswer A is better...","comment_id":"512516","timestamp":"1640800140.0","poster":"desertlotus1211","comments":[{"content":"Thank you for sharing the link, I agree with A.","timestamp":"1669678560.0","poster":"AzureDP900","upvote_count":"2","comment_id":"729715"}],"upvote_count":"3"},{"comments":[{"comment_id":"512283","timestamp":"1640789460.0","upvote_count":"1","poster":"MrPajonko","content":"Sorry guys for misleading - Pricate Intercconect ofcourse use private IP addressing."},{"timestamp":"1640800200.0","content":"You need to revisit how Partner and Dedicated Interconnect works...Public IPs are only needed for BGP peering","poster":"desertlotus1211","comment_id":"512517","upvote_count":"2"}],"comment_id":"509056","timestamp":"1640429520.0","content":"Selected Answer: C\nIt states that private RFC 1918 ip addressing is required. Partner Interconnect doesn't use private IP addressing, public only. Correct answer is C.","upvote_count":"2","poster":"MrPajonko"},{"poster":"ThisisJohn","upvote_count":"4","content":"I would vote for A because of this statement \" Most of the data transfer will be from GCP to the on-premises environment.\".\n\nAccording to the documentation, carrier peering \"Has reduced internet egress rates to your on-premises network \" while Cloud VPN \"Has standard egress rates for traffic sent through an Interconnect connection;\" https://cloud.google.com/network-connectivity/docs/how-to/choose-product#cp-compare","comment_id":"472955","timestamp":"1636100160.0"},{"comment_id":"397012","timestamp":"1625240580.0","poster":"jeeet_","upvote_count":"2","content":"C,\nQuestion is challenging. \n--> application can burst upto 1.5Gbps, \n--> Cloud VPN- can burst upto 3Gbps, and with double VPN we can minimize packet loss and bandwidth upto 6Gbps,\n-> Interconnect initial setup is complex, you need to email to google, then talk to your vendor (which is google itself) and common peer zone. It's time consuming. \n\nSince they already have a single tunnel VPN, setting up another won't take much of time."},{"poster":"seddy","comment_id":"360300","upvote_count":"1","content":"C for sure!\nKey elements: 1) Direct Connectivity (cannot be partner inter)\n 2) Cannot be Dedicated bc we want low cost\n 3) Multiple VPN tunnels with ECMP will help us deal with packet losses\n\nPeace :)","timestamp":"1621328400.0","comments":[{"content":"Partner interconnect IS a direct connectivity ..","timestamp":"1626162180.0","comment_id":"405244","poster":"JohnnyBG","upvote_count":"4"},{"poster":"clooudy","content":"partner interconnect is a direct connectivity","comment_id":"475812","timestamp":"1636579620.0","upvote_count":"2"}]},{"content":"Unless we know how much data will be transferred, we really can not give an answer.\nBecause at some point (about 45-50TB) Interconnect will get cheaper then VPN.\n\nBut knowing that this app can get a burs 1,5 Gbps, and we sure can think that his state stays longer than 30 minutes. The answer I would give is A.","comment_id":"337976","upvote_count":"2","poster":"buldas","timestamp":"1618725060.0"},{"poster":"CloudTrip","upvote_count":"1","content":"I think Answer will be A as Direct Interconnect will be too expensive and also an overkill for this requirement. Managing multiple tunnels that too with packet loss consideration is complex also. Whereas partner interconnect fits the bill with providing required bandwidth but not super expensive also once setup not too complex too manage.","timestamp":"1618634340.0","comment_id":"337353"},{"content":"I'll go A, \nC is too painful to find tune routing. In addition, as a network engineer, I don't wanna get trouble replying on a internet link with packets loss.","upvote_count":"2","comment_id":"319693","timestamp":"1616636760.0","poster":"pentium2000"},{"poster":"chetz12","comment_id":"282964","content":"A strong proponent of C \nhttps://www.noction.com/blog/equal-cost-multipath-ecmp","timestamp":"1612384740.0","upvote_count":"1"},{"content":"The question says direct connectivity to instances on GCP. Therefore, C in the best answer. The VPN will connect directly to the GCP instances\nA - partner is not direct connectivity from on-prem to GCP instances \nB - The is costly and the question says solution has to be cost effective.","upvote_count":"2","comment_id":"251437","timestamp":"1608783900.0","poster":"DrAnney"},{"poster":"Gharet","upvote_count":"1","content":"Shouldn't it be A? I would think the complexity of multiple tunnels and ECMP (not sure that matter's in VPN) be complex? Plus maybe all the egress charges over the internet, i think i would go with A here.","timestamp":"1608230520.0","comment_id":"246755"},{"upvote_count":"6","timestamp":"1605891300.0","poster":"[Removed]","comment_id":"223820","content":"Ans - C"},{"poster":"majun","timestamp":"1605232440.0","upvote_count":"1","content":"Cost and the complexity of the solution should be minimal , It should be C","comment_id":"218219"}],"answer_ET":"A","answers_community":["A (76%)","12%","12%"],"question_text":"Your software team is developing an on-premises web application that requires direct connectivity to Compute Engine Instances in GCP using the RFC 1918 address space. You want to choose a connectivity solution from your on-premises environment to GCP, given these specifications:\n✑ Your ISP is a Google Partner Interconnect provider.\n✑ Your on-premises VPN device's internet uplink and downlink speeds are 10 Gbps.\n✑ A test VPN connection between your on-premises gateway and GCP is performing at a maximum speed of 500 Mbps due to packet losses.\n✑ Most of the data transfer will be from GCP to the on-premises environment.\n✑ The application can burst up to 1.5 Gbps during peak transfers over the Interconnect.\n✑ Cost and the complexity of the solution should be minimal.\nHow should you provision the connectivity solution?","question_images":[],"timestamp":"2020-11-13 02:54:00","answer_description":"","answer":"A","choices":{"B":"Provision a Dedicated Interconnect instead of a VPN.","C":"Create multiple VPN tunnels to account for the packet losses, and increase bandwidth using ECMP.","A":"Provision a Partner Interconnect through your ISP.","D":"Use network compression over your VPN to increase the amount of data you can send over your VPN."},"topic":"1","isMC":true,"url":"https://www.examtopics.com/discussions/google/view/36893-exam-professional-cloud-network-engineer-topic-1-question-53/"},{"id":"iROxepHfAS0ZOvHhVctF","discussion":[{"comment_id":"430555","comments":[{"content":"This would be a long term solution if DDOS is confirmed. The quickest solution is to recover the service, which is BE.","upvote_count":"2","poster":"walkwolf3","timestamp":"1639765680.0","comment_id":"503855"},{"poster":"Windy_Welly88","timestamp":"1638249840.0","comment_id":"490437","upvote_count":"2","comments":[{"comment_id":"729717","poster":"AzureDP900","upvote_count":"2","timestamp":"1669678920.0","content":"A, C make sense"}],"content":"I'd go A & C. These days you can get Cloud Armor for trial, and this product will mitigate current AND sustained DDOS attacks. Would you REALLY autoscale for a massive DDOS attack, do you think Google will let you do this for free? You wont need to spend time looking at logs and traffic as it will tell you straight away who the actors are.. And finally, since this is a critical revenue-earning application any downtime would be a significant cost. Only way to ensure uptime would be to use Cloud Armor."}],"poster":"Alex_74","content":"A & C\n\nCloud Armor is the solution to prevent and mitigate attack (DDOS SQL injection and so on), it's a revenue generating so have to be alive and protected.\n\nNo Cloud Armor is not a firewall. Using the CA language you have tons of prebuild rules to evaluate and block the malicious traffic in automatic way. You can put the rule blocking a specific traffic but it's not there the value (you have the firewall for that).\nThan you need C cause Cloud Armor require an HTTP(s) load balancer (that can be used cause it's a web application)","timestamp":"1629790260.0","upvote_count":"27"},{"timestamp":"1607284680.0","comment_id":"236768","content":"I think B,E are actually correct.\n\nA and C would increase cost to global LB, change app architecture, and could potential block legitimate traffic since you “think” it is a DDoS, but do i not know. I do not think google would recommend blocking traffic unless you KNOW.\n\nSo a temp increase in auto scale, with further investigation is the best course of action. It may lead to some short-term cost increase, but ultimately less cost increase than moving to global LB premium tier with cloudarmor.","upvote_count":"14","poster":"Hybrid_Cloud_boy","comments":[{"poster":"GeorgS","timestamp":"1680250860.0","upvote_count":"3","comment_id":"856780","content":"But E just says log in with SSH and look, to get get a better view. So with B and E you won't block anything, you will just increase your serverpool"}]},{"upvote_count":"1","timestamp":"1743577560.0","poster":"mohitms1996","comment_id":"1421305","content":"Selected Answer: AC\nWhy Not the Other Options?\n\n❌ B. Increase the maximum autoscaling backend\n\n Scaling up indefinitely does not stop the attack, and it increases costs dramatically.\n\n Without blocking the malicious traffic, your instances will continue getting overwhelmed.\n\n❌ D. Shut down the entire application\n\n This is not a viable solution—taking down your application means legitimate users also lose access.\n\n The attacker could simply restart the attack when you go back online.\n\n❌ E. SSH into backend instances to analyze logs\n\n Too slow for immediate mitigation.\n\n While log analysis is useful after the attack, it doesn’t help quickly restore service for real users."},{"comment_id":"1401419","timestamp":"1742523360.0","content":"Selected Answer: AC\nA and C are correct","upvote_count":"1","poster":"RKS_2021"},{"timestamp":"1739617440.0","poster":"saraali","content":"Selected Answer: AC\nBest Choice:\nA & C is the better option to quickly restore user access and allow successful transactions while minimizing cost. Cloud Armor filters malicious traffic right away, while the Global HTTP(S) Load Balancer provides a more robust and scalable solution for long-term protection and handling of legitimate traffic.","comment_id":"1356822","upvote_count":"1"},{"content":"Selected Answer: AC\nA&C Unlike the Network Load Balancer, an HTTP(S) Load Balancer integrates with Cloud Armor and provides additional protection mechanisms such as rate limiting and advanced filtering.","timestamp":"1738056660.0","poster":"Aenarion","upvote_count":"1","comment_id":"1347813"},{"poster":"12gears","comment_id":"1343258","timestamp":"1737331320.0","content":"Selected Answer: BE\nNetwork load balancer does not support Cloud Armor","upvote_count":"1"},{"upvote_count":"1","timestamp":"1735277520.0","comment_id":"1332245","poster":"ppandher","comments":[{"comment_id":"1335183","poster":"ian_gcpca","timestamp":"1735733040.0","content":"To use Cloud Armor with your Network Load Balancer, you need to activate \"advanced network DDoS protection\" for the region where your load balancer resides. This provides always-on attack detection and mitigation. \n\nstill for a DDoS attack, the best practice is to use CA, creating global lb would change the architecture and may take some time before being setup while there's an on-going attack.","upvote_count":"1"}],"content":"Selected Answer: BC\nCloud Armor cannot be used with Network Load balancer, it operates at layer 7.I go with B and C and it require to restore Not to remediate."},{"upvote_count":"3","content":"Selected Answer: AC\ncant be B, you have to minimize the cost","comment_id":"1250630","timestamp":"1721329140.0","poster":"nkastanas"},{"timestamp":"1720122660.0","poster":"nkastanas","upvote_count":"2","content":"Selected Answer: AC\nB. Increase the maximum autoscaling backend to accommodate the severe bursty traffic: This approach might provide temporary relief but does not address the root cause (the DDoS attack). It could also significantly increase costs without solving the underlying issue.","comment_id":"1242263"},{"content":"A and C are the correct two steps we should take. These steps complete the purpose. The question is not asking for two separate approaches.","upvote_count":"1","poster":"hamish88","timestamp":"1714811280.0","comment_id":"1206392"},{"timestamp":"1708233900.0","upvote_count":"1","content":"There is some amount of Cloud Armor integration supported with Network Passthrough Load Balancers: There is some amount of integration supported for Cloud Armor with Network Load Balancers: https://cloud.google.com/armor/docs/advanced-network-ddos","poster":"Adjqwert","comment_id":"1153051"},{"upvote_count":"2","content":"Selected Answer: AB\nThe objective is to quickly restore user access. So A & B.\nLater you can move to an HTTP LB which makes sense also.","timestamp":"1707415980.0","comment_id":"1144794","poster":"gonlafer"},{"timestamp":"1704721980.0","upvote_count":"2","poster":"PhuocT","comment_id":"1116652","content":"Selected Answer: AC\nAC is the best answer. you can only use Cloud Armor with HTTP LB, not network LB."},{"comment_id":"1111509","content":"Selected Answer: AC\nAC is the correct","poster":"Chavoz","timestamp":"1704153540.0","upvote_count":"3"},{"upvote_count":"2","comment_id":"1106942","timestamp":"1703690400.0","content":"Selected Answer: AC\nThis is the textbook scenario for Cloud Armor + GCLB, so given that this is a Google exam, it seems pretty obvious to select AC.\n\nIt's actually really simple to switch the BE from one LB to another and would not add huge cost.","poster":"BenMS"},{"comment_id":"1103432","timestamp":"1703256360.0","upvote_count":"1","poster":"xhilmi","content":"Selected Answer: AB\nA. Use Cloud Armor to blacklist the attacker's IP addresses.\n\nCloud Armor is a security service on Google Cloud that allows you to defend your applications and services from Distributed Denial of Service (DDoS) attacks. By configuring blacklisting rules in Cloud Armor, you can block traffic from specific IP addresses or ranges associated with the attack, helping to mitigate the impact on your application.\n\nB. Increase the maximum autoscaling backend to accommodate the severe bursty traffic.\n\nBy increasing the maximum number of instances in your autoscaling backend, you allow your infrastructure to dynamically scale up to handle the increased traffic during the DDoS attack. This helps ensure that your application can continue to serve legitimate user requests even under heavy load."},{"timestamp":"1696079700.0","comment_id":"1021507","content":"Cloud Armor can only be integrated with HTTP(S) load balancer, it's not supported with NLB. Hence, A is not correct. I'd go with option B & E.","poster":"CloudSISG2023","upvote_count":"3"},{"comment_id":"1013568","upvote_count":"1","poster":"sidharthwader","timestamp":"1695355560.0","content":"B is not a good solution if you increase the scaling it will just keep increasing during a DDOS attacker will you more of your resources and you will pay higher price for malicious attack","comments":[{"timestamp":"1701112620.0","poster":"DelonBH","comment_id":"1081896","upvote_count":"1","content":"DDOS Attack is not confirmed.. \"you think\"."}]},{"poster":"didek1986","timestamp":"1691603760.0","content":"Selected Answer: AB\nC is wrony cause changes architecture","upvote_count":"2","comment_id":"976918"},{"comment_id":"965421","timestamp":"1690534080.0","poster":"study_aws1","upvote_count":"3","content":"A & B - Option C) of HTTPS Load balancer is not a mandatory requirement.\n\nGoogle Cloud Armor also provides advanced network DDoS protection for external passthrough Network Load Balancers, protocol forwarding, and VMs with public IP addresses.\n\nhttps://cloud.google.com/armor/docs/security-policy-overview\n\nStandard network DDoS protection: basic always-on protection for network load balancers, protocol forwarding, or VMs with public IP addresses. This is covered under Google Cloud Armor Standard and does not require any additional subscriptions.\nAdvanced network DDoS protection: additional protections for Managed Protection Plus subscribers who use network load balancers, protocol forwarding, or VMs with public IP addresses. \n\nhttps://cloud.google.com/armor/docs/advanced-network-ddos"},{"content":"auto scaling is already taken care as mentioned in question. So correct answer is to use Armor and https global load balancer.","poster":"Hetavi","comment_id":"905671","timestamp":"1684918620.0","upvote_count":"1"},{"content":"Selected Answer: BE\nBE Only","comment_id":"891669","upvote_count":"2","poster":"somnathmaddi","timestamp":"1683490860.0"},{"timestamp":"1680171060.0","upvote_count":"2","content":"Selected Answer: AB\nBlacklisting the attacker's IP addresses with Cloud Armor will help to prevent further traffic from the same source, reducing the impact of the attack. Increasing the maximum autoscaling backend will ensure that the application can handle the severe bursty traffic and continue to serve legitimate requests, reducing the impact on users.","comments":[{"comment_id":"898789","poster":"desertlotus1211","timestamp":"1684196940.0","upvote_count":"1","content":"Is the question implying the IP is known? It said think it's DDOS attack, which means they're not sure..."},{"timestamp":"1680171060.0","upvote_count":"2","comment_id":"855594","content":"C. Creating a global HTTP(s) load balancer and moving the application backend to this load balancer may help to distribute traffic across multiple regions and increase application availability, but it may not directly address the DDOS attack.\n\nD. Shutting down the entire application in GCP for a few hours is not a recommended approach as it will result in significant downtime and loss of revenue.\n\nE. SSHing into backend compute engine instances and viewing logs may provide insights into the attack but is unlikely to immediately restore access to the application.","poster":"Komal697"}],"poster":"Komal697","comment_id":"855593"},{"comment_id":"834473","upvote_count":"4","poster":"Ben756","content":"Selected Answer: AB\nA. Use Cloud Armor to blacklist the attacker’s IP addresses. This way, you can block malicious traffic from reaching your application and reduce the load on your backend instances.\nC. Create a global HTTP(s) load balancer and move your application backend to this load balancer. This way, you can leverage Cloud Armor’s integration with HTTP(s) load balancers and benefit from its advanced DDoS defense features.","timestamp":"1678400040.0"},{"poster":"refaelbc316","upvote_count":"2","comment_id":"788690","content":"Selected Answer: AB\nwhere dose the system have the answers from, i am not sure what rely correct","timestamp":"1674735180.0"},{"upvote_count":"1","poster":"gagan5","comment_id":"776383","content":"Selected Answer: AC\nI will go with A & C","timestamp":"1673776320.0"},{"upvote_count":"2","comment_id":"765530","poster":"gdtoro","content":"Selected Answer: BC\nMove from Network LB to HTTPS LB as it has DDOS defence build in.","timestamp":"1672830600.0"},{"content":"You all are wrong!!! First correct option is C. (HTTPS LB has L3/L4 DDOS defence build in, no need for Cloud Armor becouse they said about cost)\nSecond option I am not shure, but I'll go with B.","timestamp":"1672830480.0","poster":"gdtoro","upvote_count":"3","comment_id":"765526"},{"comment_id":"758954","timestamp":"1672168680.0","poster":"theereechee","upvote_count":"1","content":"Selected Answer: AC\nA & C.\nThe question says you already know it is a DDOS attack. You need cloud armor for that, but cloud armor requires http(s) loadbalancer. The question already says web application, so this setup should work fine."},{"poster":"TD24","comments":[{"timestamp":"1671177540.0","upvote_count":"3","content":"Cloud Armor does not work with Network LB and we never know whether app will work with http(s) LB so in view of that changing my ans to B & E if they need quick resolution","comment_id":"746937","comments":[{"content":"It does now","comment_id":"976927","timestamp":"1691604360.0","poster":"gcpengineer","upvote_count":"1"},{"content":"E will never help","comment_id":"976928","upvote_count":"1","poster":"gcpengineer","timestamp":"1691604420.0"}],"poster":"TD24"}],"timestamp":"1671038100.0","upvote_count":"2","content":"i go for A & C","comment_id":"745317"},{"poster":"csrazdan","timestamp":"1668140640.0","comment_id":"715763","upvote_count":"3","content":"Selected Answer: AB\nA. Cloud Armor uses machine learning algorithms that can analyze network patterns and detect anomalies which can be blocked to deal with DDoS attack. \nB. Increase the maximum autoscaling backend to accommodate the severe bursty traffic - This is a valid strategy for dealing with DDoS attack. Google will refund any cost inured during a DDoS attach caused by autoscalling of backend for enterprise customers."},{"comments":[],"poster":"jeeet_","comment_id":"702396","upvote_count":"3","timestamp":"1666550280.0","content":"Lets Eliminate: Need quick solution without downtime, \n\na. Cloud Armor -- No - Network LB doesn't work with Cloud Armor. \nc. Global HTTPs LB --> No--> you don't know what application is running and will it support https or not! Basically R&D work. \n\nd. shutdown entire application --> No Never nops\n\nCorrect answer -- \n\nb. compensate with autoscaling -- makes huge sense.\ne. ssh into one machine and check for syslogs/logs --> yes as a security guy it's your top most priority to find the attack origin, once found you can apply it on Firewall rules with necessary tags. \nsince application is live, you keep checking for logs and keep adding attacker IP's to your Firewall rules. ( Fastest resolution )"},{"comment_id":"681299","upvote_count":"1","poster":"desertlotus1211","timestamp":"1664320920.0","content":"Answer is A&E: https://cloud.google.com/service-infrastructure/docs/service-networking/getting-started"},{"content":"https://cloud.google.com/armor/docs/security-policy-overview\nCloud Armour is compatible with global external HTTP(S) load balancer, global external HTTP(S) load balancer (classic), external TCP proxy load balancer, or external SSL proxy load balancer.","comment_id":"667879","poster":"AMohanty","timestamp":"1663065420.0","upvote_count":"1"},{"content":"Answer should be C & E\nNetwork Load Balancer doesn't support Cloud Armor https://cloud.google.com/armor/docs/best-practices\nso application need to move under HTTP(s) Load Balancer. However, HTTP(s) Load Balancers are deployed at Google Front End (GFE) and they have by default DDoS protection capacity because GFE can absorb these load.","timestamp":"1660380240.0","upvote_count":"1","comment_id":"646232","poster":"mostafa_bepari"},{"upvote_count":"1","comments":[{"timestamp":"1646559000.0","comment_id":"561901","comments":[{"content":"Sorry, compared with C and E , choose E.\nC is more cost involved and not easy to perform in a short time.","comment_id":"565089","poster":"[Removed]","timestamp":"1646955600.0","upvote_count":"1"}],"poster":"[Removed]","upvote_count":"1","content":"For B & C:\nThese 2 points was metioned in link below as best practice for DDOS protection.\n\nhttps://cloud.google.com/apigee/docs/api-platform/system-administration/preventing-dos\nhttps://cloud.google.com/files/GCPDDoSprotection-04122016.pdf"}],"timestamp":"1646558880.0","comment_id":"561899","content":"For A:\n since the attack sources are distributed amongst botnets or other groups of malicious clients ranging in size from thousands to millions, it becomes increasingly difficult to mitigate an ongoing attack by systematically identifying and blocking bad clients based on IP alone\nhttps://cloud.google.com/armor/docs/adaptive-protection-use-cases\n\nFor D:\nShut down the Web service to prevent DDOS is not good choice, and may be attacked again when restart.\n\nFor E:\n\"view the auth logs and syslogs to further understand the nature of the attack\" is necessary for prevent the same attack in future, but is not a quick solution.","poster":"[Removed]"},{"upvote_count":"1","comment_id":"529964","content":"Multiple ways of looking at this problem and solution. In short term, we can use B&E to remediate the problem and for long term, a better approach to prevent this from happening would be via A&C. Since the question also specifies 'quickly restore' and 'minimize cost', in that context B&E would work. Thoughts?","timestamp":"1642867560.0","poster":"yas_cloud","comments":[{"upvote_count":"2","timestamp":"1649724240.0","poster":"yas_cloud","content":"One more point I can think of. The setup currently uses network load balancer which the cloud armor is not compatible with. Hence we need to first move the instances behind a HTTP(S) LB and then apply cloud armor.","comment_id":"584460"}]},{"content":"Answer is : B and E","poster":"kumarp6","comment_id":"516652","timestamp":"1641303540.0","upvote_count":"1"},{"poster":"desertlotus1211","timestamp":"1640741400.0","upvote_count":"2","content":"What about A&B? Since an investigations is done to reveal 'maybe' a DDoS attack - you may now the IP Source... We don't know the metrics that is used for autoscaling... is it CPU or some other metric? We can go back to the autoscaling policy and increase the max number of instances... This is quick and dirty until we know for sure on what is causing the autoscaling max limit to be reached...\n\nThoughts?","comment_id":"511691"},{"poster":"lollo883","timestamp":"1633936200.0","content":"I think B,C are correct:\n\nCloud armor is not supported in network LB so A cant be possible. Morover, D cant be because of the downtime of the service. E is just useless in this scenario.\nWith B we rely on the DDOS mitigation system of GCP infrastracture (From the documentation we have \"Even without a Google Cloud Armor configuration, Google infrastructure and GFEs provide defense-in-depth for DDoS attacks and SYN floods.\"). C is the only way to restore the service immediatly.","comment_id":"460422","upvote_count":"4"},{"poster":"PeppaPig","content":"Answer is B, C. Keep in mind that DDoS protection is auto-on for HTTP Load Balancer.\nB is obvious, because scaling out can quickly mitigate the issue. \nFor C, DDoS protection is provided by default if you use HTTP, TCP and SSL LB even without Cloud Armor configuration\n\"All projects that include HTTP(S) Load Balancing, TCP Proxy Load Balancing, or SSL Proxy Load Balancing are automatically enrolled in Google Cloud Armor Standard\"\nhttps://cloud.google.com/armor/docs/managed-protection-overview#standard_versus_plus\n\n\"Even without a Google Cloud Armor configuration, Google infrastructure and GFEs provide defense-in-depth for DDoS attacks and SYN floods.\"\nhttps://cloud.google.com/load-balancing/docs/https#open_ports","comment_id":"441468","timestamp":"1631107260.0","upvote_count":"4"},{"comment_id":"438106","upvote_count":"3","poster":"ExamTopicsFan","timestamp":"1630610160.0","content":"Assume for a second that it was a real DoDOD attack .Only option A can prevent it from happening again or stop it if it in progress . None of the other options can do it. So Option A is a must."},{"timestamp":"1630148940.0","content":"the key is quick and minimizing cost here, i think the ans is BE","poster":"Zuy01","comment_id":"433790","upvote_count":"2"},{"upvote_count":"2","timestamp":"1625246580.0","comment_id":"397075","content":"Quickly restore user access--\n\nB and E makes sense, \n\n1. with just B, you'll be able to help users to access your application. (as they are already using Network LB- that has highest bandwidth available -> meaning low congestion)\nE. Since now you let your application work again, Now quickly getting the nature of DDOS attack can help mitigate the issue further, Like knowing those IP's you can block them using Firewalls etc.","poster":"jeeet_"},{"upvote_count":"3","comments":[{"timestamp":"1621328640.0","content":"Also, not in the answers but, since this is a NW LB, which is a pass through, we could actually create firewall rules to prevent the traffic from the source if we knew the source IP. Using firewall rules to prevent traffic is not possible for proxy based LB'ers but it's possible for NW LB as it is a pass through! This is the least costly option. But we do need to know the IP address of the traffic!","poster":"seddy","comment_id":"360307","upvote_count":"1"}],"content":"A and C where you first use preview-mode in Cloud Armor to make sure!","comment_id":"360302","poster":"seddy","timestamp":"1621328520.0"},{"poster":"CloudTrip","timestamp":"1619294580.0","upvote_count":"1","comment_id":"342207","content":"No changing the LB doesn't take as much as time than analysing issues through a Putty (SSH) login and going through tons from logs. This is from practical experience and still going with B,C as the most practical response in situations like this which also goes inline with the question statement."},{"poster":"WakandaF","timestamp":"1619037060.0","upvote_count":"2","content":"B & E? are correct?","comment_id":"340619"},{"content":"The key requirement is here \"quickly restore user access to your application and allow successful transactions while minimizing cost\" which makes B,C as the right choice. E is going to be time consuming and A needs you to setup Cloud Armor which also has high price tag based on your usage. Operationally think in day to day scenario, it's B, C what you can do immediately restore access and without spending much.","poster":"CloudTrip","comments":[{"timestamp":"1618807920.0","comment_id":"338612","upvote_count":"2","poster":"buldas","content":"Changing the load balancer will take time too."}],"timestamp":"1618634880.0","upvote_count":"1","comment_id":"337356"},{"poster":"Vidyasagar","timestamp":"1616519940.0","upvote_count":"3","content":"A and C","comment_id":"318282"},{"timestamp":"1615690860.0","upvote_count":"2","poster":"ArizonaClassics","comment_id":"310197","content":"Ans= B&E (provides you quick and temporal fix and no additional costs)"},{"comment_id":"297352","content":"I think B&E is correct. It says \"You want to quickly restore user access to your application and allow successful transactions while minimizing cost.\" if you want to quickly restore access you need temp increase in auto scale while your figuring out the cause of the sudden burst of traffic.","upvote_count":"3","timestamp":"1614080400.0","poster":"LaXuS"},{"timestamp":"1612231380.0","content":"AC as B&D can't be a cost-effective solution as well as it doesn't help with identifying the origin of the attack. E can't be viable as you have to think of what's next.","upvote_count":"1","poster":"chetz12","comment_id":"281548"},{"comment_id":"269648","timestamp":"1610901900.0","content":"It's web application , so its natural to move to http load balancer, so c is correct, once you move to http load balancer, cloud armor policy can block ddos attack, and no it does not block legitimate traffic","upvote_count":"2","poster":"garbad"},{"comment_id":"223822","poster":"[Removed]","content":"Ans - AC","upvote_count":"1","timestamp":"1605891420.0"},{"poster":"majun","content":"agree AC","timestamp":"1605232500.0","upvote_count":"1","comment_id":"218220"},{"comment_id":"217142","upvote_count":"5","comments":[{"comment_id":"218411","timestamp":"1605265620.0","upvote_count":"2","poster":"marekmatula2020","content":"A is incorrect because it is network load balancer so you can't use Armor","comments":[{"content":"That's the reason you have to switch to HTTPS that's option C is for. I think AC would make a good combo","comment_id":"281546","upvote_count":"2","poster":"chetz12","timestamp":"1612231140.0"}]},{"upvote_count":"2","poster":"Hybrid_Cloud_boy","comment_id":"241797","content":"I believe this is incorrect. This could increase cost significantly, and block legitimate traffic. Correct answer is B/E. See my logic below.","timestamp":"1607794320.0"}],"content":"I think it's AC","poster":"lukedj87","timestamp":"1605082320.0"}],"answer":"AC","isMC":true,"answer_images":[],"timestamp":"2020-11-11 09:12:00","question_text":"Your company has just launched a new critical revenue-generating web application. You deployed the application for scalability using managed instance groups, autoscaling, and a network load balancer as frontend. One day, you notice severe bursty traffic that the caused autoscaling to reach the maximum number of instances, and users of your application cannot complete transactions. After an investigation, you think it as a DDOS attack. You want to quickly restore user access to your application and allow successful transactions while minimizing cost.\nWhich two steps should you take? (Choose two.)","answer_description":"","answer_ET":"AC","question_id":179,"question_images":[],"choices":{"A":"Use Cloud Armor to blacklist the attacker's IP addresses.","E":"SSH into the backend compute engine instances, and view the auth logs and syslogs to further understand the nature of the attack.","D":"Shut down the entire application in GCP for a few hours. The attack will stop when the application is offline.","B":"Increase the maximum autoscaling backend to accommodate the severe bursty traffic.","C":"Create a global HTTP(s) load balancer and move your application backend to this load balancer."},"answers_community":["AC (45%)","AB (40%)","Other"],"topic":"1","exam_id":8,"url":"https://www.examtopics.com/discussions/google/view/36743-exam-professional-cloud-network-engineer-topic-1-question-54/","unix_timestamp":1605082320},{"id":"bCgQ04ZfddiDUa81eEm3","discussion":[{"content":"Answer are A & C\nC is definitely correct. private services access require private connection\nIn below links stated Service Networking API is required\nhttps://cloud.google.com/service-infrastructure/docs/enabling-private-services-access","comment_id":"213304","comments":[{"upvote_count":"7","content":"A & C\nhttps://cloud.google.com/sql/docs/mysql/private-ip\nThis page provides information about using private IP with Cloud SQL. For step-by-step instructions for configuring a Cloud SQL instance to use private IP, see Configuring private IP.","comment_id":"430569","timestamp":"1629791220.0","poster":"Alex_74"}],"upvote_count":"28","timestamp":"1604567100.0","poster":"mlyu"},{"timestamp":"1604385000.0","poster":"ESP_SAP","upvote_count":"18","content":"Correct Answer are (C) & (E):\n\nC: If you are using private IP for any of your Cloud SQL instances, you only need to configure private services access one time for every Google Cloud project that has or needs to connect to a Cloud SQL instance.\n\nIf your Google Cloud project has a Cloud SQL instance, you can either configure it yourself or let Cloud SQL do it for you to use private IP.\n\nCloud SQL configures private services access for you when all the conditions below are true:\nhttps://cloud.google.com/sql/docs/postgres/configure-private-services-access#before_you_begin\n\nE:\nYou can enable Private Google access on a subnet level and any VMs on that subnet can access Google APIs by using their internal IP address.\nhttps://cloud.google.com/vpc/docs/configure-private-google-access","comments":[{"poster":"VivekMishraV","comment_id":"351809","timestamp":"1620378840.0","upvote_count":"6","content":"For Accessing K8S and Cloud SQL it is Google Private Service Access"}],"comment_id":"211732"},{"content":"Selected Answer: AC\nA and C are the right options\nA: Activating the Service Networking API is essential for setting up private services like Cloud SQL within your VPC. This API will allow the creation of a private IP address for Cloud SQL, ensuring that your VPC instances can communicate with Cloud SQL privately.\n\nC: Creating a private connection to a service producer (Cloud SQL in this case) ensures that you establish a direct, private network connection to Cloud SQL. This connection allows VPC instances to interact with Cloud SQL without using public IPs.","timestamp":"1739584860.0","upvote_count":"1","poster":"saraali","comment_id":"1356682"},{"poster":"nkastanas","content":"Selected Answer: AC\nIt difficult to understand why. in my opinion should be OLNY E or A and C both.\nEnabling Private Google Access allows VM instances without public IPs to access Google APIs and services. While useful, it's not strictly necessary for Cloud SQL private connectivity if you already have the Service Networking API and private connection configured. However, enabling this can provide additional benefits for accessing other Google services.","comment_id":"1246233","timestamp":"1720717440.0","upvote_count":"1"},{"content":"Answers are A&E:","upvote_count":"1","poster":"desertlotus1211","comment_id":"1154956","timestamp":"1708457760.0"},{"timestamp":"1707406920.0","poster":"gonlafer","content":"Selected Answer: CE\nC&E\nPrivate google access is a valid option for connecting from GCEs with no public ip","comment_id":"1144648","upvote_count":"1"},{"poster":"bus_karan19","content":"Selected Answer: AC\nA & C. E is not a correct option because PGA is required only if you want to connect to Google API's (restricted or private).","comment_id":"1042314","upvote_count":"1","timestamp":"1697174220.0"},{"poster":"i_0_i","timestamp":"1691635680.0","content":"Answer should be A&C.\n\nThere are different ways to consume and provide APIs and services in GCP:\nhttps://cloud.google.com/vpc/docs/private-access-options#connect-google-apis\n--- Private service connect\n--- Private Google access\n--- Private services access\n\nAmong all the given options, only A/C(Private services access) and E(Private Google access) are reasonable. As the answers have to be two, so they can only be A and C. Also, Private Google access is enabled on subnet level, not on VPC level.\n\n*For Private services access, its deployment involves the allocation of a specific internal CIDR in the local VPC and creation of a private connection between local VPC and service provider's VPC. This private connection is created using Service Networking API.\nhttps://cloud.google.com/vpc/docs/private-services-access\n\n*For Private Google access, it applies for accessing the external ip of Google APIs and services from instances with only internal ip addresses\nhttps://cloud.google.com/vpc/docs/private-google-access","upvote_count":"3","comment_id":"977190"},{"content":"Selected Answer: AC\nAC is ans","upvote_count":"1","comment_id":"976996","timestamp":"1691611560.0","poster":"gcpengineer"},{"timestamp":"1691493300.0","upvote_count":"1","content":"Selected Answer: AC\nshould be A,C","poster":"didek1986","comment_id":"975548"},{"timestamp":"1690608240.0","content":"Selected Answer: AC\nI think the answer is A and C \nTo use private service access, enabling Service Networking API is required on the project as per https://cloud.google.com/service-infrastructure/docs/enabling-private-services-access\n\nand it's required to create a private connection after enabling above API. \nhttps://cloud.google.com/sql/docs/mysql/private-ip#application_environment_requirements","upvote_count":"2","poster":"hyosung","comment_id":"966116"},{"content":"Please refer https://cloud.google.com/sql/docs/mysql/private-ip#requirements_for_private_ip\nIt clearly says creating Configuring a Cloud SQL instance and acces is privately we need private services access and Service Networking API must be enabled hence A and C is correct\n\na service","upvote_count":"2","poster":"PranavP96","comment_id":"885009","timestamp":"1682843340.0"},{"comment_id":"855595","comments":[{"timestamp":"1680171300.0","comment_id":"855597","content":"Option B is incorrect because Cloud Datastore is a NoSQL document database that is not related to Cloud SQL.\n\nOption C is incorrect because creating a private connection to a service producer is not necessary to access Cloud SQL from VPC instances without public IP addresses.\n\nOption D is also incorrect because creating a custom static route is not necessary to access Cloud SQL from VPC instances without public IP addresses.","comments":[{"poster":"desertlotus1211","upvote_count":"1","timestamp":"1684197240.0","content":"You need to read about service producer network with private access.\nhttps://cloud.google.com/vpc/docs/private-services-access#:~:text=Service%20producer%20network,-On%20the%20service&text=The%20service%20producer's%20network%20is,resources%20in%20your%20VPC%20network.","comment_id":"898791","comments":[{"comment_id":"976931","content":"its meant to custom services not google provided services","poster":"gcpengineer","upvote_count":"2","timestamp":"1691604600.0"}]}],"poster":"Komal697","upvote_count":"1"}],"poster":"Komal697","timestamp":"1680171180.0","upvote_count":"2","content":"Selected Answer: AE\nTo access Cloud SQL from VPC instances without public IP addresses, you need to enable Private Google Access on the subnet where the instances are located. Private Google Access allows VMs without public IP addresses to reach Google APIs and services such as Cloud SQL using internal IP addresses.\nIn addition, you need to activate the Service Networking API in your project. This enables you to create a private connection to Cloud SQL using VPC Service Controls. With VPC Service Controls, you can create a private connection between your VPC network and Cloud SQL without requiring an external IP address."},{"timestamp":"1678710360.0","poster":"fad3r","content":"It's A&C here is the link that shows that:\nhttps://cloud.google.com/sql/docs/mysql/configure-private-ip\n\nYou must enable the Service Networking API for your project.\nPrivate services access\nWhen you create a new VPC network in your project, you need to configure private services access to allocate an IP address range and create a private service connection. This allows resources in the VPC network to connect to Cloud SQL instances.","upvote_count":"2","comment_id":"837913"},{"comment_id":"775550","timestamp":"1673708400.0","content":"C is definitely correct. private services access require private connection In below links stated Service Networking API is required \nService Networking enables you to offer your managed services on internal IP addresses to service consumers. Service consumers use private services access to privately connect to your service.","poster":"pk349","upvote_count":"1"},{"poster":"orwell","comments":[{"content":"BUT private service access appears to be the recommended practice, leaving it to A&C","timestamp":"1664976660.0","upvote_count":"1","poster":"orwell","comment_id":"686928"}],"content":"The question is not mentioning the need of connecting to CloudSQL by its private ip, enabling Network Services API is mandatory for enabling Private Google Access, A&E are the ones.","upvote_count":"2","comment_id":"686665","timestamp":"1664952960.0"},{"comment_id":"681301","content":"Answer is A&E: https://cloud.google.com/service-infrastructure/docs/service-networking/getting-started","comments":[{"timestamp":"1691537640.0","upvote_count":"1","comment_id":"976091","poster":"desertlotus1211","content":"Sorry it's A&C"}],"timestamp":"1664320920.0","upvote_count":"1","poster":"desertlotus1211"},{"comments":[{"upvote_count":"3","timestamp":"1646973780.0","poster":"[Removed]","content":"Sorry for my mistake, Change my answer to A & C.\nBecause:\nPrivate Google Access enabled allows VM instances which only have internal IP addresses (no external IP addresses) to reach the external IP addresses of Google APIs and services.\nAND\nhttps://cloud.google.com/sql/docs/mysql/private-ip","comment_id":"565227","comments":[{"comments":[{"timestamp":"1663068420.0","poster":"AMohanty","content":"Option C is valid for Service Producers. Questions doesn't say about external Service Producers so we assume its by Google. We don't need to create a private connection for connecting to Google SQL.\nSo I will go with A and E.","comment_id":"667937","upvote_count":"2"}],"poster":"kapara","comment_id":"615723","timestamp":"1655112960.0","upvote_count":"1","content":"C&E are the correct answers A has nothing to do with this.\nNetwork Service API -\"Provides automatic management of network configurations necessary for certain services.\"\n\nC - https://cloud.google.com/vpc/docs/private-services-access#service_producer_network\n\nE - Configuring a Cloud SQL instance to use private IP requires private services access. Private services access lets you create private connections between your VPC network and the underlying Google service producer's VPC network - https://cloud.google.com/sql/docs/mysql/private-ip#allocated_ip_address_ranges\n\nAnd regarding the Cloud SQL your understanding is wrong, nothing is specified for the Cloud SQL the only thing that is mentioned in the question is that the VM's has no public IP address as infrared from the question: \"VPC instances without public IP addresses\""}]}],"timestamp":"1646480340.0","content":"Between A&C and C&E is confused.\n\nBased on the quesiton said ,\" access to Cloud SQL from VPC with no public IP\", \nit should be means: VM which only with internal IP need access to Cloud SQL\n\nBased on the PGA overview, example and its supported services, E is a suitable option at least.\nhttps://cloud.google.com/vpc/docs/private-google-access\nhttps://cloud.google.com/vpc/docs/private-google-access#example\nhttps://cloud.google.com/vpc/docs/private-services-access#private-services-supported-services\n\nAnd about option A, I only found following description:\n\"Service Networking enables you to offer your managed services on internal IP addresses to service consumers\"\n\nBase on my understanding, it seems to describe the part of services (Cloud SQL) has an internal IP. It was different with this question mentioned.\n\nI think C & E is better.","poster":"[Removed]","comment_id":"561401","upvote_count":"1"},{"upvote_count":"2","comment_id":"516656","poster":"kumarp6","content":"Answer is : A and C","timestamp":"1641303660.0"},{"poster":"kumarp6","content":"A & C\nhttps://cloud.google.com/sql/docs/mysql/private-ip#network_issues","upvote_count":"2","comment_id":"515854","timestamp":"1641222000.0"},{"content":"A & E are correct.","comments":[{"comment_id":"482012","poster":"Arad","timestamp":"1637347920.0","upvote_count":"1","content":"Correction: A & C."}],"upvote_count":"1","comment_id":"482006","timestamp":"1637347620.0","poster":"Arad"},{"timestamp":"1636543440.0","upvote_count":"2","content":"D & E\n\nE because \"You can allow these VMs to connect to the set of external IP addresses used by Google APIs and services by enabling Private Google Access on the subnet used by the VM's network interface.\" https://cloud.google.com/vpc/docs/configure-private-google-access\nD because \"Your network must have appropriate routes for the destination IP ranges used by Google APIs and services. These routes must use the default internet gateway next hop\" https://cloud.google.com/vpc/docs/configure-private-google-access#requirements","comment_id":"475358","poster":"ThisisJohn"},{"upvote_count":"2","timestamp":"1630692360.0","content":"A&C are correct.\nPrivate Google Access is for connecting to the standard Google public APIs. Cloud SQL is NOT a pubic API","poster":"PeppaPig","comment_id":"438650","comments":[{"upvote_count":"1","poster":"PeppaPig","timestamp":"1630692480.0","comment_id":"438651","content":"Cloud SQL under the hood is just a VM instance managed by Google that runs in a Google managed VPC"}]},{"content":"A,C,E all works. but, for E, it use VM's internal IP to connect to Cloud SQL's external IP. My English is not good. If 'without public IP' means for the VM instances. then A/C/E works. if 'without public IP' means for Cloud SQL, then only A/C works.","timestamp":"1624273500.0","poster":"cyma","upvote_count":"1","comment_id":"387013"},{"comment_id":"337359","upvote_count":"1","timestamp":"1618635300.0","poster":"CloudTrip","content":"Answer will be B, E as you need Private Google Access for API scenarios like this. https://cloud.google.com/vpc/docs/configure-private-google-access and also you need to enable the API services https://cloud.google.com/vpc/docs/access-apis-external-ip#requirements"},{"comment_id":"318345","timestamp":"1616522760.0","content":"C and E","poster":"Vidyasagar","upvote_count":"1"},{"comments":[{"upvote_count":"3","poster":"chetz12","content":"Not exactly.... A & C makes more sense now","comment_id":"281552","timestamp":"1612231860.0"}],"content":"C & E \nhttps://cloud.google.com/sql/docs/mysql/configure-private-ip","comment_id":"281551","poster":"chetz12","upvote_count":"2","timestamp":"1612231560.0"},{"poster":"cesar7816","upvote_count":"3","timestamp":"1607881920.0","content":"Agree A and C\n\nService Networking enables you to offer your managed services on internal IP addresses to service consumers. Service consumers use private services access to privately connect to your service","comment_id":"242841"},{"comment_id":"223832","timestamp":"1605892500.0","poster":"[Removed]","upvote_count":"5","content":"Ans - AC"},{"content":"it shout be C&E","poster":"majun","upvote_count":"1","timestamp":"1605233940.0","comment_id":"218231"},{"upvote_count":"5","poster":"lukedj87","content":"Agree with A and C.\n\nE is completely unrelated. Private Google Access is only for services not backed up by some GCE instances","comment_id":"217146","timestamp":"1605082680.0"}],"unix_timestamp":1604385000,"answer":"AC","topic":"1","url":"https://www.examtopics.com/discussions/google/view/35872-exam-professional-cloud-network-engineer-topic-1-question-55/","question_id":180,"answers_community":["AC (70%)","AE (20%)","10%"],"timestamp":"2020-11-03 07:30:00","answer_images":[],"answer_ET":"AC","question_images":[],"isMC":true,"answer_description":"","exam_id":8,"choices":{"D":"Create a custom static route to allow the traffic to reach the Cloud SQL API.","A":"Activate the Service Networking API in your project.","B":"Activate the Cloud Datastore API in your project.","E":"Enable Private Google Access.","C":"Create a private connection to a service producer."},"question_text":"You are creating a new application and require access to Cloud SQL from VPC instances without public IP addresses.\nWhich two actions should you take? (Choose two.)"}],"exam":{"numberOfQuestions":228,"id":8,"provider":"Google","lastUpdated":"11 Apr 2025","isMCOnly":true,"isImplemented":true,"isBeta":false,"name":"Professional Cloud Network Engineer"},"currentPage":36},"__N_SSP":true}