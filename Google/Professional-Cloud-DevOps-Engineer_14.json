{"pageProps":{"questions":[{"id":"70UIiZQ08keJPgzU7T8C","question_id":66,"answer_ET":"D","question_images":[],"discussion":[{"upvote_count":"1","content":"Selected Answer: D\nhttps://cloud.google.com/architecture/application-deployment-and-testing-strategies#shadow_test_pattern\nWith shadow testing, you deploy and run a new version alongside the current version, but in such a way that the new version is hidden from the users, as the following diagram shows.\nAn incoming request is mirrored and replayed in a test environment. This process can happen either in real time or asynchronously after a copy of the previously captured production traffic is replayed against the newly deployed service.","comment_id":"1152366","poster":"alpha_canary","timestamp":"1723863060.0"},{"poster":"xhilmi","upvote_count":"2","content":"Selected Answer: D\nChoose option D.\n\nShadow testing allows the deployment and execution of a new version alongside the current one, but in a manner that is hidden from users. This approach ensures zero production impact, as the incoming requests are mirrored and replayed in a test environment. By duplicating traffic, it enables comprehensive testing of new features and improvements against the full production load without affecting end-users.\n\nAdditionally, the continuous deployment aspect ensures that the deployment process remains ongoing, allowing for iterative testing and refinement based on real-world performance metrics and user interactions before a full rollout occurs.","comment_id":"1090894","timestamp":"1717827480.0"},{"upvote_count":"2","poster":"nqthien041292","content":"Selected Answer: D\nVote D","timestamp":"1717317540.0","comment_id":"1086066"},{"comment_id":"1062425","upvote_count":"3","content":"Selected Answer: D\nShadow testing is a technique where you deploy a new version of your application alongside the existing production version, but you don't route live traffic to it. Instead, you route a copy of the live traffic to the new version (the \"shadow\" version) while the production version continues to serve real user traffic. This allows you to gather performance metrics and test the new version under real-world conditions without affecting the end users' experience.","timestamp":"1714854180.0","poster":"mshafa"},{"content":"Selected Answer: D\nhttps://cloud.google.com/architecture/application-deployment-and-testing-strategies#shadow_test_pattern","poster":"lelele2023","upvote_count":"2","timestamp":"1714621440.0","comment_id":"1060288"},{"comment_id":"1054788","timestamp":"1714151580.0","upvote_count":"2","content":"Selected Answer: D\nOption A is literally for spilting traffic between versions , Canary is gradually allowing traffic to production, D is right answer","poster":"Jason_Cloud_at"}],"unix_timestamp":1698340380,"timestamp":"2023-10-26 19:13:00","exam_id":6,"choices":{"C":"Use canary testing with rolling updates deployment.","B":"Use canary testing with continuous deployment.","A":"Use A/B testing with blue/green deployment.","D":"Use shadow testing with continuous deployment."},"isMC":true,"topic":"1","answer":"D","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/124678-exam-professional-cloud-devops-engineer-topic-1-question-158/","question_text":"You are designing a deployment technique for your applications on Google Cloud. As part of your deployment planning, you want to use live traffic to gather performance metrics for new versions of your applications. You need to test against the full production load before your applications are launched. What should you do?","answers_community":["D (100%)"],"answer_images":[]},{"id":"SIiZfArhyNKdkUVY2ItO","question_images":[],"question_id":67,"question_text":"Your Cloud Run application writes unstructured logs as text strings to Cloud Logging. You want to convert the unstructured logs to JSON-based structured logs. What should you do?","choices":{"A":"Modify the application to use Cloud Logging software development kit (SDK), and send log entries with a jsonPayload field.","C":"Install the log agent in the Cloud Run container image, and use the log agent to forward logs to Cloud Logging.","D":"Configure the log agent to convert log text payload to JSON payload.","B":"Install a Fluent Bit sidecar container, and use a JSON parser."},"answer":"D","answer_ET":"D","answers_community":["D (60%)","A (40%)"],"discussion":[{"poster":"cachopo","content":"Selected Answer: A\n- Cloud Logging supports structured logging by using the jsonPayload field, which allows you to log data in JSON format.\n- Modifying the application to log in a structured JSON format ensures that the logs are parsed correctly by Cloud Logging without additional processing.\n\nWhy not D?\nConfiguring a log agent to convert logs from text to JSON adds unnecessary overhead. If you control the application, it's better to directly emit logs in structured JSON format using the SDK.","upvote_count":"2","timestamp":"1736869800.0","comment_id":"1340415","comments":[{"content":"Why not B?\nUsing a Fluent Bit sidecar container can parse logs, but it introduces complexity. Fluent Bit is better suited for parsing logs in environments where you cannot control the log output of the application (e.g., legacy systems).\n\nWhy not C?\nInstalling a log agent (such as Fluentd) within the Cloud Run container is not recommended. Cloud Run is designed to be stateless, and using log agents within the container image increases management overhead and resource consumption.","timestamp":"1736869860.0","poster":"cachopo","upvote_count":"1","comment_id":"1340416"}]},{"upvote_count":"1","content":"Cloud run doesnt use log agent, it has to be A or B","comments":[{"upvote_count":"1","comment_id":"1309305","poster":"mohan999","content":"If we are considering built in agent, then D might be valid option. But it is not clear from the question","timestamp":"1731212640.0"}],"comment_id":"1309304","timestamp":"1731212460.0","poster":"mohan999"},{"comment_id":"1265188","timestamp":"1723556760.0","poster":"6a8c7ad","content":"Selected Answer: A\nNot an instance","upvote_count":"2"},{"poster":"Rosek93","timestamp":"1716271260.0","upvote_count":"2","content":"Selected Answer: A\nThis is Cloud Run not VM -> A","comment_id":"1214742"},{"upvote_count":"1","timestamp":"1708145880.0","poster":"alpha_canary","comment_id":"1152368","content":"Selected Answer: D\nhttps://cloud.google.com/logging/docs/agent/logging/configuration#process-payload\nhttps://cloud.google.com/logging/docs/agent/logging/configuration#structured-records"},{"poster":"xhilmi","timestamp":"1702023840.0","comment_id":"1090897","content":"Selected Answer: D\nVote option D. \n\nIn this context, if you have unstructured logs written as text strings and want to convert them to JSON-based structured logs, you would typically use a log agent or parser to transform the log entries. The log agent is configured to recognize the structure of the logs and convert the text payload into a JSON payload.\n\nThe log agent would be responsible for parsing the unstructured logs and converting them into a structured format. This process involves specifying how to extract relevant information from the text payload and organize it into a JSON structure. It's important to note that this approach assumes you have a log agent or parser that supports the transformation of unstructured logs to structured logs.","upvote_count":"1"},{"comment_id":"1086302","upvote_count":"1","content":"Selected Answer: D\nVote D","poster":"nqthien041292","timestamp":"1701534060.0"},{"comment_id":"1062424","content":"Selected Answer: D\nThe Cloud Logging agent can be configured to convert log text payload to JSON payload by setting the process.payload parameter to json. This will cause the agent to parse the log text and convert it to a JSON object before forwarding it to Cloud Logging.","upvote_count":"2","poster":"mshafa","timestamp":"1699136400.0"},{"content":"Selected Answer: D\nhttps://cloud.google.com/logging/docs/agent/logging/configuration#process-payload","timestamp":"1698253320.0","poster":"Mar_Mar","comment_id":"1053897","upvote_count":"4"}],"exam_id":6,"answer_images":[],"unix_timestamp":1698253320,"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/124631-exam-professional-cloud-devops-engineer-topic-1-question-159/","timestamp":"2023-10-25 19:02:00","answer_description":"","topic":"1"},{"id":"0Er861t1C4DhaXj9ovjx","isMC":true,"unix_timestamp":1622647800,"timestamp":"2021-06-02 17:30:00","answer_ET":"D","topic":"1","answer":"D","answer_images":[],"question_text":"You are managing the production deployment to a set of Google Kubernetes Engine (GKE) clusters. You want to make sure only images which are successfully built by your trusted CI/CD pipeline are deployed to production. What should you do?","choices":{"B":"Enable Vulnerability Analysis on the Container Registry.","D":"Set up the Kubernetes Engine clusters with Binary Authorization.","A":"Enable Cloud Security Scanner on the clusters.","C":"Set up the Kubernetes Engine clusters as private clusters."},"question_images":[],"answers_community":["D (95%)","5%"],"url":"https://www.examtopics.com/discussions/google/view/54244-exam-professional-cloud-devops-engineer-topic-1-question-16/","answer_description":"","discussion":[{"comments":[{"comment_id":"702658","timestamp":"1682306040.0","content":"Agreed with D.","poster":"AzureDP900","upvote_count":"2"}],"content":"D because binary authorization is deploy time security tool and it will allow only trusted and attested containers into GKE","comment_id":"372829","upvote_count":"28","poster":"devopsbatch","timestamp":"1638466200.0"},{"comment_id":"393264","content":"D 100%","upvote_count":"9","poster":"Charun","timestamp":"1640734500.0"},{"comment_id":"1202915","poster":"trashbox","upvote_count":"2","content":"Selected Answer: D\nExam on 2024-04-26","timestamp":"1730001120.0"},{"content":"Answer is D:\nThe question states: 'only images which are successfully built..' which means Vulnerability Scanns have been completed...","upvote_count":"2","comment_id":"1194999","poster":"desertlotus1211","timestamp":"1728828840.0"},{"timestamp":"1717301640.0","comment_id":"1085744","poster":"jomonkp","upvote_count":"2","content":"option D"},{"content":"Selected Answer: D\nTo ensure that only images successfully built by your trusted CI/CD pipeline are deployed to production on Google Kubernetes Engine (GKE) clusters, you should set up the Kubernetes Engine clusters with Binary Authorization. Therefore, the correct answer is:\n\nD. Set up the Kubernetes Engine clusters with Binary Authorization.","timestamp":"1709681100.0","comment_id":"999932","poster":"carloscorreia","upvote_count":"2"},{"timestamp":"1709680620.0","comments":[{"poster":"kagami2","timestamp":"1717350840.0","content":"yes it is possible, as long as it is attested by an attestor.","comment_id":"1086391","upvote_count":"1"}],"content":"Selected Answer: B\nB\nThe question approach is about a trusted image generated, Is possible to create an image binary authorized with vulnerabilities?","poster":"carloscorreia","upvote_count":"1","comment_id":"999927"},{"poster":"SarumanMX","comment_id":"976100","content":"In another mock test I took this was a select-2 answers, and those were B & D","upvote_count":"1","timestamp":"1707443520.0"},{"poster":"samuelmorher","content":"Who is the one that selects the correct answers?, because it matches 1/9999, looks more like a random.","upvote_count":"1","timestamp":"1703684220.0","comment_id":"935296"},{"timestamp":"1689045660.0","comment_id":"772051","poster":"JonathanSJ","content":"Selected Answer: D\nD. Set up the Kubernetes Engine clusters with Binary Authorization.\n\nBinary Authorization is a feature of Google Kubernetes Engine that allows you to ensure that only containers that are verified to be from a trusted source are deployed to your clusters. It works by using a policy that checks the signatures of container images before they are deployed. You can configure Binary Authorization to require that all images are signed by a trusted certificate authority (CA) or that they are signed by a trusted key that you manage. This ensures that only images that have been successfully built by your trusted CI/CD pipeline are deployed to your production clusters.","upvote_count":"5"},{"timestamp":"1687670340.0","upvote_count":"1","comment_id":"755467","poster":"floppino","content":"Selected Answer: D\nAns: D\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/"},{"poster":"shivanisarthi","upvote_count":"2","content":"D is the right answer.\nThe dump is valid, got all questions from here and cleared the exam","timestamp":"1685887620.0","comment_id":"735225"},{"content":"i will go with D, as there is no vulnerability analysis , it is vulnerability scan in container analysis service. and the binary authorization use metadata store to secure trusted repository.","comment_id":"724939","upvote_count":"2","timestamp":"1684816020.0","poster":"hanweiCN"},{"poster":"zellck","timestamp":"1682342880.0","upvote_count":"1","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/binary-authorization\nBinary Authorization is a deploy-time security control that ensures only trusted container images are deployed on Google Kubernetes Engine (GKE) or Cloud Run. With Binary Authorization, you can require images to be signed by trusted authorities during the development process and then enforce signature validation when deploying. By enforcing validation, you can gain tighter control over your container environment by ensuring only verified images are integrated into the build-and-release process.","comment_id":"703054"},{"timestamp":"1674553980.0","comment_id":"635920","upvote_count":"1","poster":"GCP72","content":"Selected Answer: D\nanswer is D"},{"upvote_count":"1","content":"Selected Answer: D\nMust be D.","timestamp":"1672220580.0","poster":"Halimb","comment_id":"623827"},{"content":"Selected Answer: D\nanswer is D","upvote_count":"1","timestamp":"1671628260.0","comment_id":"619785","poster":"xtxrtx"},{"comment_id":"545764","upvote_count":"3","poster":"PhilipKoku","content":"Selected Answer: D\nD as Binary Authorisation enforces only trusted builds","timestamp":"1660294140.0"},{"upvote_count":"2","content":"D https://cloud.google.com/binary-authorization/?hl=zh-tw&utm_source=google&utm_medium=cpc&utm_campaign=japac-TW-all-en-dr-bkws-all-all-trial-e-dr-1009882&utm_content=text-ad-none-none-DEV_c-CRE_284325707741-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt%20~%20Security%20and%20Identity%20~%20Binary%20Authorization_binary%20authorization-KWID_43700035200283171-kwd-473575914620&userloc_9040379-network_g&utm_term=KW_gcp%20binary%20authorization&gclid=CjwKCAiArOqOBhBmEiwAsgeLmXG4Cu1unuvnKxmO7tAykQtTp-q-jDNRi-mBpNES-S5xNMPb6qSLJBoCTxQQAvD_BwE&gclsrc=aw.ds","poster":"pondai","timestamp":"1657405860.0","comment_id":"520550"},{"content":"Selected Answer: D\nCorrect Answer is D","poster":"simbu1299","comment_id":"520352","timestamp":"1657379340.0","upvote_count":"2"},{"poster":"Wwhite44","upvote_count":"1","content":"Selected Answer: D\nD clear","comment_id":"504244","timestamp":"1655553780.0"},{"comment_id":"503218","poster":"not_thanos","content":"Selected Answer: D\nhttps://cloud.google.com/binary-authorization/docs/overview","timestamp":"1655409180.0","upvote_count":"1"},{"timestamp":"1654423800.0","poster":"alaahakim","comment_id":"494311","content":"Ans: D","upvote_count":"2"},{"poster":"exploregcp","upvote_count":"4","comment_id":"411818","content":"D\nhttps://cloud.google.com/binary-authorization/docs/overview","timestamp":"1642879140.0"},{"timestamp":"1640877480.0","upvote_count":"3","poster":"WakandaF","comment_id":"394751","content":"erminology. Binary Authorization is a deploy time security service provided by Google that ensures that only trusted containers are deployed in our GKE cluster. It uses a policy driven model that allows us to configure security policies. Behind the scenes, this service talks to the Container Analysis service"}],"exam_id":6,"question_id":68},{"id":"YBsfIqLZWkZfqWLRnlXb","answer_images":[],"topic":"1","answer":"BC","timestamp":"2023-11-02 06:59:00","discussion":[{"poster":"alpha_canary","timestamp":"1723863780.0","content":"Selected Answer: BC\nWhy?\nB: Monitoring system metrics and setting up alerts can help you detect and respond to issues quickly, minimizing potential downtime during periods of high traffic.\n\nC: Reviewing your capacity requirements and planning for quota management ensures that your application has the necessary resources to handle the expected increase in traffic.\n\n\nNot.\nA: While Anthos Service Mesh can provide valuable insights into service interactions, it's not directly related to preparing for potential failures during high-traffic events. Also, it's not mentioned which tool we are using, so anthos might not even be used. \nD: While monitoring latency is important for understanding service performance, it doesn't directly help prepare for potential failures during high-traffic events. \nE: Creating alerts for all common failures could result in alert fatigue.","upvote_count":"3","comment_id":"1152371"},{"comment_id":"1090899","upvote_count":"2","timestamp":"1717828500.0","poster":"xhilmi","content":"Selected Answer: BC\nChoose B & C.\n\nB. \nCapturing system metrics with Cloud Monitoring allows you to monitor the health and performance of your application. Creating alerts based on these metrics enables proactive detection and quick response to anomalies or issues, ensuring the reliability of your application during the expected surge in traffic.\n\nC. \nAnticipating the increased capacity requirements during the event is crucial. Proper capacity planning, including scaling resources and managing quotas, ensures that your infrastructure can handle the high volume of traffic, preventing potential failures such as service degradation or outages."},{"poster":"nqthien041292","upvote_count":"1","timestamp":"1717338120.0","content":"Selected Answer: BC\nVote BC","comment_id":"1086304"},{"upvote_count":"2","timestamp":"1715173500.0","content":"Selected Answer: BE\nCreating alerts for failures is important","comment_id":"1065704","poster":"Billbalaji"},{"timestamp":"1714853700.0","comment_id":"1062420","poster":"mshafa","content":"Selected Answer: BC\nCome up to these options by skipping other options.","upvote_count":"2"},{"poster":"lelele2023","upvote_count":"3","timestamp":"1714622340.0","comment_id":"1060294","content":"Selected Answer: BC\nHaving proper metrics plus alerts, also prepare for resource quota"}],"answer_description":"","answers_community":["BC (85%)","BE (15%)"],"answer_ET":"BC","question_id":69,"question_text":"Your company is planning a large marketing event for an online retailer during the holiday shopping season. You are expecting your web application to receive a large volume of traffic in a short period. You need to prepare your application for potential failures during the event. What should you do? (Choose two.)","exam_id":6,"unix_timestamp":1698904740,"choices":{"C":"Review your increased capacity requirements and plan for the required quota management.","A":"Configure Anthos Service Mesh on the application to identify issues on the topology map.","E":"Create alerts in Cloud Monitoring for all common failures that your application experiences.","B":"Ensure that relevant system metrics are being captured with Cloud Monitoring, and create alerts at levels of interest.","D":"Monitor latency of your services for average percentile latency."},"isMC":true,"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/125156-exam-professional-cloud-devops-engineer-topic-1-question-160/"},{"id":"AIqz4n0zpCuzBrbci8na","question_images":[],"question_text":"Your company recently migrated to Google Cloud. You need to design a fast, reliable, and repeatable solution for your company to provision new projects and basic resources in Google Cloud. What should you do?","answer_description":"","discussion":[{"upvote_count":"1","poster":"alpha_canary","comment_id":"1152415","timestamp":"1723872360.0","content":"Selected Answer: D\nhttps://cloud.google.com/docs/terraform/blueprints/terraform-blueprints#:~:text=Creates%20an%20opinionated%20Google%20Cloud%20project%20by%20using%20Shared%20VPC%2C%20IAM%2C%20and%20Google%20Cloud%20APIs\n\nhttps://github.com/terraform-google-modules/terraform-google-project-factory"},{"content":"Selected Answer: D\nChoose D.\n\nUsing Terraform and the Cloud Foundation Toolkit ensures that you have a structured and version-controlled approach to provisioning resources. It also facilitates automation and scalability, making it easier to manage projects and resources across different environments.\n\nOptions A and B may lack the repeatability and version control benefits provided by IaC solutions like Terraform. While option C mentions Terraform, it doesn't specify using a toolkit or best practices for cloud foundation setup.\n\nIn summary, option D with Terraform and the Cloud Foundation Toolkit aligns with best practices for Infrastructure as Code, providing a fast, reliable, and repeatable solution for provisioning projects and resources in Google Cloud.","upvote_count":"1","comment_id":"1091015","timestamp":"1717839060.0","poster":"xhilmi"},{"content":"Selected Answer: D\nVote D","poster":"nqthien041292","timestamp":"1717338180.0","upvote_count":"1","comment_id":"1086306"},{"timestamp":"1714853580.0","content":"Selected Answer: D\nThe Cloud Foundation Toolkit provides a series of reference templates for Deployment Manager and Terraform which reflect Google Cloud best practices.","upvote_count":"1","comment_id":"1062418","poster":"mshafa"},{"timestamp":"1714152120.0","comment_id":"1054793","poster":"Jason_Cloud_at","upvote_count":"4","content":"Selected Answer: D\nFast , relaible and repeatable solution , It is terraform","comments":[{"timestamp":"1714622520.0","poster":"lelele2023","comment_id":"1060297","content":"plus D says cloud foundation toolkit","upvote_count":"1"}]}],"answer_ET":"D","choices":{"B":"Write a script by using the gcloud CLI that passes the appropriate parameters from the request. Save the script in a Git repository.","D":"Use the Terraform repositories from the Cloud Foundation Toolkit. Apply the code with appropriate parameters to create the Google Cloud project and related resources.","C":"Write a Terraform module and save it in your source control repository. Copy and run the terraform apply command to create the new project.","A":"Use the Google Cloud console to create projects."},"question_id":70,"answer":"D","answers_community":["D (100%)"],"topic":"1","url":"https://www.examtopics.com/discussions/google/view/124679-exam-professional-cloud-devops-engineer-topic-1-question-161/","answer_images":[],"exam_id":6,"timestamp":"2023-10-26 19:22:00","isMC":true,"unix_timestamp":1698340920}],"exam":{"provider":"Google","id":6,"numberOfQuestions":196,"lastUpdated":"11 Apr 2025","name":"Professional Cloud DevOps Engineer","isBeta":false,"isImplemented":true,"isMCOnly":true},"currentPage":14},"__N_SSP":true}