{"pageProps":{"questions":[{"id":"BDheJ9Zk9GrK4fNEXfSF","exam_id":5,"timestamp":"2022-12-22 00:29:00","choices":{"A":"Use the Google Cloud Console or gcloud CLI to manually create a new clone database.","D":"Start the original primary instance and resume replication.","B":"Use the Google Cloud Console or gcloud CLI to manually create a new failover replica from backup.","C":"Verify that the new replica is created automatically."},"discussion":[{"upvote_count":"1","content":"Selected Answer: C\nAgree with C","timestamp":"1732129920.0","comment_id":"1214516","poster":"dija123"},{"content":"Selected Answer: C\nFor MySQL, this should be C","upvote_count":"1","timestamp":"1727627820.0","poster":"DevBugger","comment_id":"1185618"},{"poster":"PKookNN","content":"Selected Answer: C\nFor MySQL, this should be C","upvote_count":"1","comment_id":"1137618","timestamp":"1722508260.0"},{"upvote_count":"2","poster":"kyou1313","content":"Selected Answer: C\nWhen a Cloud SQL read replica becomes unavailable, Cloud SQL automatically tries to create a new replica to replace the failed one. This process is part of the automated failover mechanism in Cloud SQL.\nB. Manually creating a new failover replica from backup might involve additional steps and may not be necessary for a temporary unavailability of the read replica.","timestamp":"1722208200.0","comment_id":"1134570"},{"upvote_count":"1","content":"Selected Answer: C\n\"During a zonal outage, traffic stops to read replicas in that zone. After the zone becomes available again, any read replicas in the zone resume replication from the primary instance.\"\nhttps://cloud.google.com/sql/docs/mysql/high-availability#read_replicas","timestamp":"1718876940.0","poster":"whoosh","comment_id":"1101489"},{"content":"C is the correct answer.\n\"During a zonal outage, traffic stops to read replicas in that zone. After the zone becomes available again, any read replicas in the zone resume replication from the primary instance.\"\nhttps://cloud.google.com/sql/docs/mysql/high-availability#read_replicas","comment_id":"1080639","poster":"kfiryo","comments":[{"comment_id":"1098262","upvote_count":"1","timestamp":"1718543520.0","content":"I think is D, if sth wrong it didn;t creat automatically. So B is correct","poster":"ArtistS","comments":[{"timestamp":"1718637480.0","comment_id":"1099104","upvote_count":"1","poster":"ArtistS","content":"srr it is B, I type it by mistake"}]}],"timestamp":"1716720480.0","upvote_count":"1"},{"comment_id":"1000053","poster":"learnazureportal","timestamp":"1709694660.0","content":"B is correct answer. Creating a new failover replica from a backup is a reliable way to restore replication and ensure that the read replica is up-to-date.","upvote_count":"1"},{"comment_id":"961954","poster":"[Removed]","timestamp":"1706130540.0","content":"Selected Answer: B\nB is correct","upvote_count":"1"},{"timestamp":"1703398800.0","upvote_count":"2","comment_id":"932153","poster":"Sandipcst","content":"C\n\nRecovery Process: Once Zone-B becomes available again, Cloud SQL will initiate the recovery process for the impacted read replica. The recovery process involves the following steps:\n\n1. Synchronization: Cloud SQL will compare the data in the recovered read replica with the primary instance in Zone-A. If there is any data divergence due to the unavailability period, Cloud SQL will synchronize the read replica with the primary instance to ensure data consistency.\n\n2. Catch-up Replication: The recovered read replica will start catching up on the changes that occurred on the primary instance during its unavailability. It will apply the necessary updates from the primary instance's binary logs (binlogs) to bring the replica up to date.\n\n3. Resuming Read Traffic: Once the synchronization and catch-up replication processes are complete, the read replica in Zone-B will resume its normal operation. It will be able to serve read traffic and stay updated with subsequent changes from the primary instance."},{"content":"Selected Answer: C\nBy verifying that the new replica is created automatically, you can ensure that the read replica instance is functioning and replication is maintained even after the temporary unavailability of the replica in Zone B.","comments":[{"upvote_count":"1","timestamp":"1702743000.0","poster":"wolfie09","comment_id":"925250","content":"A read replica is not recreated automatically."}],"comment_id":"908292","upvote_count":"2","poster":"KennyHuang","timestamp":"1701146400.0"},{"upvote_count":"2","content":"Selected Answer: D\nhttps://cloud.google.com/sql/docs/mysql/replication#:~:text=If%20replication%20is,a%20new%20one.","comment_id":"861516","timestamp":"1696455780.0","poster":"Pilot50"},{"upvote_count":"1","timestamp":"1696455660.0","content":"Selected Answer: D\nResume replication","poster":"Pilot50","comment_id":"861513"},{"comment_id":"771604","content":"B is wrong, failover replica is NOT a read replica\nA and C makes no sense","timestamp":"1688998320.0","poster":"marpayer","upvote_count":"2"},{"comment_id":"762370","upvote_count":"1","timestamp":"1688076480.0","content":"How is B correct? You don't create a replica from backup, and there's no mention of HA that would point to \"failover\" distinction. But don't like other answers either. Will go with B unless enlightened by subsequent contributor,","poster":"sp57"},{"upvote_count":"3","comment_id":"759567","timestamp":"1687933440.0","poster":"GCP72","content":"Selected Answer: B\nB is the correct answer"},{"poster":"chelbsik","content":"Selected Answer: B\nVote for B","comment_id":"758317","timestamp":"1687851060.0","upvote_count":"2"},{"upvote_count":"4","timestamp":"1687850460.0","content":"C - makes no sense\nD - nobody said primary instance was offline, plus you can't stop/resture replication on the primary instance, only on read replica\nA makes no sense: you can't create clone database from read replica, and if it means to create one from the primary instance - how would that help to insure that replica is still working?\nI'll go for B","poster":"chelbsik","comment_id":"758303"},{"content":"B: Use the Google Cloud Console or gcloud CLI to manually create a new failover ***** replica from backup.","poster":"pk349","upvote_count":"1","comment_id":"755730","timestamp":"1687697280.0"},{"upvote_count":"1","comment_id":"752862","timestamp":"1687382940.0","poster":"range9005","content":"I guess D\nStart the original primary instance and resume replication"}],"answers_community":["C (47%)","B (35%)","D (18%)"],"topic":"1","answer_images":[],"question_id":76,"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/92403-exam-professional-cloud-database-engineer-topic-1-question/","answer_ET":"C","answer_description":"","question_text":"You are managing a Cloud SQL for MySQL environment in Google Cloud. You have deployed a primary instance in Zone A and a read replica instance in Zone B, both in the same region. You are notified that the replica instance in Zone B was unavailable for 10 minutes. You need to ensure that the read replica instance is still working. What should you do?","answer":"C","unix_timestamp":1671665340,"isMC":true},{"id":"LGpAFMV3f8fcVlK10d3O","discussion":[{"upvote_count":"4","poster":"dynamic_dba","timestamp":"1726174620.0","content":"C.\nD might be possible but it’s a lot of effort to migrate to a different platform. Eliminate D. A does not mention HA. Eliminate A. B says to take periodic backups which doesn’t support an RTO/RPO of 30 minutes. The best answer is deploy an HA configuration and have a read replica you could promote to the primary in a different region. C is the best answer.","comment_id":"837460"},{"upvote_count":"3","timestamp":"1719556560.0","content":"Selected Answer: C\nC is the correct answer","comment_id":"759574","poster":"GCP72"},{"timestamp":"1719319680.0","comment_id":"755729","poster":"pk349","content":"C: Deploy Cloud SQL for PostgreSQL in a regional configuration with HA enabled. Create a cross-region read replica, and promote ***** the read replica as the primary node for disaster recovery.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1719301680.0","comment_id":"755569","content":"Selected Answer: C\nI'll go with C","poster":"chelbsik"}],"choices":{"A":"Deploy Cloud SQL for PostgreSQL in a regional configuration. Create a read replica in a different zone in the same region and a read replica in another region for disaster recovery.","C":"Deploy Cloud SQL for PostgreSQL in a regional configuration with HA enabled. Create a cross-region read replica, and promote the read replica as the primary node for disaster recovery.","D":"Migrate the PostgreSQL database to multi-regional Cloud Spanner so that a single region outage will not affect your application. Update the schema to support Cloud Spanner data types, and refactor the application.","B":"Deploy Cloud SQL for PostgreSQL in a regional configuration with HA enabled. Take periodic backups, and use this backup to restore to a new Cloud SQL for PostgreSQL instance in another region during a disaster recovery event."},"answer_ET":"C","question_images":[],"timestamp":"2022-12-25 10:48:00","isMC":true,"answer_description":"","exam_id":5,"answer":"C","url":"https://www.examtopics.com/discussions/google/view/92754-exam-professional-cloud-database-engineer-topic-1-question/","question_id":77,"question_text":"You are migrating an on-premises application to Google Cloud. The application requires a high availability (HA) PostgreSQL database to support business-critical functions. Your company's disaster recovery strategy requires a recovery time objective (RTO) and recovery point objective (RPO) within 30 minutes of failure. You plan to use a Google Cloud managed service. What should you do to maximize uptime for your application?","unix_timestamp":1671961680,"topic":"1","answers_community":["C (100%)"],"answer_images":[]},{"id":"98PZtj8BqYx8iJLYsC6b","isMC":true,"question_images":[],"timestamp":"2022-12-19 05:51:00","discussion":[{"upvote_count":"1","poster":"Zakky_09","content":"Selected Answer: A\nGoogle-recommended practices for migrating databases to Cloud SQL emphasize using the Database Migration Service (DMS) because it is a native, managed tool that supports:\n\nMinimal downtime migrations: It supports continuous data replication using change data capture (CDC).\n\nEase of use: DMS is fully integrated with Google Cloud, making it straightforward to configure and monitor migrations.\n\nMonitoring and reliability: It provides tools for monitoring the migration progress and detecting issues.\n\n\nBy using DMS for both one-time and ongoing replication needs, you align with Google's best practices while reducing the complexity of using multiple tools.","timestamp":"1735122060.0","comment_id":"1331504"},{"timestamp":"1732995600.0","comment_id":"1222282","poster":"studymoreoften","upvote_count":"2","content":"Selected Answer: A\ndatabase migration service can be used to migrate from on-prem and other clouds (AWS)"},{"content":"Selected Answer: A\nA is a correct answer","timestamp":"1726725300.0","poster":"Killerbee05","upvote_count":"2","comment_id":"1177067"},{"content":"Selected Answer: A\nhttps://cloud.google.com/database-migration/docs/overview","comment_id":"1102318","timestamp":"1718955180.0","upvote_count":"3","poster":"whoosh"},{"content":"Selected Answer: A\nhttps://cloud.google.com/database-migration/docs/overview","timestamp":"1718219220.0","poster":"jnya_1991","upvote_count":"2","comment_id":"1094966"},{"comment_id":"1010286","poster":"goodsport","content":"Selected Answer: A\nA is the correct answer here.","upvote_count":"3","timestamp":"1710746940.0"},{"comments":[{"timestamp":"1727712960.0","poster":"nmnm22","comment_id":"1186882","upvote_count":"1","content":"good point, thank you for pointing it out"}],"timestamp":"1699050060.0","content":"Selected Answer: A\nThe question says to use Google native data migration tools","comment_id":"888914","upvote_count":"3","poster":"somnathmaddi"},{"upvote_count":"4","timestamp":"1694573640.0","comment_id":"837636","poster":"cloudkoala","content":"Selected Answer: A\nDMS will do the CDC too."},{"content":"A.\nThe question says to use Google native data migration tools. That eliminates B and D. C doesn't specify the data replication tool in question so it's a reasonable assumption its referring to database native replication which wouldn't be a Google native solution. That eliminates C. That leave A.","comment_id":"835987","upvote_count":"3","timestamp":"1694429400.0","poster":"dynamic_dba"},{"upvote_count":"1","poster":"Nirca","timestamp":"1693682160.0","content":"Selected Answer: A\nDMS will do the job. For the init time and the CDC phase","comment_id":"827450"},{"timestamp":"1693651980.0","poster":"Hilab","comment_id":"826907","upvote_count":"1","content":"Option A is the most straightforward and recommended solution for migrating PostgreSQL databases to Cloud SQL while following Google-recommended practices and using native data migration tools."},{"comment_id":"796463","poster":"realvarez","content":"Selected Answer: A\nA\nhttps://cloud.google.com/blog/products/databases/tips-for-migrating-across-compatible-database-engines","upvote_count":"1","timestamp":"1691005080.0"},{"upvote_count":"4","content":"Selected Answer: A\nA is enough","poster":"chelbsik","comment_id":"757669","timestamp":"1687791720.0"},{"upvote_count":"1","poster":"pk349","timestamp":"1687699740.0","content":"A: Use Database Migration Service to migrate all databases to Cloud SQL.","comment_id":"755786"},{"upvote_count":"1","content":"Selected Answer: C\nC is the correct answer, we can use GCP migration tool for onetime or CDC","comments":[{"poster":"GCP72","comment_id":"767809","content":"My bad ,A is correct answer","upvote_count":"2","timestamp":"1688647620.0"}],"timestamp":"1687489740.0","poster":"GCP72","comment_id":"753861"},{"timestamp":"1687451460.0","upvote_count":"1","content":"Selected Answer: A\nA for live magrations","comment_id":"753575","poster":"H_S"},{"poster":"range9005","content":"Selected Answer: A\nMigrate to Cloud SQL and AlloyDB for PostgreSQL from on-premises, Google Cloud, or other clouds","comment_id":"749462","timestamp":"1687143060.0","upvote_count":"2"}],"choices":{"B":"Use Database Migration Service for one-time migrations, and use third-party or partner tools for change data capture (CDC) style migrations.","C":"Use data replication tools and CDC tools to enable migration.","D":"Use a combination of Database Migration Service and partner tools to support the data migration strategy.","A":"Use Database Migration Service to migrate all databases to Cloud SQL."},"exam_id":5,"answer_images":[],"topic":"1","question_text":"Your company has PostgreSQL databases on-premises and on Amazon Web Services (AWS). You are planning multiple database migrations to Cloud SQL in an effort to reduce costs and downtime. You want to follow Google-recommended practices and use Google native data migration tools. You also want to closely monitor the migrations as part of the cutover strategy. What should you do?","answers_community":["A (97%)","3%"],"url":"https://www.examtopics.com/discussions/google/view/92040-exam-professional-cloud-database-engineer-topic-1-question-5/","question_id":78,"answer":"A","answer_description":"","unix_timestamp":1671425460,"answer_ET":"A"},{"id":"eNyHYtHasHqCVldMXK6b","question_text":"Your team is running a Cloud SQL for MySQL instance with a 5 TB database that must be available 24/7. You need to save database backups on object storage with minimal operational overhead or risk to your production workloads. What should you do?","choices":{"C":"Clone the Cloud SQL instance, and then use the mysqldump utlity to export the data.","A":"Use Cloud SQL serverless exports.","D":"Use the mysqldump utility on the primary database instance to export the backup.","B":"Create a read replica, and then use the mysqldump utility to export each table."},"answer_images":[],"question_images":[],"timestamp":"2022-12-22 00:34:00","discussion":[{"timestamp":"1687937700.0","comment_id":"759636","poster":"GCP72","content":"Selected Answer: A\nA is the correct answer\nhttps://cloud.google.com/blog/products/databases/introducing-cloud-sql-serverless-exports","upvote_count":"5"},{"content":"Selected Answer: A\nA: https://cloud.google.com/blog/products/databases/introducing-cloud-sql-serverless-exports\n\nServerless exports enables you to export data from your MySQL and PostgreSQL database instances without any impact on performance or risk to your production workloads.","poster":"Pime13","timestamp":"1730553000.0","comment_id":"1205468","upvote_count":"1"},{"timestamp":"1694540100.0","poster":"dynamic_dba","comment_id":"837340","upvote_count":"4","content":"A.\nMinimal operational overhead eliminates B and C. Minimal risk to production workloads eliminates D. That leaves A. Least amount of work and doesn't impact the primary instance."},{"poster":"Nirca","timestamp":"1694005320.0","upvote_count":"1","comment_id":"830931","content":"Selected Answer: C\nCloud SQL backups are incremental. They contain only data that changed after the previous backup was taken. Your oldest backup is a similar size to your database, but the sizes of subsequent backups depend on the rate of change of your data. When the oldest backup is deleted, the size of the next oldest backup increases so that a full backup still exists."},{"comment_id":"830929","content":"With serverless export, Cloud SQL creates a separate, temporary instance to offload the export operation. Offloading the export operation allows databases on the primary instance to continue to serve queries and perform operations at the usual performance rate. BUT is is export (logical backup) and will never be incremental. and the recovery is slow. for 5TB server is it not an option. (only for mini databases). I believe The better option is C","timestamp":"1694005200.0","poster":"Nirca","upvote_count":"1"},{"content":"A: Use Cloud SQL serverless exports.\nServerless exports enables you to export data from your MySQL and PostgreSQL database instances without any impact on performance or risk to your production workloads. Cloud SQL exports, which offer portable data formats (SQL, CSV), can be triggered anytime and are written to Cloud Storage buckets that you control.","timestamp":"1687697220.0","comment_id":"755727","upvote_count":"1","poster":"pk349"},{"upvote_count":"1","content":"Selected Answer: A\nhttps://cloud.google.com/sql/docs/mysql/import-export#:~:text=Use%20serverless%20export,is%20deleted%20automatically.","timestamp":"1687677840.0","poster":"chelbsik","comment_id":"755552"},{"content":"Selected Answer: A\nCorrect Answer - A","poster":"jitu028","upvote_count":"1","timestamp":"1687485540.0","comment_id":"753835"},{"content":"Selected Answer: A\nUse Cloud SQL serverless exports.","poster":"range9005","timestamp":"1687383240.0","upvote_count":"1","comment_id":"752869"}],"topic":"1","answers_community":["A (90%)","10%"],"answer_description":"","isMC":true,"answer":"A","unix_timestamp":1671665640,"question_id":79,"answer_ET":"A","exam_id":5,"url":"https://www.examtopics.com/discussions/google/view/92405-exam-professional-cloud-database-engineer-topic-1-question/"},{"id":"HHkzQXVXpgJ5dCR4SI7W","isMC":true,"question_images":[],"discussion":[{"poster":"Lucker","content":"the best answer would be B . Need granular control for each of the code snippets . The advantage of using a service account for this purpose is that you can create a credential file specifically for the Cloud SQL Auth Proxy, and it is explicitly and permanently linked to the Cloud SQL Auth Proxy as long as it is running. For this reason, using a service account is the recommended method for production instances not running on a Compute Engine instance.","comment_id":"1266335","timestamp":"1723714620.0","upvote_count":"1"},{"comment_id":"882490","timestamp":"1682589900.0","content":"C. The docs proving this are here: Create and configure a Google Cloud service account that has the Cloud SQL Client role with permissions to connect to Cloud SQL.","poster":"felipeschossler","upvote_count":"1"},{"poster":"dynamic_dba","content":"C.\nThe Google recommendation would be for an application to use a service account. None of the other options make sense in light of this.","timestamp":"1678661940.0","comment_id":"837461","upvote_count":"2"},{"poster":"GCP72","comment_id":"759646","timestamp":"1672220340.0","upvote_count":"3","content":"Selected Answer: C\nCorrect answer is C, service account is the GCP recommended option"},{"timestamp":"1671979500.0","comment_id":"755725","poster":"pk349","content":"B: For each application code, set up a dedicated ***** user account.","upvote_count":"1"},{"upvote_count":"3","timestamp":"1671960480.0","content":"Selected Answer: C\nhttps://cloud.google.com/sql/docs/mysql/sql-proxy#using-a-service-account","comment_id":"755555","poster":"chelbsik"}],"topic":"1","exam_id":5,"question_id":80,"url":"https://www.examtopics.com/discussions/google/view/92750-exam-professional-cloud-database-engineer-topic-1-question/","answer":"C","answers_community":["C (100%)"],"answer_description":"","choices":{"C":"For the application server, set up a service account.","B":"For each application code, set up a dedicated user account.","A":"For each application code, set up a common shared user account.","D":"For the application server, set up a common shared user account."},"question_text":"You are deploying a new Cloud SQL instance on Google Cloud using the Cloud SQL Auth proxy. You have identified snippets of application code that need to access the new Cloud SQL instance. The snippets reside and execute on an application server running on a Compute Engine machine. You want to follow Google-recommended practices to set up Identity and Access Management (IAM) as quickly and securely as possible. What should you do?","timestamp":"2022-12-25 10:28:00","answer_images":[],"unix_timestamp":1671960480,"answer_ET":"C"}],"exam":{"isImplemented":true,"lastUpdated":"11 Apr 2025","id":5,"isMCOnly":true,"numberOfQuestions":132,"name":"Professional Cloud Database Engineer","provider":"Google","isBeta":false},"currentPage":16},"__N_SSP":true}