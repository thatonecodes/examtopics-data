{"pageProps":{"questions":[{"id":"MoRxxgHy9P0XojBYnxMs","discussion":[{"content":"USB...where can I buy a 1 PB USB ...?","poster":"SuperNest","upvote_count":"53","comments":[{"upvote_count":"7","comment_id":"441870","timestamp":"1646825100.0","content":"Lol :)","poster":"MikeB19"},{"poster":"satamex","comment_id":"640816","content":"After this question I am sure why all answers are wrong, so the we come to the discussion and increase our knowledge levels by reading from the high value notes shared by everyone.","timestamp":"1675285740.0","upvote_count":"7"},{"comment_id":"1161959","timestamp":"1724867520.0","content":"Have you tried B&H? \n\njk, that thing would be the size of a small bus and weight severalk tons at least","poster":"Timothy_Burton","upvote_count":"2"}],"comment_id":"440946","timestamp":"1646667720.0"},{"poster":"ACE_ASPIRE","comments":[{"content":"definitely A is answer, why has someone placed a trap here?","poster":"PleeO","upvote_count":"3","comments":[{"timestamp":"1649661780.0","poster":"rottzy","content":";) ;) ;)","comment_id":"460424","upvote_count":"1"}],"timestamp":"1647248040.0","comment_id":"444381"}],"content":"Who puts the answer here? how can you say that put the data in a USB....It should be A","upvote_count":"8","comment_id":"443304","timestamp":"1647072180.0"},{"content":"Selected Answer: A\nA. transfer appliance take up 20 days and we have a month: https://cloud.google.com/transfer-appliance/docs/4.0/overview#transfer-speeds","poster":"Pime13","upvote_count":"1","timestamp":"1722275760.0","comment_id":"1135265"},{"comments":[{"content":"Storage Transfer Service is usually for inter cloud, if you don't see any other cloud or cloud storage compliant service as the source you can ignore that option, as it is in this question - Storage Transfer Service\nTransfer data quickly and securely between object and file storage across Google Cloud, Amazon, Azure, on-premises, and more.","poster":"sampon279","timestamp":"1703898900.0","upvote_count":"1","comment_id":"938606"}],"timestamp":"1688316120.0","upvote_count":"3","comment_id":"763914","poster":"prakata","content":"Why can't we use storage transfer service ?"},{"timestamp":"1687801680.0","comment_id":"757787","poster":"thamaster","content":"Selected Answer: A\n1 pb to move in one month with 1 gbps you need an appliance it will take 3 weeks.\nAns A","upvote_count":"2"},{"timestamp":"1687761060.0","content":"jus purchased 1pb usb","comment_id":"757249","poster":"pawan7869","upvote_count":"6"},{"content":"Selected Answer: A\nA Is the best answer \n1 Pb Data Transfer with 1 Gbps speed takes 124 days to transfer data","timestamp":"1687054740.0","upvote_count":"1","comment_id":"748600","comments":[{"content":"92, but doesn't matter.","timestamp":"1698079020.0","poster":"medi01","comment_id":"878619","upvote_count":"1"}],"poster":"surajkrishnamurthy"},{"comment_id":"696197","content":"A is perfect for this use case","poster":"AzureDP900","timestamp":"1681643040.0","upvote_count":"2"},{"upvote_count":"3","comment_id":"689493","timestamp":"1680969900.0","poster":"abdelilahfa","content":"Selected Answer: A\nIt will take 123 days to transfer \nThe right answer is to use Transfer Appliance\nhttps://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets#time"},{"timestamp":"1676417880.0","upvote_count":"2","comment_id":"646926","content":"Answer is a A..\n123 days to transfer 1PB of data using a 1GB link... this is from DC edge to GCP... this may be longer due to internal DC Fabric design","poster":"desertlotus1211"},{"poster":"AzureDP900","content":"USB is big joke whoever wrote this question they should have make it much better, Transfer Appliance is perfect for 1PB. A is right.","comment_id":"627206","upvote_count":"1","timestamp":"1672892460.0"},{"content":"Selected Answer: A\nTransfer appliance can be used to transfer data more than 10 TB from on-prem","timestamp":"1669808160.0","upvote_count":"3","comment_id":"609111","poster":"Superr"},{"comment_id":"602619","poster":"amxexam","content":"Selected Answer: A\nThere is no special use care to call for B like third party cloud.or any special massage of data required. A is the always way to go for private sturge and peta byto of data .\n\nA","upvote_count":"2","timestamp":"1668615360.0"},{"comment_id":"591569","poster":"mad314","content":"Selected Answer: A\nHad this question on my exam.","upvote_count":"3","timestamp":"1666693920.0"},{"poster":"kimharsh","upvote_count":"2","content":"Selected Answer: A\nIT's A, \nWhoever answered B did you calculate how long it will take for the data to be transferred ? it have to be less than 1 month from the question requirement \nhttps://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets#time","comment_id":"580247","timestamp":"1664797620.0"},{"poster":"Skr6266","comment_id":"579765","timestamp":"1664699700.0","upvote_count":"3","content":"Selected Answer: A\nAnswer is A. \nhttps://cloud.google.com/transfer-appliance/docs/4.0/overview#location-availability\nWith a typical network bandwidth of 100 Mbps, one petabyte of data takes about 3 years to upload. However, with Transfer Appliance, you can receive the appliance and capture a petabyte of data in under 25 days. Your data can be accessed in Cloud Storage within another 25 days, all without consuming any outbound network bandwidth.\nwith 1GBps - online STS will take 124 days .."},{"content":"Correct Answer is A","poster":"GauravLahoti","upvote_count":"1","comment_id":"512649","timestamp":"1656524520.0"},{"content":"Selected Answer: A\n1PB USB drive is a joke.","poster":"zxcv1234","upvote_count":"3","comment_id":"509392","timestamp":"1656205620.0"},{"comment_id":"505317","timestamp":"1655711520.0","content":"Selected Answer: A\nA is correct","upvote_count":"3","poster":"Bobch"},{"comment_id":"505126","timestamp":"1655670540.0","upvote_count":"4","poster":"ABO_Doma","content":"Selected Answer: B\nTransfer Appliance is a hardware appliance you can use to securely migrate large volumes of data (from hundreds of terabytes up to 1 petabyte) to Google Cloud Platform without disrupting business operations."},{"comments":[{"poster":"szefco","upvote_count":"1","timestamp":"1673730420.0","comment_id":"631505","content":"This amount if data with 1 Gbps connection would take more than a month to transfer, so it can't be B. A is connect answer."}],"timestamp":"1655670480.0","poster":"ABO_Doma","upvote_count":"3","comment_id":"505125","content":"Selected Answer: B\nTransfer service for on-premises data is a software service that enables you to transfer large amounts of data from your data center to a Cloud Storage bucket. It is well suited for customers that are moving billions of files and 100s of TB of data in a single transfer. It can scale to network connections in the 10s of Gbps."},{"comment_id":"504347","timestamp":"1655565720.0","upvote_count":"1","content":"Selected Answer: A\nEncypted but he didnt mention virus scanned so its A","poster":"ABO_Doma"},{"upvote_count":"2","content":"Selected Answer: A\nThe expected turnaround time for a network appliance to be shipped, loaded with your data, shipped back, and rehydrated on Google Cloud is 20 days. If your online transfer timeframe is calculated to be substantially more than this timeframe, consider Transfer Appliance.\nhttps://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets?hl=en#transfer_appliance_for_larger_transfers","poster":"SamGCP","timestamp":"1655320680.0","comment_id":"502483"},{"upvote_count":"1","content":"Selected Answer: A\nA is the correct answer","poster":"vincy2202","timestamp":"1654850820.0","comment_id":"498528"},{"content":"Selected Answer: A\nMarked D is funny answer. Makes no sense. There is no usb device for 1 PB data in market.","poster":"[Removed]","upvote_count":"1","timestamp":"1654456020.0","comment_id":"494675"},{"poster":"pakilodi","comment_id":"493867","content":"Selected Answer: A\nVote A","timestamp":"1654357380.0","upvote_count":"1"},{"upvote_count":"2","poster":"pradhyumna","timestamp":"1653714180.0","content":"Selected Answer: A\nTransfer Appliance is the perfect use case for this.","comment_id":"488910"},{"comment_id":"487985","content":"Selected Answer: A\nvote A","upvote_count":"1","poster":"joe2211","timestamp":"1653633060.0"},{"timestamp":"1651325760.0","content":"A. \nTransferring 1PB data with 1Gbps connection requires 123 days, the requirement is one month hence you need a Transfer Appliances\nhttps://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets#close","comment_id":"470734","upvote_count":"3","poster":"MaxNRG"},{"content":"A. is not correct as it can take up to 50 days before data becomes visible within a bucket","comment_id":"441391","upvote_count":"2","poster":"zaxxon","timestamp":"1646743860.0"},{"upvote_count":"3","poster":"victory108","timestamp":"1646385420.0","content":"A. Request Transfer Appliances from Google Cloud, export the data to appliances, and return the appliances to Google Cloud.","comment_id":"438962"},{"upvote_count":"2","poster":"[Removed]","timestamp":"1646073300.0","content":"I would also go with A, this is about too high data volume 1 PB to transfer","comment_id":"435671"},{"poster":"nickojul","timestamp":"1645889100.0","content":"A is ok","comment_id":"432352","upvote_count":"3"},{"poster":"raf2121","comments":[{"comment_id":"431544","content":"I think u may have mis read the q. It states 1pb not 1tb. For 1pb the transfer appliance is the correct export approach","upvote_count":"1","timestamp":"1645806180.0","poster":"MikeB19"},{"poster":"raf2121","timestamp":"1645806240.0","content":"I missed - I read PB as TB - Correct answer is A (considering PB)","comment_id":"431545","upvote_count":"4"}],"timestamp":"1645756140.0","comment_id":"431058","upvote_count":"1","content":"Answer B \n\n1. One TB with 1 Gbps network bandwidth will take three hours for transfer. \n2. From Private Data Center if the data to be transferred is less than 1TB suggested option is gsutil and if it's more than 1TB with enough network bandwidth suggested option is Storage Transfer Service\n\nSince gsutil option not there, picking up Storage Transfer Service\nhttps://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets?hl=en"},{"poster":"GRGP","upvote_count":"4","timestamp":"1645719540.0","content":"A. Request Transfer Appliances from Google Cloud, export the data to appliances, and return the appliances to Google Cloud.","comment_id":"430833"},{"content":"A is OK","poster":"SweetieS","timestamp":"1645718520.0","comment_id":"430817","upvote_count":"3"},{"content":"A is the correct answer...","comment_id":"430613","poster":"velasko","upvote_count":"3","timestamp":"1645698780.0"}],"question_images":[],"answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/60483-exam-professional-cloud-architect-topic-10-question-6/","timestamp":"2021-08-24 10:33:00","answers_community":["A (83%)","B (17%)"],"question_text":"For this question, refer to the TerramEarth case study. TerramEarth has about 1 petabyte (PB) of vehicle testing data in a private data center. You want to move the data to Cloud Storage for your machine learning team. Currently, a 1-Gbps interconnect link is available for you. The machine learning team wants to start using the data in a month. What should you do?","choices":{"B":"Configure the Storage Transfer service from Google Cloud to send the data from your data center to Cloud Storage.","D":"Export files to an encrypted USB device, send the device to Google Cloud, and request an import of the data to Cloud Storage.","C":"Make sure there are no other users consuming the 1Gbps link, and use multi-thread transfer to upload the data to Cloud Storage.","A":"Request Transfer Appliances from Google Cloud, export the data to appliances, and return the appliances to Google Cloud."},"question_id":206,"answer_ET":"A","answer":"A","exam_id":4,"topic":"10","isMC":true,"unix_timestamp":1629793980},{"id":"zptYjjxKAUwDlrLSouyK","discussion":[{"comments":[{"timestamp":"1630807740.0","content":"A, you can do pretty much everything from cloud shell.","upvote_count":"3","poster":"nitinz","comment_id":"303920"},{"comment_id":"155919","content":"A is ok","upvote_count":"8","timestamp":"1613091720.0","poster":"tartar"}],"upvote_count":"33","content":"I thought operations team doesn't need SSH access to manage VMs. All it needs is Cloud Shell with the Cloud SDK and gcloud tools.\nMaybe A is correct answer.","poster":"KouShikyou","timestamp":"1587016020.0","comment_id":"15584"},{"upvote_count":"11","content":"Selected Answer: A\nOld Case Study - Should be removed","comment_id":"652612","poster":"Crick76","timestamp":"1677518520.0"},{"upvote_count":"1","timestamp":"1725371580.0","comment_id":"1164901","content":"Selected Answer: D\nWhile Google Cloud Shell provides access to the GCP console and some tools, it might not offer the full functionality needed for managing VMs, containers, and Cloud Storage objects. Additionally, granting shell access to the entire console carries a higher security risk.","poster":"mesodan"},{"poster":"Mahmoud_E","comment_id":"700356","content":"Selected Answer: A\nA is OK","timestamp":"1682029800.0","upvote_count":"1"},{"poster":"joe2211","timestamp":"1653633300.0","content":"Selected Answer: A\nvote A","upvote_count":"1","comment_id":"487986"},{"content":"We could misunderstand the question. It's not talking about SSH into the instance to deploy the images. The team only needs an environment to build and publish to the repositories.","timestamp":"1652751180.0","poster":"chorizama","comment_id":"479795","upvote_count":"1"},{"content":"A. Grant the operations engineer access to use Google Cloud Shell.","timestamp":"1642320180.0","upvote_count":"1","comment_id":"407628","poster":"victory108"},{"comment_id":"401154","upvote_count":"1","timestamp":"1641584760.0","poster":"MamthaSJ","content":"Answer is A"},{"poster":"Ausias18","timestamp":"1633094280.0","upvote_count":"1","comment_id":"325868","content":"Answer is A"},{"timestamp":"1631802480.0","poster":"VenV","upvote_count":"2","comments":[{"poster":"lynx256","upvote_count":"1","content":"I think we don't have to login to VMs; we only have to MANAGE them - which is quite different. The same for Docker containers and GCS objects.\nIMO A is the best...","comments":[{"content":"Of course - you can still SSH to VMS but from Cloud Shell (NOT externally, as task states \"security team has disabled external SSH access).","timestamp":"1632407640.0","comment_id":"318245","upvote_count":"1","poster":"lynx256"}],"comment_id":"318242","timestamp":"1632407340.0"}],"comment_id":"312526","content":"how cloudshell works to login to vms if we block port 22 in the firewall rules for external access? try this in your environment and see if it works.....not A. if we dont block external access, then cloudshell will be good option in this case."},{"upvote_count":"1","content":"Answer A - With Cloud Shell can manage your resources with its online terminal preloaded with utilities.","comment_id":"293696","poster":"cert2020","timestamp":"1629311760.0"},{"poster":"aaabbbc1","timestamp":"1629265680.0","upvote_count":"1","comment_id":"293184","content":"A will be considered as the final decision, I promise"},{"timestamp":"1629124200.0","content":"ans is A ..When the ops team login through cloud shell, the credential acc is there.\n\nthe ops team engineer typically has all the necessary permission required to manage system such as - build, push docker and manage. when the team execute command from cloud shell the command will excecute through there credential acc and succed as log as they have permission ehich they should as ops team. may not able to ssh but i am role let them to carry out action like start ,stop ,terminate all don't need ssh .","upvote_count":"2","poster":"CloudGenious","comment_id":"291922"},{"comment_id":"282348","poster":"bnlcnd","content":"A is wrong. how do you push a docker image from your on-prem server to GCP with cloud shell?\nB is the only option.","upvote_count":"2","timestamp":"1627950360.0"},{"upvote_count":"3","timestamp":"1627680720.0","content":"My choice is A","comment_id":"280229","poster":"BobBui"},{"upvote_count":"10","comment_id":"278178","timestamp":"1627428360.0","poster":"iamoct","content":"This is the official answer. No more argue.\n\nA. Grant operations team access to use Cloud Shell. ✅\n\nA - The operations team doesn't actually need SSH access to manage VMs. All it\nneeds is Cloud Shell with the Cloud SDK and gcloud tools.\nCloud Shell provides all the tools for managing Compute Engine instances. In this\ncase the assumption that SSH access is needed is incorrect.\nBusiness requirement:\n \"Improve security by defining and adhering to a set of security and Identity and\nAccess Management (IAM) best practices for cloud.\"\nB - A VPN is a way to connect from remote to the internal IP of an instance. If SSH is\nblocked everywhere, this work-around won't help.\nC - Developing an application that would use the Cloud API would be redundant with\nthe gcloud command line tool.\nD - An application the provides temporary access to SSH is basically just violating the\nsecurity practices."},{"timestamp":"1623941940.0","poster":"okixavi","content":"I'll go with A","upvote_count":"1","comment_id":"246688"},{"comment_id":"230920","timestamp":"1622354940.0","content":"To me the question is: having ssh access to the VM, can it build and push docker containers?? If yes, then go for VPN. If no, then go for Cloud Shell.","poster":"cloud_g","upvote_count":"1"},{"poster":"JCGO","timestamp":"1622289660.0","content":"For network oriented guy it's simple question and answer. VPN for sure: B.","comment_id":"230338","upvote_count":"1"},{"upvote_count":"1","content":"I will go with B = VPN connection \ngoogle documentation said: If you have isolated instances that do not have an external IP address, you can still connect to those instances by using their internal IP addresses on a Google Cloud VPC network. For example, you can still connect to VMs that you intentionally isolate from external networks by using the following methods:\n\nConnect to instances over a VPN connection that has access to the internal IP addresses of instances on your Google Cloud VPC.","poster":"Hjameel","timestamp":"1622153640.0","comment_id":"229303"},{"timestamp":"1621421640.0","upvote_count":"2","content":"agree with A","poster":"Chulbul_Pandey","comment_id":"222778"},{"upvote_count":"1","content":"A is correct Answer:\n\nWhen the operations engineer logs into Cloud shell, the credentialed account is their Cloud Identity account.\n\ne.g.\n\ngcp_test_user@cloudshell:~ (project-1-278333)$ gcloud auth list\nCredentialed Accounts\nACTIVE ACCOUNT\n* gcp.test.user@gmail.com\n\nTo set the active account, run:\n$ gcloud config set account `ACCOUNT`\n\ngcp_test_user@cloudshell:~ (project-1-278333)$\nThe operations engineer typically has all the necessary permissions required to manage systems such as - manage the VMs, build and push Docker containers, and manage Google Cloud Storage objects. When the operations engineer executes commands from the Cloud shell, the commands are executed with their Credentialed account and succeed as long as they have the necessary permissions - which they should as operations team. The fact that they may not be able to SSH from the cloud shell is not essential to managing the VMs. The IAM permissions let them carry out actions such as stop/start/restart/terminate etc. all of which don't need SSH access to VMs.","comment_id":"218503","timestamp":"1620907200.0","poster":"hems4all"},{"content":"B is correct:\nhttps://cloud.google.com/compute/docs/instances/connecting-advanced#sshbetweeninstances\n\nExplanation:\nConnecting to instances that do not have external IP addresses\nIf you have isolated instances that do not have an external IP address you can still connect to those instances using their internal IP addresses on a Google Cloud VPC network. For example, you can still connect to VM instances that you intentionally isolate from external networks by using the following methods:\n\nConnect to instances over a VPN connection that has access to the internal IP addresses of instances on your Google Cloud VPC.\nConnect through a bastion host instance to gain access to the internal IP address on your Google Cloud VPC. Then, connect from the bastion host to other instances on the same internal VPC network or instances on a peered VPC network.\nConnect using Identity-Aware Proxy for TCP forwarding to forward an SSH connection to a remote instance.","upvote_count":"1","poster":"pepYash","comments":[{"upvote_count":"1","poster":"0x24141","comment_id":"236307","timestamp":"1622965020.0","content":"You can try it from your gcloud env or a cloud console env, when connecting to an instance with gcloud compute ssh instance-1 --zone us-central1-a, it will setup IAP tunnel for you when no external IP exists..."}],"comment_id":"218106","timestamp":"1620838440.0"},{"comment_id":"213294","content":"Pay attention to the question.\nD is not correct because a similar/equal service already exists, it's the Cloud Shell\nC is not correct because grant access for VM operation only\nB is not correct because is worst than c, do the same thing but with more effort and cost\nA is correct, Cloud Shell is available from the console, so via web, and all action required are feasible","timestamp":"1620197280.0","poster":"occupatissimo","upvote_count":"1"},{"upvote_count":"1","content":"A is the correct answer.","comment_id":"209745","timestamp":"1619755620.0","poster":"gcparchitect007"},{"upvote_count":"4","comment_id":"208290","content":"I will go with B, as the questions mentioned team has disabled external SSH access into production VMs on GCP. The operations team needs to remotely manage the VMs, build and push Docker containers, and manage Google Cloud Storage objects.\n\nUsing VPN, you can avoid external connection and still manage VMs remotely.\n\nWhy NOT A, because Cloud Shell uses external SSH connection to VMs","poster":"AdityaGupta","timestamp":"1619668620.0"},{"comment_id":"201839","timestamp":"1618724220.0","upvote_count":"1","content":"from cost perspective solution is i pick A is better than B","poster":"LoganIsh"},{"comment_id":"198618","timestamp":"1618249500.0","upvote_count":"1","poster":"kimberjdaw","content":"Scenario says they're using Jenkins. That's what would do the Docker builds. Use a VPN."},{"comment_id":"196647","content":"B is correct. cloud shell can also be used but the point is, access is required for operation guys no developer so provide only that much access, which is required.","timestamp":"1617963000.0","upvote_count":"3","poster":"LalBisota"},{"timestamp":"1614322080.0","upvote_count":"1","content":"VPN is for hybrid(onprem2cloud), here generic 'remotely' - hence, would go with A","comment_id":"166452","poster":"sarva"},{"upvote_count":"2","timestamp":"1614038520.0","comment_id":"163957","poster":"droidmasta","content":"They have disabled EXTERNAL ssh access to VMs. The way to access VMs and GCP would be though a VPN or some sort of private connection to their GCP infra"},{"content":"A) is ok. SSH can be acomplished by gcloud compute ssh + iap-proxy (internal connections are allowed, only external ones are forbidden)","timestamp":"1613733720.0","upvote_count":"2","comments":[{"poster":"kimberjdaw","content":"External is forbidden in the scenario.","upvote_count":"1","timestamp":"1618249440.0","comment_id":"198614"}],"comment_id":"161371","poster":"jespinosar"},{"content":"Answer is A. gcloud for managing VMs remotely, docker push to push the docker images to GCP and gsutil to manage Cloud storage.","poster":"RahulR","timestamp":"1613196660.0","comment_id":"156935","upvote_count":"2"},{"upvote_count":"3","poster":"mlantonis","timestamp":"1608815280.0","content":"The question is very similar with a question from the Coursera course.\n\nEngineers don't actually need SSH to access VMs. All they want is to to manage VMs, build and push Docker containers, manage Google Cloud Storage objects. These actions can be done through Cloud Shell with the Cloud SDK and gcloud tools.\n\nDefinitely the correct answer is A.","comment_id":"118339"},{"poster":"kban","upvote_count":"1","timestamp":"1608325260.0","comment_id":"113432","content":"A is correct answer.\nThe operations team doesn't actually need SSH access to manage VMs. All it needs is Cloud Shell with the Cloud SDK and gcloud tools. Cloud Shell provides all the tools for managing Compute Engine instances. In this case the assumption that SSH access is needed is incorrect."},{"comment_id":"112979","content":"A for sure; question also states the need to build Docker containers and managing Cloud Storage so Cloud Shell is the tool required","poster":"syu31svc","comments":[{"timestamp":"1618249380.0","comment_id":"198613","upvote_count":"1","poster":"kimberjdaw","content":"Maybe if you're just working on a personal blog. Any real company would have a serious CI/CD workflow with Jenkins, Spinnaker, or Cloud Build. Cloud Shell should never be something you plan for."}],"timestamp":"1608282000.0","upvote_count":"1"},{"poster":"bubai01","timestamp":"1607753160.0","comment_id":"108312","content":"A\nWhy SSH access needs to be provided when not needed.","upvote_count":"2"},{"content":"A for me and not B because you don't create and push docker images from inside of a VM. You do that from cloud shell. Moreover, you can manage VMs from cloud shell using many 'gcloud compute instances' commands, questions does not say you need to SSH into VMs to manage.","comment_id":"104288","poster":"Rafaa","timestamp":"1607323140.0","comments":[{"upvote_count":"1","timestamp":"1618249320.0","content":"Nobody would ever from that from the shell. You either do that in your CI/CD flow (Cloud Build or VM); yes, of course you use a VM just as everyone currently does. Cloud Shell is only used as a plan B when you can't VPN in.","poster":"kimberjdaw","comment_id":"198612"}],"upvote_count":"1"},{"comment_id":"104076","upvote_count":"3","content":"A is the correct answer","timestamp":"1607292240.0","poster":"Ziegler"},{"upvote_count":"2","content":"Response A for me","comment_id":"103116","poster":"saadlamarti","timestamp":"1607176800.0"},{"content":"If the team only wants to remotely manage the VMs, then A. But the question said they also want to \"build and push Docker containers, manage Google Cloud Storage objects\", so I guess B is the correct answer (only if the team would be granted to have IAM to do GKE and GCS)","upvote_count":"2","timestamp":"1606971360.0","poster":"Gini","comment_id":"101376"},{"comment_id":"97917","comments":[{"timestamp":"1606618860.0","comments":[{"poster":"andyramone","comments":[{"poster":"Ani26","content":"I am totally LoL'ing as you wrote exactly what I felt :P","timestamp":"1612885500.0","upvote_count":"3","comments":[{"timestamp":"1618909320.0","upvote_count":"1","poster":"kv1610","content":"Are all the answers which are most repeated by the users in the discussion forum correct or the answers given with question?? Which one should be considered if the same question comes in the GCP certifiation exam.","comment_id":"203075"}],"comment_id":"153708"}],"comment_id":"146736","timestamp":"1611949980.0","content":"Every time I see the Final Decision statement, I laugh inside. But Final Decision Updated is even better and made me LOL.","upvote_count":"19"}],"content":"Final Decision Updated to Option A as per the coursera module","upvote_count":"11","poster":"AD2AD4","comment_id":"97926"}],"poster":"AD2AD4","content":"Final Decision to go with Option B\nRefer - https://cloud.google.com/compute/docs/instances/connecting-advanced#sshbetweeninstances","upvote_count":"1","timestamp":"1606617960.0"},{"content":"A is the correct and simplest solution.","poster":"Jack_in_Large","upvote_count":"2","timestamp":"1605649920.0","comment_id":"90826"},{"comments":[{"upvote_count":"1","timestamp":"1618249260.0","content":"Remotely is exactly what a VPN is for.","comment_id":"198610","poster":"kimberjdaw"}],"content":"Says Remotely. So Cloud shell.","comment_id":"61661","poster":"yogeshmsc","upvote_count":"3","timestamp":"1599733860.0"},{"upvote_count":"5","comment_id":"51988","content":"Enginer doesn't actually need SSH access to manage VMs. All it\nneeds is Cloud Shell with the Cloud SDK and gcloud tools.\nCloud Shell provides all the tools for managing Compute Engine instances. In this\ncase the assumption that SSH access is needed is incorrect","poster":"Ipergorta","timestamp":"1597729800.0"},{"poster":"VASI","timestamp":"1597669260.0","upvote_count":"1","comments":[{"content":"Although I also think B but the question says they have blocked external access. It does not mean they have disabled external IP of VMs.","poster":"Rafaa","comment_id":"99602","upvote_count":"1","timestamp":"1606782360.0"}],"comment_id":"51711","content":"https://cloud.google.com/compute/docs/instances/connecting-advanced#sshbetweeninstances\nThe answer should be B."},{"content":"cloud shell has gsutil & docker inside, so there is no problem to build the containers.\n+ i remember this one from coursera, which was an official preparation course.\ngo with A","timestamp":"1595740980.0","poster":"kvokka","upvote_count":"2","comment_id":"42799"},{"content":"\" push Docker containers, and manage Google Cloud Storage objects.\" cannot be achieved with B. `So I will go with A","poster":"AWS56","timestamp":"1594639800.0","upvote_count":"2","comment_id":"38481"},{"poster":"MrBog1","upvote_count":"2","timestamp":"1593128040.0","content":"I would say it is A. user cloud shell to push image to registry without SSH","comment_id":"32689"},{"content":"i think this answer is A.\n\nI see similar Question.\nPreparing for the Google Cloud Professional Cloud Architect Exam lecture of Coursera.\n\nsimilar answer is A.","poster":"JJu","upvote_count":"10","timestamp":"1590587460.0","comment_id":"24845"},{"content":"I agree it is B. Says remotely. also this link https://cloud.google.com/compute/docs/instances/connecting-advanced. A is not exactly helpful with building docker images.","comment_id":"23724","poster":"cjsammaejs","upvote_count":"3","timestamp":"1590174060.0"},{"content":"Answer is A","poster":"JoeShmoe","timestamp":"1589528640.0","upvote_count":"2","comment_id":"21732"},{"content":"It's B, the idea is to allow internal SSH + VPN.","poster":"jcmoranp","timestamp":"1587900900.0","upvote_count":"5","comment_id":"17576"},{"comment_id":"16379","content":"with Cloud Shell it will be external connection to VM which is blocked on VM","timestamp":"1587454920.0","poster":"MeasService","upvote_count":"2"},{"timestamp":"1587308160.0","comment_id":"16078","upvote_count":"2","content":"\"The operations team needs to remotely manage the VMs, build and push Docker containers, and manage Google Cloud Storage objects\"\nTo manage VMs one need to have SSH access, so I would go wtih B.","poster":"MeasService"}],"answers_community":["A (93%)","7%"],"choices":{"A":"Grant the operations engineer access to use Google Cloud Shell.","D":"Have the development team build an API service that allows the operations team to execute specific remote procedure calls to accomplish their tasks.","C":"Develop a new access request process that grants temporary SSH access to cloud VMs when an operations engineer needs to perform a task.","B":"Configure a VPN connection to GCP to allow SSH access to the cloud VMs."},"answer_description":"","unix_timestamp":1571204820,"timestamp":"2019-10-16 07:47:00","exam_id":4,"question_id":207,"answer_ET":"A","question_text":"The Dress4Win security team has disabled external SSH access into production virtual machines (VMs) on Google Cloud Platform (GCP).\nThe operations team needs to remotely manage the VMs, build and push Docker containers, and manage Google Cloud Storage objects.\nWhat can they do?","answer":"A","url":"https://www.examtopics.com/discussions/google/view/6660-exam-professional-cloud-architect-topic-11-question-1/","answer_images":[],"question_images":[],"topic":"11","isMC":true},{"id":"ABSktX8d105yvQqh7NiQ","question_text":"You want to ensure Dress4Win's sales and tax records remain available for infrequent viewing by auditors for at least 10 years.\nCost optimization is your top priority.\nWhich cloud services should you choose?","timestamp":"2019-11-27 04:50:00","choices":{"C":"Google Bigtabte with US or EU as location to store the data, and gcloud to access the data.","D":"BigQuery to store the data, and a web server cluster in a managed instance group to access the data. Google Cloud SQL mirrored across two distinct regions to store the data, and a Redis cluster in a managed instance group to access the data.","B":"Google Cloud Storage Nearline to store the data, and gsutil to access the data.","A":"Google Cloud Storage Coldline to store the data, and gsutil to access the data."},"topic":"11","question_images":[],"exam_id":4,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/9199-exam-professional-cloud-architect-topic-11-question-10/","answer_ET":"A","question_id":208,"answers_community":["A (80%)","B (20%)"],"discussion":[{"timestamp":"1622206080.0","upvote_count":"32","poster":"chiar","content":"I think it's A, because when you read documentation both of them (nearline and coldline) you can see the expresion infrecuent access. And in this case, your priority is the cost, and you are going to sabe 10 years","comment_id":"25030"},{"timestamp":"1625240400.0","upvote_count":"10","poster":"MyPractice","content":"its A - \"Cold data storage - Infrequently accessed data, such as data stored for legal or regulatory reasons, can be stored at low cost as Coldline Storage and be available when you need it\"\nhttps://cloud.google.com/storage/docs/storage-classes","comment_id":"34624"},{"comment_id":"804222","poster":"RVivek","upvote_count":"1","content":"Selected Answer: B\nColdline Data retrival takes hours \nIf the data is infrequently accessed then Nearline is better.","comments":[{"timestamp":"1723499880.0","content":"I change it to A. Just noticed the phrase \" Cost optimization is top priority\" in question","comment_id":"806926","upvote_count":"1","poster":"RVivek"}],"timestamp":"1723279140.0"},{"poster":"NodummyIQ","comment_id":"763844","content":"Option A is not a correct answer because Google Cloud Storage Coldline is not suitable for infrequent access to data. Coldline storage is optimized for archival storage with a 90-day minimum storage duration and a retrieval period measured in hours. It is not suitable for data that needs to be accessed frequently or within a short period of time.\n\nOption B is a better choice for infrequent access to data. Google Cloud Storage Nearline is optimized for infrequent access with a 30-day minimum storage duration and a retrieval period measured in seconds. It is more suitable for data that needs to be accessed infrequently or within a short period of time, such as data that needs to be accessed by auditors.","upvote_count":"2","timestamp":"1719930240.0"},{"upvote_count":"2","comment_id":"667644","poster":"alexandercamachop","timestamp":"1710310440.0","content":"Selected Answer: A\nCost + 10 years, should be Archival, but since is not here. Lets go with ColdLine."},{"content":"Answer: A","upvote_count":"1","comment_id":"641453","poster":"gcpAMa","timestamp":"1706914080.0"},{"comment_id":"488147","upvote_count":"2","poster":"joe2211","content":"Selected Answer: A\nvote A","timestamp":"1685185620.0"},{"upvote_count":"1","poster":"victory108","content":"A. Google Cloud Storage Coldline to store the data, and gsutil to access the data.","comment_id":"407637","timestamp":"1673857080.0"},{"poster":"kopper2019","comment_id":"406712","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","timestamp":"1673760000.0","upvote_count":"2"},{"content":"Answer: A","upvote_count":"1","comment_id":"405436","poster":"mbrueck","timestamp":"1673622900.0"},{"comment_id":"401722","content":"Answer is A","timestamp":"1673175900.0","upvote_count":"3","poster":"MamthaSJ"},{"comment_id":"325889","timestamp":"1664631720.0","upvote_count":"1","poster":"Ausias18","content":"Answer is A"},{"timestamp":"1664459580.0","upvote_count":"1","poster":"lynx256","content":"A is ok","comment_id":"323520"},{"comment_id":"320383","upvote_count":"1","content":"A - Coldline is cheapest one","poster":"gu9singg","timestamp":"1664117580.0"},{"timestamp":"1661537580.0","content":"Today the answer would be Archive Storage instead of coldline, so keep in mind the options on the test may be updated.","comment_id":"299945","upvote_count":"4","poster":"Joyrex"},{"comment_id":"197265","upvote_count":"1","content":"A is the answer... The catch here is that 10 years archives to store thus coldline storage is the right pick.","timestamp":"1649588460.0","poster":"LoganIsh"},{"comment_id":"118427","poster":"mlantonis","content":"I hate when we have to guess what infrequent actually means. I believe because \"Cost optimization is your top priority\" we should choose Coldline.\n\nA provides a more cost-effective solution.","comments":[{"upvote_count":"1","poster":"definepi314","comment_id":"122845","content":"Infrequent means not frequently, that is \"less\". You don't have to guess.","timestamp":"1640795220.0","comments":[{"content":"\"Infrequent\" is unclear same as \"not frequently\" :)\nI think @mlantonis wants to say \"I'd like more precision: twice a year, once a year or so on\"","comment_id":"323518","upvote_count":"2","poster":"lynx256","timestamp":"1664459520.0"}]}],"timestamp":"1640357520.0","upvote_count":"1"},{"content":"A is the correct answer","poster":"Ziegler","timestamp":"1638829860.0","upvote_count":"3","comment_id":"104093"},{"upvote_count":"4","poster":"AD2AD4","timestamp":"1638156600.0","content":"Final Decision to go with Option A","comment_id":"97952"},{"timestamp":"1637844480.0","upvote_count":"2","content":"A is the correct answer\nhttps://cloud.google.com/storage/docs/storage-classes#coldline","poster":"Ziegler","comment_id":"95350"},{"timestamp":"1630021020.0","upvote_count":"2","content":"https://cloud.google.com/storage/docs/storage-classes#available_storage_classes","poster":"Smart","comment_id":"55773"},{"timestamp":"1626177300.0","upvote_count":"6","comment_id":"38497","content":"It a straight forward question... cost is the concern and they are fine with infrequent access... So A","poster":"AWS56"},{"timestamp":"1622080200.0","upvote_count":"2","poster":"shandy","content":"Answer is B","comment_id":"24745","comments":[{"content":"Coldline Storage is the Ideal Storage class for Infrequently accessed data like the one mentioned. So A should be the answer\nhttps://cloud.google.com/storage/docs/storage-classes#coldline","upvote_count":"5","poster":"OnomeOkuma","timestamp":"1643222460.0","comment_id":"144256","comments":[{"timestamp":"1644630480.0","comment_id":"155941","poster":"tartar","content":"A is ok","upvote_count":"6"}]},{"poster":"nitinz","timestamp":"1662345600.0","upvote_count":"2","content":"ans is A","comment_id":"303942"}]}],"answer_images":[],"unix_timestamp":1574826600,"answer":"A","isMC":true},{"id":"Rfnw106wR48Enyev0XpZ","answer_images":[],"isMC":true,"question_images":[],"question_text":"The current Dress4Win system architecture has high latency to some customers because it is located in one data center.\nAs of a future evaluation and optimizing for performance in the cloud, Dresss4Win wants to distribute its system architecture to multiple locations when Google cloud platform.\nWhich approach should they use?","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/6802-exam-professional-cloud-architect-topic-11-question-11/","discussion":[{"upvote_count":"30","comments":[{"content":"I thought A is talking about MIG , but if your read the question carefully you will see MIG's , which changed my answer from D to A","timestamp":"1669808580.0","poster":"kimharsh","comment_id":"609655","upvote_count":"1"}],"comment_id":"16865","timestamp":"1587621120.0","content":"Agree. A looks correct for me.","poster":"KouShikyou"},{"timestamp":"1587312660.0","content":"I am not convinced with D. A sounds correct answer. Creating regional MIGs and connecting it to GLB. Anyone ?","comment_id":"16095","upvote_count":"19","comments":[{"content":"A is correct","comment_id":"303945","poster":"nitinz","upvote_count":"3","timestamp":"1630809720.0"},{"content":"A is ok","upvote_count":"5","poster":"tartar","comment_id":"155943","timestamp":"1613094780.0"}],"poster":"MeasService"},{"poster":"thewalker","comment_id":"1067024","content":"A.\nCreating MIGs across regions behind a GLB, gives HA across Zones and Regions.","timestamp":"1715319300.0","upvote_count":"1"},{"timestamp":"1688308200.0","content":"Answer D is correct. Answer A is not correct because it does not mention the aspect of distributing the system architecture to multiple locations. A regional managed instance group can increase performance by allowing the group to grow instances in each region separately based on traffic, but it does not address the issue of distributing the system architecture to multiple locations.","comment_id":"763850","upvote_count":"2","poster":"NodummyIQ"},{"content":"Selected Answer: A\nvote A","poster":"joe2211","timestamp":"1653649860.0","comment_id":"488151","upvote_count":"3"},{"poster":"Ari_GCP","timestamp":"1648147260.0","content":"Agree with A. It says optimize for performance, and multiple regional MIG's can definitely help you do that.","comment_id":"450992","upvote_count":"1"},{"upvote_count":"1","poster":"PeppaPig","timestamp":"1645129440.0","comments":[{"content":"Exactly. D states about implementing GLB in a set of VMs rather than using a managed service of GLBs","timestamp":"1719651000.0","poster":"parthkulkarni998","upvote_count":"1","comment_id":"1108606"}],"content":"A is correct for sure\nD is wrong. GLB is already capable of forwarding traffic to MIG in the closer region so why would you implement that again","comment_id":"426477"},{"poster":"kopper2019","timestamp":"1642516800.0","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","comment_id":"408949","upvote_count":"1"},{"poster":"victory108","comment_id":"408318","content":"A. Use regional managed instance groups and a global load balancer to increase performance because the regional managed instance group can grow instances in each region separately based on traffic.","upvote_count":"2","timestamp":"1642413360.0"},{"upvote_count":"2","poster":"MamthaSJ","comment_id":"401724","timestamp":"1641640020.0","content":"Answer is A"},{"content":"It’s A. Each region can have an instance group linked to a global load balancer. Instance groups do not need to be multi regional for this to work.","comment_id":"342111","upvote_count":"1","poster":"Pb55","timestamp":"1635092880.0"},{"comment_id":"332344","content":"A is not good, because a regional MIG, which deploys instances to multiple zones across the same region. This will not deploy instances in multi regions.\nD is good","upvote_count":"2","poster":"tzKhalil","comments":[{"upvote_count":"2","timestamp":"1641898380.0","content":"your statement is right. But A was MIGs.","comment_id":"403796","poster":"taoj"},{"content":"Doc: https://cloud.google.com/compute/docs/instance-groups#types_of_managed_instance_groups","poster":"tzKhalil","upvote_count":"1","timestamp":"1633846980.0","comment_id":"332346"}],"timestamp":"1633846800.0"},{"content":"D is the correct answer.\nWith A it says \"because the regional managed instance group can grow instances in each region separately based on traffic.\" A regional instance group cannot grow instances in Multiple Regions, only in one. \nWith D, you have multiple separate Regional Instance Groups, which is what is missing in answer A.","timestamp":"1633175460.0","poster":"jaguarrr","comment_id":"326569","upvote_count":"3"},{"comment_id":"325892","poster":"Ausias18","content":"Answer is A","upvote_count":"1","timestamp":"1633095780.0"},{"content":"IMO - A.\nWe are gointg to use a few MIGs - one per region; each of them can scale independetly from others.","comment_id":"323558","poster":"lynx256","upvote_count":"1","timestamp":"1632926640.0"},{"timestamp":"1632581760.0","comment_id":"320387","content":"A- because with Regional resources and global load balancer we can route traffic to nearest VM machine","upvote_count":"1","poster":"gu9singg"},{"comment_id":"283087","timestamp":"1628038140.0","content":"https://cloud.google.com/load-balancing/docs/https/setting-up-https\nSeems D is correct","comments":[{"poster":"bnlcnd","timestamp":"1628038500.0","upvote_count":"1","comment_id":"283090","content":"\"closer\" group of virtual machines as part of a separate managed instance groups.\nThe key word closer in the answer D means routing the client request to a closer regional MIG. Anything wrong?\nA seems not mentioning routing request to the MIG that is closer to the client."}],"poster":"bnlcnd","upvote_count":"2"},{"timestamp":"1623947400.0","upvote_count":"1","content":"A is the correct answer","comment_id":"246745","poster":"okixavi"},{"poster":"gcparchitect007","comment_id":"209758","timestamp":"1619757180.0","upvote_count":"1","content":"A is the right answer,"},{"poster":"Gudwin","content":"How would you set up \"a group of VMs forwarding requests to the closer VMs\", enlighten me? Has anything in this course so far taught you that doing something like this is the correct way?","comment_id":"204175","timestamp":"1619091480.0","upvote_count":"3"},{"poster":"awadheshk","comment_id":"199007","upvote_count":"1","content":"Regional MIGs created instance in zones in that region - \"Regional MIGs provide higher availability compared to zonal MIGs because a regional MIG's managed instances are evenly spread across multiple zones in a single region. \" -- https://cloud.google.com/compute/docs/instance-groups/distributing-instances-with-regional-instance-groups \nSo option A and C ruled out .. B talks about operation team managed .. So only correct left is D","timestamp":"1618295880.0"},{"comment_id":"186197","poster":"roastc","content":"Answer id D https://cloud.google.com/load-balancing/docs/https/setting-up-https","upvote_count":"1","timestamp":"1616600520.0"},{"upvote_count":"1","timestamp":"1616419440.0","comment_id":"184357","content":"A is correct https://cloud.google.com/compute/docs/instance-groups/distributing-instances-with-regional-instance-groups","poster":"jbrunet"},{"timestamp":"1614537300.0","upvote_count":"2","comment_id":"169401","content":"A is correct","poster":"Kabiliravi"},{"poster":"wiqi","timestamp":"1614364140.0","upvote_count":"1","comment_id":"166908","content":"A is better choice here."},{"content":"the moment you have one server forward traffic to another server would you add more latency.","comment_id":"163840","upvote_count":"1","timestamp":"1614027600.0","poster":"droidmasta"},{"comment_id":"158029","poster":"mbiy","content":"I also Agree with Option A. \nOption D sounds like there is a 2 hop, global load balancer redirect request to set of VM which further forwards to another VMs that are part of managed group.","timestamp":"1613307300.0","upvote_count":"1"},{"content":"D is correct, as A only talks about availability and not latency.","comment_id":"150045","upvote_count":"2","poster":"ksurp","timestamp":"1612401660.0"},{"comment_id":"118432","upvote_count":"2","content":"We need Global LB with MIG, so the choice is between A and C.\n\nI believe A sounds better.","timestamp":"1608821940.0","poster":"mlantonis"},{"poster":"motty","content":"B - is wrong.\n\nD sounds like anti-pattern. \nthe moment you have \"dedicated VMs\" forwarding traffic you take away\nall MIG specific benefits such as traffic based on metrics, health etc.\n\nA states \"the regional managed instance group can grow instances in each region separately based on traffic.\". \nHmm, regional MIG is managing traffic between number of zones in the same region, but it does not manages\ntraffic acrosss regions... Even though it is mentioning traffic the desciption of funcionality is wrong.\n\nC seems to be correct, even though it states failover but not mention of traffic. I think it is possible\nto have custom metric that takes into account traffic and achieve the required objective.","upvote_count":"2","comment_id":"117702","timestamp":"1608752160.0"},{"content":"A, for sure.\nfor optimizing for performance","comment_id":"109526","timestamp":"1607877480.0","poster":"gfhbox0083","upvote_count":"2"},{"poster":"Ziegler","content":"Agree with A as the right answer.","timestamp":"1606948260.0","upvote_count":"3","comment_id":"101167"},{"comment_id":"97953","content":"Final Decision to go with Option A","poster":"AD2AD4","timestamp":"1606620720.0","upvote_count":"5"},{"content":"A is correct","poster":"shiwenupper","timestamp":"1606573260.0","upvote_count":"2","comment_id":"97529"},{"timestamp":"1605846900.0","content":"high latency\nSo I thingk that is D","poster":"Kimi37LP","comment_id":"92501","upvote_count":"1"},{"comment_id":"87327","timestamp":"1605137520.0","poster":"asure","content":"Global loadbalancer is right, selection of set of virtual machines is wrong, the answerd is between A and C","upvote_count":"2"},{"content":"A is correct..Regional MIG with Global Load Balancer enables better performance (low latency which is the ask of the problem)","poster":"PRC","upvote_count":"4","comment_id":"76276","timestamp":"1603086240.0"},{"comment_id":"70609","upvote_count":"5","poster":"anton_royce","timestamp":"1601695500.0","content":"I go for A,"},{"content":"A\nLike zonal managed instance groups, regional managed instance groups support autoscaling, internal load balancing, and external load balancing.","poster":"SMS","timestamp":"1600707120.0","comment_id":"66643","upvote_count":"4"},{"comment_id":"50650","timestamp":"1597428360.0","poster":"ADVIT","upvote_count":"5","content":"I go for A"},{"comment_id":"30812","timestamp":"1592518440.0","poster":"passnow","upvote_count":"6","content":"the correct answer is A"},{"poster":"JoeShmoe","content":"Answer is A","comment_id":"21740","upvote_count":"15","timestamp":"1589530860.0"},{"comments":[{"timestamp":"1628310720.0","content":"I agree.\n\"\" A regional MIG distributes your virtual machine (VM) instances across multiple zones in a region \"\"","poster":"bunnypikachu","comment_id":"285342","upvote_count":"2"},{"poster":"shashu07","timestamp":"1608191040.0","comment_id":"112187","upvote_count":"2","content":"Scalability in MIG . When your apps require additional compute resources, autoscaled MIGs can automatically grow the number of instances in the group to meet demand. If demand drops, autoscaled MIGs can automatically shrink to reduce your costs."},{"comment_id":"24747","upvote_count":"8","timestamp":"1590544680.0","content":"A is right. You just mentioned only High Availability part. There is a scalability part of MIG which allows to grow to meet demand.","poster":"shandy"}],"content":"A is not correct, because the regional managed instance group can NOT grow instances in each region separately based on traffic, but let you spread app load across multiple zones. \nhttps://cloud.google.com/compute/docs/instance-groups/","upvote_count":"5","poster":"bigob4ek","comment_id":"20940","timestamp":"1589280060.0"},{"upvote_count":"1","comments":[{"content":"What is it we are trying to solve? -> Latency to customers and optimizing for performance\nGlobal Load Balancer helps with network latency (proximity)\nMIG helps latency issues and performance optimization by increasing capacity based on demand. We know that it also helps for redundancy but this is not asked.\n\nSo I would go with A","comment_id":"130466","poster":"cetanx","timestamp":"1610193120.0","upvote_count":"3"}],"poster":"jcmoranp","timestamp":"1587903480.0","content":"C is true, could it be C?","comment_id":"17589"}],"timestamp":"2019-10-19 18:11:00","answer":"A","answers_community":["A (100%)"],"choices":{"D":"Use a global load balancer with a set of virtual machines that forward the requests to a closer group of virtual machines as part of a separate managed instance groups.","A":"Use regional managed instance groups and a global load balancer to increase performance because the regional managed instance group can grow instances in each region separately based on traffic.","B":"Use a global load balancer with a set of virtual machines that forward the requests to a closer group of virtual machines managed by your operations team.","C":"Use regional managed instance groups and a global load balancer to increase reliability by providing automatic failover between zones in different regions."},"exam_id":4,"topic":"11","question_id":209,"unix_timestamp":1571501460,"answer_ET":"A"},{"id":"vRRiZaGh6w9T07uNPwEU","isMC":true,"unix_timestamp":1582467900,"question_id":210,"question_text":"At Dress4Win, an operations engineer wants to create a tow-cost solution to remotely archive copies of database backup files.\nThe database files are compressed tar files stored in their current data center.\nHow should he proceed?","topic":"11","url":"https://www.examtopics.com/discussions/google/view/14731-exam-professional-cloud-architect-topic-11-question-2/","exam_id":4,"question_images":[],"discussion":[{"poster":"Ayzen","upvote_count":"37","comments":[{"comment_id":"129774","content":"I would go with A\n\nStorage Transfer Service has many valuable features but it comes with some dependencies such as;\n- min 300-Mbps internet connection\n- A docker engine on-prem (app runs inside a container)\nhttps://cloud.google.com/storage-transfer/docs/on-prem-overview#what_requirements_does_have\n... and these may not be available at Dress4Win (we have no data if D4W satisfies these requirements)\n\nBased on the recommendations here: https://cloud.google.com/storage-transfer/docs/overview#gsutil\n[# gsutil rsync] command seems to be a better option in a cron job with regular intervals as it will be much easier to implement compared to setting up Storage Transfer Service.","upvote_count":"8","timestamp":"1625749620.0","comments":[{"content":"We[re talking about potentially 100s of TBs of data based on the case study (at least 65TBs as that's how much they are using in their NAS storage for backups/logs). I certainly hope they have the minimum 300-Mbps connection and a computer in their data center that they can install docker on....","poster":"Jphix","comment_id":"262275","timestamp":"1641610740.0","upvote_count":"5"}],"poster":"cetanx"},{"poster":"[Removed]","upvote_count":"2","content":"https://cloud.google.com/storage-transfer/docs/transfer-options","timestamp":"1726154880.0","comment_id":"1005886"}],"timestamp":"1619589720.0","content":"Should be C: https://cloud.google.com/storage-transfer/docs/on-prem-overview\nEspecially, when Google docs explicitly states, that custom scripts are unreliable, slow, insecure, difficult to maintain and troubleshoot.","comment_id":"80631"},{"content":"Answer should be C. As per the latest case study on google cloud website , they have DB storage of 1 PB out of which 600 TB is used. So you get the size of the data.\nThese are the thumb rules as per GCP documentation - \n\nTransfer scenario Recommendation\n\nTransferring from another cloud storage provider Use Storage Transfer Service\nTransferring less than 1 TB from on-premises Use gsutil\nTransferring more than 1 TB from on-premises Use Transfer service for on-premises data\n\nhttps://cloud.google.com/storage-transfer/docs/overview","poster":"SamirJ","comment_id":"199664","upvote_count":"21","comments":[{"comment_id":"208296","content":"I agree with Samir, when there is nothing mentioned about data size, refer the case study again. Storage appliance section mentioned total size and available size. Which means we should be using storage transfer service. I will go with option C.","poster":"AdityaGupta","upvote_count":"2","timestamp":"1635481320.0"}],"timestamp":"1634203620.0"},{"poster":"massacare","upvote_count":"2","timestamp":"1723369320.0","content":"Selected Answer: C\nAlthough Dress4Win already removed from PCA case studies list, the answer should be C.","comment_id":"978486"},{"timestamp":"1698827640.0","upvote_count":"9","comment_id":"708964","poster":"jabrrJ68w02ond1","content":"IMPORTANT: Dress4Win is not anymore part of the officially listed case studies: https://cloud.google.com/certification/guides/professional-cloud-architect"},{"timestamp":"1694577420.0","content":"Selected Answer: C\nAnswer is C.","comment_id":"667633","poster":"alexandercamachop","upvote_count":"1"},{"content":"Selected Answer: C\nC is the correct answer","poster":"ramzez4815","upvote_count":"2","timestamp":"1692758280.0","comment_id":"650532"},{"content":"I'd go with C, transfer service. gsutil is best used for transfer within GCS","poster":"Aiffone","comment_id":"523165","upvote_count":"1","timestamp":"1673649180.0"},{"timestamp":"1673598420.0","poster":"burner_1984","comment_id":"522716","content":"Storage Transfer Service is to be used when data is available online, not in physical datacenter","upvote_count":"1"},{"upvote_count":"4","timestamp":"1673263080.0","poster":"GCPCloudArchitectUser","comment_id":"520148","content":"Dress4Win case is not listed as exam case study \nhttps://cloud.google.com/certification/guides/professional-cloud-architect"},{"comment_id":"492375","comments":[{"comment_id":"520147","content":"This question is for Dress4Win case study and you are referring different one","upvote_count":"1","timestamp":"1673263020.0","poster":"GCPCloudArchitectUser"}],"upvote_count":"1","timestamp":"1669977900.0","content":"Here are the guidelines from Google: \nFrom Azure/AWS Transfer: Storage Transfer Service \nBetween two different bucket: Storage Transfer service \nFor less than 1 TB From Private datacenter to Google: gsutil \nFor more than 1 TB with enough bandwidth for Private datacenter to Google - Use Storage Transfer Service for on-premises data \nNot enough bandwidth to meet project deadline for private data center to Google for more than 1 TB - Transfer Appliance. (Transfer Appliance is recommended for data that exceeds 20 TB or would take more than a week to upload)\nI assume the DB size will be more than 1 TB. (2 million TerramEarth vehicles each generate generates 200 to 500 megabytes of data per day)\nSince it is more than 1 TB, based on google guidelines, I will go with Storage Transfer Service Answer C \nhttps://cloud.google.com/storage-transfer/docs/overview\nhttps://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets\nCase: https://services.google.com/fh/files/blogs/master_case_study_terramearth.pdf","poster":"ravisar"},{"upvote_count":"1","content":"Selected Answer: C\nvote C","poster":"joe2211","comment_id":"487991","timestamp":"1669538280.0"},{"content":"IMO option A is correct.\nAccording to the technical requirement;\n- Support multiple VPN connections between the production data center and cloud \nenvironment.\nCloud VPN tunnel can support up to 3 gigabits per second (Gbps).\nThere is no deadline for this usecase, And also by considering the industry I can say the database size wouldn’t be bigger than 1TB; hence gsutil is suitable for this case.","comment_id":"448739","timestamp":"1663746300.0","upvote_count":"1","poster":"Amirso"},{"timestamp":"1657951260.0","content":"C. Create a Cloud Storage Transfer Service Job to copy the files to a Coldline Storage bucket.","upvote_count":"2","poster":"victory108","comment_id":"407626"},{"comment_id":"401157","timestamp":"1657216080.0","upvote_count":"2","poster":"MamthaSJ","content":"Answer is C"},{"content":"Follow these rules of thumb when deciding whether to use gsutil or Storage Transfer Service:\n\nTransfer scenario Recommendation\nTransferring from another cloud storage provider Use Storage Transfer Service.\nTransferring less than 1 TB from on-premises Use gsutil.\nTransferring more than 1 TB from on-premises Use Transfer service for on-premises data.\nTransferring less than 1 TB from another Cloud Storage region Use gsutil.\nTransferring more than 1 TB from another Cloud Storage region Use Storage Transfer Service.\nhttps://cloud.google.com/storage-transfer/docs/overview","comment_id":"342085","poster":"Pb55","timestamp":"1650813540.0","upvote_count":"1"},{"poster":"jasim21","comment_id":"341107","upvote_count":"2","content":"Answer is C\nCurrent DB disk size is 5 TB & backup size is 600 TB.\nIf size is more than 1 TB google recommend transfer service. regardless from other cloud/on-premise\nhttps://cloud.google.com/storage-transfer/docs/overview#gsutil","timestamp":"1650635820.0"},{"poster":"mrhege","content":"\"Fibre channel SAN - MySQL databases\n- 1 PB total storage; 400 TB available\"\nDefinitely a use-case for Storage Transfer Service. (C)","comment_id":"331557","timestamp":"1649452140.0","upvote_count":"1"},{"upvote_count":"2","poster":"azeqsd","content":"https://cloud.google.com/storage-transfer-service\nUSE CASE\nDatabase recovery, backup, and archival\nWith our data transfer services, you can schedule incremental syncs to enable disaster recovery for apps running in other clouds and on-premises, to meet your recovery goals. Learn about all of our backup and disaster recovery options, or read about how to use Cloud Storage for archiving your data.\n\nI'll go with C","comment_id":"326016","comments":[{"upvote_count":"1","comment_id":"331230","poster":"hyordanov","timestamp":"1649425200.0","content":"but is not lowcost"}],"timestamp":"1648832160.0"},{"timestamp":"1648051260.0","content":"I also think A is the best... but do we know how much data will be tranferred ?\nIf more than 1 TB, C prevails...","upvote_count":"1","poster":"lynx256","comment_id":"318223"},{"content":"should be C.\nTechnical requirement says \"Use managed services whenever possible.\"\ngsutil command for small size file. Here they have many backup files which they want to transfer on cloud. And its not repetitive work as per problem statement. So no need of any cron job. Best suitable answer is C.","upvote_count":"3","poster":"bahadur","comment_id":"314516","timestamp":"1647655320.0"},{"content":"creating corn script is manual process and should be avoid as there is better choices. As per google custom script can be unreliable ,slow ,insecure ,difficult to maintain .\n\nSo ans is C","timestamp":"1645029420.0","poster":"CloudGenious","comment_id":"291928","upvote_count":"1"},{"comment_id":"285806","upvote_count":"2","content":"Its A. * When transferring data from another cloud storage provider, use Storage Transfer Service, BUT use Cron from On Prem.","timestamp":"1644268740.0","poster":"Rightsaidfred"},{"content":"ANS:A\nTransfer Service or gsutil?\nThere are no extra costs to using the Transfer Service; billing is the same as with gsutil or the web console. Google's docs recommend that we prefer gustil if we are copying files over from on-premise. If we are ingesting data from AWS or Azure, or from an external HTTP location, then transfer service is preferable.","poster":"ahmedemad3","comment_id":"278403","upvote_count":"1","timestamp":"1643361600.0"},{"timestamp":"1641198780.0","poster":"Prakzz","content":"Storage Transfer service can only be used for gcsp bucket aws buket and http/https location as source. On Premise data cannot be transferred by Storage Transfer service","comment_id":"258325","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"309469","content":"Transferring more than 1 TB from on-premises Use Transfer service for on-premises data\n\nhttps://cloud.google.com/storage-transfer/docs/overview","timestamp":"1647152400.0","poster":"Jane111"}]},{"poster":"okixavi","comment_id":"246690","content":"Answer is C, this is exactly what Local data transfer service is for","timestamp":"1639760640.0","upvote_count":"1"},{"comment_id":"218515","content":"C is Correct Answer: \n\nStorage Transfer Service lets you Move or backup data to a Cloud Storage bucket either from other cloud storage providers or from your on-premises storage. Storage Transfer Service provides options that make data transfers and synchronization easier. For example, you can: Schedule one-time transfer operations or recurring transfer operations, etc.\n\nRef: https://cloud.google.com/storage-transfer/docs/overview\n\nIf you are transferring more than 1TB from on-premises, Google recommends you use the transfer service.\n\nhttps://cloud.google.com/storage-transfer/docs/overview#gsutil\n\nFrom the storage appliance section, we see that 400 TB is available out of 1 PB of total storage. So does that means the database is 600 TB? You also have NAS, which is used for image storage, logs, and backups; about 65TB is in use. Although the Dress4Win scenario doesn't precisely specify how big the backups are, based on the database size and NAS usage stats, it is reasonable to assume the backups are well over 1TB so this calls for Storage transfer service.","poster":"hems4all","upvote_count":"6","timestamp":"1636812600.0"},{"timestamp":"1633774080.0","upvote_count":"1","comment_id":"196645","content":"A is correct.","poster":"LalBisota"},{"poster":"VedaSW","upvote_count":"3","timestamp":"1632720720.0","comment_id":"188132","content":"Anyone know what is \"tow-cost solution\"? tow, not low.","comments":[{"poster":"kimberjdaw","content":"It's low","upvote_count":"3","comment_id":"198635","timestamp":"1634061120.0"}]},{"poster":"kmanexamtop","upvote_count":"2","content":"I will choose A. Reason: Dress4win is planning to setup multiple VPN connections. So, the bandwidth available will be lower. For lower bandwidth, gustily is better option than Storage Transfer service.","comment_id":"187524","timestamp":"1632643620.0"},{"timestamp":"1632199920.0","comment_id":"183441","content":"C Storage transfer service does not cause any additional cost comparing with gsutil. \nhttps://cloud.google.com/storage-transfer/pricing","poster":"passtest100","upvote_count":"3","comments":[{"timestamp":"1636084080.0","comment_id":"213177","upvote_count":"1","poster":"[Removed]","content":"This is correct. if no additional charge for Transfer service then it should be used as per the thumb rules."}]},{"timestamp":"1632103740.0","poster":"brati_sankar","content":"I think low cost is the key here .. Transfer service for on prem is neither cheap nor simple to set up","upvote_count":"1","comment_id":"182600"},{"comment_id":"151955","timestamp":"1628253960.0","content":"Agree with A as data need to be transferred from on-prem.","poster":"babacandy","upvote_count":"1"},{"timestamp":"1624533180.0","content":"All we know is that the customer needs a low cost solution, so definitely we will choose Coldline. In order to choose between gsutil and Storage Transfer Service we need to have more information about the amount of data. The question is not clear, but if we want to go with the most cost effetctive solution then gsutil.\n\nA can be the correct answer.","poster":"mlantonis","comments":[{"timestamp":"1624533360.0","upvote_count":"2","content":"Also check\nhttps://cloud.google.com/storage-transfer/docs/overview","comment_id":"118348","poster":"mlantonis"}],"upvote_count":"2","comment_id":"118346"},{"poster":"hbansal077","upvote_count":"2","content":"A for sure.","comment_id":"110786","timestamp":"1623758940.0"},{"content":"A, for sure","poster":"gfhbox0083","upvote_count":"3","comment_id":"107478","timestamp":"1623393240.0"},{"timestamp":"1623009960.0","content":"A is the correct answer","upvote_count":"4","poster":"Ziegler","comment_id":"104077"},{"comment_id":"102957","poster":"bubai01","timestamp":"1622875140.0","upvote_count":"8","content":"Option A\nBoth Gsutil and Storage Transfer service can be used to transfer On-Prem data but we need to consider the below points\n1. Gsutil is free , ideal for transfer upto 1 TB and less complex solution and transfer jobs can be achieved through Cron\n2. Storage Transfer Service is ideal for more than 1 TB , lot of files needs to be transferred but it has changes for data and services used for this setup like pub/sub and others.\nSo if we need the requirement LOW-COST and simple Solution would be Gsutil unlesswe have more information on the complexity and size of the data"},{"content":"Final Decision to go with Option A","poster":"AD2AD4","comment_id":"97929","timestamp":"1622250180.0","upvote_count":"2"},{"poster":"clouddude","comment_id":"87337","content":"Going with A. Storage Transfer Service can be used with GCP or AWS source buckets or any source that has an https endpoint which rules out C/D.","timestamp":"1620770280.0","upvote_count":"3"},{"comment_id":"84908","content":"Transfer service could be the right solution as well, but the customer wants a low cost solution. Depending on the transfer size, the cost could get higher. Such questions aren't exactly answerable without a bit more context about data size and what is low-cost..Is $1000 low cost or $10?...If I had to select an answer, I'd select A but glad that in real life one has more context...","poster":"hybridpro","upvote_count":"2","timestamp":"1620376740.0"},{"comment_id":"83903","poster":"RupaliS","timestamp":"1620181800.0","content":"As per the GCP Documentation, Storage Transfer Service has the use case to move / schedule backup/archival data movement to cloud. It can be the best candidate to copy online data from On-prem or other cloud. \nHence should be C\nhttps://cloud.google.com/storage-transfer-service","upvote_count":"4"},{"content":"Agree with A","timestamp":"1614090300.0","poster":"ROPATE","comments":[{"comments":[{"poster":"nitinz","upvote_count":"1","content":"also there DB has everything: - MySQL - user data, inventory, static data. Its going to be huge dataset. Cloud transfer way to go not gsutil. gsutil is to copy small files here and there....","comment_id":"303923","timestamp":"1646453520.0"}],"comment_id":"303921","content":"No its C, Google wants you to use their product not your in-house developed Scripts.","poster":"nitinz","upvote_count":"1","timestamp":"1646453400.0"},{"content":"A is ok","timestamp":"1628723160.0","upvote_count":"4","poster":"tartar","comment_id":"155922"}],"comment_id":"54140","upvote_count":"7"}],"answer_description":"","timestamp":"2020-02-23 15:25:00","answers_community":["C (100%)"],"answer_ET":"C","answer_images":[],"answer":"C","choices":{"D":"Create a Cloud Storage Transfer Service job to copy the files to a Regional Storage bucket.","B":"Create a cron script using gsutil to copy the files to a Regional Storage bucket.","A":"Create a cron script using gsutil to copy the files to a Coldline Storage bucket.","C":"Create a Cloud Storage Transfer Service Job to copy the files to a Coldline Storage bucket."}}],"exam":{"isImplemented":true,"isMCOnly":false,"numberOfQuestions":279,"provider":"Google","name":"Professional Cloud Architect","id":4,"lastUpdated":"11 Apr 2025","isBeta":false},"currentPage":42},"__N_SSP":true}