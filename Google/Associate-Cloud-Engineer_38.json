{"pageProps":{"questions":[{"id":"hqERXMY6zuPJ6HGoJyu8","choices":{"D":"Use Cloud Data Fusion for the video files, Dataflow for the data warehouse data, and Storage Transfer Service for the PNG files.","A":"Use gcloud storage for the video files, Dataflow for the data warehouse data, and Storage Transfer Service for the PNG files.","C":"Use Storage Transfer Service for the video files, BigQuery Data Transfer Service for the data warehouse data, and Storage Transfer Service for the PNG files.","B":"Use Transfer Appliance for the videos, BigQuery Data Transfer Service for the data warehouse data, and Storage Transfer Service for the PNG files."},"exam_id":1,"answer":"B","unix_timestamp":1703915940,"answer_images":[],"topic":"1","discussion":[{"timestamp":"1704316860.0","poster":"Cynthia2023","upvote_count":"10","content":"Selected Answer: B\n• Transfer Appliance for Video Files: Given the large size of the video files (200 TB) in SAN storage, using Google's Transfer Appliance is a practical solution. Transfer Appliance is a hardware solution provided by Google for transferring large amounts of data. It is well-suited for scenarios where uploading data over the internet is too slow or not feasible.\n\n• BigQuery Data Transfer Service for Data Warehouse Data: To migrate data from Amazon Redshift to BigQuery, the BigQuery Data Transfer Service is the appropriate tool. It automates the migration of data from several sources, including Amazon Redshift, into BigQuery.\n\n• Storage Transfer Service for PNG Files: The Storage Transfer Service is ideal for moving data from Amazon S3 to Google Cloud Storage. It simplifies the process of importing your PNG files from S3 to a Cloud Storage bucket.","comment_id":"1113139"},{"comment_id":"1295943","poster":"denno22","content":"Selected Answer: B\nWe need the Transfer Appliance for the video.","timestamp":"1728641100.0","upvote_count":"1"},{"poster":"ac3baff","upvote_count":"2","content":"I think the answer is B. The controversy is whether the answer is B or C, i.e. whether one should use the transfer appliance or storage transfer service. From my knowledge, storage transfer service is not applicable for SAN, so the answer should be B.","comment_id":"1227005","timestamp":"1717896660.0"},{"poster":"Stargazer11","timestamp":"1706622060.0","comment_id":"1135838","content":"Selected Answer: B\nIf it is on-prem to cloud, transfer appliance. \n\nStorage transfer service is for transferring data between buckets.","upvote_count":"3","comments":[{"poster":"sanjay1606","upvote_count":"3","content":"Hi bro, I need to talk with you about GCP Associate Cloud Cngineer","comment_id":"1137644","timestamp":"1706794020.0"}]},{"timestamp":"1704293160.0","content":"Selected Answer: C\nC. Explanation:\n- Storage Transfer Service: It provides a straightforward way to transfer large amounts of data from an on-premises data source or cloud storage provider to Cloud Storage without writing code. This service can efficiently handle the migration of video files and PNG files.\n- BigQuery Data Transfer Service: This service allows the transfer of data from various sources, including Amazon Redshift, directly into BigQuery. It simplifies and automates the migration of data warehouse data without coding requirements.","upvote_count":"1","comment_id":"1112862","poster":"apb98","comments":[{"content":"While options A and D involve using Dataflow and Cloud Data Fusion, respectively, these services may require additional configuration, development, or transformation logic, which is contrary to the requirement of avoiding code for migration.\n\nOption B suggests using Transfer Appliance for the videos, which might be applicable for large-scale physical data transfers, but it's not the most suitable option for this scenario involving Cloud migration without coding.","comments":[{"poster":"blackBeard33","content":"But it is said that the data of the videos is on a SAN storage, is it san storage supported by google cloud storage transfer service? I cant see it here on this documentation: https://cloud.google.com/storage-transfer/docs/sources-and-sinks\n\nIt is not public accessible and I dont think it is a file system either. So option B should be the most suitable here. Dont you think ?","comment_id":"1155150","upvote_count":"1","timestamp":"1708480560.0"}],"comment_id":"1112863","timestamp":"1704293160.0","poster":"apb98","upvote_count":"1"}]},{"content":"Selected Answer: B\nC makes sense. Use transfer appliance for vid","poster":"Bagibo","timestamp":"1704267600.0","upvote_count":"1","comment_id":"1112586"},{"comment_id":"1112233","upvote_count":"1","poster":"SrinivasJasti","content":"C makes more sense","timestamp":"1704227820.0"},{"content":"Selected Answer: B\nB. Use Transfer Appliance for the videos, BigQuery Data Transfer Service for the data warehouse data, and Storage Transfer Service for the PNG files: Transfer Appliance is designed for moving large amounts of data (like 200 TB of videos) into Google Cloud Storage. The BigQuery Data Transfer Service automates data movement from several sources, including Amazon Redshift, into BigQuery. Storage Transfer Service is appropriate for moving data from Amazon S3 to Google Cloud Storage.","upvote_count":"1","poster":"kaby1987","comment_id":"1111511","timestamp":"1704153780.0"},{"content":"Selected Answer: C\nChatGPT says the answer is C.","comment_id":"1110709","upvote_count":"2","poster":"KelvinToo","timestamp":"1704041520.0"},{"timestamp":"1703915940.0","content":"B. Use Transfer Appliance for the videos, BigQuery Data Transfer Service for the data warehouse data, and Storage Transfer Service for the PNG files.","poster":"shiowbah","upvote_count":"1","comment_id":"1109462"}],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/129850-exam-associate-cloud-engineer-topic-1-question-266/","timestamp":"2023-12-30 06:59:00","answers_community":["B (84%)","C (16%)"],"answer_ET":"B","question_text":"You are planning to migrate your on-premises data to Google Cloud. The data includes:\n\n• 200 TB of video files in SAN storage\n• Data warehouse data stored on Amazon Redshift\n• 20 GB of PNG files stored on an S3 bucket\n\nYou need to load the video files into a Cloud Storage bucket, transfer the data warehouse data into BigQuery, and load the PNG files into a second Cloud Storage bucket. You want to follow Google-recommended practices and avoid writing any code for the migration. What should you do?","question_images":[],"question_id":186,"answer_description":""},{"id":"ynu2LyLYkUwMfp85LcEg","topic":"1","url":"https://www.examtopics.com/discussions/google/view/144064-exam-associate-cloud-engineer-topic-1-question-267/","unix_timestamp":1721255280,"answer_description":"","answers_community":["A (86%)","14%"],"question_id":187,"answer":"A","exam_id":1,"question_images":[],"timestamp":"2024-07-18 00:28:00","discussion":[{"poster":"iooj","timestamp":"1726249260.0","comment_id":"1283287","content":"Selected Answer: A\nAutopilot mode is designed for those who prefer a hands-off approach. It’s best suited for businesses that want to leverage the power of Kubernetes without diving deep into its intricacies. It offers a simplified, managed experience with Google taking care of the operational overhead.\n\nOn the other hand, Standard mode is for those who want granular control over their Kubernetes environment. It’s ideal for businesses with specific requirements and those who have the expertise to manage and optimize their Kubernetes clusters.","upvote_count":"3"},{"content":"Selected Answer: A\nDespite the managed nature of the infrastructure of a GKE Autopilot Cluster, you still have full control over your Kubernetes workloads, configurations, and deployments. This allows you to use Kubernetes manifests and customize your deployment as needed.","comment_id":"1273594","timestamp":"1724778480.0","upvote_count":"4","poster":"Timfdklfajlksdjlakf"},{"comment_id":"1271916","comments":[],"content":"Selected Answer: C\nC is the answer","timestamp":"1724540880.0","poster":"caminosdk","upvote_count":"1"},{"content":"Selected Answer: C\nKey requirements \"full control\" and \"minimize configuring infrastructure\" - GKE Standard Supports both","comment_id":"1259626","timestamp":"1722563640.0","poster":"jhumpamp","upvote_count":"1"},{"content":"C is the answe","poster":"ashrafh","upvote_count":"1","comment_id":"1255982","timestamp":"1722050760.0"},{"poster":"flummoxed_individual","content":"Selected Answer: A\nMinimise effort. And GKE is a managed k8s service for deploying container-ised apps using k8s","timestamp":"1721810520.0","upvote_count":"3","comment_id":"1254245"},{"timestamp":"1721255280.0","upvote_count":"2","poster":"BuenaCloudDE","comment_id":"1250015","content":"Selected Answer: A\nA- minimize effort"}],"isMC":true,"question_text":"You want to deploy a new containerized application into Google Cloud by using a Kubernetes manifest. You want to have full control over the Kubernetes deployment, and at the same time, you want to minimize configuring infrastructure. What should you do?","choices":{"D":"Deploy the application on Cloud Functions.","A":"Deploy the application on GKE Autopilot.","C":"Deploy the application on GKE Standard.","B":"Deploy the application on Cloud Run."},"answer_images":[],"answer_ET":"A"},{"id":"1wLUS9P0WSitSOc0NC9r","topic":"1","question_images":[],"answer":"D","timestamp":"2024-07-19 09:41:00","exam_id":1,"unix_timestamp":1721374860,"answer_ET":"D","url":"https://www.examtopics.com/discussions/google/view/144167-exam-associate-cloud-engineer-topic-1-question-268/","isMC":true,"choices":{"A":"Save the incoming votes to Firestore. Use Cloud Scheduler to trigger a Cloud Functions instance to periodically process the votes.","B":"Use a dedicated instance to process the incoming votes. Send the votes directly to this instance.","C":"Save the incoming votes to a JSON file on Cloud Storage. Process the votes in a batch at the end of the day.","D":"Save the incoming votes to Pub/Sub. Use the Pub/Sub topic to trigger a Cloud Functions instance to process the votes."},"question_id":188,"answer_description":"","answer_images":[],"question_text":"Your team is building a website that handles votes from a large user population. The incoming votes will arrive at various rates. You want to optimize the storage and processing of the votes. What should you do?","discussion":[{"poster":"BuenaCloudDE","timestamp":"1721374860.0","content":"Selected Answer: D\nPub/Sub: Google Cloud Pub/Sub is a messaging service which directly uses for this purpose.\n\nCloud Functions: By triggering a Cloud Function with a Pub/Sub topic, you can process the votes as they arrive, ensuring low-latency handling and efficient scaling based on demand. This approach provides real-time processing and can handle bursts of traffic effectively.","comment_id":"1250985","upvote_count":"5"},{"timestamp":"1728042060.0","upvote_count":"1","content":"Selected Answer: D\nUse Pub/Sub.","comment_id":"1293104","poster":"denno22"},{"poster":"Timfdklfajlksdjlakf","comment_id":"1275210","upvote_count":"2","content":"Selected Answer: D\nD. is the correct answer","timestamp":"1725040620.0"},{"comment_id":"1254253","timestamp":"1721811000.0","content":"Selected Answer: D\nPub/Sub (a messaging service) triggering a Cloud Function (the glue between services that are otherwise independent) to trigger something else to process the votes","poster":"flummoxed_individual","upvote_count":"3"}],"answers_community":["D (100%)"]},{"id":"xVZEw1CGviM9rXItODyI","answer":"C","question_images":[],"unix_timestamp":1721375220,"timestamp":"2024-07-19 09:47:00","question_id":189,"url":"https://www.examtopics.com/discussions/google/view/144168-exam-associate-cloud-engineer-topic-1-question-269/","isMC":true,"question_text":"You are deploying an application on Google Cloud that requires a relational database for storage. To satisfy your company’s security policies, your application must connect to your database through an encrypted and authenticated connection that requires minimal management and integrates with Identity and Access Management (IAM). What should you do?","answer_images":[],"choices":{"D":"Deploy a Cloud SQL database and configure a database user and password. Access the database through the Cloud SQL Auth Proxy.","B":"Deploy a Cloud SQL database with the SSL mode set to encrypted only, configure SSL/TLS client certificates, and configure IAM database authentication.","C":"Deploy a Cloud SQL database and configure IAM database authentication. Access the database through the Cloud SQL Auth Proxy.","A":"Deploy a Cloud SQL database with the SSL mode set to encrypted only, configure SSL/TLS client certificates, and configure a database user and password."},"answers_community":["C (100%)"],"discussion":[{"content":"Selected Answer: C\nCloud SQL Auth Proxy: This proxy ensures secure connections to your Cloud SQL database by automatically handling encryption (SSL/TLS) and IAM-based authentication. It simplifies the management of secure connections without needing to manage SSL/TLS certificates manually.\n\nIAM Database Authentication: This allows you to use IAM credentials to authenticate to the database, providing a unified and secure authentication mechanism that integrates seamlessly with Google Cloud IAM.","comment_id":"1250992","comments":[{"upvote_count":"1","comment_id":"1250997","timestamp":"1721375400.0","poster":"BuenaCloudDE","content":"A,B: You must managing SSL certification and database credentials.\n\nD: Relies on database-specific credentials rather than IAM, which doesn't fully leverage the benefits of IAM integration."}],"poster":"BuenaCloudDE","upvote_count":"7","timestamp":"1721375220.0"},{"timestamp":"1722051180.0","comment_id":"1255987","comments":[{"timestamp":"1727453400.0","upvote_count":"2","poster":"NiveusSol","content":"Google Gemini is not relaible","comment_id":"1290138"}],"poster":"ashrafh","upvote_count":"1","content":"As per Google Gemini answwer is B."},{"timestamp":"1721811180.0","content":"Selected Answer: C\nInitially chose B but then read BuenaCloudDE's comment and agreed that managing SSL certs is more complicated than using Cloud SQL Auth Proxy","comment_id":"1254257","upvote_count":"2","poster":"flummoxed_individual"}],"exam_id":1,"answer_ET":"C","answer_description":"","topic":"1"},{"id":"DqaGwgxLUmgM45cNQKPF","discussion":[{"content":"A is correct. As mentioned in the question, data access logging is enabled. I tried to download a file from a bucket and was able to view this information in Activity tab in console","timestamp":"1590298200.0","poster":"iamgcp","comments":[{"content":"I did all the configuration enabling data access logging but I still not able to see the logs when uploading or downloading a file. Does someone here has done it with a different result?","timestamp":"1639920180.0","upvote_count":"1","poster":"RegisFTM","comment_id":"504857"},{"content":"I agree with liyux21 and vito9630. In this reference link below says:\n\nIn the Activity page, where the identity performing logged actions is redacted from the audit log entry, User (anonymized) is displayed.\n\nBeacause of this, I think you can't verify the addition of metadata labels through Activity Logs.\n\nhttps://cloud.google.com/logging/docs/audit#view-activity","comment_id":"641163","timestamp":"1659428100.0","poster":"ryumada","upvote_count":"1"},{"timestamp":"1665076260.0","upvote_count":"4","comment_id":"687995","content":"activity log is deprecated:\n\nhttps://cloud.google.com/compute/docs/logging/activity-logs","poster":"MEHDIGRB","comments":[{"content":"You need to see here, https://cloud.google.com/compute/docs/logging/audit-logging. Admin activity audit logs.","timestamp":"1670418360.0","comment_id":"737874","poster":"barathgdkrish","upvote_count":"1"},{"content":"Yes, it is deprecated. However, it became the audit log which is exactly what this question is referring to. Option A is correct in my opinion.","poster":"Rog_4444","upvote_count":"2","timestamp":"1677550260.0","comment_id":"824309"}]},{"upvote_count":"25","content":"data access logging don't provide information about addition of metada, so B is correct","poster":"vito9630","timestamp":"1590665040.0","comment_id":"97466"}],"comment_id":"94694","upvote_count":"51"},{"comments":[{"content":"'Admin activity logs' capture metadata modification, but its different from 'Data Access logging', right ?","comment_id":"559622","poster":"injarapu","upvote_count":"2","timestamp":"1646246880.0"}],"content":"Answer is A. Activity log does indeed show information about metadata.\nI agree with Eshkrkrkr based on https://cloud.google.com/storage/docs/audit-logs Admin Activity logs: Entries for operations that modify the configuration or metadata of a project, bucket, or object.","comment_id":"232543","upvote_count":"15","poster":"eliteone11","timestamp":"1606881540.0"},{"comment_id":"1352502","comments":[{"timestamp":"1739613060.0","poster":"1826c27","comment_id":"1356792","upvote_count":"1","content":"mr chatgtp - stackdriver is no longer in GCP"}],"poster":"jeyam1990","timestamp":"1738857900.0","content":"Selected Answer: B\nThe correct answer is:\n\nB. Using the GCP Console, filter the Stackdriver log to view the information.\n\nExplanation:\nThe Activity log in the GCP Console is limited to Admin Activity Logs, which show administrative actions like adding metadata labels. It does not include Data Access Logs, which are required to verify file viewing activity.\n\nThe Stackdriver log (now referred to as Cloud Logging) provides access to both Admin Activity Logs and Data Access Logs, allowing you to view both types of actions (adding metadata labels and viewing files). By filtering the logs in Cloud Logging, you can get the required information for the user efficiently.\n\nAnswers provided by ChatGPT","upvote_count":"1"},{"timestamp":"1736546460.0","comment_id":"1338988","poster":"speksy","content":"Selected Answer: B\nStackdriver Logging (now called Google Cloud Logging) captures detailed logs for activities within Google Cloud, including bucket metadata changes and file access activities for Cloud Storage bucket","upvote_count":"2"},{"content":"Selected Answer: B\nThe reason why A is not an answer. The Activity log in the GCP Console is part of the Cloud Audit Logs but focuses on high-level admin activities, not specific data access or detailed operations like viewing files or adding metadata labels","upvote_count":"2","poster":"Hanu17","timestamp":"1736077560.0","comment_id":"1336741"},{"comment_id":"1332208","upvote_count":"2","timestamp":"1735270560.0","poster":"panchsonal","content":"Selected Answer: B\nThe correct answer is:\n\nB. Using the GCP Console, filter the Stackdriver log to view the information.\n\nExplanation:\nStackdriver Logging (now called Cloud Logging):\n\nLogs detailed activities, including data access, metadata changes, and file viewing events for GCP resources, including Cloud Storage buckets.\nAllows filtering logs by specific users, resource types, and actions, making it easy to verify activities for a particular user."},{"comment_id":"1330793","upvote_count":"1","content":"Selected Answer: B\nThe correct answer is B. Using the GCP Console, filter the Stackdriver log to view the information.\n\nExplanation:\nStackdriver logs (now part of Cloud Logging in GCP) capture activity logs related to interactions with resources, including Cloud Storage buckets.\nTo verify activities like metadata label additions and file views in Cloud Storage buckets, you would need to filter and examine the logs for specific actions in the Cloud Storage logs (which are stored in Cloud Logging, formerly Stackdriver).\nCloud Storage access logs record operations like viewing files, adding metadata labels, and other bucket activities, which can be filtered and reviewed using the Cloud Logging interface in the GCP Console","timestamp":"1734952560.0","poster":"modaknarayan"},{"content":"Selected Answer: B\nB. Using the GCP Console, filter the Stackdriver log to view the information.\n\nExplanation: To verify activities related to sensitive data stored in Cloud Storage buckets, including metadata labels and which files have been viewed, the Stackdriver logs (now called Cloud Logging) are the best tool. Specifically, you can filter the logs for data access events, which include details like metadata additions and file access information.\nA. The Activity log in the GCP Console typically logs changes to resources such as bucket creation, IAM policy changes, etc. It does not provide detailed data access logs or events such as metadata changes or file views.\nC. Viewing the bucket in the Storage section of the GCP Console will only show the current state of the bucket and its contents, not detailed logs about data access or metadata changes.\nD. Stackdriver Trace is used to track request latencies and performance issues within your applications, not for logging detailed activities like file access or metadata changes","comment_id":"1329381","upvote_count":"1","poster":"modaknarayan","timestamp":"1734687180.0"},{"content":"Selected Answer: A\nB is for performance monitoring","comment_id":"1321623","timestamp":"1733277480.0","upvote_count":"1","poster":"yoshi_hsc"},{"upvote_count":"1","poster":"halifax","comment_id":"1320259","content":"Selected Answer: B\nThe correct answer is B. Stackdriver is now called \"Cloud log\"\nB. Using the GCP Console, filter the Stackdriver log to view the information.\nA -(Activity log) does not capture detailed data access logs for Cloud Storage.","timestamp":"1732978920.0"},{"comment_id":"1318667","timestamp":"1732713420.0","poster":"user263263","content":"Selected Answer: B\n\"and which files have been viewed from those buckets\" - that would be logged in data_access log, not (admin) activity log. So use Cloud Logging / Log Explorer (Stackdriver is the old name for Cloud Monitoring + Cloud Logging) to filter for the relevant information.","upvote_count":"1"},{"content":"Correct answer is \"B\"\nCause they asked for metadata too on the question.","upvote_count":"1","poster":"rev89","timestamp":"1731433020.0","comment_id":"1310780"},{"upvote_count":"1","comment_id":"1310107","timestamp":"1731332760.0","content":"Selected Answer: A\nA is the correct answer.","poster":"psyll0n"},{"comment_id":"1307202","timestamp":"1730781960.0","poster":"RLIII","upvote_count":"1","content":"Selected Answer: B\nStackdriver (Cloud logging) contains both admin activity logs and data access logs."},{"comment_id":"1301667","content":"Option B is the correct Answer","timestamp":"1729618080.0","poster":"An1990","upvote_count":"1"},{"comment_id":"1299330","content":"Selected Answer: A\nThe correct answer is A. Using the GCP Console, filter the Activity log to view the information.\n\nData access logs for Cloud Storage buckets are not stored in Stackdriver Logging (formerly Stackdriver). They are stored in the Activity Log, a centralized log for all GCP activity. The Activity Log allows filtering by resource (the specific buckets), user, and activity type (adding metadata labels, viewing files). Options B, C, and D won't show this detailed access information. Therefore, directly querying the Activity Log provides the most efficient and accurate way to find the required information.","upvote_count":"3","timestamp":"1729187040.0","poster":"KC_go_reply"},{"content":"Selected Answer: A\nCloud Audit Logs (Activity Logs):These logs track who did what, where, and when within Google Cloud resources, which is crucial for security and compliance.","upvote_count":"1","timestamp":"1729064220.0","comment_id":"1298600","poster":"Jakang"}],"question_text":"You have sensitive data stored in three Cloud Storage buckets and have enabled data access logging. You want to verify activities for a particular user for these buckets, using the fewest possible steps. You need to verify the addition of metadata labels and which files have been viewed from those buckets. What should you do?","exam_id":1,"topic":"1","url":"https://www.examtopics.com/discussions/google/view/16701-exam-associate-cloud-engineer-topic-1-question-27-discussion/","unix_timestamp":1584307560,"answer":"B","answers_community":["B (55%)","A (45%)"],"question_images":[],"question_id":190,"timestamp":"2020-03-15 22:26:00","isMC":true,"answer_ET":"B","answer_description":"","answer_images":[],"choices":{"A":"Using the GCP Console, filter the Activity log to view the information.","D":"Create a trace in Stackdriver to view the information.","C":"View the bucket in the Storage section of the GCP Console.","B":"Using the GCP Console, filter the Stackdriver log to view the information."}}],"exam":{"numberOfQuestions":285,"lastUpdated":"11 Apr 2025","provider":"Google","id":1,"isBeta":false,"name":"Associate Cloud Engineer","isMCOnly":true,"isImplemented":true},"currentPage":38},"__N_SSP":true}