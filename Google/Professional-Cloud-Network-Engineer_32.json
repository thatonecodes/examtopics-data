{"pageProps":{"questions":[{"id":"Vft24XVkiiROFaragEGH","question_images":[],"answers_community":["A (100%)"],"discussion":[{"upvote_count":"31","content":"Correct Answer is (A):\n\nThe service range setting is permanent and cannot be changed.\nPlease see\nhttps://stackoverflow.com/questions/60957040/how-to-increase-the-service-address-range-of-a-gke-cluster\n\nI think the correc tanswer is A since:\nGrow is expected to up to 100 nodes (that would be /25), then up to 200 pods per node (100 times 200 = 20000 so /17 is 32768), then 1500 services in a /21 (up to 2048)","timestamp":"1604287860.0","poster":"ESP_SAP","comment_id":"210946","comments":[{"content":"yes, you are right","timestamp":"1669581360.0","comment_id":"728579","upvote_count":"2","poster":"AzureDP900"},{"comment_id":"503732","timestamp":"1639751340.0","content":"Agreed A.\n\nWhen you create a VPC-native cluster, you specify a subnet in a VPC network. The cluster uses three unique subnet IP address ranges:\n\n It uses the subnet's primary IP address range for all node IP addresses.\n It uses one secondary IP address range for all Pod IP addresses.\n It uses another secondary IP address range for all Service (cluster IP) addresses.\n\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/alias-ips#cluster_sizing","upvote_count":"3","poster":"walkwolf3"}]},{"upvote_count":"9","comment_id":"237520","timestamp":"1607361420.0","content":"isn’t max pods per node 110 in VPC native? I don’t understand how the scenario painted by the question is even possible when taking that into consideration.","comments":[{"content":"Agree with you. \n\n\"This table assumes the maximum number of Pods per node is 110 (the default and largest possible Pod density).\"\n\nRef. https://cloud.google.com/kubernetes-engine/docs/concepts/alias-ips#cluster_sizing_secondary_range_pods","timestamp":"1637068920.0","upvote_count":"2","comment_id":"479390","poster":"ThisisJohn"}],"poster":"Hybrid_Cloud_boy"},{"upvote_count":"1","content":"Selected Answer: A\nThe correct answer is A. Option A allows for optimal address allocation by creating a /25 subnet with secondary ranges of /17 for Pods and /21 for Services. This ensures that even with future growth (100 nodes, 200 Pods per node, and 1500 services), the IP space will be sufficient. By specifying the ranges in a VPC-native cluster with alias IPs, it minimizes address consumption while allowing for scalable growth. This setup meets both the current and future scaling requirements.","poster":"saraali","timestamp":"1739303880.0","comment_id":"1355127"},{"upvote_count":"1","comment_id":"1262303","timestamp":"1723091760.0","content":"A - service should be 1500 and /24 for service will not be sufficient.","poster":"e865ea8"},{"timestamp":"1703599980.0","poster":"BenMS","content":"Selected Answer: A\nI sometimes struggle to work out CIDR ranges, but in this case I think the answer is pretty clear:\n- Answers C & D do not offer network topologies at all, so can be immediately dismissed\n- Answer B suggests pods and service subnets should be the same size, which is never recommended in a GKE cluster, therefore it cannot be a correct answer\n- This leaves A, which is the only feasible choice","upvote_count":"1","comment_id":"1106068"},{"timestamp":"1693242540.0","poster":"ananta93","content":"Selected Answer: A\nCorrect Answer A.\nPlease read the question carefully. Expected number of services=1500. So, only a /22 can fulfil that requirement.","comment_id":"992433","upvote_count":"1"},{"upvote_count":"1","timestamp":"1680167280.0","poster":"Komal697","content":"Selected Answer: A\nOption A is the recommended design topology for this scenario. It suggests creating a subnet of size /25 with two secondary ranges of /17 for Pods and /21 for Services. This allows for efficient use of IP addresses, with enough address space for the expected growth. The VPC-native cluster should be created with these ranges specified. This approach is preferable because it allows for efficient utilization of IP addresses while providing enough address space for future growth.","comment_id":"855525"},{"poster":"Ben756","comment_id":"834211","timestamp":"1678382340.0","content":"Selected Answer: A\nThe correct option is A.\n\nOption A proposes to create a subnet of size/25 with 2 secondary ranges of: /17 for Pods and /21 for Services. This design will allow for 8 subnets, with a maximum of 512 Pods each and 2048 services each. The /17 range for Pods will provide up to 512 IPs per node, enough to accommodate the expected growth of 200 Pods per node. The /21 range for Services will provide up to 2048 IPs, enough to accommodate the expected growth of 1500 services.","upvote_count":"1"},{"comment_id":"830159","content":"However since 110 pods/node is max, how can we proceed? If we ignore the limit, then A is correct.","poster":"subhala","upvote_count":"1","timestamp":"1678039860.0"},{"timestamp":"1673706240.0","comment_id":"775504","upvote_count":"1","content":"A: /17 32,768 addresses 128 nodes 14,080 Pods\nSince growth is expected:\nup to 100 nodes which would be /25(=128)\nup to 200 pods per node i.e.,100*200 = 20000 which would be /17(=32768) \nup to 1500 services which would be /21 (=2048)","poster":"pk349"},{"comment_id":"650577","upvote_count":"1","poster":"GCP72","content":"Selected Answer: A\nCorrect Answer is \"A\"","timestamp":"1661229600.0"},{"timestamp":"1660665540.0","poster":"demomailinator","content":"Selected Answer: A\nAnswer is A","upvote_count":"1","comment_id":"647746"},{"upvote_count":"1","comment_id":"634570","timestamp":"1658404320.0","poster":"svsilence","content":"A is correct"},{"content":"Why not C: as the in the question it is stated: using IP alias?","poster":"zaxxon","upvote_count":"1","timestamp":"1648806360.0","comment_id":"579414"},{"comment_id":"540655","upvote_count":"1","poster":"lxs","timestamp":"1644010560.0","content":"Key aspect is GKE requires double room for pods and services. 100x2=200, so 254 which is /24."},{"content":"Answer is : A","poster":"kumarp6","timestamp":"1641298620.0","comment_id":"516563","upvote_count":"2"},{"poster":"ThisisJohn","timestamp":"1635520560.0","content":"I don't think it can be A because Google recommends a subnet not smaller than /21 for pods. My vote goes for B \n\nIf you specify a Pod address range smaller than a /21 range, you risk running out of Pod IP addresses as your cluster grow https://cloud.google.com/kubernetes-engine/docs/concepts/alias-ips#cluster_sizing","comments":[{"poster":"ThisisJohn","upvote_count":"1","timestamp":"1637069040.0","comment_id":"479391","content":"Let me correct myself. \n\nA /24 subnet cannot host 1500 services, so answer should be A"}],"comment_id":"469825","upvote_count":"1"},{"comment_id":"339240","timestamp":"1618880040.0","content":"I agree with A","poster":"[Removed]","upvote_count":"1"},{"content":"A is correct","poster":"Vidyasagar","timestamp":"1616524380.0","comment_id":"318376","upvote_count":"1"},{"comment_id":"223646","timestamp":"1605880980.0","poster":"[Removed]","upvote_count":"3","content":"Ans - A"}],"topic":"1","answer":"A","exam_id":8,"answer_ET":"A","isMC":true,"timestamp":"2020-11-02 04:31:00","unix_timestamp":1604287860,"question_id":156,"url":"https://www.examtopics.com/discussions/google/view/35722-exam-professional-cloud-network-engineer-topic-1-question-33/","answer_images":[],"question_text":"You are designing a Google Kubernetes Engine (GKE) cluster for your organization. The current cluster size is expected to host 10 nodes, with 20 Pods per node and 150 services. Because of the migration of new services over the next 2 years, there is a planned growth for 100 nodes, 200 Pods per node, and 1500 services. You want to use VPC-native clusters with alias IP ranges, while minimizing address consumption.\nHow should you design this topology?","choices":{"B":"Create a subnet of size/28 with 2 secondary ranges of: /24 for Pods and /24 for Services. Create a VPC-native cluster and specify those ranges. When the services are ready to be deployed, resize the subnets.","C":"Use gcloud container clusters create [CLUSTER NAME]--enable-ip-alias to create a VPC-native cluster.","A":"Create a subnet of size/25 with 2 secondary ranges of: /17 for Pods and /21 for Services. Create a VPC-native cluster and specify those ranges.","D":"Use gcloud container clusters create [CLUSTER NAME] to create a VPC-native cluster."},"answer_description":""},{"id":"tem9GEhfcDCPK1EyNaQi","isMC":true,"discussion":[{"timestamp":"1637314560.0","comments":[{"timestamp":"1686482040.0","poster":"AzureDP900","upvote_count":"2","comment_id":"741726","content":"Agreed"}],"poster":"densnoigaskogen","comment_id":"361144","content":"D should be the answer.\n\"Globally distributed users report that their SMTP and IMAP services are slow\" --> means it's needed to be global, traffic type is TCP.\n\"end-to-end encryption\" +\"you do not have access to the SSL certificates\" ---> means that you can not use client certificate to configure on LB to do SSL offload.\nAs per the reference below, only TCP proxy Load Balancer.\nhttps://cloud.google.com/load-balancing/docs/choosing-load-balancer","upvote_count":"32"},{"poster":"BobBui","upvote_count":"10","comment_id":"311127","content":"I go with D, https://cloud.google.com/load-balancing/docs/choosing-load-balancer\nSSL offload yes >> SSL proxy\nSSL offload no >> TCP proxy","timestamp":"1631668800.0"},{"poster":"Orzechowski","comments":[{"upvote_count":"1","timestamp":"1741269660.0","poster":"Orzechowski","comment_id":"1365890","content":"actually correcting myself answer is D TCP proxy load balancer, you have an option to use SSL offload but you don't have to. so you do not need access to the SSL certificates and still make use of the Global availability"}],"comment_id":"1365886","upvote_count":"1","content":"Selected Answer: B\nNo access to SSL then you cannot do SSL offloading, you should do passthrough and let the backend deal with the SSL part","timestamp":"1741269120.0"},{"upvote_count":"1","timestamp":"1739304120.0","content":"Selected Answer: D\nThe correct answer is D. The TCP proxy load balancer is ideal for applications like SMTP and IMAP that require end-to-end encryption but where SSL certificates are not accessible. It operates at the transport layer (Layer 4) and provides secure, encrypted traffic forwarding for non-HTTP(S) protocols such as IMAP and SMTP. It ensures that your traffic remains encrypted while reducing latency for globally distributed users. The other load balancers either require access to SSL certificates (SSL Proxy and HTTPS load balancers) or are not suitable for Layer 4 protocols (Network Load Balancer).","poster":"saraali","comment_id":"1355131"},{"content":"Selected Answer: A\nTCP Proxy load balancer does not provide the end to end encryption by itself.","comment_id":"1342326","upvote_count":"1","timestamp":"1737144960.0","poster":"RKS_2021"},{"timestamp":"1727334120.0","poster":"irmingard_examtopics","content":"Selected Answer: A\nNot HTTP => Network LB category\nPassthrough is not global => Global External Proxy Network LB\nSince creating a Google-managed certificate should still be possible, question A is correct (Global External Proxy Network LB with SSL).","comment_id":"1183150","upvote_count":"1"},{"upvote_count":"3","content":"I've changed my answer to B here's why: \n\nBoth SSL Proxy and TCP Proxy Load Balancers are designed for situations where you can terminate SSL sessions at the load balancer level, allowing for SSL offloading. However, they are not suitable for scenarios requiring end-to-end encryption without SSL termination at the load balancer, especially when SSL certificates are not available for such termination.\n\nSince you have no access to SSL certificate you cannot offload it...\nTherefore it's the responsibility of the end devices. So you the best answer now is\nAnswer B: Network Load Balancer","timestamp":"1724078640.0","comment_id":"1154121","poster":"desertlotus1211"},{"poster":"xhilmi","timestamp":"1718514420.0","upvote_count":"2","content":"Selected Answer: D\nExplanation:\n\nThe TCP proxy load balancer operates at the transport layer (Layer 4) and is designed for TCP-based protocols like SMTP and IMAP.\n\nUnlike the HTTPS load balancer, the TCP proxy load balancer does not terminate SSL, making it suitable for scenarios where SSL certificates are not accessible or not required.\n\nIt allows you to distribute TCP traffic without handling SSL encryption or decryption, making it a good choice when end-to-end encryption is not a strict requirement.","comment_id":"1097966"},{"comment_id":"991485","timestamp":"1709049000.0","poster":"Thornadoo","upvote_count":"4","content":"Selected Answer: D\nThis is D. I know this isn't super clear in the docs. But the best way to identify is as below:\n\n1) If you go to SSL Proxy (https://cloud.google.com/load-balancing/docs/ssl/setting-up-ssl), you have to choose a certificate (There is no option to do away without it)\n\n2) If you select TCP Proxy (https://cloud.google.com/load-balancing/docs/tcp/setting-up-tcp), there is no need to choose certificate"},{"comment_id":"855526","upvote_count":"1","content":"Selected Answer: A\nSince end-to-end encryption is required, the SSL Proxy Load Balancer is the appropriate choice as it allows the SSL/TLS traffic to pass through to the backends unchanged, preserving end-to-end encryption. Network Load Balancer and TCP Proxy Load Balancer do not provide end-to-end encryption for the application protocol. HTTPS Load Balancer is not appropriate because you do not have access to the SSL certificates.Therefore, the correct answer is A. SSL proxy load balancer.","timestamp":"1696065000.0","poster":"Komal697"},{"comment_id":"854679","content":"Selected Answer: A\nA is the correct answer.\nhttps://cloud.google.com/load-balancing/docs/ssl#ssl_certificates","timestamp":"1696005060.0","poster":"afeedik","upvote_count":"1"},{"comment_id":"775519","upvote_count":"2","timestamp":"1689338160.0","comments":[{"content":"I tend to agree with answer D. They have the certs, but have no one access them...","comment_id":"976079","poster":"desertlotus1211","timestamp":"1707440820.0","upvote_count":"1"}],"content":"D: It specifically states they don't”have access to the SSL certs\" not that they don't have them at all. This means they are unable to configure the client SSL certs on the LB itself and SSL offload is not required. Answer points to D for TCP Proxy.","poster":"pk349"},{"comment_id":"764313","poster":"gdtoro","upvote_count":"1","timestamp":"1688364780.0","content":"TCP Load Balancer doesn't require a certificate and can route encrypted traffic."},{"comment_id":"752847","timestamp":"1687382220.0","poster":"flyhighman","content":"Selected Answer: D\nD is right.","upvote_count":"3"},{"comment_id":"745251","upvote_count":"3","content":"I would go with D","poster":"TD24","timestamp":"1686751500.0"},{"poster":"pfilourenco","timestamp":"1686213960.0","comment_id":"738904","content":"Selected Answer: D\nAnswer is : D","upvote_count":"4"},{"content":"Selected Answer: D\nD is sure for me.","poster":"ccieman2016","timestamp":"1685908260.0","upvote_count":"4","comment_id":"735482"},{"content":"D. TCP proxy load balancer","comment_id":"729691","timestamp":"1685307720.0","upvote_count":"2","poster":"AzureDP900"},{"upvote_count":"1","comment_id":"728581","timestamp":"1685212800.0","content":"D is right","poster":"AzureDP900"},{"timestamp":"1679939340.0","upvote_count":"1","poster":"desertlotus1211","comment_id":"681026","comments":[{"content":"It specifically states they don't \"have access to the SSL certs\" not that they don't have them at all. This means they are unable to configure the client SSL certs on the LB itself and SSL offload is not required. Answer points to D for TCP Proxy.","comments":[{"comment_id":"976077","timestamp":"1707440640.0","content":"It doesn't say they have them either...","comments":[{"poster":"desertlotus1211","upvote_count":"1","content":"To me 'not having access to SSL certs' means they don't have them...","timestamp":"1707440700.0","comment_id":"976078"}],"poster":"desertlotus1211","upvote_count":"1"},{"content":"they require encryption... so they need a ssl proxy","upvote_count":"1","poster":"desertlotus1211","timestamp":"1707440580.0","comment_id":"976076"}],"timestamp":"1683736620.0","upvote_count":"1","comment_id":"715475","poster":"hogtrough"}],"content":"Answer is A: https://cloud.google.com/load-balancing/docs/ssl\nThough they company doesn't have SSL certs. Google can get it for them. Which satisfies the ask..."},{"upvote_count":"1","timestamp":"1677134640.0","content":"Selected Answer: A\nThe correct answer is A","comment_id":"650578","poster":"GCP72"},{"timestamp":"1670913000.0","comment_id":"615617","content":"Selected Answer: A\nThe correct answer is A.\n\nAs stated here: https://cloud.google.com/load-balancing/docs/tcp\n\"TCP Proxy Load Balancing is intended for TCP traffic on specific well-known ports, such as port 25 for Simple Mail Transfer Protocol (SMTP). For more information, see Port specifications. For client traffic that is encrypted on these same ports, use SSL Proxy Load Balancing.\"\nBecause encryption is required","poster":"kapara","upvote_count":"3"},{"comment_id":"516571","poster":"kumarp6","upvote_count":"1","timestamp":"1656930300.0","content":"Answer is : D"},{"comment_id":"510734","poster":"desertlotus1211","timestamp":"1656375240.0","upvote_count":"1","content":"Answer is D.\nAnswer A is wrong BECAUSE their is on SSL traffic coming in [SMTP & IMAP]. Nor does the question say SSL is being sent...\n\nThey have no SSL Certs so why are you using SSL proxy LB?"},{"content":"A \nCertificate management. Your customer-facing SSL certificates can be either certificates that you obtain and manage (self-managed certificates), or certificates that Google obtains and manages for you (Google-managed certificates). Google-managed SSL certificates each support up to 100 domains. Multiple domains are supported for Google-managed certificates. You only need to provision certificates on the load balancer. On your VMs, you can simplify management by using self-signed certificates.\n\nhttps://cloud.google.com/load-balancing/docs/ssl","upvote_count":"2","poster":"SonamDhingra","timestamp":"1656148860.0","comment_id":"509070"},{"upvote_count":"3","poster":"PeppaPig","timestamp":"1646165100.0","comment_id":"437391","comments":[{"timestamp":"1652700840.0","content":"I'm not sure but I believe users connecting may receive a security warning, since they'll see a Google-managed certificate instead of the expected service certificate","upvote_count":"1","comment_id":"479400","poster":"ThisisJohn"}],"content":"A is correct. Without access to Cert how would you be able to upload cert to your backend servers? Thus D is Wrong.\nIt has nothing to do with SSL offloading, and encryption Does NOT necessarily mean SSL encryption\n\nFor SSL proxy LB, Google automatically encrypts traffic between Google Front Ends (GFEs) and backends that reside within Google Cloud VPC networks. This is a network-level encryption. In addition to network-level encryption, you can use a secure protocol such as SSL\nhttps://cloud.google.com/load-balancing/docs/ssl-certificates/encryption-to-the-backends#encryption_between_gfes_and_backends"},{"content":"Answer is A, using managed cert you do not need to have your own. TCP/SSL proxy act as a proxy (duh), therefore it can't be TCP Proxy. HTTPS is for HTTP protocol only and network LB is regional only.","upvote_count":"3","poster":"JohnnyBG","timestamp":"1641980940.0","comment_id":"404467"},{"upvote_count":"2","poster":"jdjorge","comment_id":"341567","content":"is option A. TCP proxy for unencrypted well known ports like smtp but ssl when using those same ports with encryption\nhttps://cloud.google.com/load-balancing/docs/tcp","timestamp":"1634990100.0"},{"timestamp":"1634840340.0","upvote_count":"2","poster":"WakandaF","content":"I'll go D.\nA. SSL proxy load balancer - wrong - it needs to go end-to-end encryption, which means traffic is not off-loaded on LB.\nB. Network load balancer - wrong - it doesn't support global load balancing.\nC. HTTPS load balancer - wrong. it only works on HTTP(s) protocols.\nD. TCP proxy load balancer - I will go this on\n\nD is the correct one?","comment_id":"340550"},{"comment_id":"339245","content":"I support D, as you do not have access to the certificate, so can not use SSL offload, then can not use A.","timestamp":"1634692140.0","upvote_count":"2","poster":"[Removed]"},{"content":"I think the correct answer would be A (SSL) and I believe that to be the case because it supports TCP 25/110 & to support not having access to the SSL Certs, I think in this situation they are using Google managed SSL certs.","poster":"mwellger","upvote_count":"2","comment_id":"329549","timestamp":"1633518960.0"},{"poster":"sc00by","content":"Option B is correct answer. The only option to handle end-to-end SSL traffic without terminating traffic at the proxy level. \n\nAccroding to: https://cloud.google.com/load-balancing/docs/network\n###############################\nIt is acceptable to have SSL traffic decrypted by your backends instead of by the load balancer. The network load balancer cannot perform this task. When the backends decrypt SSL traffic, there is a greater CPU burden on the VMs.\n\n###########################################","comment_id":"327659","upvote_count":"3","timestamp":"1633305960.0"},{"content":"I'll go D.\nA. SSL proxy load balancer - wrong - it needs to go end-to-end encryption, which means traffic is not off-loaded on LB.\nB. Network load balancer - wrong - it doesn't support global load balancing.\nC. HTTPS load balancer - wrong. it only works on HTTP(s) protocols.\nD. TCP proxy load balancer - I will go this one.","comment_id":"321796","poster":"pentium2000","timestamp":"1632735480.0","upvote_count":"2"},{"upvote_count":"2","timestamp":"1632410040.0","poster":"Vidyasagar","comment_id":"318277","content":"A is the correct answer"},{"content":"It is D in my opinion.\nYou can't use SSL with SSL offload because you don't have access to any certificate. \nAnd TCP LB support end-to-end encryption just with no SSL offload.\nNetwork is regional.\nHTTPS use 80 and 443 ports only.","poster":"porsak","upvote_count":"5","comment_id":"290393","timestamp":"1628952240.0"},{"content":"Network LB: Not global \nHTTPS : Only for http(s) traffic \nTCP : supports the messaging protocols but not e2e encryption\n SSL: Supports the protocols and encrypt \nSo correct is \"A\"","comment_id":"281580","upvote_count":"2","timestamp":"1627866600.0","comments":[{"timestamp":"1660599780.0","poster":"juancambb","upvote_count":"1","content":"totally agree with you, the only reasonable answer","comment_id":"548152"}],"poster":"chetz12"},{"upvote_count":"2","content":"I would choose D.","comment_id":"260108","timestamp":"1625468160.0","poster":"groovygorilla"},{"poster":"gless","comment_id":"243547","upvote_count":"2","timestamp":"1623665880.0","comments":[{"poster":"gless","comment_id":"243813","timestamp":"1623687060.0","content":"Nah, I am wrong. It should be A.","upvote_count":"2"}],"content":"It should be D\nhttps://cloud.google.com/security/encryption-in-transit/ \nAutomatic encryption between GFEs and backends\nFor the following load balancer types, Google automatically encrypts traffic between Google Front Ends (GFEs) and your backends that reside within Google Cloud VPC networks:\nHTTP(S) Load Balancing\nTCP Proxy Load Balancing\nSSL Proxy Load Balancing"},{"timestamp":"1621515900.0","content":"Ans - A\n(Ambiguous)","poster":"[Removed]","upvote_count":"1","comment_id":"223704"},{"comment_id":"208531","content":"I'd got with A. B is out because NLB are regional not global.","upvote_count":"1","timestamp":"1619692980.0","poster":"jonclem"},{"timestamp":"1618511040.0","content":"Network Load Balancers are faster and it will allow the destination server to decrypt the SSL session...going with that one..","upvote_count":"1","comment_id":"200690","poster":"theCloudCTO"},{"timestamp":"1618198980.0","upvote_count":"1","poster":"EM0","comment_id":"198117","content":"I will choose B , as it support end-end client encryption.https://cloud.google.com/load-balancing/docs/choosing-load-balancer"},{"poster":"2cool2touch","comment_id":"194624","upvote_count":"3","timestamp":"1617741120.0","content":"Its TCP Proxy. https://cloud.google.com/load-balancing/docs/choosing-load-balancer\nTCP without SSL offload. Global. Documented to support port 25 (SMTP) and 110 (POP)"},{"comment_id":"175935","upvote_count":"2","content":"Problem with Network Load Balancer is that it is regional LB and Global.\nQuestion need us to build a Global solution.\nWe don't have certificate, so Option A and C are wrong.\nBut TCP proxy load balancer can't support encrypted traffic.\nAll options look wrong.","comments":[{"content":"Problem with Network Load Balancer is that it is regional LB and *not Global.","upvote_count":"1","timestamp":"1615221960.0","comment_id":"175936","poster":"ravirajani"}],"timestamp":"1615221900.0","poster":"ravirajani"},{"poster":"saurabh1805","content":"Considering this statement in google bookself \"TCP Proxy Load Balancing is intended for TCP traffic on specific well-known ports, such as port 25 for Simple Mail Transfer Protocol (SMTP). For more information, see Port specifications. For client traffic that is encrypted on these same ports, use SSL Proxy Load Balancing.\"\n\nI will prefer option A.","comment_id":"165489","upvote_count":"2","timestamp":"1614202200.0"},{"poster":"elguije","content":"The question states:\n\"Your company requires end-to-end encryption, but you do not have access to the SSL certificates\" My questions are:\nIf we don't hve the certificate, how could we use SSL proxy if that needs to offload the certificate?\nIs not \"end to end\"encryption guarantee if the end server on the VM instance does the SSL?","comment_id":"158124","upvote_count":"2","timestamp":"1613316480.0"},{"poster":"[Removed]","comment_id":"142830","upvote_count":"5","content":"A is the correct answer . \nTCP Proxy Load Balancing is intended for TCP traffic on specific well-known ports, such as port 25 for Simple Mail Transfer Protocol (SMTP). For more information, see Port specifications. For client traffic that is encrypted on these same ports, use SSL Proxy Load Balancing.\nhttps://cloud.google.com/load-balancing/docs/tcp","timestamp":"1611506820.0"},{"upvote_count":"6","timestamp":"1611294720.0","content":"This question is ambiguous. The requirement here is to have end-to-end encryption for SMTP & IMAP. The only load balancer that supports this is SSL proxy.\n\n\"For client traffic that is encrypted on these same ports, use SSL Proxy Load Balancing.\"\n\nhttps://cloud.google.com/load-balancing/docs/tcp\n\nThe fact that you do not have access to the SSL certificates would probably mean that you need to get the required SSL certificates or generate new ones to use SSL proxy.\n\nhttps://cloud.google.com/load-balancing/docs/ssl-certificates\n\n\nTCP proxy does not supports end-to-end encryption\n\nhttps://cloud.google.com/security/encryption-in-transit/\n\n\"For TCP load balancers, there is no encryption between the end user and the GFE. The customer's application may, however, use its own encryption between the end user and the VMs.\"\n\nEven if we could use TCP Proxy, the question never mentions the user provides the encryption or uses Gmail to enforce TLS. This leaves the possibility open to fail the encryption requirement.\n\nI would say \"A\" is the correct answer.","comment_id":"140837","poster":"terrain"},{"poster":"elguije","comment_id":"132495","content":"I think answer should be D. Global TCP traffic with no SSL offload.\n\nhttps://cloud.google.com/load-balancing/docs/choosing-load-balancer","comments":[{"comments":[{"upvote_count":"1","comment_id":"172833","content":"You are totally correct, D is wrong. My mistake.\nhttps://cloud.google.com/load-balancing/docs/network\n\nUse cases\nUse Network Load Balancing in the following circumstances:\n\nYou need to load balance UDP traffic, or you need to load balance a TCP port that isn't supported by other load balancers.\nIt is acceptable to have SSL traffic decrypted by your backends instead of by the load balancer. The network load balancer cannot perform this task. When the backends decrypt SSL traffic, there is a greater CPU burden on the VMs.\nSelf-managing the load balancer's SSL certificates is acceptable to you. Google-managed SSL certificates are only available for HTTP(S) Load Balancing and SSL Proxy Load Balancing.\nYou need to forward the original packets unproxied.\nYou have an existing setup that uses a pass-through load balancer, and you want to migrate it without changes.","timestamp":"1614799680.0","poster":"elguije"}],"comment_id":"166707","timestamp":"1614348600.0","poster":"Capo","content":"tcp porxy doesnt support end to end encryption","upvote_count":"2"}],"timestamp":"1610419920.0","upvote_count":"3"}],"answer_ET":"D","question_images":[],"answers_community":["D (67%)","A (30%)","4%"],"question_id":157,"choices":{"B":"Network load balancer","C":"HTTPS load balancer","A":"SSL proxy load balancer","D":"TCP proxy load balancer"},"unix_timestamp":1594515120,"url":"https://www.examtopics.com/discussions/google/view/25449-exam-professional-cloud-network-engineer-topic-1-question-34/","exam_id":8,"answer":"D","timestamp":"2020-07-12 02:52:00","answer_images":[],"answer_description":"","question_text":"Your company has recently expanded their EMEA-based operations into APAC. Globally distributed users report that their SMTP and IMAP services are slow.\nYour company requires end-to-end encryption, but you do not have access to the SSL certificates.\nWhich Google Cloud load balancer should you use?","topic":"1"},{"id":"uMvD4bZz6yb3n8jE76cz","answer":"AC","answer_ET":"AC","question_images":[],"topic":"1","question_id":158,"answer_description":"","discussion":[{"upvote_count":"24","comment_id":"210948","timestamp":"1619919240.0","content":"Correct Answer are (A) & (C):\n\nThe solution is incorrect. GCP recommends creating VPC peering for establishing communication between two organizations in GCP.","poster":"ESP_SAP","comments":[{"timestamp":"1684145400.0","poster":"AzureDP900","upvote_count":"2","content":"Agreed","comment_id":"718713"}]},{"upvote_count":"5","poster":"small1_small2","comment_id":"650410","timestamp":"1677103020.0","content":"Selected Answer: AC\nVPC peering offers peering between VPC which will suffice the requirement =A\nC is 100% correct"},{"poster":"saraali","upvote_count":"1","comment_id":"1355137","content":"Selected Answer: AC\nReason:The correct answers are A& C. \nA. VPC peering: This solution allows two VPCs, in this case, your company's and the partner's VPCs, to communicate securely without needing a VPN or a shared network. Since there is no CIDR overlap between the VPCs, VPC peering is a great choice for private communication between the VPCs.\n\nC. Cloud VPN: If you want to securely connect your company's VPC to the partner's network (or their VPC), Cloud VPN is a good solution. It provides an encrypted connection over the public internet. It doesn’t require CIDR overlap, making it suitable for your scenario.","timestamp":"1739304420.0"},{"poster":"Kyle1776","upvote_count":"1","comments":[{"content":"Did you test this using the Console? Because VPN should be the most flexible solution, but it's possible the Console is making some assumptions in your case. Perhaps try the CLI?\n\nA VPN tunnel needs only an IP address for the peer gateway to initiate a connection - because the peer could be any network appliance.","comment_id":"1106109","timestamp":"1719406500.0","poster":"BenMS","upvote_count":"1"}],"comment_id":"1064073","content":"For everyone saying C Cloud VPN, I ask you to lab it up real quick. Please try and create a VPN connection between 2 VPCs in separate organizations. You will not be able to because when you are creating a VPN connection and select GCP as the VPN Peer gateway, the only options available to connect you are your VPC's. Not your partners in a different organization.","timestamp":"1715007300.0"},{"timestamp":"1714483080.0","poster":"Kyle1776","upvote_count":"1","content":"I see everyone on here saying that you can use cloud VPN but the VPN gateways also have to be within the same organization in order to connect. Facing the same issue as the shared VPC.\nIn my lab when I go to create a VPN tunnel between 2 different VPC's in different organizations this message pops up \"Make sure you created a VPN gateway in the Google Cloud project that you want to connect.\" You then have to select the project you are connecting to. \nThis implies that if the VPC/project are not in your org then you cant create a VPN between the two.","comment_id":"1058975"},{"timestamp":"1706657460.0","comment_id":"967528","poster":"Thornadoo","content":"Selected Answer: AC\nThis is really not a difficult question folks - here's my explanation\n\nA. VPC peering (Correct - Now I know this opens up the subnet, and there should be an additional step of configuring firewall rules IMO - but peering can be done between two different organizations)\nB. Shared VPC (Incorrect - We are talking about company and partner - meaning different organization. Shared VPC is applicable only for projects in the same org - https://cloud.google.com/vpc/docs/shared-vpc)\nC. Cloud VPN (Correct - With Cloud VPN you get additional layer of security of encryption)\nD. Dedicated Interconnect (Incorrect - Both use GCP. If it was different cloud, then cross connect or on-prem then interconnect)\nE. Cloud NAT (Incorrect - Not needed. With peering itself all subnets can communicate using internal IPv4 addresses - https://cloud.google.com/vpc/docs/vpc-peering)","upvote_count":"4"},{"timestamp":"1699367580.0","poster":"due","content":"please someone explain.\nWhy not B. Shared VPC","comments":[{"poster":"gcpengineer","upvote_count":"1","content":"not in same org","comment_id":"974738","comments":[{"upvote_count":"1","timestamp":"1714482840.0","poster":"Kyle1776","content":"You have the same issue for VPN though","comment_id":"1058973"}],"timestamp":"1707319740.0"}],"upvote_count":"1","comment_id":"891373"},{"comment_id":"855529","content":"Selected Answer: AD\nThe two solutions that can be implemented to achieve the desired results without compromising the security are VPC peering and Dedicated Interconnect.\n\nA. VPC peering allows connecting two VPC networks through a private network connection. This solution provides private connectivity between the two VPCs without the need for public IPs or internet connectivity.\n\nD. Dedicated Interconnect allows for establishing a dedicated network connection between the two networks over a private, high-throughput, low-latency connection. This solution provides a dedicated and private connection between the two networks.","comments":[],"timestamp":"1696065060.0","poster":"Komal697","upvote_count":"1"},{"upvote_count":"1","content":"Correct Answer are (A) & (C): The solution is incorrect. GCP recommends creating VPC peering for establishing communication between two organizations in GCP.\nDedicated interconnect is used to connect on prem to GCP, not GCP to GCP. D is not correct. VPC peering allows this to occur between GCP VPCs.\nDedicated interconnect enables hybrid cloud - meaning if only on-prem network needs connectivity with Google Cloud. Question clearly mention only VPC between org. Hence D is wrong!","comment_id":"775520","poster":"pk349","timestamp":"1689338280.0"},{"comment_id":"728582","content":"A,C is perfect","timestamp":"1685212860.0","upvote_count":"1","poster":"AzureDP900"},{"upvote_count":"4","poster":"hogtrough","timestamp":"1683723120.0","comment_id":"715316","content":"Selected Answer: AC\nDedicated interconnect is used to connect on prem to GCP, not GCP to GCP. D is not correct. VPC peering allows this to occur between GCP VPCs."},{"content":"Boys oh boys, Dedicated interconnect enables hybrid cloud - meaning if only on-prem network needs connectivity with Google Cloud. Question clearly mention only VPC between org. hence D is wrong!","timestamp":"1677559260.0","poster":"Jasonwcc","comment_id":"653254","upvote_count":"2"},{"content":"Selected Answer: AC\nThe correct answer is A & C","comment_id":"650580","timestamp":"1677134880.0","upvote_count":"4","poster":"GCP72"},{"poster":"ssarabj","upvote_count":"2","content":"C is 100% accurate\nD is wrong as interconnect only comes in picture when we need to enable connectivity between on prem and gcp\nA is partially fits in picture as give access to all resource but requirement says need access on few resources.","timestamp":"1665374100.0","comment_id":"583568"},{"content":"for sure te correct answer is (A) and (C).","poster":"marcosilva79","timestamp":"1661082720.0","comment_id":"552887","upvote_count":"1"},{"upvote_count":"1","poster":"marcosilva79","timestamp":"1659727920.0","comment_id":"541280","content":"A and C are correct ."},{"content":"There is no question of going with Dedicated Interconnect when you have both networks on GCP. Easily we can implement the solution using Peering and VPN. Hence A and C.","comment_id":"529478","upvote_count":"2","poster":"yas_cloud","timestamp":"1658439660.0"},{"comment_id":"516576","timestamp":"1656930420.0","upvote_count":"3","content":"Answer is : A and C","poster":"kumarp6"},{"content":"Selected Answer: CD\nVote CD. Note that on VPC Peering it is not possible to select which subnet has access to what between subnets. Thus there is a security risk of sharing information between orgs / projects.","upvote_count":"2","timestamp":"1653244140.0","comments":[{"comment_id":"510735","poster":"desertlotus1211","timestamp":"1656375480.0","content":"You clearly don't know what Dedicated Interconnects are...","upvote_count":"1"},{"upvote_count":"3","comments":[{"timestamp":"1653737160.0","poster":"akg001","comment_id":"489157","content":"I am also trying to figure out this.","upvote_count":"3"}],"poster":"lehnon1925","timestamp":"1653366840.0","content":"anyone have taken the exam recently and can confirm that all the questions here are still valid?","comment_id":"485665"}],"comment_id":"484542","poster":"JesusMariaJose"},{"poster":"Arad","comment_id":"481323","upvote_count":"1","content":"A & C are correct.","timestamp":"1652926080.0"},{"content":"A & C are correct","upvote_count":"2","timestamp":"1632409500.0","poster":"Vidyasagar","comment_id":"318263"},{"timestamp":"1632364980.0","comment_id":"317756","upvote_count":"1","poster":"pentium2000","content":"AC 200%"},{"comment_id":"242612","content":"A and C, Google Cloud VPC Network Peering allows internal IP address connectivity across two Virtual Private Cloud (VPC) networks regardless of whether they belong to the same project or the same organization.","comments":[{"upvote_count":"1","content":"It aint A , peering will enable access to all resources on intrrnel ip but requirement says, we need to provide access to only few resources.","comment_id":"583564","poster":"ssarabj","timestamp":"1665373620.0"}],"upvote_count":"4","poster":"cesar7816","timestamp":"1623584820.0"},{"poster":"[Removed]","content":"Ans - AC","comment_id":"223710","timestamp":"1621516140.0","upvote_count":"4"}],"url":"https://www.examtopics.com/discussions/google/view/35723-exam-professional-cloud-network-engineer-topic-1-question-35/","timestamp":"2020-11-02 04:34:00","unix_timestamp":1604288040,"answers_community":["AC (86%)","10%"],"exam_id":8,"question_text":"Your company is working with a partner to provide a solution for a customer. Both your company and the partner organization are using GCP. There are applications in the partner's network that need access to some resources in your company's VPC. There is no CIDR overlap between the VPCs.\nWhich two solutions can you implement to achieve the desired results without compromising the security? (Choose two.)","answer_images":[],"isMC":true,"choices":{"E":"Cloud NAT","D":"Dedicated Interconnect","A":"VPC peering","C":"Cloud VPN","B":"Shared VPC"}},{"id":"kATV1N9W4L6WEgUxIcus","isMC":true,"choices":{"D":"Disable Cloud CDN on the storage bucket. Wait 90 seconds. Re-enable Cloud CDN on the storage bucket.","B":"Issue a cache invalidation command with pattern /folder-a/*.","C":"Make sure that all the objects with prefix folder-a are not shared publicly.","A":"Add an appropriate lifecycle rule on the storage bucket."},"answers_community":["B (100%)"],"discussion":[{"poster":"ESP_SAP","upvote_count":"21","content":"Correct Answer is (B):\n\nYou might want to remove an object from the cache prior to its normal expiration time. You can force an object or set of objects to be ignored by the cache by requesting a cache invalidation.\nPath patterns\nEach invalidation request specifies a path pattern that identifies the object or set of objects that should be invalidated. The path pattern can be either a specific path, such as /cat.jpg, or an entire directory structure, such as /pictures/*. The following rules apply to path patterns:\n\nThe path pattern must start with /.\nIt cannot include ? or #.\nIt must not include an * except as the final character following a /.\nIf it ends with /*, the preceding string is a prefix, and all objects whose paths begin with that prefix are invalidated.","timestamp":"1651455540.0","comment_id":"210951"},{"content":"Selected Answer: B\nThis approach allows you to efficiently invalidate the cached content for all objects with the folder-a prefix in Cloud CDN, ensuring that outdated copies are removed with minimal impact.\nOther options, like lifecycle rules or disabling Cloud CDN, would not directly address the need to invalidate cached content and might lead to unnecessary disruption. Restricting access to objects does not affect cached versions either, making it an ineffective solution for this scenario.","comment_id":"1355139","poster":"saraali","upvote_count":"1","timestamp":"1739304720.0"},{"comment_id":"855531","upvote_count":"2","timestamp":"1727687580.0","poster":"Komal697","content":"Selected Answer: B\nB. Issue a cache invalidation command with pattern /folder-a/*.\n\nTo remove the cached copies of all the objects with the prefix \"folder-a\", you can use the Cloud CDN cache invalidation feature. This allows you to invalidate cached content by specifying a path or pattern of paths. In this case, the pattern /folder-a/* would match all objects with the prefix \"folder-a\"."},{"comment_id":"834219","poster":"Ben756","content":"Selected Answer: B\nB. Issue a cache invalidation command with pattern /folder-a/.\nExplanation: To remove the cached copies of all the objects with the prefix folder-a, you can issue a cache invalidation command with the pattern /folder-a/ using the Cloud CDN API. This will remove all cached copies of any objects that begin with the prefix folder-a. Using a cache invalidation command is the quickest way to remove cached copies of objects, and it is not necessary to disable Cloud CDN or change the sharing settings of the objects. Adding a lifecycle rule on the storage bucket can be used to automatically delete objects after a certain period of time, but it does not directly remove cached copies of objects.","timestamp":"1725895740.0","upvote_count":"1"},{"comment_id":"775522","upvote_count":"1","poster":"pk349","timestamp":"1720960740.0","content":"• B. Issue a cache invalidation *** command with pattern /folder-a/*.\nYou can force an object or set of objects to be ignored by the cache by requesting a cache invalidation. \n4. Enter the directory path and wildcard (/path/to/file/*).\n• If you want to invalidate the whole directory for all hostnames, enter only the path and wildcard (for example: /images/*)."},{"poster":"AzureDP900","comment_id":"728583","content":"B. Issue a cache invalidation command with pattern /folder-a/*.","timestamp":"1716835320.0","upvote_count":"1"},{"comment_id":"718712","timestamp":"1715767680.0","upvote_count":"1","content":"B is right\nhttps://cloud.google.com/cdn/docs/invalidating-cached-content#invalidate_the_whole_directory","poster":"AzureDP900"},{"poster":"GCP72","timestamp":"1708671000.0","comment_id":"650581","content":"Selected Answer: B\nThe correct answer is B","upvote_count":"2"},{"content":"Selected Answer: B\nCorrect answer : https://cloud.google.com/cdn/docs/invalidating-cached-content#invalidate_the_whole_directory","timestamp":"1703592180.0","upvote_count":"2","poster":"kapara","comment_id":"622472"},{"poster":"kumarp6","upvote_count":"2","content":"Answer is : B","comment_id":"516578","timestamp":"1688466480.0"},{"content":"Answer is B: https://cloud.google.com/cdn/docs/invalidating-cached-content#gcloud_1\n\nInvalidate the whole directory\ngcloud compute url-maps invalidate-cdn-cache LOAD_BALANCER_NAME \\\n --path \"/images/*\"","comment_id":"510740","timestamp":"1687911960.0","poster":"desertlotus1211","upvote_count":"2"},{"poster":"Raghucs","timestamp":"1682827140.0","content":"Ans - B","comment_id":"470521","upvote_count":"1"},{"content":"It should be \"B\", the invalidation method is taught in the coursera course.","comment_id":"260117","upvote_count":"2","poster":"groovygorilla","timestamp":"1657004640.0"},{"poster":"cesar7816","timestamp":"1655121660.0","upvote_count":"2","comments":[{"content":"Just wanted to make sure you are aware this is a GCP certification here, not an AWS one.","upvote_count":"5","poster":"PoCk3T","comment_id":"352757","timestamp":"1667967540.0"}],"comment_id":"242623","content":"Ans is B, https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Invalidation.html"},{"content":"Ans - B","upvote_count":"2","poster":"[Removed]","comment_id":"223727","timestamp":"1653052980.0"}],"unix_timestamp":1604288340,"answer_description":"","answer_ET":"B","question_text":"You have a storage bucket that contains the following objects:\n[1]\n[1]\n[1]\n[1]\nCloud CDN is enabled on the storage bucket, and all four objects have been successfully cached. You want to remove the cached copies of all the objects with the prefix folder-a, using the minimum number of commands.\nWhat should you do?","topic":"1","question_id":159,"exam_id":8,"timestamp":"2020-11-02 04:39:00","answer_images":[],"answer":"B","url":"https://www.examtopics.com/discussions/google/view/35724-exam-professional-cloud-network-engineer-topic-1-question-36/","question_images":[]},{"id":"FSUdDbEsfhDHXPnP48B9","unix_timestamp":1604289720,"question_images":[],"answers_community":["AB (100%)"],"choices":{"A":"VPC flow logs","C":"Cloud Audit logs","D":"Stackdriver Trace","E":"Compute Engine instance system logs","B":"Firewall logs"},"question_id":160,"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/35725-exam-professional-cloud-network-engineer-topic-1-question-37/","timestamp":"2020-11-02 05:02:00","question_text":"Your company is running out of network capacity to run a critical application in the on-premises data center. You want to migrate the application to GCP. You also want to ensure that the Security team does not lose their ability to monitor traffic to and from Compute Engine instances.\nWhich two products should you incorporate into the solution? (Choose two.)","answer_images":[],"answer_description":"","answer":"AB","exam_id":8,"discussion":[{"content":"Correct Answers are (A) & (B):\n\nA: Using VPC Flow Logs\nVPC Flow Logs records a sample of network flows sent from and received by VM instances, including instances used as GKE nodes. \nThese logs can be used for network monitoring, forensics, real-time security analysis, and expense optimization.\n\nhttps://cloud.google.com/vpc/docs/using-flow-logs\n\n(B): Firewall Rules Logging overview\nFirewall Rules Logging allows you to audit, verify, and analyze the effects of your firewall rules. For example, you can determine\n if a firewall rule designed to deny traffic is functioning as intended. Firewall Rules Logging is also useful if you need to \ndetermine how many connections are affected by a given firewall rule.\n\nYou enable Firewall Rules Logging individually for each firewall rule whose connections you need to log. Firewall Rules Logging \nis an option for any firewall rule, regardless of the action (allow or deny) or direction (ingress or egress) of the rule.\n\nhttps://cloud.google.com/vpc/docs/firewall-rules-logging","comments":[{"poster":"AzureDP900","comment_id":"718706","upvote_count":"1","content":"Agreed, A & B perfect.","timestamp":"1668513900.0"}],"comment_id":"210956","upvote_count":"35","timestamp":"1604289720.0","poster":"ESP_SAP"},{"comment_id":"1355148","upvote_count":"1","content":"Selected Answer: AB\nThe correct answers are A and B.\nVPC flow logs: Capture detailed network traffic data, enabling the Security team to monitor traffic to and from Compute Engine instances.\nFirewall logs: Provide visibility into allowed and denied network traffic, allowing the Security team to track traffic based on firewall rules.","poster":"saraali","timestamp":"1739305200.0"},{"comment_id":"1342334","poster":"RKS_2021","timestamp":"1737145680.0","upvote_count":"1","content":"Selected Answer: AB\nAgreed A and B are correct"},{"upvote_count":"1","content":"Ans is A and B because they want to monitor traffic from VM, so no point in monitoring audit logs and system logs","comment_id":"905627","poster":"Hetavi","timestamp":"1684915440.0"},{"upvote_count":"3","poster":"Komal697","comment_id":"855536","timestamp":"1680167820.0","content":"Selected Answer: AB\nA. VPC flow logs\nB. Firewall logs\n\nBoth VPC flow logs and Firewall logs can be used to monitor network traffic to and from Compute Engine instances. VPC flow logs provide visibility into network flows within a VPC network, while Firewall logs provide visibility into firewall rules that are applied to traffic. Incorporating both these products into the solution will ensure that the Security team does not lose their ability to monitor traffic to and from Compute Engine instances. Cloud Audit logs are used to track who did what, where, and when across Google Cloud resources, and Stackdriver Trace is used to debug performance issues in applications, but they are not directly relevant to monitoring network traffic in this scenario. Compute Engine instance system logs provide information about the instances themselves, but not about the traffic flowing to and from them."},{"timestamp":"1678383060.0","comment_id":"834223","content":"Selected Answer: AB\nThe two products that should be incorporated into the solution to ensure that the Security team does not lose their ability to monitor traffic to and from Compute Engine instances are:\n\nA. VPC flow logs: This will allow you to capture network flows at the Virtual Private Cloud (VPC) level, including information such as source and destination IP addresses, ports, protocol, and bytes transferred.\n\nB. Firewall logs: This will allow you to capture information about the traffic that has been allowed or denied by the firewall rules that are applied to your Compute Engine instances.\n\nTherefore, options A and B are the correct answers.","upvote_count":"2","poster":"Ben756"},{"upvote_count":"1","poster":"pk349","timestamp":"1673707200.0","content":"A. VPC flow logs: VPC Flow Logs records a sample of network flows sent from and received by VM instances, including instances used as Google Kubernetes Engine nodes. These logs can be used for network monitoring, forensics, real-time security analysis, and expense optimization.\nB. Firewall logs: Firewall log analysis can be used to discover suspicious network activity that could indicate malicious threat actors breaching a network and can help greatly improve an organization's firewall effectiveness. A firewall analyzer helps by monitoring how the firewall handles traffic.","comment_id":"775523"},{"timestamp":"1656237900.0","upvote_count":"2","content":"Selected Answer: AB\nOnly A & B answer to the requirements.","comment_id":"622473","poster":"kapara"},{"comment_id":"516583","upvote_count":"2","poster":"kumarp6","timestamp":"1641299460.0","content":"Answer is : A and"},{"content":"A & B are correct.","poster":"Arad","upvote_count":"2","timestamp":"1637295000.0","comment_id":"481325"},{"poster":"Vidyasagar","timestamp":"1616556120.0","upvote_count":"2","content":"A and B","comment_id":"318725"},{"upvote_count":"2","comment_id":"223732","poster":"[Removed]","timestamp":"1605885840.0","content":"Ans - AB"}],"topic":"1","answer_ET":"AB"}],"exam":{"isBeta":false,"numberOfQuestions":228,"provider":"Google","isMCOnly":true,"id":8,"name":"Professional Cloud Network Engineer","isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":32},"__N_SSP":true}