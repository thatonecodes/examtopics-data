{"pageProps":{"questions":[{"id":"Cas1dBwDVvey9S2MBfDB","unix_timestamp":1670134200,"choices":{"A":"Cloud Run","D":"Google Kubernetes Engine using cluster autoscaling","C":"Compute Engine with unmanaged instance groups","B":"Compute Engine with managed instance groups"},"isMC":true,"discussion":[{"comment_id":"1247231","timestamp":"1720864380.0","upvote_count":"1","poster":"d_ella2001","content":"Selected Answer: A\ncorrect answer A"},{"poster":"alpha_canary","content":"Selected Answer: A\n\"handle traffic spikes efficiently\"\nCloud run the fastest to autoscale among the given options. \nGKE could be considered too, but Cloud Run s cheaper","comment_id":"1195238","upvote_count":"1","timestamp":"1713062220.0"},{"comment_id":"1087837","poster":"wanrltw","timestamp":"1701714060.0","upvote_count":"1","content":"Selected Answer: A\nCloud Run is the cheapest solution among these options and can scale up and down to 0 instances."},{"content":"Selected Answer: D\nGoogle Kubernetes Engine (GKE) is a managed Kubernetes service that allows you to deploy and run containerized applications. GKE is a good choice for running a single-player mobile game backend because it can be easily scaled up or down to meet the needs of your game.\nCloud Run is a serverless computing platform that allows you to run code without managing servers. Cloud Run is a good choice for running simple applications, but it is not as scalable as GKE.","poster":"__rajan__","comment_id":"1013750","upvote_count":"1","timestamp":"1695366900.0"},{"comment_id":"973764","poster":"purushi","content":"Selected Answer: A\nI go with A. The requirement is to optimize the cost while scaling for unexpected spikes in the traffic. Cloud Run is the cheapest among all the other options given.","timestamp":"1691321040.0","upvote_count":"1"},{"poster":"allalla","timestamp":"1682257080.0","content":"Selected Answer: D\nBing chose D: For a single-player mobile game backend with unpredictable traffic patterns and a need to optimize costs while handling traffic spikes efficiently, Google Kubernetes Engine (GKE) using cluster autoscaling (option D) would be a good choice. GKE’s cluster autoscaler automatically resizes the number of nodes in a node pool based on the demands of your workloads. This helps ensure that you have enough resources to handle requests while minimizing over-provisioning and optimizing costs.","comment_id":"878405","upvote_count":"1"},{"content":"Answer A","upvote_count":"1","comment_id":"757685","poster":"TNT87","timestamp":"1672075500.0","comments":[{"comment_id":"758257","upvote_count":"1","content":"Did you take the exam?","poster":"Georgianaaa","timestamp":"1672128000.0","comments":[{"upvote_count":"1","poster":"TNT87","timestamp":"1673005200.0","comment_id":"767567","content":"Not yet"}]}]},{"content":"Selected Answer: A\nCompute Engine answers are eliminated because they can't scale quickly enough. \nGKE Answer is ruled out because you can end up overprovisioned, also cannot scale out to add more nodes quickly enough.","upvote_count":"4","poster":"micoams","comment_id":"749244","timestamp":"1671402360.0"},{"poster":"zellck","comment_id":"747914","content":"Selected Answer: A\nA is the answer.","upvote_count":"1","timestamp":"1671268140.0"},{"poster":"test010101","comment_id":"741677","upvote_count":"1","timestamp":"1670761560.0","content":"Selected Answer: D\nvote D"},{"comment_id":"734871","poster":"gardislan18","timestamp":"1670134200.0","upvote_count":"1","comments":[],"content":"Selected Answer: D\nAnswer is D to lessen the over-provisioning\nNot A - the app is not containerized\nNot sure with Compute Engine\n\nhttps://cloud.google.com/blog/products/containers-kubernetes/gke-best-practices-to-lessen-over-provisioning"}],"url":"https://www.examtopics.com/discussions/google/view/89926-exam-professional-cloud-developer-topic-1-question-144/","topic":"1","answer_description":"","exam_id":7,"answer":"A","question_images":[],"answers_community":["A (69%)","D (31%)"],"question_id":51,"answer_images":[],"question_text":"You are developing a single-player mobile game backend that has unpredictable traffic patterns as users interact with the game throughout the day and night. You want to optimize costs by ensuring that you have enough resources to handle requests, but minimize over-provisioning. You also want the system to handle traffic spikes efficiently. Which compute platform should you use?","answer_ET":"A","timestamp":"2022-12-04 07:10:00"},{"id":"EHeJna2xE2qtBn8AbzsL","answer":"C","discussion":[{"poster":"alpha_canary","comment_id":"1195240","content":"Selected Answer: C\n. Create groups, add the users to their groups, assign the relevant roles to the groups, and then provide the users with each relevant Project ID","upvote_count":"1","timestamp":"1728873540.0"},{"comment_id":"1013757","poster":"__rajan__","content":"Selected Answer: C\nThis is the most efficient and secure way to enable developer access to Google Cloud projects. By creating groups and assigning roles to the groups, you can minimize the administrative overhead of managing user permissions. You can also provide developers with access to the projects they need, while limiting their access to other resources.","upvote_count":"1","timestamp":"1711099200.0"},{"content":"Selected Answer: C\nI choose C. Adding users to a group and assigning the role to a group is a good practice as IAM is concerned. The project ID is the more user-friendly identifier and the one which most Cloud APIs and user interfaces use when interfacing with you, the customer.\n\nThe project number is an internal implementation detail and is the key that most Google Cloud services use for storing data in their databases; most API calls implicitly translate the ID to the number when performing queries for project details.","upvote_count":"1","poster":"purushi","timestamp":"1707226320.0","comment_id":"973769"},{"poster":"TNT87","upvote_count":"1","timestamp":"1687793040.0","content":"Answer C","comment_id":"757684"},{"upvote_count":"1","poster":"zellck","content":"Selected Answer: C\nC is the answer.","comment_id":"747910","timestamp":"1686985560.0"},{"upvote_count":"1","comment_id":"744945","content":"Selected Answer: C\noption C","poster":"sharath25","timestamp":"1686728820.0"},{"upvote_count":"2","poster":"test010101","content":"Selected Answer: C\nvote C","comment_id":"741678","timestamp":"1686479220.0"},{"timestamp":"1685852100.0","content":"Selected Answer: C\nBest practice is to create a group\nnot sure between project ID and project number","poster":"gardislan18","upvote_count":"1","comments":[{"timestamp":"1702626600.0","poster":"phil_thain","upvote_count":"1","content":"What is the difference between C & D? I can use both project ID and project number to find a project is the GCP console","comment_id":"923752"}],"comment_id":"734873"}],"choices":{"A":"Add the users to their projects, assign the relevant roles to the users, and then provide the users with each relevant Project ID.","D":"Create groups, add the users to their groups, assign the relevant roles to the groups, and then provide the users with each relevant Project Number.","B":"Add the users to their projects, assign the relevant roles to the users, and then provide the users with each relevant Project Number.","C":"Create groups, add the users to their groups, assign the relevant roles to the groups, and then provide the users with each relevant Project ID."},"isMC":true,"unix_timestamp":1670134500,"exam_id":7,"answer_images":[],"answers_community":["C (100%)"],"answer_ET":"C","question_images":[],"timestamp":"2022-12-04 07:15:00","topic":"1","url":"https://www.examtopics.com/discussions/google/view/89927-exam-professional-cloud-developer-topic-1-question-145/","question_text":"The development teams in your company want to manage resources from their local environments. You have been asked to enable developer access to each team’s Google Cloud projects. You want to maximize efficiency while following Google-recommended best practices. What should you do?","answer_description":"","question_id":52},{"id":"s72iiMjzLG1qc44BoNfm","question_images":[],"answer":"C","url":"https://www.examtopics.com/discussions/google/view/89928-exam-professional-cloud-developer-topic-1-question-146/","choices":{"A":"Deploy a Vertical Pod Autoscaler, and scale based on the CPU load.","B":"Deploy a Vertical Pod Autoscaler, and scale based on a custom metric.","C":"Deploy a Horizontal Pod Autoscaler, and scale based on the CPU toad.","D":"Deploy a Horizontal Pod Autoscaler, and scale based on a custom metric."},"isMC":true,"discussion":[{"upvote_count":"1","poster":"thewalker","timestamp":"1725977400.0","comments":[{"timestamp":"1725977400.0","content":"A. Deploy a Vertical Pod Autoscaler, and scale based on the CPU load: Vertical Pod Autoscaler (VPA) scales the resources (CPU and memory) of individual pods, not the number of pods. This might not be the most efficient approach for a stateless and distributed service.\nB. Deploy a Vertical Pod Autoscaler, and scale based on a custom metric: VPA with custom metrics requires more effort to set up and configure. It's not the most efficient solution for a quick deployment.\nD. Deploy a Horizontal Pod Autoscaler, and scale based on a custom metric: While HPA with custom metrics can be powerful, it requires more time to set up and configure. For a two-week deadline, using CPU load as a metric is a simpler and faster approach.","upvote_count":"1","comment_id":"1281589","poster":"thewalker"}],"content":"Selected Answer: C\nMinimal Changes: Horizontal Pod Autoscaler (HPA) is a built-in Kubernetes feature that requires minimal configuration. You can quickly enable it and configure it to scale based on CPU utilization, which is a standard metric readily available in Kubernetes.\nStateless and Distributed Service: HPA is well-suited for stateless and distributed services. It scales by adding or removing replicas of your service, ensuring that your application remains distributed and handles load efficiently.\nTwo-Week Deadline: HPA is a straightforward solution that can be deployed and configured within a two-week timeframe.","comment_id":"1281588"},{"timestamp":"1695376320.0","comment_id":"1013931","upvote_count":"1","poster":"__rajan__","content":"Selected Answer: C\nC is correct."},{"poster":"purushi","content":"Selected Answer: C\nSince minimum number of changes, I go with C. Scaling based on the custom metrics might take more time compared to built in CPU load metric. Also, we need to see that application is stateless. So simple CPU metric is enough as a scaling parameter.","upvote_count":"1","comment_id":"973773","comments":[{"timestamp":"1691539140.0","content":"Have you given the exam yet. Are these questions similar to actual exam questions?","comment_id":"976106","upvote_count":"1","poster":"abhishek_verma1_stl_tech"}],"timestamp":"1691321940.0"},{"timestamp":"1673614620.0","upvote_count":"1","comment_id":"774492","poster":"telp","content":"Selected Answer: C\nA. Incorrect: This doesn’t help with a distributed application.\nB. Incorrect: This would work, but would require Cloud Monitoring integration and possible application modification. This would also not apply to a distributed application.\nC. Correct: This will require the least number of changes to the code and fits the requirements.\nD. Incorrect: This would work, but would require Cloud Monitoring integration and possible application modification."},{"content":"Answer C\nScale based on the percent utilization of CPUs across nodes. This can be cost effective, letting you maximize CPU resource utilization. Because CPU usage is a trailing metric, however, your users might experience latency while a scale-up is in progress.","comment_id":"755566","timestamp":"1671961200.0","upvote_count":"1","poster":"TNT87"},{"content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/horizontalpodautoscaler\nThe Horizontal Pod Autoscaler changes the shape of your Kubernetes workload by automatically increasing or decreasing the number of Pods in response to the workload's CPU or memory consumption, or in response to custom metrics reported from within Kubernetes or external metrics from sources outside of your cluster.","poster":"zellck","timestamp":"1671267780.0","comment_id":"747903","upvote_count":"2"},{"content":"Selected Answer: C\nAB are wrong because it is recommended to start with HPA if you have nothing \nD would take time and effort since you have to tune the metric\nC is right because is the most simple entry level solution for autoscaling due the unknown new requirements","poster":"melisargh","upvote_count":"3","timestamp":"1670617200.0","comment_id":"740418"},{"upvote_count":"1","content":"Selected Answer: D\nI think D is option.","poster":"TrainingProgram","comment_id":"738577","timestamp":"1670469240.0"},{"comment_id":"734874","poster":"gardislan18","content":"Selected Answer: C\nthere are too many typos here but if it is really typo then the answer is C","comments":[{"poster":"ash_meharun","content":"Please share your views about why it's not D? Question doesn't say anything about increasing load utilization but about new(addition) requirements.","timestamp":"1670405700.0","comments":[{"poster":"zellck","content":"scaling based on CPU load will be sufficient. you don't need to create custom metric.","comment_id":"747907","upvote_count":"2","timestamp":"1671267840.0"}],"comment_id":"737673","upvote_count":"1"}],"upvote_count":"3","timestamp":"1670134920.0"}],"question_text":"Your company’s product team has a new requirement based on customer demand to autoscale your stateless and distributed service running in a Google Kubernetes Engine (GKE) duster. You want to find a solution that minimizes changes because this feature will go live in two weeks. What should you do?","answer_ET":"C","exam_id":7,"timestamp":"2022-12-04 07:22:00","unix_timestamp":1670134920,"topic":"1","question_id":53,"answers_community":["C (92%)","8%"],"answer_description":"","answer_images":[]},{"id":"HQHIBgupqpg7D1zQro4Q","unix_timestamp":1670135820,"answer_images":[],"discussion":[{"comment_id":"1281605","timestamp":"1725978180.0","content":"Selected Answer: A\nDynamic Discovery: Using metadata allows your Compute Engine instances to dynamically discover the endpoint information for the specific service version they need. This eliminates the need for hardcoding endpoints or relying on fixed hostnames and ports.\nLoose Coupling: Metadata promotes loose coupling between your services. Each service can be updated independently without affecting other services, as long as the metadata is updated accordingly.\nScalability: Metadata is a scalable solution. You can easily manage and update endpoint information for a large number of services without modifying the code of each Compute Engine instance.","comments":[{"timestamp":"1725978180.0","poster":"thewalker","content":"B. Define your service endpoint information as label data that is retrieved at runtime and used to connect to the desired service: Labels are primarily used for tagging and filtering resources, not for dynamic service discovery.\nC. Define your service endpoint information to be retrieved from an environment variable at runtime and used to connect to the desired service: While environment variables can be used for configuration, they are not as flexible or scalable as metadata for managing service endpoints.\nD. Define your service to use a fixed hostname and port to connect to the desired service. Replace the service at the endpoint with your new version: This approach is inflexible and requires manual updates to the service endpoint whenever a new version is deployed.","comment_id":"1281606","upvote_count":"1"}],"upvote_count":"1","poster":"thewalker"},{"comment_id":"1195273","timestamp":"1713070440.0","upvote_count":"1","poster":"alpha_canary","content":"Selected Answer: A\nGo with A\n\nwhy not B?\nLabels are used for organizing Google Cloud resources, not for storing configuration data that your application needs to run."},{"timestamp":"1695376500.0","content":"Selected Answer: A\nThe best answer is: A. Define your service endpoint information as metadata that is retrieved at runtime and used to connect to the desired service.\n\nThis is the most flexible and scalable way to configure your application to easily bring up new Compute Engine instances that find and use a specific version of a service.","upvote_count":"1","poster":"__rajan__","comment_id":"1013934"},{"timestamp":"1691323740.0","comment_id":"973800","content":"Selected Answer: A\nIt is either A or C.\nWe can define a host URL as metadata in a virtual machine instance that orchestrates different services based on urls defined as metadata. One more way is to retrieve the urls from environment variables. Environment variables can be passed from,\n1) command line\n2) docker file\n3) kubernetes deployment descriptor\n4) through config server - application properities / yml file and so on.\n\nThe easier way is to define it as metadata in the compute engine instance itself.","poster":"purushi","upvote_count":"2"},{"comment_id":"966958","timestamp":"1690705200.0","upvote_count":"1","poster":"TQM__9MD","content":"Selected Answer: B\nI think B"},{"upvote_count":"1","timestamp":"1683160380.0","poster":"ryuhei","comment_id":"889066","content":"Selected Answer: B\nAnswer is [B] ."},{"comments":[{"content":"Ansuwer is A:\nLabels are used to categorize and organize resources in Google Cloud Platform, such as Compute Engine instances. While they can also be used to store endpoint information, they may not be as flexible as metadata when it comes to dynamically retrieving information at runtime. Additionally, labels are associated with individual resources, so updating the label data would require modifying the specific resource, rather than a centralized metadata store.\n\nIn some cases, using labels may be more appropriate, such as when you want to categorize and organize your resources, but for managing service endpoints in a loosely coupled architecture, metadata is generally a more flexible and scalable solution.","upvote_count":"4","comment_id":"804475","timestamp":"1676042100.0","poster":"mrvergara"}],"content":"Selected Answer: B\nAn example of how you can retrieve the endpoint information from a label in Python:\n\nimport google.auth\nfrom google.cloud import compute\n\n# Authenticate and create a client for the Compute Engine API\ncredentials, project = google.auth.default()\ncompute_client = compute.Client(credentials=credentials, project=project)\n\n# Get the instance based on the instance name\ninstance_name = \"example-instance\"\ninstance = compute_client.instance(instance_name)\n\n# Get the endpoint information from the instance's labels\nendpoint = instance.labels.get(\"endpoint\")","comment_id":"801101","timestamp":"1675784880.0","poster":"mrvergara","upvote_count":"2"},{"upvote_count":"2","content":"https://cloud.google.com/apis/design/glossary#api_service_endpoint\nhttps://cloud.google.com/compute/docs/metadata/overview\nAnswer A\nAnswer A","poster":"TNT87","timestamp":"1671961080.0","comment_id":"755563"},{"upvote_count":"2","timestamp":"1671267600.0","poster":"zellck","content":"Selected Answer: A\nA is the answer.\n\nhttps://cloud.google.com/service-infrastructure/docs/service-metadata/reference/rest#service-endpoint","comment_id":"747900"},{"comment_id":"734881","timestamp":"1670135820.0","content":"Selected Answer: A\nCorrect Answer: A. best practice\nB - There's no label data\nC - harder to commit env?\nD - not sure about this","poster":"gardislan18","upvote_count":"1"}],"answer_description":"","question_images":[],"question_text":"Your application is composed of a set of loosely coupled services orchestrated by code executed on Compute Engine. You want your application to easily bring up new Compute Engine instances that find and use a specific version of a service. How should this be configured?","question_id":54,"url":"https://www.examtopics.com/discussions/google/view/89929-exam-professional-cloud-developer-topic-1-question-147/","answer":"A","answer_ET":"A","exam_id":7,"choices":{"A":"Define your service endpoint information as metadata that is retrieved at runtime and used to connect to the desired service.","C":"Define your service endpoint information to be retrieved from an environment variable at runtime and used to connect to the desired service.","B":"Define your service endpoint information as label data that is retrieved at runtime and used to connect to the desired service.","D":"Define your service to use a fixed hostname and port to connect to the desired service. Replace the service at the endpoint with your new version."},"timestamp":"2022-12-04 07:37:00","isMC":true,"answers_community":["A (67%)","B (33%)"],"topic":"1"},{"id":"dukZ90Iu1b4r61AhFoRI","unix_timestamp":1671267480,"answer_images":[],"discussion":[{"timestamp":"1726999140.0","upvote_count":"1","comment_id":"1013935","poster":"__rajan__","content":"Selected Answer: BE\nBE is correct."},{"upvote_count":"1","poster":"purushi","timestamp":"1722946380.0","content":"Selected Answer: BE\nI go with B and E. They are almost same.","comment_id":"973805"},{"content":"Selected Answer: BE\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity","timestamp":"1709038980.0","upvote_count":"1","comment_id":"823697","poster":"Pime13"},{"content":"Selected Answer: BE\nA is incorrect. While it could work, all the services are using the same service account, there is no separation of permissions, and no detailed logging.\nB and E together connect GKE and Google service accounts, so GKE can authenticate a service with a Google service account.\nC is incorrect. While this is feasible, it’s not the recommended practice for workload identity because of the mandatory key rotation of the service accounts.\nD is incorrect. While this is feasible, it’s not the recommended practice for workload identity because of the mandatory key rotation of the service accounts.\nE and B together connect GKE and Google service accounts, so GKE can authenticate a service with a Google service account.","poster":"telp","upvote_count":"2","comment_id":"774490","timestamp":"1705150560.0"},{"poster":"TNT87","comment_id":"755554","timestamp":"1703496360.0","upvote_count":"2","content":"https://cloud.google.com/kubernetes-engine/docs/tutorials/authenticating-to-cloud-platform#use_workload_identity\nAnswer B\n\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts\nAnswer E"},{"content":"Selected Answer: BE\nBE is the answer.\n\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity","upvote_count":"2","comment_id":"747898","timestamp":"1702803480.0","poster":"zellck"}],"answer_description":"","question_images":[],"question_text":"You are developing a microservice-based application that will run on Google Kubernetes Engine (GKE). Some of the services need to access different Google Cloud APIs. How should you set up authentication of these services in the cluster following Google-recommended best practices? (Choose two.)","question_id":55,"answer":"BE","url":"https://www.examtopics.com/discussions/google/view/91883-exam-professional-cloud-developer-topic-1-question-148/","answer_ET":"BE","exam_id":7,"choices":{"C":"Access the Google service account keys from a secret management service.","B":"Enable Workload Identity in the cluster via the gcloud command-line tool.","E":"Use gcloud to bind the Kubernetes service account and the Google service account using roles/iam.workloadIdentity.","A":"Use the service account attached to the GKE node.","D":"Store the Google service account keys in a central secret management service."},"timestamp":"2022-12-17 09:58:00","isMC":true,"answers_community":["BE (100%)"],"topic":"1"}],"exam":{"isImplemented":true,"provider":"Google","isBeta":false,"id":7,"name":"Professional Cloud Developer","numberOfQuestions":338,"isMCOnly":false,"lastUpdated":"11 Apr 2025"},"currentPage":11},"__N_SSP":true}