{"pageProps":{"questions":[{"id":"UXd7lO2qpkRRqKmCQsK7","answer_images":[],"choices":{"B":"Configure the application code to send a small percentage of users to the newly deployed revision.","D":"Deploy the feature with “Serve this revision immediately” checked. Check for errors, roll back to the previous revision, and repeat the process until you have verified that the deployment is bug-free.","C":"Deploy the feature with “Serve this revision immediately” unchecked, and configure the new revision to serve a small percentage of traffic. Check for errors, and increase traffic to the revision as appropriate.","A":"Configure the application’s frontend load balancer to toggle between the new and old revisions."},"answers_community":["C (100%)"],"discussion":[{"comment_id":"1559768","upvote_count":"1","timestamp":"1744336980.0","poster":"yokoyan","content":"Selected Answer: C\nhttps://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration?hl=ja#gradual"},{"upvote_count":"4","content":"Selected Answer: C\nBy deploying the new feature with “Serve this revision immediately” unchecked, you can control how much traffic the new revision receives without fully switching over to it.\nConfiguring a small percentage of traffic to go to the new revision allows for gradual testing in production with real users, minimizing the risk of downtime or large-scale errors.\nIf no issues are encountered, you can gradually increase the traffic to the new revision until it fully replaces the old one.","timestamp":"1728715260.0","poster":"anshad666","comment_id":"1296372"}],"question_text":"You need to deploy a new feature into production on Cloud Run. Your company’s SRE team mandates gradual deployments to avoid large downtimes caused by code change errors. You want to configure this deployment with minimal effort. What should you do?","unix_timestamp":1728715260,"exam_id":7,"answer_ET":"C","url":"https://www.examtopics.com/discussions/google/view/149134-exam-professional-cloud-developer-topic-1-question-306/","answer":"C","question_id":231,"question_images":[],"answer_description":"","isMC":true,"topic":"1","timestamp":"2024-10-12 08:41:00"},{"id":"rCm3MXNMI8Kp1yBUCh1d","answer":"A","answer_description":"","answer_images":[],"topic":"1","question_text":"You are developing an external-facing application on GKE that provides a streaming API to users. You want to offer two subscription tiers, “basic\" and “premium\", to users based on the number of API requests that each client application is allowed to make each day. You want to design the application architecture to provide subscription tiers to users while following Google-recommended practices. What should you do?","discussion":[{"content":"Selected Answer: A\nApigee Proxy: Apigee acts as an API gateway, handling security, rate limiting, and traffic management. Using it ensures scalability and the ability to manage subscription-based API access efficiently.\nAPI Keys: Issuing API keys to identify client applications allows for tracking and controlling usage.\nQuota Policy: Apigee's quota policies allow you to set request limits (e.g., daily or per-minute quotas) based on the subscription tier. This is an ideal solution for managing different subscription levels, as you can define different API request limits for \"basic\" and \"premium\" users.","poster":"anshad666","upvote_count":"1","comment_id":"1296375","timestamp":"1728715500.0"}],"timestamp":"2024-10-12 08:45:00","url":"https://www.examtopics.com/discussions/google/view/149135-exam-professional-cloud-developer-topic-1-question-307/","unix_timestamp":1728715500,"exam_id":7,"isMC":true,"answers_community":["A (100%)"],"question_images":[],"answer_ET":"A","choices":{"C":"1. Configure the service on GKE as a backend to two new projects, each with a separate Application Load Balancer.\n2. Configure the quota \"Queries per second (QPS) per region per network” for each project individually.\n3. Provide users with API endpoints based on the subscription tier.","A":"1. Configure the service on GKE as a backend to an Apigee proxy.\n2. Provide API keys to users to identify client applications.\n3. Configure a Quota policy in Apigee for API keys based on the subscription tier.","B":"1. Configure the service on GKE as a backend to an Apigee proxy.\n2. Provide API keys to users to identify client applications.\n3. Configure a SpikeArrest policy in Apigee for API keys based on the subscription tier.","D":"1. Deploy the application to two GKE clusters, one for each subscription tier. Configure each cluster to have a separate Ingress.\n2. Configure each cluster as a backend to an Apigee proxy.\n3. Provide API keys to users to identify client applications.\n4. Configure separate rate limits for client applications based on the subscription tier."},"question_id":232},{"id":"EYCwlR8nGQ1NOwgqxrt5","question_images":[],"unix_timestamp":1728715800,"answers_community":["A (100%)"],"answer_images":[],"exam_id":7,"question_id":233,"choices":{"B":"Configure a service account for each individual by using the user name and photo, and grant permissions for each user to impersonate their respective service accounts.","A":"Configure workforce identity federation with the external IdP, and set up attribute mapping.","D":"Create a Google group that includes organization email IDs for all users. Ask users to use the same name, work email ID, and password to register and sign in.","C":"Configure workload identity federation to get the external IdP tokens, and use these tokens to sign in to the Google Cloud console."},"discussion":[{"content":"Selected Answer: A\nWorkforce Identity Federation allows organizations to authenticate and manage access for users from external IdPs (such as Azure AD or Okta) without creating and managing separate Google Cloud accounts.\nAttribute Mapping enables the personalization of the user experience by mapping attributes such as the user's name and photo from the external IdP, ensuring that the user's details are displayed correctly when accessing the Google Cloud console.","comment_id":"1296377","timestamp":"1728715800.0","poster":"anshad666","upvote_count":"1"}],"answer_ET":"A","answer_description":"","topic":"1","isMC":true,"answer":"A","url":"https://www.examtopics.com/discussions/google/view/149136-exam-professional-cloud-developer-topic-1-question-308/","question_text":"Your organization has users and groups configured in an external identity provider (IdP). You want to leverage the same external IdP to allow Google Cloud console access to all employees. You also want to personalize the sign-in experience by displaying the user's name and photo when users access the Google Cloud console. What should you do?","timestamp":"2024-10-12 08:50:00"},{"id":"Ux7oHM0r2mKL3fMMPiPi","question_images":[],"unix_timestamp":1728715980,"answers_community":["B (100%)"],"answer_images":[],"question_id":234,"exam_id":7,"choices":{"D":"Deploy your API on a Compute Engine instance. Create a Kafka cluster, and configure your API to write messages to the cluster.","C":"Deploy your API to a GKE cluster. Create a Kafka cluster, and configure your API to write messages to the cluster.","B":"Deploy your API as a Cloud Run service. Create a Pub/Sub topic, and configure your API to push messages to the topic.","A":"Deploy your API to App Engine. Create a Pub/Sub topic, and configure your API to push messages to the topic."},"discussion":[{"upvote_count":"1","comment_id":"1559807","poster":"yokoyan","timestamp":"1744356660.0","content":"Selected Answer: B\nminimizing infrastructure management overhead -> App Engine or Cloud Run\ngRPC -> Cloud Run\nhttps://cloud.google.com/endpoints/docs/choose-endpoints-option?hl=ja#grpc_apis_arent_supported_on_or"},{"comment_id":"1296378","content":"Selected Answer: B\nCloud Run is best suitable for gRPC interface","timestamp":"1728715980.0","poster":"anshad666","upvote_count":"1"}],"answer_ET":"B","answer_description":"","topic":"1","isMC":true,"answer":"B","url":"https://www.examtopics.com/discussions/google/view/149137-exam-professional-cloud-developer-topic-1-question-309/","timestamp":"2024-10-12 08:53:00","question_text":"You are developing a new API that creates requests on an asynchronous message service. Requests will be consumed by different services. You need to expose the API by using a gRPC interface while minimizing infrastructure management overhead. How should you deploy the API?"},{"id":"Z2JdsyhF1GheaPSE4tBu","answer_images":[],"choices":{"A":"Smoke tests","B":"Stackdriver uptime checks","D":"Managed instance group - heath checks","C":"Cloud Load Balancing - heath checks"},"isMC":true,"unix_timestamp":1604863740,"answers_community":["B (100%)"],"question_id":235,"question_images":[],"answer":"B","answer_description":"","discussion":[{"poster":"yuchun","upvote_count":"5","timestamp":"1656111600.0","comment_id":"389966","content":"C,D can both check but not 'alert', so I think the answer is B"},{"timestamp":"1726731720.0","comment_id":"1011077","upvote_count":"1","poster":"__rajan__","content":"Selected Answer: B\nStackdriver Uptime Check is the correct option as we can configure it to send an alert when the service is down."},{"comment_id":"882736","content":"Alert. So B.","upvote_count":"1","poster":"Chuckq","timestamp":"1714227840.0"},{"timestamp":"1692509880.0","upvote_count":"3","comment_id":"649192","content":"Selected Answer: B\nB is correct","poster":"tomato123"},{"timestamp":"1674095340.0","upvote_count":"2","content":"B is right one","poster":"herocc","comment_id":"527169"},{"content":"https://cloud.google.com/load-balancing/docs/l7-internal\n\n\"If a backend becomes unhealthy, traffic is automatically redirected to healthy backends within the same region. If all backends are unhealthy, the load balancer returns an HTTP 503 Service Unavailable response.\"\n\"One or more backends must be connected to the backend service. Because the scope of an internal HTTP(S) load balancer is regional, not global, clients and backend VMs or endpoints must all be in the same region. Backends can be instance groups or NEGs in any of the following configurations:\nManaged instance groups (zonal or regional)\"\n\nI would take C as the answer since the application runs on the MIG and traffic is being controlled by the load balancer","poster":"syu31svc","timestamp":"1658104860.0","comments":[{"upvote_count":"6","timestamp":"1659240660.0","poster":"syu31svc","comment_id":"417694","content":"Disregard what I said about C being the answer\n\nCorrect answer is B as Stackdriver or Cloud Monitoring uptime checks can be used to check if the application is unavailable.\n\nhttps://cloud.google.com/monitoring/uptime-checks:\n\"An uptime check is a request sent to a resource to see if it responds. You can use uptime checks to determine the availability of a VM instance, an App Engine service, a URL, or an AWS load balancer.\""}],"upvote_count":"2","comment_id":"408661"},{"comment_id":"394543","content":"B. Uptime check can provide the functionality of control the status of the VMs","timestamp":"1656579300.0","poster":"kernel1973","upvote_count":"1"},{"upvote_count":"2","comment_id":"215488","poster":"saurabh1805","timestamp":"1636399740.0","content":"B is correct answer, Uptime provide you a machanism to do halth check on URL."}],"url":"https://www.examtopics.com/discussions/google/view/36495-exam-professional-cloud-developer-topic-1-question-31/","topic":"1","timestamp":"2020-11-08 20:29:00","exam_id":7,"question_text":"You have an application in production. It is deployed on Compute Engine virtual machine instances controlled by a managed instance group. Traffic is routed to the instances via a HTTP(s) load balancer. Your users are unable to access your application. You want to implement a monitoring technique to alert you when the application is unavailable.\nWhich technique should you choose?","answer_ET":"B"}],"exam":{"provider":"Google","name":"Professional Cloud Developer","numberOfQuestions":338,"id":7,"lastUpdated":"11 Apr 2025","isMCOnly":false,"isImplemented":true,"isBeta":false},"currentPage":47},"__N_SSP":true}