{"pageProps":{"questions":[{"id":"jUgryJfF0RiMqZBJoGDx","choices":{"A":"Set up Vertex AI Experiments to track metrics and parameters. Configure Vertex AI TensorBoard for visualization.","D":"Set up a Cloud Function to write and save metrics files to a BigQuery table. Configure a Google Cloud VM to host TensorBoard locally for visualization.","C":"Set up a Vertex AI Workbench notebook instance. Use the instance to save metrics data in a Cloud Storage bucket and to host TensorBoard locally for visualization.","B":"Set up a Cloud Function to write and save metrics files to a Cloud Storage bucket. Configure a Google Cloud VM to host TensorBoard locally for visualization."},"topic":"1","answer":"A","answer_description":"","question_text":"You work on a team that builds state-of-the-art deep learning models by using the TensorFlow framework. Your team runs multiple ML experiments each week, which makes it difficult to track the experiment runs. You want a simple approach to effectively track, visualize, and debug ML experiment runs on Google Cloud while minimizing any overhead code. How should you proceed?","question_id":161,"timestamp":"2024-01-13 09:07:00","discussion":[{"upvote_count":"7","poster":"b1a8fae","timestamp":"1721485500.0","content":"Selected Answer: A\nYou want to run, track, visualize ML experiments -> look no further, Vertex AI experiments.","comment_id":"1127389"},{"timestamp":"1729197480.0","upvote_count":"2","content":"Selected Answer: A\nBuilt-in Tracking: Vertex AI Experiments is specifically designed for tracking ML experiments on Google Cloud. It simplifies logging metrics and parameters, eliminating the need for custom code.\nTensorBoard Integration: Vertex AI integrates with TensorBoard, allowing visualization of training logs and metrics directly within the Experiments interface. This provides a centralized location for both tracking and visualization.\nMinimized Overhead: This approach leverages existing services, minimizing the need for additional code or infrastructure setup compared to options with Cloud Functions or VMs.","poster":"fitri001","comment_id":"1197476"},{"content":"Selected Answer: A\nOptions B and D: These options involve more setup and maintenance overhead, as they require managing Cloud Functions, VMs, and storage resources.\nOption C: Vertex AI Workbench is excellent for interactive experimentation, but it's not optimized for long-term experiment tracking and visualization.","timestamp":"1720850820.0","poster":"pikachu007","upvote_count":"3","comment_id":"1121402"}],"question_images":[],"answer_ET":"A","answers_community":["A (100%)"],"answer_images":[],"isMC":true,"unix_timestamp":1705133220,"exam_id":13,"url":"https://www.examtopics.com/discussions/google/view/131064-exam-professional-machine-learning-engineer-topic-1-question/"},{"id":"cjg3z5fe3phBES3dfHCk","answer_images":[],"exam_id":13,"choices":{"A":"Deploy a Dataflow batch pipeline and a Vertex AI Prediction endpoint.","D":"Deploy a Dataflow streaming pipeline with the Runlnference API, and use automatic model refresh.","B":"Deploy a Dataflow batch pipeline with the Runlnference API, and use model refresh.","C":"Deploy a Dataflow streaming pipeline and a Vertex AI Prediction endpoint with autoscaling."},"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/131693-exam-professional-machine-learning-engineer-topic-1-question/","answer_ET":"D","question_images":[],"topic":"1","timestamp":"2024-01-20 17:35:00","isMC":true,"question_text":"Your work for a textile manufacturing company. Your company has hundreds of machines, and each machine has many sensors. Your team used the sensory data to build hundreds of ML models that detect machine anomalies. Models are retrained daily, and you need to deploy these models in a cost-effective way. The models must operate 24/7 without downtime and make sub millisecond predictions. What should you do?","question_id":162,"answer":"D","discussion":[{"timestamp":"1713386640.0","content":"Selected Answer: D\nwhy D?\nReal-time Predictions: Dataflow streaming pipelines continuously process sensor data, enabling real-time anomaly detection with sub-millisecond predictions. This is crucial for immediate response to potential machine issues.\nRunInference API: This API allows invoking TensorFlow models directly within the Dataflow pipeline for on-the-fly inference. This eliminates the need for separate prediction endpoints and reduces latency.\nAutomatic Model Refresh: Since models are retrained daily, automatic refresh ensures the pipeline utilizes the latest version without downtime. This is essential for maintaining model accuracy and anomaly detection effectiveness.\nWhy not C?\nDataflow Streaming Pipeline with Vertex AI Prediction Endpoint with Autoscaling: While autoscaling can handle varying workloads, Vertex AI Prediction endpoints might incur higher costs for real-time, high-volume predictions compared to invoking models directly within the pipeline using RunInference.","poster":"fitri001","upvote_count":"8","comment_id":"1197483"},{"comment_id":"1199225","content":"Selected Answer: D\nagree with fitri001","poster":"gscharly","upvote_count":"1","timestamp":"1713627840.0"},{"timestamp":"1712599140.0","comments":[{"timestamp":"1713013680.0","poster":"pinimichele01","content":"and also ai endpoint not good for online inference","comment_id":"1194973","upvote_count":"1"}],"upvote_count":"1","comment_id":"1191737","poster":"pinimichele01","content":"Selected Answer: D\nWith the automatic model refresh feature, when the underlying model changes, your pipeline updates to use the new model. Because the RunInference transform automatically updates the model handler, you don't need to redeploy the pipeline. With this feature, you can update your model in real time, even while the Apache Beam pipeline is running."},{"content":"Selected Answer: C\nMy Answer: C\n\nThe phrase: “The models must operate 24/7 without downtime and make sub millisecond predictions” configures a case of online prediction (option B or C) \n\nThe phrase: “Models are retrained daily, and you need to deploy these models in a cost-effective way”, choose between “ Vertex AI Prediction endpoint with autoscaling” instead “Runlnference API, and use automatic model refresh” looks better because always update with retrained models, and the scalability. \n\nhttps://cloud.google.com/blog/products/ai-machine-learning/streaming-prediction-with-dataflow-and-vertex","timestamp":"1708302300.0","upvote_count":"3","comment_id":"1153635","poster":"guilhermebutzke"},{"comment_id":"1136667","timestamp":"1706697600.0","upvote_count":"2","content":"Selected Answer: C\nlow latency - > streaming\nC & D could both work, but C is the GCP solution. So I chose C","comments":[{"poster":"asmgi","timestamp":"1720988460.0","upvote_count":"1","comment_id":"1247957","content":"I don't think autoscaling is relevant to this task, since we have the same amount of sensors at any time."},{"comment_id":"1146906","content":"i think autoscaling will lead to downtime atleast when the replicas are updating .","timestamp":"1707613560.0","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1714311000.0","comment_id":"1203577","poster":"pinimichele01","content":"i agree, D is better"}],"poster":"vaibavi"}],"poster":"sonicclasps"},{"content":"Selected Answer: D\nNeeds to be active 24/7 -> streaming.\nRunInference API seems like the way to go here, using automatic model refresh on a daily basis. https://beam.apache.org/documentation/ml/about-ml/","upvote_count":"4","poster":"b1a8fae","timestamp":"1705768500.0","comment_id":"1127395"}],"unix_timestamp":1705768500,"answers_community":["D (74%)","C (26%)"]},{"id":"NNmo1nyZBtJaJmk4KehE","exam_id":13,"unix_timestamp":1705133580,"answer_images":[],"answer":"D","choices":{"C":"Compare the results to the evaluation results from a previous run. If the performance improved deploy the model to a Vertex AI endpoint. Configure a cron job to redeploy the pipeline every night.","D":"Compare the results to the evaluation results from a previous run. If the performance improved deploy the model to a Vertex AI endpoint with training/serving skew threshold model monitoring. When the model monitoring threshold is triggered redeploy the pipeline.","B":"Compare the training and evaluation losses of the current run. If the losses are similar, deploy the model to a Vertex AI endpoint with training/serving skew threshold model monitoring. When the model monitoring threshold is triggered redeploy the pipeline.","A":"Compare the training and evaluation losses of the current run. If the losses are similar, deploy the model to a Vertex AI endpoint. Configure a cron job to redeploy the pipeline every night."},"timestamp":"2024-01-13 09:13:00","topic":"1","isMC":true,"answer_description":"","question_images":[],"question_id":163,"question_text":"You are developing an ML model that predicts the cost of used automobiles based on data such as location, condition, model type, color, and engine/battery efficiency. The data is updated every night. Car dealerships will use the model to determine appropriate car prices. You created a Vertex AI pipeline that reads the data splits the data into training/evaluation/test sets performs feature engineering trains the model by using the training dataset and validates the model by using the evaluation dataset. You need to configure a retraining workflow that minimizes cost. What should you do?","answer_ET":"D","url":"https://www.examtopics.com/discussions/google/view/131065-exam-professional-machine-learning-engineer-topic-1-question/","discussion":[{"upvote_count":"6","timestamp":"1729198320.0","content":"Selected Answer: D\nSince the goal is to minimize cost while maintaining accuracy, Option D provides a more targeted approach for retraining based on the likelihood of the model being outdated due to data changes. Option B might trigger retraining more frequently even if the performance difference doesn't necessarily stem from a significant shift in the data distribution.","poster":"fitri001","comment_id":"1197492","comments":[{"comment_id":"1197493","upvote_count":"3","timestamp":"1729198380.0","content":"Option D: Utilizes training/serving skew monitoring. This specifically focuses on identifying discrepancies between the training data and the real-world data the deployed model encounters. This is a strong indicator of when the model might be outdated due to changes in the data distribution.\nOption B: Utilizes training/serving loss monitoring. Training loss tells you how well the model performs on the training data, while serving loss tells you how well it performs on real-world data. While high serving loss can indicate a problem, it might not necessarily be due to training/serving skew. Other factors like data quality issues or concept drift (gradual changes in the underlying data patterns) could also lead to high serving loss.","poster":"fitri001"}]},{"comment_id":"1152167","poster":"guilhermebutzke","content":"Selected Answer: D\nMy answer D:\nA and C: Not Correct: Schedule a retrain every night is not necessary since the model is performing well.\nB. Not Correct: This approach focuses on internal consistency within the current training run, train versus loss evaluation. Comparing similar training and validation losses doesn't guarantee better performance than previous models. This is an approach to identity overfitting, for example, or model quality. \nD. Correct: This approach focuses on identifying performance changes over time. Comparing to previous runs helps assess if the new model performs better than the old one on the evaluation set. we will check if this new version is better or not than the old one\n\nhttps://www.youtube.com/watch?v=1ykDWsnL2LE&ab_channel=GoogleCloudTech","upvote_count":"5","timestamp":"1723825560.0"},{"poster":"omermahgoub","content":"Selected Answer: D\nD. Compare the results to the evaluation results from a previous run. If the performance improved, deploy the model to a Vertex AI endpoint with training/serving skew threshold model monitoring. When the model monitoring threshold is triggered, redeploy the pipeline.","comment_id":"1195970","comments":[{"content":"i agree, see guilhermebutzke","timestamp":"1729097280.0","poster":"pinimichele01","comment_id":"1196708","upvote_count":"1"}],"upvote_count":"3","timestamp":"1728987060.0"},{"poster":"pikachu007","content":"Selected Answer: B\nOption A: Redeploying the pipeline every night without checking for degradation wastes resources if model performance is stable.\nOption C: Comparing results to a previous run doesn't guarantee model degradation detection in the current run.\nOption D: Comparing to a previous run and using model monitoring is redundant; model monitoring alone is sufficient.","upvote_count":"5","timestamp":"1720851180.0","comment_id":"1121407"}],"answers_community":["D (74%)","B (26%)"]},{"id":"o6PKni7GtuDEfL94tDlf","answer":"C","answer_description":"","question_text":"You recently used BigQuery ML to train an AutoML regression model. You shared results with your team and received positive feedback. You need to deploy your model for online prediction as quickly as possible. What should you do?","answers_community":["C (65%)","D (32%)","3%"],"answer_images":[],"topic":"1","isMC":true,"timestamp":"2024-01-13 09:16:00","question_id":164,"url":"https://www.examtopics.com/discussions/google/view/131066-exam-professional-machine-learning-engineer-topic-1-question/","choices":{"D":"Export the model from BigQuery ML to Cloud Storage. Import the model into Vertex AI Model Registry. Deploy the model to a Vertex AI endpoint.","B":"Retrain the model by using Vertex Al Deploy the model from Vertex AI Model. Registry to a Vertex AI endpoint.","C":"Alter the model by using BigQuery ML, and specify Vertex AI as the model registry. Deploy the model from Vertex AI Model Registry to a Vertex AI endpoint.","A":"Retrain the model by using BigQuery ML, and specify Vertex AI as the model registry. Deploy the model from Vertex AI Model Registry to a Vertex AI endpoint,"},"answer_ET":"C","exam_id":13,"discussion":[{"upvote_count":"7","poster":"pikachu007","comments":[{"poster":"shadz10","timestamp":"1705310820.0","comments":[{"comment_id":"1139735","content":"I think it's C\nExported models for model types AUTOML_REGRESSOR and AUTOML_CLASSIFIER do not support AI Platform deployment for online prediction.","timestamp":"1707015120.0","upvote_count":"5","poster":"vaibavi"}],"comment_id":"1123222","content":"I agree with pikachu007","upvote_count":"2"},{"poster":"daidai75","comment_id":"1129315","upvote_count":"1","content":"Agree with Pikachu007, the option D is good.","timestamp":"1705998660.0"},{"content":"Friend is the C, and with Alter MODEL you can register the model in Vertex AI, I work in a company and I myself have registered models like this.","timestamp":"1705848960.0","poster":"Dagogi96","upvote_count":"7","comment_id":"1127889"}],"comment_id":"1121408","timestamp":"1705133760.0","content":"Selected Answer: D\nI think it's D, as model retraining should not be required unless it's specified there's new data."},{"timestamp":"1713977640.0","upvote_count":"6","content":"Selected Answer: C\nhttps://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-alter-model#alter_model_statement","comment_id":"1201525","poster":"cruise93"},{"poster":"phani49","content":"Selected Answer: C\nYou can use the ALTER MODEL statement to register your existing BigQuery ML model with Vertex AI Model Registry\n\nhttps://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-alter-model","comment_id":"1330946","upvote_count":"2","timestamp":"1734988560.0"},{"comment_id":"1324706","content":"Selected Answer: C\nNo need to export the model to Cloud Storage","timestamp":"1733855460.0","upvote_count":"1","poster":"Omi_04040"},{"comment_id":"1317004","poster":"lunalongo","content":"Selected Answer: C\nC is the best option because:\n1) Retraining the model (A/B) is not necessary (see positive feedbacks)\n2) Exporting to Cloud Storage (D) is not necessary, since you can use the ALTER MODEL statement to register it on Vertex AI Model Registry and deploy it to the Vertex AI endpoint from there\n3) Using BigQuery ML without exporting the model is the quickiest option","timestamp":"1732446300.0","upvote_count":"2"},{"comment_id":"1316997","content":"D is the best option because:\n1) BigQuery ML is excellent for training, not much for online prediction\n2) Vertex AI provides a more robust and scalable infrastructure. \n3) Exporting model from BigQuery ML to a format compatible with Vertex AI (typically Cloud Storage) is required\n\n\n***A, B, and C attempt to directly deploy from BigQuery ML, which isn't a supported workflow.","upvote_count":"1","timestamp":"1732443900.0","poster":"lunalongo"},{"comment_id":"1315956","content":"Selected Answer: C\nhttps://cloud.google.com/bigquery/docs/managing-models-vertex#register-new-bqml-model-version","upvote_count":"1","timestamp":"1732214340.0","poster":"Land3r"},{"upvote_count":"1","content":"Selected Answer: C\nIt's C","timestamp":"1727422740.0","comment_id":"1289856","poster":"hybridpro"},{"comment_id":"1271161","content":"Selected Answer: D\nThe model has already been trained and received positive feedback, so there's no need to retrain the model.","poster":"d6e1ae4","timestamp":"1724397120.0","upvote_count":"1"},{"content":"C is correct Here's why:\n1) You trained an AutoML regression model using BigQuery ML.\n2)To deploy the model for online prediction, you need to export the model in a format that is compatible with Vertex AI.\n3)Altering the model by using BigQuery ML and specifying Vertex AI as the model registry allows you to export the model in the correct format.\nOnce exported, you can deploy the model from Vertex AI Model Registry to a Vertex AI endpoint, which enables online prediction","upvote_count":"1","comment_id":"1242334","timestamp":"1720135380.0","poster":"AzureDP900"},{"content":"C is correct Here's why:\n1) You trained an AutoML regression model using BigQuery ML.\n2)To deploy the model for online prediction, you need to export the model in a format that is compatible with Vertex AI.\n3)Altering the model by using BigQuery ML and specifying Vertex AI as the model registry allows you to export the model in the correct format.\nOnce exported, you can deploy the model from Vertex AI Model Registry to a Vertex AI endpoint, which enables online prediction","upvote_count":"1","timestamp":"1720135320.0","comment_id":"1242333","poster":"AzureDP900"},{"timestamp":"1713502560.0","upvote_count":"3","poster":"gscharly","content":"Selected Answer: C\nhttps://cloud.google.com/vertex-ai/docs/model-registry/model-registry-bqml\nhttps://cloud.google.com/bigquery/docs/update_vertex","comment_id":"1198326"},{"timestamp":"1713391740.0","poster":"fitri001","upvote_count":"2","comment_id":"1197541","comments":[{"comment_id":"1197542","poster":"fitri001","timestamp":"1713391800.0","upvote_count":"1","comments":[{"poster":"pinimichele01","upvote_count":"3","timestamp":"1713685800.0","comment_id":"1199522","content":"alter the model doesn't mean retrain..."}],"content":"No Retraining: You've already trained a successful model in BigQuery ML. Retraining (Options A, B, and C) is unnecessary and adds time.\nDirect Deployment: Option D leverages existing tools for streamlined deployment. You export the model directly from BigQuery ML and import it into Vertex AI Model Registry for centralized management. Finally, you deploy the model to a Vertex AI endpoint for online predictions.\nCloud Storage: Cloud Storage provides a readily accessible location to store your exported model before deployment."}],"content":"Selected Answer: D\nYou recently used BigQuery ML to train an AutoML regression model. You shared results with your team and received positive feedback. You need to deploy your model for online prediction as quickly as possible. What should you do?\n\nA. Retrain the model by using BigQuery ML, and specify Vertex AI as the model registry. Deploy the model from Vertex AI Model Registry to a Vertex AI endpoint,\nB. Retrain the model by using Vertex Al Deploy the model from Vertex AI Model. Registry to a Vertex AI endpoint.\nC. Alter the model by using BigQuery ML, and specify Vertex AI as the model registry. Deploy the model from Vertex AI Model Registry to a Vertex AI endpoint.\nD. Export the model from BigQuery ML to Cloud Storage. Import the model into Vertex AI Model Registry. Deploy the model to a Vertex AI endpoint."},{"content":"Selected Answer: D\nD. Export the model from BigQuery ML to Cloud Storage. Import the model into Vertex AI Model Registry. Deploy the model to a Vertex AI endpoint.","timestamp":"1713175920.0","comments":[{"comment_id":"1196710","content":"why not C? it is not necessary to export in GCS","poster":"pinimichele01","comments":[{"poster":"omermahgoub","timestamp":"1713607920.0","comment_id":"1199078","content":"I changed my answer to C. GCS is not necessary","upvote_count":"2"}],"upvote_count":"1","timestamp":"1713286200.0"}],"poster":"omermahgoub","comment_id":"1195972","upvote_count":"1"},{"poster":"playerXL7","comment_id":"1195686","upvote_count":"1","content":"Selected Answer: C\nhttps://cloud.google.com/vertex-ai/docs/model-registry/model-registry-bqml","timestamp":"1713126660.0"},{"content":"Selected Answer: C\nAlter the model is correct,no need to export the model : \"You can register BigQuery ML models with the Model Registry, in order to manage them alongside your other ML models without needing to export them\"\nhttps://cloud.google.com/bigquery/docs/managing-models-vertex\na simple update is sufficient :\nhttps://cloud.google.com/bigquery/docs/update_vertex","timestamp":"1711168140.0","upvote_count":"1","poster":"alfieroy16","comment_id":"1180544"},{"upvote_count":"1","content":"Selected Answer: B\nI think the answer here is B , because even if we alter or export automl regressor model trained in BQML is not supported in vertex ai for online prediction so we need to retrain using vertex ai","comment_id":"1146887","timestamp":"1707609780.0","poster":"vaibavi"},{"timestamp":"1706944020.0","poster":"itwiz","upvote_count":"1","comment_id":"1139043","content":"C) \nhttps://cloud.google.com/bigquery/docs/create_vertex"},{"content":"Selected Answer: C\nthe answer is C, no need to export the model : \"You can register BigQuery ML models with the Model Registry, in order to manage them alongside your other ML models without needing to export them\"\nhttps://cloud.google.com/bigquery/docs/managing-models-vertex\na simple update is sufficient :\nhttps://cloud.google.com/bigquery/docs/update_vertex","timestamp":"1706698140.0","upvote_count":"4","poster":"sonicclasps","comment_id":"1136689"}],"question_images":[],"unix_timestamp":1705133760},{"id":"okQVrAcIwGewa7FatG9F","exam_id":13,"question_id":165,"discussion":[{"comment_id":"1127400","poster":"b1a8fae","upvote_count":"8","content":"Selected Answer: D\nD. You want to control how much the distribution of the data changes over time -> that's drift.","timestamp":"1705769160.0"},{"poster":"sonicclasps","upvote_count":"5","comment_id":"1136697","content":"Selected Answer: D\nthe answer cannot be C, cause your training data is not available in production. \nSo D is the only viable answer","timestamp":"1706698440.0"},{"content":"Selected Answer: C\nOption D is incorrect in my opinion. \"Feature attribution skew and drift detection\" focus on knowing how feature values are contributing to the model’s predictions, but \"training-serving skew\" is more direct and efficient to detect distribution changes that could lead to performance issues","poster":"rajshiv","comment_id":"1320734","upvote_count":"3","timestamp":"1733098560.0"},{"comment_id":"1199232","poster":"gscharly","content":"Selected Answer: D\nD, as the training data is not available","upvote_count":"2","timestamp":"1713628380.0"},{"poster":"fitri001","timestamp":"1713392160.0","content":"Selected Answer: D\nSecurity: Vertex AI Model Monitoring doesn't require uploading your training data to the cloud. It analyzes model predictions and input features on your on-premises server.\nData Distribution Shifts: Feature attribution techniques like LIME or SHAP within Vertex AI Model Monitoring can identify how different features contribute to model predictions. Detecting drifts in these feature attributions can indicate changes in the underlying data distribution compared to the training data.","upvote_count":"1","comment_id":"1197545"},{"timestamp":"1713175140.0","content":"Selected Answer: C\nFeature Attribution Skew and Drift Detection, this type of monitoring is useful in some cases, it requires access to the training and serving data for analysis. Since data cannot move to the cloud, Option D wouldn't be feasible.\n\nI vote for C. Create a Vertex AI Model Monitoring job. Enable training-serving skew detection for your model.","comments":[{"comment_id":"1199081","upvote_count":"2","timestamp":"1713608040.0","poster":"omermahgoub","content":"I changed my answer to D"}],"poster":"omermahgoub","upvote_count":"1","comment_id":"1195962"},{"upvote_count":"1","comment_id":"1191753","timestamp":"1712600160.0","poster":"pinimichele01","content":"Selected Answer: D\nthe answer cannot be C, cause your training data is not available in production."},{"poster":"pikachu007","upvote_count":"1","timestamp":"1705133940.0","content":"Selected Answer: C\nOption A and B: Vertex Explainable AI provides insights into model behavior but doesn't directly detect performance changes or concept drift. It's more suitable for understanding model decisions, not monitoring production performance.\nOption D: Feature attribution skew and drift detection requires feature attributions calculated during training, which might not be feasible without cloud access to the data.","comment_id":"1121409"}],"unix_timestamp":1705133940,"topic":"1","answer_ET":"D","answer_images":[],"answer_description":"","answer":"D","question_images":[],"question_text":"You built a deep learning-based image classification model by using on-premises data. You want to use Vertex AI to deploy the model to production. Due to security concerns, you cannot move your data to the cloud. You are aware that the input data distribution might change over time. You need to detect model performance changes in production. What should you do?","timestamp":"2024-01-13 09:19:00","url":"https://www.examtopics.com/discussions/google/view/131067-exam-professional-machine-learning-engineer-topic-1-question/","choices":{"A":"Use Vertex Explainable AI for model explainability. Configure feature-based explanations.","D":"Create a Vertex AI Model Monitoring job. Enable feature attribution skew and drift detection for your model.","C":"Create a Vertex AI Model Monitoring job. Enable training-serving skew detection for your model.","B":"Use Vertex Explainable AI for model explainability. Configure example-based explanations."},"answers_community":["D (77%)","C (23%)"],"isMC":true}],"exam":{"name":"Professional Machine Learning Engineer","lastUpdated":"11 Apr 2025","provider":"Google","numberOfQuestions":304,"isBeta":false,"isMCOnly":true,"isImplemented":true,"id":13},"currentPage":33},"__N_SSP":true}