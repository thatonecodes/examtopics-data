{"pageProps":{"questions":[{"id":"5vItqxjb6PTncTzN6RY9","answer":"B","answer_images":[],"timestamp":"2024-09-06 01:37:00","isMC":true,"question_images":[],"topic":"1","question_text":"You work for a healthcare provider that is expanding into the cloud to store and process sensitive patient data. You must ensure the chosen Google Cloud configuration meets these strict regulatory requirements:\n\n• Data must reside within specific geographic regions.\n• Certain administrative actions on patient data require explicit approval from designated compliance officers.\n• Access to patient data must be auditable.\n\nWhat should you do?","answers_community":["B (100%)"],"choices":{"B":"Deploy an Assured Workloads environment in an approved region. Configure Access Approval for sensitive operations on patient data. Enable both Cloud Audit Logs and Access Transparency.","C":"Deploy an Assured Workloads environment in multiple regions for redundancy. Utilize custom IAM roles with granular permissions. Isolate network-level data by using VPC Service Controls.","A":"Select a standard Google Cloud region. Restrict access to patient data based on user location and job function by using Access Context Manager. Enable both Cloud Audit Logging and Access Transparency.","D":"Select multiple standard Google Cloud regions for high availability. Implement Access Control Lists (ACLs) on individual storage objects containing patient data. Enable Cloud Audit Logs."},"unix_timestamp":1725579420,"exam_id":9,"discussion":[{"content":"Selected Answer: B\nhttps://cloud.google.com/assured-workloads/docs/overview","comment_id":"1324081","timestamp":"1733753160.0","upvote_count":"1","poster":"Pime13"},{"poster":"BondleB","upvote_count":"2","content":"Selected Answer: B\nOption B fulfils the given strict regulatory requirements below:\n• Data must reside within specific geographic regions.\n• Certain administrative actions on patient data require explicit approval from designated compliance officers.\n• Access to patient data must be auditable.","comment_id":"1306569","timestamp":"1730650380.0"},{"poster":"yokoyan","timestamp":"1725579420.0","comment_id":"1279235","content":"Selected Answer: B\nI think it's B.","upvote_count":"2"}],"url":"https://www.examtopics.com/discussions/google/view/147064-exam-professional-cloud-security-engineer-topic-1-question/","answer_ET":"B","question_id":191,"answer_description":""},{"id":"MwmnR81iQcIkwFHiUjE3","exam_id":9,"answers_community":["B (100%)"],"topic":"1","unix_timestamp":1725579540,"answer":"B","question_id":192,"isMC":true,"timestamp":"2024-09-06 01:39:00","answer_images":[],"question_text":"You work for a multinational organization that has systems deployed across multiple cloud providers, including Google Cloud. Your organization maintains an extensive on-premises security information and event management (SIEM) system. New security compliance regulations require that relevant Google Cloud logs be integrated seamlessly with the existing SIEM to provide a unified view of security events. You need to implement a solution that exports Google Cloud logs to your on-premises SIEM by using a push-based, near real-time approach. You must prioritize fault tolerance, security, and auto scaling capabilities. In particular, you must ensure that if a log delivery fails, logs are re-sent. What should you do?","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/147065-exam-professional-cloud-security-engineer-topic-1-question/","choices":{"D":"Utilize custom firewall rules to allow your SIEM to directly query Google Cloud logs. Implement a Cloud Function that notifies the SIEM of a failed delivery and triggers a retry action.","A":"Create a Pub/Sub topic for log aggregation. Write a custom Python script on a Cloud Function Leverage the Cloud Logging API to periodically pull logs from Google Cloud and forward the logs to the SIEM. Schedule the Cloud Function to run twice per day.","B":"Collect all logs into an organization-level aggregated log sink and send the logs to a Pub/Sub topic. Implement a primary Dataflow pipeline that consumes logs from this Pub/Sub topic and delivers the logs to the SIEM. Implement a secondary Dataflow pipeline that replays failed messages.","C":"Deploy a Cloud Logging sink with a filter that routes all logs directly to a syslog endpoint. The endpoint is based on a single Compute Engine hosted on Google Cloud that routes all logs to the on-premises SIEM. Implement a Cloud Function that triggers a retry action in case of failure."},"discussion":[{"comment_id":"1324022","poster":"Zek","timestamp":"1733745900.0","upvote_count":"1","content":"Selected Answer: B\nB - https://cloud.google.com/architecture/stream-logs-from-google-cloud-to-splunk"},{"timestamp":"1732715280.0","upvote_count":"1","content":"Selected Answer: B\nB 100%.","comment_id":"1318696","poster":"MoAk"},{"content":"Selected Answer: B\nuse pub/sub. A is wrong as it says that \"periodically pull logs\" - Not near real-time and need programing works.","timestamp":"1731576660.0","upvote_count":"1","comment_id":"1311810","poster":"KLei"},{"timestamp":"1730863680.0","poster":"BondleB","content":"Selected Answer: B\nhttps://cloud.google.com/architecture/stream-logs-from-google-cloud-to-splunk","upvote_count":"1","comment_id":"1307651"},{"content":"Selected Answer: B\nI think it's B.","comment_id":"1279236","timestamp":"1725579540.0","upvote_count":"1","poster":"yokoyan"}],"answer_ET":"B","answer_description":""},{"id":"sDAuAib2py6fOSErTJQJ","answer":"D","isMC":true,"unix_timestamp":1725579600,"answer_images":[],"answers_community":["D (100%)"],"url":"https://www.examtopics.com/discussions/google/view/147066-exam-professional-cloud-security-engineer-topic-1-question/","topic":"1","choices":{"B":"Deploy a Security Command Center source to detect Compute Engine instances created outside the EU. Use a custom remediation function to automatically relocate the instances, run the function once a day.","D":"Set an organization policy that denies the creation of Compute Engine instances outside the EU. Apply the policy to the appropriate projects. Identify existing non-compliant instances and migrate the instances to compliant EU regions.","A":"Use a third-party configuration management tool to monitor the location of Compute Engine instances. Automatically delete or migrate non-compliant instances, including existing deployments.","C":"Use organization policy constraints in Resource Manager to enforce allowed regions for Compute Engine instance creation within specific projects."},"question_images":[],"question_id":193,"discussion":[{"poster":"Pime13","timestamp":"1733749320.0","upvote_count":"1","comment_id":"1324054","content":"Selected Answer: D\nhttps://cloud.google.com/resource-manager/docs/organization-policy/defining-locations-supported-services#compute-engine\n\nFor example, an instance template is a global resource, but you might specify regional or zonal disks in an instance template. Those disks are subject to the resource locations constraints, so, in your instance template, you must specify disks in regions and zones that your org policy permits."},{"timestamp":"1733746080.0","upvote_count":"1","comment_id":"1324028","poster":"Zek","content":"Selected Answer: D\nhttps://cloud.google.com/resource-manager/docs/organization-policy/defining-locations-supported-services"},{"poster":"MoAk","comment_id":"1318700","content":"Selected Answer: D\nhttps://cloud.google.com/resource-manager/docs/organization-policy/defining-locations-supported-services","timestamp":"1732715760.0","upvote_count":"1"},{"comment_id":"1279237","timestamp":"1725579600.0","comments":[{"content":"https://cloud.google.com/resource-manager/docs/organization-policy/defining-locations-supported-services","upvote_count":"1","comment_id":"1318699","timestamp":"1732715700.0","poster":"MoAk"}],"poster":"yokoyan","content":"Selected Answer: D\nI think it's D.","upvote_count":"3"}],"answer_ET":"D","exam_id":9,"answer_description":"","question_text":"You work for a global company. Due to compliance requirements, certain Compute Engine instances that reside within specific projects must be located exclusively in cloud regions within the European Union (EU). You need to ensure that existing non-compliant workloads are remediated and prevent future Compute Engine instances from being launched in restricted regions. What should you do?","timestamp":"2024-09-06 01:40:00"},{"id":"bjznM1jJLr3KgZ7JsC7V","answers_community":["C (44%)","B (33%)","D (22%)"],"unix_timestamp":1725579600,"exam_id":9,"url":"https://www.examtopics.com/discussions/google/view/147067-exam-professional-cloud-security-engineer-topic-1-question/","answer_images":[],"answer_description":"","discussion":[{"timestamp":"1733749860.0","content":"Selected Answer: C\nIn general, the CMEK key does not encrypt metadata associated with your operation, like the job's name and region, or a dataset's display name. Metadata associated with operations is always encrypted using Google's default encryption mechanism.\n\nhttps://cloud.google.com/vertex-ai/docs/general/cmek","poster":"Pime13","comment_id":"1324056","upvote_count":"1"},{"upvote_count":"1","poster":"Zek","content":"Selected Answer: C\nC sounds right\n\nhttps://cloud.google.com/vertex-ai/docs/general/cmek#resources\nIn general, the CMEK key does not encrypt metadata associated with your operation, like the job's name and region, or a dataset's display name. Metadata associated with operations is always encrypted using Google's default encryption mechanism.","comment_id":"1324031","timestamp":"1733746440.0"},{"upvote_count":"1","comment_id":"1320883","timestamp":"1733134140.0","content":"Selected Answer: C\nAns is C\n\nGuys before recommending an answer please read the doc. \n\nIn general, the CMEK key does not encrypt metadata associated with your operation, like the job's name and region, or a dataset's display name. Metadata associated with operations is always encrypted using Google's default encryption mechanism.\nhttps://cloud.google.com/vertex-ai/docs/general/cmek#benefits","poster":"kalbd2212"},{"poster":"nah99","timestamp":"1732742700.0","upvote_count":"1","content":"Selected Answer: C\nC seems best.\nNOT B: \"In general, the CMEK key does not encrypt metadata associated with your operation\"\nNOT D: \"If you want to control your encryption keys, then you can use customer-managed encryption keys (CMEKs) \"\n\nhttps://cloud.google.com/vertex-ai/docs/general/cmek#resources","comment_id":"1318905"},{"poster":"3fd692e","comment_id":"1309453","content":"Selected Answer: B\nB is correct. D looks good but uses Google Managed Encryption Keys which violates the requirement of control the encryption resources outlined in the question.","timestamp":"1731245820.0","upvote_count":"2"},{"timestamp":"1730866140.0","upvote_count":"2","poster":"BondleB","comment_id":"1307659","content":"Selected Answer: D\nOption D enforces that all supported data types must be encrypted by key materials that reside in the Europe region."},{"comment_id":"1296664","poster":"dat987","upvote_count":"2","content":"Answer is C\n\nThe CMEK key doesn't encrypt metadata, like the instance's name and region, associated with your Vertex AI Workbench instance. Metadata associated with Vertex AI Workbench instances is always encrypted using Google's default encryption mechanism.","timestamp":"1728775380.0"},{"upvote_count":"1","timestamp":"1725579600.0","poster":"yokoyan","comments":[{"timestamp":"1730866500.0","upvote_count":"1","poster":"BondleB","comment_id":"1307663","content":"In general, the CMEK key does not encrypt metadata associated with your operation, like the job's name and region, or a dataset's display name. Metadata associated with operations is always encrypted using Google's default encryption mechanism."}],"content":"Selected Answer: B\nI think it's B.","comment_id":"1279238"}],"question_id":194,"answer_ET":"C","topic":"1","isMC":true,"choices":{"A":"Encrypt the code, training data, and metadata with Google default encryption. Use customer-managed encryption keys (CMEK) for the trained models exported to Cloud Storage buckets.","C":"Encrypt the code, training data, and exported trained models with customer-managed encryption keys (CMEK).","D":"Encrypt the code, training data, and metadata with Google default encryption. Implement an organization policy that enforces a constraint to restrict the Cloud KMS location to the Europe region.","B":"Encrypt the code, training data, metadata, and exported trained models with customer-managed encryption keys (CMEK)."},"answer":"C","question_text":"You are working with developers to secure custom training jobs running on Vertex AI. For compliance reasons, all supported data types must be encrypted by key materials that reside in the Europe region and are controlled by your organization. The encryption activity must not impact the training operation in Vertex AI. What should you do?","question_images":[],"timestamp":"2024-09-06 01:40:00"},{"id":"M9IBjY7rCXGSqtMDIV04","discussion":[{"comment_id":"1351738","content":"Selected Answer: C\nAnswer should be C. \nA - a data protection job just finds data that might contain PII. If you run it on all buckets in all regions, that won't confirm with the requirements of detecting buckets outside the EU. \nB - Irrelevant. \nC - Compliance monitoring in SCC will do this job for you. Just go in, click the compliance you're interested in (e.g. GDPR, healthcare data etc), and it will tell you why you're not compliant and where. \nD - Irrelevant.","upvote_count":"1","poster":"LegoJesus","timestamp":"1738738620.0"},{"upvote_count":"1","timestamp":"1732716960.0","poster":"MoAk","content":"Selected Answer: A\nDefinitely A","comment_id":"1318708"},{"content":"Selected Answer: A\nSpecifying the info Type of data to be detected allows to find storage buckets outside the EU that contain healthcare data.","upvote_count":"1","timestamp":"1730867580.0","poster":"BondleB","comment_id":"1307666"}],"question_text":"Your EU-based organization stores both Personally Identifiable Information (PII) and non-PII data in Cloud Storage buckets across multiple Google Cloud regions. EU data privacy laws require that the PII data must not be stored outside of the EU. To help meet this compliance requirement, you want to detect if Cloud Storage buckets outside of the EU contain healthcare data. What should you do?","answers_community":["A (80%)","C (20%)"],"answer_description":"","isMC":true,"unix_timestamp":1725579660,"choices":{"B":"Create a log sink with a filter on resourceLocation.currentLocations. Trigger an alert if a log message appears with a non- EUcountry.","D":"Enforce the gcp.resourceLocations organization policy and add \"EU\" in a custom rule that only applies on resources with the tag \"healthcare\".","C":"Activate Security Command Center Premium. Use compliance monitoring to detect resources that do not follow the applicable healthcare regulation.","A":"Create a Sensitive Data Protection job. Specify the infoType of data to be detected and run the job across all Google Cloud Storage buckets."},"url":"https://www.examtopics.com/discussions/google/view/147068-exam-professional-cloud-security-engineer-topic-1-question/","answer_ET":"A","answer_images":[],"question_id":195,"topic":"1","timestamp":"2024-09-06 01:41:00","exam_id":9,"question_images":[],"answer":"A"}],"exam":{"lastUpdated":"11 Apr 2025","isBeta":false,"provider":"Google","numberOfQuestions":321,"isImplemented":true,"name":"Professional Cloud Security Engineer","isMCOnly":false,"id":9},"currentPage":39},"__N_SSP":true}