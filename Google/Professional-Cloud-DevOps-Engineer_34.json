{"pageProps":{"questions":[{"id":"Fu96WNzKLzpM2PYLjHlW","url":"https://www.examtopics.com/discussions/google/view/64832-exam-professional-cloud-devops-engineer-topic-1-question-71/","topic":"1","answer_images":[],"timestamp":"2021-10-26 18:52:00","unix_timestamp":1635267120,"question_id":166,"choices":{"B":"Use Stackdriver Monitoring to check for a spike in CPU or memory usage for the affected region.","A":"Reroute the user traffic from the affected region to other regions that don't report issues.","C":"Add an extra node pool that consists of high memory and high CPU machine type instances to the cluster.","D":"Use Stackdriver Logging to filter on the clusters in the affected region, and inspect error messages in the logs."},"answer_description":"","discussion":[{"content":"A, reroute trafic to unblock access to site.","upvote_count":"16","comment_id":"468180","timestamp":"1666803120.0","poster":"job_search83"},{"upvote_count":"2","poster":"jomonkp","comment_id":"1086177","timestamp":"1733144460.0","content":"Selected Answer: A\noption A"},{"timestamp":"1705343460.0","content":"Selected Answer: A\nMy answer would be option A, to reroute user traffic from the affected region to other regions that don't report issues, in order to immediately resolve the problem for users and minimize impact, and then use option D, Stackdriver Logging, to investigate the root cause of the issue. This approach aligns with SRE best practices of resolving incidents quickly and then conducting a post-mortem analysis to prevent similar incidents from happening in the future.","poster":"JonathanSJ","comment_id":"776923","upvote_count":"3"},{"content":"Selected Answer: A\nA is the answer.","comment_id":"702060","timestamp":"1698055680.0","poster":"zellck","upvote_count":"1"},{"upvote_count":"4","comment_id":"535502","poster":"cyrus86","content":"Selected Answer: A\nGoogle always aims to first stop the impact of an incident, and then find the root cause (unless the root cause just happens to be identified early on).","timestamp":"1675001940.0"},{"comment_id":"528210","content":"A is correct","timestamp":"1674198600.0","poster":"Sekierer","upvote_count":"1"},{"comment_id":"524945","poster":"KyubiBlaze","timestamp":"1673873760.0","upvote_count":"2","content":"Selected Answer: A\nIssue is that one region is not serving requests. First thing to resolve is make the application responsive to users as soon as possible affected by this issue. Look into the error logs later."},{"timestamp":"1668182160.0","comment_id":"476341","upvote_count":"2","content":"A. Reroute the traffic first","poster":"Manh"},{"timestamp":"1667802180.0","upvote_count":"3","poster":"MF2C","content":"A - resume service first","comment_id":"473769"},{"content":"Anyone available for didscussion please lets collaborate","comment_id":"472976","upvote_count":"2","poster":"TNT87","timestamp":"1667638980.0"}],"question_images":[],"question_text":"You support a popular mobile game application deployed on Google Kubernetes Engine (GKE) across several Google Cloud regions. Each region has multiple\nKubernetes clusters. You receive a report that none of the users in a specific region can connect to the application. You want to resolve the incident while following Site Reliability Engineering practices. What should you do first?","isMC":true,"answers_community":["A (100%)"],"answer":"A","answer_ET":"A","exam_id":6},{"id":"7Ah3j181C7fNJlPX6cFl","url":"https://www.examtopics.com/discussions/google/view/64834-exam-professional-cloud-devops-engineer-topic-1-question-72/","timestamp":"2021-10-26 18:54:00","answer_description":"","answers_community":["AC (100%)"],"answer_ET":"AC","choices":{"D":"Your opinion of the incident's severity compared to past incidents","A":"An explanation of the root cause of the incident.","B":"A list of employees responsible for causing the incident","C":"A list of action items to prevent a recurrence of the incident","E":"Copies of the design documents for all the services impacted by the incident"},"answer_images":[],"question_id":167,"exam_id":6,"topic":"1","question_text":"You are writing a postmortem for an incident that severely affected users. You want to prevent similar incidents in the future. Which two of the following sections should you include in the postmortem? (Choose two.)","discussion":[{"timestamp":"1666857600.0","comment_id":"468448","poster":"TNT87","upvote_count":"17","content":"Ans is AC"},{"content":"Ans: AC","poster":"Alaaelanwr","timestamp":"1667066460.0","comment_id":"469922","upvote_count":"7"},{"upvote_count":"1","poster":"jomonkp","comment_id":"1086178","content":"Selected Answer: AC\noption A and C","timestamp":"1733144520.0"},{"comment_id":"776929","content":"Selected Answer: AC\nA. An explanation of the root cause of the incident.\nC. A list of action items to prevent a recurrence of the incident.","timestamp":"1705343640.0","upvote_count":"2","poster":"JonathanSJ"},{"timestamp":"1701020340.0","upvote_count":"1","content":"Ans A&C. B is incorrect as SRE recommends blameless culture and listing employees responsible portrays blaming the incident on employees responsible.","comment_id":"727718","poster":"DoodleDo"},{"comment_id":"727406","timestamp":"1700989860.0","upvote_count":"1","content":"clearly its AC","poster":"mohan999"},{"content":"Selected Answer: AC\nAC is the answer.","poster":"zellck","upvote_count":"2","comment_id":"702059","timestamp":"1698055560.0"},{"comment_id":"535506","upvote_count":"3","poster":"cyrus86","timestamp":"1675002180.0","content":"Selected Answer: AC\nFor a postmortem to be truly blameless, it must focus on identifying the contributing causes of the incident without indicting any individual or team for bad or inappropriate behavior."},{"comment_id":"528211","timestamp":"1674198660.0","content":"A and C are correct","poster":"Sekierer","upvote_count":"1"},{"upvote_count":"2","poster":"KyubiBlaze","content":"Selected Answer: AC\nWhy it occurred? and How to avoid?\nNever choose an answer that blames a human.","timestamp":"1673873880.0","comment_id":"524947"},{"upvote_count":"5","poster":"MF2C","timestamp":"1667802180.0","content":"A n C are correct","comment_id":"473770"},{"upvote_count":"1","poster":"TNT87","content":"https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons","timestamp":"1666857900.0","comment_id":"468451"},{"comment_id":"468183","poster":"job_search83","upvote_count":"4","content":"A,C explanation + list of actions to prevent in the future","timestamp":"1666803240.0"}],"question_images":[],"unix_timestamp":1635267240,"isMC":true,"answer":"AC"},{"id":"655ZIW0p5QGHGBkMoxSr","question_images":[],"answers_community":["A (100%)"],"isMC":true,"discussion":[{"poster":"TNT87","comment_id":"469194","timestamp":"1666954560.0","content":"I do agree to A as the answer.","upvote_count":"12"},{"content":"Selected Answer: A\noption A","poster":"jomonkp","upvote_count":"2","comment_id":"1086211","timestamp":"1733146800.0"},{"comments":[{"upvote_count":"2","timestamp":"1705344000.0","poster":"JonathanSJ","content":"B. Using Node taints with NoExecute could be used to prevent pods from being scheduled on certain nodes, but it would not be the best option for a phased rollout as it does not allow for a specific percentage or number of pods to be updated.\nC. A replica set in the deployment specification is used for ensuring that a specified number of replicas of a pod are running at any given time, but it does not provide a way to perform a phased rollout.\nD. A stateful set with parallel pod management policy is used for managing stateful applications, but it also does not provide a way to perform a phased rollout.\nThe option A, Using a partitioned rolling update, allows you to specify the percentage of pods that should be updated at a time, so it is the best option for performing a phased rollout.","comment_id":"776935"}],"content":"Selected Answer: A\nA partitioned rolling update allows you to control the percentage of pods that are updated at a time, which allows you to perform a phased rollout. This way you can incrementally test and monitor the new feature, before it is deployed to all the pods. This approach is useful when you want to minimize the risk of introducing new bugs or breaking changes in your production environment, it allows you to have more control over the process, and it's less likely to cause service disruption, or to have all the pods down at the same time.","upvote_count":"2","timestamp":"1705343880.0","poster":"JonathanSJ","comment_id":"776931"},{"content":"Selected Answer: A\ngoing with A) since is the only which makes sense","timestamp":"1701886080.0","poster":"WhyIronMan","comment_id":"737102","upvote_count":"1"},{"upvote_count":"1","timestamp":"1698226440.0","poster":"AzureDP900","comment_id":"703734","content":"A is right https://cloud.google.com/kubernetes-engine/docs/concepts/statefulset#partitioning_rolling_updates\nPartitioning is useful if you want to stage an update, roll out a canary, or perform a phased roll out.\n\nWhen you partition an update, all Pods with an ordinal greater than or equal to the partition value are updated when you update the StatefulSet’s Pod specification. Pods with an ordinal less than the partition value are not updated and, even if they are deleted, are recreated using the previous version of the specification. If the partition value is greater than the number of replicas, the updates are not propagated to the Pods."},{"content":"Selected Answer: A\nA is the answer.\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps#partitioning_a_rollingupdate\nPartitioning is useful if you want to stage an update, roll out a canary, or perform a phased roll out.","timestamp":"1698055380.0","upvote_count":"4","poster":"zellck","comment_id":"702058"},{"poster":"ramzez4815","comment_id":"681360","content":"Selected Answer: A\nA is the clear answer","timestamp":"1695869640.0","upvote_count":"3"},{"poster":"Sekierer","upvote_count":"2","content":"A is correct","comment_id":"528213","timestamp":"1674198720.0"},{"comments":[{"poster":"paul223344","upvote_count":"2","content":"IMHO, the question mentioned: a \"PHASED ROLLOUT\" to \"HALF\" of the web server pods. \nSo we use .spec.updateStrategy field to partition a RollingUpdate for the Pods in a StatefulSet.","timestamp":"1681876140.0","comment_id":"587966"}],"content":"A - the question is incomplete ! Nothing shows that we are using statefulsets ..","upvote_count":"3","comment_id":"523620","timestamp":"1673712960.0","poster":"helg"},{"comment_id":"504609","content":"A => https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#partitions","timestamp":"1671419940.0","upvote_count":"3","poster":"bob_builder"},{"upvote_count":"2","poster":"not_thanos","timestamp":"1671292800.0","comment_id":"503773","content":"https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps#partitioning_a_rollingupdate\n\npartition rollout only works if the workload is stateful. Nothing in the question tells us this."},{"timestamp":"1668069780.0","poster":"Shasha1","upvote_count":"2","comment_id":"475292","content":"A\nhttps://medium.com/velotio-perspectives/exploring-upgrade-strategies-for-stateful-sets-in-kubernetes-c02b8286f251"}],"timestamp":"2021-10-28 12:56:00","exam_id":6,"question_text":"You are ready to deploy a new feature of a web-based application to production. You want to use Google Kubernetes Engine (GKE) to perform a phased rollout to half of the web server pods.\nWhat should you do?","answer":"A","question_id":168,"answer_images":[],"topic":"1","unix_timestamp":1635418560,"answer_description":"","choices":{"A":"Use a partitioned rolling update.","C":"Use a replica set in the deployment specification.","B":"Use Node taints with NoExecute.","D":"Use a stateful set with parallel pod management policy."},"url":"https://www.examtopics.com/discussions/google/view/65003-exam-professional-cloud-devops-engineer-topic-1-question-73/","answer_ET":"A"},{"id":"uezhGUEOS5MB56fRYsKw","url":"https://www.examtopics.com/discussions/google/view/65079-exam-professional-cloud-devops-engineer-topic-1-question-74/","question_text":"You are responsible for the reliability of a high-volume enterprise application. A large number of users report that an important subset of the application's functionality `\" a data intensive reporting feature `\" is consistently failing with an HTTP 500 error. When you investigate your application's dashboards, you notice a strong correlation between the failures and a metric that represents the size of an internal queue used for generating reports. You trace the failures to a reporting backend that is experiencing high I/O wait times. You quickly fix the issue by resizing the backend's persistent disk (PD). How you need to create an availability\nService Level Indicator (SLI) for the report generation feature. How would you define it?","question_id":169,"answer_description":"","topic":"1","unix_timestamp":1635519780,"answers_community":["B (83%)","C (17%)"],"exam_id":6,"timestamp":"2021-10-29 17:03:00","answer_images":[],"discussion":[{"poster":"NXD","comments":[{"timestamp":"1651897920.0","comment_id":"473773","content":"B is more like SLO rather than SLI.","upvote_count":"3","poster":"MF2C"}],"timestamp":"1651351500.0","comment_id":"470944","upvote_count":"20","content":"The question is: \"create an availability SLI for the report generation feature.\" => availability.\n\nB is correct.\nOthers aren't availability SLI."},{"comment_id":"475296","upvote_count":"7","poster":"Shasha1","timestamp":"1652165580.0","content":"B is correct, availability = good time/ total time.","comments":[{"content":"AGREE WITH B","comment_id":"476613","poster":"Manh","upvote_count":"3","timestamp":"1652313000.0"}]},{"content":"C and D are SLOs (they use a threshold). B seems to be more like an indicator and didn't rely exclusivelly on PD's I/O. Any issue that disturb the correct reports finalization could be detected with this SLI","poster":"Meyucho","comment_id":"1100105","upvote_count":"1","timestamp":"1718745480.0"},{"content":"Selected Answer: B\noption B","comment_id":"1086213","timestamp":"1717328640.0","upvote_count":"2","poster":"jomonkp"},{"upvote_count":"1","poster":"jacknguyen","timestamp":"1709536440.0","content":"B is correct.","comment_id":"998226"},{"comment_id":"776944","content":"Selected Answer: B\nB. As the proportion of report generation requests that result in a successful response is a valid availability Service Level Indicator (SLI) for the report generation feature. This indicator measures the percentage of requests for report generation that are successfully completed, and it is an indicator of the service availability. This SLI provides a clear and measurable way to track the availability of the report generation feature. It is a simple and easy to understand metric, that it can be easily monitored and reported. It can be used to track the performance of the report generation feature over time and detect any potential issues that may cause it to become unavailable. It also allows you to detect and diagnose issues in the system quickly and take appropriate action to mitigate them. Additionally, it aligns well with the customer's expectation of the report generation feature as they want to see a high percentage of successful report generation requests, which indicates that the feature is working correctly.","timestamp":"1689439740.0","upvote_count":"2","poster":"JonathanSJ"},{"comment_id":"751447","timestamp":"1687286400.0","poster":"leandrojpg","upvote_count":"2","content":"https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring/sli-metrics/overview?hl=pt-br","comments":[{"upvote_count":"1","poster":"leandrojpg","content":"ANS BBB see link","timestamp":"1687318800.0","comment_id":"751451"}]},{"timestamp":"1682244000.0","poster":"zellck","upvote_count":"1","content":"Selected Answer: B\nB is the answer.","comment_id":"702052"},{"content":"Answer : B. the proportion of report generation requests that result in a successful response\n\nQuestion: create an AVAILABILITY SLI for the report generation feature\n\nAccording to SRE Workbook, one of potential SLI is as below:\n* Type of service: Request-driven\n* Type of SLI: Availability\n* Description: The proportion of requests that resulted in a successful response.\n\nhttps://sre.google/workbook/implementing-slos/","comment_id":"587997","poster":"paul223344","upvote_count":"4","timestamp":"1666156440.0"},{"comment_id":"576350","content":"Selected Answer: B\nB is correct","timestamp":"1664298420.0","upvote_count":"2","poster":"maddy94"},{"poster":"cyrus86","comment_id":"535512","timestamp":"1659097920.0","content":"Selected Answer: C\nService Level Indicator, is a key metric used to determine whether or not the SLO is being met.\nTo prevent overcomplicating things, it’s important to keep things simple and choose the right key metrics to monitor. Here Queue size is the key metric.","upvote_count":"2"},{"timestamp":"1658294040.0","comment_id":"528214","poster":"Sekierer","upvote_count":"1","content":"Selected Answer: B\nB is correct"},{"upvote_count":"3","timestamp":"1657969440.0","content":"Eliminate A,\nEliminate C and D. SLI are always based on facts, not on KNOWN GOOD\nAnswer B : good/total","poster":"KyubiBlaze","comment_id":"524949"},{"comment_id":"510194","poster":"TNT87","timestamp":"1656315600.0","upvote_count":"2","content":"Selected Answer: B\nB B B B is the answer!"},{"upvote_count":"2","poster":"sindra","content":"should be D.. since the throughput and IOPS become the issue","timestamp":"1651326000.0","comment_id":"470252"},{"comment_id":"470135","upvote_count":"2","content":"Why not C, you already have a metric that represents the size of an internal queue","poster":"giammydell","timestamp":"1651305000.0"},{"poster":"Nik22","upvote_count":"1","comment_id":"469815","content":"D for sure","timestamp":"1651244580.0"}],"isMC":true,"answer":"B","question_images":[],"answer_ET":"B","choices":{"A":"As the I/O wait times aggregated across all report generation backends","C":"As the application's report generation queue size compared to a known-good threshold","B":"As the proportion of report generation requests that result in a successful response","D":"As the reporting backend PD throughout capacity compared to a known-good threshold"}},{"id":"AUu7LYe73PB4fdKutFn2","url":"https://www.examtopics.com/discussions/google/view/64835-exam-professional-cloud-devops-engineer-topic-1-question-75/","unix_timestamp":1635267360,"discussion":[{"content":"D, opentelemetry","upvote_count":"22","timestamp":"1666803360.0","comment_id":"468185","poster":"job_search83"},{"content":"Selected Answer: D\nThis is the major usecase for Cloud Trace","comment_id":"568266","upvote_count":"9","poster":"junn8","timestamp":"1678873800.0"},{"poster":"jomonkp","comment_id":"1086216","timestamp":"1733147100.0","upvote_count":"1","content":"Selected Answer: D\nOption D"},{"upvote_count":"2","comment_id":"777009","timestamp":"1705347780.0","content":"Selected Answer: D\nD. Use a distributed tracing framework such as OpenTelemetry or Stackdriver Trace. Distributed tracing allows you to trace the path of a request as it travels through multiple services and identify where delays may be occurring. This can provide detailed information about the request and response timings for each service, making it easier to pinpoint which services are causing delays in your application. OpenTelemetry and Stackdriver Trace are both available on GCP, and provide easy integration with Kubernetes and other GCP services.","poster":"JonathanSJ"},{"timestamp":"1698055020.0","comment_id":"702047","upvote_count":"2","poster":"zellck","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/trace/docs/overview\nCloud Trace, a distributed tracing system for Google Cloud, helps you understand how long it takes your application to handle incoming requests from users or other applications, and how long it takes to complete operations like RPC calls performed when handling the requests."},{"comment_id":"700662","content":"Selected Answer: D\nCloud Trace is a distributed tracing system that collects latency data from your applications and displays it in the Google Cloud Console.","poster":"pradoUA","timestamp":"1697877060.0","upvote_count":"2"},{"poster":"maddy94","upvote_count":"3","timestamp":"1679937120.0","content":"Selected Answer: D\nD is correct","comment_id":"576352"},{"timestamp":"1675003800.0","content":"Selected Answer: C\nCorrect answer is C. \nCheck this link - https://cloud.google.com/architecture/processing-logs-at-scale-using-dataflow?hl=en\nD cannot be the answer because Strackdriver tracing is useful in troubleshooting a single application ( providing a lot of information). Here ques is about multiple services in the downstream. Read the ques carefully.","upvote_count":"3","poster":"cyrus86","comment_id":"535529"},{"content":"D is correct","poster":"Sekierer","upvote_count":"1","comment_id":"528215","timestamp":"1674198960.0"},{"timestamp":"1670460180.0","content":"https://cloud.google.com/dataflow/docs/guides/using-monitoring-intf","comment_id":"496426","upvote_count":"1","poster":"TNT87"},{"poster":"TNT87","timestamp":"1670438040.0","upvote_count":"1","content":"This solution also explains how you can change the pipeline to run in streaming mode, for low-latency, asynchronous log processing","comment_id":"496242"},{"timestamp":"1670437800.0","upvote_count":"2","content":"https://cloud.google.com/architecture/processing-logs-at-scale-using-dataflow?hl=en\nKindly read this and say why is C wrong","comments":[{"content":"Dataflow is for logs. Here we need metrics","poster":"ric79","timestamp":"1678378500.0","upvote_count":"2","comment_id":"564157"}],"poster":"TNT87","comment_id":"496241"},{"poster":"giammydell","comment_id":"471536","timestamp":"1667375280.0","upvote_count":"4","content":"Ans: D"},{"poster":"Dreamingjin","content":"B is correct","timestamp":"1667324160.0","comment_id":"471346","upvote_count":"1"}],"answer_description":"","answer":"D","answer_images":[],"exam_id":6,"timestamp":"2021-10-26 18:56:00","answers_community":["D (86%)","14%"],"answer_ET":"D","choices":{"C":"Create a Dataflow pipeline to analyze service metrics in real time.","D":"Use a distributed tracing framework such as OpenTelemetry or Stackdriver Trace.","A":"Analyze VPC flow logs along the path of the request.","B":"Investigate the Liveness and Readiness probes for each service."},"topic":"1","question_text":"You have an application running in Google Kubernetes Engine. The application invokes multiple services per request but responds too slowly. You need to identify which downstream service or services are causing the delay. What should you do?","question_id":170,"question_images":[],"isMC":true}],"exam":{"name":"Professional Cloud DevOps Engineer","isBeta":false,"numberOfQuestions":196,"isImplemented":true,"lastUpdated":"11 Apr 2025","isMCOnly":true,"id":6,"provider":"Google"},"currentPage":34},"__N_SSP":true}