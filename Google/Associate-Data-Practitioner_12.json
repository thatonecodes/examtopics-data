{"pageProps":{"questions":[{"id":"X4oZY0BPjIUkweIumlsl","answers_community":["B (100%)"],"isMC":true,"timestamp":"2025-02-26 19:37:00","choices":{"B":"Use Cloud Data Fusion to transform the data. Store the cleaned data in BigQuery.","A":"Use Cloud Run functions to create a serverless data cleaning pipeline. Store the cleaned data in BigQuery.","C":"Load the data into BigQuery, and inspect the data by using SQL queries. Use Dataflow to transform the data and remove any errors.","D":"Use Apache Beam to read the data and perform the necessary cleaning and transformation operations. Store the cleaned data in BigQuery."},"question_images":[],"question_text":"You work for a healthcare company that has a large on-premises data system containing patient records with personally identifiable information (PII) such as names, addresses, and medical diagnoses. You need a standardized managed solution that de-identifies PII across all your data feeds prior to ingestion to Google Cloud. What should you do?","question_id":56,"exam_id":2,"answer_description":"","answer":"B","answer_images":[],"unix_timestamp":1740595020,"topic":"1","answer_ET":"B","discussion":[{"timestamp":"1743261240.0","content":"Selected Answer: B\nA isnt right as Cloud Run isn't well suited to Data pipelines and generally isn't recommended. It *can* handle processing data, but not large volumes of batch data and isn't intended as an ETL tool.\nC isn't right because Ingesting first into BigQuery doesn't meet the requirement to cleansing BEFORE ingestion.\nD isn't right because Apache BEAM isn't a managed solution (although if the data had to be cleansed before leaving the on prem network it might be a suitable option to install on prem)\n\nTherefore B (Data Fusion) is the best opinion. If DataFlow was here, then that would also be a good choice - perhaps a better one - but without it, Fusion is the obvious winner.","comment_id":"1411735","upvote_count":"1","poster":"JAGLees"},{"comment_id":"1365748","poster":"n2183712847","upvote_count":"1","timestamp":"1741237020.0","content":"Selected Answer: B\nThe best option is B. Cloud Data Fusion. Option B is best because Data Fusion is a managed, visual, standardized data integration service ideal for building de-identification pipelines. Option A (Cloud Run functions) is incorrect because it requires more coding and is less inherently standardized for pipelines. Option C (Load to BigQuery first) is incorrect because it violates the requirement to de-identify before ingestion, creating a security risk. Option D (Apache Beam/Dataflow) is incorrect because while powerful, it's more code-centric and less of a pre-built managed solution compared to Data Fusion. Therefore, Option B, Cloud Data Fusion, is the best managed and standardized solution for pre-ingestion PII de-identification."},{"upvote_count":"1","timestamp":"1740595020.0","content":"Selected Answer: B\nCloud Data Fusion can be used to Sensitive Protection Service to de-identify feeds. However, Cloud Dataflow (a Google managed version of Beam) is the more general approach being used. I am only selecting Data Fusion over Beam because it is a named Google service. Had they said Dataflow, I would have gone there instead.","comment_id":"1362243","poster":"rich_maverick"}],"url":"https://www.examtopics.com/discussions/google/view/157159-exam-associate-data-practitioner-topic-1-question-6/"},{"id":"hlRini97iZZaLlrzdjeP","exam_id":2,"discussion":[{"upvote_count":"1","timestamp":"1741236360.0","comment_id":"1365737","content":"Selected Answer: B\nThe best option is B. Materialized view in new dataset + Data Viewer & Job User roles. Option B is best because it uses a view to limit data access and dataset-level permissions for least privilege. Option A (Job User only) is incorrect because it grants no data access. Option C (New project & Data Owner) is incorrect because it's overly complex and too permissive (Data Owner role). Option D (Project Data Viewer) is incorrect because it grants access to all datasets, including sensitive ones. Therefore, Option B is the most secure and least privileged way to grant access to specific data.","poster":"n2183712847"}],"question_text":"Your organization has highly sensitive data that gets updated once a day and is stored across multiple datasets in BigQuery. You need to provide a new data analyst access to query specific data in BigQuery while preventing access to sensitive data. What should you do?","answers_community":["B (100%)"],"isMC":true,"question_id":57,"choices":{"A":"Grant the data analyst the BigQuery Job User IAM role in the Google Cloud project.","D":"Grant the data analyst the BigQuery Data Viewer IAM role in the Google Cloud project.","C":"Create a new Google Cloud project, and copy the limited data into a BigQuery table. Grant the data analyst the BigQuery Data Owner IAM role in the new Google Cloud project.","B":"Create a materialized view with the limited data in a new dataset. Grant the data analyst BigQuery Data Viewer IAM role in the dataset and the BigQuery Job User IAM role in the Google Cloud project."},"answer":"B","url":"https://www.examtopics.com/discussions/google/view/157641-exam-associate-data-practitioner-topic-1-question-60/","answer_images":[],"topic":"1","answer_ET":"B","timestamp":"2025-03-06 05:46:00","question_images":[],"unix_timestamp":1741236360,"answer_description":""},{"id":"wKlr6wCslivlmyQsflJL","answer_images":[],"discussion":[{"upvote_count":"1","timestamp":"1741236300.0","comment_id":"1365734","content":"Selected Answer: B\nThe best option is B. Row-level access policy. Option B is best because row-level policies directly filter data by region for each rep. Option A (Policy tag) is incorrect because tags are for column-level control, not rows. Option C (Data masking) is incorrect because masking hides data, doesn't filter rows. Option D (IAM permissions) is incorrect because IAM controls dataset/table access, not row-level. Therefore, Option B, row-level policies, is the correct way to restrict data by region.","poster":"n2183712847"}],"question_images":[],"timestamp":"2025-03-06 05:45:00","answers_community":["B (100%)"],"answer_ET":"B","unix_timestamp":1741236300,"topic":"1","answer_description":"","choices":{"D":"Grant the appropriate IAM permissions on the dataset.","C":"Create a data masking rule.","A":"Add a policy tag in BigQuery.","B":"Create a row-level access policy."},"url":"https://www.examtopics.com/discussions/google/view/157640-exam-associate-data-practitioner-topic-1-question-61/","question_text":"You are a database administrator managing sales transaction data by region stored in a BigQuery table. You need to ensure that each sales representative can only see the transactions in their region. What should you do?","question_id":58,"isMC":true,"answer":"B","exam_id":2},{"id":"LR8YyjwomVp4iQR5RDY7","answer_description":"","choices":{"C":"Create a native table.","D":"Create an object table.","A":"Create an external table.","B":"Create a temporary table."},"isMC":true,"answer":"D","exam_id":2,"unix_timestamp":1741236240,"discussion":[{"comment_id":"1366609","upvote_count":"1","timestamp":"1741444680.0","content":"Selected Answer: D\nobject table due to audio files in cloud storage bucket","poster":"n2183712847"},{"comment_id":"1365733","upvote_count":"1","timestamp":"1741236240.0","content":"Selected Answer: D\nThe best option is D. Object table. Option D is best because Object tables directly represent Cloud Storage buckets in BigQuery, letting you query file metadata and content for BigQuery ML. Option A (External table) is incorrect because while possible, Object tables are more specialized for Cloud Storage buckets. Option B (Temporary table) is incorrect because it's for short-term data, not external sources. Option C (Native table) is incorrect because it requires loading data into BigQuery, not querying it in Cloud Storage directly. Therefore, Option D, Object table, is the most direct for Cloud Storage file analysis in BigQuery.","poster":"n2183712847"}],"question_text":"Your company’s customer support audio files are stored in a Cloud Storage bucket. You plan to analyze the audio files’ metadata and file content within BigQuery to create inference by using BigQuery ML. You need to create a corresponding table in BigQuery that represents the bucket containing the audio files. What should you do?","url":"https://www.examtopics.com/discussions/google/view/157639-exam-associate-data-practitioner-topic-1-question-62/","answer_images":[],"question_id":59,"answers_community":["D (100%)"],"timestamp":"2025-03-06 05:44:00","question_images":[],"topic":"1","answer_ET":"D"},{"id":"D56SJprwjAiyZDX6XMaq","timestamp":"2025-02-28 03:30:00","answer_ET":"A","discussion":[{"timestamp":"1741234020.0","comment_id":"1365709","content":"Selected Answer: A\nThe best option is A. Use customer-supplied encryption keys (CSEK). Option A is best because CSEK provides complete manual control over keys, meeting strict regulatory needs. Option B (Third-party KMS) is incorrect because CSEK already provides control within Google Cloud. Option C (GMEK) is incorrect because Google manages keys, not the company. Option D (CMEK) is incorrect because keys are managed within Google KMS, not fully manual control. Therefore, Option A, CSEK, offers the most direct and complete manual key control.","upvote_count":"2","poster":"n2183712847"},{"timestamp":"1741233900.0","comment_id":"1365708","upvote_count":"1","poster":"n2183712847","content":"Selected Answer: A\nxfasdfadsfsadf"},{"poster":"rich_maverick","comments":[{"poster":"n2183712847","content":"no this is wrong. for complete control you use csek.","timestamp":"1741444740.0","upvote_count":"1","comment_id":"1366610"}],"content":"Selected Answer: D\nCSEK is a dying deployment that is only supported by a few of the storage services. For compete and manual control of data encryption, you need to use CMEK.","timestamp":"1740709800.0","upvote_count":"1","comment_id":"1362802"}],"answers_community":["A (75%)","D (25%)"],"isMC":true,"exam_id":2,"question_images":[],"unix_timestamp":1740709800,"question_text":"You work for a financial services company that handles highly sensitive data. Due to regulatory requirements, your company is required to have complete and manual control of data encryption. Which type of keys should you recommend to use for data storage?","answer":"A","question_id":60,"answer_description":"","answer_images":[],"topic":"1","choices":{"C":"Use Google-managed encryption keys (GMEK).","B":"Use a dedicated third-party key management system (KMS) chosen by the company.","D":"Use customer-managed encryption keys (CMEK).","A":"Use customer-supplied encryption keys (CSEK)."},"url":"https://www.examtopics.com/discussions/google/view/157258-exam-associate-data-practitioner-topic-1-question-63/"}],"exam":{"lastUpdated":"11 Apr 2025","id":2,"isBeta":false,"name":"Associate Data Practitioner","provider":"Google","isMCOnly":true,"isImplemented":true,"numberOfQuestions":72},"currentPage":12},"__N_SSP":true}