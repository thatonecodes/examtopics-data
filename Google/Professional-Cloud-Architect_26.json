{"pageProps":{"questions":[{"id":"WIKdBSnMBkNVSIrmb78h","answers_community":["A (66%)","D (34%)"],"unix_timestamp":1622714460,"topic":"1","answer_description":"","discussion":[{"timestamp":"1623313680.0","content":"it should be A .. helm is needed for \"Deploy application bundles using dynamic templates\"\n\nLoad Balancing should be part of GKE Already","comment_id":"378882","poster":"rsamant","comments":[{"timestamp":"1743528840.0","poster":"gaufchamp","upvote_count":"1","content":"You're right to point out that GKE itself handles load balancing through Ingress and Cloud Load Balancing by default. Therefore, A. Google Kubernetes Engine, Jenkins, and Helm is a perfectly valid and strong choice to meet all of the requirements without the need to explicitly mention Cloud Load Balancing.","comment_id":"1418594"},{"content":"Then jenkins is of no use","comment_id":"1335121","upvote_count":"1","timestamp":"1735711860.0","poster":"satish4exam"},{"timestamp":"1630368900.0","content":"Kubernetes Engine offers integrated support for two types of Cloud Load Balancing (Ingress and External Network Load Balancing) , hence Option A\nReference : https://cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer","upvote_count":"4","comment_id":"435867","poster":"raf2121"},{"comment_id":"696550","upvote_count":"3","timestamp":"1665952800.0","poster":"AzureDP900","content":"A should be fine"},{"poster":"Prakzz","timestamp":"1696314600.0","content":"Load balancing is not a part of GKE untill it's created explicitly","upvote_count":"2","comment_id":"1023667"},{"poster":"poseidon24","upvote_count":"11","comments":[{"comment_id":"460162","poster":"ashish_t","upvote_count":"17","content":"https://cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer#optional_serving_multiple_applications_on_a_load_balancer\n\nAs per the above document and given example of \"fanout-ingress.yaml\" in above document and also in GKE sample repository below\nhttps://github.com/GoogleCloudPlatform/kubernetes-engine-samples/tree/master/load-balancing\n\nit's clear that GKE LB can handle \"6. Route network traffic to specific services based on URL\"\nSo NO need for Cloud Load balancing.\n\nHelm satisfy \"5. Deploy application bundles using dynamic templates\" \nand no other option satisfies this point #5.\n\nSo correct answer should be: \nA","timestamp":"1633885560.0"}],"timestamp":"1627248540.0","comment_id":"414247","content":"Not for \"based on URL\", that is the difference."}],"upvote_count":"69"},{"poster":"victory108","content":"D. Google Kubernetes Engine, Jenkins, and Cloud Load Balancing","comment_id":"398378","timestamp":"1625406480.0","comments":[{"content":"Cloud Load Balancing does not fulfill \"Be based on open-source technology for cloud portability\"","upvote_count":"1","comment_id":"1346172","timestamp":"1737732720.0","poster":"user263263"}],"upvote_count":"43"},{"comment_id":"1399116","poster":"izekc","timestamp":"1742091960.0","upvote_count":"1","content":"Selected Answer: D\nFor networking part, D is required"},{"upvote_count":"1","poster":"cloud_rider","comment_id":"1363446","content":"Selected Answer: A\nA is correct","timestamp":"1740815700.0"},{"content":"Selected Answer: D\nOption A (Google Kubernetes Engine, Jenkins, and Helm):\nThis option explicitly includes Helm, which is used for templated deployments. However, since GKE itself supports Helm, this option may be seen as redundant in the context of the requirements.\n\nOption D (Google Kubernetes Engine, Jenkins, and Cloud Load Balancing):\nThis option includes Jenkins for continuous delivery and Cloud Load Balancing for routing traffic. While it doesn't mention Helm, the dynamic template deployment can still be managed through Jenkins scripts or other CI/CD tools.","comment_id":"1359640","upvote_count":"1","timestamp":"1740117000.0","poster":"halifax"},{"poster":"MikeMike7","upvote_count":"1","content":"Selected Answer: D\nD: load balancing is needed for this requirement: 6. Route network traffic to specific services based on URL","timestamp":"1733420340.0","comment_id":"1322468"},{"timestamp":"1732373820.0","upvote_count":"1","content":"A & D are both right \nWhy D Might Still Be Preferred:\n\nWhile A is a valid choice, D (Google Kubernetes Engine, Jenkins, and Cloud Load Balancing) might be preferred for the following reasons:\n\n Cloud Load Balancing provides a more feature-rich, fully managed solution for routing traffic across multiple regions and services, including advanced load balancing, SSL termination, and support for more sophisticated network traffic management.\n It integrates well with GKE and offers additional scalability and flexibility that might be important as your system grows","comment_id":"1316698","poster":"drinkwater"},{"comment_id":"1309977","content":"Selected Answer: A\n1. Open-source technology: Kubernetes Engine, Jenkins, and Helm.\n2. Dynamically scale compute capacity: Kubernetes Engine provides autoscaling to adjust the number of nodes based on demand.\n3. Support continuous software delivery: Jenkins enables CI/CD pipelines for automated building, testing, and deployment of applications.\n4. Run multiple segregated copies: Kubernetes Engine allows deploying multiple instances of the application in isolated environments (namespaces) within the same cluster.\n5. Deploy application bundles using dynamic templates: Helm uses charts (templates) to define, install, and upgrade Kubernetes applications.\n6. Route network traffic based on URL: Kubernetes Engine's service objects and ingress controllers can route traffic to specific services based on URLs and other criteria.","upvote_count":"11","timestamp":"1731323880.0","poster":"Ekramy_Elnaggar"},{"upvote_count":"4","comment_id":"1277155","poster":"VedaSW","content":"Selected Answer: A\nBased on: \"Be based on open-source technology for cloud portability\", I go for A, because it is more portable, as compare to D.","timestamp":"1725335340.0"},{"timestamp":"1723100940.0","comment_id":"1262370","poster":"Hungdv","content":"Choose A","upvote_count":"3"},{"timestamp":"1722459240.0","upvote_count":"2","content":"Yes, Kubernetes can route network traffic to specific services based on URL using Ingress and Ingress controllers\n\nAnswer is A","poster":"desertlotus1211","comment_id":"1259097"},{"timestamp":"1719584040.0","poster":"Chris_21","content":"Selected Answer: D\nLoad Balancer is required as per point 6.\nJenkins satisfies point 3.\nD is correct","comments":[{"timestamp":"1721499240.0","content":"Helm is needed for the dynamic templates requirement. The question is vague in whether the application is internally or externally facing which would clarify things a lot more for us. However, in its ambiguity option A has the techonologies neede to the requirments and thus deduce or infer that the application is internally facing and the ingress controllers will handle the routing of traffic. It's ambiguous on purpose which I hate in these exams. More of a test of how well we can read and interpret the questions vs our knowledge of material.","upvote_count":"3","poster":"Ric350","comment_id":"1251905"}],"upvote_count":"1","comment_id":"1238768"},{"timestamp":"1710757320.0","content":"Selected Answer: D\nD is correct","upvote_count":"1","comment_id":"1176378","poster":"Rehamss"},{"upvote_count":"4","content":"Selected Answer: D\nOption A (GKE, Jenkins, Helm) meets most requirements except for explicit URL-based routing, though Kubernetes Ingress (which can be managed through Helm charts) implicitly covers this.\n\nOption D (GKE, Jenkins, Cloud Load Balancing) directly meets every requirement, including URL-based routing without needing to infer capabilities or integrate additional tools beyond the scope of what's listed. Jenkins supports continuous delivery, GKE supports dynamic scaling, segregated application stacks, and cloud portability. Cloud Load Balancing directly addresses the URL-based routing requirement.","comment_id":"1170928","comments":[{"timestamp":"1718283720.0","content":"Except none of that meets the needs for deployment templates.","upvote_count":"1","comments":[{"timestamp":"1721499420.0","content":"My point exactly and my response to Chris_21. By process of elimination, you need Helm for the dynamic templates and you need Jenkins. Thus, you have to assume the application is internally facing and the ingress controllers will handle the traffic just fine.","upvote_count":"1","comment_id":"1251907","poster":"Ric350"}],"comment_id":"1229812","poster":"Sephethus"}],"poster":"kahinah","timestamp":"1710151440.0"},{"comment_id":"1155307","poster":"VidhyaBupesh","upvote_count":"1","content":"Selected Answer: D\nD is OK","timestamp":"1708496460.0"},{"content":"1. Be based on open-source technology for cloud portability: GKE\n2. Dynamically scale compute capacity based on demand: GKE\n3. Support continuous software delivery: Jenkins\n4. Run multiple segregated copies of the same application stack: GKE\n5. Deploy application bundles using dynamic templates -> Jenkins\n6. Route network traffic to specific services based on URL -> Only HTTPs load balancer can meet this requirement: Next best is Cloud balancing (that can be either Network or HTTPs), \nSo D makes sense to me.","upvote_count":"6","poster":"ashishdwi007","comment_id":"1128966","timestamp":"1705951860.0"},{"content":"D - Correct","upvote_count":"1","poster":"kip21","comment_id":"1122643","timestamp":"1705247220.0"},{"timestamp":"1704278220.0","comments":[{"content":"A is the real-world answer, D is the \"Google (TM)\" answer I think. It's obnoxious how bad these questions are.","comment_id":"1229815","upvote_count":"1","timestamp":"1718283840.0","poster":"Sephethus"}],"content":"I thought that answer A was correct but after researching HELM I think now the option D is correct.\nHelm is not a cloud service on its own, and it is not built into Google Kubernetes Engine (GKE). Helm is an open-source package manager for Kubernetes that simplifies the deployment and management of applications on Kubernetes clusters.\n\nHere's a brief overview:\n\nHelm:\n\nHelm allows you to define, install, and upgrade even the most complex Kubernetes applications using packages called charts. A Helm chart includes pre-configured Kubernetes resources that define the structure of an application. Helm provides a convenient way to package, version, and deploy applications on Kubernetes.","poster":"MMuzammil","upvote_count":"3","comment_id":"1112668"},{"poster":"adoyt","upvote_count":"1","timestamp":"1703537640.0","content":"Selected Answer: A\nKubernetes natively supports routing to different services based on URLs via the ingress gateway regardless of wether a LB is used...","comment_id":"1105537"},{"upvote_count":"1","content":"The correct answer is A, you can route network traffic to specific services based on URL using Google Kubernetes Engine (GKE) using Ingress","timestamp":"1702975560.0","comment_id":"1100444","poster":"simiramis221"},{"poster":"_kartik_raj","timestamp":"1697451600.0","content":"Correct should be D, Focus on this part of the question \"what cloud technologies he can use to meet them\", And Now coming to options ,B,C are self explanatory now coming to A Because Helm is not a Cloud Technology first, its just a package Manager for Kubernetes, and Even if you say Loadbalncing is part of GKE , actually whatever ingress you create for path based , It does create a load Balancer , and ultimately LOad Balancer is Definitely important, now coming to Templating I Feel there can be many tools we can use ex: Kustomize can be one of them but that is completly something User can decide and even create some customised way to templatize the deployment using YAML or shell or any other language .","comment_id":"1044849","comments":[{"comment_id":"1229817","poster":"Sephethus","timestamp":"1718283900.0","content":"I hate tests and this question is why I hate them. There is too much confusion in the question. I would say A is the real world answer, D is the Google (tm) answer.","upvote_count":"1"}],"upvote_count":"1"},{"comment_id":"1040342","poster":"Arun_m_123","upvote_count":"1","content":"Selected Answer: D\nCorrect answer is D - Don't get confused with this option \"Deploy application bundles using dynamic templates\". In this option, they have mentioned as \"Deploy applications\". In GKE app deployment, can be configured using YAML files. Helm is not a highly preferred tool and that won't be a recommedation from Google. Answer is D","timestamp":"1697011440.0"},{"upvote_count":"1","poster":"AdityaGupta","comment_id":"1025273","content":"Selected Answer: D\nDynamic bundling - GKE\nCI/ CD - Jenkins\nRouting based on URL - Cloud B","timestamp":"1696478520.0"},{"upvote_count":"2","comment_id":"1018379","content":"Selected Answer: D\nK8s, Jenkins – an open source automation server which enables developers around the world to reliably build, test, and deploy their software. and LB for traffic forwarding.","poster":"RKS_2021","timestamp":"1695784500.0"},{"comment_id":"1015381","content":"Continuous Delivery ----> ci-cd pipelines --->Jenkins","poster":"theBestStudent","upvote_count":"1","timestamp":"1695513240.0"},{"comment_id":"989690","upvote_count":"1","timestamp":"1692941580.0","poster":"kenithyang","content":"Selected Answer: A\nA is correct"},{"poster":"heretolearnazure","timestamp":"1692727980.0","content":"A is the right answer","comment_id":"987675","upvote_count":"1"},{"content":"Selected Answer: D\nSimple yaml is also considered a dynamic template. Helm is just a kind on npm/mvn of Kubernetes.\nWhen you provision ingress LB in GKE, you provision Cloud LB","poster":"eka_nostra","upvote_count":"2","comment_id":"964339","timestamp":"1690433040.0"},{"comments":[{"content":"https://cloud.google.com/kubernetes-engine/docs/concepts/ingress#:~:text=GKE%20clusters%20have%20external%20Application,you%20must%20not%20disable%20it. \n\nLoad Balancers are enabled by default in GKE. There's no need to enable them.","upvote_count":"3","poster":"jrisl1991","timestamp":"1696650540.0","comment_id":"1027063"}],"content":"Selected Answer: D\nImagine \"Route network traffic to specific services based on URL\" without Load balancing service\n\nLol.","upvote_count":"1","poster":"BigfootPanda","timestamp":"1688630580.0","comment_id":"944420"},{"content":"Selected Answer: A\nD - GKE already provides LB based on URL https://cloud.google.com/kubernetes-engine/docs/concepts/ingress#multiple_backend_services \n\nA satisfies all requirements, more specifically: \"Deploy application bundles using dynamic templates\" - whilst D does not.\n\nCorrect Answer: A","upvote_count":"1","poster":"[Removed]","timestamp":"1687656180.0","comment_id":"933096"},{"poster":"nescafe7","upvote_count":"1","comment_id":"919714","timestamp":"1686358200.0","content":"Selected Answer: D\nThe correct answer is D."},{"upvote_count":"1","poster":"TheCloudGuruu","comment_id":"898197","timestamp":"1684148520.0","content":"Selected Answer: A\nThe correct answer is A"},{"comment_id":"849829","upvote_count":"6","poster":"mifrah","content":"In the exam I would have clicked D. \nAlthough you can configure GKE with Ingress for the URL maps, but in my opinion Google provisions a Google Load Balancer behind the scene, but that makes a Load Balancer necessary --> D.","timestamp":"1679724840.0","comments":[{"content":"Yep, helm is nice but it depends on what you are considering as a dynamic template, when you provision a ingress for dynamic route in a gke it will create the load balancer and the backends so I would go with D too","comment_id":"887835","poster":"Kiroo","upvote_count":"1","timestamp":"1683056760.0"}]},{"timestamp":"1679554920.0","upvote_count":"2","content":"Selected Answer: A\nGKE, Helm (for dynamic templates), Jenkins (for CICD).\nWith GKE you already have lb, you can use ingress expose app on it in easy way. you can use service loadbalancer if you wanna expose other dedicated lb.\n\nA is the only right answer because address the deploy with dynamic template","comment_id":"847899","poster":"alekonko"},{"content":"Selected Answer: A\nIt Should be 'A' since GKE already provide a load balancer with it.","upvote_count":"2","poster":"feholen210","timestamp":"1679304300.0","comment_id":"844694"},{"upvote_count":"2","timestamp":"1678352340.0","poster":"anshad666","comment_id":"833749","content":"Selected Answer: A\nHelm needed for Deploy application bundles using dynamic templates"},{"poster":"MestreCholas","comment_id":"827942","timestamp":"1677845700.0","upvote_count":"3","content":"Selected Answer: A\nThe combination of technologies that will meet all of the requirements is option A: Google Kubernetes Engine, Jenkins, and Helm.\n\nExplanation:\n\n1. Google Kubernetes Engine (GKE) is based on Kubernetes, which is an open-source container orchestration system for cloud portability.\n2. GKE supports auto-scaling of compute resources based on demand.\n3. Jenkins is a popular tool for continuous integration and continuous delivery (CI/CD) pipelines.\n4. GKE allows running multiple copies of the same application stack in different Kubernetes namespaces or clusters for segregation.\n5. Helm is a package manager for Kubernetes that enables the deployment of application bundles using dynamic templates.\n6. Cloud Load Balancing can route network traffic to specific services based on URL, and can be used with GKE."},{"upvote_count":"3","comment_id":"755044","content":"Selected Answer: A\nOverall great explanation those who selected A as the answer. Thank you for sharing. I agree that the best answer is A.\n\nLoad balancing - GKE container-native load balancing through Ingress\nRegarding your \"other options\" section. Since GKE already provides load balancing capabilities, Cloud Load Balancing is not needed since GKE has container-native load balancing by default for GKE clusters running version 1.17 or later. (1)(2)\n\nNetwork traffic to specific services based on URL - Gateway traffic management\nI read about two traffic management capabilities that provide controls to manage network traffic to \"specific\" services in GKE. They are services capacity and traffic splitting. (3)\n\nreferences - \n1. https://cloud.google.com/kubernetes-engine/docs/how-to/container-native-load-balancing\n2. https://cloud.google.com/kubernetes-engine/docs/concepts/ingress\n3. https://cloud.google.com/kubernetes-engine/docs/concepts/traffic-management","poster":"jay9114","timestamp":"1671903000.0"},{"comment_id":"751952","poster":"omermahgoub","timestamp":"1671606000.0","content":"A. Google Kubernetes Engine, Jenkins, and Helm\n\nTo meet all of the requirements specified, you can use the following combination of technologies:\n\nGoogle Kubernetes Engine: This is an open-source, container-based platform that can be used to dynamically scale compute capacity based on demand and run multiple segregated copies of the same application stack. It is also portable across different cloud environments.\n\nJenkins: This is an open-source continuous integration and delivery tool that can be used to support continuous software delivery.\n\nHelm: This is an open-source package manager for Kubernetes that can be used to deploy application bundles using dynamic templates.\n\nOther options, such as using Google Kubernetes Engine and Cloud Load Balancing or Google Kubernetes Engine and Cloud Deployment Manager, may not meet all of the requirements specified. For example, Cloud Load Balancing does not support the ability to route network traffic to specific services based on URL. Similarly, Cloud Deployment Manager does not support continuous software delivery.","upvote_count":"3"},{"upvote_count":"1","comment_id":"749916","content":"Selected Answer: A\nA is the correct answer","poster":"surajkrishnamurthy","timestamp":"1671460020.0"},{"timestamp":"1669683420.0","comment_id":"729764","content":"The key term here is \"what CLOUD technologies you would use\".\nI'd select D for that simple reason - all components are available with GCP. \nHelm is just a package manager for K8s, totally unrelated to \"Cloud technology\".","upvote_count":"5","poster":"IvanDobrinov"},{"content":"Selected Answer: D\nCorrect answer is D; Cloud load balancing supports URL based routing. I will go with D. Helm helps you to manage kubernetes application which anyways GKE is capable of.","comment_id":"721961","upvote_count":"4","poster":"AniketD","timestamp":"1668857340.0"},{"timestamp":"1666464180.0","content":"Selected Answer: A\nA seems to be the answer","comment_id":"701723","upvote_count":"1","poster":"Mahmoud_E"},{"upvote_count":"4","timestamp":"1665978840.0","comment_id":"696791","poster":"zr79","content":"it's mysterious to Google how they score these exams. Hoping they do not give points based on correct or not correct \nlike here A and D"},{"content":"Selected Answer: A\nA. Google Kubernetes Engine, Jenkins, and Helm. \nThis is a better answer than D because \n- Load Balancing is already available for Kubernetes (The Kubernetes load balancer works by sending connections to the first server in the pool until its capacity is reached)\n- Helm is required for managing Kubernetes packages - install/deploy/manage/etc.","timestamp":"1665659580.0","comment_id":"693818","upvote_count":"3","poster":"minmin2020"},{"upvote_count":"2","comment_id":"688314","poster":"Rajeev26","content":"Correct answer is D. Helm can not route traffic based on URL","timestamp":"1665119460.0"},{"comment_id":"681028","upvote_count":"3","timestamp":"1664301000.0","content":"To be able to map on URL in GKE you need an Ingress object. Behind the scenes Ingres creates a L7 Global Load Balancer. This is why D is correct. Although I'd agree with everyone else that A is correct because of HELM for \"Deploy application bundles using dynamic templates\". So seems two correct answers???","poster":"BiddlyBdoyng"},{"content":"D looks like a right answr jenkin will take care of deployment","upvote_count":"1","poster":"holerina","timestamp":"1663767480.0","comment_id":"675185"},{"upvote_count":"1","poster":"jay9114","comment_id":"651454","timestamp":"1661373540.0","content":"The answer is A. I confirmed that Helm is needed to \"deploy application bundles using dynamic templates\" and GKE clusters have HTTP Load balancer enabled by default. In other words you do not need Cloud Load Balancer when using GKE."},{"timestamp":"1659687300.0","poster":"Mikado211","upvote_count":"3","content":"Selected Answer: A\nAnswer A is good\n- URL based load balancing : use the ingress kind on GKE (I've done it for years on a kube)\n- Templated : Helm is the only tool to manage templated objects in the list, so it's mandatory","comment_id":"642832"},{"poster":"ashii007","upvote_count":"1","content":"D is wrong because \"cloud load balancing\" is not a product on GCP. It is a generic technical term.","comment_id":"600905","timestamp":"1652404560.0"},{"content":"Selected Answer: D\nURL based load balancing - cloud load balancer.","poster":"Nirca","upvote_count":"5","comment_id":"591764","timestamp":"1650896220.0"},{"poster":"ManuSharma","comment_id":"544134","timestamp":"1644447300.0","upvote_count":"2","content":"It should be A"},{"poster":"sjmsummer","upvote_count":"1","content":"Looks to me the answer should be A+D combined. Otherwise req. 2 or 5 will not be met., unless they think K8S is a native L/B by nature, then A is the answer.","comment_id":"524527","timestamp":"1642293600.0"},{"poster":"codyschneider","timestamp":"1642009620.0","upvote_count":"8","content":"I'm genuinely confused. What is consider correct in this whole thing. I'm consistently seeing a divide between most voted and whats deemed correct. Someone help me, this seems very bad in terms for learning.","comment_id":"522348"},{"content":"Selected Answer: A\nLoad Balancing is not an open source software.. so any answer with that will be incorrect. Same for CDM. So the only pre Open Source answer is A","comment_id":"518238","timestamp":"1641474660.0","upvote_count":"3","comments":[{"upvote_count":"2","poster":"elaineshi","comment_id":"609218","content":"It's said it uses open source, yet not demand all products to be open source, GKE, jenkins are open source so satisfies the ask already.\nVPC is not open source, yet it's required as well.","timestamp":"1653916620.0"},{"poster":"TitaniumBurger","content":"i think there isn't always only a single way to solve a problem. In terms of learning, it's beneficial to see so many different perspectives.","upvote_count":"1","timestamp":"1645452240.0","comment_id":"552894"},{"upvote_count":"1","timestamp":"1655444160.0","content":"HTTP load balancer is google copy of Envoy proxy, totally open source! \nD is the correct answer","poster":"Arrash","comment_id":"617553"}],"poster":"Meyucho"},{"upvote_count":"5","poster":"vincy2202","content":"Selected Answer: A\nA is the correct answer.\n\nThe key here is - The application must be based on \"open-source technology for cloud portability\"\n1.Helm is the solution for dynamic templates and \n2. Kubernetes provides inherent support for HTTPS External Load Balancer. \nThese 2 points help to nail the answer.","comment_id":"509045","timestamp":"1640427420.0"},{"comment_id":"493635","content":"Selected Answer: A\nhelm is needed for \"Deploy application bundles using dynamic templates\"","timestamp":"1638612600.0","upvote_count":"3","poster":"ggzzzzzzz"},{"content":"Go for D","upvote_count":"3","timestamp":"1638608040.0","poster":"haroldbenites","comment_id":"493598"},{"content":"Does not Kubernetes already handle loadbalancing on its own?","timestamp":"1638454380.0","poster":"Aiffone","comment_id":"492578","upvote_count":"1"},{"content":"Selected Answer: A\nvote A","comment_id":"489486","poster":"duocnh","upvote_count":"1","timestamp":"1638142620.0"},{"timestamp":"1637212140.0","comment_id":"480460","content":"1. Be based on open-source technology for cloud portability, so D is ruled out.","upvote_count":"1","poster":"Danny2021"},{"comment_id":"472521","content":"Vote for D","upvote_count":"3","poster":"exam_war","timestamp":"1636029600.0"},{"poster":"PrateekGoel","comment_id":"467610","content":"A. Helm - Its supports 1(Opensource) and 5(Dynamic Templates)\nGKE already supports URL Map based Load Balancing . \nhttps://cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer\nThe load balancer's URL map's host rules and path matchers reference one or more backend services, where each backend service corresponds to a GKE Service of type NodePort, as referenced in the Ingress","timestamp":"1635183360.0","upvote_count":"3"},{"upvote_count":"7","comment_id":"432674","content":"1. Be based on open-source technology for cloud portability\n>>K8s\n2. Dynamically scale compute capacity based on demand\n>>K8s\n3. Support continuous software delivery\n>>Jenkin\n4. Run multiple segregated copies of the same application stack\n>>K8s\n5. Deploy application bundles using dynamic templates\n>>Helm\nhttps://v2.helm.sh/docs/chart_template_guide/\n6. Route network traffic to specific services based on URL\n>>K8s\n\nHence A","comments":[{"content":"Edit (Correcting my old response)\n5. Deploy application bundles using dynamic templates\n>>yml in K8s \nHelme provides dynamic chart templates.\n6. Route network traffic to specific services based on URL\n>>Cloud Load Balancer\n\nHence D","comment_id":"432676","timestamp":"1630029420.0","poster":"amxexam","upvote_count":"10"}],"timestamp":"1630029180.0","poster":"amxexam"},{"timestamp":"1629323820.0","poster":"rikoko","comment_id":"427089","content":"I'll go with A. Cloud Load Balancer is not open-source based, no ? Ingress of Kubernetes does the job of \"route traffic to specific service based on URL\", I suppose. Internally in GKE, when there is an Ingress, it creates a HTTPS Cloud Load Balancer.","upvote_count":"1"},{"timestamp":"1627139160.0","content":"Correct Answer should be D\nCloud Load Balancer is used to route traffic to specific service based on URL","poster":"VishalB","upvote_count":"6","comment_id":"413247"},{"comment_id":"391312","timestamp":"1624717140.0","poster":"aviratna","content":"D is correct. \nGKE will need Load Balancer for routing traffic based on URL path.\nApplication deployment can be done using Jenkins CICD pipeline.\n\nHelm chart main use case is packaging & sharing the deployment. Its not a dynamic template. While Jenkins can be used to deploy application bundles using dynamic template which can take dynamic parameters","upvote_count":"7"},{"content":"My answer is D","timestamp":"1624509180.0","comment_id":"389218","upvote_count":"3","poster":"Papafel"},{"comment_id":"387374","upvote_count":"2","poster":"Areev","timestamp":"1624303140.0","content":"My pick is D. People selecting A should think about how to route network traffic based on URL path."},{"upvote_count":"2","poster":"Yogikant","timestamp":"1624179120.0","comment_id":"386089","content":"Should be A."},{"comment_id":"374397","upvote_count":"5","poster":"rishab86","content":"answer is D","timestamp":"1622815980.0"},{"upvote_count":"3","content":"i think for me D should be the best answer","timestamp":"1622714460.0","poster":"presi","comment_id":"373454"}],"choices":{"B":"Google Kubernetes Engine and Cloud Load Balancing","D":"Google Kubernetes Engine, Jenkins, and Cloud Load Balancing","A":"Google Kubernetes Engine, Jenkins, and Helm","C":"Google Kubernetes Engine and Cloud Deployment Manager"},"answer_images":[],"isMC":true,"question_id":126,"url":"https://www.examtopics.com/discussions/google/view/54389-exam-professional-cloud-architect-topic-1-question-31/","question_images":[],"question_text":"A development manager is building a new application. He asks you to review his requirements and identify what cloud technologies he can use to meet them. The application must:\n1. Be based on open-source technology for cloud portability\n2. Dynamically scale compute capacity based on demand\n3. Support continuous software delivery\n4. Run multiple segregated copies of the same application stack\n5. Deploy application bundles using dynamic templates\n6. Route network traffic to specific services based on URL\nWhich combination of technologies will meet all of his requirements?","answer":"A","exam_id":4,"answer_ET":"A","timestamp":"2021-06-03 12:01:00"},{"id":"RfnNvlmlJHdrum7BVcZZ","url":"https://www.examtopics.com/discussions/google/view/7202-exam-professional-cloud-architect-topic-1-question-32/","answers_community":["C (66%)","D (34%)"],"topic":"1","answer":"C","exam_id":4,"answer_description":"","timestamp":"2019-10-25 15:11:00","unix_timestamp":1572009060,"question_id":127,"answer_images":[],"question_images":[],"question_text":"You have created several pre-emptible Linux virtual machine instances using Google Compute Engine. You want to properly shut down your application before the virtual machines are preempted.\nWhat should you do?","discussion":[{"upvote_count":"41","content":"https://cloud.google.com/compute/docs/shutdownscript ... So C","comment_id":"17379","comments":[{"comments":[{"content":"Since the instance is already created Option C gets eliminated. \"gcloud compute instances addmetadata”\ncommand can be used to add or update the metadata of a virtual machine instance\"","timestamp":"1627631400.0","poster":"VishalB","upvote_count":"12","comment_id":"417253"}],"poster":"nitinz","upvote_count":"4","comment_id":"303621","content":"C, statup/shutdown script = metadata","timestamp":"1614895980.0"}],"poster":"Eroc","timestamp":"1572009060.0"},{"poster":"Gini","comment_id":"87005","upvote_count":"28","timestamp":"1589180460.0","content":"I have doubts with the answer C because the question states that \"You have created the instances\" so C works too but the solution cannot apply to the already created instances. D seems correct to me...\n\nReference:\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances","comments":[{"upvote_count":"2","content":"I think C should be correct over D, because https://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances","timestamp":"1703491920.0","poster":"[Removed]","comment_id":"1105104"},{"poster":"NG123","upvote_count":"2","content":"I also feel so because the virtual machines are already created.","comment_id":"618087","timestamp":"1655527140.0"},{"content":"xinetd. Xinet makes the D answer be nonsense","poster":"dsnaghxhinwtsvvmip","comment_id":"869577","upvote_count":"5","timestamp":"1681400880.0"},{"upvote_count":"4","content":"Yes. The correct answer should be D.\n\nTo add a shutdown script to a running instance, follow the instructions in the Applying a startup script to running instances documentation but replace the metadata keys with one of the following keys:\n\nshutdown-script: Supply the shutdown script contents directly with this key. Using the gcloud command-line tool, you can provide the path to a shutdown script file, using the --metadata-from-file flag and the shutdown-script metadata key.\nshutdown-script-url: Supply a Cloud Storage URL to the shutdown script file with this key.","comment_id":"215569","poster":"pepYash","timestamp":"1604875020.0","comments":[{"timestamp":"1604875260.0","upvote_count":"6","poster":"pepYash","content":"changed my mind. preemptible vms can be stopped and started anytime. with that flexibility, C is ok.","comment_id":"215573"}]},{"comment_id":"574732","upvote_count":"7","poster":"[Removed]","content":"I agree D.\nAs the mentioned in Question, \"You have created several pre-emptible Linux virtual machine...\",\nand check the answer C , \"Create a shutdown script ..... when you create the new virtual machine instance\".\nThe new script apply for new instance creating. \nIn the Quesiton , the serveral created VMs are being used.\nSupply a Cloud Storage URL to the shutdown script file with this key.\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances","timestamp":"1648167480.0"}]},{"upvote_count":"1","timestamp":"1740117660.0","poster":"halifax","content":"Selected Answer: C\nOption C is still a viable option even if the Linux VM instances are already created. You can add a shutdown script to existing instances using metadata. \nOption D is very complicated, The use of xinetd adds unnecessary complexity, and it may not be as effective as simply using the shutdown-script metadata key.","comment_id":"1359642"},{"timestamp":"1734016140.0","comment_id":"1325697","upvote_count":"1","poster":"RobertArnaud","content":"Selected Answer: C\n\"when you create the new virtual machine instance\" means it is too late, then C seems disqualified :( but the other choices are worse ?"},{"upvote_count":"1","poster":"Ekramy_Elnaggar","comment_id":"1314133","timestamp":"1731954660.0","content":"Selected Answer: C\n1. Preemptible instances and shutdown scripts: Google Cloud Platform's preemptible instances are cost-effective but can be terminated with short notice. To gracefully handle this, you need a shutdown script that runs before the instance is preempted.\n\n2. Metadata and shutdown-script: Google Cloud allows you to add custom metadata to your instances. When you create a preemptible instance, you can include a shutdown-script metadata entry. The value of this entry should be your script, which will be executed automatically before the instance is preempted."},{"content":"Selected Answer: D\nIt's not C. C says \"when you create the new virtual machine instance\". But in the question, the instances have already been created. Thus, D. In D, \"service URL\" obviously means cloud storage.","timestamp":"1729098480.0","upvote_count":"1","poster":"Barry123456","comment_id":"1298826"},{"comment_id":"1264685","timestamp":"1723472280.0","content":"Among Option C & D, option D uses shutdown-script-url but shutdown-script-url should be a Cloud storage url and not a linux service URL. \n\nThat brings us to option C","poster":"snehaso","upvote_count":"1"},{"comment_id":"1262374","timestamp":"1723101120.0","poster":"Hungdv","upvote_count":"1","content":"Choose C"},{"poster":"nicksb19","comment_id":"1238754","content":"C is correct since xinetd does not make sense.","timestamp":"1719582780.0","upvote_count":"1"},{"comment_id":"1157605","upvote_count":"2","timestamp":"1708741980.0","content":"Selected Answer: C\nEvery virtual machine instance in GCP has access to a metadata server, which provides information about the instance and allows you to configure various settings, including startup and shutdown scripts.\n\nStartup and shutdown scripts are specified using special metadata keys in the metadata server. \nshutdown-script specifies the shutdown script that should be executed when the instance is being shut down.","poster":"lisabisa"},{"comment_id":"1128978","poster":"ashishdwi007","content":"Selected Answer: C\nAll other options are related to play with Linux files or services. With Preemptible VMs ,these operations are overhead. Hence it makes sense to Automate such tasks.","timestamp":"1705952760.0","upvote_count":"1"},{"poster":"Mo7y","comment_id":"1122818","upvote_count":"3","content":"Selected Answer: C\nThe answer is either C or D\n\nI exclude D because shutdown-script-url only works with a shutdown script hosted on a cloud storage. Option D wants you to use shutdown-script-url for a locally hosted shutdown script, thus it's not the correct answer.","timestamp":"1705264380.0"},{"poster":"kip21","upvote_count":"1","timestamp":"1705247340.0","comment_id":"1122646","content":"C\nhttps://cloud.google.com/compute/docs/shutdownscript"},{"content":"The answer should be C. reference to https://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances\nRegarding the answer D, it is not the option becasue no need to touch xinetd servie inside Linux.","timestamp":"1703578080.0","upvote_count":"2","comment_id":"1105805","poster":"Terryhsieh"},{"poster":"RLsh","timestamp":"1698939240.0","upvote_count":"1","comment_id":"1060651","content":"Selected Answer: D\nI believe the answer should be D since the VMs are already created"},{"content":"Selected Answer: C\nC is the right answer. See, there is one tip. In GCP, things like these are given to the customers as a solution - like give a shutdown script. GCP won't trouble the users to know all those geeky linux stuffs. So the answer is simply C","comment_id":"1040348","poster":"Arun_m_123","timestamp":"1697011620.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1696997100.0","poster":"wukoon","content":"Option D: Creating a shutdown script, registered as a xinetd service in Linux, and using the gcloud compute instances add-metadata command to specify the service URL as the value for a new metadata entry with the key shutdown-script-url is not as reliable as option C because it requires the gcloud command-line tool to be installed and configured on the virtual machine instance.","comment_id":"1040176"},{"content":"Selected Answer: D\nReference:\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances","timestamp":"1696862820.0","comment_id":"1038761","upvote_count":"1","poster":"vc1011"},{"timestamp":"1696479300.0","poster":"AdityaGupta","content":"Selected Answer: C\nI agreed with Eroc for Option C\nhttps://cloud.google.com/compute/docs/shutdownscript","comment_id":"1025274","upvote_count":"1"},{"comment_id":"987680","timestamp":"1692728280.0","upvote_count":"1","poster":"heretolearnazure","content":"C seems to be more reasonable answer....i am also leaning towards D but C is definitely correct in my opinion."},{"content":"c is correct read the documentation it says you must have root access so basically you can do it when the machine is running > https://cloud.google.com/compute/docs/shutdownscript#provide_shutdown_script_contents_directly\\","upvote_count":"1","comment_id":"971457","timestamp":"1691096100.0","poster":"CloudWars"},{"comment_id":"912908","poster":"JohnWick2020","content":"C is the answer.\n\"shutdown-script\" metadata to provide a local script.\n\"Shutdown-script-url\" to provide a cloud storage URL where script is stored.","upvote_count":"1","timestamp":"1685718900.0"},{"timestamp":"1685698020.0","comment_id":"912684","upvote_count":"1","content":"Selected Answer: D\nC will only be an option for new VMs, thus D is the only option!","poster":"irmingard_examtopics"},{"comment_id":"854550","content":"Selected Answer: C\nOption C works fine. you might want to save the shutdown-script in a file in cloud storage or another static place and provide it's url so that you can reuse and version it. But option D is much to complicated and impractical to first set up a service to provide a static file to shut down the server on which the file is served, where you cannot modify it while the server is down .. try to explain that to the new developer kid 10 years later.","upvote_count":"2","timestamp":"1680102180.0","poster":"h7m"},{"content":"Correct answer is C!\nThis link clearly state it: https://cloud.google.com/compute/docs/shutdownscript#provide_shutdown_script_contents_directly","comment_id":"838936","timestamp":"1678804320.0","upvote_count":"1","poster":"Kysmor"},{"upvote_count":"1","content":"Selected Answer: C\nAdd shutdown script via Console during VM creation","comment_id":"831950","timestamp":"1678196940.0","poster":"BeCalm"},{"comment_id":"790605","upvote_count":"3","poster":"CosminCiuc","timestamp":"1674911100.0","content":"I believe C is the right answer.\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances\nApply a shutdown script to running instances\nTo add a shutdown script to a running instance, follow the instructions in the Applying a startup script to running instances documentation but replace the metadata keys with one of the following keys:\n\nshutdown-script: Supply the shutdown script contents directly with this key. Using the Google Cloud CLI, you can provide the path to a shutdown script file, using the --metadata-from-file flag and the shutdown-script metadata key.\nshutdown-script-url: Supply a Cloud Storage URL to the shutdown script file with this key."},{"poster":"examch","upvote_count":"2","timestamp":"1671963060.0","comment_id":"755577","content":"Selected Answer: D\nD is the correct answer, \n\nYou are applying the shutdown script to already running instance\n\nApply a shutdown script to running instances\nTo add a shutdown script to a running instance, follow the instructions in the Applying a startup script to running instances documentation but replace the metadata keys with one of the following keys:\n\nshutdown-script: Supply the shutdown script contents directly with this key. Using the Google Cloud CLI, you can provide the path to a shutdown script file, using the --metadata-from-file flag and the shutdown-script metadata key.\nshutdown-script-url: Supply a Cloud Storage URL to the shutdown script file with this key.\n\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances"},{"comment_id":"751954","content":"A. Create a shutdown script named k99.shutdown in the /etc/rc.6.d/ directory\n\nTo properly shut down your application before the virtual machines are preempted, you can create a shutdown script and place it in the /etc/rc.6.d/ directory. This directory contains scripts that are run when the system is shut down. By creating a script named k99.shutdown and placing it in this directory, you can ensure that it is run when the system is shut down, including when the virtual machine is preempted.\n\nOther options, such as creating a shutdown script registered as a xinetd service in Linux and using Stackdriver or the gcloud compute instances add-metadata command to specify the service URL, may not be necessary for properly shutting down the application before the virtual machines are preempted. Using the Cloud Platform Console to specify the shutdown script as a metadata entry when creating the virtual machine instance may not ensure that the script is run when the system is shut down.","upvote_count":"1","poster":"omermahgoub","timestamp":"1671606240.0"},{"upvote_count":"1","comment_id":"736065","timestamp":"1670255280.0","content":"Option C correct - https://cloud.google.com/compute/docs/shutdownscript","poster":"dkumar15"},{"content":"Selected Answer: C\nI see too many people saying that C is incorrect because an shutdown script cannot be assigned to an already created instance. I have just created one instance and, while running, I have modified its metadata and assigned the shutdown script. Beyond that, my instance was not preemptible, and this exercise asks for preemtible machines, wich are more flexible with that. I go with C.","poster":"jasenmornin","comment_id":"733137","upvote_count":"4","timestamp":"1669932120.0"},{"timestamp":"1668339720.0","upvote_count":"1","poster":"ashrafh","content":"Handle preemption with a shutdown script\nWhen your VM is preempted, you can use a shutdown script to perform cleanup actions before the VM stops. For example, you can gracefully stop a running process and copy a checkpoint file to Cloud Storage.\n\nThe following is a shutdown script that you can add to a running preemptible VM or add to a new preemptible VM when you create it. This script runs when the VM starts to shut down, before the operating system's normal kill command stops all remaining processes. After gracefully stopping the desired program, the script performs a parallel upload of a checkpoint file to a Cloud Storage bucket.\nhttps://cloud.google.com/compute/docs/instances/create-use-preemptible#handle_preemption","comment_id":"717276"},{"poster":"diasporabro","content":"Selected Answer: D\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances","timestamp":"1666862640.0","comment_id":"705400","upvote_count":"1"},{"comment_id":"696553","upvote_count":"1","poster":"AzureDP900","content":"C is right\nTo pass in a local shutdown script file, supply the --metadata-from-file flag, followed by a metadata key pair, shutdown-script=PATH/TO/FILE, where PATH/TO/FILE is a relative path to the shutdown script. For example:\n\n\ngcloud compute instances create example-instance \\\n --metadata-from-file shutdown-script=examples/scripts/install.sh","timestamp":"1665952920.0","comments":[{"timestamp":"1665979080.0","content":"Good luck with the exams","upvote_count":"1","comment_id":"696793","poster":"zr79"}]},{"upvote_count":"3","comment_id":"694775","timestamp":"1665755040.0","poster":"kazob","content":"Selected Answer: C\nD is wrong because shutdown-script-URL only accepts GCS urls"},{"timestamp":"1665661260.0","comment_id":"693842","content":"Selected Answer: D\nD. Create a shutdown script, registered as a xinetd service in Linux, and use the gcloud compute instances add-metadata command to specify the service URL as the value for a new metadata entry with the key shutdown-script-url","upvote_count":"3","poster":"minmin2020"},{"comment_id":"661857","poster":"alexandercamachop","content":"Selected Answer: D\nI have doubts with the answer C because the question states that \"You have created the instances\" so C works too but the solution cannot apply to the already created instances. D seems correct to me...\n\nReference:\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances","upvote_count":"3","timestamp":"1662517440.0"},{"upvote_count":"2","poster":"aut0pil0t","comment_id":"653995","content":"Selected Answer: D\nA: Assuming it refers to /etc/rc6.d (without the additional period), this should just work but it is not a good \"GCP way\" to achieve it.\nB: Too much overkill and over engineering just to run a shutdown script.\nC: Not applicable since VMs are already created and we are not creating them again.\nD: Using xinetd here doesn't make sense but adding the metadata URL key with a URL value is the best way and really the only thing needed.\n\nSo, I vote for D!\n\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances\nhttps://cloud.google.com/compute/docs/shutdownscript","timestamp":"1661856120.0"},{"comments":[{"content":"It's C","timestamp":"1661670480.0","comment_id":"652817","upvote_count":"1","poster":"Sbgani"}],"content":"Selected Answer: D\nSince the question mentions \"You have created several pre-emptible Linux virtual machine instances\", option D looks to fit in this case.","comment_id":"618088","timestamp":"1655527260.0","poster":"NG123","upvote_count":"2"},{"timestamp":"1650896340.0","upvote_count":"1","comment_id":"591766","content":"Selected Answer: C\nMetadata - shutdown startup scripts.","poster":"Nirca"},{"comment_id":"572242","content":"Selected Answer: C\nBest practice","timestamp":"1647868560.0","poster":"Davidik79","upvote_count":"1"},{"comment_id":"545476","content":"Selected Answer: C\nI got similar question on my exam.","upvote_count":"2","poster":"[Removed]","timestamp":"1644610980.0"},{"comments":[{"upvote_count":"1","comment_id":"618089","timestamp":"1655527380.0","poster":"NG123","content":"But the instances are already created. There must be a way to set a shutdown script later for already created VMs."}],"poster":"nymets","timestamp":"1642093680.0","upvote_count":"8","comment_id":"522968","content":"Selected Answer: C\n\"C\" is the correct answer here. \nAnd, here is why \"D\" CANNOT be the answer:\nOption-D states that: \"Create a shutdown script, registered as a xinetd service in Linux, and use the gcloud compute instances add-metadata command to specify the service URL as the value for a new metadata entry with the key shutdown-script-url\"\nThe sentence - \"..registered as a xinetd service in Linux\" indicates that the shutdown-script needs to be registered as service INSIDE the VM. And, the sentence \"...specify the SERVICE URL as the value ....\" indicates that we need to specify the service path of the shutdown-script (which is inside the VM) as the target URL for key shutdown-script-url. The key shutdown-script-url, however, will only accept a a Cloud Storage URL.\nI hope this helps."},{"upvote_count":"1","timestamp":"1640431080.0","poster":"vincy2202","comment_id":"509066","content":"C is the correct answer"},{"content":"Go for D.\nThe instances has already been created.","upvote_count":"1","poster":"haroldbenites","comment_id":"493602","timestamp":"1638608820.0"},{"timestamp":"1636030080.0","content":"shutdown service in linux should go on /etc/rc.3.d, so A is not right. \nD. it calls for xinetd service in Linux, xinetd is for services such as ftp/sftp/tcp... D is not right, same as B.\nso the only working answer is C","comment_id":"472523","upvote_count":"2","poster":"exam_war"},{"poster":"FERIN_02","timestamp":"1635865020.0","upvote_count":"1","content":"Key value should be shutdown-script-url ( url was missing in option C). Hence appropriate answer shall be Option D. But the terms \"registered as a xinetd service in Linux\" unclear to me.","comments":[{"comment_id":"912286","comments":[{"poster":"LaxmanTiwari","content":"even I got confused with the xinetd.","timestamp":"1685638800.0","upvote_count":"1","comment_id":"912287"}],"poster":"LaxmanTiwari","timestamp":"1685638740.0","upvote_count":"1","content":"Key value should be shutdown-script-url ( url was missing in option C). Hence appropriate answer shall be Option D. But the terms \"registered as a xinetd service in Linux\" unclear to me."}],"comment_id":"471683"},{"comment_id":"468102","poster":"MaxNRG","content":"C,\nA startup script, or a shutdown script, is specified through the metadata server, using startup script metadata keys.\nhttps://cloud.google.com/compute/docs/startupscript","timestamp":"1635260280.0","upvote_count":"1"},{"comment_id":"467617","poster":"PrateekGoel","timestamp":"1635184200.0","content":"D -> Its the only option applicable for running instances. C would have been the answer if we were creating new instances. https://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances","upvote_count":"1"},{"poster":"Urban_Life","content":"@tartar- any opinion?","timestamp":"1634085960.0","upvote_count":"1","comment_id":"461312"},{"poster":"civilizador","upvote_count":"1","comment_id":"443514","timestamp":"1631456160.0","content":"Surprised that everyone is choosing C, when question clearly asking about already running vms. So C is no go from the start. Answer is D and it is Described in google docs:\n\n Apply a shutdown script to running instances\nTo add a shutdown script to a running instance, follow the instructions in the Applying a startup script to running instances documentation but replace the metadata keys with one of the following keys:\n\nshutdown-script: Supply the shutdown script contents directly with this key. Using the gcloud command-line tool, you can provide the path to a shutdown script file, using the --metadata-from-file flag and the shutdown-script metadata key.\nshutdown-script-url: Supply a Cloud Storage URL to the shutdown script file with this key. \n\nLink: \nhttps://cloud.google.com/compute/docs/shutdownscript"},{"comment_id":"432681","upvote_count":"1","timestamp":"1630030320.0","content":"Let's go with option elimination\nA. Create a shutdown script named k99.shutdown in the /etc/rc.6.d/ directory\n>> Not aware of any script or way of execution by this way, hence eliminate.\nB. Create a shutdown script registered as a xinetd service in Linux and configure a Stackdriver endpoint check to call the service\n>> By using xinetd service you are opening a vulnerability in your application that can be exploited. Bad practice , hence eliminate.\nC. Create a shutdown script and use it as the value for a new metadata entry with the key shutdown-script in the Cloud Platform Console when you create the new virtual machine instance\n>> Recommended pratice.https://cloud.google.com/compute/docs/shutdownscript#provide_shutdown_script_contents_directly\nD. Create a shutdown script, registered as a xinetd service in Linux, and use the gcloud compute instances add-metadata command to specify the service URL as the value for a new metadata entry with the key shutdown-script-url\n>> Can be done but not a recommended way\n\nHence C","poster":"amxexam"},{"upvote_count":"4","timestamp":"1624717800.0","poster":"aviratna","comment_id":"391324","content":"C is correct\nD is not correct because to use shutdown-script-url script needs to be stored in Cloud Storage and then provide URL"},{"upvote_count":"2","poster":"victory108","content":"C. Create a shutdown script and use it as the value for a new metadata entry with the key shutdown-script in the Cloud Platform Console when you create the new virtual machine instance","comment_id":"360352","timestamp":"1621333800.0"},{"poster":"un","timestamp":"1620748440.0","comment_id":"354853","upvote_count":"1","content":"C is correct\nhttps://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances"},{"poster":"Ausias18","timestamp":"1617165120.0","upvote_count":"1","content":"Answer is C","comment_id":"324712"},{"comments":[{"comment_id":"324187","content":"... also see Apply a shutdown script to running instances: https://cloud.google.com/compute/docs/shutdownscript#apply_a_shutdown_script_to_running_instances\nand Applying a startup script to running instances: https://cloud.google.com/compute/docs/startupscript#startupscriptrunninginstances\n\nAs you can see, there is no need to register the script as a xinetd service in Linux, as D states.","upvote_count":"1","poster":"lynx256","timestamp":"1617101400.0"}],"timestamp":"1616683200.0","poster":"lynx256","upvote_count":"1","comment_id":"320278","content":"I think C is ok.\nThe shutdown script is run by GCE before GCE stops the instance. \nAnd before GCE stops the instace, I think it reads from metadata, if there a shutdown-script is set. I suppose this reading is made by GCE just before stopping the VM, not when it starts.\nI cannot find in docs explanation about WHEN GCE looks in metadata for shutdown-script but it would've been very strange if it reads all the metadata and keeps in RAM as VM start...\nRef: https://cloud.google.com/compute/docs/shutdownscript"},{"poster":"guid1984","content":"Answer is D please read below from google documentation \n\"Apply a shutdown script to running instances\nTo add a shutdown script to a running instance, follow the instructions in the Applying a startup script to running instances documentation but replace the metadata keys with one of the following keys:\n\nshutdown-script: Supply the shutdown script contents directly with this key. Using the gcloud command-line tool, you can provide the path to a shutdown script file, using the --metadata-from-file flag and the shutdown-script metadata key.\nshutdown-script-url: Supply a Cloud Storage URL to the shutdown script file with this key.\"\n\nReferences: https://cloud.google.com/compute/docs/shutdownscript","comment_id":"289580","upvote_count":"2","timestamp":"1613224860.0"},{"timestamp":"1611541380.0","upvote_count":"1","content":"Answer is C. For D, it is wrong. I don't think there is a way you can invoke the shutdown script by URL via any kind of API call.","poster":"bnlcnd","comment_id":"275634"},{"timestamp":"1604191740.0","upvote_count":"4","comment_id":"210208","content":"This is very tricky. Option C would be the best easiest approach, the problem with C is that it says \"when you create the new virtual machine instance\", it should say add to the already created instances. So the way C is worded, it would not execute the shutdown script in the instances that you already created. For that reason only I will choose D.","poster":"mexblood1"},{"comment_id":"205884","timestamp":"1603662480.0","upvote_count":"1","content":"Answer is C\nA startup script, or a shutdown script, is specified through the metadata server, using startup script metadata keys","poster":"hems4all"},{"timestamp":"1603105980.0","upvote_count":"1","poster":"sagarawale","comment_id":"202514","comments":[{"poster":"mwilbert","timestamp":"1609895940.0","comment_id":"260655","upvote_count":"1","content":"It also says that you want the existing machines to exit cleanly, which C doesn't do. D is the correct answer, because it does."}],"content":"People who are saying D please read the question and options clearly. C option clearly states \"Create a shutdown script and use it as the value for a new metadata entry with the key shutdown-script in the Cloud Platform Console when you create the new virtual machine instance\". It explicitly mentions while creating the instance. So the answer is C"},{"timestamp":"1601726640.0","content":"as VM's are already created we will need to update the metadata. Option C which is poplar answer will work for new VM's. Answer should be D. Refer - https://cloud.google.com/sdk/gcloud/reference/compute/instances/add-metadatahttps://cloud.google.com/sdk/gcloud/reference/compute/instances/add-metadata","poster":"SamirJ","upvote_count":"2","comment_id":"192236"},{"upvote_count":"1","timestamp":"1600112220.0","comment_id":"179520","content":"C - shutdown script having new metadata entry with the key shutdown-script","poster":"AshokC"},{"timestamp":"1599990180.0","upvote_count":"1","comment_id":"178639","content":"C is correct","poster":"gkdinesh"},{"poster":"wiqi","upvote_count":"2","comment_id":"162332","content":"The VMs are already created. So C can not be, as it states in the end, 'when you create the new'...I'd go with D\nThe command to add the script is\ngcloud compute instances add-metadata EXAMPLE_INSTANCE \\\n --metadata-from-file shutdown-script=PATH_TO_FILE","timestamp":"1597938540.0"},{"poster":"Musk","timestamp":"1596271440.0","comment_id":"148441","content":"Option C does not apply to running VMs, which is what we have. Option D works perfectly.","upvote_count":"3"},{"upvote_count":"3","timestamp":"1593265620.0","poster":"dreamer315","comment_id":"121246","content":"I guess its C, although this is applicable only for new VM instances and not existing one's. It can't be D because the that gcloud compute instances add-metadata command excepts the key-value pair. So key is shutdown-script-url but the value should \"a Cloud Storage URL to the shutdown script file with this key\" but in the choice (for D) it says shutdown script, registered as a xinetd service in Linux and not in publicly accessible url like GCS."},{"poster":"mlantonis","comment_id":"117178","content":"C is the correct","timestamp":"1592897640.0","upvote_count":"3"},{"upvote_count":"3","content":"C is the correct answer","poster":"Tushant","timestamp":"1592635920.0","comment_id":"114533"},{"comment_id":"111261","upvote_count":"4","poster":"hafid","timestamp":"1592275680.0","content":"Answer is D, \"You have created several pre-emptible Linux virtual machine instances using Google Compute Engine.\" take a look at the question. \n\"gcloud compute instances add-metadata can be used to add or update the metadata of a virtual machine instance\"\nhttps://cloud.google.com/sdk/gcloud/reference/compute/instances/add-metadata","comments":[{"upvote_count":"2","content":"I think the better/more obvious answer is C though.","timestamp":"1595966040.0","comment_id":"146074","poster":"mungrat"}]},{"comment_id":"106526","upvote_count":"3","poster":"gfhbox0083","content":"C, for sure","timestamp":"1591770300.0"},{"content":"C is the correct answer","timestamp":"1591106880.0","upvote_count":"3","poster":"Nirms","comment_id":"100896"},{"poster":"Ziegler","content":"C is the correct answer","upvote_count":"4","comment_id":"98446","timestamp":"1590780480.0"},{"content":"Agree C","upvote_count":"3","comment_id":"90258","timestamp":"1589679480.0","poster":"laksg"},{"content":"C is the answer","poster":"gcp_aws","timestamp":"1589323920.0","comment_id":"87990","upvote_count":"3"},{"timestamp":"1580390820.0","comment_id":"44730","content":"answer: C","poster":"2g","upvote_count":"2"},{"timestamp":"1579198140.0","poster":"sri007","upvote_count":"2","content":"C is correct","comment_id":"39814"},{"content":"Ans is C - \"The following is a shutdown script that you can add to a running preemptible instance or add to a new preemptible instance when you create it\"\nhttps://cloud.google.com/compute/docs/instances/create-start-preemptible-instance","timestamp":"1577355120.0","poster":"MyPractice","comment_id":"32744","upvote_count":"2"}],"answer_ET":"C","choices":{"D":"Create a shutdown script, registered as a xinetd service in Linux, and use the gcloud compute instances add-metadata command to specify the service URL as the value for a new metadata entry with the key shutdown-script-url","A":"Create a shutdown script named k99.shutdown in the /etc/rc.6.d/ directory","B":"Create a shutdown script registered as a xinetd service in Linux and configure a Stackdriver endpoint check to call the service","C":"Create a shutdown script and use it as the value for a new metadata entry with the key shutdown-script in the Cloud Platform Console when you create the new virtual machine instance"},"isMC":true},{"id":"CO1xLjbWjq16xjTx1dT2","answer_description":"","timestamp":"2019-11-25 01:05:00","exam_id":4,"discussion":[{"comment_id":"24165","upvote_count":"36","content":"D. refer to target filtering. https://cloud.google.com/solutions/best-practices-vpc-design","poster":"shandy","comments":[{"upvote_count":"8","poster":"tartar","content":"D is ok","comment_id":"157940","timestamp":"1597393620.0"},{"timestamp":"1604875980.0","poster":"pepYash","comments":[{"comment_id":"765056","content":"perfect! the example in that section is the exact question statement","upvote_count":"2","poster":"[Removed]","timestamp":"1672780140.0"}],"content":"Thank you for the link. \nPrecisely:\nhttps://cloud.google.com/solutions/best-practices-vpc-design#target_filtering","upvote_count":"9","comment_id":"215577"},{"upvote_count":"4","content":"D, firewalls can be done on ip or network tags or service accounts in GCE.","poster":"nitinz","timestamp":"1614896100.0","comment_id":"303622"},{"upvote_count":"1","content":"D is right","timestamp":"1665952980.0","poster":"AzureDP900","comment_id":"696554"}],"timestamp":"1574640300.0"},{"timestamp":"1630034880.0","upvote_count":"11","comment_id":"432741","poster":"amxexam","content":"Let's go with option elimination\n\nA. Add each tier to a different subnetwork\n>> Adding tiers to different subnets does not prevent or block them from accessing each other. Until specific firewall rules on VM or subnet allow access traffic on a specific port in the rule.\n\nB. Set up software-based firewalls on individual VMs\n>> Not a recommended practice will have to enable firewall anyway.\n\nC. Add tags to each tier and set up routes to allow the desired traffic flow\n>> Can be done but. \n\nD. Add tags to each tier and set up firewall rules to allow the desired traffic flow\n>> Recommended way\n\nHence D"},{"comment_id":"1314135","upvote_count":"1","content":"Selected Answer: D\n1. Firewall rules for security: Firewall rules provide the most granular and robust control over network traffic. By using tags to identify instances in each tier (web, API, database), you can create firewall rules that explicitly allow or deny traffic between these tiers.\n\n2. Controlling traffic flow: You can create rules that:\n - Allow traffic from the web tier to the API tier.\n - Allow traffic from the API tier to the database tier.\n- Explicitly deny traffic between the web and database tiers.\n\n3. Scalability and Flexibility: This approach works well even when your tiers scale independently. As new instances are added, they inherit the tags and automatically adhere to the defined firewall rules.","poster":"Ekramy_Elnaggar","timestamp":"1731954780.0"},{"content":"D is correct","comment_id":"1298612","timestamp":"1729067160.0","upvote_count":"1","poster":"ddatta"},{"content":"Selected Answer: D\nRoutes are typically used for directing traffic between networks rather than within the same network. While tags can be used for identifying resources, they are typically used in conjunction with firewall rules for controlling traffic flow.","upvote_count":"2","timestamp":"1708742820.0","poster":"lisabisa","comment_id":"1157613"},{"comment_id":"1025276","timestamp":"1696479480.0","upvote_count":"1","poster":"AdityaGupta","content":"Selected Answer: D\nWhy to implement anything else when Firewall is built-in within VPC and works based on Tags associated with resources."},{"poster":"heretolearnazure","content":"separate vnet is ruled out as they are on same network.","comment_id":"987682","timestamp":"1692728400.0","upvote_count":"1"},{"timestamp":"1685337180.0","content":"Selected Answer: D\nFor me most suitable answer is D","poster":"red_panda","upvote_count":"1","comment_id":"909053"},{"comment_id":"751956","poster":"omermahgoub","upvote_count":"5","content":"It's D\nTo configure the network so that traffic flows through the web to the API tier and then on to the database tier, but does not flow between the web and the database tier, you can add tags to each tier and set up firewall rules to allow the desired traffic flow. By adding tags to each tier, you can identify the VMs that belong to each tier and create firewall rules that allow traffic between the tiers as needed. For example, you can create a firewall rule that allows traffic from the web tier to the API tier, and another rule that allows traffic from the API tier to the database tier. This will ensure that traffic flows through the desired path and is not allowed between the web and database tiers.\n\nOther options, such as adding each tier to a different subnetwork or setting up software-based firewalls on individual VMs, may not provide the necessary level of control over the traffic flow between the tiers. Setting up routes to allow the desired traffic flow may not be sufficient to prevent traffic between the web and database tiers.","timestamp":"1671606420.0"},{"content":"Selected Answer: D\nD is ok","poster":"megumin","timestamp":"1667642160.0","upvote_count":"1","comment_id":"711654"},{"content":"Selected Answer: D\nD is right answer","comment_id":"701759","upvote_count":"1","timestamp":"1666468800.0","poster":"Mahmoud_E"},{"upvote_count":"1","poster":"minmin2020","comments":[{"upvote_count":"1","poster":"zr79","comment_id":"696796","content":"Did this appear in the exam?","timestamp":"1665979560.0"}],"comment_id":"693847","content":"Selected Answer: D\nHaving 3-tier web application deployed in the same network is wrong to begin with. However, even in different subnets you will need to apply firewall rules to prevent traffic between selected subnets. In this case they will probably be better of with D.","timestamp":"1665661560.0"},{"upvote_count":"1","timestamp":"1663818900.0","comment_id":"675721","poster":"holerina","content":"use firewall rules"},{"upvote_count":"1","comment_id":"599107","poster":"amxexam","timestamp":"1652110380.0","content":"Selected Answer: D\nA per my comment below ."},{"timestamp":"1640431200.0","content":"D is the correct answer","poster":"vincy2202","upvote_count":"3","comment_id":"509068"},{"poster":"haroldbenites","comment_id":"493604","upvote_count":"2","content":"Go for D","timestamp":"1638608880.0"},{"poster":"unnikrisb","timestamp":"1633770060.0","upvote_count":"2","comment_id":"459563","content":"From Google practice exam question : \nD is correct because as instances scale, they will all have the same tag to identify the tier. These tags can then be leveraged in firewall rules to allow and restrict traffic as required, because tags can be used for both the target and source.\nhttps://cloud.google.com/vpc/docs/using-vpc\nhttps://cloud.google.com/vpc/docs/routes\nhttps://cloud.google.com/vpc/docs/add-remove-network-tags"},{"comment_id":"389748","content":"Correct Answer: D\nThe web tier can communicate with end users and the app tier, and the app tier can communicate with the database tier, but no other communication between tiers is allowed. The instances running the web tier have a network tag of web, the instances running the app tier have a network tag of app, and the instances running the database tier have a network tag of db.\nhttps://cloud.google.com/architecture/best-practices-vpc-design#target_filtering","poster":"VishalB","timestamp":"1624550580.0","upvote_count":"1"},{"content":"D. Add tags to each tier and set up firewall rules to allow the desired traffic flow","poster":"victory108","timestamp":"1621401600.0","upvote_count":"3","comment_id":"361030"},{"upvote_count":"1","timestamp":"1620749160.0","comment_id":"354860","content":"D is correct","poster":"un"},{"timestamp":"1617165180.0","upvote_count":"1","comment_id":"324714","poster":"Ausias18","content":"answer is D"},{"content":"D is ok","poster":"lynx256","timestamp":"1617100140.0","comment_id":"324180","upvote_count":"1"},{"timestamp":"1602709740.0","upvote_count":"1","content":"D is correct. Setting up firewall rules ( Ingress/Egress ) and tags will help","poster":"Bharathy","comment_id":"200122"},{"timestamp":"1602547980.0","comment_id":"198869","upvote_count":"1","content":"it´s D , see google exam practice","poster":"[Removed]"},{"timestamp":"1600112820.0","upvote_count":"1","content":"D (key -> deployed in the same network)","poster":"AshokC","comment_id":"179522"},{"content":"Option D is right choice...","timestamp":"1599990420.0","poster":"gkdinesh","upvote_count":"1","comment_id":"178640"},{"poster":"passtest100","upvote_count":"1","timestamp":"1599956820.0","content":"C is better. first, tags on instance can be used to create routes applied for that instance. https://cloud.google.com/vpc/docs/add-remove-network-tags\nsecond, route is better than firewall rule in this scenario. route garantees the traffic from web to API only, while the firewall rule blocks traffic from web to DB.","comment_id":"178464"},{"poster":"wiqi","timestamp":"1597940520.0","comments":[{"content":"1 st point is wrong understanding of your","timestamp":"1630030740.0","upvote_count":"1","poster":"amxexam","comment_id":"432686"}],"content":"A. is incorrect. because the question is stating that '3-tier web application deployed in the same network`\nB. No need for this.\nC. No need for routing as its same network.\nD. is the way to secure it within the same network and to enforce desired flow.\n\nI'll go with D","comment_id":"162346","upvote_count":"2"},{"poster":"nezih","comment_id":"121847","upvote_count":"1","content":"I think this is \"choose 2 options\" kind of question. Non of them make sense by oneself. A won't work without creating firewall rules. D won't work because servers can communicate each other in default in same network. But A and D together correct.","timestamp":"1593346800.0"},{"comment_id":"117204","poster":"mlantonis","timestamp":"1592899080.0","content":"Definitely D","upvote_count":"3"},{"upvote_count":"2","comment_id":"114536","poster":"Tushant","content":"D is the correct answer","timestamp":"1592636160.0"},{"timestamp":"1591449240.0","content":"Why A is incorrect, and D is correct?\nAnswer: If you think on a network scale, bring Global infra in mind. Apps deployed based on subnetwork will become region locked.\nTags on the other hand, can be anywhere globally inside a network. That \"network\" is the keyword","comment_id":"103782","upvote_count":"4","poster":"KyubiBlaze"},{"comment_id":"100897","content":"D is the correct answer","upvote_count":"2","poster":"Nirms","timestamp":"1591107060.0"},{"comment_id":"98447","timestamp":"1590780600.0","content":"D is the correct answer","poster":"Ziegler","upvote_count":"3"},{"content":"D is the answer","comment_id":"93543","timestamp":"1590083520.0","poster":"gcp_aws","upvote_count":"1"},{"content":"Agree D","comment_id":"90259","poster":"laksg","upvote_count":"1","timestamp":"1589679540.0"},{"timestamp":"1589679300.0","upvote_count":"2","comment_id":"90254","content":"Agree D","poster":"laksg"},{"timestamp":"1589564940.0","comment_id":"89604","upvote_count":"2","poster":"gcp_aws","content":"D is the answer"},{"poster":"2g","timestamp":"1580390880.0","content":"answer: D","upvote_count":"3","comment_id":"44732"},{"upvote_count":"3","content":"D) is correct , shandy is right, please follow the link.","poster":"rockstar9622","timestamp":"1578827460.0","comment_id":"37978"},{"timestamp":"1577355960.0","poster":"MyPractice","comment_id":"32749","upvote_count":"2","content":"Ans A \"This allows you to create firewall rules that only apply to the VMs in a subnet—those with the associated network tag or service account\" meaning tags are associated with Subnets \nhttps://cloud.google.com/solutions/best-practices-vpc-design\nB - Not practical solution, C - talking about Routers, D - Are we allowed to add Tags to Tier??? \n\n(not with Tier - what happens if my Web Tier has 6 different subnets?)","comments":[{"poster":"MyPractice","timestamp":"1578022560.0","comment_id":"34759","upvote_count":"2","content":"Firewall rules and routes, Network tags allow you to apply firewall rules and routes to a specific instance or set of instances: You make a firewall rule applicable to specific instances by using target tags and source tags.\nhttps://cloud.google.com/vpc/docs/add-remove-network-tags\n\nYou make a route applicable to specific instances by using a tag."},{"content":"Its usually a combination of A & D. But default firewall rules allow internal communication, so putting them in subnets won't solve the problem by itself","upvote_count":"1","timestamp":"1596332820.0","comment_id":"148844","poster":"[Removed]"}]}],"answer":"D","unix_timestamp":1574640300,"question_images":[],"question_text":"Your organization has a 3-tier web application deployed in the same network on Google Cloud Platform. Each tier (web, API, and database) scales independently of the others. Network traffic should flow through the web to the API tier and then on to the database tier. Traffic should not flow between the web and the database tier.\nHow should you configure the network?","topic":"1","answers_community":["D (100%)"],"answer_ET":"D","choices":{"B":"Set up software based firewalls on individual VMs","C":"Add tags to each tier and set up routes to allow the desired traffic flow","D":"Add tags to each tier and set up firewall rules to allow the desired traffic flow","A":"Add each tier to a different subnetwork"},"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/9033-exam-professional-cloud-architect-topic-1-question-33/","question_id":128,"answer_images":[]},{"id":"fC1pnOXbRNrtyJkMADSO","unix_timestamp":1622820000,"exam_id":4,"answer":"ACE","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/54535-exam-professional-cloud-architect-topic-1-question-34/","discussion":[{"content":"ACE \nA. Use Stackdriver Logging to search for the module log entries = Check logs \nC. Use gcloud or Cloud Console to connect to the serial console and observe the logs = Check grub messages, remember new kernel module was installed. \nE. Adjust the Google Stackdriver timeline to match the failure time, and observe the batch server metrics = Zoom into the time window when problem happened.","comment_id":"374450","poster":"rishab86","upvote_count":"47","comments":[{"timestamp":"1623654660.0","comment_id":"381657","upvote_count":"3","poster":"Pokchok","content":"But the assumption you made is that stack driver was already installed on the vms. What if it was not there? Would there be any scope to install later and retrieve the logs?","comments":[{"comment_id":"765187","timestamp":"1672801260.0","poster":"[Removed]","upvote_count":"1","content":"But isn't it the same with B? it is talking about 'reading' the logs."}]},{"comments":[{"upvote_count":"1","content":"E observe the logs too. One of my problem is that several of the options go on and do some observation instead of just delivering.","poster":"tocsa","timestamp":"1717606560.0","comment_id":"1224865"}],"comment_id":"604707","timestamp":"1653105660.0","content":"A, B, E\nC - doesn't look correct as it ends with \"observe the logs\" - question is on sharing the details to development team, not to look for cause","poster":"AmitAr","upvote_count":"1"}],"timestamp":"1622820000.0"},{"poster":"haroldbenites","content":"Go for A,B,E.\nC is when the VM is running , but in this case the sentence says “recollect”. It means that “error ever” already happened.","upvote_count":"12","comment_id":"493608","comments":[{"comment_id":"519776","content":"and how will activity log help?","timestamp":"1641675720.0","upvote_count":"1","poster":"pddddd"}],"timestamp":"1638609240.0"},{"comment_id":"1399117","timestamp":"1742092200.0","content":"Selected Answer: ABE\nABE is much make sense to me","poster":"izekc","upvote_count":"1"},{"timestamp":"1735513080.0","content":"Selected Answer: ACE\nI will go for ACE.","comment_id":"1333775","upvote_count":"1","poster":"JonathanSJ"},{"poster":"Ishu_awsguy","content":"Selected Answer: ABE\nB vs C is the question.\nI vote for B , since activity logs now have been moved to audit logs and they provode system event information.\n\nC is moee real time, it will be a task to extract all the logs and put it to a file and share with dev team.\nAnyways audit logs is already abstracting that work for you.\nHence ABE is the right answer as per me","comment_id":"1332929","timestamp":"1735386360.0","upvote_count":"3"},{"poster":"mahi_h","content":"Selected Answer: ABE\nI chose B over C as both options trying to read/observe logs. But C looks like reading at the runtime. Give that, it's a nightly batch process, B seems to suitable post error occurrence.","comment_id":"1328004","timestamp":"1734450000.0","upvote_count":"1"},{"content":"Selected Answer: ACD\nA. Use Stackdriver Logging to search for the module log entries: This will help you identify any errors or issues related to the new kernel module that were logged during the batch process.\n\nC. Use gcloud or Cloud Console to connect to the serial console and observe the logs: The serial console logs can provide detailed information about the boot process and any kernel-related messages that might indicate why the batch servers failed.\n\nD. Identify whether a live migration event of the failed server occurred, using the activity log: Live migration events can sometimes cause disruptions. Checking the activity log will help you determine if this was a factor in the failures.","timestamp":"1733955960.0","comment_id":"1325289","upvote_count":"2","poster":"deep316"},{"upvote_count":"1","timestamp":"1733955900.0","poster":"deep316","comment_id":"1325288","content":"Selected Answer: ACE\nA. Use Stackdriver Logging to search for the module log entries: This will help you identify any errors or issues related to the new kernel module that were logged during the batch process.\n\nC. Use gcloud or Cloud Console to connect to the serial console and observe the logs: The serial console logs can provide detailed information about the boot process and any kernel-related messages that might indicate why the batch servers failed.\n\nD. Identify whether a live migration event of the failed server occurred, using the activity log: Live migration events can sometimes cause disruptions. Checking the activity log will help you determine if this was a factor in the failures."},{"comment_id":"1314141","poster":"Ekramy_Elnaggar","content":"Selected Answer: ACE\nA. Use Stackdriver Logging to search for the module log entries: This is crucial. Stackdriver Logging aggregates logs from various sources, including your VMs. You can search for specific entries related to the new kernel module to identify errors, warnings, or unusual behavior that might explain the failures.\n\nC. Use gcloud or Cloud Console to connect to the serial console and observe the logs: The serial console provides access to the VM's output even if the system is unresponsive. This can be invaluable for capturing kernel panic messages, boot errors, or other critical information that might not be available through standard logging channels.\n\nE. Adjust the Google Stackdriver timeline to match the failure time, and observe the batch server metrics: Stackdriver Monitoring provides detailed performance metrics for your VMs. By aligning the timeline with the failures, you can analyze CPU usage, memory consumption, disk I/O, and network activity.","timestamp":"1731955140.0","upvote_count":"3"},{"content":"Selected Answer: ABE\nconsidering that logs from the serial console might not be useful after two days:\n\nA. Use Stackdriver Logging to search for the module log entries: This will help you identify any errors or issues logged by the new kernel module.\n\nB. Read the debug GCE Activity log using the API or Cloud Console: This can provide information on significant events like reboots or live migrations that might have affected the batch process.\n\nE. Adjust the Google Stackdriver timeline to match the failure time, and observe the batch server metrics: This helps correlate the failure with any anomalies in the server metrics, providing insights into what might have gone wrong.","comment_id":"1308011","timestamp":"1730912460.0","poster":"SerGCP","upvote_count":"1"},{"comment_id":"1302396","upvote_count":"1","timestamp":"1729764240.0","content":"Answer is ACE","poster":"nareshthumma"},{"timestamp":"1723101600.0","poster":"Hungdv","upvote_count":"1","content":"Vote ACE","comment_id":"1262378"},{"comment_id":"1205125","timestamp":"1714573680.0","upvote_count":"2","content":"Selected Answer: ABE\nI'm not sure but I vote for ABE","poster":"Gino17m"},{"poster":"ashishdwi007","content":"ACE makes sense. \nA and E dont have any doubts. Questions is that if it is B, C or F. \nWhats' use of serial console if team does not use it for logging especially kernal related updates. that makes sense to choose C.","upvote_count":"1","comment_id":"1128987","timestamp":"1705953420.0"},{"comment_id":"1075717","content":"Selected Answer: ABE\nMost automated way, with C, collecting from VMs involves a lot of manual efforts","timestamp":"1700505180.0","upvote_count":"3","poster":"CloudDom"},{"comment_id":"971320","timestamp":"1691080980.0","content":"Selected Answer: ABE\nABE is correct","poster":"pablobairat","upvote_count":"2"},{"comment_id":"764609","poster":"Ozymandiax","timestamp":"1672747560.0","upvote_count":"9","content":"I'm really not sure here. A and E are just OK, and for me the final point is between B o C. many ppl is saying C, but, the question says that the VM's already failed and you're investigating what happened in the past. \n\nAnyway, there are 2 ways to interpret this, from my point of view:\n1) The failure happened and it's going to happen again. In this case ACE would be maybe the best option\nBUt\n2) The failure happened and you want to investigate this failure, which happened in the past. Therefore ABE would be the right one, as you are \"splunking\" in the logs of the past, not having a review of the logs as they happen.\n\nfrom my personal interpretation I'd go with ABE"},{"comment_id":"751960","poster":"omermahgoub","upvote_count":"4","timestamp":"1671606720.0","content":"ACE\nTo collect details on the failure of the batch servers in GCE VMs, you can take the following actions:\n\nA: Stackdriver Logging can help you identify any issues related to the new Linux kernel module by searching for log entries related to the module.\n\nC: Connecting to the serial console allows you to view the logs in real-time as the batch servers are running. This can help you identify any issues related to the new kernel module.\n\nE: By adjusting the timeline in Stackdriver to match the failure time, you can view the batch server metrics during the time when the failures occurred. This can help you identify any issues related to the new kernel module.\n\nOther options, such as reading the debug GCE Activity log using the API or Cloud Console, identifying whether a live migration event of the failed server occurred, or exporting a debug VM into an image and running the image on a local server, may not provide the necessary information to understand"},{"comment_id":"693859","content":"Selected Answer: ACE\nACE by eliminating the incorrect answers","upvote_count":"2","timestamp":"1665661920.0","poster":"minmin2020"},{"timestamp":"1663818960.0","content":"ADE seems correct","poster":"holerina","upvote_count":"1","comment_id":"675722"},{"poster":"PaulCatalin","timestamp":"1663591560.0","content":"Selected Answer: ACE\nI vote for.","comment_id":"673283","upvote_count":"1"},{"poster":"ehgm","content":"This question is very poorly asked.\n\nThere is no place saying if the live migration is enabled. If a VM is not set to live migrate, the VM is terminated during host system events.\n\nThere is no place saying if you run into problems accessing your instance through SSH or need to troubleshoot an instance that is not fully booted, so you can enable interactive access to the serial console.\n\nC: https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console\nD: https://cloud.google.com/compute/docs/instances/live-migration","comment_id":"510387","timestamp":"1640615880.0","upvote_count":"4"},{"comment_id":"499122","upvote_count":"2","content":"Selected Answer: ACE\nACE are the correct choices","timestamp":"1639195620.0","poster":"vincy2202"},{"upvote_count":"3","timestamp":"1638142680.0","poster":"duocnh","content":"Selected Answer: ACE\nvote ACE","comment_id":"489487"},{"poster":"MaxNRG","content":"I would say that Q26 = ABE\nA - since it investigates logs of Linux kernel module installed recently. For that Log Agent should be installed on VMs and Linux syslog is streamed by default to Stackdriver Logging via agent. So, this answer is relevant to Q's context, it checks if new Linux kernel runs OK.\nB - investigates \"app-level\" issues on GCE, logs API called from this VM, system events, etc.\nC - review of Serial Log is useful only for HW/OS crashes, and only during short period of time (since only last 1MB of logs are stored there, if more logs needed then they are streamed to Stackdriver logging). So, this option doesn't fit 2 days period and also serves different failure types.\nD - live migration event is irrelevant to this Q (transferring hot/running context of one VM to another transparently, so original VM can be maintained – BIOS/HW updates). Even if that happens, then GCE activity logs in B should cover this.\nE - monitoring of metrics at the time of failure makes sense for troubleshooting.\nF - smth long and ridiculous.","upvote_count":"6","timestamp":"1635094560.0","comment_id":"467061"},{"timestamp":"1633714200.0","comments":[{"poster":"ashish_t","comment_id":"460171","content":"F is practically impossible.","upvote_count":"1","timestamp":"1633887000.0"}],"content":"If I'm reading \"F\" correctly, it is to export a VM and move it back to a \"local\" server which I'm reading as \"on-prem\", your laptop, or your local datacenter.(aka NOT GCP) So if I'm reading that correctly, that is a very ineffective idea. Keep it in GCP and use the powerful GCP tools. If somebody feels that I'm reading that wrong, I would love to see from a different POV. If you are reading that the same as me, then rule out F.","comment_id":"459361","poster":"[Removed]","upvote_count":"1"},{"poster":"[Removed]","comment_id":"459358","upvote_count":"1","content":"We can also rule out D, Live Migration Event. Unless it is called out, regular VMs can be live migrated without an notice of the guest os. So this should not be your focus. Rule out D.\n\nhttps://cloudplatform.googleblog.com/2015/03/Google-Compute-Engine-uses-Live-Migration-technology-to-service-infrastructure-without-application-downtime.html","timestamp":"1633713660.0"},{"upvote_count":"6","content":"So in an effort to rule things out, B is not applicable. The question says Activity Log, but this is now called Audit Log and is a record of who touched the server and made changes. So if you think a human/service came in after the fact and modified the system, then this would be useful, but that is not the case here. So rule it out. \n\nhttps://cloud.google.com/compute/docs/logging/audit-logging\n\n \"Who did what, where, and when?\"","poster":"[Removed]","timestamp":"1633712820.0","comment_id":"459353"},{"comment_id":"458351","comments":[{"comment_id":"459501","timestamp":"1633756620.0","upvote_count":"2","content":"\"You want to collect details on the failure\" says the question. And D is not related with the failure reason but the after failure action.","poster":"kalamarka"}],"upvote_count":"2","content":"Is there any reason why can't 'D' be an answer?","poster":"maxlearn","timestamp":"1633536540.0"},{"content":"A. Use Stackdriver Logging to search for the module log entries\nC. Use gcloud or Cloud Console to connect to the serial console and observe the logs\nE. Adjust the Google Stackdriver timeline to match the failure time and observe the batch server metrics","timestamp":"1625407200.0","upvote_count":"2","poster":"victory108","comment_id":"398396"},{"comments":[{"content":"I think ACE is correct.\nOnly the batch job is failed VM is still running so it will still have serial port output","timestamp":"1624719660.0","poster":"aviratna","upvote_count":"3","comment_id":"391338"}],"upvote_count":"2","timestamp":"1624180740.0","content":"Serial port output is accessible through the Cloud Console, the gcloud tool, and the Compute Engine API, but only while the VM instance is running. https://cloud.google.com/compute/docs/instances/viewing-serial-port-output\n\nRequirement is to collect information about failed batch servers which have already happened. Hence C is not suitable. Live migration doesn't disrupt running VM. \n\nA, B, E.","poster":"Yogikant","comment_id":"386095"}],"answer_images":[],"choices":{"D":"Identify whether a live migration event of the failed server occurred, using in the activity log","C":"Use gcloud or Cloud Console to connect to the serial console and observe the logs","F":"Export a debug VM into an image, and run the image on a local server where kernel log messages will be displayed on the native screen","E":"Adjust the Google Stackdriver timeline to match the failure time, and observe the batch server metrics","B":"Read the debug GCE Activity log using the API or Cloud Console","A":"Use Stackdriver Logging to search for the module log entries"},"question_text":"Your development team has installed a new Linux kernel module on the batch servers in Google Compute Engine (GCE) virtual machines (VMs) to speed up the nightly batch process. Two days after the installation, 50% of the batch servers failed the nightly batch run. You want to collect details on the failure to pass back to the development team.\nWhich three actions should you take? (Choose three.)","topic":"1","timestamp":"2021-06-04 17:20:00","answers_community":["ACE (46%)","ABE (46%)","7%"],"isMC":true,"question_images":[],"answer_ET":"ACE","question_id":129},{"id":"3LIQ6kEcf1jtjotgA9CQ","exam_id":4,"choices":{"C":"Import logs into Google Stackdriver","E":"Upload log files into Google Cloud Storage","B":"Load logs into Google Cloud SQL","A":"Load logs into Google BigQuery","D":"Insert logs into Google Cloud Bigtable"},"answer_ET":"AE","url":"https://www.examtopics.com/discussions/google/view/54534-exam-professional-cloud-architect-topic-1-question-35/","topic":"1","unix_timestamp":1622816160,"answer_images":[],"timestamp":"2021-06-04 16:16:00","discussion":[{"comment_id":"374404","timestamp":"1622816160.0","poster":"rishab86","upvote_count":"34","content":"Answer is A as they want to load logs for analytics and E for storing data in buckets for long term."},{"timestamp":"1671606960.0","poster":"omermahgoub","upvote_count":"12","content":"AE\nTo archive approximately 100 TB of log data to the cloud and test the analytics features available while also retaining the data as a long-term disaster recovery backup, you can take the following steps:\n\nE: Upload log files into Google Cloud Storage: Google Cloud Storage is a scalable, durable, and fully-managed cloud storage service that can be used to store large amounts of data. You can upload your log files to Cloud Storage to archive them in the cloud.\n\nA: Load logs into Google BigQuery: Google BigQuery is a fully-managed, cloud-native data warehouse that can be used to analyze large amounts of data quickly and efficiently. You can load your log data into BigQuery to perform analytics on it and test the available analytics features.\n\nOther options, such as loading logs into Google Cloud SQL, importing logs into Google Stackdriver, or inserting logs into Google Cloud Bigtable, may not provide the necessary functionality for archiving and analyzing the log data.","comment_id":"751962"},{"content":"Selected Answer: AE\nI will go for AE.","comment_id":"1333777","upvote_count":"1","poster":"JonathanSJ","timestamp":"1735513140.0"},{"timestamp":"1731955500.0","poster":"Ekramy_Elnaggar","comment_id":"1314146","upvote_count":"3","content":"Selected Answer: AE\nA. Load logs into Google BigQuery: BigQuery is Google Cloud's serverless, highly scalable, and cost-effective multicloud data warehouse designed for data analytics. It's ideal for storing and analyzing large volumes of log data (100 TB in this case). You can use BigQuery's powerful SQL capabilities to run queries, generate reports, and gain insights from your logs.\n\nE. Upload log files into Google Cloud Storage: Cloud Storage provides durable, scalable, and secure object storage. It's perfect for storing your log data as a long-term disaster recovery backup. Cloud Storage offers different storage classes to optimize costs based on your data access frequency and retention needs."},{"upvote_count":"2","poster":"ionescuandrei","content":"Selected Answer: AE\nThis looks right.","comment_id":"859857","timestamp":"1680521760.0"},{"upvote_count":"3","poster":"CMata","comment_id":"718604","content":"Selected Answer: AE\nIf you want to analize those logs its recommended Big Query. For storing and backup Cloud Storage is your option, so AE","timestamp":"1668501720.0"},{"upvote_count":"2","poster":"AzureDP900","content":"A and E can do the required task","comment_id":"696558","timestamp":"1665953160.0"},{"upvote_count":"1","timestamp":"1665662760.0","comment_id":"693867","content":"Selected Answer: AE\nAE are the only options for analysis and archiving","poster":"minmin2020"},{"poster":"holerina","timestamp":"1663819140.0","comment_id":"675723","content":"A load in Big query for analytics and E for cloud storage","upvote_count":"1"},{"timestamp":"1660898520.0","comment_id":"648825","upvote_count":"1","content":"Selected Answer: AE\nThe key word is 'Analytics' here the main reason for moving logs to GCP is to perform Analytics on the data. BigQuery is the best suite for it. For long term storage it wiould be GC","poster":"Ramheadhunter"},{"content":"Selected Answer: CE\nAnswer is C and E\n\nKey features\nReal-time log management and analysis\nCloud Logging is a fully managed service that performs at scale and can ingest application and platform log data, as well as custom log data from GKE environments, VMs, and other services inside and outside of Google Cloud. Get advanced performance, troubleshooting, security, and business insights with Log Analytics, integrating the power of BigQuery into Cloud Logging. - https://cloud.google.com/products/operations","poster":"raaj_p","timestamp":"1659967260.0","comments":[{"content":"you don't do realtime log management on 10 TB data.\nYou only perform analytics on it. \nSo A for Analytics\nE for storage.","poster":"AMohanty","comment_id":"646078","upvote_count":"6","timestamp":"1660355520.0"},{"comment_id":"1224868","poster":"tocsa","timestamp":"1717606800.0","upvote_count":"1","content":"Is it even possible to import 10TB of logs into StackDriver?"}],"upvote_count":"2","comment_id":"644167"},{"content":"Selected Answer: AE\nBig Query for analytics, Cloud Storage for long term archive","upvote_count":"3","comment_id":"642301","timestamp":"1659606720.0","poster":"faagee01"},{"poster":"Dhiraj03","upvote_count":"1","timestamp":"1655536560.0","comment_id":"618116","content":"For Storage GCS is the best option and for analyzing the data BIg Query makes sense"},{"upvote_count":"2","poster":"Nirca","timestamp":"1650897000.0","comment_id":"591770","content":"A E are ok"},{"timestamp":"1640431680.0","content":"AE are the correct answers","comment_id":"509078","poster":"vincy2202","upvote_count":"3"},{"upvote_count":"4","poster":"andeu","comments":[{"poster":"MQQ","timestamp":"1654251600.0","comment_id":"611023","content":"But BigQuery is for SQL DATA, the logs are nosql ?\nWhy not choose stackdriver?","upvote_count":"1"}],"timestamp":"1639708860.0","comment_id":"503311","content":"Answers: A is correct because BigQuery is the fully managed cloud data warehouse for analytics and supports the analytics requirement.\nE is correct because Cloud Storage provides the Coldline storage class to support long-term storage with infrequent access, which would support the long-term disaster recovery backup requirement.\nhttps://cloud.google.com/bigquery/\nhttps://cloud.google.com/stackdriver/\nhttps://cloud.google.com/storage/docs/storage-classes#coldline\nhttps://cloud.google.com/sql/\nhttps://cloud.google.com/bigtable/"},{"upvote_count":"3","content":"Go for A,E","comment_id":"493609","timestamp":"1638609300.0","poster":"haroldbenites"},{"content":"A and E","poster":"Bakili","comment_id":"489859","timestamp":"1638188400.0","upvote_count":"1"},{"content":"A E is the right answer","poster":"nocrush","comment_id":"461673","timestamp":"1634148480.0","upvote_count":"2"},{"poster":"sandipk91","content":"A & E is correct","timestamp":"1630406460.0","upvote_count":"3","comment_id":"436241"},{"poster":"bala786","content":"Yes Option A and E - correct","timestamp":"1625706120.0","upvote_count":"3","comment_id":"401411"},{"timestamp":"1625407020.0","comment_id":"398392","upvote_count":"4","content":"A. Load logs into Google BigQuery\nE. Upload log files into Google Cloud Storage","poster":"victory108"},{"comment_id":"387384","poster":"Areev","timestamp":"1624304520.0","upvote_count":"1","content":"A and E seems to be right."}],"question_images":[],"answers_community":["AE (88%)","13%"],"isMC":true,"answer":"AE","answer_description":"","question_id":130,"question_text":"Your company wants to try out the cloud with low risk. They want to archive approximately 100 TB of their log data to the cloud and test the analytics features available to them there, while also retaining that data as a long-term disaster recovery backup.\nWhich two steps should you take? (Choose two.)"}],"exam":{"numberOfQuestions":279,"name":"Professional Cloud Architect","id":4,"lastUpdated":"11 Apr 2025","isBeta":false,"isImplemented":true,"provider":"Google","isMCOnly":false},"currentPage":26},"__N_SSP":true}