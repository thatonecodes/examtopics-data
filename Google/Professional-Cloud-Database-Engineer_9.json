{"pageProps":{"questions":[{"id":"xDGlutcrfwfHYx2YWUus","answer_ET":"B","question_id":41,"answer_images":[],"exam_id":5,"timestamp":"2022-12-19 09:19:00","isMC":true,"question_images":[],"discussion":[{"timestamp":"1694445600.0","content":"B.\nQuery Insights helps identify performance and load issues at the database application layer. None of the other options do that. So the answer is B.","upvote_count":"8","comment_id":"836316","poster":"dynamic_dba"},{"content":"Selected Answer: B\nVote for B","upvote_count":"5","comment_id":"757689","timestamp":"1687793220.0","poster":"chelbsik"},{"comment_id":"1208869","upvote_count":"2","content":"Selected Answer: B\nB. Query Insights is built in feature to identify long running query","poster":"hanayome","timestamp":"1731165600.0"},{"comment_id":"830220","upvote_count":"3","timestamp":"1693933740.0","poster":"H_S","content":"Selected Answer: B\nB. Query insights: for identifying long running SQLs https://cloud.google.com/sql/docs/mysql/using-query-insights#introduction"},{"comment_id":"829355","poster":"Nirca","content":"Selected Answer: B\nB. Query insights: for identifying long running SQLs https://cloud.google.com/sql/docs/mysql/using-query-insights#introduction","upvote_count":"3","timestamp":"1693850340.0"},{"timestamp":"1691732280.0","poster":"SidsA","content":"Answer should be B: As long-running query and resource intensive queries are available in query insight providing details about which queries are taking how much time and resource utilization at what stage.","upvote_count":"4","comment_id":"805062"},{"content":"Option B\n\nhttps://cloud.google.com/sql/docs/postgres/using-query-insights","poster":"Blueocean","comment_id":"756000","upvote_count":"3","timestamp":"1687718820.0"},{"comment_id":"755768","upvote_count":"1","content":"B: Use Query Insights for Cloud SQL.\n\nging multiple applications connecting","poster":"pk349","timestamp":"1687699140.0"},{"upvote_count":"1","content":"Selected Answer: B\nB is the correct answer, agree with jitu028","poster":"GCP72","comment_id":"754717","timestamp":"1687580040.0"},{"timestamp":"1687446720.0","content":"Correct answer - B\nhttps://www.youtube.com/watch?v=qN7x3ngwz1o","comment_id":"753515","poster":"jitu028","upvote_count":"2"},{"poster":"range9005","timestamp":"1687345320.0","upvote_count":"1","comment_id":"752317","content":"Selected Answer: D\nFor Database performance, Cloud SQL System insights dashboard is preferable"},{"poster":"Kloudgeek","comment_id":"750014","content":"C is correct answer. We can use Cloud SQL Instance monitoring as well, but need to build the custom metrics for the metrics needed. Instead with Cloud Monitoring these metrics are already available. https://cloud.google.com/sql/docs/mysql/monitor-instance#cloud-monitoring https://cloud.google.com/sql/docs/sqlserver/admin-api/metrics","upvote_count":"1","timestamp":"1687183980.0"},{"upvote_count":"1","poster":"range9005","comment_id":"749618","timestamp":"1687155540.0","content":"Selected Answer: D\nThe Cloud SQL System insights dashboard helps you detect and analyze system performance problems.\n.\nhttps://cloud.google.com/sql/docs/postgres/monitor-instance#sql-system-insights"}],"choices":{"D":"Use Cloud SQL instance monitoring in the Google Cloud Console.","C":"Use the Cloud Monitoring dashboard with available metrics from Cloud SQL.","A":"Use log messages produced by Cloud SQL.","B":"Use Query Insights for Cloud SQL."},"answer_description":"","answer":"B","topic":"1","url":"https://www.examtopics.com/discussions/google/view/92052-exam-professional-cloud-database-engineer-topic-1-question/","question_text":"You are managing multiple applications connecting to a database on Cloud SQL for PostgreSQL. You need to be able to monitor database performance to easily identify applications with long-running and resource-intensive queries. What should you do?","unix_timestamp":1671437940,"answers_community":["B (88%)","13%"]},{"id":"u8trzYlh8Ja1EPTeeN9K","choices":{"C":"Use Firestore in Native mode, and store user profile data as a document. Update the user profile with preferences specific to that user and use the user identifier to query.","D":"Use Firestore in Datastore mode, and store user profile data as a document. Update the user profile with preferences specific to that user and use the user identifier to query.","A":"Store your data in Bigtable, and use the user identifier as the key. Use one column family to store user profile data, and use another column family to store user preferences.","B":"Use Cloud SQL, and create different tables for user profile data and user preferences from your recommendations model. Use SQL to join the user profile data and preferences"},"answer":"C","answer_images":[],"answer_description":"","answer_ET":"C","timestamp":"2022-12-20 20:02:00","question_id":42,"question_images":[],"topic":"1","discussion":[{"comment_id":"851080","timestamp":"1695735180.0","content":"Selected Answer: C\nDynamic schema indicates this is a NoSQL solution (ruling out Cloud SQL) and the application use case specifically suits Firestore (the question even refers to storing data in documents) as opposed to BigTable.\n\nFirestore in Native supports realtime client updates, which is needed for the analytics requirement: https://cloud.google.com/firestore/docs/firestore-or-datastore#feature_comparison","upvote_count":"5","poster":"BenMS"},{"comment_id":"836332","content":"C.\nA dynamic schema means the database backend cannot be relational. That eliminates B. No criteria is mentioned that would justify Bigtable (low latency or massive data volume), so eliminate A. That leaves Firestore options which make sense since it’s a NoSQL database. Since “website” and “mobile” are both mentioned in the question, Firestore in Native mode must be the correct answer.","upvote_count":"5","timestamp":"1694446680.0","poster":"dynamic_dba"},{"upvote_count":"2","poster":"abhinav45852","comment_id":"1124571","content":"Selected Answer: A\nFirestore in native mode and Bigtable both seems to be correct answer but weightage can be given to Bigtable on the basis of replication to BigQuery via change streams is easier.","timestamp":"1721164020.0"},{"content":"Selected Answer: C\nUse Firestore in Datastore mode for new server projects.\n\nFirestore in Datastore mode allows you to use established Datastore server architectures while removing fundamental Datastore limitations. Datastore mode can automatically scale to millions of writes per second.\n\nUse Firestore in Native mode for new mobile and web apps.\n\nFirestore offers mobile and web client libraries with real-time and offline features. Native mode can automatically scale to millions of concurrent clients.","upvote_count":"3","timestamp":"1698597360.0","comment_id":"884396","poster":"Shadab"},{"timestamp":"1687699080.0","upvote_count":"2","poster":"pk349","comment_id":"755766","content":"C: Use Firestore in Native mode, and store user profile data as a document. Update the user profile with preferences specific to that user and use the user identifier to query."},{"poster":"GCP72","content":"Selected Answer: C\nC is the correct Answer","comment_id":"754725","timestamp":"1687581060.0","upvote_count":"2"},{"poster":"range9005","content":"Selected Answer: C\nFirestore introduces new features such as:\n\nA new, strongly consistent storage layer\nA collection and document data model\nReal-time updates\nMobile and Web client libraries\n.\nhttps://cloud.google.com/datastore/docs/firestore-or-datastore#in_native_mode","timestamp":"1687345440.0","upvote_count":"3","comment_id":"752321"},{"timestamp":"1687280520.0","poster":"fredcaram","upvote_count":"2","content":"Selected Answer: C\nSeems like a better use for firestore and since it needs to reflect changes downstream in real time the native one would be better.","comment_id":"751360"}],"unix_timestamp":1671562920,"url":"https://www.examtopics.com/discussions/google/view/92212-exam-professional-cloud-database-engineer-topic-1-question/","answers_community":["C (88%)","12%"],"isMC":true,"question_text":"You are building an application that allows users to customize their website and mobile experiences. The application will capture user information and preferences. User profiles have a dynamic schema, and users can add or delete information from their profile. You need to ensure that user changes automatically trigger updates to your downstream BigQuery data warehouse. What should you do?","exam_id":5},{"id":"cjzhYY0KVaVPgrSYSblO","discussion":[{"upvote_count":"7","content":"B, C.\nYou have 2 problems. Replication lag and slow report performance. E is eliminated because using BigQuery would mean changes to the current reports. Report slowness could be the result of poor indexing or just too much read load (or both!). Since excessive load is mentioned in the question, creating additional read replicas and spreading the analytics workload around makes B correct and eliminates A as a way to speed up reporting. That leaves the replication problem. Cloud SQL enables single threaded replication by default, so it stands to reason enabling parallel replication would help the lag. To do that you disable replication on the replica (not the primary), set flags on the replica and optionally set flags on the primary instance to optimize performance for parallel replication. That makes C correct and D incorrect.\nhttps://cloud.google.com/sql/docs/mysql/replication/manage-replicas#configuring-parallel-replication","comment_id":"836416","comments":[{"upvote_count":"1","poster":"cardareel","timestamp":"1694797800.0","comments":[{"comment_id":"1410678","timestamp":"1743036000.0","poster":"hmarine","upvote_count":"1","content":"B is not a problem, as the report content itself is unchanged."}],"comment_id":"1008608","content":"B isn't correct ==> \"without making changes to the current reports\". If you choose B, reports will need changes to point to the new instances."}],"poster":"dynamic_dba","timestamp":"1678561140.0"},{"comment_id":"766091","poster":"ssaporylo","upvote_count":"7","content":"Vote for AC\nA https://cloud.google.com/sql/docs/mysql/replication/read-replica-indexes increase performance on read operation\nC https://cloud.google.com/sql/docs/mysql/replication/manage-replicas#basic-steps-to-change-parallel-replication-flags","timestamp":"1672866240.0"},{"content":"Selected Answer: AC\nThe two main issues at hand are replication lag and slow report performance. While option B, creating additional read replicas, could address the load issue, it would require changes to the current reports, which is not desirable. Instead, option A, implementing secondary indexes in Cloud SQL, could enhance report speed without altering the reports. As for the replication lag, option C suggests enabling parallel replication in Cloud SQL, which is a plausible solution. To do that you disable replication on the replica (not the primary), set flags on the replica and optionally set flags on the primary instance to optimize performance for parallel replication. Therefore, considering the constraints and the context, options A and C are the most suitable choices.","poster":"Lenifia","comment_id":"1244751","upvote_count":"1","timestamp":"1720508460.0"},{"timestamp":"1717526160.0","content":"Selected Answer: BC\nB - Addresses performance improvements: Reduce the burden on the primary instance by offloading replication work to multiple read replicas.\nhttps://cloud.google.com/sql/docs/mysql/replication#cascading-replicas\nC- Addresses lag time because Parallel replication reduces replication lag by increasing the number of SQL threads that work to execute these transactions.\nhttps://cloud.google.com/sql/docs/mysql/replication/manage-replicas#configuring-parallel-replication","upvote_count":"1","poster":"studymoreoften","comment_id":"1224286"},{"content":"Selected Answer: C\nJust got this question and there is no A, and it is not 'choose two' but one answer only.","upvote_count":"3","comment_id":"1148272","poster":"PKookNN","timestamp":"1707752100.0"},{"poster":"cardareel","content":"There's no discussion about C.\nA & B both sounds reasonable. Why I would choose A instead of B? Due to keywords \"without making changes to the current reports\" and \"MySQL\". Option B would require to point to new IP addresses (the new read replicas) and split which group of users which run X reports and which group of user which run Y reports connect to which read replica. Option A (secondary indexes) is only available for Cloud SQL (the question's use case is about MySQL) and explicitly mentions \"for reporting purposes\".","upvote_count":"4","comment_id":"997928","timestamp":"1693771140.0"},{"upvote_count":"3","comments":[],"poster":"KennyHuang","content":"Selected Answer: BC\nB. By creating additional read replicas, you can distribute the load of analytics workloads across multiple instances. Partitioning your analytics users to use different read replicas allows you to further distribute the workload and improve performance. This helps to alleviate the excessive load on the primary database and enhances the reporting experience for users.\nC. Disabling replication on the read replica can help reduce the data replication lag. By setting the flag for parallel replication on the read replica, you allow parallel execution of replication threads, which can expedite data replication. Additionally, optimizing performance by setting flags on the primary instance can help improve the overall performance of the replication process and reduce the lag experienced by the read replica.","comment_id":"907397","timestamp":"1685108640.0"},{"comment_id":"832530","timestamp":"1678250280.0","poster":"Hilab","upvote_count":"1","comments":[{"comment_id":"832531","upvote_count":"1","poster":"Hilab","timestamp":"1678250280.0","content":"Disabling replication on the primary instance and setting the flag for parallel replication can improve the replication speed and reduce the lag in data replication. Once you have optimized performance on the primary instance, you can re-enable replication and optimize performance on the read replica.\n\nCreating secondary indexes on the replica may improve query performance but will not reduce the lag in data replication. Moving your analytics workloads to BigQuery and setting up a streaming pipeline to move data can provide near-real-time data but will require significant changes to your current reports."}],"content":"B. Create additional read replicas, and partition your analytics users to use different read replicas.\nD. Disable replication on the primary instance, and set the flag for parallel replication on the primary instance. Re-enable replication and optimize performance by setting flags on the read replica.\n\nCreating additional read replicas can distribute the analytics workload and reduce the lag in data replication. By partitioning your analytics users to use different read replicas, you can further reduce the load on each replica and improve performance."},{"upvote_count":"1","comments":[],"comment_id":"830234","content":"Selected Answer: BC\nB. Create additional read replicas, and partition your analytics users to use different read replicas. Most Voted\nC. Disable replication on the read replica, and set the flag for parallel replication on the read replica. Re-enable replication and optimize performance by setting flags on the primary instance.","poster":"H_S","timestamp":"1678043940.0"},{"content":"Selected Answer: BC\nA. Create secondary indexes on the replica. - No indication that the reports will benefit from indexes. \nB. Create additional read replicas, and partition your analytics users to use different read replicas. --> might rebalance the load. \nC. Disable replication on the read replica, and set the flag for parallel replication on the read replica. Re-enable replication and optimize performance by setting flags on the primary instance. --> might add parallelism to the replication lag. \nD. Disable replication on the primary instance, and set the flag for parallel replication on the primary instance. Re-enable replication and optimize performance by setting flags on the read replica. --> na\nE. Move your analytics workloads to BigQuery, and set up a streaming pipeline to move data and update BigQuery.--> according to question statement , no SQL rewrite is possible.","poster":"Nirca","timestamp":"1677961080.0","comment_id":"829371","upvote_count":"2"},{"poster":"Swapnil54","content":"A & C looks fine.","timestamp":"1676865120.0","upvote_count":"2","comment_id":"814796"},{"upvote_count":"3","comment_id":"788801","timestamp":"1674743160.0","content":"Selected Answer: AC\nAns is AC","poster":"muky31dec"},{"content":"Creating secondary indexes on the replica can help improve the performance of the reports by allowing the read replica to quickly locate the data it needs without having to scan the entire table. This can help speed up the queries","poster":"muky31dec","upvote_count":"1","comment_id":"788405","timestamp":"1674710400.0"},{"poster":"muky31dec","content":"Ans is AC","comment_id":"787996","upvote_count":"1","timestamp":"1674670740.0"},{"upvote_count":"4","poster":"csrazdan","content":"Selected Answer: BC\nThe question has 2 issues - replication lag and reports running slow.\nB - will address reports running snow since fewer uses will be on the replica server\nC - will address replication lag.","comment_id":"772014","comments":[{"upvote_count":"1","poster":"muky31dec","timestamp":"1674586980.0","content":"AC must correct choice in the situation.","comment_id":"786828"}],"timestamp":"1673411520.0"},{"upvote_count":"1","timestamp":"1672702140.0","poster":"TFMV","content":"Moving workload to BQ is not an option. That, at a minimum, would require connection changes in the reports and the question specifically states that report changes are unacceptable. Aside from that, we do not know if the reports are being generated by a tool and whether that tool supports BQ.","comment_id":"764120"},{"content":"AC - Not understanding votes for E, can't be done without some changes to reports.","timestamp":"1672361460.0","upvote_count":"2","comment_id":"761584","poster":"sp57"},{"timestamp":"1672258620.0","content":"AC\nhttps://cloud.google.com/sql/docs/mysql/replication/read-replica-indexes","comment_id":"760293","upvote_count":"2","poster":"SVGoogle89"},{"timestamp":"1672079580.0","comment_id":"757751","upvote_count":"1","content":"Selected Answer: BC\nBC, you can't disable replication on the primary instance, only on the replica","poster":"chelbsik","comments":[{"upvote_count":"1","poster":"chelbsik","comment_id":"757753","timestamp":"1672079640.0","content":"Wrong vote, should be CE"}]},{"upvote_count":"1","comment_id":"755765","poster":"pk349","timestamp":"1671981420.0","content":"E: Move your analytics workloads to ***** BigQuery, and set up a streaming pipeline to move data and update BigQuery."},{"poster":"pk349","content":"D: Disable replication on the primary ***** instance, and set the flag for parallel replication on the primary instance. Re-enable replication and optimize performance by setting flags on the read replica.","upvote_count":"1","comment_id":"755764","timestamp":"1671981360.0"},{"timestamp":"1671864840.0","comment_id":"754731","content":"Selected Answer: DE\nD & E is the correct answer","upvote_count":"1","poster":"GCP72"},{"upvote_count":"1","poster":"lapeyus","timestamp":"1671822840.0","content":"CE\nhttps://cloud.google.com/sql/docs/mysql/replication/manage-replicas#basic-steps-to-change-parallel-replication-flags","comment_id":"754446"},{"timestamp":"1671628080.0","upvote_count":"1","poster":"range9005","comment_id":"752327","content":"Selected Answer: DE\nparallel replication should be on primary instance\nBQ is better for analytics"},{"poster":"fredcaram","timestamp":"1671565020.0","content":"Selected Answer: CE\nThe B wouldn't solve the lag issue and D would optimize on the read replicas instead of the primary","upvote_count":"2","comment_id":"751405"},{"content":"Selected Answer: DE\nB wouldn't solve the lag issue.","timestamp":"1671563280.0","poster":"fredcaram","upvote_count":"1","comment_id":"751370"}],"topic":"1","timestamp":"2022-12-20 20:08:00","exam_id":5,"unix_timestamp":1671563280,"isMC":true,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/92213-exam-professional-cloud-database-engineer-topic-1-question/","answer_ET":"BC","answer_images":[],"question_id":43,"answers_community":["BC (50%)","AC (17%)","13%","Other"],"question_images":[],"question_text":"Your application uses Cloud SQL for MySQL. Your users run reports on data that relies on near-real time; however, the additional analytics caused excessive load on the primary database. You created a read replica for the analytics workloads, but now your users are complaining about the lag in data changes and that their reports are still slow. You need to improve the report performance and shorten the lag in data replication without making changes to the current reports. Which two approaches should you implement? (Choose two.)","choices":{"B":"Create additional read replicas, and partition your analytics users to use different read replicas.","D":"Disable replication on the primary instance, and set the flag for parallel replication on the primary instance. Re-enable replication and optimize performance by setting flags on the read replica.","E":"Move your analytics workloads to BigQuery, and set up a streaming pipeline to move data and update BigQuery.","A":"Create secondary indexes on the replica.","C":"Disable replication on the read replica, and set the flag for parallel replication on the read replica. Re-enable replication and optimize performance by setting flags on the primary instance."},"answer":"BC"},{"id":"w18MC26G8ffy7gfq5soT","topic":"1","url":"https://www.examtopics.com/discussions/google/view/92340-exam-professional-cloud-database-engineer-topic-1-question/","discussion":[{"poster":"juliorevk","upvote_count":"4","timestamp":"1727835360.0","content":"D because \nCMEK where the encryption keys are stored \nIAM govern the access to data\nVPC Service Controls configure where data is stored control","comment_id":"1022737"},{"comment_id":"1017148","timestamp":"1727291040.0","content":"Selected Answer: D\nD. \nC might seem ok, but you'd need some kind of tracking to localize users, and there is no mention of it.","upvote_count":"1","poster":"theseawillclaim"},{"content":"should be CSEK and not CMEK. Then 'D'.","poster":"standm","comment_id":"906837","timestamp":"1716663720.0","upvote_count":"1"},{"comment_id":"836431","timestamp":"1710184200.0","poster":"dynamic_dba","content":"D.\nUsing IAM policies, VPC Service Controls and CMEK is the best answer. A doesn’t make sense since Geography would be a factor at the Region level, not zone level. B is a lot of work and GCP is all about making things easier. C address part of the issue, but D addresses more. The link provided by sp57 is spot on.","upvote_count":"1"},{"comment_id":"766555","timestamp":"1704453360.0","upvote_count":"1","poster":"ralf_cc","content":"C - it is about location of the data"},{"content":"My vote D","timestamp":"1704402300.0","poster":"ssaporylo","comment_id":"766093","upvote_count":"1"},{"timestamp":"1703898360.0","poster":"sp57","upvote_count":"4","comment_id":"761586","content":"D, https://cloud.google.com/blog/products/identity-security/meet-data-residency-requirements-with-google-cloud"},{"content":"D. Use features like customer-managed encryption keys (CMEK), VPC Service Controls, and Identity and Access Management (IAM) policies.","poster":"pk349","upvote_count":"2","timestamp":"1703517960.0","comment_id":"755780"},{"poster":"GCP72","comment_id":"754734","content":"Selected Answer: D\nD is the correct answer","upvote_count":"1","timestamp":"1703401200.0"},{"poster":"range9005","upvote_count":"2","timestamp":"1703164380.0","content":"Selected Answer: D\ndata residency requirements can be achiy with CMEK, VPC and IAM","comment_id":"752330"}],"answers_community":["D (100%)"],"exam_id":5,"isMC":true,"choices":{"B":"Create a Cloud SQL for PostgreSQL instance on Google Cloud for the data that does not need to adhere to data residency requirements. Keep the data that must adhere to data residency requirements on-premises. Make application changes to support both databases.","D":"Use features like customer-managed encryption keys (CMEK), VPC Service Controls, and Identity and Access Management (IAM) policies.","C":"Allow application access to data only if the users are in the same region as the Google Cloud region for the Cloud SQL for PostgreSQL database.","A":"Replicate Cloud SQL databases across different zones."},"answer_description":"","answer_images":[],"question_images":[],"answer":"D","answer_ET":"D","unix_timestamp":1671628380,"question_id":44,"question_text":"You are evaluating Cloud SQL for PostgreSQL as a possible destination for your on-premises PostgreSQL instances. Geography is becoming increasingly relevant to customer privacy worldwide. Your solution must support data residency requirements and include a strategy to: configure where data is stored control where the encryption keys are stored govern the access to data\nWhat should you do?","timestamp":"2022-12-21 14:13:00"},{"id":"OWk0w0sAlwyNJPpeY0gH","answer_images":[],"answer_ET":"DE","answer_description":"","discussion":[{"timestamp":"1691175900.0","poster":"dynamic_dba","comment_id":"798362","content":"D,E.\nA is wrong because why bother configuring manual backups when Cloud SQL will automate that for you.\nB seems attractive, but why bother replicating back to on-prem when you can configure a Cloud SQL for HA.\nC is wrong because a single zone failure would not give you HA.\nThat leaves D & E.","upvote_count":"7"},{"content":"Selected Answer: DE\nTo ensure high availability (HA) for your Cloud SQL instance and adhere to Google-recommended practices, you need to prioritize reliable backups and recovery mechanisms.\n\nD. Enable point-in-time recovery:\nThis allows you to recover your database to a specific point in time in case of accidental data deletion or corruption. It ensures minimal data loss and quick recovery.\n\nE. Schedule automated backups:\nAutomated backups ensure regular snapshots of your database are taken without manual intervention, providing a reliable recovery point in case of failures.","timestamp":"1735121580.0","upvote_count":"1","poster":"Zakky_09","comment_id":"1331497"},{"content":"Selected Answer: DE\nAgree with D, E","comment_id":"1211312","upvote_count":"2","poster":"dija123","timestamp":"1731582840.0"},{"timestamp":"1731124620.0","poster":"hanayome","comment_id":"1208643","content":"Selected Answer: DE\nD and E because point in time recovery and schedule backup are HA efforts and CloudSQL already have these features","upvote_count":"2"},{"content":"Vote for D, E.","timestamp":"1710746580.0","upvote_count":"2","comment_id":"1010277","poster":"goodsport"},{"timestamp":"1693681500.0","poster":"Nirca","comment_id":"827435","content":"Selected Answer: DE\nOnly valid options.","upvote_count":"3"},{"comment_id":"757664","upvote_count":"4","poster":"chelbsik","content":"Selected Answer: DE\nVote for DE, seems only reasonable options to me","timestamp":"1687791420.0"},{"timestamp":"1687762380.0","poster":"omermahgoub","comment_id":"757282","content":"To prepare your Cloud SQL instance for high availability, you should do the following:\n\nD. Enable point-in-time recovery - This feature allows you to restore your database to a specific point in time. It helps protect against data loss and can be used in the event of data corruption or accidental data deletion.\n\nE. Schedule automated backups - Automated backups allow you to take regular backups of your database without manual intervention. You can use these backups to restore your database in the event of data loss or corruption.\n\nNote that options A and C are not recommended practices for high availability. Option B is not related to Cloud SQL.","upvote_count":"3"},{"content":"Selected Answer: DE\nD,E is the correct answer","upvote_count":"3","timestamp":"1687488960.0","poster":"GCP72","comment_id":"753857"},{"poster":"range9005","content":"Selected Answer: DE\nEnable point-in-time recovery.\nSchedule automated backups.","upvote_count":"3","timestamp":"1687470420.0","comment_id":"753755"},{"comment_id":"753288","content":"Selected Answer: DE\nD. Enable point-in-time recovery.\nE. Schedule automated backups","upvote_count":"1","timestamp":"1687430640.0","poster":"H_S"},{"upvote_count":"2","comment_id":"752419","content":"D. Enable point-in-time recovery.\nE. Schedule automated backups.\n\nTo prepare your Cloud SQL instance for high availability, Google recommends enabling point-in-time recovery and scheduling automated backups.\n\nPoint-in-time recovery allows you to restore your database to a specific point in time, helping you to recover from data loss or corruption.\n\nScheduling automated backups ensures that you have a recent copy of your database available for recovery in case of an outage or other issue.","timestamp":"1687350360.0","poster":"omermahgoub","comments":[{"timestamp":"1687350360.0","comment_id":"752420","upvote_count":"1","content":"Option A, setting up manual backups, would not be a recommended practice because manual backups are prone to errors and can be time-consuming to create and maintain. Automated backups are a more reliable and efficient way to ensure that you have a recent copy of your database available for recovery.\n\nOption B, creating a PostgreSQL database on-premises as the HA option, would not be a recommended practice because it would not take advantage of the high availability features provided by Cloud SQL.\n\nOption C, configuring single zone availability for automated backups, would not be a recommended practice because it would not provide sufficient protection against outages or other issues. To ensure high availability, it is recommended to use a multi-zone configuration for your Cloud SQL instance.","poster":"omermahgoub"}]},{"timestamp":"1687151160.0","comment_id":"749572","upvote_count":"2","poster":"Popa","content":"Selected Answer: DE\nhttps://cloud.google.com/sql/docs/mysql/high-availability#backups-and-restores"},{"poster":"range9005","content":"Selected Answer: DE\nAutomated backups and point-in-time recovery must be enabled for high availability (point-in-time recovery uses binary logs).\nFor more information check here -> https://cloud.google.com/sql/docs/mysql/high-availability#backups-and-restores","comment_id":"749396","timestamp":"1687135800.0","upvote_count":"2"}],"isMC":true,"topic":"1","url":"https://www.examtopics.com/discussions/google/view/92032-exam-professional-cloud-database-engineer-topic-1-question-2/","choices":{"A":"Set up manual backups.","D":"Enable point-in-time recovery.","E":"Schedule automated backups.","C":"Configure single zone availability for automated backups.","B":"Create a PostgreSQL database on-premises as the HA option."},"question_images":[],"answer":"DE","question_id":45,"question_text":"Your digital-native business runs its database workloads on Cloud SQL. Your website must be globally accessible 24/7. You need to prepare your Cloud SQL instance for high availability (HA). You want to follow Google-recommended practices. What should you do? (Choose two.)","timestamp":"2022-12-19 03:50:00","unix_timestamp":1671418200,"answers_community":["DE (100%)"],"exam_id":5}],"exam":{"provider":"Google","id":5,"name":"Professional Cloud Database Engineer","isMCOnly":true,"numberOfQuestions":132,"isImplemented":true,"isBeta":false,"lastUpdated":"11 Apr 2025"},"currentPage":9},"__N_SSP":true}