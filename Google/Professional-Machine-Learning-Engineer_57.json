{"pageProps":{"questions":[{"id":"P740FajCksd7WnqOhvoq","answer_ET":"B","answer":"B","question_images":[],"discussion":[{"poster":"PhilipKoku","comment_id":"1226007","timestamp":"1717752300.0","content":"Selected Answer: B\nB) Hash buckets","upvote_count":"2"},{"comment_id":"1164243","poster":"etienne0","content":"Selected Answer: A\nwent with A","timestamp":"1709400540.0","upvote_count":"1"},{"timestamp":"1683609420.0","upvote_count":"2","comment_id":"892766","content":"Selected Answer: B\nWent with B","poster":"M25"},{"timestamp":"1683541200.0","upvote_count":"4","content":"Selected Answer: B\nhttps://cloud.google.com/ai-platform/training/docs/algorithms/wide-and-deep\nIf the column is categorical with high cardinality, then the column is treated with hashing, where the number of hash buckets equals to the square root of the number of unique values in the column.","poster":"CloudKida","comment_id":"892006"},{"upvote_count":"1","comment_id":"853077","timestamp":"1679997360.0","poster":"JamesDoe","content":"Selected Answer: B\nB.\nThe other options solves nada."},{"upvote_count":"1","timestamp":"1675912320.0","content":"Selected Answer: B\nhttps://towardsdatascience.com/getting-deeper-into-categorical-encodings-for-machine-learning-2312acd347c8\nWhen you have millions uniques values try to do: Hash Encoding","poster":"enghabeth","comment_id":"802775"},{"content":"Selected Answer: B\nB unconditoinally\nhttps://cloud.google.com/ai-platform/training/docs/algorithms/xgboost#analysis\n\nIf the column is categorical with high cardinality, then the column is treated with hashing, where the number of hash buckets equals to the square root of the number of unique values in the column.\nA categorical column is considered to have high cardinality if the number of unique values is greater than the square root of the number of rows in the dataset.","poster":"John_Pongthorn","comment_id":"788804","timestamp":"1674743280.0","upvote_count":"2"},{"comment_id":"752888","poster":"MithunDesai","timestamp":"1671667740.0","content":"Selected Answer: C\nI think C as it has 10000 categorical values","upvote_count":"2"},{"comment_id":"748791","poster":"hiromi","content":"Selected Answer: B\nI think B is correct\nRef.:\"\n- https://cloud.google.com/ai-platform/training/docs/algorithms/xgboost\n- https://stackoverflow.com/questions/26473233/in-preprocessing-data-with-high-cardinality-do-you-hash-first-or-one-hot-encode","upvote_count":"4","timestamp":"1671363780.0","comments":[{"poster":"hiromi","timestamp":"1671826860.0","upvote_count":"1","content":"- https://cloud.google.com/ai-platform/training/docs/algorithms/xgboost#analysis","comment_id":"754509"}]},{"poster":"mil_spyro","upvote_count":"1","comments":[{"timestamp":"1671297780.0","content":"https://www.analyticsvidhya.com/blog/2020/08/types-of-categorical-data-encoding/","poster":"mil_spyro","comment_id":"748240","upvote_count":"1"}],"timestamp":"1671297480.0","content":"Selected Answer: B\nAnswer is B. When cardinality of the categorical column is very large best choice is binary encoding however it not here hence one-hot hash option.","comment_id":"748239"},{"content":"Selected Answer: B\nAns : B","timestamp":"1670942640.0","upvote_count":"1","poster":"JeanEl","comment_id":"744147"},{"poster":"seifou","timestamp":"1670798700.0","content":"Selected Answer: B\nB is correct","comment_id":"742174","upvote_count":"1"},{"upvote_count":"1","content":"It should be B","poster":"ares81","timestamp":"1670781240.0","comment_id":"741950"},{"content":"Selected Answer: A\nAnswer A since with 10.000 unique values one-hot shouldn't be a good solution\nhttps://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/","poster":"LearnSodas","upvote_count":"3","comment_id":"741870","timestamp":"1670774400.0","comments":[{"poster":"503b759","comment_id":"1310517","upvote_count":"1","timestamp":"1731405960.0","content":"then you introduce ordinality into a categorical concept, which can mislead models"},{"comment_id":"1164241","upvote_count":"1","timestamp":"1709400480.0","content":"I agree with A","poster":"etienne0"}]}],"url":"https://www.examtopics.com/discussions/google/view/91033-exam-professional-machine-learning-engineer-topic-1-question/","question_text":"You are creating a deep neural network classification model using a dataset with categorical input values. Certain columns have a cardinality greater than 10,000 unique values. How should you encode these categorical values as input into the model?","choices":{"D":"Convert each categorical value into a run-length encoded string.","C":"Map the categorical variables into a vector of boolean values.","B":"Convert the categorical string data to one-hot hash buckets.","A":"Convert each categorical value into an integer value."},"timestamp":"2022-12-11 17:00:00","exam_id":13,"answer_description":"","answer_images":[],"isMC":true,"unix_timestamp":1670774400,"topic":"1","question_id":281,"answers_community":["B (76%)","A (16%)","8%"]},{"id":"IYWM90iSA5Z1vwfCntUP","topic":"1","answer_ET":"B","exam_id":13,"answer_description":"","answer":"B","answer_images":[],"isMC":true,"unix_timestamp":1670774580,"choices":{"D":"Assign a numerical value to each word from 1 to 100,000 and feed the values as inputs in your model.","A":"Create a hot-encoding of words, and feed the encodings into your model.","B":"Identify word embeddings from a pre-trained model, and use the embeddings in your model.","C":"Sort the words by frequency of occurrence, and use the frequencies as the encodings in your model."},"question_text":"You need to train a natural language model to perform text classification on product descriptions that contain millions of examples and 100,000 unique words. You want to preprocess the words individually so that they can be fed into a recurrent neural network. What should you do?","question_id":282,"timestamp":"2022-12-11 17:03:00","question_images":[],"discussion":[{"content":"Selected Answer: B\nWent with B","comment_id":"892767","timestamp":"1683609420.0","upvote_count":"2","poster":"M25"},{"upvote_count":"2","content":"Selected Answer: B\nB\nhttps://developers.google.com/machine-learning/guides/text-classification/step-3\nhttps://developers.google.com/machine-learning/guides/text-classification/step-4\n\ni","comment_id":"788843","poster":"John_Pongthorn","timestamp":"1674746040.0"},{"upvote_count":"1","comment_id":"765676","poster":"ares81","content":"Selected Answer: B\nAnswer is B","timestamp":"1672838400.0"},{"comment_id":"754722","upvote_count":"4","content":"Answer is B: According to Google Docs here: - https://developers.google.com/machine-learning/guides/text-classification/ it is a Word Embedding case","poster":"egdiaa","timestamp":"1671863280.0"},{"upvote_count":"2","content":"Selected Answer: B\nB (I'm not sure)\n- https://developers.google.com/machine-learning/guides/text-classification/step-3#label_vectorization\n- https://developers.google.com/machine-learning/guides/text-classification/step-4\n- https://towardsai.net/p/deep-learning/text-classification-with-rnn\n - https://towardsdatascience.com/pre-trained-word-embedding-for-text-classification-end2end-approach-5fbf5cd8aead","timestamp":"1671366600.0","comment_id":"748830","poster":"hiromi","comments":[{"content":"- https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space","poster":"hiromi","comment_id":"754519","upvote_count":"1","timestamp":"1671827160.0"}]},{"comments":[{"timestamp":"1731406080.0","poster":"503b759","content":"probably BOW suffers from the high cardinality of the text (100k words). embeddings are typically lower dimensional (hundreds not thousands of columns)","upvote_count":"1","comment_id":"1310520"}],"timestamp":"1670774580.0","content":"Selected Answer: C\nBag of words is a good practice to represent and feed text at a DNN \nhttps://machinelearningmastery.com/gentle-introduction-bag-words-model/","upvote_count":"1","comment_id":"741872","poster":"LearnSodas"}],"answers_community":["B (88%)","13%"],"url":"https://www.examtopics.com/discussions/google/view/91035-exam-professional-machine-learning-engineer-topic-1-question/"},{"id":"F3jkIm0dQzIyZzpVtuYC","timestamp":"2021-06-05 18:30:00","answer_ET":"A","question_images":[],"answer_images":[],"exam_id":13,"answer_description":"","discussion":[{"poster":"Paul_Dirac","comments":[{"poster":"q4exam","comments":[{"upvote_count":"3","poster":"lordcenzin","comment_id":"549489","timestamp":"1645111980.0","content":"yes you can but it is not supposed to do that. DF is for data processing and transformation. you would loose all shenanigans kubeflow provide as native.\nAmong the two answers, i think A is the most correct"},{"poster":"mousseUwU","content":"Please send a source link?","comment_id":"464107","upvote_count":"1","timestamp":"1634558880.0"}],"content":"Dataflow can deploy model .... this is how you do stream inference on stream","upvote_count":"2","timestamp":"1631174280.0","comment_id":"441833"}],"timestamp":"1624345920.0","comment_id":"387673","upvote_count":"42","content":"Answer: A\nA. Kubeflow Pipelines can form an end-to-end architecture (https://www.kubeflow.org/docs/components/pipelines/overview/pipelines-overview/) and deploy models.\nB. BigQuery ML can't offer an end-to-end architecture because it must use another tool, like AI Platform, for serving models at the end of the process (https://cloud.google.com/bigquery-ml/docs/export-model-tutorial#online_deployment_and_serving).\nC. Cloud Scheduler can trigger the first step in a pipeline, but then some orchestrator is needed to continue the remaining steps. Besides, having Cloud Scheduler alone can't ensure failure handling during pipeline execution.\nD. A Dataflow job can't deploy models, it must use AI Platform at the end instead."},{"timestamp":"1622910600.0","poster":"gcp2021go","upvote_count":"11","content":"the answer is D. found similar explaination in this course. open for discussion. I found B could also work, but the question asked for end-to end, thus I choose D in stead of B https://www.coursera.org/lecture/ml-pipelines-google-cloud/what-is-cloud-composer-CuXTQ","comments":[{"timestamp":"1678093980.0","content":"D is incorrect. Cloud Composer is a fully managed workflow orchestration service built on Apache Airflow. It is a recommended way by Google to schedule continuous training jobs. But it isn’t used to run the training jobs. AI Platform is used for training and deployment.","poster":"tavva_prudhvi","upvote_count":"2","comment_id":"830681"}],"comment_id":"375319"},{"content":"Selected Answer: A\nReq: retrain the model every month+ Google-recommended best practice+ end-to-end architecture\nA. Configure Kubeflow Pipelines to schedule your multi-step workflow from training to deploying your model. : Supports all above\nB. Use a model trained and deployed on BigQuery ML, and trigger retraining with the scheduled query feature in BigQuery : Why BigQuery ML when vertexAI/kubflow can handle end to end. BigQuery ML+ traigger only initiate the code run.\nC. Write a Cloud Functions script that launches a training and deploying job on AI Platform that is triggered by Cloud Scheduler. : Not recommended by google for end to end ML\nD. Use Cloud Composer to programmatically schedule a Dataflow job that executes the workflow from training to deploying your model. : Not recommended by google for end to end ML. what if model fails? matrix monitor?","timestamp":"1727240520.0","comment_id":"946839","poster":"harithacML","upvote_count":"1"},{"comment_id":"1225137","poster":"PhilipKoku","timestamp":"1717648200.0","upvote_count":"1","content":"Selected Answer: A\nA) Kubeflow Pipelines is the answer."},{"timestamp":"1701430920.0","content":"Selected Answer: A\nChose A","comment_id":"1085178","upvote_count":"1","poster":"fragkris"},{"upvote_count":"1","content":"Selected Answer: A\nD - Dataflow job can't deploy models\nB,C are not - are not complete solutions\nleaving A to be the correct one","poster":"Sum_Sum","comment_id":"1070405","timestamp":"1699969140.0"},{"content":"Answer is A","timestamp":"1695373980.0","comment_id":"1013901","poster":"suranga4","upvote_count":"1"},{"timestamp":"1683608100.0","upvote_count":"1","content":"Selected Answer: A\nWent with A","comment_id":"892681","poster":"M25"},{"poster":"John_Pongthorn","upvote_count":"2","content":"Selected Answer: A\nA : Yet the newer is Vertext-AI Pipeline built on Kubeflow","comment_id":"820264","timestamp":"1677227760.0"},{"poster":"Fatiy","timestamp":"1675845540.0","upvote_count":"1","comment_id":"801793","content":"Selected Answer: A\nA : In this case, it would be a good fit as you need to retrain your model every month, which can be automated with Kubeflow Pipelines. This makes it easier to manage the entire process, from training to deploying, in a streamlined and scalable manner."},{"content":"Selected Answer: A\nA is correct\nAll the options get you to the required result, but only A follows the Google-recommended best practices","upvote_count":"1","comment_id":"725185","timestamp":"1669212900.0","poster":"EFIGO"},{"timestamp":"1667325540.0","comment_id":"709346","poster":"abhi0706","content":"Answer is A: Kubeflow Pipelines can form an end-to-end architecture","upvote_count":"1"},{"timestamp":"1660566300.0","comment_id":"647174","poster":"GCP72","upvote_count":"1","content":"Selected Answer: A\nCorrect answer is \"A\""},{"poster":"caohieu04","content":"Selected Answer: A\nCommunity vote","upvote_count":"2","timestamp":"1646015340.0","comment_id":"557783"},{"poster":"gcper","timestamp":"1631338500.0","upvote_count":"2","comment_id":"442830","content":"A\n\nKubeflow can handle all of those things, including deploying to a model endpoint for real-time serving."},{"comment_id":"408884","comments":[{"timestamp":"1633833360.0","poster":"ms_lemon","content":"But D doesn't follow Google best practices","comments":[{"poster":"george_ognyanov","upvote_count":"3","comment_id":"466893","timestamp":"1635067380.0","content":"Answer seems to be A really. Here is a link from Google-recommended best practices. They are talking about Vertex AI Pipelines, which are essentially Kubeflow. \n\nhttps://cloud.google.com/architecture/ml-on-gcp-best-practices?hl=en#machine-learning-workflow-orchestration"}],"upvote_count":"2","comment_id":"459846"}],"timestamp":"1626607020.0","upvote_count":"6","poster":"celia20200410","content":"ANS: A\nhttps://medium.com/google-cloud/how-to-build-an-end-to-end-propensity-to-purchase-solution-using-bigquery-ml-and-kubeflow-pipelines-cd4161f734d9#75c7\n\nTo automate this model-building process, you will orchestrate the pipeline using Kubeflow Pipelines, ‘a platform for building and deploying portable, scalable machine learning (ML) workflows based on Docker containers.’"}],"url":"https://www.examtopics.com/discussions/google/view/54655-exam-professional-machine-learning-engineer-topic-1-question/","isMC":true,"answers_community":["A (100%)"],"answer":"A","unix_timestamp":1622910600,"topic":"1","choices":{"C":"Write a Cloud Functions script that launches a training and deploying job on AI Platform that is triggered by Cloud Scheduler.","A":"Configure Kubeflow Pipelines to schedule your multi-step workflow from training to deploying your model.","D":"Use Cloud Composer to programmatically schedule a Dataflow job that executes the workflow from training to deploying your model.","B":"Use a model trained and deployed on BigQuery ML, and trigger retraining with the scheduled query feature in BigQuery."},"question_id":283,"question_text":"You work for a public transportation company and need to build a model to estimate delay times for multiple transportation routes. Predictions are served directly to users in an app in real time. Because different seasons and population increases impact the data relevance, you will retrain the model every month. You want to follow Google-recommended best practices. How should you configure the end-to-end architecture of the predictive model?"},{"id":"fRjp18YjmrkklsbahjLi","exam_id":13,"url":"https://www.examtopics.com/discussions/google/view/91558-exam-professional-machine-learning-engineer-topic-1-question/","answer_images":[],"answer_description":"","topic":"1","question_id":284,"question_images":[],"isMC":true,"answer":"B","choices":{"B":"Embed the client on the website, deploy the gateway on App Engine, deploy the database on Firestore for writing and for reading the user’s navigation context, and then deploy the model on AI Platform Prediction.","A":"Embed the client on the website, and then deploy the model on AI Platform Prediction.","C":"Embed the client on the website, deploy the gateway on App Engine, deploy the database on Cloud Bigtable for writing and for reading the user’s navigation context, and then deploy the model on AI Platform Prediction.","D":"Embed the client on the website, deploy the gateway on App Engine, deploy the database on Memorystore for writing and for reading the user’s navigation context, and then deploy the model on Google Kubernetes Engine."},"answers_community":["B (55%)","C (45%)"],"unix_timestamp":1671009840,"answer_ET":"B","discussion":[{"poster":"hiromi","comment_id":"748837","comments":[{"comment_id":"971388","upvote_count":"1","timestamp":"1691088120.0","poster":"tavva_prudhvi","content":"Yes, but in that question Option B doesnt have a database.Firestore can handle thousands of web banners, right?"}],"upvote_count":"9","content":"Selected Answer: C\nC (same question 49)\nkeywords\nthe inventory is thousands of web banners -> Bigtable\nYou want to Implement the simplest solution -> AI Platform Prediction","timestamp":"1671366900.0"},{"upvote_count":"6","poster":"e707","content":"Selected Answer: B\nHere are some of the reasons why C is not as simple as B:\n\nCloud Bigtable is a more complex database to set up and manage than Firestore.\nCloud Bigtable is not as secure as Firestore.\nCloud Bigtable is not as well-integrated with other Google Cloud services as Firestore.\nTherefore, B is the simpler solution that meets all of the requirements.","timestamp":"1682582580.0","comment_id":"882369"},{"poster":"192malba192","content":"go for B","timestamp":"1722768840.0","comment_id":"1260625","upvote_count":"1"},{"timestamp":"1712685540.0","content":"Selected Answer: B\nsee e707","upvote_count":"1","comment_id":"1192448","poster":"pinimichele01"},{"timestamp":"1712304060.0","comment_id":"1189750","poster":"ludovikush","upvote_count":"1","content":"Selected Answer: C\nas Hiromi said"},{"upvote_count":"1","comment_id":"1160367","content":"Selected Answer: B\nI would opt for B as we have requirement of retrieval latency","poster":"ludovikush","timestamp":"1709025960.0"},{"upvote_count":"1","timestamp":"1700045160.0","comment_id":"1071331","content":"Selected Answer: B\nEmbed the client on the website, deploy the gateway on App Engine, and then deploy the model on AI Platform Prediction.","poster":"Mickey321"},{"timestamp":"1699729620.0","upvote_count":"1","content":"Selected Answer: B\nI would go with Firestore as throughput or latency requirement provided in the question are possible with Firestore and bigTable may be an overkill. Had the scenario involved super large volumes of data, CBT would have taken precedence","comment_id":"1068037","poster":"Krish6488"},{"content":"Selected Answer: B\nI think B, based on \"the simplest solution\" consideration.","timestamp":"1694334000.0","comment_id":"1003813","upvote_count":"1","poster":"andresvelasco"},{"comment_id":"971386","timestamp":"1691087880.0","content":"Selected Answer: B\nthe primary requirement mentioned in the original question is to implement the simplest solution. Firestore is a fully managed, serverless NoSQL database that can also handle thousands of web banners and dynamically changing user browsing history. It is designed for real-time data synchronization and can quickly update the most relevant web banner as the user browses different pages of the website.\n\nWhile Cloud Bigtable offers high performance and scalability, it is more complex to manage and is better suited for large-scale, high-throughput workloads. Firestore, on the other hand, is easier to implement and maintain, making it a more suitable choice for the simplest solution in this scenario.","poster":"tavva_prudhvi","upvote_count":"2"},{"comments":[{"timestamp":"1694334240.0","upvote_count":"1","content":"BTW, the storage solution does not mention web banners, just browsing history.\nbut what about the \"simplest solution\" consideration? that wold point into the Datastore direction.\nIt is true however that the guide you mention recommends firestore for \" slowly changing data \", which I wonder why? I expect Firectore to be able to perfectly handle many updates per second, few updates per user per second.","comment_id":"1003817","poster":"andresvelasco"}],"comment_id":"960448","timestamp":"1690116900.0","content":"Selected Answer: C\nThe answer is C for the following reason:\n\nIf you need:\n- Submillisecond retrieval latency on a limited amount of quickly changing data, retrieved by a few thousand clients, use Memorystore.\n- Millisecond retrieval latency on slowly changing data where storage scales automatically, use Datastore.\n- Millisecond retrieval latency on dynamically changing data, using a store that can scale linearly with heavy reads and writes, use Bigtable.\nSource: https://cloud.google.com/architecture/minimizing-predictive-serving-latency-in-machine-learning#choosing_a_nosql_database\n\nC is better than B because 1) the inventory is thousands of web banners and 2) we expect the user to compare many travel destinations, dates, hotels, and tariffs during their search process. It means the user's browsing history is dynamically changing, and we need to identify \"the most relevant web banner that a user should see next\" => we will be dynamically changing the ad as the user browses different pages of the website.","upvote_count":"2","poster":"[Removed]"},{"upvote_count":"1","timestamp":"1683609480.0","poster":"M25","comment_id":"892768","content":"Selected Answer: C\nWent with C"},{"comment_id":"881305","content":"Selected Answer: B\nB for me","upvote_count":"1","timestamp":"1682497020.0","poster":"lucaluca1982"},{"timestamp":"1672838160.0","upvote_count":"2","poster":"ares81","content":"Selected Answer: B\nB, for me.","comment_id":"765667"},{"timestamp":"1671368160.0","comments":[{"timestamp":"1691088240.0","comment_id":"971390","upvote_count":"1","poster":"tavva_prudhvi","content":"correct that Cloud Bigtable can provide better latency compared to Firestore, especially when dealing with very large datasets and high-throughput workloads. However, it's important to consider the trade-offs and the specific use case.\n\nFor the given scenario, the latency requirements are 300ms@p99, which Firestore can handle effectively for thousands of web banners and dynamically changing user browsing history. Firestore is designed for real-time data synchronization and can quickly update the most relevant web banner as the user browses different pages on the website.\n\nWhile Cloud Bigtable can offer improved latency, it comes with added complexity in terms of management and configuration. If the primary goal is to implement the simplest solution while meeting the latency requirements, Firestore remains a more suitable choice for this use case."}],"poster":"kn29","content":"I think C because of latency requirements. \nCloud BigTable has high latency feature from https://cloud.google.com/bigtable","comment_id":"748854","upvote_count":"3"},{"comment_id":"744926","upvote_count":"1","timestamp":"1671009840.0","poster":"ares81","content":"I need a DB to store the banners, so no A. We're talking of thousands of banners, so no C. Memorystore calls Redis, and other solutions, so no D. The answer is B, for me."}],"timestamp":"2022-12-14 10:24:00","question_text":"You work for an online travel agency that also sells advertising placements on its website to other companies. You have been asked to predict the most relevant web banner that a user should see next. Security is important to your company. The model latency requirements are 300ms@p99, the inventory is thousands of web banners, and your exploratory analysis has shown that navigation context is a good predictor. You want to Implement the simplest solution. How should you configure the prediction pipeline?"},{"id":"vud52ocRdZHZ0EPRdYH5","timestamp":"2022-12-11 17:20:00","answer_ET":"B","question_images":[],"answer_images":[],"exam_id":13,"answer_description":"","discussion":[{"comment_id":"789379","content":"Selected Answer: B\nThe Cloud Compose may be good consideration if you are involved in getting Google Data Engineer Cert\nApp enging is relevant to Dev-Op Cert\n\nPls.\nif you know a bit about ML Google Cloud, we are preparing to take Google ML Cert, if there is no specifically particular requirement in the question.\nWe must emphasize on use of Vertext AI as much as possible.","upvote_count":"8","poster":"John_Pongthorn","timestamp":"1690433220.0"},{"comment_id":"1226032","timestamp":"1733572500.0","poster":"PhilipKoku","content":"Selected Answer: B\nB) Vertex AI Pipelines","upvote_count":"1"},{"upvote_count":"2","comment_id":"908427","poster":"rosenr0","timestamp":"1701165840.0","content":"B. Vertext AI also supports Docker container\nhttps://cloud.google.com/vertex-ai/docs/training/containers-overview"},{"upvote_count":"2","poster":"CloudKida","content":"Selected Answer: D\nA custom container is a Docker image that you create to run your training application. By running your machine learning (ML) training job in a custom container, you can use ML frameworks, non-ML dependencies, libraries, and binaries that are not otherwise supported on Vertex AI. so we need vertex ai custom container for docker container. Thus option A and B are omitted .\nApp Engine allows developers to focus on what they do best: writing code. Based on Compute Engine, the App Engine flexible environment automatically scales your app up and down while also balancing the load.\nCustomizable infrastructure - App Engine flexible environment instances are Compute Engine virtual machines, which means that you can take advantage of custom libraries, use SSH for debugging, and deploy your own Docker containers.","comment_id":"892976","timestamp":"1699532340.0"},{"timestamp":"1699514340.0","poster":"M25","comment_id":"892769","upvote_count":"2","content":"Selected Answer: B\nWent with B"},{"comment_id":"882374","comments":[{"timestamp":"1699613040.0","poster":"e707","content":"I can't change the voting but It's B.","comment_id":"893758","upvote_count":"2"}],"content":"Selected Answer: D\nI think it's D. B does not support Docker containers, does it?","upvote_count":"1","poster":"e707","timestamp":"1698394200.0"},{"timestamp":"1698016980.0","comment_id":"877684","upvote_count":"1","content":"Shouldn't it be A?\nhttps://cloud.google.com/appengine/docs/standard/scheduling-jobs-with-cron-yaml","poster":"Sas02"},{"timestamp":"1688672520.0","comment_id":"768097","upvote_count":"1","poster":"behzadsw","content":"Selected Answer: B\nVote for B"},{"poster":"hiromi","upvote_count":"3","timestamp":"1687085220.0","comment_id":"748850","content":"Selected Answer: B\nVote for B"},{"timestamp":"1687004280.0","comment_id":"748108","upvote_count":"1","content":"Selected Answer: D\nD is the only option that provides scheduled model retraining","poster":"mil_spyro"},{"comments":[{"comment_id":"765658","upvote_count":"1","content":"I changed my mind. It's D.","poster":"ares81","timestamp":"1688468820.0"}],"timestamp":"1686729960.0","comment_id":"744957","upvote_count":"1","content":"Selected Answer: C\nServe Vertex AI Prediction, but the monitoring in the question is not the one of the answer B. (that is connected to the modeol). The correct answer is C.","poster":"ares81"},{"poster":"LearnSodas","upvote_count":"3","comment_id":"741882","comments":[{"upvote_count":"1","content":"Scheduling is not possible without the Cloud Scheduler\nhttps://cloud.google.com/vertex-ai/docs/pipelines/schedule-cloud-scheduler","poster":"mil_spyro","comment_id":"750752","timestamp":"1687248960.0","comments":[{"upvote_count":"2","comment_id":"754541","poster":"hiromi","timestamp":"1687546740.0","content":"I think Vertex AI Pipeline includes schedule/trigger runs, so my vote is B"}]}],"content":"Selected Answer: B\nEverything is possible on Vetex AI","timestamp":"1686493200.0"}],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/91038-exam-professional-machine-learning-engineer-topic-1-question/","answers_community":["B (78%)","D (17%)","4%"],"answer":"B","unix_timestamp":1670775600,"topic":"1","choices":{"A":"Vertex AI Pipelines and App Engine","C":"Cloud Composer, BigQuery ML, and Vertex AI Prediction","B":"Vertex AI Pipelines, Vertex AI Prediction, and Vertex AI Model Monitoring","D":"Cloud Composer, Vertex AI Training with custom containers, and App Engine"},"question_text":"Your data science team has requested a system that supports scheduled model retraining, Docker containers, and a service that supports autoscaling and monitoring for online prediction requests. Which platform components should you choose for this system?","question_id":285}],"exam":{"isBeta":false,"isMCOnly":true,"numberOfQuestions":304,"name":"Professional Machine Learning Engineer","isImplemented":true,"id":13,"provider":"Google","lastUpdated":"11 Apr 2025"},"currentPage":57},"__N_SSP":true}