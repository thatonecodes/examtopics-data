{"pageProps":{"questions":[{"id":"H6G5dg7Iax005rH4q942","url":"https://www.examtopics.com/discussions/google/view/92713-exam-professional-cloud-database-engineer-topic-1-question/","topic":"1","answers_community":["D (62%)","B (38%)"],"choices":{"C":"1. Create the database on a Bare Metal Solution server with the database running on flash storage.\n2. Keep a local backup copy on standard storage.\n3. Use the Oracle Recovery Manager (RMAN) backup utility to move backups older than one day to a Coldline Storage bucket.","B":"1 Create the database on a Bare Metal Solution server with the database running on flash storage.\n2. Keep a local backup copy on standard storage.\n3. Keep backups older than one day stored in Actifio OnVault storage.","A":"1 Create the database on a Bare Metal Solution server with the database running on flash storage.\n2. Keep a local backup copy on all flash storage.\n3. Keep backups older than one day stored in Actifio OnVault storage.","D":"1. Create the database on a Bare Metal Solution server with the database running on flash storage.\n2. Keep a local backup copy on all flash storage.\n3. Use the Oracle Recovery Manager (RMAN) backup utility to move backups older than one day to an Archive Storage bucket."},"answer":"D","isMC":true,"discussion":[{"timestamp":"1726744080.0","poster":"james2033","upvote_count":"2","content":"Selected Answer: D\nBare Metal --> RMAN","comment_id":"1177338"},{"upvote_count":"2","timestamp":"1718834880.0","comment_id":"1101076","content":"Selected Answer: B\nOption B is correct\nThere are two activities: Manage incremental backup (transaction log) and manage obsolete backup (older than retention time to another backup storage (archival)). Option B make as actifio as tool to organize this two activities while Option D make RMAN as tools to organize this to activities. actifio have feature like “Incremental-forever” backups\" and store in OnVault storage which is official standard for actifio and actifio in gcp which is very fast compare to option D (RMAN). RMAN will need more than 2 hours to do recovery for 50 TB.","poster":"whoosh"},{"comment_id":"1069947","upvote_count":"4","poster":"Jay_Krish","timestamp":"1715648280.0","content":"Selected Answer: D\nKeeping local storage on flash drive would meet the requirement for RTO. And moving older backups to Archival storage is the cost-effective option."},{"comment_id":"1062807","poster":"Pime13","timestamp":"1714900800.0","upvote_count":"4","content":"Selected Answer: D\nhttps://cloud.google.com/backup-disaster-recovery/docs/concepts/backupdr-for-oracle#oracle_backup_apis"},{"comment_id":"1005160","upvote_count":"3","timestamp":"1710198180.0","content":"correct answer is C. Option C aligns with the requirements for performance, cost-effectiveness, and long-term data retention while meeting the RTO and RPO objectives.","poster":"learnazureportal"},{"content":"C\n\nCreating the database on a Bare Metal Solution server with the database running on flash storage will ensure high performance and low latency, which is critical for achieving the RTO and RPO objectives.\n\nKeeping a local backup copy on standard storage will provide a quick restore option in case of any issues or failures within the Bare Metal Solution environment. This allows for faster recovery when needed.\n\nUsing the Oracle Recovery Manager (RMAN) backup utility to move backups older than one day to a Coldline Storage bucket is a cost-effective solution for long-term data retention. Coldline Storage is designed for data archival and offers a lower cost compared to other storage options. By using RMAN, the backup process can be automated and scheduled, ensuring that the backups are regularly moved to the Coldline Storage bucket.","comment_id":"969128","upvote_count":"1","poster":"pico","timestamp":"1706803320.0"},{"poster":"abdenago","upvote_count":"2","content":"Selected Answer: B\nHDD (hard drive) for Local backups or archival workloads","comment_id":"922887","timestamp":"1702549620.0"},{"comment_id":"832973","timestamp":"1694171160.0","poster":"Nirca","upvote_count":"3","content":"Selected Answer: B\nGCP wants us to choose B"},{"comment_id":"826318","timestamp":"1693602060.0","poster":"PrtkKA","content":"Selected Answer: B\nRMAN cannot move backups to storage buckets.\nB","comments":[{"comment_id":"832969","comments":[{"content":"but I think you are right. and this is what GCP aiming for.","timestamp":"1694171100.0","comment_id":"832972","poster":"Nirca","upvote_count":"1"}],"poster":"Nirca","timestamp":"1694171040.0","upvote_count":"1","content":"0\n\n\nYou can use gcsfuse to mount GCS bucket as file systems on your machine and use RMAN to create backups there."}],"upvote_count":"1"},{"comment_id":"768812","poster":"openkg","timestamp":"1688747040.0","upvote_count":"3","content":"Selected Answer: D\nD is an answer"},{"content":"D is an answer","comment_id":"761781","poster":"Atnafu","upvote_count":"4","timestamp":"1688107440.0"},{"poster":"pk349","upvote_count":"4","content":"D:\nCreate the database on a Bare Metal Solution server with the database running on flash storage.\nArchive storage ARCHIVE 365 days Yes • 99.95% in multi-regions and dual-regions\n• 99.9% in regions\n\nKeep a local backup copy on all flash storage.\nUse the Oracle Recovery Manager (RMAN) backup utility to move backups older than one day to an ***** Archive Storage bucket.","timestamp":"1687638960.0","comment_id":"755211"}],"answer_description":"","answer_ET":"D","question_images":[],"unix_timestamp":1671921360,"exam_id":5,"answer_images":[],"timestamp":"2022-12-24 23:36:00","question_text":"Your organization is migrating 50 TB Oracle databases to Bare Metal Solution for Oracle. Database backups must be available for quick restore. You also need to have backups available for 5 years. You need to design a cost-effective architecture that meets a recovery time objective (RTO) of 2 hours and recovery point objective (RPO) of 15 minutes. What should you do?","question_id":121},{"id":"ACp3xeGbHtXFsSeGAoAx","exam_id":5,"choices":{"D":"Configure your Cloud SQL instance with high availability enabled.","C":"Enable maintenance notifications for users, and reschedule maintenance activities to a specific time after notifications have been sent.","B":"Create your database with one primary node and one read replica in the region.","A":"Configure a maintenance window during a period when no users will be on the system. Control the order of update by setting non-production instances to earlier and production instances to later."},"answer_images":[],"unix_timestamp":1671725640,"answer_description":"","question_images":[],"discussion":[{"poster":"chelbsik","comment_id":"757672","upvote_count":"10","timestamp":"1672074600.0","content":"Selected Answer: A\nSince we don't really need HA and we have a window that users are not need our app - A is fine, and D looks like an overkill"},{"poster":"orvalver","upvote_count":"1","content":"Selected Answer: A\nThe key term here is the maintenance window, if we see MW we can work to configure it. Letter A.","timestamp":"1733886960.0","comment_id":"1324830"},{"comment_id":"1208700","upvote_count":"2","content":"Selected Answer: A\nA because maintenance should be on the time with minimal impact","timestamp":"1715232420.0","poster":"hanayome"},{"upvote_count":"3","timestamp":"1695015240.0","comment_id":"1010290","content":"Selected Answer: A\nA is the correct answer.","poster":"goodsport"},{"upvote_count":"4","timestamp":"1678540380.0","content":"A.\nGoogle controls maintenance which could cause some downtime. Hence D would be irrelevant. C seems like a lot of work. B is also irrelevant. That leaves A as the best answer since you can choose your maintenance window to be after users will not be using the system. The addition of the earlier and later information is fluff and is not relevant to the question.","poster":"dynamic_dba","comment_id":"836018"},{"upvote_count":"1","comment_id":"827653","content":"Selected Answer: A\nA is right.","poster":"Nirca","timestamp":"1677817020.0"},{"timestamp":"1672865220.0","comment_id":"766072","poster":"ssaporylo","upvote_count":"4","content":"Vote for A. Configure time slot for maintainance\nHA for fail over but also has maintainance window"},{"comment_id":"755778","timestamp":"1671981900.0","upvote_count":"4","content":"A: Configure a maintenance window ***** during a period when no users will be on the system. Control the order of update by setting non-production instances to earlier and production instances to later.","poster":"pk349"},{"poster":"GCP72","timestamp":"1671841680.0","comment_id":"754617","content":"6AM to 10PM","upvote_count":"1"},{"upvote_count":"3","comment_id":"754616","timestamp":"1671841620.0","poster":"GCP72","content":"Selected Answer: A\nA is the correct answer because application is used between"},{"timestamp":"1671725640.0","comment_id":"753471","content":"Selected Answer: D\nCorrect answer - D\nhttps://cloud.google.com/sql/docs/mysql/high-availability#HA-configuration","poster":"jitu028","upvote_count":"2"}],"question_id":122,"isMC":true,"topic":"1","answers_community":["A (91%)","9%"],"question_text":"You host an application in Google Cloud. The application is located in a single region and uses Cloud SQL for transactional data. Most of your users are located in the same time zone and expect the application to be available 7 days a week, from 6 AM to 10 PM. You want to ensure regular maintenance updates to your Cloud SQL instance without creating downtime for your users. What should you do?","url":"https://www.examtopics.com/discussions/google/view/92469-exam-professional-cloud-database-engineer-topic-1-question-9/","timestamp":"2022-12-22 17:14:00","answer":"A","answer_ET":"A"},{"id":"2bjn4XtI2ZSbDTW3QTOY","answer_ET":"C","url":"https://www.examtopics.com/discussions/google/view/92712-exam-professional-cloud-database-engineer-topic-1-question/","discussion":[{"timestamp":"1718832120.0","content":"Selected Answer: C\nOption C is corect\nspanner.admin God-tier control over everything Full CRUD & DDL for instances, databases, users, policies Manage entire Cloud Spanner environment\n\nspanner.databaseAdmin Database master control Full CRUD & DDL for databases, users, policies Create, manage, and secure databases\n\nspanner.databaseUser Power user with data rights Full CRUD & DDL for specified databases Read, write, modify data, manage database schema\n\nspanner.databaseReader Curious but hands-off observer Read-only access and query execution Analyze data without manipulation\n\nspanner.viewer Peeping Tom (metaphorically speaking) View instances, databases, and users Monitor Cloud Spanner metadata, no data access\n\nspanner.backupAdmin Backup whiz Create, view, update, delete backups Manage backups without accessing data","comment_id":"1101065","poster":"whoosh","upvote_count":"2"},{"poster":"learnazureportal","comment_id":"1005166","content":"The answer list is not correct. we need to have a custom role for this task. BTW, Option C (assigning the Cloud Spanner Database User role) does not provide the necessary permissions to add columns and indexes or perform DDL operations. that said, it not correct either :)","timestamp":"1710199080.0","upvote_count":"1"},{"comment_id":"839060","poster":"dynamic_dba","upvote_count":"3","content":"C.\nThis has nothing to do with backups. Eliminate A. Any admin role would be too wide. Eliminate B and D. That leaves C. roles/spanner.databaseUser provides r/w. view and update schemas.\nhttps://cloud.google.com/spanner/docs/iam#spanner.databaseUser","timestamp":"1694703720.0"},{"upvote_count":"1","timestamp":"1691767620.0","poster":"zanhsieh","content":"Selected Answer: C\nC\nA: WRONG. Neither roles can add columns and indexes (missing spanner.databases.updateDdl permission)\nB: WRONG. Exceeded permissions needed.\nC: CORRECT.\nD: WRONG. Exceeded permissions needed.\nReference:\nhttps://gcp.permissions.cloud/predefinedroles/spanner.admin\nhttps://gcp.permissions.cloud/predefinedroles/spanner.databaseReader\nhttps://gcp.permissions.cloud/predefinedroles/spanner.backupWriter\nhttps://gcp.permissions.cloud/predefinedroles/spanner.databaseAdmin\nhttps://gcp.permissions.cloud/predefinedroles/spanner.databaseUser","comment_id":"805458"},{"comment_id":"787450","timestamp":"1690270200.0","content":"Selected Answer: B\nhttps://cloud.google.com/spanner/docs/iam","upvote_count":"1","poster":"orbo"},{"content":"Selected Answer: C\nVote for C","timestamp":"1687716900.0","comment_id":"755987","poster":"chelbsik","upvote_count":"4"},{"timestamp":"1687638840.0","content":"C: Assign the Cloud Spanner Database User *** role.","upvote_count":"1","poster":"pk349","comment_id":"755209"}],"answer_images":[],"choices":{"A":"Assign the Cloud Spanner Database Reader and Cloud Spanner Backup Writer roles.","C":"Assign the Cloud Spanner Database User role.","D":"Assign the Cloud Spanner Admin role.","B":"Assign the Cloud Spanner Database Admin role."},"isMC":true,"question_images":[],"unix_timestamp":1671921240,"question_text":"You are a DBA on a Cloud Spanner instance with multiple databases. You need to assign these privileges to all members of the application development team on a specific database:\n\nCan read tables, views, and DDL -\n\nCan write rows to the tables -\n\nCan add columns and indexes -\n\nCannot drop the database -\nWhat should you do?","answer":"C","answer_description":"","question_id":123,"exam_id":5,"topic":"1","timestamp":"2022-12-24 23:34:00","answers_community":["C (88%)","13%"]},{"id":"xTGpAJRgWlTGekgOMvUO","unix_timestamp":1671921240,"timestamp":"2022-12-24 23:34:00","answer_ET":"B","answer":"B","question_images":[],"discussion":[{"poster":"Zek","content":"B\nWhile IAM enables granular identity-based access control, VPC Service Controls enables broader context-based perimeter security, including controlling data egress across the perimeter. We recommend using both VPC Service Controls and IAM for defense in depth.\nhttps://cloud.google.com/vpc-service-controls/docs/overview#how-vpc-service-controls-works","upvote_count":"1","comment_id":"1313075","timestamp":"1731766740.0"},{"timestamp":"1678829580.0","upvote_count":"3","comment_id":"839318","poster":"dynamic_dba","content":"B.\nA is wrong because you might have the right credentials but still access Bigtable across the internet. Same is true for C. Cloud Armor could help, but VPC Service Controls is a classic use case of ensuring access is only from within certain VPC networks. From Google’s documentation, “Users can define a security perimeter around Google Cloud resources such as Cloud Storage buckets, Bigtable instances, and BigQuery datasets to constrain data within a VPC and control the flow of data.”\nhttps://cloud.google.com/vpc-service-controls"},{"content":"Selected Answer: B\nI'll go for B","poster":"chelbsik","timestamp":"1671999360.0","upvote_count":"4","comment_id":"755988"},{"upvote_count":"1","timestamp":"1671921240.0","content":"B: Use VPC Service Controls to create a trusted network for the Bigtable service.","poster":"pk349","comment_id":"755208"}],"choices":{"A":"Use Identity and Access Management (IAM) for Bigtable access control.","D":"Use Google Cloud Armor to add IP addresses to an allowlist.","C":"Use customer-managed encryption keys (CMEK).","B":"Use VPC Service Controls to create a trusted network for the Bigtable service."},"isMC":true,"exam_id":5,"topic":"1","answers_community":["B (100%)"],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/92711-exam-professional-cloud-database-engineer-topic-1-question/","question_id":124,"question_text":"Your project is using Bigtable to store data that should not be accessed from the public internet under any circumstances, even if the requestor has a valid service account key. You need to secure access to this data. What should you do?","answer_images":[]},{"id":"uuDgPAzRN4B5dvTAA8jB","exam_id":5,"choices":{"C":"Cloud Spanner","D":"Bigtable","A":"Cloud SQL","B":"BigQuery"},"answer_images":[],"unix_timestamp":1671921180,"answer_description":"","question_images":[],"discussion":[{"poster":"SVGoogle89","timestamp":"1687903080.0","content":"bigquery - Analytics and reporting","upvote_count":"13","comment_id":"759176"},{"poster":"juliorevk","timestamp":"1712276460.0","comments":[{"comment_id":"1212760","content":"Indeed!","upvote_count":"1","timestamp":"1731837420.0","poster":"dija123"}],"upvote_count":"6","content":"Selected Answer: B\nThis question is poorly worded. I interpret it as: you have a ticketing system that needs an analytics and reporting app. Which database for this analytics and reporting app (not the ticketing system)? It should be BQ. However, it could also be read as what database for the ticketing system which also happens to need analytics and reporting. Which means the answer should be Spanner. Very confusing, but I'm leaning towards B for BQ based on my first interpretation.","comment_id":"1025222"},{"comment_id":"1417435","poster":"bad5fad","upvote_count":"1","content":"Selected Answer: C\nC. The answer is cloud spanner. They need a DDBB, big query is not a DDBB","timestamp":"1743511020.0"},{"poster":"james2033","content":"Selected Answer: B\nMarketing analytics https://cloud.google.com/bigquery?hl=en#marketing-analytics","comment_id":"1177362","timestamp":"1726745400.0","upvote_count":"1"},{"content":"Selected Answer: C\nC because OLTP supported in spanner not in BQ","poster":"Jason_Cloud_at","comment_id":"1157015","upvote_count":"1","timestamp":"1724396220.0"},{"content":"Selected Answer: B\nthe question ask about the database for the new app which is analytic and reporting so this should BQ.","upvote_count":"1","timestamp":"1722420600.0","comment_id":"1136736","poster":"PKookNN"},{"content":"option B - managing hundreds of terabytes of data and supporting an online marketing analytics and reporting application, BigQuery (Option B) is the most suitable choice","comment_id":"1018243","timestamp":"1711501740.0","upvote_count":"1","poster":"learnazureportal"},{"upvote_count":"4","content":"Selected Answer: C\nThe answer is C \nBigquery is not a Database \" You need to select a relational database \" Bigquery is a Datawarehouse","timestamp":"1711023900.0","poster":"Kapello10","comment_id":"1012987"},{"upvote_count":"2","content":"Selected Answer: C\nIt might be both B and C. B- for analytic purpose but I would be inclining to C as we need OLTP database for ticketing systems.","comment_id":"963383","timestamp":"1706253840.0","poster":"badrisrinivas9"},{"comment_id":"959322","content":"Selected Answer: B\nBigquery is relational and recomanded for analytics: https://cloud.google.com/products/databases","poster":"Ryannn23","timestamp":"1705915140.0","upvote_count":"2"},{"poster":"DBAgain","comment_id":"954373","timestamp":"1705516020.0","upvote_count":"2","content":"Selected Answer: B\nThis is an analytics problem suited for BigQuery. Cloud Spanner isn't a good solution for analytics queries that scan a full table to do aggregations of the data because the query would span multiple (or all) shards)."},{"upvote_count":"3","comment_id":"839319","timestamp":"1694720100.0","poster":"dynamic_dba","content":"C.\nCloud SQL could not scale to 100s of TBs. Eliminate A. Neither Big Query nor Bigtable are relational (although BigQuery does support SQL). Eliminate B and D. That leaves C.","comments":[{"comment_id":"958509","timestamp":"1705849380.0","content":"Bigquery is relational: https://cloud.google.com/products/databases\nMoreover, BQ is designed for \"Multicloud analytics\"","upvote_count":"3","poster":"Ryannn23"}]},{"content":"Cloud SQL has a double-digit TB storage limit so it's Cloud Spanner.","timestamp":"1690530840.0","poster":"lukacs16","comment_id":"790490","upvote_count":"1"},{"upvote_count":"1","poster":"muky31dec","comment_id":"788755","timestamp":"1690370760.0","content":"Big query is data warehouse not a relational database"},{"upvote_count":"3","content":"Analytical Database with no transactions my vote B","comment_id":"761869","poster":"ssaporylo","timestamp":"1688116980.0"},{"upvote_count":"4","content":"B - This is a new application used for analytics, it does not need to take care of the DML required by the ticketing system","timestamp":"1687950960.0","poster":"SandyZA","comment_id":"759870"},{"timestamp":"1687717020.0","comment_id":"755990","upvote_count":"3","poster":"chelbsik","content":"Selected Answer: C\nSpanner"},{"timestamp":"1687638780.0","comment_id":"755207","poster":"pk349","upvote_count":"3","content":"C: Cloud Spanner\nOn the other hand, Google Cloud Spanner supports ***** OLTP along with scalability and high availability. Hence, Cloud Spanner is more suited for E-commerce systems, Core Banking, Gaming, Telecom, etc.\nIt allows updating to existing records and appending data to existing tables."}],"question_id":125,"isMC":true,"topic":"1","answers_community":["B (52%)","C (48%)"],"question_text":"Your organization has a ticketing system that needs an online marketing analytics and reporting application. You need to select a relational database that can manage hundreds of terabytes of data to support this new application. Which database should you use?","url":"https://www.examtopics.com/discussions/google/view/92710-exam-professional-cloud-database-engineer-topic-1-question/","timestamp":"2022-12-24 23:33:00","answer":"B","answer_ET":"B"}],"exam":{"isBeta":false,"numberOfQuestions":132,"lastUpdated":"11 Apr 2025","provider":"Google","isMCOnly":true,"isImplemented":true,"id":5,"name":"Professional Cloud Database Engineer"},"currentPage":25},"__N_SSP":true}