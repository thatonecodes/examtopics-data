{"pageProps":{"questions":[{"id":"ugYzk44jPZkVEv0xOjjq","exam_id":7,"discussion":[{"content":"Took the exam 2 weeks and got pass, however, NOT A SINGLE question is from here! Although it is still good for practice purpose, DO NOT just remember these questions to take the exam.\n\n-- My comment above is still waiting approval after two weeks, it seems someone doesn't want it to be published.","upvote_count":"5","comments":[{"content":"why do you lie","timestamp":"1627820220.0","upvote_count":"2","comment_id":"418253","poster":"1234567J"},{"poster":"looseboy","content":"My comment is still waiting approval too.","timestamp":"1627873740.0","comment_id":"418483","upvote_count":"1"}],"poster":"i896ii","timestamp":"1627144200.0","comment_id":"413306"},{"timestamp":"1742544600.0","poster":"Paxtons_Aunders","content":"Selected Answer: A\nA. gsutil cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/\nThis command is used to copy files from local storage to Google Cloud Storage. It’s the correct option for uploading data as part of a migration process that will be consumed by Cloud Dataproc.\nhttps://docs.google.com/document/d/1VV6vkkjShXDgPLSG6V_7-0dweLmZTUnYiTSxo6C5ERY/edit?tab=t.0","comment_id":"1401474","upvote_count":"1"},{"content":"Selected Answer: A\nA. gsutil cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/\ngsutil is the correct tool because:\nIt's the dedicated command-line tool for Google Cloud Storage operations\nSpecifically designed for file and bucket management in GCS\nSupports efficient file transfer between local systems and Cloud Storage\nProvides reliable upload capabilities with automatic retry mechanisms\nThe command structure:\ngsutil cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/\ncp: Copy command\n[LOCAL_OBJECT]: Source file path\ngs://: Protocol identifier for Google Cloud Storage\n[DESTINATION_BUCKET_NAME]: Target bucket name","upvote_count":"1","timestamp":"1734978240.0","poster":"Hila_Sh","comment_id":"1330902"},{"upvote_count":"1","comment_id":"1296466","poster":"Edgar0123","content":"As updates to the Google Cloud SDK, the `gcloud` tool now includes a `storage` command group that allows you to interact with Google Cloud Storage (GCS) similarly to how you would with `gsutil` command","timestamp":"1728730980.0"},{"timestamp":"1728567720.0","upvote_count":"1","poster":"www_certifiedumps_com_google","content":"Selected Answer: A\nA. gsutil cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/\nThis command is used to copy files from local storage to Google Cloud Storage. It’s the correct option for uploading data as part of a migration process that will be consumed by Cloud Dataproc.","comment_id":"1295614"},{"timestamp":"1699926000.0","content":"A is correct answer","poster":"blackshuai","upvote_count":"1","comment_id":"1069896"},{"upvote_count":"1","timestamp":"1699386240.0","content":"Selected Answer: A\nAnswer: A \nCloud Storage => gsutil. Doesn't matter how the files are going to be consumed, the task is to upload them.","comment_id":"1065121","poster":"wanrltw"},{"content":"Selected Answer: A\nI would go with A.","comment_id":"1011359","upvote_count":"1","poster":"__rajan__","timestamp":"1695130440.0"},{"poster":"didek1986","comment_id":"992460","timestamp":"1693243920.0","content":"Selected Answer: A\nfor sure A","upvote_count":"1"},{"timestamp":"1684605600.0","comment_id":"902713","poster":"Jigglypuff09","content":"Selected Answer: B\nAnyone took exam recently, what percent of questions came from examtopics?","upvote_count":"2"},{"poster":"Bossam","comment_id":"830680","content":"Anyone took exam recently, what percent of questions came from examtopics?","timestamp":"1678093920.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"812560","content":"Selected Answer: A\ngsutil cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/","timestamp":"1676685600.0","poster":"atoledo"},{"content":"A is correct","timestamp":"1671362220.0","upvote_count":"1","comment_id":"748776","poster":"Nandak217"},{"upvote_count":"1","poster":"tomato123","content":"Selected Answer: A\nA is correct","comment_id":"648886","timestamp":"1660905360.0"},{"content":"The exam is totally different from the one presented in the dump, it proves TOTALLY DIFFERENT.\nPlease update the questions with the original exam!!","timestamp":"1636067160.0","poster":"SuperDevops","upvote_count":"2","comment_id":"472800"},{"poster":"Daywa1k3r","comment_id":"394453","timestamp":"1625031780.0","content":"There was a lot of GKE especially with istio.","upvote_count":"2"},{"timestamp":"1624511880.0","comment_id":"389234","content":"cloud storage command: gsutil","upvote_count":"1","poster":"yuchun"},{"timestamp":"1623078720.0","upvote_count":"1","comment_id":"376867","poster":"chithra1990","content":"is this question set updated ?"},{"poster":"mobius_z","upvote_count":"2","content":"Took the exam two days ago, only 4 of the questions from this set appeared in the actual exam, remaining 56 were new questions. Even after the June 2nd update, I don't see any of the new questions here.","comment_id":"374407","timestamp":"1622816340.0"},{"poster":"syu31svc","content":"Cloud Storage is the key here so answer is A","timestamp":"1622344620.0","comment_id":"369832","upvote_count":"3"},{"poster":"JuanitoNN","timestamp":"1620776160.0","content":"You are running an application on Compute Engine and collecting logs through Stackdriver. You discover that some personally identifiable information (Pll) is leaking into certain log entry fields. All Pll entries begin with the text userinfo. You want to capture these log entries in a secure location for later review and prevent them from leaking to Stackdriver Logging. What should you do?\n\"A. Create a basic log filter matching userinfo, and then configure a log export in the Stackdriver console with Cloud Storage as a sink.\nB. Use a Fluentd filter plugin with the Stackdriver Agent to remove log entries containing userinfo, and then copy the entries to a Cloud Storage bucket.\nC. Create an advanced log filter matching userinfo, configure a log export in the Stackdriver console with Cloud Storage as a sink, and then configure a tog exclusion with userinfo as a filter.\nD. Use a Fluentd filter plugin with the Stackdriver Agent to remove log entries containing userinfo, create an advanced log filter matching userinfo, and then configure a log export in the Stackdriver console with Cloud Storage as a sink.\"","upvote_count":"1","comment_id":"355085"},{"upvote_count":"1","timestamp":"1620774720.0","content":"Your product is currently deployed in three Google Cloud Platform (GCP) zones with your users divided between the zones. You can fail over from one zone to another, but it causes a 10-minute service disruption for the affected users. You typically experience a database failure once per quarter and can detect it within five minutes. You are cataloging the reliability risks of a new real-time chat feature for your product. You catalog the following information for each risk.\nThe chat feature requires a new database system that takes twice as long to successfully fail over between zones. You want to account for the risk of the new database failing in one zone. What would be the values for the risk of database failover with the new system?\nA. MTTD: 5\nMTTR: 10\nMTBF: 90\nImpact: 33%\nB. MTTD:5\nMTTR: 20\nMTBF: 90\nImpact: 33%\nC. MTTD:5\nMTTR: 10\nMTBF: 90\nImpact 50%\nD. MTTD:5\nMTTR: 20\nMTBF: 90\nImpact: 50%","poster":"JuanitoNN","comments":[{"comment_id":"513352","content":"B is the answer","timestamp":"1640867640.0","poster":"TNT87","upvote_count":"1"}],"comment_id":"355080"},{"timestamp":"1620172320.0","poster":"runrajarun","comment_id":"349821","content":"any possibility to have all DevOps questions?","upvote_count":"2"},{"timestamp":"1619649960.0","upvote_count":"1","poster":"runrajarun","comments":[{"upvote_count":"1","timestamp":"1619790540.0","comment_id":"346235","poster":"JuanitoNN","content":"Hello, why is b, any reason?","comments":[{"comment_id":"349809","timestamp":"1620170940.0","upvote_count":"1","poster":"runrajarun","content":"Standard tier is less cost compared to http load balance ingress and kubernates cluster."}]}],"content":"Q. Devops\nYou support the backend of a mobile phone game that runs on a Google Kubernetes Engine (GKE) cluster. The application is serving HTTP requests from users. You need to implement a solution that will reduce the network cost. What should you do?\n\n\"A. Configure the VPC as a Shared VPC Host project.\nB. Configure your network services on the Standard Tier.\nC. Configure your Kubernetes cluster as a Private Cluster.\nD. Configure a Google Cloud HTTP Load Balancer as Ingress.\"\n\nans : B","comment_id":"344912"},{"timestamp":"1619296920.0","poster":"JuanitoNN","content":"Q. Devops\nYou support the backend of a mobile phone game that runs on a Google Kubernetes Engine (GKE) cluster. The application is serving HTTP requests from users. You need to implement a solution that will reduce the network cost. What should you do?\n\n\"A. Configure the VPC as a Shared VPC Host project.\nB. Configure your network services on the Standard Tier.\nC. Configure your Kubernetes cluster as a Private Cluster.\nD. Configure a Google Cloud HTTP Load Balancer as Ingress.\"","upvote_count":"1","comment_id":"342217"},{"content":"A is correct answer","poster":"saurabh1805","comment_id":"215379","upvote_count":"2","timestamp":"1604854440.0"},{"comment_id":"134798","upvote_count":"2","poster":"mlyu","content":"Ans:A\nhttps://cloud.google.com/storage/docs/uploading-objects","timestamp":"1594726080.0"},{"comment_id":"126496","poster":"ds0312","timestamp":"1593914220.0","upvote_count":"1","content":"Correct answer - A"}],"answer_ET":"A","question_text":"You want to upload files from an on-premises virtual machine to Google Cloud Storage as part of a data migration. These files will be consumed by Cloud\nDataProc Hadoop cluster in a GCP environment.\nWhich command should you use?","answers_community":["A (80%)","B (20%)"],"choices":{"B":"gcloud cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/","C":"hadoop fs cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/","D":"gcloud dataproc cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/","A":"gsutil cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/"},"isMC":true,"answer":"A","unix_timestamp":1593914220,"answer_description":"","answer_images":[],"timestamp":"2020-07-05 03:57:00","question_images":[],"question_id":1,"topic":"1","url":"https://www.examtopics.com/discussions/google/view/24750-exam-professional-cloud-developer-topic-1-question-1/"},{"id":"FUK0QSGqd4Tf8za8tVBt","answer":"AC","url":"https://www.examtopics.com/discussions/google/view/21441-exam-professional-cloud-developer-topic-1-question-10/","choices":{"A":"Create a multi-regional Cloud Spanner instance with \"nam-asia-eur1\" configuration.","B":"Create a multi-regional Cloud Spanner instance with \"nam3\" configuration.","E":"Create a minimum of two Cloud Spanner instances in separate regions with at least one node.","F":"Create a Cloud Dataflow pipeline to replicate data across different databases.","C":"Create a cluster with at least 3 Spanner nodes.","D":"Create a cluster with at least 1 Spanner node."},"answer_ET":"AC","exam_id":7,"unix_timestamp":1590567540,"isMC":true,"answers_community":["AC (100%)"],"question_images":[],"answer_description":"","timestamp":"2020-05-27 10:19:00","question_id":2,"topic":"1","discussion":[{"timestamp":"1620330960.0","content":"The more number of node less read latency hence i will go with option A and C","upvote_count":"9","poster":"saurabh1805","comment_id":"214306"},{"poster":"emmet","timestamp":"1606472340.0","comment_id":"96654","content":"I think the answer should be A) + something.\nThey wants 99.999% availability - only multi-regional instance fits this. To minimize read latency nam-asia-eur1 instance works best as it has replicas in Noth America, Europe and Asia regions.\n\n\nAs for second answer - I do not have strong opinion.. As per documentation \"Adding nodes gives each replica more CPU and RAM, which increases the replica's throughput\" and they recommend to choose number of nodes to \"keep high priority total CPU utilization under 65%\". So nodes are not about SLA and read latency. From another hand spanner \"Cloud Spanner automatically replicates your data between regions with strong consistency guarantees\" so no DataFlow pipeline needed to replicate data, unless the app has other DBs and ETL between Spanner and that DBs.","upvote_count":"7"},{"upvote_count":"1","content":"Selected Answer: AC\nTo achieve 99.999% availability and minimize read latency for a globally distributed user base, the company should:\n- Deploy a multi-regional Cloud Spanner instance with the \"nam-asia-eur1\" configuration (Option A). This setup will provide the geographical distribution of data across three continents — North America, Asia, and Europe. The multi-regional nature of this option is designed to maintain high availability and ensure users across these regions experience low latency when accessing the database.\n- Ensure that the Cloud Spanner instance has a minimum of three nodes (Option C). This configuration will contribute to the high availability and fault tolerance of the database. Spanner's built-in replication across these nodes in different regions will further support the five nines (99.999%) availability target, while also providing scalability for read operations.","timestamp":"1725712920.0","comment_id":"1168100","poster":"santoshchauhan"},{"timestamp":"1722942480.0","upvote_count":"1","content":"Selected Answer: AC\nLet's think about all possible answers: \n - B does not make sense, as \"nam3\" is not the global configuration we want;\n - D is not ok, 'cause 1 node is not enough\n - E is not enough, as we want a global configuration;\n - F is totally unrelated.","poster":"theseawillclaim","comment_id":"1142160"},{"poster":"__rajan__","timestamp":"1710862920.0","comment_id":"1011383","content":"Selected Answer: AC\nAC are best suited here.","upvote_count":"1"},{"upvote_count":"2","timestamp":"1699040400.0","comments":[{"timestamp":"1703540400.0","poster":"DonWang","content":"there is `nam3` \nhttps://cloud.google.com/spanner/docs/instance-configurations","comment_id":"933848","upvote_count":"2"}],"comment_id":"888800","poster":"closer89","content":"Selected Answer: AC\n99.999% availability and reduce latency\nOption A gives us 99.999% availability (think its typo in region name)\nOption C is about compute capacity, more nodes -> less latency\nhttps://cloud.google.com/spanner/docs/instances#compute-capacity\nB - there is no such multi-region configuration nam3\nD - its better to create cluster with 3 nodes, not 1\nE,F - overengineering"},{"content":"Selected Answer: AC\nA - global and provides 99.999% availability\nC - more nodes - less latency","upvote_count":"1","comment_id":"872870","timestamp":"1697558520.0","poster":"closer89"},{"content":"Selected Answer: AC\nit's obvious","comment_id":"751055","upvote_count":"1","poster":"tuanbo91","timestamp":"1687265880.0"},{"comment_id":"742619","content":"why not C and F","poster":"Lunaisxiaoxin","timestamp":"1686555780.0","upvote_count":"1"},{"timestamp":"1685190960.0","comments":[{"poster":"zevexWM","comment_id":"773372","upvote_count":"1","content":"There is according to their documentation: https://cloud.google.com/spanner/docs/instance-configurations#three_continents","timestamp":"1689152760.0"}],"comment_id":"728335","poster":"jcataluna","content":"Selected Answer: AC\n3 regions at least, and for those that says there is no region \"man-asia-eur1\", take a look at the console, its multiregion nomenclature!","upvote_count":"1"},{"poster":"jeeet_","upvote_count":"4","timestamp":"1683271020.0","comment_id":"711631","content":"There is no region called \"\"nam-asia-eur1\"\"\nA is wrong, \nB&C is correct"},{"comment_id":"650016","upvote_count":"2","poster":"brunoguzzo18","content":"Selected Answer: AC\nWe need multi-regin db (spanner) to satisfy 99,999% SLA and have multi-node to ensure resource needed.","timestamp":"1677044460.0"},{"content":"Selected Answer: AC\nAC are correct","poster":"tomato123","timestamp":"1676877960.0","upvote_count":"3","comment_id":"649167"},{"comment_id":"635083","upvote_count":"4","poster":"maxdanny","timestamp":"1674381600.0","content":"C because the number of nodes increases the computational capabilities ( queries for seconds and so minor latency), F to cover worldwide availability; A it's wrong because the configuration \"nam-asia-eur1\" not exist, Google suggests \"nam-eur-asia1\" o \"nam-eur-asia3\", D it's wrong because the number of nodes is too few; E is too expensive a solution"},{"comment_id":"630477","timestamp":"1673529960.0","upvote_count":"1","poster":"jdx000","content":"Selected Answer: AC\nA and C make sense"},{"content":"This should be A and F.","upvote_count":"1","timestamp":"1657212060.0","poster":"ParagSanyashiv","comment_id":"519156"},{"comment_id":"410609","upvote_count":"3","timestamp":"1642739820.0","poster":"wilwong","content":"Agree with A and C"},{"content":"https://cloud.google.com/spanner/docs/instances\n\nAbove link supports A for \"users across the globe\" as per qn\n\nhttps://cloud.google.com/spanner/docs/latency\n\nAbove link supports C for \"minimize the read latency \"","comment_id":"385995","upvote_count":"6","timestamp":"1639988460.0","poster":"syu31svc"},{"timestamp":"1623685620.0","content":"i think that the answer is A & F. \nA becouse minimize the latency compared to B. \nF becouse is the best way to import data: https://cloud.google.com/spanner/docs/import-non-spanner\nThe answers B & C is not possible because the number of node depends to amount of the data, that we don't know.","poster":"fraloca","comment_id":"243795","upvote_count":"3"}],"question_text":"Your company wants to expand their users outside the United States for their popular application. The company wants to ensure 99.999% availability of the database for their application and also wants to minimize the read latency for their users across the globe.\nWhich two actions should they take? (Choose two.)","answer_images":[]},{"id":"vonuXnizwOT9HKnXZgNC","question_id":3,"topic":"1","question_text":"Your development team is using Cloud Build to promote a Node.js application built on App Engine from your staging environment to production. The application relies on several directories of photos stored in a Cloud Storage bucket named webphotos-staging in the staging environment. After the promotion, these photos must be available in a Cloud Storage bucket named webphotos-prod in the production environment. You want to automate the process where possible. What should you do?","exam_id":7,"answer":"C","answer_description":"","answer_ET":"C","choices":{"D":"Add a build step in the cloudbuild.yaml file before the promotion step with the arguments:","C":"Add a build step in the cloudbuild.yaml file before the promotion step with the arguments:","A":"Manually copy the photos to webphotos-prod.","B":"Add a startup script in the application's app.yami file to move the photos from webphotos-staging to webphotos-prod."},"discussion":[{"content":"C.Add a build step in the cloudbuild.yaml file before the promotion step with the arguments:\n-name: gcr.io/cloud-builders/gsutil\nargs: ['cp','-r','gs://webphotos-staging','gs://webphotos-prod']\nwaitFor: ['-']\n\nYou should add a build step in the cloudbuild.yaml file before the promotion step with the arguments shown above. This build step will use the gsutil tool to copy the photos from the webphotos-staging bucket to the webphotos-prod bucket. The -r flag tells gsutil to copy all files in the bucket recursively, and the waitFor parameter tells Cloud Build to wait for this step to complete before continuing with the promotion step.","poster":"omermahgoub","comment_id":"767522","upvote_count":"4","timestamp":"1720255080.0"},{"upvote_count":"1","timestamp":"1718964720.0","comment_id":"752261","content":"Selected Answer: C\nC is the answer.","poster":"zellck"},{"timestamp":"1708416240.0","content":"Selected Answer: C\nC is correct","poster":"tomato123","comment_id":"649270","upvote_count":"2"},{"comment_id":"631171","timestamp":"1705214460.0","content":"Selected Answer: C\nhttps://cloud.google.com/storage/docs/gsutil/commands/cp","poster":"nehaxlpb","upvote_count":"1"},{"content":"Agree with Option C","timestamp":"1689988260.0","comment_id":"529555","upvote_count":"3","poster":"Blueocean"},{"poster":"ParagSanyashiv","upvote_count":"2","comment_id":"519986","content":"Agree with C","timestamp":"1688876940.0"}],"unix_timestamp":1641709740,"url":"https://www.examtopics.com/discussions/google/view/69719-exam-professional-cloud-developer-topic-1-question-100/","isMC":true,"question_images":[],"answers_community":["C (100%)"],"timestamp":"2022-01-09 07:29:00","answer_images":[]},{"id":"XnjlT1XDzF7RNSJGe9Pq","url":"https://www.examtopics.com/discussions/google/view/69772-exam-professional-cloud-developer-topic-1-question-101/","answer":"C","answer_description":"","question_text":"You are developing a web application that will be accessible over both HTTP and HTTPS and will run on Compute Engine instances. On occasion, you will need to SSH from your remote laptop into one of the Compute Engine instances to conduct maintenance on the app. How should you configure the instances while following Google-recommended best practices?","exam_id":7,"isMC":true,"answer_images":[],"discussion":[{"comment_id":"1250838","poster":"thewalker","timestamp":"1721363640.0","content":"Selected Answer: D\nOption D: The Best Practice\nSecurity: Using a bastion host with a public IP address provides a secure jump point. Your web servers remain behind a firewall with private IP addresses, making them less vulnerable to direct attacks.\nScalability: Bastion hosts can be easily scaled and managed, allowing you to control access to your web server instances.\nSSH Access: You can securely SSH into the bastion host and then tunnel to your web server instances.","comments":[{"timestamp":"1721363700.0","content":"Option A: TCP Proxy Load Balancer\nNot Ideal for Web Applications: TCP load balancers are better suited for applications that use TCP protocols, not HTTP/HTTPS.\nSSH Access: While you could potentially use a TCP load balancer for SSH, it's not the recommended approach.\nOption B: Open Firewall Rules\nMajor Security Risk: Exposing your web servers directly to the internet with public IP addresses is a significant security vulnerability.\nOption C: Cloud Identity-Aware Proxy (IAP) for SSH\nNot Designed for SSH: IAP is primarily designed for secure access to web applications, not for SSH. While you could potentially use IAP for SSH, it's not a standard or recommended practice.","poster":"thewalker","comment_id":"1250839","upvote_count":"1"}],"upvote_count":"1"},{"upvote_count":"1","comment_id":"1012643","content":"Selected Answer: D\nVM can only connect through IAM with public IP so C wouldn't work\nbastion host is one of options instead - https://cloud.google.com/compute/docs/connect/ssh-internal-ip","poster":"kostol","timestamp":"1695249540.0","comments":[{"upvote_count":"1","timestamp":"1700645400.0","poster":"wanrltw","comment_id":"1077176","content":"\"This document describes how to connect to a virtual machine (VM) instance through its internal IP address, using Identity-Aware Proxy (IAP) TCP forwarding.\"\nhttps://cloud.google.com/compute/docs/connect/ssh-using-iap"}]},{"comment_id":"1012066","upvote_count":"1","timestamp":"1695199140.0","poster":"__rajan__","content":"Selected Answer: C\nC is correct"},{"comment_id":"876381","content":"i go for C\nhttps://cloud.google.com/compute/docs/connect/ssh-using-iap\nIAP TCP forwarding enables you to establish an encrypted tunnel over which you can forward SSH connections to VMs. When you connect to a VM that uses IAP, IAP wraps the SSH connection inside HTTPS before forwarding the connection to the VM. Then, IAP checks if the you have the required IAM permissions and if you do, grants access to the VM.\n\nIf you need to connect to a VM that doesn't have external IP addresses and you can't use IAP, review the other methods listed in Connection options for internal-only VMs.","timestamp":"1682071500.0","poster":"closer89","comments":[{"comment_id":"876384","poster":"closer89","content":"D is wrong. \nBastion host VMs You have a specific use case, like session recording, and you can't use IAP","timestamp":"1682071740.0","upvote_count":"1"}],"upvote_count":"1"},{"content":"Selected Answer: C\ni would choose C: https://medium.com/@larry_nguyen/use-identity-aware-proxy-iap-instead-of-bastion-host-to-connect-to-private-virtual-machines-in-9885bc7c12dd","poster":"Pime13","comment_id":"823749","upvote_count":"1","timestamp":"1677505620.0"},{"poster":"omermahgoub","content":"D. is a recommended way to configure the instances while following Google-recommended best practices.\n\nThis approach provides several benefits:\n\nThe web server instances are only accessible through the load balancer and not directly via their private IP addresses, which improves security.\nThe bastion host acts as a secure jump box that allows you to SSH into the web server instances, while only allowing incoming SSH connections on a specific IP address (the bastion host's public IP).\nThe firewall rules on the web server instances can be configured to only allow connections from the bastion host's IP, further reducing the attack surface.\nIt is a more recommended to have a bastion host that is authorized by your organization to connect to private instances this way it can provide a better security to your instances. And also in terms of compliance, it will also follow the best practices of your organization.","timestamp":"1673357880.0","comments":[{"poster":"omermahgoub","content":"C is a valid approach, but it may not be the best option for all use cases.\n\nCloud IAP allows you to control access to resources in your project by using identity and access management (IAM) roles, which is a good way to secure SSH access. However, this option does not address the issue of securing incoming web traffic, which is a separate concern. Configuring the servers with private IP addresses behind an HTTP(s) load balancer would help with securing the web traffic, but it does not provide an additional layer of security for SSH access. Additionally, it does not have the concept of secure jump host, which is a security best practice in protecting your instances from unwanted incoming connections.","timestamp":"1673357880.0","upvote_count":"3","comment_id":"771458"}],"comment_id":"771456","upvote_count":"3"},{"timestamp":"1671624600.0","content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/iap","poster":"zellck","upvote_count":"1","comment_id":"752260"},{"upvote_count":"2","poster":"TNT87","content":"Selected Answer: C\nhttps://cloud.google.com/solutions/connecting-securely#storing_host_keys_by_enabling_guest_attributes\nAnswer C","timestamp":"1668411480.0","comment_id":"717766"},{"comment_id":"649271","poster":"tomato123","upvote_count":"2","timestamp":"1660975440.0","content":"Selected Answer: C\nC is correct"},{"poster":"akshaychavan7","upvote_count":"1","comment_id":"643170","timestamp":"1659755700.0","content":"Selected Answer: C\nI feel both C and D are correct for this scenario. \nThe only reason I would go with option C is that it would be easier to set up than setting up a bastion host."},{"timestamp":"1657773900.0","content":"Selected Answer: C\nWith TCP forwarding, IAP can protect SSH and RDP access to your VMs hosted on Google Cloud. Your VM instances don't even need public IP addresses.\nhttps://cloud.google.com/iap","poster":"nehaxlpb","comment_id":"631181","upvote_count":"1"},{"upvote_count":"2","content":"C is my answer, guys","comment_id":"603559","timestamp":"1652925840.0","poster":"szl0144"},{"comment_id":"601004","content":"D should be the answer (https://cloud.google.com/solutions/connecting-securely#external) But the bastion host should also be protected by IAP","poster":"s7an","timestamp":"1652426040.0","upvote_count":"2"},{"poster":"[Removed]","content":"C should be correct (https://cloud.google.com/iap/docs/using-tcp-forwarding#tunneling_ssh_connections)","comment_id":"597435","timestamp":"1651775640.0","upvote_count":"1"},{"timestamp":"1648894860.0","upvote_count":"2","content":"Ans is D","comments":[{"upvote_count":"1","timestamp":"1653016080.0","comment_id":"604225","content":"https://cloud.google.com/solutions/connecting-securely#external","poster":"dishum"}],"poster":"dishum","comment_id":"579800"},{"timestamp":"1641748620.0","content":"I vote C","poster":"scaenruy","comment_id":"520360","upvote_count":"4"}],"topic":"1","answer_ET":"C","question_id":4,"question_images":[],"unix_timestamp":1641748620,"timestamp":"2022-01-09 18:17:00","answers_community":["C (82%)","D (18%)"],"choices":{"C":"Configure Cloud Identity-Aware Proxy API for SSH access. Then configure the Compute Engine servers with private IP addresses behind an HTTP(s) load balancer for the application web traffic.","D":"Set up a backend with Compute Engine web server instances with a private IP address behind an HTTP(S) load balancer. Set up a bastion host with a public IP address and open firewall ports. Connect to the web instances using the bastion host.","A":"Set up a backend with Compute Engine web server instances with a private IP address behind a TCP proxy load balancer.","B":"Configure the firewall rules to allow all ingress traffic to connect to the Compute Engine web servers, with each server having a unique external IP address."}},{"id":"LlzaE3k5Q4Q3qiDeRNc5","timestamp":"2022-01-09 07:48:00","question_text":"You have a mixture of packaged and internally developed applications hosted on a Compute Engine instance that is running Linux. These applications write log records as text in local files. You want the logs to be written to Cloud Logging. What should you do?","answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/69720-exam-professional-cloud-developer-topic-1-question-102/","answer_description":"","question_id":5,"exam_id":7,"answer":"B","answer_ET":"B","discussion":[{"timestamp":"1693055700.0","upvote_count":"11","poster":"GCPCloudArchitectUser","comment_id":"556730","content":"Selected Answer: B\nCollectd is used for Monitoring agents \nFluentd is for cloud logging agent"},{"comment_id":"519989","timestamp":"1688878080.0","content":"Agree with B","upvote_count":"7","poster":"ParagSanyashiv"},{"timestamp":"1718957340.0","comment_id":"752122","poster":"zellck","upvote_count":"1","content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent\nThe Ops Agent is the primary agent for collecting telemetry from your Compute Engine instances. Combining logging and metrics into a single agent, the Ops Agent uses Fluent Bit for logs, which supports high-throughput logging, and the OpenTelemetry Collector for metrics.\n\nYou can configure the Ops Agent to support parsing of log files from third-party applications."},{"comment_id":"649272","upvote_count":"4","poster":"tomato123","content":"Selected Answer: B\nB is correct","timestamp":"1708416240.0"}],"isMC":true,"question_images":[],"answers_community":["B (100%)"],"topic":"1","unix_timestamp":1641710880,"choices":{"C":"Install a Google version of collectd on the Compute Engine instance.","A":"Pipe the content of the files to the Linux Syslog daemon.","D":"Using cron, schedule a job to copy the log files to Cloud Storage once a day.","B":"Install a Google version of fluentd on the Compute Engine instance."}}],"exam":{"lastUpdated":"11 Apr 2025","isBeta":false,"name":"Professional Cloud Developer","id":7,"isMCOnly":false,"isImplemented":true,"provider":"Google","numberOfQuestions":338},"currentPage":1},"__N_SSP":true}