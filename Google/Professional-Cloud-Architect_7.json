{"pageProps":{"questions":[{"id":"pwVeEHtK2e7QsVmTs7R5","answers_community":["C (97%)","3%"],"answer":"C","discussion":[{"timestamp":"1641030300.0","comment_id":"395666","poster":"TotoroChina","upvote_count":"46","content":"Answer should be C, obviously."},{"upvote_count":"43","poster":"AdGlad","comment_id":"408217","timestamp":"1642397040.0","content":"Questions say \"relevant microservice will be deployed automatically in the development environment.\" Therefore A and B are out. D says \"Rely on Vulnerability Scanning to ensure the code tests succeed.\" Vulnerability Scanning is not test so D is out. The correct Answer is therefore C."},{"timestamp":"1743475020.0","poster":"Abhi_ma_cdl_22","comment_id":"1415803","content":"Selected Answer: C\nBy elimination process, the correct answer is C","upvote_count":"1"},{"comment_id":"1336252","poster":"plumbig11","content":"Selected Answer: C\nCreate a Cloud Build trigger based on the development branch that tests the code, builds the container, and stores it in Container Registry. Create a deployment pipeline that watches for new images and deploys the new image on the development cluster. Ensure only the deployment tool has access to deploy new versions.","timestamp":"1735966860.0","upvote_count":"1"},{"poster":"de1001c","comment_id":"1226170","upvote_count":"2","content":"Selected Answer: C\nAutomatic, no developer running stuff, plus relying in pre-commit hooks alone is not a CD strategy. The C over D is because the pipeline in cloudbuild should run the tests, not the Vulnerability Scanner. While vulnerability scanner is useful, it's not required in this context, and there're no tests run in answer D.","timestamp":"1733586960.0"},{"poster":"Gino17m","upvote_count":"1","content":"Automatic deployment required in the question and manual deployment by developer in answer marked as correct !\nAnce again....Who is responsible for marking answers as correct on examtopics platform ? Enyone from examtopics read responses from community and correct wrong answers ???\nA few days after purchasing full access to this platform, I am disgusted :(","comments":[{"poster":"ccpmad","timestamp":"1733660400.0","upvote_count":"1","content":"Do not be angry. That the answers are incorrect is on purpose. First so that the pdf is not shared and they are left without business. And secondly so that Google does not change the questions because then there are no correct answers filtered.","comment_id":"1226673"}],"comment_id":"1201449","timestamp":"1729780560.0"},{"upvote_count":"1","poster":"Gall","content":"Selected Answer: C\nC but.... \"build container and add to the registry\" ???? Not container but image.","comment_id":"1150484","timestamp":"1723660020.0"},{"content":"Selected Answer: C\nNah, no way to be A.","upvote_count":"1","comment_id":"1119676","poster":"convers39","timestamp":"1720691940.0"},{"comment_id":"1113104","content":"The correct answer is C.","poster":"AWS_Sam","timestamp":"1720031460.0","upvote_count":"1"},{"comment_id":"1026696","upvote_count":"1","poster":"AdityaGupta","content":"Selected Answer: C\nAgreed with omermahgoub\nAnswer should be C.","timestamp":"1712412240.0"},{"comment_id":"857500","poster":"balajisreenivas","content":"Selected Answer: C\nBy elimination method, the answer is C.","timestamp":"1696122240.0","upvote_count":"1"},{"poster":"kopasz93","timestamp":"1695801000.0","comment_id":"851890","upvote_count":"1","content":"Selected Answer: C\nThe answer is C."},{"content":"Selected Answer: C\nClearly C","poster":"Dr_Ramzus","upvote_count":"1","comment_id":"791509","timestamp":"1690615620.0"},{"poster":"omermahgoub","content":"The correct answer is C: Create a Cloud Build trigger based on the development branch that tests the code, builds the container, and stores it in Container Registry. Create a deployment pipeline that watches for new images and deploys the new image on the development cluster. Ensure only the deployment tool has access to deploy new versions.\n\nTo automate the build and deployment process for your microservices in the development environment, you can use Cloud Build to set up a trigger that listens for code pushes to the development branch on your GitHub repository. When a code change is pushed to the branch, Cloud Build can test the code, build the container image, and store it in Container Registry. You can then create a deployment pipeline that watches for new images in Container Registry and deploys them automatically on the development cluster. To ensure that only code that has been properly tested and built is deployed in the development environment, you should ensure that only the deployment tool has access to deploy new versions.","upvote_count":"8","comments":[{"timestamp":"1687676880.0","poster":"omermahgoub","content":"Option A is incorrect because installing a pre-commit hook on each developer's workstation does not ensure that the build and test process is followed consistently for all code changes. It also does not provide a centralized way to track the deployments in the development environment.\n\nOption B is incorrect for the same reason. A post-commit hook on the remote repository does not provide a centralized way to manage the build and deployment process for all code changes in the development environment.\n\nOption D is incorrect because relying on Vulnerability Scanning alone is not sufficient to ensure that the code changes are properly tested and built before being deployed in the development environment. A more comprehensive build and test process, such as the one described in option C, is recommended to ensure the quality and reliability of the code being deployed.","upvote_count":"3","comment_id":"755536"}],"timestamp":"1687676880.0","comment_id":"755535"},{"timestamp":"1687403340.0","upvote_count":"1","comment_id":"752974","poster":"madmike123","content":"Selected Answer: C\n\"any code change that has been pushed to the remote develop branch on your GitHub repository should be built\"...this excludes A and B since both happen locally before a push.\nAnswer 'D' only performs security scanning (no test) and is not automatically deployed which is what was requested."},{"poster":"megumin","comment_id":"717837","timestamp":"1684047840.0","upvote_count":"1","content":"Selected Answer: C\nC is ok"},{"poster":"minmin2020","content":"Selected Answer: C\nC. Create a Cloud Build trigger based on the development branch that tests the code, builds the container, and stores it in Container Registry. Create a deployment pipeline that watches for new images and deploys the new image on the development cluster. Ensure only the deployment tool has access to deploy new versions.","timestamp":"1681737000.0","comment_id":"697416","upvote_count":"1"},{"content":"Selected Answer: D\nC doesn't include test success. D should be the option.","poster":"Amit_arch","upvote_count":"1","comment_id":"670250","timestamp":"1678914900.0","comments":[{"timestamp":"1679115360.0","poster":"zellck","upvote_count":"1","content":"Vulnerability Scanning is not relevant though for the question.","comment_id":"671945"},{"upvote_count":"1","comment_id":"697859","timestamp":"1681790520.0","content":"It does include tests succuss, the question is using CI/CD","poster":"zr79"}]},{"upvote_count":"2","timestamp":"1675332840.0","comment_id":"641161","poster":"shayke","content":"Selected Answer: C\nC- the only answer"},{"poster":"gardislan18","comment_id":"635895","upvote_count":"3","content":"Selected Answer: C\nThe answer should be C, we eliminate A and B because we should use Cloud Build trigger instead, now we eliminate D because the deployment step is done manually and the requirement says automatically\n\nSo answer is C, it leverages Cloud Build trigger, tests the code, and uses deployment pipeline","timestamp":"1674548220.0"},{"poster":"AzureDP900","timestamp":"1672762620.0","upvote_count":"2","content":"C is right","comment_id":"626583"},{"comment_id":"622377","poster":"GPK","upvote_count":"6","timestamp":"1672042260.0","content":"25/06/2022 , C is correct"},{"comment_id":"608522","timestamp":"1669673340.0","upvote_count":"1","poster":"Superr","content":"Selected Answer: C\nC fulfils all requirements"},{"content":"Go for C","upvote_count":"1","poster":"gaojun","comment_id":"584189","timestamp":"1665492840.0"},{"content":"Selected Answer: C\nYes C is the correct one","poster":"ss909098","timestamp":"1662407100.0","comment_id":"561666","upvote_count":"3"},{"content":"2/15/21 exam passed","comment_id":"548051","poster":"azureaspirant","comments":[{"content":"very helpful","comment_id":"570024","poster":"vikki_625","timestamp":"1663434660.0","upvote_count":"2"}],"upvote_count":"4","timestamp":"1660591140.0"},{"upvote_count":"3","content":"Selected Answer: C\nI got similar question on my exam. Answered C.","poster":"[Removed]","timestamp":"1660243500.0","comment_id":"545503"},{"content":"Pipeline is keyword","comment_id":"520362","poster":"sriandy","timestamp":"1657379940.0","upvote_count":"2"},{"poster":"OrangeTiger","content":"Can anyone please tell me why D is different?\nThe test is done with Vulnerability Scanning.\nDo other steps with Cloud Build.","timestamp":"1657250940.0","upvote_count":"2","comment_id":"519329","comments":[{"content":"Vulnerability scaNning does not functionally test the code.","comment_id":"713570","timestamp":"1683524280.0","poster":"BiddlyBdoyng","upvote_count":"1"}]},{"upvote_count":"1","poster":"GauravLahoti","content":"Correct Answer is C","timestamp":"1656519060.0","comment_id":"512536"},{"comment_id":"505364","upvote_count":"1","poster":"zaxxon","timestamp":"1655715960.0","content":"for all those people answering C: how can Cloud build \"tested automatically\"? Please explain!"},{"content":"C is correct answer.","poster":"rajadhav","comment_id":"501015","upvote_count":"1","timestamp":"1655168100.0"},{"comment_id":"500127","upvote_count":"2","timestamp":"1655046900.0","poster":"PhilipKoku","content":"Selected Answer: C\nC) It is the best answer and it test the changes and automatically build the container and pushes it using CI/CD."},{"content":"Selected Answer: C\nC is the correct answer","poster":"vincy2202","comment_id":"493665","upvote_count":"1","timestamp":"1654333560.0"},{"comment_id":"490732","timestamp":"1653911820.0","upvote_count":"1","content":"It's C -- however a container is not directly \"stored\" in Container Registry, you upload \"images\", not \"container\",\nI think is a mispelling, because, textually from GCP doc:\n\nYou use the Docker build command to build the container. \nThis builds the container and stores it locally as a runnable image. \nYou can save and upload the image into a container registry service","poster":"jdr75"},{"timestamp":"1653866040.0","upvote_count":"1","content":"Selected Answer: C\nAutomatically !","poster":"cdcollector","comment_id":"490314"},{"comment_id":"486980","timestamp":"1653514080.0","content":"Selected Answer: C\nvote C","poster":"joe2211","upvote_count":"3"},{"upvote_count":"2","content":"Selected Answer: C\nC should be the answer here","comment_id":"483036","poster":"pakilodi","timestamp":"1653106020.0"},{"poster":"robotgeek","content":"Guys you never \"Build a container\" C is not right","comments":[{"timestamp":"1653106080.0","upvote_count":"3","comment_id":"483037","content":"i've used to build Docker container with cloud Build. so it is a Best Practice. A is totaly wrong here, based on the context of the answer","poster":"pakilodi"}],"comment_id":"476266","timestamp":"1652270760.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1651573440.0","poster":"pakilodi","content":"should be C? it says automatic deploy....","comment_id":"472058"},{"poster":"SuperCloud","content":"C seems appropriate, as it's an automatic deployment.","comment_id":"455274","timestamp":"1648785540.0","upvote_count":"2"},{"content":"C is correct. Need to develop CICD pipeline for this.","comment_id":"454216","timestamp":"1648563660.0","upvote_count":"2","poster":"AnilKr"},{"upvote_count":"1","timestamp":"1647974820.0","content":"How can it be A? Needs automatic deployment , A doesn't provide that. C looks fine.","comment_id":"449641","poster":"Ari_GCP"},{"timestamp":"1646667180.0","comment_id":"440940","upvote_count":"3","poster":"aa_desh","content":"Confusion for \"C\", Can we able to store the container in Container Registry, Instead of Container Image, I think we only store Container Image in Container Registry\nhttps://cloud.google.com/container-registry/docs/overview"},{"timestamp":"1646334960.0","upvote_count":"1","poster":"[Removed]","content":"A is not a right answer. I go with C.","comment_id":"438635"},{"upvote_count":"7","timestamp":"1642531200.0","comment_id":"409062","poster":"PeppaPig","content":"C addressed the two essential parts of CI/CD. First, It created a CI pipeline to use Cloud Build to compile, test and build images. Second, it set up a CD pipeline to watch the update of new image and deploy the changes to prod environment."},{"content":"C is correct 100%","upvote_count":"6","poster":"PeppaPig","timestamp":"1642530840.0","comment_id":"409058"},{"poster":"victory108","comment_id":"403986","timestamp":"1641913320.0","content":"C. Create a Cloud Build trigger based on the development branch that tests the code, builds the container, and stores it in Container Registry. Create a deployment pipeline that watches for new images and deploys the new image on the development cluster. Ensure only the deployment tool has access to deploy new versions.","upvote_count":"3"},{"poster":"taoj","content":"would like to choose C. as the GCP document has no statements about vulnerability scanning can test code.","upvote_count":"1","comment_id":"403586","timestamp":"1641868080.0"},{"comment_id":"401664","content":"Answer is A","poster":"MamthaSJ","timestamp":"1641636600.0","upvote_count":"2"},{"timestamp":"1641579660.0","upvote_count":"1","content":"Triggers works on GitHub instead of Cloud Source Repositories??","comment_id":"401068","poster":"DiegoMDZ"},{"timestamp":"1641565020.0","content":"I tkink C beacuse test the code before creating the image (as opposed to D)","comment_id":"400852","upvote_count":"2","poster":"dguillenca"},{"timestamp":"1641543900.0","poster":"JeffClarke111","upvote_count":"2","content":"C is ok","comment_id":"400544"},{"content":"Should be C) as in D only the vulnerabilites are scanned but there should be a complete set of tests","comment_id":"395992","timestamp":"1641049800.0","upvote_count":"6","poster":"Irbis"},{"upvote_count":"7","comment_id":"395664","poster":"XDevX","content":"IMHO c) is the correct answer, not a).\nRequirement is: once code is in GitHub, built, testing and deployment shall be performed automatically.\nSee: IMHO c) is the correct answer, not a) \nhow google suggests to realize that:\nhttps://codelabs.developers.google.com/codelabs/cloud-builder-gke-continuous-deploy#0","timestamp":"1641030120.0"},{"upvote_count":"3","comment_id":"395654","comments":[{"timestamp":"1652354040.0","content":"Seems C makes more sense D is not a test environment, A and B relies on developer's workstations and C aligns with: \nhttps://cloud.google.com/kubernetes-engine/docs/tutorials/gitops-cloud-build\n\n\n Create Git repositories in Cloud Source Repositories.\n Create a container image with Cloud Build and store it in Container Registry.\n Create a CI pipeline.\n Create a CD pipeline.\n Test the CI/CD pipeline.","comment_id":"476945","upvote_count":"1","poster":"The_Dave_Mty"},{"upvote_count":"3","comment_id":"404130","content":"D does not say anything about testing where as C emphases on testing and then pushing it to cloud registry so C is correct answer","poster":"VishalB","timestamp":"1641926100.0"},{"timestamp":"1646557620.0","upvote_count":"1","comments":[{"content":"This is still used for Jenkins and other pipelines. This is an old way of doing work.","upvote_count":"1","poster":"amxexam","timestamp":"1646557680.0","comment_id":"440166"}],"poster":"amxexam","content":"B is one-time intervention","comment_id":"440165"}],"poster":"Enzian","timestamp":"1641029640.0","content":"A and B are wrong b/c they require manual intervention by the developer. C and D could be equally correct, but looking at https://cloud.google.com/kubernetes-engine/docs/tutorials/gitops-cloud-build I would suggest that D is the better choice."}],"question_text":"Your team will start developing a new application using microservices architecture on Kubernetes Engine. As part of the development lifecycle, any code change that has been pushed to the remote develop branch on your GitHub repository should be built and tested automatically. When the build and test are successful, the relevant microservice will be deployed automatically in the development environment. You want to ensure that all code deployed in the development environment follows this process. What should you do?","isMC":true,"topic":"1","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/56702-exam-professional-cloud-architect-topic-1-question-126/","answer_description":"","exam_id":4,"answer_ET":"C","choices":{"B":"Install a post-commit hook on the remote git repository that tests the code and builds the container when code is pushed to the development branch. After a successful commit, have the developer deploy the newly built container image on the development cluster.","A":"Have each developer install a pre-commit hook on their workstation that tests the code and builds the container when committing on the development branch. After a successful commit, have the developer deploy the newly built container image on the development cluster.","D":"Create a Cloud Build trigger based on the development branch to build a new container image and store it in Container Registry. Rely on Vulnerability Scanning to ensure the code tests succeed. As the final step of the Cloud Build process, deploy the new container image on the development cluster. Ensure only Cloud Build has access to deploy new versions.","C":"Create a Cloud Build trigger based on the development branch that tests the code, builds the container, and stores it in Container Registry. Create a deployment pipeline that watches for new images and deploys the new image on the development cluster. Ensure only the deployment tool has access to deploy new versions."},"unix_timestamp":1625124840,"question_id":31,"answer_images":[],"timestamp":"2021-07-01 09:34:00"},{"id":"0UJ90FKm9S0SQsvv5e1b","answer":"D","unix_timestamp":1625110020,"answer_images":[],"topic":"1","question_text":"Your operations team has asked you to help diagnose a performance issue in a production application that runs on Compute Engine. The application is dropping requests that reach it when under heavy load. The process list for affected instances shows a single application process that is consuming all available CPU, and autoscaling has reached the upper limit of instances. There is no abnormal load on any other related systems, including the database. You want to allow production traffic to be served again as quickly as possible. Which action should you recommend?","question_id":32,"url":"https://www.examtopics.com/discussions/google/view/56603-exam-professional-cloud-architect-topic-1-question-127/","choices":{"D":"Increase the maximum number of instances in the autoscaling group.","B":"Restart the affected instances on a staggered schedule.","A":"Change the autoscaling metric to agent.googleapis.com/memory/percent_used.","C":"SSH to each instance and restart the application process."},"answers_community":["D (86%)","10%"],"answer_description":"","answer_ET":"D","timestamp":"2021-07-01 05:27:00","exam_id":4,"isMC":true,"discussion":[{"timestamp":"1641031620.0","upvote_count":"44","comment_id":"395685","content":"Answer should be D.\nI doubt it is intended to provide wrong answer.","comments":[{"timestamp":"1643408880.0","upvote_count":"9","comment_id":"416461","content":"Agree. \n\nCannot be A), since changing the metric used for autoscaling will not solve the issue, the CPU is already over utilized, hence the unique \"workaround\" meanwhile the application causing the issue is fixed (connection leaks, infinite loops, etc.) is to allow introducing new nodes/workers/VMs.","poster":"poseidon24"},{"comment_id":"435205","comments":[{"content":"to prevent us from memorizing the answers and hopefully, the site can not be shut down","poster":"zr79","comments":[{"upvote_count":"2","comment_id":"1101158","timestamp":"1718845260.0","content":"Yes I always consider this to be the reason behind so many obviously wrong answers too... but who knows","poster":"Action"}],"timestamp":"1681790700.0","comment_id":"697864","upvote_count":"10"}],"upvote_count":"15","timestamp":"1646039700.0","poster":"victorlie","content":"why almost all answers are wrong?"}],"poster":"TotoroChina"},{"upvote_count":"12","poster":"MamthaSJ","timestamp":"1641636780.0","content":"Answer is D","comment_id":"401670"},{"comment_id":"1113111","content":"The question is not asking for a permanent solution to the problem, it is asking what to do to have the production traffic to be served again as quickly as possible. Therefore, the best answer is D.","poster":"AWS_Sam","upvote_count":"4","timestamp":"1720032300.0"},{"comment_id":"1074106","content":"Selected Answer: D\nAnswer D is correct.\nPrioritize the availability on production environment.","poster":"odacir","upvote_count":"2","timestamp":"1716038460.0"},{"upvote_count":"5","poster":"[Removed]","timestamp":"1708811580.0","content":"Selected Answer: D\nit says \"autoscaling has reached the upper limit of instances\" and there are no abnormal errors... so the upper limit for autoscaling has to be increased.","comment_id":"989460"},{"comment_id":"954078","upvote_count":"1","timestamp":"1705493880.0","content":"Selected Answer: D\nIncrease the maximum number of instances in the autoscaling group","poster":"gary_cooper"},{"poster":"red_panda","upvote_count":"1","timestamp":"1702221720.0","content":"Selected Answer: D\nAnswer D is correct.\nIn order to prioritize the availability on production environment (as per question), first we need to increase the number of max instances in the instance group, then, for sure we can investigate and restart application process.\nBe careful, often the answer is in the question","comment_id":"920091"},{"poster":"grejao","timestamp":"1696268400.0","upvote_count":"9","content":"I choose for A, but D is the best choice. \n\nThe trick is: \"process that is consuming all available CPU\" and \"autoscaling has reached the upper limit of instances\"\nIf the process is consuming all available CPU, we need to reconfigure our metrics for best tresholds (Option A)\nAND\nif the autoscaling reached the upper limit of instances, so we need to increase this limit (Option D), \n\n\nBUT, after reached the upper limit of instances, it doesn't matter the tresholds, the process will consume all resources that have available. So, option D is the best option.","comments":[{"upvote_count":"2","timestamp":"1699536240.0","poster":"Sur_Nikki","comment_id":"893046","content":"Loved the way you made us travel through the roots of the question"}],"comment_id":"859184"},{"poster":"CGS22","upvote_count":"6","comment_id":"833916","timestamp":"1694252940.0","content":"Selected Answer: D\nThe application is dropping requests because the available CPU is exhausted. Autoscaling has reached the upper limit of instances, so it cannot increase the number of instances to meet the demand. The best way to allow production traffic to be served again is to increase the maximum number of instances in the autoscaling group.\n\nThis will allow autoscaling to increase the number of instances to meet the demand without exhausting the available CPU. Restarting the affected instances or SSHing to each instance and restarting the application process will not solve the problem because the root cause is that there are not enough instances to meet the demand."},{"timestamp":"1687677000.0","comments":[{"upvote_count":"4","timestamp":"1687677000.0","comment_id":"755538","poster":"omermahgoub","content":"Option A is incorrect because changing the autoscaling metric to agent.googleapis.com/memory/percent_used will not address the root cause of the performance issue. The issue is related to CPU utilization, not memory usage.\n\nOption B is incorrect because restarting the affected instances on a staggered schedule will not address the root cause of the performance issue. It may provide temporary relief, but the issue is likely to recur once the instances are under heavy load again.\n\nOption C is incorrect because restarting the application process on each instance will not address the root cause of the performance issue. It may provide temporary relief, but the issue is likely to recur once the instances are under heavy load again. Increasing the maximum number of instances in the autoscaling group is a more effective solution in this case."}],"comment_id":"755537","content":"The correct answer is D: Increase the maximum number of instances in the autoscaling group.\n\nIf the application is dropping requests under heavy load and the process list for affected instances shows a single application process consuming all available CPU, increasing the maximum number of instances in the autoscaling group may help to alleviate the performance issue. By adding more instances to the group, you can distribute the load across multiple instances, which should help to reduce the strain on any single instance. This will allow production traffic to be served again more quickly.","upvote_count":"7","poster":"omermahgoub"},{"content":"Selected Answer: B\nGiven the is not no abnormal load, autoscaling will is not required, restarting should kill the single application process consuming excess CPU","comment_id":"745592","upvote_count":"1","timestamp":"1686784860.0","poster":"SureshbabuK"},{"poster":"surajkrishnamurthy","timestamp":"1686728340.0","upvote_count":"1","comment_id":"744939","content":"Selected Answer: D\nD is the correct answer"},{"timestamp":"1686077760.0","content":"The keyword is \"You want to allow production traffic to be served again as quickly as possible\" so D should be the only answer so as to resume production traffic and then you can do a root cause analysis and take further action depending upon the findings.","poster":"sanait100","upvote_count":"2","comment_id":"737216"},{"content":"Selected Answer: D\nD is ok","poster":"megumin","upvote_count":"1","timestamp":"1684048200.0","comment_id":"717838"},{"content":"Selected Answer: D\nIt all depends on how you want to troubleshoot the issue. Do you want to check the application before or after increasing the max number of instances in the scaling group. I guess in real life people will ask for an increase in the max number of instances and if the application process continues to consume all the CPU then they will probably stop/restart the app. \nD is the only sensible option.\nA is not an option\nB you could restart but you dont know if that will fix the issue\nC SSH assumes unix vm's (?)....!","comment_id":"697425","comments":[{"upvote_count":"2","comment_id":"698618","content":"autoscaling has reached the upper limit of instances. There is no abnormal load on any other related systems, including the database. This so junk question, only D seems viable option.","timestamp":"1681870560.0","poster":"AzureDP900"}],"timestamp":"1681737660.0","poster":"minmin2020","upvote_count":"3"},{"comment_id":"661920","content":"Selected Answer: D\nI feel increasing the autoscale limit seems to be the logical answer","poster":"Jay_Krish","timestamp":"1678167120.0","upvote_count":"3"},{"timestamp":"1676310060.0","comment_id":"646384","content":"Selected Answer: D\nD seems to be least wrong","poster":"ijazahmad722","upvote_count":"1"},{"timestamp":"1672762860.0","content":"Answer is D","poster":"AzureDP900","upvote_count":"1","comment_id":"626587"},{"comment_id":"622378","timestamp":"1672042380.0","poster":"GPK","content":"exam 25/6/2022 .. agree its D","upvote_count":"8"},{"poster":"amxexam","content":"Selected Answer: D\nAnswered below. typo clearly *","timestamp":"1668839160.0","comment_id":"603600","upvote_count":"1"},{"comment_id":"602888","content":"It should be D without any doubt, however practically if this is going to happen, then developer community first try B (restarting.. ).... jokes apart answer should be D.","timestamp":"1668689880.0","poster":"AmitAr","upvote_count":"3"},{"upvote_count":"1","comment_id":"599235","content":"Selected Answer: D\nThis is a 'kick the can down the road' and D is the least wrong.","timestamp":"1668027600.0","poster":"mi5key"},{"comment_id":"596970","poster":"ridyr","timestamp":"1667589240.0","content":"Selected Answer: D\nI'm not seeing anything referencing using memory metrics to gauge high cpu utilization. That's the apples to oranges concept. Nothing is mentioned of memory consumption being an issue. But since \"autoscaling has reached the upper limit of instances\", increasing instances in group would alleviate that problem(group maxed out). Possible not the high cpu, but would distribute the work over more instances, which directly adds more CPU power. Don't think this would cover googles \"site reliability engineering\" but does allow production traffic to be served again until root cause can be determined.","upvote_count":"1"},{"timestamp":"1665761580.0","comments":[{"comment_id":"585876","timestamp":"1665761640.0","content":"not mem leak since CPU, zombie processes, deadlocks, etc","upvote_count":"1","poster":"learner311"}],"comment_id":"585875","upvote_count":"1","content":"need more instances. textbook case of the application needing to scale. D.\nRestarting the application is silly because it's just going to run into the same problem over and over. The only time that would make sense is if this question commented about investigating a memory leak etc which it does not. Scale up, reduce load.","poster":"learner311"},{"poster":"gaojun","timestamp":"1665493020.0","upvote_count":"1","content":"Vote D, \"autoscaling has reached the upper limit of instances\"","comment_id":"584190"},{"upvote_count":"1","content":"The last sentence says: you want to production works as quickly as possible. D makes sense.","comment_id":"546593","timestamp":"1660402560.0","poster":"GARY1119"},{"timestamp":"1658837280.0","content":"Selected Answer: D\nvote D","upvote_count":"2","comment_id":"532938","poster":"Pime13"},{"content":"Selected Answer: D\nd is correct","poster":"ks100","comment_id":"528606","timestamp":"1658329740.0","upvote_count":"1"},{"poster":"Andre777","upvote_count":"3","timestamp":"1657599180.0","content":"I think it is C. in D there is already statement autoscaling has reached the upper limit of instances. it will not change anything.","comment_id":"521934"},{"comment_id":"521083","timestamp":"1657474320.0","content":"Selected Answer: C\n[Not A] -> A change to AutoScaling metric will make no difference as the ASG's max size is already reached\n[Not B] -> Restarting instances in an ASG will likely cause the ASG to replace those instances (due to healthcheck failures)\n[Correct, C] -> We know that the application is hogging all the CPU. Restarting the application on the VMs will allow immediate resumption of production traffic.\n[Not D]: Increasing ASG's max size will not help because requests my still end up on affected VMs","comments":[{"poster":"9xnine","content":"SSH'ing into the VM and restarting the process does not permanently (if at all) resolve the issue. Adding additional instances will balance the load across more instances rather than continuing consume all available CPU on existing instances.","timestamp":"1670046720.0","comment_id":"610888","upvote_count":"1"}],"poster":"nymets","upvote_count":"2"},{"poster":"OrangeTiger","comment_id":"519332","upvote_count":"1","content":"I think D is correct.In order to be able to reprocess traffic quickly, it would be correct to launch a new instance.\n\nBut perhaps CPU-hungry application issues also occur with new instances.\nNeed B or C to fundamentally solve your application's problems. It takes time to troubleshoot.\nI think it's better to do B or C while earning time with D. The question is a little weird.\n\nA:Changing the metric avoids the problem of eating up the maximum number of instance groups, but it doesn't solve the high CPU load, so traffic can't be resumed.","timestamp":"1657251780.0"},{"poster":"GauravLahoti","upvote_count":"1","timestamp":"1656515580.0","comment_id":"512477","content":"Selected Answer: D\nCorrect Answer is D"},{"content":"Selected Answer: D\nD is correct, because A could not be correct. It is clearly mentioned that this is a cpu issue not memory issue.","poster":"BattleSlim","timestamp":"1656463740.0","comment_id":"511727","upvote_count":"3"},{"poster":"sunil55sunil","content":"Selected Answer: B\nTo restore services asap","comment_id":"507690","timestamp":"1655968560.0","upvote_count":"1"},{"comment_id":"501036","timestamp":"1655169900.0","upvote_count":"2","poster":"rajadhav","content":"Autoscaling already reached upper limit, adding memory based metrics won`t solve problem. Increasing number of instances will work.\nD is correct answer."},{"timestamp":"1655130300.0","upvote_count":"1","comment_id":"500725","poster":"SergioPitu","content":"Selected Answer: D\nAns is D"},{"comment_id":"500166","content":"Selected Answer: B\nB) You have to restart the instances with the issue in a staggered way.","timestamp":"1655052180.0","upvote_count":"3","poster":"PhilipKoku"},{"timestamp":"1654939080.0","content":"Selected Answer: D\nvote d as ans","upvote_count":"1","comment_id":"499361","poster":"duhhh"},{"upvote_count":"1","poster":"[Removed]","content":"Selected Answer: D\nD is answer.","timestamp":"1654674420.0","comment_id":"496703"},{"upvote_count":"1","comment_id":"493672","poster":"vincy2202","content":"D is the correct answer","timestamp":"1654335300.0"},{"timestamp":"1654179240.0","content":"Selected Answer: D\nWhy is D? because the memory metric will not trigger a scale out. Because here the scaling metric is the CPU. But, if the CPU of the instances is full, should mean that the maximum number of scailng is reached because it can't scale anymore. So, the only answer here is to add another node/vm","comment_id":"492664","upvote_count":"3","poster":"pakilodi"},{"upvote_count":"5","comment_id":"490747","poster":"jdr75","timestamp":"1653912600.0","content":"B. Restart the affected instances on a staggered schedule.\nRemember: production traffic to be served again as quickly as possible\nWhy a lot of answers are incorrect??","comments":[{"content":"a comment: adding a node to the Group is not the solution; requests still will go to the compromised nodes, and, possibly request will be lost. You've to restart all the nodes (stagered to no impact in unavailability)","upvote_count":"2","timestamp":"1653912900.0","comment_id":"490751","poster":"jdr75"}]},{"upvote_count":"2","comment_id":"487902","timestamp":"1653627240.0","poster":"nqthien041292","content":"Selected Answer: D\nVote D"},{"comment_id":"485103","timestamp":"1653310320.0","poster":"dmc123","content":"I think the problem is with the CPU utilisation and not the percentage of memory used.","upvote_count":"1"},{"poster":"DMC1163","content":"A is clearly wrong. Answer should be D. \nWeird...many of the previous 8 to 10 answers are questionable.","upvote_count":"1","comment_id":"484504","timestamp":"1653240120.0"},{"upvote_count":"1","poster":"nehaxlpb","content":"Answer is D, i don't why people are getting confuse the CPU is fully utilized and auto scaling limit is reached , then only option is to increase number of nodes. How changing the matrix will help??","timestamp":"1653029520.0","comment_id":"482354"},{"poster":"ThomasChoy","comments":[{"content":"That doesn't change the fact that the application is consuming all available CPU which is causing the issues, so A cannot be the solution.","comment_id":"497435","poster":"Bert_77","timestamp":"1654755360.0","upvote_count":"2"}],"content":"Try to explain why A is the correct answer. The question is asking for diagnose of problem, and after investigation the reason of performance issue is \"a single application process that is consuming all available CPU\" which is common for legacy application, therefore, to cope with such situation, changing the metric from CPU to Memory or Disk I/O is reasonable to avoid unnecessary scaling. As a result, A is the best answer.","timestamp":"1652941200.0","upvote_count":"3","comment_id":"481491"},{"comment_id":"465546","poster":"danielfootc","timestamp":"1650517800.0","content":"IMHO, it should be A as we are being asked to diagnose the problem, not providing the solution.","upvote_count":"2"},{"upvote_count":"2","timestamp":"1648896660.0","comments":[{"upvote_count":"1","poster":"[Removed]","comments":[{"timestamp":"1653650700.0","poster":"pakilodi","upvote_count":"1","content":"think that autoscale limit is reached. they are on Compute Engine. Maybe they don't want to provision another VMs.....that's why they say that autoscale limit is reached IMHO.","comment_id":"488162"}],"content":"D is correct option. It makes more sense than of A","comment_id":"475128","timestamp":"1652133120.0"},{"content":"Think for a second. Since autoscaling limit is reached, what would change of the autoscaling metric do? Only option is to increase the limit of your autoscaling - for a quick fix. Therefore answer D.","poster":"cotam","timestamp":"1650188580.0","upvote_count":"1","comment_id":"463495"},{"poster":"cotam","content":"Think for a second. Since autoscaling limit is reached, what would change of the autoscaling metric do? Only option is to increase the autoscaling metric, for a quick fix.","timestamp":"1650188460.0","comment_id":"463493","upvote_count":"1"}],"poster":"[Removed]","content":"A is right. D is not option. Autoscaling and intances limit is reached.","comment_id":"456022"},{"poster":"gingerbeer","comment_id":"454759","content":"Vote for A\n\nB and D have problem with Bigtable throughput. According to documentation (https://cloud.google.com/bigtable/docs/performance#typical-workloads) one node SSD/HDD write can be up to 10,000 rows per second. That means to accomodate the 500,000 requests per second, we need at least 50 nodes which are a lot. Combined with the fact that Google recommends at least 2x capacity, there should be at least 100 nodes, which are too costly.\n\nBigquery streaming inserts can accomodate. \"Maximum rows per second per project in the us and eu multi-regions — 500,000\"\nhttps://cloud.google.com/bigquery/quotas#streaming_inserts","upvote_count":"1","timestamp":"1648622220.0","comments":[{"poster":"J19G","timestamp":"1650103380.0","content":"This belongs to the next question (128) and I think it might be wrong since in BigQuery streaming Each table is additionally limited to 100,000 rows per second.","comment_id":"463008","upvote_count":"1"}]},{"upvote_count":"1","content":"The answer is A - CPU is over-utilized but instances are not scaling up, which means the scaling is set on memory and not the CPU, so you need to update the instances to use memory percent use threshold for scaling and not the CPU.","poster":"BrijMohan08","timestamp":"1648431780.0","comment_id":"452949"},{"comment_id":"440186","poster":"JustJack21","timestamp":"1646559720.0","upvote_count":"3","content":"There should be a \"Not enough information\" choice in the answers :D \nJokes apart, \"restart everything\" and \"throw resources at the problem\" are the two options here. However, given that there are \"requests being dropped\" , assume that some existing users are connected and using the service. Restarting stuff will lead to the same situation soon enough + disrupt the existing connections. \nSo let's throw more resources at the problem! worst case we take it away if it doesn't work. \n\nD. Increase the maximum number of instances in the autoscaling group."},{"poster":"0ldman","content":"I think B. Restart in a staggered way. We could add more instances, but that would not stop the CPU hungry processes which may be causing other app or data issues. Additionally, there is no info in the Q about how many VMs are in the MiG or what the CPU threshold is for scaling. You may need to add a lot of VMs to the group in order to bring the average CPU down below the threshold. Also adding more VMs could be costly depending on VM size.","timestamp":"1645732560.0","upvote_count":"4","comment_id":"430940"},{"upvote_count":"1","poster":"MikeB19","timestamp":"1645352400.0","content":"They q says allow traffic to be served ASAP. agent.googleapis.com is used to collect metrics. How would this help serve traffic again?D is correct. Also the reference link has nothing to do with the q. It’s a best practice article for sap https://cloud.google.com/blog/products/sap-google-cloud/best-practices-for-sap-app-server-autoscaling-on-google-cloud","comment_id":"427980"},{"timestamp":"1643353560.0","poster":"hello_aws","upvote_count":"3","content":"go with D. Even restart is a good way by experience, but it's quiet not good for cloud solution.","comment_id":"415921"},{"timestamp":"1641913200.0","upvote_count":"3","content":"D. Increase the maximum number of instances in the autoscaling group.","comment_id":"403983","poster":"victory108"},{"comment_id":"401074","timestamp":"1641580080.0","poster":"DiegoMDZ","upvote_count":"1","content":"B or D. Restarting is the 99% first option for all problems... :-)"},{"content":"It is D","poster":"kopper2019","comment_id":"397213","upvote_count":"5","timestamp":"1641179520.0"},{"upvote_count":"4","poster":"XDevX","comment_id":"395431","comments":[{"poster":"XDevX","upvote_count":"2","timestamp":"1641153540.0","comment_id":"397100","content":"IMHO b) is correct"}],"content":"My understanding: \nWe have an application that runs on a managed instance group - autoscaling has reached the upper limit of instances, the application is under heavy load.\nNow our task is to solve somehow the problem.\n\nYou suggest to change autoscaling metric to percent_used of memory.\n\nIMHO that will not solve any problem - the application will still consume all available CPU, maybe autoscaling will release some of the instances which will not make it better.\n\nI am not sure which answer is the best, but IMHO we can exclude a.","timestamp":"1641014820.0"}],"question_images":[]},{"id":"DNpnQpSt4FFE7WY9ZcSN","isMC":true,"question_images":[],"question_text":"You are implementing the infrastructure for a web service on Google Cloud. The web service needs to receive and store the data from 500,000 requests per second. The data will be queried later in real time, based on exact matches of a known set of attributes. There will be periods where the web service will not receive any requests. The business wants to keep costs low. Which web service platform and database should you use for the application?","question_id":33,"topic":"1","timestamp":"2021-07-01 05:34:00","answer":"B","answer_ET":"B","url":"https://www.examtopics.com/discussions/google/view/56612-exam-professional-cloud-architect-topic-1-question-128/","answers_community":["B (62%)","D (36%)","3%"],"unix_timestamp":1625110440,"discussion":[{"upvote_count":"80","content":"Any correct answer must involve Cloud Bigtable over BigQuery since Bigtable is optimized for heavy write loads. That leaves B and D. I would suggest B b/c it is lower cost (\"The business wants to keep costs low\")","comments":[{"content":"B. Agree. Additionally data need to store now so use Bigtable as question is not for analysing or data Analytics etc","upvote_count":"4","poster":"AmitRBS","timestamp":"1653615960.0","comment_id":"607858"},{"poster":"zanfo","comment_id":"567540","content":"the correct is B","upvote_count":"2","timestamp":"1647249300.0"},{"upvote_count":"21","comments":[{"comment_id":"909982","poster":"Petya27","timestamp":"1685428560.0","upvote_count":"3","content":"Plus, we are talking about a predefined set of queries. For any predefined list of (simple) queries, we use Bigtable, and for any (complex) queries that we do not know ahead of time, we use BigQuery."}],"poster":"pakilodi","content":"Not only: occasionally there will be no requests. so Cloud Run will scale to zero","timestamp":"1639560600.0","comment_id":"502014"},{"timestamp":"1704223080.0","upvote_count":"1","comment_id":"1112178","poster":"kshlgpt","content":"But cloud run can't support 50,000 request per second. Even cloud run 2nd gen supports 1000 requests per second. B is eliminated.","comments":[{"timestamp":"1706153580.0","poster":"pancakes22","comment_id":"1131297","content":"That's incorrect. https://cloud.google.com/run/quotas","upvote_count":"3"}]}],"comment_id":"395665","poster":"Enzian","timestamp":"1625125500.0"},{"content":"B is correct answer.","timestamp":"1625630160.0","poster":"MamthaSJ","comment_id":"400452","upvote_count":"16"},{"poster":"Abhi_ma_cdl_22","timestamp":"1743475800.0","comment_id":"1415897","upvote_count":"1","content":"Selected Answer: B\nBigTable for heavy write loads\nCloud Run for low cost and scale down capability"},{"comment_id":"1270757","poster":"Armne96X","content":"Selected Answer: B\nCloud Run and Cloud Bigtable is the best choice because it meets all the requirements:\n\nCloud Run can scale automatically to handle 500,000 requests per second and scales to zero during periods of no requests, reducing costs. Cloud Bigtable is designed for real-time queries with exact match attributes. \n\nAutoscaling Managed Instance Group can not scale to zero during periods of no requests*","upvote_count":"2","timestamp":"1724338440.0"},{"poster":"afsarkhan","upvote_count":"1","content":"Selected Answer: D\nIt's hard for Cloud Run to scale to accept 500k rps so choosing Option D","comment_id":"1247481","timestamp":"1720901700.0"},{"poster":"yas_cloud","timestamp":"1709909820.0","content":"Not sure why this is voted between B and D. It should be A. \nMIG wont support, that rules out C and D.\nbetween BQ and BT, please see that \"data will be queried later in real time, based on exact matches of a known set of attributes\". This is supported by BQ alone. So I would go with A.","comment_id":"1168891","upvote_count":"1"},{"timestamp":"1708428000.0","comment_id":"1154654","upvote_count":"2","content":"Selected Answer: B\nB is correct","poster":"Tirthankar17"},{"poster":"the1dv","timestamp":"1705375440.0","upvote_count":"2","content":"Selected Answer: D\nCloud Run can handle this amount if there were like 500 instances which would cost a pretty ridiculous amount per minute, so unfortunately there isnt enough information in this question around how long the gaps are without data to make a proper decision.\n\nAutoscaling Managed Instance Groups can scale to zero and 500k per second would be relatively easily handled by a few instances.","comment_id":"1123828"},{"upvote_count":"4","content":"Selected Answer: B\n50,000 rps\nAt first I thought Cloud Run could not handle this request rate and then chose D. After a little bit of research on the docs I changed my mind to B. \n\nOn each instance concurrency, it clearly says\n\n> By default each Cloud Run instance can receive up to 80 requests at the same time; you can increase this to a maximum of 1000\n\nhttps://cloud.google.com/run/docs/about-concurrency\n\nThe maximum number of auto-scaling instances by default is 100, which can be configured depending on the regional quota. With the default max instances it can already handle 100 * 1000 = 100,000 requests concurrently, which should be able to achieve the 50,000 rps requirement.\n\nhttps://cloud.google.com/run/docs/about-instance-autoscaling","comments":[{"timestamp":"1720901640.0","upvote_count":"1","content":"question says it's 500k and not 50k rps","comment_id":"1247480","poster":"afsarkhan"}],"comment_id":"1119692","poster":"convers39","timestamp":"1704975360.0"},{"content":"Selected Answer: D\nCloud Run can't support 50,000 requests per second.\n\nCorrect answer should be D.","timestamp":"1704223200.0","upvote_count":"1","poster":"kshlgpt","comment_id":"1112182"},{"content":"Cloud Run can't handle 50,000 requests per second\nA & B is eliminated","timestamp":"1704222900.0","upvote_count":"1","poster":"kshlgpt","comment_id":"1112174"},{"comment_id":"1109872","upvote_count":"1","timestamp":"1703958600.0","poster":"wly_al","content":"Not receive any request = Cloud Run"},{"content":"Selected Answer: D\nAt first I through its B, but then I thought about the number of requests that will be over 1 minute, if we calculated it = 30 million request per minute, and based on cloud run pricing this will cost only for the number of requests: 24 USD. so cloud run will cost the company 24 USD / min. which might be a very costly option. \nBut in the cloud run pricing there is 2 modes: \n- CPU allocated when receiving requests: and there is a cost for CPU and requests\n- CPU always allocated: and there is only a cost for the CPU and zero price for the number of requests. \n\nI think we need someone experiencing the billing of a cloud run under a heavy load like this :)","upvote_count":"3","poster":"tamer_m_Saleh","comment_id":"1103953","timestamp":"1703325000.0"},{"comment_id":"1095470","upvote_count":"1","timestamp":"1702472520.0","poster":"Andoameda9","content":"Selected Answer: B\nApart from the reason that cloud run can scale to zero, another benefit in this scenario is the fact Cloud run will provide out of the box revision maintenance for the web service."},{"comment_id":"1074116","content":"Selected Answer: B\nCompute:\nCloud Run vs. Compute Engine autoscaling managed instance group\nCloud Run wins because can scale down up to 0 instances -> in Spike workflows will be cheaper.\nStorage:\nBigQuery vs. Big Table.\n500,000 requests per second it’s not suitable in BQ:\nhttps://cloud.google.com/bigquery/quotas\n“A user can make up to 100 API requests per second to an API method”\nSo answer most be B.","poster":"odacir","upvote_count":"1","timestamp":"1700321400.0"},{"content":"MIGs cannot scale the VMs to 0 as per https://cloud.google.com/compute/docs/autoscaler/scaling-cloud-monitoring-metrics#configure_utilization_target\nSo B is the answer.","comment_id":"1067908","upvote_count":"1","poster":"thewalker","timestamp":"1699714680.0"},{"upvote_count":"1","comment_id":"1041269","content":"Cloud Functions can also scale to 0. But I guess because it manageable scaling can be done faster on functions level","timestamp":"1697071920.0","poster":"DinRush"},{"timestamp":"1696601400.0","content":"Selected Answer: B\nAnswer should B, beasue \nData is no SQL data, real-time analysis needed. -> BigTable\nCloud Run will help in -> Low Cost (Zero when no event)","poster":"AdityaGupta","comment_id":"1026701","upvote_count":"1"},{"poster":"Frusci","upvote_count":"2","comment_id":"1004568","content":"Selected Answer: B\nB is the correct answer. Cloud Run will scale down to zero when there's not requests. As the data will be queried in real-time Big Table is appropriate.","timestamp":"1694422200.0"},{"timestamp":"1692949380.0","poster":"Rinku5005","comment_id":"989790","upvote_count":"1","content":"Selected Answer: B\noccasionally there will be no requests and bussiness wants to keep the cost low. B is the Right Choice"},{"content":"Selected Answer: B\nCloud run scales as per needs and bigtable is best for high throughput low latency use cases.","comment_id":"961982","upvote_count":"1","timestamp":"1690227120.0","poster":"capt2101akash"},{"timestamp":"1689515940.0","upvote_count":"1","poster":"kilo10x","comment_id":"953372","content":"option B- there wont be any request at times that gives Cloud Run as the answer and real time heavy writes gives Big Table"},{"content":"Answer is B. Here are the clues:\nHeavy writes = BigTable\nLow cost (scales to zero) = Cloud Run.\n\nBQ is ruled out because it's OLAP more for reads than write.","poster":"JohnWick2020","timestamp":"1685800020.0","upvote_count":"3","comment_id":"913617"},{"comment_id":"904711","timestamp":"1684828740.0","poster":"non_90919","comments":[{"comment_id":"919890","content":"BigQuery has a 100k read/s quota, I can't write the quota for writes but would be confident BigQuery cannot handle 500k/s. Bigtable is designed for such massive IO.","poster":"BiddlyBdoyng","timestamp":"1686383280.0","upvote_count":"3"}],"upvote_count":"1","content":"According to ChatGPT, \"Option B (Cloud Run and Cloud Bigtable) is not the optimal choice because Cloud Bigtable is a NoSQL wide-column database that is more suitable for handling large-scale, high-throughput analytical workloads rather than real-time querying based on exact matches.\" So everyone is just saying something different lol"},{"poster":"Fu7ed","comment_id":"893582","content":"Selected Answer: B\nThe problem is that I want a low cost, so I'll choose cloud run. Cloud run does not incur costs when not running, and auto scale is also possible. I will choose Bigtable because I need to handle a large amount of throughput. So the answer is D. Please let me know if there are any mistakes.","upvote_count":"1","timestamp":"1683691140.0","comments":[{"comment_id":"1114417","timestamp":"1704449220.0","content":"bigtable is ok for me, not bigquery.\nCloud RUN has limits. https://cloud.google.com/run/quotas?hl=it \n1000 cloud run instances, is the maximum number.\nwith 500000 request/sec. I have 500000/1000=500 request for instance \ncloud run has max number of parallel request per instance = 1000 so is ok\nbut max number of parallel data flows per instance = 100\nthe right answer is D","upvote_count":"1","poster":"salvo007"}]},{"comment_id":"857503","upvote_count":"1","timestamp":"1680311220.0","content":"Selected Answer: B\nB is correct since cost should be low.","poster":"balajisreenivas"},{"comment_id":"856601","upvote_count":"1","content":"Selected Answer: B\nBased on the requirements and constraints mentioned, the recommended web service platform and database for the application would be Cloud Run and Cloud Bigtable, option B.\n\nCloud Run is a serverless compute platform that allows for automatic scaling and provides a low-cost option for applications with unpredictable or variable traffic patterns. Cloud Bigtable is a NoSQL database that is designed for high-throughput, low-latency workloads and can handle large amounts of data. It is also fully managed, so it does not require significant administration overhead.","timestamp":"1680238080.0","poster":"JC0926"},{"upvote_count":"3","poster":"JC0926","comment_id":"845455","timestamp":"1679365920.0","content":"Selected Answer: B\nCloud Run is a serverless platform that allows you to run stateless containers on demand. It can scale quickly to handle a large number of requests and automatically scales down to zero when there are no requests, making it a cost-effective option.\n\nCloud Bigtable is a NoSQL database that is designed for handling massive amounts of data with low latency and high throughput. It can handle up to millions of operations per second, making it a suitable option for storing and querying the large volume of data generated by the web service."},{"timestamp":"1678416420.0","poster":"Deb2293","comment_id":"834576","content":"Selected Answer: B\nCloud Run can scale to 0 so should be B","upvote_count":"2"},{"timestamp":"1677646980.0","poster":"telp","comment_id":"825533","upvote_count":"2","content":"Selected Answer: B\nCloud run scale to 0 so reduce cost when no activity.\nBigtable to support the heavy write."},{"content":"MIG would not scale as fast as Run. With this high throughput I would rather use containerized solution instead of VMs as for each VM instance you are going to have a separate OS. So you may need more memory with GCE which does not support scale from 0.","poster":"segkhachat","upvote_count":"1","comment_id":"806413","timestamp":"1676211660.0","comments":[{"upvote_count":"1","timestamp":"1676211840.0","poster":"segkhachat","comment_id":"806421","content":"The only doubt I have is because of a mentioned 'infrastructure' keyword in the question."}]},{"comment_id":"790035","upvote_count":"10","content":"Selected Answer: D\nI will go with the option D.\nBoth Cloud Run and Cloud Compute can be used to solve the problem. But the main challenge is to handle 500,000 requests per secons. In case of Cloud Run the Maximum Number of instances are allowed to 100 and each cloud run container can handle maximum 1000 requests per seconds. So if we go with Cloud Run option we can maximum address 100,000 requests per second. In case of Compute Engine (with proper external load balancer) does not have these type of limitations. So D will be better option just due to number of requests.\n\nRef: https://cloud.google.com/run/docs/configuring/max-instances\nRef: https://cloud.google.com/run/docs/about-concurrency#:~:text=By%20default%20each%20Cloud%20Run,to%20a%20maximum%20of%201000.","timestamp":"1674856560.0","comments":[{"content":"https://cloud.google.com/run/docs/configuring/max-instances#limits\nFor instance using 1 CPU and 2GB memory, this maximum can be increased up to a limit of 1000 instances. The actual maximum limit depends on the region of the Cloud Run service and its CPU and memory configurations.\nIf you want to specify a maximum number of instances greater than the maximum allowed in the region of the Cloud Run service, you must request a quota increase.\nI think answer B is the correct one.","poster":"CosminCiuc","comment_id":"791978","comments":[{"upvote_count":"1","content":"Both B and D will address the requirement. For B you need to change Google limits and for D you can set the limit to yourself. I will go for the option that does not need any change at Google side.","poster":"gcppandit","comment_id":"793850","timestamp":"1675153860.0"}],"timestamp":"1675020000.0","upvote_count":"1"},{"timestamp":"1676945040.0","content":"Run can scale to 1,000 instances without requesting a quota increase. Each instance can handle up to 1,000 concurrent requests. 500,000/sec is half the maximum for Run. Run scales to zero.","upvote_count":"3","comment_id":"816107","poster":"nick_name_1"}],"poster":"gcppandit"},{"content":"Selected Answer: A\nAdditionally, \"based on exact matches of a known set of attributes\" points to Big Query. Bigtable is a key-value database.","comment_id":"759842","timestamp":"1672232280.0","upvote_count":"3","comments":[{"comment_id":"788017","upvote_count":"2","poster":"steghe","timestamp":"1674671940.0","content":"With BigTable you can build the key with the concatenation of the \"known set of attributes\" and so the exact value is found easily"},{"comment_id":"793853","upvote_count":"1","content":"BiqQuery can not handle 500,000 concurrent requests. So you have to go for either B and D. Both can be used with some configuration or change in limits.","poster":"gcppandit","timestamp":"1675154040.0"}],"poster":"skyblue07"},{"content":"Selected Answer: B\nMy reason for choosing Cloud Run? \"Cloud Run only runs when requests come in, so you don't pay for time spent idling\"\n\nhttps://dev.to/pcraig3/cloud-run-vs-app-engine-a-head-to-head-comparison-using-facts-and-science-1225","upvote_count":"2","comment_id":"758939","poster":"jay9114","timestamp":"1672167180.0"},{"comment_id":"755879","content":"Selected Answer: B\nCloud run is perfect to match high peak activity and scale to 0 to allow low cost when you don't need it.","timestamp":"1671990900.0","upvote_count":"1","poster":"thamaster"},{"timestamp":"1671960240.0","comment_id":"755551","content":"To handle 500,000 requests per second and store data that will be queried in real time based on exact matches of a known set of attributes, I would recommend using option D: A Compute Engine autoscaling managed instance group and Cloud Bigtable.\n\nCompute Engine autoscaling managed instance groups allow you to automatically increase or decrease the number of VM instances in a group based on workload demand. This can help ensure that your application has the resources it needs to handle high traffic periods, while minimizing costs during periods of low traffic.\n\nCloud Bigtable is a high-performance, NoSQL database designed for extremely large scale data storage and real-time data processing. It is well-suited for applications that require fast queries and updates on large datasets, such as the one described in the question.","comments":[{"upvote_count":"3","comment_id":"755553","timestamp":"1671960240.0","poster":"omermahgoub","content":"Cloud Run, on the other hand, is a fully managed serverless platform for deploying and scaling containerized applications. While it may be a good choice for some applications, it may not be the best fit for an application that needs to handle high levels of traffic and perform real-time queries on large datasets.\n\nBigQuery is a fully managed, cloud-native data warehouse that is well-suited for analyzing large datasets using SQL. However, it may not be the best choice for an application that needs to perform real-time queries on large datasets, as it is optimized for batch processing rather than real-time querying."}],"upvote_count":"4","poster":"omermahgoub"},{"timestamp":"1669870080.0","content":"For Heavy Write Big Table is the Only Option . For Cost Saving , Cloud RUn is the correct Option . Hence B .","poster":"CDL_Learner","comment_id":"732252","upvote_count":"1"},{"upvote_count":"1","poster":"Mr_MIXER007","timestamp":"1668682320.0","comment_id":"720399","content":"Selected Answer: B\nB for me"},{"comment_id":"717841","poster":"megumin","content":"Selected Answer: B\nB is ok","timestamp":"1668417360.0","upvote_count":"1"},{"timestamp":"1666841940.0","content":"Selected Answer: B\ni vote B. Real time is the key word of this question.","poster":"Balaji_Sakthi","comment_id":"705190","upvote_count":"1"},{"comment_id":"691914","poster":"Santanu_01","upvote_count":"3","content":"The solution should have Cloud Run (as it can scale from 0 to many) so when not in use no cost involved and Cloud Bigtable -- concerning throughput on the problem satement","timestamp":"1665477120.0"},{"comments":[{"upvote_count":"3","comment_id":"697867","content":"there will be a cost associated with your VM even if they have 0 traffic as GCE is an IaaS. You're billed for resources provisioned and the company wants to reduce cost","timestamp":"1666066260.0","poster":"zr79"}],"poster":"abhinav855","timestamp":"1664765460.0","comment_id":"685166","content":"The correct answer is D, with MIGs, you can reduce the workload to 0 as well whenever needed and it can better handled the workload compared to Cloud Run","upvote_count":"3"},{"upvote_count":"7","comments":[{"content":"If you would consider that scenario, then bursts could be way above a single compute engine instance can handle too, hence what you say applies to both situations, you say 5000, I say it'll come at 100000 and compute engine will fail too. Hence your point becomes invalid, though it is logical, hence B is the right answer.","comment_id":"748157","poster":"KyubiBlaze","upvote_count":"1","timestamp":"1671291000.0"},{"comment_id":"835137","timestamp":"1678461060.0","upvote_count":"1","content":"Very good point to mentioned. Thanks for sharing","poster":"n_nana"}],"poster":"6721sora","comment_id":"652663","content":"Selected Answer: D\nNot sure if B is right. Cloud Run will fail requests if waiting for more than 10 seconds.\nhttps://cloud.google.com/run/docs/tips/general\nIf you choose Cloud Run to minimize costs during periods of no activity, then when suddenly requests come in at 5000 requests per second, a \"Cold Start\" occurs for Cloud Run container instances. This startup can take many seconds and during this time the requests will timeout. So a minimum number of Instance of say 1 will be required to prevent Cold Start.","timestamp":"1661624340.0"},{"poster":"AzureDP900","timestamp":"1656858300.0","content":"B is right, There is no need to go with App Engine autoscaling. Cloud Run goes to zero instances when there are no requests. Question asks cost optimization. Big Query is not suitable .. so B is right.","upvote_count":"5","comment_id":"626588"},{"timestamp":"1656263880.0","poster":"Nirca","upvote_count":"3","content":"Selected Answer: B\nB is the right one","comment_id":"622697"},{"content":"Answer is B. Big table is amazing for REAL-TIME Analysis strong with heavy read/write events refer to: https://cloud.google.com/blog/topics/developers-practitioners/bigtable-vs-bigquery-whats-difference","comment_id":"618483","poster":"MarcExams","timestamp":"1655603400.0","upvote_count":"3"},{"content":"Selected Answer: B\nB is good, as it supports scaling to zero, to concurrency requests. so meet req't of cost-saving.","poster":"elainexs","timestamp":"1654240860.0","upvote_count":"3","comment_id":"610976"},{"timestamp":"1653769260.0","content":"Selected Answer: B\nB because of low cost","comment_id":"608523","upvote_count":"2","poster":"Superr"},{"timestamp":"1650268440.0","comment_id":"587536","poster":"JohnPi","content":"Selected Answer: B\nContainer instance | Maximum number of container instances | 1000 | per service\nRequest | Maximum number of concurrent requests | 1000 | per container instance\n1000*1000 > 500000","upvote_count":"4"},{"timestamp":"1649682180.0","comment_id":"584198","content":"Go for B cause \"There will be periods where the web service will not receive any requests\" and Cloud Run can scale down to zero","poster":"gaojun","upvote_count":"2"},{"upvote_count":"3","timestamp":"1648914960.0","poster":"mkc110891","comment_id":"579926","comments":[{"comment_id":"584303","comments":[{"poster":"gee1979","content":"great explanation!","upvote_count":"1","comment_id":"665361","timestamp":"1662809820.0"}],"timestamp":"1649693580.0","upvote_count":"5","content":"Yeah but you can scale out to 1000 cloud run containers each individually handling a max concurrency of 1000 req/sec. https://cloud.google.com/run/docs/configuring/max-instances\nThat would mean it can handle a soft cap of 1000 containers * 1000 req/sec = 1000000 req/sec. I'd go with B.","poster":"learner311"},{"content":"The limit 1000 is set per instance, so having 500 instances may handle that.","comment_id":"806423","upvote_count":"1","timestamp":"1676212080.0","poster":"segkhachat"}],"content":"Selected Answer: D\nThe answer is D: The default concurrency limit in the Cloud Run is 80 req/sec, which can be increased up to 1000 req/sec. Here in the question, they are talking about 500000 req/sec which is a way higher number. So it can be managed using autoscaling MIG.\nhttps://cloud.google.com/run/docs/about-concurrency#concurrency_values"},{"content":"Selected Answer: B\nI would vote for B.\nEVen though there is a max concurrency of 1000, there is no upper limit to the number of containers (unless we specify). So, CloudRun will spawn as many containers as needed to run the number of requests and take care of all the requests.\nLet me know if you have different interpretation of this link> https://cloud.google.com/run/docs/about-instance-autoscaling","comment_id":"577088","timestamp":"1648498740.0","upvote_count":"3","poster":"brvinod"},{"content":"Selected Answer: B\nYes, it is B because low cost, and cloud Run can go to 0 instances","comment_id":"561675","poster":"ss909098","upvote_count":"3","timestamp":"1646517840.0"},{"comment_id":"554599","timestamp":"1645629720.0","upvote_count":"1","poster":"bhtay","content":"Selected Answer: B\nCloud Run can scale down to zero."},{"comment_id":"543254","poster":"muky31dec","content":"Selected Answer: D\nmust D \nConcurrency values\nConcurrency is configurable. By default each Cloud Run container instance can receive up to 80 requests at the same time; you can increase this to a maximum of 1000. Note that in comparison, Functions-as-a-Service (FaaS) solutions like Cloud Functions have a fixed concurrency of 1.\n\nAlthough you should use the default concurrency value, if needed you can lower the maximum concurrency. For example, if your code cannot process parallel requests, set concurrency to 1.\n\nThe specified concurrency value is a maximum and Cloud Run might not send as many requests to a given container instance if the CPU of the instance is already highly utilized.\n\nThe following diagram shows how the concurrency setting affects the number of container instances needed to handle incoming concurrent requests:","upvote_count":"3","timestamp":"1644344700.0"},{"upvote_count":"1","timestamp":"1643206140.0","comment_id":"532939","content":"i'd say B","poster":"Pime13"},{"comment_id":"531014","upvote_count":"1","poster":"GARY1119","content":"B is correct.\nhttps://qwinix.io/blog/what-is-cloud-run/#:~:text=Powered%20by%20Knative%2C%20Cloud%20Run,a%20stateless%2C%20autoscaling%20HTTP%20service.&text=Cloud%20Run%20is%20a%20fully%20managed%20platform.\n\nCloud Run will scale to 0 if no request come and cost effective.","timestamp":"1642992000.0"},{"content":"Selected Answer: D\nCompute Engine autoscaling will scale down when service not needed","timestamp":"1642698780.0","comment_id":"528608","poster":"ks100","upvote_count":"1"},{"comments":[{"content":"and quote is 1000 cloud run instances => 1000 * 1000 = 1 000 000 reqs/s","poster":"pddddd","timestamp":"1641839280.0","comment_id":"521035","upvote_count":"2"}],"timestamp":"1641703560.0","comment_id":"519900","upvote_count":"3","content":"Selected Answer: D\nBy default each Cloud Run container instance can receive up to 80 requests at the same time; you can increase this to a maximum of 1000\nhttps://cloud.google.com/run/docs/about-concurrency","poster":"santoshindia"},{"comment_id":"519898","timestamp":"1641703500.0","content":"D. By default each Cloud Run container instance can receive up to 80 requests at the same time; you can increase this to a maximum of 1000\nhttps://cloud.google.com/run/docs/about-concurrency","poster":"santoshindia","upvote_count":"2"},{"comment_id":"517070","upvote_count":"1","timestamp":"1641341820.0","content":"Selected Answer: D\nInfrastructure is the key!","poster":"Fotofilico"},{"comment_id":"515701","poster":"joheri","content":"Selected Answer: D\nI don't think cloud run would scale upto 500K req per second. When max instance is 1000 and concurrency can't be 500 I suppose. D would be the right choice.","timestamp":"1641213120.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1640798880.0","comment_id":"512487","content":"Correct Anwer is B","poster":"GauravLahoti"},{"poster":"ehgm","upvote_count":"2","content":"Selected Answer: B\nThe only reason D is the right choice is if \"You are implementing the infrastructure for a web service on Google Cloud\" means that it must create an infra and not user a truly serverless service.","timestamp":"1640737800.0","comment_id":"511669"},{"poster":"simbu1299","content":"B is the correct answer","upvote_count":"1","comment_id":"507916","timestamp":"1640266860.0"},{"poster":"Andrea67","timestamp":"1639752900.0","content":"I'm agree with the task \"business wants to keep costs low\" but also at beginning of the question is required the I'm implementing the infrastructure for the .... so could be correct D","upvote_count":"1","comment_id":"503745"},{"poster":"PhilipKoku","content":"Selected Answer: B\nCloud Run and Big Table","timestamp":"1639335000.0","upvote_count":"1","comment_id":"500173"},{"poster":"anjuagrawal","content":"Should be B because there are times when no request. It would be cost effective to use Cloud Run instead of MIG","comment_id":"497734","timestamp":"1639054320.0","upvote_count":"2"},{"poster":"vincy2202","comment_id":"493677","content":"B is the correct answer","upvote_count":"1","timestamp":"1638617880.0"},{"upvote_count":"2","content":"B. Cloud Run and Cloud Bigtable \nCloud run scales to 0 if no request,\nand Bigtable is the BEST ingesting data, \nand VERY GOOD searching with a \"known set of attributes\".","poster":"jdr75","comment_id":"490756","timestamp":"1638282060.0"},{"content":"Selected Answer: B\nB. Because cloud run can scale to zero and for such heavy loads, it needs bigtable","comment_id":"488167","poster":"pakilodi","timestamp":"1638020040.0","upvote_count":"4"},{"timestamp":"1637996160.0","comment_id":"487905","poster":"nqthien041292","content":"Selected Answer: B\nVote B","upvote_count":"2"},{"content":"B - Cloud run can scalde down to zero when not used. BigTable instead of BigQuery as it involves realtime data.","poster":"TheCloudBoy77","comment_id":"482550","timestamp":"1637413320.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"475129","timestamp":"1636502100.0","poster":"[Removed]","comments":[{"content":"Typo mistake. The cloud run is better choice than compute engine instance.","poster":"[Removed]","comment_id":"477513","timestamp":"1636813500.0","upvote_count":"1"}],"content":"B is correct answer. Cloud Function is not suitable here for running a web app. Cloud Run is better, optimized choice"},{"comment_id":"465552","upvote_count":"2","poster":"danielfootc","timestamp":"1634793900.0","content":"IMHO, I would choose B coz cloud run can scale to zero where for compute engine autoscaling managed instance, the min is one instance. https://cloud.google.com/run/docs/about-instance-autoscaling. Bigtable is definitely one of the options as it involves real time data."},{"poster":"rottzy","timestamp":"1632919440.0","comment_id":"454140","content":"B\nweb service can be defined in cloud run, turn it down when not reqd\nbig numbers query - big table","upvote_count":"2"},{"comments":[{"upvote_count":"2","poster":"tsiddique","comment_id":"473002","content":"Cloud Run also can host web service in container. Hence B","timestamp":"1636108260.0"}],"poster":"BrijMohan08","content":"Answer D\ninfrastructure for a web service - VM (Compute Engine)\ndata will be queried later in real-time - Bigtable\nThere will be periods where the web service will not receive any requests - autoscaling managed instance group","timestamp":"1632820140.0","upvote_count":"3","comment_id":"453236"},{"content":"i think the answer is B, refer from this link: https://cloud.google.com/blog/topics/developers-practitioners/bigtable-vs-bigquery-whats-difference","poster":"Zuy01","upvote_count":"2","comment_id":"451194","timestamp":"1632539820.0"},{"upvote_count":"2","comment_id":"442567","timestamp":"1631289060.0","content":"A - as we need to query the data so we have a BigQuery Query interface, Bigtable we need to manually set an instance to help query. CE we will eliminate anyway.","poster":"amxexam"},{"upvote_count":"1","poster":"pr2web","content":"Answer is A. \nFrom BigQuery docs in GCP. In addition, Bigquery costs will be while loading data and significantly lower than BigTable when not in use. So Cloud Run (which scales down to 0) and BQ are the correct response.\n\n\"Maximum rows per second per project in the us and eu multi-regions — 500,000\"\nhttps://cloud.google.com/bigquery/quotas#streaming_inserts","timestamp":"1631130420.0","comment_id":"441625","comments":[{"comment_id":"463006","poster":"J19G","timestamp":"1634378400.0","upvote_count":"2","comments":[{"content":"I think the best option is B","poster":"J19G","comment_id":"463007","timestamp":"1634378400.0","upvote_count":"2"}],"content":"Thanks for pointing it out, I would have choose BigQuery as well until I read your link, note 500,0000 limit is a total limit, there is an additionally limit to 100,000 rows per second per table. \n\n \"In other words, the sum of rows per second streamed to all tables for a given project within a multi-region is limited to 500,000. Each table is additionally limited to 100,000 rows per second.\" \nhttps://cloud.google.com/bigquery/quotas#streaming_inserts"}]},{"upvote_count":"1","timestamp":"1630937760.0","content":"it's B","comment_id":"440380","poster":"Manh"},{"poster":"moustickiller","timestamp":"1630431600.0","content":"should be D, in my opinion cloud run can't host a listening service. it must be triggered one way or another. not very pertinent for a web service.","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1630437300.0","comment_id":"436594","content":"sorry, it's late in the evening. Confuse with cloud function :-(\nlet's go for B","poster":"moustickiller"}],"comment_id":"436537"},{"timestamp":"1629121020.0","content":"A) seems to be correct fit. \nCost low is achieved by cloud Run. Cloud big table plays well in combination with any of Bigdata tools than working alone. so BigQuery will be a good option here as the data is queried in real time","poster":"dhamo_555","comment_id":"425820","upvote_count":"1"},{"upvote_count":"3","poster":"AnilKr","comment_id":"418776","content":"I was thinking for 'A' but due to heavy writes probably better is Bigtable so 'B'.","timestamp":"1627914960.0"},{"timestamp":"1626860640.0","poster":"SSV","comment_id":"410777","upvote_count":"1","content":"I feel answer should be A. In Question it is mentioned low cost. If you use Bigtable then cost will be high. Big query also can handle real time data and it is of low cost. More over if they expect low latency then Big table is right option but here they have not mentioned that so we can use bigquery.","comments":[{"timestamp":"1628410140.0","content":"Low cost part is done by Cloud Run. High read / write = Bigtable. Big query is needed when analysis is required.","poster":"Linus11","comment_id":"421529","upvote_count":"2"}]},{"comment_id":"404752","upvote_count":"5","timestamp":"1626103080.0","content":"Ans B: Bigtable is optimized for real time reads & Cloud Run scales up and down from zero almost instantaneously depending on traffic. Cloud Run only charges you for the exact resources you use keeping the cost low","poster":"VishalB"},{"timestamp":"1626049620.0","comment_id":"404259","upvote_count":"1","content":"I agree that BigTable is the correct choice. However, I can not imagine how we can use Cloud Run; it is serverless. For this reason, option D makes sense to me.","poster":"hrosmendez"},{"poster":"victory108","comment_id":"404017","content":"B. Cloud Run and Cloud Bigtable","upvote_count":"6","timestamp":"1626010620.0"},{"comment_id":"400675","timestamp":"1625646960.0","upvote_count":"4","poster":"JeffClarke111","content":"B is ok"},{"poster":"muhasinem","comment_id":"397288","content":"B is correct Answer:\nCloud Run - Cost saving during idle time \nBig Table : Heavy writes","upvote_count":"3","timestamp":"1625284740.0"},{"comment_id":"395693","content":"Answer should be A, Cloud Run and BigQuery\nThere will be periods where the web service will not receive any requests => Cloud Run\nThe data will be queried later in real time, based on exact matches of a known set of attributes => BigQuery","timestamp":"1625127180.0","comments":[{"content":"Agree\n\n\"queried, based on exact matches of a known set of attributes\", this is more like SQL statements. BigTable we will need to build the keys using those attributes to have a good performance when querying those.","poster":"poseidon24","comments":[{"timestamp":"1627504740.0","content":"BigQuery streaming option fits with the requirement.\n\n\"Maximum rows per second per project in the us and eu multi-regions — 500,000\"\nhttps://cloud.google.com/bigquery/quotas#streaming_inserts","poster":"poseidon24","comments":[{"timestamp":"1634379060.0","poster":"J19G","comment_id":"463010","upvote_count":"1","content":"BigQuery won't work. \"Each table is additionally limited to 100,000 rows per second.\" \nhttps://cloud.google.com/bigquery/quotas#streaming_inserts"}],"comment_id":"416466","upvote_count":"2"}],"comment_id":"416464","upvote_count":"1","timestamp":"1627504500.0"},{"comment_id":"421531","poster":"Linus11","content":"It is web service. and 5 lakh request per second. Points to load balancing may be needed. Managed instance group will be needed. Cloud Run not sufficient.","timestamp":"1628410380.0","upvote_count":"1"}],"poster":"TotoroChina","upvote_count":"7"},{"timestamp":"1625110440.0","upvote_count":"7","content":"IMHO b) is the correct answer, not d).\nThe requirement is to keep cost low - the quizzer says explicitly that there will be periods where the web service will not receive any requests - my impression is that the quizzer wants by using that statement to point on a solution that can scale to zero...","comment_id":"395444","poster":"XDevX"}],"exam_id":4,"choices":{"D":"A Compute Engine autoscaling managed instance group and Cloud Bigtable","C":"A Compute Engine autoscaling managed instance group and BigQuery","B":"Cloud Run and Cloud Bigtable","A":"Cloud Run and BigQuery"},"answer_images":[],"answer_description":""},{"id":"A1Nog9pdjKTCBL5VTIYD","answer_description":"","unix_timestamp":1625713860,"isMC":true,"choices":{"B":"Deploy each microservice as a Deployment. Expose the Deployment in the cluster using an Ingress, and use the Ingress IP address to address the Deployment from other microservices within the cluster.","A":"Deploy each microservice as a Deployment. Expose the Deployment in the cluster using a Service, and use the Service DNS name to address it from other microservices within the cluster.","D":"Deploy each microservice as a Pod. Expose the Pod in the cluster using an Ingress, and use the Ingress IP address name to address the Pod from other microservices within the cluster.","C":"Deploy each microservice as a Pod. Expose the Pod in the cluster using a Service, and use the Service DNS name to address the microservice from other microservices within the cluster."},"exam_id":4,"url":"https://www.examtopics.com/discussions/google/view/57424-exam-professional-cloud-architect-topic-1-question-129/","question_id":34,"answers_community":["A (100%)"],"topic":"1","question_text":"You are developing an application using different microservices that should remain internal to the cluster. You want to be able to configure each microservice with a specific number of replicas. You also want to be able to address a specific microservice from any other microservice in a uniform way, regardless of the number of replicas the microservice scales to. You need to implement this solution on Google Kubernetes Engine. What should you do?","answer":"A","timestamp":"2021-07-08 05:11:00","answer_ET":"A","question_images":[],"discussion":[{"upvote_count":"29","poster":"MamthaSJ","content":"Answer is A","comment_id":"401672","timestamp":"1641636900.0"},{"comment_id":"420093","content":"Answer is A 100%\nB is incorrect. Ingress comes with a HTTP(S) LB with external IP hence is not needed for communications within the cluster internally.","upvote_count":"19","poster":"PeppaPig","timestamp":"1644048900.0"},{"poster":"plumbig11","upvote_count":"1","timestamp":"1735967400.0","comment_id":"1336256","content":"Selected Answer: A\nDeploy each service as a DEPLOYMENT, and in this case use DNS."},{"comment_id":"1113323","poster":"AWS_Sam","content":"Correct answer is A","upvote_count":"1","timestamp":"1720057740.0"},{"timestamp":"1709214720.0","comment_id":"993043","content":"A is correct answer","poster":"heretolearnazure","upvote_count":"1"},{"upvote_count":"8","timestamp":"1706367960.0","poster":"wooloo","comment_id":"964739","content":"each microservice with a specific number of replicas = Deployment\ninternal to the cluster = Service"},{"poster":"[Removed]","upvote_count":"2","content":"Selected Answer: A\nanswer is A","timestamp":"1688895720.0","comment_id":"770307"},{"upvote_count":"9","poster":"jay9114","timestamp":"1688051100.0","content":"Selected Answer: A\nBenefit of using Service\nLeveraging service allows for you to set up your environment with static IP addresses. So when your pods die and restart the IP address associated with the deceased pod remains\nfor the new pod that replaces it (ephemeral). I think using \"Service\" is helpful if you are setting up your pods to be able to communicate with specific pods in the cluster.\n\nBenefit of using DNS for Service\nUsing DNS for your Service (static IP) you can look up Services and/or Pods by name instead of IP. Addressability by name instead of IP is easier for me.","comment_id":"761291"},{"timestamp":"1688051040.0","content":"l\nl\nBenefit of using Service\nLeveraging service allows for you to set up your environment with static IP addresses. So when your pods die and restart the IP address associated with the deceased pod remains \nfor the new pod that replaces it (ephemeral). I think using \"Service\" is helpful if you are setting up your pods to be able to communicate with specific pods in the cluster. \n\nBenefit of using DNS for Service\nUsing DNS for your Service (static IP) you can look up Services and/or Pods by name instead of IP. Addressability by name instead of IP is easier for me.","comment_id":"761287","poster":"jay9114","upvote_count":"3"},{"timestamp":"1686430620.0","poster":"Sreenivasa739","content":"A is ok","comment_id":"741290","upvote_count":"1"},{"comment_id":"719390","upvote_count":"1","poster":"megumin","timestamp":"1684212300.0","content":"Selected Answer: A\nA is ok"},{"timestamp":"1681738080.0","content":"Selected Answer: A\nA. Deploy each microservice as a Deployment. Expose the Deployment in the cluster using a Service, and use the Service DNS name to address it from other microservices within the cluster.","upvote_count":"1","poster":"minmin2020","comment_id":"697428"},{"timestamp":"1676348040.0","content":"I got this question in exam.","upvote_count":"4","comment_id":"646524","poster":"ACE_ASPIRE","comments":[{"content":"I have received this sentence from u in every comment posted by u","comment_id":"893034","timestamp":"1699535340.0","upvote_count":"2","poster":"Sur_Nikki"}]},{"upvote_count":"3","poster":"DrishaS4","comment_id":"642712","content":"Selected Answer: A\nngress comes with a HTTP(S) LB with external IP hence is not needed for communications within the cluster internally.Microservice as Deployment - used to create replicas as per this request\nDNS name - used as an alias service name for External name which is user for internal requests","timestamp":"1675577580.0"},{"comment_id":"635197","timestamp":"1674397140.0","content":"vote A","upvote_count":"1","poster":"backhand"},{"timestamp":"1672763280.0","upvote_count":"1","poster":"AzureDP900","content":"A is right, There is no need of Ingress here because all service need to communicate internally...","comment_id":"626589"},{"upvote_count":"8","comment_id":"600503","poster":"JoeyCASD","content":"Vote A\n1. Based on the description \"You want to be able to configure each microservice with a specific number of replicas.\", It's a hint to use either Deployment or StatefulSet based on the service type is stateless or stateful, since the option only has Deployment, thus Option C and D is out.\n2. Based on the description \"You also want to be able to address a specific microservice from any other microservice in a uniform way, regardless of the number of replicas the microservice scales to.\" the later part is the key point, which means the traffic direct to each service is based on some certain rules, in K8S this means URL, which is Ingress with external HTTP LB.","timestamp":"1668244080.0"},{"content":"Selected Answer: A\nOf course it is A","timestamp":"1662408600.0","poster":"ss909098","comment_id":"561677","upvote_count":"1"},{"poster":"azureaspirant","comments":[{"poster":"deepnibm","content":"is that 2/15/22*??","upvote_count":"1","timestamp":"1660967340.0","comment_id":"551560"}],"timestamp":"1660591140.0","upvote_count":"6","comment_id":"548054","content":"2/15/21 exam"},{"poster":"hantanbl","upvote_count":"5","content":"this question came out in the exam","comment_id":"532248","timestamp":"1658757120.0"},{"poster":"technodev","timestamp":"1658240460.0","content":"Got this question in my exam, answered A","comment_id":"527712","upvote_count":"5"},{"poster":"simbu1299","upvote_count":"1","comment_id":"507917","content":"A is the correct answer","timestamp":"1655984520.0"},{"comment_id":"493742","timestamp":"1654344720.0","upvote_count":"2","content":"Selected Answer: A\nA is the correct answer","poster":"vincy2202"},{"timestamp":"1653627600.0","upvote_count":"2","content":"Selected Answer: A\nVote A","comment_id":"487908","poster":"nqthien041292"},{"poster":"Manh","comment_id":"440383","content":"It's A. internal by using cluster IP services type","timestamp":"1646583660.0","upvote_count":"2"},{"content":"ClusterIP type for internal communications, A","upvote_count":"2","timestamp":"1643815020.0","comment_id":"418722","poster":"AnilKr"},{"content":"Answer - A)\nMicroservice as Deployment - used to create replicas as per this request\nDNS name - used as an alias service name for External name which is user for internal requests","upvote_count":"7","timestamp":"1643065860.0","comment_id":"413479","poster":"dhamo_555"},{"timestamp":"1642532040.0","content":"A is correct 100%.\nIngress is intended for services exposing to external users, it usually works with a single L7 load balancer. \nService type \"ClusterIP\" is the right solution to facilitate communications within the cluster, with the help of kube-dns and kube-proxy","comment_id":"409070","poster":"PeppaPig","upvote_count":"6"},{"content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","poster":"kopper2019","upvote_count":"2","comment_id":"408941","timestamp":"1642516800.0"},{"poster":"muhasinem","upvote_count":"3","comment_id":"408370","timestamp":"1642422000.0","content":"A.traffic is internal to cluster ."},{"content":"B. Deploy each microservice as a Deployment. Expose the Deployment in the cluster using an Ingress, and use the Ingress IP address to address the Deployment from other microservices within the cluster.","comment_id":"404015","timestamp":"1641915360.0","comments":[{"content":"A is correct one. Deploy each microservice as a Deployment. Expose the Deployment in the cluster using a Service, and use the Service DNS name to address it from other microservices within the cluster.","comment_id":"433612","timestamp":"1646037780.0","poster":"victory108","upvote_count":"1"}],"upvote_count":"2","poster":"victory108"},{"comment_id":"403287","timestamp":"1641820260.0","content":"I think it is answer A. Answer B and D are opted out bc they do not comply with the requirement of addressing the microservice and replicas in a uniform way. Answer C talks about deploying a specific pod to expose as a service, while the question states you want to scale to multiple replicas.\nDocumentation link: https://medium.com/aspnetrun/deploying-microservices-on-kubernetes-35296d369fdb\nlook for Deployments paragraph","upvote_count":"5","poster":"milan74"},{"comment_id":"401994","content":"I believe it should be A as Ingress is to expose HTTP and HTTPS routes from outside the cluster.\nhttps://kubernetes.io/docs/concepts/services-networking/ingress/","upvote_count":"4","poster":"ElvinVarghese","timestamp":"1641660420.0"},{"timestamp":"1641618660.0","content":"It is B, someone else?","comment_id":"401479","comments":[{"comment_id":"407241","timestamp":"1642268100.0","upvote_count":"5","poster":"vickynag","content":"This is incorrect - Expose the Deployment in the cluster using an Ingress\nNeeds a service to expose deployment.. So correct ans is A"}],"poster":"kopper2019","upvote_count":"1"}],"answer_images":[]},{"id":"MSvUPZGPdvnKI0b8TbFv","isMC":true,"exam_id":4,"url":"https://www.examtopics.com/discussions/google/view/7137-exam-professional-cloud-architect-topic-1-question-13/","answers_community":["C (96%)","4%"],"topic":"1","answer":"C","unix_timestamp":1571923800,"question_text":"Your customer is receiving reports that their recently updated Google App Engine application is taking approximately 30 seconds to load for some of their users.\nThis behavior was not reported before the update.\nWhat strategy should you take?","answer_description":"","question_id":35,"answer_ET":"C","answer_images":[],"question_images":[],"discussion":[{"poster":"TosO","content":"C is the answer","upvote_count":"27","comment_id":"23694","timestamp":"1574450340.0"},{"upvote_count":"17","timestamp":"1726852740.0","poster":"MyPractice","content":"Key word: This behavior was not reported before the update\nA - Not Correct as it was working before with same ISP\nB - New code update caused an issue- why to open support ticket\nC - I agree with C\nD - This requires downtime and live prod affected too","comments":[{"timestamp":"1577348220.0","comments":[{"comment_id":"110581","upvote_count":"1","poster":"hafid","content":"\"then use Stackdriver Trace and Logging to diagnose the problem in a development/test/staging environment\" this is not asking for set environment either, it just says to diagnose problem in other environment so C it is","timestamp":"1592200440.0"}],"poster":"MyPractice","content":"\"then use Stackdriver Trace and Logging to diagnose the problem in a development/test/staging environment\" they are NOT asking us to setup Dev/Text/Stage.. meaning the environment already exist and we have to use it","comment_id":"32730","upvote_count":"1"}],"comment_id":"32729"},{"timestamp":"1731270420.0","poster":"Ekramy_Elnaggar","content":"Selected Answer: C\n1. Prioritize User Experience: Rolling back to a stable version quickly minimizes user impact and restores the application to a functional state. This should be the immediate first step.\n2. Controlled Environment: Diagnosing the issue in a development/test/staging environment allows you to investigate without affecting real users. You can reproduce the problem, gather data, and test potential solutions safely.\n3. Powerful Diagnostic Tools: Stackdriver Trace helps you pinpoint performance bottlenecks by tracing requests across your application. Stackdriver Logging provides detailed logs to understand application behavior and identify errors.","comment_id":"1309612","upvote_count":"4"},{"poster":"hzaoui","content":"Selected Answer: C\nC is correct","upvote_count":"1","comment_id":"1119979","timestamp":"1704991620.0"},{"content":"Selected Answer: C\nYour customer is receiving reports that their recently updated Google App Engine application is taking approximately 30 seconds to load for some of their users.\nThis behavior was not reported before the update.\nWhat strategy should you take?\n\n\nHere the application (our code) is updated and only some users are facing lantecy (Cloud Trace) issue.\n\nThe issue is not with ISP (A), Not an issue with Google (B).\nRollback must be done as mitigation, but testing should be done in Non-Prod environments (C), not on prod environment (D).\n\nHence C is correct answer.","poster":"AdityaGupta","comment_id":"1024408","timestamp":"1696391400.0","upvote_count":"1"},{"upvote_count":"2","poster":"jrisl1991","content":"Selected Answer: C\nI'm going for C. While D may be \"better\" in case this is an issue that only occurs in production, I think that keeping the disruption at minimum would be the best practice, which D would not really do. Plus, if the problem is load related, having this released at a quieter period may not surface the problem either.","comment_id":"1015457","timestamp":"1695525660.0"},{"poster":"frankryuu","comment_id":"936058","content":"Selected Answer: C\nAlthough it sounds like the right answer to do network tracing in stg again, this may be a network pass-through related issue and it is felt that the problem may not be reproduced if not checked in a prod environment.","upvote_count":"2","timestamp":"1687923780.0"},{"content":"Although it sounds like the right answer to do network tracing in stg again, this may be a network pass-through related issue and it is felt that the problem may not be reproduced if not checked in a prod environment.","upvote_count":"1","timestamp":"1687923720.0","comment_id":"936053","poster":"frankryuu"},{"poster":"FigVam","comment_id":"890710","timestamp":"1683373080.0","upvote_count":"2","content":"Selected Answer: C\nshould be C"},{"content":"Selected Answer: C\nC is the answer","poster":"alekonko","upvote_count":"2","timestamp":"1679520300.0","comment_id":"847536"},{"poster":"JC0926","comment_id":"837716","content":"Option C is also a valid strategy in this scenario. Rolling back to an earlier known good release initially and using Stackdriver Trace and Logging to diagnose the problem in a development/test/staging environment can help diagnose the issue without impacting production users.\n\nHowever, the reason why option D may be a better approach is that it allows for investigation during a quieter period, which can reduce the impact of any issues that may occur during the investigation. Rolling back to a known good release and then pushing the release again at a quieter period can help to ensure that users are not impacted during the investigation.","upvote_count":"3","timestamp":"1678692300.0"},{"comment_id":"711620","upvote_count":"1","timestamp":"1667637540.0","content":"Selected Answer: C\nok for C","poster":"megumin"},{"timestamp":"1666458420.0","poster":"Mahmoud_E","comment_id":"701676","content":"Selected Answer: C\nC is the correct answer","upvote_count":"1"},{"timestamp":"1665950700.0","upvote_count":"1","comment_id":"696507","poster":"AzureDP900","content":"C is perfect to troubleshoot latency issues with app"},{"poster":"minmin2020","comments":[{"timestamp":"1682970540.0","content":"I agree why not D, but in the past I faced issues only reproducible in prd, at that situation D was a possibility but usually yep C is for sure","poster":"Kiroo","upvote_count":"2","comment_id":"886685"}],"timestamp":"1665637440.0","content":"Selected Answer: C\nC. Roll back to an earlier known good release initially, then use Stackdriver Trace and Logging to diagnose the problem in a development/test/staging environment\n\nA and B are not relevant\nD - no IT manager will ever allow re-deployment of erroneous code in production, even in a quiet period...!","upvote_count":"3","comment_id":"693623"},{"content":"correct answer is C use the standard practise","poster":"holerina","upvote_count":"1","timestamp":"1663678020.0","comment_id":"674162"},{"content":"Selected Answer: D\nHow come everyone is agreeing to C!! In option C after rollback, the investigation will happen only on the earlier good release. Whereas in option D, all the troubleshooting will happen on current/problematic build. Option D should be the right option as it resolves the issue in short term and provides room for further investigation without downtime.","upvote_count":"1","poster":"Amit_arch","comment_id":"665433","timestamp":"1662816360.0","comments":[{"content":"you want to minimize the business loose, best option is to rollback and use stack-driver to diagnose the issue","timestamp":"1665974280.0","poster":"zr79","upvote_count":"1","comment_id":"696753"},{"comment_id":"678537","content":"Option C is investigating the bad build in test. The problem with option D is it is user impacting. Always best to attempt to find the problem in a test environment first. D could end-up being an option of last resort if all attempts to diagnose in test fail but I doubt any business person would be happy with D as it impacts service.","upvote_count":"3","timestamp":"1664091660.0","poster":"BiddlyBdoyng"}]},{"upvote_count":"1","poster":"pfilourenco","content":"Selected Answer: C\nThe correct answer is c.","timestamp":"1655967300.0","comment_id":"620815"},{"timestamp":"1650433980.0","content":"Selected Answer: C\nC is the answer.","upvote_count":"2","poster":"Nirca","comment_id":"588457"},{"upvote_count":"1","poster":"HeyBuddy95","comment_id":"576709","timestamp":"1648455240.0","content":"Selected Answer: C\nAnswer is C"},{"comment_id":"535396","timestamp":"1643453820.0","upvote_count":"2","poster":"Pime13","content":"Selected Answer: C\nchoose C"},{"poster":"vincy2202","comment_id":"508416","upvote_count":"1","timestamp":"1640339460.0","content":"C is the correct answer"},{"comment_id":"493248","timestamp":"1638548820.0","content":"Go for C","upvote_count":"1","poster":"haroldbenites"},{"poster":"sandipk91","timestamp":"1630345140.0","content":"C is the only answer","comment_id":"435701","upvote_count":"1"},{"poster":"amxexam","content":"C is the ans\nFor all those calling for D , the option dont tell they will install stackdriver, but will use it to analysie the logs. Then deploying back the faulty code without fixing does not make sences.","upvote_count":"1","comment_id":"430651","timestamp":"1629797760.0"},{"timestamp":"1627189740.0","upvote_count":"1","comment_id":"413614","poster":"DreamerK","content":"Why C is correct is there should be an assumption made by the author that new release will be deployed in the dev/test/stage environment. Otherwise C doesn't make any sense here."},{"comment_id":"393598","upvote_count":"2","timestamp":"1624952700.0","poster":"TotoroChina","content":"I go with D.\nHow can we recurrent the problem after rollback to a good former release? You should see nothing useful for the problem from Trace & Logging when you are running on a good release.\nC should be correct only when you have trace & logging always on for the period this problems happened, which is not mentioned in the question and not practical as the cost may surge if you are running a busy service."},{"comment_id":"391025","content":"C: Correct answer App engine gives flexibility to roll back to previous version. Priority should be restore the services to working state. And trace the issue using Stackdriver where the logs are already captured from previous failed service.","timestamp":"1624694760.0","poster":"aviratna","upvote_count":"1"},{"upvote_count":"2","timestamp":"1621325580.0","poster":"victory108","content":"C. Roll back to an earlier known good release initially, then use Stackdriver Trace and Logging to diagnose the problem in a development/test/staging environment","comment_id":"360239"},{"comment_id":"353881","timestamp":"1620661980.0","content":"i will go with C","upvote_count":"1","poster":"un"},{"timestamp":"1618024800.0","poster":"cmfchong","content":"I would choose D. Because Roll back to an earlier known good release initially, then install StackDriver for option C without install the updated app would not allow you to able to find the problems in the updated app. For option C it did not say it will then install the updated app.","upvote_count":"3","comment_id":"332258"},{"poster":"lynx256","content":"C is ok","upvote_count":"2","comment_id":"324016","timestamp":"1617084360.0"},{"poster":"Ausias18","upvote_count":"2","comment_id":"323978","timestamp":"1617080340.0","content":"answer is C"},{"timestamp":"1614166320.0","poster":"rmout","comment_id":"298149","upvote_count":"1","content":"application is taking approximately 30 seconds to load for \"some of their users\" not All ! So in my opinion , we would want to get hold of the network and data flow log evidences before rollingback. Testing in lower environments might not always work unless you have like to like env , and might not be even able to replicate the issue. Guess \"B\" would be the right option"},{"upvote_count":"2","timestamp":"1613344380.0","poster":"Joyjit_Deb","comment_id":"290559","content":"I would rather go with \"B\". Rolling back (as suggested in \"C\" & \"D\") without enough evidence or investigations could be not a good approach."},{"upvote_count":"1","content":"I go with C","timestamp":"1611848280.0","poster":"BobBui","comment_id":"278653"},{"upvote_count":"1","content":"I'll go with C","timestamp":"1603737300.0","comment_id":"206498","poster":"nimso"},{"content":"seems like a C. don't want impact customers before it is tested well.","upvote_count":"1","poster":"subhala","comment_id":"187387","timestamp":"1601085480.0"},{"timestamp":"1600094940.0","upvote_count":"1","poster":"AshokC","content":"C is more meaningful.","comment_id":"179356"},{"poster":"gkdinesh","timestamp":"1599742440.0","content":"Agree with option C","upvote_count":"1","comment_id":"177105"},{"content":"C is the answer without any impact on user.","timestamp":"1594292100.0","comment_id":"130525","upvote_count":"2","poster":"RM07"},{"upvote_count":"3","comment_id":"117063","content":"I'll go with C","timestamp":"1592890200.0","poster":"mlantonis"},{"content":"C, for sure.\nRoll back to an earlier known good release initially, then use Stackdriver Trace and Logging to diagnose the problem in a development/test/staging environment","timestamp":"1591767300.0","poster":"gfhbox0083","comment_id":"106497","upvote_count":"2"},{"poster":"Nirms","comment_id":"100840","content":"C is the correct answer","upvote_count":"3","timestamp":"1591103880.0"},{"content":"Final Decision to go with Option C","timestamp":"1590645060.0","comment_id":"97288","comments":[{"upvote_count":"2","timestamp":"1590765180.0","poster":"Ziegler","content":"C is very correct","comment_id":"98307"}],"upvote_count":"4","poster":"AD2AD4"},{"timestamp":"1589070060.0","comment_id":"86284","poster":"clouddude","upvote_count":"4","content":"I'll go with C.\n\nA does not seem reasonable because the problem happened after the update and is likely not ISP-related.\nB does not seem reasonable even if Support could assist because that would depend on your support level and doesn't take advantage of the tools you have available.\nC seems a reasonable first approach as it gets production back quickly and takes advantage of the ability to provision a cloud staging environment immediatelyh.\nD seems feasible but not desirable because it runs the risk of interfering with users again and imposes a delay."},{"content":"C is the answer","timestamp":"1588794120.0","upvote_count":"2","poster":"gcp_aws","comment_id":"84703"},{"upvote_count":"2","comment_id":"74424","poster":"PRC","content":"Agree with C...","timestamp":"1586855580.0"},{"comment_id":"48111","timestamp":"1581210960.0","poster":"Smart","content":"A (Incorrect): Problem began with new version; B (Incorrect): Problem is about latency - not traffic restriction. D (Incorrect): CI/CD Pipeline encourages easy rollbacks and troubleshooting in Dev/Test environment. C is the most appropriate way to diagnose and troubleshoot.","upvote_count":"3"},{"content":"answer: C","comment_id":"44701","timestamp":"1580389800.0","upvote_count":"2","poster":"2g"},{"timestamp":"1578769500.0","poster":"AWS56","upvote_count":"2","content":"C is the answer","comment_id":"37814"},{"upvote_count":"2","comments":[{"content":"C is the answer","timestamp":"1609004820.0","poster":"gh999l","comment_id":"252799","upvote_count":"2"}],"poster":"AWS56","content":"D is the answer","timestamp":"1574179020.0","comment_id":"22731"},{"poster":"Eroc","comments":[{"poster":"tartar","content":"C is ok","comment_id":"151612","upvote_count":"11","timestamp":"1596679800.0"},{"timestamp":"1614868920.0","poster":"nitinz","content":"C is the best option.","comment_id":"303391","upvote_count":"1"}],"upvote_count":"5","timestamp":"1571923800.0","comment_id":"17192","content":"More Ambiguity, I'm defaulting to a balance between frugality and likelihood. \"A\" would only be necessary if the ISP(Internet Service Provider) was causing the problem, most ISPs provide an error response faster than 30seconds. \"B\" would work, but Google Support agents are expensive... up from $50,000 annually. \"C\" is the best option as it will allow the GCP professional to find the root cause of the problem without increasing customer costs. \"D\" is the same as \"C\" but is testing in the exposed code based, \"D\" should only be chosen if the customer is not paying for other code bases already."}],"choices":{"B":"Open a support ticket to ask for network capture and flow data to diagnose the problem, then roll back your application","C":"Roll back to an earlier known good release initially, then use Stackdriver Trace and Logging to diagnose the problem in a development/test/staging environment","D":"Roll back to an earlier known good release, then push the release again at a quieter period to investigate. Then use Stackdriver Trace and Logging to diagnose the problem","A":"Work with your ISP to diagnose the problem"},"timestamp":"2019-10-24 15:30:00"}],"exam":{"name":"Professional Cloud Architect","isImplemented":true,"isBeta":false,"isMCOnly":false,"id":4,"lastUpdated":"11 Apr 2025","numberOfQuestions":279,"provider":"Google"},"currentPage":7},"__N_SSP":true}