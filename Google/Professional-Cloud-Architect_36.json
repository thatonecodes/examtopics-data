{"pageProps":{"questions":[{"id":"SiEV3F7nckWhJPtkE8ZX","choices":{"A":"Use VPC Network Peering between the VPC and the on-premises network.","B":"Expose the VPC to the on-premises network using IAM and VPC Sharing.","D":"Deploy Cloud VPN Gateway in each region. Ensure that each region has at least one VPN tunnel to the on-premises peer gateway.","C":"Create a global Cloud VPN Gateway with VPN tunnels from each region to the on-premises peer gateway."},"answer":"D","timestamp":"2020-01-12 14:48:00","answer_ET":"D","topic":"1","discussion":[{"upvote_count":"47","timestamp":"1586694240.0","poster":"Googler2","comment_id":"73665","content":"It can't be -A - VPC Network Peering only allows private RFC 1918 connectivity across two Virtual Private Cloud (VPC) networks. In this example is one VPC with on-premise network\nhttps://cloud.google.com/vpc/docs/vpc-peering\n\nIt is not definitely - B - Can't be\n\nIt is not C - Because Cloud VPN gateways and tunnels are regional objects, not global\n\nSo, it the answer is D - \nhttps://cloud.google.com/vpn/docs/how-to/creating-static-vpns","comments":[{"comment_id":"441417","upvote_count":"1","comments":[{"poster":"ochanz","upvote_count":"4","timestamp":"1639669320.0","content":"https://cloud.google.com/vpc/docs/vpc-peering allows internal IP address connectivity across two VPC so A is not the answer as the on premise network need to use public IP. cmiiw","comment_id":"503022"},{"timestamp":"1696565160.0","upvote_count":"2","content":"The question clearly asks us to use VPN.","poster":"AdityaGupta","comment_id":"1026224"}],"timestamp":"1631100420.0","content":"Why not A?\nhttps://cloud.google.com/vpc/docs/vpc-peering#benefits_of_exchanging_custom_routes\nThe second use case is exactly what is in the question.\n\nDon't get the argument about RFC 1918.\nWill go with A","poster":"amxexam"},{"poster":"AzureDP900","content":"Agreed with D.","timestamp":"1665937980.0","comment_id":"696381","upvote_count":"1"}]},{"poster":"TaherShaker","comments":[{"content":"sound promising dude","timestamp":"1638771840.0","upvote_count":"3","poster":"M_Asep","comment_id":"494941"},{"timestamp":"1683534480.0","comment_id":"891920","upvote_count":"3","content":"IS the Exam Idea questions enough dude, for passing this exam?","poster":"Sur_Nikki"}],"content":"Just Passed my exam and I answered (D) for this question","timestamp":"1605725160.0","upvote_count":"21","comment_id":"222177"},{"comment_id":"1237951","upvote_count":"2","content":"Selected Answer: D\nOption C: Create a global VPN gateway and establish VPN tunnels from each region to the on-premises peer gateway. This suggests that a single global VPN gateway manages the tunnels from both regions.\nOption D: Deploy a VPN gateway in each region and ensure that each region has at least one VPN tunnel to the on-premises peer gateway. This indicates that each region has its own VPN gateway.\n\n>Option D ensures that there is a VPN gateway in each region, providing greater redundancy. If a gateway in one region fails, the gateway in the other region remains operational.","poster":"ccpmad","timestamp":"1719472800.0"},{"content":"Selected Answer: C\nGlobal Cloud VPN Gateway: This feature allows for the creation of a single VPN gateway that can serve multiple regions within the same VPC network. By creating a global VPN gateway, you can efficiently manage VPN connections from all regions of your VPC to your on-premises network.\n\nSimplicity and Efficiency: Using a global gateway simplifies the configuration and management of VPN connections as opposed to maintaining separate regional VPN gateways. It centralizes the VPN endpoint on the Google Cloud side, reducing the complexity of the network setup.\n\nReliable and Secure Communication: The global Cloud VPN Gateway allows for secure, encrypted tunnels between Google Cloud and the on-premises network, ensuring that the application’s inter-regional and on-premises communications are secure.","timestamp":"1711524660.0","poster":"santoshchauhan","comment_id":"1183925","upvote_count":"2"},{"timestamp":"1704289980.0","comment_id":"1112809","content":"Selected Answer: D\nC is wrong. A global vpn is a single region resource.\nhttps://cloud.google.com/network-connectivity/docs/vpn/how-to/creating-ha-vpn?hl=it\n\ngcloud compute vpn-gateways create GW_NAME \\\n --network=NETWORK \\\n --region=REGION \\\n --stack-type=IP_STACK\n\nso D is the answer","upvote_count":"2","poster":"salvo007"},{"poster":"gcmrjbr","upvote_count":"2","content":"It´s option C! So, while the VPN Gateway itself is a regional resource, its scope can be effectively global as it can serve resources across different regions within the same Virtual Private Cloud (VPC). This is why it’s sometimes referred to as a ‘global’ service in the context of its functionality, even though strictly speaking, it’s a regional resource.","timestamp":"1703953440.0","comment_id":"1109831"},{"timestamp":"1684000800.0","poster":"LaxmanTiwari","content":"It can't be -A - VPC Network Peering only allows private RFC 1918 connectivity across two Virtual Private Cloud (VPC) networks. In this example is one VPC with on-premise network https://cloud.google.com/vpc/docs/vpc-peering It is not definitely - B - Can't be It is not C - Because Cloud VPN gateways and tunnels are regional objects, not global So, it the answer is D - https://cloud.google.com/vpn/docs/how-to/creating-static-vpn","comment_id":"896985","upvote_count":"3"},{"timestamp":"1673750220.0","comment_id":"776121","content":"Selected Answer: D\nD looks fine.","poster":"vvkds","upvote_count":"1"},{"upvote_count":"2","comment_id":"750028","content":"Selected Answer: D\nAs HA isn't required, why do we need two VPN gateways?","poster":"oms_muc","timestamp":"1671467280.0"},{"poster":"megumin","content":"Selected Answer: D\nD is ok","comment_id":"713179","timestamp":"1667840280.0","upvote_count":"1"},{"content":"Selected Answer: D\nD is the correct answer, in order to do A you will need VPN., or interconnect","poster":"Mahmoud_E","upvote_count":"1","timestamp":"1666491060.0","comment_id":"701861"},{"timestamp":"1665992880.0","content":"there is two VPN:\n1. classic VPN\n2. HA VPN","comment_id":"697059","upvote_count":"1","poster":"zr79"},{"content":"Selected Answer: D\nCloud VPN Gateway is a regional service, not global.","timestamp":"1659609360.0","comment_id":"642324","poster":"DrishaS4","upvote_count":"4"},{"poster":"elaineshi","upvote_count":"2","content":"Why not C? services across regions can communicate to each other, VPN only connects to the closet region, and all the VPC shall be connected if firewall's set.","comment_id":"610225","timestamp":"1654095480.0"},{"poster":"haroldbenites","comment_id":"495771","content":"Go for D.\nCloud VPN Gateway is regional. NOt Global\ngcloud compute vpn-gateways create GW_NAME \\\n --network=NETWORK \\\n --region=REGION","upvote_count":"2","timestamp":"1638864960.0"},{"timestamp":"1638084480.0","poster":"vincy2202","comment_id":"488922","upvote_count":"2","content":"D is the correct answer"},{"upvote_count":"3","comment_id":"486333","content":"Selected Answer: D\nvote D","timestamp":"1637798460.0","poster":"joe2211"},{"content":"D – Deploy Cloud VPN Gateway in each region. Ensure that each region has at least one VPN tunnel to on-prem peer gateway.\nC – could be an option though there is no such concept at global Cloud VPN gateway. In fact, GCP has HA and Classic VPN topologies: \nhttps://cloud.google.com/network-connectivity/docs/how-to/choose-product\nIn both cases, Cloud VPN gateway is deployed to single region.","upvote_count":"3","comment_id":"469368","poster":"MaxNRG","timestamp":"1635438540.0"},{"timestamp":"1625767020.0","comment_id":"402122","content":"Answer is D","poster":"MamthaSJ","upvote_count":"3"},{"content":"D. Deploy Cloud VPN Gateway in each region. Ensure that each region has at least one VPN tunnel to the on-premises peer gateway.","poster":"victory108","timestamp":"1621422720.0","comment_id":"361298","upvote_count":"2"},{"timestamp":"1621085160.0","comment_id":"357879","upvote_count":"1","content":"D is correct","poster":"un"},{"upvote_count":"1","content":"Answer is D","poster":"Ausias18","timestamp":"1617256800.0","comment_id":"325554"},{"content":"The correct ans is D","upvote_count":"2","timestamp":"1614240540.0","comment_id":"298860","poster":"ga"},{"timestamp":"1605105300.0","comments":[{"poster":"Surf","timestamp":"1607076060.0","comment_id":"234816","content":"I agree that it does not make sense. None of the answers really make sense but the closer to a correct answer is D in my opinion.","upvote_count":"5"}],"content":"doesn't 1 cloud HA VPN gateway (although setup is per region) provide access to all regions within your VPC network? why do you need to make setting up vpn tunnel in each region then?","upvote_count":"5","comment_id":"217335","poster":"SKSKSK"},{"timestamp":"1604965980.0","upvote_count":"2","comment_id":"216273","poster":"pepYash","content":"A - One VPC so no peering\nB- LOL\nC- there is no such thing. These gateways are regional resource.\nSo ~ D"},{"upvote_count":"1","content":"Answer D","comment_id":"180155","timestamp":"1600226400.0","poster":"AshokC"},{"upvote_count":"2","poster":"mlantonis","timestamp":"1592913600.0","content":"With VPC Peering and Shared VPC you cannot connect to on-prem systems. So A and B are incorrect.\n\nCloud VPN gateways and tunnels are regional objects.\nhttps://cloud.google.com/network-connectivity/docs/vpn/how-to/creating-static-vpns#creating_a_gateway_and_tunnel\n\nD is the correct answer","comment_id":"117426"},{"timestamp":"1592647860.0","content":"D is the answer","poster":"Tushant","upvote_count":"2","comment_id":"114683"},{"timestamp":"1592042640.0","poster":"syu31svc","content":"Cloud VPN gateways are bound to a single region so answer is D","upvote_count":"2","comment_id":"109338"},{"comment_id":"106611","poster":"gfhbox0083","timestamp":"1591778880.0","upvote_count":"2","content":"D, for sure.\nThere is no such thing called Global Cloud VPN Gateway"},{"timestamp":"1591284300.0","poster":"Ziegler","content":"D is the correct answer","comment_id":"102467","upvote_count":"2"},{"poster":"AD2AD4","upvote_count":"3","content":"Final Decision to go with Option D. \nRefer - https://cloud.google.com/vpn/docs/how-to/creating-vpn-dynamic-routes\n\"Region — Cloud VPN gateways and tunnels are regional objects. Choose a Google Cloud region where the gateway will be located. Instances and other resources in different regions can use the tunnel for egress traffic subject to the order of routes. \n\nFor best performance, locate the gateway and tunnel in the same region as relevant Google Cloud resources.\"","comment_id":"97472","timestamp":"1590665340.0"},{"upvote_count":"2","poster":"gcp_aws","comment_id":"95646","content":"D is the answer","timestamp":"1590438180.0"},{"timestamp":"1589571060.0","poster":"Jack_in_Large","content":"The solution is HA VPN, which lets you securely connect your on-premises network to your Virtual Private Cloud network through an IPsec VPN connection in single region. So answer is D.","upvote_count":"2","comment_id":"89628"},{"upvote_count":"1","comment_id":"58791","timestamp":"1583334480.0","poster":"MickeyD","content":"Why is the answer not A?"},{"upvote_count":"2","poster":"[Removed]","comment_id":"56432","timestamp":"1582879200.0","content":"Selected A in the exam"},{"poster":"Ronie","upvote_count":"7","comment_id":"51333","content":"D is correct. There is no global Cloud VPN gateway","timestamp":"1581877440.0"},{"content":"Answer: D","poster":"2g","comment_id":"44845","upvote_count":"2","timestamp":"1580397120.0"},{"comment_id":"38096","poster":"AWS56","upvote_count":"1","content":"C is the answer, can some one explain why it is D ?","timestamp":"1578836880.0","comments":[{"comments":[{"timestamp":"1596757740.0","upvote_count":"3","comment_id":"152217","poster":"tartar","content":"D is ok"}],"content":"Does the \"global Cloud VPN Gateway\" exist?\nI'm agree with D.","poster":"Jos","timestamp":"1579530540.0","comment_id":"41016","upvote_count":"7"},{"content":"There is no Global Cloud VPN GW, as such.","poster":"kumarp6","timestamp":"1604242680.0","comment_id":"210535","upvote_count":"1"},{"poster":"nitinz","content":"D, VPN are regional","timestamp":"1614905460.0","comment_id":"303742","upvote_count":"2"},{"comment_id":"658342","content":"Cloud VPN gateway is regional one and there is no such global Cloud VPN gateway","upvote_count":"1","timestamp":"1662201000.0","poster":"Sbgani"}]}],"question_text":"You want to establish a Compute Engine application in a single VPC across two regions. The application must communicate over VPN to an on-premises network.\nHow should you deploy the VPN?","unix_timestamp":1578836880,"question_images":[],"answers_community":["D (90%)","10%"],"answer_images":[],"question_id":176,"exam_id":4,"url":"https://www.examtopics.com/discussions/google/view/11819-exam-professional-cloud-architect-topic-1-question-77/","isMC":true,"answer_description":""},{"id":"wMlrr3LU7xHZSy4NhdoS","isMC":true,"question_images":[],"answer_description":"","question_id":177,"answer_ET":"B","answer_images":[],"answers_community":["B (100%)"],"question_text":"Your applications will be writing their logs to BigQuery for analysis. Each application should have its own table. Any logs older than 45 days should be removed.\nYou want to optimize storage and follow Google-recommended practices. What should you do?","timestamp":"2019-10-11 12:47:00","answer":"B","discussion":[{"upvote_count":"40","comments":[{"poster":"AzureDP900","comment_id":"696379","content":"Agreed and going with B","upvote_count":"2","timestamp":"1681662660.0"},{"upvote_count":"11","timestamp":"1619874000.0","comment_id":"210538","content":"it is B, if you use option A, on 46th day there is no table/content in table for application :)","poster":"kumarp6"},{"timestamp":"1630795980.0","content":"B partition table","poster":"nitinz","upvote_count":"4","comment_id":"303744"},{"content":"B is ok","comment_id":"152219","poster":"tartar","timestamp":"1612662960.0","upvote_count":"8"}],"comment_id":"14743","timestamp":"1586602020.0","content":"Could you please help clarify? I think B is correct.\nIt looks like table will be deleted with option A.\nhttps://cloud.google.com/bigquery/docs/managing-tables#updating_a_tables_expiration_time\nWhen you delete a table, any data in the table is also deleted. To automatically delete tables after a specified period of time, set the default table expiration for the dataset or set the expiration time when you create the table.","poster":"KouShikyou"},{"comment_id":"29951","content":"Agreed with B.","timestamp":"1592277840.0","upvote_count":"10","poster":"aviv"},{"content":"Selected Answer: B\nI think B is correct.","poster":"OSAMA911","comment_id":"1156202","upvote_count":"1","timestamp":"1724303580.0"},{"timestamp":"1712377200.0","upvote_count":"3","comment_id":"1026228","poster":"AdityaGupta","content":"Selected Answer: B\nhttps://cloud.google.com/bigquery/docs/managing-partitioned-tables#partition-expiration\n\nB is the correct answer."},{"timestamp":"1704570720.0","poster":"SSPPJi","comment_id":"944901","upvote_count":"4","content":"https://cloud.google.com/bigquery/docs/managing-partitioned-tables#partition-expiration"},{"content":"Selected Answer: B\nB is correct","timestamp":"1703361780.0","upvote_count":"1","poster":"FaizAhmed","comment_id":"931841"},{"poster":"Sur_Nikki","comment_id":"891922","content":"B seems correct as this will partitioning will create a filter criteria on the basis of which specified actions on logs will be taken","timestamp":"1699439520.0","upvote_count":"1"},{"upvote_count":"7","comment_id":"760591","timestamp":"1688007540.0","content":"Selected Answer: B\nB is the correct answer,\n\nIf your tables are partitioned by date, the dataset's default table expiration applies to the individual partitions. You can also control partition expiration using the time_partitioning_expiration flag in the bq command-line tool or the expirationMs configuration setting in the API. When a partition expires, data in the partition is deleted but the partitioned table is not dropped even if the table is empty.\n\nhttps://cloud.google.com/bigquery/docs/best-practices-storage","poster":"examch"},{"poster":"megumin","upvote_count":"1","content":"Selected Answer: B\nB is ok","comment_id":"713180","timestamp":"1683471540.0"},{"timestamp":"1682778060.0","upvote_count":"2","poster":"MarcoEscanor","comment_id":"707247","content":"Selected Answer: B\nB - You can control partition expiration using the time_partitioning_expiration flag in the bq command-line\nhttps://cloud.google.com/bigquery/docs/best-practices-storage"},{"comment_id":"671680","timestamp":"1679078640.0","upvote_count":"1","poster":"AhmedH7793","content":"Selected Answer: B\nB is okay"},{"content":"Selected Answer: B\nUsing Table-Partitions.","timestamp":"1675514340.0","poster":"DrishaS4","upvote_count":"1","comment_id":"642326"},{"comment_id":"642325","timestamp":"1675514280.0","poster":"DrishaS4","content":"Using Table-Partitions.","upvote_count":"1"},{"poster":"[Removed]","comment_id":"545486","upvote_count":"1","timestamp":"1660242780.0","content":"Selected Answer: B\nI got similar question on my exam."},{"comment_id":"495774","timestamp":"1654583040.0","upvote_count":"2","poster":"haroldbenites","content":"Go for B.\nhttps://cloud.google.com/bigquery/docs/creating-partitioned-tables#sql\nCREATE TABLE\n mydataset.newtable (transaction_id INT64, transaction_date DATE)\nPARTITION BY\n transaction_date\nOPTIONS(\n partition_expiration_days=3,\n require_partition_filter=true\n)"},{"upvote_count":"2","comment_id":"488926","timestamp":"1653715860.0","poster":"vincy2202","content":"Selected Answer: B\nB is the correct answer"},{"upvote_count":"2","poster":"MaxNRG","comment_id":"469370","content":"B – Make the tables time-partitioned and configure the partition expiration at 45 days.\nA – if you use table expiration time, then it will remove the whole table after 45 days.\nD – requires extra work and is not automatic.","timestamp":"1651163400.0"},{"upvote_count":"1","timestamp":"1642846020.0","poster":"Unfaithful","comment_id":"411453","content":"Answer: B\nSupport: https://cloud.google.com/bigquery/docs/best-practices-storage"},{"poster":"MamthaSJ","comment_id":"402124","upvote_count":"2","timestamp":"1641671880.0","content":"Answer is B"},{"poster":"victory108","content":"B. Make the tables time-partitioned, and configure the partition expiration at 45 days","timestamp":"1637329020.0","comment_id":"361321","upvote_count":"1"},{"poster":"Ausias18","upvote_count":"1","content":"Answer is B","comment_id":"325555","timestamp":"1633068120.0"},{"timestamp":"1632741120.0","upvote_count":"1","comment_id":"321847","content":"IMO - B is ok (assuming DAY partitioning or smaller than DAY time interval).","poster":"lynx256"},{"upvote_count":"1","timestamp":"1632445140.0","content":"B is right answers, you want to optimize storage.","poster":"padamdha","comment_id":"318710"},{"comment_id":"291113","timestamp":"1629036060.0","poster":"CloudGenious","upvote_count":"1","content":"B is write as A ans will delete whole table"},{"comment_id":"252134","upvote_count":"1","content":"B is correct","poster":"Prakzz","timestamp":"1624625580.0"},{"content":"If the partitioned table also has a table expiration configured, the table and all the partitions in it are deleted according to the table expiration settings. The table expiration takes precedence over the partition expiration. The answer A is correct. The question is on storage optimization and best practices.","upvote_count":"1","timestamp":"1624108260.0","comment_id":"248009","poster":"RKT20","comments":[{"content":"In option A the table is not partitioned, so I'll just have all the data deleted after 45 days.","poster":"sdsdfasdf4","upvote_count":"1","timestamp":"1624336800.0","comment_id":"249907"}]},{"content":"According to below link \"...Cluster autoscaler increases or decreases the size of the node pool automatically, based on the resource requests (rather than actual resource utilization) of Pods running on that node pool's nodes\" https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler\nSo technically the request to more pods, increases the size of nodes. Thats why A is the correct answer","upvote_count":"1","timestamp":"1623516120.0","comment_id":"241928","poster":"Hanmant"},{"comment_id":"238854","poster":"BhupalS","upvote_count":"2","content":"as per best practices both A& B are right Ans but for B some extra work to do so simple Ans is A \nhttps://cloud.google.com/bigquery/docs/best-practices-storage","timestamp":"1623196980.0"},{"poster":"rish01","timestamp":"1622743140.0","content":"This is definitely B. Partition expiry a very commmon practise to auto purge data.","upvote_count":"1","comment_id":"234306"},{"upvote_count":"1","comment_id":"219581","content":"I think B \nhttps://cloud.google.com/bigquery/docs/creating-partitioned-tables","poster":"p4","timestamp":"1621062180.0"},{"timestamp":"1616765520.0","comment_id":"187624","upvote_count":"4","poster":"VedaSW","content":"A is asking for trouble.\n\nDeleting the table after 45 days? But the table will have data from day 1, 2, 3...45, so on the 45th day, the entire table deleted!!! But I still need data on day 2 ... 45 still available, cause these data has not reached 45 days!"},{"timestamp":"1616079480.0","comment_id":"181647","content":"B is correct , with table expiration at 45 , the table creation date is checked , so logs which are put to the table on the 40th day will also get deleted.","upvote_count":"2","poster":"brati_sankar"},{"content":"A is correct. See\nhttps://cloud.google.com/bigquery/docs/best-practices-storage\nQuote: For example, if you set the default table expiration to 7 days, older data is automatically deleted after 1 week.","poster":"Bolek","timestamp":"1615971360.0","upvote_count":"1","comment_id":"180726"},{"content":"B - https://cloud.google.com/bigquery/docs/managing-partitioned-tables","poster":"AshokC","upvote_count":"1","comment_id":"180416","timestamp":"1615915860.0"},{"content":"All data will be gone by option A !!! The question is saying keep the last 45 days. !!!\nB is Correct","upvote_count":"1","comment_id":"168782","poster":"Kabiliravi","timestamp":"1614469560.0"},{"timestamp":"1613798040.0","upvote_count":"1","comment_id":"161928","poster":"garora","content":"B is the right answer. Time based partition is the best solution with least overhead to expire data after 45 days."},{"upvote_count":"1","timestamp":"1613797980.0","comment_id":"161927","poster":"garora","content":"B is the right answer. Time based partition is the best solution with least overhead to expire data after 45 days."},{"poster":"kaush","content":"B \nrefer https://cloud.google.com/bigquery/docs/managing-partitioned-tables","timestamp":"1612338420.0","upvote_count":"1","comment_id":"149545"},{"upvote_count":"2","content":"B is right answer.\npartitioned tables are perfect for this use case.","comment_id":"117746","timestamp":"1608756120.0","poster":"motty"},{"upvote_count":"2","poster":"Tushant","comment_id":"114684","content":"B is the answer","timestamp":"1608466260.0"},{"comment_id":"106624","upvote_count":"2","content":"B, for sure \nUsing Table-Partitions.","poster":"gfhbox0083","timestamp":"1607598540.0"},{"upvote_count":"3","comment_id":"97474","poster":"AD2AD4","timestamp":"1606570200.0","content":"Final Decision to go with Option B"},{"upvote_count":"2","poster":"gcp_aws","comment_id":"95652","content":"B is the answer","timestamp":"1606343700.0"},{"upvote_count":"1","poster":"Ziegler","timestamp":"1606170360.0","comments":[{"content":"B is indeed the best answer and not A please. Please ignore my comment above.","poster":"Ziegler","upvote_count":"5","comment_id":"102518","timestamp":"1607109720.0"}],"content":"A is the correct answer. The questions says each application has it own table. This implies that each application table with data older than 45 days will get expired and the table will be deleted with new one created. Remember as well the question says in order to optimise storage. A is the best answer none of the other option is good for storage optimisation. B is good for query optimisation etc","comment_id":"94550"},{"upvote_count":"2","poster":"Jack_in_Large","content":"Agree it's B","timestamp":"1605474600.0","comment_id":"89619"},{"content":"Answer: B","poster":"Zarmi","upvote_count":"3","comment_id":"83827","timestamp":"1604532180.0"},{"poster":"Javed","content":"B is correct","comment_id":"62358","upvote_count":"3","timestamp":"1599811560.0"},{"content":"B is correct","timestamp":"1598963700.0","poster":"PalSri","comment_id":"57245","upvote_count":"3"},{"content":"Correct: B. Selected B in exam","timestamp":"1598621220.0","upvote_count":"3","comment_id":"56533","poster":"[Removed]"},{"content":"Answer: B","upvote_count":"3","poster":"2g","comment_id":"44846","timestamp":"1596114780.0"},{"timestamp":"1595770320.0","content":"B is better","comment_id":"42946","upvote_count":"4","poster":"natpilot"},{"comment_id":"21570","timestamp":"1589464500.0","content":"B is correct","poster":"JoeShmoe","upvote_count":"6"},{"timestamp":"1587995700.0","content":"Although there are many ways to do this, B is also a good way to do it. https://cloud.google.com/bigquery/docs/managing-partitioned-tables ... A removes entire table.","upvote_count":"7","comment_id":"17785","poster":"Eroc"}],"url":"https://www.examtopics.com/discussions/google/view/6455-exam-professional-cloud-architect-topic-1-question-78/","exam_id":4,"choices":{"A":"Configure the expiration time for your tables at 45 days","D":"Create a script that uses the BigQuery command line tool (bq) to remove records older than 45 days","B":"Make the tables time-partitioned, and configure the partition expiration at 45 days","C":"Rely on BigQuery's default behavior to prune application logs older than 45 days"},"unix_timestamp":1570790820,"topic":"1"},{"id":"N6EKY2W4fNVvnVuvpKBw","timestamp":"2019-10-27 17:01:00","topic":"1","answer":"A","answer_ET":"A","question_images":[],"discussion":[{"timestamp":"1658479140.0","upvote_count":"64","comment_id":"411471","comments":[{"content":"very well explained","poster":"heretolearnazure","comment_id":"989170","upvote_count":"1","timestamp":"1724501280.0"},{"content":"Nice and detailed explanation. I agree with A.","timestamp":"1697473680.0","poster":"AzureDP900","comment_id":"696378","upvote_count":"1"},{"timestamp":"1715623380.0","upvote_count":"1","comment_id":"896988","poster":"LaxmanTiwari","content":"Nice and detailed explanation. I agree with A."},{"comment_id":"495054","poster":"Rajasa","timestamp":"1670323380.0","upvote_count":"3","content":"Good Explaination"}],"content":"Answer: A\nSupport: \nHow does Horizontal Pod Autoscaler work with Cluster Autoscaler?\n\nHorizontal Pod Autoscaler changes the deployment's or replicaset's number of replicas based on the current CPU load. If the load increases, HPA will create new replicas, for which there may or may not be enough space in the cluster. If there are not enough resources, CA will try to bring up some nodes, so that the HPA-created pods have a place to run. If the load decreases, HPA will stop some of the replicas. As a result, some nodes may become underutilized or completely empty, and then CA will terminate such unneeded nodes.","poster":"Unfaithful"},{"content":"i'm for A, but the question in ambiguous, because requires the autoscale of nodes (not pod) when the cpu overload, but in answer use k8s pod autoscaler based on cpu load ( cpu load for pod, not nodes ). strange","poster":"natpilot","comments":[{"content":"Agreed, the question is not about pods, but answers are also talking about pods (not only)\nA is correct because B is wrong according to \nhttps://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler\n\n\"Caution: Do not enable Compute Engine autoscaling for managed instance groups for your cluster nodes. GKE's cluster autoscaler is separate from Compute Engine autoscaling\"","comment_id":"219585","upvote_count":"20","poster":"p4","timestamp":"1636967580.0"},{"timestamp":"1620884100.0","comment_id":"88111","content":"Confuse with the question like you mentioned. Autoscale is via nodes not pod.. and can only be configure using gcloud command.","poster":"skywalker","upvote_count":"6"}],"timestamp":"1611675480.0","comment_id":"42949","upvote_count":"25"},{"poster":"Sur_Nikki","content":"A seems correct. y to create managed instance groups unnecessarily?","upvote_count":"1","comment_id":"891923","timestamp":"1715157240.0"},{"poster":"Deb2293","upvote_count":"1","content":"The answer is A.\nMore nodes mean it's horizontal scaling (increase VMs means vertical scaling of infrastructure). Cluster AutoScalar is used for increasing number of nodes.","timestamp":"1709079660.0","comment_id":"824259"},{"comment_id":"760631","content":"Selected Answer: A\nA is the Correct answer, Horizontal Pod Autoscaler and Cluster Autoscaler can be used together to provision new pods and new nodes as per the CPU utilization.\n\nhttps://www.youtube.com/watch?v=VNAWA6NkoBs","upvote_count":"2","timestamp":"1703829780.0","poster":"examch"},{"timestamp":"1699178460.0","poster":"megumin","content":"Selected Answer: A\nok for A","upvote_count":"1","comment_id":"711657"},{"timestamp":"1696721760.0","content":"Selected Answer: A\nMIG not for GKE as option B and C, D are not relevant to question","comment_id":"688942","poster":"Rajeev26","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\nConfigure a HorizontalPodAutoscaler with a target CPU usage. Enable the Cluster Autoscaler from the GCP Console.","timestamp":"1694804040.0","comment_id":"670230","poster":"abirroy"},{"comment_id":"664225","content":"Selected Answer: A\nA...\n\nThe HPA and CA complement each other for truly efficient scaling. If the load increases, HPA will create new replicas. If there isn’t enough space for these replicas, CA will provision some nodes, so that the HPA-created pods have a place to run.\n\nThe Horizontal Pod Autoscaler changes the shape of your Kubernetes workload by automatically increasing or decreasing the number of Pods in response to the workload's CPU or memory consumption, or in response to custom metrics reported from within Kubernetes or external metrics from sources outside of your cluster.","poster":"gee1979","timestamp":"1694234940.0","upvote_count":"1"},{"comment_id":"651622","timestamp":"1692933900.0","poster":"6721sora","upvote_count":"2","content":"A is wrong.\nPod scaling only spins up additional pods. Not nodes.\nCluster Autoscaler does adding of nodes automatically.\nI am surprised that so many people think that A is the correct answer.\n\nCorrect answer per me is C"},{"comment_id":"642328","content":"Selected Answer: A\nHorizontal Pod Autoscaler changes the deployment's or replicaset's number of replicas based on the current CPU load. If the load increases, HPA will create new replicas, for which there may or may not be enough space in the cluster. If there are not enough resources, CA will try to bring up some nodes, so that the HPA-created pods have a place to run. If the load decreases, HPA will stop some of the replicas. As a result, some nodes may become underutilized or completely empty, and then CA will terminate such unneeded nodes.","upvote_count":"2","timestamp":"1691145660.0","poster":"DrishaS4"},{"poster":"[Removed]","comment_id":"545487","upvote_count":"1","content":"I got one question on my exam which showed autoscaling configuration and was asked to select correct configuration.","timestamp":"1676147640.0"},{"timestamp":"1672823040.0","comment_id":"516386","upvote_count":"1","content":"I agree A is correct.\nI found quicklab.\nUnderstanding and Combining GKE Autoscaling Strategies.","poster":"OrangeTiger"},{"upvote_count":"6","comment_id":"510705","timestamp":"1672188540.0","poster":"ehgm","content":"Selected Answer: A\nB and D: You must never change the GKE managed instance group.\nC and D: maxUnavailable and maxSurge are used for rolling update\nA. It is the correct."},{"timestamp":"1670401620.0","poster":"haroldbenites","content":"Go for A","comment_id":"495775","upvote_count":"1"},{"comment_id":"469382","comments":[{"poster":"MaxNRG","content":"Correct answer A.","timestamp":"1666976280.0","comment_id":"469383","upvote_count":"1"}],"content":"Create Horizontal Autoscaler (min,max for pods):\nkubectl autoscale deployment my-app --max 6 --min 4 --cpu-percent 50\nAutoscaling cluster:\ngcloud container clusters create example-cluster \\\n--zone us-central1-a \\\n--node-locations us-central1-a,us-central1-b,us-central1-f \\\n--num-nodes 2 --enable-autoscaling --min-nodes 1 --max-nodes 4\nCheck scaling an application and Horizontal Pod Autoscaler: \nhttps://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\nManual Cluster Resizing: https://cloud.google.com/kubernetes-engine/docs/how-to/resizing-a-cluster\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/scaling-apps","upvote_count":"6","timestamp":"1666976220.0","poster":"MaxNRG"},{"upvote_count":"1","timestamp":"1666976100.0","poster":"MaxNRG","comment_id":"469378","content":"D.\nCloud VPN provides secure IPSec connection, though Direct Peering doesn’t. Also, check selection diagram “What GCP connection is right for you?” on Hybrid Connectivity page. https://cloud.google.com/hybrid-connectivity/\nIt explicitly points that Cloud VPN and Dedicated Interconnect are for extension of you Data Center to Cloud (== of private compute resources). And Direct Peering for accessing GSuite (full set of GCP resources).\nDirect Peering: https://cloud.google.com/network-connectivity/docs/direct-peering\nCloud VPN: https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview\nChoose Inteconnect Type: https://cloud.google.com/network-connectivity/docs/how-to/choose-product#cloud-interconnect only suggests Dedicted/Partner and Cloud VPN.\nThis Disaster Recovery scenario is described here, in section “Transferring data to and from GCP”:\nhttps://cloud.google.com/architecture/dr-scenarios-building-blocks#transferring_data_to_and_from"},{"timestamp":"1662351360.0","comment_id":"439462","content":"Not A but C. Cluster Autoscaler (horizontal infrastructure solution) : designed to add or remove nodes based on demand. When demand is high, cluster autoscaler will add nodes to the node pool to accommodate that demand. When demand is low, cluster autoscaler will scale your cluster back down by removing nodes. This allows you to maintain high availability of your cluster while minimizing superfluous costs associated with additional machines.","poster":"JustJack21","upvote_count":"3"},{"content":"A. Configure a HorizontalPodAutoscaler with a target CPU usage. Enable the Cluster Autoscaler from the GCP Console.","poster":"victory108","upvote_count":"3","timestamp":"1652960220.0","comment_id":"361320"},{"upvote_count":"1","timestamp":"1652621940.0","content":"A is correct","poster":"un","comment_id":"357892"},{"poster":"Ausias18","upvote_count":"1","timestamp":"1648792980.0","comment_id":"325556","content":"Answer is A"},{"content":"A is ok.\n\nHorizontalPodAutoscaler scales PODS\n----\nRef: https://cloud.google.com/kubernetes-engine/docs/concepts/horizontalpodautoscaler\n\"HPA changes the shape of your Kubernetes workload by automatically increasing or decreasing the number of Pods in response to the workload's CPU or memory consumption, or in response to custom metrics reported from within Kubernetes or external metrics from sources outside of your cluster.\"\n\nCluster Autoscaler scales CLUSTER (number of NODES) \n----\nRef: https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler\n\"When demand is high, the cluster autoscaler adds nodes to the node pool. When demand is low, the cluster autoscaler scales back down to a minimum size that you designate. \n[...]\nGKE's cluster autoscaler automatically resizes the number of nodes in a given node pool, based on the demands of your workloads. You don't need to manually add or remove nodes or over-provision your node pools. Instead, you specify a minimum and maximum size for the node pool, and the rest is automatic.\"","comment_id":"324979","timestamp":"1648723020.0","poster":"lynx256","upvote_count":"4"},{"upvote_count":"6","content":"I thought C is correct, but as per this - A is correct\nHow does Horizontal Pod Autoscaler work with Cluster Autoscaler?\nHorizontal Pod Autoscaler changes the deployment's or replicaset's number of replicas based on the current CPU load. If the load increases, HPA will create new replicas, for which there may or may not be enough space in the cluster. If there are not enough resources, CA will try to bring up some nodes, so that the HPA-created pods have a place to run. If the load decreases, HPA will stop some of the replicas. As a result, some nodes may become underutilized or completely empty, and then CA will terminate such unneeded nodes.","timestamp":"1646858400.0","poster":"VenV","comment_id":"306658"},{"comments":[{"poster":"amxexam","timestamp":"1661955660.0","content":"We are talking about CPU load or telling how many instances should be running or to be removed at a time.","upvote_count":"1","comment_id":"436414"}],"timestamp":"1641727200.0","content":"Why is it not D? \n\nFrom https://kubernetes.io/docs/tutorials/kubernetes-basics/explore/explore-intro/ , it mentions that:\n\"A Pod always runs on a Node. A Node is a worker machine in Kubernetes and may be either a virtual or a physical machine, depending on the cluster. Each Node is managed by the Master. A Node can have multiple pods, and the Kubernetes master automatically handles scheduling the pods across the Nodes in the cluster.\"\n\nThe question is asking about how the whole cluster can scale on the underlying VMs (i.e. Nodes) that they are sitting on, yeah?","upvote_count":"3","comment_id":"263164","poster":"joshuaquek"},{"poster":"hiteshrup","comment_id":"242754","upvote_count":"2","timestamp":"1639413420.0","content":"Answer should be A. \n\nBecause tables are not created. Keyword is \"Application **will be** writing the logs\" that means, application is not writing. So we can create table with specify expiration strategy. If words said, table are created / application is writing then option B can be the only option. Reason because, if tables are created without this option and need to set expiration then we need to delete those tables and recreate it which normally not a good option. But considering we have previliages to define expiration strategy on table creation, we should choose A. \n\nRef: https://cloud.google.com/bigquery/docs/best-practices-storage"},{"poster":"Hanmant","timestamp":"1639334520.0","comment_id":"241929","upvote_count":"5","content":"According to below link \"...Cluster autoscaler increases or decreases the size of the node pool automatically, based on the resource requests (rather than actual resource utilization) of Pods running on that node pool's nodes\" https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler\nSo technically the request to more pods, increases the size of nodes. Thats why A is the correct answer"},{"comment_id":"241926","upvote_count":"1","poster":"Hanmant","timestamp":"1639334460.0","content":"According to below link \"...Cluster autoscaler increases or decreases the size of the node pool automatically, based on the resource requests (rather than actual resource utilization) of Pods running on that node pool's nodes\" https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler"},{"upvote_count":"2","comment_id":"238862","poster":"BhupalS","content":"A seems Right Ans \nhttps://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/","timestamp":"1639016640.0"},{"poster":"doumx","timestamp":"1638816360.0","upvote_count":"1","comment_id":"236725","content":"A easy"},{"poster":"AshokC","upvote_count":"1","content":"A - \nHorizontalPodAutoscaler scales pods, Cluster autoscaler scales cluster","timestamp":"1631807280.0","comment_id":"180426"},{"poster":"richardxyz","comment_id":"178247","upvote_count":"1","timestamp":"1631456160.0","content":"C is correct; HorizontalPodAutoscaler is for PoD autoscaling"},{"content":"Question is talking about increasing node, that means we need to increase node pool, which is in cluster upgrade level and changing the increasing managed instance groups.\nB is correct","comments":[{"upvote_count":"3","content":"Answer is A: There is no concept for MIG in GKE.. HorizontalPodAutoscaler is smart enough if there is no resources to scale more pods. If Autoscaling is enabled for Nodes in GKE it will do.. \n\nAnswer is A.","comment_id":"177630","timestamp":"1631359080.0","poster":"Ankits19"}],"timestamp":"1630187880.0","poster":"Kabiliravi","upvote_count":"1","comment_id":"168789"},{"comment_id":"163210","content":"A is to be correct not B.","upvote_count":"1","poster":"wiqi","timestamp":"1629584760.0"},{"comment_id":"163204","poster":"wiqi","content":"B is correct","timestamp":"1629583980.0","upvote_count":"2"},{"timestamp":"1629476760.0","content":"Even if a node is added to cluster if CPUload is high, what is use of that, untill a pod sits on it.\nPods will be created on new nodes only if HorizontalPodAutoscaling is enabled. Answer is A.","upvote_count":"2","poster":"Krishna2401","comment_id":"162348"},{"content":"I think it is C. The question is asking about node CPU utilization and not about a particular POD CPU Utilization.\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler","timestamp":"1626266880.0","poster":"Karna","comment_id":"134840","upvote_count":"4"},{"content":"There is no \"managed instance group\" for GKE so B and D are incorrect.\nHorizontalPodAutoscaler scales pods, Cluster autoscaler scales cluster.\n\nA is the correct answer","comment_id":"117454","upvote_count":"3","poster":"mlantonis","timestamp":"1624451220.0"},{"upvote_count":"2","poster":"Tushant","content":"A is the answer","timestamp":"1624183920.0","comment_id":"114686"},{"content":"A - because HorizontalPodAutoscaler scales pods, Cluster autoscaler scales cluster.","timestamp":"1623868920.0","poster":"nhunt","comment_id":"111816","upvote_count":"3"},{"content":"Come on guys horizontalpod autoscaling is for pods not nodes C is the answer","comment_id":"105714","comments":[{"poster":"desertlotus1211","timestamp":"1623257940.0","comment_id":"106137","content":"You're adjusting nodes on the Pod. A Container cluster are nodes in Pods. Just a play in words.\n\nAnswer: A","upvote_count":"1"}],"upvote_count":"2","timestamp":"1623218280.0","poster":"pf38120"},{"timestamp":"1623070680.0","poster":"rbrto","comment_id":"104533","content":"why A ? it says add or remove node not pods, horizontal pod autoscale is used for scaling pods not nodes. the question is wrong !!","upvote_count":"4"},{"upvote_count":"2","timestamp":"1622827440.0","poster":"Ziegler","comment_id":"102521","content":"A is the correct answer"},{"content":"A, for sure.\nYou can autoscale Deployments based on CPU utilization of Pods using kubectl autoscale or from the GKE Workloads menu in Cloud Console.\nkubectl autoscale creates a HorizontalPodAutoscaler (or HPA) object that targets a specified resource (called the scale target) and scales it as needed. The HPA periodically adjusts the number of replicas of the scale target to match the average CPU utilization that you specify.\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/scaling-apps","poster":"gfhbox0083","timestamp":"1622609940.0","upvote_count":"1","comment_id":"100532"},{"comment_id":"97475","timestamp":"1622201460.0","upvote_count":"2","poster":"AD2AD4","content":"Final Decision to go with Option A"},{"comment_id":"97436","content":"answer should be C\nQuestion is to auto scale nodes not pod \nreference to below link , this is possible with gcloud command\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler","timestamp":"1622197800.0","comments":[{"poster":"AnshulVikramIkea","timestamp":"1627327500.0","content":"maxUnavailable and maxSurge is deployment update strategy. nothing to do with autoscaling","upvote_count":"3","comment_id":"144376"}],"upvote_count":"4","poster":"jayaen"},{"upvote_count":"2","poster":"gcp_aws","content":"A is the answer","comment_id":"95654","timestamp":"1621975260.0"},{"content":"Yes, it's A","upvote_count":"1","timestamp":"1621105920.0","comment_id":"89620","poster":"Jack_in_Large"},{"upvote_count":"1","poster":"asure","timestamp":"1620597300.0","content":"A\nhttps://medium.com/tensult/cluster-autoscaler-ca-and-horizontal-pod-autoscaler-hpa-on-kubernetes-f25ba7fd00b9","comment_id":"86254"},{"comment_id":"44847","timestamp":"1612019640.0","poster":"2g","content":"Answer: A","upvote_count":"1"},{"comment_id":"33677","poster":"MJK","content":"Ans -A \nhttps://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#should-i-use-a-cpu-usage-based-node-autoscaler-with-kubernetes","upvote_count":"3","timestamp":"1609304940.0"},{"content":"https://cloud.google.com/kubernetes-engine/docs/how-to/scaling-apps","poster":"Eroc","comments":[{"upvote_count":"11","comment_id":"152223","content":"A is ok\nhttps://cloud.google.com/kubernetes-engine/docs/tutorials/hello-app","poster":"tartar","timestamp":"1628294880.0"},{"upvote_count":"3","comment_id":"303746","poster":"nitinz","content":"A is only correct answer.","timestamp":"1646441580.0"},{"timestamp":"1635778860.0","comment_id":"210540","upvote_count":"3","content":"A is OK","poster":"kumarp6"}],"timestamp":"1603814460.0","comment_id":"17787","upvote_count":"6"}],"answers_community":["A (100%)"],"question_id":178,"answer_images":[],"question_text":"You want your Google Kubernetes Engine cluster to automatically add or remove nodes based on CPU load.\nWhat should you do?","exam_id":4,"answer_description":"","choices":{"A":"Configure a HorizontalPodAutoscaler with a target CPU usage. Enable the Cluster Autoscaler from the GCP Console.","C":"Create a deployment and set the maxUnavailable and maxSurge properties. Enable the Cluster Autoscaler using the gcloud command.","D":"Create a deployment and set the maxUnavailable and maxSurge properties. Enable autoscaling on the cluster managed instance group from the GCP Console.","B":"Configure a HorizontalPodAutoscaler with a target CPU usage. Enable autoscaling on the managed instance group for the cluster using the gcloud command."},"url":"https://www.examtopics.com/discussions/google/view/7323-exam-professional-cloud-architect-topic-1-question-79/","unix_timestamp":1572192060,"isMC":true},{"id":"JDRcHJOIlKH6ZMeoWCgU","answer_images":[],"topic":"1","answers_community":["B (90%)","10%"],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/7126-exam-professional-cloud-architect-topic-1-question-8/","answer":"B","question_images":[],"discussion":[{"timestamp":"1589061780.0","poster":"clouddude","content":"I'll go with B.\n\nThis is time series data. We also have no idea what kinds of data are being captured so it doesn't appear structurd.\n\nA does not seem reasonable because a flat file is not easy to query and analyze.\nB seems reasonable because this accommodates unstructured data.\nC seems unreasonable because we have no idea on the structure of the data.\nD seems unreasonable beacause there is no such Google database type.","comment_id":"86258","upvote_count":"34"},{"timestamp":"1738066440.0","comment_id":"1347886","content":"Selected Answer: B\nA / D : No very good in order to exploit the data\nC : Relational DB would have been a good candidate for managing sensor data only. But it is said to managing other data type which are not detailled.\nSo B is the best","poster":"hpf97","upvote_count":"1"},{"comment_id":"1317650","content":"Selected Answer: B\nWe don't know the data type. Only nosql make sense.","timestamp":"1732553940.0","poster":"ddatta","upvote_count":"1"},{"content":"Selected Answer: B\nAnswer is B.\n\n1. High Volume and Velocity of Data: You have 1000 rooms reporting data every second, resulting in a massive amount of data with high velocity. NoSQL databases are designed to handle this kind of volume and speed efficiently.\n2. Simple Data Structure: The data from the motion sensor is relatively simple (sensor ID and discrete information). NoSQL databases are well-suited for storing and processing this type of data without the need for complex schemas.\n3. Flexible Schema: NoSQL databases offer schema flexibility, allowing you to easily adapt to changes in the data structure if needed. This is important as your tracking requirements might evolve over time.\n4.Scalability: NoSQL databases are highly scalable, making it easy to accommodate future growth in the number of meeting rooms or data volume.","timestamp":"1731266820.0","comment_id":"1309594","upvote_count":"2","poster":"Ekramy_Elnaggar"},{"upvote_count":"2","poster":"ashishdwi007","content":"Selected Answer: B\nWith frequencies of data (per second), the best case would be using pub/sub and NoSQL. Relational DB/BlobStore/FlatFile are not good for Near realtime data.","comment_id":"1127254","timestamp":"1705752900.0"},{"content":"Selected Answer: C\nC. Relational database.\n\nHere's why:\n\nScalability: A relational database can handle the data volume from 1000 sensors reporting every second effectively.\nStructure: It provides a well-defined schema for organizing data like sensor ID, timestamp, motion status, account owner, and office location, making it easily queryable and understandable for analysts.\nRelationships: It allows establishing relationships between tables, such as linking sensor data to specific meeting rooms and their corresponding owners and locations. This facilitates analyses involving multiple data sources.\nFlexibility: Relational databases offer flexibility for expanding data collection beyond motion sensors in the future to include other sensor types or meeting room details.","poster":"hzaoui","upvote_count":"2","timestamp":"1704964260.0","comment_id":"1119532"},{"poster":"_kartik_raj","upvote_count":"1","comment_id":"1044654","content":"B, It is","timestamp":"1697430600.0"},{"upvote_count":"1","comment_id":"1024397","poster":"AdityaGupta","content":"Selected Answer: B\nUnstructured realtime aata","timestamp":"1696390500.0"},{"content":"Selected Answer: B\nb [ You need seperate fields and keys -- you do not need to relate them","timestamp":"1695017160.0","comment_id":"1010317","upvote_count":"1","poster":"ChinaSailor"},{"content":"NOSQL DB's are meant for these kind of workloads","upvote_count":"1","comment_id":"987556","timestamp":"1692718200.0","poster":"heretolearnazure"},{"poster":"BiddlyBdoyng","content":"The requirement to join the data to other data sets implies RDBMS.\nBigQuery can handle 1GB/s when streaming inserts, I doubt these 1000 sensors will send that much data.\n\nBigtable seems over the top and not able to fulfil all the requirements.","comment_id":"929692","upvote_count":"2","timestamp":"1687362900.0"},{"poster":"Deb2293","timestamp":"1677175080.0","comment_id":"819516","content":"Selected Answer: B\nThis will be time-series data. The best DB would be a Big Table (also sensorID can be used in the row key for faster retrieval of data)","upvote_count":"3"},{"timestamp":"1672474800.0","comment_id":"762555","poster":"AShrujit","upvote_count":"1","content":"B for me"},{"timestamp":"1671945840.0","comment_id":"755412","poster":"Jaldhi24","upvote_count":"1","content":"Selected Answer: B\nB is right"},{"content":"Selected Answer: B\nB (No SQL should be the right answer)","comment_id":"727527","upvote_count":"1","poster":"angelumesh","timestamp":"1669468200.0"},{"timestamp":"1665973020.0","poster":"zr79","content":"surprised by the options given, this is a great use case of Bigtable so NoSQL","upvote_count":"2","comment_id":"696740"},{"timestamp":"1665950100.0","comment_id":"696496","poster":"AzureDP900","upvote_count":"1","content":"B is right"},{"content":"Selected Answer: B\nB. NoSQL - unstructured data","timestamp":"1665580800.0","comment_id":"693113","upvote_count":"1","poster":"minmin2020"},{"comment_id":"617647","timestamp":"1655458560.0","content":"Option B - NO SQL (Unstructured)","poster":"Dhiraj03","upvote_count":"1"},{"comment_id":"588210","upvote_count":"1","timestamp":"1650376200.0","content":"Selected Answer: B\nthe data is not structed. or at least in a too simple way, (1 table). So No SQL is a good option.","poster":"Nirca"},{"comment_id":"552616","content":"B is correct","timestamp":"1645428420.0","upvote_count":"3","poster":"sasithra"},{"timestamp":"1644610740.0","poster":"[Removed]","upvote_count":"3","content":"Selected Answer: B\nI got this question on my exam.","comment_id":"545472"},{"upvote_count":"1","comment_id":"532166","timestamp":"1643118660.0","content":"Selected Answer: B\nB is the right answer.","poster":"AWS56"},{"content":"B is correct.It good for this solution.\nC RDB doesnt suppourt 'several different discrete items'.\nA&D is not good for analysis.","comment_id":"511896","timestamp":"1640761980.0","poster":"OrangeTiger","upvote_count":"1"},{"upvote_count":"1","comment_id":"493239","timestamp":"1638548220.0","content":"Go for B","poster":"haroldbenites"},{"upvote_count":"1","timestamp":"1636339140.0","content":"B is the right answer.","comment_id":"474087","poster":"vincy2202"},{"content":"B: Is a correct answer to store unstructured data like sensor data in NoSQL database like BigTable","comment_id":"390957","poster":"aviratna","timestamp":"1624686360.0","upvote_count":"3"},{"content":"Yes, B is the correct answer","poster":"Papafel","upvote_count":"1","timestamp":"1624411440.0","comment_id":"388417"},{"comment_id":"386034","content":"There is need to join sensor data with \"account owners and office locations.\". Only relational database can allow this. Also latency requirement is not very low.\nWill go with C.","timestamp":"1624173960.0","poster":"Yogikant","upvote_count":"3"},{"upvote_count":"1","timestamp":"1623634380.0","comment_id":"381450","content":"The data is only sending sensor Id and other data. The analyst will still need to do a join with other data like office id and only then they will be able to solve it. Postgresql can hold both json and relational data. To avoid joins, I would go for relational database.","poster":"Pokchok"},{"content":"B. NoSQL","poster":"victory108","timestamp":"1621320780.0","comment_id":"360175","upvote_count":"4"},{"comment_id":"352964","upvote_count":"1","content":"B is correct","timestamp":"1620558060.0","poster":"un"},{"poster":"GoCloud","comment_id":"352233","content":"B - for Bigtable ;)","timestamp":"1620427980.0","upvote_count":"4"},{"content":"Answer is B","upvote_count":"2","poster":"Ausias18","timestamp":"1617079620.0","comment_id":"323969"},{"comment_id":"319360","poster":"lynx256","upvote_count":"2","content":"IMO - B (eg. Bigtable)","timestamp":"1616604960.0"},{"comment_id":"290553","content":"\"B\" is best suited, most simple & cost effective method in this case.","upvote_count":"2","timestamp":"1613343780.0","poster":"Joyjit_Deb"},{"comment_id":"284875","timestamp":"1612621860.0","poster":"gauravagrawal","content":"B........ Bigtable, more specifically","upvote_count":"3"},{"upvote_count":"1","poster":"BobBui","timestamp":"1611847740.0","content":"I go with B","comment_id":"278649"},{"timestamp":"1607785740.0","poster":"Mndwsk","upvote_count":"2","comment_id":"241687","comments":[{"upvote_count":"1","content":"B or C could be correct, but the inclusion of analysis, additional information, and a standard set of data from each sensor means C is probably the correct choice.","timestamp":"1609861320.0","comment_id":"260359","poster":"mwilbert"}],"content":"C is correct. Discrete data means a defined number of known fields. Meaning a schema. One (1) second latency is NOT low latency. Low Latency is usually measured in milliseconds. Data stored is to be used by Analysts. Meaning joins and query support. \nThose things made me to lean towards Relational database."},{"timestamp":"1603807320.0","upvote_count":"1","poster":"rorro67","comment_id":"207088","content":"B unstructured data."},{"content":"B is right","comment_id":"196009","poster":"Ujjwalbarman","upvote_count":"1","timestamp":"1602156600.0"},{"timestamp":"1600995600.0","comment_id":"186660","content":"B is correct answer","upvote_count":"1","poster":"kavithareddygade"},{"poster":"AshokC","upvote_count":"1","comment_id":"179340","timestamp":"1600093260.0","content":"B makes more sense. NoSQL"},{"poster":"gkdinesh","upvote_count":"1","content":"Option B is correct. NoSQL data(sensor ID and several different discrete items of information)","comment_id":"175859","timestamp":"1599567180.0"},{"poster":"mlantonis","comment_id":"117041","timestamp":"1592889120.0","upvote_count":"2","content":"NoSQL because we have time series data. So B is the correct"},{"timestamp":"1592821020.0","content":"why the Question mention about use the data from sensor together with information about account owners and office locations,NOSQL Can not use joins ,hence how to address that","comment_id":"116284","upvote_count":"1","poster":"kaush"},{"comment_id":"106493","poster":"gfhbox0083","content":"B, for sure.\nnosql for time series data","timestamp":"1591766400.0","upvote_count":"4"},{"content":"And what if you need to use the data from sensor together with information about account owners and office locations? Then you will need a relational database to use a join between the different table. I would say C","comment_id":"103226","upvote_count":"3","poster":"znd","timestamp":"1591370040.0"},{"content":"B is the correct answer","upvote_count":"2","timestamp":"1591103100.0","comment_id":"100830","poster":"Nirms"},{"poster":"laksg","timestamp":"1589670000.0","comment_id":"90199","upvote_count":"2","content":"Agree B . Time series data - no sql"},{"comment_id":"83780","content":"B is the correct answer","upvote_count":"3","timestamp":"1588619880.0","poster":"gcp_aws"},{"timestamp":"1580389500.0","content":"answer: B","upvote_count":"2","poster":"2g","comment_id":"44695"},{"poster":"Eroc","comment_id":"17158","comments":[{"upvote_count":"6","poster":"tartar","timestamp":"1596620760.0","comment_id":"151066","content":"B is ok"},{"poster":"nitinz","content":"B because IoT = NoSQL or Bigtable or Datastore. Depending on the flavor of the question.","timestamp":"1614840000.0","upvote_count":"1","comment_id":"303167"}],"content":"B because the data is not yet structured but atleast provides 1 block of structured data. The ID.","timestamp":"1571917140.0","upvote_count":"4"}],"answer_ET":"B","unix_timestamp":1571917140,"exam_id":4,"answer_description":"","question_id":179,"timestamp":"2019-10-24 13:39:00","choices":{"B":"NoSQL","A":"Flat file","C":"Relational","D":"Blobstore"},"question_text":"Your company wants to track whether someone is present in a meeting room reserved for a scheduled meeting. There are 1000 meeting rooms across 5 offices on 3 continents. Each room is equipped with a motion sensor that reports its status every second. The data from the motion detector includes only a sensor ID and several different discrete items of information. Analysts will use this data, together with information about account owners and office locations.\nWhich database type should you use?"},{"id":"9Y0xvmBP2JjuPs6hZZIh","question_text":"You need to develop procedures to verify resilience of disaster recovery for remote recovery using GCP. Your production environment is hosted on-premises. You need to establish a secure, redundant connection between your on-premises network and the GCP network.\nWhat should you do?","question_images":[],"isMC":true,"discussion":[{"timestamp":"1570700520.0","poster":"KouShikyou","upvote_count":"44","comments":[{"timestamp":"1596758940.0","comment_id":"152224","poster":"tartar","upvote_count":"8","content":"B is ok"},{"comment_id":"210541","content":"Its quite a fun to use Transfer Appliance for DR, I think answer is B","comments":[{"upvote_count":"1","content":"Actually, how ca this be given as a option even?","comment_id":"891928","timestamp":"1683535140.0","poster":"Sur_Nikki"}],"timestamp":"1604242980.0","poster":"kumarp6","upvote_count":"6"},{"timestamp":"1614905700.0","content":"only B works","poster":"nitinz","upvote_count":"1","comment_id":"303749"}],"comment_id":"14583","content":"I think B is correct answer."},{"poster":"MeasService","timestamp":"1571308020.0","content":"Agree B is correct. Transfer appliance is a physical appliance for transferring huge bulk of data. does not fit into disaster recovery testing. out of A and B, B seems to be more nearest answer. One would not have direct peering and Dedicated interconnect in a solution","comment_id":"15761","upvote_count":"27"},{"comment_id":"1314816","poster":"Ekramy_Elnaggar","timestamp":"1732037400.0","upvote_count":"2","content":"Selected Answer: B\nDedicated Interconnect as Primary , and Cloud VPN as Backup"},{"timestamp":"1729712460.0","content":"answer is B","comment_id":"1302184","upvote_count":"1","poster":"nareshthumma"},{"content":"Selected Answer: B\nI go to B, because direct peering anyway requires VPN connection if you want to get access to VPC.","upvote_count":"4","timestamp":"1715884260.0","comment_id":"1212547","poster":"hitmax87"},{"upvote_count":"2","timestamp":"1702780200.0","content":"Selected Answer: A\nWhy you guys are choosing VPN? the reason to use Dedicated Interconnect is to have the max bandwidth available, does VPN give you that option in the first place? why not thinking about separate direct peering connection which might give a better performance than VPN?","poster":"MahAli","comment_id":"1098639","comments":[{"comment_id":"1098641","comments":[{"poster":"Diwz","content":"Direct peering allows only on premises to connect to Google services in GCP . If needed to connect with Google workspace where all projects hosted they dedicated or partner interconnect is required. \nhttps://cloud.google.com/network-connectivity/docs/direct-peering\n\nB is the best answer","upvote_count":"2","timestamp":"1712770800.0","comment_id":"1193187"}],"upvote_count":"1","poster":"MahAli","timestamp":"1702780260.0","content":"BTW with direct peering you are going through the service provider network which makes more sense to get different connectivity option"}]},{"timestamp":"1696566900.0","content":"You need to develop procedures to verify resilience of disaster recovery for remote recovery using GCP. Your production environment is hosted on-premises. You need to establish a secure, redundant connection between your on-premises network and the GCP network.\nWhat should you do?\n\nA. Verify that Dedicated Interconnect can replicate files to GCP. Verify that direct peering can establish a secure connection between your networks if Dedicated Interconnect fails.\n\nB. Verify that Dedicated Interconnect can replicate files to GCP. Verify that Cloud VPN can establish a secure connection between your networks if Dedicated Interconnect fails.\n\nWhy Not A, as question asks \"to establish a secure, redundant connection between your on-premises network and the GCP network.\"\n\nIs VPN considered more reliable than Direct Peering?? Both VPN and Direct Peering will provide redundant connection.\nI am not concerned about cost Direct Interconnect is already there.","poster":"AdityaGupta","comment_id":"1026236","upvote_count":"1"},{"comment_id":"940147","poster":"FaizAhmed","upvote_count":"1","content":"Selected Answer: B\nB is right,","timestamp":"1688227320.0"},{"poster":"omermahgoub","comments":[{"upvote_count":"1","poster":"omermahgoub","content":"The Transfer Appliance is a physical storage device that you can use to transfer large amounts of data from your on-premises storage to GCP. It is not a connection option and cannot be used to establish a secure connection between your on-premises network and GCP. Therefore, the options C and D are not correct.","timestamp":"1671696540.0","comment_id":"753077"},{"timestamp":"1701353940.0","comment_id":"1084438","poster":"stefanop","upvote_count":"2","content":"Why not A? Is Cloud VPN better than Direct Peering in this scenario?"}],"content":"The correct answer is B. Verify that Dedicated Interconnect can replicate files to GCP. Verify that Cloud VPN can establish a secure connection between your networks if Dedicated Interconnect fails.\n\nDedicated Interconnect is a connection that provides a private, dedicated connection between your on-premises network and GCP over a Google-owned network. It is a secure and reliable option for connecting your on-premises network to GCP. You can use it to replicate files to GCP as a part of your disaster recovery plan.\n\nIf Dedicated Interconnect fails for any reason, it is a good idea to have a backup solution in place to establish a secure connection between your networks. Cloud VPN is a secure and reliable solution for establishing a connection between your on-premises network and GCP. It uses a virtual private network (VPN) tunnel to securely connect the networks, and it is a good backup option if Dedicated Interconnect fails.","timestamp":"1671696540.0","upvote_count":"8","comment_id":"753075"},{"poster":"megumin","comment_id":"714738","content":"Selected Answer: B\nB is ok","upvote_count":"1","timestamp":"1668011880.0"},{"timestamp":"1665993720.0","poster":"zr79","upvote_count":"1","comment_id":"697079","content":"For DR with Google Cloud and on-prem use Dedicated Interconnect with HA VPN"},{"timestamp":"1665937620.0","poster":"AzureDP900","upvote_count":"1","comment_id":"696376","content":"B is right without any second thought. Question is straight forward."},{"upvote_count":"1","comment_id":"688945","content":"Selected Answer: B\nTransfer appliance you need to carry to GCP center like water bottle :)","timestamp":"1665186000.0","poster":"Rajeev26"},{"timestamp":"1663267980.0","upvote_count":"1","poster":"abirroy","comment_id":"670229","content":"Selected Answer: B\nVerify that Dedicated Interconnect can replicate files to GCP. Verify that direct peering can establish a secure connection between your networks if Dedicated Interconnect fails."},{"timestamp":"1662859920.0","comment_id":"665753","content":"It is definitely B\n1. Interconnect is the first option so that is right.\n2. Eliminates A, since Direct Peering is not supported in GCP, the option is Google Cloud VPN connection to onpremises site.","upvote_count":"3","comments":[{"poster":"BeCalm","upvote_count":"2","timestamp":"1678286940.0","comment_id":"833068","content":"GCP supports direct peering in 100 locations"}],"poster":"alexandercamachop"},{"upvote_count":"1","poster":"DrishaS4","timestamp":"1659609840.0","content":"Selected Answer: B\nTransfer appliance is a physical appliance for transferring huge bulk of data. does not fit into disaster recovery testing","comment_id":"642331"},{"comment_id":"637326","poster":"Matalf","timestamp":"1658830320.0","upvote_count":"1","content":"Selected Answer: B\nonly B have redundacy"},{"poster":"haroldbenites","content":"Go for B.\nOnly when u need connect con G.Suite applications you must use Peering.","upvote_count":"4","comment_id":"495784","timestamp":"1638866400.0"},{"comment_id":"489005","timestamp":"1638090420.0","upvote_count":"1","poster":"vincy2202","content":"B is the correct answer"},{"upvote_count":"1","timestamp":"1637798940.0","content":"Selected Answer: B\nvote B","poster":"joe2211","comment_id":"486335"},{"content":"B is correct. Dedicated Interconnect with option of Cloud VPN for redundancy","upvote_count":"3","comment_id":"469973","poster":"[Removed]","timestamp":"1635536460.0"},{"poster":"MaxNRG","content":"B.\nCloud VPN provides secure IPSec connection, though Direct Peering doesn’t. Also, check selection diagram “What GCP connection is right for you?” on Hybrid Connectivity page. https://cloud.google.com/hybrid-connectivity/\nIt explicitly points that Cloud VPN and Dedicated Interconnect are for extension of you Data Center to Cloud (== of private compute resources). And Direct Peering for accessing GSuite (full set of GCP resources).\nDirect Peering: https://cloud.google.com/network-connectivity/docs/direct-peering\nCloud VPN: https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview\nChoose Inteconnect Type: https://cloud.google.com/network-connectivity/docs/how-to/choose-product#cloud-interconnect only suggests Dedicted/Partner and Cloud VPN.\nThis Disaster Recovery scenario is described here, in section “Transferring data to and from GCP”:\nhttps://cloud.google.com/architecture/dr-scenarios-building-blocks#transferring_data_to_and_from","timestamp":"1635440160.0","comment_id":"469381","upvote_count":"6"},{"upvote_count":"3","content":"Answer: B\nSupport: Dedicated Interconnect with VPN is a better solution. If a dedicated connection is possible why anyone will use Direct Peering.","poster":"Unfaithful","comment_id":"411477","timestamp":"1626943380.0"},{"timestamp":"1625767200.0","comment_id":"402128","upvote_count":"2","poster":"MamthaSJ","content":"Answer is B"},{"poster":"Yogikant","timestamp":"1624412760.0","upvote_count":"1","content":"Direct Peering exists outside of Google Cloud. Unless you need to access Google Workspace applications, the recommended methods of access to Google Cloud are Dedicated Interconnect or Partner Interconnect.\nhttps://cloud.google.com/network-connectivity/docs/direct-peering\nAnswer: B","comment_id":"388423"},{"timestamp":"1622425260.0","poster":"Yogikant","content":"Answer: B\n\nWhen established, Direct Peering provides a direct path from your on-premises network to Google services, including Google Cloud products that can be exposed through one or more public IP addresses. \n\nRequirement is \"secure\". Enabling public IP address for VMs is not recommended.","upvote_count":"1","comment_id":"370544"},{"timestamp":"1622132460.0","content":"is it possible, i mean, if on-premise has down, do i have to wait until transfer appliance has finished? I mean, is that question little bit weird?","upvote_count":"1","comment_id":"368124","poster":"awfully"},{"poster":"victory108","upvote_count":"2","comment_id":"361316","timestamp":"1621423920.0","content":"B. Verify that Dedicated Interconnect can replicate files to GCP. Verify that Cloud VPN can establish a secure connection between your networks if Dedicated Interconnect fails."},{"poster":"un","comment_id":"357903","content":"B is correct","timestamp":"1621086540.0","upvote_count":"1"},{"content":"Answer is B","poster":"Ausias18","comment_id":"325558","upvote_count":"2","timestamp":"1617257100.0"},{"timestamp":"1616848080.0","comment_id":"321825","content":"B is ok.","upvote_count":"1","poster":"lynx256"},{"upvote_count":"1","poster":"pawel_ski","content":"A is correct.\nhttps://cloud.google.com/network-connectivity/docs/direct-peering\n\"Direct Peering enables you to establish a direct peering connection between your business network and Google's edge network and exchange high-throughput cloud traffic.\"\nDirect Peering supports HIGH-throughput traffic. Cloud VPN supports unto 3 Gbps where as Interconnect can support unto 100 Gbps.","timestamp":"1615570800.0","comment_id":"309048","comments":[{"poster":"kakarooky","timestamp":"1619483520.0","content":"I agree. the issue is throuput.","comment_id":"343652","upvote_count":"1"},{"content":"Direct Peering is within GCP. not provide Hybrid connectivity","timestamp":"1654096440.0","poster":"elaineshi","comment_id":"610230","upvote_count":"1"}]},{"comment_id":"236726","upvote_count":"1","content":"B absolutly","poster":"doumx","timestamp":"1607280480.0"},{"content":"B is good.. direct peering is needed only when you need G suite applications which is not the requirement in this question","upvote_count":"1","comment_id":"232783","poster":"Chulbul_Pandey","timestamp":"1606900080.0"},{"timestamp":"1605133620.0","content":"Answer should be A. Direct Peerting is way better option than VPN","comment_id":"217573","poster":"Ujjwalbarman","upvote_count":"2"},{"upvote_count":"1","comment_id":"180437","timestamp":"1600272180.0","poster":"AshokC","content":"B - Dedicated Interconnect + Cloud VPN"},{"upvote_count":"1","poster":"Kabiliravi","timestamp":"1598652060.0","comments":[{"upvote_count":"1","content":"Sorry I meant how C is correct???","poster":"Kabiliravi","timestamp":"1598652120.0","comment_id":"168791"}],"content":"How A is correct??? Are you going to wait for 12 days for your Transfer Appliance be ready to use in your GCP project???\n\nB is the correct answer.","comment_id":"168790"},{"timestamp":"1598048880.0","comment_id":"163211","upvote_count":"1","content":"B is correct","poster":"wiqi"},{"timestamp":"1594795740.0","content":"B prefered choice, Direct Peering exists outside of Google Cloud. Unless you need to access G Suite applications, the recommended methods of access to Google Cloud are Dedicated Interconnect or Partner Interconnect.","comment_id":"135498","upvote_count":"1","poster":"GCPMG"},{"content":"I was wrong in my post earlier about A. ( Direct Peering can be used to connect on-prem to Google, I mistook direct peering for VPC peering ) but it is not recommended unless you need to connect to G-Suite. So B ( Direct interconnect + Cloud VPN ) is still the answer\n\nhttps://cloud.google.com/network-connectivity/docs/direct-peering/direct-peering\nDirect Peering exists outside of Google Cloud. Unless you need to access G Suite applications, the recommended methods of access to Google Cloud are Dedicated Interconnect or Partner Interconnect.","timestamp":"1592938500.0","upvote_count":"5","poster":"motty","comment_id":"117755"},{"timestamp":"1592938020.0","upvote_count":"2","comment_id":"117752","poster":"motty","content":"B is correct. Dedicated Interconnect is the bestion Option B for GCP to on-prem. Cloud VPN provides back up.\nA is incorrect becasue direct peering is for VPC to VPC connectivity.\nAnything related to Transfer appliance is wrong."},{"content":"Transfer appliance is used to move datea from to Google Cloud. I believe we need a Dedicated interconnect to connect on-prem with GCP. Of course Dedicated Interconnect cannot replicate files but can be used to establish the connection.\n\nI would choose B.","upvote_count":"1","timestamp":"1592916240.0","comment_id":"117464","poster":"mlantonis"},{"timestamp":"1592647980.0","comment_id":"114687","poster":"Tushant","content":"B is the answer","upvote_count":"1"},{"content":"B ic correct..Transfer Appliance is not for connection to on-premise","timestamp":"1591871820.0","comment_id":"107622","upvote_count":"3","poster":"Rajuuu"},{"content":"is the correct answer","comment_id":"102525","comments":[{"timestamp":"1591370280.0","content":"B is the correct answer","comment_id":"103233","poster":"Ziegler","upvote_count":"2"}],"timestamp":"1591291680.0","upvote_count":"1","poster":"Ziegler"},{"poster":"gfhbox0083","timestamp":"1591074540.0","comment_id":"100538","upvote_count":"2","content":"B, for sure.\nWe can not use Transfer Appliance, as it is a high-capacity storage device that enables you to transfer and securely ship your data to a Google upload facility, where we upload your data to Google Cloud Storage."},{"upvote_count":"3","poster":"AD2AD4","timestamp":"1590665640.0","comment_id":"97481","content":"Final Decision to go with Option B"},{"content":"B is the correct answer","timestamp":"1590439500.0","poster":"gcp_aws","comment_id":"95656","upvote_count":"1"},{"comment_id":"89621","content":"B is the choice","upvote_count":"1","poster":"Jack_in_Large","timestamp":"1589570040.0"},{"upvote_count":"3","timestamp":"1589061600.0","content":"B, Keywords, Resilience=VPN, Remote=Interconnect","comment_id":"86257","poster":"asure"},{"timestamp":"1583922480.0","upvote_count":"2","content":"B is correct as it is using network and VPN","comment_id":"62366","poster":"Javed"},{"upvote_count":"2","comment_id":"44848","content":"Answer: B","poster":"2g","timestamp":"1580397300.0"},{"timestamp":"1580053200.0","comment_id":"42950","upvote_count":"2","content":"i think B","poster":"natpilot"},{"timestamp":"1578130980.0","comment_id":"35186","content":"Well well..... Transfer appliance cannot be used to replicate files....... It is used to MOVE date from On prem to Cloud. C and D speak about \"verify Transfer appliance can replicate files\" which is not possible here. Transfer service should be able to do it but not Transfer appliance. That leaves out with A and B. Of course Dedicated interconnect cannot replicate files but... atleast it can be used as a medium to replicate. I would still stick with B","poster":"MeasService","upvote_count":"2"},{"comment_id":"30613","poster":"passnow","content":"Wake up you all. Dedicated Interconnect is a network. But Transfer Appliance is a physical device that is leased from google for moving data on premise to the cloud. Please read the question and understand before commenting. Thank you","upvote_count":"1","timestamp":"1576671780.0","comments":[{"comment_id":"178595","timestamp":"1599981120.0","upvote_count":"5","poster":"Darahaas","content":"I see most of them agreeing with B. Who's supposed to wake up? :p By the way, I agree with your rationale :). B it is."}]},{"comment_id":"17789","content":"I agree, B. Transfer appliances are like Dedicated Interconnect but not wireless so the connection only occurs after mailing the device. Also the question says that it must connect to GCP, Direct Peering doesn't do that, there is a man in the middle. https://cloud.google.com/interconnect/docs/how-to/direct-peering","poster":"Eroc","upvote_count":"8","timestamp":"1572194040.0"}],"answer":"B","question_id":180,"answer_ET":"B","timestamp":"2019-10-10 11:42:00","choices":{"C":"Verify that the Transfer Appliance can replicate files to GCP. Verify that direct peering can establish a secure connection between your networks if the Transfer Appliance fails.","B":"Verify that Dedicated Interconnect can replicate files to GCP. Verify that Cloud VPN can establish a secure connection between your networks if Dedicated Interconnect fails.","A":"Verify that Dedicated Interconnect can replicate files to GCP. Verify that direct peering can establish a secure connection between your networks if Dedicated Interconnect fails.","D":"Verify that the Transfer Appliance can replicate files to GCP. Verify that Cloud VPN can establish a secure connection between your networks if the Transfer Appliance fails."},"url":"https://www.examtopics.com/discussions/google/view/6399-exam-professional-cloud-architect-topic-1-question-80/","answer_images":[],"answers_community":["B (87%)","13%"],"unix_timestamp":1570700520,"answer_description":"","exam_id":4,"topic":"1"}],"exam":{"lastUpdated":"11 Apr 2025","isBeta":false,"name":"Professional Cloud Architect","id":4,"isMCOnly":false,"numberOfQuestions":279,"isImplemented":true,"provider":"Google"},"currentPage":36},"__N_SSP":true}