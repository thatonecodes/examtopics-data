{"pageProps":{"questions":[{"id":"pQvXdRWpeUdq42cY4HLC","unix_timestamp":1671628920,"url":"https://www.examtopics.com/discussions/google/view/92343-exam-professional-cloud-database-engineer-topic-1-question/","answer":"D","question_text":"Your customer is running a MySQL database on-premises with read replicas. The nightly incremental backups are expensive and add maintenance overhead. You want to follow Google-recommended practices to migrate the database to Google Cloud, and you need to ensure minimal downtime. What should you do?","answer_ET":"D","answers_community":["D (75%)","B (25%)"],"discussion":[{"upvote_count":"8","timestamp":"1694454120.0","comment_id":"836455","poster":"dynamic_dba","content":"D.\nThe question says backups and maintenance are an issue, so moving to a managed service (Cloud SQL) would be the right thing to do. That eliminates C and A. Option B could (depending upon the DB size) require a lot of downtime to export, copy the dump file to Cloud Storage, then import into Cloud SQL. Therefore, the least amount of downtime would be D.\nhttps://cloud.google.com/sql/docs/mysql/replication/configure-replication-from-external"},{"poster":"RaphaelG","upvote_count":"4","timestamp":"1721324880.0","content":"The only issue that I have with the D answer is that an external replica is an explicit Cloud SQL concept not a MySQL concept; external replica is when you have a primary instance already in Cloud SQL, however, if you have your MySQL on premises then you are dealing with replication from an external server. I have read documentation for CloudSQL for MySQL before and I am more convinced with B to be frank","comment_id":"1126146"},{"comments":[{"upvote_count":"1","content":"Yep, D sounds wired, the question said it should import from the on-premise. So my opinion is B","comment_id":"1093336","timestamp":"1718092080.0","poster":"ArtistS"}],"comment_id":"1004046","content":"External replica is a setup with primary on cloud an the replica external to the cloud .eg.e on prem.. which is the reverse of what the question is looking for","timestamp":"1710087180.0","upvote_count":"2","poster":"kkjw"},{"poster":"KennyHuang","upvote_count":"2","timestamp":"1701013800.0","content":"Selected Answer: D\nThis approach provides a seamless migration process with minimal impact on the application's availability.","comment_id":"907406"},{"upvote_count":"2","comment_id":"851111","content":"Selected Answer: D\nAnother good explanation from dynamic_dba.","timestamp":"1695736500.0","poster":"BenMS"},{"poster":"EueChan","content":"Selected Answer: D\nI agree with D","comment_id":"848723","timestamp":"1695501300.0","upvote_count":"2"},{"poster":"H_S","comment_id":"830240","content":"Selected Answer: D\nD is the better option","timestamp":"1693934580.0","upvote_count":"3"},{"content":"Selected Answer: D\nminimal downtime!!! And the customer has read replicas + backups are expensive. \nD is the better option","timestamp":"1693852620.0","poster":"Nirca","comment_id":"829392","upvote_count":"4"},{"upvote_count":"2","content":"Selected Answer: D\nD : External read replica will help achive minimal down time.","poster":"PrtkKA","comment_id":"825488","timestamp":"1693529820.0"},{"upvote_count":"4","timestamp":"1691734560.0","content":"Correct answer is D: Create cloudsql replica of on-prem server and promote with almost-no downtime by pointing app to cloudsql. mysqldump is heavy and time-consuming operation (even though if you run it on on-prem read-replica, it will be identical to migrating to cloudsql using managed database migration service.","comment_id":"805073","poster":"SidsA"},{"poster":"SandyZA","content":"D create a read replica on cloud then promote it","upvote_count":"3","timestamp":"1688625720.0","comment_id":"767423"},{"comment_id":"754735","upvote_count":"2","content":"Selected Answer: B\nB is correct answer","poster":"GCP72","timestamp":"1687583160.0"},{"upvote_count":"3","content":"Selected Answer: B\nhttps://cloud.google.com/database-migration/docs/mysql/mysql-dump","comment_id":"752345","timestamp":"1687346520.0","poster":"range9005"}],"isMC":true,"timestamp":"2022-12-21 14:22:00","choices":{"A":"Create a Google Kubernetes Engine (GKE) cluster, install MySQL on the cluster, and then import the dump file.","D":"Create an external replica, and use Cloud SQL to synchronize the data to the replica.","B":"Use the mysqldump utility to take a backup of the existing on-premises database, and then import it into Cloud SQL.","C":"Create a Compute Engine VM, install MySQL on the VM, and then import the dump file."},"answer_description":"","question_images":[],"answer_images":[],"topic":"1","exam_id":5,"question_id":46},{"id":"7sHmo3YPpCaLiUZQggBB","answer_images":[],"exam_id":5,"topic":"1","answer_ET":"D","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/92127-exam-professional-cloud-database-engineer-topic-1-question/","discussion":[{"poster":"KennyHuang","timestamp":"1685109120.0","upvote_count":"10","comment_id":"907408","content":"Selected Answer: D\nBy combining Google Cloud IoT Core for device management and data ingestion, Google Cloud Bigtable for storing and processing IoT data with low latency, and Looker for advanced analytics and visualization, you can build a highly scalable, multi-cloud compatible, and low-latency solution to address your IoT device maintenance requirements effectively."},{"content":"D.\nThe question says a managed solution, so that eliminates C. Firestore and Spanner do not have the scalability or low latency required. This leaves D. Bigtable by itself is a GCP thing, but Looker allows data visualization across multiple cloud environments. \nhttps://www.looker.com/google-cloud/","upvote_count":"6","comment_id":"836459","timestamp":"1678564440.0","poster":"dynamic_dba"},{"upvote_count":"1","poster":"bad5fad","content":"Selected Answer: C\na multicloud solution is needed and MongoDB Atlas fill all the checks. C is correct","timestamp":"1742004300.0","comment_id":"1395763"},{"comment_id":"1346586","poster":"887ad17","upvote_count":"1","content":"Selected Answer: D\nScalability: Bigtable is a fully managed, highly scalable NoSQL database that can handle large volumes of data with low latency, making it well-suited for real-time data ingestion from thousands of IoT devices.\nLow Latency: Bigtable is designed for high-throughput and low-latency read and write operations, which is essential for real-time data processing and insights.\nMulti-Cloud Strategy: While Bigtable itself is a Google Cloud service, it can integrate with other cloud services and tools, and data can be exported or accessed from other cloud environments if needed.\nIntegration with Looker: Looker is a powerful business intelligence tool that can connect to Bigtable to provide insights and visualizations. This integration allows you to analyze the data and design inspection routines, repair schedules, and replacement schedules based on the insights gathered.","timestamp":"1737828960.0"},{"upvote_count":"2","content":"Selected Answer: D\nManaged solution hence Bigtable is right choice","poster":"rglearn","comment_id":"1303151","timestamp":"1729930920.0"},{"timestamp":"1716101640.0","content":"Selected Answer: D\nAgree with D as You need a managed solution","upvote_count":"2","comment_id":"1213636","poster":"dija123"},{"comment_id":"1203986","content":"Selected Answer: C\nBigtable can't be integrated with looker","poster":"Pime13","upvote_count":"1","timestamp":"1714389720.0"},{"content":"C . As its says to avoid refactoring.","upvote_count":"1","comment_id":"1196129","poster":"Haraprasad","timestamp":"1713198600.0"},{"content":"Selected Answer: D\nGoogle will only pitch its own products","timestamp":"1712213040.0","poster":"okkokkoo","upvote_count":"1","comment_id":"1189135"},{"poster":"james2033","content":"Selected Answer: C\nmulti-cloud","timestamp":"1711624860.0","upvote_count":"1","comment_id":"1184725"},{"poster":"ToniTovar","content":"Selected Answer: D\nI think Looker is multi-cloud as some of the colleagues said in this post. So I choose D.\n\nhttps://services.google.com/fh/files/misc/042420-ppm-multi-cloud-one-sheet-8-5x11-en-web-gc.pdf","comment_id":"1156263","timestamp":"1708593180.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nAs others said, MongoDB is the only one that support multi-cloud (otherwise D is also a candidate).","comments":[{"poster":"gcp_k","comment_id":"1202136","timestamp":"1714061520.0","upvote_count":"1","content":"BigTable is nothing but hbase."}],"comment_id":"1135733","timestamp":"1706615100.0","poster":"PKookNN"},{"comment_id":"1061062","poster":"Ravi_Mangalpally","upvote_count":"4","content":"The answer is D. Use Bigtable with Looker.\n\nBigtable is a fully managed, petabyte-scale NoSQL wide column database service for storing large amounts of data. It is designed for low latency, high throughput, and scalability. Bigtable is a good choice for storing IoT data because it can handle the high volume of data generated by IoT devices and provide low latency for real-time analysis.\n\nLooker is a business intelligence and data analytics platform that can be used to visualize and analyze data stored in Bigtable. Looker provides a variety of features that can be used to design inspection routines, device repair, and replacement schedules based on insights gathered from the data produced by IoT devices. Looker supports hosting on public clouds like AWS and GCP, and in multi-cloud and hybrid environments.","timestamp":"1698983460.0"},{"upvote_count":"4","comment_id":"1017150","poster":"theseawillclaim","content":"Selected Answer: C\n\"Multi-cloud\" is the key that rules out everything except C.","timestamp":"1695668700.0"},{"timestamp":"1688988780.0","upvote_count":"3","poster":"Ramheadhunter","content":"Selected Answer: C\nEvery thing in this question points to D except for one scenario \"multi-cloud\". So just becuase multi cloud is specified, I choose 'C'","comment_id":"948046"},{"upvote_count":"1","poster":"wolfie09","timestamp":"1686731880.0","comment_id":"922893","content":"for everyone saying managed solution is the key, MongoDb is also a managed solution"},{"upvote_count":"2","poster":"somnathmaddi","timestamp":"1683148440.0","content":"Selected Answer: D\nBigtable for IOT stuff","comment_id":"888969"},{"poster":"felipeschossler","content":"Selected Answer: C\nC. Supports Multi-cloud strategy and managed solution. This makes MongoDB Atlas the only option.","upvote_count":"2","timestamp":"1682514180.0","comment_id":"881637"},{"upvote_count":"3","comment_id":"851154","timestamp":"1679841180.0","content":"Selected Answer: C\nThis is a curious question!\n\nThis scenario has BigTable written all over it - large amounts of data from many devices to be analysed in realtime. I would even argue it could qualify as a multicloud solution, given the links to HBASE.\n\nBUT it does not support SQL queries and is not therefore compatible (on its own) with Looker.\n\nFirestore + Looker has the same problem.\n\nSpanner + Data Studio is at least a compatible pairing, but I agree with others that it doesn't fit this use-case - not least because it's Google-native.\n\nBy contrast, MongoDB Atlas is a managed solution (just not by Google) which is compatible with the proposed reporting tool (Mongo's own Charts), it's specifically designed for this type of solution and of course it can run on any cloud.\n\nTherefore the only possible answer is C, even though it isn't a Google product!","poster":"BenMS"},{"content":"Selected Answer: D\nD is the managed solution","comment_id":"848724","upvote_count":"2","poster":"EueChan","timestamp":"1679610960.0"},{"content":"Based on the requirements provided, the best option would be to use Google Cloud's Bigtable with Looker.\n\nBigtable is a highly scalable NoSQL database that can handle massive amounts of IoT data and can support a multi-cloud strategy. It also provides low latency, which is important for real-time data analysis.\n\nLooker is a business intelligence and data analytics platform that can connect to Bigtable to provide insights into the collected IoT data. Looker allows for the creation of custom dashboards and reports, making it easy to identify trends and patterns in the data.\n\nFirestore, Cloud Spanner, and MongoD8 Atlas are also capable solutions for handling large amounts of IoT data, but they may not provide the same level of scalability and low latency as Bigtable. Additionally, Data Studio and Charts are visualization tools that can be used in conjunction with Firestore and MongoD8 Atlas, respectively, but they do not offer the same level of data analysis capabilities as Looker.","timestamp":"1678330440.0","comment_id":"833545","upvote_count":"1","poster":"Hilab"},{"timestamp":"1677963720.0","comment_id":"829408","content":"Selected Answer: C\nC. Is supported for multiple clouds","poster":"Nirca","upvote_count":"1"},{"poster":"leroygordo","content":"Selected Answer: C\nMongoDB Atlas supports \"multi-cloud\" https://www.mongodb.com/atlas/database","upvote_count":"1","comment_id":"828249","timestamp":"1677868320.0"},{"comment_id":"806112","upvote_count":"2","poster":"kvenkatasudhakar","content":"We are missing one key condition \"multi-cloud strategy\". MongoDB Atlas is the only multi-cloud data service available. So, Answer is C","timestamp":"1676190840.0"},{"content":"Selected Answer: A\nA. Google recommend to use Firestore for IoT devices. Not choosing BT due to the device sync problem. Looker could connect to Firestore too.\nReference:\nhttps://cloud.google.com/blog/topics/developers-practitioners/your-google-cloud-database-options-explained\nhttps://www.gox.ai/d/docs/gds/gds-cloud-firestore/cloud-firestore/","timestamp":"1676186940.0","upvote_count":"1","poster":"zanhsieh","comment_id":"806063"},{"upvote_count":"2","poster":"muky31dec","comment_id":"788799","timestamp":"1674743040.0","content":"Selected Answer: C\nAna is C"},{"upvote_count":"1","content":"Ans is C","comment_id":"787871","poster":"muky31dec","timestamp":"1674663540.0"},{"upvote_count":"2","poster":"SVGoogle89","timestamp":"1672259880.0","content":"typo, its C","comment_id":"760308"},{"comment_id":"767833","content":"Correct https://cloud.google.com/looker/docs/dialects","upvote_count":"1","poster":"GCP72","timestamp":"1673018640.0"},{"upvote_count":"1","comment_id":"754748","content":"Selected Answer: D\n100% , D is the correct answer","timestamp":"1671866160.0","poster":"GCP72"},{"poster":"range9005","upvote_count":"1","timestamp":"1671628980.0","comment_id":"752346","content":"Selected Answer: D\nNothing is better than Bigtable for IOT stuff"},{"comments":[{"upvote_count":"1","content":"How Looker can connect to Bigtable ?","poster":"muky31dec","comment_id":"786845","timestamp":"1674587760.0"}],"comment_id":"751412","timestamp":"1671565740.0","upvote_count":"1","content":"Selected Answer: D\nThis is a use case for Bigtable and Looker","poster":"fredcaram"},{"poster":"Kloudgeek","timestamp":"1671480180.0","comment_id":"750212","content":"Correct Answer D: Use Big Table for IOT and Time series Data and Looker for visualization.","upvote_count":"3"}],"question_id":47,"answers_community":["D (53%)","C (44%)","2%"],"timestamp":"2022-12-19 21:03:00","answer_description":"","question_text":"Your team uses thousands of connected IoT devices to collect device maintenance data for your oil and gas customers in real time. You want to design inspection routines, device repair, and replacement schedules based on insights gathered from the data produced by these devices. You need a managed solution that is highly scalable, supports a multi-cloud strategy, and offers low latency for these IoT devices. What should you do?","unix_timestamp":1671480180,"answer":"D","isMC":true,"choices":{"C":"Use MongoD8 Atlas with Charts.","D":"Use Bigtable with Looker.","B":"Use Cloud Spanner with Data Studio.","A":"Use Firestore with Looker."}},{"id":"Fgy6kjfLNNTmMskUWGwD","unix_timestamp":1671480360,"answer_ET":"C","question_images":[],"choices":{"D":"Use many smaller Cloud SQL instances.","B":"Increase the number of CPUs for your instance.","C":"Increase the storage size for the instance.","A":"Use Cloud Spanner instead of Cloud SQL."},"exam_id":5,"topic":"1","discussion":[{"upvote_count":"13","timestamp":"1671480360.0","poster":"Kloudgeek","content":"Correct answer is D. https://cloud.google.com/sql/docs/mysql/best-practices#data-arch - Split your large instances into smaller instances, where possible.","comment_id":"750214"},{"upvote_count":"8","content":"Selected Answer: C\nThe solution D is better if we can execute a massive refactor. So, the best solution is C because if CPU is normal, the issue is the capacity of the I/O. For increase it, it's enough increase the disk storage. \n\nSource: https://cloud.google.com/sql/docs/sqlserver/best-practices","timestamp":"1706195160.0","comment_id":"1131784","poster":"fraloca"},{"upvote_count":"1","comment_id":"1346584","content":"Selected Answer: C\nStorage Size Impact: Increasing the storage size for your Cloud SQL instance can improve performance because Cloud SQL automatically increases the IOPS (Input/Output Operations Per Second) as the storage size increases. This can help resolve performance bottlenecks related to disk I/O, which might be the underlying issue given that CPU utilization is normal.\nNo Major Refactoring: This approach does not require any significant changes to your application architecture or code, making it a straightforward solution.\nScalability: By increasing the storage size, you can ensure that your instance has the necessary IOPS to handle the increasing load as your application grows.","poster":"887ad17","timestamp":"1737828900.0"},{"upvote_count":"1","poster":"rglearn","content":"Selected Answer: C\ncant do major refactoring. also CPU utilization is under control then mostly issue is with IOPS capacity of CloudSQL we need to increase storage space. \nto increase IOPS","comment_id":"1303152","timestamp":"1729931040.0"},{"upvote_count":"1","content":"Selected Answer: D\nd","poster":"TNT87","comment_id":"1300314","timestamp":"1729406640.0"},{"timestamp":"1716646860.0","upvote_count":"1","content":"Selected Answer: C\nAgree with C as the CPU Looks normal.","poster":"dija123","comment_id":"1218366"},{"comment_id":"1105531","poster":"0e75489","timestamp":"1703537280.0","content":"Splitting smaller databases require major effort.\nAnswer should be C","upvote_count":"2"},{"timestamp":"1696248900.0","comment_id":"1023077","content":"Selected Answer: D\nIt's a microservices architecture and CPU utilization is normal. This means that having multiple Cloud SQL instances will help for each microservice.","upvote_count":"2","poster":"juliorevk"},{"content":"Wouldn't D be a big refactoring, as well as switching to Spanner, especially if MySQL is considered?\nThis question is bad.","upvote_count":"2","timestamp":"1695668760.0","comment_id":"1017151","poster":"theseawillclaim"},{"content":"D.\nNeeding to avoid any major refactoring eliminates A. The question states CPU is not an issue, so that eliminates B. Adding more storage would increase IOPS, but there’s no indication network throughput is an issue, so that eliminates C. That leaves D. A microservice architecture is supposed to use a separate database for each microservice, rather than one big database for all the microservices. So D it is. The link provided by Kloudgeek is spot on.","comments":[{"content":"Will splitting single instance to multiple smaller instance amount to re-factoring ?","comment_id":"948052","timestamp":"1688989020.0","poster":"Ramheadhunter","upvote_count":"1"}],"comment_id":"836469","timestamp":"1678565700.0","poster":"dynamic_dba","upvote_count":"6"},{"comment_id":"830246","poster":"H_S","content":"Selected Answer: D\nD: Use many smaller Cloud SQL instances.","upvote_count":"1","timestamp":"1678044660.0"},{"comment_id":"755763","poster":"pk349","upvote_count":"3","content":"D: Use many smaller ***** Cloud SQL instances.","timestamp":"1671981240.0"},{"upvote_count":"1","timestamp":"1671866340.0","poster":"GCP72","content":"Selected Answer: D\nD is the correct answer","comment_id":"754751"},{"comment_id":"752350","poster":"range9005","upvote_count":"2","content":"Selected Answer: D\nSplit CloudSql instance into many small instances to support Microservices","timestamp":"1671629100.0"}],"isMC":true,"answer_images":[],"answer":"C","answer_description":"","question_text":"Your application follows a microservices architecture and uses a single large Cloud SQL instance, which is starting to have performance issues as your application grows. in the Cloud Monitoring dashboard, the CPU utilization looks normal You want to follow Google-recommended practices to resolve and prevent these performance issues while avoiding any major refactoring. What should you do?","url":"https://www.examtopics.com/discussions/google/view/92128-exam-professional-cloud-database-engineer-topic-1-question/","timestamp":"2022-12-19 21:06:00","question_id":48,"answers_community":["C (61%)","D (39%)"]},{"id":"y5YiVCQzgM12y2WwMe5p","answer_images":[],"exam_id":5,"topic":"1","answer_ET":"C","discussion":[{"timestamp":"1721383620.0","poster":"PKookNN","upvote_count":"1","content":"Selected Answer: C\nC is simple and works","comment_id":"1126643"},{"timestamp":"1694456520.0","poster":"dynamic_dba","upvote_count":"3","content":"C.\nThe only way to minimize performance impact of running an export on a Cloud SQL instance is to use a serverless export. The fact that no data synchronization is needed since it’s a one off eliminates every option apart from C.","comment_id":"836476"},{"upvote_count":"1","comment_id":"829413","poster":"Nirca","timestamp":"1693854420.0","content":"Selected Answer: C\nC looks simple and ok."},{"content":"Selected Answer: C\nC - serverless export https://cloud.google.com/sql/docs/mysql/import-export#serverless","timestamp":"1687847280.0","upvote_count":"1","poster":"chelbsik","comment_id":"758273"},{"poster":"pk349","comment_id":"755762","content":"C: Create a SQL dump file in Cloud Storage using a temporary instance, and then use that file to import into a new instance.","upvote_count":"1","timestamp":"1687698780.0"},{"timestamp":"1687584180.0","upvote_count":"1","poster":"GCP72","comment_id":"754753","content":"Selected Answer: C\nC is the correct answer"}],"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/92624-exam-professional-cloud-database-engineer-topic-1-question/","question_id":49,"timestamp":"2022-12-24 08:23:00","answers_community":["C (100%)"],"answer_description":"","question_text":"You need to perform a one-time migration of data from a running Cloud SQL for MySQL instance in the us-central1 region to a new Cloud SQL for MySQL instance in the us-east1 region. You want to follow Google-recommended practices to minimize performance impact on the currently running instance. What should you do?","unix_timestamp":1671866580,"answer":"C","choices":{"B":"Create two Datastream connection profiles, and use them to create a stream from one Cloud SQL instance to another.","C":"Create a SQL dump file in Cloud Storage using a temporary instance, and then use that file to import into a new instance.","A":"Create and run a Dataflow job that uses JdbcIO to copy data from one Cloud SQL instance to another.","D":"Create a CSV file by running the SQL statement SELECT...INTO OUTFILE, copy the file to a Cloud Storage bucket, and import it into a new instance."},"isMC":true},{"id":"Efci7dCIrj3vMt3clIFJ","isMC":true,"unix_timestamp":1671871020,"question_id":50,"answers_community":["B (57%)","A (43%)"],"discussion":[{"comments":[{"content":"This doesn't seem correct:\n\nhttps://www.googlecloudcommunity.com/gc/Databases/Load-Balancer-for-Postgres/m-p/647563#:~:text=To%20clarify%2C%20Google%20Cloud%20Platform%27s,in%20Cloud%20SQL%20for%20PostgreSQL.","timestamp":"1723403700.0","poster":"bigdawg70","comment_id":"1147672","upvote_count":"2"}],"timestamp":"1694458080.0","poster":"dynamic_dba","comment_id":"836495","upvote_count":"11","content":"A.\nEliminate D because Cloud SQL Auth Proxy by itself does not provide connection pooling. There’s nothing in the question about needing to load balance HTTP traffic specifically, so ignore C. B is eliminated on the basis Pgbouncer does not have multi-host configuration, failover, or detection and the question specifically says “mission critical”. That leaves A which makes sense since Google Cloud Load Balancer is a regional service and the question specifically mentions a single region."},{"poster":"Steve8512","comment_id":"1487590","upvote_count":"1","timestamp":"1743795000.0","content":"Selected Answer: A\nhttps://www.pgbouncer.org/faq.html says pgbouncer cannot handle multi-host configs, so B is out. C is out because there's nothing involving HTTP, D is out because the auth proxy does not provide connection pooling."},{"content":"Selected Answer: B\nCloud SQL doesn't provide load balancing between replicas. You can choose to implement load balancing for your Cloud SQL instance. You can also use connection pooling to distribute queries across replicas with your load balancing setup for better performance.\n\nhttps://cloud.google.com/sql/docs/postgres/replication#:~:text=Cloud%20SQL%20doesn't%20provide,balancing%20setup%20for%20better%20performance.&text=You%20can't%20configure%20maintenance%20windows%20on%20a%20read%20replica.","comment_id":"1224321","timestamp":"1733348100.0","upvote_count":"2","poster":"studymoreoften"},{"upvote_count":"1","poster":"Tempingtron","comment_id":"1181303","timestamp":"1727140140.0","content":"Should be A. Pgbouncer needs a load balancer or DNS roundrobin in front of it to operate. It can't route the traffic to multiple hosts without it. C, D are wrong."},{"poster":"Jason_Cloud_at","timestamp":"1724226180.0","upvote_count":"1","comment_id":"1155398","content":"Selected Answer: B\nPgBouncer is especially used to manage connection pools to the PostgreSQL database."},{"poster":"PKookNN","timestamp":"1722333360.0","upvote_count":"3","content":"Selected Answer: B\nCloud Load Balancing can't be used to LB cloud SQL (it's mostly for VM), so you can choose to use HAProxy or PGBouncer as Google recommend connection pooling (https://cloud.google.com/sql/docs/postgres/replication#rr-info)","comment_id":"1135740"},{"timestamp":"1718956560.0","upvote_count":"1","content":"Selected Answer: B\nBy using PgBouncer, you can configure it to distribute the application load between the Cloud SQL primary and read replica instances. PgBouncer will handle connection pooling and load balancing, ensuring efficient utilization of resources and improving performance for your mission-critical application.","poster":"whoosh","comment_id":"1102335"},{"upvote_count":"2","content":"It should be (A). Specifically, you'd (most likely) use a TCP Load balancer \n\nhttps://www.pgbouncer.org/faq.html#how-to-load-balance-queries-between-several-servers\n\n\"PgBouncer does not have an internal multi-host configuration. It is possible via external tools.\"\n\nyou need to frontend stateless pgBouncer instances with a TCP load balancer.","comment_id":"1081835","poster":"AngieSoccerBall49","timestamp":"1716824340.0"},{"timestamp":"1715613240.0","poster":"Jay_Krish","comment_id":"1069550","upvote_count":"1","content":"Selected Answer: B\nPgBouncer (Option B): PgBouncer is a lightweight connection pooler for PostgreSQL that can efficiently manage and distribute database connections between the primary and read replica instances. It helps in load balancing the application traffic between the instances."},{"comment_id":"907415","upvote_count":"2","poster":"KennyHuang","content":"Selected Answer: B\nBy using PgBouncer, you can configure it to distribute the application load between the Cloud SQL primary and read replica instances. PgBouncer will handle connection pooling and load balancing, ensuring efficient utilization of resources and improving performance for your mission-critical application.","timestamp":"1701014280.0"},{"timestamp":"1695741840.0","poster":"BenMS","comment_id":"851208","content":"Selected Answer: A\nAs others have said, A is the only option which could achieve the desired effect, providing TCP load balancing across multiple servers.","upvote_count":"3"},{"upvote_count":"2","timestamp":"1693899900.0","content":"Selected Answer: A\nA, I think is better. \nHAProxy is not same as Cloud Load balancing.","comment_id":"829804","poster":"Nirca"},{"content":"Selected Answer: B\nConnection pooling !","timestamp":"1693615320.0","poster":"PrtkKA","upvote_count":"2","comment_id":"826421"},{"upvote_count":"4","timestamp":"1691492580.0","comments":[{"content":"HAProxy is not same as Cloud Load balancing.","poster":"PrtkKA","comment_id":"826419","comments":[{"comment_id":"881647","content":"I think in the same way, it's not the same thing. However pgBouncer is not recommended for Load Balancing, just for connection pooling 🙏","timestamp":"1698326040.0","poster":"felipeschossler","upvote_count":"1"}],"timestamp":"1693615260.0","upvote_count":"1"}],"content":"Selected Answer: A\nhttps://cloud.google.com/blog/products/databases/using-haproxy-to-scale-read-only-workloads-on-cloud-sql-for-postgresql","poster":"Teraflow","comment_id":"802042"},{"content":"A is the best answer, PgBouncer does not have multi-host","poster":"JayGeotab","timestamp":"1690493640.0","upvote_count":"2","comment_id":"790067"},{"content":"Per GPC72's referenced link, you need PgBouncer only does connection pooling, need Load balancing coupled. Since Load Balancing not referenced in B., is not A the best answer?\n\n PgBouncer is a popular connection pooler designed for PostgreSQL, but it is not enough to achieve PostgreSQL High Availability by itself as it doesn’t have multi-host configuration, failover, or detection.\n\nUsing a Load Balancer is a way to have High Availability in your database topology. It could be useful for redirecting traffic to healthy database nodes, distribute the","comments":[{"comment_id":"762102","comments":[{"poster":"sp57","timestamp":"1688134140.0","content":"https://cloud.google.com/blog/products/databases/using-haproxy-to-scale-read-only-workloads-on-cloud-sql-for-postgresql","upvote_count":"1","comment_id":"762105"}],"timestamp":"1688134020.0","poster":"sp57","content":"And C & D are wrong because they don't pool connections. ref for refuting C...The load balancer doesn’t store database credentials (except for the health check user), and it doesn’t pool or decrypt/re-encrypt database connections. A single client connection in HAProxy translates to a single client connection in Postgres. \n\nThis approach is suitable when the workload is constrained by the database’s processing capacity, and not by the number of client connections. You may require an additional connection pooling component (e.g. PgBouncer) if the number of clients becomes an issue, for example, when the database instances exhibit performance or stability issues due to the sheer number of simultaneous database connections.","upvote_count":"1"}],"poster":"sp57","upvote_count":"3","timestamp":"1688133060.0","comment_id":"762090"},{"content":"PgBouncer is a light-weight connection pool manager for Greenplum and PostgreSQL. PgBouncer maintains a pool for connections for each database and user combination. PgBouncer either creates a new database connection for a client or reuses an existing connection for the same user and database.","upvote_count":"1","comment_id":"755761","timestamp":"1687698720.0","poster":"pk349"},{"upvote_count":"1","poster":"GCP72","timestamp":"1687588620.0","content":"Selected Answer: B\nB is the correct answer\nhttps://severalnines.com/blog/how-achieve-postgresql-high-availability-pgbouncer/","comment_id":"754771"}],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/92625-exam-professional-cloud-database-engineer-topic-1-question/","answer":"B","timestamp":"2022-12-24 09:37:00","choices":{"C":"Use HTTP(S) Load Balancing for database connection pooling between the Cloud SQL primary and read replica instances.","D":"Use the Cloud SQL Auth proxy for database connection pooling between the Cloud SQL primary and read replica instances.","B":"Use PgBouncer to set up database connection pooling between the Cloud SQL primary and read replica instances.","A":"Use Cloud Load Balancing for load balancing between the Cloud SQL primary and read replica instances."},"answer_ET":"B","question_text":"You are running a mission-critical application on a Cloud SQL for PostgreSQL database with a multi-zonal setup. The primary and read replica instances are in the same region but in different zones. You need to ensure that you split the application load between both instances. What should you do?","question_images":[],"answer_images":[],"topic":"1","exam_id":5}],"exam":{"isImplemented":true,"isMCOnly":true,"isBeta":false,"numberOfQuestions":132,"lastUpdated":"11 Apr 2025","id":5,"provider":"Google","name":"Professional Cloud Database Engineer"},"currentPage":10},"__N_SSP":true}