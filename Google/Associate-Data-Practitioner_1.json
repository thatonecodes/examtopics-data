{"pageProps":{"questions":[{"id":"ykpuliFtOzzakh4f7w8h","answer":"B","answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/155225-exam-associate-data-practitioner-topic-1-question-1/","question_images":[],"isMC":true,"timestamp":"2025-01-22 13:37:00","topic":"1","exam_id":2,"question_text":"Your retail company wants to predict customer churn using historical purchase data stored in BigQuery. The dataset includes customer demographics, purchase history, and a label indicating whether the customer churned or not. You want to build a machine learning model to identify customers at risk of churning. You need to create and train a logistic regression model for predicting customer churn, using the customer_data table with the churned column as the target label. Which BigQuery ML query should you use?","question_id":1,"answers_community":["B (100%)"],"discussion":[{"comment_id":"1365743","content":"Selected Answer: B\nThe best option is B. Option B is best because it correctly selects all columns as features except the churned column, and then explicitly designates the churned column as the label for BigQuery ML, which is required for training. Option A (SELECT *) is incorrect because while it includes the churned column, it doesn't explicitly define it as the label. Option C (SELECT * EXCEPT(churned)) is incorrect because it excludes the target churned column, which is essential for training a supervised model. Option D (SELECT churned as label) is incorrect because it only selects the label and excludes all feature columns needed for prediction. Therefore, Option B is the only query that correctly sets up the data for BigQuery ML logistic regression training.","upvote_count":"1","timestamp":"1741236600.0","comments":[{"poster":"baviru","content":"You can use SELECT * EXCEPT (foo) and SELECT foo AS bar.\nhttps://ln.run/dFRAn","upvote_count":"1","timestamp":"1742368920.0","comment_id":"1400412"}],"poster":"n2183712847"},{"upvote_count":"2","poster":"trashbox","comment_id":"1344739","content":"Selected Answer: B\nYou can use SELECT * EXCEPT (foo) and SELECT foo AS bar.","timestamp":"1737549420.0"}],"choices":{"D":"-------------------------","C":"-------------------------","B":"-------------------------","A":"-------------------------"},"unix_timestamp":1737549420,"answer_ET":"B"},{"id":"8HJgy5R7uinM3zrOx9oY","url":"https://www.examtopics.com/discussions/google/view/157240-exam-associate-data-practitioner-topic-1-question-10/","question_text":"Another team in your organization is requesting access to a BigQuery dataset. You need to share the dataset with the team while minimizing the risk of unauthorized copying of data. You also want to create a reusable framework in case you need to share this data with other teams in the future. What should you do?","topic":"1","exam_id":2,"discussion":[{"poster":"JAGLees","comment_id":"1411733","upvote_count":"1","content":"Selected Answer: B\nEither Authorized Views or Analytics Hub could be reasonable, but I feel the mention of reusable framework and preventing data copying are pushing towards Analytics Hub woth egress restrictions","timestamp":"1743260700.0"},{"comment_id":"1402085","upvote_count":"1","timestamp":"1742688900.0","content":"Selected Answer: A\nComparing the options, A (authorized views) and B (Analytics Hub) both seem great for job, authorized views are often a straightforward and effective way to share data while controlling access and minimizing copying.\n\nI've choosing so far Authorized views for internal sharing and Analytics hub for external sharing.","poster":"Rio55"},{"upvote_count":"2","content":"Selected Answer: A\nWhile Analytics Hub (Option B) is a powerful data sharing platform, Authorized Views (Option A) are the superior choice for this specific scenario of sharing a BigQuery dataset with another internal team while prioritizing minimizing unauthorized copying and ease of implementation. Authorized Views are simpler, more secure against data copying for internal use cases, easier to implement, and more cost-effective for this particular need.\n\nI think it could be B or A, but I believe that analytics hub is mainly for sharing with an outside organization userbase.","timestamp":"1740678780.0","poster":"n2183712847","comment_id":"1362667"}],"answers_community":["A (75%)","B (25%)"],"timestamp":"2025-02-27 18:53:00","answer_ET":"A","answer":"A","question_images":[],"unix_timestamp":1740678780,"answer_images":[],"answer_description":"","choices":{"D":"Export the dataset to a Cloud Storage bucket in the team’s Google Cloud project that is only accessible by the team.","B":"Create a private exchange using Analytics Hub with data egress restriction, and grant access to the team members.","C":"Enable domain restricted sharing on the project. Grant the team members the BigQuery Data Viewer IAM role on the dataset.","A":"Create authorized views in the team’s Google Cloud project that is only accessible by the team."},"isMC":true,"question_id":2},{"id":"PTQmRVK8MceeRgsaPMkT","question_images":[],"answers_community":["A (100%)"],"discussion":[{"timestamp":"1738755480.0","upvote_count":"5","poster":"trashbox","comments":[{"poster":"Pubb","comment_id":"1401020","timestamp":"1742473500.0","content":"I chose \"A\" too, because the problem does not describe any specific lifecycle policy.","upvote_count":"1"}],"content":"Selected Answer: A\nI will go with \"A\" because it should be automatically optimized based on actual access patterns.","comment_id":"1351836"},{"content":"Selected Answer: A\nCan anyone please share the complete question set.\nIf you already have please share it over tiwariamarnath77@gmail.com.\n\nThanks already for the community support.","timestamp":"1742971740.0","upvote_count":"1","comment_id":"1410264","poster":"AmarT"},{"poster":"Rio55","content":"Selected Answer: A\nIt's A because of the old video files that can remain popular","timestamp":"1742689140.0","comment_id":"1402087","upvote_count":"1"},{"poster":"n2183712847","comment_id":"1362666","content":"Selected Answer: A\nA. Autoclass makes the most sense for some files accessed and shared less frequently, with some old video files remaining popular.","timestamp":"1740678660.0","upvote_count":"2"},{"timestamp":"1740311880.0","comment_id":"1360482","content":"Selected Answer: A\nAutoclass is a feature of Google Cloud Storage that automatically optimizes the storage class for objects based on their access patterns. When objects are newly uploaded and frequently accessed, Autoclass will place them in a more performant (and more expensive) storage class, like Standard. Over time, if access to the objects decreases, Autoclass will automatically transition them to a lower-cost storage class, such as Nearline, Coldline, or Archive, depending on their access frequency.\nThis solution is simple, cost-effective, and does not require manual management or custom lifecycle rules. It automates the optimization of storage classes without the need for any additional processes or scheduling jobs.","upvote_count":"1","poster":"jatinbhatia2055"}],"topic":"1","answer_ET":"A","isMC":true,"choices":{"B":"Create a single-region bucket. Configure a Cloud Scheduler job that runs every 24 hours and changes the storage class based on upload date.","A":"Create a single-region bucket with Autoclass enabled.","D":"Create a single-region bucket with Archive as the default storage class.","C":"Create a single-region bucket with custom Object Lifecycle Management policies based on upload date."},"question_text":"Your company has developed a website that allows users to upload and share video files. These files are most frequently accessed and shared when they are initially uploaded. Over time, the files are accessed and shared less frequently, although some old video files may remain very popular.\nYou need to design a storage system that is simple and cost-effective. What should you do?","question_id":3,"unix_timestamp":1738755480,"answer_description":"","timestamp":"2025-02-05 12:38:00","exam_id":2,"url":"https://www.examtopics.com/discussions/google/view/155979-exam-associate-data-practitioner-topic-1-question-11/","answer_images":[],"answer":"A"},{"id":"lIxiF2x7WcTka6ugwzd4","question_id":4,"answer_images":[],"isMC":true,"answers_community":["A (83%)","C (17%)"],"url":"https://www.examtopics.com/discussions/google/view/157024-exam-associate-data-practitioner-topic-1-question-12/","timestamp":"2025-02-23 13:01:00","answer_ET":"A","answer_description":"","question_text":"You recently inherited a task for managing Dataflow streaming pipelines in your organization and noticed that proper access had not been provisioned to you. You need to request a Google-provided IAM role so you can restart the pipelines. You need to follow the principle of least privilege. What should you do?","exam_id":2,"topic":"1","question_images":[],"unix_timestamp":1740312060,"discussion":[{"comment_id":"1402088","content":"Selected Answer: A\nA and D would work but because to follow the principle of least privilege, we're going to choose A, Dataflow developer.","timestamp":"1742689380.0","upvote_count":"1","poster":"Rio55"},{"content":"Selected Answer: A\nThe best option is A. Request the Dataflow Developer role. Requesting the Dataflow Developer role is optimal because it grants the necessary permissions to restart Dataflow pipelines, aligning with the user's need, while adhering to the principle of least privilege by providing a focused set of permissions. Option B (Dataflow Viewer) is insufficient as it only provides read-only access and lacks the permission to restart pipelines. Option C (Dataflow Worker) is incorrect as it is intended for service accounts, not user access, and doesn't grant pipeline management permissions. Option D (Dataflow Admin) is excessive, granting far more permissions than needed for simply restarting pipelines, thus violating the principle of least privilege. Therefore, Option A is the clear and correct choice for requesting the minimum necessary IAM role to restart Dataflow pipelines.","timestamp":"1740678360.0","comment_id":"1362665","upvote_count":"4","poster":"n2183712847"},{"poster":"jatinbhatia2055","upvote_count":"1","timestamp":"1740312060.0","comment_id":"1360483","content":"Selected Answer: C\nDataflow Worker provides the necessary permissions for managing and interacting with Dataflow streaming pipelines, including restarting them. This role gives you the ability to execute and manage the pipelines without granting excessive permissions, aligning with the principle of least privilege."}],"choices":{"A":"Request the Dataflow Developer role.","D":"Request the Dataflow Admin role.","C":"Request the Dataflow Worker role.","B":"Request the Dataflow Viewer role."},"answer":"A"},{"id":"ZSijLZC8l5LYv8T0ccco","timestamp":"2025-02-27 18:44:00","answer_ET":"D","isMC":true,"choices":{"B":"1. Cloud Composer\n2. Cloud SQL for MySQL","A":"1. Dataproc Serverless\n2. Bigtable","C":"1. BigQuery\n2. Analytics Hub","D":"1. Dataflow\n2. BigQuery"},"question_id":5,"answer_description":"","answer":"D","exam_id":2,"question_text":"You need to create a new data pipeline. You want a serverless solution that meets the following requirements:\n• Data is streamed from Pub/Sub and is processed in real-time.\n• Data is transformed before being stored.\n• Data is stored in a location that will allow it to be analyzed with SQL using Looker.\n//IMG//\n\nWhich Google Cloud services should you recommend for the pipeline?","question_images":["https://img.examtopics.com/associate-data-practitioner/image9.png"],"unix_timestamp":1740678240,"url":"https://www.examtopics.com/discussions/google/view/157239-exam-associate-data-practitioner-topic-1-question-13/","discussion":[{"comment_id":"1362664","content":"Selected Answer: D\npubsub, dataflow, bigquery, looker\nthis architecture is very common in GCP.","upvote_count":"3","timestamp":"1740678240.0","poster":"n2183712847"}],"answer_images":[],"topic":"1","answers_community":["D (100%)"]}],"exam":{"isImplemented":true,"id":2,"lastUpdated":"11 Apr 2025","isBeta":false,"name":"Associate Data Practitioner","numberOfQuestions":72,"provider":"Google","isMCOnly":true},"currentPage":1},"__N_SSP":true}