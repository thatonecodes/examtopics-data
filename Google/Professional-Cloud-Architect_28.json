{"pageProps":{"questions":[{"id":"9ge55AsvaoPlhdcGlEv8","question_id":136,"question_images":[],"isMC":true,"timestamp":"2019-10-25 19:17:00","url":"https://www.examtopics.com/discussions/google/view/7211-exam-professional-cloud-architect-topic-1-question-40/","answer_description":"","topic":"1","discussion":[{"upvote_count":"36","poster":"mawsman","content":"It's latency issues. That won't be solved by adding another VPN tunnel. If it was just a throughput issue then VPN would do, however to improve latency you need to go layer 2. Answer is B","comment_id":"52292","timestamp":"1582070400.0"},{"poster":"chiar","timestamp":"1573817460.0","content":"I think B is correct. I think it is more reliable.","upvote_count":"30","comment_id":"21763"},{"timestamp":"1733335080.0","content":"Selected Answer: B\nAdding VPN connections may improve bandwidth but does not resolve latency or packet loss issues caused by public internet routing... though not mentioned, we must 'think' beyond the scope of the question and ask 'what is causing the latency'... \n\nAnswer B.","upvote_count":"1","poster":"desertlotus1211","comment_id":"1322038"},{"comment_id":"1314168","timestamp":"1731957120.0","upvote_count":"3","content":"Selected Answer: B\n1. Dedicated Interconnect for high performance: Dedicated Interconnect provides a direct physical connection between your on-premises network and Google Cloud. This offers significantly lower latency, higher bandwidth, and greater reliability compared to a VPN. It's ideal for demanding workloads like database replication.\n\n2. Reduced latency and packet loss: By bypassing the public internet, Dedicated Interconnect minimizes latency and packet loss, ensuring consistent and efficient data transfer for your MySQL replication.\n\n3. Enhanced reliability: Dedicated Interconnect provides a more stable and predictable connection compared to a VPN, which can be affected by internet traffic fluctuations.\n\nWhy D is not correct: Add additional VPN connections and load balance them: This might improve bandwidth slightly but won't address the fundamental latency and packet loss issues inherent with VPNs over the public internet.","poster":"Ekramy_Elnaggar"},{"content":"Selected Answer: B\nIt's B, Interconnect.\nD is wrong in this case: While this might help distribute traffic, it won't solve the underlying issue of latency and packet loss caused by the inherent limitations of VPNs.","upvote_count":"2","timestamp":"1716103560.0","comment_id":"1213647","poster":"19040e5"},{"upvote_count":"2","poster":"AWS_Sam","comment_id":"1117127","content":"Dedicated interconnect is the answer. A second VPN will give you an HA solution, not going to resolve the latency.","timestamp":"1704760020.0"},{"comment_id":"1113398","timestamp":"1704354660.0","content":"Selected Answer: E\nHave you mind the budget you'll need to improve network infrastructure - whether it's dedicated interconnect or duplicating VPN connection? Mega IT corps may can afford, but I won't approve the work just for disaster recovery plan, if I were the authority. It's definatedly overkill.\nMain problem here is a latency issue and/or packet loss, yet the reason hasn't clearly configured. Whether it's occational, or repeatetive, and/or by DB engine or by network, mostly unknown. But you don't have to solve the problem if there's better bypass. Simply retry and test it. There C also can be a solution (which likely being placed already), but it doesn't have significant feature for logging a transaction success/fail. If you take advance Pub/Sub, you can track each transaction processes. Ordering, can adding another issue, but it worth a try - cost effectively.","upvote_count":"2","poster":"[Removed]"},{"poster":"Roro_Brother","content":"Selected Answer: B\nCorrect answer is B as its a latency issue.","timestamp":"1702977300.0","comment_id":"1100459","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: B\nI go for B.\nLatency won't be solved by adding new VPN tunnels.","comment_id":"1094878","timestamp":"1702409880.0","poster":"stefanop"},{"upvote_count":"6","content":"Selected Answer: D\nWe have something called as HAVPN which uses 2 VPN Connections at a time. As this Question is old. we dont have this Option called use HAVPN. Now its Updated so the answer will be D. As its just a replication for disaster recovery and they are facing very minimal challenges","comment_id":"1006761","poster":"Demo_Helloworld","timestamp":"1694619360.0"},{"timestamp":"1677992820.0","content":"I think the best option is E, using PubSub. In question the main issue is \" a small amount of packet loss\". As per google PubSub documentation, data replication among databases is one of the common use case of PubSub. The asynchronously communication of PubSub can overcome small latency issues. Setting up dedicated interconnect would be very costly and required many pre-requisites.","poster":"SandipGhosal","comment_id":"829643","upvote_count":"3"},{"upvote_count":"1","comment_id":"827582","timestamp":"1677807000.0","poster":"Shawnn","content":"You could technically use your private key to encrypt a message, but it would not be secure because anyone who has your public key could decrypt the message. The recommended practice is to use your private key only for decryption and to use the recipient's public key for encryption.\n\nI vote for D"},{"poster":"SirajShan","upvote_count":"1","timestamp":"1677774720.0","comment_id":"827106","content":"Configuring a Google Cloud Dedicated Interconnect requirement for company is a proximity to colocation facility and meeting condition to have dedicated interconnect. Had this was possible why did they used Cloud VPN in the first place ? I think answer should be D."},{"timestamp":"1673515440.0","comment_id":"773306","upvote_count":"2","poster":"n_nana","content":"If i face this issue, I will give a try with additional VPN, decision using VPN, maybe because they need encryption as well. With switching to dedicated interconnect, you have to implement your own VPN solution or application encryption. so it need more anaylsis to just skip VPN and use dedicated interconnect solution."},{"poster":"omermahgoub","timestamp":"1671609660.0","upvote_count":"2","comment_id":"751993","content":"The company should consider configuring a Google Cloud Dedicated Interconnect. A Google Cloud Dedicated Interconnect provides a private connection between the company's on-premises data center and GCP, which can help to reduce latency and improve the reliability of the connection. This can be particularly useful for replicating large amounts of data or for applications that require low-latency connectivity.\n\nOption A, configuring the replication to use UDP, would not necessarily improve the reliability of the connection, as UDP is a connectionless protocol that does not guarantee delivery of packets.\n\nOption C, restoring the database daily using Google Cloud SQL, would not address the underlying issues with the replication process.","comments":[{"content":"Option D, adding additional VPN connections and load balancing them, may help to improve the reliability of the connection by providing redundancy, but it may not necessarily address latency issues.\n\nOption E, sending the replicated transaction to Google Cloud Pub/Sub, could potentially help to improve the reliability of the replication process by allowing the company to handle failures and retries in a more structured way, but it would not necessarily address latency issues.\n\nOverall, configuring a Google Cloud Dedicated Interconnect is likely to be the most effective solution for addressing latency issues and packet loss in the replication process.","timestamp":"1671609660.0","poster":"omermahgoub","comments":[{"poster":"VSMu","content":"Why focus on latency when the solution is for disaster recovery? The main issue is packet loss. While this can be solved with Dedicated Interconnect or Cloud Pub/Sub, PubSub seems like a cheaper alternative that prevents data loss and achieves reliability. I wouldn't care about latency as the backup is only for DA.. so how does it matter if it goes slowly?","upvote_count":"3","comments":[{"content":"Because latency and packet loss are probably coming from traffic going over public internet. This is the Cloud VPN definition from the public documentation:\n\n\"Cloud VPN securely extends your peer network to Google's network through an IPsec VPN tunnel. Traffic is encrypted and travels between the two networks over the public internet. Cloud VPN is useful for low-volume data connections.\"\n\n\nThere are documents showing what happens when public internet is used, but basically there's no way to prevent information from going through multiple hops over the internet, which is why Dedicated Interconnect should work. Plus, VPN is recommended for low-volume data connections, and I highly doubt that replicating a database is considered a low-volume operation. \n\nI'm going with B: using Cloud Dedicated Interconnect.","timestamp":"1696732380.0","poster":"jrisl1991","comment_id":"1027683","upvote_count":"2"}],"comment_id":"794623","timestamp":"1675199580.0"}],"upvote_count":"1","comment_id":"751994"}]},{"comment_id":"717332","timestamp":"1668346680.0","content":"so just to solve this issue we are going over a Dedicated Interconnect imagine saying this to a your project head.","upvote_count":"4","poster":"ashrafh"},{"content":"Selected Answer: B\nok for B","upvote_count":"2","comment_id":"711849","poster":"megumin","timestamp":"1667662020.0"},{"content":"This is straight forward question, B is right. Dedicated line solves latency issues","poster":"AzureDP900","upvote_count":"2","timestamp":"1665953880.0","comment_id":"696567"},{"upvote_count":"1","content":"Latency issue - Dedicated Interconnect solves the issue","comment_id":"618118","timestamp":"1655537100.0","poster":"Dhiraj03"},{"comment_id":"493629","poster":"haroldbenites","timestamp":"1638612000.0","content":"Go for B","upvote_count":"6"},{"upvote_count":"4","poster":"TheCloudBoy77","timestamp":"1637317740.0","content":"Selected Answer: B\nCorrect answer is B as its a latency issue.","comment_id":"481565"},{"content":"B is the correct answer.","timestamp":"1637299260.0","comment_id":"481350","upvote_count":"2","poster":"vincy2202"},{"upvote_count":"5","content":"B – Configure Google Cloud Dedicated Interconnect\nCompany can buy 10G interconnect link ($1700 monthly) with 99.9% SLA. It’s comparatively small budget for reliable migration of DB. Only requirement for company is a proximity to colocation facility (peering edge network).\nA – UDP is non-reliable, doesn’t guarantee delivery\nC – daily replication doesn’t solve problem at all (could be temp workaround), also no improvement in bandwidth, so replication may fail also.\nD – adding VPN tunnels (1.5Gbps x N) could improve the situation (but not VPN connections, which are somehow “load balanced”)\nE – using Cloud Pub/Sub is awkward solution. Would require extra protocol overhead for this Proxy service.","timestamp":"1635143160.0","comment_id":"467276","poster":"MaxNRG"},{"upvote_count":"1","content":"Answer is B","timestamp":"1625741340.0","comment_id":"401803","poster":"MamthaSJ"},{"comment_id":"393155","poster":"kopper2019","upvote_count":"2","timestamp":"1624903080.0","content":"hey guys check Q3 for new Qs, 49 New Qs"},{"content":"B is correct option.\nAdditional VPN will only provide HA it will not solve latency issue","poster":"aviratna","timestamp":"1624772880.0","comment_id":"391777","upvote_count":"1"},{"comments":[{"upvote_count":"1","content":"https://cloud.google.com/solutions/building-high-throughput-vpns","timestamp":"1625937840.0","comment_id":"403456","poster":"RKS_2021","comments":[{"timestamp":"1625938020.0","upvote_count":"1","content":"Building High-throughput VPNs\nThis tutorial shows how to create secure, high-throughput VPNs and test their speed.\n\nSecure communication between Google Cloud and other clouds or on-premises systems is a common, critical need. Fortunately, Google Cloud makes it easy for you to create secure Internet Protocol security (IPsec) virtual private networks (VPNs) to achieve this goal. If a single tunnel does not provide necessary throughput, Google Cloud can smoothly distribute traffic across multiple tunnels to provide additional bandwidth.","comment_id":"403457","poster":"RKS_2021"}]}],"upvote_count":"2","comment_id":"361076","poster":"victory108","timestamp":"1621405380.0","content":"B. Configure a Google Cloud Dedicated Interconnect."},{"comment_id":"355353","upvote_count":"1","poster":"un","content":"B is correct","timestamp":"1620803640.0"},{"content":"Answer is B.","timestamp":"1620049380.0","upvote_count":"1","poster":"Koushick","comment_id":"348665"},{"timestamp":"1617165960.0","content":"Answer is B","comment_id":"324729","upvote_count":"1","poster":"Ausias18"},{"poster":"ashish9_a","comment_id":"318450","content":"Latency is the keyword here","timestamp":"1616531280.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"276545","timestamp":"1611631200.0","poster":"bnlcnd","content":"Cloud VPN is not for performance or high load traffic. Have to use inter-connect for DB replication kind of work."},{"timestamp":"1607316360.0","upvote_count":"3","content":"B is right.\n\nAdding additional tunnels only help if you have the bandwidth to support it. The latency is likely a result of an unreliable connection, which additional tunnels will not help with.\n\nFrom the description, the primary fault lies in the fact that their connection is too slow and unreliable. A Dedicated Interconnect will give them the speed and reliability they need to complete the transfer.","comment_id":"236985","poster":"cate0012"},{"content":"I think B also, the other options make it be more complicated","upvote_count":"1","comment_id":"226299","timestamp":"1606185180.0","poster":"Xolex"},{"content":"I think you must always try to make things work with what ever is in place, also in the most efficient way (cost and implementation complexity). I don't think a sql replica would justify changing vpn for interconnect. Specially considering that after intial replication is done, no high throughput would but needed. As they don't give details about the sql database size, nor how ofter it's updated, I will choose D.","comment_id":"210605","poster":"mexblood1","timestamp":"1604248560.0","upvote_count":"2"},{"poster":"rungcpnow","upvote_count":"3","content":"Well this leads to ambiguity. The solution really depends on what we want. Ideally DB replication is recommended to happen via MPLS or P2P link in our case its cloud interconnect. Irrespective of no of tunnels , you will still encounter the latency even if you have ipsec tunnels in our case [cloud vpn tunnels]. But adding tunnels is quick turn around which might decrease the latency issue however will not solve it completely. \nI'll go with D.","timestamp":"1603150080.0","comment_id":"202869"},{"timestamp":"1601472240.0","upvote_count":"1","comments":[{"comment_id":"862804","content":"But how does second VPN improve latency???","poster":"medi01","timestamp":"1680773100.0","upvote_count":"1"}],"content":"Google Cloud Dedicated Interconnect requires a lot of leg work and some additional equipment: \nYou'll configure and test the connections with Google before you can use them. After they're ready, you can create VLAN attachments to allocate a VLAN on the Cloud Interconnect connection.\nThe questing states, \"xeperiencing latency issues and a small amount of packet loss\"\nFor latency issue and small packet loss I'd say a second VPN + Load balancer.","comment_id":"190364","poster":"f0x"},{"upvote_count":"4","content":"The company has VPN already why I need to change it to dedicated network rather than I can increase VPN tunnels to increase the performance. I would choose D as my best answer","poster":"Firask","timestamp":"1601319300.0","comment_id":"189241"},{"comment_id":"179594","content":"B is meaningful over D","timestamp":"1600132980.0","poster":"AshokC","upvote_count":"1"},{"upvote_count":"2","poster":"droidmasta","content":"VPN uses the public internet, which introduces multiple points of failure for scenarios such as packet loss which is happening in this case, that even without hitting the maximum bandwidth of VPN connections.\nInterconnect removes those points of failure by establishing a direct connection to google.","comment_id":"164461","timestamp":"1598193180.0"},{"comments":[{"comment_id":"168923","timestamp":"1598673780.0","upvote_count":"2","content":"but the question did not ask for cost effective solution so we need to look for reliability","poster":"dayody"},{"content":"But even a small amount of packets loss cause disrupting replication...\nSo - IMO - B is ok.","upvote_count":"1","comment_id":"325648","timestamp":"1617266460.0","poster":"lynx256"}],"upvote_count":"1","poster":"wiqi","comment_id":"162390","content":"B is way more expensive than having 'small amount of packet loss'\nAdding a VPN connection would increase the overall throughput by means of load balancing through different connection and hence would reduce latency and packet loss.\n\nD is a better and more suited answer here.","timestamp":"1597944540.0"},{"content":"B is the correct answer","comment_id":"114554","poster":"Tushant","upvote_count":"3","timestamp":"1592637360.0"},{"timestamp":"1592150940.0","upvote_count":"5","comment_id":"110235","content":"Correct Answer is B\nAdditional VPN connection / tunnel will not solve the latency issues and packet loss as it will still be un-reliable one using public internet.\nBasically a reliable connection is needed ie Dedicated Interconnect.","poster":"shashu07","comments":[{"timestamp":"1598673660.0","poster":"dayody","comment_id":"168921","upvote_count":"1","content":"yes correct, additional vpn will not solve the problem"}]},{"comment_id":"100936","poster":"Nirms","upvote_count":"2","content":"Both B and D will work. However, this is part of DR plan so i am going with option D. That would solve and it is cost effective solution.","timestamp":"1591109880.0"},{"timestamp":"1590781500.0","poster":"Ziegler","content":"B is the answer as that guarantee a premium network connection","comment_id":"98459","upvote_count":"1"},{"upvote_count":"3","comment_id":"97341","content":"Final Decision to go with Option B","timestamp":"1590651540.0","poster":"AD2AD4"},{"content":"B is the answer for me","comment_id":"93601","upvote_count":"2","timestamp":"1590094380.0","poster":"gcp_aws"},{"poster":"nrajesh","comment_id":"76957","upvote_count":"1","comments":[{"timestamp":"1591475880.0","upvote_count":"1","content":"you are right but question does not say the most cost effective solution so B is the answer","comment_id":"104096","poster":"rbrto"}],"timestamp":"1587385800.0","content":"If there is not enough bandwidth there will be latency issues. It can be solved by B or D. D will be a more cost-effective solution"},{"upvote_count":"2","comment_id":"57430","content":"Agreed:B. Selected B in the exam","poster":"[Removed]","timestamp":"1583109240.0"},{"timestamp":"1580391600.0","comment_id":"44752","poster":"2g","content":"answer: B","upvote_count":"2"},{"upvote_count":"4","timestamp":"1579045380.0","content":"Adding more VPN connections would require the load balancing requirements. May be they do not have the Load Balancer today. It also adds complexity in terms of replication and syncronizations issues. \n\nDedicated Internet meaning they have more throughput and reliable connectivity, which essentially means to have stable replication without packet drops.\n\nSo I will pick \"B\"","poster":"asfar","comment_id":"39158"},{"timestamp":"1578830460.0","poster":"AWS56","comment_id":"37988","content":"I don't know if you can have multiple VPN connections and load balance them, however as per https://cloud.google.com/solutions/migrating-mysql-to-cloudsql-concept, I believe B would be the best choice.","upvote_count":"5"},{"comment_id":"29621","comments":[{"poster":"hc","comment_id":"32412","content":"private data center impossible : B","upvote_count":"2","timestamp":"1577217540.0","comments":[{"content":"possible","timestamp":"1577217660.0","comment_id":"32425","poster":"hc","upvote_count":"1"}]},{"content":"Adding additional Cloud VPN does not reduce latency.. it increase bandwidth if teaming .. \n\nThus I go for B since is direct interconnect without going thru internet traffic.","comment_id":"89692","timestamp":"1589587920.0","poster":"skywalker","upvote_count":"3"},{"content":"\"you can't use Google Cloud VPN in combination with Dedicated Interconnect\" only applies for running Cloud VPN over Dedicated Interconnect (in roadmap for 2021). However, one can run Cloud VPN and DI side-by-side (active/passive)\n\nAdding more tunnels to VPN doesn't help solving the latency and reliability issues, it only provides more throughput when used with ECMP.\n\nQuestion asks for a method to reduce latency and increase reliability, Direct Interconnect is way to go. Answer is \"B\"","timestamp":"1593171720.0","comment_id":"120482","upvote_count":"7","poster":"cetanx"}],"poster":"addy007","content":"its \"D\". you can't use Google Cloud VPN in combination with Dedicated Interconnect. for high thorughput, add more tunnels in HA VPN.\nhttps://cloud.google.com/vpn/docs/how-to/choosing-a-vpn","timestamp":"1576358940.0","upvote_count":"3"},{"timestamp":"1576137120.0","upvote_count":"5","poster":"MrBog1","comment_id":"28964","content":"i think B works . more bandwidth reduces latency"},{"comment_id":"17414","timestamp":"1572023820.0","upvote_count":"3","content":"By \"I'd choose C\", I meant \"I'd choose D\".","poster":"Eroc"},{"comment_id":"148464","poster":"Musk","content":"By load balancing you don't fix the latency, and don't get more bacndwidth. You get the same. I vote for B.","upvote_count":"10","timestamp":"1596273240.0"},{"poster":"tartar","comment_id":"151754","timestamp":"1596696780.0","comments":[{"comments":[{"poster":"Vika","timestamp":"1614266880.0","content":"This feature is getting deprecated soon. how does it ensure low latency ? latency is the issue here. I would go with interconnect, option B bcoz it ensures low latency upto 5 millisecond.","upvote_count":"1","comment_id":"299167"},{"comment_id":"403459","upvote_count":"1","poster":"RKS_2021","timestamp":"1625938200.0","content":"Collect\nBuilding High-throughput VPNs\nThis tutorial shows how to create secure, high-throughput VPNs and test their speed.\n\nSecure communication between Google Cloud and other clouds or on-premises systems is a common, critical need. Fortunately, Google Cloud makes it easy for you to create secure Internet Protocol security (IPsec) virtual private networks (VPNs) to achieve this goal. If a single tunnel does not provide necessary throughput, Google Cloud can smoothly distribute traffic across multiple tunnels to provide additional bandwidth."},{"upvote_count":"3","comments":[{"timestamp":"1627628580.0","poster":"sebafranek","comment_id":"417235","content":"But Load Balancer will help with latency.\nhttps://cloud.google.com/load-balancing/docs/tutorials/optimize-app-latency\nSo D.","upvote_count":"1"}],"content":"Adding more VPN will give you more throughput but will not resolve latency (related to how VPN works) and packet loss (for some reason, used protocol may be, UDP... ). \nAlso VPN scaling is not that simple to implement.\n\nI would go with interconnect. answer C.","timestamp":"1607200860.0","poster":"ybe_gcp_cert","comment_id":"236027"}],"comment_id":"157955","poster":"tartar","upvote_count":"4","timestamp":"1597395060.0","content":"Sorry, D is ok. VPN tunnel has already been established, so adding more seems logical. \nThis link back me up: https://cloud.google.com/network-connectivity/docs/vpn/concepts/classic-topologies"}],"upvote_count":"3","content":"B is ok"},{"poster":"Vika","comment_id":"299164","timestamp":"1614266760.0","upvote_count":"1","content":"High availability is not the same thing as Latency. Latency is measured through round trip time for communication or one way time. High availability is how much percentage the network is available. Latency is Cloud interconnect is low bcoz it traverses a separate path \n different from public internet. VPN still uses public internet so limited bandwidth and high latency. I would go with option B of using Cloud interconnect."},{"content":"B, replication means lot of data. VPN can do 3Gib they need to Configure a Google Cloud Dedicated Interconnect. DR comes at a price tag.","poster":"nitinz","comment_id":"303638","timestamp":"1614897180.0","upvote_count":"2"}],"choices":{"E":"Send the replicated transaction to Google Cloud Pub/Sub.","A":"Configure their replication to use UDP.","B":"Configure a Google Cloud Dedicated Interconnect.","C":"Restore their database daily using Google Cloud SQL.","D":"Add additional VPN connections and load balance them."},"exam_id":4,"answer_images":[],"unix_timestamp":1572023820,"answer":"B","question_text":"As part of implementing their disaster recovery plan, your company is trying to replicate their production MySQL database from their private data center to their\nGCP project using a Google Cloud VPN connection. They are experiencing latency issues and a small amount of packet loss that is disrupting the replication.\nWhat should they do?","answer_ET":"B","answers_community":["B (67%)","D (25%)","8%"]},{"id":"yfB5JN7MwdSer7QoKuLX","timestamp":"2020-01-12 13:02:00","exam_id":4,"answers_community":["C (100%)"],"answer_description":"","question_id":137,"answer":"C","question_text":"Your customer support tool logs all email and chat conversations to Cloud Bigtable for retention and analysis. What is the recommended approach for sanitizing this data of personally identifiable information or payment card information before initial storage?","choices":{"C":"De-identify the data with the Cloud Data Loss Prevention API","D":"Use regular expressions to find and redact phone numbers, email addresses, and credit card numbers","B":"Encrypt all data using elliptic curve cryptography","A":"Hash all data using SHA256"},"answer_ET":"C","isMC":true,"discussion":[{"comment_id":"37989","timestamp":"1578830520.0","content":"C is the answer","comments":[{"comment_id":"303639","content":"C, data sanitization = DLP","timestamp":"1614897240.0","poster":"nitinz","upvote_count":"8"},{"upvote_count":"8","poster":"tartar","timestamp":"1597395120.0","content":"C is ok","comment_id":"157956"}],"poster":"AWS56","upvote_count":"23"},{"timestamp":"1671613080.0","upvote_count":"14","comments":[{"content":"Option A: Hashing data using SHA256 is not sufficient for protecting sensitive information, as hashes can be reversed using various techniques.\n\nOption B: Encrypting data using elliptic curve cryptography is a good option for protecting data, but it requires that you have a secure way to store and manage the encryption keys. If the keys are lost or compromised, the data will be inaccessible.\n\nOption D: Using regular expressions to find and redact phone numbers, email addresses, and credit card numbers can be effective in some cases, but it requires that you have a complete and up-to-date list of all the data patterns that you want to protect. It is also prone to errors and may not be able to detect all instances of sensitive data.","poster":"omermahgoub","timestamp":"1671613080.0","comments":[{"timestamp":"1683120120.0","content":"About D, usually is recommended that you don´t reinvent the wheel specially when talking about security .","poster":"Kiroo","upvote_count":"1","comment_id":"888552"}],"comment_id":"752034","upvote_count":"3"}],"content":"The recommended approach for sanitizing data of personally identifiable information or payment card information before storing it in Cloud Bigtable is option C: De-identify the data with the Cloud Data Loss Prevention API.\n\nThe Cloud Data Loss Prevention (DLP) API is a powerful tool that allows you to automatically discover, classify, and redact sensitive data in your organization. It uses advanced machine learning techniques to accurately identify and protect a wide range of sensitive data types, including personal information such as names, addresses, phone numbers, and payment card information.\n\nUsing the DLP API to de-identify your data before storing it in Cloud Bigtable is the most effective way to ensure that sensitive information is protected and not accessible to unauthorized users.","comment_id":"752033","poster":"omermahgoub"},{"comment_id":"1314170","upvote_count":"3","timestamp":"1731957300.0","content":"Selected Answer: C\n1. Accurate and comprehensive: The Cloud DLP API is specifically designed to identify and redact sensitive information like PII (personally identifiable information) and payment card data. It uses advanced techniques like machine learning to accurately detect sensitive data, even in complex and unstructured text.\n\n2. Context-aware: DLP understands the context of the data. It can differentiate between a credit card number and a similar-looking sequence of numbers that's not a credit card. This reduces false positives and ensures accurate sanitization.\n\n3. Flexible and customizable: You can configure DLP to detect specific types of sensitive data, define your own detection rules, and choose how to de-identify the data (e.g., redaction, masking, tokenization).\n\n4. Scalable and efficient: DLP can handle large volumes of data and integrates seamlessly with other GCP services like Cloud Storage and BigQuery.","poster":"Ekramy_Elnaggar"},{"comment_id":"1309315","content":"Selected Answer: C\nC option","timestamp":"1731220680.0","upvote_count":"1","poster":"sim7243"},{"upvote_count":"1","content":"Without any doubt C is the right answer as the DLP API is a flexible and robust tool that helps identify sensitive data like credit card numbers, social security numbers, names and other forms of personally identifiable information (PII).","comment_id":"1005621","poster":"Palan","timestamp":"1694512620.0"},{"content":"Cloud Data Loss Prevention API provides obfuscation and de-identification methods like masking and tokenization. Especially for credit card transactions, the card numbers are supposed to be tokenized. Therefore, this API is helpful.","upvote_count":"1","poster":"shutupbot","comment_id":"858080","timestamp":"1680364440.0"},{"upvote_count":"1","content":"Selected Answer: C\nC for sure !","poster":"mbrochard","comment_id":"723714","timestamp":"1669045620.0"},{"upvote_count":"1","poster":"AniketD","content":"Selected Answer: C\nC is correct, DLP is the solution","timestamp":"1668862620.0","comment_id":"721997"},{"timestamp":"1667747280.0","content":"Selected Answer: C\nok for C","comment_id":"712392","upvote_count":"1","poster":"megumin"},{"content":"Selected Answer: C\nC is the correct answer","poster":"vincy2202","timestamp":"1640433120.0","comment_id":"509087","upvote_count":"2"},{"timestamp":"1638702360.0","content":"Go for C","comments":[{"timestamp":"1638702420.0","content":"https://cloud.google.com/dlp","comment_id":"494252","poster":"haroldbenites","upvote_count":"1"}],"comment_id":"494251","upvote_count":"3","poster":"haroldbenites"},{"poster":"MamthaSJ","upvote_count":"1","content":"Answer is C","comment_id":"401829","timestamp":"1625742120.0"},{"comment_id":"361074","upvote_count":"3","timestamp":"1621405380.0","content":"C. De-identify the data with the Cloud Data Loss Prevention API","poster":"victory108"},{"content":"C is correct","poster":"un","upvote_count":"1","timestamp":"1620803640.0","comment_id":"355355"},{"upvote_count":"3","comment_id":"340183","poster":"sidhappy","content":"Effectively reduce data risk with de-identification methods like masking and tokenization\nhttps://cloud.google.com/dlp","timestamp":"1618993140.0"},{"timestamp":"1617166020.0","poster":"Ausias18","content":"Answer is C","comment_id":"324731","upvote_count":"1"},{"comment_id":"324279","upvote_count":"1","poster":"lynx256","timestamp":"1617109380.0","content":"C is ok"},{"upvote_count":"1","comment_id":"276547","poster":"bnlcnd","content":"https://cloud.google.com/dlp\nEffectively reduce data risk with de-identification methods like masking and tokenization.\nC is right.","timestamp":"1611631320.0"},{"poster":"VedaSW","comment_id":"187561","content":"I LOL on answer A.... *clap* *clap* *clap*.... hash all data...","upvote_count":"1","timestamp":"1601112360.0","comments":[{"comments":[{"timestamp":"1665954000.0","poster":"AzureDP900","content":"yes. thank you for sharing the link","upvote_count":"1","comment_id":"696570"}],"comment_id":"195594","poster":"psuthar0101","upvote_count":"2","timestamp":"1602110400.0","content":"correct answer is C - https://cloud.google.com/solutions/de-identification-re-identification-pii-using-cloud-dlp"}]},{"poster":"AshokC","comments":[],"timestamp":"1600133340.0","content":"C - Cloud Data Loss Prevention (DLP)","comment_id":"179597","upvote_count":"2"},{"content":"Yes I agree the correct answer is C","upvote_count":"1","comment_id":"168924","poster":"dayody","timestamp":"1598673900.0"},{"content":"Answer c: https://cloud.google.com/dlp","poster":"rtex","comment_id":"156780","timestamp":"1597273800.0","upvote_count":"3"},{"poster":"daurib","upvote_count":"3","content":"Selected C in the Exam","timestamp":"1594812060.0","comment_id":"135657"},{"timestamp":"1592899560.0","content":"DLP for sure, so C as the correct answer.","comment_id":"117214","poster":"mlantonis","upvote_count":"3"},{"upvote_count":"3","comment_id":"114555","content":"C is the correct answer","poster":"Tushant","timestamp":"1592637360.0"},{"upvote_count":"4","comment_id":"106546","timestamp":"1591772520.0","content":"C, for sure.\nCloud Data Loss Prevention (DLP) Fully managed service designed to help you discover, classify, and protect your most sensitive data --> Sanitizing","poster":"gfhbox0083"},{"content":"C is the correct answer","upvote_count":"3","timestamp":"1591110000.0","comment_id":"100941","poster":"Nirms"},{"comment_id":"98461","poster":"Ziegler","upvote_count":"3","content":"C is the correct answer","timestamp":"1590781620.0"},{"poster":"AD2AD4","comment_id":"98098","content":"Final Decision to go with Option C","timestamp":"1590738420.0","upvote_count":"4"},{"content":"C is the answer","upvote_count":"3","timestamp":"1590094560.0","poster":"gcp_aws","comment_id":"93606"},{"upvote_count":"3","comment_id":"90265","content":"Agree C","poster":"laksg","timestamp":"1589680140.0"},{"poster":"[Removed]","comment_id":"56381","upvote_count":"4","timestamp":"1582873260.0","content":"Answer: C. Selected C in the exam"},{"upvote_count":"3","content":"answer: C","comment_id":"44757","timestamp":"1580391960.0","poster":"2g"}],"unix_timestamp":1578830520,"url":"https://www.examtopics.com/discussions/google/view/11803-exam-professional-cloud-architect-topic-1-question-41/","answer_images":[],"question_images":[],"topic":"1"},{"id":"WmFGMSTjDlpc1XJxNb8P","question_text":"You are using Cloud Shell and need to install a custom utility for use in a few weeks. Where can you store the file so it is in the default execution path and persists across sessions?","timestamp":"2019-10-25 19:34:00","discussion":[{"upvote_count":"76","comment_id":"18320","poster":"ffk","timestamp":"1572412860.0","comments":[{"comments":[{"upvote_count":"9","comment_id":"444568","timestamp":"1631624460.0","content":"cd ~/ is egual at cd $HOME\n~/bin is egual a cd $HOME/bin\nthe persistent disk in cloud shell is for $HOME","poster":"zanfo"},{"timestamp":"1665954060.0","comment_id":"696572","upvote_count":"1","poster":"AzureDP900","content":"Agree. A is right"}],"timestamp":"1618230300.0","poster":"Jambalaja","comment_id":"333929","content":"Maybe also to mention is that ~/bin is located in the $HOME directory","upvote_count":"18"},{"content":"$HOME is not ~/bin. So 'C' is the answer.","comment_id":"222270","comments":[],"upvote_count":"1","timestamp":"1605735120.0","poster":"akoti"},{"upvote_count":"2","poster":"Shabje","comments":[{"timestamp":"1592900280.0","content":"The virtual machine instance that backs your Cloud Shell session is not permanently allocated to a Cloud Shell session and terminates if the session is inactive for an hour. After the instance is terminated, any modifications that you made to it outside your $HOME are lost.","poster":"kaush","upvote_count":"3","comment_id":"117221"},{"content":"Cloud Shell provisions 5 GB of free persistent disk storage mounted as your $HOME","poster":"zanfo","timestamp":"1631624520.0","comment_id":"444570","upvote_count":"1"}],"comment_id":"85172","content":"Won’t the persistent disk be auto-delete enabled by default, whereby the work maybe lost. Would that not be sufficient reason to consider Cloud storage instead. Thanks","timestamp":"1588855140.0"}],"content":"A is correct\nhttps://cloud.google.com/shell/docs/how-cloud-shell-works\nCloud Shell provisions 5 GB of free persistent disk storage mounted as your $HOME directory on the virtual machine instance. This storage is on a per-user basis and is available across projects. Unlike the instance itself, this storage does not time out on inactivity. All files you store in your home directory, including installed software, scripts and user configuration files like .bashrc and .vimrc, persist between sessions. Your $HOME directory is private to you and cannot be accessed by other users."},{"timestamp":"1572034860.0","poster":"Eroc","comment_id":"17441","upvote_count":"21","content":"Well, I just double checked and if they were referring to the PATH variable then /usr/local/bin is also a correct answer........................................"},{"comment_id":"1558518","poster":"izzetcanyc","upvote_count":"1","timestamp":"1744020120.0","content":"Selected Answer: A\nThe answer should be A because its standard location for user's scripts and custom utilities. \nD is also available for other sessions but /usr/local/bin is not suitable for custom utilities purposes also not all users have permission to this location. This location is for softwares for system wide."},{"content":"Selected Answer: D\n~/bin will not work for all sessions. Only /usr/local/bin is more accurate","poster":"izekc","upvote_count":"1","timestamp":"1742093220.0","comment_id":"1399120"},{"poster":"jobolesonihal","upvote_count":"1","comment_id":"1360015","timestamp":"1740196020.0","content":"Selected Answer: B\nWarning: If you delete your $HOME directory, or if you don't access Cloud Shell for 120 days, Cloud Shell automatically deletes your $HOME directory and can't recover your files. You'll receive an email notification before this occurs. Starting a Cloud Shell session prevents the $HOME directory persistent storage from being recycled."},{"timestamp":"1734017820.0","content":"Selected Answer: A\nIf \"few weeks\" means less than 120 days","poster":"RobertArnaud","upvote_count":"1","comment_id":"1325717"},{"comment_id":"1314178","timestamp":"1731957840.0","poster":"Ekramy_Elnaggar","upvote_count":"5","content":"Selected Answer: A\n1. Cloud Shell's home directory: ~/bin is a subdirectory within your Cloud Shell home directory. Files placed in this directory are automatically added to your PATH environment variable, making them accessible from anywhere in your Cloud Shell session.\n\n2. Persistence: Your Cloud Shell home directory is persistent across sessions. This means any files you store there, including those in ~/bin, will remain available even if you close and reopen Cloud Shell.\n\n3. Convenience: This option is the most straightforward. It doesn't require any extra configuration or interaction with other services.\n\nWhy D i snot correct? because /usr/local/bin: is a common directory for system-wide binaries, but in Cloud Shell, your home directory's"},{"content":"Selected Answer: D\n/usr/local/bin is the place where the files will persist across sessions.\nHence, D.","comment_id":"1070624","poster":"thewalker","timestamp":"1699978680.0","upvote_count":"2"},{"comment_id":"987693","poster":"heretolearnazure","timestamp":"1692730080.0","upvote_count":"1","content":"A is correct!"},{"comments":[{"timestamp":"1686647460.0","comment_id":"922101","poster":"Flight1976","content":"1. When logging in to cloud shell for the first time, the ~/bin directory does not exist\n2. mkdir ~/bin\n3. After re-login to the cloud shell, $PATH will automatically add ~/bin\nSo A is the correct answer","upvote_count":"4"}],"comment_id":"798200","poster":"moota","timestamp":"1675531320.0","upvote_count":"2","content":"I tested this. Although ~/bin is not in the default $PATH, choice D is definitely not persisting across sessions."},{"content":"At this moment default directory cant be set as Cloud storage bucket, so no C.\nA will be correct as zonal PD with preinstalled tools 5gb available that does not timeout!","comment_id":"761649","upvote_count":"2","poster":"FI22","timestamp":"1672369920.0"},{"comments":[{"upvote_count":"3","timestamp":"1671614100.0","content":"Option B: Cloud Storage is not a suitable location for storing a custom utility file that you want to use in Cloud Shell, as it is not in the default execution path and would require additional steps to make it accessible.\n\nOption C: The /google/scripts directory is not a suitable location for storing a custom utility file, as it is not in the default execution path and is intended for use by Google Cloud system processes.\n\nOption D: The /usr/local/bin directory is a system directory that is in the default execution path for all users, but it is not a suitable location for storing a custom utility file, as any files that you place in this directory may be deleted or overwritten during system updates.","poster":"omermahgoub","comment_id":"752052"}],"upvote_count":"4","content":"The recommended location for storing a custom utility file that you want to use in Cloud Shell and that should be in the default execution path and persist across sessions is option A: ~/bin.\n\nThe ~/bin directory is a personal directory that is in the default execution path for all users in Cloud Shell. Any executable files that you place in this directory will be available to you whenever you log in to Cloud Shell, and they will persist across sessions.","timestamp":"1671614100.0","poster":"omermahgoub","comment_id":"752051"},{"timestamp":"1667833200.0","content":"Selected Answer: A\nFor sure correct answer is A","poster":"Jailbreaker","comment_id":"713125","upvote_count":"1"},{"timestamp":"1667747400.0","content":"Selected Answer: A\nok for A","upvote_count":"1","comment_id":"712394","poster":"megumin"},{"timestamp":"1665666900.0","comment_id":"693917","poster":"minmin2020","upvote_count":"1","content":"Selected Answer: A\nA. ~/bin"},{"timestamp":"1644835680.0","content":"Selected Answer: A\nCloud Shell provisions 5 GB of persistent disk storage mounted as your $HOME directory on the Cloud Shell instance. All files you store in your home directory, including scripts and user configuration files like .bashrc and .vimrc, persist between sessions.\n\nReference- https://cloud.google.com/shell/?utm_source=google&utm_medium=cpc&utm_campaign=japac-IN-all-en-dr-bkwsrmkt-all-all-trial-e-dr-1009882&utm_content=text-ad-none-none-DEV_c-CRE_442449534611-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt%20~%20Management%20Tools%20~%20Cloud%20Shell_cloud%20shell-general%20-%20Products-KWID_43700054972141701-kwd-837034669893&userloc_9302140-network_g&utm_term=KW_gcp%20cloud%20shell&gclsrc=ds&gclsrc=ds","upvote_count":"4","poster":"vpatiltech","comment_id":"547069"},{"poster":"OrangeTiger","upvote_count":"2","comment_id":"514464","content":"I think D is correct.ummm","timestamp":"1641032580.0"},{"comment_id":"509088","upvote_count":"1","timestamp":"1640433300.0","content":"A is the correct answer","poster":"vincy2202"},{"timestamp":"1636038660.0","poster":"exam_war","content":"A is for sure. ~ stands for user's home","upvote_count":"1","comment_id":"472648"},{"content":"Answer is A","comment_id":"401833","upvote_count":"1","timestamp":"1625742360.0","poster":"MamthaSJ"},{"content":"hey guys check Q3 for new Qs, 49 New Qs","upvote_count":"1","poster":"kopper2019","timestamp":"1624903080.0","comment_id":"393154"},{"poster":"aviratna","comment_id":"391797","content":"A is correct. Cloud Shell provides 5 GB persistent disk and data in Home directory will persist","timestamp":"1624774860.0","upvote_count":"1"},{"content":"A. ~/bin","poster":"victory108","comment_id":"361073","timestamp":"1621405380.0","upvote_count":"1"},{"comment_id":"354910","timestamp":"1620753960.0","upvote_count":"1","content":"A is correct","poster":"un"},{"poster":"Ausias18","content":"Answer is A","upvote_count":"1","timestamp":"1617166080.0","comment_id":"324732"},{"content":"C is correct, /google/scripts persists between Cloud Shell sessions.","comment_id":"322055","comments":[{"timestamp":"1629361860.0","upvote_count":"1","comment_id":"427332","content":"agree with C","comments":[{"timestamp":"1629361980.0","comment_id":"427334","upvote_count":"1","content":"I correct myself, A. refer to https://medium.com/google-cloud/google-cloud-shell-the-free-playground-b5ab4793224","poster":"xavi1"}],"poster":"xavi1"}],"upvote_count":"2","timestamp":"1616870280.0","poster":"realkrt"},{"poster":"Darzan","comment_id":"297003","timestamp":"1614034800.0","content":"Only your home directory is persisted across sessions as per google docs. Any directory starting with Tilda is within your home directory. So the answer is A.","upvote_count":"3"},{"comment_id":"295568","timestamp":"1613887920.0","upvote_count":"4","content":"~/ means home directory, So ~/bin is in home which persists. A is correct.","poster":"Shruti1997"},{"timestamp":"1613493900.0","comment_id":"291936","poster":"bogd","content":"This is one confusing question... The question requires the file to be persistent - and only $HOME (aka ~) is persistent. This would suggest answer A.\n\nHowever, it also requires the file to be in the default execution environment (and I read this as \"file must be in the default $PATH) - and ~/bin is not in $PATH by default...\n\nI would still go for A, but only for lack of a better option.","upvote_count":"5"},{"content":"A is right:\nYou can install additional software packages on the virtual machine instance but the installation will not persist after the instance terminates unless you install the software in your $HOME directory\n\n~/bin == /home/<your_user_name>/bin","poster":"bnlcnd","comment_id":"276551","timestamp":"1611631560.0","upvote_count":"4"},{"content":"I just did some tests in Cloud Shell. \nBy default there is no \"bin\" directory in $HOME directory. It will have to be created.\nWhen you upload a file it goes to your $HOME directory.\nIf you try to copy the uploaded file to the /usr/local/bin directory you get an access denied error. You have to do it using sudo:\nsudo cp <my uploaded file> /usr/local/bin\n\nThe file uploaded in $HOME directory is persisted in case of a forced Cloud Shell restart. The file copied with sudo in /usr/local/bin is not.\n\nSo, the correct answer would be A (~/bin) after you manually create the \"bin\" directory.","poster":"CosminCiuc","comment_id":"247368","upvote_count":"7","timestamp":"1608300780.0"},{"poster":"varushar","upvote_count":"1","comment_id":"225476","timestamp":"1606108260.0","content":"The answer must be B ... persistence across sessions"},{"comment_id":"223991","poster":"Ananthtm","content":"It must be A. I made a mistake in my earlier reply. The tilde (the wavy horizontal line character) is used to represent users' home directories on Unix-like operating systems. https://cloud.google.com/shell/docs/how-cloud-shell-works mentions that \"You can install additional software packages on the virtual machine instance but the installation will not persist after the instance terminates unless you install the software in your $HOME directory\" and $HOME for linux is an environment variable that points to /home/<username>","upvote_count":"3","timestamp":"1605907320.0"},{"comment_id":"214016","upvote_count":"2","poster":"didiluca","timestamp":"1604659440.0","content":"I'd also agree with A. If you take a look at the README file in your Cloud Shell home directory, it says:\nWelcome to Google Cloud Shell, a tool for managing resources hosted on Google Cloud Platform!\nThe machine comes pre-installed with the Google Cloud SDK and other popular developer tools.\n\nYour 5GB home directory will persist across sessions, but the VM is ephemeral and will be reset\napproximately 20 minutes after your session ends. No system-wide change will persist beyond that."},{"upvote_count":"1","comment_id":"199098","poster":"Aru23","timestamp":"1602582840.0","content":"B is a default path so answer is C"},{"poster":"Firask","comment_id":"189256","content":"~/bin is not part of $PATH cloud shell and /usr/local/bin is there.\nall the home paths are /home/$USER/.gem/bin\nor /home/$USER/gopath/bin","timestamp":"1601321400.0","upvote_count":"1"},{"timestamp":"1601137680.0","content":"Because GCP only saves ~, answers must include ~. Thus, the standard Linux answer (D) is wrong. It's A.","upvote_count":"1","poster":"kimberjdaw","comment_id":"187791"},{"upvote_count":"1","comment_id":"179601","content":"A is correct","poster":"AshokC","timestamp":"1600133820.0"},{"poster":"Kabiliravi","upvote_count":"2","content":"Cloud Shell keeps the files for a period of time and relying on Cloud Shell storage is not safe. We can use Cloud Storage to keep files for future use. Cloud Storage B is the right answer","timestamp":"1598617680.0","comment_id":"168427"},{"content":"Anything you store in the home directory in cloud shell will be persisted across sessions. Hence, correct answer is 'A'.","timestamp":"1598591220.0","upvote_count":"2","poster":"vbondoo7","comment_id":"168095"},{"poster":"wiqi","comment_id":"162392","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"162399","poster":"wiqi","timestamp":"1597945560.0","content":"After reading 'https://medium.com/google-cloud/no-localhost-no-problem-using-google-cloud-shell-as-my-full-time-development-environment-22d5a1942439' article that Ziegler gave. I would with A too. Persistence is definitely a requirement so yes to A."}],"timestamp":"1597944900.0","content":"user@cloudshell:~ (project-name)$ echo $PATH\n/usr/local/rvm/bin:/usr/local/go/bin:/opt/gradle/bin:/opt/maven/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/nvm/versions/node/v10.14.2/bin:/usr/local/rvm/bin:/google/go_appengine:/google/google_appengine:/google/gopath/bin:/google/migrate/anthos/\n\n~/bin is not in the path.\nI would choose D as /usr/local/bin is in the path"},{"upvote_count":"2","comment_id":"153938","poster":"haidertanveer0808","timestamp":"1597003860.0","content":"AS per documentation.\nCloud Shell provisions 5 GB of free persistent disk storage mounted as your $HOME directory. All files you store in your home directory, including installed software, scripts and user configuration files like .bashrc and .vimrc, persist between sessions. Since your .bashrc persists across sessions, it's a great way to customize your Cloud Shell behavior. Similarly, you can install packages into your home directory to have your installations persist. So answer should be A"},{"content":"A is correct","timestamp":"1592899440.0","comment_id":"117210","upvote_count":"1","poster":"mlantonis"},{"upvote_count":"1","content":"A is the correct answer","timestamp":"1592637420.0","comment_id":"114557","poster":"Tushant"},{"poster":"gfhbox0083","upvote_count":"1","content":"A, for sure.","timestamp":"1591772580.0","comment_id":"106547"},{"poster":"Nirms","timestamp":"1591110120.0","content":"A is the correct answer","comment_id":"100942","upvote_count":"1"},{"content":"Answer is A, The virtual machine instance that backs your Cloud Shell session is not permanently allocated to a Cloud Shell session and terminates if the session is inactive for an hour. After the instance is terminated, any modifications that you made to it outside your $HOME are lost.","poster":"coldpar","timestamp":"1590957540.0","upvote_count":"1","comment_id":"99583"},{"timestamp":"1590783780.0","content":"A is the correct answer\nhttps://medium.com/google-cloud/no-localhost-no-problem-using-google-cloud-shell-as-my-full-time-development-environment-22d5a1942439","comment_id":"98470","upvote_count":"1","poster":"Ziegler"},{"timestamp":"1590651720.0","poster":"AD2AD4","comment_id":"97342","upvote_count":"1","content":"Final Decision to go with Option A"},{"upvote_count":"1","poster":"gcp_aws","content":"A is the correct answer","timestamp":"1590094920.0","comment_id":"93612"},{"timestamp":"1589621460.0","comment_id":"89844","upvote_count":"1","poster":"Navi08","content":"I think answer is A as its under $HOME which is persisted"},{"comment_id":"88053","upvote_count":"1","content":"B because Cloud Shell is not persistent\n\nWhen you start Cloud Shell, it provisions a e2-small Google Compute Engine virtual machine running a Debian-based Linux operating system. Cloud Shell instances are provisioned on a per-user, per-session basis. The instance persists while your Cloud Shell session is active; after an hour of inactivity, your session terminates and its VM, discarded","poster":"skywalker","timestamp":"1589335560.0"},{"timestamp":"1583273760.0","poster":"Jeysolomon","content":"I think the question is about to keep the custom file in one location and use it in other VMs. So, the correct answer is B. Cloud storage is recommended to keep the startup/shutdown scripts as well to refer and execute by VMs directly from there.","upvote_count":"2","comment_id":"58424"},{"content":"Answer: A. \nSelected A in the exam","timestamp":"1582878360.0","poster":"[Removed]","upvote_count":"5","comment_id":"56410"},{"upvote_count":"1","content":"answer: A","poster":"2g","timestamp":"1580391960.0","comment_id":"44758"},{"poster":"aviv","upvote_count":"3","comment_id":"29584","content":"Only HOME directory is persisted across sessions.So answer is A","timestamp":"1576336440.0"},{"upvote_count":"3","poster":"shandy","timestamp":"1574642280.0","content":"To have your configurations persist across sessions one must conside customizing your environment. Refer to this\n\nhttps://cloud.google.com/shell/docs/configuring-cloud-shell#environment_customization_script\n\nLooks like A is right.","comment_id":"24167"},{"comment_id":"17795","content":"A,C, D persists across sessions? Think not... If put the file in cloud storage bucket there will always be there... so B","poster":"jcmoranp","upvote_count":"7","timestamp":"1572194580.0"},{"poster":"Eroc","upvote_count":"2","comment_id":"17419","timestamp":"1572025440.0","content":"Unless by default execute path they mean the \"$PATH\" variable, in which situation A is correct"},{"upvote_count":"2","content":"The answer is not B because /bin is in the default execution path not ~/bin, Google Cloud storage also is not. The answer is C.","timestamp":"1572024840.0","comment_id":"17416","poster":"Eroc","comments":[{"comments":[{"poster":"Ananthtm","content":"Sorry, it seems like D","comments":[{"comment_id":"236853","timestamp":"1607294760.0","upvote_count":"4","content":"@Ananthtm, you're just guessing at C and D, when you have stated the correct answer above. You say it won't persist unless it is installed in your home directory which is /home/username. The shortcut for /home/username for any user is ~/, so putting it in ~/bin or any other path under ~/ would persist.","poster":"cate0012"}],"timestamp":"1605906420.0","upvote_count":"2","comment_id":"223986"}],"poster":"Ananthtm","content":"I agree, it must be C. https://cloud.google.com/shell/docs/how-cloud-shell-works mentions that \"You can install additional software packages on the virtual machine instance but the installation will not persist after the instance terminates unless you install the software in your $HOME directory\" and $HOME for linux is an environment variable that points to /home/<username>","timestamp":"1605906360.0","comment_id":"223985","upvote_count":"2"},{"content":"A is ok","upvote_count":"3","timestamp":"1596698340.0","comment_id":"151765","poster":"tartar"},{"comment_id":"303640","poster":"nitinz","upvote_count":"1","content":"A, once done logout and log back in or rehash.","timestamp":"1614897300.0"}]}],"answer_ET":"A","answer_images":[],"exam_id":4,"answer":"A","unix_timestamp":1572024840,"isMC":true,"question_id":138,"url":"https://www.examtopics.com/discussions/google/view/7212-exam-professional-cloud-architect-topic-1-question-42/","answer_description":"","question_images":[],"answers_community":["A (78%)","D (17%)","6%"],"topic":"1","choices":{"C":"/google/scripts","B":"Cloud Storage","D":"/usr/local/bin","A":"~/bin"}},{"id":"eAKhcptXnHdzKdFin5rN","answer_ET":"A","discussion":[{"comment_id":"37999","comments":[{"poster":"tartar","upvote_count":"7","content":"A is ok","comment_id":"151766","timestamp":"1596698400.0"},{"comment_id":"266421","timestamp":"1610555580.0","upvote_count":"3","content":"https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview#network-bandwidth","poster":"fraloca"},{"timestamp":"1614897360.0","content":"A, 20Gbps dedicated interconnect is the way.","poster":"nitinz","comment_id":"303644","upvote_count":"2"},{"comment_id":"696573","poster":"AzureDP900","content":"A is required for consistent speed and VPN not supports that speed","timestamp":"1665954180.0","upvote_count":"2"}],"upvote_count":"45","timestamp":"1578831180.0","content":"Cloud VPN supports unto 3 Gbps where as Interconnect can support unto 100 gbps... I'll go with A","poster":"AWS56"},{"poster":"omermahgoub","content":"Answer is A: Dedicated Interconnect is a service that allows you to create a dedicated, high-bandwidth network connection between your on-premises data center and Google Cloud. It is the recommended solution for creating a private connection between your on-premises data center and Google Cloud when you require a connection of at least 20 Gbps.\n\nOption B: Using a single Cloud VPN to connect your VPC to your on-premises data center is not suitable for a connection of at least 20 Gbps, as Cloud VPN has a maximum capacity of 30 Gbps.\n\nOption C: The Cloud Content Delivery Network (Cloud CDN) is a globally distributed network of caching servers that speeds up the delivery of static and dynamic web content. It is not suitable for creating a private connection between your instances on Compute Engine and your on-premises data center.\n\nOption D: Connecting your Cloud CDN to your on-premises data center using a single Cloud VPN is not suitable for a connection of at least 20 Gbps, as Cloud VPN has a maximum capacity of 30 Gbps.","upvote_count":"13","comments":[{"poster":"MJCLOUD","comment_id":"824877","upvote_count":"4","timestamp":"1677592980.0","content":"Very nice answer, I think you meant 3 Gbps for Cloud VPN."}],"comment_id":"752059","timestamp":"1671614220.0"},{"poster":"Ekramy_Elnaggar","upvote_count":"3","content":"Selected Answer: A\n1. Dedicated Interconnect for high bandwidth: Dedicated Interconnect is designed for high-bandwidth, private connections between your on-premises network and Google Virtual Private Cloud (VPC). It offers speeds of 10 Gbps up to 100 Gbps, meeting your requirement of at least 20 Gbps.\n\n2. Private and secure connection: Dedicated Interconnect provides a direct physical connection, bypassing the public internet. This ensures a secure and private connection for your sensitive data.\n\n3. Google-recommended practice: For demanding workloads that require high bandwidth and low latency, Google recommends Dedicated Interconnect over VPN.","timestamp":"1731958020.0","comment_id":"1314181"},{"content":"high bandwidth means A","comment_id":"987694","upvote_count":"1","poster":"heretolearnazure","timestamp":"1692730140.0"},{"timestamp":"1671196140.0","content":"Selected Answer: A\nthe question mention 20gbs for the least, it should be Dedicated Interconnect. The answer is A","upvote_count":"1","poster":"greyhats13","comment_id":"747199"},{"upvote_count":"1","comment_id":"712397","poster":"megumin","timestamp":"1667747520.0","content":"Selected Answer: A\nok for A"},{"timestamp":"1662294060.0","poster":"Jay_Krish","comment_id":"659255","content":"Selected Answer: A\nAny connection between On-Prem and GCP and requires high speed I'd choose dedicated interconnect","upvote_count":"1"},{"upvote_count":"1","timestamp":"1652512860.0","content":"A is correct","poster":"avinashvidyarthi","comment_id":"601467"},{"comment_id":"509090","timestamp":"1640433420.0","poster":"vincy2202","upvote_count":"2","content":"A is the correct answer"},{"timestamp":"1638702900.0","poster":"haroldbenites","content":"Go for A","upvote_count":"2","comment_id":"494257"},{"poster":"joe2211","content":"Selected Answer: A\nvote A","comment_id":"489496","timestamp":"1638143220.0","upvote_count":"2"},{"poster":"duocnh","content":"Selected Answer: A\nvote A","upvote_count":"3","timestamp":"1638143100.0","comment_id":"489494"},{"poster":"unnikrisb","content":"A is good option (easily elminate C & D) and B with connection speed.\n10Gbps per link for Dedicated Interconnect and Direct Peering\n1.5-3Gbps per tunnel for Cloud VPN\n50Mbps to 10Gbps per connection - Partner Interconnect\nnoSLA - Carrier Peering","timestamp":"1633768740.0","upvote_count":"1","comment_id":"459558"},{"poster":"amxexam","comment_id":"434610","content":"Let's go with option elimination\nA. Create a VPC and connect it to your on-premises data centre using Dedicated Interconnect.\n>> Is the only remaining best option after elimination. As per the document, its partner interconnects with VPN. Interconnect is between GCP and on-prem. URL1\n\nB. Create a VPC and connect it to your on-premises data centre using a single Cloud VPN.\n>> max 3 gigabits per second (Gbps) eliminate the option.\n\nC. Create a Cloud Content Delivery Network (Cloud CDN) and connect it to your on-premises data centre using Dedicated Interconnect.\n>> CDN is for egress traffic or static content hosting hence eliminate the option URL2\n\nD. Create a Cloud Content Delivery Network (Cloud CDN) and connect it to your on-premises datacenter using a single Cloud VPN.\n>> CDN is for egress traffic or static content hosting hence eliminate the option URL2\n\nHence A\n\nURL1 https://cloud.google.com/network-connectivity/docs/interconnect/concepts/overview\nURL2 https://cloud.google.com/network-connectivity/docs/cdn-interconnect","timestamp":"1630242480.0","upvote_count":"3"},{"poster":"MamthaSJ","timestamp":"1625742420.0","comment_id":"401836","content":"Answer is A","upvote_count":"1"},{"content":"A is correct. Dedicated Interconnect supports upto 80 GBPS","upvote_count":"1","poster":"aviratna","comment_id":"391800","timestamp":"1624775160.0"},{"upvote_count":"2","timestamp":"1621407300.0","comment_id":"361109","poster":"victory108","content":"A. Create a VPC and connect it to your on-premises data center using Dedicated Interconnect."},{"comment_id":"355360","upvote_count":"1","poster":"un","content":"A is correct","timestamp":"1620804240.0"},{"content":"Answer is A","comment_id":"324734","poster":"Ausias18","timestamp":"1617166140.0","upvote_count":"1"},{"timestamp":"1617110040.0","comment_id":"324288","upvote_count":"1","content":"A is ok","poster":"lynx256"},{"upvote_count":"1","content":"I'll go with A","timestamp":"1616693700.0","poster":"lynx256","comment_id":"320408"},{"comment_id":"249339","timestamp":"1608556500.0","content":"The answer is A. We could consider the option \"B\" but it says \"single\", so we cannot use several cloud VPN tunnels to achieve the mentioned bandwidth.","upvote_count":"1","poster":"sdsdfasdf4"},{"poster":"subhala","content":"cloud VPN supports 1.5 to 3 Gbps per tunnel. dedicated interconnect has two options. a) 10 Gbps per link and upto 8 of them (so 10 * 8 = 80 Gbps) b) 100 Gbps per link and upto 2 of them (so 100 * 2 = 200 Gbps).\n\nso would go with A.","timestamp":"1601235300.0","upvote_count":"3","comment_id":"188562"},{"content":"this is in exam","poster":"dk110019","timestamp":"1600224240.0","comment_id":"180141","upvote_count":"4"},{"upvote_count":"1","comment_id":"179605","content":"A - Cloud VPN supports up to 3 Gbps, while Dedicated Interconnect can support up to 80 Gbps. The requirement is 20 Gbps in the question.","poster":"AshokC","timestamp":"1600134120.0"},{"poster":"mlantonis","upvote_count":"3","comment_id":"117241","content":"You do not need CDN, so C and D are wrong. Cloud VPN supports up to 3 Gbps, while Dedicated Interconnect can support up to 80 Gbps. So A is the correct.","timestamp":"1592901840.0"},{"upvote_count":"2","content":"A is the correct answer","poster":"Tushant","comment_id":"114558","timestamp":"1592637480.0"},{"poster":"gfhbox0083","upvote_count":"2","comment_id":"106548","content":"A, for sure.","timestamp":"1591772640.0"},{"comment_id":"100944","timestamp":"1591110240.0","content":"A is the correct answer","upvote_count":"1","poster":"Nirms"},{"comment_id":"98099","timestamp":"1590738480.0","upvote_count":"2","content":"Final Decision to go with Option A","poster":"AD2AD4"},{"poster":"gcp_aws","upvote_count":"2","timestamp":"1590095160.0","content":"A is the answer","comment_id":"93614"},{"poster":"Ziegler","timestamp":"1590005340.0","comment_id":"92958","content":"A is the correct answer because VPN tunnel can only have 10Gbps","upvote_count":"2"},{"poster":"laksg","upvote_count":"2","content":"Agree A","timestamp":"1589680500.0","comment_id":"90267"},{"poster":"Erso","comment_id":"85182","timestamp":"1588856400.0","content":"Answer is A. Cloud VPN support up to 3Gbps ,the requirement (in the question) is 20 Gbps","upvote_count":"2"},{"content":"Answer : A. Selected A in exam","upvote_count":"2","comment_id":"56376","poster":"[Removed]","timestamp":"1582873020.0"},{"timestamp":"1580392080.0","comment_id":"44761","poster":"2g","upvote_count":"2","content":"answer: A"}],"answer_description":"","answers_community":["A (100%)"],"exam_id":4,"choices":{"D":"Create a Cloud Content Delivery Network (Cloud CDN) and connect it to your on-premises datacenter using a single Cloud VPN.","B":"Create a VPC and connect it to your on-premises data center using a single Cloud VPN.","C":"Create a Cloud Content Delivery Network (Cloud CDN) and connect it to your on-premises data center using Dedicated Interconnect.","A":"Create a VPC and connect it to your on-premises data center using Dedicated Interconnect."},"timestamp":"2020-01-12 13:13:00","topic":"1","unix_timestamp":1578831180,"question_images":[],"question_id":139,"answer_images":[],"answer":"A","isMC":true,"url":"https://www.examtopics.com/discussions/google/view/11804-exam-professional-cloud-architect-topic-1-question-43/","question_text":"You want to create a private connection between your instances on Compute Engine and your on-premises data center. You require a connection of at least 20\nGbps. You want to follow Google-recommended practices. How should you set up the connection?"},{"id":"IIkdEdPXqzzfHAksPsjH","discussion":[{"poster":"ehgm","content":"Sustained are automatic discounts for running specific GCE a significant portion of the billing month: https://cloud.google.com/compute/docs/sustained-use-discounts\n\nCommitted is for workloads with predictable resource needs between 1 year or 3 year, discount is up to 57% for most resources: https://cloud.google.com/compute/docs/instances/signing-up-committed-use-discounts","upvote_count":"43","comments":[{"content":"Adding to it. \n Provide training to the team about service cost management: Because we are still using free tier, and no need a separate position even if that need arises. Its startup Company any way, and they are trained to work beyond hours :-)","poster":"ashishdwi007","upvote_count":"2","timestamp":"1706016480.0","comment_id":"1129551"},{"poster":"squishy_fishy","timestamp":"1643209020.0","content":"Best answer!","upvote_count":"5","comment_id":"532982"}],"timestamp":"1640622780.0","comment_id":"510465"},{"content":"I would choose \"B\"","timestamp":"1571986140.0","comment_id":"17325","comments":[{"timestamp":"1596698520.0","poster":"tartar","upvote_count":"11","content":"B is ok","comment_id":"151767"},{"comment_id":"303647","content":"B reason minimize GCP service costs","upvote_count":"3","poster":"nitinz","timestamp":"1614897360.0"}],"upvote_count":"40","poster":"crypt0"},{"upvote_count":"4","comment_id":"1314183","poster":"Ekramy_Elnaggar","timestamp":"1731958260.0","content":"Selected Answer: B\n1. Free Tier: Google Cloud's Free Tier allows you to use certain services for free, up to specified limits. This is ideal for a startup testing the platform and controlling costs during the trial phase.\n\n2. Sustained Use Discounts: These discounts are automatically applied to your bill when you use eligible services for a significant portion of the billing month. This is beneficial for a startup that might have unpredictable usage patterns during the trial phase, as it doesn't require any upfront commitment.\n\n3. Training for cost management: Educating your team about cost management best practices empowers them to make cost-effective decisions from the start. This includes understanding pricing models, monitoring resource usage, and optimizing configurations."},{"timestamp":"1671614940.0","content":"The recommended approach for minimizing GCP service costs and adhering to Google best practices are: \n- Free tier: Google Cloud offers a free tier of services that allows you to try out many of its products for free, up to certain usage limits. Utilizing the free tier can help you minimize your GCP service costs while you are in the trial usage phase.\n\n- Committed use discounts: Committed use discounts are a type of discount that you can apply to certain GCP products by committing to a certain level of usage over a one- or three-year period. Committed use discounts can help you save on your GCP service costs, but they require you to commit to a certain level of usage, which may not be suitable if you are unsure of your future demand.\n\n- Providing training to the team about service cost management: It is important that your team is aware of the different options available for minimizing GCP service costs and understands how to manage and monitor their usage of GCP services. Providing training on service cost management can help your team make informed decisions about how to use GCP services in the most cost-effective way.","upvote_count":"9","poster":"omermahgoub","comments":[{"upvote_count":"1","timestamp":"1671614940.0","content":"The recommended approach for minimizing GCP service costs and adhering to Google best practices while your startup is in the trial usage phase and you don't yet know what consumer demand for your product will be is option D: Utilize free tier and committed use discounts. Provide training to the team about service cost management.","comment_id":"752068","poster":"omermahgoub"},{"content":"Sustained use discounts are based on your usage of GCP services over a certain period, and are not available for all GCP products. \n\nProvisioning a staff position for service cost management may not be necessary if you provide training to the team about service cost management.","poster":"omermahgoub","timestamp":"1671615000.0","upvote_count":"2","comment_id":"752069"}],"comment_id":"752067"},{"upvote_count":"1","content":"Selected Answer: B\nSustained use discounts - Compute Engine - Google Cloudhttps://cloud.google.com › ... › Documentation\nCompute Engine offers sustained use discounts on resources that are used for more than 25% of a billing month - There trial could be more than 7 or 8 days , at this point commitment of use can not be provided due to trails stage of gcp use","comment_id":"726388","poster":"SureshbabuK","timestamp":"1669351980.0"},{"timestamp":"1668342120.0","poster":"vranjan","content":"The answer is B, because Sustained use discount can give up to 30% and requires no commitment.","upvote_count":"1","comment_id":"717289"},{"poster":"megumin","upvote_count":"1","comment_id":"712399","content":"Selected Answer: B\nok for B","timestamp":"1667747700.0"},{"comment_id":"696914","content":"committed use discounts are for long-run discounts which in the case of startup they're trying GCP. So options C and D are out\nB is the correct answer","timestamp":"1665982860.0","upvote_count":"1","poster":"zr79"},{"comment_id":"696574","content":"I will choose B, D is only long term commitment","poster":"AzureDP900","upvote_count":"1","timestamp":"1665954240.0"},{"content":"Selected Answer: B\nB. Utilize free tier and sustained use discounts. Provide training to the team about service cost management.","comment_id":"693928","poster":"minmin2020","timestamp":"1665667560.0","upvote_count":"2"},{"upvote_count":"1","content":"Sustained use discount makes sense over committed as not enough info to know what to comit to. Provide staff training on how to keep things cheap gonna further keep cost down.","timestamp":"1664386200.0","poster":"BiddlyBdoyng","comment_id":"681981"},{"timestamp":"1648839300.0","poster":"cmamiusa","upvote_count":"1","content":"Selected Answer: B\nB is the correct option","comment_id":"579631"},{"comment_id":"554351","timestamp":"1645608480.0","poster":"gcmrjbr","content":"free tier (monthly discounts) does not make sense combined with committed use discounts - anual base, dont't you think so?","upvote_count":"2"},{"timestamp":"1640433840.0","upvote_count":"1","comment_id":"509094","poster":"vincy2202","content":"B is the correct answer"},{"content":"Answer is B","poster":"Israel","comment_id":"441656","upvote_count":"1","timestamp":"1631136660.0"},{"content":"Answer B\n Sustained use discounts are applied on incremental use after you reach certain usage thresholds. This means that you pay only for the number of minutes that you use an instance, and Compute Engine automatically gives you the best price. There's no reason to run an instance for longer than you need it.\n - https://cloud.google.com/compute/docs/sustained-use-discounts\nCommitted use discounts are ideal for workloads with predictable resource needs. When you purchase a committed use contract, you purchase compute resource (vCPUs, memory, GPUs, and local SSDs) at a discounted price in return for committing to paying for those resources for 1 year or 3 years. The discount is up to 57% for most resources like machine types or GPUs. The discount is up to 70% for memory-optimized machine types. For committed use prices for different machine types, see VM instances pricing.\n - https://cloud.google.com/compute/docs/instances/signing-up-committed-use-discounts","upvote_count":"5","comment_id":"417268","timestamp":"1627633680.0","poster":"VishalB"},{"timestamp":"1625743560.0","comment_id":"401847","poster":"MamthaSJ","content":"Answer is B","upvote_count":"1"},{"content":"B is correct as demand is not known","upvote_count":"1","poster":"aviratna","timestamp":"1624775280.0","comment_id":"391801"},{"poster":"gatul28","content":"\"don't yet know what consumer demand for your product will be\" so can't be C and D. Between A and B, B makes complete sense as those performing the job would directly make a positive or negative impact. B","comment_id":"365500","upvote_count":"2","timestamp":"1621851960.0"},{"content":"B. Utilize free tier and sustained use discounts. Provide training to the team about service cost management.","upvote_count":"2","comment_id":"361106","poster":"victory108","timestamp":"1621407180.0"},{"timestamp":"1620804840.0","comment_id":"355368","content":"B is correct\n\nhttps://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#billing_and_management","upvote_count":"1","poster":"un"},{"content":"Answer is B","timestamp":"1617166200.0","upvote_count":"1","poster":"Ausias18","comment_id":"324735"},{"content":"B is ok","comment_id":"324262","poster":"lynx256","timestamp":"1617108060.0","upvote_count":"1"},{"poster":"AD3","timestamp":"1616548860.0","content":"'A' seems more logical. As the person can monitor the expenses and also train others for cost minimize. Most of the money is wasted in the beginning of the usage of new technology. Analogy is a new car. How you can minimize on the efficiency of the car usage only if you have an experience person driver sitting next and teaching their kids how to improve the efficiency of a newly bought car. The trainees are first focus more on the new features and not the cost efficiency.","comment_id":"318660","upvote_count":"1"},{"timestamp":"1615401780.0","comment_id":"307378","content":"Has to be C, no? :)","poster":"JackIsMyName","upvote_count":"1"},{"comment_id":"300945","poster":"ga","content":"B is the correct answer","upvote_count":"1","timestamp":"1614539820.0"},{"poster":"bnlcnd","upvote_count":"2","timestamp":"1611632940.0","comment_id":"276570","content":"Depends on your business situation, both A & B are OK. Both A & B should be done.\nIf I saw it in the exam, I will throw a coin to get the answer. :)"},{"upvote_count":"2","content":"A, while potentially incurring higher overall cost, would help minimize the GCP service cost. B would raise the awareness on GCP cost management but may not minimize the GCP cost.","poster":"HKim","timestamp":"1610900640.0","comment_id":"269633"},{"timestamp":"1609969800.0","comment_id":"261308","poster":"Arimaverick","content":"Should be B. Because sustained use discount will give you non-committal discounts since its a startup its best fit. Provide training instead of new hires will decrease initial cost.","upvote_count":"1"},{"poster":"Xdl","upvote_count":"1","content":"If B is correct why is A highlighted as the correct answer","timestamp":"1608975840.0","comment_id":"252554"},{"poster":"Prakzz","upvote_count":"1","comment_id":"252039","timestamp":"1608899700.0","content":"B is correct"},{"content":"B is ok","timestamp":"1606891380.0","poster":"Chulbul_Pandey","comment_id":"232670","upvote_count":"1"},{"timestamp":"1601112900.0","comment_id":"187565","content":"This is a startup. Why would I incur a headcount to monitor free tier and sustained usage? Definitely not at this juncture.\n\nSo, answer A makes no logical sense for a startup.\n\nI go with B.","poster":"VedaSW","upvote_count":"4"},{"comment_id":"186077","upvote_count":"1","content":"Answer is B. Existing team member can easily be trained and hence no need to hire new resource for this simple job","poster":"asheesh0574","timestamp":"1600944600.0"},{"content":"B - Utilize free tier and sustained use discounts. Provide training to the team about service cost management.\nhttps://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#billing_and_management","poster":"AshokC","upvote_count":"1","comments":[{"content":"the link does not mention B","poster":"passtest100","upvote_count":"1","comment_id":"185325","timestamp":"1600867680.0"}],"comment_id":"179606","timestamp":"1600134360.0"},{"timestamp":"1599965580.0","content":"A is better for minimizing the cost. How can training a whole team garantee that everyone do the right thing? a dedicate staff or professional can do it better.","comment_id":"178514","comments":[{"upvote_count":"2","poster":"cate0012","timestamp":"1607295180.0","content":"How can hiring a whole person be cheaper than making sure everyone on their team knows how to control costs? And even if you have that person who watches costs, if the people using the cloud are unaware of what it costs them, they can make very stupid mistakes before the guy who manages costs can catch them. For instance, spin up 1000 across 10 regions, or Query 20 PB of BQ data multiple times a day. I had a customer spend $35,000 on some BQ queries he wrote. He was doing SELECT * on his datasets in a script. Set up a cron job and went away for the weekend. After 3 days he had spent $80,000 on BQ. Is it the fault of the guy who was supposed to be watching out for cost control? No, it's the fault of the manager who didn't provide training for the entire team.","comments":[{"comment_id":"236876","poster":"cate0012","upvote_count":"2","timestamp":"1607297220.0","content":"Additionally you wouldn't want to hire a person for something that you are only trying out. What if they decide not to use GCP. Do they let the person go after 6 months? It's gotta be B."}],"comment_id":"236862"}],"poster":"passtest100","upvote_count":"2"},{"timestamp":"1598620500.0","upvote_count":"1","comment_id":"168471","poster":"Kabiliravi","content":"B is correct, even if Staff knows everything one of the team member might do something and cause overcost because the team did not pass any training"},{"upvote_count":"1","comment_id":"162410","poster":"wiqi","timestamp":"1597946220.0","content":"sustained preferred over committed and training preferred over staff position.\nSo I will go with B."},{"timestamp":"1594988520.0","content":"I believe A is correct","upvote_count":"2","comment_id":"137152","poster":"elnagmy"},{"comment_id":"135659","upvote_count":"3","timestamp":"1594812120.0","content":"I choose B in the exam","poster":"daurib"},{"timestamp":"1594123920.0","poster":"victor_smith","upvote_count":"4","content":"if everyone says \"B\" why no one corrects the response for 8 months now?","comment_id":"128913"},{"poster":"Gobblegobble","comment_id":"126844","timestamp":"1593952740.0","content":"B is right answer","upvote_count":"2"},{"content":"Prefer sustained use discounts over committed use discounts, because it is a start up.\nThen choose B as the corretc.\nhttps://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#billing_and_management","poster":"mlantonis","timestamp":"1592902320.0","upvote_count":"1","comment_id":"117250"},{"timestamp":"1592638020.0","poster":"Tushant","content":"B is the correct answer","upvote_count":"2","comment_id":"114561"},{"upvote_count":"4","poster":"kban","content":"Correct answer as given in Linux academy practice exam is B","comment_id":"113009","timestamp":"1592466420.0"},{"comment_id":"110821","content":"I would also say B, despite the answer saying A is correct. If you're unsure of adoption you aren't going to take on a new employee dedicated to it!","timestamp":"1592226180.0","upvote_count":"1","poster":"devnull10"},{"timestamp":"1592056620.0","poster":"gfhbox0083","comment_id":"109499","upvote_count":"2","content":"B, for sure.\nUtilize free tier and sustained use discounts. Provide training to the team about service cost management."},{"content":"B it is as per Linux Academy practice qn: Anyone who will be utilizing GCP services should be trained on best practices for managing costs.","timestamp":"1592030460.0","poster":"syu31svc","comment_id":"109222","upvote_count":"3"},{"content":"B is the correct answer","upvote_count":"2","timestamp":"1591110420.0","poster":"Nirms","comment_id":"100948"},{"poster":"Ziegler","content":"Agreed with B as the right answer because this is a startup of use of GCP (cloud). Hence apart from using the free tier as provided by Google you also need to provide training to staff in order to get used to the new platform","timestamp":"1591105740.0","upvote_count":"2","comment_id":"100870"},{"timestamp":"1590651840.0","poster":"AD2AD4","comment_id":"97344","upvote_count":"3","content":"Final Decision to go with Option B"},{"timestamp":"1590095880.0","content":"I will go with B","upvote_count":"2","poster":"gcp_aws","comment_id":"93618"},{"content":"Agree its B.","comment_id":"90268","upvote_count":"1","poster":"laksg","timestamp":"1589680560.0"},{"timestamp":"1589508120.0","content":"B or SB, no other choice.","upvote_count":"2","poster":"Jack_in_Large","comment_id":"89259"},{"comment_id":"86359","upvote_count":"3","content":"Sustained use discounts are the right way to go which means A or B. I can't see provisioning a staff person at this point in the game so I would go with B.","poster":"clouddude","timestamp":"1589078520.0"},{"upvote_count":"4","content":"I choose B in the exam","poster":"[Removed]","comments":[{"poster":"droogie","comments":[{"poster":"daurib","comment_id":"135940","upvote_count":"3","timestamp":"1594836600.0","content":"The PCA Exam. I did same too"}],"comment_id":"107956","upvote_count":"8","timestamp":"1591894500.0","content":"This guy always uses the exact same phrase...not sure which exam he is referring to"}],"comment_id":"56377","timestamp":"1582873020.0"},{"timestamp":"1580392380.0","content":"answer: B","comment_id":"44764","upvote_count":"2","poster":"2g"},{"content":"B is correct","poster":"sri007","timestamp":"1579198620.0","upvote_count":"2","comment_id":"39821"},{"content":"Agreed with B","poster":"aviv","comment_id":"29587","timestamp":"1576338000.0","upvote_count":"3"},{"comment_id":"24242","poster":"kalschi","content":"according Google's best practice it should be B\n\nhttps://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#billing_and_management","timestamp":"1574675160.0","upvote_count":"10"}],"answers_community":["B (100%)"],"choices":{"C":"Utilize free tier and committed use discounts. Provision a staff position for service cost management.","B":"Utilize free tier and sustained use discounts. Provide training to the team about service cost management.","A":"Utilize free tier and sustained use discounts. Provision a staff position for service cost management.","D":"Utilize free tier and committed use discounts. Provide training to the team about service cost management."},"timestamp":"2019-10-25 08:49:00","question_images":[],"exam_id":4,"question_text":"You are analyzing and defining business processes to support your startup's trial usage of GCP, and you don't yet know what consumer demand for your product will be. Your manager requires you to minimize GCP service costs and adhere to Google best practices. What should you do?","answer_description":"","answer":"B","isMC":true,"question_id":140,"topic":"1","answer_ET":"B","answer_images":[],"unix_timestamp":1571986140,"url":"https://www.examtopics.com/discussions/google/view/7190-exam-professional-cloud-architect-topic-1-question-44/"}],"exam":{"id":4,"name":"Professional Cloud Architect","provider":"Google","isMCOnly":false,"numberOfQuestions":279,"isBeta":false,"isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":28},"__N_SSP":true}