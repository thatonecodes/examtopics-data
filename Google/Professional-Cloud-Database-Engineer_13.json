{"pageProps":{"questions":[{"id":"Eljtb8YTqC7VGMtADDZI","choices":{"C":"1. Provision a Cloud SQL for MySQL instance in us-central1-a.\n2. Create a multiple-zone instance in us-east-b.\n3. Create a read replica in us-east1-c.","B":"1. Provision a Cloud SQL for MySQL instance in us-central1-a.\n2. Create a multiple-zone instance in us-central1-b.\n3. Create a read replica in us-east1-b.","D":"1. Provision a Cloud SQL for MySQL instance in us-central1-a.\n2. Create a multiple-zone instance in us-east1-b.\n3. Create a read replica in us-central1-b.","A":"1. Provision a Cloud SQL for MySQL instance in us-central1-a.\n2. Create a multiple-zone instance in us-west1-b.\n3. Create a read replica in us-east1-c."},"discussion":[{"content":"Selected Answer: B\nThe answers are badly worded. B looks right, but reads like there will be two instances, one single-zone and one HA, in the same region. Presumably it's actually describing a single HA instance in central1.","poster":"Steve8512","comment_id":"1490077","upvote_count":"1","timestamp":"1743797700.0"},{"upvote_count":"1","poster":"Ral17","timestamp":"1733615460.0","content":"Selected Answer: B\nCloud SQL is a regional service with read replicas allowed in other regions. So the answer must reference 2 different zones in the us-central1 region, one for the primary and one for the HA replica. A read replica needs to be in a zone within us-east1.","comment_id":"1323296"},{"timestamp":"1710263940.0","poster":"dynamic_dba","upvote_count":"4","comment_id":"837253","content":"B.\nCloud SQL is a regional service with read replicas allowed in other regions. So the answer must reference 2 different zones in the us-central1 region, one for the primary and one for the HA replica. A read replica needs to be in a zone within us-east1. The only options which provides that is B."},{"poster":"sp57","upvote_count":"2","timestamp":"1703967960.0","comment_id":"762301","content":"B is correct. DR write-up helps... https://cloud.google.com/sql/docs/sqlserver/intro-to-cloud-sql-disaster-recovery"},{"timestamp":"1703516460.0","upvote_count":"1","poster":"pk349","content":"D: Provision a Cloud SQL for MySQL instance in us-central1-a.\nCreate a multiple-zone instance in ***** us-east1-b.\nCreate a read replica in us-central1-b.","comment_id":"755745"},{"upvote_count":"4","timestamp":"1703474880.0","comment_id":"755391","poster":"GCP72","content":"Selected Answer: B\nB is the correct answer"},{"poster":"chelbsik","comment_id":"755154","content":"Selected Answer: B\nVery confusing description. My only guess is that steps 1 and 2 describe the same action - creating primary instance with multiple zones HA. This eliminates all answers but B, because you can only have HA setup within the same region.","upvote_count":"2","timestamp":"1703452500.0"},{"comment_id":"752526","upvote_count":"1","poster":"range9005","timestamp":"1703173740.0","content":"I guess D\nPrimary Instance Us-Central\nFor HA, Multi-Region us-east\nReplica on the top of primary i.e Us-central for low latency"},{"timestamp":"1703108820.0","upvote_count":"1","poster":"fredcaram","content":"I got a little confused about the text, for B to be the correct answer the multiple-zone instance would be the stand-by instance and the read replica would be the cross-region read replica.","comment_id":"751550"}],"answer":"B","answer_ET":"B","question_id":61,"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/92238-exam-professional-cloud-database-engineer-topic-1-question/","answers_community":["B (100%)"],"answer_images":[],"question_text":"Your organization has a critical business app that is running with a Cloud SQL for MySQL backend database. Your company wants to build the most fault-tolerant and highly available solution possible. You need to ensure that the application database can survive a zonal and regional failure with a primary region of us-central1 and the backup region of us-east1. What should you do?","unix_timestamp":1671572820,"topic":"1","answer_description":"","timestamp":"2022-12-20 22:47:00","question_images":[],"exam_id":5},{"id":"usq2WAQL866S6v4XowkO","timestamp":"2022-12-20 22:53:00","question_text":"You are building an Android game that needs to store data on a Google Cloud serverless database. The database will log user activity, store user preferences, and receive in-game updates. The target audience resides in developing countries that have intermittent internet connectivity. You need to ensure that the game can synchronize game data to the backend database whenever an internet network is available. What should you do?","isMC":true,"question_images":[],"topic":"1","discussion":[{"poster":"dynamic_dba","comment_id":"837256","timestamp":"1726155000.0","content":"A.\nB is wrong since that’s not secure and doesn’t make sense. C is bizarre and doesn’t leverage a GCP serverless database. The key is intermittent internet coverage, meaning real-time syncing is not needed and can be supported. That rules out Spanner, which leaves Firestore. Probably Datastore mode, not that the question mentions that. The link provided by GCP72 is spot on.","upvote_count":"8"},{"content":"A: Use Firestore.","comment_id":"755744","poster":"pk349","timestamp":"1719320400.0","upvote_count":"1"},{"content":"Selected Answer: A\nA is a correct answer , Cloud Firestone https://firebase.google.com/docs/firestore","poster":"GCP72","comment_id":"755393","upvote_count":"3","timestamp":"1719279240.0"},{"timestamp":"1718977860.0","poster":"range9005","comment_id":"752529","content":"Selected Answer: A\nAndroid App -->> Cloud Firestone","upvote_count":"4"},{"comment_id":"751568","content":"Selected Answer: A\nA supports offline sync","timestamp":"1718913180.0","upvote_count":"2","poster":"fredcaram"}],"answer_ET":"A","question_id":62,"unix_timestamp":1671573180,"exam_id":5,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/92240-exam-professional-cloud-database-engineer-topic-1-question/","answer":"A","choices":{"A":"Use Firestore.","B":"Use Cloud SQL with an external (public) IP address.","C":"Use an in-app embedded database.","D":"Use Cloud Spanner."},"answer_images":[],"answers_community":["A (100%)"]},{"id":"k5m68qAp4MFG2yjEZZS5","answer":"AE","question_text":"You released a popular mobile game and are using a 50 TB Cloud Spanner instance to store game data in a PITR-enabled production environment. When you analyzed the game statistics, you realized that some players are exploiting a loophole to gather more points to get on the leaderboard. Another DBA accidentally ran an emergency bugfix script that corrupted some of the data in the production environment. You need to determine the extent of the data corruption and restore the production environment. What should you do? (Choose two.)","choices":{"B":"If the corruption is significant, perform a stale read and specify a recovery timestamp. Write the results back.","D":"If the corruption is insignificant, use backup and restore, and specify a recovery timestamp.","E":"If the corruption is insignificant, perform a stale read and specify a recovery timestamp. Write the results back.","C":"If the corruption is significant, use import and export.","A":"If the corruption is significant, use backup and restore, and specify a recovery timestamp."},"answer_ET":"AE","question_id":63,"isMC":true,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/92369-exam-professional-cloud-database-engineer-topic-1-question/","timestamp":"2022-12-21 16:52:00","unix_timestamp":1671637920,"answer_images":[],"discussion":[{"upvote_count":"11","content":"Selected Answer: AE\nhttps://cloud.google.com/spanner/docs/pitr#ways-to-recover\nTo recover the entire database, backup or export the database specifying a timestamp in the past and then restore or import it to a new database. This is typically used to recover from data corruption issues when you have to revert the entire database to a point-in-time before the corruption occurred.\nThis part describes significant corruption - A\n\nTo recover a portion of the database, perform a stale read specifying a query-condition and timestamp in the past, and then write the results back into the live database. This is typically used for surgical operations on a live database. For example, if you accidentally delete a particular row or incorrectly update a subset of data, you can recover it with this method. \nThis describes insignificant corruption case - E","comment_id":"755140","poster":"chelbsik","timestamp":"1719255360.0"},{"upvote_count":"4","comment_id":"837267","timestamp":"1726156620.0","poster":"dynamic_dba","content":"A, E.\nThe answers are split between significant and insignificant. For insignificant, the simplest form of recovery would be E. That eliminates D. For significant, let’s assume that means a lot of data of the the 50 TB total. A stale read and write back would probably been too onerous, so that eliminates B. That leaves A and C. The question doesn’t mention anything about logical backups (export) which suggests a restore from a backup would be appropriate of a large amount of data that needed to be recovered. \nhttps://cloud.google.com/spanner/docs/pitr\nhttps://cloud.google.com/spanner/docs/backup/restore-backup"},{"timestamp":"1719958020.0","content":"AE are correct.","comment_id":"764145","upvote_count":"3","poster":"TFMV"},{"timestamp":"1719320340.0","upvote_count":"1","content":"B: If the corruption is significant, perform a stale ***** read and specify a recovery timestamp. Write the results back.\nD: If the corruption is insignificant, use backup and ***** restore, and specify a recovery timestamp.","comment_id":"755743","poster":"pk349"},{"content":"Selected Answer: BD\nB. If the corruption is significant, perform a stale read and specify a recovery timestamp. Write the results back.\nD. If the corruption is insignificant, use backup and restore, and specify a recovery timestamp.","poster":"range9005","comment_id":"752534","timestamp":"1718977980.0","upvote_count":"1"},{"upvote_count":"1","poster":"range9005","content":"Selected Answer: BC\nB. If the corruption is significant, perform a stale read and specify a recovery timestamp. Write the results back.\nC. If the corruption is significant, use import and export.","timestamp":"1718977920.0","comment_id":"752533","comments":[]}],"answers_community":["AE (85%)","Other"],"exam_id":5,"topic":"1","question_images":[]},{"id":"PxxTmsVpz3NU7R1nCSCK","timestamp":"2022-12-20 23:04:00","question_text":"You are starting a large CSV import into a Cloud SQL for MySQL instance that has many open connections. You checked memory and CPU usage, and sufficient resources are available. You want to follow Google-recommended practices to ensure that the import will not time out. What should you do?","isMC":true,"question_images":[],"topic":"1","discussion":[{"poster":"dynamic_dba","content":"A.\nCPU and memory are OK so that elimiates B and D. C is nonsense which leaves A. This is supported by Google’s own documention (read recommended practices) which says close unused operations and re-start the instance. This is the best way to ensure maximum resources for the import operation.\nhttps://cloud.google.com/sql/docs/mysql/import-export#troubleshooting","timestamp":"1726157160.0","comment_id":"837276","upvote_count":"2"},{"comment_id":"761359","content":"C. for import service account needs storage.buckets.get & storage.objects.get","upvote_count":"1","timestamp":"1719678420.0","poster":"SVGoogle89"},{"comment_id":"755742","content":"A: Close idle connections or restart the instance before beginning the import operation.","timestamp":"1719320220.0","poster":"pk349","upvote_count":"2"},{"upvote_count":"3","content":"Selected Answer: A\nThe import operation is taking too long. Too many active connections can interfere with import operations.\nClose unused operations. Check the CPU and memory usage of your Cloud SQL instance to make sure there are plenty of resources available. The best way to ensure maximum resources for the import is to restart the instance before beginning the operation.\n\nA restart:\n\nCloses all connections.\nEnds any tasks that may be consuming resources\nhttps://cloud.google.com/sql/docs/mysql/import-export","poster":"GCP72","timestamp":"1719297660.0","comment_id":"755522"},{"upvote_count":"1","comment_id":"755161","content":"Selected Answer: A\nEliminate B and D because 'You checked memory and CPU usage, and sufficient resources are available.' \nEliminate C because it makes no sense.","poster":"chelbsik","timestamp":"1719256920.0","comments":[{"content":"To elaborate on C - it's required for the export into Cloud Storage, which is not the case\nhttps://cloud.google.com/sql/docs/postgres/import-export/import-export-csv#required_roles_and_permissions_for_exporting","upvote_count":"2","timestamp":"1719257040.0","comment_id":"755165","poster":"chelbsik"}]},{"content":"Selected Answer: A\nClose idle connections or restart the instance before beginning the import operation.","timestamp":"1719004380.0","upvote_count":"3","poster":"range9005","comment_id":"752844"},{"poster":"fredcaram","timestamp":"1718913840.0","comment_id":"751581","content":"Selected Answer: A\nIt should be A given the amount of opened connections","upvote_count":"3"}],"answer_ET":"A","question_id":64,"unix_timestamp":1671573840,"exam_id":5,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/92241-exam-professional-cloud-database-engineer-topic-1-question/","answer":"A","choices":{"B":"Increase the amount of memory allocated to your instance.","A":"Close idle connections or restart the instance before beginning the import operation.","C":"Ensure that the service account has the Storage Admin role.","D":"Increase the number of CPUs for the instance to ensure that it can handle the additional import operation."},"answer_images":[],"answers_community":["A (100%)"]},{"id":"4AcjxfbA5LhBYJlHI11O","choices":{"D":"Set up Traffic Director.","C":"Set up Private Service Connect.","B":"Set up Serverless VPC Access.","A":"Set up a Shared VPC, configure multiple service projects, and create firewall rules."},"unix_timestamp":1671664620,"answers_community":["A (100%)"],"answer_description":"","answer_ET":"A","answer":"A","timestamp":"2022-12-22 00:17:00","isMC":true,"exam_id":5,"topic":"1","question_id":65,"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/92400-exam-professional-cloud-database-engineer-topic-1-question/","question_text":"You are migrating your data center to Google Cloud. You plan to migrate your applications to Compute Engine and your Oracle databases to Bare Metal Solution for Oracle. You must ensure that the applications in different projects can communicate securely and efficiently with the Oracle databases. What should you do?","discussion":[{"timestamp":"1726158660.0","upvote_count":"2","comment_id":"837287","poster":"dynamic_dba","content":"A.\nB is wrong since Serverless VPC Access is for connecting to your VPC network from serverless environments (Cloud Run, App Engine, Cloud Functions). C is wrong as this concerns private consumption of services across VPC networks that belong to different groups, teams, projects, or organizations. D is wrong because it concerns application networking for services. Nothing in its documentation mentions BMS. That leaves A. I would prefer to have seen something about VPC network peering, but the clincher is firewall rules which you would use to limit IP traffic sources to the backend Oracle DBs residing in their own Google managed VPC on BMS."},{"timestamp":"1725561900.0","upvote_count":"2","poster":"H_S","content":"Selected Answer: A\nThe answer is for sure A\nread the following; https://medium.com/google-cloud/shared-vpc-in-google-cloud-64527e0a409e#:~:text=Unlike%20VPC%20peering%2C%20Shared%20VPC%20connects%20projects%20within%20the%20same%20organization.&text=There%20are%20a%20lot%20of,between%20VPCs%20in%20different%20projects.","comment_id":"830311"},{"upvote_count":"3","poster":"GCP72","content":"Selected Answer: A\nA is the correct answer","timestamp":"1719297900.0","comment_id":"755524"},{"upvote_count":"3","timestamp":"1719257640.0","comment_id":"755174","content":"Selected Answer: A\nB is not applicable here.\nC is also not the case - don't confuse it with Private Google Access https://cloud.google.com/bare-metal/docs/bms-security#enforce-a-secure-perimeter-with-private-google-access\nWe don't have a Service Mesh here, so D is also not an option.\n\nI go for A - https://cloud.google.com/bare-metal/docs/bms-security#:~:text=As%20shown%20in%20Figure%206%2C%20use%20a%20shared%20VPC%20architecture%20to%20allow%20resources%20from%20different%20projects%20to%20access%20the%20Bare%20Metal%20Solution%20servers","poster":"chelbsik"},{"upvote_count":"3","timestamp":"1719004620.0","comment_id":"752846","poster":"range9005","content":"Selected Answer: A\nWhen you use Shared VPC, you designate a project as a host project and attach one or more other service projects to it."}],"answer_images":[]}],"exam":{"numberOfQuestions":132,"id":5,"isBeta":false,"lastUpdated":"11 Apr 2025","name":"Professional Cloud Database Engineer","provider":"Google","isMCOnly":true,"isImplemented":true},"currentPage":13},"__N_SSP":true}