{"pageProps":{"questions":[{"id":"f9g0nfo6S77oxkLCVx8D","question_images":[],"choices":{"A":"Provision service account keys for the on-premises infrastructure and for the GCE virtual machines (VMs)","B":"Authenticate the on-premises infrastructure with a user account and provision service account keys for the VMs","C":"Provision service account keys for the on-premises infrastructure and use Google Cloud Platform (GCP) managed keys for the VMs","D":"Deploy a custom authentication service on GCE/Google Kubernetes Engine (GKE) for the on-premises infrastructure and use GCP managed keys for the VMs"},"unix_timestamp":1580063880,"exam_id":4,"answer_images":[],"answer_ET":"C","timestamp":"2020-01-26 19:38:00","answers_community":["C (100%)"],"topic":"2","question_text":"JencoMart has decided to migrate user profile storage to Google Cloud Datastore and the application servers to Google Compute Engine (GCE). During the migration, the existing infrastructure will need access to Datastore to upload the data.\nWhat service account key-management strategy should you recommend?","isMC":true,"url":"https://www.examtopics.com/discussions/google/view/12793-exam-professional-cloud-architect-topic-2-question-3/","answer_description":"","discussion":[{"comment_id":"84285","content":"Answer: C.\nhttps://cloud.google.com/iam/docs/understanding-service-accounts#migrating_data_to_google_cloud_platform\n\nThere are two types of service account keys:\n\nGCP-managed keys. These keys are used by Cloud Platform services such as App Engine and Compute Engine. They cannot be downloaded, and are automatically rotated and used for signing for a maximum of two weeks. The rotation process is probabilistic; usage of the new key will gradually ramp up and down over the key's lifetime. We recommend caching the public key set for a service account for at most 24 hours to ensure that you always have access to the current key set.\n\nUser-managed keys. These keys are created, downloadable, and managed by users. They expire 10 years from creation, and cease authenticating successfully when they are deleted from the service account.","timestamp":"1620250260.0","upvote_count":"28","poster":"Zarmi","comments":[{"upvote_count":"1","poster":"Carsonza","comment_id":"173559","content":"while that heading doesn't exist anymore the graphic that it is that doc speaks for itself.","timestamp":"1630780560.0"}]},{"poster":"shashu07","comment_id":"111544","content":"Correct Answer : C\nWhere will the code that assumes the identity of the service account be running: on Google Cloud Platform or on-premises?\nhttps://cloud.google.com/iam/docs/understanding-service-accounts","upvote_count":"8","timestamp":"1623845460.0"},{"timestamp":"1733340720.0","upvote_count":"2","comment_id":"1087902","poster":"pakilodi","content":"Selected Answer: C\nAnswer: C"},{"comment_id":"700028","content":"Selected Answer: C\nC is the right answer https://cloud.google.com/iam/docs/understanding-service-accounts#migrating_data_to_google_cloud_platfor","poster":"Mahmoud_E","timestamp":"1697812500.0","upvote_count":"2"},{"content":"Selected Answer: C\nvote C","comment_id":"487766","upvote_count":"2","timestamp":"1669515120.0","poster":"joe2211"},{"timestamp":"1657197480.0","upvote_count":"1","poster":"MamthaSJ","content":"Answer is C","comment_id":"400870"},{"upvote_count":"4","content":"Answer C.\n\nRefer to first figure in https://cloud.google.com/iam/docs/understanding-service-accounts#migrating_data_to_google_cloud_platfor. It mentions using User Managed Keys for on-premises usage of services accounts and GCP managed keys for code running in GCP.\n\nAlso in case study it emphasise using \"managed services as much as possible\". So this rules out A.","comment_id":"372298","timestamp":"1654135380.0","poster":"Yogikant"},{"timestamp":"1653049560.0","upvote_count":"1","comment_id":"362143","poster":"victory108","content":"C. Provision service account keys for the on-premises infrastructure and use Google Cloud Platform (GCP) managed keys for the VMs"},{"upvote_count":"1","timestamp":"1651642500.0","comment_id":"349164","content":"Answer C as per https://cloud.google.com/iam/docs/understanding-service-accounts#migrating_data_to_google_cloud_platform","poster":"Koushick"},{"content":"Answer is C","poster":"Ausias18","upvote_count":"1","comment_id":"330043","timestamp":"1649305620.0"},{"timestamp":"1647782040.0","upvote_count":"1","content":"When you provision service account keys for the on-premises infrastructure you must then manage them. So if the kyes are managed by GCP you must set up a process to rotate keys in the on-prem infrastructure. It is quite chalenging. \nTherefore I prefer option B.","comment_id":"315622","poster":"pawel_ski"},{"timestamp":"1644994740.0","comment_id":"291548","content":"I will go with A which is very similar to C but answer C suggest use Google Cloud Platform (GCP) managed keys for the VMs (there is no word : \"ONL\" for the VMs) but it's suggestion (this is how I perceive it)\nAnswer A is copy/paste from link : https://cloud.google.com/iam/docs/understanding-service-accounts#migrating_data_to_google_cloud_platform\n\nA service account is a special type of Google account intended to represent a non-human user that needs to authenticate and be authorized to access data in Google APIs.\n\nTypically, service accounts are used in scenarios such as:\n\n- Running workloads on virtual machines (VMs).(first part of answer A = and for the GCE virtual machines (VMs))\n- Running workloads on on-premises workstations or data centers that call Google APIs. (Second part of answer A = Provision service account keys for the on-premises infrastructure)","poster":"AGG","upvote_count":"4"},{"timestamp":"1644313440.0","upvote_count":"1","comment_id":"286073","poster":"ahmedemad3","content":"Ans: C \nmake sense of the service account for infrastructure and managed key for VM"},{"comment_id":"280302","poster":"bnlcnd","upvote_count":"1","content":"A /B / C are all playing with words. But the key points is who need service account key. no matter where the key is managed. GCP managed or customer managed.\nOnly the on-prom resource need the service account key. so, only C is right.","timestamp":"1643597100.0"},{"poster":"ybe_gcp_cert","comment_id":"242474","timestamp":"1639392000.0","upvote_count":"2","content":"In C, the vm part is wrong. A VM doesn't use key directly from a conf point of view. It uses a service account that is linked with a key pair. the key could be managed by google or user managed.\nhttps://cloud.google.com/iam/docs/service-accounts#service_account_keys\n\nC is only playing with words...\nI would go with A."},{"content":"C is ok","comment_id":"231267","timestamp":"1638294600.0","poster":"_CloudTech_","upvote_count":"1"},{"comment_id":"230194","timestamp":"1638172740.0","poster":"JCGO","upvote_count":"2","content":"Accessing something from on-premise to google cloud done by using service accounts this days. Datastore for example: https://cloud.google.com/datastore/docs/activate Service account keys can be managed by google, or can be self-generated and public key uploaded. \nQuestion asks about provisioning service account keys during migration phase, when on-prem stuff needs access to datastore. C looks good. A looks good also, but a involves provisioning service account keys for cloud VM's -> it is done another way. you could give permissions to defsault compute service account per API, or create service account and give it appropriate premissions and choose while creating cloud VM. I can not see any point bothering with service accout keys for cloud VM's here. So i choose C."},{"content":"Answer C:\n\"Provision service account keys for the on-premises infrastructure\": For code running on systems outside Google, you cannot use GCP-managed keys. You need to create Service account for it and provision User-managed keys. These keys are created, downloadable, and managed by users - This is solution for on-premises access to GCP datastore during migration\n\n\"use Google Cloud Platform (GCP) managed keys for the VMs\" - this is solution for Application server migration since there is no external access to GCP is required during the migration.","comment_id":"189108","timestamp":"1632838560.0","upvote_count":"3","poster":"akhadar2001"},{"content":"A is not correct; for VMs running on GCP, we the users don't need to provision SA keys explicitly","comment_id":"178794","comments":[{"comment_id":"443498","upvote_count":"1","poster":"amxexam","content":"But they use SA key automatically. SA is GCP managed key. From option, A provision (or do anything explisitly.) makes it confusing when it is automatically applied.","timestamp":"1662990180.0"}],"poster":"richardxyz","timestamp":"1631547180.0","upvote_count":"5"},{"poster":"vbondoo7","timestamp":"1630223460.0","comment_id":"169016","comments":[{"content":"the answer is A \nManaging service account keys\nThere are two types of service account keys:\n\nGCP-managed keys. These keys are used by Cloud Platform services such as App Engine and Compute Engine. They cannot be downloaded, and are automatically rotated and used for signing for a maximum of two weeks. The rotation process is probabilistic; usage of the new key will gradually ramp up and down over the key's lifetime. We recommend caching the public key set for a service account for at most 24 hours to ensure that you always have access to the current key set.\n\nUser-managed keys. These keys are created, downloadable, and managed by users. After you delete them from the service account, you cannot use them to authenticate.","poster":"dayody","timestamp":"1630377060.0","upvote_count":"1","comment_id":"170488"}],"content":"Its C, very obvious.","upvote_count":"3"},{"content":"Although A and C are similar in terms of the use of SA, i prefer C because differentiates user and google managed keys as show the graphic in the link https://cloud.google.com/iam/docs/understanding-service-accounts#migrating_data_to_google_cloud_platform","upvote_count":"4","poster":"Pupina","comment_id":"155788","timestamp":"1628710320.0"},{"upvote_count":"2","comment_id":"128782","poster":"cetanx","content":"I would go with A\nFor on-prem: service account keys are the best way to authenticate with Google APIs\nFor GCP: Preferably VMs with a service account (https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances) however that's not in the options, therefore we require service account access keys to access Datastore from the application running in the VMs.","timestamp":"1625650020.0"},{"poster":"desertlotus1211","upvote_count":"2","comment_id":"112476","content":"Answer is A:\nhttps://cloud.google.com/iam/docs/understanding-service-accounts\n\nCreating the service account and grant access via GCP managed keys and/or User managed keys. I think Answer A is inclusive of Answer C... Just a play on words...\nYou create the Service Account and apply the correct keys. 'A' is better than 'C'.\n\nAnswer C implies GCP managed keys are different than Service account keys - which wrong:\n\n'There are two types of service account keys:\n\nGCP-managed keys. These keys are used by Cloud Platform services such as App Engine and Compute Engine. They cannot be downloaded, and are automatically rotated and used for signing for a maximum of two weeks. The rotation process is probabilistic; usage of the new key will gradually ramp up and down over the key's lifetime. We recommend caching the public key set for a service account for at most 24 hours to ensure that you always have access to the current key set.\n\nUser-managed keys. These keys are created, downloadable, and managed by users. After you delete them from the service account, you cannot use them to authenticate.'","timestamp":"1623938880.0"},{"comment_id":"104711","upvote_count":"5","timestamp":"1623085260.0","poster":"CoolCat","content":"I think answer is A. I do not see the point of GCP managed keys because these are for encrypting harddrive not for database access that is asked in this question"},{"poster":"jayaen","comment_id":"98615","timestamp":"1622348760.0","content":"As per Google recommended practice for data migration onpremise - GCP or another cloud provider - GCP \nservice accounts key should be created in source part \nhttps://cloud.google.com/iam/docs/understanding-service-accounts#migrating_data_to\nC is correct answer","upvote_count":"6"},{"comment_id":"90614","upvote_count":"5","timestamp":"1621260300.0","content":"Answer is B as you need to first connect to on-prem VM using the user account and then You can use a service account from the virtual machines on the external cloud to push the data to Google Cloud Platform. To do this, you must create and download a service account key when you create the service account and then use that key from the external process to call the Cloud Platform APIs.","poster":"Navi08"},{"timestamp":"1620825300.0","content":"A is right, because in migration code is running in On-premise not in GCP, so no need to have GCP managed keys.","poster":"ankit89","upvote_count":"2","comment_id":"87635"},{"comment_id":"55209","upvote_count":"4","timestamp":"1614292620.0","poster":"Smart","content":"The options are not clear. The main point here is to when to use google-managed SA vs. user-managed SA. To give access to on-prem servers use user-managed SA and for GCP resources use google-managed."},{"timestamp":"1613443440.0","content":"A is better","comment_id":"51080","poster":"sssz","upvote_count":"2"},{"content":"C is not correct, why the instance need to use key mgmt service for access to datastore? i think A, the service account could be use for on-prem and for cloud instance vm","upvote_count":"5","poster":"natpilot","comments":[{"comment_id":"303858","timestamp":"1646448000.0","upvote_count":"1","poster":"nitinz","content":"It is A"},{"upvote_count":"1","comment_id":"98130","timestamp":"1622278680.0","poster":"q4exam","content":"to encrypt the harddisk that is the CMEK"}],"timestamp":"1611686280.0","comment_id":"43006"}],"answer":"C","question_id":226},{"id":"PtHisVjnCLA86ooZ5NIj","choices":{"D":"Total visits and average latency for users from Asia","E":"The number of character sets present in the database","C":"Total visits, error rates, and latency from Asia","A":"Error rates for requests from Asia","B":"Latency difference between US and Asia"},"question_id":227,"unix_timestamp":1581936180,"isMC":true,"timestamp":"2020-02-17 11:43:00","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/14318-exam-professional-cloud-architect-topic-2-question-4/","question_text":"JencoMart has built a version of their application on Google Cloud Platform that serves traffic to Asia. You want to measure success against their business and technical goals.\nWhich metrics should you track?","question_images":[],"answer_images":[],"exam_id":4,"answer_ET":"C","topic":"2","discussion":[{"upvote_count":"38","content":"Business Requirements include: Guarantee service availability and support. I would choose C","poster":"VASI","timestamp":"1597653780.0","comment_id":"51608","comments":[{"timestamp":"1630802460.0","comment_id":"303860","content":"D it meets both requirements. Error was never asked for in KPI.","poster":"nitinz","upvote_count":"9"},{"content":"I wonder how specific we have to be and how much common sense/best practices should we ignore.","upvote_count":"11","comment_id":"55214","poster":"Smart","timestamp":"1598388540.0"}]},{"content":"Answer is C; more complete imo. Those aligning to D should note that average latency is not the only metric available to measure and is too specific.\n\n\"Total visits\" covers the business requirements:\n- Optimize for capacity during peak periods and value during off-peak periods.\n- Expand services into Asia.\n\n\"Error rates\" covers business requirement:\n- Guarantee service availability and support. ** if service is unavailable, errors are reported!\n\n\"Latency\" covers technical requirement:\n- Decrease latency in Asia.","timestamp":"1634201700.0","upvote_count":"25","poster":"JohnWick2020","comment_id":"335329"},{"timestamp":"1721934900.0","content":"Selected Answer: C\nI understand the Case Study is already deprecated by here is my 5 cents:\nI chose C. Total visits, error rates, and latency from Asia.\nHere's why this option is the most appropriate:\nTotal Visits: Monitoring total visits helps in assessing the application's capacity to handle peak and off-peak periods, which aligns with the goal of optimizing capacity. It also provides insight into the success of their expansion efforts in Asia.\nError Rates: Tracking error rates is crucial for ensuring service availability and support. It directly relates to the goal of guaranteeing availability by identifying and resolving issues that could lead to service disruptions.\nLatency from Asia: Monitoring latency specifically for users in Asia addresses the technical goal of decreasing latency in this region. It's a direct measure of the performance improvements and user experience enhancements expected from the cloud migration.","upvote_count":"3","comment_id":"1132069","poster":"ammonia_free"},{"poster":"Mahmoud_E","content":"Selected Answer: D\nD is the best answer","comment_id":"700035","timestamp":"1682001480.0","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: C\nC.\nIt says Guarantee service availability, we need to check for error rates to make sure our application is working perfectly fine.","timestamp":"1678656480.0","comment_id":"667402","poster":"alexandercamachop"},{"upvote_count":"12","poster":"H_S","comment_id":"614754","timestamp":"1670722800.0","content":"CASE STUDY DEPRECATED PLEASE REMOVE\nReview the case studies that may be used in the exam.\nEHR Healthcare\nHelicopter Racing League\nMountkirk Games\nTerramEarth"},{"timestamp":"1667894640.0","upvote_count":"1","content":"Selected Answer: C\nerror and latency will cover technical and visits buissness hence C","comment_id":"598451","poster":"amxexam"},{"timestamp":"1654237740.0","content":"Selected Answer: C\nVote C","poster":"nqthien041292","comment_id":"493019","upvote_count":"5"},{"content":"Selected Answer: D\nvote D","timestamp":"1653610440.0","comments":[{"comment_id":"503961","upvote_count":"1","poster":"joe2211","timestamp":"1655505900.0","content":"Keywords, their business and technical goals are aimed to Asian users only\nBusiness Requirements:\nExpand services into Asia\n\nTechnical Requirements:\n- Decrease latency in Asia","comments":[{"poster":"AMohanty","upvote_count":"1","comment_id":"643202","timestamp":"1675667700.0","content":"A part of their Goal is : Guarantee service availability and support\nErrors doesn't cater well to their Service Availability."}]}],"poster":"joe2211","comment_id":"487769","upvote_count":"4"},{"content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","upvote_count":"2","comment_id":"406668","poster":"kopper2019","timestamp":"1642220100.0"},{"upvote_count":"4","content":"guys trust me - it's C","timestamp":"1642113600.0","poster":"Urban_Life","comment_id":"405714"},{"comment_id":"400872","upvote_count":"2","timestamp":"1641566460.0","content":"Answer is D","poster":"MamthaSJ"},{"content":"C. Total visits, error rates, and latency from Asia","poster":"victory108","upvote_count":"4","comment_id":"362253","timestamp":"1637423820.0"},{"content":"Answer is D","comment_id":"325770","poster":"Ausias18","timestamp":"1633089840.0","upvote_count":"1"},{"upvote_count":"2","poster":"pawel_ski","timestamp":"1632136620.0","comment_id":"315628","content":"I prefer to see the latency change not only to have an average value. \nI choose C."},{"poster":"ebinv2","comment_id":"303194","content":"Success against business and and technical goals- should be C , as it check error rates also","timestamp":"1630732500.0","upvote_count":"1"},{"content":"its D, based on the case, the technical requirement is to reduce latency","comment_id":"300064","timestamp":"1630029120.0","poster":"Fadhli","upvote_count":"2"},{"upvote_count":"6","timestamp":"1627692660.0","comment_id":"280305","poster":"bnlcnd","content":"C is better. error rate is critical not just latency. sometime the latency can be very good but just because every request errored out and finished faster.\n\"from asia\" or \"users in asia\" ? if that matters, this is not a GCP test. it's a G2 English test for Asian schools."},{"poster":"_CloudTech_","upvote_count":"3","comment_id":"231323","timestamp":"1622395560.0","content":"D is ok"},{"poster":"francisco_guerra","content":"Im not sure but error rate its a good measure of technical goals\nso Im think C is a good option too","timestamp":"1620159900.0","upvote_count":"4","comment_id":"213048"},{"comment_id":"182024","content":"Would choose D.\nD is more specific than C , also C provides error rate which is not directly a requirement . So D is better fit.","timestamp":"1616124120.0","poster":"brati_sankar","upvote_count":"2"},{"content":"D - It's more specific to visits and latency for their new resources set up for Asia.","comment_id":"175810","timestamp":"1615205820.0","poster":"varuneshwar","upvote_count":"2"},{"poster":"cetanx","comment_id":"128785","upvote_count":"10","timestamp":"1610019180.0","content":"I think it's just playing with the words;\nC says latency from Asia (not clear if they mean for Asian customers or European/American)\nD says average latency for users in Asia (better targeted metric)\nSo I believe it's D"},{"comments":[{"timestamp":"1614890580.0","poster":"Carsonza","comment_id":"173563","content":"...so does C bad justification.","upvote_count":"3"}],"comment_id":"98616","upvote_count":"4","poster":"jayaen","content":"D is right , since it covers \"total visits\" to see whether extend services business requirement goal and average latency KPI to meet technical requirements","timestamp":"1606718280.0"},{"timestamp":"1605553680.0","poster":"Jack_in_Large","content":"I support Charlie, though David is not bad either.","comment_id":"90049","upvote_count":"2"},{"poster":"Zarmi","timestamp":"1604619480.0","comment_id":"84286","upvote_count":"2","comments":[{"poster":"amxexam","timestamp":"1647100020.0","comment_id":"443500","content":"C is better than D as it has error as additional, anything additional is not bad until there is some restriction from the requirement to do so for cost-effective or something.","upvote_count":"2"}],"content":"Why D is better than C?"}],"answers_community":["C (67%)","D (33%)"],"answer":"C"},{"id":"nW1XInQbPsGhxVr5Kg2s","isMC":true,"timestamp":"2019-10-17 11:45:00","answer_description":"","answer_ET":"ACF","question_id":228,"question_images":["https://www.examtopics.com/assets/media/exam-media/04339/0000700001.png"],"unix_timestamp":1571305500,"question_text":"//IMG//\nThe migration of JencoMart's application to Google Cloud Platform (GCP) is progressing too slowly. The infrastructure is shown in the diagram. You want to maximize throughput.\nWhat are three potential bottlenecks? (Choose three.)","answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/6708-exam-professional-cloud-architect-topic-2-question-5/","choices":{"F":"Complicated internet connectivity between the on-premises infrastructure and GCP","D":"Fewer virtual machines (VMs) in GCP than on-premises machines","B":"A tier of Google Cloud Storage that is not suited for this task","A":"A single VPN tunnel, which limits throughput","E":"A separate storage layer outside the VMs, which is not suited for this task","C":"A copy command that is not suited to operate over long distances"},"topic":"2","discussion":[{"upvote_count":"21","timestamp":"1606756560.0","comment_id":"231249","content":"Where are you Tartor?","poster":"_CloudTech_"},{"comment_id":"17522","content":"Think A,D,E. \"Copy command not suited for long distances\", what does it mean?","timestamp":"1572081660.0","comments":[{"comment_id":"119356","upvote_count":"1","timestamp":"1593081780.0","poster":"kaush","content":"you need reliable agent software installed to copy files with retries ,copy command not sufficient","comments":[{"timestamp":"1598841660.0","comment_id":"170492","upvote_count":"13","poster":"dayody","content":"the diagram does not show copy command."}]}],"upvote_count":"18","poster":"jcmoranp"},{"comment_id":"1261766","poster":"6a8c7ad","timestamp":"1722961680.0","upvote_count":"2","content":"ABD single vpn, cloud storage vs previous local, and 6 machines in gcp, 9 on prem."},{"comment_id":"925896","poster":"BiddlyBdoyng","timestamp":"1686996240.0","upvote_count":"3","content":"I don't get why B isn't correct. Cloud Storage isn't a good replacement for SAN, especially when we have a database running on some of the VMs."},{"content":"Selected Answer: ACF\nI think ACF","poster":"taer","upvote_count":"5","comment_id":"859754","timestamp":"1680514320.0"},{"timestamp":"1666276800.0","upvote_count":"2","comment_id":"700038","poster":"Mahmoud_E","content":"Selected Answer: ACE\nACE are the best asnwers"},{"timestamp":"1662908160.0","upvote_count":"2","comment_id":"666221","poster":"6721sora","content":"Selected Answer: ACF\nSingle VPN tunnel limits throughput. Copying 20TB across long distances is a big bottleneck. VPN across internet cannot be relied upon for high performance"},{"comment_id":"624449","content":"Selected Answer: ACF\nACF ...","upvote_count":"1","timestamp":"1656482460.0","poster":"RGTest"},{"timestamp":"1646417700.0","comments":[{"content":"https://cloud.google.com/network-connectivity/docs/vpn/quotas#limits\nBandwidth per VPN tunnel: Up to 3 Gbps for the sum of ingress and egress","upvote_count":"1","poster":"mad314","comment_id":"590604","timestamp":"1650716460.0"}],"poster":"Joanale","comment_id":"560935","upvote_count":"1","content":"Why \"A\" dudes? even if you put 20 tunnels connection the bandwidth of on premisses remains the same. I'm sure its B, D, F, who make's migrations know google storage isn't made for migrations, i think D means that make some compression process or transformation and F is right cause all connectivity goes trough internet. If for some reason the internet bw is shared this can be congestionated."},{"upvote_count":"4","content":"Selected Answer: ACF\nACF, though there are a lot of room to imagine in answer B to make it a risk. Not sure what the test designer is implying in this case.","comment_id":"526010","poster":"sjmsummer","timestamp":"1642445400.0"},{"comment_id":"520143","content":"Looking at the figure is confusing. \nThe necessary information cannot be read from this figure.\nTherefore, select the factors that deteriorate the throughput from the options.\nI think A,C and F are factors that deteriorate the throughput.\nAnyone pls tell me why choose E?","poster":"OrangeTiger","timestamp":"1641726240.0","upvote_count":"2"},{"timestamp":"1637979540.0","poster":"joe2211","comment_id":"487777","content":"Selected Answer: AC\nvote ACF","upvote_count":"5"},{"content":"Correct answer is ACE only","comment_id":"440559","upvote_count":"3","poster":"sudarchary","timestamp":"1630959900.0"},{"content":"There is just not enough data in this q to answer correctly. For instance it does not state they r using a copy command and we don’t know what the internet connection is. I think adf but this q needs more data points","comment_id":"428008","timestamp":"1629451320.0","upvote_count":"1","poster":"MikeB19"},{"timestamp":"1621520340.0","content":"A. A single VPN tunnel, which limits throughput\nC. A copy command that is not suited to operate over long distances\nE. A separate storage layer outside the VMs, which is not suited for this task","comments":[{"comment_id":"380246","content":"\"E. A separate storage layer outside the VMs, which is not suited for this task\". My question here is that there is no 'storage layer' in the diagram given in the question.","comments":[{"comment_id":"440927","poster":"Manh","content":"it's Cloud storage mouth to VM instance","upvote_count":"1","timestamp":"1631020080.0"}],"upvote_count":"3","timestamp":"1623477120.0","poster":"dlzhang"}],"upvote_count":"3","comment_id":"362262","poster":"victory108"},{"poster":"JohnWick2020","comments":[{"upvote_count":"2","content":"But for C it mentions specifically the long distance, and the copy command problem would happen independent of distance, right?","poster":"rbarrote","comment_id":"354883","timestamp":"1620751500.0"}],"timestamp":"1618391580.0","content":"Answer is A,C,F.\n\nBreakdown:\nA. A single VPN tunnel, which limits throughput.\nRecommended practice is to have two redundant connections, usually Dedicated Interconnect and VPN. VPNs suit low volume data connections so won't cut it for this company.\n\nC. A copy command that is not suited to operate over long distances.\nAdvisable to use GCP recommended tools that support multi-part, parallel composite and resumable uploads to Cloud Storage. \n\nF. Complicated internet connectivity between the on-premises infrastructure and GCP.\nWith some existing VMs being dual-homed, firewalls, VPC and routing configs, things could get pretty complicated.","upvote_count":"18","comment_id":"335345"},{"timestamp":"1617278820.0","comment_id":"325772","content":"answer are A, C, F","upvote_count":"10","poster":"Ausias18"},{"poster":"bnlcnd","content":"A - everyone agrees\nB - the VM should have persistent disk not cloud storage.\nF - no other choices left :)","comments":[{"comment_id":"598497","poster":"amxexam","upvote_count":"1","timestamp":"1651999440.0","content":"Not necessary a db vm"}],"upvote_count":"6","timestamp":"1612062360.0","comment_id":"280311"},{"poster":"ahmedemad3","timestamp":"1611811800.0","upvote_count":"7","comment_id":"278306","content":"ans: ACF \nHe talks about maximize throughput."},{"poster":"hgd6w4tGF","comment_id":"271806","upvote_count":"1","timestamp":"1611128400.0","content":"look this \"The migration of JencoMart's application to Google Cloud Platform (GCP)\". \nIt said \"application\", right?\nThat means they move a MySQL to a Cloud Storage ,right?\nSO ,B is right one.\nthey must change a lot of code for migration . huge bottleneck it is"},{"comment_id":"261258","content":"slow progress in migration -> data migration issue ? maybe\nA. affect slow data transfer because VPN's upper limit\nC. \nF.","poster":"finchfund","upvote_count":"7","timestamp":"1609963020.0"},{"comments":[{"poster":"JCGO","comment_id":"236319","content":"A and C is 100%. (supposedly there is a 'copy' command somewhere in exam picture. \nChoise is between B and E. Their VM's on prem got local disks and SAN LUn's mounted. Both are candidates for migration to persistent disk's: https://cloud.google.com/docs/compare/data-centers/storage ; 20TB user profile DB is migrated to Datastore (from previous question). Postgre surelly will be migrated to cloud as manages service for sure. May be buckets needed for their LAMP, who knows. Between B and E needs additional info. B looks better candidate for me.","timestamp":"1607248200.0","upvote_count":"1"}],"timestamp":"1606637640.0","upvote_count":"2","content":"I think it's A,B,C. Whhy B ? Because they have databases on-prem and needs to migrate fully or partially (who knows) them also. So it's not about bucket's only. (E - separate storage layer is good for their SAN migration).","poster":"JCGO","comment_id":"230201"},{"upvote_count":"1","poster":"xigzhou","comment_id":"224744","content":"ACE too","timestamp":"1606020060.0"},{"upvote_count":"11","timestamp":"1605623040.0","comments":[{"comment_id":"234676","upvote_count":"2","content":"Though it's not very clear but C should be a reasonable answer. If you use gsutil -m with multithreading, you can increase throughput. \nF should be incorrect: the network connectivity in the topology looks simple enough, there's not such complicated setup\nI would go to ABC","timestamp":"1607062020.0","poster":"kb13"},{"poster":"MF2C","content":"agreed","comment_id":"517991","timestamp":"1641449880.0","upvote_count":"1"},{"upvote_count":"1","timestamp":"1618930140.0","poster":"Kiroo","comment_id":"339651","content":"about the letter E, I agree about the separate storage layer should not impact and even is good for the migration, but I don´t think that it should be a Cloud Storage , maybe a persistent disk. Because of that I also consider the letter E correct."}],"poster":"mexblood1","content":"A Correct. Single vpn can easily become a bottle neck specially for 100TB.\nB. Correct. If you use a regional bucket in US, it will be slower than a dual or multiregional bucket in EU-Asia.\nC. Incorrect. There's no such copy command for long distances. There are commands for small bandwidths, intermittent connectivity, packet sizes, etc but nothing to apply more force so it can go longer... we're not throwing balls. :)\nD. Incorrect. Number of vms has nothing to do with transfer speed.\nE. Incorrect. This is the way to go for migrations, a separate storage layer outside the vms.\nF. Correct. The ISP can have poor performance.","comment_id":"221135"},{"content":"A: A VPN has a limit\nE: A separate storage layer \"WHICH IS NOT SUITED\" affects the throughput; for sure.\nF: Complicated internet connectivity between the on-premises and GCP maybe the ISP is working bad.\nI don't understand why C because that said \"Long distances\" that it's right? I have never heard about that\nCan someone explain it to me, please?","poster":"francisco_guerra","timestamp":"1604529540.0","comments":[{"poster":"sealvarezmx","comment_id":"259837","timestamp":"1609808700.0","upvote_count":"2","content":"Long distance introduce latency therefore it affects throughput.\nThis is important when you use TCP and you need to wait for acknowledgements to keep transferring.\ngsutil uses HTTPS so long distances will affect performance. A way around this, would be to copy to a closer location, and then replicate, or have GCP to do it for you.\nI'll go with A, C, F"}],"comment_id":"213059","upvote_count":"2"},{"comment_id":"191257","upvote_count":"1","content":"There's absolutely nothing complicated in anyway about that networking. If it's F, the question is broken. It's ACE.","timestamp":"1601596740.0","poster":"kimberjdaw"},{"content":"poor wording for option F but this means complexity associated with VPN (primarily encryption/decryption of network traffic), results in relatively low throughput (compared to Dedicated Interconnect) and this VPN low throughput is bottleneck for transferring large amount of data between on-prem and GCP. \nSo correct answer is ACF","timestamp":"1599611100.0","upvote_count":"5","comment_id":"176164","poster":"[Removed]"},{"content":"ACE\nOn Google Cloud, you can use persistent disks to support workloads that expect SANs.","poster":"pranaylohani","upvote_count":"4","timestamp":"1598021100.0","comment_id":"163022"},{"poster":"Pupina","comment_id":"155801","upvote_count":"4","timestamp":"1597175340.0","content":"I go with ACF"},{"timestamp":"1594115820.0","upvote_count":"4","comment_id":"128798","comments":[{"upvote_count":"1","content":"Actually not all the classes have the same performance. Please check \"Additional classes\" > \"Durable Reduced Availability (DRA) Storage\". It says \"DRA has lower performance, particularly in terms of availability (DRA has a 99% availability SLA).\" \nhttps://cloud.google.com/storage/docs/storage-classes#legacy\n\nTherefore I go with ABC.","timestamp":"1603090260.0","comment_id":"202412","poster":"Anjoy"}],"content":"I don't think this has anything to do with storage because all storage classes share the same common performance attributes as outlined here\nhttps://cloud.google.com/storage/docs/storage-classes#descriptions\nAlso persistent disks is a GCE offering not a Cloud Storage class.\nso I rule out B and E\n\nD: less VMs on GCP - VM migrate is at disk level not at VM-level\n\nA, F: they both affect VPN's throughput\nC: by saying \"long distances\", they meant lots of network hops in between and should any of them fail during transfer, it may cause intermittent transfer disruptions so your copy agent should support resuming, etc.","poster":"cetanx"},{"comment_id":"90053","poster":"Jack_in_Large","content":"E should be rule out: Cloud storage is needed to replace shared 100 TB SAN in each location\nC is weird\nMy choice is ADF","upvote_count":"6","timestamp":"1589649420.0"},{"poster":"sivass","timestamp":"1589038860.0","content":"I think ACE is correct","comment_id":"86108","upvote_count":"4"},{"timestamp":"1588715460.0","poster":"Zarmi","comment_id":"84295","upvote_count":"5","comments":[{"timestamp":"1612062000.0","poster":"bnlcnd","content":"persistent disk maybe?","comment_id":"280308","upvote_count":"1"}],"content":"A separate storage layer outside the VMs, which is not suited for this task - Why Cloud Storage is not suited? What is better?"},{"poster":"JJu","comments":[{"content":"A is correct - \"Add a second Cloud VPN gateway in the same region as the existing VPN gateway. The second Cloud VPN gateway can have a tunnel that points to the same IP address of the on-premises VPN gateway as the tunnel on the first gateway. Once configured, traffic to the on-premises VPN gateway is automatically load balanced between the two Cloud VPN gateways and tunnels\"\nhttps://cloud.google.com/vpn/docs/concepts/classic-topologies","timestamp":"1577944140.0","poster":"MyPractice","upvote_count":"1","comment_id":"34445"}],"timestamp":"1574859180.0","content":"why is answer a? \nI don't know this answer. please explain me this Question.\n\nVPN tunnel\nA VPN tunnel connects two VPN gateways and serves as a virtual medium through which encrypted traffic is passed. Two VPN tunnels must be established to create a connection between two VPN gateways: Each tunnel defines the connection from the perspective of its gateway, and traffic can only pass once the pair of tunnels is established. A Cloud VPN tunnel is always associated with a specific Cloud VPN gateway resource.\nhttps://cloud.google.com/vpn/docs/concepts/overview","comment_id":"24815","upvote_count":"1"},{"content":"I think it is A,C,E... the requirements states \"20TB backed up every 12 hours\"... using Dedicated Interconnect instead of a copy utility would be better.","poster":"Eroc","timestamp":"1572281400.0","comment_id":"17976","upvote_count":"3"},{"comment_id":"15881","upvote_count":"1","poster":"MeasService","content":"agree but not entirely sure !","timestamp":"1571395620.0"},{"comment_id":"15749","timestamp":"1571305500.0","upvote_count":"10","poster":"chiar","content":"Why not A,C and F?","comments":[{"timestamp":"1593081720.0","poster":"kaush","upvote_count":"5","content":"ACF correct answer yeas","comment_id":"119355"},{"timestamp":"1614912180.0","poster":"nitinz","content":"ACE is correct","comment_id":"303861","upvote_count":"2"}]}],"answer":"ACF","answers_community":["ACF (63%)","AC (26%)","11%"],"exam_id":4},{"id":"zQtqqa2dZVCjFJH7VK84","exam_id":4,"discussion":[{"poster":"JJu","timestamp":"1590393840.0","comment_id":"24244","content":"answer is D. Google Cloud Datastorage\nGoogle Cloud Datastorage use:\n * User profile\n * game state\n * product catalogs","upvote_count":"27","comments":[{"upvote_count":"8","comment_id":"666814","content":"They have a relational oracle DB with complex table structure. I dont think Data storw will work for them.\nAnswer should be A ( Cloud Spanner)","poster":"Ishu_awsguy","comments":[{"poster":"Ishu_awsguy","timestamp":"1678623240.0","comment_id":"666819","upvote_count":"5","content":"But yeah\nit is debatable on how much moderization we take.\nWith Cloudspanner ( require less modernisation compared to Datastore)\nWith Cloud SQL ( Require less modernisation compared to Datastore)\nWith datastore - Best solution eventually - but the most tricky migration and modernisation.\nvery subjective question"}],"timestamp":"1678622820.0"},{"comment_id":"338452","timestamp":"1634592900.0","poster":"vvillar","upvote_count":"1","content":"datastore*"}]},{"comment_id":"22550","timestamp":"1589828640.0","upvote_count":"18","content":"oracle= Relational\n+Gloabal = spanner =>A)","poster":"dabrat","comments":[{"upvote_count":"1","poster":"VishalB","content":"User Profile not necessary would have relational database, Datastore is the best option for User Profile","timestamp":"1642101120.0","comment_id":"405587"},{"content":"D, profiles go to datastore","upvote_count":"1","comment_id":"303864","poster":"nitinz","timestamp":"1630802640.0"},{"timestamp":"1591376100.0","content":"Technical Requirements\n• Assess key application for cloud suitability.\n• Modify application for the cloud. **(Which means possible to change the code or database when it migrate to GCP\n)","comment_id":"26950","comments":[{"content":"D is ok\nhttps://cloud.google.com/datastore/docs/concepts/overview\nDatastore is ideal for applications that rely on highly available structured data at scale. You can use Datastore to store and query all of the following types of data:\n\nProduct catalogs that provide real-time inventory and product details for a retailer.\nUser profiles that deliver a customized experience based on the user’s past activities and preferences.\nTransactions based on ACID properties, for example, transferring funds from one bank account to another.","poster":"tartar","comment_id":"152454","timestamp":"1612696800.0","upvote_count":"11"}],"upvote_count":"5","poster":"DrLu"}]},{"poster":"masterchief735","content":"Selected Answer: A\nThe requirement is Global and also they nedd relational database which cloud datstore doesn't allow and bigquery is datawarehouse and for analysis and cloud sql support upto 30 TB relational database.So A should be correct.","upvote_count":"2","comment_id":"1342807","timestamp":"1737245340.0"},{"timestamp":"1719627780.0","upvote_count":"1","poster":"decw","content":"I think A\nhttps://cloud.google.com/solutions/migrate-oracle-workloads","comment_id":"1108342"},{"comment_id":"1093962","content":"Selected Answer: D\nIt was already mentioned in another question they are moving to data store :)","poster":"MahAli","timestamp":"1718145780.0","upvote_count":"4"},{"upvote_count":"1","poster":"Jannchie","timestamp":"1717767840.0","content":"Selected Answer: C\nC, because this company used PostgreSQL before. No reason to use NoSQL(D), Not for analytic(B), not PB level data so no need to use Spanner(A).","comment_id":"1090418"},{"comment_id":"1082182","timestamp":"1716867120.0","content":"This case study is not listed in GCP PCA exam as on date.","upvote_count":"2","poster":"thewalker"},{"timestamp":"1714408080.0","comment_id":"1057071","content":"Selected Answer: C\nSince it is relational data, it should be A or C.\n\nCloud SQL is the only that supports the Oracle SQL features, like Procedures and triggers, etc. I also think Cloud Spanner seems to be an overkill since it is a 20TB database, which Cloud SQL easily handles\nIMO, C is the cheapest and easiest, while A would require some refactorings and longer migration, which doesnt pay off for the current database's size","upvote_count":"1","poster":"cchiaramelli"},{"timestamp":"1703876340.0","upvote_count":"2","comment_id":"938386","poster":"dman69","content":"Selected Answer: D\nData store is used for user profiles"},{"upvote_count":"2","comment_id":"925901","timestamp":"1702815180.0","poster":"BiddlyBdoyng","content":"A: Spanner retains the RDBMS compatibility and helps to reduce latency for any Asia resources\n\nB: BigQuery no good for OLTP\n\nC: CloudSQL, the closest option we have to Oracle\n\nD: Significant architectural change but potentially a great alternative to RDBMS, document database typically a good fit for user data & as others have said it can eliminate the complex RDBMS structure and queries\n\n\nThe problem I have with Spanner is the cost, it is extremely expensive compared to the other options, so is it really needed? \n\nBut when I review the requierments I don't see cost as being up there whilst latency to Asia it is, so whilst I intuitively picked Datastore I'll revise to Spanner."},{"content":"I don't get why B isn't correct. Cloud Storage isn't a good replacement for SAN, especially when we have a database running on some of the VMs.","comment_id":"925891","poster":"BiddlyBdoyng","upvote_count":"1","timestamp":"1702813560.0"},{"upvote_count":"2","content":"Selected Answer: D\nDatastore is best for user profiles","poster":"TheCloudGuruu","comment_id":"899999","timestamp":"1700224380.0"},{"upvote_count":"2","content":"Selected Answer: D\nsays here https://cloud.google.com/datastore/docs/concepts/overview","timestamp":"1697470680.0","comment_id":"871885","poster":"geekgirl007"},{"timestamp":"1696325640.0","upvote_count":"2","comment_id":"859757","content":"Selected Answer: A\nCloud Spanner is a fully managed, scalable, and globally distributed relational database service. It provides strong consistency, high availability, and low-latency capabilities, which would be suitable for JencoMart's User Profiles database requirements.","poster":"taer"},{"poster":"HD2023","content":"Selected Answer: D\nOption D","upvote_count":"2","comment_id":"857149","timestamp":"1696082460.0"},{"content":"Selected Answer: A\nOracle (relational) + global => Spanner","timestamp":"1694738640.0","comment_id":"839509","upvote_count":"2","poster":"Deb2293"},{"poster":"BeCalm","content":"Selected Answer: A\nThis is pretty straightforward.\nRelational + Global = Spanner.\n\nDS not meant for TB size.","upvote_count":"2","timestamp":"1693919880.0","comment_id":"830022"},{"upvote_count":"2","comment_id":"803885","content":"Selected Answer: A\nSpanner. - Global","timestamp":"1691624700.0","poster":"zerg0"},{"content":"Selected Answer: A\nReference: https://cloud.google.com/solutions/migrate-oracle-workloads\nRewrite Strategy will apply as They have a relational oracle DB with complex table structure and business expanding globally.\n\nRewrite your application to take full advantage of cloud-native databases. If your application requires a relational database with global scalability, you can migrate to Cloud Spanner, which provides scalability with an industry-leading high availability of 99.999% SLA.","timestamp":"1690329900.0","comment_id":"788295","upvote_count":"1","poster":"GopeshSahu"},{"upvote_count":"3","timestamp":"1653611040.0","content":"Selected Answer: D\nvote D","comment_id":"487784","poster":"joe2211"},{"poster":"kopper2019","comment_id":"406670","timestamp":"1642220100.0","upvote_count":"1","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152"},{"poster":"MamthaSJ","upvote_count":"1","content":"Answer is D","timestamp":"1641566820.0","comment_id":"400875"},{"upvote_count":"1","poster":"victory108","comment_id":"362719","content":"A. Cloud Spanner","comments":[{"content":"D is correct --> Google Cloud Datastore","upvote_count":"1","poster":"victory108","comment_id":"514372","timestamp":"1656644640.0"}],"timestamp":"1637483220.0"},{"poster":"jasim21","comment_id":"340410","timestamp":"1634830440.0","upvote_count":"3","content":"The only lift & shift option for Oracle DB is bare metal. To host on cloud spanner you need to rewrite the code. Since application modification is allowed as per technical requirement why not rewrite to most suitable product of GCP for user profile i.e. Datastore.\n\nThe answer is D\nReference: https://cloud.google.com/solutions/migrate-oracle-workloads"},{"content":"My pick is A - Cloud Spanner\n\nReasons - the company are currently hosting apps on infra that is EOL or no longer supported. So immediate priority is to \"move\" database in first instance as painless as possible.\n\nThe database in question is relational with a \"complex setup\" so my preference would be to \"lift-and-shift\" to Cloud Spanner (Relational) and much later to Datastore (NoSQL). \n\nCloud Spanner is minimal effort vs DataStore which requires significant effort involving rearchitecting, data migration and optimization - among other things.","upvote_count":"4","timestamp":"1634207160.0","comment_id":"335381","poster":"JohnWick2020"},{"upvote_count":"2","content":"Answer is A","poster":"Ausias18","timestamp":"1633090140.0","comment_id":"325776"},{"content":"IMO - D is ok for may reasons but also because of Question #: 3 from Topic #: 2 :)","comments":[{"upvote_count":"2","timestamp":"1632896820.0","comment_id":"323159","poster":"lynx256","content":"IMO - D is ok - for maNy reasons but also because of Question #: 3 from Topic #: 2 :)"}],"poster":"lynx256","comment_id":"323157","timestamp":"1632896640.0","upvote_count":"1"},{"comment_id":"294146","upvote_count":"2","poster":"Kysmor","content":"Answer is D, Datastore (as also mentioned in a previous question) and as Google documentations:\n\"What it's good for... * User profiles that...\"\nhttps://cloud.google.com/datastore/docs/concepts/overview#what_its_good_for","comments":[{"comment_id":"303282","upvote_count":"4","poster":"AGG","content":"Look at this link : https://cloud.google.com/solutions/migrate-oracle-workloads\nDatastore is not taken under consideration, only Cloud Spanner & Cloud SQL \nExpand services into Asia, Global company, outsource infra - all those words are related with Spanner - I would go with A","timestamp":"1630744800.0"}],"timestamp":"1629364320.0"},{"poster":"AGG","timestamp":"1629093360.0","upvote_count":"2","content":"A is the right answer \nhttps://cloud.google.com/solutions/database-migration","comment_id":"291572"},{"comment_id":"290799","upvote_count":"2","content":"DataStore is the answer it can also eliminate their current complex table structure on premise ORACLE DB. I will choose D","poster":"guid1984","timestamp":"1629007440.0"},{"comments":[{"comment_id":"309875","timestamp":"1631546040.0","content":"They do say:\n\"Technical Requirements -\nAssess key application for cloud suitability\nModify applications for the cloud\nMove applications to a new infrastructure\"","poster":"pawel_ski","upvote_count":"1"}],"comment_id":"280696","timestamp":"1627743660.0","upvote_count":"1","content":"\"move their User Profiles database to Google Cloud Platform\" - this is not saying that they want to rebuild their user profile system from scratch. Just to move the database. So, it must be a SQL DB like Oracle. Spanner is global and Cloud SQL is regional.\nA is correct.\n\nBTW, if we want to build user profile applications in GCP, D should be the option.","poster":"bnlcnd"},{"content":"D: datastore is good use case for user profile -> \"User profiles that deliver a customized experience based on the user’s past activities and preferences.\" at https://cloud.google.com/datastore/docs/concepts/overview","timestamp":"1625594400.0","poster":"finchfund","upvote_count":"1","comment_id":"261260"},{"upvote_count":"3","timestamp":"1622965920.0","poster":"JCGO","comment_id":"236323","content":"Question in previous page tlls that they have migrated user profiles Oracle DB to Datastore. s0 D is correct :)"},{"comment_id":"205570","poster":"N1_arch","timestamp":"1619341980.0","upvote_count":"4","content":"Should be A for migrating from Oracle and complex table structure and global DB >> Spanner"},{"comment_id":"186905","content":"I believe Jencomart is not in scope for exam","upvote_count":"7","comments":[{"upvote_count":"2","content":"Yes, I think too.","poster":"cmfchong","timestamp":"1634352300.0","comment_id":"336715"}],"poster":"asheesh0574","timestamp":"1616675580.0"},{"poster":"ESP_SAP","content":"Correct Answer is (D):\n\nWhat it's good for\nDatastore is ideal for applications that rely on highly available structured data at scale. You can use Datastore to store and query all of the following types of data:\n\nProduct catalogs that provide real-time inventory and product details for a retailer.\nUser profiles that deliver a customized experience based on the user’s past activities and preferences.\nTransactions based on ACID properties, for example, transferring funds from one bank account to another.\n\nhttps://cloud.google.com/datastore/docs/concepts/overview#what_its_good_for","upvote_count":"3","timestamp":"1615430520.0","comment_id":"177386"},{"upvote_count":"5","timestamp":"1610810700.0","content":"Alternative-1: Postgre\nGCP has quite some references to migration from Oracle to Postgre but it has 1000 concurrent connection limit which seems like not good enough for a company with 10K stores. It's also a regional service.\n\nAlternative-2: Datastore\nDatastore is a good option for storing user profile data but I am not sure if it's also good for migrating from an OLTP database with complex table structure. I couldn't find any reference to it but it any how seems like a complex migration.\n\nAlternative-3: Cloud Spanner\nGCP has KBs for migrating from Oracle to Cloud Spanner (https://cloud.google.com/solutions/migrating-oracle-to-cloud-spanner) so this makes Cloud Spanner a better option. Also Cloud Spanner is a global service which makes it more suitable for a company across 3-continents.\n\nI would go with \"A\".","comment_id":"136488","poster":"cetanx"},{"comments":[{"comment_id":"160963","upvote_count":"2","poster":"fhqwhgads","content":"user credentials are on postgresql, user profiles are on Oracle","timestamp":"1613667180.0"}],"timestamp":"1610679540.0","content":"User profile database is currently on postgre\nD is correct.","poster":"Awsml","upvote_count":"1","comment_id":"135342"},{"content":"A .. Oracle DB is relational works on SQL .. Datastore does not support SQL it supports GQL soo migrating queries will take a long time. Also 20TB is too much for cloud SQl soo answer is spanner","upvote_count":"1","poster":"CoolCat","comments":[{"poster":"Ahmed_Salam","timestamp":"1619619240.0","content":"Spanner is for PB not TB","comment_id":"207921","upvote_count":"1"}],"comment_id":"104721","timestamp":"1607368980.0"},{"content":"user profiles are semi - structured .. defintely cannot be fit into relational data .\nso option should be cloud data store which is no sql document store .\nthe flowchart to choose correct data solution is as below link\nhttps://grumpygrace.dev/posts/gcp-flowcharts/#storage-and-data","timestamp":"1606719180.0","poster":"jayaen","comment_id":"98618","upvote_count":"2"},{"timestamp":"1605633720.0","poster":"Navi08","content":"I would go with A as User Profiles Database is 20TB","comment_id":"90663","upvote_count":"5"},{"timestamp":"1605190740.0","poster":"ankit89","content":"A Option Seems more close.","comment_id":"87602","upvote_count":"3"},{"timestamp":"1598389500.0","content":"Although dealing with complex table structure, if migration is not a simple lift and shift I choose Cloud Datastore/Firestore. Also, the question is old.","upvote_count":"1","comment_id":"55218","poster":"Smart"},{"content":"Should be A, because the existing Env is using Oracle for User Profiles database…","timestamp":"1595823960.0","comment_id":"43156","upvote_count":"3","poster":"YashBindlish"},{"comment_id":"30714","content":"I'd say A. It says their existing oracle database has a \"Complex table structure\". That would be easier and just as performant if migrated to cloud spanner versus trying to rewrite it for nosql.","upvote_count":"5","comments":[{"comment_id":"191260","upvote_count":"1","poster":"kimberjdaw","timestamp":"1617321960.0","content":"That wouldn't be Spanner in that case. \"NoSQL\" just means the data is denormalized in some way with the potential for a hierarchy. Spanner would still require rework. It's not for lift-and-shift. If you can port it to Spanner, you can port it to Datastore."}],"timestamp":"1592495640.0","poster":"elguando"}],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/8497-exam-professional-cloud-architect-topic-2-question-6/","question_id":229,"isMC":true,"question_text":"JencoMart wants to move their User Profiles database to Google Cloud Platform.\nWhich Google Database should they use?","answer_ET":"D","topic":"2","answers_community":["D (57%)","A (37%)","7%"],"timestamp":"2019-11-18 22:04:00","answer":"D","question_images":[],"answer_images":[],"unix_timestamp":1574111040,"choices":{"D":"Google Cloud Datastore","A":"Cloud Spanner","B":"Google BigQuery","C":"Google Cloud SQL"}},{"id":"Es7HIGeEIZ0AeMyLJmsH","isMC":true,"answer":"B","exam_id":4,"question_text":"For this question, refer to the Helicopter Racing League (HRL) case study. Your team is in charge of creating a payment card data vault for card numbers used to bill tens of thousands of viewers, merchandise consumers, and season ticket holders. You need to implement a custom card tokenization service that meets the following requirements:\n* It must provide low latency at minimal cost.\n* It must be able to identify duplicate credit cards and must not store plaintext card numbers.\n* It should support annual key rotation.\nWhich storage approach should you adopt for your tokenization service?","topic":"3","answer_description":"","answers_community":["B (97%)","3%"],"discussion":[{"content":"Answer would be B\n\nhttps://cloud.google.com/community/tutorials/pci-tokenizer\n\nDeterministic output means that a given set of inputs (card number, expiration, and userID) will always generate the same token. This is useful if you want to rely on the token value to deduplicate your token stores. You can simply match a newly generated token to your existing catalog of tokens to determine whether the card has been previously stored. Depending on your application architecture, this can be a very useful feature. However, this could also be accomplished using a salted hash of the input values.\n\n\n\nhttps://cloud.google.com/architecture/tokenizing-sensitive-cardholder-data-for-pci-dss\nFirestore is the next major version of Datastore. Firestore can run in Datastore mode, which uses the same API as Datastore and scales to millions of writes per second,","comment_id":"478824","timestamp":"1652625000.0","upvote_count":"39","poster":"Neo_ACE"},{"content":"Got this question in my exam, answered B","timestamp":"1658241240.0","comment_id":"527735","upvote_count":"19","poster":"technodev"},{"timestamp":"1721287980.0","poster":"OrangeTiger","comment_id":"1125658","upvote_count":"2","content":"A's SecretManager and C's Memorystore are absolutely different because their purposes are different. D is different because it does not mention duplication. What remains is B."},{"poster":"TopTalk","timestamp":"1711309440.0","comment_id":"1016069","upvote_count":"2","content":"Why isn't it C since Firestore doesn't meet the low latency requirement as someone said before? Bard thinks the answer is C for low latency and even cost because you're only paying for what you use. Thoughts?"},{"content":"Selected Answer: B\nBetween B (firestore in datastore mode)and D (Cloud SQL) B is better solution since firestore is preferred for low latency queries, also since firestore is in datastore mode (does not include real time capabilities supported in native mode - i.e mobile updates) it's cost effective.","poster":"sampon279","comment_id":"937282","timestamp":"1703817060.0","upvote_count":"4"},{"timestamp":"1702891560.0","content":"Why not C ?","comments":[{"poster":"bargou","content":"if we choose C, the card number can be duplicated, since we are using multiple memorystore","comment_id":"1150163","timestamp":"1723628820.0","upvote_count":"2"}],"upvote_count":"2","poster":"mimicha1","comment_id":"926505"},{"upvote_count":"2","comments":[{"content":"I agree, both answers would fit the bill but I think B just shades it due to low latency requirements.","poster":"mtj2018","upvote_count":"1","comment_id":"954517","timestamp":"1705522860.0"}],"comment_id":"925919","timestamp":"1702817760.0","poster":"BiddlyBdoyng","content":"From what I can work out column level encryption needs to be implemented by the client in Cloud SQL.\n\nSo both B & D are identical solutions except for the database type?\n\nCloud SQL seems to do a better job of the avoiding duplicates requirement & seems a better fit. \n\nDon't see why B seems to be so popular, would have expect a bigger split on the vote. Am I missing something"},{"content":"Selected Answer: B\nB fits the case","poster":"tdotcat","upvote_count":"2","timestamp":"1689441120.0","comment_id":"776973"},{"timestamp":"1686917460.0","comment_id":"747272","poster":"surajkrishnamurthy","content":"Selected Answer: B\nB Is the Correct Answer","upvote_count":"2"},{"poster":"megumin","comment_id":"716613","timestamp":"1683877140.0","content":"Selected Answer: B\nB is ok","upvote_count":"1"},{"poster":"Mahmoud_E","content":"Selected Answer: B\nB as its clear in the example by google https://cloud.google.com/architecture/tokenizing-sensitive-cardholder-data-for-pci-dss","comment_id":"700078","upvote_count":"4","timestamp":"1682004780.0"},{"timestamp":"1677844080.0","comment_id":"658299","poster":"aut0pil0t","upvote_count":"4","content":"Selected Answer: B\nB, but should be reworded as follows for clarify.\n\n\"B. Encrypt the card data with a deterministic algorithm and store in Firestore using Datastore mode.\"\n\nhttps://cloud.google.com/architecture/tokenizing-sensitive-cardholder-data-for-pci-dss#a_service_for_handling_sensitive_information"},{"content":"I would go with B.","poster":"AzureDP900","comment_id":"627216","upvote_count":"1","timestamp":"1672894620.0"},{"poster":"cpi_web","upvote_count":"2","comment_id":"608715","content":"Hmmm. What is about the very first point low latency? Firefstore is not the one with best latency values...\n\nhttps://cloud.google.com/architecture/building-scalable-apps-with-cloud-firestore#latency","timestamp":"1669722660.0"},{"upvote_count":"1","comment_id":"598013","poster":"kapara","content":"Selected Answer: D\nans is D","timestamp":"1667813100.0"},{"comment_id":"591547","content":"Selected Answer: B\nHad this question on my exam.","timestamp":"1666692960.0","poster":"mad314","upvote_count":"5"},{"comment_id":"581138","upvote_count":"2","poster":"slars2k","timestamp":"1664961000.0","content":"Considering low latency and minimal cost, will go with D."},{"comments":[{"upvote_count":"2","comment_id":"598114","content":"Agreed. Reading the key rotation section of https://cloud.google.com/bigquery/docs/column-key-encrypt it states, \"It is not possible to rotate a wrapped keyset using the KEYS.ROTATE_KEYSET function.\"","poster":"jay9114","timestamp":"1667832000.0"}],"timestamp":"1664209080.0","upvote_count":"3","content":"Key rotation is a problem with column level encryption.. hence D is rejected","comment_id":"575707","poster":"SAMBIT"},{"timestamp":"1656644580.0","content":"B. Encrypt the card data with a deterministic algorithm stored in Firestore using Datastore mode.","upvote_count":"3","poster":"victory108","comment_id":"514371"},{"upvote_count":"2","content":"Selected Answer: B\nAnswer would be B\n\nhttps://cloud.google.com/community/tutorials/pci-tokenizer","poster":"Pime13","comment_id":"511233","timestamp":"1656421740.0"},{"content":"Selected Answer: B\nB is correct","poster":"andeu","upvote_count":"3","comment_id":"499778","timestamp":"1655001060.0"},{"timestamp":"1654455420.0","poster":"[Removed]","content":"Selected Answer: B\nB is correct.\nMarked D is wrong","comment_id":"494664","upvote_count":"2"},{"poster":"joe2211","upvote_count":"3","timestamp":"1653611460.0","content":"Selected Answer: B\nvote B","comment_id":"487785"},{"comment_id":"483013","timestamp":"1653102240.0","upvote_count":"3","poster":"Scottgong","content":"Selected Answer: B\nAnswer would be B"},{"comments":[{"poster":"Neo_ACE","content":"Could you please share any Link for this","upvote_count":"2","timestamp":"1652622060.0","comment_id":"478780"}],"timestamp":"1652440140.0","comment_id":"477457","upvote_count":"3","content":"Answer is B, Tokenizing sensitive card holder data needs IAM, cloud KMS , Firestore in datastore mode.","poster":"t1nna456"}],"unix_timestamp":1636808940,"question_id":230,"choices":{"D":"Use column-level encryption to store the data in Cloud SQL.","B":"Encrypt the card data with a deterministic algorithm stored in Firestore using Datastore mode.","A":"Store the card data in Secret Manager after running a query to identify duplicates.","C":"Encrypt the card data with a deterministic algorithm and shard it across multiple Memorystore instances."},"answer_ET":"B","timestamp":"2021-11-13 14:09:00","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/65937-exam-professional-cloud-architect-topic-3-question-1/"}],"exam":{"provider":"Google","isMCOnly":false,"lastUpdated":"11 Apr 2025","isImplemented":true,"name":"Professional Cloud Architect","isBeta":false,"id":4,"numberOfQuestions":279},"currentPage":46},"__N_SSP":true}