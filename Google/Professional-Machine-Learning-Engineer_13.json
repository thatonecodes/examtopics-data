{"pageProps":{"questions":[{"id":"yL1WSoEHg7tR8G0wvMuf","answers_community":["C (100%)"],"question_text":"You work for a bank and are building a random forest model for fraud detection. You have a dataset that includes transactions, of which 1% are identified as fraudulent. Which data transformation strategy would likely improve the performance of your classifier?","topic":"1","answer_ET":"C","timestamp":"2023-02-09 12:48:00","question_id":61,"discussion":[{"content":"Selected Answer: C\nThe answer is C beacause it's the only way to improve model performance.\nBox-Cox transformation: transform feature values according to normal distribution\nZ-normalization: transform feature values according to x_new = (x – μ) / σ (so {x_new} have mean 0 and std dev 1)\nLog transform: just log transformation \nAlso, the Random Forest algorithm is not a distance-based model but it is a tree-based model, there's no need of normalization process.","upvote_count":"5","timestamp":"1692186420.0","comment_id":"810710","poster":"Scipione_"},{"poster":"fitri001","comment_id":"1199920","content":"Selected Answer: C\nOversampling is a common technique to address class imbalance and can significantly improve the performance of the random forest model in fraud detection. It's important to note that oversampling can lead to overfitting, so monitoring the model's performance on unseen data (validation set) is crucial. You might also consider exploring other techniques like undersampling the majority class or using SMOTE (Synthetic Minority Oversampling Technique) for a more balanced approach.","upvote_count":"3","timestamp":"1729562580.0","comments":[{"poster":"fitri001","content":"Class Imbalance: The dataset has a significant class imbalance, with only 1% of transactions being fraudulent (minority class). Random forest models can be biased towards the majority class during training.\n\nOversampling: Oversampling replicates instances from the minority class (fraudulent transactions) in this case. By increasing the representation of the fraudulent class (10 times in this scenario), the model is exposed to more examples of fraud, improving its ability to learn and detect fraudulent patterns.","comment_id":"1199921","upvote_count":"1","timestamp":"1729562580.0"}]},{"upvote_count":"1","comment_id":"1190900","poster":"pinimichele01","content":"Selected Answer: C\nSee #60!","timestamp":"1728297360.0"},{"upvote_count":"2","poster":"M25","comment_id":"894159","timestamp":"1699639380.0","content":"Selected Answer: C\nSee #60!\nThe End. Good luck everyone!!!"},{"upvote_count":"1","content":"Selected Answer: C\nhttps://towardsdatascience.com/how-to-build-a-machine-learning-model-to-identify-credit-card-fraud-in-5-stepsa-hands-on-modeling-5140b3bd19f1","comment_id":"803154","timestamp":"1691574480.0","poster":"TNT87"}],"isMC":true,"unix_timestamp":1675943280,"answer_images":[],"exam_id":13,"question_images":[],"choices":{"D":"Log transform all numeric features.","B":"Z-normalize all the numeric features.","A":"Modify the target variable using the Box-Cox transformation.","C":"Oversample the fraudulent transaction 10 times."},"answer":"C","url":"https://www.examtopics.com/discussions/google/view/98540-exam-professional-machine-learning-engineer-topic-1-question/","answer_description":""},{"id":"u8DgendDPsnkXYXOsRwF","choices":{"C":"Accuracy","D":"Precision","A":"F1 score","B":"Recall"},"question_id":62,"question_text":"You are developing a classification model to support predictions for your company’s various products. The dataset you were given for model development has class imbalance You need to minimize false positives and false negatives What evaluation metric should you use to properly train the model?","timestamp":"2023-05-12 19:48:00","answer":"A","answer_images":[],"discussion":[{"comment_id":"896112","upvote_count":"7","poster":"Antmal","timestamp":"1683913680.0","content":"Selected Answer: A\nif there wasn't a class imbalance that C. Accuracy would have been the right answer. There A. F1-score which is harmonic mean of precision and recall, that balances the trade-off between precision and recall. It is useful when both false positives and false negatives are important as per the question at hand, and you want to optimize for both."},{"timestamp":"1718983440.0","upvote_count":"1","content":"In this case, you want to minimize both false positives and false negatives. The F1 score takes into account both the number of true positives and true negatives, making it a suitable choice for evaluating your model.","poster":"AzureDP900","comment_id":"1234549"},{"comment_id":"1199922","content":"Selected Answer: A\nClass Imbalance: When dealing with imbalanced data, metrics like accuracy can be misleading. A model that simply predicts the majority class all the time can achieve high accuracy, but it wouldn't be very useful for identifying the minority class (which is likely more important in this scenario).\n\nF1 Score: The F1 score is the harmonic mean of precision and recall. Precision measures the proportion of positive predictions that are actually correct, while recall measures the proportion of actual positive cases that are correctly identified. By considering both metrics, F1 score provides a balanced view of the model's performance in identifying both positive and negative cases.\n\nMinimizing False Positives and False Negatives: Since a high F1 score indicates a good balance between precision and recall, it translates to minimizing both false positives (incorrect positive predictions) and false negatives (missed positive cases).","poster":"fitri001","upvote_count":"3","timestamp":"1713751560.0"},{"upvote_count":"1","poster":"PST21","content":"Recall (True Positive Rate): It measures the ability of the model to correctly identify all positive instances out of the total actual positive instances. High recall means fewer false negatives, which is desired when minimizing the risk of missing important positive cases.\n\nF1 Score: It is the harmonic mean of precision and recall. F1 score gives equal weight to both precision and recall and is suitable when you want a balanced metric. However, it might not be the best choice when the primary focus is on minimizing false positives and false negatives.","comment_id":"957665","timestamp":"1689861540.0"},{"comment_id":"957662","timestamp":"1689861420.0","poster":"PST21","content":"both recall and F1 score are valuable metrics, but based on the question's specific requirement to minimize false positives and false negatives, recall (Option B) is the best answer. It directly focuses on reducing false negatives, which is crucial when dealing with class imbalance and minimizing the risk of missing important positive cases.","upvote_count":"1"},{"timestamp":"1688799600.0","content":"Selected Answer: A\nF1 should be correct","poster":"SamuelTsch","upvote_count":"1","comment_id":"946257"},{"timestamp":"1684920720.0","comment_id":"905715","upvote_count":"1","content":"class imbalance = F1 score","poster":"nescafe7"}],"exam_id":13,"answers_community":["A (100%)"],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/109098-exam-professional-machine-learning-engineer-topic-1-question/","question_images":[],"answer_description":"","answer_ET":"A","topic":"1","unix_timestamp":1683913680},{"id":"C0BL57aaeCE9MTsqVTK9","answers_community":["D (82%)","Other"],"answer_images":[],"answer_ET":"D","exam_id":13,"question_text":"You are training an object detection machine learning model on a dataset that consists of three million X-ray images, each roughly 2 GB in size. You are using Vertex AI Training to run a custom training application on a Compute Engine instance with 32-cores, 128 GB of RAM, and 1 NVIDIA P100 GPU. You notice that model training is taking a very long time. You want to decrease training time without sacrificing model performance. What should you do?","unix_timestamp":1689245100,"url":"https://www.examtopics.com/discussions/google/view/115038-exam-professional-machine-learning-engineer-topic-1-question/","isMC":true,"timestamp":"2023-07-13 12:45:00","answer_description":"","question_images":[],"question_id":63,"topic":"1","answer":"D","discussion":[{"timestamp":"1713751680.0","comment_id":"1199923","content":"Selected Answer: D\nLarge Dataset: With millions of images, training on a single machine can be very slow. Distributed training allows you to split the training data and workload across multiple machines, significantly speeding up the process.\n\nVertex AI Training and tf.distribute: Vertex AI Training supports TensorFlow, and the tf.distribute library provides tools for implementing distributed training strategies. By leveraging this functionality, you can efficiently distribute the training tasks across the available cores and GPU on your Compute Engine instance (32 cores and 1 NVIDIA P100 GPU).","upvote_count":"5","poster":"fitri001"},{"comment_id":"1281597","upvote_count":"1","content":"Selected Answer: D\nSome strategies, like tf.distribute.MirroredStrategy, can provide performance optimizations even on a single GPU. For example, it can take advantage of better gradient computation or data parallelism during backpropagation, which can slightly optimize performance.","timestamp":"1725977760.0","poster":"baimus"},{"upvote_count":"1","comment_id":"1241438","timestamp":"1720013940.0","poster":"Prakzz","content":"Same Question as 96?"},{"comment_id":"1199756","poster":"pinimichele01","timestamp":"1713716760.0","upvote_count":"1","content":"Selected Answer: D\nhttps://www.tensorflow.org/guide/distributed_training#onedevicestrategy"},{"content":"Selected Answer: D\nD. Use the tf.distribute.Strategy API and run a distributed training job.\n\nHere's why:\n\nA. Increase instance memory and batch size: This might not be helpful. While increasing memory could help with loading more images at once, the main bottleneck here is likely processing these large images. Increasing the batch size can worsen the problem by further straining the GPU's memory.\nB. Replace P100 with K80 GPU: A weaker GPU would likely slow down training instead of speeding it up.\nC. Enable early stopping: This can save time but might stop training before reaching optimal performance.\nD. Use tf.distribute.Strategy: This allows you to distribute the training workload across multiple GPUs or cores within your instance, significantly accelerating training without changing the model itself. This effectively leverages the available hardware efficiently.","comment_id":"1140549","poster":"guilhermebutzke","timestamp":"1707082740.0","upvote_count":"4"},{"timestamp":"1693392600.0","content":"Selected Answer: D\nperhaps the fact that the second or more GPUs are created is implied and the answer is D\n https://codelabs.developers.google.com/vertex_multiworker_training#2","comment_id":"993978","poster":"bcama","upvote_count":"1"},{"comment_id":"962863","timestamp":"1690300860.0","upvote_count":"2","comments":[{"comment_id":"964001","poster":"tavva_prudhvi","content":"but using the tf.distribute.Strategy API is not limited to multiple GPU configurations. Although the current setup has only one GPU, you can still use the API to distribute the training across multiple Compute Engine instances, each with its own GPU. By running a distributed training job in this manner, you can effectively decrease the training time without sacrificing model performance.","timestamp":"1690390740.0","upvote_count":"3","comments":[{"comment_id":"1071697","content":"also, Replacing the NVIDIA P100 GPU with a K80 GPU is not recommended, as the K80 is an older, less powerful GPU compared to the P100. This might actually slow down the training process.","timestamp":"1700068740.0","upvote_count":"1","poster":"tavva_prudhvi"}]},{"content":"What you say makes sens for the most part except that K80 GPU has only 12GB of DDR5 memory not 24 , https://cloud.google.com/compute/docs/gpus#nvidia_k80_gpus\nSo that leaves me with the only viable option which is C.","comment_id":"991421","upvote_count":"1","poster":"Zemni","timestamp":"1693137780.0"}],"poster":"[Removed]","content":"Selected Answer: B\nThe same comment as in Q96. If we look at our training infrastructure, we can see the bottleneck is obviously the GPU, which has 12GB or 16GB memory depending on the model (https://www.leadtek.com/eng/products/ai_hpc(37)/tesla_p100(761)/detail). This means we can afford to have a batch size of only 6-8 images (2GB each) even if we assume the GPU is utilized 100% and model weights take 0 memory. And remember the training size is 3M, which means each epoch will have 375-500K steps even in this unlikely best case.\n\nWith 32-cores and 128GB memory, we are able to afford higher batch sizes (e.g., 32), so moving to a K80 GPU that has 24GB of memory will accelerate the training.\n\nA is wrong because we can't afford a larger batch size with the current GPU. D is wrong because you don't have multiple GPUs and your current GPU is saturated. C is a viable option, but it seems less optimal than B."},{"upvote_count":"1","timestamp":"1690258620.0","comment_id":"962326","poster":"ciro_li","content":"Selected Answer: D\nhttps://www.tensorflow.org/guide/gpu \n?","comments":[{"poster":"ciro_li","comment_id":"964817","content":"I was wrong. It's A.","upvote_count":"1","timestamp":"1690468740.0"}]},{"poster":"PST21","timestamp":"1689861660.0","content":"Selected Answer: D\nto decrease training time without sacrificing model performance, the best approach is to use the tf.distribute.Strategy API and run a distributed training job, leveraging the capabilities of the available GPU(s) for parallelized training.","upvote_count":"1","comment_id":"957668"},{"upvote_count":"1","comment_id":"950571","timestamp":"1689245100.0","content":"Selected Answer: A\nA\nsince we just have one gpu, we could not use tf.distribute.Strategy in D","comments":[{"poster":"powerby35","content":"And C early stopping maybe hurt the performance","comment_id":"950572","timestamp":"1689245160.0","upvote_count":"1"},{"content":"The increased batch size also can hurt the performance if it is not followed by further optimizations with regards to learning rate for example. If early stopping is applied according to common convention, by stopping when the validation loss starts increasing, it should not hurt the performance. However it is not specified in the answer sadly.","upvote_count":"1","timestamp":"1701096720.0","comment_id":"1081671","poster":"TLampr"}],"poster":"powerby35"}],"choices":{"A":"Increase the instance memory to 512 GB, and increase the batch size.","D":"Use the tf.distribute.Strategy API and run a distributed training job.","C":"Enable early stopping in your Vertex AI Training job.","B":"Replace the NVIDIA P100 GPU with a K80 GPU in the training job."}},{"id":"gRp0a696jIfo1ZnUrXCv","answer":"B","url":"https://www.examtopics.com/discussions/google/view/115039-exam-professional-machine-learning-engineer-topic-1-question/","timestamp":"2023-07-13 12:50:00","discussion":[{"comment_id":"1199949","upvote_count":"3","timestamp":"1729571940.0","content":"Selected Answer: B\nVertex AutoML Tables is a managed service specifically designed for building machine learning models from structured data in BigQuery, all without writing code. It automates various stages of the machine learning pipeline, including:\n\nExploratory data analysis: AutoML Tables performs basic data understanding to identify potential issues.\nFeature selection: It can automatically select relevant features for model training.\nModel building: AutoML Tables trains and evaluates various machine learning models and chooses the best performing one for classification.\nHyperparameter tuning: It automatically tunes hyperparameters to optimize model performance.\nServing: You can deploy the trained model for making predictions on new data.","poster":"fitri001"},{"upvote_count":"2","content":"Selected Answer: B\nB, since it's specifying without writing code","poster":"ludovikush","timestamp":"1728382740.0","comment_id":"1191504"},{"upvote_count":"1","poster":"Carlose2108","timestamp":"1724838600.0","comment_id":"1161580","content":"Selected Answer: B\nNo writing Code.\nOption B."},{"content":"Selected Answer: B\nAutoML -> No writing code","upvote_count":"1","timestamp":"1723902480.0","comment_id":"1152664","poster":"Tonygangrade"},{"content":"B\nWith automl we don’t write any line of code","poster":"36bdc1e","upvote_count":"1","comment_id":"1115655","timestamp":"1720334640.0"},{"content":"B is correct.\nA and D imply writing code in TF and Sklearn respectively.\nC is writing BQML code for logistic regression as well. Furthermore, how would you do the EDA and feature selection etc. without writing code?\nAutoML is THE codeless solution automating all the steps mentioned above. https://cloud.google.com/automl?hl=en","timestamp":"1717769520.0","upvote_count":"1","poster":"bugger123","comment_id":"1090433"},{"poster":"Nxtgen","content":"Selected Answer: B\nA and D would require writing code.\nC. would also imply some “code writing” in BigQuery ML\n\nI would go with B.","comment_id":"988111","upvote_count":"1","timestamp":"1708685220.0"},{"content":"Selected Answer: B\nB\n\"without writing code\"","timestamp":"1705150200.0","comment_id":"950576","upvote_count":"1","poster":"powerby35"}],"answers_community":["B (100%)"],"question_text":"You need to build classification workflows over several structured datasets currently stored in BigQuery. Because you will be performing the classification several times, you want to complete the following steps without writing code: exploratory data analysis, feature selection, model building, training, and hyperparameter tuning and serving. What should you do?","answer_description":"","answer_images":[],"unix_timestamp":1689245400,"answer_ET":"B","choices":{"A":"Train a TensorFlow model on Vertex AI.","B":"Train a classification Vertex AutoML model.","D":"Use scikit-learn in Vertex AI Workbench user-managed notebooks with pandas library.","C":"Run a logistic regression job on BigQuery ML."},"question_id":64,"topic":"1","exam_id":13,"isMC":true,"question_images":[]},{"id":"TEMkFtak6KDlqihJLhwV","timestamp":"2023-07-20 16:06:00","exam_id":13,"choices":{"B":"Add handcrafted features to inject your domain knowledge into the model","C":"Use the Vertex AI hyperparameter tuning service to identify a better learning rate","A":"Verify that your model can obtain a low loss on a small subset of the dataset","D":"Use hardware accelerators and train your model for more epochs"},"unix_timestamp":1689861960,"isMC":true,"answers_community":["A (100%)"],"answer_ET":"A","answer_images":[],"answer_description":"","question_images":[],"discussion":[{"timestamp":"1729572180.0","content":"Selected Answer: A\nIsolating the Issue: Training on a small subset helps isolate the problem to the model itself rather than the entire training pipeline or large dataset.\nEfficiency: Debugging with a small dataset is faster, allowing you to iterate through potential solutions quicker.\nIdentifying Fundamental Issues: If the model struggles to learn even on a small dataset, it indicates a more fundamental problem in the model architecture, data preprocessing, or learning algorithm.","upvote_count":"4","comment_id":"1199950","poster":"fitri001"},{"timestamp":"1715786580.0","comment_id":"1071703","poster":"tavva_prudhvi","content":"Selected Answer: A\nVerifying that your model can obtain a low loss on a small subset of the dataset is a good first step for debugging because it helps you determine if your model is capable of fitting the data and learning from it. If your model cannot fit a small subset of the data, it may indicate issues with the model architecture, initialization, or optimization algorithm. By starting with a small subset, you can identify and fix these issues more quickly, before moving on to larger-scale training and more complex debugging tasks.","upvote_count":"3"},{"timestamp":"1706725020.0","poster":"Mdso","comment_id":"968275","upvote_count":"1","content":"Selected Answer: A\nI choose A"},{"content":"Selected Answer: A\nthe first step to quickly debug the deep learning model is to verify that it can obtain a low loss on a small subset of the dataset (Option A). If the model fails to achieve good results on the smaller subset, further investigation is required to identify and address potential issues with the model.","poster":"PST21","comment_id":"957673","timestamp":"1705766760.0","upvote_count":"1"}],"question_id":65,"url":"https://www.examtopics.com/discussions/google/view/115867-exam-professional-machine-learning-engineer-topic-1-question/","answer":"A","topic":"1","question_text":"You recently developed a deep learning model. To test your new model, you trained it for a few epochs on a large dataset. You observe that the training and validation losses barely changed during the training run. You want to quickly debug your model. What should you do first?"}],"exam":{"name":"Professional Machine Learning Engineer","id":13,"isImplemented":true,"numberOfQuestions":304,"isBeta":false,"provider":"Google","lastUpdated":"11 Apr 2025","isMCOnly":true},"currentPage":13},"__N_SSP":true}