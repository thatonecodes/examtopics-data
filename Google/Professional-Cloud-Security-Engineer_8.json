{"pageProps":{"questions":[{"id":"wfufjHzXKmF10DBej4bO","isMC":true,"answer_images":[],"question_images":[],"topic":"1","answer":"DE","question_text":"You plan to use a Google Cloud Armor policy to prevent common attacks such as cross-site scripting (XSS) and SQL injection (SQLi) from reaching your web application's backend. What are two requirements for using Google Cloud Armor security policies? (Choose two.)","timestamp":"2022-04-29 03:30:00","question_id":36,"url":"https://www.examtopics.com/discussions/google/view/74836-exam-professional-cloud-security-engineer-topic-1-question/","answer_description":"","answer_ET":"DE","exam_id":9,"unix_timestamp":1651195800,"answers_community":["DE (92%)","8%"],"discussion":[{"upvote_count":"1","content":"Selected Answer: DE\nHere's the reasoning:\nD is correct because according to search result , one of the requirements for using Google Cloud Armor security policies is that \"The backend service's load balancing scheme must be EXTERNAL, EXTERNAL_MANAGED, or INTERNAL_MANAGED.\" The EXTERNAL scheme is specifically mentioned in the answer option.\nE is correct because Google Cloud Armor is primarily designed to work with HTTP(S) load balancers. This is supported by multiple search results, including which states that Google Cloud Armor security policies protect \"Global external Application Load Balancer (HTTP/HTTPS)\" among others.","poster":"i_am_robot","comment_id":"1263759","timestamp":"1723353720.0"},{"poster":"LaithTech","timestamp":"1723113000.0","comment_id":"1262444","upvote_count":"1","comments":[{"comment_id":"1315519","timestamp":"1732139040.0","content":"This says otherwise\nhttps://cloud.google.com/armor/docs/security-policy-overview#requirements","upvote_count":"1","poster":"nah99"}],"content":"Google Cloud Armor is only supported with the Premium Network Service Tier. The Standard Tier does not support Google Cloud Armor features."},{"comment_id":"1186910","poster":"Bettoxicity","upvote_count":"1","timestamp":"1711905060.0","content":"Selected Answer: BE\nBE\n\nB: Google Cloud Armor operates at Layer 7 (application layer) of the OSI model. Its security policies inspect incoming HTTP(S) requests and can match on various L7 attributes like request headers, body content, and URI paths. This allows you to define rules that block attacks like XSS and SQLi based on their specific characteristics.\n\nWhy not C: The load balancing scheme of the backend service (internal or external) doesn't impact Cloud Armor's operation. Cloud Armor focuses on filtering traffic at the external load balancer level."},{"content":"Why not B?","comment_id":"1040611","timestamp":"1697025600.0","poster":"aygitci","upvote_count":"2"},{"comment_id":"1010285","content":"Selected Answer: DE\nTo use Google Cloud Armor security policies to prevent common attacks such as cross-site scripting (XSS) and SQL injection (SQLi) from reaching your web application’s backend, you need to meet the following requirements :\n\n1) The load balancer must be a global external Application Load Balancer, a classic Application Load Balancer, a regional external Application Load Balancer, or an external proxy Network Load Balancer .\n2) The backend service’s load balancing scheme must be EXTERNAL, or EXTERNAL_MANAGED if you are using either a global external Application Load Balancer or a regional external Application Load Balancer .","timestamp":"1695014940.0","upvote_count":"1","poster":"Xoxoo"},{"upvote_count":"1","poster":"[Removed]","timestamp":"1690335900.0","comment_id":"963236","content":"Selected Answer: DE\n\"D\", \"E\"\nAs others noted in the comments, \"A\",\"D\" and \"E\" all meet the minimum requirements for setting up Cloud Armor. However part of the question is having WAF functionality which is not available for External SSL Proxy LBs (A) (no checkmark under external proxy lb column for WAF row). \n\nThis which leaves us with D and E only.\n\nReferences:\nhttps://cloud.google.com/armor/docs/security-policy-overview#requirements\nhttps://cloud.google.com/armor/docs/security-policy-overview#"},{"timestamp":"1684930140.0","content":"Now we can manage also network load balancer","poster":"gcpengineer","comment_id":"905867","upvote_count":"1"},{"content":"Selected Answer: DE\nDE is the ans","poster":"gcpengineer","comment_id":"901435","upvote_count":"1","timestamp":"1684433040.0"},{"comment_id":"711543","timestamp":"1667619660.0","upvote_count":"2","poster":"AzureDP900","content":"D,E is most appropriate in this case\nD. The backend service's load balancing scheme must be EXTERNAL. \nE. The load balancer must be an external HTTP(S) load balancer."},{"timestamp":"1665630420.0","content":"Selected Answer: DE\nDE.\nWell technically you can use EXTERNAL_MANAGED scheme too.","upvote_count":"1","comment_id":"693547","poster":"soltium"},{"timestamp":"1665240060.0","upvote_count":"1","content":"Selected Answer: DE\nD. The backend service's load balancing scheme must be EXTERNAL.\nE. The load balancer must be an external HTTP(S) load balancer.","comment_id":"689436","poster":"AwesomeGCP"},{"timestamp":"1661407980.0","upvote_count":"2","poster":"Jeanphi72","content":"Selected Answer: DE\nhttps://cloud.google.com/armor/docs/security-policy-overview#requirements says:\nThe backend service's load balancing scheme must be EXTERNAL, or EXTERNAL_MANAGED *** if you are using global external HTTP(S) load balancer ***.\n\nThus D and E fit (A could fit if a suggestion like The backend service's load balancing scheme must ** NOT ** be EXTERNAL","comment_id":"651666"},{"timestamp":"1659263520.0","comments":[{"comments":[{"timestamp":"1680777600.0","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1690335600.0","content":"If you look at the table here, you'll see that the row that has \"WAF\" (which is what you need here for web application firewall) is unchecked under the External Proxy LB column. This disqualifies \"A\" from the answer and leaves us with \"D\" and \"E\" only.\nReference:\nhttps://cloud.google.com/armor/docs/security-policy-overview#expandable-1\n\nSo good catch piyush_1982 and zellck !","comment_id":"963235","poster":"[Removed]"}],"content":"Not true....Security policy overview\n\nbookmark_border\nGoogle Cloud Armor security policies protect your application by providing Layer 7 filtering and by scrubbing incoming requests for common web attacks or other Layer 7 attributes to potentially block traffic before it reaches your load balanced backend services or backend buckets. Each security policy is made up of a set of rules that filter traffic based on conditions such as an incoming request's IP address, IP range, region code, or request headers.\n\nGoogle Cloud Armor security policies are available only for backend services of global external HTTP(S) load balancers, global external HTTP(S) load balancer (classic)s, external TCP proxy load balancers, or external SSL proxy load balancers. The load balancer can be in Premium Tier or Standard Tier.https://cloud.google.com/armor/docs/security-policy-overview . A, D,E are correct","comment_id":"862867","poster":"TNT87"}],"content":"Security policy for A does not block XSS and SQLi which is at layer 7.\nhttps://cloud.google.com/armor/docs/security-policy-overview#policy-types","poster":"zellck","comment_id":"680465","timestamp":"1664260920.0","upvote_count":"5"}],"poster":"piyush_1982","content":"I am not sure if there is some mistake in the question or in the options given.\n\nhttps://cloud.google.com/armor/docs/security-policy-overview#requirements\n\nAs per the link above, below are the requirements for using Google Cloud Armor security policies:\n\n1. The load balancer must be a global external HTTP(S) load balancer, global external HTTP(S) load balancer (classic), external TCP proxy load balancer, or external SSL proxy load balancer.\n2. The backend service's load balancing scheme must be EXTERNAL, or EXTERNAL_MANAGED if you are using a global external HTTP(S) load balancer.\n3. The backend service's protocol must be one of HTTP, HTTPS, HTTP/2, TCP, or SSL.\n\n\nThe correct answer seems to be A D and E. \n\nA. The load balancer must be an external SSL proxy load balancer. (external SSL proxy load balancer is one of the load balancing options listed in the link)\nD. The backend service's load balancing scheme must be EXTERNAL. (or EXTERNAL_MANAGED)\nE. The load balancer must be an external HTTP(S) load balancer. (Also one of the options listed)","comment_id":"640061","upvote_count":"3"},{"content":"Selected Answer: DE\nThese are the requirements for using Google Cloud Armor security policies:\n\nThe load balancer must be an external HTTP(S) load balancer, TCP proxy load balancer, or SSL proxy load balancer.\nThe backend service's load balancing scheme must be EXTERNAL.\nThe backend service's protocol must be one of HTTP, HTTPS, HTTP/2, TCP, or SSL.\nhttps://cloud.google.com/armor/docs/security-policy-overview","poster":"nacying","comment_id":"614479","upvote_count":"1","timestamp":"1654856040.0"},{"timestamp":"1654019220.0","upvote_count":"3","content":"Selected Answer: DE\nDE\n\nRequirements\n\nThese are the requirements for using Google Cloud Armor security policies:\n\n* The load balancer must be an external HTTP(S) load balancer, TCP proxy load balancer, or SSL proxy load balancer.\n* The backend service's load balancing scheme must be EXTERNAL.\n* The backend service's protocol must be one of HTTP, HTTPS, HTTP/2, TCP, or SSL.\n\nSee https://cloud.google.com/armor/docs/security-policy-overview#requirements","poster":"cloudprincipal","comment_id":"609850"},{"content":"Google Cloud Armor security policies are sets of rules that match on attributes from Layer 3 to Layer 7 to protect externally facing applications or services. Each rule is evaluated with respect to incoming traffic.\nI choose DE","timestamp":"1653359280.0","comment_id":"606429","poster":"szl0144","upvote_count":"1"},{"comment_id":"604471","content":"Ans:D,E\nhttps://cloud.google.com/armor/docs/security-policy-overview\nRelevant extracts:\n1. Google Cloud Armor security policies enable you to rate-limit or redirect requests to your HTTP(S) Load Balancing, TCP Proxy Load Balancing, or SSL Proxy Load Balancing ...\n2. Google Cloud Armor security policies are sets of rules that match on attributes from Layer 3 to Layer 7 to protect externally facing applications or services...\n3. The load balancer can be in Premium Tier or Standard Tier.","poster":"ExamQnA","timestamp":"1653055260.0","upvote_count":"3"},{"comment_id":"594163","comments":[{"comment_id":"599606","upvote_count":"5","poster":"Taliesyn","timestamp":"1652189040.0","content":"I'd say D, E, even though it's redundant.\nDefinitely not B, as you can filter on IP addresses, ie layer 3."}],"content":"Answer is (B), (D).\n\nGoogle Cloud Armor security policies protect your application by providing Layer 7 filtering and by scrubbing incoming requests for common web attacks or other Layer 7 attributes to potentially block traffic before it reaches your load balanced backend services or backend buckets. \nGoogle Cloud Armor security policies are available only for backend services behind an external HTTP(S) load balancer, TCP proxy load balancer, or an SSL proxy load balancer. The load balancer can be in Premium Tier or Standard Tier.\nhttps://cloud.google.com/armor/docs/security-policy-overview","timestamp":"1651195800.0","poster":"Tabayashi","upvote_count":"3"}],"choices":{"C":"The load balancer must use the Premium Network Service Tier.","D":"The backend service's load balancing scheme must be EXTERNAL.","E":"The load balancer must be an external HTTP(S) load balancer.","A":"The load balancer must be an external SSL proxy load balancer.","B":"Google Cloud Armor Policy rules can only match on Layer 7 (L7) attributes."}},{"id":"PPHY3k8yOgncumRHnyf6","url":"https://www.examtopics.com/discussions/google/view/80418-exam-professional-cloud-security-engineer-topic-1-question/","answer_images":[],"isMC":true,"timestamp":"2022-09-05 21:32:00","choices":{"D":"Cloud VPN","C":"Cloud Router","B":"Cloud NAT","A":"Google Cloud Armor"},"answer_ET":"B","answer":"B","question_id":37,"question_text":"You perform a security assessment on a customer architecture and discover that multiple VMs have public IP addresses. After providing a recommendation to remove the public IP addresses, you are told those VMs need to communicate to external sites as part of the customer's typical operations. What should you recommend to reduce the need for public IP addresses in your customer's VMs?","answers_community":["B (100%)"],"answer_description":"","unix_timestamp":1662406320,"question_images":[],"discussion":[{"poster":"Random_Mane","comment_id":"660498","content":"Selected Answer: B\nB. https://cloud.google.com/nat/docs/overview","timestamp":"1725564720.0","upvote_count":"7"},{"upvote_count":"2","poster":"AzureDP900","comment_id":"711545","timestamp":"1730778060.0","content":"B Cloud NAT"}],"exam_id":9,"topic":"1"},{"id":"jPlCJhRTW3XFJwNvwdjb","question_id":38,"answer_images":[],"question_text":"You are tasked with exporting and auditing security logs for login activity events for Google Cloud console and API calls that modify configurations to Google\nCloud resources. Your export must meet the following requirements:\n✑ Export related logs for all projects in the Google Cloud organization.\n✑ Export logs in near real-time to an external SIEM.\nWhat should you do? (Choose two.)","answers_community":["BC (49%)","BD (41%)","8%"],"unix_timestamp":1653064140,"timestamp":"2022-05-20 18:29:00","answer_description":"","isMC":true,"discussion":[{"comment_id":"609855","content":"Selected Answer: BD\nB\nbecause for all projects\n\n\nD\n\"Google Workspace Login Audit: Login Audit logs track user sign-ins to your domain. These logs only record the login event. They don't record which system was used to perform the login action.\"\nhttps://cloud.google.com/logging/docs/audit/gsuite-audit-logging#services","poster":"cloudprincipal","timestamp":"1654019400.0","upvote_count":"13","comments":[{"poster":"exambott","timestamp":"1675070700.0","content":"Google cloud logs is different from Google Workspace logs. D is definitely incorrect.","comment_id":"792598","upvote_count":"1"},{"upvote_count":"2","content":"There is no mentioning anything like \"Google Workspace\", why is D correct?","comment_id":"810807","poster":"mikez2023","timestamp":"1676560080.0"}]},{"upvote_count":"12","poster":"ExamQnA","comment_id":"604552","timestamp":"1653064140.0","comments":[{"upvote_count":"2","poster":"passex","content":"There is no mention about 'data access logs' in question","timestamp":"1672210980.0","comment_id":"759461","comments":[{"poster":"Nik2592s","timestamp":"1685007480.0","comments":[{"comment_id":"1134822","poster":"luca_scalzotto","content":"The question state: \"API calls that modify configurations to Google\nCloud resources\". From the documentation: \"Admin Activity audit logs contain log entries for API calls or other actions that modify the configuration or metadata of resources. For example, these logs record when users create VM instances or change Identity and Access Management permissions.\" Therefore, cannot be C","upvote_count":"1","timestamp":"1706523300.0"}],"upvote_count":"4","comment_id":"906558","content":"API calls are tracked in Data access logs"}]}],"content":"Ans:B,C\nhttps://cloud.google.com/logging/docs/export/aggregated_sinks: To use aggregated sinks, you create a sink in a Google Cloud organization or folder, and set the sink's includeChildren parameter to True. That sink can then route log entries from the organization or folder, plus (recursively) from any contained folders, billing accounts, or Cloud projects.\nhttps://cloud.google.com/logging/docs/audit#data-access\nData Access audit logs-- except for BigQuery Data Access audit logs-- are disabled by default because audit logs can be quite large. If you want Data Access audit logs to be written for Google Cloud services other than BigQuery, you must explicitly enable them"},{"timestamp":"1732973460.0","content":"Selected Answer: BE\nWhy B. Create a Log Sink at the organization level with the includeChildren parameter and set the destination to a Pub/Sub topic is Correct: E. Ensure that the SIEM processes the AuthenticationInfo field in the audit log entry to gather identity information.\n\nWhy Not the Other Options:\nC Enabling Data Access logs is not required for this use case. The question only asks for login activity and configuration changes, which are captured in Admin Activity logs\nD. Enable Google Workspace audit logs \nThis is not directly relevant. Google Workspace audit logs are not required for capturing Google Cloud login activity and configuration changes.","poster":"BPzen","upvote_count":"1","comment_id":"1320215"},{"content":"Selected Answer: BC\nB\nbecause for all projects\nС","timestamp":"1725188280.0","poster":"Mr_MIXER007","upvote_count":"1","comment_id":"1275999"},{"upvote_count":"1","content":"Selected Answer: BD\nturn on audit and sink, pub-sub (near realtime)","comment_id":"1265502","timestamp":"1723612740.0","poster":"60090d7"},{"comment_id":"1230882","content":"Selected Answer: BC\nNo Workspace","timestamp":"1718445300.0","upvote_count":"1","poster":"piipo"},{"poster":"pico","content":"Selected Answer: BC\nwhy the other options are not as suitable:\n\nA: While creating a log sink at the organization level is correct, it won't include logs from child projects unless the includeChildren parameter is set to true.\nD: Google Workspace audit logs are separate from Google Cloud audit logs and won't provide the required information about Google Cloud console logins or API calls.\nE: While processing the AuthenticationInfo field is essential for identifying actors, it is not a step in the setup of the log export itself.","upvote_count":"2","comment_id":"1212309","timestamp":"1715842020.0"},{"poster":"Bettoxicity","content":"Selected Answer: AE\nAE\nA: Setting up a Log Sink at the organization level with Pub/Sub as the destination guarantees you capture logs from all projects within your organization.\nE: The AuthenticationInfo field within audit log entries provides valuable details about the user or service that made the configuration change or login attempt. Your SIEM needs to be able to process this field to extract identity information for security audit purposes.\n\nB. IncludeChildren Parameter (Not Required)\nC. Data Access Audit Logs (Not Specific)","timestamp":"1711907940.0","comment_id":"1186928","upvote_count":"1"},{"timestamp":"1708607040.0","upvote_count":"2","comment_id":"1156369","poster":"gurusen88","content":"B & E \n\nB. Organization Level Log Sink with includeChildren parameter: Creating a log sink at the organization level with the includeChildren parameter ensures that you capture logs from all projects within the organization. Setting the destination to a Pub/Sub topic is suitable for real-time log export, meeting the requirement to export logs in near real-time to an external SIEM.\n\nE. Processing the AuthenticationInfo field: The AuthenticationInfo field in the audit log entries contains identity information, which is crucial for auditing security logs for login activity. Ensuring that the SIEM processes this field allows for a detailed analysis of who is accessing what, fulfilling the requirement to audit login activity events and API calls that modify configurations."},{"comment_id":"1114421","timestamp":"1704449400.0","content":"Selected Answer: BC\nNo mention of Google Workspace","poster":"mjcts","upvote_count":"3"},{"poster":"loonytunes","content":"ANS: B,D\nApi calls that modify configuration of resources are in Admin Activity audit logs, which are on by default (along with System Events and Deny Policies). Thus not C. You can also enable Google Workspace logs to be forwarded to Google cloud at the Org Level \nSame Link.\nhttps://cloud.google.com/logging/docs/audit/gsuite-audit-logging#log-types","comment_id":"1053172","upvote_count":"1","timestamp":"1698181920.0"},{"timestamp":"1697026980.0","upvote_count":"3","content":"Selected Answer: BC\nNot mention og Google Workspace, definitely not D","comment_id":"1040627","poster":"aygitci"},{"comment_id":"1012698","timestamp":"1695255360.0","upvote_count":"5","content":"Selected Answer: BC\nTo export and audit security logs for login activity events in the Google Cloud Console and API calls that modify configurations to Google Cloud resources with the specified requirements, you should take the following steps:\n\nB. Create a Log Sink at the organization level with the includeChildren parameter and set the destination to a Pub/Sub topic: This step will export related logs from all projects within the Google Cloud organization, including the logs you need. The use of Pub/Sub allows near real-time export of logs.\n\nC. Enable Data Access audit logs at the organization level to apply to all projects: Enabling Data Access audit logs at the organization level ensures that logs related to API calls that modify configurations to Google Cloud resources are captured.","poster":"Xoxoo","comments":[{"content":"The other options are not relevant or necessary for meeting the specified requirements:\n\nD. \"Enable Google Workspace audit logs to be shared with Google Cloud in the Admin Console\" is not directly related to exporting logs for Google Cloud Console and API calls.\n\nE. \"Ensure that the SIEM processes the AuthenticationInfo field in the audit log entry to gather identity information\" is a consideration for how the SIEM system processes logs but is not a configuration step for exporting logs.","timestamp":"1695255360.0","upvote_count":"2","poster":"Xoxoo","comment_id":"1012699"}]},{"comment_id":"999889","content":"Can someone explain how or why 'D' can be correct? The logs are Google Cloud not Workspace...","timestamp":"1693946880.0","upvote_count":"2","poster":"desertlotus1211"},{"poster":"[Removed]","comment_id":"963259","timestamp":"1690338480.0","upvote_count":"1","content":"Selected Answer: BD\n\"B\", \"D\"\nB because you need an aggregate sink to recursively pull from children entities otherwise scope is limited to the specific level where it's created. So this also excludes A.\nhttps://cloud.google.com/logging/docs/export/aggregated_sinks#create_an_aggregated_sink\n\nC - Data Access Audit Logs - Even though they include API events, they don't explicitly say they also include log-in events.\nhttps://cloud.google.com/logging/docs/audit#data-access\n\nD - For Workspace Audit Logs, they explicitly say that API calls and log-in events are captured which makes it a more complete option than \"C\". Also, cloud identity, which is used to manage users of GCP, is a workspace service. It would make sense that workspace logging providing cloud identity related sign-in logs.\nhttps://cloud.google.com/logging/docs/audit/gsuite-audit-logging\nhttps://support.google.com/cloudidentity/answer/7319251"},{"upvote_count":"2","comment_id":"905885","timestamp":"1684932180.0","poster":"gcpengineer","content":"Selected Answer: BE\nchange to BE"},{"comment_id":"901437","upvote_count":"3","poster":"gcpengineer","content":"Selected Answer: BC\nBC looks lik ans","timestamp":"1684433280.0"},{"comment_id":"848232","poster":"fad3r","content":"B&C\n\nFor C:\nhttps://cloud.google.com/logging/docs/audit#data-access\n\nPublicly available resources that have the Identity and Access Management policies allAuthenticatedUsers or allUsers don't generate audit logs. Resources that can be accessed without logging into a Google Cloud, Google Workspace, Cloud Identity, or Drive Enterprise account don't generate audit logs. This helps protect end-user identities and information.\n\nIt literally says it wont generate logs for non login events. Which of course means it generates logs for all events that involve logging in.\nD just handles cloud identity since their implementation on the workspace side. How they tied in workspace sucks. That wouldnt let you know who deleted or modified something like a vm or spun up a composer instance.","timestamp":"1679576700.0","upvote_count":"3"},{"poster":"AzureDP900","timestamp":"1667619780.0","content":"B,D is right","comment_id":"711546","upvote_count":"1"},{"timestamp":"1653553680.0","upvote_count":"7","comment_id":"607538","poster":"Medofree","content":"Correct answers are : B,D\n\nB : to respond to the \"logs for all projects\" requirement and \" near real-time \"requirement \nD: to be able de log \"login activities\" we need to export audit logs from Google Workspace to Google Cloud."}],"exam_id":9,"answer_ET":"BC","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/75964-exam-professional-cloud-security-engineer-topic-1-question/","choices":{"A":"Create a Log Sink at the organization level with a Pub/Sub destination.","B":"Create a Log Sink at the organization level with the includeChildren parameter, and set the destination to a Pub/Sub topic.","E":"Ensure that the SIEM processes the AuthenticationInfo field in the audit log entry to gather identity information.","D":"Enable Google Workspace audit logs to be shared with Google Cloud in the Admin Console.","C":"Enable Data Access audit logs at the organization level to apply to all projects."},"topic":"1","answer":"BC"},{"id":"uKSrQnHSkSGJ5KLjq6rM","isMC":true,"answer_images":[],"question_images":[],"answer":"C","topic":"1","question_text":"Your company's Chief Information Security Officer (CISO) creates a requirement that business data must be stored in specific locations due to regulatory requirements that affect the company's global expansion plans. After working on the details to implement this requirement, you determine the following:\n✑ The services in scope are included in the Google Cloud Data Residency Terms.\n✑ The business data remains within specific locations under the same organization.\n✑ The folder structure can contain multiple data residency locations.\nYou plan to use the Resource Location Restriction organization policy constraint. At which level in the resource hierarchy should you set the constraint?","timestamp":"2022-05-10 15:32:00","question_id":39,"url":"https://www.examtopics.com/discussions/google/view/75428-exam-professional-cloud-security-engineer-topic-1-question/","answer_description":"","answer_ET":"C","exam_id":9,"unix_timestamp":1652189520,"answers_community":["C (60%)","A (33%)","5%"],"discussion":[{"poster":"mouchu","comments":[{"comment_id":"642277","content":"why not D?","upvote_count":"2","poster":"piyush_1982","timestamp":"1659604200.0"},{"comments":[{"upvote_count":"1","poster":"AzureDP900","content":"Q 137 is same","comment_id":"717027","timestamp":"1668300900.0"}],"upvote_count":"3","content":"Yes, It is C. This is very tricky question and we need to read very carefully. In general Folders will used but in this case Project is right","timestamp":"1668300900.0","poster":"AzureDP900","comment_id":"717026"}],"content":"Answer = C\n\"The folder structure can contain multiple data residency locations\" suggest that restriction should be applied on projects level","timestamp":"1652773620.0","comment_id":"602834","upvote_count":"23"},{"poster":"Taliesyn","upvote_count":"6","timestamp":"1652189520.0","content":"Selected Answer: A\nOrg policies can't be applied on resources ...","comment_id":"599611"},{"poster":"Mauratay","timestamp":"1739502660.0","comment_id":"1356352","content":"Selected Answer: B\nReference:\nhttps://cloud.google.com/resource-manager/docs/organization-policy/defining-locations#overview\nA policy that includes this constraint will not be enforced on sub-resource creation for certain services, such as Cloud Storage and Dataproc.\n\nhttps://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy#inheritance\n\nCloud Storage is a resource eligibile for location constraints.\n\nAll other options would be viable with the use of value groups, at either org, folder or project level, however, the only clue here is their data to be stored, which points to cloud storage.\nhttps://cloud.google.com/resource-manager/docs/organization-policy/defining-locations#value_groups","upvote_count":"1"},{"poster":"BPzen","content":"Selected Answer: C\n\"The folder structure can contain multiple data residency locations\" suggest that restriction should be applied on projects level","comment_id":"1320219","timestamp":"1732973760.0","upvote_count":"1"},{"content":"Since you need to ensure that business data remains within specific locations under the same organization and the folder structure can contain multiple data residency locations, you should set the Resource Location Restriction organization policy constraint at the Organization level.\n\nTherefore, the correct answer is:\nD. Organization","upvote_count":"1","poster":"MFay","timestamp":"1714568580.0","comment_id":"1205097"},{"content":"Selected Answer: A\nA\n\nWhy not C?: Project-level constraints wouldn't offer the desired level of granularity. You might have data in a single project that needs to be stored in different locations based on regulations.\nWhy no D?: Organization: An organization-level constraint would restrict all resources within the organization to a single residency location, which wouldn't meet the need for differentiated locations for various data sets.","upvote_count":"1","poster":"Bettoxicity","comment_id":"1186953","timestamp":"1711910640.0"},{"upvote_count":"1","comment_id":"1181986","timestamp":"1711315500.0","content":"Selected Answer: C\nAgree with C","poster":"dija123"},{"content":"https://cloud.google.com/assured-workloads/docs/data-residency#:~:text=Organizations%20with%20data%20residency%20requirements,select%20your%20desired%20compliance%20program.\n\nOrganizations with data residency requirements can set up a Resource Locations policy that constrains the location of new in-scope resources for their whole organization or for individual projects.\n\nAnswer C is a better choice, though this documenttalks about folders. But the questions says there are multiple data residency locations in that folders, so project level seems to be the best.","poster":"desertlotus1211","comment_id":"999909","timestamp":"1693947720.0","upvote_count":"2"},{"timestamp":"1690343100.0","poster":"[Removed]","comment_id":"963322","content":"Selected Answer: C\nThese restrictions can be applied at Org level, Folder Level or Project Level, but not resource level. Also, these policies are inherited, which means they need to be applied at the lowest child possible in the hierarchy where this is needed, not higher. This makes the answer specific to the use case rather than textbook knowledge. According to the given: \"The folder structure can contain multiple data residency locations\". This means that applying location restrictions at the Folder level or above will violate the requirement.This means you must apply the constraint at Project level.\nQuotes from the references below:\n\"You can also apply the organization policy to a folder or a project with the folder or the project flags, and the folder ID and project ID, respectively.\" - no mention of resource level\nReferences:\nhttps://cloud.google.com/resource-manager/docs/organization-policy/understanding-hierarchy\nhttps://cloud.google.com/resource-manager/docs/organization-policy/using-constraints","upvote_count":"4"},{"timestamp":"1690341960.0","upvote_count":"2","comment_id":"963306","content":"\"C\" Project Level\nThese restrictions can be applied at Org level, Folder Level or Project Level, but not resource level. Also, these policies are inherited, which means they need to be applied at the lowest child possible in the hierarchy where this is needed, not higher. This makes the answer specific to the use case rather than textbook knowledge. According to the given: \"The folder structure can contain multiple data residency locations\". This means that applying location restrictions at the Folder level or above will violate the requirement.This means you must apply the constraint at Project level. \nQuotes from the references below:\n\"You can also apply the organization policy to a folder or a project with the folder or the project flags, and the folder ID and project ID, respectively.\" - no mention of resource level\nReferences:\nhttps://cloud.google.com/resource-manager/docs/organization-policy/understanding-hierarchy\nhttps://cloud.google.com/resource-manager/docs/organization-policy/using-constraints","poster":"[Removed]"},{"timestamp":"1684433400.0","comment_id":"901441","poster":"gcpengineer","content":"Selected Answer: C\nC is the ans","upvote_count":"3"},{"poster":"AnishAd","comment_id":"868194","upvote_count":"2","content":"C it is ---->\nImp line to read from Question to understand why At Project level : 1. business data must be stored in specific locations due to regulatory requirements & The folder structure can contain multiple data residency locations. \n --- > Since Folder is going to contain multiple data residency locations and requirement is to restrict in specific location , so Constraints should be set at project level.","timestamp":"1681296120.0"},{"comment_id":"859540","poster":"alleinallein","timestamp":"1680497820.0","upvote_count":"2","content":"Selected Answer: C\nProject level seems to be reasonable."},{"content":"Selected Answer: C\nAs \"The folder structure can contain multiple data residency locations.\" it has to be at project level","poster":"marrechea","upvote_count":"2","comment_id":"855888","timestamp":"1680188040.0"},{"poster":"fad3r","timestamp":"1679578320.0","comment_id":"848255","upvote_count":"3","content":"A lot of madness in these answers.\n\nIt is C.\n\nYou cant apply it at the org level since that effects everything.\n\nYou cant apply it at the folder level since can contain locations.\n\nYou CAN apply it at the project level. \n\nFor those who say you cant apply these policies at the org level I suggest you spend more time reading docs and testing things in a lab.\n\nhttps://cloud.google.com/blog/products/identity-security/meet-data-residency-requirements-with-google-cloud\n\nTo strengthen these controls further, Google Cloud offers Organization Policy constraints which can be applied at the organization, folder, or project level"},{"poster":"adelynllllllllll","comment_id":"728395","content":"the answer should be B\nhttps://cloud.google.com/resource-manager/docs/organization-policy/defining-locations","upvote_count":"1","timestamp":"1669564020.0"},{"comment_id":"723859","upvote_count":"4","content":"Selected Answer: C\nDifferent Locations therefore needs to be applied at Project Level.","timestamp":"1669059660.0","poster":"Rightsaidfred"},{"content":"To set an organization policy including a resource locations constraint:\nhttps://cloud.google.com/resource-manager/docs/organization-policy/defining-locations","timestamp":"1668883320.0","comment_id":"722172","upvote_count":"1","poster":"TonytheTiger"},{"timestamp":"1668191100.0","upvote_count":"2","content":"C is right","comment_id":"716259","poster":"AzureDP900"},{"timestamp":"1668190980.0","comments":[{"upvote_count":"2","poster":"AzureDP900","timestamp":"1668191160.0","content":"C is right in my poinion.","comment_id":"716260"}],"comment_id":"716258","poster":"AzureDP900","content":"137 and 133 questions are similar except ✑ The projects are aligned to specific locations.","upvote_count":"1"},{"comment_id":"699407","content":"Selected Answer: C\nI initially thought it will be folder but there are multiple data residencies in a folder hence it will conflict","timestamp":"1666221900.0","poster":"rotorclear","upvote_count":"2"},{"timestamp":"1665158280.0","upvote_count":"1","poster":"AwesomeGCP","comment_id":"688782","content":"Selected Answer: A\nA. Folder"},{"comment_id":"670578","upvote_count":"1","poster":"cjjatta","timestamp":"1663314360.0","content":"Selected Answer: C\nThe folder structure can contain multiple data residency locations"},{"content":"Selected Answer: A\nAnswer A,\nthe requirement says :\"The business data remains within specific locations under the same organization\" that's mean you need to set up the restriction at higher level so folder is the correct answer => Answer A","upvote_count":"4","poster":"GHOST1985","comment_id":"665427","timestamp":"1662815880.0"},{"content":"Selected Answer: D\nI think D is the best solution.\n\nhttps://cloud.google.com/assured-workloads/docs/concept-data-residency\n\nOrganizations with data residency requirements can set up a Resource Locations policy that constrains the location of new in-scope resources for their whole organization or for individual projects.\n\nAs per the link above it says for such a requirement you can set up the resource location constraint at Org or Individual Project level. Setting up at the individual project level will be exhausting hence setting up at Org level would be the best way to move forward.","upvote_count":"2","poster":"piyush_1982","timestamp":"1659606840.0","comment_id":"642302"},{"upvote_count":"1","poster":"mikesp","content":"Selected Answer: A\nSince it is possible to set org policy constraints at project and folder level and \"The folder structure can contain multiple data residency locations\", i would set the policy at folder level.\nhttps://cloud.google.com/resource-manager/docs/organization-policy/using-constraints\n\"You can also apply the organization policy to a folder or a project with the --folder or the --project flags, and the folder ID and project ID, respectively.\"","timestamp":"1654255140.0","comment_id":"611046"},{"timestamp":"1653398340.0","poster":"szl0144","content":"Selected Answer: C\nC is the answer, already have the organization policy to set all data in the same region but need to change the policy at the folder level","upvote_count":"4","comment_id":"606733"}],"choices":{"C":"Project","D":"Organization","A":"Folder","B":"Resource"}},{"id":"vxsrXAPxlqwNeHfjF5Pd","discussion":[{"upvote_count":"13","comment_id":"598931","content":"I think the correct answer is D.\nIt is mentioned in the question: \"You are required to only use APIs that are supported by VPC Service Controls\", from which we can understand that we cannot use private.googleapis.com. Hence, option A & C can be eliminated. \nAPI bundle with all-apis is mentioned in option B which is wrong as we want to use only those APIs supported by VPC service controls. Hence, option B can be eliminated. \nOption D has all the solutions we need. \n\nhttps://cloud.google.com/vpc/docs/private-service-connect\n\nAn API bundle:\nAll APIs (all-apis): most Google APIs\n(same as private.googleapis.com).\nVPC-SC (vpc-sc): APIs that VPC Service Controls supports\n(same as restricted.googleapis.com).\nVMs in the same VPC network as the endpoint (all regions)\nOn-premises systems that are connected to the VPC network that contains the endpoint","poster":"Nicky1402","timestamp":"1667987340.0","comments":[{"poster":"AzureDP900","comments":[{"poster":"AzureDP900","content":"D. Use restricted googleapis.com to access Google APIs using a set of IP addresses only routable from within Google Cloud, which are advertised as routes over the Cloud Interconnect connection.","comment_id":"711549","upvote_count":"1","timestamp":"1683251340.0"}],"upvote_count":"1","timestamp":"1683251340.0","content":"Yes, It is D","comment_id":"711548"}]},{"poster":"dija123","comment_id":"1181993","upvote_count":"1","timestamp":"1727206860.0","content":"Selected Answer: D\nAnswer is D"},{"poster":"[Removed]","comment_id":"963321","upvote_count":"2","timestamp":"1706247840.0","content":"Selected Answer: D\n\"D\" restricted.googleapis.com\nhttps://cloud.google.com/vpc-service-controls/docs/set-up-private-connectivity#procedure-overview"},{"upvote_count":"1","poster":"shayke","comment_id":"758189","timestamp":"1687839180.0","content":"Selected Answer: D\nD- route from on prem"},{"poster":"samuelmorher","comment_id":"750696","content":"Selected Answer: D\nit's D","timestamp":"1687245060.0","upvote_count":"2"},{"comment_id":"718288","upvote_count":"1","timestamp":"1684092060.0","poster":"marmar11111","content":"Selected Answer: D\nhttps://cloud.google.com/vpc/docs/configure-private-google-access-hybrid\n\nChoose restricted.googleapis.com when you only need access to Google APIs and services that are supported by VPC Service Controls."},{"poster":"AwesomeGCP","timestamp":"1680965460.0","comment_id":"689445","content":"Selected Answer: D\nD. Use restricted googleapis.com to access Google APIs using a set of IP addresses only routable from within Google Cloud, which are advertised as routes over the Cloud Interconnect connection.","upvote_count":"2"},{"timestamp":"1680103920.0","poster":"zellck","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/vpc/docs/configure-private-google-access-hybrid#config-choose-domain\nIf you need to restrict users to just the Google APIs and services that support VPC Service Controls, use restricted.googleapis.com. Although VPC Service Controls are enforced for compatible and configured services, regardless of the domain you use, restricted.googleapis.com provides additional risk mitigation for data exfiltration. Using restricted.googleapis.com denies access to Google APIs and services that are not supported by VPC Service Controls.","comment_id":"682805","upvote_count":"1"},{"poster":"bnikunj","upvote_count":"1","timestamp":"1678423440.0","content":"D is answer, https://cloud.google.com/vpc/docs/configure-private-service-connect-apis#supported-apis \nThe all-apis bundle provides access to the same APIs as private.googleapis.com\nChoose vpc-sc when you only need access to Google APIs and services that are supported by VPC Service Controls. The vpc-sc bundle does not permit access to Google APIs and services that do not support VPC Service Controls. 1","comment_id":"665050"},{"poster":"cloudprincipal","timestamp":"1670242800.0","upvote_count":"2","content":"Selected Answer: D\nWill agree with the others","comment_id":"611768","comments":[{"upvote_count":"3","comment_id":"615878","content":"This is actually specified in the documentation: https://cloud.google.com/vpc/docs/configure-private-google-access-hybrid#config-choose-domain","poster":"cloudprincipal","timestamp":"1670958240.0"}]},{"upvote_count":"3","comment_id":"604452","poster":"ExamQnA","content":"Ans: D\nNote: If you need to restrict users to just the Google APIs and services that support VPC Service Controls, use restricted.googleapis.com.\nhttps://cloud.google.com/vpc/docs/configure-private-google-access-hybrid","timestamp":"1668959100.0"}],"question_id":40,"answer":"D","timestamp":"2022-05-09 09:49:00","choices":{"A":"Enable Private Google Access on the regional subnets and global dynamic routing mode.","D":"Use restricted googleapis.com to access Google APIs using a set of IP addresses only routable from within Google Cloud, which are advertised as routes over the Cloud Interconnect connection.","B":"Set up a Private Service Connect endpoint IP address with the API bundle of \"all-apis\", which is advertised as a route over the Cloud interconnect connection.","C":"Use private.googleapis.com to access Google APIs using a set of IP addresses only routable from within Google Cloud, which are advertised as routes over the connection."},"answer_images":[],"answer_ET":"D","exam_id":9,"question_images":[],"answer_description":"","unix_timestamp":1652082540,"answers_community":["D (100%)"],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/75333-exam-professional-cloud-security-engineer-topic-1-question/","topic":"1","question_text":"You need to set up a Cloud interconnect connection between your company's on-premises data center and VPC host network. You want to make sure that on- premises applications can only access Google APIs over the Cloud Interconnect and not through the public internet. You are required to only use APIs that are supported by VPC Service Controls to mitigate against exfiltration risk to non-supported APIs. How should you configure the network?"}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","provider":"Google","id":9,"isImplemented":true,"isMCOnly":false,"name":"Professional Cloud Security Engineer","numberOfQuestions":321},"currentPage":8},"__N_SSP":true}