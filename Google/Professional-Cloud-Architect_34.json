{"pageProps":{"questions":[{"id":"Eoz2v0KSS6xDOEfpABSL","answers_community":["B (89%)","11%"],"choices":{"B":"Use Google Cloud Directory Sync to synchronize Active Directory usernames with cloud identities and configure SAML SSO.","C":"Use Cloud Identity-Aware Proxy configured to use the on-premises Active Directory domain controller as an identity provider.","A":"Use the Admin Directory API to authenticate against the Active Directory domain controller.","D":"Use Compute Engine to create an Active Directory (AD) domain controller that is a replica of the on-premises AD domain controller using Google Cloud Directory Sync."},"exam_id":4,"question_id":166,"question_images":[],"timestamp":"2019-10-13 12:46:00","isMC":true,"answer_images":[],"answer_ET":"B","answer":"B","topic":"1","question_text":"Your company wants to start using Google Cloud resources but wants to retain their on-premises Active Directory domain controller for identity management.\nWhat should you do?","unix_timestamp":1570963560,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/6528-exam-professional-cloud-architect-topic-1-question-68/","discussion":[{"comments":[{"timestamp":"1630660020.0","upvote_count":"5","comments":[{"timestamp":"1634112420.0","poster":"Bill831231","comment_id":"461434","comments":[{"comment_id":"1314508","upvote_count":"2","timestamp":"1732003140.0","content":"if not, you will not be able to access resources on GCP with same accounts as onprem.","poster":"Ekramy_Elnaggar"},{"upvote_count":"4","comment_id":"685628","timestamp":"1664810580.0","poster":"BiddlyBdoyng","content":"\"...As a prerequisite for access to GCP resources, employees must have a Google identity set up...\""}],"upvote_count":"2","content":"thanks for the explanation, may I ask if we go with SAML, why need sync the useraccount? seems we just need set up the federation between cloud and on-premise"}],"poster":"MikeB19","content":"It’s simple. Domain controllers are not meant authenticate saas or web applications. This includes iam. Domain controllers speak ntlm and Kerberos. \nThis why we use federation. Because web apps do not speak Kerberos or ntlm. They speak languages such oauth. Hence the need for ad federation proxy\nB is correct","comment_id":"438430"},{"poster":"tartar","timestamp":"1596709320.0","content":"B is ok","comment_id":"151875","upvote_count":"9"},{"poster":"kumarp6","comment_id":"210514","upvote_count":"5","content":"B should be correct","timestamp":"1604240040.0"},{"timestamp":"1614901980.0","comment_id":"303713","poster":"nitinz","content":"B, use GCDS.","upvote_count":"5"},{"content":"agreed","poster":"AzureDP900","comment_id":"696403","timestamp":"1665939180.0","upvote_count":"1"}],"upvote_count":"44","comment_id":"14981","timestamp":"1570963560.0","content":"According to the reference, my understanding is B is correct.\nAnd in the document(https://cloud.google.com/iap/docs/concepts-overview), it says:\nIf you need to create Google Accounts for your existing users, you can use Google Cloud Directory Sync to synchronize with your Active Directory or LDAP server.\n\nIs it possible to explain why correct answer is C?","poster":"KouShikyou"},{"content":"B is the nearest answer I feel !","timestamp":"1571586060.0","upvote_count":"25","comment_id":"16261","poster":"MeasService"},{"timestamp":"1735526160.0","poster":"JonathanSJ","comment_id":"1333872","content":"Selected Answer: B\nI will go for B","upvote_count":"1"},{"upvote_count":"1","poster":"eff12c1","timestamp":"1717407300.0","comment_id":"1223513","content":"Selected Answer: B\nTo integrate Google Cloud with your on-premises Active Directory (AD) domain controller for identity management while retaining your on-premises AD, the best approach is:\n\nB. Use Google Cloud Directory Sync to synchronize Active Directory usernames with cloud identities and configure SAML SSO."},{"timestamp":"1715229960.0","comment_id":"1208693","upvote_count":"1","poster":"svkds","content":"Selected Answer: D\nThe most suitable option for integrating Google Cloud resources with an on-premises Active Directory domain controller for identity management is option D. This involves creating a replica of the on-premises Active Directory domain controller using Compute Engine and Google Cloud Directory Sync for synchronization."},{"comment_id":"896948","content":"B is correct https://cloud.google.com/architecture/identity/federating-gcp-with-active-directory-introduction","upvote_count":"2","poster":"LaxmanTiwari","timestamp":"1683999720.0"},{"poster":"vamgcp","timestamp":"1675155960.0","content":"Connect your on-premises Active Directory to Google Cloud: You can use Google Cloud Directory Sync (GCDS) to synchronize your on-premises Active Directory with Google Cloud. This allows you to use your existing Active Directory users and groups in Google Cloud.\n\nSet up single sign-on (SSO): You can use Google Cloud Identity-Aware Proxy (IAP) to set up SSO for your Google Cloud resources. IAP integrates with your on-premises Active Directory and allows users to log in to Google Cloud using their existing Active Directory credentials.","comment_id":"793881","upvote_count":"3"},{"poster":"omermahgoub","upvote_count":"8","comments":[{"content":"Option A, using the Admin Directory API to authenticate against the Active Directory domain controller, would not be a suitable solution because it would require implementing custom authentication logic in the application, which would be time-consuming and error-prone.\n\nOption C, using Cloud Identity-Aware Proxy configured to use the on-premises Active Directory domain controller as an identity provider, would be a suitable solution, but it would not allow you to synchronize Active Directory usernames with cloud identities.\n\nOption D, using Compute Engine to create an Active Directory (AD) domain controller that is a replica of the on-premises AD domain controller using Google Cloud Directory Sync, would not be a suitable solution because it would require setting up and maintaining an additional AD domain controller in Google Cloud, which would be unnecessary if the company wants to retain their on-premises AD domain controller as the primary source of identity management.","upvote_count":"3","poster":"omermahgoub","timestamp":"1671688980.0","comment_id":"752993"}],"content":"B. Use Google Cloud Directory Sync to synchronize Active Directory usernames with cloud identities and configure SAML SSO.\n\nTo retain their on-premises Active Directory domain controller for identity management while using Google Cloud resources, the company can use Google Cloud Directory Sync to synchronize Active Directory usernames with cloud identities and configure SAML single sign-on (SSO). This will allow users to use their existing Active Directory credentials to access Google Cloud resources, while still maintaining their on-premises Active Directory domain controller as the primary source of identity management.","timestamp":"1671688980.0","comment_id":"752992"},{"poster":"SureshbabuK","content":"Selected Answer: B\nGCDS and Cloud Identity is provided exactly for this use case","comment_id":"728703","upvote_count":"1","timestamp":"1669595820.0"},{"comment_id":"714725","upvote_count":"2","poster":"megumin","content":"Selected Answer: B\nB is ok","timestamp":"1668011280.0"},{"content":"Selected Answer: B\nB is correct https://cloud.google.com/architecture/identity/federating-gcp-with-active-directory-introduction","comment_id":"701848","timestamp":"1666488480.0","poster":"Mahmoud_E","upvote_count":"2"},{"comment_id":"627075","timestamp":"1656951480.0","poster":"cbarg","upvote_count":"1","content":"Selected Answer: B\nAnswer is B"},{"upvote_count":"1","content":"https://support.google.com/a/answer/106368?hl=en","poster":"SAMBIT","timestamp":"1647091080.0","comment_id":"566149"},{"poster":"haroldbenites","content":"Go for B.\nCloud Directory Sync\nhttps://cloud.google.com/blog/products/identity-security/using-your-existing-identity-management-system-with-google-cloud-platform","upvote_count":"4","comment_id":"495708","timestamp":"1638860880.0"},{"comment_id":"488362","timestamp":"1638035460.0","upvote_count":"1","poster":"vincy2202","content":"B is the correct answer"},{"poster":"pulkit0627","upvote_count":"1","comment_id":"483539","timestamp":"1637517600.0","content":"B as AD groups are directly mapped to Cloud Directory Sync"},{"poster":"MaxNRG","comment_id":"468787","content":"B – use Google Cloud Directory Sync to sync Active Directory user names with cloud identities and configure SAML SSO.\nCheck the flowchart here illustrating integration of your existing identity management system into GCP: https://cloud.google.com/blog/products/identity-security/using-your-existing-identity-management-system-with-google-cloud-platform\nC – does not work, since Cloud IAP serves different purpose. It s a building block toward BeyondCorp, an enterprise security model that enables every employee to work from untrusted networks without the use of a VPN.","upvote_count":"2","timestamp":"1635356700.0"},{"poster":"MamthaSJ","content":"Answer is B","upvote_count":"4","timestamp":"1625764500.0","comment_id":"402100"},{"content":"B. Use Google Cloud Directory Sync to synchronize Active Directory usernames with cloud identities and configure SAML SSO.","poster":"victory108","comment_id":"361295","timestamp":"1621422180.0","upvote_count":"3"},{"upvote_count":"2","content":"B or C ?\n\nThis link states that IAP supports integration with external identities\n\nhttps://cloud.google.com/iap/docs/external-identities\n\nSo in this case do we need Directory Synch? If not then C is the right answer.","poster":"skvi","comment_id":"341161","timestamp":"1619106660.0"},{"upvote_count":"2","timestamp":"1617255960.0","poster":"Ausias18","content":"Answer is B","comment_id":"325542"},{"content":"IMO - B is ok.","poster":"lynx256","comment_id":"321766","timestamp":"1616841780.0","upvote_count":"2"},{"comments":[{"timestamp":"1631262240.0","poster":"MikeB19","upvote_count":"2","comment_id":"442377","content":"C would require adfs to correct. The native dc alone would not be able to provide authentication for gcp resources"}],"upvote_count":"3","timestamp":"1616601000.0","content":"'C' is correct if it implies that the company doesn't want the list of users to be copied over. The company can still achieve to keep the identities on GCP and do the SAML with the option 'B'. The pain point in 'C' is the dependency on on-premises and it can cause single point of failure & latency. Again if the security is more concern then 'C' is correct.","poster":"AD3","comment_id":"319304"},{"upvote_count":"1","poster":"VenV","timestamp":"1615130340.0","comment_id":"305172","content":"B should be correct"},{"upvote_count":"1","timestamp":"1611883200.0","poster":"bnlcnd","content":"checked some online resources and seems B is cleaner.\nBut there is a way to use IAP and on-prem AD: https://cloud.google.com/iap/docs/cloud-iap-for-on-prem-apps-overview","comment_id":"278919"},{"poster":"Arimaverick","upvote_count":"1","timestamp":"1609979700.0","comment_id":"261379","content":"B is correct. Its funny that the correct answer to this question given is C but the documentation points to B. :)"},{"poster":"NeoFer","timestamp":"1609341300.0","comment_id":"255692","content":"B is correct. For those wondering why SAML is also needed : Synch will only synch user data not passwords. SAML will delegate the authentication part to on-prem AD.","upvote_count":"3"},{"timestamp":"1608907080.0","poster":"Prakzz","comment_id":"252126","content":"B is correct","upvote_count":"1"},{"timestamp":"1608415140.0","comment_id":"248212","poster":"Khaled_Rashwan","content":"B is the right answer\nhttps://cloud.google.com/iap/docs/concepts-overview#authentication\nNon google accounts should sync using Google Cloud Directory Sync","upvote_count":"1"},{"timestamp":"1607511540.0","content":"'B' is the right answer. \nhttps://cloud.google.com/solutions/policies/designing-gcp-policies-enterprise","comment_id":"239116","poster":"Viba","upvote_count":"2"},{"upvote_count":"1","content":"i m not sure but the key word is \" but wants to retain their on-premise\" that mean that not want to migrate their user data to cloud so using just a secure proxy service is Identity-Aware Proxy !!! may be B is also correct but that mean the data will be sync into cloud for me that's not match the requirement like a future architect i hope :)","timestamp":"1607184960.0","poster":"doumx","comment_id":"235864"},{"poster":"N1_arch","content":"Definitely B","upvote_count":"1","timestamp":"1603577940.0","comment_id":"205345"},{"poster":"awadheshk","content":"Reference Link mentioned with given ans support option B (GCDS) .. Seems ans is typo to C","upvote_count":"1","comment_id":"200473","timestamp":"1602764520.0"},{"upvote_count":"1","timestamp":"1600947300.0","content":"B is just right","poster":"asheesh0574","comment_id":"186119"},{"comment_id":"180139","timestamp":"1600223760.0","content":"B - SAML SSO\nhttps://cloud.google.com/blog/products/identity-security/using-your-existing-identity-management-system-with-google-cloud-platform","upvote_count":"1","poster":"AshokC"},{"content":"B is the recommended way as in GCP documentation : https://cloud.google.com/solutions/federating-gcp-with-active-directory-introduction","comment_id":"174453","upvote_count":"1","poster":"WannaBeCloudArch","timestamp":"1599385020.0"},{"poster":"wiqi","upvote_count":"1","comment_id":"162583","content":"B is correct","timestamp":"1597970520.0"},{"comment_id":"162068","content":"link says : To allow your users to authenticate using your identity management system when accessing the GCP console, you’ll have to implement SAML SSO, so make sure you have the right details to configure this later. hence answer is B.","timestamp":"1597910100.0","poster":"Krishna2401","upvote_count":"1"},{"content":"B is right. clearly there is a mistake here, as the link proposed talks about Directory Sync","timestamp":"1595338740.0","poster":"ohcan","upvote_count":"1","comment_id":"140344"},{"timestamp":"1594997340.0","comment_id":"137287","content":"The correct answer is B, even if u are going to use IAP and u need yo retain the same user and pwd for ur org Ad u will need active directory sync refer to authentication sec\nhttps://cloud.google.com/iap/docs/concepts-overview","poster":"elnagmy","upvote_count":"1"},{"upvote_count":"1","comment_id":"137278","timestamp":"1594996620.0","poster":"elnagmy","content":"in the console it mentioned that : Identity-Aware Proxy (IAP) lets you manage who has access to services hosted on App Engine, Compute Engine, or an HTTPS Load Balancer"},{"comment_id":"117674","content":"it is cloud sync 100% - B","poster":"motty","upvote_count":"1","timestamp":"1592931120.0"},{"upvote_count":"1","timestamp":"1592912160.0","comment_id":"117396","poster":"mlantonis","content":"I also believe B is the correct answer. Google Cloud Directory Sync"},{"upvote_count":"1","comment_id":"116015","content":"C is correct as from diagram you will see IDP connection which is client identuity proxy here.","timestamp":"1592798820.0","poster":"akhilesh_pundir"},{"comment_id":"116010","poster":"akhilesh_pundir","timestamp":"1592798340.0","upvote_count":"1","content":"It says they want to use their directory as Identity provider. In case of sync it creates a replica of your diorectory and keep it in sync with the actual one."},{"timestamp":"1591873260.0","poster":"Tushant","comment_id":"107636","content":"B is right answer","upvote_count":"1"},{"content":"agree with C Take a look at this link \nhttps://cloud.google.com/iap/docs/enabling-on-prem-howto","poster":"rbrto","timestamp":"1591491360.0","comment_id":"104221","comments":[{"upvote_count":"2","content":"https://cloud.google.com/iap/docs/cloud-iap-for-on-prem-apps-overview\n\n\"Identity-Aware Proxy (IAP) allows you to manage access to HTTP-based apps outside of Google Cloud. This includes apps on-premises in your enterprise's data centers.\"\n\naccording to this IAP is to manage http access for apps .. here they want to mange the cloud","comment_id":"107375","timestamp":"1591845120.0","poster":"Sundeepk"}],"upvote_count":"1"},{"content":"B is the correct answer","timestamp":"1591275900.0","poster":"Ziegler","upvote_count":"1","comment_id":"102387"},{"content":"GCDS is the best option and recommended by Google too","poster":"Sundeepk","comment_id":"101191","timestamp":"1591132620.0","upvote_count":"1"},{"timestamp":"1591123560.0","poster":"Nirms","comment_id":"101105","content":"B is the correct answer","upvote_count":"1"},{"poster":"jayaen","comments":[{"poster":"jayaen","content":"after i went through GCP docs on cloud identity aware proxy , it seems it is not possible to add on premise AD as one of identity provider.\nso the option B should be right choice","upvote_count":"2","timestamp":"1591073220.0","comment_id":"100526"},{"upvote_count":"1","timestamp":"1615130280.0","poster":"VenV","comment_id":"305171","content":"When u configure same, then authentication is still with AD"}],"comment_id":"100523","content":"Authentication should be manged in on premise side as indicated in the question \"retains AD\". B cannot be correct since this solution will move authentication to cloud identify after sync is done. \nusing identity aware proxy various identity providers can be added and should possible to add on premise ad authentication as one of identity provider.\nC should be correct answer","upvote_count":"2","timestamp":"1591072260.0"},{"poster":"AD2AD4","upvote_count":"2","comment_id":"97450","content":"Final Decision to go with Option B","timestamp":"1590663420.0"},{"content":"B is the answer","poster":"gcp_aws","upvote_count":"1","timestamp":"1590356160.0","comment_id":"95105"},{"upvote_count":"1","content":"B is the right answer","poster":"laksg","timestamp":"1589682900.0","comment_id":"90286"},{"upvote_count":"1","comment_id":"89407","timestamp":"1589535780.0","content":"B is the best option to use existing identity management while allowing access to GCP resouorces","poster":"GunjGupta"},{"comment_id":"83807","content":"Answer: B","upvote_count":"1","timestamp":"1588623480.0","poster":"Zarmi"},{"upvote_count":"2","timestamp":"1585948200.0","comment_id":"70853","content":"B is the correct answer. GCDS works with most of the LDAP server. Here is the AD.\nhttps://cloud.google.com/blog/products/identity-security/using-your-existing-identity-management-system-with-google-cloud-platform","poster":"anton_royce"},{"comment_id":"56422","content":"Selected B in the exam","poster":"[Removed]","upvote_count":"2","timestamp":"1582878900.0"},{"timestamp":"1581496440.0","comment_id":"49421","content":"B is correct.\nhttps://cloud.google.com/solutions/federating-gcp-with-active-directory-introduction.\nYou need to enable Cloud Platform to recognize your users, using one of two recommended methods: Google Cloud directory sync (shown on the left below), or third-party identity provider connectors to Cloud Identity (shown on the right below).","upvote_count":"1","poster":"evanadarsh"},{"poster":"VinMoc","comment_id":"47180","upvote_count":"1","content":"Also Cloud IAP use Google Active Directory Sync for synchronizing. Ans is B","timestamp":"1580963640.0"},{"poster":"2g","upvote_count":"1","timestamp":"1580394960.0","content":"Answer: B","comment_id":"44817"},{"timestamp":"1580050740.0","content":"I'm for B, but i don't understand why says \"and configure SAML SSO\"; this is not necessary","upvote_count":"1","poster":"natpilot","comment_id":"42927"},{"poster":"sri007","comment_id":"40439","timestamp":"1579375080.0","content":"B is correct","upvote_count":"1"},{"timestamp":"1578835980.0","poster":"AWS56","upvote_count":"1","comment_id":"38084","content":"Agree B"},{"comment_id":"30594","upvote_count":"2","content":"just to be clear, Cloud Identity-Aware Proxy (Cloud IAP) controls access to your cloud applications and VMs running on Google Cloud Platform (GCP).B is a better answer than C","timestamp":"1576667520.0","poster":"passnow"},{"upvote_count":"7","content":"I believe B is the correct answer because With Google Cloud Directory Sync (GCDS), you can synchronize the data in your Google domain with your Microsoft® Active Directory® or LDAP server. Your Google users, groups, and shared contacts are synchronized to match the information in your LDAP server. \n\nThe data in your LDAP directory server is never modified or compromised. GCDS is a secure tool that helps you easily keep track of users and groups.\n\nGCDS used to be known as Google Apps Directory Sync (GADS).","timestamp":"1576667400.0","poster":"passnow","comment_id":"30593"}]},{"id":"KldZrldEnCA6dUQSViCU","exam_id":4,"unix_timestamp":1571666700,"url":"https://www.examtopics.com/discussions/google/view/6892-exam-professional-cloud-architect-topic-1-question-69/","topic":"1","discussion":[{"upvote_count":"34","content":"think answer is B. C cannot be, you don't need to connect to the container to view logs, you connect to stackdriver for this","poster":"jcmoranp","timestamp":"1603289100.0","comment_id":"16441","comments":[{"timestamp":"1603543260.0","poster":"crypt0","content":"Stackdriver Logging seems to be enabled by default for GKE.\n\nLooking here:\nhttps://cloud.google.com/monitoring/kubernetes-engine/legacy-stackdriver/logging\nFor container and system logs, GKE deploys a per-node logging agent that reads container logs, adds helpful metadata, and then stores them. The logging agent checks for container logs in the following sources:\n\nStandard output and standard error logs from containerized processes\n\nI would also go with B","comment_id":"17179","upvote_count":"12","comments":[{"poster":"AzureDP900","comment_id":"696402","timestamp":"1697475120.0","content":"agreed with B","upvote_count":"1"}]},{"upvote_count":"6","poster":"nitinz","content":"B, google wants you to use stackdriver.","comment_id":"303717","timestamp":"1646438160.0"},{"content":"Yes it is B","timestamp":"1635776160.0","upvote_count":"3","poster":"kumarp6","comment_id":"210516"},{"timestamp":"1603376940.0","poster":"crypt0","comment_id":"16733","comments":[{"content":"Please forget this comment ^\nAnswer B should be correct.","comment_id":"17181","upvote_count":"8","timestamp":"1603543320.0","poster":"crypt0"},{"timestamp":"1628245620.0","comment_id":"151879","content":"B is ok","poster":"tartar","upvote_count":"7"},{"comment_id":"89631","poster":"Jack_in_Large","upvote_count":"1","timestamp":"1621107300.0","content":"Yes for GKE"}],"content":"Is Stackdriver enabled by default?\nStackdriver Logging is independent and first needs to enable with GKE I guess?","upvote_count":"1"}]},{"poster":"JoeShmoe","timestamp":"1605369060.0","content":"B is correct. Serial console doesnt give you StdOut","upvote_count":"9","comment_id":"21569"},{"timestamp":"1728180240.0","comment_id":"1026144","poster":"AdityaGupta","upvote_count":"2","content":"B. Review the Stackdriver logs for the specific GKE container that is serving the unresponsive part of the application.\n\nGKE be default integrats with Google Operation Suit (Stackdriver) and you can filter the logs for more specific part of application i.e container to view logs. Also it is most efficient way of investigation."},{"content":"Selected Answer: B\nB is the simples option and more effective","timestamp":"1723728240.0","comment_id":"981704","upvote_count":"1","poster":"jalberto"},{"upvote_count":"1","poster":"MestreCholas","comment_id":"833449","content":"Selected Answer: B\nB. Review the Stackdriver logs for the specific GKE container that is serving the unresponsive part of the application.\n\nSince the application writes logs to standard output, the logs should be available in the Stackdriver logs for the container running the unresponsive part of the application. Kubernetes Engine automatically exports these logs to Stackdriver, so you can use the Stackdriver Logging console to view the logs. Option A is not the best choice because reviewing the logs for each Compute Engine instance would be time-consuming and may not provide the necessary information. Option C may work, but it involves extra steps and may not be necessary if the logs are available in Stackdriver. Option D is not relevant in this case because Serial Port logs are not likely to provide useful information for troubleshooting an unresponsive web application.","timestamp":"1709940900.0"},{"content":"C. Connect to the cluster using gcloud credentials and connect to a container in one of the pods to read the logs.\n\nTo inspect the logs of a Kubernetes Engine (GKE) cluster to find the cause of an issue, you can connect to the cluster using gcloud credentials and connect to a container in one of the pods to read the logs. This will allow you to access the logs of the application as it is running in the cluster, which should help you identify the cause of the issue.","comment_id":"752996","upvote_count":"2","comments":[{"upvote_count":"3","poster":"omermahgoub","timestamp":"1703225340.0","content":"Option A, reviewing the Stackdriver logs for each Compute Engine instance that is serving as a node in the cluster, would not be suitable because the application writes logs to standard output, not to Stackdriver.\n\nOption B, reviewing the Stackdriver logs for the specific GKE container that is serving the unresponsive part of the application, would not be suitable because the application writes logs to standard output, not to Stackdriver.\n\nOption D, reviewing the Serial Port logs for each Compute Engine instance that is serving as a node in the cluster, would not be suitable because the application writes logs to standard output, not to the Serial Port.","comment_id":"752997"}],"poster":"omermahgoub","timestamp":"1703225340.0"},{"timestamp":"1701224640.0","upvote_count":"1","content":"Selected Answer: B\nThis should be easy, the answer is B. \nJust eliminate the wrong answers (A) is not correct because the question is about GKE and not CE.\nC and D are totally lost","poster":"jaxclain","comment_id":"729859"},{"timestamp":"1701168900.0","content":"Selected Answer: B\nA, C, D all sounds unfeasible (credentials, and compute engine)","upvote_count":"1","poster":"habros","comment_id":"728987"},{"content":"Selected Answer: B\nB is ok","poster":"megumin","comment_id":"714734","timestamp":"1699547760.0","upvote_count":"1"},{"content":"Selected Answer: B\nis correct answer","upvote_count":"1","comment_id":"701852","timestamp":"1698025200.0","poster":"Mahmoud_E"},{"content":"Selected Answer: B\ncorrect","upvote_count":"1","timestamp":"1685544780.0","comment_id":"609780","poster":"Superr"},{"content":"B is correct ans.I agree.\nhttps://cloud.google.com/blog/ja/products/management-tools/finding-your-gke-logs","comment_id":"516329","upvote_count":"2","poster":"OrangeTiger","timestamp":"1672819260.0"},{"poster":"haroldbenites","content":"Go for B","upvote_count":"1","timestamp":"1670397180.0","comment_id":"495711"},{"content":"B is the correct answer","comment_id":"488365","poster":"vincy2202","timestamp":"1669571580.0","upvote_count":"1"},{"upvote_count":"3","content":"B – Review Stackdriver logs for specific GKE container that is serving the unresponsive part of the app.\nThis is a most directly matching answer for this Q, since it reviews GKE container logs, by that advertising this Stackdriver feature.\n“For container and system logs, GKE deploys a per-node logging agent that reads container logs, adds helpful metadata, and then stores them. The logging agent checks for container logs in the following sources:\n• Standard output and standard error logs from containerized processes\n• kubelet and container runtime logs\n• Logs for system components, such as VM startup scripts”\nOriginally we thought, that D is a right answer, since were confused with 2 seconds restart. But, that’s restart for Pod, not for Node (GCE)\nD – Review Serial Port logs for each Compute Engince instance, that is serving as the in the cluster.\nSerial Port output is standard feature of Compute Engine (which retains 1 MB most recent logs for analysis). But, it is irrelevant for Pod’s restart, caused by malfunction of some container.","timestamp":"1666892880.0","comment_id":"468788","poster":"MaxNRG"},{"upvote_count":"3","comment_id":"402101","poster":"MamthaSJ","content":"Answer is B","timestamp":"1657300560.0"},{"comment_id":"400923","timestamp":"1657199700.0","upvote_count":"2","poster":"lovingsmart2000","content":"B is right answer. There is a catch here - Legacy logging of GKE with Stackdriver has deprecated. If this is used, you need to migrate to Cloud Operations for GKE, a new enhanced offering by Google with same functionality. \nFuture questions will have the answer choices with new tool \"Cloud Operations for GKE\" instead of Stackdriver.\nhttps://cloud.google.com/monitoring/kubernetes-engine/legacy-stackdriver/logging"},{"content":"B is right answer. There is a catch here - Legacy logging of GKE with Stackdriver has deprecated. If this used, you need to migrate to Cloud Operations for GKE, a new enhanced offering by Google with same functionality. \nFuture questions will have the answer choices with new tool \"Cloud Operations for GKE\" instead of Stackdriver.","timestamp":"1657199520.0","comment_id":"400918","upvote_count":"2","poster":"lovingsmart2000"},{"timestamp":"1654770840.0","comment_id":"378181","upvote_count":"1","poster":"areza","content":"B is ok"},{"timestamp":"1652958180.0","content":"B. Review the Stackdriver logs for the specific GKE container that is serving the unresponsive part of the application.","poster":"victory108","comment_id":"361294","upvote_count":"2"},{"comment_id":"337443","upvote_count":"1","timestamp":"1650185820.0","poster":"Kiroo","content":"If the container keeps restarting connect to container to check the logs is stupid, the only one that makes sense is B"},{"comment_id":"325543","upvote_count":"1","content":"Answer is B","poster":"Ausias18","timestamp":"1648792020.0"},{"upvote_count":"1","poster":"lynx256","comment_id":"321753","content":"IMO - B is ok.","timestamp":"1648368900.0"},{"content":"B should be correct","timestamp":"1646666640.0","comment_id":"305173","upvote_count":"1","poster":"VenV"},{"upvote_count":"2","comment_id":"299137","poster":"Alekshar","content":"C cannot be correct, having your pods restarting each 2 seconds implies your logs in GKE are deleted each 2 seconds, not ideal for debugging.","timestamp":"1645800840.0"},{"upvote_count":"3","comment_id":"252127","timestamp":"1640443260.0","poster":"Prakzz","content":"How can you see the logs for the specific container when all pods keep restarting after 2 seconds?\nI think is A you can see the logs for the compute engine instance that is working like node"},{"content":"Not C\n\"all pods of your deployment keep restarting after 2 seconds\"\nHow are you going to connect to your container if the pods keep restarting at this frequency. What are you going to accomplish in 2 sec !!\n\nWhy not A?\n\nB seems ok, but again, if the pods keep restarting what could you see in the containers logs they might not even started yet!!\n\nI would go with A.","poster":"ybe_gcp_cert","comment_id":"237416","timestamp":"1638889260.0","upvote_count":"6"},{"poster":"doumx","content":"B every day i trooblshooting dev pb with this way","comment_id":"235874","timestamp":"1638721740.0","upvote_count":"1"},{"poster":"Chulbul_Pandey","comment_id":"232776","upvote_count":"1","content":"agree with B","timestamp":"1638435180.0"},{"content":"How can you see the logs for the specific container when all pods keep restarting after 2 seconds?\nI think is A you can see the logs for the compute engine instance that is working like node","timestamp":"1635812520.0","comment_id":"210876","poster":"francisco_guerra","upvote_count":"6"},{"comment_id":"196623","poster":"LoganIsh","content":"as per udemy practice exam answer was C it makes sense too..","timestamp":"1633771680.0","upvote_count":"1"},{"timestamp":"1631760120.0","poster":"AshokC","comment_id":"180140","content":"Answer B","upvote_count":"1"},{"poster":"age","timestamp":"1631321460.0","comment_id":"177390","upvote_count":"1","content":"C because you want to \"inspect the logs from the application\""},{"upvote_count":"1","comment_id":"168762","poster":"Kabiliravi","timestamp":"1630184700.0","content":"B is the right one"},{"poster":"wiqi","comment_id":"162584","content":"B is the one.","upvote_count":"1","timestamp":"1629506580.0"},{"upvote_count":"1","comment_id":"161911","poster":"garora","content":"B is the right answer. GKE logs on stdout and stderr are configured to be thrown on Stackdriver itself. No extra configurations needed.","timestamp":"1629424860.0"},{"upvote_count":"2","comment_id":"161909","timestamp":"1629424800.0","poster":"garora","content":"B is the right answer. GKE logs on stdout and stderr are configured to be thrown on Stackdriver itself. No extra configurations needed."},{"timestamp":"1626650040.0","content":"C is correct. its say it is writing logs to standard output.","comment_id":"138191","upvote_count":"1","poster":"TusharPinjan"},{"comment_id":"118032","poster":"kaush","timestamp":"1624506780.0","upvote_count":"3","content":"Answer is B As Google Kubernetes Engine (GKE) includes native integration with Cloud Monitoring and Cloud Logging. When you create a GKE cluster, Kubernetes Engine Operations is enabled by default and provides a monitoring dashboard specifically tailored for Kubernetes."},{"content":"Stackdriver is the right way to troubleshoot GKE. Period. It is B","timestamp":"1624467240.0","comment_id":"117675","upvote_count":"2","poster":"motty"},{"content":"No need to connect into the cluster. Just check Stackdriver for GKE.\n\nB is the correct answer","timestamp":"1624448280.0","comment_id":"117400","upvote_count":"2","poster":"mlantonis"},{"upvote_count":"1","content":"C is correct.\nhttps://kubernetes.io/docs/concepts/cluster-administration/logging/","timestamp":"1624335840.0","comment_id":"116020","poster":"akhilesh_pundir"},{"content":"B is the correct answer","poster":"Tushant","upvote_count":"2","comment_id":"114660","timestamp":"1624182180.0"},{"content":"Correct Answer: C\nConnect to the cluster using gcloud credentials and connect to a container in one of the pods to read the logs. \nLegacy Logging and Monitoring support for Google Kubernetes Engine is deprecated. If you are using Legacy Logging and Monitoring, then you must migrate to Kubernetes Engine Operations \nCloud Logging automatically collects standard output and error logs for containerized processes \nWhere to find your logs\n1.Cloud Logging console\n2.GKE console\n3.Monitoring console \n4.gcloud command line tool -Using the gcloud logging read command, select the appropriate cluster, node, pod and container logs","comment_id":"110785","upvote_count":"1","timestamp":"1623758940.0","poster":"shashu07","comments":[{"poster":"VivekMishraV","comment_id":"323415","timestamp":"1648556400.0","upvote_count":"1","content":"Pods are ephemeral and getting deleted or re-created in 2 seconds only. How anyone can login to container in 2 secs and checks logs. \nIts B use stackdriver"},{"timestamp":"1623867840.0","content":"\"Google Kubernetes Engine (GKE) includes native integration with Cloud Monitoring and Cloud Logging.\" which makes sense. Cloud Logging is Stackdriver.","upvote_count":"1","comment_id":"111808","poster":"nhunt"}]},{"upvote_count":"1","content":"B, for sure.\nReview the Stackdriver logs for the specific GKE container that is serving the unresponsive part of the application.","poster":"gfhbox0083","timestamp":"1623479220.0","comment_id":"108426"},{"timestamp":"1623428640.0","content":"Correct answer is B","upvote_count":"1","comment_id":"107922","poster":"Tushant"},{"timestamp":"1622867940.0","comment_id":"102892","content":"B is the right!","poster":"woorkim","upvote_count":"1"},{"upvote_count":"1","timestamp":"1622812020.0","content":"B is the correct answer","poster":"Ziegler","comment_id":"102388"},{"timestamp":"1622659680.0","poster":"Nirms","comment_id":"101107","content":"B is the correct answer","upvote_count":"1"},{"poster":"AD2AD4","comment_id":"97452","upvote_count":"1","timestamp":"1622199480.0","content":"Final Decision to go with Option B"},{"poster":"gcp_aws","upvote_count":"1","comment_id":"95526","timestamp":"1621961520.0","content":"B is the answer"},{"comment_id":"83809","upvote_count":"1","timestamp":"1620159660.0","poster":"Zarmi","content":"Answer: B"},{"comment_id":"75104","poster":"toyochik","content":"The answer is B. It can't be C because you are not able to see previous logs of the pod by ```kubectl logs po podname``` when it restarted.","comments":[{"poster":"Rothmansua","content":"In fact, since pretty early K8s version you can do that with -p command line switch.","upvote_count":"1","comment_id":"278823","timestamp":"1643403600.0"}],"timestamp":"1618530840.0","upvote_count":"2"},{"timestamp":"1614501360.0","poster":"[Removed]","comment_id":"56423","upvote_count":"2","content":"Selected B in the exam"},{"poster":"ADVIT","upvote_count":"1","content":"It's B","timestamp":"1613242680.0","comment_id":"50168"},{"comment_id":"44819","content":"Answer: B","timestamp":"1612017420.0","poster":"2g","upvote_count":"2"},{"timestamp":"1611673260.0","comment_id":"42929","upvote_count":"2","content":"B is good","poster":"natpilot"},{"poster":"TosO","timestamp":"1606142280.0","upvote_count":"6","content":"B is the correct answer because, in the two seconds you have, you need to find the pod name and enter the command to display the logs. That is almost impossible.","comment_id":"23865"},{"upvote_count":"4","poster":"Eroc","content":"https://cloud.google.com/run/docs/logging","timestamp":"1604083680.0","comment_id":"18419"},{"comment_id":"16859","timestamp":"1603430460.0","comments":[{"content":"Please forget my comment. B looks correct. Thanks.","comment_id":"17304","timestamp":"1603600080.0","upvote_count":"3","poster":"KouShikyou"}],"content":"I feel C is correct. Because the application writes logs to standard output. I guess you need to login to the pod to check the log.","poster":"KouShikyou","upvote_count":"3"}],"choices":{"A":"Review the Stackdriver logs for each Compute Engine instance that is serving as a node in the cluster.","D":"Review the Serial Port logs for each Compute Engine instance that is serving as a node in the cluster.","C":"Connect to the cluster using gcloud credentials and connect to a container in one of the pods to read the logs.","B":"Review the Stackdriver logs for the specific GKE container that is serving the unresponsive part of the application."},"answer_description":"","question_id":167,"answer_images":[],"answer":"B","isMC":true,"question_images":[],"answer_ET":"B","question_text":"You are running a cluster on Kubernetes Engine (GKE) to serve a web application. Users are reporting that a specific part of the application is not responding anymore. You notice that all pods of your deployment keep restarting after 2 seconds. The application writes logs to standard output. You want to inspect the logs to find the cause of the issue. Which approach can you take?","answers_community":["B (100%)"],"timestamp":"2019-10-21 16:05:00"},{"id":"yQBzhDGUQXLUPC36642d","question_images":[],"question_id":168,"discussion":[{"poster":"[Removed]","comment_id":"454965","comments":[{"upvote_count":"4","content":"(A) is not sense because the flag is to preserve disk when the istances was deleted, when the istances was stopped the data on persistend disk are not deleted. So good to know that the response was reworked\n(B) is wrong because only on AWS you can terminate istances. On GCP the \"terminate\" action do not exist .","comment_id":"645530","poster":"[Removed]","timestamp":"1660232460.0"}],"timestamp":"1726852440.0","upvote_count":"74","content":"I spent all morning researching this question. I just popped over and took the GCP Practice exam on Google's website and guess what... this question was on it word for word, but it had slightly different answers, but not by much here is what I learned. The correct answer is 100% A / D and here is why. On the sample question, the \"F\" option is gone. \"A\" is there but slightly reworked, it now says: \"Use persistent disks to store the state. Start and stop the VM as needed\" which makes much more sense. The practice exam says A and D are correct. Given the wording of this question, if A and B, where there then both would be correct because of the word \"persistent\" and not because of the flag. The \"no-auto-delete\" makes A slightly safer than B, but it is the \"persistent disk\" that makes them right, not the flag. Hope that helps! F is not right because that is a complex way of solving the issue that by choosing Persistent Disk solves it up front. HTH"},{"comment_id":"373393","poster":"rishab86","content":"A and D looks correct as per https://cloud.google.com/sdk/gcloud/reference/compute/instances/set-disk-auto-delete#--auto-delete ;\nhttps://cloud.google.com/billing/docs/how-to/export-data-bigquery","timestamp":"1622708940.0","comments":[{"upvote_count":"3","timestamp":"1625881140.0","poster":"RKS_2021","content":"-no-auto-delete flag does not have effect on the state of the application. I believe D and F are correct ANS, https://cloud.google.com/compute/docs/instances/stop-start-instance","comment_id":"403041"}],"upvote_count":"22"},{"content":"Selected Answer: DF\nA / B : the option only apply when VM are deleted (terminated ?), or here we are talking about stop/start\nSee https://cloud.google.com/compute/docs/samples/compute-disk-autodelete-change\nC : Do even know if it is possible\nD : In order to bring \"visibility on the cost\"\nE : local disks does not persist \nF : complex solution, but it works\nSo D & F","upvote_count":"1","poster":"hpf97","comment_id":"1347885","timestamp":"1738066200.0"},{"upvote_count":"3","timestamp":"1731266280.0","content":"Selected Answer: AD\nAnswer is : A& D\n\nA. Use the --no-auto-delete flag on all persistent disks and stop the VM:\n1. Cost Savings: When you stop a VM, you only pay for the persistent disks attached to it. The --no-auto-delete flag ensures that the disks remain available even when the VM is stopped, preserving the developers' work and avoiding the cost of recreating the environment from scratch each time.\n2. State Persistence: This approach ensures that the development environment's state is saved on the persistent disk, allowing developers to resume their work seamlessly when they restart the VM.\n\nD. Use Google BigQuery billing export and labels to associate cost to groups:\n1. Cost Visibility: BigQuery billing export allows you to analyze your Google Cloud costs in detail. By applying labels to your resources (e.g., \"environment: development\", \"team: frontend\"), you can categorize and track costs associated with different development groups.","poster":"Ekramy_Elnaggar","comment_id":"1309590"},{"timestamp":"1723094160.0","upvote_count":"1","comment_id":"1262311","content":"Choose A and D","poster":"Hungdv"},{"comment_id":"1228553","content":"Another confusing question because I took the \"these machines go through multiple stop/starts during the day\" as a part of the migration, not as a part of daily functionality, so none of the answers other than D made much sense to me. People need to word the questions better on tests and give more than enough context or people like me are going to get confused, second guess our answers, and fail.","timestamp":"1718126220.0","poster":"Sephethus","upvote_count":"1"},{"comment_id":"1209516","poster":"afsarkhan","content":"Selected Answer: AD\nF is too complex solution to solve this problem.\nE local SSD does not persist on termination of vm so this is also a wrong option\nA, B suggest persistent disk but I think A makes better sense.\n\nSo my answer is A and D","upvote_count":"1","timestamp":"1715370540.0"},{"upvote_count":"1","content":"E wrong:\nScenarios where Compute Engine does not persist Local SSD data\n\nData on Local SSD disks does not persist through the following events:\n\nIf you shut down the guest operating system and force the VM to stop.","timestamp":"1713688020.0","poster":"44eacc1","comment_id":"1199543"},{"content":"Hi all, i am trying to view questions from 135.But i cannot access the page as it is asking for contributer access.Is it same for everyone?","comment_id":"1177920","timestamp":"1710910500.0","poster":"shikha344","upvote_count":"1"},{"poster":"d0094d6","timestamp":"1706863080.0","upvote_count":"2","comment_id":"1138315","content":"Selected Answer: A\nFrom the GCP Practice exam... A and D"},{"content":"Based on documentation A is correct https://cloud.google.com/sdk/gcloud/reference/compute/instances/set-disk-auto-delete\nAlso the documentation clearly states that this flag will be help retain the state when VM is started/stopped.\nhttps://cloud.google.com/blog/products/storage-data-transfer/save-money-by-stopping-and-starting-compute-engine-instances-on-schedule\nFor cost visibility option D is correct.","poster":"Teckexam","timestamp":"1705769640.0","upvote_count":"1","comment_id":"1127404"},{"poster":"hzaoui","content":"Selected Answer: DE\nD. Use Google BigQuery billing export and labels to associate cost to groups: This offers granular cost visibility across various development teams or projects through BigQuery data analysis. Combining labels with billing export allows you to associate resource consumption with specific groups, enabling chargeback mechanisms and fostering cost accountability.\nE. Store all state into local SSD, snapshot the persistent disks, and terminate the VM: This option minimizes ongoing cost by utilizing low-cost local SSD for active state during runtime and terminating the VM when development isn't ongoing. Snapshots offer quick restoration back to the latest state without incurring persistent disk charges during downtime.","timestamp":"1704962400.0","upvote_count":"1","comment_id":"1119512"},{"upvote_count":"2","timestamp":"1704041880.0","poster":"kshlgpt","comment_id":"1110712","content":"DF. This is the question in google practice test."},{"comment_id":"1104007","content":"Selected Answer: DF\nD & F for me","upvote_count":"2","poster":"cfigueiredo","timestamp":"1703333760.0"},{"poster":"Prakzz","comment_id":"1028421","upvote_count":"1","timestamp":"1696818960.0","comments":[{"content":"This means you can export the billing to the BQ and then do analysis.","poster":"ArtistS","comment_id":"1069247","timestamp":"1699875120.0","upvote_count":"1"}],"content":"How can D ever be right coz it's Bigquery Billing Export and question is about VM billing"},{"timestamp":"1696390380.0","upvote_count":"4","content":"Selected Answer: AD\nA is correct, Use of persistent disk mean the data is preserved even after restart. -np-auto-delete on persistent disk means pesistent disk won't be deleted when VM is deleted.\n\nD is correct, becuase second part of question asks for billing report to finanace department and Label and BQ helps in cost analysis.","comment_id":"1024394","poster":"AdityaGupta"},{"timestamp":"1691373420.0","content":"Selected Answer: BD\nB and D. A is wrong because, (--no-auto-delete) would lead to extra storage costs for the disks even when VMs are not running.","upvote_count":"1","poster":"lucaluca1982","comment_id":"974333"},{"comment_id":"852875","timestamp":"1679986020.0","poster":"JC0926","content":"same question, official option:\nA. Use persistent disks to store the state. Start and stop the VM as needed.\nB. Use the \"gcloud --auto-delete\" flag on all persistent disks before stopping the VM.\nC. Apply VM CPU utilization label and include it in the BigQuery billing export.\nD. Use BigQuery billing export and labels to relate cost to groups.\nE. Store all state in a Local SSD, snapshot the persistent disks, and terminate the VM.\n\nThis question will not be tested, no need to read","upvote_count":"3"},{"poster":"telp","content":"Selected Answer: AD\nAD \nUse the flag -no-auto-delete with this flag, the disk won't be delete when the VM is terminated.\n\nBilling export to BigQuery enables you to export your daily usage and cost estimates automatically throughout the day to a BigQuery dataset you specify. You can then access your billing data from BigQuery.","upvote_count":"3","comment_id":"849093","timestamp":"1679643900.0"},{"poster":"JC0926","content":"Selected Answer: DF\nDF corerct","timestamp":"1678438440.0","comment_id":"834788","upvote_count":"1"},{"comment_id":"802879","timestamp":"1675923180.0","content":"I will go with A & D .F option is not chosen because it is mentioned already that state is stored in google cloud storage why then we will be taking snapshot first of all.Also, if we do,that would mean huge performance loss . It is not recommended to take snapshots in working hours ,also recreation of disks from snapshots take time so its just not efficient.All other options are easily eliminated as being dicussed by multiple persons in this forum.","poster":"curious_aj","upvote_count":"1"},{"content":"A & D for me","comment_id":"762552","upvote_count":"1","poster":"AShrujit","timestamp":"1672474740.0"},{"comment_id":"755411","content":"Selected Answer: AD\nI agree with A,D which is right choice to cost control","timestamp":"1671945600.0","poster":"Jaldhi24","upvote_count":"2"},{"timestamp":"1671254940.0","comment_id":"747780","content":"D. Use Google BigQuery billing export and labels to associate cost to groups\nF. Store all state in Google Cloud Storage, snapshot the persistent disks, and terminate the VM\n\nTo provide cost visibility to the finance department, you can use Google BigQuery billing export and labels to associate cost to groups. This will allow you to track the cost of running the development environment in Google Cloud and understand how it is being used by different teams or projects.\n\nStoring all state in Google Cloud Storage and snapshotting the persistent disks will allow you to persist the state of the development environment while also being able to stop and start the VM as needed. When you are finished with the VM, you can terminate it to avoid incurring additional costs. This will also allow you to easily restore the environment to a previous state if needed.","poster":"i_am_robot","upvote_count":"2"},{"timestamp":"1666451100.0","comment_id":"701595","comments":[{"comment_id":"805853","timestamp":"1676166120.0","content":"I agree with you on option D:, the other option is A: if you read correctly it says \"Use the - -no-auto-delete flag\" which means that delete is disabled.","upvote_count":"2","poster":"romandrigo"}],"content":"Selected Answer: DF\nA - No, because instances are being stopped, not deleted: \"When auto-delete is on, the persistent disk is deleted when the instance it is attached to is deleted.\" https://cloud.google.com/sdk/gcloud/reference/compute/instances/set-disk-auto-delete\nB - No, because instances are being stopped, not deleted: \"When auto-delete is on, the persistent disk is deleted when the instance it is attached to is deleted.\"\nhttps://cloud.google.com/sdk/gcloud/reference/compute/instances/set-disk-auto-delete\nC - No, not only concerned with CPU utilization\nD - Yes, https://cloud.google.com/billing/docs/how-to/bq-examples\nE - No. Storing state to SSD then terminating instance, as E mentions, nukes the SSD https://cloud.google.com/compute/docs/disks/local-ssd#data_persistence\nF - Allows state to persist","poster":"BobLoblawsLawBlog","upvote_count":"5"},{"content":"stopping a VM does not delete the persistent disk, the disk is attached to the VM. The only way to remove the disk is by deleting the VM where you do not specify to preserve the disk","poster":"zr79","comment_id":"696738","upvote_count":"1","timestamp":"1665972900.0"},{"content":"I agree with A,D which is right choice to cost control","timestamp":"1665950040.0","comment_id":"696494","upvote_count":"1","comments":[{"upvote_count":"1","comment_id":"934707","poster":"Rothmansua","timestamp":"1687802940.0","content":"The question doesn't ask about VM deletion. How A is correct?"}],"poster":"AzureDP900"},{"comment_id":"693112","content":"Selected Answer: AD\nA is a better answer as the no-auto-delete flag on the persistent disk will add an extra layer of security in case the VM gets deleted. B is not correct in many different ways. \nC is not relevant\nD is correct for the costs\nE and F are not relevant","upvote_count":"3","timestamp":"1665580620.0","poster":"minmin2020"},{"content":"Selected Answer: AD\nA is correct because persistent disks will not be deleted when an instance is stopped.\nD is correct because exporting daily usage and cost estimates automatically throughout the day to a BigQuery dataset is a good way of providing visibility to the finance department. Labels can then be used to group the costs based on team or cost center.","upvote_count":"5","comment_id":"633739","timestamp":"1658262120.0","poster":"enzonil70"},{"content":"AD - It states in the question \"These resources go through multiple start/stop events during the day and require state to persist.\" The most efficient way is to stop the instance and not deleting the persistent disk. Deleting the instance in F makes no sense and not sure you can fully recover from the snapshot. With A, the disk is preserved with all its data, no recovery needed and you simply just start up the instance. F Makes no sense at all to me unless someone can explain something I may be missing/overlooking.","comment_id":"633124","poster":"Ric350","upvote_count":"1","timestamp":"1658168940.0"},{"timestamp":"1652403000.0","poster":"ashii007","content":"Since VMs start and stop multiple tmes throughout the day, deleting VM is not optimal. Thats another reason to rule out F.","comment_id":"600899","upvote_count":"2"},{"content":"Selected Answer: DF\nexplained below in my erlier comment.","poster":"amxexam","upvote_count":"1","comment_id":"598173","timestamp":"1651936860.0"},{"upvote_count":"1","timestamp":"1650573960.0","poster":"YAS007","comment_id":"589616","content":"I'm not sure about A because of this : https://cloud.google.com/compute/docs/instances/instance-life-cycle#comparison_table\nit sad that , in the case of stoping vm : \"Reset to power-on state, no data is saved.\""},{"comment_id":"524470","upvote_count":"3","timestamp":"1642285260.0","poster":"sjmsummer","content":"Selected Answer: AD\nAgree with A&D for the reasons other commented."},{"comment_id":"520518","upvote_count":"1","timestamp":"1641770520.0","poster":"Aiffone","content":"Two things are key. Provide cost visibility. D.Secondly pass no auro delete on disks that need to persist. A."},{"timestamp":"1640761320.0","comment_id":"511888","content":"About cost visibility\nIt seems either is ok C or D.But I chose D.\nBecause I think labels to associate cost to groups is necessary.","poster":"OrangeTiger","upvote_count":"2"},{"content":"About a require state to persist.\nE is worong.Because SSD is volatile.\nF is worong.Because no need Store all state in Google Cloud Storage if take a snap-shot.\nAll that remains is A or B. From the contents of the flag A.","timestamp":"1640761140.0","comment_id":"511884","upvote_count":"1","poster":"OrangeTiger"},{"content":"Answers: A is correct because persistent disks will not be deleted when an instance is stopped.\nD is correct because exporting daily usage and cost estimates automatically throughout the day to a BigQuery dataset is a good way of providing visibility to the finance department. Labels can then be used to group the costs based on team or cost center.","poster":"andeu","comment_id":"503322","upvote_count":"1","timestamp":"1639709760.0"},{"upvote_count":"1","poster":"anjuagrawal","content":"D is definitely correct. \nOption F says - store the state in cloud storage. Generally states are stored in PDs and not cloud storage. Hence, the confusion between A&F.","timestamp":"1638791760.0","comment_id":"495097"},{"timestamp":"1636436520.0","comments":[{"poster":"vincy2202","comment_id":"508405","timestamp":"1640336340.0","content":"Sorry. A & D are the correct answer","upvote_count":"1"}],"content":"D & F are the correct answers.","poster":"vincy2202","comment_id":"474634","upvote_count":"1"},{"poster":"JoeJoe","comments":[{"comment_id":"464028","content":"Forgot to say that \"E\" is wrong because local disk are scratched on a instance shut down as said at the same URL above apart from the fact that using a local disk is also an expensive choice","upvote_count":"1","poster":"JoeJoe","timestamp":"1634552460.0"},{"content":"I am not sure about F. Why would you need to snapshot the persistent disk? In the following article: https://cloud.google.com/compute/docs/instances/stop-start-instance, it state, \"A stopped VM retains its persistent disks, its internal IPs, and its MAC addresses\".","timestamp":"1658757480.0","upvote_count":"1","comment_id":"636751","poster":"jay9114"}],"upvote_count":"3","content":"I think it's definitely D & F.\n\"D\" clearly meets the cost reporting requirement\n\"F\" option is the only cheaper way to save machine state because when stopping an instance \"the VM shuts down the guest OS and loses its application state\" as it is clearly stated here https://cloud.google.com/compute/docs/instances/stop-start-instance","comment_id":"464027","timestamp":"1634552100.0"},{"content":"Answers are A & D. The difference between A & F is more of a design when the developer systems are moved from on-prem VM to Cloud. Usually it will be associated with local disk and migrating to Cloud VM with persistent VM is the suitable Option. Restoring snapshot, and creating new VM will definitely take time. However, the option F doesn't seem to be a bad option but the pricing will be increased during longer time depends on the number of developers, restarts and the size of each snapshot. At sometime, the storage cost will start increasing which would be of no use. Later need to configure time period to clear existing snapshots.","upvote_count":"1","poster":"dineshdct","comment_id":"463763","timestamp":"1634513640.0"},{"poster":"JustJack21","upvote_count":"3","content":"The key confusion here seems to be between A and F:\nA: The --no-auto-delete provides additional safety. You don't want to rebuild a VM multiple times a day. It's a waste of time and saves you no money. So just stop/start it.\nF. Cloud Storage is an \"Object store\"; unless the developers were using object store on-prem to store the application state, this means unnecessary redesign. Again, snapshot, and rebuild multiple times a day?\n\nA and D it is.\nB.","comment_id":"438953","timestamp":"1630738200.0"},{"comments":[{"upvote_count":"1","content":"C. Apply VM CPU utilization label and include it in the BigQuery billing export\n>> This option won't help. Lets eliminate the option.\n\nD. Use Google BigQuery billing export and labels to associate cost to groups\n>> Is the GCP suggested way to moniter cost.\n\nE. Store all state into local SSD, snapshot the persistent disks and terminate the VM\n>> Not an ideal way to take a backup - let's eliminate this option","poster":"amxexam","comments":[{"timestamp":"1630737600.0","comments":[{"upvote_count":"1","timestamp":"1630991040.0","poster":"amxexam","content":"Anyway this will not help in this requirement.","comment_id":"440709"}],"upvote_count":"1","poster":"JustJack21","content":"gcloud compute instances set-disk-auto-delete INSTANCE_NAME (--device-name=DEVICE_NAME | --disk=DISK) [--no-auto-delete] [--zone=ZONE] [GCLOUD_WIDE_FLAG …]\n\nOPTIONAL FLAGS\n--auto-delete\nEnables auto-delete for the given disk. Enabled by default, use --no-auto-delete to disable.","comment_id":"438948"},{"comment_id":"434632","content":"F. Store all-state in Google Cloud Storage, snapshot the persistent disks and terminate the VM\n>> Is an option to backup VM during the termination and to be created from snapshot reduces the config time, retaining the configurations done in the system. This will help in multiple starts and stop.\n\nSo D and F is the best combination\n\nURL1 - https://cloud.google.com/compute/docs/instances/preventing-accidental-vm-deletion","timestamp":"1630244280.0","upvote_count":"3","poster":"amxexam"}],"timestamp":"1630244280.0","comment_id":"434631"}],"poster":"amxexam","timestamp":"1630244220.0","upvote_count":"2","comment_id":"434629","content":"Let's go with option elimination\n\nA. Use the --no-auto-delete flag on all persistent disks and stop the VM\n>> There are no these kinds of flags but there is a deleteProtection flag, hence we will eliminate this option \n\nB. Use the --auto-delete flag on all persistent disks and terminate the VM\n>> There are no these kinds of flags but there is deleteProtection flag, hence we will eliminate this option"},{"comment_id":"427946","upvote_count":"3","poster":"PeppaPig","content":"After further digging, it looks D&F is correct\nA could be wrong because --no-auto-delete flag only applies when you delete a VM\nPersistent disk is maintained when you stop/terminate the VM regardless of this flag\nhttps://cloud.google.com/compute/docs/instances/instance-life-cycle#comparison_table","timestamp":"1629443400.0"},{"poster":"rikoko","content":"Not very clear. D and F might be correct. As explained by RKS-2021, state is lost when Compute Engine is stopped https://cloud.google.com/compute/docs/instances/stop-start-instance. F addresses it. However taking daily snapshot disks (even if it has incremental changes) + egress costs might cost more than keeping the persistent disk if it happens several times a day - which in this sense would put A a cheaper solution - but the question insist on keeping the state - not so much on cost.\nSide note about A: auto-delete has impact only when the VM is deleted (it does not apply when VM is stopped)","upvote_count":"3","comment_id":"427015","timestamp":"1629312060.0"},{"timestamp":"1628869140.0","comment_id":"424404","content":"A&D, are correct.\nC is wrong, why would finance team care about CPU utilization??","upvote_count":"1","poster":"PeppaPig"},{"timestamp":"1625458020.0","upvote_count":"6","content":"A and D, are OK","comment_id":"398823","poster":"kopper2019"},{"upvote_count":"2","poster":"victory108","timestamp":"1625321100.0","comments":[{"content":"--no-auto-delete flag does not have effect on the state of the application. I believe D and F are correct ANS, https://cloud.google.com/compute/docs/instances/stop-start-instance","comment_id":"403039","upvote_count":"3","poster":"RKS_2021","timestamp":"1625881080.0"}],"comment_id":"397611","content":"A. Use the --no-auto-delete flag on all persistent disks and stop the VM\nD. Use Google BigQuery billing export and labels to associate cost to groups"},{"upvote_count":"2","content":"A & D is correct:\nA: As it will not delete the disk on start stop of VM\nD: It will give insight to finance team based on labels. BigQuery supports labels","timestamp":"1624684980.0","comment_id":"390951","poster":"aviratna"},{"comment_id":"388482","poster":"try_jai","upvote_count":"1","timestamp":"1624421400.0","content":"D and E"},{"upvote_count":"1","poster":"cugena","timestamp":"1623930660.0","comment_id":"384152","content":"Important to know: This page describes how to stop and start a virtual machine (VM) instance. Note that Compute Engine uses STOP and TERMINATE interchangeably. (https://cloud.google.com/compute/docs/instances/stop-start-instance)"},{"upvote_count":"1","comment_id":"383234","timestamp":"1623834120.0","content":"CD\nI do not understand why we shall stop or terminate the VMs","poster":"__INSIDEOUT__"},{"content":"C and D for me, because de D point speak about groups the VM instances, and the only way to achieve it is using labels over the resources, and add them to the BigQuery export Billing information.","upvote_count":"2","comment_id":"375525","poster":"Svar","timestamp":"1622938920.0"},{"timestamp":"1622665080.0","poster":"Naakos","comment_id":"373031","content":"D and E I would say","upvote_count":"1","comments":[{"timestamp":"1622997840.0","comments":[{"poster":"Bhardwajriddhi","content":"* E is not correct","upvote_count":"1","comment_id":"376213","timestamp":"1622997840.0"}],"upvote_count":"1","poster":"Bhardwajriddhi","content":"D is not correct bcoz VM can start /stop multiple times in a day & Local SSD are empheral storage","comment_id":"376212"}]}],"isMC":true,"answer":"AD","unix_timestamp":1622665080,"topic":"1","timestamp":"2021-06-02 22:18:00","answer_description":"","choices":{"B":"Use the - -auto-delete flag on all persistent disks and terminate the VM","D":"Use Google BigQuery billing export and labels to associate cost to groups","A":"Use the - -no-auto-delete flag on all persistent disks and stop the VM","F":"Store all state in Google Cloud Storage, snapshot the persistent disks, and terminate the VM","C":"Apply VM CPU utilization label and include it in the BigQuery billing export","E":"Store all state into local SSD, snapshot the persistent disks, and terminate the VM"},"answer_images":[],"answers_community":["AD (63%)","DF (26%)","5%"],"question_text":"To reduce costs, the Director of Engineering has required all developers to move their development infrastructure resources from on-premises virtual machines\n(VMs) to Google Cloud Platform. These resources go through multiple start/stop events during the day and require state to persist. You have been asked to design the process of running a development environment in Google Cloud while providing cost visibility to the finance department.\nWhich two steps should you take? (Choose two.)","url":"https://www.examtopics.com/discussions/google/view/54304-exam-professional-cloud-architect-topic-1-question-7/","answer_ET":"AD","exam_id":4},{"id":"eC9AbnxtxWPYcYsYr97U","topic":"1","exam_id":4,"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/11815-exam-professional-cloud-architect-topic-1-question-70/","timestamp":"2020-01-12 14:36:00","unix_timestamp":1578836160,"isMC":true,"discussion":[{"content":"Agree D","comments":[{"timestamp":"1596709860.0","upvote_count":"7","comment_id":"151884","poster":"tartar","content":"D is ok"},{"upvote_count":"4","content":"Yes D is right","comment_id":"210518","poster":"kumarp6","timestamp":"1604240220.0"},{"comment_id":"611776","content":"this Question is very Old and should be deleted from the exam , there is no Failover replica now , to do an HA we just confer it for the SQL instance that we have .","upvote_count":"25","poster":"kimharsh","timestamp":"1654425360.0"},{"content":"https://cloud.google.com/sql/docs/mysql/replication#:~:text=Read%20replicas%20neither%20provide%20high%20availability%20nor%20offer%20it.&text=A%20primary%20instance%20cannot%20failover,any%20way%20during%20an%20outage.&text=Maintenance%20windows%20cannot%20be%20set,windows%20with%20the%20primary%20instance.\n\n- Read replicas neither provide high availability nor offer it.\n\nAgree D","timestamp":"1654159380.0","poster":"nwk","comment_id":"610507","upvote_count":"7","comments":[{"upvote_count":"2","content":"That link is helpful! I navigated to the \"quick reference for Cloud SQL read replicas\" and read the \"failover\" and \"high availability\" topics. They state: \n1. Failover - \"A primary instance cannot failover to a read replica, and read replicas are unable to failover in any way during an outage.\"\n2. High Availability - \"Read replicas neither provide high availability nor offer it.\"","comment_id":"668205","poster":"jay9114","comments":[{"upvote_count":"1","timestamp":"1706724540.0","comment_id":"1137008","content":"Sorry for this, but in the same link you can read: \nHigh availability Read replicas allow you to enable high availability on the replicas.\n\n(What I understand is that Read Replicas give you high availability on reads, of course, not in writes).","poster":"spuyol"}],"timestamp":"1663083720.0"}]},{"poster":"nitinz","timestamp":"1614902340.0","content":"D, its regional product and failover is required for HA","comment_id":"303718","upvote_count":"4"}],"timestamp":"1578836160.0","comment_id":"38085","upvote_count":"36","poster":"AWS56"},{"comment_id":"89425","upvote_count":"18","poster":"GunjGupta","timestamp":"1589537640.0","content":"Cloud SQL is regional. For high availability, we need to think fo a failover strategy. So Option D meets the requirement.\ncreate failover replica in the same region but in different Zone"},{"content":"Selected Answer: D\nD - It's serving completely your application, so it should not be read replica it should be failover replica on a diff zone","upvote_count":"1","timestamp":"1738629240.0","comment_id":"1351155","poster":"matt57"},{"comment_id":"1335675","upvote_count":"1","poster":"plumbig11","content":"Selected Answer: D\nRead replica is not appropriated to failover.\nCreate a failover replica instance in the same region, but in a different zone","timestamp":"1735838700.0"},{"poster":"Lenifia","content":"Selected Answer: C\nC is the correct answer, failover is more like DR","upvote_count":"1","comment_id":"1302365","timestamp":"1729757880.0"},{"timestamp":"1729711320.0","poster":"nareshthumma","upvote_count":"2","comment_id":"1302173","content":"Answer is D: \nCreate a failover replica instance in the same region, but in a different zone.\n\nHere’s why this option is the best:\n\n 1. High Availability: A failover replica provides automatic failover capabilities, meaning that if the primary instance becomes unavailable (due to a zone failure, for example), Cloud SQL can automatically promote the failover replica to be the new primary instance, minimizing downtime.\n\n 2. Same Region, Different Zone: By creating the failover replica in the same region but a different zone, you ensure that the instances are geographically close to each other, which helps maintain low latency and faster failover times while still protecting against zone-specific outages.\n\n 3. Cost Efficiency: Using a failover replica in the same region is typically more cost-effective than setting up a replica in a different region, as cross-region replication can introduce additional latency and costs."},{"upvote_count":"1","content":"C is incorrect. D is the right answer. Read-replica is just an instance for read operation, it cannot provide HA.","comment_id":"1300823","timestamp":"1729498260.0","poster":"hehe_24"},{"poster":"0verK0alafied","timestamp":"1713916380.0","content":"Selected Answer: D\nThe HA configuration provides data redundancy. A Cloud SQL instance configured for HA is also called a regional instance and has a primary and secondary zone within the configured region. Within a regional instance, the configuration is made up of a primary instance and a standby instance. Through synchronous replication to each zone's persistent disk, all writes made to the primary instance are replicated to disks in both zones before a transaction is reported as committed. In the event of an instance or zone failure, the standby instance becomes the new primary instance. Users are then rerouted to the new primary instance. This process is called a failover.\nhttps://cloud.google.com/sql/docs/mysql/high-availability#HA-configuration","comment_id":"1201053","upvote_count":"3"},{"comment_id":"1142039","content":"Selected Answer: D\n\"Note: Read replicas do not provide failover capability. To provide failover capability for an instance, see Configuring an instance for high availability.\"\nhttps://cloud.google.com/sql/docs/mysql/replication/","poster":"Gall","timestamp":"1707216540.0","upvote_count":"2"},{"poster":"parthkulkarni998","upvote_count":"1","comment_id":"1097262","content":"Selected Answer: D\nCorrect answer would be D as a failover replica acts as a redundant copy incase of zone failure. However, option C causes confusion because a read replica can provide availability for reads, in case of zone failure for primary, but they cant provide support for writes. They would only work for reads.","timestamp":"1702640760.0"},{"content":"Selected Answer: D\nD, its regional product and failover is required for HA","timestamp":"1702559640.0","upvote_count":"1","comment_id":"1096489","poster":"Roro_Brother"},{"comment_id":"1067392","upvote_count":"1","timestamp":"1699635060.0","content":"C\n1. Failover replica is a legacy way and is not available in GCP now - B and D are not the options: https://cloud.google.com/sql/docs/mysql/high-availability#legacy_mysql_high_availability_option\n2. Cloud SQL is regional resource. However, cross-region read replicas are allowed now in Cloud SQL (https://cloud.google.com/blog/products/databases/introducing-cross-region-replica-for-cloud-sql) - A and C are options. \nChosen C, as there is no requirement or mention of cross-regional / global db.","comments":[{"comment_id":"1117041","timestamp":"1704750540.0","upvote_count":"1","poster":"hogtrough","content":"Read replica is not a valid choice for HA configurations. It does not provide automatic failover that is required for HA. It may be called something different or this answer has changed, but D is still the best option."}],"poster":"thewalker"},{"content":"The key is High Availability, not Resilience or Disaster Recovery. Therefore my answer is C","timestamp":"1695586920.0","upvote_count":"1","poster":"piiizu","comment_id":"1016156"},{"poster":"someone2011","upvote_count":"2","content":"D.\nIn HA config, the second replica is caled stand by. The process of replacing the primary damaged node is called failover.\nhttps://cloud.google.com/sql/docs/postgres/high-availability","comment_id":"1003117","timestamp":"1694257860.0"},{"timestamp":"1693826520.0","poster":"didek1986","comment_id":"998488","content":"Selected Answer: C\nC for sure","upvote_count":"1"},{"comment_id":"916526","upvote_count":"4","content":"Selected Answer: C\nC.\nFailover is so old and deprecated","timestamp":"1686074280.0","poster":"red_panda"},{"content":"this Question is very Old and should be deleted from the exam , there is no Failover replica now , to do an HA we just confer it for the SQL instance that we have .. agreed tested as well","poster":"LaxmanTiwari","upvote_count":"1","comment_id":"896954","timestamp":"1683999960.0"},{"comment_id":"874379","upvote_count":"4","timestamp":"1681891260.0","comments":[{"timestamp":"1686647580.0","upvote_count":"1","poster":"DevOpsifier","comment_id":"922105","content":"thanks!"}],"poster":"JC0926","content":"Selected Answer: D\nOption C is not the best choice because it suggests creating a read replica instance, which is designed to handle read traffic and provide better performance in read-heavy workloads, but it is not intended for high availability.\n\nOn the other hand, Option D suggests creating a failover replica instance in the same region but in a different zone. Failover replicas are designed specifically for high availability, as they maintain an up-to-date copy of the primary instance's data. If the primary instance becomes unresponsive or fails, Cloud SQL automatically switches to the failover replica with minimal downtime.\n\nIn summary, to introduce high availability for your Cloud SQL instance, you should create a failover replica instance in the same region but in a different zone (Option D) rather than creating a read replica instance (Option C), which doesn't provide high availability in case of primary instance failures."},{"upvote_count":"1","content":"Selected Answer: D\nD\nC is also not ideal for high availability because creating a read replica in the same region but in a different zone does not provide automatic failover. A read replica is used for scaling reads and can improve performance, but it is not a failover mechanism.","timestamp":"1678938300.0","poster":"JC0926","comment_id":"840532"},{"poster":"cert2020","content":"Agree D.\nhttps://cloud.google.com/sql/docs/mysql/configure-ha\nThe legacy configuration for high availability used a failover replica instance. The new configuration does not use a failover replica. Instead, it uses Google's regional persistent disks, which synchronously replicate data at the block level between two zones in a region.","comment_id":"827130","upvote_count":"1","timestamp":"1677776340.0"},{"upvote_count":"2","timestamp":"1677611700.0","poster":"black_magic","comment_id":"825192","content":"The high availability configuration for Cloud SQL has recently changed. Failover replicas will no longer be included in the new Google recommended configuration and will be considered legacy. Google is moving towards persistent regional disks. This question as well as the solutions should be updated.\n\n\"The legacy configuration for high availability used a failover replica instance. The new configuration does not use a failover replica. Instead, it uses Google's regional persistent disks, which synchronously replicate data at the block level between two zones in a region. If you have an existing MySQL instance that uses the legacy high availability configuration, you can update your configuration to use the current version.\"\nSource: https://cloud.google.com/sql/docs/mysql/configure-ha"},{"comment_id":"818385","timestamp":"1677098400.0","poster":"MaryMei","upvote_count":"1","content":"https://cloud.google.com/sql/docs/mysql/replication\nonly read replicas exists"},{"comment_id":"804970","content":"Option A is not a valid solution, as the .boto configuration file is not used to specify the encryption key.\n\nOption B is also not a valid solution, as gcloud config is used to set global flags for the gcloud command-line tool, and does not affect the use of gsutil.\n\nOption D is not necessary, as you can use an existing bucket and simply specify the encryption key when uploading the files.\n\nTherefore, the correct answer is C: Use gsutil to upload the files, and use the flag --encryption-key to supply the encryption key. This will encrypt the files on Cloud Storage using the customer-supplied encryption key.","upvote_count":"1","timestamp":"1676087640.0","poster":"8d31d36"},{"upvote_count":"3","timestamp":"1674978420.0","content":"Selected Answer: D\nCloud SQL is regional hence A & B are wrong\nC will work . Read replica has to be promted mannually , so down time will be there\nD is the highly available soloution","poster":"RVivek","comment_id":"791459"},{"timestamp":"1672831560.0","comments":[{"poster":"FI22","upvote_count":"1","content":"The read replica processes queries, read requests, and analytics traffic, thus reducing the load on the primary instance. So C ok!","comment_id":"765558","timestamp":"1672831680.0"},{"comment_id":"791460","content":"Both C and D are OK. However C is a manual process and there may be soem down time before the admin get alrted and promote read replica","poster":"RVivek","timestamp":"1674978480.0","upvote_count":"1"}],"upvote_count":"1","comment_id":"765557","content":"The question need to update! As D depricated.\nIn a disaster recovery scenario, you can promote a replica to convert it to a primary. High availability can be achieved by serving traffic from replicas. \nD is perfect but deprecated.\nC is also ok.","poster":"FI22"},{"timestamp":"1671924360.0","content":"Selected Answer: D\n\"Read Replicas CAN be promoted to master nodes in the case of DR. However, there is downtime entailed. Failover Replicas are designed to automatically become master nodes.\"\n\nreference: https://googlecloudarchitect.us/read-replica-versus-failover-replica-in-cloud-sql/#:~:text=Read%20Replicas%20CAN%20be%20promoted,SQL%20go%20through%20the%20proxy).","upvote_count":"1","comments":[{"upvote_count":"1","timestamp":"1671924480.0","poster":"jay9114","comments":[{"upvote_count":"1","content":"The link referenced above (https://cloud.google.com/sql/docs/mysql/high-availability) states that\n\"The legacy process for adding high availability to MySQL instances uses a failover replica.\" \nIt also states that:\n\"Cloud SQL plans to discontinue support for legacy HA instances in the future and will soon be announcing a date to do so. Currently, legacy HA instances are still covered by the Cloud SQL SLA. We recommend you upgrade your existing legacy HA instances to regional persistent disk HA instances and create new instances using regional persistent disk HA as soon as possible.\"\nSo IMHO the answer should be C","poster":"[Removed]","timestamp":"1680932100.0","comment_id":"864434"}],"content":"\"The legacy process for adding high availability to MySQL instances uses a failover replica.\"\n\nreference: https://cloud.google.com/sql/docs/mysql/high-availability","comment_id":"755271"}],"comment_id":"755267","poster":"jay9114"},{"upvote_count":"2","timestamp":"1671904980.0","comment_id":"755073","content":"Selected Answer: D\nRead replicas are used to read only purpose\nHA need failover in same region but different zone","poster":"thamaster"},{"upvote_count":"1","poster":"sithin_nair","comment_id":"754608","content":"Its D.\nhttps://cloud.google.com/sql/docs/mysql/high-availability","timestamp":"1671838980.0"},{"timestamp":"1671689520.0","upvote_count":"2","comments":[{"upvote_count":"2","content":"Option A, creating a read replica instance in a different region, would not provide high availability because the read replica would not be able to take over in the event of an issue with the primary instance.\n\nOption B, creating a failover replica instance in a different region, would not provide high availability because the failover replica would be too far away from the primary instance to take over in a timely manner in the event of an issue.\n\nOption C, creating a read replica instance in the same region but in a different zone, would not provide high availability because the read replica would not be able to take over in the event of an issue with the primary instance. A read replica is only used for read-only queries and cannot be promoted to be the primary instance.","comment_id":"753001","poster":"omermahgoub","timestamp":"1671689520.0"}],"comment_id":"753000","poster":"omermahgoub","content":"D. Create a failover replica instance in the same region, but in a different zone\n\nTo introduce high availability for a Cloud SQL instance, you can create a failover replica instance in the same region but in a different zone. This will allow the failover replica to take over in the event of an outage or other issue with the primary instance, ensuring that your application continues to function without interruption."},{"content":"Selected Answer: C\nC.\nFailover replica is deprecated.","upvote_count":"3","comment_id":"744917","timestamp":"1671009120.0","poster":"gonlafer"},{"content":"Selected Answer: C\nToday. it's C. \nhttps://cloud.google.com/sql/docs/mysql/high-availability#legacy_mysql_high_availability_option","comment_id":"742722","upvote_count":"2","timestamp":"1670845260.0","poster":"gonlafer"},{"comment_id":"731208","upvote_count":"1","timestamp":"1669793880.0","poster":"FateSpringfield","content":"C is the answer, Failover replica is deprecated for HA https://cloud.google.com/sql/docs/mysql/high-availability#legacy_mysql_high_availability_option"},{"timestamp":"1669312860.0","upvote_count":"1","comment_id":"726100","content":"Selected Answer: C\n\"If availability is a consideration for your read replicas, you can enable HA on the replicas.\"\nhttps://cloud.google.com/sql/docs/mysql/high-availability\n\nAlso below in the link: \"The legacy process for adding high availability to MySQL instances uses a failover replica. The legacy functionality isn't available in the Google Cloud console\"\nSo failover replica should not be an option now.","poster":"gonlafer"},{"comment_id":"719707","upvote_count":"3","content":"this is a very old question\n\nThe legacy configuration for high availability used a failover replica instance. The new configuration does not use a failover replica. Instead, it uses Google's regional persistent disks, which synchronously replicate data at the block level between two zones in a region. If you have an existing MySQL instance that uses the legacy high availability configuration, you can update your configuration to use the current version. For other procedures related to the legacy high availability configuration, see Legacy configuration for high","poster":"ashrafh","timestamp":"1668607260.0"},{"upvote_count":"1","timestamp":"1667847720.0","content":"Selected Answer: C\nYou do realize that a fail over replica will replicate it in a failure scenario introducing reliability not availability. \n\nC is the correct answer","comment_id":"713261","poster":"ErenYeager"},{"content":"Selected Answer: D\nD is ok","poster":"megumin","upvote_count":"1","comment_id":"712912","timestamp":"1667808480.0"},{"upvote_count":"1","content":"Selected Answer: D\nread replica does not provide high availability, so the answer is D","timestamp":"1667549460.0","poster":"Aninina","comment_id":"710985"},{"comment_id":"706298","poster":"[Removed]","timestamp":"1666947720.0","content":"Selected Answer: D\nDDDDDDDDDDD","upvote_count":"1"},{"comment_id":"699969","timestamp":"1666272420.0","poster":"drpandamd","upvote_count":"1","content":"https://cloud.google.com/sql/docs/mysql/high-availability\nThis suggests that C is correct."},{"poster":"AzureDP900","timestamp":"1665939060.0","upvote_count":"1","content":"d is right","comment_id":"696401"},{"upvote_count":"1","timestamp":"1662832080.0","content":"he new configuration does not use a failover replica. Instead, it uses Google's regional persistent disks, which synchronously replicate data at the block level between two zones in a region.","poster":"Bahubali1988","comment_id":"665583"},{"comment_id":"661466","upvote_count":"4","poster":"shekarcfc","content":"Selected Answer: B\nhttps://cloud.google.com/blog/products/databases/introducing-cross-region-replica-for-cloud-sql","timestamp":"1662482940.0"},{"comment_id":"659687","upvote_count":"3","timestamp":"1662346620.0","poster":"Jay_Krish","content":"Selected Answer: D\nAnswer must be D.\nDon't understand how can people here comment C as the answer when it can only cater to read requests. HA means it is fully available just like the primary."},{"comment_id":"657414","content":"Selected Answer: D\nHa means to test failover. performance means read replica.","timestamp":"1662121740.0","poster":"kiappy81","upvote_count":"2"},{"content":"Selected Answer: D\nHA not performance","upvote_count":"2","poster":"crg63","comment_id":"652594","timestamp":"1661609100.0"},{"comment_id":"614178","poster":"H_S","timestamp":"1654801680.0","upvote_count":"3","content":"Selected Answer: D\n100 % D I am a data eng trust me on this it can't be anything else than D"},{"poster":"Majkl93","content":"Selected Answer: D\nHA is D","timestamp":"1654693920.0","comment_id":"613281","upvote_count":"1"},{"timestamp":"1653229020.0","content":"Selected Answer: C\nThe legacy configuration for high availability used a failover replica instance. The new configuration does not use a failover replica. Instead, it uses Google's regional persistent disks, which synchronously replicate data at the block level between two zones in a region. If you have an existing MySQL instance that uses the legacy high availability configuration, you can update your configuration to use the current version. For other procedures related to the legacy high availability configuration, see Legacy configuration for high availability.\n\nhttps://cloud.google.com/sql/docs/mysql/configure-ha","upvote_count":"5","comment_id":"605557","poster":"injarapu"},{"upvote_count":"1","timestamp":"1652289420.0","content":"Selected Answer: C\nwe talking about HA not DR to go with failover. C is multi zone that meets demand of question.","comment_id":"600233","comments":[{"comment_id":"632059","upvote_count":"2","content":"No, Read Replica is only to offload read-only traffic from main database. It won't help with High Availability. D is correct answer here","poster":"szefco","timestamp":"1657960320.0"}],"poster":"amxexam"},{"comments":[{"timestamp":"1640516340.0","upvote_count":"2","poster":"Rajasa","comment_id":"509560","content":"https://cloud.google.com/sql/docs/mysql/configure-ha"}],"upvote_count":"1","timestamp":"1640516040.0","poster":"Rajasa","content":"D Agree","comment_id":"509559"},{"comment_id":"509536","poster":"vincy2202","content":"D is the correct answer.\n\nCloud SQL is a regional resource.\nRead Replica helps to reduce latency & improve performance. \nFailover Replica is used for High Availability.","upvote_count":"4","timestamp":"1640512380.0"},{"timestamp":"1640003880.0","comments":[{"content":"seems you do not understand HA and DR...","timestamp":"1641731700.0","upvote_count":"2","comment_id":"520190","poster":"pddddd"}],"upvote_count":"2","comment_id":"505417","poster":"AmitMittal","content":"D is NOT OK. It is for DR.\nFor HA, it should be C.\nAll of you (almost) are wrong here by voting D :-D"},{"upvote_count":"1","timestamp":"1638861300.0","poster":"haroldbenites","content":"Go for D. \nIt says HA.","comment_id":"495714"},{"upvote_count":"1","content":"D is the right answer","poster":"vincy2202","comment_id":"488370","timestamp":"1638035760.0"},{"poster":"MaxNRG","content":"D – create failover replicate in the same region, but in different zone.\nThe HA configuration consist of primary instance (in primary zone) and failover replicate in secondary zone.\nhttps://cloud.google.com/sql/docs/mysql/high-availability","timestamp":"1635357000.0","comment_id":"468789","upvote_count":"2"},{"content":"Now uses regional persistence disks\n\nhttps://cloud.google.com/sql/docs/mysql/configure-ha:\n\nThe legacy configuration for high availability used a failover replica instance. The new configuration does not use a failover replica. Instead, it uses Google's regional persistent disks, which synchronously replicate data at the block level between two zones in a region. If you have an existing MySQL instance that uses the legacy high availability configuration, you can update your configuration to use the","comment_id":"444682","poster":"cugena","upvote_count":"2","timestamp":"1631635320.0"},{"content":"We are talking about HA not DR, hence C","poster":"amxexam","comment_id":"435240","timestamp":"1630309560.0","upvote_count":"2","comments":[{"poster":"amxexam","comment_id":"441370","upvote_count":"1","timestamp":"1631095560.0","content":"D is also will act HA, C is also HA... But why D is better than C is the question?"}]},{"comment_id":"361292","poster":"victory108","content":"D. Create a failover replica instance in the same region, but in a different zone","timestamp":"1621422000.0","upvote_count":"1"},{"poster":"Ausias18","timestamp":"1617256080.0","content":"Answer is D","comment_id":"325544","upvote_count":"1"},{"comment_id":"321769","poster":"lynx256","content":"D is ok","timestamp":"1616842080.0","upvote_count":"2"},{"poster":"DheerajP","timestamp":"1611796140.0","upvote_count":"2","comment_id":"278163","content":"Answer : D\ncheck quick demo at https://www.youtube.com/watch?v=BFl-2_qAmdQ"},{"upvote_count":"2","timestamp":"1600224300.0","content":"D is correct","poster":"AshokC","comment_id":"180142"},{"upvote_count":"1","timestamp":"1600054620.0","poster":"ESP_SAP","comment_id":"179046","content":"Correct Answer is (D):\n\nhttps://cloud.google.com/sql/docs/mysql/high-availability#failover"},{"comment_id":"117394","content":"Read Replica is for performance. Failover Replica is for High Availability.\n\nI agree with D.","timestamp":"1592911980.0","upvote_count":"6","poster":"mlantonis"},{"upvote_count":"1","comment_id":"114661","timestamp":"1592646240.0","content":"D is the correct answer","poster":"Tushant"},{"timestamp":"1591777980.0","poster":"gfhbox0083","content":"D, for sure.\nA failover replica, in a different zone","comment_id":"106594","upvote_count":"1"},{"upvote_count":"1","comment_id":"102390","content":"D is correct","poster":"Ziegler","timestamp":"1591276080.0"},{"poster":"Nirms","upvote_count":"1","comment_id":"101110","content":"D is the correct answer","timestamp":"1591123740.0"},{"content":"Answer D: https://cloud.google.com/sql/docs/mysql/high-availability","poster":"misho","timestamp":"1590831960.0","comment_id":"98758","upvote_count":"1"},{"timestamp":"1590425940.0","content":"D is the answer","comment_id":"95532","poster":"gcp_aws","upvote_count":"2"},{"poster":"PRC","upvote_count":"2","timestamp":"1587046980.0","comment_id":"75348","content":"D is correct.."},{"content":"Answer : D. Selected D in the exam","upvote_count":"3","poster":"[Removed]","comment_id":"56424","timestamp":"1582878960.0"},{"timestamp":"1580395080.0","upvote_count":"3","poster":"2g","comment_id":"44820","content":"Answer: D"}],"answer_ET":"D","answer_description":"","answers_community":["D (60%)","C (33%)","7%"],"choices":{"B":"Create a failover replica instance in a different region","C":"Create a read replica instance in the same region, but in a different zone","D":"Create a failover replica instance in the same region, but in a different zone","A":"Create a read replica instance in a different region"},"answer":"D","question_images":[],"question_id":169,"question_text":"You are using a single Cloud SQL instance to serve your application from a specific zone. You want to introduce high availability. What should you do?"},{"id":"hODhZMFUVWaIhBdSjlpJ","question_images":[],"discussion":[{"content":"The easiest way would be to create template from --source-instance, and then create MIG, but it is not listed here, also you cannot create a MIG from image directly, you need a template, so answer is C (image -> template -> mig).","poster":"sdsdfasdf4","comment_id":"249870","upvote_count":"32","comments":[{"poster":"6721sora","upvote_count":"9","content":"C is correct. \nTo sdsdfasd4's point - Not recommended to create template from --source-instance as If the existing instance contains a static external IP address, that address is copied into the instance template and might limit the use of the template. \nTemplates are best created from images or other templates. Creating the template from a running instance may require work to clean it up before it can be used for a MIG","comment_id":"651609","timestamp":"1661396400.0"}],"timestamp":"1608616140.0"},{"poster":"AWS56","comment_id":"38086","comments":[{"upvote_count":"1","poster":"heretolearnazure","timestamp":"1692877860.0","comment_id":"989151","content":"C is definitely the right answer"}],"content":"C is the right answer","upvote_count":"12","timestamp":"1578836280.0"},{"comment_id":"1302174","upvote_count":"1","poster":"nareshthumma","timestamp":"1729711620.0","content":"Answer A:\n\nCreate a snapshot of the existing disk. Create an instance template from the snapshot. Create an autoscaled managed instance group from the instance template.\n\nHere’s why this option is the best:\n\n 1. Autoscaling: By creating an autoscaled managed instance group, you can automatically adjust the number of instances based on the load. This means that during peak business hours, additional instances will be created to handle the increased traffic, improving application performance. During off-peak hours, the number of instances can scale down to reduce costs.\n\n 2. Snapshot Creation: Taking a snapshot of the existing disk ensures that you have a backup of the current state of your application. This snapshot can be used to create the new instance template, ensuring that your autoscaled instances have the same configuration as the original instance."},{"content":"Selected Answer: B\nI prefer B, is better because I don't need to stop the instance to create the disk image.","timestamp":"1719496380.0","comment_id":"1238205","upvote_count":"1","poster":"46f094c"},{"upvote_count":"4","poster":"pakilodi","comment_id":"1085099","timestamp":"1701422760.0","content":"Selected Answer: C\nC. The key here is stateless, so we don't need snapshot the actual instance, we can start from zero."},{"upvote_count":"4","content":"Selected Answer: C\nC\nWe can create an instance from an image or a custom image or a snapshot but an instance template can be created using either image or custom image only. \n\nAlso refer: https://cloud.google.com/compute/docs/instance-templates/create-instance-templates","poster":"thewalker","comment_id":"1085065","timestamp":"1701419340.0"},{"upvote_count":"7","content":"Selected Answer: C\nOption C is the correct choice because creating a custom image from the existing disk ensures that the application environment is consistent and does not change between instances, which can reduce variability in performance. Creating an instance template from the custom image allows you to easily create new instances that are based on the same image, which can save time and effort. Finally, creating an autoscaled managed instance group allows you to automatically scale the number of instances based on demand, which can ensure that there are enough instances to handle peak traffic while minimizing costs during periods of low traffic","comment_id":"828986","poster":"Deb2293","timestamp":"1677936660.0"},{"timestamp":"1667809560.0","upvote_count":"2","content":"Selected Answer: C\nC is ok","comment_id":"712924","poster":"megumin"},{"upvote_count":"1","comment_id":"696397","poster":"AzureDP900","content":"C is right.\nCreate a custom image from the existing disk. Create an instance template from the custom image. Create an autoscaled managed instance group from the instance template.","timestamp":"1665938880.0"},{"poster":"abirroy","upvote_count":"1","timestamp":"1663105260.0","content":"Selected Answer: C\nC is correct","comment_id":"668433"},{"poster":"mv2000","content":"06/30/2022 Exam","upvote_count":"9","timestamp":"1657019940.0","comment_id":"627425"},{"comments":[{"content":"it's possible to create a snapshot of running VM by reducing I/O disks","timestamp":"1706776500.0","comment_id":"1137400","upvote_count":"1","poster":"bargou"}],"timestamp":"1644451920.0","content":"I think Snapshot option are not correct in this scenario as to take snapshot you need to stop the VM so C looks best option","poster":"SHalgatti","upvote_count":"2","comment_id":"544178"},{"poster":"PhuocT","comment_id":"512357","timestamp":"1640793240.0","content":"Selected Answer: C\nC is the answer","upvote_count":"1"},{"content":"Selected Answer: C\nC is the answer","timestamp":"1640516760.0","comment_id":"509563","poster":"Rajasa","upvote_count":"1"},{"comment_id":"495729","upvote_count":"3","poster":"haroldbenites","timestamp":"1638862140.0","content":"Go for C.\nInstance template can not be created from snapshot. Only from an image."},{"comment_id":"488865","content":"C is the right answer.\nhttps://cloud.google.com/compute/docs/instance-templates/create-instance-templates#using_custom_or_public_images_in_your_instance_templates","timestamp":"1638079620.0","upvote_count":"3","poster":"vincy2202"},{"poster":"joe2211","content":"Selected Answer: C\nvote C","upvote_count":"1","timestamp":"1637797920.0","comment_id":"486328"},{"content":"C – create a custom image from the existing disk. Create an instance template from the custom image. Create an autoscaled MIG from instance template.\nA could work if a snapshot was transformed to a custom image. Instance Template can be created only from image.","timestamp":"1635424560.0","upvote_count":"4","poster":"MaxNRG","comment_id":"469256"},{"timestamp":"1625766480.0","comment_id":"402112","poster":"MamthaSJ","content":"Answer is C","upvote_count":"3"},{"upvote_count":"1","timestamp":"1621421940.0","comment_id":"361290","poster":"victory108","content":"C. Create a custom image from the existing disk. Create an instance template from the custom image. Create an autoscaled managed instance group from the instance template."},{"timestamp":"1617256260.0","poster":"Ausias18","comment_id":"325546","content":"Answer is C","upvote_count":"1"},{"content":"The key point is to have a \"autoscaled managed instance group\". for that, you need a image. you can either create image from snapshot or from persistent disk.\nOnly C covers the right route.","comment_id":"278930","timestamp":"1611884520.0","poster":"bnlcnd","upvote_count":"2"},{"content":"I would go with C as it is a stateless server, it won't need a backup snapshot and image can be created by the persistence disk directly","upvote_count":"2","timestamp":"1609174260.0","comment_id":"254199","poster":"Prakzz"},{"poster":"doumx","comment_id":"236460","timestamp":"1607260320.0","upvote_count":"2","content":"C : https://cloud.google.com/compute/docs/instance-templates/create-instance-templates#using_custom_or_public_images_in_your_instance_templates"},{"upvote_count":"8","timestamp":"1607030100.0","poster":"Surf","comment_id":"234376","content":"I think all answers are wrong.\nA is wrong. You cannot create an instance template from the snapshot. You can create an instance template from the instance itself.\nB is wrong. You cannot create an autoscaled managed instance group from the custom image. You need an instance template to create an autoscaled managed instance group.\nC is wrong. You cannot create an instance template from the custom image. You can create an instance template from the instance itself.\nD is wrong. You cannot create an instance template from the existing disk. You can create an instance template from the instance itself. Also you cannot create a custom image from the instance template. You can create a custom image from the drive or from a snapshot.\n\nI do not know what the proper answer is. I assume none. If I had to pick one, maybe C. And only if C meant that you create an instance template using the custom image (not \"from the custom image\").","comments":[{"content":"Regarding C, \"you can either use a custom image or a public image for your instance templates\" - https://cloud.google.com/compute/docs/instance-templates/create-instance-templates#using_custom_or_public_images_in_your_instance_templates","comment_id":"519600","timestamp":"1641654780.0","poster":"lxgywil","upvote_count":"1"}]},{"comment_id":"203446","upvote_count":"2","timestamp":"1603241160.0","content":"C is right. Specify custom image while creating the instance template. https://cloud.google.com/compute/docs/instance-templates/create-instance-templates","poster":"vibhavchavan"},{"comment_id":"180145","timestamp":"1600224780.0","upvote_count":"1","content":"Answer: C","poster":"AshokC"},{"upvote_count":"1","content":"There is no requirement for a snapshot of the VM to be taken and a custom image can be created from a running disk. So the answer is C","poster":"OnomeOkuma","comment_id":"142778","timestamp":"1595597460.0"},{"poster":"mlantonis","comment_id":"117404","upvote_count":"2","timestamp":"1592912520.0","content":"I still believe that we need to take a snapshot, but C seems more correct than B, because we have the instance template."},{"comment_id":"106597","timestamp":"1591778160.0","poster":"gfhbox0083","upvote_count":"1","content":"C, for sure.\nYou create an autoscaled managed instance group from the instance template."},{"upvote_count":"2","poster":"Ziegler","comment_id":"102420","timestamp":"1591279740.0","content":"I agree C is the right answer"},{"poster":"Nirms","upvote_count":"1","content":"C is the correct answer","timestamp":"1591123800.0","comment_id":"101111"},{"timestamp":"1590663600.0","comment_id":"97455","content":"Final Decision to go with Option C","upvote_count":"2","poster":"AD2AD4"},{"timestamp":"1590425880.0","comment_id":"95530","upvote_count":"2","content":"C is the answer","poster":"gcp_aws"},{"comment_id":"88338","poster":"xionis","upvote_count":"1","content":"A. snapshots can be taken without having the VM stopped.","timestamp":"1589381880.0"},{"comments":[{"poster":"okixavi","upvote_count":"2","comment_id":"244656","timestamp":"1608043440.0","content":"you don't need states body, the application is stateless"}],"content":"I think it's B\nSnapshots:\nGood for backup and disaster recovery\nLower cost than images\nSmaller size than images since it doesn't contain OS, etc.\nDifferential backups - only the data changed since the last snapshot is recreated\nFaster to create than images\nSnapshots are only available in the project they are created (now it is possible to share between projects)\nCan be created for running disks even while they are attached to running instances\nImages:\nGood for reusing compute engine instance states with new instances\nAvailable across different projects\nCan't be created for running instances(unless you use --force flag)","timestamp":"1588855620.0","upvote_count":"2","comment_id":"85178","poster":"Applehph"},{"upvote_count":"4","comment_id":"56425","timestamp":"1582879020.0","poster":"[Removed]","content":"Answer: C. Selected C in the exam"},{"poster":"2g","content":"Answer: C","timestamp":"1580395140.0","upvote_count":"2","comment_id":"44821"},{"content":"C is correct; you can create the instance template by exisistinmg vm instance . view https://cloud.google.com/compute/docs/instance-templates/create-instance-templates","comments":[{"timestamp":"1580051580.0","upvote_count":"2","comment_id":"42939","poster":"natpilot","content":"also, You can create disk images from a persistent disk, even while that disk is attached to an instance. view https://cloud.google.com/compute/docs/images/create-delete-deprecate-private-images"}],"upvote_count":"3","comment_id":"42936","timestamp":"1580051340.0","poster":"natpilot"},{"comments":[{"upvote_count":"5","content":"C is ok","timestamp":"1596710100.0","comment_id":"151886","poster":"tartar"},{"comment_id":"210520","timestamp":"1604240280.0","poster":"kumarp6","upvote_count":"1","content":"No it should be C, as you 1st create image and use it to create template"},{"content":"Correct procedure is C","comment_id":"303720","poster":"nitinz","upvote_count":"1","timestamp":"1614902460.0"}],"timestamp":"1578028200.0","upvote_count":"3","comment_id":"34778","poster":"HenryZhang","content":"I think the answer should be A"}],"answer_description":"","answers_community":["C (95%)","5%"],"answer":"C","isMC":true,"exam_id":4,"answer_ET":"C","timestamp":"2020-01-03 06:10:00","unix_timestamp":1578028200,"topic":"1","url":"https://www.examtopics.com/discussions/google/view/11301-exam-professional-cloud-architect-topic-1-question-71/","choices":{"D":"Create an instance template from the existing disk. Create a custom image from the instance template. Create an autoscaled managed instance group from the custom image.","C":"Create a custom image from the existing disk. Create an instance template from the custom image. Create an autoscaled managed instance group from the instance template.","B":"Create a snapshot of the existing disk. Create a custom image from the snapshot. Create an autoscaled managed instance group from the custom image.","A":"Create a snapshot of the existing disk. Create an instance template from the snapshot. Create an autoscaled managed instance group from the instance template."},"answer_images":[],"question_id":170,"question_text":"Your company is running a stateless application on a Compute Engine instance. The application is used heavily during regular business hours and lightly outside of business hours. Users are reporting that the application is slow during peak hours. You need to optimize the application's performance. What should you do?"}],"exam":{"isBeta":false,"lastUpdated":"11 Apr 2025","numberOfQuestions":279,"id":4,"isMCOnly":false,"provider":"Google","isImplemented":true,"name":"Professional Cloud Architect"},"currentPage":34},"__N_SSP":true}