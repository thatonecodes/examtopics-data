{"pageProps":{"questions":[{"id":"An9QPPrLy7ymD46xJzMk","unix_timestamp":1642353720,"timestamp":"2022-01-16 18:22:00","discussion":[{"upvote_count":"5","content":"Selected Answer: C\nFor me C. In link1 we can see how google suggests to use service accounts and in link2 we can see that the invoker role exists.\nLink1: https://cloud.google.com/functions/docs/securing#authentication Link2: https://cloud.google.com/functions/docs/reference/iam/roles#cloud-functions-roles","comment_id":"560227","poster":"fabiam93","timestamp":"1646325960.0"},{"timestamp":"1721629920.0","upvote_count":"1","content":"Selected Answer: C\nThe best answer here is C. Create a service account with the Cloud Functions Invoker role. Use that service account to invoke the function.\n\nHere's why:\n\nCloud Functions Invoker Role: This role specifically grants the permission to invoke Cloud Functions. It's the most granular and appropriate role for this scenario, ensuring that the service account can only invoke Cloud Functions and nothing else.\nLeast Privilege: Using the Cloud Functions Invoker role adheres to the principle of least privilege, granting only the necessary permissions to the service account. This minimizes the risk of unauthorized access or actions.\nService Account Authentication: Service accounts are designed for machine-to-machine authentication. They provide a secure and reliable way to authenticate your calling service to the Cloud Function.","comments":[{"upvote_count":"1","poster":"thewalker","content":"Why other options are less ideal:\n\nA. Identity-Aware Proxy: Identity-Aware Proxy (IAP) is primarily used to secure web applications and APIs, not for controlling access to Cloud Functions.\nB. Cloud Functions Viewer Role: The Cloud Functions Viewer role only allows viewing Cloud Functions, not invoking them. It's not suitable for controlling access to the function.\nD. OAuth 2.0 Client ID: While OAuth 2.0 is a common authentication protocol, it's not the recommended approach for securing Cloud Functions. Service accounts provide a more streamlined and secure method for machine-to-machine authentication.","comment_id":"1252867","timestamp":"1721629920.0","comments":[{"timestamp":"1721629980.0","comment_id":"1252868","poster":"thewalker","content":"In summary: Creating a service account with the Cloud Functions Invoker role and using it to invoke the function is the most secure and efficient way to restrict access to your sensitive data processing function, following Google-recommended best practices.\n\nAdditional Security Considerations:\n\nSecret Management: Store the service account credentials securely using Google Cloud Secret Manager.\nNetwork Security: Consider using VPC Service Controls to further restrict network access to your Cloud Function.\nLogging and Monitoring: Enable logging and monitoring for your Cloud Function to track invocations and identify any potential security issues.","upvote_count":"1"}]}],"comment_id":"1252866","poster":"thewalker"},{"comment_id":"1077830","upvote_count":"1","content":"Selected Answer: C\nIAP is not available for Cloud Functions, so the only possible option is C","timestamp":"1700688000.0","poster":"Aeglas"},{"upvote_count":"1","content":"Selected Answer: A\n1\nThe best way to ensure that invocations of a Cloud Function that processes sensitive data can only happen from authorized services and follows Google-recommended best practices is to enable Identity-Aware Proxy in your project and secure function access using its permissions.","comment_id":"1013139","timestamp":"1695304380.0","poster":"__rajan__","comments":[{"poster":"Aeglas","timestamp":"1700687940.0","upvote_count":"1","comment_id":"1077826","content":"IAP is not available for Cloud Functions"}]},{"upvote_count":"1","poster":"purushi","timestamp":"1691241300.0","content":"Selected Answer: C\nSince this is service to service communication, cloud function invoker role should be provided to the service that wants to invoke cloud function in the data processing pipeline.","comment_id":"973054"},{"content":"Selected Answer: C\nvote c","upvote_count":"1","poster":"Pime13","comment_id":"821488","timestamp":"1677329940.0"},{"poster":"omermahgoub","comment_id":"772225","timestamp":"1673425440.0","comments":[{"content":"Options B and D are not correct. The Cloud Functions Viewer role does not have the necessary permissions to invoke a Cloud Function and creating an OAuth 2.0 client ID for your calling service is not enough to secure a Cloud Function.","poster":"omermahgoub","timestamp":"1673425500.0","comment_id":"772226","upvote_count":"1"},{"content":"You are wrong, as i said why do you over explain stuff and giving out wrong explanations, the documentation doesnt say that, read the question, understand there after answer, your explanation is wrong and misleading. stop with this writing of paragraphs, its annoying to be frank","timestamp":"1675411020.0","comment_id":"796853","poster":"TNT87","upvote_count":"3"}],"upvote_count":"2","content":"Selected Answer: A\nThe best approach is to use a combination of authn, authz, and encryption\n\n1. Enable IAP to ensure that only authenticated and authorized users or services can access Cloud Function\n2. Set up an appropriate level of access control using IAM roles and policies, such as roles/cloudfunctions.invoker, to ensure that only authorized services can invoke your Cloud Function, This can be done by creating a service account for the calling function, assign the appropriate invoker role to the service account on the data processing function and use the service account credentials in the calling function\n3. Use Google-provided libraries or resources, such as KMS or Cloud Storage, to encrypt and store sensitive data\n4. Apply security best practices such as limiting the scope of the service account, and using Cloud IAP to protect access to your Cloud Function\n5. consider using Cloud Event that ensure your function is triggered only by authorized events, you can use Cloud Event to ensure that your function is invoked only by specific event types that you have configured"},{"poster":"zellck","upvote_count":"1","comment_id":"749890","timestamp":"1671458760.0","content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/functions/docs/securing/authenticating"},{"poster":"jcataluna","timestamp":"1670951760.0","content":"Selected Answer: C\nC is correct","comment_id":"744300","upvote_count":"1"},{"content":"ANSWER C\nhttps://medium.com/google-cloud/how-to-securely-invoke-a-cloud-function-from-google-kubernetes-engine-running-on-another-gcp-79797ec2b2c6","timestamp":"1668074880.0","comment_id":"715129","upvote_count":"4","poster":"TNT87"},{"comment_id":"649298","upvote_count":"1","poster":"tomato123","timestamp":"1660976100.0","content":"Selected Answer: D\nI think D is correct"},{"upvote_count":"1","comment_id":"643238","content":"Selected Answer: C\nI will go with option C.","poster":"akshaychavan7","timestamp":"1659771900.0"},{"upvote_count":"2","comment_id":"598982","poster":"mbenhassine1986","content":"C :\nhttps://cloud.google.com/functions/docs/securing/authenticating#authenticating_function_to_function_calls","timestamp":"1652091540.0"},{"upvote_count":"1","poster":"nqthien041292","content":"Selected Answer: C\nVote C","comment_id":"593593","timestamp":"1651127040.0"},{"poster":"KillerGoogle","upvote_count":"1","comment_id":"558042","content":"I believe this is C","timestamp":"1646052360.0"},{"upvote_count":"2","poster":"GCPCloudArchitectUser","comments":[{"poster":"fabiam93","content":"Why not C?\nIn link1 we can see how google suggests to use service accounts and in link2 we can see that the invoker role exists.\nLink1: https://cloud.google.com/functions/docs/securing#authentication\nLink2: https://cloud.google.com/functions/docs/reference/iam/roles#cloud-functions-roles","upvote_count":"2","timestamp":"1646325900.0","comment_id":"560225"}],"timestamp":"1645930140.0","comment_id":"557107","content":"Selected Answer: D\nAgreed D … \n\nFrom link reference below \nThe tokens themselves are created using the OAuth 2 framework, and its extension, Open Identity Connect, but the sequence is complex and error-prone, and the use of Cloud Client Libraries to manage the process is highly recommended."},{"timestamp":"1643829840.0","upvote_count":"2","poster":"ZOZOKOU","comment_id":"539124","content":"Option D.\nhttps://cloud.google.com/functions/docs/securing"},{"poster":"Blueocean","timestamp":"1642353720.0","comment_id":"525099","content":"Probably Option D is better than C?","upvote_count":"3"}],"isMC":true,"choices":{"B":"Create a service account with the Cloud Functions Viewer role. Use that service account to invoke the function.","A":"Enable Identity-Aware Proxy in your project. Secure function access using its permissions.","C":"Create a service account with the Cloud Functions Invoker role. Use that service account to invoke the function.","D":"Create an OAuth 2.0 client ID for your calling service in the same project as the function you want to secure. Use those credentials to invoke the function."},"answer_images":[],"answers_community":["C (68%)","D (16%)","A (16%)"],"question_text":"Your team develops services that run on Google Cloud. You need to build a data processing service and will use Cloud Functions. The data to be processed by the function is sensitive. You need to ensure that invocations can only happen from authorized services and follow Google-recommended best practices for securing functions. What should you do?","exam_id":7,"answer":"C","topic":"1","answer_ET":"C","url":"https://www.examtopics.com/discussions/google/view/70128-exam-professional-cloud-developer-topic-1-question-126/","question_id":31,"answer_description":"","question_images":[]},{"id":"r7Cf8ckYvfNfJ8BHSNr3","question_text":"You are deploying your applications on Compute Engine. One of your Compute Engine instances failed to launch. What should you do? (Choose two.)","timestamp":"2022-01-07 07:06:00","answer_ET":"AD","question_id":32,"exam_id":7,"answer_images":[],"answer":"AD","question_images":[],"discussion":[{"poster":"thewalker","content":"Selected Answer: AD\nWhen a Compute Engine instance fails to launch, you should consider various factors that could cause the failure. Here are the two most relevant actions to take:\n\nA. Determine whether your file system is corrupted.\n\nA corrupted file system can prevent the instance from booting properly. You can check and repair the file system using a recovery process, such as attaching the boot disk to another instance for analysis.\nD. Check whether your instance boot disk is completely full.\n\nIf the boot disk is full, the instance may not be able to start because the operating system needs some free disk space to function properly. You can check the disk usage and free up space if necessary.","upvote_count":"1","comments":[{"content":"Other Options:\n\nB. Access Compute Engine as a different SSH user.\n\nWhile accessing as a different SSH user might help if you have SSH access issues, it is unlikely to resolve a failure to launch the instance itself.\nC. Troubleshoot firewall rules or routes on an instance.\n\nFirewall rules and routes affect network traffic to and from the instance but are less likely to be the root cause of a launch failure.\nE. Check whether network traffic to or from your instance is being dropped.\n\nSimilar to option C, dropped network traffic impacts connectivity but is not a primary cause for an instance failing to launch.\nTherefore, the most appropriate actions are A and D to diagnose and resolve issues preventing your Compute Engine instance from launching.","comment_id":"1252872","poster":"thewalker","upvote_count":"1","timestamp":"1721630460.0"}],"timestamp":"1721630400.0","comment_id":"1252871"},{"timestamp":"1713327180.0","content":"Selected Answer: AD\nA & D\nhttps://cloud.google.com/compute/docs/troubleshooting/vm-startup#identify_the_reason_why_the_boot_disk_isnt_booting\n\n\nNetwork issues shouldn't stop a compute engine from booting up so C & E are out. \nB cant be true because how can u SSH if it doesnt boot","comment_id":"1196975","poster":"alpha_canary","upvote_count":"2"},{"content":"Selected Answer: AD\nI will go with AD.","poster":"__rajan__","timestamp":"1695304560.0","upvote_count":"1","comment_id":"1013144"},{"content":"Selected Answer: AD\nCompute engine will not launch when either of these happens.\n1) When its file system is corrupted.\n2) When its boot disk is full.","timestamp":"1691241540.0","poster":"purushi","upvote_count":"2","comment_id":"973057"},{"poster":"Pime13","upvote_count":"4","timestamp":"1677330000.0","content":"Selected Answer: AD\nhttps://cloud.google.com/compute/docs/troubleshooting/vm-startup#identify_the_reason_why_the_boot_disk_isnt_booting\n- Verify that your boot disk is not full.\nIf your boot disk is completely full and your operating system does not support automatic resizing, you won't be able to connect to your instance. You must create a new instance and recreate the boot disk.\n\n- Verify that your disk has a valid file system.\nIf your file system is corrupted or otherwise invalid, you won't be able to launch your instance.","comment_id":"821490"},{"upvote_count":"3","poster":"zellck","timestamp":"1671450780.0","content":"Selected Answer: AD\nAD is the answer.\n\nhttps://cloud.google.com/compute/docs/troubleshooting/vm-startup#identify_the_reason_why_the_boot_disk_isnt_booting\n- Verify that your boot disk is not full.\nIf your boot disk is completely full and your operating system does not support automatic resizing, you won't be able to connect to your instance. You must create a new instance and recreate the boot disk. \n\n- Verify that your disk has a valid file system.\nIf your file system is corrupted or otherwise invalid, you won't be able to launch your instance.","comment_id":"749783"},{"poster":"tomato123","timestamp":"1660976100.0","comment_id":"649299","content":"Selected Answer: AD\nAD are correct","upvote_count":"4"},{"content":"Selected Answer: AD\nA and D seem right here.","timestamp":"1659772080.0","poster":"akshaychavan7","upvote_count":"2","comment_id":"643240"},{"upvote_count":"3","content":"Selected Answer: AD\nVote AD","comment_id":"593595","timestamp":"1651127160.0","poster":"nqthien041292"},{"content":"Options D for sure , in the rest Option A seems the nearest one as one of the troubleshooting steps is to check the file system","upvote_count":"2","comment_id":"525101","timestamp":"1642354020.0","poster":"Blueocean"},{"upvote_count":"2","poster":"Erso","timestamp":"1641914640.0","content":"A & D! \nIf the failure is on the launch changing the SSH user will not help. Network traffic, Network routes, Firewall rules...are not influencing the instance boot!","comment_id":"521611"},{"comment_id":"520050","poster":"ParagSanyashiv","content":"AD should be the correct one, because launching VM failure does not depends on network connectivity of that VM. Network comes into the picture when vm boots.","timestamp":"1641718620.0","upvote_count":"3"},{"poster":"HotSpa27","timestamp":"1641535560.0","comment_id":"518793","upvote_count":"3","content":"I vote AD.\nhttps://cloud.google.com/compute/docs/troubleshooting/vm-startup\nVerify that your disk has a valid file system.　\nVerify that your boot disk is not full."}],"choices":{"A":"Determine whether your file system is corrupted.","B":"Access Compute Engine as a different SSH user.","D":"Check whether your instance boot disk is completely full.","C":"Troubleshoot firewall rules or routes on an instance.","E":"Check whether network traffic to or from your instance is being dropped."},"unix_timestamp":1641535560,"answer_description":"","topic":"1","isMC":true,"url":"https://www.examtopics.com/discussions/google/view/69612-exam-professional-cloud-developer-topic-1-question-127/","answers_community":["AD (100%)"]},{"id":"ZN5HQkwcY0WXphBgw3BE","answers_community":["B (67%)","C (33%)"],"answer_description":"","unix_timestamp":1642354200,"question_id":33,"topic":"1","question_images":[],"discussion":[{"comments":[{"poster":"TNT87","upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"753192","poster":"tuanbo91","timestamp":"1671705300.0","comments":[{"content":"If its B, it must not use public IP, That makes B wrong. the answer is C. its already in coorporate intranet, why use public IP?","poster":"TNT87","comments":[{"upvote_count":"1","content":"How the users are going to authenticate to Compute Engine?","timestamp":"1675773600.0","poster":"mrvergara","comment_id":"800883"},{"comments":[{"comment_id":"796858","poster":"TNT87","timestamp":"1675411320.0","content":"But the question says they are using intranet. hence im saying it cant be B because yes IAP is ok, but why public IP yet they are on cooperate intranet, that makes C the best option","upvote_count":"1"},{"comment_id":"1048044","upvote_count":"1","poster":"haroonob","content":"It is clearly mentioned “You need to migrate the web application to Google Cloud” so no more intranet. B is correct answer","timestamp":"1697727240.0"}],"timestamp":"1675273560.0","content":"A public IP address is not necessary to use Google Cloud Identity-Aware Proxy (IAP). IAP can be used to secure resources in Google Cloud, such as Google Cloud Storage buckets or Google App Engine applications, without requiring a public IP address. However, you may need a public IP address if you want to allow access to your resources from the internet.","poster":"mrvergara","comment_id":"795371","upvote_count":"2"},{"timestamp":"1690319460.0","upvote_count":"1","poster":"giovanicascaes","content":"I read as: the application is being moved from the intranet to Google Cloud. So there will not be an intranet anymore and a public IP address makes sense","comment_id":"963126"}],"timestamp":"1671963000.0","comment_id":"755576","upvote_count":"1"}],"content":"it's Google public IP, https://cloud.google.com/iap/docs/managing-access"}],"comment_id":"720264","timestamp":"1668666360.0","content":"why public IP yet it must only be accessible to the employees only? B is wrong"}],"content":"Agree with Option B","timestamp":"1642354200.0","upvote_count":"9","poster":"Blueocean","comment_id":"525103"},{"comments":[{"comment_id":"1252880","upvote_count":"1","timestamp":"1721631180.0","content":"Accessibility for Traveling Employees: IAP allows employees to access the application from anywhere with an internet connection, as long as they have the necessary credentials. This eliminates the need for VPNs or other complex network configurations.\nCentralized Management: IAP simplifies security management by providing a centralized platform for controlling access to your application. You can easily add or remove users, define access policies, and monitor activity.\nWhy other options are less ideal:\n\nA. Authentication in the Application: This approach requires significant changes to your web application to handle authentication logic, which can be complex and error-prone. It also doesn't provide the same level of security and centralized management as IAP.","poster":"thewalker","comments":[{"comment_id":"1252881","poster":"thewalker","content":"C. Proxy Compute Engine Instance: While this approach could work, it requires setting up and managing a separate Compute Engine instance, which adds complexity and overhead. It also doesn't leverage the built-in security features of IAP.\nD. HTTP Redirect: This approach would expose your web application's public IP address, potentially compromising security. It also doesn't provide the same level of authentication and authorization as IAP.\nIn summary: Identity-Aware Proxy is the most efficient and secure way to migrate your web application to Google Cloud while ensuring accessibility for traveling employees and minimizing application changes. It provides a robust and centralized solution for authentication, authorization, and secure access control.","upvote_count":"1","timestamp":"1721631180.0"}]}],"upvote_count":"2","content":"Selected Answer: B\nThe best solution here is B. Configure Identity-Aware Proxy to allow employees to access the application through its public IP address.\n\nHere's why:\n\nMinimal Application Changes: Identity-Aware Proxy (IAP) is designed to handle authentication and authorization without requiring significant changes to your web application. It acts as a secure gateway, intercepting requests and verifying user identities before forwarding them to your application.\nSecure Access: IAP provides strong security by integrating with your existing corporate identity provider (e.g., Google Workspace, Active Directory). It ensures that only authorized employees with valid credentials can access the application.","timestamp":"1721631180.0","poster":"thewalker","comment_id":"1252879"},{"content":"Selected Answer: B\nB is the answer. IAP is the solution in these kind of scenarios. \nDon't be alerted by mention of public IP. It's completely fine to deploy an internal app on public IP as long as u have proper authentication. Since the question mentions \"accessible to employees as they travel\", this is how many companies deploy such internal tools.","poster":"alpha_canary","upvote_count":"1","comment_id":"1196976","timestamp":"1713327360.0"},{"poster":"__rajan__","content":"Selected Answer: B\nI will go with B.","upvote_count":"1","comment_id":"1013150","timestamp":"1695304860.0"},{"content":"Selected Answer: B\ni'd choose b: https://cloud.google.com/blog/topics/developers-practitioners/control-access-your-web-sites-identity-aware-proxy","comment_id":"823727","timestamp":"1677504240.0","poster":"Pime13","upvote_count":"2"},{"comment_id":"772237","upvote_count":"2","poster":"omermahgoub","timestamp":"1673425980.0","content":"Selected Answer: C\nThis approach allows you to use Google Cloud infrastructure to authenticate users against the corporate intranet before providing access to the web application, without making major changes to the web application. By configuring a Compute Engine instance as a proxy and changing the web application's DNS to point to this proxy, you can ensure that only employees who have been authenticated against the corporate intranet are able to access the web application. This approach also allows the employees to access the web application while they are traveling, as long as they have internet access.","comments":[{"comments":[{"comment_id":"772239","timestamp":"1673426040.0","poster":"omermahgoub","upvote_count":"1","content":"Additionally, IAP is designed to work with resources that are hosted on Google Cloud, and it may not be possible to configure it to work with an intranet-hosted application without making significant changes to the application and the intranet infrastructure.\n\nThat's why the best solution would be to use a VPN connection or a reverse proxy to allow employees to access the application as if they were on the intranet while they are traveling or to secure the access to the intranet-hosted web application from the internet."}],"poster":"omermahgoub","upvote_count":"1","comment_id":"772238","content":"Identity-Aware Proxy (IAP) is a feature of Google Cloud Platform that allows you to secure access to resources by using identity and context-based access control. IAP allows you to restrict access to a resource (such as a web application) to only authenticated and authorized users or service accounts.\n\nHowever, in this scenario, since the web application is hosted on the corporate intranet, it will not have a public IP address and it will not be accessible from the internet. And It's not possible to use IAP to restrict access to an intranet-hosted application by its IP address.","timestamp":"1673425980.0"}]},{"timestamp":"1671450600.0","poster":"zellck","upvote_count":"2","content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/iap/docs/concepts-overview\nIAP lets you establish a central authorization layer for applications accessed by HTTPS, so you can use an application-level access control model instead of relying on network-level firewalls.\n\nIAP policies scale across your organization. You can define access policies centrally and apply them to all of your applications and resources. When you assign a dedicated team to create and enforce policies, you protect your project from incorrect policy definition or implementation in any application.","comment_id":"749782"},{"content":"Selected Answer: B\nB, while employees are traveling, they don't have access to the intranet, so they need to use the public IP. IAP secures the public endpoint.","poster":"micoams","comment_id":"749196","upvote_count":"3","timestamp":"1671397980.0"},{"upvote_count":"3","content":"Selected Answer: C\nC seems right","comment_id":"649301","poster":"tomato123","timestamp":"1660976220.0"},{"poster":"akshaychavan7","comment_id":"643241","upvote_count":"2","content":"Selected Answer: C\nI would completely agree with BackendBoi's comment. I would have picked option B only if it would have not been said to access through public IP. Out of all the options, option C seems the best pick. I had read somewhere that the proxy compute engine is used for securing access to main compute engine instance hosting application.","timestamp":"1659772680.0"},{"poster":"BackendBoi","comment_id":"582352","upvote_count":"3","comments":[{"comment_id":"603371","content":"You couldn't opt anyone ? I suggest you to skip this in exam :)","poster":"dishum","timestamp":"1652891460.0","upvote_count":"1"}],"content":"I tend to C. A is bad because sending the credentials in each HTTP(s) request is bad and inefficient. B requires each user to have a Google Workspace account, which is not a given for the corporate intranet. On top of that there is no mention that the application checks for the token in the header, so a public IP would still expose the application. C would work, but its ineffective. D is useless if the application is still exposed through the public IP. None of these solutions are great, but C is the least bad of the bunch.","timestamp":"1649326320.0"}],"answer_ET":"B","url":"https://www.examtopics.com/discussions/google/view/70129-exam-professional-cloud-developer-topic-1-question-128/","answer":"B","exam_id":7,"question_text":"Your web application is deployed to the corporate intranet. You need to migrate the web application to Google Cloud. The web application must be available only to company employees and accessible to employees as they travel. You need to ensure the security and accessibility of the web application while minimizing application changes. What should you do?","timestamp":"2022-01-16 18:30:00","answer_images":[],"choices":{"D":"Configure a Compute Engine instance that requests users to log in to their corporate account. Change the web application DNS to point to the proxy Compute Engine instance. After authenticating, the Compute Engine issues an HTTP redirect to a public IP address hosting the web application.","B":"Configure Identity-Aware Proxy to allow employees to access the application through its public IP address.","A":"Configure the application to check authentication credentials for each HTTP(S) request to the application.","C":"Configure a Compute Engine instance that requests users to log in to their corporate account. Change the web application DNS to point to the proxy Compute Engine instance. After authenticating, the Compute Engine instance forwards requests to and from the web application."},"isMC":true},{"id":"SVPAHqG1H0vAODefhrtK","answer_ET":"D","isMC":true,"answer_description":"","answers_community":["D (100%)"],"answer":"D","timestamp":"2022-01-09 16:21:00","topic":"1","choices":{"D":"Access-Control-Allow-origin: https://www.example.com","C":"Access-Control-Allow-Origin: https://fn.example.com","A":"Access-Control-Allow-Origin: *","B":"Access-Control-Allow-Origin: https://*.example.com"},"unix_timestamp":1641741660,"url":"https://www.examtopics.com/discussions/google/view/69757-exam-professional-cloud-developer-topic-1-question-129/","question_text":"You have an application that uses an HTTP Cloud Function to process user activity from both desktop browser and mobile application clients. This function will serve as the endpoint for all metric submissions using HTTP POST.\nDue to legacy restrictions, the function must be mapped to a domain that is separate from the domain requested by users on web or mobile sessions. The domain for the Cloud Function is https://fn.example.com. Desktop and mobile clients use the domain https://www.example.com. You need to add a header to the function's\nHTTP response so that only those browser and mobile sessions can submit metrics to the Cloud Function. Which response header should you add?","question_images":[],"answer_images":[],"exam_id":7,"question_id":34,"discussion":[{"comment_id":"1253397","content":"Selected Answer: D\nThe correct answer is D. Access-Control-Allow-origin: https://www.example.com . Here's why:\n\nCORS (Cross-Origin Resource Sharing): The scenario you've described involves a classic CORS issue. Your Cloud Function (on https://fn.example.com ) is being accessed from a different origin ( https://www.example.com ). Browsers have security restrictions that prevent requests from one domain to another without explicit permission.\nAccess-Control-Allow-Origin Header: This header is used to tell the browser which origins are allowed to make requests to your Cloud Function.","timestamp":"1721706240.0","poster":"thewalker","upvote_count":"1"},{"timestamp":"1695305220.0","comment_id":"1013153","content":"Selected Answer: D\nD is correct.","poster":"__rajan__","upvote_count":"1"},{"poster":"purushi","content":"Selected Answer: D\nIt is like requesting service from front end to back-end service. Here front-end service domain is https://www.example.com and back-end service domain where cloud function runs is https://fn.example.com","upvote_count":"1","timestamp":"1691242380.0","comment_id":"973068"},{"comment_id":"821494","timestamp":"1677330300.0","upvote_count":"2","poster":"Pime13","content":"Selected Answer: D\nvote d"},{"timestamp":"1671450240.0","upvote_count":"1","comment_id":"749775","poster":"zellck","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/functions/docs/samples/functions-http-cors"},{"comment_id":"649302","timestamp":"1660976220.0","content":"Selected Answer: D\nD is correct","upvote_count":"2","poster":"tomato123"},{"timestamp":"1648570560.0","content":"I agree with D but just a little detail (idk if it was a typo) ... the word \"origin\" must be \"Origin\"... besides that seems correct","upvote_count":"4","poster":"htakami","comment_id":"577716"},{"content":"Selected Answer: D\nI agree it should be D","poster":"GCPCloudArchitectUser","comment_id":"557110","upvote_count":"4","timestamp":"1645930560.0"},{"poster":"Blueocean","comment_id":"525106","content":"Should be Option D, Option A will allow all and not only specific as requested in the question","timestamp":"1642354500.0","upvote_count":"3"},{"timestamp":"1641741660.0","poster":"scaenruy","content":"I vote D","upvote_count":"2","comment_id":"520286"}]},{"id":"WSmswIit9ug9UriQA5bs","choices":{"A":"Include multiple rows with each request.","D":"Write each row to a Cloud Storage object in parallel, then load into BigQuery.","B":"Perform the inserts in parallel by creating multiple threads.","C":"Write each row to a Cloud Storage object, then load into BigQuery."},"discussion":[{"poster":"fraloca","content":"For me the correct answer is A.\nInfact the loop build a single InsertReqeust and send it.\nBut we can build all request in a list and use InsertAllRequest.newBuilder(tableId).setRows(rows).build() to send.\nhttps://cloud.google.com/bigquery/streaming-data-into-bigquery#streaminginsertexamples","comment_id":"243820","timestamp":"1607970000.0","upvote_count":"24"},{"timestamp":"1640167620.0","upvote_count":"6","comment_id":"506958","content":"Selected Answer: B\nResponse should be A, because original code pushes one row at a time, which is more time consuming in contrast to batch processing. \n\nProposed answer C is incorrect, because we still have more overhead in sending each row in separate request than using batch processing.","poster":"TrueCurry"},{"poster":"d_ella2001","upvote_count":"1","content":"Selected Answer: A\nCorrect answer A: Batching Rows: By batching multiple rows into a single request, you minimise the overhead of network communication and API call latency. BigQuery's InsertAllRequest supports inserting multiple rows in a single API call.\nParallel Inserts (Option B): While parallel processing can improve performance, it introduces complexity and may require handling concurrency issues. It's generally better to batch rows first.\nWriting to Cloud Storage (Options C & D): Writing data to Cloud Storage and then loading it into BigQuery can be efficient for very large datasets, but it adds extra steps and complexity. It's more suitable for bulk load operations rather than small, frequent inserts.","comment_id":"1247137","timestamp":"1720851300.0"},{"poster":"thewalker","content":"For smaller datasets or when simplicity is paramount: Including multiple rows with each request is often sufficient.\nFor larger datasets or when performance is critical: Parallel inserts are the way to go.","timestamp":"1720613580.0","comment_id":"1245470","upvote_count":"1"},{"poster":"santoshchauhan","comment_id":"1168129","content":"Selected Answer: A\nA. Include multiple rows with each request:\nThis would be a very efficient way to batch the insert operations. BigQuery's insertAll method supports batched inserts, so instead of inserting each row in a separate request, you could group multiple rows into a single insertAll request. This approach reduces the number of HTTP requests made to the BigQuery service, which can improve throughput and reduce the risk of hitting rate limits.","upvote_count":"1","timestamp":"1709824740.0"},{"upvote_count":"1","poster":"gingrick","timestamp":"1700507400.0","comment_id":"1075778","content":"Selected Answer: B\nB - I was between A and B. Both options require changes in the code and Option B requires changes in the way you are managing the Collection. If you insert multiples rows at a time, you would still need to move through the ROWS in the collection one by one (remember, this is a loop) to then insert in bulk. If you first break the Collection into (n) subsets and then run the function in (n) threats, you would be moving through (n) subsets at a time, making (n) insertions at a time, all in parallel. That was my way of viewing it.\n\nOption A would actually not even make a change in performance (sort of), you would just be interacting with the database less. (if interacting less in faster then you would see a small decrease in insert latencies)"},{"comment_id":"1011389","poster":"__rajan__","content":"Selected Answer: A\nI would go with A.","upvote_count":"1","timestamp":"1695131040.0"},{"upvote_count":"1","content":"Selected Answer: A\ni'd choose A. for me it's same as batch insert/update recommended","comment_id":"823855","timestamp":"1677510300.0","poster":"Pime13"},{"poster":"mrvergara","comment_id":"799623","content":"Selected Answer: A\nA. Include multiple rows with each request.\n\nBatch inserts are more efficient than individual inserts and will increase write performance by reducing the overhead of creating and sending individual requests for each row. Parallel inserts could potentially lead to conflicting writes or cause resource exhaustion, and adding a step of writing to Cloud Storage and then loading into BigQuery can add additional overhead and complexity.","timestamp":"1675680120.0","upvote_count":"1"},{"comment_id":"795913","poster":"Foxal","upvote_count":"1","timestamp":"1675329840.0","content":"Selected Answer: A\nA is the corret answer"},{"upvote_count":"1","timestamp":"1674072540.0","content":"Selected Answer: A\nanswer A, biquery support multiple insert in one request\nhttps://cloud.google.com/bigquery/docs/samples/bigquery-table-insert-rows","poster":"telp","comment_id":"780387"},{"content":"A. Include multiple rows with each request.\n\nIt is generally more efficient to insert multiple rows in a single request, rather than making a separate request for each row. This reduces the overhead of making multiple HTTP requests, and can also improve performance by allowing BigQuery to perform more efficient batch operations. You can use the InsertAllRequest.RowToInsert.of(row) method to add multiple rows to a single request","comments":[{"comments":[{"comment_id":"763226","content":"Options B and D, which involve using multiple threads to perform the inserts or write the rows to Cloud Storage, may not necessarily improve the efficiency of the code. These options could potentially increase the complexity of the code and introduce additional overhead, without necessarily improving the performance of the inserts.\n\nOption C, writing each row to a Cloud Storage object before loading into BigQuery, would likely be less efficient than simply inserting the rows directly into BigQuery. It would involve additional steps and potentially increase the overall time it takes to write the rows to the table.","poster":"omermahgoub","upvote_count":"1","timestamp":"1672583760.0"}],"comment_id":"763225","timestamp":"1672583640.0","poster":"omermahgoub","upvote_count":"1","content":"For example, you could modify the code to collect the rows in a list and insert them in batches:\n\nList<InsertAllRequest.RowToInsert> rowsToInsert = new ArrayList<>();\nfor (Map<String, String> row : rows) {\n rowsToInsert.add(InsertAllRequest.RowToInsert.of(row));\n if (rowsToInsert.size() == BATCH_SIZE) {\n InsertAllRequest insertRequest = InsertAllRequest.newBuilder(\n \"datasetId\", \"tableId\", rowsToInsert).build();\n service.insertAll(insertRequest);\n rowsToInsert.clear();\n }\n}\nif (!rowsToInsert.isEmpty()) {\n InsertAllRequest insertRequest = InsertAllRequest.newBuilder(\n \"datasetId\", \"tableId\", rowsToInsert).build();\n service.insertAll(insertRequest);\n}\n\nThis will insert the rows in batches of BATCH_SIZE, which you can adjust based on the desired balance between performance and resource usage."}],"poster":"omermahgoub","comment_id":"763224","timestamp":"1672583640.0","upvote_count":"1"},{"timestamp":"1670787060.0","content":"Selected Answer: A\nvote A","comment_id":"742031","upvote_count":"1","poster":"test010101"},{"upvote_count":"1","content":"Selected Answer: A\nOriginal code inserts one row at a time so no point on using parallel requests..","poster":"jcataluna","comment_id":"731781","timestamp":"1669828200.0"},{"poster":"thaipad","content":"Selected Answer: A\nParallel saving to the database can increase the total addition time and depends on many system conditions. While batch saving is optimized at the database core level.","comment_id":"657042","timestamp":"1662099240.0","upvote_count":"1"},{"poster":"tomato123","upvote_count":"2","content":"Selected Answer: B\nB is correct","timestamp":"1660973340.0","comment_id":"649171"},{"upvote_count":"1","timestamp":"1660949520.0","comment_id":"649109","poster":"kinoko1330","content":"Selected Answer: A\nhttps://cloud.google.com/bigquery/docs/samples/bigquery-table-insert-rows"},{"poster":"akshaychavan7","comments":[{"timestamp":"1660724160.0","comment_id":"647984","content":"Agree A. Did you take the exam?","upvote_count":"1","poster":"alex8081"}],"timestamp":"1660109280.0","upvote_count":"1","content":"Selected Answer: A\nThis should be A.","comment_id":"644794"},{"upvote_count":"1","comment_id":"635532","timestamp":"1658572140.0","content":"Selected Answer: A\nBatch insert","poster":"nehaxlpb"},{"content":"I vote A because multiple rows can be inserted directly within one request: \n\nInsertAllRequest.Builder builder = InsertAllRequest.newBuilder(tableId);\nrows.forEach(builder::addRow);\nInsertAllRequest rows = builder.build();\nInsertAllResponse response = bigquery.insertAll(rows);","poster":"Elson","upvote_count":"1","comment_id":"575765","timestamp":"1648326300.0"},{"poster":"wilwong","content":"I think B is the best choice","upvote_count":"1","comment_id":"413568","timestamp":"1627180080.0"},{"poster":"yuchun","comment_id":"389273","upvote_count":"1","content":"I will choose B, C/D are 2 phase insertion, A doesn't improve the whole time of insertion.","timestamp":"1624515840.0"},{"content":"I would go for D based on the following links:\nhttps://aus800.com.au/bigquery-parallel-loading/\nhttps://cloud.google.com/bigquery/docs/batch-loading-data","comments":[{"poster":"syu31svc","comment_id":"417792","content":"Changing to A as instead of inserting each record multiple records can be clubbed to trigger a single batch insert request.","timestamp":"1627723500.0","upvote_count":"5"}],"comment_id":"386015","poster":"syu31svc","timestamp":"1624172880.0","upvote_count":"1"},{"comment_id":"290377","poster":"maxdanny","upvote_count":"3","content":"Answer is B, because with multithreading the process insert time is reduced, the map has a large number undefined of rows","timestamp":"1613318040.0"},{"upvote_count":"4","comment_id":"269799","content":"Answer is A","poster":"maleksah","timestamp":"1610914620.0"}],"topic":"1","answer_ET":"A","timestamp":"2020-12-14 19:20:00","unix_timestamp":1607970000,"answers_community":["A (59%)","B (41%)"],"exam_id":7,"question_id":35,"question_text":"Your teammate has asked you to review the code below. Its purpose is to efficiently add a large number of small rows to a BigQuery table.\n//IMG//\n\nWhich improvement should you suggest your teammate make?","answer_description":"","isMC":true,"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/39863-exam-professional-cloud-developer-topic-1-question-13/","answer":"A","question_images":["https://www.examtopics.com/assets/media/exam-media/04137/0000900001.jpg"]}],"exam":{"isBeta":false,"isImplemented":true,"isMCOnly":false,"lastUpdated":"11 Apr 2025","numberOfQuestions":338,"provider":"Google","name":"Professional Cloud Developer","id":7},"currentPage":7},"__N_SSP":true}