{"pageProps":{"questions":[{"id":"li6GIA386SjcIpFi7Y1G","question_images":[],"question_id":151,"exam_id":6,"answer_description":"","answer_images":[],"unix_timestamp":1635278940,"question_text":"You are deploying an application that needs to access sensitive information. You need to ensure that this information is encrypted and the risk of exposure is minimal if a breach occurs. What should you do?","timestamp":"2021-10-26 22:09:00","answer_ET":"A","topic":"1","url":"https://www.examtopics.com/discussions/google/view/64852-exam-professional-cloud-devops-engineer-topic-1-question-58/","answers_community":["A (100%)"],"answer":"A","discussion":[{"upvote_count":"11","timestamp":"1667056680.0","poster":"giammydell","content":"Ans: A","comment_id":"469827"},{"poster":"jomonkp","timestamp":"1733138640.0","upvote_count":"1","content":"Selected Answer: A\nOption A","comment_id":"1086118"},{"upvote_count":"1","poster":"JonathanSJ","comment_id":"776032","timestamp":"1705275480.0","content":"Selected Answer: A\nA. Store the encryption keys in Cloud Key Management Service (KMS) and rotate the keys frequently. This ensures that the sensitive information is encrypted at rest and in transit, and that the encryption keys are regularly rotated to minimize the risk of exposure in the event of a breach."},{"content":"Selected Answer: A\nA) should be the correct answer.","poster":"WhyIronMan","timestamp":"1701883380.0","upvote_count":"1","comment_id":"737038"},{"comment_id":"700591","upvote_count":"2","timestamp":"1697871600.0","poster":"ssmb","content":"A should be the correct answer."},{"comment_id":"679339","poster":"ramzez4815","content":"Selected Answer: A\nThe clear answer is A","upvote_count":"1","timestamp":"1695695100.0"},{"poster":"emdee202","timestamp":"1682176440.0","content":"Selected Answer: A\nAns: A","comment_id":"590079","upvote_count":"1"},{"timestamp":"1674196200.0","poster":"Sekierer","upvote_count":"1","content":"A is correct","comment_id":"528188"},{"upvote_count":"1","timestamp":"1666944900.0","content":"https://cloud.google.com/security-key-management","comment_id":"469092","poster":"TNT87"},{"upvote_count":"2","content":"Ans is A.","poster":"TNT87","comment_id":"469091","timestamp":"1666944840.0"},{"upvote_count":"3","poster":"Alaaelanwr","timestamp":"1666814940.0","content":"Ans: A","comment_id":"468249"}],"choices":{"A":"Store the encryption keys in Cloud Key Management Service (KMS) and rotate the keys frequently","B":"Inject the secret at the time of instance creation via an encrypted configuration management system.","D":"Leverage a continuous build pipeline that produces multiple versions of the secret for each instance of the application.","C":"Integrate the application with a Single sign-on (SSO) system and do not expose secrets to the application."},"isMC":true},{"id":"BY7vobUiBMrquKLolkNF","question_images":[],"exam_id":6,"answer_ET":"A","isMC":true,"choices":{"C":"Distribute the alerts to engineers in different time zones.","B":"Create an incident report for each of the alerts.","D":"Redefine the related Service Level Objective so that the error budget is not exhausted.","A":"Eliminate unactionable alerts."},"answer_description":"","answer":"A","unix_timestamp":1635265980,"question_id":152,"topic":"1","discussion":[{"comment_id":"471392","comments":[{"upvote_count":"1","poster":"MF2C","timestamp":"1651894920.0","content":"A or C","comment_id":"473755"}],"content":"I reckon its A, the reason is because it seems like the problem is automatically fixed with an restart of the service after a minute, therefore engineers don't really need to be woken up about these problems. If it failed multiple times or if the restart failed, then the engineer should be woken up","timestamp":"1651428120.0","upvote_count":"14","poster":"AL12"},{"poster":"09bd94b","upvote_count":"1","timestamp":"1739882820.0","content":"Selected Answer: A\nAgree with A. It does not make sense to wake up an engineer when you know that there is no need for any remedy action","comment_id":"1358295"},{"upvote_count":"2","content":"Selected Answer: A\nI agree with A.","poster":"JonathanSJ","comment_id":"776049","timestamp":"1689372600.0"},{"comment_id":"762633","upvote_count":"2","poster":"Greg123123","timestamp":"1688120760.0","content":"Selected Answer: A\nIt should be A rather than D.\nTo follow SRE practice, we should eliminate unactionable alert which is pointless and to increase precision. While D also looks valid, the question never say that the application is being affected (e.g. has downtime), and never says any actions are needed. As a result, there is no need to redefine SLI and since they didn't spend time to resolve it no error budget is spent."},{"content":"Between A and C, B and D answers are not good.\nI lean more towards A because those alerts seem unactionable a the moment alert is received, ie: machine restarted automatically already.\nThis would be best imidiate action as per the question. Of course the source of alerts should be looked at and fixed separately from addressing the issue in question.","comment_id":"700596","upvote_count":"2","timestamp":"1682060760.0","poster":"ssmb"},{"poster":"[Removed]","upvote_count":"1","timestamp":"1672134960.0","content":"I agree with A.\n\nEliminate bad monitoring : Unactionable alerts (i.e., spam)\n\nhttps://cloud.google.com/blog/products/management-tools/meeting-reliability-challenges-with-sre-principles","comment_id":"623138"},{"upvote_count":"4","timestamp":"1661089860.0","content":"Selected Answer: A\nagree with kyubiblaze about having to remove unactionable items aka spam: \"good monitoring alerts on actionable problems\" @ https://cloud.google.com/blog/products/management-tools/meeting-reliability-challenges-with-sre-principles","comment_id":"552974","poster":"zygomar"},{"comment_id":"528189","timestamp":"1658291400.0","poster":"Sekierer","upvote_count":"1","content":"A is correct"},{"content":"A - You have to remove \"unactionable\" alerts, these alerts are useless if you can't take any action.\nSimple reason, C might be following SRE practice, but it is distributing the problem, not solving it.\nB and D, totally No.","upvote_count":"3","poster":"KyubiBlaze","comment_id":"524699","timestamp":"1657947960.0"},{"timestamp":"1656586020.0","content":"answer is c. it follows google SRE and prevents staff burnout. https://sre.google/workbook/team-lifecycles/","upvote_count":"1","poster":"gcpz","comment_id":"513363"},{"timestamp":"1654452000.0","comment_id":"494616","content":"The team may continue to work on non-reliability features if:\n\nThe outage was caused by a company-wide networking problem.\nThe outage was caused by a service maintained by another team, who have themselves frozen releases to address their reliability issues.\nThe error budget was consumed by users out of scope for the SLO (e.g., load tests or penetration testers).\nMiscategorized errors consume budget even though no users were impacted.\n\nhttps://sre.google/workbook/error-budget-policy/","comments":[{"content":"Correct Answer is (D):","timestamp":"1654452060.0","upvote_count":"2","comment_id":"494617","poster":"ESP_SAP"}],"poster":"ESP_SAP","upvote_count":"3"},{"poster":"Manh","comment_id":"476048","content":"Answer D","upvote_count":"1","timestamp":"1652247420.0"},{"content":"C follows the SRE.","comments":[{"comment_id":"1102323","timestamp":"1718955480.0","poster":"Feliphus","upvote_count":"1","content":"The statemene says: you encounter a large number of outages in the production systems you support, then eliminating the alerts doesn't seem to be a good idea. If there is another support team in another time zone. What's happen if the server doesn't reboot or the services don't start fine?. There is not a correct answer between options, what it would be to resolve the reboot problem. I don't know which is better if A or C, I suppose we have losed some information in the statement or in the answers. But in this situation I agree @NXD and choose C","comments":[{"timestamp":"1719335580.0","upvote_count":"1","poster":"Feliphus","content":"Sorry, but I change to ans A. I have noticed this question is repeated as Q133 but without the text: You receive alerts for all the outages that wake you up at night","comment_id":"1105495"}]}],"poster":"NXD","upvote_count":"3","comment_id":"470919","timestamp":"1651346820.0"},{"upvote_count":"4","timestamp":"1651134060.0","content":"Ans D\nhttps://www.atlassian.com/incident-management/kpis/error-budget","comments":[{"poster":"TNT87","comment_id":"509530","comments":[{"poster":"TNT87","timestamp":"1656231240.0","upvote_count":"1","comment_id":"509547","content":"NO!D is correct"}],"upvote_count":"1","content":"Ans A...point of correction","timestamp":"1656229140.0"}],"comment_id":"469095","poster":"TNT87"},{"content":"Should be A","upvote_count":"3","poster":"neutrino9","comment_id":"469042","timestamp":"1651128420.0"},{"comment_id":"468162","content":"D redefine SLI","poster":"job_search83","upvote_count":"1","timestamp":"1650990780.0"}],"question_text":"You encounter a large number of outages in the production systems you support. You receive alerts for all the outages that wake you up at night. The alerts are due to unhealthy systems that are automatically restarted within a minute. You want to set up a process that would prevent staff burnout while following Site\nReliability Engineering practices. What should you do?","answer_images":[],"answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/google/view/64824-exam-professional-cloud-devops-engineer-topic-1-question-59/","timestamp":"2021-10-26 18:33:00"},{"id":"eGZJpAlkIvFRXBkJKQFX","unix_timestamp":1622644500,"question_id":153,"topic":"1","isMC":true,"answer_description":"","answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/54228-exam-professional-cloud-devops-engineer-topic-1-question-6/","timestamp":"2021-06-02 16:35:00","answer":"D","question_text":"You use a multiple step Cloud Build pipeline to build and deploy your application to Google Kubernetes Engine (GKE). You want to integrate with a third-party monitoring platform by performing a HTTP POST of the build information to a webhook. You want to minimize the development effort. What should you do?","answer_ET":"D","choices":{"A":"Add logic to each Cloud Build step to HTTP POST the build information to a webhook.","D":"Create a Cloud Pub/Sub push subscription to the Cloud Build cloud-builds PubSub topic to HTTP POST the build information to a webhook.","C":"Use Stackdriver Logging to create a logs-based metric from the Cloud Build logs. Create an Alert with a Webhook notification type.","B":"Add a new step at the end of the pipeline in Cloud Build to HTTP POST the build information to a webhook."},"question_images":[],"answers_community":["D (100%)"],"discussion":[{"timestamp":"1672270080.0","comment_id":"393250","content":"I have submitted D answer","upvote_count":"17","poster":"Charun"},{"comment_id":"385798","content":"Ans: D \nPub/Sub\n\nA: No becauseThere is not Structure attribute to create a http request in the steps and remember you want minimize the development effort.\nB: The same A\nC: minimize the development effort\nD: Its OK\n\nTo receive messages from push subscriptions, use a webhook and process the POST requests that Pub/Sub sends to the push endpoint. For more information about processing these POST requests in App Engine, see Writing and responding to Pub/Sub messages.\n\nhttps://cloud.google.com/pubsub/docs/push\nhttps://cloud.google.com/build/docs/subscribe-build-notifications","upvote_count":"17","poster":"francisco_guerra","timestamp":"1671493080.0"},{"poster":"JonathanSJ","upvote_count":"1","timestamp":"1720665240.0","content":"Selected Answer: D\nAnswer D","comment_id":"772017"},{"content":"Selected Answer: D\nAns: D","comment_id":"754743","timestamp":"1719205800.0","poster":"floppino","upvote_count":"2"},{"comment_id":"702999","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/build/docs/subscribe-build-notifications\nCloud Build publishes messages on a Google Pub/Sub topic when your build's state changes, such as when your build is created, when your build transitions to a working state, and when your build completes.\n\nThe Pub/Sub topic to which Cloud Build publishes these build update messages is called cloud-builds. Each message contains a base64 JSON string representation of your Build resource in the message.data attribute. The build's unique ID and the build's status can be found in the message.attributes field.\n\nYou can use a push or pull model for your Pub/Sub subscriptions.\n\nhttps://cloud.google.com/build/docs/subscribe-build-notifications#push\nPush subscriptions deliver messages to an HTTP endpoint that you define. Messages are delivered as soon as they are published to the topic.","upvote_count":"6","poster":"zellck","comments":[{"content":"Yes, D is right based on given scenario","timestamp":"1714420740.0","poster":"AzureDP900","upvote_count":"1","comment_id":"707448"}],"timestamp":"1713961020.0"},{"content":"Selected Answer: D\nAns: D","timestamp":"1706079840.0","poster":"GCP72","upvote_count":"1","comment_id":"635880"},{"poster":"Ananda","upvote_count":"1","content":"Selected Answer: D\nSubmitted D in exam.","comment_id":"599115","timestamp":"1699551600.0"},{"timestamp":"1699088940.0","comment_id":"596569","content":"Selected Answer: D\nCloud Build -> Pubsub -> HTTP Builder.........SO ans is D","poster":"akshay_jadhav","upvote_count":"2"},{"timestamp":"1690359060.0","content":"Not sure on D. Pub/Sub posts into specific format and the actual payload in is message.data.\nThird party system API (where you post status) will have its own POST format. \nI feel B is better - you add a step in CLoud Build to do the POST.","comment_id":"532774","poster":"pddddd","upvote_count":"3"},{"timestamp":"1685958960.0","poster":"alaahakim","content":"Ans : D","upvote_count":"1","comment_id":"494291"},{"comment_id":"486977","upvote_count":"1","timestamp":"1685049660.0","poster":"muk5658","content":"Its D. Cloud Build -> Pubsub -> HTTP Builder"},{"timestamp":"1670380320.0","upvote_count":"2","content":"D is correct answer \nhttps://cloud.google.com/build/docs/subscribe-build-notifications","comments":[{"upvote_count":"2","content":"Agree D looks correct to me.","poster":"akg001","comment_id":"380273","timestamp":"1670835060.0"}],"poster":"rinkeshgala1","comment_id":"376400"},{"timestamp":"1669998900.0","content":"no idea on this","poster":"devopsbatch","upvote_count":"1","comment_id":"372785"}],"exam_id":6},{"id":"x9EEmiQ1yQxbbMf6I87O","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/64985-exam-professional-cloud-devops-engineer-topic-1-question-60/","choices":{"D":"Create a runbook on inflating the disaster recovery (DR) environment if there is growth.","B":"Enable AutoScaling on the production clusters, in case there is growth.","C":"Pre-provision double the compute power used last season, expecting growth.","A":"Load teat the application to profile its performance for scaling."},"answers_community":["A (91%)","9%"],"answer_description":"","answer_ET":"A","exam_id":6,"answer":"A","timestamp":"2021-10-28 10:26:00","topic":"1","discussion":[{"poster":"NXD","comment_id":"470922","upvote_count":"18","comments":[{"upvote_count":"1","comment_id":"484811","timestamp":"1669189740.0","content":"Changing the architecture for scale and reliability\nLoad testing and failure testing, along with architecture reviews, encourage limited-scope architectural changes that can enhance the scale and reliability of the system. However, introducing changes adds risk, so limit the changes to a conservative range of time.https://cloud.google.com/architecture/black-friday-production-readiness#changing_the_architecture_for_scale_and_reliability","poster":"TNT87"}],"content":"https://cloud.google.com/architecture/black-friday-production-readiness#preparation_stage\n\nThe objective of the preparation stage is to test the system's ability to scale for peak user traffic and to document the results. Completing the preparation stage results in architecture refinement to handle peak traffic more efficiently and increase system reliability. This stage also yields procedures for operations and support that help streamline processes for handling the peak event and any issues that might occur. Consider this stage as practice for the peak event from a system and operations perspective.\n\nA is exactly what mentioned above.\nB is the step after the preparation stage.","timestamp":"1667252040.0"},{"poster":"KyubiBlaze","upvote_count":"5","timestamp":"1673853060.0","comment_id":"524702","comments":[{"content":"Good analysis, before moving any new features first thing to do performance test to understand how system behaves under load, Auto scaling is later step... A is 100% correct","comment_id":"703498","upvote_count":"1","timestamp":"1698200580.0","poster":"AzureDP900"}],"content":"Selected Answer: A\nCome on, no brainer.\nA is the answer.\nYou load test to understand how your application perform under heavy load. \"Prepare for busy season\"\nB - No, Option A will give you insight in how your applications works under load, and how do you scale, if it cannot scale, autoscaling in meaningless.\nSo first you test your application in controlled environment. Not wait for the busy time to come and then realise autoscaling is also unable to meet demand. Or Maybe you even reach your quotas."},{"timestamp":"1733138760.0","comment_id":"1086121","poster":"jomonkp","content":"Selected Answer: A\nOption A","upvote_count":"1"},{"poster":"raghu09","upvote_count":"1","timestamp":"1711438140.0","comment_id":"850746","content":"Selected Answer: A\nWould go with A because you need to know the performance of your application if it scales to serve larger customers. Scaling decisions of the application comes after."},{"upvote_count":"1","timestamp":"1705277640.0","content":"Selected Answer: A\nA. Load test the application to profile its performance for scaling. This will help to identify any potential bottlenecks or issues with the application, and allow you to make the necessary adjustments or scaling decisions before the busy season begins.","comment_id":"776054","poster":"JonathanSJ"},{"content":"After moving the application onto GCP, some amount of testing should be carried out before deciding what to do next.","poster":"ssmb","comment_id":"701114","upvote_count":"1","timestamp":"1697915100.0"},{"comment_id":"528190","upvote_count":"2","poster":"Sekierer","content":"A is correct","timestamp":"1674196260.0"},{"timestamp":"1672230060.0","content":"Selected Answer: A\nSet up load and performance testing\nLoad testing is the process of deploying a test version of the system and creating requests to simulate high use of the system. Load testing normally focuses on testing for sustainable user-perceived behavior at some percentile below the absolute peak. Testing for peak requires hitting that top percentile with consistent good performance.","poster":"TNT87","comment_id":"511074","upvote_count":"2"},{"poster":"TNT87","comments":[{"comment_id":"681315","content":"For Auto Scaling you need to provide parameters which will not be know if load test is not done. Otherwise you will be using arbitrary values which may not be consistent with actual load.","timestamp":"1695860400.0","upvote_count":"1","poster":"csrazdan"}],"content":"Selected Answer: B\nB is the answer","upvote_count":"1","timestamp":"1672187580.0","comment_id":"510692"},{"upvote_count":"1","comment_id":"494279","timestamp":"1670240520.0","poster":"TNT87","content":"https://cloud.google.com/blog/topics/retail/preparing-for-peak-holiday-season-while-wfh\nAns A makes sense according to this doc"},{"upvote_count":"4","poster":"tee_dee26","content":"Passed exam a couple of days ago. Chose A","timestamp":"1668265800.0","comment_id":"477018"},{"comment_id":"472887","poster":"MBA_1","upvote_count":"4","comments":[{"content":"Agree with A","comment_id":"476052","timestamp":"1668152640.0","upvote_count":"1","poster":"Manh"}],"timestamp":"1667626440.0","content":"Should be A , To check how application performs with load"},{"timestamp":"1667065980.0","content":"Ans : B","upvote_count":"2","comment_id":"469915","poster":"Alaaelanwr"},{"comment_id":"469836","upvote_count":"2","content":"Ans: B","poster":"giammydell","timestamp":"1667057640.0"},{"content":"Ans B\nhttps://cloud.google.com/architecture/black-friday-production-readiness","poster":"TNT87","timestamp":"1666945560.0","comment_id":"469097","upvote_count":"2"}],"question_text":"You have migrated an e-commerce application to Google Cloud Platform (GCP). You want to prepare the application for the upcoming busy season. What should you do first to prepare for the busy season?","question_id":154,"isMC":true,"unix_timestamp":1635409560},{"id":"l7jGSApz26NwPVdkvpg4","timestamp":"2021-10-27 20:55:00","answer":"D","answer_images":[],"answer_ET":"D","unix_timestamp":1635360900,"question_text":"You support a web application that runs on App Engine and uses CloudSQL and Cloud Storage for data storage. After a short spike in website traffic, you notice a big increase in latency for all user requests, increase in CPU use, and the number of processes running the application. Initial troubleshooting reveals:\n✑ After the initial spike in traffic, load levels returned to normal but users still experience high latency.\n✑ Requests for content from the CloudSQL database and images from Cloud Storage show the same high latency.\n✑ No changes were made to the website around the time the latency increased.\n✑ There is no increase in the number of errors to the users.\nYou expect another spike in website traffic in the coming days and want to make sure users don't experience latency. What should you do?","choices":{"A":"Upgrade the GCS buckets to Multi-Regional.","B":"Enable high availability on the CloudSQL instances.","C":"Move the application from App Engine to Compute Engine.","D":"Modify the App Engine configuration to have additional idle instances."},"question_id":155,"topic":"1","exam_id":6,"question_images":[],"answers_community":["D (100%)"],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/64943-exam-professional-cloud-devops-engineer-topic-1-question-61/","discussion":[{"content":"Correct Answer is D:\n\nScaling App Engine scales the number of instances automatically in response to processing volume. This scaling factors in the automatic_scaling settings that are provided on a per-version basis in the configuration file. A service with basic scaling is configured by setting the maximum number of instances in the max_instances parameter of the basic_scaling setting. The number of live instances scales with the processing volume. You configure the number of instances of each version in that service's configuration file. The number of instances usually corresponds to the size of a dataset being held in memory or the desired throughput for offline work. You can adjust the number of instances of a manually-scaled version very quickly, without stopping instances that are currently running, using the Modules API set_num_instances function.\n\nhttps://cloud.google.com/appengine/docs/standard/python/how-instances-are-managed","poster":"ESP_SAP","upvote_count":"10","comment_id":"493332","timestamp":"1654278000.0"},{"comments":[{"content":"Agree with D","poster":"Manh","upvote_count":"1","comment_id":"476307","timestamp":"1652273640.0"}],"poster":"MBA_1","upvote_count":"6","timestamp":"1651722300.0","comment_id":"472888","content":"D is correct - https://cloud.google.com/appengine/docs/standard/python/config/appref\nmax_idle_instances\nOptional. The maximum number of idle instances that App Engine should maintain for this version. Specify a value from 1 to 1000. If not specified, the default value is automatic, which means App Engine will manage the number of idle instances. Keep the following in mind:\n\nA high maximum reduces the number of idle instances more gradually when load levels return to normal after a spike. This helps your application maintain steady performance through fluctuations in request load, but also raises the number of idle instances (and consequent running costs) during such periods of heavy load."},{"timestamp":"1722736140.0","content":"Selected Answer: D\nhttps://cloud.google.com/appengine/docs/legacy/standard/python/config/appref#scaling_elements:~:text=traffic%20or%20not.-,max_idle_instances,-Optional.%20The%20maximum","poster":"alpha_canary","comment_id":"1139755","upvote_count":"1"},{"poster":"jomonkp","upvote_count":"1","timestamp":"1717321020.0","comment_id":"1086129","content":"Selected Answer: D\nOption D"},{"poster":"JonathanSJ","upvote_count":"1","content":"Selected Answer: D\nD. Modify the App Engine configuration to have additional idle instances. This will ensure that there are enough resources available to handle the spike in traffic, reducing the likelihood of latency for users. Additionally, you may also consider enabling high availability on the CloudSQL instances and upgrading the GCS buckets to Multi-Regional for more resiliency.","comment_id":"776056","timestamp":"1689372960.0"},{"comments":[{"comment_id":"762637","poster":"Greg123123","content":"A. then how about CloudSQL?\nB. then how about cloud storage?\nC. the same could also happen and even worse if it isn't MIG","timestamp":"1688121180.0","upvote_count":"1"}],"timestamp":"1688121060.0","comment_id":"762636","content":"Selected Answer: D\nD, no brainer. A B and C don't even make sense.","upvote_count":"1","poster":"Greg123123"},{"comment_id":"681356","timestamp":"1679971320.0","poster":"ramzez4815","content":"Selected Answer: D\nVote for D","upvote_count":"2"},{"comment_id":"528191","content":"Selected Answer: D\nD is correct","timestamp":"1658291460.0","upvote_count":"4","poster":"Sekierer"},{"upvote_count":"2","poster":"TNT87","content":"D is the answer","timestamp":"1656369300.0","comment_id":"510695"},{"content":"Selected Answer: D\nD is the answer","comment_id":"510694","timestamp":"1656369240.0","upvote_count":"1","poster":"TNT87"},{"poster":"Biden","comment_id":"479017","upvote_count":"1","content":"D looks like the nearest correct solution though this will not address with high latency with CloudSQL & storage instances","timestamp":"1652643900.0"},{"upvote_count":"3","comment_id":"470929","poster":"NXD","timestamp":"1651349100.0","content":"D is correct to me.\n\nA: wrong – because increase in latency for all user requests, not for specific region. So \nB: wrong – problem affects both database and GCS\nC: wrong\n\nincrease in CPU use, and the number of processes running the application => problem is that CPU is not enough to run application processes."},{"comment_id":"469105","upvote_count":"3","timestamp":"1651134840.0","poster":"giammydell","content":"B could be useful but does not solve latency problem on Cloud Storage side"},{"upvote_count":"2","content":"Ans B\nhttps://cloud.google.com/sql/docs/mysql/high-availability","comment_id":"469100","poster":"TNT87","comments":[{"upvote_count":"1","poster":"TNT87","timestamp":"1653277560.0","content":"Ans D,B has latency issues","comment_id":"484770"}],"timestamp":"1651134660.0"},{"poster":"Nik22","comment_id":"468825","content":"A. Upgrade the GCS buckets to Multi-Regional.\nB. Enable high availability on the CloudSQL instances.\nC. Move the application from App Engine to Compute Engine.\nD. Modify the App Engine configuration to have additional idle instances.\n\nThere is nothing in the question that talks about region. If I assume that bucket is created in the region where the app is deployed\nB - Gives redundancy. I don't see how this can improve the latency\nC - Does not make any sense\nD - Additional instance, would reduce the CPU Time & memory.\n\nI would go with D. But not too sure.","upvote_count":"2","timestamp":"1651085700.0"}],"answer_description":""}],"exam":{"name":"Professional Cloud DevOps Engineer","numberOfQuestions":196,"isImplemented":true,"lastUpdated":"11 Apr 2025","isBeta":false,"id":6,"provider":"Google","isMCOnly":true},"currentPage":31},"__N_SSP":true}