{"pageProps":{"questions":[{"id":"sJVIm2acut0hFQf1FVN8","unix_timestamp":1740682560,"choices":{"C":"Use AutoML Tables with built-in explainability features, and use Shapley values for explainability.","A":"Deploy the Learning Interpretability Tool (LIT) on App Engine to provide explainability and visualization of the output.","D":"Deploy pre-trained models from TensorFlow Hub to provide explainability using visualization tools.","B":"Use Vertex Explainable AI to generate feature attributions, and use feature-based explanations for your models."},"discussion":[{"poster":"CassiniExam","content":"Selected Answer: C\nConsidering the requirements of transparency, understandability, and minimal operational overhead, C. Use AutoML Tables with built-in explainability features, and use Shapley values for explainability. is the best option. It leverages a managed service with built-in explainability, providing a scalable and low-maintenance solution.","timestamp":"1740682560.0","comment_id":"1362703","upvote_count":"1"}],"question_text":"You are an ML engineer at a bank. You need to build a solution that provides transparent and understandable explanations for AI-driven decisions for loan approvals, credit limits, and interest rates. You want to build this system to require minimal operational overhead. What should you do?","exam_id":13,"answer_ET":"B","topic":"1","answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/157243-exam-professional-machine-learning-engineer-topic-1-question/","isMC":true,"answer":"C","answer_description":"","timestamp":"2025-02-27 19:56:00","question_id":226,"question_images":[],"answers_community":["C (100%)"]},{"id":"TgyQ7omvNAFHFXhJOYq5","url":"https://www.examtopics.com/discussions/google/view/156817-exam-professional-machine-learning-engineer-topic-1-question/","answer_description":"","answers_community":["B (100%)"],"unix_timestamp":1739993820,"timestamp":"2025-02-19 20:37:00","answer_ET":"B","question_images":[],"question_id":227,"isMC":true,"question_text":"You are building an application that extracts information from invoices and receipts. You want to implement this application with minimal custom code and training. What should you do?","answer":"B","choices":{"A":"Use the Cloud Vision API with TEXT_DETECTION type to extract text from the invoices and receipts, and use a pre-built natural language processing (NLP) model to parse the extracted text.","D":"Train an AutoML Natural Language model to classify and extract information from the invoices and receipts.","C":"Use Vertex AI Agent Builder with the pre-built Layout Parser model to extract information from the invoices and receipts.","B":"Use the Cloud Document AI API to extract information from the invoices and receipts."},"exam_id":13,"discussion":[{"content":"Selected Answer: B\nAnswer: B. \nDocumentAI API is much better at extracting specific fields and returning more repeatable results for specific field extraction than Cloud Vision (which is more directed at Object detection, etc.)","comment_id":"1365134","upvote_count":"1","timestamp":"1741126740.0","poster":"5091a99"},{"poster":"tk786786","timestamp":"1739993820.0","comment_id":"1358943","upvote_count":"1","content":"Selected Answer: B\nB. Use the Cloud Document AI API to extract information from the invoices and receipts.\nWhy Option B?\nPurpose-Built for Document Processing\n\nCloud Document AI (DocAI) is specifically designed for extracting structured information from invoices, receipts, and other business documents.\nIt uses pre-trained models that understand the layout, tables, and key-value pairs in structured documents.\nMinimal Custom Code and No Training Required\n\nNo need to train a custom model—DocAI automatically extracts fields like total amount, invoice number, date, and vendor name.\nReduces development effort significantly compared to training a model from scratch.\nHighly Accurate and Optimized for Business Documents\n\nSupports OCR, entity extraction, and key-value pair detection out of the box.\nHandles variations in invoice formats automatically, unlike generic OCR solutions."}],"topic":"1","answer_images":[]},{"id":"KU5wiTnUhUIx68VJb77Y","question_text":"You work for a media company that operates a streaming movie platform where users can search for movies in a database. The existing search algorithm uses keyword matching to return results. Recently, you have observed an increase in searches using complex semantic queries that include the movies’ metadata such as the actor, genre, and director.\n\nYou need to build a revamped search solution that will provide better results, and you need to build this proof of concept as quickly as possible. How should you build the search platform?","unix_timestamp":1739993880,"isMC":true,"answer_ET":"B","answer_images":[],"answer_description":"","discussion":[{"content":"Selected Answer: B\nAnswer B.\nVector search is more efficient for 'Search' based queries.\n- A: Makes sense and easily deployable, but this is 'Search' and LLMs typically are for more conversational applications that may not prioritize speed.\n- C: BERT unnecessary complexity and training. \n- D: Would work, but Agents are more geared toward conversation and results have higher latency compared to vector search.","upvote_count":"2","comment_id":"1365135","poster":"5091a99","timestamp":"1741127100.0"},{"content":"Selected Answer: B\nB. Configure Vertex AI Vector Search as the search platform’s backend.\nWhy Option B?\nBest for Semantic Search & Metadata Queries\n\nKeyword-based search is insufficient for complex semantic queries (e.g., \"Find action movies starring Tom Cruise directed by Christopher Nolan\").\nVertex AI Vector Search supports vector embeddings, which enable semantic similarity search instead of exact keyword matching.\nFast Proof of Concept with Minimal Effort\n\nPre-built solution for semantic search with high scalability.\nNo need to manually train a model—simply generate embeddings from movie metadata (actors, genre, director, etc.) and store them in Vertex AI Vector Search.\nScalable and High-Performance Search Engine\n\nOptimized for low-latency searches and retrieves the most relevant results quickly.\nWorks well with multi-dimensional search queries, making it ideal for metadata-rich movie searches.","upvote_count":"1","comment_id":"1358944","timestamp":"1739993880.0","poster":"tk786786"}],"timestamp":"2025-02-19 20:38:00","question_images":[],"answer":"B","url":"https://www.examtopics.com/discussions/google/view/156818-exam-professional-machine-learning-engineer-topic-1-question/","exam_id":13,"choices":{"A":"Use a foundational large language model (LLM) from Model Garden as the search platform’s backend.","C":"Use a BERT-based model and host it on a Vertex AI endpoint.","B":"Configure Vertex AI Vector Search as the search platform’s backend.","D":"Create the search platform through Vertex AI Agent Builder."},"answers_community":["B (100%)"],"question_id":228,"topic":"1"},{"id":"2dXh1lZNwqjannw5ECmn","unix_timestamp":1741247700,"exam_id":13,"answer_ET":"C","question_images":[],"timestamp":"2025-03-06 08:55:00","choices":{"D":"Deploy the model to a Vertex AI endpoint, and configure the model for online prediction. Schedule a job to query this endpoint weekly.","A":"Use Vertex AI’s prebuilt containers for prediction. Deploy the container on Cloud Run to generate online predictions.","B":"Use Vertex AI’s prebuilt containers for prediction. Deploy the model on Google Kubernetes Engine (GKE), and configure the model for batch prediction.","C":"Deploy the model to a Vertex AI endpoint, and configure the model for batch prediction. Schedule the batch prediction to run weekly."},"answer_images":[],"answer":"C","question_id":229,"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/157652-exam-professional-machine-learning-engineer-topic-1-question/","topic":"1","answers_community":["C (100%)"],"discussion":[{"comment_id":"1365799","timestamp":"1741247700.0","upvote_count":"1","content":"Selected Answer: C\n（Gemini Explanation）\nVertex AI Batch Prediction: This service is specifically designed for batch inference, making it ideal for processing large datasets and generating predictions offline.\nScheduled Jobs: Vertex AI allows you to schedule batch prediction jobs, automating the weekly process and eliminating the need for manual intervention.\nMinimized Maintenance: Vertex AI handles the underlying infrastructure, reducing the maintenance burden compared to managing a Kubernetes cluster or manually querying an online endpoint.\nCost Efficiency: Batch prediction is generally more cost-effective for large-scale offline processing than repeatedly querying an online endpoint.","poster":"yokoyan"}],"question_text":"You are an AI engineer that works for a popular video streaming platform. You built a classification model using PyTorch to predict customer churn. Each week, the customer retention team plans to contact customers that have been identified as at risk of churning with personalized offers. You want to deploy the model while minimizing maintenance effort. What should you do?","isMC":true},{"id":"0iC31fgIYnm6lpYSr4la","topic":"1","unix_timestamp":1624357260,"answer":"B","exam_id":13,"question_id":230,"answer_ET":"B","choices":{"B":"Reduce the batch size.","C":"Change the learning rate.","D":"Reduce the image shape.","A":"Change the optimizer."},"timestamp":"2021-06-22 12:21:00","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/55825-exam-professional-machine-learning-engineer-topic-1-question/","answer_images":[],"question_images":[],"question_text":"You need to train a computer vision model that predicts the type of government ID present in a given image using a GPU-powered virtual machine on Compute\nEngine. You use the following parameters:\n✑ Optimizer: SGD\n✑ Image shape = 224ֳ—224\n✑ Batch size = 64\n✑ Epochs = 10\n✑ Verbose =2\nDuring training you encounter the following error: ResourceExhaustedError: Out Of Memory (OOM) when allocating tensor. What should you do?","answers_community":["B (91%)","9%"],"discussion":[{"upvote_count":"25","poster":"maartenalexander","content":"B. I think you want to reduce batch size. Learning rate and optimizer shouldn't really impact memory utilisation. Decreasing image size (A) would work, but might be costly in terms final performance","comment_id":"387828","timestamp":"1640175660.0"},{"upvote_count":"9","content":"B. https://stackoverflow.com/questions/59394947/how-to-fix-resourceexhaustederror-oom-when-allocating-tensor/59395251#:~:text=OOM%20stands%20for%20%22out%20of,in%20your%20Dense%20%2C%20Conv2D%20layers","timestamp":"1643036940.0","comment_id":"413196","poster":"guruguru"},{"upvote_count":"1","content":"Selected Answer: B\nB) Reduce the batch size.","poster":"PhilipKoku","timestamp":"1733498940.0","comment_id":"1225543"},{"upvote_count":"1","comment_id":"945607","timestamp":"1704635700.0","content":"Selected Answer: B\nno doubt went to B","poster":"SamuelTsch"},{"poster":"M25","upvote_count":"2","comment_id":"892709","timestamp":"1699513380.0","content":"Selected Answer: B\nWent with B"},{"upvote_count":"1","timestamp":"1695554040.0","comment_id":"849305","poster":"SergioRubiano","content":"Selected Answer: B\nB is correct"},{"content":"Selected Answer: B\nBy reducing the batch size, the amount of memory required for each iteration of the training process is reduced","poster":"Fatiy","comment_id":"824992","timestamp":"1693231020.0","upvote_count":"1"},{"content":"Selected Answer: A\nCreating alerts to monitor for skew in the input data can help to detect when the distribution of the data has changed and the model's performance is affected. Once a skew is detected, retraining the model with the new data can improve its performance.","comments":[{"poster":"Fatiy","comment_id":"824985","timestamp":"1693230600.0","content":"Sorry it's not the response for this question. it's the response for the previous question.","upvote_count":"1"}],"timestamp":"1693230480.0","upvote_count":"1","comment_id":"824983","poster":"Fatiy"},{"poster":"John_Pongthorn","content":"Selected Answer: B\nReduce the image shape != Reduce the image Size.","timestamp":"1693205820.0","upvote_count":"1","comment_id":"824571"},{"comment_id":"722346","upvote_count":"2","content":"The answer is B\nSince you are using an SGD, you can use a batch size of 1\nref: https://stackoverflow.com/questions/63139072/batch-size-for-stochastic-gradient-descent-is-length-of-training-data-and-not-1","poster":"seifou","timestamp":"1684544580.0"},{"content":"Selected Answer: B\nto fix memory overflow you need to reduce batch size also reduce input resolution is valid\nbut reducing image size can harm model performance , so answer is B","upvote_count":"3","comment_id":"615855","timestamp":"1670956140.0","poster":"Mohamed_Mossad"},{"content":"B is my option. But, D seems not wrong.\n\nReducing batch size or reducing image size bot can reduce memory usage. But, the former seems much easier.","comment_id":"496296","upvote_count":"2","timestamp":"1654624980.0","poster":"alphard"},{"content":"B is correct.\n\nLetter D can be used, as we reduced the image size but this will directly impact the model's performance. Another point is that when doing this, if you are using a model via Keras's `Functional API` you need to change the definition of the input and also apply pre-processing on the image to reduce its size . In other words: much more work than the letter B.","upvote_count":"3","timestamp":"1652391660.0","comment_id":"477217","poster":"kaike_reis"},{"upvote_count":"3","content":"B is correct, it uses less memory.\n\nA works too but depending on what you need you will loose perfomance (just like maartenalexander said) so I think it is not recommended.","timestamp":"1650443580.0","comment_id":"465037","poster":"mousseUwU"},{"comment_id":"457665","timestamp":"1649159100.0","upvote_count":"2","content":"Initially, I though D. ,decreasing image size, would be the correct one, but now that I am reviewing the test I think maartenalexander is correct in saying reduced image size might decrease final performance, so I'd go with B eventually.","poster":"george_ognyanov"}],"isMC":true}],"exam":{"isMCOnly":true,"isBeta":false,"name":"Professional Machine Learning Engineer","numberOfQuestions":304,"isImplemented":true,"provider":"Google","id":13,"lastUpdated":"11 Apr 2025"},"currentPage":46},"__N_SSP":true}