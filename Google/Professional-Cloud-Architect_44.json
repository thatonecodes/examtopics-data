{"pageProps":{"questions":[{"id":"E23ZrsiiDxAZbYZf0vfj","exam_id":4,"question_images":[],"answer_description":"","question_text":"As part of their new application experience, Dress4Wm allows customers to upload images of themselves.\nThe customer has exclusive control over who may view these images.\nCustomers should be able to upload images with minimal latency and also be shown their images quickly on the main application page when they log in.\nWhich configuration should Dress4Win use?","unix_timestamp":1573813080,"url":"https://www.examtopics.com/discussions/google/view/8251-exam-professional-cloud-architect-topic-11-question-8/","answer":"A","choices":{"A":"Store image files in a Google Cloud Storage bucket. Use Google Cloud Datastore to maintain metadata that maps each customer's ID and their image files.","B":"Store image files in a Google Cloud Storage bucket. Add custom metadata to the uploaded images in Cloud Storage that contains the customer's unique ID.","D":"Use a distributed file system to store customers' images. As storage needs increase, add more persistent disks and/or nodes. Use a Google Cloud SQL database to maintain metadata that maps each customer's ID to their image files.","C":"Use a distributed file system to store customers' images. As storage needs increase, add more persistent disks and/or nodes. Assign each customer a unique ID, which sets each file's owner attribute, ensuring privacy of images."},"isMC":true,"answer_images":[],"timestamp":"2019-11-15 11:18:00","answers_community":["A (67%)","B (33%)"],"answer_ET":"A","topic":"11","question_id":216,"discussion":[{"content":"I think it's A, because in the question says \"The customer has exclusive control over who may view these images\"\nAnd I think it is easier to develop this feature having in cloud datastore a NOSQL database where you can manage the control of file's viewer","timestamp":"1589970300.0","upvote_count":"34","comment_id":"23009","poster":"chiar"},{"upvote_count":"9","content":"A - using gsutil for this purpose makes querries on such metadata painful for application logic.","comment_id":"50193","poster":"DrCoola","timestamp":"1597339380.0"},{"poster":"svkds","upvote_count":"1","content":"Selected Answer: B\nThis approach leverages Google Cloud Storage for storing the image files, which provides scalability, durability, and low-latency access. By adding custom metadata containing the customer's unique ID to the uploaded images, Dress4Win can maintain control over access to the images while enabling efficient retrieval based on customer identity. This configuration aligns well with the requirement for minimal latency and quick access to images while ensuring customer privacy and security.","comment_id":"1210876","timestamp":"1731511260.0"},{"timestamp":"1653634320.0","content":"Selected Answer: A\nvote A","comment_id":"488004","upvote_count":"2","poster":"joe2211"},{"upvote_count":"4","timestamp":"1643486040.0","comment_id":"416974","content":"A is correct. The whole idea is simply build and maintain an external metadata service using NoSQL database to associate the GS object key with its metadata, in order to facilitate object findings based on attributes you pre defined in metatdata\n\nThis AWS blog provides a solution in the context of AWS S3, but the idea behind is applicable to Google Storage as well\nhttps://aws.amazon.com/blogs/big-data/building-and-maintaining-an-amazon-s3-metadata-index-without-servers/","poster":"PeppaPig"},{"upvote_count":"1","comment_id":"408938","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","timestamp":"1642516740.0","poster":"kopper2019"},{"content":"B) is not correct because we cannot search on bucket using metada (maybe in the future ...). So for now we have to get all files from the bucket and fiter on metadata ( very bad performance).\nThe answer is A).","comment_id":"408510","poster":"[Removed]","upvote_count":"2","timestamp":"1642441020.0"},{"poster":"victory108","upvote_count":"1","timestamp":"1642321320.0","content":"A. Store image files in a Google Cloud Storage bucket. Use Google Cloud Datastore to maintain metadata that maps each customer's ID and their image files.","comment_id":"407641"},{"poster":"MamthaSJ","content":"Answer is A","upvote_count":"3","timestamp":"1641639600.0","comment_id":"401716"},{"comment_id":"325885","upvote_count":"1","content":"Answer is A","timestamp":"1633095480.0","poster":"Ausias18"},{"upvote_count":"3","poster":"Rightsaidfred","comment_id":"285819","timestamp":"1628364720.0","content":"Between A & B. A will take quickest time. A is the answer."},{"poster":"okixavi","timestamp":"1623944400.0","comment_id":"246709","content":"A is the man","upvote_count":"2"},{"content":"The customer has exclusive control over who can view their image. \nIs this possible by option B, by merely adding metadata on the object. I don't think so. \nA is better suited.","timestamp":"1622982480.0","poster":"Bijesh","upvote_count":"2","comment_id":"236545"},{"poster":"hems4all","timestamp":"1620925860.0","content":"A is correct","upvote_count":"2","comment_id":"218691"},{"timestamp":"1619676300.0","poster":"AdityaGupta","content":"I will go with A, Store the images in GCS is cost-optimized way of storing images/ objects. DataStore is best option to store user profiles, which gives control to user.","upvote_count":"3","comment_id":"208344"},{"timestamp":"1610804640.0","comment_id":"136419","poster":"zzaric","upvote_count":"2","content":"A is correct"},{"poster":"mlantonis","upvote_count":"2","comment_id":"118414","timestamp":"1608819840.0","content":"I agree with A"},{"comment_id":"117727","content":"A solves storage and access. What I do not like about Datastore that it requires application support and the use case is not clear how far Application team in migration. But considering migration in GCP happening, Datastore is great database for this type of things","poster":"motty","timestamp":"1608754380.0","upvote_count":"1"},{"timestamp":"1607293440.0","poster":"Ziegler","comment_id":"104089","upvote_count":"3","content":"A is the correct answer"},{"poster":"AD2AD4","upvote_count":"3","timestamp":"1606620360.0","comment_id":"97946","content":"Final Decision to go with Option A"},{"content":"customer image metadata is kind of profile information which is the kind information that Datastore/Firestore is perfect for","poster":"amralieg","comment_id":"93925","upvote_count":"1","timestamp":"1606056120.0"},{"poster":"PRC","content":"A for me. A is simpler solution (managed datastore) as opposed to custom build of metadata store.","comment_id":"76273","timestamp":"1603085520.0","upvote_count":"4"},{"timestamp":"1601781240.0","comments":[{"upvote_count":"1","timestamp":"1619676240.0","comment_id":"208343","poster":"AdityaGupta","content":"I will go with A, Store the images in GCS is cost-optimized way of storing images/ objects. DataStore is best option to store user profiles, which gives control to user."}],"upvote_count":"4","comment_id":"70913","content":"Even though cloud storage bucket objects can maintain some custom metadata, the other requirements requires us to store info of uploaded image in storage bucket, user uploaded it and authorised user list to view these images. Hence a nosql DB might help here to store all these and to design better solution.\nB may be a possible answer but A is the best answer.","poster":"Jeysolomon"},{"content":"With datastore in picture, you can't ignore A","poster":"passnow","comment_id":"30811","upvote_count":"3","timestamp":"1592517720.0"},{"poster":"JoeShmoe","timestamp":"1589530680.0","comment_id":"21738","comments":[{"upvote_count":"6","content":"A is ok:\n\n1. Use Google Cloud Storage to save images.\n\n2. Use Firestore (in Datastore mode) to map the customer ID and the location of their images in Google Cloud Storage. is the right answer\n\nGoogle Cloud Storage is an ideal place to upload images. And saving the customer ID to the object location metadata mapping in datastore is a good idea. When the user logs in, the application would have to look up the datastore based on customer ID, and this is a quick operation. Based on the object key, you can fetch the image file from Cloud storage and display it with minimal latency.","timestamp":"1622173320.0","comment_id":"229423","poster":"techalik"},{"timestamp":"1630809420.0","comment_id":"303938","poster":"nitinz","content":"A is answer","upvote_count":"2"},{"timestamp":"1608754320.0","content":"this approach will not solve \"Customers should be able to upload images with minimal latency and also be shown their images quickly on the main application page when they log in\" requirement. The database layer to quickly assemble list of images per customer is needed. ( unless you want to start storing images inside of per-customer-folder, but this is so ugly that I am gonna stop here :) )","comment_id":"117724","upvote_count":"1","comments":[{"content":"A is ok","upvote_count":"4","poster":"tartar","comment_id":"155935","timestamp":"1613093700.0"}],"poster":"motty"}],"upvote_count":"1","content":"Answer is B - set custom metadata vis gustily. https://cloud.google.com/storage/docs/gsutil/addlhelp/WorkingWithObjectMetadata"}]},{"id":"tByH15SsgSGW5N7tDIZC","answer":"B","answer_description":"","question_images":[],"exam_id":4,"isMC":true,"answers_community":["B (100%)"],"topic":"11","question_id":217,"timestamp":"2020-02-23 17:12:00","answer_ET":"B","answer_images":[],"unix_timestamp":1582474320,"discussion":[{"poster":"examtaker11","upvote_count":"28","timestamp":"1598376660.0","content":"C- I would run the same test suite in cloud) to see what breaks","comments":[{"upvote_count":"9","content":"Going with B. \"Final answer\" lol. C is a good answer except that they're asking for an additional testing method. Since they're already testing endpoints specifically, you'd literally be running the exact same test after migration. That said, for B, I'm still at a loss of why we'd need to do additional unit testing--best explanation is that some of the applications will have needed to be retooled for PaaS offerings if they're doing more than a lift-and-shift, thereby actually changing the underlying code; but the production-level load testing is like the most GCP thing you can do here","timestamp":"1625708940.0","comment_id":"262299","poster":"Jphix"},{"poster":"mesodan","comment_id":"554774","upvote_count":"2","content":"I would go with B. \"Additional\" seems to be the keyword here so adding unit tests and production scale load tests to the ones they already have makes more sense.","timestamp":"1661272920.0"},{"timestamp":"1598484900.0","upvote_count":"6","poster":"Smart","comment_id":"55770","content":"Agree, however, I think running at production-scale would not only show what breaks but also when it breaks? I go with B"}],"comment_id":"55140"},{"comment_id":"147128","timestamp":"1611992640.0","poster":"FAB1010","upvote_count":"21","content":"Question mention that \"end-to-end tests covering 100% of their endpoints\", \"ensure that the move to the cloud does not introduce any new bugs\", and \"additional testing methods should the *developers* employ to *prevent an outage*\"\n\nA - Not Correct. Developer can debug the problem, but cannot *prevent* the outage. \nB - Correct. Developers are responsible for writing unit tests. They already have end-to-end tests for *endpoints* but nothing mentioned about the unit tests. Cloud will auto-scale but you need to define your auto-scaling configuration (desired count, max count etc) and production scale load test will help you to configure the auto-scaling policies\nC - Not Correct. They already have end-to-end test. Running it on staging environment will not prevent an outage\nD - Not Correct. Answers says \"an impact the new release causes to latency\" but question ask for preventing an outage and so this one is ruled out"},{"content":"D\nthey already has 100% covering end-to-end testing, that means unit tests was finished before this\nso, additional test remains canary in production environment","upvote_count":"1","timestamp":"1731496800.0","poster":"bigzero","comment_id":"1210786"},{"timestamp":"1717485900.0","content":"B is testing scale, C is testing the code is working as intended in the cloud. the question is for bugs, not for scale. It should be C, but I understand why everyone goes for B. Neurodivergents will go for C.","comment_id":"1087487","upvote_count":"1","poster":"Jconnor"},{"upvote_count":"2","poster":"RitwickKumar","timestamp":"1676973000.0","comment_id":"649651","content":"Selected Answer: B\nNote the ask \"prevent an outage\". \nOne of the way to test outage scenarios is through load testing. Option B covers this where as option C only covers checking the intended behaviour."},{"comment_id":"578168","content":"Testing pipeline: Unit ---- Integration --- end-to-end\nIf choose B, add additional unit tests. It should be continue to do Integrationt test and end-to-end test.\nBut it just has a unit test, then go to produciton scale load test.\n\nC should be better, becasue it has finished end-to-end tests before, so for move to the cloud, it should be test the end-to-end in cloud preproduction enviroment to check whethere it's also working fine on cloud.\n\nhttps://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-developing-and-testing#end-to-end_tests","poster":"[Removed]","timestamp":"1664531100.0","upvote_count":"1"},{"comment_id":"488146","content":"Selected Answer: B\nvote B","upvote_count":"2","timestamp":"1653649560.0","poster":"joe2211"},{"poster":"rottzy","timestamp":"1649663640.0","content":"end-to-end is already present, go for additional tests","comment_id":"460452","upvote_count":"1"},{"poster":"amxexam","timestamp":"1647766440.0","content":"It should be B as for all those going with C if you do all staging you will still leave out the performance test that scales the application which is covered in B that means even if the application works well but will not scale properly will lead to an outage, which we are asked to prevent.","comment_id":"448028","upvote_count":"1"},{"comment_id":"407640","upvote_count":"3","timestamp":"1642321260.0","content":"B. They should add additional unit tests and production scale load tests on their cloud staging environment.","poster":"victory108"},{"comment_id":"401720","poster":"MamthaSJ","upvote_count":"4","timestamp":"1641639840.0","content":"Answer is B"},{"upvote_count":"3","timestamp":"1633095660.0","content":"Answer is B (but C... uff... is also possible, but as the question says end-to-end is already done)","comment_id":"325888","poster":"Ausias18"},{"comment_id":"323569","poster":"lynx256","upvote_count":"1","content":"B is ok","timestamp":"1632927660.0"},{"poster":"ybe_gcp_cert","timestamp":"1631943300.0","content":"Question asks about \"ADDITIONAL testing methods\".\n\nB adds production scale load tests.\nC should also be executed in a new cloud env but this question dosn't ask for this.\n\nIn real life serious projects, B and C are mandatory (end to end and perf tests).\n\nShould be B.","comment_id":"313909","upvote_count":"2"},{"comment_id":"294262","content":"Should be B \nReasoning: They already had end-to-end contract tests coverage for all their service(s) endpoints. So, additionally they should add unit test coverage and perform prod load tests in staging environment which will help find out performance related issues before deploying it to production.","upvote_count":"1","timestamp":"1629372540.0","poster":"guid1984"},{"poster":"Rightsaidfred","comment_id":"284674","content":"Obviously C. Yes they have end-to-end tests on prem with 100% coverage, however this hasn't been tested in the cloud yet.","upvote_count":"1","timestamp":"1628236140.0"},{"comment_id":"282393","upvote_count":"1","poster":"bnlcnd","content":"B vs C\nB sounds right other than additional \"unit\" test. C is nothing wrong but not mentioning load. I will throw a dime to decide which to choose.","timestamp":"1627954440.0"},{"poster":"okixavi","timestamp":"1623944460.0","upvote_count":"1","content":"Answer is C","comment_id":"246710"},{"upvote_count":"2","comment_id":"242060","content":"C is correct. As we want to test the code in the cloud for new bugs. (from question: They want to ensure that the move to the cloud does not introduce any new bugs.)\nWhy not B? - Unit tests are used to check individual codes are working fine or not and scaling not properly impact Scalability not reliability.\nWhy not D? can be the closest one, but answer is checking for latency. Again increased latency does not impact reliability or availability. (in question they are looking to prevent the outage).","poster":"OSNG","timestamp":"1623529080.0"},{"timestamp":"1622687880.0","comment_id":"233658","upvote_count":"1","poster":"Chulbul_Pandey","content":"\"end to end tests\" are needed so it would be C"},{"timestamp":"1622227380.0","comment_id":"229880","upvote_count":"3","poster":"mexblood1","content":"A. Incorrect. Debugging helps to fix something broken and the goal is to prevent outage.\nB. Undecided. Unit tests help identify what's broken because you tests individual code modules. You would need to add unit tests for each module, could be overwhelming and is unnecessary.\nC. Undecided. This does not add any testing method, unless using same method against different environment is considered an additional method.\nD. Undecided. Canary tests will help identify any bug on the application, but they way is worded \"measure impact to latency\" makes this one not a good option.\nNow the only option that mentions more than one method is B. The question asks for additional testing “methods” in plural. So A, C and D only mention 1 method. B mentions 2, so grammatically only option is B. This is the most nasty question I’ve read so far."},{"timestamp":"1620927900.0","upvote_count":"5","content":"C is Correct Answer:\n\nYou want to ensure the move to the cloud does not introduce any new bugs, so Dress4Win is not yet on Google Cloud which means the end to end test which cover 100% of their endpoints are running on the services/applications in the data centre. The scenario states \"They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them.\" so some components of their solution might need to be redesigned. Therefore, it is important to first carry out end-to-end tests on Cloud staging environment to see if all functionality works as expected. Unit test and load tests help, but end-to-end testing is needed first to ensure the application with all its various related services functions as intended.","poster":"hems4all","comment_id":"218710"},{"timestamp":"1619676780.0","content":"Question mention that \"end-to-end tests covering 100% of their endpoints\", \"ensure that the move to the cloud does not introduce any new bugs\", and \"additional testing methods should the *developers* employ to *prevent an outage*\"\n\nthey already have 100% coverage and cloud will not introduce code errors, maybe latency errors, so canary test would be recommanded.\n\nA-> This won't help in additional testing.\nB-> They already have 100% test converage.\nC-> Re-running end-to-end test in staging environment is not fulfilling objective of additional test.\nD-> Canary release (small set of users to new code version) will definitely help in identifying issues in new code with real-time users. + It will avoid any downtime.\n\nCorrect answer should be D.","poster":"AdityaGupta","comment_id":"208350","upvote_count":"4"},{"content":"Answer is B","poster":"avee3103","comment_id":"208265","upvote_count":"2","timestamp":"1619664420.0"},{"comment_id":"192237","content":"Resilience test recommended...so B","poster":"Here4cloud","timestamp":"1617451500.0","upvote_count":"1"},{"content":"I believe it is B. The E2E test is already done. By the cloud move there would not be any functional error introduced , the biggest question would be scaling in the cloud environment. This was not covered in the E2E test on-prem, hence this should be done.","comment_id":"187475","poster":"brati_sankar","upvote_count":"1","timestamp":"1616746200.0"},{"timestamp":"1616464920.0","content":"D - they already have 100% coverage and cloud will not introduce code errors, maybe latency errors, so canary test would be recommanded.","poster":"RomiAwasthy","comment_id":"184902","upvote_count":"3"},{"poster":"droidmasta","comment_id":"163946","upvote_count":"1","timestamp":"1614037200.0","content":"dear devs. Dont be fooled by \"100% coverage\".They currently have 100% end-to-end tests of the endpoints.\nImplementing unit tests would be something new, directly focused on maintaining the quality of the code"},{"comment_id":"161806","upvote_count":"1","content":"I understood that they conducted E2E test on-premises but they cannot be sure that in the cloud the endpoints will be solve correctly. M2C i think means that the new environment will move to the cloud son endpoints must be checked again. I 'll go with C","timestamp":"1613778060.0","poster":"Pupina"},{"upvote_count":"3","timestamp":"1613127240.0","poster":"Maya123","comment_id":"156282","content":"Yes B seems correct."},{"upvote_count":"1","content":"Vote for B just because performance test is must before production deployment. Existing test just talk about functional coverage.","poster":"saurabh1805","comment_id":"136755","timestamp":"1610840340.0"},{"poster":"Khannas","content":"B for sure","timestamp":"1610439780.0","comment_id":"132772","upvote_count":"1"},{"poster":"mlantonis","comment_id":"118412","upvote_count":"2","content":"After the satisfied end-to-end testing, the next step is to test users and devices, which naturally brings the load test in scope to demonstrate how well the system functions when faced with real world demands. The best place to do it is in environments close to resemble the production, a staging environment. Additional unit tests might need to distinguish if some bugs are functional or process flow related.\n\nB is the correct answer.","timestamp":"1608819720.0"},{"comment_id":"117735","upvote_count":"3","poster":"motty","timestamp":"1608755100.0","content":"\"They want to ensure that the move to the cloud does not introduce any new bugs\"\nto me it seems they are talking about regressing testing. So C sounds like right answer.\n\nA is not correct because it talks about debugging environment\nB speaks about additional unit tests (nothing should have changed at unit level)\nD mentions latency and load but not correctness of end points (which I believe what their testing is targeting)"},{"timestamp":"1607869440.0","upvote_count":"1","comment_id":"109439","content":"Canary deployments help in identification of bugs as well apart from latency","poster":"Sundeepk"},{"comment_id":"106046","content":"B is correct.\nAdditional testing methods is being asked which included Load and Unit testing..\n\nC:-Would mens running the same test and not Additional Test.","upvote_count":"3","timestamp":"1607532300.0","poster":"Rajuuu"},{"poster":"Hemant_C","comment_id":"104464","content":"Question is about which additional testing methods - after migration to cloud, the production environment can scale. they should add additional unit tests cases to cover this as well as production scale load test to make sure scaling is not breaking anything else .. Hence the answer seems to be B","timestamp":"1607346240.0","upvote_count":"1"},{"poster":"Ziegler","content":"B i the correct answer - because talks about unit test, which can be used to determine the application latency etc. All other tests are not related to latency but something else","timestamp":"1607293740.0","comment_id":"104092","upvote_count":"3"},{"upvote_count":"3","content":"Final Decision to go with Option B","timestamp":"1606620540.0","comment_id":"97951","poster":"AD2AD4"},{"content":"Load test seems not to be necessary as GCP environment should scale far beyond their on-prem system. Scaling is not something they should worry when moving to the cloud as it is one key selling point for cloud transformation. So I would eliminate B. Also, unit-test is at the code level and introducing unit-test would require lots of extra works if they don't have it yet.","poster":"chauvinhloi","comment_id":"95882","timestamp":"1606384740.0","upvote_count":"1","comments":[{"timestamp":"1618251960.0","comment_id":"198704","poster":"kimberjdaw","upvote_count":"1","content":"You always load test cloud services. You need to see if your specific configuration (CPU/RAM) can handle it."}]},{"comments":[{"upvote_count":"3","comment_id":"102301","content":"unit tests are not end-to-end tests ;)","poster":"misho","timestamp":"1607085780.0"}],"content":"Answer is C. B cannot be the answer, how come they add additional testes while they have already 100%","timestamp":"1606056180.0","poster":"amralieg","upvote_count":"4","comment_id":"93928"},{"upvote_count":"4","poster":"skywalker","timestamp":"1605322980.0","comment_id":"88589","content":"Vote for B....\n\nIt allow more unit testing plus load testing on their staging environment .. others options does not include these two"},{"comment_id":"87991","upvote_count":"2","content":"Ans: D, I am a Developer, moving code to Cloud and generally do Canary test to validate all set On Network, Infra and other components before moving completely.","poster":"ankit89","timestamp":"1605229140.0"},{"comment_id":"85017","timestamp":"1604750340.0","upvote_count":"4","poster":"hybridpro","content":"B seems correct. Maybe you rewrote a certain app using app engine when moving to the cloud. In that case, some extra unit test cases might be needed. Further now that you are in the cloud, you can go production scale for load testing."},{"poster":"Zarmi","upvote_count":"7","timestamp":"1604637300.0","comment_id":"84397","content":"Answer C.\nIf you have E2E test you definitely should run it on Cloud.\nUnit Test it's environment independent testing."},{"comment_id":"76275","content":"Wouldn't you run the E2E tests to check if all works fine. What is the purpose of those additional unit test that are mentioned in B? I am unclear.","upvote_count":"3","poster":"PRC","timestamp":"1603085700.0"},{"comment_id":"70915","timestamp":"1601781660.0","upvote_count":"4","content":"C is not correct because they already have 100% end to end coverage. Also, the question is talking about additional testing methods. Hence B is correct","poster":"Jeysolomon","comments":[{"poster":"Bijesh","comment_id":"236550","timestamp":"1622982600.0","upvote_count":"1","content":"\"They want to ensure that the move to the cloud does not introduce any new bugs.\" \nUnit tests has nothing to do with wer the application Runs. It should be C"},{"comment_id":"186143","timestamp":"1616595360.0","poster":"Bolek","upvote_count":"3","content":"B says \"...add additional unit tests and ... on their cloud staging environment.\" You can not run unit tests on staging environment. Running end to end tests in staging _is_ an additional testing method. Hence C is correct."}]},{"comments":[{"timestamp":"1630809540.0","poster":"nitinz","content":"B is correct","comment_id":"303940","upvote_count":"2"},{"poster":"techalik","upvote_count":"4","timestamp":"1622173380.0","content":"what about C:\n\nUpdate the test plan to modify end to end tests for GCP environment. is the right answer.\n\nYou want to ensure the move to the cloud does not introduce any new bugs, so Dress4Win is not yet on Google Cloud which means the end to end test which cover 100% of their endpoints are running on the services/applications in the data centre. The scenario states \"They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them.\" so some components of their solution might need to be redesigned. Therefore, it is important to first carry out end-to-end tests on Cloud staging environment to see if all functionality works as expected. Unit test and load tests help, but end-to-end testing is needed first to ensure the application with all its various related services functions as intended.","comment_id":"229427"},{"comments":[{"poster":"Rafaa","comments":[{"comment_id":"155938","poster":"tartar","content":"B is ok","upvote_count":"6","timestamp":"1613093880.0"}],"content":"Debugger is not used to show errors in the code. If there are error, they would be captured in Stackdriver Error Reporting and unit test itself much before running anything!","upvote_count":"1","timestamp":"1607326260.0","comment_id":"104316"}],"poster":"ROPATE","upvote_count":"1","content":"i mean what about A?","timestamp":"1598191920.0","comment_id":"54173"}],"comment_id":"54172","poster":"ROPATE","timestamp":"1598191920.0","upvote_count":"2","content":"what about B? should not use stack driver."}],"question_text":"Dress4Win has end-to-end tests covering 100% of their endpoints.\nThey want to ensure that the move to the cloud does not introduce any new bugs.\nWhich additional testing methods should the developers employ to prevent an outage?","choices":{"B":"They should add additional unit tests and production scale load tests on their cloud staging environment.","D":"They should add canary tests so developers can measure how much of an impact the new release causes to latency.","C":"They should run the end-to-end tests in the cloud staging environment to determine if the code is working as intended.","A":"They should enable Google Stackdriver Debugger on the application code to show errors in the code."},"url":"https://www.examtopics.com/discussions/google/view/14735-exam-professional-cloud-architect-topic-11-question-9/"},{"id":"DDVCexaUWRErjNEG1CkG","exam_id":4,"question_images":[],"answer_description":"","question_text":"For this question, refer to the Dress4Win case study. Dress4Win is expected to grow to 10 times its size in 1 year with a corresponding growth in data and traffic that mirrors the existing patterns of usage. The CIO has set the target of migrating production infrastructure to the cloud within the next 6 months. How will you configure the solution to scale for this growth without making major application changes and still maximize the ROI?","unix_timestamp":1571501880,"url":"https://www.examtopics.com/discussions/google/view/6803-exam-professional-cloud-architect-topic-12-question-1/","answer":"D","choices":{"A":"Migrate the web application layer to App Engine, and MySQL to Cloud Datastore, and NAS to Cloud Storage. Deploy RabbitMQ, and deploy Hadoop servers using Deployment Manager.","D":"Implement managed instance groups for the Tomcat and Nginx. Migrate MySQL to Cloud SQL, RabbitMQ to Cloud Pub/Sub, Hadoop to Cloud Dataproc, and NAS to Cloud Storage.","B":"Migrate RabbitMQ to Cloud Pub/Sub, Hadoop to BigQuery, and NAS to Compute Engine with Persistent Disk storage. Deploy Tomcat, and deploy Nginx using Deployment Manager.","C":"Implement managed instance groups for Tomcat and Nginx. Migrate MySQL to Cloud SQL, RabbitMQ to Cloud Pub/Sub, Hadoop to Cloud Dataproc, and NAS to Compute Engine with Persistent Disk storage."},"isMC":true,"answer_images":[],"timestamp":"2019-10-19 18:18:00","answers_community":["D (65%)","C (35%)"],"answer_ET":"D","topic":"12","discussion":[{"upvote_count":"45","comment_id":"16096","poster":"MeasService","content":"Why do we need to put NAS data on persistant disk and not on GCS ? I would go with D!","timestamp":"1587313080.0","comments":[{"poster":"techalik","content":"1. Use Cloud Marketplace to provision Tomcat and Nginx on Google Compute Engine.\n\n2. Replace MySQL with Cloud SQL for MySQL.\n\n3. Use the Deployment Manager to provision Jenkins on Google Compute Engine. is the right answer.\n\nAs explained above, you would use Cloud SQL to replace MySQL. For the other requirements, i.e. Nginx/Tomcat and Jenkins, you can deploy these through Cloud Deployment Manager by using custom images.\n\nRef: https://cloud.google.com/compute/docs/images\n\nUsing the same custom images every time ensures that your environments are \"reliable and reproducible\" and you achieve \"rapid provisioning\".\n\nD","timestamp":"1622211660.0","comment_id":"229721","upvote_count":"12"},{"upvote_count":"4","poster":"nitinz","comment_id":"303949","timestamp":"1630809900.0","content":"ans is D"},{"upvote_count":"11","timestamp":"1613097300.0","comment_id":"155966","poster":"tartar","content":"D is ok","comments":[{"upvote_count":"3","comment_id":"262636","poster":"Jphix","content":"Agreed. Looking to maximize ROI as well according to the question, and even the most expensive cloud storage is still going to be half the price of cheapest Persistent Disk storage, and that's without even including your compute costs. D all the way.","timestamp":"1625747460.0"}]}]},{"comment_id":"16965","comments":[{"comments":[{"timestamp":"1643551740.0","comment_id":"417360","upvote_count":"4","content":"It can, check on Cloud Storage FUSE. Buckets can be mounted as file systems.","poster":"poseidon24"}],"upvote_count":"10","timestamp":"1593772320.0","poster":"exampanic","comment_id":"34921","content":"I agree that GCS fits perfectly for storing images, log, backup. However, the question asks to avoid major application changes. GCS is not NAS, meaning it does not provide SMB or NFS shares. Therefore moving the NAS files to Google Cloud Storage would require a major application change in the way they access these files. I believe the correct answer would be C."}],"poster":"KouShikyou","upvote_count":"21","content":"I prefer D.\nOriginal NAS is for image, log, backup. GCS fits it perfectly.","timestamp":"1587647460.0"},{"content":"Selected Answer: D\nD is correct answer.","comment_id":"1388217","timestamp":"1741852080.0","poster":"cloud_rider","upvote_count":"1"},{"content":"A - no, MySQL (relational) to Datastore (document-oriented) is not a good idea\nB - no, because Hadoop to BigQuery\nC - NAS is currently 65 TB (\"100 TB total storage; 35 TB available\") for image storage, logs, backups, so with \"10 times its size in data that mirrors the existing patterns of usage\" would be 650 TB. A look to https://cloud.google.com/architecture/storage-advisor?hl=en#comparative_analysis says, it's too big for Persistent Disk. Also a replacement for NAS would be Filestore.\nD - I would choose this, even if it is an application change. Who knows if it is major. But it can have a good ROI, because Cloud Storage can be cheaper.","comment_id":"1347890","timestamp":"1738067280.0","upvote_count":"1","poster":"user263263"},{"poster":"farhan880","content":"Selected Answer: C\nBecause min change","timestamp":"1736093460.0","upvote_count":"1","comment_id":"1336809"},{"content":"Selected Answer: D\nUse case suitability:\nCloud Storage: Ideally suited for storing large, unstructured data like images, videos, and backups, which is likely the case for Dress4Win's NAS data.\nPersistent Disk: More appropriate for frequently accessed data that requires block-level access, such as databases or operating systems for virtual machines.","timestamp":"1725371220.0","poster":"mesodan","comment_id":"1164897","upvote_count":"4"},{"timestamp":"1723276860.0","content":"Selected Answer: D\nCorrect Ans: A\nNAS `\" image storage, logs, backups : for storing images, logs and backups Cloud Storage is best practice and cost effective also.","comment_id":"1146024","comments":[{"upvote_count":"1","content":"Wrongly typed A, it must be D","comment_id":"1146025","timestamp":"1723276920.0","poster":"kampatra"}],"poster":"kampatra","upvote_count":"2"},{"comment_id":"1095875","timestamp":"1718310600.0","upvote_count":"2","content":"Selected Answer: D\nShould be D","poster":"mbacelar"},{"comment_id":"1095152","poster":"MahAli","content":"Selected Answer: C\nVoting c NAS could have been replaced with file store to minimize any change, moving to GCS is not that easy change in overall architecture","upvote_count":"1","timestamp":"1718249460.0"},{"comment_id":"1091839","upvote_count":"2","poster":"Jannchie","timestamp":"1717935000.0","content":"Selected Answer: C\nC, because we can run some script on NAS. It can\n act like a normal server. But GCS cannot."},{"upvote_count":"1","comment_id":"1085698","content":"Selected Answer: C\nwithout making major application changes and still maximize the ROI --> compute engine with persistent disk. without knowing access patterns, GCS may not be an easy change.","poster":"techtitan","timestamp":"1717295100.0"},{"timestamp":"1688135700.0","content":"Selected Answer: D\nyou don't need NAS to store archive and Image disk","upvote_count":"2","poster":"thamaster","comment_id":"762145"},{"timestamp":"1669136340.0","poster":"amxexam","upvote_count":"2","content":"Selected Answer: D\nD is the correct chand equivalent mapping","comment_id":"605580"},{"upvote_count":"2","timestamp":"1663659300.0","comment_id":"571519","content":"D is OK\n\nhttps://cloud.google.com/architecture/filers-on-compute-engine?hl=en#managed_file_storage_solutions","poster":"[Removed]"},{"timestamp":"1657271400.0","content":"SAN -> persistent disk, NAS -> Cloud Storage","comment_id":"519460","poster":"MF2C","upvote_count":"2"},{"upvote_count":"2","comment_id":"509662","timestamp":"1656248460.0","poster":"edilramos","content":"Managed Instances With Tomcat and Nginx would bring the minimum necessary tweaking to the new environment.\nMigrating from MySql to Cloud SQL does not require any syntax changes.\nMoving from Rabbit MQ to Pub/Sub is relatively straightforward and has very complete documentation.\nDataProc has Libraries and tools to ensure Apache Hadoop interoperability.\nWithout many changes in the environment, mainly keeping the original architecture, Datastorage will keep the presentation characteristics of a shared area, mapped to the instances."},{"upvote_count":"3","comment_id":"489010","timestamp":"1653721920.0","content":"Selected Answer: C\nThe answer should be C. 'A' and 'B' are ruled out as they introduce significant architecture changes. or irrelevant. 'D' is fine except proposes to replace NAS with Cloud Storage. This will introduce major architectural changes. Instead, if the choice was to move 'NAS' to 'Cloud Filestore' then it would have made sense. Answer 'C' is the closest with the least amount of architectural changes involved in migration.","poster":"phantomsg"},{"content":"Selected Answer: D\nvote D","timestamp":"1653649980.0","comment_id":"488153","poster":"joe2211","upvote_count":"4"},{"poster":"kopper2019","timestamp":"1642516800.0","comments":[{"poster":"anku15","upvote_count":"1","content":"I dont see the questions now. Did you remove it?","comment_id":"445136","timestamp":"1647345300.0"}],"upvote_count":"1","comment_id":"408950","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152"},{"timestamp":"1642412940.0","content":"D. Implement managed instance groups for the Tomcat and Nginx. Migrate MySQL to Cloud SQL, RabbitMQ to Cloud Pub/Sub, Hadoop to Cloud Dataproc, and NAS to Cloud Storage.","poster":"victory108","upvote_count":"1","comment_id":"408317"},{"comment_id":"401727","poster":"MamthaSJ","content":"Answer is D","timestamp":"1641640260.0","upvote_count":"1"},{"timestamp":"1633095960.0","upvote_count":"1","comment_id":"325895","content":"Answer is D","poster":"Ausias18"},{"comment_id":"311496","timestamp":"1631707680.0","upvote_count":"2","content":"They expect “to grow to 10 times its size in 1 year with a corresponding growth in data and traffic”\nAnd “migrating production infrastructure to the cloud within the next 6 months”. \nThe MySQL DB has now 5 TB of data. In 6 months, it will raise to 25 TB. In 1 year to 50 TB. The limit for MySQL DB size is 30 TB. So it is very likely that when we launch the solution on PROD the MySQL DB will be very close to the limit. I would rather like to avoid the problem and migrate MySQL DB to Datastore. Datastore is also transactional like MySQL, hence no change in application code. \nDeploying RabbitMQ also will avoid the need to the code change. \nMigration of the web application layer to App Engine and Hadoop: as is. \nFrom the application code perspective, migration to option A requires only one change NAS -> GCS. And at the end we get and scalable solution. \nI go with A.","comments":[{"upvote_count":"1","comment_id":"331551","content":"You almost convinced me with the MySQL scaling issue, but then I realized that the DB size will not grow proportionally with the number of users as _past collected_ data is what makes it grow. Still, the issue should be on the radar and the company should start working on plan-B, as it will likely cause issues in the next year.","poster":"mrhege","timestamp":"1633725780.0"},{"upvote_count":"1","content":"IMO you are wrong with A...\nA states Migration MySQL to Cloud Datastore (which is NoSQL, object DB) - non sense.\nIMO D is the right.","comment_id":"318212","comments":[{"comment_id":"323543","upvote_count":"1","content":"Also - Cloud SQL includes SQL Server (from about 6 months ago )","poster":"lynx256","timestamp":"1632925320.0"}],"poster":"lynx256","timestamp":"1632404880.0"}],"poster":"pawel_ski"},{"content":"ans : D is the right answer","poster":"ahmedemad3","timestamp":"1628429160.0","upvote_count":"1","comment_id":"286284"},{"poster":"bnlcnd","upvote_count":"2","content":"C vs D. NAS should go to Cloud Storage.\nD is right.","timestamp":"1628038620.0","comment_id":"283092"},{"comment_id":"246753","poster":"okixavi","upvote_count":"1","content":"D is the right answer","timestamp":"1623948060.0"},{"comment_id":"233664","poster":"Chulbul_Pandey","content":"D is good\nNAS for storage","upvote_count":"1","timestamp":"1622688420.0"},{"comment_id":"220959","poster":"dcjdcj","content":"If they're 'expected to grow to 10 times its size in 1 year' then Cloud Storage (D) is probably the better option, scalability wise.","timestamp":"1621239000.0","upvote_count":"1"},{"poster":"ccie_pgh","timestamp":"1621161780.0","comment_id":"220322","content":"I will be going with A; here is my reasoning...\n• Easier migration of web app layer to App Engine versus migration of RabbitMQ and Hadoop; “Build and deploy apps quickly using popular languages or bring your own language runtimes and frameworks. You can also manage resources from the command line, debug source code, and run API back ends easily.” NGINX is either Python or Go, which App Engine supports; Tomcat is Java and also supported. https://cloud.google.com/appengine\n• Also, Cloud Datastore fits well for migration of DB & retail use case: https://cloud.google.com/datastore/docs/concepts/overview#what_its_good_for","upvote_count":"2"},{"poster":"gcparchitect007","content":"D is the right answer.","timestamp":"1619757300.0","upvote_count":"1","comment_id":"209759"},{"poster":"Gudwin","upvote_count":"1","comment_id":"204177","timestamp":"1619091720.0","content":"The question is to match services, don't overcomplicate it."},{"timestamp":"1617529440.0","content":"correct answer is D.","upvote_count":"1","comment_id":"192820","poster":"akhadar2001"},{"comment_id":"188155","timestamp":"1616832540.0","content":"I think the key to this is: scale for this growth \"without making major application changes\"\n\nAssuming the application is accessing NAS based on file system.\n\nSo, Option C is the closest to it.\n\nOption D - Cloud Storage - This will require change in the application codes to use Cloud Storage API to get the files. (And here is the argument point. Is this change consider a minor or major change?)","poster":"VedaSW","upvote_count":"1"},{"comment_id":"186209","upvote_count":"1","poster":"roastc","content":"I will go with option C: because throughput requirement for NAS is much more than what is available with Cloud storage. All possible options are listed here. But Cloud storage is not listed - https://cloud.google.com/solutions/filers-on-compute-engine#single-node-file-server","timestamp":"1616601900.0"},{"content":"It's D. Want to move with least change. NAS is serving files which is on block storage most likely via NFS/CIFS. Cloud Storage is object storage, not block storage and no NFS/CIFS.","timestamp":"1615756560.0","poster":"thecheops","comment_id":"179512","upvote_count":"1"},{"comment_id":"158036","content":"I choose Option D, As anyway there is a code change while Migrating RabbitMQ to Cloud Pub-Sub and secondly as per google documentation for NAS it recommends Cloud Storage. Hence option D sounds good here.","poster":"mbiy","upvote_count":"1","timestamp":"1613308020.0"},{"upvote_count":"1","poster":"yyy","comment_id":"153613","content":"Answer is B:\nMigrate RabbitMQ to Cloud Pub/Sub requires a lot of application changes and NAS to Cloud Storage similar to","timestamp":"1612882320.0"},{"content":"There is no NAS interface to GCS unless you are using gcs-fuse (https://cloud.google.com/storage/docs/gcs-fuse) which would also require a VM so it looks like C is a better option here.\n\nIt would be much easier answer if they had Filestore in the answers.","comment_id":"130477","timestamp":"1610194020.0","upvote_count":"1","poster":"cetanx"},{"upvote_count":"1","poster":"Google","content":"Answer - D,\n\nNAS data on storage.","comment_id":"125578","timestamp":"1609687680.0"},{"comment_id":"123114","content":"Based on the request of \" growth without making major application changes\" we can believe that migrating NAS to Compute Engine with Persistent Disk storage is the best fit. However based on the amount of data that would be migrated and the costs of using Disk Storage, this make no sense. Therefore I'll go with D.","poster":"HectorLeon2099","upvote_count":"1","timestamp":"1609291920.0"},{"upvote_count":"2","comment_id":"121131","timestamp":"1609070580.0","poster":"pbrat","content":"Answer D : considering NAS for image storage, logs, backups"},{"upvote_count":"1","poster":"mlantonis","timestamp":"1608822420.0","content":"As per \"NAS - image storage, logs, backups 100 TB total storage; 35 TB available\". Persistent Disks has a limit 64TB even if it is SSD or HDD.\nC: Can be correct only if we condiser multiple Persistent Disks, which is not ideal in my mind.\nD: Sounds a better solution, because the amount of data fits in GCS.\n\nI would choose D.","comment_id":"118437"},{"timestamp":"1608752340.0","poster":"motty","comment_id":"117704","upvote_count":"1","content":"C is correct answer"},{"comment_id":"113806","timestamp":"1608376440.0","content":"According to Google best practices, we should avoid using non-manageable services if there is a possibility to use manageable (GCS). So the answer is D.","poster":"Digital_D","upvote_count":"1"},{"comment_id":"109724","content":"D is the correct answer because of NAS part","upvote_count":"1","poster":"mikey007","timestamp":"1607904780.0"},{"timestamp":"1607582700.0","poster":"TKCZ","comment_id":"106468","upvote_count":"4","content":"D > Linux Academy"},{"comment_id":"104097","timestamp":"1607294340.0","poster":"Ziegler","content":"D is the correct answer","upvote_count":"1"},{"content":"it is possibe to access mcloud storage as file system by mounting as drive\nhttps://cloud.google.com/compute/docs/disks/gcs-buckets#mount_bucket\nso the correct answer should be D","timestamp":"1606745160.0","poster":"jayaen","upvote_count":"1","comment_id":"98814"},{"content":"Final Decision to go with Option D","poster":"AD2AD4","comment_id":"97963","upvote_count":"1","timestamp":"1606622460.0"},{"comment_id":"97785","upvote_count":"1","poster":"amralieg","timestamp":"1606599480.0","content":"Answer is D. NAS goes to Cloud storage. if it was SAN it could go to either persistence disks or cloud storage"},{"timestamp":"1604339700.0","comment_id":"82660","poster":"Ayzen","upvote_count":"2","content":"A small question to think about: their MySQL DB currently uses 600TB. Which is much higher than Cloud SQL limits ( up to 30,720 GB, depending on machine type)."},{"comment_id":"60571","poster":"rickywck","timestamp":"1599529800.0","upvote_count":"4","content":"This question is tricky again. What does it mean by major application change? Migration from RabbitMQ to Cloud Pub/Sub will require code change anyway, so why not making code changes to use GCS to replace NAS given GCS is perfect for their requirements?"},{"comments":[{"content":"did u clear the exam with this option","comment_id":"191502","timestamp":"1617354780.0","poster":"hiteshlti","upvote_count":"1"}],"timestamp":"1599166920.0","content":"Selected D in the exam","upvote_count":"3","comment_id":"58446","poster":"[Removed]"},{"comment_id":"50653","poster":"ADVIT","content":"They using NAS for image storage, logs, backups.\nDefinitely it's D.","upvote_count":"4","timestamp":"1597428600.0","comments":[]},{"comment_id":"34630","timestamp":"1593705000.0","content":"Ans is D as C has 64 TB limit - \"Persistent Disk offers industry-leading price performance for both HDD and SSD to satisfy your needs whether you’re optimizing for latency sensitive workloads or high throughput workloads. HDD offers low-cost storage with a focus on affordability for large devices for which bulk throughput is of primary importance. SSD offers consistently high performance for both random access workloads and bulk throughput. Both types can be up to 64 TB in size\"\nhttps://cloud.google.com/persistent-disk/","poster":"MyPractice","upvote_count":"3","comments":[{"poster":"exampanic","timestamp":"1593772920.0","upvote_count":"1","comments":[{"comments":[{"comment_id":"139533","content":"You would still need VMs to enable it, GCS cannot serve for that purpose all alone by itself.","upvote_count":"1","poster":"cetanx","timestamp":"1611155580.0"}],"upvote_count":"1","poster":"chauvinhloi","content":"What if they use a GCS bucket attaching to Compute Engine Instance to make it become a NAS --> So confused! Also if the large storage capacity is required, it is better to go with GCS.","comment_id":"95888","timestamp":"1606385520.0"},{"comment_id":"39782","content":"Sounds good.... Convinced it is C","timestamp":"1594909020.0","poster":"MeasService","upvote_count":"2"}],"comment_id":"34927","content":"Maximum size of a single persistent disk is 64TB, but nothing prevents you from using more than one disk on a compute instance. You can have up to 128 persistent disks on a single instance. Even if that was not enough, you can have several compute instances acting as a NAS replacement. \nAlthough option D is technically valid, I still believe the best answer is C based on the requirement of avoiding major changes to the application (because Google Cloud Storage cannot be configured as a NAS)."}]},{"poster":"passnow","upvote_count":"1","comment_id":"30813","content":"please guys take a look at the requirements. Their storage option for messages is NAS, so its typical and right to migrate NAS to cloud pub/sub. I chose D","timestamp":"1592518680.0"},{"content":"This is not like AWS, https://cloud.google.com/docs/compare/data-centers/storage#network-attached_storage_nas I think that it is C, because it is a more native solution","timestamp":"1590741060.0","comment_id":"25179","upvote_count":"1","poster":"chiar"},{"poster":"JJu","upvote_count":"8","content":"I think answer is D.\nThis full scenario explain about Storage appliances.\n\nNAS - image storage, logs, backups, 100 TB total storage; 35 TB available\n\nUsage storage size of NAS is 65TB. But Maximum size of persistent Disk Storage is 64TB.\nPersistent Disk Storage do not enough.\n\n--- Sorry, I'm not good at English.---","comments":[{"upvote_count":"2","comment_id":"34925","poster":"exampanic","timestamp":"1593772500.0","content":"Maximum size of a single persistent disk is 64TB, but nothing prevents you from using more than one disk."}],"comment_id":"24938","timestamp":"1590632280.0"},{"timestamp":"1590219420.0","comment_id":"23820","upvote_count":"4","content":"can we keep 100TB with persistant Disk with logs and other details as mentioned in their current infrastructure? I feel D should be more appropriate answer.","poster":"Jayant"},{"upvote_count":"5","comment_id":"23023","poster":"chiar","timestamp":"1589972400.0","content":"It's D"},{"comment_id":"21741","upvote_count":"5","timestamp":"1589530860.0","poster":"JoeShmoe","content":"Answer is D"},{"upvote_count":"3","timestamp":"1588188000.0","poster":"Eroc","comment_id":"18290","content":"Both are possible and both methods are documented by Google. Computer Engine: (https://cloud.google.com/docs/compare/data-centers/storage#network-attached_storage_nas) as well as Cloud Storage (https://cloud.google.com/solutions/partners/komprise-extending-on-premises-storage-with-gcp) ... Which answer did the test maker choose? I'm going with they Compute Engine because it is more adaptable to specific use cases... C"},{"comment_id":"16097","poster":"MeasService","upvote_count":"1","content":"Hmm... so NAS is accessed via ip and question mention without making any major application changes. This should be reason to persist with SAN. so C is the answer.","timestamp":"1587313260.0"}],"question_id":218},{"id":"hv2Yxq3IZGOUjey7edps","answer_images":[],"discussion":[{"comments":[{"upvote_count":"2","content":"A is the answer","poster":"nitinz","timestamp":"1646455740.0","comment_id":"303952"},{"timestamp":"1627388580.0","comments":[{"comment_id":"155959","upvote_count":"5","poster":"tartar","timestamp":"1628727960.0","comments":[{"comment_id":"262698","timestamp":"1641659520.0","content":"agreed, A. For those saying C, the question is about \"automating the deployment\" in line with the business requirements. Going from MySQL to datastore might be a good idea long term, but it won't make automating the deployment to the cloud any easier or smoother. Automate the deployment to Cloud SQL because it's a natural fit, and once that's working, re-assess the requirements to decide if it's worth the hefty lift of shifting from MySQL to a NoSQL Document DB.","poster":"Jphix","upvote_count":"1"}],"content":"A is ok"}],"poster":"cetanx","content":"Also, GAE uses Jetty for http and servlet engine. Therefore Tomcat cannot be run on GAE (unless on flexible env.) - this rules out \"C and D\"","upvote_count":"2","comment_id":"144948"}],"timestamp":"1603722420.0","poster":"jcmoranp","comment_id":"17592","content":"It's A, \"Cloud Datastore server\" doesn't exist. A fits OK.","upvote_count":"26"},{"poster":"Eroc","comments":[{"poster":"SSQX","content":"You can only deploy Jenkins with Cloud Launcher, not with Deployment manager","upvote_count":"2","timestamp":"1617291060.0","comments":[{"content":"Jenkins is just an app that should be run on a VM. You definitely can use Deployment Manager to set up a VM with needed image.","poster":"Ayzen","timestamp":"1619598360.0","comment_id":"80723","upvote_count":"3"}],"comment_id":"70159"}],"content":"The requriements also specify:\n\"Easily create non-production environment in the cloud.\nImplement an automation framework for provisioning resources in cloud.\nImplement a continuous deployment process for deploying applications to the on-premises datacenter or cloud.\"\nSo A is better.","comment_id":"18292","upvote_count":"11","timestamp":"1604006880.0"},{"comments":[{"content":"Thinking about it a second time: If the business requirements are a distraction and the scope of the case study (\"\"For the first phase of their migration to the cloud, Dress4Win is moving their development and test environments. They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them.\") is more relevant, then it's A. You can deploy Nginx, Tomcat, Jenkins with Cloud Deployment Manager (even if it's not the best idea) and it fit's the scenario of only creating dev and test environments more or less identical to on-prem prod. The question is strange.","timestamp":"1738055820.0","upvote_count":"1","comment_id":"1347809","poster":"user263263"}],"comment_id":"1347799","timestamp":"1738054920.0","poster":"user263263","content":"Selected Answer: D\nNot A, B - I would not deploy Jenkins with Deployment Manager, if I can do so with Cloud Marketplace (new name of Cloud Launcher, follow https://cloud.google.com/launcher/).\nNot C - you cannot replace a relational DB with Datastore\nCheck if D makes sense - migrate to App Engine is \"optimize architecture for performance in the cloud\", MySQL is in Cloud Marketplace (I would choose Cloud SQL even if I had to take 16 vCPU to get 128 GB) and Jenkins is also in Cloud Marketplace","upvote_count":"1"},{"poster":"rrope","timestamp":"1735244340.0","upvote_count":"1","comment_id":"1332109","content":"Selected Answer: A\nA. Deploy Nginx and Tomcat using Cloud Deployment Manager to Compute Engine"},{"poster":"theBestStudent","timestamp":"1733798460.0","comment_id":"1092259","content":"Selected Answer: D\nFor me is D:\n- Deploy NGINX and and Tomcat to App Engine, so both can scale up and down automatically\n- Deploy MySQL server using Cloud Launcer (nowadays called Marketplace)\n- Deploy Jenkins to Compute Engine using Cloud Launcher (nowadays called MarketPlace): Here literally they are choosing an instance (a compute instance to do so through MarketPlace) https://cloud.google.com/architecture/using-jenkins-for-distributed-builds-on-compute-engine.\n\nAnswer A can not be. it talks about SQL Server, why to bring that? Plus the way they want ton tackle Jenkins installation makes no sense if you already have MarketPlace. Also I'm ok that compute instances for NGINX and Tomcat could fit, BUT it doesn't talk about MIG or not MIG. It is not ensuring right declaration to have MIG and scale them up down through it will be in place.\n\n\nAnswer is D.","upvote_count":"1"},{"poster":"tuan072090","comment_id":"1005287","timestamp":"1726103400.0","content":"Selected Answer: A\nA is the most sense answer","upvote_count":"1"},{"content":"Selected Answer: A\nvote A","upvote_count":"1","poster":"joe2211","timestamp":"1669554900.0","comment_id":"488154"},{"content":"A. Deploy Nginx and Tomcat using Cloud Deployment Manager to Compute Engine. Deploy a Cloud SQL server to replace MySQL. Deploy Jenkins using Cloud Deployment Manager.","upvote_count":"2","timestamp":"1658043840.0","poster":"victory108","comment_id":"408315"},{"poster":"MamthaSJ","content":"Answer is A","comment_id":"401730","upvote_count":"2","timestamp":"1657271520.0"},{"content":"D. With produciton parity, you cant replace MySQL with 128 GB of memory with Cloud SQL as there is no such image available. I have checked it. MySQL has to go on GCE with PD\nI would go for either go for B or D.\nD is better because it is scalable better than B as B has no details if it is going to use MIG or just fleet of tomcat servers for web apps.","poster":"gosi","timestamp":"1650942300.0","upvote_count":"1","comment_id":"342964"},{"content":"Answer is A","upvote_count":"1","timestamp":"1648820880.0","comment_id":"325899","poster":"Ausias18"},{"upvote_count":"2","timestamp":"1646295060.0","content":"I think B is a valid response, please check:\nhttps://cloud.google.com/blog/products/it-ops/google-cloud-launcher-simplifies-running-third-party-apps-in-the-cloud\nand\nhttps://medium.com/@PeetDenny/automated-provisioning-of-jenkins-on-google-cloud-c297b2e0be2","comment_id":"302524","poster":"vruizm"},{"timestamp":"1643943900.0","comment_id":"283097","upvote_count":"2","poster":"bnlcnd","content":"the question and the answers are so confusing. what is \"Cloud Launcher\"? Never heard of it.\nOnly A does not mention that launcher thingy. I can only choose A.","comments":[{"poster":"Wira","upvote_count":"2","content":"its an old question - its cloud marketplace now\n\ngiven size of mysql and type of data, the only valid choice is C for me","comment_id":"311254","timestamp":"1647332700.0"},{"poster":"pawel_ski","content":"It's the previous name of GCP Marketplace.","comment_id":"311508","timestamp":"1647354120.0","upvote_count":"1"}]},{"comment_id":"272745","comments":[{"comment_id":"272746","poster":"ybe_gcp_cert","timestamp":"1642761660.0","content":"Sorry A doesn't tell which tool is used to deploy Cloud SQL. \nI would go with B.","upvote_count":"1"}],"content":"A or B;\nB doesn't tell which automation tool is used to deploy Cloud SQL. Cloud launcher generates Cloud Deployment Manager scripts. I would go with B","upvote_count":"1","timestamp":"1642761540.0","poster":"ybe_gcp_cert"},{"poster":"Mndwsk","comment_id":"242966","timestamp":"1639427520.0","content":"B. \nOnly option that automates the deployment of all the tools mentioned.\nCloud Launcher creates a Deployment in Deployment Manager.","upvote_count":"1"},{"content":"After reading the question more and kind of linking back to question one, i think it's asking how to \"automate the deployment\" of web and transactional data layers\". In that case, I think focus on deployment automation of existing technology might be a better than mapping new cloud technology in this case? so, A might be a better fit?","upvote_count":"1","comment_id":"217639","poster":"SKSKSK","timestamp":"1636682760.0"},{"poster":"homer_simpson","content":"the answer is A because datastore is nosql db and in business requirements it is clarly sais that improve bussiness agility and speed innovation through rapid provisoning of new ressources","comment_id":"203640","timestamp":"1634812620.0","upvote_count":"1"},{"timestamp":"1632642120.0","upvote_count":"4","poster":"brati_sankar","content":"I believe this is D. Here is my logic.\nIn D we are using a MySQL from the Marketplace. Presently, on-prem the amount of data is 600 TB (1 PB SAN for MySQL of which 400 TB is free) . This would not go in Cloud SQL which has a limit of 30 TB. Hence, we must go for MySQL on compute using Launcher/Marketplace.","comment_id":"187514"},{"comment_id":"186219","timestamp":"1632493200.0","poster":"roastc","upvote_count":"2","content":"I don't think there is any automation mentioned while using Cloud Launcher. So the answer should be A"},{"poster":"Kabiliravi","comment_id":"169406","content":"A is correct","timestamp":"1630255380.0","upvote_count":"1"},{"upvote_count":"1","content":"Answer A","poster":"pbrat","comment_id":"121133","timestamp":"1624788300.0"},{"poster":"mlantonis","content":"Tough question. There are two possibilities, A or C.\nA: If we consider that Jenkins will run on a VM, then we can use Deployment Manager to set up a VM with needed image.\n\nC: If we consider that the MySQL server stores user data, inventory, static data, then Cloud Datastore is an acceptable solution, but still it will be a complex migration.\n\nI choose A.","timestamp":"1624538400.0","comment_id":"118420","upvote_count":"2"},{"content":"A is correct answer.\n\nYou can not migrate open source software such as Nginx and Tomcap to AppEngine\nwithout re-writing big pieces of it. ( C and D are incorrect )\n\nMySQL should be deployed as managed CloudSQL (Launcher is a bad choice)\nand what is Clound Deployment manager \"scripts\" ? DM is using yaml definitions and gcloud to run them\nI think this invalidates B","upvote_count":"1","comment_id":"117713","poster":"motty","timestamp":"1624470420.0"},{"timestamp":"1623807060.0","poster":"hbansal077","comment_id":"111226","content":"A shud be correct ans.","upvote_count":"1"},{"content":"A is the correct answer","poster":"mikey007","timestamp":"1623622620.0","upvote_count":"1","comment_id":"109726"},{"comments":[{"comment_id":"106037","timestamp":"1623248880.0","content":"the only thing that Block me with D is to deploy Mysql with cloud launcher, But A and B are not working, Deployment manager cannot deploy jenkins. C not acceptable, you do not migrate DB,.\nSo I agree the only remaining feasible one is D","upvote_count":"1","poster":"pf38120","comments":[{"upvote_count":"1","timestamp":"1629660780.0","comment_id":"163862","content":"you can deploy nginx and jenkins from the marketplace using deployment manager","poster":"droidmasta"}]}],"timestamp":"1623154380.0","poster":"CoolCat","upvote_count":"1","comment_id":"105197","content":"Y not D ? Ngnix and tomcat can be easily run on app engine flexible."},{"poster":"AD2AD4","upvote_count":"3","timestamp":"1622253900.0","content":"Final Decision to go with Option A","comment_id":"97965"},{"comment_id":"97787","upvote_count":"1","content":"Answer is D. NAS goes to Cloud storage. if it was SAN it could go to either persistence disks or cloud storage","comments":[{"timestamp":"1633149240.0","upvote_count":"4","content":"dude, you talk abt previous question.","comment_id":"191379","poster":"hellothereby"}],"poster":"amralieg","timestamp":"1622230740.0"},{"content":"A is correct","timestamp":"1622206140.0","poster":"shiwenupper","upvote_count":"1","comment_id":"97552"},{"timestamp":"1621940700.0","comment_id":"95358","content":"A is the correct answer. Cloud Datastore is a NoSQL database and cannot be used for transactional data","poster":"Ziegler","upvote_count":"2"},{"poster":"Jack_in_Large","upvote_count":"2","comment_id":"90916","timestamp":"1621300620.0","content":"A) deployment automation"},{"content":"Answer: A","comment_id":"66546","poster":"[Removed]","timestamp":"1616337660.0","upvote_count":"4"},{"poster":"Smart","upvote_count":"2","comment_id":"55780","timestamp":"1614390900.0","content":"Switching Datastore is probably acceptable in Option C. However, Migrating to App Engine or Using Cloud Launcher is not quite relevant to automation."},{"poster":"sdu","upvote_count":"3","timestamp":"1611694320.0","comment_id":"43037","comments":[{"poster":"[Removed]","upvote_count":"1","comment_id":"204907","content":"I agree C is the answer. It Cloud Data Store fits the requirement. We need to optimize current inefficient architecture with Google recommended practices.","timestamp":"1635042120.0"},{"timestamp":"1619597160.0","comment_id":"80705","upvote_count":"6","content":"Looks like you haven't migrated complex data schemas from one DB to another. Even fairly similar MySQL and PostgreSQL can be a huge pain to migrate from one to another. Migrating MySQL to Datastore can take lots of time and efforts, despite that it supports ACIDs transactions and some \"SQL-like\" query syntax. Also, they're using Java, which implies Hibernate or something similar. As these kind of frameworks don't support Datastore, you'll have to migrate/remove everything related to them, and usually that's tons of code.","comments":[{"content":"I have had the displeasure of using Datastore for transactional data storage and i can tell you that it is not ideal for that scenario. Its \"SQL-like\" syntax is not as robust as the SQL.\n\nA should be the answer","timestamp":"1627318440.0","upvote_count":"3","poster":"OnomeOkuma","comment_id":"144266"}],"poster":"Ayzen"}],"content":"It is C.\n\nYou can move MySQL to DataStore.\nhttps://cloud.google.com/datastore/docs/concepts/overview#what_its_good_for\n\nDatastore is ideal for applications that rely on highly available structured data at scale. You can use Datastore to store and query all of the following types of data:\n Product catalogs that provide real-time inventory and product details for a retailer.\n User profiles that deliver a customized experience based on the user’s past activities and preferences.\n\nAlso in the business requirements; It says \"Analyze and optimize architecture for performance in the cloud\"\nIt is fine if we change the DB here."},{"upvote_count":"5","poster":"MeasService","timestamp":"1610814420.0","content":"Guys, Looking back at what SQL server is used for should help to understand why the right choice is C. Dress4win Case study says \"Databases:MySQL. One server for user data, inventory, static data,\" Cloud Datastore is the right place for such data hence I would replace mysql to Cloud datastore.","comment_id":"39783"},{"content":"its A - My SQL fits well with Cloud SQL (instead of Cloud Datastore as CD is No-SQL type). I choose Ans A","timestamp":"1609610160.0","upvote_count":"6","comment_id":"34632","poster":"MyPractice"},{"poster":"Eroc","timestamp":"1604006760.0","comment_id":"18291","content":"Datastore is a NoSQL database, slightly less structured than MySQL and Cloud SQL","upvote_count":"1"}],"answer_description":"","choices":{"C":"Migrate Nginx and Tomcat to App Engine. Deploy a Cloud Datastore server to replace the MySQL server in a high-availability configuration. Deploy Jenkins to Compute Engine using Cloud Launcher.","D":"Migrate Nginx and Tomcat to App Engine. Deploy a MySQL server using Cloud Launcher. Deploy Jenkins to Compute Engine using Cloud Launcher.","A":"Deploy Nginx and Tomcat using Cloud Deployment Manager to Compute Engine. Deploy a Cloud SQL server to replace MySQL. Deploy Jenkins using Cloud Deployment Manager.","B":"Deploy Nginx and Tomcat using Cloud Launcher. Deploy a MySQL server using Cloud Launcher. Deploy Jenkins to Compute Engine using Cloud Deployment Manager scripts."},"question_text":"For this question, refer to the Dress4Win case study. Considering the given business requirements, how would you automate the deployment of web and transactional data layers?","answers_community":["A (60%)","D (40%)"],"answer":"A","url":"https://www.examtopics.com/discussions/google/view/7265-exam-professional-cloud-architect-topic-12-question-2/","exam_id":4,"question_id":219,"question_images":[],"isMC":true,"timestamp":"2019-10-26 14:27:00","unix_timestamp":1572092820,"topic":"12","answer_ET":"A"},{"id":"OhvD9MorajK5SUZFENDA","choices":{"A":"Web applications deployed using App Engine standard environment","D":"Jenkins, monitoring, bastion hosts, security scanners services deployed on custom machine types","C":"Hadoop/Spark deployed using Cloud Dataproc Regional in High Availability mode","B":"RabbitMQ deployed using an unmanaged instance group"},"timestamp":"2019-10-26 14:31:00","answer":"C","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/7266-exam-professional-cloud-architect-topic-12-question-3/","question_images":[],"exam_id":4,"question_id":220,"answer_images":[],"answers_community":["C (100%)"],"answer_ET":"C","isMC":true,"question_text":"For this question, refer to the Dress4Win case study. Which of the compute services should be migrated as-is and would still be an optimized architecture for performance in the cloud?","discussion":[{"content":"Question is about compute services to be migrated as \"\"is and would still be an optimized architecture for performance - Apache Hadoop/Spark servers underline is compute and Hadoop/Spark deployed using Cloud Dataproc seems to be the correct answer.. Hence C seems correct answer to me","comments":[{"timestamp":"1695127740.0","content":"They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them.","upvote_count":"1","poster":"SAMBIT","comment_id":"571105"}],"comment_id":"104493","timestamp":"1638885900.0","poster":"Hemant_C","upvote_count":"29"},{"comment_id":"17593","content":"It's D. You cannot migrate to APP Engine \"as-is\"","upvote_count":"19","comments":[{"comment_id":"155945","upvote_count":"11","content":"C is ok","timestamp":"1644631500.0","poster":"tartar"},{"upvote_count":"7","timestamp":"1664728860.0","content":"C is correct","comment_id":"326814","poster":"army234"}],"poster":"jcmoranp","timestamp":"1619440260.0"},{"poster":"akhilesh_pundir","upvote_count":"1","timestamp":"1722460140.0","comment_id":"794703","content":"Read the previous questions ... they are going to use Managed instance groups with Tomcat &nginx installed on that so app engine is not in picture. Hadoop workloads goes to dataproc as it is."},{"content":"Selected Answer: C\nI agree with C.\n'as-is'","poster":"OrangeTiger","upvote_count":"4","timestamp":"1688973960.0","comment_id":"520761"},{"timestamp":"1687243320.0","upvote_count":"2","comment_id":"505275","content":"Google Cloud includes Dataproc, which is a managed Hadoop and Spark environment. You can use Dataproc to run most of your existing jobs with minimal alteration, so you don't need to move away from all of the Hadoop tools you already know.","poster":"ABO_Doma"},{"upvote_count":"2","poster":"ABO_Doma","content":"Selected Answer: C\nAnswer is C","timestamp":"1687102500.0","comment_id":"504360"},{"poster":"joe2211","timestamp":"1685186280.0","upvote_count":"2","content":"Selected Answer: C\nvote C","comment_id":"488156"},{"comment_id":"408311","poster":"victory108","upvote_count":"6","content":"C. Hadoop/Spark deployed using Cloud Dataproc Regional in High Availability mode","timestamp":"1673947980.0"},{"comment_id":"401732","upvote_count":"4","content":"Answer is C","poster":"MamthaSJ","timestamp":"1673176440.0"},{"upvote_count":"2","poster":"Ausias18","timestamp":"1665204240.0","comment_id":"330882","content":"Answer is C"},{"timestamp":"1661317560.0","upvote_count":"2","comment_id":"298015","content":"A. Web applications deployed using App Engine standard environment - there are multiple web apps, seems project limit of 1 - and not clear on the implications of Standard Env, with Nginx (there seems to be discussions) -- no not clear on this.\nB. RabbitMQ - is always replaced by Pub/Sub - So No.\nC. Hadoop/Spark - This is a well know Use Case\nD. Jenkins, Etc, these duplicate GCP products so it can't be the answer.\n\nMy bet is C","poster":"hkmsn"},{"timestamp":"1659965460.0","upvote_count":"1","content":"ans: C\n compute services should be migrated as is and would still be an optimized architecture for performance in the cloud?","poster":"ahmedemad3","comment_id":"286286"},{"content":"It's C. hardoop == dataproc. pretty much a cloud version.\nD is \"Jenkins, monitoring, bastion hosts, security scanners\". How can you make them as-is to run in cloud? Monitoring? on-prem to cloud no change? security scanner? no change?","upvote_count":"3","timestamp":"1659575340.0","poster":"bnlcnd","comment_id":"283099"},{"upvote_count":"1","poster":"BobBui","timestamp":"1659245700.0","comment_id":"280420","content":"I choose C"},{"comment_id":"249440","content":"C is the correct answer. The question says: \"...as is\"","poster":"okixavi","timestamp":"1655817660.0","upvote_count":"1"},{"upvote_count":"1","content":"C and D make sense. However, \"would still be an optimized architecture\". In this case, I chose C because we can move our services as is and we can get significant benefits from GCP","poster":"practicioner","comment_id":"215109","timestamp":"1651991820.0"},{"comment_id":"209762","timestamp":"1651293540.0","content":"C is correct answer.","upvote_count":"1","poster":"gcparchitect007"},{"content":"i choose A","upvote_count":"2","comment_id":"204967","timestamp":"1650783120.0","poster":"LoganIsh"},{"poster":"[Removed]","comment_id":"204912","content":"D is the answer. \nhttps://cloud.google.com/solutions/migrating-a-two-tier-web-app-to-gcp\n\nNote: Moving from a traditional LAMP workload to App Engine might require code changes to your application, and collaboration between infrastructure, operations, and developers. Make sure you weigh the costs and benefits before choosing an improve-and-move migration to App Engine.","upvote_count":"1","timestamp":"1650768300.0"},{"timestamp":"1649065500.0","comment_id":"192821","upvote_count":"1","content":"correct answer is D.","poster":"akhadar2001"},{"content":"D is the answer","comment_id":"169408","upvote_count":"1","poster":"Kabiliravi","timestamp":"1646073960.0"},{"timestamp":"1646070180.0","poster":"ragrag","comment_id":"170891","upvote_count":"1","content":"C is ok\nhttps://cloud.google.com/dataproc/docs/concepts/configuring-clusters/high-availability"},{"content":"I would think C is a better choice. With HA enabled and same technology stack.","timestamp":"1645905180.0","poster":"wiqi","upvote_count":"1","comment_id":"166961"},{"comment_id":"155944","upvote_count":"1","poster":"DCW1","timestamp":"1644631380.0","content":"I think everyone is missing what is being \"served\" by the Web Applications listed in the case study. You can move both Java Micro-Services and Static Content to AE Standard \"as-is\" and it will still be optimized for performance in the cloud (literally the point of AE). \n\nSO my answer is A.\n\nD could be right, but we dont know what \"custom machine types\" means, so you cant say for sure that everything listed would still be optimized for performance."},{"poster":"GCPMG","timestamp":"1644569580.0","comment_id":"155179","upvote_count":"1","content":"The question says computer services, prefered option would be D"},{"timestamp":"1643912760.0","upvote_count":"2","comment_id":"149867","poster":"vinasa71","content":"Dataproc is Zonal so Answer is D"},{"content":"\"... optimized architecture for performance in the cloud\" suggests a PaaS solution however AppEngine is not as-is but Datastore is.\n\nI would go with C","comment_id":"130551","poster":"cetanx","upvote_count":"1","timestamp":"1641735120.0"},{"poster":"HectorLeon2099","comment_id":"123120","content":"I'll go with C. You can migrate Hadoop as is on Dataproc. Option D seems right for Jenkins, however on the Cloud you have better options for monitoring (Stackdriver), bastion hosts and security scanners (Cloud Armor, Cloud Network Topology ).","timestamp":"1640828580.0","comments":[{"timestamp":"1657291860.0","upvote_count":"2","content":"Under-rated answer. Agreed with this because C is the only option \"optimized for cloud\" AND \"as-is\" basically","comment_id":"262709","poster":"Jphix"}],"upvote_count":"6"},{"timestamp":"1640606880.0","content":"'as is' is important, so Answer D","comment_id":"121136","upvote_count":"1","poster":"pbrat"},{"timestamp":"1640356200.0","upvote_count":"1","poster":"mlantonis","comment_id":"118417","content":"Question is about compute services to be migrated as-is. The most logical answer is C, but D could be also a candidate."},{"upvote_count":"2","timestamp":"1640289240.0","poster":"motty","comment_id":"117717","content":"It is D."},{"upvote_count":"1","content":"D cannot be answer because monitoring will be done by stackdriver, Answer is C, it is the only component which can be moved as-is","poster":"spanner","timestamp":"1639580280.0","comment_id":"110818"},{"poster":"mikey007","upvote_count":"1","timestamp":"1639441200.0","comment_id":"109729","content":"C should be correct answer as in above all question we have chosen GCE for the apps so A will not be the answer. D can not be as is ..."},{"comment_id":"104099","upvote_count":"3","content":"D is the correct answer. C is a good candidate but it says regional HA, which negated that choice","comments":[{"upvote_count":"2","timestamp":"1648140180.0","poster":"Bolek","comment_id":"186227","content":"C is fine. Regional HA Dataproc is OK. See https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/high-availability"}],"timestamp":"1638830700.0","poster":"Ziegler"},{"upvote_count":"3","content":"Final Decision to go with Option D","comment_id":"97968","timestamp":"1638159000.0","poster":"AD2AD4"},{"poster":"shiwenupper","upvote_count":"2","content":"I will go with C, since D is not talking about the performance","comment_id":"97555","timestamp":"1638111360.0"},{"comment_id":"70161","upvote_count":"2","timestamp":"1633102560.0","content":"Ans C, it's about performance and Jenkins, security ... have nothing to with performance","poster":"SSQX"},{"content":"I will buy Quizlet answer: A","timestamp":"1632313200.0","poster":"ff2107","comment_id":"66961","upvote_count":"2"},{"poster":"[Removed]","comment_id":"66545","comments":[{"comment_id":"121599","content":"SomabrataPani - I am really happy on your comments. How much score you got in the the exam?","comments":[{"comment_id":"139351","timestamp":"1642681080.0","comments":[{"timestamp":"1644898500.0","comment_id":"158400","comments":[{"content":"But not now - there is NO such Linkedin profile (SomabrataPani).","poster":"lynx256","comment_id":"318126","comments":[{"upvote_count":"1","timestamp":"1664454960.0","content":"Sorry - there is a Linkedin profile (Somabrata Pani).","poster":"lynx256","comment_id":"323424"}],"timestamp":"1663933020.0","upvote_count":"1"}],"upvote_count":"4","content":"Nope, your guess is wrong. Linkedin profile exist with this name with GCP certification .","poster":"rohit1986"}],"poster":"anant88","upvote_count":"4","content":"SomabrataPani is a bot i guess ! i havent seen him answering any of the concerns"}],"timestamp":"1640669700.0","upvote_count":"3","poster":"riyamalin"}],"upvote_count":"5","timestamp":"1632228000.0","content":"Answer: D"},{"content":"A is definitely not correct because custom runtime is required for Tomcat/Nginx. How about C? While D looks ok, but some of these components can be further optimized in Cloud environment by not migrating \"as-is\" such as using Stackdriver for monitoring, leveraging Cloud Build instead of Jenkins, etc.","comment_id":"60572","timestamp":"1631066520.0","poster":"rickywck","upvote_count":"6"},{"timestamp":"1628964900.0","upvote_count":"3","poster":"ADVIT","comment_id":"50654","content":"Yep, it's D."},{"poster":"MyPractice","content":"Agree with D","timestamp":"1625241720.0","upvote_count":"5","comment_id":"34635"},{"content":"It D because their impact is not like the others . Miscellaneous servers:\n- Jenkins, monitoring, bastion hosts, security scanners","poster":"passnow","upvote_count":"7","comment_id":"30814","timestamp":"1624054920.0"},{"comment_id":"18305","timestamp":"1619730540.0","poster":"Eroc","content":"I agree, D is referring to the case study.","upvote_count":"10"}],"unix_timestamp":1572093060,"topic":"12"}],"exam":{"numberOfQuestions":279,"id":4,"provider":"Google","isMCOnly":false,"name":"Professional Cloud Architect","isImplemented":true,"isBeta":false,"lastUpdated":"11 Apr 2025"},"currentPage":44},"__N_SSP":true}