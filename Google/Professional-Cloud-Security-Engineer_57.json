{"pageProps":{"questions":[{"id":"juok2IQdUWOYsTh4pNYu","isMC":true,"answer_ET":"B","timestamp":"2020-09-01 08:58:00","choices":{"B":"Cloud Storage buckets","C":"StackDriver logging","D":"Cloud Pub/Sub topics","A":"BigQuery datasets"},"discussion":[{"timestamp":"1725727920.0","content":"Selected Answer: B\nB : GCS without any doubts.","comment_id":"1168282","poster":"madcloud32","upvote_count":"2"},{"upvote_count":"3","poster":"[Removed]","timestamp":"1718406900.0","comment_id":"1096960","content":"Selected Answer: B\nB - minimizing cost"},{"content":"Selected Answer: B\n\"B\"\nKeyword here is minimizing cost. Cloud storage is typically the most cost effective option.\n\nReferences:\nhttps://cloud.google.com/blog/products/storage-data-transfer/how-to-save-on-google-cloud-storage-costs","comment_id":"960763","upvote_count":"3","poster":"[Removed]","timestamp":"1706044260.0"},{"upvote_count":"2","timestamp":"1687418220.0","comment_id":"753126","content":"Selected Answer: B\nB- is the cheapest optaion","poster":"shayke"},{"poster":"AzureDP900","timestamp":"1683229500.0","upvote_count":"2","content":"B is best for cost optimization perspective","comment_id":"711390"},{"content":"Selected Answer: B\nGCS would be the chipest option","upvote_count":"2","timestamp":"1681811400.0","comment_id":"698092","poster":"shayke"},{"comment_id":"688699","timestamp":"1680877800.0","upvote_count":"1","content":"Selected Answer: B\nB. Cloud Storage buckets","poster":"AwesomeGCP"},{"comment_id":"684095","upvote_count":"1","poster":"Deepanshd","timestamp":"1680339540.0","content":"Selected Answer: B\nCloud storage is always considered when minimize cost"},{"poster":"Bill1000","content":"B is correct","comment_id":"682724","upvote_count":"2","timestamp":"1680095820.0"},{"timestamp":"1661303940.0","upvote_count":"1","comment_id":"555050","poster":"mbiy","comments":[{"comment_id":"556835","upvote_count":"1","content":"Default retention for logging is 30 days because it is expensive to hold the logs there for longer duration. Bucket is always the cheapest option.","poster":"VJ_0909","timestamp":"1661526840.0"}],"content":"Ans C is correct, you can define a custom log bucket and mention the retention policy for any number of years (range - 1 day to 3650 days). Underlying these custom define log bucket is also created within Cloud Storage. As per the question you can retain log for 2 years in Stackdriver Logging which is aka Cloud Logging, and then later archive to cold line storage if there is a requirement."},{"poster":"jayk22","timestamp":"1651184760.0","upvote_count":"4","content":"Ans B. Validated.","comment_id":"469491"},{"poster":"DebasishLowes","upvote_count":"4","timestamp":"1631205120.0","content":"Ans: B","comment_id":"306612"},{"timestamp":"1619712300.0","upvote_count":"1","comment_id":"208769","poster":"[Removed]","content":"Ans - B"},{"upvote_count":"1","poster":"Raushanr","comment_id":"181264","content":"Ans is B","timestamp":"1616031240.0"},{"comment_id":"171225","poster":"mlyu","content":"Ans B\nCloud storage is always considered when minimize cost","timestamp":"1614589080.0","upvote_count":"2","comments":[{"upvote_count":"1","timestamp":"1614677580.0","comment_id":"171844","content":"Agree B","poster":"MohitA"}]}],"question_id":281,"question_text":"A manager wants to start retaining security event logs for 2 years while minimizing costs. You write a filter to select the appropriate log entries.\nWhere should you export the logs?","answers_community":["B (100%)"],"exam_id":9,"answer":"B","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/30236-exam-professional-cloud-security-engineer-topic-1-question/","answer_description":"","topic":"1","unix_timestamp":1598943480,"answer_images":[]},{"id":"ntVp1rISudNJGCej3CU8","topic":"1","answer":"C","question_images":[],"unix_timestamp":1651193460,"answer_description":"","question_text":"For compliance reasons, an organization needs to ensure that in-scope PCI Kubernetes Pods reside on `in-scope` Nodes only. These Nodes can only contain the\n`in-scope` Pods.\nHow should the organization achieve this objective?","answer_images":[],"answers_community":["C (63%)","A (38%)"],"isMC":true,"choices":{"D":"Run all in-scope Pods in the namespace ג€in-scope-pciג€.","B":"Create a node pool with the label inscope: true and a Pod Security Policy that only allows the Pods to run on Nodes with that label.","C":"Place a taint on the Nodes with the label inscope: true and effect NoSchedule and a toleration to match in the Pod configuration.","A":"Add a nodeSelector field to the pod configuration to only use the Nodes labeled inscope: true."},"timestamp":"2022-04-29 02:51:00","url":"https://www.examtopics.com/discussions/google/view/74818-exam-professional-cloud-security-engineer-topic-1-question/","question_id":282,"discussion":[{"content":"[A] Correct answer. This is a typical use case for node selector.\nhttps://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n\n[B] The Pod Security Policy is designed to block the creation of misconfigured pods on certain clusters. This does not meet the requirements.\n\n[C] Taint will no longer place pods without the \"inscope\" label on that node, but it does not guarantee that pods with the \"inscope\" label will be placed on that node.\n\n[D] Placing the \"in scope\" node in the namespace \"in-scope-pci\" may meet the requirement, but [A] takes precedence.","upvote_count":"11","comments":[{"comment_id":"611589","content":"I think [A] does not stop other pods from being run in the PCI node, which is a requirement as the question states... I would go with [C]","upvote_count":"8","poster":"MariaGabiGabriela","timestamp":"1670198040.0"},{"comment_id":"711391","content":"A is correct.","poster":"AzureDP900","timestamp":"1683229560.0","comments":[{"content":"C is correct","comment_id":"904674","timestamp":"1700731080.0","poster":"gcpengineer","upvote_count":"3"}],"upvote_count":"1"}],"comment_id":"594131","timestamp":"1667004660.0","poster":"Tabayashi"},{"comment_id":"898145","content":"Selected Answer: C\nC is the ans as per chatgpt","upvote_count":"6","timestamp":"1700046000.0","poster":"gcpengineer"},{"upvote_count":"1","poster":"Rakesh21","comment_id":"1349320","content":"Selected Answer: C\nTaints and Tolerations are used in Kubernetes to control which Pods can be scheduled on which Nodes. By applying a taint to Nodes labeled as inscope: true with the effect NoSchedule, you ensure that only Pods that can tolerate this taint can be scheduled on these Nodes. Then, by configuring the in-scope Pods with a matching toleration, you guarantee that only these Pods will land on the Nodes marked as in-scope. This method ensures both that only in-scope Pods run on these Nodes and that these Nodes are used exclusively for in-scope Pods, meeting the compliance requirement.","timestamp":"1738281540.0"},{"timestamp":"1734628260.0","content":"Selected Answer: C\nUsing a node selector does not prevent other pods from being scheduled in the pci-scope nodes. However a taint and toleration would ensure that only the pods with the toleration can be scheduled in the pci-scope nodes.","comment_id":"1329074","upvote_count":"1","poster":"JohnDohertyDoe"},{"upvote_count":"1","comment_id":"1213819","content":"Selected Answer: C\nwhy the other options are less suitable:\n\nA. nodeSelector: While nodeSelector can help target pods to specific nodes, it doesn't prevent other pods from being scheduled on those nodes if they fit the node's resources.\nB. Node pool and Pod Security Policy: Pod Security Policies are deprecated in newer Kubernetes versions, and node pools alone won't guarantee the required isolation.\nD. Namespace: Namespaces provide logical separation but don't inherently enforce node-level restrictions.","timestamp":"1732031040.0","poster":"pico"},{"timestamp":"1717309980.0","poster":"rsamant","upvote_count":"1","content":"A \nhttps://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/","comment_id":"1085968"},{"content":"C. Place a taint on the Nodes with the label inscope: true and effect NoSchedule and a toleration to match in the Pod configuration: This is the best solution. Taints and tolerations work together to ensure that Pods are not scheduled onto inappropriate nodes. By placing a taint on the Nodes, you are essentially marking them so that they repel all Pods that don't have a matching toleration. With this method, only Pods with the correct toleration can be scheduled on in-scope Nodes, ensuring compliance.","comment_id":"1007984","timestamp":"1710467640.0","upvote_count":"2","poster":"ArizonaClassics"},{"comment_id":"750953","upvote_count":"4","content":"Selected Answer: C\nA nodeselector configuration is from a pod template perspective. This question ask to PRESERVE some nodes for specific pods, so this is the main utilization for TAINT. This is a conceptual question and the answer is C","timestamp":"1687261680.0","poster":"Meyucho"},{"poster":"AwesomeGCP","content":"Selected Answer: A\nA. Add a nodeSelector field to the pod configuration to only use the Nodes labeled inscope: true.","timestamp":"1680878100.0","comment_id":"688702","upvote_count":"3"},{"timestamp":"1680530400.0","comment_id":"685586","content":"Selected Answer: A\nnodeSelector is the simplest recommended form of node selection constraint. You can add the nodeSelector field to your Pod specification and specify the node labels you want the target node to have. Kubernetes only schedules the Pod onto nodes that have each of the labels you specify. => https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\n\nTolerations are applied to pods. Tolerations allow the scheduler to schedule pods with matching taints. Tolerations allow scheduling but don't guarantee scheduling: the scheduler also evaluates other parameters as part of its function. => https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/","poster":"GHOST1985","upvote_count":"3"},{"content":"Selected Answer: C\nBasic K8s principles of scheduling workloads.\nTaints and tolerations make perfect sense for this use case. Therefore C.","comment_id":"666045","upvote_count":"2","poster":"fanilgor","timestamp":"1678539540.0"},{"content":"Selected Answer: A\nhttps://redhat-scholars.github.io/kubernetes-tutorial/kubernetes-tutorial/taints-affinity.html\nA Taint is applied to a Kubernetes Node that signals the scheduler to avoid or not schedule certain Pods.\nA Toleration is applied to a Pod definition and provides an exception to the taint.\n\nhttps://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\nNode affinity is a property of Pods that attracts them to a set of nodes (either as a preference or a **hard requirement**). \nTaints are the opposite -- they allow a node to repel a set of pods.","upvote_count":"3","poster":"Jeanphi72","timestamp":"1677227520.0","comment_id":"651124"},{"timestamp":"1671024420.0","comment_id":"616177","poster":"hybridpro","content":"Answer should be C. \"These Nodes can only contain the\nג€in-scopeג€ Pods.\" - this can only be achieved by taints and tolerations.","upvote_count":"1"}],"answer_ET":"C","exam_id":9},{"id":"AejpERr0Qk9JsPOBBYDS","answer":"A","topic":"1","question_id":283,"url":"https://www.examtopics.com/discussions/google/view/30350-exam-professional-cloud-security-engineer-topic-1-question/","answer_description":"","question_images":[],"discussion":[{"comment_id":"228225","timestamp":"1606385040.0","content":"when I revisited this, Now I think A is correct. In A - We will use an approved encryption method for encrypting Local SSD and VM to VM communication. In B and D, we are still using GCP's encryption algorithms and are not FIPS 140-2 approved. Moreover only the BoringCrypto is FIPS 140-2 approved and not the Boring SSL. I see A as evidently correct. ownez, genesis3k, MohitA has explained this and provided the right links too.","poster":"subhala","upvote_count":"16"},{"comment_id":"1349389","content":"Selected Answer: B\nDisk Encryption with customer-managed keys: FIPS 140-2 compliance often requires encryption, and using customer-managed encryption keys (CMEK) ensures that you have control over the encryption keys, which can be crucial for compliance. Google Cloud supports FIPS 140-2 compliant encryption for data at rest with customer-managed keys.\n\nBoringSSL for data transit: BoringSSL is Google's fork of OpenSSL, designed to meet high standards of cryptographic security, including FIPS 140-2. Using BoringSSL for instance-to-instance communications ensures that data in transit is encrypted according to the necessary standards. Although UDP isn't inherently encrypted, you can implement encryption at the application layer using libraries like BoringSSL.","upvote_count":"1","poster":"Rakesh21","timestamp":"1738299300.0"},{"comment_id":"1346484","content":"Selected Answer: A\n\"BoringSSL as a whole is not FIPS validated. However, there is a core library (called BoringCrypto) that has been FIPS validated.\"","poster":"p981pa123","upvote_count":"2","timestamp":"1737812760.0"},{"timestamp":"1736865480.0","comment_id":"1340386","upvote_count":"1","comments":[],"content":"Selected Answer: B\nWhen you deploy Managed Instance Groups (MIGs), you typically create an instance template that defines the configuration of instances in the group, including the disk encryption settings.","poster":"p981pa123"},{"upvote_count":"1","timestamp":"1726308900.0","poster":"SQLbox","comment_id":"1283580","content":"B\n\nTo comply with FIPS 140-2, the company needs to ensure that both data at rest and data in transit are encrypted using cryptographic libraries that are FIPS 140-2 certified.\n\n • Customer-managed keys (CMEK): Using customer-managed encryption keys (CMEK) in Google Cloud Key Management Service (KMS) ensures that encryption complies with FIPS 140-2 standards because the customer has control over the encryption keys and can ensure they are managed according to compliance requirements.\n • BoringSSL: A Google-maintained version of OpenSSL designed to be more streamlined and used in environments like Google Cloud, which includes support for FIPS 140-2 mode when linked to the BoringCrypto module. This library can be used to ensure that data in transit between instances is encrypted in compliance with FIPS."},{"timestamp":"1723025460.0","upvote_count":"1","poster":"LaithTech","comment_id":"1262027","content":"Selected Answer: B\nThe correct answer is B"},{"comment_id":"1252514","timestamp":"1721573760.0","content":"Selected Answer: B\nA. Encrypt all cache storage and VM-to-VM communication using the BoringCrypto module:\n\nBoringCrypto is not an established or widely recognized cryptographic library for FIPS 140-2 compliance. Instead, BoringSSL or OpenSSL with FIPS validation should be used for both data-at-rest and data-in-transit encryption.\nC. Change the app instance-to-instance communications from UDP to TCP and enable BoringSSL on clients' TLS connections:\n\nWhile changing from UDP to TCP might provide more reliable connections, it does not directly address FIPS 140-2 compliance. You still need to ensure that all data-in-transit encryption uses a validated cryptographic module such as BoringSSL.\nD. Set Disk Encryption on the Instance Template used by the MIG to Google-managed Key and use BoringSSL library on all instance-to-instance communications:\n\nGoogle-managed keys for disk encryption do not provide the level of control required for FIPS 140-2 compliance, which typically requires customer-managed keys for greater control and accountability.","upvote_count":"1","poster":"3d9563b"},{"poster":"gical","upvote_count":"4","content":"Selected answer B\nhttps://cloud.google.com/security/compliance/fips-140-2-validated/\n\"Google’s Local SSD storage product is automatically encrypted with NIST approved ciphers, but Google's current implementation for this product doesn’t have a FIPS 140-2 validation certificate. If you require FIPS-validated encryption on Local SSD storage, you must provide your own encryption with a FIPS-validated cryptographic module.\"","comments":[{"timestamp":"1704450180.0","upvote_count":"1","content":"YES, as in your link: you need to encrypt SSD using your own solution, and BoringSSL is a library to use","poster":"b6f53d8","comment_id":"1114430"}],"timestamp":"1703412540.0","comment_id":"1104538"},{"timestamp":"1694735940.0","content":"A. Encrypt all cache storage and VM-to-VM communication using the BoringCrypto module.\n\nThis option ensures both storage (Local SSDs) and inter-instance communications are encrypted using a FIPS 140-2 compliant module.","poster":"ArizonaClassics","upvote_count":"4","comment_id":"1007987"},{"poster":"ArizonaClassics","timestamp":"1694735880.0","content":"A. Encrypt all cache storage and VM-to-VM communication using the BoringCrypto module.\n\nThis option ensures both storage (Local SSDs) and inter-instance communications are encrypted using a FIPS 140-2 compliant module.","comment_id":"1007986","upvote_count":"1"},{"poster":"ymkk","timestamp":"1693811400.0","content":"Selected Answer: A\nhttps://cloud.google.com/security/compliance/fips-140-2-validated/","comment_id":"998280","upvote_count":"2"},{"timestamp":"1684141380.0","poster":"gcpengineer","upvote_count":"2","content":"Selected Answer: A\nA is the ans","comment_id":"898149"},{"comment_id":"787947","timestamp":"1674667200.0","poster":"pedrojorge","content":"Selected Answer: C\n\"BoringSSL as a whole is not FIPS validated. However, there is a core library (called BoringCrypto) that has been FIPS validated\"\nhttps://boringssl.googlesource.com/boringssl/+/master/crypto/fipsmodule/FIPS.md","upvote_count":"3"},{"comment_id":"710116","timestamp":"1667429760.0","upvote_count":"1","content":"https://cloud.google.com/docs/security/key-management-deep-dive\n\nA is right","poster":"AzureDP900"},{"content":"Selected Answer: A\nA. Encrypt all cache storage and VM-to-VM communication using the BoringCrypto module.","poster":"AwesomeGCP","comment_id":"688704","timestamp":"1665153420.0","upvote_count":"1"},{"content":"Selected Answer: A\nFIPS140 module is supported","upvote_count":"2","poster":"sudarchary","comment_id":"541628","timestamp":"1644142200.0"},{"comment_id":"334524","poster":"[Removed]","content":"D is the correct answer","timestamp":"1618306320.0","upvote_count":"2"},{"timestamp":"1616520900.0","content":"Ans : A","comment_id":"318301","upvote_count":"1","poster":"DebasishLowes"},{"content":"https://cloud.google.com/security/compliance/fips-140-2-validated\nGoogle Cloud Platform uses a FIPS 140-2 validated encryption module called BoringCrypto (certificate 3318) in our production environment. This means that both data in transit to the customer and between data centers, and data at rest are encrypted using FIPS 140-2 validated encryption. The module that achieved FIPS 140-2 validation is part of our BoringSSL library.\nAns A","upvote_count":"4","timestamp":"1615331940.0","comment_id":"306732","poster":"TNT87"},{"content":"A is the answer https://boringssl.googlesource.com/boringssl/+/master/crypto/fipsmodule/FIPS.md","poster":"TNT87","upvote_count":"2","timestamp":"1612858320.0","comment_id":"286638"},{"poster":"chetz12","comment_id":"260554","content":"I think A is correct as that's the only one support FIPS140 module","timestamp":"1609879980.0","upvote_count":"3"},{"comment_id":"209059","upvote_count":"2","poster":"[Removed]","content":"Ans - B","timestamp":"1604041260.0"},{"upvote_count":"3","content":"Agree Answer is A definitely. \n\"BoringSSL as a whole is not FIPS validated. However, there is a core library (called BoringCrypto) that has been FIPS validated\"\nhttps://boringssl.googlesource.com/boringssl/+/master/crypto/fipsmodule/FIPS.md","timestamp":"1604013360.0","comment_id":"208929","poster":"genesis3k"},{"timestamp":"1603556040.0","upvote_count":"2","content":"For me correct answer is B","poster":"saurabh1805","comment_id":"205200"},{"content":"Answer is A.\n\nBoringSSL as a whole is not FIPS validated.\nhttps://boringssl.googlesource.com/boringssl/+/master/crypto/fipsmodule/FIPS.md","poster":"ownez","timestamp":"1602060540.0","upvote_count":"2","comment_id":"195020"},{"poster":"mte_tech34","upvote_count":"1","content":"According to https://cloud.google.com/security/compliance/fips-140-2-validated \n\"Google’s Local SSD storage product is automatically encrypted with NIST approved ciphers, but Google's current implementation for this product doesn’t have a FIPS 140-2 validation certificate. If you require FIPS-validated encryption on Local SSD storage, you must provide your own encryption with a FIPS-validated cryptographic module.\"\n\nSo only A seems to be correct, as BoringSSL is FIPS-140-2 validated.","timestamp":"1601139360.0","comment_id":"187807","comments":[{"content":"I meant BoringCrypto, not BoringSSL, as it's not the same thing and only BoringCrypto is FIPS validated. BoringSSL is not (see https://boringssl.googlesource.com/boringssl/+/master/crypto/fipsmodule/FIPS.md), so definitely only A can be correct answer.","timestamp":"1601139720.0","upvote_count":"1","comment_id":"187809","poster":"mte_tech34"}]},{"timestamp":"1600392240.0","comment_id":"181299","poster":"Raushanr","upvote_count":"2","content":"Another reasoning on Google Documentation-You cannot use your own keys with local SSDs because local SSDs do not persist beyond the life of a virtual machine. Local SSDs are already protected with an ephemeral encryption key that Google does not retain."},{"content":"Answer-B\nReasoning from Google-Google’s Local SSD storage product is automatically encrypted with NIST approved ciphers, but Google's current implementation for this product doesn’t have a FIPS 140-2 validation certificate. If you require FIPS-validated encryption on Local SSD storage, you must provide your own encryption with a FIPS-validated cryptographic module.","poster":"Raushanr","upvote_count":"3","comment_id":"181269","timestamp":"1600386600.0"},{"content":"I think it is B.\n\nhttps://services.google.com/fh/files/misc/googlecloud_european_commitments_whitepaper.pdf","comment_id":"172567","poster":"ownez","comments":[{"content":"This is because \"The instances use Local SSDs for data caching\" and in the documentation says \"If you require FIPS-validated encryption on Local SSD storage, you must provide your own encryption with a FIPS-validated cryptographic module.\"","poster":"ownez","comment_id":"173799","upvote_count":"1","timestamp":"1599294360.0"}],"timestamp":"1599125400.0","upvote_count":"4"},{"poster":"mlyu","content":"Agreed ans is D","timestamp":"1599093540.0","comment_id":"172306","upvote_count":"1"},{"comment_id":"171867","upvote_count":"1","poster":"MohitA","content":"https://cloud.google.com/security/compliance/fips-140-2-validated","timestamp":"1599033300.0"}],"exam_id":9,"answers_community":["A (56%)","B (25%)","C (19%)"],"unix_timestamp":1599033300,"answer_images":[],"answer_ET":"A","isMC":true,"question_text":"In an effort for your company messaging app to comply with FIPS 140-2, a decision was made to use GCP compute and network services. The messaging app architecture includes a Managed Instance Group (MIG) that controls a cluster of Compute Engine instances. The instances use Local SSDs for data caching and\nUDP for instance-to-instance communications. The app development team is willing to make any changes necessary to comply with the standard\nWhich options should you recommend to meet the requirements?","timestamp":"2020-09-02 09:55:00","choices":{"C":"Change the app instance-to-instance communications from UDP to TCP and enable BoringSSL on clients' TLS connections.","A":"Encrypt all cache storage and VM-to-VM communication using the BoringCrypto module.","D":"Set Disk Encryption on the Instance Template used by the MIG to Google-managed Key and use BoringSSL library on all instance-to-instance communications.","B":"Set Disk Encryption on the Instance Template used by the MIG to customer-managed key and use BoringSSL for all data transit between instances."}},{"id":"YcIknwx5EV6o3fG5TO8l","unix_timestamp":1599093840,"answer_ET":"B","choices":{"B":"Create an egress firewall rule to allow traffic to the CIDR range of the repository with a priority less than 1000.","D":"Create an egress firewall rule to allow traffic to the hostname of the repository with a priority less than 1000.","A":"Create an egress firewall rule to allow traffic to the CIDR range of the repository with a priority greater than 1000.","C":"Create an egress firewall rule to allow traffic to the hostname of the repository with a priority greater than 1000."},"answers_community":["B (92%)","8%"],"isMC":true,"topic":"1","answer_images":[],"question_images":[],"answer":"B","answer_description":"","timestamp":"2020-09-03 02:44:00","discussion":[{"upvote_count":"26","timestamp":"1616266140.0","content":"Answer is B. Lower number is higher priority and dest is only IP ranges in firewall rules","comment_id":"315809","poster":"dtmtor"},{"content":"Selected Answer: B\nB… no hostname in firewall rules and lower number = higher priority.","upvote_count":"5","poster":"[Removed]","timestamp":"1702603920.0","comment_id":"1096964"},{"upvote_count":"1","timestamp":"1732909080.0","poster":"BPzen","content":"Selected Answer: B\nWhile the priority is correct, Google Cloud firewall rules do not support hostname-based filtering. You must use a CIDR range.","comment_id":"1319890"},{"timestamp":"1709837880.0","content":"Selected Answer: B\nB is correct.","comment_id":"1168286","upvote_count":"1","poster":"madcloud32"},{"comment_id":"753132","poster":"shayke","content":"Selected Answer: B\nAns in B lower number higher priority","timestamp":"1671701340.0","upvote_count":"3"},{"content":"Selected Answer: B\nAnswer is B","comment_id":"717287","upvote_count":"3","poster":"Littleivy","timestamp":"1668341700.0"},{"comment_id":"711818","upvote_count":"4","content":"Selected Answer: B\nhttps://cloud.google.com/vpc/docs/firewalls#priority_order_for_firewall_rules","poster":"GHOST1985","timestamp":"1667658780.0"},{"comment_id":"710117","upvote_count":"2","poster":"AzureDP900","timestamp":"1667429880.0","content":"B is correct"},{"comment_id":"708174","timestamp":"1667188020.0","poster":"Premumar","upvote_count":"3","content":"Selected Answer: B\nFirst filter is priority should be less than 1000. So, option A and C are rejected. Then, we use CIDR range to allow firewall. So, the final answer is B."},{"comment_id":"688714","content":"Selected Answer: B\nB. Create an egress firewall rule to allow traffic to the CIDR range of the repository with a priority less than 1000.\nFirewall rules only support IPv4 connections. When specifying a source for an ingress rule or a destination for an egress rule by address, you can only use an IPv4 address or IPv4 block in CIDR notation. So Answer is B","timestamp":"1665154020.0","poster":"AwesomeGCP","upvote_count":"4"},{"content":"Selected Answer: A\nThe correct answer is A. \nAs per the link https://cloud.google.com/vpc/docs/firewalls#rule_assignment\n\nLowest priority in the firewall rule is 65535. So in order for a rule to be of higher priority than 1000 the rule should have a priority of number less than 1000.","poster":"piyush_1982","comment_id":"638975","upvote_count":"2","timestamp":"1659066780.0","comments":[{"upvote_count":"3","timestamp":"1666928940.0","comment_id":"706085","content":"Your explanation is correct. But, option you selected is wrong. It has to be option B.","poster":"Premumar"}]},{"timestamp":"1623941280.0","poster":"Rithac","upvote_count":"5","comment_id":"384264","content":"I think I am confusing myself by overthinking the wording of this question. I know the answer is A or B since \"using hostname is not one of the options in firewall egress rule destination\" I also know that \"The firewall rule priority is an integer from 0 to 65535, inclusive. Lower integers indicate higher priorities.\" I know that I could resolve this by setting TCP port 80 rule to a priority of 500 (smaller number, but higher priority) and be done. Where i'm second guessing myself, is Google referring to the integer or strictly priority? If integer then i'd choose B \"priority less than 1000 (smaller number)\", if priority then i'd choose A \"priority greater than 1000\" (still the lower number). Have I thoroughly confused this question? I\"m leaning toward the answer being \"A:"},{"content":"Ans : B","timestamp":"1616521020.0","poster":"DebasishLowes","comment_id":"318307","upvote_count":"3"},{"comment_id":"241179","timestamp":"1607717100.0","poster":"ronron89","upvote_count":"4","content":"Answer: B\nhttps://cloud.google.com/vpc/docs/firewalls#rule_assignment\nThe priority of the second rule determines whether TCP traffic to port 80 is allowed for the webserver targets:\n\nIf the priority of the second rule is set to a number greater than 1000, it has a lower priority, so the first rule denying all traffic applies.\n\nIf the priority of the second rule is set to 1000, the two rules have identical priorities, so the first rule denying all traffic applies.\n\nIf the priority of the second rule is set to a number less than 1000, it has a higher priority, thus allowing traffic on TCP 80 for the webserver targets. Absent other rules, the first rule would still deny other types of traffic to the webserver targets, and it would also deny all traffic, including TCP 80, to instances without the webserver tag."},{"timestamp":"1604047200.0","poster":"[Removed]","content":"Ans - B","comment_id":"209109","upvote_count":"3"},{"content":"The firewall rule priority is an integer from 0 to 65535, inclusive. Lower integers indicate higher priorities. If you do not specify a priority when creating a rule, it is assigned a priority of 1000.","upvote_count":"1","timestamp":"1600387140.0","comment_id":"181272","poster":"Raushanr"},{"comment_id":"181271","content":"Answer-B","upvote_count":"4","poster":"Raushanr","timestamp":"1600386960.0"},{"content":"It should be B.\n\nFirewall rules can be only specify by IPv4 address or IPv4 block in CIDR.\nAnd it must be lesser priority than 1000 because if more than that, it will overwrite the deny rule.","poster":"ownez","timestamp":"1599126120.0","upvote_count":"2","comment_id":"172573","comments":[{"poster":"ownez","content":"Sorry It should be A.\n\n\"Priority: the numeric evaluation order of the rule. A rule with a priority of 1 is evaluated first. Priorities must be unique for each rule. A good practice is to give rules priority numbers that allow later insertion (such as 100, 200, 300).\"","comments":[{"content":"Correction. B","upvote_count":"3","timestamp":"1600752480.0","poster":"ownez","comment_id":"184212"}],"comment_id":"173812","timestamp":"1599295980.0","upvote_count":"1"}]},{"content":"Ans should be A\nusing hostname is not one of the options in firewall egress rule destination\nhttps://cloud.google.com/vpc/docs/firewalls#gcp_firewall_rule_summary_table","comment_id":"172308","upvote_count":"2","poster":"mlyu","timestamp":"1599093840.0"}],"question_id":284,"question_text":"A customer has an analytics workload running on Compute Engine that should have limited internet access.\nYour team created an egress firewall rule to deny (priority 1000) all traffic to the internet.\nThe Compute Engine instances now need to reach out to the public repository to get security updates.\nWhat should your team do?","url":"https://www.examtopics.com/discussions/google/view/30429-exam-professional-cloud-security-engineer-topic-1-question/","exam_id":9},{"id":"VtivTWsVkYcL9nbSZgpt","question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/30354-exam-professional-cloud-security-engineer-topic-1-question/","timestamp":"2020-09-02 10:04:00","discussion":[{"poster":"TNT87","content":"Ans B\nhttps://cloud.netapp.com/blog/gcp-cvo-blg-how-to-use-google-cloud-encryption-with-a-persistent-disk","upvote_count":"15","timestamp":"1628490480.0","comment_id":"286648"},{"poster":"[Removed]","content":"Selected Answer: B\nB… question states permissions should be the same for all keys.","upvote_count":"2","timestamp":"1718408100.0","comment_id":"1096966","comments":[{"upvote_count":"1","comment_id":"1096967","timestamp":"1718408160.0","content":"and should be managed in a group way.","poster":"[Removed]"}]},{"content":"B. Create a single KeyRing for all persistent disks and all Keys in this KeyRing. Manage the IAM permissions at the KeyRing level: This is efficient. By managing permissions at the KeyRing level, you're effectively grouping permissions for all keys in that KeyRing. As permissions should be the same for all keys, this is a logical choice.","comment_id":"1007995","poster":"ArizonaClassics","timestamp":"1710469080.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1683061320.0","comment_id":"710118","poster":"AzureDP900","content":"B is right"},{"poster":"shayke","comment_id":"698088","content":"Selected Answer: B\nall permission are the same-controled at the ring level","timestamp":"1681810800.0","upvote_count":"2"},{"timestamp":"1680878580.0","content":"Selected Answer: B\nB. Create a single KeyRing for all persistent disks and all Keys in this KeyRing. Manage the IAM permissions at the KeyRing level.","upvote_count":"3","comment_id":"688708","poster":"AwesomeGCP"},{"upvote_count":"1","comment_id":"577473","content":"Answer-B","poster":"roatest27","timestamp":"1664445600.0"},{"content":"How about A?","comments":[{"poster":"[Removed]","timestamp":"1634118300.0","comment_id":"334532","content":"oh, the same permission ,then I choose B","upvote_count":"4"}],"upvote_count":"1","timestamp":"1634117760.0","comment_id":"334526","poster":"[Removed]"},{"timestamp":"1632411480.0","upvote_count":"3","poster":"DebasishLowes","comment_id":"318308","content":"Ans : B"},{"content":"Ans - B","timestamp":"1619764620.0","comment_id":"209105","poster":"[Removed]","upvote_count":"1"},{"poster":"Raushanr","content":"Answer-B","comment_id":"185870","upvote_count":"1","timestamp":"1616567520.0"},{"content":"B is the right answer","upvote_count":"1","poster":"Namaste","comment_id":"185053","timestamp":"1616488080.0"},{"content":"B should be the answer","upvote_count":"4","timestamp":"1614679440.0","comment_id":"171875","poster":"MohitA"}],"choices":{"A":"Create a single KeyRing for all persistent disks and all Keys in this KeyRing. Manage the IAM permissions at the Key level.","C":"Create a KeyRing per persistent disk, with each KeyRing containing a single Key. Manage the IAM permissions at the Key level.","D":"Create a KeyRing per persistent disk, with each KeyRing containing a single Key. Manage the IAM permissions at the KeyRing level.","B":"Create a single KeyRing for all persistent disks and all Keys in this KeyRing. Manage the IAM permissions at the KeyRing level."},"topic":"1","answers_community":["B (100%)"],"answer_ET":"B","isMC":true,"question_id":285,"answer_description":"","answer":"B","exam_id":9,"unix_timestamp":1599033840,"question_text":"You want data on Compute Engine disks to be encrypted at rest with keys managed by Cloud Key Management Service (KMS). Cloud Identity and Access\nManagement (IAM) permissions to these keys must be managed in a grouped way because the permissions should be the same for all keys.\nWhat should you do?"}],"exam":{"isBeta":false,"id":9,"provider":"Google","isImplemented":true,"isMCOnly":false,"lastUpdated":"11 Apr 2025","name":"Professional Cloud Security Engineer","numberOfQuestions":321},"currentPage":57},"__N_SSP":true}