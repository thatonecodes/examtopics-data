{"pageProps":{"questions":[{"id":"cMcIHLIjHYLy3JvEmZQ6","answers_community":["B (100%)"],"answer_images":[],"discussion":[{"timestamp":"1626089940.0","comment_id":"38087","content":"Agree B","upvote_count":"24","poster":"AWS56","comments":[{"timestamp":"1651407600.0","poster":"kumarp6","content":"Yes B it is","comment_id":"210522","upvote_count":"2"},{"comment_id":"303722","poster":"nitinz","upvote_count":"2","timestamp":"1662328920.0","content":"B is correct"}]},{"content":"B. Use firewall rules based on network tags attached to the compute instances\n\nTo restrict communications between VM instances within a VPC without relying on static IP addresses or subnets, you can use firewall rules based on network tags attached to the compute instances. This will allow you to specify which instances are allowed to communicate with each other and on which paths and ports. You can then attach the relevant network tags to the compute instances when they are created, allowing you to control communication between the instances without relying on static IP addresses or subnets.","comments":[{"timestamp":"1719030540.0","content":"Option A, using separate VPCs to restrict traffic, would not be a suitable solution because it would not allow the instances to communicate with each other, which is likely necessary for the functioning of the web application.\n\nOption C, using Cloud DNS and only allowing connections from authorized hostnames, would not be a suitable solution because it would not allow you to control communication between the instances based on their IP addresses or other characteristics.\n\nOption D, using service accounts and configuring the web application to authorize particular service accounts to have access, would not be a suitable solution because it would not allow you to control communication between the instances based on their IP addresses or other characteristics.","comment_id":"753017","upvote_count":"5","poster":"omermahgoub"}],"poster":"omermahgoub","comment_id":"753016","upvote_count":"13","timestamp":"1719030540.0"},{"poster":"SureshbabuK","upvote_count":"4","timestamp":"1716851940.0","content":"Selected Answer: B\nAccess to specific ports and protocol can be controlled only by firewall rule - Hence B is correct. D is not correct as service account is to authenticate and Authorized a specific machine to resource or service not ports and protocols","comment_id":"728721"},{"comment_id":"712925","poster":"megumin","timestamp":"1715063220.0","content":"Selected Answer: B\nB is ok","upvote_count":"1"},{"timestamp":"1713285900.0","comment_id":"696393","poster":"AzureDP900","content":"B is the best option.","upvote_count":"1"},{"timestamp":"1710373440.0","content":"Selected Answer: B\nUse firewall rules based on network tags attached to the compute instances","upvote_count":"2","poster":"abirroy","comment_id":"668434"},{"timestamp":"1710050280.0","content":"The secret is \"paths and ports\".\nWhich tell us Firewall as our only option.","upvote_count":"5","comments":[{"content":"And how does firewall restrict \"paths\" pretty please?","upvote_count":"5","poster":"medi01","timestamp":"1729450800.0","comment_id":"875920"}],"comment_id":"665066","poster":"alexandercamachop"},{"comment_id":"627366","timestamp":"1704453480.0","content":"Selected Answer: B\nB Firewall rules to restrict traffic","poster":"cbarg","upvote_count":"1"},{"timestamp":"1686115800.0","upvote_count":"2","comment_id":"495730","content":"Go for B.","poster":"haroldbenites"},{"timestamp":"1685246940.0","poster":"vincy2202","comment_id":"488870","upvote_count":"2","content":"B is the right answer"},{"comment_id":"469258","poster":"MaxNRG","timestamp":"1682685480.0","content":"B â€“ use firewall rules based on network tags attached to the compute instances \nThis answer avoids using IP, which are replaced by tags.","upvote_count":"3"},{"comment_id":"402113","poster":"MamthaSJ","content":"Answer is B","upvote_count":"4","timestamp":"1673207340.0"},{"poster":"areza","content":"B is ok","upvote_count":"1","comment_id":"378187","timestamp":"1670589420.0"},{"comment_id":"361286","timestamp":"1668862440.0","poster":"victory108","content":"B. Use firewall rules based on network tags attached to the compute instances","upvote_count":"2"},{"poster":"Ausias18","content":"Answer is B","comment_id":"325547","upvote_count":"1","timestamp":"1664603520.0"},{"poster":"lynx256","timestamp":"1664260200.0","upvote_count":"1","content":"B is ok","comment_id":"321680"},{"comment_id":"300066","content":"Agree B","poster":"Vika","upvote_count":"1","timestamp":"1661566080.0"},{"timestamp":"1661406960.0","poster":"ga","content":"B is the answer","upvote_count":"1","comment_id":"298857"},{"upvote_count":"1","poster":"AshokC","content":"B is correct","timestamp":"1647406500.0","comment_id":"180146"},{"upvote_count":"1","timestamp":"1643038620.0","comment_id":"142782","content":"Agree B","poster":"OnomeOkuma"},{"timestamp":"1641807240.0","comment_id":"131243","content":"Agree with B","upvote_count":"1","poster":"RM07"},{"comment_id":"117392","poster":"mlantonis","upvote_count":"1","content":"I agree with B","timestamp":"1640266320.0"},{"content":"B is the correct answer","timestamp":"1640000760.0","upvote_count":"1","comment_id":"114662","poster":"Tushant"},{"content":"B, for sure\nUse firewall rules based on network tags attached to the compute instances","upvote_count":"4","comment_id":"108429","poster":"gfhbox0083","timestamp":"1639297740.0"},{"poster":"Ziegler","upvote_count":"2","comment_id":"102423","timestamp":"1638634380.0","content":"B is the right answer."},{"timestamp":"1638478320.0","content":"B is the correct answer","upvote_count":"2","poster":"Nirms","comment_id":"101112"},{"poster":"gcp_aws","content":"B is the answer","upvote_count":"1","timestamp":"1637866680.0","comment_id":"95529"},{"upvote_count":"3","content":"Agree: B. Selected B in the exam","comment_id":"56426","timestamp":"1630132620.0","poster":"[Removed]"},{"comment_id":"44822","poster":"2g","content":"Answer: B","upvote_count":"3","timestamp":"1627648800.0"}],"question_images":[],"exam_id":4,"question_text":"Your web application has several VM instances running within a VPC. You want to restrict communications between instances to only the paths and ports you authorize, but you don't want to rely on static IP addresses or subnets because the app can autoscale. How should you restrict communications?","answer_ET":"B","choices":{"C":"Use Cloud DNS and only allow connections from authorized hostnames","D":"Use service accounts and configure the web application to authorize particular service accounts to have access","A":"Use separate VPCs to restrict traffic","B":"Use firewall rules based on network tags attached to the compute instances"},"answer":"B","unix_timestamp":1578836340,"isMC":true,"question_id":171,"url":"https://www.examtopics.com/discussions/google/view/11816-exam-professional-cloud-architect-topic-1-question-72/","answer_description":"","timestamp":"2020-01-12 14:39:00","topic":"1"},{"id":"pOD0WcJ7J9YswHKJ0Nhc","question_images":[],"question_text":"You are using Cloud SQL as the database backend for a large CRM deployment. You want to scale as usage increases and ensure that you don't run out of storage, maintain 75% CPU usage cores, and keep replication lag below 60 seconds. What are the correct steps to meet your requirements?","question_id":172,"topic":"1","answer":"A","unix_timestamp":1570966260,"discussion":[{"comments":[{"comment_id":"989159","timestamp":"1692878340.0","upvote_count":"4","poster":"heretolearnazure","content":"Sharding database will reduce latency"},{"comment_id":"696391","upvote_count":"2","poster":"AzureDP900","content":"1. Enable automatic storage increase for the instance. 2. Create a Stackdriver alert when CPU usage exceeds 75%, and change the instance type to reduce CPU usage. 3. Create a Stackdriver alert for replication lag, and shard the database to reduce replication time.","timestamp":"1665938580.0"}],"poster":"AWS56","comment_id":"38089","upvote_count":"27","content":"Agree with A","timestamp":"1578836460.0"},{"poster":"9xnine","content":"Has anyone who has taken the exam recently seen any lingering questions with the Stackdriver nomenclature or is it all cloud logging, cloud monitoring, etc.?","upvote_count":"16","timestamp":"1654638660.0","comment_id":"612944"},{"comment_id":"1302176","poster":"nareshthumma","timestamp":"1729711860.0","content":"Answer is: A","upvote_count":"1"},{"comments":[{"content":"But I also understand that the question didn't mention anything about needing the DB to be online always, so maybe these offline times are acceptable...","poster":"e5019c6","comment_id":"1109101","upvote_count":"1","timestamp":"1703883720.0"}],"comment_id":"1109099","upvote_count":"2","poster":"e5019c6","timestamp":"1703883660.0","content":"Selected Answer: B\nWhile I understand the doubts of selecting a 32 core machine from the start, answer A might be wrong...\nAccording to this article: \nhttps://cloud.google.com/sql/docs/mysql/instance-settings#impact\n''For MySQL instances, changing either the machine type or the zone of the instance results in the instance going offline for several minutes.''\nAnd I understand that instance type == machine type.\nIf we switch to a PostgreSQL or SQL Server instance, similar warnings appear:\nPostgreSQL: ''Changing the number of CPUs or the memory size results in the instance going offline for less than 60 seconds. The total time for the changes to take effect can take several minutes.''\nSQL Server: ''Changing the number of CPUs or the memory size results in the instance going offline for less than 60 seconds.''"},{"poster":"AdityaGupta","upvote_count":"4","timestamp":"1696558740.0","content":"Selected Answer: A\nYou are using Cloud SQL as the database backend for a large CRM deployment. You want to scale as usage increases and ensure that you don't run out of storage, maintain 75% CPU usage cores, and keep replication lag below 60 seconds. What are the correct steps to meet your requirements?\n\n\nC & D is out of question as it is talking of 75% of storage, where in question it says 75% of CPU.\nOption A says monitoring before before taking action and sharding will also help in reducing latency.\nOption B specifies specific machine type, which is not correct and also memcache which is used to recude the round trip to fetch data, it will help in reducing latency.\n\nI would prefer to go with Option A, as it is correct sequence to solve the problem.","comment_id":"1026151"},{"upvote_count":"1","content":"Selected Answer: A\nFor me is A.","comment_id":"916530","poster":"red_panda","timestamp":"1686074940.0"},{"poster":"jfricker","content":"The correct answer is D.\n\n1. Create a Stackdriver alert when storage exceeds 75%, and increase the available storage on the instance to create more space.\n2. Deploy memcached to reduce CPU load.\n3. Create a Stackdriver alert for replication lag, and change the instance type to a 32-core machine type to reduce replication lag.\n\nThis approach ensures that you are able to address the three requirements specified in the question:\n\n- Monitoring storage usage and increasing storage when it exceeds 75% to avoid running out of storage.\n- Reducing CPU load by deploying memcached, which can be used to cache frequently-used data, offloading some of the load from the database.\n- Monitoring replication lag and increasing the number of cores to reduce lag.","comment_id":"806048","timestamp":"1676185380.0","upvote_count":"4"},{"upvote_count":"5","comment_id":"759061","poster":"Charsoft","content":"It may be A for the simple fact that all the other answers throw in a tiny detail about 32 cores. This seems like a red herring (unnecessary details that are meant to distract), so for that reason, A is the answer.","timestamp":"1672174560.0"},{"content":"Selected Answer: A\nA is ok","comment_id":"713159","poster":"megumin","timestamp":"1667838780.0","upvote_count":"1"},{"poster":"6721sora","content":"A is incorrect. because of the wording \"Shard the database\". How can you shard the database in Cloud SQL without causing major disruptions? Sharding is not a core feature of RDBMS. \n\nB should be correct. inspite of the mention of a fixed 32 core","timestamp":"1661229300.0","upvote_count":"3","comments":[{"comment_id":"696752","timestamp":"1665974100.0","comments":[{"timestamp":"1670378820.0","poster":"fiercedog","comment_id":"737369","upvote_count":"1","content":"The article only mentions sharding as a concept, and not a solution for cloudsql."}],"content":"Ii\nKk\nKk\nYou can shard cloudsql. Review this article - https://cloud.google.com/community/tutorials/horizontally-scale-mysql-database-backend-with-google-cloud-sql-and-proxysql#:~:text=Common%20approaches%20for%20horizontally%20scaling,with%20Cloud%20SQL%20and%20ProxySQL.","upvote_count":"4","poster":"jay9114"},{"comment_id":"824147","content":"https://cloud.google.com/community/tutorials/horizontally-scale-mysql-database-backend-with-google-cloud-sql-and-proxysql#:~:text=SQL%20and%20ProxySQL.-,Sharding,logic%20or%20a%20query%20router.\n\nYou can shard MySQL. \n\nAnswer should be A.","poster":"Deb2293","upvote_count":"4","timestamp":"1677531120.0"}],"comment_id":"650574"},{"content":"Selected Answer: A\nvote for A","comment_id":"565313","upvote_count":"2","timestamp":"1646986020.0","poster":"mj20201"},{"poster":"haroldbenites","upvote_count":"2","timestamp":"1638862440.0","comment_id":"495731","content":"Go for A"},{"upvote_count":"2","poster":"vincy2202","content":"A is the correct answer","timestamp":"1637218200.0","comment_id":"480484"},{"comments":[{"content":"Just to back up what amxexam said, here is the link on automatically increasing storage based on trend analysis: \n\nhttps://cloud.google.com/sql/docs/mysql/instance-settings#storage-capacity-2ndgen","poster":"[Removed]","upvote_count":"3","comments":[{"upvote_count":"1","poster":"HenkH","comments":[{"comment_id":"698357","timestamp":"1666111140.0","content":"Should read MySQl","upvote_count":"2","poster":"HenkH"}],"comment_id":"510901","timestamp":"1640679060.0","content":"That is correct - but doc only mentions auto storage increase for this specific product (cloud SQL)."}],"timestamp":"1633897620.0","comment_id":"460210"},{"poster":"cotam","upvote_count":"5","timestamp":"1634111040.0","comment_id":"461423","content":"I suppose B is not a better option, since it indicates 'add 32core cpu', with no info of the current usage that seems like a over-kill."},{"content":"I would say only because of the below line|\n\"You want to scale as usage increases\" Line 1\nCreating a 32 core machine upfront where we do not know what was the source machine cores would not be ideal .\nin that situation i would go with A","comment_id":"642859","timestamp":"1659689820.0","upvote_count":"4","poster":"Ishu_awsguy"}],"upvote_count":"4","content":"We can directly eliminate C and D we are doing some work that is already automated.\n\nStill, I cannot make a point why not B is better than A?\nI believe adding memcash will give an additional boost\n\nCan someone help me point out why A is better than B?","comment_id":"436100","poster":"amxexam","timestamp":"1630394820.0"},{"content":"Answer is A","comment_id":"402116","upvote_count":"4","poster":"MamthaSJ","timestamp":"1625766720.0"},{"timestamp":"1623238620.0","poster":"areza","upvote_count":"1","comment_id":"378227","content":"A it is"},{"upvote_count":"1","timestamp":"1621423080.0","poster":"victory108","comment_id":"361306","content":"A. 1. Enable automatic storage increase for the instance. 2. Create a Stackdriver alert when CPU usage exceeds 75%, and change the instance type to reduce CPU usage. 3. Create a Stackdriver alert for replication lag, and shard the database to reduce replication time."},{"timestamp":"1621084260.0","comment_id":"357867","poster":"un","upvote_count":"2","content":"Agree with A"},{"content":"Answer is A","upvote_count":"1","timestamp":"1617256440.0","comment_id":"325548","poster":"Ausias18"},{"timestamp":"1616840880.0","upvote_count":"3","comment_id":"321761","content":"A is ok.","poster":"lynx256"},{"comment_id":"292841","upvote_count":"1","timestamp":"1613591640.0","content":"Sharing means multiple cloud sql instances. Application will manage selection of cloud instance \nChanging instance types mean restating and downtime. Why would you do that anytime the CPU reaches 75%. Manually doing this seems so 2000.\nB should be correct","comments":[{"timestamp":"1614343080.0","upvote_count":"2","poster":"Alekshar","content":"I am not sure option B fits any better. \nSure you will have no downtimes as you are already using the biggest possible machine but it also means you pay for the biggest machine even if you do not need it, maybe 4-cores are enough for now and you will never need more than 8-cores but you will pay 32-cores, it seems pretty exepensive to avoid rare and small downtimes.","comment_id":"299731"},{"content":"changing instance type can be done with no downtime for mots of the instances type\nhttps://cloud.google.com/sql/docs/mysql/instance-settings#impact","timestamp":"1673430780.0","comment_id":"772312","upvote_count":"1","poster":"n_nana"}],"poster":"sekhrivijay"},{"comment_id":"278940","comments":[{"comment_id":"321760","comments":[{"upvote_count":"1","poster":"ryzior","timestamp":"1653655320.0","content":"Sharding makes horizontal scaling possible by partitioning the database into smaller, more manageable parts (shards), then deploying the parts across a cluster of machines. Data queries are routed to the corresponding server automatically, usually with rules embedded in application logic or a query router.\nhttps://cloud.google.com/community/tutorials/horizontally-scale-mysql-database-backend-with-google-cloud-sql-and-proxysql","comment_id":"608078"}],"poster":"lynx256","upvote_count":"1","timestamp":"1616840760.0","content":"There is not about sharding REPLICAS but sharding database (e.g. table names according to MY_TABLE_202001, to MY_TABLE_202002 and so on - one table for each month). Sharding is another way of partitioning . But the partitioning is more relevant, not sharding."}],"upvote_count":"1","content":"cannot find doc about sharding the replicas. can anyone help?","poster":"bnlcnd","timestamp":"1611885360.0"},{"poster":"AshokC","comment_id":"180150","upvote_count":"2","timestamp":"1600225560.0","content":"Answer: A"},{"comment_id":"114679","poster":"Tushant","content":"A is the answer","timestamp":"1592647680.0","upvote_count":"3"},{"upvote_count":"2","poster":"Tushant","content":"Correct answer is A","comment_id":"107931","timestamp":"1591893480.0"},{"upvote_count":"3","content":"A, for sure.\nwhen CPU usage exceeds 75%","poster":"gfhbox0083","timestamp":"1591778400.0","comment_id":"106601"},{"upvote_count":"2","timestamp":"1591280520.0","content":"A is the correct answer","poster":"Ziegler","comment_id":"102426"},{"upvote_count":"1","poster":"gcp_aws","timestamp":"1590426300.0","comment_id":"95536","content":"A is the answer"},{"upvote_count":"2","timestamp":"1582879080.0","poster":"[Removed]","comment_id":"56427","content":"Agree: A. Selected A in the exam"},{"content":"Answer: A","timestamp":"1580396940.0","comment_id":"44839","upvote_count":"2","poster":"2g"},{"poster":"KouShikyou","upvote_count":"2","comments":[{"comments":[{"timestamp":"1596710460.0","content":"A is ok","comment_id":"151890","upvote_count":"3","poster":"tartar"}],"timestamp":"1589670900.0","content":"I don't think that is the relevant document because it doesn't mention sharding.","poster":"aselunar","upvote_count":"2","comment_id":"90207"},{"poster":"kumarp6","timestamp":"1604240460.0","comment_id":"210523","upvote_count":"1","content":"A is right"},{"upvote_count":"1","comment_id":"303724","timestamp":"1614902700.0","content":"A, its very high level. Missing lot of steps. But other options just wont work.","poster":"nitinz"}],"timestamp":"1570966260.0","content":"https://cloud.google.com/sql/docs/mysql/high-availability#replication-lag","comment_id":"14984"}],"answer_description":"","exam_id":4,"isMC":true,"choices":{"C":"1. Create a Stackdriver alert when storage exceeds 75%, and increase the available storage on the instance to create more space. 2. Deploy memcached to reduce CPU load. 3. Change the instance type to a 32-core machine type to reduce replication lag.","B":"1. Enable automatic storage increase for the instance. 2. Change the instance type to a 32-core machine type to keep CPU usage below 75%. 3. Create a Stackdriver alert for replication lag, and deploy memcache to reduce load on the master.","A":"1. Enable automatic storage increase for the instance. 2. Create a Stackdriver alert when CPU usage exceeds 75%, and change the instance type to reduce CPU usage. 3. Create a Stackdriver alert for replication lag, and shard the database to reduce replication time.","D":"1. Create a Stackdriver alert when storage exceeds 75%, and increase the available storage on the instance to create more space. 2. Deploy memcached to reduce CPU load. 3. Create a Stackdriver alert for replication lag, and change the instance type to a 32-core machine type to reduce replication lag."},"answer_ET":"A","answers_community":["A (80%)","B (20%)"],"timestamp":"2019-10-13 13:31:00","answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/6529-exam-professional-cloud-architect-topic-1-question-73/"},{"id":"XuNqOX3M6CjfNkbROIJy","answer_images":[],"topic":"1","answer_ET":"D","isMC":true,"exam_id":4,"choices":{"A":"Cloud Spanner, because it is globally distributed","B":"Cloud SQL, because it is a fully managed relational database","C":"Cloud Firestore, because it offers real-time synchronization across devices","D":"BigQuery, because it is designed for large-scale processing of tabular data"},"question_id":173,"answer_description":"","answers_community":["D (94%)","6%"],"url":"https://www.examtopics.com/discussions/google/view/11817-exam-professional-cloud-architect-topic-1-question-74/","unix_timestamp":1578836520,"timestamp":"2020-01-12 14:42:00","question_text":"You are tasked with building an online analytical processing (OLAP) marketing analytics and reporting tool. This requires a relational database that can operate on hundreds of terabytes of data. What is the Google-recommended tool for such applications?","discussion":[{"upvote_count":"21","timestamp":"1578836520.0","comment_id":"38090","poster":"AWS56","comments":[{"comment_id":"151892","timestamp":"1596710520.0","poster":"tartar","content":"D is ok","upvote_count":"5","comments":[{"comment_id":"278134","poster":"Nastrand","comments":[{"content":"BigQuery is relational!","timestamp":"1623310440.0","comment_id":"378851","poster":"riflerrick","upvote_count":"5"},{"upvote_count":"15","content":"Pls do not confuse - Cloud SQL and BigQuery are RDBMS. Cloud Datastore, Bigtable are NoSQL.\nRight answer is D - BQ","timestamp":"1625724480.0","poster":"lovingsmart2000","comment_id":"401580"}],"timestamp":"1611791640.0","upvote_count":"4","content":"What about the relational part? BigQuery uses SQL but it's not relational... I'm not sure its D"}]},{"timestamp":"1604240520.0","comment_id":"210524","poster":"kumarp6","upvote_count":"2","content":"Yes it is D"},{"timestamp":"1614902760.0","poster":"nitinz","upvote_count":"5","comment_id":"303725","content":"D, OLAP=BQ","comments":[{"upvote_count":"1","poster":"Sur_Nikki","comment_id":"891909","content":"Well Said","timestamp":"1683533460.0"}]},{"comment_id":"460824","poster":"JasonL_GCP","content":"The question asks \"This requires a relational database that can operate on hundreds of terabytes of data\", but bq doesn't meet this condition?","comments":[{"poster":"elaineshi","upvote_count":"2","content":"BigQuery supports relational and query of join tables.","comment_id":"610215","timestamp":"1654094520.0"}],"upvote_count":"2","timestamp":"1633992480.0"}],"content":"Agree D"},{"poster":"gfhbox0083","timestamp":"1591778520.0","upvote_count":"16","comment_id":"106603","content":"D, for sure.\nBigQuery for OLAP\nGoogle Cloud Spanner for OLTP."},{"content":"Selected Answer: D\nsql is oltp \nolap is data cube. lots of data which we try to process somehow. biq query is for that. \n\nfirestore is for mobile and web apps. not so fast nosql db.","upvote_count":"1","comment_id":"1246312","poster":"gracjanborowiak","timestamp":"1720731360.0"},{"comment_id":"1155625","upvote_count":"1","timestamp":"1708528260.0","content":"Agreed","poster":"Anandmrk"},{"timestamp":"1696558980.0","comment_id":"1026156","upvote_count":"1","poster":"AdityaGupta","content":"Selected Answer: D\n4 reasons to choose BQ (Supports Petabytes of data)\n - OLAP Data \n - Relational DB (SQL)\n - 100s of TB data\n - Analystics and Reporting"},{"timestamp":"1678569660.0","content":"Selected Answer: D\nD is obvious","poster":"Ashish1995","upvote_count":"1","comment_id":"836530"},{"upvote_count":"1","poster":"CGS22","timestamp":"1678207800.0","comment_id":"832119","content":"Selected Answer: D\nD is the right one"},{"timestamp":"1671162900.0","content":"Cloud SQL/Spanner is OLTP DB but not OLAP. BQ is a well-known OLAP for analytics and also supports RBMS feature too... so I would got with D","upvote_count":"1","poster":"SudhirAhirkar","comment_id":"746774"},{"content":"Selected Answer: D\nD is correct. BigQuery is relational. Cloud SQL is not OLAP; moreover it can not store/process hundreds of TB of data. Max size is 64 TB only.","upvote_count":"1","poster":"AniketD","comment_id":"723332","timestamp":"1669022100.0"},{"content":"Selected Answer: D\nD is ok","timestamp":"1667839560.0","poster":"megumin","comment_id":"713172","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: D\nhttps://cloud.google.com/products/databases.","poster":"SerGCP","comment_id":"707743","timestamp":"1667122800.0"},{"poster":"zr79","content":"The words you need to focus \"You are tasked with building an online analytical processing (OLAP) marketing analytics and reporting tool\" which is BigQuery","timestamp":"1665992040.0","comment_id":"697048","upvote_count":"1"},{"timestamp":"1665938340.0","poster":"AzureDP900","upvote_count":"1","comment_id":"696385","content":"Big Query for large analytics , D is right"},{"poster":"Andre777","upvote_count":"2","timestamp":"1663554060.0","content":"Selected Answer: D\nThe keyword in this context is OLAP. CloudSQL is Relational SQL for OLTP. Capacity wise, BQ supports for PB+ while CloudSQL only have max capacity of up to ~10TB. Again the questions specifically mention \"hundreds of TB of data\". So D is the answer.","comment_id":"672858"},{"comment_id":"669050","content":"Why is it not CloudSQL? It supports TB data storage and the question is about a relational database, not a data warehouse such as BigQuery.","comments":[{"content":"The keyword in this context is OLAP. CloudSQL is Relational SQL for OLTP. Capacity wise, BQ supports for PB+ while CloudSQL only have max capacity of up to ~10TB. Again the questions specifically mention \"hundreds of TB of data\". So D is the answer.","upvote_count":"1","timestamp":"1663554000.0","poster":"Andre777","comment_id":"672857"}],"poster":"deepdowndave","upvote_count":"1","timestamp":"1663161840.0"},{"comment_id":"665067","poster":"alexandercamachop","timestamp":"1662782580.0","content":"The answer is Big Query, D\nSecret: Analytical, Hundreds of TBTs. Relational. \nAll of this are strictly meet by Big Query, if it had not said Analytical but rather, other keywords like High Availability then Cloud Spanner.","upvote_count":"1"},{"poster":"Thornadoo","content":"Selected Answer: D\nGuys, this is easy:\nOLTP - Cloud Spanner & Cloud SQL\nOLAP - Big Query\nNoSQL - Filestore and Big Table\n\nSo answer is D.","timestamp":"1658406120.0","upvote_count":"1","comment_id":"634582"},{"timestamp":"1649224980.0","upvote_count":"1","comment_id":"581613","poster":"SamT1","content":"Selected Answer: D\nCloud Spanner is used for OLTP and the question is about OLAP, hence bigquery is best suited."},{"timestamp":"1644868800.0","upvote_count":"3","poster":"Laufente","comment_id":"547330","content":"Selected Answer: D\nD, OLAP is BigQuery"},{"poster":"ZackW","content":"Selected Answer: D\ndude that voted is wrong lol.\nAns is D as all others have said.","timestamp":"1644253740.0","upvote_count":"2","comment_id":"542566"},{"poster":"KevPinto","timestamp":"1643294100.0","comment_id":"533831","content":"Selected Answer: A\nCloud Spanner -- 2 reasons 1) Relational 2) > 30 TB requirement","upvote_count":"1"},{"content":"Go for D","poster":"haroldbenites","upvote_count":"1","comment_id":"495734","timestamp":"1638862500.0"},{"comment_id":"488880","timestamp":"1638080580.0","upvote_count":"1","content":"D is the correct answer.","poster":"vincy2202"},{"timestamp":"1635424920.0","content":"D â€“ BiqQuery works for 100+ TB and is for analytics.","upvote_count":"1","poster":"MaxNRG","comment_id":"469262"},{"comment_id":"458094","upvote_count":"1","content":"D is ok","poster":"hardharsh","timestamp":"1633504740.0"},{"content":"To give more clarity for people swaying between Cloud Spanner or Bigquery\n\nThe big query does not provide you relationship between tables but you can join them freely. If your performance falls cluster then partition on the joining fields.\n\nhttps://stackoverflow.com/questions/48267761/is-it-possible-to-create-relationships-between-tables\n\nSome more literature if some want to go into the details.\n\n\"By using MapReduce, enterprises can cost-effectively apply parallel data\nprocessing on their Big Data in a highly scalable manner, without bearing the\nburden of designing a large distributed computing cluster from scratch or\npurchasing expensive high-end relational database solutions or appliances. \"\n\nhttps://cloud.google.com/files/BigQueryTechnicalWP.pdf\n\nHence D","comment_id":"436227","poster":"amxexam","upvote_count":"1","timestamp":"1630405140.0"},{"upvote_count":"2","timestamp":"1625766780.0","comment_id":"402117","poster":"MamthaSJ","content":"Answer is D"},{"poster":"areza","content":"D is ok","timestamp":"1623238680.0","comment_id":"378228","upvote_count":"1"},{"timestamp":"1621423080.0","upvote_count":"2","comment_id":"361305","poster":"victory108","content":"D. BigQuery, because it is designed for large-scale processing of tabular data"},{"poster":"un","comment_id":"357871","upvote_count":"1","content":"D is ok","timestamp":"1621084500.0"},{"upvote_count":"1","poster":"lynx256","content":"D is ok.","timestamp":"1616834040.0","comment_id":"321682"},{"upvote_count":"1","content":"D - BigQuery.\nPlease refer \"What Storage Type\" section in the below page.\nhttps://medium.com/google-cloud/a-gcp-flowchart-a-day-2d57cc109401","poster":"humbling_learning","timestamp":"1614300300.0","comment_id":"299465"},{"content":"cloud sql, cloud spanner and big query is ration sql for oltp and best for analsys so ans is D","comment_id":"291105","timestamp":"1613404260.0","upvote_count":"1","poster":"CloudGenious"},{"content":"You need to understand that BigQuery cannot be used to substitute a relational database, and it is oriented on running analytical queries, not for simple CRUD operations and queries\nBut the question is bit tricky. The requirement is for analyzing the data in a relational database manner. So no Create, Update and delete on the data. For this Big query will suffice. Answer D","comment_id":"241465","upvote_count":"1","poster":"Bijesh","timestamp":"1607765880.0"},{"content":"OLAP is the key here thus D using big query is the answer.","comment_id":"201343","poster":"LoganIsh","timestamp":"1602910740.0","upvote_count":"1"},{"timestamp":"1601624700.0","comment_id":"191475","content":"If we consider BigQuery as OLAP,marketing analytics and reporting then another part in question is it should be relational database. Is BigQuery will satisfy this requirement ?","comments":[{"comment_id":"192801","upvote_count":"2","poster":"akhadar2001","timestamp":"1601802660.0","content":"This is exam question and I cleared the exam but a lot of dilemma between cloud spanner and Bigquery since there are 2 parts OLAP (bigquery) and relational database (cloud spanner since peta bytes of data and application is a global) which were so confusing and the same is replicated in the exam too."}],"poster":"akhadar2001","upvote_count":"1"},{"timestamp":"1600225620.0","content":"D - Bigquery","upvote_count":"1","comment_id":"180151","poster":"AshokC"},{"upvote_count":"2","content":"Yeah D is correct","timestamp":"1592913960.0","poster":"mlantonis","comment_id":"117432"},{"timestamp":"1592647680.0","upvote_count":"1","content":"D is the answer","comment_id":"114680","poster":"Tushant"},{"comments":[{"poster":"BeppeIta","upvote_count":"3","timestamp":"1591423560.0","comment_id":"103601","content":"I think for \"analytics and reporting tool\" reason. you can't use Cloud spanner for analytics and reporting. you need to export data to bigquery . On the other hands, bigquery is transaztional per row and just enabled for analytics...and you can use sql language. So, cause of the purpose is not for CRUD, I'll go for D"}],"timestamp":"1591375080.0","content":"requires a relational database that can operate on hundreds of terabytes of data. This is the ask and Bigquery cannot be substitute as Relational database. why Answer can not be Cloud Spanner which is petabyte scale Relational database.. I think Answer is A","poster":"Hemant_C","comment_id":"103282","upvote_count":"3"},{"content":"D is the correct answer","comment_id":"102428","poster":"Ziegler","timestamp":"1591280580.0","upvote_count":"1"},{"comment_id":"98112","content":"Final Decision to go with Option D","poster":"AD2AD4","upvote_count":"1","timestamp":"1590740940.0"},{"content":"Supporting Standard SQL does not make BigQuery a relational database.","upvote_count":"5","poster":"chauvinhloi","timestamp":"1590461880.0","comment_id":"95743","comments":[{"content":"Agreed","poster":"NapFalg","upvote_count":"1","timestamp":"1595160840.0","comment_id":"138656"}]},{"timestamp":"1590426240.0","comment_id":"95535","upvote_count":"1","content":"D is the answer","poster":"gcp_aws"},{"comment_id":"57267","comments":[{"timestamp":"1585207140.0","comment_id":"68285","content":"Bigquery supports Standard SQL\nhttps://cloud.google.com/bigquery/?utm_source=google&utm_medium=cpc&utm_campaign=japac-SG-all-en-dr-bkws-all-super-trial-e-dr-1008074&utm_content=text-ad-none-none-DEV_c-CRE_316279348549-ADGP_Hybrid+%7C+AW+SEM+%7C+BKWS+~+T1+%7C+EXA+%7C+Big+Data+%7C+1:1+%7C+SG+%7C+en+%7C+bigquery-KWID_43700028131581223-kwd-297617549231&userloc_9062530&utm_term=KW_bigquery&gclid=EAIaIQobChMI1evg59m36AIVVaqWCh0HFAwSEAAYASAAEgKdEfD_BwE#all-features","poster":"zc","upvote_count":"1"},{"content":"From the attached source:\n\nRelational OLAP (ROLAP)\nROLAP is an OLAP solution based on relational databases (RDB). In order\nto make RDB faster, you always need to build indices before running OLAP\nqueries. Without an index, the response will be very slow when running a query\non Big Data. For this reason, you need to build indices for every possible query\nbeforehand. In many cases, you need to build many indices to cover all the\nexpected queries, and their size could become larger than original data. If the\ndata is really large, sometimes the entire set of data and indices would require\never larger and more complex and expensive hardware to house it.","comment_id":"99954","poster":"misho","upvote_count":"1","timestamp":"1591011000.0"}],"content":"its mentioned they need a relational database so how can bigquery fir into this?","poster":"gm123","timestamp":"1583075100.0","upvote_count":"2"},{"comment_id":"56428","poster":"[Removed]","upvote_count":"3","content":"Agree: D. Selected D in the exam","timestamp":"1582879080.0"},{"poster":"xkermit","comment_id":"49163","upvote_count":"1","content":"My answer is A","timestamp":"1581429780.0","comments":[{"timestamp":"1581429900.0","upvote_count":"3","comment_id":"49164","content":"Forget it. It is D. because OLAP.","poster":"xkermit"}]},{"timestamp":"1580396940.0","upvote_count":"2","comment_id":"44841","poster":"2g","content":"Answer: D"}],"answer":"D","question_images":[]},{"id":"ZIJUuWGwlPNxU94ilGPe","timestamp":"2019-10-11 11:49:00","answer_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/google/view/6452-exam-professional-cloud-architect-topic-1-question-75/","answers_community":["C (100%)"],"choices":{"A":"Use gcloud sql instances restart.","B":"Validate that the Service Account used by the Cloud SQL proxy container still has the Cloud Build Editor role.","D":"In the GCP Console, navigate to Cloud SQL. Restore the latest backup. Use kubectl to restart all pods.","C":"In the GCP Console, navigate to Stackdriver Logging. Consult logs for (GKE) and Cloud SQL."},"discussion":[{"upvote_count":"67","content":"post mortem always includes log analysis, answer is C","comment_id":"16445","comments":[{"comment_id":"891913","upvote_count":"1","timestamp":"1715156160.0","poster":"Sur_Nikki","content":"Thanks for the info"},{"comment_id":"696384","poster":"AzureDP900","upvote_count":"1","timestamp":"1697474280.0","content":"C is right for Root Cause Analysis."},{"comment_id":"38091","poster":"AWS56","timestamp":"1610459040.0","upvote_count":"3","content":"AGREE C"}],"timestamp":"1603290000.0","poster":"jcmoranp"},{"upvote_count":"5","timestamp":"1657302900.0","content":"Answer is C","comment_id":"402119","poster":"MamthaSJ"},{"comment_id":"1085106","poster":"pakilodi","upvote_count":"2","content":"Selected Answer: C\nC -> post-mortem = log analysis","timestamp":"1733045400.0"},{"poster":"AdityaGupta","timestamp":"1728181620.0","upvote_count":"1","comment_id":"1026158","content":"Selected Answer: C\nYou can jump on to the conlusion hence answer is not B. Consulting logs is always a good way to start investigation. and A and D is not a choice."},{"poster":"ale_brd_111","comment_id":"718580","content":"Stackdriver is deprecated, now you must navigate to Cloud Logging.","timestamp":"1700035860.0","upvote_count":"2"},{"upvote_count":"1","poster":"megumin","timestamp":"1699375740.0","content":"Selected Answer: C\nC is ok","comment_id":"713173"},{"timestamp":"1698026640.0","comment_id":"701858","content":"Selected Answer: C\nC is the right answer","upvote_count":"1","poster":"Mahmoud_E"},{"content":"Selected Answer: C\nLogical answer is C. But is Stackdriver Logging enabled by default? Appreciate if someone could answer this?","upvote_count":"1","timestamp":"1693900260.0","poster":"Jay_Krish","comment_id":"659884"},{"upvote_count":"1","content":"Go for C","poster":"haroldbenites","timestamp":"1670398620.0","comment_id":"495737"},{"content":"Selected Answer: C\npost mortem = logs","timestamp":"1670246040.0","upvote_count":"1","poster":"pakilodi","comment_id":"494344"},{"timestamp":"1669617000.0","poster":"vincy2202","comment_id":"488887","upvote_count":"1","content":"C is the correct answer"},{"timestamp":"1669334040.0","content":"Selected Answer: C\nvote C","comment_id":"486331","poster":"joe2211","upvote_count":"1"},{"comment_id":"469270","upvote_count":"4","content":"C â€“ in GCP Console navigate to Stackdriver Logging. Consult logs for Kubernetes Engine and Cloud SQL.\nA/D â€“ is an immediate attempt to fix an issue. No analysis.\nB â€“ is irrelevant at all. Cloud SQL proxy should not build anything in production.","poster":"MaxNRG","timestamp":"1666962540.0"},{"comment_id":"401873","upvote_count":"4","poster":"lovingsmart2000","timestamp":"1657280940.0","content":"Answer is C. I request all here - not to blindly follow the answers published at coursera or udemy as most of them are copy-pasted answer and are not real. Examtopis provides the more accurate answers and also support with comments"},{"upvote_count":"4","content":"Why Service Account needs Cloud Build Editor role for accessing Cloud SQL?\nThe role is misleading/wrong, so B is wrong.","poster":"ashish_t","comment_id":"461676","timestamp":"1665684840.0"},{"upvote_count":"2","poster":"victory108","comment_id":"361304","content":"C. In the GCP Console, navigate to Stackdriver Logging. Consult logs for Kubernetes Engine and Cloud SQL.","timestamp":"1652959080.0"},{"comment_id":"357873","upvote_count":"1","content":"C is correct","timestamp":"1652620620.0","poster":"un"},{"timestamp":"1648792620.0","comment_id":"325551","upvote_count":"2","poster":"Ausias18","content":"Answer is C"},{"content":"IMO - C is ok.","upvote_count":"1","timestamp":"1648375260.0","poster":"lynx256","comment_id":"321812","comments":[{"comments":[{"timestamp":"1649438100.0","content":"In My Opinion","upvote_count":"2","comment_id":"331395","poster":"tzKhalil"}],"upvote_count":"1","poster":"getzsagar","content":"what is IMO ?","timestamp":"1649319360.0","comment_id":"330170"}]},{"timestamp":"1647671820.0","content":"Agree with C","comment_id":"314625","upvote_count":"1","poster":"BikramY"},{"poster":"Rothmansua","timestamp":"1643405460.0","comment_id":"278842","upvote_count":"2","content":"Cloud _Build_ Editor role for Cloud SQL?"},{"poster":"pepYash","upvote_count":"1","timestamp":"1636501560.0","content":"B does not make sense.\nC is the only legit answer here with the \"post mortem\" thing\nJustification:\nhttps://cloud.google.com/sql/docs/mysql/connect-kubernetes-engine#providing_the_service_account_to_the_proxy","comment_id":"216269"},{"comment_id":"206514","poster":"AdityaGupta","timestamp":"1635267000.0","upvote_count":"2","content":"I will go with answer C: In the GCP Console, navigate to Stackdriver Logging. Consult logs for Kubernetes Engine and Cloud SQL..\n\nAfter analysing the logs the answer may come out to be B, but it is not necessary all the time."},{"upvote_count":"1","timestamp":"1634793600.0","content":"sorry C makes more sense than B.","comment_id":"203541","poster":"LoganIsh"},{"timestamp":"1633773840.0","content":"i go with b as per udemy exam.","poster":"LoganIsh","upvote_count":"1","comment_id":"196639"},{"poster":"VedaSW","content":"The Answer B is performing investigation. The question ask for post-mortem. Investigation != Post-mortem.\n\nI go with C.","timestamp":"1632655440.0","comment_id":"187618","upvote_count":"1"},{"comment_id":"182611","poster":"PJ_Exams","content":"Answer is B, because it is finding from C (which is already mentioned in question itself, \"connection\" related issues)","upvote_count":"2","timestamp":"1632105480.0"},{"content":"C is correct","timestamp":"1631761920.0","comment_id":"180153","upvote_count":"1","poster":"AshokC"},{"timestamp":"1630186440.0","comment_id":"168779","poster":"Kabiliravi","upvote_count":"1","content":"C is correct, \nthe ask is post-mortem not proposing the solution. In post-mortem you need to analyze why that problem happened. That needs observation through the logs"},{"poster":"wiqi","timestamp":"1629507360.0","content":"I would go with C.\nI dont think Cloud Build Editor has anything to do with it. That role is for Cloud build and not for SQL Connection.","comment_id":"162590","upvote_count":"1"},{"content":"answer is B in udemy practice exam","poster":"faurenlarr","comment_id":"158192","comments":[{"upvote_count":"1","content":"The ask is post-mortem not giving the solution","timestamp":"1630186320.0","poster":"Kabiliravi","comment_id":"168777"}],"timestamp":"1628956260.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1624449900.0","poster":"mlantonis","comment_id":"117431","content":"C is better solution."},{"upvote_count":"1","timestamp":"1624183740.0","content":"C is the answer","comment_id":"114681","poster":"Tushant"},{"poster":"shashu07","content":"Correct Answer: B\ntype Cloud Build Editor, must be Cloud SQL Editor \nYou have deployed application that means its not running, so here is the post-mortem of connection issues \nhttps://cloud.google.com/sql/docs/mysql/sql-proxy#troubleshooting\nRequired permissions for service accounts\nWhen you use a service account to provide the credentials for the proxy, you must create it with sufficient permissions. If you are using the finer-grained Identity Access and Management (IAM) roles to manage your Cloud SQL permissions, you must give the service account a role that includes the cloudsql.instances.connect permission. The predefined Cloud SQL roles that include this permission are: \n Cloud SQL Client\n Cloud SQL Editor\n Cloud SQL Admin\nIf you are using the legacy project roles (Viewer, Editor, Owner), the service account must have at least the Editor role.","comments":[{"content":"you right but the question says Cloud Build Editor so the answer its C\nand I think if someone ask you for a report its better to give them a logging","comment_id":"210918","poster":"francisco_guerra","upvote_count":"2","timestamp":"1635819240.0"}],"upvote_count":"3","timestamp":"1623762060.0","comment_id":"110819"},{"upvote_count":"1","poster":"Tushant","timestamp":"1623430080.0","content":"Correct answer is C","comment_id":"107947"},{"timestamp":"1623314580.0","comment_id":"106605","poster":"gfhbox0083","content":"C, for sure.\nAs your company policies require a post-mortem.","upvote_count":"1"},{"upvote_count":"1","timestamp":"1622817720.0","comment_id":"102443","poster":"Ziegler","content":"C is the right answer because you need to examine the log to know the root cause of the issue"},{"comment_id":"97459","content":"Final Decision to go with Option C","timestamp":"1622200320.0","upvote_count":"1","poster":"AD2AD4"},{"comment_id":"95644","timestamp":"1621973880.0","upvote_count":"1","poster":"gcp_aws","content":"C is the answer"},{"poster":"Jack_in_Large","upvote_count":"1","comment_id":"89624","content":"C is right","timestamp":"1621106820.0"},{"poster":"GunjGupta","comment_id":"89521","upvote_count":"2","timestamp":"1621084980.0","content":"the very first thing to do as part of post mortem/Root cause analysis is to check the logs.\nand Option C meets the requirement"},{"upvote_count":"3","content":"100% C","comment_id":"86248","poster":"asure","timestamp":"1620596460.0"},{"timestamp":"1620162600.0","comment_id":"83825","poster":"Zarmi","content":"Answer: C","upvote_count":"2"},{"upvote_count":"2","poster":"Javed","timestamp":"1615456680.0","comment_id":"62353","content":"C should be correct"},{"poster":"PalSri","content":"I think the answer should be C, as we need to provide the RCA","upvote_count":"1","comment_id":"57235","timestamp":"1614608820.0"},{"poster":"[Removed]","comment_id":"56429","upvote_count":"3","content":"Selected C in the exam.","timestamp":"1614501540.0"},{"timestamp":"1612019400.0","poster":"2g","content":"Answer: C","upvote_count":"3","comment_id":"44842"},{"timestamp":"1611674280.0","comment_id":"42940","content":"Agree C","poster":"natpilot","upvote_count":"2"},{"timestamp":"1608311040.0","upvote_count":"2","poster":"elguando","content":"Would Cloud Build Editor role even have anything to do with connecting via cloud sql proxy?","comment_id":"30689"},{"content":"B - https://cloud.google.com/sql/docs/mysql/sql-proxy#authentication-options","comment_id":"26841","timestamp":"1607159880.0","comments":[{"content":"B LOOKS RIGHT","comment_id":"179855","poster":"passtest100","upvote_count":"1","timestamp":"1631709000.0"}],"upvote_count":"2","poster":"kolcsarzs"},{"comments":[{"poster":"nitinz","timestamp":"1646438820.0","content":"C, rest all options are useless.","upvote_count":"1","comment_id":"303726"},{"content":"No it is not, it should C","upvote_count":"6","comment_id":"210531","poster":"kumarp6","timestamp":"1635778320.0"},{"content":"C is ok","upvote_count":"7","poster":"tartar","timestamp":"1628246640.0","comment_id":"151895"}],"upvote_count":"1","poster":"KouShikyou","comment_id":"14734","timestamp":"1602409740.0","content":"Is it possible to explain why answer is B?\nThanks a lot."}],"exam_id":4,"answer":"C","isMC":true,"answer_ET":"C","answer_description":"","question_images":[],"question_text":"You have deployed an application to Google Kubernetes Engine (GKE), and are using the Cloud SQL proxy container to make the Cloud SQL database available to the services running on Kubernetes. You are notified that the application is reporting database connection issues. Your company policies require a post- mortem. What should you do?","question_id":174,"unix_timestamp":1570787340},{"id":"3EJ0Jdntpv6BYUVRBAtz","question_id":175,"answer_description":"","timestamp":"2020-01-12 14:45:00","isMC":true,"choices":{"A":"Ensure that VM service accounts are granted the appropriate Cloud Pub/Sub IAM roles.","D":"Create a gateway to Cloud Pub/Sub using a Cloud Function, and grant the Cloud Function service account the appropriate Cloud Pub/Sub IAM roles.","C":"Generate an OAuth2 access token for accessing Cloud Pub/Sub, encrypt it, and store it in Cloud Storage for access from each VM.","B":"Ensure that VM service accounts do not have access to Cloud Pub/Sub, and use VM access scopes to grant the appropriate Cloud Pub/Sub IAM roles."},"url":"https://www.examtopics.com/discussions/google/view/11818-exam-professional-cloud-architect-topic-1-question-76/","question_images":[],"answer_images":[],"unix_timestamp":1578836700,"answers_community":["A (100%)"],"exam_id":4,"answer_ET":"A","answer":"A","topic":"1","discussion":[{"content":"Agree A","comments":[{"content":"A is correct","poster":"nitinz","upvote_count":"2","comment_id":"303728","timestamp":"1630793340.0"},{"upvote_count":"2","comment_id":"210533","timestamp":"1619873700.0","content":"Yes A it is","poster":"kumarp6"}],"comment_id":"38092","upvote_count":"26","poster":"AWS56","timestamp":"1594554300.0"},{"comment_id":"439449","poster":"JustJack21","upvote_count":"13","content":"It's because of questions like these that I do not feel guilty about using question banks :D In what world would you accept value requirements like this from your user? Wouldn't you ask \"Do you want to just authenticate? or the data to be encrypted on its way to pub/sub?\"\nI'll ignore the first part of the question and assume all data is sensitive, and focus on \"What is the Google- recommended way for your application to authenticate to the required Google Cloud services?\" -- The answer then is A. \n\nUse encryption and defense-in-depth for the first part.","timestamp":"1646459280.0","comments":[{"timestamp":"1720030620.0","comment_id":"1113093","poster":"bandegg","content":"> It's because of questions like these that I do not feel guilty about using question banks :D\n\nSame. To me, it wasn't clear whether the servers were in google or not due to the question about accessing google cloud. It was asked as if the VMs were outside of google","upvote_count":"3"},{"poster":"AMEJack","content":"Service accounts use keys","upvote_count":"1","comment_id":"688795","timestamp":"1680883680.0"}]},{"poster":"red_panda","timestamp":"1701933900.0","comment_id":"916886","upvote_count":"2","content":"Selected Answer: A\nA is correct for me. It's batch, so no cloud function"},{"content":"A. Ensure that VM service accounts are granted the appropriate Cloud Pub/Sub IAM roles.\n\nThe Google-recommended way for your application to authenticate to Cloud Pub/Sub and other Google Cloud services when running on Compute Engine VMs is to use VM service accounts. VM service accounts are automatically created when you create a Compute Engine VM, and they are associated with the VM instance. To authenticate to Cloud Pub/Sub and other Google Cloud services, you should ensure that the VM service accounts are granted the appropriate IAM roles.","comments":[{"upvote_count":"3","comments":[{"timestamp":"1699438920.0","content":"Great way of explanation..By removing/elimination approach","upvote_count":"1","poster":"Sur_Nikki","comment_id":"891917"}],"content":"Option B, ensuring that VM service accounts do not have access to Cloud Pub/Sub and using VM access scopes to grant the appropriate Cloud Pub/Sub IAM roles, would not be a suitable solution because VM service accounts are required for authentication to Google Cloud services.\n\nOption C, generating an OAuth2 access token for accessing Cloud Pub/Sub, encrypting it, and storing it in Cloud Storage for access from each VM, would not be a suitable solution because it would require manual management of access tokens, which can be error-prone and insecure.\n\nOption D, creating a gateway to Cloud Pub/Sub using a Cloud Function and granting the Cloud Function service account the appropriate Cloud Pub/Sub IAM roles, would not be a suitable solution because it would not allow the application to directly authenticate to Cloud Pub/Sub.","timestamp":"1687409160.0","comment_id":"753032","poster":"omermahgoub"}],"upvote_count":"8","comment_id":"753031","poster":"omermahgoub","timestamp":"1687409100.0"},{"timestamp":"1683471180.0","poster":"megumin","upvote_count":"1","content":"Selected Answer: A\nA is ok","comment_id":"713176"},{"comment_id":"701860","content":"Selected Answer: A\nA is the correct answer","poster":"Mahmoud_E","timestamp":"1682215560.0","upvote_count":"1"},{"comment_id":"642318","content":"Selected Answer: A\nhttps://cloud.google.com/iam/docs/understanding-service-accounts","poster":"DrishaS4","upvote_count":"1","timestamp":"1675513740.0"},{"comment_id":"536975","upvote_count":"2","content":"Selected Answer: A\nThe combination of Roles assigned to Service accounts granted to VMs is the way to go. :)","timestamp":"1659263640.0","poster":"Pazzooo"},{"content":"Service accounts are recommended for almost all cases in Pub/Sub (see https://cloud.google.com/pubsub/docs/authentication#service-accounts)","timestamp":"1656854820.0","poster":"elenamatay","upvote_count":"3","comment_id":"515870"},{"upvote_count":"2","timestamp":"1654580580.0","content":"Go for A.","comment_id":"495745","poster":"haroldbenites"},{"comment_id":"488891","upvote_count":"1","content":"A is the correct answer","timestamp":"1653712500.0","poster":"vincy2202"},{"comment_id":"469365","poster":"MaxNRG","upvote_count":"3","content":"A â€“ ensure that VM service accounts are granted the appropriate Cloud Pub/Sub IAM roles.\nCheck Migrating Data to GCP section of this page:\nhttps://cloud.google.com/iam/docs/understanding-service-accounts \nYou will create a service account key and use it from an external process to call Cloud Platform APIs.","timestamp":"1651162800.0"},{"upvote_count":"1","comment_id":"466486","timestamp":"1650703800.0","poster":"Bakili","content":"A is very correct"},{"upvote_count":"2","content":"Answer is A","timestamp":"1641671760.0","comment_id":"402121","poster":"MamthaSJ"},{"upvote_count":"3","comments":[{"content":"Agreed with A","timestamp":"1681662960.0","comment_id":"696383","upvote_count":"1","poster":"AzureDP900"}],"poster":"victory108","content":"A. Ensure that VM service accounts are granted the appropriate Cloud Pub/Sub IAM roles.","comment_id":"361299","timestamp":"1637327640.0"},{"comment_id":"357875","content":"A is correct","upvote_count":"1","poster":"un","timestamp":"1636989780.0"},{"comment_id":"326011","upvote_count":"1","timestamp":"1633106880.0","poster":"kartikjena31","content":"Ans. A"},{"poster":"Ausias18","content":"Answer is A","timestamp":"1633067880.0","upvote_count":"2","comment_id":"325553"},{"upvote_count":"1","poster":"lynx256","content":"A is ok.","timestamp":"1632733860.0","comment_id":"321784"},{"timestamp":"1627519080.0","comment_id":"278959","content":"for sensitive data, there must be encryption. only C mentioned that.\nI choose C","upvote_count":"1","poster":"bnlcnd"},{"timestamp":"1623234960.0","poster":"Viba","content":"As per -\nhttps://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances\nThe service account can only execute API methods that are allowed by both the access scope and the service account's specific IAM roles.\nAs per the above, correct answer is 'A'","comment_id":"239178","upvote_count":"3"},{"poster":"AshokC","timestamp":"1615871700.0","comment_id":"180154","content":"A is meaningful","upvote_count":"1"},{"timestamp":"1608732420.0","comment_id":"117434","upvote_count":"1","poster":"mlantonis","content":"A is for sure correct"},{"timestamp":"1608466200.0","comment_id":"114682","upvote_count":"1","content":"A is the answer","poster":"Tushant"},{"upvote_count":"1","poster":"gfhbox0083","comment_id":"106607","timestamp":"1607597160.0","content":"A, for sure, \nUsing VM service accounts"},{"content":"A is the right answer","upvote_count":"2","comment_id":"102445","poster":"Ziegler","timestamp":"1607100300.0"},{"poster":"gcp_aws","comment_id":"95645","upvote_count":"3","timestamp":"1606342740.0","content":"A is the answer"},{"comment_id":"56430","poster":"[Removed]","upvote_count":"3","timestamp":"1598596740.0","content":"Agree A. Selected A in the exam","comments":[{"comments":[{"poster":"victor_smith","comment_id":"130435","content":"You can clearly see that at least 5 accounts are bots mate :(","timestamp":"1610188800.0","upvote_count":"4","comments":[{"comment_id":"321786","timestamp":"1632734040.0","poster":"lynx256","content":"I don't think so :)\nCould you please write a few you think are bots ?","upvote_count":"1"}]}],"content":"you mean you had this question in your exam ? (as all of your answers look like that)","timestamp":"1607090880.0","upvote_count":"10","poster":"gfhbox0083","comment_id":"102351"}]},{"upvote_count":"3","poster":"2g","content":"Answer: A","comment_id":"44843","timestamp":"1596114660.0"}],"question_text":"Your company pushes batches of sensitive transaction data from its application server VMs to Cloud Pub/Sub for processing and storage. What is the Google- recommended way for your application to authenticate to the required Google Cloud services?"}],"exam":{"lastUpdated":"11 Apr 2025","name":"Professional Cloud Architect","isImplemented":true,"isMCOnly":false,"id":4,"provider":"Google","numberOfQuestions":279,"isBeta":false},"currentPage":35},"__N_SSP":true}