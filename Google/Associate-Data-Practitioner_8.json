{"pageProps":{"questions":[{"id":"0iCgwo8XRCcOhyyDA1zG","isMC":true,"answer":"A","choices":{"B":"Create a Cloud Data Fusion instance and configure Pub/Sub as a source. Use Data Fusion to process the Pub/Sub messages, perform transformations, and write the results to BigQuery.","A":"Use a Google-provided Dataflow template to process the Pub/Sub messages, perform transformations, and write the results to BigQuery.","D":"Use Cloud Run functions to process the Pub/Sub messages, perform transformations, and write the results to BigQuery.","C":"Load the data from Pub/Sub into Cloud Storage using a Cloud Storage subscription. Create a Dataproc cluster, use PySpark to perform transformations in Cloud Storage, and write the results to BigQuery."},"answer_ET":"A","answers_community":["A (100%)"],"unix_timestamp":1740671880,"question_id":36,"question_images":[],"discussion":[{"timestamp":"1741443480.0","poster":"n2183712847","upvote_count":"1","content":"Selected Answer: A\ndataflow is real-time","comment_id":"1366594"},{"comment_id":"1362595","upvote_count":"1","content":"Selected Answer: A\nThe best solution to minimize development time while implementing near real-time analytics for high-volume Pub/Sub events with transformations and BigQuery loading is A. Use a Google-provided Dataflow template. Dataflow templates offer pre-built, optimized pipelines, drastically reducing development effort and time. Option B, Cloud Data Fusion, is a good visual alternative, but might require slightly more initial setup than deploying a template. Option C, Dataproc and PySpark, is significantly more complex and time-consuming. Option D, Cloud Run functions, while serverless, can become less manageable and more development effort for complex, high-volume streaming pipelines compared to dedicated pipeline services. Therefore, Option A is the most efficient and fastest path to implementation.","timestamp":"1740671880.0","poster":"n2183712847"}],"answer_images":[],"answer_description":"","question_text":"Your organization needs to implement near real-time analytics for thousands of events arriving each second in Pub/Sub. The incoming messages require transformations. You need to configure a pipeline that processes, transforms, and loads the data into BigQuery while minimizing development time. What should you do?","url":"https://www.examtopics.com/discussions/google/view/157210-exam-associate-data-practitioner-topic-1-question-41/","exam_id":2,"topic":"1","timestamp":"2025-02-27 16:58:00"},{"id":"xJH4t5zmpqa8qsj0QCkD","answers_community":["A (100%)"],"isMC":true,"question_images":[],"timestamp":"2025-02-27 16:57:00","answer_images":[],"question_text":"Your organization needs to store historical customer order data. The data will only be accessed once a month for analysis and must be readily available within a few seconds when it is accessed. You need to choose a storage class that minimizes storage costs while ensuring that the data can be retrieved quickly. What should you do?","url":"https://www.examtopics.com/discussions/google/view/157209-exam-associate-data-practitioner-topic-1-question-42/","topic":"1","exam_id":2,"discussion":[{"timestamp":"1741443540.0","poster":"n2183712847","comment_id":"1366595","upvote_count":"1","content":"Selected Answer: A\nstandard - multiple times a month\nnearline - once a month\ncoldline - once 3 months\narchive - once 1 year"},{"comment_id":"1362593","upvote_count":"1","poster":"n2183712847","content":"Selected Answer: A\nThe best option is A. Store the data in Cloud Storage using Nearline storage. Nearline provides the optimal balance of minimizing storage costs while ensuring data is readily available within a few seconds when accessed monthly. Coldline (B) is cheaper storage but has higher latency and retrieval costs, potentially making it slightly slower and more expensive for monthly access. Standard (C) is too expensive for infrequently accessed data. Archive (D) is far too slow for \"seconds\" retrieval, with latency in hours. Therefore, Nearline is the most suitable choice for balancing cost and performance for this specific use case.","timestamp":"1740671820.0"}],"question_id":37,"answer":"A","choices":{"A":"Store the data in Cloud Storage using Nearline storage.","B":"Store the data in Cloud Storage using Coldline storage.","D":"Store the data in Cloud Storage using Archive storage.","C":"Store the data in Cloud Storage using Standard storage."},"answer_ET":"A","unix_timestamp":1740671820,"answer_description":""},{"id":"SBvDIZx4665dSfICCVq0","question_images":[],"question_text":"You have a Dataflow pipeline that processes website traffic logs stored in Cloud Storage and writes the processed data to BigQuery. You noticed that the pipeline is failing intermittently. You need to troubleshoot the issue. What should you do?","answer_images":[],"unix_timestamp":1739605740,"question_id":38,"timestamp":"2025-02-15 08:49:00","discussion":[{"poster":"n2183712847","content":"Selected Answer: C\nC. looks into logs of pipeline / dataflow workers","comment_id":"1366596","timestamp":"1741443600.0","upvote_count":"1"},{"timestamp":"1740671700.0","content":"Selected Answer: C\nThe best approach for troubleshooting intermittent Dataflow pipeline failures is C. Use Cloud Logging to view error messages and Cloud Monitoring to analyze pipeline metrics. This is most effective because Cloud Logging error messages pinpoint what is failing, while Cloud Monitoring metrics reveal why, often due to resource issues. Option A is less detailed and comprehensive. Option B is less targeted and its validation approach is unclear. Option D is inefficient and Cloud Profiler is less suited for general failure diagnosis compared to pipeline metrics and logs.","comment_id":"1362591","upvote_count":"1","poster":"n2183712847"}],"answers_community":["C (100%)"],"isMC":true,"answer":"C","exam_id":2,"url":"https://www.examtopics.com/discussions/google/view/156535-exam-associate-data-practitioner-topic-1-question-43/","answer_ET":"C","answer_description":"","topic":"1","choices":{"D":"Use the Dataflow job monitoring interface to check the pipeline's status every hour. Use Cloud Profiler to analyze the pipeline’s metrics, such as CPU utilization and memory usage.","C":"Use Cloud Logging to view error messages in the pipeline's logs. Use Cloud Monitoring to analyze the pipeline's metrics, such as CPU utilization and memory usage.","B":"Use Cloud Logging to create a chart displaying the pipeline’s error logs. Use Metrics Explorer to validate the findings from the chart.","A":"Use Cloud Logging to identify error groups in the pipeline's logs. Use Cloud Monitoring to create a dashboard that tracks the number of errors in each group."}},{"id":"3ZlYNmqLO0fyP6SsfhuT","answer_ET":"D","answer_images":[],"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/157207-exam-associate-data-practitioner-topic-1-question-44/","answer_description":"","question_text":"Your organization’s business analysts require near real-time access to streaming data. However, they are reporting that their dashboard queries are loading slowly. After investigating BigQuery query performance, you discover the slow dashboard queries perform several joins and aggregations.\nYou need to improve the dashboard loading time and ensure that the dashboard data is as up-to-date as possible. What should you do?","timestamp":"2025-02-27 16:26:00","answers_community":["D (100%)"],"topic":"1","discussion":[{"content":"Selected Answer: D\nMaterialized views automatically update when the underlying base tables change.","upvote_count":"1","comment_id":"1402200","timestamp":"1742722440.0","poster":"Rio55"},{"comment_id":"1362585","upvote_count":"1","poster":"n2183712847","content":"Selected Answer: D\nD. to improve load time, use materialized views for bigquery","timestamp":"1740669960.0"}],"isMC":true,"choices":{"C":"Create a scheduled query to calculate and store intermediate results.","A":"Disable BigQuery query result caching.","B":"Modify the schema to use parameterized data types.","D":"Create materialized views."},"answer":"D","unix_timestamp":1740669960,"exam_id":2,"question_id":39},{"id":"G0dcrVQ7X6JXSzid5Jyn","question_id":40,"exam_id":2,"answers_community":["A (100%)"],"answer_ET":"A","question_text":"You need to create a data pipeline that streams event information from applications in multiple Google Cloud regions into BigQuery for near real-time analysis. The data requires transformation before loading. You want to create the pipeline using a visual interface. What should you do?","answer":"A","topic":"1","answer_description":"","isMC":true,"choices":{"B":"Push event information to a Pub/Sub topic. Create a Cloud Run function to subscribe to the Pub/Sub topic, apply transformations, and insert the data into BigQuery.","C":"Push event information to a Pub/Sub topic. Create a BigQuery subscription in Pub/Sub.","D":"Push event information to Cloud Storage, and create an external table in BigQuery. Create a BigQuery scheduled job that executes once each day to apply transformations.","A":"Push event information to a Pub/Sub topic. Create a Dataflow job using the Dataflow job builder."},"url":"https://www.examtopics.com/discussions/google/view/157206-exam-associate-data-practitioner-topic-1-question-45/","discussion":[{"upvote_count":"1","comment_id":"1366597","content":"Selected Answer: A\ndataflow job builder is visual & dataflow is real-time","timestamp":"1741443660.0","poster":"n2183712847"},{"comment_id":"1362584","timestamp":"1740669900.0","poster":"n2183712847","content":"Selected Answer: A\nThe best solution is A. Push event information to a Pub/Sub topic. Create a Dataflow job using the Dataflow job builder. This is because it directly addresses all requirements: streaming data from multiple regions using Pub/Sub, transformations within Dataflow, near real-time analysis with Dataflow streaming pipelines, and a visual interface using the Dataflow Job Builder. Option B (Cloud Run) is less ideal for robust streaming pipelines and visual creation. Option C (BigQuery Subscription) lacks data transformation. Option D (Cloud Storage/Scheduled Job) is a batch, daily process, not near real-time streaming.","upvote_count":"1"}],"question_images":[],"timestamp":"2025-02-27 16:25:00","unix_timestamp":1740669900,"answer_images":[]}],"exam":{"id":2,"lastUpdated":"11 Apr 2025","isBeta":false,"isMCOnly":true,"isImplemented":true,"name":"Associate Data Practitioner","numberOfQuestions":72,"provider":"Google"},"currentPage":8},"__N_SSP":true}