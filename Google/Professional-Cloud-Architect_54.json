{"pageProps":{"questions":[{"id":"JHye6vI5hNbalwV03awY","question_id":266,"answer_images":[],"question_images":[],"topic":"8","exam_id":4,"answer_description":"","timestamp":"2019-12-30 12:20:00","url":"https://www.examtopics.com/discussions/google/view/11085-exam-professional-cloud-architect-topic-8-question-2/","unix_timestamp":1577704800,"answer":"A","discussion":[{"upvote_count":"32","timestamp":"1580016360.0","comment_id":"42768","poster":"kvokka","content":"agree with A"},{"upvote_count":"13","content":"Google offers Cloud Endpoint to develop, deploy and manage APIs on any google cloud backend. \nhttps://cloud.google.com/endpoints\n\nWith Endpoints Frameworks, you don't have to deploy a third-party web server (such as Apache Tomcat or Gunicorn) with your application. You annotate or decorate the code and deploy your application as you normally would to the App Engine standard environment.\n\nCloud Endpoints Frameworks for the App Engine standard environment : https://cloud.google.com/endpoints/docs/frameworks/about-cloud-endpoints-frameworks","comment_id":"305154","timestamp":"1615126740.0","poster":"Vika"},{"comment_id":"1244425","content":"In any question where it says developer efforts need priority over operations costs or the cost of anything other effort, the answer is always app engine, if it is one of the options.","poster":"Sephethus","timestamp":"1720450620.0","upvote_count":"2"},{"content":"Not sure why these questions are using the term Google Container Engine instead of Google Kubernetes Engine. That is so confusing","timestamp":"1675539120.0","comments":[{"upvote_count":"1","timestamp":"1678545840.0","content":"These are old questions where GKE was named Google Container Engine","poster":"n_nana","comment_id":"836158"}],"poster":"VSMu","comment_id":"798297","upvote_count":"3"},{"timestamp":"1670088420.0","poster":"KyubiBlaze","comment_id":"734597","content":"Why you don't go for C, is cuz for partners, global speed will not be relevant. You can still serve globally via app engine","upvote_count":"1"},{"upvote_count":"1","content":"Selected Answer: A\nok for A","timestamp":"1667656080.0","poster":"megumin","comment_id":"711785"},{"upvote_count":"1","poster":"Mahmoud_E","comment_id":"700302","content":"Selected Answer: A\nA correct answer","timestamp":"1666300020.0"},{"comment_id":"626775","timestamp":"1656900000.0","upvote_count":"2","poster":"AzureDP900","content":"Before even reading discussions I am fixed with my answer as A and everyone said same."},{"timestamp":"1652628060.0","content":"Selected Answer: A\nWe should choose google components only. Here GCP Endpoint does the job so A.","upvote_count":"3","poster":"amxexam","comment_id":"602155"},{"timestamp":"1650633360.0","comment_id":"590004","poster":"Nick89GR","upvote_count":"1","content":"Selected Answer: A\nDefinetely A"},{"timestamp":"1639594920.0","comment_id":"502433","upvote_count":"1","poster":"cdcollector","content":"Selected Answer: C\nOAS adoption rules out framework development. Endpoints is only for indirection of the API and configuring other services which was not part of the question","comments":[{"poster":"cyqgz_36","comment_id":"517683","content":"API should be partner and dealer facing, not public as per BR","upvote_count":"1","timestamp":"1641403140.0"}]},{"comments":[{"comments":[{"upvote_count":"3","poster":"vartiklis","comment_id":"503337","content":"The previous question deals with analysis. This question focuses on creating an API for dealers and partners","timestamp":"1639713060.0"}],"content":"Sorry typo there.. previous question answer is Container Engine while here we talk about App Engine. how come ?","timestamp":"1639288680.0","comment_id":"499814","poster":"Knerd","upvote_count":"2"}],"upvote_count":"2","poster":"Knerd","timestamp":"1639288620.0","comment_id":"499811","content":"If this is A then how come the previous question answer is B (Container Engine) ?"},{"poster":"vincy2202","timestamp":"1639140060.0","upvote_count":"1","comment_id":"498621","content":"Selected Answer: A\nA is the correct answer"},{"poster":"joe2211","timestamp":"1637996820.0","content":"Selected Answer: A\nvote A","upvote_count":"2","comment_id":"487918"},{"poster":"kopper2019","upvote_count":"2","timestamp":"1626315300.0","comment_id":"406667","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152"},{"poster":"victory108","timestamp":"1626241140.0","upvote_count":"2","comment_id":"405963","content":"A. Use Google App Engine with Google Cloud Endpoints. Focus on an API for dealers and partners"},{"upvote_count":"4","content":"Answer is A","timestamp":"1625678340.0","poster":"MamthaSJ","comment_id":"401126"},{"timestamp":"1617280980.0","content":"Answer is A","upvote_count":"2","comment_id":"325822","poster":"Ausias18"},{"timestamp":"1612145400.0","comment_id":"280916","upvote_count":"2","content":"https://cloud.google.com/endpoints/docs/frameworks/about-cloud-endpoints-frameworks\nThere is a specific document for App Engine plus Cloud API Framework.","poster":"bnlcnd"},{"timestamp":"1607808000.0","poster":"OSNG","comment_id":"242023","content":"I think its C. A is not correct as it does not fulfil the Business requirements (Have the ability to partner with different companies \"\" especially with seed and fertilizer suppliers in the fast-growing agricultural business \"\" to create compelling joint offerings for their customers.) and requirements in question (You want the development team to focus their development effort on business value versus creating a custom framework).","upvote_count":"2"},{"content":"A is the right answer","comment_id":"223079","timestamp":"1605819480.0","upvote_count":"2","poster":"Chonny"},{"poster":"AdityaGupta","upvote_count":"3","content":"I agree with explanation and answer A.","timestamp":"1603913820.0","comment_id":"208056"},{"poster":"AshokC","comment_id":"184436","upvote_count":"2","content":"A is correct","timestamp":"1600780680.0"},{"poster":"AshokC","timestamp":"1600459140.0","content":"A is correct","comment_id":"181965","upvote_count":"2"},{"timestamp":"1598433360.0","content":"A makes sense","poster":"wiqi","comment_id":"166582","upvote_count":"1"},{"comment_id":"143544","content":"Agree with A","poster":"OnomeOkuma","timestamp":"1595694240.0","upvote_count":"2"},{"poster":"mlantonis","timestamp":"1592984340.0","content":"Cloud Endpoints is a fine solution.\n\nA is the correct","comment_id":"118206","upvote_count":"2"},{"timestamp":"1591966620.0","comment_id":"108702","content":"A, for sure.\nUse Google App Engine with Google Cloud Endpoints. Focus on an API for dealers and partners","upvote_count":"3","poster":"gfhbox0083"},{"comment_id":"104028","content":"A is the correct answer for me","timestamp":"1591467180.0","poster":"Ziegler","upvote_count":"4"},{"timestamp":"1590674040.0","poster":"AD2AD4","upvote_count":"1","content":"Final Decision to go with Option A","comment_id":"97605"},{"upvote_count":"1","content":"Why C is not correct.","comments":[{"poster":"rehma017","upvote_count":"3","content":"Cloud Endpoints gives you the tools you need for every phase of API development and provides insight with Cloud Logging, Cloud Monitoring, and Cloud Trace - can follow OpenAPI spec, and furthermore, focus on giving customer data dealers.","timestamp":"1591717680.0","comment_id":"106094"}],"timestamp":"1589672040.0","poster":"Jack_in_Large","comment_id":"90219"},{"content":"App engine will provide end url. Why we need to configure end points?","comments":[{"content":"Just do A.","upvote_count":"1","poster":"nitinz","comment_id":"303887","timestamp":"1614914400.0"},{"upvote_count":"5","poster":"Ayzen","content":"Google Cloud Endpoints allows you to define specifications of your APIs (like swagger). This means you'll be able to distribute your \"end url\" packed with documentation. Also Endpoints have some auth capabilities.","timestamp":"1587976380.0","comment_id":"80242","comments":[{"timestamp":"1597125060.0","upvote_count":"8","comment_id":"155131","poster":"tartar","content":"A is ok"},{"content":"C can be eliminatet because it states \"Focus on an API for the public\". There is no requirement for an APIfor the public.","timestamp":"1600931640.0","comment_id":"185944","poster":"Bolek","upvote_count":"2"}]}],"comment_id":"33729","poster":"MJK","timestamp":"1577704800.0","upvote_count":"1"}],"answers_community":["A (90%)","10%"],"answer_ET":"A","question_text":"The TerramEarth development team wants to create an API to meet the company's business requirements. You want the development team to focus their development effort on business value versus creating a custom framework.\nWhich method should they use?","choices":{"C":"Use Google App Engine with the Swagger (Open API Specification) framework. Focus on an API for the public","E":"Use Google Container Engine with a Tomcat container with the Swagger (Open API Specification) framework. Focus on an API for dealers and partners","D":"Use Google Container Engine with a Django Python container. Focus on an API for the public","B":"Use Google App Engine with a JAX-RS Jersey Java-based framework. Focus on an API for the public","A":"Use Google App Engine with Google Cloud Endpoints. Focus on an API for dealers and partners"},"isMC":true},{"id":"fQD9MvkUJA4s4K6c1tDI","question_id":267,"discussion":[{"timestamp":"1701439500.0","upvote_count":"46","comments":[{"comment_id":"653328","poster":"huyhoang8344","content":"SAML can do both authentication and authorization If I am not mistaken\nBut agree A should be the answer","timestamp":"1724914200.0","upvote_count":"2"}],"comment_id":"491702","poster":"ravisar","content":"SAML is an authentication system. \nOAuth is an authorization system. \n\nBoth can be used with SSO (Single sign on). SAML is for users and OAuth is more for applications.\nAnswer A"},{"upvote_count":"26","timestamp":"1653746580.0","poster":"AD2AD4","content":"Final Decision to go with Option A.\nRefer - https://cloud.google.com/docs/authentication\nGood Read - https://cloud.google.com/blog/products/identity-security/identity-and-authentication-the-google-cloud-way","comment_id":"97610"},{"poster":"megumin","timestamp":"1730814660.0","content":"Selected Answer: A\nok for A","comment_id":"711789","upvote_count":"1"},{"timestamp":"1726668540.0","comment_id":"672437","content":"Selected Answer: A\nDelegate application authorization with OAuth2","poster":"Nirca","upvote_count":"1"},{"comment_id":"626778","upvote_count":"2","poster":"AzureDP900","content":"OAuth Authorization is right. A is right!","timestamp":"1720058520.0"},{"content":"Selected Answer: A\nA is correct","timestamp":"1701709080.0","poster":"pakilodi","upvote_count":"2","comment_id":"493821"},{"content":"Selected Answer: A\nvote A","poster":"joe2211","comment_id":"487920","timestamp":"1701069000.0","upvote_count":"2"},{"upvote_count":"1","timestamp":"1698142560.0","poster":"MaxNRG","comment_id":"466908","content":"A – O-Auth 2 access to system (clients would use APIs) https://cloud.google.com/docs/authentication/end-user\nB – SAML 2.0 is redundant, not in requirements."},{"upvote_count":"3","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","timestamp":"1689387240.0","comment_id":"406658","poster":"kopper2019"},{"content":"A. Build or leverage an OAuth-compatible access control system","comment_id":"406005","poster":"victory108","timestamp":"1689315540.0","upvote_count":"1"},{"poster":"MamthaSJ","content":"Answer is A","upvote_count":"2","comment_id":"401128","timestamp":"1688750400.0"},{"timestamp":"1681815960.0","poster":"wzh5831","comment_id":"338132","upvote_count":"1","content":"just query why there is not option for service account...","comments":[{"content":"Because OAuth 2.0 already take in count such flows (client credentials, that is service-to-service communication, meaning service accounts).","comment_id":"417094","timestamp":"1690674000.0","upvote_count":"1","poster":"poseidon24"}]},{"comment_id":"325825","poster":"Ausias18","content":"Answer is A","timestamp":"1680353160.0","upvote_count":"1"},{"content":"A is good, they need auth not aunthentication.","timestamp":"1677895920.0","comment_id":"303006","poster":"nitinz","upvote_count":"2"},{"content":"ANS: A\nCHECK THIS LINK : https://developers.google.com/identity/protocols/oauth2/service-account","upvote_count":"4","comment_id":"286129","timestamp":"1675854060.0","poster":"ahmedemad3"},{"content":"SAML is mostly for Single Sign On. O-Auth is better for delegation.","upvote_count":"4","poster":"bnlcnd","comment_id":"280918","timestamp":"1675217520.0"},{"content":"A is correct","poster":"AshokC","comment_id":"184468","timestamp":"1663854360.0","upvote_count":"2"},{"content":"A is correct.","poster":"wiqi","upvote_count":"1","timestamp":"1661505420.0","comment_id":"166583"},{"poster":"lvergara","timestamp":"1656461640.0","upvote_count":"3","content":"Option A I think, delegated is the key here, OAuth and a token for access the API.","comment_id":"122312"},{"poster":"mlantonis","upvote_count":"3","comment_id":"118208","content":"No mention for SSO, so probably A is the best answer.","timestamp":"1656056460.0"},{"timestamp":"1655038680.0","upvote_count":"4","content":"A, for sure.\nOAuth-compatible access control, for Authorization.","poster":"gfhbox0083","comment_id":"108703"},{"content":"A is the correct answer for me","poster":"Ziegler","comment_id":"104030","timestamp":"1654539300.0","upvote_count":"3"},{"poster":"MJK","upvote_count":"4","timestamp":"1640863380.0","content":"A would be good","comment_id":"33730"},{"content":"Can some one confirm correct answer is A or B ?","poster":"Ramrao14","upvote_count":"1","timestamp":"1638306060.0","comment_id":"25535","comments":[{"timestamp":"1651048560.0","upvote_count":"5","comment_id":"80244","poster":"Ayzen","content":"A. They don't need Single Sign-On.","comments":[{"poster":"tartar","upvote_count":"8","comment_id":"155133","content":"A is ok","timestamp":"1660197180.0"}]},{"poster":"MaxNRG","comment_id":"466910","timestamp":"1698142620.0","upvote_count":"1","content":"A – O-Auth 2 access to system (clients would use APIs) https://cloud.google.com/docs/authentication/end-user\nB – SAML 2.0 is redundant, not in requirements."},{"timestamp":"1677986460.0","content":"A is correct","upvote_count":"2","comment_id":"303891","poster":"nitinz"}]}],"exam_id":4,"url":"https://www.examtopics.com/discussions/google/view/9449-exam-professional-cloud-architect-topic-8-question-3/","question_text":"Your development team has created a structured API to retrieve vehicle data. They want to allow third parties to develop tools for dealerships that use this vehicle event data. You want to support delegated authorization against this data.\nWhat should you do?","answer_ET":"A","answers_community":["A (100%)"],"answer_images":[],"choices":{"B":"Build SAML 2.0 SSO compatibility into your authentication system","C":"Restrict data access based on the source IP address of the partner systems","D":"Create secondary credentials for each dealer that can be given to the trusted third party","A":"Build or leverage an OAuth-compatible access control system"},"answer_description":"","isMC":true,"timestamp":"2019-11-30 22:01:00","question_images":[],"topic":"8","answer":"A","unix_timestamp":1575147660},{"id":"3IBL08JHv9VvKW9ON4AK","exam_id":4,"answer_images":[],"unix_timestamp":1571196240,"question_text":"TerramEarth plans to connect all 20 million vehicles in the field to the cloud. This increases the volume to 20 million 600 byte records a second for 40 TB an hour.\nHow should you design the data ingestion?","url":"https://www.examtopics.com/discussions/google/view/6657-exam-professional-cloud-architect-topic-8-question-4/","isMC":true,"answer_ET":"B","timestamp":"2019-10-16 05:24:00","topic":"8","answers_community":["B (65%)","A (25%)","5%"],"question_id":268,"answer":"B","discussion":[{"comments":[{"timestamp":"1623924900.0","comment_id":"384099","content":"Too much for pubsub either https://cloud.google.com/pubsub/quotas","upvote_count":"4","poster":"alexspam88","comments":[{"comment_id":"458399","poster":"Bill831231","upvote_count":"7","content":"thanks for sharing the link, but seems pub/sub can handle more streaming data than bigquery. pub/sub 120,000,000 kB per minute (2 GB/s) in large regions, bigquery is 1GB/s","timestamp":"1633544340.0"}]}],"poster":"jcmoranp","comment_id":"17536","content":"It's Pub/Sub, too much data streaming for Bigquery...","upvote_count":"41","timestamp":"1572083700.0"},{"upvote_count":"20","content":"Its B, it exceeds the streaming limit for BQ","poster":"JoeShmoe","timestamp":"1573809660.0","comment_id":"21722"},{"upvote_count":"1","timestamp":"1738319100.0","comment_id":"1349469","content":"Selected Answer: D\nI think the answers to this question are outdated. Regarding https://cloud.google.com/architecture/connected-devices the correct answer is \"MQTT Broker\" or \"IoT Platform\". Google recommends \"direct to Pub/Sub\" only if the number of devices (here vehicles) is in the Hundreds.","poster":"user263263"},{"content":"Has to be pub-sub, you have remote vehicles and need to guarantee message delivery.","poster":"VegasDegenerate","upvote_count":"1","timestamp":"1720097160.0","comment_id":"1242075"},{"comment_id":"1192694","content":"Wow its almost like GCP shouldnt have offloaded their IoT Core product - you cant \"Write direct to PubSub\".\nIts the correct answer but its overly simplified\nWriting directly to GCS will cost a fortune to retrieve in GET requests etc","poster":"the1dv","upvote_count":"2","timestamp":"1712723580.0"},{"comment_id":"1108278","timestamp":"1703819880.0","content":"Selected Answer: C\nStreamed data is available for real-time analysis within a few seconds of the first streaming insertion into a table.\nInstead of using a job to load data into BigQuery, you can choose to stream your data into BigQuery one record at a time by using the tabledata().insertAll() method. This approach enables querying data without the delay of running a load job.\nReferences: https://cloud.google.com/bigquery/streaming-data-into-bigquery","poster":"Vesta1807","upvote_count":"1"},{"content":"Selected Answer: A\nThey are sending files through FTP why everyone is missing this point? The max message size in pub sub is 10MB as I remember, I would keep the files solution and try to roll out updates to direct the upload to GCS","poster":"MahAli","timestamp":"1702430880.0","upvote_count":"5","comment_id":"1095068"},{"upvote_count":"1","poster":"BiddlyBdoyng","comment_id":"927726","timestamp":"1687194360.0","content":"So many people pointing out this breaks the BigQuery quota limit but very few pointing out it also breaks the Pub/Sub quote limit.......... So the answer is either not bound by the quota limit (in which case why not BigQuery) both are wrong and we stick with FTP"},{"upvote_count":"1","comment_id":"908845","content":"Selected Answer: B\nit's B","poster":"kapara","timestamp":"1685303820.0"},{"timestamp":"1674837120.0","comment_id":"789786","poster":"nunopires2001","content":"I know it's B, however the sensors are probably legacy systems, that can not communicate to a pub/sub queue. \nIgnoring how huge is to change or adapta 20 million devices is a mistake.","upvote_count":"3"},{"timestamp":"1672240140.0","content":"To handle the volume of data that TerramEarth plans to ingest, it is recommended to use a scalable and reliable data ingestion solution such as Google Cloud Pub/Sub. With Cloud Pub/Sub, the vehicles can stream data directly to the service, which can handle the high volume of data and provide a buffer to absorb sudden spikes in traffic. The data can then be processed and stored in a data warehouse such as BigQuery for analysis.\n\nOption A (writing data directly to GCS) may not be suitable for handling high volumes of data in real-time and may result in data loss if the volume exceeds the capacity of GCS.\nOption C (streaming data directly to BigQuery) may not be suitable for handling high volumes of data in real-time as it may result in data loss or ingestion delays.\nOption D (continuing to write data using the existing system) may not be suitable as the current system may not be able to handle the increased volume of data and may result in data loss or ingestion delays.","upvote_count":"11","comment_id":"759991","poster":"omermahgoub","comments":[{"upvote_count":"1","timestamp":"1672320660.0","content":"correct. thanks for the explanation","poster":"sank8","comment_id":"761058"}]},{"comment_id":"747999","upvote_count":"1","poster":"surajkrishnamurthy","timestamp":"1671274620.0","content":"Selected Answer: B\nB is the correct answer"},{"upvote_count":"1","poster":"megumin","comment_id":"711793","timestamp":"1667656380.0","content":"Selected Answer: B\nok for B"},{"timestamp":"1666302780.0","upvote_count":"1","comment_id":"700328","content":"Selected Answer: B\nB is the correct answer, this similar question was in google simple questions","poster":"Mahmoud_E"},{"comment_id":"626779","timestamp":"1656900240.0","content":"B is right!","upvote_count":"2","poster":"AzureDP900"},{"content":"Should be A - see next question on 80% cellular connectivity and Avro format files streamed directly to GCS","timestamp":"1655564280.0","comment_id":"618301","poster":"cdcollector","upvote_count":"2"},{"timestamp":"1652628300.0","poster":"amxexam","comment_id":"602156","content":"Selected Answer: B\nWe need to buffer, the default limit of BigQuery is 100 API calls per second, till now this cannot be changed. Hence we should ease using Pub/Sub so B.","upvote_count":"2"},{"timestamp":"1650645360.0","upvote_count":"1","content":"Selected Answer: B\nYou can request limit increases to use BQ streaming for this load, but why pay to store data before ETL?","comment_id":"590119","poster":"[Removed]"},{"poster":"AWS56","content":"Selected Answer: B\nB is right","timestamp":"1645787880.0","upvote_count":"1","comment_id":"555917"},{"upvote_count":"1","comment_id":"498650","timestamp":"1639142460.0","poster":"vincy2202","content":"Selected Answer: B\nB is the correct answer\nhttps://cloud.google.com/bigquery/quotas#streaming_inserts"},{"content":"Selected Answer: B\nVote B","upvote_count":"2","poster":"pakilodi","comment_id":"493820","timestamp":"1638637080.0"},{"upvote_count":"2","timestamp":"1637997060.0","poster":"joe2211","content":"Selected Answer: B\nvote B","comment_id":"487921"},{"poster":"rottzy","comment_id":"460384","timestamp":"1633930500.0","upvote_count":"2","content":"PubSub it is!"},{"poster":"Ari_GCP","timestamp":"1632488520.0","comment_id":"450898","content":"Streaming data inserts in BQ are not free, also it doesn't seem optimized for writes. Would go with Pub/Sub","upvote_count":"3"},{"timestamp":"1626315300.0","comment_id":"406662","upvote_count":"1","poster":"kopper2019","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152"},{"upvote_count":"2","content":"B. Vehicles write data directly to Google Cloud Pub/Sub","poster":"victory108","timestamp":"1626243300.0","comment_id":"406001"},{"poster":"MamthaSJ","content":"Answer is B","upvote_count":"3","comments":[{"upvote_count":"2","timestamp":"1625917680.0","comment_id":"403317","content":"Can you share link that supports this?","poster":"Priyaahuja"}],"timestamp":"1625678520.0","comment_id":"401132"},{"timestamp":"1621292040.0","comment_id":"359873","upvote_count":"3","content":"Isnt it 20 Million x 600 Bytes per-second? Around 12GB/s? \n\nI think it should be done in batch and not streaming.","poster":"fdotid","comments":[{"timestamp":"1634567940.0","content":"yeah but remember you've got 20 milion different sources, how would you collect those into single batch? each 600b/s is a different vehicle.","comment_id":"464175","upvote_count":"2","poster":"cotam"}]},{"timestamp":"1619015280.0","poster":"Diptiman","upvote_count":"1","content":"pub/sub seems to have limits of 400 MB/s in large regions. https://cloud.google.com/pubsub/quotas#quotas BigQuery streaming without de-duplication seems to provide a quota of 1gbps. Guessing if C should be used after request to increase quotas.","comment_id":"340383"},{"content":"agree with B, but 'directly' seems not good...","upvote_count":"5","poster":"wzh5831","timestamp":"1618744140.0","comment_id":"338135"},{"timestamp":"1617281280.0","comment_id":"325826","poster":"Ausias18","upvote_count":"1","content":"Answer is B"},{"comment_id":"316982","timestamp":"1616403240.0","comments":[{"upvote_count":"3","poster":"lynx256","comment_id":"316993","timestamp":"1616404080.0","content":"Sorry, C is wrong. 20 million records per second exeeds BQ limits. Ref: https://cloud.google.com/bigquery/quotas#streaming_inserts\nI'll go with B."}],"content":"C is Ok.\n\"One example of high volume event logging is event tracking. Suppose you have a mobile app that tracks events. Your app, or mobile servers, could independently record user interactions or system errors and stream them into BigQuery. You could analyze this data to determine overall trends, such as areas of high interaction or problems, and monitor error conditions in real-time.\" - Ref: https://cloud.google.com/bigquery/streaming-data-into-bigquery#high_volume_event_logging","poster":"lynx256","upvote_count":"1"},{"content":"pub/sub","poster":"VenV","upvote_count":"2","comment_id":"311442","timestamp":"1615813740.0"},{"comment_id":"290982","poster":"guid1984","upvote_count":"1","timestamp":"1613394180.0","content":"key here is \"How do you plan data ingestion\" so Cloud PUB/SUB is recommended choice here"},{"upvote_count":"1","content":"ANS: B\nThe limit for BQ is 1 Gb per second or 10000rows per second. Go with pub-sub.","poster":"ahmedemad3","comments":[{"poster":"alexspam88","comment_id":"384101","upvote_count":"3","content":"And we have 20Gb per sec","timestamp":"1623924960.0"}],"timestamp":"1612782180.0","comment_id":"286130"},{"comment_id":"280931","poster":"bnlcnd","upvote_count":"2","timestamp":"1612147200.0","content":"pub/sub should take the injection and stream it to the BQ in the next hop. no matter how big or small the data quantity, BQ should not be injected like this. Some basic isolation between data collection of IoT and analysis should be considered."},{"upvote_count":"1","content":"Ans is B as\nStreaming inserts are limited to 1GB per second which turns out to be 3.6TB an hour whereas we require to insert 40TB an hour, so BigQuery with streaming inserts isn't going to work.","poster":"Chulbul_Pandey","comment_id":"233001","timestamp":"1606915680.0"},{"timestamp":"1605253620.0","upvote_count":"3","comment_id":"218318","poster":"hems4all","content":"B is Correct answer:\n\nAs described in the \"Designing a Connected Vehicle Platform on Cloud IoT Core\" article, Cloud Pub/Sub is a globally scalable message queueing system, making it an excellent choice to handle the streams of vehicle data while at the same time decoupling the specifics of the backend processing implementation.\n\nRef: https://cloud.google.com/solutions/designing-connected-vehicle-platform#data_ingestion"},{"timestamp":"1603914660.0","poster":"AdityaGupta","upvote_count":"5","content":"Firstly Pub/Sub is best suited for data ingestion in this case study, secondly it exceeds the quota of BQ. Do a math: 40TB = 40960 GB / 60 Minutes = 682 Gb /per minutes then 682 GB / 60 second = 11GB per second. So Big query is wrong!!!","comment_id":"208064"},{"timestamp":"1601803860.0","poster":"akhadar2001","upvote_count":"1","comment_id":"192812","content":"correct answer is B since pub/sub works as a shock absorber before the data is fed."},{"timestamp":"1601180520.0","upvote_count":"2","content":"Answer C is trying to do a DDOS on Bigquery...","comment_id":"188103","poster":"VedaSW"},{"upvote_count":"2","timestamp":"1600782420.0","comment_id":"184472","content":"B is the right answer","poster":"AshokC"},{"timestamp":"1598705700.0","content":"B is correct","upvote_count":"1","poster":"Kabiliravi","comment_id":"169261"},{"comments":[{"upvote_count":"1","comment_id":"166591","content":"So answer is B","poster":"wiqi","timestamp":"1598433900.0"}],"comment_id":"166589","content":"It should be either PUB/SUB or IOT Core.","poster":"wiqi","timestamp":"1598433840.0","upvote_count":"1"},{"timestamp":"1598232420.0","comment_id":"164789","upvote_count":"1","poster":"droidmasta","content":"didnt even know about the BQ quotas, its not an ingestion service anyway"},{"upvote_count":"1","poster":"mohit1008","comment_id":"153751","timestamp":"1596984900.0","content":"Any Ingestion system is Asynchronus in nature and should use messaging hence pubsub , the answer should be b"},{"upvote_count":"2","comment_id":"142075","content":"The limit for BQ is 1 gb per second or 10000rows per second. So answer is Go with pub sub.","timestamp":"1595514120.0","poster":"vibhavchavan"},{"timestamp":"1595419380.0","upvote_count":"1","poster":"Alasmindas","content":"Correct answer is Option C.\nStreamed data is available for real-time analysis within a few seconds of the first streaming insertion into a table. Instead of using a job to load data into BigQuery, you can choose to stream your data into BigQuery one record at a time by using the tabledata().insertAll() method. This approach enables querying data without the delay of\nrunning a load job.\n\nI think this question is purposfuly made to confuse us and tempt us to selection Option - B (Cloud Pub/Sub)\n\nThere is no mention anywhere in google doc. that BQ can not or can handle specific amount of streaming data..","comment_id":"141104"},{"upvote_count":"1","timestamp":"1595008200.0","poster":"elnagmy","comment_id":"137377","content":"Big query will not work in this case, only big table and pub/sub can handle this hug streaming data"},{"timestamp":"1593536340.0","content":"See DrLu's description which is correct. The answer is Pub/Sub (B).","poster":"cweather328","upvote_count":"1","comment_id":"123653"},{"timestamp":"1593390300.0","poster":"lvergara","upvote_count":"1","comment_id":"122319","content":"B is correct.\n1- Bigquery is not good for insert however it is good for query jobs.\n2- In a flow like this, behind the DB almost always is a broker o somthing like this. So pub/sub."},{"poster":"mlantonis","upvote_count":"1","timestamp":"1592985000.0","comment_id":"118217","content":"It is not good to write directly to BigQuery and probably the streaming inserts are beyond the Quotas.\n\nI would choose Pub/Sub, so B is the correct."},{"comment_id":"108704","content":"B, for sure.\nAs BigQuery's maximum rows per second per project quota = 1GB/sec","upvote_count":"1","timestamp":"1591966740.0","poster":"gfhbox0083"},{"timestamp":"1591695480.0","content":"Answer is B.\nDesign should decouple the systems using Pub/Sub.","comment_id":"105838","upvote_count":"1","poster":"Rajuuu"},{"comment_id":"104033","content":"B is the correct answer. pub/sub will stream and also decouple the message","timestamp":"1591467840.0","upvote_count":"2","poster":"Ziegler"},{"comment_id":"97612","content":"Final Decision to go with Option B","upvote_count":"3","poster":"AD2AD4","timestamp":"1590674700.0"},{"upvote_count":"1","comment_id":"90768","content":"Bigquery can't handle the throughput\n- If you don’t populate insertId: 1GB/sec\n- Maximum rows per second: 100,000","timestamp":"1589738700.0","poster":"Jack_in_Large"},{"timestamp":"1589139300.0","poster":"GCP_Azure","upvote_count":"1","comment_id":"86716","content":"Think its B. Cloud Pub/Sub is a globally scalable message queueing system, making it an excellent choice to handle the streams of vehicle data while at the same time decoupling the specifics of the backend processing implementation.BigQuery provides the powerful analytics engine for the usage-based insurance application and for out-of-band system analytics"},{"content":"Answer D,","poster":"anton_royce","timestamp":"1585986720.0","comments":[{"comment_id":"70961","poster":"anton_royce","timestamp":"1585986960.0","upvote_count":"3","content":"Sorry, Answer B"}],"comment_id":"70958","upvote_count":"1"},{"timestamp":"1579142280.0","comment_id":"39590","poster":"san19","upvote_count":"1","content":"B: (Correct answer) - Vehicles write data directly to Google Cloud Pub/Sub - Pub/Sub is acting as 'shock absorber', allowing asynchronous messaging between large numbers of devices."},{"poster":"MrBog1","content":"B , to directly write stream data to a dataware house is not a good practice","timestamp":"1577270280.0","comment_id":"32563","upvote_count":"3"},{"comment_id":"30729","timestamp":"1576693680.0","content":"I'd go B. Even if they didn't hit the quota for streaming inserts, batch is better. So I'd go PubSub to maybe BigTable, and then have some other job process the data needed for BigQuery","upvote_count":"2","poster":"elguando"},{"content":"answer is B.\nIngest: The first stage is to pull in the raw data, such as streaming data from devices, on-premises batch data, app logs, or mobile-app user events and analytics.\nIngest include App Engine, Compute Engine, Kubernetes Engine, Cloud Pub/Sub, Stackdriver Logging, Cloud Transfer Service, Transfer Application. \nThis case match Pub/Sub\nhttps://cloud.google.com/solutions/data-lifecycle-cloud-platform","poster":"JJu","upvote_count":"5","timestamp":"1575445380.0","comment_id":"26517"},{"content":"Answer is B. Refer here\nhttps://cloud.google.com/solutions/designing-connected-vehicle-platform","poster":"shandy","comments":[{"upvote_count":"1","poster":"cetanx","timestamp":"1594202340.0","comment_id":"129628","content":"I agree...\nhttps://cloud.google.com/solutions/designing-connected-vehicle-platform#data_ingestion"}],"comment_id":"24741","timestamp":"1574822880.0","upvote_count":"8"},{"comments":[{"content":"Do a math : 40TB = 40960 GB / 60 Minutes = 682 Gb /per minutes then 682 GB / 60 second = 11GB persecond. So Big query is wrong!!!","upvote_count":"4","poster":"DrLu","timestamp":"1575563580.0","comment_id":"26932"}],"comment_id":"18196","timestamp":"1572364200.0","upvote_count":"2","poster":"Eroc","content":"The quota is only 1,000,000 rows per second if you populate the insertId field. The requirements don't require that so the quota is st at 1 GB per second. The question says it is only 600 bytes a second. C works."},{"poster":"MeasService","comment_id":"16019","comments":[{"timestamp":"1575563640.0","content":"Do a math : 40TB = 40960 GB / 60 Minutes = 682 Gb /per minutes then 682 GB / 60 second = 11GB persecond. So Big query is wrong!!!","poster":"DrLu","comments":[{"upvote_count":"5","content":"100% agree it's pubsub without a shred of doubt.","poster":"cweather328","timestamp":"1593536400.0","comment_id":"123657"},{"upvote_count":"1","comment_id":"305179","timestamp":"1615130940.0","content":"There is a question in Topic5-Q9.\nThe answer is to Push the telemetry data in real-time to a streaming dataflow job that compresses the data, and store it in Google BigQuery.\n\nCan anyone explain why is Pub/Sub (which also has its limit) used in this question, not dataflow + BigQuery?","poster":"HCL"}],"upvote_count":"13","comment_id":"26933"}],"content":"Hmm not convinced, given the option I would still choose answer C as streaming data ingest for the situation","upvote_count":"2","timestamp":"1571475600.0"},{"comments":[{"comments":[{"upvote_count":"8","poster":"tartar","content":"B is ok","timestamp":"1597125360.0","comment_id":"155134"}],"comment_id":"117821","poster":"motty","upvote_count":"2","content":"100% agree. BQ quota is prohibitive","timestamp":"1592943060.0"},{"content":"B, go to PubSub","poster":"nitinz","comment_id":"303893","upvote_count":"1","timestamp":"1614915060.0"}],"comment_id":"15572","timestamp":"1571196240.0","upvote_count":"5","poster":"KouShikyou","content":"It looks like Bigquery doesn't work for this case.\nThere is quto limitation in Bigquery. 20million per second intert exceeds BigQuery's maximum rows per second per project quota.\nhttps://cloud.google.com/bigquery/quotas#streaming_inserts"}],"question_images":[],"choices":{"A":"Vehicles write data directly to GCS","B":"Vehicles write data directly to Google Cloud Pub/Sub","C":"Vehicles stream data directly to Google BigQuery","D":"Vehicles continue to write data using the existing system (FTP)"},"answer_description":""},{"id":"JmQgk9gJMOkQ5Z56e5sv","discussion":[{"content":"C is right choice because using cellular connectivity will greatly improve the freshness of data used for analysis from where it is now, collected when the machines are in for maintenance. Streaming transport instead of periodic FTP will tighten the feedback loop even more. Machine learning is ideal for predictive maintenance workloads.\n\n\nA is not correct because machine learning analysis is a good means toward the end of reducing downtime, but shuffling formats and transport doesn't directly help at all. B is not correct because machine learning analysis is a good means toward the end of reducing downtime, and moving to streaming can improve the freshness of the information in that analysis, but changing the format doesn't directly help at all. D is not correct because machine learning analysis is a good means toward the end of reducing downtime, but the rest of these changes don't directly help at all.","poster":"shandy","comment_id":"24742","timestamp":"1574823420.0","comments":[{"content":"There are 20 million TerramEarth vehicles in operation ... Approximately 200,000 have cellular connectivity. So, you're saying for them to keep cost low, increase cell phone bill from 0.01% connected to 80% connected? Statistical Analysis does not require such a large sample size. C CANNOT BE RIGHT.","poster":"nick_name_1","timestamp":"1677095460.0","comment_id":"818330","comments":[{"content":"It's B.","poster":"nick_name_1","timestamp":"1677095580.0","comment_id":"818334","upvote_count":"5"}],"upvote_count":"5"}],"upvote_count":"36"},{"poster":"MrBog1","upvote_count":"22","content":"A is not correct because machine learning analysis is a good means toward the end of reducing downtime, but shuffling formats and transport doesn't directly help at all.\n\nB is not correct because machine learning analysis is a good means toward the end of reducing downtime, and moving to streaming can improve the freshness of the information in that analysis, but changing the format doesn't directly help at all.\n\nC is correct because using cellular connectivity will greatly improve the freshness of data used for analysis from where it is now, collected when the machines are in for maintenance. Streaming transport instead of periodic FTP will tighten the feedback loop even more. Machine learning is ideal for predictive maintenance workloads.\n\nD is not correct because machine learning analysis is a good means toward the end of reducing downtime, but the rest of these changes don't directly help at all.","comments":[{"timestamp":"1718120520.0","upvote_count":"2","comment_id":"1228513","content":"from PCA samples","poster":"ccpmad"}],"comment_id":"32715","timestamp":"1577342160.0"},{"poster":"user263263","content":"Selected Answer: B\nNot A, D - migrate from FTP to SFTP does not help\nNot C - From the Case Study Solution Concept \"A small subset of critical data is transmitted from the vehicles in real time to facilitate fleet management.\" - so cellular connectivity is already 100%\nB - less latency and volume of data transfer","timestamp":"1738314120.0","upvote_count":"2","comment_id":"1349440"},{"comments":[{"upvote_count":"1","timestamp":"1727329320.0","content":"The other options are less optimal:\n\nA. Migrating to SFTP wouldn't significantly reduce the reporting time because it's still a batch process.\nC. Increasing fleet cellular connectivity may help collect more data, but it doesn't directly address the root issue of reducing reporting time.\n**D. Increasing dealer inventory without addressing the data collection and reporting delays won't optimize the process effectively.","comment_id":"1289299","poster":"JohnJamesB1212"}],"upvote_count":"1","poster":"JohnJamesB1212","comment_id":"1289298","content":"Selected Answer: B\nB. Migrate from FTP to streaming transport, migrate from CSV to binary format, and develop machine learning analysis of metrics.\n\nHere's why:\n\nMigrating from FTP to streaming transport (e.g., using Google Cloud Pub/Sub) allows near real-time data transfer, significantly reducing the 3-week delay in reporting by enabling faster data collection and processing.\nMigrating from CSV to binary format improves data efficiency by reducing the size of the data payload, speeding up transfer and processing times.\nDeveloping machine learning analysis of metrics can help predict parts failures and optimize inventory management, further reducing downtime by ensuring that parts are available when needed.","timestamp":"1727329320.0"},{"poster":"e3e79d9","content":"b is slightly better than c because compreessed data will allow the pipe to be expanded. To Increase cell connectivity could overload the streaming process without the needed compression.","timestamp":"1726310520.0","comment_id":"1283596","upvote_count":"1"},{"content":"choosing B because it's gonna use Pub/Sub which is what Google wants in this case.","timestamp":"1726223460.0","comment_id":"1283110","upvote_count":"2","poster":"Rehamss"},{"comment_id":"1234373","poster":"46f094c","timestamp":"1718970180.0","upvote_count":"2","content":"Selected Answer: B\nI don't C as a valid option, cause this might not depend on the company itself, but more on the client side, it will require a big investing and even maybe not possible because of signal reach to remote locations like fields outside of the cities.\nOption B focus on solving what the internal proceses first"},{"upvote_count":"1","comment_id":"1228516","timestamp":"1718120580.0","poster":"ccpmad","content":"Selected Answer: C\nPCA Samples\n\nA is not correct because machine learning analysis is a good means toward the end of reducing downtime, but shuffling formats and transport doesn't directly help at all.\n\nB is not correct because machine learning analysis is a good means toward the end of reducing downtime, and moving to streaming can improve the freshness of the information in that analysis, but changing the format doesn't directly help at all.\n\nC is correct because using cellular connectivity will greatly improve the freshness of data used for analysis from where it is now, collected when the machines are in for maintenance. Streaming transport instead of periodic FTP will tighten the feedback loop even more. Machine learning is ideal for predictive maintenance workloads.\n\nD is not correct because machine learning analysis is a good means toward the end of reducing downtime, but the rest of these changes don't directly help at all."},{"comment_id":"1228023","timestamp":"1718041440.0","poster":"Sephethus","content":"C makes no sense, how are you going to improve cellular connectivity with anything Google has to offer? That's a local carrier thing. B is the answer.","upvote_count":"1"},{"content":"Selected Answer: C\nthis question is from Goolge official PCA samples","upvote_count":"4","timestamp":"1711179960.0","comment_id":"1180691","poster":"erin24330"},{"content":"Selected Answer: B\nAnswer is B. \nC is wrong suggestion, think of cost and time for 80% cellular connection","upvote_count":"1","comment_id":"1163974","timestamp":"1709364720.0","poster":"madcloud32"},{"comment_id":"1127808","timestamp":"1705841340.0","upvote_count":"1","content":"Selected Answer: B\nanswer is B, binary is faster","poster":"35cd41b"},{"upvote_count":"5","timestamp":"1703634720.0","comments":[{"timestamp":"1703634720.0","poster":"e5019c6","upvote_count":"2","content":"The two points of the introductory info referred:\n1. Approximately 200,000 vehicles are connected to a cellular network, allowing TerramEarth to collect data directly. At a rate of 120 fields of data per second with 22 hours of operation per day, Terram Earth collects a total of about 9 TB/day from these connected vehicles.\n2. TerramEarth's existing architecture is composed of Linux-based systems that reside in a data center. These systems gzip CSV files from the field and upload via FTP, transform and aggregate them, and place the data in their data warehouse. Because this process takes time, aggregated reports are based on data that is 3 weeks old.","comment_id":"1106461"}],"content":"Selected Answer: B\nI'm voting B in this one.\nMy take on it is that increasing the cellular connectivity will generate high costs, and is not the main culprit of the 3 weeks delay, that is the problem we are trying to solve.\nThere are two parts of the introductory info that are key\nWe can say that the info we receive is quite fresh, 9TB a day. That makes increasing connectivity not so useful.\nAnd we also see that the main culprit here is the ETL process. Which would be solved migrating to streaming and handling binary format instead of FTP with CSVs.","comment_id":"1106460","poster":"e5019c6"},{"comment_id":"839838","poster":"WinSxS","timestamp":"1678880460.0","content":"Selected Answer: B\nThe most effective way to reduce the 3 weeks aggregate reporting time and achieve the business requirement of reducing downtime would be to migrate from FTP to streaming transport, migrate from CSV to binary format, and develop machine learning analysis of metrics. This would significantly reduce the time it takes to collect and analyze data","upvote_count":"4"},{"poster":"tdotcat","timestamp":"1673921700.0","upvote_count":"4","content":"Selected Answer: B\nbinary format makes faster bigquery write\nhttps://cloud.google.com/bigquery/docs/write-api#advantages","comment_id":"778470"},{"comment_id":"773859","timestamp":"1673553660.0","content":"Selected Answer: C\nA is not correct because machine learning analysis is a good means toward the end of\nreducing downtime, but shuffling formats and transport doesn't directly help at all.\nB is not correct because machine learning analysis is a good means toward the end of\nreducing downtime, and moving to streaming can improve the freshness of the\ninformation in that analysis, but changing the format doesn't directly help at all.\nC is correct because using cellular connectivity will greatly improve the freshness of data\nused for analysis from where it is now, collected when the machines are in for\nmaintenance. Streaming transport instead of periodic FTP will tighten the feedback loop\neven more. Machine learning is ideal for predictive maintenance workloads.\nD is not correct because machine learning analysis is a good means toward the end of\nreducing downtime, but the rest of these changes don't directly help at all.","poster":"foward","upvote_count":"4"},{"timestamp":"1672259940.0","poster":"thamaster","upvote_count":"6","content":"Selected Answer: C\nThis question is in the sample questions from google\nA is not correct because machine learning analysis is a good means toward the end of reducing downtime, but shuffling formats and transport doesn't directly help at all.\n\nB is not correct because machine learning analysis is a good means toward the end of reducing downtime, and moving to streaming can improve the freshness of the information in that analysis, but changing the format doesn't directly help at all.\n\nC is correct because using cellular connectivity will greatly improve the freshness of data used for analysis from where it is now, collected when the machines are in for maintenance. Streaming transport instead of periodic FTP will tighten the feedback loop even more. Machine learning is ideal for predictive maintenance workloads.\n\nD is not correct because machine learning analysis is a good means toward the end of reducing downtime, but the rest of these changes don't directly help at all.","comment_id":"760311"},{"upvote_count":"4","timestamp":"1669569000.0","comment_id":"728464","poster":"Jackalski","content":"Selected Answer: B\ngo for B\nmust go for streaming and faster processing (scalability on binary format)\n\noption C makes no sense as there is no vehicle connectivity problem mentioned (no need to change cellular network)- delay is after data is already received ."},{"poster":"megumin","timestamp":"1667656560.0","comment_id":"711795","content":"Selected Answer: C\nok for C","upvote_count":"2"},{"comment_id":"626782","timestamp":"1656900420.0","upvote_count":"1","poster":"AzureDP900","content":"C is right!"},{"comment_id":"615986","content":"C is the right answer","poster":"omodara","timestamp":"1655167860.0","upvote_count":"1"},{"comment_id":"602160","content":"Selected Answer: C\nI agree B is better than A and D but C is better than B. Hence C","timestamp":"1652628540.0","poster":"amxexam","upvote_count":"2"},{"timestamp":"1641829260.0","comment_id":"520959","poster":"Sekierer","content":"Selected Answer: C\nC is correct, taken from offiical Google practice Test:\n\nOfficial Explaination:\nA is not correct because machine learning analysis is a good means toward the end of reducing downtime, but shuffling formats and transport doesn't directly help at all.\n\nB is not correct because machine learning analysis is a good means toward the end of reducing downtime, and moving to streaming can improve the freshness of the information in that analysis, but changing the format doesn't directly help at all.\n\nC is correct because using cellular connectivity will greatly improve the freshness of data used for analysis from where it is now, collected when the machines are in for maintenance. Streaming transport instead of periodic FTP will tighten the feedback loop even more. Machine learning is ideal for predictive maintenance workloads.\n\nD is not correct because machine learning analysis is a good means toward the end of reducing downtime, but the rest of these changes don't directly help at all.","upvote_count":"7"},{"content":"The commentary on the solution seems to say that B is the correct answer.\nI'm lost in B and C.\nB The speed of the analysis itself will be faster.\nC Waiting time should be reduced by increasing the number of vehicles that can acquire information in real time.","poster":"OrangeTiger","upvote_count":"2","timestamp":"1641791880.0","comment_id":"520659"},{"comment_id":"509337","timestamp":"1640475840.0","comments":[{"upvote_count":"2","timestamp":"1642539840.0","content":"This is sample question on GCP official training documentation. Answer is C.","comment_id":"527011","poster":"hogtrough"}],"upvote_count":"1","poster":"zxcv1234","content":"Selected Answer: B\nNot all vehicles are connected by cellular, C cannot be the answer. B is correct."},{"upvote_count":"2","timestamp":"1638016020.0","poster":"mudot","content":"Selected Answer: C\nA is not correct because machine learning analysis is a good means toward the end of reducing downtime, but shuffling formats and transport doesn't directly help at all.\n\nB is not correct because machine learning analysis is a good means toward the end of reducing downtime, and moving to streaming can improve the freshness of the information in that analysis, but changing the format doesn't directly help at all.\n\nC is correct because using cellular connectivity will greatly improve the freshness of data used for analysis from where it is now, collected when the machines are in for maintenance. Streaming transport instead of periodic FTP will tighten the feedback loop even more. Machine learning is ideal for predictive maintenance workloads.\n\nD is not correct because machine learning analysis is a good means toward the end of reducing downtime, but the rest of these changes don't directly help at all.","comment_id":"488118"},{"content":"Selected Answer: C\nvote C","timestamp":"1637997060.0","upvote_count":"3","comment_id":"487922","poster":"joe2211"},{"upvote_count":"3","content":"A. Incorrect - There is nothing called SFTP Transport\nB. Correct - CSV to Binary make big difference using ML\nC. Incorrect. 80% Connectivity is illogical, It should be 100%\nD. Incorrect . SFTP Transport is illogical","comment_id":"476973","poster":"FERIN_02","timestamp":"1636725540.0"},{"comment_id":"463165","content":"Correct answer is C. \nI don't answer understand why some people have put B. C answer is explained very well on GCP exam. Guys put legitimate and valid answers. Not what I think is right. We are all techies and should have demonstrated right answer based on our knowledge and know-how.\nI don't like this site has many wrong answerS. So who are these misleading experts. Please revist all your wrong answers..","upvote_count":"4","timestamp":"1634400360.0","poster":"[Removed]"},{"poster":"kopper2019","comment_id":"406663","content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","upvote_count":"3","timestamp":"1626315300.0"},{"upvote_count":"2","comment_id":"405999","content":"C. Increase fleet cellular connectivity to 80%, migrate from FTP to streaming transport, and develop machine learning analysis of metrics","poster":"victory108","timestamp":"1626243240.0"},{"comment_id":"401134","poster":"MamthaSJ","upvote_count":"2","content":"Answer is C","timestamp":"1625678520.0"},{"poster":"Yogikant","timestamp":"1622772300.0","comment_id":"374015","comments":[{"content":"I'm agree, B should be the best solution, but Google guys say C...","timestamp":"1659960000.0","upvote_count":"1","poster":"certifiedfra","comment_id":"644092"}],"upvote_count":"4","content":"Answer B:\n\nThis is Google Cloud Exam. They expect you to use their service to solve the problem. Mobile connectivity is not cloud solution. Reason for delay in report to dealers is batch data sending by FTP instead of real-time streaming."},{"poster":"wzh5831","content":"i will go will C, but i still dont understand why increasing fleet cellular connectivity will help. is that means they keeping low utilization of cellular connectivity? and we dont know the current percentage...","timestamp":"1618744620.0","comment_id":"338143","upvote_count":"1"},{"upvote_count":"1","timestamp":"1617281460.0","content":"Answer is C","comment_id":"325829","poster":"Ausias18"},{"comment_id":"323398","upvote_count":"1","poster":"lynx256","content":"C is ok","timestamp":"1617019080.0"},{"content":"I think B is good.\nC want \"Increase fleet cellular connectivity to 80%\". The requirement says the trucks are all connected to cellular network already. what to increase? 80%? Where the number come from? I doubt they can increase the speed of the cellphone network. It not up to the user to increase either the cell network speed or network coverage.","comments":[{"poster":"rbarrote","upvote_count":"2","content":"Only 200,000 of 20 million vehicles are connected by cellular network","timestamp":"1620634860.0","comment_id":"353552"}],"timestamp":"1612147860.0","comment_id":"280941","upvote_count":"2","poster":"bnlcnd"},{"content":"All who are saying C, how you are suppose to stream data without cellular connectivity?\nWhat advantage does cellular connectivity provides over already streaming data?\nOption B seems to be aiming for 100% migration to streaming transport where as option C is only going for 80%","timestamp":"1611922080.0","poster":"manish","comment_id":"279293","upvote_count":"2"},{"content":"People are confused here..They are already using aggregated 3 weeks old data and they intend to use the same window of 3 week here too. They are merely asking what can they do to fasten the analysis process on this 3 weeks old data. So Cellular Connectivity has nothing to do with it.","poster":"Prakzz","timestamp":"1609532220.0","comment_id":"257056","upvote_count":"4"},{"comment_id":"241218","content":"https://cloud.google.com/bigquery/docs/batch-loading-data#loading_compressed_and_uncompressed_data\n\nThe Avro binary format is the preferred format for loading both compressed and uncompressed data. Avro data is faster to load because the data can be read in parallel, even when the data blocks are compressed.","upvote_count":"1","timestamp":"1607720940.0","poster":"ffgcloud"},{"content":"B, definitely. Goal should be 100% cellular connectivity, not only 80%. Convert to binary should be a recommendation, and both B & C answers include ML... https://cloud.google.com/bigquery/docs/loading-data","upvote_count":"3","comment_id":"219409","timestamp":"1605396360.0","poster":"ccie_pgh"},{"content":"I will go with C, This will provide you data much faster than uploading via FTP and ML will give you better predictions for possible vehicle failure or need for replacement parts.","comment_id":"208065","timestamp":"1603914900.0","upvote_count":"3","poster":"AdityaGupta"},{"comment_id":"193783","content":"Why is everyone pretending that they saw \"cellular\" on the Certified Professional Architect syllabus?","poster":"kimberjdaw","upvote_count":"3","timestamp":"1601931240.0"},{"upvote_count":"1","content":"The question is: \"You decided to focus on reduction of the 3 weeks aggregate reporting time\". \n\nSo focus is to optimize the reporting process itself (B). (C) will increase the amount of data by factor 80 (1% vs. 80%) while still leaving it in blown CSV format.\nA and D are ruled out for inproper SFTP protocol.\n\nSo decision is: B","poster":"nerdicbynature","comments":[{"poster":"tucson","content":"its C. Connection will increase data ingestion which will impact on time, CVS to messaging also time improving.","comment_id":"168713","timestamp":"1598644020.0","upvote_count":"1"}],"comment_id":"155236","timestamp":"1597134540.0"},{"poster":"pupi08","comment_id":"124998","timestamp":"1593691740.0","upvote_count":"2","content":"it's C"},{"content":"The question is taken from Google Practice Exam\nA: is not correct because machine learning analysis is a good means toward the end of reducing downtime, but shuffling formats and transport doesn't directly help at all.\nB: is not correct because machine learning analysis is a good means toward the end of reducing downtime, and moving to streaming can improve the freshness of the information in that analysis, but changing the format doesn't directly help at all.\nC: is correct because using cellular connectivity will greatly improve the freshness of data used for analysis from where it is now, collected when the machines are in for maintenance. Streaming transport instead of periodic FTP will tighten the feedback loop even more. Machine learning is ideal for predictive maintenance workloads.\nD: is not correct because machine learning analysis is a good means toward the end of reducing downtime, but the rest of these changes don't directly help at all.","poster":"mlantonis","comment_id":"124767","timestamp":"1593671820.0","upvote_count":"1"},{"comment_id":"107784","poster":"gfhbox0083","content":"C, for sure\nMentioned in Google Exam Practice.","timestamp":"1591882320.0","upvote_count":"2"},{"upvote_count":"2","comment_id":"104036","content":"C is the correct answer for me","poster":"Ziegler","timestamp":"1591467960.0"},{"poster":"Nata4a","upvote_count":"1","timestamp":"1591250880.0","comment_id":"102154","content":"C is correct"},{"timestamp":"1590674820.0","content":"Final Decision to go with Option C","upvote_count":"1","poster":"AD2AD4","comment_id":"97613"},{"upvote_count":"5","comment_id":"63792","content":"C is correct","timestamp":"1584175980.0","poster":"Javed"},{"comment_id":"55362","poster":"deaglee","timestamp":"1582698960.0","upvote_count":"12","content":"The question is in google practice exam, answer is C: Increase fleet cellular connectivity to 80%, migrate from FTP to streaming transport..."},{"timestamp":"1577271420.0","content":"the expanation is for B","upvote_count":"2","comment_id":"32566","poster":"MrBog1"},{"timestamp":"1574253780.0","upvote_count":"4","content":"B is correct","comments":[{"comment_id":"155136","upvote_count":"5","poster":"tartar","content":"C is ok","timestamp":"1597125540.0"},{"poster":"nitinz","comment_id":"303894","upvote_count":"1","timestamp":"1614915180.0","content":"it is C"}],"comment_id":"23017","poster":"VenkatGCP1"}],"question_id":269,"topic":"8","timestamp":"2019-11-20 13:43:00","unix_timestamp":1574253780,"answer_ET":"C","answer_description":"","answer_images":[],"answers_community":["C (55%)","B (45%)"],"isMC":true,"question_text":"You analyzed TerramEarth's business requirement to reduce downtime, and found that they can achieve a majority of time saving by reducing customer's wait time for parts. You decided to focus on reduction of the 3 weeks aggregate reporting time.\nWhich modifications to the company's processes should you recommend?","url":"https://www.examtopics.com/discussions/google/view/8687-exam-professional-cloud-architect-topic-8-question-5/","answer":"C","question_images":[],"exam_id":4,"choices":{"B":"Migrate from FTP to streaming transport, migrate from CSV to binary format, and develop machine learning analysis of metrics","A":"Migrate from CSV to binary format, migrate from FTP to SFTP transport, and develop machine learning analysis of metrics","C":"Increase fleet cellular connectivity to 80%, migrate from FTP to streaming transport, and develop machine learning analysis of metrics","D":"Migrate from FTP to SFTP transport, develop machine learning analysis of metrics, and increase dealer local inventory by a fixed factor"}},{"id":"FM2VcAIsafDRcwZ5uWWB","choices":{"A":"Opex/capex allocation, LAN changes, capacity planning","B":"Capacity planning, TCO calculations, opex/capex allocation","C":"Capacity planning, utilization measurement, data center expansion","D":"Data Center expansion, TCO calculations, utilization measurement"},"answer_images":[],"question_text":"Which of TerramEarth's legacy enterprise processes will experience significant change as a result of increased Google Cloud Platform adoption?","answer_description":"","question_id":270,"isMC":true,"timestamp":"2020-01-17 08:07:00","question_images":[],"answers_community":["B (92%)","8%"],"topic":"8","url":"https://www.examtopics.com/discussions/google/view/12205-exam-professional-cloud-architect-topic-8-question-6/","discussion":[{"timestamp":"1626498420.0","upvote_count":"30","poster":"sri007","content":"Correct Answer B\n\nCapacity planning, TCO calculations, opex/capex allocation\n\nFrom the case study, it can conclude that Management (CXO) all concern rapid provision of resources (infrastructure) for growing as well as cost management, such as Cost optimization in Infrastructure, trade up front capital expenditures (Capex) for ongoing operating expenditures (Opex), and Total cost of ownership (TCO)","comments":[{"comment_id":"155138","upvote_count":"7","timestamp":"1644566340.0","poster":"tartar","content":"B is ok"},{"content":"B is correct.","upvote_count":"1","comment_id":"303895","timestamp":"1662341580.0","poster":"nitinz"},{"upvote_count":"2","comment_id":"818342","content":"Only Issue I have w/ B is that they may currently be leasing owned compute, meaning that CapEx/OpEx considerations don't change.","timestamp":"1724349480.0","poster":"nick_name_1"}],"comment_id":"40015"},{"poster":"mudot","comment_id":"488119","timestamp":"1685183220.0","content":"Selected Answer: B\nA is not correct because LAN change management processes don't need to change significantly. TerramEarth can easily peer their on-premises LAN with their Google Cloud Platform VPCs, and as devices and subnets move to the cloud, the LAN team's implementation will change, but the change management process doesn't have to.\n\nB is correct because all of these tasks are big changes when moving to the cloud. Capacity planning for cloud is different than for on-premises data centers; TCO calculations are adjusted because TerramEarth is using services, not leasing/buying servers; OpEx/CapEx allocation is adjusted as services are consumed vs. using capital expenditures.\n\nC is not correct because measuring utilization can be done in the same way, often with the same tools (along with some new ones). Data center expansion is not a concern for cloud customers; it is part of the undifferentiated heavy lifting that is taken care of by the cloud provider.\n\nD is not correct because data center expansion is not a concern for cloud customers; it is part of the undifferentiated heavy lifting that is taken care of by the cloud provider. Measuring utilization can be done in the same way, often with the same tools (along with some new ones).","upvote_count":"6"},{"poster":"tdotcat","content":"Selected Answer: A\nsorry not B, I think A is right","timestamp":"1721175720.0","comment_id":"778477","upvote_count":"1"},{"poster":"tdotcat","comment_id":"778476","timestamp":"1721175660.0","upvote_count":"1","content":"Selected Answer: B\nTCO does not change as much as ownership of machinary is not changing"},{"upvote_count":"1","timestamp":"1714910460.0","content":"Selected Answer: B\nok for B","poster":"megumin","comment_id":"711796"},{"content":"Selected Answer: B\nB it is !!!!","poster":"Nirca","upvote_count":"1","timestamp":"1706449320.0","comment_id":"638674"},{"upvote_count":"1","comment_id":"626783","timestamp":"1704341280.0","poster":"AzureDP900","content":"B is perfect!"},{"upvote_count":"1","timestamp":"1686391680.0","content":"Selected Answer: B\nB is correct answer","comment_id":"498593","poster":"vincy2202"},{"poster":"joe2211","content":"Selected Answer: B\nvote B","upvote_count":"2","comment_id":"487923","timestamp":"1685164320.0"},{"content":"hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152","poster":"kopper2019","upvote_count":"4","comment_id":"406659","timestamp":"1673756040.0"},{"upvote_count":"1","comment_id":"405998","timestamp":"1673683980.0","content":"B. Capacity planning, TCO calculations, opex/capex allocation","poster":"victory108"},{"timestamp":"1673119380.0","poster":"MamthaSJ","content":"Answer is B","upvote_count":"3","comment_id":"401135"},{"comment_id":"335063","timestamp":"1665718140.0","content":"answer is B","poster":"go5","upvote_count":"2"},{"content":"Answer is B","comment_id":"325831","poster":"Ausias18","upvote_count":"1","timestamp":"1664628780.0"},{"upvote_count":"1","comment_id":"166594","poster":"wiqi","content":"B is correct.","timestamp":"1645874880.0"},{"upvote_count":"4","content":"GCP practice question confirms that B is correct","timestamp":"1639477920.0","comment_id":"109967","poster":"syu31svc"},{"poster":"gfhbox0083","timestamp":"1639236780.0","upvote_count":"3","comment_id":"107785","content":"B, for sure"},{"upvote_count":"2","comment_id":"104037","timestamp":"1638822360.0","content":"B is the correct answer","poster":"Ziegler"},{"timestamp":"1638115620.0","upvote_count":"3","content":"Final Decision to go with Option B","comment_id":"97614","poster":"AD2AD4"}],"answer_ET":"B","exam_id":4,"answer":"B","unix_timestamp":1579244820}],"exam":{"isBeta":false,"name":"Professional Cloud Architect","provider":"Google","numberOfQuestions":279,"isImplemented":true,"isMCOnly":false,"id":4,"lastUpdated":"11 Apr 2025"},"currentPage":54},"__N_SSP":true}