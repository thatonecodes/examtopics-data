{"pageProps":{"questions":[{"id":"gYlaXH8rEfcgKx0gRCWc","topic":"1","question_id":221,"timestamp":"2025-02-19 20:25:00","unix_timestamp":1739993100,"exam_id":13,"answers_community":["D (100%)"],"isMC":true,"question_text":"Your team is developing a customer support chatbot for a healthcare company that processes sensitive patient information. You need to ensure that all personally identifiable information (PII) captured during customer conversations is protected prior to storing or analyzing the data. What should you do?","answer_description":"","answer_ET":"D","answer":"D","discussion":[{"content":"Selected Answer: D\nD. Use the DLP API to scan and de-identify PII in chatbot conversations before storing the data.\nWhy Option D?\nEnsures Compliance with Healthcare Data Regulations\n\nHealthcare data is highly sensitive and regulated (e.g., HIPAA in the U.S.).\nCloud Data Loss Prevention (DLP) API can detect and de-identify PII before storing or analyzing conversations.\nDe-identification Removes PII While Keeping Data Usable\n\nDLP API supports de-identification techniques like masking, tokenization, and format-preserving encryption (FPE).\nAllows safe storage and analysis of conversations without exposing PII.\nScalable and Automated Data Protection\n\nDLP API scans and removes PII in real-time, ensuring automated protection across all chatbot interactions.\nPrevents storage of unprotected sensitive data, reducing compliance risks.","upvote_count":"1","timestamp":"1739993100.0","comment_id":"1358936","poster":"tk786786"}],"url":"https://www.examtopics.com/discussions/google/view/156814-exam-professional-machine-learning-engineer-topic-1-question/","answer_images":[],"question_images":[],"choices":{"A":"Use the Cloud Natural Language API to identify and redact PII in chatbot conversations.","C":"Use the DLP API to encrypt PII in chatbot conversations before storing the data.","B":"Use the Cloud Natural Language API to classify and categorize all data, including PII, in chatbot conversations.","D":"Use the DLP API to scan and de-identify PII in chatbot conversations before storing the data."}},{"id":"Pf843QzpkmtyJyWz99S6","answer":"C","choices":{"A":"Develop a custom Python component that reads the batch inference outputs from Cloud Storage, calculates evaluation metrics, and writes the results to a BigQuery table.","B":"Use a Dataflow component that processes the batch inference outputs from Cloud Storage, calculates evaluation metrics in a distributed manner, and writes the results to a BigQuery table.","C":"Create a custom Vertex AI Pipelines component that reads the batch inference outputs from Cloud Storage, calculates evaluation metrics, and writes the results to a BigQuery table.","D":"Use the Automatic side-by-side (AutoSxS) pipeline component that processes the batch inference outputs from Cloud Storage, aggregates evaluation metrics, and writes the results to a BigQuery table."},"unix_timestamp":1741126440,"question_id":222,"answers_community":["C (100%)"],"topic":"1","question_text":"Your team is experimenting with developing smaller, distilled LLMs for a specific domain. You have performed batch inference on a dataset by using several variations of your distilled LLMs and stored the batch inference outputs in Cloud Storage. You need to create an evaluation workflow that integrates with your existing Vertex AI pipeline to assess the performance of the LLM versions while also tracking artifacts. What should you do?","isMC":true,"answer_ET":"C","answer_description":"","exam_id":13,"url":"https://www.examtopics.com/discussions/google/view/157543-exam-professional-machine-learning-engineer-topic-1-question/","discussion":[{"content":"Selected Answer: C\nAnswer C: Vertex AI Pipeline.\n- The Flow already includes Pipelines, which allow for more flexibility in model training, evaluation and metadata storage. No need to go outside of the environment.","upvote_count":"1","poster":"5091a99","comment_id":"1365132","timestamp":"1741126440.0"}],"question_images":[],"timestamp":"2025-03-04 23:14:00","answer_images":[]},{"id":"PLuL3MkekmtY8AzODBiA","answer_ET":"C","answer":"C","unix_timestamp":1622663280,"choices":{"C":"Downsample the data with upweighting to create a sample with 10% positive examples.","B":"Use a convolutional neural network with max pooling and softmax activation.","D":"Remove negative examples until the numbers of positive and negative examples are equal.","A":"Use the class distribution to generate 10% positive examples."},"topic":"1","question_id":223,"question_text":"You were asked to investigate failures of a production line component based on sensor readings. After receiving the dataset, you discover that less than 1% of the readings are positive examples representing failure incidents. You have tried to train several classification models, but none of them converge. How should you resolve the class imbalance problem?","exam_id":13,"timestamp":"2021-06-02 21:48:00","discussion":[{"upvote_count":"33","content":"ANS: C\nhttps://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data#downsampling-and-upweighting\n\n - less than 1% of the readings are positive \n- none of them converge. \n\nDownsampling (in this context) means training on a disproportionately low subset of the majority class examples.","comments":[{"comment_id":"464081","upvote_count":"3","poster":"mousseUwU","timestamp":"1634556060.0","content":"Agree, C is correct"}],"timestamp":"1626750060.0","poster":"celia20200410","comment_id":"409991"},{"upvote_count":"10","timestamp":"1727240160.0","content":"=New Question3=\nYou are going to train a DNN regression model with Keras APJs using this code:\n\n model - tf.keras.Sequential() model.add(tf.keras.layers.Oense(\n 256,\n use_bias-True,\n activation-•relu',\n kernel_initializer-None,\n kernel_regularizer-None,\n input_shape-(500,)))\n model.add(tf.keras.layers.Oropout(rate-0.25)) \n model.add(tf.keras.layers.Oense( \n 128, use_bias-True, \n activation-•relu',\n kernel_initializer-'uniform', \n kernel_regularizer-'12'))\n model.add(tf.keras.layers.Oropout(rate-0.25)) \n model.add(tf.keras.layers.Oense( \n 2, use_bias-False,\n activation-•softriax')) \n model.cornpile(loss-•mse')\n \n How many trainable weights does your model have? (The arithmetic below is correct.)\n \nA. 501*256+257*128+2 = 161154\nB. 500*256+256*128+128*2 = 161024\nC. 501*256+257*128+128*2 = 161408\nD. 500*256*0(?)25+256*128*0(?)25+128*2 = 4044","comments":[{"upvote_count":"1","comment_id":"515020","comments":[{"poster":"AlexZot","content":"Correct answer is C. Do not forget about bias term which is also trainable parameter.","upvote_count":"6","comment_id":"531315","timestamp":"1643029920.0","comments":[{"comments":[{"timestamp":"1660626840.0","upvote_count":"1","content":"because of use_bias = False","poster":"suresh_vn","comment_id":"647464"}],"poster":"sakura65","content":"Why 128 for the last layer is correct and not 129 X 2?","upvote_count":"1","comment_id":"585863","timestamp":"1649948880.0"}]},{"timestamp":"1660627380.0","upvote_count":"3","content":"C is correct. 2nd Layer with use_bias = True","comment_id":"647466","poster":"suresh_vn"}],"timestamp":"1641134040.0","poster":"tooooony55","content":"B: Dense layers with 100 % trainable weigts, the dropout rate at 0.25 will randomly drop 25 % for the regularization's sake - still training for 100 % of the weights."},{"poster":"NickHapton","timestamp":"1640486820.0","comment_id":"509385","content":"Why do you post new questions in every existing question rather than post them as a new question?","comments":[{"content":"Only moderator can post new questions. Thus, I am left with this format. I have emailed the additional questions to the moderator, but he/she has not added them to the site. These questions were received off of other practice tests, but answers were not provided.","timestamp":"1640695560.0","upvote_count":"4","comment_id":"511102","poster":"MisterHairy"}],"upvote_count":"4"},{"poster":"MisterHairy","content":"Answer?","timestamp":"1640183460.0","comment_id":"507162","upvote_count":"1"},{"comments":[{"timestamp":"1655028360.0","comment_id":"615256","upvote_count":"2","content":"my bad , this was tricky \"The Dropout Layer randomly disables neurons during training. They still are present in your model and therefore aren´t discounted from the number of parameters in your model summary.\" , so D is wrong , C and A takes care of the bias , but C is correct","poster":"Mohamed_Mossad"}],"timestamp":"1655027160.0","upvote_count":"1","poster":"Mohamed_Mossad","content":"D , is the only option that takes care of the dropout factor","comment_id":"615247"},{"poster":"M25","timestamp":"1683738360.0","comments":[{"comment_id":"894201","comments":[{"comments":[{"timestamp":"1683738600.0","comment_id":"894207","content":"[3b/3]\nThe biases do not count [Option D] since it asks for “trainable weights”, not “trainable parameters”: \n“State — Mostly trainable features which are trained during ‘model.fit’. In a Dense layer, the states constitute the weights and the bias (…). In some layers, the state can also contain non-trainable features.\nComputation — (…) In a Dense layer, the computation does the following computation — Y = (w*X+c), and returns Y. Y is the output, X is the input, w = weights, c = bias.”\nhttp://webcache.googleusercontent.com/search?q=cache:Xt0HySYRkpIJ:https://towardsdatascience.com/creating-and-training-custom-layers-in-tensorflow-2-6382292f48c2&hl=de&gl=de&strip=1&vwsrc=0","poster":"M25","upvote_count":"1","comments":[{"poster":"Sunny_M","comment_id":"1104549","content":"Hello, I am a little confused, so which one is the answer for the New Question 3?","upvote_count":"1","timestamp":"1703414580.0"}]}],"comment_id":"894205","timestamp":"1683738540.0","poster":"M25","content":"[3a/3] Answer:\nThe dropout counts [Option D] since we are “going to train”: “Note that the Dropout layer only applies when training is set to True such that no values are dropped during inference.” https://keras.io/api/layers/regularization_layers/dropout/.","upvote_count":"1"}],"poster":"M25","timestamp":"1683738420.0","upvote_count":"1","content":"[2/3] Edited syntax of the Options:\nA. 501*256+257*128+2 = 161,154\nB. 500*256+256*128+128*2 = 161,024\nC. 501*256+257*128+128*2 = 161,408\nD. 500*256*0.25+256*128*0.25+128*2 = 40,448"}],"comment_id":"894200","upvote_count":"1","content":"[1/3] Edited syntax of the code:\n\nmodel = tf.keras.Sequential() \nmodel.add(tf.keras.layers.Dense(\n 256, use_bias=True, activation='relu', \n kernel_initializer=None, kernel_regularizer=None, input_shape=(500,)))\nmodel.add(tf.keras.layers.Dropout(rate=0.25))\nmodel.add(tf.keras.layers.Dense(\n 128, use_bias=True, activation='relu',\n kernel_initializer='uniform', kernel_regularizer='12'))\nmodel.add(tf.keras.layers.Dropout(rate=0.25))\nmodel.add(tf.keras.layers.Dense(\n 2, use_bias=False, activation='softmax'))\nmodel.compile(loss='mse')"}],"comment_id":"507152","poster":"MisterHairy"},{"content":"Selected Answer: C\ndownsampling is the clue here\nhttps://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data#downsampling-and-upweighting","timestamp":"1743493320.0","poster":"JPA210","comment_id":"1416611","upvote_count":"1"},{"upvote_count":"6","content":"The answer is C.\n\nWe have to note that\n(1) Downsampling on major class\n(2) Upsampling on minor class\n(3) Upweighting on minor class\nall work for imbalanced data.\n\nHowever, the key assumption in the question is that \"You have tried to train several classification models, but none of them converge\".\nYou are not asked to tackle imbalanced data but asked to handle the non-convergence problem (due to the limited resources or the poorness of the algorithm).\n\nIn the official document, it says: \"If you have an imbalanced data set, first try training on the true distribution. If the model works well and generalizes, you're done! If not, try the following downsampling and upweighting technique.\"\nhttps://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data#downsampling-and-upweighting\nIn other words, the \"downsampling and upweighting technique\" is the technique for the non-convergence problem (not for for the imbalanced data).","timestamp":"1727240280.0","comment_id":"472510","poster":"ramen_lover"},{"content":"Selected Answer: C\nC. Downsample the data with upweighting to create a sample with 10% positive examples.\n\nDealing with class imbalance can be challenging for machine learning models. One common approach to resolving the problem is to downsample the data, either by removing examples from the majority class or by oversampling the minority class. In this case, since you have very few positive examples, you would want to oversample the positive examples to create a sample that better represents the underlying distribution of the data. This could involve using upweighting, where positive examples are given a higher weight in the loss function to compensate for their relative scarcity in the data. This can help the model to better focus on the positive examples and improve its performance in classifying failure incidents.","timestamp":"1727240160.0","comment_id":"794591","upvote_count":"2","poster":"Fatiy"},{"timestamp":"1717591740.0","poster":"PhilipKoku","comment_id":"1224721","upvote_count":"1","content":"Selected Answer: C\nThis approach involves downsampling the majority class (negative examples) and upweighting the minority class (positive examples) to create a balanced dataset.\nBy doing so, the model can learn from both classes effectively.\nReference: How to Handle Imbalanced Classes in Machine Learning [https://elitedatascience.com/imbalanced-classes]"},{"comment_id":"1085159","timestamp":"1701428220.0","content":"Selected Answer: C\nC - Downsample the majority and add weights to it.","upvote_count":"2","poster":"fragkris"},{"timestamp":"1699986840.0","upvote_count":"1","content":"Max Pooling is a pooling operation that calculates the maximum value for patches of a feature map, and uses it to create a downsampled (pooled) feature map. It is usually used after a convolutional layer.","comment_id":"1070734","poster":"tatpicc"},{"comment_id":"892676","timestamp":"1683607980.0","poster":"M25","upvote_count":"1","content":"Selected Answer: C\nWent with C"},{"timestamp":"1682741940.0","upvote_count":"1","comment_id":"884031","poster":"Puneet2022","content":"Selected Answer: C\nhttps://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data#downsampling-and-upweighting"},{"upvote_count":"1","comment_id":"798972","content":"Selected Answer: C\nhttps://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data","poster":"enghabeth","timestamp":"1675613280.0"},{"timestamp":"1675196220.0","comment_id":"794589","content":"C. Downsample the data with upweighting to create a sample with 10% positive examples.\n\nDealing with class imbalance can be challenging for machine learning models. One common approach to resolving the problem is to downsample the data, either by removing examples from the majority class or by oversampling the minority class. In this case, since you have very few positive examples, you would want to oversample the positive examples to create a sample that better represents the underlying distribution of the data. This could involve using upweighting, where positive examples are given a higher weight in the loss function to compensate for their relative scarcity in the data. This can help the model to better focus on the positive examples and improve its performance in classifying failure incidents.","upvote_count":"1","poster":"Fatiy"},{"comment_id":"762595","timestamp":"1672481040.0","upvote_count":"1","poster":"SharathSH","content":"Answer would obviously be C\nAs the dataset is imbalanced and you need to resolve this issue in order to obtain desired result the best approach will be to downsample the data."},{"comment_id":"725156","poster":"EFIGO","timestamp":"1669210320.0","content":"Selected Answer: C\nBest practice for imbalanced dataset is to downsample with upweight\nhttps://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data#downsampling-and-upweighting","upvote_count":"1"},{"poster":"GCP72","timestamp":"1660565220.0","content":"Selected Answer: C\nCorrect answer is \"C\"","upvote_count":"1","comment_id":"647164"},{"timestamp":"1659036900.0","content":"Selected Answer: C\nC. because regardless of the model you use, you should always try to transform or adapt your dataset so that it is more balanced","poster":"enghabeth","comment_id":"638854","upvote_count":"1"},{"poster":"Mohamed_Mossad","upvote_count":"1","content":"Selected Answer: C\nhttps://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data","comment_id":"615218","timestamp":"1655022240.0"},{"content":"sorry , mean C","poster":"Mohamed_Mossad","timestamp":"1655022300.0","comment_id":"615219","upvote_count":"1"},{"comment_id":"531001","timestamp":"1642991100.0","poster":"wences","content":"agree on C","upvote_count":"1"},{"poster":"irumata","timestamp":"1642692720.0","upvote_count":"1","comment_id":"528543","content":"Selected Answer: C\nwe need to balance and easiest way to downsample"},{"timestamp":"1641515460.0","upvote_count":"1","content":"C looks more relevant for handling unbalanced data.","comment_id":"518681","poster":"NamitSehgal"},{"poster":"alphard","timestamp":"1638785700.0","content":"Option C is my choice.\n\nDownsampling (in this context) means training on a disproportionately low subset of the majority class examples.\n\nUpweighting means adding an example weight to the downsampled class equal to the factor by which you downsampled.","comment_id":"495034","upvote_count":"1"},{"content":"C is correct","upvote_count":"1","poster":"JobQ","timestamp":"1637951700.0","comment_id":"487560"},{"upvote_count":"4","comment_id":"375036","timestamp":"1622892780.0","poster":"gcp2021go","content":"Accoring to GCP documentation, C is the answer. Frankly, while I was doing extremely unbalance data training, I found downsampling on majority class is not useful , rather, just adding class weight on the minority class is very much useful and give the better result. I'm planning on try downsampling with upweight on majority class. However, I speculate the result will not be what I wanted. Although one could argue that adding too much class weight, could cause model overfitting on minority class and probability is not calibrated. In that case, the industry domain knowledge comes in play, you would have to look at what matrix you need to optimize."},{"poster":"inder0007","upvote_count":"2","timestamp":"1622663280.0","content":"The answer is C","comment_id":"373014"}],"question_images":[],"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/54298-exam-professional-machine-learning-engineer-topic-1-question/","answers_community":["C (93%)","7%"],"answer_description":"","isMC":true},{"id":"XjMxlyNpSeSpIkPzk05d","timestamp":"2021-06-02 23:19:00","answer_images":[],"exam_id":13,"question_images":[],"discussion":[{"content":"A\n\nData values skews: These skews are significant changes in the\nstatistical properties of data, which means that data patterns are\nchanging, and you need to trigger a retraining of the model to capture\nthese changes.\nhttps://developers.google.com/machine-learning/guides/rules-of-ml/#rule_37_measure_trainingserving_skew","comment_id":"410315","poster":"celia20200410","comments":[{"timestamp":"1653319380.0","content":"Rule #37:\nThe difference between the performance on the holdout data and the \"next­day\" data. Again, this will always exist. You should tune your regularization to maximize the next-day performance. However, large drops in performance between holdout and next-day data may indicate that some features are time-sensitive and possibly degrading model performance.\n\nMaybe it should be C","upvote_count":"2","poster":"oliveolil","comment_id":"485229"},{"comment_id":"465035","poster":"mousseUwU","timestamp":"1650443340.0","content":"I agree, A is correct","upvote_count":"2"}],"upvote_count":"34","timestamp":"1642693560.0"},{"comment_id":"390072","upvote_count":"5","content":"A\nData drift doesn't necessarily require feature reselection (e.g. by L2 regularization). \nhttps://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#challenges","timestamp":"1640406120.0","poster":"Paul_Dirac"},{"upvote_count":"1","content":"Selected Answer: A\nA) Monitor the model and set alerts","comment_id":"1225541","poster":"PhilipKoku","timestamp":"1733498760.0"},{"content":"Selected Answer: A\nWhen the distribution of input data changes, the model may not perform as well as it did during training. It is important to monitor the performance of the model in production and identify any changes in the distribution of input data. By creating alerts to monitor for skew, you can detect when the input data distribution has changed and take action to retrain the model using more recent data that reflects the new distribution. This will help ensure that the model continues to perform well in production.","poster":"tavva_prudhvi","timestamp":"1704193620.0","comment_id":"940690","upvote_count":"2"},{"poster":"M25","content":"Selected Answer: A\nWent with A","upvote_count":"2","comment_id":"892708","timestamp":"1699513320.0"},{"timestamp":"1695553980.0","upvote_count":"1","poster":"SergioRubiano","comment_id":"849304","content":"Selected Answer: A\nA is correct"},{"content":"Its A, as the model itself is performing well, neither overfitting nor performing poorly suddenly, it's a gradual change so regularization on the original model would not help. C is incorrect.","timestamp":"1694176080.0","poster":"tavva_prudhvi","upvote_count":"1","comment_id":"833055"},{"upvote_count":"1","content":"Selected Answer: A\nCreating alerts to monitor for skew in the input data can help to detect when the distribution of the data has changed and the model's performance is affected. Once a skew is detected, retraining the model with the new data can improve its performance.","comment_id":"824984","timestamp":"1693230540.0","poster":"Fatiy"},{"poster":"enghabeth","comment_id":"800435","timestamp":"1691366700.0","content":"Selected Answer: A\nSkew & drift monitoring: Production data tends to constantly change in different dimensions (i.e. time and system wise). And this causes the performance of the model to drop.\nhttps://cloud.google.com/vertex-ai/docs/model-monitoring/using-model-monitoring","upvote_count":"1"},{"comment_id":"738934","timestamp":"1686215340.0","poster":"hiromi","content":"Selected Answer: A\nA\nYou don't need to do feature selection again","upvote_count":"2"},{"timestamp":"1672574760.0","poster":"Mohamed_Mossad","content":"Selected Answer: A\nA very obvious , no need for explanation","upvote_count":"1","comment_id":"625674"},{"content":"Selected Answer: A\nabviously A no tricks here , no too much thinking","upvote_count":"1","comment_id":"615854","poster":"Mohamed_Mossad","timestamp":"1670955960.0"},{"comment_id":"527645","poster":"ggorzki","timestamp":"1658236020.0","upvote_count":"1","content":"Selected Answer: A\nA\nas celia explained"},{"upvote_count":"1","poster":"kaike_reis","comment_id":"477211","content":"Colleagues that said (C) keep attention for the question: They said the model was good, so for skewness is only necessary the (A) solution.","timestamp":"1652390820.0"},{"comment_id":"441669","upvote_count":"2","timestamp":"1646786040.0","poster":"Danny2021","content":"A. It is well documented in Google model monitoring docs."},{"content":"should be C. as L2 regularization prevent overfitting - can potential maintain model performance if data distribution is little skewed.","poster":"gcp2021go","comment_id":"417986","timestamp":"1643659920.0","upvote_count":"2"},{"comment_id":"378490","upvote_count":"2","poster":"inder0007","content":"A model learns the distribution of the data, if it has done its job well any change in the distribution will lead to underperformance not by virtue of poor model performance but by very definition.","timestamp":"1639083720.0"},{"comment_id":"373064","poster":"[Removed]","upvote_count":"4","comments":[{"comment_id":"444893","poster":"Y2Data","content":"The model itself is fine, neither overfitting nor performing poorly suddenly, it's a gradual change so regularization on the original model would not help. C is incorrect.","upvote_count":"4","timestamp":"1647312780.0"},{"timestamp":"1662733380.0","poster":"sonxxx","comment_id":"564160","upvote_count":"1","content":"right. It is a general problem in the model so we need find a general solution for the model. A answer increase instability and the model cost."}],"content":"C. \"A problem is said to be ill-posed if small changes in the given information cause large changes in the solution. This instability with respect to the data makes solutions unreliable because small measurement errors or uncertainties in parameters may be greatly magnified and lead to wildly different responses. […] The idea behind regularization is to use supplementary information to restate an ill-posed problem in a stable form.\"\n\nReference: https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/","timestamp":"1638487140.0"}],"question_id":224,"answer":"A","answer_description":"","topic":"1","url":"https://www.examtopics.com/discussions/google/view/54319-exam-professional-machine-learning-engineer-topic-1-question/","isMC":true,"unix_timestamp":1622668740,"choices":{"C":"Retrain the model, and select an L2 regularization parameter with a hyperparameter tuning service.","D":"Perform feature selection on the model, and retrain the model on a monthly basis with fewer features.","A":"Create alerts to monitor for skew, and retrain the model.","B":"Perform feature selection on the model, and retrain the model with fewer features."},"question_text":"Your team trained and tested a DNN regression model with good results. Six months after deployment, the model is performing poorly due to a change in the distribution of the input data. How should you address the input differences in production?","answers_community":["A (100%)"],"answer_ET":"A"},{"id":"fjYp4Y3KK7dEQYY9viwX","answer":"B","choices":{"D":"Remove the sensitive data from the files manually before loading them into BigQuery.","B":"Use the DLP API to de-identify the sensitive data before loading it into BigQuery.","C":"Store the unstructured data in a separate PII-compliant BigQuery database.","A":"Use BigQuery’s authorized views and column-level access controls to restrict access to PII within the dataset."},"question_images":[],"answers_community":["B (100%)"],"exam_id":13,"answer_images":[],"unix_timestamp":1739993400,"question_id":225,"answer_description":"","timestamp":"2025-02-19 20:30:00","answer_ET":"B","topic":"1","discussion":[{"timestamp":"1740682500.0","upvote_count":"1","comment_id":"1362702","content":"Selected Answer: B\nB. This is the most effective and scalable solution. The DLP (Data Loss Prevention) API is designed to identify and transform sensitive data.","poster":"CassiniExam"},{"timestamp":"1739993400.0","poster":"tk786786","comment_id":"1358940","comments":[{"comment_id":"1360451","upvote_count":"1","poster":"Trueeye","content":"Could you please answer the other questions as well","timestamp":"1740303360.0"}],"upvote_count":"2","content":"Selected Answer: B\nB. Use the DLP API to de-identify the sensitive data before loading it into BigQuery.\nWhy Option B?\nEnsures Compliance with Company Policy\n\nCompany policy requires PII to remain in Cloud Storage.\nGoogle Cloud Data Loss Prevention (DLP) API can de-identify (mask, tokenize, or redact) PII while preserving its analytical value.\nOnly de-identified structured data is moved to BigQuery, ensuring compliance.\nPreserves Data Utility for Analysis\n\nDLP API supports format-preserving encryption (FPE) and tokenization, allowing analysis without exposing sensitive details.\nFraud detection models can still leverage de-identified transaction patterns without accessing raw PII.\nScalable and Automated Solution\n\nDLP API can be used in a Dataflow pipeline to process large amounts of unstructured data before ingestion.\nAvoids manual effort (as required in Option D) and provides consistent security measures."}],"question_text":"You work for a bank. You need to train a model by using unstructured data stored in Cloud Storage that predicts whether credit card transactions are fraudulent. The data needs to be converted to a structured format to facilitate analysis in BigQuery. Company policy requires that data containing personally identifiable information (PII) remain in Cloud Storage. You need to implement a scalable solution that preserves the data’s value for analysis. What should you do?","url":"https://www.examtopics.com/discussions/google/view/156816-exam-professional-machine-learning-engineer-topic-1-question/","isMC":true}],"exam":{"isImplemented":true,"name":"Professional Machine Learning Engineer","isBeta":false,"isMCOnly":true,"numberOfQuestions":304,"id":13,"provider":"Google","lastUpdated":"11 Apr 2025"},"currentPage":45},"__N_SSP":true}