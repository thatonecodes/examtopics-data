{"pageProps":{"questions":[{"id":"TdulsRi2zx5cvKd7xydv","answer_ET":"C","topic":"1","question_text":"You are migrating your 2 TB on-premises PostgreSQL cluster to Compute Engine. You want to set up your new environment in an Ubuntu virtual machine instance in Google Cloud and seed the data to a new instance. You need to plan your database migration to ensure minimum downtime. What should you do?","unix_timestamp":1679631900,"url":"https://www.examtopics.com/discussions/google/view/103733-exam-professional-cloud-database-engineer-topic-1-question/","isMC":true,"question_images":[],"answer_images":[],"exam_id":5,"discussion":[{"timestamp":"1695857100.0","poster":"dynamic_dba","comment_id":"852561","content":"C.\nFull exports are not possible offline. Eliminate A and B. Migrating to GCE means you can't use the Database Migration Service. Note, Datastream CDC only supports MySQL and Oracle. To seed the PostgreSQL instance in GCE, a backup is needed created using pg_basebackup. An export won't cut it. That eliminates D and leaves C. Those 9 steps actually make sense.","upvote_count":"5"},{"comment_id":"1347509","poster":"887ad17","content":"Selected Answer: C\nC fullbackup = basebackup + wals","timestamp":"1738001940.0","upvote_count":"1"},{"comment_id":"1217346","poster":"dija123","upvote_count":"1","content":"Selected Answer: C\nAgree with C, As taking backup is faster than the export.","timestamp":"1732447500.0"},{"poster":"Pime13","timestamp":"1730539620.0","comment_id":"1205348","upvote_count":"1","content":"c: https://cloud.google.com/architecture/migrating-postgresql-to-gcp"},{"timestamp":"1710418920.0","comment_id":"1007474","upvote_count":"2","content":"Selected Answer: C\nCouple of reasons for C option.\n1. Database remains online (see link below, and step 1, which says \"running master database\"\n2. Backups are faster then exports (which generates new files)\nhttps://cloud.google.com/architecture/migrating-postgresql-to-gcp","poster":"njda"},{"content":"B\n\nThis approach minimizes downtime by exporting the database while it's offline, transferring it to Google Cloud Storage, and then restoring it into the new Google Cloud primary server. It's a straightforward and efficient method to migrate your PostgreSQL database.\n\nThe other options involve additional steps that are not necessary or may introduce unnecessary complexities and potential issues during the migration process.\n\nFor C and D:\n\nThe major issue with this option is the additional steps involving creating a recovery.conf file, stopping the source database, transferring write-ahead logs, and syncing with the running primary server. These steps are overly complex and can introduce unnecessary risks and potential complications during the migration process.","upvote_count":"2","comment_id":"982679","timestamp":"1708101480.0","poster":"pico"},{"comment_id":"922394","poster":"abdenago","upvote_count":"1","timestamp":"1702492560.0","content":"Selected Answer: C\nhttps://cloud.google.com/architecture/migrating-postgresql-to-gcp"},{"upvote_count":"1","timestamp":"1695522300.0","poster":"AnilKr","comment_id":"848945","content":"C, Its to take full backup not full export in this case."}],"answer_description":"","answer":"C","timestamp":"2023-03-24 05:25:00","answers_community":["C (100%)"],"question_id":31,"choices":{"B":"1. Take a full backup while the database is online.\n2. Create a bucket in Cloud Storage.\n3. Transfer the backup to the bucket you just created.\n4. Restore the backup into the Google Cloud primary server.\n5. Create a recovery.conf file in the $PG_DATA directory.\n6. Stop the source database.\n7. Transfer the write ahead logs to the bucket you created before.\n8. Start the PostgreSQL service.\n9. Wait until Google Cloud primary server syncs with the running primary server.","C":"1. Take a full export while the database is online.\n2. Create a bucket in Cloud Storage.\n3. Transfer the dump file and write-ahead logs to the bucket you just created.\n4. Restore the dump file into the Google Cloud primary server.\n5. Create a recovery.conf file in the $PG_DATA directory.\n6. Stop the source database.\n7. Transfer the write-ahead logs to the bucket you created before.\n8. Start the PostgreSQL service.\n9. Wait until the Google Cloud primary server syncs with the running primary server.","A":"1. Take a full export while the database is offline.\n2. Create a bucket in Cloud Storage.\n3. Transfer the dump file to the bucket you just created.\n4. Import the dump file into the Google Cloud primary server.\nB.1. Take a full export while the database is offline.\n2. Create a bucket in Cloud Storage.\n3. Transfer the dump file to the bucket you just created.\n4. Restore the backup into the Google Cloud primary server."}},{"id":"4leQE1NASgpL2CoJgfFW","isMC":true,"answers_community":["D (71%)","B (29%)"],"question_images":[],"answer_description":"","unix_timestamp":1679959740,"question_text":"You have deployed a Cloud SQL for SQL Server instance. In addition, you created a cross-region read replica for disaster recovery (DR) purposes. Your company requires you to maintain and monitor a recovery point objective (RPO) of less than 5 minutes. You need to verify that your cross-region read replica meets the allowed RPO. What should you do?","answer_images":[],"choices":{"A":"Use Cloud SQL instance monitoring.","B":"Use the Cloud Monitoring dashboard with available metrics from Cloud SQL.","D":"Use the SQL Server Always On Availability Group dashboard.","C":"Use Cloud SQL logs."},"answer_ET":"D","answer":"D","discussion":[{"comment_id":"852563","timestamp":"1679959740.0","upvote_count":"14","content":"D.\nNote, you cannot create a read replica in Cloud SQL for SQL Server unless you use an Enterprise Edition. Which is also a requirement for configuring SQL Server AG. That's not a coincidence. That's how Cloud SQL for SQL Server creates SQL Server read replicas. To find out about the replication, use the AG Dashboard in SSMS. \nhttps://cloud.google.com/sql/docs/sqlserver/replication/manage-replicas#promote-replica","poster":"dynamic_dba"},{"upvote_count":"1","timestamp":"1737785040.0","content":"Selected Answer: B\nSQL Server Always On Availability Groups can be configured on GCP. This feature is valuable for high availability and disaster recovery.\n\nHowever, the Cloud Monitoring dashboard is specifically tailored for Google Cloud resources, including Cloud SQL instances. It offers built-in metrics and monitoring capabilities designed to track and ensure that the Read Replica meets the required RPO. Even though the Always On Availability Group can be configured, Cloud Monitoring is generally more streamlined for this purpose.","poster":"Popa","comment_id":"1346345"},{"comment_id":"1290484","timestamp":"1727493780.0","poster":"kitechen","upvote_count":"1","content":"Selected Answer: B\nAlways On Availability Groups are a feature of on-premises SQL Server or SQL Server running on VMs, not Cloud SQL"},{"upvote_count":"2","timestamp":"1714477140.0","poster":"Pime13","comment_id":"1204541","content":"Selected Answer: D\nD- https://cloud.google.com/sql/docs/sqlserver/replication/manage-replicas#console_1"},{"comment_id":"1183176","timestamp":"1711446000.0","content":"Selected Answer: D\noption D no doubt","poster":"nmnm22","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: D\nhttps://cloud.google.com/sql/docs/sqlserver/replication/manage-replicas#replication-status explains it.","comment_id":"1132570","timestamp":"1706278380.0","poster":"PKookNN"},{"comment_id":"1081808","upvote_count":"1","poster":"Andrei_Z","timestamp":"1701104520.0","content":"Selected Answer: B\nI thought it was B at first but apparently, we can use Cloud Monitoring to see all the metrics for the recovery an replication."},{"upvote_count":"3","content":"Selected Answer: D\nD is the correct answer","poster":"sapsant","comment_id":"967480","timestamp":"1690748100.0"},{"poster":"sapsant","content":"Selected Answer: D\nhttps://cloud.google.com/sql/docs/sqlserver/replication/manage-replicas#promote-replica","timestamp":"1690660740.0","upvote_count":"3","comment_id":"966621"},{"content":"Vote for D!\nAgreed with dynamic_dba","timestamp":"1689868860.0","upvote_count":"2","poster":"dedotes","comment_id":"957791"},{"upvote_count":"2","timestamp":"1686673560.0","poster":"abdenago","content":"Selected Answer: B\nhttps://medium.com/google-cloud/cloud-sql-recovering-from-regional-failure-in-10-minutes-or-less-mysql-fc055540a8f0","comment_id":"922378"}],"url":"https://www.examtopics.com/discussions/google/view/104142-exam-professional-cloud-database-engineer-topic-1-question/","question_id":32,"timestamp":"2023-03-28 01:29:00","exam_id":5,"topic":"1"},{"id":"jVMPP1LHrxrpiN69MWF1","answer_ET":"D","choices":{"A":"Take nightly snapshots of the primary database instance, and restore them in a secondary zone.","C":"Create a read replica in another region, and promote the read replica if a failure occurs.","D":"Enable high availability (HA) for the database to make it regional.","B":"Build a change data capture (CDC) pipeline to read transactions from the primary instance, and replicate them to a secondary instance."},"discussion":[{"poster":"DBAgain","content":"Selected Answer: D\nD is the clear winner.","timestamp":"1721240100.0","comment_id":"954510","upvote_count":"1"},{"content":"D.\nMission critical means make the instance HA. Nothing else makes sense apart from D.","upvote_count":"4","comment_id":"852565","poster":"dynamic_dba","timestamp":"1711589460.0"},{"comment_id":"848949","upvote_count":"1","poster":"AnilKr","content":"D, zonal failure > enable HA to recover","timestamp":"1711254480.0"}],"topic":"1","exam_id":5,"answers_community":["D (100%)"],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/103734-exam-professional-cloud-database-engineer-topic-1-question/","answer":"D","question_id":33,"question_text":"You want to migrate an on-premises mission-critical PostgreSQL database to Cloud SQL. The database must be able to withstand a zonal failure with less than five minutes of downtime and still not lose any transactions. You want to follow Google-recommended practices for the migration. What should you do?","timestamp":"2023-03-24 05:28:00","answer_images":[],"question_images":[],"isMC":true,"unix_timestamp":1679632080},{"id":"BC9CVRvGwQbVW3PDiYab","discussion":[{"comment_id":"883393","poster":"tkg13","content":"I believe it's option B as shared VPC can be used to connect multiple projects .","upvote_count":"7","timestamp":"1682675700.0"},{"poster":"ssp01","content":"B.\nMore info on this matter:\nhttps://cloud.google.com/network-connectivity/docs/interconnect/how-to/enabling-multiple-networks-access-same-attachment","comment_id":"1232088","timestamp":"1718652660.0","upvote_count":"1"},{"timestamp":"1716545280.0","comment_id":"1217372","poster":"dija123","content":"Why not A?","upvote_count":"2"},{"comment_id":"1205342","poster":"Pime13","timestamp":"1714634400.0","content":"Selected Answer: B\nit's B","upvote_count":"1"},{"comment_id":"1183170","timestamp":"1711445760.0","upvote_count":"1","content":"Selected Answer: B\nOption B","poster":"nmnm22"},{"poster":"abdenago","upvote_count":"2","timestamp":"1686670500.0","comment_id":"922349","content":"Selected Answer: B\nhttps://groups.google.com/g/google-cloud-sql-discuss/c/M5G5_HPXytY?pli=1"}],"unix_timestamp":1682675700,"question_text":"You are migrating an on-premises application to Compute Engine and Cloud SQL. The application VMs will live in their own project, separate from the Cloud SQL instances which have their own project. What should you do to configure the networks?","answers_community":["B (100%)"],"timestamp":"2023-04-28 11:55:00","answer_description":"","answer_images":[],"question_images":[],"question_id":34,"answer_ET":"B","url":"https://www.examtopics.com/discussions/google/view/107785-exam-professional-cloud-database-engineer-topic-1-question/","topic":"1","choices":{"D":"Place both the application VMs and the Cloud SQL instances in the default network of each project.","A":"Create a new VPC network in each project, and use VPC Network Peering to connect the two together.","B":"Create a Shared VPC that both the application VMs and Cloud SQL instances will use.","C":"Use the default networks, and leverage Cloud VPN to connect the two together."},"isMC":true,"exam_id":5,"answer":"B"},{"id":"ottLo75B8p9EX0BscSNb","answer_ET":"D","choices":{"B":"Maintain a target of 23% CPU utilization by locating:\ncluster-a in zone us-central1-a\ncluster-b in zone us-central1-b\ncluster-c in zone us-east1-a","C":"Maintain a target of 35% CPU utilization by locating:\ncluster-a in zone us-central1-a\ncluster-b in zone australia-southeast1-a\ncluster-c in zone europe-west1-d\ncluster-d in zone asia-east1-b","D":"Maintain a target of 35% CPU utilization by locating:\ncluster-a in zone us-central1-a\ncluster-b in zone us-central2-a\ncluster-c in zone asia-northeast1-b\ncluster-d in zone asia-east1-b","A":"Maintain a target of 23% CPU utilization by locating:\ncluster-a in zone us-central1-a\ncluster-b in zone europe-west1-d\ncluster-c in zone asia-east1-b"},"answer":"D","question_images":[],"answers_community":["D (100%)"],"unix_timestamp":1671854280,"topic":"1","question_text":"You recently launched a new product to the US market. You currently have two Bigtable clusters in one US region to serve all the traffic. Your marketing team is planning an immediate expansion to APAC. You need to roll out the regional expansion while implementing high availability according to Google-recommended practices. What should you do?","isMC":true,"exam_id":5,"discussion":[{"comment_id":"836275","content":"D.\nThe question HA for US and APAC. Any answer which mentions Europe must be wrong. That eliminates A and C. HA requires > 1 cluster, so B must be wrong, leaving D. D shows 2 clusters in US and 2 in APAC.","upvote_count":"12","poster":"dynamic_dba","timestamp":"1694442780.0"},{"comment_id":"1208864","upvote_count":"2","poster":"hanayome","timestamp":"1731165120.0","content":"Selected Answer: D\nobviously D"},{"upvote_count":"2","poster":"goodsport","content":"Selected Answer: D\nD seems right.","comment_id":"1010298","timestamp":"1710747540.0"},{"poster":"jteru","timestamp":"1706622360.0","content":"Selected Answer: D\nD is correct.","comment_id":"967062","upvote_count":"2"},{"content":"D: Maintain a target of 35% CPU utilization by locating:\ncluster-a in zone us-central1-a\ncluster-b in zone us-central2-a\ncluster-c in zone asia-northeast1-b\ncluster-d in zone asia-east1-b","upvote_count":"2","timestamp":"1687699260.0","poster":"pk349","comment_id":"755771"},{"timestamp":"1687618080.0","poster":"chelbsik","content":"Selected Answer: D\nForgot to vote","upvote_count":"4","comment_id":"755027"},{"upvote_count":"2","comment_id":"754688","poster":"GCP72","timestamp":"1687571880.0","content":"D is the correct answer"}],"timestamp":"2022-12-24 04:58:00","answer_images":[],"answer_description":"","question_id":35,"url":"https://www.examtopics.com/discussions/google/view/92622-exam-professional-cloud-database-engineer-topic-1-question/"}],"exam":{"lastUpdated":"11 Apr 2025","isImplemented":true,"isMCOnly":true,"isBeta":false,"numberOfQuestions":132,"name":"Professional Cloud Database Engineer","provider":"Google","id":5},"currentPage":7},"__N_SSP":true}