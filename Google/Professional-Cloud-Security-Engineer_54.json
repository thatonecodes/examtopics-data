{"pageProps":{"questions":[{"id":"ATbReCxJuzV4zwD8lbSB","unix_timestamp":1584176400,"discussion":[{"comment_id":"63797","upvote_count":"20","poster":"rafaelc","timestamp":"1600066800.0","content":"A or B. Leaning towards A\nYou have a deadline you cannot develop a new app so you have to lift and shift.","comments":[{"poster":"xhova","content":"Answer is A.. You need VPC Flow Logs not \"Firewall logs\" stated in B","comment_id":"70940","comments":[{"timestamp":"1682314020.0","poster":"Table2022","content":"xhova, you got it right!","comment_id":"702714","upvote_count":"3"},{"content":"I agree.","comment_id":"132054","timestamp":"1610372880.0","upvote_count":"2","poster":"smart123"}],"upvote_count":"13","timestamp":"1601791200.0"},{"poster":"mynk29","comment_id":"557074","timestamp":"1661550060.0","content":"Agree \"Disable all traffic within the VPC and look at the Firewall logs to determine what traffic should be allowed for the application to work properly.\" if you disable all the VPC traffic there will be nothing to look into firewall logs.","upvote_count":"8"}]},{"content":"Selected Answer: B\nThe best option to complete the migration of the legacy application without putting your environment at risk is:\nB. Migrate the application into an isolated project using a “Lift & Shift” approach in a custom network. Disable all traffic within the VPC and look at the Firewall logs to determine what traffic should be allowed for the application to work properly.\nExplanation:\n\n Disable All Traffic: By disabling all traffic initially, you can ensure that no unauthorized traffic can access the application. This setup provides a secure environment.\n\n Using Firewall Logs: This approach allows you to monitor what traffic is necessary for the application to function correctly after migration. You can analyze the Firewall logs to identify which ports and protocols are being used by the application, enabling you to refine your security configurations based on actual usage.","poster":"YourFriendlyNeighborhoodSpider","comment_id":"1392260","upvote_count":"1","timestamp":"1741890540.0"},{"comment_id":"1159674","timestamp":"1724668380.0","poster":"cskhachane","content":"Option C:","upvote_count":"1"},{"content":"Selected Answer: A\nB is not correct because Disabling all traffic within the VPC is too restrictive and hinders even initial testing. Analyzing firewall logs without any initial connectivity wouldn't be feasible.","comment_id":"1153542","timestamp":"1724003580.0","poster":"okhascorpio","upvote_count":"2"},{"upvote_count":"3","timestamp":"1711076520.0","comment_id":"1013489","content":"Selected Answer: A\nOption B, C, and D involve making significant architectural changes (refactoring into microservices or using Cloud Functions) and disabling traffic, which might introduce complexities and risks. These options are more suitable when you have a better understanding of the application's requirements and can make informed decisions about its architecture and network policies. In your current scenario, option A provides a safe starting point for the migration process while you gather more information about the application's behavior.","poster":"Xoxoo"},{"poster":"ArizonaClassics","upvote_count":"1","content":"B. This option is similar to the first one but is more secure initially. The application is also migrated using a \"Lift & Shift\" approach. However, instead of enabling all internal TCP traffic, all traffic within the VPC is disabled. The Firewall logs (not exactly the most ideal tool but can give insights) are then used to determine what traffic is needed. This is more secure as it takes a deny-all-first approach.","timestamp":"1710466260.0","comment_id":"1007972"},{"timestamp":"1703852940.0","content":"Option A is a valid approach, but it is not as secure as Option C. In Option A, the application is still exposed to the network, even if it is in an isolated project. This means that if someone were to find a vulnerability in the application, they could potentially exploit it to gain access to the application.\n\nIn Option C, the application is isolated from the network by being deployed to a GKE cluster. This means that even if someone were to find a vulnerability in the application, they would not be able to exploit it to gain access to the application.\n\nAdditionally, Option C is more scalable and resilient than Option A. This is because a GKE cluster can be scaled up or down as needed, and it is more resistant to failure than a single VM.\n\nTherefore, Option C is the more secure and scalable approach. However, if you are short on time, Option A may be a better option.","poster":"amanshin","upvote_count":"2","comment_id":"937897"},{"poster":"Joanale","comment_id":"896097","timestamp":"1699817340.0","upvote_count":"2","content":"A is a best option, remember you have the hurriest of the contract. Making microservices taking too long and have to know the detailed application architecture. Answer A."},{"poster":"Ric350","comments":[{"poster":"Ric350","upvote_count":"1","timestamp":"1696110720.0","content":"Excuse me, C is the correct answer for the reasons listed below. You try lifting and shift a company application without the proper dependencies of how it works, cause a disruption or outage until you figure it out and let me know how that works for you and if you'll still have a job.","comment_id":"857447"}],"timestamp":"1696110600.0","content":"The answer is A. In real life you would NOT lift and shift an application especially not knowing the ports it uses nor any documentation. That'd be disruptive and cause an outage until you figured it out. You'd be out of a job! The question also clearly states \"You want to complete the migration without putting your environment at risk!\"\nYou'd have to refactor the application in parallel and makes sense if it's a legacy application. You'd want to modernize it with microservices so it can take advantage of all cloud features. If you simply lift and shift, the legacy app cannot take advantage of cloud services so what's the point? You still have the same problems except now you've moved it from on-prem to the cloud.","comment_id":"857446","upvote_count":"3"},{"content":"Answer is B. \neven if you disable all traffic within VPC, the request to the application will hit the firewall and will get a deny ingress response. that way we get to know what port is It coming in. the same can be determined with allowing all traffic in (which exposes your application to the world ) but the question ends with \"without putting your environment at risk\"","upvote_count":"2","comment_id":"814477","timestamp":"1692467880.0","poster":"sameer2803"},{"upvote_count":"3","poster":"pedrojorge","comment_id":"786620","timestamp":"1690202820.0","content":"Selected Answer: B\nB, as A temporarily opens vulnerable paths in the system."},{"comment_id":"759985","timestamp":"1687957620.0","upvote_count":"4","poster":"somnathmaddi","content":"Selected Answer: A\nAnswer is A.. You need VPC Flow Logs not \"Firewall logs\" stated in B"},{"content":"Selected Answer: A\nA since B disrupts the system. C and D are out of question if it's supposed to \"just work\".","upvote_count":"4","comment_id":"728905","timestamp":"1685257020.0","poster":"Mixxer5"},{"timestamp":"1684766880.0","poster":"Meyucho","content":"Selected Answer: B\nThe difference between A and B is that, in the first, you allow all traffic so the app will work after migration and you can investigate which ports should be open and then take actions. If you go with B you will have a disruption window until figure out all ports needed but will not have any port unneeded port. So... if you asked to avoid disruption go with A and (as in this question) you are asked about security, go with B","upvote_count":"4","comments":[{"upvote_count":"2","comment_id":"786622","poster":"pedrojorge","content":"The question never asks to avoid disruption, it asks to avoid risk, so the answer must be B.","timestamp":"1690202880.0"}],"comment_id":"724493"},{"content":"Selected Answer: A\nA. Migrate the application into an isolated project using a \"Lift & Shift\" approach. Enable all internal TCP traffic using VPC Firewall rules. Use VPC Flow logs to determine what traffic should be allowed for the application to work properly.","timestamp":"1680759360.0","upvote_count":"4","comment_id":"687504","poster":"AwesomeGCP"},{"comment_id":"503645","comments":[{"comment_id":"507730","timestamp":"1655973240.0","content":"Could you please help us with recent dumps or guide which dump to be referred","poster":"vicky_cyber","comments":[{"comment_id":"534865","content":"This one is accurate.","upvote_count":"2","timestamp":"1659023040.0","poster":"Bwitch"}],"upvote_count":"2"}],"upvote_count":"1","poster":"GPK","content":"These questions are no more relevant as google has changed exam and made it really challenging now.","timestamp":"1655458200.0"},{"timestamp":"1655319360.0","poster":"rr4444","upvote_count":"1","content":"Selected Answer: B\nB - VPC Flow Logs\n\nFirewall logging only covers TCP and UDP, you explicitly don't know what the app does. That limitation is also important to the fact that implied deny all ingress and deny all egress rules are not covered by Firewall Logging. Plus you have to enable Firewall Logging per rule, so you'd have to have a rule for everything in advance - chicken and egg.... you don't know what is going on, so how could you!?","comment_id":"502478","comments":[{"timestamp":"1655319480.0","comment_id":"502479","upvote_count":"2","poster":"rr4444","content":"VPC FLow logs is A!\n\nI meant A!"}]},{"timestamp":"1636630440.0","upvote_count":"4","comment_id":"354559","poster":"keresh","content":"Answer A matches \"without putting your environment at risk\" best, all the other answers are higher in risk"},{"upvote_count":"3","poster":"DebasishLowes","timestamp":"1632329460.0","comment_id":"317444","content":"Ans : A"},{"timestamp":"1619709240.0","content":"Ans - A","comment_id":"208734","upvote_count":"3","poster":"[Removed]"},{"upvote_count":"3","content":"A is the answer. You need to take a look at the VPC Flow Logs to know what kind of traffic going in.","comment_id":"190180","timestamp":"1617090720.0","poster":"CHECK666"},{"poster":"MohitA","timestamp":"1614165240.0","content":"A is the correct Answer","comment_id":"165026","upvote_count":"2"},{"poster":"aiwaai","content":"Correct Answer: B","comment_id":"161869","timestamp":"1613786220.0","upvote_count":"1","comments":[{"timestamp":"1614387240.0","upvote_count":"1","comment_id":"167158","content":"made correction B -> A","poster":"aiwaai"}]},{"comment_id":"96978","timestamp":"1606509540.0","upvote_count":"2","poster":"srinidutt","content":"A is relevent"}],"answers_community":["A (65%)","B (35%)"],"isMC":true,"question_id":266,"answer_description":"","timestamp":"2020-03-14 10:00:00","answer_ET":"A","topic":"1","url":"https://www.examtopics.com/discussions/google/view/16557-exam-professional-cloud-security-engineer-topic-1-question/","question_images":[],"choices":{"B":"Migrate the application into an isolated project using a ג€Lift & Shiftג€ approach in a custom network. Disable all traffic within the VPC and look at the Firewall logs to determine what traffic should be allowed for the application to work properly.","D":"Refactor the application into a micro-services architecture hosted in Cloud Functions in an isolated project. Disable all traffic from outside your project using Firewall Rules. Use VPC Flow logs to determine what traffic should be allowed for the application to work properly.","A":"Migrate the application into an isolated project using a ג€Lift & Shiftג€ approach. Enable all internal TCP traffic using VPC Firewall rules. Use VPC Flow logs to determine what traffic should be allowed for the application to work properly.","C":"Refactor the application into a micro-services architecture in a GKE cluster. Disable all traffic from outside the cluster using Firewall Rules. Use VPC Flow logs to determine what traffic should be allowed for the application to work properly."},"exam_id":9,"question_text":"You are in charge of migrating a legacy application from your company datacenters to GCP before the current maintenance contract expires. You do not know what ports the application is using and no documentation is available for you to check. You want to complete the migration without putting your environment at risk.\nWhat should you do?","answer":"A","answer_images":[]},{"id":"NxvZi65tvbYZGijRAj0S","timestamp":"2020-03-09 11:00:00","answer_images":[],"choices":{"B":"Package a single app as a container.","E":"Use many container image layers to hide sensitive information.","A":"Ensure that the app does not run as PID 1.","D":"Use public container images as a base image for the app.","C":"Remove any unnecessary tools not needed by the app."},"discussion":[{"comment_id":"354935","timestamp":"1668196620.0","poster":"tzKhalil","content":"BC is the answer.\nA is wrong, https://cloud.google.com/architecture/best-practices-for-building-containers#solution_1_run_as_pid_1_and_register_signal_handlers","upvote_count":"14"},{"timestamp":"1721637900.0","comment_id":"784194","upvote_count":"2","content":"Selected Answer: BC\nObviously B&C are part of containerization best practices.","poster":"Raz0r"},{"timestamp":"1708945680.0","poster":"GCP72","content":"Selected Answer: BC\nThe answer is BC","upvote_count":"2","comment_id":"652154"},{"content":"it is AE","poster":"SuperDevops","upvote_count":"2","timestamp":"1683418260.0","comment_id":"473703"},{"comment_id":"346485","timestamp":"1667262840.0","upvote_count":"1","content":"It should be A,B","poster":"Jane111"},{"comment_id":"344155","timestamp":"1666893960.0","upvote_count":"1","poster":"WakandaF","content":"So, its B C?"},{"comments":[{"comment_id":"336237","content":"You don't usually want your container to get killed instantly - you want to see the SIGINT or SIGTERM command and respond. For example, in a webserver you may stop accepting connections, and respond to the remaining open ones, before calling exit()","upvote_count":"3","poster":"lollo1234","timestamp":"1665835380.0"}],"content":"To add to my previous comment\n\"A process running as PID 1 inside a container is treated specially by Linux: it ignores any signal with the default action. So, the process will not terminate on SIGINT or SIGTERM unless it is coded to do so.\" \nLooks like this could be an issue when talking about security, a malicious coder can write a piece of code to eat all resources on the host with this one bad PID#1 \nWhat do you think guys??","poster":"bluetaurianbull","upvote_count":"1","comment_id":"314966","timestamp":"1663591680.0"},{"poster":"bluetaurianbull","content":"To add to my previous comment\n\"A process running as PID 1 inside a container is treated specially by Linux: it ignores any signal with the default action. So, the process will not terminate on SIGINT or SIGTERM unless it is coded to do so.\"","comment_id":"314964","upvote_count":"1","timestamp":"1663591560.0"},{"comments":[{"timestamp":"1701594420.0","poster":"badrik","upvote_count":"1","comment_id":"610971","content":"I don't think this is a valid action to do to improve security perhaps it helps more to improve operational excellence. Imagine you are running production application in a container and it is signalled by container run time to terminate. In this case you don't have the running container to understand what would be issue ( though you can look at the events in modern container orchestration platform but imagine you are running a simple container ). Coming back to your concern. you don't generally run some rubbish container images in your container platform and this build process is very deliberate one."}],"upvote_count":"2","poster":"bluetaurianbull","comment_id":"314962","timestamp":"1663591320.0","content":"Really??? Wat about (A)\nWhen the process with pid 1 die for any reason, all other processes are killed with KILL signal.\n\nShouldnt A be one of the biggest risk when we talk about container security???"},{"upvote_count":"1","poster":"kubosuke","timestamp":"1663537020.0","comment_id":"314448","content":"bc of bc"},{"comment_id":"199314","content":"vote for B and C","upvote_count":"1","timestamp":"1649869200.0","poster":"saurabh1805"},{"comment_id":"164619","upvote_count":"1","content":"BC for sure","timestamp":"1645648500.0","poster":"MohitA"},{"poster":"ArizonaClassics","comment_id":"144243","content":"BC on point!","upvote_count":"2","timestamp":"1643221380.0"},{"poster":"KILLMAD","content":"I agree BC","timestamp":"1631174400.0","upvote_count":"4","comment_id":"61026"}],"url":"https://www.examtopics.com/discussions/google/view/15919-exam-professional-cloud-security-engineer-topic-1-question-5/","question_id":267,"answers_community":["BC (100%)"],"unix_timestamp":1583748000,"question_text":"When creating a secure container image, which two items should you incorporate into the build if possible? (Choose two.)","exam_id":9,"topic":"1","answer":"BC","answer_description":"","answer_ET":"BC","isMC":true,"question_images":[]},{"id":"B4QiSghEPt0twvOzT5DE","discussion":[{"timestamp":"1626004380.0","upvote_count":"19","comment_id":"132057","poster":"smart123","content":"Although both TCP Proxy LB and SSL Proxy LB support port 587 but only SSL Proxy LB support TLS. Hence 'D' is the right answer."},{"content":"Answer D\nhttps://cloud.google.com/load-balancing/docs/ssl\n- SSL Proxy Load Balancing is a reverse proxy load balancer that distributes SSL traffic coming from the internet to virtual machine (VM) instances in your Google Cloud VPC network.\n\nWhen using SSL Proxy Load Balancing for your SSL traffic, user SSL (TLS) connections are terminated at the load balancing layer, and then proxied to the closest available backend instances by using either SSL (recommended) or TCP.","timestamp":"1657183440.0","poster":"umashankar_a","comment_id":"400682","upvote_count":"6"},{"comment_id":"960048","upvote_count":"2","content":"Selected Answer: D\n\"D\"\nAlthough port 587 is SMTP (mail) which is an Application Layer protocol, and one might think an Application Layer (HTTPs) Load balancer is needed, according to Google docs, Application Layer LBs offload TLS at GFE which may or may not be the LB. Only the Network Proxy LB confirms TLS offloading at LB layer. Also, as a general rule, they recommend Network Proxy LB for TLS Offloading:\n \"..As a general rule, you'd choose an Application Load Balancer when you need a flexible feature set for your applications with HTTP(S) traffic. You'd choose a proxy Network Load Balancer to implement TLS offload..\"\n\nReferences:\nhttps://cloud.google.com/load-balancing/docs/choosing-load-balancer#flow_chart\nhttps://cloud.google.com/load-balancing/docs/https#control-tls-termination","poster":"[Removed]","timestamp":"1721705100.0"},{"upvote_count":"2","poster":"Ishu_awsguy","content":"We can use an HTTPS load balancer and change the backend services port to 587 .|\nHTTPS load balacer will also work","timestamp":"1717303200.0","comments":[{"content":"accessible by client on port 587 is the power word.\nAgree with D","poster":"Ishu_awsguy","upvote_count":"1","timestamp":"1717303380.0","comment_id":"912533"}],"comment_id":"912531"},{"content":"Selected Answer: D\nAnswer D. SSL Proxy Load Balancing\nhttps://cloud.google.com/load-balancing/docs/ssl","upvote_count":"1","poster":"AwesomeGCP","timestamp":"1696571100.0","comment_id":"687515"},{"comment_id":"316292","poster":"dtmtor","content":"Answer: D","timestamp":"1647861960.0","upvote_count":"1"},{"content":"Ans : D","upvote_count":"1","poster":"DebasishLowes","timestamp":"1645465920.0","comment_id":"295965"},{"timestamp":"1635520560.0","comment_id":"208735","content":"Ans - D","poster":"[Removed]","upvote_count":"1"},{"comment_id":"190183","upvote_count":"2","poster":"CHECK666","content":"D is the answer. SSL Proxy LoadBalancer supports TLS.","timestamp":"1632988500.0"},{"content":"Agreed with smart123. Ans is D\nhttps://cloud.google.com/load-balancing/docs/choosing-load-balancer#flow_chart","upvote_count":"3","poster":"mlyu","comment_id":"171212","timestamp":"1630477560.0"}],"answer_images":[],"timestamp":"2020-07-11 13:53:00","answer_description":"","answer_ET":"D","url":"https://www.examtopics.com/discussions/google/view/25411-exam-professional-cloud-security-engineer-topic-1-question/","exam_id":9,"isMC":true,"answer":"D","question_id":268,"unix_timestamp":1594468380,"question_text":"Your company has deployed an application on Compute Engine. The application is accessible by clients on port 587. You need to balance the load between the different instances running the application. The connection should be secured using TLS, and terminated by the Load Balancer.\nWhat type of Load Balancing should you use?","answers_community":["D (100%)"],"question_images":[],"topic":"1","choices":{"A":"Network Load Balancing","D":"SSL Proxy Load Balancing","C":"TCP Proxy Load Balancing","B":"HTTP(S) Load Balancing"}},{"id":"KA58D46b8X8ZFM8S8Trm","answer_images":[],"question_images":[],"timestamp":"2020-08-30 22:43:00","answer_description":"","choices":{"C":"In Resource Manager, edit the project permissions for the trusted project. Add the organization as member with the role: Compute Image User.","B":"Use the Organization Policy Service to create a compute.trustedimageProjects constraint on the organization level. List the trusted projects as the exceptions in a deny operation.","A":"Use the Organization Policy Service to create a compute.trustedimageProjects constraint on the organization level. List the trusted project as the whitelist in an allow operation.","D":"In Resource Manager, edit the organization permissions. Add the project ID as member with the role: Compute Image User."},"isMC":true,"discussion":[{"upvote_count":"13","timestamp":"1632329640.0","comment_id":"317446","poster":"DebasishLowes","content":"Ans : A"},{"poster":"[Removed]","upvote_count":"8","comment_id":"208736","timestamp":"1619709780.0","content":"Ans - A\nhttps://cloud.google.com/compute/docs/images/restricting-image-access#trusted_images"},{"timestamp":"1723962600.0","content":"Correct Answer is: A. Option B suggests listing the trusted projects as exceptions in a deny operation, which is not necessary or recommended. It's simpler and more secure to explicitly allow only the trusted project","poster":"nccdebug","upvote_count":"1","comment_id":"1153118"},{"content":"Selected Answer: A\nTo limit the images that can be used as the source for boot disks and store these images in a dedicated project, you should use option A:\n\nA. Use the Organization Policy Service to create a compute.trustedimageProjects constraint on the organization level. List the trusted project as the whitelist in an allow operation.\n\nHere's why this option is appropriate:\n\nOrganization-Wide Control: Creating an organization-level constraint allows you to enforce the policy organization-wide, ensuring consistent image usage across all projects within the organization.\n\nWhitelist Approach: By listing the trusted project as a whitelist in an \"allow\" operation, you explicitly specify which project can be trusted as the source for boot disks. This is a more secure approach because it only allows specific trusted projects.\n\nDedicated Project: You mentioned that the images are stored in a dedicated project, and this option aligns with that requirement.","poster":"Xoxoo","upvote_count":"3","comments":[{"comment_id":"1013487","content":"Option B introduces complexity by listing the trusted projects as exceptions in a \"deny\" operation, which can become challenging to manage as more projects are added.","timestamp":"1711076280.0","upvote_count":"1","poster":"Xoxoo"}],"timestamp":"1711076280.0","comment_id":"1013486"},{"comment_id":"921062","upvote_count":"1","poster":"Joanale","timestamp":"1702353660.0","content":"Actually the default policy is allow * and if you put a constraint it must be as \"deny\" rule with exceptionsPrincipals or denial conditions. So answer is B, there's no \"whitelist\"."},{"content":"Selected Answer: A\nhttps://cloud.google.com/compute/docs/images/restricting-image-access#gcloud\n\nLook at the glcoud examples and it will make sense why A is correct","comment_id":"732679","upvote_count":"3","timestamp":"1685620920.0","poster":"meh009"},{"comments":[{"timestamp":"1683227580.0","poster":"AzureDP900","upvote_count":"1","content":"https://cloud.google.com/compute/docs/images/restricting-image-access","comment_id":"711368"}],"timestamp":"1683047040.0","upvote_count":"2","poster":"AzureDP900","content":"A is right\nUse the Trusted image feature to define an organization policy that allows principals to create persistent disks only from images in specific projects.","comment_id":"710008"},{"comment_id":"687517","content":"Selected Answer: A\nAnswer A. Use the Organization Policy Service to create a compute.trustedimageProjects constraint on the organization level. List the trusted project as the whitelist in an allow operation.","poster":"AwesomeGCP","upvote_count":"2","timestamp":"1680760020.0"},{"comments":[{"content":"Nope, I think I am getting confused. The correct answer is A.","timestamp":"1674840360.0","upvote_count":"1","comment_id":"638166","poster":"piyush_1982"}],"poster":"piyush_1982","upvote_count":"4","content":"To me the answer seems to be B.\nhttps://cloud.google.com/compute/docs/images/restricting-image-access\n\nBy default, instances can be created from images in any project that shares images publicly or explicitly with the user. So there is an implicit allow. \nOption B states that we need to deny all the projects from being used as a trusted project and add \"Trusted Project\" as an exception to that rule.","comment_id":"638162","timestamp":"1674839760.0"},{"upvote_count":"2","content":"Selected Answer: A\nAnswer is A","comment_id":"573469","poster":"simbu1299","timestamp":"1663914360.0"},{"upvote_count":"3","content":"Answer is B. You don’t whitelist in an allow operation. Since there is an implicit allow, the purpose of the whitelist has been defeated.","comments":[{"comment_id":"904385","poster":"gcpengineer","content":"implicit deny","timestamp":"1700696100.0","upvote_count":"1"}],"comment_id":"568800","timestamp":"1663301700.0","poster":"danielklein09"},{"comment_id":"190191","upvote_count":"1","content":"A is the answer. you need to allow operations.","timestamp":"1617091560.0","poster":"CHECK666"},{"content":"I agree with B.\n\n\"https://cloud.google.com/compute/docs/images/restricting-image-access\"","upvote_count":"2","poster":"ownez","timestamp":"1614552180.0","comments":[{"poster":"ownez","content":"Answer is A. \n\n\"Use the Trusted image feature to define an organization policy that allows your project members to create persistent disks only from images in specific projects.\"\n\n\"After sharing your images with other users, you can control where those users employ those resources within your organization. Set the constraints/compute.storageResourceUseRestrictions constraint to define the projects where users are permitted to use your storage resources.\"","comment_id":"170620","upvote_count":"4","timestamp":"1614504540.0","comments":[{"upvote_count":"1","poster":"Sheeda","content":"Yes, A made sense to me too.","timestamp":"1614630300.0","comment_id":"171494"}]}],"comment_id":"170321"}],"answer_ET":"A","answers_community":["A (100%)"],"exam_id":9,"answer":"A","url":"https://www.examtopics.com/discussions/google/view/30125-exam-professional-cloud-security-engineer-topic-1-question/","topic":"1","unix_timestamp":1598820180,"question_id":269,"question_text":"You want to limit the images that can be used as the source for boot disks. These images will be stored in a dedicated project.\nWhat should you do?"},{"id":"djjeT9CwjpngMZgT525o","timestamp":"2020-09-01 08:30:00","answer_ET":"AD","choices":{"E":"Grant the billing account creator role to the designated DevOps team.","A":"Remove all users from the Project Creator role at the organizational level.","D":"Add a designated group of users to the Project Creator role at the organizational level.","C":"Grant the Project Editor role at the organizational level to a designated group of users.","B":"Create an Organization Policy constraint, and apply it at the organizational level."},"answer_images":[],"answers_community":["AD (89%)","11%"],"question_text":"Your team needs to prevent users from creating projects in the organization. Only the DevOps team should be allowed to create projects on behalf of the requester.\nWhich two tasks should your team perform to handle this request? (Choose two.)","url":"https://www.examtopics.com/discussions/google/view/30232-exam-professional-cloud-security-engineer-topic-1-question/","exam_id":9,"answer":"AD","isMC":true,"unix_timestamp":1598941800,"topic":"1","question_images":[],"question_id":270,"discussion":[{"poster":"mlyu","upvote_count":"19","timestamp":"1598941800.0","content":"I think Ans is AD\nBecause we need to stop the users can create project first (A), and allow devops team to create project (D)","comment_id":"171215"},{"timestamp":"1616561280.0","content":"AD is the answer. \nIf constraint is added , no project creation will be allowed, hence B is wrong","poster":"[Removed]","upvote_count":"7","comment_id":"318779"},{"content":"E. I think that the billing account creator role is needed in this case.\nhttps://cloud.google.com/resource-manager/docs/default-access-control#removing-default-roles\n\"After you designate your own Billing Account Creator and Project Creator roles, you can remove these roles from the organization resource to restrict those permissions to specifically designated users. \"","comment_id":"1276276","poster":"taka5094","upvote_count":"1","timestamp":"1725235800.0"},{"upvote_count":"1","content":"Selected Answer: AD\n\"A,D\" seems most accurate.\nThe following page talks about how Project Creator role is granted to all users by default, which is why \"A\" is necessary. And then there's a section about granting Project Creator to specific users which is where \"D\" comes in.\nhttps://cloud.google.com/resource-manager/docs/default-access-control#removing-default-roles","comment_id":"960573","poster":"[Removed]","timestamp":"1690125840.0"},{"upvote_count":"1","content":"AD is perfect.\nA. Remove all users from the Project Creator role at the organizational level.\nD. Add a designated group of users to the Project Creator role at the organizational level.","poster":"AzureDP900","comment_id":"710009","timestamp":"1667415900.0"},{"timestamp":"1665035340.0","upvote_count":"3","comment_id":"687519","poster":"AwesomeGCP","comments":[{"poster":"AzureDP900","timestamp":"1667596500.0","upvote_count":"1","comment_id":"711370","content":"AD is correct"}],"content":"Selected Answer: AD\nA. Remove all users from the Project Creator role at the organizational level.\nD. Add a designated group of users to the Project Creator role at the organizational level.\n\nhttps://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints"},{"timestamp":"1659691560.0","poster":"Jeanphi72","upvote_count":"4","content":"Selected Answer: AD\nhttps://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints\nI see no way to restrict project creation with an organizational policy. If that would have been possible I would have voted for it as restrictions can be overriden in GCP.","comment_id":"642877"},{"poster":"piyush_1982","timestamp":"1658941020.0","comment_id":"638235","upvote_count":"1","content":"Selected Answer: AC\nSeems to be AC\nWhen an organization resource is created, all users in your domain are granted the Billing Account Creator and Project Creator roles by default.\nAs per the link https://cloud.google.com/resource-manager/docs/default-access-control#removing-default-roles\n\nHence A is definitely the answer.\nNow to add the project creator we need to add the designated group to the project creator role specifically."},{"poster":"absipat","content":"ad of course","timestamp":"1654919460.0","upvote_count":"1","comment_id":"614821"},{"comment_id":"349236","timestamp":"1620113940.0","upvote_count":"1","poster":"syllox","comments":[{"poster":"syllox","comment_id":"349237","content":"AD , C is a mistake it's project Editor and not creator","upvote_count":"3","timestamp":"1620114000.0"}],"content":"Ans AC also"},{"comment_id":"295970","content":"Ans : AD","poster":"DebasishLowes","timestamp":"1613930160.0","upvote_count":"4"},{"upvote_count":"4","poster":"Aniyadu","timestamp":"1609953660.0","comment_id":"261187","content":"A & D is the right answer."},{"upvote_count":"3","poster":"[Removed]","timestamp":"1603993020.0","comment_id":"208742","content":"Ans - AD"},{"poster":"genesis3k","upvote_count":"1","comment_id":"208492","comments":[],"timestamp":"1603973100.0","content":"I think AC. Because, a role is granted to user/group, rather user/group is added to a role."},{"upvote_count":"4","poster":"CHECK666","comment_id":"190203","content":"AD is the answer. There's nothing related to project creation in organization policy constraints.","timestamp":"1601454120.0"}],"answer_description":""}],"exam":{"name":"Professional Cloud Security Engineer","isBeta":false,"isImplemented":true,"numberOfQuestions":321,"isMCOnly":false,"lastUpdated":"11 Apr 2025","id":9,"provider":"Google"},"currentPage":54},"__N_SSP":true}