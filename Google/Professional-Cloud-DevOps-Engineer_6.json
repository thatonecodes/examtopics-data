{"pageProps":{"questions":[{"id":"8I4fn8Be2mVLLzuzqkna","question_id":26,"isMC":true,"answer_images":[],"question_images":[],"answer":"A","url":"https://www.examtopics.com/discussions/google/view/122340-exam-professional-cloud-devops-engineer-topic-1-question-121/","discussion":[{"content":"Selected Answer: D\nCloud Monitoring dashboards can be exported and shared using their JSON definition. The partner team can then import the JSON file into their own Cloud Monitoring environment to replicate the dashboard.","comments":[{"upvote_count":"1","comment_id":"1379919","content":"Why Not the Other Options?\n\nA. Provide the partner team with the dashboard URL.\nThe URL only works within the same Google Cloud project, so it won't allow the partner team to create a copy in their project.\n\nB. Export the metrics to BigQuery and use Looker Studio.\nThis approach adds unnecessary complexity since Cloud Monitoring already supports custom dashboards. BigQuery and Looker Studio are better suited for advanced analytics rather than Cloud Monitoring dashboards.\n\nC. Copy the Monitoring Query Language (MQL) query and send it.\nMQL queries only define metric queries, not dashboard configurations. The partner team would still need to manually recreate the entire dashboard layout.\n\nBest Practice:\nDownload the JSON file of the Cloud Monitoring dashboard and provide it to the partner team so they can import and replicate it in their environment.","timestamp":"1741596840.0","poster":"cachopo"}],"comment_id":"1379918","upvote_count":"1","poster":"cachopo","timestamp":"1741596780.0"},{"upvote_count":"2","content":"Unclear question, if you are sharing your dashboard with data in it, then you choose (A). However, if you are sharing the structure so they can create their own copy of the dashboard for their data then (D). https://cloud.google.com/monitoring/charts/dashboards#copy-dashboard","timestamp":"1722955800.0","comment_id":"1261713","poster":"surfer111"},{"timestamp":"1717742700.0","content":"Selected Answer: D\nThis allows the partner team to import the dashboard into their own Cloud Monitoring environment, ensuring they have an exact copy of the dashboard with all its configurations and metrics. This is a straightforward and reliable way to share custom dashboards within Google Cloud Monitoring. Option A doesn't grant viewing access to the partner team. They would need to create their own dashboard","poster":"winston9","comment_id":"1225937","upvote_count":"1"},{"comment_id":"1089528","upvote_count":"3","content":"Selected Answer: A\nThe recommended solution is (Option A).\n\nProvide the partner team with the dashboard URL to enable them to create a copy of the dashboard. By sharing the dashboard URL, the partner team can access and duplicate the specific Cloud Monitoring custom dashboard easily.\n\nThis method allows for a straightforward and efficient way to share the dashboard configuration without the need for additional manual steps or exporting/importing files. It ensures a seamless transfer of the custom dashboard to the partner team, enabling them to leverage the same monitoring setup for their needs.","poster":"xhilmi","timestamp":"1701879360.0"},{"content":"Selected Answer: A\nIn A they see your data and with D they their own data but using the same layout as in the dashboard you shared. So maybe A but the scope is not clear in the question...","upvote_count":"3","comment_id":"1079182","poster":"Andrei_Z","timestamp":"1700821920.0"},{"upvote_count":"2","comment_id":"1065427","content":"Selected Answer: A\nShould be A it looks like:\nhttps://cloud.google.com/monitoring/charts/share-dashboards#owner-rolesowner\n\n\"We recommend that you use Monitoring to send the URL of a dashboard to your recipients when you have that option. Monitoring identifies those recipients who might not have permission to view the dashboard and provides an option for you to grant the required permissions.\"","timestamp":"1699432260.0","poster":"lelele2023"},{"comment_id":"1060900","content":"D is answer.","poster":"mshafa","upvote_count":"2","timestamp":"1698958920.0"},{"comment_id":"1054455","timestamp":"1698315780.0","upvote_count":"2","poster":"Jason_Cloud_at","content":"Selected Answer: D\nI will go with D , I have omitted B and C , Option A is fine but atlast it says copy the dashboard, we cant copy the dashboard when shared."},{"content":"Selected Answer: A\nAnswer should be A according to this link:\nhttps://cloud.google.com/monitoring/charts/share-dashboards","timestamp":"1698007980.0","poster":"ABZ10","upvote_count":"1","comment_id":"1051095"},{"content":"Answer should be D","upvote_count":"2","comments":[{"comments":[{"timestamp":"1698315600.0","upvote_count":"2","comment_id":"1054454","content":"Sorry , my bad !! it actually works, I will go with D.","poster":"Jason_Cloud_at"}],"comment_id":"1054443","timestamp":"1698314700.0","content":"Bruh, Do you even know how JSON file looks like ?? What partners will do with just JSON file?","poster":"Jason_Cloud_at","upvote_count":"1"}],"timestamp":"1696397220.0","poster":"ManishKS","comment_id":"1024469"}],"choices":{"A":"Provide the partner team with the dashboard URL to enable the partner team to create a copy of the dashboard.","C":"Copy the Monitoring Query Language (MQL) query from the dashboard, and send the ML query to the partner team.","B":"Export the metrics to BigQuery. Use Looker Studio to create a dashboard, and share the dashboard with the partner team.","D":"Download the JSON definition of the dashboard, and send the JSON file to the partner team."},"topic":"1","unix_timestamp":1696397220,"answers_community":["A (69%)","D (31%)"],"answer_description":"","exam_id":6,"answer_ET":"A","timestamp":"2023-10-04 07:27:00","question_text":"You want to share a Cloud Monitoring custom dashboard with a partner team. What should you do?"},{"id":"796dbvFE1UT8qIyLPXmA","answer":"A","answer_images":[],"answer_description":"","isMC":true,"timestamp":"2023-10-05 10:30:00","unix_timestamp":1696494600,"answer_ET":"A","topic":"1","choices":{"A":"Save the API key in Secret Manager as a secret. Reference the secret as an environment variable in the Cloud Run application.","B":"Save the API key in Secret Manager as a secret key. Mount the secret key under the /sys/api_key directory, and decrypt the key in the Cloud Run application.","C":"Save the API key in Cloud Key Management Service (Cloud KMS) as a key. Reference the key as an environment variable in the Cloud Run application.","D":"Encrypt the API key by using Cloud Key Management Service (Cloud KMS), and pass the key to Cloud Run as an environment variable. Decrypt and use the key in Cloud Run."},"question_images":[],"exam_id":6,"question_id":27,"discussion":[{"comment_id":"1150972","timestamp":"1723716840.0","poster":"alpha_canary","content":"Selected Answer: A\nhttps://cloud.google.com/run/docs/configuring/services/secrets#access-secrets:~:text=Pass%20a%20secret%20using%20environment%20variables.%20Environment%20variables%20are%20resolved%20at%20instance%20startup%20time%2C%20so%20if%20you%20use%20this%20method%2C%20Google%20recommends%20that%20you%20pin%20the%20secret%20to%20a%20particular%20version%20rather%20than%20using%20latest.","upvote_count":"1"},{"content":"Selected Answer: A\nThe recommended solution is (option A)\n\nSave the API key in Secret Manager as a secret and reference the secret as an environment variable in the Cloud Run application. This approach aligns with Google-recommended practices for securely managing sensitive information.\n\nSecret Manager provides a centralized and secure storage for secrets, allowing you to store and retrieve the API key. Referencing the secret as an environment variable in the Cloud Run application ensures that the key remains confidential and is easily accessible without exposing it directly in the code. It enhances security by separating sensitive information from the application logic and adheres to best practices for secure credential management in a cloud environment.","timestamp":"1717715220.0","poster":"xhilmi","upvote_count":"3","comment_id":"1089883"},{"comment_id":"1065436","upvote_count":"3","content":"Selected Answer: A\nA is answer. B is wrong because: Cloud Run does not allow you to mount secrets at /dev, /proc and /sys, or on their subdirectories.","timestamp":"1715150220.0","poster":"lelele2023"},{"timestamp":"1714676580.0","content":"A is answer.","poster":"mshafa","comment_id":"1060902","upvote_count":"1"},{"upvote_count":"2","content":"Selected Answer: A\nIt should be A","poster":"Jason_Cloud_at","comment_id":"1054457","timestamp":"1714127220.0"},{"content":"Selected Answer: A\nAnswer should be A","timestamp":"1713766620.0","comment_id":"1050254","poster":"nhiguchi","upvote_count":"1"},{"timestamp":"1712305800.0","content":"A is the right answer as per my openion","comment_id":"1025429","upvote_count":"1","poster":"PrayasMohanty"}],"answers_community":["A (100%)"],"url":"https://www.examtopics.com/discussions/google/view/122490-exam-professional-cloud-devops-engineer-topic-1-question-122/","question_text":"You are building an application that runs on Cloud Run. The application needs to access a third-party API by using an API key. You need to determine a secure way to store and use the API key in your application by following Google-recommended practices. What should you do?"},{"id":"sN7iUyRnWDhKirkRRakW","timestamp":"2023-10-04 07:31:00","unix_timestamp":1696397460,"exam_id":6,"topic":"1","choices":{"D":"Use the current app-one-dev, app-one-staging, and app-one-prod projects as the scoping project for each folder.","B":"Create new scoping projects for each folder.","A":"Create a single new scoping project.","C":"Use the current app-one-prod project as the scoping project."},"question_images":["https://img.examtopics.com/professional-cloud-devops-engineer/image4.png"],"answer_ET":"B","answer":"B","answers_community":["B (100%)"],"url":"https://www.examtopics.com/discussions/google/view/122342-exam-professional-cloud-devops-engineer-topic-1-question-123/","discussion":[{"content":"Selected Answer: B\nBest practice is to use a new or empty project for scoping, so B rather than D: https://cloud.google.com/monitoring/settings#create-multi","timestamp":"1712674260.0","comment_id":"1038764","upvote_count":"8","poster":"florian_cartron"},{"timestamp":"1731095220.0","upvote_count":"1","content":"Selected Answer: B\nAgree With B","poster":"dija123","comment_id":"1208494"},{"poster":"alpha_canary","timestamp":"1723717140.0","upvote_count":"1","comment_id":"1150976","content":"Selected Answer: B\nhttps://cloud.google.com/monitoring/settings#create-multi"},{"timestamp":"1717727400.0","poster":"xhilmi","upvote_count":"2","content":"Selected Answer: B\nThe recommended solution is (option B)\n\nCreate new scoping projects for each folder. Google Cloud Monitoring dashboards allow you to scope metrics based on projects, and by creating separate scoping projects for each folder, you can effectively isolate and display metrics only from the projects within that specific folder.\n\nThis approach aligns with Google-recommended practices by providing a structured and organized way to manage and visualize metrics. Using dedicated scoping projects for each folder ensures a clean separation of monitoring data, allowing you to customize dashboards according to the specific projects within a given folder while excluding metrics from projects in other folders.","comment_id":"1089945"},{"timestamp":"1715713560.0","poster":"TereRolon","upvote_count":"1","comment_id":"1070849","content":"I thing is A\n\"Example of scoping projects and monitored projects\nAssume that your Staging and Production projects contain Compute Engine virtual machine (VM) instances. To view the metrics for all of your VMs in a single view, you create another project, AllEnvironments, and then add the Staging and Production projects as monitored projects.\"\nhttps://cloud.google.com/monitoring/settings#create-multi"},{"comment_id":"1060903","poster":"mshafa","timestamp":"1714676640.0","content":"B is best choose.","upvote_count":"1"},{"comment_id":"1054469","poster":"Jason_Cloud_at","upvote_count":"3","content":"B and D seems good answer , i would porbably go with B if the choice make me a millionaire.","timestamp":"1714128000.0"},{"timestamp":"1712307000.0","poster":"PrayasMohanty","comment_id":"1025482","upvote_count":"1","content":"For me the answer should be B \nreffer : https://cloud.google.com/monitoring/settings/multiple-projects"},{"content":"Answer should be D","poster":"ManishKS","comment_id":"1024476","timestamp":"1712208660.0","upvote_count":"1"}],"question_text":"You are currently planning how to display Cloud Monitoring metrics for your organization’s Google Cloud projects. Your organization has three folders and six projects:\n\n//IMG//\n\n\nYou want to configure Cloud Monitoring dashboards to only display metrics from the projects within one folder. You need to ensure that the dashboards do not display metrics from projects in the other folders. You want to follow Google-recommended practices. What should you do?","answer_images":[],"isMC":true,"question_id":28,"answer_description":""},{"id":"W5CQcqEqm7JB6O4QINbF","timestamp":"2023-10-04 07:32:00","discussion":[{"content":"Selected Answer: D\nhttps://cloud.google.com/iam/docs/job-functions/auditing#:~:text=Admin%20Activity%20logs.-,logging.privateLogViewer,privateLogViewer%20role%20gives%20the%20ability%20to%20view%20the%20Data%20Access%20logs.,-Once%20log%20entries","upvote_count":"2","poster":"alpha_canary","timestamp":"1723717380.0","comment_id":"1150979"},{"timestamp":"1722070800.0","comment_id":"1133259","content":"the question is wrong, the _Required log bucket is exclusively for Admin Activity logs and is not configurable for other types of logs.\nso B would be good, there is no good answer here.","poster":"ogerber","upvote_count":"1"},{"timestamp":"1718943060.0","poster":"LaxmanTiwari","comment_id":"1102212","upvote_count":"1","content":"Selected Answer: D\nThe right one"},{"content":"Selected Answer: D\nThe recommended solution is (option D)\n\nAssign the roles/logging.privateLogViewer role to a group with all the security team members. This approach follows the principle of least privilege by granting the specific role needed for read-only access to Data Access audit logs. The roles/logging.privateLogViewer role is more restrictive than roles/logging.viewer, providing access only to private logs, such as Data Access audit logs, and aligns with Google-recommended practices for securing sensitive data.\n\nBy assigning this role to a group with all security team members, you can efficiently manage and update permissions for the entire team, maintaining a centralized and organized approach to access control for the designated logs in the _Required bucket.","comment_id":"1089948","upvote_count":"2","poster":"xhilmi","timestamp":"1717727760.0"},{"timestamp":"1715788560.0","upvote_count":"1","poster":"pharao89","content":"Selected Answer: D\nD, no brainer, give access to private logs (so also access logs) to the team. Option C is partially correct, you should rather give access to a group than to individual members just to be future-proof.","comment_id":"1071751"},{"poster":"nhiguchi","content":"Selected Answer: D\nAnswer should be D","comment_id":"1050255","upvote_count":"1","timestamp":"1713766860.0"},{"content":"https://cloud.google.com/iam/docs/job-functions/auditing\nThe logging.privateLogViewer role gives the ability to view the Data Access logs.\n{\n \"role\": \"roles/logging.privateLogViewer\",\n \"members\": [\n \"group:security-team@example.com\"\n ]\nAnswer D seems correct.","upvote_count":"3","comment_id":"1042143","timestamp":"1712968440.0","poster":"activist"},{"upvote_count":"1","timestamp":"1712208720.0","comment_id":"1024479","content":"Answer should be D","poster":"ManishKS"}],"isMC":true,"answer_description":"","question_images":[],"answers_community":["D (100%)"],"question_text":"Your company’s security team needs to have read-only access to Data Access audit logs in the _Required bucket. You want to provide your security team with the necessary permissions following the principle of least privilege and Google-recommended practices. What should you do?","url":"https://www.examtopics.com/discussions/google/view/122343-exam-professional-cloud-devops-engineer-topic-1-question-124/","question_id":29,"topic":"1","answer":"D","answer_ET":"D","answer_images":[],"exam_id":6,"unix_timestamp":1696397520,"choices":{"D":"Assign the roles/logging.privateLogViewer role to a group with all the security team members.","A":"Assign the roles/logging.viewer role to each member of the security team.","B":"Assign the roles/logging.viewer role to a group with all the security team members.","C":"Assign the roles/logging.privateLogViewer role to each member of the security team."}},{"id":"WdA3aNKXP8o8etRna8uh","answers_community":["C (88%)","13%"],"answer_ET":"C","answer":"C","url":"https://www.examtopics.com/discussions/google/view/124659-exam-professional-cloud-devops-engineer-topic-1-question-125/","question_id":30,"exam_id":6,"isMC":true,"answer_description":"","answer_images":[],"choices":{"C":"Provide a Cloud Storage bucket so that third parties can upload batches of data, and provide appropriate Identity and Access Management (IAM) access to the bucket.\nCreate a Cloud Function with a google.storage.object.finalize Cloud Storage trigger. Write code so that the function can scale up a Compute Engine autoscaling managed instance group.\nUse an image pre-loaded with the data processing software that terminates the instances when processing completes.","B":"Provide a Cloud Storage bucket so that third parties can upload batches of data, and provide appropriate Identity and Access Management (IAM) access to the bucket.\nUse a standard Google Kubernetes Engine (GKE) cluster and maintain two services: one that processes the batches of data, and one that monitors Cloud Storage for new batches of data.\nStop the processing service when there are no batches of data to process.","A":"Provide a secure file transfer protocol (SFTP) server on a Compute Engine instance so that third parties can upload batches of data, and provide appropriate credentials to the server.\nCreate a Cloud Function with a google.storage.object.finalize Cloud Storage trigger. Write code so that the function can scale up a Compute Engine autoscaling managed instance group\nUse an image pre-loaded with the data processing software that terminates the instances when processing completes.","D":"Provide a Cloud Storage bucket so that third parties can upload batches of data, and provide appropriate Identity and Access Management (IAM) access to the bucket.\nUse Cloud Monitoring to detect new batches of data in the bucket and trigger a Cloud Function that processes the data.\nSet a Cloud Function to use the largest CPU possible to minimize the runtime of the processing."},"question_text":"Your team is building a service that performs compute-heavy processing on batches of data. The data is processed faster based on the speed and number of CPUs on the machine. These batches of data vary in size and may arrive at any time from multiple third-party sources. You need to ensure that third parties are able to upload their data securely. You want to minimize costs, while ensuring that the data is processed as quickly as possible. What should you do?","question_images":[],"discussion":[{"content":"D is best.\n\nC says writing code and all that could take time. Speed is key with using as much instant cloud services as possible.","upvote_count":"1","timestamp":"1727302080.0","poster":"mouthwash","comment_id":"1289176"},{"comment_id":"1265083","content":"Selected Answer: D\nD over C","poster":"6a8c7ad","timestamp":"1723542180.0","upvote_count":"1"},{"poster":"xhilmi","content":"Selected Answer: C\nThe recommended solution is (option C)\n\nProvide a Cloud Storage bucket for third parties to upload batches of data, and utilize a Cloud Function with a google.storage.object.finalize trigger to scale up a Compute Engine autoscaling managed instance group. This approach ensures secure data uploads to a Cloud Storage bucket with proper IAM access controls.\n\nThe Cloud Function, triggered upon new object finalization in the bucket, scales up a managed instance group with pre-loaded data processing software, optimizing for compute-heavy tasks. The instances terminate upon completion, minimizing costs.\n\nThis design efficiently leverages serverless and autoscaling capabilities, ensuring quick and cost-effective processing of data batches arriving at varying times from multiple sources.","comment_id":"1089952","upvote_count":"2","timestamp":"1701924900.0"},{"poster":"Andrei_Z","upvote_count":"2","comment_id":"1076297","content":"Selected Answer: C\nI would say C. GCS is not that expensive and you can set rules to archive old data. GCE is optimal for compute heavy batch jobs compared to cloud functions.","timestamp":"1700571300.0"},{"timestamp":"1698317340.0","upvote_count":"3","content":"Selected Answer: C\nI would go with C , using GCS is cost effective and secure compared to other options.\nD. Cloud function with large CPU results in high cost.","comment_id":"1054474","poster":"Jason_Cloud_at"}],"unix_timestamp":1698317340,"topic":"1","timestamp":"2023-10-26 12:49:00"}],"exam":{"isMCOnly":true,"numberOfQuestions":196,"isBeta":false,"isImplemented":true,"provider":"Google","name":"Professional Cloud DevOps Engineer","lastUpdated":"11 Apr 2025","id":6},"currentPage":6},"__N_SSP":true}