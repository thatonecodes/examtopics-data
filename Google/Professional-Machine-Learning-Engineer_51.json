{"pageProps":{"questions":[{"id":"euUCvwiQ8Kh8U7jG37RX","timestamp":"2021-07-06 06:43:00","topic":"1","exam_id":13,"url":"https://www.examtopics.com/discussions/google/view/57248-exam-professional-machine-learning-engineer-topic-1-question/","question_images":[],"question_text":"Your team is building a convolutional neural network (CNN)-based architecture from scratch. The preliminary experiments running on your on-premises CPU-only infrastructure were encouraging, but have slow convergence. You have been asked to speed up model training to reduce time-to-market. You want to experiment with virtual machines (VMs) on Google Cloud to leverage more powerful hardware. Your code does not include any manual device placement and has not been wrapped in Estimator model-level abstraction. Which environment should you train your model on?","answer_images":[],"question_id":251,"answer":"C","answer_ET":"C","answer_description":"","discussion":[{"upvote_count":"16","comment_id":"410216","content":"ANS: C\n\nto support CNN, you should use GPU. \nfor preliminary experiment, pre-installed pkgs/libs are good choice.\n\nhttps://cloud.google.com/deep-learning-vm/docs/cli#creating_an_instance_with_one_or_more_gpus\nhttps://cloud.google.com/deep-learning-vm/docs/introduction#pre-installed_packages","poster":"celia20200410","timestamp":"1626781320.0"},{"poster":"Paul_Dirac","content":"Code without manual device placement => default to CPU if TPU is present or to the lowest order GPU if multiple GPUs are present. => Not A, B.\nD: already using CPU and needing GPU for CNN.\nAns: C","upvote_count":"13","timestamp":"1627781640.0","comment_id":"418074"},{"comment_id":"1367648","poster":"RyanTan","content":"Selected Answer: A\nC is wrong because n1‐standard‐2 is too small for GPUs.","timestamp":"1741496040.0","upvote_count":"1"},{"timestamp":"1740322680.0","content":"Selected Answer: C\nswapping CPU for GPU will speed up the training of a CNN a lot.\nUsing preinstalled librearies is incurring in less risks which means speeding up time-to-market","comment_id":"1360524","upvote_count":"1","poster":"IrribarraC"},{"comment_id":"1319919","poster":"Pau1234","timestamp":"1732913820.0","content":"Selected Answer: A\nOption A is better because it is better to go with 1 TPU than 8 GPUs, especially when you don't have any manual placements.","upvote_count":"2"},{"upvote_count":"1","content":"Selected Answer: C\nC) GPU and all pre-installed libraries.","comment_id":"1225660","poster":"PhilipKoku","timestamp":"1717694340.0"},{"upvote_count":"1","content":"Selected Answer: C\nAgree with celia20200410 - C","timestamp":"1713598320.0","poster":"gscharly","comment_id":"1198995"},{"poster":"Sum_Sum","comment_id":"1071857","content":"Selected Answer: C\nAgree with celia20200410 - C","timestamp":"1700079900.0","upvote_count":"2"},{"timestamp":"1700067420.0","content":"Selected Answer: D\nkeyword: Your code does not include any manual device placement and has not been wrapped in Estimator model-level abstraction.","comment_id":"1071666","poster":"Mickey321","upvote_count":"1"},{"poster":"Liting","content":"Selected Answer: C\nShould use the deep learning VM with GPU. \nTPU should be selected only if necessary, coz it incurs high cost. GPU in this case is enough.","upvote_count":"1","timestamp":"1688737500.0","comment_id":"945736"},{"content":"Selected Answer: C\nWent with C","poster":"M25","comment_id":"892732","upvote_count":"1","timestamp":"1683608880.0"},{"upvote_count":"1","poster":"Melampos","content":"Selected Answer: A\nthinking in fastest way","comment_id":"875146","timestamp":"1681945920.0"},{"poster":"SergioRubiano","upvote_count":"1","timestamp":"1680262860.0","comment_id":"856987","content":"Selected Answer: C\nYou should use GPU."},{"upvote_count":"3","content":"Selected Answer: D\nCritical sentence: Your code does not include any manual device placement and has not been wrapped in Estimator model-level abstraction.\n\nSo only answer we have. it's D.","timestamp":"1677494820.0","comment_id":"823565","poster":"BenMS"},{"upvote_count":"3","poster":"shankalman717","timestamp":"1677048180.0","content":"Critical sentece: Your code does not include any manual device placement and has not been wrapped in Estimator model-level abstraction.\n\nSo only answer we have. it's D.","comment_id":"817539","comments":[{"content":"Option D provides a more powerful CPU but does not include a GPU, which may not be optimal for deep learning training.","comment_id":"941976","upvote_count":"2","poster":"tavva_prudhvi","timestamp":"1688397660.0"}]},{"content":"Selected Answer: C\nIt's C.","upvote_count":"1","timestamp":"1672922280.0","comment_id":"766615","poster":"ares81"},{"comment_id":"651261","content":"\"has not been wrapped in Estimator model-level abstraction\"\nHow you can use GPU?\nD in my opinion, E-family using for high CPU tasks","timestamp":"1661346480.0","poster":"suresh_vn","upvote_count":"3"},{"timestamp":"1657527060.0","poster":"Mohamed_Mossad","upvote_count":"1","comment_id":"629911","content":"Selected Answer: C\nAnswer C\n========\nExplanation\n\"speed up model training\" will make us biased towards GPU,TPU options\nby options eliminations we may need to stay away of any manual installations , so using preconfigered deep learning will speed up time to market"},{"poster":"mmona19","content":"Selected Answer: A\nthe question is asking speed up time to market which can happen if model trains fast. so TPU VM can be a solution. https://cloud.google.com/blog/products/compute/introducing-cloud-tpu-vms option A. if question asks most managed way than answer is deep learning container with everything installed. C","timestamp":"1649951880.0","comments":[{"upvote_count":"2","timestamp":"1688397720.0","comments":[{"upvote_count":"2","timestamp":"1695365640.0","comment_id":"1013713","poster":"maukaba","content":"Instead If you have a single GPU, TensorFlow will use this accelerator to speed up model training with no extra work on your part: https://codelabs.developers.google.com/vertex-p2p-distributed#2\nNormally you don't use just one TPU and for both GPUs and TPUs it is necessary to define a distributed training strategy: https://www.tensorflow.org/guide/distributed_training"}],"poster":"tavva_prudhvi","comment_id":"941978","content":"Option A with 1 TPU and option B with 8 GPUs might provide even faster training, but since the code does not include manual device placement, it may not utilize all the available resources effectively."}],"upvote_count":"1","comment_id":"585886"},{"content":"C is correct","poster":"NamitSehgal","comment_id":"516406","upvote_count":"1","timestamp":"1641288780.0"},{"content":"Selected Answer: C\nC is correct.","comment_id":"510168","upvote_count":"2","timestamp":"1640595660.0","poster":"GCP_Guru"},{"poster":"JobQ","content":"I think is C.","timestamp":"1640037480.0","comment_id":"505695","upvote_count":"1"},{"comment_id":"399652","poster":"inder0007","content":"I think B will give the best results in this one. with new tensorflow u don't really need to change a lot to move to GPU based machines","timestamp":"1625546580.0","upvote_count":"1"}],"unix_timestamp":1625546580,"isMC":true,"answers_community":["C (57%)","A (24%)","D (19%)"],"choices":{"D":"A Deep Learning VM with more powerful CPU e2-highcpu-16 machines with all libraries pre-installed.","C":"A Deep Learning VM with an n1-standard-2 machine and 1 GPU with all libraries pre-installed.","B":"AVM on Compute Engine and 8 GPUs with all dependencies installed manually.","A":"AVM on Compute Engine and 1 TPU with all dependencies installed manually."}},{"id":"H174hDPoUTsRD4zw8xje","answers_community":["C (100%)"],"timestamp":"2021-06-18 16:05:00","isMC":true,"answer_description":"","topic":"1","answer_images":[],"answer_ET":"C","question_text":"You work on a growing team of more than 50 data scientists who all use AI Platform. You are designing a strategy to organize your jobs, models, and versions in a clean and scalable way. Which strategy should you choose?","question_id":252,"answer":"C","url":"https://www.examtopics.com/discussions/google/view/55572-exam-professional-machine-learning-engineer-topic-1-question/","question_images":[],"choices":{"A":"Set up restrictive IAM permissions on the AI Platform notebooks so that only a single user or group can access a given instance.","C":"Use labels to organize resources into descriptive categories. Apply a label to each created resource so that users can filter the results by label when viewing or monitoring the resources.","D":"Set up a BigQuery sink for Cloud Logging logs that is appropriately filtered to capture information about AI Platform resource usage. In BigQuery, create a SQL view that maps users to the resources they are using","B":"Separate each data scientist's work into a different project to ensure that the jobs, models, and versions created by each data scientist are accessible only to that user."},"discussion":[{"poster":"chohan","timestamp":"1624025100.0","upvote_count":"14","content":"I think should be C,\nAs IAM roles are given to the entire AI Notebook resource, not to a specific instance.","comment_id":"384880"},{"content":"ans: c \n\nhttps://cloud.google.com/ai-platform/prediction/docs/resource-labels#overview_of_labels\nYou can add labels to your AI Platform Prediction jobs, models, and model versions, then use those labels to organize resources into categories when viewing or monitoring the resources.\n\nFor example, you can label jobs by team (such as engineering or research) and development phase (prod or test), then filter the jobs based on the team and phase.\n\nLabels are also available on operations, but these labels are derived from the resource to which the operation applies. You cannot add or update labels on an operation.\n\nA label is a key-value pair, where both the key and the value are custom strings that you supp","comment_id":"410180","comments":[{"poster":"vivid_cucumber","comment_id":"477225","timestamp":"1636763580.0","upvote_count":"1","content":"I read through this page: https://cloud.google.com/ai-platform/prediction/docs/sharing-models. This one sounds more like A. Is isn't that correct? I am not quite sure.","comments":[{"timestamp":"1636763880.0","content":"or maybe A is not correct because \"sharing models using IAM\" only applies to \"manage access to resource\" but this question is more like asking to \"organize jobs, models, and versions\". not sure if my understanding is right or not.","upvote_count":"1","poster":"vivid_cucumber","comment_id":"477226"}]}],"poster":"celia20200410","upvote_count":"11","timestamp":"1626778440.0"},{"upvote_count":"1","content":"B. Setting up different resources in separate projects can help separate the use of resources.\nFrom the official guide book","poster":"furix","comment_id":"1280961","timestamp":"1725892020.0","comments":[{"upvote_count":"1","content":"Creating separate projects for each data scientist would lead to significant overhead in managing resources and permissions across numerous projects, making it harder to scale and collaborate.","timestamp":"1730138100.0","poster":"desertlotus1211","comment_id":"1304075"},{"content":"I thought the same, but... se my answer below","comment_id":"1304077","timestamp":"1730138160.0","poster":"desertlotus1211","upvote_count":"1"}]},{"comment_id":"1225665","upvote_count":"1","timestamp":"1717694460.0","content":"Selected Answer: C\nC) labels","poster":"PhilipKoku"},{"comment_id":"1071859","poster":"Sum_Sum","content":"C\nAlthough there are some questions where setting up a logging sink to BQ is the answer.","upvote_count":"1","timestamp":"1700080140.0"},{"timestamp":"1683608940.0","content":"Selected Answer: C\nWent with C","comment_id":"892733","upvote_count":"1","poster":"M25"},{"poster":"BenMS","timestamp":"1677495600.0","content":"Selected Answer: C\nRestricting access is not scalable and creates silos - better to document sharable resources through tagging, hence C.","upvote_count":"1","comment_id":"823576"},{"comment_id":"741146","poster":"hiromi","timestamp":"1670694180.0","upvote_count":"1","content":"Selected Answer: C\nC\nResource tagging/labeling is the best way to manage ML resources for medium/big data science teams."},{"timestamp":"1642621500.0","content":"Selected Answer: C\nhttps://cloud.google.com/ai-platform/prediction/docs/resource-labels#overview_of_labels\n(A) applies only to notebooks wich is not enough","poster":"ggorzki","comment_id":"527863","upvote_count":"4"}],"exam_id":13,"unix_timestamp":1624025100},{"id":"vVSayJQMtshMcMSSBcOS","unix_timestamp":1623416940,"answer":"B","question_images":[],"url":"https://www.examtopics.com/discussions/google/view/55099-exam-professional-machine-learning-engineer-topic-1-question/","answers_community":["B (93%)","7%"],"choices":{"D":"Ensure that the selected GPU has enough GPU memory for the workload.","B":"Ensure that the required GPU is available in the selected region.","A":"Ensure that you have GPU quota in the selected region.","C":"Ensure that you have preemptible GPU quota in the selected region."},"topic":"1","answer_ET":"B","exam_id":13,"question_text":"You are training a deep learning model for semantic image segmentation with reduced training time. While using a Deep Learning VM Image, you receive the following error: The resource 'projects/deeplearning-platforn/zones/europe-west4-c/acceleratorTypes/nvidia-tesla-k80' was not found. What should you do?","answer_images":[],"answer_description":"","question_id":253,"discussion":[{"upvote_count":"23","timestamp":"1626778560.0","comment_id":"410181","content":"ANS: B \nhttps://cloud.google.com/deep-learning-vm/docs/troubleshooting#resource_not_found \n\nhttps://cloud.google.com/compute/docs/gpus/gpu-regions-zones \n\nResource not found\nSymptom: - The resource 'projects/deeplearning-platform/zones/europe-west4-c/acceleratorTypes/nvidia-tesla-k80' was not found\n\nProblem: You are trying to create an instance with one or more GPUs in a region where GPUs are not available (for example, an instance with a K80 GPU in europe-west4-c).\n\nSolution: To determine which region has the required GPU, see GPUs on Compute Engine.","poster":"celia20200410"},{"timestamp":"1623416940.0","content":"it is B, the error message relates to Quota is different:\nhttps://cloud.google.com/deep-learning-vm/docs/troubleshooting#resource_not_found","comment_id":"379812","upvote_count":"8","poster":"stomcarlo"},{"comment_id":"1225668","upvote_count":"1","timestamp":"1717694520.0","poster":"PhilipKoku","content":"Selected Answer: B\nB) GPUs are only available in specific regions and zones"},{"upvote_count":"1","comment_id":"1088385","timestamp":"1701772080.0","content":"Selected Answer: B\nNot all resources can be found in any region. Therefore - B","poster":"fragkris"},{"poster":"abhay669","upvote_count":"1","timestamp":"1701110340.0","content":"Selected Answer: B\nIt is clearly mentioned here: https://cloud.google.com/deep-learning-vm/docs/troubleshooting","comment_id":"1081878"},{"timestamp":"1700080200.0","poster":"Sum_Sum","content":"Selected Answer: B\nB - because it's \"cant be found\"","upvote_count":"1","comment_id":"1071861"},{"poster":"M25","content":"Selected Answer: B\nWent with B","comment_id":"892734","upvote_count":"1","timestamp":"1683608940.0"},{"poster":"BenMS","comment_id":"823661","timestamp":"1677501360.0","content":"Selected Answer: B\nThe error says the resource was not found - hence B.\nIf quota was the problem (A) then you'd see a different error message.","upvote_count":"2"},{"comment_id":"741151","content":"Selected Answer: B\nB obviously","timestamp":"1670694420.0","upvote_count":"2","poster":"hiromi"},{"poster":"_luigi_","content":"Selected Answer: B\nThe resource is not found because it doesn't exist in the region.","upvote_count":"3","timestamp":"1650375300.0","comment_id":"588198"},{"content":"Selected Answer: A\nthe question is asking what should you do not why is the error.\nAnswer should be A. if you get that exception, make sure to check your limit for instance before running the job.","timestamp":"1649952060.0","poster":"mmona19","comments":[{"poster":"desertlotus1211","content":"wrong - its a resource availability error.","upvote_count":"1","timestamp":"1730138340.0","comment_id":"1304080"}],"comment_id":"585888","upvote_count":"1"},{"poster":"ggorzki","timestamp":"1642621680.0","content":"Selected Answer: B\nhttps://cloud.google.com/deep-learning-vm/docs/troubleshooting#resource_not_found","upvote_count":"2","comment_id":"527865"}],"isMC":true,"timestamp":"2021-06-11 15:09:00"},{"id":"vca2F08EPNVFaWTHuVo7","question_id":254,"question_images":["https://www.examtopics.com/assets/media/exam-media/03841/0002900001.png"],"answer_images":[],"answer_description":"","timestamp":"2021-07-06 06:49:00","answers_community":["B (78%)","A (22%)"],"discussion":[{"poster":"rc380","content":"I think since we are predicting political leaning of authors, perhaps distributing authors make more sense? (B)","comment_id":"425081","timestamp":"1629011340.0","comments":[{"upvote_count":"7","poster":"sensev","content":"Agree it should be B. Since every author has his/her distinct style, splitting different text from the same author across different set could result in data label leakage.","timestamp":"1629136020.0","comments":[{"timestamp":"1630761840.0","comment_id":"439171","comments":[{"timestamp":"1632197520.0","content":"it is the political affiliation from a text, but to whom belong that text?\nThe statement clearly says ... Predict political affiliation of authors based on articles they have written. Hence the political affiliation is for each author according to the text he wrote.","comment_id":"448624","poster":"jk73","upvote_count":"2"}],"poster":"dxxdd7","upvote_count":"1","content":"I don't agree as we want to know the political affiliation from a text and not based on an author. I think A is better"}],"comment_id":"425941"},{"upvote_count":"12","content":"Exactly! I also consider is B\nCheck this out!\nIf we just put inside the Training set , Validation set and Test set , randomly Text, Paragraph or sentences the model will have the ability to learn specific qualities about The Author's use of language beyond just his own articles. Therefore the model will mixed up different opinions.\nRather if we divided things up a the author level, so that given authors were only on the training data, or only in the test data or only in the validation data. The model will find more difficult to get a high accuracy on the test validation (What is correct and have more sense!). Because it will need to really focus in author by author articles rather than get a single political affiliation based on a bunch of mixed articles from different authors.\n\nhttps://developers.google.com/machine-learning/crash-course/18th-century-literature","comment_id":"448646","timestamp":"1632199560.0","poster":"jk73"}],"upvote_count":"20"},{"timestamp":"1625546940.0","content":"Should be A, we are trying to get a label on the entire text so only A makes sense","comment_id":"399656","poster":"inder0007","comments":[{"comment_id":"460791","timestamp":"1633985280.0","upvote_count":"5","poster":"GogoG","content":"Correct answer is B - https://developers.google.com/machine-learning/crash-course/18th-century-literature","comments":[{"poster":"Dunnoth","comment_id":"809014","content":"This is a known study. if you use A, the moment a new author is given in a test set the accuracy is waay low than what your metrics might suggest. To have realistic evaluation results it should be B. Also note that the label is for the \"authour\" not a text.","timestamp":"1676427120.0","upvote_count":"1"}]}],"upvote_count":"8"},{"content":"Selected Answer: A\nI think A. The B option training set would not contain text from authors supporting party B","upvote_count":"2","comment_id":"1321304","poster":"chibuzorrr","timestamp":"1733216340.0"},{"timestamp":"1717694820.0","comment_id":"1225675","poster":"PhilipKoku","content":"Selected Answer: B\nB) Authors","upvote_count":"1"},{"timestamp":"1716743760.0","upvote_count":"1","comment_id":"1219072","content":"Selected Answer: B\nWe have divide / split at author level. Other wise model will used text to author relationship but we want to find text to political affiliation relation ship. While prediction we already know text to author relation but we want to find text to political relation (and therefore author to political relation is implied.","poster":"girgu"},{"timestamp":"1688398080.0","upvote_count":"3","poster":"tavva_prudhvi","comment_id":"941984","content":"Selected Answer: B\nThis is the best approach as it ensures that the data is distributed in a way that is representative of the overall population. By randomly distributing authors across the subsets, we ensure that each subset has a similar distribution of political affiliations. This helps to minimize bias and increases the likelihood that our model will generalize well to new data.\n\nDistributing texts randomly or by sentences or paragraphs may result in subsets that are biased towards a particular political affiliation. This could lead to overfitting and poor generalization performance. Therefore, it is important to distribute the data in a way that maintains the overall distribution of political affiliations across the subsets."},{"upvote_count":"1","comment_id":"892735","timestamp":"1683608940.0","content":"Selected Answer: B\nWent with B","poster":"M25"},{"content":"Selected Answer: B\nhttps://cloud.google.com/automl-tables/docs/prepare#split\nhttps://developers.google.com/machine-learning/crash-course/18th-century-literature","upvote_count":"1","poster":"John_Pongthorn","comment_id":"810313","timestamp":"1676527800.0"},{"timestamp":"1675863120.0","upvote_count":"1","poster":"enghabeth","content":"Selected Answer: B\nAns B\nThe model is to predict which political party the author belongs to, not which political party the text belongs to... You do not have the information of the political party of each text, you are assuming that the texts are associated with the political party of the author.","comment_id":"802061"},{"timestamp":"1662360000.0","content":"Selected Answer: A\nlabel is party, feature is text","upvote_count":"2","poster":"bL357A","comment_id":"659804"},{"content":"IMO, B is correct\nA,C,D label leakaged","comment_id":"645295","timestamp":"1660198380.0","poster":"suresh_vn","upvote_count":"1"},{"content":"Selected Answer: B\nhttps://developers.google.com/machine-learning/crash-course/18th-century-literature\nSplit by authors, otherwise there will be data leakage - the model will get the ability to learn author specific use of language","comment_id":"527877","timestamp":"1642622700.0","poster":"ggorzki","upvote_count":"6"},{"upvote_count":"1","content":"B I agree","comment_id":"516417","poster":"NamitSehgal","timestamp":"1641289440.0"},{"comment_id":"505701","upvote_count":"2","content":"I already saw the video in: https://developers.google.com/machine-learning/crash-course/18th-century-literature\n\nBased on this video I concluded that the answer is A. What answer B is saying is that you will have Author B's texts in the training set, Author A's texts in the testing set and Author C's texts in the validation set. According to the video B is incorrect.\n\nWe want to have texts from author A in the training, testing and validation set. So A is correct. I think most people are choosing B because the word \"author\" but let's be careful.","poster":"JobQ","timestamp":"1640038380.0","comments":[{"content":"I though the same initially, but no..We'd want texts from author A in the training, testing and validation set if the task was to predict the author from a text (meaning, if the label was the author..right? You train the model to learn the style of text and connect it to an author. You'd need new texts from the same author in the test and validation sets, to see if the model is able to recognize him/her). HERE, the task is to predict political affiliation from a text of an author. The author is given. In the test and validation sets you need new authors, to see wether the model is able to guess their political affiliation. So you would do 80 authors (and corresponding texts) for training, 10 different authors for validation, and 10 different ones for test.","timestamp":"1646820180.0","upvote_count":"5","poster":"giaZ","comment_id":"563943"}]},{"comment_id":"452620","content":"Partition by author - there is an actual example in Coursera 'Production ML systems' course","poster":"pddddd","upvote_count":"1","timestamp":"1632762480.0"},{"timestamp":"1632002280.0","upvote_count":"4","content":"I think it is B.\n--\nYour test data includes data from populations that will not be represented in production.\n\nFor example, suppose you are training a model with purchase data from a number of stores. You know, however, that the model will be used primarily to make predictions for stores that are not in the training data. To ensure that the model can generalize to unseen stores, you should segregate your data sets by stores. In other words, your test set should include only stores different from the evaluation set, and the evaluation set should include only stores different from the training set.\nhttps://cloud.google.com/automl-tables/docs/prepare#ml-use","comment_id":"447290","poster":"Macgogo"},{"comment_id":"441726","timestamp":"1631155020.0","upvote_count":"1","comments":[{"poster":"george_ognyanov","timestamp":"1634204400.0","content":"Have a look at the link the other have already provided twice. Splitting sentence by sentence is literally mentioned in said video as a bad example and something we should not do in this case.","comment_id":"461942","upvote_count":"1"}],"poster":"Danny2021","content":"Should be D. Please see the dataset provided, it is based on the text / paragraphs."}],"choices":{"B":"Distribute authors randomly across the train-test-eval subsets: (*) Train set: [TextA1, TextA2, TextD1, TextD2, ...] Test set: [TextB1, TextB2, ...] Eval set: [TexC1,TextC2 ...]","C":"Distribute sentences randomly across the train-test-eval subsets: Train set: [SentenceA11, SentenceA21, SentenceB11, SentenceB21, SentenceC11, SentenceD21 ...] Test set: [SentenceA12, SentenceA22, SentenceB12, SentenceC22, SentenceC12, SentenceD22 ...] Eval set: [SentenceA13, SentenceA23, SentenceB13, SentenceC23, SentenceC13, SentenceD31 ...]","D":"Distribute paragraphs of texts (i.e., chunks of consecutive sentences) across the train-test-eval subsets: Train set: [SentenceA11, SentenceA12, SentenceD11, SentenceD12 ...] Test set: [SentenceA13, SentenceB13, SentenceB21, SentenceD23, SentenceC12, SentenceD13 ...] Eval set: [SentenceA11, SentenceA22, SentenceB13, SentenceD22, SentenceC23, SentenceD11 ...]","A":"Distribute texts randomly across the train-test-eval subsets: Train set: [TextA1, TextB2, ...] Test set: [TextA2, TextC1, TextD2, ...] Eval set: [TextB1, TextC2, TextD1, ...]"},"url":"https://www.examtopics.com/discussions/google/view/57249-exam-professional-machine-learning-engineer-topic-1-question/","isMC":true,"answer":"B","question_text":"Your team is working on an NLP research project to predict political affiliation of authors based on articles they have written. You have a large training dataset that is structured like this:\n//IMG//\n\nYou followed the standard 80%-10%-10% data distribution across the training, testing, and evaluation subsets. How should you distribute the training examples across the train-test-eval subsets while maintaining the 80-10-10 proportion?","answer_ET":"B","topic":"1","exam_id":13,"unix_timestamp":1625546940},{"id":"LpaXGMmVigAgHlVkOyZd","topic":"1","question_text":"Your team has been tasked with creating an ML solution in Google Cloud to classify support requests for one of your platforms. You analyzed the requirements and decided to use TensorFlow to build the classifier so that you have full control of the model's code, serving, and deployment. You will use Kubeflow pipelines for the ML platform. To save time, you want to build on existing resources and use managed services instead of building a completely new model. How should you build the classifier?","discussion":[{"timestamp":"1643304240.0","upvote_count":"29","poster":"arbik","comment_id":"415560","content":"ANS: C as you want to have full control of the model code."},{"comments":[{"content":"the model cannot work as-is as the classes to predict will likely not be the same; we need to use transfer learning to retrain the last layer and adapt it to the classes we need, hence C","upvote_count":"6","comment_id":"459871","poster":"ms_lemon","timestamp":"1649563860.0"},{"content":"While D is very close for me, I think there are 2 giveaways here: \n\"To save time, you want to build on existing resources\" - transfer learning \n\"instead of building a completely new model\" - answer D leaves the model as is \n\nANS C:","poster":"george_ognyanov","comment_id":"459658","timestamp":"1649512020.0","upvote_count":"3"}],"comment_id":"409278","upvote_count":"11","timestamp":"1642568400.0","poster":"Celia20210714","content":"ANS: D \n\nhttps://cloud.google.com/ai-platform/training/docs/algorithms \n- to use TensorFlow \n- to build on existing resources\n- to use managed services"},{"upvote_count":"1","timestamp":"1733513340.0","content":"Selected Answer: C\nC) Transfer learning","poster":"PhilipKoku","comment_id":"1225679"},{"poster":"M25","timestamp":"1699513800.0","upvote_count":"3","content":"Selected Answer: C\nWent with C","comment_id":"892736"},{"comment_id":"809026","upvote_count":"1","poster":"Dunnoth","content":"Selected Answer: C\nUsage of Tensorflow, can build a simple model by using a sentence embedding and a single layer classifier.","timestamp":"1692059160.0"},{"timestamp":"1691521740.0","poster":"enghabeth","comment_id":"802561","upvote_count":"1","content":"Selected Answer: D\nyou don't need transfer learning in this case"},{"timestamp":"1670354220.0","poster":"Mohamed_Mossad","upvote_count":"2","comment_id":"612454","content":"Selected Answer: C\n- \"You analyzed the requirements and decided to use TensorFlow\" this will make choices to reduce to C and D\n- \" so that you have full control of the model's code \" will make us choose C"},{"comment_id":"599272","content":"Selected Answer: C\nAnswer is C.","poster":"David_ml","timestamp":"1668030900.0","upvote_count":"1"},{"content":"According to me it is B.\nA is not correct as it uses an API call only and we won't build the system on existing resources.\nC & D I do not see in AI Platform (Vertex AI) an established text classification that can be used.\nThe B answer is the right one, you have the labeled data, you need to remove the custom TF code and build a classifier with AutoML Natural Language","comments":[{"upvote_count":"1","timestamp":"1668030840.0","content":"B is wrong. question says \" you have full control of the model's code\". You don't have full control of automl code. The right answer is C.","comment_id":"599271","poster":"David_ml"}],"comment_id":"584707","upvote_count":"1","timestamp":"1665577020.0","poster":"MasterMath"},{"timestamp":"1662711480.0","upvote_count":"3","content":"Selected Answer: C\n\"full control of the model's code, serving, and deployment\": Not A nor B.\nand \"you want to build on existing resources and use managed services\": Not D (that's \"as-is\") You want transfer learning.","poster":"giaZ","comment_id":"563950"},{"upvote_count":"1","comment_id":"516419","poster":"NamitSehgal","timestamp":"1656920820.0","content":"Cis correct"},{"timestamp":"1649511780.0","upvote_count":"1","comment_id":"459653","content":"ANS: C according to me as well. As arbik said, full control, custom model are give aways.","poster":"george_ognyanov"}],"answers_community":["C (92%)","8%"],"timestamp":"2021-07-19 05:00:00","choices":{"B":"Use AutoML Natural Language to build the support requests classifier.","A":"Use the Natural Language API to classify support requests.","D":"Use an established text classification model on AI Platform as-is to classify support requests.","C":"Use an established text classification model on AI Platform to perform transfer learning."},"answer_description":"","answer":"C","exam_id":13,"answer_ET":"C","answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/58146-exam-professional-machine-learning-engineer-topic-1-question/","isMC":true,"question_id":255,"question_images":[],"unix_timestamp":1626663600}],"exam":{"name":"Professional Machine Learning Engineer","isMCOnly":true,"id":13,"isImplemented":true,"provider":"Google","lastUpdated":"11 Apr 2025","isBeta":false,"numberOfQuestions":304},"currentPage":51},"__N_SSP":true}