{"pageProps":{"questions":[{"id":"EwBHvQxCDpZcASyUsoqS","isMC":true,"exam_id":1,"unix_timestamp":1585024380,"question_text":"You are the organization and billing administrator for your company. The engineering team has the Project Creator role on the organization. You do not want the engineering team to be able to link projects to the billing account. Only the finance team should be able to link a project to a billing account, but they should not be able to make any other changes to projects. What should you do?","url":"https://www.examtopics.com/discussions/google/view/17333-exam-associate-cloud-engineer-topic-1-question-59-discussion/","answer_images":[],"answers_community":["C (55%)","A (43%)","1%"],"question_id":241,"answer_description":"","answer_ET":"C","topic":"1","timestamp":"2020-03-24 05:33:00","choices":{"B":"Assign the engineering team only the Billing Account User role on the billing account.","A":"Assign the finance team only the Billing Account User role on the billing account.","C":"Assign the finance team the Billing Account User role on the billing account and the Project Billing Manager role on the organization.","D":"Assign the engineering team the Billing Account User role on the billing account and the Project Billing Manager role on the organization."},"question_images":[],"discussion":[{"content":"Option A is correct, as we don't want the engineering team to link projects to billing account and want only the Finance team. Billing Account User role will help to link projects to the billing account...","poster":"Bharathy","timestamp":"1585024380.0","comments":[{"poster":"BobbyFlash","upvote_count":"8","comment_id":"465440","content":"I would also go with A. I would think they are trying to get a quick answer from you as \"Billing Administrator\": engineering team already has the project creator role; you just would want finance team to link (and only) link projects to billing accounts, nothing else. Maybe the key phrase here is \"but they should not be able to make any other changes to projects\" and that would include the action of unlinking projects.","timestamp":"1634776320.0"},{"timestamp":"1623128520.0","upvote_count":"1","content":"Billing Account User also enables the user to make changes in resources.","poster":"Hasaaaan","comment_id":"377230"},{"upvote_count":"3","content":"Billing Account User Role when granted in combination with the Project Billing Manager role, the two roles allow a user to link and unlink projects on the billing account on which the Billing Account User role is granted","timestamp":"1656907560.0","poster":"pspandher","comment_id":"626834"},{"upvote_count":"11","content":"Option A makes the most sense since Billing Account User can link projects to the billing account and the question reinforces principle of least privilege. Source: https://cloud.google.com/billing/docs/how-to/billing-access","poster":"mwwoodm","timestamp":"1599555420.0","comments":[{"comment_id":"1212890","upvote_count":"1","poster":"Nikki2424","content":"Yes, but in combination with Project Billing Manager. Also these two roles won't grant rights on any other resources, which is also intended in the question.","timestamp":"1715949600.0"}],"comment_id":"175749"}],"comment_id":"67442","upvote_count":"91"},{"upvote_count":"64","comment_id":"99370","content":"for me is C:\nhttps://cloud.google.com/billing/docs/how-to/modify-project#permissions_required_for_this_task_2\n\"Roles with adequate permissions to perform this task:\n * Project Owner or Project Billing Manager on the project, AND Billing Account Administrator or Billing Account User for the target Cloud Billing account.\"","timestamp":"1590935880.0","comments":[{"timestamp":"1727943180.0","upvote_count":"1","comment_id":"1292708","content":"Correct","poster":"sarjan"},{"comments":[{"comment_id":"692701","comments":[{"upvote_count":"4","content":"Are you blind ? you posted link where its clearly stated in billing account user description: (associate projects with the organization's billing account for all projects in the organization)\n\nSo you literarly posted link with clarification that answer A is correct.\nanswer C will give finance team additional permission to unlink billing account from projects and question clearly states that finance team should not be able to make any other changes to projects so C without any kind of doubt is wrong.","comment_id":"709905","timestamp":"1667402700.0","comments":[{"content":"Billing Account User\nPrincipal: Service account that is used for automating project creation.\nIt is for service account, so C is correct","poster":"izekc","upvote_count":"1","timestamp":"1672402860.0","comment_id":"761898"}],"poster":"[Removed]"},{"content":"\"Project Billing Manager does not allow to make any changes to projects. It's just about linking+unlinking projects to billing accounts\"\n\nCorrect, but the problem states \"... You do not want the engineering team to be able to link projects to the billing account.\" So in that case, wouldn't it be option A?","timestamp":"1681904760.0","upvote_count":"2","comment_id":"874569","poster":"Jake500"}],"timestamp":"1665554040.0","content":"Project Billing Manager does not allow to make any changes to projects. It's just about linking+unlinking projects to billing accounts\n\nOn the other hand, the single role \"billing account user\" does not grant any right to view projects. Even less likely to link them to any billing account. (see https://cloud.google.com/iam/docs/job-functions/billing \"The Billing Account User role gives the service account the permissions to enable billing (associate projects with the organization's billing account for all projects in the organization) and thereby permit the service account to enable APIs that require billing to be enabled.\"). Thus A is not the correct answer.\n\nThe right answer is C, without any kind of doubt","poster":"Robertolo","upvote_count":"4"}],"upvote_count":"3","content":"The question states that the finance group should not be able to make changes to existing projects. Granting the finance team organizational level Billing Account Administrator will allow them to make changes to other projects. C cannot be correct.","timestamp":"1646028900.0","poster":"obeythefist","comment_id":"557893"},{"poster":"fracila","content":"We are assigning the finance team the Billing Account User role on the billing account, which allows them to create new projects linked to the billing account on which the role is granted. We are also assigning them the Project Billing Manager role on the organization (trickles down to the project as well) which lets them attach the project to the billing account, but does not grant any rights over resources.","upvote_count":"4","timestamp":"1668784860.0","comment_id":"721357"}],"poster":"measme"},{"poster":"jmotisariya","content":"Selected Answer: C\nCorrect Answer Option C. Assign the finance team the Billing Account User role on the billing account and the Project Billing Manager role on the organization.\n\nExplanation:\nThe Billing Account User role allows users to view and link projects to a billing account.\nThe Project Billing Manager role allows users to manage billing for projects but does not grant broader project management permissions.\nSince the goal is to ensure only the finance team can link projects to the billing account, they need both roles.\nThe engineering team should not have billing-related roles, ensuring they cannot link projects to the billing account.","upvote_count":"1","timestamp":"1742066700.0","comment_id":"1399017"},{"content":"Selected Answer: A\nA is correct\nEngineering Team with the Project Creator role will not be able to link projects to a billing account.","upvote_count":"1","poster":"sh4dw4rri0r","timestamp":"1737799020.0","comment_id":"1346398"},{"poster":"SteveXs","comment_id":"1341199","upvote_count":"1","content":"Selected Answer: C\nWhen granted in combination with the Billing Account User role, the Project Billing Manager role lets users attach the project to the billing account, but doesn't grant any rights over resources. Project Owners can use this role to let someone else manage the billing for the project without granting them resource access.","timestamp":"1736965980.0"},{"poster":"Roman1988","timestamp":"1735728300.0","content":"Selected Answer: C\nOption C. When granted in combination with the Billing Account User role, the Project Billing Manager role lets users attach the project to the billing account, but doesn't grant any rights over resources. Project Owners can use this role to let someone else manage the billing for the project without granting them resource access.","upvote_count":"1","comment_id":"1335163"},{"upvote_count":"1","poster":"zAbuQasen","content":"Selected Answer: A\nThe Project Billing Manager role on the organization is unnecessary. The Billing Account User role alone is sufficient to allow the finance team to link projects to the billing account.","timestamp":"1734600240.0","comment_id":"1328919"},{"comment_id":"1318773","upvote_count":"1","timestamp":"1732723560.0","content":"Selected Answer: C\nFrom the documentation: \"Project Billing Manager (on Organization, folder, or project) when granted in combination with the Billing Account User role (on Organization or billing account) ... lets users attach the project to the billing account, but doesn't grant any rights over resources.\"","poster":"user263263"},{"upvote_count":"2","content":"Selected Answer: A\nChatGPT and my opinion also, A","comment_id":"1318455","poster":"Moin23","timestamp":"1732687620.0","comments":[{"upvote_count":"1","content":"I checked with ChatGPT, the answer is C.","timestamp":"1736963340.0","poster":"kamee15","comment_id":"1341167"}]},{"poster":"calebeowsiany","content":"Selected Answer: A\nA is a well suited answer and it's in accord with the least privilege principle","upvote_count":"2","comment_id":"1314969","timestamp":"1732057920.0"},{"upvote_count":"1","poster":"shuja_jilani","content":"Selected Answer: A\nA is enough for the given task.","timestamp":"1731303720.0","comment_id":"1309840"},{"comment_id":"1294879","content":"You do not want the engineering team to be able to link projects to the billing account. \nThink about this, the answer is clearly A","poster":"Alaric_wk","upvote_count":"1","timestamp":"1728423720.0"},{"upvote_count":"1","comment_id":"1286644","timestamp":"1726799520.0","content":"Selected Answer: C\nEl rol de Usuario de cuenta de facturación permite al equipo de finanzas vincular proyectos a la cuenta de facturación, sin otorgarles otros permisos sobre la administración de proyectos.\nEl rol de Gerente de facturación del proyecto otorga al equipo de finanzas la capacidad de gestionar la facturación de proyectos individuales, pero no permite otros cambios a nivel de proyecto o de organización.\nEsta combinación permite que solo el equipo de finanzas pueda vincular proyectos a la cuenta de facturación, cumpliendo con la política que el equipo de ingeniería no debe poder hacerlo.","poster":"nubelukita45852"},{"poster":"NMG264","comment_id":"1231743","timestamp":"1718602800.0","upvote_count":"1","content":"Selected Answer: C\nThe Billing Account User role in GCP allows a user to view and manage billing accounts, but does not grant permissions to associate projects with billing accounts. The Project Billing Manager role is more focused on associating GCP projects with billing accounts."},{"timestamp":"1717401240.0","comment_id":"1223480","upvote_count":"1","content":"Selected Answer: A\nC is not good because in this link https://cloud.google.com/billing/docs/how-to/billing-access, the role Project Billing Manager allows \"Link/unlink the project to/from a billing account\". Unlink is not good in this situation.","poster":"hankun"},{"comment_id":"1212893","poster":"Nikki2424","upvote_count":"1","timestamp":"1715949840.0","content":"Selected Answer: C\nWhen granted in combination with the Billing Account User role, the Project Billing Manager role allows a user to attach the project to the billing account, but does not grant any rights over resources."},{"content":"Selected Answer: C\nTo achieve the desired level of access control, where only the finance team can link projects to the billing account while preventing them from making other changes to projects, you should follow these steps: C\nExplanation:\n\nAssigning the finance team the Billing Account User role on the billing account allows them to link projects to the billing account, which is necessary for managing billing.\nAssigning the Project Billing Manager role on the organization to the finance team allows them to manage billing for projects within the organization without granting them additional permissions to modify projects themselves.\nThis approach ensures that the finance team has the necessary permissions to manage billing-related tasks while restricting their access to project management functionalities, such as creating or deleting projects, which are typically associated with the Project Creator role.","upvote_count":"2","poster":"DWT33004","comment_id":"1194265","timestamp":"1712910540.0"}],"answer":"C"},{"id":"dvnbSKhhWpaUXM6AYUTO","exam_id":1,"question_id":242,"answer_description":"","isMC":true,"topic":"1","unix_timestamp":1587120600,"discussion":[{"timestamp":"1591779420.0","comments":[{"upvote_count":"3","content":"No, archive storage might not be the correct choice as we need to consider the access time. Coldline Storage provides relatively faster access times compared to Archive Storage, which is important if you need to recover data quickly in a disaster scenario. \nColdline Storage: Fits well with disaster recovery use cases where data is infrequently accessed but needs to be available relatively quickly if a disaster occurs.","poster":"Sami_27","comment_id":"1260476","timestamp":"1727009100.0"},{"poster":"Mutune","comment_id":"298263","content":"Perfectly stated","timestamp":"1614177420.0","upvote_count":"6"}],"content":"Best Answer is \" Archive Storage \" \nhttps://cloud.google.com/storage/docs/storage-classes\n\nBut as per the given option next best solution is \" Coldline Storage\"","upvote_count":"74","poster":"poogcp","comment_id":"106618"},{"timestamp":"1589207340.0","poster":"zukko78","comment_id":"87171","upvote_count":"12","content":"D is correct, \nColdline Storage COLDLINE 90 days \n99.95% in multi-regions and dual-regions\n99.9% in regions"},{"poster":"AbsurdDragon","timestamp":"1741042920.0","content":"Selected Answer: A\nDR needs to be tested when you do pentesting\nDR needs to be sanity checked at some frequency depending on the importance of your app.\nDR needs to be kept up to date with your app changes - regular snapshots and writes.\n\nColdline is too expensive for regular writes and as needed reads.\n\nDR needs to be there when something catastrophic happens (or not too bad). If there's a hurricane in North Carolina that knocks google's DC out - and both your app and DR were hosted there - that sucks, ideally you should have had your DR in a couple of different regions.\n\nThus A - multi region is the answer","comment_id":"1364630","upvote_count":"1"},{"timestamp":"1739191620.0","content":"Selected Answer: D\nI believe Coldline Storage is the answer in absence of Archive Storage. Note how the bucket is responsible for disaster recovery, meaning it should already be in a different region from our operational data, therefore making Multi-Regional-Storage unnecessary.","comment_id":"1354457","poster":"Joseph_Covaro","upvote_count":"1"},{"timestamp":"1738925760.0","upvote_count":"1","comment_id":"1352951","content":"Selected Answer: A\nere's why:\n\nMulti-Regional Storage: This option provides the highest level of redundancy and availability. Data is replicated across multiple geographic regions, ensuring that your backups are accessible even in the event of a regional outage. This is crucial for disaster recovery scenarios where you need to restore your application quickly.\nWhy the other options are less suitable:\n\nRegional Storage: While more cost-effective than Multi-Regional, Regional Storage stores data within a single geographic region. If that region experiences an outage, your backups will be unavailable. This is not ideal for disaster recovery.\n\nNearline Storage and Coldline Storage: These options are designed for data that is accessed infrequently. They offer lower storage costs but have retrieval fees and higher latency. While suitable for archiving or long-term backups where immediate access isn't critical, they are not the best choice for disaster recovery where rapid restoration is essential. Restoring from Nearline or Coldline would add significant time to your recovery process.","poster":"vaclavbenes1"},{"content":"Selected Answer: A\nThe question focuses on \"Disaster Recovery\" and not cost. \nFor disaster recovery backups in Google Cloud Storage, Multi-Regional Storage (A) is the recommended option. This storage class ensures data is replicated across multiple geographic regions, providing maximum availability and durability. This redundancy protects against regional outages and aligns with Google’s best practices for disaster recovery, which prioritize cross-region replication to minimize downtime and ensure rapid recovery","poster":"iamshubhampatil","comment_id":"1349547","timestamp":"1738333380.0","upvote_count":"2"},{"content":"Selected Answer: A\nMulti-Regional Storage provides high durability and availability by storing your data across multiple locations in different regions, which is ideal for backup and disaster recovery. It is designed for frequently accessed data but can also be suitable for critical backups that may need to be quickly restored across a wide geographic area.\n\nRegional Storage stores data in a single region, which may not be as reliable for disaster recovery in the event of a regional failure.\n\nNearline Storage and Coldline Storage are designed for data that is infrequently accessed (e.g., archival purposes), so they are not as suitable for application backups that might need to be accessed relatively quickly in a disaster recovery scenario.\n\nTherefore, Multi-Regional Storage is the best choice for disaster recovery backups.","comment_id":"1344173","poster":"shashank_m","upvote_count":"1","timestamp":"1737467160.0"},{"upvote_count":"1","timestamp":"1736530500.0","poster":"SteveXs","content":"Selected Answer: D\nWhile multi-regional storage ensures data durability and availability, it is not cost-efficient for backup files that are rarely accessed, such as those for disaster recovery. D is the correct answer as Coldline Storage is designed for long-term storage and infrequently accessed data (e.g., disaster recovery backups).","comment_id":"1338897"},{"timestamp":"1734683040.0","upvote_count":"1","poster":"modaknarayan","content":"Selected Answer: A\nExplanation: Google's recommended best practice for disaster recovery purposes is to store backup data in Multi-Regional Storage. This storage option ensures high availability and durability by replicating your data across multiple geographic locations. This is crucial for disaster recovery scenarios, as it provides resilience against regional outages.","comment_id":"1329355"},{"poster":"dzei","upvote_count":"1","content":"Selected Answer: D\nAt first I thought it was A, but after reading the discussion and explanation I thought it was D.","comment_id":"1328885","timestamp":"1734592620.0"},{"content":"Selected Answer: D\nAnswer is D.","poster":"denno22","timestamp":"1728892080.0","comment_id":"1297307","upvote_count":"1"},{"timestamp":"1727162700.0","comment_id":"1110806","content":"Selected Answer: D\nAns is D. Coldline Storage: If the backups are truly for disaster scenarios and you expect very infrequent access (less than once a year).\nHere's how other option fits into this context:\n\nA. Multi-Regional Storage: This is best for data that is frequently accessed and needs to be highly available. It's ideal for serving content to users globally and for data that is accessed more often.\n\nB. Regional Storage: This offers high availability and is suited for storing data that is accessed frequently, but within a specific region. It's good for data used in compute operations in the same region.\n\nC. Nearline Storage: This is a low-cost option for storing infrequently accessed data. It's ideal for data that is accessed less than once a month. There are costs associated with accessing the data, so it's better for data that you don't expect to access frequently.","poster":"kaby1987","upvote_count":"5"},{"upvote_count":"2","content":"honestly, they should've added archive storage because it is better suited for disaster recovery backup. It is also stated in the doc how archive is better choice than 'coldline storage'. Also in terms of latency, archive will take care of that in events of disaster; as stated in the doc, \"In the event of a disaster recovery event, recovery time is key. Cloud Storage provides low latency access to data stored as Archive storage.\"\nhttps://cloud.google.com/storage/docs/storage-classes#archive","timestamp":"1725531420.0","comment_id":"1278832","poster":"JackSkeletonCoder"},{"upvote_count":"1","comment_id":"1216713","content":"Correct Answer: D\nReference:\nhttps://cloud.google.com/storage/docs/storage-classes#nearline","timestamp":"1716480120.0","poster":"subha.elumalai"},{"poster":"Nikki2424","comment_id":"1208833","upvote_count":"2","content":"Selected Answer: D\nMulti-regional storage = standard storage used only for objects stored in multi-regiones or dual-regions. \nRegional storage = standard storage used only for objects stored in regions \nRefer to https://cloud.google.com/storage/docs/storage-classes#legacy \nEach of the standard, nearline, coldline, and archive storage classes can have any of the location types, i.e., region, dual region, multi-region. \nCold-line storage is the ideal option here according to Google's best practices.","timestamp":"1715256660.0"},{"content":"Selected Answer: D\nGoogle recommends Archive Storage for disaster recovery, since Archive is not available as an answer, coldline is the nearest possible.","upvote_count":"1","poster":"blackBeard33","comment_id":"1156659","timestamp":"1708631400.0"},{"upvote_count":"4","poster":"sinh","timestamp":"1705401480.0","comment_id":"1124099","content":"Selected Answer: A\ndisaster recovery purposes = Multi-Regional Storage\nhttps://cloud.google.com/storage/docs/locations#location_recommendations"}],"url":"https://www.examtopics.com/discussions/google/view/18595-exam-associate-cloud-engineer-topic-1-question-6-discussion/","answers_community":["D (52%)","A (40%)","7%"],"choices":{"D":"Coldline Storage","B":"Regional Storage","A":"Multi-Regional Storage","C":"Nearline Storage"},"timestamp":"2020-04-17 12:50:00","question_images":[],"question_text":"Your company uses Cloud Storage to store application backup files for disaster recovery purposes. You want to follow Google's recommended practices. Which storage option should you use?","answer_ET":"D","answer":"D","answer_images":[]},{"id":"VqHW3MZO8Vt9HVTBVabS","answer_description":"","isMC":true,"answers_community":["C (56%)","A (44%)"],"unix_timestamp":1589732580,"question_text":"You have an application running in Google Kubernetes Engine (GKE) with cluster autoscaling enabled. The application exposes a TCP endpoint. There are several replicas of this application. You have a Compute Engine instance in the same region, but in another Virtual Private Cloud (VPC), called gce-network, that has no overlapping IP ranges with the first VPC. This instance needs to connect to the application on GKE. You want to minimize effort. What should you do?","discussion":[{"poster":"someoneinthecloud","upvote_count":"62","comments":[{"content":"A,C are ok for me. But this is a exam. Why the question mention the same region, no overlapping IP ranges means they suggest you to use VPC rather than public traffic. I 99% sure, if there is an official explaniation, there would be A is not correct there is a risk or error prone, sth like this.","upvote_count":"6","poster":"ArtistS","comment_id":"1047151","timestamp":"1697654520.0"},{"poster":"pgb54","content":"Totally agree. I had the same thought and looked through the question for any indication that the traffic must be private.","comment_id":"556207","upvote_count":"2","timestamp":"1645817640.0"},{"comment_id":"304329","upvote_count":"15","timestamp":"1614968400.0","content":"Ans: A . This sounds correct and avoids unnecessary steps in C. C is also correct but compared to it, A is much easier to achieve. Go over Kubernetes Loadbalancer concepts to get more details. Initially i was thinking C is the Answer. but after putting some time on K8's Network - changed my mind to A.","poster":"ShakthiGCP"},{"upvote_count":"10","poster":"AmitKM","content":"Yeah, I feel the same. Nowhere does it say that the traffic has to be internal. But it does say \"minimal effort\" which I feel is option A.","timestamp":"1598200740.0","comment_id":"164534"}],"comment_id":"148658","content":"I believe it's A. It's never mentioned in the question that traffic cannot go through the Internet but it's mentioned that effort should be minimized. A requires a lot less effort than C to accomplish the same (no VPC peering, per example).","timestamp":"1596299760.0"},{"poster":"juancambb","comment_id":"90691","timestamp":"1589732580.0","upvote_count":"46","content":"i think C is better solution, the solution A pass trafic trought public internet, also C by internal network and the \"no overlap ips\" in the statament suggest that."},{"timestamp":"1736063160.0","content":"Selected Answer: A\nA. 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Set the service's externalTrafficPolicy to Cluster. 3. Configure the Compute Engine instance to use the address of the load balancer that has been created.\n\nWhy Other Options Are Incorrect:\nB:\n\nUsing a proxy instance with multiple network interfaces and iptables for forwarding traffic is unnecessarily complex and requires significant manual configuration and maintenance.\nC:\n\nCreating an internal load balancer and peering the VPCs requires additional setup for VPC peering and route configurations. This violates the requirement to minimize effort.\nD:\n\nAdding a Cloud Armor Security Policy is unnecessary for this use case. Furthermore, the Compute Engine instance is in a different VPC, so using internal IPs of the GKE nodes is not possible without peering.","upvote_count":"1","poster":"fais1985","comment_id":"1336682"},{"upvote_count":"1","content":"Selected Answer: C\nC is the correct answer. \n\nReference: https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing-across-vpc-net","timestamp":"1731411720.0","comments":[{"poster":"psyll0n","content":"Reference: https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing","timestamp":"1731411960.0","comment_id":"1310551","upvote_count":"1"}],"poster":"psyll0n","comment_id":"1310549"},{"upvote_count":"1","timestamp":"1716486900.0","content":"Correct Answer: A","comment_id":"1216880","poster":"subha.elumalai"},{"comment_id":"1194873","timestamp":"1713004440.0","upvote_count":"4","poster":"DWT33004","content":"Selected Answer: A\nHere's why Option A might be preferred over Option C:\n\nSimplicity: Option A requires creating a LoadBalancer service in GKE and configuring the Compute Engine instance to use the load balancer's address. This is a straightforward setup and does not involve additional networking configurations.\n\nReduced Complexity: Peering two VPCs involves setting up and managing VPC peering configurations, which can be complex, especially if there are overlapping IP ranges. It also requires additional permissions and coordination between different teams.\n\nDirect Connectivity: Option A provides direct connectivity between the Compute Engine instance and the application running in GKE through the load balancer. Peering VPCs might introduce additional network hops, potentially impacting latency and network performance.\n\nScalability and Flexibility: Using a LoadBalancer service in GKE allows for scalability and flexibility, as the load balancer can automatically scale to handle increased traffic and can be easily configured to adapt to changing requirements."},{"poster":"edoo","content":"Selected Answer: C\nNot A, exposing the service with an external LoadBalancer (externalTrafficPolicy set to Cluster) and not peering VPCs or using an internal load balancer unnecessarily exposes the service to the internet, which is not required for inter-VPC communication and could lead to security concerns.\nAll the details in the question are pushing to answer C.","upvote_count":"3","comment_id":"1137372","timestamp":"1706773680.0"},{"poster":"ovokpus","timestamp":"1697134920.0","content":"Selected Answer: C\nOption A suggests creating an external LoadBalancer. This is not the most efficient method because you're exposing your GKE application to the internet just to allow communication between two internal resources.\n\nOption C suggests creating an internal LoadBalancer, which is the right approach. By using an internal LoadBalancer, the service is only exposed within the Google Cloud environment and won't be accessible from the internet. Peering the two VPCs ensures the two resources can communicate across the VPCs.","upvote_count":"4","comment_id":"1042001"},{"timestamp":"1696501740.0","poster":"ekta25","content":"C. 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created.","upvote_count":"2","comment_id":"1025532"},{"content":"Selected Answer: C\nCorrect Answer is C\nOption A suggests setting the service's externalTrafficPolicy to Cluster. While this is a valid configuration, it's not directly related to the scenario described.\n\nIn the given scenario, the goal is to connect a Compute Engine instance from a different VPC to the application running in GKE. This involves networking configurations, peering the VPCs, and potentially setting up a LoadBalancer.\n\nSetting the externalTrafficPolicy to Cluster primarily affects how traffic is balanced across Pods within the cluster, but it doesn't directly address the requirement of connecting an external instance from a different VPC.","poster":"SinghAnc","timestamp":"1696335120.0","upvote_count":"3","comment_id":"1023907"},{"content":"Selected Answer: A\nMinimal effort is the point.","comment_id":"992918","upvote_count":"2","poster":"RobAlt","timestamp":"1693297740.0"},{"timestamp":"1689855120.0","comment_id":"957518","content":"Selected Answer: C\nOption C.","upvote_count":"1","poster":"ExamsFR"},{"content":"Selected Answer: C\nA is not correct \nBecause the GKE cluster and the instance are not in the same vpc , so without vpc peering traffic can't be established .\nC is the correct answer. \nTraffic still internal not exposed to internet , as they mentioned creating internal tcp loadbalancer not public one and created vpc peering . so no additional steps are needed.","comment_id":"915062","upvote_count":"3","poster":"KerolesKhalil","timestamp":"1685939460.0","comments":[{"comment_id":"922472","upvote_count":"1","timestamp":"1686683580.0","content":"C is also correct but as the question states, minima effort. In A you dont need vpc peering since you will be using loadbalancer to expose the application, therefore, traffic can still be establishd b/n the two.","poster":"tempdir"}]},{"timestamp":"1685847900.0","poster":"sana_sree","content":"Selected Answer: C\nCorrect is C\nplease refer\nhttps://www.youtube.com/watch?v=qx8PEmxKYzg","comment_id":"914077","upvote_count":"3"},{"content":"Selected Answer: C\nThe answer is C as two VPC needed to Peer first","comment_id":"860516","poster":"DrLegendgun","timestamp":"1680570180.0","upvote_count":"2"},{"content":"Selected Answer: A\nsame region, but in another Virtual Private Cloud (VPC), called gce-network, that has no overlapping IP ranges with the first VPC.... need to read question again and again","poster":"esqandares","timestamp":"1680185220.0","upvote_count":"1","comment_id":"855854"},{"comment_id":"837734","content":"peering is lot easier effort but with dependent on not having overlapping IPs and that was clearly stated on the question. So C without any doubt is the correct answer here IMO.","timestamp":"1678693800.0","poster":"raselsys","upvote_count":"1"},{"upvote_count":"6","poster":"Buruguduystunstugudunstuy","comment_id":"814877","comments":[{"content":"Answer B is not recommended because it requires the creation of an additional instance called a proxy, and the use of iptables to forward traffic from gce-network to the GKE nodes. This solution introduces additional complexity and potential points of failure.\n\nAnswer C is not recommended because it requires the peering of two VPCs. This solution is also more complex and requires additional configuration.\n\nAnswer D is not recommended because it involves using Cloud Armor to whitelist the internal IPs of the MIG's instances. This solution introduces additional complexity and potential security risks.\n\nTherefore, Answer A is the most straightforward and least complex solution to connect the Compute Engine instance to the application running on GKE.","timestamp":"1676873640.0","poster":"Buruguduystunstugudunstuy","comment_id":"814878","upvote_count":"6"},{"timestamp":"1687968060.0","comment_id":"936864","upvote_count":"2","content":"externalTrafficPolicy is supported for internal LoadBalancer Services (via the TCP/UDP load balancer), but load balancing behavior depends on where traffic originates from and the configured traffic policy. Hence Answer is C as per link: https://cloud.google.com/kubernetes-engine/docs/how-to/service-parameters#externalTrafficPolicy","poster":"Shivangi30"},{"content":"Option C requires less effort compared to option A.\n\nIn option A, you need to set the service's externalTrafficPolicy to Cluster, which means that the traffic will be load balanced across all nodes in the cluster, including those outside of the VPC network. You will also need to configure the Compute Engine instance to use the address of the load balancer that has been created.\n\nIn option C, you only need to add an annotation to the service with the value of \"Internal\", which will create an internal load balancer that is only accessible from within the VPC network. You will also need to peer the two VPCs together and configure the Compute Engine instance to use the address of the load balancer that has been created.\n\nTherefore, option C requires less effort as it involves fewer steps and less configuration.","comment_id":"845535","poster":"antivrillee","upvote_count":"2","timestamp":"1679374380.0"}],"content":"Selected Answer: A\nAnswer A is the correct solution.\n\nIn Answer A, we can create a Service of the type LoadBalancer in GKE that uses the application's Pods as a backend. This will create a Google Cloud load balancer with an external IP address that can be used to connect to the application. We can set the service's externalTrafficPolicy to Cluster to ensure that traffic is routed only to the nodes running the application. Then we can configure the Compute Engine instance to use the address of the load balancer that has been created.","timestamp":"1676873640.0"},{"upvote_count":"3","poster":"Bobbybash","timestamp":"1676259360.0","comment_id":"807028","content":"Selected Answer: A\nA is correct\nOption A is the best solution to minimize effort. In GKE, creating a Service of type LoadBalancer that uses the application's Pods as backend and setting the service's externalTrafficPolicy to Cluster will expose the TCP endpoint of the application with a public IP address. Then, configuring the Compute Engine instance to use the address of the load balancer that has been created will allow it to connect to the application on GKE. Option B requires creating a separate instance as a proxy and using iptables to forward traffic, which adds unnecessary complexity. Option C involves peering the two VPCs together, which may not be desirable or feasible in all cases. Option D adds additional complexity by adding a Cloud Armor Security Policy to the load balancer."},{"content":"Selected Answer: C\nOption A exposes an unsecured TCP endpoint on the internet, and there is no mention of the VM IP ranges with the first VPC.","timestamp":"1675070520.0","upvote_count":"2","poster":"David_C_90","comment_id":"792590"},{"timestamp":"1674739980.0","content":"Selected Answer: A\nA answer","upvote_count":"1","poster":"kajitsu","comment_id":"788759"},{"content":"Selected Answer: A\nA has minimal effort","timestamp":"1674208440.0","comment_id":"782076","poster":"GS300","upvote_count":"1"},{"timestamp":"1673896380.0","content":"Selected Answer: C\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/service-parameters#externalTrafficPolicy\n\nThe externalTrafficPolicy is a standard Service option that defines how and whether traffic incoming to a GKE node is load balanced. Cluster is the default policy, but Local is often used to preserve the source IP of traffic coming into a cluster node. Local effectively disables load balancing on the cluster node so that traffic that is received by a local Pod sees the original source IP address.\n\nThere is no need to set an already default value.","comment_id":"778139","upvote_count":"2","poster":"A84-64"},{"timestamp":"1670475120.0","poster":"Rubankumar","comment_id":"738629","upvote_count":"1","content":"Selected Answer: A\nA is the minimal efforts"},{"timestamp":"1670350020.0","upvote_count":"1","content":"Selected Answer: A\nAns: A","poster":"cslince","comment_id":"737101"},{"poster":"toni90ns","upvote_count":"1","content":"Selected Answer: A\nI have never done A in past, so I was not sure will it work. Just test it and it works. Question here is not saying what is the best option, it says to minimize the effort. So definitely it is easier to do steps from answer A.","timestamp":"1666812480.0","comment_id":"704965"},{"comment_id":"691865","poster":"Robertolo","upvote_count":"2","timestamp":"1665473820.0","content":"Selected Answer: C\nC is the answer: https://cloud.google.com/load-balancing/docs/choosing-load-balancer#external-internal"},{"content":"had this question today","poster":"Cornholio_LMC","upvote_count":"2","comment_id":"677983","timestamp":"1664036580.0"},{"comment_id":"651813","content":"Selected Answer: C\n[C]\n\"no overlapping IP's\" so VPC peering will work. However one will need to configure firewall on both VPC's to allow internal traffic.","timestamp":"1661435100.0","poster":"VietmanOfficiel","upvote_count":"2"},{"upvote_count":"1","poster":"joeMP","timestamp":"1660219500.0","comment_id":"645449","content":"Selected Answer: A\nA is th goof answer"},{"comments":[{"comment_id":"870944","upvote_count":"1","timestamp":"1681564440.0","content":"Option C takes twice as many steps, it is not minimum effort, I vote A","poster":"[Removed]"}],"content":"Selected Answer: A\nC. Keyword is “minimize effort”. \n\nIf keyword was “securely” or “best practice” it would’ve been A.","poster":"Prosecute","comment_id":"644945","upvote_count":"3","timestamp":"1660132080.0"},{"upvote_count":"1","timestamp":"1659926340.0","poster":"ryumada","content":"Vote for C, externalTrafficPolicy is used to support Internal Load Balancer. Also, You should see the comments from dark_3k03r and kimharsh. They also explain about externalTrafficPolicy.\n\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/service-parameters#externalTrafficPolicy","comment_id":"643905"},{"upvote_count":"1","content":"Selected Answer: C\nI will go with C","timestamp":"1659794460.0","poster":"abirroy","comment_id":"643418"},{"comment_id":"637536","upvote_count":"1","timestamp":"1658855700.0","content":"Selected Answer: A\nsomeoneinthecloud is right","poster":"jeffangel28"},{"timestamp":"1657775640.0","upvote_count":"3","content":"In my opinion it is C.\nI think that in answer A, what we are doing is deploying an internet facing LoadBalancer (because it is the default LoadBalancer type that is deployed if we do not specify an internal one in the annotations), that is, with the possibility of being called from outside our VPC, and forcing the compute engine instance to go outside the google network to be able to go back inside through the endpoint that we are publishing with the unicast ip of the balancer.\n\nAnswer C, however, performs a peering between the two VPC's (the statement makes sure that this option is feasible since it clearly specifies that there is no overlapping between the ip ranges of both vpc's), deploy the LoadBalancer as internal with the annotation, and configure the endpoint so that the compute engine instance can access the application internally, that is, without the need to have a public ip at any time and therefore, without the need to go outside the google network. The traffic, therefore, never crosses the public internet.","comment_id":"631194","poster":"amenur"},{"comment_id":"619987","timestamp":"1655833380.0","upvote_count":"5","content":"Its not A. External traffic Policy, the name is a bit misleading. What it is referring to is the load balancing of the pods. Do you perform no load balancing of the pods and keep it internal to the node (local) or do you perform pod load balancing outside/externally from the local node (i.e. across the cluster). Has nothing to do with the routing over the internet or how traffic gets routed to it. It has all to do with how to route traffic once it gets there.\n\nIt's not B cause nodeport is a one for one mapping, so this wouldn't scale , not to mention the 2 network interfaces witha proxy in two vpc statement...\n\nIt's not D cause there is no need for cloud armor security policy.\n\nSo that leaves C as the only viable source.\n\nhttps://medium.com/pablo-perez/k8s-externaltrafficpolicy-local-or-cluster-40b259a19404","poster":"dark_3k03r"},{"upvote_count":"5","content":"Selected Answer: C\nI will vote for C. Answer A did not state if there is a public IP for compute engine and the firewall policy is not set for GKE to allow connection from the internet.","comment_id":"619343","timestamp":"1655738280.0","poster":"kohsiangyu"},{"poster":"wolfie09","upvote_count":"4","comment_id":"618602","timestamp":"1655630340.0","content":"TCP is not encrypted so A is not a good idea"},{"poster":"Tirthankar17","upvote_count":"1","timestamp":"1654849860.0","content":"Except B (NodePort), all are valid answers. However, in A the traffic is public, so not secure. In D, it is mentioned MIG, which is not the case as per the Question. Lastly it is C that is the correct option remaining.","comment_id":"614420"},{"upvote_count":"1","comment_id":"610993","poster":"haroldbenites","content":"Go for D\nA id not correct because externalTrafficPolicy don’t work to filter IPs. It works for decide the route of the traffic.\nC is not correct because the annotations not filter traffic .","timestamp":"1654246020.0"},{"comment_id":"546418","poster":"tigerbaer","upvote_count":"2","timestamp":"1644751620.0","content":"Selected Answer: A\nA is less complex than C -> Go for A"},{"content":"C is correct because an internal load balancer will create a private IP address that the compute engine instance can connect to after configuring VPC peering.","comment_id":"509060","poster":"uganeshku","comments":[{"upvote_count":"3","poster":"uganeshku","timestamp":"1640430180.0","content":"A is incorrect because even though it works, the traffic between the GKE cluster and the Compute engine will need to go through the public Internet, which should be avoided if possible.","comments":[{"content":"The question doesn't state that's a problem, and the question requires least effort option. Peering two VPC's is a lot of effort.","upvote_count":"2","poster":"obeythefist","timestamp":"1646029260.0","comment_id":"557896","comments":[{"comment_id":"837733","timestamp":"1678693740.0","upvote_count":"1","poster":"raselsys","content":"peering is lot easier effort but with dependent on not having overlapping IPs and that was clearly stated on the question. So C without any doubt is the correct answer here IMO."}]}],"comment_id":"509062"}],"upvote_count":"5","timestamp":"1640430060.0"},{"timestamp":"1640119320.0","comment_id":"506425","upvote_count":"5","content":"ANS: C\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing\nclients in a VPC network connected to the LoadBalancer network using VPC Network Peering can also access the Service","poster":"Gabocr2021"},{"timestamp":"1639306800.0","upvote_count":"2","comment_id":"499960","content":"A is technically correct, it is not mentioned that the traffic is not allowed to go through the internet. Therefore, A requires minimal effort in comparison to C.","comments":[{"poster":"kimharsh","upvote_count":"3","comment_id":"503719","timestamp":"1639749360.0","content":"But how the 2 VPC will talk to each other in A? if you think the externalTrafficPolicy please read the documentation (https://cloud.google.com/kubernetes-engine/docs/how-to/service-parameters)\nAns should be C"}],"poster":"jabrrJ68w02ond1"},{"content":"Selected Answer: C\nBoth A and C would work \nBut C is more secure","upvote_count":"3","poster":"bgallet","timestamp":"1639305900.0","comment_id":"499948"},{"comment_id":"495484","poster":"Vidyaji","content":"Selected Answer: C\nC is perfect","timestamp":"1638837240.0","upvote_count":"3"},{"timestamp":"1638648180.0","poster":"kimharsh","content":"Why A? it should be C, how the 2 VPC reaches each other \nIf you think the externalTrafficPolicy will allow the GKE Nodes to reach the internet , then please read the documentation (https://cloud.google.com/kubernetes-engine/docs/how-to/service-parameters)\nthe question said \"with minimum effort \" because it thought you will select B as it's also correct but it's very lengthy process comparing to C","comment_id":"493934","upvote_count":"6"},{"upvote_count":"3","content":"The load balancer is accessible only in the chosen region of your Virtual Private Cloud (VPC) network on an internal IP address. so peering is needed. option c it is","comments":[{"upvote_count":"1","comment_id":"487951","poster":"Ridhanya","timestamp":"1637999040.0","content":"I take my comment back, because when we define type:LoadBalancer in gke deployments, it creates an external load balancer so the service is accessible from the internet. so it should be accessible from the internet and different vpcs shouldnt matter. option a seems right (minimum effort)"}],"poster":"Ridhanya","timestamp":"1637998500.0","comment_id":"487946"},{"poster":"vishnukumartr","upvote_count":"1","content":"A. 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Set the service's externalTrafficPolicy to Cluster. 3. Configure the Compute Engine instance to use the address of the load balancer that has been created.","timestamp":"1637405880.0","comment_id":"482426"},{"content":"C is right. \nHow are you going to establish connection between independent VPCs in A?","poster":"Rothmansua","comment_id":"462769","upvote_count":"4","timestamp":"1634323620.0"},{"upvote_count":"5","content":"I believe the answer is C. \nThe question has given out hints that VPC peering should be used in this scenario such as the cluster wanting to communicate with an instance in another VPC, No overlapping IP addresses...","timestamp":"1633943640.0","comment_id":"460487","poster":"dttncl"},{"timestamp":"1633141200.0","upvote_count":"1","content":"C is correct. It's true Internal TCP/UDP Load Balancing is only for the same VPC network, but that's where VPC Network Peering comes in.\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing","comment_id":"455795","poster":"ankatsu2010"},{"upvote_count":"1","content":"I go with A, because C is \"wrong\" :)\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing\nUsing an internal TCP/UDP load balancer\nThis page explains how to create a Compute Engine internal TCP/UDP load balancer on Google Kubernetes Engine.\nInternal TCP/UDP Load Balancing makes your cluster's services accessible to applications outside of your cluster that use the same VPC network and are located in the same Google Cloud region. \nSAME VPC NETWORK IS NEEDED, and \"another Virtual Private Cloud (VPC)\" is mentioned.","poster":"WindDriver","comment_id":"405293","timestamp":"1626168240.0","comments":[{"timestamp":"1637998740.0","content":"isn't that why vpc peering is mentioned in option c?","poster":"Ridhanya","comment_id":"487950","upvote_count":"2"},{"comment_id":"546416","upvote_count":"1","content":"You are not correct. Read the full description: \"In addition, clients in a VPC network connected to the LoadBalancer network using VPC Network Peering can also access the Service.\"","timestamp":"1644751320.0","poster":"tigerbaer"}]},{"upvote_count":"2","content":"Very confusing - finally what to choose...\n\nA or C ??","comment_id":"364835","poster":"contaexamtopics","timestamp":"1621790460.0"},{"upvote_count":"1","content":"Answer should be C, Opting A changes the exposure of GKE endpoints, thus even if it less work makes it incorrect. Also the question indicates to explore VPC sharing, as this is one of the most suitable case.","comment_id":"357766","poster":"Agraved","timestamp":"1621075980.0"},{"timestamp":"1620800460.0","poster":"mcaromit","upvote_count":"2","comment_id":"355320","content":"Both A & C would work, but if effort is to be minimized then A is the best choice"},{"comments":[{"upvote_count":"1","timestamp":"1623458160.0","poster":"Furqon","content":"Indeed. I think previously is A, but there is a \"no conflicting IPs\" statement.","comment_id":"380104"}],"content":"Another tricky one between A and C however again, approaching this from hints within this specific Q (No Conflicting IPs) I believe the answer is C.","poster":"meh009","comment_id":"340190","upvote_count":"4","timestamp":"1618994160.0"},{"timestamp":"1616620980.0","poster":"[Removed]","content":"C is correct. 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created.","comment_id":"319581","upvote_count":"2"},{"comment_id":"318767","poster":"yuvi69","timestamp":"1616560500.0","content":"Correct answer is A . option C is wrong because internal loadbalancers are used within same VPC network. but here in the question it is mentioned that compute engine instance is present in another VPC .\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing","comments":[{"comment_id":"319676","content":"If use vpc peer. Use internal loadbalancer is a good plan(Need to configue firewall).\nhttps://cloud.google.com/load-balancing/docs/l7-internal/internal-https-lb-and-other-networks\nBut we need min effort so I think A is right.","poster":"pondai","timestamp":"1616633460.0","upvote_count":"1"},{"timestamp":"1622539500.0","poster":"sanhoo","upvote_count":"4","comment_id":"371724","content":"In the link you provided it is mentioned as \"In addition, clients in a VPC network connected to the LoadBalancer network using VPC Network Peering can also access the Service.\"\nIn option C they are talking about VPC peering. So technically it is possible. I tend to belive C is correct answer"}],"upvote_count":"3"},{"upvote_count":"1","timestamp":"1616215500.0","poster":"Pravin3c","content":"NOT C - Global access is an optional parameter for internal LoadBalancer Services that allows clients from any region in your VPC network to access the internal TCP/UDP load balancer.","comment_id":"315365"},{"comment_id":"312693","poster":"sumanshu","content":"Vote for 'A'","timestamp":"1615927020.0","upvote_count":"3"},{"content":"C. 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created.","timestamp":"1615301880.0","poster":"GCP_Student1","comment_id":"306487","comments":[{"upvote_count":"1","poster":"tavva_prudhvi","timestamp":"1617526380.0","comment_id":"327878","comments":[{"timestamp":"1621660200.0","content":"But Google always recomends security as the best practise and VPC peering is always better","upvote_count":"2","comment_id":"363430","poster":"viswanand"}],"content":"See, both A,C are right but in the question it says to minimize effort, then we can go with A, i guess!"}],"upvote_count":"1"},{"upvote_count":"1","content":"C. is the correct answer: \n 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created.","comment_id":"299367","timestamp":"1614284100.0","poster":"nliaustemac"},{"poster":"nitinz","comment_id":"296826","content":"common sense A, C will do the same. Requirement is less work, requirements never say you can not go to internet. A and C does the same. A via routing traffic via Internet and C using internally. But less effort in A. I will stick to A.","timestamp":"1614017580.0","comments":[{"poster":"tavva_prudhvi","upvote_count":"1","comment_id":"334473","timestamp":"1618298940.0","content":"As you said, A is doing via routing traffic via internet and C is using it internally, so Acc to your statement, it's C,right?"}],"upvote_count":"3"},{"comment_id":"296823","poster":"nitinz","timestamp":"1614017460.0","upvote_count":"2","content":"A is simplest to achieve. I do not see a reason of doing extra work with option C."},{"upvote_count":"1","comment_id":"279155","poster":"DucSiu","timestamp":"1611906420.0","content":"C. 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created."},{"comment_id":"274456","timestamp":"1611394140.0","poster":"victory108","upvote_count":"2","content":"C - 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created."},{"comment_id":"240643","upvote_count":"2","poster":"Range2019","timestamp":"1607660220.0","content":"The correct answer is C and the steps are very logical.\nBesides you have been hinted of VPC peering as a solution to the problem .....\"that has no overlapping IP ranges with the first VPC\""},{"comment_id":"239230","timestamp":"1607520780.0","poster":"nadav1","content":"Vote A.","upvote_count":"2"},{"poster":"Bhagirathi","comment_id":"236562","timestamp":"1607265960.0","upvote_count":"2","content":"Very confusing - finally what to choose...\n\nA or C ??"},{"poster":"Avinashsingh1712","timestamp":"1606691400.0","comment_id":"230662","content":"As per - https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing\nIt can't be C because cloud.google.com/load-balancer-type: \"Internal\" annotation workes only if service is in same region and same VPC. Question clearly highlighted the point that insatance is not in same VPC.\nAnswer should be A","upvote_count":"7","comments":[{"upvote_count":"1","comment_id":"334472","content":"Yes, you are right, but that's the reason we are using VPC Peering, right??","timestamp":"1618298760.0","poster":"tavva_prudhvi"}]},{"upvote_count":"1","timestamp":"1606021500.0","poster":"Bhagirathi","content":"how it is C ?\nIt asks minimal efforts to make it.","comment_id":"224748"},{"upvote_count":"1","timestamp":"1605604800.0","poster":"swatititame","comment_id":"220935","content":"C. 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created."},{"poster":"gcper","upvote_count":"2","comments":[{"poster":"magistrum","content":"I'm sold to C, in that same link you provided, it states this:\n\" In addition, clients in a VPC network connected to the LoadBalancer network using VPC Network Peering can also access the Service.\"","timestamp":"1609285440.0","comment_id":"255238","upvote_count":"4"},{"timestamp":"1615284360.0","poster":"Jacky_YO","upvote_count":"1","comment_id":"306302","content":"Answer : C\nGlobal access\n # https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing\nGlobal access is an optional parameter for internal LoadBalancer Services that allows clients from any region in your VPC network to access the internal TCP/UDP load balancer. \n\nWithout global access, traffic originating from clients in your VPC network must be in the same region as the load balancer."}],"content":"C is what I would answer. Reason being that even though cloud.google.com/load-balancer-type: Internal creates an internal IP address for the Service that receives traffic from clients in the same VPC network and compute region, we can fix this by peering. Quote \"In addition, clients in a VPC network connected to the LoadBalancer network using VPC Network Peering can also access the Service.\"\nsource: https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing\n\nAs for A, externalTrafficPolicy to Cluster would expose the application to the internet, which I don't think is what this question is trying to achieve.\nsource: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/","timestamp":"1602780060.0","comment_id":"200605"},{"content":"C. 1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created.","upvote_count":"2","comment_id":"196065","timestamp":"1602161100.0","poster":"glam"},{"content":"C is the answer...","timestamp":"1601754900.0","upvote_count":"1","comment_id":"192517","poster":"cpd"},{"timestamp":"1600585200.0","upvote_count":"1","comment_id":"182774","comments":[{"content":"are you high?","poster":"pilantra","comment_id":"254683","comments":[{"upvote_count":"1","poster":"BobbyFlash","content":"lmfao xD","timestamp":"1634777280.0","comment_id":"465446"}],"upvote_count":"15","timestamp":"1609237560.0"}],"poster":"[Removed]","content":"Ans is B\nAudit log talks about storing the logs effectively in the section What next\nhttps://cloud.google.com/storage/docs/audit-logs#whats_next\nthat maps to below link\nhttps://cloud.google.com/solutions/exporting-stackdriver-logging-for-compliance-requirements \n\nBest practice: Moving logs to Nearline or Coldline and then deleting them helps you manage the ongoing operational cost of maintaining the logs."},{"content":"C is correct for me","poster":"SSPC","timestamp":"1598170920.0","upvote_count":"2","comment_id":"164266"},{"content":"C - use Internal IP for communication after VPC Peering","comment_id":"142103","upvote_count":"3","timestamp":"1595515980.0","poster":"samvegas"},{"upvote_count":"4","timestamp":"1594462740.0","poster":"garora","comment_id":"132012","content":"C because both are in different VPCs. Need VPC peering. Option C is the right answer"},{"timestamp":"1591716360.0","content":"I think it is C too","comment_id":"106079","upvote_count":"3","poster":"mlantonis"},{"comment_id":"102476","content":"Correct answer is C as you have to set load balancer as internal otherwise it will get exposed on public internet.","timestamp":"1591285500.0","upvote_count":"6","poster":"saurabh1805"}],"answer_images":[],"exam_id":1,"choices":{"D":"1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add a Cloud Armor Security Policy to the load balancer that whitelists the internal IPs of the MIG's instances. 3. Configure the Compute Engine instance to use the address of the load balancer that has been created.","A":"1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Set the service's externalTrafficPolicy to Cluster. 3. Configure the Compute Engine instance to use the address of the load balancer that has been created.","B":"1. In GKE, create a Service of type NodePort that uses the application's Pods as backend. 2. Create a Compute Engine instance called proxy with 2 network interfaces, one in each VPC. 3. Use iptables on this instance to forward traffic from gce-network to the GKE nodes. 4. Configure the Compute Engine instance to use the address of proxy in gce-network as endpoint.","C":"1. In GKE, create a Service of type LoadBalancer that uses the application's Pods as backend. 2. Add an annotation to this service: cloud.google.com/load-balancer-type: Internal 3. Peer the two VPCs together. 4. Configure the Compute Engine instance to use the address of the load balancer that has been created."},"timestamp":"2020-05-17 18:23:00","question_id":243,"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/20773-exam-associate-cloud-engineer-topic-1-question-60-discussion/","answer":"C","answer_ET":"C","topic":"1"},{"id":"TairliWE5cQoXDAiuHGW","choices":{"C":"Write a custom script that uses logging API to copy the logs from Stackdriver logs to BigQuery.","A":"Create an export to the sink that saves logs from Cloud Audit to BigQuery.","B":"Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.","D":"Export these logs to Cloud Pub/Sub and write a Cloud Dataflow pipeline to store logs to Cloud SQL."},"exam_id":1,"topic":"1","question_id":244,"isMC":true,"discussion":[{"content":"Why not B? cost effective","poster":"yasu","upvote_count":"58","comment_id":"68347","timestamp":"1585230900.0","comments":[{"upvote_count":"1","poster":"lxs","timestamp":"1634904180.0","comments":[{"upvote_count":"2","timestamp":"1685940720.0","content":"the options have cold-line storage not nearline.\nso B is the cheapest option.","comment_id":"915071","poster":"KerolesKhalil"}],"content":"BigQuery data after 90 days has the same cost for storage as Cloud Storage Nearline. Storing it in Cloud Storage adds more costs for data retrival if the class is i.e archival","comment_id":"466128"},{"timestamp":"1680629640.0","comment_id":"861330","content":"That seems to be the one...","poster":"_Sande","upvote_count":"1"},{"comment_id":"509065","upvote_count":"6","poster":"uganeshku","content":"B is correct because Coldline Storage is the perfect service to store audit logs from all the projects and is very cost-efficient as well. Coldline Storage is a very low-cost, highly durable storage service for storing infrequently accessed data.","timestamp":"1640430600.0"}]},{"timestamp":"1585894680.0","content":"if it is all about cost, B is the best. However, speaking of \"audit\" you probably need to access the data once in a while, which Coldline storage might not be ideal for this case I guess? I would go for A in the exam though.","upvote_count":"21","comments":[{"timestamp":"1599202200.0","poster":"Ale1973","content":"Be strong!!! If B is the best, go for B!!!","upvote_count":"15","comment_id":"173179"},{"upvote_count":"8","content":"The question is clearly saying cost effect. BQ is one of the most expensive services in GCP.","comment_id":"423017","timestamp":"1628636100.0","poster":"pas77"},{"upvote_count":"4","poster":"boof","timestamp":"1632597780.0","content":"I would play it safe and interpret the question literally, implying that they will only store the audit logs and not be accessing them a lot.","comment_id":"451545"}],"comment_id":"70643","poster":"Gini"},{"timestamp":"1724931480.0","content":"Selected Answer: B\nas its logs for 3 years , coldline is the correct","comment_id":"1274472","poster":"pragneshpandya","upvote_count":"1"},{"comment_id":"1202955","poster":"jungkook_1","timestamp":"1714191540.0","content":"But the retention period of Coldline storage is 90 days, it's not meeting the requirement mentioned in ques to store for 3 years.","upvote_count":"1"},{"comment_id":"1202953","poster":"jungkook_1","content":"But retention period of coldline storage is 90 days only, in ques they've mentioned for 3 years?","upvote_count":"1","timestamp":"1714191240.0"},{"timestamp":"1712251560.0","content":"Selected Answer: B\nUsing Google Gemini, it suggests Option B.","poster":"LSB56757","upvote_count":"3","comment_id":"1189473"},{"comment_id":"1127991","upvote_count":"1","content":"Both options (exporting to BigQuery and exporting to Coldline Storage) have their merits, and the choice depends on specific use cases, access patterns, and organizational preferences. If your organization values a more structured and analyzable format with SQL-like querying capabilities, BigQuery might be preferable. If the priority is on long-term, infrequent access with cost optimization, then Coldline Storage could be a suitable choice.","timestamp":"1705856700.0","poster":"zameerb"},{"timestamp":"1699260180.0","upvote_count":"1","poster":"BAofBK","comment_id":"1063649","content":"The correct answer is B."},{"upvote_count":"1","timestamp":"1698836760.0","poster":"gsmasad","content":"Selected Answer: B\nB is correct. coldline storage it is cost-effective and for long-term storage","comment_id":"1059621"},{"comment_id":"1013049","content":"B is correct. coldline storage it is cost-effective and for long-term storage","poster":"elviskimutai","upvote_count":"1","timestamp":"1695297840.0"},{"timestamp":"1681714260.0","upvote_count":"1","poster":"sabrinakloud","comment_id":"872422","content":"Selected Answer: B\nanswer B"},{"comments":[{"upvote_count":"8","comments":[{"timestamp":"1693993680.0","upvote_count":"4","content":"Buru, Thank you so much from whole GCP community for your efforts, you are incredible man !!!","poster":"Mac_1612","comment_id":"1000453","comments":[{"timestamp":"1694672220.0","comment_id":"1007279","content":"I agree thanks a lot!!!!","poster":"cucinareblog","upvote_count":"1"}]}],"timestamp":"1676924580.0","content":"INCORRECT:\n\nAnswer A is incorrect because while it does store logs in BigQuery, it is a more expensive option than storing logs in Coldline storage.\n\nAnswer C is incorrect because writing a custom script to copy logs to BigQuery would be complex and more difficult to maintain compared to using an export sink.\n\nAnswer D is incorrect because while logs can be exported to Pub/Sub, writing a Cloud Dataflow pipeline to store logs in Cloud SQL would require additional configuration and might not be as cost-effective as exporting logs to Coldline storage.","comment_id":"815828","poster":"Buruguduystunstugudunstuy"}],"upvote_count":"7","poster":"Buruguduystunstugudunstuy","content":"Selected Answer: B\nAnswer B. Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.\n\nTo meet the requirement of retaining log files for 3 years, a cost-effective approach is to export logs to a cheaper storage option like Cloud Storage Coldline storage class. The coldline storage class is designed for cold data storage and offers lower storage costs and higher retrieval costs when compared to other storage classes.\n\nExporting logs from Cloud Audit to a Coldline Storage bucket can be done by creating an export sink. This is a straightforward process that can be done via the Cloud Console, Cloud SDK, or REST API.","timestamp":"1676924520.0","comment_id":"815825"},{"content":"Selected Answer: B\nB. Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket. This is the most cost-effective approach for log file retention as Coldline Storage has lower storage costs compared to other storage classes, making it suitable for infrequently accessed data that still needs to be retained for a long time.","comment_id":"796945","timestamp":"1675418760.0","poster":"kaisehhop","upvote_count":"1"},{"timestamp":"1672755420.0","upvote_count":"1","content":"B is the most cost effective","comment_id":"764729","poster":"alex000"},{"comment_id":"756011","content":"https://cloud.google.com/logging/docs/export/configure_export_v2\nI go with B","timestamp":"1672002480.0","upvote_count":"1","poster":"Neeleshinuk"},{"timestamp":"1670350320.0","comment_id":"737108","upvote_count":"1","content":"Selected Answer: B\nB is the best","poster":"cslince"},{"comment_id":"721788","content":"Selected Answer: B\nB is the answer, because he wants a cost-effective solution so B is the cheapest option.","upvote_count":"1","timestamp":"1668837060.0","poster":"Zoze"},{"poster":"leogor","comment_id":"707886","timestamp":"1667143260.0","content":"Selected Answer: B\nColdline Storage bucket","upvote_count":"1"},{"comment_id":"705968","timestamp":"1666912140.0","content":"Selected Answer: B\nColdline would be the least expensive.","poster":"dennydream","upvote_count":"1"},{"poster":"sandipk91","comment_id":"658104","upvote_count":"2","content":"Selected Answer: B\nOption B because it talks about cost effective solution, I know BQ has the same cost as Coldline in GCS if data is kept for 90 days but in Cloud Storage we can save more by further moving the class to Archival which is cheaper than Coldline. SO DEFINATELY IT'S OPTION B","timestamp":"1662183420.0"},{"upvote_count":"1","content":"Selected Answer: A\nMy bad. A is good for bigquery can supports store many data","timestamp":"1660219740.0","comment_id":"645452","poster":"joeMP"},{"timestamp":"1660219680.0","comment_id":"645450","poster":"joeMP","content":"Selected Answer: B\nHundreds of projects means many logs. Bigquery is the good Storage.","upvote_count":"1"},{"timestamp":"1659793800.0","poster":"abirroy","content":"Selected Answer: B\nAnswer is B","comment_id":"643411","upvote_count":"1"},{"timestamp":"1656769860.0","content":"Answer is B","poster":"RanjithK","upvote_count":"1","comment_id":"626171"},{"timestamp":"1656000060.0","comment_id":"621097","poster":"AzureDP900","upvote_count":"1","content":"Since there is archive cold line is best in this scenario. Go with B as right answer."},{"timestamp":"1654246140.0","upvote_count":"1","poster":"haroldbenites","content":"Go for B","comment_id":"610994"},{"comment_id":"605151","poster":"akshaychavan7","upvote_count":"1","timestamp":"1653193740.0","content":"As per the Google recommended practice, audit logs are (by default) stored inside cloud storage. If cloud storage is a google recommended solution then it must be cost effective."},{"comment_id":"505458","upvote_count":"3","content":"Selected Answer: B\nB is correct","poster":"rafsrod","timestamp":"1640008620.0"},{"content":"Selected Answer: B\nb is the right option","comment_id":"504201","timestamp":"1639830180.0","upvote_count":"1","poster":"maahibhai"},{"upvote_count":"1","poster":"jaffarali","content":"Selected Answer: B\nB would be the right choice. The requirement doesn't say about analysis. Hence Coldline bucket storage would be cost effective.","timestamp":"1639318020.0","comment_id":"500048"},{"upvote_count":"2","timestamp":"1639053060.0","comment_id":"497715","poster":"arapin","content":"Selected Answer: B\nLogs are not structured data and relational databases are not a good fit. That excludes SQL.\nBesides that, the most cost effective solution of the 4 is under B, the Coldline storage bucket."},{"timestamp":"1637406300.0","comment_id":"482433","upvote_count":"2","poster":"vishnukumartr","content":"B. Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket."},{"upvote_count":"2","poster":"NonstopJo","comment_id":"473675","content":"B is correct","timestamp":"1636241580.0"},{"timestamp":"1633943880.0","upvote_count":"1","poster":"dttncl","content":"Answer is B.\n\nQuestion says audit log files will be stored for 3 years. Coldline storage is perfect for storing objects for years.","comment_id":"460488"},{"upvote_count":"1","timestamp":"1633186200.0","content":"B seems correct to me","comment_id":"456133","poster":"Litan"},{"upvote_count":"2","poster":"jay1992","timestamp":"1630027020.0","comment_id":"432656","content":"B is correct option... please refer https://tutorialsdojo.com/google-cloud-logging/"},{"timestamp":"1629834180.0","comment_id":"430990","poster":"sudav","content":"B - Coldline Storage is the perfect service to store audit logs from all the projects and is very cost-efficient as well. Coldline Storage is a very-low-cost, highly durable storage service for storing infrequently accessed data. Coldline Storage is a better choice than Standard Storage or Nearline Storage in scenarios where slightly lower availability, a 90-day minimum storage duration, and higher costs for data access are acceptable trade-offs for lowered at-rest storage costs. Coldline Storage is ideal for data you plan to read or modify at most once a quarter.\nRef: https://cloud.google.com/storage/docs/storage-classes#coldline","upvote_count":"2"},{"timestamp":"1625704920.0","comment_id":"401386","poster":"Nelson2080","content":"I Agree with B I found this snippet: \n\nWhen you load data into BigQuery from Cloud Storage, you are not charged for the load operation, but you do incur charges for storing the data in Cloud Storage. After the data is loaded into BigQuery, the data is subject to BigQuery's storage pricing.\n\nhttps://cloud.google.com/bigquery/docs/best-practices-storage","upvote_count":"2"},{"upvote_count":"2","content":"Option B: \nSupported destinations for logs exports: Cloud Storage, BigQuery and Pub/Sub out of which Cloud Storage more suitable.\nCloud Storage: JSON files stored in Cloud Storage buckets; provides inexpensive, long-term storage.\nhttps://cloud.google.com/logging/docs/export#supported-destinations","comment_id":"385826","timestamp":"1624145100.0","poster":"sunilw"},{"upvote_count":"1","comment_id":"363718","timestamp":"1621691700.0","content":"Option B: Coldline is the most cost effective option for data that is not required for analysis","poster":"Umesh09"},{"timestamp":"1621516500.0","poster":"arsh1916","comment_id":"362186","content":"B is correct","upvote_count":"1"},{"comment_id":"359574","poster":"katos","timestamp":"1621257780.0","content":"cloud storage cold line is 5 times cheaper than bigquery storage","upvote_count":"2"},{"content":"B is correct & cheapest option","upvote_count":"1","comment_id":"355326","poster":"mcaromit","timestamp":"1620801240.0"},{"poster":"jahnu","comment_id":"343151","timestamp":"1619431200.0","content":"My Ans: A because coldline storage store only one yaear.so I selected BigQuery.","comments":[{"poster":"mistryminded","timestamp":"1619555700.0","comment_id":"344214","content":"no documentation explains that it stores for only 1 year sorry to correct you but answer is B.","upvote_count":"1"},{"content":"What ???????\n\"\"My Ans: A because coldline storage store only one yaear.so I selected BigQuery.\"\"\n\nTotally wrong don't fall for this!! wrong \nwrong!!!!!!!!!!!","comment_id":"424791","poster":"ashrafh","upvote_count":"2","timestamp":"1628945880.0"}],"upvote_count":"2"},{"upvote_count":"3","poster":"ayush_1995","timestamp":"1618134120.0","comment_id":"333177","comments":[{"comment_id":"335853","upvote_count":"1","content":"Logs are required for Audit, not regular analysis - cold line is a better option","poster":"r1ck","timestamp":"1618438680.0","comments":[{"comment_id":"335854","timestamp":"1618438800.0","content":"Also requirement here is retention, would this he different because it's a Financial organization?","upvote_count":"1","poster":"r1ck"}]}],"content":"A\nAdmin Activity audit logs and System Event audit logs are free.\n\nData Access audit logs and Policy Denied audit logs are chargeable.\n\nhttps://cloud.google.com/logging/docs/audit/"},{"content":"B is correct. Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.","timestamp":"1616621040.0","comment_id":"319584","upvote_count":"2","poster":"[Removed]"},{"comment_id":"318777","upvote_count":"1","poster":"yuvi69","content":"correct option is B. because in the only talked about storing at cheap-cost, so coldline has low storage cost","timestamp":"1616561160.0"},{"comment_id":"314652","upvote_count":"1","content":"I vote B. It didn't say the file need to audit .It just say store file 3 year & cost-effective .","timestamp":"1616140800.0","poster":"pondai"},{"comment_id":"312695","content":"vote 4 'B'","upvote_count":"2","timestamp":"1615927320.0","poster":"sumanshu"},{"content":"B is correct","poster":"EABDAJA","timestamp":"1615229640.0","comment_id":"305886","upvote_count":"1"},{"upvote_count":"1","poster":"nliaustemac","content":"B. is the correct answer:\nCreate an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.","timestamp":"1614301080.0","comment_id":"299467"},{"comment_id":"296832","upvote_count":"1","poster":"nitinz","timestamp":"1614017700.0","content":"B it is, its written on the wall - \"You need to implement a cost-effective approach for log file retention\""},{"content":"B. Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.","upvote_count":"1","comment_id":"296143","timestamp":"1613945460.0","poster":"GCP_Student1"},{"comment_id":"280332","timestamp":"1612065360.0","upvote_count":"2","content":"I vote for B, Question says Audit log just for adding confusion, key point is Cost and retention for 3 year.. So coldline storage is correct per my understanding.","poster":"abhigcp04"},{"upvote_count":"1","content":"B - Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.","timestamp":"1611395940.0","poster":"victory108","comment_id":"274477"},{"comment_id":"272478","content":"Vote for B\nhttps://cloud.google.com/solutions/exporting-stackdriver-logging-for-compliance-requirements#configure_object_lifecycle_management","upvote_count":"2","poster":"DucSiu","timestamp":"1611197460.0"},{"poster":"Stambh","upvote_count":"1","content":"Its B only as we have to store files","comment_id":"257587","timestamp":"1609602840.0"},{"content":"Ans is B. The question is asking for cost-effective approach to long term storage (3 years) for log files. Coldline","timestamp":"1607980860.0","comment_id":"244049","upvote_count":"2","poster":"JKRowlings"},{"timestamp":"1606052460.0","poster":"swatititame","comment_id":"224986","content":"sorry, it's B. Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.","upvote_count":"1"},{"content":"• A. Create an export to the sink that saves logs from Cloud Audit to BigQuery.","comment_id":"220942","timestamp":"1605605700.0","poster":"swatititame","upvote_count":"1"},{"upvote_count":"1","timestamp":"1604958000.0","poster":"Renovatio","comment_id":"216232","content":"OPTION B \nCreate an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.\nSink does not have custom retentions so you need to move to Coldline. \nhttps://cloud.google.com/logging/docs/storage#logs-buckets"},{"comment_id":"215138","poster":"gh999l","timestamp":"1604829180.0","upvote_count":"1","content":"for cost effective retention only option B serves the requirement"},{"comment_id":"206129","content":"Vote for B, coldline cheaper for long term storage","timestamp":"1603704420.0","upvote_count":"1","poster":"nwk"},{"content":"B. Create an export to the sink that saves logs from Cloud Audit to a Coldline Storage bucket.","comment_id":"196523","poster":"glam","timestamp":"1602223440.0","upvote_count":"6"},{"poster":"JJ_ME","upvote_count":"1","timestamp":"1602135120.0","comment_id":"195757","comments":[{"poster":"cpd","comment_id":"197833","timestamp":"1602433140.0","content":"Sink can be created for all classes of storage buckets, directly. Ans: B","upvote_count":"1"}],"content":"A.\nColdline Storage (Option B) is cheapest but logs cannot be output directly to Coldline, making Option A correct.\nhttps://cloud.google.com/logging/docs/export/aggregated_sinks#creating_the_export_destination"},{"content":"I recognize that BigQuery may be more cost effective when it comes to running queries, however, the question does not say that the anyone actually queries the data. The question only mentions that logs need to be retained for a set period, likely due to a PCI-DSS requirement as they are a financial services company. Since the question only discusses 'cost effective approach for log file retention', I think the best option is B - Coldline Storage Bucket.","poster":"[Removed]","comment_id":"175906","upvote_count":"1","timestamp":"1599573780.0"},{"upvote_count":"1","comment_id":"175416","content":"Question is about retention/storage for which using a Cloud Storage(Coldline) is better solution rather than using BigQuery to store and incur heavy costs.","timestamp":"1599513840.0","poster":"yas_cloud"},{"upvote_count":"3","timestamp":"1597936140.0","poster":"SSPC","comment_id":"162316","content":"A is correct for me. https://cloud.google.com/logging/docs/audit/best-practices#export-best-practices"},{"timestamp":"1597616760.0","upvote_count":"2","comment_id":"159485","poster":"ESP_SAP","content":"Correct Answer is A:\n\nConfiguring Cloud Audit Logs\nDetermine and apply your organization-level data access policy. For more information, go to Configuring Data Access audit logs.\n\nUse a test Google Cloud project to validate the configuration of your Data Access audit logs collection before propagating to developer and production projects.\n\nAdopt a least-privilege approach to granting permissions.\n\nData Access audit logs are off by default. When you enable new Google Cloud services, evaluate whether or not to enable Data Access audit logs for that new service. Only BigQuery has Data Access audit logs enabled by default.\n\nhttps://cloud.google.com/logging/docs/audit/best-practices#export-best-practices","comments":[{"comments":[{"comment_id":"236984","poster":"Bhagirathi","upvote_count":"1","timestamp":"1607316360.0","content":"A or B ? which one should we choose?"}],"poster":"ESP_SAP","comment_id":"164551","timestamp":"1598201760.0","content":"CORRECTION...\nCorrect Answer is (B):\nScenarios for exporting Cloud Logging: Compliance requirements\nThis scenario shows how to export logs from Cloud Logging to Cloud Storage to meet your organization's compliance requirements.\n\nBest practice: Moving logs to Nearline or Coldline and then deleting them helps you manage the ongoing operational cost of maintaining the logs.\n\nYou can follow the instructions to create lifecycle rules. The following screenshot depicts a cascading set of rules that change the storage class to Nearline after 60 days, change the storage class to Coldline after 120 days, and then delete the logs after 2555 days, which is roughly 7 years.\n\nhttps://cloud.google.com/solutions/exporting-stackdriver-logging-for-compliance-requirements#configure_object_lifecycle_management","upvote_count":"3"}]},{"comment_id":"148662","upvote_count":"2","content":"It's B, for sure. A is not cost effective and B it will continue to be more cost effective than A, even in the need to retrieve the data.","poster":"someoneinthecloud","comments":[{"comment_id":"153406","poster":"Vigneshramesh","upvote_count":"4","content":"https://cloud.google.com/logging/docs/audit/best-practices#export-best-practices\n\nA should be correct for audit log export","timestamp":"1596954120.0"}],"timestamp":"1596300180.0"},{"poster":"Meeda","timestamp":"1596276240.0","comment_id":"148490","content":"It is definitely A.\n\nhttps://cloud.google.com/logging/docs/export","upvote_count":"1"},{"upvote_count":"8","timestamp":"1595981280.0","comment_id":"146149","content":"I think the key word is \"audit\" being audit it means the data must be readily queryable and stored in coldline is an cost effective option 0.007 USD/GB while saving data on BQ is 0.02 USD/GB, around 3 times more, but the query cost is the same, since you could not use storage to query. and do not forget the retrieval fee is so HIGH from coldline storage and that makes the final, BQ is better combing the storage, data retrieval and query capabilities. So A is undoubtedly the choice","poster":"evangelist"},{"comment_id":"142123","content":"Hundreds of projects , so it should be A","upvote_count":"1","timestamp":"1595517780.0","poster":"Bituz"},{"content":"Its B . no where it questions says need these logs for analysis or queering. SO most cost effective is to move to coldline storage.","comment_id":"106681","upvote_count":"4","timestamp":"1591783860.0","poster":"poogcp"},{"upvote_count":"3","content":"It depends how often is the auditing. The cost effective solution is B on a Coldline bucket, but if the auditing is infrequent, then it should be A.","timestamp":"1591716480.0","comment_id":"106082","comments":[{"poster":"nightflyer","timestamp":"1608375960.0","content":"Auditing can never be infrequent","comment_id":"247905","upvote_count":"1"}],"poster":"mlantonis"},{"timestamp":"1589800680.0","poster":"laze","content":"B is correct","comment_id":"91205","upvote_count":"3"},{"comment_id":"82473","timestamp":"1588389240.0","upvote_count":"3","content":"B is the answer","poster":"Agents89"},{"timestamp":"1588377600.0","comment_id":"82428","upvote_count":"5","poster":"ankit89","content":"B is correct"}],"question_images":[],"answers_community":["B (97%)","3%"],"answer_images":[],"url":"https://www.examtopics.com/discussions/google/view/17515-exam-associate-cloud-engineer-topic-1-question-61-discussion/","answer_description":"","answer":"B","unix_timestamp":1585230900,"timestamp":"2020-03-26 14:55:00","question_text":"Your organization is a financial company that needs to store audit log files for 3 years. Your organization has hundreds of Google Cloud projects. You need to implement a cost-effective approach for log file retention. What should you do?","answer_ET":"B"},{"id":"WY8EqzJ6SjASaWjZvASm","answers_community":["A (60%)","B (31%)","9%"],"isMC":true,"url":"https://www.examtopics.com/discussions/google/view/21981-exam-associate-cloud-engineer-topic-1-question-62-discussion/","discussion":[{"content":"Go to cloud console and create instance\nselect Memorystore with Basic tier, select us-central1 and us-central1-a, and capacity 32GB, the cost estimate is $0.023/GB/hr\n\nselect VM instance with custom machine type with 6 vCPUs and 32 GB memory, the same region and zone as Memorystore setting, the cost estimate is $0.239/hr\n\nOption B will definitely cost more as it adds on CPU usage cost even it uses little in this scenario, but still charge you. So answer is A from real practice example.","timestamp":"1597762920.0","upvote_count":"56","comments":[{"poster":"SSPC","timestamp":"1597936500.0","comment_id":"162319","upvote_count":"1","content":"I agree with you"},{"poster":"Rothmansua","comments":[{"comment_id":"558606","poster":"obeythefist","upvote_count":"2","comments":[{"poster":"smarty_arse","comments":[{"timestamp":"1668704760.0","poster":"RNSS","content":"believe me it is very good and clean. When I was doing my research I have used both google and bing. and find bing as more trusted and complete answer.","comment_id":"720681","upvote_count":"2"}],"timestamp":"1656164940.0","comment_id":"622149","upvote_count":"13","content":"Who uses Bing at this present day and age?"}],"content":"A quick Bing search shows a number of solutions for caching HTTP services with Redis.","timestamp":"1646115060.0"}],"upvote_count":"2","comment_id":"462876","content":"and what about HTTP, how are you supporting that with Redis?","timestamp":"1634360640.0"},{"timestamp":"1599730860.0","comments":[{"content":"I agree its cheaper, but 2 drawbacks, 1 hit latency, 2 you need to install cache plain won't help even if check. So still think A.","upvote_count":"3","comment_id":"177268","comments":[{"comment_id":"182794","content":"Typo correct my statements. There are 2 issues If you create a VM how every cheap there will be a hit with latency when communicating with it. Second, you will need to install/implement a caching system on that. \n\nWhereas cloud memorystore for redis is designed for the sole purpose of HTTP caching which has very low latency compared to any other solution we are thinking of doing.","poster":"[Removed]","upvote_count":"3","timestamp":"1600587060.0"}],"poster":"[Removed]","timestamp":"1599761580.0"}],"upvote_count":"8","comment_id":"177024","content":"Using pricing calculator matching 730 hrs per month for both.. Memorystore is 537.28 per month and vm (6 cpus 32 gb memory) is 174.41 per month. So vm is still cheaper even with 6 cpus.","poster":"mexblood1"},{"timestamp":"1610493180.0","poster":"FenixRa73","upvote_count":"4","content":"$0.023 * 32 = $0.736\nis it cheaper?","comment_id":"265918"}],"comment_id":"160967","poster":"jzh"},{"comments":[{"comments":[{"upvote_count":"2","poster":"[Removed]","comments":[{"comment_id":"255321","poster":"magistrum","upvote_count":"2","timestamp":"1609294080.0","content":"Agree, don't think anything you create with the Compute Engine will meet the \"You want to have a 30-GB in-memory cache\" requirement...that's a very different technology"}],"timestamp":"1599574260.0","content":"I agree with your reasoning. Given that the question stresses that this is for a 'latency sensitive website', that's a clue that Redis is part of the answer. Even if spinning up a similarly sized VM were more cost effective, I can't find any documentation that this would provide sufficiently low latency as a memory cache. Yes, you want to keep costs low, but not if it causes your latency-sensitive website problems. Thus I agree that option A is the answer.","comment_id":"175916"}],"content":"Just to complement the answer:\nWe are looking for \"latency-sensitive website\" \n\nWhat it's good for\nMemorystore for Redis provides a fast, in-memory store for use cases that require fast, real-time processing of data. From simple caching use cases to real time analytics, Memorystore for Redis provides the performance you need.\n\nCaching: Cache is an integral part of modern application architectures. Memorystore for Redis provides low latency access and high throughput for heavily accessed data, compared to accessing the data from a disk based backend store. Session management, frequently accessed queries, scripts, and pages are common examples of caching.\n\nhttps://cloud.google.com/memorystore/docs/redis/redis-overview#what_its_good_for","poster":"ESP_SAP","timestamp":"1598202600.0","upvote_count":"21","comment_id":"164562"}],"comment_id":"159492","poster":"ESP_SAP","timestamp":"1597618620.0","content":"Correct Answer should be A:\nThe question mention \"You want to have a 30-GB in-memory cache, and\nneed an additional 2 GB of memory for the rest of the processes\" \n\nWhat is Google Cloud Memorystore?\nOverview. Cloud Memorystore for Redis is a fully managed Redis service for Google Cloud Platform. Applications running on Google Cloud Platform can achieve extreme performance by leveraging the highly scalable, highly available, and secure Redis service without the burden of managing complex Redis deployments.","upvote_count":"35"},{"upvote_count":"1","content":"Selected Answer: B\nBoth Gemini and Claude.ai wotes for B. You need to run a reverse proxy server in this can you can eliminate A.","poster":"vaclavbenes1","timestamp":"1738913700.0","comment_id":"1352884"},{"upvote_count":"2","comment_id":"1332838","timestamp":"1735372800.0","content":"Selected Answer: B\nYou need 30 GB of in-memory cache plus an additional 2 GB for other processes.\nThe solution should minimize cost while fulfilling the memory requirements.\nOption Analysis:\n\nA. Create a Cloud Memorystore for Redis instance with 32-GB capacity:\nIncorrect: While Memorystore is designed for caching, it does not meet the requirement to host an HTTP reverse proxy. Memorystore is only a caching layer, not a compute platform for running processes.\n\nB. Run it on Compute Engine with a custom instance type:\nCorrect: Compute Engine allows you to specify a custom machine type tailored to your exact resource requirements (e.g., 6 vCPUs and 32 GB of memory). This minimizes cost compared to using a predefined machine type.\nThe reverse proxy can run directly on the Compute Engine instance, and the memory requirements are fulfilled.","poster":"Sekar_1992"},{"timestamp":"1733993520.0","poster":"mnasruul","comment_id":"1325491","content":"Selected Answer: B\nIm choice B because the question is `This specific reverse proxy consumes almost no CPU. You want to have a 30-GB in-memory cache, and need an additional 2 GB of memory for the rest of the processes`, they need additional 2 GB of memory for the rest of the processes and maybe cannot running at Redis.","upvote_count":"2"},{"content":"Selected Answer: D\nLas razones por las que cada opción es o no adecuada:\n\nA: INCORRECTA. Cloud Memorystore es un servicio de caché administrado, no puede ejecutar un proxy HTTP.\nB: INCORRECTA. 6 vCPUs es excesivo ya que se especifica que consume casi nada de CPU. Sería un desperdicio de recursos y dinero.\nC: INCORRECTA. GKE sería una sobrecarga innecesaria para una única instancia y n1-standard-32 es extremadamente sobredimensionado.\nD: CORRECTA. Una n1-standard-1 (1 vCPU, 3.75GB RAM) con un disco SSD de 32GB es la opción más económica que cumple los requisitos mínimos necesarios para el proxy.\n\nLa D es la correcta porque es la opción más económica que proporciona los recursos necesarios. Un SSD persistente puede usarse para swap si se necesita más memoria, aunque no será tan rápido como la memoria RAM.","comment_id":"1320722","upvote_count":"1","timestamp":"1733090520.0","poster":"Noni_11"},{"poster":"user263263","upvote_count":"1","content":"Selected Answer: B\nA. Redis isn't used as storage for caching proxies - it is a kind of key-value store.\nB. fulfills the requirements, e.g. take nginx use a RAM disk for caching\nC. wrong machine type (32 vCPU), don't need k8s\nD. technically possible, but does not fulfill \"in memory\" requirement","comment_id":"1318795","timestamp":"1732725180.0"},{"poster":"nubelukita45852","content":"Selected Answer: D\nLa n1-standard-1 es una instancia de bajo costo con 1 vCPU y 3.75 GB de memoria, suficiente para los procesos adicionales del proxy. Dado que el proxy inverso prácticamente no consume CPU, no es necesario optar por una instancia más grande. El disco persistente SSD de 32 GB puede actuar como almacenamiento para la caché en lugar de usar costosas soluciones en memoria, lo que ayuda a minimizar costos, mientras proporciona un almacenamiento rápido, suficiente para el sitio sensible a la latencia.","comment_id":"1287101","timestamp":"1726881300.0","upvote_count":"2"},{"content":"A might be a fine answer, except that Redis is not an http reverse proxy. It is a data cache. So A, regardless of the cost, does not work for this use case.","comment_id":"1258165","poster":"spatters","upvote_count":"1","timestamp":"1722338520.0"},{"poster":"subha.elumalai","upvote_count":"1","comment_id":"1216884","content":"Correct Answer:B","timestamp":"1716486960.0"},{"poster":"gsmasad","comment_id":"1059665","content":"Selected Answer: A\nA is correct because The question mention \"You want to have a 30-GB in-memory cache, and Redis is inmemory","upvote_count":"1","timestamp":"1698839220.0"},{"upvote_count":"1","comment_id":"1025538","timestamp":"1696502340.0","poster":"ekta25","content":"B. Run it on Compute Engine, and choose a custom instance type with 6 vCPUs and 32 GB of memory."},{"timestamp":"1693629120.0","poster":"Captain1212","upvote_count":"1","content":"Selected Answer: A\nA is the correct as redis for low latency","comment_id":"996563"},{"poster":"marcus021","content":"Selected Answer: A\nLow latency should be A.","timestamp":"1686303960.0","comment_id":"919149","upvote_count":"2"},{"comment_id":"914082","timestamp":"1685848140.0","content":"correct answer is A\nhttps://www.youtube.com/watch?v=a1p1pB375Ik","upvote_count":"1","poster":"sana_sree"},{"content":"Selected Answer: A\nANSWER A is the most cost-effective solution for running a caching HTTP reverse proxy on GCP. Cloud Memorystore for Redis is a managed service that provides an in-memory cache for your applications. It offers a high throughput and low latency access to the Redis protocol. Cloud Memorystore offers an SLA of 99.9% availability and automatic failover for Redis instances. In this case, a 32-GB Redis instance is sufficient to accommodate the 30-GB cache and the additional 2 GB of memory required for the rest of the processes. This solution is highly scalable and allows you to increase the size of the Redis instance as your needs grow.","upvote_count":"7","comments":[{"timestamp":"1676925060.0","content":"INCORRECT:\n\nANSWER B is not a cost-effective solution since it requires a custom instance type with 6 vCPUs and 32 GB of memory, which is over-provisioned for a caching HTTP reverse proxy.\n\nANSWER C is also not a cost-effective solution since it uses Kubernetes Engine, which has a higher management overhead and may not be necessary for a single caching HTTP reverse proxy. Additionally, using n1-standard-32 instances as nodes is over-provisioned for the requirements of the caching HTTP reverse proxy.\n\nANSWER D is not a viable solution since the instance type n1-standard-1 only provides 3.75 GB of memory, which is insufficient for the 30-GB cache and the additional 2 GB of memory required for the rest of the processes. Adding an SSD persistent disk of 32 GB will not provide enough memory for the reverse proxy.","comment_id":"815850","poster":"Buruguduystunstugudunstuy","upvote_count":"4"}],"timestamp":"1676925000.0","comment_id":"815849","poster":"Buruguduystunstugudunstuy"},{"poster":"kaisehhop","timestamp":"1675418880.0","upvote_count":"2","comment_id":"796948","content":"Selected Answer: A\nA. Create a Cloud Memorystore for Redis instance with 32-GB capacity is the recommended option. This option provides the required memory and is cost-effective since the proxy requires almost no CPU. Cloud Memorystore for Redis is designed specifically for in-memory caching, making it the best choice for your use case."},{"upvote_count":"1","poster":"cslince","comment_id":"737116","content":"Selected Answer: A\nanswer is A","timestamp":"1670350800.0"},{"upvote_count":"1","timestamp":"1669733040.0","poster":"fragment137","comment_id":"730523","content":"Selected Answer: B\nWhile Redis is definitely the easiest and best solution for a latency sensitive workload, the question is worded in such a way to emphasize the requirement of cost. \"You want to have a 30-GB in-memory cache, and need an additional 2 GB of memory for the rest of the processes. You want to minimize cost\". Given this, the answer has to be B, even if that's no the best technical solution for the problem."},{"comment_id":"721792","content":"Selected Answer: A\nA is correct, he only wants to have memory capacity, and doesn't care about CPU at all. In addition Memory-store is already configured to use is a cache memory.","upvote_count":"1","poster":"Zoze","timestamp":"1668837780.0"},{"content":"How do you figure the correct answer here? The votes overwhelmingly say one thing, but the correct answer is another.","comment_id":"705974","upvote_count":"1","timestamp":"1666912440.0","poster":"dennydream"},{"poster":"PKookNN","comment_id":"698114","content":"Selected Answer: B\nI changed my mind - cost effective is B (while A is easiest)","upvote_count":"1","timestamp":"1666088700.0"},{"upvote_count":"1","poster":"RanjithK","comment_id":"626172","timestamp":"1656770040.0","content":"Selected Answer: A\nAnswer is A"},{"upvote_count":"1","content":"A is right ..Memorystore for Redis provides a fast.","poster":"AzureDP900","comment_id":"621099","timestamp":"1656000240.0"},{"upvote_count":"3","comment_id":"619350","content":"Selected Answer: B\nMemoryStore Pricing is $0.023/GB/hr, for 32GB means $0.736/hr compares to $0.239/hr. The question states that it needs additional 2GB for it's process, which mean if you choose A, you will need another vm with 2GB ram either.","poster":"kohsiangyu","timestamp":"1655739000.0"},{"upvote_count":"2","poster":"haroldbenites","timestamp":"1654246260.0","content":"Go for A","comment_id":"610995"},{"poster":"browneyes1985","timestamp":"1648948860.0","comment_id":"580078","upvote_count":"1","content":"Selected Answer: A\nMemorystore offers various sizes to fit any budget. Pricing varies with settings—including how much capacity, how many replicas and which region you provision. Memorystore also offers per-second billing and instances and is easy to start and stop."},{"poster":"luciorifa","content":"Selected Answer: A\nMemory store is for chaching content","timestamp":"1645466100.0","comment_id":"553062","upvote_count":"2"},{"comment_id":"523157","upvote_count":"2","poster":"Raz0r","timestamp":"1642111920.0","content":"Selected Answer: A\nA is right:\nIs Redis a reverse proxy server?\nnginx-redis-proxy is a reverse proxy based on nginx and redis to cache objects (web pages and more)."},{"timestamp":"1641357840.0","comment_id":"517173","poster":"[Removed]","content":"I would go with A","upvote_count":"1"},{"comment_id":"482719","upvote_count":"4","content":"Hello everybody, i purchased the exam from the certification-questions website ... 45% of questions are not the same as discussed in the comment. Also the certification-question help says that their dump are pretty sure. Would plz any one help where to get the right answer, from here or any other dump. And should I take the first comment as the right answer?","timestamp":"1637427660.0","poster":"ahmadjw"},{"upvote_count":"2","content":"A. Create a Cloud Memorystore for Redis instance with 32-GB capacity.","timestamp":"1637407080.0","poster":"vishnukumartr","comment_id":"482445"},{"upvote_count":"1","timestamp":"1636781340.0","poster":"AshisKumar","content":"A is correct","comment_id":"477290"},{"poster":"gerhardbl","content":"My answer is B. You guys are all forgetting that you cannot run a proxy just on Redis. The question even says: \"need an additional 2 GB of memory for the rest of the processes\". You cannot use Memorystore as memory for such other processes; you'll need a VM to run the proxy. 6 vCPUs says nothing about the compute power, it could be 6 vCPUs of a very modest CPU type. Cost does not play a role here, you simply cannot get this done with answer A.","upvote_count":"5","comment_id":"425319","timestamp":"1629036600.0","comments":[{"comment_id":"445960","upvote_count":"3","timestamp":"1631799360.0","poster":"peter77","content":"Redis behaves like a reverse proxy. And the whole point here is to have content cached so you keep the latency low. Having a caching server in a VM is an aberration and a terrible architectural choice.\n\nIt's A 100%."}]},{"poster":"ready2rock","comment_id":"381890","timestamp":"1623676080.0","content":"I'm sorry - is Redis a reverse proxy server? I don't think it is so I go with B. If it is a reverse cache proxy then A, but I don't think it is","comments":[{"content":"Correct. Redis is an in memory key/value store. It won't proxy requests.","comment_id":"382711","timestamp":"1623766920.0","upvote_count":"2","poster":"accuracy23"}],"upvote_count":"3"},{"upvote_count":"1","poster":"Umesh09","comment_id":"363719","timestamp":"1621691820.0","content":"Option B : Caching/latency is the key work"},{"timestamp":"1620801480.0","upvote_count":"1","poster":"mcaromit","comment_id":"355328","content":"A is correct...microsecond latency"},{"upvote_count":"1","content":"Here we have 2 main points to think if price -> Vm is cheaper than memstore \nbut when it comes to latency-sensitive website -> memory store is the best.\n\nNo, what should i choose?","comments":[{"comment_id":"324328","poster":"tavva_prudhvi","timestamp":"1617114300.0","upvote_count":"2","content":"It's simple, even if you create a VM how cheap it is there will be a hit with latency when communicating with it. Second, you will need to install/implement a caching system on that."},{"poster":"Rothmansua","timestamp":"1634360760.0","upvote_count":"1","content":"how to proxy HTTP requests with Redis?","comment_id":"462877"}],"poster":"tavva_prudhvi","timestamp":"1616674860.0","comment_id":"320165"},{"content":"A is correct. Create a Cloud Memorystore for Redis instance with 32-GB capacity.","upvote_count":"2","poster":"[Removed]","comment_id":"320161","timestamp":"1616674680.0"},{"poster":"yuvi69","content":"correct option is A","comment_id":"318793","timestamp":"1616563020.0","upvote_count":"2"},{"timestamp":"1615927680.0","comment_id":"312703","upvote_count":"1","poster":"sumanshu","content":"vote for 'A'"},{"poster":"Hi2ALL","content":"A is the correct answer as questions clearly mentioned it doesn't use CPU","comment_id":"303336","comments":[{"content":"Correction: doesn't \"consume CPU\"","timestamp":"1614862320.0","comment_id":"303337","poster":"Hi2ALL","upvote_count":"1"}],"timestamp":"1614862260.0","upvote_count":"1"},{"timestamp":"1614793260.0","poster":"kartikjena31","upvote_count":"1","comment_id":"302775","content":"A is correct"},{"content":"A. is the correct answer:\nCreate a Cloud Memorystore for Redis instance with 32-GB capacity.","comment_id":"299468","timestamp":"1614301620.0","poster":"nliaustemac","upvote_count":"1"},{"poster":"GCP_Student1","comment_id":"296157","timestamp":"1613946960.0","content":"A. Create a Cloud Memorystore for Redis instance with 32-GB capacity.","upvote_count":"1"},{"timestamp":"1613446740.0","upvote_count":"1","poster":"adedj99","content":"i am with A, Redish bit chipper and a fully manage in memory data store . Any how application doesnt require CPU , then it waste some money for cost and operation cost for non fully managed services","comment_id":"291463"},{"upvote_count":"3","timestamp":"1612129200.0","poster":"JackGlemins","comment_id":"280841","content":"I think A is right. The key word is \"for a latency-sensitive website.\"\n\nhttps://cloud.google.com/memorystore/docs/redis/redis-overview#what_its_good_for\n\nMemorystore for Redis provides a fast, in-memory store for use cases that require fast, real-time processing of data. From simple caching use cases to real time analytics, Memorystore for Redis provides the performance you need.\n\nCaching: Cache is an integral part of modern application architectures. Memorystore for Redis provides low latency access and high throughput for heavily accessed data, compared to accessing the data from a disk based backend store. Session management, frequently accessed queries, scripts, and pages are common examples of caching"},{"upvote_count":"1","timestamp":"1611395820.0","poster":"victory108","content":"A - Create a Cloud Memorystore for Redis instance with 32-GB capacity.","comment_id":"274475"},{"upvote_count":"10","content":"how about the key phrase \" need an additional 2 GB of memory for the rest of the processes\"?\nA - not suitable, Memorystore for Redis = without background processes.\nB - suitable, \nprice:\n per month Memorystore for Redis 32 Gb(basic): $537.28 (standard):$1,074.56\n per month GCE 6vCPU 32 Ram: $199.78","timestamp":"1610493660.0","comment_id":"265922","poster":"FenixRa73"},{"content":"open B is correct because its cost is less in compute engine rather than memory store for redis.","poster":"Harish57","comment_id":"238939","timestamp":"1607492940.0","upvote_count":"3"},{"timestamp":"1605715440.0","comment_id":"222036","poster":"ayj","content":"B is cheaper on the price calculator:\nhttps://cloud.google.com/products/calculator/#id=fda49660-0881-4bd1-aad6-fe742998958e","upvote_count":"1"},{"upvote_count":"1","timestamp":"1605606540.0","poster":"swatititame","comment_id":"220949","content":"• A. Create a Cloud Memorystore for Redis instance with 32-GB capacity."},{"poster":"gh999l","upvote_count":"1","comment_id":"215140","timestamp":"1604829420.0","content":"No doubt A, As question suggests that CPU is not required."},{"poster":"nsibuea","timestamp":"1604367900.0","content":"A is the best choice. for B there is 6 vcpu. why you need 6 vcpu when there is almost no requirement for CPU.....","comment_id":"211630","upvote_count":"1"},{"upvote_count":"1","content":"Vote for A","timestamp":"1603704720.0","poster":"nwk","comment_id":"206134"},{"comments":[{"poster":"glam","comment_id":"199659","content":"B is Cheaper... \nB. Run it on Compute Engine, and choose a custom instance type with 6 vCPUs and 32 GB of memory.","timestamp":"1602667200.0","comments":[{"comment_id":"317820","poster":"tavva_prudhvi","content":"I have a doubt, can I know why do we need 6 vCPU'S if the question mentions about 'no CPU'?","upvote_count":"1","timestamp":"1616481180.0"}],"upvote_count":"4"}],"poster":"glam","upvote_count":"5","comment_id":"196536","content":"A. Create a Cloud Memorystore for Redis instance with 32-GB capacity.","timestamp":"1602224460.0"},{"comment_id":"191407","timestamp":"1601616060.0","content":"Correct answer is A. The key point to note here is in-memory cache and hence Cloud Memorystore is the ideal option.","poster":"Abishaik","upvote_count":"2"},{"upvote_count":"1","content":"B is the most cost-effective option if you only are concerned about the billing amount.\nB is the most cost-effective option if you are concerned about the TCO.\nThen? A or B for the exam?","comment_id":"173192","poster":"Ale1973","timestamp":"1599202980.0"},{"timestamp":"1596300300.0","content":"It's A. Every time someone asks for data caching/reverse proxy for low sensitive applications, they're talking about redis or memcached...If A wasn't an option, than B could be the answer.","comments":[{"content":"but you forget a big factor in the question which is the cost, \"You want to minimize cost\"\ni think B is the cheapest solution","comment_id":"157478","timestamp":"1597336080.0","upvote_count":"3","poster":"Hjameel"}],"upvote_count":"1","comment_id":"148664","poster":"someoneinthecloud"},{"comment_id":"106687","timestamp":"1591784160.0","poster":"poogcp","content":"A best choice when compare to pricing .","upvote_count":"8","comments":[{"comments":[{"poster":"Maximus1","timestamp":"1592592780.0","content":"redis can be used for http reverse proxy caching. So A seems better option.","upvote_count":"6","comment_id":"114185"}],"content":"it will be all most the same price, but if you choose option B you are loosing 6 VCPU that doesnt do nothing, you are correct - A is better.","comment_id":"107248","upvote_count":"6","timestamp":"1591828140.0","poster":"dan80"}]},{"comments":[{"comments":[{"timestamp":"1593682560.0","poster":"spudleymcdudley","content":"Oh and C has 32 CPU and 120GB RAM. Bit pricey. B for sure","upvote_count":"1","comment_id":"124860"}],"content":"To back this up A is only a key pair store so makes no sense. Despite wasted CPU's it's still cheaper than C and D is not on-memory, it's on SSD.","poster":"spudleymcdudley","timestamp":"1593682440.0","comment_id":"124858","upvote_count":"2"}],"upvote_count":"4","content":"Agree with B , only option A and B has the Memory needed, but option B is cheaper.","poster":"dan80","comment_id":"101385","timestamp":"1591154460.0"}],"exam_id":1,"question_id":245,"timestamp":"2020-06-03 05:21:00","unix_timestamp":1591154460,"answer_description":"","answer_ET":"A","topic":"1","choices":{"C":"Package it in a container image, and run it on Kubernetes Engine, using n1-standard-32 instances as nodes.","D":"Run it on Compute Engine, choose the instance type n1-standard-1, and add an SSD persistent disk of 32 GB.","A":"Create a Cloud Memorystore for Redis instance with 32-GB capacity.","B":"Run it on Compute Engine, and choose a custom instance type with 6 vCPUs and 32 GB of memory."},"question_images":[],"answer_images":[],"answer":"A","question_text":"You want to run a single caching HTTP reverse proxy on GCP for a latency-sensitive website. This specific reverse proxy consumes almost no CPU. You want to have a 30-GB in-memory cache, and need an additional 2 GB of memory for the rest of the processes. You want to minimize cost. How should you run this reverse proxy?"}],"exam":{"numberOfQuestions":285,"isMCOnly":true,"id":1,"isBeta":false,"name":"Associate Cloud Engineer","lastUpdated":"11 Apr 2025","provider":"Google","isImplemented":true},"currentPage":49},"__N_SSP":true}