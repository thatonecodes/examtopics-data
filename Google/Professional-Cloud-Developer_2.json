{"pageProps":{"questions":[{"id":"7dFy29YzZFnAOWPydelp","exam_id":7,"answers_community":["D (100%)"],"choices":{"B":"When creating the Compute Engine instance, add a tag with the name of the database to be connected. In your application, query the Compute Engine API to pull the tags for the current instance, and use the tag to construct the appropriate database connection string.","C":"When creating the Compute Engine instance, create a metadata item with a key of ג€DATABASEג€ and a value for the appropriate database connection string. In your application, read the ג€DATABASEג€ environment variable, and use the value to connect to the appropriate database.","A":"Embed the appropriate database connection string in the image. Create a different image for each environment.","D":"When creating the Compute Engine instance, create a metadata item with a key of ג€DATABASEג€ and a value for the appropriate database connection string. In your application, query the metadata server for the ג€DATABASEג€ value, and use the value to connect to the appropriate database."},"question_id":6,"topic":"1","answer_images":[],"answer_description":"","answer":"D","question_images":[],"discussion":[{"poster":"HotSpa27","comment_id":"518000","timestamp":"1688618760.0","upvote_count":"7","content":"I vote D.\nhttps://cloud.google.com/compute/docs/metadata/querying-metadata"},{"upvote_count":"1","poster":"omermahgoub","timestamp":"1720668840.0","comment_id":"772055","content":"D. When creating the Compute Engine instance, create a metadata item with a key of \"DATABASE\" and a value for the appropriate database connection string. In your application, query the metadata server for the \"DATABASE\" value, and use the value to connect to the appropriate database.\n\nThis approach allows you to create a single golden image that is agnostic to the environment it is running in, while still allowing the appropriate database connection to be set at runtime. The metadata item is stored with the instance, so it can be read by your application at any time. This method allows you to avoid creating different images for different environments, and to use the same image for all environments.\n\nYou can create metadata item by using the gcloud command line tool or the API to set metadata for a Compute Engine instance. Once set, the metadata can be easily accessed by your application via the instance metadata server."},{"timestamp":"1718957220.0","poster":"zellck","upvote_count":"1","comment_id":"752120","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/compute/docs/metadata/setting-custom-metadata"},{"comment_id":"649273","timestamp":"1708416240.0","upvote_count":"2","content":"Selected Answer: D\nD is correct","poster":"tomato123"},{"upvote_count":"1","timestamp":"1707197220.0","poster":"akshaychavan7","comment_id":"643173","content":"Selected Answer: D\nIt should be D!"},{"poster":"GCPCloudArchitectUser","upvote_count":"3","content":"Selected Answer: D\nThanks HotSpa27 it is indeed D \nEvery VM stores its metadata on a metadata server. Use these instructions to query these metadata values. You can only query the metadata server programmatically from within a VM","comment_id":"556745","timestamp":"1693056960.0"},{"content":"D:\n\nhttps://cloud.google.com/compute/docs/metadata/overview","upvote_count":"3","timestamp":"1688254860.0","comment_id":"514767","poster":"JonathanSJ"}],"url":"https://www.examtopics.com/discussions/google/view/69229-exam-professional-cloud-developer-topic-1-question-103/","isMC":true,"timestamp":"2022-01-02 02:41:00","question_text":"You want to create `fully baked` or `golden` Compute Engine images for your application. You need to bootstrap your application to connect to the appropriate database according to the environment the application is running on (test, staging, production). What should you do?","answer_ET":"D","unix_timestamp":1641087660},{"id":"WdaGShgaeQev4EefLktX","exam_id":7,"choices":{"B":"Store the application credentials as Kubernetes Secrets, and expose them as environment variables.","A":"Configure the appropriate service accounts, and use Workload Identity to run the pods.","D":"Store the application credentials using Cloud Key Management Service, and retrieve them whenever a database connection is made.","C":"Configure the appropriate routing rules, and use a VPC-native cluster to directly connect to the database."},"question_text":"You are developing a microservice-based application that will be deployed on a Google Kubernetes Engine cluster. The application needs to read and write to a\nSpanner database. You want to follow security best practices while minimizing code changes. How should you configure your application to retrieve Spanner credentials?","url":"https://www.examtopics.com/discussions/google/view/69773-exam-professional-cloud-developer-topic-1-question-104/","answers_community":["A (76%)","B (24%)"],"isMC":true,"question_id":7,"timestamp":"2022-01-09 18:23:00","unix_timestamp":1641748980,"answer_ET":"A","answer_images":[],"topic":"1","answer":"A","question_images":[],"answer_description":"","discussion":[{"timestamp":"1660535700.0","upvote_count":"8","poster":"kinoko1330","content":"Selected Answer: A\nhttps://cloud.google.com/blog/products/containers-kubernetes/introducing-workload-identity-better-authentication-for-your-gke-applications\n\nA Cloud IAM service account is an identity that an application can use to make requests to Google APIs. As an application developer, you could generate individual IAM service accounts for each application, and then download and store the keys as a Kubernetes secret that you manually rotate. Not only is this process burdensome, but service account keys only expire every 10 years (or until you manually rotate them). In the case of a breach or compromise, an unaccounted-for key could mean prolonged access for an attacker. This potential blind spot, plus the management overhead of key inventory and rotation, makes using service account keys as secrets a less than ideal method for authenticating GKE workloads.","comment_id":"647010","comments":[{"timestamp":"1660825260.0","content":"Exact...\nand it's a recent alternative to secrets ... why would google want you to ignore it? :)","comment_id":"648426","upvote_count":"2","poster":"alex8081"}]},{"upvote_count":"5","comment_id":"575738","poster":"htakami","timestamp":"1648322820.0","content":"I assume that nobody read through the official docs and GCP Best practices for K8s and Cloud SQL. https://cloud.google.com/sql/docs/mysql/connect-kubernetes-engine#secrets\n\n\"A database credentials Secret includes the name of the database user you are connecting as, and the user's database password.\"\n\nThe best answer here is B, having K8s Secrets is the go-to method to configure and store sensitive information within a cluster such as Spanner credentials"},{"content":"Selected Answer: A\nAnswer A. Workload Identity:\n\nNative GKE-IAM integration\nNo credential management needed\nAutomatic rotation\nGoogle-recommended approach\nMinimal code changes","upvote_count":"1","poster":"dneves","comment_id":"1330500","timestamp":"1734889980.0"},{"comment_id":"1321558","upvote_count":"1","comments":[{"timestamp":"1733301300.0","comment_id":"1321774","poster":"forallthings","content":"Correcting myself. A is the right answer. Cloud Spanner does not use traditional approach with username and password","upvote_count":"1"}],"timestamp":"1733261040.0","poster":"forallthings","content":"Selected Answer: B\nThe question is to retrieve Spanner credentials, i.e username and password. Workload Identity is to allow GKE app to connect to Spanner service, not to access the DB."},{"timestamp":"1721364840.0","upvote_count":"1","comments":[{"timestamp":"1721364840.0","comments":[{"timestamp":"1721364840.0","poster":"thewalker","comment_id":"1250846","upvote_count":"1","content":"Why Workload Identity is the Best Practice:\n\nSecurity: Workload Identity eliminates the need to store sensitive credentials within your pods, making your application more secure.\nSimplified Management: You can manage access control and permissions through Google Cloud IAM, which is easier than managing credentials within your Kubernetes cluster.\nIntegration with Google Cloud: Workload Identity seamlessly integrates with Google Cloud services, making it a natural choice for applications running on GKE."}],"comment_id":"1250845","poster":"thewalker","content":"Let's break down why the other options are less ideal:\n\nB. Store credentials as Kubernetes Secrets: While this approach works, it's less secure than Workload Identity. Storing credentials in Secrets exposes them to potential security risks within the cluster.\nC. VPC-native cluster and routing rules: This approach focuses on network connectivity but doesn't address the core issue of secure credential management.\nD. Cloud Key Management Service (KMS): KMS is excellent for managing encryption keys, but it's not the primary solution for retrieving Spanner credentials. KMS is more suited for encrypting data at rest.","upvote_count":"1"}],"comment_id":"1250844","content":"Selected Answer: A\nThe best answer here is A. Configure the appropriate service accounts, and use Workload Identity to run the pods.\n\nHere's why:\n\nWorkload Identity: Workload Identity is a Google Cloud feature that allows Kubernetes service accounts to act as Google Cloud IAM service accounts. This means your pods can authenticate to Spanner without needing to store credentials directly within the pod.","poster":"thewalker"},{"comment_id":"1073624","poster":"braska","upvote_count":"1","content":"Selected Answer: A\nOption A is the recommended approach for securely configuring your microservice-based application to retrieve Spanner credentials on Google Kubernetes Engine (GKE)","timestamp":"1700253540.0"},{"timestamp":"1695199620.0","content":"Selected Answer: A\nThis approach involves configuring service accounts with the necessary permissions to access the Spanner database. By using Workload Identity, you can associate these service accounts with your Kubernetes Engine pods, allowing them to authenticate and retrieve Spanner credentials automatically.","poster":"__rajan__","comment_id":"1012088","upvote_count":"2"},{"poster":"closer89","timestamp":"1682075820.0","content":"Selected Answer: B\ni go for B\nquestion is about how to RETRIEVE db creds\nhttps://cloud.google.com/sql/docs/mysql/connect-kubernetes-engine#secrets\nA is about how to connect to spanner","comment_id":"876449","upvote_count":"1"},{"timestamp":"1675614540.0","poster":"[Removed]","content":"Selected Answer: A\nGoogle recommends using service accounts and work load identity whenever possible","upvote_count":"2","comment_id":"798985","comments":[{"timestamp":"1682409720.0","content":"Exactly!","comment_id":"880103","upvote_count":"1","poster":"felipeschossler"}]},{"comment_id":"772058","upvote_count":"1","timestamp":"1673415360.0","content":"A. Configure the appropriate service accounts, and use Workload Identity to run the pods.\n\nWorkload Identity is a way to associate Kubernetes service accounts with Google Cloud IAM service accounts, allowing your pods to authenticate to Google Cloud services using their IAM identity. This means that you don't have to store application credentials in your code or in Kubernetes Secrets, and you can manage the permissions of your application in Google Cloud IAM.\n\nYou would need to create service account in cloud IAM and a Kubernetes service account and then map them to use Workload Identity.\nYou can also use gcloud command line to map the Kubernetes service account to the desired IAM service account. Then in your application, you can use the Kubernetes service account to authenticate to Spanner, which will authenticate as the mapped IAM service account.\n\nThis way you don't have to hardcode credentials in your code, and you can easily manage the permissions of your application using Google Cloud IAM.","poster":"omermahgoub"},{"content":"Selected Answer: A\nA is the answer.\n\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity#what_is\nApplications running on GKE might need access to Google Cloud APIs such as Compute Engine API, BigQuery Storage API, or Machine Learning APIs.\n\nWorkload Identity allows a Kubernetes service account in your GKE cluster to act as an IAM service account. Pods that use the configured Kubernetes service account automatically authenticate as the IAM service account when accessing Google Cloud APIs. Using Workload Identity allows you to assign distinct, fine-grained identities and authorization for each application in your cluster.","comment_id":"752118","poster":"zellck","upvote_count":"1","timestamp":"1671617040.0"},{"upvote_count":"2","content":"Selected Answer: A\nAnswer is A\n Store the application credentials as Kubernetes Secrets, and expose them as environment variables","poster":"TNT87","timestamp":"1669013220.0","comments":[{"timestamp":"1669013280.0","poster":"TNT87","comments":[{"upvote_count":"1","content":"It cant be B because \nBecause Secrets can be created independently of the Pods that use them, there is less risk of the Secret (and its data) being exposed during the workflow of creating, viewing, and editing Pods. Kubernetes, and applications that run in your cluster, can also take additional precautions with Secrets, such as avoiding writing secret data to nonvolatile storage.\n\nSecrets are similar to ConfigMaps but are specifically intended to hold confidential data.\n\nCaution:\nKubernetes Secrets are, by default, stored unencrypted in the API server's underlying data store (etcd). Anyone with API access can retrieve or modify a Secret, and so can anyone with access to etcd. Additionally, anyone who is authorized to create a Pod in a namespace can use that access to read any Secret in that namespace; this includes indirect access such as the ability to create a Deployment.","timestamp":"1669013400.0","poster":"TNT87","comment_id":"723215"}],"comment_id":"723213","content":"Sorry i dwant to paste the link to A, not answer B. B is wrong. \nhttps://kubernetes.io/docs/concepts/configuration/secret/#alternatives-to-secrets\nAnswer A","upvote_count":"1"}],"comment_id":"723212"},{"poster":"tomato123","content":"Selected Answer: A\nI think A is correct","timestamp":"1660975500.0","comment_id":"649274","upvote_count":"4"},{"timestamp":"1657775040.0","comment_id":"631190","comments":[{"upvote_count":"1","poster":"akshaychavan7","timestamp":"1659757140.0","comment_id":"643176","content":"A service account will only allow you to establish your workload identity(basically authenticate the identity of your cluster pods).\nBut, in order to establish a database connection, you would need to connect it using the DB credentials( like host, user id, password, and database name to connect to). To securely store such credentials, Google recommends using a Secret Manager. So the answer would be B!"}],"content":"Selected Answer: A\nA and B ,both are correct. Curently in my project we are using A for allowing pods to query Bigquery. So A and B both seems to be correct.","poster":"nehaxlpb","upvote_count":"1"},{"poster":"[Removed]","content":"Selected Answer: B\nB. \nThe question is not about how to connect/access Cloud Spanner, but is how to \"retrieve Spanner *credentials*\".","timestamp":"1653742080.0","upvote_count":"3","comment_id":"608399"},{"comment_id":"604524","upvote_count":"1","timestamp":"1653061560.0","content":"A and B -> It should be select 2 best options question.","poster":"brewpike"},{"content":"Selected Answer: B\nI think B is more suitable in this situation","timestamp":"1653004980.0","upvote_count":"3","poster":"americoleonardo","comment_id":"604179"},{"timestamp":"1645889880.0","comment_id":"556746","content":"Selected Answer: A\nYes A is the option","poster":"GCPCloudArchitectUser","upvote_count":"2"},{"content":"I vote A\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity","comment_id":"520367","timestamp":"1641748980.0","poster":"scaenruy","comments":[{"comments":[{"content":"yes is better b","timestamp":"1646087040.0","upvote_count":"1","comment_id":"558391","poster":"juancambb"}],"upvote_count":"1","content":"Yes could be Option A , also Option B could work, not sure if Option B is not right considering the question states minimum code changes?","poster":"Blueocean","timestamp":"1642265580.0","comment_id":"524298"}],"upvote_count":"4"}]},{"id":"5Sfv3mxqHDoTPsHiBdVT","choices":{"C":"Assign the Cloud SQL Client role.","A":"Assign the Project Editor role.","D":"Assign the Cloud SQL Editor role.","B":"Assign the Project Owner role."},"question_images":[],"unix_timestamp":1641749220,"answer_description":"","topic":"1","exam_id":7,"answers_community":["C (100%)"],"answer":"C","answer_ET":"C","timestamp":"2022-01-09 18:27:00","question_id":8,"url":"https://www.examtopics.com/discussions/google/view/69774-exam-professional-cloud-developer-topic-1-question-105/","question_text":"You are deploying your application on a Compute Engine instance that communicates with Cloud SQL. You will use Cloud SQL Proxy to allow your application to communicate to the database using the service account associated with the application's instance. You want to follow the Google-recommended best practice of providing minimum access for the role assigned to the service account. What should you do?","discussion":[{"upvote_count":"7","content":"I vote C\nhttps://cloud.google.com/sql/docs/mysql/roles-and-permissions","comment_id":"520368","poster":"scaenruy","timestamp":"1657380420.0"},{"timestamp":"1729133340.0","poster":"alpha_canary","content":"Selected Answer: C\nhttps://cloud.google.com/sql/docs/mysql/roles-and-permissions#:~:text=When%20you%20use%20an%20account%20to%20connect%20to%20a%20Cloud%20SQL%20instance%2C%20the%20account%20must%20have%20the%20Cloud%20SQL%20%3E%20Client%20role%20(roles/cloudsql.client)%2C%20which%20includes%20the%20permissions%20required%20for%20connecting.","comment_id":"1196950","upvote_count":"1"},{"poster":"__rajan__","comment_id":"1012103","upvote_count":"1","content":"Selected Answer: C\nCloud SQL Client role: This role provides the necessary permissions to interact with Cloud SQL while minimizing access to other resources.","timestamp":"1710932160.0"},{"comment_id":"772061","poster":"omermahgoub","content":"C. Assign the Cloud SQL Client role.\n\nThe Cloud SQL Client role has the minimal set of permissions required to access Cloud SQL instances. This role includes permissions to connect to and use a Cloud SQL instance, but it doesn't include permissions to create, delete or manage the instance itself. This role should be granted to the service account associated with your Compute Engine instance, in order to allow your application to connect to the Cloud SQL instance using the Cloud SQL Proxy.\n\nYou can assign the Cloud SQL Client role to a service account by using the Cloud Console, the gcloud command-line tool, or the Cloud Identity and Access Management (IAM) API. Once the role is assigned, your application will be able to authenticate to Cloud SQL using the service account and the Cloud SQL Proxy.\n\nIt is important to note that the permissions granted by this role should be limited to the specific Cloud SQL instance that the application needs to connect to and not the entire project, to minimize the access and follow the principle of least privilege.","timestamp":"1689046680.0","upvote_count":"1"},{"upvote_count":"1","comment_id":"752115","timestamp":"1687334520.0","content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/sql/docs/mysql/roles-and-permissions#proxy-roles-permissions\nIf you are connecting to a Cloud SQL instance from a Compute Engine instance using Cloud SQL Auth proxy, you can use the default Compute Engine service account associated with the Compute Engine instance.\n\nAs with all accounts connecting to a Cloud SQL instance, the service account must have the Cloud SQL > Client role.","poster":"zellck"},{"content":"Selected Answer: C\nC is correct","upvote_count":"3","poster":"tomato123","timestamp":"1676880300.0","comment_id":"649275"}],"isMC":true,"answer_images":[]},{"id":"ZStXOYqsjDeCMRuoVEn2","answer":"C","topic":"1","question_id":9,"question_images":[],"exam_id":7,"choices":{"D":"Use a Horizontal Pod Autoscaler to scale the containers, and expose them via a NodePort Service.","B":"Use a Vertical Pod Autoscaler to scale the containers, and expose them via a NodePort Service.","A":"Use a Vertical Pod Autoscaler to scale the containers, and expose them via a ClusterIP Service.","C":"Use a Horizontal Pod Autoscaler to scale the containers, and expose them via a ClusterIP Service."},"answer_ET":"C","answers_community":["C (100%)"],"question_text":"Your team develops stateless services that run on Google Kubernetes Engine (GKE). You need to deploy a new service that will only be accessed by other services running in the GKE cluster. The service will need to scale as quickly as possible to respond to changing load. What should you do?","timestamp":"2022-01-09 17:34:00","isMC":true,"answer_description":"","discussion":[{"timestamp":"1732608420.0","poster":"plutonians123","upvote_count":"2","comment_id":"1080542","content":"Selected Answer: C\nHorizontal Pod Autoscaler (HPA) scales the number of pod replicas based on CPU usage or other select metrics, which is suitable for quick scaling with load changes. ClusterIP is appropriate for services only accessible within the cluster. This combination seems to meet all the requirements."},{"upvote_count":"1","poster":"__rajan__","content":"Selected Answer: C\nHPA automatically scales the number of pods in a deployment based on CPU utilization or other custom metrics. By using HPA, you can ensure that your service scales quickly to respond to changing load while minimizing manual intervention. Exposing the service via a ClusterIP Service allows other services running in the GKE cluster to access it securely without exposing it to the public internet.","timestamp":"1726822740.0","comment_id":"1012111"},{"content":"C. Use a Horizontal Pod Autoscaler to scale the containers, and expose them via a ClusterIP Service.\n\nWhen dealing with services that are only accessed by other services in the same GKE cluster, it's usually best to use a ClusterIP Service. This type of service allows pods to be accessed by other pods within the cluster using their IP address, but doesn't expose them to the outside world.","timestamp":"1704951540.0","comments":[{"upvote_count":"1","poster":"omermahgoub","content":"A Horizontal Pod Autoscaler is used to automatically scale the number of replicas of a deployment based on certain metrics. This is useful for scaling based on CPU utilization, memory usage, or custom metrics. By using a Horizontal Pod Autoscaler, you can respond quickly to changes in load by automatically creating or deleting replicas of your pods, so the service can handle the traffic.\n\nYou can expose the service via a ClusterIP Service by creating one in Kubernetes and configuring the selector to match the replicas running in your deployment. This allows other services to discover and communicate with your new service by its ClusterIP.","timestamp":"1704951540.0","comment_id":"772064"}],"upvote_count":"1","poster":"omermahgoub","comment_id":"772062"},{"upvote_count":"1","poster":"zellck","content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/service#services_of_type_clusterip\nWhen you create a Service of type ClusterIP, Kubernetes creates a stable IP address that is accessible from nodes in the cluster.\n\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/horizontalpodautoscaler\nThe Horizontal Pod Autoscaler changes the shape of your Kubernetes workload by automatically increasing or decreasing the number of Pods in response to the workload's CPU or memory consumption, or in response to custom metrics reported from within Kubernetes or external metrics from sources outside of your cluster.","comment_id":"752114","timestamp":"1703152800.0"},{"content":"Selected Answer: C\nC is correct","timestamp":"1692511560.0","comment_id":"649276","poster":"tomato123","upvote_count":"2"},{"upvote_count":"3","poster":"scaenruy","content":"I vote C","timestamp":"1673282040.0","comment_id":"520331","comments":[{"content":"Agree Option C \nhttps://cloud.google.com/kubernetes-engine/docs/concepts/service","upvote_count":"2","comment_id":"524300","poster":"Blueocean","timestamp":"1673802120.0"}]}],"url":"https://www.examtopics.com/discussions/google/view/69767-exam-professional-cloud-developer-topic-1-question-106/","unix_timestamp":1641746040,"answer_images":[]},{"id":"4yjssaNZ1hhtWoyOZ8Kc","answers_community":["C (93%)","7%"],"question_id":10,"url":"https://www.examtopics.com/discussions/google/view/69769-exam-professional-cloud-developer-topic-1-question-107/","question_images":[],"topic":"1","choices":{"C":"Leave the original Cloud Function as-is and deploy a second Cloud Function with the new API. Use Cloud Endpoints to provide an API gateway that exposes a versioned API.","D":"Re-deploy the Cloud Function after making code changes to support the new API. Requests for both versions of the API are fulfilled based on a version identifier included in the call.","A":"Leave the original Cloud Function as-is and deploy a second Cloud Function with the new API. Use a load balancer to distribute calls between the versions.","B":"Leave the original Cloud Function as-is and deploy a second Cloud Function that includes only the changed API. Calls are automatically routed to the correct function."},"answer_ET":"C","answer_images":[],"exam_id":7,"answer":"C","unix_timestamp":1641747120,"answer_description":"","isMC":true,"timestamp":"2022-01-09 17:52:00","question_text":"You recently migrated a monolithic application to Google Cloud by breaking it down into microservices. One of the microservices is deployed using Cloud\nFunctions. As you modernize the application, you make a change to the API of the service that is backward-incompatible. You need to support both existing callers who use the original API and new callers who use the new API. What should you do?","discussion":[{"comment_id":"556756","content":"Selected Answer: C\nBased on the link … where it says for backward incompatible strategy use two separate deployments/instances v1 and v2 and only C option is inline with the link","poster":"GCPCloudArchitectUser","timestamp":"1693058220.0","upvote_count":"7"},{"content":"Answer is C\n\nWhen making backward-incompatible changes to an API, it's important to provide a way for existing callers to continue using the old API while still supporting new callers who use the new API. One way to do this is by deploying a new version of the Cloud Function that includes the new API, and leaving the old function as-is.\n\nBy using Cloud Endpoints you can create an API Gateway that can handle multiple versions of the API, so that requests to different versions of the API can be routed to the corresponding Cloud Function. This allows you to maintain both versions of the API and have control over which version is exposed to the users.\n\nThis approach allows you to continue supporting existing callers while also introducing new features to the application through the new version. Also, it gives you a lot more flexibility in terms of rollout, testing, and monitoring.","timestamp":"1720669260.0","poster":"omermahgoub","comment_id":"772067","upvote_count":"1"},{"content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/endpoints/docs/openapi/versioning-an-api#backwards-incompatible\nWhen you make changes to your API that breaks your customers' client code, as a best practice, increment the major version number of your API. Endpoints can run more than one major version of an API concurrently. By providing both versions of the API, your customers can pick which version they want to use and control when they migrate to the new version.","timestamp":"1718956620.0","poster":"zellck","upvote_count":"1","comment_id":"752110"},{"timestamp":"1716526860.0","content":"Selected Answer: C\nhttps://cloud.google.com/architecture/migrating-a-monolithic-app-to-microservices-gke#versioning\nAnswer C","upvote_count":"2","comment_id":"725613","poster":"TNT87"},{"timestamp":"1715410380.0","content":"Selected Answer: D\nAnswer D feels more appropriate based on the below URL:\n\nhttps://cloud.google.com/endpoints/docs/openapi/versioning-an-api#backwards-incompatible","upvote_count":"1","comment_id":"715887","poster":"memcache"},{"content":"Selected Answer: C\nC is correct","upvote_count":"3","poster":"tomato123","timestamp":"1708416360.0","comment_id":"649277"},{"comment_id":"520344","comments":[{"poster":"Blueocean","content":"As per this link there is a reference that both versions need to be available simultaneously. I would go with Option C","timestamp":"1689433920.0","upvote_count":"3","comment_id":"524308"}],"timestamp":"1688914320.0","upvote_count":"2","poster":"scaenruy","content":"I vote D\nhttps://cloud.google.com/endpoints/docs/openapi/versioning-an-api"}]}],"exam":{"numberOfQuestions":338,"provider":"Google","isBeta":false,"id":7,"isMCOnly":false,"name":"Professional Cloud Developer","isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":2},"__N_SSP":true}