{"pageProps":{"questions":[{"id":"eOgy5l6AspAns4R5dIwB","question_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/google/view/36297-exam-professional-cloud-developer-topic-1-question-14/","answers_community":["B (81%)","Other"],"unix_timestamp":1604703300,"answer":"B","question_text":"You are developing a JPEG image-resizing API hosted on Google Kubernetes Engine (GKE). Callers of the service will exist within the same GKE cluster. You want clients to be able to get the IP address of the service.\nWhat should you do?","answer_description":"","exam_id":7,"answer_ET":"B","timestamp":"2020-11-06 23:55:00","question_id":46,"answer_images":[],"choices":{"C":"Define a GKE Endpoint. Clients should get the endpoint name from the appropriate environment variable in the client container.","B":"Define a GKE Service. Clients should use the service name in the URL to connect to the service.","A":"Define a GKE Service. Clients should use the name of the A record in Cloud DNS to find the service's cluster IP address.","D":"Define a GKE Endpoint. Clients should get the endpoint name from Cloud DNS."},"discussion":[{"timestamp":"1638452760.0","comment_id":"372645","poster":"accuracy23","content":"It's B - Clients are in the cluster and therefore can use service dns names. \n\nhttps://kubernetes.io/docs/concepts/services-networking/dns-pod-service/\n\"Every Service defined in the cluster (including the DNS server itself) is assigned a DNS name. By default, a client Pod's DNS search list includes the Pod's own namespace and the cluster's default domain.\"","upvote_count":"19"},{"timestamp":"1725715680.0","upvote_count":"1","content":"Selected Answer: B\nB. This is the standard Kubernetes service discovery mechanism. When you define a Service in Kubernetes, it creates a DNS entry in the internal cluster DNS. Any pod in the cluster can then reach the service using the service name as a DNS name (e.g., http://service-name). This is the most straightforward and Kubernetes-native way to enable service discovery within a cluster.","poster":"santoshchauhan","comment_id":"1168132"},{"comment_id":"1045447","timestamp":"1713318720.0","content":"This is an example of Microservice Architecture, so Ans is : B","poster":"Raja2112","upvote_count":"1"},{"timestamp":"1710863040.0","comment_id":"1011391","poster":"__rajan__","content":"Selected Answer: B\nB is correct.","upvote_count":"1"},{"content":"Selected Answer: B\nhttps://www.exam-answer.com/gke-service-url-image-resizing-api","poster":"maxdanny","upvote_count":"1","timestamp":"1708769040.0","comment_id":"988979"},{"timestamp":"1701652260.0","content":"Selected Answer: A\nA.\nGKE endpoint is external facing, Opt C and D are out. Also exposing to endpoint won't expose all containers in the GKE cluster - if one service exposes to 4000 nodes with containers then does this mean the GKE would need to update 4000 times? This just doesn't make sense. Opt B use service name, in other words, CNAME, so it still has to go through Cloud DNS. Hence the opt A shall be correct.","upvote_count":"1","poster":"zanhsieh","comment_id":"913953"},{"content":"Selected Answer: C\nIt's B","poster":"gc_exam2022","upvote_count":"1","timestamp":"1700595120.0","comment_id":"903413"},{"upvote_count":"1","poster":"closer89","content":"Selected Answer: B\nboth A and B are valid\nOption A, DNS A record maps service FQDN to IP address, fqdn like service-name.default.svc.cluster.local\nB is more easier, just use http://service-name","comment_id":"889445","timestamp":"1699116420.0"},{"timestamp":"1688878200.0","comment_id":"770090","content":"Selected Answer: B\nanswer is B because client are in the same cluster so service name can be used.","poster":"telp","upvote_count":"1"},{"content":"Selected Answer: C\nQuestion reads \"IP address\" and I don't think that using B the IP can be obtained.","comment_id":"739166","poster":"Mark123321","timestamp":"1686228060.0","upvote_count":"1","comments":[{"timestamp":"1686228480.0","content":"C answer is suggesting to define endpoint in the service and others can use that endpoint (reading its name from a variable) to ask the service what IP it has, that why I think C is correct.","poster":"Mark123321","upvote_count":"1","comment_id":"739176"}]},{"comment_id":"713714","poster":"ajipeggy","content":"Selected Answer: B\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/service-discovery\n\n\"In Kubernetes, service discovery is implemented with automatically generated service names that map to the Service's IP address. Service names follow a standard specification: as follows: my-svc.my-namespace.svc.cluster-domain.example. Pods can also access external services through their names, such as example.com. \"","timestamp":"1683537300.0","upvote_count":"3"},{"comment_id":"649172","timestamp":"1676878200.0","content":"Selected Answer: B\nB is correct","upvote_count":"3","poster":"tomato123"},{"timestamp":"1676566920.0","comment_id":"647719","upvote_count":"1","comments":[{"content":"But qn states: \"..to get the IP address of the service\". Or not?","timestamp":"1676801760.0","comment_id":"648810","upvote_count":"1","poster":"alex8081"}],"content":"Selected Answer: B\nB is correct","poster":"kinoko1330"},{"poster":"jdx000","timestamp":"1673530260.0","upvote_count":"1","comment_id":"630478","content":"Selected Answer: B\nShould be B"},{"content":"B is collect.\n\nIf client and server are in same namespace, C is collect.But in this case, no condition of namespace. So client pod must be use server service name.","upvote_count":"1","timestamp":"1660647780.0","poster":"nazonazonazo","comment_id":"548594"},{"timestamp":"1659522300.0","content":"D: see https://cloud.google.com/endpoints/docs/openapi/get-started-kubernetes-engine#configuring-endpoints-dns","poster":"zaxxon","upvote_count":"1","comment_id":"539690"},{"comment_id":"387503","upvote_count":"1","timestamp":"1640141340.0","content":"A - use SVC to expose your pod, and get the cluster DNS service to get the IP","poster":"ralf_cc"},{"content":"these answers are a bit confusing to me.\nService discovery is done in 3 ways: with env vars, with kubernetes DNS and with Istio. Env vars are not suggested because they are static and needs to be manually updated in case of new changes, Istio is an optional addon, kubernetes DNS is an addon that gke activates by default and is the suggested way for service discovery.\n\nSo I guess the answer includes using the DNS? I don't know","poster":"mastodilu","timestamp":"1637336280.0","upvote_count":"3","comment_id":"361429"},{"content":"A - get the cluster IP of the SVC","timestamp":"1636353720.0","upvote_count":"3","poster":"Kzee","comment_id":"352359"},{"comments":[{"timestamp":"1639991940.0","comment_id":"386024","comments":[{"poster":"syu31svc","timestamp":"1643609220.0","comment_id":"417693","upvote_count":"4","content":"Sorry it should be B"}],"upvote_count":"1","poster":"syu31svc","content":"Which would give A as the answer"}],"comment_id":"260056","timestamp":"1625463360.0","upvote_count":"1","content":"https://cloud.google.com/kubernetes-engine/docs/concepts/service-discovery","poster":"fraloca"},{"upvote_count":"1","content":"I'd choose C.","comment_id":"251774","timestamp":"1624562040.0","poster":"donchick"},{"poster":"saurabh1805","comment_id":"214325","timestamp":"1620334500.0","upvote_count":"1","content":"None of the option seems to be perfect, but closed one is C"}],"isMC":true},{"id":"DflJuM2cmrsuwnbA1ubc","timestamp":"2022-12-04 06:32:00","exam_id":7,"isMC":true,"answer_images":[],"topic":"1","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/89923-exam-professional-cloud-developer-topic-1-question-140/","answer_ET":"AC","answers_community":["AC (100%)"],"question_id":47,"unix_timestamp":1670131920,"discussion":[{"comment_id":"1013547","poster":"__rajan__","upvote_count":"1","timestamp":"1726975020.0","content":"Selected Answer: AC\nAC is correct."},{"comment_id":"973717","upvote_count":"1","poster":"purushi","content":"Selected Answer: AC\nApart from A and C, one more good option would be to copy the app directory only after RUN pip install so that we can avoid this copying part repeatedly after each layer build.","timestamp":"1722939360.0"},{"poster":"telp","timestamp":"1705151040.0","upvote_count":"2","content":"Selected Answer: AC\nA is correct because a high-CPU virtual machine type can increase the speed of your build.\nB is not correct because a Container Registry on a VM will not speed up the build.\nC is correct because the same container is used in subsequent steps for testing and to be pushed to the registry.\nD is not correct because an ubuntu container image will be significantly larger than the python:3.7-alpine image.\nE is not correct because storing the application source code on Cloud Storage does not decrease the time to build the application.","comment_id":"774501"},{"poster":"omermahgoub","comment_id":"772548","upvote_count":"1","content":"Selected Answer: AC\nhttps://cloud.google.com/build/docs/optimize-builds/increase-vcpu-for-builds\nhttps://cloud.google.com/build/docs/optimize-builds/building-leaner-containers#building_leaner_containers\n\nYes, answer A and C are both valid solutions based on the articles you linked.\n\nIncreasing the number of vCPUs allocated to the Cloud Build VM can help to decrease build time because it provides the build environment with more CPU resources to use, which can help to speed up the build process. This can be achieved by selecting a VM size with higher CPU for Cloud Build runs.\n\nas mentioned, caching the Docker image for subsequent builds can also help to decrease build time by reusing previously built image layers. This can be achieved by adding the --cache-from argument to the build command in the build config file, which tells Cloud Build to use the specified images as a cache source.","timestamp":"1704979020.0","comments":[{"content":"Option E Storing application source code on Cloud Storage and configuring the pipeline to use gsutil to download the source code can also be a good way to optimize the pipeline. However, it may be less effective than option A and C, so it may be less beneficial to be chosen as a single solution.\n\nIn summary, option A and C are the best solutions that can help to optimize the CI/CD pipeline in this scenario as they directly impact the build process and it also depend on the current infrastructure and requirements of your pipeline if you consider using other options.","comment_id":"772549","timestamp":"1704979020.0","poster":"omermahgoub","upvote_count":"1"}]},{"content":"https://cloud.google.com/build/docs/optimize-builds/increase-vcpu-for-builds\nAnswer A\nhttps://cloud.google.com/build/docs/optimize-builds/building-leaner-containers#building_leaner_containers\nAnswer C","timestamp":"1703498340.0","poster":"TNT87","upvote_count":"2","comment_id":"755573"},{"poster":"zellck","upvote_count":"1","comment_id":"748559","content":"Selected Answer: AC\nAC is the answer.\n\nhttps://cloud.google.com/build/docs/optimize-builds/increase-vcpu-for-builds\nBy default, Cloud Build runs your builds on a standard virtual machine (VM). In addition to the standard VM, Cloud Build provides several high-CPU VM types to run builds. To increase the speed of your build, select a machine with a higher vCPU to run builds. Keep in mind that although selecting a high vCPU machine increases your build speed, it may also increase the startup time of your build as Cloud Build only starts non-standard machines on demand.\n\nhttps://cloud.google.com/build/docs/optimize-builds/speeding-up-builds#using_a_cached_docker_image\nThe easiest way to increase the speed of your Docker image build is by specifying a cached image that can be used for subsequent builds. You can specify the cached image by adding the --cache-from argument in your build config file, which will instruct Docker to build using that image as a cache source.","timestamp":"1702867320.0"},{"comment_id":"743741","upvote_count":"1","content":"Selected Answer: AC\nA and C are correct","poster":"sharath25","timestamp":"1702455600.0"},{"content":"why don't I see community voted progress bar?","upvote_count":"1","timestamp":"1702295940.0","poster":"test010101","comment_id":"741653"},{"poster":"gardislan18","timestamp":"1701667920.0","comments":[],"upvote_count":"4","content":"Selected Answer: AC\nIMHO\nD - alpine is a much smaller distro\nB and E - does not make sense\n\nhttps://cloud.google.com/build/docs/optimize-builds/increase-vcpu-for-builds\nhttps://cloud.google.com/build/docs/optimize-builds/speeding-up-builds","comment_id":"734861"}],"answer":"AC","question_text":"You are configuring a continuous integration pipeline using Cloud Build to automate the deployment of new container images to Google Kubernetes Engine (GKE). The pipeline builds the application from its source code, runs unit and integration tests in separate steps, and pushes the container to Container Registry. The application runs on a Python web server.\n\nThe Dockerfile is as follows:\n\n\nFROM python:3.7-alpine -\n\nCOPY . /app -\n\nWORKDIR /app -\nRUN pip install -r requirements.txt\nCMD [ \"gunicorn\", \"-w 4\", \"main:app\" ]\n\nYou notice that Cloud Build runs are taking longer than expected to complete. You want to decrease the build time. What should you do? (Choose two.)","choices":{"B":"Deploy a Container Registry on a Compute Engine VM in a VPC, and use it to store the final images.","D":"Change the base image in the Dockerfile to ubuntu:latest, and install Python 3.7 using a package manager utility.","A":"Select a virtual machine (VM) size with higher CPU for Cloud Build runs.","E":"Store application source code on Cloud Storage, and configure the pipeline to use gsutil to download the source code.","C":"Cache the Docker image for subsequent builds using the -- cache-from argument in your build config file."},"question_images":[]},{"id":"5h0Ol6yfk1FzP3mJ53YD","discussion":[{"content":"Selected Answer: B\nAnswer B. Spinnaker with canary deployment:\n\nPurpose-built for Kubernetes deployments\nBuilt-in canary analysis\nAutomated rollback\nZero downtime capability\nFull automation support","timestamp":"1734894000.0","poster":"dneves","upvote_count":"1","comment_id":"1330527"},{"content":"Selected Answer: B\nZero Downtime: Canary testing allows you to gradually roll out your new container to a small percentage of users while the rest continue using the previous version. This ensures zero downtime during the deployment process.\nAutomated Testing: Spinnaker is a powerful CI/CD platform that can automate your canary testing process, including monitoring the new container's performance and health.\nTesting Before Rollout: Canary testing allows you to test the new container in a production environment with real users, but with limited impact. This helps identify any issues before a full rollout.\nQuick Rollback: If the canary test reveals problems, Spinnaker can quickly roll back to the previous version, minimizing disruption to users.","poster":"thewalker","timestamp":"1725960000.0","comment_id":"1281445","upvote_count":"1","comments":[{"comments":[{"timestamp":"1725960060.0","content":"D. Trigger another Cloud Build job that uses the Kubernetes CLI tools to deploy your new container to your GKE cluster, where you can perform a shadow test: Shadow testing involves running the new container alongside the existing one, but without routing traffic to it. This is useful for performance testing but doesn't provide real-world user feedback.","upvote_count":"1","poster":"thewalker","comment_id":"1281447"}],"upvote_count":"1","poster":"thewalker","timestamp":"1725960060.0","comment_id":"1281446","content":"A. Trigger a Spinnaker pipeline configured as an A/B test of your new code and, if it is successful, deploy the container to production: While A/B testing is valuable for comparing different versions of your application, it's not the best choice for zero-downtime deployments. A/B tests typically involve routing traffic to different versions, which can lead to downtime during the transition.\nC. Trigger another Cloud Build job that uses the Kubernetes CLI tools to deploy your new container to your GKE cluster, where you can perform a canary test: While you can manually perform canary testing using the Kubernetes CLI, it's not as efficient or automated as using a dedicated tool like Spinnaker."}]},{"timestamp":"1695366000.0","upvote_count":"1","poster":"__rajan__","comment_id":"1013729","content":"Selected Answer: B\nSpinnaker is a cloud native continuous delivery platform that can be used to deploy applications to a variety of cloud providers, including Google Kubernetes Engine (GKE). Spinnaker is a good choice for deploying applications to GKE because it provides a number of features that make it easy to deploy applications quickly and reliably, including:\n\nCanary deployments: Canary deployments allow you to deploy a new version of your application to a small subset of users before rolling it out to all users. This allows you to test the new version of your application and identify any problems before they impact all of your users.\nRollback: Spinnaker can be used to quickly rollback to a previous version of your application if you encounter any problems with the new version."},{"upvote_count":"1","poster":"purushi","timestamp":"1691317800.0","comment_id":"973727","content":"Selected Answer: D\nShadow testing is the right choice. Canary is not suitable here since the requirement is to test before rolling new version to users. Option A also comes very closer since it has A/B testing that is done only after releasing the newer version to users that is only small amount of traffic is diverted to dedicated users (testers) who gives faster feedback about newer product/service."},{"timestamp":"1673443320.0","poster":"omermahgoub","content":"Selected Answer: D\nOption D, triggering another Cloud Build job that uses the Kubernetes CLI tools to deploy your new container to your GKE cluster, where you can perform a shadow test, could meet the requirements you specified.\n\nShadow testing is a technique where you can test the new version of an application by mirroring user traffic to it, without impacting the user requests to the current version. This way, you can test the new version of your application in a real-world environment with real user traffic, which allows for testing before being rolled out to users and allows for a quick rollback if needed. And with the use of Kubernetes CLI tools you can automate this process, so the testing and deployment is fully automated.","comment_id":"772553","upvote_count":"3"},{"timestamp":"1671331080.0","comment_id":"748557","poster":"zellck","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/architecture/implementing-deployment-and-testing-strategies-on-gke#perform_a_shadow_test\nWith a shadow test, you test the new version of your application by mirroring user traffic from the current application version without impacting the user requests.","upvote_count":"2"},{"content":"Selected Answer: D\nvote D","timestamp":"1670760420.0","poster":"test010101","upvote_count":"1","comment_id":"741662"},{"upvote_count":"2","content":"Selected Answer: D\nIMHO by eliminating\nB and C - uses canary which letting the users use the new version without testing\nA - canary is often a synonym of A/B testing","comment_id":"734862","poster":"gardislan18","timestamp":"1670132820.0"}],"url":"https://www.examtopics.com/discussions/google/view/89924-exam-professional-cloud-developer-topic-1-question-141/","choices":{"D":"Trigger another Cloud Build job that uses the Kubernetes CLI tools to deploy your new container to your GKE cluster, where you can perform a shadow test.","C":"Trigger another Cloud Build job that uses the Kubernetes CLI tools to deploy your new container to your GKE cluster, where you can perform a canary test.","B":"Trigger a Spinnaker pipeline configured as a canary test of your new code and, if it is successful, deploy the container to production.","A":"Trigger a Spinnaker pipeline configured as an A/B test of your new code and, if it is successful, deploy the container to production."},"unix_timestamp":1670132820,"question_id":48,"isMC":true,"topic":"1","question_text":"You are building a CI/CD pipeline that consists of a version control system, Cloud Build, and Container Registry. Each time a new tag is pushed to the repository, a Cloud Build job is triggered, which runs unit tests on the new code builds a new Docker container image, and pushes it into Container Registry. The last step of your pipeline should deploy the new container to your production Google Kubernetes Engine (GKE) cluster. You need to select a tool and deployment strategy that meets the following requirements:\n• Zero downtime is incurred\n• Testing is fully automated\n• Allows for testing before being rolled out to users\n• Can quickly rollback if needed\n\nWhat should you do?","question_images":[],"answers_community":["D (75%)","B (25%)"],"answer_ET":"D","exam_id":7,"answer_images":[],"answer":"D","answer_description":"","timestamp":"2022-12-04 06:47:00"},{"id":"20tx71GchotjLpNIq6uA","exam_id":7,"choices":{"D":"Run gcloud bigtable instances list, gcloud redis instances list, and gcloud sql databases list. Use --filter flag with each command, and then display the results","C":"Run gcloud bigtable instances list, gcloud redis instances list, and gcloud sql databases list. Use a filter within the application, and then display the results","B":"Use the HBase API, Redis API, and MySQL connection to retrieve database lists. Filter the results individually, and then combine them to display the results","A":"Use the HBase API, Redis API, and MySQL connection to retrieve database lists. Combine the results, and then apply the filter to display the results"},"question_text":"Your operations team has asked you to create a script that lists the Cloud Bigtable, Memorystore, and Cloud SQL databases running within a project. The script should allow users to submit a filter expression to limit the results presented. How should you retrieve the data?","url":"https://www.examtopics.com/discussions/google/view/89925-exam-professional-cloud-developer-topic-1-question-142/","answers_community":["D (100%)"],"isMC":true,"question_id":49,"timestamp":"2022-12-04 06:52:00","unix_timestamp":1670133120,"answer_images":[],"answer_ET":"D","topic":"1","answer":"D","question_images":[],"answer_description":"","discussion":[{"content":"Selected Answer: D\nD is correct","timestamp":"1726988820.0","poster":"__rajan__","comment_id":"1013740","upvote_count":"1"},{"content":"Selected Answer: D\nEasy and simple. List all the different types of instances and apply '--filter' option in a command.","timestamp":"1722942720.0","upvote_count":"1","comment_id":"973757","poster":"purushi"},{"content":"Selected Answer: D\nOption D is correct, running gcloud bigtable instances list, gcloud redis instances list, and gcloud sql databases list and using the --filter flag with each command can be used to filter the results before displaying them. This would allow users to submit a filter expression to limit the results presented as specified in the question. As per the google official documentation.","comment_id":"772558","upvote_count":"1","poster":"omermahgoub","timestamp":"1704979440.0"},{"comment_id":"755570","poster":"TNT87","timestamp":"1703497920.0","upvote_count":"1","content":"https://cloud.google.com/sdk/gcloud/reference/topic/filters\nAnswer D"},{"timestamp":"1702866660.0","comment_id":"748553","poster":"zellck","upvote_count":"2","content":"Selected Answer: D\nD is the answer.\n\nhttps://cloud.google.com/sdk/gcloud/reference/topic/filters\nMost gcloud commands return a list of resources on success. By default they are pretty-printed on the standard output. The --format=NAME[ATTRIBUTES](PROJECTION) and --filter=EXPRESSION flags along with projections can be used to format and change the default output to a more meaningful result.\nUse the --format flag to change the default output format of a command. For details run $ gcloud topic formats.\n\nUse the --filter flag to select resources to be listed. Resource filters are described in detail below."},{"poster":"sharath25","content":"Selected Answer: D\noption D","timestamp":"1702546980.0","comment_id":"744942","upvote_count":"1"},{"poster":"test010101","upvote_count":"1","timestamp":"1702296360.0","comment_id":"741659","content":"Selected Answer: D\nvote D"},{"timestamp":"1701669120.0","poster":"gardislan18","content":"IMHO can't see the purpose of using HBase\n\nAnswer is D. use the --filter flag\nhttps://cloud.google.com/sdk/gcloud/reference/topic/filters","comment_id":"734864","upvote_count":"2"}]},{"id":"nMAGLOYyfBeo7rtzObr7","discussion":[{"content":"Selected Answer: B\nSingle Load Balancer with Multiple Host Rules:\n\nIn Google Kubernetes Engine, you can configure a single Ingress resource with multiple host rules that route traffic based on different domain names. This allows you to use the same load balancer but handle traffic differently depending on the domain.\nBy modifying the existing Ingress resource to include a host rule for the new domain, the same load balancer IP can be used to serve both the current website and the new European version.\nHost Rule Matching:\n\nHost rules in the Ingress resource enable domain-based routing, where traffic is directed to the correct service based on the requested domain. This is ideal for scenarios like yours where you need to serve multiple websites under the same load balancer but different domain names.","poster":"thewalker","timestamp":"1725960780.0","upvote_count":"1","comments":[{"content":"A. New Ingress resource: Defining a new Ingress resource with a host rule would create a second Ingress resource, which could lead to conflicts or issues since you want to use the same external IP. The existing Ingress should be modified instead.\n\nC. New Service with LoadBalancer type: This would create a new load balancer, which goes against the requirement to use the same external IP. Also, setting the loadBalancerIP does not achieve domain-based routing.\n\nD. New Ingress resource with static IP: While this allows you to assign an existing static IP, it's unnecessary if you're already using the same load balancer. Modifying the existing Ingress with additional host rules is more efficient and aligns with the goal.","poster":"thewalker","upvote_count":"1","timestamp":"1725960780.0","comment_id":"1281451"}],"comment_id":"1281450"},{"content":"Selected Answer: B\nB is correct.","comment_id":"1013747","timestamp":"1695366660.0","upvote_count":"1","poster":"__rajan__"},{"comment_id":"973761","upvote_count":"1","content":"Selected Answer: B\nRight answer is B. Existing Ingress resource needs to be updated to add new domain for the new service that runs within the cluster of worker nodes. It looks like this:\nUser ---> HTTP(S) Load balance IP --------> Domain 1 -----> Older version of application.\n --------> Domain 2 -----> New version of application.","poster":"purushi","timestamp":"1691320740.0"},{"comment_id":"772565","poster":"omermahgoub","timestamp":"1673443620.0","content":"Selected Answer: B\nBased on the requirements and the references\n\nhttps://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting\nhttps://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip\n\nB. You should modify the existing Ingress resource with a host rule matching the new domain. This will allow you to route traffic to the new website while still using the same IP address and load balancer. This approach allows you to use name-based virtual hosting, which supports routing HTTP traffic to multiple host names at the same IP address. It also enables you to reuse the existing IP address and load balancer, which means that the existing website and the new website can be accessed through the same IP address while having different domain names.","upvote_count":"1"},{"comment_id":"748530","content":"Selected Answer: B\nB is the answer.\n\nhttps://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting\nName-based virtual hosts support routing HTTP traffic to multiple host names at the same IP address.","timestamp":"1671326760.0","upvote_count":"1","poster":"zellck"},{"comment_id":"734868","content":"Selected Answer: D\nAnswer is D\nhttps://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip","poster":"gardislan18","timestamp":"1670133840.0","upvote_count":"1"},{"timestamp":"1670111400.0","content":"Selected Answer: B\n\"must be accessed via the same HTTP(S) load balancer's external IP address\" means re-use the existing ingress resource","comment_id":"734750","upvote_count":"3","poster":"kisswd"}],"answer":"B","unix_timestamp":1670111400,"question_text":"You need to deploy a new European version of a website hosted on Google Kubernetes Engine. The current and new websites must be accessed via the same HTTP(S) load balancer's external IP address, but have different domain names. What should you do?","answer_description":"","answer_images":[],"topic":"1","url":"https://www.examtopics.com/discussions/google/view/89912-exam-professional-cloud-developer-topic-1-question-143/","isMC":true,"question_images":[],"choices":{"A":"Define a new Ingress resource with a host rule matching the new domain","B":"Modify the existing Ingress resource with a host rule matching the new domain","C":"Create a new Service of type LoadBalancer specifying the existing IP address as the loadBalancerIP","D":"Generate a new Ingress resource and specify the existing IP address as the kubernetes.io/ingress.global-static-ip-name annotation value"},"answers_community":["B (89%)","11%"],"exam_id":7,"timestamp":"2022-12-04 00:50:00","question_id":50,"answer_ET":"B"}],"exam":{"name":"Professional Cloud Developer","isBeta":false,"isMCOnly":false,"isImplemented":true,"lastUpdated":"11 Apr 2025","id":7,"numberOfQuestions":338,"provider":"Google"},"currentPage":10},"__N_SSP":true}