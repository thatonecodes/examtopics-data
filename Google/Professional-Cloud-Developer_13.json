{"pageProps":{"questions":[{"id":"0gYUCSI80neSh1MA8nBi","url":"https://www.examtopics.com/discussions/google/view/91835-exam-professional-cloud-developer-topic-1-question-153/","exam_id":7,"answer_images":[],"answers_community":["B (100%)"],"answer_ET":"B","timestamp":"2022-12-16 14:54:00","question_text":"You are designing an application that uses a microservices architecture. You are planning to deploy the application in the cloud and on-premises. You want to make sure the application can scale up on demand and also use managed services as much as possible. What should you do?","unix_timestamp":1671198840,"isMC":true,"question_images":[],"answer":"B","choices":{"B":"Create a GKE cluster in each environment with Anthos, and use Cloud Run for Anthos to deploy your application to each cluster.","A":"Deploy open source Istio in a multi-cluster deployment on multiple Google Kubernetes Engine (GKE) clusters managed by Anthos.","D":"Create a GKE cluster in the cloud and install open-source Kubernetes on-premises. Use an external load balancer service to distribute traffic across the two environments.","C":"Install a GKE cluster in each environment with Anthos, and use Cloud Build to create a Deployment for your application in each cluster."},"discussion":[{"content":"Selected Answer: B\nAnthos with Cloud Run is the best option here.","timestamp":"1727064060.0","poster":"__rajan__","comment_id":"1014621","upvote_count":"1"},{"content":"Selected Answer: B\nAnthos supports GKE cluster creation in both On-premises and GCP cloud environments. Cloud run for Anthos supports autoscaling in both the environments.","poster":"purushi","comment_id":"973856","upvote_count":"1","timestamp":"1722949920.0"},{"content":"Selected Answer: B\nB. Create a GKE cluster in each environment with Anthos, and use Cloud Run for Anthos to deploy your application to each cluster.\n\nUsing Anthos to manage Kubernetes clusters in both cloud and on-premises environments allows for consistency in deployment and management across both environments. Deploying the application using Cloud Run for Anthos allows for easy scaling on demand and use of managed services such as Cloud SQL and Memorystore. Additionally, Cloud Run for Anthos can be deployed to both GKE clusters and on-premises Kubernetes clusters, allowing for a consistent deployment experience across environments.","comment_id":"856911","upvote_count":"2","poster":"Teraflow","timestamp":"1711880460.0"},{"content":"https://cloud.google.com/anthos/run/docs/deploy-application\nAnswer B","timestamp":"1703492640.0","comment_id":"755515","poster":"TNT87","upvote_count":"2"},{"timestamp":"1702734840.0","content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/anthos/run\nIntegrated with Anthos, Cloud Run for Anthos provides a flexible serverless development platform for hybrid and multicloud environments. Cloud Run for Anthos is Google's managed and fully supported Knative offering, an open source project that enables serverless workloads on Kubernetes.","poster":"zellck","upvote_count":"1","comment_id":"747251"}],"question_id":61,"answer_description":"","topic":"1"},{"id":"pmwt67NnuTboHisKkMvY","url":"https://www.examtopics.com/discussions/google/view/90343-exam-professional-cloud-developer-topic-1-question-154/","question_text":"You want to migrate an on-premises container running in Knative to Google Cloud. You need to make sure that the migration doesn't affect your application's deployment strategy, and you want to use a fully managed service. Which Google Cloud service should you use to deploy your container?","exam_id":7,"unix_timestamp":1670400000,"discussion":[{"poster":"__rajan__","comment_id":"1014626","timestamp":"1727064360.0","upvote_count":"1","content":"Selected Answer: A\nA is correct."},{"upvote_count":"1","poster":"purushi","content":"Selected Answer: A\nA is perfect since Cloud Run is built on Knative.","comment_id":"973862","timestamp":"1722950340.0"},{"upvote_count":"1","timestamp":"1703492460.0","poster":"TNT87","comment_id":"755513","content":"Answer A"},{"poster":"zellck","upvote_count":"2","comment_id":"747245","content":"Selected Answer: A\nA is the answer.\n\nhttps://cloud.google.com/blog/products/serverless/knative-based-cloud-run-services-are-ga","timestamp":"1702734480.0"},{"timestamp":"1702464660.0","content":"Selected Answer: A\nA. container running in knative","poster":"sharath25","comment_id":"743912","upvote_count":"1"},{"content":"Selected Answer: A\nCloud run","poster":"aa654321","comment_id":"737552","upvote_count":"1","timestamp":"1701936000.0"}],"topic":"1","question_images":[],"answer_ET":"A","question_id":62,"answer_images":[],"answers_community":["A (100%)"],"choices":{"A":"Cloud Run","B":"Compute Engine","C":"Google Kubernetes Engine","D":"App Engine flexible environment"},"timestamp":"2022-12-07 09:00:00","answer":"A","answer_description":"","isMC":true},{"id":"kEG0uMo9hgigCMmnCAhq","choices":{"D":"1. Pub/Sub\n2. Dataflow\n3. Firestore\n4. BigQuery","B":"1. Dataflow\n2. Pub/Sub\n3. Firestore\n4. BigQuery","A":"1. App Engine\n2. Pub/Sub\n3. BigQuery\n4. Firestore","C":"1. Pub/Sub\n2. Dataflow\n3. BigQuery\n4. Firestore"},"question_id":63,"topic":"1","answer_images":[],"exam_id":7,"discussion":[{"poster":"__rajan__","content":"Selected Answer: D\nD is correct.","timestamp":"1727065500.0","comment_id":"1014638","upvote_count":"1"},{"content":"Selected Answer: D\nData ingest -> Pub sub\nPipeline -> Dataflow\nTransaction -> Firestore\nAnalytics -> BigQuery","comment_id":"973867","poster":"purushi","upvote_count":"2","timestamp":"1722950880.0"},{"poster":"TNT87","content":"Answer D","comment_id":"755512","upvote_count":"2","timestamp":"1703492400.0"},{"content":"Selected Answer: D\nD is the answer.","poster":"zellck","upvote_count":"1","comment_id":"747242","timestamp":"1702734360.0"},{"poster":"sharath25","upvote_count":"1","comment_id":"743915","timestamp":"1702464900.0","content":"Selected Answer: D\noption D"},{"comment_id":"734918","upvote_count":"3","timestamp":"1701675660.0","content":"Selected Answer: D\n1. Pub/Sub - for ingest\n2. Dataflow - dataflow pipeline\n3. Firestore - transaction DB\n4. BigQuery - analytics","poster":"gardislan18"}],"answer_ET":"D","answer":"D","question_images":["https://img.examtopics.com/professional-cloud-developer/image1.png"],"url":"https://www.examtopics.com/discussions/google/view/89933-exam-professional-cloud-developer-topic-1-question-155/","unix_timestamp":1670139660,"timestamp":"2022-12-04 08:41:00","answers_community":["D (100%)"],"question_text":"This architectural diagram depicts a system that streams data from thousands of devices. You want to ingest data into a pipeline, store the data, and analyze the data using SQL statements. Which Google Cloud services should you use for steps 1, 2, 3, and 4?\n\n//IMG//","answer_description":"","isMC":true},{"id":"Jwu506vUkH3ky0B0TdKn","choices":{"D":"Deploy GKE on-premises clusters","C":"Deploy Multi-Zone clusters","B":"Deploy Regional clusters","A":"Deploy Zonal clusters"},"answer":"B","answer_images":[],"exam_id":7,"topic":"1","question_text":"Your company just experienced a Google Kubernetes Engine (GKE) API outage due to a zone failure. You want to deploy a highly available GKE architecture that minimizes service interruption to users in the event of a future zone failure. What should you do?","url":"https://www.examtopics.com/discussions/google/view/90345-exam-professional-cloud-developer-topic-1-question-156/","answer_ET":"B","unix_timestamp":1670400180,"question_id":64,"answers_community":["B (90%)","10%"],"isMC":true,"discussion":[{"poster":"thewalker","timestamp":"1729526460.0","upvote_count":"1","comment_id":"1301134","content":"Selected Answer: C\nRegional Clusters\n- Span multiple zones within a region.\n- May not guarantee that all zones within the region are always available.\n- Can provide some level of redundancy, but might not be as resilient as multi-zone clusters in the event of a zone failure.\n\nMulti-Zone Clusters\n- Distribute your workload across multiple zones within a region.\n- Ensure that your application remains highly available and resilient to zone failures.\n- Automatically move your workloads to the remaining healthy zones if one zone fails.\n- Provide the highest level of availability among the GKE deployment options.\n\nIn summary, while both regional and multi-zone clusters can provide redundancy, multi-zone clusters offer a higher level of availability by distributing your workload across multiple zones, ensuring minimal service disruption in the event of a zone failure."},{"timestamp":"1695443580.0","upvote_count":"1","poster":"__rajan__","content":"Selected Answer: B\nB is correct.","comment_id":"1014646"},{"upvote_count":"1","timestamp":"1691329020.0","poster":"purushi","content":"Selected Answer: B\nRegional cluster with master plane to be in multiple zones is a correct option.","comment_id":"973874"},{"comment_id":"755511","poster":"TNT87","timestamp":"1671956220.0","upvote_count":"3","content":"https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-creating-a-highly-available-gke-cluster\nAnswer B\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/types-of-clusters#regional_clusters"},{"poster":"zellck","comment_id":"747239","timestamp":"1671198240.0","content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/types-of-clusters#regional_clusters\nA regional cluster has multiple replicas of the control plane, running in multiple zones within a given region. Nodes in a regional cluster can run in multiple zones or a single zone depending on the configured node locations. By default, GKE replicates each node pool across three zones of the control plane's region. When you create a cluster or when you add a new node pool, you can change the default configuration by specifying the zone(s) in which the cluster's nodes run. All zones must be within the same region as the control plane.","upvote_count":"4"},{"poster":"sharath25","content":"Selected Answer: B\nregional cluster","upvote_count":"1","timestamp":"1670929080.0","comment_id":"743917"},{"poster":"melisargh","content":"Selected Answer: B\nRegional cluster replicates in at least 3 zones","upvote_count":"1","timestamp":"1670604420.0","comment_id":"740267"},{"content":"Selected Answer: B\nRegional cluster for protection against zonal outages","upvote_count":"1","poster":"aa654321","comment_id":"737557","timestamp":"1670400180.0"}],"question_images":[],"answer_description":"","timestamp":"2022-12-07 09:03:00"},{"id":"hpGqXSL9U70DSec9LceC","url":"https://www.examtopics.com/discussions/google/view/91832-exam-professional-cloud-developer-topic-1-question-157/","answer":"B","isMC":true,"answer_description":"","unix_timestamp":1671198120,"question_images":[],"question_id":65,"exam_id":7,"answer_ET":"B","timestamp":"2022-12-16 14:42:00","question_text":"Your team develops services that run on Google Cloud. You want to process messages sent to a Pub/Sub topic, and then store them. Each message must be processed exactly once to avoid duplication of data and any data conflicts. You need to use the cheapest and most simple solution. What should you do?","choices":{"C":"Process the messages with a Cloud Function, and write the results to a BigQuery location where you can run a job to deduplicate the data.","B":"Process the messages with a Dataflow streaming pipeline using Apache Beam's PubSubIO package, and write the output to storage.","D":"Retrieve the messages with a Dataflow streaming pipeline, store them in Cloud Bigtable, and use another Dataflow streaming pipeline to deduplicate messages.","A":"Process the messages with a Dataproc job, and write the output to storage."},"answers_community":["B (100%)"],"topic":"1","answer_images":[],"discussion":[{"upvote_count":"1","content":"Selected Answer: B\nB is correct.","comment_id":"1014648","timestamp":"1727066220.0","poster":"__rajan__"},{"timestamp":"1722951540.0","comment_id":"973878","content":"Selected Answer: B\nDataflow ensures that the data will be processed only once.","upvote_count":"1","poster":"purushi"},{"timestamp":"1704358620.0","comment_id":"765410","poster":"wrakky","upvote_count":"4","content":"Answer is B\n\nhttps://cloud.google.com/blog/products/data-analytics/handling-duplicate-data-in-streaming-pipeline-using-pubsub-dataflow\n\"...because Pub/Sub provides each message with a unique message_id, Dataflow uses it to deduplicate messages by default if you use the built-in Apache Beam PubSubIO\""},{"content":"Selected Answer: B\nhttps://cloud.google.com/pubsub/docs/stream-messages-dataflow\nhttps://cloud.google.com/community/tutorials/pubsub-spring-dedup-messages\nhttps://cloud.google.com/blog/products/data-analytics/handling-duplicate-data-in-streaming-pipeline-using-pubsub-dataflow","poster":"TNT87","timestamp":"1703413980.0","comment_id":"754809","upvote_count":"1"},{"content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/dataflow/docs/concepts/streaming-with-cloud-pubsub","timestamp":"1702734120.0","poster":"zellck","upvote_count":"1","comment_id":"747236"}]}],"exam":{"isBeta":false,"isMCOnly":false,"id":7,"numberOfQuestions":338,"name":"Professional Cloud Developer","provider":"Google","isImplemented":true,"lastUpdated":"11 Apr 2025"},"currentPage":13},"__N_SSP":true}