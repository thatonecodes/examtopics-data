{"pageProps":{"questions":[{"id":"CR5uJ1RdsahAVJEFTtan","question_id":91,"answer_description":"","isMC":true,"question_images":[],"url":"https://www.examtopics.com/discussions/google/view/130841-exam-professional-machine-learning-engineer-topic-1-question/","choices":{"B":"Set up a CI/CD pipeline that builds your source code and then deploys built artifacts into a pre-production environment. Run unit tests in the pre-production environment. If the tests are successful deploy the pipeline to production.","D":"Set up a CI/CD pipeline that builds and tests your source code and then deploys built artifacts into a pre-production environment. After a successful pipeline run in the pre-production environment, rebuild the source code and deploy the artifacts to production.","C":"Set up a CI/CD pipeline that builds and tests your source code and then deploys built artifacts into a pre-production environment. After a successful pipeline run in the pre-production environment, deploy the pipeline to production.","A":"Set up a CI/CD pipeline that builds and tests your source code. If the tests are successful, use the Google. Cloud console to upload the built container to Artifact Registry and upload the compiled pipeline to Vertex AI Pipelines."},"timestamp":"2024-01-11 11:45:00","discussion":[{"poster":"fitri001","comment_id":"1199892","content":"Selected Answer: C\nCI/CD Pipeline: This automates the build, test, and deployment process, enabling faster iterations and reducing manual errors.\nPre-production Environment: Deploying to a pre-production environment (staging) allows you to test the new pipeline functionality with simulated real-world data. This helps identify and fix potential issues before impacting production.\nSuccessful Pipeline Run: Verifying a successful run in the pre-production environment provides confidence that the new pipeline functions as expected.","upvote_count":"2","timestamp":"1729558200.0"},{"timestamp":"1728305640.0","poster":"pinimichele01","comment_id":"1190952","content":"Selected Answer: C\nUnit test is insufficient, there should be a pipeline run.","upvote_count":"1"},{"comment_id":"1136685","timestamp":"1722415440.0","content":"Selected Answer: C\nC. \nPre-production environment: Deploying to a pre-production environment before production allows you to thoroughly test the new pipeline's functionality and performance without affecting real-time traffic.\nSuccessful pipeline run: This ensures the entire pipeline executes correctly in the pre-production environment, including training, model pushing, and endpoint deployment.\nNo rebuild in production: Rebuilding the source code after a successful pre-production run is unnecessary and adds an extra step that could potentially introduce new errors.","upvote_count":"3","poster":"ddogg"},{"poster":"36bdc1e","upvote_count":"1","comment_id":"1121881","content":"C\nThe best option for continuing experimenting and iterating on your pipeline to improve model\nperformance, using Cloud Build for CI/CD, and deploying new pipelines into production quickly and easily, is to set up a CI/CD pipeline that builds and tests your source code and then deploys built artifacts into a pre-production environment. After a successful pipeline run in the pre-production environment, deploy the pipeline to production. This option allows you to leverage the power and simplicity of Cloud Build to automate, monitor, and manage your pipeline development and deployment workflow.","timestamp":"1720882620.0"},{"content":"Selected Answer: C\nC. Set up a CI/CD pipeline that builds and tests your source code and then deploys built artifacts into a pre-production environment. After a successful pipeline run in the pre-production environment, deploy the pipeline to production.\n\nA - Does not have pre-production environment. \nB - Unit test is insufficient, there should be a pipeline run.\nD - (Uncertain) but there's shouldn't be a rebuilding as you have already built and tested successfully, feels redundant to rebuild.","poster":"pikachu007","timestamp":"1720687500.0","upvote_count":"2","comment_id":"1119619"}],"question_text":"You recently deployed a pipeline in Vertex AI Pipelines that trains and pushes a model to a Vertex AI endpoint to serve real-time traffic. You need to continue experimenting and iterating on your pipeline to improve model performance. You plan to use Cloud Build for CI/CD You want to quickly and easily deploy new pipelines into production, and you want to minimize the chance that the new pipeline implementations will break in production. What should you do?","answers_community":["C (100%)"],"unix_timestamp":1704969900,"answer_images":[],"exam_id":13,"topic":"1","answer":"C","answer_ET":"C"},{"id":"oFeOfv60uDQjT23S4tMs","exam_id":13,"answer_images":[],"isMC":true,"question_id":92,"question_text":"You work for a bank with strict data governance requirements. You recently implemented a custom model to detect fraudulent transactions. You want your training code to download internal data by using an API endpoint hosted in your projectâ€™s network. You need the data to be accessed in the most secure way, while mitigating the risk of data exfiltration. What should you do?","answers_community":["A (65%)","B (35%)"],"unix_timestamp":1704970200,"answer_ET":"A","discussion":[{"poster":"lunalongo","comment_id":"1323294","upvote_count":"1","content":"Selected Answer: A\nA is the right answer because it provides the strongest security posture, which the question statement emphasizes.VPC Service Controls offer a more robust defense against data exfiltration\n\nWhy the other options are wrong:\n*B) If the proxy is compromised, data is exposed.\n*C) Peering establishes network connectivity; lacks inherent data access control\n*D) Downloading to Cloud Storage introduces data at rest vulnerability","timestamp":"1733614500.0"},{"poster":"tardigradum","upvote_count":"2","timestamp":"1723546020.0","comment_id":"1265111","content":"Selected Answer: A\nVPC Service Controls: This feature allows you to define network boundaries (service perimeters) and control the flow of data between services. By adding Vertex AI to a service perimeter, you can restrict its access to only the necessary resources, including the API endpoint.   \n\nWith peerings you can enable secure communication between your VPC and the VPC where Vertex AI is running, ensuring data stays within your network boundary."},{"timestamp":"1719336420.0","comment_id":"1237008","content":"Selected Answer: A\nA is correct","upvote_count":"1","poster":"dija123"},{"poster":"peppenapo7","content":"Selected Answer: A\nIt's literally written in the description of this service: avoid data exfiltration.","comment_id":"1198941","timestamp":"1713588120.0","upvote_count":"4"},{"comments":[{"poster":"fitri001","upvote_count":"1","content":"A. VPC Service Controls: While VPC Service Controls offer network segmentation, they wouldn't directly address data exfiltration risk from the training code itself.\nC. VPC Peering: VPC Peering allows communication between networks but doesn't provide access control mechanisms like IAM.\nD. Downloading to Cloud Storage: This approach creates an unnecessary data transfer step and doesn't address the risk of the training code potentially leaking data after download.","comments":[{"content":"https://cloud.google.com/vpc-service-controls/docs/overview#how-vpc-service-controls-works","comment_id":"1199118","poster":"pinimichele01","upvote_count":"1","timestamp":"1713611280.0"}],"timestamp":"1713551760.0","comment_id":"1198803"}],"content":"Selected Answer: B\nSecurity: Cloud Run offers a secure environment to run your proxy code. IAM authentication ensures only authorized training jobs have access to the data endpoint.\nData Minimization: The proxy can potentially filter or transform data before sending it to the training code, reducing the amount of sensitive information exposed.\nNetwork Isolation: The proxy acts as an additional layer of isolation between the training code and the internal data source.","upvote_count":"2","comment_id":"1198802","timestamp":"1713551700.0","poster":"fitri001"},{"upvote_count":"1","timestamp":"1713006240.0","content":"Selected Answer: A\nTo mitigate data exfiltration risks, your organization might also want to ensure secure data exchange across organizational boundaries with fine-grained controls. As an administrator, you might want to ensure the following:\n\nClients with privileged access don't also have access to partner resources.\nClients with access to sensitive data can only read public data sets but not write to them","comment_id":"1194902","poster":"pinimichele01"},{"timestamp":"1708490520.0","content":"It should be A, VPC service controls can reduce data exfiltration risks. \nhttps://cloud.google.com/vpc-service-controls/docs/overview","comment_id":"1155246","upvote_count":"2","poster":"Sunny_M"},{"timestamp":"1708270380.0","comment_id":"1153385","content":"Selected Answer: B\nMy Answer B:\nCreating a Cloud Run endpoint as a proxy to the data allows you to control access to the internal data through an API endpoint. By using IAM authentication, you can enforce strict access controls, ensuring that only authorized entities (such as your training job) can access the data. This approach helps mitigate the risk of data exfiltration by providing a secure and controlled access point to the internal data.\n- Option A: may help control access within Google Cloud Platform services, but it does not directly address securing access to the internal data through an API endpoint.\n- Option C: is more about network configurations and does not provide a solution for securely accessing the internal data through an API endpoint.\n- Option D: transferring the data to a Cloud Storage bucket, which might introduce additional security risks during the data transfer process.","upvote_count":"3","poster":"guilhermebutzke"},{"comment_id":"1153383","poster":"guilhermebutzke","content":"My Answer B:\nCreating a Cloud Run endpoint as a proxy to the data allows you to control access to the internal data through an API endpoint. By using Identity and Access Management (IAM) authentication, you can enforce strict access controls, ensuring that only authorized entities (such as your training job) can access the data. This approach helps mitigate the risk of data exfiltration by providing a secure and controlled access point to the internal data.\n\n- Option A: may help control access within Google Cloud Platform services, but it does not directly address securing access to the internal data through an API endpoint.\n- Option C: is more about network configurations and does not provide a solution for securely accessing the internal data through an API endpoint.\n- Option D: involves transferring the data to a Cloud Storage bucket, which might introduce additional security risks during the data transfer process.","upvote_count":"3","timestamp":"1708270260.0"},{"upvote_count":"1","poster":"ddogg","comment_id":"1136698","content":"Selected Answer: A\nA. https://cloud.google.com/security/vpc-service-controls?hl=en\nThe first benefit on the official google cloud site is \"Mitigate data exfiltration risks\"\nHere's why:\n\nVPC Service Controls: This powerful tool allows you to restrict the network connectivity of resources within your VPC network. By enabling it for peerings, you can control which services within your project can access specific internal resources.\n\nService perimeter: Adding Vertex AI to a service perimeter further restricts its access to only approved internal resources, including the API endpoint for your bank's data. This creates a secure zone where your model training can happen without jeopardizing sensitive data.","timestamp":"1706698740.0"},{"content":"Selected Answer: A\nI will go with A.","upvote_count":"1","timestamp":"1706690280.0","poster":"daidai75","comment_id":"1136539"},{"upvote_count":"1","comment_id":"1119625","timestamp":"1704970200.0","content":"Selected Answer: B\nIt provides a controlled and secure way to allow the training job to access the necessary data while adhering to strict data governance requirements.","poster":"pikachu007"}],"timestamp":"2024-01-11 11:50:00","question_images":[],"topic":"1","answer":"A","url":"https://www.examtopics.com/discussions/google/view/130842-exam-professional-machine-learning-engineer-topic-1-question/","choices":{"C":"Configure VPC Peering with Vertex AI, and specify the network of the training job.","A":"Enable VPC Service Controls for peerings, and add Vertex AI to a service perimeter.","B":"Create a Cloud Run endpoint as a proxy to the data. Use Identity and Access Management (IAM) authentication to secure access to the endpoint from the training job.","D":"Download the data to a Cloud Storage bucket before calling the training job."},"answer_description":""},{"id":"GaoId1uOTnOV62d4Cimn","question_text":"You are deploying a new version of a model to a production Vertex Al endpoint that is serving traffic. You plan to direct all user traffic to the new model. You need to deploy the model with minimal disruption to your application. What should you do?","isMC":true,"answers_community":["C (90%)","10%"],"topic":"1","choices":{"D":"1. Create a new model. Set it as the default version. Upload the model to Vertex AI Model Registry\n2. Deploy the new model to the existing endpoint","B":"1. Create a new endpoint\n2. Create a new model. Set the parentModel parameter to the model ID of the currently deployed model and set it as the default version. Upload the model to Vertex AI Model Registry\n3. Deploy the new model to the new endpoint, and set the new model to 100% of the traffic.","C":"1. Create a new model. Set the parentModel parameter to the model ID of the currently deployed model. Upload the model to Vertex AI Model Registry.\n2. Deploy the new model to the existing endpoint, and set the new model to 100% of the traffic","A":"1. Create a new endpoint\n2. Create a new model. Set it as the default version. Upload the model to Vertex AI Model Registry\n3. Deploy the new model to the new endpoint\n4. Update Cloud DNS to point to the new endpoint"},"answer_images":[],"answer_description":"","answer_ET":"C","exam_id":13,"answer":"C","timestamp":"2024-01-11 11:57:00","unix_timestamp":1704970620,"discussion":[{"content":"Selected Answer: C\nMinimal Downtime: By deploying the new model to the existing endpoint, you avoid any service interruptions caused by creating and switching to a completely new endpoint.\nVersioning: Setting the parentModel parameter allows you to track the lineage of your models and easily revert to the previous version if needed.\nTraffic Control: Vertex AI lets you control traffic allocation between different versions of a model deployed on the same endpoint. Setting the new model to 100% traffic directs all user requests to the new version.","timestamp":"1729363080.0","upvote_count":"3","comment_id":"1198804","poster":"fitri001","comments":[{"poster":"fitri001","timestamp":"1729363140.0","upvote_count":"1","comment_id":"1198805","content":"A. Creating a New Endpoint: This approach introduces downtime as you need to switch DNS records to point to the new endpoint.\nB. Creating a New Endpoint with Default Version: While using a parentModel helps with versioning, creating a new endpoint still leads to service disruption.\nD. Deploying to Existing Endpoint Without Traffic Control: This might cause unexpected behavior if the new model isn't ready for production traffic."}]},{"poster":"guilhermebutzke","content":"Selected Answer: C\nMy Answer: C\n\n In the context of deploying machine learning models, setting the **`parentModel`** parameter to the model ID of the currently deployed model means that the new model being deployed is created as a child model or an iteration of the existing model. This allows the new model to inherit certain properties or characteristics from the existing model, such as the architecture, hyperparameters, or feature transformations.\n\nCreate a new Endpoint is Unnecessary.","timestamp":"1723988460.0","upvote_count":"2","comment_id":"1153394"},{"content":"Selected Answer: D\nOptionally set this model as the default version. The default version is preselected whenever the model is used for prediction (although you can still select other versions).\nhttps://cloud.google.com/vertex-ai/docs/model-registry/versioning","comment_id":"1140142","timestamp":"1722770700.0","poster":"sonicclasps","upvote_count":"1"},{"upvote_count":"1","poster":"BlehMaks","content":"Selected Answer: C\na,c -creating new endpoint is an unnecessary disruption to the application\nd - doesn't work, two models are on the same endpoint and traffic is still going through the old model","comment_id":"1121802","timestamp":"1720877820.0"},{"content":"Selected Answer: C\nLeverages existing endpoint: Using the same endpoint maintains the same endpoint URL, avoiding DNS updates and potential service interruptions.\nGradual traffic transition: Vertex AI allows you to gradually shift traffic between model versions, ensuring a smooth transition without impacting users.\nClear versioning: Setting parentModel establishes a relationship between the new model and the existing one, aiding in organization and tracking model lineage.","comment_id":"1119630","timestamp":"1720688220.0","poster":"pikachu007","upvote_count":"3"}],"question_id":93,"url":"https://www.examtopics.com/discussions/google/view/130843-exam-professional-machine-learning-engineer-topic-1-question/","question_images":[]},{"id":"LbrBw23F32FbuYdTCc6n","url":"https://www.examtopics.com/discussions/google/view/130844-exam-professional-machine-learning-engineer-topic-1-question/","unix_timestamp":1704970680,"question_images":[],"topic":"1","answer_description":"","choices":{"C":"Decrease the learning rate","A":"Increase the learning rate","B":"Increase the number of epochs","D":"Increase the batch size"},"isMC":true,"question_text":"You are training an ML model on a large dataset. You are using a TPU to accelerate the training process. You notice that the training process is taking longer than expected. You discover that the TPU is not reaching its full capacity. What should you do?","timestamp":"2024-01-11 11:58:00","answer_images":[],"answer_ET":"D","discussion":[{"content":"Selected Answer: D\nA common reason for underutilized TPUs is a small batch size. TPUs are designed for high throughput, and feeding them small batches doesn't leverage their full potential.\nTry increasing the batch size while monitoring model performance. A larger batch size can lead to faster training but might also affect accuracy. Experiment to find the optimal balance.","upvote_count":"5","comment_id":"1198808","timestamp":"1729363320.0","poster":"fitri001"},{"poster":"36bdc1e","content":"D\ntaking big batch size allows to use more memory and decrease the train time","comment_id":"1121893","upvote_count":"1","timestamp":"1720883640.0"},{"comment_id":"1121813","content":"Selected Answer: D\nBatch size is too small because of sharding\nhttps://cloud.google.com/tpu/docs/performance-guide","poster":"BlehMaks","upvote_count":"1","timestamp":"1720878360.0"},{"timestamp":"1720688280.0","upvote_count":"2","content":"Selected Answer: D\nD, the bigger the batch size, the more resource is taken up","comment_id":"1119632","poster":"pikachu007"}],"question_id":94,"answers_community":["D (100%)"],"answer":"D","exam_id":13},{"id":"JjESEnpAjKUwP8yhen2T","timestamp":"2024-01-08 20:19:00","discussion":[{"comments":[{"timestamp":"1713552420.0","poster":"fitri001","content":"A. Manual Split by Store: While this might work, it doesn't consider the time element crucial for sales predictions. The new store's performance might not be well-represented by data from a single existing store.\nB. Default Split (Random): The default random split in Vertex AI might not prioritize recent data which could be more relevant for predicting sales in the new store.\nD. Random Split with Specific Ratios: Similar to the default split, a random approach might not capture the time-series aspect and recent trends that are important for your new store predictions.","comment_id":"1198810","upvote_count":"1"}],"content":"Selected Answer: C\nTime-Series Data: Your sales data has timestamps, indicating it's time-series data. A chronological split considers the order of the timestamps, ensuring the model is trained on historical trends.\nPredicting for New Store: Since you want to predict sales for a new store, a chronological split is better than a random split (option D) which wouldn't prioritize recent trends.\nVertex AI Functionality: Vertex AI's chronological split functionality is specifically designed for time-series data and leverages the timestamp feature you provide to separate data for training, validation, and testing.","comment_id":"1198809","timestamp":"1713552360.0","upvote_count":"6","poster":"fitri001"},{"comment_id":"1325156","upvote_count":"1","content":"Selected Answer: A\nSince the question is to predict the for a new store and not sales prediction in general, the answer has to be 'A'","poster":"Omi_04040","timestamp":"1733941020.0"},{"timestamp":"1708280100.0","upvote_count":"2","comment_id":"1153477","content":"Selected Answer: C\nMy answer C: \n\nA: Not Correct:  Splitting based on store name wouldn't guarantee temporal separation of data. Furthermore, for this problem is note to assign one store for each set, because the target is for a new store. \n\nB: Not Correct:  Randomly choosing data points across different time periods could lead to the model not capturing seasonal trends or temporal patterns effectively.\n\nC: CORRECT: it leverages the chronological nature of the data. Since the dataset contains sales data over time from different stores, using a chronological split ensures that the model is trained on data from earlier time periods and validated/tested on more recent data.\n\nD: Not Correct: Similar to B, a custom random split wouldn't ensure temporal separation and could lead to issues with capturing temporal trends.","poster":"guilhermebutzke"},{"content":"Selected Answer: C\nI agree with b1a8fae","timestamp":"1705286760.0","comment_id":"1123020","poster":"shadz10","upvote_count":"1"},{"upvote_count":"1","comment_id":"1121842","timestamp":"1705163160.0","content":"Selected Answer: C\nhttps://cloud.google.com/automl-tables/docs/data-best-practices#time","poster":"BlehMaks"},{"content":"Selected Answer: C\nAnything different than option C could potentially lead to data leakage imo.","upvote_count":"1","timestamp":"1705071120.0","poster":"b1a8fae","comment_id":"1120859"},{"timestamp":"1704970980.0","upvote_count":"1","poster":"pikachu007","comments":[{"upvote_count":"1","content":"All the research and document supports this answer.","poster":"DaleR","timestamp":"1733252400.0","comment_id":"1321505"}],"content":"Selected Answer: A\nBy using a manual split based on store names, you can train a model that is more sensitive to the unique characteristics of each store, ultimately leading to better predictions for the new store.","comment_id":"1119635"},{"content":"I say C , time-based splitting is always suggest","comment_id":"1116929","upvote_count":"1","timestamp":"1704741540.0","poster":"vale_76_na_xxx"}],"question_images":[],"answer_description":"","question_text":"You work for a retail company. You have a managed tabular dataset in Vertex AI that contains sales data from three different stores. The dataset includes several features, such as store name and sale timestamp. You want to use the data to train a model that makes sales predictions for a new store that will open soon. You need to split the data between the training, validation, and test sets. What approach should you use to split the data?","isMC":true,"question_id":95,"unix_timestamp":1704741540,"answer_images":[],"exam_id":13,"answer":"C","answers_community":["C (85%)","A (15%)"],"url":"https://www.examtopics.com/discussions/google/view/130628-exam-professional-machine-learning-engineer-topic-1-question/","choices":{"B":"Use Vertex AI default data split","C":"Use Vertex AI chronological split, and specify the sales timestamp feature as the time variable","A":"Use Vertex AI manual split, using the store name feature to assign one store for each set","D":"Use Vertex AI random split, assigning 70% of the rows to the training set, 10% to the validation set, and 20% to the test set"},"topic":"1","answer_ET":"C"}],"exam":{"id":13,"provider":"Google","isBeta":false,"isMCOnly":true,"numberOfQuestions":304,"lastUpdated":"11 Apr 2025","isImplemented":true,"name":"Professional Machine Learning Engineer"},"currentPage":19},"__N_SSP":true}