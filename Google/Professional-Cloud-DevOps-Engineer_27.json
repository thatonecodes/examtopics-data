{"pageProps":{"questions":[{"id":"beztJop6xZZeebEFoH5K","question_text":"You have a set of applications running on a Google Kubernetes Engine (GKE) cluster, and you are using Stackdriver Kubernetes Engine Monitoring. You are bringing a new containerized application required by your company into production. This application is written by a third party and cannot be modified or reconfigured. The application writes its log information to /var/log/app_messages.log, and you want to send these log entries to Stackdriver Logging. What should you do?","answer_description":"","topic":"1","timestamp":"2021-06-02 16:24:00","exam_id":6,"answer_images":[],"answer":"B","isMC":true,"question_images":[],"question_id":131,"discussion":[{"comment_id":"385744","upvote_count":"6","content":"Ans is B\n\nBesides the list of default logs that the Logging agent streams by default, you can customize the Logging agent to send additional logs to Logging or to adjust agent settings by adding input configurations.\nThe configuration definitions in these sections apply to the fluent-plugin-google-cloud output plugin only and specify how logs are transformed and ingested into Cloud Logging.","poster":"francisco_guerra","timestamp":"1726907700.0"},{"comment_id":"413598","poster":"muhasinem","timestamp":"1627186620.0","upvote_count":"6","content":"B is correct."},{"poster":"bartrek","timestamp":"1739855100.0","content":"Selected Answer: D\nSo in general we have a process running in a pod that opens a local file (inside the pod). Answer B does not mention volume (regardless of a type). As far as i know fluentd is not capable of accessing other pod's files unless hostpath or rwx storage is configured (shared storage). The answer does not mention that however even if this is mentioned this would not be a good choice as this way would easily lead into a log corruption when application is started in more than one replica. You may also ask yourself a question: is it right to deploy a daemonset in order to cover an edge-case? Is it good to taint the hosts with a hostpath volume?\n\nIn my opinion D is the least effort solution, utilizes existing mechanisms, does not break scaling nor taints the gke hosts. Application would have to support external log truncation (open the logfile in append mode) in order to prevent infinite file growth. Regardless if you decide to use tail -f or fluentd sidecar this method will prevent log from being corrupted and will play nice with horizontal pod autoscaling. It would be interesting if someone decides to use init container - symlinking logfile to /dev/stdout (or similar) before the main container pod is started.","upvote_count":"1","comment_id":"1358126"},{"comment_id":"1309298","poster":"mohan999","upvote_count":"1","timestamp":"1731209340.0","content":"I think it should be D, because its says you have a set of applications already running on a Google Kubernetes Engine (GKE) cluster, and you are using Stackdriver Kubernetes Engine Monitoring. \nI believe we should not enable the workload logging if we were to use the custom agent -\n\nSo, now just for one new application, it does not make any sense to disable the default stackdriver setting on GKE and use the custom agent for all application logging.\n\nSo, D would be correct option in this context since we are only customizing this for one application."},{"timestamp":"1727342100.0","comment_id":"385085","upvote_count":"4","content":"I believe that is B,\nThis tutorial describes how to customize Fluentd logging for a Google Kubernetes Engine cluster. You'll learn how to host your own configurable Fluentd daemonset to send logs to Cloud Logging, instead of selecting the cloud logging option when creating the Google Kubernetes Engine (GKE) cluster, which does not allow configuration of the Fluentd daemon","poster":"WakandaF"},{"comment_id":"727735","poster":"DoodleDo","upvote_count":"1","content":"Ans B. as the application is not writing to STDOUT or STDERR. Source for the answer - https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs\nExtract from this source relevant for the answer.\nGKE's default logging agent provides a managed solution to deploy and manage the agents that send the logs for your clusters to Cloud Logging. Depending on your GKE cluster master version, either fluentd or fluentbit are used to collect logs. Starting from GKE 1.17, logs are collected using a fluentbit-based agent. GKE clusters using versions prior to GKE 1.17 use a fluentd-based agent. If you want to alter the default behavior of the fluentdagents, then you can run a customized fluentd agent or a customized fluentbit agent.\n\nCommon use cases include:\nremoving sensitive data from your logs\ncollecting additional logs not written to STDOUT or STDERR\nusing specific performance-related settings\ncustomized log formatting","timestamp":"1727342100.0"},{"poster":"zellck","timestamp":"1727342100.0","content":"Selected Answer: B\nB is the answer.\n\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#custom_agents\nGKE's default logging agent provides a managed solution to deploy and manage the agents that send the logs for your clusters to Cloud Logging. Depending on your GKE cluster master version, either fluentd or fluentbit are used to collect logs. \nCommon use cases include:\n- collecting additional logs not written to STDOUT or STDERR\n- customized log formatting","comment_id":"702994","upvote_count":"4"},{"comments":[{"comment_id":"772010","upvote_count":"3","content":"Option D is NOT the ideal choice as it would require creating and maintaining a custom script that would have to be deployed with the application's pod in order to tail the log file and write the entries to standard output. This would mean that you would need to take care of the maintenance of this script on every new deployment, update or scaling of the pod, and also the script would need to handle all the edge cases, errors and permissions issues by your own.\n\nFurthermore, this option doesn't use the Stackdriver Logging service, the script would be writing to standard output, which may not be as reliable and secure as writing to a centralized logging service such as Stackdriver Logging. This would also require additional setup and maintenance to route the standard output to a location where the logs can be analyzed, this would take additional development and maintenance effort that would be redundant when compared to the other options.","timestamp":"1673410860.0","poster":"JonathanSJ"}],"poster":"JonathanSJ","timestamp":"1727342040.0","content":"Selected Answer: B\nB. Deploy a Fluentd daemonset to GKE. Then create a customized input and output configuration to tail the log file in the application's pods and write to Stackdriver Logging.\n\nStackdriver Kubernetes Engine Monitoring provides log collection and analysis for Kubernetes clusters running on GKE out of the box, but the default configuration doesn't include the ability to tail a specific log file. To collect log entries written to /var/log/app_messages.log, you can deploy a Fluentd daemonset to your GKE cluster. Fluentd is a log collector and forwarder that can be configured to tail a specific log file, in this case, /var/log/app_messages.log and send the log entries to Stackdriver Logging.\n\nBy deploying a Fluentd daemonset, you can create a customized input and output configuration, you can use this configuration to tail the log file in the application's pods and write to Stackdriver Logging, this allows you to collect the logs from that specific application, ensuring that the logs are going to stackdriver and can be analyzed later on.","comment_id":"772008","upvote_count":"1"},{"timestamp":"1727342040.0","upvote_count":"1","poster":"Watcharin_start","comment_id":"902349","content":"Ans. is B.\nThis solution is want to send log msg to the Stackdriver logging. However, C is possible IF we have a third party log collector like FluentD that monitoring STDOUT log from the cluster, but this question does not. \nTherefore, the answer must is B, because any content of container that write in files, we can scrape it in hosted worker node. It store in path /var/containers/* . If we create a customize tail path in the FluentD to monitor any path that store log content, we could use a STAR(*) operator to tell a plugins to find all folders that contain file named app_message.log ."},{"upvote_count":"2","content":"Selected Answer: D\nSidecar is expected here","comment_id":"920899","poster":"galkin","timestamp":"1726907700.0"},{"content":"Selected Answer: B\nDeploy a Fluentd daemonset to GKE","comment_id":"1206357","upvote_count":"1","timestamp":"1714801140.0","poster":"dija123"},{"upvote_count":"2","content":"Selected Answer: B\nTo collect log entries from a specific file within each node in your GKE cluster, you can use a DaemonSet, Fluentd is often used as the logging agent for log forwarding in GKE.","timestamp":"1698202560.0","poster":"Jason_Cloud_at","comment_id":"1053404"},{"upvote_count":"3","poster":"singularis","content":"Selected Answer: D\nThe answer is D. Fluent D cannot read logs from files.\nhttps://kubernetes.io/docs/concepts/cluster-administration/logging/#sidecar-container-with-logging-agent\n\nBy having your sidecar containers write to their own stdout and stderr streams, you can take advantage of the kubelet and the logging agent that already run on each node. The sidecar containers read logs from a file, a socket, or journald. Each sidecar container prints a log to its own stdout or stderr stream.","comment_id":"769881","timestamp":"1673218200.0"},{"comment_id":"736620","content":"Selected Answer: B\nSubmitted B","timestamp":"1670315100.0","poster":"chelbsik","upvote_count":"1"},{"upvote_count":"1","timestamp":"1670222700.0","content":"i will go with B. flentd daemonset cannot collect logs from other pods , it collects logs from host filesystem ( stdout, stderr) https://cloud.google.com/architecture/best-practices-for-operating-containers#use_the_native_logging_mechanisms_of_containers","poster":"hanweiCN","comment_id":"735707"},{"poster":"notjoost","upvote_count":"2","comment_id":"733748","timestamp":"1669987380.0","content":"Selected Answer: D\nI think this should be D instead of B, and here's why:\nInstalling a Fluentd daemonset will not solve your problem, as that logfile is not accessible by the Fluent pods. You'd need a sidecar to make the logfile accessible to another container, which will then be responsible for forwarding the logs to stdout. A daemonset will not do that, but a sidecar tailing the logs will."},{"content":"B is correct \nhttps://cloud.google.com/architecture/customizing-stackdriver-logs-fluentd","poster":"AzureDP900","upvote_count":"2","comment_id":"702415","timestamp":"1666552380.0"},{"upvote_count":"3","timestamp":"1660603320.0","comment_id":"647378","poster":"dobby_elf","content":"Selected Answer: D\nD - Installing Fluentd is overkill"},{"comment_id":"644886","upvote_count":"1","content":"Selected Answer: B\nGCP is not using fluentBit (and not fluent anymore) and it logs application data via STDOUT and STDERR, meaning you need to tail your app log to see it on CloudLogging. \nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#custom_agents","poster":"kapara","timestamp":"1660123500.0"},{"comment_id":"635862","content":"Selected Answer: B\nThe answer is B","upvote_count":"1","poster":"GCP72","timestamp":"1658632740.0"},{"poster":"wences","content":"Selected Answer: B\nD seems doable but is like lots of effort, B seems like less complex I will dare to say B, I like D because application won't have a clue of anything and no need to cahnge it at all.","comment_id":"623499","upvote_count":"3","timestamp":"1656363780.0"},{"comment_id":"599112","timestamp":"1652110500.0","content":"Selected Answer: B\nSubmitted B in the exam","poster":"Ananda","upvote_count":"3"},{"upvote_count":"4","comment_id":"563840","timestamp":"1646812500.0","poster":"lakiluk","content":"Selected Answer: D\nD is the correct answer don't get fooled."},{"upvote_count":"2","content":"Ans: B","poster":"alaahakim","timestamp":"1638705060.0","comment_id":"494287"},{"upvote_count":"4","comment_id":"492453","timestamp":"1638447780.0","content":"Selected Answer: B\nBecause Fluentd is created specifically for extracting logs. \nhttps://docs.fluentd.org/input/tail","poster":"syslog"},{"timestamp":"1636380900.0","content":"Answer is B.\n\nD sounds good, the practice way. But the question is mention about sending log to Cloud Logging but D is just send log to shared disk","upvote_count":"3","comment_id":"474325","poster":"Manh"},{"upvote_count":"2","poster":"raf2121","content":"Point for discussion : \n\nIs B the right answer ? When I was going through training content in Coursera, I read \"Dont install Logging Agent in GKE nodes, as GKE are automatically enabled for Logging\"\n\nConsidering this, Is D the right answer","comment_id":"423449","timestamp":"1628735220.0"},{"poster":"gcpengineer","comment_id":"422958","content":"Why not A?","timestamp":"1628623020.0","upvote_count":"1"},{"poster":"ralf_cc","upvote_count":"2","comment_id":"383406","content":"B it is.","timestamp":"1623848100.0"},{"comments":[{"poster":"syslog","timestamp":"1623925140.0","upvote_count":"1","content":"You can mount a volume wherever you want in a pod, so /var/log could exist.","comment_id":"384104"}],"poster":"pyc","timestamp":"1623631860.0","comment_id":"381431","content":"It should be D.\nEach sidecar container could tail a particular log file from a shared volume and then redirect the logs to its own stdout stream.\nhttps://kubernetes.io/docs/concepts/cluster-administration/logging/\nB sounds good, however, /var/log is not in the application pods IMHO. Please correct me if I am wrong here.","upvote_count":"1"},{"poster":"[Removed]","comment_id":"374735","upvote_count":"1","timestamp":"1622866200.0","content":"I think B"},{"upvote_count":"2","comment_id":"372775","comments":[{"content":"Agree. answer should be D.","timestamp":"1622739060.0","comment_id":"373751","poster":"akg001","comments":[{"comment_id":"376393","upvote_count":"1","poster":"rinkeshgala1","content":"why not B?","comments":[{"poster":"saminlo","timestamp":"1624250820.0","content":"just my thought process for choosing D over B (not sure if that's correct):\nif there are multiple such app containers that write logs to a non-standard location then you'd have to create a custom fluentd input config for each app. Using a sidecar and running it in the same pod as the app container makes more sense since you're 'bundling' related piece of code together.","comment_id":"386774","upvote_count":"2"}],"timestamp":"1623025320.0"}],"upvote_count":"3"}],"timestamp":"1622643840.0","poster":"devopsbatch","content":"D i think.."}],"unix_timestamp":1622643840,"choices":{"B":"Deploy a Fluentd daemonset to GKE. Then create a customized input and output configuration to tail the log file in the application's pods and write to Stackdriver Logging.","A":"Use the default Stackdriver Kubernetes Engine Monitoring agent configuration.","C":"Install Kubernetes on Google Compute Engine (GCE) and redeploy your applications. Then customize the built-in Stackdriver Logging configuration to tail the log file in the application's pods and write to Stackdriver Logging.","D":"Write a script to tail the log file within the pod and write entries to standard output. Run the script as a sidecar container with the application's pod. Configure a shared volume between the containers to allow the script to have read access to /var/log in the application container."},"url":"https://www.examtopics.com/discussions/google/view/54226-exam-professional-cloud-devops-engineer-topic-1-question-4/","answer_ET":"B","answers_community":["B (58%)","D (42%)"]},{"id":"blnV7zoIJv2npaBtXizi","question_id":132,"choices":{"D":"Design a policy that will require on-call teams to immediately call engineers and management to discuss a plan of action if an incident occurs.","C":"Follow up with the employees who reviewed the changes and prescribe practices they should follow in the future.","B":"Ensure that test cases that catch errors of this type are run successfully before new software releases.","A":"Identify engineers responsible for the incident and escalate to their senior management."},"exam_id":6,"question_text":"Your company follows Site Reliability Engineering principles. You are writing a postmortem for an incident, triggered by a software change, that severely affected users. You want to prevent severe incidents from happening in the future. What should you do?","answer":"B","answers_community":["B (85%)","D (15%)"],"timestamp":"2021-06-02 20:33:00","isMC":true,"topic":"1","unix_timestamp":1622658780,"answer_images":[],"answer_ET":"B","url":"https://www.examtopics.com/discussions/google/view/54287-exam-professional-cloud-devops-engineer-topic-1-question-40/","answer_description":"","discussion":[{"content":"B is correct","timestamp":"1640757180.0","poster":"Charun","comments":[{"comment_id":"424034","timestamp":"1644727980.0","upvote_count":"7","content":"Agree with B. I find this answer in \"Site Reliability Engineering: How Google Runs Production Systems\".","poster":"looseboy"}],"upvote_count":"26","comment_id":"393463"},{"poster":"devopsbatch","upvote_count":"10","content":"B make automation better","timestamp":"1638477180.0","comments":[{"comment_id":"376947","content":"Agree with you. IMO - B is the correct answer.","poster":"akg001","timestamp":"1638905640.0","upvote_count":"7"}],"comment_id":"372963"},{"content":"Selected Answer: B\nB. Ensure that test cases that catch errors of this type are run successfully before new software releases.\n\nHere's why:\n\nOption A focuses on blaming individuals, which is not helpful in a postmortem. The goal is to learn from the incident and prevent future occurrences, not to assign fault.\nOption C is a good step, but it's not enough. While following up with reviewers is important, the primary focus should be on improving the testing process to catch errors before they reach production.\nOption D might be helpful in some cases, but it's not a general solution. Not all incidents require immediate escalation, and relying solely on on-call teams to make that decision can lead to unnecessary escalations.","timestamp":"1732445100.0","poster":"thewalker","upvote_count":"1","comments":[{"upvote_count":"1","comments":[{"content":"Additional Considerations\nIt's important to note that there is no single solution that will prevent all incidents. However, by taking a proactive approach and focusing on improving your testing and development processes, you can significantly reduce the risk of future incidents.\n\nHere are some additional resources that you may find helpful:\n\nSite Reliability Engineering (SRE) Book: https://landing.google.com/sre/book.html \nGoogle Cloud Reliability Engineering: https://cloud.google.com/solutions/reliability-engineering \nPostmortem Best Practices: https://sre.google/sre-book/postmortems/","timestamp":"1732445100.0","poster":"thewalker","upvote_count":"1","comment_id":"1217319"}],"content":"Option B addresses the root cause of the incident by ensuring that similar errors are caught during testing. This will help to prevent future incidents and improve the overall reliability of the system.\n\nHere are some additional steps you can take to prevent future incidents:\n\nImplement a strong continuous integration and continuous delivery (CI/CD) pipeline. This will help to automate the testing process and ensure that new code is tested thoroughly before it is deployed to production.\nUse a blameless postmortem process. This will encourage engineers to be open and honest about their mistakes, which will help to identify and fix problems more quickly.\nInvest in training and education for your engineers. This will help them to understand the importance of reliability and how to write code that is less prone to errors.\nBy taking these steps, you can help to prevent future incidents and improve the overall reliability of your system.","comment_id":"1217318","poster":"thewalker","timestamp":"1732445100.0"}],"comment_id":"1217317"},{"content":"Selected Answer: B\nB - Blameless postmortem","poster":"habla2019pasta","comment_id":"1210153","timestamp":"1731399600.0","upvote_count":"1"},{"comment_id":"1139181","timestamp":"1722676740.0","content":"Selected Answer: B\nThe focus should be on improving processes and systems, not blaming individuals.","upvote_count":"1","poster":"alpha_canary"},{"comment_id":"1086018","timestamp":"1717313880.0","upvote_count":"1","content":"Selected Answer: B\nOption B","poster":"jomonkp"},{"poster":"JonathanSJ","upvote_count":"1","content":"Selected Answer: B\nB. Ensuring that test cases that catch errors of this type are run successfully before new software releases will help to prevent similar incidents from happening in the future.","comment_id":"774111","timestamp":"1689215700.0"},{"poster":"Greg123123","upvote_count":"1","comment_id":"762545","timestamp":"1688105340.0","content":"It is B. The main point here is \"trigged by software change\". This make B make sense and right to the point.\n\nD is not correct because it doesn't prevent this from happen again..."},{"content":"Selected Answer: B\nAns: B\n\nExam passed and taken on 19/12/2022, 50/50 from this dump without buying the full access and looking for 'devops' word here: https://www.examtopics.com/discussions/google/1/","upvote_count":"1","comment_id":"755496","poster":"floppino","timestamp":"1687671060.0"},{"poster":"GCP72","comment_id":"636604","upvote_count":"2","content":"Selected Answer: B\nAnswer is B","timestamp":"1674646680.0"},{"comment_id":"590431","content":"Selected Answer: D\nD is correct. B is too narrow","timestamp":"1666505460.0","poster":"devOpsForFun","upvote_count":"2"},{"poster":"PhilipKoku","content":"Selected Answer: B\nB - Blameless port-mortens. Focus on the process and not in the people.","timestamp":"1660313940.0","comment_id":"545994","upvote_count":"3"},{"comment_id":"535107","poster":"cyrus86","content":"I will go with C here","upvote_count":"1","timestamp":"1659055740.0"},{"comment_id":"503154","timestamp":"1655401440.0","upvote_count":"1","poster":"meetplanet","content":"I go for D based on the on-call doc"},{"comment_id":"501273","timestamp":"1655192220.0","content":"c is the correct answer","poster":"Vallal","upvote_count":"4"},{"timestamp":"1653603480.0","poster":"muk5658","comment_id":"487721","upvote_count":"2","content":"I would go with B as they are saying incident is triggered by a software change, if this has been tested thoroughly it would have been avoided."},{"content":"B is better over D because D is incident management, B is RCA.","upvote_count":"2","comment_id":"441238","poster":"MF2C","timestamp":"1646725560.0"},{"poster":"kubosuke","upvote_count":"4","timestamp":"1643019420.0","content":"I think D is correct.\n\n> you want to prevent severe incidents from happening in the future.\nwe need to chose the answer that 'prevent severe incidents'.\n\nB: create test cases can reduce the possibility of incidents, but it doesn't ease the 'severe incidents'. \nto minimize the effect of incidents, we need to make a consensus to manage incidents.\nfor these backgrounds, the answer is D.","comment_id":"413049"},{"comment_id":"391699","upvote_count":"1","poster":"francisco_guerra","comments":[{"poster":"francisco_guerra","comments":[{"content":"D is incorrect because the plan of action needs to be ready BEFORE the incident occurs. If you create a PoA AFTER the incident happens then you are losing critical time and reducing your error budget.","comment_id":"434014","timestamp":"1646071800.0","upvote_count":"4","poster":"mkumar118"}],"upvote_count":"6","timestamp":"1640581500.0","comment_id":"391705","content":"I correct myself\nI find out this\nhttps://sre.google/sre-book/being-on-call/\n\nBeing on-call is a critical duty that many operations and engineering teams must undertake in order to keep their services reliable and available.\n\nwhen an incident occurs, it’s important to evaluate what went wrong, recognize what went well, and take action to prevent the same errors from recurring in the future. SRE teams must write postmortems after significant incidents and detail a full timeline of the events that occurred.\n\nI don't find anything about test cases so I go with D"}],"content":"D sounds very good but\nto prevent severe incidents form happening in the future\ntest cases are a very good option","timestamp":"1640580660.0"}],"question_images":[]},{"id":"wGyalIxBBuPToT68aqEN","discussion":[{"comments":[{"content":"A&D. Why E isnt correct - Synthetic transaction already provides the capability mentioned in E - \"Use current and historic Request Logs to trace customer interaction with the application\". Instead, option A - to review and add additional metrics makes sense !!","upvote_count":"3","comments":[{"timestamp":"1689082260.0","content":"It says \"measure application reliability from a user perspective\" - you need synthetic measurements from outside the infrastructure (D). To simulate the synthetic journey mentioned, you first need to understand the current user behaviours using the 'request' logs (E).","upvote_count":"5","poster":"Rupo7","comment_id":"630046"}],"poster":"Biden","comment_id":"501704","timestamp":"1671057120.0"}],"content":"DE - synthetic transactions","poster":"ralf_cc","upvote_count":"29","timestamp":"1655609640.0","comment_id":"385181"},{"timestamp":"1656474780.0","comments":[{"upvote_count":"10","poster":"cetanx","timestamp":"1663316340.0","content":"Web proxy is not a reverse proxy, it is a forward proxy - a type of server that runs at the client side. If you have clients from all over the world, how will you collect their proxy logs?\n\nSo it cannot be C - D&E should be the answer which don't require any engineering changes \"in the\" application.","comment_id":"445753"}],"comment_id":"393465","upvote_count":"12","poster":"Charun","content":"CE ans"},{"content":"Selected Answer: CE\nOption C and E","timestamp":"1733132640.0","comment_id":"1086022","upvote_count":"1","poster":"jomonkp"},{"content":"Selected Answer: DE\nA - Adding metrics doesn't necessarily reflect reliability from a user perspective'\nB - Modifying the code is against the requirement\nC - Analyzing proxy logs doesn't connect the findings to a user perspective\n\nFrom the request logs, user journeys can be recreated (E) and the replays can be fed to synthetic clients to simulate/replay (D).","poster":"enter_co","comment_id":"719019","upvote_count":"4","timestamp":"1700073600.0"},{"upvote_count":"5","comments":[{"timestamp":"1687687680.0","comment_id":"622084","upvote_count":"2","poster":"[Removed]","content":"From \"measure application reliability from a user perspective..\" comments\nD is closest I think"}],"comment_id":"609535","timestamp":"1685505240.0","poster":"[Removed]","content":"1.Based on \" without making any engineering changes to it\" , exclude A,B at first.\n2. Based on following described, \nhttps://cloud.google.com/architecture/adopting-slos#choosing_a_measurement_method\n\nD & E should be better."},{"content":"Answer: CE \n\nA. Review current application metrics and add new ones as needed.\n ==> (x) \"add new ones\" needs engineering changes\nB. Modify the code to capture additional information for user interaction.\n ==> (x) \"Modify the code\" needs engineering changes\nC. Analyze the web proxy logs only and capture response time of each request.\n ==> (O) no engineering changes\nD. Create new synthetic clients to simulate a user journey using the application.\n => (x) \"Create new synthetic client\" needs engineering changes. \nE. Use current and historic Request Logs to trace customer interaction with the application. ==> (O) no engineering changes","comment_id":"587013","upvote_count":"5","poster":"paul223344","timestamp":"1681693200.0"},{"content":"Selected Answer: DE\nD & E - Reliability review using synthetic transactions and customer journeys from logs.","poster":"PhilipKoku","timestamp":"1676276640.0","upvote_count":"3","comment_id":"546307"},{"upvote_count":"3","content":"Selected Answer: DE\nThis two option doesn't require engineering changes into the application. Web Proxy logs is a forward proxy thing so it present in client side. others need changes","poster":"cloudbee","timestamp":"1672679040.0","comment_id":"515089"},{"poster":"guid1984","upvote_count":"1","content":"C& E.\nC-> a web proxy relays URL requests from clients to a server. Analyzing web proxy logs can give unobtrusive insights into the browsing behavior of users","comment_id":"506970","timestamp":"1671704880.0"},{"upvote_count":"2","timestamp":"1671365580.0","content":"Selected Answer: DE","comment_id":"504193","poster":"rspstudent"},{"timestamp":"1670387220.0","comment_id":"495590","content":"Selected Answer: CE\nC and E should be the correct answer, since the question state that \"without making ANY engineering changes\"","poster":"Freemiums","comments":[{"upvote_count":"4","comment_id":"503604","poster":"not_thanos","timestamp":"1671274440.0","content":"with making any engineering changes to IT (i.e the application itself)"}],"upvote_count":"4"},{"poster":"Biden","timestamp":"1668430740.0","comment_id":"478128","upvote_count":"4","content":"A&D should be the correct answer:\nD - Easy/default choice since this doesnt need any changes on the app\nA - Since the ask is to \"measure reliability\" - review and add the appropriate SLIs. Option E -tracing is needed only for collecting/troubleshooting latency issues - hence not the correct choice"},{"timestamp":"1660093680.0","comment_id":"422374","upvote_count":"4","content":"To me , it looks C & E\nB & D, need engineering changes and investment, hence I ruled these two out\nThis leaves us with A, C and E - The question is asking for \"Need to measure Application Reliability from User perspective without Engineering Changes\" - This rules out A, as talks about adding new metric but not stating which one\n\nConsidering high-traffic web application as \"Request Driven Services\" - Two of the suggested SLI's are Availability and Latency - C & E to me covers Latency\n\nhttps://cloud.google.com/architecture/adopting-slos?hl=en","poster":"raf2121"},{"upvote_count":"2","poster":"gcpengineer","content":"A & D is the answer","comment_id":"421466","timestamp":"1659930180.0"},{"poster":"kubosuke","content":"maybe C,D,E, and it looks like create synthetic client looks like \"engineering change\", so I choose C and E .","comment_id":"414669","timestamp":"1658838960.0","comments":[{"timestamp":"1662908400.0","upvote_count":"2","poster":"[Removed]","comment_id":"443024","content":"Create synthetic client is not an engineering change for the application : the application is not modified. So the answer is still valid."},{"poster":"kubosuke","content":"umm but\n> C. Analyze the web proxy logs 'only' and\nthe phrase 'only' bothers me...\nwe can know the reliability by getting the status of web applications by web proxy logs(I mean HTTP status is good/bad), but we don't need to view these logs 'only'...","upvote_count":"2","timestamp":"1659143040.0","comments":[{"timestamp":"1659930240.0","comment_id":"421467","content":"C cant be the ans , as it talks about response time. we need answer for reliability","upvote_count":"4","poster":"gcpengineer"}],"comment_id":"417120"}],"upvote_count":"1"},{"comments":[{"poster":"holahola","comment_id":"386816","timestamp":"1655790900.0","content":"Same here, because no engineering effort should be required. All others definitely need engineering effort.","upvote_count":"2"}],"upvote_count":"5","comment_id":"376951","poster":"akg001","content":"for me it looks like C,E the correct answer. E for sure.","timestamp":"1654623540.0"},{"timestamp":"1654582320.0","poster":"rinkeshgala1","comment_id":"376547","upvote_count":"2","content":"may be A&E as these options may not need any additional engineering efforts"}],"url":"https://www.examtopics.com/discussions/google/view/54763-exam-professional-cloud-devops-engineer-topic-1-question-41/","topic":"1","question_id":133,"unix_timestamp":1623046320,"question_images":[],"question_text":"You support a high-traffic web application that runs on Google Cloud Platform (GCP). You need to measure application reliability from a user perspective without making any engineering changes to it. What should you do? (Choose two.)","answers_community":["DE (67%)","CE (33%)"],"answer":"DE","answer_images":[],"exam_id":6,"answer_description":"","choices":{"C":"Analyze the web proxy logs only and capture response time of each request.","D":"Create new synthetic clients to simulate a user journey using the application.","A":"Review current application metrics and add new ones as needed.","B":"Modify the code to capture additional information for user interaction.","E":"Use current and historic Request Logs to trace customer interaction with the application."},"answer_ET":"DE","isMC":true,"timestamp":"2021-06-07 08:12:00"},{"id":"8dywjhiO51lkGp71dKxv","answers_community":["A (73%)","C (27%)"],"question_images":[],"answer_ET":"A","choices":{"C":"Create and grant a custom IAM role with the permissions logging.sinks.list and logging.sink.get.","B":"Configure Access Context Manager to allow only these members to export logs.","A":"Grant the team members the IAM role of logging.configWriter on Cloud IAM.","D":"Create an Organizational Policy in Cloud IAM to allow only these members to create log exports."},"question_text":"You manage an application that is writing logs to Stackdriver Logging. You need to give some team members the ability to export logs. What should you do?","isMC":true,"discussion":[{"comments":[{"comment_id":"376955","timestamp":"1654623780.0","upvote_count":"5","comments":[{"content":"I understand that option A gives the ability to export logs, but isn't C the best option following the least privilege principle since the question only says that the team members needs to export logs and not to write them?","timestamp":"1668875940.0","poster":"irocketsoldier","upvote_count":"6","comment_id":"481930"}],"poster":"akg001","content":"agree for the A."}],"content":"option A","timestamp":"1654582320.0","comment_id":"376548","upvote_count":"27","poster":"rinkeshgala1"},{"timestamp":"1668133800.0","content":"It's should be C. least privilege\n\nThe question is ask about export log and does not mention about read and write log \nOption A give too many permission\nLogs Configuration Writer\n(roles/logging.configWriter)\nProvides permissions to read and write the configurations of logs-based metrics and sinks for exporting logs.\n\nlogging.buckets.create\nlogging.buckets.delete\nlogging.buckets.get\nlogging.buckets.list\nlogging.buckets.undelete\nlogging.buckets.update\nlogging.cmekSettings.*\nlogging.exclusions.*\nlogging.locations.*\nlogging.logMetrics.*\nlogging.logServiceIndexes.*\nlogging.logServices.*\nlogging.logs.list\nlogging.notificationRules.*\nlogging.operations.*\nlogging.sinks.*\nlogging.views.create\nlogging.views.delete\nlogging.views.get\nlogging.views.list\nlogging.views.update\nresourcemanager.projects.get\nresourcemanager.projects.list","comment_id":"475935","comments":[{"poster":"Manh","comment_id":"475940","upvote_count":"2","comments":[{"upvote_count":"11","content":"logging.sinks.create is needed to export logs - this is why C is wrong","comment_id":"499601","poster":"Goram113","timestamp":"1670783400.0"}],"content":"After review again, Ans A had enough permission to export log https://cloud.google.com/logging/docs/routing/overview","timestamp":"1668134280.0"},{"comment_id":"732201","upvote_count":"1","timestamp":"1701400080.0","content":"ability to use sinks Add logging.sinks.{list, create, get, update, delete} , the list, get function can only have view permission. can not create sinks to export logs. u need create sink to export logs.","poster":"hanweiCN"}],"poster":"Manh","upvote_count":"7"},{"timestamp":"1733133540.0","comment_id":"1086029","upvote_count":"2","poster":"jomonkp","content":"Selected Answer: C\noption C"},{"poster":"JonathanSJ","content":"Selected Answer: A\nA is correct, although it has wide permissions, but option C have missing other granular permissions for exporting logs, like logging, sinks, create","comment_id":"775979","timestamp":"1705271700.0","upvote_count":"1"},{"timestamp":"1703488320.0","upvote_count":"1","content":"correct ans is A\nLogs Configuration Writer \n(roles/logging.configWriter)\n\nProvides permissions to read and write the configurations of logs-based metrics and sinks for exporting logs.","comment_id":"755458","poster":"GaneshSurwase"},{"upvote_count":"1","comment_id":"599134","poster":"Ananda","timestamp":"1683647880.0","content":"Selected Answer: A\nOption A"},{"upvote_count":"3","poster":"Sreedharveluru","content":"Selected Answer: A\nThere is no such thing called logging.sink.get","timestamp":"1682164080.0","comment_id":"589951"},{"content":"Selected Answer: A\nroles/logging.configWriter (Logs Configuration Writer) gives you the permissions to create log-based metrics, exclusions, buckets, and views, and to use sinks. To use the Logs Explorer (console) for these actions, add roles/logging.viewer.","timestamp":"1680073800.0","upvote_count":"1","comment_id":"577328","poster":"Epic_rose"},{"comment_id":"564119","timestamp":"1678374960.0","poster":"Shasha1","content":"A \nLogs configuration writer can access to configure log exporting and metrics","upvote_count":"1"},{"upvote_count":"1","content":"What is the minimum set of privs in order to export logs?","comment_id":"563265","timestamp":"1678279920.0","poster":"ric79"},{"timestamp":"1676990340.0","comment_id":"552923","upvote_count":"1","poster":"zygomar","content":"Selected Answer: A\nin addition to other comments here, C would be too restrictive. User new to have logs list permissions at least to know which logs to export.\nGoram113 also indicate that logging.sinks.create is needed to export logs hence why C is wrong"},{"content":"Selected Answer: C\nC - Use principle of minimum access required to fulfill the requirements","upvote_count":"1","poster":"PhilipKoku","timestamp":"1676276760.0","comment_id":"546309"},{"poster":"vijaigcp","upvote_count":"1","comment_id":"535575","content":"Selected Answer: A\nAgree with A","timestamp":"1675009200.0"},{"content":"https://cloud.google.com/logging/docs/export/configure_export_v2#before-you-begin A is the answer","upvote_count":"3","comment_id":"515097","poster":"cloudbee","timestamp":"1672679700.0"},{"comment_id":"503892","upvote_count":"4","content":"Write answer is A as stated in the documentation here \n\nhttps://cloud.google.com/logging/docs/export/configure_export_v2#before-you-begin\n\n\"Note that this guide describes creating and managing sinks at the Cloud project level, but you can create sinks (non-aggregated) for billing accounts, folders, and organizations. As you get started, ensure the following:\n\nYou have a Google Cloud project with logs that you can see in the Logs Explorer.\n\nYou have one of the following IAM roles for the source Cloud project from which you're routing logs.\n\nOwner (roles/owner)\nLogging Admin (roles/logging.admin)\nLogs Configuration Writer (roles/logging.configWriter)\nThe permissions contained in these roles allow you to create, delete, or modify sinks. For information on setting IAM roles, see the Logging Access control guide.\"","timestamp":"1671308280.0","poster":"not_thanos"},{"poster":"giammydell","timestamp":"1667049900.0","upvote_count":"3","comment_id":"469777","content":"but C could follow the least privilege priciple","comments":[{"comment_id":"472081","content":"I agree. logging.configWriter (answer A) gives too much power to the team members. We only need to give them the rights to export, not change the whole logging configuration.\nC is ok.","poster":"Trony","timestamp":"1667480940.0","upvote_count":"1"}]},{"content":"A is correct\n\nLogs Configuration Writer\n(roles/logging.configWriter)\n- Provides permissions to read and write the configurations of logs-based metrics and sinks for exporting logs.\nhttps://cloud.google.com/logging/docs/access-control","comment_id":"455078","upvote_count":"4","poster":"sticky","timestamp":"1664561760.0"}],"timestamp":"2021-06-07 08:12:00","topic":"1","answer_images":[],"question_id":134,"answer_description":"","unix_timestamp":1623046320,"answer":"A","exam_id":6,"url":"https://www.examtopics.com/discussions/google/view/54764-exam-professional-cloud-devops-engineer-topic-1-question-42/"},{"id":"rvSaldUnHRtvhoFTx4r9","choices":{"D":"Add a tag to each image in gcr.io/altostrat-images and check that this tag is present when the image is deployed.","C":"Add logic to the deployment pipeline to check that all manifests contain only images from gcr.io/altostrat-images.","A":"Create a custom builder for Cloud Build that will only push images to gcr.io/altostrat-images.","B":"Use a Binary Authorization policy that includes the whitelist name pattern gcr.io/altostrat-images/."},"question_images":[],"answers_community":["B (100%)"],"timestamp":"2021-06-07 08:12:00","discussion":[{"comment_id":"376549","content":"option B","timestamp":"1638864720.0","comments":[{"poster":"akg001","comment_id":"381509","timestamp":"1639460940.0","upvote_count":"5","content":"agree for answer-B"}],"poster":"rinkeshgala1","upvote_count":"25"},{"timestamp":"1640757180.0","upvote_count":"12","comment_id":"393466","poster":"Charun","content":"B is correct"},{"upvote_count":"1","comment_id":"1139195","timestamp":"1722678180.0","content":"Selected Answer: B\nhttps://cloud.google.com/binary-authorization/docs/key-concepts#allowlist_patterns","poster":"alpha_canary"},{"poster":"jomonkp","upvote_count":"2","timestamp":"1717315260.0","comment_id":"1086032","content":"Selected Answer: B\nOption B"},{"upvote_count":"1","content":"Selected Answer: B\nD.\nSee admissionWhitelistPatterns in: \nhttps://cloud.google.com/binary-authorization/docs/example-policies#add_exempt_images","comment_id":"940760","comments":[{"timestamp":"1704198600.0","poster":"zanhsieh","content":"Should be B not D.","comments":[{"timestamp":"1705368480.0","poster":"aswani","upvote_count":"1","comment_id":"952763","content":"are these questions still valid?"}],"comment_id":"940761","upvote_count":"1"}],"poster":"zanhsieh","timestamp":"1704198600.0"},{"content":"Selected Answer: B\nSee https://cloud.google.com/binary-authorization/docs/example-policies","timestamp":"1673080260.0","upvote_count":"2","comment_id":"628225","poster":"Halimb"},{"timestamp":"1668016740.0","content":"Selected Answer: B\nB is the answer","upvote_count":"2","comment_id":"599135","poster":"Ananda"},{"timestamp":"1660314540.0","poster":"PhilipKoku","content":"Selected Answer: B\nB - Binary authorisation is the answer…","upvote_count":"2","comment_id":"546000"},{"content":"Selected Answer: B\nAnswer B - Binary Authorization","poster":"vijaigcp","timestamp":"1659104580.0","comment_id":"535578","upvote_count":"1"},{"upvote_count":"3","timestamp":"1654849620.0","poster":"Shasha1","content":"D \nhttps://cloud.google.com/container-registry/docs/using-with-google-cloud-platform","comment_id":"498519"},{"timestamp":"1650349440.0","upvote_count":"4","poster":"tycho","comment_id":"464479","content":"B)\nhttps://cloud.google.com/binary-authorization/docs/cloud-build"}],"topic":"1","url":"https://www.examtopics.com/discussions/google/view/54765-exam-professional-cloud-devops-engineer-topic-1-question-43/","answer_images":[],"exam_id":6,"answer":"B","question_id":135,"answer_ET":"B","unix_timestamp":1623046320,"answer_description":"","isMC":true,"question_text":"Your application services run in Google Kubernetes Engine (GKE). You want to make sure that only images from your centrally-managed Google Container\nRegistry (GCR) image registry in the altostrat-images project can be deployed to the cluster while minimizing development time. What should you do?"}],"exam":{"isBeta":false,"isImplemented":true,"provider":"Google","numberOfQuestions":196,"lastUpdated":"11 Apr 2025","isMCOnly":true,"id":6,"name":"Professional Cloud DevOps Engineer"},"currentPage":27},"__N_SSP":true}