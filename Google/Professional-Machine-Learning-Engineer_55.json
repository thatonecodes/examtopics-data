{"pageProps":{"questions":[{"id":"rYlYZ1qiniGo5ZlNI5G2","topic":"1","question_images":[],"exam_id":13,"isMC":true,"discussion":[{"comment_id":"741012","poster":"LearnSodas","content":"I think it's B, since we want to reduce false positives","comments":[{"upvote_count":"3","content":"B\nyes, A is incorrect as minimize false negatives does not help","comment_id":"769970","poster":"jamesking1103","timestamp":"1673228820.0","comments":[{"upvote_count":"2","comments":[{"upvote_count":"1","comment_id":"1285681","content":"Upon reading further it seems like the model predicts compliance, so a positive means the picture is compliant. Then B seems more appropriate","timestamp":"1726656540.0","poster":"julesnoa"}],"comment_id":"1285680","poster":"julesnoa","timestamp":"1726656360.0","content":"False negative: Non-compliant, but did not alert. That is what we want to minimize."},{"comment_id":"933623","upvote_count":"10","content":"a non-compliant profile image = positive\nfalse negatives = didn't alert the non-compliant profile image\nso the objective is to minimize false nagatives","timestamp":"1687699080.0","poster":"NickHapton"}]}],"timestamp":"1670679600.0","upvote_count":"18"},{"content":"Selected Answer: A\nThe answer is A. The negative event is usually labeled as positive (e.g., fraud detection, customer default prediction, and here non-compliant picture identification). The question explicitly says, \"ensure that the application does not falsely accept a non-compliant picture.\" So we should avoid falsely labeling a non-compliant image as compliant (negative). \n\nIt is never mentioned in the question that false positives are also a concern. So, recall is better than F1-score for this problem.","comment_id":"960295","upvote_count":"15","poster":"[Removed]","timestamp":"1690104480.0","comments":[{"timestamp":"1725793200.0","comment_id":"1280315","poster":"baimus","upvote_count":"1","content":"The question explicitly states that this isn't the case, it's identifying compliant images, it is compliance that is the positive, so F1 is the only sensible metric."}]},{"timestamp":"1740244800.0","content":"Selected Answer: B\nideally it should minimize FP but that's not an option, option A is incorrect as minimizing FN will increase FP. So next best option is target the f1 score as that is harmonic mean of precision and recall so that will have the most impact in getting towards the ask","upvote_count":"1","poster":"bc3f222","comment_id":"1360192"},{"poster":"8619d79","timestamp":"1739249520.0","content":"Selected Answer: A\nCompliant=negative, accepted non-compliant=false negative (I thought it is negative, to be accepted, but is not). So I need to minimize false negative, Recall","comment_id":"1354846","upvote_count":"2"},{"upvote_count":"2","content":"Selected Answer: A\nAnswer is A --> non-compliant photo is positive. Falsely accepting a non-compliant photo is a false negative.","timestamp":"1737479700.0","poster":"moammary","comment_id":"1344248"},{"comment_id":"1341003","content":"Selected Answer: B\nThe goal is the compliance of an image: false positives means an image accepted but not-compliant and viceversa for false negatives","timestamp":"1736947920.0","upvote_count":"1","poster":"vinevixx"},{"content":"Selected Answer: D\noversampling the negative class to avoid falsely labelling them as compliant","comment_id":"1333680","upvote_count":"1","poster":"nimbous","timestamp":"1735500180.0"},{"comment_id":"1333102","upvote_count":"1","content":"Selected Answer: B\nChoice between A & B. A if +ve class is non-compliant pics, B if +ve class is compliant pics,\nAs per query, +ve class is compliant pics - \"to predict whether a user’s submitted profile photo meets the requirements\".\nThough I feel the person who framed the question really wanted A to be the choice, seems like question is wrongly framed - Selected B","timestamp":"1735409760.0","poster":"Ankit267"},{"upvote_count":"1","timestamp":"1735319040.0","comment_id":"1332538","content":"Selected Answer: D\nD: In this case, a false positive means accepting a non-compliant picture. You want to minimize these. By providing more examples of non-compliant pictures, you train the model to be more sensitive to identifying them and less likely to make this type of error.","poster":"thescientist"},{"upvote_count":"1","poster":"soumik_barori","content":"Selected Answer: D\n1. Emphasizes the minority class (non-compliant pictures), ensuring the model better differentiates non-compliant images.\n2. Balances the dataset to prevent the model from favouring compliant images disproportionately.\n3. Provides flexibility to fine-tune the model for this specific use case.","comment_id":"1330636","timestamp":"1734915720.0"},{"poster":"uatud3","timestamp":"1732772880.0","comment_id":"1319037","upvote_count":"1","content":"Selected Answer: B\nIt's B. You are optimizing for false positives, Not false negatives(Recall)"},{"timestamp":"1732582020.0","upvote_count":"2","comment_id":"1317848","poster":"AB_C","content":"Selected Answer: D\nD - minimizing false positives"},{"poster":"desertlotus1211","upvote_count":"2","comment_id":"1306179","timestamp":"1730555400.0","content":"Answer is D: \nSince the goal is to minimize false positives (incorrectly accepting a non-compliant photo), having more examples of non-compliant photos in the training data will help the model better identify these cases. By training with more non-compliant examples, the model will learn to recognize these images more accurately, thus reducing the chance of falsely accepting them."},{"upvote_count":"1","comments":[],"comment_id":"1280317","poster":"baimus","content":"Selected Answer: B\nA is wrong because we are trying to minimise false positives, not false negatives. The question states that the model identifies compliance (rather than non-compliance) so a positive means compliant.\nB is correct, though one would usually say \"we are trying to optimise precision\", optimising F1 is the only answer that addresses this, albiet not as directly as I'd like.\nC and D are nonsense.","timestamp":"1725793260.0"},{"timestamp":"1717740840.0","poster":"PhilipKoku","content":"Selected Answer: A\nA) Minimise False Negatives","upvote_count":"1","comment_id":"1225927"},{"poster":"girgu","content":"Selected Answer: D\nD. Cost of Misclassification: In this scenario, falsely accepting a non-compliant picture (false positive) is more critical than rejecting a compliant picture (false negative). A user with a non-compliant picture could violate the platform's terms or negatively impact the user experience.\nTraining Data Imbalance: Social media applications might receive many compliant pictures and far fewer non-compliant ones. A standard training dataset might be imbalanced, with the model learning more from the majority class (compliant pictures).","upvote_count":"1","comment_id":"1219644","timestamp":"1716823140.0"},{"upvote_count":"2","comments":[{"poster":"pinimichele01","comment_id":"1203059","upvote_count":"1","content":"a non-compliant profile image = positive\nfalse negatives = didn't alert the non-compliant profile image\nso the objective is to minimize false nagatives","timestamp":"1714211400.0"}],"comment_id":"1184113","poster":"Delphin_8150","content":"Selected Answer: B\nGonna go with B on this one, tricky question but since reducing false positives is the goal here only B fits that requirement","timestamp":"1711544820.0"},{"upvote_count":"2","poster":"Carlose2108","timestamp":"1709553840.0","comment_id":"1165544","content":"Selected Answer: A\nI went with A."},{"timestamp":"1706020800.0","poster":"b1a8fae","comment_id":"1129677","upvote_count":"2","content":"Selected Answer: B\nB.\nA non-compliant picture is the positive and not the negative. What the question is asking is to decrease the number of false positives (\"falsely labeled as non compliant\"), which is achieved through optimizing for precision and not recall. Since C and D sound a bit overkill, I would go for the one that prioritizes false positives which is B."},{"upvote_count":"1","content":"Think is B since we need to optimize for percision","timestamp":"1700209380.0","poster":"Mickey321","comment_id":"1073104"},{"content":"Selected Answer: D\nMinimize False positive. Hence percision. D is the closest.","timestamp":"1700112540.0","comment_id":"1072160","upvote_count":"1","poster":"Mickey321"},{"comment_id":"1068060","content":"Selected Answer: B\nOptimising for false positives is the goal here which should have been precision. Since precision is not available in options, the next best is F1 score which is harmonic mean of precision and recall. Although it wont fully satisfy the false positives it atleast wont skew towards recall which is more false positives that deviates from the goal. Hence B","upvote_count":"1","poster":"Krish6488","timestamp":"1699731720.0"},{"poster":"MCorsetti","upvote_count":"1","comment_id":"1050439","timestamp":"1697970180.0","content":"Selected Answer: B\nWe should optimize for precision to minimize false positives, so optimizing for recall should be incorrect. F1 Score will balance both precision and recall. Both B and C might not necessarily meet the goal"},{"poster":"aberthe","comment_id":"1039570","content":"Selected Answer: A\nI vote B","upvote_count":"1","timestamp":"1696945560.0"},{"poster":"libo1985","upvote_count":"2","comment_id":"1018887","timestamp":"1695824700.0","content":"A. Let me explain why. You may have 3 times more examples of images, however, the total number of images can be small, which lead to poor model performace, so C and D are not the for definite answer. The target is the detection of abnormal photo, so falsely accept a non-compliant picture is false negative. So A."},{"comment_id":"1018885","poster":"libo1985","timestamp":"1695824520.0","upvote_count":"1","content":"A. Let me explain why. You may have 3 times more examples of images, however, the total number of images can be small, which lead to poor model performace, so C and D are not the for definite answer. The target is the detection of abnormal photo, so falsely accept a non-compliant picture is false negative. So A."},{"poster":"lalala_meow","content":"Selected Answer: A\nI was thinking B but after reading the comments I think it should be A. \nI was thinking a non-compliant profile image = negative but actually it should be the positive case we do want to flag out. So minimising false negative fits the requirement \"ensure that the application does not falsely accept a non-compliant picture.\"","upvote_count":"1","comment_id":"1015857","timestamp":"1695563880.0"},{"timestamp":"1688761440.0","content":"Selected Answer: B\nB should be correct. It covers not only the recall but also the precision","comment_id":"945979","upvote_count":"1","poster":"SamuelTsch"},{"poster":"Liting","timestamp":"1688738640.0","content":"Selected Answer: A\nOptimize recall can help lowering the false negative cases","upvote_count":"1","comment_id":"945753"},{"poster":"tavva_prudhvi","timestamp":"1688492460.0","upvote_count":"2","comments":[{"timestamp":"1699383360.0","poster":"tavva_prudhvi","upvote_count":"1","comment_id":"1065091","comments":[{"comment_id":"1274336","upvote_count":"1","timestamp":"1724905560.0","content":"in the questions it says build a model to ensure the application does not falsely accept non-complaint picture , thats it ,, whats the need of bringing false negative also ? however your point is valid when the question has both false postive and false negative , since it is not , i would rather go with D, where it will identity and reject non-compliant photos.","poster":"Jason_Cloud_at"}],"content":"Given the requirement not to falsely accept a non-compliant picture, the best option would likely be:\n\nB. Use AutoML to optimize the model’s F1 score in order to balance the accuracy of false positives and false negatives. This ensures that the model is not overly biased towards accepting or rejecting pictures and provides a balanced approach to handling both types of errors. However, if the priority is strongly weighted towards not accepting non-compliant pictures, then: Dcould be the better approach, as it would likely improve the model's ability to correctly identify non-compliant pictures."}],"content":"Selected Answer: B\nIn this scenario, it is important to balance the accuracy of false positives (where a non-compliant picture is accepted) and false negatives (where a compliant picture is rejected). By optimizing the F1 score, the model will find the best balance between precision and recall, which will help reduce both false positives and false negatives. This will ensure that the application doesn't falsely accept a non-compliant picture.","comment_id":"943042"},{"comment_id":"915239","content":"Selected Answer: B\nB. Use AutoML to optimize the model’s F1 score in order to balance the accuracy of false positives and false negatives.\nCan't be A. The sentence \"ensure that the application does not falsely accept a non-compliant picture\" stattes that we don't want false positives (so I'm less concern about false negatives). A false positive will be that one classfied as compliant when is not compliant. I interpret that the positive class will be that one that \"meets the requirements\" as stated as well.","poster":"Voyager2","timestamp":"1685954760.0","upvote_count":"1"},{"comment_id":"912433","timestamp":"1685666400.0","poster":"julliet","content":"Selected Answer: B\nnot recall, because we 1) do tell the customer if pic is accepted, 2) can't accept non-compliant pic","upvote_count":"1"},{"poster":"Scipione_","comment_id":"909349","content":"Selected Answer: B\nWent with B","upvote_count":"2","timestamp":"1685360700.0"},{"upvote_count":"1","poster":"Scipione_","comment_id":"909347","timestamp":"1685360580.0","content":"Selected Answer: B\nWent with B"},{"upvote_count":"1","poster":"TNT87","content":"Selected Answer: D\nAnswer D","timestamp":"1683627540.0","comment_id":"892978"},{"content":"Selected Answer: B\nWent with B","poster":"M25","timestamp":"1683609240.0","upvote_count":"2","comment_id":"892756"},{"comment_id":"880065","timestamp":"1682406600.0","content":"Selected Answer: B\nB. Option B, \"Use AutoML to optimize the model’s F1 score in order to balance the accuracy of false positives and false negatives\", is the best approach to build an ML model that can predict whether a user's submitted profile photo meets the requirements while ensuring that the application does not falsely accept a non-compliant picture.","poster":"lucaluca1982","upvote_count":"3"},{"upvote_count":"1","timestamp":"1680430140.0","poster":"dfdrin","content":"Selected Answer: D\nIt's D. It can't be A since we want to minimize false positives","comment_id":"858726"},{"upvote_count":"1","content":"The answer must be as below\nUse AutoML to optimize the model’s precision in order to minimize false positive\n\nTarget class =compliant picture but Does not falsely accept a non-compliant picture is False Positive.\nI suppose the question may be incomplete","timestamp":"1678029060.0","poster":"John_Pongthorn","comment_id":"830008"},{"comment_id":"825035","poster":"jenjenjenjenjen","comments":[{"upvote_count":"1","content":"argument is valid, but it only addresses one aspect of the problem. While increasing the frequency of negative class in the dataset may improve the model's precision for the negative class, it may also lead to a decrease in recall for the positive class. This means that the model may miss some compliant pictures and falsely reject them as non-compliant.\n\nTherefore, it is important to balance the frequency of both positive and negative classes in the dataset, and use a metric like F1 score to optimize the model's performance. Additionally, building a custom model may require more resources and time compared to using AutoML, which can automatically select the best model based on the specified performance metric.\n\nOverall, while increasing the frequency of negative class may improve the model's precision, it is not the only factor to consider when building a model for this task.","comments":[{"timestamp":"1687422000.0","upvote_count":"1","content":"I generally agree, however the question states clearly that rejecting non-compliant pictures is more important than accepting compliant pictures (which also makes sense from a business view, as non-compliant fotos allow users to simply take another one, while accepting a non-compliant photo might be catastrophic for downstream tasks). Therefore I would also go with D","poster":"friedi","comment_id":"930285"}],"poster":"tavva_prudhvi","timestamp":"1679074740.0","comment_id":"842175"}],"upvote_count":"2","content":"Selected Answer: D\nI think it's D because\n\nIf you increase the frequency of the negative class in your dataset, it will cause the classifier to become more cautious in its predictions and increase its precision for the negative class. This is because the classifier now has more negative examples to learn from and is less likely to make false positive predictions.","timestamp":"1677602280.0"},{"timestamp":"1677153480.0","poster":"Scipione_","upvote_count":"1","comment_id":"819147","content":"Selected Answer: B\nit's B since you need to optimize precision, you don't want \"the application does not falsely accept a non-compliant picture\" so you want to minimize false positive.\nIn my opinion, F1 score is the only possible answer between these."},{"poster":"enghabeth","content":"Selected Answer: D\nmakes sense to increase non-compliant examples","comment_id":"802741","upvote_count":"2","timestamp":"1675909860.0"},{"content":"Selected Answer: A\nFalse Negative means it is False that the picture does not follow the requirements -> Accepted. I.e. the model predicts that a non-compliant picture (N) is not against the requirements (F), and so accepted. Tricky one. \n\nFP would say that it is false that the picture follows the requirements, and so it rejects a valid image. \n\nTrue Positive + False Negative = Actual Positive = Accepted","upvote_count":"4","poster":"taxberg","comment_id":"794093","comments":[{"upvote_count":"1","comment_id":"842172","poster":"tavva_prudhvi","content":"Option A may lead to a high recall but may result in a higher number of false positives, which is not desirable in this case.","timestamp":"1679074560.0"},{"comment_id":"795884","upvote_count":"2","content":"No it's not tricky. \nTP - photo meets requirements and it classified as that\nFP - photo doesn't meet requirements but is classified as that, so it's falsely accepted \nYour logic makes sense only if you invert the question for classification as\n\"Find photos that don't meet requirements\" then FN would mean photo that doesn't meet requirements was classified as it has. (double negation)","poster":"pshemol","timestamp":"1675326540.0"}],"timestamp":"1675166700.0"},{"comment_id":"793141","content":"Selected Answer: D\n\"application does not falsely accept\" it's FP not FN so it's not recall but precison.\nModel must better know wrong photos to make less mistakes on them.\nVote for D","poster":"pshemol","timestamp":"1675101480.0","upvote_count":"3"},{"timestamp":"1673626620.0","comments":[{"timestamp":"1674701400.0","comment_id":"788312","poster":"kukumalu","upvote_count":"1","content":"recall = TP/(TP+FN) , by minimizing FN, shouldn't it be recall or sensitivity increase instead?"}],"content":"Selected Answer: A\nA - the sentence says optimize recall, lowering the recall we get a higher precision, which is the question requirement.","poster":"Nick1237","upvote_count":"1","comment_id":"774655"},{"timestamp":"1673021940.0","poster":"behzadsw","upvote_count":"1","content":"Selected Answer: A\nA optimize for recall (TP/TP+FN)","comment_id":"767882"},{"content":"Selected Answer: A\noptimize recall","comment_id":"760936","timestamp":"1672313460.0","upvote_count":"3","poster":"mymy9418"},{"poster":"hiromi","upvote_count":"4","comment_id":"747045","content":"Selected Answer: D\nD for me","timestamp":"1671186120.0"},{"poster":"neochaotic","comments":[{"poster":"behzadsw","comments":[{"poster":"tavva_prudhvi","content":"point is valid. Oversampling the non-compliant class may result in a biased model, especially if the training data does not reflect the true distribution of the classes in the real-world data. This can lead to a model that is more accurate for the oversampled class but performs poorly on the actual data.\n\nMoreover, optimizing for recall (i.e., minimizing false negatives) may increase the risk of false positives, which is not desirable for this specific task. It is important to maintain a balance between precision and recall to ensure that the model performs well on both compliant and non-compliant pictures.\n\nTherefore, optimizing the model's F1 score, which considers both precision and recall, is a better approach to ensure that the model performs well on both classes while avoiding bias. Additionally, using AutoML can help to select the best model while avoiding bias in the dataset.","upvote_count":"2","comment_id":"842178","timestamp":"1679074920.0"}],"content":"Answer is A (TP/TP+FN). Why do you want to oversample non-compliant? We don't know the distribution in the training data. You might risk a model that is biased.","upvote_count":"2","timestamp":"1673021880.0","comment_id":"767880"}],"timestamp":"1670701260.0","content":"D - the question is regarding non-compliant Images. So it makes sense to increase non-compliant examples","comment_id":"741204","upvote_count":"4"},{"timestamp":"1670554020.0","poster":"YangG","upvote_count":"3","comment_id":"739685","content":"I will go for A"}],"choices":{"C":"Use Vertex AI Workbench user-managed notebooks to build a custom model that has three times as many examples of pictures that meet the profile photo requirements.","D":"Use Vertex AI Workbench user-managed notebooks to build a custom model that has three times as many examples of pictures that do not meet the profile photo requirements.","B":"Use AutoML to optimize the model’s F1 score in order to balance the accuracy of false positives and false negatives.","A":"Use AutoML to optimize the model’s recall in order to minimize false negatives."},"answer_ET":"A","question_id":271,"timestamp":"2022-12-09 03:47:00","answer_images":[],"answer_description":"","answer":"A","question_text":"You need to build an ML model for a social media application to predict whether a user’s submitted profile photo meets the requirements. The application will inform the user if the picture meets the requirements. How should you build a model to ensure that the application does not falsely accept a non-compliant picture?","unix_timestamp":1670554020,"url":"https://www.examtopics.com/discussions/google/view/90750-exam-professional-machine-learning-engineer-topic-1-question/","answers_community":["A (43%)","B (32%)","D (25%)"]},{"id":"G0F8mFFbT6YW3TZuwPfQ","exam_id":13,"topic":"1","answers_community":["A (100%)"],"question_text":"You need to build classification workflows over several structured datasets currently stored in BigQuery. Because you will be performing the classification several times, you want to complete the following steps without writing code: exploratory data analysis, feature selection, model building, training, and hyperparameter tuning and serving. What should you do?","timestamp":"2021-06-05 17:43:00","discussion":[{"comment_id":"413008","content":"A. Because BigQuery ML need to write code.","upvote_count":"28","poster":"guruguru","timestamp":"1627107180.0"},{"upvote_count":"1","timestamp":"1736724960.0","poster":"plumbig11","comment_id":"1339726","content":"Selected Answer: A\nAutoml is now Vertex AI Tabular Workflows"},{"timestamp":"1721135040.0","comment_id":"1248913","poster":"tadeupan","upvote_count":"1","content":"create a model without doing literally anything, logo AutoML. A."},{"upvote_count":"2","timestamp":"1717648080.0","comment_id":"1225136","poster":"PhilipKoku","content":"Selected Answer: A\nA) Auto ML Tables doesn’t require code."},{"upvote_count":"3","timestamp":"1711925700.0","comment_id":"1187066","poster":"Azhar10","content":"The question says 'over several structured datasets' means large/multiple datasets and 'several times' means frequently use of data. Though BigQuery ML is not an absolute 'NO Code' solution but all it needs is very simple SQL query to train ML model So 'B' could be the correct answer here but it is asking for Hyperparameter tuning which is not available in BigQuery ML so correct answer is 'A'"},{"poster":"fragkris","content":"Selected Answer: A\nA - AutoML is no code","upvote_count":"1","comment_id":"1085177","timestamp":"1701430800.0"},{"comment_id":"946828","upvote_count":"1","timestamp":"1688867460.0","content":"Selected Answer: A\nrequirement : No code\nA. Configure AutoML Tables to perform the classification task. : No code\nB. Run a BigQuery ML task to perform logistic regression for the classification. : coding LR model\nC. Use AI Platform Notebooks to run the classification model with pandas library. : Notebooks include codes\nD. Use AI Platform to run the classification model job configured for hyperparameter tuning.: job needs to be written what to execute","poster":"harithacML"},{"poster":"M25","upvote_count":"1","content":"Selected Answer: A\nWent with A","comment_id":"892680","timestamp":"1683608040.0"},{"upvote_count":"1","comment_id":"737114","content":"Selected Answer: A\nBecause BigQueryML doesn't have lots of steps that mentioned in question","poster":"Moulichintakunta","timestamp":"1670350680.0"},{"poster":"EFIGO","comment_id":"725181","upvote_count":"1","timestamp":"1669212060.0","content":"Selected Answer: A\n\"without writing code\" ==> AutoML\nA is correct"},{"comment_id":"709340","timestamp":"1667325180.0","upvote_count":"1","poster":"abhi0706","content":"Correct answer is \"A\""},{"poster":"GCP72","comment_id":"647168","timestamp":"1660565340.0","upvote_count":"1","content":"Selected Answer: A\nCorrect answer is \"A\""},{"comment_id":"643201","poster":"sachinxshrivastav","upvote_count":"1","timestamp":"1659762780.0","content":"Selected Answer: A\nBecause BigQuery ML need to write code, so A is the correct one"},{"poster":"Mohamed_Mossad","comment_id":"615282","upvote_count":"1","content":"Selected Answer: A\n\"without writing code\" only A option complies with this statment , all other options requires writing code","timestamp":"1655033520.0"},{"poster":"caohieu04","timestamp":"1646015100.0","content":"Selected Answer: A\nA is correct","comment_id":"557777","upvote_count":"2"},{"comment_id":"518687","content":"A is correct \nhttps://cloud.google.com/automl-tables/docs/beginners-guide","poster":"NamitSehgal","upvote_count":"3","timestamp":"1641517020.0"},{"poster":"MisterHairy","content":"=New Question7=\nYou recently designed and built a custom neural network that uses critical dependencies specific to your organization's framework. You need to train the model using a managed training service on Google Cloud. However, the ML framework and related dependencies are not supported by Al Platform Training. Also, both your model and your data are too large to fit in memory on a single machine. Your ML framework of choice uses the scheduler, workers, and servers distribution structure. What should you do?\n\nA. Build your custom container to run jobs on Al Platform Training\nB. Use a built-in model available on Al Platform Training\nC. Build your custom containers to run distributed training jobs on Al Platform Training\nD. Reconfigure your code to a ML framework with dependencies that are supported by Al Platform Training","timestamp":"1640183400.0","comments":[{"poster":"coderpk","upvote_count":"4","timestamp":"1641409980.0","comment_id":"517753","content":"C custom container and distributed system"},{"comment_id":"528938","upvote_count":"3","content":"Answer - C\nIt's between A & C\nC - Because the questions states data too large to fit in memory hence distributed training is relevant","poster":"A4M","timestamp":"1642740780.0"},{"content":"C is the answer without doubt.\nA: Distributed? Nope\nB: Built-in? Nope\nD: Reconfig? Nope","timestamp":"1649219340.0","comment_id":"581577","upvote_count":"3","poster":"morgan62"},{"upvote_count":"1","poster":"MisterHairy","comment_id":"507167","timestamp":"1640183580.0","content":"Answer?"},{"upvote_count":"2","timestamp":"1640488380.0","comments":[{"content":"Only moderator can post new questions. Thus, I am left with this format. I have emailed the additional questions to the moderator, but he/she has not added them to the site. These questions were received off of other practice tests, but answers were not provided.","poster":"MisterHairy","comment_id":"511104","upvote_count":"4","comments":[{"timestamp":"1649604540.0","upvote_count":"1","content":"Hi MisterHairay, are these the real exam questions? Because most of the questions on examtopic are real exam questions.","poster":"AliNaqi","comment_id":"583755"},{"upvote_count":"1","timestamp":"1649249100.0","content":"I really appreciate your efforts. Thank you for the questions! It helps a lot!","comment_id":"581813","poster":"eeah"}],"timestamp":"1640695620.0"}],"poster":"NickHapton","content":"why you have so many new questions ? Do I need to prepare your questions as well?","comment_id":"509394"},{"upvote_count":"1","poster":"Mohamed_Mossad","timestamp":"1655033640.0","content":"\"ML framework and related dependencies are not supported by Al Platform Training\" use custom containers \n\"your model and your data are too large to fit in memory on a single machine \" use distributed learning techniques\nanswer is C","comment_id":"615284"}],"upvote_count":"3","comment_id":"507158"},{"content":"You have to export out BQ trained ML model to set it up for inference. Inference is not natively offered in BQ. \nYou can perform EDA in autoML tables.","poster":"ashii007","upvote_count":"1","comment_id":"500065","timestamp":"1639320180.0"},{"timestamp":"1638786660.0","upvote_count":"1","poster":"alphard","content":"A is right. \n\nDump data to table and do the work by clicks of button and no coding needed.","comment_id":"495049"},{"content":"A -> Automatically build and deploy state-of-the-art machine learning models on structured data\n\nhttps://cloud.google.com/automl-tables/docs#docs","poster":"mousseUwU","upvote_count":"2","timestamp":"1634557560.0","comment_id":"464096"},{"content":"I think it's B because you cannot perform exploratory data analysis with AutoML.","poster":"ron123_aa","timestamp":"1632845700.0","comment_id":"453510","upvote_count":"2"},{"poster":"Y2Data","timestamp":"1631580780.0","upvote_count":"1","content":"Only A doesn't require code.","comment_id":"444251"},{"poster":"chohan","timestamp":"1623765900.0","upvote_count":"4","comments":[{"comment_id":"407856","upvote_count":"1","poster":"omar_bh","content":"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-hyperparameter-tuning#:~:text=BigQuery%20ML%20supports%20hyperparameter%20tuning%20when%20training%20ML,hyperparameters.%20Hyperparameter%20tuning%20supports%20the%20following%20model%20types%3A","timestamp":"1626438480.0"},{"comment_id":"395383","content":"actually Automl tables can do tuning, click the trail and check the log, you can see all the parameter the model been using","poster":"gcp2021go","timestamp":"1625103780.0","upvote_count":"2"}],"content":"The answer is B. Automl Tables can't do Hyperparameter Tuning","comment_id":"382704"},{"upvote_count":"3","content":"A is the correct answer. The other options will require coding.","comment_id":"375528","timestamp":"1622939880.0","poster":"esuaaaa"},{"poster":"gcp2021go","upvote_count":"4","comment_id":"375295","content":"the answer is A. AutoML table is a fully managed easy to deploy model training and delployment engine. however, AutoML tables has limitation in terms of feature engineering ( oversampling or downsampling)","timestamp":"1622907780.0"}],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/54654-exam-professional-machine-learning-engineer-topic-1-question/","question_images":[],"answer_images":[],"isMC":true,"choices":{"A":"Configure AutoML Tables to perform the classification task.","C":"Use AI Platform Notebooks to run the classification model with pandas library.","B":"Run a BigQuery ML task to perform logistic regression for the classification.","D":"Use AI Platform to run the classification model job configured for hyperparameter tuning."},"unix_timestamp":1622907780,"question_id":272,"answer_ET":"A","answer":"A"},{"id":"Hjjd5Z03MgB14vyG1eil","question_id":273,"answer_images":[],"choices":{"B":"Use AI Platform to run distributed training jobs without checkpoints.","A":"Use AI Platform to run distributed training jobs with checkpoints.","D":"Migrate to training with Kuberflow on Google Kubernetes Engine, and use preemptible VMs without checkpoints.","C":"Migrate to training with Kuberflow on Google Kubernetes Engine, and use preemptible VMs with checkpoints."},"question_text":"You lead a data science team at a large international corporation. Most of the models your team trains are large-scale models using high-level TensorFlow APIs on AI Platform with GPUs. Your team usually takes a few weeks or months to iterate on a new version of a model. You were recently asked to review your team’s spending. How should you reduce your Google Cloud compute costs without impacting the model’s performance?","discussion":[{"timestamp":"1671187680.0","content":"Selected Answer: C\nhttps://cloud.google.com/blog/products/ai-machine-learning/reduce-the-costs-of-ml-workflows-with-preemptible-vms-and-gpus?hl=en","comment_id":"747070","upvote_count":"11","poster":"seifou"},{"comment_id":"1307640","content":"Selected Answer: C\nC for me","timestamp":"1730860260.0","poster":"sashimii14","upvote_count":"1"},{"timestamp":"1717743660.0","comment_id":"1225944","content":"Selected Answer: C\nC) Preemptible VMs with Check points","poster":"PhilipKoku","upvote_count":"1"},{"timestamp":"1711961820.0","upvote_count":"3","comment_id":"1187327","poster":"MultiCloudIronMan","content":"Selected Answer: C\nPre-emptive VMs are cheaper and checkpoints will enable termination if the result is acceptable"},{"poster":"libo1985","comment_id":"1018894","upvote_count":"1","content":"I guess distributed training is not cheap. So C.","timestamp":"1695825060.0"},{"upvote_count":"4","comment_id":"1011620","poster":"joaquinmenendez","timestamp":"1695148440.0","content":"C is the best approach because it allows you to reduce your compute costs without impacting the model's performance. Preemptible VMs are much cheaper than standard VMs, but they can be terminated at any time. By using checkpoints, you can ensure that your training job can be resumed if a preemptible VM is terminated. \nAlso, even if training takes days, the checkpoints will prevent lossing the progress if preemtible VM are down."},{"upvote_count":"2","comment_id":"945754","timestamp":"1688738700.0","content":"Selected Answer: C\nOptimize cost then should use kubeflow","poster":"Liting"},{"poster":"M25","comment_id":"892757","upvote_count":"1","timestamp":"1683609300.0","content":"Selected Answer: C\nWent with C"},{"timestamp":"1683538200.0","poster":"CloudKida","content":"Selected Answer: C\nhttps://cloud.google.com/ai-platform/prediction/docs/ai-explanations/overview\nAI Explanations helps you understand your model's outputs for classification and regression tasks. Whenever you request a prediction on AI Platform, AI Explanations tells you how much each feature in the data contributed to the predicted result. You can then use this information to verify that the model is behaving as expected, recognize bias in your models, and get ideas for ways to improve your model and your training data.","comment_id":"891968","upvote_count":"1"},{"content":"Selected Answer: A\npreemtible vm are valid for 24hrs. Hence training needs months to complete which is mentioned in question that makes A is answer.","comment_id":"889775","poster":"_learner_","timestamp":"1683259920.0","upvote_count":"2"},{"comment_id":"842187","poster":"tavva_prudhvi","comments":[{"upvote_count":"1","timestamp":"1679075580.0","content":"I think it’s a.\nBy using distributed training jobs with checkpoints, you can train your models on multiple GPUs simultaneously, which reduces the training time. Checkpoints allow you to save the progress of your training jobs regularly, so if the training job gets interrupted or fails, you can restart it from the last checkpoint instead of starting from scratch. This saves time and resources, which reduces costs. Additionally, AI Platform's autoscaling feature can automatically adjust the number of resources used based on the workload, further optimizing costs.","comment_id":"842188","poster":"tavva_prudhvi"}],"content":"Additionally, AI Platform's autoscaling feature can automatically adjust the number of resources used based on the workload, further optimizing costs.","timestamp":"1679075580.0","upvote_count":"1"},{"timestamp":"1674652500.0","comment_id":"787648","poster":"John_Pongthorn","upvote_count":"1","content":"C is out of date ? AI Platform is Vertex-AI ,so , this is a simple scenario that would accommodate infrastructure for this case."},{"comment_id":"765724","timestamp":"1672841220.0","upvote_count":"2","poster":"ares81","content":"Selected Answer: A\nIt's A."},{"comment_id":"747052","poster":"hiromi","upvote_count":"4","content":"Selected Answer: C\nIt's seem C\n- https://www.kubeflow.org/docs/distributions/gke/pipelines/preemptible/\n- https://cloud.google.com/optimization/docs/guide/checkpointing","timestamp":"1671186480.0"},{"timestamp":"1670770980.0","comment_id":"741812","content":"\"A Preemptible VM (PVM) is a Google Compute Engine (GCE) virtual machine (VM) instance that can be purchased for a steep discount as long as the customer accepts that the instance will terminate after 24 hours.\"\nThis excludes C and D. Checkpoints are needed for long processing, so A.","upvote_count":"3","poster":"ares81"},{"comment_id":"741211","poster":"neochaotic","timestamp":"1670701980.0","content":"Selected Answer: C\nC - Reduce cost with preemptive instances and add checkpoints to snapshot intermediate results","upvote_count":"3"},{"content":"Selected Answer: A\nSaving checkpoints avoids re-run from scratch","poster":"LearnSodas","timestamp":"1670686680.0","comment_id":"741074","upvote_count":"2"},{"upvote_count":"1","poster":"YangG","comment_id":"739689","timestamp":"1670554320.0","content":"I think it should be A\nhttps://cloud.google.com/ai-platform/training/docs/overview"}],"answer":"C","question_images":[],"unix_timestamp":1670554320,"url":"https://www.examtopics.com/discussions/google/view/90751-exam-professional-machine-learning-engineer-topic-1-question/","answers_community":["C (82%)","A (18%)"],"isMC":true,"exam_id":13,"answer_ET":"C","answer_description":"","topic":"1","timestamp":"2022-12-09 03:52:00"},{"id":"o0m0bGzuD50SNkeC5eo8","question_images":[],"answer_images":[],"choices":{"C":"Use AutoML Tables to train the model without early stopping.","A":"Create a custom TensorFlow DNN model","D":"Use AutoML Tables to train the model with RMSLE as the optimization objective.","B":"Use BQML XGBoost regression to train the model."},"answer_description":"","discussion":[{"content":"Selected Answer: B\nWent with B","timestamp":"1728909960.0","poster":"gscharly","comment_id":"1195508","upvote_count":"2"},{"comment_id":"892758","upvote_count":"1","timestamp":"1699514100.0","poster":"M25","content":"Selected Answer: B\nWent with B"},{"comment_id":"805184","timestamp":"1691748240.0","poster":"abneural","content":"Selected Answer: B\nAns B.\nC --> No early stopping means longer training time\nD --> RMSLE metric need non-negative Y values","upvote_count":"4"},{"upvote_count":"1","timestamp":"1690456740.0","content":"Selected Answer: B\nB and C is the most likely because of regression approach, But RMSLE it not allow you to take negative label to train as https://cloud.google.com/automl-tables/docs/evaluate#evaluation_metrics_for_regression_models \n\nRMSLE: The root-mean-squared logarithmic error metric is similar to RMSE, except that it uses the natural logarithm of the predicted and actual values plus 1. RMSLE penalizes under-prediction more heavily than over-prediction. It can also be a good metric when you don't want to penalize differences for large prediction values more heavily than for small prediction values. This metric ranges from zero to infinity; a lower value indicates a higher quality model.\n The RMSLE evaluation metric is returned only if all label and predicted values are non-negative.","poster":"John_Pongthorn","comment_id":"789626"},{"timestamp":"1690286880.0","content":"Selected Answer: D\nBQML XGBoost ==> you have to take sql knowlege to write statement and B didn't mention how to get mx performance. Meanwhile \nAutoML you just click and select, click and select, click and select to get it done. and D refers to measurement to get maximizing model performance. you can minimize effort literally","comments":[{"poster":"John_Pongthorn","timestamp":"1690456800.0","upvote_count":"2","comment_id":"789629","content":"To john pongthorn , You are wrong 55555\nit must be B genuinely"}],"upvote_count":"2","poster":"John_Pongthorn","comment_id":"787713"},{"content":"I recommend option D, Use AutoML Tables to train the model with RMSLE as the optimization objective.\n\nUsing AutoML Tables to train the model can be a convenient and efficient way to minimize effort and training time while still maximizing model performance. In this case, using RMSLE as the optimization objective can be a good choice because it is a good fit for regression models with negative values in the target variable.","timestamp":"1688545260.0","comment_id":"766521","upvote_count":"2","poster":"zeic"},{"timestamp":"1687384800.0","upvote_count":"3","poster":"MithunDesai","content":"Selected Answer: B\nB is correct","comment_id":"752882"},{"content":"Selected Answer: B\nIts seen B for me","timestamp":"1686939600.0","poster":"hiromi","comment_id":"747562","upvote_count":"1"},{"poster":"seifou","timestamp":"1686510780.0","content":"Selected Answer: B\nB is correct","comment_id":"742105","upvote_count":"1"},{"content":"It's B.","timestamp":"1686488640.0","comment_id":"741815","upvote_count":"1","poster":"ares81"},{"comment_id":"739693","upvote_count":"2","poster":"YangG","content":"B. BigQuery is a keyword for me","timestamp":"1686272160.0"}],"url":"https://www.examtopics.com/discussions/google/view/90752-exam-professional-machine-learning-engineer-topic-1-question/","exam_id":13,"answer":"B","question_id":274,"answer_ET":"B","question_text":"You need to train a regression model based on a dataset containing 50,000 records that is stored in BigQuery. The data includes a total of 20 categorical and numerical features with a target variable that can include negative values. You need to minimize effort and training time while maximizing model performance. What approach should you take to train this regression model?","answers_community":["B (87%)","13%"],"unix_timestamp":1670554560,"isMC":true,"timestamp":"2022-12-09 03:56:00","topic":"1"},{"id":"cNNZYFojwK7o4Lczv4oW","topic":"1","question_id":275,"url":"https://www.examtopics.com/discussions/google/view/91026-exam-professional-machine-learning-engineer-topic-1-question/","answers_community":["B (71%)","14%","Other"],"exam_id":13,"isMC":true,"answer_ET":"B","question_text":"You are building a linear model with over 100 input features, all with values between –1 and 1. You suspect that many features are non-informative. You want to remove the non-informative features from your model while keeping the informative ones in their original form. Which technique should you use?","discussion":[{"comment_id":"748739","timestamp":"1687077300.0","upvote_count":"8","content":"Selected Answer: B\nL1 regularization it's good for feature selection\nhttps://www.quora.com/How-does-the-L1-regularization-method-help-in-feature-selection\nhttps://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization","comments":[{"poster":"ailiba","comment_id":"818403","content":"but this is not a sparse input vector, just a high dimensional vector where many features are not relevant.","timestamp":"1692730620.0","upvote_count":"1"}],"poster":"hiromi"},{"upvote_count":"5","content":"A. PCA reconfigures the features, so no. \nC. After building your model, so no.\nD. Dropout should be in the model and it doesn't tell us which features are informative or not. Big No!\nFor me, it's B.","poster":"ares81","comment_id":"741822","timestamp":"1686489300.0"},{"timestamp":"1734632940.0","upvote_count":"1","content":"Selected Answer: D\nEven D is correct, but computationally not efficient. But in exam would opt for B if only 1 is correct","comment_id":"1329103","poster":"phani49"},{"comment_id":"1225981","upvote_count":"1","poster":"PhilipKoku","content":"Selected Answer: B\nB) L1 Regularisation","timestamp":"1733566620.0"},{"timestamp":"1704643620.0","poster":"Liting","upvote_count":"1","comment_id":"945755","content":"Selected Answer: B\nWent with B"},{"content":"Selected Answer: B\nWent with B","poster":"M25","timestamp":"1699514100.0","upvote_count":"1","comment_id":"892759"},{"upvote_count":"1","timestamp":"1696104840.0","content":"Selected Answer: B\nL1 regularization penalises weights in proportion to the sum of the absolute value of the weights. L1 regularization helps drive the weights of irrelevant or barely relevant features to exactly 0. A feature with a weight of 0 is effectively removed from the model. https://developers.google.com/machine-learning/glossary#L1_regularization","poster":"Antmal","comment_id":"856213"},{"upvote_count":"1","timestamp":"1694966580.0","content":"Its B. See my explanations under the comments why its not C.","comment_id":"842194","poster":"tavva_prudhvi"},{"content":"Selected Answer: B\nit's a best way, becouse you reduce features non relevant in this case non-informatives","timestamp":"1691541780.0","upvote_count":"1","comment_id":"802750","poster":"enghabeth"},{"poster":"behzadsw","comments":[{"upvote_count":"1","content":"That is a good point. PCA is a technique used to reduce the dimensionality of the dataset by transforming the original features into a new set of uncorrelated features. This can help to eliminate the least informative features and reduce the computational burden of building a model with many input features. However, it is important to note that PCA does not necessarily remove the original features from the model, but rather transforms them into a new set of features. On the other hand, L1 regularization can effectively remove the impact of non-informative features by setting their coefficients to 0 during the model building process. Therefore, both techniques can be useful for addressing the issue of non-informative features in a linear model, depending on the specific needs of the problem.","timestamp":"1694966460.0","comment_id":"842191","poster":"tavva_prudhvi"},{"comment_id":"773989","poster":"jamesking1103","comments":[{"content":"How PCA can keep the original form?","comment_id":"1017802","poster":"libo1985","upvote_count":"1","timestamp":"1711466880.0"}],"timestamp":"1689204540.0","content":"should be A\nas keeping the informative ones in their original form","upvote_count":"3"}],"comment_id":"768070","content":"Selected Answer: A\nThe features must be removed from the model. They are not removed when doing L1 regularization. PCA is used prior to training.","timestamp":"1688669100.0","upvote_count":"2"},{"timestamp":"1686656820.0","upvote_count":"2","content":"Selected Answer: B\nAgree with B","poster":"JeanEl","comment_id":"744086"}],"timestamp":"2022-12-11 16:15:00","answer_description":"","unix_timestamp":1670771700,"question_images":[],"choices":{"C":"After building your model, use Shapley values to determine which features are the most informative.","B":"Use L1 regularization to reduce the coefficients of uninformative features to 0.","A":"Use principal component analysis (PCA) to eliminate the least informative features.","D":"Use an iterative dropout technique to identify which features do not degrade the model when removed."},"answer":"B","answer_images":[]}],"exam":{"provider":"Google","isMCOnly":true,"id":13,"lastUpdated":"11 Apr 2025","numberOfQuestions":304,"isImplemented":true,"isBeta":false,"name":"Professional Machine Learning Engineer"},"currentPage":55},"__N_SSP":true}