{"pageProps":{"questions":[{"id":"qU2WYP8T5HmynuZql3kd","discussion":[{"timestamp":"1641723780.0","upvote_count":"6","content":"I vote D","comment_id":"520104","poster":"scaenruy"},{"poster":"thewalker","comments":[{"timestamp":"1721288040.0","comment_id":"1250213","content":"Let's analyze why the other options are less suitable:\n\nB. Collect messages from production and replay: This approach is risky because it involves using real production data, which might contain sensitive information. It also doesn't provide a controlled environment for testing.\nC. Collect messages from production and publish to the emulator: This approach still involves using real production data, which can be problematic. It also doesn't allow for testing with random data or controlled scenarios.\nD. Publish a standard set of testing messages: While using a standard set of messages is helpful, it might not cover all possible scenarios. Generating random content provides a more comprehensive test.","upvote_count":"1","poster":"thewalker"}],"content":"Selected Answer: A\nThe best answer is A. Create a service to publish messages and deploy the Pub/Sub emulator. Generate random content in the publishing service and publish to the emulator.\n\nHere's why:\n\nPub/Sub Emulator: The Pub/Sub emulator provides a local environment that mimics the behavior of the production Pub/Sub service. This allows you to test your application's Pub/Sub integration without needing to deploy to Google Cloud.\nTesting with Random Data: Generating random content in the publishing service ensures that your application can handle various data formats and scenarios. This helps identify potential issues that might not be caught by unit testing alone.\nControlled Environment: Using the emulator gives you a controlled environment where you can easily manipulate the messages being published, allowing you to test different scenarios and edge cases.","timestamp":"1721288040.0","upvote_count":"1","comment_id":"1250212"},{"timestamp":"1700554560.0","content":"Selected Answer: D\nhttps://cloud.google.com/pubsub/docs/emulator","upvote_count":"1","poster":"wanrltw","comment_id":"1076108"},{"timestamp":"1689567600.0","upvote_count":"1","content":"Selected Answer: D\nD is correct","comment_id":"953818","poster":"amier"},{"content":"Selected Answer: D\nD is the answer.","comment_id":"753385","poster":"zellck","timestamp":"1671719640.0","upvote_count":"1"},{"comment_id":"703548","content":"Selected Answer: D\nVote D","timestamp":"1666672440.0","upvote_count":"1","poster":"lakiluk"},{"timestamp":"1660975140.0","comment_id":"649258","content":"Selected Answer: D\nD is correct","poster":"tomato123","upvote_count":"2"}],"question_id":326,"answer_ET":"D","answers_community":["D (86%)","14%"],"choices":{"B":"Create a service to publish messages to your application. Collect the messages from Pub/Sub in production, and replay them through the publishing service.","A":"Create a service to publish messages, and deploy the Pub/Sub emulator. Generate random content in the publishing service, and publish to the emulator.","D":"Create a service to publish messages, and deploy the Pub/Sub emulator. Publish a standard set of testing messages from the publishing service to the emulator.","C":"Create a service to publish messages, and deploy the Pub/Sub emulator. Collect the messages from Pub/Sub in production, and publish them to the emulator."},"answer":"D","exam_id":7,"unix_timestamp":1641723780,"timestamp":"2022-01-09 11:23:00","topic":"1","isMC":true,"url":"https://www.examtopics.com/discussions/google/view/69735-exam-professional-cloud-developer-topic-1-question-88/","question_images":[],"answer_images":[],"answer_description":"","question_text":"You are developing an application that reads credit card data from a Pub/Sub subscription. You have written code and completed unit testing. You need to test the\nPub/Sub integration before deploying to Google Cloud. What should you do?"},{"id":"mMLN9hZBBJvps61rGTco","answer_description":"","answer_ET":"A","timestamp":"2022-01-02 00:52:00","exam_id":7,"question_images":[],"discussion":[{"poster":"GCPCloudArchitectUser","timestamp":"1645833120.0","content":"Selected Answer: A\nIMO it should be A","upvote_count":"7","comment_id":"556319"},{"timestamp":"1641081120.0","comment_id":"514745","upvote_count":"5","poster":"JonathanSJ","content":"I vote A"},{"comments":[{"poster":"thewalker","comment_id":"1250224","content":"Let's analyze why the other options are less suitable:\n\nB. Broadcast message to users: This approach is not a reliable way to initiate a graceful shutdown. It relies on user interaction and might not be effective if users are not actively using the application.\nC. Write a file for polling: This approach is less efficient and introduces a delay. The application needs to poll the file every five minutes, which can introduce latency and might not be timely enough for a graceful shutdown.\nD. Publish a message to the Pub/Sub topic: This approach is not ideal because it introduces additional complexity and relies on the application's ability to process messages from the same topic it's subscribing to. It also might not be a reliable way to ensure a timely shutdown.","upvote_count":"2","timestamp":"1721289060.0"}],"timestamp":"1721289000.0","upvote_count":"2","comment_id":"1250223","content":"Selected Answer: A\nThe best answer is A. Write a shutdown script that uses inter-process signals to notify the application process to disconnect from the database. Here's why:\n\nInter-process Signals: Signals are a standard mechanism in Unix-like systems for communicating between processes. They are a reliable and efficient way to notify the application process that a shutdown is imminent.\nGraceful Shutdown: Using signals allows the application to gracefully disconnect from the database, ensuring data integrity and preventing potential data loss. The application can handle the signal, perform necessary cleanup tasks, and then exit gracefully.","poster":"thewalker"},{"upvote_count":"1","timestamp":"1709874480.0","poster":"santoshchauhan","comment_id":"1168558","content":"Selected Answer: A\nA. Write a shutdown script that uses inter-process signals to notify the application process to disconnect from the database.\n\nIn the scenario of using preemptible virtual machines for running an application that interacts with a database, a graceful shutdown is essential to ensure data consistency and prevent potential issues like incomplete transactions. A shutdown script utilizing inter-process signals is an efficient and direct way to manage this process."},{"comment_id":"1076138","poster":"wanrltw","timestamp":"1700557020.0","upvote_count":"1","content":"Selected Answer: A\nI vote A:\n- https://cloud.google.com/compute/docs/instances/preemptible#preemption\n- https://cloud.google.com/compute/docs/shutdownscript\n\nOption D is not good as we only have a SINGLE pub/sub topic that is also receiving other messages. I wouldn't rely on the new (shutdown) message to come through and be read by the app timely to disconnect from the db."},{"poster":"braska","timestamp":"1700250480.0","comment_id":"1073580","upvote_count":"1","content":"Selected Answer: D\nOption D is a suitable approach for initiating a graceful shutdown in a scenario where the application needs to receive a notification to disconnect from the database before the virtual machine is preempted. Here's how the process works:","comments":[{"content":"Shutdown Script: Write a shutdown script that is executed when the instance is being preempted.\n\nPublish a Message to Pub/Sub: In the shutdown script, publish a message to the Pub/Sub topic, indicating that a shutdown is in progress. This message serves as a notification to the application.\n\nApplication Subscription: The application subscribes to the Pub/Sub topic and continuously listens for incoming messages","comment_id":"1073581","upvote_count":"1","poster":"braska","timestamp":"1700250540.0"},{"poster":"Aeglas","timestamp":"1700848800.0","content":"You have only one topic, so if there are multiple messages in the queue before the one announcing the disconnect, then a lot of time can pass before the retrival of the message","upvote_count":"1","comment_id":"1079479"}]},{"content":"Selected Answer: A\nI will go with A","timestamp":"1695189960.0","comment_id":"1011963","poster":"__rajan__","upvote_count":"1"},{"timestamp":"1692962940.0","comment_id":"989994","upvote_count":"1","poster":"maxdanny","content":"Selected Answer: A\nhttps://cloud.google.com/compute/docs/instances/preemptible#preemption"},{"upvote_count":"2","comments":[{"content":"Option B, broadcasting a message to signed-in users and instructing them to save current work and sign out, is not relevant to the shutdown process of the application. Option C, writing a file in a location that is being polled by the application, is not a reliable method for initiating a graceful shutdown because the application may not read the file in a timely manner. Option D, publishing a message to the Pub/Sub topic announcing that a shutdown is in progress, is not a reliable method for initiating a graceful shutdown because the application may not read the message in a timely manner.","upvote_count":"1","poster":"omermahgoub","comment_id":"767604","timestamp":"1673006760.0"}],"timestamp":"1673006760.0","content":"It's A\nTo handle the preemption notice and initiate a graceful shutdown, you should write a shutdown script that uses inter-process signals to notify the application process to disconnect from the database. The application can then initiate a graceful shutdown by completing any in-progress tasks and disconnecting from the database, ensuring that data is not lost or corrupted during the shutdown process. This is the most reliable method for initiating a graceful shutdown in response to a preemption notice, as it allows the application to respond directly to the signal and initiate the shutdown process.","poster":"omermahgoub","comment_id":"767603"},{"timestamp":"1660975140.0","poster":"tomato123","content":"Selected Answer: A\nA is correct","upvote_count":"2","comment_id":"649259"},{"timestamp":"1658906640.0","comment_id":"637892","poster":"GossipDolphin","upvote_count":"1","content":"it's A\nCompute Engine sends a preemption notice to the instance in the form of an ACPI G2 Soft Off signal. You can use a shutdown script to handle the preemption notice and complete cleanup actions before the instance stops.\nhttps://cloud.google.com/compute/docs/instances/preemptible#preemption"},{"upvote_count":"2","timestamp":"1652796600.0","poster":"szl0144","content":"A seems correct, guys","comment_id":"602957"},{"poster":"dishum","content":"Looks like D","comment_id":"579539","upvote_count":"2","timestamp":"1648819800.0"},{"content":"C does not make sense, because you don't know when pub sub message will be consumed (there might other events be in the queue before), so I'll go with option A","timestamp":"1642860480.0","poster":"p4","comment_id":"529900","upvote_count":"1"},{"upvote_count":"2","comments":[{"upvote_count":"2","poster":"ParagSanyashiv","comment_id":"519706","timestamp":"1641666000.0","content":"Because for preemptible instances the script should run within 30 seconds of the instance being shutdown or restarted, in this case a pub sub trigger would be faster to perform."},{"poster":"morenocasado","upvote_count":"2","comment_id":"586431","content":"The issue with option D is that we have a SINGLE PubSub topic that is used to send the rows to be inserted; sending a completely different message seems wrong.","timestamp":"1650045060.0"}],"poster":"ParagSanyashiv","content":"According to me , it should be D","comment_id":"519705","timestamp":"1641665880.0"}],"url":"https://www.examtopics.com/discussions/google/view/69226-exam-professional-cloud-developer-topic-1-question-89/","question_text":"You are designing an application that will subscribe to and receive messages from a single Pub/Sub topic and insert corresponding rows into a database. Your application runs on Linux and leverages preemptible virtual machines to reduce costs. You need to create a shutdown script that will initiate a graceful shutdown.\nWhat should you do?","choices":{"A":"Write a shutdown script that uses inter-process signals to notify the application process to disconnect from the database.","C":"Write a shutdown script that writes a file in a location that is being polled by the application once every five minutes. After the file is read, the application disconnects from the database.","B":"Write a shutdown script that broadcasts a message to all signed-in users that the Compute Engine instance is going down and instructs them to save current work and sign out.","D":"Write a shutdown script that publishes a message to the Pub/Sub topic announcing that a shutdown is in progress. After the application reads the message, it disconnects from the database."},"topic":"1","answers_community":["A (94%)","6%"],"answer_images":[],"isMC":true,"unix_timestamp":1641081120,"answer":"A","question_id":327},{"id":"p2QDvRSQTfEBV1sv0Gcv","exam_id":7,"isMC":true,"choices":{"C":"Rolling deployment","D":"Recreate deployment","B":"Canary deployment","A":"Blue/green deployment"},"question_images":[],"timestamp":"2020-04-05 12:55:00","answer_ET":"B","question_text":"You have an application deployed in production. When a new version is deployed, some issues don't arise until the application receives traffic from users in production. You want to reduce both the impact and the number of users affected.\nWhich deployment strategy should you use?","url":"https://www.examtopics.com/discussions/google/view/17899-exam-professional-cloud-developer-topic-1-question-9/","answer_description":"","answers_community":["B (93%)","7%"],"question_id":328,"discussion":[{"poster":"hasithalakshan","timestamp":"1729063020.0","upvote_count":"1","content":"B Canary deployment allows you to release a new version of your application to a small subset of users before rolling it out to everyone. This strategy helps you identify potential issues with the new version while minimizing the impact on users, as only a small portion of traffic is directed to the new version initially.","comment_id":"1298594"},{"upvote_count":"1","poster":"hlljyj","comment_id":"1228969","content":"this is A, Canary is a Testing strategy not a deployment strategy.","timestamp":"1718192880.0"},{"poster":"santoshchauhan","timestamp":"1709820720.0","content":"Selected Answer: B\nB. Canary deployment: In this strategy, the new version of the application (the \"canary\") is rolled out to a small subset of users before it is made available to the entire user base. This allows you to monitor the performance and stability of the new version in the real-world production environment with actual traffic, but only affects a small group of users. If issues arise, the canary deployment can be rolled back with minimal impact.","upvote_count":"1","comment_id":"1168069"},{"timestamp":"1707809760.0","poster":"theseawillclaim","comment_id":"1148962","content":"Selected Answer: B\nThat's exactly what Canary Deployment is for.","upvote_count":"1"},{"timestamp":"1699477020.0","upvote_count":"1","poster":"wanrltw","content":"Selected Answer: B\nB: \nhttps://cloud.google.com/architecture/application-deployment-and-testing-strategies#canary_test_pattern","comment_id":"1065951"},{"timestamp":"1695130860.0","content":"Selected Answer: B\nI would go with B as it is best suited for this senario.","upvote_count":"1","poster":"__rajan__","comment_id":"1011380"},{"poster":"telp","comment_id":"770088","timestamp":"1673246580.0","upvote_count":"2","content":"Selected Answer: B\nanswer is B to reduce impact on users because it's a progressive release"},{"content":"Selected Answer: A\nI think A is correct because of the switching to green only happens after you perform all the tests on it. So you can also test traffic (to satisfy the question) This is the point of blue-green deployment as far as I understood it.\nB is not correct because the real traffic is switched partially to new version immediately and so it effects some users.\n\nreference: https://digitalvarys.com/what-is-blue-gren-deployment/","comment_id":"739145","upvote_count":"1","poster":"Mark123321","timestamp":"1670509440.0"},{"comment_id":"728329","timestamp":"1669559280.0","content":"Selected Answer: B\nBlue/Green is 100% users to Green, Canary id progressive. B.","poster":"jcataluna","upvote_count":"1"},{"comment_id":"649166","upvote_count":"2","content":"Selected Answer: B\nB is correct","timestamp":"1660973160.0","poster":"tomato123"},{"content":"For me it's B, in Canary Deployment only a percentage of users receives the new version and therefore in case of error immediately rollback , B/G immediately the new version , Green, receive all traffic and Blue marked as deprecated","poster":"maxdanny","comment_id":"635068","upvote_count":"1","timestamp":"1658474760.0"},{"upvote_count":"1","timestamp":"1657176840.0","comment_id":"628234","content":"I think the concept of google about B/G testing is that there is a shadow running next to production that receives the same traffic as production. When this shadow is not having any errors you can update the shadow to PROD. So no user is impacted, since all possible new errors will occur in the shadow and not in prod.","comments":[{"timestamp":"1657791360.0","upvote_count":"1","content":"Find more info here: https://cloud.google.com/architecture/implementing-deployment-and-testing-strategies-on-gke#perform_a_bluegreen_deployment","comment_id":"631274","poster":"PetervanLeeuwen"}],"poster":"PetervanLeeuwen"},{"content":"Selected Answer: B\nFor me is B. But I cannot understand why all purchased exam test with this question, put Blue/Green as correct answer. It's so clear that Canary is the rightest one 'cos forward only a few of users to new deploy (not every as blue/green) and also allow the rollback action","comment_id":"607298","timestamp":"1653493800.0","poster":"ruben82","upvote_count":"1"},{"content":"B is correct. Blue Green(B/G) affects all users.","timestamp":"1644974820.0","comment_id":"548210","poster":"nazonazonazo","upvote_count":"1"},{"timestamp":"1638378360.0","poster":"HolaBaby","content":"Selected Answer: B\n1. Reducing impact \n2. Number of users affected \nIf you want meet both of the conditions, you need to choose Canary","upvote_count":"3","comment_id":"491825"},{"poster":"tendzen","upvote_count":"1","timestamp":"1635756120.0","comment_id":"471091","content":"I think it is B, but correct answer is A, hmmm.......\nif we think that we need to test 100% of the traffic, i.e. create a full working test, then right A, because if there is an error we can quickly go back to the old version"},{"timestamp":"1626832260.0","upvote_count":"1","poster":"wilwong","comment_id":"410599","content":"Agree B"},{"content":"This is canary for sure; B","comment_id":"385988","poster":"syu31svc","upvote_count":"4","timestamp":"1624169340.0"},{"poster":"MikeFR","comment_id":"315583","timestamp":"1616239920.0","comments":[{"timestamp":"1624514460.0","poster":"yuchun","comment_id":"389266","content":"blue/green will affect all user, canary can gradually change traffic allocation","upvote_count":"3"}],"content":"A","upvote_count":"1"},{"comment_id":"269788","timestamp":"1610913840.0","poster":"maleksah","content":"Answer is B","upvote_count":"3"},{"poster":"saurabh1805","timestamp":"1604597880.0","content":"B is correct answer hre.","upvote_count":"3","comment_id":"213604"},{"content":"Agree it should be B (canary deployment) Blue/green will affect all users, as well as recreate. The rolling update has other purposes, so Canary is the best for scenario described.","timestamp":"1590504720.0","comment_id":"96178","poster":"emmet","upvote_count":"3"}],"answer_images":[],"topic":"1","unix_timestamp":1586084100,"answer":"B"},{"id":"R8zrMn2Ztm5T3HXLZ18y","isMC":true,"answers_community":["C (100%)"],"question_id":329,"topic":"1","exam_id":7,"url":"https://www.examtopics.com/discussions/google/view/69687-exam-professional-cloud-developer-topic-1-question-90/","discussion":[{"comment_id":"1075611","content":"Selected Answer: C\nC is correct","poster":"Aeglas","upvote_count":"1","timestamp":"1732120860.0"},{"content":"Selected Answer: C\nC is correct.","comment_id":"1011964","timestamp":"1726812480.0","upvote_count":"1","poster":"__rajan__"},{"content":"Selected Answer: C\nC is the answer.\n\nhttps://cloud.google.com/shell/docs\nloud Shell is an interactive shell environment for Google Cloud that lets you learn and experiment with Google Cloud and manage your projects and resources from your web browser.\n\nWith Cloud Shell, the Google Cloud CLI and other utilities you need are pre-installed, fully authenticated, up-to-date, and always available when you need them. Cloud Shell comes with a built-in code editor with an integrated Cloud Code experience, allowing you to develop, build, debug, and deploy your cloud-based apps entirely in the cloud.","timestamp":"1703174580.0","poster":"zellck","comment_id":"752548","upvote_count":"2"},{"comment_id":"649260","poster":"tomato123","content":"Selected Answer: C\nC is correct","upvote_count":"2","timestamp":"1692511140.0"},{"content":"Selected Answer: C\nVote C","timestamp":"1682652300.0","comment_id":"593496","poster":"nqthien041292","upvote_count":"1"},{"poster":"GCPCloudArchitectUser","comment_id":"556322","timestamp":"1677369540.0","upvote_count":"4","content":"Selected Answer: C\nCloud shell is the answer"},{"upvote_count":"4","content":"C should be the correct answer because the source code should not be stores locally in the public pc.","comments":[{"timestamp":"1674303540.0","content":"Yes agree about Option C \nhttps://cloud.google.com/shell/docs","poster":"Blueocean","comment_id":"529120","upvote_count":"2"}],"poster":"ParagSanyashiv","timestamp":"1673202180.0","comment_id":"519707"}],"answer_ET":"C","answer_images":[],"timestamp":"2022-01-08 19:23:00","answer":"C","choices":{"A":"Use a text editor and the Git command line to send your source code updates as pull requests from a public computer.","B":"Use a text editor and the Git command line to send your source code updates as pull requests from a virtual machine running on a public computer.","D":"Use a Cloud Storage bucket to store the source code that you need to edit. Mount the bucket to a public computer as a drive, and use a code editor to update the code. Turn on versioning for the bucket, and point it to the team's Git repository.","C":"Use Cloud Shell and the built-in code editor for development. Send your source code updates as pull requests."},"answer_description":"","unix_timestamp":1641666180,"question_text":"You work for a web development team at a small startup. Your team is developing a Node.js application using Google Cloud services, including Cloud Storage and Cloud Build. The team uses a Git repository for version control. Your manager calls you over the weekend and instructs you to make an emergency update to one of the company's websites, and you're the only developer available. You need to access Google Cloud to make the update, but you don't have your work laptop. You are not allowed to store source code locally on a non-corporate computer. How should you set up your developer environment?","question_images":[]},{"id":"h0YBTOXQDE9GtjZ0Suv1","isMC":true,"answers_community":["AC (48%)","CD (33%)","AD (19%)"],"question_id":330,"topic":"1","exam_id":7,"url":"https://www.examtopics.com/discussions/google/view/69688-exam-professional-cloud-developer-topic-1-question-91/","discussion":[{"upvote_count":"10","poster":"ParagSanyashiv","content":"C,D are the correct in this case.","timestamp":"1641666480.0","comment_id":"519709"},{"timestamp":"1642857600.0","poster":"p4","content":"I go for A, C","upvote_count":"10","comment_id":"529871"},{"poster":"thewalker","upvote_count":"2","content":"Selected Answer: CD\nC. Single-line JSON to Cloud Logging: This is the most straightforward and efficient way to standardize logs. By writing logs as single-line JSON, you ensure consistent formatting and make it easy for Cloud Logging to parse and analyze the data. Cloud Logging automatically handles ingestion and storage.\nD. Logging API for Structured Logs: Using the Logging API directly allows for more control over log formatting and metadata. You can include specific labels, severity levels, and other information to make your logs more informative. This approach also ensures that logs are written directly to Cloud Logging, eliminating the need for additional processing steps.","comment_id":"1250334","timestamp":"1721302140.0","comments":[{"timestamp":"1721302140.0","content":"Why other options are less ideal:\n\nA. Aggregated Exports to BigQuery: While BigQuery is excellent for analytics, this approach requires additional steps to configure and manage exports. It's not the most efficient way to standardize logs initially.\nB. Aggregated Exports to Cloud Storage: Similar to option A, this adds complexity and requires additional processing to analyze the data in Cloud Storage.\nE. Pub/Sub and Dataflow: This is a more complex solution that involves multiple services and requires significant development effort. It's overkill for simply standardizing logs.","poster":"thewalker","upvote_count":"1","comment_id":"1250335"}]},{"content":"Selected Answer: AC\nCorrect answer AC","poster":"d_ella2001","upvote_count":"1","comment_id":"1247191","timestamp":"1720859460.0"},{"content":"Selected Answer: AC\nA: Obvious\n\nC: https://cloud.google.com/kubernetes-engine/docs/concepts/about-logs#best_practices:~:text=Structured%20logging%3A%20The%20logging%20agent%20integrated%20with%20GKE%20will%20read%20JSON%20documents%20serialized%20to%20single%2Dline%20strings%20and%20written%20to%20standard%20output%20or%20standard%20error%20and%20will%20send%20them%20to%20Google%20Cloud%20Observability%20as%20structured%20log%20entries.","timestamp":"1713314100.0","comment_id":"1196898","upvote_count":"1","poster":"alpha_canary"},{"poster":"santoshchauhan","comment_id":"1168564","upvote_count":"3","timestamp":"1709875080.0","content":"Selected Answer: AC\nC. Writing log output to standard output (stdout) as single-line JSON: This is a recommended practice for containerized applications running on Kubernetes. Kubernetes captures everything written to stdout and stderr and routes it to its logging agent (in this case, Cloud Logging in GKE). By structuring logs as single-line JSON, you enable Cloud Logging to ingest them as structured logs, which are more queryable and readable. This approach is efficient and does not require any changes in the application to use specific logging APIs.\n\nA. Create aggregated exports on application logs to BigQuery: Exporting logs to BigQuery allows for powerful analytics capabilities. BigQuery is well-suited for running fast, SQL-like queries on large datasets. By exporting logs to BigQuery, you can perform more complex analyses and gain deeper insights from your log data."},{"upvote_count":"4","content":"Selected Answer: CD\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/about-logs#best_practices","poster":"Kadhem","timestamp":"1703627520.0","comment_id":"1106410"},{"comment_id":"1103718","poster":"Kadhem","content":"Selected Answer: AC\nfewest steps + make log useful (analytics)","timestamp":"1703278440.0","comments":[],"upvote_count":"2"},{"upvote_count":"2","comment_id":"1079686","content":"Selected Answer: AC\nin the fewest number of steps --> C","timestamp":"1700879460.0","poster":"IF_FI"},{"comment_id":"1076630","content":"A & C:\n\nOption A to “make the data more useful”, as BigQuery will allow us to use big data analysis capabilities on the stored logs: https://cloud.google.com/logging/docs/export/aggregated_sinks#supported-destinations\n\nOption C to “to standardize their log data” creating structured logs: https://cloud.google.com/kubernetes-engine/docs/concepts/about-logs#best_practices\n\nOption D is also a viable solution but C is preferred, considering the “fewest number of steps” requirement.\n\nChoosing C and D together makes no sense, as both aim to achieve the same goal.","timestamp":"1700597700.0","upvote_count":"2","poster":"wanrltw"},{"timestamp":"1700250900.0","poster":"braska","comments":[{"content":"Both options for the same purpose then? Why would one implement option C having implemented option D?","timestamp":"1700596920.0","comment_id":"1076616","poster":"wanrltw","upvote_count":"1"}],"upvote_count":"3","comment_id":"1073587","content":"Selected Answer: CD\nWrite log output to standard output (stdout) as single-line JSON:\n\nThis practice allows you to use structured logs, specifically in JSON format, making it easier to parse and analyze log data.\nCloud Logging can ingest logs from standard output, and structured logs enhance the usability of log data.\nMandate the use of the Logging API in the application code to write structured logs to Cloud Logging:\n\nUsing the Logging API allows your applications to send structured log data directly to Cloud Logging.\nStructured logs provide more context and are easier to filter, search, and analyze within Cloud Logging."},{"timestamp":"1695190440.0","comment_id":"1011969","poster":"__rajan__","content":"Selected Answer: AC\nOption A: Create aggregated exports on application logs to BigQuery. This will facilitate log analytics by exporting application logs to BigQuery, which is a fully-managed, serverless data warehouse. BigQuery allows you to perform advanced analytics on your log data, including running complex queries and visualizing the results.\n\nOption C: Write log output to standard output (stdout) as single-line JSON to be ingested into Cloud Logging as structured logs. This approach involves writing log output to standard output in a specific format (single-line JSON) that can be easily ingested by Cloud Logging. By using structured logs, you can take advantage of advanced querying and filtering capabilities provided by Cloud Logging.","upvote_count":"2"},{"timestamp":"1692963360.0","poster":"maxdanny","upvote_count":"1","content":"Selected Answer: AC\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#best_practices","comment_id":"990000"},{"comment_id":"916272","content":"Selected Answer: CD\nCD. Only C and D mentioned Cloud Logging. Other options involve extra steps and won't come out free.\n\"When you create a new GKE cluster, Cloud Operations for GKE integration with Cloud Logging and Cloud Monitoring is enabled by default.\"\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#:~:text=When%20you%20create%20a%20new%20GKE%20cluster%2C%20Cloud%20Operations%20for%20GKE%20integration%20with%20Cloud%20Logging%20and%20Cloud%20Monitoring%20is%20enabled%20by%20default.","poster":"zanhsieh","upvote_count":"2","timestamp":"1686056940.0"},{"upvote_count":"1","comment_id":"888022","timestamp":"1683071340.0","content":"Selected Answer: AC\nfewest number of steps A &C","poster":"ryuhei"},{"comment_id":"821530","content":"Selected Answer: AC\nfewest number of steps -> i believe this sentence is the key. option D would take take.\nalso: https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#best_practices","upvote_count":"1","poster":"Pime13","timestamp":"1677333060.0"},{"upvote_count":"2","comment_id":"767586","comments":[{"comment_id":"767590","timestamp":"1673006040.0","upvote_count":"2","content":"A and B, which involve creating aggregated exports of log data to either BigQuery or Cloud Storage, are not necessary for standardizing log data. These options may be useful for storing and analyzing log data, but they are not necessary for standardizing the format of the log data. To standardize log data, it is sufficient to write log output to standard output (stdout) as single-line JSON, which can be ingested into Cloud Logging as structured logs.","poster":"omermahgoub"},{"poster":"omermahgoub","timestamp":"1673006100.0","comment_id":"767593","upvote_count":"2","content":"E, which involves using the Pub/Sub API and creating a Dataflow streaming pipeline to normalize logs and write them to BigQuery for analytics, is a more complex solution that requires more steps and is not necessary for standardizing log data. While this option may be useful for storing and analyzing log data, it is not necessary for standardizing the format of the log data. To standardize log data, it is sufficient to write log output to stdout and use the Logging API to write structured logs to Cloud Logging."}],"poster":"omermahgoub","content":"Anser is C&D\nTo standardize log data and make it more useful in the most efficient way, it is recommended to write log output to standard output (stdout) as single-line JSON to be ingested into Cloud Logging as structured logs. This method allows for easy and efficient ingestion of structured log data into Cloud Logging, which can then be easily queried and analyzed. Additionally, mandating the use of the Logging API in the application code allows for the writing of structured logs directly from the application code, improving the usability and reliability of the logs.","timestamp":"1673005860.0"},{"content":"Selected Answer: AD\na d is correct","poster":"cicciopuddu","upvote_count":"2","timestamp":"1671729180.0","comment_id":"753516"},{"content":"Selected Answer: AC\nAC is the answer.","timestamp":"1671638460.0","poster":"zellck","upvote_count":"1","comment_id":"752546"},{"upvote_count":"4","comment_id":"717858","timestamp":"1668418920.0","content":"https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#best_practices\nAnswer is A, C.\nIn best practices i dnt see anything to do with D","poster":"TNT87"},{"content":"Selected Answer: CD\nIf log data is to be standardized and made more useful with minimal steps, I think CD is the right answer.\nhttps://cloud.google.com/logging/docs/structured-logging","comment_id":"698625","upvote_count":"3","poster":"tab02733","timestamp":"1666147140.0"},{"timestamp":"1662259920.0","upvote_count":"4","comment_id":"658923","content":"https://cloud.google.com/logging/docs/structured-logging\nIf you're using Google Kubernetes Engine or the App Engine flexible environment, you can write structured logs as JSON objects serialized on a single line to stdout or stderr. The Logging agent then sends the structured logs to Cloud Logging as the jsonPayload of the LogEntry structure.\n\nThis point to C","poster":"NapFalg"},{"timestamp":"1660975200.0","comment_id":"649261","upvote_count":"3","content":"Selected Answer: AD\nAD are correct","poster":"tomato123"},{"content":"Selected Answer: AC\nGo with A, C for the \"fewest steps\"","poster":"kinoko1330","upvote_count":"2","comment_id":"649121","timestamp":"1660954200.0"},{"upvote_count":"3","comment_id":"642732","poster":"akshaychavan7","timestamp":"1659675480.0","content":"Selected Answer: AD\nI will go with an unpopular answer here. \nOption A - allowing log analytics\nOption D - standardizing the logs"},{"content":"Selected Answer: AC\nagree with a,c","comment_id":"604631","timestamp":"1653079080.0","upvote_count":"3","poster":"americoleonardo"},{"poster":"szl0144","content":"A&C seems correct, guys","timestamp":"1652828160.0","upvote_count":"2","comment_id":"603060"},{"timestamp":"1651768500.0","comment_id":"597390","upvote_count":"1","content":"the answer should be A (from the question -> make data more useful) and D (https://cloud.google.com/logging/docs/structured-logging)","poster":"[Removed]"},{"upvote_count":"1","content":"A , E \nE - Standardize the logs\nA - Making more useful of the data","comment_id":"579417","timestamp":"1648807500.0","poster":"dishum"},{"upvote_count":"3","timestamp":"1648256820.0","poster":"htakami","content":"A & E are great options for analytics but as the question refers to providing the answer with the fewest steps possible, I will go with the in-built Logging monitor features. (C&D)","comment_id":"575316"}],"answer_ET":"AC","answer_images":[],"timestamp":"2022-01-08 19:28:00","answer":"AC","choices":{"A":"Create aggregated exports on application logs to BigQuery to facilitate log analytics.","C":"Write log output to standard output (stdout) as single-line JSON to be ingested into Cloud Logging as structured logs.","D":"Mandate the use of the Logging API in the application code to write structured logs to Cloud Logging.","E":"Mandate the use of the Pub/Sub API to write structured data to Pub/Sub and create a Dataflow streaming pipeline to normalize logs and write them to BigQuery for analytics.","B":"Create aggregated exports on application logs to Cloud Storage to facilitate log analytics."},"answer_description":"","unix_timestamp":1641666480,"question_text":"Your team develops services that run on Google Kubernetes Engine. You need to standardize their log data using Google-recommended practices and make the data more useful in the fewest number of steps. What should you do? (Choose two.)","question_images":[]}],"exam":{"isMCOnly":false,"name":"Professional Cloud Developer","isImplemented":true,"id":7,"provider":"Google","isBeta":false,"lastUpdated":"11 Apr 2025","numberOfQuestions":338},"currentPage":66},"__N_SSP":true}